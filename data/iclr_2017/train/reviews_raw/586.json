{"conference": "ICLR 2017 conference submission", "title": "Extensions and Limitations of the Neural GPU", "abstract": "The Neural GPU is a recent model that can learn algorithms such as multi-digit binary addition and binary multiplication in a way that generalizes to inputs of arbitrary length.  We show that there are two simple ways of improving the performance of the Neural GPU: by carefully designing a curriculum, and by increasing model size.  The latter requires a memory efficient implementation, as a naive implementation of the Neural GPU is memory intensive.  We find that these techniques increase the set of algorithmic problems that can be solved by the Neural GPU: we have been able to learn to perform all the arithmetic operations (and generalize to arbitrarily long numbers) when the arguments are given in the decimal representation (which, surprisingly, has not been possible before). We have also been able to train the Neural GPU to evaluate long arithmetic expressions with multiple operands that require respecting the  precedence order of the operands, although these have succeeded only in their binary representation, and not with perfect accuracy.  In addition, we gain insight into the Neural GPU by investigating its failure modes.  We find that Neural GPUs that correctly generalize to arbitrarily long numbers still fail to compute the correct answer on highly-symmetric, atypical inputs: for  example, a Neural GPU that achieves near-perfect generalization on decimal multiplication of up to 100-digit long numbers can fail on $000000\\dots002 \\times 000000\\dots002$ while succeeding at $2 \\times 2$.  These failure modes are reminiscent of adversarial examples.", "reviews": [{"is_meta_review": true, "comments": "The paper investigates on better training strategies for the Neural GPU models as well as studies the limitations of the model.\n\nPros:\n* Well written.\n* Many investigations.\n* Available source code.\n\nCons:\n* Misleading title, there is no extension to the Neural GPU model, just to its training strategies.\n* No comparisons to similar architectures (e.g. Grid LSTM, NTM, Adaptive Computation Time).\n* More experiments on other tasks would be nice, it is only tested on some toy tasks.\n* No positive results, only negative results. To really understand the negative results, it would be good to know what is missing to make it work. This has not been studied further.\n* Some details remain unclear or missing, e.g. if gradient noise was used in all experiments, or the length of sequences e.g. in Figure 3.\n* Misleading number of NTM computation steps. You write O(n) but it is actually variable.\n\nAfter the results from the paper, the limitations still remain unclear because it is not clear exactly why the model fails. Despite showing some examples which make it fail, it was not studied in more detail why it failed for those examples, and how you could fix the problem.", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "This paper is clearly written, and contains original observations on the properties of the neural GPU model. These observations are an important part of research, and sharing them (and code) will help the field move forward. However, these observations do not quite add up to a coherent story, nor is a particular set of hypotheses explored in depth. So the main problem with this paper is that it doesn't fit the 'one main idea' standard format of papers, making it hard to build on this work.\n \n The other big problem with this paper is the lack of comparison to similar architectures. There is lots of intuition given about why the NGPU should work better than other architectures in some situations, but not much empirical validation of this idea.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"TITLE": "-", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_META_REVIEW": false, "DATE": "24 Dec 2016", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "scattered but interesting remarks don't quite add up to a publishable unit", "is_meta_review": false, "comments": "Overall the paper has the feel of a status update by some of the best researchers in the field. The paper is very clear, the observations are interesting, but the remarks are scattered and don't add up to a quantum of progress in the study of what can be done with the Neural GPU model.\n\nMinor remark on the use of the term RNN in Table 1: I found Table 1 confusing because several of the columns are for models that are technically RNNs, and use of RNNs for e.g. translation and word2vec highlight that RNNs can be characterized in terms of the length of their input sequence, the length of their input, and the sizes (per step) of their input, output, and working memories.\n\nBasic model question: How are inputs presented (each character 1-hot?) and outputs retrieved when there are e.g. 512 \u201cfilters\u201d in the model ?  If inputs and outputs are 1-hot encoded, and treated with the same filters as intermediate layers, then the intermediate activation functions should be interpretable as digits, and we should be able to interpret the filters as implementing a reliable e.g. multiplication-with-carry algorithm. Looking at the intermediate values may shed some light on why the usually-working models fail on e.g. the pathological cases identified in Table 3.\n\nThe preliminary experiment on input alignment is interesting in two ways: the seeds for effective use of an attentional mechanism are there, but also, it suggests that the model is not presently dealing with general expression evaluation the way a correct algorithm should.\n\nThe remarks in the abstract about improving the memory efficiency of Neural GPU seem overblown -- the paragraph at the top of page 6 describes the improvements as using tf.while_loop instead of unrolling the graph, and using swap_memory to use host memory when GPU memory runs short. These both seem like good practice, but not a remarkable improvement to the efficiency of the model, in fact it would likely slow down training and inference when memory does in fact fit in the GPU.\n\nThe point about trying many of random seeds to get convergence makes me wonder if the Neural GPU is worth its computational cost at all, when evaluated as means of learning algorithms that are already well understood (e.g. parsing and evaluating S-exprs). Consider spending all of the computational cycles that go into training one of these models (with the multiple seeds) on a traditional search through program space (e.g. sampling lisp programs or something).\n\nThe notes on the curriculum strategies employed to get the presented results were interesting to read, as an indication of the lengths to which someone might have to go to train this sort of model, but it does leave this reviewer with the impression that despite the stated extensions of the Neural GPU model it remains unclear how useful it might be to practical problems.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "24 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer5", "TITLE": "No Title", "is_meta_review": false, "comments": "The authors investigate the neural GPU model introduced by Kaiser and Sutskever. In section 3 they claim its performance is due to the O(n^2) number of steps it can perform for each example. In the subsequent section they highlight the importance of curriculum training and empirically show that larger models generalize better. In section 5 they construct examples that reveal failure modes. In the last section they compare the performance given different input formats.\n\nThe paper is well written. It contains an exhaustive set of experiments which provide insight into the details of training the neural GPU model. It pushes the boundary of algorithms that can be learned further. On the other hand, the paper seems to lack a coherent message. It also fails to provide any insight into the how and why of the observations made (i.e. why curriculum training is essential and why certain failure modes exist).\n\nThe introduction contains several statements which should be qualified or explained further. As far as I am aware statistical learning theory does not guarantee that empirical risk minimization is consistent when the number of parameters is larger than the number of examples; the generalization performance depends on the VC dimension of the function space instead. Furthermore, the suggested link between adversarial examples and learning algorithms is tenuous, and references or a further explanation should be provided for the contentious statement that deep neural networks are able to match the performance of any parallel machine learning algorithm.\n\nThe authors argue that the neural GPU performs O(n^2) \u201csteps\u201d on each example, which allows it to learn algorithms with super-linear complexity such as multiplication. This analysis seems to overlook the parallel nature of the neural GPU architecture: Both addition and multiplication have O(log n) time complexity when parallelism is used (cf. a carry-lookahead adder and a Wallace tree respectively).\n\nIn section 4 the authors show that their larger models generalize better, which they argue is not self-evident. However, since both training and test error decrease it is likely that the smaller models are underfitting, in which case it is not counter-intuitive at all that a larger model would have better generalization error.\n\nIt is interesting to see that progressively decreasing the number of terms and increasing the radix of the number system works well as a learning curriculum, although it would be nice to have a stronger intuitive or theoretical justification for the latter.\n\nThe final section claims that neural GPUs are cellular automata. Further justification for this statement would be useful, since cellular automata are discrete models, and the equivalence between both models is in no way obvious. The relationship between global operations and changing the input format is circuitous.\n\nIn conclusion, the paper provides some useful insights into the neural GPU model, but does not introduce original extensions to the model and does not explain any fundamental limitations. Several statements require stronger substantiation.\n\nPro:\n\n* Well written\n* Exhaustive set of experiments\n* Learning algorithms with decimal representation\n* Available source code\n\nCons:\n\n* No coherent hypothesis/premise advanced\n* Two or three bold statements without explanation or references\n* Some unclarity in experimental details\n* Limited novelty and originality factor\n\nTypos: add minus in \u201cchance of carrying k digits is 10^k\u201d (section 5); remove \u201care\u201d from \u201cthe larger models with 512 filters are achieve\u201d (section 4); add \u201ca\u201d in \u201csuch model doesn\u2019t generalize\u201d (section 4).", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "interesting paper but requires some more work", "is_meta_review": false, "comments": "The paper investigates on better training strategies for the Neural GPU models as well as studies the limitations of the model.\n\nPros:\n* Well written.\n* Many investigations.\n* Available source code.\n\nCons:\n* Misleading title, there is no extension to the Neural GPU model, just to its training strategies.\n* No comparisons to similar architectures (e.g. Grid LSTM, NTM, Adaptive Computation Time).\n* More experiments on other tasks would be nice, it is only tested on some toy tasks.\n* No positive results, only negative results. To really understand the negative results, it would be good to know what is missing to make it work. This has not been studied further.\n* Some details remain unclear or missing, e.g. if gradient noise was used in all experiments, or the length of sequences e.g. in Figure 3.\n* Misleading number of NTM computation steps. You write O(n) but it is actually variable.\n\nAfter the results from the paper, the limitations still remain unclear because it is not clear exactly why the model fails. Despite showing some examples which make it fail, it was not studied in more detail why it failed for those examples, and how you could fix the problem.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "extensions / improvements to NeuralGPU model, test data length, NTM steps", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "", "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "is_meta_review": false}, {"TITLE": "header typo: ICLR 2016", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "I guess you should write ICRL 2017 there.", "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "is_meta_review": false}], "SCORE": 5, "authors": "Eric Price, Wojciech Zaremba, Ilya Sutskever", "accepted": false, "id": ""}
