{
  "name" : "1609.05989.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Macro-optimization of email recommendation response rates harnessing individual activity levels and group affinity trends",
    "authors" : [ "Mohammed Korayem", "Trey Grainger" ],
    "emails" : [ "mohammed.korayem@careerbuilder.com", "khalifeh.aljadda@careerbuilder.com", "trey.grainger@careerbuilder.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "I. INTRODUCTION Recommender systems are widely deployed across many industries for diverse use cases such as e-commerce, advertising, media distribution, and job boards. Recommender systems automate the process of discovering the interests of a user and subsequently suggesting what should be relevant to his/her needs [1], [2].\nMany companies depend on recommender systems to help drive their revenue, like Netflix1, Amazon2, CareerBuilder3, etc. For example, Netflix, a movie rental and video streaming web site, offered a prize (known as the Netflix prize) of 1 million dollars in 2006 for any recommendation algorithm that could beat their recommender system, named Cinematch [3]. Netflix, like many other websites, depends heavily on\n1http://www.netflix.com 2http://www.amazon.com 3http://www.careerbuilder.com\nrecommendations in order to keep their customers interested in their service. Recommendations can take place while a user is browsing a website, or even asynchronously while the user is not actively online. In the former case, recommendations are focused on selecting similar items based on the other items with which the user has previously interacted. In the latter case, recommendation emails are often sent on a regular basis (i.e. nightly, weekly, or monthly) in order to recapture offline users’ attention and have them return to the website to reengage. These offline recommendation emails are more complicated than real-time recommendations due to the fact that they have to deal with two additional dimensions: 1) the right users to target among all users, and 2) the right time to send the recommendations to those users. Looking to the recommendation email process across a three-dimensional space of right person (who), right item (what), and right time (when) gives us a model to optimize the effectiveness of the system at generating quality recommendations that successfully re-engage offline users.\nWhereas a real-time recommendation system provides online recommendations to users while they are browsing a website or otherwise interacting with a system, e-mail recommendations must be much more carefully optimized to ensure they are only sent to users when the user will appreciate and benefit from them. There is a fundamental supply and demand problem here: once a user has left a website, they then become your supply of potential future customers to reengage, but every time you attempt to email them, you risk having them unsubscribe if they are for any reason unhappy with the email. Sending them a timely and relevant recommendation email is a good way to get them to return and reengage, but if you send too many emails to a user then you may annoy them and lose them as a future customer forever. You wouldn’t, for example, want to send a recommendation to every user of your system multiple times per day, as you may quickly run out of users to send to once they all unsubscribe from your service. Instead, it is important to drive as many successful conversions as possible with as few emails as possible, such that both you and your customers maximize the impact of your interactions.\nIn this paper we describe a novel system to address the three dimensions of a recommendation email system in order to maximize the aggregate response rate through sending the right content to the right people at the right time. This system has been deployed in production as part of CareerBuilder’s\nar X\niv :1\n60 9.\n05 98\n9v 1\n[ cs\n.A I]\n2 0\nSe p\n20 16\n2 recommendation email system, significantly increasing email response rates (by 50%) while simultaneously reducing (by 72%) the number of sent e-mails necessary to achieve those improved response rates."
    }, {
      "heading" : "II. RELATED WORK",
      "text" : "The main task of a recommendation system is to provide users with relevant content suggestions. It works by collecting the preferences of users for a set of items and then ranking other items for each user based on how interested the system predicts a user will be to see those other items [4]. There are two major types of recommendation systems: Collaborative filtering [5] and content-based recommendations (often refered to as content-based filtering) [4], [6], [7]. Content-based recommendation systems recommend items for a user based on the similarity of features between a user and the items being recommended. For example, a job posting may contain features such as a job title, skills, salary, and location, and a job seeker will similarly have a desired job title, list of skills, salary, and location. Because a content-based recommendation system is just performing a similarity calculation on features, a content-based recommendation system can actually match between any two sets of entities (i.e. item to item, user to item, user to user, etc.) with a shared feature space, as it relies on no past interactions with the items by users in order to make the recommendations.\nCollaborative filtering [8]–[11], on the other hand, is based on the concept that users with a shared interest in some items will also have a shared interest in other items. For example, a user who applies to a software engineering job is likely to apply to other jobs related to software engineering, whereas a user who applies to a registered nurse job is likely to apply to other jobs related to nursing. Thus if a new user applies to a registered nurse job, there is a good chance that if we look at the other people who applied to that job and recommend the other jobs those people applied to, that our new user may be interested in those other jobs, as well. Collaborative filtering can be performed using different approaches like factorization-based methods [12], graph methods [13], genetic algorithms [14], and case-based reasoning [15]. Hybrid approaches also exist, which can combine both collaborative filtering and content-based recommendations into a unified recommendation algorithm [16]–[19].\nWhile the majority of published research on recommendation systems focuses on some form of content-based, collaborative filtering-based, or hybrid algorithm for matching users with the best items (”what” to match), the additional dimensions of ”when” to match and even ”who” to match to maximize the response rate of the overall system are far less studied. The most related prior research to ours is [20], which tries to find the best time to send a job recommendation to a user in order to optimize the odds of that user acting upon the recommendation. Their system is focused on the when component of the recommendation system, while ours combines the three components of the recommendation together (who, what, and when), with a particular emphasis on the who and what being decided relative to a more prescriptive when dimension."
    }, {
      "heading" : "III. METHODS",
      "text" : "Our methodology aims to address the three dimensions of recommendation email relevancy: who to send to, what to send, and when to send. We ultimately choose one of these dimensions - when to send, as our fixed dimension from which we will pivot, choosing to calculate who to send to and what to send relative to each time window in which we choose to send a batch of recommendations. We address these three dimensions by utilizing both individual user behavior, as well as historical group behavior from other users within the same classification, in order to figure out who to send to and what to send for each time period. The individual user behavioral data predominantly dictates who to send to relative to when the recommendations will be sent, with the goal being to maximize response rate. The group behavioral data primarily determines what to send to a particular user from a list of candidate recommendation lists in order to maximize response rate. This fusion of personal and group behavioral data provides us with better understanding of what to send, when to send, and whom to target in order to maximize the aggregate response rate across the entire batch of sent recommendation emails."
    }, {
      "heading" : "A. Response Likelihood",
      "text" : "One of the most important goals for any recommendation email system should be to achieve a high response rate. Sending a high volume of emails with a low response rate will likely lead to several problems. First, sending too many emails to end users may overwhelm or annoy them, hurting the sender’s reputation and likely resulting in the user unsubscribing from future emails or possibly breaking ties completely with the sender. Second, sending emails that are not sufficiently interesting to the end user will result in reputational harm for the sender, since the sender will be perceived as having a low-quality platform that is not worth the end user’s time. Third, if too many emails are sent by the system to a particular email service provider, that email service provider may determine that the large volume of emails are spam, and they may blacklist the sender such that future emails to any recipients are blocked. Fourth, sending many emails without a good response rate is waste of resources since sending recommendation emails requires servers, queues, databases, and bandwidth to store, transmit, and track all of the emails.\nWith the risks of losing customers, losing the right to continue contacting customers, having a sender’s reputation damaged, having all future email communications blocked to all users, and wasting resources sending ineffective emails, it is clearly important that a recommendation email system optimize how it sends emails to maximize impact while minimizing emails sent.\nIn order to address these issues, recommendation emails should be sent only to the users who are most likely to respond. The immediate challenge, therefore, becomes how to predict those users with high response likelihood for a set of recommendations. In our system we utilize each user’s recent behavioral data with the hypothesis that active users were more recently interested and therefore are more likely to respond in general. Following this logic, if a user was active in the last 24\n3 hours his response likelihood will be higher than the someone who was active 7 days ago, while users with a last activity within 7 days are more likely to respond than others who were active 20 days ago. For Careerbuilder we tracked three kinds of behaviors to calculate recent activity levels, namely, searching for a job, applying to a job, and updating a resume.\nWe use the most recent of these activities to calculate what we call the Activity Score, which is the basis for our identification of users who are, in general, most likely to respond to recommendation emails. Assume a user u was active on a date dau while today’s date is dt. Also, assume that we only consider users who were active more recently than a given date do. We can calculate the Activity Score AS(u) as follows:\nAS(u) = 1− dt − dau dt − do\nThe only parameter that needs to be chosen here is the do. For CareerBuilder’s use case, we found that 90 days before the current date is a good cut-off threshold, as users tend to be much more responsive to recommendation emails within their first 90 days, but a response becomes much less likely beyond 90 days."
    }, {
      "heading" : "B. Group Trends",
      "text" : "In addition to looking at a user’s Activity Score to predict the general likelihood of that user responding to a recommendation email, it is also important to consider that not all recommendation emails sent to the user are equally likely to receive a response. Because we often have limited behavioral data for any particular user regarding the various data classification for which the user may be interested, we instead rely on historical group behavioral trends to learn affinities between the group of users within each classification and their likelihood of responding to a recommendation within any other classification.\nThe underlying theory here is that when users are classified into categories based on their common features, they tend to share similar interest as the other users in the same category. We built our second module of the proposed system upon that hypothesis, utilizing the group behavior within each category to predict the response rate of new users within the same category when shown items from any other category. The importance of this module is that it expands the selection pool of items beyond just those that fall under the same category as the targeted users. Without some notion of how related different categories are, it can be risky to recommend items not within the same category as the user. For example, in the recruitment domain users who are classified into the “Java Developer” category would probably not have a high response rate to recommended jobs from the “Registered Nurse” category, while they might respond very favorably to recommendation from the “Software Engineer” category, and reasonably well to recommendations from the “Hadoop Developer” category. The recommendation engine should thus be able to understand these category affinities when predicting response rates.\nTo understand the probabilistic model which we implemented to represent these category affinities and to predict\nCategory a Category b\nXt,1 Xt,2\nXt,3\nXt,4\nFig. 1. Group Trend. In this example users of category a interact with items of category b\nthe interest of a user based on his group’s behavior, let us first understand the notations we use to describe the model.\n1) u = 1, 2, ..., U is the index of the user. 2) a, b = 1, 2, ..., C is the index of the category. 3) ua = 1, 2, ..., Ua is the index of the user in category a. 4) ia = 1, 2, ..., Ia is the index of the item in category a. 5) t = 1, 2, ..., T is the index of transition a→ b, where a\nuser ua interacts with item ib 6) Ot = {xt,1, ..., xt,i} A set of all transitions of type t.\nxt,i is an instance i of transition t. 7) ra,b is the trend of users in group a towards items of\ngroup b 8) Sa,b = {xa,b,1, ..., xa,b,n} A set of all items of category\nb seen by users of category a. In figure 1 we show an example of a group trend. The example shows the transition trend of users ua towards items ib where xt,1 is an instance of that transition and Ot = {xt,1, xt,2, xt,3, xt,4}. We calculate the group trend as a transition probability from the users’ category to another category based on the number of interactions between those users and items from the other category.\nP (ra,b|t, sa,b) = |Ot| |sa,b|\nThe probability score represents the likelihood that users from category a would accept and interact with recommendations including items from category b. We build a transition graph modeling the probability score between different categories, and this transition graph is then utilized to select a list of recommendations corresponding with the highest probability of interest, as shown in figure 2."
    }, {
      "heading" : "IV. EXPERIMENT AND RESULTS",
      "text" : "To test the proposed system, we applied it within the recommendation email system at CareerBuilder, which is one of the largest job boards in the world. This system has millions of job postings, more than 60 million actively-searchable resumes, over one billion searchable documents, and more than a million searches per hour [21]–[23]. The recommendation\nTABLE I. RESULTS FOR THE PROPOSED SYSTEM AGAINST THE BASELINE (CONTROL) SYSTEM. THE PROPOSED SYSTEM IMPROVES TOTAL APPS, OSR, CTR, AND AOR WHILE REDUCING THE TOTAL NUMBER OF SENT EMAILS\nBaseline Proposed System Total Apps 10000 15000 Total Sent 500,000 150,000\nOSR: Open to Send Ratio. Opens / Emails Sent 29% 40% CTR: Click Through Rate. Clicks / Emails Sent 8% 32% AOR: Apps to Open Ratio. Applications / Emails Opened 6% 25%\nengine selects jobs of interest to job seekers and then sends those jobs via recommendation emails to job seekers. Hence, these are user-item recommendations, where the users are job seekers and the items are jobs. The previous recommendation email system at CareerBuilder would restrict sent emails to the target user’s category, which was not performing well because the system was overly restrictive and was unable to consider alternate, related categories that users within the initial category may also find interesting. Our methodology (shown in figure 3) has been applied in order to improve the quality and performance of CareerBuilder’s recommendation emails, so it was important to measure how the new system is performing compared to the old one. Our measurement was based on the open to send ratio and the number of job applications created based on the recommendation emails.\nWe define an indicator function as\nO(eui) = { 1 if eui is opened 0 if eui is not opened\nThen we calculate the open to send ratio as:\nOSR =\nn∑ i=1 O(eui)\nn\nwhere OSR is the open to send ratio, eui is the recommendation email sent to the user ui, and n is the total number of emails which were sent. This score represents the relevancy of the emailed job recommendations given the hypothesis that a user will not open a recommendation email if the job in that email is not of interest to that user.\nWhile the OSR is a good initial indicator of relevancy, we should note that the user is only exposed to limited information about the job being recommended (the job title) when reviewing the subject of the email. As a result, we capture another intermediate metric called the CTR (clickthrough ratio). For the CTR, we first define another indicator function as\nC(eui) = { 1 if eui is clicked from a link in the email 0 if eui is not clicked from a link in the email\n5 Then we calculate the click-through ratio as:\nCTR =\nn∑ i=1 C(eui)\nn\nBoth the OSR and the CTR provide valuable information about users’ perceptions about the relevance of the recommendations they are receiving. When comparing our baseline/control algorithm versus the proposed system, these metrics also show us useful information about drop-off at each step at which the user interacts with the recommendation. Our end goal, however, to actually convert a user’s interest in the job to an application for the job. To measure this, we need one additional metric: the application to open ratio (AOR). For the AOR, we defined one more indicator function:\nA(Appeui ) = { 1 if Appeui is a resulting job application 0 if Appeui is not a resulting job application\nThen we calculate the application to open ratio (AOR) as:\nAOR =\nn∑ i=1 A(Appeui )\nm\nwhere Appeui is a job application created based on the recommendation email eui , and m is the total number of emails where A(eui) = 1. While OSR represents the open rate of the sent emails, AOR represents the conversion of a recommendation e-mail into a job application, so AOR is the most important factor in our case. Table I shows the significant improvement in OSR and AOR delivered by the new system over the old one.\nWe can essentially view the email recommendations responses as a funnel, where all users who are sent recommendations are the starting volume, less users open the email (measured by the OSR metric), even less users click on a recommendation (measured by the CTR metric), and even less users apply to the job (measured by the AOR metric). In this funnel, we note that the improvement of the proposed system over the baseline/control system compounds at each step in the funnel. For example, we note that the OSR increases from 29% to 40%, meaning that more users are reading the subject of the email (which lists the title of the job being recommended) and identifying it as a potentially good match based upon that limited information. Then, once a user actually views the additional information about the job in the email, his/her interest in clicking on the job (CTR) to continue engaging with it improves even further, from the baseline of 8% CTR all the way to 32% CTR. Finally, for each of the opened emails, we also see an improvement in actual application rate (AOR) from 6% to 25%, meaning that drop-off has decreased at every stage in the funnel and that users are collectively finding the recommendations from the new system more relevant and timely for their interests."
    }, {
      "heading" : "V. CONCLUSION",
      "text" : "In this paper we presented a novel approach to improving the quality and response rate of recommendation emails. The\nproposed system utilizes personal behavioral data to calculate a per-user activity score to determine which users are most likely to respond at the present time based upon the most recent activity and type of activity they have exhibited. The new system additionally utilizes historical group behavior to build a transition graph which represents the probabilities that a typical user within any specific category would be likely to respond to recommendations for items from any other category. By leveraging both the group transition graph (likelihood of a typical user within a category to respond to recommendations within any particular category) and the personal activity score (likelihood of a specific user to respond to any recommendation), the proposed model is able to optimize the aggregate choice of which recommendations should be sent to which users for the given time period. The proposed model has been applied successfully within CareerBuilder’s job recommendation email system to increase total conversions by 50% while simultaneously decreasing emails sent by 72%."
    } ],
    "references" : [ {
      "title" : "Introduction to recommender systems: Algorithms and evaluation",
      "author" : [ "Joseph A Konstan" ],
      "venue" : "ACM Transactions on Information Systems (TOIS),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2004
    }, {
      "title" : "Itembased collaborative filtering recommendation algorithms",
      "author" : [ "Badrul Sarwar", "George Karypis", "Joseph Konstan", "John Riedl" ],
      "venue" : "In Proceedings of the 10th international conference on World Wide Web,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2001
    }, {
      "title" : "The netflix prize",
      "author" : [ "James Bennett", "Stan Lanning" ],
      "venue" : "In Proceedings of KDD cup and workshop,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2007
    }, {
      "title" : "Recommender systems survey",
      "author" : [ "Jesús Bobadilla", "Fernando Ortega", "Antonio Hernando", "Abraham Gutiérrez" ],
      "venue" : "Knowledge-Based Systems,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "An algorithmic framework for performing collaborative filtering",
      "author" : [ "Jonathan L Herlocker", "Joseph A Konstan", "Al Borchers", "John Riedl" ],
      "venue" : "In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1999
    }, {
      "title" : "Content-based recommendation systems. In The adaptive web, pages 325–341",
      "author" : [ "Michael J Pazzani", "Daniel Billsus" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2007
    }, {
      "title" : "Contentboosted collaborative filtering for improved recommendations",
      "author" : [ "Prem Melville", "Raymond J Mooney", "Ramadass Nagarajan" ],
      "venue" : "In AAAI/IAAI,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2002
    }, {
      "title" : "Explaining collaborative filtering recommendations",
      "author" : [ "Jonathan L Herlocker", "Joseph A Konstan", "John Riedl" ],
      "venue" : "In Proceedings of the 2000 ACM conference on Computer supported cooperative work,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2000
    }, {
      "title" : "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions",
      "author" : [ "Gediminas Adomavicius", "Alexander Tuzhilin" ],
      "venue" : "IEEE Trans. on Knowl. and Data Eng.,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2005
    }, {
      "title" : "Collaborative filtering with graph information: Consistency and scalable methods",
      "author" : [ "Nikhil Rao", "Hsiang-Fu Yu", "Pradeep K Ravikumar", "Inderjit S Dhillon" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2015
    }, {
      "title" : "A survey of collaborative filtering techniques",
      "author" : [ "Xiaoyuan Su", "Taghi M. Khoshgoftaar" ],
      "venue" : "Adv. in Artif. Intell.,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2009
    }, {
      "title" : "Kernelized matrix factorization for collaborative filtering",
      "author" : [ "Xinyue Liu", "Charu Aggarwal", "Yu-Feng Li", "Xiangnan Kong", "Xinyuan Sun", "Saket Sathe" ],
      "venue" : "In SIAM Conference on Data Mining,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2016
    }, {
      "title" : "Horting hatches an egg: A new graph-theoretic approach to collaborative filtering",
      "author" : [ "Charu C Aggarwal", "Joel L Wolf", "Kun-Lung Wu", "Philip S Yu" ],
      "venue" : "In Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1999
    }, {
      "title" : "Improving collaborative filtering recommender system results and performance using genetic algorithms",
      "author" : [ "Jesus Bobadilla", "Fernando Ortega", "Antonio Hernando", "Javier Alcalá" ],
      "venue" : "Knowledge-based systems,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2011
    }, {
      "title" : "A case-based reasoning view of automated collaborative filtering",
      "author" : [ "Conor Hayes", "Pádraig Cunningham", "Barry Smyth" ],
      "venue" : "In Case-Based Reasoning Research and Development,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2001
    }, {
      "title" : "Combining content-based and collaborative recommendations: A hybrid approach based on bayesian networks",
      "author" : [ "Luis M De Campos", "Juan M Fernández-Luna", "Juan F Huete", "Miguel A Rueda-Morales" ],
      "venue" : "International Journal of Approximate Reasoning,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "Hybrid recommender systems: Survey and experiments",
      "author" : [ "Robin Burke" ],
      "venue" : "User modeling and user-adapted interaction,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2002
    }, {
      "title" : "A hybrid approach for movie recommendation",
      "author" : [ "George Lekakos", "Petros Caravelas" ],
      "venue" : "Multimedia tools and applications,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2008
    }, {
      "title" : "Recommending web services via combining collaborative filtering with content-based features",
      "author" : [ "Lina Yao", "Quan Z Sheng", "Aviv Segev", "Jian Yu" ],
      "venue" : "In Web Services (ICWS),",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2013
    }, {
      "title" : "Is it time for a career switch",
      "author" : [ "Jian Wang", "Yi Zhang", "Christian Posse", "Anmol Bhasin" ],
      "venue" : "In Proceedings of the 22nd international conference on World Wide Web,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2013
    }, {
      "title" : "Pgmhd: A scalable probabilistic graphical model for massive hierarchical data problems",
      "author" : [ "Khalifeh AlJadda", "Mohammed Korayem", "Camilo Ortiz", "Trey Grainger", "John A Miller", "William S York" ],
      "venue" : "In Big Data (Big Data),",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2014
    }, {
      "title" : "Crowd sourced query augmentation through semantic discovery of domain-specific jargon",
      "author" : [ "Khalifeh AlJadda", "Mohammed Korayem", "Trey Grainger", "Chris Russell" ],
      "venue" : "IEEE International Conference on Big Data,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2014
    }, {
      "title" : "Query sense disambiguation leveraging large scale user behavioral data",
      "author" : [ "Mohammed Korayem", "Camilo Ortiz", "Khalifeh AlJadda", "Trey Grainger" ],
      "venue" : "In Big Data (Big Data),",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Recommender systems automate the process of discovering the interests of a user and subsequently suggesting what should be relevant to his/her needs [1], [2].",
      "startOffset" : 149,
      "endOffset" : 152
    }, {
      "referenceID" : 1,
      "context" : "Recommender systems automate the process of discovering the interests of a user and subsequently suggesting what should be relevant to his/her needs [1], [2].",
      "startOffset" : 154,
      "endOffset" : 157
    }, {
      "referenceID" : 2,
      "context" : "For example, Netflix, a movie rental and video streaming web site, offered a prize (known as the Netflix prize) of 1 million dollars in 2006 for any recommendation algorithm that could beat their recommender system, named Cinematch [3].",
      "startOffset" : 232,
      "endOffset" : 235
    }, {
      "referenceID" : 3,
      "context" : "It works by collecting the preferences of users for a set of items and then ranking other items for each user based on how interested the system predicts a user will be to see those other items [4].",
      "startOffset" : 194,
      "endOffset" : 197
    }, {
      "referenceID" : 4,
      "context" : "There are two major types of recommendation systems: Collaborative filtering [5] and content-based recommendations (often refered to as content-based filtering) [4], [6], [7].",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 3,
      "context" : "There are two major types of recommendation systems: Collaborative filtering [5] and content-based recommendations (often refered to as content-based filtering) [4], [6], [7].",
      "startOffset" : 161,
      "endOffset" : 164
    }, {
      "referenceID" : 5,
      "context" : "There are two major types of recommendation systems: Collaborative filtering [5] and content-based recommendations (often refered to as content-based filtering) [4], [6], [7].",
      "startOffset" : 166,
      "endOffset" : 169
    }, {
      "referenceID" : 6,
      "context" : "There are two major types of recommendation systems: Collaborative filtering [5] and content-based recommendations (often refered to as content-based filtering) [4], [6], [7].",
      "startOffset" : 171,
      "endOffset" : 174
    }, {
      "referenceID" : 7,
      "context" : "Collaborative filtering [8]–[11], on the other hand, is based on the concept that users with a shared interest in some items will also have a shared interest in other items.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 10,
      "context" : "Collaborative filtering [8]–[11], on the other hand, is based on the concept that users with a shared interest in some items will also have a shared interest in other items.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 11,
      "context" : "Collaborative filtering can be performed using different approaches like factorization-based methods [12], graph methods [13], genetic algorithms [14], and case-based reasoning [15].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 12,
      "context" : "Collaborative filtering can be performed using different approaches like factorization-based methods [12], graph methods [13], genetic algorithms [14], and case-based reasoning [15].",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 13,
      "context" : "Collaborative filtering can be performed using different approaches like factorization-based methods [12], graph methods [13], genetic algorithms [14], and case-based reasoning [15].",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 14,
      "context" : "Collaborative filtering can be performed using different approaches like factorization-based methods [12], graph methods [13], genetic algorithms [14], and case-based reasoning [15].",
      "startOffset" : 177,
      "endOffset" : 181
    }, {
      "referenceID" : 15,
      "context" : "Hybrid approaches also exist, which can combine both collaborative filtering and content-based recommendations into a unified recommendation algorithm [16]–[19].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 18,
      "context" : "Hybrid approaches also exist, which can combine both collaborative filtering and content-based recommendations into a unified recommendation algorithm [16]–[19].",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 19,
      "context" : "The most related prior research to ours is [20], which tries to find the best time to send a job recommendation to a user in order to optimize the odds of that user acting upon the recommendation.",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 20,
      "context" : "This system has millions of job postings, more than 60 million actively-searchable resumes, over one billion searchable documents, and more than a million searches per hour [21]–[23].",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 22,
      "context" : "This system has millions of job postings, more than 60 million actively-searchable resumes, over one billion searchable documents, and more than a million searches per hour [21]–[23].",
      "startOffset" : 178,
      "endOffset" : 182
    } ],
    "year" : 2016,
    "abstractText" : "Recommendation emails are among the best ways to re-engage with customers after they have left a website. While on-site recommendation systems focus on finding the most relevant items for a user at the moment (right item), email recommendations add two critical additional dimensions: who to send recommendations to (right person) and when to send them (right time). It is critical that a recommendation email system not send too many emails to too many users in too short of a timewindow, as users may unsubscribe from future emails or become desensitized and ignore future emails if they receive too many. Also, email service providers may mark such emails as spam if too many of their users are contacted in a short time-window. Optimizing email recommendation systems such that they can yield a maximum response rate for a minimum number of email sends is thus critical for the long-term performance of such a system. In this paper, we present a novel recommendation email system that not only generates recommendations, but which also leverages a combination of individual user activity data, as well as the behavior of the group to which they belong, in order to determine each user’s likelihood to respond to any given set of recommendations within a given time period. In doing this, we have effectively created a meta-recommendation system which recommends sets of recommendations in order to optimize the aggregate response rate of the entire system. The proposed technique has been applied successfully within CareerBuilder’s job recommendation email system to generate a 50% increase in total conversions while also decreasing sent emails by 72%.",
    "creator" : "LaTeX with hyperref package"
  }
}