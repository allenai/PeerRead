{
  "name" : "1302.4992.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Generating Explanations for Evidential Reasoning",
    "authors" : [ "Hong XU", "Philippe SMETS" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this paper, we present two methods to provide explanations for reasoning with be lief functions in the valuation-based systems. One approach, inspired by Strat's method, is based on sensitivity analysis, but its com putation is simpler thus easier to implement than Strat 's. The other one is to examine the impact of evidence on the conclusion based on the measure of the information content in the evidence. We show the property of ad ditivity for the pieces of evidence that are conditional independent within the context of the valuation-based systems. We will give an example to show how these approaches are applied in an evidential network.\n1 Introduction\nThe developers of expert systems have realized that a good facility to explain the computer-based reasoning to users is a prerequisite to their more widespread ac ceptance. The importance of explanation is due to two reasons. First, expert systems are usually used to solve difficult problems. A good explanation facility allows users to observe the inference process that leads the conclusions thereby increases their confidence in the system. Second, an explanation facility helps knowl edge engineers refine the problem solving knowledge.\nRecently, much attention has been paid to the gen eration of comprehensible explanations for uncertain reasoning, especially for probabilistic reasoning. One approach is to use sensitivity analysis since it can tell which parameters are most important and most af fect the result of the influence. For reasoning with be lief functions, Strat [ ?] has presented some strategies for generating explanation based on sensitivity analy sis. Here, we use this idea for generating explanation\nin a more general network - the valuation-based sys tems, and show that the computation can be simpli fied, therefore the implementation is easier.\nAnother approach for the explanation is to examine the individual impact of evidence on the overall con clusion. A classic technique for probabilistic reasoning is the weight of evidence. Weights of evidence have a useful property of additivity provided that the pieces of evidence are conditional independent. Another term for measuring the impact of a piece of evidence is the amount of information provided by the evidence [15]. Good [ 2] gave the analysis of these two measures and the relation between them. Within the context of be lief functions, Smets [ 8] has defined a measure of the information content provided by a piece of evidence to show its impact on a frame of discernment. The mea sure also has the additivity property for the distinct pieces of evidence. In this paper, we use this concept to examine the importance of different pieces of evi dence on the hypothesis and show the impact of the pieces of evidence which are conditional independent.\nThe rest of this paper is as follows: In section 2, we briefly review the basic concepts of evidential reason ing in the valuation-based systems. In section 3, we present the approaches for the explanation through a simple example. In section 4, we discuss the imple mentation issues of the proposed approaches. Finally in section 5, we give some conclusions.\n2 Evidential Reasoning\nDempster-Shafer theory [ 3, 9, 13] is regarded as a use ful tool for representing and manipulating uncertain knowledge. It provides flexible input requirements and an efficient method for combining information ob tained from multiple sources. In this section, we briefly review reasoning with belief functions in the valuation based systems. More details can be found in [ 6].\nGenerating Explanations for Evidential Reasoning 575\n2.1 Basic Concepts\nDefinition 1 Let n be a finite non-empty set called the frame of discernment (the frame for short). The mapping bel: 2° ___. {0, 1} is an (unnormalized) be lief function if and only if there exists a basic belief assignment (bba) m: 2° ___. {0, 1} such that:\n(i) L m(A) = 1,\n(ii) bel(A) = L m(B), BCA,B-:/:0 (iii) be/(0) = 0.-\nThose subsets A such that m(A) > 0 are called the focal elements. A vacuous belief function is a belief function such that m(f2)=1 and m(A)=O for all A i= n, which represents total ignorance.\nGiven a belief function, we can define a plausibility function pi: 2° ___.[0, 1] and a commonality function q: 2° ___.[0, 1] as follows: for A � n,\npl(A)\nq(A)\nbel(f2)- bel( A) and p/(0) = 0 L m(B) A�B�O\nwhere A is the complement of A relative ton.\nConsider two distinct pieces of evidence on n repre sented by m1 and m2. The belief function m12 = m1 EB m2 that quantifies the combined impact of these two pieces of evidence is obtained by the (unnormal ized) Dempster's rule of combination. The computa tion is as follows: VA � n,\n(m1 EB m2)(A) = L m1(B)m2(C) BnC=A\nIf the commonality functions are used, then\nThe m12(0) measures how much m1 and m2 are con flicting [11]. And k = 1- m12(0) is a normalization factor in Dempster's rule for getting a normalized be lief function. In this paper, we will discard the nor malization factor1 for the computation.\n2.2 Valuation-Based Systems\nValuation-based systems (VBS) is an abstract frame work proposed by Shenoy [6] for uncertainty repre sentation and reasoning. It can represent uncertain\n1The normalization factor has been criticized by Zadeh [19] with a counter-example which shown the danger of its blind application. More discussion about the normalization problem can be found in [9].\nknowledge in different domains including probability theory, belief function theory, and possibility theory, etc.. The graphical representation of VBS is called a valuation network. A VBS representation consists of a set of variables, and a set of valuations defined on the subsets of variables. The set of all the variables, de noted by U, represents the universe of discourse of the problem. For each variable X;, we use 8x; to denote the set of its possible values, and call it the frame of X;. For some subset A(IAI > 1) of U, a set of valuations defined on 8 A represents the relationship among the variables in A, where the frame eA is the Cartesian product of all 8x; for X; in A . We call the knowl edge represented by this kind of valuations the generic knowledge. In VBS, we can also define the valuations on single variables, which represent the so-called fac tual knowledge. We use H to denote the set of all subsets on which the valuations are defined. The valu ations are specialized as belief functions in the case for Dempster-Shafer theory. We call such V BS an eviden tial reasoning system or simply an evidential system, and the valuation network an evidential network.\nThe goal of evidential reasoning is to assess a certain hypothesis when certain pieces of evidence (factual knowledge) are given. The way to assess the hypoth esis is to infer its belief value from the belief values of the evidence. This can be done by evaluating the valuation network by two steps: (1) combine all be lief functions in the network, resulting in the so-called global belief function; (2) marginalize the global belief function to the frame of each variable or subsets of variables, obtaining the marginals for each variables or for subsets of variables. The operations for the rea soning are combination and marginalization which are defined as follows:\nCombination EB: Suppose mA and mB are two bba's on the subsets A and B, then mA EB mB will be the bba on Au B computed by: Vc � eAuB,\nafAUBnb!AUB=e\nwhere a fAuB and b T AuB are the cylindric extension of a(� 8A) and b(� 8B) to 8AuB, respectively.\nMarginalization l: Suppose mA is a bba on a subset A and suppose B � A, B i= 0. The marginal of mA for B, denoted by m!B, is a bba on B computed by: Vb � eB,\nwhere a!B is a projection of a to 8 B by projecting each element of a to 8 B.\n576 Xu and Smets\nThe marginal for a variable X; is computed by: (E9{belBIB E H})!X•.\nAs it is not feasible to compute the global belief func tion when there are a large number of variables in the network, Shenoy and Shafer [5] has proposed a local computation technique to compute the marginals for variables without computing the global belief function explicitly. For the details of the technique, readers can refer to [4, 5].\n3 Explanation of Reasoning Process\nOne major goal of the work on explanation is to un derstand the reasoning process of an evidential sys tem. This helps the builders and the users to maintain the system and to use it effectively. Explanations can usually be performed by answering the questions such as: why a specific hypothesis is strongly supported, or not? Which evidence is more influential to the conclu sion? etc .. In this section, we present two methods for the explanations by answering such kinds of questions through a simple example2•\nExample: The Captain of a ship would like to know how many days late a ship will arrive in port. The goal is to find the Arrival delay, or by how many days the ship will be delayed (assumed to be an integer). This delay is the sum of two attributes: the Departure delay and the �ailing delay (both of which are expressed as an integer number of days). Before the ship leaves port it could be delayed for fLoading problems; a E.orecast of foul weather could cause the Captain to delay de parture; and Maintenance could cause the ship to sit at the dock (we simplify these to true/false variables for the example). For simplicity, we assume that each of these factors delay departure by one day. Therefore the total Departure delay could be up to three days. Similarly, bad Weather en route could cause delays, as could need making J1.epairs at sea (again simplified to true/false variables). These delays contribute to the �ailing delays, again an integer number of days. Fig ure 1 shows the evidential network for the problem. In the network, there are 8 variables represented by the circles and 7 valuation variables represented by the diamond-shaped rectangles. The belief functions rep resenting the relations among the variables are defined on the valuation variables connecting the variables they include, the details about the relations among the variables are shown in the appendix. We can also provide prior beliefs for some variables, regarded as the evidence, which are stored in the valuation vari ables connected to those variables. In this example,\n2The example is abstracted from [1] with minor changes on some prior beliefs.\nFigure 1: An evidential network for the Captain prob lem where U={A, D, S, F, L, M, W, R}.\nwe have three pieces of evidence on the variable L, M and F, respectively, shown in table 1.\nAs the goal of the example is to find how many days late the ship might arrive in port, the marginal for the variable A will be the focus of our attention. This can be obtained by evaluating the network using lo cal computation. Note that the possible value of A is eA={0,1,2,3,4,5,6}. The result is shown in table 2.\nGenerally, it is difficult to interpret the raw focal el ements for the non-binary variables. So we will look at beliefs and plausibilities for the singleton subsets of eA which correspond to each day and for the single ton subsets of a coarsening frame e� = { {0,1}, {2,3}, { 4,5,6}}. Table 3 shows the result.\nGenerating Explanations for Evidential Reasoning 577\nArrival delay.\nConsidering frame E> A, we find that the most plausible day that the ship might delay is one day, and that it has the strongest support. However, the belief on the subset { 1} is very small. So we look at a coarsening frame E>A. From E>A, we find that being late within one day is strongest supported and more than 4 days is hardly plausible. Now we would like to know the origin of the support given to the conclusion. Since there are several prior beliefs (or pieces of evidence), which one is most important to the result? In the rest of this section, we will discuss two strategies to answer such kinds of questions.\n3.1 Sensitivity of the support for the hypotheses of a piece of evidence\nConsider n distinct pieces of evidence £; (i=1, . . . ,n) on E> represented by belief functions bel; . bel quantifies the combined impact of the n pieces of evidence. Sup pose X E E>, bel({x}) � bel({z}) for all z E e, z #X. Strat [?] has proposed a tool to explain why a par ticular hypothesis was found to be strongly (weakly) supported based on sensitivity analysis. Since the re quirement of systematic variation for sensitivity anal ysis is not feasible for the case of belief functions, Strat proposed to use discounting operation. The idea is to first use the discounting operation for each evidence. I.e.,\ndiu( ) - { a;m;(a) a # e m; a - 1- a;+ a;m;(E>) otherwise. where a; is the credibility of the original evidence £;, and then proceed the following,\n1. compute for each evidence: -- 8bel4''\"(x)\nI bel;(x) = aa • o;=l Pt. (x) = 8pl\ndo.c(x) I • aa, a;=l\nwhere j=1, . . . , n. Here bd;(x) can be interpreted as the sensitivity of the support for x of £;, and likewise for Pt i ( x).\n2. Identify those £; with the extreme values.\nIn general, the positive values of bd; ( x) and Pt; ( x) in dicates the support to the conclusion, while the nega tive one indicates that the evidence argues against the conclusion. The larger the absolute value of bd;(x) or pl1(x) is, the greater the impact of£; upon the hy pothesis is. Positive bd;(x) and negative pl1(x) means decreasing the ignorance without necessarily arguing for or against hypothesis, while negative bd; ( x) and positive Pt;(x) indicates adding to the confusion about the hypothesis. Note that in [?], the normalized belief function is used for the analysis. In this paper, we will always use the unnormalized belief. Moreover, instead of analyzing the impact on the belief of a single hy pothesis, we also consider the case for some subsets of the hypotheses if they are meaningful.\nStrat [?] showed that, in practice, numeric techniques are required to compute these quantities, and in real ity, they are computed by:\nb-l·( ) ,..., [be/f i'c( X )]a;=l - [belfi'c( X )]a;=l-b e,x ,..., 8\nfor some small8. So as for pl;(x). The following theo rem [17] shows that if we do not consider the normal ization factor, bd;(x) and Pt;(x) are constants, and thus can be computed precisely.\nTheorem 1 Consider n distinct pieces of evidence £; (i=l, . . . , n) on e represented by bel; . Let bel quantify the combination of the n pieces of evidence, bel-i be the combination of n-1 belief functions except bel; , i.e., bel-i =EB{beli li = 1, ... , n, j # i}. Then, Vx � e\nbd;(x) Pt;(x)\nbel(x)- bel-'(x), p/(x) - pl-'(x).\nFrom theorem 1, we find that bd; ( x) is in fact the dif ference of bel for x between the cases when £; is con sidered and not considered given the other evidence. So as for pl1(x). It is not difficult to derive that the similar result holds in the evidential systems.\nCorollary 1 Let U ={Xl, . . . ,Xn} be the set of the variables in an evidential system. Suppose Xj (EU) is the hypothesis variable that we are interested in, and suppose we have prior beliefs on some variables. Then the sensitivity of the impact of variable X; on X� ex, is computed by:\nbd;(x) = (EB{be/AIA E H})!X;(x) -(EB{belAIA E (H- {X;})})!X;(x), (1)\nand likewise for pl;(x).\nFrom eq.(1), we find that, to compute bd;(x), we only need to compute the differences of the bel and p/ for\n578 Xu and Smets\nx between the cases where £; is considered and not considered. This makes the computation easier.\nExample (continued): According to theorem 1, we compute the sensitivity of the support to the hypothe ses of L, F, and M respectively. The result is shown in table 4.\nLet's first look at the change of the belief and of the plausibility for the singleton subsets of eA. From ta ble 4, it can be found that none of the three pieces of evidence explicitly argue for or against the hypothesis \"being one day late\" since bei x (a) > 0 and PIx (a) < 0 (X E {F,M,L}). All three ague against {6} since Wx(a) = 0 and Plx(a) < 0 and the evidence on E.orcast has the largest impact. Now consider the sup port for {0, 1} and {4, 5, 6}, we have that the evidence on Maintenance is the only one supporting {0, 1} and arguing against { 4, 5, 6} while the other two only de crease the ignorance.\n3.2 Analysis of the Measure of Information provided by a piece of evidence\nApart from sensitivity analysis, another way to explain the reasoning process is to analyze the amount of in formation provided by the evidence, thus the impact of the evidence on the overall conclusion instead of on a single hypothesis. Measures of information are of ten quantified such that the additivity property holds. In the theory of belief functions, Smets [8] gave the following definition:\nDefinition 2 Let !(bel) denote the amount of infor mation in a piece of evidence £ represented by a belief function bel on n. Then !(bel) is computed by:\nI(bel) =- L logq(a) ac;n\nwhere q is the commonality function.\nNote that in this paper all the beliefs should be such as m(f!) > 0, called the non-dogmatic belief functions. In this case, !(bel) is non-negative. Otherwise I(bel) is infinite, for which case Smets gave a discussion in [8]. From definition 2, we find that a vacuous belief\nfunction contains no information, i.e., I(bel)=O. The following lemma states the additivity property such that the amount of information of the combination of two distinct pieces of evidence3 is the sum of the in formation of these two pieces of evidence.\nLemma 1 Consider two distinct pieces of evidence £1 and £2 on n represented by bell and bel2. bel12 quan tifies the combined impact of £1 and £2. Then\nI(bel12) = I(beh) + I(bel2).\nIt is easy to generalize lemma 1 to the case of n distinct pieces of evidence: Let bel denote the belief quantify ing the combined impact of the n pieces of evidence. We have: n\nI(bel) = L I(bel;). (2) i=l\nTherefore, we define the information brought by a dis tinct piece of evidence &n+l as following:\n6.r+1 = I(bel EB beln+l)- !(bel)= I(beln+l)· (3)\nThen the explanation is as follows: Let £1, ... , &n ben distinct pieces of the evidence on n. £; brings the most information on n or £; is the most important evidence iff 6.11;::: 6.Ji or !(bel;);::: I(beli) for j = 1, . . . , n.\nGenerally, in an evidential network, let X be a hypoth esis variable that we are interested in, X1, . . . , Xn be some evidence variables. Suppose we have prior beliefs belax, on some of Xfs. After propagation, we can get the marginal of the global belief function bela for X. In the rest of this section, we analyze how much infor mation each piece of evidence has brought to X, thus explain which piece of evidence is most important to the conclusion.\nDefinition 3 In an evidential network, suppose X is a hypothesis variable that we are interested in. Let bela be the global belief function where all the prior beliefs are vacuous Suppose there is one prior belief belax, on some variable X;. Then we define the amount of information that X; has brought to X individually as:\nI(X;) =!((bela EB belax.)!X)- I(bel5x),\nSuppose A � U, then the amount of information that A has brought to X is defined as:\nJ(A) =!((bela EB {belax,!X; E A})!X)- I(bel5x).\nDefinition 4 Let bel-i = bela EB {belaxi !Xi # Xi}. Then we can define the amount of information that X; brought to X given the other evidence as:\n3Smets [10] has given a definition for the concept of distinct evidence\nGenerating Explanations for Evidential Reasoning 579\nWe can also define t1I(B) for a subset B: let bel-B = belotB {belox; IXi fl. B}, then we have:\nt1l(B) = l(bel!X)- l((bel-8)!X).\nGenerally, the amount of information that a subset A brought to X is not the sum of the information brought to X individually, i.e., I(A) :/= L:x;eA I( X;). When there are more than one pieces of evidence, the amount of information that Xi brought to X given the other evidence does not always equal to the informa tion it brought to X individually, i.e., t1/(X;) :f= I( X;). This is because the combination and coarsening are not commutative. However, the conclusion is differ ent when there exist the relations of conditional in dependence among the variables. Theorem 2 and its corollary will illustrate such relations. F irst, let's look at the concept of conditional independence in VBS, which is given in [7].\nDefinition 5 Suppose S, T , and X are disjoint sub sets of U. We say S and T are conditionally indepen dent given X, written as S l.. T I X, if and only if bel!XUSUT = bel!XUS (B bel!XUT.\nTheorem 2 Let A, B be two disjoint subsets of U, X be the hypothesis variable we are interested in, and A l.. B I X4• Suppose bel�x is vacuous and only the variables in A or B have prior beliefs. Then we have the following relations for the information measures. (Proof can be found in {17]}\nI(AUB) =l(A)+I(B), t1I(A) = I(A),\nt1I(AUB) = t1I(A)+t1I(B), t1I(B) = I(B)\nCorollary 2 Suppose all the variables which have prior beliefs are conditionally independent given X, i. e., for any Xi, Xj such that belox;, belox; are not vacuous, Xi l.. Xj I X. And suppose bel� x is vacu ous. Then t1I(Xi) =!(Xi), and I(A) = L:x;eA !(Xi) where A is the set of all the variables with prior beliefs.\nIn an evidential system, when we analyze the impact of a piece of evidence on the conclusion, it generally depends on the situation where the other pieces of ev idence are given. Thus, to answer the question such as: which evidence brings most (less) information or which evidence is the most (less) important to the con clusion, we select the one whose t1/(X;) is the biggest.\nExample (continued): By applying eq. (4) in the cap tain example, we have:\nt1I(L) t1I(F)\nt1I(M)\nI(bel!A) - I( (bel-L )!A) = 60.47 I(bel!A)- I((bel-F)!A) = 67.60\n!(belLA)- I((bel-M)!A) = 102.95. 4We write X for {X} when confusion is absent.\nTherefore, for the question \"which evidence is the most important to the conclusion?\", the evidence on Maintenance would be its answer.\n4 The Implementation Issue\nWe have presented the approaches for the explanation. Now we discuss their implementation. First, we intro duce the concept of removal. Smets [14] defined the operator e as the inverse of the operator tB in the sense that:\nbell tB bel2 e bel2 = bell for any bell and bel2 on n, and bel1 8 bel1 is a vacuous belief function.\nIn VBS, Shenoy [7] gave the definition of removal e for belief functions as follows: Considering two valuations represented by the commonality functions qA and qn on the subsets A and B. Then qA 8 qn will be on AU B computed by5: Tfc � 8AuB,\nGiven the operator e, eq. (1) for the computation of the sensitivity of support can be rewritten as:\nbeJ;(x) = bel!X (x)- (bel 8 beloxJ!X (x),\nt1l(X;) = l(bel!X)- !((bel 8 beloxJ!X), where bel is the global belief function and X is the variable we are interested in.\nAs mentioned before, we use local computational tech nique to compute bel!X 0 To compute (bel e bel ox; )!X, one way is to remove the prior belief for each variable and repropagating the changes in the whole network each time. This needs a lot of redundant computation. From the definition of removal operator, it is easy to have:\n(bel 8 beloxJ!X = (bel!(XUX;) 8 beloxJ!X (5) That's to say, if we compute bel!(XuX;) by local com putation, then we can compute (bel 8 beloxJ!X di rectly, Xu [18] has proposed a method to compute the marginals for any subsets from the marginal represen tation, avoiding the unnecessary computation. There fore, (bel 8 beloAJ!X can be computed as follows:\n1. From the marginal we have computed, we first compute the marginals bel!XUX; for all Xfs which have prior beliefs. This can be done in parallel according to [18];\n5The removal operation for the case of belief function may result in a non-belief function if qB has not been com bined in qA before being removed. In this paper, this will not happen since in the later discussion, all the valuations to be removed are those having been combined previously.\n580 Xu and Smets\n2. Compute (bel e beloxJ!X by applying eq. (5).\nThen we can easily compute beli(x), pli(x) and �I(X;) for the explanation purpose.\n5 Conclusions\nWe have presented two approaches to explain reason ing process in general evidential systems. One is to compute the sensitivity of the support to a hypothe sis based on sensitivity analysis , the other is to explain which evidence is the most important to the whole con clusion based on the measure of information that the evidence provides. We have also discussed the possibil ity of implementing these approaches. In this paper, we only consider the impact of a single piece of ev idence. However, the approaches can be generalized to find the strongest relevant subset of factual knowl edge (evidence) Rjact to the conclusion by a stepwise procedure as following:\n1. Find the strongest relevant evidence (whose has greatest impact on the conclusion) Xi such that �I(Xi) � �I(Xk)· Let RJact ={Xi};\n2. Find the next strongest one Xj such that �I(RJactU{Xj}) � �I(RJactU {Xk}), Xj, Xk � Rjact · Let Rjact = Rjact U {Xj };\n3. Do step 2 iteratively until the increase in �I(Rjact U {Xj}) is negligible when adding more Xj in R 1 act. Then we find a small set of strong rel evant evidence. e.g., in figure 2, when the number of elements in Rjact is larger than 6, the increase in �I(Rjact) can be negligible, thus we keep the first 6 pieces of evidence in R 1 act.\n4. Since �I(Xi) is the amount of information that Xi brought given the other evidence, it is pos sible that 3Xi E Rjact such that �I(X;) > �I(Xk), Xk E RJact , but �I(Xi) � �I(RJact {Xi}). Then Xi can not be regarded as a strong relevant piece of evidence to the conclusion since\nits impact depends on the appearance of the other evidence and thus should be removed from Rjact· After all such kind of Xi removed, the rest Rfact will be the strongest relevant subset of factual knowledge.\nIn this paper, we focus our attention on the numeric computation, further research on integrating the quali tative analysis and on the natural language processing is needed to perfect the explanation facilities and to provide a better user-friendly interface.\nAcknowledgment\nThe authors would like to thank the anonymous refer ees for their comments. This research work has been partially s:upported by the ESPRIT III , Basic Research Project Action 6156 (DRUMS II) funded by a grant from the Commission of the European Communities. The first author is supported by a grant of IRIDIA, Universite libre de Bruxelles.\nAppendix: Belief Functions on the Valuation Variables for the Example:\nThe relationship among A, D, S can be expressed as a = d + s where a E 6A = {0 ... 6}, dE 6D ={0 ... 3} and s E 6s ={0 ... 3}. Then belief function for {A, D, S} lS:\n(1,1,0) (2,1,1) (3,1,2) (4, 1,3) -1 ({ (0, 0, 0) (1, 0, 1) (2, 0, 2) (3, 0, 3) })\nm (2, 2, 0) (3, 2, 1) (4, 2, 2) (5, 2, 3) - ·\n(3,3,0) (4,3, 1) (5,3,2) (6,3,3)\nFor {D, L, M, F} , any of L, M, or F being true adds one day to the total delay D. The belief function is:\n({ (0, F, F, F) (1, T, F, F) (1, F, T, F) }) m (1, F, F, T) (2, F, T, T) (2, T, F, T) = 1.\n(2, T, T, F) (3, T, T, T)\nSimilar for the {S, W, R}, but we expect our rule to be accurate 90% of time. Then,\nm( {(0, F, F), (1, F, T), (1, T, F), (2, T, T)}) m(6s X 6w X 6R)\n.9\n. 1.\nIf the weatherman was 100% accurate, we could ex press the rule { F, W } as F ,...... W. But we have only 80% confidence in the weatherman. Thus:\nm( {(F, F), (T, T)}) .8 m(6w X 6R) .2.\nIf we have a separate body of evidence that indicates that the ship breaks down between 20 and 80% of the\nGenerating Explanations for Evidential Reasoning 581\ntime after no maintenance and that 10 to 30% after maintenance. R given M:\nbelief of R given M T F {T} .1 .2 {F} .7 .2 eR .2 .6\nBelief on the product space R x M can be computed by using so-called ballooning extension proposed by Smets [12]:\nnn({(T,T), (T,F), (F,F)}) .06 nn( {(T, T), (T, F)}) .02 nn({(T,T), (F,F)}) .02\nnn({(T,F), (F, T),(F,F)}) .42 nn( {(T, F), ( F, T)}) .14 nn({(F,T),(F,F)}) .14\nnn({(T,T),(T,F), (F,T)}) .04 nn({(T,T), (F,T),(F,F)}) .04\nm(8R X 8M) .12.\nReferences\n[1] Almond R., Fusion and Propagation in Graphical Belief Models, in Wegman E. J ., Gantz D. T. and Miller J. J. eds. Computing Science and Statis tics: Proc. of the 20th Symposium on the Inter face (American Statistical Association, Alexan dria, Virginia, 1988).\n[2] Good I. J ., Good Thinking - The Foudations of Probability and Its Applications (University of Minnesota Press, Minneapolis, 1983).\n[3] Shafer G., A Mathematical Theory of Evidence (Princeton University 1976).\n[4] Shafer G. and Shenoy P. P., Local Computation in Hypertrees, Working Paper No. 201, School of Business, University of Kansas, Lawrence, KS, (1988).\n[5] Shenoy P. P. and Shafer G., Propagating Belief Functions with Local Computations, IEEE Expert 1 (1986) 43-52.\n[6] Shenoy P. P., Valuation-Based Systems: A frame work for managing uncertainty in expert systems, in L. A. Zadeh and J. Kacprzyk eds. Fuzzy logic for the Management of Uncertainty (John Wiley & Sons, NewYork, 1992) 83-104.\n[7] Shenoy P. P., Conditional Independence in Valuation-based Systems, Int. J. of Approximate Reasoning 10 (1994) 203-234.\n[8] Smets Ph., Information Content of an evidence, Int. J. Man-Machine Stud. 19 (1983) 33-43.\n[9] Smets Ph., Belief Functions, in Smets Ph., Mam dani A., Dubois D. and Prade H. eds. Non Stan dard Logics for Automated Reasoning (Academic Press, London, 1988) 253-286.\n[10] Smets Ph., The Concept of Distinct Evidence, in Proc. of the 4th Int. Conf. of Information Processing and Management of Uncertainty in Knowledge-Based Systems (1992) 789-794.\n[11] Smets Ph., The Nature of the Unnormalized Beliefs Encountered in the Transferable Belief Model, in Dubois D., Wellman M. P. D'Ambrosio B. and Smets Ph. eds. Proc. 8th Uncertainty in Artificial Intelligence (San Mateo, Ca.: Morgan Kaufmann, 1992) 292-297.\n[12] Smets Ph., Belief Functions: the Disjunctive Rule of Combination and the Generalized Bayesian Theorem, Int. J. of Approximate Reasoning 9 (1993) 1-35.\n[13] Smets Ph. and Kennes R., The transferable belief model, Artificial Intelligence 66 (1994) 191-234.\n[14] Smets Ph., The Representation of Quantified Be lief by the Transferable Belief Model, Technical Report, TR/IRIDIA/94-19.1, IRIDIA, Universite libre de Bruxelles, Belgium, (1994).\n[15] Spiegelhalter D. J. and Knill-J ones R. P., Statisti cal Knowledge-based approaches to clinical deci sion Support Systems, with an application in gas troenterology (with discussion), J. of the Royal Stratistical Society A147 (1984) 35-77.\n[16] Strat T. and Lawrence J., Explaining evidential analyses, Int. ]. of Approximate Reasoning 3( 4) (1989) 299-353.\n[17] Xu H. and Smets Ph., Some Strategies for the ex planation in Evidential Reasoning, Technical Re port, TR/IRIDIA/94-29, IRIDIA, Universite li bre de Bruxelles, Belgium, (1994).\n[18] Xu H., Computing Marginals for Arbitrary Sub sets from the Marginal Representation in Markov Trees, Artificial Intelligence 7 4 (1995) 177-189.\n[19] Zadeh L., A mathematical theory of evidence (book review), AI Magazine 5(3) (1984) 81-83."
    } ],
    "references" : [ {
      "title" : "Fusion and Propagation",
      "author" : [ "R. Almond" ],
      "venue" : "Graphical Belief Models,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1988
    }, {
      "title" : "A Mathematical Theory of Evidence (Princeton",
      "author" : [ "G. Shafer" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1976
    }, {
      "title" : "Local Computation in Hypertrees",
      "author" : [ "G. Shafer", "P. Shenoy P" ],
      "venue" : "Working Paper No. 201, School of Business,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1988
    }, {
      "title" : "Propagating Belief Functions with Local Computations",
      "author" : [ "P. Shenoy P", "G. Shafer" ],
      "venue" : "IEEE Expert",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1986
    }, {
      "title" : "Valuation-Based Systems: A frame­ work for managing uncertainty in expert systems",
      "author" : [ "P. Shenoy P" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1992
    }, {
      "title" : "Conditional Independence in Valuation-based Systems, Int",
      "author" : [ "P. Shenoy P" ],
      "venue" : "J. of Approximate Reasoning",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1994
    }, {
      "title" : "Information Content of an evidence",
      "author" : [ "Smets Ph" ],
      "venue" : "Int.  J. Man-Machine Stud",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1983
    }, {
      "title" : "Non Stan­ dard Logics for Automated Reasoning",
      "author" : [ "Smets Ph" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1988
    }, {
      "title" : "The Concept of Distinct Evidence",
      "author" : [ "Smets Ph" ],
      "venue" : "in Proc. of the 4th Int. Conf. of Information Processing and Management of Uncertainty in Knowledge-Based Systems",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1992
    }, {
      "title" : "Belief Functions: the Disjunctive Rule of Combination and the Generalized Bayesian Theorem",
      "author" : [ "Smets Ph" ],
      "venue" : "Int.  J. of Approximate Reasoning",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1993
    }, {
      "title" : "The transferable belief model, Artificial Intelligence",
      "author" : [ "Smets Ph", "Kennes R" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1994
    }, {
      "title" : "The Representation of Quantified Be­ lief by the Transferable Belief Model, Technical Report, TR/IRIDIA/94-19.1, IRIDIA",
      "author" : [ "Smets Ph" ],
      "venue" : "Universite libre de Bruxelles, Belgium,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1994
    }, {
      "title" : "Statisti­ cal Knowledge-based approaches to clinical deci­ sion Support Systems, with an application in gas­ troenterology (with discussion)",
      "author" : [ "J. Spiegelhalter D", "P. Knill-J ones R" ],
      "venue" : "J. of the Royal Stratistical Society",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1984
    }, {
      "title" : "Explaining evidential analyses, Int",
      "author" : [ "T. Strat", "J. Lawrence" ],
      "venue" : "Approximate Reasoning",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1989
    }, {
      "title" : "Some Strategies for the ex­ planation in Evidential Reasoning, Technical Re­ port, TR/IRIDIA/94-29, IRIDIA",
      "author" : [ "Xu H", "Smets Ph" ],
      "venue" : "Universite li­ bre de Bruxelles, Belgium,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1994
    }, {
      "title" : "Computing Marginals for Arbitrary Sub­ sets from the Marginal Representation in Markov Trees, Artificial Intelligence",
      "author" : [ "H. Xu" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1995
    }, {
      "title" : "A mathematical theory of evidence (book review), AI Magazine",
      "author" : [ "L. Zadeh" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1984
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "Another term for measuring the impact of a piece of evidence is the amount of information provided by the evidence [15].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 6,
      "context" : "Within the context of be­ lief functions, Smets [ 8] has defined a measure of the information content provided by a piece of evidence to show its impact on a frame of discernment.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 1,
      "context" : "Dempster-Shafer theory [ 3, 9, 13] is regarded as a use­ ful tool for representing and manipulating uncertain knowledge.",
      "startOffset" : 23,
      "endOffset" : 34
    }, {
      "referenceID" : 7,
      "context" : "Dempster-Shafer theory [ 3, 9, 13] is regarded as a use­ ful tool for representing and manipulating uncertain knowledge.",
      "startOffset" : 23,
      "endOffset" : 34
    }, {
      "referenceID" : 10,
      "context" : "Dempster-Shafer theory [ 3, 9, 13] is regarded as a use­ ful tool for representing and manipulating uncertain knowledge.",
      "startOffset" : 23,
      "endOffset" : 34
    }, {
      "referenceID" : 4,
      "context" : "More details can be found in [ 6].",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 0,
      "context" : "[0, 1] and a commonality function q: 2° ___.",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 0,
      "context" : "[0, 1] as follows: for A � n,",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 4,
      "context" : "Valuation-based systems (VBS) is an abstract frame­ work proposed by Shenoy [6] for uncertainty repre­ sentation and reasoning.",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 16,
      "context" : "1The normalization factor has been criticized by Zadeh [19] with a counter-example which shown the danger of its blind application.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 7,
      "context" : "More discussion about the normalization problem can be found in [9].",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 3,
      "context" : "As it is not feasible to compute the global belief func­ tion when there are a large number of variables in the network, Shenoy and Shafer [5] has proposed a local computation technique to compute the marginals for variables without computing the global belief function explicitly.",
      "startOffset" : 139,
      "endOffset" : 142
    }, {
      "referenceID" : 2,
      "context" : "For the details of the technique, readers can refer to [4, 5].",
      "startOffset" : 55,
      "endOffset" : 61
    }, {
      "referenceID" : 3,
      "context" : "For the details of the technique, readers can refer to [4, 5].",
      "startOffset" : 55,
      "endOffset" : 61
    }, {
      "referenceID" : 0,
      "context" : "2The example is abstracted from [1] with minor changes on some prior beliefs.",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 14,
      "context" : "The following theo­ rem [17] shows that if we do not consider the normal­ ization factor, bd;(x) and Pt;(x) are constants, and thus can be computed precisely.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 6,
      "context" : "In the theory of belief functions, Smets [8] gave the following definition:",
      "startOffset" : 41,
      "endOffset" : 44
    }, {
      "referenceID" : 6,
      "context" : "Otherwise I(bel) is infinite, for which case Smets gave a discussion in [8].",
      "startOffset" : 72,
      "endOffset" : 75
    }, {
      "referenceID" : 8,
      "context" : "3Smets [10] has given a definition for the concept of distinct evidence",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 5,
      "context" : "F irst, let's look at the concept of conditional independence in VBS, which is given in [7].",
      "startOffset" : 88,
      "endOffset" : 91
    }, {
      "referenceID" : 11,
      "context" : "Smets [14] defined the operator e as the inverse of the operator tB in the sense that:",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 5,
      "context" : "In VBS, Shenoy [7] gave the definition of removal e for belief functions as follows: Considering two valuations represented by the commonality functions qA and qn on the subsets A and B.",
      "startOffset" : 15,
      "endOffset" : 18
    }, {
      "referenceID" : 15,
      "context" : "(bel 8 beloxJ!X = (bel!(XUX;) 8 beloxJ!X (5) That's to say, if we compute bel!(XuX;) by local com­ putation, then we can compute (bel 8 beloxJ!X di­ rectly, Xu [18] has proposed a method to compute the marginals for any subsets from the marginal represen­ tation, avoiding the unnecessary computation.",
      "startOffset" : 160,
      "endOffset" : 164
    }, {
      "referenceID" : 15,
      "context" : "This can be done in parallel according to [18];",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 9,
      "context" : "Belief on the product space R x M can be computed by using so-called ballooning extension proposed by Smets [12]:",
      "startOffset" : 108,
      "endOffset" : 112
    } ],
    "year" : 2011,
    "abstractText" : "In this paper, we present two methods to provide explanations for reasoning with be­ lief functions in the valuation-based systems. One approach, inspired by Strat's method, is based on sensitivity analysis, but its com­ putation is simpler thus easier to implement than Strat 's. The other one is to examine the impact of evidence on the conclusion based on the measure of the information content in the evidence. We show the property of ad­ ditivity for the pieces of evidence that are conditional independent within the context of the valuation-based systems. We will give an example to show how these approaches are applied in an evidential network.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}