{
  "name" : "1606.00401.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "How to advance general game playing artificial intelligence by player modelling",
    "authors" : [ "Benjamin Ultan Cowley" ],
    "emails" : [ "ben.cowley@helsinki.fi" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 6.\n00 40\n1v 3\n[ cs\n.H C\n] 2\n1 Ju\nCowley, B., & Charles, D. (2016). Behavlets: a Method for Practical Player Modelling using Psychology-Based Player Traits and Domain Specific Features. User Modeling and User-Adapted Interaction, 26(2), 257–306.\nI. INTRODUCTION\nAtari (当たり, あたり, or アタリ) nominalized form of ataru (当たる, あたる, or アタル) (verb), meaning:\n”to hit the target”\nWith great fanfare and much publicity, recent studies have claimed solutions to two important landmarks of game-playing artificial intelligence (AI) - competitive world-class Go [1] and (constrained) generalised game playing [2] 1. Each of these problems is an exemplar ’difficult problem’ in AI, and each solution uses variations on the ’deep neural network’ learning method. However despite this leap of progress, there remains the need to move beyond the constraints exploited by these deep learning methods.\nBeyond the recent advances in game playing AI lie two still more daunting challenges: to build AI that can react to\n1Although see [3] for criticism of the claimed originality.\nhuman players as individuals; and to play games of imperfect information and strategic scope [4]. I argue that both of these problems are related, and therefore share a common solution. The link, or intersection in problem space, is that games are essentially human-relevant artefacts. Encoding human-style playing strategies will enable not only better responses to human players, but better responses to problems of recreational interest to humans. Therefore both problems can be addressed with an improved understanding of human play, by building a generalised player model. A general player model should be thought of primarily as a system for expressing the supraspecific elements that apply to all players, especially cognition, emotion and personality. The specific implementation then depends on the game.\nAs well as advancing the state of art, [1], [2] demonstrate, directly and indirectly, that human-level performance (in specific problems) is different to human-level capability. The senior author of both papers (they each come from Google’s DeepMind lab) hinted at this [4]:\nI think for perfect information games, Go is the pinnacle... There are other games — no-limit poker is very difficult, multiplayer has its challenges because it’s an imperfect information game. And then there are obviously all sorts of video games that humans play way better than computers, like StarCraft... Strategy games require a high level of strategic capability in an imperfect information world — ”partially observed,” it’s called.\nThe specifics of the two systems nicely illustrate the problem. In both cases, their solution is largely a method to deal with very large possibility spaces, which were tackled by constraint of the search space and learning from large amounts of data, but in different ways.\n[1]’s ’alphaGo’ system represented the Go board with a 19 × 19 matrix, and used Monte Carlo tree search (MCTS) enhanced by deep convolutional neural networks, to reduce the search space and determine play strategy. The algorithm first used supervised learning from existing games; then performed unsupervised reinforcement learning (RL) by playing against\nitself. I term this the ’strategic approach’, learning by deeply examining playing strategies (in the MCTS rollouts). It does not generalise well because large quantities of human-played games need to be used in the supervised part of training.\n[2]’s ’Atari’ system presented a deep RL algorithm with a 84 × 84 × 4 map of pixels of the game screen from 49 Atari games. The algorithm then played a very large number of games to learn a policy. The performance was expressed proportional to a human expert, achieving >90% in 26 games. At the other end of the scale, authors state that ”temporally extended planning strategies still constitute a major challenge”. Indeed, examining the lowest scoring games (<10%) shows that they all share the features of an extensive game world, and the need to manage resources or tokens across this world. Thus the ’general approach’ does not handle strategy well. Especially in the two lowest scoring games, Montezuma’s Revenge and Private Eye, the relationship between current task and overall possibility space is quite non-linear, as players must track back and forth through the game world to search, transport and use tokens such as keys. Compared to this, the strategy the authors actually describe their algorithm as having found in Breakout, a totally deterministic and perfect information game, is trivial.\nThe poor performance (compared to a human) in this type of open problem is mirrored of the work of [5]. Given feedback, humans were shown to achieve close-to-optimal solutions on certain classes of computationally hard problems, e.g. Travelling Salesman, by heuristically exploiting structure in the ’typical instances’.\n[6] has also pointed out how the DeepMind Atari player exploits constraints in its problem domain:\nin the Atari game system, data is very cheap. You can play the game over and over again...get gigabytes of data very quickly, with no real cost.\nin the Atari system, ...you have [only] eighteen choices at any given moment.\nHe contrasts this with learning problems of unconstrained choices and sparse data, e.g., when trying to learn from a human or a real-world scenario. Computer games may never be as noisy and unconstrained as real-world scenarios, modern games with multiplayer interaction are frequently very complex. Although [2] used games for humans, they were nevertheless from an era of much greater technological constraint, such that their dimensional reduction to tractability was straightforward - modern games will not allow that.\nThus the field of computational intelligence in games faces a research question which I state as RQ1: how can general game playing AI cope with human-level games and human players?\nBoth [1], [2] imposed well-chosen constraints on the problem domain to enable their solutions. Constraints can be dimensionality reduction, and can also be simulation of the original system, according to some simplifying theory.\nAs stated above, I propose that a generalised player model gives a partial solution. There are two parts to the solution:\na) to capture information about player psychology (cognition, emotion and personality) and activity; b) to represent that information in the context of the game. Part a) constrains the model of player behaviour to well-understood theoretical constructs; part b) presents the model as input to a learning algorithm."
    }, {
      "heading" : "A. Behavlets",
      "text" : "A general model should provide insight into different facets of player behaviour, for example the cognitive information processing ’style’ of a player. It thus requires a foundation of parameters that describe the subjective experience of play. The foundation will draw on established modelling tools, including at least: i) psychology of behaviour; ii) general game design; and iii) actions in the context of a given game.\nI previously proposed the Behavlets method [7] to build facets i) to iii) above into composite features of game-play defined over entire action sequences. The aim is to create player-modelling features linked to valid psychological theory. The Behavlet process integrates descriptive models for temperament theory, game design patterns, and patterns of player actions. The core concept is to capture behaviours with certain known bias of personality; e.g. aggression, caution; and thus observe the players’ self-expression. Behavlets have been used to model players for, e.g. personality type classification [8] and move prediction [9]. Thus I use the Behavlets method to fulfil part a) above."
    }, {
      "heading" : "B. Formalism",
      "text" : "How best to represent Behavlets (or any other psychological model) ’in the game’, i.e. in a manner both machine- and human-comprehensible? In principle, this should be done by simulation. As stated in the inspirational work of [10], simulation ”models’ main purposes are to leave out certain aspect of complex systems to facilitate study of those systems.”\nNote that games can be neatly modelled as a mathematical system because they rely on rule-based interactions defined on a possibility space, and the mechanics of play are essentially functions over that space.\nRestricting the games under consideration to those with strictly bounded rules, observe that a state at time t is determined by the game state at time t−1. Thus the game can usually be represented by a finite-state Markov process 2. A state-based model is often used for game representation, and Markov methods are often used for computational intelligence in games.\nHowever, observe that play involves spaces and control systems; these can be either discrete, or approximately continuous with minimum lower bound, sometimes defined by the frame rate of e.g. 60fps or 16.67ms per frame.\nFor purpose of player modelling, the difference between approximate and truly continuous is not as important as the\n2With a non-rational learning human player at the core of gameplay (who may display high choice variance, i.e. infer different predicates based on the same observations), game processes are usually strictly non-Markovian; however they can still be given Markovian representations as a simplifying assumption.\nplayer’s understanding of the nature of the play space. To create a general player model we must capture the player’s understanding, and deal with ’approximately continuous’ data.\nIf the model must capture every frame of the game, it is hardly an efficient simulation. Far more parsimonious to use a modelling framework that can handle continuous entities.\nFor example, consider Go played with clocks. Players make a single discrete move while their clock elapses continuous time. The elapsed time value can be captured with a simple integer, but the elapsed psychological experience cannot.\nFortunately, the required tools are already in [11]’s category theory framework to model interactive control systems. The framework in [11] models both discrete and continuous control systems, in hybrid form and as abstraction simulations. I will draw on the definition of hybrid control systems (HCS), following [10] and building on [11].\n[10] is an excellent complement for the reader; it works lucidly through the foundational technical aspects of applying this formalism to games. It also concludes at about the point where I aim to depart: the composition of micro-games (e.g. Behavlets) to form complete games (e.g. player models). The approach is more applied than [10], but as in that paper I still aim to produce a simulation model with reduced complexity compared to the original game.\n[10] described the how of game specification using HCS methods, but he himself questioned why one would wish to do it. I am interested in providing this motivating vision."
    }, {
      "heading" : "C. Summary",
      "text" : "In this paper I aim to provide a notation to represent Behavlets as action sequences in a formally defined simulation of a game system, by extending [11]. The motivation is to generate a representation of possible player actions, and the archetypal behaviour traits that can shape those actions, such that the representation can be used as input for a learning system. Ultimately, the goal is to learn from real human behaviour.\nIn the rest of the paper, I first give a brief literature review in the next section. In section III I describe a formal model of a game system, before showing briefly in section V how it can be used to represent some Behavlets taken from [7]. Finally, in section VI, I suggest some future directions of work."
    }, {
      "heading" : "II. BACKGROUND",
      "text" : "A general player model has the difficult task to account for the variation between players, variability in their behaviour over time, and the reciprocal relationship of players to the game. For example, such a model should account not only for player learning, but also player emotions’ impact on play. There are many relevant fields of study in that problem, and I have previously reviewed literature contributing to generalised player modelling [12]. Here I briefly review literature on formal models.\nVarious descriptive models of game play have tried to include aspects of player psychology, such as emotions. For example, I proposed the User-System-Experience (USE) model\n[13], [14], to describe the intrinsic motivation of games in terms of the cognitive neuroscience of information processing and learning. However the specification of games themselves was lacking in detail. Järvinen [15, pp.99-247] built a player experience model on top of a game decomposition theory. The model has two concepts: game experiences are composed of sequences of emotions; and game elements embody conditions that elicit emotions. [16] define a formalisation of ‘synthetic’ emotions using Decision Theory, to be used for player modelling or for communication of AI agent states to the player. Methods which codify game mechanics allow a model to capture player-game interactions. [17] attempts this, using the object oriented programming paradigm to define game mechanics as ”methods invoked by agents”. [18] developed a formal modelling toolset to analyse player behaviour by action sequence mining. The method finds all action sequences and their frequency in a game log, representing common sequences as features, which are selected by ranking according to their mutual information with the class variable.\nFormal specification of the play space can support the integration of game and psychological models. [19] defined game theory, which gives useful tools to analyse player behaviour: assuming that players are rational agents with definable utilities for action. Such assumptions do not serve our purpose to learn from real human behaviour. More generally, formal methods such as category theory [20], enable specification and verification of the objects and actions of the play space, and thus support rigorous testing of system coherence. Category theory was applied to game specification in [10], which leveraged [11]’s system of notation for abstractions. In [10]’s abstract specification, a game ”consists of objects which change their state during the play, where the evolution of their state is governed by rules and influenced by the players or other objects”. [10] defined a game as a triple(S,M, F ), where S is a set of game states; M is a monoid describing the inputs to the system; and F is an action of the monoid on the set, i.e. the rules. [10] also showed how the operation of composition defined in [11] could be used to create novel games; this was a useful abstract discussion.\nThis approach is flexible, but the complexity of the domain poses a large problem for this method. [10] agrees: ”describing a game with this formalism seems to be a cumbersome task”. The task is cumbersome because the approach relies too much on one system; any such system will be either unwieldy or insufficiently descriptive. In a multi-step modelling approach, methods for action-tracking [18], design pattern analysis [21], and player psychology profiling [7] can first describe the game; i.e. part a) above. These descriptions can then be associated with a coding formalism for rigour, i.e. part b) above."
    }, {
      "heading" : "III. FORMAL MODEL",
      "text" : "Here, I extend the full HCS defined by [11]. A game is modelled as a HCS; some rectifying operations are also defined, to force the HCS to behave as games do."
    }, {
      "heading" : "A. Model Foundation",
      "text" : "Definition: A game G = (X ,M,Φ), consisting of:\n• the state space X = {Xq}q∈Q • a monoid M = ∐ n∈N(U ∗ ∪ Σ∗)n • a partial action Φ of M on X , such that there exist invariants Inv(q) ⊆ Xq\nNote: Here, X is a set of smooth manifolds parametrised by discrete states q ∈ Q; this allows modelling of any simulated spaces with entities, such as a game’s 3D environment with typical player-controlled unit(s) and opponent(s).\nNote: Monoid M is defined as the product union of the sets U∗, the set of smooth manifold inputs, and Σ∗, the set of discrete inputs 3; which allows modelling of combined analogue and digital inputs, such as a joystick and buttons. Individual inputs are denoted by m, a map in N+0 , defined as a composition of finite ut1...i with finite σ1...j . In this system, ut ′\nindexes time, with ’embedded’ discrete inputs from Σ∗, if modelling game time is required.\nNote: The partial action Φ implies a ruleset that can be defined over a subset of the state space; this allows modelling of rules such as power-ups, which alter some core function in a restricted area of state-space, i.e. after a power-up item has been consumed, and perhaps within limited time/space.\nThis general-form model may be revised to obtain the core framework for specific games. For example perfectinformation purely-discrete games, such as chess and Go, can be obtained when Xq is a singleton and U = ∅.\nExample: Let us model the game of Noughts & Crosses (TicTacToe in American) as a demonstration.\n• Xxo = (posψ){ψ∈1...9}, the set of 3× 3 board positions, uniquely ordered by the magic square n = 3 4. • Mxo = σx∈ψ ∪ σo∈ψ, the act of placing an x or an o. • Φxo = φ : {1, 2, 3}, a map to three ’rules’,\n1) σx × σo −→ 4Pψ, paired player turns involve sampling without replacement from the magic square n = 3, up to four times, 2) x ∩ o = ∅, choices are disjoint, 3) win ⇐⇒ ∑ Σ∗ = 15, winning condition such\nthat player wins if and only if 3 choices sum to 15.\nAlthough Noughts & Crosses is a trivial child’s game, it is a simple matter to adapt this specification to model Gomoku, which is also an m,n, k-game. From there, it is straightforward to model Go, at least for (X ,M). To define Φ for the core Go rules, which we will not state here for the sake of brevity, would require significant effort but tractable complexity because the rules are all simply derived from the board and input definitions X ,M.\n3Although continuous systems are constrained to have finite duration of input times, they may have infinite number of inputs defined as vector field maps from an input manifold. This permits a model consistent with the player’s point of view, which is an important part of creating psychologically relevant models.\n4This is a rare occasion when a magic square becomes a magic circle (in the sense of Huizinga, not Yang Hui)!\nIn order to more flexibly create games, it helps to exploit modularity; for this we can use the operation composition of monoids. Composition implies that, given two monoids M1 and M2, we can form the composition M′ = M1 ⊗ M2, which is also a monoid. M′ has all possible evolutions of the composed monoids and no interaction between their parts.\nFor such a model (X ,M,Φ)as described, a common shorthand notation is ΦX , denoting ΦX : X ×Mx → X . With this notation, and composition, we can thus describe a basic game, Φ0, and compatible game-parts ΦXa and ΦX b, and obtain a complete game by composition, ΦX b×ΦXa×ΦX0 → ΦXab. The goal is that such game-parts are used to represent Behavlets, as described below, section IV.\nHowever as [10] pointed out, with such a framework it is not yet possible to build any reasonably interesting game, in the sense of a system which produces meaningful decisions and outcomes [22]. This is because the composition operator does not impose any interaction on the composed parts, leaving the resultant system causally heterogeneous and un-gamelike. Composition should additionally impose constraints on the composed monoids, such that the inputs of each are influenced by the other. Additionally, tracking activity patterns allows us to see more clearly how the defined influences work in practice. Therefore, two more concepts will complete our core toolset: composition with restriction, and orbits.\nDefinition: Composition with restriction, denoted ⊗, from [11], imposes a restriction of ΦX to a subset of X ⊗M′x, such that the composed monoids are forced to synchronise by the restriction.\nDefinition: An orbit is a set Ox containing all points visited on an evolution starting at x and controlled by some input m ∈ M. Formally, Ox = {x′ ∈ X : x′ = ΦX (x,m′) for some prefix m′ of m}. [20] defines an orbit as the behaviour of an imperative program f , i.e. the effect of a series of inputs a on an initial state x, such that fai(xi−1) = xi.\nFor our purposes, an orbit of monoid ΦX will represent instances whenever the game-play activity pattern defined by ΦX is played. For example, in Noughts & Crosses there are well-known tactics, which when played according to the correct selection criteria will generate a perfect game. These include Play Center, Block, Fork and others defined in [23]. They can be modelled with a triplet defining: the player’s move, the state of the board, plus a test to determine the type of tactic played.\nIn the game of Go there are also various well-known patterns of play, such as atari, gote vs. sente, joseki, ko fighting. These concepts may be captured by orbits, at least where the analysis of the pattern characteristics is algorithmic and tractable (in Go, an element of expert judgement is often involved in assessing such patterns).\nTo make a well-formed map from games to models, an orbit for modelling behaviour is under two constraints. It cannot be a cycle, as cycles are not game-like: consider the ko rule in Go. It cannot consist only of a stable state, as this cannot evolve (by definition [20]), and is therefore uninteresting from a player modelling point of view."
    }, {
      "heading" : "B. Complete Model",
      "text" : "Based on this framework I propose a modelling scheme for game behaviour, which is descriptive rather than generative; i.e. the aim is to simulate the game components that relate to player actions, rather than deriving a simulation of game play from a model of the engine mechanics.\nDefinition: A game G′ is a composition of HCSs ΦX i, 1 < i ≤ k, where each ΦX i is used to model a distinct game play pattern, and the composition (by the properties of composition of monoids) is also a HCS.\nThe ’base’ monoid ΦX0 represents the core game framework, with no orbit restrictions. A single game play pattern is represented by a monoid, ΦX i : (Xi,Mi,Φi), instantiated by an orbit OX i, with a starting condition (q, x0)i, an initial condition from Xqi which corresponds to the opening state of the game pattern. Such monoids are constrained from having initial or terminal objects (as defined by [20]), because they would then be allowed to define only a single function, violating the principle that games should be uncertain.\nModelling of the complete game is achieved by composition with restriction, where three restriction operators are defined.\n1) Xqi ⊆ Xqi−1, i.e. state space is reduced every time by composition. This models the progression of games, i.e. the fact that a game can generally be modelled as a tree traversal, such that every move will reduce the remaining possible moves. 2) mi⊗mi−1 iff mi−1 is a prefix of mi, such that e.g. in a time-indexed system mt1 ≥ m− 1t1 , i.e. the start time of the orbit for the next monoid to be composed must be greater than or equal to the prior monoid, such that game progression is modelled. 3) Oxi 6= Oxi−1 where (q, x0)i ∩ (q, x0)i−1 6= ∅ without any other restriction on x ∈ OX i. I.e. monoids composed such that their orbits have overlapping time sequences, shall not be isomorphic.\nThus, based on this approach, a game G′ is a basis monoid ΦX0 : (X0,M0,Φ0), which provides the complete state space and time registration, without inputs. The basis monoid is composed with 1..k − 1 additional game pattern monoids, to describe those activities in the game that reduce the possibility space until game end. Each pattern monoid Φi is restricted to join the base monoid in a time-ordered fashion, without overlap of isomorphs, and without expanding the game tree with nodes excluded by previously composed monoids Φ1..i−1."
    }, {
      "heading" : "IV. BEHAVLETS-BASED FORMAL MODEL",
      "text" : "As mentioned, the intention is to formalise the Behavlets’ method of player modelling. As indicated in the formal model definition, this can be done by using orbits to represent the play patterns which arise in the game. Here I elaborate this idea.\nA Behavlet is essentially a game play pattern associated with a temperament trait. Thus, a well-chosen monoid representation of a pattern, ΦX i, can also represent a Behavlet, and thereby be associated with a temperament trait. To select the\nright monoid for the Behavlet is quite straightforward. The instantiation orbit OX i is equivalent to the Behavlet logic, defined in [7]. Further, the orbit starting condition (q, x0)i is equivalent to the Behavlet concept of a constraint harness, defined in [7].\nAn example will illustrate the approach, for which I will take already peer-reviewed [7] and empirically tested [9] Behavlets, derived for the game Pac-Man (Namco, 1980). The formal framework for the Behavlets model of a given game Γ is obtained and used with the following five step process:\n1) define basis monoid for Γ 2) define compositional Γ play pattern monoids, each with\nassociated temperament trait 3) define model instance as label for play personality in Γ 4) model reduction by the operation of simulation, giving\nrepresentations of behaviour patterns in Γ-like games which can be compared 5) obtain generalised player model by iterating this process\nI will apply this process to the Pac-Man Behavlets using the Pac-Man specification from my previous work (see e.g. appendix D to [8]). This specification was totally state-based, abstracting the smooth movement aspect of original Pac-Man. Thus, as with chess or Go, this Pac-Man does not need U∗, and X is singleton. For brevity, I will make a number of further simplifications which do not relate to the example Behavlet. I model only a single level, to avoid extra complications surrounding tests that would be needed to model end-of-level or loss of lives (for a description of test function construction, see e.g. [20, pp.46]). I do not provide extra state variables to model the bonus Fruit item, a cherry; or record the points scored, or Pac-Man’s lives (these values are referenced but left undefined). I also refrain from modelling any driver of Ghost behaviour, which in the prior specification is simply a probabilistic map to adjacent positions, weighted toward PacMan in normal play and away from Pac-Man when a power pill is in effect. All these features can be trivially added to the model.\nFirst, the basis monoid for a Pac-Man game P . Definition: ΦP = (XP0,MP0,ΦP0),\n• XP0 = {mat, xyp}, where mat = (hposx) ∪ (vposy), {x, y ∈ N, 1 . . . 20} the Pac-Man ’map’ matrix with values drawn from {∅, wall, pill, powerpill}; and xyp is a set of current position values for Pac-Man and the Ghosts {xyp | p ∈ PM,G1..4}, • MP0 = m : {←, ↑, ↓,→}×XxyPM d=1 −−→ X , a map from\nthe four directions of movement to the matrix position adjacent to Pac-Man’s current position,\n• ΦP0 = φ : {1, 2, 3}, a map to three ’rules’,\n1) m × pill −→ {+5points,XxyPM = ∅}, Pac-Man passes through a matrix position with a pill: increase points by +5, position becomes empty, 2) m × powerpill −→ {+10points,XxyPM = ∅, φ = φ′ : {1, 2, 3′}, t : (1..n)}, similar effects as pill; also transition to the map φ′, where vulnerability of\nPac-Man to the Ghosts is inverted for a limited time n, 3) m×xyG1..4 −→ −1life, Pac-Man and a Ghost enter the same matrix position: Pac-Man loses a life, 3′ m×xyG1..4 −→ {+50points×i, i ∈ (1..4), xyGi = xy0Gi}, Pac-Man and a Ghost enter the same matrix position: +50 points (multiplied by consecutive Ghost order), Ghost returns to starting position\nSecond, the Behavlets themselves are modelled. To illustrate, I select a Behavlet listed in [7, pp.293], A1 Hunt Close To Ghost House. Behavlet A1 (for short) tracks how often a player follows the Ghosts right up to their house while attacking them in powerpill mode.\nDefinition: ΦA1 = (x′,m′, OPA1),\n• x′ = ∀1..4,dist(xyGi , xy0Gi) ≤ 3, the manhattan distance of each Ghost to its own starting position is three or less, • m′ ⊆ MP0∀t(1..n), the orbit elapses for all inputs until the end of the powerpill timer, • OPA1 = {x′ ∈ XP0 : x′ = ΦP0(x,m′), an orbit defined on the Pac-Man basis monoid\nThird, the composited game is produced, P = ΦA1 ⊗ ΦP = ΦPA1. Game instances where this Behavlet monoid appears can be labelled as examples of cautious play, with a quantification scheme as described above.\nFourth, model reduction by simulation creates a simpler representation without reference to the specifics of the game. Thus we do not need to define, for example, the dimensions of game space states Xq , only to define the type of spaces as they appear to the player. In this way, we can make an equivalence between models for Pac-Man, Go, even Noughts & Crosses if we wish. Given the game produced by composition with restrictions ΦPA1, we define two simulations of the composed parts, βA1 and βP . The map ϕ which defines each β is an abstraction of the part of the model which is not relevant to comparison with another simulated game. βs are composed by restriction to produce a more general version of the model, βPA1.\nβA1 ⊗ βP βPA1\nΦA1 ⊗ ΦP ΦPA1\nϕ ϕ (1)\nThe complete approach to simulation is detailed in [11], and is also discussed in [10]. Here it is enough to note that, given proven models of games such as those described above, the reduction can be pursued and the simulations are then ’safe’ to study without reference to the messy details.\nFifth and finally, obtaining the generalised player model from the given framework is perhaps possible for a class of\ngames between which simulation is well-defined. Proving this is clearly a matter for future work."
    }, {
      "heading" : "V. DISCUSSION",
      "text" : "The approach I described for a generalised player model draws on the Behavlet method to create psychologically-based features of game play, and redefines them as parts of a category theoretic formal model. The value of this approach is that, under a formal framework, Behavlet models of particular games can be further generalised by the operation of simulation."
    }, {
      "heading" : "A. Potential applications",
      "text" : "The primary use case for the described method is to capture player variation. Consider that, if we model Behavlets as game parts ΦX , then by the Behavlets method [7], each ΦX i will have an associated behaviour trait. Thus, a game instance with a specific Φ composition will reflect the ’character’ of a particular player’s play style. Potentially, characteristics of human play can be learned through enough such instances.\nAlso consider that the method allow abstraction and specificity: we can build a canonical game model and also simulate game instances quite easily from the same definitions. This allows exploration of the space of possible games.\nThis might be termed personality profiling, but skill and strategy are also a relevant considerations. Based on the work of [5] where humans achieved near-optimal solutions on hard problems, we can expect to find many problems where human skills can provide the seed for improved computational solutions. For example, [24] used a gamification to learn from humans solutions, creating heuristic optimisation methods for quantum computing problems which outperform traditional multi-parameter numerical methods. The problem remains to characterise player activity in a manner which is flexible to the level and type of detail required, a problem to which I suggest that simulation is well suited. Thus, given a composite model of Behavlet-based game parts, defining play-sequences such as the Noughts & Crosses or Go tactics described, the actually-played components can denote the level of insight of the player into the game problem.\nA further consequence of this flexibility is the capacity to model multiple flavours of game rules. As defined by [22], a game contains three different types of rule, Constituative (written before play), Operative (emergent during play) and Implicit (unspoken ’house’ rules between players). Go is an example where all these rule types have been studied, standardised, and written about in great detail, and thus were available to the developers of alphaGo. For less well-studied games, the method I present can characterise them with some flexibility without loss of rigour.\nB. Issues and considerations\nThis is a work at the concept stage, and like any concept there are many details lacking. The state of the method presented is probably sub-optimal, and this may frustrate the more engineering-minded reader; but the aim is initiate a\nconversation. It is to be hoped that the concept will provide fertile soil to grow more detailed methods.\nDespite the seeming complexity, what is required to build such models is quite complementary to the development process - defining the entities and operations of game-play.\nWhen building such models, the user must take note of whether the restrictions and constraints ever contradict his game: this can help highlight flaws in either the game or the model, and facilitate the work of quality assurance."
    }, {
      "heading" : "VI. CONCLUSION",
      "text" : "I argue that in order to advance general game playing AI, it is necessary to include the player perspective, because games are ultimately human artefacts and therefore contain cases which benefit from a human-style problem solving approach. The argument implies creating a generalised player model. I have set out a method to do so, based on integrating my previously published Behavlets work [7] with a formal model of game play. The result is a vision for a general player model, rather than a complete and final work, which I hope will serve as inspiration."
    } ],
    "references" : [ {
      "title" : "Mastering the game of Go with deep neural networks and tree search",
      "author" : [ "D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre", "G. van den Driessche", "J. Schrittwieser", "I. Antonoglou", "V. Panneershelvam", "M. Lanctot", "S. Dieleman", "D. Grewe", "J. Nham", "N. Kalchbrenner", "I. Sutskever", "T. Lillicrap", "M. Leach", "K. Kavukcuoglu", "T. Graepel", "D. Hassabis" ],
      "venue" : "Nature, vol. 529, no. 7587, pp. 484–489, jan 2016.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Human-level control through deep reinforcement learning",
      "author" : [ "V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski", "S. Petersen", "C. Beattie", "A. Sadik", "I. Antonoglou", "H. King", "D. Kumaran", "D. Wierstra", "S. Legg", "D. Hassabis" ],
      "venue" : "Nature, vol. 518, no. 7540, pp. 529–533, feb 2015.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "DeepMind’s Nature Paper and Earlier Related Work",
      "author" : [ "J. Schmidhuber" ],
      "venue" : "2015. [Online]. Available: http://people.idsia.ch/{∼}juergen/naturedeepmind.html",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "DeepMind founder Demis Hassabis on how AI will shape the future",
      "author" : [ "D. Hassabis" ],
      "venue" : "2016. [Online]. Available: http://www.theverge.com/2016/3/10/11192774/demis-hassabis-interview-alphago-google-deepmind-ai",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "People efficiently explore the solution space of the computationally intractable traveling salesman problem to find near-optimal tours",
      "author" : [ "D.E. Acuña", "V. Parada" ],
      "venue" : "PloS one, vol. 5, no. 7, 2010.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Is Big Data Taking Us Closer to the Deeper Questions in Artificial Intelligence? — Edge.org",
      "author" : [ "G. Marcus" ],
      "venue" : "2016. [Online]. Available: https://www.edge.org/conversation/gary{ }marcus-big-data-ai",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Behavlets: a Method for Practical Player Modelling using Psychology-Based Player Traits and Domain Specific Features",
      "author" : [ "B. Cowley", "D. Charles" ],
      "venue" : "User Modeling and User-Adapted Interaction, vol. 26, no. 2, pp. 257–306, Feb 2016.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Real-time rule-based classification of player types in computer games",
      "author" : [ "B. Cowley", "D. Charles", "M. Black", "R. Hickey" ],
      "venue" : "User Modeling and User-Adapted Interaction, vol. 23, no. 5, pp. 489–526, Aug 2013.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Utility of a Behavlets approach to a Decision theoretic predictive player model",
      "author" : [ "B.U. Cowley", "D. Charles" ],
      "venue" : "arXiv, vol. 1603.08973, mar 2016.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Formal Models and Game Design",
      "author" : [ "S. Grünvogel" ],
      "venue" : "Games Studies, vol. 5, no. 1, p. Online, 2005.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Compositional Abstractions of Hybrid Control Systems",
      "author" : [ "P. Tabuada", "G.J. Pappas", "P. Lima" ],
      "venue" : "Discrete Event Dynamic Systems, vol. 14, no. 2, pp. 203–238, apr 2004.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Short Literature Review for a General Player Model Based on Behavlets",
      "author" : [ "B.U. Cowley", "D. Charles" ],
      "venue" : "arXiv, vol. 1603.06996, p. 7, mar 2016.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "User-System- Experience Model for User Centered Design in Computer Games",
      "author" : [ "B. Cowley", "D. Charles", "M. Black", "R. Hickey" ],
      "venue" : "Adaptive Hypermedia and Adaptive Web-Based Systems, vol. 4018. Dublin: LNCS, 2006, pp. 419–424.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Toward an understanding of flow in video games",
      "author" : [ "——" ],
      "venue" : "Comput. Entertain., vol. 6, no. 2, pp. 1–27, 2008.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Games Without Frontiers: Methods for Game Studies and Design",
      "author" : [ "A. Järvinen" ],
      "venue" : "Copenhagen: VDM Verlag,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2009
    }, {
      "title" : "Modeling users’ emotions during interactive entertainment sessions",
      "author" : [ "P.J. Gmytrasiewicz", "C.L. Lisetti" ],
      "venue" : "Stanford, CA, USA, pp. 30–35, 2000.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Defining Game Mechanics",
      "author" : [ "M. Sicart" ],
      "venue" : "Games Studies, vol. 8, no. 2, p. Online, 2008.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Action Sequence Mining",
      "author" : [ "S. Breining", "H.-P. Kriegel", "M. Schubert", "A. Zufle" ],
      "venue" : "Second International Workshop on Machine Learning and Data Mining in Games, at European Conference on Machine Learning, T. Croonenborghs, K. Driessens, and O. Missura, Eds., Athens, Greece, 2011.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Theory of games and economic behavior",
      "author" : [ "J. Von Neuman", "O. Morgenstern" ],
      "venue" : "New York: J. Wiley,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1944
    }, {
      "title" : "Categories and computer science",
      "author" : [ "R. Walters" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1991
    }, {
      "title" : "Patterns in game design",
      "author" : [ "S. Björk", "J. Holopainen" ],
      "venue" : "Hingham, Massachusetts: Charles River Media,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2005
    }, {
      "title" : "Flexible strategy use in young children’s tic-tac-toe",
      "author" : [ "K. Crowley" ],
      "venue" : "Cognitive Science, vol. 17, no. 4, pp. 531–561, dec 1993.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Exploring the quantum speed limit with computer games",
      "author" : [ "J.J.W.H. Sørensen", "M.K. Pedersen", "M. Munch", "P. Haikka", "J.H. Jensen", "T. Planke", "M.G. Andreasen", "M. Gajdacz", "K. Mølmer", "A. Lieberoth", "J.F. Sherson" ],
      "venue" : "Nature, vol. 532, no. 7598, pp. 210–213, Apr 2016.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "With great fanfare and much publicity, recent studies have claimed solutions to two important landmarks of game-playing artificial intelligence (AI) - competitive world-class Go [1] and (constrained) generalised game playing [2] 1.",
      "startOffset" : 178,
      "endOffset" : 181
    }, {
      "referenceID" : 1,
      "context" : "With great fanfare and much publicity, recent studies have claimed solutions to two important landmarks of game-playing artificial intelligence (AI) - competitive world-class Go [1] and (constrained) generalised game playing [2] 1.",
      "startOffset" : 225,
      "endOffset" : 228
    }, {
      "referenceID" : 2,
      "context" : "1Although see [3] for criticism of the claimed originality.",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 3,
      "context" : "human players as individuals; and to play games of imperfect information and strategic scope [4].",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 0,
      "context" : "As well as advancing the state of art, [1], [2] demonstrate, directly and indirectly, that human-level performance (in specific problems) is different to human-level capability.",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 1,
      "context" : "As well as advancing the state of art, [1], [2] demonstrate, directly and indirectly, that human-level performance (in specific problems) is different to human-level capability.",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 3,
      "context" : "The senior author of both papers (they each come from Google’s DeepMind lab) hinted at this [4]:",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 0,
      "context" : "[1]’s ’alphaGo’ system represented the Go board with a 19 × 19 matrix, and used Monte Carlo tree search (MCTS) enhanced by deep convolutional neural networks, to reduce the search space and determine play strategy.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "[2]’s ’Atari’ system presented a deep RL algorithm with a 84 × 84 × 4 map of pixels of the game screen from 49 Atari games.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "The poor performance (compared to a human) in this type of open problem is mirrored of the work of [5].",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 5,
      "context" : "[6] has also pointed out how the DeepMind Atari player exploits constraints in its problem domain:",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "Although [2] used games for humans, they were nevertheless from an era of much greater technological constraint, such that their dimensional reduction to tractability was straightforward - modern games will not allow that.",
      "startOffset" : 9,
      "endOffset" : 12
    }, {
      "referenceID" : 0,
      "context" : "Both [1], [2] imposed well-chosen constraints on the problem domain to enable their solutions.",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 1,
      "context" : "Both [1], [2] imposed well-chosen constraints on the problem domain to enable their solutions.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 6,
      "context" : "I previously proposed the Behavlets method [7] to build facets i) to iii) above into composite features of game-play defined over entire action sequences.",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 7,
      "context" : "personality type classification [8] and move prediction [9].",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 8,
      "context" : "personality type classification [8] and move prediction [9].",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 9,
      "context" : "As stated in the inspirational work of [10], simulation ”models’ main purposes are to leave out certain aspect of complex systems to facilitate study of those systems.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 10,
      "context" : "Fortunately, the required tools are already in [11]’s category theory framework to model interactive control systems.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 10,
      "context" : "The framework in [11] models both discrete and continuous control systems, in hybrid form and as abstraction simulations.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 9,
      "context" : "I will draw on the definition of hybrid control systems (HCS), following [10] and building on [11].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 10,
      "context" : "I will draw on the definition of hybrid control systems (HCS), following [10] and building on [11].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 9,
      "context" : "[10] is an excellent complement for the reader; it works lucidly through the foundational technical aspects of applying this formalism to games.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 9,
      "context" : "The approach is more applied than [10], but as in that paper I still aim to produce a simulation model with reduced complexity compared to the original game.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 9,
      "context" : "[10] described the how of game specification using HCS methods, but he himself questioned why one would wish to do it.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "In this paper I aim to provide a notation to represent Behavlets as action sequences in a formally defined simulation of a game system, by extending [11].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 6,
      "context" : "In section III I describe a formal model of a game system, before showing briefly in section V how it can be used to represent some Behavlets taken from [7].",
      "startOffset" : 153,
      "endOffset" : 156
    }, {
      "referenceID" : 11,
      "context" : "There are many relevant fields of study in that problem, and I have previously reviewed literature contributing to generalised player modelling [12].",
      "startOffset" : 144,
      "endOffset" : 148
    }, {
      "referenceID" : 12,
      "context" : "For example, I proposed the User-System-Experience (USE) model [13], [14], to describe the intrinsic motivation of games in terms of the cognitive neuroscience of information processing and learning.",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 13,
      "context" : "For example, I proposed the User-System-Experience (USE) model [13], [14], to describe the intrinsic motivation of games in terms of the cognitive neuroscience of information processing and learning.",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 15,
      "context" : "[16] define a formalisation of ‘synthetic’ emotions using Decision Theory, to be used for player modelling or for communication of AI agent states to the player.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[17] attempts this, using the object oriented programming paradigm to define game mechanics as ”methods invoked by agents”.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "[18] developed a formal modelling toolset to analyse player behaviour by action sequence mining.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "[19] defined game theory, which gives useful tools to analyse player behaviour: assuming that players are rational agents with definable utilities for action.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "More generally, formal methods such as category theory [20], enable specification and verification of the objects and actions of the play space, and thus support rigorous testing of system coherence.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 9,
      "context" : "Category theory was applied to game specification in [10], which leveraged [11]’s system of notation for abstractions.",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 10,
      "context" : "Category theory was applied to game specification in [10], which leveraged [11]’s system of notation for abstractions.",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 9,
      "context" : "In [10]’s abstract specification, a game ”consists of objects which change their state during the play, where the evolution of their state is governed by rules and influenced by the players or other objects”.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 9,
      "context" : "[10] defined a game as a triple(S,M, F ), where S is a set of game states; M is a monoid describing the inputs to the system; and F is an action of the monoid on the set, i.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 9,
      "context" : "[10] also showed how the operation of composition defined in [11] could be used to create novel games; this was a useful abstract discussion.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[10] also showed how the operation of composition defined in [11] could be used to create novel games; this was a useful abstract discussion.",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 9,
      "context" : "[10] agrees: ”describing a game with this formalism seems to be a cumbersome task”.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "In a multi-step modelling approach, methods for action-tracking [18], design pattern analysis [21], and player psychology profiling [7] can first describe the game; i.",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 20,
      "context" : "In a multi-step modelling approach, methods for action-tracking [18], design pattern analysis [21], and player psychology profiling [7] can first describe the game; i.",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 6,
      "context" : "In a multi-step modelling approach, methods for action-tracking [18], design pattern analysis [21], and player psychology profiling [7] can first describe the game; i.",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 10,
      "context" : "Here, I extend the full HCS defined by [11].",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 9,
      "context" : "However as [10] pointed out, with such a framework it is not yet possible to build any reasonably interesting game, in the sense of a system which produces meaningful decisions and outcomes [22].",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 10,
      "context" : "Definition: Composition with restriction, denoted ⊗, from [11], imposes a restriction of ΦX to a subset of X ⊗Mx, such that the composed monoids are forced to synchronise by the restriction.",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 19,
      "context" : "[20] defines an orbit as the behaviour of an imperative program f , i.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "These include Play Center, Block, Fork and others defined in [23].",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 19,
      "context" : "It cannot consist only of a stable state, as this cannot evolve (by definition [20]), and is therefore uninteresting from a player modelling point of view.",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 19,
      "context" : "Such monoids are constrained from having initial or terminal objects (as defined by [20]), because they would then be allowed to define only a single function, violating the principle that games should be uncertain.",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 6,
      "context" : "The instantiation orbit OX i is equivalent to the Behavlet logic, defined in [7].",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 6,
      "context" : "Further, the orbit starting condition (q, x0)i is equivalent to the Behavlet concept of a constraint harness, defined in [7].",
      "startOffset" : 121,
      "endOffset" : 124
    }, {
      "referenceID" : 6,
      "context" : "An example will illustrate the approach, for which I will take already peer-reviewed [7] and empirically tested [9] Behavlets, derived for the game Pac-Man (Namco, 1980).",
      "startOffset" : 85,
      "endOffset" : 88
    }, {
      "referenceID" : 8,
      "context" : "An example will illustrate the approach, for which I will take already peer-reviewed [7] and empirically tested [9] Behavlets, derived for the game Pac-Man (Namco, 1980).",
      "startOffset" : 112,
      "endOffset" : 115
    }, {
      "referenceID" : 7,
      "context" : "appendix D to [8]).",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 10,
      "context" : "The complete approach to simulation is detailed in [11], and is also discussed in [10].",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 9,
      "context" : "The complete approach to simulation is detailed in [11], and is also discussed in [10].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 6,
      "context" : "Consider that, if we model Behavlets as game parts ΦX , then by the Behavlets method [7], each ΦX i will have an associated behaviour trait.",
      "startOffset" : 85,
      "endOffset" : 88
    }, {
      "referenceID" : 4,
      "context" : "Based on the work of [5] where humans achieved near-optimal solutions on hard problems, we can expect to find many problems where human skills can provide the seed for improved computational solutions.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 22,
      "context" : "For example, [24] used a gamification to learn from humans solutions, creating heuristic optimisation methods for quantum computing problems which outperform traditional multi-parameter numerical methods.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 6,
      "context" : "I have set out a method to do so, based on integrating my previously published Behavlets work [7] with a formal model of game play.",
      "startOffset" : 94,
      "endOffset" : 97
    } ],
    "year" : 2016,
    "abstractText" : "General game playing artificial intelligence has recently seen important advances due to the various techniques known as ’deep learning’. However the advances conceal equally important limitations in their reliance on: massive data sets; fortuitously constructed problems; and absence of any humanlevel complexity, including other human opponents. On the other hand, deep learning systems which do beat human champions, such as in Go, do not generalise well. The power of deep learning simultaneously exposes its weakness. Given that deep learning is mostly clever reconfigurations of well-established methods, moving beyond the state of art calls for forwardthinking visionary solutions, not just more of the same. I present the argument that general game playing artificial intelligence will require a generalised player model. This is because games are inherently human artefacts which therefore, as a class of problems, contain cases which require a human-style problem solving approach. I relate this argument to the performance of state of art general game playing agents. I then describe a concept for a formal category theoretic basis to a generalised player model. This formal model approach integrates my existing ’Behavlets’ method for psychologically-derived player modelling: Cowley, B., & Charles, D. (2016). Behavlets: a Method for Practical Player Modelling using Psychology-Based Player Traits and Domain Specific Features. User Modeling and User-Adapted Interaction, 26(2), 257–306.",
    "creator" : "LaTeX with hyperref package"
  }
}