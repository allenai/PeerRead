{
  "name" : "1412.7022.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Pablo Sprechmann", "Joan Bruna", "Yann Lecun" ],
    "emails" : [ "pablo@cims.nyu.edu", "bruna@cims.nyu.edu", "yann@cims.nyu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n41 2.\n70 22\nv3 [\ncs .S\nD ]\n2 8\nA pr\n2 01\n5 Accepted as a workshop contribution at ICLR 2015"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); Hänsler & Schmidt (2008)). Successful algorithms rely on models that capture signal regularity while preserving discrimination between different speakers. The decomposition of time-frequency representations, such as the power or magnitude spectrogram in terms of elementary atoms of a dictionary, has become a popularcitet tool in audio processing. Non-negative matrix factorization (NMF) (Lee & Seung (1999)), have been widely adopted in various audio processing tasks, including in particular source separation, see Smaragdis et al. (2014) for a recent review. There are many works that follow this line in speech separation (Schmidt & Olsson (2006); Shashanka et al. (2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)).\nAlthough NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (Févotte (2011)), including co-occurrence statistics of the basis functions (Wilson et al. (2008)), and learned temporal dynamics with Kalman filtering like techniques(Mysore & Smaragdis (2011); Han et al. (2012); Févotte et al. (2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)).\nMore recently, several works have observed that the efficiency of these methods can be improved with discriminative training. Discriminatively trained dictionary learning techniques (Mairal et al. (2012); Gregor & LeCun (2010); Sprechmann et al. (2014); Weninger et al. (2014a)) show the importance of adapting the modeling task to become discriminative at the inverse problem at hand.\nA number of works completely bypass the modeling aspect and approach inverse problems as non-linear regression problems using Deep Neural Networks(DNN) (Sprechmann et al. (2013); Schuler et al. (2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)).\nThe goal of this work is to show that using stable and robust multi-resolution representation of the data can benefit the sources separation algorithms in both discriminative and non-discriminative settings. Previous works have shown that the choice of the input features plays a very important role of on source separation (Weninger et al. (2014b)) and speech recognition (Mohamed et al. (2012)). This work takes this observation a step further to the multi-resolution setting.\nWe consider a deep representation based on the wavelet scattering pyramid, which produces information at different temporal resolutions and defines a metric which is increasingly contracting. This representation can be thought as a generalization of the CQT. Discriminative features having longer temporal context can be constructed with the scattering transform (Bruna & Mallat (2013b)) and have been sucessfully applied to audio signals by Andén & Mallat (2013). While these features have shown excellent performance in various classification tasks, in the context of source separation we require a representation that not only captures long-range temporal structures, but also preserves as much temporal discriminability as possible.\nFor the non-discriminative setting, we present an extension of the NMF framework to the pyramid representation. We learn NMF models at different levels of the hierarchy. While NMF dictionaries at the first level are very selective to temporally localized energy patterns, deeper layers provide additional modeling of the longer temporal dynamics (Bruna et al. (2014)). For the discriminative setting we discuss a number of baseline models based on neural networks. As a proof of concept, we evaluate both settings on a multi-speaker speech separation task. We observe that in both training regimes the multi-resolution setting leads to better performance with respect to the baselines. We also confirm with experiments the superiority of discriminative approaches.\nThe paper is organized as follows. In Section 2 we describe the general setting of source separation and review some baseline solutions for both in training regimes. We present the proposed representation in Sections 3 and show how it can be used in the context of source separation in Section 4. We show some initial experimental results in Section 5 and a discussion is given in Section 6."
    }, {
      "heading" : "2 SINGLE-CHANNEL SOURCE SEPARATION",
      "text" : "In this work we are intereseted in the families of algorithms that solve source separation on a feature space. This section is dedicated to describing different alternatives that fall in this category. We first introduce the general setting in Section 2.1. In Section 2.2 we describe the popular NMF framework and different training regimes employed with it. Finally we discuss purely discriminative approaches based on deep networks in Section 2.3."
    }, {
      "heading" : "2.1 PROBLEM FORMULATION",
      "text" : "We consider the setting in which we observe a temporal signal y(t) that is the sum of two sources xi(t), with i = 1, 2,\ny(t) = x1(t) + x2(t), (1)\nand we aim at finding estimates x̂i(t). We consider the supervised monoaural source separation problem, in which the components xi, i = 1, 2 come from sources for which we have representative training data. In this report we concentrate to the case of speech signals, but other alternatives could be considered, such as noise or music.\nMost recent techniques typically operate on a non-negative time-frequency representation. Let us denote as Φ(y) ∈ Rm×n the transformed version of y(t), comprising m frequency bins and n temporal frames. This transform can be thought as a non-linear analysis operator and is typically defined as the magnitude (or power) of a time-frequency representation such as the Short-Time Fourier Transform (STFT). Other robust alternatives have also been explored (Huang et al. (2014a);\nWeninger et al. (2014b)). In all cases, the temporal resolution of the features is fixed and given by the frame duration.\nPerforming the separation in the non-linear representation is key to the success of these algorithms. The transformed domain is in general invariant to some irrelevant variability of the signals (such as local shifts), thus relieving the algorithms from learning it. This comes at the expense of inverting the unmixed estimates in the feature space, normally known as the phase recovery problem (Gerchberg & Saxton (1972)). Specifically, these algorithms take Φ(y) as input and produce estimates for each source, Φ(x̂i) with i = 1, 2. The phase recovery problem corresponts to finding signals x̂′i such matching the obtained features Φ(x̂i) and satisfying y = x̂ ′ 1 + x̂ ′ 2.\nThe most common choice is to use the magintud (or power) STFT as the feature space. In this case, the phase recovery problem can be solved very efficiently using soft masks to filter the mixture signal (Schmidt et al. (2007)). The strategy resembles Wiener filtering and has demonstrated very good results in practice. Specifically, Φ(y) = |S{y}|, where S{y} ∈ Cm×n is a complex matrix corresponding to the STFT. The estimated unmixed signals are obtained by filtering the mixture,\nx̂i = S −1 {Mi ◦ S{y}} , with Mi =\nΦ(x̂i) p\n∑ l=1,2 Φ(x̂l) p , (2)\nwhere multiplication denoted ◦, division, and exponentials are element-wise operations. The parameter p defines the smoothness of the mask, we use p = 2 in our experiments. Note that this solution automatically imposes the consistency restriction y = x̂′1 + x̂ ′ 2."
    }, {
      "heading" : "2.2 NON-NEGATIVE MATRIX FACTORIZATION",
      "text" : "Source separation methods based on matrix factorization approaches have received a lot of attention in the literature in recent years. NMF-based source separation techniques attempt to find the nonnegative activations Zi ∈ Rq×n, i = 1, 2 best representing the different speech components in two dictionaries Di ∈ Rm×q. Ideally one would want to solve the problem,\nmin x′ i ,Zi≥0\n∑\ni=1,2\nD(Φ(x′i)|DiZi) + λR(Zi) s.t. y = x ′ 1 + x ′ 2 . (3)\nwhere the first term in the optimization objective measures the dissimilarity between the input data and the estimated channels in the feature space. Common choices of D are the squared Euclidean distance, the Kullback-Leibler divergence, and the Itakura-Saito divergence. The second term in the minimization objective is included to promote some desired structure of the activations. This is done using a designed regularization function R, whose relative importance is controlled by the parameters λ. In this work we use D reweighted squared Euclidean distance and the ℓ1 norm as the regularization function R.\nProblem (3) could be minimized with an alternating gradient descent between x′i and zi. Note that fixing zi and minimizing with respect to x′i requires locally inverting the transform Φ, which amounts to solve an overcomplete phase recovery problem. In practice, a greedy proxy of (3) is solved instead. First a separation is obtained in the feature spaces by solving a clasic NMF problem,\nmin Zi≥0\nD(Φ(x)| ∑\ni=1,2\nDiZi) + λ ∑\ni=1,2\nR(Zi) , (4)\nfor which there exist standard optimization algorithms, see for example Févotte & Idier (2011). Once the optimal activations are solved for, the spectral envelopes of the speech are estimated as Φ(x̂i) = DiZi, and the phase recovery is solved using (2).\nIn this supervised setting, the dictionaries are obtained from training data. The classic approach is to build model for each source independently and later use them together at testing time. Many works have observed that sparse coding inference algorithms can be improved in specific tasks by using discriminative training, i.e. by directly optimizing the parameters of the model on the evaluation cost function. Task-aware (or discriminative) sparse modeling is elegantly described by Mairal et al. (2012), observing that one can back-propagate through the Lasso. These ideas have been used in the context of source separation and enhancement (Sprechmann et al. (2014); Weninger et al. (2014a)). The goal is to obtain dictionaries such that the solution of (4) also minimizes the reconstruction\ngiven the ground truth separation,\nmin D1≥0,D2≥0\nD(Φ(x1)|D1Z ∗ 1 ) + αD(Φ(x2)|D2Z ∗ 2 ), (5)\nwhere Z∗i are the solutions of (4) (and depend on the dictionaries) and α is a parameter controlling the relative importance of source recovery; typically, one would set α = 0 in a denoising application (where the second signal is noise), and α = 1 in a source separation application where both signals need to be recovered. When the phase recovery can be obtained using the masking scheme described in Section 2.1, it could be included into the objective in order to directly optimize the signal reconstruction in the time domain. While the discriminative setting is a better target, the estimation needs to be computed over the product set rather than each training set independently and the generalization might be compromised when small training sets are available. It is important to note that the level of supervision is very mild, as in the training of autoencoders. We are artificially generating the mixtures, and consequently obtaining the ground truth.\nThe standard NMF approaches treat different time-frames independently, ignoring the temporal dynamics of the signals. As described in Section 1, many works attempt to change the regularization function R in order integrate several frames into de decomposition. It’s analysis and description is outside the scope of this report."
    }, {
      "heading" : "2.3 PURELY DISCRIMINATIVE SETTINGS",
      "text" : "With the mindset of the discriminative learning, one is tempted to simply replace the inference step by a generic neural network architecture, having enough capacity to perform non-linear regression. The systems are trained as to minimize a measure of fitness between the ground truth separation and the output as in (5), being the most common the Mean Squared Error (MSE). Not that this can be performed in the feature space or in the time domain (when the phase recovery is simple). Other alternatives studied in the literature consist of predicting the masks given in (3) as described by Huang et al. (2014a).\nThe most straight forward choice is to perform the estimation using a DNN on a fixed time scale. Using a short temporal context fails to model long range temporal dependencies on the speech signals, while increasing the context renders the regression problem intractable. One could consider to train a DNN on an set of several frames (Weninger et al. (2014b)). Recent works have explored neural network architectures that exploit temporal context such as RNN and Long Short-Term Memory (LSTM) (Huang et al. (2014a); Weninger et al. (2014b))."
    }, {
      "heading" : "3 PYRAMID WAVELET SCATTERING",
      "text" : "In this section we present briefly the proposed wavelet scattering pyramid, which is conceptually similar to standard scattering networks introduced by Mallat (2010), but creates features at different temporal resolutions at every layer."
    }, {
      "heading" : "3.1 WAVELET FILTER BANK",
      "text" : "A wavelet ψ(t) is a band-pass filter with good frequency and spatial localization. We consider a complex wavelet with a quadrature phase, whose Fourier transform satisfies Fψ(ω) ≈ 0 for ω < 0. We assume that the center frequency of Fψ is 1 and that its bandwidth is of the order of Q−1. Wavelet filters centered at the frequencies λ = 2j/Q are computed by dilating ψ: ψλ(t) = λψ(λ t), and hence Fψλ(ω) = ψ̂(λ−1ω). We denote by Λ the index set of λ = 2j/Q over the signal frequency support, with j ≤ J1. The resulting filter bank has a constant number Q of bands per octave and J1 octaves. Let us define φ1(t) as a low-pass filter with bandwidth 2−J1 . The wavelet transform of a signal x(t) is\nWx = {x ∗ φ1(t) , x ∗ ψλ(t)}λ∈Λ .\nSince the bandwidth of all filters is at most Q1, we can down-sample its outputs with a stride Q."
    }, {
      "heading" : "3.2 PYRAMID SCATTERING TRANSFORM",
      "text" : "Instead of using a fixed bandwidth smoothing kernel that is applied at all layers, we sample at critical rate in order to preserve temporal locality as much as possible. We start by removing the complex phase of wavelet coefficients in Wx with a complex modulus nonlinearity. Then, we arrange these first layer coefficients as nodes in the first level of a tree. Each node of this tree is down sampled at the critical sampling rate of the layer ∆1, given by the reciprocal of the largest bandwidth present in the filter bank:\n|W 1|x = {x1i }i=1...1+|Λ| = {x ∗ φ1(∆1n) , |x ∗ ψλ(∆1n)|}λ∈Λ .\nThese first layer coefficients give localized information both in time and frequency, with a trade-off dictated by the Q factor. They are however sensitive to local time-frequency warps, which are often uninformative. In order to increase the robustness of the representation, we transform each of the down sampled signals with a new wavelet filter bank and take the complex modulus of the oscillatory component. For simplicity, we assume a dyadic transformation, which reduces the filter bank to a pair of conjugate mirror filters {φ2, ψ2} (Mallat (1999)), carrying respectively the low-frequencies and high-frequencies of the discrete signal from above the tree:\n|W 2|x = {x1i ∗ φ2(2n) , |x 1 i ∗ ψ2(2n)|}i=1...|W 1| .\nEvery layer thus produces new feature maps at a lower temporal resolution. As shown in Bruna & Mallat (2013b), only coefficients having gone through m ≤ mmax non-linearities are in practice computed, since their energy quickly decays. We fix mmax = 2 in our experiments.\nWe can reapply the same operator as many times k as desired until reaching a temporal context T = 2k∆1. If the wavelet filters are chosen such that they define a non-expansive mapping Bruna & Mallat (2013b), it results that every layer defines a metric which is increasingly contracting:\n‖|W k|x− |W k|x′‖ ≤ ‖|W k−1|x− |W k−1|x′‖ ≤ ‖x− x′‖ .\nEvery layer thus produces new feature maps at a lower temporal resolution. In the end we obtain a tree of different representations, Φj(x) = |W j |x with j = 1, . . . , k."
    }, {
      "heading" : "4 SOURCE SEPARATION ALGORITHMS",
      "text" : "In this section we show a few examples of how the proposed pyramid scattering features could be used for solving the source separation problem. We present alternatives for both learning paradigms: non-discriminative and discriminative."
    }, {
      "heading" : "4.1 NON-DISCRIMINATIVE TRAINING",
      "text" : "In this setting, we try to find models for each speaker using the features of the wavelet scattering pyramid. Each layer of the transform produces information with different stability/discriminability trade-offs. Whereas in typical classification applications one is mostly interested in choosing a single layer which provides the best trade-off given the intrinsic variability of the dataset, in inverse problems we can leverage signal models at all levels. Let us suppose two different sources X1 and X2, and let us consider for simplicity the features Φj(xi), j = 1, 2, i = 1, 2, xi ∈ Xi, obtained by localizing the scattering features of two different resolutions at their corresponding sampling rates. Therefore, Φ1 carries more discriminative and localized information than Φ2.\nIn the non-discriminative training, we train independent models for each source. Given training examples Xti from each source, we consider a NMF of each of the features Φj(x t i):\nmin Dj\ni ,Zj i ≥0\n∑\nxi∈Xi\n1 2 ‖Φj(xi)−D j iZ j i ‖ 2 + λji‖Z j i ‖1,\nwhere here the parameters λji control the sparsity-reconstruction trade-off in the sparse coding. In our experiments we used a fixed value for all of them λ2i = λ. At test time, given y = x1 + x2, we\nestimate x̂1, x̂2 as the solution of\nmin x̂1+x̂2=y,Z j\ni ≥0\n∑\ni=1,2\n1 2 ‖Φ1(x̂i)−D 1 iZ 1 i ‖ 2 2 + λ 1 i ‖Zi‖1 + 1 2 ‖Φ2(x̂i)−D 2 iZ 2 i ‖ 2 2 + λ 2 i ‖Z 2 i ‖1 . (6)\nProblem (6) is a coupled phase recovery problem under linear constraints. It can be solved using gradient descent as in Bruna & Mallat (2013a), but in our setting we use a greedy algorithm, which approximates the unknown complex phases using the phase of W1y and W2|W1y| respectively. Similarly as in Weninger et al. (2014b), we simplify the inference by using a stronger version of the linear constraint y = x1 + x2, namely\n|W 1y|2 = |W 1x1| 2 + |W 1x2| 2 ,\nand therefore that destructive interferences are negligible."
    }, {
      "heading" : "4.2 DISCRIMINATIVE TRAINING",
      "text" : "The pyramid scattering features can also be used to train end-to-end models. The most simple alternative is to train a DNN directly from features having the same temporal context as second layer scattering features. For simplicity, we replace the second layer of complex wavelets and modulus with a simple Haar transform:\nΦ2(x) = {|x ∗ ψλ| ∗ hk(∆1n)}λ∈Λ,k=0,...J2 ,\nwhere hk is the Haar wavelet at scale 2k, and we feed this feature into a DNN with the same number of hidden units as before. We do not take the absolute value as in standard scattering to leave the chance to the DNN to recombine coefficients before the first non-linearity. We report results for J2 = 5 which corresponds to a temporal context of 130ms. We will refer to this alternative as DNNmulti. As a second example, we also consider a multi-resolution Convolutional Neural Network (CNN), constructed by creating contexts of three temporal frames at resolutions 2j , j = 0 . . . , J2 = 5. We will refer to this alternative as CNN-multi. This setting has the same temporal context as the DNN-multi but rather than imposing separable filters we leave extra freedom. This architecture can access relatively large temporal context with a small number of learnable parameters. Since the phse recovery problem cannot be approximated with softmax as in (3), we use as the cost function the MSE of the reconstructed feature at all resolutions."
    }, {
      "heading" : "5 EXPERIMENTS",
      "text" : "In this section we present some initial experimental evaluation in which we study the use of multi resolution signal representation with both discriminative and non-discriminative training regimes. We compare the performance against some basic baseline settings.\nAs a proof of concept, we evaluated the different alternatives in a multi-speaker setting in which we aim at separating male and female speech. In each case, we trained two gender-specific modeles. The training data consists of recordings of a generic group of speakres per gender, none of which were included in the test set. The experiments were carried out on the TIMIT corpus. We adopted the standard test-train division, using all the training recordings (containing 462 different speakers) for building the models and a subset of 12 different speakers (6 males and 6 females) for testing. For each speaker we randomly chose two clips and compared all female-male combinations (144 mixtures). All signals where mixed at 0 dB and resampled to 16 kHz. We used the source-todistortion ratio (SDR), source-to-interference ratio (SIR), and source-to-artifact ratio (SAR) from the BSS-EVAL metrics (Vincent et al. (2006)). We report the average over the both speakers, as the measure are not symmetric.\nNon-discriminative settings: As a basline for the non-discriminative setting we used standard NMF with STFT of frame lengths of 1024 samples and 50% overlap, leading to 513 feature vectors. The dictionaries were chosen with 200 and 400 atoms. We evaluated the proposed scattering features in combination with NMF (as described in Section 4.1) with one and two layers, referred as scattNMF1 and scatt-NMF2 respectively. We use complex Morlet wavelets with Q1 = 32 voices per octave in the first level, and dyadic Morlet wavelets (Q2 = 1) for the second level, for a review on Morlet wavelets refer to Mallat (1999). The resulting representation had 175 coefficients for the first\nlevel and around 2000 for the second layer. We used 400 atoms for scatt-NMF1 and 1000 atoms for scatt-NMF2. In all cases, the features were frame-wise normalized and we used λ = 0.1. In all cases, parameters were obtained using cross-validation on a few clips separated from the training as a validation set.\nDiscriminative settings: We use a single and multi-frame DNNs as a baseline for this training setting.The network architectures consist of two hidden layers using the outputs of the first layer of scattering, that is, the CQT coefficients at a given temporal position. It uses RELU’s as in the rest of the architectures and the output is normalize so that it corresponds to the spectral mask discussed in (3). The multi-frame version considers the concatenation of 5 frames as inputs matching the temporal context of the tested multi-resolution versions. We used 512 and 150 units for the singleframe DNN (referred as CQT-DNN) and 1024 and 512 for the multi-frame one (referred as CQTDNN-5), increasing the number of parameters did not improve the results. We optimize the network to optimize the MSE to each of the sources. We also include the architectures DNN-multi and CNN-multi described in Section 4.2. In all cases the weights are randomly initialized and training is performed using stochastic gradient descent with momentum. We used the GPU-enabled package Matconvnet (Simonyan & Zisserman (2014)).\nTable 1 shows the results obtained for the speaker-specific and multi-speaker settings. In all cases we observe that the one layer scattering transform outperforms the STFT in terms of SDR. Furthermore, there is a tangible gain in including a deeper representation; scatt-NMF2 performs always better than scatt-NMF1. While the gain in the SDR and SAR are relatively small the SIR is 3dB higher. It is thus benefitial to consider a longer temporal context in order to perform the separation sucessfully.\nOn the other hand, as expected, the discriminative training yields very significant improvements. The same reasons that produced the improvements in the non-discriminative setting also have an impact in the discriminative case. Adding enough temporal contexts to the neural regressors improves their performance. The multi-temporal representation plays a key role as simply augmenting the number of frames does not lead to better performance (at least using baseline DNNs). It remains to be seen how these architectures would compare with the alternative RNN models."
    }, {
      "heading" : "6 DISCUSSION",
      "text" : "We have observed that the performance of baseline source separation algorithms can be improved by using a temporal multi-resolution representation. The representation is able to integrate information across longer temporal contexts while removing uninformative variability with a relatively low parameter budget. In line with recent findings in the literature, we have observed that including discriminative criteria in the training leads to significant improvements in the source separation performance. However, contrary to standard sparse modeling in which the resulting inference can be readily approximated with a neural network, it remains unclear whether phase-recovery type inference can also be efficiently approximated with neural network architectures. We believe there might still be a gap in performance that might be bridged with appropriate discriminative architectures.\nWhile this report presents shows some promising initial results, several interesting comparisons need to be made and are subject of current research. We consider an interesting problem exploring the best way of including the long-term temporal consistency into the estimation. Recent studies have evaluate the use of deep RNN’s for solving the source separation problem Huang et al. (2014a); Weninger et al. (2014b). While Huang et al. (2014a) do not observe significant improvements over\nstandard DNN’s in speech separation, Weninger et al. (2014b) obtain significant improvements using LSTM-DRNN in speech enhancement. We are currently addressing the question of comparing different neural network architectures that exploit temporal dependancies and assessing whether the use of multi-resolution representation can play a role as in this initial study."
    } ],
    "references" : [ {
      "title" : "Deep scattering spectrum",
      "author" : [ "J. Andén", "S. Mallat" ],
      "venue" : "arXiv preprint arXiv:1304.6763,",
      "citeRegEx" : "Andén and Mallat,? \\Q2013\\E",
      "shortCiteRegEx" : "Andén and Mallat",
      "year" : 2013
    }, {
      "title" : "Exploiting long-term temporal dependencies in nmf using recurrent neural networks with application to source separation",
      "author" : [ "N. Boulanger-Lewandowski", "G.J. Mysore", "M. Hoffman" ],
      "venue" : "In ICASSP,",
      "citeRegEx" : "Boulanger.Lewandowski et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Boulanger.Lewandowski et al\\.",
      "year" : 2014
    }, {
      "title" : "Audio texture synthesis with scattering moments",
      "author" : [ "J. Bruna", "S. Mallat" ],
      "venue" : "arXiv preprint arXiv:1311.0407,",
      "citeRegEx" : "Bruna and Mallat,? \\Q2013\\E",
      "shortCiteRegEx" : "Bruna and Mallat",
      "year" : 2013
    }, {
      "title" : "Invariant scattering convolution networks. Pattern Analysis and Machine Intelligence",
      "author" : [ "J. Bruna", "S. Mallat" ],
      "venue" : "IEEE Transactions on,",
      "citeRegEx" : "Bruna and Mallat,? \\Q2013\\E",
      "shortCiteRegEx" : "Bruna and Mallat",
      "year" : 2013
    }, {
      "title" : "Source separation with scattering non-negative matrix factorization",
      "author" : [ "J. Bruna", "P. Sprechmann", "Lecun", "Yann" ],
      "venue" : null,
      "citeRegEx" : "Bruna et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bruna et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning a deep convolutional network for image super-resolution",
      "author" : [ "Dong", "Chao", "Loy", "ChenChange", "He", "Kaiming", "Tang", "Xiaoou" ],
      "venue" : "Computer Vision ? ECCV 2014,",
      "citeRegEx" : "Dong et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Dong et al\\.",
      "year" : 2014
    }, {
      "title" : "Online plca for real-time semi-supervised source separation",
      "author" : [ "Z. Duan", "G.J. Mysore", "P. Smaragdis" ],
      "venue" : "In LVA/ICA,",
      "citeRegEx" : "Duan et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Duan et al\\.",
      "year" : 2012
    }, {
      "title" : "Majorization-minimization algorithm for smooth itakura-saito nonnegative matrix factorization",
      "author" : [ "C. Févotte" ],
      "venue" : "In ICASSP,",
      "citeRegEx" : "Févotte,? \\Q2011\\E",
      "shortCiteRegEx" : "Févotte",
      "year" : 2011
    }, {
      "title" : "Algorithms for nonnegative matrix factorization with the β-divergence",
      "author" : [ "C. Févotte", "J. Idier" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Févotte and Idier,? \\Q2011\\E",
      "shortCiteRegEx" : "Févotte and Idier",
      "year" : 2011
    }, {
      "title" : "Non-negative dynamical system with application to speech and audio",
      "author" : [ "C. Févotte", "Roux", "J. Le", "J.R. Hershey" ],
      "venue" : "In ICASSP,",
      "citeRegEx" : "Févotte et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Févotte et al\\.",
      "year" : 2013
    }, {
      "title" : "A practical algorithm for the determination of the phase from image and diffraction plane",
      "author" : [ "R.W. Gerchberg", "Saxton", "W. Owen" ],
      "venue" : "pictures. Optik,",
      "citeRegEx" : "Gerchberg et al\\.,? \\Q1972\\E",
      "shortCiteRegEx" : "Gerchberg et al\\.",
      "year" : 1972
    }, {
      "title" : "Learning fast approximations of sparse coding",
      "author" : [ "K. Gregor", "Y. LeCun" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Gregor and LeCun,? \\Q2010\\E",
      "shortCiteRegEx" : "Gregor and LeCun",
      "year" : 2010
    }, {
      "title" : "Audio imputation using the non-negative hidden markov model",
      "author" : [ "J. Han", "G.J. Mysore", "B. Pardo" ],
      "venue" : "In LVA/ICA,",
      "citeRegEx" : "Han et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2012
    }, {
      "title" : "Speech and Audio Processing in Adverse Environments",
      "author" : [ "E. Hänsler", "G. Schmidt" ],
      "venue" : null,
      "citeRegEx" : "Hänsler and Schmidt,? \\Q2008\\E",
      "shortCiteRegEx" : "Hänsler and Schmidt",
      "year" : 2008
    }, {
      "title" : "Deep learning for monaural speech separation",
      "author" : [ "Huang", "P.-S", "M. Kim", "M. Hasegawa-Johnson", "P. Smaragdis" ],
      "venue" : "In ICASSP, pp",
      "citeRegEx" : "Huang et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2014
    }, {
      "title" : "Singing-voice separation from monaural recordings using deep recurrent neural networks",
      "author" : [ "Huang", "Po-Sen", "Kim", "Minje", "Hasegawa-Johnson", "Mark", "Smaragdis", "Paris" ],
      "venue" : null,
      "citeRegEx" : "Huang et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning parts of objects by non-negative matrix factorization",
      "author" : [ "D.D. Lee", "H.S. Seung" ],
      "venue" : null,
      "citeRegEx" : "Lee and Seung,? \\Q1999\\E",
      "shortCiteRegEx" : "Lee and Seung",
      "year" : 1999
    }, {
      "title" : "Speech Enhancement: Theory and Practice, volume 30",
      "author" : [ "P.C. Loizou" ],
      "venue" : null,
      "citeRegEx" : "Loizou,? \\Q2007\\E",
      "shortCiteRegEx" : "Loizou",
      "year" : 2007
    }, {
      "title" : "Task-driven dictionary learning",
      "author" : [ "J. Mairal", "F. Bach", "J. Ponce" ],
      "venue" : "Pattern Analysis and Machine Intelligence, IEEE Transactions on,",
      "citeRegEx" : "Mairal et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Mairal et al\\.",
      "year" : 2012
    }, {
      "title" : "A wavelet tour of signal processing",
      "author" : [ "Mallat", "Stéphane" ],
      "venue" : "Academic press,",
      "citeRegEx" : "Mallat and Stéphane.,? \\Q1999\\E",
      "shortCiteRegEx" : "Mallat and Stéphane.",
      "year" : 1999
    }, {
      "title" : "Recursive interferometric representation",
      "author" : [ "Mallat", "Stéphane" ],
      "venue" : "In Proc. of EUSICO conference,",
      "citeRegEx" : "Mallat and Stéphane.,? \\Q2010\\E",
      "shortCiteRegEx" : "Mallat and Stéphane.",
      "year" : 2010
    }, {
      "title" : "Understanding how deep belief networks perform acoustic modelling",
      "author" : [ "Mohamed", "Abdel-rahman", "Hinton", "Geoffrey", "Penn", "Gerald" ],
      "venue" : "In Acoustics, Speech and Signal Processing (ICASSP),",
      "citeRegEx" : "Mohamed et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Mohamed et al\\.",
      "year" : 2012
    }, {
      "title" : "Supervised and unsupervised speech enhancement using nonnegative matrix factorization. Audio, Speech, and Language Processing",
      "author" : [ "N. Mohammadiha", "P. Smaragdis", "A. Leijon" ],
      "venue" : "IEEE Transactions on,",
      "citeRegEx" : "Mohammadiha et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mohammadiha et al\\.",
      "year" : 2013
    }, {
      "title" : "A non-negative approach to semi-supervised separation of speech from noise with the use of temporal dynamics",
      "author" : [ "G.J. Mysore", "P. Smaragdis" ],
      "venue" : "In ICASSP, pp",
      "citeRegEx" : "Mysore and Smaragdis,? \\Q2011\\E",
      "shortCiteRegEx" : "Mysore and Smaragdis",
      "year" : 2011
    }, {
      "title" : "Single-channel speech separation using sparse non-negative matrix factorization",
      "author" : [ "M.N. Schmidt", "R.K. Olsson" ],
      "venue" : "In INTERSPEECH,",
      "citeRegEx" : "Schmidt and Olsson,? \\Q2006\\E",
      "shortCiteRegEx" : "Schmidt and Olsson",
      "year" : 2006
    }, {
      "title" : "Wind noise reduction using non-negative sparse coding",
      "author" : [ "M.N. Schmidt", "J. Larsen", "Hsiao", "F.-T" ],
      "venue" : "In MLSP,",
      "citeRegEx" : "Schmidt et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Schmidt et al\\.",
      "year" : 2007
    }, {
      "title" : "Learning to deblur",
      "author" : [ "Schuler", "Ch", "M. Hirsch", "S. Harmeling", "B. Scholkopf" ],
      "venue" : "arXiv preprint arXiv:1406.7444,",
      "citeRegEx" : "Schuler et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Schuler et al\\.",
      "year" : 2014
    }, {
      "title" : "Sparse Overcomplete Decomposition for Single Channel Speaker Separation",
      "author" : [ "M.V.S. Shashanka", "B. Raj", "P. Smaragdis" ],
      "venue" : "In ICASSP,",
      "citeRegEx" : "Shashanka et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Shashanka et al\\.",
      "year" : 2007
    }, {
      "title" : "Very deep convolutional networks for large-scale image recognition",
      "author" : [ "Simonyan", "Karen", "Zisserman", "Andrew" ],
      "venue" : "arXiv preprint arXiv:1409.1556,",
      "citeRegEx" : "Simonyan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Simonyan et al\\.",
      "year" : 2014
    }, {
      "title" : "Static and dynamic source separation using nonnegative factorizations: A unified view",
      "author" : [ "P. Smaragdis", "C. Fevotte", "G Mysore", "N. Mohammadiha", "M. Hoffman" ],
      "venue" : "Signal Processing Magazine, IEEE,",
      "citeRegEx" : "Smaragdis et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Smaragdis et al\\.",
      "year" : 2014
    }, {
      "title" : "Learnable low rank sparse models for speech denoising",
      "author" : [ "P. Sprechmann", "A. Bronstein", "M. Bronstein", "G. Sapiro" ],
      "venue" : "In ICASSP,",
      "citeRegEx" : "Sprechmann et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Sprechmann et al\\.",
      "year" : 2013
    }, {
      "title" : "Supervised non-euclidean sparse NMF via bilevel optimization with applications to speech enhancement",
      "author" : [ "P. Sprechmann", "A.M. Bronstein", "G. Sapiro" ],
      "venue" : "In HSCMA,",
      "citeRegEx" : "Sprechmann et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Sprechmann et al\\.",
      "year" : 2014
    }, {
      "title" : "Performance measurement in blind audio source separation",
      "author" : [ "E. Vincent", "R. Gribonval", "C. Févotte" ],
      "venue" : "IEEE Trans. on Audio, Speech, and Lang. Proc.,",
      "citeRegEx" : "Vincent et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Vincent et al\\.",
      "year" : 2006
    }, {
      "title" : "Discriminative NMF and its application to single-channel source separation",
      "author" : [ "F. Weninger", "J. Le Roux", "Hershey", "J. R", "S. Watanabe" ],
      "venue" : "Proc. of ISCA Interspeech,",
      "citeRegEx" : "Weninger et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Weninger et al\\.",
      "year" : 2014
    }, {
      "title" : "Discriminatively trained recurrent neural networks for single-channel speech separation",
      "author" : [ "Weninger", "Felix", "Le Roux", "Jonathan", "Hershey", "John R", "Schuller", "Björn" ],
      "venue" : "In Proc. IEEE GlobalSIP 2014 Symposium on Machine Learning Applications in Speech Processing,",
      "citeRegEx" : "Weninger et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Weninger et al\\.",
      "year" : 2014
    }, {
      "title" : "Speech denoising using nonnegative matrix factorization with priors",
      "author" : [ "K.W. Wilson", "B. Raj", "P. Smaragdis", "A. Divakaran" ],
      "venue" : "In ICASSP,",
      "citeRegEx" : "Wilson et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Wilson et al\\.",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); Hänsler & Schmidt (2008)).",
      "startOffset" : 82,
      "endOffset" : 96
    }, {
      "referenceID" : 12,
      "context" : "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); Hänsler & Schmidt (2008)).",
      "startOffset" : 82,
      "endOffset" : 122
    }, {
      "referenceID" : 12,
      "context" : "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); Hänsler & Schmidt (2008)). Successful algorithms rely on models that capture signal regularity while preserving discrimination between different speakers. The decomposition of time-frequency representations, such as the power or magnitude spectrogram in terms of elementary atoms of a dictionary, has become a popularcitet tool in audio processing. Non-negative matrix factorization (NMF) (Lee & Seung (1999)), have been widely adopted in various audio processing tasks, including in particular source separation, see Smaragdis et al.",
      "startOffset" : 82,
      "endOffset" : 506
    }, {
      "referenceID" : 12,
      "context" : "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); Hänsler & Schmidt (2008)). Successful algorithms rely on models that capture signal regularity while preserving discrimination between different speakers. The decomposition of time-frequency representations, such as the power or magnitude spectrogram in terms of elementary atoms of a dictionary, has become a popularcitet tool in audio processing. Non-negative matrix factorization (NMF) (Lee & Seung (1999)), have been widely adopted in various audio processing tasks, including in particular source separation, see Smaragdis et al. (2014) for a recent review.",
      "startOffset" : 82,
      "endOffset" : 639
    }, {
      "referenceID" : 12,
      "context" : "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); Hänsler & Schmidt (2008)). Successful algorithms rely on models that capture signal regularity while preserving discrimination between different speakers. The decomposition of time-frequency representations, such as the power or magnitude spectrogram in terms of elementary atoms of a dictionary, has become a popularcitet tool in audio processing. Non-negative matrix factorization (NMF) (Lee & Seung (1999)), have been widely adopted in various audio processing tasks, including in particular source separation, see Smaragdis et al. (2014) for a recent review. There are many works that follow this line in speech separation (Schmidt & Olsson (2006); Shashanka et al.",
      "startOffset" : 82,
      "endOffset" : 749
    }, {
      "referenceID" : 12,
      "context" : "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); Hänsler & Schmidt (2008)). Successful algorithms rely on models that capture signal regularity while preserving discrimination between different speakers. The decomposition of time-frequency representations, such as the power or magnitude spectrogram in terms of elementary atoms of a dictionary, has become a popularcitet tool in audio processing. Non-negative matrix factorization (NMF) (Lee & Seung (1999)), have been widely adopted in various audio processing tasks, including in particular source separation, see Smaragdis et al. (2014) for a recent review. There are many works that follow this line in speech separation (Schmidt & Olsson (2006); Shashanka et al. (2007)) and enhancement (Duan et al.",
      "startOffset" : 82,
      "endOffset" : 774
    }, {
      "referenceID" : 5,
      "context" : "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al.",
      "startOffset" : 25,
      "endOffset" : 44
    }, {
      "referenceID" : 5,
      "context" : "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)).",
      "startOffset" : 25,
      "endOffset" : 71
    }, {
      "referenceID" : 5,
      "context" : "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)). Although NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (Févotte (2011)), including co-occurrence statistics of the basis functions (Wilson et al.",
      "startOffset" : 25,
      "endOffset" : 627
    }, {
      "referenceID" : 5,
      "context" : "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)). Although NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (Févotte (2011)), including co-occurrence statistics of the basis functions (Wilson et al. (2008)), and learned temporal dynamics with Kalman filtering like techniques(Mysore & Smaragdis (2011); Han et al.",
      "startOffset" : 25,
      "endOffset" : 709
    }, {
      "referenceID" : 5,
      "context" : "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)). Although NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (Févotte (2011)), including co-occurrence statistics of the basis functions (Wilson et al. (2008)), and learned temporal dynamics with Kalman filtering like techniques(Mysore & Smaragdis (2011); Han et al.",
      "startOffset" : 25,
      "endOffset" : 805
    }, {
      "referenceID" : 5,
      "context" : "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)). Although NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (Févotte (2011)), including co-occurrence statistics of the basis functions (Wilson et al. (2008)), and learned temporal dynamics with Kalman filtering like techniques(Mysore & Smaragdis (2011); Han et al. (2012); Févotte et al.",
      "startOffset" : 25,
      "endOffset" : 824
    }, {
      "referenceID" : 5,
      "context" : "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)). Although NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (Févotte (2011)), including co-occurrence statistics of the basis functions (Wilson et al. (2008)), and learned temporal dynamics with Kalman filtering like techniques(Mysore & Smaragdis (2011); Han et al. (2012); Févotte et al. (2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al.",
      "startOffset" : 25,
      "endOffset" : 847
    }, {
      "referenceID" : 1,
      "context" : "(2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)).",
      "startOffset" : 79,
      "endOffset" : 115
    }, {
      "referenceID" : 1,
      "context" : "(2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)). More recently, several works have observed that the efficiency of these methods can be improved with discriminative training. Discriminatively trained dictionary learning techniques (Mairal et al. (2012); Gregor & LeCun (2010); Sprechmann et al.",
      "startOffset" : 79,
      "endOffset" : 321
    }, {
      "referenceID" : 1,
      "context" : "(2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)). More recently, several works have observed that the efficiency of these methods can be improved with discriminative training. Discriminatively trained dictionary learning techniques (Mairal et al. (2012); Gregor & LeCun (2010); Sprechmann et al.",
      "startOffset" : 79,
      "endOffset" : 344
    }, {
      "referenceID" : 1,
      "context" : "(2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)). More recently, several works have observed that the efficiency of these methods can be improved with discriminative training. Discriminatively trained dictionary learning techniques (Mairal et al. (2012); Gregor & LeCun (2010); Sprechmann et al. (2014); Weninger et al.",
      "startOffset" : 79,
      "endOffset" : 370
    }, {
      "referenceID" : 1,
      "context" : "(2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)). More recently, several works have observed that the efficiency of these methods can be improved with discriminative training. Discriminatively trained dictionary learning techniques (Mairal et al. (2012); Gregor & LeCun (2010); Sprechmann et al. (2014); Weninger et al. (2014a)) show the importance of adapting the modeling task to become discriminative at the inverse problem at hand.",
      "startOffset" : 79,
      "endOffset" : 395
    }, {
      "referenceID" : 24,
      "context" : "A number of works completely bypass the modeling aspect and approach inverse problems as non-linear regression problems using Deep Neural Networks(DNN) (Sprechmann et al. (2013); Schuler et al.",
      "startOffset" : 153,
      "endOffset" : 178
    }, {
      "referenceID" : 21,
      "context" : "(2013); Schuler et al. (2014); Dong et al.",
      "startOffset" : 8,
      "endOffset" : 30
    }, {
      "referenceID" : 4,
      "context" : "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN.",
      "startOffset" : 8,
      "endOffset" : 27
    }, {
      "referenceID" : 4,
      "context" : "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al.",
      "startOffset" : 8,
      "endOffset" : 208
    }, {
      "referenceID" : 4,
      "context" : "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al.",
      "startOffset" : 8,
      "endOffset" : 230
    }, {
      "referenceID" : 4,
      "context" : "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al.",
      "startOffset" : 8,
      "endOffset" : 272
    }, {
      "referenceID" : 4,
      "context" : "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)).",
      "startOffset" : 8,
      "endOffset" : 321
    }, {
      "referenceID" : 4,
      "context" : "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)). The goal of this work is to show that using stable and robust multi-resolution representation of the data can benefit the sources separation algorithms in both discriminative and non-discriminative settings. Previous works have shown that the choice of the input features plays a very important role of on source separation (Weninger et al. (2014b)) and speech recognition (Mohamed et al.",
      "startOffset" : 8,
      "endOffset" : 672
    }, {
      "referenceID" : 4,
      "context" : "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)). The goal of this work is to show that using stable and robust multi-resolution representation of the data can benefit the sources separation algorithms in both discriminative and non-discriminative settings. Previous works have shown that the choice of the input features plays a very important role of on source separation (Weninger et al. (2014b)) and speech recognition (Mohamed et al. (2012)).",
      "startOffset" : 8,
      "endOffset" : 719
    }, {
      "referenceID" : 4,
      "context" : "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)). The goal of this work is to show that using stable and robust multi-resolution representation of the data can benefit the sources separation algorithms in both discriminative and non-discriminative settings. Previous works have shown that the choice of the input features plays a very important role of on source separation (Weninger et al. (2014b)) and speech recognition (Mohamed et al. (2012)). This work takes this observation a step further to the multi-resolution setting. We consider a deep representation based on the wavelet scattering pyramid, which produces information at different temporal resolutions and defines a metric which is increasingly contracting. This representation can be thought as a generalization of the CQT. Discriminative features having longer temporal context can be constructed with the scattering transform (Bruna & Mallat (2013b)) and have been sucessfully applied to audio signals by Andén & Mallat (2013).",
      "startOffset" : 8,
      "endOffset" : 1189
    }, {
      "referenceID" : 4,
      "context" : "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)). The goal of this work is to show that using stable and robust multi-resolution representation of the data can benefit the sources separation algorithms in both discriminative and non-discriminative settings. Previous works have shown that the choice of the input features plays a very important role of on source separation (Weninger et al. (2014b)) and speech recognition (Mohamed et al. (2012)). This work takes this observation a step further to the multi-resolution setting. We consider a deep representation based on the wavelet scattering pyramid, which produces information at different temporal resolutions and defines a metric which is increasingly contracting. This representation can be thought as a generalization of the CQT. Discriminative features having longer temporal context can be constructed with the scattering transform (Bruna & Mallat (2013b)) and have been sucessfully applied to audio signals by Andén & Mallat (2013). While these features have shown excellent performance in various classification tasks, in the context of source separation we require a representation that not only captures long-range temporal structures, but also preserves as much temporal discriminability as possible.",
      "startOffset" : 8,
      "endOffset" : 1266
    }, {
      "referenceID" : 4,
      "context" : "While NMF dictionaries at the first level are very selective to temporally localized energy patterns, deeper layers provide additional modeling of the longer temporal dynamics (Bruna et al. (2014)).",
      "startOffset" : 177,
      "endOffset" : 197
    }, {
      "referenceID" : 14,
      "context" : "Other robust alternatives have also been explored (Huang et al. (2014a);",
      "startOffset" : 51,
      "endOffset" : 72
    }, {
      "referenceID" : 25,
      "context" : "In this case, the phase recovery problem can be solved very efficiently using soft masks to filter the mixture signal (Schmidt et al. (2007)).",
      "startOffset" : 119,
      "endOffset" : 141
    }, {
      "referenceID" : 7,
      "context" : "for which there exist standard optimization algorithms, see for example Févotte & Idier (2011). Once the optimal activations are solved for, the spectral envelopes of the speech are estimated as Φ(x̂i) = DiZi, and the phase recovery is solved using (2).",
      "startOffset" : 72,
      "endOffset" : 95
    }, {
      "referenceID" : 7,
      "context" : "for which there exist standard optimization algorithms, see for example Févotte & Idier (2011). Once the optimal activations are solved for, the spectral envelopes of the speech are estimated as Φ(x̂i) = DiZi, and the phase recovery is solved using (2). In this supervised setting, the dictionaries are obtained from training data. The classic approach is to build model for each source independently and later use them together at testing time. Many works have observed that sparse coding inference algorithms can be improved in specific tasks by using discriminative training, i.e. by directly optimizing the parameters of the model on the evaluation cost function. Task-aware (or discriminative) sparse modeling is elegantly described by Mairal et al. (2012), observing that one can back-propagate through the Lasso.",
      "startOffset" : 72,
      "endOffset" : 762
    }, {
      "referenceID" : 7,
      "context" : "for which there exist standard optimization algorithms, see for example Févotte & Idier (2011). Once the optimal activations are solved for, the spectral envelopes of the speech are estimated as Φ(x̂i) = DiZi, and the phase recovery is solved using (2). In this supervised setting, the dictionaries are obtained from training data. The classic approach is to build model for each source independently and later use them together at testing time. Many works have observed that sparse coding inference algorithms can be improved in specific tasks by using discriminative training, i.e. by directly optimizing the parameters of the model on the evaluation cost function. Task-aware (or discriminative) sparse modeling is elegantly described by Mairal et al. (2012), observing that one can back-propagate through the Lasso. These ideas have been used in the context of source separation and enhancement (Sprechmann et al. (2014); Weninger et al.",
      "startOffset" : 72,
      "endOffset" : 925
    }, {
      "referenceID" : 7,
      "context" : "for which there exist standard optimization algorithms, see for example Févotte & Idier (2011). Once the optimal activations are solved for, the spectral envelopes of the speech are estimated as Φ(x̂i) = DiZi, and the phase recovery is solved using (2). In this supervised setting, the dictionaries are obtained from training data. The classic approach is to build model for each source independently and later use them together at testing time. Many works have observed that sparse coding inference algorithms can be improved in specific tasks by using discriminative training, i.e. by directly optimizing the parameters of the model on the evaluation cost function. Task-aware (or discriminative) sparse modeling is elegantly described by Mairal et al. (2012), observing that one can back-propagate through the Lasso. These ideas have been used in the context of source separation and enhancement (Sprechmann et al. (2014); Weninger et al. (2014a)).",
      "startOffset" : 72,
      "endOffset" : 950
    }, {
      "referenceID" : 14,
      "context" : "Other alternatives studied in the literature consist of predicting the masks given in (3) as described by Huang et al. (2014a). The most straight forward choice is to perform the estimation using a DNN on a fixed time scale.",
      "startOffset" : 106,
      "endOffset" : 127
    }, {
      "referenceID" : 14,
      "context" : "Other alternatives studied in the literature consist of predicting the masks given in (3) as described by Huang et al. (2014a). The most straight forward choice is to perform the estimation using a DNN on a fixed time scale. Using a short temporal context fails to model long range temporal dependencies on the speech signals, while increasing the context renders the regression problem intractable. One could consider to train a DNN on an set of several frames (Weninger et al. (2014b)).",
      "startOffset" : 106,
      "endOffset" : 487
    }, {
      "referenceID" : 14,
      "context" : "Other alternatives studied in the literature consist of predicting the masks given in (3) as described by Huang et al. (2014a). The most straight forward choice is to perform the estimation using a DNN on a fixed time scale. Using a short temporal context fails to model long range temporal dependencies on the speech signals, while increasing the context renders the regression problem intractable. One could consider to train a DNN on an set of several frames (Weninger et al. (2014b)). Recent works have explored neural network architectures that exploit temporal context such as RNN and Long Short-Term Memory (LSTM) (Huang et al. (2014a); Weninger et al.",
      "startOffset" : 106,
      "endOffset" : 643
    }, {
      "referenceID" : 14,
      "context" : "Other alternatives studied in the literature consist of predicting the masks given in (3) as described by Huang et al. (2014a). The most straight forward choice is to perform the estimation using a DNN on a fixed time scale. Using a short temporal context fails to model long range temporal dependencies on the speech signals, while increasing the context renders the regression problem intractable. One could consider to train a DNN on an set of several frames (Weninger et al. (2014b)). Recent works have explored neural network architectures that exploit temporal context such as RNN and Long Short-Term Memory (LSTM) (Huang et al. (2014a); Weninger et al. (2014b)).",
      "startOffset" : 106,
      "endOffset" : 668
    }, {
      "referenceID" : 33,
      "context" : "Similarly as in Weninger et al. (2014b), we simplify the inference by using a stronger version of the linear constraint y = x1 + x2, namely |W y| = |W x1| 2 + |W x2| 2 , and therefore that destructive interferences are negligible.",
      "startOffset" : 16,
      "endOffset" : 40
    }, {
      "referenceID" : 32,
      "context" : "We used the source-todistortion ratio (SDR), source-to-interference ratio (SIR), and source-to-artifact ratio (SAR) from the BSS-EVAL metrics (Vincent et al. (2006)).",
      "startOffset" : 143,
      "endOffset" : 165
    }, {
      "referenceID" : 14,
      "context" : "Recent studies have evaluate the use of deep RNN’s for solving the source separation problem Huang et al. (2014a); Weninger et al.",
      "startOffset" : 93,
      "endOffset" : 114
    }, {
      "referenceID" : 14,
      "context" : "Recent studies have evaluate the use of deep RNN’s for solving the source separation problem Huang et al. (2014a); Weninger et al. (2014b). While Huang et al.",
      "startOffset" : 93,
      "endOffset" : 139
    }, {
      "referenceID" : 14,
      "context" : "Recent studies have evaluate the use of deep RNN’s for solving the source separation problem Huang et al. (2014a); Weninger et al. (2014b). While Huang et al. (2014a) do not observe significant improvements over",
      "startOffset" : 93,
      "endOffset" : 167
    } ],
    "year" : 2015,
    "abstractText" : "In this report we describe an ongoing line of research for solving single-channel source separation problems. Many monaural signal decomposition techniques proposed in the literature operate on a feature space consisting of a time-frequency representation of the input data. A challenge faced by these approaches is to effectively exploit the temporal dependencies of the signals at scales larger than the duration of a time-frame. In this work we propose to tackle this problem by modeling the signals using a time-frequency representation with multiple temporal resolutions. The proposed representation consists of a pyramid of wavelet scattering operators, which generalizes Constant Q Transforms (CQT) with extra layers of convolution and complex modulus. We first show that learning standard models with this multi-resolution setting improves source separation results over fixed-resolution methods. As study case, we use Non-Negative Matrix Factorizations (NMF) that has been widely considered in many audio application. Then, we investigate the inclusion of the proposed multi-resolution setting into a discriminative training regime. We discuss several alternatives using different deep neural network architectures.",
    "creator" : "LaTeX with hyperref package"
  }
}