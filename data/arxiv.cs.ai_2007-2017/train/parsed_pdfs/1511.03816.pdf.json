{
  "name" : "1511.03816.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Characterizing Concept Drift",
    "authors" : [ "Geoffrey I. Webb", "Hai Long Nguyen", "Francois Petitjean" ],
    "emails" : [ "geoff.webb@monash.edu", "roy.hyde@alumni.monash.edu", "hong.cao@mclaren.com", "long.nguyen@mclaren.com", "francois.petitjean@monash.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "G. I. Webb Faculty of Information Technology Monash University Clayton, Vic 3800, Australia E-mail: geoff.webb@monash.edu\nR. Hyde Faculty of Information Technology Monash University Clayton, Vic 3800, Australia E-mail: roy.hyde@alumni.monash.edu\nH. Cao McLaren Applied Technologies Pte Ltd APAC Suntec Tower One, Singapore 038987 E-mail: hong.cao@mclaren.com\nH. L. Nguyen McLaren Applied Technologies Pte Ltd APAC Suntec Tower One, Singapore 038987 E-mail: long.nguyen@mclaren.com\nF. Petitjean Faculty of Information Technology Monash University Clayton, Vic 3800, Australia E-mail: francois.petitjean@monash.edu\nar X\niv :1\n51 1.\n03 81\n6v 1\n[ cs\n.L G\n] 1\n2 N\nov 2\n01 5\nfirst comprehensive framework for quantitative analysis of drift. This supports the development of the first comprehensive set of formal definitions of types of concept drift. The formal definitions clarify ambiguities and identify gaps in previous definitions, giving rise to a new comprehensive taxonomy of concept drift types and a solid foundation for research into mechanisms to detect and address concept drift.\nKeywords Concept Drift · Learning from Non-stationary Distributions · Stream Learning · Stream Mining"
    }, {
      "heading" : "1 Introduction",
      "text" : "Most machine learning systems operate in batch mode. They analyze a set of historical data and then develop a model that reflects the world as it was when the model was formed. But the world is dynamic, and the complex distributions that a model models are likely to be non-stationary and thus to change over time, leading to deteriorating model performance. To address this problem it is necessary to develop mechanisms for detecting and handling concept drift. To this end there has been much work on identifying types of concept drift [Widmer and Kubat, 1996, Gama and Rodrigues, 2009, Zliobaite, 2010, Hoens et al., 2012, Moreno-Torres et al., 2012, Gama et al., 2014]. While many types have been identified, most definitions have been qualitative, many of the definitions have been informal and despite efforts to introduce standardization [Moreno-Torres et al., 2012], the terminology has been non-uniform and inconsistently applied.\nWe argue that quantitative measures of concept drift are essential for the development of a detailed understanding of the problems confronted by attempts to detect and address non-stationary distributions, and to assess the relative capacity of techniques that may be proposed.\nWe propose some core quantitative measures and provide a framework for developing further such measures. This framework also provides the foundation for formal definitions of qualitative categorizations of types of drift. We exploit this to develop precise formal definitions for the key types of concept drift previously mentioned in the literature and provide a comprehensive taxonomy thereof.\nOur formal definitions allow some of the controversies in the field to be resolved, such as whether the distinction between incremental and gradual drift is meaningful and if so exactly how the two categories of drift relate to one another. They also remove the ambiguity inherent in many current definitions, as illustrated by the inability of previous definitions of gradual drift to clearly distinguish which of the forms of drift illustrated in Fig. 1 are gradual and which are not. Most importantly, they provide a solid foundation for the research community to develop new technologies to detect, characterize and resolve concept drift, and design new machine learning techniques that are robust to a greater diversity of drift types.\nMuch of the work on concept drift has concentrated on classification [Wang et al., 2003a, Zhang et al., 2008, Masud et al., 2011]. However, it is also an issue in other forms of learned model that are deployed for extended periods of time, and of especial relevance to all forms of stream mining including clustering [Aggarwal et al., 2003], association discovery [Jiang and Gruenwald, 2006] and outlier detection [Subramaniam et al., 2006]. While the issues relating to drift subject, raised in Section 4.2, are specific to classification models, the rest of the paper is broadly applicable across many forms of model.\nThis paper does not directly address issues of how to detect and handle concept drift from data, for which interested readers are encouraged to read the numerous existing excellent tutorials and surveys [Bifet et al., 2011, Nguyen et al., 2014, Gama and Rodrigues, 2009, Aggarwal, 2009, Gaber et al., 2005, Krempl et al., 2014] for the current state of the art and the open challenges. We leave it to future research to apply the new conceptual tools that we have developed to these important problems."
    }, {
      "heading" : "2 Initial Definitions",
      "text" : "Before we can discuss our new quantitative measures and formal definitions for different types of drift, we must define the terms and concepts we use to create them. We couch our analysis in the context of data streams, but note that the fundamental issues and techniques are applicable to any context in which a model may be learned from historical data and applied in future contexts.\nWe first discuss data streams and their analysis. We then present our definition of a concept and the common functions we have used to demonstrate the characterization differences between concepts.\n2.1 Data Streams\nWe define a data stream as a data set in which the data elements have time stamps. In a standard application, a system only has access to data with time\nstamps prior to a specific point of time, but the models to be developed must be applied to data elements with subsequent time stamps.\nThe process that generates the stream can be considered to be a random variable X from which the objects o ∈ dom(X ) are drawn at random, where dom(·) denotes the domain of a random variable. For classification learning, we need to distinguish a class variable or label, y ∈ dom(Y ), where Y denotes a random variable over class labels, and the covariates x ∈ dom(X), where X denotes a random variable over vectors of attribute values. In this case, X represents the joint distribution XY and o represents a pair 〈x, y〉. We provide a summary of the key symbols used in this paper in Table 1.\nA learning algorithm analyses the training data to create a model for future test data.\nIn the context of classification learning, we use P (Y ) to denote the prior probability distribution over the class labels, P (X) to denote the prior probability distribution over covariates, P (X,Y ) to denote the joint probability distribution over objects and class labels, P (Y | X) to denote the likelihood distribution over class labels given objects and P (X | Y ) to denote the posterior probability distribution over covariates given class labels.\nIn order to reference the probability distribution at a particular time we add a time subscript, such as Pt(X ), to denote a probability distribution at time t.\nWe allow for the possibility of continuous time, as it is more general. However, our definitions do not require modification if time is restricted to discrete units.\n2.2 Concepts and concept drift\nA formal definition of concept is a prerequisite for formal characterizations of concept drift.\nThe classical definition of a concept is by extension—a concept is a set of objects [Michalski, 1983, Angluin, 1988]. Two variants of a definition by extension are possible, by type or token [Zalta, 2009]. A definition by type defines a concept as a set of vectors of X values such that any object with any vector of values in the set belongs to the concept, or equivalently, as a function X → Y Such a definition does not allow that different objects with identical attribute values might belong to different concepts. However, many applications of machine learning require that there be a many-to-many mapping from X values to Y values rather than the many-to-one mapping that such a definition implies. The alternative definition by extension defines a concept as a set of object instances. This is coherent, but does not seem useful in the context of stream learning, because in many applications each object instance will appear only once. Even in a situation where a patient is diagnosed on multiple occasions, in some sense the object being classified is the patient presentation, rather than the patient, as they may have a condition on one presentation and not another. As the sets of objects at different times will not overlap in such a case it is difficult to see how one might assess whether a concept has changed under such a definition.\nIt is perhaps for this reason that recent concept drift literature has instead given a probabilistic definition of concept [Kuncheva, 2004]. Hoens et al. [2012] define a concept as the prior class probabilities P (Y ) and class conditional probabilities P (X | Y ). As P (Y ) and P (X | Y ) uniquely determines the joint distribution P (X,Y ) and vice versa, this is equivalent to defining a concept as the joint distribution P (X,Y ), as proposed by Gama et al. [2014]. For this reason we adopt Gama et. al.’s (2014) definition for stream classification.\nConcept = P (X,Y ). (1)\nBeyond classification learning (i.e. in the unsupervised case, where there is no special class attribute) this is simply:\nConcept = P (X ). (2)\nIn the context of a data stream, we need to recognize that concepts may change over time. To this end we define the concept at a particular time t as\nPt(X ). (3)\nConcept drift occurs between times t and u when the distributions change,\nPt(X ) 6= Pu(X ). (4)\nConcept drift is the stream learning counterpart of dataset shift from batch learning [Quionero-Candela et al., 2009, Moreno-Torres et al., 2012]."
    }, {
      "heading" : "3 Quantitative measures of drift",
      "text" : "There has been little prior work on quantifying concept drift. Bartlett et al. [2000] define a measure they call drift rate. However, they use a limited definition of a concept as a function f : X → Y . They define the drift rate as P (ft 6= ft+1). Minku and Yao [2009] provide a similar measure that they call severity, the primary difference being that they model drift as occurring between periods of concept stability and define the severity as the proportion of the instance space for which the class labels change between successive stable concepts. Kosina et al. [2010] investigate the use of these measures for detecting drift. These definitions are limited in assuming that there is a many to one mapping from X to Y values. The earlier of these definitions is further limited in assuming that time is discrete, and appears to assume that Pt(X) = Pt+1(X), as it is otherwise unclear over which of these distributions the probability of the inequality is defined.\nWe here provide quantitative measures of concept drift that allow that concepts may be probabilistic relationships between X and Y values.\nQuantifying the degree of difference between two points of time is a key characterization of any concept drift. We call this drift magnitude. However, the appropriate function for measuring drift magnitude may change from domain to domain. Rather than specifying which measure of distance between distributions should be used, our definitions refer to an unspecified distribution distance function:\nD(t, t+m). (5)\nThis function returns a non-negative value indicating the magnitude of the difference in the concepts at times t and t+m. Note that while we only use the times as parameters to this function, it is the concepts at those times between which the distance is judged.\nAt this dawn of the exploration and analysis of quantitative characterization of concept drift, it is not clear what properties are desirable of a measure of distance between concepts. Examples of distance functions that might be used include Kullback-Leibler Divergence [Kullback and Leibler, 1951] and Hellinger Distance [Hoens et al., 2011].\nIt may be desirable to use a metric as\n– it is hard to understand what sense might be made of negative distances; – it seems credible that the distance between concept A and B should be the\nsame as the distance between B and A; and – the triangle inequality seems desirable if one is to consider the evolution of\nconcept drift over a number of concepts. It seems implausible that the distance from concept A to concept B should exceed the sum of the distances from A to an intermediate concept C and from C to B.\nFor this reason, in this paper we use Hellinger Distance in our case study. In the context of classification, it will also be relevant to use all of measures of distance between the joint distributions Pt(X,Y ) and Pu(X,Y ); the X distributions, Pt(X) and Pu(X); the class distributions Pt(Y ) and Pu(Y );\nthe posterior distributions, Pt(Y | X) and Pu(Y | X); and the likelihood distributions, Pt(X | Y ) and Pu(X | Y ).\nGiven a measure of drift distance it is straightforward to define a set of useful quantitative measures of concept drift.\nThe first of these is the magnitude of a drift, which is simply the distance between the concepts at the start and end of the period of drift. The magnitude of drift between times t and u is\nMagnitudet,u = D(t, u). (6)\nThe magnitude will greatly impact the manner in which a learner should respond to the drift.\nAnother critical measure of drift is drift duration, the elapsed time over which a period of drift occurs. The duration of a drift starting at time t and ending at time u is\nDurationt,u = u− t. (7)\nAnother aspect is the length of the path that the drift traverses during a period of drift. Path length is defined as the cumulative deviation observed during the period of drift. Note that this quantity is bounded below by the drift magnitude over the period (assuming D is a metric), with the latter being the path length observed if the drift observed was monotone (see the upper left plot of Figure 1). The path length of a drift between times t and u is\nPathLent,u = lim n→∞ n−1∑ k=0 D ( t+ k n (u− t), t+ k+1 n (u− t) ) . (8)\nThe path length provides another means of quantifying differences between drifts. For example, the gradual and incremental drifts depicted in the upper left and upper center plots of Figure 1 both have the same magnitude, but the latter has greater path length.\nA further important quantitative measure is drift rate, which quantifies how fast the distribution is changing at time t.\nRatet = lim n→∞\nnD(t−0.5/n, t+0.5/n). (9)\nThe average drift rate between times t and u is thus\nPathLent,u/(u− t). (10)\nIn the context of classification, for different purposes it may be useful to apply these measures with respect to any of the joint (P (XY )), P (X), P (Y ), posterior (P (Y | X)) or likelihood (P (X | Y )) distributions."
    }, {
      "heading" : "4 Qualitative characterization of drift types",
      "text" : "There is a substantial literature discussing types of concept drift, with terms such as abrupt drift given informal definitions.\nOur formal analysis of these definitions leads to the conclusion that they often make an implicit assumption that drift occurs over discrete periods of time that are bounded before and after by periods without drift. The concept of abrupt drift [Tsymbal, 2004, Hoens et al., 2012, Zliobaite, 2010, Bose et al., 2011, Huang et al., 2013, Minku et al., 2010, Dongre and Malik, 2014, Brzeziński, 2010, Brzezinski and Stefanowski, 2014a] illustrates this implicit assumption. Abrupt drift seems to have been intended to mean a change in distributions that occurs instantaneously or near instantaneously. Although we are the first to introduce the notion of drift magnitude, we assume that the notion of abrupt drift of small magnitude is coherent. If this is the case, and it is allowed that abrupt drift may be immediately preceded and followed by periods of drift, then it is difficult to see how it can be possible to sensibly distinguish between periods of repeated abrupt drift and other extended periods of drift.\n4.1 Functions describing points in time in the stream\nTo aid the creation of formal definitions of the standard qualitative characterizations of concept drift, we provide a formal model of this notion that a stream can be considered as being composed of a number of periods of time during which there are stable concepts, interspersed by periods of instability and concept change. We define a period of concept stability as any interval [t, t+m] such that m ≥ φ and ∀v∈(0,m]D(t, t+m) = 0, where φ is the minimum time period over which a concept must remain invariant in order to be assessed stable. We leave φ unspecified, as appropriate values may differ from domain to domain.\nThe function Sa returns the starting time and the function Ea returns the ending time of the ath stable concept in a stream.\nSa = { min{t | ∀m∈(0,φ]D(t, t+m) = 0} | a = 1 min{t | t > Ea−1 ∧ ∀m∈(0,φ]D(t, t+m) = 0} | a > 1\n(11)\nEa = max{t | ∀m∈(0,t−Sa]D(Sa, Sa+m) = 0}. (12)\nIn this section we provide a taxonomy of categories of concept drift. For each category defined we provide a formal definition. The taxonomy is summarized in Fig. 2.\n4.2 Drift Subject\nIn the context of classification learning, Kelly et al. [1999] observe that any of the following aspects of a joint distribution might change over time, P (Y ),\nP (Y | X) or P (X | Y ). To this one can also add P (X) [Tsymbal, 2004]. It should be noted that such changes are inter-related. For example, P (Y ) cannot change without either P (Y | X) or P (X) changing. It is also worth noting that a change over time in any of these aspects of a distribution requires a change in P (X,Y ), and hence all are captured by our definition of concept drift (4).\nKelly et al. [1999] suggest that in the context of classification learning P (Y | X) is the most important of these drift subjects, as such a change will necessitate an update of a model if it is to maintain accuracy. Tsymbal [2004] argue that changes in P (X) are also important, as an increase in the frequency of specific types of cases may increase the importance of accuracy in classifying those cases."
    }, {
      "heading" : "4.2.1 Class drift",
      "text" : "Class drift, often called real concept drift or prior probability shift, occurs when the posterior class probabilities P (Y | X) change over time [Tsymbal, 2004, Hoens et al., 2012, Moreno-Torres et al., 2012, Gama et al., 2014]. For example, tax law may change over time and hence the set of tax-payer attributes that are associated with the class compliant will change.\nFormally, class drift occurs between times t and u whenever\nPt(Y | X) 6= Pu(Y | X). (13)\nMoreno-Torres et al. [2012] add two further constraints to their definition of what they call prior probability shift,\n1. that it only occurs when the covariates (X variables) are causally determined by the class, and 2. that it only occurs when Pt(X | Y ) = Pu(X | Y ).\nHowever, the value of the first constraint is questionable, as it is likely that in many real world learning tasks some X variables have casual influence on the class, others are causally influenced by it, and still others simply share common causes. Further, for many learning systems, the direction of the causal relationships are not relevant, all that is utilized is the correlation between the covariates and the class.\nThe second constraint also seems needlessly strong. To illustrate this take the following simple example. Suppose:\n– the covariates are types of product, with values a or b; – the probability of each product remains 0.5 throughout; – the class is whether the product has a defect (Y=d) or not; – initially, at time t, Pt(Y=d | X=a) = Pt(Y=d | X=b) = 0.1; – subsequent, at time u, product a is improved and the probability of a defect\nis halved, Pu(Y=d | X=a) = 0.05, while Pu(Y=d | X=b) = 0.1 remains unchanged.\nIn this case Pt(X=a | Y=d) = 0.5 6= Pu(X=a | Y=d) = 0.3̇. Nonetheless, this seems like a straightforward example of class drift.\nAs an alternative to the second constraint, we propose the term pure class drift to capture situations where it is only the posterior probability that is changing, defined as:\nPt(Y | X) 6= Pu(Y | X) ∧ Pt(X) = Pu(X). (14)\nClass drift can be further divided into two sub-types that depend on the scope of the drift. Drift scope, also referred to as drift severity [Minku et al., 2010], refers to the proportion of the domain of X for which P (Y | X) changes,\n{x ∈ Dom(X) | ∃y Pt(Y=y | X=x) 6= Pu(Y=y | X=x)}. (15)\nDrift scope impacts the ease of detecting changes in the stream and affects how much of a model needs to be updated.\nSubconcept drift, also referred to as intersected drift [Minku et al., 2010], is where the drift scope is limited to a subspace of dom(X). For example, a data stream that deals with financial records may have a class called ‘fraud’, among others. If a new form of fraud is developed, the conditional probabilities of the fraud class occurring will change, but only for those contexts that relate to the new form of fraud. Whilst this is happening, cases that involve other forms of fraud could remain the same, and may continue in the same way as before.\nSubconcept drift can be defined as:\nPt(Y | X) 6= Pu(Y | X) ∧ ∃x∈Dom(X) ∀y∈Dom(Y ) Pt(Y=y | X=x) = Pu(Y=y | X=x). (16)\nFull-concept drift, also referred to as severe drift [Minku et al., 2010], involves the posterior class distribution changing for all types of object.\n∀x∈Dom(X) ∃y∈Dom (Y )Pt(Y=y | X=x) 6= Pu(Y=y | X=x). (17)"
    }, {
      "heading" : "4.2.2 Covariate Drift",
      "text" : "Covariate drift, or virtual concept drift as it is commonly called in the literature, occurs when the distribution of non-class attributes, P (X), changes over time [Tsymbal, 2004, Cieslak and Chawla, 2009, Hoens et al., 2012, MorenoTorres et al., 2012, Gama et al., 2014]. Take, for example, a business that uses socio-economic factors to make predictions about customers. Over time the demographics of the customer base may change, leading to a change in the probability of each demographic factor.\nFormally, covariate drift occurs between times t and u whenever\nPt(X) 6= Pu(X). (18)\nMoreno-Torres et al. [2012] argue that two further constraints should be applied to the definition of covariate drift,\n1. that it only occurs when the class label is causally determined by the values of the covariates (X variables), and\n2. that it only occurs when Pt(Y | X) = Pu(Y | X). However, as argued above, the value of the first constraint is questionable, as it is likely that in many real world learning tasks the causal relationships are mixed and many learners utilize only the correlations between the covariates and the class.\nShould it be useful to distinguish situations in which the second constraint is satisfied, we propose the term pure covariate drift, defined as:\nPt(X) 6= Pu(X) ∧ Pt(Y | X) = Pu(Y | X). (19)\nThis identifies a situation where the X distribution changes, but the posterior class distribution remains unaffected.\nIt seems desirable to retain the more general definitions of class and covariate drift (Eqs. 13 and 18) that we propose in addition to the pure forms, as it seems to be both coherent and useful to be able to make a statement that a case of drift includes both class and covariate drift."
    }, {
      "heading" : "4.2.3 Novel Class Appearance",
      "text" : "Novel class appearance is a special case of concept drift in which a new class comes into existence [Masud et al., 2011]. We treat this as a situation where Pt(Y=y) = 0 for the new class y at time t and Pu(Y=y) > 0 at subsequent time u. Take, for example, a business that predicts which option a user will select on a web page. If a new option is added to the web page then a new class is introduced.\nWe can define minor drift between successive stable concepts as\nD(Ea, Sa+1) < γ (20)\nand major drift as D(Ea, Sa+1) ≥ γ. (21)\nTo give an example of how drift magnitude will affect how the drift should be handled, if there is abrupt minor drift then it is likely to be appropriate to retain a model that is accurate for concept a and to just refine it as evidence is gathered about concept a+1. In contrast, if there is abrupt major drift then it might be best to simply abandon the previous model and start afresh with the evidence about the nature of the new concept as it becomes available [Nguyen et al., 2012].\n4.3 Drift Frequency\nDrift frequency, also referred to as drift rate, refers to how often concept drifts occur over a defined period of time [Kuh et al., 1991, Widmer and Kubat, 1996]. A high frequency indicates that new concept drifts start within a short amount of time from each other, whereas a low frequency indicates that there are long intervals between drifts.\nWe define drift frequency F[t,u] relative to a time interval [t, u]:\nF[t,u] = |{w | t ≤ Sw ≤ u}|. (22)\nFor an example of drift frequency comparison, consider two people, Alice and Bob. They are repeating the same set of exercises with rests between each set. Alice is fitter than Bob. As such, Alice can complete the set quicker than Bob, and Bob needs longer rest than Alice. If the transition of their vital signs between resting and exercising and vice versa were compared, the frequency of Alice’s transitions would be higher than Bob’s.\n4.4 Drift Duration\nThe literature identifies several distinct categories of drift duration. [Tsymbal, 2004, Hoens et al., 2012, Zliobaite, 2010, Bose et al., 2011, Huang et al., 2013, Minku et al., 2010, Dongre and Malik, 2014, Brzeziński, 2010].\nAbrupt drift, or sudden drift occurs when a stream with concept a suddenly changes to concept a+1 [Tsymbal, 2004, Hoens et al., 2012, Zliobaite, 2010, Bose et al., 2011, Huang et al., 2013, Minku et al., 2010, Dongre and Malik, 2014, Brzeziński, 2010, Brzezinski and Stefanowski, 2014a]. A real world example of abrupt drift could be a market crash. In a stock market stream, almost instantly, stock values will change and follow a pattern different to previously.\nGiven that δ is some natural number > 0 that defines the maximum duration over which abrupt drift can occur, abrupt drift between concepts a and a+ 1 can be defined as occurring when:\nSa+1 − Ea ≤ δ. (23)\nThe value of the constant δ will depend on the context of the data stream, and may be different for different streams.\nFor completeness we also define the alternative to abrupt drift, extended drift, which occurs when\nSa+1 − Ea > δ. (24)\nA real world example of extended drift could be a resession. Unlike a market crash, stock values at the beginning of a resession will slowly change over an extended period of time. Eventually, the changes in all of the stock values will follow a different pattern to before the recession started.\n4.5 Blip Drift\nBlip drift is a special case of abrupt drift coupled with very short concept duration. In blip drift, the blip concept replaces the dominant concept for a very short period of time [Dongre and Malik, 2014].\nIn the literature, there has been some debate as to whether blip drift should be adjusted for during training, or whether it should even be considered a type of drift [Brzeziński, 2010]. As such, a number of systems have been designed to ignore blip drift. Those that do detect the change in concept and adjust their models when a blip occurs may lose accuracy if they are unable to detect that the change is a blip and restore the old model when the blip concept has gone.\nIt is important to note that blip drift is different to what is defined as an outlier. An outlier is a single example from a stream which is anomalous in the context of the concept at the time the example occurs. A blip is a short sequence of examples that are part of a single concept. As such, outliers fall under the problem of anomaly detection, which is an entirely different topic.\nA real world example of blip drift is the Cyber Monday sale. Cyber Monday is the first Monday after US Thanksgiving, where online stores persuade customers to shop online and offer significant discounts on their merchandise for that day only. If an online store had a stream that reported sales statistics at regular intervals, all samples from Cyber Monday would be significantly different to most other times in the year.\nGiven that β is the maximum duration for a blip drift to occur, concept a can be defined as blip drift if\nSa+1 − Ea ≤ β. (25)\nThe value of β will depend on the context of the data stream, and may be different for every stream.\n4.6 Concept Transition\nThere has been a wide diversity of terms and descriptions relating to the manner in which a transition between two concepts unfolds [Brzezinski and Stefanowski, 2014a, Tsymbal, 2004, Zliobaite, 2010, Bose et al., 2011, Huang\net al., 2013, Minku et al., 2010, Dongre and Malik, 2014, Hoens et al., 2012, Brzeziński, 2010]. This is another area in which the process of formalization has revealed a range of inter-related issues.\nThe first issue is whether the drift is a gradual progression of small changes or involves major abrupt changes. Gradual changes may or may not be a steady progression from one concept towards another. Fig. 1 illustrates some examples of how such changes might vary from a direct progression from one stable concept to another. Given that µ is a maximum allowed difference between concepts over time period ν during a period of drift for the drift to be considered gradual, we define gradual drift between concepts a and a+1 as:\n∀t∈[Ea,Sa+1−ν]D(t, t+ ν) ≤ µ. (26)\nA further issue is whether the change is a steady progression from concept a toward concept a+1 such that at each time step the distance from concept a increases and the distance to concept a+1 decreases. We call this incremental drift and define it as follows:\n∀t∈(Ea, Sa+1) ∀u∈(t, Sa+1)D(Ea, t) ≤ D(Ea, u)∧ D(t, Sa+1) ≥ D(u, Sa+1). (27)\nAn example of incremental drift is where credit card fraud patterns change over time. Consider the introduction of RFID chips in credit cards. The new technology changes the types of fraud that can be committed. As more credit card customers get new cards with RFID chips, the new types of fraud become more common until everyone has new cards, where the concept drift in the transaction stream would stop.\nNot all drift is incremental. Probabilistic drift [Minku et al., 2010] occurs when there are two alternating concepts such that one initially predominates and over time the other comes to predominate [Tsymbal, 2004, Zliobaite, 2010, Bose et al., 2011, Huang et al., 2013, Minku et al., 2010, Dongre and Malik, 2014, Hoens et al., 2012]. Consider a sensor network node. Probabilistic drift would occur in a stream when a sensor network node is replaced. A node cannot be immediately swapped; the new node must be tested to ensure it is working correctly. As such, the two nodes will be turned on and off while the tests are conducted. In terms of the sensor network stream, samples from two different concepts are flowing from that node, one from the faulty node and another from the new node. The data from the new node will become more likely to occur in the stream, until only the concept from the new node is present.\nGiven that fk is a monotonically increasing function, indicating the probability of the new concept being in force, such that f0 = 0 and fSa+1−Ea = 1, probabilistic drift can be defined as:\n∀t∈[0,Sa+1−Ea] ∀o PEa+t(X=o) = (1−ft)PEa(X=o) + ftPSa+1(X=o). (28)\nDepending on the nature of f , probabilistic drift may be gradual, and if so is likely to be incremental, but is not necessarily so.\nNote that there has been some debate as to whether probabilistic and incremental drift are actually different. Huang et al. [2013] and Hoens et al. [2012] do not distinguish between the two types. Brzeziński [2010] raises the issue that some of the literature ignores this difference. Our formal definitions make it clear that they are in fact different, yet somewhat related, as expressed in Brzeziński [2010]. Incremental drift may be probabilistic, but is not necessarily so, and probabilistic drift may be incremental, but is also not necessarily so. To our knowledge we are the first to formally identify an alternative form of incremental drift to probabilistic drift.\n4.7 Drift Recurrence\nWhen drift occurs, the new concept may either be one that has not previously appeared in the data stream or may be a recurrence of a pre-existing concept. The latter is known as drift recurrence. There are a number of ways in which concepts can recur in a stream [Minku et al., 2010, Bose et al., 2011, Dongre and Malik, 2014, Brzeziński, 2010, Zliobaite, 2010, Hoens et al., 2012, Gomes et al., 2011].\nA real world example of recurring drift could be in the use of a phone app. A user using a particular app could use it in a certain way when they are at home compared to how they use it when they are at work. The recurring concepts would be the use at home and the use at work. These concepts of app use would recur whenever a user arrives at home or at work.\nRecurring drift can be defined as:\n∃a ∃b a 6= b ∧D(Sa, Sb) = 0. (29)"
    }, {
      "heading" : "4.7.1 Cyclical Drift",
      "text" : "As the name implies, Cyclical Drift is a form of recurring drift that occurs when two or more concepts recur in a specific order [Tsymbal, 2004, Hoens et al., 2012]. A good example of this is the weather patterns in a city. Assuming no climate change is present, meteorologists can expect the patterns in the weather to recur at particular times of the year when compared to previous years. The concepts could be defined as the four seasons, with incremental drift occurring between each season. This cycle in the drift would renew itself at the start/end of each year.\nGiven a stream has i concepts in a cycle, cyclical drift can be defined as:\n∀aD(Sa, Sa+i) = 0. (30)"
    }, {
      "heading" : "4.7.2 Cycle duration",
      "text" : "One issue that naturally arises in the context of recurring concept drift is the periodicity of the drift recurrence. Our formal analysis of this issue has\nrevealed that this actually encompasses multiple dimensions. For example, winter may always occur at a particular time of year, but the exact start date and duration of winter may vary from year to year. In contrast, the working day might always start and end at precisely defined times.\nIf a cycle contains i concepts, the duration of a cycle starting at concept a is\nSa+i − Sa. (31) Fixed frequency cyclical concept drift occurs when a cycle has a fixed amount of time to occur. For example, the cycle of the seasons must complete over the course of 365.24 days. Fixed frequency cyclical concept drift of duration m between i concepts can be defined as follows.\n∀aD(Sa, Sa+i) = 0 ∧ Sa+i ≤ Ea+m ∧ Ea+i ≥ Sa+m. (32)\nA number of other aspects of concept periodicity might be fixed. Fixed concept duration cyclical drift occurs when every period of stability occurs for a fixed amount of time. For example, a store might conduct periodic one-day sales. The relevant concepts might be shared between each sale period, which is always 24 hours. Fixed concept duration cyclical drift can be defined as:\n∀aD(Sa, Sa+i) = 0 ∧ Ea−Sa = Ea+i−Sa+i. (33) Fixed drift duration cyclical drift occurs when every period of drift occurs for a fixed amount of time. For example, consider an athlete repeating a set of exercises with rest breaks between each set. The transition of his vital signs between resting and exercising and vice versa will have a fixed transition time. Fixed drift duration cyclical drift can be defined as:\n∀aD(Sa, Sa+i) = 0 ∧ Sa+1−Ea = Sa+i+1−Ea+i. (34)\nFixed concept onset cyclical drift occurs when the start of a period of stability begins at the same time in every cycle. For example, a store might open at the same time every day. It will enter a state of being open but inactive and this state will last a differing period of time and drift to a fully active state in varying ways and at varying rates. Fixed concept onset cyclical drift can be defined as:\n∀a ∀bD(Sa, Sa+i) = 0 ∧ Sa+i−Sa = Sb+i−Sb. (35) Fixed drift onset cyclical drift occurs when the start of a period of drift begins at the same time in every cycle. For example, a store might close at the same time every day. At this time it will start a drift from an open and fully active state to a closed state. The nature and duration of that drift will depend on the number of customers still in the store at closing time and the types of transactions that they are seeking to compete. Fixed drift onset cyclical drift can be defined as:\n∀a ∀bD(Sa, Sa+i) = 0 ∧ Ea+i−Ea = Eb+i−Eb. (36)\nVarying frequency, concept duration, drift duration, concept onset and drift onset cyclical drift each can be defined by negation of the corresponding definitions above.\n4.8 Drift Predictability\nDrift predictability, as the name implies, describes how predictable some aspect of a drift is [Minku et al., 2010]. Any aspect of drift might be more or less predictable, from when a drift starts, to when a drift ends, to what the subject of the drift is, and so on. As this list of aspects of drift that could be predicted can be very long, we find that producing formal definitions for each type of drift predictability would be impractical. Drift predictability is important however, as it should influence the selection of stream mining algorithms; affect the performance of algorithms that seek to anticipate drift; and inform the design of stream mining algorithms that will operate in environments with predictable drift, such as cyclical drift governed by seasonality.\nOf the types of concept drift that we have defined, the only ones that are inherently predictable are fixed frequency, concept duration, drift duration, concept onset and drift onset concept drift. These are predictable because there is a constant involved in each that might be inferred. For example, drift due to time of day has a regular cycle and hence many aspects of it are relatively predictable. In contrast, the onset, duration and magnitude of drift due to a stock market crash is relatively difficult to predict."
    }, {
      "heading" : "5 Case study",
      "text" : "We have asserted that our new quantitative characterizations of concept drift are critical to deep understanding of drift, its impacts on learning systems, the capacity of drift detection mechanisms to detect drift, the capacity of drift remediation mechanisms to adjust to drift and our capacity to design effective mechanisms for detecting and responding to drift. In order to substantiate these assertions, we conduct a simple proof-of-concept pilot study, that provides significant insights that would not be possible without our quantitative measures.\nTo this end, we generated synthetic data containing an abrupt drift of a given magnitude. We conducted the experiments in the MOA [Bifet et al., 2010a] workbench. We studied the responses to this drift of the following key learners from MOA: AccuracyUpdatedEnsemble [Brzezinski and Stefanowski, 2014b], AccuracyWeightedEnsemble [Wang et al., 2003b], DriftDetectionMethodClassifier [Gama et al., 2004b], DriftDetectionMethodClassifierEDDM [Baena-Garcıa et al., 2006], HoeffdingAdaptiveTree [Bifet and Gavaldà, 2009], HoeffdingOptionTree [Pfahringer et al., 2007], HoeffdingTree [Hulten et al., 2001], LeveragingBag [Bifet et al., 2010b], Naive Bayes, OzaBag [Oza and Russell, 2001], OzaBagAdwin, OzaBoost [Oza and Russell, 2001] and OzaBoostAdwin [Oza and Russell, 2001, Babcock et al., 2002].\nWe list and motivate below the experimental setting that we chose in order to highlight the response of state-of-the-art classifiers to drift.\nModel of the distribution from which the data is drawn We generate categorical data from a Bayesian Network structure. The posterior distribution is mod-\neled by a full conditional probability table, which makes it possible to model any possible interaction between the different input variables. The structure of the network is given in Figure 3; we chose 5 parent nodes so that the posterior probability distribution is relatively difficult to learn. Each parent attribute takes 3 values and its multinomial probability is sampled following a flat Dirichlet with concentration parameter 1. For ease of interpretation we assign, at random, a single class to every combination of X values. To this end, the posterior probability P (y | x1, · · · , x5) is sampled independently for each combination x of x1, · · · , x5; we start by choosing one of the 3 possible class values vc ∼ U(1, 3) and assign P (v | x) = 1 if v = vc, otherwise 0. This allows us to be sure that the error of the Bayes optimal classifier is 0; note that this distribution favors tree classifiers, as they can build a precise model of the distribution.\nGeneration of the data We then generate a set of 100 synthetic data streams, each with 300,000 time steps (t = 1 to t = 300, 000), and with one instance arriving at each time step. The stream is generated from two concepts, with an abrupt drift solely in the posterior probability at t = 100, 000. We chose 100,000 as a value that is sufficient for all the learners to have converged to their model in the limit, e.g. for which the tree classifiers obtain an errorrate that is close to 0. We then study the behaviour of the classifiers over the following time steps t = 100, 001 to t = 300, 000.\nGenerating a drift of the posterior probability with given magnitude For each dataset that we generate, we start by generating a random prior probability following the setting described above. We then need two posterior probability distributions: one before the drift and one after. The distribution before the drift is also generated following the process described above; we detail now how to generate the posterior distribution after the drift, i.e. a posterior distribution with a given magnitude with the initial one.\nWe use the Hellinger distance [Hoens et al., 2011] as a measure of the drift magnitude in the posterior. We choose the Hellinger distance in this paper because we believe that\n1. most readers are familiar with the Euclidean distance, which is very similar to the Hellinger distance; 2. because of its nice mathematical properties including taking values in [0, 1] and being symmetric and 3. we will see below that it is simple to generate a posterior probability with given magnitude from another one.\nThe Hellinger distance for our model follows:\nH2(p′, p) = 1\nC ∑ v1 · · · ∑ v5 1√ 2 (∑ y (p′(y|v1, · · · , v5)− p(y|v1, · · · , v5)) 2 ) 1 2\n(37) where C is the number of combinations of x1, · · · , x5, i.e. 35 in our case.\nAs we want to keep the Dirach form for the posterior for each combination of the parent attributes, there are only two choices that can be made for each combination of x1, · · · , x5: either we keep P (y | x1, · · · , x5) unchanged, or we modify it by changing the class for which P (y | x1, · · · , x5) = 1. When unchanged, the partial Hellinger distance is 0 for this particular combination of values; it is 1 otherwise ( √ 2√ 2 ). We then have:\nH2(p′, p) = k\nC ⇔ k = H2(p′, p) · C (38)\nwhere k is the number of combinations of x1, · · · , x5 for which the posterior distribution is changed. For a given (desired) magnitude H2(p′, p), we thus simply modify the posterior distribution for H2(p′, p) · C combinations of x1, · · · , x5, chosen following U(1, ( C k ) ). For each of these combinations, we then choose another class value, following the process described above, but ensuring that a different class value is chosen.\n5.1 Results\nThe learning task is one that favors decision trees. It is not possible to well describe the concepts before or after drift other than by producing a map from each attribute-value combination to a class, except perhaps in a few cases where by chance multiple combinations differing only in one attribute value all map to the same class by chance. As a result of this advantage to one particular type of model we do not believe much should be concluded from the relative errors of the alternative classifiers when they have reached their asymptote at the end of the initial concept period, at t = 100, 000.\nWe do however believe that the response to the abrupt drift is revealing. There appear to be three classes of response. The first is evidenced Naive Bayes, which does not have any drift detection or remediation mechanisms, and OzaBoost. This is perhaps the type of relative response to different magnitudes of drift that one would naively expect from most systems. The greater the magnitude of drift the greater the immediate jump in error and the longer the time taken to recover the original error level. The learning curves for these algorithms are shown in Fig. 4. This and the following learning curves plot averages over each 1,000 times steps of the 0-1 loss for all of the 100 synthetic data streams — thus each point plotted is an average of 100,000 values.\nThe second class of response is shared by HoeffdingAdaptiveTree, HoeffdingOptionTree, HoeffdingTree and OzaBag. The greater the magnitude of the\ndrift the greater the immediate jump in error, but all magnitudes of drift take the same length of time to recover back to the level of error without drift. The learning curves for these algorithms are shown in Fig. 5.\nThe third class of response is shared by AccuracyUpdatedEnsemble, AccuracyWeightedEnsemble, DriftDetectionMethodClassifier, DriftDetectionMethodClassifierEDDM, LeveragingBag, OzaBagAdwin and OzaBoostAdwin. While the magnitude of the initial jump in error is ordered relative to the magnitude of the drift, rates of recovery are not. For example, for DriftDe-\ntectionMethodClassifierEDDM magnitude 1.0 drift recovers much faster than magnitudes 0.75 or 0.5 and there is some indication that magnitude 0.123 drift is the slowest to recover. The learning curves for these algorithms are shown in Fig. 6.\nThese results should only be regarded as preliminary. They only show the response of each learner in the context of one specific type of pre and post abrupt drift concept. No attempt has been made to understand why the different mechanisms respond as they do. There is clearly much work to be done to develop a comprehensive understanding of how different drift detection and remediation mechanisms perform in the context of different forms of drift.\nHowever, this simple experiment with different magnitudes of an abrupt drift and its results provide compelling evidence of the importance of quantitative characterizations of drift for understanding the relative response of different drift detection and remediation mechanisms to different forms of drift, for designing effective drift detection and remediation mechanisms, and ultimately for developing a solid theoretical understanding of learning in the context of concept drift."
    }, {
      "heading" : "6 Discussion",
      "text" : "In this section we explore some of the implications of our new conceptual analysis of types of concept drift.\nMany of the qualitative definitions rely on user defined thresholds φ, δ, β, γ, ν and µ. As a result, these definitions are inherently subjective. While this may seem a limitation of our proposal, we believe it is actually a useful contribution to make explicit which aspects of these definitions are subjective.\nOur analysis has made explicit the subjective nature of many of the core concept drift types that have been previously proposed. Rather than relying on these subjective qualitative descriptions, we suggest that it is better to use the new objective quantitative measures that we have defined. These include cycle duration and drift rate, magnitude, frequency, duration and path length.\nIt is not clear to what extent it might be feasible to use our definitions to directly quantify real-world cases of concept drift, as it will often not be feasible to accurately estimate the relevant probability distributions at each point in time. Nonetheless, they are likely to be useful in helping the design of drift detection systems [Gama et al., 2004a, Dries and Rückert, 2009, Nishida and Yamauchi, 2007, Wang et al., 2013], as they provide clear guidance about the ways in which drift may occur.\nOur definitions should play an important role in informing the design of online learning algorithms. By improving understanding of the drift mechanisms that a learner may confront, our definitions have the potential to assist the design of more robust and effective online learning systems.\nAdditionally, by providing a comprehensive taxonomy of types of drift and measures for exactly quantifying them, our conceptual analysis should assist\nthe design of more thorough experimental evaluations of the relative capacities of different learners to respond to different forms of drift. For example, synthetic data streams are frequently used to assess relative performance of different algorithms under various possible drift types [Zliobaite, 2014, Brzezinski and Stefanowski, 2014c, Shaker and Hullermeier, 2015]. Our taxonomy and definitions of drift types provide comprehensive and structured guidance for the design of synthetic data stream experiments. They make explicit the different types of drift that may affect algorithm performance.\nFurther, they should play an important role in improving the analysis of experimental performance. They provide a comprehensive set of formal definitions and the first set of quantitative measures of different types of drift. As a result, they supply a framework for more objective evaluation of stream mining algorithms and their relative capacities to respond to different drift scenarios.\nWhile only a few of the types of drift that we have defined are inherently predictable (see Section 4.8), there may be other types of factors that make some aspects of drift predictable. For example, in some applications it may be possible to detect triggers for different types of drift. Here our definitions will provide a useful framework for characterizing and exploiting the predictable elements of the drift.\nOur formal qualitative definitions of types of drift are based on the model of a stream as comprising periods of concept stability interspersed by periods of drift. This model appears to be implicit in many previous characterizations of types of concept drift. This is a questionable assumption for many streams and one which would be an interesting subject for empirical study."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We have provided the first quantitative measures for key aspects of concept drift, creating a foundation for more thorough objective characterization and analysis of concept drift and concept drift algorithms. These quantitative measures have provided a foundation for formal definitions of the many different qualitative drift types that have been previously identified in the literature. This process has clarified ambiguities and identified gaps in past definitions that we have filled by defining new terms. They have also made explicit an implicit assumption that appears to underlie previous work, that streams undergo cycles of drift interposed by periods of stability.\nWe have created a new drift type taxonomy that encompasses all of the different types of drift that have been identified. In some cases, these types have been given new names that we believe are more meaningful and less ambiguous than previous terminology. We have also provided examples of each drift type to ensure clarity of understanding as to how the drift functions.\nWe anticipate that resolving the ambiguities and imprecision of past definitions of types of concept drift will help\n– standardize the terminology used in the literature;\n– provide a rigorous theoretical basis for designing new mechanisms to detect, characterize and resolve concept drift; – understand what forms of drift are best handled by each different mechanism for handling drift; – create greater diversity in the types of drift that are created by synthetic drift data generators [Narasimhamurthy and Kuncheva, 2007] for stream mining evaluation; – develop more comprehensive and objective approaches for evaluating stream mining algorithms; and – design new machine learning techniques that are robust to a greater diversity of drift types."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We are grateful to David Albrecht, Mark Carman and the anonymous reviewers for valuable comments and suggestions.\nCompliance with Ethical Standards\nThis research has been supported by the Australian Research Council under grant DP140100087 and Asian Office of Aerospace Research and Development, Air Force Office of Scientific Research under contract FA2386-15-1-4007.\nThe authors declare that they have no conflict of interest."
    } ],
    "references" : [ {
      "title" : "Data Streams: An Overview and Scientific Applications, pages 377–397",
      "author" : [ "Charu C. Aggarwal" ],
      "venue" : "ISBN 978-3-642-02788-8",
      "citeRegEx" : "Aggarwal.,? \\Q2009\\E",
      "shortCiteRegEx" : "Aggarwal.",
      "year" : 2009
    }, {
      "title" : "A framework for clustering evolving data streams",
      "author" : [ "Charu C Aggarwal", "Jiawei Han", "Jianyong Wang", "Philip S Yu" ],
      "venue" : "In Proceedings of the 29th International Conference on Very Large Data Bases-Volume",
      "citeRegEx" : "Aggarwal et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Aggarwal et al\\.",
      "year" : 2003
    }, {
      "title" : "Queries and concept learning",
      "author" : [ "Dana Angluin" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Angluin.,? \\Q1988\\E",
      "shortCiteRegEx" : "Angluin.",
      "year" : 1988
    }, {
      "title" : "Sampling from a moving window over streaming data",
      "author" : [ "Brian Babcock", "Mayur Datar", "Rajeev Motwani" ],
      "venue" : "In Proceedings of the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms,",
      "citeRegEx" : "Babcock et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Babcock et al\\.",
      "year" : 2002
    }, {
      "title" : "Early drift detection method",
      "author" : [ "Manuel Baena-Garcıa", "José del Campo-Ávila", "Raúl Fidalgo", "Albert Bifet", "R Gavalda", "R Morales-Bueno" ],
      "venue" : "In Fourth International Workshop on Knowledge Discovery from Data Streams,",
      "citeRegEx" : "Baena.Garcıa et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Baena.Garcıa et al\\.",
      "year" : 2006
    }, {
      "title" : "Learning changing concepts by exploiting the structure of change",
      "author" : [ "Peter L Bartlett", "Shai Ben-David", "Sanjeev R Kulkarni" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Bartlett et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Bartlett et al\\.",
      "year" : 2000
    }, {
      "title" : "Handling concept drift: Importance, challenges and solutions",
      "author" : [ "A. Bifet", "J. Gama", "M. Pechenizkiy", "I. Zliobaite" ],
      "venue" : null,
      "citeRegEx" : "Bifet et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bifet et al\\.",
      "year" : 2011
    }, {
      "title" : "Adaptive learning from evolving data streams",
      "author" : [ "Albert Bifet", "Ricard Gavaldà" ],
      "venue" : "In Advances in Intelligent Data Analysis VIII,",
      "citeRegEx" : "Bifet and Gavaldà.,? \\Q2009\\E",
      "shortCiteRegEx" : "Bifet and Gavaldà.",
      "year" : 2009
    }, {
      "title" : "Moa: Massive online analysis",
      "author" : [ "Albert Bifet", "Geoff Holmes", "Richard Kirkby", "Bernhard Pfahringer" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Bifet et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Bifet et al\\.",
      "year" : 2010
    }, {
      "title" : "Leveraging bagging for evolving data streams. In Machine Learning and Knowledge Discovery in Databases, pages 135–150",
      "author" : [ "Albert Bifet", "Geoff Holmes", "Bernhard Pfahringer" ],
      "venue" : null,
      "citeRegEx" : "Bifet et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Bifet et al\\.",
      "year" : 2010
    }, {
      "title" : "Handling concept drift in process mining",
      "author" : [ "R.P. Jagadeesh Chandra Bose", "Wil M.P. van der Aalst", "Indre Zliobaite", "Mykola Pechenizkiy" ],
      "venue" : "Advanced Information Systems Engineering,",
      "citeRegEx" : "Bose et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bose et al\\.",
      "year" : 2011
    }, {
      "title" : "Reacting to different types of concept drift: The accuracy updated ensemble algorithm",
      "author" : [ "D. Brzezinski", "J. Stefanowski" ],
      "venue" : "Neural Networks and Learning Systems, IEEE Transactions on,",
      "citeRegEx" : "Brzezinski and Stefanowski.,? \\Q2013\\E",
      "shortCiteRegEx" : "Brzezinski and Stefanowski.",
      "year" : 2013
    }, {
      "title" : "Mining data streams with concept drift",
      "author" : [ "Dariusz Brzeziński" ],
      "venue" : "Master’s thesis, Poznan University of Technology,",
      "citeRegEx" : "Brzeziński.,? \\Q2010\\E",
      "shortCiteRegEx" : "Brzeziński.",
      "year" : 2010
    }, {
      "title" : "Reacting to different types of concept drift: The accuracy updated ensemble algorithm",
      "author" : [ "Dariusz Brzezinski", "Jerzy Stefanowski" ],
      "venue" : "Neural Networks and Learning Systems, IEEE Transactions on,",
      "citeRegEx" : "Brzezinski and Stefanowski.,? \\Q2014\\E",
      "shortCiteRegEx" : "Brzezinski and Stefanowski.",
      "year" : 2014
    }, {
      "title" : "Prequential AUC for classifier evaluation and drift detection in evolving data streams",
      "author" : [ "Dariusz Brzezinski", "Jerzy Stefanowski" ],
      "venue" : "In Proceedings of the 3rd International Workshop on New Frontiers in Mining Complex Patterns, Nancy, France,",
      "citeRegEx" : "Brzezinski and Stefanowski.,? \\Q2014\\E",
      "shortCiteRegEx" : "Brzezinski and Stefanowski.",
      "year" : 2014
    }, {
      "title" : "A framework for monitoring classifiers performance: when and why failure",
      "author" : [ "David A Cieslak", "Nitesh V Chawla" ],
      "venue" : "occurs? Knowledge and Information Systems,",
      "citeRegEx" : "Cieslak and Chawla.,? \\Q2009\\E",
      "shortCiteRegEx" : "Cieslak and Chawla.",
      "year" : 2009
    }, {
      "title" : "A review on real time data stream classification and adapting to various concept drift scenarios",
      "author" : [ "P.B. Dongre", "L.G. Malik" ],
      "venue" : "In Advance Computing Conference (IACC),",
      "citeRegEx" : "Dongre and Malik.,? \\Q2014\\E",
      "shortCiteRegEx" : "Dongre and Malik.",
      "year" : 2014
    }, {
      "title" : "Adaptive concept drift detection. Statistical Analysis and Data Mining: The ASA Data",
      "author" : [ "Anton Dries", "Ulrich Rückert" ],
      "venue" : "Science Journal,",
      "citeRegEx" : "Dries and Rückert.,? \\Q2009\\E",
      "shortCiteRegEx" : "Dries and Rückert.",
      "year" : 2009
    }, {
      "title" : "Mining data streams: a review",
      "author" : [ "Mohamed Medhat Gaber", "Arkady Zaslavsky", "Shonali Krishnaswamy" ],
      "venue" : "ACM Sigmod Record,",
      "citeRegEx" : "Gaber et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Gaber et al\\.",
      "year" : 2005
    }, {
      "title" : "Heuristic updatable",
      "author" : [ "T. Ryan Hoens", "Nitesh V. Chawla", "Robi Polikar" ],
      "venue" : null,
      "citeRegEx" : "Hoens et al\\.,? \\Q1982\\E",
      "shortCiteRegEx" : "Hoens et al\\.",
      "year" : 1982
    }, {
      "title" : "Research issues in data stream association rule",
      "author" : [ "ACM", "2001. Nan Jiang", "Le Gruenwald" ],
      "venue" : null,
      "citeRegEx" : "106",
      "shortCiteRegEx" : "106",
      "year" : 2001
    }, {
      "title" : "Drift severity metric",
      "author" : [ "Petr Kosina", "João Gama", "Raquel Sebastião" ],
      "venue" : "In European Conference on Artificial Intelligence,",
      "citeRegEx" : "Kosina et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Kosina et al\\.",
      "year" : 2010
    }, {
      "title" : "Open challenges for data stream mining research",
      "author" : [ "Georg Krempl", "Indre Zliobaite", "Dariusz Brzezinski", "Eyke Hullermeier", "Mark Last", "Vincent Lemaire", "Tino Noack", "Ammar Shaker", "Sonja Sievi", "Myra Spiliopoulou", "Jerzy Stefanowski" ],
      "venue" : "In ACM SIGKDD Explorations Newsletter,",
      "citeRegEx" : "Krempl et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Krempl et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning time-varying concepts",
      "author" : [ "Anthony Kuh", "Thomas Petsche", "Ronald L Rivest" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Kuh et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Kuh et al\\.",
      "year" : 1991
    }, {
      "title" : "On information and sufficiency",
      "author" : [ "Solomon Kullback", "Richard A Leibler" ],
      "venue" : "The Annals of Mathematical Statistics,",
      "citeRegEx" : "Kullback and Leibler.,? \\Q1951\\E",
      "shortCiteRegEx" : "Kullback and Leibler.",
      "year" : 1951
    }, {
      "title" : "Classifier ensembles for changing environments",
      "author" : [ "Ludmila I Kuncheva" ],
      "venue" : "In Multiple Classifier Systems,",
      "citeRegEx" : "Kuncheva.,? \\Q2004\\E",
      "shortCiteRegEx" : "Kuncheva.",
      "year" : 2004
    }, {
      "title" : "Classification and novel class detection in concept-drifting data streams under time constraints",
      "author" : [ "Mohammad M Masud", "Jing Gao", "Latifur Khan", "Jiawei Han", "Bhavani Thuraisingham" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering,",
      "citeRegEx" : "Masud et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Masud et al\\.",
      "year" : 2011
    }, {
      "title" : "A theory and methodology of inductive learning",
      "author" : [ "Ryszard S Michalski" ],
      "venue" : null,
      "citeRegEx" : "Michalski.,? \\Q1983\\E",
      "shortCiteRegEx" : "Michalski.",
      "year" : 1983
    }, {
      "title" : "Using diversity to handle concept drift in on-line learning",
      "author" : [ "Fernanda L Minku", "Xin Yao" ],
      "venue" : "In International Joint Conference on Neural Networks,",
      "citeRegEx" : "Minku and Yao.,? \\Q2009\\E",
      "shortCiteRegEx" : "Minku and Yao.",
      "year" : 2009
    }, {
      "title" : "The impact of diversity on online ensemble learning in the presence of concept drift",
      "author" : [ "L.L. Minku", "A.P. White", "Xin Yao" ],
      "venue" : "Knowledge and Data Engineering, IEEE Transactions on,",
      "citeRegEx" : "Minku et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Minku et al\\.",
      "year" : 2010
    }, {
      "title" : "A unifying view on dataset shift in classification",
      "author" : [ "Jose G Moreno-Torres", "Troy Raeder", "RocO Alaiz-RodrGuez", "Nitesh V Chawla", "Francisco Herrera" ],
      "venue" : "Pattern Recognition,",
      "citeRegEx" : "Moreno.Torres et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Moreno.Torres et al\\.",
      "year" : 2012
    }, {
      "title" : "A framework for generating data to simulate changing environments",
      "author" : [ "Anand Narasimhamurthy", "Ludmila I Kuncheva" ],
      "venue" : "In Proceedings of the 25th IASTED International Multi-Conference: Artificial Intelligence and Applications,",
      "citeRegEx" : "Narasimhamurthy and Kuncheva.,? \\Q2007\\E",
      "shortCiteRegEx" : "Narasimhamurthy and Kuncheva.",
      "year" : 2007
    }, {
      "title" : "Heterogeneous ensemble for feature drifts in data streams",
      "author" : [ "Hai-Long Nguyen", "Yew-Kwong Woon", "Wee-Keong Ng", "Li Wan" ],
      "venue" : "In Advances in Knowledge Discovery and Data Mining,",
      "citeRegEx" : "Nguyen et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2012
    }, {
      "title" : "A survey on data stream clustering and classification",
      "author" : [ "Hai-Long Nguyen", "Yew-Kwong Woon", "Wee-Keong Ng" ],
      "venue" : "Knowledge and Information Systems,",
      "citeRegEx" : "Nguyen et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2014
    }, {
      "title" : "Detecting concept drift using statistical testing",
      "author" : [ "Kyosuke Nishida", "Koichiro Yamauchi" ],
      "venue" : "In Discovery Science,",
      "citeRegEx" : "Nishida and Yamauchi.,? \\Q2007\\E",
      "shortCiteRegEx" : "Nishida and Yamauchi.",
      "year" : 2007
    }, {
      "title" : "Online bagging and boosting",
      "author" : [ "Nikunj C. Oza", "Stuart Russell" ],
      "venue" : "In Artificial Intelligence and Statistics",
      "citeRegEx" : "Oza and Russell.,? \\Q2001\\E",
      "shortCiteRegEx" : "Oza and Russell.",
      "year" : 2001
    }, {
      "title" : "New options for hoeffding trees",
      "author" : [ "Bernhard Pfahringer", "Geoffrey Holmes", "Richard Kirkby" ],
      "venue" : "In AI 2007: Advances in Artificial Intelligence,",
      "citeRegEx" : "Pfahringer et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Pfahringer et al\\.",
      "year" : 2007
    }, {
      "title" : "Dataset Shift in Machine Learning",
      "author" : [ "Joaquin Quionero-Candela", "Masashi Sugiyama", "Anton Schwaighofer", "Neil D Lawrence" ],
      "venue" : null,
      "citeRegEx" : "Quionero.Candela et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Quionero.Candela et al\\.",
      "year" : 2009
    }, {
      "title" : "Recovery analysis for adaptive learning from non-stationary data streams",
      "author" : [ "Ammar Shaker", "Eyke Hullermeier" ],
      "venue" : "In Neurocomputing,",
      "citeRegEx" : "Shaker and Hullermeier.,? \\Q2015\\E",
      "shortCiteRegEx" : "Shaker and Hullermeier.",
      "year" : 2015
    }, {
      "title" : "Online outlier detection in sensor data using non-parametric models",
      "author" : [ "Sharmila Subramaniam", "Themis Palpanas", "Dimitris Papadopoulos", "Vana Kalogeraki", "Dimitrios Gunopulos" ],
      "venue" : "In Proceedings of the 32nd International Conference on Very Large Data Bases,",
      "citeRegEx" : "Subramaniam et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Subramaniam et al\\.",
      "year" : 2006
    }, {
      "title" : "The problem of concept drift: definitions and related work",
      "author" : [ "Alexey Tsymbal" ],
      "venue" : "Technical Report TCD-CS-2004-15,",
      "citeRegEx" : "Tsymbal.,? \\Q2004\\E",
      "shortCiteRegEx" : "Tsymbal.",
      "year" : 2004
    }, {
      "title" : "Mining concept-drifting data streams using ensemble classifiers",
      "author" : [ "Haixun Wang", "Wei Fan", "Philip S. Yu", "Jiawei Han" ],
      "venue" : "In Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "Wang et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2003
    }, {
      "title" : "Mining concept-drifting data streams using ensemble classifiers",
      "author" : [ "Haixun Wang", "Wei Fan", "Philip S Yu", "Jiawei Han" ],
      "venue" : "In Proceedings of the Ninth ACM SIGKDD International conference on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "Wang et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2003
    }, {
      "title" : "Concept drift detection for online class imbalance learning",
      "author" : [ "Shuo Wang", "Leandro L Minku", "Davide Ghezzi", "Daniele Caltabiano", "Peter Tino", "Xin Yao" ],
      "venue" : "In The 2013 International Joint Conference on Neural Network,",
      "citeRegEx" : "Wang et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning in the presence of concept drift and hidden contexts",
      "author" : [ "Gerhard Widmer", "Miroslav Kubat" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Widmer and Kubat.,? \\Q1996\\E",
      "shortCiteRegEx" : "Widmer and Kubat.",
      "year" : 1996
    }, {
      "title" : "Categorizing and mining concept drifting data streams",
      "author" : [ "Peng Zhang", "Xingquan Zhu", "Yong Shi" ],
      "venue" : "In Proceeding of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "Zhang et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2008
    }, {
      "title" : "Learning under concept drift: an overview",
      "author" : [ "Indre Zliobaite" ],
      "venue" : "Technical report,",
      "citeRegEx" : "Zliobaite.,? \\Q2010\\E",
      "shortCiteRegEx" : "Zliobaite.",
      "year" : 2010
    }, {
      "title" : "Controlled permutation for testing adaptive learning models",
      "author" : [ "Indre Zliobaite" ],
      "venue" : "In Knowledge and Information Systems,",
      "citeRegEx" : "Zliobaite.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zliobaite.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 30,
      "context" : "While many types have been identified, most definitions have been qualitative, many of the definitions have been informal and despite efforts to introduce standardization [Moreno-Torres et al., 2012], the terminology has been non-uniform and inconsistently applied.",
      "startOffset" : 171,
      "endOffset" : 199
    }, {
      "referenceID" : 1,
      "context" : "However, it is also an issue in other forms of learned model that are deployed for extended periods of time, and of especial relevance to all forms of stream mining including clustering [Aggarwal et al., 2003], association discovery [Jiang and Gruenwald, 2006] and outlier detection [Subramaniam et al.",
      "startOffset" : 186,
      "endOffset" : 209
    }, {
      "referenceID" : 39,
      "context" : ", 2003], association discovery [Jiang and Gruenwald, 2006] and outlier detection [Subramaniam et al., 2006].",
      "startOffset" : 81,
      "endOffset" : 107
    }, {
      "referenceID" : 25,
      "context" : "It is perhaps for this reason that recent concept drift literature has instead given a probabilistic definition of concept [Kuncheva, 2004].",
      "startOffset" : 123,
      "endOffset" : 139
    }, {
      "referenceID" : 2,
      "context" : "The classical definition of a concept is by extension—a concept is a set of objects [Michalski, 1983, Angluin, 1988]. Two variants of a definition by extension are possible, by type or token [Zalta, 2009]. A definition by type defines a concept as a set of vectors of X values such that any object with any vector of values in the set belongs to the concept, or equivalently, as a function X → Y Such a definition does not allow that different objects with identical attribute values might belong to different concepts. However, many applications of machine learning require that there be a many-to-many mapping from X values to Y values rather than the many-to-one mapping that such a definition implies. The alternative definition by extension defines a concept as a set of object instances. This is coherent, but does not seem useful in the context of stream learning, because in many applications each object instance will appear only once. Even in a situation where a patient is diagnosed on multiple occasions, in some sense the object being classified is the patient presentation, rather than the patient, as they may have a condition on one presentation and not another. As the sets of objects at different times will not overlap in such a case it is difficult to see how one might assess whether a concept has changed under such a definition. It is perhaps for this reason that recent concept drift literature has instead given a probabilistic definition of concept [Kuncheva, 2004]. Hoens et al. [2012] define a concept as the prior class probabilities P (Y ) and class conditional probabilities P (X | Y ).",
      "startOffset" : 102,
      "endOffset" : 1513
    }, {
      "referenceID" : 2,
      "context" : "The classical definition of a concept is by extension—a concept is a set of objects [Michalski, 1983, Angluin, 1988]. Two variants of a definition by extension are possible, by type or token [Zalta, 2009]. A definition by type defines a concept as a set of vectors of X values such that any object with any vector of values in the set belongs to the concept, or equivalently, as a function X → Y Such a definition does not allow that different objects with identical attribute values might belong to different concepts. However, many applications of machine learning require that there be a many-to-many mapping from X values to Y values rather than the many-to-one mapping that such a definition implies. The alternative definition by extension defines a concept as a set of object instances. This is coherent, but does not seem useful in the context of stream learning, because in many applications each object instance will appear only once. Even in a situation where a patient is diagnosed on multiple occasions, in some sense the object being classified is the patient presentation, rather than the patient, as they may have a condition on one presentation and not another. As the sets of objects at different times will not overlap in such a case it is difficult to see how one might assess whether a concept has changed under such a definition. It is perhaps for this reason that recent concept drift literature has instead given a probabilistic definition of concept [Kuncheva, 2004]. Hoens et al. [2012] define a concept as the prior class probabilities P (Y ) and class conditional probabilities P (X | Y ). As P (Y ) and P (X | Y ) uniquely determines the joint distribution P (X,Y ) and vice versa, this is equivalent to defining a concept as the joint distribution P (X,Y ), as proposed by Gama et al. [2014]. For this reason we adopt Gama et.",
      "startOffset" : 102,
      "endOffset" : 1822
    }, {
      "referenceID" : 2,
      "context" : "The classical definition of a concept is by extension—a concept is a set of objects [Michalski, 1983, Angluin, 1988]. Two variants of a definition by extension are possible, by type or token [Zalta, 2009]. A definition by type defines a concept as a set of vectors of X values such that any object with any vector of values in the set belongs to the concept, or equivalently, as a function X → Y Such a definition does not allow that different objects with identical attribute values might belong to different concepts. However, many applications of machine learning require that there be a many-to-many mapping from X values to Y values rather than the many-to-one mapping that such a definition implies. The alternative definition by extension defines a concept as a set of object instances. This is coherent, but does not seem useful in the context of stream learning, because in many applications each object instance will appear only once. Even in a situation where a patient is diagnosed on multiple occasions, in some sense the object being classified is the patient presentation, rather than the patient, as they may have a condition on one presentation and not another. As the sets of objects at different times will not overlap in such a case it is difficult to see how one might assess whether a concept has changed under such a definition. It is perhaps for this reason that recent concept drift literature has instead given a probabilistic definition of concept [Kuncheva, 2004]. Hoens et al. [2012] define a concept as the prior class probabilities P (Y ) and class conditional probabilities P (X | Y ). As P (Y ) and P (X | Y ) uniquely determines the joint distribution P (X,Y ) and vice versa, this is equivalent to defining a concept as the joint distribution P (X,Y ), as proposed by Gama et al. [2014]. For this reason we adopt Gama et. al.’s (2014) definition for stream classification.",
      "startOffset" : 102,
      "endOffset" : 1870
    }, {
      "referenceID" : 5,
      "context" : "Bartlett et al. [2000] define a measure they call drift rate.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 5,
      "context" : "Bartlett et al. [2000] define a measure they call drift rate. However, they use a limited definition of a concept as a function f : X → Y . They define the drift rate as P (ft 6= ft+1). Minku and Yao [2009] provide a similar measure that they call severity, the primary difference being that they model drift as occurring between periods of concept stability and define the severity as the proportion of the instance space for which the class labels change between successive stable concepts.",
      "startOffset" : 0,
      "endOffset" : 207
    }, {
      "referenceID" : 5,
      "context" : "Bartlett et al. [2000] define a measure they call drift rate. However, they use a limited definition of a concept as a function f : X → Y . They define the drift rate as P (ft 6= ft+1). Minku and Yao [2009] provide a similar measure that they call severity, the primary difference being that they model drift as occurring between periods of concept stability and define the severity as the proportion of the instance space for which the class labels change between successive stable concepts. Kosina et al. [2010] investigate the use of these measures for detecting drift.",
      "startOffset" : 0,
      "endOffset" : 514
    }, {
      "referenceID" : 24,
      "context" : "Examples of distance functions that might be used include Kullback-Leibler Divergence [Kullback and Leibler, 1951] and Hellinger Distance [Hoens et al.",
      "startOffset" : 86,
      "endOffset" : 114
    }, {
      "referenceID" : 40,
      "context" : "To this one can also add P (X) [Tsymbal, 2004].",
      "startOffset" : 31,
      "endOffset" : 46
    }, {
      "referenceID" : 40,
      "context" : "To this one can also add P (X) [Tsymbal, 2004]. It should be noted that such changes are inter-related. For example, P (Y ) cannot change without either P (Y | X) or P (X) changing. It is also worth noting that a change over time in any of these aspects of a distribution requires a change in P (X,Y ), and hence all are captured by our definition of concept drift (4). Kelly et al. [1999] suggest that in the context of classification learning P (Y | X) is the most important of these drift subjects, as such a change will necessitate an update of a model if it is to maintain accuracy.",
      "startOffset" : 32,
      "endOffset" : 390
    }, {
      "referenceID" : 40,
      "context" : "To this one can also add P (X) [Tsymbal, 2004]. It should be noted that such changes are inter-related. For example, P (Y ) cannot change without either P (Y | X) or P (X) changing. It is also worth noting that a change over time in any of these aspects of a distribution requires a change in P (X,Y ), and hence all are captured by our definition of concept drift (4). Kelly et al. [1999] suggest that in the context of classification learning P (Y | X) is the most important of these drift subjects, as such a change will necessitate an update of a model if it is to maintain accuracy. Tsymbal [2004] argue that changes in P (X) are also important, as an increase in the frequency of specific types of cases may increase the importance of accuracy in classifying those cases.",
      "startOffset" : 32,
      "endOffset" : 603
    }, {
      "referenceID" : 29,
      "context" : "Drift scope, also referred to as drift severity [Minku et al., 2010], refers to the proportion of the domain of X for which P (Y | X) changes,",
      "startOffset" : 48,
      "endOffset" : 68
    }, {
      "referenceID" : 29,
      "context" : "Subconcept drift, also referred to as intersected drift [Minku et al., 2010], is where the drift scope is limited to a subspace of dom(X).",
      "startOffset" : 56,
      "endOffset" : 76
    }, {
      "referenceID" : 29,
      "context" : "Full-concept drift, also referred to as severe drift [Minku et al., 2010], involves the posterior class distribution changing for all types of object.",
      "startOffset" : 53,
      "endOffset" : 73
    }, {
      "referenceID" : 26,
      "context" : "Novel class appearance is a special case of concept drift in which a new class comes into existence [Masud et al., 2011].",
      "startOffset" : 100,
      "endOffset" : 120
    }, {
      "referenceID" : 32,
      "context" : "In contrast, if there is abrupt major drift then it might be best to simply abandon the previous model and start afresh with the evidence about the nature of the new concept as it becomes available [Nguyen et al., 2012].",
      "startOffset" : 198,
      "endOffset" : 219
    }, {
      "referenceID" : 16,
      "context" : "In blip drift, the blip concept replaces the dominant concept for a very short period of time [Dongre and Malik, 2014].",
      "startOffset" : 94,
      "endOffset" : 118
    }, {
      "referenceID" : 12,
      "context" : "In the literature, there has been some debate as to whether blip drift should be adjusted for during training, or whether it should even be considered a type of drift [Brzeziński, 2010].",
      "startOffset" : 167,
      "endOffset" : 185
    }, {
      "referenceID" : 29,
      "context" : "Probabilistic drift [Minku et al., 2010] occurs when there are two alternating concepts such that one initially predominates and over time the other comes to predominate [Tsymbal, 2004, Zliobaite, 2010, Bose et al.",
      "startOffset" : 20,
      "endOffset" : 40
    }, {
      "referenceID" : 18,
      "context" : "[2013] and Hoens et al. [2012] do not distinguish between the two types.",
      "startOffset" : 11,
      "endOffset" : 31
    }, {
      "referenceID" : 12,
      "context" : "Brzeziński [2010] raises the issue that some of the literature ignores this difference.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 12,
      "context" : "Brzeziński [2010] raises the issue that some of the literature ignores this difference. Our formal definitions make it clear that they are in fact different, yet somewhat related, as expressed in Brzeziński [2010]. Incremental drift may be probabilistic, but is not necessarily so, and probabilistic drift may be incremental, but is also not necessarily so.",
      "startOffset" : 0,
      "endOffset" : 214
    }, {
      "referenceID" : 29,
      "context" : "Drift predictability, as the name implies, describes how predictable some aspect of a drift is [Minku et al., 2010].",
      "startOffset" : 95,
      "endOffset" : 115
    }, {
      "referenceID" : 4,
      "context" : ", 2004b], DriftDetectionMethodClassifierEDDM [Baena-Garcıa et al., 2006], HoeffdingAdaptiveTree [Bifet and Gavaldà, 2009], HoeffdingOptionTree [Pfahringer et al.",
      "startOffset" : 45,
      "endOffset" : 72
    }, {
      "referenceID" : 7,
      "context" : ", 2006], HoeffdingAdaptiveTree [Bifet and Gavaldà, 2009], HoeffdingOptionTree [Pfahringer et al.",
      "startOffset" : 31,
      "endOffset" : 56
    }, {
      "referenceID" : 36,
      "context" : ", 2006], HoeffdingAdaptiveTree [Bifet and Gavaldà, 2009], HoeffdingOptionTree [Pfahringer et al., 2007], HoeffdingTree [Hulten et al.",
      "startOffset" : 78,
      "endOffset" : 103
    }, {
      "referenceID" : 35,
      "context" : ", 2010b], Naive Bayes, OzaBag [Oza and Russell, 2001], OzaBagAdwin, OzaBoost [Oza and Russell, 2001] and OzaBoostAdwin [Oza and Russell, 2001, Babcock et al.",
      "startOffset" : 30,
      "endOffset" : 53
    }, {
      "referenceID" : 35,
      "context" : ", 2010b], Naive Bayes, OzaBag [Oza and Russell, 2001], OzaBagAdwin, OzaBoost [Oza and Russell, 2001] and OzaBoostAdwin [Oza and Russell, 2001, Babcock et al.",
      "startOffset" : 77,
      "endOffset" : 100
    }, {
      "referenceID" : 31,
      "context" : "– provide a rigorous theoretical basis for designing new mechanisms to detect, characterize and resolve concept drift; – understand what forms of drift are best handled by each different mechanism for handling drift; – create greater diversity in the types of drift that are created by synthetic drift data generators [Narasimhamurthy and Kuncheva, 2007] for stream mining evaluation; – develop more comprehensive and objective approaches for evaluating stream mining algorithms; and – design new machine learning techniques that are robust to a greater diversity of drift types.",
      "startOffset" : 318,
      "endOffset" : 354
    } ],
    "year" : 2017,
    "abstractText" : "Most machine learning models are static, but the world is dynamic, and increasing online deployment of learned models gives increasing urgency to the development of efficient and effective mechanisms to address learning in the context of non-stationary distributions, or as it is commonly called concept drift. However, the key issue of characterizing the different types of drift that can occur has not previously been subjected to rigorous definition and analysis. In particular, while some qualitative drift categorizations have been proposed, few have been formally defined, and the quantitative descriptions required for detailed understanding of learner performance have not existed. We present the G. I. Webb Faculty of Information Technology Monash University Clayton, Vic 3800, Australia E-mail: geoff.webb@monash.edu R. Hyde Faculty of Information Technology Monash University Clayton, Vic 3800, Australia E-mail: roy.hyde@alumni.monash.edu H. Cao McLaren Applied Technologies Pte Ltd APAC Suntec Tower One, Singapore 038987 E-mail: hong.cao@mclaren.com H. L. Nguyen McLaren Applied Technologies Pte Ltd APAC Suntec Tower One, Singapore 038987 E-mail: long.nguyen@mclaren.com F. Petitjean Faculty of Information Technology Monash University Clayton, Vic 3800, Australia E-mail: francois.petitjean@monash.edu ar X iv :1 51 1. 03 81 6v 1 [ cs .L G ] 1 2 N ov 2 01 5 2 Geoffrey I. Webb et al. first comprehensive framework for quantitative analysis of drift. This supports the development of the first comprehensive set of formal definitions of types of concept drift. The formal definitions clarify ambiguities and identify gaps in previous definitions, giving rise to a new comprehensive taxonomy of concept drift types and a solid foundation for research into mechanisms to detect and address concept drift.",
    "creator" : "LaTeX with hyperref package"
  }
}