{
  "name" : "1505.06072.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Diffusion Methods for Classification with Pairwise Relationships",
    "authors" : [ "Pedro F. Felzenszwalb", "Benar F. Svaiter" ],
    "emails" : [ "pff@brown.edu", "benar@impa.br" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We define two algorithms for propagating information in classification problems with pairwise relationships. The algorithms are based on contraction maps and are related to non-linear diffusion and random walks on graphs. The approach is also related to message passing algorithms, including belief propagation and mean field methods. The algorithms we describe are guaranteed to converge on graphs with arbitrary topology. Moreover they always converge to a unique fixed point, independent of initialization. We prove that the fixed points of the algorithms under consideration define lower-bounds on the energy function and the max-marginals of a Markov random field. The theoretical results also illustrate a relationship between message passing algorithms and value iteration for an infinite horizon Markov decision process. We illustrate the practical application of the algorithms under study with numerical experiments in image restoration, stereo depth estimation and binary classification on a grid."
    }, {
      "heading" : "1 Introduction",
      "text" : "In many classification problems there are relationships among a set of items to be classified. For example, in image reconstruction problems adjacent pixels are likely to belong to the same object or image segment. This leads to relationships between the labels of different pixels in an image. Energy minimization methods based on Markov random fields (MRF) address these problems in a common framework [4, 23, 15]. Within this framework we introduce two new algorithms for classification with pairwise information. These algorithms are based on contraction maps and are related to non-linear diffusion and random walks on graphs.\nThe setting under consideration is as follows. Let G = (V,E) be an undirected simple graph and L be a set of labels. A labeling of V is a function x : V → L assigning a label from L to each vertex ∗Partially supported by NSF under grant 1161282 and the Brown-IMPA collaboration program. †Partially supported by CNPq grants 474996/2013-1, 302962/2011-5 and FAPERJ grant E-26/201.584/2014.\nar X\niv :1\n50 5.\n06 07\n2v 3\n[ cs\n.A I]\n2 2\nD ec\nin V . Local information is modeled by a cost gi(a) for assigning label a to vertex i. Information on label compatibility for neighboring vertices is modeled by a cost hij(a, b) for assigning label a to vertex i and label b to vertex j. The cost for a labeling x is defined by an energy function,\nF (x) = ∑ i∈V gi(xi) + ∑ {i,j}∈E hij(xi, xj). (1)\nIn the context of MRFs the energy function defines a Gibbs distribution on random variables X associated with the vertices V ,\np(X = x) = 1\nZ exp(−F (x)). (2)\nMinimizing the energy F (x) corresponds to maximizing p(X = x). This approach has been applied to a variety of problems in image processing and computer vision [11]. A classical example involves restoring corrupted images [12, 5]. In image restoration there is a grid of pixels and the problem is to estimate an intensity value for each pixel. To restore an image I one looks for an image J that is similar to I and is smooth almost everywhere. Similarity between I and J is defined by local costs at each pixel. The smoothness constraint is defined by pairwise costs between neighboring pixels in J ."
    }, {
      "heading" : "1.1 Basic Definitions and Overview of Results",
      "text" : "Let G = (V,E) be an undirected, simple, connected graph, with more than one vertex. For simplicity let V = {1, . . . , n}. Let N(i) and d(i) denote respectively the set of neighbors and the degree of vertex i,\nN(i) = {j ∈ V | {i, j} ∈ E}, d(i) = |N(i)|.\nLet L be a set of labels. For each vertex i ∈ V we have a non-negative cost for assigning label a to vertex i, denoted by gi(a). These costs capture local information about the label of each vertex. For each edge {i, j} ∈ E we have a non-negative cost for assigning label a to vertex i and label b to vertex j, denoted equally by hij(a, b) or hji(b, a). These costs capture relationships between labels of neighboring vertices.\ngi : L→ [0,∞) for i ∈ V ;\nhij , hji : L 2 → [0,∞) for {i, j} ∈ E with hij(a, b) = hji(b, a)\nLet x ∈ LV denote a labeling of V with labels from L. A cost for x that takes into account both local information at each vertex and the pairwise relationships can be defined by an energy function F : LV → R,\nF (x) = ∑ i∈V gi(xi) + ∑ {i,j}∈E hij(xi, xj). (3)\nThis leads to a natural optimization problem where we look for a labeling x with minimum energy.\nThroughout the paper we assume L is finite. The optimization problem defined by F is NP-hard even when |L| = 2 as it can be used to solve the independent set problem on G. It can also be used to solve coloring with k colors when |L| = k. The optimization problem can be solved in polynomial time using dynamic programming when G is a tree [2]. More generally dynamic programming leads to polynomial optimization algorithms when the graph G is chordal (triangulated) and has bounded tree-width.\nMin-sum (max-product) belief propagation [23, 15] is a local message passing algorithm that is equivalent to dynamic programming when G is a tree. Both dynamic programming and belief propagation aggregate local costs by sequential propagation of information along the edges in E.\nFor i ∈ V we define the value function fi : L→ R,\nfi(τ) = min x∈LV xi=τ F (x). (4)\nIn the context of MRFs the value functions are also known as max-marginals. The value functions are also what is computed by the dynamic programming and belief propagation algorithms for minimizing F when G is a tree. Each value function defines a cost for assigning a label to a vertex that takes into account the whole graph. If x∗ minimizes F (x) then x∗i minimizes fi(τ), and when fi(τ) has a unique minimum we can minimize F (x) by selecting\nx∗i = argmin τ fi(τ). (5)\nA local belief is a function γ : L → R. A field of beliefs specifies a local belief for each vertex in V , and is an element of\n(RL)V = {ϕ = (ϕ1, . . . , ϕN ) | ϕi : L→ R}. (6)\nWe define two algorithms in terms of maps,\nT : (RL)V → (RL)V , S : (RL)V → (RL)V .\nThe maps T and S are closely related. Both maps are contractions, but each of them has its own unique fixed point. Each of these maps can be used to define an algorithm to optimize F (x) based on fixed point iterations and local decisions.\nFor z ∈ {T, S} we start from an initial field of beliefs ϕ0 and sequentially compute\nϕk+1 = z(ϕk).\nBoth Sk(ϕ0) and T k(ϕ0) converge to the unique fixed points of S and T respectively. After convergence to a fixed point ϕ (or a bounded number of iterations in practice) we select a labeling\nx by selecting the label minimizing the belief at each vertex (breaking ties arbitrarily),\nxi = argmin τ ϕi(τ). (7)\nThe algorithms we consider depend on parameters p ∈ (0, 1), q = 1− p and weights wij ∈ [0, 1] for each i ∈ V and j ∈ N(i). The weights from each vertex are constrained to sum to one,∑\nj∈N(i)\nwij = 1, ∀i ∈ V. (8)\nThese weights can be interpreted in terms of transition probabilities for a random walk on G. In a uniform random walk we have wij = 1/d(i). Non-uniform weights can be used to capture additional information about an underlying application. For example, in the case of stereo depth estimation (Section 5.2) we have used non-uniform weights that reflect color similarity between neighboring pixels. We note, however, that while we may interpret the results of the fixed point algorithms in terms of transition probabilities in a random walk, the algorithms we study are deterministic.\nThe maps S and T we consider are defined as follows,\nDefinition 1.1.\n(Tϕ)i(τ) = pgi(τ) + ∑ j∈N(i) min uj∈L p 2 hij(τ, uj) + qwjiϕj(uj) (9)\n(Sϕ)i(τ) = pgi(τ) + ∑ j∈N(i) wij min uj∈L phij(τ, uj) + qϕj(uj) (10)\nThe map defined by T corresponds to a form of non-linear diffusion of beliefs along the edges of G. The map defined by S corresponds to value iteration for a Markov decision process (MDP) [3] defined by random walks on G. We show that both S and T are contractions. Let ϕ̄ be the fixed point of T and ϕ̂ be the fixed point of S. We show ϕ̄ defines a lower bound on the energy function F , and that ϕ̂ defines lower bounds on the value functions fi,∑ i∈V ϕ̄i(xi) ≤ F (x), ∀x ∈ LV , (11)\nϕ̂i(τ) ≤ fi(τ), ∀i ∈ V, τ ∈ L. (12)\nIn Section 3 we study the fixed point iteration algorithm defined by T and the relationship between ϕ̄ and F . To the extent that ∑\ni∈V ϕ̄i(xi) approximates F (x) this justifies selecting a\nlabeling x by minimizing ϕ̄i at each vertex. This approach is related to mean field methods and variational inference with the Gibbs distribution p(X = x) [23, 15].\nIn Section 4 we study the algorithm defined by S and the relationship between ϕ̂i and fi. To the extent that ϕ̂i(τ) approximates fi(τ) this justifies selecting a labeling x by minimizing ϕ̂i at each vertex. We also show a connection between the fixed point ϕ̂ and optimal policies of a Markov decision process. The process is defined in terms of random walks on G, with transition probabilities given by the weights wij ."
    }, {
      "heading" : "1.2 Examples",
      "text" : "Figure 1 shows two examples of fixed points of T when the graph G = (V,E) is a cycle with 5 vertices. In this case we have a binary labeling problem L = {1, 2}. The local costs are all zero except that vertex 1 has a preference for label 2. This is encoded by a cost for label 1,\ng1(1) = 1, (13)\ng1(2) = 0, (14) gi(a) = 0, ∀i 6= 1, a ∈ L. (15)\nIn example (a) we have pairwise costs that encourage equal labels for neighboring vertices,\nhij(a, b) = 0 a = b1 a 6= b, (16) In example (b) we have pairwise costs that encourage different labels for neighboring vertices,\nhij(a, b) = 1 a = b0 a 6= b, (17)\nFigure 1 shows a graphical representation of the local costs for each vertex, and the value of ϕ̄, the fixed point of T , on each example. In (a) local selection of xi minimizing ϕ̄i leads to x = (2, 2, 2, 2, 2). In (b) local selection of xi minimizing ϕ̄i leads to x = (2, 1, 2, 2, 1). In both examples the resulting labeling x is the global minimum of F (x). For these examples we used p = 0.1 and wij = 1/d(i).\nOf course in general local minimization of ϕ̄ does not lead to a labeling minimizing F (x) and\nit would be interesting to characterize when this happens."
    }, {
      "heading" : "1.3 Related Work",
      "text" : "For general graphs G, when the pairwise costs hij(a, b) define a metric over L there are polynomial time approximation algorithms for the optimization problem defined by F [14]. In some important cases the optimization problem can be solved using graph cuts and maximum flow algorithms [13, 8, 7, 17]. This includes in particular the case of MAP estimation for an Ising model with an external field [13].\nThe algorithms we study are closely related to message passing methods, in particular to minsum (or equivalently max-product) belief propagation (BP) [23, 15]. When the graph G is a tree, BP converges and solves the optimization problem defined by F . Unfortunately BP is not guaranteed to converge and it can have multiple fixed points for general graphs. Some form of dampening can help BP converge in practice. The algorithms we study provide a simple alternative to min-sum belief propagation that is guaranteed to converge to a unique fixed point, regardless of initialization. The algorithms are also guaranteed to converge “quickly”.\nOne approach for solving the optimization problem defined by F involves using a linear program (LP) relaxation. The optimization problem can be posed using a LP with a large number of constraints and relaxed to obtain a tractable LP over the local polytope [22]. Several message passing methods have been motivated in terms of this LP [19]. There are also recent methods which use message passing in the inner loop of an algorithm that converges to the optimal solution of the local polytope LP relaxation [20, 21]. In Section 3.1 we characterize the fixed point of S using a different LP.\nThe mean-field algorithm [23, 15] is an iterative method for approximating the Gibbs distribu-\ntion p(x) by a factored distribution q(x),\nq(x) = ∏ i∈V qi(xi). (18)\nThe mean-field approach involves minimization of the KL divergence between p and q using fixed point iterations that repeatedly update the factors qi defining q. A drawback of the approach is that the fixed point is not unique and the method is sensitive to initialization.\nThe algorithm defined by T is related to the mean-field method in the sense that the fixed\npoints of T appear to approximate F (x) by a function H(x) that is a sum of local terms,\nH(x) = ∑ i∈V ϕ̄i(xi). (19)\nWe do not know, however, if there is a measure under which the resulting H(x) is an optimal approximation to F (x) within the class of functions defined by a sum of local terms."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "The algorithms we study are efficient in the following sense. Let m = |E| and k = |L|. Each iteration in the fixed point algorithm involves evaluating T or S. This can be done in O(mk2) by “brute-force” evaluation of the expressions in Definition 1.1. In many applications, including in image restoration and stereo matching, the pairwise cost hij has special structure that allows for faster computation using the techniques described in [10]. This leads to an O(mk) algorithm for each iteration of the fixed point methods. Additionally, the algorithms are easily parallelizable.\nThe fixed point algorithms defined by T and S converge quickly because the maps are contrac-\ntions in (RL)V . Let z : RK → RK and ‖x‖ be a norm in RK . For γ ∈ (0, 1), z is a γ-contraction if\n‖z(x)− z(y)‖ ≤ γ‖x− y‖. (20)\nWhen z is a contraction it has a unique fixed point x̄. It also follows directly from the contraction property that fixed point iteration xk = z(xk−1) converges to x̄ quickly,\n‖xk − x̄‖ ≤ γk‖x0 − x̄‖. (21)\nThe weights wij in the definition of T and S define a random process that generates random walks on G. We have a Markov chain with state space V . Starting from a vertex Q0 we generate an infinite sequence of random vertices (Q0, Q1, . . .) with transition probabilities\np(Qt+1 = j|Qt = i) = wij . (22)\nA natural choice for the weights is wij = 1/d(i), corresponding to moving from i to j with uniform probability over N(i). This choice leads to uniform random walks on G [18].\nWe consider in (RL)V the partial order\nϕ ≤ ψ ⇐⇒ ϕi(τ) ≤ ψi(τ) ∀i ∈ V, ∀τ ∈ L. (23)\nIt follows trivially from the definitions of T and S that both maps preserve order in (RL)V ,\nϕ ≤ ψ ⇒ Tϕ ≤ Tψ, Sϕ ≤ Sψ. (24)\nWe claim that for any α ∈ RV , ∑ i∈V ∑ j∈N(i) wjiαj = ∑ j∈V αj . (25)\nThis follows from re-ordering the double summation and the constraints that the weights out of each vertex sum to one, ∑ i∈V ∑ j∈N(i) wjiαj = ∑ j∈V ∑ i∈N(j) wjiαj = ∑ j∈V αj\nWe note that the algorithms defined by T and S are related in the following sense. For a regular graph with degree d, if we let wij = 1/d the maps T and S are equivalent up to rescaling if the costs in T and S are rescaled appropriately."
    }, {
      "heading" : "3 Algorithm defined by T (Diffusion)",
      "text" : "In this section we study the fixed point algorithm defined by T . We show that T is a contraction in (RL)V and that the fixed point of T defines a “factored” lower bound on F . We start by showing that T is a contraction with respect to the norm on (RL)V defined by\n‖ϕ‖∞,1 = ∑ i∈V ‖ϕi‖∞. (26)\nLemma 3.1. (Contraction) For any ϕ,ψ ∈ (RL)V ‖(Tϕ)i − (Tψ)i‖∞ ≤ q ∑ j∈N(i) wji‖ϕj − ψj‖∞ ∀i ∈ V, (27)\n‖(Tϕ)− (Tψ)‖∞,1 ≤ q‖ϕ− ψ‖∞,1. (28)\nProof. Take i ∈ V and τ ∈ L. For any x ∈ LV (Tϕ)i(τ) = pgi(τ) + ∑ j∈N(i) min uj∈L p 2 hij(τ, uj) + qwjiϕj(uj)\n≤ pgi(τ) + ∑ j∈N(i) p 2 hij(τ, xj) + qwjiϕj(xj)\n≤ pgi(τ) + ∑ j∈N(i) p 2 hij(τ, xj) + qwji(ψj(xj) + |ϕj(xj)− ψj(xj)|)\n≤ pgi(τ) + ∑ j∈N(i) p 2 hij(τ, xj) + qwji(ψj(xj) + ‖ϕj − ψj‖∞)\nSince the inequality defined by the first and last terms above holds for any x, it holds when x minimizes the last term. Therefore\n(Tϕ)i(τ) ≤ (Tψ)i(τ) + q ∑ j∈N(i) wji‖ϕj − ψj‖∞.\nSince this inequality holds interchanging ϕ with ψ we have |(Tϕ)i(τ)− (Tψ)i(τ)| ≤ q ∑ j∈N(i) wji‖ϕj − ψj‖∞.\nTaking the τ maximizing the left hand side proves (27). To prove (28), we sum the inequalities (27) for all i ∈ V and use (25).\nThe contraction property above implies the fixed point algorithm defined by T converges to a unique fixed point independent on initialization. It also implies the distance to the fixed point decreases quickly, and we can bound the distance to the fixed point using either the initial distance to the fixed point or the distance between consecutive iterates (a readily available measure).\nTheorem 3.2. The map T has a unique fixed point ϕ̄ and for any ϕ ∈ (RL)V and integer k ≥ 0,\n‖ϕ̄− T kϕ‖∞,1 ≤ qk‖ϕ̄− ϕ‖∞,1, (29)\n‖ϕ̄− ϕ‖∞,1 ≤ 1\np ‖Tϕ− ϕ‖∞,1. (30)\nProof. Existence and uniqueness of the fixed point, as well as the first inequality follows trivially from Lemma 3.1. To prove the second inequality observe that since T kϕ converges to ϕ̄,\n‖ϕ̄− ϕ‖∞,1 ≤ ∞∑ k=0 ‖T k+1ϕ− T kϕ‖∞,1 ≤ ∞∑ k=0 qk‖Tϕ− ϕ‖∞,1. (31)\nNow note that since p ∈ (0, 1) and p+ q = 1, ∞∑ k=0 qkp = 1 =⇒ ∞∑ k=0 qk = 1 p . (32)\nThe map T and the energy function F are related as follows.\nProposition 3.3. For any ϕ ∈ (RL)V and x ∈ LV∑ i∈V (Tϕ)i(xi) ≤ pF (x) + q ∑ i∈V ϕi(xi). (33) Proof. Direct use of the definition of T yields∑ i∈V (Tϕ)i(xi) = ∑ i∈V pgi(xi) + ∑ j∈N(i) min uj∈L p 2 hij(xi, uj) + qwjiϕj(uj)\n≤ ∑ i∈V pgi(xi) + ∑ j∈N(i) p 2 hij(xi, xj) + qwjiϕj(xj)\n= p ∑ i∈V gi(xi) + ∑ i∈V ∑ j∈N(i) 1 2 hij(xi, xj)  + q∑ i∈V ∑ j∈N(i) wjiϕj(xj)\n= pF (x) + q ∑ j∈V ϕj(xj),\nwhere the last equality follows from the fact that hij(xi, xj) = hji(xj , xi) and Equation (25).\nNow we show the fixed point of T defines a lower bound on F in terms of a sum of local terms.\nTheorem 3.4. Let ϕ̄ be the fixed point of T and H(x) = ∑ i∈V ϕ̄i(xi).\nThen 0 ≤ ϕ̄ and H(x) ≤ F (x).\nProof. The fact that H(x) ≤ F (x) follows directly from Proposition 3.3. To prove 0 ≤ ϕ̄ consider the sequence (0, T0, T 20, . . .). The non-negativity of gi and hij implies 0 ≤ T0. Since T is order preserving (24) it follows by induction that T k0 ≤ T k+10 for all k ≥ 0. Since the sequence is pointwise non-decreasing and converges to ϕ̄ we have 0 ≤ ϕ̄.\nTheorem 3.4 allows us to compute both a lower and an upper bound on the optimal value of\nF , together with a solution where F attains the upper bound.\nCorollary 3.5. Let ϕ̄ be the fixed point of T and\nx̄i = argmin τ\nϕ̄i(τ) ∀i ∈ V,\nthen for any x∗ minimizing F , ∑ i∈V ϕ̄i(x̄i) ≤ F (x∗) ≤ F (x̄). Proof. If x∗ is a minimizer of F , then the inequality F (x∗) ≤ F (x̄) holds trivially. We can use the definition of x̄ to conclude that ∑\ni∈V ϕ̄i(x̄i) ≤ ∑ i∈V ϕ̄i(x ∗ i ) ≤ F (x∗),\nwhere the second inequality follows from Theorem 3.4"
    }, {
      "heading" : "3.1 Linear Programming Formulation",
      "text" : "Here we provide a LP characterizing for the fixed point of T . We note that the LP formulation described here is different from the standard LP relaxation for minimizing F (x) which involves the local polytope described in [22].\nConsider the following LP which depends on a vector of coefficients a in (RL)V ,\nmax ϕ\naTϕ\nϕi(ui) ≤ pgi(ui) + ∑ j∈N(i) p 2 hij(ui, uj) + qwjiϕj(uj) ∀i ∈ V,∀u ∈ LV .\nNote that the constraints in the LP are equivalent to ϕ ≤ Tϕ. Next we show that this LP has a unique solution which equals the fixed point of T whenever every coefficient is positive, independent of their specific values. For example, ϕ̄ is the optimal solution when a is the vector of ones.\nTheorem 3.6. If a is a non-negative vector the fixed point of T is an optimal solution for the LP. If a is a positive vector the fixed point of T is the unique optimal solution for the LP.\nProof. Let ϕ̄ be the fixed point of T . First note that ϕ̄ is a feasible solution since ϕ̄ ≤ T ϕ̄. Let ϕ ∈ (RL)V be any feasible solution for the LP. The linear constraints are equivalent to ϕ ≤ Tϕ. Since T preserves order it follows by induction that T kϕ ≤ T k+1ϕ for all k ≥ 0. Since the sequence (ϕ, Tϕ, T 2ϕ, . . .) converges to ϕ̄ and it is pointwise non-decreasing we conclude ϕ ≤ ϕ̄.\nIf a is non-negative we have aTϕ ≤ aT ϕ̄ and therefore ϕ̄ must be an optimal solution for the LP. If a is positive and ϕ 6= ϕ̄ we have aTϕ < aT ϕ̄. This proves the fixed point is the unique optimal solution for the LP."
    }, {
      "heading" : "4 Algorithm defined by S (Optimal Control)",
      "text" : "In this section we study the algorithm defined by S. We start by showing that S corresponds to value iteration for an infinite horizon discounted Markov decision process (MDP) [3].\nAn infinite horizon discounted MDP is defined by a tuple (Q,A, c, t, γ) where Q is a set of states, A is a set of actions and γ is a discount factor in R. The cost function c : Q × A → R specifies a cost c(s, a) for taking action a on state s. The transition probabilities t : Q × A ×Q → R specify the probability t(s, a, s′) of moving to state s′ if we take action a in state s.\nLet o be an infinite sequence of state and action pairs, o = ((s1, a1), (s2, a2), . . .) ∈ (Q × A)∞. The (discounted) cost of o is\nc(o) = ∞∑ k=0 γkc(sk, ak). (34)\nA policy for the MDP is defined by a map π : Q→ A, specifying an action to be taken at each state. The value of a state s under the policy π is the expected cost of an infinite sequence of state and action pairs generated using π starting at s,\nvπ(s) = E[c(o)|π, s1 = s]. (35)\nAn optimal policy π∗ minimizes vπ(s) for every starting state. Value iteration computes vπ∗ as\nthe fixed point of L : RQ → RQ,\n(Lv)(s) = min a∈A c(s, a) + γ ∑ s′∈Q t(s, a, s′)v(s′). (36)\nThe map L is known to be a γ-contraction [3] with respect to the ‖ · ‖∞ norm.\nNow we show that S is equivalent to value iteration for an MDP defined by random walks on G. Intuitively we have states defined by a vertex i ∈ V and a label a ∈ L. An action involves selecting a different label for each possible next vertex, and the next vertex is selected according to a random walk defined by the weights wij .\nLemma 4.1. Define an MDP (Q,A, c, t, γ) as follows. The states are pairs of vertices and labels Q = V ×L. The actions specify a label for every possible next vertex A = LV . The discount factor is γ = q. The transition probabilities and cost function are defined by\nt((i, τ), u, (j, τ ′)) = wij j ∈ N(i), τ ′ = uj0 otherwise (37) c((i, τ), u) = pgi(τ) +\n∑ j∈N(i) pwijhij(τ, uj) (38)\nThe map S is equivalent to value iteration for this MDP. That is, if ϕi(τ) = v((i, τ)) then\n(Sϕ)i(τ) = (Lv)((i, τ)).\nProof. The result follows directly from the definition of the MDP, L and S.\n(Lv)((i, τ)) = min u∈LV\nc((i, τ), u) + γ ∑\n(j,τ ′)∈Q\nt((i, τ), u, (j, τ ′))v(j, τ ′) (39)\n= min u∈LV pgi(τ) + ∑ j∈N(i) pwijhij(τ, uj) + q ∑ j∈N(i) wijv(j, uj) (40)\n= pgi(τ) + ∑ j∈N(i) wij min uj∈L phij(τ, uj) + qv(j, uj) (41)\n= (Sϕ)i(τ) (42)\nThe relationship to value iteration shows S is a contraction and we have the following results\nregarding fixed point iterations with S.\nTheorem 4.2. The map S has a unique fixed point ϕ̂ and for any ϕ ∈ (RL)V and integer k ≥ 0,\n‖ϕ̂− Skϕ‖∞ ≤ qk‖ϕ̂− ϕ‖∞, (43)\n‖ϕ̂− ϕ‖∞ ≤ 1\np ‖Sϕ− ϕ‖∞. (44)\nProof. The first inequality follows directly from Lemma 4.1 and the fact that L is a γ-contraction with γ = q. The proof of the second inequality is similar to the proof of the analogous result for the map T in Theorem 3.2."
    }, {
      "heading" : "4.1 Random Walks",
      "text" : "The formalism of MDPs is quite general, and encompasses the fixed point algorithm defined by S. In this section we further analyze this fixed point algorithm and provide an interpretation using one-dimensional problems defined by random walks on G.\nThe weights wij define a random process that generates infinite walks on G. Starting from some\nvertex in V we repeatedly move to a neighboring vertex, and the probability of moving from i ∈ V to j ∈ N(i) in one step is given by wij .\nAn infinite walk ω = (ω1, ω2, . . .) ∈ V∞ can be used to define an energy on an infinite sequence of labels z = (z1, z2, . . .) ∈ L∞,\nFω(z) = ∞∑ t=0 pqtgωt(zt) + pq thωtωt+1(zt, zt+1). (45)\nThe energy Fω(z) can be seen as the energy of a pairwise classification problem on a graph G ′ = (V ′, E′) that is an infinite path,\nV ′ = {1, 2, . . .}, (46) E′ = {{1, 2}, {2, 3}, . . .}. (47)\nThe graph G′ can be interpreted as a one-dimensional “unwrapping” of G along the walk ω. This unwrapping defines a map from vertices in the path G′ to vertices in G.\nConsider a policy π : V × L× V → L that specifies zk+1 in terms of ωk, zk and ωk+1,\nzk+1 = π(ωk, zk, ωk+1). (48)\nNow consider the expected value of Fω(z) when ω is a random walk starting at i ∈ V and z is a sequence of labels defined by the policy π starting with z1 = τ ,\nvπ(i, τ) = E[Fω(z)|ω1 = i, z1 = τ, zk+1 = π(ωk, zk, ωk+1)]. (49)\nThere is an optimal policy π∗ that minimizes vπ(i, τ) for every i ∈ V and τ ∈ L. Let ϕ̂ be the fixed point of S. Then ϕ̂i(τ) = vπ∗(i, τ). This follows directly from the connection between S and the MDP described in the last section."
    }, {
      "heading" : "4.2 Bounding the Value Functions of F",
      "text" : "Now we show that ϕ̂ defines lower bounds on the value functions (max-marginals) fi defined in (4). We start by showing that fi can be lower bounded by fj for j ∈ N(i).\nProposition 4.3. Let i ∈ V and j ∈ N(i).\nfi(ui) ≥ pgi(ui) + min uj phij(ui, uj) + qfj(uj), (50) fi(ui) ≥ pgi(ui) + ∑ j∈N(i) wij min uj phij(ui, uj) + qfj(uj). (51)\nProof. The second inequality follows from the first one by taking a convex combination over j ∈ N(i). To prove the first inequality note that,\nfi(ui) = min x∈LV xi=ui F (x) (52)\n= min uj∈L\nmin x∈LV\nxi=ui,xj=uj\nF (x) (53)\n= min uj∈L\nmin x∈LV\nxi=ui,xj=uj\npF (x) + qF (x) (54)\n≥ pgi(ui) + min uj∈L phij(ui, uj) + min x∈LV\nxi=ui,xj=uj\nqF (x) (55)\n≥ pgi(xi) + min uj∈L phij(ui, uj) + min x∈LV xj=uj qF (x) (56)\n= pgi(xi) + min uj∈L phij(ui, uj) + qfj(uj). (57)\nThe first inequality above follows from F (x) ≥ gi(xi) + hij(xi, xj) since all the terms in F (x) are non-negative. The second inequality follows from the fact that we are minimizing F (x) over x with fewer restrictions.\nThe map S and the value functions are related as follows.\nProposition 4.4. Let f = (f1, . . . , fN ) ∈ (RL)V be a field of beliefs defined by the value functions.\nSf ≤ f. (58)\nProof. The result follows directly from Proposition 4.3.\nNow we show that the fixed point of S defines lower bounds on the value functions.\nTheorem 4.5. Let ϕ̂ be the fixed point of S. Then\n0 ≤ ϕ̂i(τ) ≤ fi(τ).\nProof. Since the costs gi and hij are non-negative we have 0 ≤ S0. Using the fact that S preserves order we can conclude 0 ≤ ϕ̂.\nSince Sf ≤ f and S preserves order, Skf ≤ f for all k. To end the proof, take the limit k →∞ at the left hand-side of this inequality."
    }, {
      "heading" : "5 Numerical Experiments",
      "text" : "In this section we illustrate the practical feasibility of the proposed algorithms with preliminary experiments in computer vision problems. We also evaluate the fixed point algorithms defined by S and T and other methods on random binary classification problems on a grid."
    }, {
      "heading" : "5.1 Image Restoration",
      "text" : "The goal of image restoration is to estimate a clean image z from a noisy, or corrupted, version y. A classical approach to solve this problem involves looking for a piecewise smooth image x that is similar to y [12, 6]. In the weak membrane model [6] the local costs gi(a) penalize differences between x and y while the pairwise costs hij(a, b) penalize differences between neighboring pixels in x. In this setting, the graph G = (V,E) is a grid in which the vertices V correspond to pixels and the edges E connect neighboring pixels. The labels L are possible pixel values and a labeling x defines an image. For our experiments we use L = {0, . . . , 255} corresponding to the possible values in an 8-bit image.\nTo restore y we define the energy F (x) using\ngi(xi) = (yi − xi)2; (59)\nhij(xi, xj) = λmin((xi − xj)2, τ). (60)\nThe local cost gi(xi) encourages xi to be similar to yi. The pairwise costs depend on two parameters λ, τ ∈ R. The cost hij(xi, xj) encourages xi to be similar to xj but also allows for large differences since the cost is bounded by τ . The value of λ controls the relative weight of the local and pairwise costs. Small values of λ lead to images x that are very similar to the noisy image y, while large values of λ lead to images x that are smoother.\nFigure 2 shows an example result of image restoration using the algorithm defined by T . The example illustrates the algorithm is able to recover a clean image that is smooth almost everywhere while at the same time preserving sharp discontinuities at the boundaries of objects. For comparison we also show the results of belief propagation. In this example the noisy image y was obtained from a clean image z by adding independent noise to each pixel using a Gaussian distribution with standard deviation σ = 20. The input image has 122 by 179 pixels. We used λ = 0.05 and τ = 100 to define the pairwise costs. For the algorithm defined by T we used uniform weights, wij = 1/d(i) and p = 0.001. Both the algorithms defined by T and belief propagation were run for 100 iterations. We based our implementations on the belief propagation code from [9], which provides efficient methods for handling truncated quadratic discontinuity costs. The algorithm defined by T took 16 seconds on a 1.6Ghz Intel Core i5 laptop computer while belief propagation took 18 seconds.\nThe goal of restoration is to recover a clean image z. We evaluate the restored image x by computing the root mean squared error (RMSE) between x and z. We see in Figure 2 that when λ = 0.05 and τ = 100 the result of T has lower RMSE value compared to the result of BP, even though the result of T has significantly higher energy. We also evaluate the results of T , S and BP using different values of λ in Table 1. For all of these experiments we used τ = 100 and ran each algorithm for 100 iterations. The minimum RMSE obtained by T and S is lower than the minimum RMSE obtained by BP considering different values for λ, even though T and S alwayd\nfind solutions that have higher energy compared to BP. This suggests the algorithms we propose do a good job aggregating local information using pairwise constraints, but the energy minimization problem defined by F (x) may not be the ideal formulation of the restoration problem."
    }, {
      "heading" : "5.2 Stereo Depth Estimation",
      "text" : "In stereo matching we have two images Il and Ir taken at the same time from different viewpoints. Most pixels in one image have a corresponding pixel in the other image, being the projection of the same three-dimensional point. The difference in the coordinates of corresponding pixels is called the disparity. We assume the images are rectified such that a pixel (x, y) in Il matches a pixel (x − d, y) in Ir with d ≥ 0. For rectified images the distance of a three-dimensional point to the image plane is inversely proportional to the disparity.\nIn practice we consider the problem of labeling every pixel in Il with an integer disparity in L = {0, . . . , D}. In this case a labeling x is a disparity map for Il. The local costs gi(a) encourage pixels in Il to be matched to pixels of similar color in Ir. The pairwise costs hij(a, b) encourage piecewise smooth disparity maps.\nThe model we used in our stereo experiment is defined by,\ngi(a) = min(γ, ||Il(i)− Ir(i− (a, 0))||1); (61)\nhij(a, b) =  0 a = b, α |a− b| = 1,\nβ |a− b| > 1.\n(62)\nHere Il(i) is the value of pixel i in Il while Ir(i− (a, 0)) is the value of the corresponding pixel in Ir assuming a disparity a for i. The `1 norm ||Il(i) − Ir(i − (a, 0))||1 defines a distance between RGB values (matching pixels should have similar color). The color distance is truncated by γ to allow for some large color differences which occur due to specular reflections and occlusions. The pairwise costs depend on two parameter α, β ∈ R with α < β. The pairwise costs encourage the disparity neighboring pixels to be similar or differ by 1 (to allow for slanted surfaces), but also allows for large discontinuities which occur at object boundaries.\nFigure 3 shows an example result of disparity estimation using the fixed point algorithm defined by S. In this example we used non-uniform weights wij to emphasize the relationships between neighboring pixels of similar color, since those pixels are most likely to belong to the same object/surface. The parameters we used for the results in Figure 3 were defined by,\nwij ∝ 0.01 + e−0.2||Il(i)−Il(j)||1 , (63)\np = 0.0001, α = 500, β = 1000 and γ = 20. The input image has 384 by 288 pixels and the maximum disparity is D = 15. The fixed point algorithm was run for 1,000 iterations which took 13 seconds on a laptop computer.\nWe note that the results in Figure 3 are similar to results obtained min-sum belief propagation\nshown in [9]."
    }, {
      "heading" : "5.3 Binary Classification on a Grid",
      "text" : "Let G = (V,E) be a K by K grid and L = {−1,+1}. We can define a classification problem on G using energy functions of the form,\nF (x) = ∑ i∈V αixi + ∑ {i,j}∈E βijxixj . (64)\nTo evaluate different algorithms we generated random classification problems by independently selecting each αi from a uniform distribution over [−1,+1] and each βij from a uniform distribution over [−λ,+λ]. The parameter λ controls the relative strength of the pairwise relations and the local information associated with each vertex.\nLet x∗ be the global minimum of F (x). When K = 10 we can compute x∗ using dynamic programming over the columns of G. In our experiments we quantify the quality of a potential solution x using two different measures: (1) the value of F (x), and (2) the Hamming distance between x and x∗. Table 2 shows the results of various algorithms we evaluated on 20 random problem instances.\nWe compare the results of the following algorithms:\nDP Dynamic programming over the columns of G. Dynamic programming finds the global mini-\nmum of F (x) but has a runtime that is exponential in K.\nICM Iterative conditional modes [5]. This is a simple local search technique that considers changing\nthe label of a single vertex at a time.\nS The fixed point algorithm defined by S with p = 0.01 and wij = 1/d(i).\nT The fixed point algorithm defined by T with p = 0.01 and wij = 1/d(i).\nBP Loopy belief propagation with a damping factor of 0.5.\nTRWS Sequential tree-reweighted message passing [16].\nADSAL Adaptive Diminishing Smoothing [21]. This algorithm is based on the local polytope LP\nrelaxation of optimization problem defined by F .\nAll of the algorithms were implemented in C++. For BP, TRWS and ADSAL we used the implementation available in OpenGM2 [1]. We also consider the result of applying local-search (ICM) to the output of each algorithm. All iterative algorithms were run for 1000 iterations.\nWe found that post-processing solutions of different algorithms with local-search (ICM) often gives a substantial improvement. In particular the solutions found by the algorithms defined by S and T are not very good in terms of their energy value when compared to the alternatives. However, the solutions found by S and T improve in energy substantially after post-processing with ICM. We also found that lower energy solutions are sometimes further from the global minimum, in terms of Hamming distance, when compared to higher energy solutions. For example, on average, the energy of the solutions found by BP+ICM is lower the energy of the solutions found by T, but the solutions found by T are closer to the global minimum. After post-processing with ICM the solutions found by S and T and are often closer to the global optimum when compared to the alternatives.\nIn terms of running time the algorithms defined by S and T are more efficient than the alternatives. Each iteration using S or T requires updating a belief for each vertex of G. In contrast, each BP iteration requires updating two messages for each edge of G. Other message passing methods like TRWS are similar to BP. Both S and T require less memory than these other algorithms because they work with beliefs associated with vertices instead of messages associated with edges. Moreover, we find that the fixed point algorithms defined by S and T converge faster than the alternatives. Table 3 compares the results of different algorithms when using a limited number of iterations. The ADSAL algorithm solves a sequence of problems using TRWS as a subroutine. In this case the number of iterations refers to the iterations of the TRWS subroutine."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "The experimental results in the last section illustrate the practical feasibility of the algorithms under study. Our theoretical results prove these algorithms are guaranteed to converge to unique fixed points on graphs with arbitrary topology and with arbitrary pairwise relationships. This includes the case of repulsive interactions which often leads to convergence problems for message passing methods.\nOur results can be extended to other contraction maps similar to T and S and alternative"
    }, {
      "heading" : "S + ICM 35.6 35.6",
      "text" : ""
    }, {
      "heading" : "T + ICM 36.0 36.0",
      "text" : "methods for computing the fixed points of these maps. Some specific directions for future work are as follows.\n1. Asynchronous updates. It is possible to define algorithms that update the beliefs of a single\nvertex at a time in any order. As long as all vertices are updated infinitely many times, the resulting algorithms converge to the same fixed point as the parallel update methods examined in this work. We conjecture that in a sequential computation, the sequential update of vertices in a “sweep” would converge faster than a “parallel” update. Moreover, after a sequential update of all vertices, the neighbors of those vertices with greater change should be the first ones to be updated in the next “sweep”.\n2. Non-backtracking random walks. The algorithms defined by S and T can be understood in\nterms of random walks on G. It is possible to define alternative algorithms based on nonbacktracking random walks. In particular, starting with the MDP in Section 4 we can increase the state-space Q to keep track of the last vertex visited in the walk and define transition probabilities that avoid the previous vertex when selecting the next one. The resulting value iteration algorithm becomes very similar to belief propagation and other message passing methods that involve messages defined on the edges of G.\nAcknoledgements\nWe thank the anonymous reviewers for many helpful comments and suggestions."
    } ],
    "references" : [ {
      "title" : "Nonserial Dynamic Programming",
      "author" : [ "U. Bertele", "F. Brioschi" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1972
    }, {
      "title" : "Dynamic Programming and Optimal Control",
      "author" : [ "Dimitry P. Bertsekas" ],
      "venue" : "Athena Scientific,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2005
    }, {
      "title" : "Spatial interaction and the statistical analysis of lattice systems",
      "author" : [ "Julian Besag" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1974
    }, {
      "title" : "On the statistical analysis of dirty pictures",
      "author" : [ "Julian Besag" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1986
    }, {
      "title" : "Pseudo-boolean optimization",
      "author" : [ "Endre Boros", "Peter L Hammer" ],
      "venue" : "Discrete applied mathematics,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2002
    }, {
      "title" : "Fast approximate energy minimization via graph cuts",
      "author" : [ "Yuri Boykov", "Olga Veksler", "Ramin Zabih" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2001
    }, {
      "title" : "Efficient belief propagation for early vision",
      "author" : [ "Pedro F Felzenszwalb", "Daniel P Huttenlocher" ],
      "venue" : "International Journal of Computer Vision,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2006
    }, {
      "title" : "Distance transforms of sampled functions",
      "author" : [ "Pedro F. Felzenszwalb", "Daniel P. Huttenlocher" ],
      "venue" : "Theory of Computing,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2012
    }, {
      "title" : "Dynamic programming and graph algorithms in computer vision",
      "author" : [ "Pedro F. Felzenszwalb", "Ramin Zabih" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2011
    }, {
      "title" : "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images",
      "author" : [ "S. Geman", "D. Geman" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1984
    }, {
      "title" : "Exact maximum a posteriori estimation for binary images",
      "author" : [ "D.M. Greig", "B.T. Porteous", "A.H. Seheult" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1989
    }, {
      "title" : "Approximation algorithms for classification problems with pairwise relationships: Metric labeling and markov random fields",
      "author" : [ "Jon Kleinberg", "Eva Tardos" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2002
    }, {
      "title" : "Probabilistic Graphical Models",
      "author" : [ "Daphne Koller", "Nir Friedman" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2009
    }, {
      "title" : "Convergent tree-reweighted message passing for energy minimization",
      "author" : [ "Vladimir Kolmogorov" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2006
    }, {
      "title" : "What energy functions can be minimized via graph cuts",
      "author" : [ "Vladimir Kolmogorov", "Ramin Zabih" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2004
    }, {
      "title" : "Random walks on graphs: A survey",
      "author" : [ "László Lovász" ],
      "venue" : "Combinatorics, Paul Erdos is Eighty,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1993
    }, {
      "title" : "Convergent message passing algorithms: a unifying view",
      "author" : [ "Talya Meltzer", "Amir Globerson", "Yair Weiss" ],
      "venue" : "In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2009
    }, {
      "title" : "Message-passing for graphstructured linear programs: Proximal methods and rounding schemes",
      "author" : [ "Pradeep Ravikumar", "Alekh Agarwal", "Martin J Wainwright" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2010
    }, {
      "title" : "Efficient MRF energy minimization via adaptive diminishing smoothing",
      "author" : [ "Bogdan Savchynskyy", "Stefan Schmidt", "Jörg Kappes", "Christoph Schnörr" ],
      "venue" : "In Uncertainty in AI,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    }, {
      "title" : "Map estimation via agreement on trees: message-passing and linear programming",
      "author" : [ "Martin J Wainwright", "Tommi S Jaakkola", "Alan S Willsky" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2005
    }, {
      "title" : "Graphical models, exponential families, and variational inference",
      "author" : [ "Martin J. Wainwright", "Michael I. Jordan" ],
      "venue" : "Foundations and Trends R © in Machine Learning,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Energy minimization methods based on Markov random fields (MRF) address these problems in a common framework [4, 23, 15].",
      "startOffset" : 109,
      "endOffset" : 120
    }, {
      "referenceID" : 20,
      "context" : "Energy minimization methods based on Markov random fields (MRF) address these problems in a common framework [4, 23, 15].",
      "startOffset" : 109,
      "endOffset" : 120
    }, {
      "referenceID" : 12,
      "context" : "Energy minimization methods based on Markov random fields (MRF) address these problems in a common framework [4, 23, 15].",
      "startOffset" : 109,
      "endOffset" : 120
    }, {
      "referenceID" : 8,
      "context" : "This approach has been applied to a variety of problems in image processing and computer vision [11].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 9,
      "context" : "A classical example involves restoring corrupted images [12, 5].",
      "startOffset" : 56,
      "endOffset" : 63
    }, {
      "referenceID" : 3,
      "context" : "A classical example involves restoring corrupted images [12, 5].",
      "startOffset" : 56,
      "endOffset" : 63
    }, {
      "referenceID" : 0,
      "context" : "The optimization problem can be solved in polynomial time using dynamic programming when G is a tree [2].",
      "startOffset" : 101,
      "endOffset" : 104
    }, {
      "referenceID" : 20,
      "context" : "Min-sum (max-product) belief propagation [23, 15] is a local message passing algorithm that is equivalent to dynamic programming when G is a tree.",
      "startOffset" : 41,
      "endOffset" : 49
    }, {
      "referenceID" : 12,
      "context" : "Min-sum (max-product) belief propagation [23, 15] is a local message passing algorithm that is equivalent to dynamic programming when G is a tree.",
      "startOffset" : 41,
      "endOffset" : 49
    }, {
      "referenceID" : 1,
      "context" : "The map defined by S corresponds to value iteration for a Markov decision process (MDP) [3] defined by random walks on G.",
      "startOffset" : 88,
      "endOffset" : 91
    }, {
      "referenceID" : 20,
      "context" : "This approach is related to mean field methods and variational inference with the Gibbs distribution p(X = x) [23, 15].",
      "startOffset" : 110,
      "endOffset" : 118
    }, {
      "referenceID" : 12,
      "context" : "This approach is related to mean field methods and variational inference with the Gibbs distribution p(X = x) [23, 15].",
      "startOffset" : 110,
      "endOffset" : 118
    }, {
      "referenceID" : 11,
      "context" : "3 Related Work For general graphs G, when the pairwise costs hij(a, b) define a metric over L there are polynomial time approximation algorithms for the optimization problem defined by F [14].",
      "startOffset" : 187,
      "endOffset" : 191
    }, {
      "referenceID" : 10,
      "context" : "In some important cases the optimization problem can be solved using graph cuts and maximum flow algorithms [13, 8, 7, 17].",
      "startOffset" : 108,
      "endOffset" : 122
    }, {
      "referenceID" : 5,
      "context" : "In some important cases the optimization problem can be solved using graph cuts and maximum flow algorithms [13, 8, 7, 17].",
      "startOffset" : 108,
      "endOffset" : 122
    }, {
      "referenceID" : 4,
      "context" : "In some important cases the optimization problem can be solved using graph cuts and maximum flow algorithms [13, 8, 7, 17].",
      "startOffset" : 108,
      "endOffset" : 122
    }, {
      "referenceID" : 14,
      "context" : "In some important cases the optimization problem can be solved using graph cuts and maximum flow algorithms [13, 8, 7, 17].",
      "startOffset" : 108,
      "endOffset" : 122
    }, {
      "referenceID" : 10,
      "context" : "This includes in particular the case of MAP estimation for an Ising model with an external field [13].",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 20,
      "context" : "The algorithms we study are closely related to message passing methods, in particular to minsum (or equivalently max-product) belief propagation (BP) [23, 15].",
      "startOffset" : 150,
      "endOffset" : 158
    }, {
      "referenceID" : 12,
      "context" : "The algorithms we study are closely related to message passing methods, in particular to minsum (or equivalently max-product) belief propagation (BP) [23, 15].",
      "startOffset" : 150,
      "endOffset" : 158
    }, {
      "referenceID" : 19,
      "context" : "The optimization problem can be posed using a LP with a large number of constraints and relaxed to obtain a tractable LP over the local polytope [22].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 16,
      "context" : "Several message passing methods have been motivated in terms of this LP [19].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 17,
      "context" : "There are also recent methods which use message passing in the inner loop of an algorithm that converges to the optimal solution of the local polytope LP relaxation [20, 21].",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 18,
      "context" : "There are also recent methods which use message passing in the inner loop of an algorithm that converges to the optimal solution of the local polytope LP relaxation [20, 21].",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 20,
      "context" : "The mean-field algorithm [23, 15] is an iterative method for approximating the Gibbs distribution p(x) by a factored distribution q(x),",
      "startOffset" : 25,
      "endOffset" : 33
    }, {
      "referenceID" : 12,
      "context" : "The mean-field algorithm [23, 15] is an iterative method for approximating the Gibbs distribution p(x) by a factored distribution q(x),",
      "startOffset" : 25,
      "endOffset" : 33
    }, {
      "referenceID" : 7,
      "context" : "In many applications, including in image restoration and stereo matching, the pairwise cost hij has special structure that allows for faster computation using the techniques described in [10].",
      "startOffset" : 187,
      "endOffset" : 191
    }, {
      "referenceID" : 15,
      "context" : "This choice leads to uniform random walks on G [18].",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 19,
      "context" : "We note that the LP formulation described here is different from the standard LP relaxation for minimizing F (x) which involves the local polytope described in [22].",
      "startOffset" : 160,
      "endOffset" : 164
    }, {
      "referenceID" : 1,
      "context" : "We start by showing that S corresponds to value iteration for an infinite horizon discounted Markov decision process (MDP) [3].",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 1,
      "context" : "The map L is known to be a γ-contraction [3] with respect to the ‖ · ‖∞ norm.",
      "startOffset" : 41,
      "endOffset" : 44
    }, {
      "referenceID" : 9,
      "context" : "A classical approach to solve this problem involves looking for a piecewise smooth image x that is similar to y [12, 6].",
      "startOffset" : 112,
      "endOffset" : 119
    }, {
      "referenceID" : 6,
      "context" : "We based our implementations on the belief propagation code from [9], which provides efficient methods for handling truncated quadratic discontinuity costs.",
      "startOffset" : 65,
      "endOffset" : 68
    }, {
      "referenceID" : 6,
      "context" : "We note that the results in Figure 3 are similar to results obtained min-sum belief propagation shown in [9].",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 3,
      "context" : "ICM Iterative conditional modes [5].",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 13,
      "context" : "TRWS Sequential tree-reweighted message passing [16].",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 18,
      "context" : "ADSAL Adaptive Diminishing Smoothing [21].",
      "startOffset" : 37,
      "endOffset" : 41
    } ],
    "year" : 2015,
    "abstractText" : "We define two algorithms for propagating information in classification problems with pairwise relationships. The algorithms are based on contraction maps and are related to non-linear diffusion and random walks on graphs. The approach is also related to message passing algorithms, including belief propagation and mean field methods. The algorithms we describe are guaranteed to converge on graphs with arbitrary topology. Moreover they always converge to a unique fixed point, independent of initialization. We prove that the fixed points of the algorithms under consideration define lower-bounds on the energy function and the max-marginals of a Markov random field. The theoretical results also illustrate a relationship between message passing algorithms and value iteration for an infinite horizon Markov decision process. We illustrate the practical application of the algorithms under study with numerical experiments in image restoration, stereo depth estimation and binary classification on a grid.",
    "creator" : "LaTeX with hyperref package"
  }
}