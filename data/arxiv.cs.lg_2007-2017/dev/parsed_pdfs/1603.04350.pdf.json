{
  "name" : "1603.04350.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "An optimal algorithm for bandit convex optimization",
    "authors" : [ "Elad Hazan", "Yuanzhi Li" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "√ T )-regret algorithm for this setting based\non a novel application of the ellipsoid method to online learning. This bound is known to be tight up to logarithmic factors. Our analysis introduces new tools in discrete convex geometry."
    }, {
      "heading" : "1 Introduction",
      "text" : "In the setting of Bandit Convex Optimization (BCO), a learner repeatedly chooses a point in a convex decision set. The learner then observes a loss which is equal to the value of an adversarially chosen convex loss function. The only feedback available to the learner is the loss — a single real number. Her goal is to minimize the regret, defined to be the difference between the sum of losses incurred and the loss of the best fixed decision (point in the decision set) in hindsight.\nThis fundamental decision making setting is extremely general, and has been used to efficiently model online prediction problems with limited feedback such as online routing, online ranking and ad placement, and many others (see [8] and [17] chapter 6 for applications and a detailed survey of BCO). This generality and importance is accompanied by significant difficulties: BCO allows for an adversarially chosen cost functions, and extremely limited information is available to the leaner in the form of a single scalar per iteration. The extreme exploration-exploitation tradeoff common in bandit problems is accompanied by the additional challenge of polynomial time convex optimization to make this problem one of the most difficult encountered in learning theory.\nAs such, the setting of BCO has been extremely well studied in recent years and the state-of-the-art significantly advanced. For example, in case the adversarial cost functions are linear, efficient algorithms are known that guarantee near-optimal regret bounds [2, 9, 18]. A host of techniques have been developed to tackle the difficulties of partial information, exploration-exploitation and efficient convex optimization. Indeed, most known optimization and algorithmic techniques have been applied, including interior point methods [2], random walk optimization [23], continuous multiplicative updates [13], random perturbation [6], iterative optimization methods [15] and many more.\nDespite this impressive and the long lasting effort and progress, the main question of BCO remains unresolved: construct an efficient and optimal regret algorithm for the full setting of BCO. Even the optimal regret attainable is yet unresolved in the full adversarial setting.\nA significant breakthrough was recently made by [10], who show that in the oblivious setting and in the special case of 1-dimensional BCO, O( √ T ) regret is attainable. Their result is existential in nature, showing that the minimax regret for the oblivious BCO setting (in which the adversary decides upon a distribution over cost functions independently of the learners’ actions) behaves as Θ̃( √ T ). This result was very recently extended to any dimension by [11], still with an existential bound rather than an explicit algorithm and in the oblivious setting. ∗Princeton University, Email: ehazan@cs.princeton.edu †Princeton University, Email: yuanzhil@cs.princeton.edu\nar X\niv :1\n60 3.\n04 35\n0v 1\n[ cs\n.L G\n] 1\n4 M\nar 2\n01 6\nIn this paper we advance the state of the art in bandit convex optimization and show the following results:\n1. We show that minimax regret for the full adversarial BCO setting is Θ̃( √ T ).\n2. We give an explicit algorithm attaining this regret bound. Such an explicit algorithm was unknown previously even for the oblivious setting. 3. The algorithm guarantees Θ̃( √ T ) regret with high probability and exponentially decaying tails. Specifi-\ncally, the algorithm guarantees regret of Θ̃( √ T log 1δ ) with probability at least 1− δ.\nIt is known that any algorithm for BCO must suffer regret Ω( √ T ) in the worst case, even for oblivious adversaries and linear cost functions. Thus, up to logarithmic factors, our results close the gap of the attainable regret in terms of the number of iterations.\nTo obtain these results we introduce some new techniques into online learning, namely a novel online variant of the ellipsoid algorithm, and define some new notions in discrete convex geometry.\nWhat remains open? Our algorithms depend exponentially on the dimensionality of the decision set, both in terms of regret bounds as well as in computational complexity. As of the time of writing, we do not know whether this dependencies are tight or can be improved to be polynomial in terms of the dimension, and we leave it as an open problem to resolve this question1"
    }, {
      "heading" : "1.1 Prior work",
      "text" : "The best known upper bound in the regret attainable for adversarial BCO with general convex loss functions is Õ(T 5/6) due to [15] and [21] 2. A lower bound of Ω( √ T ) is folklore, even the easier full-information setting of online convex optimization, see e.g. [17]. The special case of bandit linear optimization (BCO in case where the adversary is limited to using linear losses) is significantly simper. Informally, this is since the average of the function value on a sphere around a center point equals the value of the function in the center, regardless of how large is the sphere. This allows for very efficient exploration, and was first used by [13] to devise the Geometric Hedge algorithm that achieves an optimal regret rate of Õ( √ T ). An efficient algorithm inspired by interior point methods was later given by [2] with the same optimal regret bound. Further improvements in terms of the dimension and other constants were subsequently given in [9, 18].\nThe first gradient-descent-based method for BCO was given by [15]. Their regret bound was subsequently improved for various special cases of loss functions using ideas from [2]. For convex and smooth losses, [24] attained an upper bound on the regret of of Õ(T 2/3). This was recently improved to by [14] to Õ(T 5/8). [3] obtained a regret bound of Õ(T 2/3) for strongly-convex losses. For the special case of strongly-convex and smooth losses, [3] obtained a regret of Õ( √ T ) in the unconstrained case, and [19] obtain the same rate even in the constrained cased. [25] gives a lower bound of Ω( √ T ) for the setting of strongly-convex and smooth BCO.\nA comprehensive survey by Bubeck and Cesa-Bianchi [8], provides a review of the bandit optimization literature in both stochastic and online setting.\nAnother very relevant line of work is that on zero-order convex optimization. This is the setting of convex optimization in which the only information available to the optimizer is a valuation oracle that given x ∈ K for some convex set K ⊆ Rd, returns f(x) for some convex function f : K 7→ R (or a noisy estimate of this number). This is considered one of the hardest areas in convex optimization (although strictly a special case of BCO), and a significant body of work has culminated in a polynomial time algorithm, see [12]. Recently, [4] give a polynomial time algorithm for regret minimization in the stochastic setting of zero-order optimization, greatly improving upon the known running times.\n1In the oblivious setting [11] show that the regret behaves polynomially in the dimension. It is not clear if this result can be extended to the adversarial setting.\n2although not specified precisely to the adversarial setting, this result is implicit in these works."
    }, {
      "heading" : "1.2 Paper structure",
      "text" : "In the next section we give some basic definitions and constructs that will be of use. In section 3 we survey a natural approach, motivated by zero-order optimization, and explain why completely new tools are necessary to apply it. We proceed to give the new mathematical constructions for discrete convex geometry in section 4. This is followed by our main technical lemma, the discretization lemma, in section 5. We proceed to give the new algorithm and the main result statement in section 6."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "The setting of bandit convex optimization (BCO) is a repeated game between an online learner and an adversary (see e.g. [17] chapter 6). Iteratively, the learner makes a decision which is a point in a convex decision set, which is a subset of Euclidean space xt ∈ K ⊆ Rd. Meanwhile, the adversary responds with an arbitrary Lipschitz convex loss function ft : K 7→ R. The only feedback available to the learner is the loss, ft(xt) ∈ R, and her goal is to minimize regret, defined as\nRT = ∑ t ft(xt)− min x∗∈K ∑ t ft(x ∗)\nLet K ⊆ Rd be a convex compact and closed subset in Euclidean space. We denote by EK the minimal volume enclosing ellipsoid (MVEE) in K, also known as the John ellipsoid [20, 7]. For simplicity, assume that EK is centered at zero.\nGiven an ellipsoid E = { ∑ i αivi : ∑ i α 2 i ≤ 1}, we shall use the notation ‖x‖E ≡ √ x>(V V >)−1x to denote the (Minkowski) semi-norm defined by the ellipsoid, where V is the matrix with the vectors vi’s as columns.\nJohn’s theorem says that if we shrink MVEE of K by a factor of 1/d, then it will be inside K. For connivence, we denote by ‖ · ‖K the norm according to 1dEK, which is the matrix norm corresponding to the (shrinked by factor 1/d) MVEE ellipsoid of K . To be specific, Let E be the MVEE of K,\n‖x‖K = d‖x‖E = ‖x‖ 1 dE\nWe use d‖x‖E inside of ‖x‖E merely to insure ∀x /∈ K, ‖x‖K ≥ 1, which simplifies our expression.\nEnclosing box. Denote by CK the bounding box of the ellipsoid EK, which is obtained by the box with axis parallel to the eigenpoles of EK. The containing box CK can be computed by first computing EK, then the diagonal transformation of this ellipsoid into a ball, computing the minimal enclosing cube of this ball, and performing the inverse diagonal transformation into a box.\nDefinition 2.1 (Minkowski Distance of a convex set). Given a convex set K ⊂ Rd and x ∈ Rd, the Minkowski distance γ(x,K) is defined as γ(x,K) = ||x− x0||K−x0 Where x0 is the center of the MVEE of K. K−x0 denotes shifting K by−x0 (so its MVEE is centered at zero)\nDefinition 2.2 (Scaled set). For β > 0, define βK as the scaled set 3\nβK = {y | γ(y,K) ≤ β}\nHenceforth we will require a discrete representation of convex sets, which we call grids, as constructed in Algorithm 1.\nClaim 2.1. For every K ∈ Rd, grid = grid(K, α) contains at most (2dα)d many points 3According to our definition of γ, 1K ⊆ K ⊆ dK\nAlgorithm 1 construct grid 1: Input: convex set K ∈ Rd, resolution α. 2: Compute the MVEE E ′ of K. Let E = 1dE ′\n3: Let A be the (unique) linear transformation such that A(E) = Bα(0) (unit ball of radius α centered at 0). 4: Let Zd = {(x1, ..., xd), xi ∈ Z} be d-dimensional integer lattice. 5: Output: grid = A−1(Z) ∩ K.\nLemma 2.1 (Property of the grid). LetK′ ⊆ K ⊆ Rd 4 be two convex sets. For every β, γ such that β > γ > 1, β > d, for every α ≥ 2(γ + 1)β2 √ d such that the following holds. Let grid = grid(βK′ ∩ K, α), then we have:\n1. For every x ∈ K′: ∃xg ∈ grid such that xg + γ(xg − x) ∈ 12βK ′\n2. For every x /∈ K′, x ∈ K: ∃xg ∈ grid such that xg + γγ(x,K′) (xg − x) ∈ 1 2βK ′\nProof of Lemma 2.1. Since β > d, by John’s theorem, K′ ⊂ βK′. Moreover, since we only interested in the distance ratio, we can assume that the MVEE E ′ of βK′ ∩ K is the ball centered at 0 of radius dα, and grid are all the integer points intersected with βK′ ∩ K. Let E = 1dE\n′ = Bα(0), by John’s Theorem, we know that E ⊆ βK′ ∩ K ⊆ dE .\n(a). For every x ∈ K′, consider point z = γγ+1x. Since E = Bα(0) ⊆ βK ′, we know that Bα β (0) ⊆ K′.\nTherefore, B α γβ\n(z) ⊆ K′, which implies when α ≥ γβ √ d, we can find xg ∈ grid such that ‖xg − z‖2 ≤ √ d.\nTherefore,\n‖xg + γ(xg − x)‖2 = ‖ [z + γ(z − x)] + [xg − z + γ(xg − z)] ‖2 = ||xg − z + γ(xg − z)||2 since z + γ(z − x) = 0 = (γ + 1)‖xg − z‖2 ≤ (γ + 1) √ d by ‖xg − z‖ ≤ √ d\nMoreover, 12βK ⊇ 1 2β2 E = 1 2β2Bα(0) contains all points with norm α 2β2 , and in particular it contains xg + γ(xg − x) when α ≥ 2(γ + 1)β2 √ d.\n(b). For every x /∈ K′ but x ∈ K, take z = γγ(x,K′)+γx. When β > 2γ, we know that z ∈ 1 2βK ′. With same idea as (a), we can also conclude that\nB γ(x,K′) γ(x,K′)+γ α β2\n(z) ⊆ βK′ ∩ K\n4We will apply the lemma to K′ being our working Ellipsoid and K being the original input convex set\nSince γ(x,K′) ≥ 1 for x /∈ K′, we can find xg ∈ grid be such that ‖xg−z‖2 ≤ √ dwhen α ≥ (γ+1)β2 √ d.\nTherefore,\n∥∥∥∥xg + γγ(x,K) (xg − x) ∥∥∥∥\n2\n= ∥∥∥∥[z + γγ(x,K) (z − x) ] + [ xg − z +\nγ\nγ(x,K) (xg − z) ]∥∥∥∥ 2\n= ∥∥∥∥xg − z + γγ(x,K) (xg − z) ∥∥∥∥\n2\nsince z + γγ(x,K) (z − x) = 0\n= ( 1 +\nγ\nγ(x,K)\n) ‖xg − z‖2 ≤ ( γ\nγ(x,K) + 1\n)√ d\n≤ (1 + γ) √ d since γ(x,K) ≥ 1\nAs before, this implies that when α ≥ 2(γ + 1)β2 √ d, it holds that xg + γγ(x,K) (xg − x) ∈ 1 2βK."
    }, {
      "heading" : "2.1 Non-stochastic bandit algorithms",
      "text" : "Define the following\n(pt, vt, σt)← A(S, {pt−1, f1:t−1})\npt: A probability distribution over the discrete set S vt: Estimation of the values of F t = ∑t i=1 fi on S. σt: Variance, such that for every x ∈ S, vt(x)− σt(x) ≤ Ft(x) ≤ vt(x) + σt(x). For xt picking according to distribution pt, define the regret of A as:\nRT = ∑ t ft(xt)−min x {∑ t ft(x) }\nThe following theorem was essentially established in [5] (although the original version was stated for gains instead of losses, and had known horizon parameter), for the algorithm called EXP3.P, which is given in Appendix 8 for completeness:\nTheorem 2.1 ([5]). Algorithm EXP3.P over N arms guarantees that with probability at least 1− δ,\nRT = ∑ t ft(xt)−min x {∑ t ft(x) } ≤ 8 √ TN log TN δ"
    }, {
      "heading" : "3 The insufficiency of convex regression",
      "text" : "Before proceeding to give the main technical contributions of this paper, we give some description of the technical difficulties that are encountered and intuition as to how they are resolved.\nA natural approach for BCO, and generally for online learning, is to borrow ideas from the less general setting of stochastic zero-order optimization. Till recently, the only polynomial time algorithm for zero-order optimization was based on the ellipsoid method [16]. Roughly speaking, the idea is to maintain a subset, usually an ellipsoid, in space in which the minimum resides, and iteratively reduce the volume of this region till it is ultimately found.\nIn order to reduce the volume of the ellipsoid one has to find a hyperplane separating the minimum and a large constant fraction of the current ellipsoid in terms of volume. In the stochastic case, such a hyperplane can be found by sampling and estimating a sufficiently indicative region of space. A simple way to estimate the\nunderlying convex function in the stochastic setting is called convex regression (although much more time and query-efficient methods are known, e.g. [4]).\nFormally, given noisy observations from a convex function f : K 7→ Rd, denoted {v(x1), ..., v(xn)}, such that v(xi) is a random variable whose expectation is f(xi), the problem of convex regression is to create an estimator of the value of f over the entire space which is consistent, i.e. approaches its expectation as the number of observations increases n 7→ ∞. The methodology of convex regression proceeds by solving a convex program to minimize the mean square error and ensuring convexity by adding gradient constraints, formally,\nmin n∑ i=1 (v(xi)− yi)2 yj ≥ yi +∇>i (xj − xi)\nIn this convex program {∇i, yi} are variables, points xi are chosen by the algorithm designer to observe, and v(xi) the observed values from sampling. Intuitively, there are nd + n degrees of freedom (n scalars and n vectors in d dimensions) and O(n2) constraints, which ensures that this convex program has a unique solution and generates a consistent estimator for the values of f w.h.p. (see [22] for more details).\nThe natural approach of iteratively applying convex regression to find a separating hyperplane within an ellipsoid algorithm fails for BCO because of the following difficulties:\n1. The ellipsoid method was thus far not applied successfully in online learning, since the optimum is not fixed and can change in response to the algorithms’ behavior. Even within a particular ellipsoid, the optimal strategy is not stationary.\n2. Estimation using convex regression over a fixed grid is insufficient, since arbitrarily deep “valleys” can hide between the grid points.\nOur algorithm and analysis below indeed follows the general ellipsoidal scheme, and overcomes these difficulties by:\n1. The ellipsoid method is applied with an optional “restart button”. If the algorithm finds that the optimum is not within the current ellipsoidal set, it restarts from scratch. We show that by the time this happens, the algorithm has accumulated so much negative regret that it only helps the player. Further, inside each ellipsoid we use the standard multiarmed bandit algorithm EXP3.P due to [5], to exploit and explore it.\n2. A new estimation procedure is required to ensure that no valleys are missed. For this reason we develop some new machinery in convex geometry and convex regression that we call the lower convex envelope of a function. This is a convex lower bound on the original function that ensures there are no valleys missed, and in addition needs only constant-precision grids for being consistent with the original function.\nThis contribution is the most technical part of the paper, as culminates in the ”discretization lemma”, and can be skimmed at first read."
    }, {
      "heading" : "4 Geometry of discrete convex function",
      "text" : ""
    }, {
      "heading" : "4.1 Lower convex envelopes of continuous and discrete convex functions",
      "text" : "Bandit algorithms generate a discrete set of evaluations, which we have to turn into convex functions. The technical definitions that allow this are called lower convex envelopes (LCE), which we define below. First, for continuous but non-convex function f , we can define the LCE denoted FLCE(f) as the maximal convex function that bounds f from below, or formally,\nDefinition 4.1 (Simple Lower Convex Envelope). Given a function f : K → R (not necessarily convex) where K ⊂ Rd, the simple lower convex envelope FSLCE = SLCE(f) : K → R is a convex function defined as:\nFSLCE(x) = min { s∑ i=1 λif(yi) ∣∣∣∣∣ ∃s ∈ N∗, y1, ..., ys ∈ K : ∃(λ1, ..., λs) ∈ ∆s, x = ∑ i λiyi }\nIt can be seen that FSLCE is always convex, by showing for every x, y ∈ K that f( 12x + 1 2y) ≤ 1 2f(x) + 1 2f(y), which follows from the definition. Further, for a convex function, FSLCE(f) = f , since for a convex function any convex combination of points satisfy f( ∑ i λiyi) ≤ ∑ i λif(yi), and the minimum in the definition is realized at the point x itself. For a discrete function, the SLCE is defined to be the SLCE of the piecewise linear continuation. We will henceforth need a significant generalization of this notion, both for the setting above, and for the setting in which the discrete function is given as a random variable - on each point in the grid we have a value estimation and variance estimate. We first define the minimal extension, and then the SLCE of this minimal extension.\nDefinition 4.2 (Random Discrete Function). A Random Discrete Function (RDF), denoted (X, v, σ), is a mapping f : X → R2 on a discrete domain X = {x1, ..., xk} ⊆ K ⊆ Rd, and range of values and variances denoted {v(x), σ(x), x ∈ X} such that f(xi) = (v(xi), σ(xi)).\nDefinition 4.3 (Minimal Extension of a Random Discrete Function). Given a RDF (X, v, σ), we define f̃ imin(X, v, σ) : K → R as\nf̃ imin(x) = min h∈Rd:∀xj ,〈h,xj−xi〉≤v(xj)+σ(xj)−[v(xi)−σ(xi)] {〈h, x− xi〉+ [v(xi)− σ(xi)]}\nThe minimal extension f̃min(X, v, σ) is now defined as\nf̃min(x) = max i∈[k]\nf̃ imin(x)\nWe can now define the LCE of a discrete random function\nDefinition 4.4 (Lower convex envelope of a random discrete function). Given a RDF (X, v, σ) over domain X = grid ⊆ K ⊆ Rd, for the grid for K as constructed in Algorithm 1, its lower convex envelope is defined to be\nFLCE(X, v, σ) = FSLCE(f̃min(X, v, σ))\nWe now address the question of computation of an LCE of a discrete function, or how to provide oracle access to the LCE efficiently. The following theorem and algorithm establish the computational part of this section, whose proof is deferred to the appendix.\nAlgorithm 2 Fit-LCE 1: Input: RDF (X, v, σ), and a convex set K where X ⊆ K. 2: (minimal extension): Compute the minimal extension f̃min(X, v, σ) : CK → R (see Section 2 for definition\nof the bounding box C) 3: (LCE) Compute and return FLCE = SLCE(f̃min).\nTheorem 4.1 (LCE computation). Given a discrete random function over k points {x1, ..., xk} in a polytope K ⊆ Rd defined by N = poly(d) halfspaces, with confidence intervals [v(xi)− σ(xi), v(xi) + σ(xi)] for each point xi, then for every x ∈ K, the value FLCE(x) can be computed in time O ( kd 2 )\nTo prove the running time of LCE computation, we need the following Lemma:\nLemma 4.1 (LCE properties). The lower convex envelope (LEC) has the follow properties:\n1. f̃min is a piece-wise linear function with kO(d 2) different regions, each region is a polytope with d + 1\nvertices. We denote all the vertices of all regions as v1, ..., vn where n = kO(d 2), where each vi and its value f̃min(vi) are computable in time kO(d 2).\n2.\nFLCE(x) = min ∑ i∈[n] λif̃min(vi) ∣∣∣∣∣∣ ∑ i∈[n] λivi = x, (λ1, ..., λn) ∈ ∆n \nProof. Recall the definition of f̃ imin : K → R as\nf̃ imin(x) = min h∈Rd:∀xj ,〈h,xj−xi〉≤v(xj)+σ(xj)−[v(xi)−σ(xi)] {〈h, x− xi〉+ [v(xi)− σ(xi)]}\nThe vector h in the above expression is the result of a linear program. Therefore, it belongs to the vertex set of the polyhedral set given by the inequalities 〈h, xj − xi〉 ≤ v(xj) + σ(xj)− [v(xi)− σ(xi)], or the objective is unbounded, a case which we can ignore since f̃min is finite. The number of vertices of a polyhedral set in Rd defined by k hyperplanes is bounded by ( k d ) ≤ kd.\nThus, f̃ imin is the minimal of a finite set of linear functions at any point in space. This implies that it is a piecewise linear function with at most kd regions. More generally, the minimum of s linear functions is a piece-wise linear function of at most s regions, as we now prove:\nLemma 4.1. The minimum (or maximum) of s linear functions is a piecewise linear function with at most s regions.\nProof. Let f(x) = mini∈[s] fi(x) for linear functions {fi}, the proof for maxi∈[s] fi(x) is analoguous. Consider the sets Si = {x | f(x) = fi(x)}, inside which f = fi is linear. It suffices to show that each Si is a convex set, and thus each Si is a polyhedral region with at most s faces. Now suppose x1, x2 ∈ Si, we want to argue that x3 = x1+x22 ∈ Si: Observe that for every j, fj(x3) = fj(x1)+fj(x2) 2 (this is because fj is linear). If there is a j such that fj(x3) < fi(x3), then either fj(x1) < fi(x1) or fj(x2) < fi(x2), contradict to the fact that x1, x2 ∈ Si.\nNext we consider f̃min(x) = max\ni∈[k] f̃ imin(x)\nRecall that each f̃ imin is piecewise linear with s = k d regions who are determined by at most s hyperplanes. Consider regions in which all these functions are jointly linear, we would like to bound the number of such regions. These regions are created by the hyperplanes that create the regions of the functions f̃ imin, a total of at most ks hyperplanes, plus N hyperplanes of the bounding polytope K. The number of regions these hyperplanes create is at most (N + ks)2 [1]. In each such region, the functions f̃ imin are linear, and according to the previous lemma there are at most k sub-regions, giving a total of k× (N+ks)2 ≤ kN2 +k3d polyhedral regions within which the function f̃min is linear.\nThe vertices of these regions can be computed by taking all d intersections of the (N + ks)2 hyperplanes and solving a system of d equations, in overall time (N + ks)2d = kO(d\n2). 2. By definition of FLCE, there exists points p1, ..., pm ∈ K and (λ1, ..., λm) ∈ ∆m such that\nFLCE(x) = ∑ i∈[m] λif̃min(pi), ∑ i∈[m] λipi = x (1)\nBy part 1, f̃min is a piece-wise linear function, we know that for every i ∈ [m], there exists d + 1 vertices vi1 , ..., vid+1 such that there exists (λi1 , ..., λid+1) ∈ ∆d+1 with ∑ j∈[d+1] λij f̃min(vij ) = f̃min(pi), ∑ j∈[d+1] λijvij = pi. Put it into Equation 1 we get the result.\nHaving Lemma 4.1, we can calculate FLCE by first finding vertices v1, ..., vn and then solve an LP on λi. The algorithm runs in time kO(d 2)"
    }, {
      "heading" : "5 The discretization lemma",
      "text" : "The tools for discrete convex geometry developed in the previous section, and in particular the lower convex envelope, are culminated in the discretization lemma that shows consistency of the LCE for discrete random functions which we prove in this section.\nInformally, the discretization lemma asserts that for any value of a given RDF, the LCE has a point with value at least as large not too far away. Convexity is crucial for this lemma to be true at all, as demonstrated in Figure 3.\nWe now turn to a precise statement of this lemma and its proof:\nLemma 5.1 (Discretization). . Let (X, v, σ) be a RDF on X = Zd ∩ K such that v, σ are non-negative, moreover, for all x ∈ X, v(x) − (8d2 + 1)σ(x) ≥ 0. Assume further that there exists a convex function F : Rd 7→ R such that for all x ∈ X , F (x) ∈ [v(x) − σ(x), v(x) + σ(x)]. Let K′ = CK be the enclosing bounding box for K such that B24d2 (0) ⊆ 4 d2K\n′ ⊆ K ⊆ K′ 5. Define FLCE = LCE(X, v, σ) : K′ → R as in Definition 4.4.\nThen there exists a value r = 23d 2 such that for every y ∈ 14K with Br(y) ⊆ K, there exists a point y′ ∈ Br(y) with FLCE(y′) ≥ 12F (y)."
    }, {
      "heading" : "5.1 Proof intuition in one dimension",
      "text" : "The discretization lemma is the main technical challenge of our result, and as such we first give intuition for the proof for one dimension, for readability purposes only, and for the special case that the input DRF is actually a deterministic function (i.e. all variances are zero, and v(xi) = F (xi) for a convex function F . The full proof is deferred to the appendix.\nProof. Please refer to Figure 4 for an illustration.\nAssume w.l.o.g. that y ∈ Z , otherwise take the nearest point. Assume w.l.o.g that f ′(y) > 0, and thus all points x > y have value larger than F (y). Consider the discrete points {y = x−1, x0, x1, ...., }, and the value of f̃min on these integer points, which by definition has to be equal to F , and thus larger than F (y).\nSince F is increasing in the positive direction, we have that f̃min(x0) ≤ f̃min(x1), and by the definition of f̃min, the gradient from x0 to x1, implies that\n∀z ≥ x1, f̃min(z) ≥ f̃min(x0)\nIn the open interval [x2,∞), the value of the LCE is by definition a convex combination of values f̃min(x) only for points in the range x ∈ [x1,∞). Thus, the function FLCE obtains a value larger than f̃min(x1) ≥ F (y) on all points within this range, which is within a distance of two from y.\nThe proof of the Discretization Lemma requires the following lemmas:\nLemma 5.2 (Convex cover). For every k ∈ N∗, r ∈ R∗, if k convex sets S1, ...,Sk covers a ball in Rd of radius r, then there exists a set Si that contains a ball of radius rkdd .\n5John’s theorem implies 1 d3/2 K′ ⊆ K ⊆ K′ for any convex body K\nProof of Lemma 5.2. Consider the maximum volume contained Ellipsoid Ei of Si ∩ Br(0), we know that the volume of Ei is at least 1/dd the volume of Si ∩ Br(0). Now, since S1, ...,Sk covers Br(0), there exists a set Si ∩ Br(0) of volume at least 1/k fraction of the volume of Br(0). Which implies that Ei has volume at least 1/(kdd) of Br(0), note that Ei ⊆ Br(0), therefore, it contains a ball of radius rkdd .\nLemma 5.3 (Approximation of polytope with integer points). Suppose a polytope Po = conv{v1, ..., vd+1} ⊆ Rd contains B4d8(0), then there exists d+ 1 integer points g1, ..., gd+1 ∈ 2d2Po such that:\n1. Let (λ1, ..., λd+1) ∈ ∆d+1 be the coefficient such that ∑ i λivi = 0, then there exists (λ ′ 1, ..., λ ′ d+1) ∈\n∆d+1 such that ∑ i λ ′ igi = 0. Moreover, 1 2λ ′ i ≤ λi ≤ 2λ′i\n2. For every i ∈ [d+ 1], there exists {λij ∈ ∆d+1} such that λii ≥ 12d2 and\ngi = λ i ivi + ∑ j 6=i λijgj\nProof of Lemma 5.3. Property 1:\nLet ui = 1d2 vi. For every i ∈ [n], since B4d8(0) ⊆ conv{v1, ..., vd+1}, it holds that\nBd (ui) ⊆ conv{v1, ..., vd+1}\nTherefore, we can find integer points around ui in conv{v1, ..., vd+1}. Now, let gi be the closest integer point to ui, which has distance at most d to ui, i.e. ‖gi − ui‖2 ≤ d. Observe that\nBd6 (0) ⊆ conv{2u1, ..., 2ud+1}\nWhich implies that for every i ∈ [d+1], Bd6/2 (ui) ⊆ conv{2u1, ..., 2ud+1}. Therefore, gi ∈ conv{2u1, ..., 2ud+1} = 2 d2Po\nNow we want to show that 0 ∈ conv{g1, ..., gd+1}. Consider a function f : conv{u1, u2, ..., ud+1} → Rd defined as: for x = ∑ i λ ′ iui where (λ ′ 1, λ ′ 2, ..., λ ′ d+1) ∈\n∆d+1: f(x) = ∑ i λ′igi\nObserve that\n‖f(x)− x‖2 = ∥∥∥∥∥ d+1∑ i=1 λ′i (ui − gi) ∥∥∥∥∥ 2 ≤ d\nNotice that for x1, x2 ∈ conv{u1, u2, ..., ud+1},\nf\n( x1 + x2\n2\n) = f(x1) + f(x2)\n2\nWhich implies that f is a linear transformation. Moreover, Bd2(0) ⊆ conv{u1, u2, ..., ud+1}. Therefore, f(Bd2(0)) = ∪x∈Bd2 (0){f(x)} is a convex set, since a linear transformation preserves convexity.\nNow, we want to show that 0 ∈ f(Bd2(0)). Suppose on the contrary 0 /∈ f(Bd2(0)), then we know there is a separating hyperplane going through 0 that separates 0 and f(Bd2(0)). Which implies that there is a point g′ ∈ ∂Bd2(0) such that\ndist(g′, f(Bd2(0))) = min x∈f(Bd2 (0)) ‖x− g′‖ ≥ d2\nIn particular, since f(g′) ∈ f(Bd2(0)), the above equality implies dist(g′, f(g′)) ≥ d2, in contradiction to ‖f(x)− x‖2 ≤ d. Therefore, 0 ∈ f(Bd2(0)) ⊆ conv{g1, ..., gd}.\nWe proceed to argue about the coefficients. Denote gi = ui+bi, and by the above ‖bi‖2 ≤ d. By symmetry it suffices to show that 12λ ′ 1 ≤ λ1 ≤ 2λ′1.\nLet {λ′i} ∈ ∆d+1 be such that ∑ i λ ′ igi = ∑ i λ ′ i(ui + bi) = 0. Then∑\ni λ′iui = − ∑ i λ′ibi\nSince ‖bi‖2 ≤ d, by the triangle inequality it holds that ‖ ∑ i λ ′ ibi‖2 ≤ d, which implies∥∥∥∥∥∑\ni\nλ′iui ∥∥∥∥∥ ≤ d Let H be the hyperplane going through u2, ..., ud+1. Without lost of generality, we can apply a proper rotation (unitary transformation) to put H = {x1 = −a} for some value a > 0, where x1 denotes the first axis. Now, (after rotation) Define b = (b1, ..., bd) = ∑ i λ ′ iui and denote u1 = (a1, ..., ad). The point b is a\nconvex combination of u1 and c := 11−λ′1 ∑ j≥2 λ ′ juj . In addition we know that c1 = −a. Thus, we can write λ′1 as:\nλ′1 = b1 − c1 (u1)1 − c1 = b1 + a a1 + a\nOn the other hand, by ∑ i λiui = 0, we know that\nλ1 = a\na1 + a\nNote that ‖b‖2 ≤ d, which implies |b1| < d. However, by assumption there is a ball centered at 0 of radius 4d6 in conv{u1, ..., ud+1}, which implies a ≥ 4d6 ≥ 4|b1|.\nTherefore 12λ ′ 1 ≤ λ1 ≤ 2λ′1.\nProperty 2: By symmetry, it suffices to show for v1. there exists λ11 ≥ 12d2 and λ\n1 j ≥ 0(j = 2, 3, ..., d + 1), λ11 +∑d+1\nj=2 λ 1 j = 1 such that\ng1 = λ 1 1v1 + d+1∑ j=2 λ1jgj\nConsider a function f : conv{v1, u2, ..., ud+1} → Rd defined as: for x = λ′v1 + ∑d+1 j=2 λ ′ juj where\n(λ′, λ′2, ..., λ ′ d+1) ∈ ∆d+1:\nf(x) = λ′vi + d+1∑ j=2 λ′jgj\nObserve that\n‖f(x)− x‖2 = ∥∥∥∥∥∥ d+1∑ j=2 λ′j (uj − gj) ∥∥∥∥∥∥ 2 ≤ d\nNotice that for x1, x2 ∈ conv{v1, u2, ..., ud+1},\nf\n( x1 + x2\n2\n) = f(x1) + f(x2)\n2\nWhich implies that f is a linear transformation. Moreover, Bd2(g1) ⊆ B2d2 (u1) ⊆ conv{v1, u2, ..., ud+1}. Therefore, f(Bd2(g1)) = ∪x∈Bd2 (g1){f(x)} is a convex set, since a linear transformation preserves convexity.\nNow, we want to show that g1 ∈ f(Bd2(g1)). Suppose on the contrary g1 /∈ f(Bd2(g1)), then we know there is a separating hyperplane going through g1 that separates g1 and f(Bd2(g1)). Which implies that there is a point g′ ∈ Bd2(g1) such that\ndist(g′, f(Bd2(g1))) = min x∈f(Bd2 (g1)) ‖x− g′‖ = d2\nIn particular, since f(g′) ∈ f(Bd2(g1)), the above equality implies dist(g′, f(g′)) ≥ d2, in contradiction to ‖f(x)− x‖2 ≤ d for all x ∈ conv{v1, u2, ..., ud+1}.\nTherefore, there is a point g ∈ Bd2(g1) such that f(g) = g1, i.e. g1 can be written as\ng1 = λ ′v1 + d+1∑ j=2 λ′jgj (λ ′, λ′2, ..., λ ′ d+1) ∈ ∆d+1\nWe proceed to give a bound on the coefficients. Since g1 = f(g), we know that\ng = λ′v1 + d+1∑ j=2 λ′juj\nOn the other hand, observe that (since ∑ j λjuj = 0 as defined in Property 1)\nu1 = 1\nd2 v1 +\n( 1− 1\nd2 ) d+1∑ j=1 λjuj\nBy ‖g − u1‖2 ≤ 2d2, using the same method as Property 1 we can obtain: λ′ ≥ 12d2 Which completes the proof.\nNow we can prove the discretization Lemma. The proof goes by the following steps:\n1. First, suppose the Lemma does not hold, then we can find a large hypercube that is contained inside K′ and has entirely small LCE compared to the value of the point y.\n2. We proceed to identify the points whose f̃min value is associated with the LCE of the large hypercube, these f̃min have small values (compare to F (y)) and span a large region.\n3. We find a simplex of d + 1 points that span a large region in which the same holds, i.e. f̃min value compared to v(y).\n4. Using the approximation Lemma, we find an inner simplex of d + 1 discrete points inside the previous simplex. These discrete points all have f̃min value larger than f(y) by the fact that they are inside the first large region.\n5. We use the definition of f̃min to show that one of the vertices of the outer simplex has value of f̃min larger than f(y), in contradiction to the previous observations.\nProof of Lemma 5.1. Step 1:\nConsider a point y ∈ P with Br(y) ∈ K. By convexity of F , there is a hyperplane H going y such that on one side of the hyperplane, all the points have larger or equal F value than F (y). Therefore, there exists a point y′, a cube Qr′(y′) ⊂ Br(y) centered at y′ with radius r′ = r2√d such that for all integer points z ∈ Qr′(y\n′), F (z) ≥ F (y). Let v1, ..., v2d be the vertex of this cube.\nIf there exists i ∈ [2d] such that FLCE(vi) ≥ 12F (y), then we already conclude the proof. Therefore, we can assume that for all i ∈ [2d], FLCE(vi) < 12F (y). Step 2:\nBy the definition of FLCE, we know that for every i ∈ [2d], there exists pi,1, ...., pi,m ∈ K′ such that vi = ∑ j λi,jpi,j , (λi,1, ..., λi,m) ∈ ∆m with\nFLCE(vi) = ∑ λi,jF̃min(pi,j) < 1\n2 F (y)\nMoreover, by Carathodory’s theorem 6, we can make m = d+ 1. Now we get a set of (d + 1)2d many points Po = {pi,j}i∈[2d],j∈[d+1]. Consider a size d + 1 subset\nJ = {pi1,j1 , ..., pid+1,jd+1} of Po, define convex set\nSJ = { x ∈ Qr′(y′) | ∃(λ1, ..., λd+1) ∈ ∆d+1 : x =\n∑ s λspis,js , ∑ s λsF̃min(pis,js) < 1 2 F (y)\n}\nWe claim that ⋃ J⊆P0,|J|=d+1 SJ = Qr′(y′)\nThis is because for every x ∈ Qr′(y′), there exists vi1 , ..., vid+1 and λ1, ..., λd+1 ∈ ∆d+1 such that∑ s∈[d+1] λsvis = x\nMoreover, for each vi, vi = ∑ j λi,jpi,j . Therefore:\nx = ∑\ns∈[d+1]\nλs ∑ j λis,jpis,j  On the other hand, ∑ s∈[d+1] λs (∑ j λis,jF̃min(pis,j) ) < 12F (y). By Carathodory’s theorem, we can\nmake the sum only contains d+ 1 such pis,j , which proves the claim.\nStep 3: By lemma 5.2, we know that there exists J∗ such that SJ∗ contains a ball Br′′(y′′) inside Qr′(y′) of radius\nr′′ = r ′\n2 √ dkdd\nwhere k = ( (d+1)2d\nd+1\n) ≤ 22d2 and y′′ is an integer point.\nFor simplicity, we denote J∗ = {p1, ..., pd+1}. By the definition of SJ∗ , there exists (λ′′1 , ..., λ′′d+1) ∈ ∆d+1 such that\n1. ∑ i λ′′i pi = y ′′\n6The original Carathedory’s theorem only states for convex combination of points, but the same proof can be extended to convex functions by looking at the graph of the function\n2. ∑ i λ′′i F̃min(pi) < 1 2 F (y)\nStep 4:LetP = conv{p1, ..., pd+1}with center y′′. The above argument implies that Br′′(y′′) ⊆ conv{p1, ..., pd+1}, when r′′ = r ′\n2 √ dkdd ≥ r (2d)2d2 ≥ 4d8. By lemma 5.3, there exists integer points g1, ..., gd+1 ∈ 2d2P (where 2 d2P denotes shrink P of factor 2 d2 according to center y ′′) with\n1. y′′ ∈ conv{g1, ..., gd+1}\n2. For every i ∈ [d+ 1], there exists {λij ∈ ∆d+1} such that λii ≥ 12d2 and\ngi = λ i ipi + ∑ j 6=i λijgj\nThe conditions of the lemma assert that 2d2K ′ ⊆ 12K, by y ′′ ∈ 12K, P ⊆ K ′, we know that 2d2P ⊆ K. This implies that gi ∈ Zd ∩ K, over which the RDF is defined, and we have values v(gi) and σ(gi) to construct F̃min. Step 5: By the fact that gi = λipii + ∑ j 6=i λ i jgj and the definition of F̃min, we know that\nF̃min(pi) ≥ 1\nλii v(gi)− σ(gi)−∑ j 6=i λij [v(gj) + σ(gj)]  Let us write y′′ = ∑ i λ ′ igi : (λ ′ 1, ..., λ\n′ d+1) ∈ ∆d+1. By the fact that pi = 1λii (gi −\n∑ j 6=i λ i jgj) We can\ncalculate:\ny′′ = ∑ i λ′′i pi, where λ′′i λii − ∑ j 6=i λ′′j λ j i λjj = λ′i\nFrom Lemma 5.3 we also obtain that λ′′i ≤ 2λ′i. Moreover, for the interpolation:∑\ni\nλ′′i F̃min(pi)\n≥ ∑ i λ′′i λii v(gi)− σ(gi)−∑ j 6=i λij [v(gj) + σ(gj)]  =\n∑ i λ′′i λii v(gi) + σ(gi)−∑ j 6=i λij [v(gj) + σ(gj)] − 2∑ i λ′′i λii σ(gi)\n= ∑ i λ′′i λii − ∑ j 6=i λ′′j λ j i λjj  [v(gi) + σ(gi)] − 2∑ i λ′′i λii σ(gi)\n= ∑ i λ′i[v(gi) + σ(gi)]− 2 ∑ i λ′′i λii σ(gi)\n≥ ∑ i λ′i[v(gi) + σ(gi)]− 4d2 ∑ i λ′iσ(gi) since λ i i ≥ 1d2 ,λ ′′ i ≤ 2λ′i\n= ∑ i λ′i[v(gi)− (4d2 − 1)σ(gi)]\nBy assumption, since gi is a integer point, we get v(gi)− (8d2 + 1)σ(gi) ≥ 0\nv(gi)− (4d2 − 1)σ(gi) ≥ v(gi) + σ(gi)− 4d2σ(gi) ≥ F (gi)− 4d2σ(gi) since by definition v(gi) + σ(gi) ≥ F (gi)\n≥ F (gi)− v(gi)− σ(gi)\n2 since (8d2 + 1)σ(gi) ≤ v(gi)\n≥ 1 2 F (gi) since by definition v(gi)− σ(gi) ≤ F (gi)\nNote that by the convexity of F , ∑ i λ ′ iF (gi) ≥ F (y′′) ≥ F (y) (last inequality is due to our choice of y′′).\nThus, ∑ i λ′′i F̃min(pi) ≥ ∑ i 1 2 λ′iF (gi) ≥ 1 2 F (y)\nBy contradiction we complete the proof."
    }, {
      "heading" : "6 Algorithm and statement of results",
      "text" : ""
    }, {
      "heading" : "6.1 Algorithm statement and parameter setting",
      "text" : "1. δ > 0 - an upper bound on the failure probability of the algorithm\n2. The desired regret bound ` = ( 2d 4\n(log T )2d log 1δ\n)√ T\n3. resolution of the grid: α = 23d 2 log3 T ≥ γβ2 √ d.\n4. Scaling factor β = 4096d4 log T .\n5. Extension ratio: γ = 2048d4 log T .\n6. Blow up factor η = 8d2 + 1.\n7. Upper bound on the number of epoch τ ≤ 8d2 log T .\nThis algorithm calls upon two subroutines, FitLCE which was defined in section 4, and ShrinkSet which we now define.\nAlgorithm 3 Bandit Ellipsoid 1: Input: A convex set K ⊆ Rd, A: a high-probability low regret bandit algorithm on discrete set of points 2: Initialize: Epoch τ = 0, epoch set Γτ = ∅, Kτ = K, Grid gridτ = grid(βKτ ∩ K) 3: for t = 1 to T do 4: Apply the low-regret algorithm on current grid:\n(pt, vt, σt)← A(gridτ , {pi, xi, fi(xi) | i ∈ Γτ})\nwhere pt, vt, σt are defined as in section 2.1. 5: Play a point xt ∈ gridτ from distribution pt(xt), observe value ft(xt). Set Γτ = Γτ ∪ {t}. 6: (Shift): Shift vt by a constant so that minx∈gridτ {vt(x)− ησt(x)} = 0, for simplicity we just keep the\nsame notation for the new vt. Moreover, we can shift F τ = ∑ j∈Γτ fj by the same constant and assume that adversary presents us the (shifted) fj . For simplicity we also keep the same notation for the new F τ .\n7: Compute F τLCE = FitLCE(βKτ ∩ K, [gridτ , vτ , στ ]). 8: if ∀x ∈ Kτ ,∃j ≤ τ, F jLCE(x) > ` 4 then\n9: RESTART (goto Initialize) 10: end if 11: if (DecideMove) ∃x̃τ ∈ Kτβ such that F τ LCE(x̃τ ) ≥ ` then 12: Kτ+1 = ShrinkSet(Kτ , x̃τ , F τLCE, gridτ , {vt, σt}) 13: Set Γτ+1 = ∅, gridτ+1 = grid(βKτ+1 ∩ K, α), τ = τ + 1. 14: end if 15: end for\nAlgorithm 4 ShrinkSet 1: Input: Convex set Kτ , convex function F τLCE, point x̃τ ∈ Kτ , Grid gridτ , value estimation vt and variance\nestimation σt. 2: Compute a separation hyperplane H ′τ through x̃τ between x̃τ and {y | F τLCE(y) < `}. Assume H ′τ = {x | 〈hτ , x〉 = wτ} and {y | F τLCE(y) < `} ⊆ {y | 〈hτ , x〉 ≤ wτ} 3: Let xτ be the center of the MVEE Eτ of Kτ . 4: (Amplify Distance). Let Hτ = {x | 〈hτ , x〉 = zτ} for some zτ ≥ 0 such that the following holds:\n1. {y | F τLCE(y) < `} ⊆ {y | 〈hτ , y〉 ≤ zτ}\n2. dist(xτ , Hτ ) = 2dist(xτ , H ′τ ).\n3. 〈hτ , xτ 〉 ≤ zτ .\n5: Return Kτ+1 = (Kτ ∩ {y | 〈hτ , y〉 ≤ zτ})"
    }, {
      "heading" : "6.2 Statement of main theorem",
      "text" : "Theorem 6.1 (Main, full algorithm). Suppose for all time t in all epoch τ , A outputs vt and σt such that for all x ∈ gridτ , (∑ j∈Γτ ,j≤t fj(x) ) ∈ [vt(x)− σt(x), vt(x) + σt(x)]. Moreover, A achieves a value\nvτ (A) = ∑\nj∈Γτ ,j≤t\nfj(xj) ≤ min x∈gridτ\n{vt(x)− ησt(x)}+ `\n1024d3 log T\nthen Algorithm 3 satisfies ∑ t ft(xt)−min x∗ ∑ t ft(x ∗) ≤ `\nCorollary 6.1 (Exp3.P.). Algorithm 3 with A being Exp3.P satisfies the condition in Theorem 6.1 with probability 1− δ for\n` = ( 2d 4 (log T )2d log 1\nδ\n)√ T"
    }, {
      "heading" : "6.3 Running time",
      "text" : "Our algorithm runs in time O ( (log T )poly(d) ) , which follows from Theorem 4.1 and the running time of\nExp3.P on K ≤ (2dα)d Experts"
    }, {
      "heading" : "6.4 Analysis sketch",
      "text" : "Before going to the details, we briefly discuss the steps of the proof.\nStep 1: In the algorithm, we shift the input function so that the player can achieve a value≤ √ T . Therefore, to get the regret bound, we can just focus on the minimal value of ∑ t ft.\nStep 2: We follow the standard Ellipsoid argument, maintaining a shrinking set, which at epoch τ is denoted Kτ . We show the volume of this set decreases by a factor of at least 1 − 1d , and hence the number of epochs between iterative RESTART operations can be bounded by O(d2 log T ) (when the diameter of Kτ along one direction decreases below 1√\nT , we do not need to further discretizate along that direction). Step 3: We will show that inside each epoch τ , for every x ∈ Kτ , ∑ t:t in epoch τ ft(x) is lower bounded by\n− 2`γ for ` ≈ √ T , γ ≥ 1. For point x outside the Kτ , ∑ t:t in epoch τ ft(x) is lower bounded by − 2` γ γ(x,Kτ ).\nStep 4: We will show that when one epoch τ ends, for every point x cut off by the separation hyperplane,∑ t:t in epoch τ ft(x) is lower bounded by ` 2γ(x,Kτ )\nStep 5: Putting the result of 3, 4 together, we know that for a point outside the current setKτ , it must be cut off by a separation hyperplane at some epoch j ≤ τ . Moreover, we can find such j with γ(x,Kj) ≥ γ(x,Kτ )d . Which implies that∑\nt\nft(x) = ∑\nt:t in epoch 1,2,...,j−1,j+1,...,τ ft(x) + ∑ t:t in epoch j ft(x) ≥ − 2τ` γ γ(x,Kτ ) + `γ(x,Kτ ) 2d ≈ √ T\nBy our choice of γ ≥ 8dτ . Therefore, when the adversary wants to move the optimal outside the current set Kτ , the player has zero regret. Moreover, by the result of 3, inside current set Kτ , the regret is bounded by τ 2`γ ≈ √ T .\nThe crucial steps in our proof are Step 3 and Step 4. Here we briefly discuss about the intuition to prove the two steps.\nIntuition of Step 3: For x ∈ Kτ , we use the grid property (Property of grid, 2.1) to find a grid xg point such that xc = xg + γ(xg − x) is close to the center of Kτ . Since xg is a grid point, by shifting we know that∑\nt:t in epoch τ\nft(xg) ≥ 0\nTherefore, if ∑ t:t in epoch τ ft(x) < − 2` γ , by convexity of ft, we know that ∑ t:t in epoch τ ft(xc) ≥ 2`. Now,\napply discretization Lemma 5.1, we know that there is a point x′c near xc such that F τ LCE(x ′ c) ≥ `, by our DecideMove condition, the epoch τ should end. Same argument can be applied to x /∈ Kτ . Intuition of Step 4: We use the fact that the algorithm does not RESTART, therefore, according to our condition, there is a point x0 ∈ Kτ with F τLCE(x0) ≤ ` 4 . Observe that the separation hyperplane of our algorithm separates x0 with points whose F τLCE ≥ `. Using the convexity of FLCE, we can show that F τLCE(x) ≥ ` 2γ(x,Kτ ). Apply the fact that F τ LCE is a lower bound of ∑ t:t in epoch τ ft we can conclude ∑ t:t in epoch τ ft(x) ≥ ` 2γ(x,Kτ ).\nNotice that here we use the convexity of FLCE, and also the fact that it is a lower bound on F (standard convex regression is not a lower bound on F , see section 3 for further discussion on this issue).\nNow we can present the proof for general dimension d To prove the main theorem we need the following lemma, starting from the following corollary of Lemma\n5.1:\nCorollary 6.2. (1). For every epoch τ , ∀x ∈ βKτ ∩ K,\nF τLCE(x) ≤ F τ (x) = ∑ i∈Γτ fi(x)\n. (2). For every epoch τ , let xτ be the center of the MVEE of Kτ , then F τ (x) = ∑ i∈Γ fi(x) ≤ 2`.\nProof. (1) is just due to the definition of LCE. (2) is due to the Geometry Lemma on F τ : for every x ∈ K2β , there exists x′ ∈ ( x+ Kτ2β ) ⊆ Kτβ such that F τ LCE(x ′) ≥ 12F τ (x)\nLemma 6.1 (During an epoch). During every epoch τ the following holds:\nF τ (x) ≥  − 2`γ x ∈ K ∩ Kτ\n− 2γ(x,Kτ )`γ x ∈ K ∩ K c τ\nLemma 6.2 (Number of epoch). There are at most 8d2 log T many epochs before RESTART.\nProof of 6.2. Let Eτ be the minimal volume enclosing Ellipsoid of Kτ , we will show that\nvol(Eτ+1) ≤ (\n1− 1 8d\n) vol(Eτ )\nFirst note that Kτ+1 = Kτ ∩ H for some half space H corresponding to the separating hyperplane going through 1βEτ , therefore, Kτ+1 ⊂ Eτ ∩H.\nLet E ′τ+1 be the minimal volume enclosing Ellipsoid of Eτ ∩H, we know that\nvol(Eτ ) ≤ vol(E ′τ+1)\nWithout lose of generality, we can assume that Eτ is centered at 0. Let A be a linear operator on Rd such that A(Eτ ) is the unit ball B1(0), observe that\nvol(E ′τ+1) vol(Eτ ) = vol(AE ′τ+1) vol(AEτ )\nSince AE ′τ+1 is the MVEE of AEτ ∩ AH, where AH is the halfspace corresponding to the separating hyperplane going through B 1\nβ (0). Without lose of generality, we can assume that H = {x ∈ Rd | x1 ≥ a} for\nsome a such that |a| ≤ 1β ≤ 1 d2 .\nObserve that\nAEτ ∩AH ⊆ { x ∈ Rd | (x1 − 14d ) 2(\n1− 14d )2 + x221 + 112d2 + ...+ x 2 d 1 + 112d2 ≤ 1\n} = E\nTherefore,\nvol(AE ′τ+1) ≤ vol(E) ≤ 1− 1\n8d .\nNow, observe that the algorithm will not cut through one eigenvector of the MVEE of Kτ if its length is smaller than 1√\nT , and the algorithm will stop when all its eigenvectors have length smaller than 1√ T . Therefore,\nthe algorithm will make at most\nd log1− 18d ( 1√ T ) = 8d2 log T\nmany epochs.\nLemma 6.3 (Beginning of each epoch). For every τ ≥ 0:\nτ−1∑ i=0 F i(x) ≥  −τ 2`γ x ∈ K ∩ Kτ\nγ(x,Kτ )` 64d x ∈ K ∩ K c τ\nLemma 6.4 (Restart). (After shifting) If A obtains a value vj(A) = ∑ t∈Γj ft(xt) ≤ ` 1024d3 log T for each epoch j, then when the algorithm RESTART, Regret = 0."
    }, {
      "heading" : "6.5 Proof of main theorem",
      "text" : "Now we can prove the regret bound assuming all the lemmas above, whose proof we defer to the next section.\nProof of Theorem 6.1. Using Lemma 6.4, we can only consider epochs between two RESTART. Now, for epoch τ , we know that for x ∈ K ∩ Kcτ , ∑\ni∈Γ0∪...∪Γτ−1\nfi(x) ≥ γ(x,Kτ )`\n64d\n∑ i∈Γτ fi(x) ≥ − 2γ(x,Kτ )` γ\nTherefore, for x ∈ K ∩ Kcτ ∑ i∈Γ0∪...∪Γτ fi(x) ≥ γ(x,Kτ )` ( 1 64d − 2 γ ) ≥ 0\nBy our choice of γ = 2048d4 log T .\nIn the same manner, we know that for x ∈ K ∩ Kτ ,∑ i∈Γ0∪...∪Γτ fi(x) ≥ − 2(τ + 1)` γ ≥ − ` 2\nBy τ ≤ 8d2 log T . Which implies that for every x ∈ K, ∑ i∈Γ0∪...∪Γτ fi(x) ≥ − ` 2 .\nDenote by vj(A) = ∑ i∈Γj ,i≤t fj(xj) the overall loss incurred by the algorithm in epoch j before time t.\nThe low-regret algorithm A guarantees that in each epoch:\nvj(A) = ∑\ni∈Γτ ,i≤t\nfi(xi)\n≤ min x∈gridτ\n{vt(x)− ησt(x)}+ `\n1024d3 log T\n≤ ` 1024d3 log T\nby shifting min x∈gridτ {vt(x)− ησt(x)} = 0\nThus A obtains over all epochs a total value of at most∑ 0≤j≤τ ` 1024d3 log T = (τ + 1)× ` 1024d3 log T ≤ ` 2 .\nTherefore, Regret = ∑ 0≤j≤τ vj(A)− ∑ i∈Γ0∪...∪Γτ fi(x ∗) ≤ `"
    }, {
      "heading" : "7 Analysis and proof of main lemmas",
      "text" : ""
    }, {
      "heading" : "7.1 Proof of Lemma 6.1",
      "text" : "Proof of 6.1. Part 1: Consider any x ∈ Kτ . By Lemma 2.1 part 1, we know that there exists xg ∈ gridτ such that xc = xg + γ(x − xg) ∈ Kτ2β . Any convex function f satisfies for any two points y, z that f(γx + (1 − γ)y) ≤ γf(x) + (1 − γ)f(y). Applying this to the convex function F τ over the line on which the points x, xc, xg reside and observe γ = ‖xc−xg‖2‖xg−x‖2 , we have\nF τ (xc)− F τ (xg) ≥ ||xc − xg||2 ||xg − x||2 (F τ (xg)− F τ (x)) = γ(F τ (xg)− F τ (x))\nSince xg ∈ grid and we shifted all losses on the grid to be nonnegative, F τ (xg) ≥ 0. Thus, we can simplify the above to:\nF τ (xc) ≥ −γF τ (x)\nSince the epoch is ongoing, the conditions of DecideMove are not yet satisfied, and hence ∀x′ ∈ 1βKτ , F τ LCE(x ′) ≤ `. By (2) of Lemma 6.2 for all points x′′ in 12βKτ it holds that F\nτ (x′′) ≤ 2`, in particular F τ (xc) ≤ 2`. The above simplifies to\nF τ (x) ≥ − 1 γ F τ (xc) ≥ − 2` γ\nPart 2:\nFor x ∈ Kcτ ∩ K By Lemma 2.1 part 2, we know that there exists xg ∈ gridτ such that xc = xg + γ\nγ(x,Kτ ) (x− xg) ∈ Kτ β2 . Now, by the convexity of F τ , we know that\nF τ (xc)− F τ (xg) ≥ ||xc − xg||2 ||xg − x||2 (F τ (xg)− F τ (x)) = γ γ(x,Kτ ) (F τ (xg)− F τ (x))\nSince xg ∈ grid and we shifted all losses on the grid to be nonnegative, F τ (xg) ≥ 0. Thus, we can simplify the above to:\nF τ (xc) ≥ − γ\nγ(x,Kτ ) F τ (x)\nSince the epoch is ongoing, the conditions of DecideMove are not yet satisfied, and hence ∀x′ ∈ 1βKτ , F τ LCE(x ′) ≤ `. By (2) of Lemma 6.2 for all points x′′ in 12βKτ it holds that F\nτ (x′′) ≤ 2`, in particular F τ (xc) ≤ 2`. The above simplifies to\nF τ (x) ≥ −γ(x,Kτ ) γ F τ (xc) ≥ − 2γ(x,Kτ )` γ"
    }, {
      "heading" : "7.2 Proof of Lemma 6.3",
      "text" : "Proof of Lemma 6.3. Part 1: For every x ∈ K ∩ Kτ , since Kτ ⊆ Kτ−1 ⊆ ... ⊆ K0 = K, we have x ∈ Kj for every 0 ≤ j ≤ τ . Therefore, by Lemma 6.1 we get F j(x) ≥ − 2`γ . Summing over the epochs,\nτ−1∑ i=0 F i(x) ≥ −τ 2` γ\nPart 2: Figure 8 illustrates the proof.\nFor every x ∈ K ∩ Kcτ , since the Algorithm does not RESTART, therefore, there must be a point x0 ∈ Kτ such that\n∀τ ′ ≤ τ, F τ ′ LCE(x0) ≤ `\n4 (2)\nLet l be the line segment between x and x0. Since x /∈ Kτ , the line l intersects Kτ , and denote xm be the intersection point between l and Kτ : {xm} = l ∩ Kτ . The corresponding boundary of Kτ was constructed in an epoch j ≤ τ , and a hyperplane which separates the `-level set of Kj , namely H = {xm | 〈hj , xm〉 = zj}) (See ShrinkSet for definition of hj , zj) such that H ∩ l = {xm}.\nNow, by the definition of Minkowski Distance, we know that (Since Minkowski Distance is the distance ratio to 1dEτ where Eτ is the MVEE of Kτ , 1 dEτ can be 1/d smaller than Kτ , and xm is the intersection point to Kτ ) ||x− xm||2 ||xm − x0||2 ≥ γ(x,Kτ )− 1 2d\nWe know that (by the convexity of F jLCE)\nF jLCE(x)− F j LCE(xm)\nF jLCE(xm)− F j LCE(x0)\n≥ ||x− xm||2 ||xm − x0||2 ≥ γ(x,Kτ )− 1 2d\nwhere the denominator is non-negative, by equation (2), F jLCE(x0) ≤ ` 4 , and by the definition of H (separation hyperplane of the `-level-set of F jLCE), F j LCE(xm) ≥ `. This implies\nF jLCE(x) ≥ (γ(x,Kτ )− 1) · 34` 2d + ` ≥ γ(x,Kτ )` 4d\nWe consider the following two cases: (a). x ∈ βKj , (b). x /∈ βKj . case (a): x ∈ βKj The LCE is a lower bound of the original function only for x in the LCE fitting domain, here LCE = F jLCE, original function F j : βKj ∩K → R, so it is only true for x ∈ βKj ∩K. Now, by (1) in Lemma 6.2, we know that F j(x) ≥ F jLCE(x) ≥ γ(x,Kτ )` 4d .\nFor other epoch i < τ , we can apply Lemma 6.1 and get F i(x) ≥ − 2γ(x,Ki)`γ . Since the set Kτ ⊆ Kτ−1 ⊆ ... ⊆ K0, By John’s theorem, we can conclude that γ(x,Ki) ≤ 2dγ(x,Kτ )\nwhich implies\nτ−1∑ i=0 F i(x) ≥ ∑ i 6=j F i(x) + F j(x)\n≥ γ(x,Kτ )` 4d − τ × 4dγ(x,Kτ )` γ ≥ γ(x,Kτ )` 32d\nby our choice of parameters τ ≤ 8d2 log T and γ = 2048d4 log T . case (b): x /∈ βKj , x ∈ K 7 This part of the proof consists of three steps. First, We find a point xj in center ofKj that has low F j value. Then we find a point xp inside βKj , on the line between xj and x, with large F jLCE value, which implies by lemma 6.2 it has large F j value. Finally, we use both x0, xp to deduce the large value of F j(x).\nStep1: Let xj be the center of MVEE Ej of Kj . By (2) in Lemma 6.2, we know that F j(xj) ≤ 2`. Step 2: Define H ′ = {y | 〈y, hj〉 = wj} to be the hyperplane parallel to H such that dist(xj , H ′) =\n1 2dist(xj , H), and H ′′ = {y | 〈y, hj〉 = uj} to be the hyperplane parallel to H such that dist(x0, H ′′) = 9dist(x0, H).\n7In the follow proof, if not mentioned specifically, every points are in K\nWe can assume 〈x0, hj〉 < wj (x0, H are in different side of H ′), since we know that F jLCE(x0) ≤ ` 4 by definition, and the hyperplaneH ′ separates such that all points with 〈x0, hj〉 ≥ wj (See ShrinkSet for definition of H , H ′) have value F jLCE(x) ≥ `.\nNote 〈x0, hj〉 < wj implies dist(x0, H) ≥ 12dist(xj , H) = dist(H,H ′) 8, which implies that\ndist(xj , H ′′) ≥ dist(H,H ′′) = 8dist(x0, H) ≥ 4dist(xj , H).\nNow, let xs = l ∩ H ′′ be the intersection point between H ′′ and l, we can get: xs = xm + 8(xm − x0). Since x0, xm ∈ Kj , we can obtain xs ∈ β2Kj by our choice of β ≥ 64d 2. Let x′s = l ′ ∩H ′′ be the intersection point of H ′′ and the line segment l′ of x and xj . Let x1 be the intersection point of H ′ and l: {x1} = H ′ ∩ l. Consider the plane defined by x0, xj , x. Define xp to be the intersecting point of the ray shooting from xs towards the interval [x, xj ], that is parallel to the line from x1 to xj . Note that ‖xs − xp‖ ≤ ‖x1 − xj‖, we have:\nxp = xs + (xp − xs) = xs + (xj − x1) ||xs − xp|| ||x1 − xj ||\nWe know that x1, xj ∈ Kj , xs ∈ β2Kj , therefore, xs + (xj −x1) ||xs−xp|| ||x1−xj || ∈ βKj , which means xp ∈ βKj . Moreover, we know that ||x′s − xp||2 ≤ ||xp − x′m||2 due to the fact that ||x′s − xp||2 ≤ ||x′m − xj ||2 ≤ 1 2‖x ′ m − x′s‖2 (last inequality by dist(xj , H ′′) ≥ 4dist(xj , H)). We also note that ||x′s − xp||2 ≤ ||xp − x′m||2 implies\ndist(xp, H) ≥ 1\n2 dist(x′s, H).\nNow, let l′′ be the line segment between xp and x0, let x′′m be the intersection point of H and l ′′: H ∩ l′′ = {x′′m}. Consider the value of F j(xp), by (1) in Lemma 6.2 and xp ∈ βKj , we know that F j(xp) ≥ F jLCE(xp). By the convexity of F jLCE, we obtain:\nF jLCE(xp)− F j LCE(x ′′ m) F jLCE(x ′′ m)− F jLCE(x0) ≥ ||xp − x ′′ m||2 ||x′′m − x0||2\n= dist(xp, H) dist(x0, H) ≥ 1 2dist(x ′ s, H)\ndist(x0, H)\n= 1 2dist(H ′′, H)\ndist(x0, H) = 4\nNote that F jLCE(x ′′ m) ≥ `, F j LCE(x0) ≤ ` 4 , therefore, F j LCE(xp) ≥ 3`. Which implies F j(xp) ≥ F jLCE(xp) ≥ 3`.\nStep 3: Due to x /∈ βKj and xm ∈ Kj , by our choice of xs and β, we know that ||x− xm||2 ≥ 8||xs − xm||2.\n8H,H′, H′′ are parallel to each other, so we can define distance between them\nWe ready to bound the value of F j(x): By the convexity of F j , we have:\nF j(x)− F j(xp) F j(xp)− F j(xj) ≥ ||x− xp||2 ||xp − xj ||2 = ||x− xs||2 ||xs − x1||2\ntriangle similarity\n= ||x− xm||2 − ||xs − xm||2 ||xm − x1||2 + ||xs − xm||2 ≥ ||x− xm||2 2||xs − xm||2 by ||xs − xm||2 ≥ 8||xm − x1|| ≥ ||x− xm||2 ||xm − x0||2 × ||xm − x0||2 2||xs − xm||2 ≥ γ(x,Kτ )− 1 32d\nThe last inequality is due to ||xm−x0||2||xs−xm||2 = 1 8 and ||x−xm||2 ||xm−x0||2 ≥ γ(x,Kτ )−1 2d Putting together, we obtain (by F j(xj) ≤ 2`):\nF j(x) ≥ γ(x,Kτ )− 1 32d\n( F j(xp)− F j(xj) ) ≥ γ(x,Kτ )− 1\n32d\nSame as case (a) , we can sum over rest epoch to obtain:\nτ−1∑ i=0 F i(x) ≥ (γ(x,Kτ )− 1)` 32d − τ × 4dγ(x,Kτ )` γ ≥ γ(x,Kτ )` 64d\nby our choice of parameters τ ≤ 8d2 log T and γ = 2048d4 log T ."
    }, {
      "heading" : "7.3 Proof of Lemma 6.4",
      "text" : "Proof of Lemma 6.4. Suppose algorithm RESTART at epoch τ , then ∑ j≤τ vj(A) ≤ ` 128d . Therefore, we just need to show that for every x ∈ K, ∑ i∈Γ0∪...∪Γτ fi(x) ≥ ` 128d . (a). Since the algorithm RESTART, by the RESTART condition, for every x ∈ Kτ , we know that ∃j ≤ τ\nsuch that F j(x) = ∑ i∈Γj fi(x) ≥ F j LCE(x) > ` 4 . Using Lemma 6.1, we know that for every j\n′ ≤ τ, j′ 6= j: F j ′ (x) = ∑ i∈Γj′\nfi(x) ≥ − 2`γ . Which implies that ∑\ni∈Γ0∪...∪Γτ\nfi(x) ≥ ` 4 − τ 2` γ ≥ ` 8\n(b). For every x /∈ Kτ , by Lemma 6.3, we know that∑ i∈Γ0∪...∪Γτ−1 fi(x) ≥ γ(x,Kτ )` 64d\nMoreover, by Lemma 6.1, we know that∑ i∈Γτ fi(x) ≥ − 2γ(x,Kτ )` γ\nPutting together we have: ∑ i∈Γ0∪...∪Γτ fi(x) ≥ γ(x,Kτ ) ( ` 64d − 2` γ ) ≥ ` 128d"
    }, {
      "heading" : "8 The EXP3 algorithm",
      "text" : "For completeness, we give in this section the definition of the EXP3.P algorithm of [5], in slight modification which allows for unknown time horizon and output of the variances.\nAlgorithm 5 Exp3.P 1: Initial: T = 1. 2: Input: K experts, unknown rounds. In round t the cost function is given by ft.\n3: Let γ = √\nK lnK T , α = √ ln ( KT δ ) ,\n4: for j = 1, ...,K do 5: set\nw1(j) = exp\n( ηαγ √ T\nK ) 6: end for 7: for t = T, ..., 2T − 1 do 8: for j = 1, ...,K do 9:\npt(j) = (1− γ) wt(j)∑ j′ wt(j ′) + γ K\n10: end for 11: pick jt at random according to pt(j), play expert jt and receive ft(jt) 12: for j = 1, ...,K do 13: Let\nf̂t(j) =\n{ ft(j) pt(j)\nif j = jt; 0 otherwise.\n14: And\nĝt(j) =\n{ 1−ft(j) pt(j)\nif j = jt; 0 otherwise.\n15: end for 16: Update\nwt+1(j) = wt(j) exp\n( γ\nK\n( ĝt(j) +\nηα\npt(j) √ TK )) 17: return\nvt(j) = t∑ i=1 f̂i(j)\nand\nσt(j) = t∑ i=1\nα\npi(j) √ TK\n18: end for 19: Set T = 2T and Goto 3."
    } ],
    "references" : [ {
      "title" : "Competing in the dark: An efficient algorithm for bandit linear optimization",
      "author" : [ "Jacob Abernethy", "Elad Hazan", "Alexander Rakhlin" ],
      "venue" : "In COLT,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2008
    }, {
      "title" : "Optimal algorithms for online convex optimization with multi-point bandit feedback",
      "author" : [ "Alekh Agarwal", "Ofer Dekel", "Lin Xiao" ],
      "venue" : "In COLT,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2010
    }, {
      "title" : "Stochastic convex optimization with bandit feedback",
      "author" : [ "Alekh Agarwal", "Dean P. Foster", "Daniel Hsu", "Sham M. Kakade", "Alexander Rakhlin" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "The nonstochastic multiarmed bandit problem",
      "author" : [ "Peter Auer", "Nicolò Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2003
    }, {
      "title" : "Online linear optimization and adaptive routing",
      "author" : [ "Baruch Awerbuch", "Robert Kleinberg" ],
      "venue" : "J. Comput. Syst. Sci.,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2008
    }, {
      "title" : "An elementary introduction to modern convex geometry. In Flavors of Geometry, pages 1–58",
      "author" : [ "Keith Ball" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1997
    }, {
      "title" : "Regret analysis of stochastic and nonstochastic multi-armed bandit problems",
      "author" : [ "Sébastien Bubeck", "Nicolo Cesa-Bianchi" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "Towards minimax policies for online linear optimization with bandit feedback",
      "author" : [ "Sébastien Bubeck", "Nicolò Cesa-Bianchi", "Sham M. Kakade" ],
      "venue" : "Journal of Machine Learning Research - Proceedings Track,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2012
    }, {
      "title" : "Bandit convex optimization: \\(\\sqrt{T}\\) regret in one dimension",
      "author" : [ "Sébastien Bubeck", "Ofer Dekel", "Tomer Koren", "Yuval Peres" ],
      "venue" : "In Proceedings of The 28th Conference on Learning Theory, COLT",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2015
    }, {
      "title" : "Multi-scale exploration of convex functions and bandit convex optimization",
      "author" : [ "Sébastien Bubeck", "Ronen Eldan" ],
      "venue" : "CoRR, abs/1507.06580,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2015
    }, {
      "title" : "Introduction to Derivative-Free Optimization, volume 8",
      "author" : [ "Andrew R Conn", "Katya Scheinberg", "Luis N Vicente" ],
      "venue" : "Society for Industrial and Applied Mathematics,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2009
    }, {
      "title" : "The price of bandit information for online optimization",
      "author" : [ "Varsha Dani", "Thomas P. Hayes", "Sham Kakade" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2007
    }, {
      "title" : "Bandit smooth convex optimization: Improving the biasvariance tradeoff",
      "author" : [ "Ofer Dekel", "Ronen Eldan", "Tomer Koren" ],
      "venue" : "In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2015
    }, {
      "title" : "Online convex optimization in the bandit setting: gradient descent without a gradient",
      "author" : [ "Abraham Flaxman", "Adam Tauman Kalai", "H. Brendan McMahan" ],
      "venue" : "In SODA,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2005
    }, {
      "title" : "Geometric algorithms and combinatorial optimization",
      "author" : [ "M. Grötschel", "L. Lovász", "A. Schrijver" ],
      "venue" : "Algorithms and combinatorics. Springer-Verlag,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1993
    }, {
      "title" : "DRAFT: Introduction to online convex optimimization",
      "author" : [ "Elad Hazan" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2015
    }, {
      "title" : "Hard-margin active linear regression",
      "author" : [ "Elad Hazan", "Zohar Karnin" ],
      "venue" : "In 31st International Conference on Machine Learning",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2014
    }, {
      "title" : "Bandit convex optimization: Towards tight bounds",
      "author" : [ "Elad Hazan", "Kfir Y. Levy" ],
      "venue" : "In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2014
    }, {
      "title" : "Extremum Problems with Inequalities as Subsidiary Conditions",
      "author" : [ "F. John" ],
      "venue" : "Studies and Essays: Courant Anniversary Volume,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1948
    }, {
      "title" : "Nearly tight bounds for the continuum-armed bandit problem",
      "author" : [ "Robert D Kleinberg" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2004
    }, {
      "title" : "Consistency of multidimensional convex regression",
      "author" : [ "Eunji Lim", "Peter W. Glynn" ],
      "venue" : "Oper. Res.,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2012
    }, {
      "title" : "Random walk approach to regret minimization",
      "author" : [ "Hariharan Narayanan", "Alexander Rakhlin" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2010
    }, {
      "title" : "Improved regret guarantees for online smooth convex optimization with bandit feedback",
      "author" : [ "Ankan Saha", "Ambuj Tewari" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2011
    }, {
      "title" : "On the complexity of bandit and derivative-free stochastic convex optimization",
      "author" : [ "Ohad Shamir" ],
      "venue" : "In Conference on Learning Theory,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "This fundamental decision making setting is extremely general, and has been used to efficiently model online prediction problems with limited feedback such as online routing, online ranking and ad placement, and many others (see [8] and [17] chapter 6 for applications and a detailed survey of BCO).",
      "startOffset" : 229,
      "endOffset" : 232
    }, {
      "referenceID" : 15,
      "context" : "This fundamental decision making setting is extremely general, and has been used to efficiently model online prediction problems with limited feedback such as online routing, online ranking and ad placement, and many others (see [8] and [17] chapter 6 for applications and a detailed survey of BCO).",
      "startOffset" : 237,
      "endOffset" : 241
    }, {
      "referenceID" : 0,
      "context" : "For example, in case the adversarial cost functions are linear, efficient algorithms are known that guarantee near-optimal regret bounds [2, 9, 18].",
      "startOffset" : 137,
      "endOffset" : 147
    }, {
      "referenceID" : 7,
      "context" : "For example, in case the adversarial cost functions are linear, efficient algorithms are known that guarantee near-optimal regret bounds [2, 9, 18].",
      "startOffset" : 137,
      "endOffset" : 147
    }, {
      "referenceID" : 16,
      "context" : "For example, in case the adversarial cost functions are linear, efficient algorithms are known that guarantee near-optimal regret bounds [2, 9, 18].",
      "startOffset" : 137,
      "endOffset" : 147
    }, {
      "referenceID" : 0,
      "context" : "Indeed, most known optimization and algorithmic techniques have been applied, including interior point methods [2], random walk optimization [23], continuous multiplicative updates [13], random perturbation [6], iterative optimization methods [15] and many more.",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 21,
      "context" : "Indeed, most known optimization and algorithmic techniques have been applied, including interior point methods [2], random walk optimization [23], continuous multiplicative updates [13], random perturbation [6], iterative optimization methods [15] and many more.",
      "startOffset" : 141,
      "endOffset" : 145
    }, {
      "referenceID" : 11,
      "context" : "Indeed, most known optimization and algorithmic techniques have been applied, including interior point methods [2], random walk optimization [23], continuous multiplicative updates [13], random perturbation [6], iterative optimization methods [15] and many more.",
      "startOffset" : 181,
      "endOffset" : 185
    }, {
      "referenceID" : 4,
      "context" : "Indeed, most known optimization and algorithmic techniques have been applied, including interior point methods [2], random walk optimization [23], continuous multiplicative updates [13], random perturbation [6], iterative optimization methods [15] and many more.",
      "startOffset" : 207,
      "endOffset" : 210
    }, {
      "referenceID" : 13,
      "context" : "Indeed, most known optimization and algorithmic techniques have been applied, including interior point methods [2], random walk optimization [23], continuous multiplicative updates [13], random perturbation [6], iterative optimization methods [15] and many more.",
      "startOffset" : 243,
      "endOffset" : 247
    }, {
      "referenceID" : 8,
      "context" : "A significant breakthrough was recently made by [10], who show that in the oblivious setting and in the special case of 1-dimensional BCO, O( √ T ) regret is attainable.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 9,
      "context" : "This result was very recently extended to any dimension by [11], still with an existential bound rather than an explicit algorithm and in the oblivious setting.",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 13,
      "context" : "1 Prior work The best known upper bound in the regret attainable for adversarial BCO with general convex loss functions is Õ(T ) due to [15] and [21] 2.",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 19,
      "context" : "1 Prior work The best known upper bound in the regret attainable for adversarial BCO with general convex loss functions is Õ(T ) due to [15] and [21] 2.",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 15,
      "context" : "[17].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "This allows for very efficient exploration, and was first used by [13] to devise the Geometric Hedge algorithm that achieves an optimal regret rate of Õ( √ T ).",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 0,
      "context" : "An efficient algorithm inspired by interior point methods was later given by [2] with the same optimal regret bound.",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 7,
      "context" : "Further improvements in terms of the dimension and other constants were subsequently given in [9, 18].",
      "startOffset" : 94,
      "endOffset" : 101
    }, {
      "referenceID" : 16,
      "context" : "Further improvements in terms of the dimension and other constants were subsequently given in [9, 18].",
      "startOffset" : 94,
      "endOffset" : 101
    }, {
      "referenceID" : 13,
      "context" : "The first gradient-descent-based method for BCO was given by [15].",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "Their regret bound was subsequently improved for various special cases of loss functions using ideas from [2].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 22,
      "context" : "For convex and smooth losses, [24] attained an upper bound on the regret of of Õ(T ).",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 12,
      "context" : "This was recently improved to by [14] to Õ(T ).",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 1,
      "context" : "[3] obtained a regret bound of Õ(T ) for strongly-convex losses.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "For the special case of strongly-convex and smooth losses, [3] obtained a regret of Õ( √ T ) in the unconstrained case, and [19] obtain the same rate even in the constrained cased.",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 17,
      "context" : "For the special case of strongly-convex and smooth losses, [3] obtained a regret of Õ( √ T ) in the unconstrained case, and [19] obtain the same rate even in the constrained cased.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 23,
      "context" : "[25] gives a lower bound of Ω( √ T ) for the setting of strongly-convex and smooth BCO.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 6,
      "context" : "A comprehensive survey by Bubeck and Cesa-Bianchi [8], provides a review of the bandit optimization literature in both stochastic and online setting.",
      "startOffset" : 50,
      "endOffset" : 53
    }, {
      "referenceID" : 10,
      "context" : "This is considered one of the hardest areas in convex optimization (although strictly a special case of BCO), and a significant body of work has culminated in a polynomial time algorithm, see [12].",
      "startOffset" : 192,
      "endOffset" : 196
    }, {
      "referenceID" : 2,
      "context" : "Recently, [4] give a polynomial time algorithm for regret minimization in the stochastic setting of zero-order optimization, greatly improving upon the known running times.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 9,
      "context" : "1In the oblivious setting [11] show that the regret behaves polynomially in the dimension.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 15,
      "context" : "[17] chapter 6).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "We denote by EK the minimal volume enclosing ellipsoid (MVEE) in K, also known as the John ellipsoid [20, 7].",
      "startOffset" : 101,
      "endOffset" : 108
    }, {
      "referenceID" : 5,
      "context" : "We denote by EK the minimal volume enclosing ellipsoid (MVEE) in K, also known as the John ellipsoid [20, 7].",
      "startOffset" : 101,
      "endOffset" : 108
    }, {
      "referenceID" : 3,
      "context" : "The following theorem was essentially established in [5] (although the original version was stated for gains instead of losses, and had known horizon parameter), for the algorithm called EXP3.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 3,
      "context" : "1 ([5]).",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 14,
      "context" : "Till recently, the only polynomial time algorithm for zero-order optimization was based on the ellipsoid method [16].",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 2,
      "context" : "[4]).",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 20,
      "context" : "(see [22] for more details).",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 3,
      "context" : "P due to [5], to exploit and explore it.",
      "startOffset" : 9,
      "endOffset" : 12
    }, {
      "referenceID" : 0,
      "context" : "If there exists i ∈ [2] such that FLCE(vi) ≥ 12F (y), then we already conclude the proof.",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 0,
      "context" : "Therefore, we can assume that for all i ∈ [2], FLCE(vi) < 12F (y).",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 0,
      "context" : "Step 2: By the definition of FLCE, we know that for every i ∈ [2], there exists pi,1, .",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 3,
      "context" : "P algorithm of [5], in slight modification which allows for unknown time horizon and output of the variances.",
      "startOffset" : 15,
      "endOffset" : 18
    } ],
    "year" : 2017,
    "abstractText" : "We consider the problem of online convex optimization against an arbitrary adversary with bandit feedback, known as bandit convex optimization. We give the first Õ( √ T )-regret algorithm for this setting based on a novel application of the ellipsoid method to online learning. This bound is known to be tight up to logarithmic factors. Our analysis introduces new tools in discrete convex geometry.",
    "creator" : "LaTeX with hyperref package"
  }
}