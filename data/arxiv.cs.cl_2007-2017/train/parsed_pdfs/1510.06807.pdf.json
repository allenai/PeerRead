{
  "name" : "1510.06807.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning in the Rational Speech Acts Model",
    "authors" : [ "Will Monroe", "Christopher Potts" ],
    "emails" : [ "wmonroe4@cs.stanford.edu,", "cgpotts@stanford.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "The Rational Speech Acts (RSA) model treats language use as a recursive process in which probabilistic speaker and listener agents reason about each other’s intentions to enrich the literal semantics of their language along broadly Gricean lines. RSA has been shown to capture many kinds of conversational implicature, but it has been criticized as an unrealistic model of speakers, and it has so far required the manual specification of a semantic lexicon, preventing its use in natural language processing applications that learn lexical knowledge from data. We address these concerns by showing how to define and optimize a trained statistical classifier that uses the intermediate agents of RSA as hidden layers of representation forming a non-linear activation function. This treatment opens up new application domains and new possibilities for learning effectively from data. We validate the model on a referential expression generation task, showing that the best performance is achieved by incorporating features approximating well-established insights about natural language generation into RSA."
    }, {
      "heading" : "1 Pragmatic language use",
      "text" : "In the Gricean view of language use [18], people are rational agents who are able to communicate efficiently and effectively by reasoning in terms of shared communicative goals, the costs of production, prior expectations, and others’ belief states. The Rational Speech Acts (RSA) model [11] is a recent Bayesian reconstruction of these core Gricean ideas. RSA and its extensions have been shown to capture many kinds of conversational implicature and to closely model psycholinguistic data from children and adults [7, 2, 23, 30, 33].\nBoth Grice’s theories and RSA have been criticized for predicting that people are more rational than they actually are. These criticisms have been especially forceful in the context of language production. It seems that speakers often fall short: their utterances are longer than they need to be, underinformative, unintentionally ambiguous, obscure, and so forth [1, 10, 16, 24, 28, 29]. RSA can incorporate notions of bounded rationality [4, 13, 20], but it still sharply contrasts with views in the tradition of [6], in which speaker agents rely on heuristics and shortcuts to try to accurately describe the world while managing the cognitive demands of language production.\nIn this paper, we offer a substantially different perspective on RSA by showing how to define it as a trained statistical classifier, which we call learned RSA. At the heart of learned RSA is the back-and-forth reasoning between speakers and listeners that characterizes RSA. However, whereas standard RSA requires a hand-built lexicon, learned RSA infers a lexicon from data. And whereas standard RSA makes predictions according to a fixed calculation, learned RSA seeks to optimize the likelihood of whatever examples it is trained on. Agents trained in this way exhibit the pragmatic behavior characteristic of RSA, but their behavior is governed by their training data and hence is only as rational as that experience supports. To the extent that the speakers who produced the data are pragmatic, learned RSA discovers that; to the extent that their behavior is governed by other factors, learned RSA picks up on that too. We validate the model on the task of attribute selection for referring expression generation with a widely-used corpus of referential descriptions (the TUNA corpus; [34, 15]), showing that it improves on heuristic-driven models and pure RSA by synthesizing the best aspects of both.\nar X\niv :1\n51 0.\n06 80\n7v 1\n[ cs\n.C L\n] 2\n3 O\nct 2\n01 5"
    }, {
      "heading" : "2 RSA as a speaker model",
      "text" : "RSA is a descendent of the signaling systems of [25] and draws on ideas from iterated best response (IBR) models [13, 20], iterated cautious response (ICR) models [21], and cognitive hierarchies [4] (see also [17, 31]). RSA models language use as a recursive process in which speakers and listeners reason about each other to enrich the literal semantics of their language. This increases the efficiency and reliability of their communication compared to what more purely literal agents can achieve.\nFor instance, suppose a speaker and listener are playing a reference game in the context of the images in Figure 1(a). The speaker S has been privately assigned referent r1 and must send a message that conveys this to the listener. A literal speaker would make a random choice between beard and glasses. However, if S places itself in the role of a listener L receiving these messages, then S will see that glasses creates uncertainty about the referent whereas beard does not, and so S will favor beard. In short, the pragmatic speaker chooses beard because it’s unambiguous for the listener.\nRSA formalizes this reasoning in probabilistic Bayesian terms. It assumes a set of messages M , a set of states T , a prior probability distribution P over states T , and a cost function C mapping messages to real numbers. The semantics of messages is defined by a lexicon L, where L(m, t) = 1 if m is true of t and 0 otherwise. The agents are then defined as follows:\ns0(m | t,L) ∝ exp (λ (logL(m, t)− C(m))) (1) l1(t | m,L) ∝ s0(m | t,L)P (t) (2) s1(m | t,L) ∝ exp (λ (log l1(t | m,L)− C(m))) (3)\nThe model that is the starting point for our contribution in this paper is the pragmatic speaker s1. It reasons not about the semantics directly but rather about a pragmatic listener l1 reasoning about a literal speaker s0. The strength of this pragmatic reasoning is partly governed by the temperature parameter λ, with higher values leading to more aggressive pragmatic reasoning.\nFigure 1 tracks the RSA computations for the reference game in Figure 1(a). Here, the message costs C are all 0, the prior over referents is flat, and λ = 1. The chances of success for the literal speaker s0 are low, since it chooses true messages at random. In contrast, the chances of success for s1 are high, since it derives the unambiguous system highlighted in gray.\nThe task we seek to model is a language generation task, so we present RSA from a speakercentric perspective. It has been explored more fully from a listener perspective. In that formulation, the model begins with a literal listener reasoning only in terms of the lexicon L and state priors. Models of this general form have been shown to capture a wide range of pragmatic behaviors [2, 12, 22, 23, 30] and to increase success in task-oriented dialogues [35, 36].\nRSA has been criticized on the grounds that it predicts unrealistic speaker behavior [16]. For instance, in Figure 1, we confined our agents to a simple message space. If permitted to use natural language, they will often produce utterances expressing predicates that are redundant from an RSA perspective—for example, by describing r1 as the man with the long beard and sweater, even though man has no power to discriminate, and beard and sweater each uniquely identify the intended referent. This tendency has several explanations, including a preference for including certain kinds of descriptors, a desire to hedge against the possibility that the listener is not pragmatic, and cognitive pressures that make optimal descriptions impossible. One of our central objectives is to allow these factors to guide the core RSA calculation."
    }, {
      "heading" : "3 The TUNA corpus",
      "text" : "In Section 6, we evaluate RSA and learned RSA in the TUNA corpus [34, 15], a widely used resource for developing and testing models of natural language generation. We introduce the corpus now because doing so helps clarify the learning task faced by our model, which we define in the next section.\nIn the TUNA corpus, participants were assigned a target referent or referents in the context of seven other distractors and asked to describe the target(s). Trials were performed in two domains, furniture and people, each with a singular condition (describe a single entity) and a plural condition (describe two). Figure 2 provides a (slightly simplified) example from the singular furniture section, with the target item identified by shading. In this case, the participant wrote the message “blue fan small”. All entities and messages are annotated with their semantic attributes, as given in simplified form here. (Participants saw just the images; we include the attributes in Figure 2 for reference.)\nThe task we address is attribute selection: reproducing the multiset of attributes in the message produced in each context. Thus, for Figure 2, we would aim to produce {[size:small ],\n[colour:blue], [type:fan]}. This is less demanding than full natural language generation, since it factors out all morphosyntactic phenomena. Section 6 provides additional details on the nature of this evaluation."
    }, {
      "heading" : "4 Learned RSA",
      "text" : "We now formulate RSA as a machine learning model that can incorporate the quirks and limitations that characterize natural descriptions while still presenting a unified model of pragmatic reasoning. This approach builds on the two-layer speaker-centric classifier of [17], but differs from theirs in that we directly optimize the performance of the pragmatic speaker in training, whereas [17] apply a recursive reasoning model on top of a pre-trained classifier. Like RSA, the model can be generalized to allow for additional intermediate agents, and it can easily be reformulated to begin with a literal listener.\nFeature representations. To build an agent that learns effectively from data, we must represent the items in our dataset in a way that accurately captures their important distinguishing properties and permits robust generalization to new items [8, 26]. We define our feature representation function φ very generally as a map from state–utterance–context triples 〈t,m, c〉 to vectors of real numbers. This gives us the freedom to design the feature function to encode as much relevant information as necessary.\nAs noted above, in learned RSA, we do not presuppose a semantic lexicon, but rather induce one from the data as part of learning. The feature representation function determines a large, messy hypothesis space of potential lexica that is refined during optimization. For instance, as a starting point, we might define the feature space in terms of the cross-product of all possible entity attributes and all possible utterance meaning attributes. For m entity attributes and n utterance attributes, this defines each φ(t,m, c) as an mn-dimensional vector. Each dimension of this vector records the number of times that its corresponding pair of attributes co-occurs in t and m. Thus, the representation of the target entity in Figure 2 would include a 1 in the dimension for clearly good pairs like colour:blue ∧ [colour:blue] as well as for intuitively incorrect pairs like size:small ∧ [colour:blue].\nBecause φ is defined very generally, we can also include information that is not clearly lexical. For instance, in our experiments, we add dimensions that count the color attributes in the utterance in various ways, ignoring the specific color values. We can also define features that intuitively involve negation, for instance, those that capture entity attributes that go unmentioned. This freedom is crucial to bringing generation-specific insights into the RSA reasoning.\nLiteral speaker. Learned RSA is built on top of a log-linear model, standard in the machine learning literature and widely applied to classification tasks [19, 27].\nS0(m | t, c; θ) ∝ exp(θTφ(t,m, c)) (4)\nThis model serves as our literal speaker, analogous to s0 in (1). The lexicon of this model is embedded in the parameters (or weights) θ. Intuitively, θ is the direction in feature representation space that the literal speaker believes is most positively correlated with the probability that the message will be correct. We train the model by searching for a θ to maximize the conditional likelihood the model assigns to the messages in the training examples. Assuming the training is\neffective, this increases the weight for correct pairings between utterance attributes and entity attributes and decreases the weight for incorrect pairings.\nTo find the optimal θ, we seek to maximize the conditional likelihood of the training examples using first-order optimization methods (described in more detail in Learning, below). This requires the gradient of the likelihood with respect to θ. To simplify the gradient derivation and improve numerical stability, we maximize the log of the conditional likelihood:\nJS0(t,m, c, θ) = logS0(m | t, c; θ) (5)\nThe gradient of this log-likelihood is\n∂JS0 ∂θ = φ(t,m, c)− 1∑ m′ exp(θ Tφ(t,m′, c)) ∑ m′ exp(θTφ(t,m′, c))φ(t,m′, c)\n= φ(t,m, c)− ∑ m′ S0(m ′ | t, c; θ)φ(t,m′, c) = φ(t,m, c)− Em′∼S0(·|t,c;θ) [φ(t,m ′, c)] (6)\nwhere the first two equations can be derived by expanding the proportionality constant in the definition of S0.\nPragmatic speaker. We now define a pragmatic listener L1 and a pragmatic speaker S1. We will show experimentally (Section 6) that the learned pragmatic speaker S1 agrees better with human speakers on a referential expression generation task than either the literal speaker S0 or the pure RSA speaker s1.\nThe parameters for L1 and S1 are still the parameters of the literal speaker S0; we wish to update them to maximize the performance of S1, the agent that acts according to S1(m | t, c; θ), where\nS1(m | t, c; θ) ∝ L1(t | m, c; θ) (7) L1(t | m, c; θ) ∝ S0(m | t, c; θ) (8)\nThis corresponds to the simplest case of RSA in which λ = 1 and message costs and state priors are uniform: s1(m | t,L) ∝ l1(t | m,L) ∝ s0(m | t,L).\nIn optimizing the performance of the pragmatic speaker S1 by adjusting the parameters to the simpler classifier S0, the RSA back-and-forth reasoning can be thought of as a non-linear function through which errors are propagated in training, similar to the activation functions in neural network models [32]. However, unlike neural network activation functions, the RSA reasoning applies a different non-linear transformation depending on the pragmatic context (sets of available referents and utterances).\nFor convenience, we define symbols for the log-likelihood of each of these probability distributions:\nJS1(t,m, c, θ) = logS1(m | t, c; θ) (9) JL1(t,m, c, θ) = logL1(t | m, c; θ) (10)\nThe log-likelihood of each agent has the same form as the log-likelihood of the literal speaker, but with the value of the distribution from the lower-level agent substituted for the score θTφ. By a derivation similar to the one in (6) above, the gradient of these log-likelihoods can thus\nbe shown to have the same form as the gradient of the literal speaker, but with the gradient of the next lower agent substituted for the feature values:\n∂JS1 ∂θ = ∂JL1 ∂θ (t,m, c, θ)− Em′∼S1(·|t,c;θ) [ ∂JL1 ∂θ (t,m′, c, θ) ] (11)\n∂JL1 ∂θ = ∂JS0 ∂θ (t,m, c, θ)− Et′∼L1(·|m,c;θ) [ ∂JS0 ∂θ (t′,m, c, θ) ] (12)\nThe value JS0 in (12) is as defined in (5).\nTraining. As mentioned above, our primary objective in training is to maximize the (log) conditional likelihood of the messages in the training examples given their respective states and contexts. We add to this an `2 regularization term, which expresses a Gaussian prior distribution over the parameters θ. Imposing this prior helps prevent overfitting to the training data and thereby damaging our ability to generalize well to new examples [5]. With this modification, we instead maximize the log of the posterior probability of the parameters and the training examples jointly. For a dataset of M training examples 〈ti,mi, ci〉, this log posterior is:\nJ(θ) = −M 2 `||θ||2 + M∑ i=1 logS1(mi | ti, ci; θ) (13)\nThe stochastic gradient descent (SGD) family of first-order optimization techniques [3] can be used to approximately maximize J(θ) by obtaining noisy estimates of its gradient and “hillclimbing” in the direction of the estimates. (Strictly speaking, we are employing stochastic gradient ascent to maximize the objective rather than minimize it; however, SGD is the much more commonly seen term for the technique.)\nThe exact gradient of this objective function is\n∂J ∂θ = −M`θ + M∑ i=1 ∂JS1 ∂θ (ti,mi, ci, θ) (14)\nusing the per-example gradient dJS1 dθ given in (11). SGD uses the per-example gradients (and a simple scaling of the `2 regularization penalty) as its noisy estimates, thus relying on each example to guide the model in roughly the correct direction towards the optimal parameter setting. Formally, for each example (t,m, c), the parameters are updated according to the formula\nθ := θ + α ( −`θ + ∂JS1\n∂θ (t,m, c, θ)\n) (15)\nThe learning rate α determines how “aggressively” the parameters are adjusted in the direction of the gradient. Small values of α lead to slower learning, but a value of α that is too large can result in the parameters overshooting the optimal value and diverging. To find a good learning rate, we use AdaGrad [9], which sets the learning rate adaptively for each example based on an initial step size η and gradient history. The effect of AdaGrad is to reduce the learning rate over time such that the parameters can settle down to a local optimum despite the noisy gradient estimates, while continuing to allow high-magnitude updates along certain dimensions if those dimensions have exhibited less noisy behavior in previous updates."
    }, {
      "heading" : "5 Example",
      "text" : "In Figure 3, we illustrate crucial aspects of how our model is optimized, fleshing out the concepts from the previous section. The example also shows the ability of the trained S1 model to make a specificity implicature without having observed one in its data, while preserving the ability to produce uninformative attributes if encouraged to do so by experience.\nAs in our main experiments, we frame the learning task in terms of attribute selection with TUNA-like data. In this toy experiment, the agent is trained on two example contexts, consisting of a target referent, a distractor referent, and a human-produced utterance. It is evaluated on a third test example. This small dataset is given in the top two rows of Figure 3. The utterance on the test example is shown for comparison; it is not provided to the agent.\nOur feature representations of the data are in the third row. Attributes of the referents are in small caps; semantic attributes of the utterances are in [square brackets]. These representations employ the cross-product features described in Section 4; in TUNA data, properties that the target entities do not possess (e.g., ¬glasses) are also included among their “attributes.”\nBelow the feature representations, we summarize the gradient of the log likelihood ( ∂JS1 ∂θ ) for each example, as an m × n table representing the weight update for each of the mn crossproduct features. (We leave out the `2 regularization and AdaGrad learning rate for simplicity.) Tracing the formula for this gradient (11) back through the RSA layers to the literal listener (5), one can see that the gradient consists of the feature representation of the triple 〈t,m, c〉 containing the correct (human-produced) message, minus adjustments that penalize the other messages according to how much the model was “fooled” into expecting them.\nThe RSA reasoning yields gradients that express both lexical and contextual knowledge. From the first training example, the model learns the lexical information that [person] and [glasses] should be used to describe the target. However, this knowledge receives higher weight in the association with glasses, because that attribute is disambiguating in this context. As one would hope, the overall result is that intuitively good pairings generally have higher weights, though the training set is too small to fully distinguish good features from bad ones. For example, after seeing both training examples and failing to observe both a beard and glasses on the same individual, the model incorrectly infers that [beard ] can be used to indicate a lack of glasses and vice versa. Additional training examples could easily correct this.\nFigure 3(b) shows the distribution over utterances given target referent as predicted by the learned pragmatic speaker S1 after one pass through the data with a fixed learning rate α = 1 and no regularization (` = 0). We compare this distribution with the distribution predicted by the learned literal speaker S0 and the pure RSA speaker s1. We wish to determine whether each model can (i) minimize ambiguity; and (ii) learn a prior preference for producing certain descriptors even if they are redundant.\nThe distributions in Figure 3(b) show that the linear classifier correctly learns that humanproduced utterances in the training data tend to mention the attribute [person] even though it is uninformative. However, for the referent that was not seen in the training data, the model cannot decide among mentioning [beard ], [glasses], both, or neither, even though the messages that don’t mention [glasses] are ambiguous in context. The pure RSA model, meanwhile, chooses messages that are unambiguous, but because it has no mechanism for learning from the examples, it does not prefer to produce [person] without a manually-specified prior.\nOur pragmatic speaker S1 gives us the best of both models: the parameters θ in learned RSA show the tendency exhibited in the training data to produce [person] in all cases, while the RSA recursive reasoning mechanism guides the model to produce unambiguous messages by including the attribute [glasses].\nTraining examples Test example\nContext\nr2 r3 r3 r4 r1 r4\nUtterance [person] with [glasses] [person] with [beard] [person] with [glasses]\nFeatures for true utterance person ∧ [person] person ∧ [glasses] glasses ∧ [person] glasses ∧ [glasses] ¬beard ∧ [person] ¬beard ∧ [glasses] person ∧ [person] person ∧ [beard ] ¬glasses ∧ [person] ¬glasses ∧ [beard ] beard ∧ [person] beard ∧ [beard ] person ∧ [person] person ∧ [glasses] glasses ∧ [person] glasses ∧ [glasses] beard ∧ [person] beard ∧ [glasses]\nGradient\n[p er so n\n]\n[g la ss es\n]\n[b ea rd\n]\nperson 1 1 -1 glasses 2 2 -2 beard 0 0 0 ¬glasses -1 -1 1 ¬beard 1 1 -1\n[p er so n\n]\n[g la ss es\n]\n[b ea rd\n]\nperson 1 -1 1 glasses 0 0 0 beard 2 -2 2 ¬glasses 1 -1 1 ¬beard -1 1 -1\n(unused)\n(a) Learned S1 model training. Gradient values given are 6 ∂JS1 ∂θ , evaluated at θ = ~0."
    }, {
      "heading" : "6 Experiments",
      "text" : "Data. We report experiments on the TUNA corpus (Section 3 above). We focus on the singular portion of the corpus, which was used in the 2008 and 2009 Referring Expression Generation Challenges. We do not have access to the train/dev/test splits from those challenges, so we report five-fold cross-validation numbers. The singular portion consists of 420 furniture trials involving 176 distinct referents and 360 people trials involving 228 distinct referents.\nEvaluation metrics. The primary evaluation metric used in the attribute selection task with TUNA data is multiset Dice calculated on the attributes of the generated messages:\n2 ∑ x∈D min [ Za(mi)(x),Za(mj)(x) ] |a(mi)|+ |a(mj)|\n(16)\nHere, a(m) is the multiset of attributes of message m, D is the non-multiset union of a(mi) and a(mj), ZX(x) is the number of occurrences of x in the multiset X, and |a(mi)| is the cardinality of multiset a(m). Accuracy is the fraction of examples for which the subset of attributes is predicted perfectly (equivalent to achieving multiset Dice 1).\nExperimental set-up. We evaluate all our agents in the same pragmatic contexts: for each trial in the singular corpus, we define the messages M to be the powerset of the attributes used in the referential description and the states T to be the set of entities in the trial, including the target. The message predicted by a speaker agent is the one with the highest probability given the target entity; if more than one message has the highest probability, we allow the agent to choose randomly from the highest probability ones.\nIn learning, we use initial step size η = 0.01 and regularization constant ` = 0.01. RSA agents are not trained, but we cross-validate to optimize λ and the function defining message costs, choosing from (i) C(m) = 0; (ii) C(m) = |a(m)|; and (iii) C(m) = −|a(m)|.\nFeatures. We use indicator features as our feature representation; that is, the dimensions of the feature representation take the values 0 and 1, with 1 representing the truth of some predicate P (t,m, c) and 0 representing its negation. Thus, each vector of real numbers that is the value of φ(t,m, c) can be represented compactly as a set of predicates.\nThe baseline feature set consists of indicator features over all conjunctions of an attribute of the referent and an attribute in the candidate message (e.g., P (t,m, c) = red(t) ∧ [blue] ∈ m). We compare this to a version of the model with additional generation features that seek to capture the preferences identified in prior work on generation. These consist of indicators over the following features of the message:\n(i) attribute type (e.g., P (t,m, c) = “m contains a color”);\n(ii) pair-wise attribute type co-occurrences, where one can be negated (e.g., “m contains a color and a size”, “m contains an object type but not a color”); and\n(iii) message size in number of attributes (e.g., “m consists of 3 attributes”).\nFor comparison, we also separately train literal speakers S0 as in (4) (the log-linear model) with each of these feature sets using the same optimization procedure.\nResults. The results (Table 1) show that training a speaker agent with learned RSA generally improves generation over the ordinary classifier and RSA models. On the more complex people dataset, the pragmatic S1 model significantly outperforms all other models. The value of the model’s flexibility in allowing a variety of feature designs can be seen in the comparison of the different feature sets: we observe consistent gains from adding generation features to the basic cross-product feature set. Moreover, the two types of features complement each other: neither the cross-product features nor the generation features in isolation achieve the same performance as the combination of the two.\nOf the models in Table 1, all but the last exhibit systematic errors. Pure RSA performs poorly for reasons predicted by [16]—for example, it under-produces color terms and head nouns like desk, chair, and person. This problem is also observed in the trained S1 model, but is corrected by the generation features. On the people dataset, the S0 models under-produce beard and hair, which are highly informative in certain contexts. This type of communicative failure is eliminated in the S1 speakers.\nThe performance of the learned RSA model on the people trials also compares favorably to the best dev set performance numbers from the 2008 Challenge [14], namely, .762 multiset Dice, although this comparison must be informal since the test sets are different. (In particular, the Accuracy values given in [14] are unfortunately not comparable with the values we present, as they reflect “perfect match with at least one of the two reference outputs” [emphasis in original].) Together, these results show the value of being able to train a single model that synthesizes RSA with prior work on generation."
    }, {
      "heading" : "7 Conclusion",
      "text" : "Our initial experiments demonstrate the utility of RSA as a trained classifier in generating referential expressions. The primary advantages of this version of RSA stem from the flexible ways in which it can learn from available data. This not only removes the need to specify a complex semantic lexicon by hand, but it also provides the analytic freedom to create models that are sensitive to factors guiding natural language production that are not naturally expressed in standard RSA.\nThis basic presentation suggests a range of potential next steps. For instance, it would be natural to apply the model to pragmatic interpretation (the listener’s perspective); this requires no substantive formal changes to the model as defined in Section 4, and it opens up new avenues in terms of evaluating pragmatic models in standard classification tasks like sentiment analysis, topic prediction, and natural language reasoning. In addition, for all versions of the model, one could consider including additional hidden speaker and listener layers, incorporating message costs and priors into learning, to capture a wider range of pragmatic phenomena."
    } ],
    "references" : [ {
      "title" : "Overspecification and the cost of pragmatic reasoning about referring expressions",
      "author" : [ "Peter Baumann", "Brady Clark", "Stefan Kaufmann" ],
      "venue" : "In Proceedings of the 36th Annual Meeting of the Cognitive Science Society. Cognitive Science Society,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2014
    }, {
      "title" : "Pragmatic reasoning through semantic inference",
      "author" : [ "Leon Bergen", "Roger Levy", "Noah D. Goodman" ],
      "venue" : "Ms., MIT, UCSD, and Stanford,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2014
    }, {
      "title" : "Large-scale machine learning with stochastic gradient descent",
      "author" : [ "Léon Bottou" ],
      "venue" : "Proceedings of the 19th International Conference on Computational Statistics,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2010
    }, {
      "title" : "A cognitive hierarchy model of games",
      "author" : [ "Colin F. Camerer", "Teck-Hua Ho", "Juin-Kuan Chong" ],
      "venue" : "The Quarterly Journal of Economics,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2004
    }, {
      "title" : "A Gaussian prior for smoothing maximum entropy models",
      "author" : [ "Stanley F. Chen", "Ronald Rosenfeld" ],
      "venue" : "Technical Report CMU-CS-99-108,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1999
    }, {
      "title" : "Computational interpretations of the Gricean maxims in the generation of referring expressions",
      "author" : [ "Robert Dale", "Ehud Reiter" ],
      "venue" : "Cognitive Science,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1995
    }, {
      "title" : "Optimal reasoning about referential expressions",
      "author" : [ "Judith Degen", "Michael Franke" ],
      "venue" : "Proceedings of the 16th Workshop on the Semantics and Pragmatics of Dialogue,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2012
    }, {
      "title" : "A few useful things to know about machine learning",
      "author" : [ "Pedro Domingos" ],
      "venue" : "Communications of ACM,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "John Duchi", "Elad Hazan", "Yoram Singer" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "Do speakers and listeners observe the Gricean maxim of quantity",
      "author" : [ "Paul E. Engelhardt", "Karl G.D. Bailey", "Fernanda Ferreira" ],
      "venue" : "Journal of Memory and Language,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "Predicting pragmatic reasoning in language",
      "author" : [ "Michael C. Frank", "Noah D. Goodman" ],
      "venue" : "games. Science,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2012
    }, {
      "title" : "Inferring word meanings by assuming that speakers are informative",
      "author" : [ "Michael C. Frank", "Noah D. Goodman" ],
      "venue" : "Cognitive Psychology,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2014
    }, {
      "title" : "Signal to Act: Game Theory in Pragmatics",
      "author" : [ "Michael Franke" ],
      "venue" : "ILLC Dissertation Series. Institute for Logic, Language and Computation,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2009
    }, {
      "title" : "The TUNA Challenge 2008: Overview and evaluation results",
      "author" : [ "Albert Gatt", "Anja Belz", "Eric Kow" ],
      "venue" : "In Proceedings of the Fifth International Natural Language Generation Conference,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Evaluating algorithms for the generation of referring expressions using a balanced corpus",
      "author" : [ "Albert Gatt", "Ielka van der Sluis", "Kees van Deemter" ],
      "venue" : "In Proceedings of the Eleventh European Workshop on Natural Language Generation,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2007
    }, {
      "title" : "Are we Bayesian referring expression generators",
      "author" : [ "Albert Gatt", "Roger P.G. van Gompel", "Kees van Deemter", "Emiel Krahmer" ],
      "venue" : "In Proceedings of the Thirty-Fifth Annual Conference of the Cognitive Science Society,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2013
    }, {
      "title" : "A game-theoretic approach to generating spatial descriptions",
      "author" : [ "Dave Golland", "Percy Liang", "Dan Klein" ],
      "venue" : "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2010
    }, {
      "title" : "Logic and conversation",
      "author" : [ "H. Paul Grice" ],
      "venue" : "Syntax and Semantics,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1975
    }, {
      "title" : "The Elements of Statistical Learning",
      "author" : [ "Trevor Hastie", "Robert Tibshirani", "Jerome Friedman" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2009
    }, {
      "title" : "Game theory in semantics and pragmatics",
      "author" : [ "Gerhard Jäger" ],
      "venue" : "Semantics: An International Handbook of Natural Language Meaning,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2012
    }, {
      "title" : "Formalizing the pragmatics of metaphor understanding",
      "author" : [ "Justine T. Kao", "Leon Bergen", "Noah D. Goodman" ],
      "venue" : "In Proceedings of the 36th Annual Meeting of the Cognitive Science Society,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2014
    }, {
      "title" : "Nonliteral understanding of number words",
      "author" : [ "Justine T. Kao", "Jean Y. Wu", "Leon Bergen", "Noah D. Goodman" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2014
    }, {
      "title" : "Speaking: From Intention to Articulation, volume 1",
      "author" : [ "Willem JM Levelt" ],
      "venue" : "MIT press,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1993
    }, {
      "title" : "Convention",
      "author" : [ "David Lewis" ],
      "venue" : "Reprinted",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1969
    }, {
      "title" : "Bringing machine learning and compositional semantics together",
      "author" : [ "Percy Liang", "Christopher Potts" ],
      "venue" : "Annual Review of Linguistics,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2015
    }, {
      "title" : "Generalized Linear Models",
      "author" : [ "Peter McCullagh", "John A. Nelder" ],
      "venue" : null,
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1989
    }, {
      "title" : "A Bayesian model of grounded color semantics",
      "author" : [ "Brian McMahan", "Matthew Stone" ],
      "venue" : "Transactions of the Association for Computational Linguistics,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2015
    }, {
      "title" : "Incremental speech production and referential overspecification",
      "author" : [ "Thomas Pechmann" ],
      "venue" : null,
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1989
    }, {
      "title" : "Embedded implicatures as pragmatic inferences under compositional lexical uncertainty",
      "author" : [ "Christopher Potts", "Daniel Lassiter", "Roger Levy", "Michael C. Frank" ],
      "venue" : "To appear in Journal of Semantics,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2015
    }, {
      "title" : "Speakers’ and listeners’ processes in a word communication",
      "author" : [ "Seymour Rosenberg", "Bertram D. Cohen" ],
      "venue" : "task. Science,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 1964
    }, {
      "title" : "Learning internal representations by error propagation",
      "author" : [ "David E. Rumelhart", "Geoffrey E. Hinton", "Ronald J. Williams" ],
      "venue" : "Parallel Distributed Processing: Explorations in the Microstructure of Cognition,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 1986
    }, {
      "title" : "Ad-hoc scalar implicature in adults and children",
      "author" : [ "Alex Stiller", "Noah D. Goodman", "Michael C. Frank" ],
      "venue" : "Proceedings of the 33rd Annual Meeting of the Cognitive Science Society,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2011
    }, {
      "title" : "Building a semantically transparent corpus for the generation of referring expressions",
      "author" : [ "Kees van Deemter", "Ielka van der Sluis", "Albert Gatt" ],
      "venue" : "In Proceedings of the Fourth International Natural Language Generation Conference,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2006
    }, {
      "title" : "Emergence of Gricean maxims from multi-agent decision theory. In Human Language Technologies: The 2013 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 1072–1081",
      "author" : [ "Adam Vogel", "Max Bodoia", "Christopher Potts", "Dan Jurafsky" ],
      "venue" : "Association for Computational Linguistics,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2013
    }, {
      "title" : "Learning to reason pragmatically with cognitive limitations",
      "author" : [ "Adam Vogel", "Andrés Gómez Emilsson", "Michael C. Frank", "Dan Jurafsky", "Christopher Potts" ],
      "venue" : "In Proceedings of the 36th Annual Meeting of the Cognitive Science Society,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "In the Gricean view of language use [18], people are rational agents who are able to communicate efficiently and effectively by reasoning in terms of shared communicative goals, the costs of production, prior expectations, and others’ belief states.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 10,
      "context" : "The Rational Speech Acts (RSA) model [11] is a recent Bayesian reconstruction of these core Gricean ideas.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 6,
      "context" : "RSA and its extensions have been shown to capture many kinds of conversational implicature and to closely model psycholinguistic data from children and adults [7, 2, 23, 30, 33].",
      "startOffset" : 159,
      "endOffset" : 177
    }, {
      "referenceID" : 1,
      "context" : "RSA and its extensions have been shown to capture many kinds of conversational implicature and to closely model psycholinguistic data from children and adults [7, 2, 23, 30, 33].",
      "startOffset" : 159,
      "endOffset" : 177
    }, {
      "referenceID" : 21,
      "context" : "RSA and its extensions have been shown to capture many kinds of conversational implicature and to closely model psycholinguistic data from children and adults [7, 2, 23, 30, 33].",
      "startOffset" : 159,
      "endOffset" : 177
    }, {
      "referenceID" : 28,
      "context" : "RSA and its extensions have been shown to capture many kinds of conversational implicature and to closely model psycholinguistic data from children and adults [7, 2, 23, 30, 33].",
      "startOffset" : 159,
      "endOffset" : 177
    }, {
      "referenceID" : 31,
      "context" : "RSA and its extensions have been shown to capture many kinds of conversational implicature and to closely model psycholinguistic data from children and adults [7, 2, 23, 30, 33].",
      "startOffset" : 159,
      "endOffset" : 177
    }, {
      "referenceID" : 0,
      "context" : "It seems that speakers often fall short: their utterances are longer than they need to be, underinformative, unintentionally ambiguous, obscure, and so forth [1, 10, 16, 24, 28, 29].",
      "startOffset" : 158,
      "endOffset" : 181
    }, {
      "referenceID" : 9,
      "context" : "It seems that speakers often fall short: their utterances are longer than they need to be, underinformative, unintentionally ambiguous, obscure, and so forth [1, 10, 16, 24, 28, 29].",
      "startOffset" : 158,
      "endOffset" : 181
    }, {
      "referenceID" : 15,
      "context" : "It seems that speakers often fall short: their utterances are longer than they need to be, underinformative, unintentionally ambiguous, obscure, and so forth [1, 10, 16, 24, 28, 29].",
      "startOffset" : 158,
      "endOffset" : 181
    }, {
      "referenceID" : 22,
      "context" : "It seems that speakers often fall short: their utterances are longer than they need to be, underinformative, unintentionally ambiguous, obscure, and so forth [1, 10, 16, 24, 28, 29].",
      "startOffset" : 158,
      "endOffset" : 181
    }, {
      "referenceID" : 26,
      "context" : "It seems that speakers often fall short: their utterances are longer than they need to be, underinformative, unintentionally ambiguous, obscure, and so forth [1, 10, 16, 24, 28, 29].",
      "startOffset" : 158,
      "endOffset" : 181
    }, {
      "referenceID" : 27,
      "context" : "It seems that speakers often fall short: their utterances are longer than they need to be, underinformative, unintentionally ambiguous, obscure, and so forth [1, 10, 16, 24, 28, 29].",
      "startOffset" : 158,
      "endOffset" : 181
    }, {
      "referenceID" : 3,
      "context" : "RSA can incorporate notions of bounded rationality [4, 13, 20], but it still sharply contrasts with views in the tradition of [6], in which speaker agents rely on heuristics and shortcuts to try to accurately describe the world while managing the cognitive demands of language production.",
      "startOffset" : 51,
      "endOffset" : 62
    }, {
      "referenceID" : 12,
      "context" : "RSA can incorporate notions of bounded rationality [4, 13, 20], but it still sharply contrasts with views in the tradition of [6], in which speaker agents rely on heuristics and shortcuts to try to accurately describe the world while managing the cognitive demands of language production.",
      "startOffset" : 51,
      "endOffset" : 62
    }, {
      "referenceID" : 19,
      "context" : "RSA can incorporate notions of bounded rationality [4, 13, 20], but it still sharply contrasts with views in the tradition of [6], in which speaker agents rely on heuristics and shortcuts to try to accurately describe the world while managing the cognitive demands of language production.",
      "startOffset" : 51,
      "endOffset" : 62
    }, {
      "referenceID" : 5,
      "context" : "RSA can incorporate notions of bounded rationality [4, 13, 20], but it still sharply contrasts with views in the tradition of [6], in which speaker agents rely on heuristics and shortcuts to try to accurately describe the world while managing the cognitive demands of language production.",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 32,
      "context" : "We validate the model on the task of attribute selection for referring expression generation with a widely-used corpus of referential descriptions (the TUNA corpus; [34, 15]), showing that it improves on heuristic-driven models and pure RSA by synthesizing the best aspects of both.",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 14,
      "context" : "We validate the model on the task of attribute selection for referring expression generation with a widely-used corpus of referential descriptions (the TUNA corpus; [34, 15]), showing that it improves on heuristic-driven models and pure RSA by synthesizing the best aspects of both.",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 23,
      "context" : "RSA is a descendent of the signaling systems of [25] and draws on ideas from iterated best response (IBR) models [13, 20], iterated cautious response (ICR) models [21], and cognitive hierarchies [4] (see also [17, 31]).",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 12,
      "context" : "RSA is a descendent of the signaling systems of [25] and draws on ideas from iterated best response (IBR) models [13, 20], iterated cautious response (ICR) models [21], and cognitive hierarchies [4] (see also [17, 31]).",
      "startOffset" : 113,
      "endOffset" : 121
    }, {
      "referenceID" : 19,
      "context" : "RSA is a descendent of the signaling systems of [25] and draws on ideas from iterated best response (IBR) models [13, 20], iterated cautious response (ICR) models [21], and cognitive hierarchies [4] (see also [17, 31]).",
      "startOffset" : 113,
      "endOffset" : 121
    }, {
      "referenceID" : 3,
      "context" : "RSA is a descendent of the signaling systems of [25] and draws on ideas from iterated best response (IBR) models [13, 20], iterated cautious response (ICR) models [21], and cognitive hierarchies [4] (see also [17, 31]).",
      "startOffset" : 195,
      "endOffset" : 198
    }, {
      "referenceID" : 16,
      "context" : "RSA is a descendent of the signaling systems of [25] and draws on ideas from iterated best response (IBR) models [13, 20], iterated cautious response (ICR) models [21], and cognitive hierarchies [4] (see also [17, 31]).",
      "startOffset" : 209,
      "endOffset" : 217
    }, {
      "referenceID" : 29,
      "context" : "RSA is a descendent of the signaling systems of [25] and draws on ideas from iterated best response (IBR) models [13, 20], iterated cautious response (ICR) models [21], and cognitive hierarchies [4] (see also [17, 31]).",
      "startOffset" : 209,
      "endOffset" : 217
    }, {
      "referenceID" : 1,
      "context" : "Models of this general form have been shown to capture a wide range of pragmatic behaviors [2, 12, 22, 23, 30] and to increase success in task-oriented dialogues [35, 36].",
      "startOffset" : 91,
      "endOffset" : 110
    }, {
      "referenceID" : 11,
      "context" : "Models of this general form have been shown to capture a wide range of pragmatic behaviors [2, 12, 22, 23, 30] and to increase success in task-oriented dialogues [35, 36].",
      "startOffset" : 91,
      "endOffset" : 110
    }, {
      "referenceID" : 20,
      "context" : "Models of this general form have been shown to capture a wide range of pragmatic behaviors [2, 12, 22, 23, 30] and to increase success in task-oriented dialogues [35, 36].",
      "startOffset" : 91,
      "endOffset" : 110
    }, {
      "referenceID" : 21,
      "context" : "Models of this general form have been shown to capture a wide range of pragmatic behaviors [2, 12, 22, 23, 30] and to increase success in task-oriented dialogues [35, 36].",
      "startOffset" : 91,
      "endOffset" : 110
    }, {
      "referenceID" : 28,
      "context" : "Models of this general form have been shown to capture a wide range of pragmatic behaviors [2, 12, 22, 23, 30] and to increase success in task-oriented dialogues [35, 36].",
      "startOffset" : 91,
      "endOffset" : 110
    }, {
      "referenceID" : 33,
      "context" : "Models of this general form have been shown to capture a wide range of pragmatic behaviors [2, 12, 22, 23, 30] and to increase success in task-oriented dialogues [35, 36].",
      "startOffset" : 162,
      "endOffset" : 170
    }, {
      "referenceID" : 34,
      "context" : "Models of this general form have been shown to capture a wide range of pragmatic behaviors [2, 12, 22, 23, 30] and to increase success in task-oriented dialogues [35, 36].",
      "startOffset" : 162,
      "endOffset" : 170
    }, {
      "referenceID" : 15,
      "context" : "RSA has been criticized on the grounds that it predicts unrealistic speaker behavior [16].",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 32,
      "context" : "In Section 6, we evaluate RSA and learned RSA in the TUNA corpus [34, 15], a widely used resource for developing and testing models of natural language generation.",
      "startOffset" : 65,
      "endOffset" : 73
    }, {
      "referenceID" : 14,
      "context" : "In Section 6, we evaluate RSA and learned RSA in the TUNA corpus [34, 15], a widely used resource for developing and testing models of natural language generation.",
      "startOffset" : 65,
      "endOffset" : 73
    }, {
      "referenceID" : 16,
      "context" : "This approach builds on the two-layer speaker-centric classifier of [17], but differs from theirs in that we directly optimize the performance of the pragmatic speaker in training, whereas [17] apply a recursive reasoning model on top of a pre-trained classifier.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 16,
      "context" : "This approach builds on the two-layer speaker-centric classifier of [17], but differs from theirs in that we directly optimize the performance of the pragmatic speaker in training, whereas [17] apply a recursive reasoning model on top of a pre-trained classifier.",
      "startOffset" : 189,
      "endOffset" : 193
    }, {
      "referenceID" : 7,
      "context" : "To build an agent that learns effectively from data, we must represent the items in our dataset in a way that accurately captures their important distinguishing properties and permits robust generalization to new items [8, 26].",
      "startOffset" : 219,
      "endOffset" : 226
    }, {
      "referenceID" : 24,
      "context" : "To build an agent that learns effectively from data, we must represent the items in our dataset in a way that accurately captures their important distinguishing properties and permits robust generalization to new items [8, 26].",
      "startOffset" : 219,
      "endOffset" : 226
    }, {
      "referenceID" : 18,
      "context" : "Learned RSA is built on top of a log-linear model, standard in the machine learning literature and widely applied to classification tasks [19, 27].",
      "startOffset" : 138,
      "endOffset" : 146
    }, {
      "referenceID" : 25,
      "context" : "Learned RSA is built on top of a log-linear model, standard in the machine learning literature and widely applied to classification tasks [19, 27].",
      "startOffset" : 138,
      "endOffset" : 146
    }, {
      "referenceID" : 30,
      "context" : "In optimizing the performance of the pragmatic speaker S1 by adjusting the parameters to the simpler classifier S0, the RSA back-and-forth reasoning can be thought of as a non-linear function through which errors are propagated in training, similar to the activation functions in neural network models [32].",
      "startOffset" : 302,
      "endOffset" : 306
    }, {
      "referenceID" : 4,
      "context" : "Imposing this prior helps prevent overfitting to the training data and thereby damaging our ability to generalize well to new examples [5].",
      "startOffset" : 135,
      "endOffset" : 138
    }, {
      "referenceID" : 2,
      "context" : "The stochastic gradient descent (SGD) family of first-order optimization techniques [3] can be used to approximately maximize J(θ) by obtaining noisy estimates of its gradient and “hillclimbing” in the direction of the estimates.",
      "startOffset" : 84,
      "endOffset" : 87
    }, {
      "referenceID" : 8,
      "context" : "To find a good learning rate, we use AdaGrad [9], which sets the learning rate adaptively for each example based on an initial step size η and gradient history.",
      "startOffset" : 45,
      "endOffset" : 48
    }, {
      "referenceID" : 15,
      "context" : "Pure RSA performs poorly for reasons predicted by [16]—for example, it under-produces color terms and head nouns like desk, chair, and person.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 13,
      "context" : "The performance of the learned RSA model on the people trials also compares favorably to the best dev set performance numbers from the 2008 Challenge [14], namely, .",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 13,
      "context" : "(In particular, the Accuracy values given in [14] are unfortunately not comparable with the values we present, as they reflect “perfect match with at least one of the two reference outputs” [emphasis in original].",
      "startOffset" : 45,
      "endOffset" : 49
    } ],
    "year" : 2015,
    "abstractText" : "The Rational Speech Acts (RSA) model treats language use as a recursive process in which probabilistic speaker and listener agents reason about each other’s intentions to enrich the literal semantics of their language along broadly Gricean lines. RSA has been shown to capture many kinds of conversational implicature, but it has been criticized as an unrealistic model of speakers, and it has so far required the manual specification of a semantic lexicon, preventing its use in natural language processing applications that learn lexical knowledge from data. We address these concerns by showing how to define and optimize a trained statistical classifier that uses the intermediate agents of RSA as hidden layers of representation forming a non-linear activation function. This treatment opens up new application domains and new possibilities for learning effectively from data. We validate the model on a referential expression generation task, showing that the best performance is achieved by incorporating features approximating well-established insights about natural language generation into RSA. 1 Pragmatic language use In the Gricean view of language use [18], people are rational agents who are able to communicate efficiently and effectively by reasoning in terms of shared communicative goals, the costs of production, prior expectations, and others’ belief states. The Rational Speech Acts (RSA) model [11] is a recent Bayesian reconstruction of these core Gricean ideas. RSA and its extensions have been shown to capture many kinds of conversational implicature and to closely model psycholinguistic data from children and adults [7, 2, 23, 30, 33]. Both Grice’s theories and RSA have been criticized for predicting that people are more rational than they actually are. These criticisms have been especially forceful in the context of language production. It seems that speakers often fall short: their utterances are longer than they need to be, underinformative, unintentionally ambiguous, obscure, and so forth [1, 10, 16, 24, 28, 29]. RSA can incorporate notions of bounded rationality [4, 13, 20], but it still sharply contrasts with views in the tradition of [6], in which speaker agents rely on heuristics and shortcuts to try to accurately describe the world while managing the cognitive demands of language production. In this paper, we offer a substantially different perspective on RSA by showing how to define it as a trained statistical classifier, which we call learned RSA. At the heart of learned RSA is the back-and-forth reasoning between speakers and listeners that characterizes RSA. However, whereas standard RSA requires a hand-built lexicon, learned RSA infers a lexicon from data. And whereas standard RSA makes predictions according to a fixed calculation, learned RSA seeks to optimize the likelihood of whatever examples it is trained on. Agents trained in this way exhibit the pragmatic behavior characteristic of RSA, but their behavior is governed by their training data and hence is only as rational as that experience supports. To the extent that the speakers who produced the data are pragmatic, learned RSA discovers that; to the extent that their behavior is governed by other factors, learned RSA picks up on that too. We validate the model on the task of attribute selection for referring expression generation with a widely-used corpus of referential descriptions (the TUNA corpus; [34, 15]), showing that it improves on heuristic-driven models and pure RSA by synthesizing the best aspects of both. 1 ar X iv :1 51 0. 06 80 7v 1 [ cs .C L ] 2 3 O ct 2 01 5 Learning in the Rational Speech Acts Model Monroe and Potts r1 r2 r3 (a) Simple reference game. be a rd gl a ss es ti e r1 .5 .5 0 r2 0 .5 .5 r3 0 0 1",
    "creator" : "easychair.cls-3.4"
  }
}