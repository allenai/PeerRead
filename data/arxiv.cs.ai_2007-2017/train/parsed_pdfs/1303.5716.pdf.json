{
  "name" : "1303.5716.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Symbolic Decision Theory and Autonomous Systems",
    "authors" : [ "John Fox" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "The ability to reason under uncertainty and with incomplete information is a fundamental require ment of decision support technology. In this paper we argue that the concentration on theoretical techniques for the evaluation and selection of de cision options has distracted attention from many of the wider issues in decision making. Although numerical methods of reasoning under uncertain ty have strong theoretical foundations, they are representationally weak and only deal with a small part of the decision process. Knowledge based systems, on the other hand, offer greater flexibility but have not been accompanied by a clear decision theory. We describe here work which is under way towards providing a theoreti cal framework for symbolic decision procedures. A central proposal is an extended form of infer ence which we call argumentation; reasoning for and against decision options from generalised do main theories. The approach has been successful ly used in several decision support applications, but it is argued that a comprehensive decision the ory must cover autonomous decision making, where the agent can formulate questions as well as take decisions. A major theoretical challenge for this theory is to capture the idea of reflection to permit decision agents to reason about their goals, what they believe and why, and what they need to know or do in order to achieve their goals.\n1 INTRODUCTION1\nMedicine has been an important field for developing and testing decision support systems which are capable of rea soning with uncertain and incomplete information. Ex peri-\nments with numerical techniques for diagnosis and other applications began in the sixties, and produced some early encouraging progress, notably de Dombal's classic work on the diagnosis of abdominal pain [ 1]. By the end of the seventies, systems such as MYCIN, INTERNIST and CASNET were showing that symbolic techniques for knowledge representation, inference and heuristic reason ing held much promise for decision support systems. While arousing great excitement, these early expert systems were also treated with some skepticism by decision theorists on the grounds that they were somewhat ad hoc in design. This stimulated a great deal of technical activity in developing more rigorous and precise numerical uncertainty handling techniques, but we feel that this has distracted attention from many fundamental issues which still need to be ad dressed in order to produce flexible and sound decision support systems that will have significant impact in many practical applications.\nA major cause of the criticisms levelled at some of the above mentioned systems, was the attempt to incorporate uncertainty handling into a simple rule-based knowledge representation framework. There is, unfortunately, a funda mental conflict between the demands of computational tractability and of semantic expressiveness. The modulari ty of simple rule-based systems aids efficient data update procedures. However, severe evidence independence as sumptions have to be made for uncertainties to be com bined and propagated using strictly local calculations. A general and rigorous implementation of a fully intentional system, in which all possible interactions between rules and evidences are taken into account on each data update, could become so computationally intractable that the de velopment of a realistic application would be infeasible\n1. This paper is a shortened and revised version of a keynote address given at the IMACS workshop in Qualitative Reason ing and Decision Support Systems, Toulouse, March 13-15, 1991 [8].\n104 Fox and Krause\n(12]. In order to develop computationally tractable, yet rig orous, uncertainty handling mechanisms much recent work has been directed towards the development of graphical structures in which the dependencies and influences be tween knowledge items are explicitly represented [11], [13]. This has led to a realisation that the correct structuring of the knowledge that is relevant in a given decision mak ing context is as important, if not rrwre important, than the numerical values that are propagated through the graph.\nIn fact, at least for certain classes of applications such as medical diagnostic applications, decision accuracy can be highly insensitive to these values. In [2] for example the performance of a strictly probabilistic approach to diagno sis and a heuristic approach were quantitatively compared. Using a database of medical records of some 400 patients who had been reliably diagnosed as having one of 5 differ ent gastrointestinal conditions, two diagnostic systems were constructed. The first was a simple bayesian proce dure for computing posterior probabilities given a set of pa tient symptoms. The second was a set of categorical production rules for interpreting patterns of symptoms. The rules excluded quantitative information about the associa tions between symptoms and diseases. A typical rule was:\nif: age( elderly) and weight_loss(present) then: maybe(cancer)\nIt turned out that the diagnostic accuracy of the rule-based system approximately equalled that of the probabilistic system (-70%)1 while requesting only half the available symptom data. The relative naturalness of the categorical representation did not apparently entail a significant reduc tion in decision making performance.\nThere are well documented differences between the per formance of different numerical calculi [17], [18]. Howev er, theoreticians have not paid so much attention to studies comparing precise with imprecise methods like the above. There is considerable evidence that the performance of a well structured, largely symbolic system may well be as good as a more rigorous numerical approach [20]. In [28], it was demonstrated that a purely symbolic system only dif fered in behaviour from a numerical probabilistic system in those cases with an uncommon diagnosis (prior probability ::; 0.03). Chard's conclusion was that, so long as it could be ensured that a purely symbolic approach could pick up the less common conditions, then it would suffer no perform ance disadvantage when compared to a bayesian system.\nWe will go further than simply saying there is no disadvan tage; we shall argue that a symbolic approach to decision making has in fact many advantages (other than reducing the purely computational and cost overheads associated with the elicitation and use of large amounts of numerical data). The next section will suggest that a symbolic ap proach allows us to explicate more of the decision process,\n1. This figure is not untypical; in gastroenterology a diagnostic accuracy from the patient history alone is frequently much lower than this because of high intrinsic uncertainty.\nincluding the knowledge required to define, organise and make a decision. It also allows us to explicitly represent de cisions, knowledge sources, reasoning strategies and repre sentations, and to reason about the control and inference processes involved in specific tasks. These are all require ments which need to be satisfied if we are to be able to de velop systems with an advanced decision making capability. The third section of this paper addresses the re quirements of a particularly challenging class of AI system, those capable of making decisions autonomously.\n2 SYMBOLIC DECISION MAKING\nUNDER UNCERTAINTY\nThe Concise Oxford Dictionary defines a decision as fol lows \"Decision: settlement of (question etc.), conclusion, formal judgement, making up one's mind\". But how should we settle questions, particularly where they involve uncer tainty? The view from classical decision theory is quite un equivocal:\n\"First, the uncertainties present in the situation must be quantified in terms of values called probabilities. Second, the various consequences of the courses of action must be similarly described in terms of utilities. Third that decision must be taken which is expected- on the basis of the calcu lated probabilities- to give the greatest utility.\"\nDennis Lindley [3].\nProbabilistic inference, or \"how degrees of belief are al tered by data\"(4] is one of the two pillars of classical deci sion theory. Unfortunately it is widely acknowledged that objective probabilities (e.g. frequency based estimates of the cooccurrence of symptoms and diseases) are impracti cal for general decision making. Therefore the Bayesian notion of \"subjective probability\", of a person's willing ness to accept a wager, has been formulated in a well-de fined way in order to finesse this difficulty.\nIn reality the (psychological) processes that are involved in the formulation of subjective probabilities, and the formal nature of such numbers, are obscure. Probabilistic infer ence certainly places clear mathematical requirements on \"coherent\" belief revision procedures but it pays little at tention to the question of what numerical degrees of belief can be said to represent. Unfortunately, heuristic methods may suffer from the reverse problem; while symbolic rep resentational techniques are claimed to capture knowledge of informal domains like medicine quite well, the formal requirements of sound reasoning are not always adequately addressed.\nThe second pillar of decision theory is utility: roughly a nu merical representation of the costs and benefits associated with deciding on a particular option. Unfortunately, as with probability, though for different reasons, it is often difficult to assign objective measures of utility to the consequences of decisions (e.g. the utility of life and death; pain or dis tress). Even in situations where there seems to be an objec tive scale (e.g. monetary value) the relationship between\nsubjective and objective scales is not at all clear. It should also be noted that subjective values are multidi mensional not unidimensional, and often qualitative. For example a drug treatment may be desirable because it is painless, because it can be taken at home, and because it is low cost, while it may be less desirable than a surgical pro �edure because �e latter has a higher success rate, though It may compromise long term quality of life. Quantitative repr�sentation of values remains, at the very least, contro versial.\nIn this section we will describe techniques for a number of aspects of decision making which are non-quantitative and yet can be clearly formulated. These techniques make use of first-order logic (POL) to formulate methods for reason i?g for and a�ainst decision options; introducing new op tions; structunng the decision; representing beliefs, values and preferences; taking the decision, and improving com munication between decision support systems and their us ers.\n2.1 EXTENDING THE REQUIREMENTS FOR SYMBOLIC REASONING\nInf�r�nce is t�e p!vot of most kinds of problem solving and deciSion makmg IS no exception. Classical decision theory eJ?lphasises probabilistic inference, and many other tech mques (both numerical and logical) are being developed to capture aspects of commonsense inference which are not expressible in standard monotonic logic [22]. However,\nDecision Theory and Autonomous Systems 105\nthese formalisations apply to just one (albeit a central one) of the activities �ssociated with decision support. They ad dress the evaluation and selection of decision options. Sur rounding this activity are a number of further layers of activities, represented in figure 1 (after Andriole [5]), in volving information acquisition, the actual identification of relevant decision options, and so forth. The concentration on the development of formalisms for option evaluation and selection h� distracted attention from providing a more formal basis for these other activities [6).\nTo address the requirements raised by a more eclectic view of �ecisio\n. n support we shall have to extend radically our\n?otion of mference to one which can work at the multiplic Ity of levels represented in figure 1. We need to construct a general inference mechanism which satisfies at least the following requirements:\n1. I� must ?e able to construct arguments for decision op tions usmg whatever knowledge is productive; we do not wish to restrict reasoning to, nor for it to wholly de pend upon, any one kind of inference (such as statisti cal inference) if this is restrictive.\n2. There must be an explicit conceptualisation of what it means to make a decision and the roles of different kinds of inference in that process [7].\n3. I� is desirable .� have a simple declarative representa tion of the deciSion procedure, decision criteria and ap plication knowledge, permitting greater flexibility and\n106 Fox and Krause\nmore natural understanding by designers and users.\n4. Of course we also want our extended inference to be well understood and mathematically sound.\nThe demand for greater capabilities in decision support systems, and the need to address these requirements is en capsulated in a central goal of our research: achieving a deep understanding of what we have dubbed symbolic de cision procedures (SDPs). Informally a symbolic decision procedure can be characterised as:\nan explicit representation of the knowledge required to de fine, organise and make a decision, and ... a logical ab straction from the qualitative and quantitative knowledge that is required for any specific application. A SDP may in clude a specification of when and how the procedure is to be executed [6].\nThe basic idea of classical decision making is the weighing of quantitative evidence and values for predefined options; the fundamental mechanism of a symbolic decision proce dure is a flexible framework for qualitative reasoning that we call argumentation. Argumentation provides a rigorous basis for weighing the pros and cons of decisions but also for structuring the decision and, as we shall see later, for controlling the initiation and execution of a decision proc ess.\n2.2 INFERENCE AND \"ARGUMENTATION\"\nOur central thesis is that practical decision making requires diverse sources of domain specific and domain independ ent knowledge. The relevance and nature of various forms of knowledge may vary with the context and the decision. To accommodate this, we use an extended form of infer ence, which we call argumentation. Informally we want to capture some of the kinds of argument that are commonly used in decision making, such as \"based on the facts that the patient is elderly and suffering from weight loss, there is support for the proposition that cancer is present\"\nArgumentation consists of the identification and appraisal of lines of reasoning about propositions. Argumentation permits the use of whatever theories and sources of knowl edge are deemed appropriate. An argument for a proposi tion P may have an associated qualifier or sign SP which represents the certainty of the proposition given that the ar gument is valid. The grounds for the argument, Gp• are also associated with the proposition. These indicate the facts used in initiating the argument, and the theories used to connect these facts with P.\nMore formally, if an argument is identified for a proposi tion P, then we may write KB f- (P,Sp,Gp) with SP and GP as above. The qualifier S.P and grounds GP are not merely present to provide useful mformation to the user. They also satisfy a more formal requirement. Multiple triples will be associated with a proposition P if P can be deduced with different qualifiers SP, or with the same qual-\nifiers but using different grounds GP. We say these consti tute distinct arguments for P.\nThe knowledge base, KB, over which the inference engine operates may be partitioned into a number of theories. These may be domain specific theories, consisting primari ly of ground facts, or domain independent theories consist ing of first order rules for establishing links between knowledge items in a given task. A further knowledge layer may contain information about which theories are relevant to which specific tasks. In our view practical decision mak ing may involve arguing from different points of view (e.g. arguing from a causal theory, an anatomical theory, a theo ry of physiological function or from statistical knowledge). The kinds of theory that are relevant are determined by the kind of decision that is being taken. We have to keep these theories partitioned because in practice we cannot guaran tee that the different views that they embody are globally consistent.\nA more detailed discussion on how arguments can be con structed may be found in [9] and [26].\n2.3 AGGREGATION OF ARGUMENTS\nWe have seen that from different grounds it is possible to construct multiple arguments about (for or against) a prop osition. If:\nKB f- (P,SJ,GJ) KB f- (P,S2,Gz)\nwhere S1 i' S2, or G1 i' G2, then there are two distinct argu ments for P. Once two or more distinct arguments have been identified for a proposition P, the associated qualifiers S; will need to be aggregated to form a global qualification ofP.\nThe process of argumentation allows plenty of scope for the definition of various aggregation operators, both nu merical and qualitative. The Si may be taken from a variety of symbolic or numeric dictionaries. Here we shall focus on a simple 4-valued dictionary:\n(confirmed, eliminated, supported, opposed}.\nexactly one of which must be associated with each argu ment. The semantics of these terms is not numerical, but where probabilities (or other numerical certainty data) are available they could be substituted without modification to the basic argumentation framework.\nOur interest of course is in the more common situation where those data are not available. A straightforward ag gregation operator is simply to add up the arguments for and against each option, and decide on that with the largest ratio of pros to cons. This was the method employed in the gastroenterology example described in the introduction, and such improper linear decision rules are well recognised as effective.\nWe can also formulate symbolic aggregation operators. Making the grounds explicit in the argument has obvious value in the user interface, but they can also play an im-\nportant part in aggregation because we can use them in computing states of belief in options (or any proposition). This can be done using logical schemata which demand no numerical coefficients, but which we believe are intuitively appealing and logically coherent.\nThe following symbolic aggregation rules1 define logical schemata for assigning propositions to various classes of belief: conceivable; possible; plausible; confirmed.\n(P, conceivable) �not 3G • (P, G, eliminated).\n(P, possible) � (P, conceivable) A 3G • (P,G, supported).\n(P, plausible) � (P, possible) A not 3G • (P, G, opposed).\n(P, confrrmed) � (P, conceivable) A 3G • (P, G, confrrmed).\nThe aggregation operator defined by this schema allows only a fairly coarse-grained categorisation of decision op tions. A more complex schema could be defined to allow finer distinctions, but in The Oxford System of Medicine (OSM), a decision support system designed to provide flexible assistance for general medical practice (and a spe cialised derivative for oncology, BOSS) [16], the 4 qualifi ers in the dictionary above, together with the belief terms constructible from them, provide an adequate basis for car rying out decision making.\nOur contention is that for many problems, where limited statistical data are available, attempts to use numbers to make a fine grained distinction between decision options may be unnecessary, and lead to illusory precision in the fi nal result. A logical approach to arguing for and against and comparing decision options, on the other hand, has a clear ly defined semantics which is easily explained to and un derstood by the user.\n2.4 DISCUSSION\nCurrent probabilistic techniques require the prior construc tion of the �aph linking decision options to observables and findings . However, the exact nature of these links may vary with context and the nature of the decision problem at hand, and in general decision systems should be able to construct and revise the graph dynamically as information becomes available and the goals of the problem at hand are identified [15]. Our approach allows for arguing about this graph structure [14],[15]; for example, the discovery that a patient is under medication which can cause an observed abnormality as a side effect may lead to a revision of the graph that had previously been generated.\nWe have described a purely symbolic approach to identify-\n!. Called \"annotation rules\" in [6], [14], [15]. 2. Although we are grateful to an anonymous referee for draw ing our attention to work that is underway to correct this defi ciency.\nDecision Theory and Autonomous Systems 107\ning and evaluating decision options. Further to this, we aim to develop techniques which address how and when a deci sion may be taken. As with symbolic terms for representing states of belief, symbolic representations of preference and value may not be arbitrary but must be assigned an explicit semantics. In order to avoid confounding distinct logical ideas like obligations, duties and preferences we are taking an approach in which arguments are constructed from prin ciples of what must be done (\"deontic\" principles) and what ought to be done (\"praxeological\" principles) and pluralis tic value theory [10].\nIt is our intention to strive towards a normative theory of decision making. To achieve this we need \"an explicit con ceptualisation of what it means to make a decision\" (re quirement 2 above). A possible approach to this is discussed in the next section.\n3 AUTONOMOUS DECISION MAKING\nUNDER UNCERTAINTY\nThe central claim of section 2 was that symbolic proce dures can significantly extend the capabilities for reasoning about belief and values and structuring the decision as com pared with strictly numerical procedures (requirement 1 above). A further advantage we claim is that a symbolic ap proach allows for an explicit representation of the decision itself. Neither classical decision theory nor work on knowl edge based decision aids have placed emphasis on this, ap parently because these systems are intended to assist in decision making, not to make decisions autonomously. They can rely on knowledgeable users to critically super vise the decision process. In our view this is a serious omis sion from, and challenge to, theory. For practical reasons and to be confident in our understanding of the limits on de cision making capabilities we need to address the problem of building systems that can operate autonomously, with out relying on external support.\nThere is a steadily increasing interest in AI in the develop ment of autonomous agents [23]. In particular SOAR, an \"architecture for general intelligence\" [21] and HOMER, a simulated submersible capable of receiving task instruc tions and autonomously planning its solution [24], are projects which are making interesting progress towards au tonomous capabilities. Although not developed with either decision theory or uncertainty management in mind they may guide us towards a statement of what the capabilities of an autonomous decision system should be. We first at tempt the following definition of an autonomous agent:\nAn agent is autonomous with respect to its environment if it can set and achieve goals, and respond adaptively to events in its environment, without external advice or assist ance.\nPractical environments are frequently so complex they can evolve in far more ways than could be allowed for in any a priori structuring of a decision. A definite requirement for an autonomous decision maker therefore is that it should be\n108 Fox and Krause\nresponsive to the arrival of unexpected information. For ex ample, HOMER [24] is given an instruction to collect a package from a pier and constructs a plan to do this. En route, however, it finds a large ship on its course; HOMER must perceive this, recognise its implications and replan to achieve its goal.\nIn general information may at any time become available to a decision maker that has implications for any aspect of a decision viz: raising new problems requiring additional de cisions; challenging the grounds for current beliefs, or in dicating that the current decision can be taken without further information.\nPart of the responsiveness of an effective decision maker is the ability to recognise that there is a decision to be taken. The Concise Oxford Dictionary relates a decision to the \"settlement of a question\". Classical decision theory has had much to say about how we should settle a question; the new challenge is to understand how these questions are formulated in the first place. This suggests a revision to our definition:\nAn agent is an autonomous decision maker if it can pose and resolve questions about the state of its envir011ment or the actions that are desirable to achieve its goals\nIf a decision maker could ask and answer questions such as the following it would gain great power:\n1. The pivotal questions are: what is the problem? what do I need to know, or do? As with all AI systems we will necessarily require an explicit representation of the systems goals in order to be able to formulate these questions. Decision theory has taken the question of what a decision is required for entirely for granted. As soon as we address it a cascade of further questions follows."
    }, {
      "heading" : "2. What do I know that is relevant to this decision? An",
      "text" : "agent that has a great deal of knowledge may encoun ter difficulties in retrieving relevant knowledge during decision making. Explicit representation of theories and their applicability aids search."
    }, {
      "heading" : "3. What are the possible options? How could I find out?",
      "text" : "Symbolic decision procedures can introduce decision options as information is acquired by making use of explicit advice like \"in diagnosis, propose possible causes of symptoms as possible diagnoses\".\n4. What justifies a belief (value or preference)? Is this ar gument still valid? Practical problem solving almost always risks blind-alleys and misunderstandings. The underpinning of beliefs by explicit arguments that record the grounds for those beliefs provides the infor mation necessary for detecting and resolving incon sistencies [25].\n5. Am I thinking about this decision the right way? All problem solving takes place in a \"problem space\" which embodies presuppositions about the problem\nand affects the way problem solving proceeds. If pre suppositions or representations are implicit then we are at the mercy of them. If theories and presupposi tions are explicit then the agent potentially has the ability to detect when assumptions of validity or rele vance are violated.\n3.1 REQUIREMENTS AND SKETCH OF AN AUTONOMOUS DECISION MAKER\nIn this section we summarise some of the principle require ments for a comprehensive decision capability and the main theoretical challenges that they entail. The principle requirements for an autonomous decision maker include the following:\n1. It should be able to observe and interpret its environ ment, and recognise when a decision or sequence of decisions needs to be taken in order to achieve its goals.\n2. Goals and decisions should be represented explicitly. One approach (used in the OSM and BOSS) is to rep resent the \"generic\" decision as the root class in a gen eralisation hierarchy. This defines the decision procedure as a set of partially instantiated attribute templates, such as:\ndecision_prototype(Decision,Prototype). relevant_ theories(Decision, Theories). relevant_argument_types(Decision,Arguments). option_proposal_criteria(Decision,Criteria). ...\n3. The decision maker should be able to classify the types of decision required. One way to do this is to associate with each class a particular decision_prototype, invok ing it when its prototype is satisfied. For example a prototype for a diagnosis decision may specify that if an observation has been made that is abnormal and its cause is not known then a decision of class \"diagnosis\" is required in the context. Specific classes of decision inherit the generic attributes, but are distinguished from it by the values that instantiate the attribute tem plates, as in:\nrelevant_theories( diagnosis, symptomatology). relevant_argument_types( diagnosis,causali ty). option_proposal_criteria(diagnosis,possibility) ...\n4. The agent must be able to initiate the decision in the context; this will entail inheriting all the class informa tion to the decision instance, further instantiating it with details of the context (e.g. a patient's name) and presumably executing some control actions.\n5. Guiding the decision process. Explicit knowledge of relevant theories and arguments associated with the decision class can be used to guide information acqui sition and data interpretation. Decision options (e.g. diagnoses) can be proposed on the basis of criteria as sociated with the class (in the above example any op tion is proposed as a candidate if it satisfies the condition for being \"possible\" (section 2).\n6. The decision should be terminated when appropriate. Explicit criteria for formulating decisions also pre sumably imply criteria for knowing when those deci sions can be taken. For example, the criterion given above for requiring a diagnosis decision was that we cannot confirm the cause of an abnormal observation. The opposite is also true; if we can confirm the cause then the diagnosis can be made.\nWork is in progress to provide an adequate theoretical basis for these capabilities, and to demonstrate their application. Figure 2 presents a schematic outline of a proposed layered architecture for autonomous decision agents. The ascend ing layers represent knowledge at increasing levels of ab straction; each layer is capable of manipulating the know ledge in the layers beneath it.\nThe three lower layers are deductive data bases represent ing (in ascending order) domain theories (application spe cific knowledge), task theories (knowledge about decisions), and the symbolic decision procedure itself. The top layer in figure 2 may be described as a control layer; among its functions are to look after interactions with the environment, respond to events, initiate, control and termi nate decisions and arguments, and maintain the agent's be liefs and goals. This organisation echoes the traditional distinction between knowledge and action; the symbolic decision procedure and other deductive components can be naturally implemented with a pure logic theorem prover, while the top layer - which operates in time, entails side-ef fects on the system's knowledge, and has other non-logical features - is procedural in character.\nA full explanation of these examples would need a detailed description of an interpreter, which cannot be presented here. Some discussion of techniques to provide this capa bility can be found in [27].\n4 PRINCIPLE RESEARCH DIRECTIONS\nIt is imJX>rtant to carry out work like this in the context of applications. The OSM and BOSS systems, under develop ment in this laboratory, have been important in forcing us to develop our approaches and in evaluating our ideas. For generality we would like to see applications in domains other than medicine and for decision tasks other than med ical decisions. We also hope to build on our approach to look into compound decisions, such as planning, design and other tasks. These tasks can be viewed (in part) as com plexes of simple selection decisions. Some experimental work on integrating decisions in problem solving is in progress, focusing on planning of cancer treatment and for mulation of antibiotic therapy for chest infections [19].\nWe are in the early stages of formalising argumentation and other aspects of symbolic decision making, focusing on non-autonomous decision support systems. Some work on autonomous systems is in progress, and influences the work, but for the moment is of lower priority.\nPerhaps one of the most obvious features of our proposals is the importance we attach to meta-level reasoning, or re flection. To express the questions in section 3 and imple ment the mechanisms required in section 3.1 it seems clear that considerable capabilities for reflection are needed - re flecting on beliefs, arguments, knowledge, and decisions. Classical decision procedures offer few handholds for de veloping these ideas. Formalising the concept of reflection will be, we believe, fundamental to significant progress in the field. It is perhaps the most difficult yet most fascinat ing theoretical challenge before us.\n110 Fox and Krause\nAcknowledgements\nWe would like to thank all our colleagues in the Biomedi cal Computing Unit for many useful discussions on this work, but especially Saki Hajnal, Dominic Clark, Andrzej Glowinski, Mike O'Neil and Mirko Dohnal. This work has received an added stimulus with our involvement in and support from the Esprit Basic Research Programme 3085, DRUMS.\nP. Krause is supported under the SERC project 1822: a For mal Basis for Decision Support Systems. Our thanks also to Mike Clarke of Queen Mary College who is involved in this project with us.\nReferences\n[I] de Do mba!, F T \"Computer assisted diagnosis of Ab dominal pain\" in J Rose and J H Mitchell Advances in Med ical Computing, Edinburgh: Churchill Livingstone,l975.\n[2] Fox J, Barber D C, Bardhan K D \"Alternatives to Bayes: A quantitative comparison with rule-based diagno sis\". Method of Information in Medicine, 1980.\n[3] Lindley D V Making decisions (2nd ed) Wiley 1985.\n[4] Lindley D V Introduction to probability and statistics: part 2. inference. Cambridge: Cambridge University Press, 1965.\n[5] Andriole S J Handbook of decision support systems, Blue Ridge: Tab Books, 1989.\n[6] Fox J \"Symbolic decision procedures for knowledge based systems.\" Chapter 2 in H Adeli (ed) Knowledge En gineering, New York: McGraw Hill, 1989.\n[7] Fox J \"Formal and knowledge based methods for deci sion technology\" Acta Psychologica, 56, 303-331, 1984.\n[8] Fox J \"Decision Theory and Autonomous Systems\" Proc IMACS workshop, 1991.\n[9] Fox J, Clarke M \"Towards a formalisation of arguments in decision making\" Proceedings of Stanford Spring Sym posium in AI, 1991.\n[I 0] Clarke M \"A model of practical reasoning for decision support systems\" Proc IMACS workshop, 1991.\n[IIJ Pearl J Heuristics: Intelligent Search Strategies for Computer Problem Solving, Addison-Wesley: Reading MA, 1984.\n[12] Pearl J Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, Morgan Kaufmann, 1988.\n[13] Lauritzen S L and Spiegelhalter D \"Local computa tions with probabilities on graphical stuctures and their ap plication to expert systems\" J Roy. Statist. Soc B 50 (2), 1988.\n[14] Fox J, Glowinski A J, O'Neil M \"Decision making from a logical point of view\" in B Kelly and A Rector Re search in Expert Systems V, Cambridge: Cambridge Uni versity Press, 1988.\n[15] Fox J, Clark D A, Glowinski A J, O'Neil M \"Using predicate logic to integrate qualitative reasoning and clas sical decision theory\" IEEE Trans on Systems Man and Cy bernetics, 20, 347-357, 1990.\n[16] Fox J, Gordon C, Glowinski A J and O'Neil M \"Logic engineering for knowledge engineering\" Artifical Intelli gence in Medicine, 2, 323-339, 1990.\n[17] Beckerman D, \"An Empirical Comparison of Three Inference Methods\" in Shachter, Levitt, Kanal and Lem mer, eds, Uncertainty in Artificial Intelligence 4, Amster dam: North-Holland, 283-301, 1990.\n[18] Henrion M, \"Some Practical Issues in Constructing Belief Networks\" in Kanal, Levitt and Lemmer, eds, Un certainty in Artificial Intelligence 3, Amsterdam: North Holland, 161-173, 1989.\n[19] O'Neil M \"An abstract description of a general ap proach to problem solving\", ICRF technical report, 1991.\n[20] O'Neil M, Glowinski A \"Evaluating and validating very large knowledge-based systems\" Med. Inform., 15, 237-251, 1990.\n[21] Laird J, Newell A, Rosenbloom P \"SOAR: an archi tecture for general intelligence\" Artificial Intelligence, 1987.\n[22] Smets P, Mamdani E H, Dubois D, Prade H, Non Standard Log:�s for Automated Reasoning, Academic Press, 1988.\n[23] See! N R, for example, \"From Here to Agent Theory\" in AISB Quarterly, Quarterly Newsletter of the Society for the Study of Artificial Intelligence and the Simulation of Behaviour, no 72, 1990.\n[24] Vere S, Bicknell T \"A Basic Agent\" Computational Intelligence, 6 (1) 41-60, 1990.\n[25] Krause P J, Byers P, Hajnal S, Fox J \"The use of ob ject-oriented process specification for the validation and verification of decision support systems\" in Aye! M and Laurent J-P eds, Validation, Verification and Test of Knowledge-Based Systems, Chichester: John Wiley, 1991.\n[26] Krause P J and Fox J \"Combining symbolic and nu merical methods for reasoning under uncertainty\" in AI and Computer Power: The Impact on Statistics, Unicorn Semi nars Ltd, 1991.\n[27] Fox J, Gordon C, Glowinsk A J, O'Neil M \"Expert systems, databases and decision procedures\" Proceedings of Medical Informatics Europe, Berlin: Springer 1990.\n[28] Chard T \"Qualitative probability versus quantitative probability in clinical diagnosis: a study using a computer simulation\" Medical Decision Making, 1991, 11,38-41."
    } ],
    "references" : [ {
      "title" : "Alternatives to Bayes: A quantitative comparison with rule-based diagno­ sis",
      "author" : [ "J Fox", "C Barber D", "D Bardhan K" ],
      "venue" : "Method of Information in Medicine,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1980
    }, {
      "title" : "Making decisions (2nd ed",
      "author" : [ "V Lindley D" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1985
    }, {
      "title" : "Introduction to probability and statistics: part 2. inference",
      "author" : [ "V Lindley D" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1965
    }, {
      "title" : "Handbook of decision support systems, Blue Ridge",
      "author" : [ "J Andriole S" ],
      "venue" : "Tab Books,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1989
    }, {
      "title" : "Symbolic decision procedures for knowledge based systems.\" Chapter 2 in H Adeli (ed) Knowledge En­",
      "author" : [ "J Fox" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1989
    }, {
      "title" : "Formal and knowledge based methods for deci­ sion technology",
      "author" : [ "J Fox" ],
      "venue" : "Acta Psychologica,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1984
    }, {
      "title" : "Decision Theory and Autonomous Systems",
      "author" : [ "J Fox" ],
      "venue" : "Proc IMACS workshop,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1991
    }, {
      "title" : "Towards a formalisation of arguments in decision making",
      "author" : [ "J Fox", "M Clarke" ],
      "venue" : "Proceedings of Stanford Spring Sym­ posium in AI,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1991
    }, {
      "title" : "A model of practical reasoning for decision support systems",
      "author" : [ "M Clarke" ],
      "venue" : "Proc IMACS workshop,",
      "citeRegEx" : "Clarke,? \\Q1991\\E",
      "shortCiteRegEx" : "Clarke",
      "year" : 1991
    }, {
      "title" : "Heuristics: Intelligent Search Strategies for Computer Problem Solving, Addison-Wesley",
      "author" : [ "J IIJ Pearl" ],
      "venue" : "Reading MA,",
      "citeRegEx" : "Pearl,? \\Q1984\\E",
      "shortCiteRegEx" : "Pearl",
      "year" : 1984
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "author" : [ "J Pearl" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1988
    }, {
      "title" : "Local computa­ tions with probabilities on graphical stuctures and their ap­ plication to expert systems",
      "author" : [ "L Lauritzen S", "D Spiegelhalter" ],
      "venue" : "J Roy. Statist. Soc B",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1988
    }, {
      "title" : "Logic engineering for knowledge engineering",
      "author" : [ "J Fox", "C Gordon", "J Glowinski A", "M O'Neil" ],
      "venue" : "Artifical Intelli­ gence in Medicine,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1990
    }, {
      "title" : "From Here to Agent Theory\" in AISB Quarterly, Quarterly Newsletter of the Society for the Study of Artificial Intelligence and the Simulation of Behaviour",
      "author" : [ "R See! N" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1990
    }, {
      "title" : "A Basic Agent",
      "author" : [ "S Vere", "T Bicknell" ],
      "venue" : "Computational Intelligence,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1990
    }, {
      "title" : "Combining symbolic and nu­ merical methods for reasoning under uncertainty\" in AI and Computer Power: The Impact on Statistics",
      "author" : [ "J Krause P", "J Fox" ],
      "venue" : "Unicorn Semi­ nars Ltd,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1991
    }, {
      "title" : "Expert systems, databases and decision procedures",
      "author" : [ "J Fox", "C Gordon", "J Glowinsk A", "M O'Neil" ],
      "venue" : "Proceedings of Medical Informatics Europe,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1990
    }, {
      "title" : "Qualitative probability versus quantitative probability in clinical diagnosis: a study using a computer simulation",
      "author" : [ "T Chard" ],
      "venue" : "Medical Decision Making,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1991
    } ],
    "referenceMentions" : [ ],
    "year" : 2011,
    "abstractText" : "The ability to reason under uncertainty and with incomplete information is a fundamental require­ ment of decision support technology. In this paper we argue that the concentration on theoretical techniques for the evaluation and selection of de­ cision options has distracted attention from many of the wider issues in decision making. Although numerical methods of reasoning under uncertain­ ty have strong theoretical foundations, they are representationally weak and only deal with a small part of the decision process. Knowledge­ based systems, on the other hand, offer greater flexibility but have not been accompanied by a clear decision theory. We describe here work which is under way towards providing a theoreti­ cal framework for symbolic decision procedures. A central proposal is an extended form of infer­ ence which we call argumentation; reasoning for and against decision options from generalised do­ main theories. The approach has been successful­ ly used in several decision support applications, but it is argued that a comprehensive decision the­ ory must cover autonomous decision making, where the agent can formulate questions as well as take decisions. A major theoretical challenge for this theory is to capture the idea of reflection to permit decision agents to reason about their goals, what they believe and why, and what they need to know or do in order to achieve their goals.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}