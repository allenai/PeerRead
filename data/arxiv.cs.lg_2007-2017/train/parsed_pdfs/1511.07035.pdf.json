{
  "name" : "1511.07035.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Detecting Road Surface Wetness from Audio: A Deep Learning Approach",
    "authors" : [ "Irman Abdić", "Lex Fridman", "Erik Marchi", "Daniel E. Brown", "William Angell", "Bryan Reimer", "Björn Schuller" ],
    "emails" : [ "reimer}@mit.edu", "irman.abdic@tum.de", "schuller}@tum.de", "schuller@ieee.org" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Index Terms—Road surface audio analysis; wetness detection; deep learning; safety systems; on-road driving data; LSTM; RNN.\nI. INTRODUCTION\nWet pavement is responsible for 74 % of all weather-related crashes in the U.S. with over 380,000 injuries and 4,700 deaths per year [1]. Furthermore, wet roads often increase traffic congestion and result in infrastructure damage and supply chain disruptions [2]. From the perspective of driver safety, wetness detection during the period of time after the percipitation has ended but whether the road is still wet is critical. Under these conditions, human estimation of road wetness and friction properties is less accurate than normal, especially in reduced visibility over night or in the presence of fog [3].\nThe automated detection of road conditions from audio may be an important component of next generation Advanced Driver Assistance Systems (ADAS) that have the potential to enhance driver safety [4]. Moreover, autonomous and semi-autonomous\nSupport for this work was provided by the New England University Transportation Center, and the Toyota Class Action Settlement Safety Research and Education Program. The views and conclusions being expressed are those of the authors, and have not been sponsored, approved, or endorsed by Toyota or plaintiffs’ class counsel.\nI. Abdić, L. Fridman, D. E. Brown, W. Angell and B. Reimer are with the MIT AgeLab, CTL, Massachusetts Institute of Technology, Cambridge, MA, United States. E-mail: {abdic, fridman, danbr, wha, reimer}@mit.edu\nI. Abdić is also with the Department of Informatics, Technische Universität München, Munich, Germany. E-mail: irman.abdic@tum.de\nE. Marchi and B. Schuller are with the Machine Intelligence & Signal Processing Group, MMK, Technische Universität München, Munich, Germany. E-mail: {erik.marchi, schuller}@tum.de\nB. Schuller is also with the Department of Computing, Imperial College London, United Kingdom, and Chair of Complex & Intelligent Systems, University of Passau, Passau, Germany. E-mail: schuller@ieee.org\nvehicles have to be aware of road conditions to automatically adapt vehicle speed while entering the curve or keep a safe distance to the vehicle in front. There are numerous approaches that can detect whether a surface is wet or dry, but in the majority of cases they are not robust to variation in realworld datasets. Accuracy of video-based wetness prediction decreases significantly in poor lighting conditions (i.e., night, fog, smoke). Audio-based wetness prediction is heavily dependent upon surface type and vehicle speed which is fairly represented in our dataset of 785,826 bins (feature vectors described in §III-B) [5]. We elucidate this dependence by visualizing the first two principal components for (1) two full trips and (2) a small 10-second section of road from (1). These two visualizations are shown in Fig. 1a and Fig. 1b,\nar X\niv :1\n51 1.\n07 03\n5v 2\n[ cs\n.L G\n] 4\nD ec\n2 01\n5\n2 respectively. The feature set we use is linearly separable for a specific road type and vehicle speed, as visualized in Fig. 1b. However, given the nonlinear relation of our feature set for (1) that is visualized in Fig. 1a we applied Recurrent Neural Networks (RNNs) which can model and separate the data points."
    }, {
      "heading" : "II. RELATED WORK",
      "text" : "Long short-term memory RNNs (LSTM-RNNs) have been successfully applied in many fields from hand writing recognition to robotic heart surgery [6], [7]. In the audio context, LSTM-RNNs contributed to the development of better phoneme classification, speech enhancement, affect recognition from speech, animal species identification and finding temporal structure in music [8]–[13]. However, to our best knowledge LSTM-RNNs have not been applied to the task of road wetness detection.\nRelated works can be found in the video processing domain, where wetness detection has been studied with two camera setups: (1) a surveillance camera at night, and (2) a camera onboard a vehicle. The detection of road surface wetness using surveillance camera images at night is relying on passing cars’ headlights as a lighting source that creates a reflection artifact on the road area [14]. On-board video cameras use polarization changes of reflections on road surfaces or spatio-temporal reflection models [15]–[17]. A recent study uses near infrared (NIR) camera to classify several road conditions per every pixel with a high accuracy, the evaluation has been done in laboratory conditions, and field experiments [18]. However, a drawback of video processing methods is that they require (1) an external illumination source to be present and (2) visibility conditions to be clear.\nAnother approach capable of detecting road wetness relies on 24-GHz automotive radar technology for detecting low-friction spots [19]. It analyzes backscattering properties of wet, dry, and icy asphalt in laboratory and field experiments.\nTraditionally, audio analysis of the road-tire interaction has been done by examining tire noises of passing vehicles from a stationary microphone positioned on the side of the road. This kind of analysis reveals that tire speed, vertical tire load, inflation pressure and driving torque are primary contributors to tire sound in dry road conditions [20]. Acoustic-based vehicle detection methods, as the one that uses bispectral entropy have been applied in the ground surveillance systems [21]. Other on-road audio collecting devices for surface analysis can be found in specialized vehicles for pavement quality evaluation (e.g., VOTERS [22]) and for vehicles instrumented for studying driver behavior in the context of automation (e.g., MIT RIDER [23]). Finally, road wetness has been studied from on-board audio of tire-surface interaction, where SVMs have been applied [5]."
    }, {
      "heading" : "A. Contribution",
      "text" : "The method described in our paper improves the prediction accuracy of the method presented in [5] and expands the evaluation to a wider range of surface types and pavement conditions. Additionally, the present study is the first in applying LSTM-RNNs in this field. Moreover, we improve on the following three aspects of [5] where (1) the model was trained and tested on the same road segment, (2) false predictions caused by the impact of pebbles on the vehicle chassis were ignored, and (3) audio segments associated with speeds below 18.6 mph were removed.\nWe trained and tested the model on different routes, and considered all predictions regardless of the speed, pebbles impact or any other factor."
    }, {
      "heading" : "III. ROAD SURFACE WETNESS CLASSIFICATION",
      "text" : ""
    }, {
      "heading" : "A. Data Collection",
      "text" : "For data collection purposes, we instrumented a 2014 Mercedes CLA with an inexpensive shotgun microphone behind the rear tire, as shown in Fig. 2. The gain level of the microphone and its distance from the tire were kept the same for the entire data collection process. Three different routes were selected. For each route, we drove the same exact path once during the rain (or immediately after) and another time when the road surface was completely dry, as shown in Fig. 3. We provide spectrograms in Fig. 4 for wet and dry road segments of the same route that highlight the difference in frequency response. The duration and length of trips ranged from 14 min to 30 min and 6.1 mi to 9.0 mi, respectively. The summary of the dataset is presented in Table I.\naA video of these trips is available at: http://lexfridman.com/wetroad\nABDIĆ et al.: DETECTING ROAD SURFACE WETNESS FROM AUDIO: A DEEP LEARNING APPROACH 3\nThe data collection was carried out in Cambridge and the Greater Boston area with different speeds, traffic conditions and pavement roughness. The latter is measured with the International Roughness Index (IRI) which represents pavement quality [24]. A histogram of IRI values for the collected dataset is presented in Fig. 5, wherein the unit of measurement is in inches per mile (in/mi). Our dataset contains values from 25 in/mi to 1400 in/mi, but in Fig. 5, values over 400 in/mi are aggregated into a single bin. According to the Massachusetts Department of Transportation (MassDOT) Road Inventory, the route we traveled is a combination of surface-treated road and bituminous concrete road [25]."
    }, {
      "heading" : "B. Features",
      "text" : "Our aim was to model the whole spectrum along with the first order differences and then select a subset of features that discriminates our classes the best. We extracted Auditory Spectral Features (ASF) [13], that were computed by applying the short-time Fourier transform (STFT) using a frame size\n30 ms and a frame step of 10 ms. Furthermore, each STFT power spectrogram has been converted to the Mel-Frequency scale using 26 triangular filters obtaining the Mel spectrograms M30(n,m). To match the human perception of loudness, a logarithmic representation has been chosen:\nM30log(n,m) = log(M 30(n,m) + 1.0). (1)\nIn addition, the positive first order differences D30(n,m) were calculated from each Mel spectrogram as follows:\nD30(n,m) = M30log(n,m)−M30log(n− 1,m). (2)\nThe frame energy has also been included as a feature which resulted in a total of 54 features [26]. To foster reproducibility, we use the opensource software toolkits: (a) openSMILE – for extracting features from the audio, and (b) Weka 3 – for feature evaluation with Information Gain (IG) and Correlation-based Feature Selection (CFS) to reduce the dimension of the feature space [27], [28].\nThe IG feature evalaution is an univariate filter that calculates the worth of a feature by measuring the IG with respect to the class, it measures individual feature value but neglects redundancy [29], [30]. The output is a list of ranked features of which we selected best 5n features, where n ∈ [1..10] and the whole feature set for comparison.\nThe CFS subset evaluation is a multivaraite filter that seeks for subsets of features that are highly correlated with the class while having low intercorrelation [28], [29], [31]. We used the BestFirst search algorithm in a forward search mode (-D 1) and a threshold of 5 non-improving nodes (-N 5) for consideration before terminating search. The CFS subset evaluation returned a list of 5 features."
    }, {
      "heading" : "C. Classifier",
      "text" : "In this work, we used a deep learning approach with initialized nets – LSTM and bi-directional LSTM (BLSTM) RNN architectures which in contrast to other RNNs do not suffer from the problem of vanishing gradients [32]. The BLSTM is an extension of the LSTM architecture that allows for an additional forward pass if a look-ahead buffer may be used, which has been proven successful in many applications [8].\nIn addition, we evaluated different parameters, such as the layout of LSTM and BLSTM hidden layers (54-54-54, 54- 30-54, 156-256-156, 216-216-216, 216-316-216 neurons in the three hidden layers) and learning rates (1e-4, 1e-5, 1e-6). Initially, we chose deep architecture with three hidden layers of the same size as input vectors (54), before we ranked features and reduced its dimensionality. In the next step we investigated effectiveness of internal feature compression and augmentation of hidden layers to model more information. We used feed forward output layer with a logistic activation function and sum of squared error as objective function. The experiments were carried out with the CURRENNT toolkit [33].\n4"
    }, {
      "heading" : "IV. RESULTS",
      "text" : "Table II shows the evaluation results in an ascending order for the best 20 features that were selected with IG (IG-20), as described in §III-B and trained with LSTM-RNNs. We present only the worst three and the best three results for RNNs, whereas other experiments were left out from the table. For every combination of parameters we conducted crossvalidation on all three folds from Table I. I.e., we leave out wet/dry 3 at a time for training with wet/dry 1 and testing with wet/dry 2, and run six experiments in total. Furthermore, an average UAR was computed for results obtained from all speeds including vehicle stationary mode. The best result with an UAR of 93.2 % was achieved with BLSTM network layout 216-216-216 and learning rate 1e−5.\nAdditionally, we compared our results with the state-of-theart approach of [5] that uses zero-norm minimization (L0) to select four most promising features (L0-4) from 125 ms audio bins of 1/3 octave bands (5000 Hz, 1600 Hz, 630 Hz and 200 Hz frequency bands). We trained SVMs with Sequential Minimal Optimization (SMO) on our dataset and found a C parameter of 1e−3 to give the best UAR of 67.4 %. Furthermore, experiments with SVMs and IG-20 feature set were carried out and gave the best UAR of 78.8 %.\nThe mean UAR value for experiments with LSTM-RNNs is 86.6 % and the standard deviation equals 6.4. The mean UAR of all experiments with BLSTM network is 87.0 %, while the mean UAR for experiments with LSTM network is 86.0 %. The best mean UAR for experiments with learning rate 1e−5 amounts to 90.8 %, while the worst performing learning rate 1e−4 achieves only 78.8 %.\nTwo out of three wet trips have significantly higher number of false predictions (1) at the beginning, where vehicle tires were dry before getting wetted from the surface, and (2) at the end of the trip, when the vehicle entered a parking lot with relatively dry road surface.\nIn Fig. 6 we compare speed and false predictions of wet and dry trips for the same route that has similar properties, which are described in §III-A. One can observe that all false predictions of wet trip 2 in Fig. 6a occured below the speed of 2.9 mph, whilst Fig. 6b depicts a dry trip 2 and has only one false prediction when the vehicle is not moving. Therefore, discarding speeds below 2.9 mph improves the UAR to 100 %. When we look only at speeds below 2.9 mph and ignore everything above we are still able to attain 74.5 % UAR. The latter is possible only in presence of ambient sounds, as noises of vehicles that are driving by."
    }, {
      "heading" : "V. CONCLUSION",
      "text" : "We proposed a deep learning approach based on LSTM-RNNs for detecting road wetness from audio of the tire-surface interaction and discriminating between wet and dry classes. This method is shown to be robust to vehicle speed, road type, and pavement quality on a dataset containing 785,826 bins of audio. It outperforms the state-of-the-art SVMs and achieves an outstanding performance on the road wetness detection task with an 93.2 % UAR for all vehicle speeds and the more challenging speeds being those below 2.9 mph, including vehicle stationary mode. In future work, we will augment the feature set for estimating depth of water on the road surface and detecting hydroplaning conditions.\nABDIĆ et al.: DETECTING ROAD SURFACE WETNESS FROM AUDIO: A DEEP LEARNING APPROACH 5"
    } ],
    "references" : [ {
      "title" : "Ten-year averages from 2002 to 2012 based on nhtsa data",
      "author" : [ "Booz-Allen-Hamilton" ],
      "venue" : "US Department of Transportation - Federal Highway Administration, 2012. [Online]. Available: www.ops.fhwa.dot.gov/ weather",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Weather as a chronic hazard for road transportation in canadian cities",
      "author" : [ "J. Andrey", "B. Mills", "M. Leahy", "J. Suggett" ],
      "venue" : "Natural Hazards, vol. 28, no. 2-3, pp. 319–343, 2003.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Weather information and road safety",
      "author" : [ "J. Andrey", "B. Mills", "J. Vandermolen" ],
      "venue" : "Institute for Catastrophic Loss Reduction, Toronto, Ontario, Canada, 2001.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Sensor sensibility: Advanced driver assistance systems",
      "author" : [ "M. Mueller" ],
      "venue" : "Vision Zero International, 2015.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "On-board wet road surface identification using tyre/road noise and support vector machines",
      "author" : [ "J. Alonso", "J. López", "I. Pavón", "M. Recuero", "C. Asensio", "G. Arcas", "A. Bravo" ],
      "venue" : "Applied Acoustics, vol. 76, pp. 407– 415, 2014.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "A novel connectionist system for unconstrained handwriting recognition",
      "author" : [ "A. Graves", "M. Liwicki", "S. Fernández", "R. Bertolami", "H. Bunke", "J. Schmidhuber" ],
      "venue" : "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 31, no. 5, pp. 855–868, 2009.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A system for robotic heart surgery that learns to tie knots using recurrent neural networks",
      "author" : [ "H. Mayer", "F. Gomez", "D. Wierstra", "I. Nagy", "A. Knoll", "J. Schmidhuber" ],
      "venue" : "Advanced Robotics, vol. 22, no. 13-14, pp. 1521–1537, 2008.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Framewise phoneme classification with bidirectional lstm and other neural network architectures",
      "author" : [ "A. Graves", "J. Schmidhuber" ],
      "venue" : "Neural Networks, vol. 18, no. 5, pp. 602–610, 2005.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Abandoning emotion classes-towards continuous emotion recognition with modelling of long-range dependencies.",
      "author" : [ "M. Wöllmer", "F. Eyben", "S. Reiter", "B. Schuller", "C. Cox", "E. Douglas- Cowie", "R. Cowie" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2008
    }, {
      "title" : "An experimental study on speech enhancement based on deep neural networks",
      "author" : [ "Y. Xu", "J. Du", "L.-R. Dai", "C.-H. Lee" ],
      "venue" : "Signal Processing Letters, IEEE, vol. 21, no. 1, pp. 65–68, 2014.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Audio recognition in the wild: Static and dynamic classification on a real-world database of animal vocalizations",
      "author" : [ "F. Weninger", "B. Schuller" ],
      "venue" : "acoustics, speech and signal processing (ICASSP), 2011 IEEE international conference on. IEEE, 2011, pp. 337–340.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Finding temporal structure in music: Blues improvisation with lstm recurrent networks",
      "author" : [ "D. Eck", "J. Schmidhuber" ],
      "venue" : "Neural Networks for Signal Processing, 2002. Proceedings of the 2002 12th IEEE Workshop on. IEEE, 2002, pp. 747–756.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Multi-resolution Linear Prediction Based Features for Audio Onset Detection with Bidirectional LSTM Neural Networks",
      "author" : [ "E. Marchi", "G. Ferroni", "F. Eyben", "L. Gabrielli", "S. Squartini", "B. Schuller" ],
      "venue" : "Proceedings 39th IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2014, IEEE. Florence, Italy: IEEE, May 2014, pp. 2183–2187, (acceptance rate: 50 %, IF* 1.16 (2010)).",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Efficient distinction of road surface conditions using surveillance camera images in night time",
      "author" : [ "Y. Horita", "S. Kawai", "T. Furukane", "K. Shibata" ],
      "venue" : "Image Processing (ICIP), 2012 19th IEEE International Conference on. IEEE, 2012, pp. 485–488.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A study of the road surface condition detection technique for deployment on a vehicle",
      "author" : [ "M. Yamada", "T. Oshima", "K. Ueda", "I. Horiba", "S. Yamamoto" ],
      "venue" : "JSAE review, vol. 24, no. 2, pp. 183–188, 2003.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Road condition monitoring system based on a stereo camera",
      "author" : [ "M. Jokela", "M. Kutila", "L. Le" ],
      "venue" : "Intelligent Computer Communication and Processing, 2009. ICCP 2009. IEEE 5th International Conference on. IEEE, 2009, pp. 423–428.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Road condition estimation based on spatio-temporal reflection models",
      "author" : [ "M. Amthor", "B. Hartmann", "J. Denzler" ],
      "venue" : "pp. 3–15, 2015.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Road surface status classification using spectral analysis of nir camera images",
      "author" : [ "P. Jonsson", "J. Casselgren", "B. Thornberg" ],
      "venue" : "Sensors Journal, IEEE, vol. 15, no. 3, pp. 1641–1656, 2015.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Road-condition recognition using 24-ghz automotive radar",
      "author" : [ "V.V. Viikari", "T. Varpula", "M. Kantanen" ],
      "venue" : "Intelligent Transportation Systems, IEEE Transactions on, vol. 10, no. 4, pp. 639–648, 2009.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A study on the mechanism of tire/road noise",
      "author" : [ "K. Iwao", "I. Yamazaki" ],
      "venue" : "JSAE review, vol. 17, no. 2, pp. 139–144, 1996.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Acoustical vehicle detection based on bispectral entropy",
      "author" : [ "M. Bao", "C. Zheng", "X. Li", "J. Yang", "J. Tian" ],
      "venue" : "Signal Processing Letters, IEEE, vol. 16, no. 5, pp. 378–381, 2009.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Voters: design of a mobile multimodal multi-sensor system",
      "author" : [ "R. Birken", "G. Schirner", "M. Wang" ],
      "venue" : "Proceedings of the Sixth International Workshop on Knowledge Discovery from Sensor Data. ACM, 2012, pp. 8–15.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Automated synchronization of driving data using vibration and steering events",
      "author" : [ "L. Fridman", "D.E. Brown", "W. Angell", "I. Abdić", "B. Reimer", "H.Y. Noh" ],
      "venue" : "arXiv preprint arXiv:1510.06113, 2015.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "International roughness index: Relationship to other measures of roughness and riding quality",
      "author" : [ "W.D. Paterson" ],
      "venue" : "Transportation Research Record, no. 1084, 1986.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1986
    }, {
      "title" : "Road inventory - massdot planning",
      "author" : [ "MassDOT" ],
      "venue" : "2015. [Online]. Available: https://www.massdot.state.ma.us/planning/Main/ MapsDataandReports/Data/GISData/RoadInventory.aspx",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Non-Linear Prediction with LSTM Recurrent Neural Networks for Acoustic Novelty Detection",
      "author" : [ "E. Marchi", "F. Vesperini", "F. Weninger", "F. Eyben", "S. Squartini", "B. Schuller" ],
      "venue" : "Proceedings 2015 International Joint Conference on Neural Networks (IJCNN), IEEE. Killarney, Ireland: IEEE, July 2015, pp. 1–7.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Recent developments in opensmile, the munich open-source multimedia feature extractor",
      "author" : [ "F. Eyben", "F. Weninger", "F. Gross", "B. Schuller" ],
      "venue" : "Proceedings of the 21st ACM international conference on Multimedia. ACM, 2013, pp. 835–838.",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The weka data mining software: an update",
      "author" : [ "M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten" ],
      "venue" : "ACM SIGKDD explorations newsletter, vol. 11, no. 1, pp. 10–18, 2009.",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Comparative study of attribute selection using gain ratio and correlation based feature selection",
      "author" : [ "A.G. Karegowda", "A. Manjunath", "M. Jayaram" ],
      "venue" : "International Journal of Information Technology and Knowledge Management, vol. 2, no. 2, pp. 271–277, 2010.",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Benchmarking attribute selection techniques for discrete class data mining",
      "author" : [ "M. Hall", "G. Holmes" ],
      "venue" : "Knowledge and Data Engineering, IEEE Transactions on, vol. 15, no. 6, pp. 1437–1447, 2003.",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Correlation-based feature subset selection for machine learning",
      "author" : [ "M.A. Hall" ],
      "venue" : "Ph.D. dissertation, University of Waikato, Hamilton, New Zealand, 1998.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Long short-term memory",
      "author" : [ "S. Hochreiter", "J. Schmidhuber" ],
      "venue" : "Neural computation, vol. 9, no. 8, pp. 1735–1780, 1997.",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Introducing currennt the munich open-source cuda recurrent neural network toolkit",
      "author" : [ "J. Weninger", "Felix Bergmann", "B. Schuller" ],
      "venue" : "Journal of Machine Learning Research, no. 16, pp. 547–551, 2014.",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "with over 380,000 injuries and 4,700 deaths per year [1].",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "Furthermore, wet roads often increase traffic congestion and result in infrastructure damage and supply chain disruptions [2].",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 2,
      "context" : "Under these conditions, human estimation of road wetness and friction properties is less accurate than normal, especially in reduced visibility over night or in the presence of fog [3].",
      "startOffset" : 181,
      "endOffset" : 184
    }, {
      "referenceID" : 3,
      "context" : "The automated detection of road conditions from audio may be an important component of next generation Advanced Driver Assistance Systems (ADAS) that have the potential to enhance driver safety [4].",
      "startOffset" : 194,
      "endOffset" : 197
    }, {
      "referenceID" : 4,
      "context" : "Audio-based wetness prediction is heavily dependent upon surface type and vehicle speed which is fairly represented in our dataset of 785,826 bins (feature vectors described in §III-B) [5].",
      "startOffset" : 185,
      "endOffset" : 188
    }, {
      "referenceID" : 5,
      "context" : "Long short-term memory RNNs (LSTM-RNNs) have been successfully applied in many fields from hand writing recognition to robotic heart surgery [6], [7].",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 6,
      "context" : "Long short-term memory RNNs (LSTM-RNNs) have been successfully applied in many fields from hand writing recognition to robotic heart surgery [6], [7].",
      "startOffset" : 146,
      "endOffset" : 149
    }, {
      "referenceID" : 7,
      "context" : "In the audio context, LSTM-RNNs contributed to the development of better phoneme classification, speech enhancement, affect recognition from speech, animal species identification and finding temporal structure in music [8]–[13].",
      "startOffset" : 219,
      "endOffset" : 222
    }, {
      "referenceID" : 12,
      "context" : "In the audio context, LSTM-RNNs contributed to the development of better phoneme classification, speech enhancement, affect recognition from speech, animal species identification and finding temporal structure in music [8]–[13].",
      "startOffset" : 223,
      "endOffset" : 227
    }, {
      "referenceID" : 13,
      "context" : "The detection of road surface wetness using surveillance camera images at night is relying on passing cars’ headlights as a lighting source that creates a reflection artifact on the road area [14].",
      "startOffset" : 192,
      "endOffset" : 196
    }, {
      "referenceID" : 14,
      "context" : "On-board video cameras use polarization changes of reflections on road surfaces or spatio-temporal reflection models [15]–[17].",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 16,
      "context" : "On-board video cameras use polarization changes of reflections on road surfaces or spatio-temporal reflection models [15]–[17].",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 17,
      "context" : "A recent study uses near infrared (NIR) camera to classify several road conditions per every pixel with a high accuracy, the evaluation has been done in laboratory conditions, and field experiments [18].",
      "startOffset" : 198,
      "endOffset" : 202
    }, {
      "referenceID" : 18,
      "context" : "Another approach capable of detecting road wetness relies on 24-GHz automotive radar technology for detecting low-friction spots [19].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 19,
      "context" : "This kind of analysis reveals that tire speed, vertical tire load, inflation pressure and driving torque are primary contributors to tire sound in dry road conditions [20].",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 20,
      "context" : "Acoustic-based vehicle detection methods, as the one that uses bispectral entropy have been applied in the ground surveillance systems [21].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 21,
      "context" : ", VOTERS [22]) and for vehicles instrumented for studying driver behavior in the context of automation (e.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 22,
      "context" : ", MIT RIDER [23]).",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 4,
      "context" : "Finally, road wetness has been studied from on-board audio of tire-surface interaction, where SVMs have been applied [5].",
      "startOffset" : 117,
      "endOffset" : 120
    }, {
      "referenceID" : 4,
      "context" : "The method described in our paper improves the prediction accuracy of the method presented in [5] and expands the evaluation to a wider range of surface types and pavement conditions.",
      "startOffset" : 94,
      "endOffset" : 97
    }, {
      "referenceID" : 4,
      "context" : "Moreover, we improve on the following three aspects of [5] where (1) the model was trained and tested on the same road segment, (2) false predictions caused by the impact of pebbles on the vehicle chassis were ignored, and (3) audio segments associated with speeds below 18.",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 23,
      "context" : "The latter is measured with the International Roughness Index (IRI) which represents pavement quality [24].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 24,
      "context" : "According to the Massachusetts Department of Transportation (MassDOT) Road Inventory, the route we traveled is a combination of surface-treated road and bituminous concrete road [25].",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 12,
      "context" : "We extracted Auditory Spectral Features (ASF) [13], that were computed by applying the short-time Fourier transform (STFT) using a frame size 30 ms and a frame step of 10 ms.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 25,
      "context" : "The frame energy has also been included as a feature which resulted in a total of 54 features [26].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 26,
      "context" : "To foster reproducibility, we use the opensource software toolkits: (a) openSMILE – for extracting features from the audio, and (b) Weka 3 – for feature evaluation with Information Gain (IG) and Correlation-based Feature Selection (CFS) to reduce the dimension of the feature space [27], [28].",
      "startOffset" : 282,
      "endOffset" : 286
    }, {
      "referenceID" : 27,
      "context" : "To foster reproducibility, we use the opensource software toolkits: (a) openSMILE – for extracting features from the audio, and (b) Weka 3 – for feature evaluation with Information Gain (IG) and Correlation-based Feature Selection (CFS) to reduce the dimension of the feature space [27], [28].",
      "startOffset" : 288,
      "endOffset" : 292
    }, {
      "referenceID" : 28,
      "context" : "The IG feature evalaution is an univariate filter that calculates the worth of a feature by measuring the IG with respect to the class, it measures individual feature value but neglects redundancy [29], [30].",
      "startOffset" : 197,
      "endOffset" : 201
    }, {
      "referenceID" : 29,
      "context" : "The IG feature evalaution is an univariate filter that calculates the worth of a feature by measuring the IG with respect to the class, it measures individual feature value but neglects redundancy [29], [30].",
      "startOffset" : 203,
      "endOffset" : 207
    }, {
      "referenceID" : 27,
      "context" : "The CFS subset evaluation is a multivaraite filter that seeks for subsets of features that are highly correlated with the class while having low intercorrelation [28], [29], [31].",
      "startOffset" : 162,
      "endOffset" : 166
    }, {
      "referenceID" : 28,
      "context" : "The CFS subset evaluation is a multivaraite filter that seeks for subsets of features that are highly correlated with the class while having low intercorrelation [28], [29], [31].",
      "startOffset" : 168,
      "endOffset" : 172
    }, {
      "referenceID" : 30,
      "context" : "The CFS subset evaluation is a multivaraite filter that seeks for subsets of features that are highly correlated with the class while having low intercorrelation [28], [29], [31].",
      "startOffset" : 174,
      "endOffset" : 178
    }, {
      "referenceID" : 31,
      "context" : "In this work, we used a deep learning approach with initialized nets – LSTM and bi-directional LSTM (BLSTM) RNN architectures which in contrast to other RNNs do not suffer from the problem of vanishing gradients [32].",
      "startOffset" : 212,
      "endOffset" : 216
    }, {
      "referenceID" : 7,
      "context" : "The BLSTM is an extension of the LSTM architecture that allows for an additional forward pass if a look-ahead buffer may be used, which has been proven successful in many applications [8].",
      "startOffset" : 184,
      "endOffset" : 187
    }, {
      "referenceID" : 32,
      "context" : "The experiments were carried out with the CURRENNT toolkit [33].",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 4,
      "context" : "Additionally, we compared our results with the state-of-theart approach of [5] that uses zero-norm minimization (L0) to select four most promising features (L0-4) from 125 ms audio bins of 1/3 octave bands (5000 Hz, 1600 Hz, 630 Hz and 200 Hz frequency bands).",
      "startOffset" : 75,
      "endOffset" : 78
    } ],
    "year" : 2015,
    "abstractText" : "We introduce a recurrent neural network architecture for automated road surface wetness detection from audio of tiresurface interaction. The robustness of our approach is evaluated on 785,826 bins of audio that span an extensive range of vehicle speeds, noises from the environment, road surface types, and pavement conditions including international roughness index (IRI) values from 25 in/mi to 1400 in/mi. The training and evaluation of the model are performed on different roads to minimize the impact of environmental and other external factors on the accuracy of the classification. We achieve an unweighted average recall (UAR) of 93.2 % across all vehicle speeds including 0 mph. The classifier still works at 0 mph because the discriminating signal is present in the sound of other vehicles driving by.",
    "creator" : "LaTeX with hyperref package"
  }
}