{
  "name" : "1601.01660.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "An Automaton Learning Approach to Solving Safety Games over Infinite Graphs",
    "authors" : [ "Daniel Neider", "Ufuk Topcu" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "I. INTRODUCTION\nWe propose an automata learning-based method to construct reactive controllers subject to safety specifications. We model the interaction between a controlled system and its possibly adversarial environment as a two-player game over a graph [1]. We consider games over infinite graphs. In this setting, the conventional techniques for reactive controller synthesis (e.g., fixed-point computations) are not applicable anymore. Therefore, we resort to a learning-based approach for constructing finite-state reactive controllers for the controlled system. The learning takes place in a setting akin to counterexample-guided inductive synthesis (CEGIS) [2] between a teacher, who has knowledge about the safety game in question, and a learner, whose objective is to identify a controller using information disclosed by the teacher in response to (incorrect) conjectures.\nA natural context for the proposed method is one in which the interaction between the controlled system and its environment is so complex that it can be represented only by graphs with infinitely many vertices (e.g., motion planning over unbounded grid worlds) or “practically infinitely many\" states (i.e., the number of possible configurations is so large that the game becomes impractical for conventional techniques). Additionally, in situations where a complete description of the game is not available in a format amenable to existing game solvers [3], [4], there may still exist human experts (or automated oracles, as in Section IV) who have sufficient insight into how the controlled system should behave and can act as teacher.\nWe focus on games with safety specifications, which already capture practically interesting properties (e.g., safety and bounded-horizon reachability). However, games over infinite graphs require special attention on the representation and manipulation of the underlying graph structure. Hence, one of our main contributions is a symbolic representation of safety games, called rational safety games, that follows the idea of regular model checking [5] in that it represent sets of vertices by regular languages and edges by so-called rational relations.\nA straightforward approach to solve (rational) safety games is computing a winning set for the controlled system (i.e., a safe subset of the vertices in which the system can force to remain). Once a winning set is computed, a strategy for the system is determined by choosing its moves (in each of its turns) to stay inside the set, which is possible regardless of the moves of the environment. We use winning sets as a proxy for an actual controller, and the objective of the learning task is the construction of a winning set. In fact, learning a winning set rather than a controller results in more permissive strategies (and potentially smaller solutions) as the moves of the system do not need to be fixed during the learning process.\nWe develop a framework for learning winning sets for rational safety games and particular implementations of a teacher and learner. The actual learning works iteratively. In each iteration, the learner conjectures a winning set, represented as a deterministic finite automaton. The teacher performs a number of checks and returns, based on whether the conjecture passes the checks, a counterexample. Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal implication counterexamples. Based on the response from the teacher, the learner updates his conjecture. If the conjecture passes all checks (i.e., the teacher returns no counterexample), the learning process terminates with the desired controller.\nA learning-based approach offers several advantages: First, even though the underlying game may be prohibitively large, the reactive controller necessary to realize the specifications often has a compact representation in practice; for example, depending on the given task specification in a robotic motion planning scenario, only a small subset of all possible rich interactions between the robot and its dynamic environment over a possibly large workspace is often relevant. Second, since\nar X\niv :1\n60 1.\n01 66\n0v 1\n[ cs\n.F L\n] 7\nJ an\n2 01\n6\nlearning-based approaches usually identify “small\" solutions (as they typically produce intermediate conjectures of increasing size), their runtime mainly depends on the size of the solution rather than the size of the underlying game. Third, learningbased approaches reduce the gap between human designers and construction of reactive controllers by hiding the complexity of the underlying game from the learner.\nFinally, we demonstrate the use of our overall learning-based framework empirically on a series of examples motivated by robotic motion planning in dynamic environments.\nRelated Work: Games over infinite graphs have been studied in the past, predominantly in the case of games over pushdown graphs [9]. The games we consider here, however, are played over a richer class of graphs and require different techniques to be solved. Also, a constraint-based approach to solving games over infinite graphs has recently been proposed [10].\nLearning-based techniques for games over infinite graphs have already been studied in the context of reachability games [11]; in fact, our symbolic representation of safety games is a generalization of the representation proposed there. In the context of safety games, recent work [12] has already demonstrated the ability of learning-based approaches to extract small reactive controllers from a priori constructed controllers with possibly large number of states. In this work, we by-pass the a priori construction of possibly large reactive controllers by learning (an appropriate representation of) a controller directly."
    }, {
      "heading" : "II. RATIONAL SAFETY GAMES",
      "text" : "This section recaps infinite-duration, two-player safety games\nas well as basic concepts of automata theory and introduces rational safety games.\na) Safety Games: We consider safety games (i.e., infinite duration two-person games on graphs) as popularized by McNaughton [1]. A safety game is played on an arena A = (V0, V1, E) consisting of two nonempty, disjoint sets V0, V1 of vertices (we denote their union by V ) and a directed edge relation E ⊆ V × V . In contrast to the classical (finite) setting, we allow V0 and V1 to be countable sets. As shorthand notation, we write the successors of a set X ⊆ V of vertices as E(X) = {y | ∃x ∈ X : (x, y) ∈ E}.\nWe consider safety games with initial vertices, which are defined as triples G = (A, F, I) consisting of an arena A = (V0, V1, E), a set F ⊆ V of safe vertices, and a set I ⊆ F of initial vertices. Such safety games are played by two players, named Player 0 and Player 1, as follows: A token is placed on some initial vertex v0 ∈ I and, in each turn, the player owning the current vertex moves the token to a successor vertex of his choice. This process of moving the token is repeated ad infinitum, thereby forming an infinite sequence of vertices, which is called a play. Formally, a play is an infinite sequence π = v0v1 . . . ∈ V ω that satisfies v0 ∈ I and (vi, vi+1) ∈ E for all i ∈ N. The set F defines the winning condition of the game in the sense that a play v0v1 . . . is winning for Player 0 if vi ∈ F for all i ∈ N—otherwise it is winning for Player 1.\nA strategy for Player σ, σ ∈ {0, 1}, is a mapping fσ : V ∗Vσ → V , which prescribes how to continue playing. A\nstrategy fσ is called winning if any play v0v1 . . . that is played according to the strategy (i.e., that satisfies vi+1 = fσ(v0 . . . vi) for all i ∈ N and vi ∈ Vσ) is winning for Player σ. A winning strategy for Player 0 straightforwardly translates into a controller satisfying the given safety specifications and, hence, we restrict ourselves to compute winning strategies for Player 0.\nComputing a winning strategy for Player 0 is usually reduced to finding a so-called winning set.\nDefinition 1 (Winning set): For a safety game G = (A, I, F ) over the arena A = (V0, V1, E), a winning set is a set W ⊆ V satisfying (1) I ⊆ W , (2) W ⊆ F , (3) E({v}) ∩W 6= ∅ for all v ∈W ∩ V0 (existential closedness), and (4) E({v}) ⊆W for all v ∈W ∩ V1 (universal closedness).\nBy computing a winning set, one immediately obtains a strategy for Player 0: starting in an initial vertex, Player 0 simply moves to a successor vertex inside W whenever it is his turn. A straightforward induction over the length of plays proves that every play that is played according to this strategy stays inside F , no matter how Player 1 plays, and, hence, is won by Player 0 (since I ⊆W ⊆ F ). A winning set is what we want to compute—or, more precisely, learn.\nGames over infinite arenas require a symbolic representation in order to work with them algorithmically. We follow the idea of regular model checking [5], an approach in verification, and represent sets of vertices by regular languages and edges by so-called rational relations. Before we can introduce our symbolic representation of safety games, however, we need to recap basic concepts and notations of automata theory.\nb) Basics of Automata Theory: An alphabet Σ is a nonempty, finite set, whose elements are called symbols. A word over the alphabet Σ is a sequence u = a1 . . . an of symbols ai ∈ Σ for i ∈ {1, . . . , n}; the empty sequence is called empty word and denoted by ε. Given two words u = a1 . . . am and v = b1 . . . bn, the concatenation of u and v is the word u · v = uv = a1 . . . amb1 . . . bn. The set of all words over the alphabet Σ is denoted by Σ∗, and a subset L ⊆ Σ∗ is called a language. The set of prefixes of a language L ⊆ Σ∗ is the set Pref (L) = {u ∈ Σ∗ | ∃v ∈ Σ∗ : uv ∈ L}.\nA nondeterministic finite automaton (NFA) is a tuple A = (Q,Σ, q0,∆, F ) consisting of a nonempty, finite set Q of states, an input alphabet Σ, an initial state q0 ∈ Q, a transition relation ∆ ⊆ Q×Σ×Q, and a set F ⊆ Q of final states. A run of an NFA A on a word u = a1 . . . an is a sequence of states q0, . . . , qn such that (qi−1, ai, qi) ∈ ∆ for i ∈ {1, . . . , n}. We denote this run by A : q0\nu−→ qn. An NFA A accepts a word u ∈ Σ∗ if A : q0\nu−→ q with q ∈ F . The set L(A) = {u ∈ Σ∗ | A : q0\nu−→ q, q ∈ F} is called language of A. A language L is said to be regular if there exists an NFA A with L(A) = L. Finally, NFAΣ denotes the set of all NFAs over Σ.\nA deterministic finite automaton (DFA) is an NFA in which (p, a, q) ∈ ∆, (p, a, q′) ∈ ∆ implies q = q′. We replace the transition relation ∆ with a transition function δ : Q×Σ→ Q.\nWe define rational relations by resorting to transducers. A transducer is an NFA T = (Q, Σ̂, q0,∆, F ) over the alphabet Σ̂ = (Σ ∪ {ε}) × (Γ ∪ {ε})—Σ and Γ are both alphabets— that processes pairs (u, v) ∈ Σ∗ × Γ∗ of words. The run of\na transducer T on a pair (u, v) is a sequence q0, . . . , qn of states such that (qi−1, (ai, bi), qi) ∈ ∆ for all i ∈ {1, . . . , n}, u = a1 . . . an, and v = b1 . . . bn; note that u and v do not need to be of equal length since any ai or bi can be ε. A pair (u, v) is said to be accepted by T if there exists a run of T on (u, v) that starts in the initial state and ends in a final state. As an acceptor of pairs of words, a transducer T defines a relation, namely the relation consisting of exactly the pairs accepted by T , which we denote by R(T ). Finally, a relation R ⊆ Σ∗ × Γ∗ is called rational if there exists a transducer T with R(T ) = R. (This definition of rational relations is simplified from that in [13] but sufficient for our purpose.)\nOur learning framework relies on the two well-known facts. Lemma 1: Let R ⊆ Σ∗ × Γ∗ be a rational relation and X ⊆ Σ∗ a regular set. Then, (1) the relation R−1 = {(y, x) | (x, y) ∈ R} is again rational, and a transducer defining this set can be constructed in linear time; and (2) the set R(X) = {y ∈ Γ∗ | ∃x ∈ X : (x, y) ∈ R}, called the image of X under R, is again regular, and an NFA accepting this set can be constructed effectively.\nc) Rational Safety Games: A rational safety game is a symbolic representation of a safety game in terms of regular languages and rational relations.\nDefinition 2: A rational arena over the alphabet Σ is an arena AΣ = (V0, V1, E) where V0, V1 ⊆ Σ∗ are regular languages and E ⊆ V × V is a rational relation.\nThe definition of rational safety games is now immediate. Definition 3: A rational safety game over the alphabet Σ is\na safety game GΣ = (AΣ, F, I) where AΣ is a rational arena over Σ and F, I ⊆ Σ∗ are regular languages.\nIn the remainder, we assume regular languages to be given as NFAs and rational relations as transducers. In addition, we use these notions interchangeably when referring to rational arenas and rational safety games; for instance, we write a rational area AΣ = (V0, V1, E) as AΣ = (AV0 ,AV1 , TE) given that L(AV0) = V0, L(AV1) = V1, and R(TE) = E.\nLet us illustrate rational safety games through an example. Example 1: Consider a simple example motivated by motion\nplanning, sketched in Figure 1a, in which a robot moves on an infinite, discrete one-dimensional grid that is “bounded on the left”. The robot can move left or right to an adjacent cell (provided that it has not reached edge of the grid) or it can stay at its current position. The grid is partitioned into a safe and an unsafe area, the former being shown shaded in Figure 1a. The safe area is parameterized by an integer k ∈ N \\ {0} and consists of all position greater than or equal to k. The robot starts somewhere inside the safe area.\nThe robot’s movement is governed by two adversarial players, called system and environment; the system can move the robot to the right or keep it at its current position, whereas the environment can move the robot to the left (if the edge has not been reached) or keep it at its current position. The players move the robot in alternation, and the system moves first. The system’s objective is to stay within the safe area, whereas the environment wants to move the robot out of it. Note that the system can win, irrespective of k, by always moving right.\nA formalization as safety game is straightforward. Player 0 corresponds to the system and Player 1 corresponds to the environment. The arena A = (V0, V1, E) consists of vertices V0 = {s} ×N and V1 = {e} ×N—s, respectively e, indicates the player moving next—as well as the edge relation E ={(\n(s, i), (e, i + 1) ) | i ∈ N } ∪ {( (e, i + 1), (s, i) ) | i ∈ N } .\nThe safety game itself is the triple Gk = (A, F, I) with F = {s, e} × {i ∈ N | i ≥ k} and I = {s} × {i ∈ N | i ≥ k}. Figure 1b sketches the game Gk for the case k = 2.\nWe now turn Gk into a rational safety game. To this end, we label each vertex uniquely with a finite word. In our example, we choose Σ = {s, e, l} and associate the vertex (x, i) ∈ {s, e} × N with the word xli where li is the encoding of i in unary. We represent the sets V0 and V1 by the following NFAs:\nAV0 : s\nl AV1 : e\nl\nMoreover, we represent the edges by the following transducer:\nTE : (s, e) (e, s)\n(l, l)\n(ε, l)\n(l, l)\n(l, ε)\nFinally, the NFA\n. . .AF : s, e l l l\nl\nk − 1 states\nrepresents the set F ; similarly, I is represented by a copy of AF in which the transition labeled with e is omitted.\nIt is worth mentioning that rational arenas not only subsume finite arenas but also a rich class of of infinite arenas, including such encoding computations of Turing machines. Hence, the problem of determining the winner of a rational safety game is undecidable, and any algorithm for computing a winning set can at best be a semi-algorithm (i.e., an algorithm that, on termination, gives the correct answer but does not guarantee to halt). The algorithm we design in this paper is of this kind and guarantees to learn a winning set if one exists. To ease description, we always assume that a winning set set exists."
    }, {
      "heading" : "III. THE LEARNING FRAMEWORK",
      "text" : "Our learning framework is an extension of the ICE framework proposed by Garg et. al. [6], which deals with learning loop invariants from positive and negative data as well as\nimplications. The learning takes place between a teacher, who has (explicit or implicit) knowledge about the rational safety game in question, and a learner, whose objective is to learn a DFA accepting a winning set, but who is agnostic to the game. We assume that the teacher announces the alphabet of the game before the actual learning starts.\nThe learning proceeds in a CEGIS-style loop [2]. In every iteration, the learner conjectures a DFA, let us call it C, and the teacher checks whether L(C) is a winning set—this kind of query is often called equivalence or correctness query. Although the teacher does not know a winning set (the overall objective is to learn one after all), he can resort to Conditions (1)–(4) of Definition 1 in order to decide whether L(C) is a winning set. If L(C) satisfies Conditions (1)–(4) (i.e., L(C) is a winning set), then the teacher replies “yes” and the learning ends. If this is not the case, the teacher returns a counterexample witnessing the violation of one of these conditions, and the learning continues with the next iteration. The definition below fixes the protocol between the teacher and the learner and defines counterexamples.\nDefinition 4 (Teacher for rational safety games): Let GΣ = (AΣ, F, I) be a rational safety game over the rational arena AΣ = (V0, V1, E). Confronted with a DFA C, a teacher for GΣ replies as follows:\n1) If I 6⊆ L(C), then the teacher returns a positive counterexample u ∈ I \\ L(C).\n2) If L(C) 6⊆ F , then the teacher returns a negative counterexample u ∈ L(C) \\ F .\n3) If there exists u ∈ L(C)∩V0 such that E({u})∩L(C) = ∅, then the teacher picks such a u and returns an existential implication counterexample (u,A) ∈ Σ∗ ×NFAΣ where L(A) = E({u}).\n4) If there exists u ∈ L(C) ∩ V1 such that E({u}) 6⊆ L(C), then the teacher picks such a u and returns a universal implication counterexample (u,A) ∈ Σ∗ ×NFAΣ where L(A) = E({u})."
    }, {
      "heading" : "If C passes all four checks, the teacher replies “yes”. The",
      "text" : "order in which the teacher performs these checks is arbitrary.\nIt is easy to see that the language of a conjecture is indeed a winning set if the teacher replies “yes” (since it satisfies all conditions of Definition 1). The meaning of a positive counterexample is that any conjecture needs to accepts it, but it was rejected. Similarly, a negative counterexample indicates that any conjecture has to reject it but it was accepted. An existential implication counterexample (u,A) means that any conjecture accepting u has to accept at least one v ∈ L(A), which was violated by the current conjecture. Finally, a universal implication counterexample (u,A) means that any conjecture accepting u needs to accept all v ∈ L(A). At this point, it is important to note that Definition 4 is sound (in particular, both types of implication counterexamples are well-defined due to Lemma 1 Part 2) and every counterexample is a finite object.\nLet us illustrate this learning framework through an example. Example 2: We revisit the setting of Example 1 for the case\nk = 2 and describe how the learner learns a winning set.\nSuppose that the learner conjectures the DFA C0 with L(C0) = ∅. As C0 fails Check 1 (it passes all other checks), the teacher returns a positive counterexample, say u = sll ∈ I .\nNext, suppose the learner conjectures the DFA C1 with L(C1) = {sln | n ≥ 2}, which passes all checks but Check 3 (as the players alternate but L(C1) does not contain a vertex of the environment). The teacher replies with an existential implication counterexample, say (sll,A) with L(A) = {ell, elll}.\nIn the next round, let us assume that the learner conjectures the DFA C2 with L(C2) = {sln | n ≥ 2} ∪ {elm | m ≥ 3}. This conjecture passes all checks (i.e., L(C2) is a winning set), the teacher replies “yes”, and the learning ends.\nIt is important to note that classical learning frameworks for regular languages that involve learning from positive and negative data only, such as Gold’s passive learning [7] or Angluin’s active learning [8], are insufficient in our setting. If the learner provides a conjecture C that violates Condition (3) or (4) of Definition 1, the teacher is stuck. For instance, if C does not satisfy Condition (4), the teacher does not know whether to exclude u or to include E({u}). Returning an implication counterexample, however, resolves this problem in that it communicates exactly why the conjecture is incorrect and, hence, allows the learner to make progress.1"
    }, {
      "heading" : "IV. A GENERIC TEACHER",
      "text" : "We now present a generic teacher that, taking a rational safety game as input, answers queries according to Definition 4. For the remainder of this section, fix a rational safety game GΣ = (AΣ,AF ,AI) over the rational arena AΣ = (AV0 ,AV1 , TE), and let C be a DFA conjectured by the learner.\nTo answer a query, the teacher performs Checks 1 to 4 of Definition 4 as described below. If the conjecture passes all checks, the teacher returns “yes”; otherwise, he returns a corresponding counterexample, as described next.\nCheck 1 (initial vertices): The teacher computes an NFA B with L(B) = L(AI) \\ L(C). If L(B) 6= ∅, he returns a positive counterexample u ∈ L(B).\nCheck 2 (safe vertices): The teacher computes an NFA B with L(B) = L(C) \\ L(AF ). If L(B) 6= ∅, he returns a negative counterexample u ∈ L(B).\nCheck 3 (existential closure): To check existential closure, the teacher successively computes three NFAs:\n1) An NFA B1 with L(B1) = R(TE)−1(L(C)); the language L(B1) contains all vertices that have a successor in L(C). 2) An NFA B2 with L(B2) = L(AV0)\\L(B1); the language L(B2) contains all vertices of Player 0 that have no successor in L(C). 3) An NFA B3 with L(B3) = L(C) ∩ L(B2); the language L(B3) contains all vertices of Player 0 that belong to L(C) and have no successor in L(C).\nEvery u ∈ L(B3) is a witness that C is not existentially closed. Hence, if L(B3) 6= ∅, the teacher picks an arbitrary u ∈ L(B3)\n1Garg et. al. [6] argue comprehensively why implications needed in a robust invariant learning framework. Their arguments also apply to our setting as one obtains a setting similar to Garg et. al.’s by considering a solitary game with Player 1 as the only player.\nand returns the existential implication counterexample (u,A) where L(A) = R(TE)({u}). Check 4 (universal closure): To check universal closure, the teacher, again, computes three NFAs:\n1) An NFA B1 with L(B1) = ( L(AV0) ∪ L(AV1) ) \\ L(C);\nthe language L(B1) contains all vertices not in L(C). 2) An NFA B2 with L(B2) = R(TE)−1(L(B1)); the lan-\nguage L(B2) contains all vertices that have a successor not belonging to L(C). 3) An NFA B3 with L(B3) = L(AV1) ∩ L(C) ∩ L(B2); the language L(B3) contains all vertices of Player 1 that are in L(C) and have at least one successor not in L(C).\nEvery u ∈ L(B3) is a witness that C is not universally closed. Hence, if L(B3) 6= ∅, the teacher picks an arbitrary u ∈ L(B3) and returns the universal implication counterexample (u,A) where L(A) = R(TE)({u}).\nAll checks can be performed using standard methods of automata theory, including product constructions, projections, determinizing automata, and emptiness checks (see Lemma 1)."
    }, {
      "heading" : "V. A LEARNER FOR RATIONAL SAFETY GAMES",
      "text" : "We design our learner with two key features: (1) the learner always conjectures a DFA consistent with the counterexamples received so far (we make this precise shortly), and (2) the learner always conjectures a minimal consistent DFA (i.e., a DFA with the least number of states among all DFAs that are consistent with the received counterexamples). The first design goal prevents the learner from making the same mistake twice, while the second design goal facilitates convergence of the overall learning (assuming that a winning set exists).\nTo meet these goals, our learner stores counterexamples in a data structure, which we call sample. Formally, a sample is a four-tuple S = (Pos,Neg ,Ex ,Uni) consisting of a finite set Pos ⊂ Σ∗ of positive words, a finite set Neg ⊂ Σ∗ of negative words, a finite set Ex ⊂ Σ∗ × NFAΣ of existential implications, and a finite set Uni ⊂ Σ∗ ×NFAΣ of universal implications. We encourage the reader to think of a sample as a finite approximation of the safety game learned thus far.\nIn every iteration, our learner constructs a minimal DFA consistent with the current sample. A DFA B is called consistent with a sample S = (Pos,Neg ,Ex ,Uni) if\n1) Pos ⊆ L(B); 2) Neg ∩ L(B) = ∅; 3) u ∈ L(B) implies L(B)∩L(A) 6= ∅ for each (u,A) ∈ Ex ; 4) u ∈ L(B) implies L(A) ⊆ L(B) for each (u,A) ∈ Uni . Constructing a DFA that is consistent with a sample is\npossible only if the sample does not contain contradictory information. Contradictions can arise in two ways: first, Pos and Neg are not disjoint; second, the (alternating) transitive closure of the implications in Ex and Uni contains a pair (u, v) with u ∈ Pos and v ∈ Neg . This observation justifies to introduce the notion of contradiction-free samples: a sample S is called contradiction-free if a DFA that is consistent with S exists. Since we assume that Player 0 wins from set I , a\nAlgorithm 1: A learner for rational safety games 1 Initialize an empty sample S = (Pos,Neg ,Ex ,Uni) with Pos = ∅, Neg = ∅, Ex = ∅, and Uni = ∅; 2 repeat 3 Construct a minimal DFA AS consistent with S; 4 Submit AS to an equivalence query; 5 if the teacher returns a counterexample then 6 Add the counterexample to S; 7 end 8 until the teacher replies “yes” to an equivalence query; 9 return AS ;\nwinning set exists and the counterexamples returned by the teacher always form contradiction-free samples.2\nAfter having constructed a minimal consistent DFA, the learner conjectures it to the teacher. If the teacher replies “yes”, the learning terminates. If the teacher returns a counterexample, on the other hand, the learner adds it to the appropriate set in S and iterates. This procedure is sketched as Algorithm 1. Note that, by definition of the teacher, a conjecture is guaranteed to accept a wining set once the learning terminates.\nIt is left to describe how the learner actually constructs a minimal DFA that is consistent with the current sample. However, this task, known as passive learning, is computationally hard (i.e., the corresponding decision problem is NP-complete) already in the absence of implications [7]. Our strategy to approach this hurdle is to translate the original problem into a sequence of satisfiability problems of formulas in propositional Boolean logic and use highly optimized constraint solvers as a practically effective means to solve the resulting formulas (note that a translation into a logical formulation is a popular and effective strategy). More precisely, our learner creates and solves propositional Boolean formulas ϕSn , for increasing values of n ∈ N, n ≥ 1, with the following two properties:\n1) The formula ϕSn is satisfiable if and only if there exists a DFA with n states that is consistent with S. 2) A model M of ϕSn (i.e., a satisfying assignment of the variables in ϕSn) contains sufficient information to construct a DFA, denoted by AM, that has n states and is consistent with S .\nIf ϕSn is satisfiable, then Property 2 enables us to construct a consistent DFA from a model. However, if the formula is unsatisfiable, then the parameter n has been chosen too small and the learner increments it (e.g., by one or using a binary search). This procedure is summarized as Algorithm 2. We show its correctness shortly in Section V-B.\nThe key idea of the formula ϕSn is to encode a DFA with n states by means of Boolean variables and to pose constraints on those variables. Our encoding relies on a simple observation: for every DFA there exists an isomorphic (hence, equivalent) DFA over the state set Q = {0, . . . , n− 1} with initial state\n2In fact, checking for contradictions equips the learner with a means to detect that the game is won by Player 1. However, since determining the winner of a rational safety game is undecidable, any sample obtained during the learning might be contradiction-free despite the fact that Player 1 wins.\nAlgorithm 2: Computing a minimal consistent DFA.\nInput: A contradiction-free sample S Output: A minimal DFA that is consistent with S\n1 n← 0; 2 repeat 3 n← n+ 1; 4 Construct and solve ϕSn ; 5 until ϕSn is satisfiable, say with model M; 6 return AM;\nq0 = 0; moreover, given that Q and q0 are fixed, any DFA with n states is uniquely determined by its transitions and final states. Therefore, we can fix the state set of the prospective DFA as Q = {0, . . . , n − 1} and the initial state as q0 = 0; the alphabet Σ is announced by the teacher.\nOur encoding of transitions and final states follows an idea from [14] (independently due to [15]). We introduce Boolean variables dp,a,q and fq where p, q ∈ Q and a ∈ Σ, which have the following meaning: setting dp,a,q to true means that the transition δ(p, a) = q exists in the prospective DFA, and setting fq to true means that q is a final state.\nTo make sure that the variables dp,a,q encode a deterministic transition function, we impose two constraints:∧\np∈Q ∧ a∈Σ ∧ q,q′∈Q,q 6=q′\n¬dp,a,q ∨ ¬dp,a,q′ (1)∧ p∈Q ∧ a∈Σ ∨ q∈Q dp,a,q (2)\nLet ϕDFAn be the conjunction of Formulas (1) and (2). Given a model M of ϕDFAn (we assume a model to be a map from the variables of a formula to the set {true, false}), deriving the encoded DFA is straightforward, as shown next.\nDefinition 5: Let M be a model of ϕDFAn . We define the DFA AM = (Q,Σ, q0, δ, F ) by (1) δ(p, a) = q for the unique q ∈ Q with M(dp,a,q) = true; and (2) F = {q ∈ Q | M(fq) = true}. (Recall that we fixed Q = {0, . . . , n− 1} and q0 = 0.)\nTo enforce that AM is consistent with the given sample S = (Pos,Neg ,Ex ,Uni), we impose further constraints, corresponding to the four requirements of consistent DFAs: • a formula ϕPosn asserting Pos ⊆ L(AM); • a formula ϕNegn asserting Neg ∩ L(AM) = ∅; • a formula ϕExn asserting that u ∈ L(AM) implies L(AM) ∩ L(A) 6= ∅ for each (u,A) ∈ Ex ; and\n• a formula ϕUnin asserting that u ∈ L(AM) implies L(AM) ⊆ L(A) for each (u,A) ∈ Uni . Then, ϕSn := ϕ DFA n ∧ ϕPosn ∧ ϕNegn ∧ ϕExn ∧ ϕUnin . We here sketch formula ϕUnin and refer the reader to Appendix A for a detailed presentation of the remaining formulas. A description of ϕPosn and ϕ Neg n can also be found in [14]."
    }, {
      "heading" : "A. The formula ϕUnin",
      "text" : "We break the construction of ϕUnin down into smaller parts. Roughly speaking, we construct for each universal implication\nι = (u,A) ∈ Uni a formula ϕιn that asserts L(A) ⊆ L(AM) if u ∈ L(AM). The formulas ϕUnin is then the finite conjunction∧ ι∈Uni ϕ ι n. For the remainder, let us fix a universal implication ι ∈ Uni , say ι = (u,A) with A = (QA,Σ, qA0 ,∆A, FA), and let Ante(Uni) = {u | (u,A) ∈ Uni} be the set of all words occurring as antecedent of a universal implication.\nAs a preparatory step, we introduce auxiliary Boolean variables that track the runs of AM on words of Pref (Ante(Uni)) in order to detect when AM accepts the antecedent of a universal implication. More precisely, we introduce variables xu,q where u ∈ Pref (Ante(Uni)) and q ∈ Q, which have the meaning that xu,q is set to true if AM : q0\nu−→ q (i.e., AM reaches state q on reading u):\nxε,q0 (3)∧ u∈Pref (Ante(Uni)) ∧ q 6=q′∈Q\n¬xu,q ∨ ¬xu,q′ (4)∧ ua∈Pref (Ante(Uni)) ∧ p,q∈Q (xu,p ∧ dp,a,q)→ xua,q (5)\nFormula (3) asserts that xε,q0 is set to true since any run starts in the initial state q0. Formula (4) enforces that for every u ∈ Pref (Ante(Uni)) there exists at most one q ∈ Q such that xu,q is set to true (in fact, the conjuction of Formulas (2)–(5) implies that there exists a unique such state). Finally, Formula (5) prescribes how the run of AM on a word u ∈ Pref (Ante(Uni)) proceeds: if AM reaches state p on reading u (i.e., xu,p is set to true) and there exists a transition from p to state q on reading the symbol a ∈ Σ (i.e., dp,a,q is set to true), then AM reaches state q on reading ua and xua needs to be set to true .\nWe now define ϕιn. The formula ranges, in addition to dp,a,q , fq, and xu,q, over Boolean variables yιq,q′ where q ∈ Q and q′ ∈ QA, which track runs of A and AM. Their precise meaning is the following: if there exists a word u ∈ Σ∗ with AM : q0 u−→ q and A : qA0 u−→ q′, then yιq,q′ is set to true:\nyιq0,qA0 (6)∧\np,q∈Q ∧ (p′,a,q′)∈∆A (yιp,p′ ∧ dp,a,q)→ yιq,q′ (7)\nFormula (6) enforces yι q0,qA0 to be set to true because AM : q0 ε−→ q0 and A : qA0\nε−→ qA0 . Formula (7) is similar to Formula (5) and describes how the runs of AM and A proceed: if there exists a word v such that AM : q0\nv−→ p and A : qA0\nv−→ p′ (i.e., yιp,p′ is set to true) and there are transitions (p′, a, q′) ∈ ∆A and δ(p, a) = q in AM, then AM : q0\nva−→ q and A : qA0\nva−→ q′, which requires yιq,q′ to be set to true . Finally, the next constraint ensures that whenever AM accepts u (i.e., the antecedent is true), then all words that lead to an accepting state in A also lead to an accepting state in AM (i.e., the consequent is true).(∨\nq∈Q xu,q ∧ fq ) → (∧ q∈Q ∧ q′∈FA yιq,q′ → fq )\n(8)\nLet ϕAnte(Uni)n be the conjunction of Formulas (3), (4), and (5) as well as ϕιn the conjunction of Formulas (6), (7), and (8). Then, ϕUnin is the (finite) conjunction ϕ Ante(Uni) n ∧ ∧ ι∈Uni ϕ ι n."
    }, {
      "heading" : "B. Correctness of the Learner",
      "text" : "We now sketch a correctness proof of the learner—we refer the reader to Appendix B for a detailed proof. First, we state that ϕSn has the desired properties.\nLemma 2: Let S be a sample, n ≥ 1, and ϕSn be as defined above. Then, the following statements hold: (1) If M |= ϕSn , then AM is a DFA with n states that is consistent with S. (2) If there exists a DFA that has n states and is consistent with S, then ϕSn is satisfiable.\nNext, let us show the correctness of Algorithm 2. Theorem 1: Given a contradiction free-sample S , Algorithm 2\nreturns a minimal DFA (in terms of the number of states) that is consistent with S . If a minimal consistent DFA has k states, then Algorithm 2 terminates after k iterations.\nProof: Given a sample S, suppose that there exists a DFA that has k states and is consistent with S. Then, ϕSn is satisfiable for all n ≥ k (see Lemma 2). Moreover, if M is a model of ϕSn , then AM is a DFA with n states that is consistent with S . Since Algorithm 2 increases the parameter n by one in every iteration (starting with n = 1), the algorithm eventually finds the smallest value for which ϕSn is satisfiable (after k iterations) and, hence, a consistent DFA of minimal size.\nFinally, we can prove the correctness of our learner. Theorem 2: Given a teacher, Algorithm 1, equipped with\nAlgorithm 2 to construct conjectures, terminates and returns a (minimal) DFA accepting a winning set if one exists.\nProof: Theorem 2 follows from three observations about the learner: (1) The learner never conjectures the same DFA twice (due to Theorem 1 and the fact that counterexamples are added to the sample). (2) The conjectures grow monotonically in size (due to minimality of conjectures) with increasing n, and (3) adding counterexamples to a sample does not rule out any solution (as every DFA accepting a winning set is consistent with any sample produced during the learning). Now, suppose a DFA accepting a winning set exists, say with k states. Due to Observations 1 and 2, the learner eventually conjectures a DFA with k states and, moreover, cannot conjecture a larger DFA (due to Observation 3 and the minimality of conjectures). Hence, the learner eventually conjectures a DFA with k states that accepts a winning set, and the learning terminates."
    }, {
      "heading" : "VI. EXPERIMENTS",
      "text" : "In order to demonstrate the feasibility of our learning approach, we implemented a Java prototype using the BRICS automaton library [16] and Microsoft’s Z3 [17] constraint solver. The source code, including the games used in the experiments, is available at http://preview.tinyurl.com/n7a7byj.\nIn addition to the learner of Section V, we implemented a learner based on the popular RPNI algorithm [18], which is a polynomial time algorithm for learning DFAs from positive and negative words. For this learner, we modified the RPNI algorithm such that it constructs a consistent DFA from existential and universal implications in addition to positive and negative words (a detailed presentation can be found in Appendix C). In contrast to Algorithm 2, our modified version of RPNI cannot guarantee to find smallest consistent DFAs\nand, hence, the resulting learner is a fast heuristic that is sound but in general not complete. Another limitation is that it can only handle implication counterexamples of the form (u,A) where L(A) is finite. We refer to the learner of Section V as SAT learner and the RPNI-based learner as RPNI learner.\nOur experiments are on a slightly restricted type of games: 1) Edge relations are automatic. Automatic relations are\ndefined by transducers that do not possess transitions of the form (a, ε) and (ε, b) but rather use a dedicated padding symbol to balance the length of their input-words.3\n2) Each vertex of an arena has a finite (but not necessarily bounded) number of outgoing edges.\nRestriction 1 simplifies the implementation of the teacher. Restriction 2 is due to the limitation of the RPNI learner.\nWe use two benchmark suits: the first suite serves to demonstrate the feasibility of our techniques for various examples, predominantly taken from the area of motion planning; the second suite serves to assess the performance of our techniques when confronted with games of increasing “complexity”. All games were given as finite automata, and we employed the teacher described in Section IV. We conducted all experiments on an Intel Core i7-4510U CPU (running Microsoft Windows 8.1) with a memory limit of 4 GiB and a runtime limit of 300 s."
    }, {
      "heading" : "A. Examples",
      "text" : "We consider the following examples. Diagonal game: A robot moves on an infinite, discrete twodimensional grid world from one cell to an adjacent cell. Player 0 controls the robot’s vertical movement, whereas Player 1 controls the horizontal movement. Both players move the robot in alternation, and Player 0’s objective is to stay inside a margin of two cells around the diagonal.\nBox game: A version of the diagonal game in which Player 0’s objective is to stay within a horizontal stripe of width three.\nSolitary box game: A version of the box game in which Player 0 is the only player and has control over both the horizontal and the vertical movement.\nEvasion game: Two robots move in alternation on an infinite, two-dimensional grid. Each robot is controlled by a player. Player 0’s objective is to avoid collision with Player 1’s robot.\nFollow game: A version of the evasion game in which Player 0’s objective is to keep his robot within a distance of two cells (in the Manhattan distance) from Player 1’s robot.\nProgram-repair game: A finitely-branching version of the program-repair game described by Beyene et al. [10]. Table I lists the overall time taken by each of the two\nlearners to learn a winning set (including the time taken by the teacher) as well as further statistics of the learning process. The second column |G| corresponds to sum of states of all automata constituting a game (size of the game), which serves as measure for the complexity of a game. The remaining columns list the number of iterations, the number of states of the learned DFA, and the cardinality of each set of the final sample.\n3Automatic relations constitute a proper subset of rational relations, but are still expressive enough to encode computations of Turing machines.\nAs Table I shows, the SAT learner computed the winning sets for all games, whereas the RPNI learner computed the winning sets for all but the Follow game. Since the RPNI learner does not compute minimal consistent DFAs, we expected that it is on average faster than the SAT learner, which turned out to be the case. However, the RPNI learner fails to terminate within the time limit on the Follow game, and the large number of iterations seem to indicate that the learner in fact diverges.\nFinally, it is important to note that the teacher replied implication counterexamples in all but one experiment. This observation highlights that classical learning algorithms, which learn from positive and negative words only, are insufficient to learn winning sets (since the learning would be stuck at that point) and one has to move to a richer learning framework."
    }, {
      "heading" : "B. Scalability Benchmarks",
      "text" : "To assess the scalability of our technique when confronted with inputs of increasing size, we modified the game of Example 1 such that the safe region is now determined by two parameters, namely k and k′, and contains all positions in the interval [k, k′] (we assume k < k′ and fix k = 1). In this new setting, the number of states of the automaton AF increases when k′ increases as the automaton needs to count in unary to check the position of the robot.\nFigure 2 depicts the overall time taken to learn a winning set, depending on the parameter k′. To put the runtimes into perspective, it also shows the size of the games.\nOn the scalability benchmark suite, the RPNI learner was about one order of magnitude faster than the SAT learner and can computed a winning set for games up to a combined size of 50 000. The SAT learner, on the other hand, computed a winning set for games up to a combined size of 10 000 but did not terminate for game with k′ = 50 000. While a thorough assessment remains as part of future work, our results promise\napplicability to practically interesting problem instances."
    }, {
      "heading" : "VII. CONCLUSION",
      "text" : "We developed an automata learning method to construct finite-state reactive controllers for systems whose interactions with their environment are modeled by infinite-state games. We focused on the practically interesting family of safety games, utilized a symbolic representation of the underlying game, developed specific implementations of the learner and the teacher, and demonstrated the feasibility of the method on a set of problems motivated by robotic motion planning."
    }, {
      "heading" : "APPENDIX A CONSTRUCTING CONSISTENT DFAS USING CONSTRAINT SOLVERS",
      "text" : "The key building block of our learner is an algorithm that, given a sample S , produces a smallest DFA that is consistent with S. Recall that the learner translates this problem into a series of satisfiability problem of propositional Boolean formulas ϕSn and uses a constraint solver to check their satisfiability.\nIn the following, we describe in detail how the formula ϕSn is constructed. For the sake of a self-contained presentation, we repeat parts of Section V; as a beneficial side-effect, this repetition allows us to provide further explanations of the formulas presented in Section V. Moreover, to facilitate a more concise and accessible description, we define ϕSn slightly different. In particular, we introduce a formula ϕWn , which tracks the run of AM on words occurring in the sample (in Pos , Neg , and as antecedent of an implication). In contrast to Section V (where we defined the formula ϕUnin to track the run of AM on the set Ante(Uni)) this approach results in more concise and easier to understand formulas since (a prefix of) a word can occur more than once in a sample. As a consequence, however, the formula ϕUnin has to be changed in comparison to Section V.\nRecapping the main ideas and encoding of states and transitions\nThe key idea of the formula ϕSn is to encode a DFA with n states by means of Boolean variables and to pose constraints on those variables in order to obtain a DFA that is consistent with the given sample. Our encoding relies on a simple observation: if we fix the alphabet, the set of states and the initial state, then any DFA with n states is uniquely determined (up to isomorphism) by its transitions and final states. Hence, we can without loss of generality fix the state set of the prospective DFA to be Q = {0, . . . , n − 1} and the initial state to be q0 = 0; the alphabet Σ is determined by the given game.\nTo encode the transitions and the final states, we introduce Boolean variables dp,a,q and fq where p, q ∈ Q and a ∈ Σ, which have the following meaning: assigning true to dp,a,q means that the transition δ(p, a) = q exists in the prospective DFA, and assigning true to fq means that q is a final state.\nTo make sure that the variables dp,a,q indeed encode a deterministic transition function, we impose the following constraints.∧\np∈Q ∧ a∈Σ ∧ q,q′∈Q,q 6=q′\n¬dp,a,q ∨ ¬dp,a,q′ (9)∧ p∈Q ∧ a∈Σ ∨ q∈Q dp,a,q (10)\nFormula (9) and (10) are the same as Formula (1) and (2) of Section V, respectively: Formula (9) enforces that dp,a,q encode a deterministic function, while Formula (10) asserts that the function is total.\nLet ϕDFAn (d, f) be the conjunction of Formulas (9) and (10) where d denotes the list of variables dp,a,q and f denotes the\nlist of variables fq for p, q ∈ Q and a ∈ Σ. Given a model M of ϕDFAn , deriving the encoded DFA is straightforward, as shown next.\nDefinition 6: Let M |= ϕDFAn (d, f). We define the DFA AM = (Q,Σ, q0, δ, F ) by • δ(p, a) = q for the unique q ∈ Q with M(dp,a,q) = true;\nand • F = {q ∈ Q |M(fq) = true}.\n(Recall that we fixed Q = {0, . . . , n− 1} and q0 = 0.) To produce a DFA that is consistent with a sample, we add\nfurther constraints: • a formula ϕPosn asserting Pos ⊆ L(AM); • a formula ϕNegn asserting Neg ∩ L(AM) = ∅; • a formula ϕExn asserting for each (u,A) ∈ Ex that u ∈ L(AM) implies L(AM) ∩ L(A) 6= ∅; and\n• a formula ϕUnin asserting for each (u,A) ∈ Ex that u ∈ L(AM) implies L(AM) ⊆ L(A). Moreover, we add an auxiliary formula ϕWn , which we discuss shortly. Then,\nϕSn := ϕ DFA n ∧ ϕWn ∧ ϕPosn ∧ ϕNegn ∧ ϕExn ∧ ϕUnin\nis the desired formula. The pivotal idea of these formulas is to impose constraints\non the variables dp,a,q and fq, which, in turn, determine the DFA AM. Having this in mind, it is easier to describe the effects of these constraints by referring to M rather then to the variables themselves. However, we thereby implicitly assume that the formula is satisfiable and that the valuation M is a model.\nTHE FORMULA ϕWn To ensure that the prospective automaton AM is consistent with the given sample, we need a mechanism to determine whether AM accepts or rejects the words occurring in the sample. The idea is to track the run of AM on all prefixes of the set"
    }, {
      "heading" : "W = Pos ∪Neg ∪Ante(Ex ) ∪Ante(Uni),",
      "text" : "which contains all positive and negative words as well as all words that occur as antecedent of an existential or universal implication. The idea is to introduce auxiliary Boolean variables xu,q where u ∈ Pref (W ) and q ∈ Q; the intended meaning of these variables is that if the prospective DFA AM reaches state q on reading the word u, then xu,q is set to true. The following constraints enforce this.\nxε,q0 (11)∧ u∈Pref (W ) ∧ q 6=q′∈Q\n¬xu,q ∨ ¬xu,q′ (12)∧ ua∈Pref (W ) ∧ p,q∈Q (xu,p ∧ dp,a,q)→ xua,q (13)\nSince any run starts in the initial state q0, Formula (11) asserts that xε,q0 is set to true . Formula (12) enforces that for every u ∈ Pref (W ) there exists at most one q ∈ Q such that\nxu,q is set to true (in fact, the conjuction of Formulas (10)– (13) implies that there exists a unique such state). Finally, Formula (13) prescribes how the run of AM on a word u ∈ Pref (W ) proceeds: if AM reaches state p on reading u (i.e., xu,p is set to true) and there exists a transition from p to state q on reading the symbol a ∈ Σ (i.e., dp,a,q is set to true), then AM reaches state q on reading ua and xua is set to true .\nLet ϕWn (d, f, x) be the conjunction of Formulas (11), (12), and (13) where d and f are as above and x is the list of variables xu,q for u ∈ Pref (W ) and q ∈ Q. Then a strightforward induction proves the following lemma (see, e.g., Neider and Jansen [14]).\nLemma 3: Let n ≥ 1, M a model of\nϕDFAn (d, f) ∧ ϕWn (d, f, x),\nand AM the DFA defined according to Definition 6. Then, AM : q0 u−→ q implies M(xu,q) = true for all u ∈ Pref (W ).\nTHE FORMULAS ϕPosn AND ϕ Neg n\nHaving introduced the formula ϕWn , it is straightforward to enforce a correct behavior of AM on Pos and Neg . To assert that AM accepts all words in Pos , we impose the constraint∧\nu∈Pos ∧ q∈Q xu,q → fq, (14)\nwhich ensures that state q is a final state if AM reaches q on reading a word u ∈ Pos . Similarly, the constraint∧\nu∈Neg ∧ q∈Q xu,q → ¬fq (15)\nmakes sure that state q is not a final state if AM reaches q on reading a word u ∈ Neg , hence, asserting that all words of Neg are rejected.\nLet ϕPosn (d, f, x) denote Formula (14) and ϕ Neg n (d, f, x) denote Formula (15) where d, f , and x are as above. Then, we obtain the following results.\nLemma 4: Let S = (Pos,Neg ,Ex ,Uni) be a sample, n ≥ 1, and\nψPosn (d, f, x) := ϕ DFA n (d, f) ∧ ϕWn (d, f, x) ∧ ϕPosn (d, f, x).\nThen, the following statements hold: 1) If M |= ψPosn , then AM is a DFA with n states that\nsatisfies Pos ⊆ L(AM). 2) If a DFA B with n states exists that satisfies Pos ⊆ L(B),\nthen ψPosn is satisfiable. Lemma 5: Let S = (Pos,Neg ,Ex ,Uni) be a sample, n ≥ 1,\nand\nψNegn (d, f, x) := ϕ DFA n (d, f) ∧ ϕWn (d, f, x) ∧ ϕNegn (d, f, x).\nThen, the following statements hold: 1) If M |= ψNegn , then AM is a DFA with n states that\nsatisfies Neg ∩ L(AM) = ∅. 2) If a DFA B with n states exists that satisfies Neg∩L(B) = ∅, then ψNegn is satisfiable.\nLet us now prove Lemma 4. The proof of Lemma 5 is analogous.\nProof of Lemma 4: To prove the Statement 1, assume M |= ψPosn and let AM be the DFA constructed according to Definition 6. Furthermore, pick an arbitrary u ∈ Pos . Then, Lemma 3 implies that if AM reaches state q on reading u, then M(xu,q) = true . Additionally, Formula (14) asserts that q is a final state and, therefore, AM accepts u by Definition 6. Since this is true for all u ∈ Pos , we obtain Pos ⊆ L(AM).\nTo prove the second statement, let B = (QB,Σ, qB0 , δB, FB) be a DFA with n states that satisfies Pos ⊆ L(B). The key idea is to translate B into a valuation V that satisfies ψPosn . To simplify this translation a bit, we assume without loss of generality that the sets of states of B and AM coincide (i.e., QB = Q); one can easily achieve this by renaming states. The definition of V is a follows: • For each p, q ∈ QB and a ∈ Σ, we set dp,a,q to true if\nand only if δB(p, a) = q. • For each q ∈ QB, we set fq to true if and only if q ∈ FB. • For each u ∈ W , we set xu,q to true if and only if B : qB0\nu−→ q. It is not hard to verify that V indeed satisfies ψPosn since V(xu,q) is defined according to the runs of B on the inputs u ∈W .\nTHE FORMULA ϕUnin The formula ϕUnin needs to enforce that L(AM) respects all universal implications in Uni . (Recall that the learner stores universal and existential implication as a pair (u,A) where u ∈ Σ∗ is a word and A is an NFA over Σ.) To achieve this, we construct for each universal implication ι = (u,A) ∈ Uni a formula ϕιn that asserts L(A) ⊆ L(AM) if u ∈ L(AM). The formulas ϕUnin is then the (finite) conjunction ∧ ι∈Uni ϕ ι n.\nGiven a universal implication ι ∈ Uni , say ι = (u,A) with A = (QA,Σ, qA0 ,∆A, FA), the key idea of the formula ϕιn is to track the runs of AM and A in parallel. To this end, we introduce new auxiliary variables yιq,q′ where q ∈ Q and q′ ∈ QA, which have the following meaning: the variable yιq,q′ is set to true if there exists a word v ∈ Σ∗ such that AM : q0 v−→ q and A : qA0 v−→ q′. The following constraints assert this.\nyιq0,qA0 (16)∧\np,q∈Q ∧ (p′,a,q′)∈∆A (yιp,p′ ∧ dp,a,q)→ yιq,q′ (17)\nFormula (16) enforces yι q0,qA0 to be set to true because AM : q0 ε−→ q0 and A : qA0\nε−→ qA0 . Formula (17) is similar to Formula (13) and describes how the runs of AM and A proceed: if there exists a word v such that AM : q0\nv−→ p and A : qA0\nv−→ p′ (i.e., yιp,p′ is set to true) and there are transitions (p′, a, q′) ∈ ∆A and δ(p, a) = q in AM, then AM : q0\nva−→ q and A : qA0\nva−→ q′, which requires that yιq,q′ has to be set to true as well.\nNote that the variables yιq,q′ do not track runs exactly: it is possible that a variable yq,q′ is set to true even without the\nexistence of a word v ∈ Σ∗ that induces the runs AM : q0 v−→ q and A : qA0 v−→ q′. This inaccuracy, however, is sufficient to obtain the desired result. In order to express that AM indeed respects the universal implication ι, we add the implication∨ q∈Q xu,q ∧ fq → ∧ q∈Q ∧ q′∈FA yιq,q′ → fq\n . (18) This formula ensures that whenever AM accepts u (i.e., the antecedent is true), then all words that lead to an accepting state in A also lead to an accepting state in AM (i.e., the consequent is true).\nLet ϕιn(d, f, x, yι) be the conjunction of Formulas (16), (17), and (18) where d, f , as well as x are as above and yι is the list of all yιq,q′ for q ∈ Q and q′ ∈ QA. Additionally, let ϕExn be the conjunction\nϕUnin (d, f, x, y) := ∧\nι∈Uni ϕιn(d, f, x, y ι),\nwhere y denotes the list of all variables occurring in yι for each ι ∈ Uni . Then, the following holds.\nLemma 6: Let S = (Pos,Neg ,Ex ,Uni) be a sample, n ≥ 1, and\nψUnin (d, f, x, y) := ϕ DFA n (d, f)\n∧ ϕWn (d, f, x) ∧ ϕUnin (d, f, x, y).\nThen, the following statements hold: 1) If M |= ψUnin , then AM is a DFA with n states that\nsatisfies for all (u,A) ∈ Uni that u ∈ L(AM) implies L(A) ⊆ L(AM). 2) If a DFA with n states exists that satisfies for all (u,A) ∈ Uni that u ∈ L(AM) implies L(A) ⊆ L(AM), then ψUnin is satisfiable. Proof: We split the proof in two parts: we first show\nStatement 1 and subsequently Statement 2.\nTo prove Statement 1, we show that for an universal implication ι = (u,A) ∈ Uni , a model M of the formula\nψιn(d, f, x, y ι) := ϕDFAn (d, f) ∧ ϕWn (d, f, x) ∧ ϕιn(d, f, x, yι)\nresults in an automaton AM that respects ι (i.e., u ∈ L(AM) implies L(A) ⊆ L(AM)). The claim of Statement 1 then follows immediately because ϕUnin is the conjunction of the individual formulas ϕιn. In the following, fix an universal implication ι = (u,A) ∈ Uni , assume M |= ψιn, and let AM be the DFA constructed according to Definition 6.\nGiven an universal implication ι = (u,A), say with A = (QA,Σ, q0,∆A, FA), we first show by induction over the length of inputs v ∈ Σ∗ that the variables yιq,q′ have indeed the desired meaning (i.e., AM : q0 v−→ q and A : qA0 v−→ q′ imply M(yιq,q′) = true). Base case (v = ε) Both AM : q0 ε−→ q0 and A : qA0\nε−→ qA0 hold by definition of runs. Moreover, Formula (16) enforces M(yι\nq0,qA0 ) = true . Thus, the claim holds.\nInduction step (v = v′a) Assume AM : q0 v′−→ p a−→ q and\nA : qA0 v′−→ p′ a−→ q′. Thus, there exists transitions (p′, a, q′) ∈ ∆A and δ(p, a) = q; the latter means M(dp,a,q) = true by Definition 6. Moreover, applying the induction hypothesis yields M(yιp,p′) = true. In this situation, Formula (17) enforces M(yιq,q′) = true , which proves the claim.\nHaving established the meaning of the variables yιq,q′ , it is now straightforward to prove thatAM satisfies L(A) ⊆ L(AM) if u ∈ L(AM). If AM accepts u, say AM : q0\nu−→ q with q ∈ F , then we know that M(xu,q) = true (by Lemma 3) and M(fq) = true (by Definition 6). In this situation, the antecedent of Formula (18) is satisfied. Thus, its consequent is necessarily satisfied as well because M is a satisfying assignment of ψUnin . This, in turn, ensures that whenever A accepts a word v ∈ Σ∗, say A : qι0\nv−→ q′ with q′ ∈ FA, then the run AM : q0\nv−→ q is also accepting: the induction above shows that M(yιq,q′) = true and, since the consequent of Formula (18) ensures that M(yιq,q′) = true implies M(fq) = true for all q ∈ Q and q′ ∈ FA, also M(fq) = true holds. Hence, L(A) ⊆ L(AM) because v was chosen arbitrarily. Since these arguments are true for all ι ∈ Uni , the DFA AM respects all implications in Uni .\nTo prove Statement 2, suppose that B = (QB,Σ, qB0 , δB, FB) is a DFA with n states that respects all universal implications in Uni . Similar to the proof of Lemma 3, we translate this DFA into a assignment V that satisfies ψUnin . For the sake of this translation, we assume without loss of generality that the state stets of B and AM coincide (i.e., QB = Q).\nThe translation is as follows: • For each p, q ∈ QB and a ∈ Σ, we set V(dp,a,q) = true\nis and only if δB(p, a) = q. • For each q ∈ QB, we set V(fq) = true if and only if q ∈ FB. • For each u ∈W and q ∈ QB, we set V(xu,q) = true if and only if B : qB0\nu−→ q. • For each universal implication ι = (u,A) ∈ Uni with A = (QA,Σ, qA0 ,∆A, FA), q ∈ QB, and q′ ∈ QA, we set V(yιq,q′) = true if a v ∈ Σ∗ exists such that B : q0\nv−→ q and A : qA0\nv−→ q′. It is not hard to verify that V satisfies ϕDFAn ∧ϕWn . To show that is also satisfies ϕUnin , fix a universal implication ι = (u,A), say with A = (QA,Σ, qA0 ,∆A, FA). We first observe that V satisfies Formulas (16) and (17) since the variables yιq,q′ track the runs of both automata on inputs v ∈ Σ∗. Second, if u /∈ L(B), then V does not satisfy the antecedent of Formula (18) and, hence, satisfies Formula (18). If u ∈ L(B), on the other hand, consider the runs B : qB0 v−→ q and A : qA0 v−→ q′ on some input v ∈ Σ∗. Then, V(yιq,q′) = true by definition of V. Moreover, if A accepts v (i.e., q′ ∈ FA), then B accepts v as well (i.e., q ∈ FB) because B respects all implications in Uni . Hence, V(fq) = true by definition of V. Thus, the valuation V satisfies the consequent of Formula (18) (since v was chosen arbitrary), which implies that V satisfies Formula (18). Finally,\nwe note that these arguments are true for each ι ∈ Uni and, thus, V satisfies ϕUnin .\nTHE FORMULA ϕExn\nThe formula ϕExn needs to enforce that L(AM) respects all existential implications in Ex . Similar to the previous formula, we construct for each existential implication ι = (u,A) ∈ Ex a formula φιn that asserts L(AM) ∩ L(A) 6= ∅ if u ∈ L(AM). The formulas ϕExn is then the (finite) conjunction ∧ ι∈Ex φ ι n.\nThe formulas φιn work similar to the formulas ϕ ι n introduced above. Given an existential implication ι = (u,A), say with A = (QA,Σ, qA0 ,∆A, FA), the key idea is again to track the runs of AM and A in parallel. In contrast to ϕUnin , however, it is no longer sufficient to build upon the variables yq,q′ as they do not track the runs exactly; recall that yq,q′ might be set to true even without the existence of a word that induces runs to the state q ∈ AM and q′ ∈ A. This fact prevents us from enforcing the existence of a word in the intersection L(AM) ∩ L(A) based on the variables yq,q′ (should this be necessary due to AM accepting the antecedent of ι).\nWe approach this problem by tracking the parallel runs of AM and A exactly, exploiting the following simple fact about finite automata.\nObservation 1: Let B1 = (QB1 ,Σ, q B1 0 ,∆B1 , FB1) and B2 = (QB2 ,Σ, q B2 0 ,∆B2 , FB2) be two NFAs. Then, a word w ∈ Σ∗ with B1 : qB10 w−→ q and B2 : qB20\nw−→ q′ exists if and only if a word w′ ∈ Σ∗ of length at most |QB1 ||QB2 | − 1 with B1 : qB10 w′−→ q and B2 : qB20 w′−→ q′ exists.\nTo see why Observation 1 is true, suppose there exists an input w ∈ Σ∗ of length greater than k = |QB1 ||QB2 | − 1 with B1 : qB10 w−→ q and B2 : qB20 w−→ q′. Then, there has to be a pair of states occurring in these runs that repeats at least once. The (nonempty) part of w in between this repetition can be removed, resulting in a word w′ with B1 : qB10\nw′−→ q and B2 : qB20\nw′−→ q′. By repeating this argument successively, one obtains a word of length less of equal to k that leads to state q in B1 and state q′ in B2.\nAs Observation 1 shows, it is indeed enough to consider words of length at most k = n|A| − 1 in order to track the parallel runs of AM and A exactly. We do so by means of new auxiliary variables zιq,q′,` where q ∈ Q, q′ ∈ QA, and ` ∈ {0, . . . , k}, which have the following meaning: the variable zιq,q′,` is set to true if and only if there exists a word v ∈ Σ∗ with |v| = ` such that AM : q0 v−→ q and A : qA0\nv−→ q′. The following formulas constrain the variables zq,q′,` as described.\nzιq0,qA0 ,0 ∧ ∧ (q,q′)∈Q×QA\\{(q0,qA0 )} ¬zιq,q′,0\n(19)∧ p,q∈Q ∧ (p′,a,q′)∈∆A ∧ `∈{0,...,k−1} (zιp,p′,` ∧ dp,a,q)→ zιq,q′,`+1\n(20)\n∧ q∈Q ∧ q′∈QA ∧ `∈{1,...,k}\nzιq,q′,` →∨ p∈Q ∨ (p′,a,q′)∈∆A dp,a,q ∧ zιp,p′,`−1 (21)\nFormula (19) makes sure that zι q0,qA0 ,0 is set to true , whereas all other variables zιq,q′,0 are set to false, since AM : q0 ε−→ q0 and A : qA0 ε−→ qA0 are the only runs on the empty word. Formula (20) is similar to Formula (13) and describes how the runs of both automata proceed: if there exists a word v ∈ Σ∗ with |v| < k that induces the runs AM : q0\nv−→ q and A : qA0\nv−→ q′ (i.e., zιq,q′,|v| is set to true) and there exists transitions (p′, a, q′) ∈ ∆A and δ(p, a) = q (i.e., dp,a,q is set to true), then the word va induces the runs AM : q0\nva−→ q and A : qA0\nva−→ q′, which implies that zιq,q′,|va| has to be set to true as well. In a similar manner, Formula (21) prevents zιq,q′,` from being set to true if there exists no input of length ` that leads to the states q in AM and state q′ in A; an exemption to this constraint is the pair of initial states.\nFinally, adding the implication∨ q∈Q xu,q ∧ fq → ∨ q∈Q ∨ q′∈FA ∨ `∈{0,...,k} zιq,q′,` ∧ fq  (22)\nenforces that L(AM) indeed respects the implication ι = (u,A): if AM accepts u (signaled by the antecedent being true), then there also has to exist an input on which both automata reach final states (indicated by the consequent being set to true), hence, proving L(AM) ∩ L(A) 6= ∅.\nLet φιn(d, f, x, zι) be the conjunction of Formulas (19)–(22) where d, f , and x are as above and zι is a list of variables zιq,q′,` for q ∈ Q, q′ ∈ QA, and ` ∈ {0, . . . , k}. Moreover, let ϕExn be the conjunction\nϕExn (d, f, x, z) := ∧ ι∈Ex φιn(d, f, x, z ι),\nwhere z denotes the list of all variables occurring in zι. Then, the following holds.\nLemma 7: Let S = (Pos,Neg ,Ex ,Uni) be a sample, n ≥ 1, and\nψExn (d, f, x, z) := ϕ DFA n (d, f)∧ϕWn (d, f, x)∧ϕExn (d, f, x, z).\nThen, the following statements hold:\n1) If M |= ψExn , then AM is a DFA with n states that satisfies for all (u,A) ∈ Ex that u ∈ L(AM) implies L(AM) ∩ L(A) 6= ∅. 2) If a DFA with n states exists that satisfies for all (u,A) ∈ Ex that u ∈ L(AM) implies L(AM) ∩ L(A) 6= ∅, then ψExn is satisfiable.\nProof of Lemma 7: This proof is similar to the proof of Lemma 6. Again, we split this proof into two part: we first prove Statement 1 and subsequently Statement 2.\nTo prove Statement 1, we show that for an existential implication ι = (u,A) ∈ Ex , a model of the formula ψιn(d, f, x, z\nι) := ϕDFAn (d, f) ∧ ϕWn (d, f, x) ∧ φιn(d, f, x, zι) results in an automaton AM that respects ι (i.e., u ∈ L(AM) implies L(AM) ∩ L(A) 6= ∅). The claim of Statement 1 then follows immediately because ϕExn is the conjunction of the individual formulas φιn. In the following, fix an existential implication ι = (u,A) ∈ Ex , assume M |= ψιn, let AM be the DFA constructed according to Definition 6 and k = n|QA|−1.\nWe first prove that the variable zιq,q′,`, where ` ∈ {0, . . . , k}, is set to true if and only if there exists a v ∈ Σ∗ with |v| ≤ ` such that AM : q0 v−→ q and A : qA0 v−→ q′. This proof proceeds by induction over `. Base case (` = 0) The empty word ε is the unique word v ∈\nΣ∗ with |v| = 0. By definition of runs, AM : q0 ε−→ q0 and A : qA0 ε−→ qA0 . Moreover, Formula (19) makes sure that zι q0,qA0 ,0\nis set to true, whereas zιq,q′,0 is set to false for all other pairs of states. In addition, Formula (21) does not restrict any variable in the case ` = 0. Hence, the claim holds. Induction step (` = `′ + 1) To prove the direction from left to right, assume M(yιq,q′,`) = true. Then, Formula (21) asserts that there exists a state p ∈ Q and a transition (p′, a, q′) ∈ ∆ such that M(zιp,p′,`′) = true and M(dp,a,q) = true (the latter means that AM contains the transition δ(p, a) = q). In addition, applying the induction hypothesis yields that there exists a word v′ ∈ Σ∗ with |v′| = `′ such that AM : q0 v−→ p and A : qA0 v−→ p′. Thus,\nv = v′a is a word of length ` satisfying AM : q0 v−→ q and A : qA0 v−→ q′, which proves the claim. To prove the reverse direction, let v = v′a ∈ Σ∗ be a word of length ` and assume that AM : q0\nv−→ p a−→ q and A : qA0\nv−→ p′ a−→ q′. Thus, we know that (p′, a, q′) ∈ ∆A and δ(p, a) = q (the latter implying M(dp,a,q) = true). In addition, applying the induction hypothesis yields M(zp,p′,`′) = true. In this situation, Formula (20) enforces that zq,q′,` has to be set to true, which proves the claim.\nHaving established the correct meaning of the variables zq,q′,`, proving that AM satisfies L(AM) ∩ L(A) 6= ∅ if u ∈ L(AM) is now straightforward: If u ∈ L(AM), say AM : q0\nu−→ q with q ∈ F , then we know that xu,q is set to true (by Lemma 3) and that M(fq) = true (by Definition 6). In this situation, the antecedent of Formula (19) is satisfied, which implies that its consequent is satisfied as well (since M is a model of ψιn). This means that there exist q ∈ Q, q′ ∈ FA, and ` ∈ {0, . . . , k} such that both M(zq,q′,`) = true and M(fq) = true . The former asserts that there exists a word v ∈ Σ∗ (of length `) such that AM : q0 v−→ q and A : qA0 v−→ q′ (according to the induction above); on the other hand, the latter means q ∈ F . Hence v is accepted by both automata and, consequently, u ∈ L(AM) implies L(AM) ∩ L(A) 6= ∅.\nTo prove Statement 2, let B = (QB,Σ, qB0 , δB, FB) be a DFA with n states that satisfies L(B) ∩ L(A) 6= ∅ if u ∈ L(B) for\nall (u,A) ∈ Ex . Similar to the previous proofs, we translate B into a satisfying valuation V of the variables d, f , x, and z. For the sake of this translation, we once more assume without loss of generality that the sets of states of B and AM coincide (i.e., QB = Q). The definition of V then is as follows: • For each p, q ∈ QB and a ∈ Σ, we set V(dp,a,q) = true\nif and only if δB(p, a) = q. • For each q ∈ QB, we set V(fq) = true if and only if q ∈ FB. • For each u ∈W and q ∈ QB, we set V(xu,q) = true if and only if B : qB0\nu−→ q. • For each ι = (u,A) ∈ Ex , where A =\n(QA,Σ, q A 0 ,∆A, FA), q ∈ QB, and q′ ∈ QA, we set V(zιq,q′,`) = true if and only if there exists a word v ∈ Σ∗ with length ` ≤ n|QA| − 1 such that B : qB0\nv−→ q and A : qA0\nv−→ q′ . It is not hard to verify that V satisfies ϕDFAn ∧ϕWn . To see why it also satisfies ϕExn , pick a universal implication (u,A) ∈ Ex , say with A = (QA,Σ, qA0 ,∆A, FA), and let k = |QB||QA| (recall that |QB| = n = |Q|). First, it is not hard to see that V satisfies Formulas (19) to (21) since these formulas exactly describe the runs of B and A on words of length at most k. Second, if u /∈ L(B), then V does not satisfy the antecedent of Formula (22) and, hence, satisfies Formula (22). If u ∈ L(B), on the other hand, we know that L(B) ∩ L(A) 6= ∅.\nIn other words, there exists a word v ∈ L(B) ∩ L(A) such that B : qB0 v−→ q and A : qA0 v−→ q′ where q ∈ FB and q′ ∈ FA. Moreover, Observation 1 allows us to assume without loss of generality that |v| ≤ k. In this situation, V(zιq,q′,|v|) = true and V(fq) = true holds by definition of V. Hence, V satisfies the consequent of Formula (22), which implies that V satisfies Formula (22) as well. Finally, since these arguments are true for each ι ∈ Ex , the valuation V satisfies ϕExn ."
    }, {
      "heading" : "APPENDIX B CORRECTNESS OF THE SAT LEARNER",
      "text" : "The fact that formula ϕSn has the desired properties is a straightforward corollary of Lemmas 4 to 7.\nCorollary 1: Let S = (Pos,Neg ,Ex ,Uni) be a sample, n ≥ 1, and\nϕSn(d, f, x, y, z) := ϕ DFA n (d, f)∧ϕWn (d, f, x)∧ϕPosn (d, f, x)\n∧ ϕNegn (d, f, x) ∧ ϕUnin (d, f, x, y) ∧ ϕExn (d, f, x, z).\nThen, the following statements hold: 1) If M |= ϕSn , then AM is a DFA with n states that is\nconsistent with S. 2) If a DFA with n states exists that is consistent with S,\nthen ϕSn is satisfiable. Having established that formula ϕSn has the desired properties, we can now show that Algorithm 2 computes a smallest DFA that is consistent with a given sample.\nTheorem 3: Given a contradiction free-sample S , Algorithm 2 returns a minimal DFA (in terms of the number of states) that is consistent with S . In addition, if a minimal consistent DFA has k states, then Algorithm 2 terminates after k iterations.\nProof of Theorem 3: Theorem 3 follows directly from the properties of the formula ϕSn (see Corollary 1): Given a sample S , suppose that a DFA with k states that is consistent with S exists. Then, the formula ϕSn is satisfiable for all n ≥ k. Moreover, if M |= ϕSn , then AM is a DFA with n states that is consistent with S . Since Algorithm 2 increases the parameter n by one in every iteration (starting with n = 1), the algorithm eventually finds the smallest value for which ϕSn is satisfiable (after k iterations) and, thus, a consistent DFA of minimal size.\nWe are now ready to prove the correctness of the SAT learner.\nTheorem 4: Given a teacher for a rational safety game, Algorithm 1, equipped with Algorithm 2 to construct conjectures, terminates and returns a (minimal) DFA accepting a winning set if one exists.\nProof of Theorem 4: Due to the way the teacher answers queries, is is clear that the DFA returned by the SAT learner accepts a winning set. Thus, it is left to show that the SAT learner terminates (given that a winning set exists) and that its result is of minimal size. To this end, we first make three observations:\n1) The SAT learner never conjectures the same DFA twice. This is due to the fact that the SAT learner only conjectures DFAs that are consistent with the sample of the iteration in which is was constructed. Moreover, a simple proof by contradiction shows that the conjecture of the current iteration is also consistent with the samples of all previous iterations since a new sample results from adding a counterexample (i.e., a word or an implication) to the sample the previous iteration. Hence, the conjectures Ai of iteration i and Aj of iteration j < i differ at least on the counterexample added in iteration j.\n2) The SAT learner conjectures DFAs that grow monotonically in size. To see why, suppose that conjecture Ai+1 of iteration i+ 1 has less states than the conjecture Ai of iteration i. As argued above, Ai+1 is also consistent with the sample Si, but has fewer states than Ai. This, however, contradicts the fact that Algorithm 2 always constructs consistent DFAs of minimal size (see Theorem 3).\n3) Any DFA accepting a winning set is consistent with any sample produces during the learning. In other words, adding counterexamples does not rule out solutions.\nTheorem 4 can now be proven as follows. Suppose that a winning set exists and let A be a smallest DFA, say with k states, that accepts a winning set. Since no smaller DFA accepting a winning set exists and due to Observations 1 and 2, we know that the SAT learner eventually conjectures a DFA with at least k states. Towards a contradiction, assume that the SAT learner does not conjecture a DFA with k accepting a winning set. This means that the learner eventually conjectures a DFA with more than k states. Then, however, Observation 3 in connection with the fact that the SAT learner always produces smallest consistent DFAs implies that there exists no DFA with k states accepting a winning set. This is a contradiction. Hence, the SAT learner eventually conjectures a minimal DFA\naccepting a winning set, which passes the teacher’s query, and terminates."
    }, {
      "heading" : "APPENDIX C RPNI LEARNER",
      "text" : "The RPNI learner works in a restricted setting in which every vertex of the arena has a finite (but not necessarily bounded) number of outgoing edges (i.e., E({v}) is finite for all v ∈ V ). This implies that implication counterexamples are of the form (u,A) with L(A) being finite.\nThe RPNI learner works identical to the SAT learner, but uses a different method to construct a consistent DFA from a sample. While the SAT learner uses a constraint solver for this task (see Algorithm 2), the RPNI learner employs a modified version of the popular RPNI algorithm [18], which is a polynomial time heuristic for learning DFAs from positive and negative words (we adapted the RPNI algorithm such that it now learns DFAs not only from positive and negative words but also from existential and universal implications). In contrast to Algorithm 2, however, the modified RPNI algorithm does not, in general, produce minimal consistent DFAs but is much faster. Hence, we encourage the reader to think of the RPNI learner as a heuristic, which uses a faster means to construct conjectures but can no longer guarantee to terminate given that a winning set exists.\nAs a preparatory step, we first present the original RPNI algorithm. Then, we show how to modify the RPNI algorithm such that it can handle existantial and universal in addition to positive and negative words. Finally, we present the RPNI learner and"
    }, {
      "heading" : "A. The RPNI Algorithm",
      "text" : "The RPNI algorithm is a so-called passive learning algorithm for regular languages. It takes two disjoint, finite sets Pos ⊂ Σ∗ and Neg ⊂ Σ∗ as input and constructs a DFA A that satisfies Pos ⊆ L(A) and Neg ∩ L(A) = ∅. The algorithm runs in time and space polynomial in |Pref (Pos ∪Neg)| and, hence, the constructed DFA can, in general, not be minimal (as the problem it solves is NP-complete, see Gold [7]). It turns out, however, that the RPNI algorithm often produces “small” automata in practice.\nThe RPNI algorithm operates on given sets Pos and Neg as follows. It first constructs the prefix-tree acceptor of the set Pos (i.e., the tree-like automaton that accepts exactly the set Pos). Then, it successively tries to merges states of this automaton (in a fixed order), where a merge is considered to be successful if the resulting DFA still rejects all words in Neg . If a merge was successful, RPNI proceeds to merge further states of the resulting automaton. If it was not successful, the merged automaton is discarded and RPNI proceeds with the automaton of the last successful merge. The algorithm stops once there are no more merges left.\nFor our purpose, it is helpful to view the RPNI algorithm as a concrete instance of a generic state-merging algorithm,\nwhich is sketched in pseudo code as Algorithm 3.4 In this more abstract setting, the learning algorithm takes a finite collection κ of data as input and outputs a DFA that satisfies a given (decidable) property p (which usually refers to κ); in the case of RPNI, κ is the pair (Pos,Neg) and the property p states that the resulting DFA has to accept all words in Pos and to reject all words in Neg . The pivotal idea of Algorithm 3 is to start with a potentially large initial DFA that satisfies property p and then reduce its size by merging states, thereby discarding merges that result in a DFA that violates p. Since merging states of a DFA increase its language, we encourage the reader to think of merging as a means of generalization.\nAlgorithm 3: Generic state-merging algorithm\nInput: A collection of data κ Output: A DFA machine A that passes test(A)\n1 Ainit = (Q,Σ, q0, δ, f)← init(κ); 2 (q0, . . . , qn)← order(Q); 3 ∼0← {(q, q) | q ∈ Q}; 4 for i = 1, . . . , n do 5 if qi 6∼i−1 qj for all j ∈ {0, . . . , i− 1} then 6 j ← 0; 7 repeat 8 Let ∼ be the smallest congruence that contains ∼i−1 and the pair (qi, qj); 9 j ← j + 1;\n10 until test(Ainit/∼); 11 ∼i←∼; 12 else 13 ∼i←∼i−1; 14 15 end\n16 return Ainit/∼n ;\nAlgorithm 3 uses three functions init, order, and test, which have the following effects: • The function init receives a finite collection of data as\ninput and returns a (potentially large) DFA that satisfies property p (assuming that this is possible).\n• The function order receives a finite set Q as input and returns an ordered sequence of the elements of Q.\n• The function test receives a DFA as input and returns a Boolean value indicating whether this DFA satisfies property p.\n(We shortly introduce implementations of these functions that allows us to compute a DFA that is consistent with a given finite sample.)\nAlgorithm 3 runs in two consecutive phases. In the first phase (Lines 1 and 2), it calls the function init with parameter κ to construct an initial DFA Ainit that satisfies p (recall that we assume that this is possible). Then, it fixes an order\n4The description here closely follows the more general description by Garg et al. [6].\nq0, . . . , qn of the states of Ainit by calling the function order with parameter Q.\nThe actual merging takes place in the second phase (Lines 3 to 15), according to the order determined in the first phase. For i = 1, . . . , n and j = 0, . . . , i − 1, the algorithm tries to merge state qi with state qj if state qi has not already been merged with a smaller state; since a merge might introduce nondeterminism, the algorithm merges additional states until determinism is restored. Note that we represent merging of states abstractly as constructing a congruence relation ∼⊆ Q × Q (i.e., an equivalence relation that is compatible with the transition function) and the result of the merging as the quotient automaton Ainit/∼, which is defined in the usual way. A merge is kept only if the resulting automaton passes test (otherwise it is discarded). This preserves the invariant that any intermediate DFA Ainit/∼k satisfies property p (since Ainit/∼0 = Ainit satisfies p by definition of init). Hence, the final DFA is guaranteed to satisfy p as well."
    }, {
      "heading" : "B. Adapting the Generic State Merging Algorithm",
      "text" : "In our setting, the collection κ corresponds to a sample S = (Pos,Neg ,Ex ,Uni), and the property p is consistency with S . We now describe how to implement the functions init, order, and test such that the output of Algorithm 3 is a DFA that is consistent with the input-sample S.\na) Creating an initial DFA: Given a sample S , we need to construct a DFA satisfying p (i.e., a DFA consistent with S). To this end, we follow the idea of the RPNI algorithm, namely to construct the prefixtree acceptor of the set Pos . The prefix tree acceptor of a finite set X ⊂ Σ∗ is a partial DFA5 that accepts exactly the set X . It is defined as follows.\nDefinition 7: Given an alphabet Σ and finite set X ⊆ Σ∗, the prefix tree acceptor is the partial DFA AX = (Q,Σ, q0, δ, F ) defined by\n• Q = Pref (X); • q0 = ε; • F = X; and\n• δ(u, a) = { ua if ua ∈ Pref (X) and; undefined otherwise.\nA straightforward induction over the length of input-words proves L(AX) = X .\nHowever, just starting with the prefix tree acceptor APos is not sufficient as APos is not necessarily consistent with S: an implication (u,A) might require to accept a word v ∈ L(A) (because u ∈ L(APos)) that is not an element of Pos and, hence, is rejected by APos . In the case of universal implications, the problem is easy to resolve by (temporarily) adding L(A) to Pos (recall that L(A) is finite). However, the problem becomes more involved in the presence of existential implications as it is no longer apparent which word v ∈ L(A) one should add to Pos in order to obtain a consistent (and preferable small) prefix tree acceptor.\n5A DFA is called partial if not all transitions are defined. Runs that cannot be continue due to missing transition are considered to be rejecting.\nWe approach this problem by using a straightforward translation into a satisfiability problem of formulas in propositional Boolean logic (the resulting satisfiability problem is much simpler than those generated by the SAT learner as it does not involve finding a minimal solution). Given a sample S = (Pos,Neg ,Ex ,Uni), we introduce a Boolean variable xw for each word w of the set\nV = Pos ∪Neg ∪Ante(Ex ) ∪Ante(Uni)\n∪  ⋃ (u,A)∈Ex L(A)  ∪  ⋃ (u,A)∈Uni L(A)  , which consists of all words occurring (explicitly and implicitly) in S. Since the languages of the automata occurring in S is finite, V is a finite set and, hence, the number of variables is finite as well.\nThe desired meaning of the variables is the following: xw is set to true if w either belongs to Pos or it is needs to be added to Pos in order to satisfy the implications. The following constraints enforce this meaning.\n( ∧ w∈Pos xw ) ∧  ∧ w∈Neg ¬xw  (23) ∧\n(u,A)∈Ex xu ⇒ ∨ v∈L(A) xv  (24) ∧\n(u,A)∈Uni xu ⇒ ∧ v∈L(A) xv  (25) Let χ(x) be the conjunction of Formulas (23), (24), and (25) where x is the list of all variables w ∈ V . Then, χ(x) is satisfiable since we assume any sample to be contradictionfree. Moreover, if M is a model of χ(x), then the prefix tree acceptor APos′ of the set\nPos ′ = {w ∈ V |M(w) = true}\nis consistent with S (i.e., satisfies p), which is formalized by the lemma below. This automaton is what the function init returns.\nLemma 8: Let S = (Pos,Neg ,Ex ,Uni) a contradiction-free sample. Then, the following holds:\n1) The formula χ(x) is satisfiable. 2) If M a model of χ(x) and\nPos ′ = {w ∈ V |M(w) = true},\nthen the prefix tree acceptor APos′ is consistent with S. Proof of Lemma 8: Since S is contradiction-free, there exists a DFA, let us denote it by B, that is consistent with S. If we assign true to the variable xw if and only if w ∈ L(B), then this assignment satisfies χ(x). This proves the first claim.\nThe proof of the second claim relies on the fact that the prefix tree acceptor of a set X ⊆ Σ∗ indeed accepts exactly the set X , which can be shown by a simple induction. Given\nthis fact, we first observe that APos′ accepts all words in Pos since L(APos′) = Pos ′ and Formula (23) ensures that Pos ⊆ Pos ′; moreover, a similar argument shows that APos′ rejects all words in Neg . Second, Formula (24) asserts for each existential implication (u,A) ∈ Ex that u ∈ Pos ′ implies the existence of a v ∈ L(A) with v ∈ Pos ′ = L(APos′). Hence, APos′ respects all existential implications. Moreover, one can establish the fact that APos′ respects all universal implications in an analogous manner by referring to Formula (25).\nb) Choosing the Merging Order: The function init returns a DFA whose set of states consists of words over the alphabet Σ. The order function order takes this set and orders it according to the canonical order of words6. This order is also used by RPNI.\nc) Implementing the Test: The function test needs to check whether a given automaton A is consistent with the finite sample S. Since S is a finite a collection of words, consistency can be decided easily by computing the runs of A on those words and checking whether all four conditions (i.e., acceptance of all words in Pos , rejection of all words in Neg , and respecting both types of implications) are fulfilled."
    }, {
      "heading" : "C. Correctness of the RPNI learner",
      "text" : "The correctness of the RPNI learner relies on the correctness of Algorithm 3, which is stated in the next lemma.\nLemma 9: Given a contradiction-free sample S , Algorithm 3 modified as described in Appendix C-B constructs a DFA that is consistent with S. The resulting automaton comprises at most |V | states.\nProof of Lemma 9: Proving that Algorithm 3 constructs a DFA that is consistent with the given sample S is straightforward: the function init constructs an initial DFA that is consistent with S (see Lemma 8), and a merge is only kept if the merged DFA passes the check test (i.e., it is still consistent); hence, the final DFA is guaranteed to be consistent as well. Since the initial DFA has |V | states and merging of states reduces the number of states, the final DFA has at most |V | states.\nThe correctness of the RPNI learner immediately follows from the fact that the learning terminates only if the learner proposes a DFA accepting a winning set. In contrast to the SAT learner, however, the RPNI learner uses an algorithm to derive conjectures that does not necessarily produce consistent DFAs of minimal size. As a consequence, termination of the RPNI learner is not guaranteed even if a DFA accepting a winning set exists. The following theorem summarizes the main result.\nTheorem 5: Given a teacher for a rational safety game over a finitely branching arena, the RPNI learner (i.e., Algorithm 1 equipped with Algorithm 3 to construct conjectures) on termination returns a DFA accepting a winning set.\n6Given an alphabet Σ and a total order <Σ⊂ Σ× Σ, the canonical order of words ≺⊂ Σ∗ × Σ∗ is defined by a1 . . . am ≺ b1 . . . bn if and only if m < n or there exists an i ∈ {1, . . . ,m} such that ai <Σ bi and aj = bj for all j ∈ {1, . . . , i− 1}."
    } ],
    "references" : [ {
      "title" : "Infinite games played on finite graphs",
      "author" : [ "R. McNaughton" ],
      "venue" : "Ann. Pure Appl. Logic, vol. 65, no. 2, pp. 149–184, 1993.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "A simple inductive synthesis methodology and its applications",
      "author" : [ "S. Itzhaky", "S. Gulwani", "N. Immerman", "M. Sagiv" ],
      "venue" : "OOPSLA 2010. ACM, 2010, pp. 36–46.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Slugs GR(1) synthesizer",
      "author" : [ "R. Ehlers", "V. Raman", "C. Finucane" ],
      "venue" : "2014, available at https://github.com/LTLMoP/slugs/.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Acacia+, a tool for ltl synthesis",
      "author" : [ "A. Bohy", "V. Bruyère", "E. Filiot", "N. Jin", "J.-F. Raskin" ],
      "venue" : "CAV, 2012, pp. 652–657.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Regular model checking",
      "author" : [ "A. Bouajjani", "B. Jonsson", "M. Nilsson", "T. Touili" ],
      "venue" : "CAV 2000, ser. LNCS, vol. 1855. Springer, 2000, pp. 403–418.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "ICE: A robust framework for learning invariants",
      "author" : [ "P. Garg", "C. Löding", "P. Madhusudan", "D. Neider" ],
      "venue" : "CAV 2014, ser. LNCS, vol. 8559. Springer, 2014, pp. 69–87.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Complexity of automaton identification from given data",
      "author" : [ "E.M. Gold" ],
      "venue" : "Information and Control, vol. 37, no. 3, pp. 302–320, 1978.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1978
    }, {
      "title" : "Learning regular sets from queries and counterexamples",
      "author" : [ "D. Angluin" ],
      "venue" : "Inf. Comput., vol. 75, no. 2, pp. 87–106, 1987.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1987
    }, {
      "title" : "An automata-theoretic approach to infinite-state systems",
      "author" : [ "O. Kupferman", "N. Piterman", "M.Y. Vardi" ],
      "venue" : "Time for Verification, Essays in Memory of Amir Pnueli, ser. LNCS, vol. 6200. Springer, 2010, pp. 202–259.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A constraint-based approach to solving games on infinite graphs",
      "author" : [ "T.A. Beyene", "S. Chaudhuri", "C. Popeea", "A. Rybalchenko" ],
      "venue" : "POPL 2014. ACM, 2014, pp. 221–234.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Reachability games on automatic graphs",
      "author" : [ "D. Neider" ],
      "venue" : "CIAA 2010, ser. LNCS, vol. 6482. Springer, 2010, pp. 222–230.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Small strategies for safety games",
      "author" : [ "——" ],
      "venue" : "ATVA 2011, ser. LNCS, vol. 6996. Springer, 2011, pp. 306–320.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Finite presentations of infinite structures: Automata and interpretations",
      "author" : [ "A. Blumensath", "E. Grädel" ],
      "venue" : "Theory Comput. Syst., vol. 37, no. 6, pp. 641–674, 2004.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Regular model checking using solver technologies and automata learning",
      "author" : [ "D. Neider", "N. Jansen" ],
      "venue" : "NFM 2013, ser. LNCS, vol. 7871. Springer, 2013, pp. 16–31.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Exact DFA identification using SAT solvers",
      "author" : [ "M. Heule", "S. Verwer" ],
      "venue" : "ICGI 2010, ser. LNCS, vol. 6339. Springer, 2010, pp. 66–79.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "dk.brics.automaton – finite-state automata and regular expressions for Java",
      "author" : [ "A. Møller" ],
      "venue" : "2010, http://www.brics.dk/automaton/.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Z3: an efficient SMT solver",
      "author" : [ "L.M. de Moura", "N. Bjørner" ],
      "venue" : "TACAS 2008, ser. LNCS, vol. 4963. Springer, 2008, pp. 337–340.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "We model the interaction between a controlled system and its possibly adversarial environment as a two-player game over a graph [1].",
      "startOffset" : 128,
      "endOffset" : 131
    }, {
      "referenceID" : 1,
      "context" : "learning takes place in a setting akin to counterexample-guided inductive synthesis (CEGIS) [2] between a teacher, who has knowledge about the safety game in question, and a learner, whose objective is to identify a controller using information disclosed by the teacher in response to (incorrect) conjectures.",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 2,
      "context" : "Additionally, in situations where a complete description of the game is not available in a format amenable to existing game solvers [3], [4], there may still exist human experts (or automated oracles, as in Section IV) who have sufficient insight into how the controlled system should behave and can act as teacher.",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 3,
      "context" : "Additionally, in situations where a complete description of the game is not available in a format amenable to existing game solvers [3], [4], there may still exist human experts (or automated oracles, as in Section IV) who have sufficient insight into how the controlled system should behave and can act as teacher.",
      "startOffset" : 137,
      "endOffset" : 140
    }, {
      "referenceID" : 4,
      "context" : "Hence, one of our main contributions is a symbolic representation of safety games, called rational safety games, that follows the idea of regular model checking [5] in that it represent sets of vertices by regular languages and edges by so-called rational relations.",
      "startOffset" : 161,
      "endOffset" : 164
    }, {
      "referenceID" : 5,
      "context" : "Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal",
      "startOffset" : 37,
      "endOffset" : 40
    }, {
      "referenceID" : 6,
      "context" : "Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 7,
      "context" : "Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal",
      "startOffset" : 131,
      "endOffset" : 134
    }, {
      "referenceID" : 8,
      "context" : "in the past, predominantly in the case of games over pushdown graphs [9].",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 9,
      "context" : "Also, a constraint-based approach to solving games over infinite graphs has recently been proposed [10].",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 10,
      "context" : "Learning-based techniques for games over infinite graphs have already been studied in the context of reachability games [11]; in fact, our symbolic representation of safety games is a generalization of the representation proposed there.",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 11,
      "context" : "In the context of safety games, recent work [12] has already demonstrated the ability of learning-based approaches to extract small reactive controllers from a priori constructed controllers with possibly large number of states.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 0,
      "context" : ", infinite duration two-person games on graphs) as popularized by McNaughton [1].",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 4,
      "context" : "We follow the idea of regular model checking [5], an approach in verification, and represent sets of vertices by regular languages and edges by so-called rational relations.",
      "startOffset" : 45,
      "endOffset" : 48
    }, {
      "referenceID" : 12,
      "context" : "(This definition of rational relations is simplified from that in [13] but sufficient for our purpose.",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 5,
      "context" : "[6], which deals with learning loop invariants from positive and negative data as well as",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "The learning proceeds in a CEGIS-style loop [2].",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 6,
      "context" : "It is important to note that classical learning frameworks for regular languages that involve learning from positive and negative data only, such as Gold’s passive learning [7] or Angluin’s active learning [8], are insufficient in our setting.",
      "startOffset" : 173,
      "endOffset" : 176
    }, {
      "referenceID" : 7,
      "context" : "It is important to note that classical learning frameworks for regular languages that involve learning from positive and negative data only, such as Gold’s passive learning [7] or Angluin’s active learning [8], are insufficient in our setting.",
      "startOffset" : 206,
      "endOffset" : 209
    }, {
      "referenceID" : 5,
      "context" : "[6] argue comprehensively why implications needed in a robust invariant learning framework.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : ", the corresponding decision problem is NP-complete) already in the absence of implications [7].",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 13,
      "context" : "Our encoding of transitions and final states follows an idea from [14] (independently due to [15]).",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 14,
      "context" : "Our encoding of transitions and final states follows an idea from [14] (independently due to [15]).",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 13,
      "context" : "A description of φ n and φ Neg n can also be found in [14].",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 15,
      "context" : "In order to demonstrate the feasibility of our learning approach, we implemented a Java prototype using the BRICS automaton library [16] and Microsoft’s Z3 [17] constraint solver.",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 16,
      "context" : "In order to demonstrate the feasibility of our learning approach, we implemented a Java prototype using the BRICS automaton library [16] and Microsoft’s Z3 [17] constraint solver.",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 9,
      "context" : "[10].",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2016,
    "abstractText" : "We propose a method to construct finite-state reactive controllers for systems whose interactions with their adversarial environment are modeled by infinite-duration twoplayer games over (possibly) infinite graphs. The proposed method targets safety games with infinitely many states or with such a large number of states that it would be impractical— if not impossible—for conventional synthesis techniques that work on the entire state space. We resort to constructing finitestate controllers for such systems through an automata learning approach, utilizing a symbolic representation of the underlying game that is based on finite automata. Throughout the learning process, the learner maintains an approximation of the winning region (represented as a finite automaton) and refines it using different types of counterexamples provided by the teacher until a satisfactory controller can be derived (if one exists). We present a symbolic representation of safety games (inspired by regular model checking), propose implementations of the learner and teacher, and evaluate their performance on examples motivated by robotic motion planning in dynamic environments.",
    "creator" : "LaTeX with hyperref package"
  }
}