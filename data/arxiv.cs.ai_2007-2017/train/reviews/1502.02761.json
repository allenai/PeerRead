{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2015", "title": "Generative Moment Matching Networks", "abstract": "We consider the problem of learning deep generative models from data. We formulate a method that generates an independent sample via a single feedforward pass through a multilayer perceptron, as in the recently proposed generative adversarial networks (Goodfellow et al., 2014). Training a generative adversarial network, however, requires careful optimization of a difficult minimax program. Instead, we utilize a technique from statistical hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simple objective that can be interpreted as matching all orders of statistics between a dataset and samples from the model, and can be trained by backpropagation. We further boost the performance of this approach by combining our generative network with an auto-encoder network, using MMD to learn to generate codes that can then be decoded to produce samples. We show that the combination of these techniques yields excellent generative models compared to baseline approaches as measured on MNIST and the Toronto Face Database.", "histories": [["v1", "Tue, 10 Feb 2015 02:54:58 GMT  (855kb,D)", "http://arxiv.org/abs/1502.02761v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI stat.ML", "authors": ["yujia li", "kevin swersky", "richard s zemel"], "accepted": true, "id": "1502.02761"}
