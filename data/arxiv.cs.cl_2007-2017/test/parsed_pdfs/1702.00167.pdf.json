{
  "name" : "1702.00167.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "SMPOST: Parts of Speech Tagger for Code-Mixed Indic Social Media Text",
    "authors" : [ "Deepak Gupta" ],
    "emails" : [ "deepak.pcs16@iitp.ac.in", "stripathi1770@gmail.com", "pb}@iitp.ac.in" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 2.\n00 16\n7v 1\n[ cs\n.C L\n] 1\nF eb\n2 01\n7"
    }, {
      "heading" : "1 Introduction",
      "text" : "Code-mixing refers to the mixing of two or more languages or language varieties. The terms, code switching and code mixing, are nowadays interchangeably used. The sheer access to internet has resulted in increased social media involvement among the masses. Over the past decade, Indian language contents on various media types such as\nblogs, email, websites and chats have increased significantly. With the advent of smart phones, more people have now access to social media through WhatsApp, Twitter, Facebook by which they share their opinions on people, products, services, organizations and governments. The abundance of social media data has created many new opportunities for information access, but has also led to many novel challenges.\nPart-of-Speech (PoS) tagging is a fundamental task of Natural Language Processing. Many higher level NLP tasks requires input as a PoStagged sentence for parsing. The result of PoS tagging on English-Spanish code-mixed data have been reported in (Solorio and Liu, 2008). Recently, (Vyas et al., 2014) has proposed an architecture of PoS tagging for English-Hindi codemixed data. A language identification system developed by (Gella et al., 2013) used a simple heuristic approach to form chunks of data for the same language. They apply a CRF-based PoS tagger for Hindi and Twitter POS tagger (Owoputi et al., 2013) for English, and map it to the Universal tagset (Petrov et al., 2011). This paper explores the task of PoS tagging in codemixed Indian social media text using a supervised learning approach. The task is to perform PoS tagging in three language pair data sets, namely English-Hindi (EN-HI), English-Bengali (EN-BE) and English-Telugu (EN-TE). PoS tagging for all the three types of data, i.e. Facebook, Twitter and WhatsApp, At first we build a rule-based PoS tagger to identify a subset of PoS tags, followed by a CRF based classification system for the others. In our literature survey on PoS tagging on social code-mixed data, we observe that Universal PoS tags (Petrov et al., 2011) are the most popular. On the other hand, the data sets provided for this shared task were PoS tagged using BIS tagset(Jamatia et al., 2015). For the constrained system, we used the respective\nlanguage pair data set provided by the organizer (Jamatia and Das, 2016). We used the ICON-2015 PoS tagging shared task data in addition to this year data to build the unconstrained system."
    }, {
      "heading" : "2 Rule based PoS Tagging",
      "text" : "Social media data is an amalgamation of diverse heuristics. The task of developing systems for the prediction of PoS is, thus immensely complex. Prior to sending word tokens for classification, it is necessary to remove the inappropriate tokens. This includes all residuals, numerals, emoticons, website links and twitter-specific word tokens like ‘@’,‘#’,‘~’ and many more. In order to address the variations of such tokens in the testing data, we develop a rule-based system for sequentially removing one type after the another. We started by removing all the punctuations and their respective extensions such as ‘....’, ‘!.!.’ and ‘~’. All the numeric tokens were tackled next. This includes tokens starting with a numeric entry and ending with ‘st’, ‘nd’, ‘rd’, ‘th’ for tagging tokens like ‘1st’, ‘2nd’, ‘3rd’ and ‘100th’, respectively. Cellular numbers and textual representations such as ‘lakh’ and ‘million’ were also tagged as numerals. Web URLs were searched through a regular expression based classification system, capturing tokens having strings such as ‘.com’, ‘.me’, ‘.org’, ‘.in’ and starting with ‘https:// ’, ‘http:// ’. Emoticons were searched via a two-step mechanism: a regular expression based system followed by a dictionary look-up. The tokens were first checked for common emoticons such as ‘:)’, ‘:(’ and then sent for a match from a dictionary of popular emoticons. Any token with a unicode expression was marked as ‘RD UNK’. Rest of the tokens are considered to form a set of final cleaned data. We followed the same processes for both training and test data sets. Features are extracted on these datasets for classifier’s training."
    }, {
      "heading" : "3 Feature Extraction",
      "text" : "The proposed system uses an exhaustive set of features for PoS labelling. The features are explained in brief below:\n1. Context word: Local contextual information is useful to determine the type of the current word. We use the contexts of previous two and next two words as features.\n2. Character n-gram: Character n-gram is a contiguous sequence of n characters extracted from a given word. The set of ngrams that can be generated for a given token is basically the result of moving a window of n characters along the text. We extracted character n-grams of length one (unigram), two(bigram) and three (trigram), and use these as features of the classifiers.\n3. Word normalization : Words are normalized in order to capture the similarity between two different words that share some common properties. Each uppercase letter is replaced by ‘A’, lowercase by ’a’ and number by ’0’.\nWords Normalization NH10 AA00 Maine Aaaaa NCR AAA\n4. Prefix and suffix: Prefix and suffix of fixed length character sequences (here, 3) are stripped from each token and used as features of the classifier.\n5. Word Class feature: This feature was defined to ensure that the words having similar structures belong to the same class. In the first step we normalize all the words following the process as mentioned above. Thereafter, consecutive same characters are squeezed into a single character. For example, the normalized word AAAaaa is converted to Aa. We found this feature to be effective for the biomedical domain, and we directly adapted this without any modification.\n6. Word position: In order to capture the word context in the sentence, we have used a numeric value to indicate the position of word in the sentence. The normalized position of word in the sentence is used as a features. The feature values lies in the ranges between 0 and 1.\n7. Number of upper case characters: This feature takes into account the number of uppercase alphabets in the word. The feature is relative in nature and ranges between 0 and 1.\n8. Test word probability: This feature computes the likelihood of a test instance to be\nlabeled based on the information available in the training data. The length of this vector feature is the total number of labels or output tags, where each bit represents an output tag, It is initialized with 0. If the test word does not appear in training, every bits retain their initially marked value 0. Based on the probability value, we have two features:\n(a) Top@1-Probability: For the output tag with highest probability, its corresponding bit in the feature vector is set to 1. All other bits remain as 0.\n(b) Top@2-Probability: For the output tag with highest and second highest probability, their corresponding bit are set to 1 in the feature vector. All other bits remain as 0. (comment: this feature is not clear. Why and how probabilities were computed? how probabilities of test instance computed based on this? etc.)\n9. Binary features: We define the following binary-valued features from the information available in the training data.\n(a) isSufficientLength: Since most of the entity from training data have a significant length. Therefore we set a binary feature to fire when the length of token is greater than a specific threshold value. The threshold value 4 is used to extract the binary features.\n(b) isAllCapital: This value of this feature is set when all the character of current token is in uppercase.\n(c) isFirstCharacterUpper: This value of this feature is set when the first character of current token is in uppercase..\n(d) isInitCap: This feature checks whether the current token starts with a capital letter or not. This provides an evidence for the target word to be of NE type for the English language.\n(e) isInitPunDigit: We define a binaryvalued feature that checks whether the current token starts with a punctuation or a digit. It indicates that the respective word does not belong to any language. Few such examples are 4u,:D, :P etc.\n(f) isDigit: This feature is fired when the current token is numeric.\n(g) isDigitAlpha: We define this feature in such a way that checks whether the current token is alphanumeric. The word for which this feature has a true value has a tendency of not being labeled as any named entity type.\n(h) isHashTag: Since we are dealing with tweeter data , therefore we encounter a lot of hashtag is tweets. We define the binary feature that checks whether the current token starts with # or not.\n10. Stemming and Lemmatizing: For English Language tokens, this features separately adds the stemmed and lemmatized version of the token as a feature. We have used the Porter Stemmer and Word Net Lemmatizer, both from the nltk module, for this feature addition. For Non-English tokens, this feature is a Null feature.\n11. Phonetic Normalization: For English Language tokens, this features adds the Phonetics of the token as a feature. We have used the Double Metaphone phonetic algorithm for this obtaining the feature. For Non-English tokens, this feature is a Null feature."
    }, {
      "heading" : "4 Data Set & Experimental Setup",
      "text" : ""
    }, {
      "heading" : "4.1 Dataset",
      "text" : "The dataset used in the experiment are provided by the organizer of PoS tagging tool contest at ICON2016 (Jamatia and Das, 2016). Dataset consists of Facebook, Twitter and WhatsApp utterance at fine grained and coarse grained level. There are three different code-mixed language pair English-Hindi, English-Bengali and English-Telugu, dataset from each three major social media Facebook, Twitter and WhatsApp are provided to build the system. The more details about the dataset can be found in overview paper (Jamatia and Das, 2016)."
    }, {
      "heading" : "4.2 Experiment",
      "text" : "The features set discussed in Section-3 used to build a PoS model. Conditional random field (CRF) is used as underlying classifier. CRF++1, an implementation of CRF is used to perform the experiment. We have used the default setting of CRF++ throughout the experiment. As CRF++ uses a specified feature template, therefore to find\n1https://taku910.github.io/crfpp/\nthe optimal feature template a series of experiment was performed on training data set in crossvalidation manner. However we tune the feature template on English-Hindi data set only and used the optimal template for all the three language pair."
    }, {
      "heading" : "5 Results",
      "text" : "We have submitted two separate constrained runs for this shared task. The runs differ in the manner of their training while the feature set remains the same. The description of constrained runs are as follows:\n1. Run-1: The system was trained by augmenting the respective language pair training data from all three social media platform viz Facebook, Twitter and WhatsApp. Therefore the same model was used to get the POS tag of Facebook, Twitter and WhatsApp test data. The same strategy was followed for both coarse grained and fine grained POS tag.\n2. Run-2: The system was trained individually by only respective language pair training data from different social media platform viz Facebook, Twitter and WhatsApp. Therefore the model, trained on Facebook, twitter\nand WhatsApp training data was used to get the POS tag of Facebook, Twitter and WhatsApp test data respectively. The same strategy was followed for both coarse grained and fine grained POS tag.\nThe details results of both the runs on finer and coarse grained POS tagging are shown in Table-1 and Table-2. Our a unconstrained system is an extension of Run-1 of constrained system along with previous year data. We augment the respective language pair training data from previous year task and this year task. While cross-validating our systems performance, we could not observe a significant increase in the performance. It is observed from the results of both the constrained runs that, in general, Run-1 performed better in WhatsApp domain among all the language pairs in the finer as well as coarser grained tag set. Similarly, Run-1 performed better in Twitter domain too, except for the Bengali-English language pair. Conversely, Run2 performed better in Facebook domain among all the language pairs in both the tag sets."
    }, {
      "heading" : "6 Future work and Conclusion",
      "text" : "This paper describes the approach for Parts of Speech tagging at finer and coarser level on Bengali-English, Hindi-English and TeluguEnglish language pairs code-mixed data. The system performed exceptionally well in all the domains for finer and coarser tag set, barring the Telugu Twitter Constrained Run-2 on Coarse grained tag set. The team is currently working on the application of Deep Neural Networks in the task of PoS tagging. A lack of labeled data has been the major cause for poor results when applying Recurrent Neural Networks and Long-Short Term Memory (LSTM) models for the classification task. We are currently working on combining a CRF based classifier system and a Bi-Directional LSTM (BLSTM) model for improving the results on code-mixed data sets."
    } ],
    "references" : [ {
      "title" : "Query word labeling and back transliteration for indian languages: Shared task system description",
      "author" : [ "Gella et al.2013] Spandana Gella", "Jatin Sharma", "Kalika Bali" ],
      "venue" : "FIRE Working Notes,",
      "citeRegEx" : "Gella et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Gella et al\\.",
      "year" : 2013
    }, {
      "title" : "Task report: Tool contest on pos tagging for code-mixed indian social media (facebook, twitter, and whatsapp) text",
      "author" : [ "Jamatia", "Das2016] Anupam Jamatia", "Amitava Das" ],
      "venue" : "In Proceeding of ICON 2016",
      "citeRegEx" : "Jamatia et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Jamatia et al\\.",
      "year" : 2016
    }, {
      "title" : "Part-of-speech tagging for code-mixed english-hindi twitter and facebook chat messages",
      "author" : [ "Björn Gambäck", "Amitava Das" ],
      "venue" : "RECENT ADVANCES IN NATURAL LANGUAGE PROCESSING,",
      "citeRegEx" : "Jamatia et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Jamatia et al\\.",
      "year" : 2015
    }, {
      "title" : "Improved part-of-speech tagging for online conversational text",
      "author" : [ "Brendan O’Connor", "Chris Dyer", "Kevin Gimpel", "Nathan Schneider", "Noah A Smith" ],
      "venue" : null,
      "citeRegEx" : "Owoputi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Owoputi et al\\.",
      "year" : 2013
    }, {
      "title" : "A universal part-of-speech tagset",
      "author" : [ "Petrov et al.2011] Slav Petrov", "Dipanjan Das", "Ryan McDonald" ],
      "venue" : "arXiv preprint arXiv:1104.2086",
      "citeRegEx" : "Petrov et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Petrov et al\\.",
      "year" : 2011
    }, {
      "title" : "Part-of-speech tagging for english-spanish code-switched text",
      "author" : [ "Solorio", "Liu2008] Thamar Solorio", "Yang Liu" ],
      "venue" : "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Solorio et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Solorio et al\\.",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "A language identification system developed by (Gella et al., 2013) used a simple heuristic approach to form chunks of data for the same language.",
      "startOffset" : 46,
      "endOffset" : 66
    }, {
      "referenceID" : 3,
      "context" : "They apply a CRF-based PoS tagger for Hindi and Twitter POS tagger (Owoputi et al., 2013) for English, and map it to the Universal tagset (Petrov et al.",
      "startOffset" : 67,
      "endOffset" : 89
    }, {
      "referenceID" : 4,
      "context" : ", 2013) for English, and map it to the Universal tagset (Petrov et al., 2011).",
      "startOffset" : 56,
      "endOffset" : 77
    }, {
      "referenceID" : 4,
      "context" : "In our literature survey on PoS tagging on social code-mixed data, we observe that Universal PoS tags (Petrov et al., 2011) are the most popular.",
      "startOffset" : 102,
      "endOffset" : 123
    }, {
      "referenceID" : 2,
      "context" : "tagged using BIS tagset(Jamatia et al., 2015).",
      "startOffset" : 23,
      "endOffset" : 45
    } ],
    "year" : 2017,
    "abstractText" : "Use of social media has grown dramatically during the last few years. Users follow informal languages in communicating through social media. The language of communication is often mixed in nature, where people transcribe their regional language with English and this technique is found to be extremely popular. Natural language processing (NLP) aims to infer the information from these text where Part-of-Speech (PoS) tagging plays an important role in getting the prosody of the written text. For the task of PoS tagging on Code-Mixed Indian Social Media Text, we develop a supervised system based on Conditional Random Field classifier. In order to tackle the problem effectively, we have focused on extracting rich linguistic features. We participate in three different language pairs, ie. English-Hindi, English-Bengali and English-Telugu on three different social media platforms, Twitter, Facebook & WhatsApp. The proposed system is able to successfully assign coarse as well as fine-grained PoS tag labels for a given a code-mixed sentence. Experiments show that our system is quite generic that shows encouraging performance levels on all the three language pairs in all the domains.",
    "creator" : "LaTeX with hyperref package"
  }
}