{
  "name" : "1502.04780.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Qiong Wu" ],
    "emails" : [ "wuqi0005@e.ntu.edu.sg" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Computational Curiosity\n(A Book Draft)\nby\nQiong Wu\nwuqi0005@e.ntu.edu.sg\nNanyang Technological University"
    }, {
      "heading" : "Contents",
      "text" : "Preface 5\nChapter 1 Psychology Underpinnings of Curiosity 10\n1.1. Categories of Curiosity 10\n1.2. Curiosity-Related Emotions 11\n1.3. Curiosity-Related Behaviors 12\n1.4. Benefits of Curiosity 13\nChapter 2 Arousal Theory 14\n2.1. Collative Variables 14\n2.2. Intermediate Arousal Potential 17\nChapter 3 Traditional Computaional models of curiosity 19\n3.1. Models based on Novelty 22\n3.2. Models based on Surprise 25\n3.3. Models based on Change 28\n3.4. Models based on Uncertainty 29\n3.5. Models based on Complexity 30\n3.6. Discussion 32\nChapter 4 A Novel Generic Computational Model of curiosity 33\n4.1. Standard Agent 34\n4.1.1. Environment 34\n4.1.2. Internal Functions 35\n4.2. Memory and Learning 38\n4.2.1. Memory 39\n4.2.2. Learning 40\n4.3. Curious Functions 42\n4.3.1. Stimulus Detection 43\n4.3.2. Interest Evaluation 44\n4.3.3. Meta-level Decision-making 44\n4.4. Summary 46\nChapter 5 Promising Applications for Computational Curiosity 47\n5.1. Machine Learning 47\n5.2. Robotics 48\n5.3. Artificial Creativity 50\n5.4. Games 51\n5.5. Affective Computing 52\n5.6. Artificial Companions 52\n5.7. Persuasive Technology 53\n5.8. Agent Negotiation 53\n5.9. Trustworthy Computing 54\nChapter 6 A Curious Extreme Learning machine 55\n6.1. Introduction 55\n6.2. Curious Extreme Learning Machine Classifier (C-ELM) 57\n6.2.1. The Internal Cognitive Component: SLFN 58\n6.2.2. Curious Functions 59\n6.3. Performance Evaluation of C-ELM 65\n6.3.1. Performance Measures 65\n6.3.2. Performance Study on Multi-category Classification Problems 66\n6.3.3. Performance Study on Binary Classification Problems 67\n6.4. Summary 68\nChapter 7 A Curious Recommender agent 70\n7.1. Introduction 70\nChapter 8 a curious virtual peer learner 72\n8.1. Introduction 72\nChapter 9 A Curious Virtual Learning Companion 74\n9.1. Introduction 74\nChapter 10 Open Problems 76\n10.1. Evaluation of Simulation 76\n10.2. Evaluation of Curiosity 76\n10.3. Interactions between Collative Variables 76\n10.4. Neuroscience Inspired Modeling Approaches 77\n10.5. Curiosity-based Decision Making 78"
    }, {
      "heading" : "PREFACE",
      "text" : "In recent years, researchers have shown an increasing interest in studying intelligent agents with various characteristics, such as affective agents, negotiation agents, trust agents, persuasive agents, and pedagogical agents. Each of the characteristics brings a new capability to intelligent agents and enhances certain aspect of their performances. These agents, however, still lack the capability to direct their attention towards novelty or to seek interestingness. In human beings, this capability is commonly observed, which is driven by the natural motivation: curiosity. Curiosity has been consistently recognized as the critical motivation that is associated with exploratory behaviors such as exploration, investigation, and learning. It has been identified as a driving force for child development, scientific research, and educational achievements. According to Kashdan, curiosity benefits human beings at two levels: the individual level and the social level. At the individual level, curiosity is associated with individual growth, as an ``innate love of learning without the lure of any profit\". At the social level, curiosity is an ingredient for enhancing interpersonal relationships, through infusing energy and passion into social interactions.\nThe many advantages of curiosity to human beings have inspired researchers to devise computational forms of curiosity to endow artificial beings (or agents) with desirable functions. For example, a curious design agent can arrange art exhibits to elicit the curiosity of their viewers and provide an aesthetically pleasing experience; a curious exploratory agent has been shown to achieve higher learning efficiency in unknown environments. From a machine learning perspective, curiosity has been proposed as algorithmic principles to focus learning on novel and learnable regularities in contrast to irregular noises. These algorithm principles make the agents to be ``explorative\" and allow them to have ``the desire to improve the model's knowledge about the world\", which have shown success in speeding up learning and building unsupervised developmental robotics.\nHuman beings, unfortunately, is often more complex than what a machine learning model can describe. Most machine learning algorithms are strictly utilitarian. The machine always remains enthusiastic to learn and mostly assumes that there is something to be learned. On the other hand, a person may behave less rationally. For example, a person may lack the will to learn even when ample opportunities for learning exist. Alternatively, a person may be curious about a stimulus but realize that little can be learnt from it due to a lack of knowledge or adverse environments (e.g. information blocked by a firewall). In order to provide a more complete model of human cognition and design artificial companions that can elicit curiosity (e.g. for pedagogical purposes), we believe it is beneficial to go back to the research in psychology to understand how human curiosity can be aroused.\nPsychology studies suggest that curiosity can be externally stimulated by various factors, such as novelty, conflict, uncertainty, and complexity, etc. Each of these factors characterizes a different condition where curiosity can potentially be elicited. For example, novelty is induced by something new, whereas surprisingness occurs when an expectation based on previous knowledge is violated by the actual outcome. Several curiosity stimulating factors have been considered in computational curiosity and the explicit consideration of different curiosity stimulating factors makes the curious agents more human-like, more efficient in exploration, and more reactive in collaborative learning environments. Hence, we believe that the explicit consideration of various curiosity stimulating factors can enrich the current understanding of computational curiosity and open up new directions for future development.\nIn this book, we introduce a generic computational model of curiosity for intelligent agents based on the psychology of curiosity. This computational model of curiosity consists of abstract functions and their interactions between each other. Representing computational models for intelligent agents with abstract functions makes them general enough to allow different implementations in different application contexts. Based on this generic computational model of curiosity, we introduce a curiosity-driven learning algorithm and a curiosity-driven recommendation algorithm. The curiosity-driven learning algorithm showcases how curiosity\nbenefits an agent at the individual development level, whereas the curiosity-driven recommendation algorithm demonstrates how curiosity benefits an agent at the social recommendation level. The curiosity-driven learning algorithm realizes the generic computational model of curiosity in a fast neural learning agent: the extreme learning machine, and is referred to as the Curious Extreme Learning Machine (C-ELM). Experimental comparisons with other popular classifiers on benchmark classification problems show a superior learning and generalization performance of C-ELM. In the context of social recommendation, a curiosity-driven recommendation algorithm is developed by realizing the generic computational model of curiosity in a recommender agent. Experimental studies with large scale real world data sets show that curiosity significantly enhances the recommendation coverage and diversity, while maintaining a sufficient level of accuracy.\nTo further evaluate the practical values of the generic computational model of curiosity, we discuss the study of it in the domain of virtual worlds for educational purposes. It has been shown in educational studies that curiosity is an important driving force for child development, scientific research, and educational achievements. Hence, it can be envisioned that considering the concept of curiosity in the design of virtual worlds may enrich their educational potentials. In this book, two types of pedagogical agents are chosen for study in virtual world based learning environments, a virtual peer learner and a virtual learning companion. The virtual peer learner is a Non-player Character that aims to provide a believable virtual environment without direct interactions with users, whereas the virtual learning companion directly interacts with users to enhance their learning experience. It can be expected that curiosity may allow the virtual peer learner to demonstrate more human-like learning behaviors in a virtual learning environment, and adds new ingredients into the interactions provided by the virtual learning companion.\nIn a word, this book discusses computational curiosity, from the psychology of curiosity to the computational models of curiosity, and then showcases several interesting applications of computational curiosity. A brief overview of the book is given as follows.\n Chapter 1 discusses the underpinnings of curiosity in human beings, including the major\ncategories of curiosity, curiosity-related emotions and behaviors, and the benefits of curiosity.\n Chapter 2 reviews the arousal theories of curiosity in psychology and summarizes a\ngeneral two-step process model for computational curiosity.\n Base on the perspective of the two-step process model, Chapter 3 reviews and analyzes\nsome of the traditional computational models of curiosity.\n In Chapter 4, we introduce a novel generic computational model of curiosity, which is\ndeveloped based on the arousal theories of curiosity. This computational model of curiosity consists of abstract functions and their interactions between each other, and such a representation method allows different implementations in different application contexts.\n After the discussion of computational models of curiosity, we outline the important\napplications where computational curiosity may bring significant impacts in Chapter 5\n Chapter 6 discusses an implementation of the generic computational model of curiosity in\na machine learning algorithm. This algorithm realizes the generic computational model of curiosity in an extreme learning machine based classifier, which is referred to as the Curious Extreme Learning Machine classifier (C-ELM). The performance of C-ELM is evaluated against other popular classifiers in the literature on benchmark data sets.\n Chapter 7 discusses an implementation of the generic computational model of curiosity in\na recommender system. This curiosity-driven recommender system realizes the generic computational model of curiosity in the popular matrix factorization algorithm, which largely enhances recommendation diversity and coverage. The performance of the curiosity-driven recommendation algorithm is evaluated using two large scale real world datasets.\n In Chapter 8 and Chapter 9 we study of the generic computational model of curiosity in\ntwo types of pedagogical agents. In Chapter 8 a curious peer learner is developed. It is a non-player character that aims to provide a believable virtual learning environment for\nusers. The effects brought by curiosity to virtual peer learners are studied through computer simulations. In 9 a curious learning companion is developed. It aims to enhance users' learning experience through providing meaningful interactions with them. The curious learning companion realizes the generic computational model of curiosity and is carefully evaluated with human users through field studies.\n Chapter 10 discusses the open questions in the research field of computation curiosity.\nCHAPTER 1 PSYCHOLOGY UNDERPINNINGS OF"
    }, {
      "heading" : "CURIOSITY",
      "text" : "In human beings, curiosity is closely related to cognition, emotion and behavior. It underlines human cognitive development, aesthetic appreciation, and interpersonal relationships. In this chapter, we review the literature in psychology on the underpinnings of curiosity and the benefits of curiosity for human beings.\n1.1. Categories of Curiosity\nMost psychologists believe that curiosity is an intrinsic motivation driving the cognitive development of both humans and animals alike. Berlyne [Berlyne (1960a)] categorized curiosity along two spectrums: (1) from perceptual curiosity to epistemic curiosity, and (2) from specific curiosity to diversive curiosity. Perceptual curiosity, which resides in the lower level of cognition, stems from the senses of both animals and humans (e.g. senses of touch, vision, taste, etc.). It is defined as “a drive that is aroused by novel stimuli and reduced by continued exposure to these stimuli” [Loewenstein (1994)]. Epistemic curiosity, referred to as “an appetite for knowledge”, is related to the higher level of cognition and believed to be a distinctive human feature. While perceptual curiosity and epistemic curiosity are defined along the lines of “lower” and “higher” levels of cognition, specific curiosity and diversive curiosity are distinguished by the possibility of curiosity having a “direction”. Specific curiosity is aroused by a particular piece of information. Diversive curiosity is a general drive to seek information with no specific direction and is predominantly employed to relieve boredom.\nBerlyne's cognitive account for curiosity has been a theoretical foundation for the majority of recent studies. Litman and Speilberger [Litman and Speilberger (2003)] agreed with Berlyne that there is a salient difference between diversive curiosity and specific curiosity, and conducted experimental analysis to provide scales for measuring both concepts. They further concluded that\ndiversive curiosity and specific curiosity, as well as perceptual curiosity and epistemic curiosity, are “substantially correlated”. Speilberger and Starr [Speilberger and Starr (1994)] associated diversive curiosity with “low-level” stimuli and specific curiosity with “high-level” stimuli. However, Schmitt and Lahroodi [Schmitt and Lahroodi (2008)] disagreed with the notion that curiosity can be diversive. They argued that curiosity can only be specific towards its possessor and objects that cause the curiosity. Instead of diversive curiosity, they referred to the generic desire for knowledge as “inquisitiveness”.\nNevertheless, a general consensus among the psychologists points to the close relationship between curiosity and cognition, as a drive to explore novel stimuli or an appetite for knowledge.\n1.2. Curiosity-Related Emotions\nCuriosity is related to emotional constructs. In an early account of curiosity by James [James (1950)], curiosity is viewed as an instinctual or emotional response closely related to fear. He believed that curiosity motivates organisms to actively explore their environment, whereas fear tends to turn the organisms away from the risks induced by unfamiliarity. Berlyne's branch of research, referred to as “drive theory” by Loewenstein [Loewenstein (1994)], is based on the assumption that curiosity produces an unpleasant sensation that is reduced by exploratory behaviors. Loewenstein believed that rather than serving a purposive end, the primary objective of satisfying one's curiosity is to induce pleasure.\nWundt [Wundt (1874)] introduced the theory of “optimal level of stimulation”, which serves as a general rule postulating the relationships between stimulus intensity and the hedonic tone. Based on this theory, Berlyne [Berlyne (1960b)] proposed that there is a need of “intermediate arousal potential” for curiosity to be aroused. Berlyne's theory demonstrates that too little stimulation can result in boredom or inaction, while too much stimulation may result in aversion or withdrawal. Only when the level of stimulation is optimal and pleasurable can exploratory behaviors occur.\nFrom the above discussion, it can be seen that curiosity is closely related to emotional constructs such as fear, pleasure, boredom and anxiety. The decision on whether to explore or to avoid a stimulus is driven by emotional comfort and results in behaviors that regulate emotional states.\n1.3. Curiosity-Related Behaviors\nThe most salient expression of curiosity is through exploratory behaviors, by which curiosity can be satisfied. Berlyne [Berlyne (1960b)] defined two levels of exploratory behaviors, one associated with the perceptual level of curiosity, and the other associated with the epistemic level of curiosity. At each level, the exploratory behaviors can take many forms. At the perceptual level of curiosity, Berlyne divided exploratory behaviors into three categories according to the nature of responses. He referred to the exploratory behaviors as orienting responses if they consist of changes in posture, orientations of sensory organs, or states of sensory organs. The second category of exploratory behaviors is associated with locomotion, such as approaching or withdrawing from the stimuli. When an exploratory behavior causes changes in external objects, through manipulation or otherwise, it is called an investigatory response.\nAt the epistemic level of curiosity, Berlyne also defined three categories of exploratory behaviors. The first category is observation, which places the subject in contact with external situations that can nourish the pertinent learning process. The second category is thinking, which refers to “productive” and “creative” thinking, rather than “reproductive thinking” that only calls up memories to determine how problems should be handled. The last category is consultation, which exposes an individual to verbal stimuli issued from other individuals, including questioning and reading, etc.\nIn summary, through exploratory behaviors, cognitive growth is achieved by creative thinking and emotional states are regulated towards a feeling of “pleasure”.\n1.4. Benefits of Curiosity\nCurrent research indicates that curiosity can contribute to human well-beings at two distinct levels: individual level and social level. At the individual level, curiosity provides an emotional motivation for self-development. It is the driving force for child development as well as an important spur for educational achievements [Loewenstein (1994)]. Also, literature in psychology indicates a close relationship between curiosity and aesthetics, humor, and fun. According to Berlyne [Berlyne (1960b)], these behaviors have common motivational factors and are reinforced by common sources of rewards.\nAt the social level, curiosity can enhance interpersonal relationships. By studying the role of curiosity in conversations, Kashdan et al. [Kashdan et al. (2011)] suggested that curiosity can build social bonds by promoting behaviors such as engagement, responsiveness, and flexibility. These are desirable behaviors for developing interpersonal relationships and building intimacy. Their findings indicate that curiosity is uniquely related to the development of interpersonal closeness with strangers [Kashdan et al. (2004)].\nCHAPTER 2 AROUSAL THEORY\nIn this chapter, we review the literature in psychology on the arousal mechanisms of curiosity. This review will provide insights into possible ways of implementing curiosity in artificial beings and is the basis for conducting our research.\nAccording to Loewenstein [Loewenstein (1994)], existing psychological theories on human curiosity can be divided into three categories: incongruity theory, competence theory, and drive theory. Incongruity theory holds on to the idea that curiosity is evoked by the violation of expectations [Hebb (1949)]. Competence theory views curiosity as an intrinsic motivation to master one's environments [White (1959)]. Drive theory believes in the existence of a curious drive, either primary (homeostatic generated in a similar way as hunger) or secondary (externally generated by stimuli). As commented by Loewenstein, the incongruity theory and the competence theory suffer from the same deficiency that both fail to offer a comprehensive account of curiosity. Hence, in this work, we focus on the drive theory and adopt Berlyne's interpretation of curiosity.\nAccording to Berlyne [Berlyne (1960b)], traditional psychological research concentrated on problems of response selection, which studies what response humans will make to one standard stimulus at a time. However, curiosity deals with a different problem from response selection, which is referred to as stimulus selection. Stimulus selection discusses when several conspicuous stimuli are introduced at once, to which stimulus humans will respond. Berlyne has conducted extensive experimental studies to understand the process of stimulus selection and discovered a set of collative variables that govern this process.\n2.1. Collative Variables\nCollative variables, according to Berlyne [Berlyne (1960b)], refer to the external factors that govern various forms of stimulus selection. There are four major collative variables, viz., novelty, uncertainty, conflict and complexity. Berlyne named these factors collative variables\nbecause the evaluation of each variable involves an analysis of similarities and differences between elements in a stimulus pattern. In the following part of this section, the major collative variables are reviewed.\nNovelty denotes something new. In accordance with the time when a stimulus has been experienced by an organism, novelty can be divided into short-term, long-term, and complete novelty. A stimulus can either be completely new to an organism, or it could have been experienced within just the last few minutes. In the former case, it is called complete novelty, and in the latter case, it is called short-term novelty. The intermediate case where a stimulus has not been experienced for a period of time (usually days) is called long-term novelty. Based on whether a stimulus possesses qualities that have been perceived before, it is classified into absolute novelty or relative novelty. If the stimulus does not have any previously perceived quality, then it is absolute novelty; otherwise, it is relative novelty.\nBased on these observations, Berlyne introduced three criteria to measure novelty, i.e., novelty is inversely related to (1) how often the stimuli have been experienced before, (2) how recently the stimuli have been experienced, and (3) how similar the stimuli are to previously experienced ones.\nNovelty is often accompanied by other properties, each of which may have different influences on exploratory behaviors. Berlyne listed them as supplementary variables to novelty, which includes change, surprisingness, and incongruity. A change of the stimulus in question may induce some priority in exploratory directions. Surprisingness arises when there is a stimulus that induces an expectation and a later stimulus that contradicts the expectation. Incongruity is somewhat different from surprisingness (e.g., the statement that the Earth is round is a surprise to people who are accustomed to the concept that the Earth is _at), and indicates an expectation that is not met by the same stimulus (e.g., a person who is used to receiving gifts on his birthday before may find the experience incongruent when nobody sends him birthday gifts this year).\nUncertainty arises when an organism has difficulty selecting a response to a stimulus. Berlyne adopted information theory to quantify uncertainty. He proposed to measure the uncertainty caused by a stimulus with the following steps: (1) draw up a list of stimuli that might occur (as a response to the stimulus in question), (2) partition them into classes, and (3) assign a probability to each class. The probability of each class denotes the competing strength of each possible response, and Shannon's entropy ∑ denotes the degree of uncertainty.\nConflict occurs when a stimulus arouses two or more incompatible responses in an organism. A response can be incompatible with one another due to different reasons. Firstly, some responses may be innately antagonist to each other. For example, no organism can move forward and backward at the same time. Secondly, some responses may initially be capable of performing together but become incompatible through learning. For example, we seldom frown when shaking hands. Another reason for incompatible responses may be attributed to the limitation of an organism's ability to multi-task. For example, it would be considered an outstanding ability if a person can read two books at the same time. Berlyne proposed four criteria for measuring conflict. Conflict is positively related to (1) the nearness to equality in the strengths of competing responses, (2) the absolute strengths of competing responses, (3) the number of competing responses, and (4) the degree of incompatibility between competing responses.\nComplexity roughly refers to the variety or diversity in a stimulus pattern. Three most obvious properties that determine the degree of complexity are: (1) the number of distinguishable elements in a stimulus, (2) the dissimilarity between these elements, and (3) the degree to which several elements are perceived and responded to as a unit.\nIn summary, collative variables are properties of a stimulus that describe the curiosity stimulating conditions. According to Berlyne, they are all eminently quantitative properties that exist in varying degrees. This endows them potential candidates for measuring the stimulation level of curiosity. Most of the computational models of curiosity have considered at least one of the collative variables for the determination of stimulation level.\n2.2. Intermediate Arousal Potential\nThe existence of a stimulus does not necessarily result in curiosity. The arousal of curiosity depends on an appropriate level of stimulation induced by a stimulus. In the 1870s, Wundt [Wundt (1874)] introduced the concept of “optimal level of stimulation” and postulated an inverted U-shape relationship between the stimulation level and the hedonic value, referred to as the Wundt curve (Figure 2.1). It is a general rule stating that many forms of stimulation are pleasant at medium intensities and become unpleasant when their intensities are too high. Based on Wundt's theory and other experimental results from the literature, Berlyne formed the theory of “intermediate arousal potential”, where too little stimulation results in boredom, too much stimulation results in anxiety and only intermediate stimulation results in curiosity. The two ends of the spectrum in the Wundt curve reflect two rules in stimulus selection: Avoidance of Boredom (AoB) and Avoidance of Anxiety (AoA).\nTo summarize, from the psychological point of view, the arousal process of curiosity can be abstracted into a two-step process model, which offers a uniform angle for examining and analyzing the computational models of curiosity:\n Step 1: evaluation of the stimulation level based on collative variables.\n Step 2: evaluation of the interest level based on the principle of intermediate arousal\npotential.\nCHAPTER 3 TRADITIONAL COMPUTAIONAL MODELS"
    }, {
      "heading" : "OF CURIOSITY",
      "text" : "In this chapter, we review and analyze the traditional computational models of curiosity from the perspective of the proposed two-step process model summarized at the end of the previous chapter.\nBased on the two-step process model, a general appraisal process for computational curiosity can be illustrated as in Figure 3.1. In this figure, the input stimuli are data samples perceived by the agent. The input stimuli trigger the agent's computational appraisal process of curiosity. In step 1, the appraisal process first evaluates the level of stimulation elicited by the stimuli, based on collative variables. Some of the existing models adopt a single collative variable to determine the stimulation value (e.g., [Saunders and Gero (2001)]), while others aggregate multiple collative variables to derive the stimulation value (e.g., [Macedo and Cardoso (2005)]).\nIn step 2, the level of curiosity is evaluated through a mapping from the stimulation value to the curiosity value. Some of the existing models follow the principle of “intermediate arousal potential\" by explicitly simulating the Wundt curve, which represents a nonlinear mapping from the stimulation value to the curiosity value (e.g., [Saunders and Gero (2001); Merrick et al. (2008)]). These models accommodate both AoB and AoA in their stimulus selection approaches. In comparison, other models simply use the stimulation value as the curiosity value (e.g., [Schmidhuber (1991b); Oudeyer and Kaplan (2004); Macedo and Cardoso (2001)]). Some of these models also consider the principle of “intermediate arousal potential\" when determining\nthe stimulation value (e.g., [Schmidhuber (1991b); Oudeyer and Kaplan (2004)]), which accommodate both AoB and AoA. The rest of these models simply assume a positive correlation between the stimulation value and the curiosity value, which only support AoB but not AoA. In this case, a high stimulation can lead the agent to anxiety (e.g., [Macedo and Cardoso (2001)]).\nTaxonomy for the existing computational models of curiosity is provided in Table 3.1. The models are classified into five categories according to the collative variables used for the evaluation of stimulation in Step 1. The five categories include novelty, surprise, uncertainty, change, and complexity. Within each category, the models are further classifies into two subcategories, according to whether the principle of “intermediate arousal potential” is followed in the models. The first sub-category follows this principle and supports both AoB and AoA in stimulus selection, while the second sub-category assumes a positive correlation between the stimulation value and the curiosity value, which only supports AoB. Next, we will discuss each of the models following this taxonomy\nInformation gain\nStorck et al. [95] Improbability Macedo & Cardoso\n[99]\nUncertainty - Entropy Macedo & Cardoso\n[95]\nChange Spread\nadjustment in Gaussian\nKaraoguz et al. [11] -\nComplexity Prediction\nimprovement between successive situations\nSchmidhuber [91b] -\nPrediction improvement between similar situations Oudeyer & Kaplan [04]\nCompression improvement\nSchmidhuber [06]\nDiscriminability difference between two spaces Pang et al. [09]\n3.1. Models based on Novelty\nTo explore the possibility of artificial creativity, Sanders and Gero [Saunders and Gero (2001)] developed a computational model of curiosity for intelligent design agents, focusing on the appraisal of novelty. The goal of such an agent is to evaluate the interestingness of creative design patterns based on individual experiences, where curiosity is the key for the evaluation of interestingness [Saunders and Gero (2001)]. In their model, each creative design pattern (generated by a design generator) can be considered as a stimulus and the stimuli experienced in the past are stored in a “conceptual design space”. This conceptual design space is modeled by a Self-Organizing Map (SOM), representing the forms that the agent has experienced often enough to learn.\nIf we view their model from the perspective of the two-step process model, in Step 1, the evaluation of stimulation is governed by the degree of novelty in a stimulus. The evaluation of novelty is achieved by comparing the stimulus (a creative design pattern) with past experiences (the SOM representations), and is defined by the complement of the typicality measure. This implementation is in line with Berlyne's third criteria for measuring novelty: novelty is inversely proportional to similarity (typicality).\nIn Step 2, Saunders and Gero adopted the principle of intermediate arousal potential and explicitly modeled the Wundt curve as a non-linear function. This function is defined by the difference of two sigmoid functions as follows [Saunders (2002)]:\nwhere is the curiosity value, , P, , , , , and are the reward, punishment, maximum reward, maximum punishment, slope of the reward sigmoid functions, slope of the punishment sigmoid functions, minimum novelty to be rewarded and minimum novelty to be punished, respectively. This curiosity value is the evaluation of the interestingness of a design pattern or how curious it is about the design pattern.\nLater, Merrick and Maher applied this model of curiosity in Non-Player Characters (NPCs) and reconfigurable robots [Merrick et al. (2008); Merrick and Maher (2009); Maher et al. (2008); Merrick and Huntington (2008); Merrick (2008a)] to enhance their performances. For NPCs, the goal of infusing curiosity is to achieve creative behaviors, namely, behavioral diversity [Merrick et al. (2008); Maher et al. (2008)]. These works are rooted in a motivated reinforcement learning framework, by which NPCs can learn the state-action policy in a virtual environment. Here, each event is regarded as a stimulus and is defined as the change between the current state and the previous one. All previously experienced events are stored in an SOM structure. A habituation layer of neurons is connected to the clustering layer and a habituation function is used to compute novelty. The final curiosity value is obtained by feeding the novelty value into the simulated Wundt curve (Equation 3.1). The curiosity value is used as an intrinsic reward to update the policy that maps states to actions. This curiosity reward can eventually lead to creative behaviors, because each new interesting event results in a perturbation of the existing behavioral patterns and form reward signals for the learning process.\nFor reconfigurable robots [Merrick and Huntington (2008)], the role of curiosity is to direct the\nrobots' attention to reconfigurations in their structures. This is an important skill for them to learn new behaviors in response to structural changes. For robots, an event can be considered as a stimulus, which is defined as the change between the current sensation and the previous one. Following a similar algorithm in curious NPCs, curiosity rewards are generated for reconfigurable robots. With the curiosity rewards, the robots are self-motivated to explore changes in their structures and develop new behaviors.\nIn the domain of planetary exploration and map-building of interiors, Macedo and Cardoso [Macedo and Cardoso (1999)] proposed a model of curiosity for intelligent agents to simulate human-like exploratory behaviors in unknown environments. Along their research, they gradually introduced novelty, surprise, and uncertainty into their computational model of curiosity. Here, we first look at their model of novelty. Macedo and Cardoso's model relies on graph-based mental representations of objects. Each object can be regarded as a stimulus. In Step 1, the level of novelty regarding a stimulus (object) is measured based on the error correcting code theory of Hamming. Three steps are considered: 1) representing each graph (describing an object) in a common shape matrix 2) extracting the numerical code from the matrix representation of each graph, and 3) computing the Hamming Distance. Here, novelty is defined as the minimum Hamming Distance from the stimulus to the ones that have been experienced before, which determines the stimulation value. In Step 2, the stimulation value is directly used as the curiosity value. The system only supports AoB because the chance of an object to be explored is positively correlated to the level of curiosity, which direct the system away from boredom.\nFor both the models proposed by Sanders & Gero [Saunders and Gero (2001)] and Macedo & Cardoso [Macedo and Cardoso (1999)], regardless of the implementation, i.e., atypicality in SOM or hamming distance in graph-based mental representations, novelty reflects a comparison between the current stimuli and previous experiences. In other words, similarity. In some later models of curiosity, the factor of time, as another dimension in addition to similarity, is considered for measuring novelty.\nOgino et al. [Ogino et al. (2006)] addressed lexical acquisition problems for robots using computational curiosity to associate visual features of observed objects with the labels (for objects) that are uttered by a caregiver. In their work, each object can be interpreted as a stimulus for the robot. Visual features of each object are represented by an SOM. In Step 1, stimulation value is determined by novelty. The novelty of each object is calculated based on two types of saliency: habituation saliency, reflecting the temporal infrequency; and knowledge-driven\nsaliency, reflecting the level of dissimilarity. The habituation saliency is characterized by habituation and inversely related to the frequency of the observation of a visual feature.\nThe knowledge-driven saliency is characterized by the acquired knowledge, where more saliency is given to visual features that are not associated with other labels. The product of the two saliency values represents the overall level of stimulation, which is directed used as curiosity value (in Step 2). The robot chooses to learn about the object with maximum curiosity value, which drives the system away from boredom and considers the AoB rule in stimulus selection. Their experimental results show that the infusion of curiosity helps accelerate the robot's learning.\n3.2. Models based on Surprise\nTwo interpretations for surprise exist in the literature of computational curiosity. The first one interprets surprise as the difference between an expectation and the real outcome. Prediction error matches well with this interpretation and has been utilized in many curiosity models to measure the level of surprise [Schmidhuber (1991a); Barto et al. (2004a); Schmidhuber (1999); Uğur et al. (2007)]. The second interpretation describes surprise as the degree of not expecting something. Storck et al. [Storck et al. (1995)] modeled this type of surprise using the information gain before and after an observation, while Macedo and Cardoso [Macedo and Cardoso (2001)] proposed another measure using improbability. Next, we will discuss each of these models in detail.\nPrediction Error-based Models: Schmidhuber [Schmidhuber (1991a)] introduced artificial curiosity into model building control systems. The goal of such a control system is to learn the input-output mapping in a noisy environment. Curiosity is infused to give the control system an intrinsic desire to improve the model's knowledge about the world. This is realized by introducing an additional reinforcement unit on top of the controller, which rewards actions that cause high prediction errors. The prediction error inherently measures the degree of mismatch between belief and reality, which is in line with the first interpretation of surprise. In Step 1, the\nstimulation value is determined by surprise (prediction error) and it is directly used as the curiosity value (in Step 2) to form decisions (on rewarding the system). This mechanism (rewarding the system with high surprise/curiosity) encourages certain past actions to be carried out again in order to repeat situations similar to the mismatched ones. Hence, the system will always direct its attention toward something that is unknown and therefore avoid boredom. This working mechanism only supports AoB in stimulus selection. Barto's theory of intrinsically motivated reinforcement learning is implemented based on a similar principle [Barto et al. (2004a); Singh et al. (2004)].\nIn a later variation, Schmidhuber [Schmidhuber (1999, 2002)] worked on exploring the space of general algorithms that can automatically create predictable internal abstractions of complex spatial-temporal events. In this model, both AoB and AoA are accommodated. Curiosity is interpreted as the ability of the system to focus on interesting things by losing interest in the overly predictable (boring) or the overly unpredictable (anxiety inducing) aspects of the world. To achieve this goal, the system is realized by two intrinsically motivated agents playing zerosum games. The two agents can bet in advance on whether a prediction is true or false. If they bet on different outcomes, the system will check who is right. The winner gets rewarded by receiving the other's bids whereas the loser loses its bids due to surprise (error in prediction). Hence, both agents are motivated to lure the opponent into agreeing on computation sequences that will surprise the other one. However, a surprised module will eventually adapt and in turn, cause the other agent to lose a source of reward. In this way, the system as a whole is motivated to shift the exploration focus and reveal the unknown yet predictable regularities.\nAnother example of prediction error-based implementation of surprise is given by the work of Uğur et al. [Uğur et al. (2007)]. In situations where a robot physically interacts with the environment to explore and learn, assuming the traditional reinforcement learning method is applied, the robot may require a large number of interactions to learn even simple tasks. This could eventually damage the robot. To address this problem, Uğur adopted a Support Vector Machine (SVM) to learn the perception and action mapping in the robot, where curiosity is\nintroduced to select interesting training data for SVM to reduce the total number of training data required. In Step 1, the stimulation level is determined by surprise, which is measured by a sample's distance to the hyper-plane (which separates two classes) in the feature space. In Step 2, the stimulation value is directly used as curiosity value for decision making. The system supports AoB because it can be driven away from boredom: only if the distance is smaller than a fixed threshold (curiosity value is high), the sample is considered interesting and sent for learning.\nProbability-based Models: An extension of Schmidhuber's curiosity principle to nondeterministic environments was done by Storck et al. [Storck et al. (1995)]. The goal of their system is to learn the model of a nondeterministic Markov environment where each state-action pair ( ; may result in different next states probabilistically. The goal of introducing curiosity into this learning system is to actively search for interesting training examples that can maximize expected learning improvement. In step 1, the stimulation value is determined by surprise, which reflects “the degree of not expecting something\". They adopt a probabilistic way of measuring surprise, which is the Kullback-Leibler distance between the agent's belief distribution before and after making an observation. This value of information gain reflects the learnability of the exploration space. Exploration areas where little information gain can be achieved are either too predictable (well-learnt) or too unpredictable (inherently unlearnable). Hence, the information gain (surprise) accommodates both AoB and AoA in stimulus selection. In step 2, the surprise value is directly used as the curiosity value, which acts as rewards for the reinforcement learning of state-action pairs. In this way, curiosity drives the system away from the exploration space where little information gain can be achieved, i.e., areas that are either too boring or anxiety-inducing.\nMacedo and Cardoso [Macedo and Cardoso (1999, 2001, 2004, 2005)], mentioned in Section 3.1, also modeled human forms of surprise in artificial agents. Surprise serves as an intrinsic drive to direct the agent's exploration in unknown environment. Their model relies on graphbased mental representations of objects, where each object is considered as a stimulus. The surprise level is defined by the degree of not expecting a stimulus (object), and is implemented\nas the improbability of existence of the stimulus. However, surprise in this model is not treated as a stimulating factor for curiosity. Hence, the surprise value is not mapped to the curiosity value.\n3.3. Models based on Change\nIn robot sensory-motor learning, Karaoguz et al. [Karaoguz et al. (2011)] proposed a model of curiosity to direct robots' attention to changes in the environment. The aim of the model is not to measure the amount (or level) of changes in a stimulus, but rather to focus on how to react when changes occur. Hence, the system does not provide evaluation for the level of stimulation or the level of curiosity (induced by change), but offers mechanisms to redirect its attention to changes.\nFor the robot, the focus of attention is determined by a Gaussian distribution that governs the sampling of training examples over the laser motor space. The center of the Gaussian distribution is determined by the mean value of the last N samples added to the mapping, and directs the attention of the robot to areas where new samples have been recently added. The spread of Gaussian distribution is related to the performance (success rate) of the mapping by\nwhere is the baseline, is the number of time steps since the last new sample was added, is the boredom coefficient, is the failure threshold, is the success rate, and is the failure\ncoefficient.\nIt can be seen from Equation 3.3 that the attention spread is inversely correlated to the success rate. For example, the attention spread is wide when the success rate is low due to a high value of . When a change happens, will be reset to 0 and the high past success rate of\nthat region will result in a narrow Gaussian distribution of samples. Newly-added links in unlearnable areas (noisy region) will fail on retest, which can drive the success rate for that region below the failure threshold and increase the width of sampling distribution, redirecting\nthe system away from that region. Hence, the system has a drive towards regions where the existing mappings are not making accurate predictions (AoB) and a drive away from the regions where no improvements can be obtained (AoA).\nFrom the perspective of machine learning, one can argue that this model is a special case of the earlier introduced models based on predictors [Schmidhuber (1991a,b)], because a predictor always predicts that the next observation is similar to the current observation, which indicates no change. Once a change occurs, the predictor makes an error and updates its knowledge about the world.\n3.4. Models based on Uncertainty\nUncertainty arises when there is no clear response to a stimulus [Berlyne (1960b)]. The entropy in information theory has been proposed to measure the degree of uncertainty in a stimulus. This measure has also been employed very often in computational implementations to realize uncertainty-based curiosity [Macedo and Cardoso (2005)]. To improve an agent's exploration in unknown environments, Macedo and Cardoso [Macedo and Cardoso (2005)] introduced a measure of uncertainty, on top of novelty [Macedo and Cardoso (1999, 2001, 2004)], into their model of curiosity. Based on the same system setup as presented in Section 3.1, Macedo and Cardoso [Macedo and Cardoso (2005)] argued that the desire to know or learn an object can be induced by both novelty and uncertainty. Each object (stimulus) can contain known parts (without uncertainty) and uncertain parts. The known parts of an object are used to measure novelty through Hamming Distance(introduced in Section 3.1), whereas uncertainty is measured by the entropy of all uncertain parts, including analogical and propositional descriptions of the physical structure, and functions of the object. In step 1, the stimulation value is determined by the aggregation of novelty and uncertainty. In step 2, the stimulation value is directly used as curiosity value. The system adopts AoB in stimulus selection and chooses objects with highest curiosity value to explore.\n3.5. Models based on Complexity\nIn machine learning models of curiosity, complexity has been associated with the predictive power of predictive systems or compressive power of data compression systems [Li and Vitanyi (2008); Schmidhuber (1991b, 2006); Oudeyer and Kaplan (2004)]. In this subsection, we review these models and their variations.\nIn Section 3.2, we introduced Schmidhuber's early ideas on implementing curiosity by rewarding the system proportionally to surprise, i.e., prediction error [Schmidhuber (1991a)]. However, this implementation only succeeds in guiding the system to avoid boredom (i.e., well learnt area) but not anxiety (i.e., inherently unpredictable area caused by noisy). Later, Schmidhuber refined the model to accommodate both AoB and AoA. He defined curiosity as a simple principle: to learn a mapping from actions to the expectation of future performance improvement [Schmidhuber (1991b,c)]. Instead of pure prediction error, reward is now generated according to the controller's prediction improvement, i.e., change in prediction error. In step 1, the complexity of a data to be learnt by the system (e.g., familiar data that is easy to learn or noises that are too difficult to learn) is determined by prediction improvement, which supports both AoB and AoA in stimulus selection. The prediction improvement is obtained by a confidence module, which evaluates the reliability of a prediction and can be realized by probability-based or error-based methods. In step 2, the stimulation value is directly used as curiosity value, which is adopted as intrinsic rewards for learning. In this way, the controller will choose actions (based on the delayed reward) to deliberately select training examples with easily learnable regularities. Hence, the infusion of curiosity can direct the system's attention away from the exploration space that is either too predictable or too unpredictable.\nSchmidhuber [Schmidhuber (2006, 2009a,b)] formed his formal theory of creativity, by generalizing the simple principle of curiosity from predictors to data compressors. According to this theory, a 'beautiful' sensory data is one that is simple yet has not been fully assimilated by the adaptive observer, which is still learning to compress data better. The agent's goal is to create\naction sequences that can extend the observation history to yield previously unpredictable but quickly learnable algorithmic regularities. In other words, it is looking for data with high compressibility (reflected by curiosity value).\nSchmidhuber's implementation of prediction improvement by nature is a comparison of prediction error between situations that are successive in time. This principle allows robots to avoid long periods of time in front of a television with white noise (completely unlearnable situations) because the prediction error will remain large and the robot will be bored due to little prediction improvement. However, this principle is not robust enough in the alternation of completely predictable and unpredictable situations, because robots can get stuck here due to large prediction improvements. To cope with such problems, Oudeyer and Kaplan [Oudeyer and Kaplan (2004); Oudeyer et al. (2005)] refined Schmidhuber's simple principle. Instead of comparing the prediction error between situations that are successive in time, they compare the prediction error between situations that are similar. They proposed a model of curiosity that allows a robot to group similar situations into regions where comparison between situations is meaningful. The learning space is divided into regions and each region has an expert to make local predictions. Each expert computes the prediction improvement (curiosity value) locally and rewards its state-action pairs according to the prediction improvement. This works well in practice to handle problems such as robots get stuck in situations with completely predictable and unpredictable sample data in alternation.\nAnother variation of using prediction improvement as curiosity drive has been proposed by Pang et al. [Pang et al. (2009)]. This model is rooted in incremental Linear Discriminant Analysis (LDA). Here, curiosity is measured as the discriminability difference (residue) between the LDA transformed space and the original space. The infusion of curiosity can help the system actively search for informative examples to learn and improve the performance using fewer instances.\n3.6. Discussion\nAn interesting point worth noting is that, from the machine learning perspective, there are certain recurring principles underlying curiosity-inspired algorithms. The first group of recurring principles includes generating intrinsic curious rewards based on errors [Schmidhuber (1991a); Uğur et al. (2007)] or Shannon's information [Scott and Markovitch (1989)]. This group of principles can redirect learning to focus on the unknown samples. However, they fail to distinguish noise from the novel and learnable regularities. The second group of recurring principles include generating intrinsic curious rewards based on error reduction [Schmidhuber (1991b); Oudeyer and Kaplan (2004)], information gain [Storck et al. (1995)], or compression improvement [Schmidhuber (2006)]. This group of principles effectively addresses the above mentioned problem. They are able to guide learning to focus on easily learnable regularities and at the same time filter out noise. The second group of principles forms the basis of Schmidhuber's theory of artificial curiosity, which shows success in speeding up learning and building unsupervised developmental systems [Schmidhuber (1991b)]. Also, Schmidhuber believes that these principles make machines “creative\" and intrinsically motivate machines to create action sequences that make data interesting, which forms the basis of his theory of artificial creativity [Schmidhuber (2006)].\nCHAPTER 4 A NOVEL GENERIC COMPUTATIONAL"
    }, {
      "heading" : "MODEL OF CURIOSITY",
      "text" : "In this chapter, we present a computational model of curiosity for intelligent agents. This computational model consists of abstract functions and their interactions between each other, which is inspired by Wooldridge's work [Wooldridge (2002)]. Representing agent models with abstract functions makes them general enough to allow different implementations in different application contexts.\nThe proposed computational model of curiosity for intelligent agents is built based on the model of a standard agent [Wooldridge (2002)], which is a system situated within an environment and consists of basic functions that sense the environment and act on it to achieve goals. However, to support the mechanism of curiosity, a standard agent is required to go beyond the basic functions and possess other important functions such as memory and learning. Memory stores an agent's previous experiences that are the basis for evaluating the novelty of new experiences. Learning allows an agent to improve its model of the world and make better predictions of the future outcomes, where the accuracy of predictions is the basis for evaluating the surprisingness of new experiences. According to Berlyne's theory [Berlyne (1960b)], both novelty and surprisingness are important collative variables that govern the curiosity arousal mechanism in human beings. Based on these functions, curious functions are introduced by transposing Berlyne's theory [Berlyne (1960b)] and Wundt's theory [Wundt (1874)] from psychology. Curious functions are the meta-level decision-making functions that regulate other functions such as learning and acting of the agent. Next, we will introduce the functions in the proposed computational model of curiosity for intelligent agents and their interactions between each other. We start with the model of a standard agent and then present the two important functions that are required to support curiosity: memory and learning. After that, we will introduce the curious functions in detail.\n4.1. Standard Agent\nThis section presents the basic functions that form a standard agent. The description of a standard agent begins with the environment with which the agent interacts. The internal components of a standard agent consist of a set of internal functions that map from one type of internal states to another type of internal states.\n4.1.1. Environment\nAccording to the classical definition given by Franklin and Graesser [Franklin and Graesser (1996)], an agent is a system situated within and a part of an environment that senses that environment and acts on it, over time, in pursuit of its own agenda and so as to effect what it senses in the future. Hence, an agent must reside in certain environment and act upon it to achieve goals. An agent's environment can be characterized as a set of possible environmental states, denoted by:\nwhere\nElements in the angle brackets '<>' represent different types of components that constitute the composite factor that appearing before '=' (this format will be followed throughout the book). In this case, only the environmental state is highlighted for the environment , which means agents only pay attention to environmental states (e.g., reinforcement learning agents). In other cases when agents also pay attention to other components of the environment, such as objects (e.g., exploratory robots), the environment can be denoted by where represents a set of environmental states and represents a set of objects. This can be customized for different types of agents. In this chapter, we focus on the environmental state for illustration.\n4.1.2. Internal Functions\nTo interact with the environment and achieve goals, a standard agent consists of internal functions that observe, deliberate, and then act upon the environment. In this section, the basic internal functions that form a standard agent will be presented.\nAn agent's ability to effect changes in the environment is determined by the range of actions that it can perform, denoted by:\nConsequently, an agent can be viewed as an abstract function:\nwhich maps environmental states to actions.\nThe behavior of an environment with respect to an agent's actions can be modeled as a function:\nwhich takes the current environmental state and an agent action , and maps them to a set of environmental states . If all the sets in the range of are singletons (i.e., the result of performing any action in any state is a set containing a single member that belongs to ), then the environment is deterministic, which means its behavior can be accurately predicted.\nThe abstract function of an agent can be decomposed into a set of internal functions, which will be discussed next.\n4.1.2.1. Perceiving\nThe function of perceiving captures an agent's ability to understand information about its environment. The perceiving function can be implemented in hardware agents (e.g., mobile robots) by a video camera or an infra-red sensor, or in software agents (e.g., email assistants) by system commands. An agent's ability to perceive the environment is characterized by a set of percepts:\nConsequently, the perceiving function is described by:\nwhich maps environmental states to the internal percepts of the agent.\n4.1.2.2. Decision-Making\nThe function of decision-making encompasses all of the high-level functions of an agent, including belief revision, goal setting, and plan setting. An agent's ability to take appropriate actions is determined by its ability to make decisions, which can be characterized by a set of decision states:\nConsequently, an agent's decision-making process can be represented by a function:\nwhich maps percepts to decision states.\n4.1.2.3. Acting\nActing is the process of translating high-level goals and plans lower-level commands that can be carried out by effectors. The acting process can be represented by a function:\nwhich maps decision states to actions.\n4.1.2.4. An abstract agent\nWith all the internal functions described above, a standard agent can be represented abstractly as a compound function:\nThe architecture for a standard agent is illustrated in Figure 4.1. The functions described above are illustrated by circular nodes. Solid arrows represent the flow of state variables between functions.\n4.2. Memory and Learning\nThe standard agent described above is a simple reactive agent that acts only on the basis of the current percept, ignoring the rest of the percept history. This type of agent only succeeds when the environment is fully observable. However, in most cases, the environment is only partially observable. For example, a robot's range of perception is limited by the sensors that it possesses. To tackle this problem, an agent usually maintains a model of the environment based on the previous perceptions. This model of the environment describes the part of the world that cannot be seen. However, the initial model may not always succeed when the environment reveals more of itself in front of the agent. This phenomenon requires the agent to be adaptive in order to become more competent than its initial knowledge alone may allow.\nThese requirements are also the important basis for an agent to become curious. For example, being able to remember past experiences allows the agent to evaluate the novelty of newly encountered stimulus; being able to adapt its initial model of the world allows the agent to make more accurate predictions of the future outcomes, which are important basis for evaluating the\nsurprisingness of new experiences. Here, both novelty and surprisingness are key collative variables that govern the curiosity arousal process [Berlyne (1960b)]. All these requirements point to two important abilities that are desirable by intelligent agents: memory and learning. Next, we will present these two functions and their interactions with other internal functions of an agent.\n4.2.1. Memory\nMemory stores representations of previous experiences, including a number of percepts, decision states, and actions, denoted by:\nwhere , , and represent the previous percepts, decision states, and actions, respectively.\nThese previous experiences, if organized structurally (e.g., neural networks, plan structures, concept maps, etc.), can form the agent's model of the environment. This model of the environment helps the belief revision, goal setting, and plan setting in the agent's decisionmaking process, which can be characterized by the following function:\nAn agent with memory is illustrated in Figure 4.2. In this figure, * refers to the previously experienced percepts, decisions, and actions. It can be seen that memory is located between the processes of perceiving, decision-making and acting.\n4.2.2. Learning\nLearning enables the agents to initially operate in unknown environments and become more competent than its initial knowledge may allow. The agent's ability to adapt is determined by its ability to update the model of environment stored in its memory and the high level functions in the decision-making process, which is represented by a set of learning rules (or states):\nThe learning rules are triggered depending on the current percepts and the previous decision states stored in memory. For example, prediction errors trigger learning, which are obtained by the differences between the predictions (previous decision states) and the true facts (current percepts). This process can be represented by the following function:\nOnce the learning rules are triggered (e.g., by newly emerged percepts), they can update the model of environment stored in the agent's memory. For example, a planning agent will\nincorporate a newly encountered event into its plan structure. This process can be represented by the following function:\nwhere is the updated memory.\nWhen the agent's decision is observed to be not optimal, the agent will trigger the learning rules that update the high level functions in the decision-making process to enhance its decisionmaking ability. For example, a trend analysis agent implemented by neural networks should update its node selection rules when its prediction differs significantly from the true facts. This process can be represented by the following function:\nwhich requires the current percepts and the previous decision states stored in memory to trigger learning rules and update the decision-making process.\nA learning agent is illustrated in Figure 4.3. It can be seen that the learning function takes the outputs of the perceiving function and the memory function as its inputs. The outputs of the learning function in turn influence the memory function and decision-making function.\n4.3. Curious Functions\nCurious functions model the agent's curiosity appraisal process. In order to simulate a humanlike curiosity appraisal process, our work is based on Berlyne's [Berlyne (1960b)] and Wundt's [Wundt (1874)] theories in psychology. According to Berlyne, curiosity is a process of stimulus selection, which is governed by a set of collative variables, such as novelty, surprise, uncertainty, conflict, and complexity. Wundt states that the level of curiosity simulation is closely related to two other emotions: boredom and anxiety. According to Wundt, only optimal stimulation level leads to curiosity whereas too less stimulation results in boredom and too much stimulation results in anxiety. Based on these theories, we derived a two-step process model of curiosity arousal, which has been discussed at the end of Chapter2. Following the two-step process model, we propose two curious functions for intelligent agents: stimulus detection and interest evaluation. Stimulus detection is based on Berlyne's theory and corresponds to the first step in\nthe two-step process model, i.e., evaluation of the stimulation level based on collative variables. Interest evaluation is based on Wundt's theory and corresponds to the second step in the two-step process model, i.e., evaluation of the interest level based on the principle of intermediate arousal potential. Next, we will introduce the two curious functions and then discuss their interactions with other internal functions of an agent in detail.\n4.3.1. Stimulus Detection\nAccording to Berlyne's theory [Berlyne (1960b)], curiosity can be viewed as a process of stimulus selection. The stimuli are characterized by a set of collative variables, which can be represented as follows:\nwhere and represent novelty, surprise, uncertainty, conflict, change, and complexity, respectively. The detection of these collative variables relies on several internal functions of the agent, including perceiving, memory, and decision-making. For example, novelty detection requires a comparison between the current stimuli (obtained by the perceiving function) and previous experiences (stored in memory). Surprise detection involves a comparison between the agent's prediction (generated by the decision-making function) and the true facts (obtained by the perceiving function). Uncertainty is triggered when a stimulus is difficult to classify (by the perceiving function). Conflict occurs when a stimulus triggers multiple decision states (by the decision-making function). Change happens when the state of a stimulus changes (observed by the perceiving function). Complexity is judged by the agent's perceiving function of how much variety or diversity in the stimulus pattern. In summary, the stimulus detection process can be characterized by an abstract function as follows:\nNote that it is not necessary to model a complete set of collative variables for an agent to be curious, as each collative variable can stand alone to trigger a person's curiosity. Hence, a subset of collative variables can always be chosen according to the agent's functional requirements.\n4.3.2. Interest Evaluation\nAccording to Wundt's theory [Wundt (1874)], the arousal of curiosity depends on the appropriate level of stimulation that can be induced by a stimulus. Curiosity arouses only if the stimulation is optimal, whereas too little stimulation results in boredom and too much stimulation results in anxiety. The set of emotions closely related to curiosity is represented by:\nwhere , , and represent anxiety, curiosity, and boredom, respectively.\nThe process of interest evaluation can be represented by an abstract function as follows:\nwhere returns the stimulation level induced by the collative variables, and the function maps the curiosity stimulation level to the interest level (indicated by emotions) based on the Wundt curve (Figure 2.1).\n4.3.3. Meta-level Decision-making\nThe two curious functions, i.e., stimulus detection and interest evaluation, are meta-level decision-making functions that interact with agents' learning function and decision-making function to enhance their performances.\nStimulus detection identifies a set of collative variables, all of which reflect certain knowledge gaps between the agent and the environment, which form the motivation for the agents to learn [Loewenstein (1994)]. Hence, the stimulus detection function outputs collative variables that can\nguide the learning function of an agent to improve its model of the environment. This process can be characterized by the following functions:\nThe stimulus detection function can also influence the agent's decision-making function based on different collative variables identified. For example, human beings will have different coping strategies when facing with novelty and conflict. Novelty often triggers a human being to observe the stimulus in order to understand it, whereas conflict often triggers a human being to think of some ideas to resolve the conflict. This process can be characterized by the following functions:\nInterest evaluation determines the agent's emotion states based on the level of stimulation. Emotion states often influences a person's learning ability. For example, a human being will refuse to learn when he/she is bored but learns much faster when he/she is curious. Hence, emotions can influence the agent's learning as follows:\nEmotions also influence a person's decision-making ability. For example, during a study in gambling decisions and job selection decisions, unhappy subjects were found to prefer highrisk/high-reward options unlike anxious subjects who preferred low-risk/low-reward options [Raghunathan and Pham (1999)]. Hence, emotions can influence the agent's decision-making as follows:\nCurious agent architecture is illustrated in Figure 4.4. The two functions: and highlighted with dashed box are the curious functions. It can be observed that stimulus detection requires the\noutputs of perceiving, memory, and decision-making functions, which outputs detected collative variables to trigger interest evaluation and influence the agent's learning and decision-making functions. The emotions generated through interest evaluation also influence the agent's learning and decision-making functions.\n4.4. Summary\nIn this chapter, we presented a generic computational model of curiosity for intelligent agents. This computational model consists of abstract functions and their interactions between each other, which allow different implementations in different types of agents. This computational model of curiosity is built based on the model of a standard agent, with two important functions introduced that are required to support curiosity appraisal: memory and learning. Based on these functions, two curious functions, i.e., stimulus detection and interest evaluation are proposed based on Berlyne's and Wundt's theories from psychology. The curious functions serve as metalevel decision-making functions that enhance an agent's learning ability and decision-making ability.\nCHAPTER 5 PROMISING APPLICATIONS FOR\nCOMPUTATIONAL CURIOSITY\n5.1. Machine Learning\nThe close-knit relationship between curiosity and human learning has inspired many researchers to devise computational forms of curiosity for machine learning systems, with the expectation to enhance learning capability and potentially drive them to evolve into autonomous intelligent agents. The study of computational curiosity in machine learning systems has some overlap with other concepts such as “active learning” and “intrinsically motivated learning”.\nActive learning, as the name suggests, attempts to machines “active” by allowing the learning system to select actions or make queries that influence what data to be added into its training set [Cohn et al. (1996)]. Active learning is especially useful when data are expensive or difficult to obtain. Curiosity can play a critical role in active learning by helping the system to determine which data are interesting. For example, Scott and Markovitch [Scott and Markovitch (1989)] introduced a curiosity drive into supervised learning systems to actively select the most informative samples for learning. Here, the system is continually directed towards regions with highest uncertainty, which is also a general principle followed by many other active learning algorithms [Fedorov (1972)]. Uğur et al. [Uğur et al. (2007)] infused curiosity into an SVMbased learning system to select interesting training data, which significantly reduces the number of training samples required to learn. Similarly, Pang et al. [Pang et al. (2009)] introduced curiosity into an LDA-based learning system.\nIntrinsically motivated learning advocates the development of “intrinsic motivations” for learning systems to achieve task-independent learning [Barto et al. (2004a); Singh et al. (2004)] or autonomous development [Oudeyer and Kaplan (2004)]. These learning approaches are gaining increasing popularity among AI researchers [Baldassarre (2011)]. Intrinsically motivated\nlearning often takes root in a reinforcement learning framework, where intrinsic motivations act as intrinsically generated rewards that are to be maximized. In human psychology, curiosity is known to be one of the most important intrinsic motivations related to learning. Hence, curiosity has often been adopted in intrinsically motivated learning algorithms. For example, Barto et al. [Barto et al. (2004a)] used Berlyne's theory as the psychological foundations to develop his intrinsically motivated learning algorithm. Schmidhuber [Schmidhuber (1991b, 1999, 2009b)] introduced artificial curiosity as intrinsic rewards for general learning algorithms. Oudeyer and Kaplan [Oudeyer and Kaplan (2004)] proposed an intelligent adaptive curiosity mechanism for intrinsically motivated robots.\n5.2. Robotics\nWith the attempt to design robots that can autonomously self-develop in a progressive manner, Oudeyer and Kaplan [Oudeyer and Kaplan (2004)] devised for them a mechanism that resembles human curiosity. This mechanism acts as an intrinsic motivation to motivate robots to explore into regions with new knowledge [Oudeyer and Kaplan (2007)], and endows them with the ability to adapt to new environments without prior knowledge or manual adjustment. With a similar goal of designing robots that can self-develop without an explicit teacher, Ngo et al. [Ngo et al. (2012)] applied Schmidhuber's principle of curiosity into a robot arm that enables robots to learn skills through playing. Pape et al. [Pape et al. (2012)] applied the same into a biomimetic robot finger for learning tactile skills.\nTraversibility affordance refers to the ability of robots to navigate through an environment with obstacles. This ability is highly dependent on the robot's current location, orientation, and the shape of objects in the environment. In situations where robots physically interact with the environment to explore and learn, assuming traditional reinforcement learning methods are applied, even simple tasks such as avoiding objects may require a large number of trials. This increases the risk of the robot being damaged during the exploration. To address this problem, Uğur et al. [Uğur et al. (2007)] simulated curiosity in robots to select informative training\nsamples, which can significantly reduce the number of interactions required with minimal degradations in the learning process.\nAnother problem in robotics is self-directed reconfiguration. Reconfigurable robots can rearrange their modules to achieve different structures, behaviors, and functions. Instead of looking into how robots can adapt in an unstructured environment, reconfigurable robots focus on adaptation to changes in their own structures and changes of goals when the actuator or effector of the robot changes. Merrick and Huntington [Merrick and Huntington (2008)] introduced curiosity into reconfigurable robots to select informative samples to learn, so that with fewer interactions, robots can still achieve better learning outcomes.\nOne of the most important sensory-motor problems for robots when interacting with an environment is to learn a mapping from the gaze space (the location of an object) to the reach space (the movement of arms to grasp the object) in response to changes in the environment (camera replacement or changes in the physical environment) without manual recalibration of the hardware. To address this problem, Karaoguz et al. [Karaoguz et al. (2011)] devised a mechanism of curiosity that drives the exploration into learning spaces where a proper level of complexity is associated with a particular level of capability. With this mechanism, robots can concentrate on highly interesting areas that are neither fully explored nor pure noise. In addition, the mechanism can successfully direct robots' attention to regions where changes have occurred.\nExploration in extreme environments can be a dangerous task for humans. Artificial agents, especially in the form of robots, have been a good substitute for humans to undertake such tasks. Exploration of unknown environments has been an active research field in domains such as planetary exploration, meteorite searches in Antarctic, volcano exploration, and map building of interiors, etc. [Moorehead et al. (2001); Burgard et al. (2002); Macedo and Cardoso (2005)]. In human beings, exploration is often driven by curiosity, a motivating force for attention focus, determination of interest, and gathering knowledge. Based on these observations, researchers devised artificial forms of curiosity for agent to make proper decisions in unknown\nenvironments. For example, Macedo and Cardoso [Macedo and Cardoso (2001, 2002, and 2005)] modeled human forms of surprise and curiosity in case-based reasoning frameworks to guide agent's exploration in unknown environments populated with objects. Graziano et al. [Graziano et al. (2011)] also discussed the application of computational curiosity to solve autonomous exploration problems.\nTo summarize, computational curiosity has the potential to contribute to various aspects of robotic systems, such as selective attention, autonomous learning, and self-direction. Numerous studies on computational curiosity are continuously emerging in this field [Stojanov et al. (2006); Macedo (2010); Oudeyer (2012)].\n5.3. Artificial Creativity\nComputational creativity explores the possibility of machines capable of generating creative artifacts that are commonly defined as being previously unknown, useful and surprising [Boden (2009)]. Computational curiosity has been studied in machines to demonstrate creative behaviors. Based on Csikzentmihalyi's system view of creativity, Saunders [Saunders (2007)] postulated two levels of creativity: the individual level and the society level. According to Saunders, there are two questions to be answered at the individual level of creativity: (1) how to evaluate creativity, and (2) how to produce creativity. Saunders and Gero [Saunders and Gero (2004)] argued that curiosity can be used to guide problem solving by finding interesting design solutions as well as discovering interesting design problems. Curious design agents were proposed to evaluate the interestingness (creativity) of designs based on novelty. Research of curiosity at the society level looks into the socio-cultural influence of curiosity on creativity and the acceptance of creative works by other individuals. Based on previous works, Saunders [Saunders (2011)] studied the society level of creativity by creating a virtual society populated with curious design agents. Simulation results showed that the artificial society exhibited certain similar behaviors as in real human societies.\nSchmidhuber [Schmidhuber (2006, 2007, 2009b)] explored the relationship between creativity, artists, humor and fun. He argued that art and creativity can be seen as the by-products of curiosity rewards. He further argued that the optimal curious reward framework can be sufficiently formal and precise to allow the implementation on computers and developmental robots. Schmidhuber [Schmidhuber (2006)] generalized his simple principle of curiosity to form artificial creativity: “the current compressor of a given subjective observer tries to compress his history of acoustic and other inputs where possible\" and “the compression progress becomes the wow-effect or intrinsic reward for the 'creative' action selector, which is thus motivated to create more data that allows for more wow-effect\". Later, Schmidhuber [Schmidhuber (2013)] proposed a greedy but practical implementation of the basic principle of creativity: POWERPLAY, which can automatically inventor discover problems to train a general problem solver from scratch. In his survey, Schmidhuber [Schmidhuber (2009a)] drew a comparison between his formal theory with less formal works in aesthetics theory and psychology.\n5.4. Games\nWith the advances in computer technologies for graphics, processing power, and networking, virtual worlds are emerging as platforms for massive online games. Merrick and Maher [Merrick and Maher (2009)] highlighted the need for new non-player characters to cope with the increasing complexity and functionality of multi-user virtual worlds. They argued that the behavioral traits of humans and animals generated by curiosity can also advance the performance of artificial agents when dealing with complex or dynamic environments, where only limited information is available and the information changes over time. To cope with the difficulty of predefining task specific rules or environment-specific motivation signals, Merrick et al. [Merrick et al. (2008)] introduced a mechanism of curiosity into non-player characters, which enables them to direct attention to relevant information and be curious about changes in the environment. Simulation results showed that the curious motive led the non-player characters to demonstrate higher variety and complexity in behavior patterns [Maher et al. (2008)].\nWhile most of the works that apply computational intelligence to games focused on the generation of behaviors, strategies, or environments, Togelius and Schmidhuber [Togelius and Schmidhuber (2008)] looked at the very heart of games: the rules that define a game. They proposed automatic game designs based on Koster's theory of fun and Schmidhuber's theory of artificial curiosity, where Schmidhuber's theory of curiosity is a coarse approximation of Koster's theory of fun [Koster (2005)], i.e., a game is fun if it is learnable but not trivial.\n5.5. Affective Computing\nAffective computing is computing that relates to, arises from, or deliberately influences emotion or other affective phenomena [Picard (1997)]. It requires multidisciplinary knowledge such as psychology, cognitive science, computer science, and engineering. Affective computing is gaining rapid popularity and has great potential in the next generation of human-computer interfaces. Curiosity is closely related to emotional constructs such as “fear\", “pleasure\", “boredom\", and “anxiety\" [Loewenstein (1994)]. Computational curiosity offers a new dimension from which emotions can be appraised, apart from the consequences of events, the actions of agent, and the characteristics of objects [Ortony et al. (1988). The consideration of computational curiosity in affective modeling is especially interesting in learning contexts and social contexts, where curiosity-related emotions significantly influences the believability and performance of emotional agents.\n5.6. Artificial Companions\nArtificial companions, designed to develop a close and long-term human computer relationship, have emerged in the latter half of the 2000s. Two key words, close and long-term, have been guiding the development in this field. Researchers are working on the design of believable human-computer interfaces to provide close interactions (e.g. embodied conversational agent) and robust memory architectures to sustain long-term relationships [Bickmore and Picard (2005); Wilks (2010); Wu et al. (2012b)]. Computational curiosity can be an important dimension to be studied in artificial companions for enhancing both the closeness of interactions and the\npossibility for long-term relationships. The potential for computational curiosity in creating a closer human-computer relationship draws evidence from psychological findings that curiosity plays an important role in promoting the intimacy of interpersonal relationships in social context. A curious artificial companion can be more responsive; may infuse more novel twists of excitement into interactions, and might induce a natural flow of engagement between the interaction discourses. As for promoting long-term relationships, curiosity can be a motivational force to learn more about the partner and develop a historical knowledge base through interactions. A curious artificial companion may be more interested to know the partner; may be more inquisitive to novel changes of the partner; and may incorporate information of the partner into part of the cognitive development of the companion itself.\n5.7. Persuasive Technology\nPersuasive technology deals with the use of computing systems, devices or applications to gradually change a person's attitudes or behavior [Fogg (2002)]. This technology has the potential to bring constructive changes in health science, safety and education. Examples include a digital doll to persuade kids to eat fruit and vegetables, and a virtual coach to persuade the elderly to exercise more [Fogg (1999)]. Understanding users' curiosity and properly infusing curiosity stimuli into the human-computer interaction process can potentially help intelligent agents achieve persuasive goals. For example, if a sales agent can successfully elicit the customer's curiosity in a product; there will be a higher chance for this product to be sold. Curiosity has been harnessed to “persuade\" programmers to increase the correctness in end-user programming [Wilson et al. (2003)].\n5.8. Agent Negotiation\nNegotiation is a process that involves two or more parties to reach an agreement. This mechanism has received increasing attention in multi-agent systems for managing inter-agent dependencies in real time [Jennings and Wooldridge (2002)]. Traditional implementations of negotiation process focused on its rational aspects to build consensus. Recently, [Broekens et al.\n(2010)] argued that negotiation is a multifaceted process in which affect plays an important role. Computational curiosity has the potential to influence the human-agent negotiation process by promoting positive emotional states, responsiveness and engagement. Enabling a negotiation agent to understand the curiosity exhibited by a user may allow it to notice the unusual, surprising, or conflicting information offered by the user and reach agreements that are more socially optimal. A negotiation agent that can adapt its decision-making based on the users' curiosity may improve its chance of gaining more utility out of the final agreement.\n5.9. Trustworthy Computing\nAnother important issue in multi-agent systems is trust management. It is useful in open and dynamic systems such as peer-to-peer systems, semantic Web, ad hoc networks, and ecommerce, etc. [Ramchurn et al. (2004); Yu et al. (2010, 2012)]. Similar to negotiation, trust management is also closely related to emotion states [Dunn and Schweitzer (2005); Schoorman et al. (2007)]. The motivational role of curiosity in building interpersonal relationships can contribute to the trust building between strangers [Kashdan et al. (2011)]. Computational curiosity can potentially enhance an agent's judgment by making the agent more sensitive to novel, surprising, conflicting, and uncertain information presented in the environment.\nCHAPTER 6 A CURIOUS EXTREME LEARNING\nMACHINE\n6.1. Introduction\nIn this chapter, we focus on realizing the generic computational model of curiosity (Chapter 4) in a type of neural learning agent: an extreme learning machine (ELM) based classifier.\nAn extremely fast learning neural algorithm referred to as extreme learning machine (ELM) has been developed for single-hidden layer feed-forward networks (SLFNs) by Huang et al. [Huang et al. (2006a,b)]. The essence of ELM is that the hidden layer of SLFNs need not be tuned [Huang et al. (2011)]. ELM randomly assigns hidden neuron parameters and finds the output weights analytically. It has been shown to generate good generalization performance at extremely high learning speed [Huang et al. (2006a, b, c); Liang et al. (2006b)] and has been successfully applied to many real world applications [Huang et al. (2006c); Liang et al. (2006b); Xu et al. (2006); Yeu et al. (2006)].\nAlthough ELM has shown advanced generalization performance with extremely high learning speed, several major issues still remain in ELM:\n1. Manually set the number of hidden neurons: The number of hidden neurons needs to be set a priori to training [Feng et al. (2009)]. The number of hidden neurons is usually chosen by trialand-error.\n2. Fixed structure: The network structure is fixed once the number of hidden neurons is set [Rong et al. (2008)]. It cannot evolve, i.e., add or delete hidden neurons, based on the training data.\n3. Randomization effect: The random assignment of hidden neuron parameters induces high\nrandomization effect in the generated results.\nTo address issue 1), several algorithms have been proposed, such as incremental ELM (I-ELM) [Huang and Chen (2007)], enhanced incremental ELM (EI-ELM) [Huang and Chen (2008)], pruning ELM (P-ELM) [Rong et al. (2008)], optimally-pruned ELM(OP-ELM) [Miche et al. (2008)], and error minimized ELM (EM-ELM) [Feng et al. (2009)]. However, all these algorithms can either add neurons (I-ELM, EI-ELM, EM-ELM) or delete neurons (P-ELM, OPELM) without being able to adjust network structure based on the incoming data. In other words, they lack the evolving capability. Recently, a meta-cognitive ELM (McELM) has been proposed [Savitha et al. (2014)], which addresses issue 1) and partially issue 2). McELM can decide network structure based on the training data, but it can only add neurons without pruning capability. To our knowledge, few works have been done towards issue 3).\nTo address all the three issues mentioned above, we propose a curious extreme learning machine (C-ELM) algorithm for classification problems [Wu and Miao (2015)]. It is a psychologically inspired algorithm based on the theory of curiosity [Wu and Miao (2013a)]. In psychology, curiosity is commonly known as the important intrinsic motivation that drives human exploration and learning [Loewenstein (1994)]. The psychological concept of curiosity has been applied in many computational systems to enhance their learning capability (e.g., intrinsically motivated reinforcement learning) [Barto et al. (2004a); Schmidhuber (2009a)] and believability (e.g., curious companions) [Wu et al. (2012a); Wu and Miao (2013b); Wu et al. (2014)]. This is the first attempt to introduce curiosity in an ELM framework.\nC-ELM is inspired by the psychological theory of curiosity proposed by Berlyne [Berlyne (1960b)]. Berlyne interpreted curiosity as a process of stimulus selection, i.e., when several conspicuous stimuli are introduced at once, to which stimulus will human respond. He identified several key collative variables, e.g., novelty, uncertainty, conflict, and surprise that govern the stimulus selection process. Based on this theory, C-ELM classifier treats each training data as a\nstimulus and decides its learning strategy based on the appraisal of collative variables. There are three learning strategies for C-ELM classifier: neuron addition, neuron deletion, and parameter update.\nWhen a new neuron is added, conventional incremental ELM algorithms will randomly assign the center and impact factor of the RBF kernel (other kernels such as linear kernel can also apply) in the new neuron. However, random center selection may require more number of hidden neurons to p-proximate the decision function accurately [Suresh et al. (2008)]. Hence, C-ELM uses data-driven center selection which adopts the current training data that triggers the neuron addition strategy as the center of the new neuron. It removes partially the random effect of the traditional ELM algorithms. Data-driven center selection also allows the class label of the new neuron to be apparent, which enables further analysis of the hidden neurons. During neuron deletion, the most conflicting neuron for the current training data is removed from the network. In literature, various neuron deletion schemes for ELM have been proposed such as pruning based on relevance [Rong et al. (2008)] or based on leave-one-out cross-validation [Miche et al. (2008)]. These techniques, although effective, might render the system slow. Hence, we propose the neuron deletion strategy based on conflict resolution, which helps the system attain fast and efficient convergence. The parameter update is conducted using recursive least squares method.\nIn the rest of this chapter, we will present the detailed definition of the CELM classifier and evaluate its performance against other popular classifiers on benchmark data sets.\n6.2. Curious Extreme Learning Machine Classifier (C-ELM)\nIn this section, we provide a detailed description of the C-ELM classifier. The goal of C-ELM classifier is defined as follows:\nGiven: a stream of training data , where\nis a M-\ndimensional input vector of the th input data, is its class label, and represents\nthe total number of distinct classes. The coded class label\nis obtained by\nconverting the class label ( ) as follows:\n{\nFind: a decision function that maps the input features ( ) to the coded class labels ( ), i.e.,\n, as close as possible.\nTo solve this problem, C-ELM employs two major components: an internal cognitive component which is a unified single layer feed-forward neural network (SLFN) and a curiosity appraisal component that consists of curious functions that regulate the extreme learning process.\n6.2.1. The Internal Cognitive Component: SLFN\nThe internal cognitive component of the C-ELM is an SLFN with input neurons, hidden neurons and output neurons. For RBF hidden neuron with activation function\n(e.g., Gaussian), the output of the th hidden neuron with respect to the input is given by:\n( || ||)\nwhere and are the center and impact factor of the th RBF neuron. indicates the set of all positive real values.\nThe predicted output for the input is given by:\n ̂  ̂  ̂\n ̂\nHere, the output of the th neuron in the output layer is given by:\n ̂ ∑\nwhere is the output weight connecting the th hidden neuron to the th output neuron. The output for a chunk of t input data can be written by:\n ̂\nwhere is the hidden layer output matrix and is the weight matrix connecting the hidden neurons to the output neurons as shown below:\n[\n]\nand\n[\n]\nWith the cognitive component of C-ELM described above, next, we will introduce the curious functions that regulate the extreme learning process.\n6.2.2. Curious Functions\nC-ELM employs an intrinsically motivated learning paradigm transposed from the psychological theory of curiosity proposed by Berlyne [Berlyne (1960b)]. Learning is regulated based on the curiosity appraisal of input data.\n6.2.2.1. Stimulus Selection\nFor each input data, the stimulus selection is governed by four collative variables, i.e., novelty, uncertainty, surprise, and conflict. In this section, we will introduce the definitions of the four collative variables in C-ELM.\nNovelty: Novelty reflects how much the input data differs from the network's current knowledge. In kernel methods, spherical potential is often used to determine the novelty of data [Subramanian et al. (2013)]. The spherical potential of an input data is defined by (a detailed derivation can be found in [Subramanian et al. (2013)]):\n∑\nA higher potential indicates that the input data is more similar to the existing knowledge, while a smaller potential indicates that the input data is more novel. Hence, the novelty of an input data is determined by:\n∑\nUncertainty: Uncertainty reflects how not confident the network is in its predictions. The confidence of a network is often measured by the posterior probability of the prediction. It has been proven theoretically that hinge-loss function can accurately estimate the posterior probability for a classification problem [Zhang (2004)]. Hence, we use the truncated hinge loss\nerror (\n) [Suresh et al. (2008)] to measure the prediction error,\nwhere each element is defined by:\n{\n ̂\n( ( ̂\n) )\nWith the truncated hinge-loss error, the posterior probability of input belonging to class is given by:\n|\nSince uncertainty measures how not confident a network is in its predictions, we define uncertainty of the prediction to an input data by:\n ̂|\nwhere  ̂ is the predicted class for .\nConflict: In psychology, conflict occurs when a stimulus arouses two or more incompatible responses in an organism [Wu and Miao (2013a)]. The degree of conflict depends on the competing strengths of those incompatible responses. For a classifier, conflict can be reflected by the competing strengths of the most _red two output neurons.\nGiven an input , let  ̂ and  ̂ be the outputs of the most fired output neuron and the second\nmost fired two output neurons, respectively. The more closer  ̂ is to  ̂ , the higher competing\nstrength is between the two output neurons, which indicates a higher conflict between the network's decisions. Hence, the conflict F induced by an input is defined by:\n{\n| ̂  ̂ | | ̂  ̂ |  ̂  ̂\nSurprise: In psychology, surprise indicates a violation of expectation [Wu and Miao (2013a)]. For a classifier, surprise occurs when the predicted output differs from the true class label. The degree of surprise is determined by prediction errors for both the true class and the predicted class. As we adopt hinge-loss error in this work to measure prediction error, the surprise S induced by an input is defined by:\n{ |\n̂ |  ̂\nwhere  ̂ and represent the predicted class and the true class, respectively; and is the hingeloss error. It can be analyzed that all the four collative variables are within the range of [0, 1].\nThe collative variables determine the level of curiosity arousal and the learning strategy selection. With the collative variables defined as above, we will introduce the learning strategies in the following section.\n6.2.2.2. Learning Strategies\nC-ELM has three learning strategies: neuron addition, neuron deletion, and parameter update. CELM begins with zero hidden neurons, add or delete hidden neurons and update parameters of the existing neurons to achieve an optimal network structure with optimal parameters. The decision on whether to update network structure or update parameters is made based on the appraisal of collative variables. Intuitively, higher values of collative variables induce a higher level of curiosity towards the input data, which require more efforts in learning, i.e., updating network structure, to incorporate the new knowledge; otherwise, simply update parameters of the existing neurons to reinforce the 'familiar' knowledge. Next, we will introduce the three learning strategies of C-ELM in detail.\nNeuron Addition Strategy: Intuitively, for an input data, if novelty is high and uncertainty is high and surprise is high, it indicates that a misclassification (i.e., surprise high) with high uncertainty in its prediction (i.e., uncertainty high) is caused by the newness of the knowledge (i.e., novelty high). In this case, the network should add new neurons to capture this new knowledge. Hence, given an input , the neuron addition condition is:\n>\nwhere , , and are neuron addition thresholds for novelty, uncertainty, and surprise,\nrespectively. If these parameters are chosen close to 1, then very few input data can trigger the neuron addition strategy and the network cannot approximate the decision function accurately. If these parameters are chosen close to 0, then many input data can trigger the neuron addition\nstrategy, leading to poor generalization ability. In general, is chosen in the range of [0.1,\n0.5], is chosen in the range of [0.1, 0.3], and is chosen in the range of [0.2, 0.9].\nA typical ELM randomly chooses hidden neuron parameters and finds the output weights analytically. However, random exploration of the feature space may need more hidden neurons to accurately approximate the decision function. In C-ELM, we propose data-driven center selection for the hidden neurons without compromising the extreme learning capability. When a new neuron is added, instead of randomly assigning the center , we assign the input features of the current input data as the center, i.e., = . Since the center selection is data-driven, we can label the class of the new neuron using the target value of the input data, i.e., . Datadriven center selection allows fast hidden neuron clustering using their class labels and provides class specific information when deleting neurons. The values of the impact factors in the hidden neurons are randomly assigned. Hence, with the new hidden neuron, the dimension of the hidden layer output matrix increases from to . The target values of the input data is represented by:\n[ ]\nThe output weight for can be analytically found by:\nwhere is the Moore-Penrose generalized inverse of the hidden layer output matrix .\nNeuron Deletion Strategy: Intuitively, for an input data, if surprise is high and conflict is high and novelty is low, it indicates that a misclassification (i.e., surprise high) occurs for a familiar stimulus (i.e., novelty low) due to high competing strengths between two decisions (i.e., conflict). In this case, the network should adjust its decision-making by strengthening the correct\ndecision and weakening the wrong decision, i.e., deleting the most contributing neuron in the wrong class. Hence, given an input , the neuron deletion condition is:\n>\nwhere , , and are neuron deletion thresholds for surprise, conflict, and novelty,\nrespectively. When and are chosen close to 1 and is chosen close to 0, then very few\ninput data can trigger neuron deletion, leading to poor generalization ability. When and are\nchosen close to 0 and is chosen close to 1, then many input data can trigger neuron deletion\nand the network cannot approximate the decision function accurately. In general, is chosen in\nthe range of [0.2, 0.9], is chosen in the range of [0.1, 0.3], and is chosen in the range of\n[0.1, 0.8]. When neuron deletion is triggered, C-ELM will remove the most fired hidden neuron\nbelonging to the predicted class:\n| ( )\nAfter the th neuron is removed, the network will re-calculate the output weight with the\ninput data.\nParameter Update Strategy: When both the neuron addition strategy and the neuron deletion strategy are not triggered, it indicates that the new input data is a 'familiar' one. Hence, the network will update the output weight using recursive least squares to reinforce the familiar knowledge. For the new input data , let the partial hidden layer output be represented by\nThe output weights are updated according to [Liang et al.\n(2006a)] by:\nwhere\n6.3. Performance Evaluation of C-ELM\nThe performance of C-ELM is evaluated on the benchmark problems described in Table 6.1 from the UCI machine learning repository, which contains four multi-category classification problems (vehicle classification, iris, wine, and glass identification) and four binary classification problems (liver disorder, PIMA, breast cancer, and ionosphere). The performance of CELM is evaluated in comparison with other popular classifiers such as SVM, ELM and McELM. The results of SVM, ELM and McELM are reproduced from [Savitha et al. (2014)]. For simulating the results of C-ELM, MATLAB 2014b with 3.2 GHz and 16 GB ram was used. The parameters were optimized using grid search.\nThe performance of C-ELM is measured against other popular classifiers using two types of performance measures: average classification accuracy and overall classification accuracy. When the number of samples in each class is highly unbalanced, the average classification accuracy tends to yield more useful information.\nAverage classification accuracy: The average classification accuracy is defined by:\n∑\nwhere is the number of data in class that have been correctly classified, and is the total number of data in class . It reflects the average ratio of correctly classified data in each class.\nOverall classification accuracy: The overall classification accuracy is defined by:\n∑\nwhere is the total number of data in the testing data set. It reflects the overall ratio of correctly classified data in the whole testing data set.\n6.3.2. Performance Study on Multi-category Classification Problems\nThe performance of the C-ELM on multi-category benchmark classification problems is shown in Table 6.2. It can be observed from Table 6.2 that the generalization performance of C-ELM is better than other classifiers used for comparison on all the multi-category classification problems. Also, the number of hidden neurons added during the evolving process is comparable with other algorithms. For example, C-ELM selected 140 hidden neurons with 6 times neuron deletion for Vehicle classification problem, 6 hidden neurons for Iris problem, 8 hidden neurons for Wine problem, and 52 hidden neurons with 8 times neuron deletion for Glass identification problem. Another advantage of C-ELM in comparison with other self-regulated learning algorithms such as McELM is that it takes a substantially small amount of time for training. For example, McELM takes 40 seconds to train the Vehicle classification problem whereas C-ELM only takes 15.2 seconds. Hence, it shows that C-ELM achieves better performance than other classifiers on multi-category classification problems due to the intrinsically motivated learning mechanism of curiosity.\n# support vectors. Number of neuron deleted: (b) 6 (c) 0 (d) 0 (e) 8.\n6.3.3. Performance Study on Binary Classification Problems\nThe performance of C-ELM on three binary classification problems is shown in Table 6.3. Table 6.3 shows that C-ELM achieves better generalization performance than other classifiers used for comparison on all the binary classification problems. Also, the total number of hidden neurons added during the evolving process is comparable with other algorithms. For example, C-ELM requires 31 hidden neurons for Liver disorder problem, 33 hidden neurons for PIMA problem, 9 hidden neurons for Breast cancer problem, and 17 hidden neurons for the Ionosphere problem. For binary classification problems, the training time of C-ELM is comparable with other selfregulated learning algorithms such as McELM. For example, it requires 0.73 seconds for C-ELM and 0.95 seconds for McELM to train the Liver disorder problem. Hence, it shows that C-ELM achieves better generalization ability than other classifiers on binary classification problems\nwithout compromising the extreme leaning ability of ELM, due to the intrinsically motivated learning mechanism of curiosity.\n# support vectors. Number of neuron deleted: (b) 0 (c) 0 (d) 0 (e) 0.\n6.4. Summary\nIn this chapter, we have presented a curious extreme learning machine (CELM) classifier, which is a neural learning agent, based on the generic computational model of curiosity. C-ELM treats each input data as a stimulus for curiosity and performs curiosity appraisal towards each input data based on four collative variables: novelty, uncertainty, conflict, and surprise. Three learning strategies can be chosen from based on the curiosity appraisal results, including neuron addition, neuron deletion, and parameter update. C-ELM enhances traditional ELM algorithms with the evolving capability, which determines optimal network structure dynamically based on the training data. Also, C-ELM reduces partially the random effect of the traditional ELM algorithm by selecting RBF centers based on data instead of random assignment. Moreover, C-ELM\nemploys a novel neuron deletion strategy which is based on conflict resolution. Empirical study of C-ELM shows that the proposed approach leads to compact network structures and generates better generalization performance with fast response, comparing with traditional ELM and other popular classifiers.\nCHAPTER 7 A CURIOUS RECOMMENDER AGENT\n7.1. Introduction\nIn this chapter, we focus on the domain of recommender systems and present a curiosity-driven recommendation algorithm that realizes the generic computational model of curiosity (Chapter 4) in another type of intelligent agents: the social recommender agents.\nIn the current age of information overload, recommender system has become an indispensable technique for filtering and recommending online information. Due to their effectiveness in helping users filtering through the enormous number of items and in helping enterprisers increasing their sales, recommender systems have been successfully adopted by a number of industrial companies, including but not limited to Amazon, Netflix, Yahoo!News, Apple iTunes, etc.\nAs highlighted in [Resnick and Varian (1997)], the ultimate goal of a recommender system is to suggest particularly interesting items, in addition to indicating those that should be filtered out. Traditional recommender systems are built based on a general consensus that user preferences reflect their underlying interests. Hence, various collaborative filtering techniques [Sarwar et al. (2000)] have been proposed to discover items that best match users' preferences. However, determining interestingness based on user preferences alone is far from sufficient. According to the psychology of interest [Silvia (2008)], the appraisal of interestingness in human beings is closely related to curiosity. Instead of focusing on a person's preferences, curiosity is more related to the novelty and surprisingness in the environment. In this work, we take a new angle to look at the interestingness of recommendation and introduce a novel dimension of social information into the traditional recommender systems: social curiosity.\nIn real life, it is a commonly observed phenomenon that a person gets curious about the surprising behaviors of his/her friends. For example, Alice knows that her friend Bob always\nhates horror movies, and the incidence that Bob gives a high rating to a horror movie would interest Alice. In order to find out why Bob gave this surprising rating, Alice may be driven by curiosity to watch this horror movie. This phenomenon is generally known as social curiosity in human psychology. It is the desire to acquire new information about how other people behave, think, and feel [Renner (2006); Wu and Miao (2013a)]. Based on this theory, an item rated by a user's friends can become a recommendation candidate according to how surprising those friends' ratings are for this item.\nMotivated as above, we propose a social curiosity inspired recommender system. On top of user preferences, the interestingness of an item is evaluated based on user curiosity as well. The major contributions of this work are summarized as follows. Firstly, we identify a novel dimension of social information for recommender systems: the social curiosity. Secondly, we build a general and parameter-free model for measuring user curiosity in the social contexts. This model takes into consideration the different responses given by a user to different friends' surprising ratings. We also propose and compare three strategies for evaluating user curiosity when multiple friends give surprising ratings to the same item. Thirdly, the model is comprehensively studied with two large scale real world datasets: Douban and Flixster.\nThe experiment results show that social curiosity significantly improves recommendation diversity and coverage, while maintaining a sufficient level of accuracy. To the best of our knowledge, this is the first work to explore social information for enhancing recommendation diversity and coverage in recommender systems. In the rest of this chapter, we will implement the proposed computational model of curiosity in recommender agents and conduct experimental studies to analyze the effects brought by curiosity.\nCHAPTER 8 A CURIOUS VIRTUAL PEER LEARNER\n8.1. Introduction\nThis chapter focuses on developing a curious peer learner that realizes the generic computational model of curiosity to enhance believability. With the advances in computer graphics, communication technologies and networking, virtual worlds are rapidly becoming part of the educational technology landscape [Wiecha et al. (2010); Wu et al. (2013a)]. Dede [Dede (2009)] suggests that the immersive interfaces offered by virtual worlds can promote learning, by enabling the design of educational experiences that are challenging or even impossible to duplicate in real world. In recent years, the usage of virtual worlds within the educational context is growing quickly. The New Media Consortium (NMC) Annual Survey on Second Life (SL) received 170% increase in response rate between 2007 and 2008. They also found that many of the educators, who earlier used the existing SL, have started creating their own virtual worlds in less than a year's time [Harris and Rea (2009)].\nVirtual Singapura is a Virtual Learning Environment (VLE) designed to facilitate the learning of plant transport systems in lower secondary school. It has been employed in various studies, such as design perspectives for learning in VLE, pre-service teachers' perspectives on VLE in science education, productive failure and impact of structure on learning in VLE, slow pedagogy in scenario-based VLE, and what students learn in VLE, etc. [Jacobson et al. (2010); KennedyClark (2011, 2009); Kennedy-Clark and Thompson (2011); Tanti and Kennedy-Clark (2010)]. Till date, over 500 students in Singapore and over 300 students in Australia have played Virtual Singapura. During the field studies of Virtual Singapura, several issues with learning in VLE have been observed. First, students tend to spend more time exploring the landscape of the virtual world rather than concentrating on the learning content. Second, some low-functioning students studying alone in VLE often get confused or stuck, and require constant guidance from teachers or game designers to move forward.\nBased on these observations, we propose a virtual peer learner to reside in VLE and accompany students to learn. The idea is derived from the common educational practice of peer learning, where students learn with and from each other without the immediate intervention of a teacher [Boud et al. (2001)]. Benefits of a peer learner include: a peer learner can present _learning triggers\", that are interactions or experiences causing students to try new things or to think in novel ways; bi-directional peer relationships can facilitate professional and personal growth; and tapping into a learner's own experience can be both affirming and motivating [Eisen (2001)]. Hence, a virtual peer learner has the potential to engage students and motivate them to spend more time on the learning content. Also, a virtual peer learner can potentially help lowfunctioning students to think and learn better in VLE.\nA key design issue for such virtual characters is their believability [Johnson et al. (2000)]: they need to give the users an impression of being lifelike and believable, producing behaviors that appear to the users as natural and appropriate. In order to design a virtual peer learner that can emulate a real student and behave naturally in the learning process, a biologically inspired approach is necessary. In human psychology, studies have shown that curiosity is an important motivation that links cues reflecting novelty and challenge with natural behaviors such as exploration, investigation and learning [Kashdan and Steger (2007)]. In Reiss's [Reiss (2000)] 16 basic desires that motivate our actions and shape our personalities, curiosity is defined as “the need to learn\". Attempts to incorporate curiosity into Artificial Intelligence find curious machines have advanced behaviors in exploration, autonomous development, creativity and adaptation [Macedo and Cardoso (2005); Merrick (2008b); Saunders (2007); Scott and Markovitch (1993)]. However, as a basic motivation that drives the learning behaviors of human beings [Reiss (2000)], the role of curiosity in a virtual peer learner has not yet been explored. This creates a challenge for introducing curiosity into virtual peer learners and studying its impact on their learning behaviors. In the rest of this chapter, we will tackle this challenge by implementing the proposed computational model of curiosity in virtual peer learners and conducting experimental studies to analyze the effects brought by curiosity.\nCHAPTER 9 A CURIOUS VIRTUAL LEARNING\nCOMPANION\n9.1. Introduction\nIn the previous chapter, we presented a virtual peer learner which realizes the generic computational framework of curiosity. Virtual peer learners are background characters to enrich the virtual learning environment, which do not directly interact with users. However, many educational practices are instantiated through the interactions between teachers and students or between peer learners [Brophy and Good (1974); Webb (1989)]. Hence, a virtual learning companion that can interact with the users would be interesting to enhance their learning experiences. In this chapter, we focus on developing a virtual learning companion which realizes the generic computational framework of curiosity to provide more meaningful interactions with the users. Teaching and learning are highly social activities [Kim (2004)]. With the goal to bring a social context into Virtual Learning Environment (VLE), a growing interest has been shown in designing virtual learning companions that adopt a peer metaphor to simulate peer interactions. Virtual learning companions allow human learners to take advantage of the cognitive and affective gains of human peer-mediated learning in a VLE [Kim (2004)].\nThe general role of a virtual learning companion is illustrated in Figure 9.1. It can be shown from this figure that a human learner is the main actor in a VLE, who acts upon the environment and learns from it. A virtual learning companion performs as a peer who observes the human learner's actions and their effects, i.e., the environmental changes. Based on the observations, the virtual learning companion performs cognitive and affective reasoning to provide appropriate peer-like interactions with the human learner. Curiosity is an emotional motivation related to exploratory behaviors such as learning, investigation, and exploration, which drives human beings to ask questions and explore for answers. According to the information gap theory by\nLoewenstein [Loewenstein (1994)], curiosity can be viewed as arising when attention becomes focused on a gap in one's knowledge. Hence, modeling human-like curiosity in a virtual learning companion may allow the companion to discover knowledge gaps and ask relevant questions. These questions can add new ingredients into the interactions provided by the companion, which may help human learners notice the weakness in their knowledge structure and motivate them to actively explore the VLE. However, curiosity has not been studied as a key personality trait in existing virtual learning companions, which creates a challenge for introducing this novel characteristic into such agents and studying the impact brought by it. In the rest of this chapter, we will tackle this challenge by implementing the generic computational framework of curiosity in virtual learning companions and conducting field studies with human users to analyze how an agent with curiosity will impact the human users' learning experience in a human-agent interaction context.\nCHAPTER 10 OPEN PROBLEMS\n10.1. Evaluation of Simulation\nMost of the current computational models of curiosity adopt a heuristic approach for the evaluation of stimulations. This is often done based on algorithmic characteristics and goals in machine learning. These models advance the performance of machine learning systems in learning and exploration. However, they have difficulties supporting humanoid agents to evaluate curiosity stimuli in complex environments such as computer-based education, ecommerce, and teleconference. Some models have started from a psychological theory and evaluated stimulation levels based one collative variable or a subset of collative variables. As of yet, how the collative variables affect the level of stimulation, individually or collectively, has not been studied. Both qualitative and quantitative analysis of collative variables can help form a deeper understanding of the working mechanism of computational curiosity, and provide a clear picture of how collative variables are related to performance changes in intelligent agents.\n10.2. Evaluation of Curiosity\nExisting computational models mostly assume a positive correlation between stimulation and curiosity, which may not be always true in human beings. Studies have been done on simulating the Wundt curve to map the level of stimulation to the level of curiosity, but the understanding of how this mapping affects the performance of human-like agents is still unclear. Moreover, in psychology, the curiosity zone is right next to the boredom zone and the anxiety zone. Hence, deeper studies are necessary to provide more proper mapping methods to allow human-like agents to avoid entering the boredom zone or the anxiety zone during exploration.\n10.3. Interactions between Collative Variables\nIn the proposed computational model of curiosity, the collative variables are treated as independent factors that stimulate curiosity. This model neglects the inter-influences between the\ncollative variables which have been discussed by Berlyne [Berlyne (1960b)] from the field of psychology. Berlyne postulated that novel stimuli can lead to conflict when a new pattern of stimulus is sufficiently similar to several familiar stimulus patterns, which may induce many incompatible responses. Also, novelty has a connection with complexity. For example, a stimulus with short-term novelty will have a higher degree of temporal complexity than purely repetitive patterns. Alternatively, a higher degree of synchronous complexity may induce a higher degree of relative novelty. Moreover, complexity is also associated with uncertainty and conflict. For example, complex patterns with more parts can assume a larger amount of alternative forms and the degree of uncertainty can be affected by the number of classes in these alternative forms; each sub-element of a complex figure may induce different responses that are incompatible with each other, leading to a higher level of conflict.\nModeling the interactions between the collative variables in the stimulus selection function may yield a more accurate curiosity model for the intelligent agents. However, the interactions between the collative variables are rather vague and complicated. Hence, it is difficult to define the interaction weights using expert knowledge. A possible solution is to learn the interaction weights between the collative variables from data through a machine learning approach.\n10.4. Neuroscience Inspired Modeling Approaches\nThe current computational model of curiosity is mainly inspired by the drive theory and optimal arousal theory from the psychological viewpoint. Recently, researchers argued that the psychological models failed to reconcile whether the reward of obtaining new knowledge is mediated through a feeling of _deprivation\", as defined by Loewenstein [Loewenstein (1994)], or a feeling of “interest\", as defined by Spielberger and Starr [Spielberger and Starr (1994)]. Hence, researchers began to integrate the neurological aspects of reward, wanting, and liking into a new way to understand curiosity, one that is explained by biological processes. Litman [Litman (2005)] developed interest deprivation (I/D) theory of curiosity that incorporates the neuroscience of “wanting\" and “liking\", which are two systems hypothesized to underlie\nmotivation and affective experience for a broad class of appetites. Litman theory can be summarized in table 10.1. It can be seen that according to this theory, the different states of curiosity are determined by the corresponding levels of the two factors: wanting and liking. This theory motivates the modeling of computational curiosity from a neuroscience inspired approach, which may be considered in the future works to provide a more comprehensive computational model of curiosity.\n10.5. Curiosity-based Decision Making\nOne interesting issue with computational curiosity is the risk management in curiosity-based decision making. As curiosity often leads to explorations, sometimes the agent or human being may be exposed to the possibility of being harmed or causing undesirable consequences to\nothers. Hence, curious machines should operate under the protection of proper risk management systems so that they will not harm themselves. Ethical boundaries should also be defined for curious agents so that they will not intrude on the privacy of the users or other agents.\nBibliography\nBaldassarre, G. (2011). What are intrinsic motivations? A biological perspective. In proceedings of IEEE Conference on Development and Learning, pages 1_8. Bandura, A. (1997). Selfefficacy: The exercise of control. New York: W.H. Freeman.\nBarto, A., Singh, S., and Chentanez, N. (2004a). Intrinsically motivated learning of hierarchical collections of skills. In proceedings of International Conference on Development Learn, pages 112_119.\nBaylor, A. and Ryu, J. (2003). The API (Agent Persona Instrument) for assessing pedagogical agent persona. In proceedings of The World Conference on Educational Multimedia, Hypermedia and Telecommunications, pages 448_451.\nBerlyne, D. E. (1960a). Conflict, arousal, and curiosity. McGraw-Hill Book Company.\nBickmore, T. and Picard, R. (2005). Establishing and maintaining long-term human-computer relationships. ACM Transaction on Computer-Human Interaction, 12(2):293_327.\nBiswas, G., Leelawong, K., Schwartz, D., and Vye, N. (2005). Learning by teaching: A new agent paradigm for educational software. Applied Artificial Intelligence, 19(3-4):363_392.\nBoud, D., Cohen, R., and Sampson, J. (2001). Peer Learning in Higher Education: Learning from & with Each Other. ERIC.\nBradley, K. and Smyth, B. (2001). Improving recommendation diversity. In proceedings of AICS'01, pages 75_84.\nBroekens, J., Jonker, C., and Meyer, J. (2010). Affective negotiation support systems. Journal of Ambient Intelligence and Smart Environments, 2(2):121_144.\nBrophy, J. and Good, T. (1974). Teacher-student relationships: Causes and consequences. Rinehart & Winston.\nBurgard, W., Moors, M., and Schneider, F. (2002). Collaborative exploration of unknown environments with teams of mobile robots. Advances in plan-based control of robotic agents, 2466:187_215.\nCohn, D., Ghahramani, Z., and Jordan, M. (1996). Active learning with statistical models. Journal of Artificial Intelligence Research, 4:129_145.\nDede, C. (2009). Immersive interfaces for engagement and learning. Science, 323:66_69.\nDunn, J. and Schweitzer, M. (2005). Feeling and believing: The influence of emotion on trust. Journal of personality and social psychology, 88(5):736_748.\nEdelson, D., Gordin, D., and Pea, R. (1999). Addressing the challenges of inquiry-based learning through technology and curriculum design. Journal of the Learning Sciences, 8(3-4):391_450.\nEisen, M. (2001). Peer-based learning: A new-old alternative to professional development. Adult Learning, 12(1):9_10.\nEmotion enhances learning via norepinephrine regulation of ampa-receptor trafficking. Cell, 131(1):160_173.\nFedorov, V. (1972). Theory of optimal experiments. Academic Press. Feng, G., Huang, G., Lin, Q., and Gay, R. (2009). Error minimized extreme learning machine with growth of hidden nodes and incremental learning. IEEE Transactions on Neural Networks, 20(8):1352_1357.\nFogg, B. (1999). Persuasive technologies. Communications of the ACM, 42(5):26_29.\nFogg, B. (2002). Persuasive technology: Using computers to change what we think and do. Ubiquity, 2002(5):27_29.\nFranklin, S. and Graesser, A. (1996). Is it an agent, or just a program?: A taxonomy for autonomous agents. In proceedings of the Workshop on Intelligent Agents III, Agent Theories, Architectures, and Languages, pages 21_35.\nGetzels, J. (1966). The problem of interests: A reconsideration. Supplementary Education Monographs, 66:97_106.\nGratch, J. (2000). Emile: Marshalling passions in training and education. In proceedings of International Conference on Autonomous Agents, pages 325_332.\nGraziano, V., Glasmachers, T., Schaul, T., Pape, L., Cuccu, G., Leitner, J., and Schmidhuber, J. (2011). Artificial curiosity for autonomous space exploration. Acta Futura, pages 41_51.\nH. Dong, B. He, and C. Miao. A Survey of Resource Management in Multi-Tier Web Applications, IEEE Communications Surveys and Tutorials, vol. 16, pp.1574-1590, January 2014.\nH. Yu, C. Miao, B. An, Z. Shen, and C. Leung, “Reputation aware task allocation for human trustees,” in Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS’14) . May 2014, pp. 357–364\nH. Yu, X. Yu, S. F. Lim, J. Lin, Z. Shen, and C. Miao, “A multiagent game for studying human\ndecision making,” in Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS’14). May 2014, pp. 1661–1662.\nH. Yu, Z. Shen, C. Miao, B. An, and C. Leung, Filtering trust opinions through reinforcement learning, Decision Support Systems, vol. 66, pp.102–113, October 2014.\nH. Zhong, C. Miao, Z. Shen and Y. Feng, Comparing the Learning Effectiveness of BP, ELM, IELM, and SVM for Corporate Credit Ratings.Neurocomputing, vol. 128, pp.285-295, 2014.\nHarris, A. and Rea, A. (2009). Web 2.0 and virtual world technologies: A growing impact on IS education. Journal of Information Systems Education, 20(2):137_144.\nHebb, D. (1949). The organization of behavior. New York: Wiley.\nHerlocker, J. L., Konstan, J. A., Terveen, L. G., and Riedl, J. T. (2004). Evaluating collaborative filtering recommender systems. ACM Transactions on Information Systems (TOIS), 22(1):5_53.\nHu, H., Real, E., Takamiya, K., Kang, M., Ledoux, J., Huganir, R., and Malinow, R. (2007).\nHuang, G. and Chen, L. (2007). Convex incremental extreme learning machine. Neurocomputing, 70(16):3056_3062.\nHuang, G. and Chen, L. (2008). Enhanced random search based incremental extreme learning machine. Neurocomputing, 71(16):3460_3468.\nHuang, G., Wang, D., and Lan, Y. (2011). Extreme learning machines: a survey. International Journal of Machine Learning and Cybernetics, 2(2):107_122.\nHuang, G., Zhu, Q., and Siew, C. (2006b). Extreme learning machine: theory and applications. Neurocomputing, 70(1):489_501.\nHuang, G., Zhu, Q., and Siew, C. (2006c). Real-time learning capability of neural networks. IEEE Transactions on Neural Networks, 17(4):863_878.\nHuang, G., Zhu, Q., Mao, K., Siew, C., Saratchandran, P., and Sundararajan, N. (2006a). Can threshold networks be trained directly? IEEE Transactions on Circuits and Systems II: Express Briefs, 53(3):187_191.\nJ. Gan, B. An, C. Miao, An efficient algorithm for taxi system optimization, in Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS’14) . May 2014, pp. 1465-1466."
    }, {
      "heading" : "J. Lin, H. Yu, Z. Shen, and C. Miao, “Studying task allocation decisions of novice agile teams",
      "text" : "with data from agile project management tools,” in Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering (ASE’14). ACM, September 2014, pp.689–694."
    }, {
      "heading" : "J. P. Mei, H. Yu, Y. Liu, Z. Shen, and C. Miao, “A social trust model considering trustees’",
      "text" : "influence,” in Proceedings of the 17th International Conference on Principles and Practice of MultiAgent Systems (PRIMA’14), December 2014, Lecture Notes in Computer Science Volume 8861, 2014, pp 357-364.\nJ.P. Mei, Y. Wang, L. Chen, and C. Miao, “Incremental fuzzy clustering for document\ncategorization,” in Proceedings of the IEEE International Conference on Fuzzy Systems (FUZZIEEE’14) . IEEE, July 2014, pp. 1518–1525.\nJacobson, M., Kim, B., Miao, C., and Chavez, M. (2010). Design for learning environments of the future. Springer US, pages 111_141.\nJamali, M. and Ester, M. (2011). A transitivity aware matrix factorization model for recommendation in social networks. In proceedings IJCAI'11, pages 2644_2649.\nJames, W. (1950). Principles of psychology. New York: Holt. Jennings, N. and Wooldridge, M. (2002). Agent technology: foundations, applications, and markets. Springer.\nJohnson, W., Rickel, J., and Lester, J. (2000). Animated pedagogical agents: Face-to-face interaction in interactive learning environments. International Journal of Artificial intelligence in education, 11(1):47_78.\nKaelbling, L., Littman, M., and Moore, A. (1996). Reinforcement learning: A survey. Journal of Arti_cial Intelligence Research, 4:237_285.\nKaraoguz, C., Drix, D. anad Potapova, E., and Huelse, M. (2011). Curiosity driven exploration of sensory-motor mappings. Deliverable for the IM-CLeVeR Spring School at the Capo Caccia Cognitive Neuromorphic Engineering Workshop, pages 1_7.\nKashdan, T. and Steger, M. (2007). Curiosity and pathways to well-being and meaning in life: Traits, states, and everyday behaviors. Motivation and Emotion, 31(3):159_173.\nKashdan, T., McKnight, P., Fincham, F., and Rose, P. (2011). When curiosity breeds intimacy taking advantage of intimacy opportunities and transforming boring conversations. Journal of Personality, 79(6):1369_ 1402.\nKashdan, T., Rose, P., and Fincham, F. (2004). Curiosity and exploration: Facilitating positive subjective experiences and personal growth opportunities. Journal of Personality Assessment, 82(3):291_305.\nKempe, D., Kleinberg, J., and Tardos, É. (2003). Maximizing the spread of influence through a social network. In proceedings of ACM SIGKDD'03, pages 137_146.\nKennedy-Clark, S. (2009). Designing failure to encourage success: Productive failure in a multiuser virtual environment to solve complex problems. In proceedings of European Conference on Technology Enhanced Learning, pages 609_614.\nKennedy-Clark, S. (2011). Pre-service teachers' perspectives on using scenario-based virtual worlds in science education. Computers & Education, 57(4):2224_2235.\nKennedy-Clark, S. and Thompson, K. (2011). What do students learn when collaboratively using a computer game in the study of historical disease epidemics, and why? Games and Culture, 6(6):513_537.\nKim, Y. (2004). Pedagogical agents as learning companions: The effects of agent affect and gender on learning, interest, self-efficacy, and agent persona. PhD thesis, The Florida State University.\nKoren, Y. (2008). Factorization meets the neighborhood: a multifaceted collaborative filtering model. In proceedings of KDD'08, pages 426_434.\nKoster, R. (2005). A theory of fun for game design. Paraglyph Press.\nLi, M. and Vitanyi, P. (2008). An introduction to Kolmogorov complexity and its applications. Springer-Verlag New York Inc.\nLiang, N., Huang, G., Saratchandran, P., and Sundararajan, N. (2006a). A fast and accurate online sequential learning algorithm for feedforward networks. IEEE Transactions on Neural Networks, 17(6):1411_1423.\nLiang, N., Saratchandran, P., Huang, G., and Sundararajan, N. (2006b). Classification of mental tasks from EEG signals using extreme learning machine. International Journal of Neural Systems, 16(01):29_38.\nLitman, J. (2005). Curiosity and the pleasures of learning: Wanting and liking new information. Cognition & emotion, 19(6):793_814.\nLitman, J. and Spielberger, C. (2003). Measuring epistemic curiosity and its diversive and speci_c components. Journal of Personality Assessment, 80(1):75_86.\nLoewenstein, G. (1994). The psychology of curiosity: A review and reinterpretation. Psychological Bulletin, 116(1):75_98.\nMa, H., Zhou, D., Liu, C., Lyu, M., and King, I. (2011). Recommender systems with social regularization. In proceedings of ACM international conference on Web search and data mining, pages 287_296.\nMacedo, L. (2010). Selecting information based on artificial forms of selective attention. In proceedings of European Conference on Artificial Intelligence, pages 1053_1054.\nMacedo, L. and Cardoso, A. (1999). Towards artificial forms of surprise and curiosity. In proceedings of the European Conference on Cognitive Science, pages 139_144.\nMacedo, L. and Cardoso, A. (2001). Modeling forms of surprise in an artificial agent. In proceedings of the Annaul Conference of the Cognitive Science Society, pages 588_593.\nMacedo, L. and Cardoso, A. (2002). Assessing creativity: the importance of unexpected novelty. In proceedings of the ECAI Workshop on Creative Systems: Approaches to Creativity in AI and Cognitive Science, pages 31_37.\nMacedo, L. and Cardoso, A. (2004). Exploration of unknown environments with motivational agents. In proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, pages 328_335.\nMacedo, L. and Cardoso, A. (2005). The role of surprise, curiosity and hunger on exploration of unknown environments populated with entities. In proceedings of Portuguese Conference on Artificial Intelligence, pages 47_53.\nMaher, M., Merrick, K., and Saunders, R. (2008). Achieving creative behavior using curious learning agents. In proceedings of AAAI Spring Symposium on Creative Intelligent Systems, pages 26_28.\nMerrick, K. (2008a). Designing toys that come alive: curious robots for creative play. In proceedings of International Conference on Entertainment Computing, pages 149_154.\nMerrick, K. (2008b). Modeling motivation for adaptive nonplayer characters in dynamic computer game worlds. Computers in Entertainment, 5(4):5. 1_32.\nMerrick, K. and Huntington, E. (2008). Attention focus in curious, reconfigurable robots. In proceedings of Australian Conference on Robotics and Automation.\nMerrick, K. and Maher, M. (2009). Motivated reinforcement learning: curious characters for multiuser games. Springer.\nMerrick, K., Maher, M., and Saunders, R. (2008). Achieving adaptable behaviour in intelligent rooms using curious supervised learning agents. In proceedings of Conference on Computer Aided Architectural Design Research in Asia, pages 185_192.\nMiche, Y., Sorjamaa, A., and Lendasse, A. (2008). OP-ELM: theory, experiments and a toolbox. Lecture Notes in Computer Science, pages 145_154.\nMoorehead, S., Simmons, R., and Whittaker, W. (2001). Autonomous exploration using multiple sources of information. In proceedings of IEEE International Conference on Robotics and Automation, pages 3098_3103.\nNgo, H., Luciw, M., Forster, A., and Schmidhuber, J. (2012). Learning skills from play: Artificial curiosity on a katana robot arm. In proceedings Of International Conference on Neural Networks, pages 1_8.\nNovak, J. and Gowin, D. (1984). Learning how to learn. Cambridge University Press.\nOgino, M., Kikuchi, M., and Asada, M. (2006). How can humanoid acquire lexicon?-active approach by attention and learning biases based on curiosity. In proceedings of IEEE International Conference on Intelligent Robots and Systems, pages 3480_3485.\nOrtony, A., Clore, G., and Collins, A. (1988). The cognitive structures of emotions. Cambridge University Press.\nOudeyer, P. (to appear in 2012). Developmental robotics. Encyclopedia of the Sciences of Learning.\nOudeyer, P. and Kaplan, F. (2004). Intelligent adaptive curiosity: a source of self-development. In proceedings of International Workshop on Epigenetic Robotics, pages 127_130.\nOudeyer, P. and Kaplan, F. (2007). What is intrinsic motivation? A typology of computational approaches. Frontiers in Neurorobotics, 1(6):257_262.\nOudeyer, P., Kaplan, F., Hafner, V., and Whyte, A. (2005). The playground experiment: Taskindependent development of a curious robot. In proceedings of the AAAI Spring Symposium on Developmental Robotics, pages 42_47.\nP. Li, X. Luo, X. Meng, C. Miao, M.a He and X. Guo. A Two‐ Stage Win–Win Multiattribute Negotiation Model: Optimization and Then Concession. Computational Intelligence, vol. 29, pp.577–626, 2013.\nP. Wu, S. C. H. Hoi, H. Xia, P. Zhao, D. Wang, and C. Miao, “Online multimodal deep similarity learning with application to image retrieval,” in Proceedings of the 21st ACM International Conference on Multimedia (MM ’13) #. ACM, October 2013, pp. 153–162.\nP. Wu, Y. Ding, P. Zhao, C. Miao, and S. Hoi, “Learning relative similarity by stochastic dual\ncoordinate ascent,” in Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI’14). AAAI, July 2014.\nPang, S., Ozawa, S., and Kasabov, N. (2009). Curiosity driven incremental LDA agent active learning. In proceedings of International Joint Conference on Neural Networks, pages 2401_2408.\nPape, L., Oddo, C., Controzzi, M., Cipriani, C., F_'oster, A., Carrozza, M., and Schmidhuber, J. (2012). Learning tactile skills through curious exploration. Frontiers in Neurorobotics, 6:6.\nPicard, R. (1997). A_ective computing. The MIT Press.\nRaghunathan, R. and Pham, M. T. (1999). All negative moods are not equal: Motivational in_uences of anxiety and sadness on decision making. Organizational behavior and human decision processes, 79(1):56_77.\nRamchurn, S., Huynh, D., and Jennings, N. (2004). Trust in multi-agent systems. The Knowledge Engineering Review, 19(1):1_25.\nReiss, S. (2000). Who am I? The 16 basic desires that motivate our actions and define our personalities. The Berkley Publishing Group.\nRenner, B. (2006). Curiosity about people: The development of a social curiosity measure in adults. Journal of Personality Assessment, 87(3):305_ 316.\nResnick, P. and Varian, H. R. (1997). Recommender systems. Communications of the ACM, 40(3):56_58.\nRolls, E. (2003). Emotions in Humans and Artifacts, chapter A Theory of Emotion, lts Functions, and lts Adaptive Value, pages 11_34. MIT Press.\nRong, H., Ong, Y., Tan, A., and Zhu, Z. (2008). A fast pruned-extreme learning machine for classi_cation problem. Neurocomputing, 72(1):359_ 366.\nRussell, S. and Norvig, P. (1995). Artificial intelligence: a modern approach. Prentice hall Englewood Cliffs.\nS. Liu, H. Yu, C. Miao, and A. C. Kot, “A fuzzy logic based reputation model against unfair ratings,” in Proceedings of the 12th International Conference on Autonomous Agents and Multiagent Systems (AAMAS’13) #. May 2013, pp. 821–828.\nS. Liu, Jie Zhang, C. Miao, Y.-L. Theng and A. C. Kot, An Integrated Clustering-Based Approach to Filtering Unfair Multi-Nominal Testimonies, Computational Intelligence, vol. 30, no. 2, pp. 316–341, May 2014.\nS. Liu, Z. Shen, M. J. McKeown, C. Leung, and C. Miao, “A fuzzy logic based Parkinson’s disease risk predictor,” in Proceedings of the IEEE International Conference on Fuzzy Systems (FUZZ-IEEE’14) . IEEE, July 2014, pp. 1624–1631.\nSalichs, M. and Malfaz, M. (2011). A new approach to modeling emotions and their use on a decision making system for artificial agents. IEEE Transaction on Affective Computing, pages 56_68.\nSarwar, B., Karypis, G., Konstan, J., and Riedl, J. (2000). Application of dimensionality reduction in recommender system: a case study. In proceedings of WEBKDD WORKSHOP.\nSaunders, R. (2002). Curious design agents and artificial creativity: A synthetic approach to the study of creative behaviour. PhD thesis, University of Sydney.\nSaunders, R. (2007). Towards a computational model of creative societies using curious design agent. In proceedings of International Conference on Engineering Societies in the Agents World VII, pages 340_353.\nSaunders, R. (2011). Artificial creative systems and the evolution of language. In proceedings of the International Conference on Computational Creativity, pages 36_41.\nSaunders, R. and Gero, J. (2001). A curious design agent. In proceedings Of Conference on Computer Aided Architectural Design Research in Asia, pages 345_350.\nSaunders, R. and Gero, J. (2004). Curious agents and situated design evaluations. Artificial Intelligence for Engineering Design, Analysis and Manufacturing, 18(2):153 _ 161.\nSavitha, R., Suresh, S., and Kim, H. (2014). A meta-cognitive learning algorithm for an extreme learning machine classifier. Cognitive Computation, 6(2):253_263.\nSchmidhuber, J. (1991a). Adaptive con_dence and adaptive curiosity. Technical Report FKI149-91, Technische Universitat Munchen.\nSchmidhuber, J. (1991b). Curious model-building control systems. In proceedings of IEEE International Joint Conference on Neural Networks, pages 1458_1463.\nSchmidhuber, J. (1991c). A possibility for implementing curiosity and boredom in modelbuilding neural controllers. In proceedings of the International Conference on Simulation of Adaptive Behavior: From Animals to Animats, pages 222_227.\nSchmidhuber, J. (1999). Artificial curiosity based on discovering novel algorithmic predictability through coevolution. In proceedings of the Congress on Evolutionary Computation, pages 1612_1618.\nSchmidhuber, J. (2002). Exploring the predictable. Advances in Evolutionary Computing, pages 579_612.\nSchmidhuber, J. (2006). Developmental robotics, optimal artificial curiosity, creativity, music, and the _ne arts. Connection Science, 18(2):173_187.\nSchmidhuber, J. (2007). Simple algorithmic principles of discovery, subjective beauty, selective attention, curiosity & creativity. In Proc: International Conference on Discovery Science, pages 26_28.\nSchmidhuber, J. (2009a). Formal theory of creativity, fun and intrinsic motivation. IEEE Transaction on Autonomous Mental Development, 2(3):230_ 247.\nSchmidhuber, J. (2009b). Simple algorithmic theory of subjective beauty, novelty, surprise, interestingness, attention, curiosity, creativity, art, science, music, jokes. Journal of the Society of Instrument and Control Engineers, 48(1):21_32.\nSchmidhuber, J. (2013). Powerplay: Training an increasingly general problem solver by continually searching for the simplest still unsolvable problem. Frontiers in psychology, 4(313).\nSchmitt, F. and Lahroodi, R. (2008). The epistemic value of curiosity. Educational Theory, 58(2):125_148.\nSchoorman, F., Mayer, R., and Davis, J. (2007). An integrative model of organizational trust: Past, present, and future. Academy of Management review, 32(2):344_354.\nScott, P. and Markovitch, S. (1989). Learning novel domains through curiosity and conjecture. In proceedings of International Joint Conference on Artificial Intelligence, pages 669_674.\nScott, P. and Markovitch, S. (1993). Experience selection and problem choice in an exploratory learning system. Machine Learning, 12(1-3):49 _ 67.\nSilvia, P. J. (2008). Interestæ¡¾he curious emotion. Current Directions in Psychological Science, 17(1):57_60.\nSingh, S., Barto, A., and Chentanez, N. (2004). Intrinsically motivated reinforcement learning. In proceedings of International Conference on Neural Information Processing Systems.\nSoloway, E., Guzdial, M., and Hay, K. (1994). Learner-centered design: The challenge for hci in the 21st century. Interactions, 1(2):36_48.\nSpielberger, C. and Starr, L. (1994). Curiosity and exploratory behavior. NJ: Lawrence Erlbaum Associates, pages 221_243.\nStojanov, G., Kulakov, A., and Clauzel, D. (2006). On curiosity in intelligent robotic systems. In proceedings of AAAI Fall Symposium on Interaction and Emergent Phenomena in Societies of Agents, Arlington, Virginia, pages 44_51.\nStorck, J., Hochreiter, S., and Schmidhuber, J. (1995). Reinforcement driven information acquisition in non-deterministic environments. In proceedings Of the Int. Conference on Artificial Neural Networks, pages 159_164.\nSubramanian, K., Suresh, S., and Sundararajan, N. (2013). A metacognitive neuro-fuzzy inference system (McFIS) for sequential classification problems. IEEE Transaction on Fuzzy Systems, 21(6):1080_1095.\nSuresh, S., Sundararajan, N., and Saratchandran, P. (2008). Risk-sensitive loss functions for sparse multi-category classification problems. Information Sciences, 178(12):2621_2638.\nTanti, M. and Kennedy-Clark, S. (2010). Curriculum, technology & transformation for an unknown future. Proceedings ascilite Sydney, pages 963_967.\nTogelius, J. and Schmidhuber, J. (2008). An experiment in automatic game design. In proceedings of IEEE Symposium On Computational Intelligence and Games, pages 111_118.\nTversky, A. (1977). Features of similarity. Psychological Review, 84(4):327_ 352.\nUğur, E., Dogar, M., Cakmak, M., and Sahin, E. (2007). Curiosity-driven learning of traversability a_ordance on a mobile robot. In proceedings of IEEE International Conference on Development and Learning, pages 13_18.\nWebb, N. M. (1989). Peer interaction and learning in small groups. International journal of Educational research, 13(1):21_39.\nWhite, R. (1959). Motivation reconsidered: The concept of competence. Psychological Review, 66(5):297_333.\nWiecha, J., Heyden, R., Sternthal, E., and Merialdi, M. (2010). Learning in a virtual world: experience with using second life for medical education. Journal of Medical Internet Research, 12(1):e1. 1_27.\nWilks, Y. (2010). Close engagements with artificial companions: Key social, psychological, ethical and design issues. John Benjamins Publishing Company.\nWilson, A., Burnett, M., Beckwith, L., Granatir, O., Casburn, L., Cook, C., Durham, M., and Rothermel, G. (2003). Harnessing curiosity to increase correctness in end-user programming. In proceedings of SIGCHI Conference on Human Factors in Computing Systems, pages 305_312.\nWooldridge, M. (2002). Intelligent agents: The key concepts. Springer, pages 3_43.\nWu, M. (2007). Collaborative filtering via ensembles of matrix factorizations. In proceedings of KDD Cup and Workshop, pages 43_47.\nWu, Q. and Miao, C. (2013a). Curiosity: From psychology to computation. ACM Computing Surveys, 46(2):18.\nWu, Q. and Miao, C. (2013b). Modeling curiosity-related emotions for virtual peer learners. Computational Intelligence Magazine, 8(2):50_62.\nWu, Q. and Miao, C. (2015). C-ELM: A curious extreme learning machine for classification problems. In proceedings of the International Conference on Extreme Learning machine, pages 355_366.\nWu, Q., Han, X., Yu, H., Shen, Z., and Miao, C. (2013a). The innovative application of learning companions in virtual singapura. In proceedings of the international conference on Autonomous agents and multi-agent systems, pages 1171_1172.\nWu, Q., Miao, C., and An, B. (2014). Modeling curiosity for virtual learning companions. In proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, pages 1401_1402.\nWu, Q., Miao, C., and Shen, Z. (2012a). A curious learning companion in virtual learning environment. In proceedings of IEEE International Conference on Fuzzy Systems, pages 1_8.\nWu, Q., Miao, C., Tao, X., and Helander, M. (2012b). A curious companion for elderly gamers. In proceedings of Southeast Asian Network of Ergonomics Societies Conference, pages 1_5.\nWu, Q., Miao, C., Tao, X., Helander, M., & IEEE (2012). A curious companion for elderly gamers. In Proceedings of Southeast Asian Network of Ergonomics Societies Conference (SEANES), pages 1-5.\nWu, Q., Shen, Z., and Miao, C. (2013b). Stimulating students' curiosity with a companion agent in virtual learning environments. In proceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications, 2013(1):2401_2409.\nWu, Q., Shen, Z., Leung, C., Zhang, H., Ya, A. L., & Cai, Y., et al. (2013). Internet of things based data driven storytelling for supporting social connections. In Proceedings of IEEE International Conference on Internet of Things, pages 383-390.\nWundt, W. (1874). Grundzüde physiologischen psychologie. W.Engelman.\nX. Han, W. Wei, C. Miao, J. P. Mei, and H. Son, Context aware personal information retrieval from multiple social networks, IEEE Computational Intelligence Magazine, vol. 9, no. 2, pp. 18– 28, May 2014.\nX. Luo, C. Miao, N. Jennings, M. He, Z. Shen, and M. Zhang, KEMNAD: A Knowledge Engineering Methodology for Negotiating Agent Development, Computational Intelligence, vol. 28, pp. 51-105, 2012.\nXu, J., Wang, W., Goh, J., and Lee, G. (2006). Internal model approach for gait modeling and classi_cation. Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pages 7688_7691."
    }, {
      "heading" : "Y. Cai, Z. Shen, S. Liu, H. Yu, X. Han, J. Ji, M. J. McKeown, C. Leung, and C. Miao, “An agent",
      "text" : "based game for the predictive diagnosis of Parkinson’s disease,” in Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS’14) , May 2014, pp. 1663–1664."
    }, {
      "heading" : "Y. Liu, J. Zhang, H. Yu, and C. Miao, “Reputation aware continuous double auction,” in",
      "text" : "Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI’14) . AAAI, July 2014.\nY. Liu, S. Liu, J. Zhang, H. Fang, H. Yu, and C. Miao,RepRev: Mitigating the negative effects\nof misreported ratings, in Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI’14). AAAI, July 2014.\nY. Liu, W. Wei, A. Sun, and C. Miao, Exploiting geographical neighborhood characteristics for location recommendation, in Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management (CIKM’14) . ACM, November 2014, pp. 739–748.\nY. Z. Zhao, C. Miao, M. Ma, J. Bing Zhang and C. Leung, A Survey and Projection on Medium Access Control Protocols for Wireless Sensor Networks, ACM Computer Survey, vol. 45. no.1, 2012.\nY. Z. Zhao, C. Miao, M. Ma, Y. Cheng, A Self-Adaptable Energy-Efficient Medium Access Control Protocol for Wireless Sensor Networks, Wireless Personal Communications, vol. 68, no. 4, pp. 1287-1315, 2013.\nYang, Z., Wu, Q., Leung, C., & Miao, C. (2015). OS-ELM Based Emotion Recognition for Empathetic Elderly Companion. In proceedings of the International Conference on Extreme Learning machine, pages 331-341.\nYeu, C., Lim, M., Huang, G., Agarwal, A., and Ong, Y. (2006). A new machine learning paradigm for terrain reconstruction. IEEE Geoscience and Remote Sensing Letters, 3(3):382_386.\nYu, H., Shen, Z., Miao, C., and An, B. (2012). Challenges and opportunities for trust management in crowdsourcing. In proceedings of the IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technology, pages 486_493.\nYu, H., Shen, Z., Miao, C., Leung, C., and Niyato, D. (2010). A survey of trust and reputation management systems in wireless communications. Proceedings of the IEEE, 98(10):1755_1772.\nYu, H., Shen, Z., Wu, Q., & Miao, C. (2014). Designing Socially Intelligent Virtual Companions. arXiv preprint arXiv:1411.7090,\nZhang, T. (2004). Statistical behavior and consistency of classification methods based on convex risk minimization. Annals of Statistics, 32(1):56_85."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2015,
    "abstractText" : null,
    "creator" : "Microsoft® Word 2010"
  }
}