{
  "name" : "1701.01614.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "hirao.tsutomu@lab.ntt.co.jp", "nishino.masaaki@lab.ntt.co.jp", "suzuki.jun@lab.ntt.co.jp", "nagata.masaaki@lab.ntt.co.jp" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 1.\n01 61\n4v 1\n[ cs\n.C L\n] 6\nJ an\n2 01\n7"
    }, {
      "heading" : "1 Introduction",
      "text" : "Recently, compressive and abstractive summarization are attracting attention (e.g., Almeida and Martins (2013), Qian and Liu (2013), Yao et al. (2015), Banerjee et al. (2015), Bing et al. (2015)). However, extractive summarization remains a primary research topic because the linguistic quality of the resultant summaries is guaranteed, at least at the sentence level, which is a key requirement for practical use (e.g., Hong and Nenkova (2014), Hong et al. (2015), Yogatama et al. (2015), Parveen et al. (2015)).\nThe summarization research community is experiencing a paradigm shift from extractive to compressive or abstractive summarization. Cur-\nrently our question is: “Is extractive summarization still useful research?” To answer it, the ultimate limitations of the extractive summarization paradigm must be comprehended; that is, we have to determine its upper bound and compare it with the performance of the state-of-the-art summarization methods. Since ROUGEn is the de-facto automatic evaluation method and is employed in many text summarization studies, an oracle summary is defined as a set of sentences that have a maximum ROUGEn score. If the ROUGEn score of an oracle summary outperforms that of a system that employs another summarization approach, the extractive summarization paradigm is worthwhile to leverage research resources.\nAs another benefit, identifying an oracle summary for a set of reference summaries allows us to utilize yet another evaluation measure. Since both oracle and extractive summaries are sets of sentences, it is easy to check whether a system summary contains sentences in the oracle summary. As a result, F-measures, which are available to evaluate a system summary, are useful for evaluating classification-based extractive summarization (Mani and Bloedorn, 1998; Osborne, 2002; Hirao et al., 2002). Since ROUGEn evaluation does not identify which sentence is important, an F-measure conveys useful information in terms of “important sentence extraction.” Thus, combining ROUGEn and an F-measure allows us to scrutinize the failure analysis of systems.\nNote that more than one oracle summary might exist for a set of reference summaries because ROUGEn scores are based on the unweighted counting of n-grams. As a result, an F-measure might not be identical among multiple oracle summaries. Thus, we need to enumerate the oracle summaries for a set of reference summaries and compute the F-measures based on them.\nIn this paper, we first derive an Integer Linear\nProgramming (ILP) problem to extract an oracle summary from a set of reference summaries and a source document(s). To the best of our knowledge, this is the first ILP formulation that extracts oracle summaries. Second, since it is difficult to enumerate oracle summaries for a set of reference summaries using ILP solvers, we propose an algorithm that efficiently enumerates all oracle summaries by exploiting the branch and bound technique. Our experimental results on the Document Understanding Conference (DUC) corpora showed the following:\n1. Room still exists for the further improvement of extractive summarization, i.e., where the ROUGEn scores of the oracle summaries are significantly higher than those of the state-ofthe-art summarization systems.\n2. The F-measures derived from multiple oracle summaries obtain significantly stronger correlations with human judgment than those derived from single oracle summaries."
    }, {
      "heading" : "2 Definition of Extractive Oracle Summaries",
      "text" : "We first briefly describe ROUGEn. Given set of reference summaries R and system summary S, ROUGEn is defined as follows:\nROUGEn(R, S) = |R| ∑\nk=1\n|U(Rk)| ∑\nj=1\nmin{N(gnj ,Rk), N(g n j ,S)}\n|R| ∑\nk=1\n|U(Rk)| ∑\nj=1\nN(gnj ,Rk)\n. (1)\nRk denotes the multiple set of n-grams that occur in k-th reference summary Rk, and S denotes the multiple set of n-grams that appear in system-generated summary S (a set of sentences). N(gnj ,Rk) and N(g n j ,S) return the number of occurrences of n-gram gnj in the k-th reference and system summaries, respectively. Function U(·) transforms a multiple set into a normal set. ROUGEn takes values in the range of [0, 1], and when the n-gram occurrences of the system summary agree with those of the reference summary, the value is 1.\nIn this paper, we focus on extractive summarization, employ ROUGEn as an evaluation measure,\nand define the oracle summaries as follows:\nO =argmax S⊆D ROUGEn(R, S)\ns.t. ℓ(S) ≤ Lmax. (2)\nD is the set of all the sentences contained in the input document(s), and Lmax is the length limitation of the oracle summary. ℓ(S) indicates the number of words in the system summary. Eq. (2) is an NP-hard combinatorial optimization problem, and no polynomial time algorithms exist that can attain an optimal solution."
    }, {
      "heading" : "3 Related Work",
      "text" : "Lin and Hovy (2003) utilized a naive exhaustive search method to obtain oracle summaries in terms of ROUGEn and exploited them to understand the limitations of extractive summarization systems. Ceylan et al. (2010) proposed another naive exhaustive search method to derive a probability density function from the ROUGEn scores of oracle summaries for the domains to which source documents belong. The computational complexity of naive exhaustive methods is exponential to the size of the sentence set. Thus, it may be possible to apply them to single document summarization tasks involving a dozen sentences, but it is infeasible to apply them to multiple document summarization tasks that involve several hundred sentences.\nTo describe the difference between the ROUGEn scores of oracle and system summaries in multiple document summarization tasks, Riedhammer et al. (2008) proposed an approximate algorithm with a genetic algorithm (GA) to find oracle summaries. Moen et al. (2014) utilized a greedy algorithm for the same purpose. Although GA or greedy algorithms are widely used to solve NP-hard combinatorial optimization problems, the solutions are not always optimal. Thus, the summary does not always have a maximum ROUGEn score for the set of reference summaries. Both works called the summary found by their methods the oracle, but it differs from the definition in our paper.\nSince summarization systems cannot reproduce human-made reference summaries in most cases, oracle summaries, which can be reproduced by summarization systems, have been used as training data to tune the parameters of summarization systems. For example, Kulesza and Tasker (2011)\nand Sipos et al. (2012) trained their summarizers with oracle summaries found by a greedy algorithm. Peyrard and Eckle-Kohler (2016) proposed a method to find a summary that approximates a ROUGE score based on the ROUGE scores of individual sentences and exploited the framework to train their summarizer. As mentioned above, such summaries do not always agree with the oracle summaries defined in our paper. Thus, the quality of the training data is suspect. Moreover, since these studies fail to consider that a set of reference summaries has multiple oracle summaries, the score of the loss function defined between their oracle and system summaries is not appropriate in most cases.\nAs mentioned above, no known efficient algorithm can extract “exact” oracle summaries, as defined in Eq. (2), i.e., because only a naive exhaustive search is available. Thus, such approximate algorithms as a greedy algorithm are mainly employed to obtain them."
    }, {
      "heading" : "4 Oracle Summary Extraction as an Integer Linear Programming (ILP) Problem",
      "text" : "To extract an oracle summary from document(s) and a given set of reference summaries, we start by deriving an Integer Linear Programming (ILP) problem. Since the denominator of Eq. (1) is constant for a given set of reference summaries, we can find an oracle summary by maximizing the numerator of Eq. (1). Thus, the ILP formulation is defined as follows:\nmaximize z\n|R| ∑\nk=1\n|U(Rk)| ∑\nj=1\nzkj (3)\ns.t.\n|D| ∑\ni=1\nℓ(si)xi ≤ Lmax (4)\n∀j :\n|D| ∑\ni=1\nN(gnj , si)xi ≥ zkj (5)\n∀j : N(gnj ,Rk) ≥ zkj (6)\n∀i : xi ∈ {0, 1} (7)\n∀j : zkj ∈ Z+. (8)\nHere, zkj is the count of the j-th n-gram of the k-th reference summary in the oracle summary, i.e., zkj = min{N(gnj ,Rk), N(g n j ,S)}. ℓ(·) returns the number of words in the sentence, xi is a binary indicator, and xi = 1\ndenotes that the i-th sentence si is included in the oracle summary. N(gnj , si) returns the number of occurrences of n-gram gnj in the i-th sentence. Constraints (5) and (6) ensure that zkj = min{N(gnj ,Rk), N(g n j ,S)}."
    }, {
      "heading" : "5 Branch and Bound Technique for Enumerating Oracle Summaries",
      "text" : "Since enumerating oracle summaries with an ILP solver is difficult, we extend the exhaustive search approach by introducing a search and prune technique to enumerate the oracle summaries. The search pruning decision is made by comparing the current upper bound of the ROUGEn score with the maximum ROUGEn score in the search history.\n5.1 ROUGEn Score for Two Distinct Sets of Sentences\nThe enumeration of oracle summaries can be regarded as a depth-first search on a tree whose nodes represent sentences. Fig. 1 shows an example of a search tree created in a naive exhaustive search. The nodes represent sentences and the path from the root node to an arbitrary node represents a summary. For example, the red path in Fig. 1 from the root node to node s2 represents a summary consisting of sentences s1, s2. By utilizing the tree, we can enumerate oracle summaries by exploiting depth-first searches while excluding the summaries that violate length constraints. However, this naive exhaustive search approach is impractical for large data sets because the number of nodes inside the tree is 2|D|.\nIf we prune the unwarranted subtrees in each step of the depth-first search, we can make the search more efficient. The decision to search or\nprune is made by comparing the current upper bound of the ROUGEn score with the maximum ROUGEn score in the search history. For instance, in Fig. 1, we reach node s2 by following this path: “Root → s1, → s2”. If we estimate the maximum ROUGEn score (upper bound) obtained by searching for the descendant of s2 (the subtree in the blue rectangle), we can decide whether the depthfirst search should be continued. When the upper bound of the ROUGEn score exceeds the current maximum ROUGEn in the search history, we have to continue. When the upper bound is smaller than the current maximum ROUGEn score, no summary is optimal that contains s1, s2, so we can skip subsequent search activity on the subtree and proceed to check the next branch: “Root → s1 → s3”.\nTo estimate the upper bound of the ROUGEn score, we re-define it for two distinct sets of sentences, V and W , i.e., V ∩W = φ, as follows:\nROUGEn(R, V ∪W ) = ROUGEn(R, V )\n+ ROUGE′n(R, V,W ). (9)\nHere ROUGE′n is defined as follows:\nROUGE′n(R, V,W ) = |R| ∑\nk=1\n∑\ntn∈U(Rk)\nmin{N(tn,Rk \\ V), N(tn,W)}\n|R| ∑\nk=1\n∑\ntn∈U(Rk))\nN(tn,Rk)\n.\n(10)\nV,W are the multiple sets of n-grams found in the sets of sentences V and W , respectively.\nTheorem 1. Eq. (9) is correct.\nProof. See Appendix A.\n5.2 Upper Bound of ROUGEn Let V be the set of sentences on the path from the current node to the root node in the search tree, and let W be the set of sentences that are the descendants of the current node. In Fig. 1, V={s1, s2} and W={s3, s4, s5, s6}. According to Theorem 1, the upper bound of the ROUGEn score is defined as:\n̂ROUGEn(R, V ) = ROUGEn(R, V ) +\nmax Ω⊆W\n{ROUGE′n(R, V,Ω):ℓ(Ω)≤Lmax−ℓ(V )}.(11)\nAlgorithm 1 Algorithm to Find Upper Bound of ROUGEn 1: Function: ̂ROUGEn(R, V ) 2: W ← descendant(last(V )), W ′ ← φ 3: U ← ROUGE(R, V ) 4: for each w ∈ W do 5: append(W ′, ROUGE ′ n (R,V,{w})\nℓ(w) )\n6: end for 7: sort(W ′, ’descend’) 8: for each w ∈ W ′ do 9: if Lmax − ℓ({w}) ≥ 0 then\n10: U ← U + ROUGE′n(R, V, {w}) 11: Lmax ← Lmax − ℓ({w}) 12: else"
    }, {
      "heading" : "13: U ← U +",
      "text" : "ROUGE′n(R, V, {w})\nℓ({w}) × Lmax\n14: break the loop 15: end if 16: end for 17: return U 18: end\nSince the second term on the right side in Eq. (11) is an NP-hard problem, we turn to the following relation by introducing inequality, ROUGE′n(R, V,Ω) ≤ ∑\nω∈Ω ROUGE ′ n(R, V, {ω}),\nmax Ω⊆W\n{ ROUGE′n(R, V,Ω):ℓ(Ω)≤Lmax−ℓ(V ) }\n≤max x\n{\n∑|W | i=1 ROUGE ′ n(R, V, {wi})xi:\n∑|W | i=1ℓ({wi})xi≤Lmax−ℓ(V )\n}\n. (12)\nHere, x = (x1, . . . , x|W |) and xi ∈ {0, 1}. The right side of Eq. (12) is a knapsack problem, i.e., a 0-1 ILP problem. Although we can obtain the optimal solution for it using dynamic programming or ILP solvers, we solve its linear programming relaxation version by applying a greedy algorithm for greater computation efficiency. The solution output by the greedy algorithm is optimal for the relaxed problem. Since the optimal solution of the relaxed problem is always larger than that of the original problem, the relaxed problem solution can be utilized as the upper bound. Algorithm 1 shows the pseudocode that attains the upper bound of ROUGEn. In the algorithm, U indicates the upper bound score of ROUGEn. We first set the initial score of upper bound U to ROUGEn(R, V ) (line 3). Then we compute the density of the ROUGE′n scores (ROUGE′n(R, V, {w})/ℓ(w)) for each sentence w in W and sort them in descending order (lines 4 to 6). When we have room to add w to the summary, we update U by adding the ROUGE′n(R, V, {w}) (line 10) and update length\nAlgorithm 2 Greedy algorithm to obtain initial score 1: Function: GREEDY(R, D, Lmax) 2: L ← 0, S ← φ,E ← D 3: while E 6= φ do\n4: s∗← arg max s∈E\n{\nROUGEn(R, S ∪ {s})−ROUGEn(R, S)\nℓ({s})\n}\n5: L ← L+ ℓ({s∗}) 6: if L ≤ Lmax then 7: S ← S ∪ {s∗} 8: end if 9: E ← E \\ {s∗}\n10: end while 11: i∗ ← arg max\ni∈D,ℓ({i})≤Lmax\nROUGEn(R, {i})\n12: S∗ ← arg max K∈{{i∗},S} ROUGEn(R,K) 13: return ROUGEn(R, S∗) 14: end\nconstraint Lmax (line 11). When we do not have room to add w, we update U by adding the score obtained by multiplying the density of w by the remaining length, Lmax (line 13), and exit the while loop."
    }, {
      "heading" : "5.3 Initial Score for Search",
      "text" : "Since the branch and bound technique prunes the search by comparing the best solution found so far with the upper bounds, obtaining a good solution in the early stage is critical for raising search efficiency.\nSince ROUGEn is a monotone submodular function (Lin and Bilmes, 2011), we can obtain a good approximate solution by a greedy algorithm (Khuller et al., 1999). It is guaranteed that the score of the obtained approximate solution is larger than 12(1 − 1 e )OPT, where OPT is the score of the optimal solution. We employ the solution as the initial ROUGEn score of the candidate oracle summary.\nAlgorithm 2 shows the greedy algorithm. In it, S denotes a summary and D denotes a set of sentences. The algorithm iteratively adds sentence s∗ that yields the largest gain in the ROUGEn score to current summary S, provided the length of the summary does not violate length constraint Lmax (line 4). After the while loop, the algorithm compares the ROUGEn score of S with the maximum ROUGEn score of the single sentence and outputs the larger of the two scores (lines 11 to 13)."
    }, {
      "heading" : "5.4 Enumeration of Oracle summaries",
      "text" : "By introducing threshold τ as the best ROUGEn score in the search history, pruning decisions involve the following three conditions:\nAlgorithm 3 Branch and bound technique to enumerate oracle summaries 1: Read R,D,Lmax 2: τ ← GREEDY(R,D, Lmax),Oτ ← φ 3: for each s ∈ D do 4: append(S,〈ROUGEn(R, {s}), s〉) 5: end for 6: sort(S,’descend’) 7: call FINDORACLE(S,C) 8: output Oτ 9: Procedure: FINDORACLE(Q,V ) 10: while Q 6= φ do 11: s ←shift(Q) 12: append(V, s) 13: if Lmax − ℓ(V ) ≥ 0 then 14: if ROUGEn(R, V ) ≥ τ then 15: τ ← ROUGEn(R, V ) 16: append(Oτ , V ) 17: call FINDORACLE(Q,V ) 18: else if ̂ROUGEn(R, V ) ≥ τ then 19: call FINDORACLE(Q,V ) 20: end if 21: end if 22: pop(V ) 23: end while 24: end\n1. ROUGEn(R, V ) ≥ τ ;\n2. ROUGEn(R, V ) < τ , ̂ROUGEn(R, V ) < τ ;\n3. ROUGEn(R, V ) < τ , ̂ROUGEn(R, V ) ≥ τ .\nWith case 1, we update the oracle summary as V and continue the search. With case 2, because both ROUGEn(R, V ) and ̂ROUGEn(R, V ) are smaller than τ , the subtree whose root node is the current node (last visited node) is pruned from the search space, and we continue the depthfirst search from the neighbor node. With case 3, we do not update oracle summary as V because ROUGEn(R, V ) is less than τ . However, we might obtain a better oracle summary by continuing the depth-first search because the upper bound of the ROUGEn score exceeds τ . Thus, we continue to search for the descendants of the current node.\nAlgorithm 3 shows the pseudocode that enumerates the oracle summaries. The algorithm reads a set of reference summaries R, length limitation Lmax, and set of sentences D (line 1) and initializes threshold τ as the ROUGEn score obtained by the greedy algorithm (Algorithm 2). It also initializes Oτ , which stores oracle summaries whose ROUGEn scores are τ , and priority queue C , which stores the history of the depth-first search (line 2). Next, the algorithm computes the ROUGEn score for each sentence and stores S after sorting them in descending order. After that, we start a depth-first search by recursively call-\ning procedure FINDORACLE. In the procedure, we extract the top sentence from priority queue Q and append it to priority queue V (lines 11 to 12). When the length of V is less than Lmax, if ROUGEn(R, V ) is larger than threshold τ (case 1), we update τ as the score and append current V to Oτ . Then we continue the depth-first search by calling the procedure the FINDORACLE (lines 15 to 17). If ̂ROUGEn(R, V ) is larger than τ (case 3), we do not update τ and Oτ but reenter the depthfirst search by calling the procedure again (lines 18 to 19). If neither case 1 nor case 3 is true, we delete the last visited sentence from V and return to the top of the recurrence."
    }, {
      "heading" : "6 Experiments",
      "text" : ""
    }, {
      "heading" : "6.1 Experimental Setting",
      "text" : "We conducted experiments on the corpora developed for a multiple document summarization task in DUC 2001 to 2007. Table 1 show the statistics of the data. In particular, the DUC-2005 to -2007 data sets not only have very large numbers of sentences and words but also a long target length (the reference summary length) of 250 words.\nAll the words in the documents were stemmed by Porter’s stemmer (Porter, 1980). We computed ROUGE1 scores, excluding stopwords, and computed ROUGE2 scores, keeping them. Owczarzak et al. (2012) suggested using ROUGE1 and keeping stopwords. However, as Takamura et al. argued (Takamura and Okumura, 2009), the summaries optimized with non-content words failed to consider the actual quality. Thus, we excluded stopwords for computing the ROUGE1 scores.\nWe enumerated the following two types of oracle summaries: those for a set of references for a given topic and those for each reference in the set of references."
    }, {
      "heading" : "6.2 Results and Discussion",
      "text" : "6.2.1 Impact of Oracle ROUGEn scores\nTable 2 shows the average ROUGE1,2 scores of the oracle summaries obtained from both a set of references and each reference in the set (“multi” and “single”), those of the best conventional system (Peer), and those obtained from summaries produced by a greedy algorithm (Algorithm 2).\nOracle (single) obtained better ROUGE1,2 scores than Oracle (multi). The results imply that it is easier to optimize a reference summary than a set of reference summaries. On the other hand, the ROUGE1,2 scores of these oracle summaries are significantly higher than those of the best systems. The best systems obtained ROUGE1 scores from 60% to 70% in “multi” and from 50% to 60% in “single” as well as ROUGE2 scores from 40% to 55% in “multi” and from 30% to 40% in “single” for their oracle summaries.\nSince the systems in Table 2 were developed over many years, we compared the ROUGEn scores of the oracle summaries with those of the current state-of-the-art systems using the DUC-2004 corpus and obtained summaries generated by different systems from a public repository1 (Hong et al., 2014). The repository includes summaries produced by the following seven state-of-the-art summarization systems: CLASSY04 (Conroy et al., 2004), CLASSY11 (Conroy et al., 2011), Submodular (Lin and Bilmes, 2012), DPP (Kulesza and Tasker, 2011), RegSum (Hong and Nenkova, 2014), OCCAMS V (Davie et al., 2012; Conroy et al., 2013), and ICSISumm (Gillick and Favre, 2009; Gillick et al., 2009). Table 3 shows the results.\nBased on the results, RegSum (Hong and Nenkova, 2014) achieved the best ROUGE1=0.331 result, while ICSISumm (Gillick and Favre, 2009; Gillick et al., 2009) (a compressive summarizer) achieved the best result with ROUGE2=0.098. These systems outperformed the best systems (Peers 65 and 67 in Table 2), but the differences in the ROUGEn scores between the systems and the oracle summaries are still large. More recently, Hong et al. (2015) demonstrated that their system’s combination approach achieved the current best ROUGE2 score, 0.105, for the DUC-2004 corpus. However,\n1http://www.cis.upenn.edu/˜nlp/corpora/sumrepo.html\na large difference remains between the ROUGE2 score of oracle and their summaries.\nIn short, the ROUGEn scores of the oracle summaries are significantly higher than those of the current state-of-the-art summarization systems, both extractive and compressive summarization. These results imply that further improvement of the performance of extractive summarization is possible.\nOn the other hand, the ROUGEn scores of the oracle summaries are far from ROUGEn = 1. We believe that the results are related to the summary’s compression rate. The data set’s compression rate was only 1 to 2%. Thus, under tight length constraints, extractive summarization basically fails to cover large numbers of n-grams in the reference summary. This reveals the limitation of the extractive summarization paradigm and suggests that we need another direction, compressive or abstractive summarization, to overcome the limitation.\n6.2.2 ROUGE Scores of Summaries Obtained from Greedy Algorithm\nTable 2 also shows the ROUGE1,2 scores of the summaries obtained from the greedy algorithm (greedy summaries). Although there are statisti-\ncally significant differences between the ROUGE scores of the oracle summaries and greedy summaries, those obtained from the greedy summaries achieved near optimal scores, i.e., approximation ratio of them are close to 0.9. These results are surprising since the algorithm’s theoretical lower bound is 12(1− 1 e )(≃ 0.32)OPT.\nOn the other hand, the results do not support that the differences between them are small at the sentence-level. Table 4 shows the average Jaccard Index between the oracle summaries and the corresponding greedy summaries for the DUC-2004 corpus. The results demonstrate that the oracle summaries are much less similar to the greedy summaries at the sentence-level. Thus, it might not be appropriate to use greedy summaries as training data for learning-based extractive summarization systems."
    }, {
      "heading" : "6.2.3 Impact of Enumeration",
      "text" : "Table 5 shows the median number of oracle summaries and the rates of the reference summaries that have multiple oracle summaries for each data set. Over 80% of the reference summaries and about 60% to 90% of the topics have multiple oracle summaries. Since the ROUGEn scores are based on the unweighted counting of n-grams, when many sentences have similar meanings, i.e., many redundant sentences, the number of oracle summaries that have the same ROUGEn scores increases. The source documents of multiple document summarization tasks are prone to have many such redundant sentences, and the amount of ora-\ncle summaries is large.\nThe oracle summaries offer significant benefit with respect to evaluating the extracted sentences. Since both the oracle and system summaries are sets of sentences, it is easy to check whether each sentence in the system summary is contained in one of the oracle summaries. Thus, we can exploit the F-measures, which are useful for evaluating classification-based extractive summarization (Mani and Bloedorn, 1998; Osborne, 2002; Hirao et al., 2002). Here, we have to consider that the oracle summaries, obtained from a reference summary or a set of reference summaries, are not identical at the sentence-level (e.g., the average Jaccard Index between the oracle summaries for the DUC-2004 corpus is around 0.5). The F-measures are varied with the oracle summaries that are used for such computation. For example, assume that we have system summary S={s1, s2, s3, s4} and oracle summaries O1={s1, s2, s5, s6} and O2={s1, s2, s3}. The precision for O1 is 0.5, while that for O2 is 0.75; the recall for O1 is 0.5, while that for O2 is 1; the F-measure for O1 is 0.5, while that for O2 is 0.86.\nThus, we employ the scores gained by averaging all of the oracle summaries as evaluation measures. Precision, recall, and F-measure are defined as follows: P={ ∑\nO∈Oall |O ∩ S|/|S|}/|Oall|,\nR={ ∑\nO∈Oall |O ∩ S|/|O|}/|Oall|,\nF-measure=2PR/(P +R).\nTo demonstrate F-measure’s effectiveness, we investigated the correlation between an F-measure and human judgment based on the evaluation results obtained from the DUC-2004 corpus. The results include summaries generated by 17 systems, each of which has a mean coverage score assigned\nby a human subject. We computed the correlation coefficients between the average F-measure and the average mean coverage score for 50 topics. Table 6 shows Pearson’s r and Spearman’s ρ. In the table, “F-measure (R1)” and “F-measure (R2)” indicate the F-measures calculated using oracle summaries optimized to ROUGE1 and ROUGE2, respectively. “M” indicates the F-measure calculated using multiple oracle summaries, and “S” indicates F-measures calculated using randomly selected oracle summaries. “multi” indicates oracle summaries obtained from a set of references, and “single” indicates oracle summaries obtained from a reference summary in the set. For “S,” we randomly selected a single oracle summary and calculated the F-measure 100 times and took the average value with the 95% confidence interval of the F-measures by bootstrap resampling.\nThe results demonstrate that the F-measures are strongly correlated with human judgment. Their values are comparable with those of ROUGE1,2. In particular, F-measure (R1) (single-M) achieved the best Spearman’s ρ result. When comparing “single” with “multi,” Pearson’s r of “multi” was slightly lower than that of “single,” and the Spearman’s r of “multi” was almost the same as those of “single.” “M” has significantly better performance than “S.” These results imply that F-measures based on oracle summaries are a good evaluation measure and that oracle summaries have the potential to be an alternative to human-made reference summaries in terms of automatic evaluation. Moreover, the enumeration of the oracle summaries for a given reference summary or a set of reference summaries is essential for automatic evaluation."
    }, {
      "heading" : "6.2.4 Search Efficiency",
      "text" : "To demonstrate the efficiency of our search algorithm against the naive exhaustive search method, we compared the number of feasible solutions (sets of sentences that satisfy the length constraint) with the number of summaries that were checked in our search algorithm. The algorithm that counts the number of feasible solutions is shown in Appendix B.\nTable 7 shows the median number of feasible solutions and checked summaries yielded by our method for each data set (in the case of “single”). The differences in the number of feasible solutions between ROUGE1 and ROUGE2 are very large. Input set (|D|) of ROUGE1 is much larger than ROUGE1. On the other hand, the differences between ROUGE1 and ROUGE2 in our method are of the order of 10 to 102. When comparing our method with naive exhaustive searches, its search space is significantly smaller. The differences are of the order of 107 to 1030 with ROUGE1 and 104 to 1017 with ROUGE2. These results demonstrate the efficiency of our branch and bound technique.\nIn addition, we show an example of the processing time for extracting one oracle summary and enumerating all of the oracle summaries for the reference summaries in the DUC-2004 corpus with a Linux machine (CPU: Intel R© Xeon R© X5675 (3.07GHz)) with 192 GB of RAM. We utilized CPLEX 12.1 to solve the ILP problem. Our algorithm was implemented in C++ and complied with GCC version 4.4.7. The results show that we needed 0.026 and 0.021 sec. to extract one oracle summary per reference summary and 0.047 and 0.031 sec. to extract one oracle summary per set of reference summaries for ROUGE1 and ROUGE2, respectively. We needed 11.90 and 1.40 sec. to enumerate the oracle summaries\nper reference summary and 102.94 and 3.65 sec. per set of reference summaries for ROUGE1 and ROUGE2, respectively. The extraction of one oracle summary for a reference summary can be achieved with the ILP solver in practical time and the enumeration of oracle summaries is also efficient. However, to enumerate oracle summaries, we needed several weeks for some topics in DUCs 2005 to 2007 since they hold a huge number of source sentences."
    }, {
      "heading" : "7 Conclusions",
      "text" : "To analyze the limitations and the future direction of extractive summarization, this paper proposed (1) Integer Linear Programming (ILP) formulation to obtain extractive oracle summaries in terms of ROUGEn scores and (2) an algorithm that enumerates all oracle summaries to exploit F-measures that evaluate the sentences extracted by systems.\nThe evaluation results obtained from the corpora of DUCs 2001 to 2007 identified the following: (1) room still exists to improve the ROUGEn scores of extractive summarization systems even though the ROUGEn scores of the oracle summaries fell below the theoretical upper bound ROUGEn=1. (2) Over 80% of the reference summaries and from 60% to 90% of the sets of reference summaries have multiple oracle summaries, and the F-measures computed by utilizing the enumerated oracle summaries showed stronger correlation with human judgment than those computed from single oracle summaries."
    }, {
      "heading" : "Appendix A.",
      "text" : "Proof. We can rewrite the right side of equation (9) as follows:\nROUGE(R, V )+ROUGE′n(R, V,W ) = |R| ∑\nk=1\n∑\ntn∈U(Rk)\nf(tn,Rk,V,W)\n|R| ∑\nk=1\n∑\ntn∈U(Rk)\nN(tn,Rk)\n. (13)\nHere, f(tn,Rk,V,W) is defined as follows:\nf(tn,Rk,V,W)=min{N(tn,Rk), N(tn,V)}+\nmin{N(tn,Rk \\ V), N(tn,W)}.\n(14)\nN(tn,Rk \\ V) is the number of times tn occurs in the multiple set Rk \\ V . Equation (14) is rewritten as\nf(tn,Rk,V,W)=min{N(tn,Rk), N(tn,V)}+\nmin{max{N(tn,Rk)−N(tn,V), 0}, N(tn,W)}.\n(15)\nThe solutions of equation (15) are obtained by considering the following three conditions:\n1. If N(tn,Rk) − N(tn,V) > 0 and N(tn,Rk) − N(tn,V) > N(tn,W), then f(tn,Rk,V,W) = N(tn,V) +N(tn,W)\n2. If N(tn,Rk) − N(tn,V) > 0 and N(tn,Rk) − N(tn,V) < N(tn,W), then f(tn,Rk,V,W) = N(tn,Rk)\n3. If N(tn,Rk) − N(tn,V) < 0, then f(tn,Rk,V,W) = N(tn,Rk)\nFrom the above relations,\nf(tn,Rk,V,W) =\nmin{N(tn,Rk), N(tn,V) +N(tn,W)}. (16)\nThus,\nROUGEn(R, V ∪W ) = |R| ∑\nk=1\n∑\ntn∈U(Rk)\nmin{N(tn,Rk), N(tn,V)+N(tn,W)}\n|R| ∑\nk=1\n∑\ntn∈U(Rk)\nN(tn,Rk)\n(17)\nAlgorithm 4 Dynamic Programming Algorithm to Count the Number of the Feasible Summaries 1: Function: GETNUMFS(D,Lmax) 2: C[0][0] ← 1, C[0][j] ← 0, 1 ≤ j ≤ Lmax 3: for i = 1 to |D| do 4: for j = 0 to Lmax do 5: if j − ℓ(si) ≥ 0 then 6: C[i][j] ← C[i− 1][j] +C[i− 1][j − ℓ(si)] 7: else 8: C[i][j] ← C[i− 1][j] 9: end if 10: end for 11: end for 12: return Lmax∑\nj=1\nC[|D|][j]\n13: end"
    }, {
      "heading" : "Appendix B.",
      "text" : "We propose an algorithm to compute the number of feasible solutions under the length constraint by extending the dynamic programming based approach for the subset sum problem (Cormen et al., 2009). We define C[i][j](0 ≤ i ≤ |D|, 0 ≤ j ≤ Lmax), which stores the number of feasible solutions (length is less than j) that can be obtained from set {s1, . . . , si} as follows:\n• Initialization\nC[0][j] = 0 (0 ≤ j ≤ Lmax) (18)\n• Recurrence (1 ≤ i ≤ |D|)\nC[i][j]= {\nC[i−1][j] + C[i−1][j−ℓ(si)] if j−ℓ(si) ≥ 0 C[i−1][j] otherwise\n(19)\nAlgorithm 4 is a dynamic program that fills out the (|D| + 1) × (Lmax + 1) table. After the table is filled, each cell on the |D| + 1-th line stores the number of feasible solutions. In the algorithm, first, we pick up the sentences that contain an n-gram that appears in the reference summary at least once and recursively count the number of feasible solutions. Then, the sum of the j-th line whose index is from 1 to Lmax indicates the number of feasible solutions. The order of the algorithm is O(nLmax)."
    } ],
    "references" : [ {
      "title" : "Fast and robust compressive summarization with dual decomposition and",
      "author" : [ "Almeida", "Martins2013] Miguel B. Almeida", "André F.T. Martins" ],
      "venue" : null,
      "citeRegEx" : "Almeida et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Almeida et al\\.",
      "year" : 2013
    }, {
      "title" : "Multidocument abstractive summarization using ILP based multi-sentence compression",
      "author" : [ "Prasenjit Mitra", "Kazunari Sugiyama" ],
      "venue" : "In Proc. of the 24th International Joint Conference on Artificial In-",
      "citeRegEx" : "Banerjee et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Banerjee et al\\.",
      "year" : 2015
    }, {
      "title" : "Abstractive multi-document summarization via phrase selection and merging",
      "author" : [ "Bing et al.2015] Lidong Bing", "Piji Li", "Yi Liao", "Wai Lam", "Weiwei Guo", "Rebecca J. Passonneau" ],
      "venue" : "In Proc. of the 53rd Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Bing et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Bing et al\\.",
      "year" : 2015
    }, {
      "title" : "Quantifying the limits and success of extractive summarization systems across domains",
      "author" : [ "Ceylan et al.2010] Hakan Ceylan", "Rada Mihalcea", "Umut Özertem", "Elena Lloret", "Manuel Palomar" ],
      "venue" : "In Proc. of the Human Language Technologies:",
      "citeRegEx" : "Ceylan et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Ceylan et al\\.",
      "year" : 2010
    }, {
      "title" : "Left-brain/right-brain multi-document summarization",
      "author" : [ "Jade Goldstein", "Judith D. Schlesinger", "Dianne P. O’Leary" ],
      "venue" : "In Proc. of the Document Understanding Conference (DUC)",
      "citeRegEx" : "Conroy et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Conroy et al\\.",
      "year" : 2004
    }, {
      "title" : "Classy 2011 at TAC: Guided and multi-lingual summaries and evaluation metrics",
      "author" : [ "Judith D. Schlesinger", "Jeff Kubina", "Peter A. Rankel", "Dianne P. O’Leary" ],
      "venue" : "In Proc. of the Text Analysis Conference",
      "citeRegEx" : "Conroy et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Conroy et al\\.",
      "year" : 2011
    }, {
      "title" : "Multilingual summarization: Dimensionality reduction and a step towards optimal term coverage",
      "author" : [ "Sashka T. Davis", "Jeff Kubina", "Yi-Kai Liu", "Dianne P. O’Leary", "Judith D Schlesinger" ],
      "venue" : "In Proc. of the MultiL-",
      "citeRegEx" : "Conroy et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Conroy et al\\.",
      "year" : 2013
    }, {
      "title" : "Introduction to Algorithms",
      "author" : [ "Clifford Stein", "Ronald L. Rivest", "Charles E. Leiserson" ],
      "venue" : null,
      "citeRegEx" : "Cormen et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Cormen et al\\.",
      "year" : 2009
    }, {
      "title" : "OCCAMS - an optimal combinatorial covering algorithm for multidocument summarization",
      "author" : [ "John M. Conroy", "Judith D. Schlesinger" ],
      "venue" : "In Proc. of the 12th IEEE International Conference on Data Mining Work-",
      "citeRegEx" : "Davie et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Davie et al\\.",
      "year" : 2012
    }, {
      "title" : "A scalable global model for summarization",
      "author" : [ "Gillick", "Favre2009] Dan Gillick", "Benoit Favre" ],
      "venue" : "In Proc. of the Workshop on Integer Linear Programming for Natural Language Processing,",
      "citeRegEx" : "Gillick et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Gillick et al\\.",
      "year" : 2009
    }, {
      "title" : "The ICSI/UTD summarization system at TAC",
      "author" : [ "Gillick et al.2009] Dan Gillick", "Benoit Favre", "Dilek Hakkani-Tur", "Berndt Bohnet", "Yang Liu", "Shasha Xie" ],
      "venue" : "In Proc. of the Text Analysis Conference (TAC)",
      "citeRegEx" : "Gillick et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Gillick et al\\.",
      "year" : 2009
    }, {
      "title" : "Extracting import sentences with support vector machines",
      "author" : [ "Hirao et al.2002] Tsutomu Hirao", "Hideki Isozaki", "Eisaku Maeda", "Yuji Matsumoto" ],
      "venue" : "In Proc. of the 19th International Conference on Computational Linguistics (COLING),",
      "citeRegEx" : "Hirao et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Hirao et al\\.",
      "year" : 2002
    }, {
      "title" : "Improving the estimation of word importance for news multi-document summarization",
      "author" : [ "Hong", "Nenkova2014] Kai Hong", "Ani Nenkova" ],
      "venue" : "In Proc. of the 14th Conference of the European Chapter of the Association for Computational Linguistics,",
      "citeRegEx" : "Hong et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hong et al\\.",
      "year" : 2014
    }, {
      "title" : "A repository of state of the art and competitive baseline summaries for generic news summarization",
      "author" : [ "Hong et al.2014] Kai Hong", "John Conroy", "Benoit Favre", "Alex Kulesza", "Hui Lin", "Ani Nenkova" ],
      "venue" : "In Proc. of the Ninth International",
      "citeRegEx" : "Hong et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hong et al\\.",
      "year" : 2014
    }, {
      "title" : "System combination for multidocument summarization",
      "author" : [ "Hong et al.2015] Kai Hong", "Mitchell Marcus", "Ani Nenkova" ],
      "venue" : "In Proc. of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Hong et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Hong et al\\.",
      "year" : 2015
    }, {
      "title" : "The budgeted maximum coverage problem",
      "author" : [ "Anna Moss", "Joseph Naor" ],
      "venue" : "Information Processing Letters,",
      "citeRegEx" : "Khuller et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Khuller et al\\.",
      "year" : 1999
    }, {
      "title" : "Learning determinantal point process",
      "author" : [ "Kulesza", "Tasker2011] Alex Kulesza", "Ben Tasker" ],
      "venue" : "In Proc. of the 27th Conference on Uncertainty in Artificial Intelligence",
      "citeRegEx" : "Kulesza et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Kulesza et al\\.",
      "year" : 2011
    }, {
      "title" : "A class of submodular functions for document summarization",
      "author" : [ "Lin", "Bilmes2011] Hui Lin", "Jeff Bilmes" ],
      "venue" : "In Proc. of the 49th Association for Computational Linguistics: Human Language Technologies,",
      "citeRegEx" : "Lin et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2011
    }, {
      "title" : "Learning mixtures of submodular shells with application to document summarization",
      "author" : [ "Lin", "Bilmes2012] Hui Lin", "Jeff Bilmes" ],
      "venue" : "In Proc. of the 28th Conference on Uncertainty in Artificial Intelligence (UAI2012)",
      "citeRegEx" : "Lin et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2012
    }, {
      "title" : "The potential and limitations of automatic sentence extraction for summarization",
      "author" : [ "Lin", "Hovy2003] Chin-Yew Lin", "Eduard Hovy" ],
      "venue" : "In Proc. of the HLT-NAACL 03 Text Summarization Workshop,",
      "citeRegEx" : "Lin et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2003
    }, {
      "title" : "Machine learning of generic and user-focused summarization",
      "author" : [ "Mani", "Bloedorn1998] Inderjeet Mani", "Eric Bloedorn" ],
      "venue" : null,
      "citeRegEx" : "Mani et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Mani et al\\.",
      "year" : 1998
    }, {
      "title" : "On evaluation of automatically generated clinical discharge summaries",
      "author" : [ "Moen et al.2014] Hans Moen", "Juho Heimonen", "LauraMaria Murtola", "Antti Airola", "Tapio Pahikkala", "Virpi Terv", "Riitta Danielsson-Ojala", "Tapio Salakoski", "Sanna Salanter" ],
      "venue" : null,
      "citeRegEx" : "Moen et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Moen et al\\.",
      "year" : 2014
    }, {
      "title" : "Using maximum entropy for sentence extraction",
      "author" : [ "Miles Osborne" ],
      "venue" : "In Proceedings of the ACL-02 Workshop on Automatic Summarization,",
      "citeRegEx" : "Osborne.,? \\Q2002\\E",
      "shortCiteRegEx" : "Osborne.",
      "year" : 2002
    }, {
      "title" : "An assessment of the accuracy of automatic evaluation in summarization",
      "author" : [ "John M. Conroy", "Hoa Trang Dang", "Ani Nenkova" ],
      "venue" : "In Proc. of Workshop on Evaluation Metrics and System Comparison",
      "citeRegEx" : "Owczarzak et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Owczarzak et al\\.",
      "year" : 2012
    }, {
      "title" : "Topical coherence for graph-based extractive summarization",
      "author" : [ "Hans-Martin Ramsl", "Michael Strube" ],
      "venue" : "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Parveen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Parveen et al\\.",
      "year" : 2015
    }, {
      "title" : "Optimizing an approximation of rouge - a problem-reduction approach to extractive multi-document summarization",
      "author" : [ "Peyrard", "Eckle-Kohler2016] Maxime Peyrard", "Judith Eckle-Kohler" ],
      "venue" : "In Proceedings of the 54th Annual Meeting of the Associa-",
      "citeRegEx" : "Peyrard et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Peyrard et al\\.",
      "year" : 2016
    }, {
      "title" : "An algorithm for suffix stripping",
      "author" : [ "Martin F. Porter" ],
      "venue" : null,
      "citeRegEx" : "Porter.,? \\Q1980\\E",
      "shortCiteRegEx" : "Porter.",
      "year" : 1980
    }, {
      "title" : "Fast joint compression and summarization via graph cuts",
      "author" : [ "Qian", "Liu2013] Xian Qian", "Yang Liu" ],
      "venue" : "In Proc. of the 2013 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Qian et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Qian et al\\.",
      "year" : 2013
    }, {
      "title" : "Packing the meeting summarization knapsack",
      "author" : [ "Dan Gillick", "Benoit Favre", "Dilek Hakkani-Tür" ],
      "venue" : "In Proc. of the 9th Annual Conference of the International Speech Communication",
      "citeRegEx" : "Riedhammer et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Riedhammer et al\\.",
      "year" : 2008
    }, {
      "title" : "Large-margin learning of submodular summarization models",
      "author" : [ "Sipos et al.2012] Ruben Sipos", "Pannaga Shivaswamy", "Thorsten Joachims" ],
      "venue" : "In Proc. of the 13th Conference of the European Chapter of the Association for Computational Linguistics,",
      "citeRegEx" : "Sipos et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Sipos et al\\.",
      "year" : 2012
    }, {
      "title" : "Text summarization model based on maximum coverage problem and its variant",
      "author" : [ "Takamura", "Okumura2009] Hiroya Takamura", "Manabu Okumura" ],
      "venue" : "In Proc. of the 12th Conference of the European of the Association for Computational Linguis-",
      "citeRegEx" : "Takamura et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Takamura et al\\.",
      "year" : 2009
    }, {
      "title" : "Compressive document summarization via sparse optimization",
      "author" : [ "Yao et al.2015] Jin-ge Yao", "Xiaojun Wan", "Jianguo Xiao" ],
      "venue" : "In Proc. of the 24th International Joint Conference on Artificial Intelligence (IJCAI",
      "citeRegEx" : "Yao et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Yao et al\\.",
      "year" : 2015
    }, {
      "title" : "Extractive summarization by maximizing semantic volume",
      "author" : [ "Fei Liu", "Noah A. Smith" ],
      "venue" : "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Yogatama et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Yogatama et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 25,
      "context" : ", Almeida and Martins (2013), Qian and Liu (2013), Yao et al. (2015), Banerjee et al.",
      "startOffset" : 51,
      "endOffset" : 69
    }, {
      "referenceID" : 1,
      "context" : "(2015), Banerjee et al. (2015), Bing et al.",
      "startOffset" : 8,
      "endOffset" : 31
    }, {
      "referenceID" : 1,
      "context" : "(2015), Banerjee et al. (2015), Bing et al. (2015)).",
      "startOffset" : 8,
      "endOffset" : 51
    }, {
      "referenceID" : 1,
      "context" : "(2015), Banerjee et al. (2015), Bing et al. (2015)). However, extractive summarization remains a primary research topic because the linguistic quality of the resultant summaries is guaranteed, at least at the sentence level, which is a key requirement for practical use (e.g., Hong and Nenkova (2014), Hong et al.",
      "startOffset" : 8,
      "endOffset" : 301
    }, {
      "referenceID" : 1,
      "context" : "(2015), Banerjee et al. (2015), Bing et al. (2015)). However, extractive summarization remains a primary research topic because the linguistic quality of the resultant summaries is guaranteed, at least at the sentence level, which is a key requirement for practical use (e.g., Hong and Nenkova (2014), Hong et al. (2015), Yogatama et al.",
      "startOffset" : 8,
      "endOffset" : 321
    }, {
      "referenceID" : 1,
      "context" : "(2015), Banerjee et al. (2015), Bing et al. (2015)). However, extractive summarization remains a primary research topic because the linguistic quality of the resultant summaries is guaranteed, at least at the sentence level, which is a key requirement for practical use (e.g., Hong and Nenkova (2014), Hong et al. (2015), Yogatama et al. (2015), Parveen et al.",
      "startOffset" : 8,
      "endOffset" : 345
    }, {
      "referenceID" : 1,
      "context" : "(2015), Banerjee et al. (2015), Bing et al. (2015)). However, extractive summarization remains a primary research topic because the linguistic quality of the resultant summaries is guaranteed, at least at the sentence level, which is a key requirement for practical use (e.g., Hong and Nenkova (2014), Hong et al. (2015), Yogatama et al. (2015), Parveen et al. (2015)).",
      "startOffset" : 8,
      "endOffset" : 368
    }, {
      "referenceID" : 22,
      "context" : "As a result, F-measures, which are available to evaluate a system summary, are useful for evaluating classification-based extractive summarization (Mani and Bloedorn, 1998; Osborne, 2002; Hirao et al., 2002).",
      "startOffset" : 147,
      "endOffset" : 207
    }, {
      "referenceID" : 11,
      "context" : "As a result, F-measures, which are available to evaluate a system summary, are useful for evaluating classification-based extractive summarization (Mani and Bloedorn, 1998; Osborne, 2002; Hirao et al., 2002).",
      "startOffset" : 147,
      "endOffset" : 207
    }, {
      "referenceID" : 3,
      "context" : "Ceylan et al. (2010) proposed another naive exhaustive search method to derive a probability density function from the ROUGEn scores of oracle summaries for the domains to which source documents belong.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 27,
      "context" : "To describe the difference between the ROUGEn scores of oracle and system summaries in multiple document summarization tasks, Riedhammer et al. (2008) proposed an approximate algorithm with a genetic algorithm (GA) to find oracle summaries.",
      "startOffset" : 126,
      "endOffset" : 151
    }, {
      "referenceID" : 21,
      "context" : "Moen et al. (2014) utilized a greedy algorithm for the same purpose.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 29,
      "context" : "and Sipos et al. (2012) trained their summarizers with oracle summaries found by a greedy algorithm.",
      "startOffset" : 4,
      "endOffset" : 24
    }, {
      "referenceID" : 29,
      "context" : "and Sipos et al. (2012) trained their summarizers with oracle summaries found by a greedy algorithm. Peyrard and Eckle-Kohler (2016) proposed a method to find a summary that approximates a ROUGE score based on the ROUGE scores of individual sentences and exploited the framework to train their summarizer.",
      "startOffset" : 4,
      "endOffset" : 133
    }, {
      "referenceID" : 15,
      "context" : "Since ROUGEn is a monotone submodular function (Lin and Bilmes, 2011), we can obtain a good approximate solution by a greedy algorithm (Khuller et al., 1999).",
      "startOffset" : 135,
      "endOffset" : 157
    }, {
      "referenceID" : 26,
      "context" : "All the words in the documents were stemmed by Porter’s stemmer (Porter, 1980).",
      "startOffset" : 64,
      "endOffset" : 78
    }, {
      "referenceID" : 23,
      "context" : "Owczarzak et al. (2012) suggested using ROUGE1 and keeping stopwords.",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 12,
      "context" : "Since the systems in Table 2 were developed over many years, we compared the ROUGEn scores of the oracle summaries with those of the current state-of-the-art systems using the DUC-2004 corpus and obtained summaries generated by different systems from a public repository1 (Hong et al., 2014).",
      "startOffset" : 272,
      "endOffset" : 291
    }, {
      "referenceID" : 4,
      "context" : "The repository includes summaries produced by the following seven state-of-the-art summarization systems: CLASSY04 (Conroy et al., 2004), CLASSY11 (Conroy et al.",
      "startOffset" : 115,
      "endOffset" : 136
    }, {
      "referenceID" : 5,
      "context" : ", 2004), CLASSY11 (Conroy et al., 2011), Submodular (Lin and Bilmes, 2012), DPP (Kulesza and Tasker, 2011), RegSum (Hong and Nenkova, 2014), OCCAMS V (Davie et al.",
      "startOffset" : 18,
      "endOffset" : 39
    }, {
      "referenceID" : 8,
      "context" : ", 2011), Submodular (Lin and Bilmes, 2012), DPP (Kulesza and Tasker, 2011), RegSum (Hong and Nenkova, 2014), OCCAMS V (Davie et al., 2012; Conroy et al., 2013), and ICSISumm (Gillick and Favre, 2009; Gillick et al.",
      "startOffset" : 118,
      "endOffset" : 159
    }, {
      "referenceID" : 6,
      "context" : ", 2011), Submodular (Lin and Bilmes, 2012), DPP (Kulesza and Tasker, 2011), RegSum (Hong and Nenkova, 2014), OCCAMS V (Davie et al., 2012; Conroy et al., 2013), and ICSISumm (Gillick and Favre, 2009; Gillick et al.",
      "startOffset" : 118,
      "endOffset" : 159
    }, {
      "referenceID" : 9,
      "context" : ", 2013), and ICSISumm (Gillick and Favre, 2009; Gillick et al., 2009).",
      "startOffset" : 22,
      "endOffset" : 69
    }, {
      "referenceID" : 9,
      "context" : "331 result, while ICSISumm (Gillick and Favre, 2009; Gillick et al., 2009) (a compressive summarizer) achieved the best result with ROUGE2=0.",
      "startOffset" : 27,
      "endOffset" : 74
    }, {
      "referenceID" : 9,
      "context" : "331 result, while ICSISumm (Gillick and Favre, 2009; Gillick et al., 2009) (a compressive summarizer) achieved the best result with ROUGE2=0.098. These systems outperformed the best systems (Peers 65 and 67 in Table 2), but the differences in the ROUGEn scores between the systems and the oracle summaries are still large. More recently, Hong et al. (2015) demonstrated that their system’s combination approach achieved the current best ROUGE2 score, 0.",
      "startOffset" : 53,
      "endOffset" : 357
    }, {
      "referenceID" : 22,
      "context" : "Thus, we can exploit the F-measures, which are useful for evaluating classification-based extractive summarization (Mani and Bloedorn, 1998; Osborne, 2002; Hirao et al., 2002).",
      "startOffset" : 115,
      "endOffset" : 175
    }, {
      "referenceID" : 11,
      "context" : "Thus, we can exploit the F-measures, which are useful for evaluating classification-based extractive summarization (Mani and Bloedorn, 1998; Osborne, 2002; Hirao et al., 2002).",
      "startOffset" : 115,
      "endOffset" : 175
    }, {
      "referenceID" : 7,
      "context" : "We propose an algorithm to compute the number of feasible solutions under the length constraint by extending the dynamic programming based approach for the subset sum problem (Cormen et al., 2009).",
      "startOffset" : 175,
      "endOffset" : 196
    } ],
    "year" : 2017,
    "abstractText" : "To analyze the limitations and the future directions of the extractive summarization paradigm, this paper proposes an Integer Linear Programming (ILP) formulation to obtain extractive oracle summaries in terms of ROUGEn. We also propose an algorithm that enumerates all of the oracle summaries for a set of reference summaries to exploit F-measures that evaluate which system summaries contain how many sentences that are extracted as an oracle summary. Our experimental results obtained from Document Understanding Conference (DUC) corpora demonstrated the following: (1) room still exists to improve the performance of extractive summarization; (2) the F-measures derived from the enumerated oracle summaries have significantly stronger correlations with human judgment than those derived from single oracle summaries.",
    "creator" : "LaTeX with hyperref package"
  }
}