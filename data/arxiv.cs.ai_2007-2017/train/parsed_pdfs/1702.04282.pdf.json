{
  "name" : "1702.04282.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "T-SKIRT: Online Estimation of Student Proficiency in an Adaptive Learning System",
    "authors" : [ "Chaitanya Ekanadham", "Yan Karklin" ],
    "emails" : [ "CHAITU@KNEWTON.COM", "YAN@KNEWTON.COM" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Accurately predicting student responses is an important task for adaptive learning systems. Better predictions enable more efficient diagnosis and remediation of student deficiencies. When reported as analytics, these predictions can also provide the student or teacher with actionable information to improve student outcomes. Traditional approaches mostly consider single-session assessments (e.g., a standardized examination), but to work in learning environments, adaptive systems must deal with significant challenges:\n• student knowledge states are constantly fluctuating, due to online or offline learning, forgetting, and varying levels of engagement with the content\n• lack of control over the user experience: students may do different, unrelated, assignments on their own schedule, and at different paces\n• student paths through content are often heavily correlated for pedagogical reasons (contrary to an ideal\nProceedings of the 31 st International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).\nrandomized controlled trial) and may include repeat attempts and/or be subject to selection bias\n• up-to-date predictions must be available as soon as a new response is made (imagine a student aces a quiz and submits, then gets recommended similar material)\n• accurate inferences and sensible recommendations must be made even at the beginning of a session, when little data about the student is available\n• the pool of content is very diverse: fitting a model of student responses to one set of content may not generalize to another set. Furthermore, relationships between content are difficult to establish and represent in the model, even given expert labels (Lindsey et al., 2014).\nBayesian Knowledge Tracing (BKT) is a framework that explicitly models student learning (Corbett & Anderson, 1994) but it accounts for diversity in neither students nor content. On the other hand, Item Response Theory (IRT) is a framework for modeling responses by estimating both student and content properties (Rasch, 1960; Lord, 1980), but it does not account for student learning. Several recent efforts have attempted to combine the complementary benefits of these two frameworks, with some success (González-Brenes et al., 2013; Khajah et al., 2014; SohlDickstein, 2013; Lan et al., 2014). However, a few gaps remain: First, the way in which these models are evaluated is not consistent with the requirements of an adaptive learning system, which has access to all previous responses and is tasked with predicting the outcome of one or more prospective pairings of students and questions. Instead, model performance is gauged by predicting randomly held out chunks of responses (which is not a realistic task even if these responses are in the future and contiguous in time) for each student, or all responses for a randomly chosen subset of students (an approach that does not leverage currently available information). Second, the benefit of temar X iv :1 70 2.\n04 28\n2v 1\n[ cs\n.A I]\n1 4\nFe b\n20 17\nporal methods over standard IRT methods has not been empirically observed. This could be due to high correlation in student paths through the content (observed in some of our data as well). Third, previous models either do not account for multiple dimensions of knowledge, or assume they can be modelled independently. Finally, data are typically collected via a highly instrumented and standardized system (intelligent tutoring system), which is unlike several other online learning environments.\nWe develop a unified IRT-based model that allows for student and item parameters, temporal fluctuation of student abilities, and content diversity. We compare this model with standard IRT models on an evaluation task identical to that performed in a production setting: predicting the next response given all previous responses to date. Our findings are twofold: First, incorporating temporality into our model yields a significant performance boost. Second, modeling multiple dimensions of knowledge along with the connections between them (based on labels from subject matter experts) provides additional improvement in performance."
    }, {
      "heading" : "2. Background",
      "text" : ""
    }, {
      "heading" : "2.1. Knowledge tracing",
      "text" : "Knowledge tracing (Corbett & Anderson, 1994) (KT) is a framework for modeling the process of students mastering one or more skills while completing a sequence of assessments. At each time t, Zt is an unobserved binary variable indicating whether the student has mastered the skill or not, and Xt is an observed binary variable indicating the correctness value of the completed assessment. A Hidden Markov Model is used to capture the statistical relationships between these. Emission probabilities govern how likely a correct response is given each hidden state. Transition probabilities govern how a student transitions between the hidden states. Several KT variants have been proposed to individually handle student abilities, multiple skills, assessment difficulty, and external aids (see (Khajah et al., 2014) and the references therein). In (González-Brenes et al., 2013; Khajah et al., 2014), a unifying framework for these is proposed where the probabilities are parameterized in terms of these observed features."
    }, {
      "heading" : "2.2. Item response theory",
      "text" : "Item response theory (IRT) (Lord, 1980; Rasch, 1993) is a framework for modeling binary student responses on a set of assessments. In the two-parameter formulation the probability that a student s answers an assessment q correctly is given by:\npsq = f(αq(θs − βq)) (1)\nwhere θs is the student proficiency, βq is the assessment difficulty, and αq is the assessment discrimination which governs how sensitive the correctness probability is to the students proficiency. The function f(.) is known as the item response function and increases monotonically from 0 to 1. We choose f(x) = Φ(x), the cumulative distribution function of the normal distribution. This model is known as the two-parameter ogive, or 2PO model (Rasch, 1993).\nAn underlying assumption of this model is that student abilities (θs) remain constant over time, making this more applicable to responses from an examination rather than a learning experience over an extended period of time. In (González-Brenes et al., 2013) and (Sohl-Dickstein, 2013), the IRT framework is augmented to handle temporal fluctuations in student proficiencies. However, the benefits over standard IRT were not empirically realized in the former, while the latter required considerable amount of computing resources and time to fit.\nNote also that none of the models in the KT or IRT families have been rigorously evaluated on the online prediction task."
    }, {
      "heading" : "3. T-SKIRT",
      "text" : ""
    }, {
      "heading" : "3.1. Temporality",
      "text" : "We extend the 2PO model by modeling the student proficiencies over time as a Wiener process. Under this model, the conditional relationships are given by\nP (θt+τ |θt) = φθt,ν2τ (θt+τ ) (2) where φµ,σ2(.) is the probability density function of the normal distribution with mean µ and variance σ2. The proportionality constant ν2 on the conditional variance is a model parameter, tuned to maximize prediction accuracy on a separate dataset). Under this model, the joint probability over responses and proficiencies for a single student is given by:\nP (r1:t, θ1:t) = P (r1:t|θ1:t)P (θ1:t) (3)\n= P (θ1) t∏ i=2 P (θi|θi−1) t∏ i=1 P (ri|θi)\n= φµ0,σ20 (θ1) t∏ i=2 φθi−1,ν2(θi) t∏ i=1 prii (1− pi) 1−ri\nwhere pi = Φ(αqi(θi − βqi)) is the probability of correct on the i′th response to question qi, as per Eq. 1. The primary task is to infer the posterior distribution over the current proficiencies θt given all past responses. We assume that item parameters have been learned previously\nand are fixed. Let r1:n and θ1:n denote sequences of binary responses and real-valued proficiencies, respectively. The posterior is then given by:\nP (θt|r1:t) ∝ P (r1:t|θt)P (θt) (4)\nTo evaluate the first term on the right-hand side, it is necessary to integrate out all possible paths θ1:t−1:\nP (r1:t|θt) = ∫ P (r1:t, θ1:t−1|θt)dθ1:t−1\nHowever, computing this integral is expensive, especially in an online setting. For computational efficiency, we make the following approximation:\nP (r1:t|θt) ≈ t∏ i=1 P (ri|θt)\n= t∏ i=1 ∫ P (ri, |θi)P (θi|θt)dθi\n= t∏ i=1 ∫ prii (1− pi) 1−riφθt,ν2(t−i)(θi)dθi (5)\nUsing the definition of pi and the fact that ∫\nΦ(α(x − β))φµ,σ2(x)dx = Φ ( α(β−µ)√ 1+α2σ2 ) , we can simplify this to:\nP (r1:t|θt) ≈ t∏ i=1 p̃rii (1− p̃i) 1−ri (6)\nwhere:\np̃i = Φ(α̃i(θt − βqi))\nα̃i = αqi√\n1 + α2qiν 2(t− i)\n(7)\nNote that this formulation is exactly the same as the likelihood under a non-temporal IRT model, with αqi replaced by α̃i. Therefore, we refer to α̃i as the “effective discrimination” of the i’th response on the student’s current proficiency θt. Note that the further back in time the response, the lower the effective discrimination and thus the smaller effect it has on the posterior over θt in Eq. 4. Finally, we can substitute Eq. 6 into Eq. 4 and take the log to get the approximate log-posterior:\nlogP (θt|r1:t) ≈ logP (θt) + t∑ i=1 ri log(p̃i) (8)\n+ (1− ri) log(p̃i) (9)"
    }, {
      "heading" : "3.2. Structured, multidimensional prior over student proficiencies",
      "text" : "When the content pool is very diverse, summarizing student proficiency with a single number (varying over time) may not be enough to capture the student response patterns. Content can be organized into groups against which student proficiency is measured. These groups have been referred to as knowledge components (Corbett et al., 1997) or skills (Lindsey et al., 2014; Lan et al., 2014). The content used in our experiments has been grouped by subject matter experts into groups called concepts. Each student’s proficiency at a single time is now represented by a vector of proficiencies in each concept, ~θt ∈ RC where C is the total number of concepts. The IRT likelihood (Eq. 1) can then be rewritten as:\npsq = f(αq(θscq − βq)) (10)\nwhere cq is the concept assessed by question q.\nExperts also identify prerequisite relationships between concepts indicating that content in one concept cannot be mastered without having mastered content in another concept. For more details see (Wilson & Nichols, 2014). These concepts and prerequisite relationships define a directed acyclic graph, and from this we can define a prior distribution over ~θt that captures the conceptual relationships (similar to how expert labels were used in (Lindsey et al., 2014)). We employ a specific multivariate Gaussian prior whose log-probability is given by:\nlogP (~θt) = −λ N∑ n=1 θ2tn − γ ∑ n,m:n≺m (θn − θm)2 (11)\nwhere θtn is the n’th element of the vector ~θt, n ≺ m indicates that concept n is prerequisite to concept m, and the parameters λ and γ control the overall variance and relative correlations, respectively. Note that the precision matrix has non-zero entries along the diagonal and only for pairs of concepts that have a prerequisite relationship. This defines a prior over proficiencies at any fixed point in time. In order to incorporate this into the temporal model, we make the following approximation for computational tractability:\nP (~θi|~θt) ≈ ∏ n P (θin|θtn) (12)\nwhich allows us to have a multivariate analog of Eq. 9:\nlogP (~θt|r1:t) ≈ logP (~θt) + t∑ i=1 ri log(p̃i) (13)\n+ (1− ri) log(p̃i) (14)\nSubstituting Eq. 11 into Eq. 14 gives:\nlogP (~θt|r1:t) ≈− λ N∑ n=1 θ2tn (15)\n− γ ∑\nn,m:n≺m (θn − θm)2\n+ t∑ i=1 ri log(p̃i) + (1− ri) log(p̃i)"
    }, {
      "heading" : "4. Experimental setup",
      "text" : "Data was collected from a variety of educational products integrated with Knewton’s adaptive learning platform and used in various classroom settings across the world. These products vary with respect to the educational content used (disciplines spanned math, science, and English language learning) as well as the way in which students are guided through the content. For example, students may take an initial assessment and then be remediated on areas needing improvement. In other products, student start from the beginning and work toward a predefined goal set by the teacher. In all of these settings, Knewton receives data about each interaction (anonymized student id, content module id, correctness, and timestamp).\nWe utilized approximately 1M responses of 6.3K randomly sampled students on 105.6K questions spanning roughly 4 months. Students who worked on fewer than 5 questions total were excluded. For each student/question pair, only the most recent 4 responses were used to avoid long strings of multiple attempts on questions. After pre-processing, student history lengths ranged from 5 to 3.2K responses, including repeat attempts (see Fig 1). The overall percent correct of these responses is 54.6%."
    }, {
      "heading" : "5. Results",
      "text" : "We compare the following student response models:\n• student percent-correct (SPC): predict correct if and only if the majority of previous responses for the student are correct.\n• 2PO IRT: standard ogive model, equivalent to Eq. 9 with ν = 0 and λ = 1.0.\n• 2PO temporal IRT: same as above but with ν = 10.0.\n• Factorial MVN 2PO IRT: factorial multivariate Gaussian prior on proficiencies per concept (labelled by experts), using Eq. 15 with ν = 0, γ = 0 and λ = 1.0.\n• Correlated MVN 2PO IRT: same as above but with γ = 0.5.\n• Correlated MVN temporal 2PO IRT (T-SKIRT): same as above but with γ = 0.5, ν = 0.1.\nTo compare model performance in a task relevant for online adaptive learning systems, we measured the accuracy of predicting each student response given only the previous history of that student. For the SPC model this amounts to predicting correct if the majority of previous interactions are correct. For models with latent student abilities, this entails estimating θt (or ~θt for multi-dimensional proficiency models) by maximizing the logarithm of the (approximate) posterior probability (Eq. 9 for single-dimensional, Eq. 15 for multi-dimensional). Note that both of these objective functions are convex w.r.t. the proficiencies and are easily optimized using first- or second-order gradient-based methods. We use this estimate to predict the correctness of the next interaction via Eq. 10, and record the fraction of predictions that matched the observed responses.\nThe data was split into two parts. The first was used to estimate item difficulties (βq’s) and discriminations (αq’s) using a standard 2PO IRT model with normal priors (βq ∼ N (0, 1), αq ∼ N (1, 0.5)). The parameters λ, β, ν2 were also tuned to optimize prediction accuracy on this data set. The second data set was used to evaluate and compare the models.\nThe results are summarized in Table. 5. Adding a temporal component to the standard 2PO IRT model (using the effective discriminations in Eq. 7) yields a 2% increase in\naccuracy. Using multidimensional proficiencies based on conceptual groupings identified by experts gives a 1.6% increase. Adding information about conceptual relationships (using a correlated multivariate prior) brings this improvement to 1.9%. Combining the multidimensional prior with the temporal component yields a total of 2.8% improvement over standard 2PO IRT.\nFigure 3 plots the improvement per student as a function of the student’s overall fraction of correct responses, illustrating that the majority of the improvement comes from responses for students that are most difficult to predict. TSKIRT does slightly worse than 2PO IRT for students who are doing very well or very poorly, and we are investigating why it underperforms in this regime.\nModel Accuracy ± 1 SEM AUC SPC 0.7085 ± 0.0021 n/a 2PO IRT 0.7201 ± 0.0018 0.7954 2PO temporal IRT 0.7420 ± 0.0018 0.8119 Spherical MVN 2PO IRT 0.7362 ± 0.0016 0.8056 Correlated MVN 2PO IRT 0.7390 ± 0.0016 0.8110 T-SKIRT 0.7478 ± 0.0016 0.8194"
    }, {
      "heading" : "6. Conclusions",
      "text" : "We developed a model, T-SKIRT, for predicting student responses that addresses two major challenges faced by an adaptive learning system: accounting for student learning and handling diversity in student ability and content properties. We evaluated this model on a task required in a production environment (predicting the next response of a student given all previous responses) and found that it gives superior predictions over standard IRT-based models when applied to real student data despite the large variability in content discipline, grade level, and learning environment.\nIn contrast to (González-Brenes et al., 2013), incorporating temporality into the model yielded significant benefits over standard IRT. We also found that conceptual groupings and prerequisite relationships provided by experts also yielded significant improvement in contrast with (Lindsey et al., 2014) where expert labels did not yield better predictions.\nOur model can be improved or extended in several ways. For example, the temporal model can be augmented to account for observable events where learning is likely to occur (e.g., completing a lesson, using learning aids or hints). The model can also be extended to account for more gradual learning or forgetting of material by incorporating drift terms into the Wiener process prior. Another area of active research focuses on whether concept-module and inter-concept relationships can be automatically determined from data within this framework (e.g., (Lindsey et al., 2014; Lan et al., 2014)) and encoded in a structured prior over student proficiencies. Finally, our inference method makes an approximation of conditional independence for the sake of tractability – we find that this yields improved performance, but are also investigating the theoretical validity of this approximation."
    } ],
    "references" : [ {
      "title" : "Knowledge tracing: Modeling the acquisition of procedural knowledge",
      "author" : [ "Corbett", "Albert T", "Anderson", "John R" ],
      "venue" : "User modeling and user-adapted interaction,",
      "citeRegEx" : "Corbett et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Corbett et al\\.",
      "year" : 1994
    }, {
      "title" : "Intelligent tutoring systems",
      "author" : [ "Corbett", "Albert T", "Koedinger", "Kenneth R", "Anderson", "John R" ],
      "venue" : "Handbook of human computer interaction,",
      "citeRegEx" : "Corbett et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Corbett et al\\.",
      "year" : 1997
    }, {
      "title" : "Integrating knowledge tracing and item response theory: A tale of two frameworks",
      "author" : [ "Khajah", "Mohammad M", "Huang", "Yun", "González-Brenes", "José P", "Mozer", "Michael C", "Brusilovsky", "Peter" ],
      "venue" : "Personalization Approaches in Learning Environments,",
      "citeRegEx" : "Khajah et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Khajah et al\\.",
      "year" : 2014
    }, {
      "title" : "Time-varying learning and content analytics via sparse factor analysis",
      "author" : [ "Lan", "Andrew S", "Studer", "Christoph", "Baraniuk", "Richard G" ],
      "venue" : "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "Lan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Lan et al\\.",
      "year" : 2014
    }, {
      "title" : "Automatic discovery of cognitive skills to improve the prediction of student learning",
      "author" : [ "Lindsey", "Robert V", "Khajah", "Mohammad", "Mozer", "Michael C" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Lindsey et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Lindsey et al\\.",
      "year" : 2014
    }, {
      "title" : "Applications of item response theory to practical testing problems",
      "author" : [ "Lord", "Frederic M" ],
      "venue" : null,
      "citeRegEx" : "Lord and M.,? \\Q1980\\E",
      "shortCiteRegEx" : "Lord and M.",
      "year" : 1980
    }, {
      "title" : "Studies in mathematical psychology: I. probabilistic models for some intelligence and attainment tests",
      "author" : [ "Rasch", "Georg" ],
      "venue" : null,
      "citeRegEx" : "Rasch and Georg.,? \\Q1960\\E",
      "shortCiteRegEx" : "Rasch and Georg.",
      "year" : 1960
    }, {
      "title" : "Probabilistic models for some intelligence and attainment tests",
      "author" : [ "Rasch", "Georg" ],
      "venue" : "ERIC,",
      "citeRegEx" : "Rasch and Georg.,? \\Q1993\\E",
      "shortCiteRegEx" : "Rasch and Georg.",
      "year" : 1993
    }, {
      "title" : "Personalized learning and temporal modeling at khan academy",
      "author" : [ "Sohl-Dickstein", "Jascha" ],
      "venue" : "In Workshop on Data Driven Education in Neural Information Processing Systems (NIPS), Lake Tahoe,",
      "citeRegEx" : "Sohl.Dickstein and Jascha.,? \\Q2013\\E",
      "shortCiteRegEx" : "Sohl.Dickstein and Jascha.",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Furthermore, relationships between content are difficult to establish and represent in the model, even given expert labels (Lindsey et al., 2014).",
      "startOffset" : 123,
      "endOffset" : 145
    }, {
      "referenceID" : 2,
      "context" : "Several recent efforts have attempted to combine the complementary benefits of these two frameworks, with some success (González-Brenes et al., 2013; Khajah et al., 2014; SohlDickstein, 2013; Lan et al., 2014).",
      "startOffset" : 119,
      "endOffset" : 209
    }, {
      "referenceID" : 3,
      "context" : "Several recent efforts have attempted to combine the complementary benefits of these two frameworks, with some success (González-Brenes et al., 2013; Khajah et al., 2014; SohlDickstein, 2013; Lan et al., 2014).",
      "startOffset" : 119,
      "endOffset" : 209
    }, {
      "referenceID" : 2,
      "context" : "Several KT variants have been proposed to individually handle student abilities, multiple skills, assessment difficulty, and external aids (see (Khajah et al., 2014) and the references therein).",
      "startOffset" : 144,
      "endOffset" : 165
    }, {
      "referenceID" : 2,
      "context" : "In (González-Brenes et al., 2013; Khajah et al., 2014), a unifying framework for these is proposed where the probabilities are parameterized in terms of these observed features.",
      "startOffset" : 3,
      "endOffset" : 54
    }, {
      "referenceID" : 1,
      "context" : "These groups have been referred to as knowledge components (Corbett et al., 1997) or skills (Lindsey et al.",
      "startOffset" : 59,
      "endOffset" : 81
    }, {
      "referenceID" : 4,
      "context" : ", 1997) or skills (Lindsey et al., 2014; Lan et al., 2014).",
      "startOffset" : 18,
      "endOffset" : 58
    }, {
      "referenceID" : 3,
      "context" : ", 1997) or skills (Lindsey et al., 2014; Lan et al., 2014).",
      "startOffset" : 18,
      "endOffset" : 58
    }, {
      "referenceID" : 4,
      "context" : "These concepts and prerequisite relationships define a directed acyclic graph, and from this we can define a prior distribution over ~ θt that captures the conceptual relationships (similar to how expert labels were used in (Lindsey et al., 2014)).",
      "startOffset" : 224,
      "endOffset" : 246
    } ],
    "year" : 2017,
    "abstractText" : "We develop T-SKIRT: a temporal, structuredknowledge, IRT-based method for predicting student responses online. By explicitly accounting for student learning and employing a structured, multidimensional representation of student proficiencies, the model outperforms standard IRTbased methods on an online response prediction task when applied to real responses collected from students interacting with diverse pools of educational content.",
    "creator" : "LaTeX with hyperref package"
  }
}