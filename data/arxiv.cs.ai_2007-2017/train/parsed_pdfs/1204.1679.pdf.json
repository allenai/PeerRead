{
  "name" : "1204.1679.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Clustering and Bayesian network for image of faces classification",
    "authors" : [ "Khlifia Jayech" ],
    "emails" : [ "jayech_k@yahoo.fr", "Medali.mahjoub@ipeim.rnu.tn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "target images are sorted by feature similarities with respect to the query (CBIR). In this paper, we propose to use new approach combining distance tangent, k-means algorithm and Bayesian network for image classification. First, we use the technique of tangent distance to calculate several tangent spaces representing the same image. The objective is to reduce the error in the classification phase. Second, we cut the image in a whole of blocks. For each block, we compute a vector of descriptors. Then, we use K-means to cluster the low-level features including color and texture information to build a vector of labels for each image. Finally, we apply five variants of Bayesian networks classifiers (Naïve Bayes, Global Tree Augmented Naïve Bayes (GTAN), Global Forest Augmented Naïve Bayes (GFAN), Tree Augmented Naïve Bayes for each class (TAN), and Forest Augmented Naïve Bayes for each class (FAN) to classify the image of faces using the vector of labels. In order to validate the feasibility and effectively, we compare the results of GFAN to FAN and to the others classifiers (NB, GTAN, TAN). The results demonstrate FAN outperforms than GFAN, NB, GTAN and TAN in the overall classification accuracy.\nKeywords; face recognition, clustering, Bayesian network, Naïve Bayes, TAN, FAN\nI. INTRODUCTION\nClassification is a basic task in data mining and pattern recognition that requires the construction of a classifier, that is, a function that assigns a class label to instances described by a set of features (or attributes) [15]. Learning accurate classifiers from pre-classified data has been a very active research topic in the machine learning. In recent years, numerous approaches have been proposed in face recognition for classification such as Fuzzy sets, Rough sets, Hidden Markov Model (HMM), Neural Network, Support Vector Machine and Genetic Algorithms, Ant Behavior Simulation, Case-based Reasoning, Bayesian Networks etc. Much of the related work on image classification for indexing, classifying and retrieval has focused on the definition of low-level descriptors and the generation of metrics in the descriptor\nspace [2]. These descriptors are extremely useful in some generic image classification tasks or when classification based on query by example. However, if the aim is to classify the image using the descriptors of the object content this image.\nSeveral methods have been proposed for face recognition and classification, we quote: structural methods and global techniques. Structural techniques deal with local or analytical characteristics. It is to extract the geometric and structural features that constitute the local structure of face of image. Thus, analysis of the human face is achieved by the individual description of its different parts (eyes, nose, mouth, ..) and by measuring the relative positions of one by another. The class of global methods includes methods that enhance the overall properties of the face. Among the most important approaches, we quote Correlation Technique used by Alexandre [Lemieux 03] is based on a simple comparison between a test image and face learning, Principal component analysis approach (eigenfaces) based on principal component analysis (PCA) [52-53], discrete cosine transform technique (DCT) which based on computing the discrete cosine transform [58], Technique using Neural Networks and support vector machine (SVM) In [45].\nThere are two questions to be answered in order to solve difficulties that are hampering the progress of research in this direction. Firstly, how to link semantically objects in images with high-level features? That’s mean how to learn the dependence between objects that reflected better the data? Secondly, how to classify the image using the structure of dependence finding? Our paper presents a work which uses three variants of naïve Bayesian Networks to classify image of faces using the structure of dependence finding between objects. This paper is divided as follows: Section 2, presents an overview of distance tangent; Section 3 describes the developed approach based in Naïve Bayesian Network, we describe how the feature space is extracted; and we introduce the method of building the Naïve Bayesian network, Global Tree Augmented Naïve Bayes (GTAN), Global Forest Augmented Naïve Bayes (GFAN), Tree Augmented Naïve Bayes (TAN) and Forest Augmented Naïve Bayes (FAN)and inferring posterior probabilities out of the\nnetwork; Section 4 presents some experiments; finally, Section 5 presents the discussion and conclusions.\nII. TANGENT DISTANCE\nThe tangent distance is a mathematical tool that can compare two images taking into account small transformations (rotations, translations, etc.).. Introduced in the early 90s by Simard [60] it was combined with different classifiers for character recognition, detection and recognition of faces and recognition of speech. It is still not widely used. The distance of an image to another image I1 I2 is calculated by measuring the distance between the parameter spaces via I1 and I2 respectively. These spaces locally model all forms generated by the possible transformations between two images. When an image is transformed (e.g. scaled and rotated) by a transformation which depends on L parameters (e.g. the scaling factor and rotation angle), the set of all transformed patterns\n(1)\nis a manifold of at most dimension L in pattern space. The distance between two patterns can now be defined as the minimum distance between their respective manifolds, being truly invariant with respect to the L regarded transformations. Unfortunately, computation of this distance is a hard nonlinear optimization problem and the manifolds concerned generally do not have an analytic expression. Therefore, small transformations of the pattern xare approximated by a tangent\nsubspace to the manifold at the point x. This subspace is obtained by adding to x a linear combination of the vectors that span the tangent subspace and are the partial derivatives of with respect to . We obtain a first-order approximation of\nThe single-sided (SS) TD is defined as :\nThe tangent vectors can be computed using finite differences between the original image xand a reasonably small transformation of x. Example images that were computed using 3 are shown in Figure 1(with the original image on the left).\n.\nIII. BAYESIAN NETWORK"
    }, {
      "heading" : "A. Definition",
      "text" : "Bayesian networks represent a set of variables in the form of nodes on a directed acyclic graph (DAG). It maps the conditional independencies of these variables. Bayesian networks bring us four advantages as a data modeling tool [20- 22-24]. Firstly, Bayesian networks are able to handle incomplete or noisy data which is very frequently in image analysis. Secondly, Bayesian networks are able to ascertain causal relationships through conditional independencies, allowing the modeling of relationships between variables. The last advantage is that Bayesian networks are able to incorporate existing knowledge, or pre-known data into its learning, allowing more accurate results by using what we already know. Bayesian network is defined by :\n A directed acyclic graph (DAG) G= (V, E), where V is a set of nodes of G, and E of of G ;\n A finite probabilistic space ( ;  A set of random variables associated with graph\nnodes and defined on as :\nwhere is a set causes (parents) in graph G.\nB. Inference in bayesian network\nSuppose we have a Bayesian network defined by a graph and the probability distribution associated with (G, P). Suppose that the graph is composed of n nodes, denoted . The general problem of inference is to compute where Y X and . To calculate these conditional probabilities we can use methods of exact or approximate inferences. The first gives an accurate result, but is extremely costly in time and memory. The second turn, requires less resources but the result is an approximation of the exact solution.\nTo calculate these conditional probabilities we can use methods of exact or approximate inferences. The first gives an accurate result, but is extremely costly in time and memory. The second turn, requires less resources but the result is an approximation of the exact solution. A BN is usually transformed into a decomposable Markov network [59] for inference. During this transformation, two graphical operations are performed on the DAG of a BN, namely, moralization and triangulation."
    }, {
      "heading" : "C. Parameters learning",
      "text" : "In this case the structure is completely known a priori and all variables are observable from the data, the learning of conditional probabilities associated with variables (network nodes) may be from either a randomly or according to a Bayesian approach. The statistical learning calculation value\nfrequencies in the training data is based on the maximum likelihood (ML) defined as follows:\nwhere is the number of events in the data base for which\nthe variable in the state of his parents are in the configuration\nThe Bayesian approach for learning from complete data consists to find the most likely θ given the data observed using the method of maximum a posteriori (MAP) where :\nWith the conjugate prior distribution ; est la distribution de Dirichlet :\nAnd the posterior parameter :\nThus"
    }, {
      "heading" : "D. Structure learning",
      "text" : "Structure learning is the act of finding a plausible structure for a graph based on data input. However, it has been proven that this is an NP-Hard problem, and therefore any learning algorithm that would be appropriate for use on such a large dataset such as microarray data would require some form of modification for it to be feasible. It is explained by Spirtes et al (2001) that finding the most appropriate DAG from sample data is large problem as the number of possible DAGs grows super-exponentially with the number of nodes present. The number of possible structures is super-exponential in the number of variables. The number of possible combinations G of DAGs of n variables can be calculated by the recursive formula [20]\nIn practice we use heuristics and approximation methods like K2 algorithm."
    }, {
      "heading" : "E. Bayesian network as a classifier",
      "text" : "1) Naïve bayes\nA variant of Bayesian Network is called Naïve Bayes. Naïve Bayes is one of the most effective and efficient classification algorithms.\nThe conditional independence assumption in naïve\nBayes is rarely true in reality. Indeed, naive Bayes has been found to work poorly for regression problems (Frank et al., 2000), and produces poor probability estimates (Bennett, 2000). One way to alleviate the conditional independence assumption is to extend the structure of naive Bayes to represent explicitly attribute dependencies by adding arcs between attributes.\nConstruct-TAN procedure is described in our previous work [5].\n3) FAN\nTo improve the performance of TAN, we have added a premature stop criterion based on a minimum value of increase in the score in the search algorithms of maximum weight spanning tree. (For more details view [5]).\nIV. PROPOSED SYSTEM\nIn this section, we present two architectures of the classification system developed face. We recall the architecture developed in our article [5] and the new architecture developed in this work. In the latter, we proposed a Bayesian network for each class. So we all structures as classes in the training set. Each structure models the dependencies between different objects in the face image. The proposed system comprises three main modules: a module for extracting primitive blocks from the local cutting of facial images, a classification module of primitives in the cluster by using the method of k-means, and a classification module the overall picture based on the structures of Bayesian networks developed for each class. The developed system for faces classification is shown in the following figure:\nEmphasize at this level we will adopt two types of Bayesian networks. On the one hand, a global network (figure 5) for all classes and other one network for every class.\nThis sub-section describes the different step of the proposed system:"
    }, {
      "heading" : "A. Step 1: decomposition of images into blocks",
      "text" : ""
    }, {
      "heading" : "B. Step 2: Features Extraction",
      "text" : "The feature vector was constructed on the basis of the average (Eq. 1), the standard deviation σ (equation 2) calculated from model mixtures of Gaussians, and energy (equation 3), the entropy (Equation 4), contrast (equation 5) and homogeneity (equation 6) derived from the co-occurrence matrix of gray levels used to cut blocks of the image. These characteristics are very used in the synthesis of texture. The average gives the average value (or moderate) levels of gray from all the pixels in the region of interest (ROI). This parameter represents the location of the histogram on the scale of grays. The images that have a higher average appear brighter. The standard\ndeviation expresses the clustering (or dispersion) around the mean value. Values are more scattered, the greater the standard deviation is large. Most values are clustered around the mean, minus the standard deviation is high. Energy is a parameter that measures the homogeneity of the image. The energy has a value far lower than a few homogeneous areas. In this case, there are a lot of gray level transitions. Homogeneity is a parameter that has a behavior opposite contrast. Has more texture and more homogeneous regions of the parameter is high.\nThe mean, standard deviation, energy, entropy, contrast, and\nhomogeneity are computed as follow:\nThe means is defined as:\n(1)\nThe standard deviation is defined as:\n(2)\nThe energy is defined as:\n(3)\nThe entropy is defined as\n(4)\nThe contrast is defined as\n(5)\nThe homogeneity is defined as\n(6)"
    }, {
      "heading" : "C. Step 3: Clustering of blocs with K-means:",
      "text" : "Our aproach is based on modeling of the image by a 3x3 grid reflecting a local description of the image. So the image to be processed is considered a grid of nine blocks (figure 6). At each block we will apply the descriptors presented in the previous section.\nTo generate the label vector from vector descriptor, we used the k-means algorithm. Each vector will undergo a clustering attribute, and replace the labels generated vector components descriptors. We use the method of k-means to cluster the descriptor as shown in figure?"
    }, {
      "heading" : "D. Step 4: Structure Learning",
      "text" : "The originality of this work is the development of a Bayesian network for each class. Then, we have compared the results of this network to a global Bayesian network. We have utilized naïve Bayes, Global Structure Tree Augmented Naïve Bayes, Global Structure Forest Augmented Naïve Bayes, Tree Augmented Naïve Bayes for each class (TAN), and Forest Augmented Naïve Bayes for each class (FAN) classifiers. This sub-section describes the implementation of these methods"
    }, {
      "heading" : "E. Step 5: Parameters learning",
      "text" : "NB, TAN and FAN classifiers parameters were obtained by using the procedure as follows. In implementation of NB, TAN and FAN, we used the Laplace estimation to avoid the zero-frequency problem. More precisely, we estimated the probabilities and using Laplace estimation as follows :\nWhere - N: is the total number of training instances.\n- k: is the number of classes, - : is the number of values of attribute , - : is the number of instances in class c, - : is the number of instances in class c and with\n,\n- : is the number of instances in class c and with\n,\n- : is the number of instances in class c and with\nand ."
    }, {
      "heading" : "F. Step 6: Classification",
      "text" : "In this work the decisions are inferred using Bayesian Networks. Class of an example is decided by calculating posterior probabilities of classes using Bayes rule. This is described for both classifiers.\n NB classifier In NB classifier, class variable maximizing equation (7) is assigned to a given example.\n(7)\n TAN and FAN classifiers In TAN and FAN classifiers, the class probability P (C|A) is estimated by the following equation defined as:\nWhere is the parent of and\nThe classification criterion used is the most common maximum a posteriori (MAP) in Bayesian Classification problems. It is given by:\nV. EXPERIMENTS AND RESULTS\nIn this section, we present the results obtained using a database of images. We start by presenting the database with which we conducted our tests, then we present our results according to the used structure (global or one for each class).."
    }, {
      "heading" : "A. Data base prensentation",
      "text" : "Now, we present the results of the contribution of our approach to classify images of some examples of classes from the database used 'Database of Faces'. We have used the GTAV face database found at 1 and the ORL (figure 7) face database found at 2 . The databases are used to evaluate systems classification in the presence of facial variations in lighting conditions, facial expressions (smiling, open/closed eyes) and facial details (glasses / no glasses)."
    }, {
      "heading" : "B. Structure learning",
      "text" : "We have used Matlab, and more exactly Bayes Net Toolbox of Murphy (Murphy, on 2004) and Structure Learning Package described in (Leray and al. 2004) to learn structure. Indeed, by applying the two architectures developed and the algorithm of\n1http://gpstsc.upc.es/GTAV/ResearchAreas/UPCFaceDatabase/GTAVF\naceDatabase.htm\n2 http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\nTAN and FAN detailed in our previous work [5], we obtained the structures as follows :\nThe application of structure learning algorithm based on global image and on the basis of images from each class gave us the following results:\n- The structure of GFAN (Global FAN) returns to the structure of NB, that is to say, the attributes are\nindependent of each other. In fact, the variability of face images and the choice of a very high mutual information will decrease the degree of dependency between attributes. - On the other hand, we note that there is a dependency between the attributes of face images in the same class as\nshows the structures of class 1, 2, 3.4, and 5.\n- By comparing the structure with those of FAN TAN, we see that the choice of a very high dependency criterion\nwill eliminate weak dependencies between attributes and keeps only the bonds that represent a strong dependency between attributes and which will influence positively on the classification results.\nFAN Structure TAN structure\nStructure of class1\nStructure of class2\nStructure of class3\nStructure of class4\nStructure of class5\nFigure 9: Bayesian Network structure for each class"
    }, {
      "heading" : "C. Parameter learning",
      "text" : "After estimating the global structure of GTAN, GFAN and the structure of TAN and FAN of each class. We have used those structures to estimate the conditional and a priori probability and using Laplace\nestimation to avoid the zero-frequency problem; we obtained the results as follows (Tables I, II):"
    }, {
      "heading" : "D. Results",
      "text" : "For each experiment, we used the percentage of correct classification (PCC) to evaluate the classification accuracy defined as:\nThe results of experiments are summarized in Tables IV,V and figure 10 with number of cluster k=83, Naive Bayes, Global TAN, Global FAN, TAN and FAN use the same training set and are exactly evaluated on the same test set."
    }, {
      "heading" : "E. Naïve Bayes",
      "text" : "From the table III, we note that the naive Bayesian networks, despite their simple construction gave a very good classification rates. However, this rate is improving as we see that the classification rates obtained by class 3 is 40%. So we conclude that there is a slight dependency between the\n3 The choice of k value discussed in our previous work [5]\nattributes that must be determined by performing a structure learning."
    }, {
      "heading" : "F. Tree augmented Naïve Bayes",
      "text" : "From the table above, we note that the rate of correct classification decreases. However, there is a slight improvement in rate of correct classification using a class structure."
    }, {
      "heading" : "G. Forest augmented Naïve Bayes",
      "text" : "From the table above, we find that the rate of correct classification GFAN is the same as that obtained by naive Bayes. Since learning of GFAN structure with a strict threshold equivalent to 0.8 gave the same structure as Naïve Bayes. However, using the structure of class 1, we note that the classification rate was slightly improved to class 1. Also for the Class 3 classification rate increased from 0.4 to 0.9 using the structure for class 3 FAN"
    }, {
      "heading" : "H. Discussion",
      "text" : "According to our experiments, we observe that the naive Bayesian network gave a good result as NAT. Two factors may cause:\n The directions of links are crucial in a NAT. According to the TAN algorithm detailed in our article [5] an\nattribute is randomly selected as the root of the tree and the directions of all links are made thereafter. We note that the selection of the root attribute actually determines the structure of the TAN result, since TAN is a directed graph. Thus the selection of the root attribute is important to build a NAT.\n Of unnecessary links can exist in a NAT. According to the TAN algorithm, a spanning tree of maximum weight\nis constructed. Thus, the number of links is set to n-1. Sometimes it could be a possible bad fit of the data, since some links may be unnecessary to exist in the NAT.\nIt is observed that NB and Global Fan gave the same classification rate, since they have the same structure. We note also that the rate of correct classification given by FAN is very high that TAN. Several factors are involved:\n1- According to the FAN algorithm illustrated in our article [5], the choice of the attribute A root is defined by the\nequation below, the maximum mutual root has the information with the class.,\n. It is obvious to use this strategy, ie the attribute that has the greatest influence on the\nclassification should be the root of the tree. 2- Filtering of links that have less than a conditional mutual\ninformation threshold. These links are at high risk for a\npossible bad fit of the data which could distort the calculation of conditional probabilities. Specifically, the use of a conditional average mutual information defined in the equation below as a threshold. All links that have conditional mutual information unless Iavg are removed.\n.\nVI. CONCLUSION\nThis study is an extension of our previous work [5]. We have developed a new approach for classifying image of faces using distance tangent and the method of k-means to cluster the vectors descriptors of the images. First, we use the technique of tangent distance to calculate several tangent\nspaces representing the same image. The objective is to reduce the error in the research phase. Then we have used Bayesian network as classifier to classify the whole image into five classes. We have implemented and compared three classifiers: NB TAN and FAN using two types of structure, a global structure and structure per class presenting respectively the dependence between the attributes inter and intra-class. The goal was to compare the results obtained by these structures and apply algorithms that can produce useful information from a high dimensional data. In particular, the aim is to improve Naïve Bayes by removing some of the unwarranted independence relations among features and hence we extend Naïve Bayes structure by implementing the Tree Augmented Naïve Bayes. Unfortunately, our experiments show that TAN performs even worse than Naïve Bayes in classification. Responding to this problem, we have modified the traditional TAN learning algorithm by implementing a novel learning algorithm, called Forest Augmented Naïve Bayes. We experimentally test our algorithm in data image of faces and compared it to NB and TAN. The experimental results show that FAN improves significantly NB classifiers’ performance in classification. In addition, the results show that the mean of classification accuracy is better when the number of cluster is optimal that’s mean the number of cluster that can reflected better the data. Then, we marked that the structure of FAN per class performs better than Global FAN. This results is explained by the use of structure of FAN per class reflect better the dependence of the attribute intra-class (in the same class), and the use of a global structure reflects better the dependence inter-class (between the classes)."
    } ],
    "references" : [ {
      "title" : "On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,",
      "author" : [ "G. Eason", "B. Noble", "I.N. Sneddon" ],
      "venue" : "Phil. Trans. Roy. Soc. London,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1955
    }, {
      "title" : "A bayesian network approach to multi-feature based image retrieval",
      "author" : [ "Q. Zhang", "I. Ebroul" ],
      "venue" : "First International Conference on Semantic and Digital Media Technologies. GRECE,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2006
    }, {
      "title" : "A.A.‖A bayesian network model combining color, shape and texture information to improve content based image retrieval systems",
      "author" : [ "Rodrigues P.S", "Araujo" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2004
    }, {
      "title" : "New approach using Bayesian Network to improve content based image classification systems",
      "author" : [ "Jayech K", "Mahjoub M.A" ],
      "venue" : "IJCSI International Journal of Computer Science Issues,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2010
    }, {
      "title" : "Textural features for image database retrieval",
      "author" : [ "S.Aksoy et R.Haralik" ],
      "venue" : "IEEE Workshop on Content-Based Access of Image and Video Libraries,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1998
    }, {
      "title" : "Indexation et appariement d’images par modèle de mélange  gaussien des couleurs ",
      "author" : [ "C.Biernacki", "R.Mohr" ],
      "venue" : "Institut National de Recherche en Informatique et en Automatique, Rapport de recherche n_3600_Janvier",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2000
    }, {
      "title" : "bakan Tree augmented naïve baysian classifier with feature selection for FRMI",
      "author" : [ "Abbid Sharif", "Ahmet" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2007
    }, {
      "title" : "Learning bayesian network is NP-complete, In Learning from data: artificial intelligence and statistics V, pages 121-130",
      "author" : [ "DM Chikering" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1996
    }, {
      "title" : "Tractable bayesian learning of tree augmented naïve bayes classifiers",
      "author" : [ "Cerquides J", "R.L.Mantaras" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2003
    }, {
      "title" : "Computational complexity of probabilistic inference using bayesian belief networks",
      "author" : [ "Cooper JF" ],
      "venue" : "Artificial Intelligence, vol.42,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1990
    }, {
      "title" : "Les relations spatiales : de la moélisation à la mise en oeuvre",
      "author" : [ "Nicolas Loménie", "Nicole Viencent", "rémy Mullot" ],
      "venue" : "Revue des nouvelles technologies de l’information, cépadues éditions",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Building classifiers using bayesian networks",
      "author" : [ "Friedman N", "N.Goldszmidt" ],
      "venue" : "Proceedings of the American association for artificial intelligence conference,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1996
    }, {
      "title" : "De l’identification de structure de réseaux bayésiens à la reconnaissance de formes à partir d’informations complètes ou incomplètes",
      "author" : [ "O. Francois" ],
      "venue" : "Thèse de doctorat, Institut National des Sciences Appliquées de Rouen,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2006
    }, {
      "title" : "Learning the tree augmented naïve bayes classifier from incomplete datasets, LITIS Lab",
      "author" : [ "Francois O", "P.Leray" ],
      "venue" : "INSA de Rouen,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2008
    }, {
      "title" : "Y.Lee, S.Lin. 2D C-Tree Spatial Representation for Iconic Image",
      "author" : [ "F. Hsu" ],
      "venue" : "Journal of Visual Languages and Comp,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1999
    }, {
      "title" : "A Discriminative Representation for Symbolic Image Similarity Evaluation",
      "author" : [ "Huang G", "W.Zhang", "et L.Wenyin" ],
      "venue" : "Workshop on Graphics Recognition,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2007
    }, {
      "title" : "Réseaux Bayésiens : apprentissage et modélisation de systèmes complexes, novembre",
      "author" : [ "P. Leray" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2006
    }, {
      "title" : "Augmented naive bayesian classifiers for mixed-mode",
      "author" : [ "Li X" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2003
    }, {
      "title" : "P.H.Wuillemin, P.Leray, O.Pourret, A.Becker",
      "author" : [ "P. Naim" ],
      "venue" : "Réseaux bayésiens, Eyrolles, Paris,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2007
    }, {
      "title" : "Design and evaluation of spatial similarity approaches for image retrieval",
      "author" : [ "Patrakis EGM" ],
      "venue" : "In Image and Vision Computing",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2002
    }, {
      "title" : "Algorithmique pour les réseaux Bayésiens et leurs extensions",
      "author" : [ "Smail L" ],
      "venue" : "Thèse de doctorat,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2004
    }, {
      "title" : "Highspeed face recognition based on discrete cosine transform and RBF neural networks‖",
      "author" : [ "J.E. Meng", "W. Chen", "W. Shiqian" ],
      "venue" : "IEEE Transactions on Neural Networks,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2005
    }, {
      "title" : "Eigenfaces for recognition",
      "author" : [ "M. Turk", "A. Pentland" ],
      "venue" : "Journal of Cognitive Neuroscience,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1991
    }, {
      "title" : "Face Recognition using Boosted Local Features",
      "author" : [ "M. Jones", "P. Viola" ],
      "venue" : "IEEE ICCV",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2003
    }, {
      "title" : "2D and 3D Multimodal Hybrid Face Recognition",
      "author" : [ "A.S. Mian", "M. Bennamoun", "R.A. Owens" ],
      "venue" : "ECCV 3,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2006
    }, {
      "title" : "Face Recognition: A Literature Survey",
      "author" : [ "W. Zhao", "R. Chellappa", "P.J. Phillips", "A. Rosenfeld" ],
      "venue" : "ACM Computing Survey,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2003
    }, {
      "title" : "Component-based Face Recognition with 3D Morphable Models",
      "author" : [ "J. Huang", "B. Heisele", "V. Blanz" ],
      "venue" : "AVBPA",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2003
    }, {
      "title" : "A Wavelet-based Framework for Face Recognition. Workshop on advances in facial image analysis and recognition technology, 5 European conference on computer vision,1998",
      "author" : [ "G. Christophe", "Z. Giorgos", "T. Giorgos" ],
      "venue" : null,
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 1998
    }, {
      "title" : "Face Recognition Using Eigenfaces",
      "author" : [ "M. Turk", "A. Pentland" ],
      "venue" : "In IEEE Intl. Conf on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 1991
    }, {
      "title" : "Face Recognition by Independent Component Analysis",
      "author" : [ "M. Bartlett", "J. Movellan", "T. Sejnowski" ],
      "venue" : "IEEE Trans. on Neural Networks, 13(6):1450–1464",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Eigenfaces vs",
      "author" : [ "P. Belhumeur", "J. Hespanha", "D. Kriegman" ],
      "venue" : "Fisherfaces: Recognition Using Class Specific Linear Projection. IEEE  Trans. on Pattern Analysis and Machine Intelligence, 19(7):711–720",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "and M",
      "author" : [ "T. Ahonen", "A. Hadid" ],
      "venue" : "Pietik ̈ainen. Face Recognition With Local Binary Patterns. In European Conference on Computer Vision (ECCV), pages 469–481. Springer",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Comparison of MLP and GMM classifiers for face verification on XM2VTS",
      "author" : [ "F. Cardinaux", "C. Sanderson", "S. Marcel" ],
      "venue" : "4th Intl. Conf. Audio- and Video-based Biometric Person Authentication, AVBPA’03. Springer",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "A GMM Parts Based Face Representation for Improved Verification through Relevance Adaptation",
      "author" : [ "S. Lucey", "T. Chen" ],
      "venue" : "IEEE Intl. Conf on Computer Vision and Pattern Recognition (CVPR), pages 855– 861",
      "citeRegEx" : "37",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Face Authentication Using Adapted Local Binary Pattern Histograms",
      "author" : [ "Y. Rodriguez", "S. Marcel" ],
      "venue" : "European Conference on Computer Vision (ECCV), pages 321–332",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "N",
      "author" : [ "L. Wiskott", "J-M. Fellous" ],
      "venue" : "Kr ̈uger, and C. Von Der Malsburg. Face Recognition By Elastic Bunch Graph Matching. In 7th Intl. Conf. on Computer Analysis of Images and Patterns (CAIP), pages 456–463",
      "citeRegEx" : "39",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Hidden Markov Models for Face Recognition",
      "author" : [ "A. Nefian", "M. Hayes" ],
      "venue" : "IEEE Intl. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), volume 5, pages 2721–2724",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "User Authentication via Adapted Statistical Models of Face Images",
      "author" : [ "F. Cardinaux", "C. Sanderson", "S. Bengio" ],
      "venue" : "IEEE Trans. on Signal Processing,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2005
    }, {
      "title" : "Hybrid Face Recognition Method using Markov Random Fields",
      "author" : [ "Huang.R", "Pavlovic.V", "N. Metaxas.D", "―A" ],
      "venue" : "Proceedings of the Pattern Recognition,",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2004
    }, {
      "title" : "Système d’identification de personnes par vision numérique",
      "author" : [ "Alexandre Lemieux" ],
      "venue" : null,
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 2003
    }, {
      "title" : "Automatic Video Based Face Verification and Recognition by Support Vector Machines",
      "author" : [ "Gang Song", "Haizhou Ai", "Guangyou Xu", "Li Zhuang" ],
      "venue" : "Proceedings of SPIE Vol. 5286 Third International Symposium on Multispectral Image Processing and Pattern Recognition,",
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 2003
    }, {
      "title" : "Real-time face detection and recognition using hybrid information extracted from face space and facial features",
      "author" : [ "Hyeon Bae", "Sungshin Kim" ],
      "venue" : "Image and Vision Computing",
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 2005
    }, {
      "title" : "Towards Robust Face Recognition from Video",
      "author" : [ "Jeffery R", "Price Timothy F. Gee" ],
      "venue" : "Applied Image Pattern Recognition Workshop (AIPR",
      "citeRegEx" : "47",
      "shortCiteRegEx" : "47",
      "year" : 2001
    }, {
      "title" : "N-feature neural network human face recognition",
      "author" : [ "Javad Haddadnia", "Majid Ahmadi" ],
      "venue" : "Image and Vision Computing",
      "citeRegEx" : "50",
      "shortCiteRegEx" : "50",
      "year" : 2004
    }, {
      "title" : "Abdulredha, ―Face Detection Using DCT Coefficients in MPEG Video ",
      "author" : [ "Jun Wang", "Mohan S Kankanhalli", "Philippe Mulhem", "Hadi Hassan" ],
      "venue" : "in International Workshop on Advanced ImageTechnology,",
      "citeRegEx" : "51",
      "shortCiteRegEx" : "51",
      "year" : 2002
    }, {
      "title" : "Venkatesh,‖ An integrated automatic face detection and recognition system",
      "author" : [ "Lian Hock Koh", "Y.V. Surendra Ranganath" ],
      "venue" : "Pattern Recognition",
      "citeRegEx" : "54",
      "shortCiteRegEx" : "54",
      "year" : 2002
    }, {
      "title" : "A neural network face recognition system",
      "author" : [ "M.J. Aitkenheada", "A.J.S. McDonaldb" ],
      "venue" : "Engineering Applications of Arti.cial Intelligence 16 ",
      "citeRegEx" : "55",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Contentbased indexing of images and video using face detection and recognition methods",
      "author" : [ "Stefan Eickeler", "Frank Wallhoff", "Uri Iurgel", "Gerhard Rigoll" ],
      "venue" : "In IEEE Int. Conference on Acoustics, Speech, and Signal Processing (ICASSP),",
      "citeRegEx" : "56",
      "shortCiteRegEx" : "56",
      "year" : 2001
    }, {
      "title" : "Face recognition: a new feature selection and classification technique",
      "author" : [ "Xiaolong Fan", "Brijesh Verma" ],
      "venue" : "Proceedings of the 7th Asia- Pacific Conference on Complex Systems Cairns Converntion Centre,",
      "citeRegEx" : "57",
      "shortCiteRegEx" : "57",
      "year" : 2004
    }, {
      "title" : "Face Recognition Using the Discrete Cosine Transform",
      "author" : [ "ZIAD M. HAFED", "MARTIN D. LEVINE" ],
      "venue" : "International Journal of Computer Vision 43(3), 167–188",
      "citeRegEx" : "58",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "A tutorial on learning with Bayesian networks",
      "author" : [ "D. Heckerman" ],
      "venue" : "Technical Report MSR-TR-95-06,",
      "citeRegEx" : "59",
      "shortCiteRegEx" : "59",
      "year" : 1995
    }, {
      "title" : "Transformation Invariance in Pattern Recognition — Tangent Distance and Tangent Propagation",
      "author" : [ "P. Simard", "Y. Le Cun", "J. Denker", "B. Victorri" ],
      "venue" : "G. Orr and K.-R. M ̈uller, editors, Neural networks: tricks of the trade, volume 1524 of Lecture Notes in Computer Science, Springer, Heidelberg, pages 239–274",
      "citeRegEx" : "60",
      "shortCiteRegEx" : null,
      "year" : 1998
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "INTRODUCTION Classification is a basic task in data mining and pattern recognition that requires the construction of a classifier, that is, a function that assigns a class label to instances described by a set of features (or attributes) [15].",
      "startOffset" : 238,
      "endOffset" : 242
    }, {
      "referenceID" : 49,
      "context" : "Among the most important approaches, we quote Correlation Technique used by Alexandre [Lemieux 03] is based on a simple comparison between a test image and face learning, Principal component analysis approach (eigenfaces) based on principal component analysis (PCA) [52-53], discrete cosine transform technique (DCT) which based on computing the discrete cosine transform [58], Technique using Neural Networks and support vector machine (SVM) In [45].",
      "startOffset" : 372,
      "endOffset" : 376
    }, {
      "referenceID" : 40,
      "context" : "Among the most important approaches, we quote Correlation Technique used by Alexandre [Lemieux 03] is based on a simple comparison between a test image and face learning, Principal component analysis approach (eigenfaces) based on principal component analysis (PCA) [52-53], discrete cosine transform technique (DCT) which based on computing the discrete cosine transform [58], Technique using Neural Networks and support vector machine (SVM) In [45].",
      "startOffset" : 446,
      "endOffset" : 450
    }, {
      "referenceID" : 51,
      "context" : "Introduced in the early 90s by Simard [60] it was combined with different classifiers for character recognition, detection and recognition of faces and recognition of speech.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 50,
      "context" : "A BN is usually transformed into a decomposable Markov network [59] for inference.",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 16,
      "context" : "The number of possible combinations G of DAGs of n variables can be calculated by the recursive formula [20]",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 3,
      "context" : "Construct-TAN procedure is described in our previous work [5].",
      "startOffset" : 58,
      "endOffset" : 61
    }, {
      "referenceID" : 3,
      "context" : "(For more details view [5]).",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 3,
      "context" : "We recall the architecture developed in our article [5] and the new architecture developed in this work.",
      "startOffset" : 52,
      "endOffset" : 55
    }, {
      "referenceID" : 3,
      "context" : "TAN and FAN detailed in our previous work [5], we obtained the structures as follows :",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 3,
      "context" : "3 The choice of k value discussed in our previous work [5] attributes that must be determined by performing a structure learning.",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 3,
      "context" : "According to the TAN algorithm detailed in our article [5] an attribute is randomly selected as the root of the tree and the directions of all links are made thereafter.",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 3,
      "context" : "1- According to the FAN algorithm illustrated in our article [5], the choice of the attribute A root is defined by the equation below, the maximum mutual root has the information with the class.",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 3,
      "context" : "CONCLUSION This study is an extension of our previous work [5].",
      "startOffset" : 59,
      "endOffset" : 62
    } ],
    "year" : 2011,
    "abstractText" : "In a content based image classification system, target images are sorted by feature similarities with respect to the query (CBIR). In this paper, we propose to use new approach combining distance tangent, k-means algorithm and Bayesian network for image classification. First, we use the technique of tangent distance to calculate several tangent spaces representing the same image. The objective is to reduce the error in the classification phase. Second, we cut the image in a whole of blocks. For each block, we compute a vector of descriptors. Then, we use K-means to cluster the low-level features including color and texture information to build a vector of labels for each image. Finally, we apply five variants of Bayesian networks classifiers (Naïve Bayes, Global Tree Augmented Naïve Bayes (GTAN), Global Forest Augmented Naïve Bayes (GFAN), Tree Augmented Naïve Bayes for each class (TAN), and Forest Augmented Naïve Bayes for each class (FAN) to classify the image of faces using the vector of labels. In order to validate the feasibility and effectively, we compare the results of GFAN to FAN and to the others classifiers (NB, GTAN, TAN). The results demonstrate FAN outperforms than GFAN, NB, GTAN and TAN in the overall classification accuracy. Keywords; face recognition, clustering, Bayesian network, Naïve Bayes, TAN, FAN",
    "creator" : "Conv2pdf.com"
  }
}