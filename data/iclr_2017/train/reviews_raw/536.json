{"conference": "ICLR 2017 conference submission", "title": "On Robust Concepts and Small Neural Nets", "abstract": "The universal approximation theorem for neural networks says that any reasonable function is well-approximated by a two-layer neural network with sigmoid gates but it does not provide good bounds on the number of hidden-layer nodes or the weights. However, robust concepts often have small neural networks in practice. We show an efficient analog of the universal approximation theorem on the boolean hypercube in this context.  We prove that any noise-stable boolean function on n boolean-valued input variables can be well-approximated by a two-layer linear threshold circuit with a small number of hidden-layer nodes and small weights, that depend only on the noise-stability and approximation parameters, and are independent of n. We also give a polynomial time learning algorithm that outputs a small two-layer linear threshold circuit that approximates such a given function. We also show weaker generalizations of this to noise-stable polynomial threshold functions and noise-stable boolean functions in general.", "reviews": [{"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "The paper makes a solid technical contribution in establishing a universal approximation theorem for the boolean hypercube. They characterize the class of boolean functions that can be efficiently approximated by a two-layer network.\n \n We like the idea of noise stability, and it could explain why in practice, perturbation techniques such as dropout are effective. Moreover, humans can identify images, despite corruptions, and hence, intuitively the concepts we aim to learn should be robust.\n \n However, the framework of the paper deviated from the networks and data structures that are the norm in practice. In practice, we rarely have boolean functions. And it is well known that boolean functions can behave quite differently from continuous functions. \n \n We recommend that the authors widen the scope of their work, and attempt to connect their findings to practical networks and functions. Moreover, we recommend that they do a more thorough literature survey. For instance, the idea of robust concepts has appeared before\n ", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "review of ``ON ROBUST CONCEPTS AND SMALL NEURAL NETS''", "is_meta_review": false, "comments": "SUMMARY \nThis paper presents a study of the number of hidden units and training examples needed to learn functions from a particular class. \nThis class is defined as those Boolean functions with an upper bound on the variability of the outputs. \n\nPROS\nThe paper promotes interesting results from the theoretical computer science community to investigate the efficiency of representation of functions with limited variability in terms of shallow feedforward networks with linear threshold units. \n\nCONS \nThe analysis is limited to shallow networks. The analysis is based on piecing together interesting results, however without contributing significant innovations. \nThe presentation of the main results and conclusions is somewhat obscure, as the therein appearing terms/constants do not express a clear relation between increased robustness and decreasing number of required hidden units. \n\nCOMMENTS \n\n- In the abstract one reads ``The universal approximation theorem for neural networks says that any reasonable function is well-approximated by a two-layer neural network with sigmoid gates but it does not provide good bounds on the number of hidden-layer nodes or the weights.'' \n\nIn page 1 the paper points the reader to a review article. It could be a good idea to include also more recent references. \n\nGiven the motivation presented in the abstract of the paper it would be a good idea to also comment of works discussing the classes of Boolean functions representable by linear threshold networks. \nFor instance the paper [Hyperplane Arrangements Separating Arbitrary Vertex Classes in n-Cubes. Wenzel, Ay, Paseman] discusses various classes of functions that can be represented by shallow linear threshold networks and provides upper and lower bounds on the number of hidden units needed for representing various types of Boolean functions. In particular that paper also provides lower bounds on the number of hidden units needed to define a universal approximator. \n\n- It certainly would be a good idea to discuss the results on the learning complexity in terms of measures such as the VC-dimension. \n\n- Thank you for the explanations regarding the constants.  \nSo if the noise sensitivity is kept constant, larger values of epsilon are associated with a smaller value of delta and of 1/epsilon. \nNonetheless, the description in Theorem 2 is in terms of poly(1/epsilon, 1/delta), which still could increase? \nAlso, in Lemma 1 reducing the sensitivity at a constant noise increases the bound on k? \n\n- The fact that the descriptions are independent of n seems to be related to the definition of the noise sensitivity as an expectation over all inputs. This certainly deserves more discussion. One good start could be to discuss examples of functions with an upper bound on the noise sensitivity (aside from the linear threshold functions discussed in Lemma 2). \nAlso, reverse statements to Lemma 1 would be interesting, describing the noise sensitivity of juntas specifically, even if only as simple examples. \n\n- On page 3 ``...variables is polynomial in the noise-sensitivity parameters'' should be inverse of?\n\nMINOR COMMENTS\n\nOn page 5 Proposition 1 should be Lemma 1? \n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "TITLE": "A work that finds connections between existing theoretical results and the universal approximation theorem", "is_meta_review": false, "comments": "This work finds a connection between Bourgain's junta problem, the existing results in circuit complexity, and the approximation of a boolean function using two-layer neural net. I think that finding connections between different fields and applying the insights gained is a valid contribution. For this reason, I recommend acceptance.\n\nBut my current major concern is that this work is only constrained to the domain of boolean hypercube, which is far from what is done in practice (continuous domain). Indeed, the authors could argue that understanding the former is a first step, but if the connection is only suitable for this case and not adaptable to more general scenarios, then it probably would have limited interest.", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 2}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "This paper provides an analog of the universal approximation theorem where the size of the network depends on a notion of noise-stability instead of the dimension.", "is_meta_review": false, "comments": "The approximation capabilities of neural networks have been studied before for approximating different classes of functions. The goal of this paper is to provide an analog of the approximation theorem for the class of noise-stable functions. The class of functions that are noise-stable and their output does not significantly depend on an individual input seems an interesting class and therefore I find the problem definition interesting.  The paper is well-written and it is easy to follow the proofs and arguments. \n\nI have two major comments:\n\n1- Presentation: The way I understand this arguments is that the noise-stability measures the \"true\" dimensionality of the data based on the dependence of the function on different dimensions. Therefore, it is possible to restate and prove an analog to the approximation theorems based on \"true\" dimensionality of data. It is also unclear when the stability based bounds are tighter than dimension based bounds as both of them grow exponentially. I find these discussions interesting but unfortunately, the authors present the result as some bound that does not depend on the dimension and a constant (!??) that grows exponentially with (1/eps). This is not entirely the right picture because the epsilon in the stability could itself depend on the dimension. I believe in most problems (1/epsilon) grows with the dimension. \n\n2- Contribution: Even though the connection is new and interesting, the contribution of the paper is not significant enough. The presented results are direct applications of previous works and most of the lemmas in the paper are restating the known results. I believe more discussions and results need to be added to make this a complete work.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "15 Dec 2016 (modified: 14 Jan 2017)", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Application of previous results?", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "", "IS_META_REVIEW": false, "DATE": "03 Dec 2016", "is_meta_review": false}, {"TITLE": "Exponential dependence on epsilon", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_META_REVIEW": false, "DATE": "03 Dec 2016", "is_meta_review": false}, {"TITLE": "Sensitivity vs size", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "", "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "is_meta_review": false}], "authors": "Amit Deshpande, Sushrut Karmalkar", "KEYWORDS": "an efficient analog of the universal approximation theorem for neural networks over the boolean hypercube", "accepted": false, "id": ""}
