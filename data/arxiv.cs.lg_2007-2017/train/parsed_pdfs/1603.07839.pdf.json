{
  "name" : "1603.07839.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Early Detection of Combustion Instabilities using Deep Convolutional Selective Autoencoders on Hi-speed Flame Video",
    "authors" : [ "Adedotun Akintayo", "Kin Gwn Lore", "Soumalya Sarkar", "Soumik Sarkar" ],
    "emails" : [ "akintayo@iastate.edu", "kglore@iastate.edu", "sms388@gmail.com", "soumiks@iastate.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords deep convolutonal networks; selective autoencoder; combustion instability; Implicit labeling"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Deep Learning models have been shown to outperform all other state-of-the-art machine learning techniques for handling very large dimensional data spaces and learn hierarchical features in order to perform various machine learning tasks. However, most of the studied applications primarily have been in the domains of image, speech and texts processing. For example, convolutional neural network-based applications include Graph Transformer Networks (GTN) for rapid, online recognition of handwriting [22], natural language processing [8], large vocabulary continuous speech recognition [31] and avatar CAPTCHA machine image recognition [7] by training machines to distinguish between human faces and computer generated faces. In this paper, we propose a novel selective autoencoder approach within a deep convolutional architecture for implicit labeling in order to derive soft labels from extreme classes that are explicitly labeled as either positive or negative examples. This particular property is significant for tracking continuous temporal phenomenon such as the transition from combustion stability to instability, where labels of extreme states (stable or unstable) are available but intermediate state labels are not. Explicit labels are utilized to selectively mask selective features while allowing other features to remain. Figure 1 shows greyscale images describing typical gradual development of instability at the stated parameters in the swirl-stabilized combustor used for the experiment.\nLabeling (e.g., structured and implicit) can be considered a multi-class classification problem [10]. For example, three stage Hidden Markov Models (HMM) were used for handling speech recognition [26] problems, parts of speech tagging [25] and sequence labeling because they derive the relationships from observations to state and state to state in dynamic systems. Maximum Entropy Markov Model (MEMM) a discriminative modification of HMM was introduced to overcome the latter’s recall and precision problems especially in labeling texts. In those models, conditional probability of the desired labels are learnt directly based on the un-\nar X\niv :1\n60 3.\n07 83\n9v 1\n[ cs\n.C V\n] 2\ncertainty maximization idea. Applications of MEMM for natural language processing can be found in [3].\nDue to ”label bias” defects of MEMM, a Conditional Random Field (CRF), which is a joint Markov Random Field (MRF) of the states conditioned on the whole observations was later explored by [20]. It enabled considering the global labels of the observation as against localization of labels of MEMM [10]. However, labeling in this case is made computationally complex by the relaxation of statistical independence assumption of the observations which most of the models assume.\nRecurrent Neural Networks (RNNs) have been utilized for sequence labeling problems due to its cyclic connections of neurons [14] as well as its temporal modeling ability. Although earlier construction of RNNs was known to have short ranged memory issues and a restrictive unidirectional information context access, formulation of a bidirectional Long Short Term Memory (LSTM) [15] resolved such issues. However, this construction adds to the complexity of the model significantly as typically two RNNs get connected through same output layer.\nFrom the application standpoint, early detection of instability in the combustion chambers of dynamic systems aids anticipative actions for reducing its consequent effects. Visualizing the features characterizing the intermediate frames of its spectrum is an important approach to unravel the processes that precedes instability. The authors [28] introduced Deep Belief Networks, DBNs as a viable technique to achieve the aim with a view to exploring other machine learning for confirmation. They improved on that by applying a modular neural-symbolic approach [27] in another publication.\nIn this paper, we propose a deep convolutional selective autoencoder-based anomaly detection framework for the crucial physical process of combustion where a pure black box model is unacceptable in order to enable domain interpretation and better understanding of the underlying complex physics. Combustion instability is a significant anomaly characterized by high-amplitude flame oscillations at discrete frequencies that reduces the efficiency and longevity of aircraft gas-turbine engines. Full-blown instability can be differentiated from stable combustion via video analysis with high confidence because unstable combustion flames show distinct coherent structures similar to ’mushroom’ shapes. But it is extremely difficult to detect an onset of instability early due fast spatio-temporal transience in the video data. Therefore, the instability detection problem boils down to an\nimplicit soft labeling problem where we train a deep model using hi-speed flame videos with explicit labels of stable and unstable flames such that it recognizes onset of instability early as the combustion process makes transition from a stable to unstable region.\nConceptually, this is similar to cognitive psychologists’ description of human reasoning in object classification [33]. An example is to consider how a child is taught on intrinsic classes. A similar problem is detecting a cross breed of dog and wolf including how close the animal is to either of the classes. Contributions: The main contributions of this paper is delineated below:\n• a convolutional selective autoencoder framework based on emerging deep learning techniques is proposed for early detection of combustion instability,\n• the method avoids extensive expert-guided feature handcrafting [11] while addressing a complex physical phenomenon like combustion to discover coherent structures in the images,\n• the proposed framework is able to learn from high dimensional datasets (e.g, high speed video) of most applications and provide a platform for determining the degree of relationship between the states of two temporally close observations,\n• A metric to desired level of granularity is constructed to track the onset of combustion instability and detect pre-transition phenomena such as ’intermittence’. Intermittence is a temporary (of the order of millisecond) blast of instability characterized by small and partially observable coherent structure.\n• extensive validation is provided based on laboratoryscale combustion data collected under various realistic operating conditions.\nPaper organization: The paper was introduced earlier in this section with an idea of the motivating problem. The next section is set apart to discuss: prior work on the proposed approach, the chosen problem, and an essential part of the attack technique. In section 3, the main architecture for the problem is discussed followed by a measure of similarity to access the result quantitatively. Section 4 provided an opportunity to introduce the problem dataset collection and then the implementation of the composite architecture. The results obtained for the hypothesis is discussed in section 5 after which we conclude the paper in section 6 as well as give some insights to the direction of future works."
    }, {
      "heading" : "2. BACKGROUND",
      "text" : "This section provides a brief overview of convolutional networks, a description of the example problem of detecting combustion instability, and the notion of implicit labeling."
    }, {
      "heading" : "2.1 Convolutional networks",
      "text" : "Convolutional networks [18] are a type of deep networks that offer discriminative advantages as in the MEMM as well as providing globally relationship between observations as in the CRF. The architectures rely primarily on local neighborhood matching for data dimension reduction using nonlinear mapping (i.e. sigmoid, softmax, hyperbolic tangent). Each\nunit of the feature maps has common shared weights or kernels for efficient training in relatively - compared to fully connected layers - lower trainable parameters, added to an additive bias on which is squashed. Feature extraction and classifier learning are the two main functions of these networks [22]. However, to learn the most expressive features, we have to determine the invariance rich codes embedded in the raw data and then follow with a fully connected layer to reduce further the dimensionality of the data and map the most important codes to a low dimension of the examples. Many image processing and complex simulations depend on the invariance property of the convolution neural network stated in [21] to prevent overfitting by learning expressive codes.\nThe feature maps are able to preserve local neighborhood patterns for each receptive field as with over-complete dictionaries in [1]. The fully connected layers tend to complement the learned features by propagating only the highly active weights and serving as the classifier. A more detailed review may be found in [22] where the authors note the advantage of local correlation enforcing convolution before spatio-temporal recognition. For efficient learning purposes, convolutional networks are able to utilize distributed mapreduce frameworks [12] as well as GPU computing."
    }, {
      "heading" : "2.2 The problem of combustion instability",
      "text" : "Combustion instability reduces the efficiency and longevity of aircraft gas-turbine engines. It is considered a significant anomaly characterized by high-amplitude flame oscillations at discrete frequencies. These frequencies typically represent the natural acoustic modes of the combustor. Combustion instability arises from a positive coupling between the heat release rate oscillations and the pressure oscillations. Coherent structures are fluid mechanical structures associated with coherent phase of vorticity [16]. These structures, whose generation mechanisms vary system wise, cause large scale velocity oscillations and overall flame shape oscillations by curling and stretching. These structures can be caused to shed/generated at the duct acoustic modes when the forcing (pressure) amplitudes are high. There is a lot of recent research interest on detection and correlation of these coherent structures to heat release rate and unsteady pressure. The popular methods resorted for detection of coherent structures are proper orthogonal decomposition (POD) [5] (similar to principal component analysis [6]) and dynamic mode decomposition (DMD) [30], which use tools from spectral theory to derive spatial coherent structure modes."
    }, {
      "heading" : "2.3 Implicit labeling",
      "text" : "Semi-supervised training for classification takes advantage of the labels at the final layers. A variant of structured labeling by [19] called implicit labeling is used to derive soft labels from extreme classes that are explicitly labeled as either positive or negative examples. Explicit labels usually can be utilized to selectively mask one feature, especially that one is not interested in while leaving parsing the class of interest. However, explicit labels on its own can only serve as a classifier for intrinsic classes in the test sets learnt from the training set.\nImplicit labeling here also bears similarity to the sequence labeling [10] with an extra constraint of utilizing prior knowledge provided only by explicit label. It is then fused with convolutional auto-encoder architecture algorithm described\nin section 3 to determine the intermediate or transition phases– a mixed breed of a dog and a wolf for instance–and more importantly to what degree is the animal is dog or a wolf. Thus, it attempts to derive soft labels from expert-informed, hard-mined labels as illustrated in fig. 2 with a composite architecture."
    }, {
      "heading" : "3. CONVOLUTIONAL SELECTIVE AUTOENCODER",
      "text" : "Based on the convolutional network’s (convnet for short) performances on several similar tasks reviewed, it was found a suitable candidate for the composite architecture to examine our hypothesis of soft label generation. Having previously utilized convnet architecture, an end-to-end convolutional auto-encoder (as shown in fig. 3), designed and tested to examine another perspective to the current problem instead of adding a symbolic graphical model such as STSA [27] at the top level. The constituent steps for the model to learning from the data are outlined below.\nExplicit labels and pre-processing: Given an M × N dimensional image frames and corresponding ground truth labels (one of the two classes), explicit labels are generated by selectively masking frames with the undesired class with black pixels. Hence, N pairs of input-output pairs {(Xi, Yi)} for i = 1, 2, ..., N are generated where X represents the original images, Y are the masked frames that are considered explicitly as ground truth. The images are then normalized where pixel intensities have zero mean and a standard deviation of 1 as preprocessing.\nConvolutional layers: Convolutional autoencoders start with propagation from the input layer to the convolution layer while the penultimate step to the output layer is the deconvolution layer. At each convolution or deconvolution layer, a chosen (c×c) filter size is convolved with the patches to learn a zo−dimensional feature map from which joint weight over the zi−dimensional feature maps that are useful for enforcing local correlation is learnt to characterize all maps as follows:\nŶzo(m−c+1)(n−c+1) = C[Xzimn ? Wzicc + bc] (1)\nwhere C is the squashing function, ? denoting the convolution operator of the joint weights, Wzicc, bc the biases and input from previous layer Xzimn. To enhance the invariance further, pooling is done for representative features selection in a local neighborhood. While other pooling schemes exist [29], we chose the highly activated units to take up the features for the local p× p neighborhood in the maxpooling\ncase. It is expressed as:\nŶzikl = max i∈I; i→i+p j∈J; j→j+p (Ŷziij) (2)\nwhere zi is the number of receptive fields of the input feature maps, Ŷzikl is the pooled feature map, Ŷziij is the input from a previous layer, and I = {1 + (k− 1)(p+ 1), · · · }, J = {1+(l−1)(p+1), · · · } where i = 1, 2, ..., h and j = 1, 2, ..., v and h, v denote the horizontal and vertical input dimensions respectively.\nFully connected layers: Feature maps from previous layers are flattened into row vectors and are passed through the bottleneck layer. The encoding layer encodes the most important feature from the input of the previous layer with the following expression:\nŶe = E[WeŶ + be] (3)\nand the decoder is given by:\nŶd = D[WdŶe + bd] (4)\nwhere E and D stands for the encoder and decoder functions respectively, which are both the same nonlinear function known as the rectified linear unit (ReLU). b denotes the biases and W denotes the weights of the layer. The subscripts e and d indicates the encoder and decoder. The ReLU nonlinearity performed on the argument f is given by:\nReLU(f) = max(0, f) (5)\nIntuitively, it has the advantage of easier training compared to other nonlinearity types because the activations of each neuron is a piece-wise linear function of argument f and do not saturate.\nUnpooling: In this layer, a reversal of the pooled dimension is done by stretching and widening [17] the identified features from the filters of the previous layer. It is also an upscaling of the feature maps around the axes of symmetry where the reconstructed feature maps are optimized through the back-propagation algorithm.\nError minimization: This phase is akin to a feedback stage in a control paradigm or a scenario where a teacher– labeled data–provides feedback in performance measure on how well a student–the machine–has learned features related to a particular application–the task. The process included a regularization function as in [22] to avoid overfitting the data. The Nesterov momentum-based [32] stochastic gradient descent was used for improved results when compared to other loss functions such as adaptive subgradient (ADAGRAD) [9] and adaptive learning rate method (ADADELTA) [35] for the reconstruction error updates given\nthe reconstructed output Ŷmn and the labels, Ymn. Let θ = {W,b} be the set of weights and biases for all layers that are to be optimized by minimizing the loss function L(θ). The loss function is expressed as:\nL(θ) = Ltrain(θ) + σR(W ) (6)\nwhere σ is a parameter controlling the regularization function R(W ). R(W ) that has the following form:\nR(W ) = ( ∑ l ∑ Wdim W 2l ) 1 2 + ∑ l ∑ Wdim |Wl| (7)\nwhere l represents the layer and Wdim represents the dimension of the weights at each layer. The works in [2] points out that that SGD with early stopping is equivalent to an `2− regularization. The mean square error training loss is given\nas:\nLtrain(θ) = 1\nmn m∑ i=1 n∑ j=1 (Yij − Ŷij)2 (8)\nSubsequently, the weights are updated for each time step via stochastic gradient descent [22]:\nWt = Wt−1 − α ∂L(W )\n∂W (9)\nwhere α is the learning rate equivalent of step size in optimization problems. More details can be found in [24] while the background materials presented thus far and those in subsection 3.1 are the more important aspects with embedded improvements."
    }, {
      "heading" : "3.1 Instability measure",
      "text" : "The similarity index selected for instability measure is the correlation ratio reported in [13] and mathematically proven by [23] to have low computational requirement as a way of reducing the already-large computation architecture. Also useful was its ability to quantify the relationship between two image frames with differing intensities as well as not directly including the actual images in the computation, hence its choice as our performance metric. Assuming that the input image X has pixels x ∈ X with intensities xi ∈ (1, 255) for i = 1, 2, ... and the inferred output frames denoted as Y , the correlation ratio is calculated by computing the total and conditional variances σ and σi in Y :\nσi = 1\nZi ∑ xi (Y [xi]) 2 − ( 1 Zi ∑ Y [xi]) 2 (10)\nand:\nσ = 1\nZ ∑ X (Y [x])2 − ( 1 Z ∑ Y [x])2 (11)\nUsing these equations, the correlation ratio is found as:\nδ = 1\nZσ ∑ i Ziσi (12)\nwhere Zi and Z are enumerations of the pixels in xi and X respectively. Like other chosen measure of dissimilarity such as `1 and `2 norm, the correlation ratio usually varies from 0 for uncorrelated images and 1 for fully correlated images."
    }, {
      "heading" : "4. DATASET AND IMPLEMENTATION",
      "text" : "Dataset collection and Experimental setup: To collect training data for learning coherent structures, thermoacoustic instability was induced in a laboratory-scale combustor with a 30 mm swirler (60 degree vane angles with geometric swirl number of 1.28). Figure 5 (a) shows the setup and a detail description can be found in [28]. In the combustor, 4 different instability conditions are induced: 3 seconds of hi-speed videos (i.e., 9000 frames) were captured at 45 lpm (liters per minute) FFR (fuel flow rate) and 900 lpm AFR (air flow rate), and at 28 lpm FFR and 600 lpm AFR for both levels of premixing. Figure 5 (b) presents sequences of images of dimension 100×237 pixels for unstable (AFR = 900lpm, FFR = 45lpm and full premixing) state. The flame inlet is on the right side of each image and the flame flows downstream to the left. As the combustion is unstable, figure 5 (b) shows formation of mushroom-shaped vortex (coherent structure) at t = 0, 0.001s and the shedding\nof that towards downstream from t = 0.002s to t = 0.004s. For testing the proposed architecture, 5 transition videos of 7 seconds length were collected where stable combustion progressively becomes unstable via ’intermittence’ phenomenon (fast switching between stability and instability as a precursor to persistent instability) by reducing FFR or increasing AFR. The transition conditions are as follows (all units are lpm): (i) AFR = 500 and FFR = 40 to 28, (ii) AFR = 500 and FFR = 40 to 30, (iii) FFR = 40 and AFR = 500 to 600, (iv) AFR = 600 and FFR = 50 to 35, (v) FFR = 50 and AFR = 700 to 800. For clarity, these data sets are named as 50040to38, 50040to30, 40500to600, 60050to35, and 50700to800 respectively for analysis in the subsequent sections of this paper.\nTraining process: The architecture inputs and implementation for model learning from data by the architecture are described in this part. In training the network, 63, 000 gray scale frames having dimensions 100 × 237 are resized to 64 × 64 for computational simplicity. A total of 35, 000 frames was labeled stable while the remaining 28, 000 were labeled unstable. These images were a combination of datasets with different premixing lengths of either 90mm or 120mm and a wide range of air and fuel LPMs for which the combustor is either in a stable or an unstable state. A learning rate of 0.0001 with momentum = 0.975 was found to train the model best in the Nesterov based stochastic gradient descent formulation. The network was trained to 100 epochs in order to conveniently strike a good minima of the validation error. As stated earlier, `2−regularization parameters of 0.0001 each were added to widen the parameter search space for locating the minima by helping to minimize the difference between the test and training. Also, the `1 enhances the sparsity of the algorithm while ensuring that only the most likely units are activated. Training was done on GPU Titan Black with 2880\nCUDA cores, equipped with 6GB video memory, using the python-based machine learning frameworks such as Theano, Lasagne and NoLearn [4] [34]. Lasagne offers a wide variety of control over the layer types, nonlinearity types, objective functions, interfacing with Theano, and many other features\nbuilt into it. NoLearn, on the other hand, is a coordinating library for the implementation of the layers in Lasagne which offers model visualization features. While training, a filter of c × c pixels (c = 3 in the implementation) and a non-overlapping p × p (p=2) maxpooling were found to be experimentally less costly to produce the results. Algorithm training was done in batches of 128 training examples which was found to be suitable via cross validation. Note that the batch iterative training in NoLearn and Lasagne functions were replaced with Theano’s LeNet 5 [22] early stopping algorithm which showed further improvements in test performance. The architecture in fig. 3 shows how the layers\nare interlinked in the training stage which leads to an overall of 5, 090, 249 learnable parameters. The training progress is indicated by the algorithm’s loss profile fig. 4 showing the validation loss, validloss, reduction as well as training loss denoted as trainloss. Note that the training loss was raised by lowering the regularization parameter in order to allow for more training epochs. This helps to reduce the validation loss more for better result. Leveraging the capability of GPU, generating results from the trained model based on a transition sequence of 21, 841 frames took ≈ 35.5secs.\n5. RESULTS AND DISCUSSIONS\nIn this section, some results obtained from the algorithm are discussed and analyzed closely. First, we consider the detection of the presence of region two properties in frames supposedly of region 1 in the early instability detection paradigm. Then we discuss how the network explores the space between the stable and unstable regions to get softer labels assuming the system were static.\nEarly Detection of combustion instability: Let the stable region be denoted by SR on one end of the spectrum and the unstable region be UR on the other end of the spectrum. For emphasis, training of the algorithm was done with explicitly available ground truth labels. These were categorized into frames of stable flame types and frames of unstable flame types. Any unit of frames in the stable region are then given labels of ’0’ while those of the unstable region were retained in algorithm training. Figure 8 shows the algorithm’s ability to reproduce such training in one of the frames trained on. The algorithm’s selective ability is shown by fig. 8. Feature maps from the model are shown in fig. 9 to highlight the detected features and the reconstructed outputs.\nSome important feature maps are visualized in in fig. 9. The fully connected layers serve at least two important purposes, namely: (1) to reduce further the image dimensions towards only rich explanatory features, and (2) ensuring structural consistency via reshaping to gradually restore the feature maps and output images into dimensions similar to the input.\nFor frames in the unstable region, the corresponding feature maps showed more activated units responding to the mushroom structures characteristic to unstable combustion. These are highlighted in fig. 9. For those from the stable region, information is seen to be rapidly diffusing from the input into the hidden layers. At each layer, joint parameters capture the trade-off between discarded and retained information from the stable and unstable training sets. Based on the understanding so far, it is hypothesized that the trained model could identify frames having flame types intersecting both stable and unstable regions as discussed in the motivating example. The subsequent parts of the section are devoted to this analysis.\nAfter running the test data (the inputs) under different transition conditions through the trained model, the results are presented in in fig. 7. The figure shows the capability of the model in suppressing unwanted features (the unstable flame images) through masking and revealing the desired\nanomaly features (the stable flame images). Note that similarity measure introduced in section 3.1 was used to evaluate the strength of the algorithm’s ability to mask examples closer to the stable region compared to those nearer to the unstable region. Thereafter, a local regression smoothing was applied to obtain weighted moving averages for visualizing the transitional trends.\nThe general trends and fluctuations in instability measures are shown in fig. 7. These results are similar to those reported in [27] where the framework used a neural-symbolic approach with a combination of convolutional neural networks and symbolic time series analysis to obtain instability measures. In fig. 7(a), output frames from the stable region is suppressed while output frames from the unstable region is entirely visible. Essentially, the model has become a filter which only enables desired features to show up in\nthe outputs. A worthy mention is that intermittency is a precursor to combustion instability. In these regions, the train model produces an output that partially reveals the unstable features as highlighted in fig. 7(b). The same phenomenon can be observed in fig. 7(c). As reported in [27], these intermittency phenomena can not be observed from pressure data or POD analysis of image data. Hence the proposed metric localizes the intermittencies prior to fullblown instability with more prominence than other state-ofthe-art approaches [27]. Better accuracy in tracking intermittence leads to an early detection of instability with less false alarm [27].\nFrame labeling: A computationally complex decision in attempting implicit labeling with these results would be to search through all the frames for adjacent neighbors to a given frame. In clear terms, this means finding which frames come before and after any chosen frame. This kind of search is usually difficult with most primitive low dimensional local labeling algorithms, HMM and MEMM due to dependency depth and labeling bias limitations respectively. We hypothesize that simplifying any such high dimensional problem using a single value, average instability measure through the composite convolutional auto-encoder would facilitate soft labeling. This is especially required in the regions before and after the abrupt transitioning from SR to UR. With averagely linear lines superimposed on the frames that are nearer to SR and UR, the complex topology of the frames’ arrangement could be simplified to a linear plot that enhances the determination of most likely nearest neighbor frames to any given reference frame. A proposed approach for adjacency labeling in transition protocols of fig. 7 are shown in fig. 10. By considering the averaged sections before and after the abrupt transition, the gradual labels could be explored for implicit neighborhood graph decision. Note that the data in this case had to be smoothened to remove the transients introduced by the dynamics of the combustor. However, the richness in the dynamics signifies some defect in this approach for labeling problems of generic applications. Let the red lines be the average linear lines on each examples in fig. 10 for a static system with similar result to that considered. The results of transition protocol in fig. 10a is closest to the explicit labels example used for training the algorithm because the lines are constant before sudden jump. Also, its neighboring graphs are less graduated than those of fig. 10b and fig. 10c whose protocols represent more steady rise in the transition property - average instability measure. However, the protocol in fig. 10c has more subtlety between the SR and UR with a fuzzy transition region because of the prominence of the second region’s property in the first. The closest representation of the implicit labeling problem among the datasets is that shown in fig. 10b. Given any frame at random, one would be able to determine all its sets of neighbors in both regions by a graduation of the average instability measure especially after a random shuffling of the frame positions or in cases where the knowledge of ground truth states for each individual frames are not available. Also implicit labeling helps in higher level learning of the flame dynamics from the video by using probabilistic graphical model such as HMM or STSA [27].\nSpecifically highlighted on plates of fig. 10b are the results of three consecutive frames on a region that would represent our hypothesis in the portions before and after full transition\nfor static applications. In this application however, the gradual build up of the two lobes ”mushroom-like structure” [28] from frame to frame as well as increasing average instability measure are a pointer to the graduated transitioning ability of the framework. Note that the dynamics of the regions in red line would hide this information if frames were selected from there. Thus, we could easily fix frames back to their original position in static applications by the soft labels generated. However, it is expected that the discriminative advantage of the network would intuitively support that presumption. This is a consequence of marginalizing on each hidden layer given the previous layer which has aided determining roughly, neighboring flame patterns and thus providing a coarse to finer labels."
    }, {
      "heading" : "6. CONCLUSIONS AND FUTURE WORKS",
      "text" : "An end-to-end convolutional selective autoencoder is developed to generate fuzzy labels from prior knowledge of hard labeled examples. The framework is used to perform early detection of combustion instabilities using hi-speed flame video. Validation results are presented using data from a laboratory scale swirl-stabilized combustor. The results are discussed in the light of a high fidelity similarity metric which is used to gauge the closeness to ground truth unstable flames. Using the same measure, the architecture was extended to address the neighborhood implicit graph labeling problem. The framework can be generalized for a highdimensional data in order to perform soft-labeling by interpolation of explicit labels. While the framework is shown to be an efficient diagnostics technique for combustion process in laboratory experiments, large scale validation is underway to demonstrate its wide-range applicability. Apart from that, the framework is also enabling domain experts to learn more about the coherent structures that appear during combustion instabilities. From a technical point of view, future research will involve extending the framework to multi-class implicit labeling problems."
    }, {
      "heading" : "7. ACKNOWLEDGMENTS",
      "text" : "Authors sincerely acknowledge the extensive data collection performed by Vikram Ramanan and Dr. Satyanarayanan Chakravarthy at Indian Institute of Technology Madras (IITM), Chennai. Authors also gratefully acknowledge the support of NVIDIA Corporation with the donation of the GeForce GTX TITAN Black GPU used for this research."
    }, {
      "heading" : "8. REFERENCES",
      "text" : "[1] M. Aharon, M. Elad, and A. Bruckstein. An algorithm\nfor designing overcomplete dictionaries for sparse representation. IEEE Transactions on Signal Processing, 54(11):4311–4322, 2006.\n[2] Y. Bengio. Learning deep architecture for ai. Foundations and Trends in Machine Learning, pages 1–71, 2008.\n[3] A. L. Berger, S. A. D. Pietra, and V. J. D. Pietra. A maximum entropy approach to natural language processing. Association for Computational Linguistics, 22(1):1 – 36, 1996.\n[4] J. Bergstra, O. Breulex, F. Bastien, P. Lamblin, R. Pascanu, G. Desjardins, J. Turian, D. Warde-Farley, and Y. Bengio. Theano: a cpu and gpu math expression compiler. Proceedings of the\nPython for Scientific Computing Conference (SciPy), June 2010. Oral Presentation.\n[5] G. Berkooz, P. Holmes, and J. L. Lumley. The proper orthogonal decomposition in the analysis of turbulent flows. Annual Review of Fluid Mechanics, 25(1):539–575, 1993.\n[6] C. M. Bishop. Pattern Recognition and Machine Learning. Springer, New York, NY, USA, 2006.\n[7] B. Cheung. Convolutional neural networks applied to human face classification. ICMLA, 2(12):580–583, 2012.\n[8] R. Collobert and J. Weston. A unified architecture for natural language processing:deep neural networks with multitask learning. 25th International Conference on Machine Learning, pages 1 – 7, 2008.\n[9] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. JMLR, 12:2121–2159, July 2011.\n[10] H. Erdogan. A tutorial on sequence labeling. ICMLA, December 2010.\n[11] C. Farabet, C. Couprie, L. Najman, and Y. LeCun. Learning hierarchical features for scene labeling. exdb, pages 1–15, 2013.\n[12] J. Fung and S. Mann. Using multiple graphics cards as\na general purpose parallel computer: Applications to compute vision. 1:805–808, August 2004.\n[13] A. A. Goshtasby. Similarity and Dissimilarity Measures, chapter 2, pages 1 – 66. Number 978-1-4471-2457-3. Springer-Verlag London Limited, 2012.\n[14] A. Graves. Generating sequences with recurrent neural networks. arXiv:1308.0850v5 [cs.NE], pages 1 – 43, June 2014.\n[15] A. Graves and J. Schmidhuber. Framewise phoneme classification with bidirectional lstm and other neural network architectures. IJCNN, pages 1 – 8, 2005.\n[16] A. K. M. F. Hussain. Coherent structures - reality and myth. Physics of Fluids, 26(10):2816–2850, 1983.\n[17] S. Jones. Convolutional autoencoders in python/theano/lasagne, April 2015.\n[18] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012.\n[19] T. Kulesza, S. Amershi, R. Caruana, D. Fisher, and D. Charles. Strudtured labeling to facilitate concept evolution in machine learning. ACM, pages 1 – 10, April 2014.\n[20] J. Lafferty, A. McCallum, and F. C. Pereira.\nConditional random fields: Probabilistic models for segmenting and labeling sequence data. International Conference on Machine Learning, pages 282–289, June 2001.\n[21] Y. LeCun and Y. Bengio. Convolutional networks for Images, Speech and Time-Series, 1998.\n[22] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proc of IEEE, pages 1–46, November 1998.\n[23] D. Lewandowski, R. M. Cooke, and R. J. D. Tebbens. Sample-based estimation of correlation ratio with polynomial approximation. ACM, V(N):1–16, May 2007.\n[24] J. Masci, U. Meier, D. Ciresan, and J. Schmidhuber. Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction, pages 52–59. Number 6791. Springer-Verlag Berlin Heidelberg, 2011.\n[25] A. Meyer. Hmm and part of speech tagging. Lecture Note, 2011-2012.\n[26] L. Rabiner. A tutorial on hidden markov models and selected applications in speech proccessing. Proceedings of the IEEE, 77(2):257–286, 1989.\n[27] S. Sarkar, K. G. Lore, and S. Sarkar. Early detection of combustion instability by neural-symbolic analysis on hi-speed video. In Workshop on Cognitive Computation: Integrating Neural and Symbolic Approaches (CoCo @ NIPS 2015), Montreal, Canada, December 2015.\n[28] S. Sarkar, K. G. Lore, S. Sarkar, V. Ramaman, S. R. Chakravarthy, S. Phoha, and A. Ray. Early detection of combustion instability from hi-speed flame images via deep learning and symbolic time series analysis. Annual Conference of the Prognostics and Health Management Management Society, pages 1–10, 2015.\n[29] D. Scherer, A. Muller, and S. Behnke. Evaluation of pooling operations in convolutional architectures for object recognition. Intenational Conference on Artificial Neural Networks, ICANN, pages 1–10, 2010.\n[30] P. J. Schmid. Dynamic mode decomposition of numerical and experimental data. Journal of Fluid Mechanics, 656:5–28, 2010.\n[31] T. Sercu, C. Puhrsch, B. Kingsbury, and Y. LeCun. Very deep multilingual convolutional neural networks for lvcsr. arXiv:1509.08967v1 [cs.CL], page 5, September 2015.\n[32] I. Sutskever, J. Martens, G. Dahl, and G. Hinton. On the importance of initialization and momentum in deep learning. International Conference on Machine Learning, JMLR, 28, 2013.\n[33] J. B. Tenenbaum, C. Kemp, T. L. Griffiths, and N. D. Goodman. How to grow a mind: Statistics, structure, and abstraction. Science, 331:1279–1285, 2011.\n[34] M. Thoma. Lasagne for python newbies, February 2016.\n[35] M. D. Zeiler. Adadelta:an adaptive learning rate method. arXiv:1212.5701v1, pages 1–6, December 2012."
    } ],
    "references" : [ {
      "title" : "An algorithm for designing overcomplete dictionaries for sparse representation",
      "author" : [ "M. Aharon", "M. Elad", "A. Bruckstein" ],
      "venue" : "IEEE Transactions on Signal Processing,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2006
    }, {
      "title" : "Learning deep architecture for ai",
      "author" : [ "Y. Bengio" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2008
    }, {
      "title" : "A maximum entropy approach to natural language processing",
      "author" : [ "A.L. Berger", "S.A.D. Pietra", "V.J.D. Pietra" ],
      "venue" : "Association for Computational Linguistics,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1996
    }, {
      "title" : "Theano: a cpu and gpu math expression compiler",
      "author" : [ "J. Bergstra", "O. Breulex", "F. Bastien", "P. Lamblin", "R. Pascanu", "G. Desjardins", "J. Turian", "D. Warde-Farley", "Y. Bengio" ],
      "venue" : "Proceedings of the 0.4231",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2010
    }, {
      "title" : "The proper orthogonal decomposition in the analysis of turbulent flows",
      "author" : [ "G. Berkooz", "P. Holmes", "J.L. Lumley" ],
      "venue" : "Annual Review of Fluid Mechanics,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1993
    }, {
      "title" : "Pattern Recognition and Machine Learning",
      "author" : [ "C.M. Bishop" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2006
    }, {
      "title" : "Convolutional neural networks applied to human face classification",
      "author" : [ "B. Cheung" ],
      "venue" : "ICMLA,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2012
    }, {
      "title" : "A unified architecture for natural language processing:deep neural networks with multitask learning",
      "author" : [ "R. Collobert", "J. Weston" ],
      "venue" : "25th International Conference on Machine Learning,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "J. Duchi", "E. Hazan", "Y. Singer" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "A tutorial on sequence labeling",
      "author" : [ "H. Erdogan" ],
      "venue" : "ICMLA,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2010
    }, {
      "title" : "Learning hierarchical features for scene labeling",
      "author" : [ "C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun" ],
      "venue" : "exdb, pages",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2013
    }, {
      "title" : "Using multiple graphics cards as  a general purpose parallel computer: Applications to compute vision",
      "author" : [ "J. Fung", "S. Mann" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2004
    }, {
      "title" : "Similarity and Dissimilarity Measures, chapter 2, pages 1 – 66. Number 978-1-4471-2457-3",
      "author" : [ "A.A. Goshtasby" ],
      "venue" : "Springer-Verlag London Limited,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2012
    }, {
      "title" : "Generating sequences with recurrent neural networks. arXiv:1308.0850v5 [cs.NE], pages 1 ",
      "author" : [ "A. Graves" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2014
    }, {
      "title" : "Framewise phoneme classification with bidirectional lstm and other neural network architectures. IJCNN, pages 1 ",
      "author" : [ "A. Graves", "J. Schmidhuber" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2005
    }, {
      "title" : "Coherent structures - reality and myth",
      "author" : [ "A.K.M.F. Hussain" ],
      "venue" : "Physics of Fluids,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1983
    }, {
      "title" : "Convolutional autoencoders in python/theano/lasagne",
      "author" : [ "S. Jones" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2015
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "A. Krizhevsky", "I. Sutskever", "G.E. Hinton" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2012
    }, {
      "title" : "Strudtured labeling to facilitate concept evolution in machine learning",
      "author" : [ "T. Kulesza", "S. Amershi", "R. Caruana", "D. Fisher", "D. Charles" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2014
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "J. Lafferty", "A. McCallum", "F.C. Pereira" ],
      "venue" : "International Conference on Machine Learning,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2001
    }, {
      "title" : "Convolutional networks for Images",
      "author" : [ "Y. LeCun", "Y. Bengio" ],
      "venue" : "Speech and Time-Series,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1998
    }, {
      "title" : "Gradient-based learning applied to document recognition",
      "author" : [ "Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner" ],
      "venue" : "Proc of IEEE,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1998
    }, {
      "title" : "Sample-based estimation of correlation ratio with polynomial approximation",
      "author" : [ "D. Lewandowski", "R.M. Cooke", "R.J.D. Tebbens" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2007
    }, {
      "title" : "Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction, pages 52–59. Number 6791",
      "author" : [ "J. Masci", "U. Meier", "D. Ciresan", "J. Schmidhuber" ],
      "venue" : null,
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2011
    }, {
      "title" : "Hmm and part of speech tagging",
      "author" : [ "A. Meyer" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2012
    }, {
      "title" : "A tutorial on hidden markov models and selected applications in speech proccessing",
      "author" : [ "L. Rabiner" ],
      "venue" : "Proceedings of the IEEE,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1989
    }, {
      "title" : "Early detection of combustion instability by neural-symbolic analysis on hi-speed video. In Workshop on Cognitive Computation: Integrating Neural and Symbolic Approaches (CoCo",
      "author" : [ "S. Sarkar", "K.G. Lore" ],
      "venue" : "NIPS",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2015
    }, {
      "title" : "Early detection of combustion instability from hi-speed flame images via deep learning and symbolic time series analysis",
      "author" : [ "S. Sarkar", "K.G. Lore", "V. Ramaman", "S.R. Chakravarthy", "S. Phoha", "A. Ray" ],
      "venue" : "Annual Conference of the Prognostics and Health Management Management Society,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2015
    }, {
      "title" : "Evaluation of pooling operations in convolutional architectures for object recognition",
      "author" : [ "D. Scherer", "A. Muller", "S. Behnke" ],
      "venue" : "Intenational Conference on Artificial Neural Networks,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2010
    }, {
      "title" : "Dynamic mode decomposition of numerical and experimental data",
      "author" : [ "P.J. Schmid" ],
      "venue" : "Journal of Fluid Mechanics,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2010
    }, {
      "title" : "Very deep multilingual convolutional neural networks for lvcsr",
      "author" : [ "T. Sercu", "C. Puhrsch", "B. Kingsbury", "Y. LeCun" ],
      "venue" : "arXiv:1509.08967v1 [cs.CL],",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2015
    }, {
      "title" : "On the importance of initialization and momentum in deep learning",
      "author" : [ "I. Sutskever", "J. Martens", "G. Dahl", "G. Hinton" ],
      "venue" : "International Conference on Machine Learning, JMLR,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2013
    }, {
      "title" : "How to grow a mind: Statistics, structure, and abstraction",
      "author" : [ "J.B. Tenenbaum", "C. Kemp", "T.L. Griffiths", "N.D. Goodman" ],
      "venue" : "Science, 331:1279–1285,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2011
    }, {
      "title" : "Lasagne for python newbies, February 2016",
      "author" : [ "M. Thoma" ],
      "venue" : null,
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2016
    }, {
      "title" : "Adadelta:an adaptive learning rate method",
      "author" : [ "M.D. Zeiler" ],
      "venue" : null,
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "For example, convolutional neural network-based applications include Graph Transformer Networks (GTN) for rapid, online recognition of handwriting [22], natural language processing [8], large vocabulary continuous speech recognition [31] and avatar CAPTCHA machine image recognition [7] by training machines to distinguish between human faces and computer generated faces.",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 7,
      "context" : "For example, convolutional neural network-based applications include Graph Transformer Networks (GTN) for rapid, online recognition of handwriting [22], natural language processing [8], large vocabulary continuous speech recognition [31] and avatar CAPTCHA machine image recognition [7] by training machines to distinguish between human faces and computer generated faces.",
      "startOffset" : 181,
      "endOffset" : 184
    }, {
      "referenceID" : 30,
      "context" : "For example, convolutional neural network-based applications include Graph Transformer Networks (GTN) for rapid, online recognition of handwriting [22], natural language processing [8], large vocabulary continuous speech recognition [31] and avatar CAPTCHA machine image recognition [7] by training machines to distinguish between human faces and computer generated faces.",
      "startOffset" : 233,
      "endOffset" : 237
    }, {
      "referenceID" : 6,
      "context" : "For example, convolutional neural network-based applications include Graph Transformer Networks (GTN) for rapid, online recognition of handwriting [22], natural language processing [8], large vocabulary continuous speech recognition [31] and avatar CAPTCHA machine image recognition [7] by training machines to distinguish between human faces and computer generated faces.",
      "startOffset" : 283,
      "endOffset" : 286
    }, {
      "referenceID" : 9,
      "context" : ", structured and implicit) can be considered a multi-class classification problem [10].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 25,
      "context" : "For example, three stage Hidden Markov Models (HMM) were used for handling speech recognition [26] problems, parts of speech tagging [25] and sequence labeling because they derive the relationships from observations to state and state to state in dynamic systems.",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 24,
      "context" : "For example, three stage Hidden Markov Models (HMM) were used for handling speech recognition [26] problems, parts of speech tagging [25] and sequence labeling because they derive the relationships from observations to state and state to state in dynamic systems.",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 2,
      "context" : "Applications of MEMM for natural language processing can be found in [3].",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 19,
      "context" : "Due to ”label bias” defects of MEMM, a Conditional Random Field (CRF), which is a joint Markov Random Field (MRF) of the states conditioned on the whole observations was later explored by [20].",
      "startOffset" : 188,
      "endOffset" : 192
    }, {
      "referenceID" : 9,
      "context" : "It enabled considering the global labels of the observation as against localization of labels of MEMM [10].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 13,
      "context" : "Recurrent Neural Networks (RNNs) have been utilized for sequence labeling problems due to its cyclic connections of neurons [14] as well as its temporal modeling ability.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 14,
      "context" : "Although earlier construction of RNNs was known to have short ranged memory issues and a restrictive unidirectional information context access, formulation of a bidirectional Long Short Term Memory (LSTM) [15] resolved such issues.",
      "startOffset" : 205,
      "endOffset" : 209
    }, {
      "referenceID" : 27,
      "context" : "The authors [28] introduced Deep Belief Networks, DBNs as a viable technique to achieve the aim with a view to exploring other machine learning for confirmation.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 26,
      "context" : "They improved on that by applying a modular neural-symbolic approach [27] in another publication.",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 32,
      "context" : "Conceptually, this is similar to cognitive psychologists’ description of human reasoning in object classification [33].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 10,
      "context" : "• the method avoids extensive expert-guided feature handcrafting [11] while addressing a complex physical phenomenon like combustion to discover coherent structures in the images,",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 17,
      "context" : "Convolutional networks [18] are a type of deep networks that offer discriminative advantages as in the MEMM as well as providing globally relationship between observations as in the CRF.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 21,
      "context" : "Feature extraction and classifier learning are the two main functions of these networks [22].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 20,
      "context" : "Many image processing and complex simulations depend on the invariance property of the convolution neural network stated in [21] to prevent overfitting by learning expressive codes.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 0,
      "context" : "The feature maps are able to preserve local neighborhood patterns for each receptive field as with over-complete dictionaries in [1].",
      "startOffset" : 129,
      "endOffset" : 132
    }, {
      "referenceID" : 21,
      "context" : "A more detailed review may be found in [22] where the authors note the advantage of local correlation enforcing convolution before spatio-temporal recognition.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 11,
      "context" : "For efficient learning purposes, convolutional networks are able to utilize distributed mapreduce frameworks [12] as well as GPU computing.",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 15,
      "context" : "Coherent structures are fluid mechanical structures associated with coherent phase of vorticity [16].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 4,
      "context" : "The popular methods resorted for detection of coherent structures are proper orthogonal decomposition (POD) [5] (similar to principal component analysis [6]) and dynamic mode decomposition (DMD) [30], which use tools from spectral theory to derive spatial coherent structure modes.",
      "startOffset" : 108,
      "endOffset" : 111
    }, {
      "referenceID" : 5,
      "context" : "The popular methods resorted for detection of coherent structures are proper orthogonal decomposition (POD) [5] (similar to principal component analysis [6]) and dynamic mode decomposition (DMD) [30], which use tools from spectral theory to derive spatial coherent structure modes.",
      "startOffset" : 153,
      "endOffset" : 156
    }, {
      "referenceID" : 29,
      "context" : "The popular methods resorted for detection of coherent structures are proper orthogonal decomposition (POD) [5] (similar to principal component analysis [6]) and dynamic mode decomposition (DMD) [30], which use tools from spectral theory to derive spatial coherent structure modes.",
      "startOffset" : 195,
      "endOffset" : 199
    }, {
      "referenceID" : 18,
      "context" : "A variant of structured labeling by [19] called implicit labeling is used to derive soft labels from extreme classes that are explicitly labeled as either positive or negative examples.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 9,
      "context" : "Implicit labeling here also bears similarity to the sequence labeling [10] with an extra constraint of utilizing prior knowledge provided only by explicit label.",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 26,
      "context" : "3), designed and tested to examine another perspective to the current problem instead of adding a symbolic graphical model such as STSA [27] at the top level.",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 28,
      "context" : "While other pooling schemes exist [29], we chose the highly activated units to take up the features for the local p× p neighborhood in the maxpooling",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 16,
      "context" : "Unpooling: In this layer, a reversal of the pooled dimension is done by stretching and widening [17] the identified features from the filters of the previous layer.",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 21,
      "context" : "The process included a regularization function as in [22] to avoid overfitting the data.",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 31,
      "context" : "The Nesterov momentum-based [32] stochastic gradient descent was used for improved results when compared to other loss functions such as adaptive subgradient (ADAGRAD) [9] and adaptive learning rate method (ADADELTA) [35] for the reconstruction error updates given",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 8,
      "context" : "The Nesterov momentum-based [32] stochastic gradient descent was used for improved results when compared to other loss functions such as adaptive subgradient (ADAGRAD) [9] and adaptive learning rate method (ADADELTA) [35] for the reconstruction error updates given",
      "startOffset" : 168,
      "endOffset" : 171
    }, {
      "referenceID" : 34,
      "context" : "The Nesterov momentum-based [32] stochastic gradient descent was used for improved results when compared to other loss functions such as adaptive subgradient (ADAGRAD) [9] and adaptive learning rate method (ADADELTA) [35] for the reconstruction error updates given",
      "startOffset" : 217,
      "endOffset" : 221
    }, {
      "referenceID" : 1,
      "context" : "The works in [2] points out that that SGD with early stopping is equivalent to an `2− regularization.",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 21,
      "context" : "Subsequently, the weights are updated for each time step via stochastic gradient descent [22]:",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 23,
      "context" : "More details can be found in [24] while the background materials presented thus far and those in subsection 3.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 12,
      "context" : "The similarity index selected for instability measure is the correlation ratio reported in [13] and mathematically proven by [23] to have low computational requirement as a way of reducing the already-large computation architecture.",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 22,
      "context" : "The similarity index selected for instability measure is the correlation ratio reported in [13] and mathematically proven by [23] to have low computational requirement as a way of reducing the already-large computation architecture.",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 27,
      "context" : "Figure 5 (a) shows the setup and a detail description can be found in [28].",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 3,
      "context" : "CUDA cores, equipped with 6GB video memory, using the python-based machine learning frameworks such as Theano, Lasagne and NoLearn [4] [34].",
      "startOffset" : 131,
      "endOffset" : 134
    }, {
      "referenceID" : 33,
      "context" : "CUDA cores, equipped with 6GB video memory, using the python-based machine learning frameworks such as Theano, Lasagne and NoLearn [4] [34].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 21,
      "context" : "Note that the batch iterative training in NoLearn and Lasagne functions were replaced with Theano’s LeNet 5 [22] early stopping algorithm which showed further improvements in test performance.",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 26,
      "context" : "These results are similar to those reported in [27] where the framework used a neural-symbolic approach with a combination of convolutional neural networks and symbolic time series analysis to obtain instability measures.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 26,
      "context" : "As reported in [27], these intermittency phenomena can not be observed from pressure data or POD analysis of image data.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 26,
      "context" : "Hence the proposed metric localizes the intermittencies prior to fullblown instability with more prominence than other state-ofthe-art approaches [27].",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 26,
      "context" : "Better accuracy in tracking intermittence leads to an early detection of instability with less false alarm [27].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 26,
      "context" : "Also implicit labeling helps in higher level learning of the flame dynamics from the video by using probabilistic graphical model such as HMM or STSA [27].",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 27,
      "context" : "In this application however, the gradual build up of the two lobes ”mushroom-like structure” [28] from frame to frame as well as increasing average instability measure are a pointer to the graduated transitioning ability of the framework.",
      "startOffset" : 93,
      "endOffset" : 97
    } ],
    "year" : 2016,
    "abstractText" : "This paper proposes an end-to-end convolutional selective autoencoder approach for early detection of combustion instabilities using rapidly arriving flame image frames. The instabilities arising in combustion processes cause significant deterioration and safety issues in various human-engineered systems such as land and air based gas turbine engines. These properties are described as self-sustaining, large amplitude pressure oscillations and show varying spatial scales periodic coherent vortex structure shedding. However, such instability is extremely difficult to detect before a combustion process becomes completely unstable due to its sudden (bifurcation-type) nature. In this context, an autoencoder is trained to selectively mask stable flame and allow unstable flame image frames. In that process, the model learns to identify and extract rich descriptive and explanatory flame shape features. With such a training scheme, the selective autoencoder is shown to be able to detect subtle instability features as a combustion process makes transition from stable to unstable region. As a consequence, the deep learning tool-chain can perform as an early detection framework for combustion instabilities that will have a transformative impact on the safety and performance of modern engines.",
    "creator" : "LaTeX with hyperref package"
  }
}