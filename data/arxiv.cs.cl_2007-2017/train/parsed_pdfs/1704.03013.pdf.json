{
  "name" : "1704.03013.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Automatic Classification of the Complexity of Nonfiction Texts in Portuguese for Early School Years",
    "authors" : [ "Nathan Hartmann", "Livia Cucatto", "Danielle Brants", "Sandra Alúısio" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Automatic Readability Assessment. Early Grade Reading. Methods for Selecting Reading Material"
    }, {
      "heading" : "1 Introduction",
      "text" : "According to data collected by the Organisation for Cooperation and Economic Development (OECD) in the Programme for International Student Assessment (PISA)1, Brazilian students have serious problems regarding their reading skills. The most recent survey, carried out in 2012, showed results for Brazil below the average of the countries surveyed. 49.5% of Brazilian students did not reach the levels considered minimum in reading, which means that, at best, they can only recognize themes of simple and familiar texts. Furthermore, only 0.5% of Brazilian students reached maximum reading levels, which means that only one in every 200 young people in Brazil is able to deal with complex texts and perform in-depth analysis on such texts. More negative numbers were seen in the Brazilian National High School Exam (ENEM – Exame Nacional do Ensino Médio) in 2014: from the 6.1 million students who did the exam, 529 flunked the composition. Experts stated that most students do not even understand the wording of the question. Only 250 students, equivalent to 0.004%, aced the composition.\nThe development of reading skills has long been related to success in future academic and professional activities. Aimed at raising the quality of the teaching model for reading and text comprehension in this country and trying to close some gaps in Brazilian public policies for education, many features and computer systems for the Brazilian Portuguese have been launched recently. An example is the First Book Project (Projeto Primeiro Livro)2, which helps children and young people from public schools to learn grammar, spelling and develop narratives. Another example is the Victor Civita Foundation, sponsored by the publishing house Abril, which supports teachers, school managers and public policy makers of Elementary Education with lesson plan search engines, social network for educators to exchange experience and share knowledge, and a resource bank for classes3.\nCurrently, in Brazil, the elementary school is divided into two stages - 1st to 5th year, and 6th to 9th year. The National Curriculum Parameters (1998), however, divide these two stages into four cycles. In this article, we focus on the end of the first cycle - 3rd year -, and the second and third cycles - 4th/5th and 6th/7th years because they are fundamental for students to achieve adult reading comprehension.\n1 Available at oecd.org/education/PISA-2012-results-brazil.pdf 2 Available at primeiro-livro.com 3 Available at rede.novaescolaclube.org.br\nar X\niv :1\n70 4.\n03 01\n3v 1\n[ cs\n.C L\n] 1\n0 A\npr 2\n01 7\n2 Nathan Hartmann1, Livia Cucatto2, Danielle Brants2, and Sandra Alúısio1\nThere are some tools for Brazilian Portuguese such as the Flesch Index [30], which is adapted for Portuguese and used in the Microsoft Word, and mainly the Coh-Metrix-Port and AIC, developed in the PorSimples project [3], whose goal is to simplify Web texts for people with poor literacy levels. These tools, however, do not meet the needs of educators in the classroom: there are no classifiers able to discriminate the level of complexity of each year focus of this study – 3rd to 7th years, using metrics of the many language levels.\nFor the English language, there are tools for classifying reading materials for children used in US schools, based on both quantitative data such as Lexile4 [25] [39] and better informed such as Text Easability Assessor (TEA)5 that uses Coh-Metrix [17] [18] metrics.\nIn this article, we present the process of features development and training of a classifier based on machine learning to automatically distinguish five levels of textual complexity to support the selection of texts for students of a given class. Here, we use grade levels, which indicate the number of years of education required to completely understand a text, as a proxy for reading difficulty, the same way as [11]. However, we understand that there can be a great diversity of competences, abilities and background knowledge regarding reading in a same classroom.\nIn Section 2 we present some recent work on automatic readability assessment of grade levels. In Section 3 we present the manual annotation criteria and the process of manual annotation of our corpus. In Section 4 we present the experiments carried out and the results obtained on 5 grade levels and on combining adjacent levels, achieving best results on 3 classes. Finally, in Section 5 we present our final remarks and future work."
    }, {
      "heading" : "2 Related Work",
      "text" : "In recent years, the interest in building automatic classifiers of text complexity has increased. Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9]. Automatic classifiers of text complexity have various applications, as follows: teaching a second language [9], reading and comprehension for poor literacy readers [3], legal and scientific texts and as a first step in building Text Simplification Systems [1].\nReadability studies are an area of great interest for language teaching, particularly in building materials for reading and learning vocabulary. The studies in this area allow to establish a scale of difficulty levels of texts used to assess students. Generally, in elementary levels of education, teachers acknowledge that giving reading materials not suitable for the students’ level impairs their learning, discouraging them [15].\nCurto [9] developed a system to extract linguistic features and a text classifier to teach Portuguese as a second language. The motivation presented by the author is the need of selecting texts for language teaching, which is done manually.\nThe Coh-Metrix-Port 2.06, an adaptation of the Coh-Metrix developed in the PorSimples project [1], currently provides 48 metrics that enable the analysis of lexical, morphosyntactic, syntactic (chunking), semantic and discursive features [37]. The AIC tool, with 39 metrics [31], covers the lack of syntactic analysis (full parsing) in the Coh-Metrix-Port. Scarton and Alúısio [37] evaluated the first version of the Coh-Metrix-Port tool (with 38 metrics) comparing written texts for adults with written texts for children, considering only two levels: simple texts and complex ones related to the journalistic and scientific dissemination genre. It is worth noting that a simple measure such as the Flesch Index and its components results in a SVM classifier with polynomial kernel with 82.5% accuracy, while the CohMetrix-Port increased accuracy to 92% and the measures altogether resulted in 93% of accuracy.\nThe work most related to ours is for the English language [11] and classifies textual complexity using a corpus of magazines for elementary and high school students (Weekly Reader Corpus7 that has texts for elementary school students labeled with grade levels, which range from 2 to 5). Their best results were obtained by group-wise add-one-best feature selection, resulting in 74% classification accuracy, with 273 features selected, including language modeling features, syntactic features, PoS features, traditional readability metrics, and out-of-vocabulary features.\n4 Available at lexile.com 5 Available at tea.cohmetrix.com 6 Available at nilc.icmc.usp.br/coh-metrix-port 7 Available at www.weeklyreader.com\nAutomatic Classification of Text Complexity 3"
    }, {
      "heading" : "3 Corpus and Manual Annotation on Grade Levels",
      "text" : ""
    }, {
      "heading" : "3.1 Description of grade levels and the problem",
      "text" : "In recent years, the Brazilian government has been working on a systematization of the education policy in an attempt to unify the curricula methods and content for schools and teachers all over Brazil to speak the same language. The Provinha Brasil8, the state assessment tests (e.g., SARESP9 in the state of São Paulo) and even the ENEM (National High School Exam) are attempts to direct education professionals to the same educational setting. However, it is still not clear for teachers, especially for elementary school ones, how to distribute such content by school year, especially when it comes to reading. In addition, in Brazil, there is an extremely diverse learning scenario in the same grade. The insertion of dictionaries in grade levels by the National Textbook Program (PNLD) [23] since 2006 shows a change, albeit slow, in the Brazilian educational system.\nBuilding a five-level classifier is in line with this emerging educational scenario. For the 3rd, 4th and 5th years (Ensino Fundamental I ) and the 6th and 7th years of the elementary school (Ensino Fundamental II ), we can measure the complexity of texts and, thus, meet the diversity in reading comprehension.\nThe creation basis was: the National Curriculum Parameters (PCNs) (1998), the descriptors of Prova Brasil10, analysis of textbooks, articles in the psycholinguistics area [7] [12] [16] [27] [28] [29] [32] [33] [35] and language acquisition [21] [22], and the knowledge of linguists with experience in Education and the Portuguese language (phonology, morphology, syntax, semantics and discourse).\nWith respect to PCNs, one way to measure these skills was to create descriptors that synthesized the competencies and skills. Such descriptors are used as reference matrix for Prova Brasil. The Portuguese language test assesses only reading skills, represented by 21 descriptors for the 9th year and by 15 descriptors for the 5th year, divided into six groups: (1) Reading procedures; (2) implications of support, gender and/or enunciator in the text comprehension; (3) Relationship between texts; (4) Coherence and cohesion in text processing; (5) Relations between expressive features and effects of meaning; and (6) Linguistic variation. However, neither the PCNs nor the descriptors distinguish five levels. On the other hand, it is known that each grade level has a specific curriculum and, therefore, its difficulties and expected progress. One way to obtain a more objective division by grade levels was to resort to textbooks. All of them indicate the content to be taught and bring nonfiction texts."
    }, {
      "heading" : "3.2 Corpus and selection of texts for annotation",
      "text" : "In order to build the corpus, we search for pre-selected texts in terms of complexity levels, using the following sources: SARESP and textbooks. We obtained only 72 texts, distributed in five levels, from SARESP tests, given limitations such as they do not cover all school years; they are generally applied once a year; the test contains several textual genres – that is, there are few informative texts; and, above all, not all texts are available online. Considering the difficulties above and knowing the importance of a large amount of data to machine learning techniques, we turned to textbooks as our main source of texts. Experts selected 178 informative texts from Portuguese language textbooks. Therefore, we equally distributed 50 texts in each level, totaling 250.\nBecause of the small amount of texts which had some level information, new sources, not previously classified, were included in the corpus: NILC corpus11, Ciência Hoje das Crianças (CHC)12, Folhinha13, Para Seu Filho Ler14 and Mundo Estranho15, which currently contains 7,645 texts compiled, whose sources distribution is shown in Table 1. Among the seven sources, the one that presents great diversity of textual type and gender is textbooks, since the purpose of this type of source is to present the student with all existing genres and types – we found from simple expository texts to more complex structures such as argumentative texts very common in the editorial genre; the same textual amplitude is seen\n8 Provinha Brasil is a test to evaluate how much children have learned about Portuguese and Mathematics subjects. Available at provinhabrasil.inep.gov.br\n9 Available at http://www.educacao.sp.gov.br/saresp 10 Prova Brasil is a test to evaluate the quality of the educational brazilian system. Available at http://portal.\nmec.gov.br/prova-brasil 11 Available at nilc.icmc.usp.br/nilc/images/download/corpusNilc.zip 12 Available at chc.cienciahoje.uol.com.br 13 Available at www.folha.uol.com.br/folhinha 14 Available at zh.clicrbs.com.br/rs 15 Available at mundoestranho.abril.com.br\n4 Nathan Hartmann1, Livia Cucatto2, Danielle Brants2, and Sandra Alúısio1\nin SARESP tests16. Although the NILC corpus is also composed of textbooks, its texts generally have three text types: descriptive, narrative and expository. However, CHC, Folhinha and Mundo Estranho are similar: they present, in most cases, dialogues; varied text types in the same text; and the predominance of a particular type. These different possibilities of textual occurrence increase the challenge of building the curricula (see Section 3.3) and, therefore, the classification system. So far, 1,456 texts have been annotated by a sole linguist."
    }, {
      "heading" : "3.3 Annotation criteria",
      "text" : "The first annotation grid built relied on textbook curricula, which has linguistic phenomena organized by grade levels. From this basis, the contact with texts targeted to school years and the knowledge of linguists, we kept on improving the grid. We should emphasize that although the school introduces linguistic elements in certain years, children can already understand and produce them long before being exposed to them in the educational system. Hence, the need to link different sources of knowledge.\nAnother challenge lies in the text type diversity found in informative texts, namely: narrative, descriptive, injunctive, expository and argumentative [4]. Such text types have different structures, but they may still be in the same reading comprehension level. Thus, for example, a mostly injunctive text may have the same level of complexity as a text that is mostly descriptive. Structural possibilities were and are still considered in the grid detailing.\nLinguistic and non-linguistic elements are divided into six groups: morphological, lexical, syntactic, textual, punctuation and semantic and reader’s commonsense knowledge. The first one corresponds to linguistic elements in the morphological level such as verb endings, affixes and grammatical categories; the second brings together linguistic phenomena connected to vocabulary and semantic relationships such as synonymy, antonymy, polysemy, among others; the syntactic group highlights the types of clauses present in the texts, how they are organized within the sentence, the paragraph, the order and size of constituents; with regard to text metrics, the main focus is cohesion: the type of cohesion used and the elements used for this end. The Punctuation and Semantic and reader’s commonsense knowledge complement the previous ones: this maps the punctuation richness and the other is an attempt to capture the semantic and world knowledge of the reader, so far, by means of named entities."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Preliminary Experiments: using language independent features",
      "text" : "The manual annotation process started focusing on a balanced sample of 971 texts in 5 levels of textual complexity, from the 3rd to 7th grade levels, mapped here from level 1 to 5. The distribution of our initial data set is as follows: 208 texts of level 1, 185 texts of level 2, 196 texts of level 3, 191 texts of level 4 and 191 texts of level 5. For this set of texts, we extracted the following 10 features list we call “simple statistics feature”: Flesch-Kincaid Grade Level index, the average sentences per paragraph, average words per sentence, number of paragraphs, number of sentences, number of words in the text, type-token ratio, number of simple words matching the dictionary of simple words to youngsters [6], incidence of punctuation and diversity of punctuation. All of these features are independent of language, except for the dictionary of simple words, but it is easy to find it for many languages. When performing a 10-fold cross-validation experiment on the initial data set, with an SVM classifier17 with linear kernel and C=1, we obtained 52% of accuracy (+/- 14). It is worth noting that the 3 features best classified by the recursive feature elimination (RFE) process for selecting features were the Flesch-Kincaid, the number of paragraphs in the text and the diversity of punctuation.\n16 Available at sites.google.com/site/provassaresp 17 It was used a libsvm implementation of SVM classifier.\nAutomatic Classification of Text Complexity 5"
    }, {
      "heading" : "4.2 Increasing the Number of Features and Data",
      "text" : "Keeping the size of the initial corpus, we decided to increase our features set to better represent differences among the textual levels. Table 2 maps the features implemented in 6 linguistic categories used for corpus annotation, described in Section 3.3. Table 2 shows a total of 108 features: (i) 52 Coh-Metrix-Port features 2.018, (ii) 32 AIC Features, (iii) two features based on the lists of positive and negative words of the LIWC - Dictionary for Sentiment Analysis19, 14 features about Named Entities, calculated on the flat output of the PALAVRAS parser [5], and (v) 8 new features on Verbs Incidence implemented especially for this work comprising Portuguese verb tenses and moods. Some features were duplicated on Table 2 because they use information from many linguistic categories.\nBy repeating the experiment with the same fold and SVM settings for the new set of 108 features, we obtained 56% of accuracy (+/-13). We know it is difficult to have statistical learning in a small dataset such as the initial dataset. Therefore, we use the Active Learning Approach [40] for selecting new instances for annotation, so that the new instances are those that are most difficult for our classifier to label. Thus, we use the distance of texts from SVM separating hyperplanes as criteria for selecting instances for annotation. The closer an instance is from the separating hyperplanes, there is greater indecision in classifying that instance. Therefore, when we label this text manually, we believe we are helping the classifier to better define the existing limits between classes.\n18 Available at http://143.107.183.175:22680 19 Available at http://143.107.183.175:21380/portlex/index.php/en/liwc\n6 Nathan Hartmann1, Livia Cucatto2, Danielle Brants2, and Sandra Alúısio1\nWe performed four steps to select texts for annotation, where each step selected the 100 most complex texts for SVM. The texts that could not be processed due to parsing problems were removed. The results are shown in Table 3. They show that even when we select the texts in which the classifier has greater indecision in classifying, the SVM has not yet been able to define a boundary between the classes, which led to lower accuracy in classifying data. This shows that there is a mix between classes so that the 108 current features are not able to correctly distinguish the five levels manually annotated. Finally, we conducted a stage of selecting the 100 most easily annotated texts (those with greater distance from SVM separating hyperplanes) in order to contrast with the current distribution of data and the accuracy obtained. We obtained a set of 1,456 texts with the following distribution: 242 texts of level 1, 313 texts of level 2, 338 texts of level 3,287 texts of level 4 and 276 texts of level 5. The accuracy obtained when performing a 10-fold cross-validation experiment with linear kernel SVM and C=1 was 52% (+/- 15).\nThis slight improvement in performance shows us that, in fact, there is a set of complex texts that the classifier cannot handle: due to either lack of discriminative features or lack of data for training (see confusion matrix on Table 4). The problem can also consist in human annotation errors. To evaluate that we performed a double-blind annotation of a random sampling of 100 texts. We obtained a Kappa score of 0.528 that represents a moderate agreement on Landis and Koch scale [24]. This agreement suggests that the manual annotation process and the labeled data should be reviewed because, as Hovy and Lavid says, “if humans can agree on something at N%, systems will achieve (N-10)%” [20]. In addition to the\nAutomatic Classification of Text Complexity 7\nconfusion matrix, we can see in Figure 1 the axes that represent the two most discriminative features of the 44 selected by the RFE method of feature selection, and that there is, in fact, a mixture in the features space, particularly between the 2-3, 3-4-5, and 4-5 levels. This scenario will be hardly separated by SVM.\nFeng’s work [11] addresses 4 levels of difficulty, reaching the state-of-art 74% of accuracy in English. Our experiments with fewer classes showed that, when joining classes 2 and 3, we achieved 65% (+/- 15) of accuracy, and by joining classes 4 and 5, we achieved 63% (+/- 11) of accuracy. By simultaneously joining class 2 with class 3 and 4 with 5, we reached the 74% of accuracy achieved by the state of art. This division of grade levels better reflects the division into cycles indicated by the PCNs (1998)."
    }, {
      "heading" : "5 Discussion and Future Work",
      "text" : "Our work presents the first efforts to automatically classify Portuguese texts into 5 close grade levels. The literature shows that this task is complex and, in this sense, our results are promising. We also understand that, despite the number of features used is 40% of the 273 features used in the state-of-art work for the English language [11], there is a high rate of mixed data, especially in the central levels 4-6. Our selection of features brought 44 of the 108 features used in this work, obtaining 52% (+/- 15) of accuracy. This selection brings features to meet 5 out of 6 linguistic groups that model the manual annotation, for example: Flesch Index for the Morphological category; Ambiguity of adjectives and Incidence of Adverbs for the Lexical category; Mean Apposition Per Clause for the Syntactic category; Adjacent content word overlap and Incidence of Negative Additive Connective for the Textual category; Incidence of Human Named Entity in Text for the Semantic and reader’s commonsense knowledge. By reducing the classification to 3 levels of textual complexity, we achieved 74% of accuracy - as obtained by the state-of-art work for the English language that focuses on 4 levels.\nAs future work, we indicate two fronts of efforts:(i) the re-annotation of the corpus by a second annotator, using the manual annotation developed to check discrepancies; (ii) the addition of features in the six categories of linguistic elements that were used for manual classification of texts. We will replicate 6 out-of-vocabulary features described in [11]. For each text in our final corpus, these 6 features are computed using the most common 100, 200 and 500 word tokens and types based on texts from 3th grade. Also, we will implement successful features for the English language, cited by [34], such as average sentence length and features from the language model of our corpus. Moreover, and more importantly, we will implement a text type classifier to distinguish the text types occurring in our corpus. As the features of each text in our corpus are being annotated and there is a corpus annotated with text types in the Lácio-Web project [2] we will be able to better understand the correlations between text types and the others features for readability assessment in our project."
    } ],
    "references" : [ {
      "title" : "Readability assessment for text simplification",
      "author" : [ "S. Aluisio", "L. Specia", "C. Gasperin", "C. Scarton" ],
      "venue" : "Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications. pp. 1–9. Association for Computational Linguistics",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "The lácioweb: Corpora and tools to advance brazilian portuguese language investigations and computational linguistic tools",
      "author" : [ "S.M. Alúısio", "G.M. Pinheiro", "A.M. Manfrin", "L.H. de Oliveira", "L.C. Genoves Jr", "S.E. Tagnin" ],
      "venue" : "Proceedings of LREC. pp. 1779–1782",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Fostering digital inclusion and accessibility: the porsimples project for simplification of portuguese texts",
      "author" : [ "S.M. Alúısio", "C. Gasperin" ],
      "venue" : "Proceedings of the NAACL HLT 2010 Young Investigators Workshop on 8 Nathan Hartmann, Livia Cucatto, Danielle Brants, and Sandra Alúısio Computational Approaches to Languages of the Americas. pp. 46–53. Association for Computational Linguistics",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Estética da criação verbal",
      "author" : [ "M. Bakhtin" ],
      "venue" : "Livraria Martins Fontes",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "The Parsing System “Palavras”: Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework",
      "author" : [ "E. Bick" ],
      "venue" : "Aarhus University Press Aarhus",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Dicionários do português: da tradição à contemporaneidade",
      "author" : [ "M.T.C. Biderman" ],
      "venue" : "ALFA: Revista de Lingúıstica 47(1)",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Personalizing web search results by reading level",
      "author" : [ "K. Collins-Thompson", "P.N. Bennett", "R.W. White", "S. de la Chica", "D. Sontag" ],
      "venue" : "Proceedings of the 20th ACM international conference on Information and knowledge management. pp. 403–412. ACM",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Classificador de textos para o ensino de português como segunda ĺıngua",
      "author" : [ "P. Curto" ],
      "venue" : "Master’s thesis, Universidade Técnico Lisboa, Portugal",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "T2k2: System for automatically extracting and organizing knowledge from texts",
      "author" : [ "F. Dell’Orletta", "G. Venturi", "A. Cimino", "S. Montemagni" ],
      "venue" : "Proceedings of the 9th International Conference on Language Resources and Evaluation (LREC’14)",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "A comparison of features for automatic readability assessment",
      "author" : [ "L. Feng", "M. Jansche", "M. Huenerfauth", "N. Elhadad" ],
      "venue" : "Proceedings of the 23rd International Conference on Computational Linguistics: Posters. pp. 276–284. COLING ’10, Association for Computational Linguistics",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Associative lexical cohesion as a factor in text complexity",
      "author" : [ "M. Flor", "B.B. Klebanov" ],
      "venue" : "International Journal of Applied Linguistics 165(2), 223–258",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "An analysis of a french as a foreign language corpus for readability assessment",
      "author" : [ "T. François" ],
      "venue" : "NEALT Proceedings Series Vol. 22 pp. 13–32",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Randomised controlled trial of graded exercise in patients with the chronic fatigue syndrome",
      "author" : [ "K.Y. Fulcher", "P.D. White" ],
      "venue" : "Bmj 314(7095), 1647–1652",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "A influência da memória operacional nas habilidades de compreensão de leitura em escolares de 4 série influence of working memory in reading comprehension in 4th grade students",
      "author" : [ "Giangiacomo", "M.C.P.B.", "Navas", "A.L.G.P." ],
      "venue" : "Sociedade Brasileira de Fonoaudiologia 13(1), 69–74",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Coh-metrix providing multilevel analyses of text characteristics",
      "author" : [ "A.C. Graesser", "D.S. McNamara", "J.M. Kulikowich" ],
      "venue" : "Educational Researcher 40(5), 223–234",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Coh-metrix: Analysis of text on cohesion and language",
      "author" : [ "A.C. Graesser", "D.S. McNamara", "M.M. Louwerse", "Z. Cai" ],
      "venue" : "Behavior research methods, instruments, & computers 36(2), 193–202",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Readability classification for german using lexical, syntactic, and morphological features",
      "author" : [ "J. Hancke", "S. Vajjala", "D. Meurers" ],
      "venue" : "Proceedings of COLING. pp. 1063–1080",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Towards a ‘science’of corpus annotation: a new methodological challenge for corpus linguistics",
      "author" : [ "E. Hovy", "J. Lavid" ],
      "venue" : "International journal of translation 22(1), 13–36",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "O aprendizado da leitura",
      "author" : [ "M. Kato" ],
      "venue" : "Martins Fontes",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1985
    }, {
      "title" : "No mundo da escrita: uma perspectiva psicolingǘıstica, vol",
      "author" : [ "M.A. Kato" ],
      "venue" : "9. Editora Ática",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1986
    }, {
      "title" : "Dicionários para o ensino de ĺıngua materna: prinćıpios e critérios de escolha",
      "author" : [ "Krieger", "M.d.G." ],
      "venue" : "Revista Ĺıngua&Literatura 7(10-11), 101–112",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "The measurement of observer agreement for categorical data",
      "author" : [ "J.R. Landis", "G.G. Koch" ],
      "venue" : "Biometrics 33(1), pp. 159–174",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1977
    }, {
      "title" : "The lexile framework as an approach for reading measurement and success",
      "author" : [ "C. Lennon", "H. Burdick" ],
      "venue" : "Electronic publication on www.lexile.com",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "System and method for enhancing comprehension and readability of legal text (2014), US Patent 8,794,972",
      "author" : [ "L.M. LoPucki" ],
      "venue" : null,
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2014
    }, {
      "title" : "Gramática e parser",
      "author" : [ "M. Maia" ],
      "venue" : "Boletim da ABRALIN 1(26)",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Efeitos do status argumental e de segmentação no processamento de sintagmas preposicionais em português brasileiro",
      "author" : [ "M. Maia" ],
      "venue" : "Cadernos de Estudos Lingǘısticos 50(1)",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Processamento da linguagem",
      "author" : [ "M. Maia", "I. FINGER" ],
      "venue" : "Pelotas: Educat",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Readability formulas applied to textbooks in brazilian portuguese",
      "author" : [ "T.B. Martins", "C.M. Ghiraldelo", "Nunes", "M.d.G.V.", "O.N. de Oliveira Junior" ],
      "venue" : "Icmsc-Usp",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Ferramenta de análise automática de inteligibilidade de córpus (aic)",
      "author" : [ "E.G. Maziero", "T.A.S. Pardo", "S.M. Alúısio" ],
      "venue" : "Tech. rep.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Avanços no conhecimento do processamento da fluência em leitura: da palavra ao texto improvements in the knowledge of the reading fluency processing: from word to text",
      "author" : [ "Navas", "A.L.G.P.", "Pinto", "J.C.B.R.", "P.R.R. Dellisa" ],
      "venue" : "Sociedade Brasileira de Fonoaudiologia 14(3), 553–9",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "istart: A web-based reading strategy intervention that improves students’s science comprehension",
      "author" : [ "T. O’Reilly", "G. Sinclair", "D.S. McNamara" ],
      "venue" : "CELDA. pp. 173–180",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "A machine learning approach to reading level assessment",
      "author" : [ "S.E. Petersen", "M. Ostendorf" ],
      "venue" : "Computer speech & language 23(1), 89–106",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Readability of surgical informed consent in spain",
      "author" : [ "E.M. San Norberto", "D. Gómez-Alonso", "J.M. Trigueros", "J. Quiroga", "J. Gualis", "C. Vaquero" ],
      "venue" : "Ciruǵıa Española 92(3), 201–207",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Análise da Inteligibilidade de textos via ferramentas de Processamento de Ĺıngua Natural: adaptando as métricas do Coh-Metrix para o Português",
      "author" : [ "C. Scarton", "S. Alúısio" ],
      "venue" : "Linguamática 2(1), 45–62",
      "citeRegEx" : "37",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A two-stage approach for generating unbiased estimates of text complexity",
      "author" : [ "K.M. Sheehan", "M. Flor", "D. Napolitano" ],
      "venue" : "Proceedings of the Workshop on Natural Language Processing for Improving Textual Accessibility. pp. 49–58",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Measuring reading comprehension with the lexile framework",
      "author" : [ "A.J. Stenner" ],
      "venue" : null,
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 1996
    }, {
      "title" : "Support vector machine active learning with applications to text classification",
      "author" : [ "S. Tong", "D. Koller" ],
      "venue" : "The Journal of Machine Learning Research 2, 45–66",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Readability assessment for text simplification: From analysing documents to identifying sentential simplifications",
      "author" : [ "S. Vajjala", "D. Meurers" ],
      "venue" : "International Journal of Applied Linguistics 165(2), 194–222",
      "citeRegEx" : "41",
      "shortCiteRegEx" : null,
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "For English, Feng’s work [11] is considered the state-of-art in grade level prediction and achieved 74% of accuracy in automatically classifying 4 levels of textual complexity for close school grades.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 27,
      "context" : "There are some tools for Brazilian Portuguese such as the Flesch Index [30], which is adapted for Portuguese and used in the Microsoft Word, and mainly the Coh-Metrix-Port and AIC, developed in the PorSimples project [3], whose goal is to simplify Web texts for people with poor literacy levels.",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 2,
      "context" : "There are some tools for Brazilian Portuguese such as the Flesch Index [30], which is adapted for Portuguese and used in the Microsoft Word, and mainly the Coh-Metrix-Port and AIC, developed in the PorSimples project [3], whose goal is to simplify Web texts for people with poor literacy levels.",
      "startOffset" : 217,
      "endOffset" : 220
    }, {
      "referenceID" : 22,
      "context" : "For the English language, there are tools for classifying reading materials for children used in US schools, based on both quantitative data such as Lexile [25] [39] and better informed such as Text Easability Assessor (TEA) that uses Coh-Metrix [17] [18] metrics.",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 35,
      "context" : "For the English language, there are tools for classifying reading materials for children used in US schools, based on both quantitative data such as Lexile [25] [39] and better informed such as Text Easability Assessor (TEA) that uses Coh-Metrix [17] [18] metrics.",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 14,
      "context" : "For the English language, there are tools for classifying reading materials for children used in US schools, based on both quantitative data such as Lexile [25] [39] and better informed such as Text Easability Assessor (TEA) that uses Coh-Metrix [17] [18] metrics.",
      "startOffset" : 246,
      "endOffset" : 250
    }, {
      "referenceID" : 15,
      "context" : "For the English language, there are tools for classifying reading materials for children used in US schools, based on both quantitative data such as Lexile [25] [39] and better informed such as Text Easability Assessor (TEA) that uses Coh-Metrix [17] [18] metrics.",
      "startOffset" : 251,
      "endOffset" : 255
    }, {
      "referenceID" : 9,
      "context" : "Here, we use grade levels, which indicate the number of years of education required to completely understand a text, as a proxy for reading difficulty, the same way as [11].",
      "startOffset" : 168,
      "endOffset" : 172
    }, {
      "referenceID" : 6,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 14,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 23,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 34,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 11,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 8,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 185,
      "endOffset" : 189
    }, {
      "referenceID" : 32,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 199,
      "endOffset" : 203
    }, {
      "referenceID" : 16,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 212,
      "endOffset" : 216
    }, {
      "referenceID" : 37,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 217,
      "endOffset" : 221
    }, {
      "referenceID" : 0,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 250,
      "endOffset" : 253
    }, {
      "referenceID" : 7,
      "context" : "Although the English language is a highlight in this topic [8] [17] [26] [38], it has served as base for other languages to develop their own classifiers, such the French [14], Italian [10], Spanish [36], German [19] [41], Arabic [13] and Portuguese [1] [9].",
      "startOffset" : 254,
      "endOffset" : 257
    }, {
      "referenceID" : 7,
      "context" : "Automatic classifiers of text complexity have various applications, as follows: teaching a second language [9], reading and comprehension for poor literacy readers [3], legal and scientific texts and as a first step in building Text Simplification Systems [1].",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 2,
      "context" : "Automatic classifiers of text complexity have various applications, as follows: teaching a second language [9], reading and comprehension for poor literacy readers [3], legal and scientific texts and as a first step in building Text Simplification Systems [1].",
      "startOffset" : 164,
      "endOffset" : 167
    }, {
      "referenceID" : 0,
      "context" : "Automatic classifiers of text complexity have various applications, as follows: teaching a second language [9], reading and comprehension for poor literacy readers [3], legal and scientific texts and as a first step in building Text Simplification Systems [1].",
      "startOffset" : 256,
      "endOffset" : 259
    }, {
      "referenceID" : 12,
      "context" : "Generally, in elementary levels of education, teachers acknowledge that giving reading materials not suitable for the students’ level impairs their learning, discouraging them [15].",
      "startOffset" : 176,
      "endOffset" : 180
    }, {
      "referenceID" : 7,
      "context" : "Curto [9] developed a system to extract linguistic features and a text classifier to teach Portuguese as a second language.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 0,
      "context" : "0, an adaptation of the Coh-Metrix developed in the PorSimples project [1], currently provides 48 metrics that enable the analysis of lexical, morphosyntactic, syntactic (chunking), semantic and discursive features [37].",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 33,
      "context" : "0, an adaptation of the Coh-Metrix developed in the PorSimples project [1], currently provides 48 metrics that enable the analysis of lexical, morphosyntactic, syntactic (chunking), semantic and discursive features [37].",
      "startOffset" : 215,
      "endOffset" : 219
    }, {
      "referenceID" : 28,
      "context" : "The AIC tool, with 39 metrics [31], covers the lack of syntactic analysis (full parsing) in the Coh-Metrix-Port.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 33,
      "context" : "Scarton and Alúısio [37] evaluated the first version of the Coh-Metrix-Port tool (with 38 metrics) comparing written texts for adults with written texts for children, considering only two levels: simple texts and complex ones related to the journalistic and scientific dissemination genre.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 9,
      "context" : "The work most related to ours is for the English language [11] and classifies textual complexity using a corpus of magazines for elementary and high school students (Weekly Reader Corpus that has texts for elementary school students labeled with grade levels, which range from 2 to 5).",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 20,
      "context" : "The insertion of dictionaries in grade levels by the National Textbook Program (PNLD) [23] since 2006 shows a change, albeit slow, in the Brazilian educational system.",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 10,
      "context" : "The creation basis was: the National Curriculum Parameters (PCNs) (1998), the descriptors of Prova Brasil, analysis of textbooks, articles in the psycholinguistics area [7] [12] [16] [27] [28] [29] [32] [33] [35] and language acquisition [21] [22], and the knowledge of linguists with experience in Education and the Portuguese language (phonology, morphology, syntax, semantics and discourse).",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 13,
      "context" : "The creation basis was: the National Curriculum Parameters (PCNs) (1998), the descriptors of Prova Brasil, analysis of textbooks, articles in the psycholinguistics area [7] [12] [16] [27] [28] [29] [32] [33] [35] and language acquisition [21] [22], and the knowledge of linguists with experience in Education and the Portuguese language (phonology, morphology, syntax, semantics and discourse).",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 24,
      "context" : "The creation basis was: the National Curriculum Parameters (PCNs) (1998), the descriptors of Prova Brasil, analysis of textbooks, articles in the psycholinguistics area [7] [12] [16] [27] [28] [29] [32] [33] [35] and language acquisition [21] [22], and the knowledge of linguists with experience in Education and the Portuguese language (phonology, morphology, syntax, semantics and discourse).",
      "startOffset" : 183,
      "endOffset" : 187
    }, {
      "referenceID" : 25,
      "context" : "The creation basis was: the National Curriculum Parameters (PCNs) (1998), the descriptors of Prova Brasil, analysis of textbooks, articles in the psycholinguistics area [7] [12] [16] [27] [28] [29] [32] [33] [35] and language acquisition [21] [22], and the knowledge of linguists with experience in Education and the Portuguese language (phonology, morphology, syntax, semantics and discourse).",
      "startOffset" : 188,
      "endOffset" : 192
    }, {
      "referenceID" : 26,
      "context" : "The creation basis was: the National Curriculum Parameters (PCNs) (1998), the descriptors of Prova Brasil, analysis of textbooks, articles in the psycholinguistics area [7] [12] [16] [27] [28] [29] [32] [33] [35] and language acquisition [21] [22], and the knowledge of linguists with experience in Education and the Portuguese language (phonology, morphology, syntax, semantics and discourse).",
      "startOffset" : 193,
      "endOffset" : 197
    }, {
      "referenceID" : 29,
      "context" : "The creation basis was: the National Curriculum Parameters (PCNs) (1998), the descriptors of Prova Brasil, analysis of textbooks, articles in the psycholinguistics area [7] [12] [16] [27] [28] [29] [32] [33] [35] and language acquisition [21] [22], and the knowledge of linguists with experience in Education and the Portuguese language (phonology, morphology, syntax, semantics and discourse).",
      "startOffset" : 198,
      "endOffset" : 202
    }, {
      "referenceID" : 30,
      "context" : "The creation basis was: the National Curriculum Parameters (PCNs) (1998), the descriptors of Prova Brasil, analysis of textbooks, articles in the psycholinguistics area [7] [12] [16] [27] [28] [29] [32] [33] [35] and language acquisition [21] [22], and the knowledge of linguists with experience in Education and the Portuguese language (phonology, morphology, syntax, semantics and discourse).",
      "startOffset" : 203,
      "endOffset" : 207
    }, {
      "referenceID" : 18,
      "context" : "The creation basis was: the National Curriculum Parameters (PCNs) (1998), the descriptors of Prova Brasil, analysis of textbooks, articles in the psycholinguistics area [7] [12] [16] [27] [28] [29] [32] [33] [35] and language acquisition [21] [22], and the knowledge of linguists with experience in Education and the Portuguese language (phonology, morphology, syntax, semantics and discourse).",
      "startOffset" : 238,
      "endOffset" : 242
    }, {
      "referenceID" : 19,
      "context" : "The creation basis was: the National Curriculum Parameters (PCNs) (1998), the descriptors of Prova Brasil, analysis of textbooks, articles in the psycholinguistics area [7] [12] [16] [27] [28] [29] [32] [33] [35] and language acquisition [21] [22], and the knowledge of linguists with experience in Education and the Portuguese language (phonology, morphology, syntax, semantics and discourse).",
      "startOffset" : 243,
      "endOffset" : 247
    }, {
      "referenceID" : 3,
      "context" : "Another challenge lies in the text type diversity found in informative texts, namely: narrative, descriptive, injunctive, expository and argumentative [4].",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 5,
      "context" : "For this set of texts, we extracted the following 10 features list we call “simple statistics feature”: Flesch-Kincaid Grade Level index, the average sentences per paragraph, average words per sentence, number of paragraphs, number of sentences, number of words in the text, type-token ratio, number of simple words matching the dictionary of simple words to youngsters [6], incidence of punctuation and diversity of punctuation.",
      "startOffset" : 370,
      "endOffset" : 373
    }, {
      "referenceID" : 4,
      "context" : "0, (ii) 32 AIC Features, (iii) two features based on the lists of positive and negative words of the LIWC - Dictionary for Sentiment Analysis, 14 features about Named Entities, calculated on the flat output of the PALAVRAS parser [5], and (v) 8 new features on Verbs Incidence implemented especially for this work comprising Portuguese verb tenses and moods.",
      "startOffset" : 230,
      "endOffset" : 233
    }, {
      "referenceID" : 36,
      "context" : "Therefore, we use the Active Learning Approach [40] for selecting new instances for annotation, so that the new instances are those that are most difficult for our classifier to label.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 21,
      "context" : "528 that represents a moderate agreement on Landis and Koch scale [24].",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 17,
      "context" : "This agreement suggests that the manual annotation process and the labeled data should be reviewed because, as Hovy and Lavid says, “if humans can agree on something at N%, systems will achieve (N-10)%” [20].",
      "startOffset" : 203,
      "endOffset" : 207
    }, {
      "referenceID" : 9,
      "context" : "Feng’s work [11] addresses 4 levels of difficulty, reaching the state-of-art 74% of accuracy in English.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 9,
      "context" : "We also understand that, despite the number of features used is 40% of the 273 features used in the state-of-art work for the English language [11], there is a high rate of mixed data, especially in the central levels 4-6.",
      "startOffset" : 143,
      "endOffset" : 147
    }, {
      "referenceID" : 9,
      "context" : "We will replicate 6 out-of-vocabulary features described in [11].",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 31,
      "context" : "Also, we will implement successful features for the English language, cited by [34], such as average sentence length and features from the language model of our corpus.",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 1,
      "context" : "As the features of each text in our corpus are being annotated and there is a corpus annotated with text types in the Lácio-Web project [2] we will be able to better understand the correlations between text types and the others features for readability assessment in our project.",
      "startOffset" : 136,
      "endOffset" : 139
    } ],
    "year" : 2017,
    "abstractText" : "Recent research shows that most Brazilian students have serious problems regarding their reading skills. The full development of this skill is key for the academic and professional future of every citizen. Tools for classifying the complexity of reading materials for children aim to improve the quality of the model of teaching reading and text comprehension. For English, Feng’s work [11] is considered the state-of-art in grade level prediction and achieved 74% of accuracy in automatically classifying 4 levels of textual complexity for close school grades. There are no classifiers for nonfiction texts for close grades in Portuguese. In this article, we propose a scheme for manual annotation of texts in 5 grade levels, which will be used for customized reading to avoid the lack of interest by students who are more advanced in reading and the blocking of those that still need to make further progress. We obtained 52% of accuracy in classifying texts into 5 levels and 74% in 3 levels. The results prove to be promising when compared to the state-of-art work.",
    "creator" : "LaTeX with hyperref package"
  }
}