{
  "name" : "1604.01219.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning to Generate Posters of Scientific Papers∗",
    "authors" : [ "Yuting Qiang", "Yanwei Fu", "Yanwen Guo", "Zhi-Hua Zhou", "Leonid Sigal" ],
    "emails" : [ "qiangyuting.new@gmail.com,", "ywguo.nju@gmail.com,", "zhouzh@nju.edu.cn,", "yanwei.fu@disneyresearch.com", "lsigal@disneyresearch.com" ],
    "sections" : [ {
      "heading" : "Introduction",
      "text" : "The emergence of large number of scientific papers in various academic fields and venues (conferences and journals) is noteworthy. For example, IEEE Conference on Computer Vision and Pattern Recognition (CVPR) accepted over 600 papers in 2016 alone. It is time-consuming to read all of these papers for the researchers, particularly those interested to holistically assess state-of-the-art or emerge with understanding of core scientific ideas explored in the last year. Converting a conference paper into a poster provides important means to efficiently and coherently convey core ideas and findings of the original paper. To achieve this goal, it is therefore essential to keep the posters readable, informative and visually aesthetic. It is challenging, however, to design a high-quality scientific poster which meets all of the above design constraints, particularly for those researchers who may not be proficient at design tasks or familiar with design packages (e.g., Adobe Illustrator). ∗This work is supported by NSFC (61333014, 61373059, and 61321491) and JiangsuSF (BK20150016). †Corresponding author Copyright c© 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nIn general, poster design is a complicated and timeconsuming task; both understanding of the paper content and experience in design are required.\nAutomatic tools for scientific poster generation would help researchers by providing them with an easier way to effectively share their research. Further, given avid amount of scientific papers on ArXiv and other on-line repositories, such tools may also provide a way for other researchers to consume the content more easily. Rather than browsing raw papers, they may be able to browse automatically generated poster previews (potentially constructed with their specific preferences in mind).\nHowever, in order to generate a scientific poster in accordance with, and representative of, the original paper, many problems need to be solved: 1) Content extraction. Both important textual and graphical content needs to be extracted from the original paper; 2) Panel layout. Content should fit each panel, and the shape and position of panels should be optimized for readability and design appeal; 3) Graphical element (figures and tables) arrangement. Within each panel, textual content can typically be sequentially itemized, but for graphical elements, their size and placement should be carefully considered. Due to these challenges, there are few automatic tools for scientific poster generation.\nIn this paper, we propose a data-driven method for automatic scientific poster generation (given a corresponding paper). Contents extraction and layout generation are two key components in this process. For content extraction, we use TextRank (Mihalcea and Tarau 2004) to extract textual content, and provide an interface for extraction of graphical content (e.g., figures, tables, etc.). Our approach focuses primarily on poster layout generation. We address the layout in three steps. First, we propose a simple probabilistic graphical model to infer panel attributes. Second, we introduce a tree structure to represent panel layout, based on which we further design a recursive algorithm to generate new layouts. Third, in order to synthesize layout within each panel, we train another probabilistic graphical model to infer the attributes of the graphical elements.\nCompared with posters designed by the authors, our approach can generate different results to adapt to different paper sizes/aspect ratios or styles, by training our model with different dataset, and thus provides more expressiveness in poster layout. To the best of our knowledge, this pa-\nar X\niv :1\n60 4.\n01 21\n9v 1\n[ cs\n.A I]\n5 A\npr 2\n01 6\nper presents the first framework for poster generation from the original scientific paper.\nOur paper makes the following contributions:\n• Probabilistic graphical models are proposed to learn scientific poster design patterns, including panel attributes and graphical element attributes, from existing posters.\n• A new algorithm, that considers both information conveyed and aesthetics, is developed to generate the poster layout.\n• We also collected and make available a Poster-Paper dataset with labelled poster panels and attributes."
    }, {
      "heading" : "Related Work",
      "text" : "General Graphical Design. Graphical design has been studied extensively in computer graphics community. This involves several related, yet different topics, including textbased layout generation (Jacobs et al. 2003; DameraVenkata, Bento, and O’Brien-Strain 2011; Hurst, Li, and Marriott 2009), single-page graphical design (O’Donovan, Agarwala, and Hertzmann 2014; Harrington et al. 2004), photo albums layout (Geigel and Loui 2003), furniture layout (Merrell et al. 2011; Yu et al. 2011), and even interface design (Gajos and Weld 2005). Among them, text-based layout pays more attention on informativeness, while attractiveness also needs to be considered in poster generation. Other topics would take aesthetics as the highest priority. However, some principles (such as alignment or read-order) need to be followed in poster design. In summary, poster generation needs to consider readability, informativeness and aesthetics of the generated posters simultaneously. Manga Layout Generation. Several techniques have been studied to facilitate layout generation for western comics or manga. For example,, for example, scene frame extraction (Arai and Herman 2010; Pang et al. 2014), automatic stylistic manga layout generation (Cao, Chan, and Lau 2012; Jing et al. 2015), and graphical elements composition (Cao, Lau, and Chan 2014). For preview generation of comic episodes (Hoashi et al. 2011), both frame extraction and layout generation are considered. Other research areas, such as manga retargeting (Matsui, Yamasaki, and Aizawa 2011) and manga-like rendering (Qu et al. 2008) also draw considerable attention. However, none of these methods can be directly used to generate scientific posters, which is the focus of this paper.\nOur panel layout generation is inspired by the recent work on Manga layout (Cao, Chan, and Lau 2012). We use a binary tree to represent the panel layout. By contrast, the manga Layout trains a Dirichlet distribution to sample a splitting configuration, and different Dirichlet distribution for each kind of instance need to be trained. Instead, we propose a recursive algorithm to search for the best splitting configuration along a tree."
    }, {
      "heading" : "Overview",
      "text" : "Problem Formulation. Assume that we have a set of posters M and their corresponding scientific papers. Each poster m ∈M includes a set of panels Pm, and each panel p ∈ Pm\nhas a set of graphical elements (figures and tables) Gp. Each panel p is characterized by five attributes:\ntext length (lp) text length within a panel; text ratio (tp) text length within a panel relative to text\nlength of the whole poster, tp = lp/ ∑\nq∈Pm lq;\ngraphical elements ratio (gp) 1 the size of graphical elements within a panel relative to the total size of graphical elements in the poster.\npanel size (sp) and aspect ratio (rp), sp = wp × hp and rp = wp/hp, where wp and hp denote the width and height of a panel with respect to the poster, separately.\nEach graphical element g ∈ Gp has four attributes: graphical element size (sg) and aspect ratio (rg), sg = wg × hg and rg = wg/hg , where wg and hg denote the width and height of a graphical element relative to the whole paper respectively;\nhorizontal position (hg) we assume that panel content is arranged sequentially from top to bottom2; hence only relative horizontal position needs to be considered, which is defined by a discrete variable hg ∈ {left, center, right};\ngraphical element size in poster (ug) is the ratio of the width of the graphical element with width of the panel.\nTo learn how to generate the poster, our goal is to determine the above attributes of each panel p and each graphical element g ∈ Gp, as well as to infer the arrangement of all panels.\nIntuitively, a trivial solution is to use a learning model (e.g., SVR) to learn how to regress these attributes, including sp, rp, ug , and hg , while regarding tp, gp , lp, rg , and sg as features. However, such a solution lacks an insight mechanism for exploring the relationships between the panel attributes (e.g., sp) and graphical elements attributes (e.g., ug). And it may fail to meet the requirements of readability, informativeness, and aesthetics. We thus propose a novel framework to solve our problem. Overview. To generate a readable, informative and aesthetic poster, we simulate the rule-of-thumb on how people design the posters in practice. We generate the panel layout, then arrange the textual and graphical elements within each panel.\nOur framework overall has four steps (as shown in Figure 1). However, the core of our framework focuses on three specific algorithms designed to facilitate poster generation. We first extract textual content from the paper using TextRank (Mihalcea and Tarau 2004)3, this will be detailed in the Experimental Result section. Non-textual content (figures and tables) are extracted by user interaction. All these extracted contents are sequentially arranged and represented by the first blob in Figure 1. Inference of the initial panel key\n1Note that there is a little difference between this variable and text ratio tp. We do not use the figure size in poster. Instead, we use the corresponding figure from the original paper.\n2This holds true when using latex beamer to make posters. 3We use TextRank for text content extraction, however, TextRank can be replaced with other state-of-the-art textual summary algorithms.\nattributes (such as panel size sp and aspect ratio rp) is then conducted by learning a probabilistic graphical model from the training data. Furthermore, panel layout is synthesized by developing a recursive algorithm to further update these key attributes (i.e., sp and rp) and generate an informative and aesthetic panel layout. Finally, we compose panels by utilizing the graphical model to further synthesize the visual properties of each panel (such as the size and position of its graphical elements)."
    }, {
      "heading" : "Methodology",
      "text" : "Panel Attribute Inference. Our approach tries to divide a scientific poster into several rectangular panel blocks. Each panel should not only be of an appropriate size, to contain corresponding textual and graphical content, but also be in a suitable shape (aspect ratio) to maximize aesthetic appeal. Our approach learns a probabilistic graphical model to infer the initial values for the size and aspect ratio of each panel.\nAs each panel is composed of both textual description and graphical elements, we assume that panel size (sp) and aspect ratio (rp) are conditionally dependent on text ratio tp and graphical element ratio gp. Therefore, the likelihood of a set of panels p can be defined as:\nPr(sp, rp|tp, gp) = ∏ p∈P Pr(sp|tp, gp)Pr(rp|tp, gp) (1)\nwhere Pr(sp|tp, gp) and Pr(rp|tp, gp) are conditional probability distributions (CPDs) of sp and rp given tp and gp. We define them as two conditional linear Gaussian distributions:\nPr(sp|tp, gp) = N(sp;ws · [tp, gp, 1]T, σs) (2)\nPr(rp|tp, gp) = N(rp;wr · [tp, gp, 1]T, σr) (3) where tp and gp are defined by the content extraction step demonstrated in Figure 1; ws and wr are the parameters that leverage the influence of various factors; σs and σr are the variances. The parameters (ws, wr, σs and σr) are estimated using maximum likelihood from training data. Using the learned parameters, initial attributes of each panel can be inferred.\nNote that in order to learn from limited data, this step actually employs two assumptions: (1) sp and rp are conditionally independent; (2) The attribute sets of panels are independent. We need the panels to be neither too small in size (sp), nor too distorted in aspect ratio (rp), to ensure readable, informative and aesthetic poster. The two assumptions introduced here are sufficient for this task. Furthermore, the attribute values estimated from this step are just good initial values for the property of each panel. We use the next two steps to further relax these assumptions and discuss the relationship between sp and rp, as well as the relationship among different panels (Algorithm 1).\nTo ease exposition, we denote the set of panels as L = {(sp1 , rp2), (sp2 , rp2), · · · , (spk , rpk)}, where spi and rpi are the size and aspect ratio of ith panel pi, separately; with |L| = k. Panel Layout Generation. One conventional way to design posters is to simply arrange them in two or three columns style. This scheme, although simple, however, makes all posters look similar and unattractive. Inspired by manga layout generation (Cao, Chan, and Lau 2012), we propose a more vivid panel layout generation method. Specifically, we arrange the panels with a binary tree structure to help represent the panel layout. The panel layout generation is then formulated as a process of recursively splitting of a page, as is illustrated and explained in Figure 2.\nConveying information is the most important goal for a scientific poster, thus we attempt to maintain relative size for each panel during panel layout generation. This motivates the following loss function for the panel shape variation,\nl(pi) = |rpi − r ′ pi | (4)\nwhere r ′\npi is the aspect ratio of a panel after optimization. This will lead to a combined aesthetic loss for the poster,\nLoss(L,L ′ ) = k∑ i=1 l(pi) (5)\nwhere L ′\nis the poster panel set after optimization. In each splitting step, the combinatorial choices for splitting posi-\ntions can be recursively computed and compared with respect to the loss function above. We choose the panel attributes with the lowest loss (Eq. 5). The whole algorithm is summarized in Algorithm 1. Composition within a Panel. Having inferred layout of the panels, we turn our attention to composition of graphical elements within the panels. We model and infer attributes of graphical elements using another probabilistic graphical model. Particularly, the key attributes we need to estimate are the horizontal position hg and graphical element size ug . In our model, horizontal position hg relies on sp, lp and sg , while ug relies on rp, sg and rg , so the likelihood is\nPr(hg, ug|sp, rp, lp, sg, rg) =∏ p∈P ∏ g∈p Pr(hg|sp, lp, sg)Pr(ug|rp, sg, rg) (6)\nPr(ug|sp, lp, sg) and Pr(hg|rp, sg, rg) are the conditional probability distributions (CPDs) of ug and hg given sp, lp, rp, sg and rg respectively. The conditional linear Gaussian distribution is also used here,\nPr(ug|sp, lp, sg) = N(ug|wu · [sp, lp, sg, 1]T, σu) (7) where wu is the parameter to balance the influence of different factors. Since we take horizontal position hg as an enumerated variable, a natural way to estimate it is to make it a classification problem by using the softmax function,\nPr(hg = i|rp, sg, rg) = ewhi·[rp,sg,rg,1] T∑H j=1 e whj ·[rp,sg,rg,1]T (8)\nwhere H is the cardinality of the value set of hg , i.e. H = 3, whi is the ith row of wh. The maximum likelihood method is used to estimate parameters, including wu,wh and σu.\nAlgorithm 1 Panel layout generation Input:\nPanels which we learned from graphical model L = {(sp1 , rp1), (sp2 , rp2), · · · , (spk , rpk)}; rectangular page area x, y, w, h.\nOutput: 1: if k == 1 then 2: adjust panels[0] to adapt to the whole rectangular\npage area, return the aesthetic loss: |rp0 − w/h|; 3: else 4: for each i ∈ [1, k − 1] do 5: t = ∑i j=1 spj/ ∑n j=1 spj ; 6: Loss1 = Panel Arrangement((sp1 , rp1), (sp2 , rp2), · · · , (spi , rpi), x, y, w, h× t); 7: Loss2 = Panel Arrangement((spi+1 , rpi+1), (spi+2 , rpi+2), · · · , (spk , rpk), x, y+h×t, w, h×(1−t));\n8: if Loss > Loss1 + Loss2 then 9: Loss = Loss1 + Loss2;\n10: record this arrangement; 11: end if 12: Loss1 = Panel Arrangement((sp1 , rp1), (sp2 , rp2), · · · , (spi , rpi), x, y, w × t, h); 13: Loss2 = Panel Arrangement((spi+1 , rpi+1), (spi+2 ,\nrpi+2), · · · , (spk , rpk), x + w ∗ t, y, w × (1 − t), h);\n14: if Loss > Loss1 + Loss2 then 15: Loss = Loss1 + Loss2; 16: record this arrangement; 17: end if 18: end for 19: end if 20: return Loss and arrangement.\nDifferent from Eq. 1, directly inferring hg and ug is not advisable, since the panel content may exceed the panel bounding box and affect the aesthetic measure of a poster. To avoid this problem, we employ the likelihood-weighted sampling method (Fung and Chang 1990) to generate samples from the model, by maximizing the likelihood function (Eq. 6) with this strict constraint,∑\ng∈p hp × ug + α× β × lp/wp < hp (9)\nwhere α and β denote the width and height of a single character respectively. The first term of the above constraint indicates the height of graphical elements while the second term represents the height of textual contents."
    }, {
      "heading" : "Experimental Results",
      "text" : "Experimental Setup. We collect and make available to the community the first Poster-Paper dataset. Specifically, we selected 25 well-designed pairs of scientific papers and their corresponding posters from 600 publicly available pairs we collected. These papers are all about scientific topics, and their posters have relatively similar design styles. We further\nannotate panel attributes, such as panel width, panel height and so on. We make a training and testing split: 20 pairs for training and five for testing. There is total of 173 panels in our dataset. 143 for training and 30 for testing.\nWe use TextRank to extract textual content from the original paper. In order to give different importance of different sections, we can set different extraction ratio for each section. This will result in important sections generating more content and hence occupying bigger panels. For simplicity, this paper uses equal important weights for all sections. User-interaction is also required to highlight and select important figures and tables from original paper. We use the Bayesian Network Toolbox (BNT) (Murphy 2002) to estimate key parameters. For graphical element attributes inference, we generate 1000 samples by the likelihood-weighted sampling method (Fung and Chang 1990) for Eq. 6 while the constraint Eq.9 is used. With the inferred metadata, the final poster is generated in latex Beamerposter format with Lankton theme.\nFor baseline comparison, we invite three second-year Phd students, who are not familiar with our project, to hand design posters for the test set. These three students work in computer vision and machine learning and have not yet published any papers on these topics; hence they are novices to research. Given the test set papers, we ask the students to work together and design a poster for each paper. Running time. Our framework is very efficient. Our experiments were done on a PC with an Intel Xeon 2.0 GHz CPU and 144GB RAM. Tab. 1 shows the average time we needed for each step. Strictly speaking, we can not compare with “previous methods”, since we are the first work on poster generation and there is no existing directly comparable work. Nevertheless, we argue that the total running time is significantly less than the time people require to design a good poster, it is also less than the time spent to generate the posters made by three novices in Quantitative evaluation section. Quantitative Evaluation. We quantitatively evaluate the effectiveness of our approach.\n(1) Effectiveness of panel inference. For this step, we compare the inferred size and aspect ratio of panels with the trivial solution – SVR which trains a linear regressor4\n4sp and rp are used as features for SVR. The parameters are chosen using cross-validation. Nonlinear kernels (such as RBF) perform worse due to over-fitting on training data.\nto predict the panel size and panel aspect ratio from training data. We use the panel attributes from the original posters5 as the ground-truth and compute the mean-square error (MSE) of inferred values versus ground-truth values. Our results can achieve 3650.4 and 0.67 for panel size and aspect ratio. By contrast, the values of SVR method are 3831.3 and 0.76 respectively. This shows that our algorithm can better estimates the panel attributes than SVR.\n(2) User study. User study is employed to compare our results with original posters and posters made by novices. We invited 10 researchers (who are experts on the evaluated topic and kept unknown to our projects) to evaluate these results on readability, informativeness and aesthetics. Each researcher is sequentially shown the three results generated (in randomized order) and asked to score the results from 0 − 10, where 0, 5 and 10 indicate the lowest, middle and highest scores of corresponding metrics. The final results are averaged for each metric item.\nAs in Tab. 2, our method is comparable to original posters on readability and informativeness; and it is significantly better than posters made by novices. This validates the effectiveness of our method, since the inferred panel attributes and generated panel layout will save most valuable and important information. In contrast, our method is lower than the original posters on aesthetics metric (yet, still higher than those from novices). This is reasonable, since aesthetics is a relatively subjective metric and aesthetics generally requires a “human touch”. It is an open problem to generate more aesthetic posters from papers. Qualitative Evaluation of Three Methods. We qualitatively compare our result (Figure 3(b)) with the poster from novices in Figure 3(a) and the original poster Figure 3(c). All of them are for the same paper.\n5Note that, though the panels of original poster may not be the best ones, they are the best candidate to serve as the ground truth here.\nIt is interesting to show that if compared with the panel layout of original poster, our panel layout looks more similar to the original one than the one by novices. This is due to, first, the Poster-Paper dataset has a relatively similar graphical design with high quality, and second, our split and panel layout algorithms that work well to simulate the way how people design posters. In contrast, the poster designed by novices in Figure 3(a) has two columns, which appears less attractive to our 10 researchers; it takes the novices around 2 hours to finish all the posters. Further Qualitative Evaluation. We further qualitatively evaluate our results (Figure 4) by the general graphical design principles (O’Donovan, Agarwala, and Hertzmann 2014), i.e., flow, alignment,and overlap and boundaries.\nFlow It is essential for a scientific poster to present information in a clear read-order, i.e. readability. People always read a scientific poster from left to right and from top to bottom. Since Algorithm 1 recursively splits the page of poster into left, right or top, bottom, the panel layout we generate ensure that the read-order matches the section order of original paper. Within each panel, our algorithm also sequentially organizes contents which also follow the section order of original paper and this improves the readability.\nAlignment. Compared with the complex alignment constraint in (O’Donovan, Agarwala, and Hertzmann 2014), our formulation is much simpler and uses an enumeration variable to indicate the horizontal position of graphical elements\nhg . This simplification does not spoil our results which still have reasonable alignment as illustrated in Figure 4 and quantitatively evaluated by three metrics in Tab. 2.\nOverlap and boundaries. Overlapped panels will make the poster less readable and less esthetic. To avoid this, our approach (1) recursively splits the page for panel layout; (2) sequentially arranges the panels; (3) enforces the constraint Eq. 9 to penalize the cases of overlapping between graphical elements and panel boundaries. As a result, our algorithm can achieve reasonable results without significant overlapping and/or crossing boundaries. Similar to the manually created poster – Figure 3(c), our result (i.e., Figure 3(b)) does not have significantly overlapped panels and/or boundaries."
    }, {
      "heading" : "Conclusion and Future Work",
      "text" : "Automatic tools for scientific poster generation are important for poster designers. Designers can save a lot of time with these kinds of tools. Design is a hard work, especially for scientific posters, which require careful consideration of both utility and aesthetics. Abstract principles about scientific poster design can not help designers directly. By contrast, we propose an approach to learn design patterns from existing examples, and this approach will hopefully lead to an automatic tool for scientific poster generation to aid designers.\nExcept for scientific poster design, our approach also provides a framework to learn other kinds of design patterns, for example web-page design, single-page graphical design and so on. And by providing different set of training data, our approach could generate different layout styles. Our work has several limitations. We do not consider font types in our current implementation and only adopt a simple yet effective aesthetic metric. We plan to address these problems in future."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We would like to thank the anonymous reviewers for their insightful suggestions in improving this paper."
    } ],
    "references" : [ {
      "title" : "Method for automatic e-comic scene frame extraction for reading comic on mobile devices",
      "author" : [ "Arai", "K. Herman 2010] Arai", "T. Herman" ],
      "venue" : "In Information Technology: New Generations (ITNG),",
      "citeRegEx" : "Arai et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Arai et al\\.",
      "year" : 2010
    }, {
      "title" : "Automatic stylistic manga layout",
      "author" : [ "Chan Cao", "Y. Lau 2012] Cao", "A.B. Chan", "R.W.H. Lau" ],
      "venue" : "ACM Trans. Graph",
      "citeRegEx" : "Cao et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2012
    }, {
      "title" : "Look over here: Attention-directing composition of manga elements",
      "author" : [ "Lau Cao", "Y. Chan 2014] Cao", "R.W. Lau", "A.B. Chan" ],
      "venue" : "ACM Transactions on Graphics",
      "citeRegEx" : "Cao et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2014
    }, {
      "title" : "Probabilistic document model for automated document composition",
      "author" : [ "Bento Damera-Venkata", "J. Bento", "E. O’Brien-Strain" ],
      "venue" : "In Proceedings of the 11th ACM symposium on Document engineering,",
      "citeRegEx" : "Damera.Venkata et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Damera.Venkata et al\\.",
      "year" : 2011
    }, {
      "title" : "Weighing and integrating evidence for stochastic simulation in bayesian networks. 209–220",
      "author" : [ "Fung", "R.M. Chang 1990] Fung", "Chang", "K.-C" ],
      "venue" : null,
      "citeRegEx" : "Fung et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Fung et al\\.",
      "year" : 1990
    }, {
      "title" : "Preference elicitation for interface optimization",
      "author" : [ "Gajos", "K. Weld 2005] Gajos", "D.S. Weld" ],
      "venue" : "In Proceedings of the 18th annual ACM symposium on User interface software and technology,",
      "citeRegEx" : "Gajos et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Gajos et al\\.",
      "year" : 2005
    }, {
      "title" : "Using genetic algorithms for album page layouts. IEEE multimedia (4):16–27",
      "author" : [ "Geigel", "J. Loui 2003] Geigel", "A. Loui" ],
      "venue" : null,
      "citeRegEx" : "Geigel et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Geigel et al\\.",
      "year" : 2003
    }, {
      "title" : "Aesthetic measures for automated document layout",
      "author" : [ "Harrington" ],
      "venue" : "In Proceedings of the 2004 ACM symposium on Document engineering,",
      "citeRegEx" : "Harrington,? \\Q2004\\E",
      "shortCiteRegEx" : "Harrington",
      "year" : 2004
    }, {
      "title" : "Automatic preview generation of comic episodes for digitized comic search",
      "author" : [ "Hoashi" ],
      "venue" : "In Proceedings of the 19th ACM international conference on Multimedia,",
      "citeRegEx" : "Hoashi,? \\Q2011\\E",
      "shortCiteRegEx" : "Hoashi",
      "year" : 2011
    }, {
      "title" : "Review of automatic document formatting",
      "author" : [ "Li Hurst", "N. Marriott 2009] Hurst", "W. Li", "K. Marriott" ],
      "venue" : "In Proceedings of the 9th ACM symposium on Document engineering,",
      "citeRegEx" : "Hurst et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hurst et al\\.",
      "year" : 2009
    }, {
      "title" : "Adaptive grid-based document layout",
      "author" : [ "Jacobs" ],
      "venue" : null,
      "citeRegEx" : "Jacobs,? \\Q2003\\E",
      "shortCiteRegEx" : "Jacobs",
      "year" : 2003
    }, {
      "title" : "Content-aware video2comics with manga-style layout",
      "author" : [ "Jing" ],
      "venue" : "Multimedia, IEEE Transactions on",
      "citeRegEx" : "Jing,? \\Q2015\\E",
      "shortCiteRegEx" : "Jing",
      "year" : 2015
    }, {
      "title" : "Interactive manga retargeting",
      "author" : [ "Yamasaki Matsui", "Y. Aizawa 2011] Matsui", "T. Yamasaki", "K. Aizawa" ],
      "venue" : "In ACM SIGGRAPH 2011 Posters,",
      "citeRegEx" : "Matsui et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Matsui et al\\.",
      "year" : 2011
    }, {
      "title" : "Interactive furniture layout using interior design guidelines",
      "author" : [ "Merrell" ],
      "venue" : "ACM Transactions on Graphics",
      "citeRegEx" : "Merrell,? \\Q2011\\E",
      "shortCiteRegEx" : "Merrell",
      "year" : 2011
    }, {
      "title" : "Textrank: Bringing order into texts. Association for Computational Linguistics",
      "author" : [ "Mihalcea", "R. Tarau 2004] Mihalcea", "P. Tarau" ],
      "venue" : null,
      "citeRegEx" : "Mihalcea et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Mihalcea et al\\.",
      "year" : 2004
    }, {
      "title" : "Learning layouts for single-pagegraphic designs. Visualization and Computer Graphics",
      "author" : [ "Agarwala O’Donovan", "P. Hertzmann 2014] O’Donovan", "A. Agarwala", "A. Hertzmann" ],
      "venue" : "IEEE Transactions on 20(8):1200–1213",
      "citeRegEx" : "O.Donovan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "O.Donovan et al\\.",
      "year" : 2014
    }, {
      "title" : "A robust panel extraction method for manga",
      "author" : [ "Pang" ],
      "venue" : "In Proceedings of the ACM International Conference on Multimedia, ACM MM",
      "citeRegEx" : "Pang,? \\Q2014\\E",
      "shortCiteRegEx" : "Pang",
      "year" : 2014
    }, {
      "title" : "Richness-preserving manga screening",
      "author" : [ "Qu" ],
      "venue" : null,
      "citeRegEx" : "Qu,? \\Q2008\\E",
      "shortCiteRegEx" : "Qu",
      "year" : 2008
    }, {
      "title" : "Make it home: automatic optimization of furniture arrangement",
      "author" : [ "Yu" ],
      "venue" : "ACM Transactions on Graphics (TOG)-Proceedings of ACM SIGGRAPH 2011, v. 30,",
      "citeRegEx" : "Yu,? \\Q2011\\E",
      "shortCiteRegEx" : "Yu",
      "year" : 2011
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "Researchers often summarize their work in the form of posters. Posters provide a coherent and efficient way to convey core ideas from scientific papers. Generating a good scientific poster, however, is a complex and time consuming cognitive task, since such posters need to be readable, informative, and visually aesthetic. In this paper, for the first time, we study the challenging problem of learning to generate posters from scientific papers. To this end, a data-driven framework, that utilizes graphical models, is proposed. Specifically, given content to display, the key elements of a good poster, including panel layout and attributes of each panel, are learned and inferred from data. Then, given inferred layout and attributes, composition of graphical elements within each panel is synthesized. To learn and validate our model, we collect and make public a Poster-Paper dataset, which consists of scientific papers and corresponding posters with exhaustively labelled panels and attributes. Qualitative and quantitative results indicate the effectiveness of our approach. Introduction The emergence of large number of scientific papers in various academic fields and venues (conferences and journals) is noteworthy. For example, IEEE Conference on Computer Vision and Pattern Recognition (CVPR) accepted over 600 papers in 2016 alone. It is time-consuming to read all of these papers for the researchers, particularly those interested to holistically assess state-of-the-art or emerge with understanding of core scientific ideas explored in the last year. Converting a conference paper into a poster provides important means to efficiently and coherently convey core ideas and findings of the original paper. To achieve this goal, it is therefore essential to keep the posters readable, informative and visually aesthetic. It is challenging, however, to design a high-quality scientific poster which meets all of the above design constraints, particularly for those researchers who may not be proficient at design tasks or familiar with design packages (e.g., Adobe Illustrator). ∗This work is supported by NSFC (61333014, 61373059, and 61321491) and JiangsuSF (BK20150016). †Corresponding author Copyright c © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. In general, poster design is a complicated and timeconsuming task; both understanding of the paper content and experience in design are required. Automatic tools for scientific poster generation would help researchers by providing them with an easier way to effectively share their research. Further, given avid amount of scientific papers on ArXiv and other on-line repositories, such tools may also provide a way for other researchers to consume the content more easily. Rather than browsing raw papers, they may be able to browse automatically generated poster previews (potentially constructed with their specific preferences in mind). However, in order to generate a scientific poster in accordance with, and representative of, the original paper, many problems need to be solved: 1) Content extraction. Both important textual and graphical content needs to be extracted from the original paper; 2) Panel layout. Content should fit each panel, and the shape and position of panels should be optimized for readability and design appeal; 3) Graphical element (figures and tables) arrangement. Within each panel, textual content can typically be sequentially itemized, but for graphical elements, their size and placement should be carefully considered. Due to these challenges, there are few automatic tools for scientific poster generation. In this paper, we propose a data-driven method for automatic scientific poster generation (given a corresponding paper).",
    "creator" : "LaTeX with hyperref package"
  }
}