{
  "name" : "1105.5449.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Gianni Di Caro", "Marco Dorigo" ],
    "emails" : [ "gdicaro@iridia.ulb.ac.be", "mdorigo@ulb.ac.be" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Journal of Arti cial Intelligence Research 9 (1998) 317-365 Submitted 5/98; published 12/98 AntNet: Distributed Stigmergetic Control forCommunications NetworksGianni Di Caro gdicaro@iridia.ulb.ac.beMarco Dorigo mdorigo@ulb.ac.beIRIDIA, Universit e Libre de Bruxelles50, av. F. Roosevelt, CP 194/6, 1050 - Brussels, BelgiumAbstractThis paper introduces AntNet, a novel approach to the adaptive learning of routingtables in communications networks. AntNet is a distributed, mobile agents based MonteCarlo system that was inspired by recent work on the ant colony metaphor for solvingoptimization problems. AntNet's agents concurrently explore the network and exchangecollected information. The communication among the agents is indirect and asynchronous,mediated by the network itself. This form of communication is typical of social insectsand is called stigmergy. We compare our algorithm with six state-of-the-art routing algo-rithms coming from the telecommunications and machine learning elds. The algorithms'performance is evaluated over a set of realistic testbeds. We run many experiments overreal and arti cial IP datagram networks with increasing number of nodes and under sev-eral paradigmatic spatial and temporal tra c distributions. Results are very encouraging.AntNet showed superior performance under all the experimental conditions with respectto its competitors. We analyze the main characteristics of the algorithm and try to explainthe reasons for its superiority.1. IntroductionWorldwide demand and supply of communications networks services are growing exponen-tially. Techniques for network control (i.e., online and o -line monitoring and managementof the network resources) play a fundamental role in best exploiting the new transmissionand switching technologies to meet user's requests.Routing is at the core of the whole network control system. Routing, in conjunctionwith the admission, ow, and congestion control components, determines the overall networkperformance in terms of both quality and quantity of delivered service (Walrand & Varaiya,1996). Routing refers to the distributed activity of building and using routing tables, onefor each node in the network, which tell incoming data packets which outgoing link to useto continue their travel towards the destination node.Routing protocols and policies have to accommodate con icting objectives and con-straints imposed by technologies and user requirements rapidly evolving under commercialand scienti c pressures. Novel routing approaches are required to e ciently manage dis-tributed multimedia services, mobile users and networks, heterogeneous inter-networking,service guarantees, point-to-multipoint communications, etc. (Sandick & Crawley, 1997;The ATM Forum, 1996).The adaptive and distributed routing algorithm we propose in this paper is a mobile-agent-based, online Monte Carlo technique inspired by previous work on arti cial antc 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.\nDi Caro & Dorigocolonies and, more generally, by the notion of stigmergy (Grass e, 1959), that is, the in-direct communication taking place among individuals through modi cations induced intheir environment.Algorithms that take inspiration from real ants' behavior in nding shortest paths (Goss,Aron, Deneubourg, & Pasteels, 1989; Beckers, Deneubourg, & Goss, 1992) using as infor-mation only the trail of a chemical substance (called pheromone) deposited by other ants,have recently been successfully applied to several discrete optimization problems (Dorigo,Maniezzo, & Colorni, 1991; Dorigo, 1992; Dorigo, Maniezzo, & Colorni, 1996; Dorigo &Gambardella, 1997; Schoonderwoerd, Holland, Bruten, & Rothkrantz, 1996; Schoonderwo-erd, Holland, & Bruten, 1997; Costa & Hertz, 1997). In all these algorithms a set of arti cialants collectively solve the problem under consideration through a cooperative e ort. Thise ort is mediated by indirect communication of information on the problem structure theants concurrently collect while building solutions by using a stochastic policy. Similarly,in AntNet, the algorithm we propose in this paper, a set of concurrent distributed agentscollectively solve the adaptive routing problem. Agents adaptively build routing tables andlocal models of the network status by using indirect and non-coordinated communicationof information they collect while exploring the network.To ensure a meaningful validation of our algorithm performance we devised a realisticsimulation environment in terms of network characteristics, communications protocol andtra c patterns. We focus on IP (Internet Protocol) datagram networks with irregulartopology and consider three real and arti cial topologies with an increasing number ofnodes and several paradigmatic temporal and spatial tra c distributions. We report onthe behavior of AntNet as compared to some e ective static and adaptive state-of-the-artrouting algorithms (vector-distance and link-state shortest paths algorithms (Steenstrup,1995), and recently introduced algorithms based on machine learning techniques).AntNet shows the best performance and the most stable behavior for all the consideredsituations. In many experiments its superiority is striking. We discuss the results and themain properties of our algorithm, as compared with its competitors.The paper is organized as follows. In Section 2 the de nition, taxonomy and charac-teristics of the routing problem are reported. In Section 3 we describe the communicationnetwork model we used. Section 4 describes in detail AntNet, our novel routing algorithm,while in Section 5 we brie y describe the algorithms with which we compared AntNet. InSection 6, the experimental settings are reported in terms of tra c, networks and algorithmparameters. Section 7 reports several experimental results. In Section 8 we discuss theseresults and try to explain AntNet's superior performance. Finally, in Section 9, we discussrelated work, and in Section 10, we draw some conclusions and outline directions for futureresearch.2. Routing: De nition and CharacteristicsRouting in distributed systems can be characterized as follows. Let G = (V;E) be a directedweighted graph, where each node in the set V represents a processing/queuing and/or for-warding unit and each edge is a transmission system. The main task of a routing algorithmis to direct data ow from source to destination nodes maximizing network performance.318\nAntNet: Distributed Stigmergetic Control for Communications NetworksIn the problems we are interested in, the data ow is not statically assigned and it followsa stochastic pro le that is very hard to model.In the speci c case of communications networks (Steenstrup, 1995; Bertsekas & Gallager,1992), the routing algorithm has to manage a set of basic functionalities and it tightlyinteracts with the congestion and admission control algorithms, with the links' queuingpolicy, and with the user-generated tra c. The core of the routing functions is (i) theacquisition, organization and distribution of information about user-generated tra c andnetwork states, (ii) the use of this information to generate feasible routes maximizing theperformance objectives, and (iii) the forwarding of user tra c along the selected routes.The way the above three functionalities are implemented strongly depends on the un-derlying network switching and transmission technology, and on the features of the otherinteracting software layers. Concerning point (iii), two main forwarding paradigms are inuse: circuit and packet-switching (also indicated with the terms connection-oriented andconnection-less). In the circuit-switching approach, a setup phase looks for and reserves theresources that will be assigned to each incoming session. In this case, all the data packetsbelonging to the same session will follow the same path. Routers are required to keep stateinformation about active sessions. In the packet-switching approach, there is no reservationphase, no state information is maintained at routers and data packets can follow di erentpaths. In each intermediate node an autonomous decision is taken concerning the node'soutgoing link that has to be used to forward the data packet toward its destination.In the work described in this paper, we focus on the packet-switching paradigm, butthe technique developed here can be used also to manage circuit-switching and we expectto have qualitatively similar results.2.1 A Broad TaxonomyA common feature of all the routing algorithms is the presence in every network node ofa data structure, called routing table, holding all the information used by the algorithm tomake the local forwarding decisions. The routing table is both a local database and a localmodel of the global network status. The type of information it contains and the way thisinformation is used and updated strongly depends on the algorithm's characteristics. Abroad classi cation of routing algorithms is the following: centralized versus distributed; static versus adaptive.In centralized algorithms, a main controller is responsible for updating all the node'srouting tables and/or to make every routing decision. Centralized algorithms can be usedonly in particular cases and for small networks. In general, the delays necessary to gatherinformation about the network status and to broadcast the decisions/updates make theminfeasible in practice. Moreover, centralized systems are not fault-tolerant. In this work,we will consider exclusively distributed routing.In distributed routing systems, the computation of routes is shared among the networknodes, which exchange the necessary information. The distributed paradigm is currentlyused in the majority of network systems.In static (or oblivious) routing systems, the path taken by a packet is determined onlyon the basis of its source and destination, without regard to the current network state. This319\nDi Caro & Dorigopath is usually chosen as the shortest one according to some cost criterion, and it can bechanged only to account for faulty links or nodes.Adaptive routers are, in principle, more attractive, because they can adapt the rout-ing policy to time and spatially varying tra c conditions. As a drawback, they can causeoscillations in selected paths. This fact can cause circular paths, as well as large uctu-ations in measured performance. In addition, adaptive routing can lead more easily toinconsistent situations, associated with node or link failures or local topological changes.These stability and inconsistency problems are more evident for connection-less than forconnection-oriented networks (Bertsekas & Gallager, 1992).Another interesting way of looking at routing algorithms is from an optimization per-spective. In this case the main paradigms are: minimal routing versus non-minimal routing; optimal routing versus shortest path routing.Minimal routers allow packets to choose only minimal cost paths, while non-minimalalgorithms allow choices among all the available paths following some heuristic strategies(Bolding, Fulgham, & Snyder, 1994).Optimal routing has a network-wide perspective and its objective is to optimize a func-tion of all individual link ows (usually this function is a sum of link costs assigned on thebasis of average packet delays) (Bertsekas & Gallager, 1992).Shortest path routing has a source-destination pair perspective: there is no global costfunction to optimize. Its objective is to determine the shortest path (minimum cost) betweentwo nodes, where the link costs are computed (statically or adaptively) following somestatistical description of the link states. This strategy is based on individual rather thangroup rationality (Wang & Crowcroft, 1992). Considering the di erent content stored ineach routing table, shortest path algorithms can be further subdivided into two classescalled distance-vector and link-state (Steenstrup, 1995).Optimal routing is static (it can be seen as the solution of a multicommodity ow prob-lem) and requires the knowledge of all the tra c characteristics. Shortest paths algorithmsare more exible, they don't require a priori knowledge about the tra c patterns and theyare the most widely used routing algorithms.In appendix A, a more detailed description of the properties of optimal and shortestpath routing algorithms is reported.In Section 4, we introduce a novel distributed adaptive method, AntNet, that shares thesame optimization perspective as (minimal or non-minimal) shortest path algorithms butnot their usual implementation paradigms (as depicted in appendix A).2.2 Main Characteristics of the Routing ProblemThe main characteristics of the routing problem in communications networks can be sum-marized in the following way: Intrinsically distributed with strong real-time constraints: in fact, the database andthe decision system are completely distributed over all the network nodes, and failuresand status information propagation delays are not negligible with respect to the user's320\nAntNet: Distributed Stigmergetic Control for Communications Networkstra c patterns. It is impossible to get complete and up-to-date knowledge of the dis-tributed state, that remains hidden. At each decision node, the routing algorithm canonly make use of local, up-to-date information, and of non-local, delayed informationcoming from the other nodes. Stochastic and time-varying: the session arrival and data generation process is, inthe general case, non-stationary and stochastic. Moreover, this stochastic processinteracts recursively with the routing decisions making it infeasible to build a work-ing model of the whole system (to be used for example in a dynamic programmingframework). Multi-objective: several con icting performance measures are usually taken into ac-count. The most common are throughput (bit/sec) and average packet delay (sec).The former measures the quantity of service that the network has been able to o erin a certain amount of time (amount of correctly delivered bits per time unit), whilethe latter de nes the quality of service produced at the same time. Citing Bertsekasand Gallager (1992), page 367: \\the e ect of good routing is to increase throughputfor the same value of average delay per packet under high o ered load conditions andto decrease average delay per packet under low and moderate o ered load conditions\".Other performance measures consider the impact of the routing algorithm on the net-work resources in terms of memory, bandwidth and computation, and the algorithmsimplicity, exibility, etc. Multi-constraint: constraints are imposed by the underlying network technology, thenetwork services provided and the user services requested. In general, users ask forlow-cost, high-quality, reliable, distributedmultimedia services available across hetero-geneous static and mobile networks. Evaluating technological and commercial factors,network builders and service providers try to accommodate these requests while max-imizing some pro t criteria. Moreover, a high level of fault-tolerance and reliability isrequested in modern high-speed networks, where user sessions can formulate preciserequests for network resources. In this case, once the session has been accepted, thesystem should be able to guarantee that the session gets the resources it needs, underany recoverable fault event.It is interesting to note that the above characteristics make the problem of routing belongto the class of reinforcement learning problems with hidden state (Bertsekas & Tsitsiklis,1996; Kaelbling, Littman, & Moore, 1996; McCallum, 1995). A distributed system of agents,the components of the routing algorithm in each node, determine a continual and onlinelearning of the best routing table values with respect to network's performance criteria. Anexact measure of evaluation that scores forwarding decisions is not available, neither onlinenor in the form of a training set. Moreover, because of the distributed nature of the problemand of its constraints, the complete state of the network is hidden to each agent.3. The Communication Network ModelIn this paper, we focus on irregular topology connection-less networks with an IP-like net-work layer (in the ISO-OSI terminology) and a very simple transport layer. In particular,we focus on wide-area networks (WAN). In these cases, hierarchical organization schemes321\nDi Caro & Dorigoare adopted.1 Roughly speaking, sub-networks are seen as single host nodes connected tointerface nodes called gateways. Gateways perform fairly sophisticated network layer tasks,including routing. Groups of gateways, connected by an arbitrary topology, de ne logicalareas. Inside each area, all the gateways are at the same hierarchical level and \\ at\" routingis performed among them. Areas communicate only by means of area border gateways. Inthis way, the computational complexity of the routing problem, as seen by each gateway, ismuch reduced (e.g., in the Internet, OSPF areas typically group 10 to 300 gateways), whilethe complexity of the design and management of the routing protocol is much increased.The instance of our communication network is mapped on a directed weighted graphwith N processing/forwarding nodes. All the links are viewed as bit pipes characterizedby a bandwidth (bit/sec) and a transmission delay (sec), and are accessed following astatistical multiplexing scheme. For this purpose, every node, of type store-and-forward,holds a bu er space where the incoming and the outgoing packets are stored. This bu eris a shared resource among all the queues attached to every incoming and outgoing link ofthe node. All the traveling packets are subdivided in two classes: data and routing packets.All the packets in the same class have the same priority, so they are queued and served onthe basis of a rst-in- rst-out policy, but routing packets have a greater priority than datapackets. The workload is de ned in terms of applications whose arrival rate is dictated bya selected probabilistic model. By application (or session, or connection in the following),we mean a process sending data packets from an origin node to a destination node. Thenumber of packets to send, their sizes and the intervals between them are assigned accordingto some de ned stochastic process. We didn't make any distinction among nodes, they actat the same time as hosts (session end-points) and gateways/routers (forwarding elements).The adopted workload model incorporates a simple ow control mechanism implementedby using a xed production window for the session's packets generation. The windowdetermines the maximum number of data packets waiting to be sent. Once sent, a packet isconsidered to be acknowledged. This means that the transport layer neither manages errorcontrol, nor packet sequencing, nor acknowledgements and retransmissions.2For each incoming packet, the node's routing component uses the information stored inthe local routing table to assign the outgoing link to be used to forward the packet towardits target node. When the link resources are available, they are reserved and the transferis set up. The time it takes to move a packet from one node to a neighboring one dependson the packet size and on the link transmission characteristics. If, on a packet's arrival,there is not enough bu er space to hold it, the packet is discarded. Otherwise, a servicetime is stochastically generated for the newly arrived packet. This time represents the delaybetween the packet arrival time and the time when it will be put in the bu er queue of theoutgoing link the local routing component has selected for it.Situations causing a temporary or steady alteration of the network topology or of itsphysical characteristics are not taken into account (link or node failure, adding or deletingof network components, etc.).1. A hierarchical structure is adopted on the Internet, organized in hierarchical Autonomous Systems andmultiple routing areas inside each Autonomous System (Moy, 1998).2. This choice is the same as in the \\Simple Tra c\" model in the MaRS network simulator (Alaettino glu,Shankar, Dussa-Zieger, & Matta, 1992). It can be seen as a very basic form of File Transfer Protocol(FTP). 322\nAntNet: Distributed Stigmergetic Control for Communications NetworksWe developed a complete network simulator in C++. It is a discrete event simulatorusing as its main data structure an event list, which holds the next future events. Thesimulation time is a continuous variable and is set by the currently scheduled event. The aimof the simulator is to closely mirror the essential features of the concurrent and distributedbehavior of a generic communication network without sacri cing e ciency and exibilityin code development.We end this section with some remarks concerning two features of the model.First, we chose not to implement a \\real\" transport layer for a proper managementof error, ow, and congestion control. In fact, each additional control component has aconsiderable impact on the network performance,3 making very di cult to evaluate and tostudy the properties of each control algorithm without taking in consideration the complexway it interacts with all the other control components. Therefore, we chose to test thebehavior of our algorithm and of its competitors in conditions such that the number ofinteracting components is minimal and the routing component can be evaluated in isolation,allowing a better understanding of its properties. To study routing in conjunction with error, ow and congestion control, all these components should be designed at the same time, toallow a good match among their characteristics to produce a synergetic e ect.Second, we chose to work with connection-less and not with connection-oriented net-works because connection-oriented schemes are mainly used in networks able to deliverQuality of Service (QoS) (Crawley, Nair, Rajagopalan, & Sandick, 1996).4 In this case,suitable admission control algorithms have to be introduced, taking into account manyeconomic and technological factors (Sandick & Crawley, 1997). But, again, as a rst stepwe think that it is more reasonable to try to check the validity of a routing algorithm byreducing the number of components heavily in uencing the network behavior.4. AntNet: An Adaptive Agent-based Routing AlgorithmThe characteristics of the routing problem (discussed in Section 2.2) make it well suitedto be solved by a mobile multi-agent approach (Stone & Veloso, 1996; Gray, Kotz, Nog,Rus, & Cybenko, 1997). This processing paradigm is a good match for the distributed andnon-stationary (in topology and tra c patterns) nature of the problem, presents a highlevel of redundancy and fault-tolerance, and can handle multiple objectives and constraintsin a exible way.AntNet, the routing algorithm we propose in this paper, is a mobile agents system show-ing some essential features of parallel replicated Monte Carlo systems (Streltsov & Vakili,1996). AntNet takes inspiration from previous work on arti cial ant colonies techniques tosolve combinatorial optimization problems (Dorigo et al., 1991; Dorigo, 1992; Dorigo et al.,1996; Dorigo & Gambardella, 1997) and telephone network routing (Schoonderwoerd et al.,3. As an example, some authors reported an improvement ranging from 2 to 30% in various performancemeasures for real Internet tra c (Danzig, Liu, & Yan, 1994) by changing from the Reno version to theVegas version of the TCP (Peterson & Davie, 1996) (the current Internet Transport Control Protocol),and other authors even claimed improvements ranging from 40 to 70% (Brakmo, O'Malley, & Peterson,1994).4. This is not the case for the current Internet, where the IP bearer service is of \\best-e ort\" type, meaningthat it does the best it can do but no guarantees of service quality in terms of delay or bandwidth orjitter, etc., can be assured. 323\nDi Caro & Dorigo1996, 1997). The core ideas of these techniques (for a review see Dorigo, Di Caro, andGambardella, 1998) are (i) the use of repeated and concurrent simulations carried out by apopulation of arti cial agents called \\ants\" to generate new solutions to the problem, (ii)the use by the agents of stochastic local search to build the solutions in an incremental way,and (iii) the use of information collected during past simulations to direct future search forbetter solutions.In the arti cial ant colony approach, following an iterative process, each ant builds asolution by using two types of information locally accessible: problem-speci c information(for example, distance among cities in a traveling salesman problem), and information addedby ants during previous iterations of the algorithm. In fact, while building a solution, eachant collects information on the problem characteristics and on its own performance, anduses this information to modify the representation of the problem, as seen locally by theother ants. The representation of the problem is modi ed in such a way that informationcontained in past good solutions can be exploited to build new better solutions. This formof indirect communication mediated by the environment is called stigmergy, and is typicalof social insects (Grass e, 1959).In AntNet, we retain the core ideas of the arti cial ant colony paradigm, and we applythem to solve in an adaptive way the routing problem in datagram networks.Informally, the AntNet algorithm and its main characteristics can be summarized asfollows. At regular intervals, and concurrently with the data tra c, from each network nodemobile agents are asynchronously launched towards randomly selected destinationnodes. Agents act concurrently and independently, and communicate in an indirect way,through the information they read and write locally to the nodes. Each agent searches for a minimum cost path joining its source and destination nodes. Each agent moves step-by-step towards its destination node. At each intermediatenode a greedy stochastic policy is applied to choose the next node to move to. Thepolicy makes use of (i) local agent-generated and maintained information, (ii) localproblem-dependent heuristic information, and (iii) agent-private information. While moving, the agents collect information about the time length, the congestionstatus and the node identi ers of the followed path. Once they have arrived at the destination, the agents go back to their source nodesby moving along the same path as before but in the opposite direction. During this backward travel, local models of the network status and the local routingtable of each visited node are modi ed by the agents as a function of the path theyfollowed and of its goodness. Once they have returned to their source node, the agents die.In the following subsections the above scheme is explained, all its components are ex-plicated and discussed, and a more detailed description of the algorithm is given.324\nAntNet: Distributed Stigmergetic Control for Communications Networks4.1 Algorithm Description and CharacteristicsAntNet is conveniently described in terms of two sets of homogeneous mobile agents (Stone& Veloso, 1996), called in the following forward and backward ants. Agents5 in each setpossess the same structure, but they are di erently situated in the environment; that is,they can sense di erent inputs and they can produce di erent, independent outputs. Theycan be broadly classi ed as deliberative agents, because they behave reactively retrieving apre-compiled set of behaviors, and at the same time they maintain a complete internal statedescription. Agents communicate in an indirect way, according to the stigmergy paradigm,through the information they concurrently read and write in two data structures stored ineach network node k (see Figure 1): Network Nodes\n........\n........ ........\nNetwork Nodes\nRouting Table\nStatistics\nLocal Traffic\nNetwork\nNode\nP P P P P P P P 1 1 1 2 1 N 2 1 2 2 2 N\nP L 2 L N\nStat (1) Stat (2) Stat(N)\nO u\ntg o\nin g\nL in ks L 1\nFigure 1: Node structures used by mobile agents in AntNet for the case of a node withL neighbors and a network with N nodes. The routing table is organized as invector-distance algorithms, but the entries are probabilistic values. The structurecontaining statistics about the local tra c plays the role of a local adaptive modelfor the tra c toward each possible destination.i) A routing table Tk, organized as in vector-distance algorithms (see Appendix A),but with probabilistic entries. Tk de nes the probabilistic routing policy currentlyadopted at node k: for each possible destination d and for each neighbor node n, Tkstores a probability value Pnd expressing the goodness (desirability), under the currentnetwork-wide routing policy, of choosing n as next node when the destination nodeis d: Xn2Nk Pnd = 1; d 2 [1; N ]; Nk = fneighbors(k)g:ii) An arrayMk( d; d2;Wd), of data structures de ning a simple parametric statisticalmodel for the tra c distribution over the network as seen by the local node k. Themodel is adaptive and described by sample means and variances computed over thetrip times experienced by the mobile agents, and by a moving observation windowWdused to store the best value Wbestd of the agents' trip time.5. In the following, we will use interchangeably the terms ant and agent.325\nDi Caro & DorigoFor each destination d in the network, an estimated mean and variance, d and d2,give a representation of the expected time to go and of its stability. We used arith-metic, exponential and windowed strategies to compute the statistics. Changing strat-egy does not a ect performance much, but we observed the best results using theexponential model:6 d d + (ok!d d); d2 d2 + ((ok!d d)2 d2); (1)where ok!d is the new observed agent's trip time from node k to destination d.7The moving observation window Wd is used to compute the value Wbestd of the bestagents' trip time towards destination d as observed in the last w samples. After eachnew sample, w is incremented modulus jWjmax, and jWjmax is the maximum allowedsize of the observation window. The value Wbestd represents a short-term memoryexpressing a moving empirical lower bound of the estimate of the time to go to noded from the current node.T and M can be seen as memories local to nodes capturing di erent aspects of thenetwork dynamics. The model M maintains absolute distance/time estimates to all thenodes, while the routing table gives relative probabilistic goodness measures for each link-destination pair under the current routing policy implemented over all the network.The AntNet algorithm is described as follows.1. At regular intervals t from every network node s, a mobile agent (forward ant) Fs!dis launched toward a destination node d to discover a feasible, low-cost path to thatnode and to investigate the load status of the network. Forward ants share the samequeues as data packets, so that they experience the same tra c loads. Destinations arelocally selected according to the data tra c patterns generated by the local workload:if fsd is a measure (in bits or in number of packets) of the data ow s! d, then theprobability of creating at node s a forward ant with node d as destination ispd = fsdNXd0=1 fsd0 : (2)In this way, ants adapt their exploration activity to the varying data tra c distribu-tion.2. While traveling toward their destination nodes, the agents keep memory of their pathsand of the tra c conditions found. The identi er of every visited node k and the timeelapsed since the launching time to arrive at this k-th node are pushed onto a memorystack Ss!d(k).6. This is the same model as used by the Jacobson/Karels algorithm to estimate retransmission timeoutsin the Internet TCP(Peterson & Davie, 1996).7. The factor weights the number of most recent samples that will really a ect the average. The weightof the ti-th sample used to estimate the value of d after j samplings, with j > i, is: (1 )j i. Inthis way, for example, if = 0:1, approximately only the latest 50 observations will really in uence theestimate, for = 0:05, the latest 100, and so on. Therefore, the number of e ective observations is 5(1= ). 326\nAntNet: Distributed Stigmergetic Control for Communications Networks3. At each node k, each traveling agent headed towards its destination d selects the noden to move to choosing among the neighbors it did not already visit, or over all theneighbors in case all of them had been previously visited. The neighbor n is selectedwith a probability (goodness) P 0nd computed as the normalized sum of the probabilisticentry Pnd of the routing table with a heuristic correction factor ln taking into accountthe state (the length) of the n-th link queue of the current node k:P 0nd = Pnd + ln1 + (jNkj 1) : (3)The heuristic correction ln is a [0,1] normalized value proportional to the length qn(in bits waiting to be sent) of the queue of the link connecting the node k with itsneighbor n: ln = 1 qnjNkjXn0=1 qn0 : (4)The value of weights the importance of the heuristic correction with respect to theprobability values stored in the routing table. ln re ects the instantaneous state of thenode's queues, and assuming that the queue's consuming process is almost stationaryor slowly varying, ln gives a quantitative measure associated with the queue waitingtime. The routing tables values, on the other hand, are the outcome of a continuallearning process and capture both the current and the past status of the whole networkas seen by the local node. Correcting these values with the values of l allows thesystem to be more \\reactive\", at the same time avoiding following all the network uctuations. Agent's decisions are taken on the basis of a combination of a long-termlearning process and an instantaneous heuristic prediction.In all the experiments we ran, we observed that the introduced correction is a verye ective mechanism. Depending on the characteristics of the problem, the best valueto assign to the weight can vary, but if ranges between 0.2 and 0.5, performancedoesn't change appreciably. For lower values, the e ect of l is vanishing, while forhigher values the resulting routing tables oscillate and, in both cases, performancedegrades.4. If a cycle is detected, that is, if an ant is forced to return to an already visited node,the cycle's nodes are popped from the ant's stack and all the memory about them isdestroyed. If the cycle lasted longer than the lifetime of the ant before entering thecycle, (that is, if the cycle is greater than half the ant's age) the ant is destroyed. Infact, in this case the agent wasted a lot of time probably because of a wrong sequenceof decisions and not because of congestion states. Therefore, the agent is carrying anold and misleading memory of the network state and it is counterproductive to use itto update the routing tables (see below).5. When the destination node d is reached, the agent Fs!d generates another agent(backward ant) Bd!s, transfers to it all of its memory, and dies.327\nDi Caro & Dorigo6. The backward ant takes the same path as that of its corresponding forward ant, butin the opposite direction.8 At each node k along the path it pops its stack Ss!d(k) toknow the next hop node. Backward ants do not share the same link queues as datapackets; they use higher priority queues, because their task is to quickly propagate tothe routing tables the information accumulated by the forward ants.7. Arriving at a node k coming from a neighbor node f , the backward ant updates thetwo main data structures of the node, the local model of the tra cMk and the rout-ing table Tk, for all the entries corresponding to the (forward ant) destination noded. With some precautions, updates are performed also on the entries correspondingto every node k0 2 Sk!d; k0 6= d on the \\sub-paths\" followed by ant Fs!d after visit-ing the current node k. In fact, if the elapsed trip time of a sub-path is statistically\\good\" (i.e., it is less than + I( ; ), where I is an estimate of a con dence intervalfor ), then the time value is used to update the corresponding statistics and therouting table. On the contrary, trip times of sub-paths not deemed good, in the samestatistical sense as de ned above, are not used because they don't give a correct ideaof the time to go toward the sub-destination node. In fact, all the forward ant routingdecisions were made only as a function of the destination node. In this perspective,sub-paths are side e ects, and they are intrinsically sub-optimal because of the localvariations in the tra c load (we can't reason with the same perspective as in dynamicprogramming, because of the non-stationarity of the problem representation). Obvi-ously, in case of a good sub-path we can use it: the ant discovered, at zero cost, anadditional good route. In the following two items the way M and T are updated isdescribed with respect to a generic \\destination\" node d0 2 Sk!d.i) Mk is updated with the values stored in the stack memory Ss!d(k). The timeelapsed to arrive (for the forward ant) to the destination node d0 starting fromthe current node is used to update the mean and variance estimates, d0 and d02,and the best value over the observation window Wd0 . In this way, a parametricmodel of the traveling time to destination d0 is maintained. The mean value ofthis time and its dispersion can vary strongly, depending on the tra c conditions:a poor time (path) under low tra c load can be a very good one under heavytra c load. The statistical model has to be able to capture this variabilityand to follow in a robust way the uctuations of the tra c. This model plays acritical role in the routing table updating process (see item (ii) below). Therefore,we investigated several ways to build e ective and computationally inexpensivemodels, as described in the following Section 4.2.ii) The routing table Tk is changed by incrementing the probability Pfd0 (i.e., theprobability of choosing neighbor f when destination is d0) and decrementing, bynormalization, the other probabilities Pnd0 . The amount of the variation in theprobabilities depends on a measure of goodness we associate with the trip timeTk!d0 experienced by the forward ant, and is given below. This time representsthe only available explicit feedback signal to score paths. It gives a clear indica-tion about the goodness r of the followed route because it is proportional to its8. This assumption requires that all the links in the network are bi-directional. In modern networks this isa reasonable assumption. 328\nAntNet: Distributed Stigmergetic Control for Communications Networkslength from a physical point of view (number of hops, transmission capacity of theused links, processing speed of the crossed nodes) and from a tra c congestionpoint of view (the forward ants share the same queues as data packets).The time measure T , composed by all the sub-paths elapsed times, cannot beassociated with an exact error measure, given that we don't know the \\optimal\"trip times, which depend on the whole network load status.9 Therefore, T canonly be used as a reinforcement signal. This gives rise to a credit assignmentproblem typical of the reinforcement learning eld (Bertsekas & Tsitsiklis, 1996;Kaelbling et al., 1996). We de ne the reinforcement r r(T;Mk) to be afunction of the goodness of the observed trip time as estimated on the basis ofthe local tra c model. r is a dimensionless value, r 2 (0; 1], used by the currentnode k as a positive reinforcement for the node f the backward ant Bd!s comesfrom. r takes into account some average of the so far observed values and oftheir dispersion to score the goodness of the trip time T , such that the smaller Tis, the higher r is (the exact de nition of r is discussed in the next subsection).The probability Pfd0 is increased by the reinforcement value as follows:Pfd0 Pfd0 + r(1 Pfd0): (5)In this way, the probability Pfd0 will be increased by a value proportional to thereinforcement received and to the previous value of the node probability (that is,given a same reinforcement, small probability values are increased proportionallymore than big probability values, favoring in this way a quick exploitation of new,and good, discovered paths).Probabilities Pnd0 for destination d0 of the other neighboring nodes n implicitlyreceive a negative reinforcement by normalization. That is, their values arereduced so that the sum of probabilities will still be 1:Pnd0 Pnd0 rPnd0 ; n 2 Nk; n 6= f: (6)It is important to remark that every discovered path receives a positive reinforce-ment in its selection probability, and the reinforcement is (in general) a non-linearfunction of the goodness of the path, as estimated using the associated trip time.In this way, not only the (explicit) assigned value r plays a role, but also the(implicit) ant's arrival rate. This strategy is based on trusting paths that receiveeither high reinforcements, independent of their frequency, or low and frequentreinforcements. In fact, for any tra c load condition, a path receives one or morehigh reinforcements only if it is much better than previously explored paths. Onthe other hand, during a transient phase after a sudden increase in network loadall paths will likely have high traversing times with respect to those learned bythe modelM in the preceding, low congestion, situation. Therefore, in this casegood paths can only be di erentiated by the frequency of ants' arrivals.9. When the network is in a congested state, all the trip times will score poorly with respect to the timesobserved in low load situations. Nevertheless, a path with a high trip time should be scored as a goodpath if its trip time is signi cantly lower than the other trip times observed in the same congestedsituation. 329\nDi Caro & DorigoAssigning always a positive, but low, reinforcement value in the case of pathswith high traversal time allows the implementation of the above mechanism basedon the frequency of the reinforcements, while, at the same time, avoids givingexcessive credit to paths with high traversal time due to their poor quality.The use of probabilistic entries is very speci c to AntNet and we observed itto be e ective, improving the performance, in some cases, even by 30%-40%.Routing tables are used in a probabilistic way not only by the ants but alsoby the data packets. This has been observed to improve AntNet performance,which means that the way the routing tables are built in AntNet is well matchedwith a probabilistic distribution of the data packets over all the good paths.Data packets are prevented from choosing links with very low probability by re-mapping the T 's entries by means of a power function f(p) = p ; > 1, whichemphasizes high probability values and reduces lower ones (in our experimentswe set to 1.2).Figure 2 gives a high-level description of the algorithm in pseudo-code, while Figure3 illustrates a simple example of the algorithm behavior. A detailed discussion of thecharacteristics of the algorithm is postponed to Section 8, after the performance of thealgorithm has been analyzed with respect to a set of competitor algorithms. In this way,the characteristics of AntNet can be meaningfully evaluated and compared to those of otherstate-of-the-art algorithms.4.2 How to Score the Goodness of the Ant's Trip TimeThe reinforcement r is a critical quantity that has to be assigned by considering three mainaspects: (i) paths should receive an increment in their selection probability proportionalto their goodness, (ii) the goodness is a relative measure, which depends on the tra cconditions, that can be estimated by means of the modelM, and (iii) it is important not tofollow all the tra c uctuations. This last aspect is particularly important. Uncontrolledoscillations in the routing tables are one of the main problems in shortest paths routing(Wang & Crowcroft, 1992). It is very important to be able to set the best trade-o betweenstability and adaptivity.We investigated several ways to assign the r values trying to take into account the abovethree requirements: The simplest way is to set r = constant: independently of the ant's \\experimentoutcomes\", the discovered paths are all rewarded in the same way. In this simple butmeaningful case, what is at work is the implicit reinforcement mechanism due to thedi erentiation in the ant arrival rates. Ants traveling along faster paths will arriveat a higher rate than other ants, hence their paths will receive a higher cumulativereward.10 The obvious problem of this approach lies in the fact that, although antsfollowing longer paths arrive delayed, they will nevertheless have the same e ect onthe routing tables as the ants who followed shorter paths.10. In this case, the core of the algorithm is based on the capability of \\real\" ants to discover shortest pathscommunicating by means of pheromone trails (Goss et al., 1989; Beckers et al., 1992).330\nAntNet: Distributed Stigmergetic Control for Communications Networkst := Current time;tend := Time length of the simulation; t := Time interval between ants generation;foreach (Node) = Concurrent activity over the network =M = Local tra c model;T = Node routing table;while ( t tend )in parallel = Concurrent activity on each node =if ( t mod t = 0)destination node := SelectDestinationNode(data tra c distribution);LaunchForwardAnt(destination node, source node);end ifforeach (ActiveForwardAnt[source node, current node, destination node])while (current node 6= destination node)next hop node := SelectLink(current node, destination node,T ; link queues);PutAntOnLinkQueue(current node, next hop node);WaitOnDataLinkQueue(current node, next hop node);CrossTheLink(current node, next hop node);PushOnTheStack(next hop node, elapsed time);current node := next hop node;end whileLaunchBackwardAnt(destination node, source node, stack data);Die();end foreachforeach (ActiveBackwardAnt[source node, current node, destination node])while (current node 6= destination node)next hop node := PopTheStack();WaitOnHighPriorityLinkQueue(current node, next hop node);CrossTheLink(current node, next hop node);UpdateLocalTra cModel(M, current node, source node, stack data);reinforcement := GetReinforcement(current node, source node, stack data, M);UpdateLocalRoutingTable(T , current node, source node, reinforcement);end whileend foreachend in parallelend whileend foreachFigure 2: AntNet's top-level description in pseudo-code. All the described actions take placein a completely distributed and concurrent way over the network nodes (while, inthe text, AntNet has been described from an individual ant's perspective). All theconstructs at the same level of indentation inside the context of the statementin parallel are executed concurrently. The processes of data generation andforwarding are not described, but they can be thought as acting concurrentlywith the ants. 331\nDi Caro & Dorigo ( 1 4) 2 41 3 Forward Ant (1 4 )\nBackward AntFigure 3: Example of AntNet behavior. The forward ant, F1!4, moves along the path1 ! 2 ! 3 ! 4 and, arrived at node 4, launches the backward ant B4!1 thatwill travel in the opposite direction. At each node k; k = 3; : : : ; 1, the backwardant will use the stack contents S1!4(k) to update the values forMk( 4; 42;W4),and, in case of good sub-paths, to update also the values forMk( i; i2;Wi); i =k+1; : : : ; 3. At the same time the routing table will be updated by incrementingthe goodness Pj4, j = k + 1, of the last node k + 1 the ant B4!1 came from,for the case of node i = k + 1; : : : ; 4 as destination node, and decrementing thevalues of P for the other neighbors (here not shown). The increment will be afunction of the trip time experienced by the forward ant going from node k todestination node i. As forM, the routing table is always updated for the case ofnode 4 as destination, while the other nodes i0 = k + 1; : : : ; 3 on the sub-pathsare taken in consideration as destination nodes only if the trip time associated tothe corresponding sub-path of the forward ant is statistically good.In the experiments we ran with this strategy, the algorithm showed moderately goodperformance. These results suggest that the \\implicit\" component of the algorithm,based on the ant arrival rate, plays a very important role. Of course, to compete withstate-of-the-art algorithms, the available information about path costs has to be used. More elaborate approaches de ne r as a function of the ant's trip time T , and of theparameters of the local statistical modelM. We tested several alternatives, by usingdi erent linear, quadratic and hyperbolic combinations of the T and M values. Inthe following we limit the discussion to the functional form that gave the best results,and that we used in the reported experiments:r = c1 WbestT + c2 Isup Iinf(Isup Iinf ) + (T Iinf ) : (7)In Equation 7, Wbest is the best trip time experienced by the ants traveling towardthe destination d, over the last observation window W. The maximum size of the window(the maximum number of considered samples before resetting the Wbest value) is assignedon the basis of the coe cient of Equation 1. As we said, weights the number ofsamples e ectively giving a contribution to the value of the estimate, de ning a sort ofmoving exponential window. Following the expression for the number of e ective samplesas reported in footnote 7, we set jWjmax = 5(c= ), with c < 1. In this way, the long-term exponential mean and the short-term windowing are referring to a comparable set ofobservations, with the short-term mean evaluated over a fraction c of the samples used for332\nAntNet: Distributed Stigmergetic Control for Communications Networksthe long-term one. Isup and Iinf are convenient estimates of the limits of an approximatecon dence interval for . Iinf is set to Wbest, while Isup = + z( =pjWj), with z =1=p(1 ) where gives the selected con dence level.11 There is some level of arbitrarinessin our computation of the con dence interval, because we set it in an asymmetric way and and are not arithmetic estimates. Anyway, what we need is a quick, raw estimate of themean value and of the dispersion of the values (for example, a local bootstrap procedurecould have been applied to extract a meaningful con dence interval, but such a choice isnot reasonable from a CPU time-consuming perspective).The rst term in Equation 7 simply evaluates the ratio between the current trip time andthe best trip time observed over the current observation window. This term is correctedby the second one, that evaluates how far the value T is from Iinf in relation to theextension of the con dence interval, that is, considering the stability in the latest triptimes. The coe cients c1 and c2 weight the importance of each term. The rst term is themost important one, while the second term plays the role of a correction. In the currentimplementation of the algorithm we set c1 = 0:7 and c2 = 0:3. We observed that c2 shouldn'tbe too big (0.35 is an upper limit), otherwise performance starts to degrade appreciably.The behavior of the algorithm is quite stable for c2 values in the range 0.15 to 0.35 butsetting c2 below 0.15 slightly degrades performance. The algorithm is very robust to changesin , which de nes the con dence level: varying the con dence level in the range from 75%to 95% changes performance little. The best results have been obtained for values around75% 80%. We observed that the algorithm is very robust to its internal parameter settingsand we didn't try to \\adapt\" the set of parameters to the problem instance. All the di erentexperiments were carried out with the same \\reasonable\" settings. We could surely improvethe performance by means of a ner tuning of the parameters, but we didn't because wewere interested in implementing a robust system, considering that the world of networks isincredibly varied in terms of tra c, topologies, switch and transmission characteristics, etc.The value r obtained from Equation 7 is nally transformed by means of a squashfunction s(x): s(x) = 1 + exp axjNkj ! 1; x 2 (0; 1]; a 2 R+; (8)r s(r)s(1) : (9)Squashing the r values allows the system to be more sensitive in rewarding good (high)values of r, while having the tendency to saturate the rewards for bad (near to zero) rvalues: the scale is compressed for lower values and expanded in the upper part. In such away an emphasis is put on good results, while bad results play a minor role.11. The expression is obtained by using the Tchebyche inequality that allows the de nition of a con denceinterval for a random variable following any distribution (Papoulis, 1991) Usually, for speci c probabilitydensities the Tchebyche bound is too high, but here we can conveniently use it because (i) we wantto avoid to make assumptions on the distribution of and, (ii) we need only a raw estimate of thecon dence interval. 333\nDi Caro & Dorigo\nThe coe cient a=jNkj determines aparametric dependence of the squashedreinforcement value on the numberjNkj of neighbors of the reinforced nodek: the greater the number of neighbors,the higher the reinforcement (see Fig-ure 4). The reason to do this is that wewant to have a similar, strong, e ect ofgood results on the probabilistic rout-ing tables, independent of the numberof neighbor nodes.\n5. Routing Algorithms Used for ComparisonTo evaluate the performance of AntNet, we compared it with state-of-the-art routing algo-rithms from the telecommunications and machine learning elds. The following algorithms,belonging to the various possible combinations of static and adaptive, distance-vector andlink-state classes (see Appendix A), have been implemented and used to run comparisons.OSPF (static, link state): is our implementation of the current Interior Gateway Pro-tocol (IGP) of Internet (Moy, 1998). Being interested in studying routing under theassumptions described in Section 3, the routing protocol we implemented does notmirror the real OSPF protocol in all its details. It only retains the basic features ofOSPF. Link costs are statically assigned on the basis of their physical characteristicsand routing tables are set as the result of the shortest (minimum time) path com-putation for a sample data packet of size 512 bytes. It is worth remarking that thischoice penalizes our version of OSPF with respect to the real one. In fact, in the realInternet link costs are set by network administrators who can use additional heuristicand on- eld knowledge they have about tra c workloads.SPF (adaptive, link-state): is the prototype of link-state algorithms with dynamic met-ric for link costs evaluations. A similar algorithm was implemented in the secondversion of ARPANET (McQuillan, Richer, & Rosen, 1980) and in its successive revi-sions (Khanna & Zinky, 1989). Our implementation uses the same ooding algorithm,while link costs are assigned over a discrete scale of 20 values by using the ARPANEThop-normalized-delay metric12 (Khanna & Zinky, 1989) and the the statistical win-dow average method described in (Shankar, Alaettino glu, Dussa-Zieger, & Matta,1992a). Link costs are computed as weighted averages between short and long-termreal-valued statistics re ecting the delay (e.g., utilization, queueing and/or transmis-12. The transmitting node monitors the average packet delay d (queuing and transmission) and the averagepacket transmission time t over x observation windows. From these measures, assuming an M/M/1queueing model (Bertsekas & Gallager, 1992), a link utilization cost measure is calculated as 1 t=d.334\nAntNet: Distributed Stigmergetic Control for Communications Networkssion delay, etc.) over xed time intervals. Obtained values are rescaled and saturatedby a linear function. We tried several additional discrete and real-valued metrics butthe discretized hop-normalized-delay gave the best results in terms of performanceand stability. Using a discretized scale reduces the sensitivity of the algorithm but atthe same time reduces also undesirable oscillations.BF (adaptive, distance-vector): is an implementation of the asynchronous distributedBellman-Ford algorithm with dynamic metrics (Bertsekas & Gallager, 1992; Shankaret al., 1992a). The algorithm has been implemented following the guidelines of Ap-pendix A, while link costs are assigned in the same way as described for SPF above.Vector-distance Bellman-Ford-like algorithms are today in use mainly for intra-domainrouting, because they are used in the Routing Information Protocol (RIP) (Malkin& Steenstrup, 1995) supplied with the BSD version of Unix. Several enhanced ver-sions of the basic adaptive Bellman-Ford algorithm can be found in the literature (forexample the Merlin-Segall (Merlin & Segall, 1979) and the Extended Bellman-Ford(Cheng, Riley, Kumar, & Garcia-Luna-Aceves, 1989) algorithms). They focus mainlyon reducing the information dissemination time in case of link failures. When linkfailures are not a major issue, as in this paper, their behavior is in general equivalentto that of the basic adaptive Bellman-Ford.Q-R (adaptive, distance-vector): is the Q-Routing algorithm as proposed by Boyanand Littman (1994). This is an online asynchronous version of the Bellman-Fordalgorithm. Q-R learns online the values Qk(d; n), which are estimates of the timeto reach node d from node k via the neighbor node n. Upon sending a packet Pfrom k to neighbor node n with destination d, a back packet Pback is immediatelygenerated from n to k. Pback carries the information about the current time estimatetn!d = minn02Nn Qn(d; n0) held at node n about the time to go for destination d, andthe sum tPk!n of the queuing and transmission time experienced by P since its arrivalat node k. The sum Qnew(d; n) = tn!d + tPk!n is used to compute the variation Qk(d; n) = (Qnew(d; n) Qk(d; n)) of the Q-learning-like value Qk(d; n).PQ-R (adaptive, distance-vector): is the Predictive Q-Routing algorithm (Choi & Ye-ung, 1996), an extension of Q-Routing. In Q-routing the best link (i.e., the one withthe lowest Qk(d; n)) is deterministically chosen by packets. Therefore, a link thathappens to have a high expected Qk(d; n), for example because of a temporary loadcondition, will never be used again until all the other links exiting from the same nodehave a worse, that is higher, Qk(d; n). PQ-R learns a model of the rate of variation oflinks' queues, called the recovery rate, and uses it to probe those links that, althoughnot having the lowest Qk(d; n), have a high recovery rate.Daemon (adaptive, optimal routing): is an approximation of an ideal algorithm. Itde nes an empirical bound on the achievable performance. It gives some informa-tion about how much improvement is still possible. In the absence of any a prioriassumption on tra c statistics, the empirical bound can be de ned by an algorithmpossessing a \\daemon\" able to read in every instant the state of all the queues in thenetwork and then calculating instantaneous \\real\" costs for all the links and assigning335\nDi Caro & Dorigopaths on the basis of a network-wide shortest paths re-calculation for every packethop. Links costs used in shortest paths calculations are the following:Cl = dl + Spbl + (1 )SQ(l)bl + SQ(l)bl ;where dl is the transmission delay for link l, bl is its bandwidth, Sp is the size (inbits) of the data packet doing the hop, SQ(l) is the size (in bits) of the queue of linkl, SQ(l) is the exponential mean of the size of links queue and it is a correction to theactual size of the link queue on the basis of what observed until that moment. Thiscorrection is weighted by the value set to 0.4. Of course, given the arbitrarinesswe introduced in calculating Cl, it could be possible to de ne an even better Daemonalgorithm.6. Experimental SettingsThe functioning of a communication network is governed by many components, which mayinteract in nonlinear and unpredictable ways. Therefore, the choice of a meaningful testbedto compare competing algorithms is no easy task.A limited set of classes of tunable components is de ned and for each class our choicesare explained.6.1 Topology and physical properties of the netTopology can be de ned on the basis of a real net instance or it can de ned by hand, tobetter analyze the in uence of important topological features (like diameter, connectivity,etc.).Nodes are mainly characterized by their bu ering and processing capacity, whereas linksare characterized by their propagation delay, bandwidth and streams multiplexing scheme.For both, fault probability distributions should be de ned.In our experiments, we used three signi cant net instances with increasing numbersof nodes. For all of them we describe the main characteristics and we summarize thetopological properties by means of a triple of numbers ( , , N) indicating respectively themean shortest path distance, in terms of hops, between all pairs of nodes, the variance ofthis average, and the total number of nodes. From these three numbers we can get an ideaabout the degree of connectivity and balancing of the network. The di culty of the routingproblem roughly increases with the value of these numbers. SimpleNet (1.9, 0.7, 8) is a small network speci cally designed to study some aspectsof the behavior of the algorithms we compare. Experiments with SimpleNet weredesigned to closely study how the di erent algorithms manage to distribute the loadon the di erent possible paths. SimpleNet is composed of 8 nodes and 9 bi-directionallinks with a bandwidth of 10 Mbit/s and propagation delay of 1 msec. The topologyis shown in Figure 5. NSFNET (2.2, 0.8, 14) is the old USA T1 backbone (1987). NSFNET is a WANcomposed of 14 nodes and 21 bi-directional links with a bandwidth of 1.5 Mbit/s. Its336\nAntNet: Distributed Stigmergetic Control for Communications Networks 8 2 4\n6\n5\n7\n3\n1\nFigure 5: SimpleNet. Numbers within circles are node identi ers. Shaded nodes have aspecial interpretation in our experiments, described later. Each edge in the graphrepresents a pair of directed links. Link bandwidth is 10 Mbit/sec, propagationdelay is 1 msec.topology is shown in Figure 6. Propagation delays range from 4 to 20 msec. NSFNETis a well balanced network. Figure 6: NSFNET. Each edge in the graph represents a pair of directed links. Link band-width is 1.5 Mbit/sec, propagation delays range from 4 to 20 msec. NTTnet (6.5, 3.8, 57) is the major Japanese backbone. NTTnet is the NTT (NipponTelephone and Telegraph company) ber-optic corporate backbone. NTTnet is a57 nodes, 162 bi-directional links network. Link bandwidth is of 6 Mbit/sec, whilepropagation delays range around 1 to 5 msec. The topology is shown in Figure 7.NTTnet is not a well balanced network. Figure 7: NTTnet. Each edge in the graph represents a pair of directed links. Link band-width is 6 Mbit/sec, propagation delays range from 1 to 5 msec.337\nDi Caro & DorigoAll the networks are simulated with zero link-fault and node-fault probabilities, localnode bu ers of 1 Gbit capacity, and data packets maximum time to live (TTL) set to 15sec.6.2 Tra c patternsTra c is de ned in terms of open sessions between pairs of di erent nodes. Tra c patternscan show a huge variety of forms, depending on the characteristics of each session and ontheir distribution from geographical and temporal points of view.Each single session is characterized by the number of transmitted packets, and by theirsize and inter-arrival time distributions. More generally, priority, costs and requested qualityof service should be used to completely characterize a session.Sessions over the network can be characterized by their inter-arrival time distributionand by their geographical distribution. The latter is controlled by the probability assignedto each node to be selected as a session start or end-point.We considered three basic patterns for the temporal distribution of the sessions, andthree for their spatial distribution.Temporal distributions: Poisson (P): for each node a Poisson process is de ned which regulates the arrival ofnew sessions, i.e., sessions inter-arrival times are negative exponentially distributed. Fixed (F): at the beginning of the simulation, for each node, a xed number of one-to-all sessions is set up and left constant for the remainder of the simulation. Temporary (TMPHS): a temporary, heavy load, tra c condition is generated turningon some nodes that act like hot spots (see below).Spatial distributions: Uniform (U): the assigned temporal characteristics for session arrivals are set identi-cally for all the network nodes. Random (R): in this case, the assigned temporal characteristics for session arrivals areset in a random way over the network nodes. Hot Spots (HS): some nodes behave as hot spots, concentrating a high rate of in-put/output tra c. A xed number of sessions are opened from the hot spots to allthe other nodes.General tra c patterns have been obtained combining the above temporal and spatialcharacteristics. Therefore, for example, UP tra c means that, for each node, an identicalPoisson process is regulating the arrival of new sessions, while in the RP case the process isdi erent for each node, and UP-HS means that a Hot Spots tra c model is superimposedto a UP tra c.Concerning the shape of the bit stream generated by each session, we consider two basictypes: Constant Bit Rate (CBR): the per-session bit rate is maintained xed. Examples ofapplications of CBR streams are the voice signal in a telephone network, which isconverted into a stream of bits with a constant rate of 64 Kbit/sec, and the MPEG1compression standard, which converts a video signal in a stream of 1.5 Mbit/sec.338\nAntNet: Distributed Stigmergetic Control for Communications Networks Generic Variable Bit Rate (GVBR): the per-session generated bit rate is time varying.The term GVBR is a broad generalization of the VBR term normally used to designatea bit stream with a variable bit rate but with known average characteristics andexpected/admitted uctuations.13 Here, a GVBR session generates packets whosesizes and inter-arrival times are variable and follow a negative exponential distribution.The information about these characteristics is never directly used by the routingalgorithms, like in IP-based networks.The values we used in the experiments to shape tra c patterns are \\reasonable\" valuesfor session generations and data packet production taking into consideration current networkusage and computing power. The mean of the packet size distribution has been set to 4096bits in all the experiments. Basic temporal and spatial distributions have been chosen tobe representative of a wide class of possible situations that can be arbitrarily composed togenerate a meaningful subset of real tra c patterns.6.3 Metrics for performance evaluationDepending on the type of services delivered on the network and on their associated costs,many performance metrics could be de ned. We focused on standard metrics for per-formance evaluation, considering only sessions with equal costs, bene ts and priority andwithout the possibility of requests for special services like real-time. In this framework, themeasures we are interested in are: throughput (correctly delivered bits/sec), delay distri-bution for data packets (sec), and network capacity usage (for data and routing packets),expressed as the sum of the used link capacities divided by the total available link capacity.6.4 Routing algorithms parametersAll the algorithms used have a collection of parameters to be set. Common parametersare routing packet size and elaboration time. Settings for these parameters are shownin table 1. These parameters have been assigned to values used in previous simulationAntNet OSPF & SPF BF Q-R & PQ-RPacket size (byte) 24 + 8Nh 64 + 8jNnj 24 + 12N 12Packet elaboration time (msec) 3 6 2 3Table 1: Routing packets characteristics for the implemented algorithms (except for theDaemon algorithm, which does not generate routing packets). Nh is the incremen-tal number of hops made by the forward ant, jNnj is the number of neighbors ofnode n, and N is the number of network nodes.works (Alaettino glu et al., 1992) and/or on the basis of heuristic evaluations taking into13. The knowledge about the characteristics of the incoming CBR or VBR bit streams is of fundamentalimportance in networks able to deliver Quality of Service. It is only on the basis of this knowledge thatthe network can accept/refuse the session requests, and, in case of acceptance, allocate/reserve necessaryresources. 339\nDi Caro & Dorigoconsideration information encoding schemes and currently available computing power (e.g.,the size for forward ants has been determined as the same size of a BF packet plus 8 bytes foreach hop to store the information about the node address and the elapsed time). Concerningthe other main parameters, speci c for each algorithm, for the AntNet competitors we usedthe best settings we could nd in the literature and/or we tried to tune the parametersas much as possible to obtain better results. For OSPF, SPF, and BF, the length of thetime interval between consecutive routing information broadcasts and the length of the timewindow to average link costs are the same, and they are set to 0.8 or 3 seconds, depending onthe experiment for SPF and BF, and to 30 seconds for OSPF. Link costs inside each windoware assigned as the weighted sum between the arithmetic average over the window and theexponential average with decay factor equal to 0.9. The obtained values are discretizedover a linear scale saturated between 1 and 20, with slope set to 20 and maximum admittedvariation equal to 1. For Q-R and PQ-R the transmission of routing information is totallydata-driven. The learning and adaptation rate we used were the same as used by thealgorithm's authors (Boyan & Littman, 1994; Choi & Yeung, 1996).Concerning AntNet, we observed that the algorithm is very robust to internal parameterstuning. We did not nely tune the parameter set, and we used the same set of values for allthe di erent experiments we ran. Most of the settings we used have been previously givenin the text at the moment the parameter was discussed and they are not reported in thissection. The ant generation interval at each node was set to 0.3 seconds. In Section 7.4it will be shown the robustness of AntNet with respect to this parameter. Regarding theparameters of the statistical model, the value of , weighting the number of the samplesconsidered in the model (Equation 1), has been set to 0.005, the c factor for the expressionof jWjmax (sect. 4.2) has been put equal to 0.3, and the con dence level factor z (sect. 4.2)equal to 1.70, meaning a con dence level of approximately 0.95.7. ResultsExperiments reported in this section compare AntNet with the competing routing algo-rithms described in Section 5. We studied the performance of the algorithms for increasingtra c load, examining the evolution of the network status toward a saturation condition,and for temporary saturation conditions. Under low load conditions, all algorithms tested have similar performance. In thiscase, also considering the huge variability in the possible tra c patterns, it is veryhard to assess whether an algorithm is signi cantly better than another or not. Under high, near saturation, loads, all the tested algorithms are able to deliver theo ered throughput in a quite similar way, that is, in most of the cases all the gener-ated tra c is routed without big losses. On the contrary, the study of packet delaydistributions shows remarkable di erences among the di erent algorithms. To presentsimulation results regarding packet delays we decided either to report the whole em-pirical distribution or to use the 90-th percentile statistic, which allows one to comparethe algorithms on the basis of the upper value of delay they were able to keep the 90%of the correctly delivered packets. In fact, packet delays can be spread over a widerange of values. This is an intrinsic characteristics of data networks: packet delayscan range from very low values for sessions open between adjacent nodes connected by340\nAntNet: Distributed Stigmergetic Control for Communications Networksfast links, to much higher values in the case of sessions involving nodes very far apartconnected by many slow links. Because of this, very often the empirical distributionof packet delays cannot be meaningfully parametrized in terms of mean and variance,and the 90-th percentile statistic, or still better the whole empirical distribution, aremuch more meaningful. Under saturation there are packet losses and/or packet delays that become too big,cause all the network operations to slow down. Therefore, saturation has to be onlya temporary situation. If it is not, structural changes to the network characteristics,like adding new and faster connection lines, rather than improvements of the routingalgorithm, should be in order. For these reasons, we studied the responsiveness of thealgorithms to tra c loads causing only a temporary saturation.All reported data are averaged over 10 trials lasting 1000 virtual seconds of simulationtime. One thousand seconds represents a time interval long enough to expire all transientsand to get enough statistical data to evaluate the behavior of the routing algorithm. Beforebeing fed with data tra c, the algorithms are given 500 preliminary simulation seconds withno data tra c to build initial routing tables. In this way, each algorithm builds the routingtables according to its own \\vision\" about minimum cost paths. Results for throughputare reported as average values without an associated measure of variance. The inter-trialvariability is in fact always very low, a few percent of the average value.Parameter values for tra c characteristics are given in the Figure captions with thefollowing meaning (see also previous section): MSIA is the mean of the sessions inter-arrivaltime distribution for the Poisson (P) case, MPIA stands for the mean of the packet inter-arrival time distribution. In the CBR case, MPIA indicates the xed packet productionrate. HS is the number of hot-spots nodes and MPIA-HS is the equivalent of MPIA for thehot-spot sessions. In the following, when not otherwise explicitly stated, the shape of thesession bit streams is assumed to be of GVBR type.Results for throughput and packet delays for all the considered network topologies aredescribed in the three following subsections. Results concerning the network resourcesutilization are reported in Section 7.4.7.1 SimpleNetExperiments with SimpleNet were designed to study how the di erent algorithms manageto distribute the load on the di erent possible paths. In these experiments, all the tra c,of F-CBR type, is directed from node 1 to node 6 (see Figure 5), and the tra c load hasbeen set to a value higher than the capacity of a single link, so that it cannot be routede ciently on a single path.Results regarding throughput (Figure 8a) in this case strongly discriminate among thealgorithms. The type of the tra c workload and the small number of nodes determinedsigni cant di erences in throughput. AntNet is the only algorithm able to deliver almostall the generated data tra c: its throughput after a short transient phase approaches veryclosely the level of that delivered by the Daemon algorithm. PQ-R attains a steady valueapproximately 15% inferior to that obtained by AntNet. The other algorithms behave verypoorly, stabilizing on values of about 30% inferior to those provided by AntNet. In this341\nDi Caro & Dorigocase, it is rather clear that AntNet is the only algorithm able to exploit at best all the threeavailable paths (1-8-7-6, 1-3-5-6, 1-2-4-5-6) to distribute the data tra c without inducingcounterproductive oscillations. The utilization of the routing tables in a probabilistic wayalso by data packets in this case plays a fundamental role in achieving higher quality re-sults. Results for throughput are con rmed by those for packet delays, reported in thegraph of Figure 8b. The di erences in the empirical distributions for packet delays re ectapproximatively the same proportions as evidenced in the throughput case.\n9.5\n10.0\n10.5\n11.0\n11.5\n12.0\n12.5\n13.0\n13.5\n14.0\n0 100 200 300 400 500 600 700 800 900 1000\nT hr\nou gh\npu t (\n10 6\nbi t/s\nec )\nSimulation Time (sec)\nOSPF SPF\nBF Q-R PQ-R AntNet Daemon\n(a) 0.00.2 0.4\n0.6\n0.8\n1.0\n0 0.05 0.1 0.15 0.2\nE m\npi ric\nal D\nis tr\nib ut\nio n\nPacket Delay (sec)\nOSPF SPF\nBF Q-R PQ-R AntNet\nDaemon(b)Figure 8: SimpleNet: Comparison of algorithms for F-CBR tra c directed from node 1 to node 6(MPIA = 0.0003 sec). (a) Throughput, and (b) packet delays empirical distribution.7.2 NSFNETWe carried out a wide range of experiments on NSFNET using UP, RP, UP-HS and TMPHS-UP tra c patterns. In all the cases considered, di erences in throughput are of minorimportance with respect to those shown by packet delays. For each one of the UP, RPand UP-HS cases we ran ve distinct groups of ten trial experiments, gradually increasingthe generated workload (in terms of reducing the session inter-arrival time). As explainedabove, we studied the behavior of the algorithms when moving the tra c load towards asaturation region.In the UP case, di erences in throughput (Figure 9a) are small: the best performingalgorithms are BF and SPF, which can attain performance of only about 10% inferior tothose of Daemon and of the same amount better than those of AntNet, Q-R and PQ-R,14while OSPF behaves slightly better than these last ones. Concerning delays (Figure 9b) the14. It is worth remarking that in these and in some of the experiments presented in the following, PQ-R'sperformance is slightly worse than that of Q-R. This seems to be in contrast with the results presentedby the PQ-R's authors in the article where they introduced PQ-R (Choi & Yeung, 1996). We think thatthis behavior is due to the fact that (i) their link recovery rate matches a discrete-time system whilein our simulator time is a continuous variable, and (ii) the experimental and simulation conditions arerather di erent (in their article it is not speci ed the way they produced tra c patterns and they didnot implement a realistic network simulator). 342\nAntNet: Distributed Stigmergetic Control for Communications Networkssituation is rather di erent, as can be seen by the fact that all the algorithms but AntNethave been able to produce a slightly higher throughput at the expenses of much worseresults for packet delays. This trend in packet delays was con rmed by all the experimentswe ran. OSPF, Q-R and PQ-R show really poor results (delays of order 2 or more secondsare very high values, even if we are considering the 90-th percentile of the distribution),while BF and SPF behave in a similar way with performance of order 50% worse than thoseobtained by AntNet and of order 65% worse than Daemon.\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\nAntNet OSPF SPF BF Q-R PQ-R Daemon\nT h ro\nu g h p u t (1\n0 6\nb it/\nse c)\n2.4 2.3 2.2 2.1 2\n(a) 0.00.51.0 1.5\n2.0\n2.5\n3.0\n3.5\n4.0\n4.5\nAntNet OSPF SPF BF Q-R PQ-R Daemon9 0\n-t h\np e\nrc e\nn til\ne o\nf p\na ck\ne t\nd e\nla ys\n( se\nc)\n2.4 2.3 2.2 2.1 2\n(b)Figure 9: NSFNET: Comparison of algorithms for increasing load for UP tra c. The load isincreased reducing the MSIA value from 2.4 to 2 seconds (MPIA = 0.005 sec). (a)Throughput, and (b) 90-th percentile of the packet delays empirical distribution.In the RP case (Figure 10a), throughputs generated by AntNet, SPF and BF are verysimilar, although AntNet has a slightly better performance. OSPF and PQ-R behave onlyslightly worse while Q-R is the worst algorithm. Daemon is able to obtain only slightlybetter results than AntNet. Again, looking at packet delays results (Figure 10b) OSPF,Q-R and PQ-R perform very badly, while SPF shows results a bit better than those of BFbut of order 40% worse than those of AntNet. Daemon is in this case far better, whichindicates that the testbed was very di cult.For the case of UP-HS load, throughputs (Figure 11a) for AntNet, SPF, BF, Q-R andDaemon are very similar, while OSPF and PQ-R clearly show much worse results. Again(Figure 11b), packet delays results for OSPF, Q-R and PQ-R are much worse than thoseof the other algorithms (they are so much worse that they do not t in the scale chosento make clear di erences among the other algorithms). AntNet is still the best performingalgorithm. In this case, di erences with SPF are of order 20% and of 40% with respect toBF. Daemon performs about 50% better than AntNet and scales much better than AntNet,which, again, indicates the testbed was rather di cult.The last graph for NSFNET shows how the algorithms behave in the case of a TMPHS-UP situation (Figure 12). At time t = 400 four hot spots are turned on and superimposedto the existing light UP tra c. The transient is kept on for 120 seconds. In this case, onlyone, typical, situation is reported in detail to show the answer curves. Reported values343\nDi Caro & Dorigo\n0\n2\n4\n6\n8\n10\n12\nAntNet OSPF SPF BF Q-R PQ-R Daemon\nT h ro\nu g h p u t (1\n0 6\nb it/\nse c)\n2.8 2.7 2.6 2.5 2.4\n(a) 0.00.51.0 1.5\n2.0\n2.5\n3.0\n3.5\n4.0\nAntNet OSPF SPF BF Q-R PQ-R Daemon9 0\n-t h\np e\nrc e\nn til\ne o\nf p\na ck\ne t\nd e\nla ys\n( se\nc)\n2.8 2.7 2.6 2.5 2.4\n(b)Figure 10: NSFNET: Comparison of algorithms for increasing load for RP tra c. The load isincreased reducing the MSIA value from 2.8 to 2.4 seconds (MPIA = 0.005 sec). (a)Throughput, and (b) 90-th percentile of the packet delays empirical distribution.\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\nAntNet OSPF SPF BF Q-R PQ-R Daemon\nT h ro\nu g h p u t (1\n0 6\nb it/\nse c)\n2.4 2.3 2.2 2.1 2\n(a) 0.00.1 0.2\n0.3\n0.4\n0.5\nAntNet OSPF SPF BF Q-R PQ-R Daemon9 0\n-t h\np e\nrc e\nn til\ne o\nf p\na ck\ne t\nd e\nla ys\n( se\nc)\n2.4 2.3 2.2 2.1 2\n(b)Figure 11: NSFNET: Comparison of algorithms for increasing load for UP-HS tra c. The load isincreased reducing the MSIA value from 2.4 to 2.0 seconds (MPIA = 0.3 sec, HS = 4,MPIA-HS = 0.04 sec). (a) Throughput, and (b) 90-th percentile of the packet delaysempirical distribution.are the \\instantaneous\" values for throughput and packet delays computed as the averageover 5 seconds moving windows. All algorithms have a similar very good performance asfar as throughput is concerned, except for OSPF and PQ-R, which lose a few percent ofthe packets during the transitory period. The graph of packet delays con rms previousresults: SPF and BF have a similar behavior, about 20% worse than AntNet and 45%worse than Daemon. The other three algorithms show a big out-of-scale jump, being notable to properly dump the sudden load increase.344\nAntNet: Distributed Stigmergetic Control for Communications Networks\n6.0\n8.0\n10.0\n12.0\n14.0\n16.0\nTh ro\nug hp\nut (1\n06 b\nit/ se\nc)\nOSPF SPF\nBF Q-R PQ-R AntNet Daemon\n0.03\n0.04\n0.05\n0.06\n200 300 400 500 600 700 800 900 1000\nP ac\nke t D\nel ay\n(s ec\n)\nSimulation Time (sec)Figure 12: NSFNET: Comparison of algorithms for transient saturation conditions withTMPHS-UP tra c (MSIA = 3.0 sec, MPIA = 0.3 sec, HS = 4, MPIA-HS =0.04). (a) Throughput, and (b) packet delays averaged over 5 seconds movingwindows.7.3 NTTnetThe same set of experiments run on the NSFNET have been repeated on NTTnet. In thiscase the results are even sharper than those obtained with NSFNET: AntNet performanceis much better that of all its competitors.For the UP, RP and UP-HS cases, di erences in throughput are not signi cant (Figures13a, 14a and 15a). All the algorithms, with the OSPF exception, practically behave inthe same way as the Daemon algorithm. Concerning delays (Figures 13b, 14b and 15b),di erences between AntNet and each of its competitors are of one order of magnitude.AntNet keeps delays at low values, very close to those obtained by Daemon, while SPF,BF, Q-R and PQ-R perform poorly and OSPF completely collapses.In the UP and RP cases (Figures 13b and 14b) SPF and BF performs similarly, even if SPFshows slightly better results, and about 50% better than Q-R and PQ-R.In the UP-HS case, again, SPF and BF show similar results, while Q-R performs compa-rably but in a much more irregular way and PQ-R can keep delays about 30% lower. OSPF,which is the worse algorithm in this case, shows an interesting behavior. The increase in thegenerated data throughput determines a decrease or a very slow increase in the deliveredthroughput while delays decrease (Figure 15a and 15b). In this case the load was too highfor the algorithm and the balance between the two, con icting, objectives, throughput and345\nDi Caro & Dorigo\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\nAntNet OSPF SPF BF Q-R PQ-R Daemon\nT h ro\nu g h p u t (1\n0 6\nb it/\nse c)\n3.1 3 2.9 2.8 2.7\n(a) 0.01.02.03.0 4.0\n5.0\n6.0\n7.0\n8.0\n9.0\n10.0\nAntNet OSPF SPF BF Q-R PQ-R Daemon9 0\n-t h\np e\nrc e\nn til\ne o\nf p\na ck\ne t\nd e\nla ys\n( se\nc)\n3.1 3 2.9 2.8 2.7\n(b)Figure 13: NTTnet: Comparison of algorithms for increasing load for UP tra c. The load isincreased reducing the MSIA value from 3.1 to 2.7 seconds (MPIA = 0.005 sec). (a)Throughput, and (b) 90-th percentile of the packet delays empirical distribution.\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\nAntNet OSPF SPF BF Q-R PQ-R Daemon\nT h ro\nu g h p u t (1\n0 6\nb it/\nse c)\n3.1 3 2.9 2.8 2.7\n(a) 0.01.02.03.0 4.0\n5.0\n6.0\n7.0\n8.0\n9.0\n10.0\nAntNet OSPF SPF BF Q-R PQ-R Daemon9 0\n-t h\np e\nrc e\nn til\ne o\nf p\na ck\ne t\nd e\nla ys\n( se\nc) 3.1 3 2.9 2.8 2.7\n(b)Figure 14: NTTnet: Comparison of algorithms for increasing load for RP tra c. The load isincreased reducing the MSIA value from 3.1 to 2.7 seconds (MPIA = 0.005 sec). (a)Throughput, and (b) 90-th percentile of the packet delays empirical distribution.packet delays, showed an inverse dynamics: having a lot of packet losses made it possiblefor the surviving packets to obtain lower trip delays.The TMPHS-UP experiment (Figure 16), concerning sudden load variation, con rmsthe previous results. OSPF is not able to follow properly the variation both for throughputand delays. All the other algorithms are able to follow the sudden increase in the o eredthroughput, but only AntNet (and Daemon) show a very regular behavior. Di erences inpacket delays are striking. AntNet performance is very close to those obtained by Daemon(the curves are practically superimposed at the scale used in the Figure). Among the otheralgorithms, SPF and BF are the best ones, although their response is rather irregular and,in any case, much worse than AntNet's. OSPF and Q-R are out-of-scale and show a verydelayed recovering curve. PQ-R, after a huge jump, which takes the graph out-of-scale in346\nAntNet: Distributed Stigmergetic Control for Communications Networks\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\n50\nAntNet OSPF SPF BF Q-R PQ-R Daemon\nT h ro\nu g h p u t (1\n0 6\nb it/\nse c)\n4.1 4 3.9 3.8 3.7\n(a) 0.01.02.0 3.0\n4.0\n5.0\n6.0\n7.0\nAntNet OSPF SPF BF Q-R PQ-R Daemon9 0\n-t h\np e\nrc e\nn til\ne o\nf p\na ck\ne t\nd e\nla ys\n( se\nc)\n4.1 4 3.9 3.8 3.7\n(b)Figure 15: NTTnet: Comparison of algorithms for increasing load for UP-HS tra c. The load isincreased reducing the MSIA value from 4.1 to 3.7 seconds (MPIA = 0.3 sec, HS = 4,MPIA-HS = 0.05 sec). (a) Throughput, and (b) 90-th percentile of the packet delaysempirical distribution.the rst 40 seconds after hot spots are turned on, shows a trend approaching those of BFand SPF. 15.0 25.0 35.0 45.0 55.0 Th ro ug hp ut (1 06 b it/ se c)\nOSPF SPF\nBF Q-R PQ-R AntNet Daemon\n0.0\n0.2\n0.4\n0.6\n0.8\n200 300 400 500 600 700 800 900 1000\nP ac\nke t D\nel ay\n(s ec\n)\nSimulation Time (sec)Figure 16: NTTnet: Comparison of algorithms for transient saturation conditions withTMPHS-UP tra c (MSIA = 4.0 sec, MPIA = 0.3 sec, HS = 4, MPIA-HS =0.05). (a) Throughput, and (b) packet delays averaged over 5 seconds movingwindows. 347\nDi Caro & Dorigo7.4 Routing OverheadTable 2 reports results concerning the overhead generated by routing packets. For eachalgorithm the network load generated by the routing packets is reported as the ratio betweenthe bandwidth occupied by the routing packets and the total available network bandwidth.Each row in the table refers to a previously discussed experiment (Figs. 8 to 11 and 13to 15). Routing overhead is computed for the experiment with the heaviest load in theincreasing load series. AntNet OSPF SPF BF Q-R PQ-RSimpleNet - F-CBR 0.33 0.01 0.10 0.07 1.49 2.01NSFNET - UP 2.39 0.15 0.86 1.17 6.96 9.93NSFNET - RP 2.60 0.15 1.07 1.17 5.26 7.74NSFNET - UP-HS 1.63 0.15 1.14 1.17 7.66 8.46NTTnet - UP 2.85 0.14 3.68 1.39 3.72 6.77NTTnet - RP 4.41 0.14 3.02 1.18 3.36 6.37NTTnet - UP-HS 3.81 0.14 4.56 1.39 3.09 4.81Table 2: Routing Overhead: ratio between the bandwidth occupied by the routing packetsand the total available network bandwidth. All data are scaled by a factor of 10 3.All data are scaled by a factor of 10 3. The data in the table show that the routingoverhead is negligible for all the algorithms with respect to the available bandwidth. Amongthe adaptive algorithms, BF shows the lowest overhead, closely followed by SPF. AntNetgenerates a slightly bigger consumption of network resources, but this is widely compensatedby the much higher performance it provides. Q-R and PQ-R produce an overhead a bithigher than that of AntNet. The routing load caused by the di erent algorithms is a functionof many factors, speci c of each algorithm. Q-R and PQ-R are data-driven algorithms: ifthe number of data packets and/or the length of the followed paths (because of topologyor bad routing) grows, so will the number of generated routing packets. BF, SPF andOSPF have a more predictable behavior: the generated overhead is mainly function of thetopological properties of the network and of the generation rate of the routing informationpackets. AntNet produces a routing overhead depending on the ants generation rate andon the length of the paths they travel.The ant tra c can be roughly characterized as a collection of additional tra c sources,one for each network node, producing very small packets (and related acknowledgementpackets) at constant bit rate with destinations matching the o ered data tra c. On averageants will travel over rather \\short\" paths and their size will grow of only 8 bytes at each hop.Therefore, each \\ant routing tra c source\" represents a very light additional tra c sourcewith respect to network resources when the ant launching rate is not excessively high. InFigure 17, the sensitivity of AntNet with respect to the ant launching rate is reported.For a sample case of a UP data tra c model on NSFNET (previously studied in Figure9) the interval g between two consecutive ant generations is progressively decreased ( gis the same for all nodes). g values are sampled at constant intervals over a logarithmicscale ranging from about 0.006 to 25 seconds. The lower, dashed, curve interpolates the348\nAntNet: Distributed Stigmergetic Control for Communications Networks\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n0.001 0.01 0.1 1 10 100\nAn tN\net N\nor m\nal iz\ned P\now er\nV s.\nR ou\ntin g\nO ve\nrh ea\nd\nInterval g Between Two Consecutive Ants Generations (sec)\nNormalized Power Routing Overhead\nFigure 17: AntNet normalized power vs. routing overhead. Power is de ned as the ratiobetween delivered throughput and packet delay.generated routing overhead expressed, as before, as the fraction of the available networkbandwidth used by routing packets. The upper, solid, curve plots the data for the obtainedpower normalized to its highest value, where the power is de ned as the ratio between thedelivered throughput and the packet delay. The value used for delivered throughput is thethroughput value at time 1000 averaged over ten trials, while for packet delay we used the90-th percentile of the empirical distribution.In the gure, we can see how an excessively small g causes an excessive growth of therouting overhead, with consequent reduction of the algorithm power. Similarly, when gis too big, the power slowly diminishes and tends toward a plateau because the number ofants is not enough to generate and maintain up-to-date statistics of the network status. Inthe middle of these two extreme regions a wide range of g intervals gives raise to similar,very good power values, while, at the same time, the routing overhead quickly falls downtoward negligible values. This gure strongly con rms our previous assertion about therobustness of AntNet's internal parameter settings.8. DiscussionIn AntNet, the continual on-line construction of the routing tables is the emergent resultof a collective learning process. In fact, each forward-backward agent pair is complexenough to nd a good route and to adapt the routing tables for a single source-destinationpath, but it cannot solve the global routing optimization problem. It is the interactionbetween the agents that determines the emergence of a global e ective behavior from thenetwork performance point of view. Ants cooperate in their problem-solving activity bycommunicating in an indirect and non-coordinated way. Each agent acts independently.Good routes are discovered by applying a policy that is a function of the information349\nDi Caro & Dorigoaccessed through the network nodes visited, and the information collected about the routeis eventually released on the same nodes. Therefore, the inter-agent communication ismediated in an explicit and implicit way by the \\environment\", that is, by the node's datastructures and by the tra c patterns recursively generated by the data packets' utilizationof the routing tables. This communication paradigm, called stigmergy, matches well theintrinsically distributed nature of the routing problem. Cooperation among agents goeson at two levels: (a) by modi cations of the routing tables, and (b) by modi cations oflocal models that determine the way the ants' performance is evaluated. Modi cations ofthe routing tables directly a ect the routing decisions of following ants towards the samedestination, as well as the routing of data, which, in turn, in uences the rate of arrivalof other ants towards any destination. It is interesting to remark that the used stigmergyparadigm makes the AntNet's mobile agents very exible from a software engineering pointof view. In this perspective, once the interface with the node's data structure is de ned,the internal policy of the agents can be transparently updated. Also, the agents could beexploited to carry out multiple concurrent tasks (e.g., collecting information for distributednetwork management using an SNMP-like protocol or for Web data-mining tasks).As shown in the previous section, the results we obtained with the above stigmergeticmodel of computation are excellent. In terms of throughput and average delay, AntNetperforms better than both classical and recently proposed routing algorithms on a widerange of experimental conditions. Although this is very interesting per se, in the followingwe try to justify AntNet superior performance by highlighting some of its characteristicsand by comparing them with those of the competing algorithms. We focus on the followingmain aspects: AntNet can be seen as a particular instance of a parallel Monte Carlo simulationsystem with biased exploration. All the other algorithms either do not explore thenet or their exploration is local and tightly connected to the ux of data packets. The information AntNet maintains at each node is more complete and organized in aless critical way than that managed by the other algorithms. AntNet does not propagate local estimates to other nodes, while all its competitorsdo. This mechanism makes the algorithm more robust to locally wrong estimates. AntNet uses probabilistic routing tables, which have the triple positive e ect of bet-ter redistributing data tra c on alternative routes, of providing ants with a built-inexploration mechanism and of allowing the exploitation of the ants' arrival rate toassign cumulative reinforcements. It was experimentally observed that AntNet is much more robust than its competitorsto the frequency with which routing tables are updated. The structure of AntNet allows one to draw some parallels with some well-knownreinforcement learning (RL) algorithms. The characteristics of the routing problem,that can be seen as a distributed time-varying RL problem (see sect. 2.2), determinesa departure of AntNet from the structure of classical RL algorithms.These aspects of AntNet are discussed in more detail in the following.350\nAntNet: Distributed Stigmergetic Control for Communications Networks8.1 AntNet as an on-line Monte Carlo system with biased explorationThe AntNet routing system can be seen as a collection of mobile agents collecting dataabout the network status by concurrently performing on-line Monte Carlo simulations (Ru-bistein, 1981; Streltsov & Vakili, 1996). In Monte Carlo methods, repeated experimentswith stochastic transition components are run to collect data about the statistics of in-terest. Similarly, in AntNet ants explore the network by performing random experiments(i.e., building paths from source to destination nodes using a stochastic policy dependenton the past and current network states), and collect on-line information on the networkstatus. A built-in variance reduction e ect is determined (i) by the way ants' destinationsare assigned, biased by the most frequently observed data's destinations, and (ii) by the waythe ants' policy makes use of current and past tra c information (that is, inspection of thelocal queues' status and probabilistic routing tables). In this way, the explored paths matchthe most interesting paths from a data tra c point of view, which results in a very e cientvariance reduction e ect in the stochastic sampling of the paths. Di erently from usualo -line Monte Carlo systems, in AntNet the state space sampling is performed on-line, thatis, the sampling of the statistics and the controlling of the non-stationary tra c process areperformed concurrently.This way of exploring the network concurrently with data tra c is very di erent fromwhat happens in the other algorithms where, either there is no exploration at all (OSPF,SPF and BF), or exploration is both tightly coupled to data tra c and of a local nature(Q-R and PQ-R). Conveniently, as was shown in Section 7.4, the extra tra c generated byexploring ants is negligible for a wide range of values, allowing very good performance.8.2 Information management at each network nodeKey characteristics of routing algorithms are the type of information used to build/updaterouting tables and the way this information is propagated. All the algorithms (except thestatic OSPF) make use at each node of two main components: a local model M of somecost measures and a routing table T . SPF and BF use M to estimate smoothed averagesof the local link costs, that is, of the distances to the neighbor nodes. In this case, M isa local model maintaining estimates of only local components. In Q-R the local model is ctitious because the raw transition time is directly used as a value to update T . PQ-Ruses a slightly more sophisticated model with respect to Q-R, storing also a measure of thelink utilization. All these algorithms propagate part of their local information to the othernodes, which, in turn, make use of it to update their routing tables and to build a globalview of the network. In SPF and BF the content of each T is updated, at regular intervals,by a \\memoryless strategy\": the new entries do not depend on the old values, that arediscarded. Therefore, the whole adaptive component of the routing system is representedby the model M. Otherwise, in Q-R and PQ-R the adaptive content of M is almostnegligible and the adaptive component of the algorithm is represented by the smoothedaverage carried out by the Q-learning-like rule. AntNet shows characteristics rather di erentfrom its competitors: its modelM contains a memory-based local perspective of the globalstatus of the network. The content of M allow the reinforcements to be weighted on thebasis of a rich statistical description of the network dynamics as seen by the local node.These reinforcements are used to update the routing table, the other adaptive component351\nDi Caro & Dorigomaintained at the node. The T updates are carried out in an asynchronous way and as afunction of their previous values. Moreover, while T is used in a straightforward probabilisticway by the data packets, traveling ants select the next node by using both T , that is, anadaptive representation of the past policy, and a model of the current local link queues,that is, an instantaneous representation of the node status. It is evident that AntNet buildsand uses more information than its competitors: two di erent memory-based componentsand an instantaneous predictor are used and combined at di erent levels. Moreover, in thisway AntNet robustly redistributes among these completely local components the criticalityof all the estimates and decisions.8.3 AntNet's robustness to wrong estimatesAs remarked above, AntNet, di erently from its competitors, does not propagate localestimates to other nodes. Each node routing table is updated independently, by usinglocal information and the ants' experienced trip time. Moreover, (i) each ant experimenta ects only one entry in the routing table of the visited nodes, the one relative to the ant'sdestination, and, (ii) the local information is built from the \\global\" information collectedby traveling ants, implicitly reducing in this way the variance in the estimates. Thesecharacteristics make AntNet particularly robust to wrong estimates. On the contrary, inall the other algorithms a locally wrong estimate will be propagated to all other nodes andwill be used to compute estimates to many di erent destinations. How bad this is for thealgorithm performance depends on how long the wrong estimate e ect lasts. In particular,this will be a function of the time window over which estimates are computed for SPF andBF, and of the learning parameters for Q-R and PQ-R.8.4 AntNet's probabilistic use of routing tables to route data packetsAll the tested algorithms but AntNet use deterministic routing tables.15 In these algorithms,entries in the routing tables contain distance/time estimates to the destinations. Theseestimates can provide misleading information if the algorithm is not fast enough to followthe tra c uctuations, as can be the case under heavy load conditions. Instead, AntNetrouting tables have probabilistic entries that, although re ecting the goodness of a particularpath choice with respect to the others available, do not force the data packets to choosethe perceived best path. This has the positive e ect of allowing a better balancing ofthe tra c load on di erent paths, with a resulting better utilization of the resources (aswas shown in particular in the experiments with the SimpleNet). As remarked at theend of Section 4.1, the intrinsic probabilistic structure of the routing tables and the waythey are updated allow AntNet to exploit the ant's arrival rate as a way to assign implicit(cumulative) reinforcements to discovered paths. It is not obvious how the same e ectcould be obtained by using routing tables containing distance/time estimates and usingthis estimates in a probabilistic way. In fact, in this case each new trip time sample would15. Singh, Jaakkola, and Jordan (1994) showed that stochastic policies can yield higher performance thandeterministic policies in the case of an incomplete access to the state information of the environment. In(Jaakkola, Singh, & Jordan, 1995), the same authors developed a Monte-Carlo-based stochastic policyevaluation algorithm, con rming the usefulness of the Monte-Carlo approach, used in AntNet too, todeal with incomplete information problems. 352\nAntNet: Distributed Stigmergetic Control for Communications Networksmodify the statistical estimate that would simply oscillate around its expected value withoutinducing an arrival-dependent cumulative e ect.Probabilistic routing tables provide some remarkable additional bene ts: (a) they give tothe ants a built-in exploration method in discovering new, possibly better, paths, and (b)since ants and data routing are independent in AntNet, the exploration of new routescan continue while, at the same time, data packets can exploit previously learned, reliableinformation. It is interesting to note that the use of probabilistic routing tables whose entriesare learned in an adaptive way by changing on positive feedback and ignoring negativefeedback, is reminiscent of older automata approaches to routing in telecommunicationsnetworks. In these approaches, a learning automaton is usually placed on each networknode. An automaton is de ned by a set of possible actions and a vector of associatedprobabilities, a continuous set of inputs and a learning algorithm to learn input-outputassociations. Automata are connected in a feedback con guration with the environment(the whole network), and a set of penalty signals from the environment to the actions isde ned. Routing choices and modi cations to the learning strategy are carried out in aprobabilistic way and according to the network conditions (see for example (Nedzelnitsky& Narendra, 1987; Narendra & Thathachar, 1980)). The main di erence lies in the factthat in AntNet the ants are part of the environment itself, and they actively direct thelearning process towards the most interesting regions of the search space. That is, thewhole environment plays a key, active role in learning good state-action pairs.8.5 AntNet robustness to routing table update frequencyIn BF and SPF the broadcast frequency of routing information plays a critical role, particu-larly so for BF, which has only a local representation of the network status. This frequencyis unfortunately problem dependent, and there is no easy way to make it adaptive, while,at the same time, avoiding large oscillations. In Q-R and PQ-R, routing tables updatingis data driven: only those Q-values belonging to pairs (i; j) of neighbor nodes visited bypackets are updated. Although this is a reasonable strategy given that the exploration ofnew routes could cause undesired delays to data packets, it causes delays in discovering newgood routes, and is a great handicap in a domain where good routes could change all thetime. In OSPF, in which routing tables are not updated, we set static link costs on thebasis of their physical characteristics. This lack of an adaptive metric is the main reasonof the poor performance of OSPF (as remarked in Section 5, we slightly penalized OSPFwith respect to its real implementations, where additional heuristic knowledge about tra cpatterns is used by network administrators to set link costs). In AntNet, we experimentallyobserved the robustness to changes in the ants' generation rate: for a wide range of genera-tion rates, rather independent of the network size, the algorithm performance is very goodand the routing overhead is negligible (see Section 7.4).8.6 AntNet and reinforcement learningThe characteristics of the routing problem allow one to interpret it as a distributed, stochas-tic time-varying RL problem. This fact, as well as the structure of AntNet, make it naturalto draw some parallels between AntNet and classical RL approaches. It is worth remarkingthat those RL problems that have been most studied, and for which algorithms have been de-353\nDi Caro & Dorigoveloped, are problems where, unlike routing, assumptions like Markovianity or stationarityof the process considered are satis ed. The characteristics of the adaptive routing problemmake it very di cult and not well suited to be solved with usual RL algorithms. This fact,as we explain below, determines a departure of AntNet from classical RL algorithms.A rst way to relate the structure of AntNet to that of a (general) RL algorithm isconnected to the way the outcomes of the experiments, the trip times Tk!d, are processed.The transformation from the raw values Tk!d to the more re ned reinforcements r arereminiscent of what happens in Actor-Critic systems (Barto, Sutton, & Anderson, 1983):the raw reinforcement signal is processed by a critic module, which is learning a model (thenode's componentM) of the underlying process, and then is fed to the learning system (therouting table T ) transformed into an evaluation of the policy followed by the ants. In ourcase, the critic is both adaptive, to take into account the variability of the tra c process,and rather simple, to meet computational requirements.Another way of seeing AntNet as a classical RL system is related to its interpretation asa parallel replicated Monte Carlo (MC) system. As was shown by Singh and Sutton (1996),a rst-visit MC (only the rst visit to a state is used to estimate its value during a trial)simulation system is equivalent to a batch temporal di erence (TD) method with replacingtraces and decay parameter =1. Although AntNet is a rst-visit MC simulation system,there are some important di erences with the type of MC used by Singh and Sutton (andin other RL works), mainly due to the di erences in the considered class of problems. InAntNet, outcomes of experiments are both used to update local models able to capturethe variability of the whole network status (only partially observable) and to generate asequence of stochastic policies. On the contrary, in the MC system considered by Singh andSutton, outcomes of the experiments are used to compute (reduced) maximum-likelihoodestimates of the expected mean and variance of the states' returns (i.e., the total rewardfollowing a visit of a state) of a Markov chain. In spite of these di erences, the weak parallelwith TD( ) methods is rather interesting, and allows to highlight an important di erencebetween AntNet and its competitors (and general TD methods): in AntNet, following thegeneration of a stochastic transition chain by the forward ant, there is no back-chainingof the information from one state (i.e., a triple fcurrent node, destination node, next hopnodeg) to its predecessors. Each state is rewarded only on the basis of the ant's trip timeinformation strictly relevant to it. This approach is completely di erent from that followedby (TD methods) Q-R, PQ-R, BF and, in a di erent perspective, by SPF. In fact, thesealgorithms build the distance estimates at each node by using the predictions made at othernodes. In particular, Q-R and PQ-R, which propagate the estimation information only onestep back, are precisely distributed versions of the TD(0) class of algorithms. They could betransformed into generic TD( ), 0 < 1, by transmitting backward to all the previouslyvisited nodes the information collected by the routing packet generated after each data hop.Of course, this would greatly increase the routing tra c generated, because it has to bedone after each hop of each data packet, making the approach at least very costly, if feasibleat all.In general, using temporal di erences methods in the context of routing presents an impor-tant problem: the key condition of the method, the self-consistency between the estimatesof successive states16 may not be strictly satis ed in the general case. This is due to the16. For instance, the prediction made at node k about the time to-go to the destination node d should be354\nAntNet: Distributed Stigmergetic Control for Communications Networksfact that (i) the dynamics at each node are related in a highly non-linear way to the dy-namics of all its neighbors, (ii) the tra c process evolves concurrently over all the nodes,and (iii) there is a recursive interaction between the tra c patterns and the control actions(that is, the modi cations of the routing tables). This aspect can explain in part the poorperformance of the pure TD(0) algorithms Q-R and PQ-R.9. Related WorkAlgorithms based on the ant colony metaphor were inspired by the ant colony foragingbehavior (Beckers et al., 1992). These were rst proposed by Dorigo (1992), Colorni etal. (1991) and Dorigo et al. (1991, 1996) and were applied to the traveling salesmanproblem (TSP). Apart from the natural metaphor, the idea behind that rst applicationwas similar to the one presented in this paper: a set of agents that repeatedly run MonteCarlo experiments whose outcomes are used to change the estimates of some variables usedby subsequent ants to build solutions. In ant-cycle, one of the rst ant-based algorithms,a value called \\pheromone trail\" is associated to each edge of the graph representing theTSP. Each ant builds a tour by exploiting the pheromone trail information as follows.When in node i an ant chooses the next node j to move to among those not visited yetwith a probability Pij that is a function of the amount of pheromone trail on the edgeconnecting i to j (as well as of a local heuristic function; the interested reader can nd adetailed description of ant-cycle elsewhere (Dorigo, 1992; Dorigo et al., 1996)). The valueof the pheromone trails is updated once all ants have built their tours. Each ant addsto all visited edges a quantity of pheromone trail proportional to the quality of the tourgenerated (the shorter the tour, the higher the quantity of pheromone trail added). Thishas an e ect very similar to AntNet's increase of routing tables probabilities, since a higherpheromone trail on a particular edge will increase its probability of being chosen in thefuture. There are obviously many di erences between ant-cycle and AntNet, mostly dueto the very di erent types of problems to which they have been applied, a combinatorialoptimization problem versus a distributed, stochastic, time varying, real-time problem.Though the majority of previous applications of ant colony inspired algorithms con-cern combinatorial optimization problems, there have been recent applications to routing.Schoonderwoerd et al. (1996, 1997) were the rst to consider routing as a possible applica-tion domain for ant colony algorithms. Their ant-based control (ABC) approach, which isapplied to routing in telephone networks, di ers from AntNet in many respects. The maindi erences are a direct consequence of the di erent network model they considered, whichhas the following characteristics (see Figure 18): (i) connection links potentially carry anin nite number of full-duplex, xed bandwidth channels, and (ii) transmission nodes arecrossbar switches with limited connectivity (that is, there is no necessity for queue manage-ment in the nodes). In such a model, bottlenecks are put on the nodes, and the congestiondegree of a network can be expressed in terms of connections still available at each switch.As a result, the network is cost-symmetric: the congestion status over available paths iscompletely bi-directional. The path n0; n1; n2; : : : ; nk connecting n0 and nk will exhibit theadditively related to the prediction for the same destination from each one of k's neighbors, being eachneighbor one of the ways to go to d. 355\nDi Caro & Dorigosame level of congestion in both directions because the congestion depends only on the stateof the nodes in the path. Moreover, dealing with telephone networks, each call occupies Link 4 N bidirectional channels Link 1\nLink 3 n << N possible connections\nLink 2\nexactly one physical channel across the path.Therefore, \\calls\" are not multiplexed over thelinks, but they can be accepted or refused, de-pending on the possibility of reserving a physicalcircuit connecting the caller and the receiver. Allof these modeling assumptions make the prob-lem of Schoonderwoerd et al. very di erent fromthe cost-asymmetric routing problem for datanetworks we presented in this paper. This dif-ference is re ected in many algorithmic di er-ences between ABC and AntNet, the most im-portant of which is that in ABC ants updatepheromone trails after each step, without waitingfor the completion of an experiment as done inAntNet. This choice, which is reminiscent of thepheromone trail updating strategy implementedin ant-density, another of the rst ant colony based algorithms (Dorigo et al., 1991; Dorigo,1992; Colorni et al., 1991), makes ABC behavior closer to real ants', and was made possibleby the cost-symmetry assumption made by the authors.Other di erences are that ABC does not use local models to score the ants trip times,nor local heuristic information and ant-private memory to improve the ants decision policies.Also, it does not recover from cycles and does not use the information contained in all theant sub-paths.Because of the di erent network model used and of the many implementation detailstightly bound to the network model, it was impossible for us to re-implement and comparethe ABC algorithm with AntNet.Subramanian, Druschel, and Chen (1997) have proposed an ant-based algorithm forpacket-switched nets. Their algorithm is a straightforward extension of Schoonderwoerdet al. system by adding so-called uniform ants, an additional exploration mechanism thatshould avoid a rapid sub-optimal convergence of the algorithm. A limitation of Subramanianet al. work is that, although the algorithm they propose is based on the same cost-symmetryhypothesis as ABC, they apply it to packet-switched networks where this requirement isvery often not met.10. Conclusions and Future WorkIn this paper, we have introduced AntNet, a novel distributed approach to routing in packet-switched communications networks. We compared AntNet with 6 state-of-the-art routingalgorithms on a variety of realistic testbeds. AntNet showed superior performance androbustness to internal parameter settings for almost all the experiments. AntNet's mostinnovative aspect is the use of stigmergetic communication to coordinate the actions of aset of agents that cooperate to build adaptive routing tables. Although this is not the rst application of stigmergy-related concepts to optimization problems (e.g., Dorigo et al.,356\nAntNet: Distributed Stigmergetic Control for Communications Networks1991; Dorigo, 1992; Dorigo et al., 1996; Bonabeau, Dorigo, & Th eraulaz, 1999), the appli-cation presented here is unique in many respects. First, in AntNet, stigmergy-based controlis coupled to a model-building activity: information collected by ants is used not only tomodify routing tables, but also to build local models of the network status to be used tobetter direct the routing table modi cations. Second, this is the rst attempt to evaluatestigmergy-based control on a realistic simulator of communications networks: the used sim-ulator retains many of the basic components of a real routing system. An interesting stepforward, in the direction of testing the applicability of the idea presented to real networks,would be to rerun the experiments presented here using a complete Internet simulator.Third, this is also the rst attempt to evaluate stigmergy-based control by comparing astigmergetic algorithm to state-of-the-art algorithms on a realistic set of benchmark prob-lems. It is very promising that AntNet turned out to be the best performing in all thetested conditions.There are obviously a number of directions in which the current work could be extended,which are listed below.1) A rst, natural, extension of the current work would consider the inclusion in thesimulator of ow and congestion control components (with re-transmissions and error man-agement). This inclusion will require a paired tuning of the routing and ow-congestioncomponents, to select the best matching between their dynamics.2) In AntNet, each forward ant makes a random experiment: it builds a path from asource node s to a destination node d. The path is built exploiting the information containedin the probabilistic routing tables and the status of the queues of the visited nodes. Whilebuilding the path, the ant collects information on the status of the network. This is doneby sharing link queues with data packets, and by measuring waiting times of queues andtraversal times that will be used as raw reinforcements by backward ants. Since forwardants share queues with data packets, the time required to run an experiment depends onthe network load, and is approximately the same as the time Ts!d required for a packet togo from the same source node s to the same destination node d. This delays the momentthe information collected by forward ants can be distributed by backward ants, and makesit less up-to-date than it could be. A possible improvement in this schema would be toadd a model of link-queue depletion to nodes, and to let forward ants use high priorityqueues to reach their destinations without storing crossing times (for a rst step in thisdirection see Di Caro & Dorigo, 1998). Backward ants would then make the same path, inthe opposite direction, as forward ants, but use the queue local models they nd on theirway to estimate local \\virtual\" queueing and crossing times. Raw reinforcements, used toupdate the routing tables, are then computed using these estimates. Clearly, here there is atrade-o between delayed but real information and more recent but estimated information.It will be interesting to see which scheme works better, although we are con dent that thelocal queue models should allow the backward ants to build estimates accurate enough tomake the improved system more e ective than the current AntNet, at a cost of a littleincrease in computational complexity at the nodes.3) As we discussed in Section 8, AntNet is missing one of the main components of classicalRL/TD algorithms: there is no back-chaining of information from a state to previous ones,each node policy is learned by using a complete local perspective. An obvious extensionof our work would therefore be to study versions of AntNet closer to TD( ) algorithms.357\nDi Caro & DorigoIn this case each node should maintain Q-values expressing the estimate of the distanceto each destination via each neighbor. These estimates should be updated by using boththe ant trip time outcome and the estimates coming from successive nodes (closer to thedestination node) that could be also carried by the backward ant.4) In this paper we applied AntNet to routing in datagram communications networks. Itis reasonable to think that AntNet could be easily adapted to be used for the generation ofreal-time car route guidance in Dynamic Tra c Assignment (DTA) systems (see for exampleYang, 1997). DTA systems exploit currently available and emerging computer, communi-cation, and vehicle sensing technologies to monitor, manage and control the transportationsystem (the attention is now focused mainly on highway systems) and to provide variouslevels of information and advice to system users so that they can make timely and informedtravel decisions. Therefore, adaptive routing of vehicle tra c presents very similar featuresto the routing of data packets in communications networks. Moreover, vehicle tra c controlsystems have the interesting property of a very simpli ed \\transport\" layer. In fact, manyactivities that interfere with routing and that are implemented in the transport layer ofcommunications networks do not exist, or exist only to a limited extent, in vehicles tra ccontrol algorithms. For example, typical transport layer activities like data acknowledge-ment and retransmission cannot be implemented with real vehicles. Other activities, like ow control, have strong constraints (e.g., people would not be happy to be forbidden toleave their o ces for, say, one hour on the grounds that there are already too many cars onthe streets!). This makes AntNet still more interesting since it can express its full potentialas a routing algorithm.5) In AntNet, whenever an ant uses a link its desirability (probability) is incremented.Although this strategy, which nds its roots in the ant colony biological metaphor thatinspired our work, allowed us to obtain excellent results, it would be interesting to investigatethe use of negative reinforcements, even if it can potentially lead to stability problems, asobserved by people working on older automata systems. As discussed before, AntNet di ersfrom automata systems because of the active role played by the ants. Therefore, the useof negative reinforcements could show itself to be e ective, for example, in reducing theprobability of choosing a given link if the ant that used it performed very badly.AcknowledgementsThis work was supported by a Madame Curie Fellowship awarded to Gianni Di Caro (CEC-TMR Contract N. ERBFMBICT 961153). Marco Dorigo is a Research Associate with theFNRS. We gratefully acknowledge the help received from Tony Bagnall, Nick Bradshaw andGeorge Smith, who proofread and commented an earlier draft of this paper, as well as themany useful comments provided by the three anonymous referees and by Craig Boutilier,the associate editor who managed the review process.Appendix A. Optimal and Shortest Path RoutingIn this appendix, the characteristics of the two most used routing paradigms, optimal andshortest path routing (introduced in Section 2.1) are summarized:358\nAntNet: Distributed Stigmergetic Control for Communications NetworksA.1 Optimal routingOptimal routing (Bertsekas & Gallager, 1992) has a network-wide perspective and its ob-jective is to optimize a function of all individual link ows.Optimal routing models are also called ow models because they try to optimize the totalmean ow on the network. They can be characterized as multicommodity ow problems,where the commodities are the tra c ows between the sources and the destinations, andthe cost to be optimized is a function of the ows, subject to the constraints of ow con-servation at each node and positive ow on every link. It is worth observing that the owconservation constraint can be explicitly stated only if the tra c arrival rate is known.The routing policy consists of splitting any source-target tra c pair at strategic points,then shifting tra c gradually among alternative routes. This often results in the use ofmultiple paths for a same tra c ow between an origin-destination pair.Implicit in optimal routing is the assumption that the main statistical characteristics of thetra c are known and not time-varying. Therefore, optimal routing can be used for staticand centralized/decentralized routing. It is evident that this kind of solution su ers all theproblems of static routers.A.2 Shortest path routingShortest path routing (Wang & Crowcroft, 1992) has a source-destination pair perspective.As opposed to optimal routing, there is no global cost function to be optimized. Instead,the route between each node pair is considered by itself and no a priori knowledge aboutthe tra c process is required (although of course such knowledge could be fruitfully used).If costs are assigned in a dynamic way, based on statistical measures of the link congestionstate, a strong feedback e ect is introduced between the routing policies and the tra cpatterns. This can lead to undesirable oscillations, as has been theoretically predicted andobserved in practice (Bertsekas & Gallager, 1992; Wang & Crowcroft, 1992). Some verypopular cost metrics take into account queuing and transmission delays, link usage, linkcapacity and various combination of these measures. The way costs are updated usuallyinvolves attempting to reduce big variations considering both long-term and short-termstatistics of link congestion states (Khanna & Zinky, 1989; Shankar, Alaettino glu, Dussa-Zieger, & Matta, 1992b).On the other hand, if the costs are static, they will re ect both some measure of theexpected/wished tra c load over the links and their transmission capacity. Of course,serious loss of e ciency could arise in case of non-stationary conditions or when the a prioriassumptions about the tra c patterns are strongly violated in practice.Considering the di erent content stored in each routing table, shortest path algorithms canbe further subdivided in two classes called distance-vector and link-state (Steenstrup, 1995;Shankar et al., 1992b). The common behavior of most shortest path algorithms can bedepicted as follows.1. Each node assigns a cost to each of its outgoing links. This cost can be static ordynamic. In the latter case, it is updated in presence of a link failure or on the basisof some observed link-tra c statistics averaged over a de ned time-window.359\nDi Caro & Dorigo2. Periodically and without a required inter-node synchronization, each node sends to allof its neighbors a packet of information describing its current estimates about somequantities (link costs, distance from all the other nodes, etc.).3. Each node, upon receiving the information packet, updates its local routing table andexecutes some class-speci c actions.4. Routing decisions can be made in a deterministic way, choosing the best path indicatedby the information stored in the routing table, or adopting a more exible strategywhich uses all the information stored in the table to choose some randomized oralternative path.In the following, the main features speci c to each class are described.A.2.1 Distance-vectorDistance-vector algorithms make use of routing tables consisting of a set of triples of theform (Destination, Estimated Distance, Next Hop), de ned for all the destinations in thenetwork and for all the neighbor nodes of the considered switch.17 In this case, the requiredtopological information is represented by the list of the reachable nodes identi ers. Theaverage per node memory occupation is of order O(Nn), where N is the number of nodes inthe network and n is the average connectivity degree (i.e., the average number of neighbornodes considered over all the nodes).The algorithm works in an iterative, asynchronous and distributed way. The informationthat every node sends to its neighbors is the list of its last estimates of the distances fromitself to all the other nodes in the network. After receiving this information from a neighbornode j, the receiving node i updates its table of distance estimates overwriting the entrycorresponding to node j with the received values.Routing decisions at node i are made choosing as next hop node the one satisfying therelationship: arg minj2Nifdij +Djgwhere dij is the assigned cost to the link connecting node i with its neighbor j and Dj isthe estimated shortest distance from node j to the destination.It can be shown that this process converges in nite time to the shortest paths withrespect to the used metric if no link cost changes after a given time (Bertsekas & Gallager,1992).The above brie y described algorithm is known in literature as distributedBellman-Ford (Bellman, 1958; Ford & Fulkerson, 1962; Bertsekas & Gallager, 1992) and itis based on the principles of dynamic programming (Bellman, 1957; Bertsekas, 1995). Itis the prototype and the ancestor of a wider class of distance-vector algorithms (Malkin& Steenstrup, 1995) developed with the aim of reducing the risk of circular loops and ofaccelerating the convergence in case of rapid changes in link costs.17. In some cases, only the best estimates are kept at nodes. Therefore, the above triples are de ned for allthe destinations only. 360\nAntNet: Distributed Stigmergetic Control for Communications NetworksA.2.2 Link-stateLink-state algorithms make use of routing tables containing much more information thanthat used in vector-distance algorithms. In fact, at the core of link-state algorithms there is adistributed and replicated database. This database is essentially a dynamic map of the wholenetwork, describing the details of all its components and their current interconnections.Using this database as input, each node calculates its best paths using an appropriatealgorithm like Dijkstra's (1959) algorithm (a wide variety of alternative e cient algorithmsare available, as described for example in Cherkassky, Goldberg, & Radzik, 1994). Thememory requirements for each node in this case are O(N2).In the most common form of link-state algorithm, each node acts autonomously, broad-casting information about its link costs and states and computing shortest paths from itselfto all the destinations on the basis of its local link costs estimates and of the estimatesreceived from other nodes. Each routing information packet is broadcast to all the neighbornodes that in turn send the packet to their neighbors and so on. A distributed oodingmechanism (Bertsekas & Gallager, 1992) supervises this information transmission trying tominimize the number of re-transmissions.As in the case of vector-distance, the described algorithm is a general template and avariety of di erent versions have been implemented to make the algorithm behavior morerobust and e cient (Moy, 1998).ReferencesAlaettino glu, C., Shankar, A. U., Dussa-Zieger, K., & Matta, I. (1992). Design and imple-mentation of MaRS: A routing testbed. Tech. rep. UMIACS-TR-92-103, CS-TR-2964,Institute for Advanced Computer Studies and Department of Computer Science, Uni-versity of Maryland, College Park (MD).Barto, A. G., Sutton, R. S., & Anderson, C. W. (1983). Neuronlike adaptive elements thatcan solve di cult learning control problems. IEEE Transaction on Systems, Man andCybernetics, SMC-13, 834{846.Beckers, R., Deneubourg, J. L., & Goss, S. (1992). Trails and U-turns in the selection of theshortest path by the ant Lasius Niger. Journal of Theoretical Biology, 159, 397{415.Bellman, R. (1957). Dynamic Programming. Princeton University Press.Bellman, R. (1958). On a routing problem. Quarterly of Applied Mathematics, 16 (1), 87{90.Bertsekas, D. (1995). Dynamic Programming and Optimal Control. Athena Scienti c.Bertsekas, D., & Gallager, R. (1992). Data Networks. Prentice-Hall.Bertsekas, D., & Tsitsiklis, J. (1996). Neuro-Dynamic Programming. Athena Scienti c.Bolding, K., Fulgham, M. L., & Snyder, L. (1994). The case for chaotic adaptive routing.Tech. rep. CSE-94-02-04, Department of Computer Science, University of Washington,Seattle. 361\nDi Caro & DorigoBonabeau, E., Dorigo, M., & Th eraulaz, G. (1999). From Natural to Arti cial SwarmIntelligence. Oxford University Press.Boyan, J., & Littman, M. (1994). Packet routing in dinamically changing networks: A rein-forcement learning approach. In Advances in Neural Information Processing Systems6 (NIPS6), pp. 671{678. San Francisco, CA:Morgan Kaufmann.Brakmo, L. S., O'Malley, S. W., & Peterson, L. L. (1994). TCP vegas: New techniques forcongestion detection and avoidance. ACM Computer Communication Review (SIG-COMM'94), 24 (4).Cheng, C., Riley, R., Kumar, S. P. R., & Garcia-Luna-Aceves, J. J. (1989). A loop-freeextended bellman-ford routing protocol without bouncing e ect. ACM ComputerCommunication Review (SIGCOMM '89), 18 (4), 224{236.Cherkassky, B. V., Goldberg, A. V., & Radzik, T. (1994). Shortest paths algorithms: Theoryand experimental evaluation. In Sleator, D. D. (Ed.), Proceedings of the 5th AnnualACM-SIAM Symposium on Discrete Algorithms (SODA 94), pp. 516{525 Arlington,VA. ACM Press.Choi, S., & Yeung, D.-Y. (1996). Predictive Q-routing: A memory-based reinforcementlearning approach to adaptive tra c control. In Advances in Neural InformationProcessing Systems 8 (NIPS8), pp. 945{951. MIT Press.Colorni, A., Dorigo, M., & Maniezzo, V. (1991). Distributed optimization by ant colonies.In Proceedings of the European Conference on Arti cial Life (ECAL 91), pp. 134{142.Elsevier.Costa, D., & Hertz, A. (1997). Ants can colour graphs. Journal of the Operational ResearchSociety, 48, 295{305.Crawley, E., Nair, R., Rajagopalan, B., & Sandick, H. (1996). A framework for QoS-basedrouting in the internet. Internet Draft (expired in September, 1997) draft-ietf-qosr-framework-00, Internet Engineering Task Force (IEFT).Danzig, P. B., Liu, Z., & Yan, L. (1994). An evaluation of TCP Vegas by live emulation.Tech. rep. UCS-CS-94-588, Computer Science Department, University of SouthernCalifornia, Los Angeles.Di Caro, G., & Dorigo, M. (1998). Two ant colony algorithms for best-e ort routingin datagram networks. In Proceedings of the Tenth IASTED International Confer-ence on Parallel and Distributed Computing and Systems (PDCS'98), pp. 541{546.IASTED/ACTA Press.Dijkstra, E. W. (1959). A note on two problems in connection with graphs. Numer. Math.,1, 269{271.Dorigo, M. (1992). Optimization, Learning and Natural Algorithms (in Italian). Ph.D.thesis, Dipartimento di Elettronica e Informazione, Politecnico di Milano, IT.362\nAntNet: Distributed Stigmergetic Control for Communications NetworksDorigo, M., Di Caro, G., & Gambardella, L. M. (1998). Ant algorithms for distributeddiscrete optimization. Tech. rep. 98-10, IRIDIA, Universit e Libre de Bruxelles. Sub-mitted to Arti cial Life.Dorigo, M., & Gambardella, L. M. (1997). Ant colony system: A cooperative learningapproach to the traveling salesman problem. IEEE Transactions on EvolutionaryComputation, 1 (1), 53{66.Dorigo, M., Maniezzo, V., & Colorni, A. (1991). Positive feedback as a search strategy.Tech. rep. 91-016, Dipartimento di Elettronica, Politecnico di Milano, IT.Dorigo, M., Maniezzo, V., & Colorni, A. (1996). The ant system: Optimization by a colonyof cooperating agents. IEEE Transactions on Systems, Man, and Cybernetics{PartB, 26 (1), 29{41.Ford, L., & Fulkerson, D. (1962). Flows in Networks. Prentice-Hall.Goss, S., Aron, S., Deneubourg, J. L., & Pasteels, J. M. (1989). Self-organized shortcuts inthe Argentine ant. Naturwissenschaften, 76, 579{581.Grass e, P. P. (1959). La reconstruction du nid et les coordinations interindividuelleschez bellicositermes natalensis et cubitermes sp. La th eorie de la stigmergie: essaid'interpr etation du comportement des termites constructeurs. Insectes Sociaux, 6,41{81.Gray, R., Kotz, D., Nog, S., Rus, D., & Cybenko, G. (1997). Mobile agents: The nextgeneration in distributed computing. In Proceedings of the Second Aizu InternationalSymposium on Parallel Algorithms/Architectures Synthesis (pAs '97), pp. 8{24. IEEEComputer Society Press.Jaakkola, T., Singh, S. P., & Jordan, M. I. (1995). Reinforcement learning algorithm forpartially observable Markov decision problems. In Advances in Neural InformationProcessing Systems 7, pp. 345{352. MIT Press.Kaelbling, L. P., Littman, M. L., & Moore, A. W. (1996). Reinforcement learning: A survey.Journal of Arti cial Intelligence Research, 4, 237{285.Khanna, A., & Zinky, J. (1989). The revised ARPANET routing metric. ACM SIGCOMMComputer Communication Review, 19 (4), 45{56.Malkin, G. S., & Steenstrup, M. E. (1995). Distance-vector routing. In Steenstrup, M. E.(Ed.), Routing in Communications Networks, chap. 3, pp. 83{98. Prentice-Hall.McCallum, A. K. (1995). Reinforcement learning with selective perception and hidden state.Ph.D. thesis, Department of Computer Science, University of Rochester, Rochester(NY).McQuillan, J. M., Richer, I., & Rosen, E. C. (1980). The new routing algorithm for theARPANET. IEEE Transactions on Communications, 28, 711{719.363\nDi Caro & DorigoMerlin, P., & Segall, A. (1979). A failsafe distributed routing protocol. IEEE Transactionson Communications, COM-27 (9), 1280{1287.Moy, J. T. (1998). OSPF Anatomy of an Internet Routing Protocol. Addison-Wesley.Narendra, K. S., & Thathachar, M. A. (1980). On the behavior of a learning automa-ton in a changing environment with application to telephone tra c routing. IEEETransactions on Systems, Man, and Cybernetics, SMC-10 (5), 262{269.Nedzelnitsky, O. V., & Narendra, K. S. (1987). Nonstationary models of learning automatarouting in data communication networks. IEEE Transactions on Systems, Man, andCybernetics, SMC-17, 1004{1015.Papoulis, A. (1991). Probability, Random Variables and Stochastic Process (Third edition).McGraw-Hill.Peterson, L. L., & Davie, B. (1996). Computer Networks: A System Approach. MorganKaufmann.Rubistein, R. Y. (1981). Simulation and the Monte Carlo Method. John Wiley & Sons.Sandick, H., & Crawley, E. (1997). QoS routing (qosr) working group report. InternetDraft, Internet Engineering Task Force (IEFT).Schoonderwoerd, R., Holland, O., & Bruten, J. (1997). Ant-like agents for load balancingin telecommunications networks. In Proceedings of the First International Conferenceon Autonomous Agents, pp. 209{216. ACM Press.Schoonderwoerd, R., Holland, O., Bruten, J., & Rothkrantz, L. (1996). Ant-based loadbalancing in telecommunications networks. Adaptive Behavior, 5 (2), 169{207.Shankar, A. U., Alaettino glu, C., Dussa-Zieger, K., & Matta, I. (1992a). Performancecomparison of routing protocols under dynamic and static le transfer connections.ACM Computer Communication Review, 22 (5), 39{52.Shankar, A. U., Alaettino glu, C., Dussa-Zieger, K., & Matta, I. (1992b). Transient andsteady-state performance of routing protocols: Distance-vector versus link-state. Tech.rep. UMIACS-TR-92-87, CS-TR-2940, Institute for Advanced Computer Studies andDepartment of Computer Science, University of Maryland, College Park (MD).Singh, S. P., & Sutton, R. S. (1996). Reinforcement learning with replacing eligibility traces.Machine Learning, 22, 123{158.Singh, S. P., Jaakkola, T., & Jordan, M. I. (1994). Learning without state estimationin partially observable Markovian decision processes. In Proceedings of the EleventhMachine Learning Conference, pp. 284{292. New Brunswick, NJ: Morgan Kaufmann.Steenstrup, M. E. (Ed.). (1995). Routing in Communications Networks. Prentice-Hall.Stone, P., & Veloso, M. M. (1996). Multiagent systems: A survey from a machine learningpersective. Tech. rep. CMU-CS-97-193, Carnegie Mellon University, Pittsburgh, PA.364\nAntNet: Distributed Stigmergetic Control for Communications NetworksStreltsov, S., & Vakili, P. (1996). Variance reduction algorithms for parallel replicatedsimulation of uniformized Markov chains. Discrete Event Dynamic Systems: Theoryand Applications, 6, 159{180.Subramanian, D., Druschel, P., & Chen, J. (1997). Ants and reinforcement learning: Acase study in routing in dynamic networks. In Proceedings of IJCAI-97, InternationalJoint Conference on Arti cial Intelligence, pp. 832{838. Morgan Kaufmann.The ATM Forum (1996). Private Network-Network Interface Speci cation: Version 1.0.Walrand, J., & Varaiya, P. (1996). High-performance Communication Networks. MorganKaufmann.Wang, Z., & Crowcroft, J. (1992). Analysis of shortest-path routing algorithms in a dynamicnetwork environment. ACM Computer Communication Review, 22 (2).Yang, Q. (1997). A Simulation Laboratory for Evaluation of Dynamic Tra c Manage-ment Systems. Ph.D. thesis, Department of Civil and Environmental Engineering,Massachusetts Institute of Technology (MIT).\n365"
    } ],
    "references" : [ {
      "title" : "Neuronlike adaptive elements",
      "author" : [ "A.G. Barto", "R.S. Sutton", "C.W. Anderson" ],
      "venue" : null,
      "citeRegEx" : "Barto et al\\.,? \\Q1983\\E",
      "shortCiteRegEx" : "Barto et al\\.",
      "year" : 1983
    }, {
      "title" : "Trails and U-turns in the selection",
      "author" : [ "R. Beckers", "J.L. Deneubourg", "S. Goss" ],
      "venue" : null,
      "citeRegEx" : "Beckers et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Beckers et al\\.",
      "year" : 1992
    }, {
      "title" : "Dynamic Programming",
      "author" : [ "R. Bellman" ],
      "venue" : null,
      "citeRegEx" : "Bellman,? \\Q1957\\E",
      "shortCiteRegEx" : "Bellman",
      "year" : 1957
    }, {
      "title" : "On a routing problem",
      "author" : [ "R. Bellman" ],
      "venue" : "Quarterly of Applied Mathematics,",
      "citeRegEx" : "Bellman,? \\Q1958\\E",
      "shortCiteRegEx" : "Bellman",
      "year" : 1958
    }, {
      "title" : "Dynamic Programming and Optimal Control",
      "author" : [ "D. Bertsekas" ],
      "venue" : "Athena Scienti c",
      "citeRegEx" : "Bertsekas,? \\Q1995\\E",
      "shortCiteRegEx" : "Bertsekas",
      "year" : 1995
    }, {
      "title" : "The case for chaotic adaptive routing",
      "author" : [ "K. Bolding", "M.L. Fulgham", "L. Snyder" ],
      "venue" : null,
      "citeRegEx" : "Bolding et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Bolding et al\\.",
      "year" : 1994
    }, {
      "title" : "Packet routing in dinamically changing networks: A rein",
      "author" : [ "J. Boyan", "M. Littman" ],
      "venue" : null,
      "citeRegEx" : "Boyan and Littman,? \\Q1994\\E",
      "shortCiteRegEx" : "Boyan and Littman",
      "year" : 1994
    }, {
      "title" : "TCP vegas: New techniques",
      "author" : [ "L.S. Brakmo", "S.W. O'Malley", "L.L. Peterson" ],
      "venue" : null,
      "citeRegEx" : "Brakmo et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Brakmo et al\\.",
      "year" : 1994
    }, {
      "title" : "Shortest paths algorithms: Theory",
      "author" : [ "B.V. Cherkassky", "A.V. Goldberg", "T. Radzik" ],
      "venue" : null,
      "citeRegEx" : "Cherkassky et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Cherkassky et al\\.",
      "year" : 1994
    }, {
      "title" : "Predictive Q-routing: A memory-based reinforcement",
      "author" : [ "S. Choi", "Yeung", "D.-Y" ],
      "venue" : null,
      "citeRegEx" : "Choi et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 1996
    }, {
      "title" : "Distributed optimization by ant colonies",
      "author" : [ "A. Colorni", "M. Dorigo", "V. Maniezzo" ],
      "venue" : null,
      "citeRegEx" : "Colorni et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Colorni et al\\.",
      "year" : 1991
    }, {
      "title" : "Ants can colour graphs",
      "author" : [ "D. Costa", "A. Hertz" ],
      "venue" : "Journal of the Operational Research",
      "citeRegEx" : "Costa and Hertz,? \\Q1997\\E",
      "shortCiteRegEx" : "Costa and Hertz",
      "year" : 1997
    }, {
      "title" : "A framework for QoS-based",
      "author" : [ "E. Crawley", "R. Nair", "B. Rajagopalan", "H. Sandick" ],
      "venue" : null,
      "citeRegEx" : "Crawley et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Crawley et al\\.",
      "year" : 1996
    }, {
      "title" : "An evaluation of TCP Vegas by live emulation",
      "author" : [ "P.B. Danzig", "Z. Liu", "L. Yan" ],
      "venue" : null,
      "citeRegEx" : "Danzig et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Danzig et al\\.",
      "year" : 1994
    }, {
      "title" : "Two ant colony algorithms for best-e ort routing",
      "author" : [ "G. Di Caro", "M. Dorigo" ],
      "venue" : null,
      "citeRegEx" : "Caro and Dorigo,? \\Q1998\\E",
      "shortCiteRegEx" : "Caro and Dorigo",
      "year" : 1998
    }, {
      "title" : "A note on two problems in connection with graphs",
      "author" : [ "E.W. Dijkstra" ],
      "venue" : null,
      "citeRegEx" : "Dijkstra,? \\Q1959\\E",
      "shortCiteRegEx" : "Dijkstra",
      "year" : 1959
    }, {
      "title" : "Optimization, Learning and Natural Algorithms (in Italian)",
      "author" : [ "M. Dorigo" ],
      "venue" : null,
      "citeRegEx" : "Dorigo,? \\Q1992\\E",
      "shortCiteRegEx" : "Dorigo",
      "year" : 1992
    }, {
      "title" : "Ant algorithms for distributed",
      "author" : [ "M. Dorigo", "G. Di Caro", "L.M. Gambardella" ],
      "venue" : null,
      "citeRegEx" : "Dorigo et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Dorigo et al\\.",
      "year" : 1998
    }, {
      "title" : "Ant colony system: A cooperative learning",
      "author" : [ "M. Dorigo", "L.M. Gambardella" ],
      "venue" : null,
      "citeRegEx" : "Dorigo and Gambardella,? \\Q1997\\E",
      "shortCiteRegEx" : "Dorigo and Gambardella",
      "year" : 1997
    }, {
      "title" : "Positive feedback as a search strategy",
      "author" : [ "M. Dorigo", "V. Maniezzo", "A. Colorni" ],
      "venue" : null,
      "citeRegEx" : "Dorigo et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Dorigo et al\\.",
      "year" : 1991
    }, {
      "title" : "The ant system: Optimization by a colony",
      "author" : [ "M. Dorigo", "V. Maniezzo", "A. Colorni" ],
      "venue" : null,
      "citeRegEx" : "Dorigo et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Dorigo et al\\.",
      "year" : 1996
    }, {
      "title" : "Self-organized shortcuts",
      "author" : [ "S. Goss", "S. Aron", "J.L. Deneubourg", "J.M. Pasteels" ],
      "venue" : null,
      "citeRegEx" : "Goss et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Goss et al\\.",
      "year" : 1989
    }, {
      "title" : "La reconstruction du nid et les coordinations interindividuelles",
      "author" : [ "P.P. e" ],
      "venue" : null,
      "citeRegEx" : "e,? \\Q1959\\E",
      "shortCiteRegEx" : "e",
      "year" : 1959
    }, {
      "title" : "Reinforcement learning algorithm",
      "author" : [ "T. Jaakkola", "S.P. Singh", "M.I. Jordan" ],
      "venue" : null,
      "citeRegEx" : "Jaakkola et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Jaakkola et al\\.",
      "year" : 1995
    }, {
      "title" : "Reinforcement learning: A survey",
      "author" : [ "L.P. Kaelbling", "M.L. Littman", "A.W. Moore" ],
      "venue" : null,
      "citeRegEx" : "Kaelbling et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Kaelbling et al\\.",
      "year" : 1996
    }, {
      "title" : "The revised ARPANET routing metric",
      "author" : [ "A. Khanna", "J. Zinky" ],
      "venue" : null,
      "citeRegEx" : "Khanna and Zinky,? \\Q1989\\E",
      "shortCiteRegEx" : "Khanna and Zinky",
      "year" : 1989
    }, {
      "title" : "Reinforcement learning with selective perception and hidden state",
      "author" : [ "A.K. McCallum" ],
      "venue" : null,
      "citeRegEx" : "McCallum,? \\Q1995\\E",
      "shortCiteRegEx" : "McCallum",
      "year" : 1995
    }, {
      "title" : "The new routing algorithm",
      "author" : [ "J.M. McQuillan", "I. Richer", "E.C. Rosen" ],
      "venue" : null,
      "citeRegEx" : "McQuillan et al\\.,? \\Q1980\\E",
      "shortCiteRegEx" : "McQuillan et al\\.",
      "year" : 1980
    }, {
      "title" : "A failsafe distributed routing protocol",
      "author" : [ "P. Merlin", "A. Segall" ],
      "venue" : "IEEE Transactions",
      "citeRegEx" : "Merlin and Segall,? \\Q1979\\E",
      "shortCiteRegEx" : "Merlin and Segall",
      "year" : 1979
    }, {
      "title" : "OSPF Anatomy of an Internet Routing Protocol",
      "author" : [ "J.T. Moy" ],
      "venue" : null,
      "citeRegEx" : "Moy,? \\Q1998\\E",
      "shortCiteRegEx" : "Moy",
      "year" : 1998
    }, {
      "title" : "On the behavior of a learning",
      "author" : [ "K.S. Narendra", "M.A. Thathachar" ],
      "venue" : null,
      "citeRegEx" : "Narendra and Thathachar,? \\Q1980\\E",
      "shortCiteRegEx" : "Narendra and Thathachar",
      "year" : 1980
    }, {
      "title" : "Nonstationary models of learning automata",
      "author" : [ "O.V. Nedzelnitsky", "K.S. Narendra" ],
      "venue" : null,
      "citeRegEx" : "Nedzelnitsky and Narendra,? \\Q1987\\E",
      "shortCiteRegEx" : "Nedzelnitsky and Narendra",
      "year" : 1987
    }, {
      "title" : "Probability, Random Variables and Stochastic Process (Third edition)",
      "author" : [ "A. Papoulis" ],
      "venue" : null,
      "citeRegEx" : "Papoulis,? \\Q1991\\E",
      "shortCiteRegEx" : "Papoulis",
      "year" : 1991
    }, {
      "title" : "Computer Networks: A System",
      "author" : [ "L.L. Peterson", "B. Davie" ],
      "venue" : null,
      "citeRegEx" : "Peterson and Davie,? \\Q1996\\E",
      "shortCiteRegEx" : "Peterson and Davie",
      "year" : 1996
    }, {
      "title" : "Simulation and the Monte Carlo Method",
      "author" : [ "R.Y. Rubistein" ],
      "venue" : null,
      "citeRegEx" : "Rubistein,? \\Q1981\\E",
      "shortCiteRegEx" : "Rubistein",
      "year" : 1981
    }, {
      "title" : "QoS routing (qosr) working group report",
      "author" : [ "H. Sandick", "E. Crawley" ],
      "venue" : null,
      "citeRegEx" : "Sandick and Crawley,? \\Q1997\\E",
      "shortCiteRegEx" : "Sandick and Crawley",
      "year" : 1997
    }, {
      "title" : "Ant-like agents for load balancing",
      "author" : [ "R. Schoonderwoerd", "O. Holland", "J. Bruten" ],
      "venue" : null,
      "citeRegEx" : "Schoonderwoerd et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Schoonderwoerd et al\\.",
      "year" : 1997
    }, {
      "title" : "Reinforcement learning with replacing eligibility",
      "author" : [ "S.P. Singh", "R.S. Sutton" ],
      "venue" : null,
      "citeRegEx" : "Singh and Sutton,? \\Q1996\\E",
      "shortCiteRegEx" : "Singh and Sutton",
      "year" : 1996
    }, {
      "title" : "Learning without state estimation",
      "author" : [ "S.P. Singh", "T. Jaakkola", "M.I. Jordan" ],
      "venue" : null,
      "citeRegEx" : "Singh et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Singh et al\\.",
      "year" : 1994
    }, {
      "title" : "Multiagent systems: A survey from a machine learning",
      "author" : [ "P. Stone", "M.M. Veloso" ],
      "venue" : null,
      "citeRegEx" : "Stone and Veloso,? \\Q1996\\E",
      "shortCiteRegEx" : "Stone and Veloso",
      "year" : 1996
    }, {
      "title" : "Variance reduction algorithms for parallel replicated",
      "author" : [ "S. Streltsov", "P. Vakili" ],
      "venue" : null,
      "citeRegEx" : "Streltsov and Vakili,? \\Q1996\\E",
      "shortCiteRegEx" : "Streltsov and Vakili",
      "year" : 1996
    }, {
      "title" : "Ants and reinforcement learning: A",
      "author" : [ "D. Subramanian", "P. Druschel", "J. Chen" ],
      "venue" : null,
      "citeRegEx" : "Subramanian et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Subramanian et al\\.",
      "year" : 1997
    }, {
      "title" : "High-performance Communication Networks",
      "author" : [ "J. Walrand", "P. Varaiya" ],
      "venue" : null,
      "citeRegEx" : "Walrand and Varaiya,? \\Q1996\\E",
      "shortCiteRegEx" : "Walrand and Varaiya",
      "year" : 1996
    }, {
      "title" : "Analysis of shortest-path routing algorithms in a dynamic",
      "author" : [ "Z. Wang", "J. Crowcroft" ],
      "venue" : null,
      "citeRegEx" : "Wang and Crowcroft,? \\Q1992\\E",
      "shortCiteRegEx" : "Wang and Crowcroft",
      "year" : 1992
    }, {
      "title" : "A Simulation Laboratory for Evaluation of Dynamic Tra c Manage",
      "author" : [ "Q. Yang" ],
      "venue" : null,
      "citeRegEx" : "Yang,? \\Q1997\\E",
      "shortCiteRegEx" : "Yang",
      "year" : 1997
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "Journal of Arti cial Intelligence Research 9 (1998) 317-365 Submitted 5/98; published 12/98 AntNet: Distributed Stigmergetic Control for Communications Networks Gianni Di Caro gdicaro@iridia.",
      "startOffset" : 24,
      "endOffset" : 52
    }, {
      "referenceID" : 16,
      "context" : "Algorithms that take inspiration from real ants' behavior in nding shortest paths (Goss, Aron, Deneubourg, & Pasteels, 1989; Beckers, Deneubourg, & Goss, 1992) using as information only the trail of a chemical substance (called pheromone) deposited by other ants, have recently been successfully applied to several discrete optimization problems (Dorigo, Maniezzo, & Colorni, 1991; Dorigo, 1992; Dorigo, Maniezzo, & Colorni, 1996; Dorigo & Gambardella, 1997; Schoonderwoerd, Holland, Bruten, & Rothkrantz, 1996; Schoonderwoerd, Holland, & Bruten, 1997; Costa & Hertz, 1997).",
      "startOffset" : 346,
      "endOffset" : 573
    }, {
      "referenceID" : 26,
      "context" : "It is interesting to note that the above characteristics make the problem of routing belong to the class of reinforcement learning problems with hidden state (Bertsekas & Tsitsiklis, 1996; Kaelbling, Littman, & Moore, 1996; McCallum, 1995).",
      "startOffset" : 158,
      "endOffset" : 239
    }, {
      "referenceID" : 4,
      "context" : "Citing Bertsekas and Gallager (1992), page 367: \\the e ect of good routing is to increase throughput for the same value of average delay per packet under high o ered load conditions and to decrease average delay per packet under low and moderate o ered load conditions\".",
      "startOffset" : 7,
      "endOffset" : 37
    }, {
      "referenceID" : 29,
      "context" : "A hierarchical structure is adopted on the Internet, organized in hierarchical Autonomous Systems and multiple routing areas inside each Autonomous System (Moy, 1998).",
      "startOffset" : 155,
      "endOffset" : 166
    }, {
      "referenceID" : 19,
      "context" : "AntNet takes inspiration from previous work on arti cial ant colonies techniques to solve combinatorial optimization problems (Dorigo et al., 1991; Dorigo, 1992; Dorigo et al., 1996; Dorigo & Gambardella, 1997) and telephone network routing (Schoonderwoerd et al.",
      "startOffset" : 126,
      "endOffset" : 210
    }, {
      "referenceID" : 16,
      "context" : "AntNet takes inspiration from previous work on arti cial ant colonies techniques to solve combinatorial optimization problems (Dorigo et al., 1991; Dorigo, 1992; Dorigo et al., 1996; Dorigo & Gambardella, 1997) and telephone network routing (Schoonderwoerd et al.",
      "startOffset" : 126,
      "endOffset" : 210
    }, {
      "referenceID" : 20,
      "context" : "AntNet takes inspiration from previous work on arti cial ant colonies techniques to solve combinatorial optimization problems (Dorigo et al., 1991; Dorigo, 1992; Dorigo et al., 1996; Dorigo & Gambardella, 1997) and telephone network routing (Schoonderwoerd et al.",
      "startOffset" : 126,
      "endOffset" : 210
    }, {
      "referenceID" : 24,
      "context" : "This gives rise to a credit assignment problem typical of the reinforcement learning eld (Bertsekas & Tsitsiklis, 1996; Kaelbling et al., 1996).",
      "startOffset" : 89,
      "endOffset" : 143
    }, {
      "referenceID" : 21,
      "context" : "In this case, the core of the algorithm is based on the capability of \\real\" ants to discover shortest paths communicating by means of pheromone trails (Goss et al., 1989; Beckers et al., 1992).",
      "startOffset" : 152,
      "endOffset" : 193
    }, {
      "referenceID" : 1,
      "context" : "In this case, the core of the algorithm is based on the capability of \\real\" ants to discover shortest paths communicating by means of pheromone trails (Goss et al., 1989; Beckers et al., 1992).",
      "startOffset" : 152,
      "endOffset" : 193
    }, {
      "referenceID" : 32,
      "context" : "The expression is obtained by using the Tchebyche inequality that allows the de nition of a con dence interval for a random variable following any distribution (Papoulis, 1991) Usually, for speci c probability densities the Tchebyche bound is too high, but here we can conveniently use it because (i) we want to avoid to make assumptions on the distribution of and, (ii) we need only a raw estimate of the con dence interval.",
      "startOffset" : 160,
      "endOffset" : 176
    }, {
      "referenceID" : 29,
      "context" : "OSPF (static, link state): is our implementation of the current Interior Gateway Protocol (IGP) of Internet (Moy, 1998).",
      "startOffset" : 108,
      "endOffset" : 119
    }, {
      "referenceID" : 2,
      "context" : "BF (adaptive, distance-vector): is an implementation of the asynchronous distributed Bellman-Ford algorithm with dynamic metrics (Bertsekas & Gallager, 1992; Shankar et al., 1992a). The algorithm has been implemented following the guidelines of Appendix A, while link costs are assigned in the same way as described for SPF above. Vector-distance Bellman-Ford-like algorithms are today in use mainly for intra-domain routing, because they are used in the Routing Information Protocol (RIP) (Malkin & Steenstrup, 1995) supplied with the BSD version of Unix. Several enhanced versions of the basic adaptive Bellman-Ford algorithm can be found in the literature (for example the Merlin-Segall (Merlin & Segall, 1979) and the Extended Bellman-Ford (Cheng, Riley, Kumar, & Garcia-Luna-Aceves, 1989) algorithms). They focus mainly on reducing the information dissemination time in case of link failures. When link failures are not a major issue, as in this paper, their behavior is in general equivalent to that of the basic adaptive Bellman-Ford. Q-R (adaptive, distance-vector): is the Q-Routing algorithm as proposed by Boyan and Littman (1994). This is an online asynchronous version of the Bellman-Ford algorithm.",
      "startOffset" : 85,
      "endOffset" : 1142
    }, {
      "referenceID" : 16,
      "context" : "Di Caro & Dorigo paths on the basis of a network-wide shortest paths re-calculation for every packet hop. Links costs used in shortest paths calculations are the following: Cl = dl + Sp bl + (1 )SQ(l) bl + SQ(l) bl ; where dl is the transmission delay for link l, bl is its bandwidth, Sp is the size (in bits) of the data packet doing the hop, SQ(l) is the size (in bits) of the queue of link l, SQ(l) is the exponential mean of the size of links queue and it is a correction to the actual size of the link queue on the basis of what observed until that moment. This correction is weighted by the value set to 0.4. Of course, given the arbitrariness we introduced in calculating Cl, it could be possible to de ne an even better Daemon algorithm. 6. Experimental Settings The functioning of a communication network is governed by many components, which may interact in nonlinear and unpredictable ways. Therefore, the choice of a meaningful testbed to compare competing algorithms is no easy task. A limited set of classes of tunable components is de ned and for each class our choices are explained. 6.1 Topology and physical properties of the net Topology can be de ned on the basis of a real net instance or it can de ned by hand, to better analyze the in uence of important topological features (like diameter, connectivity, etc.). Nodes are mainly characterized by their bu ering and processing capacity, whereas links are characterized by their propagation delay, bandwidth and streams multiplexing scheme. For both, fault probability distributions should be de ned. In our experiments, we used three signi cant net instances with increasing numbers of nodes. For all of them we describe the main characteristics and we summarize the topological properties by means of a triple of numbers ( , , N) indicating respectively the mean shortest path distance, in terms of hops, between all pairs of nodes, the variance of this average, and the total number of nodes. From these three numbers we can get an idea about the degree of connectivity and balancing of the network. The di culty of the routing problem roughly increases with the value of these numbers. SimpleNet (1.9, 0.7, 8) is a small network speci cally designed to study some aspects of the behavior of the algorithms we compare. Experiments with SimpleNet were designed to closely study how the di erent algorithms manage to distribute the load on the di erent possible paths. SimpleNet is composed of 8 nodes and 9 bi-directional links with a bandwidth of 10 Mbit/s and propagation delay of 1 msec. The topology is shown in Figure 5. NSFNET (2.2, 0.8, 14) is the old USA T1 backbone (1987). NSFNET is a WAN composed of 14 nodes and 21 bi-directional links with a bandwidth of 1.",
      "startOffset" : 10,
      "endOffset" : 2655
    }, {
      "referenceID" : 34,
      "context" : "1 AntNet as an on-line Monte Carlo system with biased exploration The AntNet routing system can be seen as a collection of mobile agents collecting data about the network status by concurrently performing on-line Monte Carlo simulations (Rubistein, 1981; Streltsov & Vakili, 1996).",
      "startOffset" : 237,
      "endOffset" : 280
    }, {
      "referenceID" : 16,
      "context" : "Di Caro & Dorigo maintained at the node. The T updates are carried out in an asynchronous way and as a function of their previous values. Moreover, while T is used in a straightforward probabilistic way by the data packets, traveling ants select the next node by using both T , that is, an adaptive representation of the past policy, and a model of the current local link queues, that is, an instantaneous representation of the node status. It is evident that AntNet builds and uses more information than its competitors: two di erent memory-based components and an instantaneous predictor are used and combined at di erent levels. Moreover, in this way AntNet robustly redistributes among these completely local components the criticality of all the estimates and decisions. 8.3 AntNet's robustness to wrong estimates As remarked above, AntNet, di erently from its competitors, does not propagate local estimates to other nodes. Each node routing table is updated independently, by using local information and the ants' experienced trip time. Moreover, (i) each ant experiment a ects only one entry in the routing table of the visited nodes, the one relative to the ant's destination, and, (ii) the local information is built from the \\global\" information collected by traveling ants, implicitly reducing in this way the variance in the estimates. These characteristics make AntNet particularly robust to wrong estimates. On the contrary, in all the other algorithms a locally wrong estimate will be propagated to all other nodes and will be used to compute estimates to many di erent destinations. How bad this is for the algorithm performance depends on how long the wrong estimate e ect lasts. In particular, this will be a function of the time window over which estimates are computed for SPF and BF, and of the learning parameters for Q-R and PQ-R. 8.4 AntNet's probabilistic use of routing tables to route data packets All the tested algorithms but AntNet use deterministic routing tables.15 In these algorithms, entries in the routing tables contain distance/time estimates to the destinations. These estimates can provide misleading information if the algorithm is not fast enough to follow the tra c uctuations, as can be the case under heavy load conditions. Instead, AntNet routing tables have probabilistic entries that, although re ecting the goodness of a particular path choice with respect to the others available, do not force the data packets to choose the perceived best path. This has the positive e ect of allowing a better balancing of the tra c load on di erent paths, with a resulting better utilization of the resources (as was shown in particular in the experiments with the SimpleNet). As remarked at the end of Section 4.1, the intrinsic probabilistic structure of the routing tables and the way they are updated allow AntNet to exploit the ant's arrival rate as a way to assign implicit (cumulative) reinforcements to discovered paths. It is not obvious how the same e ect could be obtained by using routing tables containing distance/time estimates and using this estimates in a probabilistic way. In fact, in this case each new trip time sample would 15. Singh, Jaakkola, and Jordan (1994) showed that stochastic policies can yield higher performance than deterministic policies in the case of an incomplete access to the state information of the environment.",
      "startOffset" : 10,
      "endOffset" : 3222
    }, {
      "referenceID" : 16,
      "context" : "Di Caro & Dorigo veloped, are problems where, unlike routing, assumptions like Markovianity or stationarity of the process considered are satis ed. The characteristics of the adaptive routing problem make it very di cult and not well suited to be solved with usual RL algorithms. This fact, as we explain below, determines a departure of AntNet from classical RL algorithms. A rst way to relate the structure of AntNet to that of a (general) RL algorithm is connected to the way the outcomes of the experiments, the trip times Tk!d, are processed. The transformation from the raw values Tk!d to the more re ned reinforcements r are reminiscent of what happens in Actor-Critic systems (Barto, Sutton, & Anderson, 1983): the raw reinforcement signal is processed by a critic module, which is learning a model (the node's componentM) of the underlying process, and then is fed to the learning system (the routing table T ) transformed into an evaluation of the policy followed by the ants. In our case, the critic is both adaptive, to take into account the variability of the tra c process, and rather simple, to meet computational requirements. Another way of seeing AntNet as a classical RL system is related to its interpretation as a parallel replicated Monte Carlo (MC) system. As was shown by Singh and Sutton (1996), a rst-visit MC (only the rst visit to a state is used to estimate its value during a trial) simulation system is equivalent to a batch temporal di erence (TD) method with replacing traces and decay parameter =1.",
      "startOffset" : 10,
      "endOffset" : 1320
    }, {
      "referenceID" : 1,
      "context" : "Related Work Algorithms based on the ant colony metaphor were inspired by the ant colony foraging behavior (Beckers et al., 1992).",
      "startOffset" : 107,
      "endOffset" : 129
    }, {
      "referenceID" : 16,
      "context" : "When in node i an ant chooses the next node j to move to among those not visited yet with a probability Pij that is a function of the amount of pheromone trail on the edge connecting i to j (as well as of a local heuristic function; the interested reader can nd a detailed description of ant-cycle elsewhere (Dorigo, 1992; Dorigo et al., 1996)).",
      "startOffset" : 308,
      "endOffset" : 343
    }, {
      "referenceID" : 20,
      "context" : "When in node i an ant chooses the next node j to move to among those not visited yet with a probability Pij that is a function of the amount of pheromone trail on the edge connecting i to j (as well as of a local heuristic function; the interested reader can nd a detailed description of ant-cycle elsewhere (Dorigo, 1992; Dorigo et al., 1996)).",
      "startOffset" : 308,
      "endOffset" : 343
    }, {
      "referenceID" : 1,
      "context" : "Related Work Algorithms based on the ant colony metaphor were inspired by the ant colony foraging behavior (Beckers et al., 1992). These were rst proposed by Dorigo (1992), Colorni et al.",
      "startOffset" : 108,
      "endOffset" : 172
    }, {
      "referenceID" : 1,
      "context" : "Related Work Algorithms based on the ant colony metaphor were inspired by the ant colony foraging behavior (Beckers et al., 1992). These were rst proposed by Dorigo (1992), Colorni et al. (1991) and Dorigo et al.",
      "startOffset" : 108,
      "endOffset" : 195
    }, {
      "referenceID" : 19,
      "context" : "This choice, which is reminiscent of the pheromone trail updating strategy implemented in ant-density, another of the rst ant colony based algorithms (Dorigo et al., 1991; Dorigo, 1992; Colorni et al., 1991), makes ABC behavior closer to real ants', and was made possible by the cost-symmetry assumption made by the authors.",
      "startOffset" : 150,
      "endOffset" : 207
    }, {
      "referenceID" : 16,
      "context" : "This choice, which is reminiscent of the pheromone trail updating strategy implemented in ant-density, another of the rst ant colony based algorithms (Dorigo et al., 1991; Dorigo, 1992; Colorni et al., 1991), makes ABC behavior closer to real ants', and was made possible by the cost-symmetry assumption made by the authors.",
      "startOffset" : 150,
      "endOffset" : 207
    }, {
      "referenceID" : 10,
      "context" : "This choice, which is reminiscent of the pheromone trail updating strategy implemented in ant-density, another of the rst ant colony based algorithms (Dorigo et al., 1991; Dorigo, 1992; Colorni et al., 1991), makes ABC behavior closer to real ants', and was made possible by the cost-symmetry assumption made by the authors.",
      "startOffset" : 150,
      "endOffset" : 207
    }, {
      "referenceID" : 15,
      "context" : "Di Caro & Dorigo same level of congestion in both directions because the congestion depends only on the state of the nodes in the path. Moreover, dealing with telephone networks, each call occupies Link 4 N bidirectional channels Link 1 Link 3 n << N possible connections Link 2 Figure 18: Network node in the telecommunications network model of Schoonderwoerd et al. (1996). exactly one physical channel across the path.",
      "startOffset" : 10,
      "endOffset" : 375
    }, {
      "referenceID" : 10,
      "context" : ", 1991; Dorigo, 1992; Colorni et al., 1991), makes ABC behavior closer to real ants', and was made possible by the cost-symmetry assumption made by the authors. Other di erences are that ABC does not use local models to score the ants trip times, nor local heuristic information and ant-private memory to improve the ants decision policies. Also, it does not recover from cycles and does not use the information contained in all the ant sub-paths. Because of the di erent network model used and of the many implementation details tightly bound to the network model, it was impossible for us to re-implement and compare the ABC algorithm with AntNet. Subramanian, Druschel, and Chen (1997) have proposed an ant-based algorithm for packet-switched nets.",
      "startOffset" : 22,
      "endOffset" : 689
    } ],
    "year" : 2011,
    "abstractText" : null,
    "creator" : "dvipsk 5.58f Copyright 1986, 1994 Radical Eye Software"
  }
}