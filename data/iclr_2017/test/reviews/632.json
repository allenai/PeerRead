{"conference": "ICLR 2017 conference submission", "title": "Gaussian Attention Model and Its Application to Knowledge Base Embedding and Question Answering", "abstract": "We propose the Gaussian attention model for content-based neural memory access. With the proposed attention model, a neural network has the additional degree of freedom to control the focus of its attention from a laser sharp attention to a broad attention. It is applicable whenever we can assume that the distance in the latent space reflects some notion of semantics. We use the proposed attention model as a scoring function for the embedding of a knowledge base into a continuous vector space and then train a model that performs question answering about the entities in the knowledge base. The proposed attention model can handle both the propagation of uncertainty when following a series of relations and also the conjunction of conditions in a natural way. On a dataset of soccer players who participated in the FIFA World Cup 2014, we demonstrate that our model can handle both path queries and conjunctive queries well.", "reviews": [{"is_meta_review": true, "comments": "SUMMARY.\n\nThe paper propose a new scoring function for knowledge base embedding.\nThe scoring function called TransGaussian is an novel take on (or a generalization of) the well-known TransE scoring function.\nThe proposed function is tested on two tasks knowledge-base completion and question answering.\n\n----------\n\nOVERALL JUDGMENT\nWhile I think this proposed work is very interesting and it is an idea worth to explore further, the presentation and the experimental section of the paper have some problems.\nRegarding the presentation, as far as I understand this is not an attention model as intended standardly in the literature.\nPlus, it has hardly anything to share with memory networks/neural Turing machines, the parallel that the authors try to make is not very convincing.\nRegarding the experimental section, for a fair comparison the authors should test their model on standard benchmarks, reporting state-of-the-art models.\nFinally, the paper lack of discussion of results and insights on the behavior of the proposed model.\n\n\n----------\n\nDETAILED COMMENTS\n\n\nIn section 2.2 when the authors calculate \\mu_{context} do not they loose the order of relations? And if it is so, does it make any sense?", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "Three knowledgable reviewers recommend rejection. While they agree that the paper has interesting aspects, they suggest a more convincing evaluation. The authors did not address some of the reviewer's concerns. The AC strongly encourages the authors to improve their paper and resubmit it to a future conference.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "review", "is_meta_review": false, "comments": "The contribution of this paper can be summarized as:\n\n1, A TransGaussian model (in a similar idea of TransE) which models the subject / object embeddings in a parameterization of Gaussian distribution.  The model can be naturally adapted to path queries like the formulation of (Guu et al, 2015).\n2. Along with the entity / relation representations trained by TransGaussian, an LSTM + attention model is built on natural language questions, aiming at learning a distribution (not normalized though) over relations for question answering.\n3. Experiments on a generated WorldCup2014 dataset, focusing on path queries and conjunctive queries.\n\nOverall, I think the Gaussian parameterization exhibits some nice properties, and could be suitable to KB completion and question answering. However, some details and the main experimental results are not convincing enough to me.  The paper writing also needs to be improved. More comments below:\n\n[Major comments]\n\n- My main concern is that that evaluation results are NOT strong. Either knowledge base completion or KB-based question answering, there are many existing and competitive benchmarks (e.g., FB15k / WebQuestions). Experimenting with such a tiny WordCup2014 dataset is not convincing.  Moreover, the questions are just generated by a few templates, which is far from NL questions. I am not even not sure why we need to apply an LSTM in such scenario. The paper would be much stronger if you can demonstrate its effectiveness on the above benchmarks. \n\n- Conjunctive queries:  the current model assumes that all the detected entities in the question could be aligned to one or more relations and we can take conjunctions in the end. This assumption might be not always correct, so it is more necessary to justify this on real QA datasets.\n\n- The model is named as  \u201cGaussian attention\u201d and I kind of think it is not very closely related to well-known attention mechanism, but more related to KB embedding literature.\n\n[Minor comments]\n- I find Figure 2 a bit confusing. The first row of orange blocks denote KB relations, and the second row of those denote every single word of the NL question. Maybe make it clearer?\n\n- Besides \u201centity recognition\u201d, usually we still need an \u201centity linker\u201d component which links the text mention to the KB entity. \n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "21 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Review", "is_meta_review": false, "comments": "This paper presents extensions to previous work using embeddings for modeling Knowledge Bases and performing Q&A on them, centered around the use of multivariate gaussian likelihood instead of inner products to score attention. This is supposed to allow more control on the attention by dealing with its spread.\n\nThis is a dense paper centered around a quite complicated model. With the supplementary material, this makes a 16p paper. It might be clearer to make 2 separate papers: one on KB completion and another one on Q&A.\n\nI like the idea of controlling the spread of the attention. This makes sense. However, I do not feel that this paper is convincing enough to justify its use compared to usual inner products.\n\nFor several reasons:\n- These should be more ablation experiments to separate the different pieces of the model and study their influence separately. The only interesting point in that sense is Table 8 in Appendix B. We need more of this. \n- In particular, a canonical experiments comparing Gaussian interaction vs inner product would be very useful. \n- Experiments on existing benchmarks (for KB completion, or QA) would help. I agree with the authors that it is difficult to find the perfect benchmark, so it is a good idea to propose a new one (WorldCup2014). But this should come in addition to experiments on existing data.\n- Table 11 of Appendix C (page 16) that compares TransE and TransGaussian for the task of link prediction on WordNet can be seen as fixing the two points above (simple setting on existing benchmark). Unfortunately, TransGaussian does not perform well compared to simpler TransE. This, along with the poor results of TransGaussian (SINGLE) of Table 2, indicate that training TransGaussian seems pretty complex, and hence question the actual validity of this architecture.\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "No Title", "is_meta_review": false, "comments": "SUMMARY.\n\nThe paper propose a new scoring function for knowledge base embedding.\nThe scoring function called TransGaussian is an novel take on (or a generalization of) the well-known TransE scoring function.\nThe proposed function is tested on two tasks knowledge-base completion and question answering.\n\n----------\n\nOVERALL JUDGMENT\nWhile I think this proposed work is very interesting and it is an idea worth to explore further, the presentation and the experimental section of the paper have some problems.\nRegarding the presentation, as far as I understand this is not an attention model as intended standardly in the literature.\nPlus, it has hardly anything to share with memory networks/neural Turing machines, the parallel that the authors try to make is not very convincing.\nRegarding the experimental section, for a fair comparison the authors should test their model on standard benchmarks, reporting state-of-the-art models.\nFinally, the paper lack of discussion of results and insights on the behavior of the proposed model.\n\n\n----------\n\nDETAILED COMMENTS\n\n\nIn section 2.2 when the authors calculate \\mu_{context} do not they loose the order of relations? And if it is so, does it make any sense?\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_META_REVIEW": false, "DATE": "03 Dec 2016", "is_meta_review": false}, {"TITLE": "Some questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "", "IS_META_REVIEW": false, "DATE": "30 Nov 2016", "is_meta_review": false}], "SCORE": 4, "authors": "Liwen Zhang, John Winn, Ryota Tomioka", "KEYWORDS": "We make (simple) knowledge base queries differentiable using the Gaussian attention model.", "accepted": false, "id": ""}
