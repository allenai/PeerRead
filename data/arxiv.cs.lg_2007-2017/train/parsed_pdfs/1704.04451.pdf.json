{
  "name" : "1704.04451.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Optimizing Differentiable Relaxations of Coreference Evaluation Metrics",
    "authors" : [ "Phong Le", "Ivan Titov" ],
    "emails" : [ "p.le@uva.nl", "ititov@inf.ed.ac.uk" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Coreference resolution is the task of identifying all mentions which refer to the same entity in a document. It has been shown beneficial in many natural language processing (NLP) applications, including question answering (Hermann et al., 2015) and information extraction (Kehler, 1997), and often regarded as a prerequisite to any text understanding task.\nCoreference resolution can be regarded as a clustering problem: each cluster corresponds to a single entity and consists of all its mentions in a given text. Consequently, it is natural to evaluate predicted clusters by comparing them with the ones annotated by human experts, and this is exactly what the standard metrics (e.g., MUC, B3, CEAF) do. In contrast, most state-of-theart systems are optimized to make individual co-\nreference decisions, and such losses are only indirectly related to the metrics.\nOne way to deal with this challenge is to optimize directly the non-differentiable metrics using reinforcement learning (RL), for example, relying on the REINFORCE policy gradient algorithm (Williams, 1992). However, this approach has not been very successful, which, as suggested by Clark and Manning (2016a), is possibly due to the discrepancy between sampling decisions at training time and choosing the highest ranking ones at test time. A more successful alternative is using a ‘roll-out’ stage to associate cost with possible decisions, as in Clark and Manning (2016a), but it is computationally expensive. Imitation learning (Ma et al., 2014b; Clark and Manning, 2015), though also exploiting metrics, requires access to an expert policy, with exact policies not directly computable for the metrics of interest.\nIn this work, we aim at combining the best of both worlds by proposing a simple method that can turn popular coreference evaluation metrics into differentiable functions of model parameters. As we show, this function can be computed recursively using scores of individual local decisions, resulting in a simple and efficient estimation procedure. The key idea is to replace nondifferentiable indicator functions (e.g. the member function I(m ∈ S)) with the corresponding posterior probabilities (p(m ∈ S)) computed by the model. Consequently, non-differentiable functions used within the metrics (e.g. the set size function |S| = ∑ m I(m ∈ S)) become differ-\nentiable (|S|c = ∑\nm p(m ∈ S)). Though we assume that the scores of the underlying statistical model can be used to define a probability model, we show that this is not a serious limitation. Specifically, as a baseline we use a probabilistic version of the neural mention-ranking\nar X\niv :1\n70 4.\n04 45\n1v 3\n[ cs\n.C L\n] 2\n2 Ju\nn 20\n17\nmodel of Wiseman et al. (2015b), which on its own outperforms the original one and achieves similar performance to its global version (Wiseman et al., 2016). Importantly when we use the introduced differentiable relaxations in training, we observe a substantial gain in performance over our probabilistic baseline. Interestingly, the absolute improvement (+0.52) is higher than the one reported in Clark and Manning (2016a) using RL (+0.05) and the one using reward rescaling1 (+0.37). This suggests that our method provides a viable alternative to using RL and reward rescaling.\nThe outline of our paper is as follows: we introduce our neural resolver baseline and the B3 and LEA metrics in Section 2. Our method to turn a mention ranking resolver into an entity-centric resolver is presented in Section 3, and the proposed differentiable relaxations in Section 4. Section 5 shows our experimental results."
    }, {
      "heading" : "2 Background",
      "text" : ""
    }, {
      "heading" : "2.1 Neural mention ranking",
      "text" : "In this section we introduce neural mention ranking, the framework which underpins current stateof-the-art models (Clark and Manning, 2016a). Specifically, we consider a probabilistic version of the method proposed by Wiseman et al. (2015b). In experiments we will use it as our baseline.\nLet (m1,m2, ..,mn) be the list of mentions in a document. For each mentionmi, let ai ∈ {1, ..., i} be the index of the mention that mi is coreferent with (if ai = i, mi is the first mention of some entity appearing in the document). As standard in coreference resolution literature, we will refer to mai as an antecedent of mi.\n2 Then, in mention ranking the goal is to score antecedents of a mention higher than any other mentions, i.e., if s is the scoring function, we require s(ai = j) > s(ai = k) for all j, k such that mi and mj are coreferent but mi and mk are not.\nLet φa(mi) ∈ Rda and φp(mi,mj) ∈ Rdp be respectively features of mi and features of pair\n1Reward rescaling is a technique that computes error values for a heuristic loss function based on the reward difference between the best decision according to the current model and the decision leading to the highest metric score.\n2This slightly deviates from the definition of antecedents in linguistics (Crystal, 1997).\n(mi,mj). The scoring function is defined by:\ns(ai = j) = u T [ ha(mi) hp(mi,mj) ] + u0 if j < i\nvTha(mi) + v0 if j = i\nwhere\nha(mi) = tanh(Waφa(mi) + ba)\nhp(mi,mj) = tanh(Wpφp(mi,mj) + bp)\nand u,v,Wa,Wp,ba,bp are real vectors and matrices with proper dimensions, u0, v0 are real scalars.\nUnlike Wiseman et al. (2015b), where the maxmargin loss is used, we define a probabilistic model. The probability3 that mi and mj are coreferent is given by\np(ai = j) = exp{s(ai = j)}∑i j′=1 exp{s(ai = j′)}\n(1)\nFollowing Durrett and Klein (2013) we use the following softmax-margin (Gimpel and Smith, 2010) loss function: L(Θ) = − n∑ i=1 log ( ∑ j∈C(mi) p′(ai = j) ) +λ||Θ||1,\nwhere Θ are model parameters, C(mi) is the set of the indices of correct antecedents of mi, and p′(ai = j) ∝ p(ai = j)e∆(j,C(mi)). ∆ is a cost function used to manipulate the contribution of different error types to the loss function:\n∆(j, C(mi)) =  α1 if j 6= i ∧ i ∈ C(mi) α2 if j = i ∧ i /∈ C(mi) α3 if j 6= i ∧ j /∈ C(mi) 0 otherwise\nThe error types are “false anaphor”, “false new”, “wrong link”, and “no mistake”, respectively. In our experiments, we borrow their values from Durrett and Klein (2013): (α1, α2, α3) = (0.1, 3, 1). In the subsequent discussion, we refer to the loss as mention-ranking heuristic cross entropy.\n3For the sake of readability, we do not explicitly mark in our notation that all the probabilities are conditioned on the document (e.g., the mentions) and dependent on model parameters."
    }, {
      "heading" : "2.2 Evaluation Metrics",
      "text" : "We use five most popular metrics4,\n• MUC (Vilain et al., 1995),\n• B3 (Bagga and Baldwin, 1998),\n• CEAFm, CEAFe (Luo, 2005),\n• BLANC (Luo et al., 2014),\n• LEA (Moosavi and Strube, 2016).\nfor evaluation. However, because MUC is the least discriminative metric (Moosavi and Strube, 2016), whereas CEAF is slow to compute, out of the five most popular metrics we incorporate into our loss only B3. In addition, we integrate LEA, as it has been shown to provide a good balance between discriminativity and interpretability.\nLet G = {G1, G2, ..., GN} and S = {S1, S2, ..., SM} be the gold-standard entity set and an entity set given by a resolver. Recall that an entity is a set of mentions. The recall and precision of the B3 metric is computed by:\nRB3 =\n∑N v=1 ∑M u=1\n|Gv∩Su|2 |Gv |∑N\nv=1 |Gv|\nPB3 =\n∑M u=1 ∑N v=1\n|Gv∩Su|2 |Su|∑M\nu=1 |Su|\nThe LEA metric is computed as:\nRLEA =\n∑N v=1 ( |Gv| × ∑M u=1 link(Gv∩Su) link(Gv) )∑N v=1 |Gv|\nPLEA =\n∑M u=1 ( |Su| × ∑N v=1 link(Gv∩Su) link(Su) )∑M u=1 |Su|\nwhere link(E) = |E| × (|E| − 1)/2 is the number of coreference links in entity E. Fβ , for both metrics, is defined by:\nFβ = (1 + β 2) P ×R β2P +R\nβ = 1 is used in the standard evaluation.\n4All are implemented in Pradhan et al. (2014), https://github.com/conll/ reference-coreference-scorers."
    }, {
      "heading" : "3 From mention ranking to entity centricity",
      "text" : "Mention-ranking resolvers do not explicitly provide information about entities/clusters which is required by B3 and LEA. We therefore propose a simple solution that can turn a mention-ranking resolver into an entity-centric one.\nFirst note that in a document containing n mentions, there are n potential entities E1, E2, ..., En where Ei has mi as the first mention. Let p(mi ∈ Eu) be the probability that mention mi corresponds to entity Eu. We now show that it can be computed recursively based on p(ai = j) as follows:\np(mi ∈ Eu) = ∑i−1 j=u p(ai = j)× p(mj ∈ Eu) if u < i p(ai = i) if u = i 0 if u > i\nIn other words, if u < i, we consider all possible mj with which mi can be coreferent, and which can correspond to entity Eu. If u = i, the link to be considered is the mi’s self-link. And, if u > i, the probability is zero, as it is impossible formi to be assigned to an entity introduced only later. See Figure 1 for extra information.\nWe now turn to two crucial questions about this formula:\n• Is p(mi ∈ •) a valid probability distribution?\n• Is it possible for a mention mu to be mostly anaphoric (i.e. p(mu ∈ Eu) is low) but for the corresponding cluster Eu to be highly\nprobable (i.e. p(mi ∈ Eu) is high for some i)?\nThe first question is answered in Proposition 1. The second question is important because, intuitively, when a mention mu is anaphoric, the potential entity Eu does not exist. We will show that the answer is “No” by proving in Proposition 2 that the probability that mu is anaphoric is always higher than any probability that mi, i > u refers to Eu. Proposition 1. p(mi ∈ •) is a valid probability distribution, i.e., ∑n u=1 p(mi ∈ Eu) = 1, for all i = 1, ..., n.\nProof. We prove this proposition by induction. Basis: it is obvious that ∑n u=1 p(m1 ∈ Eu) = p(a1 = 1) = 1. Assume that ∑n u=1 p(mj ∈ Eu) = 1 for all j < i. Then,\ni−1∑ u=1 p(mi ∈ Eu)\n= i−1∑ u=1 i−1∑ j=u p(ai = j)× p(mj ∈ Eu)\nBecause p(mj ∈ Eu) = 0 for all j < u, this expression is equal to\ni−1∑ u=1 i−1∑ j=1 p(ai = j)× p(mj ∈ Eu)\n= i−1∑ j=1 p(ai = j)× i−1∑ u=1 p(mj ∈ Eu)\n= i−1∑ j=1 p(ai = j)\nTherefore,\nn∑ u=1 p(mi ∈ Eu) = i−1∑ j=1 p(ai = j)+p(ai = i) = 1\n(according to Equation 1).\nProposition 2. p(mi ∈ Eu) ≤ p(mu ∈ Eu) for all i > u.\nProof. We prove this proposition by induction. Basis: for i = u+ 1,\np(mu+1 ∈ Eu) = p(au+1 = u)× p(mu ∈ Eu) ≤ p(mu ∈ Eu)\nAssume that p(mj ∈ Eu) ≤ p(mu ∈ Eu) for all j ≥ u and j < i. Then\np(mi ∈ Eu) = i−1∑ j=u p(ai = j)× p(mj ∈ Eu)\n≤ i−1∑ j=u p(ai = j)× p(mu ∈ Eu)\n≤ p(mu ∈ Eu)× i∑\nj=1\np(ai = j)\n= p(mu ∈ Eu)"
    }, {
      "heading" : "3.1 Entity-centric heuristic cross entropy loss",
      "text" : "Having p(mi ∈ Eu) computed, we can consider coreference resolution as a multiclass prediction problem. An entity-centric heuristic cross entropy loss is thus given below:\nLec(Θ) = − n∑ i=1 log p′(mi ∈ Ee(mi)) + λ||Θ||1\nwhere Ee(mi) is the correct entity that mi belongs to, p′(mi ∈ Eu) ∝ p(mi ∈ Eu)eΓ(u,e(mi)). Similar to ∆ in the mention-ranking heuristic loss in Section 2.1, Γ is a cost function used to manipulate the contribution of the four different error types (“false anaphor”, “false new”, “wrong link”, and “no mistake”):\nΓ(u, e(mi)) = γ1 if u 6= i ∧ e(mi) = i γ2 if u = i ∧ e(mi) 6= i γ3 if u 6= e(mi) ∧ u 6= i ∧ e(mi) 6= i 0 otherwise"
    }, {
      "heading" : "4 From non-differentiable metrics to differentiable losses",
      "text" : "There are two functions used in computing B3 and LEA: the set size function |.| and the link function link(.). Because both of them are non-differentiable, the two metrics are nondifferentiable. We thus need to make these two functions differentiable.\nThere are two remarks. Firstly, both functions can be computed using the indicator function\nI(mi ∈ Su):\n|Su| = n∑ i=1 I(mi ∈ Su)\nlink(Su) = ∑ j<i I(mi ∈ Su)× I(mj ∈ Su)\nSecondly, given πi,u = log p(mi ∈ Su), the indicator function I(mi ∈ Su∗), u∗ = arg maxu p(mi ∈ Su) is the converging point of the following softmax as T → 0 (see Figure 2):\np(mi ∈ Su;T ) = exp{πi,u/T}∑ v exp{πi,v/T}\nwhere T is called temperature (Kirkpatrick et al., 1983).\nTherefore, we propose to represent each Su as a soft-cluster:\nSu = {p(m1 ∈ Eu;T ), ..., p(mn ∈ Eu;T )}\nwhere, as defined in Section 3, Eu is the potential entity that has mu as the first mention. Replacing the indicator function I(mi ∈ Su) by the probability distribution p(mi ∈ Eu;T ), we then have a differentiable version for the set size function and the link function:\n|Su|d = n∑ i=1 p(mi ∈ Eu;T )\nlinkd(Su) = ∑ j<i p(mi ∈ Eu;T )× p(mj ∈ Eu;T )\n|Gv∩Su|d and linkd(Gv∩Su) are computed similarly with the constraint that only mentions in Gv are taken into account. Plugging these functions into precision and recall of B3 and LEA in Section 2.2, we obtain differentiable F̂β,B3 and F̂β,LEA, which are then used in two loss functions:\nLβ,B3(Θ;T ) = −F̂β,B3(Θ;T ) + λ||Θ||1 Lβ,LEA(Θ;T ) = −F̂β,LEA(Θ;T ) + λ||Θ||1\nwhere λ is the hyper-parameter of the L1 regularization terms.\nIt is worth noting that, as T → 0, F̂β,B3 → Fβ,B3 and F̂β,LEA → Fβ,LEA.5 Therefore, when training a model with the proposed losses, we can start at a high temperature (e.g., T = 1) and anneal to a small but non-zero temperature. However, in our experiments we fix T = 1. Annealing is left for future work."
    }, {
      "heading" : "5 Experiments",
      "text" : "We now demonstrate how to use the proposed differentiable B3 and LEA to train a coreference resolver. The source code and trained models are available at https://github.com/ lephong/diffmetric_coref.\nSetup\nWe run experiments on the English portion of CoNLL 2012 data (Pradhan et al., 2012) which consists of 3,492 documents in various domains and formats. The split provided in the CoNLL 2012 shared task is used. In all our resolvers, we use not the original features of Wiseman et al. (2015b) but their slight modification described in Wiseman et al. (2016) (section 6.1).6\nResolvers\nWe build following baseline and three resolvers:\n• baseline: the resolver presented in Section 2.1. We use the identical configuration as in Wiseman et al. (2016): Wa ∈ R200×da , Wp ∈ R700×dp , λ = 10−6 (where da, dp are respectively the numbers of mention features and pair-wise features). We also employ their pretraining methodology.\n5We can easily prove this using the algebraic limit theorem.\n6https://github.com/swiseman/nn_coref/\n• Lec: the resolver using the entity-centric cross entropy loss introduced in Section 3.1. We set (γ1, γ2, γ3) = (α1, α2, α3) = (0.1, 3, 1).\n• Lβ,B3 and Lβ,LEA: the resolvers using the losses proposed in Section 4. β is tuned on the development set by trying each value in { √ 0.8, 1, √ 1.2, √ 1.4, √ 1.6, √ 1.8, 1.5, 2}.\nTo train these resolvers we use AdaGrad (Duchi et al., 2011) to minimize their loss functions with the learning rate tuned on the development set and with one-document mini-batches. Note that we use the baseline as the initialization point to train the other three resolvers."
    }, {
      "heading" : "5.1 Results",
      "text" : "We firstly compare our resolvers against Wiseman et al. (2015b) and Wiseman et al. (2016). Results are shown in the first half of Table 1. Our baseline surpasses Wiseman et al. (2015b). It is likely due to using features from Wiseman et al. (2016). Using the entity-centric heuristic cross entropy loss and the relaxations are clearly beneficial: Lec is slightly better than our baseline and on par with the global model of Wiseman et al. (2016). Lβ=1,B3 , Lβ=1,LEA outperform the baseline, the global model of Wiseman et al. (2016), and Lec. However, the best values of β are √ 1.4,√\n1.8 respectively for Lβ,B3 , and Lβ,LEA. Among these resolvers, Lβ= √ 1.8,LEA achieves the highest F1 scores across all the metrics except BLANC. When comparing to Clark and Manning (2016a) (the second half of Table 1), we can see that the absolute improvement over the baselines (i.e. ‘heuristic loss’ for them and the heuristic cross entropy loss for us) is higher than that of reward rescaling but with much shorter training time: +0.37 (7 days7) and +0.52 (15 hours) on the CoNLL metric for Clark and Manning (2016a) and ours, respectively. It is worth noting that our absolute scores are weaker than these of Clark and Manning (2016a), as they build on top of a similar but stronger mention-ranking baseline, which employs deeper neural networks and requires a much larger number of epochs to train (300 epochs, including pretraining). For the purpose of illustrating the proposed losses, we started with a simpler model by Wiseman et al. (2015b) which requires\n7As reported in https://github.com/ clarkkev/deep-coref\na much smaller number of epochs, thus faster, to train (20 epochs, including pretraining)."
    }, {
      "heading" : "5.2 Analysis",
      "text" : "Table 2 shows the breakdown of errors made by the baseline and our resolvers on the development set. The proposed resolvers make fewer “false anaphor” and “wrong link” errors but more “false new” errors compared to the baseline. This suggests that loss optimization prevents over-clustering, driving the precision up: when antecedents are difficult to detect, the self-link (i.e., ai = i) is chosen. When β increases, they make more “false anaphor” and “wrong link” errors but less “false new” errors.\nIn Figure 3(a) the baseline, but not Lβ=1,B3 nor Lβ= √ 1.4,B3 , mistakenly links 17[it] with 13[the virus]. Under-clustering, on the other hand, is a problem for our resolvers with β = 1: in example (b), Lβ=1,B3 missed 165[We]. This behaviour results in a reduced recall but the recall is not damaged severely, as we still obtain a better F1 score. We conjecture that this behaviour is a consequence of using the F1 score in the objective, and, if undesirable, Fβ with β > 1 can be used instead. For instance, also in Figure 3, Lβ= √ 1.4,B3 correctly detects 17[it] as non-anaphoric and links 165[We] with 157[our].\nFigure 4 shows recall, precision, F1 (average of MUC, B3, CEAFe), on the development set when training with Lβ,B3 and Lβ,LEA. As expected, higher values of β yield lower precisions but higher recalls. In contrast, F1 increases until\nreaching the highest point when β = √\n1.4 ≈ 1.18 for Lβ,B3 (β = √ 1.8 ≈ 1.34 for Lβ,LEA), it then decreases gradually."
    }, {
      "heading" : "5.3 Discussion",
      "text" : "Because the resolvers are evaluated on F1 score metrics, it should be that Lβ,B3 and Lβ,LEA perform the best with β = 1. Figure 4 and Table 1 however do not confirm that: β should be set with values a little bit larger than 1. There are two hypotheses. First, the statistical difference between the training set and the development set leads to the case that the optimal β on one set can be suboptimal on the other set. Second, in our experiments we fix T = 1, meaning that the relaxations might not be close to the true evaluation metrics enough. Our future work, to confirm/reject this, is to use annealing, i.e., gradually decreasing T down to (but larger than) 0.\nTable 1 shows that the difference betweenLβ,B3 and Lβ,LEA in terms of accuracy is not substan-\ntial (although the latter is slightly better than the former). However, one should expect that Lβ,B3 would outperform Lβ,LEA on B3 metric while it would be the other way around on LEA metric. It turns out that, B3 and LEA behave quite similarly in non-extreme cases. We can see that in Figure 2, 4, 5, 6, 7 in Moosavi and Strube (2016)."
    }, {
      "heading" : "6 Related work",
      "text" : "Mention ranking and entity centricity are two main streams in the coreference resolution literature. Mention ranking (Denis and Baldridge, 2007; Durrett and Klein, 2013; Martschat and Strube, 2015; Wiseman et al., 2015a) considers local and independent decisions when choosing a correct antecedent for a mention. This approach is computationally efficient and currently dominant with state-of-the-art performance (Wiseman et al., 2016; Clark and Manning, 2016a). Wiseman et al. (2015b) propose to use simple neural\nnetworks to compute mention ranking scores and to use a heuristic loss to train the model. Wiseman et al. (2016) extend this by employing LSTMs to compute mention-chain representations which are then used to compute ranking scores. They call these representations global features. Clark and Manning (2016a) build a similar resolver as in Wiseman et al. (2015b) but much stronger thanks to deeper neural networks and “better mention detection, more effective, hyperparameters, and more epochs of training”. Furthermore, using reward rescaling they achieve the best performance in the literature on the English and Chinese portions of the CoNLL 2012 dataset. Our work is built upon mention ranking by turning a mentionranking model into an entity-centric one. It is worth noting that although we use the model proposed by Wiseman et al. (2015b), any mentionranking models can be employed.\nEntity centricity (Wellner and McCallum, 2003; Poon and Domingos, 2008; Haghighi and Klein, 2010; Ma et al., 2014a; Clark and Manning, 2016b), on the other hand, incorporates entitylevel information to solve the problem. The approach can be top-down as in Haghighi and Klein (2010) where they propose a generative model. It can also be bottom-up by merging smaller clusters into bigger ones as in Clark and Manning (2016b). The method proposed by Ma et al. (2014a) greedily and incrementally adds mentions to previously built clusters using a prune-and-score technique. Importantly, employing imitation learning these two methods can optimize the resolvers directly on evaluation metrics. Our work is similar to Ma et al. (2014a) in the sense that our resolvers incrementally add mentions to previously built clusters.\nHowever, different from both Ma et al. (2014a); Clark and Manning (2016b), our resolvers do not use any discrete decisions (e.g., merge operations). Instead, they seamlessly compute the probability that a mention refers to an entity from mentionranking probabilities, and are optimized on differentiable relaxations of evaluation metrics.\nUsing differentiable relaxations of evaluation metrics as in our work is related to a line of research in reinforcement learning where a nondifferentiable action-value function is replaced by a differentiable critic (Sutton et al., 1999; Silver et al., 2014). The critic is trained so that it is as close to the true action-value function as possible. This technique is applied to machine translation (Gu et al., 2017) where evaluation metrics (e.g., BLUE) are non-differentiable. A disadvantage of using critics is that there is no guarantee that the critic converges to the true evaluation metric given finite training data. In contrast, our differentiable relaxations do not need to train, and the convergence is guaranteed as T → 0."
    }, {
      "heading" : "7 Conclusions",
      "text" : "We have proposed\n• a method for turning any mention-ranking resolver into an entity-centric one by using a recursive formula to combine scores of individual local decisions, and\n• differentiable relaxations for two coreference evaluation metrics, B3 and LEA.\nExperimental results show that our approach outperforms the resolver by Wiseman et al. (2016), and gains a higher improvement over the baseline\nthan that of Clark and Manning (2016a) but with much shorter training time."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We would like to thank Raquel Fernández, Wilker Aziz, Nafise Sadat Moosavi, and anonymous reviewers for their suggestions and comments. The project was supported by the European Research Council (ERC StG BroadSem 678254), the Dutch National Science Foundation (NWO VIDI 639.022.518) and an Amazon Web Services (AWS) grant."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2017,
    "abstractText" : "Coreference evaluation metrics are hard to optimize directly as they are nondifferentiable functions, not easily decomposable into elementary decisions. Consequently, most approaches optimize objectives only indirectly related to the end goal, resulting in suboptimal performance. Instead, we propose a differentiable relaxation that lends itself to gradient-based optimisation, thus bypassing the need for reinforcement learning or heuristic modification of cross-entropy. We show that by modifying the training objective of a competitive neural coreference system, we obtain a substantial gain in performance. This suggests that our approach can be regarded as a viable alternative to using reinforcement learning or more computationally expensive imitation learning.",
    "creator" : "LaTeX with hyperref package"
  }
}