{"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Feb-2017", "title": "Efficient Computation of Moments in Sum-Product Networks", "abstract": "Bayesian online learning algorithms for Sum-Product Networks (SPNs) need to compute moments of model parameters under the one-step update posterior distribution. The best existing method for computing such moments scales quadratically in the size of the SPN, although it scales linearly for trees. We propose a linear-time algorithm that works even when the SPN is a directed acyclic graph (DAG). We achieve this goal by reducing the moment computation problem into a joint inference problem in SPNs and by taking advantage of a special structure of the one-step update posterior distribution: it is a multilinear polynomial with exponentially many monomials, and we can evaluate moments by differentiating. The latter is known as the \\emph{differential trick}. We apply the proposed algorithm to develop a linear time assumed density filter (ADF) for SPN parameter learning. As an additional contribution, we conduct extensive experiments comparing seven different online learning algorithms for SPNs on 20 benchmark datasets. The new linear-time ADF method consistently achieves low runtime due to the efficient linear-time algorithm for moment computation; however, we discover that two other methods (CCCP and SMA) typically perform better statistically, while a third (BMM) is comparable to ADF. Interestingly, CCCP can be viewed as implicitly using the same differentiation trick that we make explicit here. The fact that two of the top four fastest methods use this trick suggests that the same trick might find other uses for SPN learning in the future.", "histories": [["v1", "Wed, 15 Feb 2017 20:40:12 GMT  (42kb,D)", "http://arxiv.org/abs/1702.04767v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["han zhao", "geoff gordon"], "accepted": true, "id": "1702.04767"}
