{
  "name" : "1605.03004.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "MUST-CNN: A Multilayer Shift-and-Stitch Deep Convolutional Architecture for Sequence-based Protein Structure Prediction",
    "authors" : [ "Zeming Lin", "Jack Lanchantin", "Yanjun Qi" ],
    "emails" : [ "zl4ry@virginia.edu", "jjl5sw@virginia.edu", "yq2h@virginia.edu" ],
    "sections" : [ {
      "heading" : "Introduction",
      "text" : "Proteins are vital to the function of living beings. It is easy to determine the sequence of a protein, yet it is difficult to determine other properties, such as secondary structure and solvent accessibility. These properties are hypothesized to be almost uniquely determined by primary structure, but it is still computationally difficult to determine them on a large scale.\nPrevious state-of-the-art methods for protein secondary structure prediction use multilayer perceptron (MLP) networks (Qi et al. 2012; Drozdetskiy et al. 2015). In order to predict a per-position label for each amino acid in the input protein sequence, MLP networks must use a “windowing” approach where a single label is predicted by feeding the target amino acid and its surrounding amino acids through the network. This is then repeated for each amino acid in the sequence. These architectures generally has two major drawbacks due to the windowing approach: (1) they take a long time to train, on the order of days or weeks and (2) they have smaller window sizes, and thus cannot make longer range connections. For instance, the PSIPRED algorithm handles a window size of only 15 amino acids (Jones 1999).\nCopyright c© 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nTo overcome the windowing issue, we propose to use a convolutional neural network (CNN) which can label the properties of each amino acid in the entire target sequence all at once. CNNs have been used successfully in computer vision (Pinheiro and Collobert 2013; Szegedy et al. 2014) and natural language processing (Kim 2014; Collobert and Weston 2008). In addition to parameter sharing and pooling, which reduce computation, CNNs are also highly parallelizable. Thus, CNNs can achieve a much greater speedup compared to a windowed MLP approach. The issue when trying to label each position in an input sequence with a CNN is that pooling leads to a decreased output resolution. To handle this issue, we propose a new multilayer shift-and-stitch method which allows us to efficiently label each target input at full resolution in a computationally efficient manner.\nWe show that a MUltilayer Shift-and-sTitch CNN (MUST-CNN) trained end-to-end and per-position on protein property prediction beats the state-of-the-art without other machinery. To our knowledge, we are the first to train convolutional networks end-to-end for per-position protein property prediction. Both learning and inference are performed on entire arbitrarily sized sequences. Feedforward computation and backpropagation is made possible by our novel application of the shift-and-stitch technique on the entire sequence.\nIn summary we make the following contributions: 1. Beat the state-of-the-art performance on two large\ndatasets of protein property prediction tasks. 2. Propose a multilayer shift-and-stitch technique for deep\nCNNs, which significantly speeds up training and test time and increases the size of the model we can train.\n3. Propose a generic end-to-end system for per-position labeling on the sequence level. That is, for a sequence {ak}nk=1, we can generate labels {yk}nk=1 for each ak."
    }, {
      "heading" : "Related Works",
      "text" : "Two of the most used algorithms in bioinformatics literature for protein property prediction are PSIPRED (Jones 1999) and Jpred (Drozdetskiy et al. 2015). PSIPRED 3.2, which uses a two layer MLP approach, claims a 3-class per-position accuracy (Q3) score of 81.6%. The Jpred algorithm uses a very similar structure of a two layer MLP network. However, Jpred considers more features and uses\nar X\niv :1\n60 5.\n03 00\n4v 1\n[ cs\n.L G\n] 1\n0 M\nay 2\n01 6\na jury based approach with multiple models (Cuff and Barton 2000). Jpred claims an 81.5% Q3 score on secondary structure prediction, and also predicts relative solvent accessibility. (Qi et al. 2012) uses a deep MLP architecture with multitask learning and achieves 81.7% Q3. (Zhou and Troyanskaya 2014) created a generative stochastic network to predict secondary structure from the same data we used, for a Q8 of 66.4%. Unlike Q3, the Q8 accuracy tries to distinguish between more classes.\nThe state-of-the-art protein sequence classification system is SSpro, which obtains 91.74% Q3 and 85.88% Q8 on a different unfiltered PDB dataset (Magnan and Baldi 2014). However, this system exploits additional information via sequence similarity, and their reported accuracies were only 80% without this module. Our work would complement their machine learning module and likely result in even better accuracies.\nRecently, work has also been done on the model side, particularly in natural language processing and image recognition tasks. (Collobert et al. 2011) created a similar algorithm in the natural language processing domain, where they labeled word properties, such as part of speech or category of a named entity, on text data. If we consider each protein chain to be a sentence and each amino acid to be a word, the techniques transfer easily. (Collobert et al. 2011) used both a windowed approach and a sentence level approach with a convolutional network, though their network was shallow and only outputed predictions for one position at a time. Long-short term memory networks have been used very successfully in sequence learning, machine translation (Sutskever, Vinyals, and Le 2014; Bahdanau, Cho, and Bengio 2014) and language modeling (Zaremba, Sutskever, and Vinyals 2014). We note that machine translation is a much more general sequence to sequence task where the input and output sizes are not matched. Language modeling tries to guess future words based on past words, while protein sequences has no innate direction.\nIn the image domain, (Szegedy et al. 2014) has beaten the state-of-the-art on image classification by a large percentage through using a deep multilayer convolutional network in the ImageNet Large-Scale Visual Recognition Challenge. Scene labeling is the task of labeling each pixel of an image with one of several classes, a 2D analogue of protein property prediction. (Pinheiro and Collobert 2013) uses a recurrent neural network to obtain state-of-the-art results on scene labeling without any feature engineering. (Long, Shelhamer, and Darrell 2014) designs fully convolutional networks for dense pixel prediction by running several convolutional networks on different scales. (Sermanet et al. 2013) increases the resolution of a bounding box based image classifier by introducing the shift-and-stitch technique, which we use on sequences instead of images and on the entire model instead of only on the last layer."
    }, {
      "heading" : "Method: MUST-CNN",
      "text" : ""
    }, {
      "heading" : "Convolutional Neural Networks (CNN)",
      "text" : "Convolutional networks were popularized for the task of handwriting recognition of 2D images (Lecun et al. 1998).\nIn a similar way, we use a 1D convolution for the protein sequence labeling problem. A convolution on sequential data tensor X of size T × nin with length T , kernel size k and input hidden layer size nin has output Y of size T × nout:\nYt,i = σ(Bi + nin∑ j=1 k∑ z=1 Wi,j,kXt+z−1,j)\nwhere W and B are the trainable parameters of the convolution kernel, and σ is the nonlinearity. We try three different nonlinearity functions in our experiments: the hyperbolic tangent, rectified linear units (ReLU), and piecewise rectified linear units (PReLU). The hyperbolic tangent is historically the most used in neural networks, since it has nice computational properties that make optimization easy. Both ReLU and PReLU have been shown to work very well on deep convolutional networks for object recognition. ReLU was shown to perform better than tanh on the same tasks, and enforces small amounts of sparsity in neural networks (Glorot, Bordes, and Bengio 2011). By making the activations trainable and piecewise, PReLUs have shown to match the state of the art on ILSVRC while converging in only 7% of the time (He et al. 2015).\nThe ReLU nonlinearity is defined as\nrelu(x) = max(0, x)\nand the PReLU nonlinearity is defined as\nprelu(x) = { αx if x < 0 x if x ≥ 0\nwith a trainable parameter α. After the convolution and nonlinearity, we use a pooling layer. The only pooling strategy tested was maxpooling, which has shown to perform much better than subsampling as a pooling scheme (Scherer, Müller, and Behnke 2010) and has generally been the preferred pooling strategy for large scale computer vision tasks. Maxpooling on a sequence Y of size T × n with a pooling size of m results in output Z where\nZt,i = m\nmax j=1 Ym(t−1)+j,i\nFinally, the outputs are passed through a dropout layer. The dropout layer is a randomized mask of the outputs, equivalent to randomly zeroing out the inputs to the next layer during training time with probability d (Srivastava et al. 2014). During testing, the dropout layer is removed and all weights are used. This acts as a regularizer for the neural network and prevents overfitting, though the best values for d must be discovered experimentally.\nOne layer of the convolutional network is depicted in Figure 1. In our model design, we apply the CNN module multiple times for a deep multilayer framework."
    }, {
      "heading" : "Multilayer Shift-and-Stitch (MUST)",
      "text" : "Pooling is a dimension reduction operation which takes several nearby values and combines them into a single value – maxpooling uses the max function to do this. Maxpooling is important because as nearby values are merged into one, the classifier is encouraged to learn translation invariance. However, after a single application of maxpooling with a pool size of m on input sequence X of length T , the resulting maxpool output has sequence length Tm .\nSince the dimensionality of the sequence has been divided by a factor of m, it is no longer possible to label every position of the original sequence. A technique to increase the resolution in convolutional networks was given in (Sermanet et al. 2013), called “shift-and-stitch”. Their implementation uses the technique in a two dimensional setting to increase the resolution of pixel labels in the last layer of a convolutional network, for up to a 4× increase in resolution. We observe that the limiting factor on applying this to an entire image is the massive slowdown in computation, since each pooling layer in a two-dimensional case requires the network to stitch together 4 different outputs and 3 pooling layers require 64 different stitched outputs.\nHowever, in the sequential case, we need to stitch together significantly fewer sequences. Using 3 pooling layers with pooling size 2 will only requires 8 different stitches, making computation tractable. Therefore, we propose to apply shift-and-stitch to every layer of our deep CNN which generates dense per-position predictions for the entire sequence. This process is described in Figure 3. This will allow us to take advantage of the computational speeds provided by the convolution module, making it feasible to try a much larger model.\nDue to the kernel size, a convolution with kernel size k removes the bk2 c edge values on each end of the sequence. Thus, we pad the input with a total of bk2 c − 1 zeros at each end, colored as red in Figures 1 and 3. Because a maxpooling operation with pooling size m labels every m values in the input, we duplicate the inputm times and pad the i-th input such that the first convolution window is centered on the first amino acid. We observe that we can then join the m duplicated inputs along the batch dimension and pass it into the convolution module and take advantage of the batch computation ability offered by standard linear algebra packages to train our system even faster. After pooling, the output is a zipped version of the original input along the batch dimension. We simply “stitch” together the output in full resolution for the final result.\nThis novel multilayer shift-and-stitch technique makes it feasible to train a CNN end-to-end and generate dense perposition protein property prediction. This technique allows us to use convolution and maxpooling layers to label sequences of arbitrary length.\nMUST can also be extended to train sequences in minibatches if needed, though the operations will be slightly more complicated. However, we found minibatches not useful, because each amino acid is a training example, and each sequence already contains many amino acids. Additionally, sequences are generally of different lengths, which make implementation of minibatches harder."
    }, {
      "heading" : "End-to-end Architecture",
      "text" : "In this section we describe the end-to-end model structure of the MUST-CNN and how we are able to train it to make fully dense per-position predictions.\nThe input into the network is a one-hot encoding of an amino acid base pair sequence and the PSI-BLAST position specific scoring matrix (PSSM), which is described in more detail in section Experiments subsection Feature. Dropout is applied to the amino acid input and then fed through a Lookup Table, similar to (Collobert et al. 2011), to construct an embedding representation for each amino acid. Then, the features from the amino acid embeddings are joined directly with the PSSM matricies along the feature dimension and fed into the deep convolutional network.\nTo apply the shift-and-stitch technique, we shift the amino acid sequences according to the amount of pooling in each layer. Then, we pass every shift through each layer as described above, and stitch the results together after all convolutional layers. This creates a deep embedding for every amino acid in our sequence. Most previous methods use windowing to label the center amino acid. In our model, we can run the whole sequence through the model instead of each window at a time. This allows us to take advantage of the speed of convolution operations and use much larger models.\nWe use a multitask construction similar to (Qi et al. 2012), where we pass the deep embedding from the convolution layers into several linear fully connected layers which classify the protein sequence into each separate task. This as-\nsumes a linear relationship between the deep embedding of a protein chain and the properties predicted. In order for us to classify the outputs of the network for task τ ∈ T , into class c ∈ Cτ for sequence s ∈ S, we apply the softmax operator on the outputs ft,τ,c,s of the subclassifiers for task τ at position t = 1, . . . , T . Given the parameters of the network θ, this gives us a conditional probability of class c:\npτ (c ∈ Cτ |ft,τ,s, θ) = eft,τ,c,s∑\nc∈Cτ e ft,τ,c,s\nThe parameters of the network are trained end-to-end by minimizing the negative log-likelihood function over the training set, summing over all tasks and all elements in the sequence:\nL(θ) = − ∑ s∈S ∑ τ∈T T∑ t=1 ln pτ (ccorrect|ft,τ,s, θ)\nwhere ccorrect is the correct label of the amino acid. The minimization of the loss function is obtained via the stochastic gradient descent (SGD) algorithm with momentum, where we update the parameters after every sequence. After the initial multitask model is trained, we take the top layers and each task-specific subclassifier and fine-tune the models by initializing their weights at the weights learned by the multitask model and training only on each specific task with 110 of the original learning rate. Regularization is achieved via dropout (Srivastava et al. 2014).\nAll models are implemented using the Torch7 framework (Collobert, Kavukcuoglu, and Farabet 2011)."
    }, {
      "heading" : "Connecting to Previous Studies",
      "text" : "MUST-CNN is closely related to three previous models: OverFeat (Sermanet et al. 2013), Generative Stochastic networks (GSNs) (Zhou and Troyanskaya 2014), and Conditional Neural Fields (CNFs) (Wang et al. 2011).\nCNFs are equivalent to a Conditional Random Field (CRF) with a convolutional feature extractor. As far as we know, the authors implement a windowed version using MLP networks. Their model, although able to consider the entire sequence due to the use of a CRF, is unable to build deeper representations of models. Our model uses multiple convolutional layers and multitasking to classify each amino acid into one of a few classes across multiple tasks. Our models are much deeper, and hence can learn more efficient representations for complex dependencies.\nThe GSN is similar to a Restricted Boltzmann Machine with interconnections between the hidden states. Training requires a settling algorithm similar to finding the stationary distribution of a Markov chain. Although this technique allows for a model that considers the entire protein sequence, it is less well understood. Convolution layers have the advantage of being used more often in industry (See Related Works), and being well understood. Additionally, a fully feedforward model is almost certainly faster than a model that requires a distribution to converge, though (Zhou and Troyanskaya 2014) did not state training or testing time in their paper.\nOverFeat is the most closely related, though it works on images instead of sequence based classification. The pipeline of OverFeat takes in images and classifies them densely to detect objects at every patch. Then the bounding boxes for the objects are combined into a single bounding box, which is used to localize the object. MUST-CNN\nis a one dimensional classification algorithm, which takes in the protein sequence surrounding an amino acid and returns a dense property prediction of each amino acid. However, since object localization does not need to be done on every bounding box, OverFeat only uses shift-and-stitch on the last layer for a small resolution improvement. We do fully endto-end shift-and-stitch, which is difficult on the image domain due to the quadratic increase in calculation time.\nExperiments"
    }, {
      "heading" : "Feature",
      "text" : "The features that we use are (1) individual amino acids and (2) PSI-BLAST information (Altschul et al. 1997) of a protein sequence. Each amino acid a ∈ A, where A is the dictionary of amino acids, is coded as a one-hot vector in R|A|. That is, the encoding x of the i-th amino acid has xi = 1 and xj 6=i = 0. PSI-BLAST generates a PSSM of size T × 20 for a T lengthed sequence, where a higher score represents a higher likelihood of the ith amino acid replacing the current one in other species. Generally, two amino acids that are interchangeable in the PSSM indicates that they are also interchangeable in the protein without significantly modifying the functionality of the protein. The PSI-BLAST profiles were generated in the same way as the original authors in each of the datasets (Qi et al. 2012; Zhou and Troyanskaya 2014)."
    }, {
      "heading" : "Data",
      "text" : "We used two large protein property datasets in our experiments. The train, validation and test splits are given in Table 1. The two datasets we use are as follows:\n4prot Derived from (Qi et al. 2012), we use a trainvalidation-test split where the model is trained on the training set, selected via validation set results, and best results reported by testing on the test set.\nCullPDB Derived from (Zhou and Troyanskaya 2014), we choose to use the CullPDB dataset where sequences with > 25% identity with the CB513 dataset was removed. The train and validation sets are derived from CullPDB while the test set is CB513 in order to compare results with (Kaae Sønderby and Winther 2014; Wang et al. 2011)."
    }, {
      "heading" : "Tasks",
      "text" : "Both datasets were formatted to have the same multitask representation. These are the four classification tasks we tested our system on:\ndssp The 8 class secondary structure prediction task from the dssp database (Touw et al. 2015). The class labels are H = alpha helix, B = residue in isolated beta bridge, E = extended strand, G = 3-helix, I = 5-helix, T = hydrogen bonded turn, S = bend, L = loop.\nssp A collapsed version of the 8 class prediction task, since many protein secondary structure prediction algorithms use a 3 class approach instead of the 8-class approach given in dssp. {H,G} → H =Helix, {B,E} → B =Beta sheet, and {I, S, T, L} → C =Coil\nsar Relative solvent accessibility. Given the most solvent accessible amino acid in the protein has x Å of accessible surface area, we label other amino acids as solvent accessible if they have greater than 0.15x Å of accessible surface area.\nsaa Absolute solvent accessibility. Defined as the amino acid having more than 0.15 Å of accessible surface area."
    }, {
      "heading" : "Training",
      "text" : "Model Selection (Small model) We use Bayesian Optimiza-\ntion (Snoek, Larochelle, and Adams 2012) to find the optimal model. This is done using the Spearmint package (Snoek 2015). We ran Bayesian Optimization for one week to find the optimal parameters for the small model.\nModel Selection (Large model) The large model was found using a combination of grid search and manual tuning. The specific architectures we found is detailed in Table 2. Bayesian Optimization could not be used because large models were too slow to train. After training of the joint model, we also fine-tuned the model by considering each individual task and kickstarting the training from the models learned in the joint model. That is, we started training a model whose parameters were the same as the multitask model, but the loss function only included one specific task. The loss function for task τ , sequence s indexed from t = 1, . . . , T is then\nL(θ) = − ∑ s∈S T∑ t=1 ln pτ (ccorrect|ft,τ,s, θ)\nThis result is labeled as fine-tune in tables 2 and 3 We use the validation set during the finetuning to find the best dropout value, but then we include the validation set in the retraining set. Dropout generally ensures that early stopping is not needed, so including the validation set should improve the accuracy of our model. We fine-tune at a learning rate of 110 of the joint model learning rate.\nTime Training of the small model takes 6 hours, while training of the large model takes one day. Since testing the fine-tuned models involve passing the data through four separate models, while testing the multitask model involves doing all at the same time, it takes longer to test on the fine-tuned model. Nevertheless, we were able to handle testing speeds of over a million amino acids in under 2 seconds.\nHardware In order to speed up computation, we utilize the parallel architecture of the GPU, which is especially useful for convoultional models which do many parallel computations. All training and testing uses a Tesla C2050 GPU unit."
    }, {
      "heading" : "Results",
      "text" : "During model selection, we discovered that our model is very robust to model parameters. Most combinations of parameter tweaks inside the optimal learning rate give a less than 1% improvement in average accuracy. By using maxpooling with shift-and-stitch in our model our average accuracy improved by almost 0.5% with barely any computational slowdown.\nOur results on the 4prot dataset are detailed in Table 3. The small model we found via Bayesian Optimization has approximately as many parameters as previous state-of-theart models, but we see that it outperformed the network created by (Qi et al. 2012) on all tasks. Fine-tuning on individual models is necessary for good performance. This implies that it may perhaps be easier to build an MLP subclassifier for each task, instead of assuming linearity. Training jointly on the large model already beats (Qi et al. 2012), but finetuning increases the accuracy dramatically. Additionally, the testing time is reported in milliseconds per million amino acids. We see that the small models can test fairly quickly, while the fine-tuned large models have a 2.5× slowdown. We are the first to report precise training and testing times for a model on protein property prediction.\nA detailed listing of precision-recall scores for 4prot is given in Table 4. We see the expected pattern of lower frequencies having a lower F1 score, since unbalanced datasets are harder to classify. Precision is very stable, while recall dramatically lowers according to the frequency of labels. This suggests that our model picked up on several key properties of labels with few training examples, but missed many. More training data is one way to solve this issue.\nOur results on the CullPDB dataset and comparisions with existing state-of-the-art algorithms is detailed in ta-\nble 5. We do 1% better than the previous published best, despite using a dramatically simpler algorithm. Testing on the CB513 dataset allows a direct comparison to how previous methods perform. We do not achieve a dramatically higher accuracy rate as we do on 4prot. We suspect that filtering non-homologuous protein sequences decreases possible accuracy, since we are essentially demanding a margin of difference between the data distributions for the training and testing samples. It may not be possible to predict protein properties accurately using a statistical method if nonhomologuous protein sequences were filtered from the training set."
    }, {
      "heading" : "Discussion",
      "text" : "We have described a multilayer shift-and-stitch convolutional architecture for sequence prediction. We use ideas from the image classification domain to train a deep convolutional network on per-position sequence labeling. We are the first to use multilayer shift-and-stitch on protein se-\nModel Q8 CNF (Wang et al. 2011) .649 GSN (Zhou and Troyanskaya 2014) .664 LSTM (Kaae Sønderby and Winther 2014) .674 MUST-CNN (Ours) .684\nTable 5: Q8 accuracy training on the CullPDB dataset and testing on CB513. Testing takes around the same time as for the 4prot dataset. We use the same architecture as MUSTCNN large, detailed in table 2.\nquences to generate per-position results. Shift-and-stitch is a trick to quickly compute convolutional network scores on every single window of a sequence at the same time, but the fixed window sizes of the convolutional network still remains. Surprisingly, we achieve better results than whole sequence-based approaches like the GSN, LSTM, and CNF models used in previous papers (see Table 5). We believe this is because the speed of our model allows us to train models with far higher capacity. We show that the architecturally simpler MUST-CNN does as well or better than more complex approaches.\nIn our experiments, the same network works very well on two different large datasets of protein property prediction, in which we only changed the amount of dropout regularization. This suggests that our model is very robust and can produce good results without much manual tuning once we find a good starting set of hyperparameters. More generally, our technique should work on arbitrary per-position sequence tagging tasks, such as part of speech tagging and semantic role labeling.\nAdditionally, our model can make predictions for a million amino acids in under 2 seconds. Although the main speed bottleneck of protein property prediction is obtaining the PSI-BLAST features, the speed of our model can be useful on other sequence prediction tasks where feature extraction is not the bottleneck.\nFuture work can incorporate techiques such as the fully convolutional network (Long, Shelhamer, and Darrell 2014) to further speed up and reduce the parameter set of the model. Another direction is to continue along the lines of LSTMs and GSNs and try to better model the long range interactions of the protein sequences."
    } ],
    "references" : [ {
      "title" : "D",
      "author" : [ "S.F. Altschul", "T.L. Madden", "A.A. Schäffer", "J. Zhang", "Z. Zhang", "W. Miller", "Lipman" ],
      "venue" : "J.",
      "citeRegEx" : "Altschul et al. 1997",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Cho Bahdanau", "D. Bengio 2014] Bahdanau", "K. Cho", "Y. Bengio" ],
      "venue" : "arXiv preprint arXiv:1409.0473",
      "citeRegEx" : "Bahdanau et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2014
    }, {
      "title" : "and Weston",
      "author" : [ "R. Collobert" ],
      "venue" : "J.",
      "citeRegEx" : "Collobert and Weston 2008",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Natural language processing (almost) from scratch",
      "author" : [ "Collobert" ],
      "venue" : "The Journal of Machine Learning Research 12:2493–2537",
      "citeRegEx" : "Collobert,? \\Q2011\\E",
      "shortCiteRegEx" : "Collobert",
      "year" : 2011
    }, {
      "title" : "Torch7: A matlab-like environment for machine learning",
      "author" : [ "Kavukcuoglu Collobert", "R. Farabet 2011] Collobert", "K. Kavukcuoglu", "C. Farabet" ],
      "venue" : "In BigLearn,",
      "citeRegEx" : "Collobert et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Collobert et al\\.",
      "year" : 2011
    }, {
      "title" : "G",
      "author" : [ "J.A. Cuff", "Barton" ],
      "venue" : "J.",
      "citeRegEx" : "Cuff and Barton 2000",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "G",
      "author" : [ "A. Drozdetskiy", "C. Cole", "J. Procter", "Barton" ],
      "venue" : "J.",
      "citeRegEx" : "Drozdetskiy et al. 2015",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Deep sparse rectifier neural networks",
      "author" : [ "Bordes Glorot", "X. Bengio 2011] Glorot", "A. Bordes", "Y. Bengio" ],
      "venue" : "In International Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "Glorot et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Glorot et al\\.",
      "year" : 2011
    }, {
      "title" : "Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification",
      "author" : [ "He" ],
      "venue" : "arXiv preprint arXiv:1502.01852",
      "citeRegEx" : "He,? \\Q2015\\E",
      "shortCiteRegEx" : "He",
      "year" : 2015
    }, {
      "title" : "D",
      "author" : [ "Jones" ],
      "venue" : "T.",
      "citeRegEx" : "Jones 1999",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "and Winther",
      "author" : [ "S. Kaae Sønderby" ],
      "venue" : "O.",
      "citeRegEx" : "Kaae Sønderby and Winther 2014",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Y",
      "author" : [ "Kim" ],
      "venue" : "2014. Convolutional Neural Networks for Sentence Classification. arXiv:1408.5882 [cs]. arXiv:",
      "citeRegEx" : "Kim 2014",
      "shortCiteRegEx" : null,
      "year" : 1408
    }, {
      "title" : "P",
      "author" : [ "Y. Lecun", "L. Bottou", "Y. Bengio", "Haffner" ],
      "venue" : "1998. Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11):2278–",
      "citeRegEx" : "Lecun et al. 1998",
      "shortCiteRegEx" : null,
      "year" : 2324
    }, {
      "title" : "Fully convolutional networks for semantic segmentation",
      "author" : [ "Shelhamer Long", "J. Darrell 2014] Long", "E. Shelhamer", "T. Darrell" ],
      "venue" : "arXiv preprint arXiv:1411.4038",
      "citeRegEx" : "Long et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Long et al\\.",
      "year" : 2014
    }, {
      "title" : "and Baldi",
      "author" : [ "C.N. Magnan" ],
      "venue" : "P.",
      "citeRegEx" : "Magnan and Baldi 2014",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "R",
      "author" : [ "P.H.O. Pinheiro", "Collobert" ],
      "venue" : "2013. Recurrent Convolutional Neural Networks for Scene Parsing. arXiv:1306.2795 [cs]. arXiv:",
      "citeRegEx" : "Pinheiro and Collobert 2013",
      "shortCiteRegEx" : null,
      "year" : 1306
    }, {
      "title" : "W",
      "author" : [ "Y. Qi", "M. Oja", "J. Weston", "Noble" ],
      "venue" : "S.",
      "citeRegEx" : "Qi et al. 2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "S",
      "author" : [ "D. Scherer", "A. Müller", "Behnke" ],
      "venue" : "2010. Evaluation of pooling operations in convolutional architectures for object recognition. In Artificial Neural Networks–ICANN",
      "citeRegEx" : "Scherer. Müller. and Behnke 2010",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Overfeat: Integrated recognition, localization and detection using convolutional networks. arXiv preprint arXiv:1312.6229",
      "author" : [ "Sermanet" ],
      "venue" : null,
      "citeRegEx" : "Sermanet,? \\Q2013\\E",
      "shortCiteRegEx" : "Sermanet",
      "year" : 2013
    }, {
      "title" : "R",
      "author" : [ "J. Snoek", "H. Larochelle", "Adams" ],
      "venue" : "P.",
      "citeRegEx" : "Snoek. Larochelle. and Adams 2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Dropout: A simple way to prevent neural networks from overfitting",
      "author" : [ "Srivastava" ],
      "venue" : "The Journal of Machine Learning Research",
      "citeRegEx" : "Srivastava,? \\Q2014\\E",
      "shortCiteRegEx" : "Srivastava",
      "year" : 2014
    }, {
      "title" : "Q",
      "author" : [ "I. Sutskever", "O. Vinyals", "Le" ],
      "venue" : "V.",
      "citeRegEx" : "Sutskever. Vinyals. and Le 2014",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "A",
      "author" : [ "C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "Rabinovich" ],
      "venue" : "2014. Going Deeper with Convolutions. arXiv:1409.4842 [cs]. arXiv:",
      "citeRegEx" : "Szegedy et al. 2014",
      "shortCiteRegEx" : null,
      "year" : 1409
    }, {
      "title" : "W",
      "author" : [ "Touw" ],
      "venue" : "G.; Baakman, C.; Black, J.; te Beek, T. A. H.; Krieger, E.; Joosten, R. P.; and Vriend, G.",
      "citeRegEx" : "Touw et al. 2015",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Protein 8-class secondary structure prediction using conditional neural fields",
      "author" : [ "Wang" ],
      "venue" : "Proteomics",
      "citeRegEx" : "Wang,? \\Q2011\\E",
      "shortCiteRegEx" : "Wang",
      "year" : 2011
    }, {
      "title" : "O",
      "author" : [ "W. Zaremba", "I. Sutskever", "Vinyals" ],
      "venue" : "2014. Recurrent Neural Network Regularization. arXiv:1409.2329 [cs]. arXiv:",
      "citeRegEx" : "Zaremba. Sutskever. and Vinyals 2014",
      "shortCiteRegEx" : null,
      "year" : 1409
    }, {
      "title" : "O",
      "author" : [ "J. Zhou", "Troyanskaya" ],
      "venue" : "G.",
      "citeRegEx" : "Zhou and Troyanskaya 2014",
      "shortCiteRegEx" : null,
      "year" : 2014
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "Predicting protein properties such as solvent accessibility and secondary structure from its primary amino acid sequence is an important task in bioinformatics. Recently, a few deep learning models have surpassed the traditional window based multilayer perceptron. Taking inspiration from the image classification domain we propose a deep convolutional neural network architecture, MUST-CNN, to predict protein properties. This architecture uses a novel multilayer shift-and-stitch (MUST) technique to generate fully dense per-position predictions on protein sequences. Our model is significantly simpler than the state-of-the-art, yet achieves better results. By combining MUST and the efficient convolution operation, we can consider far more parameters while retaining very fast prediction speeds. We beat the state-of-the-art performance on two large protein property prediction datasets.",
    "creator" : "LaTeX with hyperref package"
  }
}