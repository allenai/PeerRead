{
  "name" : "1508.06161.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Robot Language Learning, Generation, and Comprehension",
    "authors" : [ "Daniel Paul Barrett", "Scott Alan Bronikowski", "Haonan Yu", "Jeffrey Mark Siskind" ],
    "emails" : [ "dpbarret@purdue.edu", "sbroniko@purdue.edu", "yu239@purdue.edu", "qobi@purdue.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "With recent advances in machine perception and robotic automation, it becomes increasingly relevant and important to allow machines to interact with humans in natural language in a grounded fashion, where the language refers to actual things and activities in the world. Here, we present our efforts to automatically drive— and learn to drive—a mobile robot under naturallanguage command. Our contribution is summarized in Fig. 1. A human teleoperator is given a set of sentential instructions designating robot paths. The operator then drives a mobile robot under radio control according to these instructions through a variety of floorplans. The robot uses onboard odometry and inertial guidance sensors to determine its location in real time and saves traces of the driving path to log files. From a training corpus of paths paired with sentential descriptions\nand floorplan specifications, our system automatically learns the meanings of nouns that refer to objects in the floorplan and prepositions that describe both the spatial relations between floorplan objects and between such objects and the robot path. With such learned meanings, the robot can then generate sentential descriptions of new driving activity undertaken by the teleoperator. Moreover, instead of manually controlling the robot through teleoperation, one can issue the robot natural-language commands which can induce fully automatic driving to satisfy the path specified in the naturallanguage command.\nWe have conducted experiments with an actual radio-controlled robot that demonstrate all three of these modes of operation: acquisition, generation, and comprehension. We demonstrate successful completion of all three of these tasks on hundreds of driving examples. We evaluate the fidelity of the sentential descriptions produced automatically in response to manual driving and the fidelity of the driving paths induced automatically to fulfill natural-language commands, by presenting the pairs of sentences together with the associated paths to human judges. Overall, the average “correctness” (the degree to which the description is true of the path) reported is 94.6% and the average “completeness” (the degree to which the description fully covers the path) reported is 85.6%."
    }, {
      "heading" : "2 Related Work",
      "text" : "We know of no other work which presents a physical robot which learns word meanings from physical robot paths paired with sentences, uses these learned meanings to generate sentential descriptions of manually driven paths, and automatically plans and physically drives paths to satisfy input sentential descriptions.\nWhile there is other work which claims to learn the meanings of words from robot paths or follow natural instructions, upon further inspection\nar X\niv :1\n50 8.\n06 16\n1v 1\n[ cs\n.R O\n] 2\n5 A\nug 2\n01 5\nthese systems operate only within discrete simulation, as they utilize the internal representation of the simulation to obtain discrete symbolic primitives (Tellex et al., 2014, 2011; Kollar et al., 2010; Chen and Mooney, 2011; MacMahon et al., 2006; Koller et al., 2010). Their space of possible robot actions, positions and states are very small and are represented in terms of symbolic primitives like TURN LEFT, TURN RIGHT, and MOVE FORWARD N STEPS (Chen and Mooney, 2011), or DRIVE TO LOCATION 1 and PICK UP PALLET 1 (Tellex et al., 2014). Thus, they take a sequence of primitives like {DRIVE TO LOCATION 1; PICK UP PALLET 1} and a sentence like go to the pallet and pick it up and learn that the word pallet maps to the primitive PALLET, that the phrase pick up maps to the primitive PICK UP, and that the phrase go to X means DRIVE TO LOCATION X.\nIn contrast, our robot and environment, being in the continuous physical world, can take an uncountably infinite number of configurations. We take a set of sentences matched with paths of the robot as input, where the paths are densely sampled points in the real 2D Cartesian plane. Not all points in the path correspond to words in the sentences, multiple (often undescribed) relationships can be true of any point, and the correspondence between described relationships and path points is unknown. This is a vastly more difficult problem.\nFurthermore, previous work does not even solve the simplified problem without additional annotation. Kollar et al. (2010) requires hand-drawn\npositive and negative paths depicting specific word meanings. Tellex et al. (2011) requires manual annotation of the groundings of all words in the training sentences to specific objects and relationships in the training data. Tellex et al. (2014) does not require annotation of the grounding of each word, but does require manual temporal segmentation and alignment of paths and the pieces of multi-part sentences, whereas our method can learn without any such annotation.\nDobnik et al. (2005) has an actual robot but only learns to classify simple phrases like A is near B from robot paths paired with such phrases that have hand-grounded nouns. They can neither generate sentences describing driven paths, nor automatically drive a path described by a sentence. Our system can do both of these, as well as learn meanings for both nouns and prepositions."
    }, {
      "heading" : "3 Our Mobile Robot",
      "text" : "All experiments were performed on a custom mobile robot (Fig. 2). This robot can be driven by a human teleoperator or drive itself automatically to accomplish specified navigational goals. During all operation, robot localization is performed onboard the robot in real-time via an Extended Kalman Filter (Jazwinski, 1970) with odometry from shaft encoders on the wheels and inertialguidance from an IMU.\nDue to sensor noise and mechanical factors such as wheel sliding, this localization is noisy, but generally within 20cm of the actual location. The\nvideo feed, localization, and all sensor and actuator data is logged in a time-stamped format. When conducting experiments on generation and acquisition, a human teleoperator drives the robot along a variety of paths in a variety of floorplans. The path recovered from localization supports generation and acquisition. When conducting experiments on comprehension, the path is first planned automatically, then the robot automatically follows its planned path by comparing the new odometry gathered in real time with the planned path and controlling the wheels accordingly.\nThe use of an actual robot with noisy real-world sensor data increases the difficulty of the tasks when compared to work which occurs in simulation. The noisy robot position is densely sampled in the continuous domain. For acquisition and generation, this adds an additional layer of uncertainty, as the correspondence between individual points in the robot path and the phrases of a sentence is unknown."
    }, {
      "heading" : "4 Technical Details",
      "text" : ""
    }, {
      "heading" : "4.1 Grammar and Logical Form",
      "text" : "We employ the grammar shown in Fig. 3, which, while small, supports an infinite set of possible utterances, unlike the grammars used in Teller et al. (2010) and Harris et al. (2005). Nothing turns on this however. In principle, one could replace this grammar with any other mechanism for generating logical form. This paper concerns itself with semantics, not syntax, and only addresses issues relating to the grounding of logical form. This particular grammar is simply a convenient surface representation of our logical form.\nNote that our surface syntax allows two uses\nof prepositions (and the associated prepositional phrases): as modifiers to nouns in noun phrases, indicated with a subscript ‘SR’ (i.e., spatial relation), and as adjuncts to verbs in verb phrases, indicated with a subscript ‘path.’ Many prepositions can be used in both SR and path form. They share the same semantic representation and both uses are learned from the pooled data of both kinds of occurrences in the training corpus. Furthermore, note that the grammar supports infinite NP recursion: noun phrases can contain prepositional phrases that, in turn, contain noun phrases. Finally, note that the grammar supports conjunctions of prepositional phrases in both SR and path form.\nWe employ the logical form shown in Fig. 4. Informally, formulas in logical form denote paths through a floorplan. Both paths and floorplans are specified as collections of waypoints. A waypoint is a 2D Cartesian coordinate optionally labeled with the class of the object that resides at that coordinate, e.g., (3, 47,bag) The waypoint is unlabeled, e.g.,(3, 47), if no object resides at that coordinate. A floorplan is a set of labeled waypoints, while a path is a sequence of unlabeled waypoints (Fig. 5 right). A formula in logical form contains three parts: a path quantifier, a floorplan quantifier, and a condition that the path through the floorplan must satisfy. The condition is a conjunction of atomic formulas, predicates applied to variables bound by the path or floorplan quantifiers. The formula must be closed, i.e., every variable in the condition must appear either in the path quantifier or the floorplan quantifier. The model of a formula is a set of bindings for each of the quantified path variables to unlabeled waypoints, and floorplan variables to labeled waypoints.\nThe one-argument atomic formulas constrain the class of waypoints to which the variables that appear as their arguments are bound. The twoargument atomic formulas constrain the spatial relations between pairs of waypoints to which the variables that appear as their arguments are bound. The logical form in Fig. 4 contains a particular\nset of six one-argument predicate and six twoargument predicates. Nothing turns on this however. This is simply the set of predicates that we use in the experiments reported. The framework clearly extends to any number of predicates of any arity, particularly since we learn the meanings of the predicates.\nStraightforward (semantic) parsing and surface generation techniques map bidirectionally between the surface language form as specified by the grammar in Fig. 3 and the logical form in Fig. 4. For example, a surface form like\nThe robot went towards the stool, then went behind the chair which is right of the stool, then went towards the cone, then went away from the chair which is left of the cone, then went in front of the table.\n(commas added for legibility) would correspond to the following logical form:\n[α, β, γ, δ, ]{t, u, v, w, x, y, z}  TOWARDS(α, t) ∧ STOOL(t)∧ BEHIND(β, u) ∧ CHAIR(u) ∧ RIGHTOF(u, v) ∧ STOOL(v)∧ TOWARDS(γ,w) ∧ CONE(w)∧ AWAYFROM(δ, x) ∧ CHAIR(x) ∧ LEFTOF(x, y) ∧ CONE(y)∧ INFRONTOF( , z) ∧ TABLE(z)  (1)\nNote that in the above, nouns all correspond to one-argument predicates while prepositions all correspond to two-argument predicates. But nothing turns on this. One could imagine lexical prepositional phrases, like leftward, that correspond to one-argument predicates. Moreover,\npath uses of prepositions specify waypoints in the path. These appear in logical form as predicates whose first argument is a variable in the path quantifier. Similarly, SR uses of prepositions specify waypoints in the floorplan. These appear in logical form as predicates whose first argument is a variable in the floorplan quantifier. Thus, in the above, the atomic formulas TOWARDS(α, t), BEHIND(β, u), TOWARDS(γ,w), AWAYFROM(δ, x), and INFRONTOF( , z) constitute path uses while the atomic formulas RIGHTOF(u, v) and LEFTOF(x, y) constitute SR uses. Note that each (path) prepositional phrase consists of a subset of the atomic formulas in the condition, as indicated above by the line breaks."
    }, {
      "heading" : "4.2 Representation of the Lexicon",
      "text" : "The lexicon specifies the meanings of the oneand two-argument predicates in logical form. The meanings of one-argument predicates are discrete distributions over the set of class labels. Note that the one-argument predicates, like BAG, are distinct from the class labels, like bag. The mapping between such is learned. Moreover, a given floorplan might have multiple instances of objects of the same class. These would be disambiguated with complex noun phrases such as the chair which is right of the stool and the chair which is left of the cone. Such disambiguating prepositional phrase modifiers of noun phrases can be nested and conjoined arbitrarily. Similarly, waypoints can be disambiguated by conjunctions of prepositional phrase adjuncts.\nTwo-argument predicates specify relations between target objects and reference objects. In SR uses, the reference object is the object of the preposition while the target object is the head noun. For example, in the chair to the left of the table, chair is the target object and table is the reference object. In path uses, the target object is a waypoint in the robot path while the reference object is the object of the preposition. For example, in went towards the table, table is the reference object. The lexical entry for each two-argument predicate is specified as the location µ and concentration κ parameters for multiple independent von Mises distributions (Abramowitz and Stegun, 1972) for a variety of angles between target and reference objects.\nThe meanings of two-argument predicates are specified as a pair of von Mises distributions on\nangles. One, the position angle, is the orientation of a vector from the coordinates of the reference object to the coordinates of the target object (Fig. 6 left).1 The same distribution is used both for SR and path uses. The second, the velocity angle, is the angle between the velocity vector at a waypoint and a vector from the coordinates of the waypoint to the coordinates of the reference object (Fig. 6 right). This is only used for path uses, because it requires computation of the direction of robot motion which is determined from adjacent waypoints in the path. This angle is thus taken from the frame of reference of the robot.\nFig. 1(bottom left) illustrates how this framework is used to represent the meanings of prepositions. Here, we render the angular distributions as potential fields around the reference object at the center for the position angle, and the target object at the center for the velocity angle. The intensity of a point (target object for position angle) reflects its probability mass. Note that the distributions are uniform in velocity angle for left of, right of, in front of, and behind and in position angle for towards and away from."
    }, {
      "heading" : "4.3 Tasks",
      "text" : "We formulate sentential semantics as a variety of relationships between a sentence s, or more precisely a formula in logical form, a path p, a sequence of unlabeled waypoints, a floorplan f , a set of labeled waypoints, and a lexicon Λ, the collective µ and κ parameters for the angular distributions for each of the two-argument predicates and the discrete distributions for each of the oneargument predicates. acquisition Learn a lexicon Λ from a collection\nof observed paths pi taken by the robot in the corresponding floorplans fi as described by human-generated sentences si.\ngeneration Generate a sentence s that describes an observed path p taken by the robot in a\n1Without loss of generality, angles are measured in the frame of reference of the robot prior to the beginning of action, which is taken to be the origin.\ngiven floorplan f with a known lexicon Λ. comprehension Generate a path p to be taken by\nthe robot that satisfies a given sentence s issued as a command in a given floorplan f with a known lexicon Λ."
    }, {
      "heading" : "4.3.1 Acquisition",
      "text" : "To perform acquisition, we formulate a large hidden Markov model (HMM), with a state k for every path prepositional phrase PPpath,k in each sentence in the training corpus. The observations for this HMM are the sequences of path waypoints in the training corpus. Each state’s output model sums over all mappings m between object references in the PPpath,k and floorplan waypoints. Given such a mapping, the output model for a state k consists of the product of the probabilities P determined by each atomic formula i in the logical form derived from PPpath,k, given the probability models for the predicates as specified by the current estimates of the parameters in Λ:\nRk(PPpath,k,p, f ,Λ,m) =∏ i P (wai0 . . . waiNi |Λi,m)\n(2)\nwhere w is the set of all path and floorplan waypoints, and where aij is the index in w of the jth argument of the ith atomic formula.\nThe transition matrix for the HMM is constructed from the sentences in the training corpus to allow each state only to self loop or to transition to the state for the next path prepositional phrase in the training sentence. The HMM is constrained to start in the state associated with the first path prepositional phrase in the sentence associated with each path. We add dummy states, with a small fixed output probability, between the states for each pair of adjacent path prepositional phrases, as well as at the beginning and end of each sentence, to allow for portions of the path that are not described in the associated sentence. We then train this HMM with Baum-Welch (Baum and Petrie, 1966; Baum et al., 1970; Baum, 1972). This trains the distributions for the words in the lexicon Λ as they are tied as components of the output models. Specifically, it infers the latent alignment between the noisy robot path waypoints and the phrases in the training data while simultaneously updating the meanings of the words to match the relationships between waypoints described in the corpus. In this way, the meanings of both the nouns and the prepositions are learned."
    }, {
      "heading" : "4.3.2 Generation",
      "text" : "Language generation takes as input a path p obtained by odometry during human teleoperation of the robot. This path consists of a collection of 2D floor positions sampled at 50Hz. To generate a formula in logical form, and thus the corresponding sentence, one must select a subsequence of this dense sequence worthy of description.\nDuring generation, we care about three properties: “correctness,” that the sentence be logically true of the path, “completeness,” that the sentence differentiate the intended path from all other possible paths, and “conciseness,” that the sentence be the shortest that does so. We attempt to find a balance between these properties with the following heuristic algorithm (Fig. 7). First, we sample path waypoints in a way that the sampled points evenly distribute along the path. To this end, we downsample the path by computing the integral distance traveled from the initial position for each point in the dense path and selecting a subsequence whose points are separated by 5cm of integral path length. We then produce a path prepositional phrase to describe each path waypoint by selecting that atomic formula with maximum posterior probability constructed out of a two-argument predicate with the path waypoint as its first argument and with a floorplan waypoint as its second argument. Identical such choices for consecutive sets of waypoints in the path are coalesced and short intervals of path prepositional phrases are discarded. We then generate a noun phrase for the object of each waypoint preposition that refers to that referenced floorplan waypoint. We take a one-argument predicate to be true of that class with maximum posterior probability and false of all others. Similarly, for each pair of floor-\nplan waypoints, we take that two-argument predicate with maximum posterior probability to be true of that tuple and all other predicates applied to that tuple to be false. Thus when the floorplan contains a single instance of a class, it can be referred to with a simple noun. But when there are multiple instances of a class, the shortest possible noun phrase, with one or more SR prepositional phrases, is generated to disambiguate.\nMore formally, let c(e) be the class name of the object at the floorplan waypoint e. For each pair of floorplan waypoints (e, en), there exists only one two-argument spatial-relation predicate φn that is true of this tuple. Let d(e) be the noun phrase we want to generate to disambiguate the floorplan waypoint e from others en. Then e can be referred to with d(e) unambiguously if (a) d(e) = (c(e), {}) is unique; or (b), there exists a collection of two-argument predicates {φn(e, en)} such that formula d(e) = (c(e), {(φn, d(en))}) is unique. To produce a concise sentence, we want the size of the collection of two-argument predicates in step (b) above to be as small as possible. However, finding the smallest collection of modifiers is NP-hard (Dale and Reiter, 1995). To avoid exhaustive search, we use a greedy heuristic that biases towards adding the least frequent pairs (φn, d(en)) into the collection until d(e) is unique. This results in a tractable polynomial algorithm. After we get d(e), we turn it into a noun phrase by simple realization, for example:\n(TABLE, {(LEFT-OF, CHAIR), (BEHIND, TABLE)}) ↓\nthe table which is left of the chair and behind the table"
    }, {
      "heading" : "4.3.3 Comprehension",
      "text" : "To perform comprehension, we use gradient ascent to optimize the scoring function with respect to an unknown path p\np∗ = arg max p R(s,p, f ,Λ)\nwhere R(s,p, f ,Λ) is the product of all Rk from Eq. 2. We are computing a MAP estimate of the joint probability of satisfying the conjunction of atomic formulas assuming that they are independent.\nThe above scoring function alone is insufficient. It represents the strict meaning of the sentence, but does not take into account constraints of the world, such as the need to avoid collision with the objects in the floorplan. It can also be difficult to optimize\nbecause the cost associated with the relative orientation between two waypoints becomes increasingly sensitive to small changes in position as they become closer together. To remedy the problems of the path waypoints getting too close to objects and to each other, a barrier penalty term is added between each pair of a path waypoint and floorplan waypoint as well as between pairs of temporally adjacent path waypoints to prevent them from becoming too close. This term is 1 until the distance between the two waypoints becomes less than a threshold, at which point it decreases rapidly. Finally, our formulation of the semantics of prepositions is based on angles but not distance. Thus there is is a large subspace of the floor that leads to equal probability of satisfying each atomic formula, i.e., the cones in Fig. 1. This allows a path to satisfy a prepositional phrase like to the left of the chair by being far away from the chair. To remedy this, we add a small attraction between each path waypoint and the floorplan waypoints selected as its reference objects to prefer short distances. A postprocessing step performs obstacle avoidance by adding additional path waypoints as needed."
    }, {
      "heading" : "5 Experiments",
      "text" : "We conducted an experiment as outlined in Fig. 1. We generated 250 random sentences from the grammar in Fig. 3, 25 in each of 10 different floorplans that were randomly generated to place either 4 or 5 objects, with 2 objects always being of the same class, to introduce ambiguity requiring disambiguation via SR prepositional phrases, at one of 12 possible grid positions. Path data was logged while a human teleoperator manually drove the robot to comply with these sentential instructions in these floorplans (Fig. 8 top). Models were learned for each of the nouns and prepositions. These were used to automatically generate descriptions for 10 different new paths manually driven by a human teleoperator in 10 new random floorplans (Fig. 8 middle). These were also used to automatically drive the robot to follow 10 different new random sentences in each of 10 different new random floorplans where the same objects could be placed at one of 56 possible grid positions (Fig. 8 bottom). The random sentences used for training had either 2 or 3 path waypoints while those used for generation and comprehension had either 5 or 6 path waypoints.\nOdometry and inertial guidance were used to\ndetermine paths driven. Pairs of sentences and paths obtained during both generation and comprehension were given to a pool of 6 independent judges to obtain 3 judgments on each. Judges were asked to label each path prepositional phrase in each sentence paired with the entire path as being either ‘correct’ or ‘incorrect’, i.e., whether it was true of the intended portion of the path as determined by that judge. For generation, judges were also asked to assess how much of the path was described by the sentence, giving a completeness judgment ranging from 0 (worst) to 5 (best). These were converted to percentages. For comprehension, judges were also asked to assess what fraction of the path constitutes motion that is described by the sentence (quantized as 0 to 5). These were again converted to percentages to measure completeness. For generation, judgments were obtained twice, pairing each input path with sentences generated using the hand-constructed models from Fig. 1 as well the learned models from Fig. 8. For comprehension, judgments were also obtained twice, pairing each input sentence with both the planned path as well as the actually driven path as determined by odometry and inertial guidance. Fig. 9(top) summarizes the judgments aggregated across the 3 judges and 100 samples. The standard deviations are across the mean value of the 3 judges for each sample. Overall, the average “correctness” reported is 94.6% and the average “completeness” reported is 85.6%.\nFor generation, we also measured “conciseness” by having the 3 human judges score each generated sentence as -2 (much too short), -1 (too short), 0 (about right), 1 (too long), or 2 (much too long). Fig. 9(bottom) summarize these judgments as histograms. Overall, judges assessed that the generated sentence length was ‘about right’ a little\nover half of the time, with generation erring more towards being too long than too short."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We demonstrate a novel approach for grounding the semantics of natural language in the domain of robot navigation. Sentences describe paths taken by the robot relative to other objects in the environment. The meanings of nouns and prepositions are trained from a corpus of paths driven by a human teleoperator annotated with sentential descriptions. These can then support both automatic generation of sentential descriptions of new paths driven as well as automatic driving of paths to satisfy navigational goals specified in provided sentences. This is a step towards the ultimate goal of grounded natural language that allows machines to interact with humans when the language refers to actual things and activities in the real world."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This research was sponsored, in part, by the Army Research Laboratory and was accomplished under Cooperative Agreement Number W911NF-10-20060. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either express or implied, of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes, notwithstanding any copyright notation herein."
    } ],
    "references" : [ {
      "title" : "Handbook of mathematical functions",
      "author" : [ "M. Abramowitz", "I.A. Stegun" ],
      "venue" : null,
      "citeRegEx" : "Abramowitz and Stegun,? \\Q1972\\E",
      "shortCiteRegEx" : "Abramowitz and Stegun",
      "year" : 1972
    }, {
      "title" : "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process",
      "author" : [ "L.E. Baum" ],
      "venue" : null,
      "citeRegEx" : "Baum,? \\Q1972\\E",
      "shortCiteRegEx" : "Baum",
      "year" : 1972
    }, {
      "title" : "Statistical inference for probabilistic functions of finite state Markov chains",
      "author" : [ "L.E. Baum", "T. Petrie" ],
      "venue" : null,
      "citeRegEx" : "Baum and Petrie,? \\Q1966\\E",
      "shortCiteRegEx" : "Baum and Petrie",
      "year" : 1966
    }, {
      "title" : "A maximization technique occuring in the statistical analysis of probabilistic functions of Markov chains",
      "author" : [ "L.E. Baum", "T. Petrie", "G. Soules", "N. Weiss" ],
      "venue" : null,
      "citeRegEx" : "Baum et al\\.,? \\Q1970\\E",
      "shortCiteRegEx" : "Baum et al\\.",
      "year" : 1970
    }, {
      "title" : "Reading between the lines: Learning to map high-level instructions to commands",
      "author" : [ "S.R.K. Branavan", "L.S. Zettlemoyer", "R. Barzilay" ],
      "venue" : "In ACL,",
      "citeRegEx" : "Branavan et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Branavan et al\\.",
      "year" : 2010
    }, {
      "title" : "Type-logical semantics",
      "author" : [ "B. Carpenter" ],
      "venue" : null,
      "citeRegEx" : "Carpenter,? \\Q1997\\E",
      "shortCiteRegEx" : "Carpenter",
      "year" : 1997
    }, {
      "title" : "Learning to interpret natural language navigation instructions from observations",
      "author" : [ "D.L. Chen", "R.J. Mooney" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Chen and Mooney,? \\Q2011\\E",
      "shortCiteRegEx" : "Chen and Mooney",
      "year" : 2011
    }, {
      "title" : "Driving semantic parsing from the world’s response",
      "author" : [ "J. Clarke", "D. Goldwasser", "Chang", "M.-W", "D. Roth" ],
      "venue" : "In Conference on Computational Natural Language Learning,",
      "citeRegEx" : "Clarke et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Clarke et al\\.",
      "year" : 2010
    }, {
      "title" : "Computational interpretations of the gricean maxims in the generation of referring expressions",
      "author" : [ "R. Dale", "E. Reiter" ],
      "venue" : "Cognitive Science,",
      "citeRegEx" : "Dale and Reiter,? \\Q1995\\E",
      "shortCiteRegEx" : "Dale and Reiter",
      "year" : 1995
    }, {
      "title" : "Teaching a robot spatial expressions",
      "author" : [ "S. Dobnik", "S. Pulman", "P. Newman", "A. Harrison" ],
      "venue" : "Proceedings of the Second ACLSIGSEM Workshop on The Linguistic Dimensions of Prepositions and their Use in Computa-",
      "citeRegEx" : "Dobnik et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Dobnik et al\\.",
      "year" : 2005
    }, {
      "title" : "Heterogeneous multi-robot dialogues for search tasks",
      "author" : [ "T.K. Harris", "S. Banerjee", "A.I. Rudnicky" ],
      "venue" : "In Proceedings of the AAAI Spring Symposium Intelligence",
      "citeRegEx" : "Harris et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Harris et al\\.",
      "year" : 2005
    }, {
      "title" : "Semantic processing using the hidden vector state model",
      "author" : [ "Y. He", "S. Young" ],
      "venue" : "Computer Speech & Language,",
      "citeRegEx" : "He and Young,? \\Q2005\\E",
      "shortCiteRegEx" : "He and Young",
      "year" : 2005
    }, {
      "title" : "Generative models for statistical parsing with combinatory categorial grammar",
      "author" : [ "J. Hockenmaier", "M. Steedman" ],
      "venue" : "In ACL,",
      "citeRegEx" : "Hockenmaier and Steedman,? \\Q2002\\E",
      "shortCiteRegEx" : "Hockenmaier and Steedman",
      "year" : 2002
    }, {
      "title" : "Stochastic Processes and Filtering Theory",
      "author" : [ "A.H. Jazwinski" ],
      "venue" : null,
      "citeRegEx" : "Jazwinski,? \\Q1970\\E",
      "shortCiteRegEx" : "Jazwinski",
      "year" : 1970
    }, {
      "title" : "A new approach to linear filtering and prediction problems",
      "author" : [ "R.E. Kalman" ],
      "venue" : "Journal of Fluids Engineering,",
      "citeRegEx" : "Kalman,? \\Q1960\\E",
      "shortCiteRegEx" : "Kalman",
      "year" : 1960
    }, {
      "title" : "Toward understanding natural language directions",
      "author" : [ "T. Kollar", "S. Tellex", "D. Roy", "N. Roy" ],
      "venue" : "In International Conference on HumanRobot Interaction,",
      "citeRegEx" : "Kollar et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Kollar et al\\.",
      "year" : 2010
    }, {
      "title" : "Gradient-based learning applied to document recognition",
      "author" : [ "Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner" ],
      "venue" : "Proceedings of the IEEE,",
      "citeRegEx" : "LeCun et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "LeCun et al\\.",
      "year" : 1998
    }, {
      "title" : "Walk the talk: connecting language, knowledge, and action in route instructions",
      "author" : [ "M. MacMahon", "B. Stankiewicz", "B. Kuipers" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "MacMahon et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "MacMahon et al\\.",
      "year" : 2006
    }, {
      "title" : "Seeing what you’re told: Sentenceguided activity recognition in video",
      "author" : [ "N. Siddharth", "A. Barbu", "J.M. Siskind" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Siddharth et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Siddharth et al\\.",
      "year" : 2014
    }, {
      "title" : "Surface structure and interpretation",
      "author" : [ "M. Steedman" ],
      "venue" : null,
      "citeRegEx" : "Steedman,? \\Q1996\\E",
      "shortCiteRegEx" : "Steedman",
      "year" : 1996
    }, {
      "title" : "The syntactic process",
      "author" : [ "M. Steedman" ],
      "venue" : null,
      "citeRegEx" : "Steedman,? \\Q2000\\E",
      "shortCiteRegEx" : "Steedman",
      "year" : 2000
    }, {
      "title" : "A voicecommandable robotic forklift working alongside humans in minimally-prepared outdoor",
      "author" : [ "S. Teller", "M.R. Walter", "M. Antone", "A. Correa", "R. Davis", "L. Fletcher", "E. Frazzoli", "J. Glass", "J.P. How", "Huang", "A. S" ],
      "venue" : null,
      "citeRegEx" : "Teller et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Teller et al\\.",
      "year" : 2010
    }, {
      "title" : "Understanding natural language commands for robotic navigation and mobile manipulation",
      "author" : [ "S. Tellex", "T. Kollar", "S. Dickerson", "M.R. Walter", "A.G. Banerjee", "S.J. Teller", "N. Roy" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Tellex et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Tellex et al\\.",
      "year" : 2011
    }, {
      "title" : "Learning perceptually grounded word meanings from unaligned parallel data",
      "author" : [ "S. Tellex", "P. Thaker", "J. Joseph", "N. Roy" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Tellex et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Tellex et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "these systems operate only within discrete simulation, as they utilize the internal representation of the simulation to obtain discrete symbolic primitives (Tellex et al., 2014, 2011; Kollar et al., 2010; Chen and Mooney, 2011; MacMahon et al., 2006; Koller et al., 2010).",
      "startOffset" : 156,
      "endOffset" : 271
    }, {
      "referenceID" : 6,
      "context" : "these systems operate only within discrete simulation, as they utilize the internal representation of the simulation to obtain discrete symbolic primitives (Tellex et al., 2014, 2011; Kollar et al., 2010; Chen and Mooney, 2011; MacMahon et al., 2006; Koller et al., 2010).",
      "startOffset" : 156,
      "endOffset" : 271
    }, {
      "referenceID" : 17,
      "context" : "these systems operate only within discrete simulation, as they utilize the internal representation of the simulation to obtain discrete symbolic primitives (Tellex et al., 2014, 2011; Kollar et al., 2010; Chen and Mooney, 2011; MacMahon et al., 2006; Koller et al., 2010).",
      "startOffset" : 156,
      "endOffset" : 271
    }, {
      "referenceID" : 6,
      "context" : "Their space of possible robot actions, positions and states are very small and are represented in terms of symbolic primitives like TURN LEFT, TURN RIGHT, and MOVE FORWARD N STEPS (Chen and Mooney, 2011), or DRIVE TO LOCATION 1 and PICK UP PALLET 1 (Tellex et al.",
      "startOffset" : 180,
      "endOffset" : 203
    }, {
      "referenceID" : 23,
      "context" : "Their space of possible robot actions, positions and states are very small and are represented in terms of symbolic primitives like TURN LEFT, TURN RIGHT, and MOVE FORWARD N STEPS (Chen and Mooney, 2011), or DRIVE TO LOCATION 1 and PICK UP PALLET 1 (Tellex et al., 2014).",
      "startOffset" : 249,
      "endOffset" : 270
    }, {
      "referenceID" : 15,
      "context" : "Kollar et al. (2010) requires hand-drawn positive and negative paths depicting specific word meanings.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 15,
      "context" : "Kollar et al. (2010) requires hand-drawn positive and negative paths depicting specific word meanings. Tellex et al. (2011) requires manual annotation of the groundings of all words in the training sentences to specific objects and relationships in the training data.",
      "startOffset" : 0,
      "endOffset" : 124
    }, {
      "referenceID" : 15,
      "context" : "Kollar et al. (2010) requires hand-drawn positive and negative paths depicting specific word meanings. Tellex et al. (2011) requires manual annotation of the groundings of all words in the training sentences to specific objects and relationships in the training data. Tellex et al. (2014) does not require annotation of the grounding of each word, but does require manual temporal segmentation and alignment of paths and the pieces of multi-part sentences, whereas our method can learn without any such annotation.",
      "startOffset" : 0,
      "endOffset" : 289
    }, {
      "referenceID" : 13,
      "context" : "During all operation, robot localization is performed onboard the robot in real-time via an Extended Kalman Filter (Jazwinski, 1970) with odometry from shaft encoders on the wheels and inertialguidance from an IMU.",
      "startOffset" : 115,
      "endOffset" : 132
    }, {
      "referenceID" : 20,
      "context" : "3, which, while small, supports an infinite set of possible utterances, unlike the grammars used in Teller et al. (2010) and Harris et al.",
      "startOffset" : 100,
      "endOffset" : 121
    }, {
      "referenceID" : 10,
      "context" : "(2010) and Harris et al. (2005). Nothing turns on this however.",
      "startOffset" : 11,
      "endOffset" : 32
    }, {
      "referenceID" : 0,
      "context" : "The lexical entry for each two-argument predicate is specified as the location μ and concentration κ parameters for multiple independent von Mises distributions (Abramowitz and Stegun, 1972) for a variety of angles between target and reference objects.",
      "startOffset" : 161,
      "endOffset" : 190
    }, {
      "referenceID" : 2,
      "context" : "We then train this HMM with Baum-Welch (Baum and Petrie, 1966; Baum et al., 1970; Baum, 1972).",
      "startOffset" : 39,
      "endOffset" : 93
    }, {
      "referenceID" : 3,
      "context" : "We then train this HMM with Baum-Welch (Baum and Petrie, 1966; Baum et al., 1970; Baum, 1972).",
      "startOffset" : 39,
      "endOffset" : 93
    }, {
      "referenceID" : 1,
      "context" : "We then train this HMM with Baum-Welch (Baum and Petrie, 1966; Baum et al., 1970; Baum, 1972).",
      "startOffset" : 39,
      "endOffset" : 93
    }, {
      "referenceID" : 8,
      "context" : "However, finding the smallest collection of modifiers is NP-hard (Dale and Reiter, 1995).",
      "startOffset" : 65,
      "endOffset" : 88
    } ],
    "year" : 2015,
    "abstractText" : "We present a unified framework which supports grounding natural-language semantics in robotic driving. This framework supports acquisition (learning grounded meanings of nouns and prepositions from human annotation of robotic driving paths), generation (using such acquired meanings to generate sentential description of new robotic driving paths), and comprehension (using such acquired meanings to support automated driving to accomplish navigational goals specified in natural language). We evaluate the performance of these three tasks by having independent human judges rate the semantic fidelity of the sentences associated with paths, achieving overall average correctness of 94.6% and overall average completeness of 85.6%.",
    "creator" : "LaTeX with hyperref package"
  }
}