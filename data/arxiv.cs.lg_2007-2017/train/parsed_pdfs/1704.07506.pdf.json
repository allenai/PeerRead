{
  "name" : "1704.07506.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Some Like it Hoax: Automated Fake News Detection in Social Networks",
    "authors" : [ "Eugenio Tacchini", "Gabriele Ballarin", "Marco L. Della Vedova", "Stefano Moret", "Luca de Alfaro" ],
    "emails" : [ "eugenio.tacchini@unicatt.it", "gabriele.ballarin@gmail.com", "marco.dellavedova@unicatt.it", "moret.stefano@gmail.com", "luca@ucsc.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "As a contribution towards this objective, we show that Facebook posts can be classified with high accuracy as hoaxes or non-hoaxes on the basis of the users who “liked” them. We present two classification techniques, one based on logistic regression, the other on a novel adaptation of boolean crowdsourcing algorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users, we obtain classification accuracies exceeding 99% even when the training set contains less than 1% of the posts. We further show that our techniques are robust: they work even when we restrict our attention to the users who like both hoax and non-hoax posts. These results suggest that mapping the diffusion pattern of information can be a useful component of automatic hoax detection systems."
    }, {
      "heading" : "1 Introduction",
      "text" : "The World Wide Web (WWW) has revolutionized the way in which information is disseminated. In particular, social network sites (SNSs) are platforms where content\nar X\niv :1\n70 4.\n07 50\n6v 1\ncan be freely shared, enabling users to actively participate to - and, possibly, influence - information diffusion processes. As a consequence, SNSs are also increasingly used as vectors for the dissemination of spam [10], conspiracy theories and hoaxes, i.e. intentionally crafted fake information. This recently led to the emphatic definition of our current times as the age of misinformation [3]. A significant share of hoaxes on SNSs diffuses rapidly, with a peak in the first 2 hours [6]. This finding, together with the high amount of shared content, highlights the need of automatic online hoax detection systems [9].\nIn the literature, various approaches have been proposed for automatic hoax detection, covering quite heterogeneous applications. Historically, one of the first applications has been hoax detection in e-mail messages and webpages. In the context of scam e-mail detection, spamassassin uses keyword-based methods with logistic regression [16]; Petković et al. [18] and Ishak et al. [11] proposed the use of distance-based methods; Vuković et al. [21] applied neural network and advanced text processing; Yevseyeva et al. [22] used evolutionary algorithms for the development of anti-spam filters. Sharifi et al. [20] applied logistic regression to automatically detect scam on webpages, reaching an accuracy of 98%.\nThe concepts of trust and reputation [17, 7] can be adopted for hoax detection in applications with a dominant social component. Metrics and algorithms for this purpose have been proposed by Golbeck and Hendler [8]. Adler and de Alfaro [2] developed a content-driven user reputation system for Wikipedia, allowing to predict the quality of new contributions. The detection of Wikipedia hoaxes has been addressed e.g. in [19, 1, 14]. More recently, automatic hoax detection in SNSs has gained increasing interest. As an example, Chen et al. [4] developed a semi-supervised scam detector for Twitter based on self-learning and clustering analysis, while Ito et al. [12] proposed the use of Latent Dirichlet Allocation (LDA) to assess the credibility of tweets.\nThe key idea behind our work, which constitutes its main novelty, is that hoaxes can be identified with great accuracy on the basis of the users that interact with them. In particular, focusing on Facebook, we answer the following research question: Can a hoax be identified based on the users who “liked” it? We consider a dataset consisting of 15,500 posts and 909,236 users; the posts originate from pages that deal with either scientific topics or with conspiracies and fake scientific news [3]. We propose two classification techniques. One consists in applying logistic regression, considering the user interaction with posts as features. The other technique consists in a novel adaptation of boolean label crowdsourcing techniques to a setting where a training set is available, but no prior assumption on users being mostly reliable can be made.\nThe proposed techniques yield an accuracy exceeding 99% even for training sets consisting of less of 1% of posts. These results are obtained in spite of the fact that the communities of users participating in the scientific and conspiracy pages overlap. Our main contributions, in summary, are: i) the proposal of a novel way to identify hoaxes on SNSs based on the users who interacted with them rather than their content; ii) an improved version of the harmonic crowdsourcing method, suited to hoax detection in SNSs; iii) the application on Facebook and, in particular, on a representative dataset obtained from the literature.\nThe code we developed for this paper is available from https://github.com/ gabll/some-like-it-hoax."
    }, {
      "heading" : "2 Dataset",
      "text" : "Our dataset consists in all the public posts and posts’ likes of a list of selected Facebook pages during the second semester of 2016: from Jul. 1st, 2016 to Dec. 31st, 2016. We collected the data by means of the Facebook Graph API1 on Jan. 27th, 2017.\nWe based our selection of pages on [3]. In that work, the authors present a list of Facebook pages divided into two categories: scientific news sources vs. conspiracy news sources. We assume all posts from scientific pages to be reliable, i.e. “nonhoaxes”, and all posts from conspiracy pages to be “hoaxes”. Among the 73 pages listed in [3], we limited our analysis to the top 20 pages of both categories. It is worth noting that at the time of data collection, not all the pages were still available: some of them had been deleted in the meantime, or were no longer publicly accessible. We note also that the actual posts comprising our dataset are distinct from those originally included in the dataset of [3], as we performed our data collection in a different, and more recent, period.\nThe resulting dataset, the so-called complete dataset, is composed of 15,500 posts from 32 pages (14 conspiracy and 18 scientific), with more than 2,300,00 likes by 900,000+ users (Table 1). Among posts, 8,923 (57.6%) are hoaxes and 6,577 (42.4%) non-hoaxes.\nAs a first observation, the distribution of the number of likes per post is exponentiallike, as attested by the histograms in Fig. 1 (a); the majority of the posts have few likes. Hoax posts have, on average, more likes than non-hoax posts. In particular, some figures about the number of likes per post are: average, 204.5 (for hoax post) vs. 84.0 (non-hoax); median, 22 (hoax) vs. 14 (non-hoax); maximum, 121,491 (hoax) vs. 13,608 (non-hoax).\nA second observation is related to the number of likes per user: once again, Fig. 1 (b) shows an exponential-like distribution. The majority of the users appears in the dataset\n1See https://developers.facebook.com/docs/graph-api. We used version 2.6.\nwith one single like (629,146 users, 69.2%), while the maximum number of likes by a user is 1,028. Users can be divided into three categories based on what they liked: i) those who liked hoax posts only, ii) those who liked non-hoax posts only, and iii) those who liked at least one post belonging to a hoax page, and one belonging to a non-hoax page. Fig. 2 (a) shows that, despite a high polarization, there are many users in the mixed category: among users with at least 2 likes, 209,280 (74.7%) liked hoax post only, 56,671 (20.3%) liked non-hoax post only, and 14,139 (5.0%) are in the mixed category. This latter category gives rise to the intersection dataset, which consists only of the users who liked both hoax and non-hoax posts, and of the posts these users liked. The intersection dataset was introduced to study the performance of our methods for communities of users that are not strongly polarized towards hoax or non-hoax posts, as will be discussed in Section 4. The composition of the intersection dataset is summarized in Table 1.\nA third observation concerns the relation between pages, measured by the number of users that pages have in common: given each pair of pages, we study how many users liked at least one post from one page and one post from the other page. Fig. 2 (b) shows the result as a symmetric matrix: each page vs. each other page. Color intensity displays that hoax pages have more users in common with other hoax pages (up-left part, which appears darker) than with non-hoax pages (up-right and bottom-left). The same applies to non-hoax pages (bottom-right). Nevertheless, the figure shows that the communities gravitating around hoax and non-hoax pages share many common users (as evidenced also from the composition of the intersection dataset)."
    }, {
      "heading" : "3 Algorithmic Classification of Posts",
      "text" : "Our goal is to classify posts into hoax and non-hoax posts. According to the analysis of social media sharing by [6], “users tend to aggregate in communities of interest, which causes reinforcement and fosters confirmation bias, segregation, and polarization”, and “users mostly tend to select and share content according to a specific narrative and to ignore the rest.” This suggests that the set of users who like a post should be highly indicative of the nature of the post. We present two approaches, one based on logistic regression, the other based on boolean crowdsourcing algorithms."
    }, {
      "heading" : "3.1 Classification via logistic regression",
      "text" : "We formulate the post classification problem as a supervised learning, binary classification problem. We consider a set of posts I and a set of users U . Each post i ∈ I has an associated set of features {xiu | u ∈ U}, where xiu = 1 if u liked post i, and xiu = 0 otherwise. We classify the posts on the basis of their features, that is, on the basis of which users liked them.\nTo perform the classification, we use a logistic regression model. The logistic regression model learns a weight wu for each user u ∈ U ; the probability pi that a post i is non-hoax is then given by pi = 1/(1+ e−yi), where yi = ∑ u∈U xiuwu. Intuitively, wu > 0 (resp. wu < 0) indicates that u likes mostly non-hoax (resp. hoax) posts. We chose logistic regression for two reasons. First, logistic regression is well suited to problems with a very large, and uniform, set of features. In our case, we have about a million features (users) in our dataset, but a real application would involve up to hundreds of millions of users. Second, our logistic regression setting enjoys a noninterference property with respect to unrelated set of users that facilitates learning, and is appealing on conceptual grounds. Specifically, assume that the set of users and posts are partitioned into disjoint subsets U = U1 ∪ U2, I = I1 ∪ I2, so that users in Uk like only posts in Ik, for k = 1, 2. This situation can arise, for instance, when there are two populations of users and posts in different languages, or simply when two topics are very unrelated. In such a setting, it is equivalent to train a single model, or to train separately two models, one for I1, U1, one for I2, U2, and then take their “union”. This because the weights wu for u ∈ U3−k do not matter for classifying posts in Ik, k = 1, 2, since the features xiu with i ∈ Ik and u ∈ U3−k are all zero. In other words, models for unrelated communities do not interfere: if we learn a model for I1, U1, we do not need to revise the model once the community I2, U2 is discovered: all we need to do is learn a model of this second community, and use it jointly with the first."
    }, {
      "heading" : "3.2 Classification via harmonic boolean label crowdsourcing",
      "text" : "The weak aspect of logistic regression is that it does not transfer information across users who liked some of the same posts. In particular, if the training set does not contain any post liked by a user u, then logistic regression will not be able to learn anything about u, and wu will be undetermined. Thus, posts that are only liked by users not in the training set cannot be classified. As an alternative approach, we propose to perform\nthe hoax/non-hoax classification using algorithms derived from crowdsourcing, and precisely, from the boolean label crowdsourcing (BLC) problem.\nIn the BLC problem, users provide True/False labels for posts, indicating for instance whether a post is vandalism, or whether it violates community guidelines. The BLC problem consists in computing the consensus labels from the user input [13, 15, 5]. We model liking a post as voting True on that post.\nOur setting differs from standard BLC in one important respect. Standard BLC algorithms do not use a learning set: rather, they assume that people are more likely to tell the truth than to lie. The algorithms compare what people say, correct for the effect of the liars, and reconstruct a consensus truth [13, 5]. In our setting, we cannot assume that users are more likely to tell the truth, that is, like preferentially non-hoax posts. Indeed, hoax articles may well have more “likes” than non-hoax ones. Rather, we will rely on a learning set of posts for which the ground truth is known.\nWe present here an adaptation of the harmonic algorithm of [5] to a setting with a learning set of posts. We chose the harmonic algorithm because it is computationally efficient, can cope with large datasets, and it offers good accuracy in practice, as evidenced in [5]. Furthermore, while the harmonic algorithm can be adapted to the presence of a learning set, it is less obvious how to do so for some of the other algorithms, such as those of [13].\nWe represent the dataset as a bipartite graph (I ∪ U,L), where L ⊆ I × U is the set of likes. We denote by ∂i = {u | (i, u) ∈ L} and ∂u = {i | (i, u) ∈ L} the 1-neighborhoods of a post i ∈ I and user u ∈ U , respectively.\nThe harmonic algorithm maintains for each node v ∈ I ∪ U two non-negative parameters αv , βv . These parameters define a beta distribution: intuitively, for a user u, αu−1 represents the number of times we have seen the user like a non-hoax post, and βu−1 represents the number of times we have seen the user like a hoax post. For a post i, αi−1 represents the number of non-hoax votes it has received, and βi−1 represents the number of hoax votes it has received. For each node v, let pv = αv/(αv + βv) be the mean of its beta distribution: for a user u, pu is the (average) probability that the user is truthful (likes non-hoax posts), and for a post i, pi is the (average) probability that i is not a hoax. Letting qv = 2pv − 1 = (αv − βv)/(αv + βv), positive values of qv indicate propensity for non-hoax, and negative values, propensity for hoax.\nLet the training set consist of two subets IH , IN ⊆ I of known hoax and non-hoax posts. The algorithm sets qi := −1 for all i ∈ IH , and qi := 1 for all i ∈ IN ; it sets qi = 0 for all other posts i ∈ I \\ (IH ∪ IN ). The algorithm then proceeds by iterative updates. First, for each user u ∈ U , it lets:\nαu := A+ ∑ {qi | i ∈ ∂u, qi > 0} βu := B − ∑ {qi | i ∈ ∂u, qi < 0}\nqu := (αu − βu)/(αu + βu) . (1)\nThe positive constants A, B determine the amount of evidence needed to sway the algorithm towards believing that a user likes hoax or non-hoax posts: the higher the values of A and B, the more evidence will be required. After some experimentation, we settled on the values A = 5.01 and B = 5, corresponding to a very weak a-priori preference of users for non-hoax posts. This corresponds to needing about 5 “likes” from known good (resp bad) users to reach a 2:1 probability ratio in favor of non-hoax\n(resp. hoax), which seems intuitively reasonable. The algorithm then updates the values for each post i ∈ I \\ (IH ∪ IN ) by:\nαi := A ′ + ∑ {qu | u ∈ ∂i, qu > 0} βi := B′ − ∑ {qu | u ∈ ∂i, qu < 0}\nqi := (αi − βi)/(αi + βi) . (2)\nWe choose A′ = B′ = 5, thus adopting a symmetrical a-priori for items being hoax vs. non-hoax. The updates (1)–(2) are performed iteratively; while they could be performed until a fixpoint is reached, we just perform them 5 times, as further updates do not yield increased accuracy. Finally, we classify a post i as hoax if qi < 0, and as non-hoax otherwise.\nThe harmonic algorithm satisfies the non-interference property described for logistic regression, since information is only propagated along graph edges that correspond to “likes”.\nThe harmonic algorithm is able to propagate information from posts where the ground truth is known, to posts that are connected by common users. In the first iteration, the users who liked mostly hoax (resp. non-hoax) posts will see their β (resp. α) coefficient increase, and thus their preferences will be characterized. In the next iteration, the user preferences will be reflected on post beliefs, and these post beliefs will subsequently be used to infer the preferences of more users, and so on. We will see how the ability to transfer information will allow the harmonic algorithm to reach high levels of accuracy even starting from small training sets."
    }, {
      "heading" : "4 Results",
      "text" : "We characterize the performance of the logistic regression and harmonic BLC algorithm via two sets of experiments. The first set of experiments measures the accuracy of the algorithms as a function of the number of posts available as training set. Since the training set can be produced, in general, only via a laborious process of manual post inspection, these results tell us how much do we need to invest in manual labeling, to reap the benefits of automated classification. The second set of experiments measures how much information our learning is able to transfer from one set of pages to another. As the community of Facebook users is organized around pages, these experiments shed light on how much what we learn from one community can be transferred to another, via the shared users among communities."
    }, {
      "heading" : "4.1 Accuracy of classification vs. training set size",
      "text" : "Cross-validation analysis. We performed a standard cross-validation analysis of logistic regression and of the harmonic algorithm for BLC. The cross-validation was performed by dividing the posts in the dataset into 80% training and 20% testing, and performing a 5-fold cross-validation analysis. Both approaches performed remarkably well, with accuracies exceeding 99% for logistic regression and 99.4% for the harmonic algorithm.\nAccuracy vs. training set size. Cross-validation is not the most insightful evaluation of our algorithms. In classifying news posts as hoax or non-hoax, there is a cost involved in creating the training set, as it may be necessary to examine each post individually. The interesting question is not the level of accuracy we can reach when we know the ground truth for 80% of the posts, but rather, how large a training set do we need in order to reach a certain level of accuracy. In order to be able to scale up to the size of social network information sharing, our approaches need to be able to produce an accurate classification relying on a small fraction of posts of known class.\nTo better understand this point, it helps to contrast the situation for standard ML settings, versus our post-classification problem. In standard ML settings, the set of features is chosen in advance, and the model that is developed from the 80% of data in the training set is expected to be useful for all future data, and not merely the 20% that constitutes the evaluation set. Thus, cross-validation provides a measure of performance for any future data. In contrast, in our setting the “features” consist in the users that liked the posts. The larger the set of posts we consider, the larger the set of users that might have interacted with them; we cannot assume that the model developed from 80% of our data will be valid for any set of future posts to be classified. Rather, the interesting question is, how many posts do we need to randomly select and classify, in order to be able to automatically classify all others?\nWe report the classification accuracy both for the complete dataset, and for the intersection dataset (see Section 2).\nIn Fig. 3, we report the accuracy our methods as a function of the size of the training set. In the figure, the classification accuracy reported for each training set size is the average of 50 runs. In each run, we select randomly a subset of posts to serve as training\nset, and we measure the classification accuracy on all other posts. The error bars in the figure denote the standard deviation of the classification accuracy of each run. Thus, the error bars provide an indication of run-to-run variablity (how much the accuracy varies with the particular training set), rather than of the precision in measuring the average accuracy. The standard deviation with which the average accuracy is known is about seven times smaller.\nFor the complete dataset, the harmonic BLC algorithm is the superior one. As long as the training set contains at least 0.5% of the posts, or about 80 posts, the accuracy exceeds 99.4%. For even lower training set sizes the accuracy decreases, but it is still about 80% for a training set consisting of 0.1% of posts, or about 15 posts. Logistic regression is somewhat inferior, but still yields accuracy above 90% for training sets consisting of only 1% of the posts.\nOn the intersection dataset, on the other hand, the logistic regression approach is the superior one. While the differences between the logistic regression and harmonic BLC algorithms is not large, the performance of logistic regression starts at 91.6% for a training set consisting of 10% of posts, and degrades towards 56% for a training set consisting of 0.1% of posts, maintaining a performance margin of 3–4% over harmonic BLC.\nGenerally, these results indicate that harmonic BLC is more efficient at transfering information across the dataset. Its inferior performance for the intersection dataset may be explained by the fact that the artificial construction of the intersection dataset biases towards the transfer of erroneous information. Most users have only a few likes (see Figure 1). The intersection dataset filters out all users who liked only one post, and of the users who liked two posts, the intersection dataset filters out all those who liked two posts of the same hoax/non-hoax class. As a consequence, the intersection dataset heavily over-samples “straddling” users who like exactly two posts, one hoax, one not; these straddling users constitute 32% of the users in the intersection dataset. When the two posts liked by a straddling user belong one to the training, one to the evaluation dataset, the straddling user contributes in the wrong direction to the classification of the post in the evaluation set."
    }, {
      "heading" : "4.2 Cross-page learning",
      "text" : "As the community of Facebook users naturally revolves around common interests and pages, an interesting question concerns whether what we learn from one community of users on one page transfers to other pages. In order to answer this question, we test our classifiers on posts related to pages that they have not seen during the training phase. To this end, we perform two experiments in which the set of pages from which we learn, and those on which we test, are disjoint. In the first experiment, one-page-out, we select in turn each page, and we place all its posts in the testing set; the posts belonging to all other pages are in the training set. In the second experiment, half-pages-out, we perform 50 runs. In each run, we randomly select a set consisting of half of the pages in the dataset, and we place the posts belonging to those pages in the testing set, and all others in the training set. The results are reported in Table 2.\nThe results clearly indicate that the harmonic BLC algorithm is the superior one for transferring information across pages, achieving essentially perfect accuracy in\nboth one-page-out and half-page-out experiments. Surprisingly, for harmonic BLC, the performance is slightly superior in the half-pages-out than in the one-page-out experiments. This is due to the fact that for one page the performance is only 87.3%; the performance for all other pages is always above 97.2%, and is 100% for 23 pages in the dataset. The poor performance on one particular page drags down the average for one-page-out, compared to half-pages-out where better-performing pages ameliorate the average."
    }, {
      "heading" : "5 Conclusions",
      "text" : "The high accuracy achieved by both logistic regression and the harmonic BLC algorithm confirm our basic hypothesis: the set of users that interacts with news posts in social network sites can be used to predict whether posts are hoaxes.\nWe presented two techniques for exploiting this information: one based on logistic regression, the other on boolean label crowdsourcing (BLC). Both algorithms provide good performance, with the harmonic BLC algorithm providing accuracy above 99% even when trained over sets of posts consisting of 0.5% of the full dataset (or about 80 posts). This suggests that the algorithms can scale up to the size of entire social networks, while requiring only a modest amount of manual classification.\nWe also analyzed the extent to which our performance depends on the community of users naturally aggregating around pages of similar content. We showed that the harmonic BLC algorithm can transfer information across pages: even when only half of the pages are represented in the training set, the performance is above 99%. Even on the “intersection dataset”, consisting of only users who liked both hoax and non-hoax posts, our methods achieve performance of 90%, albeit requiring for this a training set consisting of 10% of the posts; this produces evidence that our approach might work even when applied to communities of users that are not strongly polarized towards scientific vs. conspiracy pages. We note that the intersection dataset is a borderline example that does not occur in the communities we studied. Together, these results seem to indicate that the techniques proposed may be sufficiently robust for an extensive application in a real-world scenario."
    } ],
    "references" : [ {
      "title" : "Wikipedia vandalism detection: Combining natural language, metadata, and reputation features",
      "author" : [ "B Adler", "Luca De Alfaro", "Santiago Mola-Velasco", "Paolo Rosso", "Andrew West" ],
      "venue" : "Computational linguistics and intelligent text processing,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2011
    }, {
      "title" : "A Content-driven Reputation System for the Wikipedia",
      "author" : [ "B. Thomas Adler", "Luca de Alfaro" ],
      "venue" : "In Proceedings of the 16th International Conference on World Wide Web, WWW",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2007
    }, {
      "title" : "Science vs Conspiracy: Collective Narratives in the Age of Misinformation",
      "author" : [ "Alessandro Bessi", "Mauro Coletto", "George Alexandru Davidescu", "Antonio Scala", "Guido Caldarelli", "Walter Quattrociocchi" ],
      "venue" : "PLOS ONE,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2015
    }, {
      "title" : "Scam Detection in Twitter. In Katsutoshi Yada, editor, Data Mining for Service, number 3 in Studies in Big Data, pages 133–150",
      "author" : [ "Xiaoling Chen", "Rajarathnam Chandramouli", "Koduvayur P. Subbalakshmi" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2014
    }, {
      "title" : "Reliable aggregation of boolean crowdsourced tasks",
      "author" : [ "Luca de Alfaro", "Vassilis Polychronopoulos", "Michael Shavlovsky" ],
      "venue" : "In Third AAAI Conference on Human Computation and Crowdsourcing,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2015
    }, {
      "title" : "The spreading of misinformation online",
      "author" : [ "Michela Del Vicario", "Alessandro Bessi", "Fabiana Zollo", "Fabio Petroni", "Antonio Scala", "Guido Caldarelli", "H. Eugene Stanley", "Walter Quattrociocchi" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2016
    }, {
      "title" : "The digitization of word of mouth: Promise and challenges of online feedback mechanisms",
      "author" : [ "Chrysanthos Dellarocas" ],
      "venue" : "Management science,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2003
    }, {
      "title" : "Accuracy of Metrics for Inferring Trust and Reputation in Semantic Web-Based Social Networks. In Engineering Knowledge in the Age of the Semantic Web, pages 116–131",
      "author" : [ "Jennifer Golbeck", "James Hendler" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2004
    }, {
      "title" : "A first step towards automatic hoax detection",
      "author" : [ "J.C. Hernandez", "C.J. Hernandez", "J.M. Sierra", "A. Ribagorda" ],
      "venue" : "In Proceedings. 36th Annual 2002 International Carnahan Conference on Security Technology,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2002
    }, {
      "title" : "Fighting Spam on Social Web Sites: A Survey of Approaches and Future Challenges",
      "author" : [ "P. Heymann", "G. Koutrika", "H. Garcia-Molina" ],
      "venue" : "IEEE Internet Computing,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2007
    }, {
      "title" : "Distance-based hoax detection system",
      "author" : [ "A. Ishak", "Y.Y. Chen", "Suet-Peng Yong" ],
      "venue" : "In 2012 International Conference on Computer Information Science (ICCIS),",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2012
    }, {
      "title" : "Assessment of Tweet Credibility with LDA Features",
      "author" : [ "Jun Ito", "Jing Song", "Hiroyuki Toda", "Yoshimasa Koike", "Satoshi Oyama" ],
      "venue" : "In Proceedings of the 24th International Conference on World Wide Web, WWW ’15 Companion,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Iterative learning for reliable crowdsourcing systems",
      "author" : [ "David R. Karger", "Sewoong Oh", "Devavrat Shah" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2011
    }, {
      "title" : "Disinformation on the Web: Impact, Characteristics, and Detection of Wikipedia Hoaxes",
      "author" : [ "Srijan Kumar", "Robert West", "Jure Leskovec" ],
      "venue" : "In Proceedings of the 25th International Conference on World Wide Web, WWW",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2016
    }, {
      "title" : "Variational inference for crowdsourcing",
      "author" : [ "Qiang Liu", "Jian Peng", "Alexander T. Ihler" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2012
    }, {
      "title" : "Filtering spam with spamassassin",
      "author" : [ "Justin Mason" ],
      "venue" : "In HEANet Annual Conference,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2002
    }, {
      "title" : "A Computational Model of Trust and Reputation for E-businesses",
      "author" : [ "L. Mui", "M. Mohtashemi", "A. Halberstadt" ],
      "venue" : "In Proceedings of the 35th Annual Hawaii International Conference on System Sciences",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2002
    }, {
      "title" : "E-Mail System for Automatic Hoax Recognition",
      "author" : [ "Tomislav Petković", "Zvonko Kostanjčar", "Predrag Pale" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2005
    }, {
      "title" : "Automatic vandalism detection in wikipedia",
      "author" : [ "Martin Potthast", "Benno Stein", "Robert Gerling" ],
      "venue" : "In European Conference on Information Retrieval,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2008
    }, {
      "title" : "Detection of Internet scam using logistic regression",
      "author" : [ "M. Sharifi", "E. Fink", "J.G. Carbonell" ],
      "venue" : "In 2011 IEEE International Conference on Systems, Man, and Cybernetics,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2011
    }, {
      "title" : "An Intelligent Automatic Hoax Detection System. In Knowledge-Based and Intelligent Information and Engineering Systems, pages 318–325",
      "author" : [ "Marin Vuković", "Krešimir Pripužić", "Hrvoje Belani" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2009
    }, {
      "title" : "Optimising anti-spam filters with evolutionary algorithms",
      "author" : [ "Iryna Yevseyeva", "Vitor Basto-Fernandes", "David Ruano-Ordás", "José R. Méndez" ],
      "venue" : "Expert Systems with Applications,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "As a consequence, SNSs are also increasingly used as vectors for the dissemination of spam [10], conspiracy theories and hoaxes, i.",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 2,
      "context" : "This recently led to the emphatic definition of our current times as the age of misinformation [3].",
      "startOffset" : 95,
      "endOffset" : 98
    }, {
      "referenceID" : 5,
      "context" : "A significant share of hoaxes on SNSs diffuses rapidly, with a peak in the first 2 hours [6].",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 8,
      "context" : "This finding, together with the high amount of shared content, highlights the need of automatic online hoax detection systems [9].",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 15,
      "context" : "In the context of scam e-mail detection, spamassassin uses keyword-based methods with logistic regression [16]; Petković et al.",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 17,
      "context" : "[18] and Ishak et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] proposed the use of distance-based methods; Vuković et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "[21] applied neural network and advanced text processing; Yevseyeva et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "[22] used evolutionary algorithms for the development of anti-spam filters.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[20] applied logistic regression to automatically detect scam on webpages, reaching an accuracy of 98%.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "The concepts of trust and reputation [17, 7] can be adopted for hoax detection in applications with a dominant social component.",
      "startOffset" : 37,
      "endOffset" : 44
    }, {
      "referenceID" : 6,
      "context" : "The concepts of trust and reputation [17, 7] can be adopted for hoax detection in applications with a dominant social component.",
      "startOffset" : 37,
      "endOffset" : 44
    }, {
      "referenceID" : 7,
      "context" : "Metrics and algorithms for this purpose have been proposed by Golbeck and Hendler [8].",
      "startOffset" : 82,
      "endOffset" : 85
    }, {
      "referenceID" : 1,
      "context" : "Adler and de Alfaro [2] developed a content-driven user reputation system for Wikipedia, allowing to predict the quality of new contributions.",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 18,
      "context" : "in [19, 1, 14].",
      "startOffset" : 3,
      "endOffset" : 14
    }, {
      "referenceID" : 0,
      "context" : "in [19, 1, 14].",
      "startOffset" : 3,
      "endOffset" : 14
    }, {
      "referenceID" : 13,
      "context" : "in [19, 1, 14].",
      "startOffset" : 3,
      "endOffset" : 14
    }, {
      "referenceID" : 3,
      "context" : "[4] developed a semi-supervised scam detector for Twitter based on self-learning and clustering analysis, while Ito et al.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 11,
      "context" : "[12] proposed the use of Latent Dirichlet Allocation (LDA) to assess the credibility of tweets.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "In particular, focusing on Facebook, we answer the following research question: Can a hoax be identified based on the users who “liked” it? We consider a dataset consisting of 15,500 posts and 909,236 users; the posts originate from pages that deal with either scientific topics or with conspiracies and fake scientific news [3].",
      "startOffset" : 325,
      "endOffset" : 328
    }, {
      "referenceID" : 2,
      "context" : "We based our selection of pages on [3].",
      "startOffset" : 35,
      "endOffset" : 38
    }, {
      "referenceID" : 2,
      "context" : "Among the 73 pages listed in [3], we limited our analysis to the top 20 pages of both categories.",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 2,
      "context" : "We note also that the actual posts comprising our dataset are distinct from those originally included in the dataset of [3], as we performed our data collection in a different, and more recent, period.",
      "startOffset" : 120,
      "endOffset" : 123
    }, {
      "referenceID" : 5,
      "context" : "According to the analysis of social media sharing by [6], “users tend to aggregate in communities of interest, which causes reinforcement and fosters confirmation bias, segregation, and polarization”, and “users mostly tend to select and share content according to a specific narrative and to ignore the rest.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 12,
      "context" : "The BLC problem consists in computing the consensus labels from the user input [13, 15, 5].",
      "startOffset" : 79,
      "endOffset" : 90
    }, {
      "referenceID" : 14,
      "context" : "The BLC problem consists in computing the consensus labels from the user input [13, 15, 5].",
      "startOffset" : 79,
      "endOffset" : 90
    }, {
      "referenceID" : 4,
      "context" : "The BLC problem consists in computing the consensus labels from the user input [13, 15, 5].",
      "startOffset" : 79,
      "endOffset" : 90
    }, {
      "referenceID" : 12,
      "context" : "The algorithms compare what people say, correct for the effect of the liars, and reconstruct a consensus truth [13, 5].",
      "startOffset" : 111,
      "endOffset" : 118
    }, {
      "referenceID" : 4,
      "context" : "The algorithms compare what people say, correct for the effect of the liars, and reconstruct a consensus truth [13, 5].",
      "startOffset" : 111,
      "endOffset" : 118
    }, {
      "referenceID" : 4,
      "context" : "We present here an adaptation of the harmonic algorithm of [5] to a setting with a learning set of posts.",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 4,
      "context" : "We chose the harmonic algorithm because it is computationally efficient, can cope with large datasets, and it offers good accuracy in practice, as evidenced in [5].",
      "startOffset" : 160,
      "endOffset" : 163
    }, {
      "referenceID" : 12,
      "context" : "Furthermore, while the harmonic algorithm can be adapted to the presence of a learning set, it is less obvious how to do so for some of the other algorithms, such as those of [13].",
      "startOffset" : 175,
      "endOffset" : 179
    } ],
    "year" : 2017,
    "abstractText" : "In recent years, the reliability of information on the Internet has emerged as a crucial issue of modern society. Social network sites (SNSs) have revolutionized the way in which information is spread by allowing users to freely share content. As a consequence, SNSs are also increasingly used as vectors for the diffusion of misinformation and hoaxes. The amount of disseminated information and the rapidity of its diffusion make it practically impossible to assess reliability in a timely manner, highlighting the need for automatic hoax detection systems. As a contribution towards this objective, we show that Facebook posts can be classified with high accuracy as hoaxes or non-hoaxes on the basis of the users who “liked” them. We present two classification techniques, one based on logistic regression, the other on a novel adaptation of boolean crowdsourcing algorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users, we obtain classification accuracies exceeding 99% even when the training set contains less than 1% of the posts. We further show that our techniques are robust: they work even when we restrict our attention to the users who like both hoax and non-hoax posts. These results suggest that mapping the diffusion pattern of information can be a useful component of automatic hoax detection systems.",
    "creator" : "LaTeX with hyperref package"
  }
}