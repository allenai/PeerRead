{
  "name" : "1301.2296.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "The Factored Frontier Algorithm for Approximate Inference in DBNs",
    "authors" : [ "Kevin Murphy", "Yair Weiss" ],
    "emails" : [ "}@cs.berkeley.edu" ],
    "sections" : null,
    "references" : [ {
      "title" : "Approximate learning of dy­ namic models",
      "author" : [ "X. Boyen", "D. Koller" ],
      "venue" : "In NIPS-11,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1998
    }, {
      "title" : "Tractable inference for com­ plex stochastic processes",
      "author" : [ "X. Boyen", "D. Koller" ],
      "venue" : "In UAI,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1998
    }, {
      "title" : "Probabilistic Networks and Expert Sys­",
      "author" : [ "R.G. Cowell", "A.P. Dawid", "S.L. Lauritzen", "D.J. Spiegelhalter" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1999
    }, {
      "title" : "Mini-buckets: a general scheme of ap­ proximating approximations in automated reasoning",
      "author" : [ "R. Dechter" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1997
    }, {
      "title" : "On the fixed points of the max-product algorithm",
      "author" : [ "W. Freeman", "Y. Weiss" ],
      "venue" : "IEEE Trans. on Info. Theory,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2000
    }, {
      "title" : "Turbo factor analysis",
      "author" : [ "B.J. Frey" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1999
    }, {
      "title" : "Factorial hidden Markov models",
      "author" : [ "Z. Ghahramani", "M. Jordan" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1997
    }, {
      "title" : "Ped­ ersen. An expert system for control of waste water treatment - a pilot project",
      "author" : [ "F.V. Jensen", "U. Kjaerulff", "K.G. Olesen" ],
      "venue" : "Technical report, Univ. Aalborg, Judex Datasystemer,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1989
    }, {
      "title" : "Triangulation of graphs - algorithms giving small total state space",
      "author" : [ "U. Kjaerulff" ],
      "venue" : "Technical Report R-",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1990
    }, {
      "title" : "A computational scheme for reasoning in dynamic probabilistic networks",
      "author" : [ "U. Kjaerulff" ],
      "venue" : "In UAI�B,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1992
    }, {
      "title" : "Modeling freeway traffic with coupled HMMs",
      "author" : [ "J. Kwon", "K. Murphy" ],
      "venue" : "Technical report, Univ. Califor­ nia, Berkeley,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2000
    }, {
      "title" : "Turbo decoding as an instance of Pearl's 'belief prop­ agation' algorithm",
      "author" : [ "R.J. McEliece", "D.J.C. MacKay", "J.F. Cheng" ],
      "venue" : "IEEE J. on Selectred Areas in Comm.,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1998
    }, {
      "title" : "A family of algorithms for approximate Bayesian inference",
      "author" : [ "T. Minka" ],
      "venue" : "In UAI,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2001
    }, {
      "title" : "Loopy belief propagation for approximate inference: an empirical study",
      "author" : [ "K. Murphy", "Y. Weiss", "M. Jordan" ],
      "venue" : "In UAI,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1999
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Sys� terns: Networks of Plausible Inference",
      "author" : [ "J. Pearl" ],
      "venue" : "Morgan Kauf­ mann,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1988
    }, {
      "title" : "Fusion and propagation with multiple observations in belief networks",
      "author" : [ "M. Peat", "R. Shachter" ],
      "venue" : "Artifi� cial Intelligence,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1991
    }, {
      "title" : "A tutorial on Hidden Markov Models and selected applications in speech recognition",
      "author" : [ "L.R. Rabiner" ],
      "venue" : "Proc. of the IEEE,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1989
    }, {
      "title" : "Prob­ abilistic independence networks for hidden Markov probability models",
      "author" : [ "P. Smyth", "D. Beckerman", "M.I. Jordan" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1997
    }, {
      "title" : "Correctness of local probability propagation in graphical models with loops",
      "author" : [ "Y. Weiss" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2000
    }, {
      "title" : "Correctness of belief propagation in Gaussian graphical models of arbitrary topology",
      "author" : [ "Y. Weiss", "W.T. Freeman" ],
      "venue" : "In NIPS�12,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1999
    }, {
      "title" : "Generalized belief propagation",
      "author" : [ "J. Yedidia", "W.T. Freeman", "andY. Weiss" ],
      "venue" : "In NIPS-13,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2000
    }, {
      "title" : "A forward-backward algorithm for infer­ ence in Bayesian networks and an empirical compar­ ison with HMMs",
      "author" : [ "G. Zweig" ],
      "venue" : "Master's thesis, Dept. Comp. Sci., U.C. Berkeley,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1996
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "The simplest way to perform exact inference in a DBN is to convert the model to an HMM and ap­ ply the forwards-backwards algorithm [18].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 14,
      "context" : "In Section 4, we show how both FF and BK are related to loopy belief propagation (LBP) [15, 21, 20, 6, 7, 13] , which is the method of applying Pearl's message pass­ ing algorithm [16] to a Bayes net even if it contains (undirected) cycles or loops.",
      "startOffset" : 87,
      "endOffset" : 109
    }, {
      "referenceID" : 20,
      "context" : "In Section 4, we show how both FF and BK are related to loopy belief propagation (LBP) [15, 21, 20, 6, 7, 13] , which is the method of applying Pearl's message pass­ ing algorithm [16] to a Bayes net even if it contains (undirected) cycles or loops.",
      "startOffset" : 87,
      "endOffset" : 109
    }, {
      "referenceID" : 19,
      "context" : "In Section 4, we show how both FF and BK are related to loopy belief propagation (LBP) [15, 21, 20, 6, 7, 13] , which is the method of applying Pearl's message pass­ ing algorithm [16] to a Bayes net even if it contains (undirected) cycles or loops.",
      "startOffset" : 87,
      "endOffset" : 109
    }, {
      "referenceID" : 5,
      "context" : "In Section 4, we show how both FF and BK are related to loopy belief propagation (LBP) [15, 21, 20, 6, 7, 13] , which is the method of applying Pearl's message pass­ ing algorithm [16] to a Bayes net even if it contains (undirected) cycles or loops.",
      "startOffset" : 87,
      "endOffset" : 109
    }, {
      "referenceID" : 6,
      "context" : "In Section 4, we show how both FF and BK are related to loopy belief propagation (LBP) [15, 21, 20, 6, 7, 13] , which is the method of applying Pearl's message pass­ ing algorithm [16] to a Bayes net even if it contains (undirected) cycles or loops.",
      "startOffset" : 87,
      "endOffset" : 109
    }, {
      "referenceID" : 12,
      "context" : "In Section 4, we show how both FF and BK are related to loopy belief propagation (LBP) [15, 21, 20, 6, 7, 13] , which is the method of applying Pearl's message pass­ ing algorithm [16] to a Bayes net even if it contains (undirected) cycles or loops.",
      "startOffset" : 87,
      "endOffset" : 109
    }, {
      "referenceID" : 15,
      "context" : "In Section 4, we show how both FF and BK are related to loopy belief propagation (LBP) [15, 21, 20, 6, 7, 13] , which is the method of applying Pearl's message pass­ ing algorithm [16] to a Bayes net even if it contains (undirected) cycles or loops.",
      "startOffset" : 180,
      "endOffset" : 184
    }, {
      "referenceID" : 8,
      "context" : "This model is originally from [9], and was modified by [2] to include (discrete) evi­ dence nodes.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "This model is originally from [9], and was modified by [2] to include (discrete) evi­ dence nodes.",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 17,
      "context" : "We start by reviewing the forwards-backwards (FB) algorithm [18] for HMMs, and then the frontier algo­ rithm [23] for DBNs, since this will form the basis of our generalisation.",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 9,
      "context" : "Nevertheless, heuristics meth­ ods, such as greedy search [10], often perform as well as exhaustive search using branch and bound [23].",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 7,
      "context" : "A special case of the frontier algorithm, applied to fac­ torial HMMs, was published in Appendix B of [8].",
      "startOffset" : 102,
      "endOffset" : 105
    }, {
      "referenceID" : 2,
      "context" : ") For regular1 DBNs, the frontier algorithm is equivalent to the junction tree algorithm [3, 11, 19] applied to the \"unrolled\" DEN.",
      "startOffset" : 89,
      "endOffset" : 100
    }, {
      "referenceID" : 10,
      "context" : ") For regular1 DBNs, the frontier algorithm is equivalent to the junction tree algorithm [3, 11, 19] applied to the \"unrolled\" DEN.",
      "startOffset" : 89,
      "endOffset" : 100
    }, {
      "referenceID" : 18,
      "context" : ") For regular1 DBNs, the frontier algorithm is equivalent to the junction tree algorithm [3, 11, 19] applied to the \"unrolled\" DEN.",
      "startOffset" : 89,
      "endOffset" : 100
    }, {
      "referenceID" : 1,
      "context" : "The Boyen-Koller algorithm [2] represents the belief state, O:t = P(Xt!Yt:t), as a product of marginals over C \"clusters\", P(Xt IYI:t) � TI�=l P(XfiYl:t), where Xf is a subset of the variables {Xi}.",
      "startOffset" : 27,
      "endOffset" : 30
    }, {
      "referenceID" : 0,
      "context" : "We can use a similar method for computing the backward messages in an efficient manner [1].",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 15,
      "context" : "Pearl's belief propagation algorithm [16] is a way of computing exact marginal posterior probabilities in graphs with no undirected cycles (loops).",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 12,
      "context" : "Nevertheless, the out­ standing empirical success of turbo decoding, which has be shown to be equivalent to LBP [13], has cre­ ated great interest in the algorithm.",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 14,
      "context" : "LBP has been empirically shown to work well on sev­ eral kinds of Bayesian networks which are quite differ­ ent from turbo codes [15, 7].",
      "startOffset" : 129,
      "endOffset" : 136
    }, {
      "referenceID" : 6,
      "context" : "LBP has been empirically shown to work well on sev­ eral kinds of Bayesian networks which are quite differ­ ent from turbo codes [15, 7].",
      "startOffset" : 129,
      "endOffset" : 136
    }, {
      "referenceID" : 20,
      "context" : "In addition, a number of theoretical results have now been proved for networks in which all nodes are Gaussian [21], for networks in which there is only a single loop [20], and for general networks but using the max-product (Viterbi) version instead of the sum-product (forwards-backwards) ver­ sion of the algorithm [6].",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 19,
      "context" : "In addition, a number of theoretical results have now been proved for networks in which all nodes are Gaussian [21], for networks in which there is only a single loop [20], and for general networks but using the max-product (Viterbi) version instead of the sum-product (forwards-backwards) ver­ sion of the algorithm [6].",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 5,
      "context" : "In addition, a number of theoretical results have now been proved for networks in which all nodes are Gaussian [21], for networks in which there is only a single loop [20], and for general networks but using the max-product (Viterbi) version instead of the sum-product (forwards-backwards) ver­ sion of the algorithm [6].",
      "startOffset" : 317,
      "endOffset" : 320
    }, {
      "referenceID" : 16,
      "context" : "In particular, if the D BN is in fact an HMM, then a single FB iteration (2T N message computations) will result in the exact posteriors, whereas it requires T iterations of the decentralized protocol (each iteration comput­ ing 2T N messages in parallel) to reach the same result; hence the centralized algorithm is more efficient [17].",
      "startOffset" : 332,
      "endOffset" : 336
    }, {
      "referenceID" : 15,
      "context" : "and 1r messages without having to do work which is exponential in the number of parents [16].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 21,
      "context" : "The equivalence between BK and a single iteration of LBP on the clustered graph allows us to utilize the re­ cent result of Yedidia et al [22] to obtain a free energy for \"iterated\" BK.",
      "startOffset" : 138,
      "endOffset" : 142
    }, {
      "referenceID" : 21,
      "context" : "The analysis of [22] shows that iterated BK can only converge to zero gradient points of the Bethe free energy.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 11,
      "context" : "We used a CHMM model with 10 chains trained on some real freeway traffic data using exact EM [12].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 14,
      "context" : "We there­ fore used the damping trick described in [15].",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 13,
      "context" : "Perhaps the closest is the expecta­ tion propagation algorithm [14] .",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 3,
      "context" : "The mini­ bucket algorithm [4] also approximates joint distribu­ tions over collections of nodes as a product of smaller terms; however, this is not an iterative algorithm, and hence cannot correct for erroneous independence as­ sumptions made in the first pass.",
      "startOffset" : 27,
      "endOffset" : 30
    } ],
    "year" : 2011,
    "abstractText" : "The Factored Frontier (FF) algorithm is a simple approximate inference algorithm for Dynamic Bayesian Networks (DBNs). It is very similar to the fully factorized version of the Boyen-Koller (BK) algorithm, but in­ stead of doing an exact update at every step followed by marginalisation (projection), it always works with factored distributions. Hence it can be applied to models for which the exact update step is intractable. We show that FF is equivalent to (one iteration of) loopy belief propagation (LBP) on the origi­ nal DBN, and that BK is equivalent (to one iteration of) LBP on a DBN where we clus­ ter some of the nodes. We then show em­ pirically that by iterating more than once, LBP can improve on the accuracy of both FF and BK. We compare these algorithms on two real-world DBNs: the first is a model of a water treatment plant, and the second is a coupled HMM, used to model freeway traffic.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}