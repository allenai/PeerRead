{
  "name" : "1606.00128.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Self-Paced Learning: an Implicit Regularization Perspective",
    "authors" : [ "Yanbo Fan", "Ran He", "Jian Liang", "Bao-Gang Hu" ],
    "emails" : [ "hubg}@nlpr.ia.ac.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 6.\n00 12\n8v 3\n[ cs\n.L G\n] 1\n8 Se"
    }, {
      "heading" : "1 Introduction",
      "text" : "Inspired by the learning process and cognitive mechanism of humans and animals, Bengio et al. propose a new learning strategy called curriculum learning (CL) in [1], which gradually includes more and more hard samples into training process. A curriculum can be seen as a sequence of training criteria. For example, in the training of a shape recognition system, images that exhibit less variability such as squares and circles are considered first, followed by hard shapes like ellipses. The curriculum in CL is usually determined by some certain priors, and thus is problem specific and lacks generalizations. To alleviate this, Kumar et al. propose a new learning strategy named selfpaced learning (SPL) that incorporates the curriculum updating in the process of model optimization [14]. General SPL model consists of a problem specific weighted loss term on all samples and a SPL regularizer on sample weights. Alternative search strategy (ASS) is generally used for optimization. By gradually increasing the penalty of the SPL regularizer during the optimization, more samples are included into training from easy to hard by a self-paced manner. Due to its ability of avoiding bad local minima and improving the generalization performance, many works have been developed based on SPL [16, 17, 13, 31, 25, 15].\nOne key issue in SPL is to obtain better weighting strategy that is determined by the minimizer functions, and existing methods usually pursue this by artificially designing the explicit form of SPL regularizers [29, 32, 11, 12]. Some examples are listed in the appendix. Specifically, a definition of self-paced regularizer is given in [11]. Though shown to be effective in many applications experimentally, the underlying working mechanism of SPL is still unclear and is heavily desired for its\nfuture development. One attempt in this aspect is [19], they show that the ASS method used for SPL accords with the majorization minimization [26] algorithm implemented on a latent SPL objective, and deduce the latent objective of hard, linear and mixture regulraizers.\nConsidering the crucial role of minimizer function in SPL, we focus on it and study a group of new regularizer (named self-paced implicit regularizer) for SPL based on the convex conjugacy theory. Comparing with existing SPL regularizers, the self-paced implicit regularizer is deduced from robust loss function and its analytic form can be even unknown. Its properties and corresponding minimizer function can be learned from the latent loss function directly. Besides, the proposed self-paced implicit regularizer is independent of the learning objective and thus leads to a general framework (named SPL-IR) for SPL. SPL-IR can be optimized via ASS algorithm. More importantly, we demonstrate that the learning procedure of SPL-IR is indeed associated with latent robust loss functions, thus may provide some theoretical inspirations for its working mechanism (e.g. its robustness to outliers and heavy noise). We further analyze the relations between SPL-IR and halfquadratic (HQ) optimization and provide a group of self-paced implicit regularizer accordingly. Such relations can be beneficial to both SPL and HQ optimization. Finally, we implement SPL-IR to three classical tasks (i.e. matrix factorization, clustering and classification). Experimental results corroborate our ideas and demonstrate the correctness and effectiveness of SPL-IR.\nOur work has three main contributions: (1) We propose self-paced implicit regularizer for SPL, and develop a general implicit regularization framework (named SPL-IR) based on it. The selfpaced implicit regularizers not only enrich the family of regularizers for SPL but also can provide some inspirations on the working mechanism of SPL. (2) We analyze the connections between SPLIR and HQ optimization, and provide a group of robust loss function induced self-paced implicit regularizers for SPL-IR accordingly. (3) Experimental results on both supervised and unsupervised tasks corroborate our ideas and demonstrate the correctness and effectiveness of SPL-IR."
    }, {
      "heading" : "2 Preliminaries",
      "text" : ""
    }, {
      "heading" : "2.1 Self-Paced Learning via Explicit Regularizers",
      "text" : "Given training dataset D = {(xi, yi)}ni=1 with n samples, where xi ∈ Rd is the i-th sample, yi is the optional information according to the learning objective (e.g. yi can be the label of xi in classification model). Let f(. ,w) denote the learned model and w be the model parameter. L(yi, f(xi,w)) is the loss function of i-th sample.\nMimicking the cognitive mechanism of humans and animals, SPL aims to optimize the model from easy to hard samples gradually. The objective of SPL is to jointly optimize model parameter w and latent sample weights v = [v1, v2, . . . , vn] via the following minimization problem:\nmin w,v E(w,v;λ) =\nn ∑\ni=1\nviL(yi, f(xi,w)) + g(λ, vi), (1)\nwhere g(λ, v) is called self-paced regularizer and λ is a penalty parameter that controls the learning pace. ASS algorithm is generally used for (1), which alternatively optimizes w and v while keeping the other fixed. Specifically, given sample weights v, the minimization over w is a weighted loss minimization problem that is independent of regularizer g(λ, v); given model parameter w, the optimal weight of i-th sample is determined by\nmin vi viL(yi, f(xi,w)) + g(λ, vi). (2)\nSince ℓi = L(yi, f(xi,w) is constant oncew is given, the optimal value of vi is uniquely determined by the corresponding minimizer function σ(λ, ℓi) that satisfies σ(λ, ℓi)ℓi + g(λ, σ(λ, ℓi)) ≤ viℓi + g(λ, vi), ∀vi ∈ [0, 1]. (3) For example, if g(λ, vi) = −λvi [14], the optimal v∗i is calculated by\nv∗i = σ(λ, ℓi) =\n{\n1, if ℓi ≤ λ 0, otherwise\n(4)\nBy gradually increasing the value of λ, more and more hard samples are included into the training process. Many efforts have been put into the learning of minimizer functions [29, 32, 11, 12, 25], and we name them as SPL with explicit regularizers as they usually require the explicit form of regularizer g(λ, v) . σ(λ, ℓ) is then derived from the form of g(λ, v)."
    }, {
      "heading" : "2.2 Half-Quadratic Optimization",
      "text" : "Half-quadratic optimization [21, 5, 4] is a commonly used optimization method that based on the convex conjugacy theory. It tries to solve a nonlinear objective function via optimizing a series of half-quadratic reformulation problems iteratively [7, 9, 8, 6, 30].\nGiven a differentiable function φ(t) : R → R, if φ(t) further satisfies the conditions of the multiplicative form of HQ optimization in [20], the following equation holds for any fixed t,\nφ(t) = inf p∈R+\n{\n1 2 pt2 + ψ(p)\n}\n, (5)\nwhere ψ(p) is the dual potential function of φ(t) and R+ = {t|t ≥ 0}. ψ(p) is convex and reads\nψ(p) = sup t∈R+\n{\n−1 2 pt2 + φ(t)\n}\n, (6)\nMore analysis about φ(t) and ψ(p) refers to [21]. The optimal p∗ that minimize (5) is uniquely determined by the corresponding minimizer function δ(t) , which is derived from convex conjugacy and is only relative to function φ(t). For each t, δ(t) is such that\n1 2 δ(t)t2 + ψ(δ(t)) ≤ 1 2 pt2 + ψ(p), ∀p ∈ R+. (7)\nThe optimization of φ(t) can be done via iteratively minimizing t and p in (5). One only needs to focus on φ(t) and its corresponding minimizer function δ(t) in HQ optimization, and the analytical form of the dual potential function ψ(p) can be even unknown."
    }, {
      "heading" : "3 The Proposed Method",
      "text" : "In this section, we first give the definition of the proposed self-paced implicit regularizer and derive its minimizer function based on convex conjugacy. Then we develop a general self-paced learning framework, named SPL-IR, based on implicit regularization. Finally, we analyze the relations between SPL-IR and HQ optimization."
    }, {
      "heading" : "3.1 Self-Paced Implicit Regularizer",
      "text" : "Based on our above analysis of SPL, we define the self-paced implicit regularizer as follows,\nDefinition 1. Self-Paced Implicit Regularizer. A self-paced implicit regularizer ψ(λ, v) is defined as the dual potential function of a robust loss function φ(λ, t), and satisfies\n1. φ(λ, t) = minv≥0 vt+ ψ(λ, v);\n2. σ(λ, t) is the minimizer function of φ(λ, t) that satisfies σ(λ, t)t+ ψ(λ, σ(λ, t)) ≤ vt+ ψ(λ, v), ∀ v ∈ R+; 3. σ(λ, t) is non-negative and up-bounded, ∀ t ∈ R+; 4. σ(λ, t) is monotonically decreasing w.r.t. t, ∀ t ∈ R+; 5. σ(λ, t) is monotonous w.r.t. λ ∈ R+; where λ is a hyper-parameter and it is the same in φ(λ, t), ψ(λ, v) and σ(λ, t). λ is considered to be fixed in the first four conditions.\nProposition 1 For any fixed λ, if φ(λ, t) in Definition 1 further satisfies the conditions referred in [20], its minimizer function σ(λ, t) is uniquely determined by φ(λ, t) and the analytic form of the dual potential function ψ(λ, v) can be even unknown during the optimization.\nThe proof of Proposition 1 is given in the appendix. According to Definition 1, the self-paced implicit regularizer is derived from robust loss function. Its properties can be learned from both ψ(λ, v) and the latent loss function φ(λ, t). The corresponding minimizer function σ(λ, t) can be learned from φ(λ, t) directly. During the optimization, the optimal v∗ is determined by σ(λ, t) and the analytic form of ψ(λ, v) can be even unknown, hence ψ(λ, v) is named self-paced implicit regularizer. Besides, the last three conditions in Definition 1 are required for SPL regimes. Specifically, let t denote the sample loss, condition 4 indicates that the model is likely to select easy samples (with smaller losses) in favor of hard samples (with larger losses) for a fixed λ, and condition 5 makes sure that we can incorporate more and more samples through turning parameter λ.\nBesides, Jiang et al. have given a definition of self-paced regularizer and derived necessary conditions of the regularizer and the corresponding minimizer function for SPL in [11]. However, it is still nontrivial to design self-paced regularizers or analyze their properties accordingly. The self-paced implicit regularizer ψ(λ, v) defined here is derived from robust loss function φ(λ, t). By establishing the relations between φ(λ, t) and ψ(λ, v), we can analyze their working mechanisms as well as develop new SPL regularizers based on the development of robust loss functions. Moreover, the properties of ψ(λ, v) and its corresponding minimizer function σ(λ, t) can be learned from φ(λ, t)."
    }, {
      "heading" : "3.2 Self-Paced Learning via Implicit Regularizers",
      "text" : "We can develop an implicit regularization framework for SPL based on the proposed self-paced implicit regularizer. By substituting the regularization term g(λ, v) in (1) with a self-paced implicit regularizer ψ(λ, v) given in Definition 1, we obtain the following SPL-IR problem,\nmin w,v E(w,v;λ) =\nn ∑\ni=1\nviL(yi, f(xi,w)) + ψ(λ, vi). (8)\nIt can be solved via ASS algorithm, which alternatively optimizes w and v while keeping the other fixed. However, different from existing SPL regularizers, the analytic form of ψ(λ, v) in (8) can be unknown and the optimal v∗ is determined by the corresponding minimizer function given in Definition 1. The optimization procedure of (8) is described in Algorithm 1. Model (8) is called an implicit regularization framework since it does not require the explicit form of ψ(λ, v). The benefit of implicit regularization has been analyzed in [18, 22].\nAn insightful phenomenon is that the learning procedure of SPL-IR is actually associated with certain latent loss functions. For example, for a certain implicit regularizer and its corresponding minimizer function v∗i = σ(λ, ℓi) = 1/(1 + ℓi/λ\n2) in Algorithm 1 (where ℓi = L(yi, f(xi,w∗))), one is actually minimizing a latent robust function ∑n\ni=1 λ 2 log(1 + ℓi/λ 2) during each round. Figure 1 gives a graphical illustration. The latent loss function φ(λ, ℓ) can be considered to carry out a meaningful transformation on original loss ℓ. When ℓ is larger than a certain threshold, φ(λ, ℓ)\nbecomes a constant and its corresponding minimizer function σ(λ, ℓ) becomes zero, hence the related sample is not considered for optimization. Through this, it can suppress the influence of hard samples (refer to larger ℓ) while retaining that of easy samples (refer to smaller ℓ). This may also provide some inspirations on the robustness of SPL-IR to outliers and heavy noise as they can usually cause larger losses. More specifically, starting with a small λ (e.g. 0.3), only a small part of samples with very small losses will be involved (they are considered to contain reliable information). As λ increases, the suppressing effect of φ(λ, ℓ) on larger losses becomes weaker and their corresponding weights increase, consequently more and more hard samples with larger losses (may also contain more knowledge) are involved into training process. While gradually incorporating these knowledge, the model becomes stronger and stronger. The learning procedure of some existing regularizers like hard and linear [19] can also be explained under the framework of SPL-IR.\nSPL-IR in (8) is considered as a general SPL framework from two aspects: firstly, ψ(λ, v) represents a spectrum of self-paced implicit regularizer that is developed based on robust loss function and convex conjugacy theory; secondly, ψ(λ, v) is independent of specific model objective L(yi, f(xi,w)) and thus can be used in various applications. Besides, standard ASS strategy is used for both SPL with explicit regularizer (model (1)) and SPL-IR (model (8)). It includes a weighted loss minimization step and a weight updating step at each iteration, and the time overhead is mainly in the former step. Hence for a specific loss function L(yi, f(xi,w)) and a fixed number of iteration, the time complexities of SPL with explicit regularizer and SPL-IR is in the same order of magnitude."
    }, {
      "heading" : "3.3 SPL-IR and Half-Quadratic Optimization",
      "text" : "We can develop new self-paced implicit regularizers based on the development of robust loss functions. Specifically, we analyze the relations between SPL-IR and HQ optmization and provide several self-paced implicit regularizers accordingly. For better demonstration, we first give an equivalent quadratic form definition of self-paced implicit regularizer,\nDefinition 2 (Quadratic Form). Self-Paced Implicit Regularizer. A self-paced implicit regularizer ψ(λ, v) is defined as the dual potential function of a robust loss function φ(λ, t), and satisfies\n1. φ(λ, t) = minv≥0 12 vt 2 + ψ(λ, v);\n2. σ(λ, t) is the minimizer function of φ(λ, t) and satisfies 12σ(λ, t)t 2 + ψ(λ, σ(λ, t)) ≤ 12vt2 + ψ(λ, v), ∀ v ∈ R+. 3. σ(λ, t) is non-negative and up-bounded, ∀ t ∈ R+; 4. σ(λ, t) is monotonically decreasing w.r.t. t, ∀ t ∈ R+; 5. σ(λ, t) is monotonous w.r.t. λ ∈ R+; where λ is a hyper-parameter and it is the same in φ(λ, t), ψ(λ, v) and σ(λ, t). λ is considered to be fixed in the first four conditions.\nAlgorithm 1 : Self-Paced Learning via Implicit Regularizers Input: Input dataset D = {xi, yi}ni=1, step size µ > 1. Output: Model parameter w.\n1: Initialize sample weights v∗ and parameter λ; 2: repeat 3: Update (w∗,v∗) = argminw,v E(w,v;λ) by using ASS algorithms, v is iteratively optimized by the corresponding minimizer function σ; 4: Monotone increase (or decrease) λ by step-size µ; 5: until convergence. 6: return w∗\nThe equivalency of Definition 1 and Definition 2 is shown in the appendix. Seen from Definition 2, there is a close relationship between self-paced implicit regularizer and the dual potential function defined in HQ reformulation (5). Apparently, the dual potential function in (5) and the minimizer function in (7) satisfy the first two conditions in Definition 2, and self-paced implicit regularizer imposes further constraints on the minimizer function σ(λ, t) for the regimes of SPL. Many loss functions and their corresponding minimizer functions in multiplicative form of HQ have been developed (some of them are tabulated in Table 1). It is easy to verify that the functions in Table 1 satisfy all the conditions in Definition 2, hence they can be adjusted for self-paced implicit regularizers. The loss functions in Table 1 are well defined and have proven to be effective in many areas [9]. Meanwhile, though self-paced implicit regularizer can be developed from HQ optimization, their optimization procedures are quite different. In HQ, one mainly focuses on the minimization of loss function φ(λ, t) and hyper-parameter λ is predetermined and fixed during the optimization. While aiming to gradually optimize from easy to hard samples, SPL-IR uses the right-hand side vt2/2 + ψ(λ, v) to model problems and one key concern is the weighting strategy that determined by the minimizer function σ(λ, t). Besides, in order to gradually increase samples, λ is updated stage by stage in SPL-IR.\nFigure 2 gives an intuitive interpretation. If we set ti = √ L(yi, f(xi,w∗)) and use the minimizer function of Welsch given in Table 1 for weight updating in Algorithm 1, model (8) can be considered to sequential optimize a group of Welsch loss functions with monotonically increasing λ. Hence SPL-IR is able to gradually optimize from easy to hard samples while incorporating the good properties of robust Welsch functions. On the other hand, for HQ optimization, λ is predefined and fixed during the whole optimization. Hence its performance may be largely influenced by the selection of λ. For example, when λ is somehow small (e.g. λ < 1 in Figure 2(b)), some hard samples will be simply considered as outliers and discarded. From the comparisons in Figure 2(b), we can find that SPL-IR can always outperform HQ for every λ."
    }, {
      "heading" : "4 Experiments",
      "text" : "To illustrate the correctness and effectiveness of the developed SPL-IR model, we apply it to three classical tasks: matrix factorization, clustering and classification. Experimental results demonstrate that the proposed self-paced implicit regularizers outperform baseline algorithms and achieve comparable or even better performance comparing to the artificially designed SPL regularizers.\nThere are two hyper-parameter (λ, µ) that need to be tuned in Algorithm 1. We follow a standard setting in SPL [14] for all our experiments. That is, λ is initialized to obtain about half samples, then it is iteratively updated to involve more and more samples gradually. The practical updating direction depends on the specific minimizer function. For functions given in Table 1, λT+1 = λT /µ for L1-L2 while λT+1 = λT ∗ µ for Huber, Cauchy and Welsch, where µ > 1 is a step factor and T\nis an iteration number. µ is empirically set to 1.05 in our experiments. Similar settings are adjusted for the competing SPL regularizers, including SPL-hard [14] and SPL-mixture [32]."
    }, {
      "heading" : "4.1 Matrix Factorization",
      "text" : "Matrix factorization (MF) is one of the fundamental problems in machine learning and data mining. It aims to factorize an m × n data matrix Y into two smaller factors U ∈ Rm×r and V ∈ Rn×r, where r ≪ min(m,n), such that UVT is possibly close to Y. MF has been successfully implemented in many applications, such as collaborative filtering [24].\nHere we consider the MF problem on synthetic dataset. Specifically, the data used here is generated as follows: two matrices U and V, both of which are of size 100× 4, are first randomly generated with each entry drawn from the Gaussian distribution N (0, 1), leading to a ground truth rank-4 matrix Y0 = UVT . Then we randomly choose 40% of the entries and treat them as missing data. Another 20% of the entries are randomly selected and added to uniform noise on [−20, 20], and the rest are perturbed with Gaussian noise drawn from N (0, 0.12). Similar to [32], we consider L1-norm MF problem with L2-norm regularization, and the baseline algorithm is PRMF [27]. We modify it with different SPL regularizers for comparison. Two commonly used metrics are adopted here: (1) root mean square error (RMSE): 1√\nmn ||Y0 − ÛV̂T ||F , and (2) mean absolute error\n(MAE): 1 mn ||Y0−ÛV̂T ||1, where Û and V̂ denote the outputs of MF algorithms. All the algorithms are implemented with 50 realizations and their mean values are reported.\nTable 2 tabulates their numerical results. All SPL-IR algorithms obtain performance improvements over baseline algorithm PRMF, which shows the benefits of SPL regimes. Comparing among different SPL regularizers, the results of proposed self-paced implicit regularizers are comparable to or even better than that of mixture and hard schemes, especially for SPL-IR with welsch regularizer. These demonstrate the correctness and effectiveness of the proposed self-paced implicit regularizer. Figure 3 further plots the tendency curves of RMSE and MAE with different self-paced implicit regularizers and mixture regularizer for better understanding, the results of PRMF are also reported as a baseline. The performances of all implicit regularizers improve rapidly for the first few iterations\nas more and more easy samples are likely to be involved in these phases. With the increasing of the iterations, the improvements become steady as some hard instances or outliers are included."
    }, {
      "heading" : "4.2 Multi-view Clustering",
      "text" : "Multi-view clustering aims to group data with multiple views into their underlying classes [28]. Most existing multi-view clustering algorithms fit a non-convex model and may be stuck in bad local minima. To alleviate this, Xu et al. propose a multi-view self-paced learning algorithm (MSPL) that considers the learnability of both samples and views and achieves promising results in [29]. Here we simply modified their MSPL model with different SPL regularizers for comparison. The UCI Handwritten Digit dataset 1 is used in this experiment. It consists of 2,000 handwritten digits classified into ten categories (0-9). Each instance is represented in terms of the following six kinds of features (or views): Fourier coefficients of the character shapes (FOU), profile correlations (FAC), Karhunen-Love coefficients (KAR), pixel averages in 2 x 3 windows (PIX), Zernike moments (ZER), and morphological features (MOR). Here we make use of all the six views for all the comparing algorithms. The baseline algorithms are standard k-means on each single view’s representation and Con-MC (the features are concatenated on all views firstly, and then standard k-means is applied).\nFive commonly used metrics are adopted to measure the clustering performances: clustering accuracy (ACC), normalized mutual information (NMI), F-score, Purity, and adjusted rand index (AR) [10]. Higher value indicates better performance for all the metrics. All algorithms are implemented 20 times and both mean values and standard derivations are reported. Table 3 tabulates their numerical results. It can be seen that all the multi-view algorithms obtain significant improvements over single-view ones, which demonstrates the benefits of integrating information from different views. More importantly, comparing to Con-MC, the SPL-IR algorithms can further improve the performance by gradually optimizing from easy to hard samples and avoiding bad local minima. The proposed self-paced implicit regularizers are comparable to or even better than the compared SPL regularizers."
    }, {
      "heading" : "4.3 Classification",
      "text" : "The proposed self-paced implicit regularizers can be flexible implemented to supervised tasks. Here we conduct a binary classification task. Specifically, we utilize the L2-regularized Logistic Regression (LR) model as our baseline, and incorporate it with different SPL regularizers for comparison. Liblinear [3] is used as the solver of LR. Three real-world databases are considered: Breast1, Spambase1 and Svmguide1 [2]. Their statistical information is summarized in Table 4. For each dataset,\n1https://archive.ics.uci.edu/ml/datasets\nwe consider it without additional noise and with 20% random label noise, respectively. The 20% random label noise means we randomly select 20% samples from training data and reversal their labels (change positive to negative, and vice-versa). We use 10-fold cross validation for all the databases, and report both their mean values and their standard derivations.\nClassification accuracy is used for performance measure. Table 5 reports their numerical results. For both situations, SPL-IR algorithms can get performance improvements over original LR method to some extent. Moreover, when adding random label noise, the performance of original LR degenerates a lot, while the SPL algorithms can still obtain relatively high performance, especially for SPL-IR with welsch regularizer. This corroborates our analysis about the robustness of SPL-IR to outliers and heavy noise."
    }, {
      "heading" : "5 Conclusions",
      "text" : "In this paper, we study a group of new regularizer, named self-paced implicit regularizer for SPL based on the convex conjugate theory. The self-paced implicit regularizer is derived from robust loss function and its analytic form can be even unknown. Its properties and the corresponding minimizer function can be learned from the latent loss function directly. We then develop a general SPL framework (SPL-IR) based on it. We further demonstrate that the learning procedure of SPL-IR is actually associated with certain latent robust loss functions, thus may provide some theoretical inspirations on the working mechanisms of SPL-IR (such as the robustness to outliers or heavy noise). We later analyze the relations between SPL-IR and HQ optimization and develop a group of selfpaced implicit regularizer accordingly. Experimental results on both supervised and unsupervised tasks demonstrate the correctness and effectiveness the proposed self-paced implicit regularizer."
    }, {
      "heading" : "6 Appendix",
      "text" : ""
    }, {
      "heading" : "6.1 Proof of Proposition 1",
      "text" : "Proof. The proof sketch is similar to that in [20]. For ease of representation, we omit λ and use φ(t), ψ(v) and σ(t) for short. Some fundamental assumptions about φ(t) are: H1: φ : R+ → R is increasing with φ 6≡ 0 and φ(0) = 0; H2: φ(t) is C1 and concave; H3: limt→∞ φ(t)/t = 0. Put θ(t) = −φ(t), then θ is convex by H2. Its convex conjugate is θ∗(v) = supt≥0 {vt − θ(t)}. By the Fenchel-Moreau theorem [23], the convex conjugate of θ∗ is θ, that is θ(t) = (θ∗)∗(t) = supv≤0 {vt− θ∗(v)} = − infv≥0 {vt+ θ∗(−v)}. Thus we have\nψ(v) = θ∗(−v) = sup t≥0 {−vt− θ(t)} = sup t≥0 {−vt+ φ(t)}. (9)\nφ(t) = −θ(t) = inf v≥0 {vt+ θ∗(−v)} = inf v≥0 {vt+ ψ(v)}. (10)\nThen the problem becomes how to achieve the supremum in (9) jointly with the infimum in (10). For any v̂ > 0, define fv̂ : R+ → R by fv̂(t) = v̂t + θ(t), then we have ψ(v̂) = − inft≥0 fv̂(t) from (9). According to H1-H3, fv̂ is convex with fv̂(0) = 0 and limt→+∞ fv̂(t) = +∞. Thus fv̂ can reach its unique minimum at a t̂ ≥ 0, and ψ(v̂) = −v̂t̂+ φ(t̂) from (9). Hence equivalently the infimum in (10) is reached at v̂ as φ(t̂) = v̂t̂ + ψ(v̂). Then we have v̂ = σ(t) = −θ′(t) = φ′(t). Thus the optimal v is uniquely determined by the minimizer function σ(t) that is derived from φ(t). The analytic form of the dual potential function ψ(v) could be unknown during the optimization. The proof is then completed."
    }, {
      "heading" : "6.2 Definition 1 and Definition 2",
      "text" : "To show the equivalency of Definition 1 and Definition 2 in the main body, we first give the following proposition about Definition 2.\nProposition 2 For any fixed λ, if φ(λ, t) in Definition 2 further satisfies the conditions referred in [20], its minimizer function σ(λ, t) is uniquely determined by φ(λ, t) and the analytic form of ψ(λ, v) can be even unknown during the optimization.\nProof. The proof sketch is similar to that in [20]. For ease of representation, we omit λ and use φ(t), ψ(v) and σ(t) for short. Some fundamental assumptions about φ(t) are: H1: φ : R+ → R is increasing with φ 6≡ 0 and φ(0) = 0; H2: t → φ( √ t) is concave; H3: φ(t) is C1; H4: limt→∞ φ(t)/t 2 = 0. Put θ(t) = −φ( √ t), then θ is convex by H2. Its convex conjugate is θ∗(v) = supt≥0 {vt− θ(t)}. By the Fenchel-Moreau theorem [23], the convex conjugate of θ∗ is θ, that is θ(t) = (θ∗)∗(t) = supv≤0 {vt− θ∗(v)} = − infv≥0 {vt+ θ∗(−v)}. Define ψ(v) = θ∗(− 12v), we have\nψ(v) = sup t≥0 {−1 2 vt− θ(t)} = sup t≥0 {−1 2 vt2 + φ(t)}. (11)\nφ(t) = −θ(t2) = inf v≥0 {vt2 + θ∗(−v)} = inf v≥0 {1 2 vt2 + ψ(v)}. (12)\nThen the problem becomes how to achieve the supremum in (11) jointly with the infimum in (12). For any v̂ > 0, define fv̂ : R+ → R by fv̂(t) = 12 v̂t + θ(t), then we have ψ(v̂) = − inft≥0 fv̂(t) from (11). According to H1-H4, fv̂ is convex with fv̂(0) = 0 and limt→+∞ fv̂(t) = +∞. Thus fv̂ can reach its unique minimum at a t̂ ≥ 0, and ψ(v̂) = − 12 v̂t̂2 + φ(t̂) from (11). Hence equivalently the infimum in (12) is reached at v̂ as φ(t̂) = 12 v̂t̂\n2 + ψ(v̂). Then we have v̂ = σ(t) = −2θ′(t2) = φ′(t)/t. Thus the optimal v is uniquely determined by the minimizer function σ(t) that is only related to φ(t). The analytic form of the dual potential function ψ(v) could be unknown during the optimization. The proof is then completed.\nDenote ℓi = L(yi, f(xi,w)) and rewrite model (8) in the main body as\nmin w,v E(w,v;λ) =\nn ∑\ni=1\nvi( √ ℓi) 2 + ψ(λ, vi). (13)\nIf we adopt ψ(λ, vi) with an implicit regularizer given in Definition 2 and use v∗i = 1 2σ(λ, √ ℓi),\nwhere σ(λ, √ ℓi) is the minimizer function in Definition 2, model (13) is optimizing a latent loss function ∑n i=1 φ(λ, √ ℓi) equivalently.\nNow we demonstrate the equivalency of Definition 1 and Definition 2 in the main body. For easy of representation, we omit λ, and use {φ1(t), ψ1(v), σ1(t)} and {φ2(t), ψ2(v), σ2(t)} to refer to the functions in Definition 1 and Definition 2, respectively. Considering a simplified model\nmin w,v vL(y, f(x,w)) + ψ(v). (14)\nDenote ℓ = L(y, f(x,w)). We show that for a same implicit regularizer ψ(v) = ψ1(v) = ψ2(v), the optimal v∗ and the latent loss function of model (14) derived from Definition 1 and Definition 2 are the same. Specifically, let ψ1(v) = ψ2(v) = supt≥0 {−vt + φ1(t)} (where φ1(t) satisfies conditions H1-H3 of Proposition 1 in the main body), it is easy to verify that its corresponding latent loss function is φ1(ℓ) and optimal v∗ = σ1(ℓ) = φ′1(ℓ) according to Definition 1 and Proposition 1. Meanwhile, we have ψ2(v) = supt≥0 {−vt + φ1(t)} = supt≥0 {−vt2 + φ2(t)}, where φ2(t) = φ1(t 2). Then model (14) can be considered to optimize a latent loss function φ2( √ ℓ) = φ1(ℓ) and\nthe optimal v∗ = 12σ2( √ ℓ) = φ′1(ℓ) according to Definition 2 and Proposition 2. Thus we show the equivalency of Definition 1 and Definition 2."
    }, {
      "heading" : "6.3 Self-Paced Regularizer",
      "text" : "Similar definitions of self-paced regularizer (or self-paced function) have been proposed in [13, 32, 11]. The definition in [32] is shown below.\nDefinition 3 (Self-Paced Regularizer) [32]: Suppose that v is a weight variable, ℓ is the loss, and λ is the learning pace parameter. g(λ, v) is called self-paced rgularizer, if\n1. g(λ, v) is convex with respect to v ∈ [0, 1]; 2. v∗(λ, ℓ) is monotonically decreasing w.r.t. ℓ, and it holds that limℓ→0 v∗(λ, ℓ) = 1, limℓ→∞ v ∗(λ, ℓ) = 0 ;\n3. v∗(λ, ℓ) is monotonically increasing w.r.t. λ, and it holds that limλ→0 v∗(λ, ℓ) = 0, limλ→∞ v\n∗(λ, ℓ) ≤ 1 ; where v∗(λ, ℓ) = argminv∈[0,1] vℓ+ g(λ, v).\nTable 6 tabulates some examples of self-paced regularizers g(λ, v) and their corresponding v∗(λ, ℓ). We modify their original expressions for better comparison. It is still nontrivial to design self-paced regularizers or analyze their properties according to Definition 3. Besides, though shown to be effective in many applications experimentally, the underlying working mechanism of SPL is still unclear.\nOne attempt about the underlying working mechanism of SPL is [19]. Starting from SPL regularizers and their minimizer functions, they show that the ASS method used for SPL accords with the majorization minimization [26] algorithm implemented on a latent SPL objective, and deduced the latent objective of hard, linear and mixture regulraizers. In contrast, we start from a latent loss function φ(λ, ℓ) directly and propose self-paced implicit regularizer based on the convex conjugacy theory. We establish the relations between robust loss function φ(λ, ℓ), self-paced implicit regularizer ψ(λ, v) and minimizer function σ(λ, ℓ). According to Definition 1, ψ(λ, v) and σ(λ, ℓ) are derived from latent loss function φ(λ, ℓ), thus we can analyze their properties based on the development of φ(λ, ℓ) (many loss functions have be widely studied in related areas). We further demonstrate that for SPL with the proposed implicit regularizer, its learning procedure actually associates with certain latent robust loss functions. Thus we can provide some inspirations for the working mechanism of SPL (e.g. its robustness to outliers and heavy noise). Moreover, by establishing the relations between φ(λ, ℓ) and ψ(λ, v), we can develop new SPL regularizers based on the development of robust loss functions. Specifically, we analyze the relations between self-paced implicit regularizer and HQ optimization. Many robust loss functions and their minimizer functions have been developed and widely used in HQ optimization, and they can be adjusted for self-paced implicit regularizers (some examples are given in Table 1 in main body)."
    } ],
    "references" : [ {
      "title" : "Curriculum learning",
      "author" : [ "Y. Bengio", "J. Louradour", "R. Collobert", "J. Weston" ],
      "venue" : "In ICML,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2009
    }, {
      "title" : "Libsvm: a library for support vector machines",
      "author" : [ "C.-C. Chang", "C.-J. Lin" ],
      "venue" : "ACM Transactions on Intelligent Systems and Technology,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2011
    }, {
      "title" : "Liblinear: A library for large linear classification",
      "author" : [ "R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin" ],
      "venue" : "JMLR, 9(Aug):1871–1874,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2008
    }, {
      "title" : "Constrained restoration and the recovery of discontinuities",
      "author" : [ "D. Geman", "G. Reynolds" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1992
    }, {
      "title" : "Nonlinear image recovery with half-quadratic regularization",
      "author" : [ "D. Geman", "C. Yang" ],
      "venue" : "TIP, 4(7):932–946,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1995
    }, {
      "title" : "Two-stage sparse representation for robust recognition on large-scale database",
      "author" : [ "R. He", "B.-G. Hu", "W.-S. Zheng", "Y. Guo" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2010
    }, {
      "title" : "Robust recovery of corrupted low-rankmatrix by implicit regularizers",
      "author" : [ "R. He", "T. Tan", "L. Wang" ],
      "venue" : "TPAMI, 36(4):770–783,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2014
    }, {
      "title" : "Maximum correntropy criterion for robust face recognition",
      "author" : [ "R. He", "W.S. Zheng", "B.G. Hu" ],
      "venue" : "TPAMI, 33(8):1561–1576,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2011
    }, {
      "title" : "Half-quadratic-based iterative minimization for robust sparse representation",
      "author" : [ "R. He", "W.-S. Zheng", "T. Tan", "Z. Sun" ],
      "venue" : "TPAMI, 36(2):261–275,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2014
    }, {
      "title" : "Comparing partitions",
      "author" : [ "L. Hubert", "P. Arabie" ],
      "venue" : "Journal of Classification,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1985
    }, {
      "title" : "Easy samples first: Self-paced reranking for zero-example multimedia search",
      "author" : [ "L. Jiang", "D. Meng", "T. Mitamura", "A.G. Hauptmann" ],
      "venue" : "In MM,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "Self-paced learning with diversity",
      "author" : [ "L. Jiang", "D. Meng", "S.-I. Yu", "Z. Lan", "S. Shan", "A. Hauptmann" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2014
    }, {
      "title" : "Self-paced curriculum learning",
      "author" : [ "L. Jiang", "D. Meng", "Q. Zhao", "S. Shan", "A.G. Hauptmann" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2015
    }, {
      "title" : "Self-paced learning for latent variable models",
      "author" : [ "M.P. Kumar", "B. Packer", "D. Koller" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2010
    }, {
      "title" : "Learning the easy things first: Self-paced visual category discovery",
      "author" : [ "Y.J. Lee", "K. Grauman" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2011
    }, {
      "title" : "Multi-objective self-paced learning",
      "author" : [ "H. Li", "M. Gong", "D. Meng", "Q. Miao" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2016
    }, {
      "title" : "Self-paced cross-modal subspace matching",
      "author" : [ "J. Liang", "Z. Li", "D. Cao", "R. He", "J. Wang" ],
      "venue" : "In SIGIR,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2016
    }, {
      "title" : "Approximate computation and implicit regularization for very large-scale data analysis",
      "author" : [ "M.W. Mahoney" ],
      "venue" : "In PODS,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2012
    }, {
      "title" : "What objective does self-paced learning indeed optimize",
      "author" : [ "D. Meng", "Q. Zhao" ],
      "venue" : "arXiv preprint arXiv:1511.06049,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2015
    }, {
      "title" : "The equivalence of half-quadratic minimization and the gradient linearization iteration",
      "author" : [ "M. Nikolova", "R.H. Chan" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2007
    }, {
      "title" : "Analysis of half-quadratic minimization methods for signal and image recovery",
      "author" : [ "M. Nikolova", "M.K. Ng" ],
      "venue" : "SIAM Journal on Scientific Computing,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2005
    }, {
      "title" : "Implementing regularization implicitly via approximate eigenvector computation",
      "author" : [ "L. Orecchia", "M.W. Mahoney" ],
      "venue" : "In ICML,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2011
    }, {
      "title" : "Convex analysis",
      "author" : [ "R.T. Rockafellar" ],
      "venue" : "Princeton university press,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2015
    }, {
      "title" : "Probabilistic matrix factorization",
      "author" : [ "R. Salakhutdinov", "A. Mnih" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2008
    }, {
      "title" : "Self-paced learning for long-term tracking",
      "author" : [ "J.S. Supancic", "D. Ramanan" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2013
    }, {
      "title" : "Parameter convergence for em and mm algorithms",
      "author" : [ "F. Vaida" ],
      "venue" : "Statistica Sinica, pages 831–840,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2005
    }, {
      "title" : "A probabilistic approach to robust matrix factorization",
      "author" : [ "N. Wang", "T. Yao", "J. Wang", "D.-Y. Yeung" ],
      "venue" : "In ECCV",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2012
    }, {
      "title" : "A survey on multi-view learning",
      "author" : [ "C. Xu", "D. Tao" ],
      "venue" : "arXiv preprint arXiv:1304.5634,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2013
    }, {
      "title" : "Multi-view self-paced learning for clustering",
      "author" : [ "C. Xu", "D. Tao" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2015
    }, {
      "title" : "Robust feature extraction via information theoretic learning",
      "author" : [ "X.-T. Yuan", "B.-G. Hu" ],
      "venue" : "In ICML,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2009
    }, {
      "title" : "A self-paced multiple-instance learning framework for co-saliency detection",
      "author" : [ "D. Zhang", "D. Meng", "C. Li", "L. Jiang", "Q. Zhao", "J. Han" ],
      "venue" : "In ICCV,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2015
    }, {
      "title" : "Self-paced learning for matrix factorization",
      "author" : [ "Q. Zhao", "D. Meng", "L. Jiang", "Q. Xie", "Z. Xu", "A.G. Hauptmann" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "propose a new learning strategy called curriculum learning (CL) in [1], which gradually includes more and more hard samples into training process.",
      "startOffset" : 67,
      "endOffset" : 70
    }, {
      "referenceID" : 13,
      "context" : "propose a new learning strategy named selfpaced learning (SPL) that incorporates the curriculum updating in the process of model optimization [14].",
      "startOffset" : 142,
      "endOffset" : 146
    }, {
      "referenceID" : 15,
      "context" : "Due to its ability of avoiding bad local minima and improving the generalization performance, many works have been developed based on SPL [16, 17, 13, 31, 25, 15].",
      "startOffset" : 138,
      "endOffset" : 162
    }, {
      "referenceID" : 16,
      "context" : "Due to its ability of avoiding bad local minima and improving the generalization performance, many works have been developed based on SPL [16, 17, 13, 31, 25, 15].",
      "startOffset" : 138,
      "endOffset" : 162
    }, {
      "referenceID" : 12,
      "context" : "Due to its ability of avoiding bad local minima and improving the generalization performance, many works have been developed based on SPL [16, 17, 13, 31, 25, 15].",
      "startOffset" : 138,
      "endOffset" : 162
    }, {
      "referenceID" : 30,
      "context" : "Due to its ability of avoiding bad local minima and improving the generalization performance, many works have been developed based on SPL [16, 17, 13, 31, 25, 15].",
      "startOffset" : 138,
      "endOffset" : 162
    }, {
      "referenceID" : 24,
      "context" : "Due to its ability of avoiding bad local minima and improving the generalization performance, many works have been developed based on SPL [16, 17, 13, 31, 25, 15].",
      "startOffset" : 138,
      "endOffset" : 162
    }, {
      "referenceID" : 14,
      "context" : "Due to its ability of avoiding bad local minima and improving the generalization performance, many works have been developed based on SPL [16, 17, 13, 31, 25, 15].",
      "startOffset" : 138,
      "endOffset" : 162
    }, {
      "referenceID" : 28,
      "context" : "One key issue in SPL is to obtain better weighting strategy that is determined by the minimizer functions, and existing methods usually pursue this by artificially designing the explicit form of SPL regularizers [29, 32, 11, 12].",
      "startOffset" : 212,
      "endOffset" : 228
    }, {
      "referenceID" : 31,
      "context" : "One key issue in SPL is to obtain better weighting strategy that is determined by the minimizer functions, and existing methods usually pursue this by artificially designing the explicit form of SPL regularizers [29, 32, 11, 12].",
      "startOffset" : 212,
      "endOffset" : 228
    }, {
      "referenceID" : 10,
      "context" : "One key issue in SPL is to obtain better weighting strategy that is determined by the minimizer functions, and existing methods usually pursue this by artificially designing the explicit form of SPL regularizers [29, 32, 11, 12].",
      "startOffset" : 212,
      "endOffset" : 228
    }, {
      "referenceID" : 11,
      "context" : "One key issue in SPL is to obtain better weighting strategy that is determined by the minimizer functions, and existing methods usually pursue this by artificially designing the explicit form of SPL regularizers [29, 32, 11, 12].",
      "startOffset" : 212,
      "endOffset" : 228
    }, {
      "referenceID" : 10,
      "context" : "Specifically, a definition of self-paced regularizer is given in [11].",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 18,
      "context" : "One attempt in this aspect is [19], they show that the ASS method used for SPL accords with the majorization minimization [26] algorithm implemented on a latent SPL objective, and deduce the latent objective of hard, linear and mixture regulraizers.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 25,
      "context" : "One attempt in this aspect is [19], they show that the ASS method used for SPL accords with the majorization minimization [26] algorithm implemented on a latent SPL objective, and deduce the latent objective of hard, linear and mixture regulraizers.",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 0,
      "context" : "Since li = L(yi, f(xi,w) is constant oncew is given, the optimal value of vi is uniquely determined by the corresponding minimizer function σ(λ, li) that satisfies σ(λ, li)li + g(λ, σ(λ, li)) ≤ vili + g(λ, vi), ∀vi ∈ [0, 1].",
      "startOffset" : 217,
      "endOffset" : 223
    }, {
      "referenceID" : 13,
      "context" : "(3) For example, if g(λ, vi) = −λvi [14], the optimal v∗ i is calculated by v∗ i = σ(λ, li) = { 1, if li ≤ λ 0, otherwise (4)",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 28,
      "context" : "Many efforts have been put into the learning of minimizer functions [29, 32, 11, 12, 25], and we name them as SPL with explicit regularizers as they usually require the explicit form of regularizer g(λ, v) .",
      "startOffset" : 68,
      "endOffset" : 88
    }, {
      "referenceID" : 31,
      "context" : "Many efforts have been put into the learning of minimizer functions [29, 32, 11, 12, 25], and we name them as SPL with explicit regularizers as they usually require the explicit form of regularizer g(λ, v) .",
      "startOffset" : 68,
      "endOffset" : 88
    }, {
      "referenceID" : 10,
      "context" : "Many efforts have been put into the learning of minimizer functions [29, 32, 11, 12, 25], and we name them as SPL with explicit regularizers as they usually require the explicit form of regularizer g(λ, v) .",
      "startOffset" : 68,
      "endOffset" : 88
    }, {
      "referenceID" : 11,
      "context" : "Many efforts have been put into the learning of minimizer functions [29, 32, 11, 12, 25], and we name them as SPL with explicit regularizers as they usually require the explicit form of regularizer g(λ, v) .",
      "startOffset" : 68,
      "endOffset" : 88
    }, {
      "referenceID" : 24,
      "context" : "Many efforts have been put into the learning of minimizer functions [29, 32, 11, 12, 25], and we name them as SPL with explicit regularizers as they usually require the explicit form of regularizer g(λ, v) .",
      "startOffset" : 68,
      "endOffset" : 88
    }, {
      "referenceID" : 20,
      "context" : "Half-quadratic optimization [21, 5, 4] is a commonly used optimization method that based on the convex conjugacy theory.",
      "startOffset" : 28,
      "endOffset" : 38
    }, {
      "referenceID" : 4,
      "context" : "Half-quadratic optimization [21, 5, 4] is a commonly used optimization method that based on the convex conjugacy theory.",
      "startOffset" : 28,
      "endOffset" : 38
    }, {
      "referenceID" : 3,
      "context" : "Half-quadratic optimization [21, 5, 4] is a commonly used optimization method that based on the convex conjugacy theory.",
      "startOffset" : 28,
      "endOffset" : 38
    }, {
      "referenceID" : 6,
      "context" : "It tries to solve a nonlinear objective function via optimizing a series of half-quadratic reformulation problems iteratively [7, 9, 8, 6, 30].",
      "startOffset" : 126,
      "endOffset" : 142
    }, {
      "referenceID" : 8,
      "context" : "It tries to solve a nonlinear objective function via optimizing a series of half-quadratic reformulation problems iteratively [7, 9, 8, 6, 30].",
      "startOffset" : 126,
      "endOffset" : 142
    }, {
      "referenceID" : 7,
      "context" : "It tries to solve a nonlinear objective function via optimizing a series of half-quadratic reformulation problems iteratively [7, 9, 8, 6, 30].",
      "startOffset" : 126,
      "endOffset" : 142
    }, {
      "referenceID" : 5,
      "context" : "It tries to solve a nonlinear objective function via optimizing a series of half-quadratic reformulation problems iteratively [7, 9, 8, 6, 30].",
      "startOffset" : 126,
      "endOffset" : 142
    }, {
      "referenceID" : 29,
      "context" : "It tries to solve a nonlinear objective function via optimizing a series of half-quadratic reformulation problems iteratively [7, 9, 8, 6, 30].",
      "startOffset" : 126,
      "endOffset" : 142
    }, {
      "referenceID" : 19,
      "context" : "Given a differentiable function φ(t) : R → R, if φ(t) further satisfies the conditions of the multiplicative form of HQ optimization in [20], the following equation holds for any fixed t,",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 20,
      "context" : "More analysis about φ(t) and ψ(p) refers to [21].",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 19,
      "context" : "Proposition 1 For any fixed λ, if φ(λ, t) in Definition 1 further satisfies the conditions referred in [20], its minimizer function σ(λ, t) is uniquely determined by φ(λ, t) and the analytic form of the dual potential function ψ(λ, v) can be even unknown during the optimization.",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 10,
      "context" : "have given a definition of self-paced regularizer and derived necessary conditions of the regularizer and the corresponding minimizer function for SPL in [11].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 17,
      "context" : "The benefit of implicit regularization has been analyzed in [18, 22].",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 21,
      "context" : "The benefit of implicit regularization has been analyzed in [18, 22].",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 20,
      "context" : "For HQ-welsch, standard HQ algorithm [21] is implemented with each λ independently.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 18,
      "context" : "The learning procedure of some existing regularizers like hard and linear [19] can also be explained under the framework of SPL-IR.",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 8,
      "context" : "The loss functions in Table 1 are well defined and have proven to be effective in many areas [9].",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 13,
      "context" : "We follow a standard setting in SPL [14] for all our experiments.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 13,
      "context" : "Similar settings are adjusted for the competing SPL regularizers, including SPL-hard [14] and SPL-mixture [32].",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 31,
      "context" : "Similar settings are adjusted for the competing SPL regularizers, including SPL-hard [14] and SPL-mixture [32].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 23,
      "context" : "MF has been successfully implemented in many applications, such as collaborative filtering [24].",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 31,
      "context" : "Similar to [32], we consider L1-norm MF problem with L2-norm regularization, and the baseline algorithm is PRMF [27].",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 26,
      "context" : "Similar to [32], we consider L1-norm MF problem with L2-norm regularization, and the baseline algorithm is PRMF [27].",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 27,
      "context" : "Multi-view clustering aims to group data with multiple views into their underlying classes [28].",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 28,
      "context" : "propose a multi-view self-paced learning algorithm (MSPL) that considers the learnability of both samples and views and achieves promising results in [29].",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 9,
      "context" : "Five commonly used metrics are adopted to measure the clustering performances: clustering accuracy (ACC), normalized mutual information (NMI), F-score, Purity, and adjusted rand index (AR) [10].",
      "startOffset" : 189,
      "endOffset" : 193
    }, {
      "referenceID" : 2,
      "context" : "Liblinear [3] is used as the solver of LR.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 1,
      "context" : "Three real-world databases are considered: Breast1, Spambase1 and Svmguide1 [2].",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 19,
      "context" : "The proof sketch is similar to that in [20].",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 22,
      "context" : "By the Fenchel-Moreau theorem [23], the convex conjugate of θ∗ is θ, that is θ(t) = (θ∗)∗(t) = supv≤0 {vt− θ∗(v)} = − infv≥0 {vt+ θ∗(−v)}.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 19,
      "context" : "Proposition 2 For any fixed λ, if φ(λ, t) in Definition 2 further satisfies the conditions referred in [20], its minimizer function σ(λ, t) is uniquely determined by φ(λ, t) and the analytic form of ψ(λ, v) can be even unknown during the optimization.",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 19,
      "context" : "The proof sketch is similar to that in [20].",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 22,
      "context" : "By the Fenchel-Moreau theorem [23], the convex conjugate of θ∗ is θ, that is θ(t) = (θ∗)∗(t) = supv≤0 {vt− θ∗(v)} = − infv≥0 {vt+ θ∗(−v)}.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 12,
      "context" : "Similar definitions of self-paced regularizer (or self-paced function) have been proposed in [13, 32, 11].",
      "startOffset" : 93,
      "endOffset" : 105
    }, {
      "referenceID" : 31,
      "context" : "Similar definitions of self-paced regularizer (or self-paced function) have been proposed in [13, 32, 11].",
      "startOffset" : 93,
      "endOffset" : 105
    }, {
      "referenceID" : 10,
      "context" : "Similar definitions of self-paced regularizer (or self-paced function) have been proposed in [13, 32, 11].",
      "startOffset" : 93,
      "endOffset" : 105
    }, {
      "referenceID" : 31,
      "context" : "The definition in [32] is shown below.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 31,
      "context" : "Definition 3 (Self-Paced Regularizer) [32]: Suppose that v is a weight variable, l is the loss, and λ is the learning pace parameter.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 0,
      "context" : "g(λ, v) is convex with respect to v ∈ [0, 1]; 2.",
      "startOffset" : 38,
      "endOffset" : 44
    }, {
      "referenceID" : 0,
      "context" : "λ, and it holds that limλ→0 v∗(λ, l) = 0, limλ→∞ v ∗(λ, l) ≤ 1 ; where v∗(λ, l) = argminv∈[0,1] vl+ g(λ, v).",
      "startOffset" : 90,
      "endOffset" : 95
    }, {
      "referenceID" : 13,
      "context" : "[14] −λ∑ni=1 vi, λ > 0 {",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11, 13] 1 2 λ ∑n i=1(v 2 i − 2vi), λ > 0 {",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 12,
      "context" : "[11, 13] 1 2 λ ∑n i=1(v 2 i − 2vi), λ > 0 {",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 10,
      "context" : "[11, 13] n",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 12,
      "context" : "[11, 13] n",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 10,
      "context" : "[11, 13] − ζ n",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 12,
      "context" : "[11, 13] − ζ n",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 11,
      "context" : "[12] −λ∑ i=1 vi − γ||v||2,1, λ > 0, γ > 0 { 1, li ≤ λ+ γ 1 √ i− √ i−1 0, otherwise",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 28,
      "context" : "[29] n",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 31,
      "context" : "[32] ∑n i=1 λγ λvi+γ , λ > 0, γ > 0 ",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 30,
      "context" : "[31] − λ K",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "One attempt about the underlying working mechanism of SPL is [19].",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 25,
      "context" : "Starting from SPL regularizers and their minimizer functions, they show that the ASS method used for SPL accords with the majorization minimization [26] algorithm implemented on a latent SPL objective, and deduced the latent objective of hard, linear and mixture regulraizers.",
      "startOffset" : 148,
      "endOffset" : 152
    } ],
    "year" : 2016,
    "abstractText" : "Self-paced learning (SPL) mimics the cognitive mechanism of humans and animals that gradually learns from easy to hard samples. One key issue in SPL is to obtain better weighting strategy that is determined by minimizer function. Existing methods usually pursue this by artificially designing the explicit form of SPL regularizer. In this paper, we focus on the minimizer function, and study a group of new regularizer, named self-paced implicit regularizer that is deduced from robust loss function. Based on the convex conjugacy theory, the minimizer function for self-paced implicit regularizer can be directly learned from the latent loss function, while the analytic form of the regularizer can be even known. A general framework (named SPL-IR) for SPL is developed accordingly. We demonstrate that the learning procedure of SPL-IR is associated with latent robust loss functions, thus can provide some theoretical inspirations for its working mechanism. We further analyze the relation between SPL-IR and half-quadratic optimization. Finally, we implement SPL-IR to both supervised and unsupervised tasks, and experimental results corroborate our ideas and demonstrate the correctness and effectiveness of implicit regularizers.",
    "creator" : "LaTeX with hyperref package"
  }
}