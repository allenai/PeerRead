{
  "name" : "1702.00318.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Hybrid Evolutionary Algorithm Based on Solution Merging for the Longest Arc-Preserving Common Subsequence Problem",
    "authors" : [ "Christian Blum", "Maria J. Blesa" ],
    "emails" : [ "christian.blum@iiia.csic.es", "mjblesa@cs.upc.es" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In computer science, a string (or sequence) x of length lx is defined as a finite sequence of characters from a finite alphabet Σ. A string is a data type used to represent and store information. Words in a specific language, for example, are stored in a computer in terms of strings. Even whole texts may be stored by means of strings. Apart from fields such as information and text processing, strings arise, in particular, in the field of computational biology. This is because most of the genetic instructions involved in the growth, development, functioning and reproduction of living organisms are stored in Deoxyribonucleic acid (DNA) and Ribonucleic acid (RNA) molecules, which are double-stranded (in the case of DNA) or single-stranded (in the case of RNA) sequences of nucleotides. Hereby, each nucleotide is composed of a nitrogenous base, a five-carbon sugar (ribose or deoxyribose), and at least one phosphate group. Nucleotides in the context of RNA have one of four different nitrogenous bases: guanine (G), uracil (U), adenine (A), and cytosine (C). Therefore, any RNA molecule can be represented as a string of symbols from Σ = {G,U,A,C}. Such a string is called the primary structure of an RNA molecule. However, RNA molecules generally fold in space, and different nucleotides bind together, for example, by means of hydrogene bonds. In simplified\nar X\niv :1\n70 2.\n00 31\n8v 1\n[ cs\n.A I]\nterms, G can only bind with C and U can only bind with A. En example of the secondary structure of an RNA molecule is shown in Figure 1a.\nIn computer science terms, the hydrogene bonds of the secondary structure of an RNA sequence x can be represented by a so-called arc annotation set Px, which is an unordered set of pairs of positions of x. Henceforth, the positions of a string x range from 1 to lx. Each pair (i1, i2) ∈ Px is called an arc annotation (or simply an arc) between positions i1 and i2. As a convention, it must hold that i1 < i2. Moreover, i1 is called the left endpoint of arc (i1, i2), and i2 is called the right endpoint. A pair (x, Px) is called an arc-annotated sequence [5]. Note that the secondary structure of an RNA sequence can be described by an arc-annotated sequence. For an example see Figure 1b. In fact, arc-annotated sequences have been widely used for this purpose (see, for example, [4]). In particular, arc-annotated sequences have been useful in the context of the structural comparison of RNA sequences. An important way of comparing two (or more) sequences consists in computing their longest common subsequence (LCS). Given a sequence x over a finite alphabet Σ, sequence t is called a subsequence of x, if t can be produced from x by deleting characters. Given a set of input strings {s1, . . . , sn}, the problem of finding the longest commons subsequence of all input strings is, in general, NP-hard [11]. The best techniques available nowadays for solving this problem are based on beam search [2]."
    }, {
      "heading" : "1.1 Contribution of this Work",
      "text" : "The longest common subsequence problem in the context of arc-annotated sequences—the longest arc-preserving common subsequence (LAPCS) problem—has first been introduced in [6, 5]. In particular, in the same works it was shown that the most general case of the problem (without any restrictions on the arcs) is NP-hard. In the meanwhile, five different variants of the problem—that is, restrictions of the general problem—have been studied in the related literature, and efficient algorithms were developed for three of these variants.1 However, as far as we know, only one algorithm that is applicable to the most general case has been proposed so far (see [9]). In this work, we first phrase the LAPCS problem in the form of an integer linear program (ILP) [12]. Then we make use of this ILP in the context of a simple evolutionary algorithm based on solution merging, where two or more solutions are merged and the best solution in this union is derived by means of an exact technique.\n1More details are given in Section 2.\nAggarwal et al. [1] originally suggested such an approach, labeled optimized crossover, for the independent set problem. We provide an extensive experimental comparison of the proposed algorithm in comparison to the heuristic from the literature and to the application of a randomized multi-start heuristic."
    }, {
      "heading" : "1.2 Outline of the Paper",
      "text" : "The remainder of this paper is structured as follows. In Section 2, a technical description of the tackled problem is provided. In subsequent sections—see Section 3 and Section 4—we describe a heuristic from the literature and phrase an ILP model for the tackled problem. Next, the proposed algorithm is outlined in Section 5. Finally, an extensive experimental evaluation on artificial and real problem instances is provided in Section 6, and an outlook to future work is given in Section 7."
    }, {
      "heading" : "2 The LAPCS Problem",
      "text" : "Given two input sequences x and y, we define the set of possible assignments A as the set of all ai,j—where i ∈ {1, . . . , lx} and j ∈ {1, . . . , ly}—such that x[i] = y[j]. That is A consists of all ai,j such that the letter at position i of x is equal to the letter at position j of y. A valid common subsequence of the two input sequences x and y can then be represented by a subset S ⊆ A that fullfills the following conditions:\n• Common subsequence condition: For any two assignments ai,j , ak,l ∈ S (where ai,j 6= ak,l) it must hold that either i < k and j < l or i > k and j > l.\nIn order to translate such a solution into the corresponding common subsequence, the assignments in S have to ordered from small to large indecees, either according to the first or the second index. Then, the letters corresponding to the assignments must be joined in this order.\nA solution S that fullfills the common subsequence condition is called arc-preserving if the arcs induced by the solution are preserved:\n• Arc preservation condition: for any two assignments ai,j , ak,l ∈ A (where ai,j 6= ak,l and i < k) it must hold that (i, k) ∈ Px ⇔ (j, l) ∈ Py.\nGiven two arc-annotated input strings x and y, the LAPCS problem consists in finding a solution S ⊆ A that fullfills both the common subsequence and the arc preservation condition and is of maximal cardinality. Note that such a mapping corresponds to the longest arcpreserving common subsequence of x and y. In [5, 6] it was shown that this problem is, in general, NP-hard. However, the structure of the arc annotation in the context of RNA sequences, for example, is in practise likely to satisfy some constraints. Concerning a string x, the following types of constraints have been considered in the literature:\n1. No two arcs may share an endpoint. That is, ∀(i1, i2), (i3, i4) ∈ Px it must hold that i1 6= i4 and i2 6= i3.\n2. Crossing arcs do not exist. That is, ∀(i1, i2), (i3, i4) ∈ Px it must hold that i3 ≤ i1 ≤ i4 ⇔ i3 ≤ i1 ≤ i4.\n3. Nesting arcs do not exist. That is, ∀(i1, i2), (i3, i4) ∈ Px it must hold that i1 ≤ i3 ⇔ i2 ≤ i3.\n4. No arcs exist. That is, Px = ∅.\nBased on these four restrictions concerning the arc annotation, input strings are characterized into unlimited (no constraints), crossing (constraint 1), nested (constraints 1 and 2), chain (constraints 1, 2, and 3), and plain (constraint 4). Different versions of the LAPCS problem can therefore be denoted as follows: LAPCS(·, ·) where each of the two dots must be replaced by the characterization of the arc annotation of the first and the second input string. For example, in problem LAPCS(unlimited,nested), the arc annotation of the first input string is characterized as unlimited, and the one of the second one as nested. It is well known that LAPCS(plain,plain), for example, can be solved in polynomial time with the dynamic programming algorithm by Smith and Waterman [13]. In this paper, however, we deal with the most general version of the problem, LAPCS(unlimited,unlimited), which—as mentioned above—was shown to be NP-hard. For simplicity reasons we refer to this problem version simply as LAPCS."
    }, {
      "heading" : "3 Existing Heuristic for LAPCS",
      "text" : "As far as we know, the only heuristic from the literature that is applicable to the most general version of the LAPCS problem was described in [9], and works as follows. First, the dynamic programming algorithm by Smith and Waterman is applied to input strings x and y, disregarding the arc annotations. The result is a mapping S ⊆ A that—most probably— violates some of the arc preservation constraints. In order to repair this invalid solution, the following is done. First a graph G is constructed as follows. A vertex v is introduced for each assignment ai,j ∈ S. Two vertices v (corresponding to an assignment ai,j ∈ S) and v′ (corresponding to an assignment ak,l ∈ S with i < k) are connected by an edge if either (i, k) ∈ Px or (j, l) ∈ Py, but not both. In other words, two vertices are connected by an edge if they represent a violation of the arc preservation constraints. Note that in order to repair S by removing as few assignments from S as possible, we can solve the maximum independent set (MIS) problem in G, and remove all assignments from S that correspond to vertices that are not in the optimal solution to the MIS problem. In our implmentation we used CPLEX 12.6 to solve the MIS problem in all cases."
    }, {
      "heading" : "4 An ILP Model for LAPCS",
      "text" : "The LAPCS problem can be stated in terms of an integer linear program (ILP) in the following way. For each ai,j ∈ A is introdcued a binary variable zi,j . The set of all binary variables is denoted by Z. We say that two variables zi,j 6= zk,l (where i ≤ k) are in conflict, if setting both variables to one violates (1) the common subsequence condition, (2) the are preservation condition, or both. In technical terms, two variables zi,j 6= zk,l (where i ≤ k) are in conflict, if at least one of the following holds:\n1. j ≥ l\n2. Either (i, k) ∈ Px or (j, l) ∈ Py, but not both at the same time.\nThe LAPCS problem can then be rephrased as the problem of selecting a maximal number of non-conflicting variables from Z. Given these notations, the ILP is stated as follows.\nmax ∑\nzi,j∈Z zi,j\nsubj. to:\nzi,j + zk,l ≤ 1 ∀ zi,j 6= zk,l, i ≤ k in conflict zi,j ∈ {0, 1} for zi,j ∈ Z\n(1)\n(2)\n(3)\nHereby, constraints (2) ensure that selected variables are not in conflict."
    }, {
      "heading" : "5 The Hybrid EA with Solution Merging",
      "text" : "The proposed hybrid EA, henceforth labelled Hyb-Ea, is pseudo-coded in Algorithm 1. In the context of this algorithm, valid solutions to the problem are subsets of the complete set Z of variables introduced in the context of the ILP model. If a solution S contains a variable zi,j , this means that the variable must be given value one in order to produce the corresponding solution. The main loop of the EA is executed while the CPU time limit is not reached. It consists of the following actions. First, the best-so-far solution Sbsf is initialized to ∅. Then, at each iteration, first, the set of variables representing a set of merged solutions is initialized with the best-so-far solution Sbsf. Then, a number of nsols solutions is probabilistically constructed in function GenerateRandomSolution(drate, lsize, Z) in line 6 of Algorithm 1. The variables contained in these solutions are added to S′. Afterwards, solution merging is applied to S′, that is, an ILP solver is applied to find the best valid solution that can be built from the variables in S′ (see function ApplySolutionMerging(tmax, S\n′) in line 9 of Algorithm 1). Parameter tmax is a time limit for the ILP solver. In particular, the output of this function is the best solution found by the ILP solver within tmax seconds. Note that for applying an ILP solver to S′ ⊆ Z, all the appearences of Z in the ILP model of Section 4 have to be replaced with S′. In case S′opt is better than the current best-so-far solution Sbsf , solution S′opt is stored as the new best-so-far solution (line 10). The output of the algorithm is the best-so-far solution Sbsf.\nIn the following we will describe in detail the remaining component of the algorithm: the probabilistic construction of solutions in function GenerateRandomSolution(drate, lsize, Z). First, a common subsequence of x and y is—without regarding the arc preservation constraints—probabilistically generated as follows. For this purpose let us first introduce for each letter a ∈ Σ the subset Za ⊆ Z of variables which correspond to letter a. A solution construction starts with an empty solution S = ∅, and the first step consists in generating the set of variables C ⊆ Z that serve as options to be added to S. More specifically, the initial set C is generated in order to contain for each letter a ∈ Σ the variable zi,j ∈ Za (if any) such that i ≤ k and j ≤ l, ∀zk,l ∈ Za. Moreover, options zi,j ∈ C are given a weight value w(zi,j) :=\ni lx + jly , which is a known greedy function for longest common subsequence\nproblems (see, for example, [7, 8]). At each construction step, exactly one variable is chosen from C and added to S. For doing so, first, a value r is chosen uniformly at random from [0, 1]. In case r ≤ drate, where drate is a parameter of the algorithm, the variable zi,j ∈ C\nAlgorithm 1 Hyb-Ea for the LAPCS problem\n1: input: strings x and y over alphabet Σ, values for parameters nsols, drate, lsize, and tmax 2: Sbsf := ∅ 3: while CPU time limit not reached do 4: for i = 1, . . . , nsols do 5: S′ := Sbsf 6: S := GenerateRandomSolution(drate, lsize, Z) 7: S′ := S′ ∪ S 8: end for 9: S′opt := ApplySolutionMerging(tmax, S\n′) 10: if |S′opt| > |Sbsf | then Sbsf := S′opt 11: end while 12: output: Sbsf\nwith the smallest weight value is deterministically chosen. Otherwise, a candidate list L ⊆ C of size min{lsize, |C|} containing the options with the lowest weight values is generated and exactly one variable zi,j ∈ L is then chosen uniformly at random and added to S. Note that lsize is another parameter of the solution construction process. Finally, the set of options C for the next construction step is generated. Being zi,j the last variable that was added to S, C contains for each letter a ∈ Σ the variable zr,s ∈ Za (if any) with the lowest weight value w(zr,s) calculated as w(zr,s) :=\nr−i lx−i + s−j ly−j . The solution construction is finished when the\nset of options is empty. However, note that a solution S constructed in the way as described above does not necesarrily respect all arc preservation constraints. Therefore, the same repair mechanism is utilized as in the heuristic from Section 3 in order to transform S into a valid LAPCS solution."
    }, {
      "heading" : "6 Experimental Evaluation",
      "text" : "Summarizing, the following techniques are included in the experimental evaluation: (1) the heuristic described in Section 3 (Heuristic), (2) the hybrid EA (Hyb-Ea), and (3) Hyb-Ea without the application of solution merging. This last algorithm—henceforth denoted by MsHeur—is bascially a multi-start heuristic that constructs randomized solutions (and applies the repair procedure to them) until it runs out of computation time. Comparing Hyb-Ea with Ms-Heur will enable us to measure the contribution of solution merging. The three above-mentioned algorithms were implemented in ANSI C++ using GCC 4.7.3, without the use of any external libraries. In addition, the ILP models in the context of Hyb-Ea were solved with the ILP solver IBM ILOG CPLEX v12.6 in one-threaded mode. The experimental evaluation has been performed on a cluster of PCs with Intel(R) Xeon(R) CPU 5670 CPUs of 12 nuclei of 2933 MHz and at least 40 Gigabytes of RAM. Note that we also tried to apply CPLEX to the complete ILP models for each problem instance. However, the models were too large, even in the case of the smallest problem instances.\nThe remainder of this section is organized as follows. First, the set of benchmark instances is described. Second, the tuning experiments that were conducted in order to determine a proper setting for the parameters of Hyb-Ea are outlined. Finally, an exhaustive experimental evaluation is presented."
    }, {
      "heading" : "6.1 Benchmark Instances",
      "text" : "Two sets of benchmark instances were generated. The first set, labelled Set1, consists of artificial problem instances. Each of these instances consists of two artifically generated RNA strings of length n ∈ {100, 200, . . . , 900, 1000}. The probability of each letter and each position was chosen to be 1/4. Moreover, for each input string we randomly generated a number of narcs ∈ {n/10, n/5, n/2}. Hereby, it was taken care that all narcs arcs were different. For each combination of n and narcs we randomly generated 30 problem instances. This makes a total of 900 problem instances.\nFor the second benchmark set, labelled Set2, we downloaded arc-annotated RNA sequences from the RNase P Database [3]. In total we assembled 10 problem instances, whose characteristics are described in Table 1. Moreover, the secondary structures of the RNA sequences involved in instances Real 1 and Real 8 are exemplary shown in Figure 3."
    }, {
      "heading" : "6.2 Algorithm Tuning",
      "text" : "The automatic configuration tool irace [10] was used for tuning the parameters of HybEa. The following parameters of Hyb-Ea were considered for tuning: (nsols) the number of solution constructions per iteration (drate) the determinism rate, (lsize) the candidate list size, and (tmax) the maximum time in seconds allowed for solution merging (at each call of the solution merging procedure). In particular, Hyb-Ea was tuned separately for each input string length, which—after initial experiments—seemed to have a greater influence on the behavior of the algorithm than the number of arcs. For each n ∈ {100, 200, . . . , 900, 1000} we randomly generated two tuning instances for each of the three values of narcs. This makes a total of six tuning instances for each n. The tuning process for each n was given a budget of 1000 runs of Hyb-Ea, where each run was given a computation time limit of n/10 CPU seconds. Finally, the following parameter value ranges were considered concerning the four parameters of Hyb-Ea:\n• nsols ∈ {5, 10, 20}\n• drate ∈ {0.0, 0.3, 0.5, 0.7, 0.9}, where a value of 0.0 means that the selection of the assignment to be added to the partial solution under construction is always done randomly from the candidate list, while a value of 0.9 means that solution constructions are nearly deterministic.\nThe tuning runs with irace produced the configurations of Hyb-Ea as shown in Table 2. The following trends can be observed. Apart from n = 100, the number of solution constructions is always set to five. This is because the smaller nsols, the smaller is the ILP model that has to be solved by CPLEX in the context of solution merging at each iteration of the algorithm. Moreover, the smaller the ILP model, the more efficient is CPLEX in solving such a model. The values of drate are consistently between 0.3 and 0.7, whereas the values of lsize are consistently set to two or three. Finally, the settings of tmax seem somewhat erratic. However, this is due to the fact that the application of CPLEX in solution merging is very efficient and stops, most of times, much below 5 CPU seconds. Therefore, it is only of importance that the value of tmax is at least set to 5.0."
    }, {
      "heading" : "6.3 Numercial Results",
      "text" : "The results concerning the artificial problem instances from Set1 are presented in Table 3. Each row provides the results of Heuristic, Ms-Heur and Hyb-Ea in terms of the average solution quality obtained for the 30 problem instances of the corresponding combination of n and narcs. All techniques were applied exactly once to each problem instance. The computation time limit used for Ms-Heur and Hyb-Ea was n/10 CPU seconds. The column with heading time shows the average computation time for the 30 problem instances in the case of Heuristic, and the average time at which the best solution of a run was found, in the case of Ms-Heur and Hyb-Ea. The best result of each table row is marked by a lightgrey background. The following observations can be made:\n• Heuristic is very fast. Its application to any of the problem instances requires less than one CPU second. Moreover, the results of Heuristic are always better than the results of Ms-Heur.\n• Hyb-Ea is, by far, the best algorithm in the comparison. It obtains the best result for each combination of n and narcs. In particular, Hyb-Ea always improves over MsHeur. This means that the solution merging component is an essential part of HybEa. This is remarkable as the application of CPLEX to the original problem instances\nIn order to study the magnitude of the improvement of Hyb-Ea over Ms-Heur, we show the percentage improvement of Hyb-Ea over Ms-Heur—by means of boxplots—for each combination of n and narcs in the three graphics of Figure 2. The x-axis of each graphic ranges from n = 100 to n = 1000. These grapics show, first, that the improvement of Hyb-Ea over Ms-Heur is generally around 15−20%. Moreover, it can be observed that the improvements become bigger with a growing number of arcs.\nIn a second set of experiments we applied the three algorithms considered in this work to the set of 10 real problem instances (Set2). The results are provided in Table 4, in\nthe following way. Heuristic was applied exactly once to each problem instance. The corresponding result can be found in columns with headings result and time. Both MsHeur and Hyb-Ea are applied 30 times to each problem instance, with a computation time limit of 30 seconds per application. In both cases we provide the best result obtained over 30 applications (column best), the average of the 30 results obtained (column avg.), and the average time at which the best solution of each run was found (column time). Again, the best result for each of the 10 instances is marked by a lightgrey background. Apart from one case (Real 4), the results are consistent with our observations in the context of the artificial benchmark instances. In the case of Real 4, Heuristic outperforms Hyb-Ea. This suggest that this problem instance has certain characteristics that are difficult to be discovered by the step-by-step way of constructing solutions as used in Hyb-Ea. Remember that Heuristic, in contrast, uses the dynamic programming algorithm by Smith and Waterman in order to generate the (possibly invalid) initial solution."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper we proposed a simple, hybrid evolutionary algorithm for solving the so-called longest arc-preserving common subsequence problem. The most important feature of this algorithm is a crossover component based on solution merging. At each iteration, the best solution found so far is merged with randomly generated solutions, and a general purpose integer linear programming solver is used to find the best solution within the resulting set of assignments. The results show that the algorithm is superior to the only existing heuristic from the literature. Moreover, we have shown that the solution merging component is an\nessential part of the algorithm. In future work we will try to replace the probabilistic way of constructing solutions by a probabilistic version of the Smith and Waterman algorithm. In this way it might be possible to avoid situations such as the one for real-life instance Real 4, where our algorithm was not able to outperform the existing heuristic."
    }, {
      "heading" : "Acknowledgment",
      "text" : "This work was funded by project TIN2012-37930-C02-02 (Spanish Ministry for Economy and Competitiveness, FEDER funds from the European Union) and project SGR 2014-1034 (AGAUR, Generalitat de Catalunya). Our experiments have been executed in the High Performance Computing environment managed by the rdlab at the Technical University of Barcelona (http://rdlab.cs.upc.edu) and we would like to thank them for their support."
    } ],
    "references" : [ {
      "title" : "Optimized crossover for the independent set problem",
      "author" : [ "C. Aggarwal", "J. Orlin", "R. Tai" ],
      "venue" : "Operations Research, 45:226–234",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Beam search for the longest common subsequence problem",
      "author" : [ "C. Blum", "M.J. Blesa", "M. López-Ibáñez" ],
      "venue" : "Computers & Operations Research, 36(12):3178–3186",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "The ribonuclease P database",
      "author" : [ "J.W. Brown" ],
      "venue" : "Nucleic Acids Research, 27(1):314–314",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "A comprehensive study of RNA secondary structure alignment algorithms",
      "author" : [ "Jimmy Ka Ho Chiu", "Yi-Ping Phoebe Chen" ],
      "venue" : "Briefings in Bioinformatics,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2016
    }, {
      "title" : "Finding common subsequences with arcs and pseudoknots",
      "author" : [ "Patricia A. Evans" ],
      "venue" : "Proceedings of CPM 1999 – 10th Annual Symposium on Combinatorial Pattern Matching,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1999
    }, {
      "title" : "Algorithms and Complexity for Annotated Sequence Analysis",
      "author" : [ "Patricia Anne Evans" ],
      "venue" : "PhD thesis, University of Victoria,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1999
    }, {
      "title" : "Subsequences and supersequences of strings",
      "author" : [ "C.B. Fraser" ],
      "venue" : "PhD thesis, University of Glasgow",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Fast algorithms for finding the common subsequences of multiple sequences",
      "author" : [ "K. Huang", "C. Yang", "K. Tseng" ],
      "venue" : "Proceedings of the 2004 International Computer Symposium, pages 1006–1011. IEEE press",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "The longest common subsequence problem for arc-annotated sequences",
      "author" : [ "Tao Jiang", "Guohui Lin", "Bin Ma", "Kaizhong Zhang" ],
      "venue" : "Journal of Discrete Algorithms,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2004
    }, {
      "title" : "The irace package: Iterated racing for automatic algorithm configuration",
      "author" : [ "M. López-Ibáñez", "J. Dubois-Lacoste", "L. Pérez Cáceres", "M. Birattari", "T. Stützle" ],
      "venue" : "Operations Research Perspectives, 3:43 – 58",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "The complexity of some problems on subsequences and supersequences",
      "author" : [ "D. Maier" ],
      "venue" : "Journal of the ACM, 25:322–336",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1978
    }, {
      "title" : "Integer and Combinatorial Optimization",
      "author" : [ "G.L. Nemhauser", "L.A. Wolsey" ],
      "venue" : "Wiley & Sons",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "Identification of common molecular subsequences",
      "author" : [ "T.F. Smith", "M.S. Waterman" ],
      "venue" : "Journal of Molecular Biology, 147",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1981
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "The example is reproduced from [9].",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 4,
      "context" : "A pair (x, Px) is called an arc-annotated sequence [5].",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 3,
      "context" : "In fact, arc-annotated sequences have been widely used for this purpose (see, for example, [4]).",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 10,
      "context" : ", sn}, the problem of finding the longest commons subsequence of all input strings is, in general, NP-hard [11].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 1,
      "context" : "The best techniques available nowadays for solving this problem are based on beam search [2].",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 5,
      "context" : "The longest common subsequence problem in the context of arc-annotated sequences—the longest arc-preserving common subsequence (LAPCS) problem—has first been introduced in [6, 5].",
      "startOffset" : 172,
      "endOffset" : 178
    }, {
      "referenceID" : 4,
      "context" : "The longest common subsequence problem in the context of arc-annotated sequences—the longest arc-preserving common subsequence (LAPCS) problem—has first been introduced in [6, 5].",
      "startOffset" : 172,
      "endOffset" : 178
    }, {
      "referenceID" : 8,
      "context" : "1 However, as far as we know, only one algorithm that is applicable to the most general case has been proposed so far (see [9]).",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 11,
      "context" : "In this work, we first phrase the LAPCS problem in the form of an integer linear program (ILP) [12].",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 0,
      "context" : "[1] originally suggested such an approach, labeled optimized crossover, for the independent set problem.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "In [5, 6] it was shown that this problem is, in general, NP-hard.",
      "startOffset" : 3,
      "endOffset" : 9
    }, {
      "referenceID" : 5,
      "context" : "In [5, 6] it was shown that this problem is, in general, NP-hard.",
      "startOffset" : 3,
      "endOffset" : 9
    }, {
      "referenceID" : 12,
      "context" : "It is well known that LAPCS(plain,plain), for example, can be solved in polynomial time with the dynamic programming algorithm by Smith and Waterman [13].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 8,
      "context" : "As far as we know, the only heuristic from the literature that is applicable to the most general version of the LAPCS problem was described in [9], and works as follows.",
      "startOffset" : 143,
      "endOffset" : 146
    }, {
      "referenceID" : 6,
      "context" : "Moreover, options zi,j ∈ C are given a weight value w(zi,j) := i lx + j ly , which is a known greedy function for longest common subsequence problems (see, for example, [7, 8]).",
      "startOffset" : 169,
      "endOffset" : 175
    }, {
      "referenceID" : 7,
      "context" : "Moreover, options zi,j ∈ C are given a weight value w(zi,j) := i lx + j ly , which is a known greedy function for longest common subsequence problems (see, for example, [7, 8]).",
      "startOffset" : 169,
      "endOffset" : 175
    }, {
      "referenceID" : 0,
      "context" : "For doing so, first, a value r is chosen uniformly at random from [0, 1].",
      "startOffset" : 66,
      "endOffset" : 72
    }, {
      "referenceID" : 2,
      "context" : "All 20 RNA sequences, together with their secondary structure, were downloaded from the RNase P Database [3].",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 2,
      "context" : "For the second benchmark set, labelled Set2, we downloaded arc-annotated RNA sequences from the RNase P Database [3].",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 9,
      "context" : "The automatic configuration tool irace [10] was used for tuning the parameters of HybEa.",
      "startOffset" : 39,
      "endOffset" : 43
    } ],
    "year" : 2017,
    "abstractText" : "The longest arc-preserving common subsequence problem is an NP-hard combinatorial optimization problem from the field of computational biology. This problem finds applications, in particular, in the comparison of arc-annotated Ribonucleic acid (RNA) sequences. In this work we propose a simple, hybrid evolutionary algorithm to tackle this problem. The most important feature of this algorithm concerns a crossover operator based on solution merging. In solution merging, two or more solutions to the problem are merged, and an exact technique is used to find the best solution within this union. It is experimentally shown that the proposed algorithm outperforms a heuristic from the literature.",
    "creator" : "LaTeX with hyperref package"
  }
}