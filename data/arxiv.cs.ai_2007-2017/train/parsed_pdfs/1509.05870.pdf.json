{
  "name" : "1509.05870.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Exploiting Reduction Rules and Data Structures: Local Search for Minimum Vertex Cover in Massive Graphs",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "Introduction",
      "text" : "The Minimum Vertex Cover (MinVC) problem is a wellknown NP-hard problem (Karp 1972) with many real-world applications (Johnson and Trick 1996). Given a simple undirected graph G = (V,E) where V is the vertex set and E is the edge set. An edge e is a set {u, v} s.t. u, v ∈ V , and we say that u and v are endpoints of e. A vertex cover of a graph G = (V,E) is a subset V ′ ⊆ V s.t. for each e ∈ E, at least one of e’s endpoints is in V ′. The size of a vertex cover is the number of vertices in it. The MinVC problem is to find a vertex cover of minimum size.\nWith growing interest in social networks, scientific computation networks and wireless sensor networks, etc., the MinVC problem has re-emerged even with greater significance and complexity, so solving this problem in massive graphs has become an active research agenda. In this paper we are concerned in finding a vertex cover whose size is as small as possible.\nIt is hard to approximate MinVC within any factor smaller than 1.3606 (Dinur and Safra 2004). During last decades there were many works in local search for MinVC like (Richter, Helmert, and Gretton 2007; Cai et al. 2013). Recently FastVC (Cai 2015) makes a breakthrough in massive graphs. It makes a balance between the time efficiency and the guidance effectiveness of heuristics. However, we realize that FastVC exploits very little about the structural informa-\nCopyright c© 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\ntion. Also in order to achieve satisfactory time efficiency, it sacrifices the guidance effectiveness.\nThe aim of this work is to develop a local search MinVC solver to deal with massive graphs with strong structures. The basic framework is this. Firstly, we exploit reduction rules to construct good starting vertex covers. Then we use local search to find better covers. In both the construction stage and the local search stage, we exploit a novel data structure called alternative partitions to pursue time efficiency, without sacrificing the quality of heuristics. Since we are now focusing on the impacts of the reduction rules and the data structures, we use naive local search strategies, so our solver may be too greedy. For future works, we will exploit some strategies to diversify our local search.\nOur solver constructs starting vertex covers by incorporating reduction rules. In our experiments, our construction heuristic performs close to or even better than FastVC, on a large portion of the graphs. Moreover, it outputs a cover typically within 10 seconds. Hence, it provides a good starting point for later search. Furthermore, for a small portion of the graphs, our heuristic guarantees that it has found an optimal cover, due to the power of reduction rules. So far as we know, this is the first time reduction rules are applied in a local search MinVC solver, although they have been widely discussed in the community of theoretical computer science.\nWe also propose a brand new data structure to achieve time efficiency. The main idea is to partition the vertices wrt. their scores, i.e., two vertices are in the same partition if they have the same score, otherwise they are in different partitions. Thanks to this data structure, (1) as to the construction stage, the complexity of two important construction heuristics has been lowered, from O(|V |2) to O(|V |+ |E|); (2) as to the local search stage, the complexity of the best-picking heuristic has also been lowered, from O(|C|) to O(davg) where C is the set of vertices to be selected in local search, and davg is the average degree. Later in this paper we will prove these results rigorously. We applied these theoretical results in our solver, so we call our solver LinCom (LinearComplexity-Heuristic Solver).\nWe tested LinCom and FastVC on the standard benchmark of massive graphs from the Network Data Repository1 (Rossi and Ahmed 2015). Our experiments show that among\n1http://www.graphrepository.com./networks.php\nar X\niv :1\n50 9.\n05 87\n0v 1\n[ cs\n.D S]\n1 9\nSe p\n20 15\nall the 12 classes of instances in this benchmark, LinCom falls behind FastVC in only one class. Moreover LinCom finds smaller covers for a considerable portion of the graphs. This improvement is big, since it rarely happens in the literature (Cai 2015)."
    }, {
      "heading" : "Preliminaries",
      "text" : ""
    }, {
      "heading" : "Basic Notations",
      "text" : "If e = {u, v} is an edge of G, we say that u and v are neighbors. We define N(v) as {u ∈ V |{u, v} ∈ E}. The degree of a vertex v, denoted by d(v), is defined as |N(v)|. We use davg(G) and dmax(G) to denote the average degree and the maximum degree of graph G respectively, suppressing G if understood from the context. An edge e = {u, v} is covered by a vertex set S if one of its endpoints is in S, i.e., u ∈ S or v ∈ S (or both). Otherwise it is uncovered by S."
    }, {
      "heading" : "Local Search for MinVC",
      "text" : "Most local search algorithms solve the MinVC problem by iteratively solving its decision version-given a positive integer k, searching for a k-sized vertex cover. A general framework is Algorithm 1. We denote the current candidate solution as C, which is a set of vertices selected for covering.\nAlgorithm 1: A Local Search Framework for MinVC 1 (C, optInfo)← InitV C(); 2 while not reach terminate condition do 3 if C covers all edges then 4 C∗ ← C; 5 remove a vertex from C; 6 exchange a pair of vertices; 7 return C∗\nAlgorithm 1 consists of two stages: the construction stage (Line 1) and the local search stage (Line 2 to 6). At the beginning, an initial vertex cover is constructed by the InitV C procedure. Throughout this paper, this initial cover is called the starting vertex cover. Besides InitV C returns another parameter, i.e., optInfo which takes the value optimalguaranteed or optimal-not-guaranteed (See Algorithm 2).\nIn the local search stage, each time a k-sized cover is found (Line 3), the algorithm removes a vertex from C (Line 5) and begins to search for a (k− 1)-sized cover, until some termination condition is reached (Line 2). The move to a neighboring candidate solution consists of exchanging a pair of vertices (Line 6): a vertex u ∈ C is removed from C, and a vertex v 6∈ C is added into C. Such an exchanging procedure is also called a step by convention. Thus the local search moves step by step in the search space to find a better vertex cover. When the algorithm terminates, it outputs the smallest vertex cover that has been found.\nFor a vertex v ∈ C, the loss of v, denoted as loss(v), is defined as the number of covered edges that will become uncovered by removing v from C. For a vertex v 6∈ C, the gain of v, denoted as gain(v), is defined as the number of uncovered edges that will become covered by adding v into C.\nBoth loss and gain are scoring properties of vertices. In any step, a vertex v has two possible states: inside C and outside C, and we use age(v) to denote the number of steps that have been performed since last time v’s state was changed."
    }, {
      "heading" : "The Construction Stage",
      "text" : "Previous InitV C procedures construct a starting vertex cover from an empty set C mainly as below:\n1. Max-gain: select a vertex v with the maximum gain and add v into C, breaking ties randomly. Repeat this procedure until C becomes a cover. (Papadimitrious and Steiglitz 1982)\n2. Min-gain: Select a vertex v with the minimum positive gain and add all v’s neighbors into C, breaking ties randomly. Repeat this procedure until C becomes a cover. Redundant vertices (vertices whose loss is 0) in C are then removed. (Ugurlu 2012; Kettani, Ramdani, and Tadili 2013)\n3. Edge-greedy: Select an uncovered edge e, add the endpoint with higher degree into C. Repeat this procedure until C becomes a cover. Redundant vertices in C are then removed by a read-one procedure. (Cai 2015)"
    }, {
      "heading" : "Reduction Rules for MinVC",
      "text" : "Our solver will incorporate the following reduction rules in the InitV C procedure to handle vertices of small degrees. Degree-1 Rule: If G contains a vertex u s.t. N(u) = {v}, then there is a minimum vertex cover of G that contains v.\nThe two rules below are from (Chen, Kanj, and Jia 2001). Degree-2 with Triangle Rule: If G contains a vertex v s.t. N(v) = {n1, n2} and {n1, n2} ∈ E, then there is a minimum vertex cover of G that contains both n1 and n2. Degree-2 with Quadrilateral Rule: If G contains two vertices u and v s.t. N(u) = N(v) = {n1, n2} and {n1, n2} 6∈ E, then there is a minimum vertex cover of G that contains both n1 and n2.\nSince we are to develop a local search solver, we now rewrite them in the terminologies of local search. Degree-1 Rule: If gain(v) = 1 and u is a neighbor of v s.t. u 6∈ C, then put u into the C. Degree-2 with Triangle Rule: If gain(v) = 2, and n1, n2 are both v’s neighbors s.t. n1, n2 6∈ C and {n1, n2} ∈ E, then put both n1 and n2 into the C. Degree-2 with Quadrilateral Rule: If gain(u) = gain(v) = 2, and both n1, n2 are neighbors shared by u, v s.t. n1, n2 6∈ C and {n1, n2} 6∈ E, then put both n1 and n2 into the C."
    }, {
      "heading" : "Incorporating Reduction Rules",
      "text" : "We incorporate reduction rules in order to: (1) construct smaller starting vertex covers; (2) help confirm optimality."
    }, {
      "heading" : "Constructing A Vertex Cover with Reductions",
      "text" : "Like (Cai 2015), our InitV C procedure also consists of an extending phase (Lines 3 to 8) and a shrinking phase (Line 9). Notice that if we construct a cover by only using reduction rules, then it must be optimal. So we employ a predicate\nAlgorithm 2: InitVC input : A graph G = (V,E) output: A cover C and whether-optimal-guaranteed\n1 C ← ∅; 2 max gain used← false; 3 while there exist uncovered edges do 4 Repeatedly apply the Degree-2 with Triangle Rule until it is not applicable; 5 Repeatedly apply the Degree-2 with Quadrilateral Rule until it is not applicable; 6 Repeatedly apply the Degree-1 Rule until it is not applicable; 7 if any rule above is applicable then continue if all\nedges are covered then break max gain used← true;\n8 pick a vertex v with the maximum gain (ties are broken randomly), put it into C;\n9 C ← eliminateRedundantVertices(C); 10 if max gain used = true then 11 return (C, optimal-not-guaranteed); 12 else 13 return (C, optimal-guaranteed);\nmax gain used s.t. max gain used = true if Line 8 has been executed, and max gain used = false otherwise.\nIn Line 1, we initialize C to be an empty set. Then we extend C to be a vertex cover of G, by iteratively adding a vertex into C. Lines 4 to 6 apply reduction rules to put vertices into C. Line 7 ensures that no reduction rules are applicable before making use of the max-gain heuristic. After the extending phase (Lines 3 to 8), Line 9 removes the redundant vertices from C just as what (Cai 2015) did.\nFixing Vertices in the Starting Vertex Cover When Algorithm 2 constructs a starting vertex cover, we realize that some of the vertices are put into C based on pure reductions. That is, they were put into C when max gain used = false. Hence, there exist a minimum vertex cover which contains all of such vertices, and we call them inferred vertices. In local search we can fix the inferred vertices in C s.t. they are never allowed to be removed from C. It seems that such a procedure are able to reduce the search space and speed up the search.\nSo we employ an array fixed, whose element is an indicator for a vertex. During the execution of Algorithm 2, we maintain the fixed array as below:\n1. Rule 1: Before the extending phase, for each vertex v, fixed[v] is set to false.\n2. Rule 2: When putting a vertex into C, we check whether max gain used = false. If so, fixed[v] is set to true.\nThus when Algorithm 2 is completed, fixed[v] = true if v is an inferred vertex, and fixed[v] = false otherwise. So later when we are doing local search, we can forbid u from being removed from C if fixed[u] = true, as is shown in Line 5 and 6 in Algorithm 3."
    }, {
      "heading" : "A Local Search MinVC Solver",
      "text" : "Algorithm 3: LinCom(G, cutoff ) input : A graph G = (V,E), the cutoff time output: A vertex cover of G\n1 (C, optInfo)← InitV C(); 2 if optInfo = optimal-guaranteed then return C while\nelapsed time < cutoff do 3 if C covers all edges then 4 C∗ ← C; 5 remove a vertex u s.t. fixed[u] = false with minimum loss from C, breaking ties randomly; 6 remove a vertex u ∈ C s.t. fixed[u] = false with the minimum loss, breaking ties randomly; 7 e← a random uncovered edge; 8 add the endpoint of e with the greater gain, breaking ties in favor of the older one;"
    }, {
      "heading" : "9 return C∗;",
      "text" : "Our solver LinCom is outlined in Algorithm 3. At first a vertex cover is constructed. If the returned cover is guaranteed to be optimal, the algorithm will immediately return.\nThen at each step, the algorithm first chooses a vertex u ∈ C s.t. u is not an inferred vertex (i.e., fixed[u] = false) with the minimum loss, breaking ties randomly. Then the algorithm picks a random uncovered edge e, chooses one of e’s endpoints with the greater gain and adds it, breaking ties in favor of the older one."
    }, {
      "heading" : "Data Structures",
      "text" : "In order to lower the complexities, we exploited an efficient data structure named alternative partitions (See Figure 1)."
    }, {
      "heading" : "Alternative Partitions",
      "text" : "We use loss-k (resp. gain-k) partition to denote the partition that contains vertices in C (resp. outside C) whose loss (resp. gain) is k (Figure 1). All the loss-k partitions are shown as dark regions, and all the gain-k partitions are shown as light ones. Since the dark and the light regions are distributed alternatively, we call them alternative partitions. Obviously we have\nProposition 1 1. 0 ≤ gain(v) ≤ d(v) ≤ |V | where v 6∈ C. 2. 0 ≤ loss(v) ≤ d(v) ≤ |V | where v ∈ C. Then we use Algorithm 4 to find those vertices in C with the minimum loss.\nAlgorithm 4: randomMinLossVertex input : A sequence of alternative partitions output: A random vertex v ∈ C with minimum loss\n1 k ← 0; 2 while the loss-k partition is empty do k ← k + 1\nreturn a random vertex in the loss-k partition;\nIn this algorithm we first check whether there are any vertices whose loss is 0. If so, we randomly return one of them. Otherwise, we go on to check whether there are any vertices whose loss is 1, 2, . . . until we find a non-empty partition. Then we randomly return one in that partition. So we have, Proposition 2 The complexity of Algorithm 4 is O(dmax).\nSimilarly we have Proposition 3 The complexity of finding the partition with the maximum/minimum gain is O(dmax)."
    }, {
      "heading" : "Implementations",
      "text" : "Given a graph G = (V,E) and a candidate solution C, we implement the alternative partitions on an array where each position holds a vertex (See Figure 1). Besides, we maintain two additional arrays of pointers, each of which points to the beginning of a specific partition. Imagine the array as a book of vertices and the pointer arrays as the indexes of the book.\nInitializing the Partitions At first when C is empty, there are no dark regions in our data structure, so initializing the partitions is equivalent to sorting the vertices into a monotonic nondecreasing order, based on their gain. Notice that at this time, the gain of any vertex is equal to its degree, so we now need to sort vertices by degrees. By Proposition 1, this satisfies the assumption of counting sort which runs in linear time (Cormen et al. 2009). Thus we have, Proposition 4 Initializating the partitions is O(|V |). Maintaining the Partitions After initializations, there are two cases in which a particular vertex, say v, has to be moved from one partition to another: (1) adding (resp. removing) v into (resp. from) C; (2) increasing/decreasing gain(v)/loss(v) by 1. Thus the core operation is to move a vertex v to an adjacent partition.\nNow we show how to do this with an example (See Figure 1 to 3). In this example, we are to add v68 into C. Initially v91 and v68 are in the gain-52 partition and thus their gain is 52 (Figure 1). Notice that after being added, v68’s loss will become 52, i.e., it should be in the loss-52 partition. Thus the operation is performed like this: (1) v68 is swapped with v91 (Figure 2); (2) Pgain-52 is moved (Figure 3).\nWe define placeVertexIntoC(v) as the procedure that moves v from certain gain-k partition to the respective loss-k partition, puts it into C and updates its score. And we define gainMinusMinus(v) as the procedure that moves v from certain gain-k partition to the respective gain-(k − 1) partition and updates its score. Analogously we define placeVertexOutfromC(v), lossMinusMinus(v), gainPlusPlus(v), and lossPlusPlus(v). Then we have\nProposition 5 All the procedures are of O(1) complexities."
    }, {
      "heading" : "Complexity Analysis",
      "text" : "In this section, we evaluate the complexities of the bestpicking and the vertex cover construction heuristics."
    }, {
      "heading" : "Complexity of The Best-picking Heuristic",
      "text" : "Along with adding/removing a vertex v, we have to move this vertex and all its neighbors to other partitions. Thus by Proposition 5, maintaining the partitions will take O(1) time plus an amount of time proportional to d(v). Thus,\nProposition 6 When a vertex is added/removed, the complexity of maintaining the partitions at each step is O(dmax).\nBy Proposition 2 and 6, we have\nProposition 7 The best-picking heuristic in Algorithm 3 can be done in O(dmax) complexity.\nIn the local search stage, by Proposition 1, we have\nTheorem 8 Suppose that each vertex has equal probability to be added or removed, then the average complexity of the best-picking heuristic in Algorithm 3 is O(davg).\nIt is nice because (Cai 2015) stated that the best-picking heuristic was of O(|C|) complexity. Since most real-world graphs are sparse (Barabasi and Albert 1999; Eubank et al. 2004; Chung et al. 2006), we have davg << |C|."
    }, {
      "heading" : "Complexity of The Max-gain/Min-gain Heuristics",
      "text" : "(Cai 2015) formally proved that the max-gain heuristic had a worst-case complexity of O(|V |2). Moreover, both (Ugurlu\nAlgorithm 5: minGainConstructVC input : A graph G = (V,E) output: A cover C and whether-optimal-guaranteed\n1 C ← ∅; |UE| ← |E|; initialize the partitions; 2 while |UE| > 0 do 3 k ← 1; 4 while the gain-k partition is empty do k ← k + 1 min g v ← a random vertex in the gain-k partition; 5 foreach v ∈ N(min g v) do 6 if v ∈ C then continue placeVertexIntoC(v); |UE| ← |UE| − gain(v); 7 foreach n ∈ N(v) do 8 if n ∈ C then lossMinusMinus(n) else\ngainMinusMinus(n)\n9 return (C, optimal-not-guaranteed);\n2012) and (Kettani, Ramdani, and Tadili 2013) proved rigorously that the worst-case complexity of the min-gain heuristic was O(|V |2). Yet with the alternative partitions, we have\nTheorem 9 The min-gain/max-gain heuristic constructs a vertex cover in O(|V | + |C| + |E|) complexity, where C is the starting vertex cover.\nProof: We use UE to denote the set of uncovered edges.\n1. We prove the case for min-gain by Algorithm 5. By Proposition 4, Line 1 has a complexity of O(|V |). In any cycle of the outer while-loop, if the condition in Line 4 is tested for t times, then gain(min g v) = t, and thus t neighbors of min g v will be put into C. That is, in any cycle, the number of tests done in Line 4 is equal to the number of vertices that will be put. So that condition will be tested for exactly |C| times during the algorithm. Given min gain v in Line 4, the algorithm tests each of its neighbors whether they are in C in Line 6. Considering the case that we have to test every neighbor of every vertex, the total number of tests done is 2|E|. Thus the condition in Line 6 will be tested for at most 2|E| times. After putting a vertex into C in Line 6, we have to update the information about its neighbors (Line 8-8). Again considering the extreme case above, the total number of updates (gainMinusMinus or lossMinusMinus) will be at most 2|E|. By Proposition 5, the time spent in Line 8-8 during the algorithm is O(|E|). To conclude, the overall complexity is O(|V |+ |C|+ |E|).\n2. We prove the case for max-gain by Algorithm 6. In Line 2, we initialize k to be dmax which is equal to the maximum gain at this time. Notice that the value of the maximum gain never increases in the construction stage. So during the execution, whenever we find that there are no vertices whose gain is g, we go on to check whether there are any vertices whose gain is g − 1. Thus, during the execution, k is always the value of the maximum gain.\nWhen the condition in Line 4 is tested, there are two cases: (1) if succeeds, then k is decreased by 1; (2) if fails, then one vertex is put into C. So the number of tests done in Line 4 is exactly |C| + dmax ≤ |C| + |V |. Similarly, the overall complexity is O(|V |+ |C|+ |E|).\nAlgorithm 6: maxGainConstructVC input : A graph G = (V,E) output: A cover C, whether-optimal-guaranteed\n1 C ← ∅; |UE| ← |E|; initialize the partitions; 2 k ← dmax; 3 while |UE| > 0 do 4 while the gain-k partition is empty do k ← k − 1 v ←a random vertex in the gain-k partition; 5 placeVertexIntoC(v); |UE| ← |UE| − gain(v); 6 foreach n ∈ N(v) do 7 if n ∈ C then lossMinusMinus(n) else\ngainMinusMinus(n)\n8 return (C, optimal-not-guaranteed);\nBesides, we compared Algorithm 6 with the traditional one (Cai et al. 2013) through experiments. Moreover, as to the min-gain heuristic, we program it ourselves in two ways: Algorithm 5 and the previous way. It shows that our methods are faster than the traditional ones by orders of magnitude on large instances. So our experimental results were completely consistent with the theoretical expectations. So far we have not derived the complexity of Algorithm 2 yet, but we believe that it is also linear, because our InitV C procedure outputs a vertex cover typically within 10 seconds.\nBecause the max-gain heuristic was proposed about three decades ago (Papadimitrious and Steiglitz 1982), and (Cai 2015) still proved the O(|V |2) complexity, our result is surprising. Note that partitioning is a general method and can also be applied to solve huge instances for other problems."
    }, {
      "heading" : "Experimental Evaluation",
      "text" : "In this section, we carry out extensive experiments to evaluate LinCom on massive graphs, compared against the stateof-the-art local search MinVC algorithm FastVC. To show the individual impacts, we also present the performances of our InitV C procedure (named as InitVC in the tables)."
    }, {
      "heading" : "Benchmarks",
      "text" : "We downloaded all 139 instances2. They were originally online,3 and then transformed to DIMACS graph format. But we excluded three extremely large ones, since they are out of memory for all the algorithms here. Thus we tested all the solvers on the remaining 136 instances. Some of them have recently been used in testing parallel algorithms for Maximum Clique and Coloring problems (Rossi and Ahmed 2014; Rossi et al. 2014).\n2http://lcs.ios.ac.cn/c̃aisw/Resource/realworld%20graphs.tar.gz 3http://www.graphrepository.com./networks.php"
    }, {
      "heading" : "Experiment Setup",
      "text" : "All the solvers were compiled by g++ 4.6.3 with the ’-O3’ option. For FastVC4, we adopt the parameter setting reported in (Cai 2015). The experiments were conducted on a cluster equipped with a number of Intel(R) Xeon(R) CPUs X5650 @2.67GHz with 8GB RAM, running Red Hat Santiago OS.\nAll the algorithms are executed on each instance with a time limit of 1000 seconds, with seeds from 1 to 100. For each algorithm on each instance, we report the minimum size (”Cmin”) and averaged size (”Cavg”) of vertex covers found by the algorithm. To make the comparisons clearer, we also report the difference (”∆”) between the minimum size of vertex cover found by FastVC and that found by LinCom. A positive ∆ means that LinCom finds a smaller vertex cover, while a negative ∆ means that FastVC finds a smaller vertex cover. The numbers of vertices of these graphs lie between 1 × 103 to 4 × 106. We omit them and readers may refer to (Cai 2015) or the download website."
    }, {
      "heading" : "Experimental Results",
      "text" : "We show the main experimental results in Tables 1 and 2. For the sake of space, we do not report the results on graphs with less than 1000 vertices. Furthermore, we do not report the results on graphs where LinCom and FastVC precisely return both the same minimum size and average size.\nFrom the results in Tables 1 and 2, we observe that: 1) LinCom attains the best known solutions for most instances, and makes a significant progress. In Fact, among all the 136 tested instances LinCom has found covers with 26\n4http://lcs.ios.ac.cn/ caisw/Code/FastVC.zip\nless vertices on average. This improvement is big, since it rarely happens to find a better solution (Cai 2015).\n2) LinCom is more robust. Actually out of 12 classes, LinCom outperforms FastVC over 7 classes, while FastVC outperforms LinCom over 1 class (e.g., facebook networks). It seems that our local search is too greedy and not as effective as FastVC for facebook networks.\n3) There are quite a few instances (e.g., soc-delicious) where InitVC outperforms FastVC. This illustrates that our InitV C procedure generates desired starting vertex covers.\nFurthermore, the solutions to the following 9 instances are guaranteed to be optimal: ca-CSphd, ca-Erdos992, ia-emailEU, ia-reality, ia-wiki-Talk, soc-douban, soc-LiveMocha, soc-twitter-follows, tech-internet-as. So our InitV C procedure is sometimes complete in practice."
    }, {
      "heading" : "Conclusions and Future Work",
      "text" : "In this paper, we have developed a local search algorithm for MinVC called LinCom, based on reduction rules and data structures. The reduction rules help generate a better quality starting vertex cover, while the data structures lower the complexities of the heuristics.\nThe main contributions are two folds: (1) we have lowered the complexity of two vertex cover construction heuristics and the best-picking heuristic based on the score-based alternative partitions at the theoretical level; (2) we apply these results and some reduction rules to develop a local search solver which outperforms the state-of-the-art.\nAs for future works we will utilize various diversification strategies to in our solver. Also, we will apply reduction rules to select vertices for exchanging in local search."
    } ],
    "references" : [ {
      "title" : "Emergence of scaling in random networks. Science 286(5439):509–512",
      "author" : [ "Barabasi", "Albert 1999] Barabasi", "A.-L", "R. Albert" ],
      "venue" : null,
      "citeRegEx" : "Barabasi et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Barabasi et al\\.",
      "year" : 1999
    }, {
      "title" : "Numvc: An efficient local search algorithm for minimum vertex cover",
      "author" : [ "Cai" ],
      "venue" : "J. Artif. Intell. Res",
      "citeRegEx" : "Cai,? \\Q2013\\E",
      "shortCiteRegEx" : "Cai",
      "year" : 2013
    }, {
      "title" : "Vertex cover: Further observations and further improvements",
      "author" : [ "Kanj Chen", "J. Jia 2001] Chen", "I.A. Kanj", "W. Jia" ],
      "venue" : "J. Algorithms",
      "citeRegEx" : "Chen et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2001
    }, {
      "title" : "Introduction to Algorithms (3",
      "author" : [ "Cormen" ],
      "venue" : null,
      "citeRegEx" : "Cormen,? \\Q2009\\E",
      "shortCiteRegEx" : "Cormen",
      "year" : 2009
    }, {
      "title" : "On the hardness of approximating label-cover",
      "author" : [ "Dinur", "I. Safra 2004] Dinur", "S. Safra" ],
      "venue" : null,
      "citeRegEx" : "Dinur et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Dinur et al\\.",
      "year" : 2004
    }, {
      "title" : "Structural and algorithmic aspects of massive social networks",
      "author" : [ "Eubank" ],
      "venue" : "In Proceedings of the Fifteenth Annual ACM-SIAM Symposium on Discrete Algorithms,",
      "citeRegEx" : "Eubank,? \\Q2004\\E",
      "shortCiteRegEx" : "Eubank",
      "year" : 2004
    }, {
      "title" : "Cliques, Coloring, and Satisfiability: Second DIMACS Implementation Challenge",
      "author" : [ "Johnson", "D.J. Trick 1996] Johnson", "M.A. Trick", "eds" ],
      "venue" : "Workshop, October",
      "citeRegEx" : "Johnson et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 1996
    }, {
      "title" : "Reducibility among combinatorial problems",
      "author" : [ "R.M. Karp" ],
      "venue" : "In Proceedings of a symposium on the Complexity of Computer Computations, held March 20-22,",
      "citeRegEx" : "Karp,? \\Q1972\\E",
      "shortCiteRegEx" : "Karp",
      "year" : 1972
    }, {
      "title" : "Article: A heuristic approach for the vertex cover problem",
      "author" : [ "Ramdani Kettani", "O. Tadili 2013] Kettani", "F. Ramdani", "B. Tadili" ],
      "venue" : "International Journal of Computer Applications 82(4):9–11",
      "citeRegEx" : "Kettani et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Kettani et al\\.",
      "year" : 2013
    }, {
      "title" : "Combinatorial Optimaization: Algorithms and Complexity",
      "author" : [ "Papadimitrious", "K. Steiglitz" ],
      "venue" : null,
      "citeRegEx" : "Papadimitrious et al\\.,? \\Q1982\\E",
      "shortCiteRegEx" : "Papadimitrious et al\\.",
      "year" : 1982
    }, {
      "title" : "A stochastic local search approach to vertex cover",
      "author" : [ "Helmert Richter", "S. Gretton 2007] Richter", "M. Helmert", "C. Gretton" ],
      "venue" : "In KI 2007: Advances in Artificial Intelligence, 30th Annual German Conference on AI,",
      "citeRegEx" : "Richter et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Richter et al\\.",
      "year" : 2007
    }, {
      "title" : "The network data repository with interactive graph analytics and visualization",
      "author" : [ "Rossi", "R.A. Ahmed 2015] Rossi", "N.K. Ahmed" ],
      "venue" : "In Proceedings of the TwentyNinth AAAI Conference on Artificial Intelligence",
      "citeRegEx" : "Rossi et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Rossi et al\\.",
      "year" : 2015
    }, {
      "title" : "Fast maximum clique algorithms for large graphs",
      "author" : [ "Rossi" ],
      "venue" : "In 23rd International World Wide Web Conference,",
      "citeRegEx" : "Rossi,? \\Q2014\\E",
      "shortCiteRegEx" : "Rossi",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "The Minimum Vertex Cover (MinVC) problem is a wellknown NP-hard problem (Karp 1972) with many real-world applications (Johnson and Trick 1996).",
      "startOffset" : 72,
      "endOffset" : 83
    } ],
    "year" : 2015,
    "abstractText" : "The Minimum Vertex Cover (MinVC) problem is a well-known NP-hard problem. Recently there has been great interest in solving this problem on real-world massive graphs. For such graphs, local search is a promising approach to finding optimal or near-optimal solutions. In this paper we propose a local search algorithm that exploits reduction rules and data structures to solve the MinVC problem in such graphs. Experimental results on a wide range of real-word massive graphs show that our algorithm finds better covers than state-of-theart local search algorithms for MinVC. Also we present interesting results about the complexities of some wellknown heuristics.",
    "creator" : "LaTeX with hyperref package"
  }
}