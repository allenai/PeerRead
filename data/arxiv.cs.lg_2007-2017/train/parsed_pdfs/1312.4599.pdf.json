{
  "name" : "1312.4599.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Evolution and Computational Learning Theory: A survey on Valiant’s paper",
    "authors" : [ "Arka Bhattacharya" ],
    "emails" : [ "(ab3899@columbia.edu)" ],
    "sections" : [ {
      "heading" : "1 Introduction and Basic Definitions",
      "text" : "Darwin said, evolution consists of many complex mechanisms, which can come into existence without any unlikely events to occur. Evolution consists of a path consisting of many interdependent small stages, but what are the conditions which make these paths to be taken and others, not? It may take exponential time, if evolution just randomly searched all the possible paths, but since we know that the time to evolve is a large finite polynomially bounded value it means there may exist an efficient learning mechanism, which can learn certain function classes and cannot learn others. So, basically mechanisms are treated as mathematical functions in this analysis, such that some functions can be learned in polynomial time, but others cannot due to their inherent computational intractability. We describe some notions, which may help us to formally analyze the quantitative theory of evolvability. We all know, that a cell consists of various types of proteins and maybe, other chemicals and complex circuits and thus, its working depends on many variables. So, in order to define some formalized theory ar X\niv :1\n31 2.\n45 99\nv1 [\ncs .L\nG ]\n1 7\nD ec\n2 01\nof evolution, mechanisms need to be represented as many argument functions. Hence, a mechanism can take a lot of input parameters to properly function. So, what are many argument functions and how do we represent a mechanism through many argument functions? Well, a many argument function is a function f , which takes more than one input parameters to produce an output. The complex structures of living cells, have to respond to wide variations in both external and internal conditions. Say the conditions are represented by n boolean variables, x1, x2, ..., xn and let us have a function, say f whose output shows some particular desirable response under a particular combination of the x ′\nis, for all i ∈ [n]. We say, the function f(x1, x2, ..., xn) is an ideal function and since, it depends on many input parameters, so it is a many argument function.Later in the text, it is explicitly shown that the class of parity functions is not evolvable, while the class of monotone conjunctions over the uniform distribution is. Let Xn be the set of all 2 n possible values that all the x ′\nis can take. Let Dn be the probability distribution over Xn, which basically gives the relative frequency of the occurrence of certain combinations of the x ′\nis.Now, let us have the notion of performance.\nDefinition 1.1. Let us have a function r : Xn → {−1, 1}. The performance of function r with respect to the ideal function f : Xn → {−1, 1} for the probability distribution Dn over Xn is\nPf (r,Dn) = ∑ x∈Xn f(x)r(x)Dn(x) (1)\nSay for some points x ∈ Xn which have non-zero probability in Dn, we have∑ x∈Xn:Dn(x)6=0Dn(x) = 1. Now, if the ideal function f completely agrees with r on these set of points, then we have f(x).r(x) = 1 for all of them and thus,Pf (r,Dn) = ∑ Dn(x) = 1. Again, if f does not agree with r for all these\nx, then we have f(x).r(x) = −1 and so Pf (r,Dn) = − ∑ Dn(x) = −1.So, the range of Pf (r,Dn) is [−1, 1] and can be viewed as a fitness landscape over all the genomes r.All the points in Xn can be thought of as life experiences. When r agrees with the ideal function, we have a benefit, otherwise we have a penalty in case of disagreement.So, over a sequence of life experiences, the organisms or groups which have high values of the performance function are selected preferentially for survival over organisms which have low values of the performance function. It is thus, a basic mathematical definition of the Darwinian concept of Survival of the Fittest. An organism or a group can test the performance of its genome r against the ideal function, by sampling a set S ⊂ Xn, of poly(n) size, say s(n) life experiences. Let us have a definition concerning empirical performance, which concerns the size of the independent selections, s.\nDefinition 1.2. The empirical performance, Pf (r,Dn, s), for some positive integer s is a random variable which makes s independent selections from the set S with replacements according to the distribution Dn and has the value 1 s . ∑ x∈S f(x)r(x).\nWe take s(n) to be the upper bound of population size, as the life experiences xi may correspond to one or more organisms.Moreover, let us also insist that evolution is able to proceed from any starting point, otherwise proceeding back to the reinitialized state from the current state may heavily decrease the value of the performance function.Let us discuss in short, the final two notions before proceeding to the definition of the concept of evolvability.Since, the organisms that can exist at any time is finite and is polynomially bounded, so for a function only a limited number of variants can be explored per generation, whether through mutations or recombination.And finally, we say that mechanisms with significant improvements in the value of performance function, evolve in a limited number of generations.\nLet us now have an idea of evolvability and some of its definitions, in terms of learning theory."
    }, {
      "heading" : "2 Evolvability and its definitions",
      "text" : "From the perspective of learning theory, we can ask whether there exists a hypothesis r for a target concept f , such that r closely approximates f , the ideal function.Let the concept class C consists of all the ideal functions. Since, evolution has a path and follows a finite number of steps, before it tries to be as close to f as possible, so let us say that the hypothesis for the initial stage be r1, the hypothesis for the second stage be r2 and continuing like this, the hypothesis for the ith stage is ri. The path of evolutionary sequence can be represented by r1 ⇒ r2 ⇒ ..., where we have Pf (ri, Dn) > Pf (ri−1, Dn) and each hypothesis tries to approximate the ideal function better than its predecessor. If after a certain number of steps, say k, such that the kth hypothesis is rk and we have Pf (rk, Dn)− Pf (r1, Dn) ≥ d, for some positive threshold d, then the process of evolution starts from any function. Hence, in short we have to get a good evolved representation r, from the representation class, say Rn, such that Pf (r,Dn) is very close to 1.We assume that any representation from Rn is polynomially evaluatable, i.e r(x) can be computed in polynomial time, where x ∈ Xn.Let the error parameter of the evolved representation be .\nDefinition 2.1. A p-neighborhood N on R, for polynomial p and representation class R is a pair of two randomized Turing machines M1 and M2, such that M1 outputs all the p(n, 1/ )neighbors of a representation r ∈ Rn so that they all have error parameters of , using n and 1/ as its input and M2 takes all the outputs of M1 as its input and returns some representation with probability at least equal to 1/p(n, 1/ ).\nLet the representations, which are generated byM1 be put in the setNeighN (r, ), so that we have |NeighN (r, )| = p(n, 1/ ). M1 may also do random coin tosses to output members from the set NeighN (r, ). After this, M2 takes all the mem-\nbers of NeighN (r, ) as its input and returns some rc ∈ NeighN (r, ) with probability, PrN (r, rc) ≥ 1/p(n, 1/ ).Since, the size of NeighN (r, ) is polynomially bounded, it means that the number of variants which can be searched is not unlimited, which is logical as the population at any time is finite. M2 makes sure that differences in performance can be detected reliably. Most of the exponentially many variants are considered to be impractical and hence, are discarded, while only poly(n) variants are assumed to be feasible for evolution.It can be seen from the analysis, that all the resources, computation time, population and generation sizes are upper bounded by some polynomial, which depends on the number of variables and the inverse of the error parameter and this makes PAC learning possible,which we will analyze later.\nTo give a basic intuitive understanding of Definition 2.1, consider the diagram below. The blue region corresponds to the representation class, R, the yellow\nregion consists of all the neighboring representations of r having error parameter of , generated by the randomized Turing Machine, M1 and the red region consists of r, which is taken as input by M1. The yellow region has a size of p(n, 1/ ) and M2 randomly selects some representation rc from this region with probability at least equal to the inverse of the size of this region. Now, let us define the Mutator function, which helps in genetic mutation.\nDefinition 2.2. The mutator function, M(f, p,R,N,D, s, r, t)(where all of the input parameters represent same concepts as before and there exists a p(n, 1/ ) neighborhood N on R) for the current representation, r ∈ Rn is a random variable, which outputs some variant rc ∈ NeighN (r, ) with a certain probability, such that the performance value of rc with respect to the ideal function, f never\ngoes below the performance value of r with respect to f by some threshold t > 0. For some r1, r2 ∈ Rn, if we have r1 ⇒ r2 in the evolutionary path, we say that r2 = M(f, p,R,N,D, s, r1, t).\nThe above definition captures the notion of feasibility of an evolutionary path, somewhat in a lower level. Say, for some representation, r the mutator function M computes some variant rc of it and computes the value of the performance, Pf (rc, Dn) = P (rc).(We will represent the performance of a representation r with respect to the ideal function over a distribution D, by P (r) from now onwards). It is easy to see that if P (rc)−P (r) ≥ t, then it is beneficial for evolution and we create a set POS, which contains all the positive variants of r, capable of mutation. Similarly, let us create a set NEUT , to keep all the variants, which have performance values, at least equal to P (r) − t, but not exceeding P (r). Hence, NEUT = {rc|P (rc) ≥ P (r)− t} − POS.Now, if the cardinality of the set POS is at least equal to 1, we output a representation, rc ∈ POS with probability equal to PrN (r, rc)/ ∑ rc∈POS PrN (r, rc), otherwise we output a rep-\nresentation rc ∈ NEUT , with probability PrN (r, rc)/ ∑ rc∈NEUT PrN (r, rc).We refer to t as the tolerance variable of a representation.Let ti denote the tolerance variable of each representation, ri, such that it is generated by a Turing machine on inputs ri−1, n and the error parameter . It is logical to assume that each ti diminishes with , as we want an accuracy of 1 − , whereas population size or the no. of generations is inversely proportional to . So, we can bound each ti by two polynomially related polynomials pl and pu, such that we have pl(1/n, ) ≤ ti ≤ pu(1/n, ).We also have the number of experiences represented by the polynomial s(n, 1/ ).So, basically, if we need higher accuracy, then needs to be small and tolerance levels,ti should be less, so each variant must be closer to the parent genome with respect to performance.However, we need more life experiences, s for analyzing the conditions of evolvability, which is logical.(at least s is polynomially bounded). So, we have the following equation, representing evolvability of variants.\nri = M(f, p(n, 1/ ), Rn, N,Dn, s(n, 1/ ), ri−1, ti) (2)\nDefinition 2.3. A class C is tolerance evolvable iff there exists a polynomial g(n, 1/ )(generation size for evolution)and a Turing machine T , which computes ti for every ri ∈ Rn, where pl(1/n, ) ≤ ti ≤ pu(1/n, ), such that for every positive integer n, every f ∈ Cn, every 0 ≤ < 1 and every initial representation, r1 ∈ Rn, the evolution sequence r1, r2, r3, ..., where ri = M(f, p(n, 1/ ), Rn, N,Dn, s(n, 1/ ), ri−1, ti) must have a representation, rg(n,1/ ), such that its performance value with respect to f is at least 1− .\nDefinition 2.4. A class C is poly evolvable over D iff there exists polynomially related variables, pl and pu, such that C is tolerance evolvable by p(n, 1/ ), s(n, 1/ ), R and N over D.\nDefinition 2.5. A class C is R-evolvable iff C is poly evolvable over D for some\npolynomials s(n, 1/ ), p(n, 1/ ) and some p(n, 1/ ) neighborhood N on R.\nDefinition 2.6. A class C is D-evolvable, if for some representation class, R it is R-evolvable over D.\nDefinition 2.7. A class C is perfectly-evolvable if it is D-evolvable over all D.\nThus, to give a low level intuitive overview of the definitions, consider the diagram below.(Note that the diagram looks like a decision list, but it is not a decision list by any means. The diagram is just for basic intuitive understanding of the definitions above) From the definitions it is clear that one notion follows from the previous, only if the previous is true. Thus, a concept class which is perfectly-evolvable is the broadest of all the notions and is independent of any distribution."
    }, {
      "heading" : "3 Propositions and proofs",
      "text" : "Proposition 3.1. If there exists a concept class, C which is R-evolvable over a distribution D, then C is efficiently PAC-learnable by R over D.\nProof. Recall the basic definition of Probably Approximately Correct (PAC) learning model from [2] and [4].\nDefinition. If C is a concept class over some domain X, then C is PAC learnable if there exists an algorithm A, such that for every target concept c ∈ C, for every distribution D on X and for all 0 < , δ < 1/2, it outputs a hypothesis h from the hypothesis class H with probability at least 1 − δ so that the error of h is upper bounded by , provided the algorithm is given access to an example oracle EX(c,D) and supplied with the parameters and δ.\nThe above proposition says that the concept class C is R-evolvable over D, so this means that C is poly-evolvable over D for polynomials s(n, 1/ ), p(n, 1/ ) and some p(n, 1/ ) neighborhood N on R and since, it is poly-evolvable, this means there exists two polynomially bounded polynomials pl and pu, such that C is tolerance evolvable by s, p,R and N over D. This means there exists some evolutionary sequence r1 ⇒ r2 ⇒ r3 ⇒ ..., which satisfies equation (2), such\nthat after k evolutionary steps, where k = O(g(n, 1/ )), the final hypothesis rk satisfies P (rk) > 1 − , provided the tolerance values for each representation, ti are generated by some Turing machine T , on inputs ri−1, n and . The evolution algorithm runs in many stages and is fed with labelled examples from the distribution, D. Say, for some stage i, let us have a set Si of labelled examples, such that its cardinality, ki is bounded by the polynomial s(n, 1/ ). In this case, our target concept is the ideal function, f . We have Si = {〈x1, f(x1)〉, 〈x2, f(x2)〉, ..., 〈xki , f(xki)〉}, where ki = O(s(n, 1/ )) and the algorithm returns a hypothesis, ri in each stage, i under polynomial time as per our assumptions.Now, the empirical performance of all the possible hypotheses for the current stage is computed in polynomial time and the best one is made the new genome, so that it has the capacity to evolve. Thus, the new hypothesis is generated in polynomial amount of time, using polynomially bounded resources and polynomially bounded input parameters.But, the computation of the performance value for the current hypothesis, is nothing but measuring the probability that the hypothesis matches the target concept on some example point from the distribution D. So, for a stage i, input domain Xn and distribution Dn, we have P (ri) = ∑ x∈Xn f(x)ri(x)Dn(x) = Prx∼D[ri(x) = f(x)]. Moreover, since the final hypothesis, rk has a performance of at least 1 − , where k = O(g(n, 1/ )), this means we have Prx∼D[rk(x) = f(x)] ≥ 1− , which tells us that the error of the final evolved genome is at most , i.e error(rk) ≤ . All of these statements completely agree with the basic definition of the PAC learning model, provided above and thus, it can be said that C is efficiently PAC learnable by the hypothesis class, R over the distribution D.\nProposition 3.2. If there exists a concept class C, such that it is R-evolvable over distribution D, then it is also efficiently learnable using the statistical query model using R over D.\nProof. In the statistical query learning model, the PAC oracle, EX(c,D), which gives random examples of the target concept,f with respect to an input distribution D over the domain, X is replaced by a weaker oracle, say SQ(c,D). The new oracle, SQ(c,D) does not provide the learning algorithm, with individual random examples, but provides accurate probability estimates within arbitrary inverse polynomial additive error, over the sample space generated by the PAC oracle EX(c,D).Say, we have a query q = (q1, α), where q1 = q1(x, l) is any Boolean function over inputs x ∈ X, such that x is drawn from D and l ∈ {0, 1}, the oracle SQ(c,D) will return a probability estimate that q1(x, c(x)) = 1, which is accurate within additive error α ∈ [0, 1].Hence, it can be said that the statistical query learning model is a weaker form of learning than Valiant’s PAC model. The diagram below shows a block representation of statistical query learning, such that it acts as a messenger between the PAC oracle and the learning algorithm, which have no direct contacts between them.\nLet rc be a variant of the current representation r ∈ R, such that rc ∈ NeighN (r, )\nand we want to measure the chances of rc being the next hypothesis of r, which is denoted by Pr[r, rc]. So, we need pairs (r, rc) from the set POS. In other words, we need to find the probability that for certain pairs (r, rc), the empirical performance for the samples, whose size is upper bounded by s, follows P (rc) ≥ P (r) + t. Let there be four events,whose corresponding queries are denoted by qi and additive errors by αi, for all i ∈ [4]. If the ideal function is f , the four events are (r = f, rc = f), (r = f, rc 6= f), (r 6= f, rc = f) and (r 6= f, rc 6= f) respectively for i = 1, 2, 3, 4. Each query, qi is a request for the probability of event i on the distribution generated by the PAC oracle, EX(f,D). Hence, a query (qi, αi) is interpreted as a request for the value P qix = Pi(say) = Prx∈D[qi(x, f(x)) = 1] = PrEX(f,D)[qi = 1] and since, αi is the additive error of the probability estimates, so the statistical query oracle, SQ(f,D) actually returns P̂i, where we have Pi−αi ≤ P̂i ≤ Pi+αi. Since, each αi is bounded by inverse polynomial, so we have 1/αi = O(pα(1/ , n, size(f))), for some polynomial pα. Now, let us write the equations below, for the four events to give a clear picture.\nP1 = PrEX(f,D)[q1 = 1] = PrEX(f,D)[r(x) = f(x) and rc(x) = f(x)]\nP2 = PrEX(f,D)[q2 = 1] = PrEX(f,D)[r(x) = f(x) and rc(x) 6= f(x)]\nP3 = PrEX(f,D)[q3 = 1] = PrEX(f,D)[r(x) 6= f(x) and rc(x) = f(x)]\nP4 = PrEX(f,D)[q4 = 1] = PrEX(f,D)[r(x) 6= f(x) and rc(x) 6= f(x)]\nAgain for each additive error, αi, such that 1/αi = O(pα(1/ , n, size(f))), we have the following equations below.\nP1 − α1 ≤ P̂1 ≤ P1 + α1\nP2 − α2 ≤ P̂2 ≤ P2 + α2 P3 − α3 ≤ P̂3 ≤ P3 + α3 P4 − α4 ≤ P̂4 ≤ P4 + α4\nHence, we can say that the statistical query oracle generates probabilities as its output over the random sample space of the PAC oracle. It is very easy to simulate the oracle, SQ(f,D) on some query, say (qi, αi), with probability at\nleast 1− . A sufficient number of random labeled examples 〈x, f(x)〉, polynomial in n and 1/ can be drawn from EX(f,D), such that we only use the fraction of examples for which qi = 1 as the estimate, P̂i of Pi.(Note that we always assume that the number of calls to the PAC oracle is bounded by the polynomial pα and each qi is evaluatable in polynomial time, so that the efficiency is maintained). Thus, if the learning algorithm is given access to SQ(f,D), it can be easily simulated given access to the PAC oracle, EX(f,D).So, we can say that, the statistical query oracle is some sort of a midman between the learning algorithm and the PAC oracle, such that the learning algorithm has access to the statistical query oracle, which in turn uses the PAC oracle but there does not exist any direct contact between the algorithm and the PAC oracle.\nThus, the proof of the proposition is complete.\nFollow the diagram below to have an intuitive understanding of the mechanism discussed above (all the P̂i , s are replaced by Pi for simplicity).\nSo, uptil now, we discussed whether a class is learnable or not, provided it is evolvable. But,what happens if we say the converse, i.e whether a class is evolvable or not, provided that it is learnable? Well, it is for sure, by simple intuition that if a class is not learnable, it can’t be evolvable, which we will see in the following two propositions, with respect to the classes of parity functions and Boolean threshold functions.\nProposition 3.3. If Fn is the class of all parity concepts over n Boolean vari-\nables, then there does not exist any polynomial time efficient statistical query learning algorithm for the class F , where F = ⋃ n≥1 Fn.\nProof. The proof has been analyzed from [3]. Consider a query, q : {0, 1}n × {0, 1} → {0, 1}, which takes a variable x ∈ {0, 1}n and f(x) ∈ {0, 1} as it input, to give a Boolean output. (note that f here denotes the parity concept and not the ideal function in the model of evolution) Let us have our target distribuion, D, uniform over {0, 1}n and represent the probability of the query that it is equal to 1, on an input generated by the PAC oracle EX(f,D), such that f is drawn randomly from Fn by the variable, Pq. So, we have Pq = PrEX(f,D)[q = 1]. As we are considering uniform distribution over {0, 1}n, it is easy to see that we have Pq = (1/2 n) ∑ x∈{0,1}n q(x, f(x)). Hence, we have the following equation below if we take expectations on both sides of the previous equation.\nE[Pq] = 1\n2n E[ ∑ x∈{0,1}n q(x, f(x))]\nUsing the additive property of expectations (E[ ∑ k] = ∑ E[k]), we have the following equation below.\nE[Pq] = 1\n2n ∑ x∈{0,1}n E[q(x, f(x))]\nLet the cardinality of the set, say S0 consisting of all x, such that q is always zero (independent of f ′ s value) be equal to c0 and that of the set, say S1 consisting of all x, such that q is always 1 ((independent of f ′ s value))be equal to c1.This means, when we have some x ∈ S0, then E[q(x, f(x)) = 0 and when we have some x ∈ S1, then E[q(x, f(x))] = 1. Let c2 be the the cardinality of the set, say S2, where S2 contains all such x, for which we have q(x, 0) 6= q(x, 1). Thus, we get\nE[Pq] = 1\n2n\n( c1 + 1\n2 c2 ) Again, we have\nE[P 2q ] = 1\n22n ∑ x,y∈{0,1}n E[q(x, f(x))q(y, f(y))]\nIntuitively it can be written as,\nE[P 2q ] = 1\n22n ∑ x∈S0,y∈{0,1}n E[q(x, f(x))q(y, f(y))]+ 1 22n ∑ x∈S1,y∈{0,1}n E[q(x, f(x))q(y, f(y))] +\n1\n22n ∑ x∈S2,y∈{0,1}n E[q(x, f(x))q(y, f(y))]\nAfter analyzing the results for each set, we finally get\nE[P 2q ] = 1\n22n (c1(c1 + 1/2 c2) + c2(1/2 + 1/2 c1 + 1/4 (c2 − 1)))\nAgain, squaring both the sides of the equation for E[Pq], we get\nE[Pq] 2 =\n1\n22n\n( c1 + 1\n2 c2 )2 Hence, the variance can be calculated as,\nV ar[Pq] = E[P 2 q ]− E[Pq]2 = c2 22n+2 ≤ 1 2n+2\nHence, for any query, q, the variance of the quantity, Pq is exponentially small with respect to the random draw of the target concept and thus, it can be proved by contradiction, by taking the parameter to be any constant lesser than 1/4, fixing the parameter for α and then showing that a randomly chosen parity concept will be consistent with the query responses received by the learning algorithm, say A, by using Chebyshev’s inequality and the bound for variance, calculated above. Hence, the error of A’s hypothesis must be large with respect to the random draw of the target concept, as many parity concepts are consistent with the responses received by A and this, proves that the class of parity concepts is not efficiently SQ learnable."
    }, {
      "heading" : "4 Evolvability of the class of monotone conjunctions",
      "text" : "In this section, we will show that the class of monotone conjunctions is evolvable, under some conditions, unlike that of the parity class and the class of Boolean threshold functions.\nTheorem. The class of monotone conjunctions is provably evolvable over the uniform distribution for their natural representations.\nProof. Let us have a total of n Boolean variables, say x1, x2, ..., xn. A monotone k− conjunction is a conjunction of at most k non-negated literals over the n Boolean variables. If we want to apply our discussed evolution model to this case, it is very important that we have proper notion of neighborhood N , value of tolerance, t and the sample sizes, before we evaluate the mutator random variable at each step. We take our hypothesis class (i.e the representation class) R to be the class of all monotone k− conjunctions, such that we want an accuracy of on the evolution of this class.For some positive constant c, fix the value of k to be equal to blog(cn/ )c. (We will see later, why we assumed this value) Let for any representation r ∈ R, we have a set Sr, which contains all the sets of conjunctions of literals in r. Then we have to either remove some literal from r or add something to it or maybe add and then remove something to get a better hypothesis (representation), which has performance better than r and gets one step closer to realizing the ideal function, f . So, it is logical to assume that the neighborhood N , which is represented by the notation, Neighn(r, ), encompasses all these cases and thus, we get some better variant of r from this\nset. Let us have the following sets below.\nSr1 - Sets of all the conjunctions which consist all the literals of r, with one extra literal added Sr2 - Sets of all the conjunctions which consist all the literals of r, with one literal removed Sr3 - Sets of all the conjunctions which consist all the literals of r, with one extra literal added and then another literal removed\nSo, we have NeighN (r, ) = S r 1 ∪ Sr2 ∪ Sr3 . Thus, either we can stay at r and add or remove a literal to r and then output a variant from them (this has a probability of 1/2) or we can add a literal to r and then remove another literal from it, to get a better variant (this also has a probability of 1/2). Hence, from above, clearly N is an O(n2) neighborhood of r. Now, we have to discuss about the tolerance, sample size and performance issues of this construction.\n(Note that we will represent the tolerance, t(1/n, ) and the number of samples, s(n, 1/ ) by simply t and s respectively.) Let us take t = 12 .(2\n−2k) and s = 1/t3. Since, we have taken k = blog(cn/ )c, so we get t = 2\n2c2n2 . The construction is done in such a way that every mutation in the neighborhood N will cause a performance improvement of at least 2t or causes no improvement. The test, which has been devised identifies the right mutation except with some small exponential probability (which we get by Hoeffding bound) from the one which gives no improvement in performance.Recall the theorem of the Hoeffding bound. It says that the probability that the mean of s independent random variables , with each taking values in the range [a, b], is greater than or less than the mean of their expectations by more than δ is at most equal to e −2sδ2\n(b−a)2 . In our case, we have a = −1 and b = 1, which we have seen before. Again, since the variable δ captures deviations, so it must be equal to the tolerance, t. So, we have δ = t and hence, the number of trials, which is nothing but the sample size, s is equal to 1/δ3. So, by Hoeffding bound, the probability that all the s mutation trials each with an expected improvement of 2δ will produce a mean improvement of less than t = δ is at most equal to e −2. 1 δ3 .δ2 4 = e −1 2δ = e −1 2t = e− c2n2\n2 , which is indeed very small. Now, if we take g(n, 1/ ) to be the number of stages (equivalent to saying number of generations) and in each stage, we have a total of p variants, which are to be tested, so if we calculate g.p.e− c2n2 2 ,we see that it is strictly less than /2 if we fix some\nc > n\n√ ln 2pg properly, which is indeed what we want.\nNow, finally we prove a set of claims about the testing and performance by modifying and manipulating the current representation, r as a whole and try to give combined short proofs of them, according to [1]. We say, that r is a monotone conjunction of m literals, where m ≤ k. Consider r = y1y2...ym, where each yi ∈ {x1, x2, ..., xn}. Let A be the set of v literals, which form the conjunction\nof the ideal representation, f and B be the set of m literals, which form the conjunction of the current hypothesis r. So, let us have a set of cases and try to prove them.\nCase 1. If we have m < k, i.e the number of literals in the current hypothesis is strictly less than that of the ideal conjunction, then intuitively we can see that if we add a literal from the true function to the hypothesis, then our performance will increase and it is indeed so, mathematically. So, consider a literal, l in the set A−B, which will be added to the present hypothesis, r = y1y2...ym. Hence, adding l to r will change the value of the hypothesis from +1 to -1 on the points which satisfy the conjunction, l ′ y1y2...ym and thus, l ′ = 1, which makes l = −1 and so, the ideal function must be equal to -1 on these points as we have l = −1 and l ∈ A. As, we know that over the uniform distribution, U the probability that a conjunction of d literals will be satisfied is equal to 2−d (and hence for a disjunction to be satisfied, it is equal to 1− 2−d), so in our case, the (m+ 1) points in r will have a probability of 2−(m+1) ≥ 2−k. Thus, performance increase will be at least equal to 2.2−k = 21−k. (notice here that the value of the hypothesis is equal to the target concept, i.e r = f and hence, the performance is bound to increase).\nCase 2. Consider a literal, l in A ∩ B, which will be removed from r. Now, since the literal is also present in the ideal function, so it will surely decrease the performance. Let us take l to be equal to y1, without loss of generality.Hence, the hypothesis changes the value from -1 to +1, such that it satisfies the conjunction l ′ y2y3...ym and thus, l = −1, which makes value of the ideal function to be equal to -1. Hence, the probability of the points in the hypothesis is equal to 2−m ≥ 2−k and, since r 6= f , the performance value decreases by at least 2.2−k = 21−k.\nCase 3. Consider two literals, l1 ∈ A−B and l2 ∈ B−A, such that we add l1 to r and then remove l2 from r. Now, from the previous two cases, we see that adding l1 to r will change the hypothesis from incorrect to correct and has a probability of 2−(m+1) and removing of l2, also applies with a probability of 2\n−(m+1) and the change in some of the points is from correct to incorrect. Now, we have to show that the net change is not neutral, but positive for the evolution performance, which is very easy. Consider the set of literals, L, such that they are missing from r, but are present in f (of course, other than l1) and we have |L| = x. Now, if we consider that l2 was removed, so we have a satisfying conjunction of l1l2 ′ y2...ym and it is also known that x fraction of these have a value of 1 in the ideal function, with a probability equal to 2−x. Thus, the improvement in performance is at least equal to 2−x−m ≥ 2−|A|−k.\nCase 4. Let us have two literals, l1 6∈ A and l2 ∈ A ∩ B, so that l1 is added to r and l2 is removed from r. If we look carefully into this, we can see that it is exactly the opposite of the previous case. Now, removing l2 is an incorrect\nchange at every point, as it belongs to both the sets A and B and occurs with probability, 2−(m+1). Consider the set of literals, L such that they are absent from the ideal function, f and let |L| = x. Then we can find that on the domain of points satisfying, l1 ′ y1y2...ym, x fraction of them have a correct value of 1 on the ideal function, with a probability of 2−x, which decreases the performance measure, by at least 2−x−m ≥ 2−|A|−k.\nCase 5. Analyzing the above four cases, we find that the performance remains constant when we combine the addition of a literal in A − B to r from Case 3 with the removal of a literal in A ∩ B from r and the same thing happens when we combine the addition part of Case 4 with the removal part of Case 3. Consider two literals l1 ∈ A−B and l2 ∈ A∩B. From these two, it is clear that l1 belongs to the ideal function, but does not belong to the current hypothesis. Again, l2 belongs both to the target function and the current hypothesis. As we analyzed in the previous cases, the addition of l1 to r is a correct change at every point and the probability is equal to 2−(m+1). Also, the removal of l2 from r is an incorrect change at every point and has an equal probability of 2−(m+1). So, the effect of two changes gets cancelled. The proof of the second case is similar.\nCase 6. If the current representation, r contains all the literals that are already present in the ideal conjunction, f and it is logical, that if we remove all the irrelevant variables in r, which are not present in the target, it will increase the performance measure.(It seems that this should be the final step of evolution, in which it has been able to learn the target genome and now is ready to get rid of all the unworthy life experiences and mutate to an advanced life form. It is indeed the case, which we will see later) Without loss of generality, assume l1 = y1. Now, removing l1 from r, will change the hypothesis’s value from -1 to +1 on the points satisfying l1 ′ y2y3...ym. Again, since r contains all the literals in the target and all such points have a true value of +1 with a probability of at least 2−m, hence the performance must increase by at least 2.2−m = 21−m ≥ 21−k.\nCase 7. Have a literal, l1 in the set, B −A, which is to be added to the current representation, r, which already contains all the literals of f . Therefore, comparing with the previous cases, the value of the hypothesis changes from +1 to -1 on the points satisfying l1 ′ y1y2...ym. Similar to previous case, if r contains all the literals in f , then all such points must have true values of +1. Hence, we got a disagreement between the hypothesis and the target concept, and so the performance must decrease by 2−m ≥ 2−k. (If we consider the intuitive thinking of this case, it is like, that the evolution mechanism is already prepared to mutate and getting rid of the unwanted variables, but some extraneous agent is trying to stuff an unwanted life experience to prevent the process of mutation, by decreasing its performance measure).\nCase 8. What happens when we have |A| > k, i.e the number of literals in\nthe ideal function is greater than the number of literals in the initial representaton, of the whole evolution process? Well ,then the fraction of points on which the prediction of -1 is there, increases by (1−2−m−1)−(1−2−m) = 2−m−1. Now, if we have m ≤ k − 2, then the fraction increases by at least 21−k and a literal is added. The fraction may also decrease by at least 21−k, with the removal of one literal if we have m ≤ k − 1. Hence, for the case when we have |A| > k, the corresponding increase or decrease in the fraction of points on which the prediction is correct is at least 2−k.\nThus, according to the above mentioned rules, the evolution mechanism functions and tries to have the best possible representation, closest to the ideal function. So, it only chooses the cases, where there seems to be an increase of performance by adding or deleting literals to or from the conjunction of the current representation. Now, it can be possible that some non-ideal literals may have been added to the representaion, without decreasing the performance, but if the ideal conjunction has a total of say, z literals, then by the coupon collector’s problem, after a total of (n log z + n log 1/ ) generations, all z would have been swapped or added in, thus giving the final genome, except with a probability of . Thus, [1] says that if the initial number of literals in the representation, r0 and the number of literals in the ideal conjunction is at most equal to k, then the evolution mechanism gets completed in the above mentioned number of stages (or generations), except with a probability of , where is the error parameter due to various factors, hindering evolution. Again, if we have m > k, then the removal of any literal from the hypothesis will change the value on at most, 2−m < 2−k = 2 /cn of the distribution and hence, the performance can decrease at the most by 2 /cn. Thus, if we set the tolerance, t to 4 /cn and hence, we have δ = 2 /cn for the Hoeffding Bound analysis, for checking the probability when we decrease the number of literals from the hypothesis, we actually have a neutral condition of mutation. But, putting a = −1, b = 1, δ = 2 /cn = t/2 and s = δ3, the probability is at most e−cn/4 , which is very less. Thus, after running the process for O(n) stages, we will be able to reach to a smaller conjunction of length k, except with an exponentially small probability. We can also show optimality for the 8th case, by similar manner.\nBy duality principle, we can convert a conjunction to a disjunction, by the laws of negation and applying De-Morgan’s laws, we can also prove evolvability for the class of disjunctions."
    }, {
      "heading" : "5 Critical assessment, suggestions and open problems",
      "text" : "I discuss some open problems and further suggestions to extend the model of evolution of [1]. Though [1] is undoubtedly one of the very few best papers in this area of evolution and theoretical computer science, but according to me, there is still much to be done in this new field of study. Let us discuss some of them below.\n1. We have some forceful assumptions in the definitions of evolvability, such that it falls in the framework of PAC learning model. Though, we can say that a genome is evolvable only when its performance is close to 1, i.e it, almost is same to the target function (target genome) and so can assume that the final performance is equal to 1− , for some small > 0, but is it necessary to bound the resources and time of computing the variants by polynomials. How can we be so sure, that everything is polynomially bounded? We are basically assuming beforehand that evolutionary mechanism is a PAC learning model in the definitions, that we define. Maybe, we could have assumed that the final performance is some 0 < x < 1 and then established the PAC learnability of evolution.\n2. Maybe, there exists an algorithm with nature which efficiently searches all the exponentially possible many variants of the current genome. Maybe, there are c.2n many representations, for some positive constant c, but somehow the evolutionary mechanism knows beforehand which representation to pick and then may apply binary search, so that the search completes in O(n) time, which is very efficient. We should always understand that evolution mechanism is itself learning for millions of years and through its experience, it may have some information of which representation to select (or there may exist some probability distribution over the variants and there may exist many variants which are capable of evolution in the probability space) for the next generation and hence, can perform a binary search over all the variants. The idea of discarding most of the variants seems to be too much of an assumption.\n3. It may be possible that evolution has some efficient algorithm to search all the exponential variants in efficient polynomial time and finding the algorithm, will be one of the the first stepping stones towards the great P-NP problem from biological evolution point of view. It may be probable that nature has some algorithm, which outputs the evolved genome without even looking at all the variants. (Here where, statistical query learning may have great importance to formulate a better theory of evolution, by generating a favorable probability space over the variants). It is the right time, that computer science theorists and mathematicians look more deeply into Darwinian theories, to some how come close to one of the greatest problems ever posed by the humans.\n4. Does there exist any distribution free evolution model, is a very general and broad question and it may take quite a long time to get a satisfactory answer to this question.[1]\n5. Finally, it is unknown whether we can PAC learn the class of DNF using DNF hypothesis and find a consistent hypothesis finder in polynomial time. So, there is some possibility that we learn the evolvability of the DNF expressions, where we start our initial representation of the genome with a DNF and the target concept is also a DNF. Since, DNFs are extremely rich in their representations and can entail lots of valuable information, so it is possible that evolution\nmechanism uses this class of expressions and still evolves into a stronger individual within a finite number of generations. Hence, evolvability with respect to the class of DNFs, will be an open problem for a great amount of time, according to me."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2013,
    "abstractText" : "Darwin’s theory of evolution is considered to be one of the greatest scientific gems in modern science. It not only gives us a description of how living things evolve, but also shows how a population evolves through time and also, why only the fittest individuals continue the generation forward. The paper basically gives a high level analysis of the works of Valiant[1]. Though, we know the mechanisms of evolution, but it seems that there does not exist any strong quantitative and mathematical theory of the evolution of certain mechanisms. What is defined exactly as the fitness of an individual, why is that only certain individuals in a population tend to mutate, how computation is done in finite time when we have exponentially many examples: there seems to be a lot of questions which need to be answered. [1] basically treats Darwinian theory as a form of computational learning theory, which calculates the net fitness of the hypotheses and thus distinguishes functions and their classes which could be evolvable using polynomial amount of resources. Evolution is considered as a function of the environment and the previous evolutionary stages that chooses the best hypothesis using learning techniques that makes mutation possible and hence, gives a quantitative idea that why only the fittest individuals tend to survive and have the",
    "creator" : "LaTeX with hyperref package"
  }
}