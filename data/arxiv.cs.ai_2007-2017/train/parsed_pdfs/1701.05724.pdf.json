{
  "name" : "1701.05724.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Logical Inferences with Contexts of RDF Triples",
    "authors" : [ "Vinh Nguyen", "Amit Sheth" ],
    "emails" : [ "vinh@knoesis.org", "amit@knoesis.org", "info@vldb.org." ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this paper, we propose the first inferencing mechanism that allows context of RDF triples, represented in the form of RDF triples about triples, to be the first-class citizens in the model-theoretic semantics and in the logical rules. Our inference mechanism is well-formalized with all new concepts being captured in the model-theoretic semantics. This formal semantics also allows us to derive a new set of entailment rules that could entail new contextual triples about triples.\nTo demonstrate the feasibility and the scalability of the proposed mechanism, we implement a new tool in which we transform the existing knowledge bases to our representation of RDF triples about triples and provide the option for this tool to compute the inferred triples for the proposed rules. We evaluate the computation of the proposed rules on a large scale using various real-world knowledge bases such as Bio2RDF NCBI Genes and DBpedia. The results show that the computation of the inferred triples can be highly scalable. On average, one billion inferred triples adds 5-6 minutes to the overall transformation process. NCBI Genes, with 20 billion triples in total, took only 232 minutes for the transformation of 12 billion triples and added 42 minutes for inferring 8 billion triples to the overall process."
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Semantic Web technologies such as RDF and OWL are emerging as standard languages for machine-understandable knowledge representation and reasoning. A Semantic Web\nThis work is licensed under the Creative Commons AttributionNonCommercial-NoDerivatives 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-nd/4.0/. For any use beyond those covered by this license, obtain permission by emailing info@vldb.org. Proceedings of the VLDB Endowment, Vol. 10, No. 4 Copyright 2016 VLDB Endowment 2150-8097/16/12.\nknowledge base, as a set of RDF triples, can be created using different methods. Existing data from a structured form (e.g., relational databases, text files, XML documents, or HTML pages) can be transformed into RDF with ontologies describing the database schema (e.g., Bio2RDF [8] and PubChem [12]). A knowledge base can also be created by extracting the triples in the form of (subject, predicate, object) from unstructured data using natural language processing algorithms (e.g., Google Knowledge Vault [11], Yago2S [17], and DBpedia [20]). In either method, each RDF triple in the resulting knowledge bases can be associated and enriched with different types of contextual information, such as the time duration in which the triple holds true, and the provenance specifying the source of the triple.\nIf a knowledge base is created and maintained by an organization, the knowledge integrity can be validated within that organization. Nowadays, it is commonplace for a knowledge base to be created and shared by anyone on the Web, or in the Linked Open Data. Therefore, we believe that the context of every fact or assertion should be provided for consumers to validate and assess the reliability of the knowledge before using it. The contextual information of a triple may provide the time interval or the time instant when the triple holds true so that the consumers can validate it. It may also provide the Web page or the article where the triple was extracted from, or any provenance information that allows for tracking the origin of the triples so that the consumers can assess the reliability of the triples. Since a fact would not hold true in every context, the context in which a proposition holds true needs to be presented in the knowledge bases so that the proposition can be validated and reused.\nPopular knowledge bases currently represent the contextual information of their triples in the RDF quad form. For example, DBpedia [6], CTD [1], and GO Annotations [2], NCBI Genes [4], and PharmGKB [5] have the provenance of every RDF triple represented in the quad form. Since the fourth element of the RDF quad is not formalized as firstclass citizen of the current model-theoretic semantics [15], it cannot be represented in the entailment rules. Therefore, to support the inferences involving contextual information about RDF triples, we believe that the current RDF and OWL semantics should be expanded to allow for the accomodation of contexts of triples as first-class citizens in the model-theoretic semantics and entailment rules."
    }, {
      "heading" : "1.1 Motivating Example",
      "text" : "Given a statement “Barack Obama is married to Michelle Obama” (T1), and a sub-property relationship between isMarriedTo and isSpouseOf (T2), applying the rule rdfs7 [14]\nar X\niv :1\n70 1.\n05 72\n4v 1\n[ cs\n.A I]\n2 0\nJa n\n20 17\nfor rdfs:subPropertyOf on the two triples will entail the new triple “Barack Obama is a spouse of Michelle Obama” (T3).\nT1: BarackObama isMarriedTo MichelleObama . T2: isMarriedTo subPropertyOf isSpouseOf . T3: BarackObama isSpouseOf MichelleObama .\nThese triples would provide enough knowledge for answering simple questions. For example, who is Barack Obama married to? Or who is spouse of Barack Obama?\nHowever, these triples do not provide sufficient knowledge to give answers to more complex questions. For example, when and where did Barack Obama marry Michelle Obama? Was he married to Michelle Obama before 2008? Was he a spouse of Michelle Obama in Harvard, Massachusetts?\nTo answer these questions, contextual information such as time and location need to be represented, as in “Barack Obama is married to Michelle Obama in Chicago in 1992”. Given this contextual statement and the knowledge that Chicago is a city in Illinois, and Illinois is a state in the USA, we as humans can quickly infer many contextual statements which could answer the above questions. Furthermore, we can also infer statements that could be much different from the original statement and from each other. For example, the statements S1 and S5 in Table 1 only share the subject and the object while their relationships and contextual information are totally different, as shown in Table 1 with the inferred information in bold font.\nHow does a machine become intelligent enough to infer contextual statements as humans do? We address this question by (1) developing an inferencing mechanism that could entail new contextual statements and (2) demonstrating an inferencing process that derives the human-inferred contextual statements from the original statement.\nIn order for machines to infer contextual statements, we believe that two requirements need to be fulfilled. First, these contextual statements must be represented in machine-understandable form, with explicitly defined semantics for the relationship between the triple and its contextual information. Second, we need an entailment mechanism that takes into account the semantics of the contextual triples about triples so that it can entail the new ones.\nTo the best of our knowledge, there is no RDF/RDFS inferencing rule that involves RDF contextual triples about triples. Our paper addresses this missing capability."
    }, {
      "heading" : "1.2 Approach",
      "text" : "The contextual statement “Barack Obama is married to Michelle Obama in Chicago” is used as an illustrative example throughout the paper. We represent this contextual statement and the background knowledge of Chicago in the form of triples as follows:\nT1: BarackObama isMarriedTo MichelleObama . T4: T1 happenedIn Chicago . T5: Chicago partOf Illinois . T6: Illinois partOf USA .\nWe call T1 a primary triple and T4 a meta triple about location. The primary triple T1 is a regular RDF triple, while the meta triple T4 describes the context in which the primary triple holds true.\nConsidering the original statement represented in T1 and T4, there is no relationship between the triple “BarackObama isMarriedTo MichelleObama” and its identifier T1. Therefore, there is no relationship between the primary triple T1 and the meta triple T4.\nTo bridge this gap and fulfill the requirement of representing contextual statements in machine-understandable form as discussed earlier, several approaches such as named graph [9], RDF reification [14], and singleton property [22] can be used for representing the relationship between a triple and its identifier. Furthermore, the semantics of the relationship between a triple and its identifier must be captured and expressed as a first-class citizen in the formal semantics. It allows the semantics of the contextual statements to be expressed in the formal model as well as in the logical rules.\nAmong the existing approaches, the singleton property representation comes with a formal semantics formalizing the relationship between the singleton property and the triple it represents. Meanwhile, although the named graph could be used as a triple identifier, it was not intended to be used for that purpose. Instead, the named graph is mainly used for representing a set of triples. The RDF reification does not have a formal semantics for capturing the relationship between a statement instance and the triple it represents. As a result, we choose the singleton property (SP) representation and use its semantics in our entailment mechanism. Correspondingly, all the knowledge bases available in the form of RDF reification or named graph need to be transformed into the singleton property representation for inference purposes.\nThis paper has two contributions:\n• We developed a new entailment mechanism that allows contextual statements, represented in the form of RDF contextual triples about triples, to be the firstclass citizens in model-theoretic semantics as well as in the logical rules. The proposed mechanism is wellformalized with all new concepts for RDF triples about triples (Section 2) being captured by a model-theoretic semantics (Section 3). The formal semantics also allows us to derive a new set of rules that could entail new contextual statements (Section 4.1). We demonstrate how the human-inferred contextual statements in Table 1 can be entailed using the proposed rules (Section 4.2).\n• We demonstrated that the proposed entailment mechanism is scalable. We developed a new tool, called rdfcontextualizer, to transform existing knowledge bases from the named graph form to the singleton property representation. We then provide the option to compute all inferred triples using the proposed contextual entailment rules in this tool (Section 5). We evaluated the computational performance in very large realworld knowledge bases with billions of triples such as DBpedia and NCBI Genes (Section 6).\nThis paper presents the foundational capability. While the location context and simple question answering are used as the illustrative examples, discussions of a broad class of Semantic Web applications such as querying SPARQL with backward-chaining reasoning, streaming reasoning, temporal reasoning, tracking context of inferred triples, and question answering based on extracted knowledge and logical inferences, are beyond the scope of the paper.\nThe remaining sections are as follows. We present the related work in Section 7. We discuss the future work in Section 8 and conclude with Section 9."
    }, {
      "heading" : "2. CONCEPTUAL MODEL",
      "text" : ""
    }, {
      "heading" : "2.1 Preliminaries",
      "text" : "Here we recall the singleton property concept with its syntax and semantics from [22]. A singleton property is a specific property instance that represents a unique relationship under a specific context. For the example at hand, the singleton property isMarriedTo#1 uniquely represents the isMarriedTo relationship between BarackObama and MichelleObama. This singleton property can be asserted with contextual information “in Chicago” about the relationship as follows:\nSP1: BarackObama isMarriedTo#1 MichelleObama . SP2: isMarriedTo#1 singletonPropertyOf isMarriedTo . SP3: isMarriedTo#1 happenedIn Chicago .\nFormal semantics. Here we recall the mapping function IEXT from the current model-theoretic semantics [15].\nA property mapping function IEXT is a binary relation that maps one property to a set of pairs of resources.\nFormally, let IP be the set of properties, IR be the set of resources. Then IEXT : IP → 2IR×IR.\nA singleton mapping function IS EXT is a binary relation that maps one singleton property to one pair of resources.\nFormally, let IR be the set of resources, IPs ⊆ IP be the set of singleton properties. Then IS EXT : IPs → IR × IR.\nFor example, IS EXT (isMarriedTo#1) = 〈BarackObama, MichelleObama〉. As the singleton property isMarriedTo#1 is also a property, its property extension is a singleton set, which has only one element. IEXT (isMarriedTo#1) = 〈BarackObama, MichelleObama〉.\nThe syntax and the semantics of singleton properties described here are sufficient to allow us to attach contextual information for any RDF individual triple.\nNext, we describe how singleton properties can be utilized for developing our inference scheme to infer new triples."
    }, {
      "heading" : "2.2 Property Types",
      "text" : "A generic property asserts the relationship between the subject and the object without providing additional contextual information about the relationship. This property groups all singleton properties sharing the same characteristics across contexts, and it is connected to a singleton property via the property singletonPropertyOf.\nSP2: isMarriedTo#1 singletonPropertyOf isMarriedTo .\nIn this example, isMarriedTo is a generic property. Here we propose to add the new class GenericProperty to represent the set of generic properties, in addition to the class SingletonProperty from [22]. Any property that is not defined as a singleton property can become generic property. Intuitively, a generic property is mapped to a set\nof pairs while the singleton property is mapped to a single pair. If a singleton property also plays the role of a generic property, it will occur as the predicate in multiple triples. This contradicts to the definition of the singleton property. Therefore, a singleton property should never be defined as a generic property. In other words, the set of generic properties and the set of singleton properties are disjoint. The two classes SingletonProperty and GenericProperty do not share common instances.\nEvery generic property is an RDF property, but not every RDF property is a generic property as, for example, it could be a singleton. That makes GenericProperty a sub-class of Property.\nrdf:GenericProperty rdfs:subClassOf rdf:Property . rdf:SingletonProperty rdfs:subClassOf rdf:Property .\nEvery generic property is an instance of the Property class. However, one Property instance may not belong to any of the classes SingletonProperty or GenericProperty. We call this a regular property. In the example at hand, partOf is a regular property.\nAlthough a regular property in some cases may share the same property extension with a generic property, it is necessary to make the clear distinction between them.\nDistinguishing property types. Here we distinguish three types of properties: singleton, generic, and regular. We also call them context-associated, context-dissociated, and context-agnostic property, respectively. A singleton property such as isMarriedTo#1 is called context-associated because it can be asserted with contextual information. A generic property, or context-dissociated property such as isMarriedTo, does not have contextual information attached. Finally, a regular property such as happenedIn, instance of Property class, is called a context-agnostic property because it is not yet committed to be associated or dissociated with contextual information."
    }, {
      "heading" : "2.3 Triple Types",
      "text" : "Similar to the distinction of the property types, here we can also distinguish the type of a triple based on the type of its property. The three types of properties form three types of triples: singleton, generic, and regular triple. A singleton triple is the only triple that has its singleton property occurring as a predicate. A generic triple is a triple that has its predicate asserted as a generic property. A regular triple is a triple that does not have its predicate asserted as a generic or singleton property.\nSingleton: BarackObama isMarriedTo#1 MichelleObama . Generic: BarackObama isMarriedTo MichelleObama . Regular: Chicago partOf Illinois .\nDistinguishing triple types based on context. The three types of properties form three types of triples: contextassociated, context-dissociated, and context-agnostic triple. A context-associated triple is a singleton triple that may have contextual information associated with it via its singleton property. A context-dissociated triple is a generic triple that does not have any contextual information associated with it. A context-agnostic triple is a regular triple that is not committed to be associated or dissociated with contextual information."
    }, {
      "heading" : "2.4 Contextual triple instantiation",
      "text" : "Back to the motivating example, we have the original statement “Barack Obama married to Michelle Obama in\nChicago” represented as follows:\nT1: BarackObama isMarriedTo MichelleObama . T4: T1 happenedIn Chicago .\nWe utilize the singleton property graph pattern to bridge the gap between the primary triple T1 and its identifier as explained in Section 2.1.\nSP1: BarackObama isMarriedTo#1 MichelleObama . SP2: isMarriedTo#1 singletonPropertyOf isMarriedTo . SP3: isMarriedTo#1 happenedIn Chicago .\nThis singleton property graph pattern represents the primary triple T1 and its meta triple T4 by creating a singleton property isMarriedTo#1 and using it as triple identifier for asserting meta triples.\nFrom triple SP2, isMarriedTo#1 is the singleton property and isMarriedTo is a generic property. According to the triple type classification in Section 2.3, T1 is a generic triple and SP1 is a singleton triple. SP1 can be considered as one contextual triple instance of T1. We generalize this relationship between the two triples as follows.\nDefinition. Let sp be the singleton property of property p and (s, sp, o) be the singleton triple, (s, sp, o) is the contextual triple instance of the generic triple (s, p, o).\nHow a generic triple (s, p, o) can be derived from the singleton graph pattern will be formalized in the RDF formal semantics described in Section 3.3."
    }, {
      "heading" : "3. MODEL-THEORETIC SEMANTICS",
      "text" : ""
    }, {
      "heading" : "3.1 Mapping Functions",
      "text" : "In the formal semantics, we use the concept of function to assign the set of URIs and literals into the set of resources in a model interpretation, and assign each property a set of pairs (subject, object).\nNext, we define new mapping functions to be used in the interpretations described later in this section. We reuse the set of singleton properties IPs, the set of properties IP, the mapping function IEXT , and the singleton mapping function IS EXT mentioned in Section 2.1.\nDefinition. A generic property instance function IG is a binary relation that maps a generic property to a set of its singleton properties.\nFormally, let IPg ⊆ IP be the set of generic properties. We define the function\nIG : IPg → 2IPs such that IG(pg) = {ps | 〈ps, pg〉 ∈ IEXT (rdf:singletonPropertyOf)}. For example, isMarriedTo is a generic property and it has\ntwo singleton properties as follows:\nisMarriedTo#1 rdf:singletonPropertyOf isMarriedTo . isMarriedTo#2 rdf:singletonPropertyOf isMarriedTo .\nIG(isMarriedTo) = {isMarriedTo#1, isMarriedTo#2}. Definition. A generic mapping function IG EXT is a binary relation that maps a generic property to a set of pairs of resources.\nIG EXT : IPg → 2IR×IR such that IG EXT (pg) = {IS EXT (ps) | ps ∈ IG(pg)}. Since IPg ⊆ IP, we have IG EXT (pg) ⊆ IEXT (pg). We also have IEXT (ps) = {〈s, o〉|〈s, o〉 = IS EXT (ps)}. IEXT (pg) = {〈s, o〉|〈s, o〉 ∈ IG EXT (pg)}. In the example at hand, we have:\nIEXT (isMarriedTo#1) = {〈BarackObama, MichelleObama〉}, IEXT (isMarriedTo) = {〈BarackObama, MichelleObama〉}.\nNext, we describe model-theoretic semantics using these mapping functions.\nFor RDF and RDFS, the entailments are determined by the model-theoretic semantics. For an entailment relation X (e.g., RDFS entailment), an RDF graph G is said to X-entail an RDF graph G′ if each X-interpretation that satisfies G also satisfies G′. This definition is completed with a mathematical definition of X-interpretation.\nWe specify three interpretations: simple, RDF and RDFS by extending the model-theoretic semantics described in [16, 22]. For each interpretation, we add additional criteria for supporting the singleton property and the generic property. While we explain the new vocabulary elements in detail, elements without further explanation remain as they are in the original model-theoretic semantics described in [16, 22]."
    }, {
      "heading" : "3.2 Simple Interpretation",
      "text" : "In the simple interpretation, we formalize the three types of properties as described in Section 2. We also use the mapping functions described in Section 3.1 to assign each property to a semantic construct.\nGiven a vocabulary V, the simple interpretation I consists of:\n1. IR, a non-empty set of resources, alternatively called domain or universe of discourse of I,\n2. IP, the set of properties of I,\n3. IPs, called the set of singleton properties of I, as a subset of IP,\n4. IPg, called the set of generic properties of I, as a subset of IP, IPs ∩ IPg = ∅,\n5. IPr, called the set of regular properties, IPr = IP \\ (IPs ∪ IPg),\n6. IG, a function assigning a generic property to a set of its singleton properties,\n7. IEXT , a mapping function assigning to each property a set of pairs from IR,\nIEXT : IP → 2 IR×IR where IEXT (p) is called the extension of property p,\n8. IS EXT (ps), the singleton mapping function assigning a singleton property to a pair of resources.\nIS EXT : IPs → IR × IR.\n9. IG EXT (pg), the generic mapping function assigning each generic property a set of pairs of resources.\nIG EXT : IPg → 2 IR×IR.\nNote that the mapping function IS EXT is not a one-toone mapping; multiple singleton properties may be mapped to the same pair of entities."
    }, {
      "heading" : "3.3 RDF Interpretation",
      "text" : "In the RDF interpretation, we formalize the definition of singleton property, generic property, and how to derive the generic triple from a singleton graph pattern.\nRDF interpretation of a vocabulary V is a simple interpretation I of the vocabulary V ∪ VRDF that satisfies the criteria from the current RDF interpretation [15] and the following criteria:\n1. Define a singleton property xs ∈ IPs iff 〈xs, rdf:SingletonProperty I〉 ∈ IEXT (rdf:type I〉.\n2. Singleton condition If xs ∈ IPs then ∃!〈u, v〉 : 〈u, v〉 = IS EXT (xs), and u,v ∈ IR. This enforces the singleton-ness for the property instances.\n3. Define a generic property xg ∈ IPg iff 〈xg, rdf:GenericProperty I〉 ∈ IEXT (rdf:type I). If x /∈ IPs, then IPg = IPg ∪ {x}. Any property that is not defined as a singleton property can become generic property.\n4. Infer singleton property and generic property (rule rdfsp-1 and rdf-sp-2)\nxs ∈ IPs and xg ∈ IPg if 〈xs, xg〉 ∈ IEXT (rdf:singletonPropertyOf I). A singleton property xs is connected to a generic property xg via the property rdf:singletonPropertyOf. As IG(xg) is the set of singleton properties connected to the property xg, IG(xg) = {xs | 〈xs, xg〉 ∈ IEXT (rdf:singletonPropertyOfI)}.\n5. Generic mapping extension\nIf 〈xs, xg〉 ∈ IEXT (rdf:singletonPropertyOf I), then xs ∈ IPs, xg ∈ IPg, and IS EXT (xs) ∈ IG EXT (xg). IG EXT (xg) is called a generic mapping extension of the generic property xg. IG EXT (xg) = {IS EXT (xs) |xs ∈ IG(xg)}, and IG EXT (xg) ⊆ IEXT (xg).\n6. Generic triple derivation (rule rdf-sp-3)\nIf 〈u, v〉 = IS EXT (xs), and 〈xs, xg〉 ∈ IEXT (rdf:singletonPropertyOf I), then 〈u, v〉 ∈ IG EXT (xg). Proof. 〈xs, xg〉 ∈ IEXT (rdf:singletonPropertyOf I) implies (1): IS EXT (xs) ∈ IG EXT (xg). The combination of 〈u, v〉 = IS EXT (xs) and (1) implies 〈u, v〉 ∈ IG EXT (xg). This shows how the generic triple 〈u, v〉 ∈ IG EXT (xg) can be derived from its singleton graph pattern."
    }, {
      "heading" : "3.4 RDFS Interpretation",
      "text" : "Here we formalize the connections from a singleton property to its generic property, as well as to other properties such as rdfs:domain, rdfs:range, and rdfs:subPropertyOf. We will reuse the function (from [15]) ICEXT : IR → 2IR where ICEXT (y) is called a class extension of y, ICEXT (y) = {x | ∀x ∈ IR : 〈x, y〉 ∈ IEXT (rdf:typeI)}.\nRDFS interpretation of a vocabulary V is an RDF interpretation I of the vocabulary V ∪ VRDFS that satisfies criteria from the current RDFS interpretation [15] and the following criteria:\n1. Class rdf:SingletonProperty\n〈rdf:SingletonProperty I , rdfs:Class I〉 ∈ IEXT (rdf:type I). The extension of rdf:SingletonProperty class is the set IPs of all singleton properties, or IPs = ICEXT (rdf:SingletonProperty I).\n2. Class rdf:GenericProperty\n〈rdf:GenericPropertyI ,rdfs:ClassI〉 ∈ IEXT (rdf:type I). The extension of the rdf:GenericProperty class is the set IPg of all generic properties, or IPg = ICEXT (rdf:GenericProperty I).\n3. Every singleton property is a resource\n〈rdf:SingletonProperty I , rdfs:Resource I〉 ∈ IEXT (rdfs:subClassOf I), this causes IPs ⊆ IR.\n4. Every generic property is a resource\n〈rdf:GenericProperty I , rdfs:Resource I〉 ∈ IEXT (rdfs:subClassOf I), this causes IPg ⊆ IR.\n5. Domain of singleton property (rule rdfs-sp-1)\n〈xs, x〉 ∈ IEXT (rdf:singletonPropertyOf I), 〈x, y〉 ∈ IEXT (rdfs:domain\nI), if 〈u, v〉 ∈ IS EXT (xs), then u ∈ ICEXT (y). A singleton property shares the domain with its generic property.\n6. Range of singleton property (rule rdfs-sp-2)\n〈xs, x〉 ∈ IEXT (rdf:singletonPropertyOf I), 〈x, y〉 ∈ IEXT (rdfs:range\nI), if 〈u, v〉 = IS EXT (xs), then v ∈ ICEXT (y). A singleton property also shares the range with its generic property.\n7. Sub-property condition\nIf x, y ∈ IPg, 〈x, y〉 ∈ IEXT (rdfs:subPropertyOf I), then IG(x) ⊆ IG(y), and IG EXT (x) ⊆ IG EXT (y).\n8. Sub-property upper bound condition\nIf y ∈ IPs and 〈x, y〉 ∈ IEXT (rdfs:subPropertyOf I), then x ∈ IPs and IS EXT (x) = IS EXT (y). Proof. Since y ∈ IPs, ∃!〈u, v〉 : 〈u, v〉 = IS EXT (y), and IEXT (y) = {〈u, v〉}. Since 〈x, y〉 ∈ IEXT (rdfs:subPropertyOf I), by definition, IEXT (x) ⊆ IEXT (y) = {〈u, v〉}. Since x can be mapped to at most one pair of resources, x ∈ IPs, and IS EXT (x) = 〈u, v〉 = IS EXT (y).\n9. Sub-property lower bound condition (rule rdfs-sp-4)\nIf x ∈ IPg and 〈x, y〉 ∈ IEXT (rdfs:subPropertyOf I), then y ∈ IPg. Proof. Assume that y ∈ IPs, then x ∈ IPs (upper bound condition). We have both x ∈ IPs and x ∈ IPg. This contradicts to the condition IPs ∩ IPg = ∅. Therefore, y /∈ IPs, and according to the condition (3) of RDF interpretation, IPg = IPg ∪ {y}, or y ∈ IPg.\n10. Property hierarchy (rule rdfs-sp-3)\nIf 〈xs, x〉 ∈ IEXT (rdf:singletonPropertyOf I), and 〈x, y〉 ∈ IEXT (rdfs:subPropertyOf I), then 〈xs, y〉 ∈ IEXT (rdf:singletonPropertyOf I). Proof. 〈xs, x〉 ∈ IEXT (rdf:singletonPropertyOf I) implies (1): xs ∈ IG(x). 〈x, y〉 ∈ IEXT (rdfs:subPropertyOf I) implies (2): IG(x) ⊆ IG(y). (1) and (2) derive (3): xs ∈ IG(y). In other words, xs is a singleton property of y, or 〈xs, y〉 ∈ IEXT (rdf:singletonPropertyOf I)."
    }, {
      "heading" : "3.5 OWL 2 RDF-based Semantic Conditions",
      "text" : "From the RDF-based semantics of OWL 2 Full [23], we consider the semantic conditions of the OWL classes and properties that are relevant to singleton properties. These semantic conditions belong to the two categories: logical characteristics of the properties, and relations to other properties. We tighten the semantic conditions of these OWL classes and properties to make sure they are valid in the extended semantics, by enforcing more constraints on the generic property and singleton property extensions. The semantic conditions of these properties must be satisfied in the interpretations extended with singleton property semantics.\nLet Vp be the vocabulary of OWL classes and properties relevant to singleton properties: Vp = {FunctionalProperty, InverseFunctionalProperty, ReflexiveProperty, IrreflexiveProperty, SymmetricProperty, AsymmetricProperty, TransitiveProperty, inverseOf, equivalentOf}.\nLet ps, p ′ s, and p ′′ s be the singleton properties of the generic property p, then ps ∈ IG(p), p′s ∈ IG(p), p′′s ∈ IG(p). We define the OWL 2 RDF-based interpretation as follows.\nOWL 2 RDF-based interpretation of a vocabulary V is an RDFS interpretation I of the vocabulary V ∪ VOWL that satisfies criteria from the OWL interpretation [23] and the following semantic conditions:\n• Functional property. If a property is functional, then at most one distinct value can be assigned to any given individual via this property.\nA property p is an instance of owl:FunctionalProperty iff ∀x, y1, y2: (1) p ∈ IP, 〈x, y1〉 ∈ IEXT (p), 〈x, y2〉 ∈ IEXT (p) implies y1 = y2,\n(2) p ∈ IPg, 〈x, y1〉 ∈ IG EXT (p), 〈x, y2〉 ∈ IG EXT (p) implies y1 = y2,\n(3) ∀ps ∈ IG(p), 〈x, y1〉 = IS EXT (ps), 〈x, y2〉 = IS EXT (ps) implies y1 = y2.\n• Inverse functional property. An inverse functional property can be regarded as a “key” property, i.e., no two different individuals can be assigned the same value via this property.\nA property p is an instance of owl:InverseFunctionalProperty iff ∀x1, x2, y: (1) p ∈ IP, 〈x1, y〉 ∈ IEXT (p), 〈x2, y〉 ∈ IEXT (p) implies x1 = x2,\n(2) p ∈ IPg, 〈x1, y〉 ∈ IG EXT (p), 〈x2, y〉 ∈ IG EXT (p) implies x1 = x2,\n(3) ∀ps ∈ IG(p), 〈x1, y〉 = IS EXT (ps), 〈x2, y〉 = IS EXT (ps) implies x1 = x2.\n• Reflexive property. A reflexive property relates every individual in the universe to itself.\nA property p is an instance of the class owl:ReflexiveProperty iff ∀x: (1) p ∈ IP, 〈x, x〉 ∈ IEXT (p), (2) p ∈ IPg, 〈x, x〉 ∈ IG EXT (p), (3) ∀ps ∈ IG(p), 〈x, x〉 = IS EXT (ps).\n• Irreflexive property. An irreflexive property does not relate any individual to itself.\nA property p is an instance of the class owl:IrreflexiveProperty iff ∀x: (1) p ∈ IP, 〈x, x〉 /∈ IEXT (p), (2) p ∈ IPg, 〈x, x〉 /∈ IG EXT (p), (3) ∀ps ∈ IG(p), 〈x, x〉 6= IS EXT (ps).\n• Symmetric property. If two individuals are related by a symmetric property, then this property also relates them reversely.\nA property p is an instance of the class owl:SymmetricProperty iff ∀x, y : (1) p ∈ IP, 〈x, y〉 ∈ IEXT (p) implies 〈y, x〉 ∈ IEXT (p), (2) p ∈ IPg, 〈x, y〉 ∈ IG EXT (p) implies 〈y, x〉 ∈ IG EXT (p), (3) ∀ps ∈ IG(p), 〈x, y〉 = IS EXT (ps) implies ∃p′s ∈ IG(p), 〈y, x〉 = IS EXT (p′s).\n• Asymmetric property. If two individuals are related by an asymmetric property, then this property never relates them reversely.\nA property p is an instance of the class owl:AsymmetricProperty iff ∀x, y : (1) p ∈ IP, 〈x, y〉 ∈ IEXT (p) implies 〈y, x〉 /∈ IEXT (p), (2) p ∈ IPg, 〈x, y〉 ∈ IG EXT (p) implies 〈y, x〉 /∈ IG EXT (p), (3) ∀ps ∈ IG(p), 〈x, y〉 = IS EXT (ps) implies @p′s ∈ IG(p), 〈y, x〉 = IS EXT (ps).\n• Transitive property. A transitive property that relates an individual a to an individual b, and individual b to an individual c, also relates a to c.\nA property p is an instance of the class owl:TransitiveProperty iff ∀x, y, z : (1) p ∈ IP, 〈x, y〉 ∈ IEXT (p), 〈y, z〉 ∈ IEXT (p) implies 〈x, z〉 ∈ IEXT (p), (2) p ∈ IPg, 〈x, y〉 ∈ IG EXT (p), 〈y, z〉 ∈ IG EXT (p) implies 〈x, z〉 ∈ IG EXT (p), (3) ∀ps, p′s ∈ IG(p), 〈x, y〉 = IS EXT (ps), 〈y, z〉 = IS EXT (p ′ s) implies ∃p′′s ∈ IG(p), 〈x, z〉 = IS EXT (p′′s ).\n• Inverse property. The inverse of a given property is the corresponding property with subject and object swapped for each property assertion built from it.\n(p1, p2) ∈ IEXT (owl:inverseOf I) iff (1) ∀p1, p2 ∈ IP, IEXT (p1) = {〈x, y〉 | 〈y, x〉 ∈ IEXT (p2)}, (2) ∀p1, p2 ∈ IPg, IG EXT (p1) = {〈x, y〉 | 〈y, x〉 ∈ IG EXT (p2)}, (3) ∀ps ∈ IG(p1),∀p′s ∈ IG(p2), IS EXT (ps) = 〈x, y〉 , IS EXT (p ′ s) = 〈y, x〉.\n• Equivalent property. Two equivalent properties share the same property extension.\n(p1, p2) ∈ IEXT (owl:equivalentOf I) iff (1) ∀p1, p2 ∈ IP : IEXT (p1) = IEXT (p2), (2) ∀p1, p2 ∈ IPg : IG EXT (p1) = IG EXT (p2), (3) ∀ps ∈ IG(p1), ∃p′s ∈ IG(p2) : IS EXT (ps) = IS EXT (p ′ s)."
    }, {
      "heading" : "4. CONTEXTUAL INFERENCES",
      "text" : "In the RDF, RDFS, and OWL 2 Full interpretations, we have proved several deduction rules in Section 3. Here we present a set of these rules in Section 4.1 and demonstrate how these rules can be applied to derive the inferred statements described in the motivating example in Section 4.2."
    }, {
      "heading" : "4.1 Contextual Entailment Rules",
      "text" : "The three following rdf-sp rules are derived from the RDF interpretation.\nu rdf:singletonPropertyOf v .\nu rdf:type rdf:SingletonProperty . (rdf-sp-1)\nu rdf:singletonPropertyOf v .\nv rdf:type rdf:GenericProperty . (rdf-sp-2)\nu rdf:singletonPropertyOf v . x u y .\nx v y . (rdf-sp-3)\nThe four rdfs-sp rules are derived from the RDFS interpretation.\nu rdf:singletonPropertyOf v . v rdfs:domain x .\nu rdfs:domain x . (rdfs-sp-1)\nu rdf:singletonPropertyOf v . v rdfs:range y .\nu rdfs:range y . (rdfs-sp-2)\nu rdf:singletonPropertyOf x . x rdfs:subPropertyOf y .\nu rdf:singletonPropertyOf y . (rdfs-sp-3)\nx rdf:type rdf:GenericProperty . x rdfs:subPropertyOf y .\ny rdf:type GenericProperty . (rdfs-sp-4)\nu rdf:singletonPropertyOf x . x rdfs:subPropertyOf y .\ny rdf:type GenericProperty . (rdfs-sp-5)\nThe rule rdfs-sp-5 can easily be drived by combining the two rules rdfs-sp-3 and rdf-sp-2. Similar to the property rdfs:subPropertyOf, here we also provide the rules for the owl:equivalentOf.\nu rdf:singletonPropertyOf x . x owl:equivalentOf y .\nu rdf:singletonPropertyOf y . (owl-sp-1)\nx rdf:type GenericProperty . x owl:equivalentOf y .\ny rdf:type GenericProperty . (owl-sp-2)\nu rdf:singletonPropertyOf x . x owl:equivalentOf y .\ny rdf:type GenericProperty . (owl-sp-3)\nIf x owl:equivalentOf y then (1) x rdfs:subPropertyOf y and (2) y rdfs:subPropertyOf x.\nThe above three owl-sp rules can be derived easily by combing this rule and the rules rdfs-sp-3, rdfs-sp-4, and rdfssp-5, respectively."
    }, {
      "heading" : "4.2 Contextual Inferencing",
      "text" : "Back to the motivating example, from the contextual statement “BarackObama is married to Michelle Obama in Chicago”, we as humans can infer a list of statements (S1 to S5) as shown in Table 1. Here we demonstrate step-by-step how to infer statements S1 to S5 from the original statement.\nOur initial knowledge base includes the singleton property graph pattern representing the original contextual statement and the background knowledge as follows:\nSP1: BarackObama isMarriedTo#1 MichelleObama . SP2: isMarriedTo#1 singletonPropertyOf isMarriedTo . SP3: isMarriedTo#1 happenedIn Chicago .\nT2: isMarriedTo subPropertyOf isSpouseOf . T5: Chicago partOf Illinois . T6: Illinois partOf USA .\nAssume that we also have a partOf-rule that, if x happened in a place y which is a part of a bigger place z, then x also happened at the place z.\nx happenedIn y . y partOf z .\nx happenedIn z . (partOf-rule)\nWe start by applying the partOf-rule on the triples SP3 and T5, we obtain the triple SP4.\nSP4: isMarriedTo#1 happenedIn Illinois .\nThe singleton triple pattern including triples SP1 and SP2 derives the statement “Barack Obama is married to Michelle Obama” according to rule rdf-sp-3. Combining three triples SP1, SP2, and SP4 will derive the contextual statement S1 “Barack Obama isMarriedTo Michelle Obama in Illinois”.\nRe-applying the partOf-rule on the triples SP4 and T6, we obtain the new triple SP5.\nSP5: isMarriedTo#1 happenedIn USA .\nSimilar to S1, the combination of triples SP1, SP2, and SP5 derives the contextual statement S2 “Barack Obama isMarriedTo Michelle Obama in USA”.\nNext, if we apply the rule rdfs-sp-3 on the triples SP2 and T2, we obtain the new triple SP6.\nSP6: isMarriedTo#1 singletonPropertyOf isSpouseOf .\nApplying the rule rdf-sp-3 on the triples SP1 and SP6 derives the statement “Barack Obama isSpouseOf Michelle Obama”.\nThe combination of the triples SP1, SP6, and SP3 will derive the contextual statement S3 “Barack Obama isSpouseOf Michelle Obama in Chicago”.\nSimilarly, combining the triples SP1, SP6, and SP4 will derive the contextual statement S4 “Barack Obama isSpouseOf Michelle Obama in Illinois”.\nThe combination of SP1, SP6, and SP5 derives the contextual statement S5 “Barack Obama isSpouseOf Michelle Obama in USA”.\nTherefore, we have shown how the contextual statements S1 to S5 can be inferred in our approach."
    }, {
      "heading" : "5. IMPLEMENTATION",
      "text" : "Here we explain how we compute all inferred triples using the proposed entailment rules for existing knowledge bases in two steps. First we describe how we transform the existing knowledge bases into the singleton property representation in Section 5.1. Then Section 5.2 describes how all the proposed rules are computed for every triple in the resulting knowledge bases."
    }, {
      "heading" : "5.1 Transforming Representation",
      "text" : "As we discussed earlier in Section 1, knowledge bases like DBpedia and Bio2RDF represent the contextual information such as provenance in the form of a quad. Before computing the inferred triples for these datasets, we need to prepare the knowledge bases by transforming them to the singleton property representation.\nGiven any quad in the form of (s, p, o, g), we transform it to the singleton property representation by creating a singleton property (spi, singletonPropertyOf, p) and asserting the singleton triple (s, spi, o). We use the property wasDerivedFrom from the PROV ontology [19] to represent the provenance of the triple (spi, prov:wasDerivedFrom, g). The singleton property URIs are constructed by appending a unique string to the generic property URI, with an incremental counter for the unique number in the whole dataset.\nWe developed a Java 8 tool, called rdf-contextualizer, to transform any RDF datasets from the quad representation to the singleton property. We took advantages of the Jena RIOT API [7] with high throughput parsers for parsing an input file from any RDF format and generating a stream of RDF quads. For each quad stream, we created a pipeline of streams for converting each quad to the singleton property representation, shortening triples to Turtle format, and writing them to gzip files though buffer writers. As each stream is handled by a separate thread, we can utilize the CPU resources, especially the ones with multiple cores, by creating multiple threads for parsing multiple files concurrently.\nWe validated the syntax of the output datasets by writing an analyzer to parse the output files and also generate the statistics reported in Section 6.3."
    }, {
      "heading" : "5.2 Computing Inferred Triples",
      "text" : "Running all contextual entailment rules on every singleton triple produces at least two more triples (rdf-sp-1 and rdfsp-3). The number of inferred triples goes up to multi-billion with datasets like DBpedia and Bio2RDF. That amount of inferred triples cannot fit an in-memory reasoner such as Jena [10]. The proposed entailment rules can also be computed in the reasoners with the support for user-defined rules such as Oracle [25]. However, for the rules generating a large number of inferred triples, optimization is necessary as Oracle has optimized the computation of large number of inferred triples for owl:sameAs [18]. Without taking such optimization step in the existing engines, it is time-consuming to query the rule patterns and insert the inferred triples to the store because the insert query is always expensive. Therefore, the proposed contextual entailment rules may not be best computed in the existing engines without taking the optimization step.\nTo demonstrate that the computation of the proposed rules can be scalable with proper optimization, we implemented our engine in the tool rdf-contextualizer. Since the proposed rules can be applied to each triple independently, we can pass the triples to concurrent tasks. While transforming the RDF quads to the singleton property representation, we added an optional inferring task in the stream pipelines to compute the proposed rules for every triple. The time difference between the runs with and without the -infer option would be the run time for inferring triples added to the overall process."
    }, {
      "heading" : "6. EVALUATION",
      "text" : "We evaluate the performance of computing inferred triples from the proposed rules on a large scale by using the tool rdf-contextualizer on real-world knowledge bases."
    }, {
      "heading" : "6.1 Experiment Setup",
      "text" : "We use a single server installed with Ubuntu 12.04. It has 24 cores, each core is Intel Xeon CPU 2.60GHz. We use two disks, one SSD 220GB for storing input datasets, and one HD disk 2.7T for writing the output. This server has 256GB of RAM, however, we limit 60GB for each Java program."
    }, {
      "heading" : "6.2 Datasets",
      "text" : "We downloaded and used the ontologies and RDF quad datasets from DBpedia [6] and four Bio2RDF datasets including NCBI Genes [4], PharmGKB [5], CTD [1], and GO Annotations [2] in our evaluation. We chose these quad datasets because they are large and widely-used with high impact in the community. For Bio2RDF datasets, we also downloaded the Bio2RDF mapping files [3].\nWe reported the number of RDF quads per dataset in the first and second columns of Table 2. The dataset identifier is taken from the first 3 letters of its name.\nWe observed that there were too many duplicate quads among the files within each dataset. We also believe that the duplicates may be created on purpose. Each of these datasets has a number of files and each file contains a number of RDF quads for a topic. For example, NCBI Genes dataset has one file for all genes belonging to one species. Therefore, we keep these datasets in the original version and created a new version for each dataset with all duplicates being removed. We removed the duplicates by 1) concatenating all files into a single file, 2) splitting this file into multiple smaller files, 3) sorting each small file, and 4) merging all the sorted files into a single file. The third column of Table 2 shows the number of unique quads per dataset after removing the duplicates.\nWe then generated the singleton property version of each dataset by running the tool rdf-contextualizer with and without the -infer option. We ran each dataset version at least 3 times and reported the average results in Section 6.3.\nThe tool rdf-contextualizer and the materials used in this paper are publicly available for reproducing the experiments1."
    }, {
      "heading" : "6.3 Results",
      "text" : "We consider four dimensions in our evaluation: number of triples, number of singleton triples, run time, and disk\n1https://archive.org/services/purl/ rdf-contextualizer\nspace. In all figures, the series Reasoning stands for running the tool with -infer option and No-Reasoning stands for running the tool without -infer option. Running the NoReasoning option provides the results as the baseline cost. The differences in the results between the NoReasoning and Reasoning versions are the extra cost estimated for the computation of the inferred triples. We run the tool on two versions of datasets. The series with Dup denotes the datasets with duplicate quads and the series with Unique denotes the datasets with all duplicates being removed.\nCombining the two options: with vs. without -infer and with vs. without removing duplicates, each evaluating dimension has four cases: Reasoning-Dup, Reasoning-Unique, NoReasoning-Dup, and NoReasoning-Unique.\n6.3.1 Number of Inferred Triples Figure 1 shows the total number of triples of each dataset\nin four cases. In general, the Reasoning cases contain larger number of triples than the NoReasoning cases, from 66.7% to 96.67%. For example, the Reasoning-Dup version of\nNCBI genes, the largest dataset, contains about 8 billion inferred triples (66.67%) more than the NoReasoning-Dup version. Similarly, the Reasoning-Unique version of NCBI genes contains about 4 billion inferred triples more than the NoReasoning-Unique version. Some other datasets have their number of inferred triples higher than 66.67%. For example, the Reasoning-Unique version of CTD contains about 950 million inferred triples (96.67%) more than the NoReasoning-Unique version.\nBetween the Dup and Unique versions, the Reasoning-Dup versions contain 50% (NCBI Genes), 32% ( DBpedia), 86% (CTD), 35% (PharmGKB) and 63% (GOA) more triples than the corresponding Reasoning-Unique versions.\n6.3.2 Number of Inferred Singleton Triples Resulted from the inference rules involving property hi-\nerarchy in the schema, the number of inferred singleton triples varies across datasets as shown in Figure 2 since they have different schema. For example, since NCBI Genes dataset does not have property hierarchy, the number of singleton triples remains the same in both version Reasoning\nand NoReasoning. Meanwhile, CTD dataset inferred 194 million singleton triples (30%) for the Reasoning-Dup version and 148 million singleton properties (45%) for the Reasoning-Unique version.\n6.3.3 Disk Space Generally speaking, for every RDF quad, we generated 3\ntriples for NoReasoning version and at least 5 triples for the Reasoning version. That makes the overall number of triples of each SP dataset increase up to 3-5 times compared to the number of quads of the corresponding named graph dataset. Consequently, the disk size of one SP dataset could be 3-5 times more than the disk size of its corresponding named graph dataset. This is the case in which the triples of SP datasets being serialized into the N-Triple format. For very large datasets like DBpedia and NCBI Genes, we do not recommend this N-Triple serialization since the unzipped files may require disks with tetrabyte capacity.\nRDF Turtle format is more compact than the N-Triple format, especially with very large datasets. Since our approach enables data to be represented in the RDF triple\nform, we chose the Turtle format to serialize the triples to files. It allows us to arrange the triple order so that we can shorten the strings of triples sharing subject, or subject and predicate. For shortening the URIs in the Turtle format, we compiled a list of prefixes used in these datasets. Thanks to this compact representation, comparing to the NoReasoning-Dup version, the Reasoning-Dup version only adds 15-25% more space for 66.7-96.97% more number of triples (Figure 3).\n6.3.4 Run Time Figure 4 shows the run time execution for all four cases\nof each dataset. GO Annotations dataset, took 11 minutes for 480 million triples of NoReasoning-Dup version and 13 minutes for 796 million triples of Reasoning-Dup version. In other words, it added 2 minutes to the overall process to infer 316 million triples. NCBI Genes, the largest dataset, took 232 minutes for 12 billion triples of NoReasoning-Dup version and 274 minutes for 20 billion triples of Reasoning-Dup version. In terms of percentage, the Reasoning-Dup versions of these datasets add 14-19% run time for inferring 66.7-96.67%\nof the total number of triples in the NoReasoning-Dup versions. This shows that the inferencing time is quite small and practical.\nWe plot the size of the datasets and the time execution in the same chart to show the correlation between them. Figure 5 shows that when the size of the datasets increases, the time execution for both Reasoning and NoReasoning case also increases almost linearly to the size of the dataset. This figure also shows that for the same number of triples, the Reasoning versions take shorter run time than the NoReasoning versions. This is reasonable because for generating the same amount of triples, the time it takes for the NoReasoning versions to parse content from files and serialize the output to files is longer than the time it does for the Reasoning version to infer the triples. Figure 6 plots the time execution and the number of inferred triples. It also shows the run time is linear to the number of inferred triples.\nThese results are consistent with our Java stream-based implementation. Since each triple can be processed independently, a set of triples can be passed to multiple streams for concurrent processing instead of sequential processing. Multi-core CPUs are also utilized for processing multiple files concurrently.\n6.3.5 Overall Remarks Between the Reasoning and NoReasoning versions, the re-\nsults show that the numbers of triples of the Reasoning versions are higher than the number of triples in the NoReasoning versions from 66.7% to 96.67%. In terms of number of inferred singleton triples, the Reasoning versions produce up to 45% of the number of singleton triples in the NoReasoning version. In terms of disk space, the Reasoning versions require 15-25% of disk space of the NoReasoning version. Last but not least, the Reasoning versions added 14-19% run time to the overall process.\nBetween the Dup and Unique versions, the results show that the number of triples, number of singleton triples, the disk space, and the run time reduce significantly (up to 50%) in the Unique versions."
    }, {
      "heading" : "7. RELATED WORK",
      "text" : "Representing and querying contextual information about triples has received significant attention, and several approaches have been proposed. We can classify these approaches into three categories: triple (reification, singleton property), quadruple (named graph), and quintuple (RDF+ [24]). However, logical inferences with contextual information about triples remain largely underdeveloped due to the lack of a model-theoretic semantics that would determine entailment rules. Without such a model-theoretic semantics, we can make up some rules using the syntax of RDF reification to simulate our proposed rules. Nevertheless, these syntactical rules are not logically valid since they are neither logically derived from nor proven in a model-theoretic semantics. Therefore, we chose the singleton property approach over other approaches to develop the proposed inferencing mechanism mainly because it comes with a formal semantics. To the best of our knowledge, our proposal is the first one to provide the model-theoretic semantics with entailment rules that enables the entailment of new contextual triples about triples.\nThe stream reasoning [21] where the temporal dimension is not represented directly in RDF may benefit from our work as it allows the temporal dimension to be incorporated within the RDF syntax. The temporal RDF [13] incorporates temporal reasoning into RDF using reification. This temporal RDF may take advantages of singleton property semantics as temporal information can be incorporated into RDF through singleton properties instead of reification."
    }, {
      "heading" : "8. DISCUSSION AND FUTURE WORK",
      "text" : "Applications. We have implemented and evaluated the proposed rules with the forward-chaining inferences in this paper. The backward chaining inferences with the proposed rules can be implemented in the reasoners. They can also be implemented in the triple stores for answering SPARQL queries based on the triples inferred from the proposed rules. We also believe that the proposed inference mechanism will benefit several applications, such as streaming reasoning, temporal reasoning, tracking context of inferred triples, and question answering based on extracted knowledge and logical inferences.\nPerformance. Performance is the real challenge for Semantic Web reasoning in general, and also for the proposed inferencing mechanism, especially on the Web scale. Inferred triples can be computed by SPARQL INSERT query\nto find the rule patterns and insert the matching triples to triple stores. However, this approach is not scalable as insert query is costly. Computing the inferred triples on a large scale requires the reasoners to be optimized. Since the singleton pattern is fixed, it can be indexed for faster retrieval. Furthermore, our evaluation shows that parallelizing the computation such as using the stream-based pipelines would also improve the performance for existing reasoners.\nOWL 2. We have studied RDF-based semantics of the OWL 2 Full and obtained initial results on its compability with the semantics we proposed here because they are based on the model theory. We believe that the contextual inferences can also be applicable to OWL 2 DL and OWL 2 direct semantics. However, we need to extend the semantics of these OWL 2 profiles with new semantic constructs in order to accomodate the proposed conceptual model.\nFormal studies. Incorporating these contextual information into RDF triples would enable several logics such as temporal reasoning, geological reasoning, and provenance reasoning to be studied and applied in these knowledge bases. Logical reasoning tasks such as consistency checking, classification, subsumption, or deriving new knowledge would allow more intelligent systems to be developed, especially on the Web scale."
    }, {
      "heading" : "9. CONCLUSION",
      "text" : "We have presented our inferencing mechanism that allows contextual statements, in the form of RDF contextual triples about triples, to be reasoned with. Our proposed mechanism is theoretically sound and computationally scalable. Our model-theoretic semantics represents the contextual statements as first-class citizens and enables them to be inferred with the proposed entailment rules. We also demonstrated the feasibility and scalability of computing inferred triples using the proposed entailment rules in various real-world knowledge bases."
    }, {
      "heading" : "10. REFERENCES",
      "text" : "[1] Bio2rdf ctd release 3.\nhttp://download.bio2rdf.org/release/3/ctd/.\n[2] Bio2rdf goa release 3. http://download.bio2rdf.org/release/3/goa/.\n[3] Bio2rdf mappings. https://github.com/bio2rdf/bio2rdf-mapping.\n[4] Bio2rdf ncbi genes release 3. http: //download.bio2rdf.org/release/3/ncbigene/.\n[5] Bio2rdf pharmgkb release 3. http: //download.bio2rdf.org/release/3/pharmgkb/.\n[6] Dbpedia version 2015-10. http://wiki.dbpedia.org/Downloads2015-10.\n[7] Jena riot api. https://jena.apache.org/documentation/io/.\n[8] F. Belleau, M. Nolin, N. Tourigny, P. Rigault, and J. Morissette. Bio2rdf: towards a mashup to build bioinformatics knowledge systems. Journal of biomedical informatics, 41(5):706–716, 2008.\n[9] J. J. Carroll, C. Bizer, P. Hayes, and P. Stickler. Named graphs. Web Semantics: Science, Services and Agents on the World Wide Web, 3(4):247–267, 2005.\n[10] J. J. Carroll, I. Dickinson, C. Dollin, D. Reynolds, A. Seaborne, and K. Wilkinson. Jena: implementing the semantic web recommendations. In Proceedings of\nthe 13th international World Wide Web conference on Alternate track papers & posters, pages 74–83. ACM, 2004.\n[11] X. Dong, E. Gabrilovich, G. Heitz, W. Horn, N. Lao, K. Murphy, T. Strohmann, S. Sun, and W. Zhang. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 601–610. ACM, 2014.\n[12] G. Fu, E. Bolton, N. Queralt-Rosinach, L. I. Furlong, V. Nguyen, A. P. Sheth, O. Bodenreider, and M. Dumontier. Exposing provenance metadata using different RDF models. In Proceedings of the 8th SWAT4LS, pages 167–176, 2015.\n[13] C. Gutierrez, C. Hurtado, and A. Vaisman. Temporal rdf. In The Semantic Web: Research and Applications, pages 93–107. Springer, 2005.\n[14] P. Hayes and B. McBride. Rdf semantics, 2004.\n[15] P. Hayes and P. Patel-Schneider. Rdf 1.1 semantics. W3C Recommendation, 2014.\n[16] P. Hitzler, M. Krotzsch, and S. Rudolph. Foundations of semantic web technologies. Chapman and Hall/CRC, 2011.\n[17] J. Hoffart, F. M. Suchanek, K. Berberich, and G. Weikum. Yago2: A spatially and temporally enhanced knowledge base from wikipedia. Artificial Intelligence, 194:28–61, 2013.\n[18] V. Kolovski, Z. Wu, and G. Eadon. Optimizing enterprise-scale owl 2 rl reasoning in a relational database system. In International Semantic Web Conference, pages 436–452. Springer, 2010.\n[19] T. Lebo, S. Sahoo, and D. McGuinness. Prov-o: The prov ontology. W3C. http://www. w3. org/TR/prov-o, 2012.\n[20] J. Lehmann, R. Isele, M. Jakob, A. Jentzsch, D. Kontokostas, P. N. Mendes, S. Hellmann, M. Morsey, P. van Kleef, S. Auer, et al. Dbpedia–a large-scale, multilingual knowledge base extracted from wikipedia. Semantic Web, 6(2):167–195, 2015.\n[21] T. N. Nguyen and W. Siberski. Slubm: An extended lubm benchmark for stream reasoning. In OrdRing@ ISWC, pages 43–54, 2013.\n[22] V. Nguyen, O. Bodenreider, and A. Sheth. Don’t like rdf reification?: Making statements about statements using singleton property. In Proceedings of the 23rd International Conference on World Wide Web, WWW ’14, pages 759–770, 2014.\n[23] M. Schneider, J. Carroll, I. Herman, and P. F. Patel-Schneider. Owl 2 web ontology language: Rdf-based semantics (second edition). W3C Recommendation (December 11 2012), 2012.\n[24] B. Schueler, S. Sizov, S. Staab, and D. T. Tran. Querying for meta knowledge. In Proceedings of the 17th World Wide Web Conference, pages 625–634. ACM, 2008.\n[25] Z. Wu, G. Eadon, S. Das, E. I. Chong, V. Kolovski, M. Annamalai, and J. Srinivasan. Implementing an inference engine for rdfs/owl constructs and user-defined rules in oracle. In Data Engineering, 2008. ICDE 2008. IEEE 24th International Conference on, pages 1239–1248. IEEE, 2008."
    } ],
    "references" : [ {
      "title" : "Bio2rdf: towards a mashup to build bioinformatics knowledge systems",
      "author" : [ "F. Belleau", "M. Nolin", "N. Tourigny", "P. Rigault", "J. Morissette" ],
      "venue" : "Journal of biomedical informatics,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "Named graphs. Web Semantics: Science, Services and Agents on the World",
      "author" : [ "J.J. Carroll", "C. Bizer", "P. Hayes", "P. Stickler" ],
      "venue" : "Wide Web,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2005
    }, {
      "title" : "Jena: implementing the semantic web recommendations",
      "author" : [ "J.J. Carroll", "I. Dickinson", "C. Dollin", "D. Reynolds", "A. Seaborne", "K. Wilkinson" ],
      "venue" : "In Proceedings of  the 13th international World Wide Web conference on Alternate track papers & posters,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2004
    }, {
      "title" : "Knowledge vault: A web-scale approach to probabilistic knowledge fusion",
      "author" : [ "X. Dong", "E. Gabrilovich", "G. Heitz", "W. Horn", "N. Lao", "K. Murphy", "T. Strohmann", "S. Sun", "W. Zhang" ],
      "venue" : "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "Exposing provenance metadata using different RDF models",
      "author" : [ "G. Fu", "E. Bolton", "N. Queralt-Rosinach", "L.I. Furlong", "V. Nguyen", "A.P. Sheth", "O. Bodenreider", "M. Dumontier" ],
      "venue" : "In Proceedings of the 8th SWAT4LS,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Temporal rdf",
      "author" : [ "C. Gutierrez", "C. Hurtado", "A. Vaisman" ],
      "venue" : "In The Semantic Web: Research and Applications,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2005
    }, {
      "title" : "Foundations of semantic web technologies",
      "author" : [ "P. Hitzler", "M. Krotzsch", "S. Rudolph" ],
      "venue" : "Chapman and Hall/CRC,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2011
    }, {
      "title" : "Yago2: A spatially and temporally enhanced knowledge base from wikipedia",
      "author" : [ "J. Hoffart", "F.M. Suchanek", "K. Berberich", "G. Weikum" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2013
    }, {
      "title" : "Optimizing enterprise-scale owl 2 rl reasoning in a relational database system",
      "author" : [ "V. Kolovski", "Z. Wu", "G. Eadon" ],
      "venue" : "In International Semantic Web Conference,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2010
    }, {
      "title" : "Prov-o: The prov ontology",
      "author" : [ "T. Lebo", "S. Sahoo", "D. McGuinness" ],
      "venue" : "W3C. http://www. w3. org/TR/prov-o,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2012
    }, {
      "title" : "Dbpedia–a large-scale, multilingual knowledge base extracted from wikipedia",
      "author" : [ "J. Lehmann", "R. Isele", "M. Jakob", "A. Jentzsch", "D. Kontokostas", "P.N. Mendes", "S. Hellmann", "M. Morsey", "P. van Kleef", "S. Auer" ],
      "venue" : "Semantic Web,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2015
    }, {
      "title" : "Slubm: An extended lubm benchmark for stream reasoning",
      "author" : [ "T.N. Nguyen", "W. Siberski" ],
      "venue" : "In OrdRing@ ISWC,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2013
    }, {
      "title" : "Don’t like rdf reification?: Making statements about statements using singleton property",
      "author" : [ "V. Nguyen", "O. Bodenreider", "A. Sheth" ],
      "venue" : "In Proceedings of the 23rd International Conference on World Wide Web,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2014
    }, {
      "title" : "Owl 2 web ontology language: Rdf-based semantics (second edition)",
      "author" : [ "M. Schneider", "J. Carroll", "I. Herman", "P.F. Patel-Schneider" ],
      "venue" : "W3C Recommendation (December",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2012
    }, {
      "title" : "Querying for meta knowledge",
      "author" : [ "B. Schueler", "S. Sizov", "S. Staab", "D.T. Tran" ],
      "venue" : "In Proceedings of the 17th World Wide Web Conference,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2008
    }, {
      "title" : "Implementing an inference engine for rdfs/owl constructs and user-defined rules in oracle",
      "author" : [ "Z. Wu", "G. Eadon", "S. Das", "E.I. Chong", "V. Kolovski", "M. Annamalai", "J. Srinivasan" ],
      "venue" : "In Data Engineering,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : ", Bio2RDF [8] and PubChem [12]).",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 4,
      "context" : ", Bio2RDF [8] and PubChem [12]).",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 3,
      "context" : ", Google Knowledge Vault [11], Yago2S [17], and DBpedia [20]).",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 7,
      "context" : ", Google Knowledge Vault [11], Yago2S [17], and DBpedia [20]).",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 10,
      "context" : ", Google Knowledge Vault [11], Yago2S [17], and DBpedia [20]).",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 1,
      "context" : "To bridge this gap and fulfill the requirement of representing contextual statements in machine-understandable form as discussed earlier, several approaches such as named graph [9], RDF reification [14], and singleton property [22] can be used for representing the relationship between a triple and its identifier.",
      "startOffset" : 177,
      "endOffset" : 180
    }, {
      "referenceID" : 12,
      "context" : "To bridge this gap and fulfill the requirement of representing contextual statements in machine-understandable form as discussed earlier, several approaches such as named graph [9], RDF reification [14], and singleton property [22] can be used for representing the relationship between a triple and its identifier.",
      "startOffset" : 227,
      "endOffset" : 231
    }, {
      "referenceID" : 12,
      "context" : "Here we recall the singleton property concept with its syntax and semantics from [22].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 12,
      "context" : "Here we propose to add the new class GenericProperty to represent the set of generic properties, in addition to the class SingletonProperty from [22].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 6,
      "context" : "We specify three interpretations: simple, RDF and RDFS by extending the model-theoretic semantics described in [16, 22].",
      "startOffset" : 111,
      "endOffset" : 119
    }, {
      "referenceID" : 12,
      "context" : "We specify three interpretations: simple, RDF and RDFS by extending the model-theoretic semantics described in [16, 22].",
      "startOffset" : 111,
      "endOffset" : 119
    }, {
      "referenceID" : 6,
      "context" : "While we explain the new vocabulary elements in detail, elements without further explanation remain as they are in the original model-theoretic semantics described in [16, 22].",
      "startOffset" : 167,
      "endOffset" : 175
    }, {
      "referenceID" : 12,
      "context" : "While we explain the new vocabulary elements in detail, elements without further explanation remain as they are in the original model-theoretic semantics described in [16, 22].",
      "startOffset" : 167,
      "endOffset" : 175
    }, {
      "referenceID" : 13,
      "context" : "From the RDF-based semantics of OWL 2 Full [23], we consider the semantic conditions of the OWL classes and properties that are relevant to singleton properties.",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 13,
      "context" : "OWL 2 RDF-based interpretation of a vocabulary V is an RDFS interpretation I of the vocabulary V ∪ VOWL that satisfies criteria from the OWL interpretation [23] and the following semantic conditions:",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 9,
      "context" : "We use the property wasDerivedFrom from the PROV ontology [19] to represent the provenance of the triple (spi, prov:wasDerivedFrom, g).",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 2,
      "context" : "That amount of inferred triples cannot fit an in-memory reasoner such as Jena [10].",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 15,
      "context" : "The proposed entailment rules can also be computed in the reasoners with the support for user-defined rules such as Oracle [25].",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 8,
      "context" : "However, for the rules generating a large number of inferred triples, optimization is necessary as Oracle has optimized the computation of large number of inferred triples for owl:sameAs [18].",
      "startOffset" : 187,
      "endOffset" : 191
    }, {
      "referenceID" : 14,
      "context" : "We can classify these approaches into three categories: triple (reification, singleton property), quadruple (named graph), and quintuple (RDF+ [24]).",
      "startOffset" : 143,
      "endOffset" : 147
    }, {
      "referenceID" : 11,
      "context" : "The stream reasoning [21] where the temporal dimension is not represented directly in RDF may benefit from our work as it allows the temporal dimension to be incorporated within the RDF syntax.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 5,
      "context" : "The temporal RDF [13] incorporates temporal reasoning into RDF using reification.",
      "startOffset" : 17,
      "endOffset" : 21
    } ],
    "year" : 2017,
    "abstractText" : "Logical inference, an integral feature of the Semantic Web, is the process of deriving new triples by applying entailment rules on knowledge bases. The entailment rules are determined by the model-theoretic semantics. Incorporating context of an RDF triple (e.g., provenance, time, and location) into the inferencing process requires the formal semantics to be capable of describing the context of RDF triples also in the form of triples, or in other words, RDF contextual triples about triples. The formal semantics should also provide the rules that could entail new contextual triples about triples. In this paper, we propose the first inferencing mechanism that allows context of RDF triples, represented in the form of RDF triples about triples, to be the first-class citizens in the model-theoretic semantics and in the logical rules. Our inference mechanism is well-formalized with all new concepts being captured in the model-theoretic semantics. This formal semantics also allows us to derive a new set of entailment rules that could entail new contextual triples about triples. To demonstrate the feasibility and the scalability of the proposed mechanism, we implement a new tool in which we transform the existing knowledge bases to our representation of RDF triples about triples and provide the option for this tool to compute the inferred triples for the proposed rules. We evaluate the computation of the proposed rules on a large scale using various real-world knowledge bases such as Bio2RDF NCBI Genes and DBpedia. The results show that the computation of the inferred triples can be highly scalable. On average, one billion inferred triples adds 5-6 minutes to the overall transformation process. NCBI Genes, with 20 billion triples in total, took only 232 minutes for the transformation of 12 billion triples and added 42 minutes for inferring 8 billion triples to the overall process.",
    "creator" : "LaTeX with hyperref package"
  }
}