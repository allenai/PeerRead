{
  "name" : "1206.6841.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Asymmetric Separation for Local Independence Graphs",
    "authors" : [ "Vanessa Didelez" ],
    "emails" : [ "vanessa@stats.ucl.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Directed possibly cyclic graphs have been proposed by Didelez (2000) and Nodelmann et al. (2002) in order to represent the dynamic dependencies among stochastic processes. These dependencies are based on a generalization of Granger–causality to continuous time, first developed by Schweder (1970) for Markov processes, who called them local dependencies. They deserve special attention as they are asymmetric. In this paper we focus on their graphical representation and develop an asymmetric notion of separation. The properties of this graph separation as well as local independence are investigated in detail within a framework of asymmetric (semi)graphoids allowing insight into what information can be read off these graphs."
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "Classical graphical models and Bayesian networks represent (conditional) independence between random variables. They can be adapted to variables observed in discrete or discretized time, like e.g. time series or dynamic Bayesian networks. This does not, however, capture the intuitive notion of dynamic dependence between processes, which is asymmetric, and we therefore propose an alternative.\nPut informally, we are interested in the following kind of dynamic (conditional) independencies among stochastic processes X(t), Y (t) and Z(t):\npresent of X⊥⊥past of Y | past of (X, Z),\nwhich will be denoted by Y →/ X|Z, or more formally\nX(t)⊥⊥FYt− | FX,Zt− ,\nwhere Ft− is the history of a process. Such independence underlies the notion of Granger non–causality for time series (Granger, 1969), which has been used as the basis for a graphical representation by Eichler (2002). It also underlies the continuous–time notion of local independence given by Schweder (1970) for Markov processes, and its bivariate version for general continuous–time processes by Aalen (1987) with a multivariate version in Didelez (2000, pp.65). A special case of Schweder’s concept are the dependencies represented in the continuous time Bayesian networks developed by Nodelman et al. (2002) for homogenous Markov processes. Cyclic graphs have also been proposed to represent non–recursive structural equation models or feedback processes (Sprites, 1995; Pearl and Dechter, 1996), but with the above notion of dependence between past and present we explicitly consider processes instead of cross sectional measurements of variables in equilibrium.\nConsider the following example illustrating the idea of local dependence and its graphical representation. In some countries programs exist to assist the elderly, e.g. through regular visits by nurses. Assume that these visits reduce the frequency of hospitalizations but do not in any other way affect future survival (this could be the null hypothesis). Assume further that the frequency of visits is intensified when a person has previously been hospitalized. Also assume that the general health status affects the rate of future hospitalization and the survival but not the frequency of future visits. The proposed graphical representation of these assumptions is given in Figure 1.\nThe outline of the paper is as follows. We first review, in Section 2, the notion of local independence for Markov processes and its generalization to multi– state processes. A graphical representation as well as a suitable asymmetric separation are proposed in Section 3. The properties of local independence and the corresponding graphical representation are investigated in Section 4 within the framework of asymmetric graphoids."
    }, {
      "heading" : "2 LOCAL INDEPENDENCE",
      "text" : ""
    }, {
      "heading" : "2.1 MARKOV PROCESSES",
      "text" : "We consider a first order Markov process Y(t), t ∈ T , with a finite state space S and with transition intensities αqr(t), q 6= r ∈ S, which are assumed to exist. The Markov process Y is assumed to consist of components in the following sense (Schweder, 1970).\nDefinition 2.1 Composable Markov process Let V = {1, . . . ,K}, K ≥ 2, and assume that there are K spaces Sk, k ∈ V , with |Sk| ≥ 2, and that there exists a one-to-one mapping f of S onto ⊗k∈V Sk so that elements y ∈ S can be identified with elements (y1, . . . , yK) ∈ ⊗ k∈V Sk. Then, a Markov process Y is a composable process with components Y1, . . . , YK given by f(Y(t)) = (Y1(t), . . . , YK(t)) if for all A ⊂ V , |A| ≥ 2,\nlim h↓0 1 h P\n( ⋂\nk∈A {Yk(t + h) 6= yk}\n∣∣∣∣∣ ⋂\nk∈A {Yk(t) = yk}\n) = 0\nfor all yk ∈ Sk, k ∈ V , and t ∈ T . We then write Y ∼ (Y1, . . . , YK).\nThe definition implies that for a composable process the probability that more than one component changes in a short period of length h is of magnitude o(h). Hence, any change of state can be represented as a change in only one of the components which justifies regarding the processes as composed of different components. The components are not necessarily unique. If for example Y ∼ (Y1, . . . , YK) then Y ∼ (YA,YB) with A ⊂ V and B = V \\A. Note that the components of such a Markov process correspond to the local variables of Nodelman et al. (2002).\nFrom now, we consider composable finite Markov processes (CFMPs) and write α(t; (y,y′)) instead of αyy′(t) for notational convenience. Schweder (1970) proves the following.\nCorollary 2.2 Transition intensities for CFMPs Let Y ∼ (Y1, . . . , YK) be a CFMP. The intensity\nα(t; (y,y′)) for any y 6= y′ ∈ S is given by α(t; (y,y′)) = {\nαk(t; (y, y′k)), yk 6= y′k ∧ y−k = y′−k 0, else,\nwhere y−k = yV \\{k}, and\nαk(t; (y, y′k)) = lim h↓0 1 h P (Yk(t + h) = y′k | Y(t) = y) .\nThe dependence structure of (Y1, . . . , YK) is thus determined by the quantities αk(t; (y, y′k)),y ∈ S, y′k ∈ Sk\\{yk}, k ∈ V .\nDefinition 2.3 Local independence in a CFMP Let Y ∼ (Y1, . . . , YK) be a CFMP. Then, Yj is locally independent of Yk, k 6= j, if and only if αj(t; (y, y′j)) is constant in the k-th component yk of the first argument ∀ y−k ∈ S−k and y′j ∈ Sj , y′j 6= yj , for all t ∈ T . We denote this by {k} →/ {j}|V \\{j, k}. For disjoint subsets A,B,C of V we say that B →/ A|C if for all j ∈ A the transition intensities αj(t; (y, y′j)) are constant in all the components yB of y for any yA∪C ∈ SA∪C and y′j ∈ Sj , y′j 6= yj , written as B →/ A|C.\nSince for small h > 0\nP ( Yj(t + h) = y′j | Y(t) = y ) ≈ h · αj(t; (y, y′j)) one can roughly say that {k} →/ {j}|V \\{j, k} means Yj(t + h) is conditionally independent of Yk(t) given Y−k(t) for small h, hence local independence.\nA straightforward graphical representation of local dependence structures is to depict components Yk by nodes and local dependencies by directed edges. We can then summarize the transition intensities as αk(t; (ycl(k), y ′ k)), where cl(k) is the closure of node k, i.e. its parents and itself. In the terminology of Nodelman et al. (2002), a component Yk can be regarded as a conditional Markov process, the transition intensities of which depend on the states of Ypa(k) and can be represented in a collection of conditional transition matrices for the transitions yk → y′k, yk 6= y′k ∈ Sk, one matrix for each value of ypa(k) ∈ Spa(k). In the above we assume that a component is always locally dependent on its own past so that this is not explicitly stated in the conditioning set when writing {k} →/ {j}|V \\{j, k} or in the parent set in the corresponding graph. For practical applications it seems unlikely that a component is locally independent of itself, but such processes can of course be constructed. If we wanted to allow this, the graphs would need to be extended to include self–loops (j, j), j ∈ V , and there would be a difference between {k} →/ {j}|V \\{j, k} and {k} →/ {j}|V \\{k}. But we do not pursue this any further here."
    }, {
      "heading" : "2.2 MULTI–STATE PROCESSES",
      "text" : "Marginally, a subprocess YA, A ⊂ V , of a CFMP is not necessarily Markov anymore unless pa(A) = ∅ (Didelez, 2005b). Hence it is useful to generalize the notion of local independence to a larger class of processes like multi–state processes that are not necessarily Markov (cf. Didelez, 2005a).\nLet Y denote a multi–state process with a one–to–one mapping of its state space S onto ⊗Sk yielding the components Y1, . . . , YK similar to Definition 2.1. Let further FAt , A ⊂ V , denote the filtration generated by the subprocess YA, i.e. FAt = σ{YA(s), s ≤ t}. Then we assume that for each component Yk there exists a process Λk such that Mk = Yk − Λk is a FVt – martingale, i.e.\nYk = Λk + Mk. (1)\nProperty (1) is the Doob–Meyer decomposition (cf. Andersen et al., 1993) and is similar to a regression model, where Λk(t) is the predictor based on the past FVt− of this and all other components (formally this means that Λk(t) is a FVt –predictable compensator), and Mt corresponds to a zero–mean error term (conditionally on the past). Further, the martingales Mk, k = 1, . . . , K, are assumed to be orthogonal, which can be regarded as a dynamic version of an ‘independent errors’ assumption. It also ensures that no two components ‘jump’ at the same time in analogy to Definition 2.1.\nFor a Markov process the predictor Λk(t) can be constructed from the transition intensities and suitable indicator functions for the state of a process just before the transition. If it is absolutely continuous then its derivative λk(t) is called the intensity process. E.g. for a Markov process Y , and considering one particular transition q → r, we have λqr(t) = αqr(t)I{Y (t−)=q}, q 6= r ∈ S, and Λqr(t) = ∫ t 0 λqr(s)ds.\nUnder mild regularity conditions the assumptions allowing (1) are also satisfied by multivariate counting processes and hence by (not necessarily Markovian) multi–state processes, where each change of state can be represented as a jump in a multivariate counting process (cf. Andersen et al., 1993). This leads to the following more general definition of local independence.\nDefinition 2.4 Local independence Let Y ∼ (Y1, . . . , YK) satisfy the above assumptions. Then, Yj is locally independent of Yk, k 6= j, if and only if Λj(t) is F−kt –measurable for all t ∈ T . In words this means that the predictor Λj does not depend on the past history of the component Yk given the whole past of all other components."
    }, {
      "heading" : "3 GRAPHICAL REPRESENTATION",
      "text" : "We now formally define the graphs representing local independence structures.\nDefinition 3.1 Local independence graph Let YV ∼ (Y1, . . . , YK) be a composable process satisfying the assumptions of Section 2.2 and let G = (V, E) be a directed graph, where V = {1, . . . , K} and E ⊂ {(j, k)|j, k ∈ V, j 6= k}. Then G is the local independence graph of YV if for all j, k ∈ V\n(j, k) /∈ E ⇔ {j} →/ {k} | V \\{j, k}. (2)\nWe can regard (2) as a dynamic version of the pairwise Markov property (Lauritzen, 1996) and hence call it the pairwise dynamic Markov property.\nIn the special case of YV being a homogenous Markov process its local independence graph is the same as a continuous time Bayesian network (Nodelman et al., 2002).\nA local independence graph is directed but not necessarily acyclic. Furthermore, it allows two edges between two vertices, one in each direction. The notation familiar for DAGs can still be applied, such as parents, ancestors, non–descendants. In particular we will need the notion of an ancestral set An(A) = an(A) ∪ A. Also, the operation of moralizing a graph can be carried out as usual, by marrying parents of a common child and then making the whole graph undirected, i.e. Gm = (V, Em) with Em = {{j, k}| (j, k) ∈ E or (k, j) ∈ E} ∪ {{j, k}|∃ υ ∈ V : j, k ∈pa(υ)}. In Gm we can check for usual separation in undirected graphs and will denote this by the symbol ⊥⊥u . In Section 2.1 we said that the transition intensities can be summarized as αk(t; (ycl(k), y ′ k)). In the general case this corresponds to the following property.\nDefinition 3.2 Local dynamic Markov property Let G = (V, E) be a directed graph. For a multivariate process YV the property\n∀ k ∈ V : V \\cl(k) →/ {k} | pa(k), (3) is called the local dynamic Markov property w.r.t. G.\nIn general (2) does not imply (3), e.g. if two components, k, l say, contain the same information we might have that {k} →/ {j}|{l} as well as {l} →/ {j}|{k} without {k, l} →/ {j}. However under additional conditions, such as the one of orthogonal martingales, we can show that in our setting the implication holds, because counting processes that are almost sure identical do not have orthogonal martingales (Andersen et al., 1993, p.73). The precise condition for the implication (2) ⇒ (3) is given by (9) below.\nIn order to formulate a global dynamic Markov property we need a suitable notion of separation.\nDefinition 3.3 δ–separation Let G = (V, E) be a directed graph. For B ⊂ V , let GB denote the graph given by deleting all directed edges of G starting in B, i.e. GB = (V,EB) with EB = E\\{(j, k)|j ∈ B, k ∈ V }. Then, we say for pairwise disjoint subsets A,B,C ⊂ V that C δ–separates A from B in G if A⊥⊥u B|C in the undirected graph (GBAn(A∪B∪C))\nm. In case that A,B and C are not disjoint we define that C δ–separates A from B if C\\B δ–separates A\\(B∪C) from B. The empty set is always separated from B. Additionally, we define that the empty set δ–separates A from B if A and B are unconnected in (GBAn(A∪B)) m.\nNote that deleting edges out of B does not change An(A∪B ∪C) so that GBAn(A∪B∪C) is not ambiguous. Equivalently to Definition 3.3 we can use a trail condition, where a trail is a sequence of not necessarily direction preserving edges connecting two nodes. Define that any allowed trail from A to B contains no edge of the form (b, k), b ∈ B, k ∈ V \\B. Then, for disjoint subsets A,B,C of V , we have that C δ–separates A from B if and only if all allowed trails from A to B are d–separated by C (Didelez, 2000, pp.22).\nAs mentioned above, δ–separation is not symmetric in A and B. This can be seen in the simple graph given in Figure 2(a). From the moral graphs in Figures 2(b) and (c) we see that a⊥⊥u b|c in (Ga)m but not in (Gb)m. Alternatively, there are two trails between a and b: {(a, b)} and {(c, a), (b, c)}. Consider separating b from a, then the first trail is not allowed and the second is d–separated by c since the directed edges do not meet head–to–head in c. In contrast, if we want to separate a from b, the second path is not allowed and the first is not d–separated by c. Hence c δ–separates b from a but not a from b.\nThe significance of δ–separation is due to the following global dynamic Markov property.\nDefinition 3.4 Global dynamic Markov property Let YV ∼ (Y1, . . . , YK) be a composable process and G = (V, E) a directed graph. For disjoint subsets\nA,B, C ⊂ V the property\nC δ–separates A from B in G ⇒ A →/ B | C. (4)\nis called the global dynamic Markov property w.r.t. G.\nTo understand why δ–separation works, consider again the above example, Figure 2(a). For a Markov process and small h > 0 this corresponds to the infinitesimal conditional independencies in Figure 3. Checking, e.g. whether c δ–separates b from a corresponds to Ya(t + h)⊥⊥Yb(t)|(Ya(t), Yc(t)), which can be verified in Figure 3. Whereas c δ–separating a from b would mean to Ya(t)⊥⊥Yb(t + h)|(Yb(t), Yc(t)), which is clearly not the case."
    }, {
      "heading" : "4 ASYMMETRIC GRAPHOIDS",
      "text" : "The (semi)graphoid axioms first introduced by Dawid (1979) (cf. also Pearl and Paz, 1987; Pearl, 1988, p. 84; Dawid, 2001) are properties that we would like to be satisfied by an irrelevance relation. They hold for instance for undirected graph separation ⊥⊥u and for d– separation (Verma and Pearl, 1988) as well as for probabilistic conditional independence. Symmetry is one of the basic (semi)graphoid properties. As yet, there is no general framework for asymmetric irrelevance relations available although other examples apart from local independence exist (e.g. Dawid, 1979, 1980; Galles and Pearl, 1996; Cozman and Walley, 1999). In the following we re–define the (semi)graphoid axioms for the asymmetric case and check which of them are satisfied by δ–separation and local independence.\nDefinition 4.1 Asymmetric (semi)graphoid Consider a lattice (V,≤), where A ∨ B denotes the least upper bound and A∧B the largest lower bound. Further, let (A irB|C) be a ternary relation on this lattice. The following properties are called the asymmetric semi–graphoid properties:\nLeft redundancy: A irB | A Right redundancy: A irB | B Left decomposition: A irB | C, D ≤ A ⇒ D irB | C\nRight decomposition: A irB | C, D ≤ B ⇒ A irD | C\nLeft weak union: A irB | C, D ≤ A ⇒ A irB | (C ∨D)\nRight weak union: A irB | C, D ≤ B ⇒ A irB | (C ∨D)\nLeft contraction: A irB | C and D irB | (A∨C)⇒ (A∨D) irB | C\nRight contraction: A irB | C and A irD | (B∨C)⇒ A ir (B∨D) | C\nIf, in addition, the following properties hold we have an asymmetric graphoid:\nLeft intersection: A irB | C and C irB | A⇒ (A∨C) irB | (A∧C)\nRight intersection: A irB | C and A irC | B ⇒ A ir (B∨C) | (B∧C).\nWhile Definition 4.1 applies for possibly overlapping sets, the following lemma clarifies the conditions under which it suffices to consider non–overlapping sets.\nLemma 4.2 Irrelevance for disjoint sets Let V be the power set of V and A,B, C ∈ V. For a ternary relation A irB|C that satisfies left redundancy, decomposition, and contraction we have that\nA irB | C ⇔ A\\C irB | C. (5) For a ternary relation that satisfies right redundancy, decomposition, and contraction we have that\nA irB | C ⇔ A irB\\C | C. (6)\nProof: To see (5) note that it follows directly from left decomposition that A irB|C ⇒ A\\C irB|C. To show A\\C irB|C ⇒ A irB|C, note that trivially A\\C irB|(C ∪ (C ∩A)). Additionally, it follows from left redundancy (i.e. C irB|C) and left decomposition that (C ∩ A) irB|C. Left contraction now yields the desired result. Property (6) is shown similarly.\nThe following corollary exploits (5) and (6) to reformulate the intersection property in a more familiar way.\nCorollary 4.3 Alternative intersection property Let V be the power set of V and A,B, C ∈ V. Given an ternary relation with property (5), left decomposition, and left intersection. For pairwise disjoint sets A,B, C, D ∈ V it holds that\nA irB | (C ∪D) and C irB | (A ∪D) ⇒ (A ∪ C) irB | D. (7)\nWith property (6), right decomposition, and right intersection it holds that\nA irB | (C ∪D) and A irC | (B ∪D) ⇒ A ir (B ∪ C) | D. (8)\nProof: With property (5) we have that A irB|(C∪D) ⇔ (A ∪ C ∪ D) irB|(C ∪ D) from where it follows with left decomposition that (A ∪ D) irB|(C ∪ D). With the same argument we get C irB|(A ∪ D) ⇒ (C ∪D) irB|(A∪D). Left intersection yields (A∪C ∪ D) irB|D which is again equivalent to (A∪C) irB|D because of (5). Implication (8) can be shown similarly."
    }, {
      "heading" : "4.1 PROPERTIES OF LOCAL INDEPENDENCE",
      "text" : "An obvious way to translate local independence into an irrelevance relation is by letting A irB | C stand for A →/ B | C, where A,B, C ⊂ V . The semi–order is given by the set inclusion ’⊂’, the join and meet operations by union and intersection, respectively.\nProposition 4.4 Local independence as graphoid The following properties hold for local independence:\n(i) left redundancy,\n(ii) left decomposition,\n(iii) left and right weak union,\n(iv) left contraction,\n(v) right intersection.\nProof: Didelez (2000, pp.70)\nWith the above proposition we have that (5) holds, i.e. A →/ B | C ⇔ A\\C →/ B | C. In contrast, it is clear by the definition of local independence that right redundancy does not hold because otherwise any process would always be locally independent of any other process given its own past. It follows that property (6) does not hold. Instead we have:\nLemma 4.5 Special version of right decomposition The following implication holds for local independence:"
    }, {
      "heading" : "A →/ B | C, and D ⊂ B ⇒ A →/ D | (C ∪B)\\D",
      "text" : "The importance of intersection for the equivalence of pairwise, local and global Markov properties in undirected conditional independence graphs is well–known (cf. Lauritzen, 1996). It is of similar importance for local independence graphs.\nProposition 4.6 Left intersection Under the assumption that\nFAt ∩ FBt = FA∩Bt ∀ A,B ⊂ V, ∀ t ∈ T (9) the property of left intersection holds for local independence.\nProof: Left intersection assumes that the FA∪B∪Ct – compensators Λk(t), k ∈ B, are FB∪Ct – as well as FA∪Bt –measurable. With (9) we get that they are FB∪(A∩C)t –measurable which yields the desired result. Property (9) formalizes the intuitive notion that the considered components of the process are ‘different enough’ to ensure that common events in the past are necessarily due to common components. Its main consequence is the following.\nCorollary 4.7 Pairwise implies local dynamic MP Under (9) the pairwise dynamic Markov property (2) and the local one (3) are equivalent.\nProof: (3) ⇒ (2) follows from left weak union and left decomposition. (2)⇒ (3) follows immediately from (7) which holds if (9) holds.\nRight decomposition requires special consideration because it makes a statement about the irrelevance of a subprocess YA after discarding part of the possibly relevant information YB\\D. If the irrelevance of YA is due to knowing the past of YB\\D then it will not necessarily be irrelevant anymore if the latter is discarded. It therefore only holds under specific restrictions on the relation among the processes. The first restriction exploits property (9) to show that under an additional condition right decomposition also holds for local independence.\nProposition 4.8 Right decomposition (I) Given (9) right decomposition holds for local independence under the following additional conditions:\n(B ∩A)\\(C ∪D) = ∅ and B →/ D | A ∪ C. (10)\nProof: Didelez (2000, p.72)\nAnother situation where right decomposition holds is given as follows.\nProposition 4.9 Right decomposition (II) Let A,B, C,D ⊂ V with (B ∩A)\\(C ∪D) = ∅. Right decomposition holds under the conditions that\nB →/ A\\(C ∪D) | (C ∪D) (11) and\nA →/ {k} | C ∪B or B →/ {k} | (C ∪D ∪A) (12) for all k ∈ C\\D. Proof: Didelez (2000, pp.72)"
    }, {
      "heading" : "4.2 PROPERTIES OF δ–SEPARATION",
      "text" : "The interpretation of δ–separation as irrelevance relation should be that if C δ–separates A from B in G then A is irrelevant for B given C. This is denoted by A irδ B|C.\nProposition 4.10 δ–separation as graphoid δ–separation satisfies the following properties:\n(i) left redundancy,\n(ii) left decomposition,\n(iii) left and right weak union,\n(iv) left and right contraction,\n(v) left and right intersection.\nProof: Didelez (2000, pp.27).\nWith these results not only property (5) but also (7) hold for δ–separation. So far, however, the conditions for (6) and (8) are not satisfied because right redundancy does not hold. By definition right redundancy would imply that A irδ B|B ⇔ A\\B irδ B|∅ which is only true if A\\B and B are unconnected in (GBAn(A∪B))\nm. A simple counterexample is given by the graph with V = {a, b} and E = {(a, b)}. Additionally, property (6) does not hold, as can be seen by another example shown in Figure 4. Let A = {a}, B = {b1, b2}, and C = {b1, c}. Then, A irδ B\\C|C but not A irδ B|C since the latter only holds if A irδ B|C\\B. In contrast, the converse does hold because it is a special case of the subsequent result paralleling Lemma 4.5.\nLemma 4.11 Special version of right decomposition Given a directed graph G, it holds that:\nA irδ B | C, D ⊂ B ⇒ A irδ D | (C ∪B)\\D\nProof: Let A∗ = A\\(B∪C) and C∗ = C\\B. Then, we have to show that A∗⊥⊥u B|C∗ in (GBAn(A∪B∪C))m implies A∗⊥⊥u D|C∗ ∪ (B\\D) in (GDAn(A∪B∪C))m. Note that A∗⊥⊥u D|C∗ ∪ (B\\D) in (GBAn(A∪B∪C))m holds due to weak union and decomposition of ⊥⊥u . Changing the graph to (GDAn(A∪B∪C)) m means that all edges\nthat are present in G as directed edges starting in B\\D are added. Additionally, those edges have to be added which result from vertices in B\\D having common children with other vertices. Since all these new edges involve vertices in B\\D there can be no additional path between A∗ and D in (GDAn(A∪B∪C))\nm not intersected by C∗ ∪ (B\\D). Although (6) does not hold in full generality it is easily checked that (8) does.\nProposition 4.12 Alternative intersection property Property (8) holds for δ–separation, i.e."
    }, {
      "heading" : "A irδ B | (C ∪D) and A irδ C | (B ∪D)",
      "text" : "⇒ A irδ (B ∪ C) | D\nfor pairwise disjoint sets A, B,C, D.\nProof: Given that A⊥⊥u B|(C ∪D) in (GBA∪B∪C∪D)m and A⊥⊥u C|(B ∪ D) in (GCA∪B∪C∪D)m, both separations also hold in (GB∪CA∪B∪C∪D)\nm. With the properties of ⊥⊥u it follows that A⊥⊥u (B ∪ C)|D in (GB∪CA∪B∪C∪D) m.\nThe above proposition does not necessarily hold if B,C, D are not disjoint. But it can be shown by a very similar proof that it remains valid if A ∩ B 6= ∅ or A ∩ C 6= ∅.\nA simple counterexample for right decomposition of δ– separation is given in Figure 5, where {c} δ–separates {a} from B = {b, d} but it is not true that {c} δ– separates {a} from {d}. In the first case we delete the arrow from b to a whereas in the second case it is kept. However, we can obtain the following result paralleling Propositions 4.8 and 4.9.\nProposition 4.13 Right decomposition Right decomposition holds for δ–separation in the special case that (A ∩B)\\(C ∪D) = ∅ and\n(i) either B irδ D|(A ∪ C) (ii) or B irδ A\\(C ∪ D)|(C ∪ D) and for all\nk ∈ C\\D either A irδ {k}|((C\\{k}) ∪ B) or B irδ {k}|((C\\{k}) ∪D ∪A).\nProof: Didelez (2000, pp.31).\nProperty (i) of Proposition 4.13 is illustrated in Figure 6 which includes the moral graph (Gd)m. Choose A = {a}, B = {b, d} and C = {c}. Property (ii) of Proposition 4.13 is illustrated in Figure 7 which includes the moral graph (Gd)m. Choose A = {a}, B = {b, d} and C = {c}. Roughly one can summarize the assumptions of Proposition 4.13 as that either B\\D does not affect D or A and B\\D do not affect common nodes in C as this would open a path between them.\nThe main consequence of the properties of local independence and δ–separation is that we can indeed use δ–separation to read off local independencies among sub–processes from a local independence graph.\nTheorem 4.14 Pairwise implies global MP With the above properties, using right decomposition under the conditions specified by Propositions 4.8, 4.9 and 4.13, we have that the pairwise dynamic Markov property (2) and the global dynamic Markov property (4) are equivalent.\nProof: That (4) implies (2) is easily seen because V \\{j, k} δ–separates j from k if (j, k) /∈ E. The structure of the proof of (2) ⇒ (4) corresponds to the one given by Lauritzen (1996, p. 34) for the equivalence of the Markov properties in undirected conditional independence graphs. Due to the asymmetry of local independence the present proof is more complicated and is given in Didelez (2000, pp.90).\nIn order to illustrate the significance of Theorem 4.14 we return to the example given in the Introduction and depicted in Figure 1. We can see from the graph that in an analysis that only uses data on the visits, hospitalization and survival, i.e. where health status is ignored, we might find that survival depends on the visits. This is somewhat surprising as the visit process is locally independent of the health status process\ngiven the other components. The reason is that the node ‘visits’ is not separated from ‘survival’ by ‘hospitalization’ alone. In other words, a history of e.g. hospitalization without prior visit by a nurse carries a different information than a history of hospitalization with prior visit — it is informative for the unobserved health process. The health status could be regarded as a particular type of time dependent confounder."
    }, {
      "heading" : "5 DISCUSSION",
      "text" : "Local independence graphs and δ–separation represent dynamic dependencies among continuous time multi– state processes. They are a valuable tool for reasoning in dynamic settings in the presence of time–dependent confounding and censoring (Didelez, 2005a). In addition, the framework of asymmetric (semi)graphoids developed here can be applied more generally to asymmetric irrelevance relations.\nSimilar to the classical Bayesian networks, the graph structure can be exploited to simplify and accelerate computations. In this context some further results on collapsibility and likelihood factorization are derived in Didelez (2005a, 2005b). Such a likelihood factorization is also exploited by Nodelman et al. (2003) for learning the graph. However, as can be seen from their work the computational side is more intricate than for standard networks and deserves further investigation."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work has been supported by the German Research Foundation (SFB 386) and the Centre for Advanced Study at the Norwegian Academy of Science and Letters."
    } ],
    "references" : [ {
      "title" : "Dynamic modelling and causality",
      "author" : [ "O.O. Aalen" ],
      "venue" : "Scand. Actuar. J.,",
      "citeRegEx" : "Aalen,? \\Q1987\\E",
      "shortCiteRegEx" : "Aalen",
      "year" : 1987
    }, {
      "title" : "Statistical models based on counting processes",
      "author" : [ "P.K. Andersen", "Borgan", "R.D.Ø. Gill", "N. Keiding" ],
      "venue" : null,
      "citeRegEx" : "Andersen et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Andersen et al\\.",
      "year" : 1993
    }, {
      "title" : "Graphoid properties of epistemic irrelevance and independence",
      "author" : [ "Cozman F.G", "P. Walley" ],
      "venue" : "Technical Report,",
      "citeRegEx" : "F.G. and Walley,? \\Q1999\\E",
      "shortCiteRegEx" : "F.G. and Walley",
      "year" : 1999
    }, {
      "title" : "Conditional independence in statistical theory",
      "author" : [ "A.P. Dawid" ],
      "venue" : "J. Roy. Statist. Soc. Ser. B",
      "citeRegEx" : "Dawid,? \\Q1979\\E",
      "shortCiteRegEx" : "Dawid",
      "year" : 1979
    }, {
      "title" : "Conditional independence for statistical operations",
      "author" : [ "A.P. Dawid" ],
      "venue" : "The Annals of Statistics,",
      "citeRegEx" : "Dawid,? \\Q1980\\E",
      "shortCiteRegEx" : "Dawid",
      "year" : 1980
    }, {
      "title" : "Separoids: A mathematical framework for conditional independence and irrele",
      "author" : [ "A.P. Dawid" ],
      "venue" : null,
      "citeRegEx" : "Dawid,? \\Q2001\\E",
      "shortCiteRegEx" : "Dawid",
      "year" : 2001
    }, {
      "title" : "Graphical models for event history data based on local independence",
      "author" : [ "V. Didelez" ],
      "venue" : null,
      "citeRegEx" : "Didelez,? \\Q2000\\E",
      "shortCiteRegEx" : "Didelez",
      "year" : 2000
    }, {
      "title" : "Graphical models for marked point processes based on local independence",
      "author" : [ "V. Didelez" ],
      "venue" : "Tech. Rep. No. 258,",
      "citeRegEx" : "Didelez,? \\Q2005\\E",
      "shortCiteRegEx" : "Didelez",
      "year" : 2005
    }, {
      "title" : "Graphical models for composable finite Markov processes",
      "author" : [ "V. Didelez" ],
      "venue" : "Scandinavian Journal of Statistics,",
      "citeRegEx" : "Didelez,? \\Q2005\\E",
      "shortCiteRegEx" : "Didelez",
      "year" : 2005
    }, {
      "title" : "Granger-causality and path diagrams for multivariate time series",
      "author" : [ "M. Eichler" ],
      "venue" : "Journal of Econometrics,",
      "citeRegEx" : "Eichler,? \\Q2002\\E",
      "shortCiteRegEx" : "Eichler",
      "year" : 2002
    }, {
      "title" : "Axioms of causal relevance",
      "author" : [ "D. Galles", "J. Pearl" ],
      "venue" : "Technical Report 240,",
      "citeRegEx" : "Galles and Pearl,? \\Q1996\\E",
      "shortCiteRegEx" : "Galles and Pearl",
      "year" : 1996
    }, {
      "title" : "Investigating causal relations by econometric models and cross–spectral",
      "author" : [ "C.W.J. Granger" ],
      "venue" : "methods. Econometrica",
      "citeRegEx" : "Granger,? \\Q1969\\E",
      "shortCiteRegEx" : "Granger",
      "year" : 1969
    }, {
      "title" : "Graphical models",
      "author" : [ "S.L. Lauritzen" ],
      "venue" : null,
      "citeRegEx" : "Lauritzen,? \\Q1996\\E",
      "shortCiteRegEx" : "Lauritzen",
      "year" : 1996
    }, {
      "title" : "Continuous time Bayesian networks",
      "author" : [ "U. Nodelman", "C.R. Shelton", "D. Koller" ],
      "venue" : "Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Nodelman et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Nodelman et al\\.",
      "year" : 2002
    }, {
      "title" : "Learning continuous time Bayesian networks",
      "author" : [ "U. Nodelman", "C.R. Shelton", "D. Koller" ],
      "venue" : "Proceedings of the 19th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Nodelman et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Nodelman et al\\.",
      "year" : 2003
    }, {
      "title" : "Probabilistic reasoning in intelligent systems",
      "author" : [ "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "Pearl,? \\Q1988\\E",
      "shortCiteRegEx" : "Pearl",
      "year" : 1988
    }, {
      "title" : "Identifying independencies in causal graphs with feedback",
      "author" : [ "J. Pearl", "R. Dechter" ],
      "venue" : "Proceedings of the 12th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Pearl and Dechter,? \\Q1996\\E",
      "shortCiteRegEx" : "Pearl and Dechter",
      "year" : 1996
    }, {
      "title" : "Graphoids: A graph– based logic for reasoning about relevancy relations",
      "author" : [ "J. Pearl", "A. Paz" ],
      "venue" : "Advances in Artificial Intelligence – II,",
      "citeRegEx" : "Pearl and Paz,? \\Q1987\\E",
      "shortCiteRegEx" : "Pearl and Paz",
      "year" : 1987
    }, {
      "title" : "Composable Markov processes",
      "author" : [ "T. Schweder" ],
      "venue" : "J. Appl. Prob",
      "citeRegEx" : "Schweder,? \\Q1970\\E",
      "shortCiteRegEx" : "Schweder",
      "year" : 1970
    }, {
      "title" : "Directed cyclic graphical representations of feedback models",
      "author" : [ "P. Spirtes" ],
      "venue" : "Proceedings of the 11th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Spirtes,? \\Q1995\\E",
      "shortCiteRegEx" : "Spirtes",
      "year" : 1995
    }, {
      "title" : "Causal networks: Semantics and expressiveness",
      "author" : [ "T. Verma", "J. Pearl" ],
      "venue" : "Proceedings of the 4th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Verma and Pearl,? \\Q1988\\E",
      "shortCiteRegEx" : "Verma and Pearl",
      "year" : 1988
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Directed possibly cyclic graphs have been proposed by Didelez (2000) and Nodelmann et al.",
      "startOffset" : 54,
      "endOffset" : 69
    }, {
      "referenceID" : 6,
      "context" : "Directed possibly cyclic graphs have been proposed by Didelez (2000) and Nodelmann et al. (2002) in order to represent the dynamic dependencies among stochastic processes.",
      "startOffset" : 54,
      "endOffset" : 97
    }, {
      "referenceID" : 6,
      "context" : "Directed possibly cyclic graphs have been proposed by Didelez (2000) and Nodelmann et al. (2002) in order to represent the dynamic dependencies among stochastic processes. These dependencies are based on a generalization of Granger–causality to continuous time, first developed by Schweder (1970) for Markov processes, who called them local dependencies.",
      "startOffset" : 54,
      "endOffset" : 297
    }, {
      "referenceID" : 11,
      "context" : "Such independence underlies the notion of Granger non–causality for time series (Granger, 1969), which has been used as the basis for a graphical representation by Eichler (2002).",
      "startOffset" : 80,
      "endOffset" : 95
    }, {
      "referenceID" : 16,
      "context" : "Cyclic graphs have also been proposed to represent non–recursive structural equation models or feedback processes (Sprites, 1995; Pearl and Dechter, 1996), but with the above notion of dependence between past and present we explicitly consider processes instead of cross sectional measurements of variables in equilibrium.",
      "startOffset" : 114,
      "endOffset" : 154
    }, {
      "referenceID" : 5,
      "context" : "Such independence underlies the notion of Granger non–causality for time series (Granger, 1969), which has been used as the basis for a graphical representation by Eichler (2002). It also underlies the continuous–time notion of local independence given by Schweder (1970) for Markov processes, and its bivariate version for general continuous–time processes by Aalen (1987) with a multivariate version in Didelez (2000, pp.",
      "startOffset" : 164,
      "endOffset" : 179
    }, {
      "referenceID" : 5,
      "context" : "Such independence underlies the notion of Granger non–causality for time series (Granger, 1969), which has been used as the basis for a graphical representation by Eichler (2002). It also underlies the continuous–time notion of local independence given by Schweder (1970) for Markov processes, and its bivariate version for general continuous–time processes by Aalen (1987) with a multivariate version in Didelez (2000, pp.",
      "startOffset" : 164,
      "endOffset" : 272
    }, {
      "referenceID" : 0,
      "context" : "It also underlies the continuous–time notion of local independence given by Schweder (1970) for Markov processes, and its bivariate version for general continuous–time processes by Aalen (1987) with a multivariate version in Didelez (2000, pp.",
      "startOffset" : 181,
      "endOffset" : 194
    }, {
      "referenceID" : 0,
      "context" : "It also underlies the continuous–time notion of local independence given by Schweder (1970) for Markov processes, and its bivariate version for general continuous–time processes by Aalen (1987) with a multivariate version in Didelez (2000, pp.65). A special case of Schweder’s concept are the dependencies represented in the continuous time Bayesian networks developed by Nodelman et al. (2002) for homogenous Markov processes.",
      "startOffset" : 181,
      "endOffset" : 395
    }, {
      "referenceID" : 18,
      "context" : "The Markov process Y is assumed to consist of components in the following sense (Schweder, 1970).",
      "startOffset" : 80,
      "endOffset" : 96
    }, {
      "referenceID" : 13,
      "context" : "Note that the components of such a Markov process correspond to the local variables of Nodelman et al. (2002). From now, we consider composable finite Markov processes (CFMPs) and write α(t; (y,y′)) instead of αyy′(t) for notational convenience.",
      "startOffset" : 87,
      "endOffset" : 110
    }, {
      "referenceID" : 13,
      "context" : "Note that the components of such a Markov process correspond to the local variables of Nodelman et al. (2002). From now, we consider composable finite Markov processes (CFMPs) and write α(t; (y,y′)) instead of αyy′(t) for notational convenience. Schweder (1970) proves the following.",
      "startOffset" : 87,
      "endOffset" : 262
    }, {
      "referenceID" : 13,
      "context" : "In the terminology of Nodelman et al. (2002), a component Yk can be regarded as a conditional Markov process, the transition intensities of which depend on the states of Ypa(k) and can be represented in a collection of conditional transition matrices for the transitions yk → y′ k, yk 6= y′ k ∈ Sk, one matrix for each value of ypa(k) ∈ Spa(k).",
      "startOffset" : 22,
      "endOffset" : 45
    }, {
      "referenceID" : 12,
      "context" : "We can regard (2) as a dynamic version of the pairwise Markov property (Lauritzen, 1996) and hence call it the pairwise dynamic Markov property.",
      "startOffset" : 71,
      "endOffset" : 88
    }, {
      "referenceID" : 13,
      "context" : "In the special case of YV being a homogenous Markov process its local independence graph is the same as a continuous time Bayesian network (Nodelman et al., 2002).",
      "startOffset" : 139,
      "endOffset" : 162
    }, {
      "referenceID" : 5,
      "context" : "The (semi)graphoid axioms first introduced by Dawid (1979) (cf. also Pearl and Paz, 1987; Pearl, 1988, p. 84; Dawid, 2001) are properties that we would like to be satisfied by an irrelevance relation.",
      "startOffset" : 59,
      "endOffset" : 122
    }, {
      "referenceID" : 20,
      "context" : "They hold for instance for undirected graph separation ⊥⊥u and for d– separation (Verma and Pearl, 1988) as well as for probabilistic conditional independence.",
      "startOffset" : 81,
      "endOffset" : 104
    }, {
      "referenceID" : 10,
      "context" : "As yet, there is no general framework for asymmetric irrelevance relations available although other examples apart from local independence exist (e.g. Dawid, 1979, 1980; Galles and Pearl, 1996; Cozman and Walley, 1999).",
      "startOffset" : 145,
      "endOffset" : 218
    }, {
      "referenceID" : 3,
      "context" : "The (semi)graphoid axioms first introduced by Dawid (1979) (cf.",
      "startOffset" : 46,
      "endOffset" : 59
    }, {
      "referenceID" : 6,
      "context" : "They are a valuable tool for reasoning in dynamic settings in the presence of time–dependent confounding and censoring (Didelez, 2005a). In addition, the framework of asymmetric (semi)graphoids developed here can be applied more generally to asymmetric irrelevance relations. Similar to the classical Bayesian networks, the graph structure can be exploited to simplify and accelerate computations. In this context some further results on collapsibility and likelihood factorization are derived in Didelez (2005a, 2005b). Such a likelihood factorization is also exploited by Nodelman et al. (2003) for learning the graph.",
      "startOffset" : 120,
      "endOffset" : 597
    } ],
    "year" : 2006,
    "abstractText" : "Directed possibly cyclic graphs have been proposed by Didelez (2000) and Nodelmann et al. (2002) in order to represent the dynamic dependencies among stochastic processes. These dependencies are based on a generalization of Granger–causality to continuous time, first developed by Schweder (1970) for Markov processes, who called them local dependencies. They deserve special attention as they are asymmetric. In this paper we focus on their graphical representation and develop an asymmetric notion of separation. The properties of this graph separation as well as local independence are investigated in detail within a framework of asymmetric (semi)graphoids allowing insight into what information can be read off these graphs.",
    "creator" : " TeX output 2006.05.19:1854"
  }
}