{
  "name" : "1502.03475.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Stochastic and Adversarial Combinatorial Bandits",
    "authors" : [ "Richard Combes", "Marc Lelarge", "Alexandre Proutiere", "Sadegh Talebi" ],
    "emails" : [ "RICHARD.COMBES@SUPELEC.FR", "MARC.LELARGE@ENS.FR", "ALEPRO@KTH.SE", "MSTMS@KTH.SE" ],
    "sections" : null,
    "references" : [ {
      "title" : "Asymptotically efficient allocation rules for the multiarmed bandit problem with multiple plays-part i: iid rewards",
      "author" : [ "References Anantharam", "Venkatachalam", "Varaiya", "Pravin", "Walrand", "Jean" ],
      "venue" : "Automatic Control, IEEE Transactions on,",
      "citeRegEx" : "Anantharam et al\\.,? \\Q1987\\E",
      "shortCiteRegEx" : "Anantharam et al\\.",
      "year" : 1987
    }, {
      "title" : "Regret in online combinatorial optimization",
      "author" : [ "Audibert", "Jean-Yves", "Bubeck", "Sébastien", "Lugosi", "Gábor" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "Audibert et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Audibert et al\\.",
      "year" : 2013
    }, {
      "title" : "Finite time analysis of the multiarmed bandit problem",
      "author" : [ "P. Auer", "N. Cesa-Bianchi", "P. Fischer" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Auer et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Auer et al\\.",
      "year" : 2002
    }, {
      "title" : "The nonstochastic multiarmed bandit problem",
      "author" : [ "P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Auer et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Auer et al\\.",
      "year" : 2002
    }, {
      "title" : "Regret analysis of stochastic and nonstochastic multi-armed bandit problems",
      "author" : [ "S. Bubeck", "N. Cesa-Bianchi" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "Bubeck and Cesa.Bianchi,? \\Q2012\\E",
      "shortCiteRegEx" : "Bubeck and Cesa.Bianchi",
      "year" : 2012
    }, {
      "title" : "Towards minimax policies for online linear optimization with bandit feedback",
      "author" : [ "Bubeck", "Sébastien", "Cesa-Bianchi", "Nicolo", "Kakade", "Sham M" ],
      "venue" : "arXiv preprint arXiv:1202.3079,",
      "citeRegEx" : "Bubeck et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Bubeck et al\\.",
      "year" : 2012
    }, {
      "title" : "Combinatorial bandits",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Cesa.Bianchi and Lugosi,? \\Q2012\\E",
      "shortCiteRegEx" : "Cesa.Bianchi and Lugosi",
      "year" : 2012
    }, {
      "title" : "Prediction, learning, and games, volume 1",
      "author" : [ "Cesa-Bianchi", "Nicolo", "Lugosi", "Gábor" ],
      "venue" : null,
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2006
    }, {
      "title" : "Combinatorial multi-armed bandit: General framework and applications",
      "author" : [ "Chen", "Wei", "Wang", "Yajun", "Yuan", "Yang" ],
      "venue" : "In Proceedings of The 30th International Conference on Machine Learning,",
      "citeRegEx" : "Chen et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2013
    }, {
      "title" : "Unimodal bandits: Regret lower bounds and optimal algorithms",
      "author" : [ "Combes", "Richard", "Proutiere", "Alexandre" ],
      "venue" : "[cs.LG],",
      "citeRegEx" : "Combes et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Combes et al\\.",
      "year" : 2014
    }, {
      "title" : "Information theory and statistics: A tutorial",
      "author" : [ "I. Csiszár", "P.C. Shields" ],
      "venue" : "Now Publishers Inc,",
      "citeRegEx" : "Csiszár and Shields,? \\Q2004\\E",
      "shortCiteRegEx" : "Csiszár and Shields",
      "year" : 2004
    }, {
      "title" : "Learning multiuser channel allocations in cognitive radio networks: A combinatorial multi-armed bandit formulation",
      "author" : [ "Gai", "Yi", "Krishnamachari", "Bhaskar", "Jain", "Rahul" ],
      "venue" : "In New Frontiers in Dynamic Spectrum,",
      "citeRegEx" : "Gai et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Gai et al\\.",
      "year" : 2010
    }, {
      "title" : "Combinatorial network optimization with unknown variables: Multiarmed bandits with linear rewards and individual observations",
      "author" : [ "Gai", "Yi", "Krishnamachari", "Bhaskar", "Jain", "Rahul" ],
      "venue" : "IEEE/ACM Transactions on Networking (TON),",
      "citeRegEx" : "Gai et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gai et al\\.",
      "year" : 2012
    }, {
      "title" : "The kl-ucb algorithm for bounded stochastic bandits and beyond",
      "author" : [ "A. Garivier", "O. Cappé" ],
      "venue" : "In Proceedings of Conference On Learning Theory COLT,",
      "citeRegEx" : "Garivier and Cappé,? \\Q2011\\E",
      "shortCiteRegEx" : "Garivier and Cappé",
      "year" : 2011
    }, {
      "title" : "Asymptotically efficient adaptive choice of control laws in controlled markov chains",
      "author" : [ "T.L. Graves", "T.L. Lai" ],
      "venue" : "SIAM J. Control and Optimization,",
      "citeRegEx" : "Graves and Lai,? \\Q1997\\E",
      "shortCiteRegEx" : "Graves and Lai",
      "year" : 1997
    }, {
      "title" : "The shortest path problem under partial monitoring",
      "author" : [ "György", "Andras", "Linder", "Tamas", "Ottucsak", "Gyorgy" ],
      "venue" : "Learning Theory, volume 4005 of Lecture Notes in Computer Science,",
      "citeRegEx" : "György et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "György et al\\.",
      "year" : 2006
    }, {
      "title" : "The on-line shortest path problem under partial monitoring",
      "author" : [ "György", "András", "Linder", "Tamás", "Lugosi", "Gábor", "Ottucsák" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "György et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "György et al\\.",
      "year" : 2007
    }, {
      "title" : "Learning permutations with exponential weights",
      "author" : [ "Helmbold", "David P", "Warmuth", "Manfred K" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "Helmbold et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Helmbold et al\\.",
      "year" : 2009
    }, {
      "title" : "Non-stochastic bandit slate problems",
      "author" : [ "S. Kale", "L. Reyzin", "R. Schapire" ],
      "venue" : "Advances in Neural Information Processing Systems, pp",
      "citeRegEx" : "Kale et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Kale et al\\.",
      "year" : 2010
    }, {
      "title" : "Matroid bandits: Fast combinatorial optimization with learning",
      "author" : [ "Kveton", "Branislav", "Wen", "Zheng", "Ashkan", "Azin", "Eydgahi", "Hoda", "Eriksson", "Brian" ],
      "venue" : null,
      "citeRegEx" : "Kveton et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kveton et al\\.",
      "year" : 2014
    }, {
      "title" : "Asymptotically efficient adaptive allocation rules",
      "author" : [ "T.L. Lai", "H. Robbins" ],
      "venue" : "Advances in Applied Mathematics,",
      "citeRegEx" : "Lai and Robbins,? \\Q1985\\E",
      "shortCiteRegEx" : "Lai and Robbins",
      "year" : 1985
    }, {
      "title" : "Lipschitz bandits: Regret lower bounds and optimal algorithms",
      "author" : [ "Magureanu", "Stefan", "Combes", "Richard", "Proutiere", "Alexandre" ],
      "venue" : "COLT 2014,",
      "citeRegEx" : "Magureanu et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Magureanu et al\\.",
      "year" : 2014
    }, {
      "title" : "On cliques in graphs. Israel",
      "author" : [ "J.W. Moon", "L. Moser" ],
      "venue" : "Journal of Mathematics,",
      "citeRegEx" : "Moon and Moser,? \\Q1965\\E",
      "shortCiteRegEx" : "Moon and Moser",
      "year" : 1965
    }, {
      "title" : "An efficient algorithm for learning with semi-bandit feedback",
      "author" : [ "Neu", "Gergely", "Bartók", "Gábor" ],
      "venue" : "In Algorithmic Learning Theory,",
      "citeRegEx" : "Neu et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Neu et al\\.",
      "year" : 2013
    }, {
      "title" : "Some aspects of the sequential design of experiments",
      "author" : [ "Robbins", "Herbert" ],
      "venue" : "In Herbert Robbins Selected Papers,",
      "citeRegEx" : "Robbins and Herbert.,? \\Q1985\\E",
      "shortCiteRegEx" : "Robbins and Herbert.",
      "year" : 1985
    }, {
      "title" : "Combinatorial Optimization: Polyhedra and Efficiency",
      "author" : [ "Schrijver", "Alexander" ],
      "venue" : null,
      "citeRegEx" : "Schrijver and Alexander.,? \\Q2003\\E",
      "shortCiteRegEx" : "Schrijver and Alexander.",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : ", (Bubeck & Cesa-Bianchi, 2012; Cesa-Bianchi et al., 2006).",
      "startOffset" : 2,
      "endOffset" : 58
    }, {
      "referenceID" : 0,
      "context" : "Some research contributions concern problems where the set of arms exhibits very specific structures, such as m-set (Anantharam et al., 1987), matroid (Kveton et al.",
      "startOffset" : 116,
      "endOffset" : 141
    }, {
      "referenceID" : 19,
      "context" : ", 1987), matroid (Kveton et al., 2014), or matching in bi-partite graphs (Gai et al.",
      "startOffset" : 17,
      "endOffset" : 38
    }, {
      "referenceID" : 11,
      "context" : ", 2014), or matching in bi-partite graphs (Gai et al., 2010).",
      "startOffset" : 42,
      "endOffset" : 60
    }, {
      "referenceID" : 12,
      "context" : "Generic combinatorial problems have been investigated in (Gai et al., 2012) and Algorithm Regret LLR (Gai et al.",
      "startOffset" : 57,
      "endOffset" : 75
    }, {
      "referenceID" : 12,
      "context" : ", 2012) and Algorithm Regret LLR (Gai et al., 2012) O ( md∆max ∆min log(T ) )",
      "startOffset" : 33,
      "endOffset" : 51
    }, {
      "referenceID" : 8,
      "context" : "CUCB (Chen et al., 2013) O ( md ∆min log(T ) )",
      "startOffset" : 5,
      "endOffset" : 24
    }, {
      "referenceID" : 8,
      "context" : "(Chen et al., 2013).",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 1,
      "context" : "When μ −1 min = O(poly(d)), which happens in several specific problems of interest, the regret under COMBEXP-1 matches the regret minimax lower bound √ mdT up to a logarithmic factor (Audibert et al., 2013).",
      "startOffset" : 183,
      "endOffset" : 206
    }, {
      "referenceID" : 1,
      "context" : "Note that a known regret minimax lower bound is Ω(m √ dT ) (Audibert et al., 2013), and hence the regret gap between COMBEXP-2 and this lower bound scales at most as m up to a logarithmic factor.",
      "startOffset" : 59,
      "endOffset" : 82
    }, {
      "referenceID" : 1,
      "context" : "Adversarial combinatorial bandits have been extensively investigated recently, see (Audibert et al., 2013) and references therein.",
      "startOffset" : 83,
      "endOffset" : 106
    }, {
      "referenceID" : 15,
      "context" : "shortest-path routing (György et al., 2006; 2007) or m-sets (Kale et al.",
      "startOffset" : 22,
      "endOffset" : 49
    }, {
      "referenceID" : 18,
      "context" : ", 2006; 2007) or m-sets (Kale et al., 2010).",
      "startOffset" : 24,
      "endOffset" : 43
    }, {
      "referenceID" : 1,
      "context" : "For generic combinatorial problems, known regret lower bounds scale as Ω (√ mdT ) and Ω ( m √ dT ) (if d ≥ 2m) in the case of semi-bandit and bandit feedback, respectively (Audibert et al., 2013).",
      "startOffset" : 172,
      "endOffset" : 195
    }, {
      "referenceID" : 1,
      "context" : "In the case of semibandit feedback, (Audibert et al., 2013) proposes OSMD, an algorithm whose regret upper bound matches the lower bound.",
      "startOffset" : 36,
      "endOffset" : 59
    }, {
      "referenceID" : 1,
      "context" : "Stochastic and Adversarial Combinatorial Bandits Algorithm Regret Lower Bound (Audibert et al., 2013) Ω (√ mdT )",
      "startOffset" : 78,
      "endOffset" : 101
    }, {
      "referenceID" : 1,
      "context" : "OSMD (Audibert et al., 2013) O (√ mdT )",
      "startOffset" : 5,
      "endOffset" : 28
    }, {
      "referenceID" : 5,
      "context" : "(Bubeck et al., 2012) addresses generic linear optimization with bandit feedback and the proposed algorithm, referred to as EXP2 WITH JOHN’S EXPLORATION, has a regret scaling at most as O(m √ dT log(d/m)) in the case of combinatorial structure.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 1,
      "context" : "Stochastic and Adversarial Combinatorial Bandits Algorithm Regret Lower Bound (Audibert et al., 2013) Ω ( m √ dT ) , if d ≥ 2m COMBAND (Cesa-Bianchi & Lugosi, 2012) O ( m √ dT log |M| ( 1 + 2m dλmin ))",
      "startOffset" : 78,
      "endOffset" : 101
    }, {
      "referenceID" : 5,
      "context" : "EXP2 WITH JOHN’S EXPLORATION (Bubeck et al., 2012) O (√ m3dT log ( d m ))",
      "startOffset" : 29,
      "endOffset" : 50
    }, {
      "referenceID" : 0,
      "context" : "Furher remark that ifM is the set of singletons (classical bandit), Theorem 1 reduces to the Lai-Robbins bound (Lai & Robbins, 1985) and ifM is the set of m-sets (bandit with multiple plays), Theorem 1 reduces to the lower bound of (Anantharam et al., 1987).",
      "startOffset" : 232,
      "endOffset" : 257
    }, {
      "referenceID" : 0,
      "context" : "Indeed, in the case of m-sets, there exists an algorithm with O(d∆−1 min log(T )) regret (Anantharam et al., 1987).",
      "startOffset" : 89,
      "endOffset" : 114
    }, {
      "referenceID" : 21,
      "context" : "The proof of statement (ii) is based on a concentration inequality on sums of empirical KL divergences proven in (Magureanu et al., 2014).",
      "startOffset" : 113,
      "endOffset" : 137
    }, {
      "referenceID" : 8,
      "context" : "A close look at cM (n) reveals that the indexes proposed in (Chen et al., 2013) and (Gai et al.",
      "startOffset" : 60,
      "endOffset" : 79
    }, {
      "referenceID" : 12,
      "context" : ", 2013) and (Gai et al., 2012) are too conservative to be optimal: there the “confidence bonus” ∑d i=1 Mi ti(n) was replaced by (at least) m ∑d i=1 Mi ti(n) .",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 21,
      "context" : "A concentration inequality We first recall Lemma 1, a concentration inequality derived in (Magureanu et al., 2014)[Theorem].",
      "startOffset" : 90,
      "endOffset" : 114
    }, {
      "referenceID" : 19,
      "context" : "2 in the main document, in this case the regret of CUCB takes the form O( d ∆min log(T )) = O( N ∆min log(T )) on the account of (Kveton et al., 2014).",
      "startOffset" : 129,
      "endOffset" : 150
    } ],
    "year" : 2017,
    "abstractText" : "This paper investigates stochastic and adversarial combinatorial multi-armed bandit problems. In the stochastic setting, we first derive problem-specific regret lower bounds, and analyze how these bounds scale with the dimension of the decision space. We then propose COMBUCB, algorithms that efficiently exploit the combinatorial structure of the problem, and derive finite-time upper bound on their regrets. These bounds improve over regret upper bounds of existing algorithms, and we show numerically thatCOMBUCB significantly outperforms any other algorithm. In the adversarial setting, we propose two simple algorithms, namely COMBEXP-1 and COMBEXP-2 for semi-bandit and bandit feedback, respectively. Their regrets have similar scaling as state-of-the-art algorithms, in spite of the simplicity of their implementation.",
    "creator" : "LaTeX with hyperref package"
  }
}