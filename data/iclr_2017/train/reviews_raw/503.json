{"conference": "ICLR 2017 conference submission", "title": "Gated Multimodal Units for Information Fusion", "abstract": "This paper presents a novel model for multimodal learning based on gated neural networks. The Gated Multimodal Unit (GMU) model is intended to be used as an internal unit in a neural network architecture whose purpose is to find an intermediate representation based on a combination of data from different modalities. The GMU learns to decide how modalities influence the activation of the unit using multiplicative gates. It was evaluated on a multilabel scenario for genre classification of movies using the plot and the poster. The GMU improved the macro f-score performance of single-modality approaches and outperformed other fusion strategies, including mixture of experts models. Along with this work, the MM-IMDb dataset is released which, to the best of our knowledge, is the largest publicly available multimodal dataset for genre prediction on movies.", "reviews": [{"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "The authors propose a Gated Muiltimodal Unit to combine multi-modal information (visual and textual). They also collect a large dataset of movie summers and posters. Overall, the reviewers were quite positive, while AR4 points to related models and feels that the contribution in the current version is too weak for ICLR. The AC read the paper and the authors responses but tends to agree with AR4. The authors are encouraged to strengthen their work and resubmit to a future conference.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"TITLE": "New revision submitted", "OTHER_KEYS": "John Arevalo", "comments": "We have added a new version which includes the mixture of experts evaluation. Since this is a multilabel scenario, we implement tied and untied gates for the outputs. We also evaluate Logistic regression and MaxoutMLP as experts. \n\nOverall, the MoE models did not work very well in comparison with other fusion strategies. We believe this has to do with the amount of training samples. It is known that MoE models require large datasets because the data is fractionated over different experts.", "IS_META_REVIEW": false, "DATE": "13 Jan 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "review", "is_meta_review": false, "comments": "Paper proposes Gated Muiltimodal Unit, a building block for connectionist models capable of handling multiple modalities.\n\n(Figure 2) The bimodal case returns weighted activation by gains of gating units, do you do anything special to keep multi-modal case weighted as well? I.e. how the equation for h in section 3.1 would look like for multi-modal case. Also what\u2019s the rationale for using tanh nonlinearity (over, say RELU), is it somehow experimentally optimised choice?\n\nI would find interesting a discussion on a possibility of handling missing data in case one or more modalities are unavailable at test time. Is this possible in the current model to back-off to fewer modalities? Synthetic example may suggest that\u2019s in fact possible. Those numbers, perhaps, could be added to table 2.\n\nIn the synthetic experiment, you should compare MGU with the fully-connected MLP model really, with similar complexity - that is - at least two hidden units (as GMU has two such for each modality) followed by logistic regression. At least in terms of capability of drawing decision boundary, those should be comparable.\n\nI think, broader discussion shall be written on the related work associated with mixture of experts models (which is fact are very similar conceptually) as well as multiplicative RNN models [1]. Also, gating unit in LSTM can, in principle, play very similar role when multiple modalities are spliced in the input.\n\nOverall, the paper is interesting, so is the associated (and to be released) dataset.\n\nMinor comments/typos:\n\nSec. 3.3:  layers and a MLP (see Section 3.4) -> layers and an MLP\n\nApologies for unacceptably late review.\n\n[1] Multiplicative LSTM for sequence modelling B Krause, L Lu, I Murray, S Renals\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "21 Dec 2016 (modified: 19 Jan 2017)", "REVIEWER_CONFIDENCE": 5}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "TITLE": "Promising work, but too preliminary for a major conference", "is_meta_review": false, "comments": "The paper introduces Gated Multimodal Units GMUs, which use multiplicative weights to select the degree to which a hidden unit will consider different modalities in determining its activation.  The paper also introduces a new dataset, \"Multimodal IMDb,\" consisting of over 25k movie summaries, with their posters, and labeled genres.\n\nGMUs are related to \"mixture of experts\" in that different examples will be classified by different parts of the model, (but rather than routing/gating entire examples, individual hidden units are gated separately).  They are related to attention models in that different parts of the input are weighted differently; there the emphasis is on gating modalities of input.\n\nThe dataset is a very nice contribution, and there are many experiments varying text representation and single-modality vs two-modality.  What the paper is lacking is a careful discussion, experimentation and analysis in comparison to other multiplicative gate models---which is the core intellectual contribution of the paper.  For example, I could imagine that a mixture of experts or attention models or other gated models might perform very well, and at the very least provide interesting scientific comparative analysis.  I encourage the authors to continue the work, and submit a revised paper when ready.\n\nAs is, I consider the paper to be a good workshop paper, but not ready for a major conference.", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "GMU is an interesting model, but still it is not straighforward to understand how much better than baselines", "is_meta_review": false, "comments": "This paper proposed The Gated Multimodal Unit (GMU) model for information fusion. The GMU learns to decide how modalities influence the activation of the unit using multiplicative gates. The paper collected a large genre dataset from IMDB and showed that GMU gets good performance.\n\nThe proposed approach seems quite interesting, and the audience may expect it can be used in general scenarios beyond movie genre prediction. So it is quite straightforward that the paper should test the algorithm in other applications, which was not done yet. That is the biggest shortcoming of this paper in my opinions.  \n\nAnother concern lies in how to evaluate the performance of information fusion. The abstract claims \"The model improves the macro f-score performance of single-modality models by 30% and 4% with respect to visual and textual information respectively\", however, such an improvement is off the key. If two modals are complementary to each other, the fusion results will always be higher. The key fact is how much better than baselines the proposed GMU is. There is a long list of techniques for fusions, so it is difficult to conduct an impressive comparison on only one real dataset. I think GMU did a nice work on movie dataset, but I would also expect other techniques, including fine-tuning, dropout, distillation may help too.  It would be nice if the author could compare these techniques. \n\nI also hope this paper could talk in more details the connection with mixture-of-expert (MoE) model. Both models are based on the nonlinear gated functions, while both method may suffer from local minimum for optimization on small datasets. I would like more in-depth discussion in their similarity and difference.\n\nTo gain more attention for GMU, I would encourage the author to open-source their code and try more datasets.", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016 (modified: 24 Jan 2017)", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "New revision submitted", "OTHER_KEYS": "John Arevalo", "comments": "Following your comments, we've added a new revision which includes:\n  - More details on parameter exploration and training procedure.\n  - Updates on multimodal baseline and synthetic results.\n  - Histogram for image sizes.\n  - Link to the dataset webpage.\n  - Plot depicting the influence of each modality in the label assignment.\n\nThanks again for your feedback.", "IS_META_REVIEW": false, "DATE": "13 Dec 2016", "is_meta_review": false}, {"TITLE": "Questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "", "IS_META_REVIEW": false, "DATE": "04 Dec 2016", "is_meta_review": false}, {"TITLE": "several questions on experiments", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "IS_META_REVIEW": false, "DATE": "22 Nov 2016", "is_meta_review": false}], "authors": "John Arevalo, Thamar Solorio, Manuel Montes-y-G\u00f3mez, Fabio A. Gonz\u00e1lez", "KEYWORDS": "Gated Multimodal Units: a novel unit that learns to combine multiple modalities using multiplicative gates", "accepted": false, "id": ""}
