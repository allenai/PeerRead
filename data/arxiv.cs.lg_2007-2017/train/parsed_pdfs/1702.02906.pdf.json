{
  "name" : "1702.02906.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Switching EEG Headsets Made Easy: Reducing Offline Calibration Effort Using Active Weighted Adaptation Regularization",
    "authors" : [ "Dongrui Wu" ],
    "emails" : [ "drwu09@gmail.com).", "vernon.j.lawhern.civ@mail.mil).", "william.d.hairston4.civ@mail.mil,", "brent.j.lance.civ@mail.mil)." ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 2.\n02 90\n6v 1\n[ cs\n.L G\n] 9\nF eb\n2 01\nIndex Terms—EEG; event-related potential; visual evoked potential; single-trial classification; transfer learning; domain adaptation; weighted adaptation regularization; active learning; active transfer learning; active weighted adaptation regularization\nI. INTRODUCTION\nELECTROENCEPHALOGRAPHY (EEG) headsets arethe most commonly used sensing devices for BrainComputer Interface (BCI), which have been employed in many applications, such as healthcare and gaming [15], [18], [26],\nManuscript received June 16, 2015; revised January 13, 2016; accepted March 10, 2016. Research was sponsored by the U.S. Army Research Laboratory and was accomplished under Cooperative Agreement Numbers W911NF-10-2-0022 and W911NF-10-D-0002/TO 0023. The views and the conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Army Research Laboratory or the U.S Government.\nD. Wu is with DataNova, Clifton Park, NY USA (email: drwu09@gmail.com).\nV. J. Lawhern is with the Human Research and Engineering Directorate, U.S. Army Research Laboratory, Aberdeen Proving Ground, MD USA. He is also with the Department of Computer Science, University of Texas at San Antonio, San Antonio, TX USA (emails: vernon.j.lawhern.civ@mail.mil).\nW. D. Hairston and B. J. Lance are with the Human Research and Engineering Directorate, U.S. Army Research Laboratory, Aberdeen Proving Ground, MD USA (emails: william.d.hairston4.civ@mail.mil, brent.j.lance.civ@mail.mil).\nColor versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org.\nDigital Object Identifier XXXXXXXXXXX.\n[44], [49], because of the general ease of setup for normal individuals. However, BCI applications have not received widespread acceptance for real-world applications. One reason for this is the inability of BCI technologies to adapt to the numerous potential sources of variation inherent in the underlying technologies. These can include human sources of variability, such as individual differences and intra individual variability. They can also include sources of variability in the technology, such as unintentional differences in recording locations for the EEG electrodes from session to session, or even differences between different EEG headsets. To date, this latter source remains largely unexplored.\nThere are many existing EEG headsets, with new models and styles continually becoming available [14]. Ideally, EEG classification methods should be completely independent from any specific EEG hardware, such that classifiers trained using data from one EEG headset will be transferable to other headsets with little or no recalibration. This would help ensure that applications could reach a broad base of users and would not become obsolete through hardware upgrades. However, evidence comparing the performance of various classifiers when using different headsets has shown that often performance is not equal across systems; that is, the headset does in fact matter [30]. From a hardware standpoint, systems can vary along a number of dimensions, including (but not limited to) onboard filter characteristics, electrode types and contact methods, electrode locations, or online reference schemes. All of these inherently change the resulting signal characteristics, some of which are critical features on which the classifiers operate.\nThus, it is not surprising that currently switching to a new or different headset requires the subject to re-calibrate it, which can take anywhere from 5-20 minutes [44]. When implemented into a BCI system this calibration session would decrease the utility and appeal of the overall system, likely slowing the rate of acceptance. While it is not currently possible to switch between EEG headsets completely calibrationfree, it is certainly possible to decrease the amount of time and data needed to calibrate an EEG data classifier for use with another EEG system.\nIn this paper, we specifically attempt to address the problem of developing classifiers that can account for variation due to different EEG headsets within a transfer learning (TL) [27] framework. In TL, some data from a prior calibration or other user sessions is used to facilitate learning of the calibration in\n2 a new target context. According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications:\n1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features. These features are generally better than extracting features directly from only the limited number of samples from a new subject or session. 2) Instance transfer [21], [22], [52], [55], which uses certain parts of the data from other subjects or sessions to help the learning for the current subject or session. The underlying assumption is that data distributions for these subjects or sessions are similar. 3) Classifier transfer, which includes domain adaptation [1], [35], [46], i.e., handling the different data distributions for different subjects or sessions, and ensemble learning [39], [40], i.e., combining multiple classifiers from multiple subjects or sessions, and their combinations [50], [53], [54].\nIn our case, data acquired from one style of headset is used to facilitate classification of data currently being acquired from a different one, through domain adaptation and regularized optimization [36], [38], [57]. We look at this problem within the context of offline single-trial Event-Related Potential (ERP) classification, with the eventual goal of moving to online single-trial classification within a BCI system.\nIn some application domains, we have existing unlabeled data and the calibration session is focused on labeling this data, e.g., BCI applications focused on labeling images, using EEG data [37], [43]. In these applications, the user can manually label a few images, and based on the EEG signals associated with these images a classifier can be trained to automatically label the rest. Improved calibration performance can be achieved by selecting the most informative images for manual labeling. In other words, a desired level of calibration performance can be obtained with less labeling effort if the most informative images are selected for labeling. This is the idea of active learning (AL) [33], which has also started to find application in BCI [9], [19], [25]. For example, in our recent work on EEG artifacts classification [19], we showed that classification accuracy equivalent to classifiers trained on full data annotation can be obtained while labeling less than 25% of the data by AL. In another study [25], we applied AL to a simulated BCI system for target identification using data from a rapid serial visual presentation paradigm, and showed that it can produce similar overall classification accuracy with significantly less labeled data (in some cases less than 20%) when compared to alternative calibration approaches.\nTL and AL are complementary to each other, and hence can be integrated to further reduce the number of labeled training samples in offline BCI calibration. The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58]. However, most of this work is outside of the EEG analysis domain. In our previous work [51], we investigated how TL and AL can be integrated to reduce the amount of subject-specific calibration data in a\nVisual-Evoked Potential (VEP) task, by making use of data collected using the same headset but from other subjects; in contrast, this paper considers the problem of reducing subjectspecific calibration data when the same subject switches from one headset to another.\nThis paper introduces weighted adaptation regularization (wAR), a particular TL algorithm, and designs a novel AL algorithm for it. Using a single-trial ERP experiment, we demonstrate that wAR can achieve improved performance over the TL approach used in [51], and active weighted adaptation regularization (AwAR), which integrates wAR and AL, can further reduce the offline calibration effort when switching between different EEG headsets. It should be noted that, while the ultimate goal is an understanding of how well these approaches work when transferring both within and across subjects, here, in order to minimize sources of variability, our analyses are focused on within subjects TL.\nThe rest of the paper is organized as follows: Section II introduces the details of wAR. Section III introduces the details of AwAR. Section IV describes experimental results and a performance comparison of wAR and AwAR with other algorithms. Section V draws conclusions."
    }, {
      "heading" : "II. WEIGHTED ADAPTATION REGULARIZATION (WAR)",
      "text" : "This section introduces the details of the wAR algorithms. We consider two-class classification of EEG data, but the algorithms can also be generalizable to other calibration problems."
    }, {
      "heading" : "A. Problem Definition",
      "text" : "Given a large amount of labeled EEG epochs from one headset, how can that data be used to customize a classifier for a different headset? Although EEG epochs from the two headsets are usually not completely consistent, previous data still contain useful information, due to the fact that they came from the same subject. As a result, the amount of calibration data may be reduced if these auxiliary EEG epochs are used properly.\nTL [27], [56], particularly wAR, is a framework for addressing the aforementioned problem. Some notations used in TL and wAR are introduced next.\nDefinition 1: (Domain) [23], [27] A domain D is composed of a d-dimensional feature space X and a marginal probability distribution P (x), i.e., D = {X , P (x)}, where x ∈ X .\nIf two domains Ds and Dt are different, then they may have different feature space, i.e., Xs 6= Xt, and/or different marginal probability distributions, i.e., Ps(x) 6= Pt(x) [23].\nDefinition 2: (Task) [23], [27] Given a domain D, a task T is composed of a label space Y and a prediction function f(x), i.e., T = {Y, f(x)}.\nLet y ∈ Y , then f(x) = Q(y|x) can be interpreted as the conditional probability distribution. If two tasks Ts and Tt are different, then they may have different label spaces, i.e., Ys 6= Yt, and/or different conditional probability distributions, i.e., Qs(y|x) 6= Qt(y|x) [23].\nDefinition 3: (Domain Adaptation) Given a source domain DS = {(x1, y1), ..., (xn, yn)}, and a target domain DT with ml labeled samples {(xn+1, yn+1), ..., (xn+ml , yn+ml)} and\n3 mu unlabeled samples {xn+ml+1, ...,xn+ml+mu}, domain adaptation transfer learning aims to learn a target prediction function f : xt 7→ yt with low expected error on Dt, under the assumptions Xs = Xt, Ys = Yt, Ps(x) 6= Pt(x), and Qs(y|x) 6= Qt(y|x).\nIn our application, EEG epochs from the new headset are in the target domain, while EEG epochs from the previous headset are in the source domain. A single data sample would consist of the feature vector for a single EEG epoch from a headset, collected as a response to a specific stimulus. Though the features in source and target domains are computed in the same way, generally their marginal and conditional probability distributions are different, i.e., Ps(x) 6= Pt(x) and Qs(y|x) 6= Qt(y|x), because the two headsets may have different sensor locations, filters, and signal fidelity. As a result, the auxiliary data from the source domain cannot represent the primary data in the target domain accurately and must be integrated with some labeled data in the target domain to induce the target predictive function."
    }, {
      "heading" : "B. The Learning Framework",
      "text" : "Because\nf(x) = Q(y|x) = P (x, y)\nP (x) =\nQ(x|y)P (y)\nP (x) , (1)\nto use the source domain data in the target domain, we need to make sure1 Ps(xs) is close to Pt(xt), and Qs(xs|ys) is also close to Qt(xt|yt).\nLet the classifier be f = wTφ(x), where w is the classifier parameters, and φ : X 7→ H is the feature mapping function that projects the original feature vector to a Hilbert space H. The learning framework of wAR is formulated as:\nf =argmin f∈HK\nn ∑\ni=1\nws,iℓ(f(xi), yi) + wt\nn+ml ∑\ni=n+1\nwt,iℓ(f(xi), yi)\n+ σ‖f‖2K + λPDf,K(Ps, Pt) + λQDf,K(Qs, Qt) (2)\nwhere ℓ is the loss function, wt is the overall weight of target domain samples, K ∈ R(n+ml+mu)×(n+ml+mu) is the kernel function induced by φ such that K(xi,xj) = 〈φ(xi), φ(xj)〉, and σ, λP and λQ are non-negative regularization parameters. wt is the overall weight for target domain samples, which should be larger than 1 so that more emphasis is given to target domain samples than source domain samples. ws,i is the weight for the ith sample in the source domain, and wt,i is the weight for the ith sample in the target domain, i.e.,\nws,i =\n{\n1, xi ∈ Ds,1 n1/(n− n1), xi ∈ Ds,2\n(3)\nwt,i =\n{\n1, xi ∈ Dt,1 m1/(ml −m1), xi ∈ Dt,2\n(4)\nin which Ds,c = {xi|xi ∈ Ds ∧ yi = c} is the set of samples in Class c of the source domain, and Dt,c = {xj |xj ∈ Dt ∧ yj = c} is the set of samples in Class c of the target domain,\n1Strictly speaking, we should make sure Ps(y) is also close to Pt(y). However, in this paper we assume all subjects conduct similar VEP tasks, so Ps(y) and Pt(y) are intrinsically close. Our future research will consider the more general case that Ps(y) and Pt(y) are different.\nnc = |Ds,c| and mc = |Dt,c|. The goal of ws,i and wt,i is to balance the number of positive and negative samples in source and target domains, respectively.\nBriefly speaking, the meanings of the five terms in (2) are:\n1) The 1st term minimizes the loss on fitting the labeled samples in the source domain. 2) The 2nd term minimizes the loss on fitting the labeled samples in the target domain. 3) The 3rd term minimizes the structural risk of the classifier. 4) The 4th term minimizes the distance between the marginal probability distributions Ps(xs) and Pt(xt). 5) The 5th term minimizes the distance between the conditional probability distributions Qs(xs|ys) and Qt(xt|yt).\nBy the Representer Theorem [2], [23], the solution of (2) admits an expression:\nf(x) =\nn+ml+mu ∑\ni=1\nαiK(xi,x) = α TK(X,x) (5)\nwhere X = [x1, ...,xn+ml+mu ] T , and α = [α1, ..., αn+ml+mu ] T are coefficients to be computed.\nNote that our algorithm formulation and derivation closely resemble those in [23]; however, there are several major differences:\n1) We consider the scenario that there are a few labeled samples in the target domain, whereas [23] assumes there are no labeled samples in the target domain. 2) We explicitly consider the class imbalance problem in both domains by introducing the weights on samples from different classes. 3) wAR is iterative and we further design an AL algorithm for it, whereas in [23] domain adaptation is performed only once and there is no AL. 4) [23] also considers manifold regularization [2]. We investigated it, but we were not able to achieve improved performance in our application, so we excluded it in this paper.\nAlso note that one of the wAR algorithms (wAR-RLS) described in this paper was introduced in our previous publication [54]; however, this paper includes a new wAR algorithm (wAR-SVM), and shows how AL can be integrated with wAR-RLS and wAR-SVM. The application scenario is also different."
    }, {
      "heading" : "C. Loss Functions Minimization",
      "text" : "Two widely used loss functions are the squared loss for regularized least squares (RLS):\nℓ(f(xi), yi) = (yi − f(xi)) 2 (6)\nand the hinge loss for support vector machines (SVMs):\nℓ(f(xi), yi) = max(0, 1− yif(xi)) (7)\nBoth will be considered in this paper. In the following, we denote the classifier obtained using squared loss as wAR-RLS, and the one obtained using hinge loss as wAR-SVM.\n4 1) Squared Loss: Let\ny = [y1, ..., yn+ml+mu ] T (8)\nwhere {y1, ..., yn} are known labels in the source domain, {yn+1, ..., yn+ml} are known labels in the target domain, and {yn+ml+1, ..., yn+ml+mu} are pseudo labels for the unlabeled target domain samples, i.e. labels estimated using another classifier and known samples in both source and target domains.\nDefine E ∈ R(n+ml+mu)×(n+ml+mu) as a diagonal matrix with\nEii =\n\n\n ws,i, 1 ≤ i ≤ n wtwt,i, n+ 1 ≤ i ≤ n+ml 0, otherwise\n(9)\nSubstituting (6) into the first two terms in (2), it follows that\nn ∑\ni=1\nws,iℓ(f(xi), yi) + wt\nn+ml ∑\ni=n+1\nwt,iℓ(f(xi), yi)\n=\nn ∑\ni=1\nws,i(yi − f(xi)) 2 + wt\nn+ml ∑\ni=n+1\nwt,i(yi − f(xi)) 2\n=\nn+ml+mu ∑\ni=1\nEii(yi − f(xi)) 2\n=(yT −αTK)E(y −Kα) (10)\n2) Hinge Loss: Using the hinge loss and E defined in (9), the first two terms on the right-hand side of (2) can be reexpressed as:\nn ∑\ni=1\nws,iℓ(f(xi), yi) + wt\nn+ml ∑\ni=n+1\nwt,iℓ(f(xi), yi)\n= n ∑\ni=1\nws,i max(0, 1− yif(xi))\n+ wt\nn+ml ∑\ni=n+1\nwt,imax(0, 1− yif(xi))\n=\nn+ml+mu ∑\ni=1\nEii max (0, 1− yif(xi)) (11)\nOften in SVM formulations, an unregularized bias term b is added to (5), i.e.,\nf(x) =\nn+ml+mu ∑\ni=1\nαiK(xi,x) + b = α TK(X,x) + b (12)\nWe also use this convention in this paper. Then, by introducing non-negative slack variables ξi (i = 1, 2, ..., n+ml+mu), the minimization of (11) is equivalent to:\nmin α∈Rn+ml+mu\nξ∈Rn+ml\nn+ml ∑\ni=1\nEiiξi (13)\ns.t. yi\n\n\nn+ml+mu ∑\nj=1\nαjK(xi,xj) + b\n\n ≥ 1− ξi\nξi ≥ 0, i = 1, ..., n+ml"
    }, {
      "heading" : "D. Structural Risk Minimization",
      "text" : "As in [23], [45], we define the structural risk as the squared norm of f in HK , i.e.,\n‖f‖2K =\nn+ml+mu ∑\ni=1\nn+ml+mu ∑\nj=1\nαiαjK(xi,xj) = α TKα (14)"
    }, {
      "heading" : "E. Marginal Probability Distribution Adaptation",
      "text" : "Similar to [23], [28], we compute Df,K(Ps, Pt) using the projected maximum mean discrepancy (MMD):\nDf,K(Ps, Pt) =\n[\n1\nn\nn ∑\ni=1\nf(xi)− 1\nml +mu\nn+ml+mu ∑\ni=n+1\nf(xi)\n]2\n=αTKM0Kα (15)\nwhere M0 ∈ R(n+ml+mu)×(n+ml+mu) is the MMD matrix:\n(M0)ij =\n\n  \n \n1 n2\n, 1 ≤ i ≤ n, 1 ≤ j ≤ n 1\n(ml+mu)2 , n+ 1 ≤ i ≤ n+ml +mu,\nn+ 1 ≤ j ≤ n+ml +mu −1\nn(ml+mu) , otherwise\n(16)"
    }, {
      "heading" : "F. Conditional Probability Distribution Adaptation",
      "text" : "Similar to the idea proposed in [23], we first need to compute pseudo labels for the unlabeled target domain samples and construct the label vector y in (8). These pseudo labels can be borrowed directly from the estimates in the previous iteration if the algorithm is used iteratively, or estimated using another classifier, e.g., a SVM. We then compute the projected MMD w.r.t. each class. The distance between the conditional probability distributions in source and target domains is next computed as:\nDf,K(Qs, Qt)\n=\n2 ∑\nc=1\n\n\n1\nnc\n∑\nxi∈Ds,c\nf(xi)− 1\nmc\n∑\nxj∈Dt,c\nf(xj)\n\n\n2\n(17)\nwhere Ds,c, Dt,c, nc and mc have been defined under (4). Substituting (5) into (17), it follows that\nDf,K(Qs, Qt)\n=\n2 ∑\nc=1\n\n\n1\nnc\n∑\nxi∈Ds,c\nαTK(X,x)− 1\nmc\n∑\nxj∈Dt,c\nαTK(X,x)\n\n\n2\n=\n2 ∑\nc=1\nαTKMcKα = α TKMKα (18)\nwhere\nM = M1 +M2 (19)\nin which M1 and M2 are MMD matrices computed as:\n(Mc)ij =\n\n    \n    \n1/n2c, xi,xj ∈ Ds,c 1/m2c, xi,xj ∈ Dt,c −1/(ncmc), xi ∈ Ds,c,xj ∈ Dt,c, or xj ∈ Ds,c,xi ∈ Dt,c 0, otherwise\n(20)\n5"
    }, {
      "heading" : "G. wAR-RLS: The Closed-Form Solution",
      "text" : "Substituting (10), (14), (15), and (18) into (2), it follows that\nf = argmin f∈HK\n(yT −αTK)E(y −Kα) + σαTKα\n+αTK(λPM0 + λQM)Kα (21)\nSetting the derivative of the objective function above to 0 leads to\nα = [(E + λPM1 + λQM)K + σI] −1Ey (22)"
    }, {
      "heading" : "H. wAR-SVM Solution",
      "text" : "Substituting (13), (14), (15), and (18) into (2), then α in (5) can be re-expressed as:\nα = argmin α∈Rn+ml+mu\nξ∈Rn+ml\nn+ml ∑\ni=1\nEiiξi + σα TKα\n+αTK(λPM0 + λQM)Kα (23)\ns.t. yi\n\n\nn+ml+mu ∑\nj=1\nαjK(xi,xj) + b\n\n ≥ 1− ξi\nξi ≥ 0, i = 1, ..., n+ml\nDefine\nβ = [α; ξ; b]\nf = [01×(n+ml+mu) ws,1 · · · ws,n wtwt,1 · · · wtwt,ml 0]\nH =\n[\nσK +K(λPM0 + λQM)K 0 (n+ml+mu)×(n+ml+1)\n0(n+ml+1)×(n+m) 0(n+ml+1)×(n+ml+1)\n]\nA = −[A′ I(n+ml)×(n+ml) y]\nB = diag([01×(n+ml+mu) 11×(n+ml) 0])\nb = −1(n+ml)×1\nwhere A′ ∈ R(n+ml)×(n+ml) and A′i,j = yiKi,j , 01×(n+ml+mu) ∈ R1×(n+ml+mu) is a vector of all zeros, 11×(n+ml) ∈ R1×(n+ml) is a vector of all ones, and I(n+ml)×(n+ml) ∈ R(n+ml)×(n+ml) is the identity matrix.\nThen, solving for α and b in (23) is equivalent to solving for β below:\nβ = argmin β∈R2n+2ml+mu+1\nβ THβ + fβ (24)\ns.t. A · β ≤ b\nB · β ≥ 0\nwhich can be easily done using quadratic programming. In summary, the pseudo code for wAR-RLS and wAR-SVM is shown in the first part of Algorithm 1."
    }, {
      "heading" : "III. ACTIVE WEIGHTED ADAPTATION REGULARIZATION",
      "text" : "(AWAR)\nAs mentioned in the Introduction, wAR can be integrated with AL [33] for better performance. AL tries to select the most informative samples to label so that a given learning performance can be achieved with less labeling effort. The\nAlgorithm 1: The active weighted adaptation regularization (AwAR) algorithm.\nInput: n labeled source domain samples, {xi, yi}ni=1; ml labeled target domain samples, {xj , yj} n+ml j=n+1; mu unlabeled target domain samples, {xj}\nn+ml+mu j=n+ml+1\n; Parameters wt, σ, λP , and λQ; k, number of unlabeled target domain samples to\nlabel. Output: {y′j} n+ml+mu j=n+ml+1\n, estimated labels of the mu unlabeled target domain samples; Indices of k target domain samples to label.\n// wAR begins Compute ws,i and wt,i by (3) and (4); Compute the kernel matrix K; Construct {yj}\nn+ml+mu j=n+ml+1\n, pseudo labels for the mu unlabeled target domain samples, using the estimates from the previous iteration, or build another classifier (e.g., a basic SVM) to estimate the pseudo labels if this is the first iteration; Construct y in (8), E in (9), M0 in (16), and M in (19); Compute α by (22) for wAR-RLS, or α and b by (24) for wAR-SVM; Compute {f(xj)}\nn+ml+mu j=n+ml+1\nby (5) for wAR-RLS, or by (21) for wAR-SVM; Return {y′j} n+ml+mu j=n+ml+1\n, where y′j = sign(f(xj)); // wAR ends; AL begins Construct Jd = {j|yj 6= y ′ j , n+ml + 1 ≤ j ≤ n+ml +mu}; Sort Jd in ascending order according to |f(xj)|, j ∈ Jd; Construct Js = {j|yj = y ′ j , n+ml + 1 ≤ j ≤ n+ml +mu}; Sort Js in ascending order according to |f(xj)|, j ∈ Js; Concatenate Jd and Js to form an ordered set J = {Jd, Js}; Return The first k elements in J . // AL ends\nkey problem in using AL is estimating which of the data samples are the most informative. There are many different heuristics for this purpose [33]. In this paper we select the most volatile and uncertain ones as the most informative ones. More sophisticated approaches will be studied in our future research2."
    }, {
      "heading" : "A. Active Learning",
      "text" : "Our AL for identifying the k most informative samples is a two-step procedure: the first step identifies the most volatile unlabeled target domain samples, and the second step further selects the k most uncertain ones from them.\nRecall that at the beginning of wAR we obtain {yj}\nn+ml+mu j=n+ml+1\n, the pseudo labels for unlabeled target domain samples, from the previous iteration, and finally we output\n2We attempted the active learning approaches in [5], [16] but failed to observe better performance than the method proposed in this section.\n6 {y′j} n+ml+mu j=n+ml+1\n, the updated estimates of these labels. If y′j is different from yj for a certain sample, then there is evidence that that sample is volatile, probably because it is close to the decision boundary. According to the volatility of the unlabeled target domain samples, we partition them into two groups: Jd = {j|yj 6= y ′ j, n + ml + 1 ≤ j ≤ n + ml + mu} and Js = {j|yj = y ′ j, n+ml + 1 ≤ j ≤ n+ml +mu}. Samples in Jd are more volatile than those in Js, and hence they are better candidates for labeling.\nWe further rank the uncertainties of the samples in Jd by their closeness to the current decision boundary: a sample closer to the decision boundary means the classifier has more uncertainty about its class, and hence we should select it for labeling in the next iteration. To do this, we first sort Jd in ascending order according to |f(xj)|. Since a smaller |f(xj)| means a closer distance to the decision boundary and hence higher uncertainty, we select the first k samples in Jd for labeling in the next iteration. If k is larger than the number of samples in Jd, then we also sort Js in ascending order according to |f(xj)| and select the first k−|Jd| samples from it."
    }, {
      "heading" : "B. The Complete AwAR Algorithm",
      "text" : "The complete AwAR algorithm is given in Algorithm 1. We denote the one based on wAR-RLS as AwAR-RLS, and the one based on wAR-SVM as AwAR-SVM. In each algorithm, we first use wAR to classify the unlabeled target domain samples, and then AL to identify k such samples that are most volatile and uncertain. AwAR-RLS and AwAR-SVM can easily be embedded into an iterative procedure (Section IV-C) so that k target domain samples are labeled in each iteration until the maximum number of iterations is reached, or the desired classification performance is achieved."
    }, {
      "heading" : "C. Make Use of the Extra Channels",
      "text" : "In Algorithm 1, we assume the source and target domains have consistent features, i.e., the old and new headsets have same channels so that the features extracted from them have the same dimensionality and meaning. This also works if the old headset has more channels, but it includes all channels in the new headset, in which case only the common channels are used in feature extraction. However, things become more complicated if the new headset has channels that are not included in the old headset. We can again use the common channels for feature extraction and then apply Algorithm 1, but there is information loss if the extra channels in the new headset are completely ignored. We next propose a solution for this problem.\nThe extra channels are difficult to use in wAR, because the target domain does not contain them. However, it is possible to use them in AL, as shown in Algorithm 2, which can be used to replace the AL part in Algorithm 1. Algorithm 2 still consists of two steps. The first step identifies the most volatile unlabeled target domain samples, which is the same as that in the original AL algorithm. The second step ranks the uncertainties of the unlabeled samples by incorporating the uncertainty information from all channels (common channels\nplus extra channels). For that we first build a separate classifier using features extracted from all channels and trained from only the ml labeled samples. For each unlabeled sample, we compute the sum of two signed distances: 1) the distance from the decision boundary determined by this additional classifier, and 2) the distance from the decision boundary determined by wAR. The smaller the sum, the larger the uncertainty. We then return the top k unlabeled samples that are volatile and most uncertain.\nAlgorithm 2: The active learning (AL) algorithm for making use of extra channels in the target domain.\n// wAR ends; AL begins Design another classifier, e.g., a SVM, to classify the mu unlabeled target domain samples using features from all channels; denote the signed distances to its decision boundary as {g(xj)}\nn+ml+mu j=n+ml+1 ; Jd = {j|yj 6= y ′ j , n+ml + 1 ≤ j ≤ n+ml +mu}; Sort Jd in ascending order according to |f(xj) + g(xj)|, j ∈ Jd; Js = {j|yj = y ′ j , n+ml + 1 ≤ j ≤ n+ml +mu}; Sort Js in ascending order according to |f(xj) + g(xj)|, j ∈ Js; Concatenate Jd and Js to form the ordered set J = {Jd, Js}; Return The first k elements in J . // AL ends"
    }, {
      "heading" : "IV. EXPERIMENTS AND DISCUSSIONS",
      "text" : "Experimental results are presented in this section to compare wAR-RLS, wAR-SVM, AwAR-RLS, and AwAR-SVM with several other algorithms."
    }, {
      "heading" : "A. Experiment Setup",
      "text" : "We used data from a VEP oddball task [30]. In this task, image stimuli were presented to subjects at a rate of 0.5 Hz (one image every two seconds). The images presented were either an enemy combatant [target; an example is shown in Fig. 1(a)] or a U.S. Soldier [non-target; an example is shown in Fig. 1(b)]. The subjects were instructed to identify each image as being target or non-target with a unique button press as quickly, but as accurately, as possible. There were a total of 270 images presented to each subject, of which 34 were targets. The experiments were approved by the U.S. Army Research Laboratory (ARL) Institutional Review Board (Protocol # 20098-10027). The voluntary, fully informed consent of the persons used in this research was obtained as required by federal and Army regulations [41], [42]. The investigator adhered to Army policies for the protection of human subjects.\nEighteen subjects participated in the experiments, which lasted on average 15 minutes. Data from four subjects were not used due to data corruption or poor responses. Signals were recorded with three different EEG headsets, including a wired 64-channel ActiveTwo3 system (sample rate set to\n3http://www.biosemi.com/products.htm\n7 (a) (b)\nFig. 1. Example images of (a) a target; (b) a non-target.\n512Hz) from BioSemi, a wireless 9-channel 256Hz B-Alert X10 EEG Headset System4 from Advanced Brain Monitoring (ABM), and a wireless 14-channel 128Hz EPOC headset5 from Emotiv. We considered switching between BioSemi and Emotiv headsets, and between BioSemi and ABM headsets, respectively. Switching between Emotiv and ABM headsets was not considered because they have too few common channels."
    }, {
      "heading" : "B. Preprocessing and Feature Extraction",
      "text" : "We used EEGLAB [10] for EEG signal preprocessing and feature extraction. Raw amplitude features were used in this study. The performances of AwAR-RLS and AwAR-SVM on other feature sets are studied later in this section.\nFor switching between BioSemi and Emotiv headsets, we used their 14 common channels (AF3, AF4, F3, F4, F7, F8, FC5, FC6, O1, O2, P7, P8, T7, T8). For switching between BioSemi and ABM headsets, we used their nine common channels (C3, C4, Cz, F3, F4, Fz, P3, P4, POz). For each headset, we first band-passed the EEG signals to [1, 50] Hz, then downsampled them to 64 Hz, performed average reference, and next epoched them to the [0, 0.7] second interval timelocked to stimulus onset. We removed mean baseline from each channel in each epoch and removed epochs with incorrect button press responses6. The final numbers of epochs from the 14 subjects are shown in Table I. Observe that there is significant class imbalance for all headsets; that’s why we need to use ws,i and wt,i in (2) to balance the two classes in both domains.\nEach [0, 0.7] second epoch contains 45 raw EEG magnitude samples. The concatenated feature vector has hundreds of dimensions. To reduce the dimensionality, we combined concatenated feature vectors from the old and new headsets, performed a simple principal component analysis (PCA), and took only the scores for the first 20 principal components (PCs). We then normalized each feature dimension separately to [0, 1] for each subject.\n4http://www.advancedbrainmonitoring.com/xseries/x10/ 5https://emotiv.com/epoc.php 6Button press responses were not recorded for the ABM headset, so we\nused all epochs from it."
    }, {
      "heading" : "C. Evaluation Process and Performance Measures",
      "text" : "Although we know the labels of all EEG epochs from all headsets for each subject, we simulate a different scenario, as shown in Fig. 2: all EEG epochs from the old headset are labeled, but none of the epochs from the new headset is initially labeled. Our approach is to iteratively label some epochs from the new headset, and then to build a classifier to label the rest of the epochs. The goal is to achieve the highest classification accuracy for the epochs from the new headset, with as few labeled epochs as possible.\nThe following three performance measures were used:\n1) False positive rate (FPR), which is the number of false positives (the number of non-targets which were mistakenly classified as targets) divided by the number of true negatives (non-targets). 2) False negative rate (FNR), which is the number of false negatives (the number of targets which were mistakenly classified as non-targets) divided by the number of true positives (targets). 3) Balanced classification accuracy (BCA), which is the average of classification accuracies on the positive (target) class and the negative (non-target) class. It can be shown that BCA = 1− (FPR+ FNR)/2."
    }, {
      "heading" : "D. Algorithms",
      "text" : "We compared the performances of wAR-RLS, wAR-SVM, AwAR-RLS and AwAR-SVM with three other algorithms:\n1) Baseline (BL), which is a simple iterative procedure: in each iteration we randomly select a few unlabeled training samples collected using the new headset, ask the subject to label them, add them to the labeled training dataset, and then train an SVM classifier by 5-fold crossvalidation. We iterate until the maximum number of iterations is reached. 2) The simple TL (TL) algorithm introduced in [51], which is very similar to BL, except that in each iteration it combines labeled samples from the old and new headsets in building an SVM classifier and then applies it to the unlabeled samples from the new headset.\n8\nTABLE I NUMBER OF EPOCHS FOR EACH SUBJECT AFTER PREPROCESSING. THE NUMBERS OF TARGET EPOCHS ARE GIVEN IN THE PARENTHESES.\nSubject 1 2 3 4 5 6 7 8 9 10 11 12 13 14 BioSemi 241(26) 260(24) 257(24) 261(29) 259(29) 264(30) 261(29) 252(22) 261(26) 259(29) 267(32) 259(24) 261(25) 269(33) Emotiv 263(28) 265(30) 266(30) 255(23) 264(30) 263(32) 266(30) 252(22) 261(26) 266(29) 266(32) 264(33) 261(26) 267(31) ABM 270(34) 270(34) 235(30) 270(34) 270(34) 270(34) 270(34) 270(33) 270(34) 239(30) 270(34) 270(34) 251(31) 270(34)\n3) The active TL (ATL) algorithm introduced in [51], which adds AL to the above TL: instead of randomly selecting unlabeled samples from the new headset to label, it selects those closest to the SVM decision boundary.\nWeighted LIBSVM [6] with a linear kernel was used as the classifier in BL, TL, ATL, wAR-SVM, and AwAR-SVM. Grid search was used to determine the optimal penalty parameter in LIBSVM for BL, TL and ATL. We chose wt = 2 in wARRLS, wAR-SVM, AwAR-RLS and AwAR-SVM to give the labeled target domain samples more weights, and σ = 0.1 and λP = λQ = 10, following the practice in [23]. In Section IV-H we present robustness analysis for AwAR-RLS and AwAR-SVM to σ, λP and λQ, and show that AwARRLS and AwAR-SVM are insensitive to them. Because there are labeled target domain samples, cross-validation could also be used to optimize these parameters. This will be considered in our future research."
    }, {
      "heading" : "E. Experimental Results",
      "text" : "All seven algorithms started with zero labeled samples from the new headset. In each iteration, five new EEG epochs were labeled and added to the training dataset. For BL, TL, wAR-RLS and wAR-SVM, these five were the same and were selected randomly from unlabeled samples. For ATL, AwAR-RLS and AwAR-SVM, these five were selected by their respective AL algorithms, so generally they were different in different algorithms.\nTo cope with randomness in these methods, each of them was repeated 30 times and the average results are shown. Because the AL-based algorithms are deterministic, we introduced randomness by randomly selecting (without replacement) 200 epochs from the old headset as data in the source domain, before running the seven algorithms. The average performances of the seven algorithms across the 14 subjects for the four switching scenarios are shown in Figs. 3 and 4. Observe that:\n1) Generally, the performance of BL increases as more samples from the new headset are labeled and added; however, it cannot build a model when there are no labeled samples at all from the new headset (observe that the first point on the BL curve is missing in every subfigure). On the contrary, without any labeled samples from the new headset, all other TL or wAR-based methods can build a model which has over 50%, many times much higher, BCA for most subjects, because they can transfer useful knowledge from the old headset to the new one. More specifically, the first point on the TL (or ATL) curve in each subfigure represents the BCA when the best classifier learned from the old headset\nis applied directly to the new headset. Observe that it is better than 50% (random guess) for most subjects. However, better BCAs can be obtained with wAR and AwAR. 2) Generally, all six TL or wAR-based methods outperform BL, which is expected, as TL and wAR get additional data from the old headset. 3) AwAR-RLS almost always achieves better performance (in terms of FPR, FNR, and BCA) than wAR-RLS, and AwAR-SVM almost always achieves better performance\n9 0 10 20 30 40 50 60 70 80 90 100 0 0.05 0.1 0.15 0.2 0.25 0.3\nml, number of labeled ABM samples\nFP R\n0 10 20 30 40 50 60 70 80 90 100 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nml, number of labeled ABM samples\nFN R\n0 10 20 30 40 50 60 70 80 90 100 0.5\n0.55\n0.6\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\nml, number of labeled ABM samples\nB C\nA\nBL STL wAR−RLS wAR−SVM ATL AwAR−RLS AwAR−SVM\n(a)\n0 10 20 30 40 50 60 70 80 90 100 0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\nml, number of labeled BioSemi samples\nFP R\n0 10 20 30 40 50 60 70 80 90 100 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nml, number of labeled BioSemi samples\nFN R\n0 10 20 30 40 50 60 70 80 90 100 0.5\n0.55\n0.6\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\nml, number of labeled BioSemi samples\nB C\nA\nBL STL wAR−RLS wAR−SVM ATL AwAR−RLS AwAR−SVM\n(b)\n5) Generally, wAR-RLS has similar performance to wARSVM, and AwAR-RLS also has similar performance to AwAR-SVM. However, since wAR-RLS and AwARRLS can be trained several times faster than wAR-SVM and AwAR-SVM, they are the preferred methods to use. This is also consistent with the observations in [23]."
    }, {
      "heading" : "F. Statistical Analysis",
      "text" : "We also performed comprehensive statistical tests to check if the BCA differences among the algorithms were statistically significant. To assess overall performance differences among all the algorithms, a measure called the area-underperformance-curve (AUPC) [25] was calculated. The AUPC is the area under the curve of the BCA values plotted at each of the 30 random runs and is normalized to [0, 1]. Larger AUPC values indicate better overall classification performance.\nFirst, we used Friedman’s test, a two-way non-parametric Analysis of Variance (ANOVA) where column effects are tested for significant differences after adjusting for possible row effects. We treated the algorithm type (BL, TL, wARRLS, wAR-SVM, ATL, AwAR-RLS, AwAR-SVM) as the column effects, with subjects as the row effects. Each combination of algorithm and subject had 30 values corresponding to 30 random runs performed. Friedman’s test showed statistically significant differences among the seven algorithms (p = .0000) across all four modes of transfer (BioSemi ↔ ABM, Emotiv ↔ BioSemi).\nThen, non-parametric multiple comparison tests using Dunn’s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method by [4]. This test was performed for each mode of transfer, and the results are shown in Tables II-V. Observe that in all cases, AL based methods (ATL, AwAR-SVM, AwARRLS) performed significantly better than the corresponding non-AL based methods. AwAR-RLS and AwAR-SVM always performed significantly better than BL, TL, wAR-RLS and wAR-SVM. Although AwAR-RLS and AwAR-SVM did not perform significantly better than ATL, the p-values were close to the threshold when switching from Emotiv to BioSemi (Table II), and from ABM to BioSemi (Table V). The BCA difference between AwAR-RLS and AwAR-SVM was always not statistically significant.\nIn summary, we have demonstrated that AwAR-RLS and AwAR-SVM can significantly improve the BCA, given the same number of labeled samples from the new headset. In other words, given a desired BCA, these algorithms can\n10\nsignificantly reduce the number of labeled samples from the new headset. For example, Figs. 3 and 4 show that on average, AwAR-RLS and AwAR-SVM can achieve the same BCA as BL, trained from 100 labeled samples from the new headset, using only 60 to 65 labeled samples. Figs. 3 and 4 also show that, without using any labeled samples from the new headset, on average AwAR-RLS and AwAR-SVM can achieve the same BCA as BL which is trained from about 25 labeled samples from the new headset."
    }, {
      "heading" : "G. Make Use of the Extra Channels (ECs)",
      "text" : "In the above experiments, we have only used the common channels between the old and new headsets. This is fine if all channels of the new headset are included in the old headset; however, there is information loss if the new headset has channels that do not present in the old headset. For example, when switching from Emotiv to BioSemi, the extra 64− 14 = 50 channels are completely ignored, whereas they may contain valuable information.\nIn this subsection, we replace the AL part in Algorithm 1 by Algorithm 2 to make use of the extra channels, and the corresponding algorithms are denoted as AwAR-RLS-EC and AwAR-SVM-EC. Because this modification only affects AwAR-RLS and AwAR-SVM, we do not present results from STL, wAR-RLS and wAR-SVM since they are the same as those in the last subsection. However, for comparison purpose, we include BL and ATL. We also added another baseline algorithm (BL-EC), which is similar to BL in the\nlast subsection but uses features extracted from all 64 BioSemi channels.\nThe average results across the 14 subjects are shown in Fig. 5, and the results for the individual subjects are shown in the Appendix. Observe from Fig. 5 that by making use of the extra channels, BL-EC had better FPR, FNR and BCA than BL, AwAR-RLS-EC had better FPR, FNR and BCA than AwAR-RLS, and AwAR-SVM-EC also had better FPR, FNR and BCA than AwAR-SVM. In summary, Algorithm 2 indeed allowed us to exploit new information in the extra channels to improve performance.\nWe also performed statistical tests to check if the BCA improvement with the extra channels were statistically significant. Friedman’s test showed statistically significant difference among the six learning algorithms (p = .0000) across both modes of transfer (Emotiv → Biosemi, ABM → Biosemi). Dunn’s procedure (Tables VI-VII) showed that BL-EC was always statistically better than BL. AwAR-SVM-EC was sta-\n11\ntistically better than AwAR-SVM when switching from ABM to BioSemi. With the help of the extra channels, AwAR-SVMEC had statistically better BCA than ATL when switching from Emotiv to BioSemi, and both AwAR-SVM-EC and AwAR-RLS-EC had statistically better BCAs than ATL when switching from ABM to BioSemi."
    }, {
      "heading" : "H. Robustness Analysis",
      "text" : "In this subsection we study the robustness of AwAR-RLS and AwAR-SVM to three different factors: the number of linear PC features, the feature sets extracted using different methods, and the parameters σ and λP (λQ). To save space, we only show the BCA results when switching from BioSemi to ABM. Similar results were obtained from other switching scenarios.\nThe average BCAs of AwAR-RLS and AwAR-SVM for different number of linear PCs are shown in Fig. 6. Observe that AwAR-RLS and AwAR-SVM are very robust to the number of PCs. 20 PCs were used in this paper mainly for the computational cost consideration.\nTwo other feature sets were employed to study the robustness of AwAR-RLS and AwAR-SVM to different feature\nextraction methods: 1) 20 nonlinear PCA features extracted from an auto-encoder [3]; and, 2) 18 power spectral density features [theta band (4-7.5Hz) and alpha band (7.5-12Hz)] from the 9 common channels using Welch’s method [48]. The BCA results are shown in Fig. 7. Observe that AwAR-RLS and AwAR-SVM still achieved the best overall BCAs in both cases, and they had more obvious performance improvements over other methods than the linear PCA case in Fig. 4(a). The BCAs of ATL decreased on these two feature sets, suggesting that ATL is not as robust as AwAR-RLS and AwAR-SVM to different features.\nThe average BCAs of AwAR-RLS and AwAR-SVM for different σ (λP and λQ were fixed at 10) are shown in Fig. 8(a), and for different λP and7 λQ (σ was fixed at 0.1) are shown in Fig. 8(b). Observe from Fig. 8 that AwAR-RLS and AwAR-SVM are robust to both σ and λP (λQ)."
    }, {
      "heading" : "I. Discussions",
      "text" : "Extensive experimental results have demonstrated that AwAR-RLS and AwAR-SVM can indeed reduce the calibration effort when switching to a new EEG headset, and they are very robust. However, they still have some limitations, which will be considered in our future research:\n1) AwAR-RLS and AwAR-SVM assume that the old and new headsets have enough common channels. We will need to quantify the minimum number of common channels for them to work well, and develop approaches\n7We always assigned λP and λQ identical value because they are conceptually close.\n12\nto perform transfer for headsets with none or very few common channels, e.g., more sophisticated feature extraction methods that allow compensation from closeby electrodes. 2) In the current study each subject performed the same task in three sessions on three different days, with the subject wearing a different headset each day. The headset difference was the most challenging problem in this transfer learning setting, but there could also be session transfer effects, e.g., nonstationarity of the brain, mind wandering, distraction, human-system mutual adaptation, environment impacts, physical condition changes, electrode re-positioning, etc. In future research we will conduct additional experiments, in which each subject wears the same headset in multiple sessions. By comparing the transfer learning performance between sessions with the same headset and between sessions with different headsets, we can separately study the effects of headset transfer and session transfer."
    }, {
      "heading" : "V. CONCLUSIONS",
      "text" : "In this paper, we have introduced two active weighted adaptation regularization approaches, which integrate domain adaptation transfer learning and active learning, to expedite the calibration process when a subject switches to a new EEG headset. Domain adaptation makes use of labeled data from the subject’s previous headset, whereas active learning selects the most informative samples from the new headset to be labeled. Experiments on single-trial classification of ERPs using three different EEG headsets showed that active weighted adaptation regularization can significantly improve the classification performance, given the same number of labeled samples from the new headset; or, equivalently, it can\neffectively reduce the number of labeled samples from the new headset, given a desired classification accuracy.\nWhile the current examples are based on intra-subject transfer (e.g., same-subject, different headsets), our ultimate goal is the application of this approach to more sophisticated preprocessing and feature extraction techniques, such as active weighted adaptation regularization from multiple sources (e.g., use data from other subjects and multiple headsets in a new headset calibration), and the generalization of weighted adaptation regularization to online BCI calibration. Together, these will open the door for a host of applications facilitating BCI technology across a wide range of domains. For example, cross-headset transfer learning, as shown here, will allow data acquired from one research group to be utilized by others, enabling a vast wealth of resources for generating calibration data. To date, this has not been a possible practice due to a wide variety of hardware used in research settings. However, the techniques discussed here not only suggest feasibility, but also lay the foundation for understanding the most critical features of data acquisition hardware which affect transfer and classifier performance. This information can, in turn, be used to further refine and propel the system design industry."
    }, {
      "heading" : "ACKNOWLEDGEMENT",
      "text" : "The authors would like to thank Scott Kerick, Jean Vettel and Anthony Ries at the US Army Research Laboratory (ARL) for designing the experiment and collecting the data."
    } ],
    "references" : [ {
      "title" : "Improving session-tosession transfer performance of motor imagery-based BCI using adaptive extreme learning machine",
      "author" : [ "A. Bamdadian", "C. Guan", "K.K. Ang", "J. Xu" ],
      "venue" : "Proc. 35th Annual Int’l Conf. of the IEEE Engineering in Medicine and Biology Society (EMBC), Osaka, Japan, July 2013, pp. 2188–2191.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples",
      "author" : [ "M. Belkin", "P. Niyogi", "V. Sindhwani" ],
      "venue" : "Journal of Machine Learning Research, vol. 7, pp. 2399–2434, 2006.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Learning deep architectures for AI",
      "author" : [ "Y. Bengio" ],
      "venue" : "Foundations and Trends in Machine Learning, vol. 2, no. 1, pp. 1–127, 2009.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Controlling the false discovery rate: A practical and powerful approach to multiple testing",
      "author" : [ "Y. Benjamini", "Y. Hochberg" ],
      "venue" : "Journal of the Royal Statistical Society, Series B (Methodological), vol. 57, pp. 289– 300, 1995.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Adaptive batch mode active learning",
      "author" : [ "S. Chakraborty", "V. Balasubramanian", "S. Panchanathan" ],
      "venue" : "IEEE Trans. on Neural Networks and Learning Systems, vol. 26, no. 8, pp. 1747–1760, 2015.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "LIBSVM: A library for support vector machines",
      "author" : [ "C.-C. Chang", "C.-J. Lin" ],
      "venue" : "ACM Trans. on Intelligent Systems and Technology, vol. 2, no. 3, pp. 27:1–27:27, 2011, software available at http://www.csie.ntu.edu.tw/$\\sim$cjlin/libsvm.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Joint transfer and batch-mode active learning",
      "author" : [ "R. Chattopadhyay", "W. Fan", "I. Davidson", "S. Panchanathan", "J. Ye" ],
      "venue" : "Proc. 30th Int’l. Conf. on Machine Learning (ICML), Atlanta, GA, June 2013.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Co-training for domain adaptation",
      "author" : [ "M. Chen", "K. Weinberger", "J. Blitzer" ],
      "venue" : "Proc. 25th Conf. on Neural Information Processing Systems (NIPS), Granada, Spain, December 2011.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Batch mode active learning algorithm combining with self-training for multiclass brain-computer interfaces",
      "author" : [ "M. Chen", "X. Tan" ],
      "venue" : "Journal of Information & Computational Science, vol. 12, no. 6, pp. 2351–2359, 2015.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis",
      "author" : [ "A. Delorme", "S. Makeig" ],
      "venue" : "Journal of Neuroscience Methods, vol. 134, pp. 9–21, 2004.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Multisubject learning for common spatial patterns in motor-imagery BCI",
      "author" : [ "D. Devlaminck", "B. Wyns", "M. Grosse-Wentrup", "G. Otte", "P. Santens" ],
      "venue" : "Computational intelligence and neuroscience, vol. 20, no. 8, 2011.  13",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Multiple comparisons among means",
      "author" : [ "O. Dunn" ],
      "venue" : "Journal of the American Statistical Association, vol. 56, pp. 62–64, 1961.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1961
    }, {
      "title" : "Multiple comparisons using rank sums",
      "author" : [ "O. Dunn" ],
      "venue" : "Technometrics, vol. 6, pp. 214–252, 1964.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1964
    }, {
      "title" : "Usability of four commerciallyoriented EEG systems",
      "author" : [ "W.D. Hairston", "K.W. Whitaker", "A.J. Ries", "J.M. Vettel", "J.C. Bradford", "S.E. Kerick", "K. McDowell" ],
      "venue" : "Journal of Neural Engineering, vol. 11, no. 4, 2014.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Brain-computer interface (BCI) literature – a bibliometric study",
      "author" : [ "B. Hamadicharef" ],
      "venue" : "Proc. 10th Int’l. Conf. on Information Sciences Signal Processing and their Applications, Kuala Lumpur, May 2010, pp. 626– 629.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Active learning by querying informative and representative examples",
      "author" : [ "S.-J. Huang", "R. Jin", "Z.-H. Zhou" ],
      "venue" : "IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 36, no. 10, pp. 1936–1949, 2014.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1936
    }, {
      "title" : "Composite common spatial pattern for subject-to-subject transfer",
      "author" : [ "H. Kang", "Y. Nam", "S. Choi" ],
      "venue" : "Signal Processing Letters, vol. 16, no. 8, pp. 683–686, 2009.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Brain-computer interface technologies in the coming decades",
      "author" : [ "B.J. Lance", "S.E. Kerick", "A.J. Ries", "K.S. Oie", "K. McDowell" ],
      "venue" : "Proc. of the IEEE, vol. 100, no. 3, pp. 1585–1599, 2012.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Efficient labeling of EEG signal artifacts using active learning",
      "author" : [ "V.J. Lawhern", "D.J. Slayback", "D. Wu", "B.J. Lance" ],
      "venue" : "Proc. IEEE Int’l. Conf. on Systems, Man and Cybernetics, Hong Kong, October 2015.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Group nonnegative matrix factorization for EEG classification",
      "author" : [ "H. Lee", "S. Choi" ],
      "venue" : "Proc. Int’l. Conf. on Artificial Intelligence and Statistics, Clearwater Beach, FL, April 2009, pp. 320–327.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Application of covariate shift adaptation techniques in brain-computer interfaces",
      "author" : [ "Y. Li", "H. Kambara", "Y. Koike", "M. Sugiyama" ],
      "venue" : "IEEE Trans. on Biomedical Engineering, vol. 57, no. 6, pp. 1318–1324, 2010.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A framework of adaptive brain computer interfaces",
      "author" : [ "Y. Li", "Y. Koike", "M. Sugiyama" ],
      "venue" : "Proc. 2nd IEEE Int’l. Conf. on Biomedical Engineering and Informatics (BMEl), Tianjin, China, October 2009.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Adaptation regularization: A general framework for transfer learning",
      "author" : [ "M. Long", "J. Wang", "G. Ding", "S.J. Pan", "P.S. Yu" ],
      "venue" : "IEEE Trans. on Knowledge and Data Engineering, vol. 26, no. 5, pp. 1076–1089, 2014.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Learning from other subjects helps reducing brain-computer interface calibration time",
      "author" : [ "F. Lotte", "C. Guan" ],
      "venue" : "Proc. IEEE Int’l. Conf. on Acoustics Speech and Signal Processing (ICASSP), Dallas, TX, March 2010.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Improved neural signal classification in a rapid serial visual presentation task using active learning",
      "author" : [ "A. Marathe", "V. Lawhern", "D. Wu", "D. Slayback", "B. Lance" ],
      "venue" : "IEEE Trans. on Neural Systems and Rehabilitation Engineering, vol. 24, no. 3, pp. 333–343, 2016.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Real-world neuroimaging technologies",
      "author" : [ "K. McDowell", "C.-T. Lin", "K. Oie", "T.-P. Jung", "S. Gordon", "K. Whitaker", "S.-Y. Li", "S.-W. Lu", "W. Hairston" ],
      "venue" : "IEEE Access, vol. 1, pp. 131–149, 2013.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A survey on transfer learning",
      "author" : [ "S.J. Pan", "Q. Yang" ],
      "venue" : "IEEE Trans. on Knowledge and Data Engineering, vol. 22, no. 10, pp. 1345–1359, 2010.",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Large margin transductive transfer learning",
      "author" : [ "B. Quanz", "J. Huan" ],
      "venue" : "Proc. 18th ACM Conf. on Information and Knowledge Management (CIKM), Hong Kong, November 2009.",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Domain adaptation meets active learning",
      "author" : [ "P. Rai", "A. Saha", "III H. Daumé", "S. Venkatasubramanian" ],
      "venue" : "Proc. NAACL HLT 2010 Workshop on Active Learning for Natural Language Processing, Los Angeles, CA, June 2010, pp. 27–32.",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A comparison of electroencephalography signals acquired from conventional and mobile systems",
      "author" : [ "A.J. Ries", "J. Touryan", "J. Vettel", "K. McDowell", "W.D. Hairston" ],
      "venue" : "Journal of Neuroscience and Neuroengineering, vol. 3, no. 1, pp. 10–20, 2014.",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Transferring subspaces between subjects in brain-computer interfacing",
      "author" : [ "W. Samek", "F. Meinecke", "K.-R. Muller" ],
      "venue" : "IEEE Trans. on Biomedical Engineering, vol. 60, no. 8, pp. 2289–2298, 2013.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A covariate shift minimisation method to alleviate non-stationarity effects for an adaptive braincomputer interface",
      "author" : [ "A. Satti", "C. Guan", "D. Coyle", "G. Prasad" ],
      "venue" : "Proc. 20th IEEE Int’l. Conf. on Pattern Recognition (ICPR), Istanbul, Turkey, August 2010, pp. 105–108.",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Active learning literature survey",
      "author" : [ "B. Settles" ],
      "venue" : "University of Wisconsin– Madison, Computer Sciences Technical Report 1648, 2009.",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Actively transfer domain knowledge",
      "author" : [ "X. Shi", "W. Fan", "J. Ren" ],
      "venue" : "Proc. European Conf. on Machine Learning (ECML), Antwerp, Belgium, September 2008, pp. 342–357.",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Principal component based covariate shift adaption to reduce non-stationarity in a MEG-based  brain-computer interface",
      "author" : [ "M. Spuler", "W. Rosenstiel", "M. Bogdan" ],
      "venue" : "EURASIP Journal on Advances in Signal Processing, vol. 2012, no. 1, pp. 1–7, 2012.",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Regularization, Optimization, Kernels, and Support Vector Machines",
      "author" : [ "J.A. Suykens", "M. Signoretto", "A. Argyriou", "Eds" ],
      "venue" : null,
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2014
    }, {
      "title" : "A regularized discriminative framework for EEG analysis with application to brain-computer interface",
      "author" : [ "R. Tomioka", "K.-R. Muller" ],
      "venue" : "NeuroImage, vol. 49, pp. 415–432, 2010.",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Dynamical ensemble learning with model-friendly classifiers for domain adaptation",
      "author" : [ "W. Tu", "S. Sun" ],
      "venue" : "Proc. 21st Int’l. Conf. on Pattern Recognition (ICPR), Tsukuba, Japan, November 2012.",
      "citeRegEx" : "39",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A subject transfer framework for EEG classification",
      "author" : [ "W. Tu", "S. Sun" ],
      "venue" : "Neurocomputing, vol. 82, pp. 109–116, 2012.",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Code of federal regulations protection of human subjects",
      "author" : [ "US Department of Defense Office of the Secretary of Defense" ],
      "venue" : "Government Printing Office, no. 32 CFR 19, 1999.",
      "citeRegEx" : "41",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Use of volunteers as subjects of research",
      "author" : [ "US Department of the Army" ],
      "venue" : "Government Printing Office, no. AR 70-25, 1990.",
      "citeRegEx" : "42",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "An iterative framework for EEG-based image search: Robust retrieval with weak classifiers",
      "author" : [ "M. Uscumlic", "R. Chavarriaga", "J. del R. Millan" ],
      "venue" : "PLoS One, vol. 8, no. 8, 2013.",
      "citeRegEx" : "43",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Brain-computer interfaces: Beyond medical applications",
      "author" : [ "J. van Erp", "F. Lotte", "M. Tangermann" ],
      "venue" : "Computer, vol. 45, no. 4, pp. 26–34, 2012.",
      "citeRegEx" : "44",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Statistical Learning Theory",
      "author" : [ "V. Vapnik" ],
      "venue" : null,
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 1998
    }, {
      "title" : "Toward unsupervised adaptation of LDA for brain-computer interfaces",
      "author" : [ "C. Vidaurre", "M. Kawanabe", "P.V. Bunau", "B. Blankertz", "K. Muller" ],
      "venue" : "IEEE Trans. on Biomedical Engineering, vol. 58, no. 3, pp. 587–597, 2011.",
      "citeRegEx" : "46",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "A review on transfer learning for brain-computer interface classification",
      "author" : [ "P. Wang", "J. Lu", "B. Zhang", "Z. Tang" ],
      "venue" : "Prof. 5th Int’l. Conf. on Information Science and Technology (IC1ST), Changsha, China, April 2015.",
      "citeRegEx" : "47",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms",
      "author" : [ "P. Welch" ],
      "venue" : "IEEE Trans. on Audio Electroacoustics, vol. 15, pp. 70– 73, 1967.",
      "citeRegEx" : "48",
      "shortCiteRegEx" : null,
      "year" : 1967
    }, {
      "title" : "Online driver’s drowsiness estimation using domain adaptation with model fusion",
      "author" : [ "D. Wu", "C.-H. Chuang", "C.-T. Lin" ],
      "venue" : "Proc. Int’l. Conf. on Affective Computing and Intelligent Interaction, Xi’an, China, September 2015.",
      "citeRegEx" : "50",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Active transfer learning for reducing calibration data in single-trial classification of visually-evoked potentials",
      "author" : [ "D. Wu", "B.J. Lance", "V.J. Lawhern" ],
      "venue" : "Proc. IEEE Int’l. Conf. on Systems, Man, and Cybernetics, San Diego, CA, October 2014.",
      "citeRegEx" : "51",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Collaborative filtering for braincomputer interaction using transfer learning and active class selection",
      "author" : [ "D. Wu", "B.J. Lance", "T.D. Parsons" ],
      "venue" : "PLoS ONE, 2013.",
      "citeRegEx" : "52",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Reducing BCI calibration effort in RSVP tasks using online weighted adaptation regularization with source domain selection",
      "author" : [ "D. Wu", "V.J. Lawhern", "B.J. Lance" ],
      "venue" : "Proc. Int’l. Conf. on Affective Computing and Intelligent Interaction, Xi’an, China, September 2015.",
      "citeRegEx" : "53",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Reducing offline BCI calibration effort using weighted adaptation regularization with source domain selection",
      "author" : [ "D. Wu", "V.J. Lawhern", "B.J. Lance" ],
      "venue" : "Proc. IEEE Int’l. Conf. on Systems, Man and Cybernetics, Hong Kong, October 2015.",
      "citeRegEx" : "54",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Inductive transfer learning for handling individual differences in affective computing",
      "author" : [ "D. Wu", "T.D. Parsons" ],
      "venue" : "Proc. 4th Int’l Conf. on Affective Computing and Intelligent Interaction, vol. 2, Memphis, TN, October 2011, pp. 142–151.",
      "citeRegEx" : "55",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Improving SVM accuracy by training on auxiliary data sources",
      "author" : [ "P. Wu", "T.G. Dietterich" ],
      "venue" : "Proc. Int’l Conf. on Machine Learning, Banff, Alberta, Canada, July 2004, pp. 871–878.",
      "citeRegEx" : "56",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "L1regularized multiway canonical correlation analysis for SSVEP-based BCI",
      "author" : [ "Y. Zhang", "G. Zhou", "J. Jin", "M. Wang", "X. Wang", "A. Cichocki" ],
      "venue" : "IEEE Trans. on Neural Systems and Rehabilitation Engineering, vol. 21, no. 6, pp. 887–896, 2013.",
      "citeRegEx" : "57",
      "shortCiteRegEx" : null,
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "INTRODUCTION ELECTROENCEPHALOGRAPHY (EEG) headsets are the most commonly used sensing devices for BrainComputer Interface (BCI), which have been employed in many applications, such as healthcare and gaming [15], [18], [26],",
      "startOffset" : 206,
      "endOffset" : 210
    }, {
      "referenceID" : 17,
      "context" : "INTRODUCTION ELECTROENCEPHALOGRAPHY (EEG) headsets are the most commonly used sensing devices for BrainComputer Interface (BCI), which have been employed in many applications, such as healthcare and gaming [15], [18], [26],",
      "startOffset" : 212,
      "endOffset" : 216
    }, {
      "referenceID" : 25,
      "context" : "INTRODUCTION ELECTROENCEPHALOGRAPHY (EEG) headsets are the most commonly used sensing devices for BrainComputer Interface (BCI), which have been employed in many applications, such as healthcare and gaming [15], [18], [26],",
      "startOffset" : 218,
      "endOffset" : 222
    }, {
      "referenceID" : 42,
      "context" : "[44], [49], because of the general ease of setup for normal individuals.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "There are many existing EEG headsets, with new models and styles continually becoming available [14].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 29,
      "context" : "However, evidence comparing the performance of various classifiers when using different headsets has shown that often performance is not equal across systems; that is, the headset does in fact matter [30].",
      "startOffset" : 200,
      "endOffset" : 204
    }, {
      "referenceID" : 42,
      "context" : "Thus, it is not surprising that currently switching to a new or different headset requires the subject to re-calibrate it, which can take anywhere from 5-20 minutes [44].",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 26,
      "context" : "In this paper, we specifically attempt to address the problem of developing classifiers that can account for variation due to different EEG headsets within a transfer learning (TL) [27] framework.",
      "startOffset" : 181,
      "endOffset" : 185
    }, {
      "referenceID" : 45,
      "context" : "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 10,
      "context" : "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 16,
      "context" : "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.",
      "startOffset" : 155,
      "endOffset" : 159
    }, {
      "referenceID" : 19,
      "context" : "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 23,
      "context" : "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 30,
      "context" : "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 31,
      "context" : "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 34,
      "context" : "According to a recent literature review [47], there are mainly three types of TL approaches for BCI applications: 1) Feature representation transfer [11], [17], [20], [24], [31], [32], [35], which encodes the knowledge across different subjects or sessions as features.",
      "startOffset" : 185,
      "endOffset" : 189
    }, {
      "referenceID" : 20,
      "context" : "2) Instance transfer [21], [22], [52], [55], which uses certain parts of the data from other subjects or sessions to help the learning for the current subject or session.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 21,
      "context" : "2) Instance transfer [21], [22], [52], [55], which uses certain parts of the data from other subjects or sessions to help the learning for the current subject or session.",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 49,
      "context" : "2) Instance transfer [21], [22], [52], [55], which uses certain parts of the data from other subjects or sessions to help the learning for the current subject or session.",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 52,
      "context" : "2) Instance transfer [21], [22], [52], [55], which uses certain parts of the data from other subjects or sessions to help the learning for the current subject or session.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 0,
      "context" : "3) Classifier transfer, which includes domain adaptation [1], [35], [46], i.",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 34,
      "context" : "3) Classifier transfer, which includes domain adaptation [1], [35], [46], i.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 44,
      "context" : "3) Classifier transfer, which includes domain adaptation [1], [35], [46], i.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 37,
      "context" : ", handling the different data distributions for different subjects or sessions, and ensemble learning [39], [40], i.",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 38,
      "context" : ", handling the different data distributions for different subjects or sessions, and ensemble learning [39], [40], i.",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 47,
      "context" : ", combining multiple classifiers from multiple subjects or sessions, and their combinations [50], [53], [54].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 50,
      "context" : ", combining multiple classifiers from multiple subjects or sessions, and their combinations [50], [53], [54].",
      "startOffset" : 98,
      "endOffset" : 102
    }, {
      "referenceID" : 51,
      "context" : ", combining multiple classifiers from multiple subjects or sessions, and their combinations [50], [53], [54].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 35,
      "context" : "In our case, data acquired from one style of headset is used to facilitate classification of data currently being acquired from a different one, through domain adaptation and regularized optimization [36], [38], [57].",
      "startOffset" : 200,
      "endOffset" : 204
    }, {
      "referenceID" : 36,
      "context" : "In our case, data acquired from one style of headset is used to facilitate classification of data currently being acquired from a different one, through domain adaptation and regularized optimization [36], [38], [57].",
      "startOffset" : 206,
      "endOffset" : 210
    }, {
      "referenceID" : 54,
      "context" : "In our case, data acquired from one style of headset is used to facilitate classification of data currently being acquired from a different one, through domain adaptation and regularized optimization [36], [38], [57].",
      "startOffset" : 212,
      "endOffset" : 216
    }, {
      "referenceID" : 41,
      "context" : ", BCI applications focused on labeling images, using EEG data [37], [43].",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 32,
      "context" : "This is the idea of active learning (AL) [33], which has also started to find application in BCI [9], [19], [25].",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 8,
      "context" : "This is the idea of active learning (AL) [33], which has also started to find application in BCI [9], [19], [25].",
      "startOffset" : 97,
      "endOffset" : 100
    }, {
      "referenceID" : 18,
      "context" : "This is the idea of active learning (AL) [33], which has also started to find application in BCI [9], [19], [25].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 24,
      "context" : "This is the idea of active learning (AL) [33], which has also started to find application in BCI [9], [19], [25].",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 18,
      "context" : "For example, in our recent work on EEG artifacts classification [19], we showed that classification accuracy equivalent to classifiers trained on full data annotation can be obtained while labeling less than 25% of the data by AL.",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 24,
      "context" : "In another study [25], we applied AL to a simulated BCI system for target identification using data from a rapid serial visual presentation paradigm, and showed that it can produce similar overall classification accuracy with significantly less labeled data (in some cases less than 20%) when compared to alternative calibration approaches.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 33,
      "context" : "The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58].",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 6,
      "context" : "The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58].",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 7,
      "context" : "The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58].",
      "startOffset" : 98,
      "endOffset" : 101
    }, {
      "referenceID" : 28,
      "context" : "The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58].",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 48,
      "context" : "The idea of integrating TL and AL was proposed recently [34] and is beginning to be explored [7], [8], [29], [51], [58].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 48,
      "context" : "In our previous work [51], we investigated how TL and AL can be integrated to reduce the amount of subject-specific calibration data in a Visual-Evoked Potential (VEP) task, by making use of data collected using the same headset but from other subjects; in contrast, this paper considers the problem of reducing subjectspecific calibration data when the same subject switches from one headset to another.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 48,
      "context" : "Using a single-trial ERP experiment, we demonstrate that wAR can achieve improved performance over the TL approach used in [51], and active weighted adaptation regularization (AwAR), which integrates wAR and AL, can further reduce the offline calibration effort when switching between different EEG headsets.",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 26,
      "context" : "TL [27], [56], particularly wAR, is a framework for addressing the aforementioned problem.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 53,
      "context" : "TL [27], [56], particularly wAR, is a framework for addressing the aforementioned problem.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 22,
      "context" : "Definition 1: (Domain) [23], [27] A domain D is composed of a d-dimensional feature space X and a marginal probability distribution P (x), i.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 26,
      "context" : "Definition 1: (Domain) [23], [27] A domain D is composed of a d-dimensional feature space X and a marginal probability distribution P (x), i.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 22,
      "context" : ", Ps(x) 6= Pt(x) [23].",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 22,
      "context" : "Definition 2: (Task) [23], [27] Given a domain D, a task T is composed of a label space Y and a prediction function f(x), i.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 26,
      "context" : "Definition 2: (Task) [23], [27] Given a domain D, a task T is composed of a label space Y and a prediction function f(x), i.",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 22,
      "context" : ", Qs(y|x) 6= Qt(y|x) [23].",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 1,
      "context" : "By the Representer Theorem [2], [23], the solution of (2) admits an expression:",
      "startOffset" : 27,
      "endOffset" : 30
    }, {
      "referenceID" : 22,
      "context" : "By the Representer Theorem [2], [23], the solution of (2) admits an expression:",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 22,
      "context" : "Note that our algorithm formulation and derivation closely resemble those in [23]; however, there are several major differences: 1) We consider the scenario that there are a few labeled samples in the target domain, whereas [23] assumes there are no labeled samples in the target domain.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 22,
      "context" : "Note that our algorithm formulation and derivation closely resemble those in [23]; however, there are several major differences: 1) We consider the scenario that there are a few labeled samples in the target domain, whereas [23] assumes there are no labeled samples in the target domain.",
      "startOffset" : 224,
      "endOffset" : 228
    }, {
      "referenceID" : 22,
      "context" : "3) wAR is iterative and we further design an AL algorithm for it, whereas in [23] domain adaptation is performed only once and there is no AL.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 22,
      "context" : "4) [23] also considers manifold regularization [2].",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 1,
      "context" : "4) [23] also considers manifold regularization [2].",
      "startOffset" : 47,
      "endOffset" : 50
    }, {
      "referenceID" : 51,
      "context" : "Also note that one of the wAR algorithms (wAR-RLS) described in this paper was introduced in our previous publication [54]; however, this paper includes a new wAR algorithm (wAR-SVM), and shows how AL can be integrated with wAR-RLS and wAR-SVM.",
      "startOffset" : 118,
      "endOffset" : 122
    }, {
      "referenceID" : 22,
      "context" : "Structural Risk Minimization As in [23], [45], we define the structural risk as the squared norm of f in HK , i.",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 43,
      "context" : "Structural Risk Minimization As in [23], [45], we define the structural risk as the squared norm of f in HK , i.",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 22,
      "context" : "Marginal Probability Distribution Adaptation Similar to [23], [28], we compute Df,K(Ps, Pt) using the projected maximum mean discrepancy (MMD):",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 27,
      "context" : "Marginal Probability Distribution Adaptation Similar to [23], [28], we compute Df,K(Ps, Pt) using the projected maximum mean discrepancy (MMD):",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 22,
      "context" : "Conditional Probability Distribution Adaptation Similar to the idea proposed in [23], we first need to compute pseudo labels for the unlabeled target domain samples and construct the label vector y in (8).",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 32,
      "context" : "ACTIVE WEIGHTED ADAPTATION REGULARIZATION (AWAR) As mentioned in the Introduction, wAR can be integrated with AL [33] for better performance.",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 32,
      "context" : "There are many different heuristics for this purpose [33].",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 4,
      "context" : "2We attempted the active learning approaches in [5], [16] but failed to observe better performance than the method proposed in this section.",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 15,
      "context" : "2We attempted the active learning approaches in [5], [16] but failed to observe better performance than the method proposed in this section.",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 29,
      "context" : "Experiment Setup We used data from a VEP oddball task [30].",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 39,
      "context" : "The voluntary, fully informed consent of the persons used in this research was obtained as required by federal and Army regulations [41], [42].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 40,
      "context" : "The voluntary, fully informed consent of the persons used in this research was obtained as required by federal and Army regulations [41], [42].",
      "startOffset" : 138,
      "endOffset" : 142
    }, {
      "referenceID" : 9,
      "context" : "Preprocessing and Feature Extraction We used EEGLAB [10] for EEG signal preprocessing and feature extraction.",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "For each headset, we first band-passed the EEG signals to [1, 50] Hz, then downsampled them to 64 Hz, performed average reference, and next epoched them to the [0, 0.",
      "startOffset" : 58,
      "endOffset" : 65
    }, {
      "referenceID" : 47,
      "context" : "For each headset, we first band-passed the EEG signals to [1, 50] Hz, then downsampled them to 64 Hz, performed average reference, and next epoched them to the [0, 0.",
      "startOffset" : 58,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "We then normalized each feature dimension separately to [0, 1] for each subject.",
      "startOffset" : 56,
      "endOffset" : 62
    }, {
      "referenceID" : 48,
      "context" : "2) The simple TL (TL) algorithm introduced in [51], which is very similar to BL, except that in each iteration it combines labeled samples from the old and new headsets in building an SVM classifier and then applies it to the unlabeled samples from the new headset.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 48,
      "context" : "3) The active TL (ATL) algorithm introduced in [51], which adds AL to the above TL: instead of randomly selecting unlabeled samples from the new headset to label, it selects those closest to the SVM decision boundary.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 5,
      "context" : "Weighted LIBSVM [6] with a linear kernel was used as the classifier in BL, TL, ATL, wAR-SVM, and AwAR-SVM.",
      "startOffset" : 16,
      "endOffset" : 19
    }, {
      "referenceID" : 22,
      "context" : "1 and λP = λQ = 10, following the practice in [23].",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 22,
      "context" : "This is also consistent with the observations in [23].",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 24,
      "context" : "To assess overall performance differences among all the algorithms, a measure called the area-underperformance-curve (AUPC) [25] was calculated.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 0,
      "context" : "The AUPC is the area under the curve of the BCA values plotted at each of the 30 random runs and is normalized to [0, 1].",
      "startOffset" : 114,
      "endOffset" : 120
    }, {
      "referenceID" : 11,
      "context" : "Then, non-parametric multiple comparison tests using Dunn’s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method by [4].",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 12,
      "context" : "Then, non-parametric multiple comparison tests using Dunn’s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method by [4].",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 3,
      "context" : "Then, non-parametric multiple comparison tests using Dunn’s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method by [4].",
      "startOffset" : 251,
      "endOffset" : 254
    }, {
      "referenceID" : 2,
      "context" : "Two other feature sets were employed to study the robustness of AwAR-RLS and AwAR-SVM to different feature extraction methods: 1) 20 nonlinear PCA features extracted from an auto-encoder [3]; and, 2) 18 power spectral density features [theta band (4-7.",
      "startOffset" : 187,
      "endOffset" : 190
    }, {
      "referenceID" : 46,
      "context" : "5-12Hz)] from the 9 common channels using Welch’s method [48].",
      "startOffset" : 57,
      "endOffset" : 61
    } ],
    "year" : 2017,
    "abstractText" : "Electroencephalography (EEG) headsets are the most commonly used sensing devices for Brain-Computer Interface. In real-world applications, there are advantages to extrapolating data from one user session to another. However, these advantages are limited if the data arise from different hardware systems, which often vary between application spaces. Currently, this creates a need to recalibrate classifiers, which negatively affects people’s interest in using such systems. In this paper, we employ active weighted adaptation regularization (AwAR), which integrates weighted adaptation regularization (wAR) and active learning, to expedite the calibration process. wAR makes use of labeled data from the previous headset and handles class-imbalance, and active learning selects the most informative samples from the new headset to label. Experiments on single-trial event-related potential classification show that AwAR can significantly increase the classification accuracy, given the same number of labeled samples from the new headset. In other words, AwAR can effectively reduce the number of labeled samples required from the new headset, given a desired classification accuracy, suggesting value in collating data for use in wide scale transfer-learning applications.",
    "creator" : "LaTeX with hyperref package"
  }
}