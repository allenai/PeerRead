{
  "name" : "1506.02170.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Hybridized Feature Extraction and Acoustic Modelling Approach for Dysarthric Speech Recognition",
    "authors" : [ "Megha Rughani" ],
    "emails" : [ "megharughani@gmail.com", "d.shivakrishna@marwadieducation.edu.in" ],
    "sections" : [ {
      "heading" : null,
      "text" : "caused by faintness in the human nervous system. It is characterized by the slurred speech along with physical impairment which restricts their communication and creates the lack of confidence and affects the lifestyle. This paper attempt to increase the efficiency of Automatic Speech Recognition (ASR) system for unimpaired speech signal. It describes state of art of research into improving ASR for speakers with dysarthria by means of incorporated knowledge of their speech production. Hybridized approach for feature extraction and acoustic modelling technique along with evolutionary algorithm is proposed for increasing the efficiency of the overall system. Here number of feature vectors are varied and tested the system performance. It is observed that system performance is boosted by genetic algorithm. System with 16 acoustic features optimized with genetic algorithm has obtained highest recognition rate of 98.28% with training time of 5:30:17."
    }, {
      "heading" : "Keywords— Dysarthria, Hybrid Log RASTA Perceptive Linear Prediction/Neural Network, Hybrid Hidden Markov Model/ Multilayer Perceptron, Genetic Algorithm",
      "text" : "I. INTRODUCTION\nSpeech is very essential part of our lives. It is one of the most prominent form of senses through which human easily communicate. It is the speech which assists one develop and nature the relation among the society. The consequences and nature of speech is very less cared while speaking, but in real it is very complex task. It is the combined process of hearing and speaking generated by motor muscles co-ordinated by the brain muscles. However, it is misfortune that some lacks integration of all the above required processes and they are said to have communication disorder. If communication does not occur as it should, the disruption is in the process, not the individual. There are many reasons for the disruption in communication like hearing loss, speaking disability, or lack of co-ordination of neural muscles. Dysarthria is one such impairment which result in slurred speech.\nDysarthria is caused due to reduced control of neuro-motor muscles. It results into slurred speech as articulation is mainly affected. Insertion, deletion and repetition of phoneme reduce the intelligibility of speech signal. Severity of dysarthric speech affects the intelligibility of speech. It is caused due to brain tumour, celebral palsy, Parkinson diseases, head injury and many more. It lessens the controlling portion of brain which is involved in planning, execution and controlling of the specific affected organ along with motor speech disorder. Lungs, larynx, vocal tract movement, lip movement are basically affected. Mostly they are handicapped. [1, 2]\nVarious clinical treatments including exercise of motor muscles were carried out to increase the strength in order to improve articulation, phonation, and resonance. Special therapy like principles of motor learning are carried out by speech language pathologist but these are very time consuming and tedious to be followed. Assistive technology like Automatic Speech Recognition (ASR) helps in recognition and synthesis of unintelligible speech into intelligible form. [3, 4]\nState-of-art of ASR system implemented with normal speakers for automation. But Dysarthric speech is different due to difference in articulation so it gives less recognition when trained on simple ASR system. So, it is required to develop a system specifically for Dysarthric patient.\nSpectral and cepstral features are extracted from the input raw speech data which are modelled by various classifiers using acoustic modelling technique and looked up into dictionary to find similar match and accordingly generates the text output. Here Log RASTA Perceptive Linear Prediction (Log RASTA PLP) hybridized with Artificial Neural Network (ANN) is used for feature extraction which are acoustically modelled using hybrid Hidden Markov Model (HMM) /Artificial Neural Network (ANN) technique. Genetic algorithm (GA) is applied for the optimization of the parameters and system performance is compared without and with GA.\nII. PREVIOUS WORK\nHere in this section state of art of methods and combination of different technologies developed is presented for Dysarthric as well as normal dataset. For Dysarthric speech recognition rate is not achieved up to the desired level because of the difficulty mentioned in previous section.\nHarsh Sharma & Mark Johnson [5] has applied various different algorithms and its combination for the adaptation of the system based on HMM acoustic modelling technique like Maximum A-posterior Probability (MAP) adaptation for Speaker independent (SI) system and Transition probability matrix (Linear interpolation) for Speaker Dependent (SD) and Speaker Adapted (SA) with 12 PLP coefficients along with velocity and acceleration coefficients forming 39 dimensional acoustic feature vector using UA speech database and concluded that adaptation of various parameters leads to increase in word recognition rate or overall system.\nHarsh Sharma & Mark Johnson [6] have attempted to explicit modelling by first considering the mismatch between unimpaired and Dysarthric speech among the population and model is prepared. In the second stage this model acts as initial model for the adaptation. Background Interpolated (BI) and MAP adaptation are used for the HMM based system using UA Speech database and PLP feature extraction technique and achieved 4.16% -82.07% of WRA.\nSantiago & Caballero [7] found out the best combination of HMM parameters like its topology, number of states and Gaussian mixture components using evolutionary algorithm like Genetic Algorithm. For Speaker dependent approach Bakis topology with 7 states having 13 Gaussian mixture components perform well for some speakers but it cannot be generalized for all speaker as phoneme characteristics varies widely. WRA of 47.27% - 81.22% is obtained by using GA optimized HMM system having Bakis topology.\nSantiago & Caballero [8] performed integration of different pronunciation pattern by weighting the responses of an Automatic Speech Recognition (ASR) system when different language model restrictions are set. They performed confusion matrix modelling with weighted Finite State Transducer (WFST) implemented with extended Metamodels (MM) along with evolutionary algorithm like Genetic Algorithm. Comparison of baseline HMM, baseline MM, micro GA and MM built with improved GA was carried and MM with built in GA outperforms among all with WRA of 42.6% - 77.54% which is comparatively similar to previous one implementing HMM and GA algorithm.\nShahamiri & Salim [9] have tried to find out best performing set of MFCC feature extracted set for the usage of ANN acoustic modelling technique and stated that SD and SA have poor performance in terms of speaker's generalizability, so adopted SI approach in his work. Feed forward back propagation training algorithm was implemented using UA\nspeech database and found out that Mel Cepstrum with 12 coefficients, each utterance represented by 264 vector features outperforms well.\nJoel Pinto & Hermansky [10] analyze a simple hierarchical architecture consisting of two multilayer perceptron (MLP) classifiers. The first MLP classifier is trained using standard acoustic features. The second MLP is trained using the posterior probabilities of phonemes estimated by the first, but with a long temporal context of around 150-230ms. Here 3 layer MLP architecture is implemented in which temporal context of 90ms is taken of acoustic features obtained using MFCC or PLP technique. These become input to MLP layer 1; again temporal context of 150-230ms is carried and applied to MLP layer 2. On an average recognition rate of 71.6% and 63.3% for TIMIT and CTS database is obtained.\nLilia Lazli & Mounir [11] compared two different approach using speech and biomedical database which are: 1) MultiNetwork Radial Basis Function (RBF) / Learning Vector Quantization (LVQ) structure, 2) Hybrid HMM/MLP approach along with K-means clustering algorithm for normal speech and obtained on an average of 90% WRA for HMM/MLP hybrid approach which performs better than multi-network RBF/LVQ method.\nLilia Lazli & Mounir [12] compared five different methods which are: (1) Multi network RBF/LVQ structure (2) Discrete Hidden Markov Models (HMM) (3) Hybrid HMM & MLP system using a Multi-Layer Perceptron (MLP) to estimate the HMM emission probabilities and using the K-means algorithm for pattern clustering (4) Hybrid HMM-MLP system using the Fuzzy C-Means (FCM) algorithm for fuzzy pattern clustering and (5) Hybrid HMM-MLP system using the Genetic Algorithm using three different database (unimpaired speech) along with biomedical speech database. Hybrid HMM/MLP along with GA using Log RASTA PLP feature extraction obtained on an average of 93.5% and this technique outperforms in comparison of other considered technique.\nIt is clearly concluded from literature review that hybridized approach the recognition of Dysarthric speech has not been practiced. Here it is an attempt to increase the recognition rate by hybridized feature extraction and acoustic modelling technique. Use of ANN for clustering improves the efficiency of the system. Study explains that hybridized acoustic modelling consisting of ANN and HMM can used benefits of both the system and evolutionary algorithm can optimize one of the HMM parameter in order to improve recognition rate.\nIII. METHODS & MATERIALS\nThis section describes system implementation and database used. It gives detailed description of system adopted with neat block diagram. Database which is used in the research work is UA Speech database which is described briefly.\nFig.1: Hybrid Feature Extraction and Acoustic Modelling ASR for Dysarthric Speaker"
    }, {
      "heading" : "A. System Description",
      "text" : "For the implementation of the hybrid HMM/MLP approach acoustic feature vectors [13, 14] are need to extracted from the raw speech file. These acoustic feature vectors are extracted through feature extraction technique. After performing several experiments by using various feature extraction techniques 12-Log RASTA PLP method with frame length equal to 12 is selected for Dysarthric speech having 25ms of frame size and 10ms of overlap. Frame length is choosen to be equal to maximum length of the utterance. Silence portion is removed from the beginning and end portion based on energy of frame and frame length of each utterance is made equal by appending zeros at the end in order to make number of inputs same for each utterance to neural net. Feature extracted matrix is transferred to array form by appending m+1 column to the end of mth column. So, each utterance is represented by 126 features (13 features per frame x 12 frames). Each feature was assigned to one of the corresponding neuron of the clustering structure of ANN which groups features into 64 different clusters which sufficient for phoneme classification.\nThe clustered features are mapped to input neurons of the ANN structure for acoustic modelling. Here 3 layer MLP structure is considered with number of input neurons equals to number of features and output neurons are equal to size of the vocabulary the hidden layer consists of 5000 neurons.\nThe feed-forward network and backpropagation methods are used for training the features. The output of the net is converted into posterior probability for HMM modelling and applied to the Viterbi decoding along with the transition probability and prior probability. Which decodes the sequence of uttered words and output text is obtained. Detailed block diagram is shown in below Fig. 1\nAbove system forms the baseline system. The genetic Algorithm is applied for the optimization of the probabilities forming baseline + GA system. Mean square error is used as optimizing function and it updates probability matrix accordingly.\nThe training time required for the system is quiet more so, in order to reduce the time and hence the system complexity number of acoustic feature vectors are varied and tested the system performance. Variation in number of acoustic features shows distinct variation in recognition rate and system complexity. Here, system name is given based on number of feature vector considered from SOM neural net. Number of feature vector are added as suffix to the acronym of system (sys) i.e. sys16, sys32, sys64 and sys132 are having 16, 32, 64 and 128 acoustic feature vectors respectively. Sys64 is also referred to as baseline system as it was initially proposed. Application of Genetic Algorithm for optimization of HMM parameter is referred by adding suffix “+ GA” forming sys16 +GA, sys32 + GA, sys64 + GA, sys128 + GA respectively."
    }, {
      "heading" : "B. Database Description",
      "text" : "Database is developed at the Rehabilitation Education Centre at the University of Illinois at Urbana- Champaign. Recordings (both audio and video) took place while subjects were seated comfortably in front of a laptop computer. Subjects were asked to read an isolated word displayed on a PowerPoint slide on a computer.\nThe vocabulary contains 765 words including 455 distinct words and 300 distinct uncommon words chosen to maximize phone-sequence diversity. 455 distinct words contains 3 repetition of 155 words including 10 digits (“zero” to “nine”), 26 radio alphabet letters (e.g., “Alpha”, “Bravo”, “Charlie”), 19 computer commands (e.g., “backspace”, “delete”, “enter”) and 100 common words (the most common words in the Brown corpus of written English such as “it”, “is”, “you”). The uncommon words (e.g., “naturalization”, “moonshine”, “exploit”) were selected from children's novels digitized by Project Gutenberg, using a greedy algorithm that maximized token counts of infrequent bi-phones.\nTable I summarizes the characteristics of 19 subjects that have been recorded so far. The letter M (Male) and F (Female) in speaker code specifies a participant’s gender. Speech intelligibility (severity of speech disorder) is based on word transcription tasks by human listeners.\nIn this section we describe the result obtained on performing the various experiment and detailed discussion is made on it. Here performance evaluation of proposed four system is carried out.\nThe evaluation criteria considered for testing system performance is Word Recognition Rate (WRR) or Word Recognition Accuracy (WRA) which describes the correctness of system performance from speaker point of view. It is calculated as below:\nWhere,\nWTOT = Total number of words Werr = Number if incorrect recognized words\nThe system described in section III is having 64 feature vectors obtained from SOM Neural Net which act as an input to MLP, but the training time required for this system is fairly high. So, in order to decrease the complexity of the system number of feature vectors are changed, maintaining other parameters and its performance is evaluated. Here, 16, 32 and 128 features vectors are tested forming sys16, sys32 and sys128 respectively. System with 64 feature is either known as Baseline system or sys64.\nFig.2: WRA comparison of sys16 and sys16 + GA\nFig.3: WRA comparison of sys32 and sys32 + GA\nFrom Fig. 2 to Fig. 5 shows the comparison of WRA for baseline and baseline optimized with Genetic Algorithm (GA) i.e. baseline + GA. Here, patients along with severity in Dysarthria is represented is represented in X-axis while recognition rate is represented at Y-axis. It can be observed\nthat WRA differs among the speakers with F05 having least recognition rate. Also, optimization of posterior probability through GA improves the performance. This is observed among all adopted system but the range of recognition rate differs from each other. For all four system F05 and M10 speakers are found to get least trained and have comparatively less recognition rate in reference to other speakers but significantly higher in order to practice this system on daily basis.\nFig.4: WRA comparison of sys64 and sys64 + GA\nFig.5: WRA comparison of sys128 and sys128 + GA\nBelow Fig. 6 shows the overall performance of all the system along with evolution of observation probabilities through GA. It is found experimentally that system with less number of feature vectors gives highest recognition rate and vice versa. This is due to constant number of hidden and output nodes in feed forward neural network and varying number of input acoustic features. Lower number of input feature i.e. less number of input nodes is trained with higher hidden and output nodes makes the system to perform better as compared to others.\nFig.6: WRA Comparison of all System\nTable II shows the comparison of different proposed system in terms of system complexity i.e. time required for training neural network along with obtained recognition rate. It is observed that as the number of feature vector increases training time for SOM network of clustering increases as there are more number of groups to get into classified while opposite is the case for MLP network due to decrease in difference between number of input and hidden nodes but, overall training period tends to depend more on training of feed forward network as it takes much training period as compared to SOM topology. Observation from the table indicates that recognition rate and training period is almost same for sys32 and sys64. Detailed description of each system along with speaker is summarized in tabular format attached in appendix\n[3] Fox, Cynthia; Ramig, Lorraine; Ciucci, Michelle; Sapir,\nShimon; McFarland, David; Farley, Becky: Neural Plasticity-Principled Approach to Treating Individuals with Parkinson Disease and Other Neurological Disorders, Seminars in Speech and Language 27 (4): 283–99. Doi: 10.1055/s-2006-955118.\n[4] The National Collaborating Centre for Chronic Conditions,\n\"Other key interventions\". Parkinson's Disease. London: Royal College of Physicians. pp. 135–46, 2006.\n[5] Harsh Vardhan Sharma, Mark Hasegawa-Johnson, “State-\nTransition Interpolation and MAP Adaptation for HMMbased Dysarthric Speech Recognition”, Proceedings of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive Technologies, Los Angeles, California, 72-79, June 2010.\n[6] Harsh Vardhan Sharma, Mark Hasegawa-Johnson, “Acous-\ntic model adaptation using in-domain background models for dysarthric speech recognition”, Computer Speech & Language 27(6), 1147-1162, 2013.\n[7] Santiago-Omar Caballero-Morales, “Estimation of Phoneme\nSpecific HMM Topologies for the Automatic Recognition of Dysarthric Speech”, Hindawi Publishing Corporation Computational and Mathematical Methods in Medicine, Article ID 297860, Volume 2013.\n[8] Santiago Omar Caballero Morales, Felipe Trujillo-Romero,\n“Evolutionary approach for integration of multiple pronunciation patterns for enhancement of dysarthric speech recognition”, Expert Syst. Appl. 41(3), 841-85, 2014.\n[9] Seyed Reza Shahamiri, Siti Salwah Binti Salim, “Artificial\nneural networks as speech recognisers for dysarthric speech: Identifying the best-performing set of MFCC parameters and studying a speaker-independent approach”, Advanced Engineering Informatics. 28(1), 102-110, 2014.\n[10] Joel Pinto, G.S.V.S. Sivaram, Mathew Magimai Doss,\n“Analysis of MLP Based Hierarchical Phoneme Posterior Probability Estimator”, IEEE Audio, Speech and Language Processing, 2010.\n[11] Lilia Lazli1, Mounir Boukadoum, “Hidden Neural Network\nfor Complex Pattern Recognition: A Comparison Study with Multi- Neural Network Based Approach”, International Journal of Life Science and Medical Research, 3(6), 234- 245, 2013.\n[12] Lilia Lazli, Boukadoum Mounir, Abdennasser Chebira,\nKurosh Madani and Mohamed Tayeb Laskri, “Application for Speech Recognition and Medical Dignoias”, International Journal of Digital Information and Wireless Communications (IJDIWC) 1(1): 14-31. The Society of Digital Information and Wireless Communications, (ISSN 2225-658X), 2011.\n[13] Frantisek Grézl, and Martin Karafiát, “Integrating Recent\nMLP Feature Extraction Techniques into TRAP Architecture”, INTERSPEECH, 1229-1232, 2011.\n[14] Mondher Frikha, Ahmed Ben Hamida, “A Comparitive\nSurvey of ANN and Hybrid HMM/ANN Architectures for Robust Speech Recognition”, American Journal of Intelligent Systems, 2(1): 1-8, 2012.\nAPPENDIX\nTables shown below summarized performance of all the described system for each speaker. TABLE shows the performance for basic four system i.e. sys16, sys32, sys64 and sys128. Total 765 unique words are used and each word is repeated about 5-7 times forming different number of total words for which system is trained. Number of words which are falsely classified are mentioned in 4th column of both the table and last column indicates WRA for each system. TABLE shows the same description of all four system whose posterior probability is optimized along with Genetic Algorithm forming sys-x + GA, where x = 16,32,64,128."
    } ],
    "references" : [ {
      "title" : "J.,Physical rehabilitation (5th ed.),(Philadelphia",
      "author" : [ "S.B. O'Sullivan", "T. Schmitz" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2007
    }, {
      "title" : "Motor speech disorders: substrates, differential diagnosis, and management",
      "author" : [ "Duffy", "Joseph" ],
      "venue" : "(St. Louis, Mo: Elsevier Mosby,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2005
    }, {
      "title" : "Neural Plasticity-Principled Approach to Treating Individuals with Parkinson Disease and Other Neurological Disorders, Seminars in Speech and Language",
      "author" : [ "Cynthia Fox", "Lorraine Ramig", "Michelle Ciucci", "Shimon Sapir", "David McFarland", "Becky Farley" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2006
    }, {
      "title" : "State- Transition Interpolation and MAP Adaptation for HMMbased Dysarthric Speech Recognition",
      "author" : [ "Harsh Vardhan Sharma", "Mark Hasegawa-Johnson" ],
      "venue" : "Proceedings of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive Technologies,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2010
    }, {
      "title" : "Acoustic model adaptation using in-domain background models for dysarthric speech recognition",
      "author" : [ "Harsh Vardhan Sharma", "Mark Hasegawa-Johnson" ],
      "venue" : "Computer Speech & Language",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2013
    }, {
      "title" : "Evolutionary approach for integration of multiple pronunciation patterns for enhancement of dysarthric speech recognition",
      "author" : [ "Santiago Omar Caballero Morales", "Felipe Trujillo-Romero" ],
      "venue" : "Expert Syst. Appl",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2014
    }, {
      "title" : "Artificial neural networks as speech recognisers for dysarthric speech: Identifying the best-performing set of MFCC parameters and studying a speaker-independent approach",
      "author" : [ "Seyed Reza Shahamiri", "Siti Salwah Binti Salim" ],
      "venue" : "Advanced Engineering Informatics",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2014
    }, {
      "title" : "Analysis of MLP Based Hierarchical Phoneme Posterior Probability Estimator",
      "author" : [ "Joel Pinto", "G.S.V.S. Sivaram", "Mathew Magimai Doss" ],
      "venue" : "IEEE Audio, Speech and Language Processing,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2010
    }, {
      "title" : "Hidden Neural Network for Complex Pattern Recognition: A Comparison Study with Multi- Neural Network Based Approach",
      "author" : [ "Lilia Lazli", "Mounir Boukadoum" ],
      "venue" : "International Journal of Life Science and Medical Research,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2013
    }, {
      "title" : "Application for Speech Recognition and Medical Dignoias”, International Journal of Digital Information and Wireless Communications (IJDIWC",
      "author" : [ "Lilia Lazli", "Boukadoum Mounir", "Abdennasser Chebira", "Kurosh Madani", "Mohamed Tayeb Laskri" ],
      "venue" : "The Society of Digital Information and Wireless Communications, (ISSN 2225-658X),",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "[1, 2]",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 1,
      "context" : "[1, 2]",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 2,
      "context" : "[3, 4]",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 3,
      "context" : "Harsh Sharma & Mark Johnson [5] has applied various different algorithms and its combination for the adaptation of the system based on HMM acoustic modelling technique like Maximum A-posterior Probability (MAP) adaptation for Speaker independent (SI) system and Transition probability matrix (Linear interpolation) for Speaker Dependent (SD) and Speaker Adapted (SA) with 12 PLP coefficients along with velocity and acceleration coefficients forming 39 dimensional acoustic feature vector using UA speech database and concluded that adaptation of various parameters leads to increase in word recognition rate or overall system.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 4,
      "context" : "Harsh Sharma & Mark Johnson [6] have attempted to explicit modelling by first considering the mismatch between unimpaired and Dysarthric speech among the population and model is prepared.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 5,
      "context" : "Santiago & Caballero [8] performed integration of different pronunciation pattern by weighting the responses of an Automatic Speech Recognition (ASR) system when different language model restrictions are set.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 6,
      "context" : "Shahamiri & Salim [9] have tried to find out best performing set of MFCC feature extracted set for the usage of ANN acoustic modelling technique and stated that SD and SA have poor performance in terms of speaker's generalizability, so adopted SI approach in his work.",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 7,
      "context" : "Joel Pinto & Hermansky [10] analyze a simple hierarchical architecture consisting of two multilayer perceptron (MLP) classifiers.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 8,
      "context" : "Lilia Lazli & Mounir [11] compared two different approach using speech and biomedical database which are: 1) MultiNetwork Radial Basis Function (RBF) / Learning Vector Quantization (LVQ) structure, 2) Hybrid HMM/MLP approach along with K-means clustering algorithm for normal speech and obtained on an average of 90% WRA for HMM/MLP hybrid approach which performs better than multi-network RBF/LVQ method.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 9,
      "context" : "Lilia Lazli & Mounir [12] compared five different methods which are: (1) Multi network RBF/LVQ structure (2) Discrete Hidden Markov Models (HMM) (3) Hybrid HMM & MLP system using a Multi-Layer Perceptron (MLP) to estimate the HMM emission probabilities and using the K-means algorithm for pattern clustering (4) Hybrid HMM-MLP system using the Fuzzy C-Means (FCM) algorithm for fuzzy pattern clustering and (5) Hybrid HMM-MLP system using the Genetic Algorithm using three different database (unimpaired speech) along with biomedical speech database.",
      "startOffset" : 21,
      "endOffset" : 25
    } ],
    "year" : 2015,
    "abstractText" : "Dysarthria is malfunctioning of motor speech caused by faintness in the human nervous system. It is characterized by the slurred speech along with physical impairment which restricts their communication and creates the lack of confidence and affects the lifestyle. This paper attempt to increase the efficiency of Automatic Speech Recognition (ASR) system for unimpaired speech signal. It describes state of art of research into improving ASR for speakers with dysarthria by means of incorporated knowledge of their speech production. Hybridized approach for feature extraction and acoustic modelling technique along with evolutionary algorithm is proposed for increasing the efficiency of the overall system. Here number of feature vectors are varied and tested the system performance. It is observed that system performance is boosted by genetic algorithm. System with 16 acoustic features optimized with genetic algorithm has obtained highest recognition rate of 98.28% with training time of 5:30:17. Keywords— Dysarthria, Hybrid Log RASTA Perceptive Linear Prediction/Neural Network, Hybrid Hidden Markov Model/ Multilayer Perceptron, Genetic Algorithm",
    "creator" : "Microsoft® Word 2013"
  }
}