{
  "name" : "1406.3692.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Analyzing Social and Stylometric Features to Identify Spear phishing Emails",
    "authors" : [ "Prateek Dewan", "Anand Kashyap", "Ponnurangam Kumaraguru" ],
    "emails" : [ "prateekd@iiitd.ac.in,", "pk@iiitd.ac.in,", "kashyap@symantec.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "I. INTRODUCTION\nA new race of insidious threats called Advanced Persistent Threats (APTs) have joined the league of eCrime activities on the Internet, and caught a lot of organizations off guard in the fairly recent times. Critical infrastructures and the governments, corporations, and individuals supporting them are under attack by these increasingly sophisticated cyber threats. The goal of the attackers is to gain access to intellectual property, personally identifiable information, financial data, and targeted strategic information. This is not simple fraud or hacking, but intellectual property theft and infrastructure corruption on a grand scale [7]. APTs use multiple attack techniques and vectors that are conducted by stealth to avoid detection, so that hackers can retain control over target systems unnoticed for long periods of time. Interestingly, no matter how sophisticated these attack vectors may be, the most common ways of getting them inside an organization’s network are\nsocial engineering attacks like phishing, and targeted spear phishing emails. There have been numerous reports of spear phishing attacks causing losses of millions of dollars in the recent past. 1 2 Although there exist antivirus, and other similar protection software to mitigate such attacks, it is always better to stop such vectors at the entry level itself [21]. This requires sophisticated techniques to deter spear phishing attacks, and identify malicious emails at a very early stage itself.\nIn this research paper, we focus on identifying such spear phishing emails, wherein the attacker targets an individual or company, instead of anyone in general. Spear phishing emails ususally contain victim-specific context instead of general content. Since it is targeted, a spear phishing attack looks much more realistic, and thus, harder to detect [16]. A typical spear phishing attack can broadly be broken down into two phases. In the first phase, the attacker tries to gather as much information about the victim as possible, in order to craft a scenario which looks realistic, is believable for the victim, and makes it very easy for the attacker to attain the victim’s trust. In the second phase, the attacker makes use of this gained trust, and draws the victim into giving out sensitive / confidential information like a user name, password, bank account details, credit card details, etc. The attacker can also exploit the victim’s trust by infecting the victim’s system, through luring them into downloading and opening malicious attachments [16]. While spear phishing may be a timeworn technique, it continues to be effective even in today’s Web 2.0 landscape. A very recent example of such a spear phishing attack was reported by FireEye. Here, attackers exploited the news of the disappearance of Malaysian Airlines Flight MH370, to lure government officials across the world into opening malicious attachments (Figure 1) sent to them over email [25]. In 2011, security firm RSA suffered a breach via a targeted attack; analysis revealed that the compromise began with the opening of a spear phishing email. 3 That same year, email service provider Epsilon also fell prey to a spear phishing attack that caused the organization to lose an estimated US$4 billion. 4 These examples indicate that spear phishing has been, and continues to be one of the biggest forms of eCrime over the past few years, especially in terms of the monetary losses incurred.\n1http://businesstech.co.za/news/internet/56731/south-africas-3-billionphishing-bill/\n2http://www.scmagazine.com/stolen-certificates-used-to-deliver-trojans-inspear-phishing-campaign/article/345626/\n3http://blogs.rsa.com/rivner/anatomy-of-an-attack/ 4http://www.net-security.org/secworld.php?id=10966\nar X\niv :1\n40 6.\n36 92\nv1 [\ncs .C\nY ]\n1 4\nJu n\n20 14\nSpear phishing was first studied as context aware phishing by Jakobsson et al. in 2005 [15]. A couple of years later, Jagatic et al. performed a controlled experiment and found that the number of victims who fell for context aware phishing / spear phishing is 4.5 times the number of victims who fell for general phishing [14]. This work was preliminary proof that spear phishing attacks have a much higher success rate than normal phishing attacks. It also highlighted that, what separates a regular phishing attack from a spear phishing attack is the additional information / context. Online social media services like LinkedIn, which provide rich professional information about individuals, can be one such source for extracting contextual information, which can be used against a victim. Recently, the FBI also warned that spear phishing emails typically contain accurate information about victims often obtained from data posted on social networking sites, blogs or other websites. 5 In this work, we investigate if publicly available information from LinkedIn can help in differentiating a spear phishing from a non spear phishing email received by an individual. We attained a dataset of true positive targeted spear phishing emails, and a dataset of a mixture of non targeted, spam and phishing attack emails from the Symantec’s enterprise email scanning service, which is deployed at multiple international organizations around the world. To conduct the analysis at the organizational level, we extracted the most frequently occurring domains from the “to” fields of these emails, and filtered out 14 most targeted organizations, where the first name and last name could be derived from the email address. Our final dataset consisted of 4,742 spear phishing emails sent to 2,434 unique employees, and 9,353 non targeted spam / phishing emails to 5,914 unique employees. For a more exhaustive analysis, we also used a random sample of 6,601 benign emails from the Enron email dataset [6] sent to 1,240 unique employees with LinkedIn profiles.\nWe applied 4 classification algorithms, and were able to achieve a maximum accuracy of 97.04% for classifying spear phishing, and non spear phishing emails using a combination\n5http://www.computerweekly.com/news/2240187487/FBI-warns-ofincreased-spear-phishing-attacks\nof email features, and social features. However, without the social features, we were able to achieve a slightly higher accuracy of 98.28% for classifying these emails. We then looked at the most informative features, and found that email features performed better than social features at differentiating targeted spear phishing emails from non targeted spam / phishing emails, and benign Enron emails. To the best of our knowledge, this is the first attempt at making use of a social media profile of a user to distinguish targeted spear phishing emails from non targeted attack emails, received by her. Having found that social features extracted from LinkedIn profiles do not help in distinguishing spear phishing and non spear phishing emails, our results encourage to explore other social media services like Facebook, and Twitter. Such studies can be particularly helpful in mitigating APTs, and reducing the chances of attacks to an organization at the entry level itself.\nThe rest of the paper is arranged as follows. Section II discuss the related work, Section III describes our email and LinkedIn profile datasets, and the data collection methodology. The analysis and results are described in Section IV. We conclude our findings, and discuss the limitations, contributions, and scope for future work in Section V."
    }, {
      "heading" : "II. BACKGROUND AND RELATED WORK",
      "text" : "The concept of targeted phishing was first introduced in 2005 as social phishing or context-aware phishing [15]. Authors of this work argued that if the attacker can infer or manipulate the context of the victim before the attack, this context can be used to make the victim volunteer the target information. This theory was followed up with an experiment where Jagatic et al. harvested freely available acquaintance data of a group of Indiana University students, by crawling social networking websites like Facebook, LinkedIn, MySpace, Orkut etc. [14]. This contextual information was used to launch an actual (but harmless) phishing attack targeting students between the age group of 18-24 years. Their results indicated about 4.5 times increase in the number of students who fell for the attack which made use of contextual information, than the generic phishing attack. However, authors of this work do not provide details of the kind and amount of information they were able to gather from social media websites about the victims.\na) Who falls for phish: Dhamija et al. provided the first empirical evidence about which malicious strategies are successful at deceiving general users [8]. Kumaraguru et al. conducted a series of studies and experiments on creating and evaluating techniques for teaching people not to fall for phish [19], [20], [21]. Lee studied data from Symantec’s enterprise email scanning service, and calculated the odds ratio of being attacked for these users, based on their area of work. The results of this work indicated that users with subjects “Social studies”, and “Eastern, Asiatic, African, American and Australasian Languages, Literature and Related Subjects” were both positively correlated with targeted attacks at more than 95% confidence [22]. Sheng et al. conducted an online survey with 1,001 participants to study who is more susceptible to phishing based on demographics. Their results indicated that women are more susceptible than men to phishing, and participants between the ages 18 and 25 are more susceptible\nto phishing than other age groups [27]. In similar work, Halevi et al. found a strong correlation between gender and response to a prize phishing email. They also found that neuroticism is the factor most correlated to responding to the email. Interestingly, authors detected no correlation between the participants’ estimate of being vulnerable to phishing attacks and actually being phished. This suggests susceptibility to phishing is not due to lack of awareness of the phishing risks, and that realtime response to phishing is hard to predict in advance by online users [10].\nb) Phishing email detection techniques: To keep this work focused, we concentrate only on techniques proposed for detecting phishing emails; we do not cover all the techniques used for detecting phishing URLs or phishing websites in general. Abu-Nimeh et al. [2] studied the performance of different classifiers used in text mining such as Logistic regression, classification and regression trees, Bayesian additive regression trees, Support Vector Machines, Random forests, and Neural networks. Their dataset consisted of a public collection of about 1,700 phishing mails, and 1,700 legitimate mails from private mailboxes. They focused on richness of word to classify phishing email based on 43 keywords. The features represent the frequency of “bag-of-words” that appear in phishing and legitimate emails. However, the ever-evolving techniques and language used in phishing emails might make it hard for this approach to be effective over a long period of time.\nVarious feature selection approaches have also been recently introduced to assist phishing detection. A lot of previous work [2], [4], [9] has focused on email content in order to classify the emails as either benign or malicious. Chandrasekaran et al. [4] presented an approach based on natural structural characteristics in emails. The features included number of words in the email, the vocabulary, the structure of the subject line, and the presence of 18 keywords. They tested on 400 data points which were divided into five sets with different type of feature selection. Their results were the best when more features were used to classify phishing emails using Support Vector Machine. Authors of this work proposed a rich set of stylometric features, but the dataset they used was very small as compared to a lot of other similar work. Fette et al. [9] on the other hand, considered 10 features which mostly examine URL and presence of JavaScript to flag emails as phishing. Nine features were extracted from the email and the last feature was obtained from WHOIS query. They followed a similar approach as Chandrasekaran et al. but using larger datasets, about 7,000 normal emails and 860 phishing emails. Their filter scored 97.6% F-measure, false positive rate of 0.13% and a false negative rate of 3.6%. The heavy dependence on URL based features, however, makes this approach ineffective for detecting phishing emails which do not contain a URL, or are attachment based attacks, or ask the user to reply to the phishing email with potentially sensitive information. URL based features were also used by Chhabra et al. to detect phishing using short URLs [5]. Their work, however, was limited to only URLs, and did not cover phishing through emails. Islam and Abawajy [13] proposed a multi-tier phishing detection and filtering approach. They also proposed a method for extracting the features of phishing email based on weights of message content and message header. The results of their experiments showed that the proposed algorithm reduces the false positive problems substantially with lower complexity.\nBehavior-based approaches have also been proposed by various researchers to determine phishing messages [28], [29]. Zhang et al. [29] worked on detecting abnormal mass mailing hosts in network layer by mining the traffic in session layer. Toolan et al. [28] investigated 40 features that have been used in recent literature, and proposed behavioral features such as number of words in sender field, total number of characters in sender field, difference between sender’s domain and replyto domain, and difference between sender’s domains and the email’s modal domain, to classify ham, spam, and phishing emails. Ma et al. [24] attempted to identify phishing email based on hybrid features. They derived 7 features categorized into three classes, i.e. content features, orthographic features, and derived features, and applied 5 machine learning algorithms. Their results stated that Decision Trees worked best in identifying phishing emails. Hamid et al. [12] proposed a hybrid feature selection approach based on combination of content and behaviour. Their approach mined attacker behavior based on email header, and achieved an accuracy of 94% on a publicly available test corpus.\nAll of the aforementioned work concentrates on distinguishing phishing emails from legitimate ones, using various types of features extracted from email content, URLs, header information etc. To the best of our knowledge, there exists little work which focuses specifically on targeted spear phishing emails. Further, there exists no work which utilizes features from the social media profiles of the victim in order to distinguish an attack email from a legitimate one. In this work, we direct our focus on a very specific problem of distinguishing targeted spear phishing emails from general phishing, spam, and benign emails. Further, we apply social features extracted from the LinkedIn profile of recipients of such emails to judge whether an email is a spear phishing email or not; which has never been attempted before, to the best of our knowledge. We performed our entire analysis on a real-world dataset derived from Symantec’s enterprise email scanning service."
    }, {
      "heading" : "III. DATA COLLECTION METHODOLOGY",
      "text" : "The dataset we used for the entire analysis, is a combination of two separate datasets, viz. a dataset of emails (combination of targeted attack and non targeted attack emails), and a dataset of LinkedIn profiles. We now explain both these datasets in detail."
    }, {
      "heading" : "A. Email dataset",
      "text" : "Our email dataset consisted of a combination of targeted spear phishing emails, non targeted spam and phishing emails, and benign emails. We obtained the targeted spear phishing emails from Symantec’s enterprise email scanning service. Symantec collects data regarding targeted attacks that consist of emails with malicious attachments. These emails are identified from the vast majority of non-targeted malware by evidence of there being prior research and selection of the recipient, with the malware being of high sophistication and low copy number. The process by which Symantec’s enterprise mail scanning service collects such malware has already been described elsewhere [1], [23]. The corpus almost certainly omits some attacks, and most likely also includes some non-targeted attacks, but nevertheless it represents a large number of sophisticated\ntargeted attacks compiled according to a consistent set of criteria which render it a very useful dataset to study.\nThe non targeted attack emails were also obtained from Symantec’s email scanning service. These emails were marked as malicious, and were a combination of malware, spam, and phishing. Both these datasets contained an enormously large number of emails received at hundreds of organizations around the world, where Symantec’s email scanning services are being used. Before selecting a suitable sample for organization level analysis, we present an overview of this entire data. Table I shows the top 20 most frequently occurring attachment names in the complete spear phishing and spam / phishing datasets. We found distinct differences in the type of attachment names in these two datasets. While names in spear phishing emails looked fairly genuine and personalized, attachment names in spam / phishing emails were irrelevant, and long. It was also interesting to see that the attachment names associated with spear phishing emails were less repetitive than those associated with spam / phishing emails. As visible in Table I, the most commonly occurring attachment name in spear phishing emails was found in less than 3.5% of all spear phishing emails, while in the case of spam / phishing emails, the most common attachment name was present in over 20% of all spam / phishing emails. This behavior reflects that attachments in spear phishing emails are named more carefully, and with more effort to make them look genuine.\nWe also looked at the most frequently spread file types in spear phishing, spam, and phishing emails. Table II shows the top 15 most frequently occurring file types in both the spear phishing and spam / phishing email datasets. Not surprisingly, both these datasets had notable presence of executable (.exe, .bat, .com), and compressed (.rar, .zip, .7z) file types. In fact, most of the file types spread through such emails were among the most frequently used file types in general, too. Microsoft Word, Excel, PowerPoint, and PDF files were also amongst the most frequently spread files. It was, however, interesting to note that lesser percentage of targeted spear phishing emails contained executables than spam / phishing emails. This reflects that attackers prepare targeted attacks\nsmartly as compared to spammers / phishers, and avoid using executables, which are more prone to suspicion.\nAll the emails present in our full dataset were collected over a period of slightly under 4 years, from March 2009 to December 2013. Figure 2 presents a timeline of the “received time” of all these emails. The spam / phishing emails were collected over a period of 3 years, from March 2009 to March 2012. The targeted spear phishing emails were also collected during a period of about 3 years, but from January 2011, to December 2013. The two datasets, thus, had data for a common time period of about 15 months, from January 2011, to March 2012. It was interesting to observe that during this period, while the number of spam and phishing emails saw a tremendous rise, the number of spear phishing emails did not vary too much. This characteristic was observed for the entire 3-year period for spear phishing emails. The number of spear phishing emails received in the beginning and end of our three year observation period saw a 238% rise, as compared to a rise of 35,422% percent in the number of spam / phishing emails.\nIn addition to the attachment information and timeline, we also looked at the “subject” fields of all the emails present\nin our datasets. Table III shows the top 20 most frequently occurring “subject lines” in our datasets. Evidently, “subjects” in both these datasets were very different in terms of context. Targeted spear phishing email subjects seemed to be very professional, talking about jobs, meetings, unclassified information etc. Spam / phishing email subjects, however, were observed to follow a completely different genre. These emails’ subjects were found to follow varied themes, out of which, three broad themes were fairly prominent: a) fake email delivery failure error messages, which lure victims into opening these emails to see which of their emails failed, and why; b) arrival of packages or couriers by famous courier delivery services – victims tend to open such messages out of curiosity, even if they are not expecting a package; and c) personalized messages via third party websites and social networks (Hallmark E-Card, hi5 friend request, and Facebook message in this case). Most of such spam / phishing emails have generic subjects, to which most victims can relate easily, as compared to spear phishing email subjects, which would seem irrelevant to most common users.\nIt is important to note that these statistics are for the complete datasets we obtained from Symantec. The total number of emails present in the complete dataset was of the order of hundred thousands. However, we performed our entire analysis on a sample picked from this dataset. The analysis in the rest of the paper talks about only this sample. To make our analysis more exhaustive, we also used a sample of benign emails from the Enron email dataset for our analysis [6]. All the three email datasets had duplicates, which we identified and removed by using a combination of 5 fields, viz. from ID, to ID, subject, body, and timestamp. On further investigation, we found that these duplicate email messages were different instances of the same email. This happens when an email is sent to multiple recipients at the same time. A globally unique message-id is generated for each recipient, and thus results in duplication of the message. Elimination of duplicates reduced our email sample dataset by about 50%. Our final sample email dataset that we used for all our analysis was, therefore, a mixture of targeted attack emails, non targeted attack emails, and benign emails. We now describe this sample."
    }, {
      "heading" : "B. Email Sample Dataset Description",
      "text" : "To focus our analysis at the organization level, we identified and extracted the most attacked organizations (excluding free email providing services like Gmail, Yahoo, Hotmail etc.) from the domain names of the victims’ email addresses, and picked 14 most frequently attacked organizations. We were however, restricted to pick only those organizations, where the first names and last names were easily extractable from the email addresses. The first name and last name were required to obtain the corresponding LinkedIn profiles of these victims (this process is discussed in detail in Section III-C). This restriction, in addition to removal of duplicates, left us with a total of 4,742 targeted spear phishing emails sent to 2,434 unique victims (referred to as SPEAR in the rest of the paper); 9,353 non targeted attack emails sent to 5,912 unique non victims (referred to as SPAM in the rest of the paper), and 6,601 benign emails from the Enron dataset, sent to 1,240 unique Enron employees (referred to as BENIGN in the rest of the paper). Further details of this dataset can be found in Table IV. Table contains the number of victims, and non victims in each of the 15 companies (including Enron), and the number of emails sent to them. The victim and non victim employee sets are mutually exhaustive, and each employee in these datasets received at least one email, and had at least one LinkedIn profile. To maintain anonymity, we do not include the name of the organizations we picked; we only mention the operation sector of these companies.\nFigures 3(a), 3(c), and 3(d) represent the tag clouds of the 100 most frequently occurring words in the “subject” fields of our SPEAR, SPAM, and BENIGN datasets respectively. We noticed considerable differences between subjects from all the three datasets. While all three datasets were observed to have a lot of forwarded emails (represented by “fw”, and “fwd” in the tag clouds), SPAM and BENIGN datasets were found to have much more reply emails (signified by “re” in the tag clouds) as compared to SPEAR emails. These characteristics of whether an email is forwarded, or a reply, have previously been used as boolean features by researchers to distinguish between phishing and benign emails [28]. The difference in vocabularies used across the three email datasets\nis also notable. The SPEAR dataset (Figure 3(a)) was found to be full of attention-grabbing words like strategy, unclassified, warning, weapons, defense, US Army etc. Artifact V shows an example of the attachment name, subject and body of such an email. We removed the received address and other details to maintain anonymity.\nSPAM emails in our dataset (Figure 3(c)) followed a completely different genre, dominated by words like parcel, order, delivery, tracking, notification, shipment etc. We also found mentions of famous courier service brand names like FedEx and DHL which seem to have been used for targeting victims. Such attacks have been widely talked about in the recent past; users have also been warned about scams, and infected payloads (like spyware or malware), that accompany such emails. 6 7 Some examples of attachment names, and subjects of such non targeted SPAM emails are shown in Artifact VI. BENIGN subjects comprised of diverse keywords like report, program, meeting, migration, energy, which did not seem specific to a particular theme (Figure 3(d)). These keywords were fairly representative of the kind of typical internal communication that may have been going on in the company.\n6http://nakedsecurity.sophos.com/2013/03/20/dhl-delivery-malware/ 7http://www.spamfighter.com/News-13360-FedEx-and-DHL-Spam-\nAttack-with-Greater-Ferocity.htm\nWe also compared the body content of SPEAR and BENIGN emails. Figures 3(b) and 3(e) represent the tag clouds of the 100 most frequently occurring words in the body fields of the SPEAR and BENIGN datasets respectively. Contrary to our observations from the subject content in the SPEAR dataset (Figure 3(a)), the body content of the SPEAR emails (Figure 3(b)) did not look very attention-grabbing or themed. SPEAR bodies contained words like attached, please, email, dear, materials, phone etc., which commonly occur in routine email communications too. The BENIGN body content did not contain anything peculiar or alarming either (Figure 3(e)). Since Symantec’s email dataset of spear phishing, spam and phishing emails isn’t publicly available, we believe that this characterization of our dataset can be useful for researchers to get a better idea of state-of-the-art, real world malicious email data which circulates in the corporate environment."
    }, {
      "heading" : "C. LinkedIn profile dataset",
      "text" : "Our second dataset consisted of LinkedIn profiles of the receivers of all the emails present in our email dataset. In fact, we restricted our email dataset to only those emails which were sent to employees having at least one LinkedIn profile. This was done to have a complete dataset in terms of the availability of social and stylometric features. There were two major challenges with data collection from LinkedIn; a) Strict input requirements, and b) Rate limited API.\nFirstly, to fetch the profiles of LinkedIn users who are outside a user’s network (3rd degree connections and beyond), the LinkedIn People Search API requires first name, last name, and company name as a mandatory input. 8 Understandably, none of the users we were looking for, were in our network, and thus, as specified in the previous subsection, we were restricted to pick up emails of only those companies which followed the format firstName.lastName@companyDomain or firstName lastName@companyDomain. Restricting our dataset to such email addresses was the only way we could satisfy the API’s input requirements.\nSecondly, the rate limit of the people search API posed a major hindrance. Towards the end of 2013, LinkedIn imposed\n8developer.linkedin.com/documents/people-search-api\na tight limit of 250 calls per day, per application, on the people search API for existing developers, and completely restricted access for new applications and developers, under their Vetted API access program. 9 We were able to get access to the Vetted API for two of our applications. Although the new rate limit allowed 100,000 API calls per day, per application, this was still restricted to 100 calls per user, per day, per application. We then created multiple LinkedIn user accounts to make calls to the API. Even with multiple applications, and user accounts, this data collection process took about 4 months. This happened because a lot of our search queries to the API returned no results. On average, we were able to find a LinkedIn profile for only 1 in 10 users in our dataset. This resulted in about 90% of the API calls returning no results, and hence getting wasted. Eventually, we were able to collect a total of 2,434 LinkedIn profiles of victims, 5,914 LinkedIn profiles of non victims, across the 14 organizations; and 1,240 LinkedIn profiles of employees from Enron (Table IV). To obtain these profiles for the 9,588 employees (2,434 victims, 5,914 non victims, and 1,240 Enron employees), the number of API calls we had to make was approximately 100,000 (approx. 10 times the number of profiles obtained). Figure 4 shows the flow diagram describing our data collection process.\nOur first choices for extracting social features about employees were Facebook, and Twitter. However, we found that identifying an individual on Facebook and Twitter using only the first name, last name, and employer company was a hard task. Unlike LinkedIn, the Facebook and Twitter APIs do not provide endpoints to search people using the work company name. This left us with the option to search for people using first name, and last name only. However, searching for people using only these two fields returned too many results on\n9https://developer.linkedin.com/blog/vetted-api-access\nboth Facebook and Twitter, and we had no way to identify the correct user that we were looking for. We then visited the profile pages of some users returned by the API results manually, and discovered that the work field for most users on Facebook was private. On Twitter profiles, there did not exist a work field at all. It thus became very hard to be able to find Facebook or Twitter profiles using the email addresses in our dataset."
    }, {
      "heading" : "IV. ANALYSIS AND RESULTS",
      "text" : "To distinguish spear phishing emails from non spear phishing emails using social features of the receivers, we used four machine learning algorithms, and a total of 27 features; 18 stylometric, and 9 social. The entire analysis and classification tasks were performed using the Weka data mining software [11]. We applied 10-fold cross validation to validate our classification results. We now describe our feature sets, analysis, and results of the classification.\nAttachment: All information about mobile phone.rar Subject: RE: Issues with Phone for help Body: <name>, Thanks for your replying.I contacted my supplier,but he could not resolved it.Now I was worried, so I take the liberty of writing to you.I collect all information including sim card details,number,order record and letters in the txt file.I hope you can deal with the issues as your promised. Best, <name>\n—–Original Message—– From: Customer Care [mailto:Customer Care@<companyDomain>] Sent: 2011-12-8 0:35 To: <name> Cc: Subject: RE: Issues with Phone for help\nDear <name>,\nThank you for your E-mail. I am sorry to hear of your issues. Please can you send your SIM card details or Mobile number so that we can identify your supplier who can assist you further?\nThank you\nKind regards,\n<name> Customer Service Executive\n<Company Name>, <Company Address> United Kingdom\nTel: <telephone number> Fax : <Fax number> <company website>\n—–Original Message—– From: <name> [mailto:<email address>] Sent: 08 December 2011 08:27 To: support@<companyDomain> Subject: Issues with Phone for help\nHello, I purchased order for your IsatPhone Pro six months ago.Now I have trouble that it can’t work normally.It often automatic shuts down.Sometimes it tells some information that i can’t understand.How to do?Can you help me? Best, <name>\nThis e-mail has been scanned for viruses by Verizon Business Internet Managed Scanning Services - powered by MessageLabs. For further information visit http://www.verizonbusiness.com/uk\nARTIFACT V. A SPEAR PHISHING EMAIL FROM OUR SPEAR DATASET. THE EMAIL SHOWS A SEEMINGLY GENUINE CONVERSATION,\nWHERE THE ATTACKER SENT A MALICIOUS COMPRESSED (.RAR) ATTACHMENT TO THE VICTIM IN THE MIDDLE OF THE CONVERSATION.\nAttachment: 100A 0.txt Subject: DHL Express Notification for shipment 15238305825550113 Attachment: ./attach/100 4X AZ-D PA2 FedEx=5FInvoice=5FN 56=2D141.exe Subject: FEDEX Shipment Status NR-6804\nARTIFACT VI. EXAMPLES OF subject AND attachment NAMES OF TWO SPAM EMAILS FROM OUR SPAM DATASET. THE body FIELD OF THE\nEMAILS WAS NOT AVAILABLE IN THIS DATASET."
    }, {
      "heading" : "A. Feature set description",
      "text" : "We extracted a set of 18 stylometric features from each email in our email dataset, and a set of 9 social features from each LinkedIn profile present in our LinkedIn profile dataset, features described in Table VII. Features extracted from our email dataset are further categorized into three categories,\nviz. subject features, attachment features, and body features. It is important to note that we did not have all the three types of these aforementioned features available for all our datasets. While the SPAM dataset did not have body features, the BENIGN dataset did not have the attachment features. Features marked with ∗ (in Table VII) have been previously used by researchers to classify spam and phishing emails [28]. The richness feature is calculated as the ratio of the number of words to the number of characters present in the text content under consideration. We calculate richness value for the email subject, email body, and LinkedIn profile summary. The Body hasAttach features is a boolean variable which is set to true, if the body of the email contain the word “attached” or “attachment”, indicating that an attachment is enclosed with the email. This feature helped us to capture the presence of attachments for the BENIGN dataset, which did not have attachment information. The Body numFunctionWords feature captures the total number of occurrences of function words present in the email body, from a list of function words which includes the words: account, access, bank, credit, click, identity, inconvenience, information, limited, log, minutes, password, recently, risk, social, security, service, and suspended. These features have been previously used by Chandrasekaran [4].\nThe social features we extracted from the LinkedIn profiles, captured three distinct types of information about an employee, viz. location, connectivity, and profession. The Location was a text field containing the state / country level location of an employee, as specified by her on her LinkedIn profile. We extracted and used the country for our analysis. The numConnections was a numeric field, and captured the number of connections that a user has on LinkedIn. If the number of connections for a user is more than 500, the value returned is “500+” instead of the actual number of connections. These features captured the location and connectivity respectively.\nIn addition to these two, we extracted 5 features from the Summary field, and 2 features from the headline field returned by LinkedIn’s People Search API. The Summary field is a long, free-text field comprising of a summary about a user, as specified by her, and is optional. The features we extracted from this field were similar to the ones we extracted from the subject and body fields in our email dataset. These features were, the summary length, number of characters, number of unique words, total number of words, and richness. We introduced two new features, job level and job type, which are numeric values ranging from 0 to 7, and 0 to 9 respectively, describing the position and area of work of an individual. We looked for presence of certain level and designation specific keywords in the “headline” field of a user, as returned by the LinkedIn API. The job levels and job types, and their numeric equivalents are as follows:\n• Job level; maximum of the following: 1 - Support 2 - Intern 3 - Temporary 4 - IC 5 - Manager 6 - Director 7 - Executive 0 - Other; if none of the above are found.\n• Job type; minimum of the following: 1 - Engineering 2 - Research 3 - QA 4 - Information Technology 5 - Operations 6 - Human Resources 7 - Legal 8 - Finance 9 - Sales / Marketing 0 - Other; if none of the above are found.\nTo see if information extracted about a victim from online social media helps in identifying a spear phishing email sent to her, we performed classification using a) email features 10; b) social features, and c) using a combination of these features. We compared these three accuracy scores across a combination of datasets viz. SPEAR versus SPAM emails from Symantec’s email scanning service, SPEAR versus benign emails from BENIGN dataset, and SPEAR versus a mixture of emails from BENIGN, and SPAM from the Symantec dataset. As mentioned earlier, not all email features mentioned in Table VII were available for all the three email datasets. The BENIGN dataset did not have attachment related features, and the body field was missing in the SPAM email dataset. We thus used only those features for classification, which were available in both the targeted, and non targeted emails."
    }, {
      "heading" : "B. SPEAR versus SPAM emails from Symantec",
      "text" : "Table VIII presents the results of our first analysis where we subjected SPEAR and SPAM emails from Symantec, to four machine learning classification algorithms, viz. Random Forest [3], J48 Decision Tree [26], Naive Bayesian [17], and\n10We further split email features into subject, body, and attachment features for analysis, wherever available.\nDecision Table [18]. Feature vectors for this analysis were prepared from 4,742 SPEAR emails, and 9,353 SPAM emails, combined with social features extracted from the LinkedIn profiles of receivers of these emails. Using a combination of all email and social features, we were able to achieve a maximum accuracy of 96.47% using the Random Forest classifier for classifying SPEAR and SPAM emails. However, it was interesting to notice that two out of the four classifiers performed better without the social features. Although the Decision Table classifier seemed to perform equally well with, and without the social features, it performed much better using only email features, as compared to only social features. 11 In fact, the Decision Table classifier achieved the maximum accuracy using attachment features, which highlights that the attachments associated with SPEAR and SPAM emails were also substantially different in terms of name and size. We achieved an overall maximum accuracy of 98.28% using the Random Forest classifier trained on only email features. This behavior revealed that the public information available on the LinkedIn profile of an employee in our dataset, does not help in determining whether she will be targeted for a spear phishing attack or not.\nTo get a better understanding of the results, we looked at the information gain associated with each feature using the InfoGainAttributeEval Attribute Evaluator package. 12 This package calculates the information gain 13 associated with each feature, and ranks the features in descending order of the information gain value. The ranking revealed that the attachment related features were the most distinguishing features between SPEAR and SPAM emails. This phenomenon was also highlighted by the Decision Table classifier (Table VIII). The attachment size was the most distinguishing feature with an information gain score of 0.631, followed by length of attachment name, with an information gain score of 0.485. As evident from Table IX, attachment sizes associated with SPAM emails have very high standard deviation values, even though the average attachment sizes of SPAM and SPEAR emails are fairly similar. It is also evident that attachments associated with SPAM emails tend to have longer names; on average, twice in size as compared to attachments associated with SPEAR emails. Among subject features, we found no major difference\n11This happened because the Decision Table classifier terminates search after scanning for a certain (fixed) number of non-improving nodes / features.\n12http://weka.sourceforge.net/doc.dev/weka/attributeSelection/ InfoGainAttributeEval.html\n13This value ranges between 0 and 1, where a higher value represents a more discriminating feature.\nin the length (number of characters, and number of words) of the subject fields across the two email datasets.\nIt was interesting to see that apart from the Location, number of LinkedIn connections, and SummaryRichness, none of the other social features were ranked amongst the top 10 informative features. Figure 5 shows the top 25 Locations extracted from the LinkedIn profiles of employees of the 14 companies who received SPAM and SPEAR emails. We found a fairly high correlation of 0.88 between the number of SPAM and SPEAR emails received at these locations, depicting that there is not much difference between the number of SPAM and SPEAR emails received by most locations. This falls in line with the low information gain associated with this feature. Among the top 25, only 3 locations viz. France, Australia, and Afghanistan received more SPEAR emails than SPAM emails.\nThe number of LinkedIn connections of the recipients of SPEAR and SPAM emails in our dataset are presented in Figure 6. There wasn’t much difference between the number of LinkedIn connections of recipients of SPEAR emails, and the number of LinkedIn connections of recipients of SPAM emails. We grouped the number of LinkedIn connections into 11 buckets as represented by the X axis in Figure 6, and found a strong correlation value of 0.97 across the two classes (SPEAR and SPAM). This confirmed that the number of LinkedIn connections did not vary much between recipients of SPEAR and SPAM emails, and thus, is not an informative feature for distinguishing between SPEAR and SPAM emails."
    }, {
      "heading" : "C. SPEAR emails versus BENIGN emails",
      "text" : "Similar to the analysis performed in Section IV-B, we applied machine learning algorithms on a different dataset containing SPEAR emails, and BENIGN emails. This dataset contained 4,742 SPEAR emails, and 6,601 benign emails from BENIGN. Since BENIGN mostly contains internal email communication between Enron’s employees, we believe that it is safe to assume that none of these emails would be targeted spear phishing emails, and can be marked as benign. Similar to our observations in Section IV-B, we found that, in this case too, only email features performed slightly better than a combination of email and social features, at distinguishing spear phishing emails from non spear phishing emails. We were able to achieve a maximum accuracy of 97.04% using the Random Forest classifier trained on a set of 25 features; 16 email, and 9 social features. However, the overall maximum accuracy that we were able to achieve for this dataset was 97.39%, using only email features. Table X shows the results of our analysis in detail. Three out of the four classifiers performed best with email features; two classifiers performed best using a combination of subject and body features, while one classifier performed best using only body features. The Naive Bayes classifier worked best using social features.\nTable XI presents the 10 most informative features, along with their information gain, mean and standard deviation values from the SPEAR and BENIGN datasets. The body features were found to be the most informative in this analysis,\nwith only 2 social features among the top 10. Emails in the BENIGN dataset were found to be much longer than SPEAR emails in our Symantec dataset in terms of number of words, and number of characters in their “body”. The “subject” lengths, however, were found to be very similar across SPEAR and BENIGN.\nThe Random Forest classifier was also able to achieve an accuracy rate of 94.48% using only social features; signifying that there exist distinct differences between the LinkedIn profiles of Enron employees, and the LinkedIn profiles of the employees of the 14 companies in our dataset. The location attribute was found to be the most distinguishing feature among the social features. This was understandable since most of the Enron employees were found to be based in the US (as Enron was an American services company). However, we also found a considerable difference in the average number of LinkedIn connections of Enron employees, and employees of the 14 organizations from our dataset (mean values for numConnections feature in Table XI)."
    }, {
      "heading" : "D. SPEAR versus a mixture of BENIGN and SPAM",
      "text" : "While analyzing SPEAR with SPAM, and BENIGN emails separately, we found similar results where social features were not found to be very useful in both the cases. So we decided to use a mixture of SPAM and BENIGN emails against SPEAR emails, and perform the classification tasks again. We found that in this case, two out of the four classifiers performed better with a combination of email and social features, while two classifiers performed better with only email features. However, the overall maximum accuracy was achieved using a combination of email and social features (89.86% using Random Forest classifier). This result is in contradiction with our analysis of SPEAR versus SPAM, and SPEAR versus BENIGN separately, where email features always performed better independently, than a combination of email and social features. Our overall maximum accuracy, however, dropped to 89.86% (from 98.28% in SPEAR versus SPAM email classification) because of the absence of attachment features in this dataset. Although the attachment features were available in the SPAM dataset, their unavailability in BENIGN forced us to remove this feature for the current classification task. Eventually, merging the SPAM email dataset with BENIGN reduced our email dataset to only 7 features, all based on the email “subject”. Table XII presents the detailed results from this analysis.\nAs mentioned earlier, combining the SPAM email dataset with BENIGN largely reduced our email feature set. We were left with 7 out of a total of 18 email features described in Table VII. Understandably, due to this depleted email feature set, we found that the email features did not perform as good as social features in this classification task. Despite being fewer in number, the subject features, viz. Subject richness and Subject numChars were found to be two of the most informative features (Table XIII). However, the information gain value associated with both these features was fairly low. This shows that even being the best features, the Subject richness and Subject numChars were not highly distinctive features amongst spear phishing, and non spear phishing emails. Similar mean and standard deviation values for both these features in Table XIII confirm these outcomes.\nContrary to our observations in SPEAR versus SPAM, and SPEAR versus BENIGN emails, we found five social features among the top 10 features in this analysis. These were the Location, numConnections, SummaryNumChars, Richness, and jobLevel features. Although there was a significant difference between the average number of LinkedIn connections in the two datasets, this feature did not have much information gain associated with it due to the very large standard deviation."
    }, {
      "heading" : "V. DISCUSSION",
      "text" : "In this paper, we attempted to utilize social features from LinkedIn profiles of employees from 14 organizations, to distinguish between spear phishing and non spear phishing emails. We extracted LinkedIn profiles of 2,434 employees who received a 4,742 targeted spear phishing emails; 5,914 employees who received 9,353 spam or phishing emails; and 1,240 Enron employees who received 6,601 benign emails.\nWe performed our analysis on a real world dataset from Symantec’s enterprise email scanning service, which is one of the biggest email scanning services used in the corporate organizational level. Furthermore, we targeted our analysis completely on corporate employees from 14 multinational organizations instead of random real-world users. The importance of studying spear phishing emails in particular, instead of general phishing emails, has been clearly highlighted by Jagatic et al. [14]. We performed three classification tasks viz. spear phishing emails versus spam / phishing emails, spear phishing emails versus benign emails from Enron, and spear phishing emails versus a mixture of spam / phishing emails and benign Enron emails. We found that in two out of the three cases, social features extracted from LinkedIn profiles of employees did not help in determining whether an email received by them was a spear phishing email or not. Classification results from a combination of spam / phishing, and benign emails showed some promise, where social features were found to be slightly helpful. The depleted email feature sets in this case, however, aided the enhancement in classifier performance. We believe that it is safe to conclude that publicly available content on an employee’s LinkedIn profile was not used to send her targeted spear phishing emails in our dataset. However, we cannot rule out the possibility of such an attack outside our dataset, or in future. These attacks may be better detected with access to richer social features. This methodology of detecting spear phishing can be helpful for safeguarding soft targets for phishers, i.e. those who have strong social media footprint. Existing phishing email filters and products can also exploit this technique to improve their performance, and provide personalized phishing filters to individuals.\nThere can be multiple reasons for our results being nonintuitive. Firstly, the amount of social information we were able to gather from LinkedIn, was very limited. These limitations have been discussed in Section III-C. It is likely that in a real-world scenario, an attacker may be able to gain much more information about a victim prior to the attack. This could include looking for the victim’s profile on other social networks like Facebook, Twitter etc., looking for the victim’s presence on the Internet in general, using search engines (Google, Bing etc.), and profiling websites like Pipl 14, Yasni 15 etc. The process of data collection by automating this behavior was a time consuming process, and we were not able to take this approach due to time constraints. Secondly, it was not clear that which all aspect(s) of a user’s social profiles were most likely to be used by attackers against them. We tried to use all the features viz. textual information (summary and headline), connectivity (number of connections), work information (job level, and job type) and location information, which were made available by LinkedIn API, to perform our classification tasks. However, it is possible that none of these features were used by attackers to target their victims. In fact, we have no way to verify that the spear phishing emails in our dataset were even crafted using features from social profiles of the victims. These reasons, however, only help us in better understanding the concept of using social features in spear phishing emails.\nIn terms of research contributions, this work is based on a rich, true positive, real world dataset of spear phishing,\n14https://pipl.com/ 15http://www.yasni.com/\nspam, and phishing emails, which is not publicly available. We believe that characterization of this data can be very useful for the entire research community to better understand the stateof-the-art spear phishing emails that have been circulated on the Internet over the past two years. To maintain anonymity and confidentiality, we could not characterize this data further, and had to anonymize the names of the 14 organizations we studied. Also, after multiple reports highlighting and warning about social media features being used in spear phishing, there does not exist much work in the research community which studies this phenomenon.\nWe would like to emphasize that the aim of this work is not to try and improve the existing state-of-the-art phishing email detection techniques based on their header, and content features, but to see if the introduction of social media profile features can help existing techniques to better detect spear phishing emails. We believe that this work can be a first step towards exploring threats posed by the enormous amount of contextual information about individuals, that is present on online social media. In future, we would like to carry out a similar analysis using the same email dataset, with more social features, which we were not able to collect in this attempt due to time constraints. We would also like to apply more machine learning and classification techniques like Support Vector Machines, Stochastic Gradient boosting techniques etc. on this dataset to get more insights into why social features did not perform well."
    }, {
      "heading" : "VI. ACKNOWLEDGEMENT",
      "text" : "We would like to thank the Symantec team for providing us with the email data that we used for this work. We would also like to thank the members of Precog Research Group, and Cybersecurity Education and Research Center at IIIT-D for their support."
    } ],
    "references" : [ {
      "title" : "A comparison of machine learning techniques for phishing detection",
      "author" : [ "S. Abu-Nimeh", "D. Nappa", "X. Wang", "S. Nair" ],
      "venue" : "eCRS, pages 60–69. ACM",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Random forests",
      "author" : [ "L. Breiman" ],
      "venue" : "Machine Learning, 45(1):5–32",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Phishing email detection based on structural properties",
      "author" : [ "M. Chandrasekaran", "K. Narayanan", "S. Upadhyaya" ],
      "venue" : "NYS Cyber Security Conference, pages 1–7",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "and P",
      "author" : [ "S. Chhabra", "A. Aggarwal", "F. Benevenuto" ],
      "venue" : "Kumaraguru. Phi.sh/$ocial: the phishing landscape through short urls. In CEAS, pages 92–101. ACM",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Enron email dataset",
      "author" : [ "W.W. Cohen" ],
      "venue" : "Internet: www. cs. cmu. edu/enron/,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Advanced persistent threat",
      "author" : [ "M.K. Daly" ],
      "venue" : "23rd Large Installation System Administration Conference. USENIX, Baltimore",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Why phishing works",
      "author" : [ "R. Dhamija", "J.D. Tygar", "M. Hearst" ],
      "venue" : "CHI, pages 581–590. ACM",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Learning to detect phishing emails",
      "author" : [ "I. Fette", "N. Sadeh", "A. Tomasic" ],
      "venue" : "WWW, pages 649–656. ACM",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Phishing",
      "author" : [ "T. Halevi", "J. Lewis", "N. Memon" ],
      "venue" : "personality traits and facebook. arXiv preprint arXiv:1301.7643",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The weka data mining software: an update",
      "author" : [ "M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten" ],
      "venue" : "ACM SIGKDD explorations newsletter, 11(1):10–18",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "J",
      "author" : [ "I.R.A. Hamid" ],
      "venue" : "Abawajy, and T.-h. Kim. Using feature selection and classification scheme for automating phishing email detection. Studies In Informatics and Control, ISSN, pages 1220–1766",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A multi-tier phishing detection and filtering approach",
      "author" : [ "R. Islam", "J. Abawajy" ],
      "venue" : "Journal of Network and Computer Applications, 36(1):324– 335",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Social phishing",
      "author" : [ "T.N. Jagatic", "N.A. Johnson", "M. Jakobsson", "F. Menczer" ],
      "venue" : "Communications of the ACM, 50(10):94–100",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Modeling and preventing phishing attacks",
      "author" : [ "M. Jakobsson" ],
      "venue" : "Financial Cryptography, volume 5. Citeseer",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Phishing and countermeasures: understanding the increasing problem of electronic identity theft",
      "author" : [ "M. Jakobsson", "S. Myers" ],
      "venue" : "John Wiley & Sons",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Estimating continuous distributions in bayesian classifiers",
      "author" : [ "G.H. John", "P. Langley" ],
      "venue" : "Eleventh Conference on Uncertainty in Artificial Intelligence, pages 338–345, San Mateo",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "The power of decision tables",
      "author" : [ "R. Kohavi" ],
      "venue" : "8th European Conference on Machine Learning, pages 174–189. Springer",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "School of phish: a real-world evaluation of antiphishing training",
      "author" : [ "P. Kumaraguru", "J. Cranshaw", "A. Acquisti", "L. Cranor", "J. Hong", "M.A. Blair", "T. Pham" ],
      "venue" : "SOUPS, page 3. ACM",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Protecting people from phishing: the design and evaluation of an embedded training email system",
      "author" : [ "P. Kumaraguru", "Y. Rhee", "A. Acquisti", "L.F. Cranor", "J. Hong", "E. Nunge" ],
      "venue" : "CHI, pages 905–914. ACM",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Teaching johnny not to fall for phish",
      "author" : [ "P. Kumaraguru", "S. Sheng", "A. Acquisti", "L.F. Cranor", "J. Hong" ],
      "venue" : "ACM Transactions on Internet Technology (TOIT), 10(2):7",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Who’s next? identifying risks factors for subjects of targeted attacks",
      "author" : [ "M. Lee" ],
      "venue" : "Proc. Virus Bull. Conf, pages 301–306",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Clustering disparate attacks: mapping the activities of the advanced persistent threat",
      "author" : [ "M. Lee", "D. Lewis" ],
      "venue" : "Last accessed June, 26",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Detecting phishing emails using hybrid features",
      "author" : [ "L. Ma", "B. Ofoghi", "P. Watters", "S. Brown" ],
      "venue" : "Ubiquitous, Autonomic and Trusted Computing, 2009. UIC-ATC’09. Symposia and Workshops on, pages 493–497. IEEE",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Spear phishing the news cycle: Apt actors leverage interest in the disappearance of malaysian flight mh 370",
      "author" : [ "N. Moran", "A. Lanstein" ],
      "venue" : "http://www.fireeye.com/blog/technical/malwareresearch/2014/03/spear-phishing-the-news-cycle-apt-actors-leverageinterest-in-the-disappearance-of-malaysian-flight-mh-370.html",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Programs for Machine Learning",
      "author" : [ "R. Quinlan" ],
      "venue" : null,
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1993
    }, {
      "title" : "Who falls for phish?: a demographic analysis of phishing susceptibility and effectiveness of interventions",
      "author" : [ "S. Sheng", "M. Holbrook", "P. Kumaraguru", "L.F. Cranor", "J. Downs" ],
      "venue" : "CHI, pages 373–382. ACM",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Feature selection for spam and phishing detection",
      "author" : [ "F. Toolan", "J. Carthy" ],
      "venue" : "eCRS, pages 1–12. IEEE",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A behavior-based detection approach to mass-mailing host",
      "author" : [ "J. Zhang", "Z.-h. Du", "W. Liu" ],
      "venue" : "In Machine Learning and Cybernetics,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "This is not simple fraud or hacking, but intellectual property theft and infrastructure corruption on a grand scale [7].",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 19,
      "context" : "1 2 Although there exist antivirus, and other similar protection software to mitigate such attacks, it is always better to stop such vectors at the entry level itself [21].",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 14,
      "context" : "Since it is targeted, a spear phishing attack looks much more realistic, and thus, harder to detect [16].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 14,
      "context" : "The attacker can also exploit the victim’s trust by infecting the victim’s system, through luring them into downloading and opening malicious attachments [16].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 23,
      "context" : "Here, attackers exploited the news of the disappearance of Malaysian Airlines Flight MH370, to lure government officials across the world into opening malicious attachments (Figure 1) sent to them over email [25].",
      "startOffset" : 208,
      "endOffset" : 212
    }, {
      "referenceID" : 13,
      "context" : "in 2005 [15].",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 12,
      "context" : "5 times the number of victims who fell for general phishing [14].",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 4,
      "context" : "For a more exhaustive analysis, we also used a random sample of 6,601 benign emails from the Enron email dataset [6] sent to 1,240 unique employees with LinkedIn profiles.",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 13,
      "context" : "The concept of targeted phishing was first introduced in 2005 as social phishing or context-aware phishing [15].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 12,
      "context" : "[14].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 6,
      "context" : "provided the first empirical evidence about which malicious strategies are successful at deceiving general users [8].",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 17,
      "context" : "conducted a series of studies and experiments on creating and evaluating techniques for teaching people not to fall for phish [19], [20], [21].",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 18,
      "context" : "conducted a series of studies and experiments on creating and evaluating techniques for teaching people not to fall for phish [19], [20], [21].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 19,
      "context" : "conducted a series of studies and experiments on creating and evaluating techniques for teaching people not to fall for phish [19], [20], [21].",
      "startOffset" : 138,
      "endOffset" : 142
    }, {
      "referenceID" : 20,
      "context" : "The results of this work indicated that users with subjects “Social studies”, and “Eastern, Asiatic, African, American and Australasian Languages, Literature and Related Subjects” were both positively correlated with targeted attacks at more than 95% confidence [22].",
      "startOffset" : 262,
      "endOffset" : 266
    }, {
      "referenceID" : 25,
      "context" : "to phishing than other age groups [27].",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 8,
      "context" : "This suggests susceptibility to phishing is not due to lack of awareness of the phishing risks, and that realtime response to phishing is hard to predict in advance by online users [10].",
      "startOffset" : 181,
      "endOffset" : 185
    }, {
      "referenceID" : 0,
      "context" : "[2] studied the performance of different classifiers used in text mining such as Logistic regression, classification and regression trees, Bayesian additive regression trees, Support Vector Machines, Random forests, and Neural networks.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 0,
      "context" : "A lot of previous work [2], [4], [9] has focused on email content in order to classify the emails as either benign or malicious.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 2,
      "context" : "A lot of previous work [2], [4], [9] has focused on email content in order to classify the emails as either benign or malicious.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 7,
      "context" : "A lot of previous work [2], [4], [9] has focused on email content in order to classify the emails as either benign or malicious.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 2,
      "context" : "[4] presented an approach based on natural structural characteristics in emails.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[9] on the other hand, considered 10 features which mostly examine URL and presence of JavaScript to flag emails as phishing.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "to detect phishing using short URLs [5].",
      "startOffset" : 36,
      "endOffset" : 39
    }, {
      "referenceID" : 11,
      "context" : "Islam and Abawajy [13] proposed a multi-tier phishing detection and filtering approach.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 26,
      "context" : "Behavior-based approaches have also been proposed by various researchers to determine phishing messages [28], [29].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 27,
      "context" : "Behavior-based approaches have also been proposed by various researchers to determine phishing messages [28], [29].",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 27,
      "context" : "[29] worked on detecting abnormal mass mailing hosts in network layer by mining the traffic in session layer.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 26,
      "context" : "[28] investigated 40 features that have been used in recent literature, and proposed behavioral features such as number of words in sender field, total number of characters in sender field, difference between sender’s domain and replyto domain, and difference between sender’s domains and the email’s modal domain, to classify ham, spam, and phishing emails.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 22,
      "context" : "[24] attempted to identify phishing email based on hybrid features.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[12] proposed a hybrid feature selection approach based on combination of content and behaviour.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "The process by which Symantec’s enterprise mail scanning service collects such malware has already been described elsewhere [1], [23].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 4,
      "context" : "To make our analysis more exhaustive, we also used a sample of benign emails from the Enron email dataset for our analysis [6].",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 26,
      "context" : "These characteristics of whether an email is forwarded, or a reply, have previously been used as boolean features by researchers to distinguish between phishing and benign emails [28].",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 0,
      "context" : "FW: [2] for the extension of the measures against North Korea 1.",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 9,
      "context" : "The entire analysis and classification tasks were performed using the Weka data mining software [11].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 26,
      "context" : "Features marked with ∗ (in Table VII) have been previously used by researchers to classify spam and phishing emails [28].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 2,
      "context" : "These features have been previously used by Chandrasekaran [4].",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 1,
      "context" : "Random Forest [3], J48 Decision Tree [26], Naive Bayesian [17], and",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 24,
      "context" : "Random Forest [3], J48 Decision Tree [26], Naive Bayesian [17], and",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 15,
      "context" : "Random Forest [3], J48 Decision Tree [26], Naive Bayesian [17], and",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 16,
      "context" : "Decision Table [18].",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 12,
      "context" : "[14].",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2014,
    "abstractText" : "Targeted social engineering attacks in the form of spear phishing emails, are often the main gimmick used by attackers to infiltrate organizational networks and implant stateof-the-art Advanced Persistent Threats (APTs). Spear phishing is a complex targeted attack in which, an attacker harvests information about the victim prior to the attack. This information is then used to create sophisticated, genuine-looking attack vectors, drawing the victim to compromise confidential information. What makes spear phishing different, and more powerful than normal phishing, is this contextual information about the victim. Online social media services can be one such source for gathering vital information about an individual. In this paper, we characterize and examine a true positive dataset of spear phishing, spam, and normal phishing emails from Symantec’s enterprise email scanning service. We then present a model to detect spear phishing emails sent to employees of 14 international organizations, by using social features extracted from LinkedIn. Our dataset consists of 4,742 targeted attack emails sent to 2,434 victims, and 9,353 non targeted attack emails sent to 5,912 non victims; and publicly available information from their LinkedIn profiles. We applied various machine learning algorithms to this labeled data, and achieved an overall maximum accuracy of 97.76% in identifying spear phishing emails. We used a combination of social features from LinkedIn profiles, and stylometric features extracted from email subjects, bodies, and attachments. However, we achieved a slightly better accuracy of 98.28% without the social features. Our analysis revealed that social features extracted from LinkedIn do not help in identifying spear phishing emails. To the best of our knowledge, this is one of the first attempts to make use of a combination of stylometric features extracted from emails, and social features extracted from an online social network to detect targeted spear phishing emails.",
    "creator" : "LaTeX with hyperref package"
  }
}