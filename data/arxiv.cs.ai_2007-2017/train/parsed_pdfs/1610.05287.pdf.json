{
  "name" : "1610.05287.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Internet of Things Applications: Animal Monitoring with Unmanned Aerial Vehicle",
    "authors" : [ "Jun Xu", "Rouhollah Rahmatizadeh" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Index Terms—value of information; markov decision process; path planning; animal monitoring; unmanned aerial vehicles.\nF"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "Wireless sensor networks (WSNs) have been widely used for wildlife monitoring and tracking of different species [2]. Often, different functional devices working as sensors are used to report animal data to the base station [3] [4]. However, animal monitoring is difficult in remote largescale wildlife areas due to the dangerous environment and the uncertainty of animal movement patterns. In addition, due to the energy limitations of traditional sensor networks, sending the sensed information in a timely manner is costly and impractical.\nThe recent advances in technology of unmanned aerial vehicles (UAVs) allow their usage as a part of the WSNs. UAVs provide an extremely flexible platform for WSNs applications by playing different roles in WSNs such as actors [2], sensors [5], and mobile sinks [6]. In some monitoring scenarios such as forest fire monitoring or animal monitoring, the sensed information is time-sensitive. In other words, the earlier the sensed information is reported to a base station, the higher value the information has. The arise of UAVs provide cost-effective and appealing solutions for surveillance applications.\nIn this paper, we focus on the animal monitoring and tracking in large wild areas. In an unknown large area, it is\n• Gürkan Solmaz is with NEC Laboratories Europe, Heidelberg, Germany, 69115. E-mail: gurkan.solmaz@neclab.eu • The other authors are with the Department of Computer Science, University of Central Florida, Orlando, FL, 32816. E-mail: {junxu,rrahmati,turgut,lboloni}@eecs.ucf.edu • Part of this work was published in IEEE LCN 2015 [1] difficult and sometimes infeasible to find wildlife animals and attach wearable tracking devices to them. In this case, low cost sensors can be widely deployed throughout the observation area to detect and recognize the wildlife appearance. Currently, sensors can identify animals appearance by different types of inputs such as smell, sound and image. With deployed sensors, we can get animal appearance information in wildlife areas, however, long distance wireless communication in large remote wildlife areas is costly and impractical. If the delay of reporting sensed information becomes too large, the animal may leave that place. Therefore, the key challenge is to collect and transmit the sensed animal data in a timely and efficient way such that we can track and monitor those animals. By observing animal activities, we find that animal activities usually have some specific features such as living in groups and having more activities around habitats. These features make animal movements have some specific patterns. Examples of animal movement trajectories can be seen in ??, instead of having activities in a large area, animals usually have activities only in one or several small areas. If we focus more on these ”hot” areas, we have a much higher probability to track and predict animals movement. Inspired by this idea, we divide the whole observation area into small virtual grids. Then based on this grid structure network, we design our system model by utilizing a UAV and letting the UAV to explore and learn these ”hot” small virtual grids. By treating each grid as a cluster of sensor nodes, data collection by the UAV is reduced to visiting the cluster head of each grid. The Markov decision process (MDP) model is used to do path planning for the UAV as each grid represents a state of ar X iv :1 61 0. 05 28 7v 1\n[ cs\n.A I]\n1 7\nO ct\n2 01\n6\n2 MDP. We solve the MDP model using Q-learning algorithm by letting UAV to receive rewards from grids when animal data is reported. The goal of our path planning approach is collecting animal data efficiently and then predicting future animal movements. The UAV is self-learning and can dynamically plan and adapt according to environment changes.\nTo quantitatively weigh the value of the sensed animal appearance information, the proposed path planning approach utilizes the value of information (VoI) [7]. The basic idea of VoI is that the sensed information has the highest valued when it is first generated and the value decrease as time goes. In such a way, the task of UAV can be reduced to maximizing the overall value of information obtained from the entire network. We give a mathematical model for calculating the VoI in animal monitoring operation in Section 2. Lastly, we evaluate the performance of the proposed network model and the path planning approach with real animal datasets: ZebraNet [4] and leopard tortoises dataset.\nThe remainder of this paper is organized as follows. Section 2 defines mathematical model for calculating the value of information as well as the reward in Q-learning. Section 3 defines the network model and explains the implementation of Markov decision process (MDP) for UAV path planning. Section 4 evaluates the performance of the proposed network model and the path planning approach. Section 5 briefly summarizes the related studies on animal tracking and mobile sinks path planning in WSNs. Finally, Section 6 gives the conclusion."
    }, {
      "heading" : "2 MATHEMATICAL MODEL",
      "text" : "In this section, we describe the mathematical model of the value of information for animal monitoring and our definition of the sensors’ credibility and initial rewards."
    }, {
      "heading" : "2.1 Value of information",
      "text" : "Value of information (VoI) is a metric initially proposed in game theory as the price an optimal player would pay for a piece of information. This metric is used in recent studies of sensor networks [7] as a way of assigning a higher value to more recently sensed data. The VoI of an event is highest at the moment the event is created and continuously decreases as time passes.\nLet us describe an example environmental mission where VoI has critical importance. In the times of marine oil spills, where crude oil is released into ocean or coastal waters from offshore platforms or tankers, actions must be taken to stop leakage and repair the damages at the earliest time. After the oil leakage information is sensed by a set of underwater sensor nodes, early arrival of the information to the base station will provide the operators more ability to take decisions for repairing and patching up the leaks.\nTo the best of our knowledge, the concept of VoI is not considered for the animal monitoring problem in the literature. However, maximizing VoI may be very useful for monitoring wild animals such as finding the current locations of endangered species. For instance, earlier arrival of the information to a UAV that collects data may be helpful for finding the exact location of an animal who needs certain\nhelp or rescue from a region. Moreover, earlier information retrieval by the UAV may result in direct observation of the animal.\nThe idea behind VoI can be described by a scenario where an actuation action has to be taken on the basis of sensed data. The sensed information is of more value at present as compared to it being processed for actuation at a later time. For many scenarios, we define the value of information in terms of an exponential decay (although other forms are possible):\nFV oI(t) = Ae −Bt (1)\nIn Equation 1, the constant value A represents the initial value of the information while B represents the decay speed of the VoI. A higher value of A defines the information with a higher initial value while a higher value of B defines a faster decay of the VoI. Fig. 1 shows three different examples of A and B values and their outcomes as the VoI function. It may be considered as representations of three urgent levels of data in a sensor network. As it can be seen in the figure, higher values such as A = 10 and B = 0.1 produce the VoI with sharper decays, meaning urgent events that lose their importance earlier. If we define a threshold value of events as FV oI = 1, the events with higher values of A and B expire before 60 minutes while the events with lower values (A = 5, B = 0.02) expire around 90 minutes."
    }, {
      "heading" : "2.2 Initial rewards",
      "text" : "We define each sensed information as an event in the system. Each event has an initial reward (IR) that is the value of information at the time of the event occurs (t = 0). In other words, IR is the maximum value of information that can be gathered for each detected event. In our application, IR is affected by several factors: credibility of sensors, distance to the animal and the duration.\nCredibility (C) is a parameter that represents the reliability of the sensed information. We define credibility based on heterogeneous sensor nodes with different abilities and quality of services. For instance, an acoustic sensor node\n3 detects the sounds coming from an animal while another sensor node can take visual images. Moreover, a sensor node may have a lower quality camera that results in lower resolution images than the other sensor nodes. We assume there are k sensor nodes {N1, N2, ..., Nk} deployed in the target area. Different types of sensor nodes perceive different types of information such as picture, sound, and odor. Each data type has a weight value according to its importance {W1,W2, ...,Wk}. While some of these sensor nodes are identical, their W values are also the same accordingly. Moreover, quality and resolution of the data are considered as factors of credibility. For instance, images taken by cameras with different resolutions and images with different brightness and contrast levels.\nLet us define the credibility for the ith event as\nCi = λ×Wi, (2)\nwhere λ is an impact factor of the quality and resolution of the sensed data. We consider the maximum Ci = 1 with Wi = 1 and λ = 1, meanwhile, we consider the minimum Ci to be equal to 0.\nThe distance of an animal to the sensor node is considered as a factor of the initial reward. Distance has importance due to two reasons. The first is its effect to the accuracy of the data. For instance, the volume of sounds from the animals may affect the accuracy of classification of the animal species. Another example may be the resolution of the image taken by a sensor node or the distance of the image. The second reason is sensed event with lower distance may help finding the exact location of animal and direct observation by the UAV.\nIdist = α× 1\nAest (3)\nBy Equation 3, the distance to the animal will be reflected into an estimation of the size of the area where the animal is located. The smaller the estimated area Aest is, the more credible the sensing result is. α is a constant value used for adjusting the value Idist\nWe define the duration parameter Idura of the sensed event for the initial reward. Events having longer durations are considered more effective evidences for the animals appearances. For instance, an event with a longer duration may infer that the animal prefers staying in the proximity of the sensor node. Idura also used for data types such that when an animal is detected, sensor nodes records series of images with a previously defined frequency. Some environmental noise may also cause similar results. We consider a threshold value Tmax for the maximum duration that leads to ideal Idura and define the duration parameter as\nIdura = T\nTmax , (4)\nwhere T is the duration of the event and 0 < Idura ≤ 1. Finally, we define the initial reward IRi of the event i as below. IRi = σ × Ci × Idist × Idura, (5)\nwhere σ is a parameter that depends on the type of animal. For instance, information sensed by endangered animal species may have better reward.\nWith the IR, specific event’s value of information V oIi can be calculated. V oIi shows the value of the sensed event i at the time when it is sent to a mobile sink (UAV). V oIi has the maximum value at the moment the event is detected and then it gradually decreases as time passes.\nAi = I ×Ri (6)\nV oIi = Ai × e−Bit (7)\nwhere B is a factor to control the convergence speed of the VoI. Our main objective is to maximize VoI collected by the UAV during its operation."
    }, {
      "heading" : "3 ANIMAL MONITORING SYSTEM",
      "text" : ""
    }, {
      "heading" : "3.1 Network model",
      "text" : "Considering a large observation area with animals living in it, the goal is to monitor specific animals’ appearance. First, a set of sensor nodes with monitoring functionalities are deployed and one UAV is introduced to collect data from deployed sensors. One way about collecting data by the UAV is visiting each sensor directly. However, visiting each sensor node becomes impractical when number of sensors is large. So, we divide the whole area into virtual grids and one cluster head is selected."
    }, {
      "heading" : "3.1.1 Sensor nodes",
      "text" : "Sensor nodes are deployed by uniform random distribution in strategic parts of the observation area. As illustrated in Fig. 2, sensors in a grid can be treated as a cluster and a cluster head is selected periodically. Sensors inside a virtual grid can communicate with the cluster head directly or via a hop-by-hop communication. Cluster head is responsible for receiving event messages from other sensors and then submitting all the event messages to the UAV when it comes. While routing and clustering are not in the scope of this paper, they are well-investigated problems and there exist various efficient mechanisms [8] [9]. For instance, Hamidreza et\n4 al. [8] propose a cluster head (rendezvous points) selection method by jointly considering node degree and hop distance such that minimizing energy consumption and improving load balance. They also use virtual rendezvous points to increase the performance. In our application, cluster head selection is based on an energy balancing policy which is proposed in [9]."
    }, {
      "heading" : "3.1.2 UAV",
      "text" : "UAVs have been widely used in various applications due to their several advantages such as flexibility, fast speed and good endurance. In this WSN application, UAV is used as an autonomous mobile sink for gathering time sensitive information. Apart from previous mentioned advantages, using UAV for animal monitoring not only overcomes the geographical challenge but also executes no effects on animals.\nAssumptions of the network model are given as follows:\n- There is a single UAV as it is the expensive element of the network. - The UAV has no energy constraints, while it is not the case for the sensor nodes. - The UAV flies with a fixed speed and it only communicates with cluster heads."
    }, {
      "heading" : "3.2 Markov decision-based path planning",
      "text" : "Wildlife animals have their own habitats, which means they are more likely to stay at a certain location for rest or just having activities in a small area. Fig. 3 shows real movement trajectories of 2 zebras in 3 days. As it can be seen in this figure, zebras’ mobility choices are not random. Instead, most of the time they prefer to stay in a place or just move nearby. Furthermore, we observe that a zebra can visit an already visited location multiple times. Therefore, sensing a zebra in a region may infer the possibility of future visits in the same region.\nBased on this observation, we use a Markov decision process (MDP) model for the path planning problem of UAV. A finite state MDP is a 6-tuple (S,A, P,D,R, γ) where S = s0, s1, ..., sm is a finite set of states. A is a set of actions and P is a set of state transition probabilities.D is the initialstate distribution, from which the start state s0 is drawn. R : S −→ A is the reward function and γ ∈ [0, 1) is a discount factor. In the context of UAV path planning, we define the elements of MDP as follows.\n- S is the set of states (grids) in the network.\n- A is the set of cardinal directions that UAV can go plus staying in the same grid: {north, east, south, west, northeast, southeast, southwest, northwest, stay} . - P is the set of state transition probabilities. Our model is deterministic, i.e. the probability of ending up in the desired grid (say north neighboring grid) by taking the corresponding action (north) is 1. The probability of accidentally appearing in non-desired states is 0. - D is the initial-state distribution which is 1 for the top-left corner grid in the network and 0 for all other grids. This means that the algorithm always starts from state s0. - R is the reward UAV gets if it enters gird s. Reward is calculated using Equation 5. - γ ∈ [0, 1] is the discount factor which incorporates the fact into our model that obtaining the information in distant future worths less compared to getting informed in near future.\nA solution to the MDP can be achieved by repeating the bellman optimality equation [10]:\nV π(s) := Ra(s, s ′) + γ ∑ s′∈S Pa(s, s ′)V π(s′) (8)\nin which V π(s) is the state value function that helps in choosing the best action a according to the policy π which leads to state s′. If π is the optimal policy, then we can reach the optimal value function V ∗(s) which gives the best available solution to the MDP:\nV ∗(s) := max a∈A {Ra(s, s′) + γ ∑ s′∈S Pa(s, s ′)V ∗(s′)} (9)\nThis equation basically describes the highest expected discounted reward for taking action a from state s and following the policy π onwards. Therefore, policy π can be achieved by iteratively solving the bellman optimality equation and updating the state values.\nWe use this MDP model to find a solution to the path planning problem in our application. In our model, the set of cluster heads in the network are represented by the set of states S in MDP. In this setting, UAV needs to make decision on its next visiting location after collecting one cluster head’s event messages, which can be represented by the state transitions in the MDP model. After visiting each cluster head, the UAV will update its information of the network and decide the next visiting cluster head. This decision process actually have an analogy to the MDP in which rewards of previous actions will have an effect on the next state transition decision. Lastly, maximizing the VoI in our problem actually means optimizing rewards in MDP.\nSolving the MDP gives the optimal policy which specifies the best next grid in the observation area that the UAV should visit. To solve the MDP, we use Q-learning algorithm [11]. By utilizing value iteration method, we calculate the Q-value for each state-action pairs using the following equation.\nQ(s, a)← R(s, a) + γmax a′\nQ(s′, a′) (10)\n5\nR(s, a) =\n{∑ i∈events IRi if grid has animals\nRNegative if grid does not have animals (11)\nQ(s, a) is the new Q-value for taking action a when the UAV is in state s. R(s) is calculated using Equation 5. s′ is the grid the UAV appears in when it takes action a and a′ is any action possible when we are in state s′. This means each time a is taken from state s, UAV reaches state s′, calculates the maximum Q-value of next state by taking any arbitrary action from state s′, sums it with initial reward it gets as it enters state s′, and uses this value to update Q(s, a).\nIn the context of UAV path planning in this animal monitoring application, when the UAV goes to one of the neighboring grids, it gets some experience (finds some animals, or does not find anything there), it will update the reward of coming to this state from the previous state. This helps the UAV to use these experiences to decide about which grid is best to go from the current grid. Formally, this policy is obtained using the following equation.\nπ(s) = arg max a Q(s, a) (12)\nFig. 4 illustrates an example of path planning decision for the UAV based on the Q-value of each action in the current state. The UAV is initially in state s4 as it decides which of the adjacent states it should go. The actions are shown by the arrows. Available actions are either visiting the neighboring states or staying in the same state. The Q-value corresponding to each action is shown near each arrow. UAV decides to take action which leads to state s5 since the Q-value of the corresponding action is higher than others. In addition, there is a probability of random exploration during the next state selection process. The exploration is based on the -greedy scenario in Q-learning.\nThe pseudocode for the path planning of UAV is given in Algorithm 1. The UAV starts from an arbitrary grid location named as state s with 9 possible actions {north, east, south, west, northeast, southeast, southwest, northwest,\nAlgorithm 1 Path planning of UAV 1: Initialize the UAV in state s, with possible Action[north,\neast, south, west, northeast, southeast, southwest, northwest, stay] and their corresponding Q-values Q(s, a), a ∈ Action[]. is the probability of taking a random action, 0 ≤ ≤ 1\n2: while Termination condition not reached do 3: Generate RandomNumber ← Random(0, 1) 4: if RandomNumber ≤ then 5: NextAction = Action[Random(Action.len)] 6: end if 7: if RandomNumber > then 8: if all Q(s, a) have the same value then 9: NextAction = Action[Random(Action.len)]\n10: else 11: NextAction = Action[maxaQ(s, a).index] 12: end if 13: end if 14: Take action NextAction, get the reward R(s, a) 15: Q(s, a)← R(s, a) + γmaxa′ Q(s′, a′) 16: // Update Q value 17: Current state s← s′ 18: end while\nstay}. Note that the grids near the edge of the observation area have less number of possible actions. The parameter controls how much exploration the UAV does instead of following the best path. This enables the UAV to explore the whole area to find potential animal information which the system did not know about before. The UAV will take a completely random action if = 1 while choosing the best possible next grid when = 0. To accomplish this, at each path planning decision, it generate a random number num, 0 ≤ num ≤ 1. If num is smaller than , the UAV randomly selects the next grid from the possible actions (lines [2-6]). If num is greater than , however, the UAV deterministically decides the best possible next grid according to the Q value of each action. In cases where all possible actions have the same Q value, for instance at the beginning of the network performance, the UAV does random action selection (lines [7-13]). When the next grid is decided, the UAV moves to that grid and receives the reward associated with that state which is determined based on whether the animal is observed or not. Having the immediate rewards, the UAV updates the Q(s, a) using equation 10 (lines [14-17]). After this step, the UAV initializes a new path planning decision which includes repeating the process explained above."
    }, {
      "heading" : "4 SIMULATION STUDY",
      "text" : ""
    }, {
      "heading" : "4.1 Simulation environment",
      "text" : "The proposed WSN application and the UAV path planning approach are tested with simulation experiments. The whole observation area is deployed by sensors and then classified into grids. One node in each grid is selected periodically as the head node. Head node is responsible for collecting messages from other sensors and communicating with the UAV.\n6"
    }, {
      "heading" : "4.1.1 Dataset and UAV",
      "text" : "We test our model with two real world animal datasets. The first one is the ZebraNet [4] dataset which was used in our previous work [1]. This dataset contains the location information of 5 zebras in June 2005 at a place near Nanyuki, Kenya. The sampling time of the GPS traces is 10 minutes and the total experiment time is 14 days. The second one is a leopard tortoises dataset which contains the movement traces of 10 leopard tortoises in the Kalahari desert. It includes the traces recorded for three months from January to March in 2013. The sampling time of the GPS traces is 60 minutes. The difference between these two datasets is that animals in the ZebraNet roam around in a more broad area. They keep moving most of the time, for instance examples of their movement traces are shown in Fig. 3. On the other hand, animals in the leopard tortoises dataset usually have activities in a small area. In other words, animal movements pattern in the ZebraNet dataset are more complex and unpredictable while animal activities in the leopard tortoises dataset are more stationary and predictable.\nWe setup our experimental network by getting the animal movement information from both datasets and then converting them into our grid-based area which is 10km × 10km. A single UAV is used for event message collection. The UAV is responsible for collecting animal information from sensors. In general, the higher the UAV speed is, the sooner the information can be collected. However, UAVs with high maximum speed (usually above 200km/h) are very expensive and are only allowed for military purpose. UAVs for commercial purpose have lower speed (usually maximum speed of less than 100km/h) and shorter lifetime between charges. Some existing UAVs have been used for sensor data collection, for instance, the Claw 3 from General Atomics Aeronautical Systems company and the Mantis from AeroVironment company. However, most of the highspeed UAVs are only used for military purpose. In our case, we select a Bayraktar mini UAV which has a good endurance of 1 hour and a moderate maximum flight speed of 60km/h. The time unit used in the experiments is 1 minute so the UAV speed is set as 1km/round. In the case of battery exhausting, we assume that the UAV can be recharged so that it can continue to work."
    }, {
      "heading" : "4.1.2 Event and reward",
      "text" : "We define some interested events in the conducted experiments. The purpose of the application is to detect and predict the appearances of animals. During the operation, when an animal first appears in an area, the sensor nodes can record it. However, if the same animal stays in that small area for a very long time, such as the case when the animal sleeps there, this is valueless to our application and may cause excessive energy consumption to the sensor nodes. Therefore, we define the events as following.\n- If an animal moves from one grid to another, we count it as an event. - If an animal always stays in a grid, instead of recording it in every sampling time interval, we periodically record its location once in every ∆t amount of time.\nIn Section 3, equation 11 gives the rewards details when the UAV enters a grid. We discussed the initial reward (IR) in Section 2. Each event has an initial reward which is related to the type of animal σ, the credibility of sensed information Ci, the distance Idist and the duration time Idura. In our experiment, we assume homogeneous events for simplicity such that we can focus on the UAV’s path planning performance. Also, with the homogeneous events assumption, we set the Ai and Bi in VoI to fixed values. The reason we do this assumption is that these parameters only affect the final specific values of the experimental performance. In other words, specific values of these parameters do not affect the final performance when compared with other approaches. In different problems, these parameters can be set according to the nature of the application."
    }, {
      "heading" : "4.1.3 Metrics",
      "text" : "To quantitatively evaluate the performance of a path planning strategy, we report the results according to three performance metrics in our simulation study.\n- Value of information (VoI). VoI is the main metric in this animal monitoring application and maximizing it is the primary goal in designing the proposed MDP path planning approach. The definition of VoI is given in Section 2 and the parameter values used in the experiment is given in Table 1. - Time delay. Since event messages need to be kept in sensors buffer until being sent to the UAV, message delay is an important metric. Long message delays make the event messages useless and as their information content becomes valueless. In this experiment, we measure both the average message delay and the message delay distribution for all of the events. - Number of animals encountered. As the UAV flies throughout the network, we define a radius r inside which the zebras can be directly observed by the UAV. Although the number of zebras encountered is not the main goal in designing our path planning approach, direct encounters may be more helpful for the monitoring as the UAV can capture higher resolution images.\nTable 1 includes the parameter values used in our experiments. For the performance evaluation of the proposed\n7 Markov decision process-based (MDP) path planning approach, we compare its outcomes with three other approaches: greedy, traveling salesman problem-based (TSP) and random. Each of the these approaches independently does path planning for the UAV in order to efficiently collect event messages.\nIn greedy approach, when the UAV visits a grid, IRs of events in this grid are summed and used for future grid selection. According to greedy approach, the UAV always pursues the highest local IR in its movement. In other words, the UAV always flies to a neighbor grid with the highest IR. In the case of multiple neighbor grids having the same IRs, the UAV randomly selects one of them. In TSP approach, solution to the TSP problem is used as it provides the shortest path of visiting all grids among all these possible paths. Given the network structure, the path produced by TSP is actually fixed, which means the UAV always flies along a pre-set movement path to ensure visiting all the nodes. The fixed path feature of TSP results in a very stable experimental performance and can also be used as a good reference for comparing with adaptive approaches. Lastly, in random approach, UAV simply selects its next destination grid randomly among all the grids in the network."
    }, {
      "heading" : "4.2 Simulation results",
      "text" : "This section reports the experimental results of the compared path planning approaches. We implement 4 independent UAVs which are controlled by MDP, greedy, TSP and random approaches respectively. The results are obtained from an average of 10 simulation runs. To clearly distinguish the experimental results from two different datasets, each figure is marked as first dataset or second dataset in the caption. Since the total experimental time in both datasets is too long, we show the experimental result of the first 70 hours in the first dataset which contains 5682 GPS traces, while in the second dataset we show the experimental result of the first 200 hours which contains 7896 GPS traces.\nFig. 5 and Fig. 6 show the performances of the path planning approaches in terms of the VoI by simulation time. The network structure is set to 4 × 4 grids. In MDP, the = 0.2 means the UAV has a 20% chance of randomly exploring the area during path planning while a 80% chance of exploitation of the best available policy. At the beginning of the experiment, the MDP-UAV does not contain any animal appearance information, so it randomly visits each grid. Once the MDP-UAV gets animal appearance information from one grid, it gets a reward from that grid and updates the Q-value table such that it has a higher probability to visit back that grid and its neighbor grids. The -greedy policy is applied at each path planning step such that animal information in other grids can be detected by the UAV. In such a continuous learning way, the MDP-UAV is more likely to go to those areas that previously had animals.\nAs the learning process continues, the VoI obtained by MDP-UAV gradually outperforms other path planning approaches on both datasets. The random approach performs the worst due to its totally random grid selection. The result of TSP is better than greedy under both datasets. This is because to a given network structure, the TSP-UAV always flies along a fixed path in the network, which means it\nhas a very stable performance. But in greedy approach, the Greedy-UAV keeps go to neighbor grids where it finds animals last time. In other words, the greedy approach is trapped into a local minima and cannot adapt itself based on animal movements. Note that the results of all algorithms are pretty consistent across different datasets.\nThe performance results of different simulation runs using the MDP approach are shown in Fig. 7 and Fig. 8. Note that the -greedy policy brings stochasticity in selecting the next state and therefore leads to randomness in the results. To examine the stability of our approach despite the randomness, four independent experiments of MDP approach with the same parameter settings are conducted on both datasets. It can be seen that though some small differences exist among different experimental runs, the overall outcome is consistent.\nWe include the results for the message delay distribution of both datasets in Fig. 9 and Fig. 10. It can be seen that the MDP approach has a much more stable message delay dis-\n8 0 10 20 30 40 50 60 70 0 500 1000 1500 2000 2500\nSimulation time (h)\nV al\nue o\nf i nf\nor m\nat io\nn\nMDP−1 MDP−2 MDP−3 MDP−4\nFig. 7. ZebraNet dataset, stable performance of MDP, with network settings: 4× 4 grids, = 0.2\n0 50 100 150 200 0\n500\n1000\n1500\n2000\n2500\n3000\n3500\n4000\nSimulation time (h)\nV al\nue o\nf i nf\nor m\nat io\nn\nMDP−1 MDP−2 MDP−3 MDP−4\nFig. 8. Leopard tortoises dataset, stable performance of MDP, with network settings: 4× 4 grids, = 0.2\ntribution compared with other path planning approaches. Due to the continuous learning process, the MDP-UAV keeps visiting those ’hot’ areas in the network which enables the sensed messages to be collected in a timely manner. So it has the smallest median and the smallest third quartile among the four approaches. It means 75% animal events can be collected by the MDP-UAV in a short prediod of time. When compared with the TSP approach which has a median of 200 and the third quartile of 320, the MDP approach turns to be much more effective and intelligent in path planning and animal detecting. These distribution results also support the findings about the value of information shown in Fig. 5 and Fig. 6. VoI is highly correlated to the time delay, i.e. messages delivered quickly will result in a higher obtained VoI.\nWe depict the results for the total number of times the UAV encountered animals in Fig. 11 and Fig. 12. In each dataset, the MDP-UAV has encountered animals more often compared to the other approaches. Note that the standard\nMDP Greedy TSP Random 0\n100\n200\n300\n400\n500\n600\nT im\ne de\nla y\n(m in\n)\nFig. 9. ZebraNet dataset, message delay distribution of the MDP, greedy, TSP, and random approaches, with network settings: 4×4 grids, = 0.2\nMDP Greedy TSP Random 0\n100\n200\n300\n400\n500\n600\nT im\ne de\nla y\n(m in\n)\nFig. 10. Leopard tortoises dataset, message delay distribution of the MDP, greedy, TSP, and random approaches, with network settings: 4×4 grids, = 0.2\ndeviation is smallest for the MDP-UAV approach. This finding means that we reached our primary goal of designing this approach which is effective and reliable predicting animal movements. While the greedy and TSP approaches seem to result in the same frequency of encountering animals, TSP turns out to be more stable than greedy. This is because the greedy-UAV visits the grids randomly when the IRs of all neighbor grids are equal to each other.\nNote that all the previous experimental results come with the network settings 4 × 4 grids and = 0.2. In order to investigate the impact of these network parameters on the performance, Fig. 13 and Fig. 14 show the impact of varying the parameter in -greedy approach on the MDPUAV’s VoI performance. is the parameter that indicates the probability of stochastic state decisions in MDP, i.e., the probability of random grid selection at each step of path planning. = 0.0 basically means turing off the exploration feature, i.e. the UAV always does deterministic path planning at each step. On the other hand, = 1.0 means the UAV does totally stochastic path planning. In this case, the Q-value table does not have any impact on its decisions.\n9 MDP Greedy TSP Random 0 20 40 60 80 100 120 140 160 180 200 N um be r of a ni m al s en co un te re d\nFig. 11. ZebraNet dataset, Times of zebras encountered for the MDP, greedy, TSP, and random approaches, with network settings: 4×4 grids, = 0.2\nMDP Greedy TSP Random 0\n50\n100\n150\n200\n250\n300\nN um\nbe r\nof a\nni m\nal s\nen co\nun te\nre d\nFig. 12. Leopard tortoises dataset, Times of zebras encountered for the MDP, greedy, TSP, and random approaches, with network settings: 4×4 grids, = 0.2\nThe MDP-UAV gets the worst performance when = 1.0 on both datasets. This is easy to understand because the UAV always performs random selection at each step. As the value of decrease, the MDP-UAV’s performance gradually increases. The MDP-UAV gets the best performance when = 0.2 on both datasets. The performance draws back when the value continues to decrease. This is because with low values, the UAV looses its exploration ability which is important to detect potential animal appearance. It can be understood that when = 0.0, the MDP-UAV’s performance decreases to the level with = 0.8 and = 0.6 in the first dataset and second dataset respectively. Empirically, we use = 0.2 in our experiments as it provides the best tradeoff.\nFig. 15 and Fig. 16 show the impact of the number of grids on the MDP-UAV’s VoI performance. The number of grids is related to the grid size as well as the total number of the MDP states. When the total number of grids is smaller,\n0 10 20 30 40 50 60 70 0\n500\n1000\n1500\n2000\n2500\nSimulation time (h)\nV al\nue o\nf i nf\nor m\nat io\nn\nε = 0.00 ε = 0.20 ε = 0.40 ε = 0.60 ε = 0.80 ε = 1.00\nFig. 13. ZebraNet dataset, The impact of on VoI by simulation time, with network settings: 4× 4 grids\n0 50 100 150 200 0\n500\n1000\n1500\n2000\n2500\n3000\n3500\n4000\nSimulation time (h)\nV al\nue o\nf i nf\nor m\nat io\nn\nε = 0.00 ε = 0.20 ε = 0.40 ε = 0.60 ε = 0.80 ε = 1.00\nFig. 14. Leopard tortoises dataset, The impact of on VoI by simulation time, with network settings: 4× 4 grids\nsay less than 3 × 3, it means the area size of each grid is larger. Hence, the UAV needs more time to visit each grid, and it would waste time if there is no event taking place in that grid. On the contrary, as the total number of grids increases, the predication becomes harder. It can be seen from Fig. 15 and Fig. 16 that the best VoI performance can be acquired when the grid number is between 4 × 4 and 5× 5. Empirically, we use 4× 4 grids in our experiments as it provides the best performance.\nOverall, it can be seen in both experimental results that the MDP approach highly outperforms the other path planning approaches. Compared to the greedy approach as an example, MDP produces a 80% increase in VoI, much lower median value in message delay, and a 90% increase in the number of zebras encountered. Although greedy path planning approach also relies on the previous information, it only considers the last time of zebra appearances in each grid. Unlike the greedy approach, the UAV in MDP approach continuously learns about the events occuring\n10\nthroughout the network and then updates the Q-value of each grid. The Q-table maintained by the UAV actually reflects all previous information of zebras activities. As the learning process continues, the UAV is more likely to go to the hot-spots where zebras often appear. Additionally, both exploration and exploitation modes are introduced so that while the UAV is visiting the hot-spots, it also explores new regions in the observation area."
    }, {
      "heading" : "5 RELATED WORK",
      "text" : ""
    }, {
      "heading" : "5.1 Tracking animals with sensor networks",
      "text" : "Tracking animals can be viewed as specific applications of object tracking problems. Its main goal is tracking certain animals in a monitored area and reporting their location and other information to the applications users [12]. Many animal tracking technologies have been proposed and implemented by engineers and wildlife researchers [4], [13]– [15]. One main technology is the wearable GPS-based animal tracking devices. Juang et al. [4] present their ZebraNet\nproject in which a low-power wireless system is built for position tracking of zebras. Tracking nodes are installed on zebras and record zebras’ GPS positions periodically. In their research, they investigate system design ideas, communication protocols between tracking nodes, and how sensor specifications such as battery lifetime and weight limit the system performance. In addition, some recent research [16]– [18] on animal behaviour gather animal movement data by installing wearable GPS devices. Although remote sensing can be used for sensing different types of data from a large area [19], [20], sensor networks seem to be a more feasible and reliable choice for animal monitoring.\nIn recent years, camera sensor networks emerge due to the advancements in hardware technology which provides sufficient bandwidth for transferring video. Camera sensor networks greatly promote wild-life research by providing much more animal related information such as image, sound and video. He et al. [21] develop integrated camerasensor networking systems and deploy them at large scales for collaborative wildlife monitoring and tracking. They develop an eMammal cyber infrastructure in which advanced computational and informatics tools are used to analyze and manage massive wildlife monitoring data. Animal species recognition is the problem they tried to solve by using machine learning methods to train a model based on large number of images. Similar studies based on camera sensor networks are conducted in [22] [23].\nIn addition, UAVs are being increasingly used as sensor nodes for monitoring various species in nature. Tuna et al. [24] propose to use UAVs for deployment of sensor nodes for post-disaster monitoring. Hodgson et al. [25] use ScanEagle UAV to survey marine mammals. Their results indicate that UAVs are not limited by sea conditions as sightings from manned surveys. Chamoso et al. [26] propose to use UAVs for scanning large areas of livestock systems. Using visual recognition techniques, the recorded images are used to count and monitor animal species. Akbas et al. [6] propose the use of aerial sensor networks consisting of UAVs for volcanic eruption monitoring. They propose positioning approaches for multiple UAVs based on the Valence Shell Electron (VSEPR) model of molecular geometries. Our study differs from the aforementioned ones as we propose using UAV as a major element of the WSNs for monitoring purpose."
    }, {
      "heading" : "5.2 Path planning for mobile sinks in WSNs",
      "text" : "Mobile sinks provide great advantages such as distributing the energy consumption throughout the network and increasing network lifetime. They can be programmed to move to different areas of WSN to accomplish applicationspecific tasks. The common goal of path planning for mobile sinks is to maximize the information collected while minimizing travel time. In such applications, mobile sinks can either visit each sensor node directly or just visit a subset of them. Hollinger et al. [27] address path planning for autonomous underwater vehicle (AUV) to collect data from an underwater sensor network. Each AUV needs to collect as much data as possible while considering fuel expenditure, i.e., the travel time. Salarian et al. [8] propose a path planning approach for the mobile sink called weighted\n11\nrendezvous planning (WRP) to collect data from the set of rendezvous points (RPs). WRP assigns weights to sensor nodes based on the number of data packets and hop distance, and selects the sensor nodes with the highest weight as RPs. The goal of WRP is to collect all data within a given deadline while minimizing energy consumption. Cheng et al. [28] propose a Traveling Salesman Problem (TSP) based path planning algorithm for the mobile sink. Instead of visiting each sensor in the observation area, the mobile sink only visits a set of virtual points which are actually overlapping areas of communication ranges of sensors. Their approach first finds out those overlapping areas based on an IRO rule and then assigns contribution value to each overlapping area based on the number of sensors that a mobile sink can communicate in that area. The mobile sink selects visiting points with contribution values and visits them with a TSP strategy such that the whole data can be collected in the shortest traveling path.\nResearch on mobile sinks to accomplish other tasks is also well conducted. Ma et al. [29] use one SenCar as a mobile sink for data collection in a static sensor network. Their research reveals the effects of traveling path on network lifetime in a given network. They propose a heuristic algorithm for planning the traveling path such that traffic load can be balanced. Basagni et al. [30] investigate the problem of maximizing value of information in underwater sensor networks. They formulate the problem using an Integer Linear Programming (ILP) model for path planning of underwater vehicles. Their method achieves better results in terms of value of information compared to a greedy heuristic. Rahmatizadeh et al. [31] study sink mobility in virtual coordinates domain and propose a routing strategy to minimize energy consumption while notifying the nodes about the latest location of the sink. Solmaz and Turgut [32] propose positioning approaches for multiple mobile sinks to optimize event coverage using WSNs."
    }, {
      "heading" : "6 CONCLUSION",
      "text" : "In this paper, we propose using UAV-aided WSNs for animal monitoring in wildlife areas. Motivated by the movement features of animal, we propose a Markov decision based path planning approach for the UAV. The decision policy is dynamically based on the learning knowledge of animal appearance. The UAV predicts animals active areas and visits these predicted areas such that maximizing the overall value of information obtained from the entire network. The proposed network model is evaluated using realworld mobility traces of zebras and leopard tortoises. Simulation results show that the performance of the proposed path planning approach is better than random, greedy, and TSP-based approaches in terms of VoI, message delay and number of directly observed animals. In addition to animals tracking, the proposed model in this research is still effective to other scenarios like tracking objects who have some regular visiting areas, monitoring some dynamic changing sub-areas in a large network. The UAV in our model can find out these dynamic hot areas by exploring the monitored area and learning the obtained knowledge."
    } ],
    "references" : [ {
      "title" : "Animal monitoring with unmanned aerial vehicle-aided wireless sensor networks",
      "author" : [ "J. Xu", "G. Solmaz", "R. Rahmatizadeh", "D. Turgut", "L. Boloni" ],
      "venue" : "Proceedings of IEEE LCN’15, October 2015, pp. 125–132.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Path planning algorithm for mobile anchor-based localization in wireless sensor networks",
      "author" : [ "C.-H. Ou", "W.-L. He" ],
      "venue" : "IEEE Sensors Journal, vol. 13, no. 2, pp. 466–475, February 2013.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Implementation of herd management systems with wireless sensor networks",
      "author" : [ "K.H. Kwong", "T.T. Wu", "H.G. Goh", "K. Sasloglou", "B. Stephen", "I. Glover", "C. Shen", "W. Du", "C. Michie1", "I. Andonovic" ],
      "venue" : "IET Wireless Sensor Systems, vol. 1, no. 2, pp. 55–65, June 2011.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Energy-efficient computing for wildlife tracking: Design tradeoffs and early experiences with zebranet",
      "author" : [ "P. Juang", "H. Oki", "Y. Wang", "M. Martonosi", "L.S. Peh", "D. Rubenstein" ],
      "venue" : "SIGARCH Comput. Archit. News, vol. 30, no. 5, pp. 96–107, December 2002.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Multi-uav sensing over urban areas via layered data fusion",
      "author" : [ "S. Jwa", "U. Ozguner" ],
      "venue" : "Statistical Signal Processing, 2007. SSP ’07. IEEE/SP 14th Workshop on, August 2007, pp. 576–580.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Actor positioning based on molecular geometry in aerial sensor networks",
      "author" : [ "M.I. Akbas", "G. Solmaz", "D. Turgut" ],
      "venue" : "Proceedings of IEEE ICC’12, June 2012, pp. 508–512.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "IVE: improving the value of information in energy-constrained intruder tracking sensor networks",
      "author" : [ "D. Turgut", "L. Boloni" ],
      "venue" : "Proceedings of IEEE ICC’13, June 2013, pp. 6360–6364.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "An energy-efficient mobile-sink path selection strategy for wireless sensor networks",
      "author" : [ "H. Salarian", "K.-W. Chin", "F. Naghdy" ],
      "venue" : "IEEE Transactions on Vehicular Technology, vol. 63, no. 5, pp. 2407– 2419, June 2014.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Coverage-time optimization for clustered wireless sensor networks: A power-balancing approach",
      "author" : [ "T. Shu", "M. Krunz" ],
      "venue" : "IEEE/ACM Transactions on Networking, vol. 18, no. 1, pp. 202–215, February 2010.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A markovian decision process",
      "author" : [ "R. Bellman" ],
      "venue" : "DTIC Document, Tech. Rep., 1957.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1957
    }, {
      "title" : "Q-learning",
      "author" : [ "C.J. Watkins", "P. Dayan" ],
      "venue" : "Machine learning, vol. 8, no. 3-4, pp. 279–292, May 1992.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "A predictive energyefficient technique to support object-tracking sensor networks",
      "author" : [ "S. Samarah", "M. Al-Hajri", "A. Boukerche" ],
      "venue" : "IEEE Transactions on Vehicular Technology, vol. 60, no. 2, pp. 656– 663, February 2011.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Tracking targets in quantized areas with wireless sensor networks",
      "author" : [ "E.L. Souza", "A. Campos", "E.F. Nakamura" ],
      "venue" : "Proceedings of IEEE LCN’11, October 2011, pp. 235–238.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Cross-layer scheduling for power efficiency in wireless sensor networks",
      "author" : [ "M.L. Sichitiu" ],
      "venue" : "Proceedings of IEEE INFOCOM’04, March 2004, pp. 1740–1750.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "A cluster-based continuous object tracking scheme in wireless sensor networks",
      "author" : [ "W. Lee", "Y. Yim", "S. Park", "J. Lee", "H. Park", "S.H. Kim" ],
      "venue" : "Proceedings of IEEE VTC’11 Fall, September 2011, pp. 1–5.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Tracking and monitoring horses in the wild using wireless sensor networks",
      "author" : [ "I.E. Radoi", "J. Mann", "D. Arvind" ],
      "venue" : "Proceedings of IEEE WiMob’15, October 2015, pp. 732–739.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Mobile animal tracking systems using light sensor for efficient power and cost saving motion detection",
      "author" : [ "C. So-In", "C. Phaudphut", "S. Tesana", "N. Weeramongkonlert", "K. Wijitsopon", "U. KoKaew", "B. Waikham", "S. Saiyod" ],
      "venue" : "Proceedings of IEEE CSNDSP’12, July 2012, pp. 1–6.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Preserving national animal using wireless sensor network based hotspot algorithm",
      "author" : [ "T.K.S. Jose Anand", "Aida Jones", "K. Besna" ],
      "venue" : "Proceedings of IEEE ICGHPC’13, March 2013, pp. 1–6.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Investigation of rain effects on aquarius sea surface salinity measurements",
      "author" : [ "A. Santos-Garcia", "M.M. Jacob", "W.L. Jones", "W.E. Asher", "Y. Hejazin", "H. Ebrahimi", "M. Rabolli" ],
      "venue" : "Journal of Geophysical Research: Oceans, vol. 119, no. 11, pp. 7605–7624, 2014.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Use of monte carlo simulation in remote sensing data analysis",
      "author" : [ "H. Ebrahimi", "S. Aslebagh", "L. Jones" ],
      "venue" : "Proceedings of IEEE Southeastcon, 2013, pp. 1–4.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Visual informatics tools for supporting large-scale collaborative wildlife monitoring with citizen scientists",
      "author" : [ "Z. He", "R. Kays", "Z. Zhang", "G. Ning", "C. Huang", "T.X. Han", "J. Millspaugh", "T. Forrester", "W. McShea" ],
      "venue" : "IEEE Circuits and Systems Magazine, vol. 16, no. 1, pp. 73–86, February 2016.  12",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Design and implementation of an audio-visual integrated wireless sensor remote monitoring network on wetland",
      "author" : [ "L. Xiuhong", "C. Xiao", "Y. Rongjin", "Z. Haijing", "Z. Jialin" ],
      "venue" : "Proceedings of IEEE MEC’13, December 2013, pp. 609–614.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Tracking and identification of animals for a digital zoo",
      "author" : [ "J. Karlsson", "K. Ren", "H. Li" ],
      "venue" : "Proceedings of IEEE and ACM Green- Com’10 and CPSCom’10, December 2010, pp. 510–515.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Unmanned aerial vehicle-aided wireless sensor network deployment system for post-disaster monitoring",
      "author" : [ "G. Tuna", "T. Mumcu", "K. Gulez", "V. Gungor", "H. Erturk" ],
      "venue" : "Emerging Intelligent Computing Technology and Applications, ser. Communications in Computer and Information Science, July 2012, vol. 304, pp. 298–305.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Unmanned aerial vehicles (UAVs) for surveying marine fauna: a dugong case study",
      "author" : [ "A. Hodgson", "N. Kelly", "D. Peel" ],
      "venue" : "PloS one, vol. 8, no. 11, p. e79556, November 2013.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Uavs applied to the counting and monitoring of animals",
      "author" : [ "P. Chamoso", "W. Raveane", "V. Parra", "A. Gonzlez" ],
      "venue" : "Ambient Intelligence - Software and Applications, May 2014, vol. 291, pp. 71–80.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Underwater data collection using robotic sensor networks",
      "author" : [ "G.A. Hollinger", "S. Choudhary", "P. Qarabaqi", "C. Murphy", "U. Mitra", "G.S. Sukhatme", "M. Stojanovic", "H. Singh", "F. Hover" ],
      "venue" : "IEEE Journal on Selected Areas in Communications, vol. 30, no. 5, pp. 899–911, June 2012.",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Data gathering in wireless sensor networks: A combine-tsp-reduce approach",
      "author" : [ "C.-F. Cheng", "C.-F. Yu" ],
      "venue" : "IEEE Transactions on Vehicular Technology, vol. PP, no. 99, pp. 1–1, 2016.",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Sencar: An energy-efficient data gathering mechanism for large-scale multihop sensor networks",
      "author" : [ "M. Ma", "Y. Yang" ],
      "venue" : "IEEE Transactions on Parallel and Distributed Systems, vol. 18, no. 10, pp. 1476– 1488, October 2007.",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Maximizing the value of sensed information in underwater wireless sensor networks via an autonomous underwater vehicle",
      "author" : [ "S. Basagni", "L. Boloni", "P. Gjanci", "C. Petrioli", "C.A. Phillips", "D. Turgut" ],
      "venue" : "Proceedings of IEEE INFOCOM’14, April 2014, pp. 988– 996.",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Routing towards a mobile sink using virtual coordinates in a wireless sensor network",
      "author" : [ "R. Rahmatizadeh", "S.A. Khan", "A.P. Jayasumana", "D. Turgut", "L. Boloni" ],
      "venue" : "Proceedings of IEEE ICC’14, June 2014, pp. 12–17.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Wireless sensor networks (WSNs) have been widely used for wildlife monitoring and tracking of different species [2].",
      "startOffset" : 112,
      "endOffset" : 115
    }, {
      "referenceID" : 2,
      "context" : "Often, different functional devices working as sensors are used to report animal data to the base station [3] [4].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 3,
      "context" : "Often, different functional devices working as sensors are used to report animal data to the base station [3] [4].",
      "startOffset" : 110,
      "endOffset" : 113
    }, {
      "referenceID" : 1,
      "context" : "UAVs provide an extremely flexible platform for WSNs applications by playing different roles in WSNs such as actors [2], sensors [5], and mobile sinks [6].",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 4,
      "context" : "UAVs provide an extremely flexible platform for WSNs applications by playing different roles in WSNs such as actors [2], sensors [5], and mobile sinks [6].",
      "startOffset" : 129,
      "endOffset" : 132
    }, {
      "referenceID" : 5,
      "context" : "UAVs provide an extremely flexible platform for WSNs applications by playing different roles in WSNs such as actors [2], sensors [5], and mobile sinks [6].",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 0,
      "context" : "edu • Part of this work was published in IEEE LCN 2015 [1] difficult and sometimes infeasible to find wildlife animals and attach wearable tracking devices to them.",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 6,
      "context" : "To quantitatively weigh the value of the sensed animal appearance information, the proposed path planning approach utilizes the value of information (VoI) [7].",
      "startOffset" : 155,
      "endOffset" : 158
    }, {
      "referenceID" : 3,
      "context" : "Lastly, we evaluate the performance of the proposed network model and the path planning approach with real animal datasets: ZebraNet [4] and leopard tortoises dataset.",
      "startOffset" : 133,
      "endOffset" : 136
    }, {
      "referenceID" : 6,
      "context" : "This metric is used in recent studies of sensor networks [7] as a way of assigning a higher value to more recently sensed data.",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 7,
      "context" : "While routing and clustering are not in the scope of this paper, they are well-investigated problems and there exist various efficient mechanisms [8] [9].",
      "startOffset" : 146,
      "endOffset" : 149
    }, {
      "referenceID" : 8,
      "context" : "While routing and clustering are not in the scope of this paper, they are well-investigated problems and there exist various efficient mechanisms [8] [9].",
      "startOffset" : 150,
      "endOffset" : 153
    }, {
      "referenceID" : 7,
      "context" : "[8] propose a cluster head (rendezvous points) selection method by jointly considering node degree and hop distance such that minimizing energy consumption and improving load balance.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "In our application, cluster head selection is based on an energy balancing policy which is proposed in [9].",
      "startOffset" : 103,
      "endOffset" : 106
    }, {
      "referenceID" : 0,
      "context" : "- γ ∈ [0, 1] is the discount factor which incorporates the fact into our model that obtaining the information in distant future worths less compared to getting informed in near future.",
      "startOffset" : 6,
      "endOffset" : 12
    }, {
      "referenceID" : 9,
      "context" : "A solution to the MDP can be achieved by repeating the bellman optimality equation [10]:",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 10,
      "context" : "To solve the MDP, we use Q-learning algorithm [11].",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 1,
      "context" : "If num is smaller than , the UAV randomly selects the next grid from the possible actions (lines [2-6]).",
      "startOffset" : 97,
      "endOffset" : 102
    }, {
      "referenceID" : 2,
      "context" : "If num is smaller than , the UAV randomly selects the next grid from the possible actions (lines [2-6]).",
      "startOffset" : 97,
      "endOffset" : 102
    }, {
      "referenceID" : 3,
      "context" : "If num is smaller than , the UAV randomly selects the next grid from the possible actions (lines [2-6]).",
      "startOffset" : 97,
      "endOffset" : 102
    }, {
      "referenceID" : 4,
      "context" : "If num is smaller than , the UAV randomly selects the next grid from the possible actions (lines [2-6]).",
      "startOffset" : 97,
      "endOffset" : 102
    }, {
      "referenceID" : 5,
      "context" : "If num is smaller than , the UAV randomly selects the next grid from the possible actions (lines [2-6]).",
      "startOffset" : 97,
      "endOffset" : 102
    }, {
      "referenceID" : 6,
      "context" : "In cases where all possible actions have the same Q value, for instance at the beginning of the network performance, the UAV does random action selection (lines [7-13]).",
      "startOffset" : 161,
      "endOffset" : 167
    }, {
      "referenceID" : 7,
      "context" : "In cases where all possible actions have the same Q value, for instance at the beginning of the network performance, the UAV does random action selection (lines [7-13]).",
      "startOffset" : 161,
      "endOffset" : 167
    }, {
      "referenceID" : 8,
      "context" : "In cases where all possible actions have the same Q value, for instance at the beginning of the network performance, the UAV does random action selection (lines [7-13]).",
      "startOffset" : 161,
      "endOffset" : 167
    }, {
      "referenceID" : 9,
      "context" : "In cases where all possible actions have the same Q value, for instance at the beginning of the network performance, the UAV does random action selection (lines [7-13]).",
      "startOffset" : 161,
      "endOffset" : 167
    }, {
      "referenceID" : 10,
      "context" : "In cases where all possible actions have the same Q value, for instance at the beginning of the network performance, the UAV does random action selection (lines [7-13]).",
      "startOffset" : 161,
      "endOffset" : 167
    }, {
      "referenceID" : 11,
      "context" : "In cases where all possible actions have the same Q value, for instance at the beginning of the network performance, the UAV does random action selection (lines [7-13]).",
      "startOffset" : 161,
      "endOffset" : 167
    }, {
      "referenceID" : 12,
      "context" : "In cases where all possible actions have the same Q value, for instance at the beginning of the network performance, the UAV does random action selection (lines [7-13]).",
      "startOffset" : 161,
      "endOffset" : 167
    }, {
      "referenceID" : 13,
      "context" : "Having the immediate rewards, the UAV updates the Q(s, a) using equation 10 (lines [14-17]).",
      "startOffset" : 83,
      "endOffset" : 90
    }, {
      "referenceID" : 14,
      "context" : "Having the immediate rewards, the UAV updates the Q(s, a) using equation 10 (lines [14-17]).",
      "startOffset" : 83,
      "endOffset" : 90
    }, {
      "referenceID" : 15,
      "context" : "Having the immediate rewards, the UAV updates the Q(s, a) using equation 10 (lines [14-17]).",
      "startOffset" : 83,
      "endOffset" : 90
    }, {
      "referenceID" : 16,
      "context" : "Having the immediate rewards, the UAV updates the Q(s, a) using equation 10 (lines [14-17]).",
      "startOffset" : 83,
      "endOffset" : 90
    }, {
      "referenceID" : 3,
      "context" : "The first one is the ZebraNet [4] dataset which was used in our previous work [1].",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 0,
      "context" : "The first one is the ZebraNet [4] dataset which was used in our previous work [1].",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 11,
      "context" : "Its main goal is tracking certain animals in a monitored area and reporting their location and other information to the applications users [12].",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 3,
      "context" : "Many animal tracking technologies have been proposed and implemented by engineers and wildlife researchers [4], [13]– [15].",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 12,
      "context" : "Many animal tracking technologies have been proposed and implemented by engineers and wildlife researchers [4], [13]– [15].",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 14,
      "context" : "Many animal tracking technologies have been proposed and implemented by engineers and wildlife researchers [4], [13]– [15].",
      "startOffset" : 118,
      "endOffset" : 122
    }, {
      "referenceID" : 3,
      "context" : "[4] present their ZebraNet project in which a low-power wireless system is built for position tracking of zebras.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 15,
      "context" : "In addition, some recent research [16]– [18] on animal behaviour gather animal movement data by installing wearable GPS devices.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 17,
      "context" : "In addition, some recent research [16]– [18] on animal behaviour gather animal movement data by installing wearable GPS devices.",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 18,
      "context" : "Although remote sensing can be used for sensing different types of data from a large area [19], [20], sensor networks seem to be a more feasible and reliable choice for animal monitoring.",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 19,
      "context" : "Although remote sensing can be used for sensing different types of data from a large area [19], [20], sensor networks seem to be a more feasible and reliable choice for animal monitoring.",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 20,
      "context" : "[21] develop integrated camerasensor networking systems and deploy them at large scales for collaborative wildlife monitoring and tracking.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "Similar studies based on camera sensor networks are conducted in [22] [23].",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 22,
      "context" : "Similar studies based on camera sensor networks are conducted in [22] [23].",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 23,
      "context" : "[24] propose to use UAVs for deployment of sensor nodes for post-disaster monitoring.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 24,
      "context" : "[25] use ScanEagle UAV to survey marine mammals.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 25,
      "context" : "[26] propose to use UAVs for scanning large areas of livestock systems.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 5,
      "context" : "[6] propose the use of aerial sensor networks consisting of UAVs for volcanic eruption monitoring.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 26,
      "context" : "[27] address path planning for autonomous underwater vehicle (AUV) to collect data from an underwater sensor network.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 7,
      "context" : "[8] propose a path planning approach for the mobile sink called weighted",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 27,
      "context" : "[28] propose a Traveling Salesman Problem (TSP) based path planning algorithm for the mobile sink.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 28,
      "context" : "[29] use one SenCar as a mobile sink for data collection in a static sensor network.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 29,
      "context" : "[30] investigate the problem of maximizing value of information in underwater sensor networks.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 30,
      "context" : "[31] study sink mobility in virtual coordinates domain and propose a routing strategy to minimize energy consumption while notifying the nodes about the latest location of the sink.",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2017,
    "abstractText" : "In animal monitoring applications, both animal detection and their movement prediction are major tasks. While a variety of animal monitoring strategies exist, most of them rely on mounting devices. However, in real world, it is difficult to find these animals and install mounting devices. In this paper, we propose an animal monitoring application by utilizing wireless sensor networks (WSNs) and unmanned aerial vehicle (UAV). The objective of the application is to detect locations of endangered species in large-scale wildlife areas and monitor movement of animals without any attached devices. In this application, sensors deployed throughout the observation area are responsible for gathering animal information. The UAV flies above the observation area and collects the information from sensors. To achieve the information efficiently, we propose a path planning approach for the UAV based on a Markov decision process (MDP) model. The UAV receives a certain amount of reward from an area if some animals are detected at that location. We solve the MDP using Q-learning such that the UAV prefers going to those areas that animals are detected before. Meanwhile, the UAV explores other areas as well to cover the entire network and detects changes in the animal positions. We first define the mathematical model underlying the animal monitoring problem in terms of the value of information (VoI) and rewards. We propose a network model including clusters of sensor nodes and a single UAV that acts as a mobile sink and visits the clusters. Then, one MDP-based path planning approach is designed to maximize the VoI while reducing message delays. The effectiveness of the proposed approach is evaluated using two real-world movement datasets of zebras and leopard. Simulation results show that our approach outperforms greedy and random heuristics as well as the path planning based on the solution of the traveling salesman problem.",
    "creator" : "LaTeX with hyperref package"
  }
}