{
  "name" : "1702.02206.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Semi-Supervised QA with Generative Domain-Adaptive Nets",
    "authors" : [ "Zhilin Yang", "Junjie Hu", "Ruslan Salakhutdinov", "William W. Cohen" ],
    "emails" : [ "zhiliny@cs.cmu.edu", "junjieh@cs.cmu.edu", "rsalakhu@cs.cmu.edu", "wcohen@cs.cmu.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Recently, various neural network models were proposed and successfully applied to the tasks of questions answering (QA) and/or reading comprehension (Xiong et al., 2016; Dhingra et al., 2016; Yang et al., 2017). While achieving stateof-the-art performance, these models rely on a large amount of labeled data. However, it is extremely difficult to collect large-scale question answering datasets. Historically, many of the question answering datasets have only thousands of question answering pairs, such as WebQuestions (Berant et al., 2013), MCTest (Richardson et al., 2013), WikiQA (Yang et al., 2015), and TREC-QA (Voorhees and Tice, 2000). Although larger question answering datasets with hundreds of thousands of question-answer pairs have been collected, including SQuAD (Rajpurkar et al.,\n2016), MSMARCO (Nguyen et al., 2016), and NewsQA (Trischler et al., 2016a), the data collection process is expensive and time-consuming in practice. This hinders real-world applications for domain-specific question answering.\nCompared to obtaining labeled question answer pairs, it is trivial to obtain unlabeled text data. In this work, we study the following problem of semi-supervised question answering: is it possible to leverage unlabeled text to boost the performance of question answering models, especially when only a small amount of labeled data is available? The problem is challenging because conventional manifold-based semi-supervised learning algorithms (Zhu and Ghahramani, 2002; Yang et al., 2016a) cannot be straightforwardly applied. Moreover, since the main foci of most question answering tasks are extraction rather than generation, it is also not sensible to use unlabeled text to improve language modeling as in machine translation (Gulcehre et al., 2015).\nTo better leverage the unlabeled text, we propose a novel neural framework called Generative Domain-Adaptive Nets (GDANs). The starting point of our framework is to use linguistic tags to extract possible answer chunks in the unlabeled text, and then train a generative model to generate questions given the answer chunks and their contexts. The model-generated questionanswer pairs and the human-generated questionanswer pairs can then be combined to train a question answering model, referred to as a discriminative model in the following text. However, there is discrepancy between the model-generated data distribution and the human-generated data distribution, which leads to suboptimal discriminative models. To address this issue, we further propose two domain adaptation techniques that treat the model-generated data distribution as a different domain. First, we use an additional domain tag to ar X iv :1 70 2.\n02 20\n6v 2\n[ cs\n.C L\n] 2\n2 A\npr 2\n01 7\nindicate whether a question-answer pair is modelgenerated or human-generated. We condition the discriminative model on the domain tags so that the discriminative model can learn to factor out domain-specific and domain-invariant representations. Second, we employ a reinforcement learning algorithm to fine-tune the generative model to minimize the loss of the discriminative model in an adversarial way.\nIn addition, we present a simple and effective baseline method for semi-supervised question answering. Although the baseline method performs worse than our GDAN approach, it is extremely easy to implement and can still lead to substantial improvement when only limited labeled data is available.\nWe experiment on the SQuAD dataset (Rajpurkar et al., 2016) with various labeling rates and various amounts of unlabeled data. Experimental results show that our GDAN framework consistently improves over both the supervised learning setting and the baseline methods, including adversarial domain adaptation (Ganin and Lempitsky, 2014) and dual learning (Xia et al., 2016). More specifically, the GDAN model improves the F1 score by 9.87 points in F1 over the supervised learning setting when 8K labeled question-answer pairs are used.\nOur contribution is four-fold. First, different from most of the previous neural network studies on question answering, we study a critical but challenging problem, semi-supervised question answering. Second, we propose the Generative Domain-Adaptive Nets that employ domain adaptation techniques on generative models with reinforcement learning algorithms. Third, we introduce a simple and effective baseline method. Fourth, we empirically show that our framework leads to substantial improvements."
    }, {
      "heading" : "2 Semi-Supervised Question Answering",
      "text" : "Let us first introduce the problem of semisupervised question answering.\nLet L = {q(i), a(i), p(i)}Ni=1 denote a question answering dataset of N instances, where q(i), a(i), and p(i) are the question, answer, and paragraph of the i-th instance respectively. The goal of question answering is to produce the answer a(i) given the question q(i) along with the paragraph p(i). We will drop the superscript ·(i) when the context is unambiguous. In our formulation, follow-\ning the setting in SQuAD (Rajpurkar et al., 2016), we specifically focus on extractive question answering, where a is always a consecutive chunk of text in p. More formally, let p = (p1, p2, · · · , pT ) be a sequence of word tokens with T being the length, then a can always be represented as a = (pj , pj+1, · · · , pk−1, pk), where j and k are the start and end token indices respectively. The questions can also be represented as a sequence of word tokens q = (q1, q2, · · · , qT ′) with length T ′.\nIn addition to the labeled dataset L, in the semisupervised setting, we are also given a set of unlabeled data, denoted as U = {a(i), p(i)}Mi=1, where M is the number of unlabeled instances. Note that it is usually trivial to have access to an almost infinite number of paragraphs p from sources such as Wikipedia articles and other web pages. And since the answer a is always a consecutive chunk in p, we argue that it is also sensible to extract possible answer chunks from the unlabeled text using linguistic tags. We will discuss the technical details of answer chunk extraction in Section 4.1, and in the formulation of our framework, we assume that the answer chunks a are available.\nGiven both the labeled data L and the unlabeled data U , the goal of semi-supervised question answering is to learn a question answering model D that captures the probability distribution P(a|p, q). We refer to this question answering model D as the discriminative model, in contrast to the generative model that we will present in Section 3.2."
    }, {
      "heading" : "2.1 A Simple Baseline",
      "text" : "We now present a simple baseline for semisupervised question answering. Given a paragraph p = (p1, p2, · · · , pT ) and the answer a = (pj , pj+1, · · · , pk−1, pk), we extract (pj−W , pj−W+1, · · · , pj−1, pk+1, pk+2, pk+W ) from the paragraph and treat it as the question. Here W is the window size and is set at 5 in our experiments so that the lengths of the questions are similar to human-generated questions. The context-based question-answer pairs on U are combined with human-generated pairs on L for training the discriminative model. Intuitively, this method extracts the contexts around the answer chunks to serve as hints for the question answering model. Surprisingly, this simple baseline method leads to substantial improvements when labeled data is limited."
    }, {
      "heading" : "3 Generative Domain-Adaptive Nets",
      "text" : "Though the simple method described in Section 2.1 can lead to substantial improvement, we aim to design a learning-based model to move even further. In this section, we will describe the model architecture and the training algorithms for the GDANs. We will use a notation in the context of question answering following Section 2, but one should be able to extend the notion of GDANs to other applications as well.\nThe GDAN framework consists of two models, a discriminative model and a generative model. We will first discuss the two models in detail in the context of question answering, and then present an algorithm based on reinforcement learning to combine the two models."
    }, {
      "heading" : "3.1 Discriminative Model",
      "text" : "The discriminative model learns the conditional probability of an answer chunk given the paragraph and the question, i.e., P(a|p, q). We employ a gated-attention (GA) reader (Dhingra et al., 2016) as our base model in this work, but our framework does not make any assumptions about the base models being used. The discriminative model is referred to as D.\nThe GA model consists of K layers with K being a hyper-parameter. Let Hkp be the intermediate paragraph representation at layer k, and Hq be the question representation. The paragraph representation Hkp is a T × d matrix, and the question representation Hq is a T ′ × d matrix, where d is the dimensionality of the representations. Given the paragraph p, we apply a bidirectional Gated Recurrent Unit (GRU) network (Chung et al., 2014) on top of the embeddings of the sequence (p1, p2, · · · , pT ), and obtain the initial paragraph representation H0p. Given the question q, we also apply another bidirectional GRU to obtain the question representation Hq.\nThe question and paragraph representations are combined with the gated-attention (GA) mechanism (Dhingra et al., 2016). More specifically, for each paragraph token pi, we compute\nαj = exphTq,jh k−1 p,i∑T ′\nj′=1 exph T q,j′h k−1 p,i\nhkp,i = T ′∑ j=1 αjhq,j hk−1p,i\nwhere hkp,i is the i-th row of H k p and hq,j is the j-th row of Hq. Since the answer a is a sequence of consecutive word tokens in the paragraph p, we apply two softmax layers on top of HKp to predict the start and end indices of a, following Yang et al. (2017)."
    }, {
      "heading" : "3.1.1 Domain Adaptation with Tags",
      "text" : "We will train our discriminative model on both model-generated question-answer pairs and human-generated pairs. However, even a welltrained generative model will produce questions somewhat different from human-generated ones. Learning from both human-generated data and model-generated data can thus lead to a biased model. To alleviate this issue, we propose to view the model-generated data distribution and the human-generated data distribution as two different data domains and explicitly incorporate domain adaptation into the discriminative model.\nMore specifically, we use a domain tag as an additional input to the discriminative model. We use the tag “d true” to represent the domain of human-generated data (i.e., the true data), and “d gen” for the domain of model-generated data. Following a practice in domain adaptation (Johnson et al., 2016; Chu et al., 2017), we append the domain tag to the end of both the questions and the paragraphs. By introducing the domain tags, we expect the discriminative model to factor out domain-specific and domain-invariant representations. At test time, the tag “d true” is appended."
    }, {
      "heading" : "3.2 Generative Model",
      "text" : "The generative model learns the conditional probability of generating a question given the paragraph and the answer, i.e., P(q|p, a). We implement the generative model as a sequence-tosequence model (Sutskever et al., 2014) with a copy mechanism (Gu et al., 2016; Gulcehre et al., 2016).\nThe generative model consists of an encoder and a decoder. An encoder is a GRU that encodes the input paragraph into a sequence of hidden states H. We inject the answer information by appending an additional zero/one feature to the word embeddings of the paragraph tokens; i.e., if a word token appears in the answer, the feature is set at one, otherwise zero.\nThe decoder is another GRU with an attention mechanism over the encoder hidden states H. At each time step, the generation probabilities over all\nAlgorithm 1 Training Generative DomainAdaptive Nets\nInput: labeled data L, unlabeled data U , #iterations TG and TD Initialize G by MLE training on L Randomly initialize D while not stopping do\nfor t← 1 to TD do Update D to maximize J(L, d true, D) + J(UG, d gen, D) with SGD end for for t← 1 to TG do\nUpdate G to maximize J(UG, d true, D) with Reinforce and SGD\nend for end while return model D\nword types are defined with a copy mechanism:\npoverall = gtpvocab + (1− gt)pcopy (1)\nwhere gt is the probability of generating the token from the vocabulary, while (1 − gt) is the probability of copying a token from the paragraph. The probability gt is computed based on the current hidden state ht:\ngt = σ(w T g ht)\nwhere σ denotes the logistic function and wg is a vector of model parameters. The generation probabilities pvocab are defined as a softmax function over the word types in the vocabulary, and the copying probabilities pcopy are defined as a softmax function over the word types in the paragraph. Both pvocab and pcopy are defined as a function of the current hidden state ht and the attention results (Gu et al., 2016)."
    }, {
      "heading" : "3.3 Training Algorithm",
      "text" : "We first define the objective function of the GDANs, and then present an algorithm to optimize the given objective function. Similar to the Generative Adversarial Nets (GANs) (Goodfellow et al., 2014) and adversarial domain adaptation (Ganin and Lempitsky, 2014), the discriminative model and the generative model have different objectives in our framework. However, rather than formulating the objective as an adversarial game between the two models (Goodfellow et al., 2014; Ganin and Lempitsky, 2014), in our framework, the discriminative model relies on the data generated by\nthe generative model, while the generative model aims to match the model-generated data distribution with the human-generated data distribution using the signals from the discriminative model.\nGiven a labeled datasetL = {p(i), q(i), a(i)}Ni=1, the objective function of a discriminative modelD for a supervised learning setting can be written as∑\np(i),q(i),a(i)∈L logPD(a(i)|p(i), q(i)), where PD is a probability distribution defined by the model D. Since we also incorporate domain tags into the model D, we denote the objective function as\nJ(L, tag, D) = 1 |L| ∑\np(i),q(i),a(i)∈L\nlog PD,tag(a (i)|p(i), q(i))\nmeaning that the domain tag, “tag”, is appended to the dataset L. We use |L| = N to denote the number of the instances in the dataset L. The objective function is averaged over all instances such that we can balance labeled and unlabeled data.\nLet UG denote the dataset obtained by generating questions on the unlabeled dataset U with the generative model G. The objective of the discriminative model is then to maximize J for both labeled and unlabeled data under the domain adaptation notions, i.e., J(L, d true, D) + J(UG, d gen, D).\nNow we discuss the objective of the generative model. Similar to the dual learning (Xia et al., 2016) framework, one can define an autoencoder objective. In this case, the generative model aims to generate questions that can be reconstructed by the discriminative model, i.e., maximizing J(UG, d gen, D). However, this objective function can lead to degenerate solutions because the questions can be thought of as an overcomplete representation of the answers (Vincent et al., 2010). For example, given p and a, the generative model might learn to generate trivial questions such as copying the answers, which does not contributed to learning a better D.\nInstead, we leverage the discriminative model to better match the model-generated data distribution with the human-generated data distribution. We propose to define an adversarial training objective J(UG, d true, D). We append the tag “d true” instead of “d gen” for the model-generated data to “fool” the discriminative model. Intuitively, the goal of G is to generate ”useful” questions where the usefulness is measured by the probability that the generated questions can be answered correctly by D.\nThe overall objective function now can be written as\nmaxD J(L, d true, D) + J(UG, d gen, D)\nmaxG J(UG, d true, D)\nWith the above objective function in mind, we present a training algorithm in Algorithm 1 to train a GDAN. We first pretrain the generative model on the labeled data L with maximum likelihood estimation (MLE):\nmax G N∑ i=1 T ′∑ t=1 logPG(q (i) t |q (i) <t, p (i), a(i))\nwhere PG is the probability defined by Eq. 1. We then alternatively update D and G based on their objectives. To update D, we sample one batch from the labeled data L and one batch from the unlabeled data UG, and combine the two batches to perform a gradient update step. Since the output of G is discrete and non-differentiable, we use the Reinforce algorithm (Williams, 1992) to update G. The action space is all possible questions with length T ′ (possibly with padding) and the reward is the objective function J(UG, d true, D). Let θG be the parameters of G. The gradient can be written as\n∂J(UG, d true, D) ∂θG\n= EPG(q|p,a)(log PD,d true(a|p, q)− b) ∂ log PG(q|p, a)\n∂θG\nwhere we use an average reward from samples as the baseline b. We approximate the expectation\nEPG(q|p,a) by sampling one instance at a time from PG(q|p, a) and then do an update step. This training algorithm is referred to as reinforcement learning (RL) training in the following sections. The overall architecture and training algorithm are illustrated in Figure 1.\nMLE vs RL. The generator G has two training phases–MLE training and RL training, which are different in that: 1) RL training does not require labels, so G can explore a broader data domain of p using unlabeled data, while MLE training requires labels; 2) MLE maximizes logP (q|p, a), while RL maximizes logPD(a|q, p). Since logP (q|a, p) is the sum of logP (q|p) and logP (a|q, p) (plus a constant), maximizing logP (a|q, p) does not require modeling logP (q|p) that is irrelevant to QA, which makes optimization easier. Moreover, maximizing logP (a|q, p) is consistent with the goal of QA."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Answer Extraction",
      "text" : "As discussed in Section 2, our model assumes that answers are available for unlabeled data. In this section, we introduce how we use linguistic tags and rules to extract answer chunks from unlabeled text.\nTo extract answers from massive unlabelled Wikipedia articles, we first sample 205,511 Wikipedia articles that are not used in the training, development and test sets in the SQuAD dataset. We extract the paragraphs from each article, and limit the length of each paragraph at the word level to be less than 850. In total, we obtain 950,612\nparagraphs from unlabelled articles. Answers in the SQuAD dataset can be categorized into ten types, i.e., “Date”, “Other Numeric”, “Person”, “Location”, “Other Entity”, “Common Noun Phrase”, “Adjective Phrase”, “Verb Phrase”, “Clause” and “Other” (Rajpurkar et al., 2016). For each paragraph from the unlabeled articles, we utilize Stanford Part-Of-Speech (POS) tagger (Toutanova et al., 2003) to label each word with the corresponding POS tag, and implement a simple constituency parser to extract the noun phrase, verb phrase, adjective and clause based on a small set of constituency grammars. Next, we use Stanford Named Entity Recognizer (NER) (Finkel et al., 2005) to assign each word with one of the seven labels, i.e., “Date”, “Money”, “Percent”, “location”, “Organization” and “Time”. We then categorize a span of consecutive words with the same NER tags of either “Money” or “Percent” as the answer of the type “Other Numeric”. Similarly, we categorize a span of consecutive words with the same NER tags of\n“Organization” as the answer of the type “Other Entity”. Finally, we subsample five answers from all the extracted answers for each paragraph according to the percentage of answer types in the SQuAD dataset. We obtain 4,753,060 answers in total, which is about 50 times larger than the number of answers in the SQuAD dataset."
    }, {
      "heading" : "4.2 Settings and Comparison Methods",
      "text" : "The original SQuAD dataset consists of 87,636 training instances and 10,600 development instances. Since the test set is not published, we split 10% of the training set as the test set, and the remaining 90% serves as the actual training set. Instances are split based on articles; i.e., paragraphs in one article always appear in only one set. We tune the hyper-parameters and perform early stopping on the development set using the F1 scores, and the performance is evaluated on the test set using both F1 scores and exact matching (EM) scores (Rajpurkar et al., 2016).\nWe compare the following methods. SL is\nthe supervised learning setting where we train the model D solely on the labeled data L. Context is the simple context-based method described in Section 2.1. Context + domain is the “Context” method with domain tags as described in Section 3.1.1. Gen is to train a generative model and use the generated questions as additional training data. Gen + GAN refers to the domain adaptation method using GANs (Ganin and Lempitsky, 2014); in contrast to the original work, the generative model is updated using Reinforce. Gen + dual refers to the dual learning method (Xia et al., 2016). Gen + domain is “Gen” with domain tags, while the generative model is trained with MLE and fixed. Gen + domain + adv is the approach we propose (Cf. Figure 1 and Algorithm 1), with “adv” meaning adversarial training based on Reinforce. We use our own implementation of “Gen + GAN” and “Gen + dual”, since the GAN model (Ganin and Lempitsky, 2014) does not handle discrete features and the dual learning model (Xia et al., 2016) cannot be directly applied to question answering. When implementing these two baselines, we adopt the learning schedule introduced by Ganin and Lempitsky (2014), i.e., gradually increasing the weights of the gradients for the generative model G."
    }, {
      "heading" : "4.3 Results and Analysis",
      "text" : "We study the performance of different models with varying labeling rates and unlabeled dataset sizes. Labeling rates are the percentage of training instances that are used to train D. The results are reported in Table 2. Though the unlabeled dataset we collect consists of around 5 million instances, we also sample a subset of around 50,000 instances to evaluate the effects of the size of unlabeled data. The highest labeling rate in Table 2 is 0.9 because 10% of the training instances are used for testing. Since we do early stopping on the development set using the F1 scores, we also report the development F1. We report two metrics, the F1 scores and the exact matching (EM) scores (Rajpurkar et al., 2016), on the test set. All metrics are computed using the official evaluation scripts.\nSL v.s. SSL. We observe that semi-supervised learning leads to consistent improvements over supervised learning in all cases. Such improvements are substantial when labeled data is limited. For example, the GDANs improve over supervised learning by 9.87 points in F1 and 7.26 points in\nEM when the labeling rate is 0.1. With our semisupervised learning approach, we can use only 0.1 training instances to obtain even better performance than a supervised learning approach with 0.2 training instances, saving more than half of the labeling costs.\nComparison with Baselines. By comparing “Gen + domain + adv” with “Gen + GAN” and “Gen + Dual”, it is clear that the GDANs perform substantially better than GANs and dual learning. With labeling rate 0.1, GDANs outperform dual learning and GANs by 2.47 and 4.29 points respectively in terms of F1.\nAblation Study. We also perform an ablation study by examining the effects of “domain” and “adv” when added to “gen”. It can be seen that both the domain tags and the adversarial training contribute to the performance of the GDANs when the labeling rate is equal to or less than 0.5. With labeling rate 0.9, adding domain tags still leads to better performance but adversarial training does not seem to improve the performance by much.\nUnlabeled Data Size. Moreover, we observe that the performance can be further improved when a larger unlabeled dataset is used, though the gain is relatively less significant compared to changing the model architectures. For example, increasing the unlabeled dataset size from 50K to 5M, the performance of GDANs increases by 0.38 points in F1 and 0.52 points in EM.\nContext-Based Method. Surprisingly, the simple context-based method, though performing worse than GDANs, still leads to substantial gains; e.g., 7.00 points in F1 with labeling rate 0.1. Adding domain tags can improve the performance of the context-based method as well.\nMLE vs RL. We plot the loss curve of −J(UG, d gen, D) for both the MLE-trained generator (“Gen + domain”) and the RL-trained generator (“Gen + domain + adv”) in Figure 2. We observe that the training loss for D on RLgenerated questions is lower than MLE-generated questions, which confirms that RL training maximizes logP (a|p, q).\nSamples of Generated Questions. We present some questions generated by our model in Table 1. The generated questions are post-processed by removing repeated subs-sequences. Compared to MLE-generated questions, RL-generated questions are more informative (Cf., P1, P2, and P4), and contain less “UNK” (unknown) tokens (Cf.,\nP1). Moreover, both semantically and syntactically, RL-generated questions are more accurate (Cf., P3 and P5)."
    }, {
      "heading" : "5 Related Work",
      "text" : "Semi-Supervised Learning. Semi-supervised learning has been extensively studied in literature (Zhu, 2005). A batch of novel models have been recently proposed for semi-supervised learning based on representation learning techniques, such as generative models (Kingma et al., 2014), ladder networks (Rasmus et al., 2015) and graph embeddings (Yang et al., 2016a). However, most of the semi-supervised learning methods are based on combinations of the supervised loss p(y|x) and an unsupervised loss p(x). In the context of reading comprehension, directly modeling the likelihood of a paragraph would not possibly improve the supervised task of question answering. Moreover, traditional graph-based semisupervised learning (Zhu and Ghahramani, 2002) cannot be easily extended to modeling the unlabeled answer chunks.\nDomain Adaptation. Domain adaptation has been successfully applied to various tasks, such as classification (Ganin and Lempitsky, 2014) and machine translation (Johnson et al., 2016; Chu et al., 2017). Several techniques on domain adaptation (Glorot et al., 2011) focus on learning distribution invariant features by sharing the intermediate representations for downstream tasks. Another line of research on domain adaptation attempt to match the distance between different domain distributions in a low dimensional space (Long et al., 2015; Baktashmotlagh et al., 2013). There are\nalso methods seeking a domain transition from the source domain to the target domain (Gong et al., 2012; Gopalan et al., 2011; Pan et al., 2011). Our work gets inspiration from a practice in Johnson et al. (2016) and Chu et al. (2017) based on appending domain tags. However, our method is different from the above methods in that we apply domain adaptation techniques to the outputs of a generative model rather than a natural data domain.\nQuestion Answering. Various neural models based on attention mechanisms (Wang and Jiang, 2016; Seo et al., 2016; Xiong et al., 2016; Wang et al., 2016; Dhingra et al., 2016; Kadlec et al., 2016; Trischler et al., 2016b; Sordoni et al., 2016; Cui et al., 2016; Chen et al., 2016) have been proposed to tackle the tasks of question answering and reading comprehension. However, the performance of these neural models largely relies on a large amount of labeled data available for training.\nLearning with Multiple Models. GANs (Goodfellow et al., 2014) formulated a adversarial game between a discriminative model and a generative model for generating realistic images. Ganin and Lempitsky (Ganin and Lempitsky, 2014) employed a similar idea to use two models for domain adaptation. Review networks (Yang et al., 2016b) employ a discriminative model as a regularizer for training a generative model. In the context of machine translation, given a language pair, various recent work studied jointly training models to learn the mappings in both directions (Tu et al., 2016; Xia et al., 2016)."
    }, {
      "heading" : "6 Conclusions",
      "text" : "We study a critical and challenging problem, semi-supervised question answering. We propose a novel neural framework called Generative Domain-Adaptive Nets, which incorporate domain adaptation techniques in combination with generative models for semi-supervised learning. Empirically, we show that our approach leads to substantial improvements over supervised learning models and outperforms several strong baselines including GANs and dual learning. In the future, we plan to apply our approach to more question answering datasets in different domains. It will also be intriguing to generalize GDANs to other applications.\nAcknowledgements. This work was funded by the Office of Naval Research grants N000141512791 and\nN000141310721 and NVIDIA."
    } ],
    "references" : [ {
      "title" : "Unsupervised domain adaptation by domain invariant projection",
      "author" : [ "Mahsa Baktashmotlagh", "Mehrtash T Harandi", "Brian C Lovell", "Mathieu Salzmann." ],
      "venue" : "ICCV . pages 769–776.",
      "citeRegEx" : "Baktashmotlagh et al\\.,? 2013",
      "shortCiteRegEx" : "Baktashmotlagh et al\\.",
      "year" : 2013
    }, {
      "title" : "Semantic parsing on freebase from question-answer pairs",
      "author" : [ "Jonathan Berant", "Andrew Chou", "Roy Frostig", "Percy Liang." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Berant et al\\.,? 2013",
      "shortCiteRegEx" : "Berant et al\\.",
      "year" : 2013
    }, {
      "title" : "A thorough examination of the cnn/daily mail reading comprehension task",
      "author" : [ "Danqi Chen", "Jason Bolton", "Christopher D Manning." ],
      "venue" : "arXiv preprint arXiv:1606.02858 .",
      "citeRegEx" : "Chen et al\\.,? 2016",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2016
    }, {
      "title" : "An empirical comparison of simple domain adaptation methods for neural machine translation",
      "author" : [ "Chenhui Chu", "Raj Dabre", "Sadao Kurohashi." ],
      "venue" : "arXiv preprint arXiv:1701.03214 .",
      "citeRegEx" : "Chu et al\\.,? 2017",
      "shortCiteRegEx" : "Chu et al\\.",
      "year" : 2017
    }, {
      "title" : "Empirical evaluation of gated recurrent neural networks on sequence modeling",
      "author" : [ "Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1412.3555 .",
      "citeRegEx" : "Chung et al\\.,? 2014",
      "shortCiteRegEx" : "Chung et al\\.",
      "year" : 2014
    }, {
      "title" : "Attention-overattention neural networks for reading comprehension",
      "author" : [ "Yiming Cui", "Zhipeng Chen", "Si Wei", "Shijin Wang", "Ting Liu", "Guoping Hu." ],
      "venue" : "arXiv preprint arXiv:1607.04423 .",
      "citeRegEx" : "Cui et al\\.,? 2016",
      "shortCiteRegEx" : "Cui et al\\.",
      "year" : 2016
    }, {
      "title" : "Gated-attention readers for text comprehension",
      "author" : [ "Bhuwan Dhingra", "Hanxiao Liu", "Zhilin Yang", "William W Cohen", "Ruslan Salakhutdinov." ],
      "venue" : "arXiv preprint arXiv:1606.01549 .",
      "citeRegEx" : "Dhingra et al\\.,? 2016",
      "shortCiteRegEx" : "Dhingra et al\\.",
      "year" : 2016
    }, {
      "title" : "Incorporating non-local information into information extraction systems by gibbs sampling",
      "author" : [ "Jenny Rose Finkel", "Trond Grenager", "Christopher Manning." ],
      "venue" : "ACL. Association for Computational Linguistics, pages 363–370.",
      "citeRegEx" : "Finkel et al\\.,? 2005",
      "shortCiteRegEx" : "Finkel et al\\.",
      "year" : 2005
    }, {
      "title" : "Unsupervised domain adaptation by backpropagation",
      "author" : [ "Yaroslav Ganin", "Victor Lempitsky." ],
      "venue" : "arXiv preprint arXiv:1409.7495 .",
      "citeRegEx" : "Ganin and Lempitsky.,? 2014",
      "shortCiteRegEx" : "Ganin and Lempitsky.",
      "year" : 2014
    }, {
      "title" : "Domain adaptation for large-scale sentiment classification: A deep learning approach",
      "author" : [ "Xavier Glorot", "Antoine Bordes", "Yoshua Bengio." ],
      "venue" : "ICML. pages 513–520.",
      "citeRegEx" : "Glorot et al\\.,? 2011",
      "shortCiteRegEx" : "Glorot et al\\.",
      "year" : 2011
    }, {
      "title" : "Geodesic flow kernel for unsupervised domain adaptation",
      "author" : [ "Boqing Gong", "Yuan Shi", "Fei Sha", "Kristen Grauman." ],
      "venue" : "CVPR. IEEE, pages 2066– 2073.",
      "citeRegEx" : "Gong et al\\.,? 2012",
      "shortCiteRegEx" : "Gong et al\\.",
      "year" : 2012
    }, {
      "title" : "Generative adversarial nets",
      "author" : [ "Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio." ],
      "venue" : "NIPS. pages 2672–2680.",
      "citeRegEx" : "Goodfellow et al\\.,? 2014",
      "shortCiteRegEx" : "Goodfellow et al\\.",
      "year" : 2014
    }, {
      "title" : "Domain adaptation for object recognition: An unsupervised approach",
      "author" : [ "Raghuraman Gopalan", "Ruonan Li", "Rama Chellappa." ],
      "venue" : "ICCV . IEEE, pages 999–1006.",
      "citeRegEx" : "Gopalan et al\\.,? 2011",
      "shortCiteRegEx" : "Gopalan et al\\.",
      "year" : 2011
    }, {
      "title" : "Incorporating copying mechanism in sequence-to-sequence learning",
      "author" : [ "Jiatao Gu", "Zhengdong Lu", "Hang Li", "Victor OK Li." ],
      "venue" : "arXiv preprint arXiv:1603.06393 .",
      "citeRegEx" : "Gu et al\\.,? 2016",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2016
    }, {
      "title" : "Pointing the unknown words",
      "author" : [ "Caglar Gulcehre", "Sungjin Ahn", "Ramesh Nallapati", "Bowen Zhou", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1603.08148 .",
      "citeRegEx" : "Gulcehre et al\\.,? 2016",
      "shortCiteRegEx" : "Gulcehre et al\\.",
      "year" : 2016
    }, {
      "title" : "On using monolingual corpora in neural machine translation",
      "author" : [ "Caglar Gulcehre", "Orhan Firat", "Kelvin Xu", "Kyunghyun Cho", "Loic Barrault", "Huei-Chi Lin", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1503.03535 .",
      "citeRegEx" : "Gulcehre et al\\.,? 2015",
      "shortCiteRegEx" : "Gulcehre et al\\.",
      "year" : 2015
    }, {
      "title" : "Google’s multilingual neural machine translation system: Enabling zero-shot translation",
      "author" : [ "Melvin Johnson", "Mike Schuster", "Quoc V Le", "Maxim Krikun", "Yonghui Wu", "Zhifeng Chen", "Nikhil Thorat", "Fernanda Viégas", "Martin Wattenberg", "Greg Corrado" ],
      "venue" : null,
      "citeRegEx" : "Johnson et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2016
    }, {
      "title" : "Text understanding with the attention sum reader network",
      "author" : [ "Rudolf Kadlec", "Martin Schmid", "Ondrej Bajgar", "Jan Kleindienst." ],
      "venue" : "arXiv preprint arXiv:1603.01547 .",
      "citeRegEx" : "Kadlec et al\\.,? 2016",
      "shortCiteRegEx" : "Kadlec et al\\.",
      "year" : 2016
    }, {
      "title" : "Semi-supervised learning with deep generative models",
      "author" : [ "Diederik P Kingma", "Shakir Mohamed", "Danilo Jimenez Rezende", "Max Welling." ],
      "venue" : "NIPS. pages 3581–3589.",
      "citeRegEx" : "Kingma et al\\.,? 2014",
      "shortCiteRegEx" : "Kingma et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning transferable features with deep adaptation networks",
      "author" : [ "Mingsheng Long", "Yue Cao", "Jianmin Wang", "Michael I Jordan." ],
      "venue" : "ICML. pages 97–105.",
      "citeRegEx" : "Long et al\\.,? 2015",
      "shortCiteRegEx" : "Long et al\\.",
      "year" : 2015
    }, {
      "title" : "Ms marco: A human generated machine reading comprehension dataset",
      "author" : [ "Tri Nguyen", "Mir Rosenberg", "Xia Song", "Jianfeng Gao", "Saurabh Tiwary", "Rangan Majumder", "Li Deng." ],
      "venue" : "arXiv preprint arXiv:1611.09268 .",
      "citeRegEx" : "Nguyen et al\\.,? 2016",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2016
    }, {
      "title" : "Domain adaptation via transfer component analysis",
      "author" : [ "Sinno Jialin Pan", "Ivor W Tsang", "James T Kwok", "Qiang Yang." ],
      "venue" : "IEEE Transactions on Neural Networks 22(2):199–210.",
      "citeRegEx" : "Pan et al\\.,? 2011",
      "shortCiteRegEx" : "Pan et al\\.",
      "year" : 2011
    }, {
      "title" : "Squad: 100,000+ questions for machine comprehension of text",
      "author" : [ "Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Rajpurkar et al\\.,? 2016",
      "shortCiteRegEx" : "Rajpurkar et al\\.",
      "year" : 2016
    }, {
      "title" : "Semisupervised learning with ladder networks",
      "author" : [ "Antti Rasmus", "Mathias Berglund", "Mikko Honkala", "Harri Valpola", "Tapani Raiko." ],
      "venue" : "NIPS. pages 3546–3554.",
      "citeRegEx" : "Rasmus et al\\.,? 2015",
      "shortCiteRegEx" : "Rasmus et al\\.",
      "year" : 2015
    }, {
      "title" : "Mctest: A challenge dataset for the open-domain machine comprehension of text",
      "author" : [ "Matthew Richardson", "Christopher JC Burges", "Erin Renshaw." ],
      "venue" : "EMNLP. volume 3.",
      "citeRegEx" : "Richardson et al\\.,? 2013",
      "shortCiteRegEx" : "Richardson et al\\.",
      "year" : 2013
    }, {
      "title" : "Bidirectional attention flow for machine comprehension",
      "author" : [ "Minjoon Seo", "Aniruddha Kembhavi", "Ali Farhadi", "Hannaneh Hajishirzi." ],
      "venue" : "arXiv preprint arXiv:1611.01603 .",
      "citeRegEx" : "Seo et al\\.,? 2016",
      "shortCiteRegEx" : "Seo et al\\.",
      "year" : 2016
    }, {
      "title" : "Iterative alternating neural attention for machine reading",
      "author" : [ "Alessandro Sordoni", "Philip Bachman", "Adam Trischler", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1606.02245 .",
      "citeRegEx" : "Sordoni et al\\.,? 2016",
      "shortCiteRegEx" : "Sordoni et al\\.",
      "year" : 2016
    }, {
      "title" : "Sequence to sequence learning with neural networks",
      "author" : [ "Ilya Sutskever", "Oriol Vinyals", "Quoc V Le." ],
      "venue" : "NIPS. pages 3104–3112.",
      "citeRegEx" : "Sutskever et al\\.,? 2014",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2014
    }, {
      "title" : "Feature-rich part-ofspeech tagging with a cyclic dependency network",
      "author" : [ "Kristina Toutanova", "Dan Klein", "Christopher D Manning", "Yoram Singer." ],
      "venue" : "NAACL. Association for Computational Linguistics, pages 173–180.",
      "citeRegEx" : "Toutanova et al\\.,? 2003",
      "shortCiteRegEx" : "Toutanova et al\\.",
      "year" : 2003
    }, {
      "title" : "Newsqa: A machine comprehension dataset",
      "author" : [ "Adam Trischler", "Tong Wang", "Xingdi Yuan", "Justin Harris", "Alessandro Sordoni", "Philip Bachman", "Kaheer Suleman." ],
      "venue" : "arXiv preprint arXiv:1611.09830 .",
      "citeRegEx" : "Trischler et al\\.,? 2016a",
      "shortCiteRegEx" : "Trischler et al\\.",
      "year" : 2016
    }, {
      "title" : "Natural language comprehension with the epireader",
      "author" : [ "Adam Trischler", "Zheng Ye", "Xingdi Yuan", "Kaheer Suleman." ],
      "venue" : "arXiv preprint arXiv:1606.02270 .",
      "citeRegEx" : "Trischler et al\\.,? 2016b",
      "shortCiteRegEx" : "Trischler et al\\.",
      "year" : 2016
    }, {
      "title" : "Modeling coverage for neural machine translation",
      "author" : [ "Zhaopeng Tu", "Zhengdong Lu", "Yang Liu", "Xiaohua Liu", "Hang Li." ],
      "venue" : "ACL.",
      "citeRegEx" : "Tu et al\\.,? 2016",
      "shortCiteRegEx" : "Tu et al\\.",
      "year" : 2016
    }, {
      "title" : "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion",
      "author" : [ "Pascal Vincent", "Hugo Larochelle", "Isabelle Lajoie", "Yoshua Bengio", "Pierre-Antoine Manzagol." ],
      "venue" : "JMLR 11(Dec):3371–3408.",
      "citeRegEx" : "Vincent et al\\.,? 2010",
      "shortCiteRegEx" : "Vincent et al\\.",
      "year" : 2010
    }, {
      "title" : "Building a question answering test collection",
      "author" : [ "Ellen M Voorhees", "Dawn M Tice." ],
      "venue" : "SIGIR. ACM, pages 200–207.",
      "citeRegEx" : "Voorhees and Tice.,? 2000",
      "shortCiteRegEx" : "Voorhees and Tice.",
      "year" : 2000
    }, {
      "title" : "Machine comprehension using match-lstm and answer pointer",
      "author" : [ "Shuohang Wang", "Jing Jiang." ],
      "venue" : "arXiv preprint arXiv:1608.07905 .",
      "citeRegEx" : "Wang and Jiang.,? 2016",
      "shortCiteRegEx" : "Wang and Jiang.",
      "year" : 2016
    }, {
      "title" : "Multi-perspective context matching for machine comprehension",
      "author" : [ "Zhiguo Wang", "Haitao Mi", "Wael Hamza", "Radu Florian." ],
      "venue" : "arXiv preprint arXiv:1612.04211 .",
      "citeRegEx" : "Wang et al\\.,? 2016",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2016
    }, {
      "title" : "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning",
      "author" : [ "Ronald J Williams." ],
      "venue" : "Machine learning 8(3-4):229–256.",
      "citeRegEx" : "Williams.,? 1992",
      "shortCiteRegEx" : "Williams.",
      "year" : 1992
    }, {
      "title" : "Dual learning for machine translation",
      "author" : [ "Yingce Xia", "Di He", "Tao Qin", "Liwei Wang", "Nenghai Yu", "Tie-Yan Liu", "Wei-Ying Ma." ],
      "venue" : "arXiv preprint arXiv:1611.00179 .",
      "citeRegEx" : "Xia et al\\.,? 2016",
      "shortCiteRegEx" : "Xia et al\\.",
      "year" : 2016
    }, {
      "title" : "Dynamic coattention networks for question answering",
      "author" : [ "Caiming Xiong", "Victor Zhong", "Richard Socher." ],
      "venue" : "arXiv preprint arXiv:1611.01604 .",
      "citeRegEx" : "Xiong et al\\.,? 2016",
      "shortCiteRegEx" : "Xiong et al\\.",
      "year" : 2016
    }, {
      "title" : "Wikiqa: A challenge dataset for open-domain question answering",
      "author" : [ "Yi Yang", "Wen-tau Yih", "Christopher Meek." ],
      "venue" : "EMNLP. Citeseer, pages 2013– 2018.",
      "citeRegEx" : "Yang et al\\.,? 2015",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2015
    }, {
      "title" : "Revisiting semi-supervised learning with graph embeddings",
      "author" : [ "Zhilin Yang", "William Cohen", "Ruslan Salakhutdinov." ],
      "venue" : "ICML.",
      "citeRegEx" : "Yang et al\\.,? 2016a",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2016
    }, {
      "title" : "Words or characters? fine-grained gating for reading comprehension",
      "author" : [ "Zhilin Yang", "Bhuwan Dhingra", "Ye Yuan", "Junjie Hu", "William W Cohen", "Ruslan Salakhutdinov." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Yang et al\\.,? 2017",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2017
    }, {
      "title" : "Review networks for caption generation",
      "author" : [ "Zhilin Yang", "Ye Yuan", "Yuexin Wu", "William W Cohen", "Ruslan R Salakhutdinov." ],
      "venue" : "NIPS. pages 2361– 2369.",
      "citeRegEx" : "Yang et al\\.,? 2016b",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2016
    }, {
      "title" : "Semi-supervised learning literature survey",
      "author" : [ "Xiaojin Zhu" ],
      "venue" : null,
      "citeRegEx" : "Zhu.,? \\Q2005\\E",
      "shortCiteRegEx" : "Zhu.",
      "year" : 2005
    }, {
      "title" : "Learning from labeled and unlabeled data with label propagation",
      "author" : [ "Xiaojin Zhu", "Zoubin Ghahramani" ],
      "venue" : null,
      "citeRegEx" : "Zhu and Ghahramani.,? \\Q2002\\E",
      "shortCiteRegEx" : "Zhu and Ghahramani.",
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 38,
      "context" : "Recently, various neural network models were proposed and successfully applied to the tasks of questions answering (QA) and/or reading comprehension (Xiong et al., 2016; Dhingra et al., 2016; Yang et al., 2017).",
      "startOffset" : 149,
      "endOffset" : 210
    }, {
      "referenceID" : 6,
      "context" : "Recently, various neural network models were proposed and successfully applied to the tasks of questions answering (QA) and/or reading comprehension (Xiong et al., 2016; Dhingra et al., 2016; Yang et al., 2017).",
      "startOffset" : 149,
      "endOffset" : 210
    }, {
      "referenceID" : 41,
      "context" : "Recently, various neural network models were proposed and successfully applied to the tasks of questions answering (QA) and/or reading comprehension (Xiong et al., 2016; Dhingra et al., 2016; Yang et al., 2017).",
      "startOffset" : 149,
      "endOffset" : 210
    }, {
      "referenceID" : 1,
      "context" : "Historically, many of the question answering datasets have only thousands of question answering pairs, such as WebQuestions (Berant et al., 2013), MCTest (Richardson et al.",
      "startOffset" : 124,
      "endOffset" : 145
    }, {
      "referenceID" : 24,
      "context" : ", 2013), MCTest (Richardson et al., 2013), WikiQA (Yang et al.",
      "startOffset" : 16,
      "endOffset" : 41
    }, {
      "referenceID" : 39,
      "context" : ", 2013), WikiQA (Yang et al., 2015), and TREC-QA (Voorhees and Tice, 2000).",
      "startOffset" : 16,
      "endOffset" : 35
    }, {
      "referenceID" : 33,
      "context" : ", 2015), and TREC-QA (Voorhees and Tice, 2000).",
      "startOffset" : 21,
      "endOffset" : 46
    }, {
      "referenceID" : 22,
      "context" : "Although larger question answering datasets with hundreds of thousands of question-answer pairs have been collected, including SQuAD (Rajpurkar et al., 2016), MSMARCO (Nguyen et al.",
      "startOffset" : 133,
      "endOffset" : 157
    }, {
      "referenceID" : 20,
      "context" : ", 2016), MSMARCO (Nguyen et al., 2016), and NewsQA (Trischler et al.",
      "startOffset" : 17,
      "endOffset" : 38
    }, {
      "referenceID" : 29,
      "context" : ", 2016), and NewsQA (Trischler et al., 2016a), the data collection process is expensive and time-consuming in practice.",
      "startOffset" : 20,
      "endOffset" : 45
    }, {
      "referenceID" : 44,
      "context" : "able? The problem is challenging because conventional manifold-based semi-supervised learning algorithms (Zhu and Ghahramani, 2002; Yang et al., 2016a) cannot be straightforwardly applied.",
      "startOffset" : 105,
      "endOffset" : 151
    }, {
      "referenceID" : 40,
      "context" : "able? The problem is challenging because conventional manifold-based semi-supervised learning algorithms (Zhu and Ghahramani, 2002; Yang et al., 2016a) cannot be straightforwardly applied.",
      "startOffset" : 105,
      "endOffset" : 151
    }, {
      "referenceID" : 15,
      "context" : "answering tasks are extraction rather than generation, it is also not sensible to use unlabeled text to improve language modeling as in machine translation (Gulcehre et al., 2015).",
      "startOffset" : 156,
      "endOffset" : 179
    }, {
      "referenceID" : 22,
      "context" : "We experiment on the SQuAD dataset (Rajpurkar et al., 2016) with various labeling rates and various amounts of unlabeled data.",
      "startOffset" : 35,
      "endOffset" : 59
    }, {
      "referenceID" : 8,
      "context" : "tal results show that our GDAN framework consistently improves over both the supervised learning setting and the baseline methods, including adversarial domain adaptation (Ganin and Lempitsky, 2014) and dual learning (Xia et al.",
      "startOffset" : 171,
      "endOffset" : 198
    }, {
      "referenceID" : 37,
      "context" : "tal results show that our GDAN framework consistently improves over both the supervised learning setting and the baseline methods, including adversarial domain adaptation (Ganin and Lempitsky, 2014) and dual learning (Xia et al., 2016).",
      "startOffset" : 217,
      "endOffset" : 235
    }, {
      "referenceID" : 22,
      "context" : "In our formulation, following the setting in SQuAD (Rajpurkar et al., 2016), we specifically focus on extractive question answering, where a is always a consecutive chunk of text in p.",
      "startOffset" : 51,
      "endOffset" : 75
    }, {
      "referenceID" : 4,
      "context" : "Given the paragraph p, we apply a bidirectional Gated Recurrent Unit (GRU) network (Chung et al., 2014) on top of the embeddings of the sequence (p1, p2, · · · , pT ), and obtain the initial paragraph representation Hp.",
      "startOffset" : 83,
      "endOffset" : 103
    }, {
      "referenceID" : 6,
      "context" : "The question and paragraph representations are combined with the gated-attention (GA) mechanism (Dhingra et al., 2016).",
      "startOffset" : 96,
      "endOffset" : 118
    }, {
      "referenceID" : 39,
      "context" : "max layers on top of Hp to predict the start and end indices of a, following Yang et al. (2017).",
      "startOffset" : 77,
      "endOffset" : 96
    }, {
      "referenceID" : 16,
      "context" : "Following a practice in domain adaptation (Johnson et al., 2016; Chu et al., 2017), we append the",
      "startOffset" : 42,
      "endOffset" : 82
    }, {
      "referenceID" : 3,
      "context" : "Following a practice in domain adaptation (Johnson et al., 2016; Chu et al., 2017), we append the",
      "startOffset" : 42,
      "endOffset" : 82
    }, {
      "referenceID" : 27,
      "context" : "We implement the generative model as a sequence-tosequence model (Sutskever et al., 2014) with a copy mechanism (Gu et al.",
      "startOffset" : 65,
      "endOffset" : 89
    }, {
      "referenceID" : 13,
      "context" : ", 2014) with a copy mechanism (Gu et al., 2016; Gulcehre et al., 2016).",
      "startOffset" : 30,
      "endOffset" : 70
    }, {
      "referenceID" : 14,
      "context" : ", 2014) with a copy mechanism (Gu et al., 2016; Gulcehre et al., 2016).",
      "startOffset" : 30,
      "endOffset" : 70
    }, {
      "referenceID" : 13,
      "context" : "Both pvocab and pcopy are defined as a function of the current hidden state ht and the attention results (Gu et al., 2016).",
      "startOffset" : 105,
      "endOffset" : 122
    }, {
      "referenceID" : 11,
      "context" : "Similar to the Generative Adversarial Nets (GANs) (Goodfellow et al., 2014) and adversarial domain adaptation (Ganin and Lempitsky, 2014), the discriminative model and the generative model have different objectives in our framework.",
      "startOffset" : 50,
      "endOffset" : 75
    }, {
      "referenceID" : 8,
      "context" : ", 2014) and adversarial domain adaptation (Ganin and Lempitsky, 2014), the discriminative model and the generative model have different objectives in our framework.",
      "startOffset" : 42,
      "endOffset" : 69
    }, {
      "referenceID" : 11,
      "context" : "However, rather than formulating the objective as an adversarial game between the two models (Goodfellow et al., 2014; Ganin and Lempitsky, 2014), in our framework, the discriminative model relies on the data generated by the generative model, while the generative model aims to match the model-generated data distribu-",
      "startOffset" : 93,
      "endOffset" : 145
    }, {
      "referenceID" : 8,
      "context" : "However, rather than formulating the objective as an adversarial game between the two models (Goodfellow et al., 2014; Ganin and Lempitsky, 2014), in our framework, the discriminative model relies on the data generated by the generative model, while the generative model aims to match the model-generated data distribu-",
      "startOffset" : 93,
      "endOffset" : 145
    }, {
      "referenceID" : 37,
      "context" : "Similar to the dual learning (Xia et al., 2016) framework, one can define an autoencoder objective.",
      "startOffset" : 29,
      "endOffset" : 47
    }, {
      "referenceID" : 32,
      "context" : "plete representation of the answers (Vincent et al., 2010).",
      "startOffset" : 36,
      "endOffset" : 58
    }, {
      "referenceID" : 36,
      "context" : "Since the output of G is discrete and non-differentiable, we use the Reinforce algorithm (Williams, 1992) to update G.",
      "startOffset" : 89,
      "endOffset" : 105
    }, {
      "referenceID" : 22,
      "context" : ", “Date”, “Other Numeric”, “Person”, “Location”, “Other Entity”, “Common Noun Phrase”, “Adjective Phrase”, “Verb Phrase”, “Clause” and “Other” (Rajpurkar et al., 2016).",
      "startOffset" : 143,
      "endOffset" : 167
    }, {
      "referenceID" : 28,
      "context" : "For each paragraph from the unlabeled articles, we utilize Stanford Part-Of-Speech (POS) tagger (Toutanova et al., 2003) to label each word with the corresponding POS tag, and implement a simple constituency parser to extract the noun phrase, verb phrase, adjective and clause based on a small set of constituency grammars.",
      "startOffset" : 96,
      "endOffset" : 120
    }, {
      "referenceID" : 7,
      "context" : "Next, we use Stanford Named Entity Recognizer (NER) (Finkel et al., 2005) to assign each word with one of the seven labels, i.",
      "startOffset" : 52,
      "endOffset" : 73
    }, {
      "referenceID" : 22,
      "context" : "We tune the hyper-parameters and perform early stopping on the development set using the F1 scores, and the performance is evaluated on the test set using both F1 scores and exact matching (EM) scores (Rajpurkar et al., 2016).",
      "startOffset" : 201,
      "endOffset" : 225
    }, {
      "referenceID" : 8,
      "context" : "Gen + GAN refers to the domain adaptation method using GANs (Ganin and Lempitsky, 2014); in contrast to the original work, the generative model is updated using Reinforce.",
      "startOffset" : 60,
      "endOffset" : 87
    }, {
      "referenceID" : 37,
      "context" : "Gen + dual refers to the dual learning method (Xia et al., 2016).",
      "startOffset" : 46,
      "endOffset" : 64
    }, {
      "referenceID" : 8,
      "context" : "We use our own implementation of “Gen + GAN” and “Gen + dual”, since the GAN model (Ganin and Lempitsky, 2014) does not handle discrete features and the dual learning model (Xia et al.",
      "startOffset" : 83,
      "endOffset" : 110
    }, {
      "referenceID" : 37,
      "context" : "We use our own implementation of “Gen + GAN” and “Gen + dual”, since the GAN model (Ganin and Lempitsky, 2014) does not handle discrete features and the dual learning model (Xia et al., 2016) cannot be directly applied to question",
      "startOffset" : 173,
      "endOffset" : 191
    }, {
      "referenceID" : 8,
      "context" : "When implementing these two baselines, we adopt the learning schedule introduced by Ganin and Lempitsky (2014), i.",
      "startOffset" : 84,
      "endOffset" : 111
    }, {
      "referenceID" : 22,
      "context" : "We report two metrics, the F1 scores and the exact matching (EM) scores (Rajpurkar et al., 2016), on the test set.",
      "startOffset" : 72,
      "endOffset" : 96
    }, {
      "referenceID" : 43,
      "context" : "Semi-supervised learning has been extensively studied in literature (Zhu, 2005).",
      "startOffset" : 68,
      "endOffset" : 79
    }, {
      "referenceID" : 18,
      "context" : "been recently proposed for semi-supervised learning based on representation learning techniques, such as generative models (Kingma et al., 2014), ladder networks (Rasmus et al.",
      "startOffset" : 123,
      "endOffset" : 144
    }, {
      "referenceID" : 23,
      "context" : ", 2014), ladder networks (Rasmus et al., 2015) and graph embeddings (Yang et al.",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 40,
      "context" : ", 2015) and graph embeddings (Yang et al., 2016a).",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 44,
      "context" : "Moreover, traditional graph-based semisupervised learning (Zhu and Ghahramani, 2002) cannot be easily extended to modeling the unlabeled answer chunks.",
      "startOffset" : 58,
      "endOffset" : 84
    }, {
      "referenceID" : 8,
      "context" : "Domain adaptation has been successfully applied to various tasks, such as classification (Ganin and Lempitsky, 2014) and machine translation (Johnson et al.",
      "startOffset" : 89,
      "endOffset" : 116
    }, {
      "referenceID" : 16,
      "context" : "Domain adaptation has been successfully applied to various tasks, such as classification (Ganin and Lempitsky, 2014) and machine translation (Johnson et al., 2016; Chu et al., 2017).",
      "startOffset" : 141,
      "endOffset" : 181
    }, {
      "referenceID" : 3,
      "context" : "Domain adaptation has been successfully applied to various tasks, such as classification (Ganin and Lempitsky, 2014) and machine translation (Johnson et al., 2016; Chu et al., 2017).",
      "startOffset" : 141,
      "endOffset" : 181
    }, {
      "referenceID" : 9,
      "context" : "tation (Glorot et al., 2011) focus on learning distribution invariant features by sharing the intermediate representations for downstream tasks.",
      "startOffset" : 7,
      "endOffset" : 28
    }, {
      "referenceID" : 19,
      "context" : "Another line of research on domain adaptation attempt to match the distance between different domain distributions in a low dimensional space (Long et al., 2015; Baktashmotlagh et al., 2013).",
      "startOffset" : 142,
      "endOffset" : 190
    }, {
      "referenceID" : 0,
      "context" : "Another line of research on domain adaptation attempt to match the distance between different domain distributions in a low dimensional space (Long et al., 2015; Baktashmotlagh et al., 2013).",
      "startOffset" : 142,
      "endOffset" : 190
    }, {
      "referenceID" : 11,
      "context" : "2012; Gopalan et al., 2011; Pan et al., 2011). Our work gets inspiration from a practice in Johnson et al. (2016) and Chu et al.",
      "startOffset" : 6,
      "endOffset" : 114
    }, {
      "referenceID" : 3,
      "context" : "(2016) and Chu et al. (2017) based on appending domain tags.",
      "startOffset" : 11,
      "endOffset" : 29
    }, {
      "referenceID" : 11,
      "context" : "GANs (Goodfellow et al., 2014) formulated a adversarial game between a discriminative model and a gener-",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 8,
      "context" : "Ganin and Lempitsky (Ganin and Lempitsky, 2014) employed a similar idea to use two models for domain adaptation.",
      "startOffset" : 20,
      "endOffset" : 47
    }, {
      "referenceID" : 42,
      "context" : "Review networks (Yang et al., 2016b) employ a discriminative model as a regularizer for training a generative model.",
      "startOffset" : 16,
      "endOffset" : 36
    }, {
      "referenceID" : 31,
      "context" : "text of machine translation, given a language pair, various recent work studied jointly training models to learn the mappings in both directions (Tu et al., 2016; Xia et al., 2016).",
      "startOffset" : 145,
      "endOffset" : 180
    }, {
      "referenceID" : 37,
      "context" : "text of machine translation, given a language pair, various recent work studied jointly training models to learn the mappings in both directions (Tu et al., 2016; Xia et al., 2016).",
      "startOffset" : 145,
      "endOffset" : 180
    } ],
    "year" : 2017,
    "abstractText" : "We study the problem of semi-supervised question answering—-utilizing unlabeled text to boost the performance of question answering models. We propose a novel training framework, the Generative Domain-Adaptive Nets. In this framework, we train a generative model to generate questions based on the unlabeled text, and combine model-generated questions with human-generated questions for training question answering models. We develop novel domain adaptation algorithms, based on reinforcement learning, to alleviate the discrepancy between the modelgenerated data distribution and the humangenerated data distribution. Experiments show that our proposed framework obtains substantial improvement from unlabeled text.",
    "creator" : "LaTeX with hyperref package"
  }
}