{
  "name" : "1301.2308.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Tractable POMDP for a Class of Sequencing Problems",
    "authors" : [ "Paat Rusmevichientong", "Benjamin Van Roy" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "We consider a partially observable Markov decision problem (POMDP) that models a class of sequencing problems. Although POMDPs are typically intractable, our for mulation admits tractable solution. Instead of maintaining a value function over a high dimensional set of belief states, we reduce the state space to one of smaller dimension, in which grid-based dynamic programming techniques are effective. We develop an er ror bound for the resulting approximation, and discuss an application of the model to a problem in targeted advertising.\n1 Introduction\nMotivated by a problem in targeted advertising, we consider a partially observable Markov decision prob lem that models a customer's responses to different products that are presented during a marketing cam paign. In our model, a customer's responses are de pendent random variables, but are assumed to be con ditionally independent given another random variable X, which can be interpreted as the profile of the cus tomer. The \"profile\" can consist of both known and unknown characteristics that influence a purchasing decision, e.g. age, gender, or income.\nStarting with a prior distribution of X, which rep resents initial beliefs, our model maintains a belief state over a customer's profile. As information is acquired through interaction with the customer, be liefs are updated by computing posterior distributions, which then guide presentation of additional products.\nOur formulation constitutes a specialized class of partially observable Markov decision problems (POMDPs). POMDPs are generally intractable [4], and their intractability has motivated the development\nof approximation methods. It is well known that a POMDP can be viewed as a fully observable Markov decision problem (MDP), for which the state of the MDP corresponds to the posterior distribution over states of the POMDP [1]. Lovejoy [3] has proposed a method that approximates the value function over a grid of points in the space of posterior distributions. A grid is formed; then, an upper and a lower bound for the value function are computed. A policy is gen erated based on the lower bound. The difference in the performance between this policy and that of the opti mal policy is bounded by the gap between the upper and lower approximations. Unfortunately, the number of grid points required for an effective approximation typically grows exponentially in the number of states of the POMDP.\nAs we will show in this paper, under a further as sumption on the form of probabilistic relationships be tween customer profile and behavior, an approximate solution to the class of POMDPs we consider can be computed efficiently. In particular, for this class of problems, we offer a grid-based dynamic programming method that entails forming a grid on a lower dimen sional Euclidean space rather than the space of poste rior distributions. The identification of this tractable class ofPOMDPs together with a solution method con stitute the main contribution of this paper.\nThe paper is organized as follows. In the next section, we provide a general problem formulation. Then, in Section 3, we discuss why standard dynamic program ming techniques are computationally too demanding. A class of distributions that admits efficient solution is introduced in Section 4. An effective approximation technique is then developed in Section 5. In Section 6, we consider a possible application of our model to a problem in targeted advertising. Finally, we conclude with a discussion of extensions and future work.\nUAI2001 RUSMEVICHIENTONG & VAN ROY 481\n2 Problem Formulation\nLet X be a random variable taking values in a finite setS with a prior distribution ¢0 satisfying ¢o(x) > 0 for all x E S, and let U be a set of available decisions. The random variable X might correspond to a cus tomer's profile, and U to a set of products that we can present to the customer during a marketing campaign. Let Y be a binary random variable that denotes the customer's response, with Y = 1 if the customer pur chases a product, and zero otherwise. Since customers with different profiles respond to products differently, the probability distribution of Y depends on both the product u E U that is offered and the customer's pro file, and it is given by\nP{Y=1IX=x,U=u}=pu(x), 'VxES,uEU,\nfor some function p,(x). Also, let Qu(x) = 1- Pu(x). If the customer purchases a product u E U, a nonneg ative reward Ru :$ Rmax is obtained. We assume that the process terminates once the cus tomer purchases a product. Thus, a policy 1r = (1r1, 1r2, .. . ) is a sequence of products to be presented to the customer, where 7rt is the product that will be shown at time t in the event that the customer did not purchase the products 1r1, ... , 1ft-l during the previous t - 1 marketing campaigns. The objective is to find a sequence of products 1r = ( 1r1, 1r2, . . . ) that maximizes the expected discounted reward: E� [� 13t-I R(rt, 7re) 1¢0 l , where T� is the first time that the customer purchases a product; Yt is the customer's response to the prod uct 7rt at time t; R(Yt, 7rt) is the reward, given by R�, if Yt = 1 and zero otherwise, and 0 < !3 < 1 is the discount factor. The discount factor !3 can also be in terpreted as the probability that the customer remains engaged in the marketing campaign, given that she was not interested in the product that was just presented to her.\n3 Intractability of Dynamic Programming\nOur POMDP can be converted to a standard Markov decision problem whose states correspond to posterior distributions of X. Let Vs denote the set of probabil ity distributions on S. For any bounded measurable function V : Vs ---> 1R, let TV : Vs ---> 1R be defined by (TV)(¢) ma.x{R,Pu {Y = 11¢}+ uEU\nf3V(F,A>)Pu {Y = Ol¢}}, V¢ E Vs,\nwhere P,{Y = 11¢} denotes the probability that the customer will purchase product u, provided that the posterior distribution of X is ¢. The variable F,¢> denotes the updated posterior distribution given that the product u was not purchased by the customer, and it is defined by\n(Fu¢)(x) = q,Ax)¢(x) , 'Vx E S. L-zES q,(z)¢>(z)\nThe optimal value function V* satisfies the equation: v· =TV*. The standard dynamic programming algorithm gener ates a sequence of functions V0, V1, . • . where\nVt = TVt-t> Vt ;::: 1, with V0 = 0. Because future rewards are discounted, as t increases, vt becomes a good approximation to V*. Since the space of posterior distributions is con tinuous, one might consider a grid-based approxima tion to Vt. It is possible to derive a relationship be tween the number of grid points and the quality of the resulting appraximation, but we will not pursue that here. Rather, we just mention that the number of grid points required for an approximation error to be less than E generally grows exponentially in JSI. Hence, the grid-based approach quickly becomes intractable as lSI increases. Although we have encoded state in terms of pos terior distribution, one may alternatively encode state in terms of the number of times each prod uct has been rejected by the customer. In this case, the state space at time t + 1 is given by { (nr. . . . , n1u1 ) In;;::: 0 Vi, 2:; n; = t } , where n; de notes the number of times that product i was not pur chased by the customer during the previous t market ing campaigns. It is not hard to show that the cardinality of this set is given by ( t rJr� � 1 ) ' which becomes enormous as JUI and t grow.\n4 A Tractable Class of Distributions\nAlthough the general problem is intractable, we will show that for a certain class of distributions, this prob lem can be solved efficiently. This class of distributions satisfies the following assumption:\nAssumption 1 (a) For all u E U,\nK qu(x) =IT !1(\"·1 (x), 'Vx E S,\n1=1 where (u. = ( (u, 1, ... , Cu.,K) is the parameter associ ated with the decision u, and (u,l ;::: 0 for all u E U\n482 RUSMEVICHIENTONG & VAN ROY UAI2001\nand l = 1, . . . , K. The functions fi, ... , fx are map pings from S to (0, 1]. (b) The vectors {ln j; ( -) E 1RISI]i = 1, ... , K} are lin early independent.\nBefore we proceed to the analysis, let us motivate our assumptions. Assumption 1(a) simplifies the form of posterior distributions. If P{X == x]a1, • . • , at } de notes the conditional probability of X given that the customer is not interested in products a1, .. . , at, then\nP{X =x]ab···,at} cPo(x) IT�-1 Qa)x) = t\nZ:zES <Po(z) Or==l qa)z) !/Jo(x) IT�1 !t(x)L�=l <ar.!\nThe posterior distribution is now characterized by a K-dimensional vector (l:r(ar,l,···l:r(a\"'K). Thus, the class of posterior distributions V associated with our problem is given by\nV == {g(·,1)l1 E 1R�, g(xr)= <Po(x)O�lf?l(x) 'VxES} .\n' Z:zEs<Po(z)fi{:,lf?'1(z)' Recall that in the general problem, posterior distribu tions of X lie in a ]$]-dimensional simplex. With As sumption 1(a), the set of posterior distributions can now be identified with 1Rf. Thus, the dimension of our state space is reduced to K, which can be much smaller than ISJ. We assume that for all i, j;(x) > 0 for all x E S. This assumption excludes classes of re sponse functions for which there exists a profile x E S such that q,.(x) = 0 for all u. This unrealistic situation corresponds to a scenario in which customers with a particular profile x will always purchase any product that is offered.\nIn addition to simplifying the form of posterior distri butions, the set of vectors {ln fi} can be interpreted as a basis used to encode the logarithms of the response functions. In particular, Assumption 1(a) implies that for all u E U,\nK ln Qu(x) = L (u,lln fz(x), 'Vx E S.\ni=l\nUsing the fact (u,l ?: 0, the above equation implies that the logarithms of the response functions lie in a pos itive K-dimensional cone generated by {ln J;}. Since {ln fi(-) E �ISI]i = 1, . . . , K} is a linearly indepen dent set of vectors by Assumption 1 (b), by choosing K = JSJ, any response function can be represented\nin the form required by Assumption 1(a). However, in many cases, these response functions should lie in some lower-dimensional subspace, and thus, K can be much smaller than JS[.\n5 A Solution Method and Its Analysis\nIn this section, we will develop an effective approxi mation method for solving the class of POMDPs that satisfies Assumption 1. As we have noted in the pre vious section, the class of posterior distributions 1) as sociated with our problem is\n1J = {g(-,1)b Eat�, g(x 'Y) = ¢o(x) nt:1 f;-\"1 (x) 'Vx E s}. '\nLzES l/Jo(z) n�l J?l (z)' Since 1) can be identified with ��, we can also define a value function on ��. The dynamic programming equation for the optimal value function J* : iRf ...... ar+ can now be written as\nJ*(J) = max{Ru(l- H,.(i)) + f3J*(I + (u)H,.(I)}, uEU (1)\nfor all1 E !l?�, where Hu(r) denotes the probability that the customer will not purchase product u given that the posterior distribution of X is g(·,/), and it is given by\nThe derivation of Equation 1 also makes use of the fact that if g(·,/) E 1) is the posterior distribution of X, then g(·, 1 + (u) is the updated posterior distribution given that the customer rejected product u. To facil itate our discussion, let us introduce some notation. Let B denote the set of bounded measurable functions on iR;:, and define T : B ....,. B as follows (T J) (/)=max {Ru (1- Hu(/)) + (31 (/ + (u) H,.(/)}, uEU for all J E B and 1 E ��. Hence, the optimal value function J* is the fixed point of T, i.e. J* = T J*. Also, let a sequence of functions Io, 11, .. . be defined by Jt = T lt-1, 'Vt?: 1, with J0 = 0. Thus, It denotes the optimal value func tion associated with at-time horizon problem. Before we proceed to the analysis , let us outline the main ideas of our argument. In Section 5.1, we will consider the dynamic programming algorithm for com puting approximations to J*, and show that an error\nUAI2001 AUSMEVICHIENTONG & VAN ROY 483\nbound of the form III*- Itlloo � E can be obtained with t � O(ln(l/E)). This result enables us to fo cus our effort on finding good approximations to It. Since the domain of It is ��, which is unbounded, it is unreasonable to expect a uniformly accurate ap proximation. Instead, we will only require that our approximation is good over an appropriatel y bounded region.\nThen, in Section 5.2, we will prove that the function Hu is Lipschitz continuous, and as a corollary, that the value function It is also Lipschitz continuous. This re sult motivates grid-based approximations to the value function. In Section 5.3, we define a grid and the cor responding approximation, and show that the perfor mance of the resulting policy is near optimal. Our main result establishes that an E-optimal policy can be generated using 0 ( ( � ln �) K) grid points. 5.1 Dynamic Programming\nIn this section, we study the dynamic programming algorithm for computing approximations to the value function I*. This method is motivated by the follow ing result whose proof follows immediately from the contraction mapping property ofT, and the fact that J*(;) � Rma.x for all1 E ��. Lemma 1 For all t,\nLet n(E) be defined by\n( ) _ r ln Rmax + ln � 1\nn E - 1 • ln i3\nIt follows from the above lemma that J!J*- In{•) JJoo � E. Thus, it suffices to find good approximations to Jn(•}· If Jn(•} denotes an approximation to In{•)• ideally, we would like the error II In(•} - Jn(•) II 00 to be small. However, the domain of In(<) is an unbounded set ��, so finding an approximation that is uniformly accurate may not be possible.\nThus, we will consider an alternative metric that ex ploits a special feature of our problem formulation. To facilitate our discussion, let (* be defined by\n(* = max (u,l, uEU,I=l, ... ,K and for any positive integer n, let\nRecall that in our formulation, we start with a prior distribution ¢0 of X, which corresponds to 1 = 0 E\n��. In addition, it follows from Equation 1 that, at each time period, the value of 1 can be incremented by at most (*. Since In(<) corresponds to the optimal value function for a n( E)-time horizon problem, the \"effective domain\" of In(<) starting at 1 = 0- the set of possible values of 1 at time n(e:) - is given by f n(<}· Therefore, it is natural to restrict the requirement on our approximation to reflect accuracy only over this domain. This motivates the following metric: for any G r:;;_ ��,IE B, let\n11 11� =sup I (r)l. -yEG\nNote that 11 11� � II IIoo for all I E B. Our goal is to find an approximation Jn(•) to In(•) such that the\nII - llr n(•) error In(•) - Jn(•} 00 is small. 5.2 Lipschitz Condition\nIn this section, we will show that the function Hu is Lipschitz continuous. This result will enable us to bound error resulting from our approximations. Be fore we proceed to the statement of this result, let us introduce some notation. Let M :2: 0 be defined by\nM Kmax (max qu (x) - min qu(x)) uEU xES xES x . max (maxlnf;(x)- minlnh(x)).\nt=l, ... ,K xES xES\nWe then have the following result.\nLemma 2 For all1, \"(1 E ��,\nfor all u E U.\nThe proof of Lemma 2 makes use of the following result which bounds the derivative of Hu. Since the proof of this result consists of simple algebraic manipulations, we refer the reader to our full-length paper for more details.\nLemma 3 For all u E U, f) -8 Hu(/1, . . ·, 'YK) /i\n= E-y [qu(X)ln/;(X)]- E-y [qu(X)] E-y [ln/;(X)] = Cov-y (qu(X),ln/;(X))\nwhere E-y[·] denotes the expectation with respect to the density g(·, 1) defined by\n() rfio(x)[I{:1f?1(x) g X,\"' = \"\"\"' A. ( ) IlK j'YI ( ) ' LJZES 'f'O Z l=l ! Z Vx E S.\n484 RUSMEVICHIENTONG & VAN ROY UAI2001\nMoreover, for all u E U,\nII('VHu)(r)llt:::; M, \\11 E ��-\nHere is the proof of Lemma 2. Proof: Using a standard result that for all/, r' E �!,\nIHu(r)-Hub')l :::; sup II('VHu)(r+o(r'-r))lltllr-r'lloo' oE (O,t)\nit follows from Lemma 3 that IHu(r)- Hu(r')l ::; Mllr-r'lloo· • From the Lipschitz condition of Hu, we can also prove that the value function It is Lipschitz continuous. This result is stated in the following corollary. Due to the space constraint, the reader is referred to our full length paper for the proof.\nCorollary 1 For all r, 1' E ��,\nI ( ) _ 1 ( ')I < (1 + f3)RmaxM II _ 'II tr tr - 1-,8 r r oo' for all t ;::: 0.\n5.3 Approximate Value Function\nCorollary 1 motivates grid-based dynamic program ming techniques. Let h E (0, 1] be a scalar that pa rameterizes the coarseness of our discretization; we call h the \"grid spacing\". We start by partitioning the nonnegative half-line �+ into a collection Ih of dis joint subsets. In particular, Th consists of sets of the form [ih, ( i + 1) h) for i = 0, 1, 2, .. . . We then partition [0, 1)K into a collection If! of subsets defined by\nIf!= {It X ... X hll; E .rh}. For any r E ��, if\nr E [ith, (it+ 1)h) X · · · X [iKh, (iK + 1)h), for some i1, .. . ,iK, then let i'h = (ith, . . . ,iKh). We will use .:Yh as an approximation to I·\nThus, we only need to define our approximate value functions on subsets of r 2n(•l. So, let a sequence of . . -h -h -h approximate value f unctwns ]0, .. . , Jn(<)' where Jt : r2n(<)-t --4 �+,be defined by\nwith J[; = 0. The following theorem shows that our approximate value function is close to the true value function. The proof of this theorem will be given in Section 5.4.\nTheorem 1 For all t::; n(E), II] _ Jhllr2n(<)-t < (1 + ,B)RmaxM h t t DO - (1 _ ,8)2 • The above result suggests that the performance of a greedy policy generated from the approximate value function should also be close to optimal. Our ap-\n. t l\" ' h { ' h ' h } h 'h proxtma e po 1cy J1 = Jlt, .. . , Jln(<) , w ere Jlt : f2n(•)-t ___. U, is defined by �h -h TMJt-1 = T Jt-1, Vt;::: 1, where for any decision rule Jl, Tf.' is defined by\nRl-'hl (1- HJ.<(rkr)) + ,BJ (r + (p(rJ) Hl-'lrl(r),\nfor all J E B and 1 E ��. If J� denotes the expected reward for a t-time horizon problem under the policy p,h, then J� satisfies the following equation:\n'h 'h Jt = Tp.7lt-1• Vt;::: 1, with J[; = 0. The following theorem asserts that the performance of our greedy policy is close to the optimal performance.\nTheorem 2 For all t :::; n( E) ,\nIIJ _ J\"llr2n(<l-• < 2,8(1 + ,B)RmaxM h t t 00 - (1 - ,8)3 We are now ready to define our approximation. Let The proof of Theorem 2 makes use of the following jh: B ___. B be defined by lemma which shows that the operators T, Th, and Tl-' are contraction mappings. This lemma follows imme {'ThJ)(J) = max{Ru(l-H..,(7h)) +{31fth +(u)Hu(i'h)} diately from the definition of these operators, and we uEU \"t h f for all J E B and r E �!. We should note that in order to compute the function f'h J, it suffices to compute f'h J only at the grid points. Since we are only interested in approximating In(•) on the set r n(<), the maximal value of r that we need to consider is\nn(<)-1 (*n(t:) + L (* = 2(.n(t:).\ni=O\nom1 t e proo .\nLemma 4 For any Gt,G2 E B, and J1: ��-> U,\nIITJ.<Gl-TpGzll� for all n :2': 0.\n< ,B IIGl-G2ll�+l' < ,B IIGl- G2ll�+l\nUAI2001 RUSMEVICHIENTONG & VAN ROY 485\nHere is the proof of Theorem 2. Proof; For any t ::; n(t),\n<\n+\n+\nBy definition of fl?, we have -h -h Tf<�It-1 = T It-1>\nwhich implies that\nwhere the inequality follows from Lemma 4. Similarly, Lemma 4 implies that\nThe above corollary shows that in order for our ap proximation to be within 2t of the optimal value func tion, we need to approximate In(<) using a grid spacing of h = t(l- (3)3 2(3(1 + (J)RmaxM. Since our approximate value functions are defined on subsets of r 2n(<), the maximum number of grid points is of order\nwhere the equality follows from the definition of n(t), and we have ignored the constants Rmax and (3 since these two variables generally do not scale with the problem size. Let us first note the dependence of the number of grid points on the error tolerance E. Note that\n�In�= 0 (�), E E tP\nII -h llr2,<•J-t j -h llr2 .. (•J-t+t for all p > 1. Since any other grid-based approxi-TMit-1- Tp.�lt-1 00 ::; f3 It-1- It-1 DO ' mation method would require at least 0((1/t)K) grid points, the number of grid points used by our approx imation method is comparable to even the best grid-and 11 'h 11r2n<•J-• 11 'h llr2 .. (•J-•+' based approximation technique. Tp.hlt-1- Tp.hi1_1 ::; (3 It-1- 11_1 . ' ' oo DO Let us now consider the dependence of the number of Hence, it follows from Theorem 1 that grid points on the constant M. Recall that\nSince lo = Jt; = 0, the above recursion implies that\nII 'hllr2n(•J-• 2(3(1 + (J)RmaxM I -I < h t t 00 - (1 - (3)3 for all t. Since\n1\\J*- 1�(,)\\C(·J ::; II I* - In(<) �� (<) + II In(<) - j�(<) IC(<) ::; JJI*- In(•) II=+ ll1n<•)- 1�c,JIC(·),\n•\nthe following corollary follows immediately from Lemma 1 and Theorem 2.\nCorollary 2\nIIJ* _ jh llrn(<J < 2(3(1 + fJ)RmaxM h n(E) oo - f + (1 - (3)3\nwhere\nand\nC1 = Kmax (maxqu(x)- minqu(x)) , uEU xES xES\nc2 =.max (maxln/i(x)- minlnfi(x)) . •=1, . . . ,K xES xES The constant C1 represents the maximum variability in the response functions, relative to the number of basis functions K. At first glance, it seems that C1 should increase proportionally with K. This would imply that the number of grid points would quickly become intractable as the problem size increases and we need more basis functions. However, we believe that, in most cases, C1 will remain bounded even when the problem size increases. As an example, consider a situation where\nand\nfi(x)::; a< l, Vx E S, i = 1, . . . ,K,\n( = min (u 1 > 0. - uEU1i=l, ... ,K '\n486 RUSMEVICHIENTONG & VAN ROY UAI2001\nIn that case, K K\nqv.(x) =IT j1(,.,l (x) ::;: ( cS) , 'Vx E S, u E U, 1=1\nwhere 0 < a� < 1. For any function fe : 3t+ --> 3t+, 0 < B < 1, defined by fe(w) = w(}w, 'Vw E �+,\none can verify that\nmax fe(w) = fe(w)lw=log (!) = � loge (�) , wE1R+ o e e e where e denotes the base of the natural logarithm, and log0(') denotes the logarithm with base B. Therefore,\nKmax (maxq,.(x)- minq,.(x)) :::; � log , (�), uEU xES xES e a- e which shows that cl is bounded above by a constant that does not increase with K. The constant C2 denotes the variability in our basis functions {lnf;}. From Assumption l(a), we have\nK ln q,.(x) = L (v.,!ln !L(x), 'Vx E S, u E U.\n1=1 Thus, the logarithms of our response functions lie in a positive cone generated by {ln fi}· If c2 is large, then our basis functions can represent a larger class of response functions. Hence, the number of required grid points increases proportionally with the represen tation capability of our basis functions. In the extreme case where c2 = 0, fi is a constant function for all i. In that case, the only response functions that can be represented using this basis are the ones where q,.(x) is constant for all x E S. In most cases, we expect that\n/;(x)�8, VxES,i=1, . . . , K, for some 8 > 0. Under this condition, we have\nmax (maxln J;(x)- min lnf;(x)) :::; ln (1/8) , ' xES xES which shows that c2 does not increase with the prob lem size. Finally, let us consider the dependence of the number of grid points on the constant (*, which was defined in Section 5.1 as\n(* = max (u,l· uEU,l=1, ... ,K\nWe believe that, in most cases, (* will remain bounded even when the problem size increases and more prod ucts are considered. As an example, consider a situa tion where\n0 < v::;: qu(x), 'Vx E S, u E U.\nUnder this condition, if(* = (u•,t• for some u• E U and l* E {1, . . . , K}, then\nv:::; q,..(x) = f1�· (x) IT f1(,.•,1(x), 'Vx E S, l;tfl•\nwhich implies that\n(* < l nv- 2:::1,..1• (u• , t ln ft (x) < ln(1/v) . - lnft·(x) - ln(1/fz.(x))\nFrom our discussion on the scalability of the constant C1, we expect that ft(x) :::; a < 1, 'Vx E S, l = 1, . .. , K., which implies that\n(* < In (1/v). - ln (1/a)\nThe above inequality shows that (* does not increase with the problem size.\n5.4 Proof of Theorem 1\nProof\" For any t :5 n(c:),\nIt follows from the definition of Jt and ]f that IJt(/)- Jt(l)l = lcr Jt-dh)- cr\"Jt_d(!)l :::; max {Ru IHu(/)- Hu('Yh)l +\nuEU\nf31Jt-1 (I'+ (u)Hu('y) - Jt-1 ( 'Yh + (u) H,. ( 'Yh) I } $max {RmaxMih'- 'Yhlloo + uEU f31Jt-1b + (v.)H,.('y)- jth-l('Yh + (,)H,(ih)l }\nwhere the last inequality follows from Lemma 2. How ever,\nIJt-1 (r + (,.)Hu (/) - Jt-1 ( 'Yh + (u )Hu( 'Yh) I :::; Jt-1 (/ + (u) IH,.('Y) - H,( 'Yh) I +\nH,.(..Yh) IJt-lh + (,.)- Jt-l('Yh +(,)I+ Hu( 'Yh) I Jt-1 hh + (,.) - Jt-1 ('Yh + (u) I\n:::; RmaxMib- 'Yhlloo + (1 + {3)RmaxM\nII _ , II + 1 _ f3 I lh oo IJt-l(i'h +(u)- jth-1('Yh +(u)/\n< 2RmaxM II _ , II + _ l _ f3 I lh oo\nIIJt-1Jt-111:\"(<}-t+l,\nUA12001 RUSMEVICHIENTONG & VAN ROY 487\nwhere the next to last inequality follows from Lemma 2 and Corollary 1, along the fact that lt-tb) :::; Rmax and Hub) :::; 1 for all 1 E R�. The last inequality follows from the fact that r E r2n(•)-t and .:Yh S\"; r· Thus, putting everything together and using the fact that Jlr � .:Yh//oo :::; h, we obtain\n< (1 + {3)RmaxM h 1�;3 +!311 lt-1 - ]I:_ �11:\"(')-t+l .\nSince 10 = Jt = 0, the above recursion implies that IIJ - jhllr2n(<)-t < (1 + iJ)RmaxM h t t 00 - (1 - !3)2 ' for all t :::; n (E) .\n6 A Motivating Application\n•\nIn this section, we consider an application of our model to a problem in targeted advertising. Consider a re\ntailer who would like to develop a marketing campaign to attract new customers. Let U denote the set of available products. Assume the we have demographic information and purchase history on our existing cus tomers. Let X1, ... , Xn denote demographic variables that are deemed to be good predictors of a customer's propensity to buy a product. Although we do not have demographic information on new customers that we would like to attract through our marketing campaign, we can exploit the information available in our exist ing database. For instance, we might assume that the demographic characteristics of the population that is targeted by our campaign has the same distribution as that of our previous customers.\nLet us assume without loss of generality that the Xi's are binary variables. We can think of X = (X 1, . . . , X n) as a random variable that represents a customer's profile. Then, this problem falls within the framework of our model. In this case, the set S of possible values of X has cardinality 2n. Thus, a so lution via dynamic programming requires us to com pute a value function over a 2n-dimensional space of belief states, which quickly becomes intractable as n increases.\nHowever, if the probability that a customer will pur chase a product given her demographic characteristics exhibits a noisy-OR structure [5], then this problem becomes tractable. The noisy-OR structure assumes that different demographic factors independently act to influence a customer's purchasing decision. This form of conditional independence has been used suc cessfully to model problems, for example, in medical\ndiagnosis [2]. The noisy-OR model leads to a function of the form\nn\nqu(x) = II(l-dl)x!(o.,l, Yx E {O,l}n. l=l\nThe parameter d1 can be interpreted as the base line probability that the demographic characteristic xl leads the customer to purchase an arbitrary product, and the parameter (u,l represents the deviation from the baseline probability associated with the product u E U. As (u,l decreases, the probability that the de mographic characteristic xl will lead the customer to purchase product u also decreases.\nNote that the response function takes the form re quired by Assumption l(a). Thus, this problem can be solved using a grid on an n-dimensional space. This offers a significant reduction in the amount of compu tation since the dimension of the state space is reduced from 2n ton.\n7 Conclusion\nWe studied a POMDP that models a class of sequenc ing problems. Although the general problem is in tractable, we show that for a certain class of distri butions, the problem can be solved efficiently. Our current research focuses on extending the results to broader classes of problems. We also hope to further explore applications of the model developed in this pa per.\nAcknowledgments\nThis research was supported by NSF CAREER Grant ECS-9985229, by the ONR under Grant MURI N00014-00-l-0637, and by a Stanford Graduate Fel lowship.\nReferences\n[1] D. Bertsekas, Dynamic Programming and Optimal Control, vol. 1. Belmont, MA: Athena Scientific, 1995.\n[2] D. Heckerman, \"A Tractable Inference Algorithm for Diagnosing Multiple Diseases,\" Uncertainty in Artifi cial Intelligence 5, pp. 163-171, 1990.\n[3] W. S. Lovejoy, \"Computationally Feasible Bounds for Partially Observed Markov Decision Processes,\" Op erations Research, 39, 1, pp. 162-175.\n[4] C. H. Papadimitriou, and J. N. Tsitsiklis, \"The Com plexity of Markov Decision Processes,\" Mathematics of Operations Research, 12, 3, pp. 441-450, August 1987.\n[5] J. Pearl, Probabilistic Reasoning in Intelligent Sys tems: Networks of Plausible Inference. San Mateo, CA: Morgan Kaufmann, 1988."
    } ],
    "references" : [ {
      "title" : "Dynamic Programming and Optimal Control, vol",
      "author" : [ "D. Bertsekas" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1995
    }, {
      "title" : "A Tractable Inference Algorithm for Diagnosing Multiple Diseases",
      "author" : [ "D. Heckerman" ],
      "venue" : "Uncertainty in Artifi­ cial Intelligence 5, pp. 163-171, 1990.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "Computationally Feasible Bounds for Partially Observed Markov Decision Processes",
      "author" : [ "W.S. Lovejoy" ],
      "venue" : "Op­ erations Research, 39, 1, pp. 162-175.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 0
    }, {
      "title" : "The Com­ plexity of Markov Decision Processes",
      "author" : [ "C.H. Papadimitriou", "J.N. Tsitsiklis" ],
      "venue" : "Mathematics of Operations Research, 12, 3, pp. 441-450, August 1987.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1987
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Sys­ tems: Networks of Plausible Inference",
      "author" : [ "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1988
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "POMDPs are generally intractable [4], and their intractability has motivated the development of approximation methods.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 0,
      "context" : "It is well known that a POMDP can be viewed as a fully observable Markov decision problem (MDP), for which the state of the MDP corresponds to the posterior distribution over states of the POMDP [1].",
      "startOffset" : 195,
      "endOffset" : 198
    }, {
      "referenceID" : 2,
      "context" : "Lovejoy [3] has proposed a method that approximates the value function over a grid of points in the space of posterior distributions.",
      "startOffset" : 8,
      "endOffset" : 11
    }, {
      "referenceID" : 4,
      "context" : "However, if the probability that a customer will pur­ chase a product given her demographic characteristics exhibits a noisy-OR structure [5], then this problem becomes tractable.",
      "startOffset" : 138,
      "endOffset" : 141
    }, {
      "referenceID" : 1,
      "context" : "This form of conditional independence has been used suc­ cessfully to model problems, for example, in medical diagnosis [2].",
      "startOffset" : 120,
      "endOffset" : 123
    } ],
    "year" : 2011,
    "abstractText" : "We consider a partially observable Markov decision problem (POMDP) that models a class of sequencing problems. Although POMDPs are typically intractable, our for­ mulation admits tractable solution. Instead of maintaining a value function over a high­ dimensional set of belief states, we reduce the state space to one of smaller dimension, in which grid-based dynamic programming techniques are effective. We develop an er­ ror bound for the resulting approximation, and discuss an application of the model to a problem in targeted advertising.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}