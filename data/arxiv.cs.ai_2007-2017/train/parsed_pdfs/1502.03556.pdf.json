{
  "name" : "1502.03556.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "INSTANCE MATCHINGTECHNIQUE", "Md. Hanif Seddiqui", "Rudra Pratap Deb Nath", "Masaki Aono" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "DOI : 10.5121/ijwest.2015.6101 01\nThe proliferation of heterogeneous data sources of semantic knowledge base intensifies the need of an automatic instance matching technique. However, the efficiency of instance matching is often influenced by the weight of a property associated to instances. Automatic weight generation is a non-trivial, however an important task in instance matching technique. Therefore, identifying an appropriate metric for generating weight for a property automatically is nevertheless a formidable task. In this paper, we investigate an approach of generating weights automatically by considering hypotheses: (1) the weight of a property is directly proportional to the ratio of the number of its distinct values to the number of instances contain the property, and (2) the weight is also proportional to the ratio of the number of distinct values of a property to the number of instances in a training dataset. The basic intuition behind the use of our approach is the classical theory of information content that infrequent words are more informative than frequent ones. Our mathematical model derives a metric for generating property weights automatically, which is applied in instance matching system to produce re-conciliated instances efficiently. Our experiments and evaluations show the effectiveness of our proposed metric of automatic weight generation for properties in an instance matching technique.\nKEYWORDS Instance Matching, Automatic Property Weight, Semantic Integration, Identity Recognition, Record Linkage"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "With the rapid growth of diversified heterogeneous semantically linked data, often called as instances, instance matching becomes a key factor to reconcile the data. In semantic web, instances of people, places and things, are connected by means of concepts, properties and their instantiation in domain ontologies. However, ontologies in a same domain are often defined differently by different creators influenced by their interest, social behaviours and after all due to their different needs. That imposes a challenge to reconcile instances to integrate information of semantic knowledge bases.\nA semantic knowledge base contains assertion about instances of two disjoint sets called “concepts”, C and “relations”, R which is technically called as property in Resource Description Framework (RDF) [1] and in Web Ontology Language (OWL) [2]. The semantic knowledge base is defined in [3] as follows:\nKB=(C,R,I, ιC , ιR) (1)\nWith the definition of the knowledge base, we find that it consists of two disjoint sets C and R as defined before, a set I whose elements are called instance identifiers, a function, ιC: C→ℜ(I) called concept instantiation and a function ιR: R→ℜ(I2) with ιR(r)⊆ ιC(dom(r)) x ιC(ran(r)), for all r∈R. The function ιR is called relation instantiation.\nCurrently a large number of ontology instances are available in semantic knowledge bases: AllegroGraph1 [4] contains more than one trillion triples, a basic building block of Semantic Web formed as <subject> <predicate> and <object>, Linked Open Data (LOD) [5] contains more than fifty billion triples and there are more other knowledge bases too like DBpedia [6], DBLP [7] and so on. Moreover, several individual groups are also working to create billions of triples to represent ontology instances of semantic web. Due to the proliferation of semantically connected instances, automatic instance reconciliation is getting researchers’ attention. The problem of instance reconciliation is often called as instance matching problem.\nOntology instance matching is a relatively new domain for researchers in comparison to record linkage, which has a classical state-of-the-art [8, 9, 10], although there is a close relationship between instance matching to record linkage. Instance matching is an important approach to connect all the islands of instances of semantic web to achieve the interoperability and information integration issues. Instances in knowledge base contain descriptions through a number of properties.\nThe description of instances varies in their natural language based lexicon, in their structure and so on. For example, a person's name is differently described across nations and even in the citation of different publications, and date has also wide variants. Therefore, instance matching becomes a formidable task for measuring the proximity considering different transformations in their descriptions. There are three basic transformations across instances: value transformation, logical transformation and structural transformation. Value transformation focuses on the description variation in their lexicon, while logical transformation is about the typeset variations in terms of ontology concept. However, the structural variation is more challenging as instance functionality varies in terms of ontology properties. To cope with the missing information of instances in different knowledge base is also challenging. In addition, instances from different ontology impose some extra challenges as we need ontology schema alignment before going for instance matching.\nAs in equation 1 of the definition of knowledge base, instances are well defined in terms of properties. Properties are classified into DatatypeProperty, where the range of the property is a literal and ObjectProperty, where the range of the property is another instance. An instance may be defined by instantiating properties from a few numbers to hundreds of them. Every property may have different impact on their associated instances. This imposes additional challenges in instance matching techniques.\nMost of the instance matching research has been focused on the straight forward instance matching problem with different type of transformations. In the contrary, HMatch(I) [11] tried to address automatically detecting property weight. However, it was only focusing on the distinct value based weight generation, which has a negative impact when there are a small number of available instances containing that property. This paper, in fact, addresses the necessity of weight\n1 http://www.franz.com/products/allegrograph/\nof properties, where the authors refer to as featuring properties. Let us give a comprehensive short example. An instance of type “Person” may have property values attached to hasEmail and hasAge properties. Once, two instances have same values for hasEmail property. Both of the instances should be same even if the values against hasAge are different as the data might be captured at different year. Therefore, hasEmail and hasAge have different weight factor. Apparently, hasGender may have different weight factor than hasEmail and hasAge to identify an instance.\nIn [12] authors propose that properties, which have a maximum or an exact cardinality of 1 have a higher impact factor on the matching process. However, it has a fallacy in logic. For instance, a person has exactly one father i.e. the cardinality of hasFather property is one. However, father of all siblings is the same one. Therefore, the system may falsify that two persons are same if they have same value for the property hasFather. So far researches in Ontology Instance Matching (OIM) assigns the weight factor to the property in top down approach i.e. by either analysing the schema of the ontology or manually. However, our effort is to automatically impose the weight by analysing the information of instances which is more convincing and practical.\nWe investigate different factors that affect weight of a property. Eventually we find three factors: the uniqueness of the property values, the number of instances a property contains, and the total number of instances in the knowledge base. Obviously, the uniqueness of property values has the direct relationship with property weight. Combining the three factors we find that property weight is directly proportional to the ratio of the number of distinct values of a property to the number of instances contain that property. This, in turn, depicts that the number of instances contained a property has a negative effect if the number of distinct values is constant. Moreover, property weight is also non-linear proportional to he ratio of the number of distinct values of a property to the number of total instances. This, in turn, gives us message that the total number of instances has a negative effect if the number of distinct values is kept constant; however the total number of instances is increased. Therefore, measuring a straight forward property weight by linear equation may not work properly. Suppose, out of one million instances only ten of them contain birth-date, and unfortunately all of them are unique. In that case, it is not wiser to consider that one million instances must contain unique birth-date. Therefore, we propose a metric combining the factors together to generate relatively effective weight factors.\nIn this regard, we experimented with the proposed metric of property weight generation applied in our previous core instance matching technique [13]. The result depicts that our proposed metric for property weight generation has better impact over instance matching technique.\nOntology instance matching is required to compare different individuals with the goal of recognizing the same real-world objects. In particular, the application of instance matching plays an important role in information integration, identity recognition and in ontology population. Ontology schema matching and instance matching work in each other to facilitate to discovering semantic mappings between possibly distributed and heterogeneous semantic data. Identity recognition is a widely used term in database and emerging topic in the semantic web of detecting whether two different resource descriptions refer to the same real-world entity, namely an individual. Ontology population is evolved by acquiring new semantic descriptions of data extracted from heterogeneous data sources. For this ontology population, instance matching plays a crucial role to correctly perform the insertion activity and to discover a set of semantic mappings between a new incoming instance and the set of instances already stored in an ontology.\nThe rest of the paper is organized as follows. Section 2 compares our idea with other existing related work to articulate a research gap. The factors that affect the property weight are articulated at Section 3 along with some comprehensive examples. Section 4 contains the mathematical explanation of our metric and necessity of the different considerable factors. The detail implementation of our instance matching technique along with our integrated metric to generate property weight factors are described at Section 5. Section 6 includes experiments and evaluation to show the effectiveness of our proposed metric to generate property weight factors to match different instances. Concluded remarks and some future directions of our work are described in Section 7."
    }, {
      "heading" : "2. RELATED WORK",
      "text" : "The rising demand of sharing knowledge, data and information within same or heterogeneous knowledge bases has recently attained a novel attention on issues related to ontology and instance matching. Until now, many researchers have invested their efforts on ontology instance matching to resolve the interoperability issues across heterogeneous sources. In SERIMI [14], instances are matched between a source and target datasets, without prior knowledge of the data, domain or schema of these datasets. However, in the instance matching process, SERIMI does not impose any weights to the properties associated with instances. The weight of each property can be manually specified by a domain expert [15] and [11] or it can be automatically determined through statistical analysis [16], [17], [18]. In HMatch 2.0 [11], each property is associated with a weight ranging from 0 to 1 expressing the capability of the property for the goal of equivocally identifying the individual in the domain of interest. This weight is defined during the featuring properties identification step of the instance matching process. In BOEMIE, property weights are manually defined for the considered domain by taking into account the results of the extraction process from a corpus of (manually) annotated multimedia resources. Nonetheless, manual definition of weight requires involvement of domain experts and the definition of weight may vary among different domains.\nTo discover semantic equivalence between persons in online profiles or otherwise, an appropriate metric is proposed in [12] for weighting the attributes which are syntactically and/or semantically matched. The properties that have a maximum or an exact cardinality of 1 have a higher impact on the likelihood those two particular profiles are semantically equivalent. However, it has a fallacy in logic. For instance, a person has exactly one father i.e. the cardinality of hasFather property is one. However, father of all siblings is the same one. Therefore, the system may falsify that two persons are same if they have same value for the property hasFather.\nA further refinement of the instance matching process is taken into account considering the frequency of each value occurs [16] in the knowledge base. In particular, a pair of matching attribute values will receive a high weight if these values occur with a low frequency within the domain, while they will receive a low weight otherwise.\nRiMOM [19] used several instance matching benchmark data sets to evaluate their systems namely, A-R-S, T-S-D and IIMB. However, for different datasets, their matching strategy is different.\nIn [20] and [21], J. Huber et. al. have proposed CODI: Combinatorial Optimization for Data Integration in where they emphasize on object-properties to determine the instances for which the similarity should be computed. Although object-properties have a strong influence in the matching process, involvement of data-properties in the matching process is also necessary.\nTill date researchers in the domain of ontology instance matching tried to assign the weight factor to the property in a top down manual approach. In this approach, researchers were assigning weight factors to the property either by analysing the schema of the ontology manually or by domain experts arbitrarily. However, our effort is to automatically generate the weight by analysing the information of instances which is more convincing, generic and practical."
    }, {
      "heading" : "3. FACTORS THAT INFLUENCE THE PROPERTY WEIGHT",
      "text" : "We have factorized the property weight considering very classical information theoretic approaches. The basic intuition behind the use of the this approach is that the more probable a concept is of appearing then the less information it conveys, in other words, infrequent words are more informative than frequent ones.\nInformation theoretic approaches are well defined in a couple of research works by [22, 23, 24, 25, 26]. They obtain their needed Information Content (IC) values by statistically analysing corpora. They associate probabilities to each concept in the taxonomy based on word occurrences in a given corpus. The IC value is then obtained by considering the negative log likelihood [24, 27]:\nicres (c) = -log p(c), (2)\nwhere c is any concept and p(c) is the probability of encountering c in a given corpus. [24] was the first to consider the use of this formula, that stems from the work of Shannon [28], for the purpose of semantic similarity judgments.\nMoreover, instances in knowledge base contain values associating with properties. Some properties like name, date-of-birth, and homepage have larger weighting factors than the properties like height, frequency and so on. However, determining the weight factor automatically is a formidable task. Some properties have great influence on identifying instances, while the other has less influence in a semantic knowledge base. For example, an instance of type Person may have property values attached to hasEmail and hasAge properties. Once, two instances have same values for hasEmail property. Both of the instances must be same even if the values against hasAge are different as the data is captured at different year. Therefore, hasEmail and hasAge have different weight factor.\nThe above fact depicts from Equation 2 and we consider that properties with distinct values are having more weight than that of a property with duplicate values. Therefore, duplicate values are influencing weights as a negative factor."
    }, {
      "heading" : "3.1. Influence of Negative Factors",
      "text" : "Our basic hypothesis to identify the influence of a property on instance identification is that a property has higher weight if its values do not repeat in a semantic knowledge base like a primary key in a database repository. Alternatively a property has less weight if it repeats in the knowledge base. As many times the property value repeats, it loses its ability to identify an instance.\nIf a property value repeats, the weight is penalized by a negative probability factor, np defined as a ration of the number of repetition to the number of instances the property belongs to, i.e.\n(3)\nMoreover, the ratio of the property value repetition to the total number of instance has also negative effect on property weight. Primarily, let us consider the fact in the equation below:\n(4)"
    }, {
      "heading" : "3.2. Our Proposed Property Weight Factors",
      "text" : "As described in Subsection 3.1, there are two types of negative factors associated with our automatic weight generation for properties of semantic knowledge base, namely np1 and np2 and they are defined as primarily as follows:\n(5) (6)\nwhere |dup| is the number of value duplication for a property p available throughout the knowledge base and i represents an instance. Moreover, |i ∋ p| represents the total number of instances containing the property, p and |I| represents the total number of instances in the knowledge base.\nThe probability of identifying an instance with p would be denoted as Prob(p)=1-np(p). We consider the probability as the weight of that property. Therefore, we measure the weight of each property of an ontology schema used in a knowledge base as a joint probability and is stated as follows:\nweight (p) = (1.0 − np1 (p)) ∗ (1.0 − np2 (p)), (7)\nwhere np1 and np2 are defined above."
    }, {
      "heading" : "4. MATHEMATICAL EXPLANATION",
      "text" : "The primary equation 7 articulates the impact of negative factors in terms of the number of value repetition of a property. However, our metric concentrates on the reverse of the value repetition, i.e. the number of distinct value of a property available in a knowledge base. The following subsection focuses on the mathematical derivations and reasoning."
    }, {
      "heading" : "4.1. Mathematical Derivations",
      "text" : "Let us start from the joint probability equation 7 for mathematical derivation and to look insight the nature of the equation.\n(8)\nwhere |distinct| is the number of instances that contain distinct values to property p. Although the first term |distinct|2/(|I ∋ p|*|I|) is quite convincing in equation 8, however in the second term (|distinct|*|I ∌ p|)/(|I∋ p|*|I|), we consider that |I ∌ p| has a positive contribution to the weight factor, which is a contradiction. Let us consider that there are 1 million instances as human being in a knowledge base and 10 instances of them are containing date-of-birth property values and unfortunately all of them have a distinct value. This obviously does not guaranty that the rest instances will contain distinct values. On the other hand, it is not also guaranteed that most of them are duplicate value. Therefore, we need a factorization parameter,λ before the second term as a multiplier, which is defined as below:\n(9)\nwhereδ is the empirical threshold and sigmod is a logistic distribution function defined below:\n(10)\nwhere s and μ are two empirical constants as defined to control the distribution as starting closely from 0.5 and ending around 0.95 for the argument parameter (|i ∋ p|)/|I| in our experiment. Although s is a scaling parameter, we define the value of s as 0.2 to set the maximum value of the sigmod function at around 0.95. On the other hand, although μ is a location parameter to set the center of origin, we set the value at 0.1 to achieve the minimum value of the sigmod function at 0.5.\n(11)\nThereafter the equation 8 becomes as:"
    }, {
      "heading" : "4.2. Comprehensive Example",
      "text" : "Let us consider a number of comprehensive examples to understand the equation 11. In equation 11, if we consider that a property, p is densely instantiated among instances, i.e. every instance in the knowledge base contains some values of p, then |i ∌ p| is zero. Hence, the equation 11 becomes:\n(12)\nLet the total number of instance, |I| and the number of instances having distinct values |distinct| of a property, p be constants. In this case, if the number of instances containing p, denoted as |i ∋ p| increases, the possibility of identifying an instance with that property decreases. Because, as the |distinct| remain constants and |i ∋ p| increases, therefore, duplicate values increases, which means probability of identifying an instance decreases and hence weight of the property decreases and vice-versa. This scenario depicts the natural effect and is successfully addressed in equation 11.\nLet the total number of instance, |I| and the number of instances containing property p denoted by |i ∋ p| be constants. In this case, if the number of distinct values denoted as |distinct| increases, the possibility of identifying an instance with that property increases. Therefore, duplicate values decreases, which means probability of identifying an instance increases and hence weight of the property increases and vice-versa. This scenario also depicts the natural effect and is successfully addressed in equation 11.\nLet the number of distinct values, denoted as |distinct| and the number of instances containing property p denoted by |i ∋ p| be constants. In this case, if the total number of instance, denoted as |I| increases, the possibility of identifying an instance with that property decreases as the nonidentifiable instances increase, which means probability of identifying an instance decreases and hence weight of the property decreases and vice-versa. This is also addressed in equation 11.\nIn equation 12, if we consider that a property, p is sparsely instantiated among instances, i.e. some instances in the knowledge base may not contain values of p, then |i ∌ p| is not zero. Hence, the equation 11 remains as it is.\nLet the total number of instance, |I| and the number of instances having distinct values |distinct| of a property, p be constants. In this case, if the number of instances containing p, denoted as |i ∋ p| increases, the possibility of identifying an instance with that property decreases. Because, as the |distinct| remain constants and |i ∋ p| increases, therefore, duplicate values increases, which means probability of identifying an instance decreases and hence weight of the property decreases and vice-versa.\nLet the total number of instance, |I| and the number of instances containing property p denoted by |i ∋ p| be constants. In this case, if the number of distinct values denoted as |distinct| increases, the possibility of identifying an instance with that property increases. Therefore, duplicate values decreases, which means probability of identifying an instance increases and hence weight of the property increases and vice-versa.\nLet the number of distinct values, denoted as |distinct| and the number of instances containing property p denoted by |i∋ p| is constants. In this case, if the total number of instance, denoted as |I| increases, λ * |i ∌ p| increases partly, therefore the possibility of identifying an instance with that property decreases as the non-identifiable instances increase, which means probability of identifying an instance decreases and hence weight of the property decreases and vice-versa. Therefore, it is now obvious that the termλ * |i ∌ p| does not affect the natural behaviour, rather it only reduces the adverse effect of |i ∌ p|."
    }, {
      "heading" : "4.3. Quantity Normalization",
      "text" : "As the number of instances |I|, the number of distinct values of a property p denoted by |distinct|, the number of instances contain property p denoted by |i ∋ p| and the number of instances that does not contain p and is denoted by |i ∌ p| are usually degree of large numbers, therefore we consider using log of the terms in equation to reduce the adverse effect of numbers. Hence, the equation 11 becomes:\n(13)"
    }, {
      "heading" : "5. OUR INSTANCE MATCHING SYSTEM",
      "text" : "Our primitive instance matching system [13, 29] did not get the essence of automatic weight generation. However, we still consider the system as a core of our augmented approach. Our primitive system of instance matching contains: 1. Ontology Alignment Module, 2. Semantic Link Cloud (SLC) Generation module, and 3. Instance Matching Algorithm."
    }, {
      "heading" : "5.1. Ontology Alignment",
      "text" : "A concept is neither complete nor explicit in its own words. Therefore, concepts are organized in a semantic network or taxonomy associated with a number of relations to define them explicitly for avoiding polysemy problem. Our ontology schema matching algorithm [30, 13, 31] takes the essence of the locality of reference by considering the neighbouring concepts and relations to align the entities of ontologies.\nOur algorithm of ontology alignment starts off a seed point called an anchor, where the notion anchor is a pair of “look-alike” concepts from each of two ontologies. Starting off an anchor point our scalable algorithm collects two sets of neighbouring concepts across ontologies. As our algorithm starts off an anchor and explores to the neighbouring concepts, it does not depend much on the sizes of the ontologies. Thus, our algorithm has a salient feature of size independence in aligning ontologies. Our algorithm achieves enhancement in terms of scalability and performance in aligning large ontologies."
    }, {
      "heading" : "5.2. SLC Generation Module",
      "text" : "Semantic Link Cloud (SLC), collection of linked information of an instance is an important step toward the instance matching. Users often describe an instance in different ways and even by different, however, neighbouring concepts of an ontology. This often leads to undetected or misaligned pairs. Collection of semantically linked resources of ABox along with concepts or properties of TBox specifies an instance at sufficient depth to identify instances even at a different location or with quite different label. Therefore, our proposed method collects all the linked information from a particular instance as a reference point. The linked information is defined as the concepts, properties or their values which have a direct relation to the reference instance, and is referred to a semantic link cloud."
    }, {
      "heading" : "5.3. Instance Matching Algorithm",
      "text" : "The strength of our instance matching algorithm depends mainly on the efficiency of generation of SLC, and ontology schema matching.\nThe algorithm in Fig.1 portrays a simple flow of the matching algorithm. For an SLC of an instance is matched against every SLCs of instances of knowledge base (line 1 through 4 in Fig.1) if and only if there is an aligned concepts across Block (ins1.type) and Block (ins2.type) (as there exists a condition at line 5 in Fig.1). Block (concept) is a related concept block and generateSLC(ins, ab) collects an SLC against an instance ins in ABox ab. An SLC usually contains concepts, properties, and their consolidated values. Every value of an SLC is compared with that of another SLC (as of line 6 of Fig.1) by affinity measurement metric to calculate similarity between two SLCs. Once similarity value is greater than the threshold, it is collected as an aligned pair (as stated at line 7 in Fig.1). Finally, the algorithm produces a list of matched instance pairs.\nGiven two individuals i1 and i2 that are instances of the same (or aligned) concept, the instance affinity function IA(i1, i2) → [0, 1] provides a measure of their affinity in the range [0,1]. For each pair of instances, instance affinity, IA is calculated by taking all the properties, their values and other instances of the pair of SLCs into account."
    }, {
      "heading" : "5.4. Automatic Weight in Instance Matching System",
      "text" : "We augmented our system by introducing a primitive automatic weight generation technique [17]. We further improve our primitive automatic weight generation technique with our proposed metric of automatic weight generation [32]. The overall augmented instance matching system is depicted in Fig. 2.\nConsidering weight factor assigned to each of the property automatically, we define the affinity between two SLCs by modified affinity measurement metric as follows:\n(14)\nwhereγ represents the factors for missing property values."
    }, {
      "heading" : "6. PERFORMANCE EVALUATION",
      "text" : "We perform a number of experiments on IIMB data sets of 2009 and 2010 versions and evaluated with evaluation metrics."
    }, {
      "heading" : "6.1. Data sets",
      "text" : "A generated benchmark to test the efficiency of an instance matcher is called as ISLab Instance Matching Benchmark (IIMB)2. The test-bed provides OWL/RDF data about actors, sport persons, and business firms.\nWe have used two different versions of IIMB datasets: 2009 version and 2010 version. In 2009 version, the main directory contains 37 sub-directories and the original ABox and the associated TBox (abox.owl and tbox.owl). The original ABox contains about 222 different instances with a number of associated property values. Each sub-directory contains a modified ABox (abox.owl + tbox.owl) and the corresponding mapping with the instances in the original ABox (refalign.rdf). The benchmark data is divided into four major groups: value transformation (001-010), structural transformation (011-019), logical transformation (020-029) and combination transformation (030- 037) [33].\nThe 2010 edition of IIMB is a collection of OWL ontologies consisting of 29 concepts, 20 object properties, 12 data properties and thousands of individuals divided into 80 test cases. In fact, in IIMB 2010,80 test cases are defined and divided into 4 sets of 20 test cases each. The rest three sets are different implementations of data value, data structure and data semantic transformations, respectively, while the fourth set is obtained by combining together the three kinds of transformations. IIMB 2010 is created by extracting data from Freebase, an open knowledge base that contains information about 11 million real objects including movies, books, TV shows, celebrities, locations, companies and more. The benchmark has been generated in a small version consisting in 363 individuals and in a large version containing 1416 individuals [34]. Here, large version set is considered in evaluation.\nWe perform two independent experiments for our instance matcher by not considering property weight and considering property weight on the IIMB benchmark data set. The consecutive sections contain the corresponding evaluation respectively.\n2 http://islab.dico.unimi.it/iimb/"
    }, {
      "heading" : "6.2. Evaluation Metrics",
      "text" : "In the experiment of instance matching, we have conducted evaluations in terms of precision, recall and f-measure as defined below:\n• Precision, P: It is the ratio of the number of correct discovered aligned pairs to the total number of discovered aligned pairs. • Recall, R: It is defined as the ratio of the number of correct discovered aligned pairs to the total number of correct aligned pairs. • F-Measure: It is a measure to combine precision, P and recall, R as (2 * P * R)/(P+R)."
    }, {
      "heading" : "6.3. Without Weight Factors",
      "text" : "For the first time, an instance matching track was proposed to the participants in the Ontology Alignment Evaluation Initiatives, 20093. Our primitive instance matching algorithm produces results on IIMB datasets of 2009 without considering property weight in OAEI campaign [13]. The result is portrayed at Table 1.\nMoreover, Fig. 3 demonstrates the results of the participants [33] of OAEI-2009 in where AFlood is our instance matcher without considering property weight.\n3 http://oaei.ontologymatching.org/2009/"
    }, {
      "heading" : "6.4. With Primitive Weight Factors",
      "text" : "Our system with primitive weight generation technique of instance matching shows its strength over our basic instance matching system without weight factor [17]. The result is depicted in Table 2."
    }, {
      "heading" : "6.5. Result of Our Proposed System with IIMB-2009 Data Set",
      "text" : "Table 3 shows the results of different transformations when our proposed metric of automatic weight generation is considered. The results depict that the proposed metric of automatic weight generation for properties has a positive impact in instance matching technique.\nTable 3. Instance matching results of different transformations when our proposed metric of automatic weight generation.\nDatasets Transformation Prec. Rec. F-Measure\n001-010 Value transformations 1.00 1.00 1.000\n011-019 Structural transformations 0.91 0.84 0.868\n020-029 Logical transformations 1.00 1.00 1.000\n030-037 Several combinations of the previous transformations\n0.96 0.83 0.885\nAs a summation on IIMB 2009 data sets, Fig. 4 shows the recall-precision graph depicting our three different approach of instance matching system: 1. our core instance matcher without property weight, called as AFlood (PW-); 2. our augmented instance matcher with primitive property weight, we called as AFlood (PW); and 3. our further improved instance matcher with proposed automatic weight factor, we are calling as AFlood (PW+). The figure depicts the improvement of our three different instance matcher."
    }, {
      "heading" : "6.6. Result of Our Proposed System with IIMB-2010 Data Set",
      "text" : "In the instance matching track of OAEI-20104, the participants for IIMB2010 large dataset were Combinatorial Optimization for Data Integration (CODI) [20], Automated Semantic Mapping of Ontologies with Validation (ASMOV) [35] and RiMOM [19]. We experimented with our core instance matching system without property weight, we called as AFlood(PW-), and our augmented instance matching system with proposed automatic weight factor, we call as AFlood(PW+). Fig.5 shows the recall-precision graph of the participants [34] and the curves of our instance matching systems. Our proposed method outperforms other methods in several cases although CODI shows better result in some cases.\n4 http://oaei.ontologymatching.org/2010/\n7. CONCLUSIONS\nIn this paper, we address a unique idea of generating non-linear property weights automatically in instance matching technique to integrate semantically rich data, often called as instances of semantic knowledge base. Our mathematical reasoning section logically satisfies the theoretical strength of the proposed method from different aspects. We mathematically model a metric for generating property weights in a knowledge base. The metric is then used in our instance matching algorithm to produce better results. Experiment and evaluation section exhibits how theoretically proven approach strongly contributes in achieving better outcome to integrate semantic data within same or among heterogeneous data sources. Our instance matcher with property weight provides better outcome than without property weight. Therefore, we can clearly state that automatic property weight generation in instance matching algorithm plays a vital role in semantic data integration. Application of this method in other domain such as record linkage, entity resolution problem, identity recognition may also open a new research scope.\nOur future task covers to improve the scalability issues of the proposed method. Moreover, we would like to apply this integrator in integration of different social network data for investigating its applicability in real world."
    } ],
    "references" : [ {
      "title" : "Resource description framework (rdf) model and syntax specification",
      "author" : [ "O. Lassila", "R.R. Swick" ],
      "venue" : "The World Wide Web Consortium ",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "F",
      "author" : [ "D. McGuinness" ],
      "venue" : "van Harmelen, OWL Web Ontology Language Overview, W3C Recommendation 10(10) ",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Ontology Alignment: Bridging the Semantic Gap",
      "author" : [ "M. Ehrig" ],
      "venue" : "Springer, New York ",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Allegro graph: RDF triple database",
      "author" : [ "J. Aasman" ],
      "venue" : "Technical report. Franz Incorporated, 2006. ur l: http://www. franz. com/agraph/allegrograph/ ",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Linked data on the web (ldow2008)",
      "author" : [ "C. Bizer", "T. Heath", "K. Idehen", "T. Berners-Lee" ],
      "venue" : "in: Proceeding of the 17th international conference on World Wide Web, ACM ",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Dbpedia: A nucleus for a web of open data",
      "author" : [ "S. Auer", "C. Bizer", "G. Kobilarov", "J. Lehmann", "R. Cyganiak", "Z. Ives" ],
      "venue" : "The Semantic Web ",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "The DBLP computer science bibliography: Evolution",
      "author" : [ "M. Ley" ],
      "venue" : "research issues, perspectives, String Processing and Information Retrieval, Springer ",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "A Theory for Record Linkage",
      "author" : [ "I. Fellegi", "A. Sunter" ],
      "venue" : "Journal of the American Statistical Association 64 (328) ",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1969
    }, {
      "title" : "Record Linkage: Current Practice and Future Directions",
      "author" : [ "L. Gu", "R. Baxter", "D. Vickers", "C. Rainsford" ],
      "venue" : "CSIRO Mathematical and Information Sciences Technical Report 3 ",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "The State of Record Linkage and Current Research Problems",
      "author" : [ "W.E. Winkler" ],
      "venue" : "Technical report, Statistical Research Division, U.S. Census Bureau, Washington DC ",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Instance matching for ontology population",
      "author" : [ "S. Castano", "A. Ferrara", "S. Montanelli", "D. Lorusso" ],
      "venue" : "in: SEBD ",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Discovering semantic equivalence of people behind online profiles",
      "author" : [ "K. Cortis", "S. Scerri", "I. Rivera", "S. Handschuh" ],
      "venue" : "Proceedings of the Resource Discovery (RED) Workshop, ser. ESWC ",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Anchor-Flood: Results for OAEI-2009",
      "author" : [ "M.H. Seddiqui", "M. Aono" ],
      "venue" : "Proceedings of Ontology Matching Workshop of the 8th International Semantic Web Conference, Chantilly, VA, USA ",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Merging the results of approximate match operations",
      "author" : [ "S. Guha", "N. Koudas", "A. Marathe", "D. Srivastava" ],
      "venue" : "in: Proceedings of the Thirtieth international conference on Very large data bases-Volume 30, VLDB Endowment ",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "The state of record linkage and current research problems",
      "author" : [ "W. Winkler" ],
      "venue" : "in: Statistical Research Division, US Census Bureau, Citeseer ",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Augmentation of ontology instance matching by automatic weight generation",
      "author" : [ "M.H. Seddiqui", "S. Das", "I. Ahmed", "R. Nath", "M. Aono" ],
      "venue" : "in: Information and Communication Technologies (WICT), 2011 World Congress on, IEEE ",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "An efficient method for ontology instance matching",
      "author" : [ "R. Nath", "M.H. Seddiqui", "M. Aono" ],
      "venue" : "Japanese Society for Artificial Intelligence ",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Rimom results for OAEI 2010",
      "author" : [ "Z. Wang", "X. Zhang", "L. Hou", "Y. Zhao", "J. Li", "Y. Qi", "J. Tang" ],
      "venue" : "Ontology Matching 195 ",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Codi: Combinatorial optimization for data integration–results for oaei 2010",
      "author" : [ "J. Noessner", "M. Niepert" ],
      "venue" : "Ontology Matching ",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Codi: Combinatorial optimization for data integration– results for oaei 2011",
      "author" : [ "J. Huber", "T. Sztyler", "J. Noessner", "C. Meilicke" ],
      "venue" : "Ontology Matching ",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Semantic similarity based on corpus statistics and lexical taxonomy",
      "author" : [ "J. Jiang", "D. Conrath" ],
      "venue" : "Proceedings on International Conference on Research in Computational Linguistics, Taiwan ",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "An information-theoretic definition of similarity",
      "author" : [ "D. Lin" ],
      "venue" : "ICML (98) ",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Using information content to evaluate semantic similarity in a taxonomy",
      "author" : [ "P. Resnik" ],
      "venue" : "Proceedings of the 14th International Joint Conference on Artificial Intelligence, Montreal, Canada ",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "An intrinsic information content metric for semantic similarity in WordNet",
      "author" : [ "N. Seco", "T. Veale", "J. Hayes" ],
      "venue" : "in: ECAI, Vol. 16 ",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Metric of intrinsic information content for measuring semantic similarity in an ontology",
      "author" : [ "M.H. Seddiqui", "M. Aono" ],
      "venue" : "in: Proceedings of the Seventh Asia-Pacific Conference on Conceptual Modelling- Volume 110, Australian Computer Society, Inc. ",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language",
      "author" : [ "P. Resnik" ],
      "venue" : "Journal of artificial intelligence ",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "A mathematical theory of communication",
      "author" : [ "C. Shannon", "W. Weaver" ],
      "venue" : "Bell System Technical Journal 27 ",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 1948
    }, {
      "title" : "Ontology instance matching by considering semantic link cloud",
      "author" : [ "M.H. Seddiqui", "M. Aono" ],
      "venue" : "in: 9th WSEAS Int. Conf. on Applications of Computer Engineering ",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "An efficient and scalable algorithm for segmented alignment of ontologies of arbitrary size",
      "author" : [ "M.H. Seddiqui", "M. Aono" ],
      "venue" : "Web Semantics: Science, Services and Agents on the World Wide Web 7 (4) ",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Alignment Results of Anchor-Flood Algorithm for OAEI-2008",
      "author" : [ "M.H. Seddiqui", "M. Aono" ],
      "venue" : "Proceedings of Ontology Matching Workshop of the 7th International Semantic Web Conference, Karlsruhe, Germany ",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "A novel automatic property weight generation for semantic data integration",
      "author" : [ "R.P.D. Nath", "M.H. Seddiqui", "M. Aono" ],
      "venue" : "in: 16th Int. Conf. on Computer and Information Technology, Khulna, Bangladesh, March ",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "V",
      "author" : [ "J. Euzenat", "A. Ferrara", "L. Hollink", "A. Isaac", "C. Joslyn" ],
      "venue" : "Malais ́e, C. Meilicke, A. Nikolov, J. Pane, M. Sabou, et al., Results of the ontology alignment evaluation initiative 2009, in: Proc. 4th ISWC workshop on ontology matching (OM) ",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "C",
      "author" : [ "J. Euzenat", "A. Ferrara", "C. Meilicke", "A. Nikolov", "J. Pane", "F. Scharffe", "P. Shvaiko", "H. Stuckenschmidt", "O. Svb-Zamazal", "V. Svtek" ],
      "venue" : "Trojahn dos Santos, Results of the ontology alignment evaluation initiative 2010, in: Proc. 5th ISWC workshop on ontology matching (OM), Shanghai (CN) ",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Asmov: Results for oaei 2010",
      "author" : [ "Y.R. Jean-Mary", "E.P. Shironoshita", "M.R. Kabuka" ],
      "venue" : "Ontology Matching 126 (2010).  International Journal of Web & Semantic Technology ",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 1994
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "A semantic knowledge base contains assertion about instances of two disjoint sets called “concepts”, C and “relations”, R which is technically called as property in Resource Description Framework (RDF) [1] and in Web Ontology Language (OWL) [2].",
      "startOffset" : 202,
      "endOffset" : 205
    }, {
      "referenceID" : 1,
      "context" : "A semantic knowledge base contains assertion about instances of two disjoint sets called “concepts”, C and “relations”, R which is technically called as property in Resource Description Framework (RDF) [1] and in Web Ontology Language (OWL) [2].",
      "startOffset" : 241,
      "endOffset" : 244
    }, {
      "referenceID" : 2,
      "context" : "The semantic knowledge base is defined in [3] as follows:",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 3,
      "context" : "Currently a large number of ontology instances are available in semantic knowledge bases: AllegroGraph [4] contains more than one trillion triples, a basic building block of Semantic Web formed as <subject> <predicate> and <object>, Linked Open Data (LOD) [5] contains more than fifty billion triples and there are more other knowledge bases too like DBpedia [6], DBLP [7] and so on.",
      "startOffset" : 103,
      "endOffset" : 106
    }, {
      "referenceID" : 4,
      "context" : "Currently a large number of ontology instances are available in semantic knowledge bases: AllegroGraph [4] contains more than one trillion triples, a basic building block of Semantic Web formed as <subject> <predicate> and <object>, Linked Open Data (LOD) [5] contains more than fifty billion triples and there are more other knowledge bases too like DBpedia [6], DBLP [7] and so on.",
      "startOffset" : 256,
      "endOffset" : 259
    }, {
      "referenceID" : 5,
      "context" : "Currently a large number of ontology instances are available in semantic knowledge bases: AllegroGraph [4] contains more than one trillion triples, a basic building block of Semantic Web formed as <subject> <predicate> and <object>, Linked Open Data (LOD) [5] contains more than fifty billion triples and there are more other knowledge bases too like DBpedia [6], DBLP [7] and so on.",
      "startOffset" : 359,
      "endOffset" : 362
    }, {
      "referenceID" : 6,
      "context" : "Currently a large number of ontology instances are available in semantic knowledge bases: AllegroGraph [4] contains more than one trillion triples, a basic building block of Semantic Web formed as <subject> <predicate> and <object>, Linked Open Data (LOD) [5] contains more than fifty billion triples and there are more other knowledge bases too like DBpedia [6], DBLP [7] and so on.",
      "startOffset" : 369,
      "endOffset" : 372
    }, {
      "referenceID" : 7,
      "context" : "Ontology instance matching is a relatively new domain for researchers in comparison to record linkage, which has a classical state-of-the-art [8, 9, 10], although there is a close relationship between instance matching to record linkage.",
      "startOffset" : 142,
      "endOffset" : 152
    }, {
      "referenceID" : 8,
      "context" : "Ontology instance matching is a relatively new domain for researchers in comparison to record linkage, which has a classical state-of-the-art [8, 9, 10], although there is a close relationship between instance matching to record linkage.",
      "startOffset" : 142,
      "endOffset" : 152
    }, {
      "referenceID" : 9,
      "context" : "Ontology instance matching is a relatively new domain for researchers in comparison to record linkage, which has a classical state-of-the-art [8, 9, 10], although there is a close relationship between instance matching to record linkage.",
      "startOffset" : 142,
      "endOffset" : 152
    }, {
      "referenceID" : 10,
      "context" : "In the contrary, HMatch(I) [11] tried to address automatically detecting property weight.",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 11,
      "context" : "In [12] authors propose that properties, which have a maximum or an exact cardinality of 1 have a higher impact factor on the matching process.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 12,
      "context" : "In this regard, we experimented with the proposed metric of property weight generation applied in our previous core instance matching technique [13].",
      "startOffset" : 144,
      "endOffset" : 148
    }, {
      "referenceID" : 13,
      "context" : "The weight of each property can be manually specified by a domain expert [15] and [11] or it can be automatically determined through statistical analysis [16], [17], [18].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 10,
      "context" : "The weight of each property can be manually specified by a domain expert [15] and [11] or it can be automatically determined through statistical analysis [16], [17], [18].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 14,
      "context" : "The weight of each property can be manually specified by a domain expert [15] and [11] or it can be automatically determined through statistical analysis [16], [17], [18].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 15,
      "context" : "The weight of each property can be manually specified by a domain expert [15] and [11] or it can be automatically determined through statistical analysis [16], [17], [18].",
      "startOffset" : 160,
      "endOffset" : 164
    }, {
      "referenceID" : 16,
      "context" : "The weight of each property can be manually specified by a domain expert [15] and [11] or it can be automatically determined through statistical analysis [16], [17], [18].",
      "startOffset" : 166,
      "endOffset" : 170
    }, {
      "referenceID" : 10,
      "context" : "0 [11], each property is associated with a weight ranging from 0 to 1 expressing the capability of the property for the goal of equivocally identifying the individual in the domain of interest.",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 11,
      "context" : "To discover semantic equivalence between persons in online profiles or otherwise, an appropriate metric is proposed in [12] for weighting the attributes which are syntactically and/or semantically matched.",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 14,
      "context" : "A further refinement of the instance matching process is taken into account considering the frequency of each value occurs [16] in the knowledge base.",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 17,
      "context" : "RiMOM [19] used several instance matching benchmark data sets to evaluate their systems namely, A-R-S, T-S-D and IIMB.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 18,
      "context" : "In [20] and [21], J.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 19,
      "context" : "In [20] and [21], J.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 20,
      "context" : "Information theoretic approaches are well defined in a couple of research works by [22, 23, 24, 25, 26].",
      "startOffset" : 83,
      "endOffset" : 103
    }, {
      "referenceID" : 21,
      "context" : "Information theoretic approaches are well defined in a couple of research works by [22, 23, 24, 25, 26].",
      "startOffset" : 83,
      "endOffset" : 103
    }, {
      "referenceID" : 22,
      "context" : "Information theoretic approaches are well defined in a couple of research works by [22, 23, 24, 25, 26].",
      "startOffset" : 83,
      "endOffset" : 103
    }, {
      "referenceID" : 23,
      "context" : "Information theoretic approaches are well defined in a couple of research works by [22, 23, 24, 25, 26].",
      "startOffset" : 83,
      "endOffset" : 103
    }, {
      "referenceID" : 24,
      "context" : "Information theoretic approaches are well defined in a couple of research works by [22, 23, 24, 25, 26].",
      "startOffset" : 83,
      "endOffset" : 103
    }, {
      "referenceID" : 22,
      "context" : "The IC value is then obtained by considering the negative log likelihood [24, 27]: icres (c) = -log p(c), (2)",
      "startOffset" : 73,
      "endOffset" : 81
    }, {
      "referenceID" : 25,
      "context" : "The IC value is then obtained by considering the negative log likelihood [24, 27]: icres (c) = -log p(c), (2)",
      "startOffset" : 73,
      "endOffset" : 81
    }, {
      "referenceID" : 22,
      "context" : "[24] was the first to consider the use of this formula, that stems from the work of Shannon [28], for the purpose of semantic similarity judgments.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 26,
      "context" : "[24] was the first to consider the use of this formula, that stems from the work of Shannon [28], for the purpose of semantic similarity judgments.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 12,
      "context" : "Our primitive instance matching system [13, 29] did not get the essence of automatic weight generation.",
      "startOffset" : 39,
      "endOffset" : 47
    }, {
      "referenceID" : 27,
      "context" : "Our primitive instance matching system [13, 29] did not get the essence of automatic weight generation.",
      "startOffset" : 39,
      "endOffset" : 47
    }, {
      "referenceID" : 28,
      "context" : "Our ontology schema matching algorithm [30, 13, 31] takes the essence of the locality of reference by considering the neighbouring concepts and relations to align the entities of ontologies.",
      "startOffset" : 39,
      "endOffset" : 51
    }, {
      "referenceID" : 12,
      "context" : "Our ontology schema matching algorithm [30, 13, 31] takes the essence of the locality of reference by considering the neighbouring concepts and relations to align the entities of ontologies.",
      "startOffset" : 39,
      "endOffset" : 51
    }, {
      "referenceID" : 29,
      "context" : "Our ontology schema matching algorithm [30, 13, 31] takes the essence of the locality of reference by considering the neighbouring concepts and relations to align the entities of ontologies.",
      "startOffset" : 39,
      "endOffset" : 51
    }, {
      "referenceID" : 0,
      "context" : "Given two individuals i1 and i2 that are instances of the same (or aligned) concept, the instance affinity function IA(i1, i2) → [0, 1] provides a measure of their affinity in the range [0,1].",
      "startOffset" : 129,
      "endOffset" : 135
    }, {
      "referenceID" : 0,
      "context" : "Given two individuals i1 and i2 that are instances of the same (or aligned) concept, the instance affinity function IA(i1, i2) → [0, 1] provides a measure of their affinity in the range [0,1].",
      "startOffset" : 186,
      "endOffset" : 191
    }, {
      "referenceID" : 15,
      "context" : "We augmented our system by introducing a primitive automatic weight generation technique [17].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 30,
      "context" : "We further improve our primitive automatic weight generation technique with our proposed metric of automatic weight generation [32].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 31,
      "context" : "The benchmark data is divided into four major groups: value transformation (001-010), structural transformation (011-019), logical transformation (020-029) and combination transformation (030037) [33].",
      "startOffset" : 196,
      "endOffset" : 200
    }, {
      "referenceID" : 32,
      "context" : "The benchmark has been generated in a small version consisting in 363 individuals and in a large version containing 1416 individuals [34].",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 12,
      "context" : "Our primitive instance matching algorithm produces results on IIMB datasets of 2009 without considering property weight in OAEI campaign [13].",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 31,
      "context" : "3 demonstrates the results of the participants [33] of OAEI-2009 in where AFlood is our instance matcher without considering property weight.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 15,
      "context" : "Our system with primitive weight generation technique of instance matching shows its strength over our basic instance matching system without weight factor [17].",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 18,
      "context" : "Result of Our Proposed System with IIMB-2010 Data Set In the instance matching track of OAEI-2010, the participants for IIMB2010 large dataset were Combinatorial Optimization for Data Integration (CODI) [20], Automated Semantic Mapping of Ontologies with Validation (ASMOV) [35] and RiMOM [19].",
      "startOffset" : 203,
      "endOffset" : 207
    }, {
      "referenceID" : 33,
      "context" : "Result of Our Proposed System with IIMB-2010 Data Set In the instance matching track of OAEI-2010, the participants for IIMB2010 large dataset were Combinatorial Optimization for Data Integration (CODI) [20], Automated Semantic Mapping of Ontologies with Validation (ASMOV) [35] and RiMOM [19].",
      "startOffset" : 274,
      "endOffset" : 278
    }, {
      "referenceID" : 17,
      "context" : "Result of Our Proposed System with IIMB-2010 Data Set In the instance matching track of OAEI-2010, the participants for IIMB2010 large dataset were Combinatorial Optimization for Data Integration (CODI) [20], Automated Semantic Mapping of Ontologies with Validation (ASMOV) [35] and RiMOM [19].",
      "startOffset" : 289,
      "endOffset" : 293
    }, {
      "referenceID" : 32,
      "context" : "5 shows the recall-precision graph of the participants [34] and the curves of our instance matching systems.",
      "startOffset" : 55,
      "endOffset" : 59
    } ],
    "year" : 2015,
    "abstractText" : "The proliferation of heterogeneous data sources of semantic knowledge base intensifies the need of an automatic instance matching technique. However, the efficiency of instance matching is often influenced by the weight of a property associated to instances. Automatic weight generation is a non-trivial, however an important task in instance matching technique. Therefore, identifying an appropriate metric for generating weight for a property automatically is nevertheless a formidable task. In this paper, we investigate an approach of generating weights automatically by considering hypotheses: (1) the weight of a property is directly proportional to the ratio of the number of its distinct values to the number of instances contain the property, and (2) the weight is also proportional to the ratio of the number of distinct values of a property to the number of instances in a training dataset. The basic intuition behind the use of our approach is the classical theory of information content that infrequent words are more informative than frequent ones. Our mathematical model derives a metric for generating property weights automatically, which is applied in instance matching system to produce re-conciliated instances efficiently. Our experiments and evaluations show the effectiveness of our proposed metric of automatic weight generation for properties in an instance matching technique.",
    "creator" : "Microsoft Word"
  }
}