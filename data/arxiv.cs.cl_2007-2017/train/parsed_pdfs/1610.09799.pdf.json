{
  "name" : "1610.09799.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Experiments with POS Tagging Code-mixed Indian Social Media Text",
    "authors" : [ "Prakash B. Pimpale", "Raj Nath Patel" ],
    "emails" : [ "prakash@cdac.in", "rajnathp@cdac.in" ],
    "sections" : [ {
      "heading" : null,
      "text" : "This paper presents Centre for Development of Advanced Computing Mumbai’s (CDACM) submission to the NLP Tools Contest on Part-Of-Speech (POS) Tagging For Code-mixed Indian Social Media Text (POSCMISMT) 2015 (collocated with ICON 2015). We submitted results for Hindi (hi), Bengali (bn), and Telugu (te) languages mixed with English (en). In this paper, we have described our approaches to the POS tagging techniques, we exploited for this task. Machine learning has been used to POS tag the mixed language text. For POS tagging, distributed representations of words in vector space (word2vec) for feature extraction and Log-linear models have been tried. We report our work on all three languages hi, bn, and te mixed with en."
    }, {
      "heading" : "1 Introduction",
      "text" : "In this paper, we present our experiments for POS tagging code-mixed Indian social media text. The evolution of social media platforms such as blogs, micro-blogs (e.g., Twitter), and chats (e.g., Facebook messages) has created many new sources for information access and language technology. But the same has presented many new challenges, making it one of the prime present-day research areas.\nMost of the Indians and many other NonEnglish speakers across the world don’t always use Unicode to write something in social media, they make use of transliteration and frequently insert English elements through code-mixing and Anglicisms, and often mix multiple languages to express their thoughts.\nEnglish still is the principal language for social media communications, but this kind of multilingual content is growing and calls for the development of language technologies for languages other than English. If we observe twitter and facebook feeds of Indians, it’s full of frequent code-mixing. It’s not a surprise given the diverse linguistic culture across India. But this poses additional difficulties for automatic Indian social media text processing.\nPart-of-speech (POS) is an essential prerequisite for most of the NLP applications. POS tagging of English text are now a quite matured filed in NLP and a lot of work is in progress for English social media text. The work on POS tagging for code-mixed language is a recent topic and not much work has been done for Indian Languages code-mixed text.\nVyas et al. (2014) created a multi-level annotated corpus of Hindi-English code-mixed text from facebook forums, and explored language identification, back-transliteration, normalization and POS tagging of this data. They used tools like CRF++ based tagger and Stanford POS tagger for experimentation. (Jamatia et al., 2015) created a good amount of labeled corpus using amazon mechanical turk and bootstrapping. They experimented with various machine learning techniques for POS tagging and reported Random Forest to be the best one among what they tried.\nWe have used Stanford log-linear PartOf-Speech tagger (Toutanova and Manning, 2000; Toutanova et al., 2003) for tagging, word2vec (Mikolov et al., 2013) for feature extraction and WEKA (Hall et al., 2009) for machine learning.\nThe rest of the paper is organized as follows. In section 2, we discuss datasets followed by experiments and results in section 3. The submission to shared task has been discussed in section 4 and the\nar X\niv :1\n61 0.\n09 79\n9v 1\n[ cs\n.C L\n] 3\n1 O\nct 2\n01 6\nconclusion and future work in section 5."
    }, {
      "heading" : "2 Data-sets",
      "text" : "We have used 80% of the training data shared by POSCMISMT detailed in Table 1 for the experiments. Testing for the experiments was done using remaining 20% data. But the system for final submission was trained using the complete data shared. The submitted systems were evaluated against a test corpus, by the organizers."
    }, {
      "heading" : "3 Experiments and Results",
      "text" : "We have used Stanford POS tagger (Toutanova and Manning, 2000; Toutanova et al., 2003) available on Stanford Natural Language Processing group’s website for constrained training and result submission. And unconstrained training and result submission has been done using word2vec (Mikolov et al., 2013) and WEKA (Hall et al., 2009)."
    }, {
      "heading" : "3.1 POS Tagging using Stanford POS tagger: Constrained",
      "text" : "The constrained result submission needed to be done using system trained on data provided by POSCMISMT only. We trained Stanford POS tagger using train data provided. Basically this POS tagger learns a log-linear conditional probability model from tagged text, using a maximum entropy method. The POS tag of input word is then decided by the model based on context and surrounding tags of the word. The architecture (arch\nproperty) we used for training was: words(-2, 2), order(1), prefix(6), suffix(6), unicodeshapes(1)."
    }, {
      "heading" : "3.2 POS tagging using Machine Learning: Unconstrained",
      "text" : "We used WEKA to experiment with the application of various machine learning techniques to the POS tagging problem. Various combinations of following word features were used for training and testing the system:\n1. language of the word\n2. language of the previous word\n3. language of the next word\n4. POS tags of the previous 2 word\n5. POS tags of the next 2 word’s similar words\n6. Position of the word in sentence\nIn a sentence with length L, words located at positions 1, 2, L and L-1 were assigned required number of default feature values for previous and next languages and POS tags.\nFor POS tag of the next word’s similar word, we used distributed representation of the words in vector space. We trained a word2vec model using train and test corpus detailed in Table 1. For the POS tag of the next word, we followed one of the following steps:\n1. The word was looked up in the list from training data, if it was found, the most frequent POS of that word was used. If it was not in the list, we followed next step.\n2. The nearest word list was fetched using word2vec model trained with the train and test set and the most frequent available POS tag of the nearest word was used instead. If this failed i.e no nearest word was found in the training set, we followed next step.\n3. The most frequent POS tag from the training set was used instead.\nWe reserved 20% of training data for the purpose of evaluation. Table 2 details some of the significant results we obtained during the experiments on this test set."
    }, {
      "heading" : "4 Submission to the Shared Task",
      "text" : "From the Table 2 we can see that J48 decision tree gave better results and so that was used to train the final system for submission. The submitted results were evaluated by organizers. These results by organizers have been detailed in Table 3 below."
    }, {
      "heading" : "5 Conclusion and Feature Work",
      "text" : "In this paper, we presented two techniques for POS tagging of code-mixed Indian social media text. The method used for constrained submission is performing well, but lack of the quality training data doesn’t allow to do much with it. On the other hand, use of the distributed vector representation of words in feature engineering may allow us to use unlabeled data for training.\nThe results are encouraging and future work can be focused on obtaining more social media corpus and using that for the better feature representation."
    } ],
    "references" : [ {
      "title" : "The weka data mining software: an update",
      "author" : [ "Hall et al.2009] Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H Witten" ],
      "venue" : "ACM SIGKDD explorations newsletter,",
      "citeRegEx" : "Hall et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hall et al\\.",
      "year" : 2009
    }, {
      "title" : "Part-of-speech tagging for code-mixed English-Hindi Twitter and Facebook chat messages",
      "author" : [ "Björn Gambäck", "Amitava Das" ],
      "venue" : "RECENT ADVANCES IN,",
      "citeRegEx" : "Jamatia et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Jamatia et al\\.",
      "year" : 2015
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Mikolov et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Enriching the Knowledge Sources used in a Maximum Entropy Part-of-Speech Tagger",
      "author" : [ "Toutanova", "Manning2000] Kristina Toutanova", "Christopher D Manning" ],
      "venue" : "In Proceedings of the 2000 Joint SIGDAT conference on Empirical meth-",
      "citeRegEx" : "Toutanova et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Toutanova et al\\.",
      "year" : 2000
    }, {
      "title" : "Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network",
      "author" : [ "Dan Klein", "Christopher D Manning", "Yoram Singer" ],
      "venue" : "In Proceedings of the 2003 Conference of the North American Chapter",
      "citeRegEx" : "Toutanova et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Toutanova et al\\.",
      "year" : 2003
    }, {
      "title" : "Pos tagging of english-hindi code-mixed social media content",
      "author" : [ "Vyas et al.2014] Yogarshi Vyas", "Spandana Gella", "Jatin Sharma", "Kalika Bali", "Monojit Choudhury" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Vyas et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Vyas et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "(Jamatia et al., 2015) created a good amount of labeled corpus using amazon mechanical turk and bootstrapping.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 4,
      "context" : "We have used Stanford log-linear PartOf-Speech tagger (Toutanova and Manning, 2000; Toutanova et al., 2003) for tagging, word2vec (Mikolov et al.",
      "startOffset" : 54,
      "endOffset" : 107
    }, {
      "referenceID" : 2,
      "context" : ", 2003) for tagging, word2vec (Mikolov et al., 2013) for feature extraction and WEKA (Hall et al.",
      "startOffset" : 30,
      "endOffset" : 52
    }, {
      "referenceID" : 0,
      "context" : ", 2013) for feature extraction and WEKA (Hall et al., 2009) for machine learning.",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 4,
      "context" : "We have used Stanford POS tagger (Toutanova and Manning, 2000; Toutanova et al., 2003) available on Stanford Natural Language Processing group’s website for constrained training and result submission.",
      "startOffset" : 33,
      "endOffset" : 86
    }, {
      "referenceID" : 2,
      "context" : "And unconstrained training and result submission has been done using word2vec (Mikolov et al., 2013) and WEKA (Hall et al.",
      "startOffset" : 78,
      "endOffset" : 100
    }, {
      "referenceID" : 0,
      "context" : ", 2013) and WEKA (Hall et al., 2009).",
      "startOffset" : 17,
      "endOffset" : 36
    } ],
    "year" : 2016,
    "abstractText" : "This paper presents Centre for Development of Advanced Computing Mumbai’s (CDACM) submission to the NLP Tools Contest on Part-Of-Speech (POS) Tagging For Code-mixed Indian Social Media Text (POSCMISMT) 2015 (collocated with ICON 2015). We submitted results for Hindi (hi), Bengali (bn), and Telugu (te) languages mixed with English (en). In this paper, we have described our approaches to the POS tagging techniques, we exploited for this task. Machine learning has been used to POS tag the mixed language text. For POS tagging, distributed representations of words in vector space (word2vec) for feature extraction and Log-linear models have been tried. We report our work on all three languages hi, bn, and te mixed with en.",
    "creator" : "LaTeX with hyperref package"
  }
}