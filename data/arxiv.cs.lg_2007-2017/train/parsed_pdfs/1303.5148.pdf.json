{
  "name" : "1303.5148.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Estimating Confusions in the ASR Channel for Improved Topic-based Language Model Adaptation",
    "authors" : [ "Damianos Karakos", "Mark Dredze", "Sanjeev Khudanpur" ],
    "emails" : [ "dkarakos@bbn.com", "mdredze@jhu.edu", "khudanpur@jhu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "THE JOHNS HOPKINS UNIVERSITY\nEstimating Confusions in the ASR Channel for Improved Topic-based Language Model Adaptation\nDamianos Karakos, Mark Dredze, Sanjeev Khudanpur\nTECHNICAL REPORT 8\nMARCH 22, 2013\nar X\niv :1\n30 3.\n51 48\nv1 [\ncs .C\nL ]\n2 1\nM ar\n2 01\n3\nc©HLTCOE, 2013\nAcknowledgements This work is supported, in part, by the Human Language Technology Center of Excellence. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsor.\nHLTCOE 810 Wyman Park Drive Baltimore, Maryland 21211 http://hltcoe.jhu.edu\nEstimating Confusions in the ASR Channel for Improved Topic-based Language Model Adaptation\nDamianos Karakos Raytheon BBN Technologies\nCambridge, MA dkarakos@bbn.com\nMark Dredze and Sanjeev Khudanpur Human Language Technology Center of Excellence\nCenter for Language and Speech Processing Johns Hopkins University\nBaltimore, MD, 21211 mdredze,khudanpur@jhu.edu\nAbstract\nHuman language is a combination of elemental languages/domains/styles that change across and sometimes within discourses. Language models, which play a crucial role in speech recognizers and machine translation systems, are particularly sensitive to such changes, unless some form of adaptation takes place. One approach to speech language model adaptation is self-training, in which a language model’s parameters are tuned based on automatically transcribed audio. However, transcription errors can misguide self-training, particularly in challenging settings such as conversational speech. In this work, we propose a model that considers the confusions (errors) of the ASR channel. By modeling the likely confusions in the ASR output instead of using just the 1-best, we improve self-training efficacy by obtaining a more reliable reference transcription estimate. We demonstrate improved topic-based language modeling adaptation results over both 1-best and lattice selftraining using our ASR channel confusion estimates on telephone conversations."
    }, {
      "heading" : "1 Introduction",
      "text" : "Modern statistical automatic speech recognition (ASR) systems rely on language models for ranking hypotheses generated from acoustic data. Language models are trained on millions of words (or more) taken from text that matches the spoken language, domain and style of interest. Reliance on (static) training data makes language models brittle (Bellegarda, 2001) to changes in domain. However, for\nmany problems of interest, there are numerous hours of spoken audio but little to no written text for language model training. In these settings, we must rely on language model adaptation using the spoken audio to improve performance on data of interest. One common approach to language model adaptation is self-training (Novotney et al., 2009), in which the language model is retrained on the output from the ASR system run on the new audio. Unfortunately, self-training learns from both correct and error ridden transcriptions that mislead the system, a particular problem for high word error rate (WER) domains, such as conversational speech. Even efforts to consider the entire ASR lattice in self-training cannot account for the ASR error bias. Worse still, this is particularly a problem for rare content words as compared to common function words; the fact that content words are more important for understandability exacerbates the problem.\nConfusions in the ASR output pose problems for other applications, such as speech topic classification and spoken document retrieval. In high-WER scenarios, their performance degrades, sometimes considerably (Hazen and Richardson, 2008).\nIn this work, we consider the problem of topic adaptation of a speech recognizer (Seymore and Rosenfeld, 1997), in which we adapt the language model to the topic of the new speech. Our novelty lies in the fact that we correct for the biases present in the output by estimating ASR confusions. Topic proportions are estimated via a probabilistic graphical model which accounts for confusions in the transcript and provides a more accurate portrayal of the spoken audio. To demonstrate the util-\nity of our model, we show improved results over traditional self-training as well as lattice based selftraining for the challenging setting of conversational speech transcription. In particular, we show statistically significant improvements for content words.\nNote that Bacchiani et al. (2004) also consider the problem of language model adaptation as an error correction problem, but with supervised methods. They train an error-correcting perceptron model on reference transcriptions from the new domain. In contrast, our approach does not assume the existence of transcribed data for training a confusion model; rather, the model is trained in an unsupervised manner based only on the ASR output.\nThe paper proceeds as follows: Section 2 describes our setting of language model adaptation and our topic based language model. Section 3 presents a language model adaptation process based on maximum-likelihood and maximum-aposteriori self-training, while Section 4 introduces adaptation that utilizes ASR channel estimates. Section 5 describes experiments on conversational speech."
    }, {
      "heading" : "2 Language Model Adaptation",
      "text" : "We are given a trained speech recognizer, topicbased language model and a large collection of audio utterances (many conversations) for a new domain, i.e. a change of topics, but not manually transcribed text needed for language model training. Our goal is to adapt the language model by learning new topic distributions using the available audio. We consider self-training that adapts the topic distributions based on automatically transcribed audio.\nA conversation C is composed of N speech utterances are represented by N lattices (confusion networks) – annotated with words and posterior probabilities – produced by the speech recognizer. 1 Each confusion network consists of a sequence of bins, where each bin is a set of words hypothesized by the recognizer at a particular time. The i-th bin is denoted by bi and contains words {wi,j}|V|j=1, where V is the vocabulary. 2 When obvious from context, we\n1We assume conversations but our methods can be applied to non-conversational genres.\n2Under specific contexts, not all vocabulary items are likely to be truly spoken in a bin. Although we use summations over all w ∈ V , we practically use only words which are acoustically confusable and consistent with the lexical context of the bin.\nomit subscript j. The most likely word in bin bi is denoted by ŵi. Let M be the total number of bins in the N confusion networks in a single conversation.\nWe use unigram topic-based language models (multinomial distributions over V), which capture word frequencies under each topic. Such models have been used in a variety of ways, such as in PLSA (Hofmann, 2001) and LDA (Blei et al., 2003), and under different training scenarios. Topic-based models provide a global context beyond the local word history in modeling a word’s probability, and have been found especially useful in language model adaptation (Tam and Schultz, 2005; Wang and Stolcke, 2007; Hsu and Glass, 2006). Each topic t ∈ {1, . . . , T} has a multinomial distribution denoted by q(w|t), w ∈ V . These topic-word distributions are learned from conversations labeled with topics, such as those in the Fisher speech corpus.3\nAdapting the topic-based language model means learning a set of conversation specific mixture weights λC = (λC1 , . . . , λ C T ), where λ C t indicates the likelihood of seeing topic t in conversation C.4 While topic compositions remain fixed, the topics selected change with each conversation.5 These mixture weights form the true distribution of a word:\nq(w) = T∑ t=1 λtq(w|t). (1)"
    }, {
      "heading" : "3 Learning λ from ASR Output",
      "text" : "We begin by following previous approaches to selftraining, in which model parameters are re-estimated based on ASR output. We consider self-training based on 1-best and lattice maximum-likelihood estimation (MLE) as well as maximum-aposteriori (MAP) training. In the next section, we modify these approaches to incorporate our confusion estimates.\nFor estimating the topic mixtures λ using selftraining on the 1-best ASR output, i.e. the 1-best path in the confusion network ŵ = {ŵi}Mi=1, we write the log-likelihood of the observations ŵ:\nL(1) = M∑ i=1 log q(ŵi), (2)\n3Alternative approaches estimate topics from unlabeled data, but we use labeled data for evaluation purposes.\n4Unless required we drop the superscript C. 5This assumption can be relaxed to learn q(w|t) as well.\nwhere q is a mixture of topic models (1), for mixture weights λ. We expect topic-based distributions will better estimate the true word distribution than the empirical estimate q̂(w) = 1M ∑M i=1 1(ŵi = w), as the latter is biased due to ASR errors. Maximumlikelihood estimation of λ in (2) is given by:\nλ∗ = argmax λ M∑ i=1 log q(ŵi)\n= argmax λ M∑ i=1 log (∑ t λtq(ŵi|t) ) (3)\nUsing the EM algorithm, Q is the expected loglikelihood of the “complete” data:\nQ(λ(j),λ) = M∑ i=1 ∑ t r(j)(t|ŵi) log(λtq(ŵi|t)),\n(4) where r(j)(t|ŵi) is the posterior distribution of the topic in the i-th bin, given the 1-best word ŵi; this is computed in the E-step of the j-th iteration:\nr(j)(t|ŵi) = λ (j) t q(ŵi|t)∑\nt′ λ (j) t′ q(ŵi|t′)\n. (5)\nIn the M-step of the j+1 iteration, the new estimate of the prior is computed by maximizing (4), i.e.,\nλ (j+1) t =\n∑M i=1 r\n(j)(t|ŵi)∑ t′ ∑M i′=1 r (j)(t′|ŵi′) . (6)"
    }, {
      "heading" : "3.1 Learning λ from Expected Counts",
      "text" : "Following Novotney et al. (2009) we next consider using the entire bin in self-training by maximizing the expected log-likelihood of the ASR output:\nL′(1) = E [ M∑ i=1 log q(Wi) ] , (7)\nwhereWi is a random variable which takes the value w ∈ bi with probability equal to the confidence (posterior probability) si(w) of the recognizer. The maximum-likelihood estimation problem becomes:\nλ∗= argmax λ L′(1) (8)\n= argmax λ M∑ i=1 ∑ w∈bi si(w) log (∑ t λtq(w|t) )\n= argmax λ ∑ w∈V tf(w) log (∑ t λtq(w|t) )\nwhere tf(w) = ∑\ni si(w) denotes the expected count of word w in the conversation, given by the sum of the posteriors of w in all the confusion network bins of the conversation (Karakos et al., 2011) (note that for text documents, it is equivalent to termfrequency). We again use the EM algorithm, with objective function:\nQ(λ(j),λ) = ∑ w∈V tf(w) ∑ t r(j)(t|w) log(λtq(w|t)), (9) where r(j)(t|w) is the posterior distribution of the topic given word w computed using (5) (but with w instead of ŵi). In the M-step of the j + 1 iteration, the new estimate of the prior is computed by maximizing (9), i.e.,\nλ (j+1) t =\n∑ w∈V tf(w)r\n(j)(t|w)∑ t′ ∑ w∈V tf(w)r(j)(t′|w) . (10)"
    }, {
      "heading" : "3.2 Maximum-Aposteriori Estimation of λ",
      "text" : "In addition to a maximum likelihood estimate, we consider a maximum-aposteriori (MAP) estimate by placing a Dirichlet prior over λ (Bacchiani and Roark, 2003):\nλ∗ = argmax λ L+ β log(Dir(λ;α)) (11)\nwhere Dir(λ;α) is the pdf of the Dirichlet distribution with parameter α: Dir(λ;α) = 1B(α) ∏ t λ α−1 t .\nThis introduces an extra component in the optimization. It is easy to prove that the update equation for λ(j+1)t becomes:\nλ (j+1) t =\n[ ∑M i=1 r\n(j)(t|ŵi) + β(α− 1)∑ t′ ∑M i=1 r (j)(t′|ŵi) + Tβ(α− 1) ] + .\n(12) for the case where only the ASR 1-best is used, and\nλ (j+1) t =\n[ ∑ w∈V tf(w)r\n(j)(t|w) + β(α− 1)∑ t′ ∑ w∈V tf(w)r(j)(t′|w) + Tβ(α− 1) ] + .\n(13) for the case where expected counts are used. Note that the [x]+ notation stands for max{0, x}."
    }, {
      "heading" : "4 Confusion Estimation in ASR Output",
      "text" : "Self-training on ASR output can mislead the language model through confusions in the ASR channel. By modeling these confusions we can guide self-training and recover from recognition errors.\nThe ASR channel confusion model is represented by a conditional probability distribution pc(v|w), v, w ∈ V , which denotes the probability that the most likely word in the output of the recognizer (i.e., the “1-best” word) is v, given that the true (reference) word spoken is w. Of course, this conditional distribution is just an approximation as many other phenomena – coarticulation, non-stationarity of speech, channel variations, lexical choice in the context, etc. – cause this probability to vary. We assume that pc(v|w) is an “average” of the conditional probabilities under various conditions.\nWe use the following simple procedure for estimating the ASR channel, similar to that of (Xu et al., 2009) for computing cohort sets:\n• Create confusion networks (Mangu et al., 1999) with the available audio.\n• Count c(w, v), the number of times words w, v appear in the same bin.\n• The conditional ASR probability is computed as pc(v|w) = c(v, w)/ ∑ v′ c(v ′, w). • Prune words whose posterior probabilities are lower than 5% of the max probability in a bin.\n• Keep only the top 10 words in each bin.\nThe last two items above were implemented as a way of reducing the search space and the complexity of the task. We did not observe significant changes in the results when we relaxed these two constraints."
    }, {
      "heading" : "4.1 Learning λ with ASR Confusion Estimates",
      "text" : "We now derive a maximum-likelihood estimate of λ based on the 1-best ASR output but relies on the ASR channel confusion model pc. The loglikelihood of the observations (most likely path in the confusion network) is:\nL(2) = M∑ i=1 log p(ŵi), (14)\nwhere p is the induced distribution on the observations under the confusion model pc(v|w) and the estimated distribution q of (1):\np(ŵi) = ∑ w∈V q(w)pc(ŵi|w). (15)\nRecall that while we sum over V , in practice the summation is limited to only likely words. One could argue that the ASR channel confusion distribution pc(ŵi|w) should discount unlikely confusions. However, since pc is not bin specific, unlikely words in a specific bin could receive non-negligible probability from pc if they are likely in general. This makes the truncated summation over V problematic.\nOne solution would be to reformulate pc(ŵi|w) so that it becomes a conditional distribution given the left (or even right) lexical context of the bin. But this formulation adds complexity and suffers from the usual sparsity issues. The solution we follow here imposes the constraint that only the words already\nexisting in bi are allowed to be candidate words giving rise to ŵi. This uses the “pre-filtered” set of words in bi to condition on context (acoustic and lexical), without having to model such context explicitly. We anticipate that this conditioning on the words of bi leads to more accurate inference. The likelihood objective then becomes:\nL′(2) = M∑ i=1 log pi(ŵi), (16)\nwith pi defined as: pi(ŵi) = ∑ w∈bi q(w)∑ w′∈bi q(w ′) pc(ŵi|w), (17)\ni.e., the induced probability conditioned on bin bi. Note that although we estimate a conversation level distribution q(w), it has to be normalized in each bin by dividing by ∑ w∈bi q(w), in order to condition only on the words in the bin. The maximumlikelihood estimation for λ becomes:\nλ∗ = argmax λ L′(2) = argmax λ M∑ i=1 log pi(ŵi)\n= argmax λ M∑ i=1 log ∑ w∈bi ∑ t λtq(w|t)pc(ŵi|w)∑ w′∈bi ∑ t′ λt′q(w ′|t′)  (18)\nNote that the appearance of λt in the denominator makes the maximization harder.\nAs before, we rely on an EM-procedure to maximize this objective. Let us assume that at the j-th iteration of EM we have an estimate of the prior distribution q, denoted by q(j). This induces an observation probability in bin i based on equation (17), as well as a posterior probability r(j)i (w|ŵi) that a word w ∈ bi is the reference word, given ŵi. The goal is to come up with a new estimate of the prior distribution q(j+1) that increases the value of the loglikelihood. If we define:\nQ(q(j), q′) =\n= M∑ i=1 ∑ w∈bi r (j) i (w|ŵi) log(pc(ŵi|w)q ′ i(w))\n= M∑ i=1 ∑ w∈bi r (j) i (w|ŵi) log\n( pc(ŵi|w)q′(w)∑\nw′∈bi q ′(w′) ) (19)\nthen we have:\nL′(2)(q(j), q′)− L′(2)(q(j), q(j)) = Q(q(j), q′)−Q(q(j), q(j))\n+ M∑ i=1 D(r (j) i (·|ŵi)‖r ′ i(·|ŵi))\n≥ Q(q(j), q′)−Q(q(j), q(j)) , (20)\nwhere (20) holds because D(r(j)i (·|ŵi)‖r′i(·|ŵi)) ≥ 0 (Cover and Thomas, 1996). Thus, we just need to find the value of q′ that maximizes Q(q(j), q′), as this will guarantee that L′(2)(q(j), q′) ≥ L′(2)(q(j), q(j)). The distribution q′ can be written:\nq′(w) = ∑ t λtq(w|t). (21)\nThus, Q, as a function of λ, can be written as:\nQ(q(j),λ) = M∑ i=1 ∑ w∈bi r (j) i (w|ŵi) log ( pc(ŵi|w) ∑ t λtq(w|t)∑ w′∈bi ∑ t λtq(w ′|t) ) .\n(22)\nEquation (22) cannot be easily maximized with respect to λ by simple differentiation, because the elements of λ appear in the denominator, making them coupled. Instead, we will derive and maximize a lower bound for the Q-difference (20).\nFor the rest of the derivation we assume that λt = eµt∑ t′ e\nµt′ , where µt ∈ R. We can thus express Q as a function of µ = (µ1, . . . , µT ) as follows:\nQ(q(j),µ) = M∑ i=1 ∑ w∈bi r (j) i (w|ŵi) log ( pc(ŵi|w) ∑ t eµt∑ t′ e µt′ q(w|t)∑ w′∈bi ∑ t eµt∑ t′ e µt′ q(w ′|t) )\n= M∑ i=1 ∑ w∈bi r (j) i (w|ŵi) log\n( pc(ŵi|w) ∑ t e µtq(w|t)∑\nw′∈bi ∑ t e µtq(w′|t) ) (23)\nInterestingly, the fact that the sum ∑\nt e µt appears\nin both numerator and denominator in the above expression allows us to discard it.\nAt iteration j + 1, the goal is to come up with an update δ, such that µ(j)+δ results in a higher value for Q; i.e., we require:\nQ(q(j),µ(j) + δ) ≥ Q(q(j),µ(j)), (24)\nwhere µ(j) is the weight vector that resulted after optimizing Q in the j-th iteration. Obviously,\nq(j)(w) = ∑ t eµ (j) t q(w|t)∑ t′ e µ (j) t′ . (25)\nLet us consider the difference:\nQ(q(j),µ(j) + δ)−Q(q(j),µ(j)) (26)\n= M∑ i=1 ∑ w∈bi\nr (j) i (w|ŵi)×[\n− log ∑t eµ(j)t +δt∑w′∈bi q(w′|t)∑ t e µ (j) t ∑ w′∈bi q(w ′|t)  + log (∑ t e µ (j) t +δtq(w|t)∑\nt e µ (j) t q(w|t)\n)] . (27)\nWe use the well-known inequality log(x) ≤ x−1⇒ − log(x) ≥ 1− x and obtain:\n− log ∑t eµ(j)t +δt∑w′∈bi q(w′|t)∑ t e µ (j) t ∑ w′∈bi q(w ′|t)  ≥ 1− ∑ t e µ (j) t +δt ∑ w′∈bi q(w\n′|t)∑ t e µ (j) t ∑ w′∈bi q(w ′|t) . (28)\nNext, we apply Jensen’s inequality to obtain:\nlog (∑ t e µ (j) t +δtq(w|t)∑\nt e µ (j) t q(w|t)\n) ≥ ∑ t e µ (j) t q(w|t)δt∑\nt e µ (j) t q(w|t)\n.\n(29) By combining (27), (28) and (29), we obtain a lower bound on the Q-difference of (26):\nQ(q(j),µ(j) + δ)−Q(q(j),µ(j)) ≥ M∑ i=1 ∑ w∈bi r (j) i (w|ŵi) [ 1 + ∑ t e µ (j) t q(w|t)δt∑ t e µ (j) t q(w|t)\n− ∑ t e µ (j) t +δt ∑ w′∈bi q(w\n′|t)∑ t e µ (j) t ∑ w′∈bi q(w ′|t)\n] . (30)\nIt now suffices to find a δ that maximizes the lower bound of (30), as this will guarantee that the Qdifference will be greater than zero. Note that the lower bound in (30) is a concave function of δt, and it thus has a global maximum that we will find using\ndifferentiation. Let us set g(δ) equal to the righthand-side of (30). Then,\n∂g(δ)\n∂δt = M∑ i=1 ∑ w∈bi\nr (j) i (w|ŵi)×− eµ(j)t +δt∑w′∈bi q(w′|t)∑\nt′ e µ (j)\nt′ ∑\nw′∈bi q(w ′|t′))\n+ eµ (j) t q(w|t)∑\nt′ e µ (j) t′ q(w|t′)  . (31)\nBy setting (31) equal to 0 and solving for δt, we obtain the update for δt (or, equivalently, eµ (j) t +δt):\neµ (j) t +δt = ( M∑ i=1 ∑ w∈bi r (j) i (w|ŵi)eµ (j) t q(w|t)∑ t′ e µ (j) t′ q(w|t′) )\n× ( M∑ i=1 ∑ w∈bi q(w|t)∑ t′ e µ (j) t′ ∑ w∈bi q(w|t ′) )−1 (32)"
    }, {
      "heading" : "4.2 Learning λ from Expected Counts",
      "text" : "As before, we now consider maximizing the expected log-likelihood of the ASR output:\nL′′(2) = E [ M∑ i=1 log p(Wi) ] , (33)\nwhere Wi takes the value w ∈ bi with probability equal to the confidence (posterior probability) si(w) of the recognizer. The modified maximumlikelihood estimation problem now becomes:\nλ∗ = argmax λ L′′(2)\n= argmax λ M∑ i=1 ∑ w∈bi si(w) log pi(w)\n= argmax λ M∑ i=1 ∑ w∈bi si(w)×\nlog ∑ w′∈bi ∑ t λtq(w ′|t)pc(w|w′)∑ w′′∈bi ∑ t′ λt′q(w ′′|t′)  . (34)\nBy following a procedure similar to the one described earlier in this section, we come up with the\nlower bound on the Q-difference:\nQ(q(j),µ(j) + δ)−Q(q(j),µ(j)) ≥ M∑ i=1 ∑ w,w′∈bi r (j) i (w|w ′)si(w ′) [ 1 + ∑ t e µ (j) t q(w|t)δt∑ t e µ (j) t q(w|t)\n− ∑ t e µ (j) t +δt ∑ w′∈bi q(w\n′|t)∑ t e µ (j) t ∑ w′∈bi q(w ′|t)\n] (35)\nwhose optimization results in the following update equation for δt:\neµ (j) t +δt =(\nM∑ i=1 ∑ w,w′∈bi r (j) i (w|w′)si(w′)eµ (j) t q(w|t)∑ t′ e µ (j) t′ q(w|t′)\n)\n× ( M∑ i=1 ∑ w∈bi q(w|t)∑ t′ e µ (j) t′ ∑ w∈bi q(w|t ′) )−1 . (36)"
    }, {
      "heading" : "4.3 Maximum-Aposteriori Estimation of λ",
      "text" : "Finally, we consider a MAP estimation of λ with the confusion model. The optimization contains the term β log(Dir(λ;α)) and the Q-difference (20) is:\nQ(q(j),µ(j) + δ)−Q(q(j),µ(j))+ β log(Dir(eµ (j)+δ/Z1))− β log(Dir(eµ (j) /Z0))\n(37)\nwhere Z0, Z1 are the corresponding normalizing constants. In order to obtain a lower bound on the difference in the second line of (37), we consider the following chain of equalities:\nlog(Dir(eµ (j)+δ/Z1))− log(Dir(eµ (j) /Z0)) = = (α− 1) ∑ t log  eµ(j)t +δt/eµ(j)t(∑ t′ e µ (j) t′ +δt′ ) / (∑ t′ e µ (j) t ) \n= (α− 1) ∑ t δt − T log ∑ t eµ (j) t∑ t′ e µ (j) t′ eδt (38) We distinguish two cases: (i) Case 1: α < 1. We apply Jensen’s inequality to obtain the following\nlower bound on (38),\n(α− 1) ∑ t δt − T ∑ t eµ (j) t∑ t′ e µ (j) t′ δt  = (α− 1)\n[∑ t δt − T ∑ t λ (j) t δt ] . (39)\nThe lower bound (39) now becomes part of the lower bound in (30) (for the case of the 1-best) or the lower bound (35) (for the case of expected counts), and after differentiating with respect to δt and setting the result equal to zero we obtain the update equation:\neµ (j) t +δt = (A+ β(α− 1)(1− Tλ(j)t ))×(\nM∑ i=1 ∑ w∈bi q(w|t)∑ t′ e µ (j) t′ ∑ w∈bi q(w|t ′) )−1 (40)\nwhere A in (40) is equal to M∑ i=1 ∑ w∈bi r (j) i (w|ŵi)eµ (j) t q(w|t)∑ t′ e µ (j) t′ q(w|t′) (41)\nin the case of using just the 1-best, and M∑ i=1 ∑ w,w′∈bi r (j) i (w|w′)si(w′)eµ (j) t q(w|t)∑ t′ e µ (j) t′ q(w|t′) . (42)\nin the case of using the lattice. (ii) Case 2: α ≥ 1. We apply the well-known inequality log(x) ≤ x− 1 and obtain the following lower bound on (38),\n(α− 1) ∑ t δt − T ∑ t eµ (j) t +δt∑ t′ e µ (j) t′ − 1  (43) As before, the lower bound (43) now becomes part of the lower bound in (30) (for the case of the 1- best) or the lower bound (35) (for the case of expected counts), and after differentiating with respect to δt and setting the result equal to zero we obtain the update equation:\neµ (j) t +δt = (A+ β(α− 1))×\n× ( M∑ i=1 ∑ w∈bi q(w|t)∑ t′ e µ (j) t′ ∑ w∈bi q(w|t ′) − β(α− 1)T∑ t′ e µ (j) t′ )−1 (44)\nwhere A in (44) is equal to (41) or (42), depending on whether the log-likelihood of the 1-best or the expected log-likelihood is maximized.\nSummary: We summarize our methods as graphical models in Figure 1. We estimate the topic distributions λC for a conversation C by either selftraining directly on the ASR output, or including our ASR channel confusion model. For training on the ASR output, we rely on MLE 1-best training ((5),(6), left figure), or expected counts from the lattices (10). For both settings we also consider MAP estimation: 1-best (12) and expected counts (13). When using the ASR channel confusion model, we derived parallel cases for MLE 1-best ((32), middle figure) and expected counts (36), as well as the MAP (right figure) training of each ((41),(42))."
    }, {
      "heading" : "5 Experimental Results",
      "text" : "We compare self-training, as described in Section 3, with our confusion approach, as described in Section 4, on topic-based language model adaptation.\nSetup Speech data is taken from the Fisher telephone conversation speech corpus, which has been split into 4 parts: set A1 is one hour of speech used for training the ASR system (acoustic modeling). We chose a small training set to simulate a high WER condition (approx. 56%) since we are primarily interested in low resource settings. While conversational speech is a challenging task even with many hours of training data, we are interested in settings with a tiny amount of training data, such as for new domains, languages or noise conditions. Set A2, a superset of A1, contains 5.5mil words of manual transcripts, used for training the topic-based distribution q(·|t). Conversations in the Fisher corpus are labeled with 40 topics so we create 40 topic-based unigram distributions. These are smoothed based on the vocabulary of the recognizer using the WittenBell algorithm (Chen and Goodman, 1996). Set B, which consists of 50 hours and is disjoint from the other sets, is used as a development corpus for tuning the MAP parameter β(α− 1). Finally, set C (44 hours) is used as a blind test set. The ASR channel and the topic proportions λ are learned in an unsupervised manner on both sets B and C. The results are reported on approximately 5-hour subsets of sets B and C, consisting of 35 conversations each.\nBBN’s ASR system, Byblos, was used in all ASR experiments. It is a multi-pass LVCSR system that uses state-clustered Gaussian tied-mixture models at the triphone and quinphone levels (Prasad et al., 2005). The audio features are transformed using cepstral normalization, HLDA and VTLN. Only ML estimation was used. Decoding performs three passes: a forward and backward pass with a triphone acoustic model (AM) and a 3-gram language model (LM), and rescoring using quinphone AM and a 4-gram LM. These three steps are repeated after speaker adaptation using CMLLR. The vocabulary of the recognizer is 75k words. References of the dev and test sets have vocabularies of 13k and 11k respectively.\nContent Words Our focus on estimating confusions suggests that improvements would be manifest for content words, as opposed to frequently occurring function words. This would be a highly desirable improvement as more accurate content words lead to improved readability or performance on downstream tasks, such as information retrieval and spoken term detection. As a result, we care more about reducing perplexity on these content words than reducing overall scores, which give too much emphasis to function words, the most frequent tokens in the reference transcriptions.\nTo measure content word (low-frequency words) improvements we use the method of Wu and Khudanpur (2000), who compute a constrained version of perplexity focused on content words. We restrict the computation to only those words whose counts in the reference transcripts are at most equal to a threshold thr. Perplexity (Jelinek, 1997) is measured on the manual transcripts of both dev and test data based on the formula PPL(p) , 10 − 1|C| ∑|C| i=1 log10(p(wi)), where p represents the estimated language model, and |C| is the size of the (dev or test) corpus. We emphasize that constrained perplexity is not an evaluation metric, and directly optimizing it would foolishly hurt overall perplexity. However, if overall perplexity remains unchanged, then improvements in content word perplexity reflect a shift of the probability mass, emphasizing corrections in content words over the accuracy of function words, a sensible choice for improving output quality.\nResults First we observe that overall perplexity (far right of Figure 2) remains unchanged; none of the differences between models with and without confusion estimates are statistically significant. However, as expected, the confusion estimates significantly improves the performance on content words (left and center of Figure 2.) The confusion model gives modest (4-6% relative) but statistically significant (p < 2 · 10−2) gains in all conditions for content (low-frequency) word. Additionally, the MAP variant (which was tuned based on low-frequency words) gives gains over the MLE version in all conditions, for both the self-supervised and the confusion model cases. This indicates that modeling confusions focuses improvements on content words, which improve readability and downstream applications.\nASR Improvements Finally, we consider how our adapted language models can improve WER of the ASR system. We used each of the language models with the recognizer to produce transcripts of the dev and test sets. Overall, the best language model (including the confusion model) yielded no change in the overall WER (as we observed with perplexity). However, in a rescoring experiment, the adapted model with confusion estimates resulted in a 0.3% improvement in content WER (errors restricted to words that appear at most 3 times) over the unadapted model, and a 0.1% improvement over the regular adapted model. This confirms that our improved language models yield better recognition output, focused on improvements in content words."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We have presented a new model that captures the confusions (errors) of the ASR channel. When incorporated with adaptation of a topic-based language model, we observe improvements in modeling of content words that improve readability and downstream applications. Our improvements are consistent across a number of settings, including 1-best and lattice self-training on conversational speech. Beyond improvements to language modeling, we believe that our confusion model can aid other speech tasks, such as topic classification. We plan to investigate other tasks, as well as better confusion models, in future work."
    } ],
    "references" : [ {
      "title" : "Unsupervised language model adaptation",
      "author" : [ "Bacchiani", "Roark2003] M. Bacchiani", "B. Roark" ],
      "venue" : "In Proceedings of ICASSP-2003,",
      "citeRegEx" : "Bacchiani et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Bacchiani et al\\.",
      "year" : 2003
    }, {
      "title" : "Language model adaptation with MAP estimation and the perceptron algorithm",
      "author" : [ "B. Roark", "M. Saraclar" ],
      "venue" : "In Proceedings of HLT-2004,",
      "citeRegEx" : "Bacchiani et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Bacchiani et al\\.",
      "year" : 2004
    }, {
      "title" : "An overview of statistical language model adaptation",
      "author" : [ "J.R. Bellegarda" ],
      "venue" : "In Proceedings of ISCA Tutorial and Research Workshop (ITRW),",
      "citeRegEx" : "Bellegarda.,? \\Q2001\\E",
      "shortCiteRegEx" : "Bellegarda.",
      "year" : 2001
    }, {
      "title" : "An empirical study of smoothing techniques for language modeling",
      "author" : [ "Chen", "Goodman1996] S.F. Chen", "J. Goodman" ],
      "venue" : "In Proceedings of the 34th Annual Meeting of the ACL,",
      "citeRegEx" : "Chen et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 1996
    }, {
      "title" : "Elements of Information Theory",
      "author" : [ "Cover", "Thomas1996] T.M. Cover", "J.A. Thomas" ],
      "venue" : null,
      "citeRegEx" : "Cover et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Cover et al\\.",
      "year" : 1996
    }, {
      "title" : "A hybrid svm/mce training approach for vector space topic identification of spoken audio recordings",
      "author" : [ "Hazen", "Richardson2008] T.J. Hazen", "F. Richardson" ],
      "venue" : "In Proceedings of Interspeech-2008,",
      "citeRegEx" : "Hazen et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Hazen et al\\.",
      "year" : 2008
    }, {
      "title" : "Unsupervised learning by probabilistic latent semantic analysis",
      "author" : [ "T. Hofmann" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Hofmann.,? \\Q2001\\E",
      "shortCiteRegEx" : "Hofmann.",
      "year" : 2001
    }, {
      "title" : "Style & topic language model adaptation using HMM-LDA",
      "author" : [ "Hsu", "Glass2006] B-J. Hsu", "J. Glass" ],
      "venue" : "In Proceedings of EMNLP-2006",
      "citeRegEx" : "Hsu et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2006
    }, {
      "title" : "Statistical Methods for Speech Recognition",
      "author" : [ "F. Jelinek" ],
      "venue" : null,
      "citeRegEx" : "Jelinek.,? \\Q1997\\E",
      "shortCiteRegEx" : "Jelinek.",
      "year" : 1997
    }, {
      "title" : "Estimating document frequencies in a speech corpus",
      "author" : [ "Karakos et al.2011] D. Karakos", "M. Dredze", "K. Church", "A. Jansen", "S. Khudanpur" ],
      "venue" : "In Proceedings of ASRU-2011",
      "citeRegEx" : "Karakos et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Karakos et al\\.",
      "year" : 2011
    }, {
      "title" : "Finding consensus among words: Latticebased word error minimization",
      "author" : [ "Mangu et al.1999] L. Mangu", "E. Brill", "A. Stolcke" ],
      "venue" : "In Proceedings of Eurospeech-1999",
      "citeRegEx" : "Mangu et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Mangu et al\\.",
      "year" : 1999
    }, {
      "title" : "Unsupervised acoustic and language model training with small amounts of labelled data",
      "author" : [ "Novotney et al.2009] S. Novotney", "R. Schwartz", "J. Ma" ],
      "venue" : "In Proceedings of ICASSP-2009",
      "citeRegEx" : "Novotney et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Novotney et al\\.",
      "year" : 2009
    }, {
      "title" : "Using story topics for language model adaptation",
      "author" : [ "Seymore", "Rosenfeld1997] K. Seymore", "R. Rosenfeld" ],
      "venue" : "In Proceedings of Eurospeech-1997",
      "citeRegEx" : "Seymore et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Seymore et al\\.",
      "year" : 1997
    }, {
      "title" : "Dynamic language model adaptation using variational Bayes inference",
      "author" : [ "Tam", "Schultz2005] Y-C. Tam", "T. Schultz" ],
      "venue" : "In Proceedings of Eurospeech-2005",
      "citeRegEx" : "Tam et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Tam et al\\.",
      "year" : 2005
    }, {
      "title" : "Integrating MAP, marginals, and unsupervised language model adaptation",
      "author" : [ "Wang", "Stolcke2007] W. Wang", "A. Stolcke" ],
      "venue" : "In Proceedings of Interspeech-2007,",
      "citeRegEx" : "Wang et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2007
    }, {
      "title" : "Maximum entropy techniques for exploiting syntactic, semantic and collocational dependencies in language modeling",
      "author" : [ "Wu", "Khudanpur2000] J. Wu", "S. Khudanpur" ],
      "venue" : "Computer Speech and Language,",
      "citeRegEx" : "Wu et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2000
    }, {
      "title" : "Self-supervised discriminative training of statistical language models",
      "author" : [ "Xu et al.2009] P. Xu", "D. Karakos", "S. Khudanpur" ],
      "venue" : "In Proceedings of ASRU-2009",
      "citeRegEx" : "Xu et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Reliance on (static) training data makes language models brittle (Bellegarda, 2001) to changes in domain.",
      "startOffset" : 65,
      "endOffset" : 83
    }, {
      "referenceID" : 11,
      "context" : "One common approach to language model adaptation is self-training (Novotney et al., 2009), in which the language model is retrained on the output from the ASR system run on the new audio.",
      "startOffset" : 66,
      "endOffset" : 89
    }, {
      "referenceID" : 0,
      "context" : "Note that Bacchiani et al. (2004) also consider the problem of language model adaptation as an error correction problem, but with supervised methods.",
      "startOffset" : 10,
      "endOffset" : 34
    }, {
      "referenceID" : 6,
      "context" : "Such models have been used in a variety of ways, such as in PLSA (Hofmann, 2001) and LDA (Blei et al.",
      "startOffset" : 65,
      "endOffset" : 80
    }, {
      "referenceID" : 11,
      "context" : "1 Learning λ from Expected Counts Following Novotney et al. (2009) we next consider using the entire bin in self-training by maximizing the expected log-likelihood of the ASR output:",
      "startOffset" : 44,
      "endOffset" : 67
    }, {
      "referenceID" : 9,
      "context" : "t λtq(w|t) ) where tf(w) = ∑ i si(w) denotes the expected count of word w in the conversation, given by the sum of the posteriors of w in all the confusion network bins of the conversation (Karakos et al., 2011) (note that for text documents, it is equivalent to termfrequency).",
      "startOffset" : 189,
      "endOffset" : 211
    }, {
      "referenceID" : 16,
      "context" : "We use the following simple procedure for estimating the ASR channel, similar to that of (Xu et al., 2009) for computing cohort sets:",
      "startOffset" : 89,
      "endOffset" : 106
    }, {
      "referenceID" : 10,
      "context" : "• Create confusion networks (Mangu et al., 1999) with the available audio.",
      "startOffset" : 28,
      "endOffset" : 48
    }, {
      "referenceID" : 8,
      "context" : "Perplexity (Jelinek, 1997) is measured on the manual transcripts of both dev and test data based on the formula PPL(p) ,",
      "startOffset" : 11,
      "endOffset" : 26
    } ],
    "year" : 2013,
    "abstractText" : "Human language is a combination of elemental languages/domains/styles that change across and sometimes within discourses. Language models, which play a crucial role in speech recognizers and machine translation systems, are particularly sensitive to such changes, unless some form of adaptation takes place. One approach to speech language model adaptation is self-training, in which a language model’s parameters are tuned based on automatically transcribed audio. However, transcription errors can misguide self-training, particularly in challenging settings such as conversational speech. In this work, we propose a model that considers the confusions (errors) of the ASR channel. By modeling the likely confusions in the ASR output instead of using just the 1-best, we improve self-training efficacy by obtaining a more reliable reference transcription estimate. We demonstrate improved topic-based language modeling adaptation results over both 1-best and lattice selftraining using our ASR channel confusion estimates on telephone conversations.",
    "creator" : "LaTeX with hyperref package"
  }
}