{
  "name" : "1301.7395.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Incremental Tradeoff Resolution in Qualitative Probabilistic Networks",
    "authors" : [ "Chao-Lin Liu" ],
    "emails" : [ "@umich.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Qualitative probabilistic reasoning in a Bayesian network often reveals tradeoffs: relationships that are ambiguous due to competing qualita tive influences. We present two techniques that combine qualitative and numeric probabilistic reasoning to resolve such tradeoffs, inferring the qualitative relationship between nodes in a Bayesian network. The first approach incremen tally marginalizes nodes that contribute to the ambiguous qualitative relationships. The sec ond approach evaluates approximate Bayesian networks for bounds of probability distributions, and uses these bounds to determinate qualitative relationships in question. This approach is also incremental in that the algorithm refines the state spaces of random variables for tighter bounds until the qualitative relationships are resolved. Both approaches provide systematic methods for tradeoff resolution at potentially lower compu tational cost than application of purely numeric methods.\n1 Introduction\nResearchers in uncertain reasoning regularly observe that to reach a desired conclusion (e.g., a decision), full pre cision in probabilistic relationships is rarely required, and that in many cases purely qualitative information (for some conception of \"qualitative\") is sufficient (Goldszmidt 1994). In consequence, the literature has admitted numer ous schemes attempting to capture various forms of quali tative relationships (Wellman 1994 ), useful for various un certain reasoning tasks. Unfortunately, we generally lack a robust mapping from tasks to the levels of precision re quired, and indeed, necessary precision is inevitably vari able across problem instances. As long as some potential problem might require precision not captured in the qualita tive scheme, the scheme is potentially inadequate for the as-\nsociated task. Advocates of qualitative uncertain reasoning typically acknowledge this, and sometimes suggest that one can always revert to full numeric precision when necessary. But specifying a numerically precise probabilistic model as a fallback preempts any potential model-specification ben efit of the qualitative scheme, and so it seems that one may as well use the precise model for everything.' This is per haps the primary reason that qualitative methods have not seen much use in practical applications of uncertain reason ing to date.\nThe case for qualitative reasoning in contexts where numer ically precise models are available must appeal to benefits other than specification, such as computation. Cases where qualitative properties justify computational shortcuts are of course commonplace (e.g., independence), though we do not usually consider this to be qualitative reasoning unless some inference is required to establish the qualitative prop erty itself in order to exploit it. Since pure qualitative in ference can often be substantially more efficient than its numeric counterpart (e.g., in methods based on infinitesi mal probabilities (Goldszmidt & Pearll992) or ordinal re lationships (Druzdzel & Henrion 1993)), it is worth explor ing any opportunities to exploit qualitative methods even where some numeric information is required.\nWe have begun to investigate this possibility for the task of deriving the qualitative relationship (i.e., the sign of the probabilistic association, defined below) between a pair of variables in a Bayesian network. From an abstracted ver sion of the network, where all local relationships are de scribed qualitatively, we can derive the entailed sign be tween the variables of interest efficiently using propagation techniques. However, since the abstraction process dis cards information, the result may be qualitatively ambigu ous even if the actual relationship entailed by the precise\n1 If the qualitative formalism is a strict abstraction, then any conclusions produced by the precise model will agree at the qual itative level. Even in such cases, qualitative models may have ben efits for explanation or justification (Henrion & Druzdzel 1991), as they can indicate something about the robustness of the conclu sions (put another way, they can concisely convey broad classes of conclusions).\nmodel is not.\nIn this paper, we report on two approaches that use qualita tive reasoning to derive these relationships without neces sarily resorting to solution of the complete problem at full precision, even in cases where purely qualitative reasoning would be ambiguous. Both approaches are incremental, in that they apply numeric reasoning to either subproblems or simplified versions of the original, to produce an interme diate model more likely to be qualitatively unambiguous.\nThe next section reviews the concepts of qualitative influ ences and tradeoffs in a network model. The third sec tion explains the incremental marginalization approach, followed by the experimental results. We then discuss the state-space abstraction approach, and conclude with a brief comparison of our approaches with some others.\n2 Qualitative probabilistic networks\n2.1 Qualitative influences\nQualitative probabilistic networks (QPNs) (Wellman 1990) are abstractions of Bayesian networks, with conditional probability tables summarized by the signs of qualitative relationships between variables. Each arc in the network is marked with a sign-positive ( + ), negative (-), or ambigu ous (?)-denoting the sign of the qualitative probabilistic relationship between its terminal nodes.\nThe interpretation of such qualitative influences is based on first-order stochastic dominance (F S D) (Fishburn & Vick son 1978). LetF(x) andF'(x) denote two cumulative dis tribution functions (CDFs) of a random variable X. Then F(x) FSD F'(x) holds if and only if (iff)\nF(x) :S F'(x) for all x. (1)\nWe say that one node positively influences another iff the latter's conditional distribution is increasing in the former, all else equal, in the sense of FSD.\nDefinition 1 ((Wellman 1990)) Let F(zjxi,Y) be the cu mulative distribution function of Z given X = Xi and the rest of Z's parent nodes Y = y. We say that node X posi tively influences node Z, denoted s+(X , Z ) , iff\n\\fxi,Xj,Y· Xi:::; Xj => F(zjxj,y) FSD F(zjxi , y).\nAnalogously, we say that node X negatively influences node Z, denoted s-(x, Z ) , when we reverse the direction of the dominance relationship in Definition 1. The arc from X to Z in that case carries a negative sign. When the dom inance relationship holds for both directions, we denote the situation by S0(X, Z ) . However, this entails conditional independence, and so we typically do not have a direct arc from X to Z in this case. When none of the preceding re lationships between the two CDFs hold, we put a question\nIncremental Tradeoff Resolution in QPNs 339\nmark on the arc, and denote such situations as S7 (X, Z ) . We may apply the preceding definitions to boolean nodes under the convention that true > false.\n2.2 Inference and tradeoff resolution\nGiven a QPN, we may infer the effects of the change in the value of one variable on the values of other variables of interest. The inference can be carried out via graph reduc tion (Wellman 1990), or qualitative propagation techniques (Druzdze1 & Henrion 1993).\nIf we are fortunate, we may acquire decisive answers from the qualitative inference algorithms. Often, however, the results of such qualitative reasoning are ambiguous. This might be because the relationship in question actually is ambiguous (i.e., nonmonotone or context-dependent), or due to loss of information in the abstraction process.\nThis can happen, for instance, when there are competing influential paths from the source node-whose value is ten tatively modified-to the target node-whose change in · value is of interest. W hile accept flu shots may decrease the probability of get flu, it also increases the probabil ity and degree of feel pain. On the other hand, increasing either get flu or feel pain decreases overall bodily well being, all else equal. As a result, qualitative reasoning about the problem of whether we should accept flu shots will yield only an ambiguous answer. The situation is illus trated by the QPN in Figure 1, where there is one positive path an� one negative path from accept flu shots to bodily well-bemg. The combination of these two paths is qualita tively ambiguous. Worse, the ambiguity of this relationship would propagate within any network for which this pattern forms a subnetwork. For example, if this issue plays a role in a decision whether to go to a doctor, the result would be ambiguous regardless of the other variables involved.\nHad we applied more precise probabilistic knowledge, such as a numerically specified Bayesian network, the result may have been decisive. Indeed, if accept flu shots and\n340 Liu and Wellman\nbodily well-being are binary, then a fully precise model is by necessity qualitatively unambiguous. However, per forming all inference at the most precise level might squan der some advantages of the qualitative approach. In the developments below, we consider some ways to apply nu meric inference incrementally, to the point where qualita tive reasoning can produce a decisive result.\nWe use the term tradeoff resolution to refer to the task of resolving the qualitatively ambiguous relationship between variables of interest. Next, we demonstrate that in the worst case, qualitative tradeoff resolution may be no easier than full numerical inference.\n2.3 Computational complexity of tradeoff resolution\nTheorem 1 Qualitative tradeoff resolution is NP-hard.\nWe show that resolving qualitative tradeoff is an NP-hard problem by reducing the problem of computing absolute approximations to the task of qualitative tradeoff resolu tion. An estimate 'Y is an absolute approximation of Pr(y) if\nPr(y) - 8 ::; 'Y ::; Pr(y) + 8,\nwhere 8 is the range of error. The problem of computing absolute approximations has been shown NP-hard (Dagum & Luby 1993).\nConsider the task of computing absolute approximations for Pr(y) in a given Bayesian network in which Y is a boolean variable. We construct a corresponding trade off resolution problem for this task as follows. The net work for this tradeoff resolution problem includes the given Bayesian network and two boolean variables D and T. The tradeoff resolution task is to determine the qualitative in fluence of D on T in the network shown in Figure 2. The cloud where Y resides represents the given Bayesian net work. We use x and x to denote that X is true and false, respectively.\nTo check the overall influence of D on T, we need to know whether Pr(tjd) � Pr(tjd). Using the data shown in the following figure, we can show that the previous inequality implies that Pr(y) ::; 1!\". Notice that the range of 1!\" is [1/2, 1] when we change c between 1 and 0. Therefore, using an efficient algorithm for tradeoff reso lution, we can efficiently determine the range of Pr(y) if its range is in [1/2, 1]. This can be done by setting c to a very small number a, and gradually setting c to multiples of a, i.e., 2a, 3a, . . . , etc. As a result, when the range of Pr(y) is in [1/2, 1], we will find a more precise range of Pr(y) by calling the efficient algorithm for tradeoff reso lution 0( �) times. Similarly, we can determine the range of Pr(y) when the range is in [0, 1/2], by calling the ef ficient algorithm for tradeoff resolution 0( �) times. This\n3 Incremental marginalization\n3.1 Node reduction\nThe idea of incremental marginalization is to reduce the network node-by-node until the result is qualitatively un ambiguous. The basic step is Shachter's arc reversal oper ation.\nTheorem 2 ((Shachter 1988)) If there is an arc from node X to node Y in the given Bayesian network, and no other directed paths from X to Y, then we may transform the network to one with an arc from Y to X instead. In the new network, X andY inherit each other's parent nodes.\nLet P x, Py, and P XY respectively denote X' s own par ent nodes, Y's own parent nodes, and X andY's com mon parent nodes in the original network, and let Py, = Py -{X}. The new conditional probability distribution ofY and X are determined by the following:\nPrnew(YiPx,PY' ,Pxy) Lx Prold(yjpy,Pxy )Prold(xipx,Pxy) Prnew(xjy,px,py,,Pxy) Pr01d(yjpy,Pxy) Prold(xiPx,Pxy)\nPrnew (y jp X' PY1 • P XY)\nOn reversing all the outgoing arcs from node X, the node becomes barren and can be removed from the network. The net effect of reversing arcs and removing barren nodes as described is equivalent to marginalizing node X from the network.\n3.2 Tradeoff resolution via node reduction\nConsider the QPN shown on the left-hand side of Figure 3. Since there exist both a positive path (through X) and a negative path (direct arc) from W to Z, the qualitative in fluence of W on Z is ambiguous. This local \"?\" would propagate throughout the network, necessarily ambiguating the relationship of any predecessor of W to any successor ofZ.\nOnce we have detected the source of such a local ambigu ity, we may attempt to resolve it by marginalizing node X.\nincremental marginauJtion\nFigure 3: Marginalizing X potentially resolves the qualita tive influence of W on Z.\nThe new sign on the direct arc from W to Z can be deter mined by inspecting the new conditional probability table of Z, given by Equation (2). If we are fortunate, the quali tative sign a1 may turn out to be decisive, in which case we have resolved the tradeoff.\nThis example illustrates the main idea of the incremental marginalization approach to resolving tradeoffs in QPNs. If we obtain an unambiguous answer to the desired qualitative relationship from the reduced network after marginalizing a selected node, then there is no need to do further com putation. If the answer is still ambiguous, we may select other nodes to marginalize. The iteration continues until a decisive answer is uncovered. We present the skeleton of the Incremental IradeQff Resolution algorithm below. The algorithm is designed to answer queries about the qualita tive influence of a decision node on a target node, using a given strategy for selecting the next node to reduce.\nAlgorithm 1 /TOR( decision, target, strategy)\n1. Remove nodes that are irrelevant to the query about decision's influence on target (Shachter 1988)."
    }, {
      "heading" : "2. Attempt to answer the query via qualitative inference",
      "text" : "(Druzdzel & Henrion 1993)."
    }, {
      "heading" : "3. If the answer to the query is decisive, exit; otherwise continue.",
      "text" : "4. Select a node to reduce according to strategy. If there is no node that can be reduced, return \"? \" , else per form the node reduction, and calculate the qualitative abstractions of the transformed relationships. Return to Step 2.\nWe expect the incremental approach to improve perfor mance over purely numeric inference on average. Since qualitative inference is quadratic whereas exact inference in Bayesian networks is exponential in the worst case, the qualitative inference steps do not add appreciably to com putation time. On the other hand, when the intermediate results suffice to resolve the tradeoff, we save numeric com putation over whatever part of the network is remaining.\n3.3 Prioritizing node reduction operations\nThe objective of carrying out node-reduction operations in ITOR is to resolve qualitative tradeoffs. The optimal strate-\nIncremental Tradeoff Resolution in QPNs 341\ngies for respective tasks will differ, in general. For exam ple, a node that is very expensive to reduce at a certain stage of the evaluation might be the best prospect for resolving the tradeoff.\nWe exploit intermediate information provided in qualita tive belief propagation (Druzdzel & Henrion 1993) in de termining which node to reduce next. If we can propagate a decisive qualitative influence from the decision node D all the way to the target node T, we will be able to answer the query. Otherwise, there must be a node X that has an in decisive relationships from D. Recall that we have pruned nodes irrelevant to the query, so any nodes that have indeci sive relationship with D will eventually make the relation ship between D and T indecisive. We have identified sev eral conceivable strategies based on this observation, and have tried two of them thus far.\nThe first strategy is to reduce node X, as long as X is not the target node T. When X is actually T, we choose to reduce the node Y that passed the message to X changing its qualitative sign from a decisive one to \"?\". However, this Y cannot be D itself. If it is, then either (1) there are only two nodes remaining in the network, and there is no decisive answer to the query, or (2) there are other nodes, and we randomly pick among those adjacent to D or T.\nThe second strategy is similar to the first, except that we exchange the priority of reducing X andY. We handle the situations where X and/or Y happen to be D and/or T in the same manner as in the first strategy.\nThese strategies have the advantage that finding the next node to reduce does not impose extra overhead in the ITOR algorithm. The selection is a by-product of the qualitative inference algorithm. However neither of these strategies (nor any that we know) is guaranteed to minimize the cost of resolving the tradeoff.\n4 Experimental study\nWe have tested the effectiveness of the algorithm using ran domly generated network instances. The experiments are designed to examine how connectivity of the network, sizes of state spaces, and strategies for scheduling node reduction affect the performance of the algorithm.\n4.1 Generating random networks\nIn the experiments, we use Bayesian networks in which arcs can be assigned decisive qualitative signs. To this end, we construct QPNs with only decisive signs on arcs, and then use the signs to govern the way we assign condi tional probability values for nodes in their corresponding Bayesian network. The conditional probability distribu tions of nodes and the qualitative signs on arcs must agree with each other.\n342 Liu and Wellman\nTo create a random QPN with n nodes and l arcs, we first create a complete directed acyclic graph (DAG) with n nodes. Each arc in this DAG is assigned a random num ber that is sampled from a uniform distribution. We then attempt to remove the arc with the largest assigned num ber, under the constraint that the DAG remains connected. If removing the arc with the largest assigned number will make the DAG disconnected, we will attempt to remove the arc with the next largest number. We remove arcs until the DAG contains only l arcs. After creating the network structure, we randomly assign qualitative signs (positive or negative) to the arcs.\nWe then build a Bayesian network that corresponds to the generated QPN, that is, respects its structure and qualita tive signs. We select the cardinality of each node by sam pling from a uniform distribution over the range [2,MC], where MC denotes the maximum state-space cardinality. For nodes without parents, we assign prior probabilities by selecting parameters from a uniform distribution and then normalizing.\nFor a node X with parent nodes PA(X), the qualitative signs in the QPN dictate a partial ordering of the con ditional probability distributions for various values of X, where the distributions are ordered based on the FSD relationship. Let pai(X) denote an instantiation of the parent nodes of X. To enforce this ordering, we iden tify the pai (X) that requires us to make the distribution F(x jpai (X)) dominate distributions F(xjpaj (X)) for all otherpaj (X). We assign the parameters for F(x jpai (X)) (as for priors) by sampling from a uniform distribution. We then assign the remaining distributions in stages, at each stage setting only those distributions dominated by the pre viously assigned distributions. We make these assignments using the same random procedure, but under the constraint that the resulting distribution must respect the qualitative signs given the previous assignments.\n4.2 Results\nIn each experiment, we specify the number of nodes, the number of arcs, and maximum cardinality of state spaces for the randomly generated networks. In all experiments, we create networks with I 0 nodes before pruning. We query the qualitative influence from the node1 to node1 0, and disregard the instances in which the answer is ambigu ous after exact evaluation of the network.\nSince the first step of the ITOR algorithm prunes nodes ir relevant to the query, the network actually used in inference is usually simpler than the original network. In Table 1, we record the average number of nodes and links after the pruning step. MC denotes maximum cardinality. All ex periments reported used the first node selection strategy; results from the second strategy were virtually identical.\nWe measure the performance of ITOR with two metrics. The first metric, Rnodes• is the ratio of the number of re duced nodes when the decisive answer is found to the num ber of nodes that would be reduced in exact numerical eval uation. The second metric, Rreversals, is the ratio of num ber of arc reversal operations already done when the solu tion is found to the number of arc reversal operations that would be carried out for exact numerical evaluation. The latter figure is based on an arbitrary strategy for reducing the remaining network after the tradeoff is resolved, how ever, and so would tend to be an optimistic estimate of the saving. Table 1 reports averages for each metric. The sav ings due to incremental tradeoff resolution are 1 - Rnodes and 1 - Rreversals, respectively, and so lower values of the metrics indicate better performance.\nThe results in Table 1 suggest that ITOR offers greater performance for sparsely connected networks and smaller state spaces. Further experimentation may lead us to more precise characterization of the expected savings achievable through incremental marginalization.\n5 State-space abstraction\nRecall that qualitative relationships are defined based on the concept of first-order stochastic dominance defined by (1). Since only qualitative relationships among variables are of interest, exact calculation of the values of the CDFs may not be necessary if we can use approximate CDFs to determine whether F S D holds.\nIn previous work, we report an iterative state-space ab straction (ISSA) algorithm for approximate evaluation of Bayesian networks (Wellman & Liu 1994). The ISSA al gorithm aggregates states of selected variables, called ab stracted nodes, into superstates to construct abstract ver sions of the original Bayesian networks (OBNs) that spec ify exact probability distributions. The aggregation of states requires the reassignment of the conditional proba bility tables (CPTs) of both the abstracted nodes and their child nodes. We call the method used in this assignment task a CPT assignment policy. These abstract Bayesian networks (ABNs) are then used to compute point-valued approximations of the probability distributions of interest. As a result of the abstraction operations, the computational cost of evaluating the ABNs can be less than that of evalu ating the OBNs. The algorithm iteratively refines the state\nspaces of the selected abstracted nodes for improving the quality of approximations, when the allocated computation time permits.\nIn this section, we introduce a new policy for computing bounds of probability distributions, and apply the revised ISSA algorithm to resolving ambiguous qualitative rela tionships.\n5.1 Motivation and definitions\nConsider the task of determining whether F(xldi) dom inates F(xidj) . Assume that we have ways to con trol approximation methods to obtain approximate CDFs F(xldi) and F(xidj) such that F(xldi) ::::; F(xldi) and F(xidj) ::::; F(xidj) for all x. Given these approximate CDFs, F(xidi) FSD F(xidj) will hold if we also have F(xidi) ::::; F(xid1) for all x. In other words, it is possible to determine qualitative relationship using bounds of prob ability distributions. We define bounds ofCDFs as follows.\nDefinition 2 A CDF F(x) is an upper bound of F(x) , if F(x) ::::; F(x) for all x. A CDF F(x) is a lower bound of F(x) , if F(x) ::::; F(x) for all x.\nIn terms of these definitions, s-(D, X) holds if there exist F(xidi) and F(xidj) such that\nfor all x, di < d1 => F(xidi) ::::; F(xidj) · (2)\nSimilarly, s+ (D, X) holds if there exist F(xid1) and F(xidi) such that\nfor all x, di < dj => F(xidj) ::::; F(xldi) · (3) In addition, we may be able to tell that D neither positively nor negatively influences T by examining bounds. Specifi cally, a sufficient condition for 87 (D, X) is that there exist Xr, X8, and bounds such that, for some di < dj,\nF(xrldi) < F(xrldj) and F(xsldj) < F(xsldi) · (4) When (4) holds, the curves for F(xidi) and F(xidj) must intersect as illustrated in the following figure.\n5.2 Bounding probability distributions\nWe may compute bounds of conditional probability distri butions by using an ISSA algorithm that applies the domi nance policy in aggregating states of abstracted nodes (Liu\nIncremental Tradeoff Resolution in QPNs 343\n& Wellman 1998). Let PA(A) be the set of parent nodes of an abstracted node A, and [ai,Jl the superstate represent ing the aggregation of states from ai through a1, i ::::; j. The dominance policy modifies the CPT of A as follows:\nj Pr([ai,j]ipa(A)) = L Pr(akipa(A)).\nk=i\nLet Y be a child node of A, and P X (Y) be the subset of parent nodes of Y excluding A. Depending on whether we want to compute lower or upper bounds of selected CDFs, we strengthen or weaken the conditional probability dis tribution of Y given its parent nodes. To strengthen the distribution, we assign F(yi[ai,j],px(Y)) as follows:\nF(yi[ai,j],px(Y)) = m�� F(yiaz,px(Y)). IE[t,J)\nTo weaken the distribution, we assign F(yi[ai,j],px(Y)) as follows:\nF(yi[ai,j],px(Y)) = m� F(yiaz,px(Y)). IE[•,J)\nWe have identified and reported conditions under which the ISSA algorithm may compute bounds of conditional probability distributions (Liu & Wellman 1998). Taking advantage of qualitative relationship and conditional inde pendence among variables, we can compute lower and up per bounds of desired conditional probability distributions.\n� + D A� + .. '1\nFigure 5: We may use qualitative relationships for bound ing probability distributions.\nConsider the network in Figure 5. We have (a) Y1 pos itively influences X given D and Y2, (b) Y2 negatively influences X given D and Y1, (c) X and A are indepen dent given D, Y1, and Y2, (d) [D,A,Y1,Y2] is an an cestral ordering, and (e) Y1 is not a descendant of Y2 and vice versa in the network. An ordering [ J1, J2, ... , Jn) of nodes in a set of nodes J is an ancestral ordering if, for every Ji E J, all the ancestors of Ji are ordered before Ji. Given these conditions, we can compute the bounds of F(xid) when we abstract A with the dominance policy. Specifically, we obtain lower (upper) bounds of F(xid) by weakening (strengthening) F(y1ia, y2) and strengthening (weakening) F(y2ia, y1) with respect to A when we ab stract A. In addition, We can obtain lower (upper) bounds of F(xid) by strengthening (weakening) F(xiy 1) with re spect to Y1 when we abstract Y1, given that (a) [D, y1, X]\n344 Liu and Wellman\nis an ancestral ordering and (b) X is the only child node of Y1• Analogously, we may abstract Y2 in computing bounds of F(xid) to further reduce computation time.\nIn addition, we have shown that bounds computed by the ISSA algorithm tighten as we refine the state space of the abstracted nodes (Liu & Wellman 1998). Therefore, we are more likely to resolve qualitative tradeoffs as we carry out more iterations of the ISSA algorithm. The computation can terminate whenever we determine the qualitative rela tionship of interest.\n5.3 Tradeoff resolution via approximation\nAs we discussed in Section 3.3, if the relationship between D and T is ambiguous, there must be a node X such that X is marked with \"?\" when we propagate the sign from D toward T. As an alternative to incremental marginaliza tion, we may apply any approximate evaluation algorithm for Bayesian networks in Step 4 of ITOR, if the approxima tion algorithm can return bounds of conditional probability distributions. We use ISSA with the dominance policy as such an alternative in the following discussion.\nUsing the ISSA algorithm with dominance policy can save computation time for the tradeoff resolution task. As men tioned, the ISSA algorithm may find the correct qualitative relationship by the time it needs to exactly evaluate F(xid) using the conditions specified in (2) to (4). In addition, the ISSA algorithm may compute the bounds of F(xid) by evaluating a portion of the given Bayesian network. For in stance, T in Figure 5 is barren and can be ignored for the computation of F(xid).\nNotice that we should not terminate ITOR when ISSA re turns a\"?\" for the relationship of D and X in Step 4. When this occurs, we need to continue ITOR as usual. It is pos sible that we find a decisive relationship between D and T even when some nodes in the network have ambiguous re lationship with D. For instance, using ISSA, we might find that D positively influences T even if D neither negatively nor positively influences X in the network shown in the following figure. Therefore, ITOR should run until either a decisive relationship between D and T has been found in Step 2 or an ambiguous relationship between D and T is confirmed by ISSA in Step 4.\n? . .... ® +\nample. Assume that we find that D negatively influences X in Figure 5 by exactly computing the values of F(xid), and that we are about to use the ISSA algorithm to deter mine the qualitative relationship between D and T. In this case, if we do not reuse previous results, we may abstract A, Y1, Y2, and X in computing the bounds of F(t!d) in Step 4. However, given that CI(T, {D,X}, {A, Y1, Y2}) and that we have computed the exact values of F(xid), the network has been reduced to the one shown in the follow ing figure. Therefore, we could save computation time by running ISSA over the network in Figure 7, and should not. run ISSA over the network in Figure 5 from scratch.\nFigure 7: Reduced version of the network in Figure 5.\nW hether we reuse the information about the bounds that are obtained from running ISSA is a design issue. For in stance, assume that we find that D negatively influences X in Figure 5 by applying (2). Given this result, the qualita tive relationship between D and T is still ambiguous since there are still two competing influential paths from D to T as indicated in Figure 7. Upon locating this ambiguity, ITOR uses ISSA to resolve the ambiguity, and the issue is whether we reuse the information we have about F(xid) that is obtained from the previous execution of ISSA. Given that CI(T,{D,X},{A,Y1,Y2}) and that D decisively influences X in the network, a heuristic is that we use the knowledge about F(xid) obtained in the previous run of ISSA first. To do so, we set the conditional probability of X given D according to bounds of F(xld) in the network shown in Figure 7, and use this approximate network for re solving the ambiguity. If this opportunistic approach does not resolve the qualitative ambiguity between D and T, we then use ISSA to evaluate a network that includes A, Yl and Y2. Another alternative is to directly compute bounds of F(tid) using the original network. It is possible that we can resolve the ambiguity when A, Yl, Y2, and X have very small number of states in ISSA. The optimal choice for this design issue varies from network to network, de pending on ·their underlying probability distributions.\n6 Discussion\nWe have shown that resolving qualitative tradeoff is NP hard, and have discussed the application of incremen tal marginalization and state-space abstraction methods to the qualitative tradeoff resolution task. The incremental marginalization approach iteratively reduces a node in the network, and the state-space abstraction approach approx imately evaluates a portion of the network. Initial exper-\niments with incremental marginalization suggest that no ticeable savings are possible, but definitive evaluation of both methods awaits further empirical and theoretical in vestigation.\nThe incremental marginalization approach bears some sim ilarity to symbolic probabilistic inference, as in the vari able elimination (VE) algorithm (Zhang & Poole 1996), in that we sum out one node from the Bayesian network at a time. The ITOR algorithm differs from the VE algorithm in the determination of the elimination ordering, and of course in the stopping criterion.\nParsons and Dohnal (1993) discuss a semiqualitative ap proach for inference using Bayesian networks. The basic idea is similar to state-space abstraction. The center of their work is to design calculus for computing the the prob ability intervals of variables, and their methods may work even when the conditional probabilities in Bayesian net works are not completely specified. However, their meth ods cannot be applied to the qualitative tradeoff resolution task. Parsons (1995) also exploits more special numerical relationships among variables to define new qualitative re lationships for refining inference in QPN.\nThere are other approaches that make use of numerically specified knowledge in qualitative inference. For instance, Kuipers and Berleant (1988) apply incompletely specified numerical information in qualitative inference tasks.\nThe incremental approaches we propose in this paper pro vide systematic ways to resolving qualitative tradeoffs at potentially lower computational cost than fully pre cise methods. Empirical results suggest that incremental marginalization can provide savings for some networks. How to use qualitative information to guide the schedul ing of node reduction and how to reuse partial results ob tained from approximate evaluation of Bayesian networks to achieve the best performance possible remain as open problems for future work.\nReferences\nDagum, P., and Luby, M. 1993. Approximating proba bilistic inference in Bayesian belief networks is NP-hard. Artificial Intelligence 60:141-153.\nDruzdzel, M. J., and Henrion, M. 1993. Efficient reason ing in qualitative probabilistic networks. In Proceedings of the Eleventh National Conference on Artificial Intelli gence, 548-553.\nFishburn, P. C., and Vickson, R. G. 1978. Theoretical foundations of stochastic dominance. In Whitmore, G. A., and Findlay, M. C., eds., Stochastic Dominance: An Ap proach to Decision Making Under Risk, 39-113. Lexing ton, MA: D. C. Heath and Company.\nGoldszmidt, M., and Pearl, J. 1992. Reasoning with qual-\nIncremental Tradeoff Resolution in QPNs 345\nitative probabilities can be tractable. In Proceedings of the Eighth Conference on Uncertainty in Artificial Intelli gence, 112-120.\nGoldszmidt, M. 1994. Research issues in qualitative and abstract probability. AI Magazine 15(4):63-65.\nHenrion, M., and Druzdzel, M. J. 1991. Qualitative prop agation and scenario-based approaches to explanation of probabilistic reasoning. In Bonissone, P.; Henrion, M.; Kanal, L.; and Lemmer, J., eds., Uncertainty in Artificial Intelligence 6. North Holland: Elsevier. 17-32.\nKuipers, B., and Berleant, D. 1988. Using incomplete quantitative knowledge in qualitative reasoning. In Pro ceedings of the Seventh National Conference on Artificial Intelligence, 324-329.\nLiu, C.-L., and Wellman, M.P. 1998. Using qualitative re lationships for bounding probability distributions. In Pro ceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence.\nParsons, S. 1995. Refining reasoning in qualitative proba bilistic networks. In Proceedings of the Eleventh Confer ence on Uncertainty in Artificial Intelligence, 427-433.\nParsons, S., and Dohnal, M. 1993. A semiqualitative approach to reasoning in probabilistic networks. Applied Artificial Intelligence 7:223-235.\nShachter, R. D. 1988. Probabilistic inference and influ ence diagrams. Operation Research 36(4):589-604.\nWellman, M. P. 1990. Fundamental concepts of qualita tive probabilistic networks. Artificial Intelligence 44:257- 303.\nWellman, M. P. 1994. Some varieties of qualitative prob ability. In Proceedings of the Fifth International Confer ence on Information Processing and Management of Un certainty in Knowledge-Based Systems, 437-442.\nWellman, M. P., and Liu, C.-L. 1994. State-space abstrac tion for anytime evaluation of probabilistic networks. In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, 567-574.\nZhang, N. L., and Poole, D. 1996. Exploiting causal independence in Bayesian network inference. Journal of Artificial Intelligence Research 5:301-328."
    } ],
    "references" : [ {
      "title" : "Approximating proba­ bilistic inference in Bayesian belief networks is NP-hard",
      "author" : [ "P. Dagum", "M. Luby" ],
      "venue" : "Artificial Intelligence 60:141-153.",
      "citeRegEx" : "Dagum and Luby,? 1993",
      "shortCiteRegEx" : "Dagum and Luby",
      "year" : 1993
    }, {
      "title" : "Efficient reason­ ing in qualitative probabilistic networks",
      "author" : [ "M.J. Druzdzel", "M. Henrion" ],
      "venue" : "Proceedings of the Eleventh National Conference on Artificial Intelli­ gence, 548-553.",
      "citeRegEx" : "Druzdzel and Henrion,? 1993",
      "shortCiteRegEx" : "Druzdzel and Henrion",
      "year" : 1993
    }, {
      "title" : "Theoretical foundations of stochastic dominance",
      "author" : [ "P.C. Fishburn", "R.G. Vickson" ],
      "venue" : "Whitmore, G. A., and Findlay, M. C., eds., Stochastic Dominance: An Ap­ proach to Decision Making Under Risk, 39-113. Lexing­ ton, MA: D. C. Heath and Company.",
      "citeRegEx" : "Fishburn and Vickson,? 1978",
      "shortCiteRegEx" : "Fishburn and Vickson",
      "year" : 1978
    }, {
      "title" : "Reasoning with qual",
      "author" : [ "M. Goldszmidt", "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "Goldszmidt and Pearl,? \\Q1992\\E",
      "shortCiteRegEx" : "Goldszmidt and Pearl",
      "year" : 1992
    }, {
      "title" : "Research issues in qualitative and",
      "author" : [ "M. Goldszmidt" ],
      "venue" : null,
      "citeRegEx" : "Goldszmidt,? \\Q1994\\E",
      "shortCiteRegEx" : "Goldszmidt",
      "year" : 1994
    }, {
      "title" : "Refining reasoning in qualitative proba­",
      "author" : [ "S. Parsons" ],
      "venue" : null,
      "citeRegEx" : "Parsons,? \\Q1995\\E",
      "shortCiteRegEx" : "Parsons",
      "year" : 1995
    }, {
      "title" : "A semiqualitative",
      "author" : [ "S. Parsons", "M. Dohnal" ],
      "venue" : null,
      "citeRegEx" : "Parsons and Dohnal,? \\Q1993\\E",
      "shortCiteRegEx" : "Parsons and Dohnal",
      "year" : 1993
    }, {
      "title" : "Probabilistic inference and influ­",
      "author" : [ "R.D. Shachter" ],
      "venue" : null,
      "citeRegEx" : "Shachter,? \\Q1988\\E",
      "shortCiteRegEx" : "Shachter",
      "year" : 1988
    }, {
      "title" : "Fundamental concepts of qualita­",
      "author" : [ "M.P. Wellman" ],
      "venue" : null,
      "citeRegEx" : "Wellman,? \\Q1990\\E",
      "shortCiteRegEx" : "Wellman",
      "year" : 1990
    }, {
      "title" : "Some varieties of qualitative prob­",
      "author" : [ "M.P. Wellman" ],
      "venue" : null,
      "citeRegEx" : "Wellman,? \\Q1994\\E",
      "shortCiteRegEx" : "Wellman",
      "year" : 1994
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "Qualitative probabilistic networks (QPNs) (Wellman 1990) are abstractions of Bayesian networks, with conditional probability tables summarized by the signs of qualitative relationships between variables.",
      "startOffset" : 42,
      "endOffset" : 56
    }, {
      "referenceID" : 8,
      "context" : "Definition 1 ((Wellman 1990)) Let F(zjxi,Y) be the cu­ mulative distribution function of Z given X = Xi and the rest of Z's parent nodes Y = y.",
      "startOffset" : 14,
      "endOffset" : 28
    }, {
      "referenceID" : 8,
      "context" : "The inference can be carried out via graph reduc­ tion (Wellman 1990), or qualitative propagation techniques (Druzdze1 & Henrion 1993).",
      "startOffset" : 55,
      "endOffset" : 69
    }, {
      "referenceID" : 7,
      "context" : "Theorem 2 ((Shachter 1988)) If there is an arc from node X to node Y in the given Bayesian network, and no other directed paths from X to Y, then we may transform the network to one with an arc from Y to X instead.",
      "startOffset" : 11,
      "endOffset" : 26
    }, {
      "referenceID" : 7,
      "context" : "Remove nodes that are irrelevant to the query about decision's influence on target (Shachter 1988).",
      "startOffset" : 83,
      "endOffset" : 98
    } ],
    "year" : 2011,
    "abstractText" : "Qualitative probabilistic reasoning in a Bayesian network often reveals tradeoffs: relationships that are ambiguous due to competing qualita­ tive influences. We present two techniques that combine qualitative and numeric probabilistic reasoning to resolve such tradeoffs, inferring the qualitative relationship between nodes in a Bayesian network. The first approach incremen­ tally marginalizes nodes that contribute to the ambiguous qualitative relationships. The sec­ ond approach evaluates approximate Bayesian networks for bounds of probability distributions, and uses these bounds to determinate qualitative relationships in question. This approach is also incremental in that the algorithm refines the state spaces of random variables for tighter bounds until the qualitative relationships are resolved. Both approaches provide systematic methods for tradeoff resolution at potentially lower compu­ tational cost than application of purely numeric methods.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}