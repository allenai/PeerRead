{
  "name" : "1409.6440.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "A non-linear learning & classification algorithm that achieves full training accuracy with stellar classification accuracy",
    "authors" : [ "Rashid Khogali", "Anastasios N. Venetsanopoulos" ],
    "emails" : [ "rkhogali@ryerson.ca,", "khogali@alumni.utoronto.ca" ],
    "sections" : [ {
      "heading" : null,
      "text" : "This is a raw manuscript proposed and submitted by the author to the EE8209 Course Instructor in Winter 2012. EE8209 Course Instructor: Prof. Anastasios N. Venetsanopoulos.\nCopyright © 2014, by the author. All rights reserved.\nContents Pg. 1 Introduction 1\n1.1 Algorithm Validation 1\n2 Introducing the (R.R.E) Algorithm 1\n2.1 Brainstorming 1 2.2 Preliminary Definitions 2 2.3 The Monotonically Decreasing Weight Function 2 2.4 Introducing Cost (P) 3 2.5 Introducing Variance 4 2.6 Introducing the Auxiliary Sensitivity Factor (な) 4 2.7 Prediction Capabilities of Discriminant Function 5 2.8 Naming & Defining the Classification Algorithm 5 2.9 Potential Optimization 6 2.9.1: The possible need for ‘filtering’ the training data 6 2.10 R.R.E Algorithm Impervious to Noisy Training Environments 7 2.11 R.R.E Algorithm Validation 8\n3 Comparing R.R.E to P.C.A 9\n3.1: Using “iris_setosa_versicolor” Dataset 9 3.2: Applying R.R.E to the “iris_setosa_versicolor” Dataset 9 3.3: Applying P.C.A to the “iris_setosa_versicolor” Dataset 14 3.4: Using “Iris_Versicolor_VirginicaV2” Dataset 19 3.5: Applying R.R.E Algorithm to the “Iris_Versicolor_VirginicaV2” Dataset 20 3.6: Applying P.C.A to the “Iris VersicolorVirginicaV2” Dataset 22 3.7: Overall Comparison 23\n4 Comparing R.R.E to Linear Support Vector Machines 25\n4.1: Preliminary 25 4.2: Applying R.R.E Algorithm to the “Support1” Dataset 26 4.3: Applying Linear S.V.M to the “Support1” Dataset 27 4.4: Applying R.R.E Algorithm to the “Support2” Dataset\nVersus L.S.V.M & Fisher Linear Discriminant 29 5 Comparing R.R.E to a 2-2-1 Neural Network in application to the XOR Problem 31\n5.1: Applying R.R.E Algorithm to the XOR problem 32 5.2: Solving the XOR problem using a 2-2-1 Neural Network 35 5.3: Overall Comparison 38\n6 Conclusion 39 7 Acknowledgments 40 8 References 40 9 Appendices 45 Appendix B1: “iris_setosa_versicolor” Normalized & Augmented Row Vectors 41\nAppendix B2: “iris_versicolor_virginicaV2” Normalized & Augmented Row Vectors 42 Appendix B3: “Support1” Normalized & Augmented Row Vectors 43"
    }, {
      "heading" : "1 Introduction",
      "text" : "In this study, a non-iterative algorithm named the \"Reverse Ripple algorithm (R.R.E)\" is synthesized and validated using numerical simulations conducted in MATLAB. The R.R.E algorithm is a classification algorithm that achieves 100% learning/training accuracy and stellar classification accuracy even with limited training data. This algorithm achieves stellar results when data is categorically separable (linearly as well as non-linearly separable). The algorithm is modifiable such that it is able to:\n• classify based on cost • classify based on the multi-category case • operate on an un-supervised mode after limited\nsupervised training\nThese modifications above are not explored much due to the constrained scope of the paper. A major drawback of the algorithm is that it is computationally expensive upon classifying data when the training data is large hence it requires substantial further optimization."
    }, {
      "heading" : "1.1 Algorithm Validation",
      "text" : "The R.R.E algorithm is compared to the P.C.A (Perceptron Criterion Algorithm [7]) using two types of datasets. It is then compared to Linear Support Vector Machines [2] on two types of data sets as well. Lastly, it is compared to a Neural Network ([3],[6]) of comparable complexity for a non-linearly separable case (XOR problem). Due to a time constraint imposed on the paper, Bootstrapping, Bagging, and Boosting validation techniques were not used, but instead, a variation of the S-fold cross validation technique was employed to validate the algorithm in comparison to the P.C.A. See [1]and [3] for details on the Perceptron Criterion Algorithm, Linear Support Vector machines, the Linear Fisher Discriminant ([5]) and Neural Networks."
    }, {
      "heading" : "2 Introducing the (R.R.E) Algorithm",
      "text" : ""
    }, {
      "heading" : "2.1 Brainstorming",
      "text" : "Let us attempt to superimpose any monotonically decreasing weight function at all training set points, intuitively this makes sense as it increases the weight of properly classifying a test point that is radially close to a known training point. The idea is we are using training\npoints as our evidence and associating a modified distance (dissimilarity) between a test point and neighbourhood training points as our criteria of categorizing a test point. The smaller the distance or dissimilarity, it is more likely that a test point belongs to a region that is dominated or heavily populated by the training data in question and the larger the distance, the unlikely the training point belongs to that region; this explains why the weight functions have to monotonically decrease as directed by our intuition. We also know that initially our training set is small, so the variances of our weight functions should be huge to maximize the known entropy/known information even if it means that we may poorly classify regions that are very far from training data - this is the price we pay for having little information. As our training set grows, we can afford to reduce the variance of our weight functions and make more accurate decisions based on smaller distances that are associated with high confidence levels. Let us introduce mathematical syntax to better capture the idea being proposed."
    }, {
      "heading" : "2.2 Preliminary Definitions",
      "text" : "Due to the limited scope of the paper, we only consider the two category case, but the reader is advised that the algorithm can effortlessly be extended to the multicategory case.\nLet 1T and 2T be the set of all training points associated with category 1W and category 2W respectively, where 1Txi ∈ and 2Tx j ∈ . Let kV be the set of all test/verification data\nwhere kk Vx ∈ ."
    }, {
      "heading" : "2.3 The Monotonically Decreasing Weight Function",
      "text" : "Let (x)Wm be the monotonically decreasing weight\nfunction. A good hunch is to let (x)Wm be Gaussian, but other desirable choices would be the decay exponential or the hyperbolic function. We stick to the Gaussian for now because the central limit theorem tells us that the sum of I.I.D random variables converge to a Gaussian; if we treat a specific training point as a Bernoulli R.V with respect to categorization (w1 or w2), without any prior information, it can have us to believe that the sum of many future testing points that converge in the neighbourhood or vicinity of that training point may behave more and more like the normal distribution.\nSo (x)Wm = 2xe− .\nNext we superimpose (x)Wm at all training set points.\nFrom signal processing, this operation is a convolution\noperation between (x)Wm and a delta functions centred at testing points. Superposition is a great idea because it is a suitable way to consider multiple responses simultaneously. So the category 1 is classified by the influence of:\n(x)Wm *∑ − i ixx )(δ , 1Txi ∈∀ (1)\nLikewise, the category 2 is classified by the influence of:\n(x)Wm *∑ − j jxx )(δ 2Tx j ∈∀ (2)\n(1) can be written as: ∑ − i im xxW )( , 1Txi ∈∀ (3) (2) can be written as: ∑ − j jm xxW )( , 2Tx j ∈∀ (4)\nWe can write the equations above in more explicit forms.\nWriting (3) in more explicit form is: ∑ −−− i xxxx i t ie )()( , 1Txi ∈∀ Writing (4) in more explicit form is: ∑ −−− j xxxx j t je )()( , 2Tx j ∈∀\nWe can now come up with a skeleton Discriminant function G(x) that takes the testing points xk as its argument.\nG(xk) = ∑ −−− i xxxx ik T ike )()( - ∑ −−− j xxxx jk T jke )()( , 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈\n• If G(xk)>0 we categorize xk as category w1 • If G(xk)<0 we categorize xk as category w2 • If G(xk)= 0, we reject xk or we toss a coin (a joke)"
    }, {
      "heading" : "2.4 Introducing Cost (P)",
      "text" : "The nice thing about our Discriminant function above is it allows us to introduce cost in so many ways. Let us keep it simple. Assuming a linear fixed cost, p1 associated with choosing w1 and a linear fixed cost p2 associated with choosing category w2, we can modify our Discriminant function as follows:\n=)( kxG 2p ∑ −−− i xxxx ik T ike )()( - 1p ∑ −−− j xxxx jk T jke )()( , 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈\nNotice that p2 enters the influencing factor for category 1 and vice versa because a high linear cost of category 2 should boost the picking/selection of category 1. Depending on the nature of the cost, it can also be simultaneously or separately introduced in the exponential argument, but we will ignore this for now, but keep in mind that we can introduce multiple types of costs simultaneously with different degrees of influence."
    }, {
      "heading" : "2.5 Introducing Variance",
      "text" : "Let in be the number of 1Txi ∈∀ and let jn be the number of\n2Tx j ∈∀ .\nThe reason we split in and jn instead of using ji nn + is\nbecause we need to give a fair chance to either category in the event that the training data is biased (we are indirectly mitigating (potential) sample-model error). Next, let f(n) be any increasing function of n. we are trying to grow f(n) with n. The exact family of functions for n that does a good job is unknown for now and suggest it could possibly be derived empirically. So we will leave f(n) in its implicit form. Introducing a dynamic variance as opposed to assuming a fixed variance, we modify the Discriminant function as follows:\n∑∑ −−−−−− −= j xxxxnf i xxxxnf k jk T jkjik T iki epepxG )())(( 1 )())(( 2)( , 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈"
    }, {
      "heading" : "2.6 Introducing the Auxiliary Sensitivity Factor (λ)",
      "text" : "When we are not concerned about over-fitting, but we want our Discriminant function to obtain outputs that are arbitrarily close to our training data, we can use a sensitivity 1>>λ . In the modified Discriminant function below:\n∑∑ −−−−−− −= j xxxxnf i xxxxnf k jk T jkjik T iki epepxG )())(( 1 )())(( 2)( λλ , 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈\nThe larger the λ , the less we take advantage of mutual information between neighbouring data points and each\ntraining point becomes more isolated like a delta function, hence we are able to retrieve any training value with minimal interference from neighbouring training values. For much of this paper, we will eliminate the sensitivity factor and assume a unitary value for now to avoid over fitting. We will reintroduce it again in section 3.5 to demonstrate that the algorithm is capable of achieving 100% learning/training accuracy with an adjusted λ ."
    }, {
      "heading" : "2.7 Prediction Capabilities of Discriminant Function",
      "text" : "The Discriminant function of R.R.E algorithm has a quantitative interpretation. Under unitary categorical cost, when evaluated at a test point, it tells us roughly the number of training points(and/or fraction of a training point)that lie in the ‘vicinity’ of a test point. The larger the absolute value of the Discriminant function evaluated at a test point, the better the confidence level of the prediction/classification. In fact, in-light of this insight, we can choose to discard output values of the Discriminant functions that do not meet a reliable threshold, where the threshold can be empirically derived depending on the application. Implementing this threshold would improve the accuracy of classification but introduces a rejection set - which warrants require further consideration."
    }, {
      "heading" : "2.8 Naming & Defining the Classification Algorithm",
      "text" : "Lets name the algorithm the ‘Reverse-ripple Effect’ algorithm (R.R.E) because each training point is like a ‘water ripple’ with a Gaussian like function superimposed on it, but unlike a water ripple, its variance becomes smaller as more training points are introduced. i.e the radial Gaussian variance decreases hence ‘reverses’ unlike a true ripple seen in water which actually expands with time. The R.R.E algorithm is a multi-part algorithm. For most classification applications, we only require Part(A) followed by Part(C).\n(A) Training:\n• Start of with some training sets T1 and T2. • Prepare xk (test point) • Find n1 and n2 (number of points in T1 and T2 respectively.\n• Evaluate f(n1) and f(n2)(can assume f(n) = n and 1=λ ) • Construct the Discriminant below:\n∑∑ −−−−−− −= j xxxxnf i xxxxnf k jk T jkjik T iki epepxG )())(( 1 )())(( 2)( λλ , 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈\n(B) Extra supervised training (rarely needed in practice)\n• use )( TxG above to classify all 21 TTxT U∈\n• If any Tx is misclassified, redundantly include Tx in the correct training set (in appropriate T1 or T2)\nand/or adjust λ (the auxiliary sensitivity factor) • Re-construct )( kxG with updated T1 and T2 • Stop when )( TxG correctly classify all 21 TTxT U∈\n(C) Classifying (predictor)\nUse )( kxG to classify any or all kk Vx ∈\n(D) Classifying with further (unsupervised) learning\n• Use )( kxG above to classify kk Vx ∈\n• put xk in T1 if xk was classified as w1 and otherwise, put xk in T2. • Re-construct )( kxG with updated T1 and T2\n• Repeat for all kk Vx ∈ Note for Part D only: The memory requirements grow linearly with every test point that is included in the training set and can be stopped once sufficient test data has been incorporated into training data. For most classification applications and for the rest of this paper, we safely assume that the R.R.E Algorithm is Part(A) followed by Part(C) only."
    }, {
      "heading" : "2.9 Potential Optimization",
      "text" : "2.9.1: The possible need for ‘filtering’ the training data The memory requirements of the Discriminant function grows linearly with every training point that it uses. Classification becomes computationally expensive when the\ntraining set 21 TT U is large. One way to fix this without much elaboration is; after part A or Part B of the algorithm, for any training point, temporarily remove it from the Discriminant function, run the Discriminant function and see if it correctly classifies all original training points including the training point that was removed. If it does, then the removed training point was\nredundant, so we can safely eliminate (‘filter’) it permanently from our Discriminant function. We have to iteratively do this for all our training points and our final reduced training points that remain in the Discriminant function may not be unique because this filtering process is sensitive to the order in which we select the training points that we wish to filter. This filtering exercise has a computational complexity of O(n2), (where n is the number of training points)and may be worth while if the number of test data is substantial."
    }, {
      "heading" : "2.10 R.R.E Algorithm Impervious to Noisy Training Environments",
      "text" : "We define noisy training environments are such that there is a high cross correlation or better yet, similarity between training points of different categories. More\nprecisely, a noisy training environment is: if 1Txi ∈ and\n2Tx j ∈ , there exist some or many training points such that\nji xx ≅ . In a noisy training environment, as we expand our\ntraining set by adding training data points that we know are correct, and in the rare case that a new training point has a categorization that conflicts with the classification of the Discriminant function, we simply include the point m times. m for the worse case scenario is usually 2 indicating that it was initially used to cancel the wrong pre-existing training point and the other is to fully guarantee the correct classification training of the more recent training point in question. This is very powerful because noisy data can be cancelled out when m = 1 and recent, more correct training is enforced when m = 2. Note that m = 2 will rarely be needed as duplication is rare (we\nrarely have the existence of any ji xx = ), so most of the\ntime, m = 1 rectifies and enforces training accordingly. To mathematically describe what has been discussed above, Let us initially have a noisy training point 1Tx f ∈ ) that is\ninitially included in our Discriminant function at some early stage in the training. (Assuming equal categorical cost: p1 = p2.)\n∑∑ −−−−−− −= j xxxxnf i xxxxnf k jk T jkji T iki epepxG )())(( 1 )())(( 2)1( )( : 1, Txx if ∈∀ ) , 2Tx j ∈∀ and kk Vx ∈\n∑∑ −−− ≠ −−−−−− −+= j xxxxnf fi xxxxnfxxxxnf jk T jkjik T ikif T fki epepep )())(( 1 )())(( 2 )())(( 2\n))\nLater as we train, we discover that due to noisy training data, we have an ambiguity because 2Tx f ∈ ) , we implement\ntraining as normal and we have )())((\n1)1()2( )()( fk\nT fki xxxxnf kk epxGxG )) −−−−=\n∑∑ ≠\n−−−−−−\n≠ −−−−−− −−+= fj xxxxnfxxxxnf fi xxxxnfxxxxnf k jk T jkjf T fkii T ikifk T fki epepepepxG )())(( 1 )())(( 1 )())(( 2 )())(( 2)2( )( ))))\n∑∑ ≠\n−−−\n≠ −−−−−−−−− −+−= fj xxxxnf fi xxxxnfxxxxnfxxxxnf jk T jkjik T ikifk T fkifk T fki epepepep )())(( 1 )())(( 2 )())(( 1 )())(( 2\n))))\n∑∑ ≠\n−−−\n≠ −−− −= fj xxxxnf fi\nxxxxnf jk T jkjik T\niki epep )())((\n1\n)())((\n2\nNote 0 )())((\n1\n)())(( 2 =− −−−−−− f T fkif T fki xxxxnfxxxxnf epep\n))))\nbecause we initially\nassumed equal categorical cost: p1 = p2, so algebraically, we have demonstrated the desirable cancellation of the noisy training data point fx ) . If we now want to enforce the training of 2Tx f ∈ )\nWe have )())((\n1)2()3( )()( fk\nT fki xxxxnf kk epxGxG )) −−−−= )())((\n1\n)())((\n1\n)())((\n2)3( )( fk\nT fkijk T jkjik T iki xxxxnf\nfj\nxxxxnf\nfi\nxxxxnf k epepepxG )) −−−\n≠\n−−−\n≠\n−−− −−= ∑∑\n∑∑ −−− ≠ −−− −= j xxxxnf fi xxxxnf jk T jkjik T iki epep )())(( 1 )())(( 2 1Txi ∈∀ , 2, Txx jf ∈∀ ) and kk Vx ∈\nNote: this convenient ‘cancellation’ of noisy training points may not work well when we have an unequal categorical cost; that is when p1 ≠ p2. To be more precise, if initially 1Tx f ∈ ) , but we later want to enforce 2Tx f ∈ ) ,\ntraining noise cancellation:\n• fails if p1 < p2. • works if p1 > p2 with an unnecessary over-compensation. • works perfectly if p1 = p2."
    }, {
      "heading" : "2.11 R.R.E Algorithm Validation",
      "text" : "The R.R.E algorithm is compared to the P.C.A (Perceptron Criterion Algorithm) in section 3 using two types of datasets. It is then compared to Linear Support Vector Machines in section 4 on two types of data sets as well. Lastly, in section 5, it is compared to a Neural Network of comparable complexity under a simple non-linearly separable case (XOR problem)."
    }, {
      "heading" : "3 Comparing R.R.E to P.C.A",
      "text" : ""
    }, {
      "heading" : "3.1: Using “iris_setosa_versicolor” Dataset",
      "text" : "“iris_setosa_versicolor” data is an appropriate twocategory dataset that exhibits the strength of P.C.A (Perceptron Criterion Algorithm) because the data is somewhat linearly correlated along each category. The data is used to demonstrate and contrast the performance of both the P.C.A and R.R.E algorithms. The figure below visually depicts the “iris_setosa_versicolor” dataset. Refer to Appendix B1 to view a tabular listing of all normalized and augmented row vectors contained in the dataset. We can see the data is somewhat linearly correlated along each category.\n3.2: Applying R.R.E to the “iris_setosa_versicolor” Dataset 3.2(a): 40% Training Data & 60% Test Data The dataset of (“iris_setosa_versicolor”) was split into two sets. We placed the first 40% of the data in one set (training set) and the remaining 60% (test set) in the second set. We start of with the R.R.E algorithm Discriminant function:\n∑∑ −−−−−− −= j xxxxnf i xxxxnf k jk T jkjik T iki epepxG )())(( 1 )())(( 2)( 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈\nAssuming equal unitary categorical cost (p1 = p2) and a variance reduction function of f(ni) = f(nj) = ni = nj = 20, our Discriminant function reduces to:\n∑∑ −−−−−− −= j xxxx i xxxx k jk T jkik T ik eexG )()(20)()(20 )( 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈\nAfter running the test data on the Discriminant function above, we get a classification summarized by the table below.\nThe decision surface shown above indeed shows the behaviour of the algorithm’s Discriminant function, but what is of essential interest is the decision boundary because it visually depicts the separation of decision regions. In the contour diagram below, the decision boundary is seen when the contour height is zero (indicated by the green line labelled‘0’) which is equivalent to the Discriminant function being zero.\nFigure 3.2a2: Contour Diagram of R.R.E algorithm applied to “iris_setosa_versicolor” using 40% training data and 60% test data. Note: decision boundary indicated by ‘0’ (zero contour height). We have a parasitic outlier at (4.5,2.3)T that is solely misclassified.\n3.2(b): 60% Training Data and 40% Test Data The dataset of (“iris_setosa_versicolor”) was split into two sets with the first 60% of the data in one set(training set) and the remaining 40%(test set) in the second set. Repeating section 3.2(a) with 60% training data and 40% test data, we obtain a classification summarized by the table below.\nSimilarly, the decision surface of the configuration above (using 60% Training data and 40% test data) is presented below.\nFigure 3.2.b: Decision surface of R.R.E algorithm applied to \"iris_setosa_versicolor” using 60% training data and 40% test data.\nSimilarly, the contour diagram below shows the decision regions separated by a decision boundary (zero contour height). This decision boundary is indicated by the greenish-bluish line labelled with ‘0’.\nFigure 3.2.b2: Contour Diagram of R.R.E algorithm applied to “iris_setosa_versicolor” using 60% training data and 40% test data. Note: decision boundary indicated by ‘0’ (zero contour height). We have a parasitic outlier at (4.5,2.3)T that is solely misclassified.\n3.2(c): 90% Training data and 10% test data The dataset of (“iris_setosa_versicolor”) was split into two sets with the first 90% of the data in one set(training set) and the remaining 10%(test set) in the second set. Repeating section 3.2(b) with 90% training data and 10% test data, we obtain a classification summarized by the table below.\nThe decision Surface of the configuration above (using 90% training data and 10% test data) is provided below:\nFigure 3.2.c: Decision surface of R.R.E algorithm applied to “iris_setosa_versicolor” using 90% training data and 10% test data.\nSimilarly, the contour diagram below shows the decision regions separated by a decision boundary (zero contour height). This decision boundary is indicated by the greenish-bluish line labelled with ‘0’.\nFigure 3.2.c2: Contour Diagram of R.R.E algorithm applied to “iris_setosa_versicolor” using 90% training data and 10% test data. Note: decision boundary indicated by ‘0’ (zero contour height). We have finally resolved the parasitic outlier at (4.5,2.3)T because it has now been included in training, and has influenced the decision boundary effectively."
    }, {
      "heading" : "3.3 Applying P.C.A to the “iris_setosa_versicolor” Dataset",
      "text" : "The objective of this section is to repeat section 3.2 (3.2(a), 3.2(b), & 3.2(c)) using P.C.A. 3.3(a): 40% Training data and 60% test data The “iris_setosa_versicolor” dataset was split into two sets with 40% of the data in one set and the remaining 60% in the second set. The first 40% of the Data set is the training data that was used to compute the weight vector a r . We used a learning rate, 01.0(.))( ==ηη k , a threshold or criterion of θ=0 and an initial weight initiala r = [0, 0, 1]T. The number of iterations was limited to 300. After implementing P.C.A using the abovementioned conditions, We get a final weight vector of\nT finala ]4.2240 2.5860,- 0.2100, [= r by fully converging after 42\niterations. After running the test data on the final weight vector above, we get a classification summarized by the table below.\nTo capture the learning behaviour of P.C.A, the criterion function over iterations is shown below.\nFigure 3.3a: Criterion function over the iterations of P.C.A applied to “iris_setosa_versicolor” using 40% training data and 60% test data.\nIn order to compare P.C.A to R.R.E, the Feature Space plot and the Decision Boundary is presented below.\nFigure 3.3a2: Feature Space plot and the Decision Boundary of P.C.A applied to “iris_setosa_versicolor” using 40% training data and 60% test data\n3.3(b): 60% Training data and 40% test data Repeating section 3.3(a) with 60% of data as training data and 40% as testing data, we get a final weight vector of\nT finala ]6.4120 3.9360,- 0.5100,[= r by fully converging after 45 iterations. After running the test data on the final weight vector above, we get a classification summarized by the table below. TABLE 3.3.b: Classification summary of P.C.A applied to “iris_setosa_versicolor” using 60% training data and 40% test data. Category Number of\ntraining vectors Misclassified\nNumber of testing vectors Misclassified\nClassifier Accuracy excluding Training Data\nClassifier Accuracy including Training Data\none 0/30 1/20 95% 98% two 0/30 0/20 100% 100% both 0/60 1/40 97.5% 99%\nLikewise, to capture the learning behaviour of P.C.A, the criterion function over iterations is shown below.\nFigure 3.3.b: Criterion function over the iterations of P.C.A applied to “iris_setosa_versicolor” using 60% training data and 40% test data.\nAgain, to compare P.C.A to R.R.E, the Feature Space plot and the Decision Boundary is presented below.\nFigure 3.3.b2: Feature Space plot and the Decision Boundary of P.C.A applied to “iris_setosa_versicolor” using 60% training data and 40% test data\n3.3(c): 90% Training data and 10% test data Repeating 3.3(b) with 90% of data as training data and 10% as testing data, we get a final weight vector of\nT finala ]9.2230 .4640,[1.4300,-5= r without fully converging after 300 iterations (convergence impossible due to linearly non-separable training set). After running the test data on the final weight above, we get a classification summarized by the table below. TABLE 3.3c: Classification summary of P.C.A applied to “iris_setosa_versicolor” using 90% training data and 10% test data. Category Number of\ntraining vectors Misclassified\nNumber of testing vectors Misclassified\nClassifier Accuracy excluding Training Data\nClassifier Accuracy including Training Data\none 1/45 0/5 100% 98% two 0/45 0/5 100% 100% both 1/90 0/10 100% 99%\nSimilarly, to capture the learning behaviour of P.C.A, the criterion function over iterations is shown below.\nFigure 3.3c: Criterion function over the iterations of P.C.A applied to “iris_setosa_versicolor” using 90% training data and 10% test data.\nLastly, to compare P.C.A to R.R.E, the Feature Space plot and the Decision Boundary is presented below.\nFigure 3.3c2: Feature Space plot and the Decision Boundary of P.C.A applied to “iris_setosa_versicolor” using 90% training data and 10% test data"
    }, {
      "heading" : "3.4: Using “Iris_Versicolor_VirginicaV2” Dataset",
      "text" : "In sections 3.1 -3.3, the R.R.E and P.C.A were implemented on a dataset that was favourable to P.C.A (because the data is somewhat linearly correlated along each category), despite this, the R.R.E achieved better overall classification results. In this section, we compare both algorithms to a dataset that is not that friendly - a dataset that is separable but not linearly separable as a convincing argument that R.R.E can achieve 100% learning/training accuracy while the P.C.A can not. We use the “Iris_Versicolor_VirginicaV2”, a mild modification of Iris_Versicolor_Virginica” such that the 10 overlapping categorical data points have been marginally adjusted to not overlap. The figure below visually depicts the “Iris_Versicolor_VirginicaV2” dataset. Refer to Appendix B2 to view a tabular listing of all normalized and augmented row vectors contained in the dataset. We can see the data is quite ‘noisy’ because data points from each category are heavily shuffled together."
    }, {
      "heading" : "3.5: Applying R.R.E Algorithm to the “Iris_Versicolor_VirginicaV2” dataset",
      "text" : "The goal is to achieve the highest training accuracy on the entire dataset in order to assess the training ability of the algorithm. Using our Discriminant function below,\n∑∑ −−−−−− −= j xxxxnf i xxxxnf k jk T jkjik T iki epepxG )())(( 1 )())(( 2)( λλ 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈ Assuming equal unitary categorical cost (p1 = p2) and a variance reduction function of f(ni) = f(nj) = ni = nj = 50, our Discriminant function reduces to:\n∑∑ −−−−−− −= j xxxx i xxxx k jk T jkik T ik eexG )()(50)()(50 )( λλ 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈ Empirically, an auxiliary sensitivity factor of 5.3≥λ allows us to achieve 100% learning/training accuracy. The decision surface of the configuration above using 100% of the dataset as training data is seen below:\nThe contour diagram below shows the decision regions separated by decision boundaries which are the contours of zero height (indicated by the green lines labelled ‘0’) Note: 100% training/learning accuracy has been achieved; it can be verified by inspecting the contours and observing that no training point is misplaced or misclassified."
    }, {
      "heading" : "3.6: Applying P.C.A to the “Iris VersicolorVirginicaV2” Dataset",
      "text" : "We used 100% of the data set as our training data to compute the weight vector a r . We used a learning rate 01.0(.))( ==ηη k , a threshold or criterion of θ=0 and an initial weight initiala r = [0, 0, 1]T. We get a final weight vector of T\nfinala ]5.1680 13.228,- 56.5, [= r without fully converging after 3000\niterations. Note that we can not converge because the data is linearly non-separable. We achieve 56% learning/training accuracy. To capture the learning behaviour of P.C.A under the conditions of section 3.3, the criterion function over iterations is shown below. Notice the non-convergence; the oscillatory behaviour is not because the learning rate is too high, it is due to the fact that the data is linearly non-separable.\nLastly, to compare P.C.A to R.R.E, the Feature Space plot and the Decision Boundary is presented below."
    }, {
      "heading" : "3.7: Overall Comparison",
      "text" : "The table below summarizes the results of sections 3.2 and 3.3 plus it includes results of extrapolated configurations (different training data to test data ratios) that were not mentioned.\nThe table below summarizes the results of sections 3.5 and 3.6 where we showed that when the dataset is separable, but not linearly separable, R.R.E can achieve 100% learning/training accuracy while the P.C.A can not. TABLE 3.7.2: Training accuracy comparison between R.R.E and P.C.A using entire “Iris_Versicolor_VirginicaV2” dataset for training.\nAlgorithm Training Accuracy\nR.R.E 100% 100% Training Data\nP.C.A 56%\nOverall, we see that P.C.A requires a training of n iterations to adjust the augmented weight vector with a training computational complexity of O(n); Since R.R.E is non-iterative, it requires minimal training in its construction of its Discriminant function with a computational complexity O(1). Once training is complete, in order to classify a single test point, P.C.A achieves classification with a computational complexity of O(1)- a single dot product operation, while R.R.E has a complicated Discriminant function that has an expensive computational complexity of O(nt) where nt is the number of training points. If data is linearly non-separable, P.C.A will achieve a training accuracy of less than 100% but R.R.E seems to\nachieve 100% training/learning accuracy as seen in section 3. One last merit to consider is that even if the data is linearly separable, P.C.A achieves a linear Discriminant that is not optimum with respect to the margin of separation between the support vectors of each category, on the other hand, R.R.E achieves better if not optimum margins of separation. Overall, R.R.E is indeed superior to P.C.A in terms of achieving more elegant classification results, but P.C.A is more computationally conservative upon classification."
    }, {
      "heading" : "4 Comparing R.R.E to Linear Support Vector Machines using “Support1” & “Support2” Datasets",
      "text" : ""
    }, {
      "heading" : "4.1: Preliminary",
      "text" : "The figure below visually depicts the “Support1” dataset. This dataset is a modified version of “iris_setosa_versicolor” dataset with an outlier removed such that the data is linearly separable so as to correctly implement the linear support vector machine in the next section. Refer to Appendix B3 to view a tabular listing of all normalized and augmented row vectors contained in the dataset. We can see that the dataset below is clearly linearly separable."
    }, {
      "heading" : "4.2: Applying R.R.E Algorithm to the “Support1” Dataset",
      "text" : "The goal of this section is to achieve optimum margin between categories by attaining a learning/training accuracy of 100%. Using our Discriminant function below,\n∑∑ −−−−−− −= j xxxxnf i xxxxnf k jk T jkjik T iki epepxG )())(( 1 )())(( 2)( λλ 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈ Assuming equal unitary categorical cost (p1 = p2) and a variance reduction function of f(ni) = f(nj) = ni = nj = 50, our Discriminant function reduces to:\n∑∑ −−−−−− −= j xxxx i xxxx k jk T jkik T ik eexG )()(50)()(50 )( λλ 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈ Empirically, an auxiliary sensitivity factor of 1≥λ allows us to achieve 100% learning/training accuracy with an optimum non-linear margin. The contour diagram below shows the decision regions separated by a decision boundary which is the contour height of zero (indicated by the bluish-green line labelled ‘0’). This decision boundary separates both categories by not only considering the linear support vectors, but rather all data. We can see an optimum margin emerging that is justifiably non-linear."
    }, {
      "heading" : "4.3: Applying Linear S.V.M to the “Support1” Dataset",
      "text" : "Step 1: Identifying the support vectors In order to use the Linear S.V.M., we would first need to identify the support vectors. Assuming P.C.A was pre-implemented and the closest data points to the linear Discriminant line were obtained, we find the support vectors shown in the diagram below:\nStep 2: Augmenting and normalizing support vectors Our support vectors from category one are: TV ]3,5[1,1 = and TV ]3.3,4.5[2,1 = Our support vector from category two is: TV ]3,4.5[1,2 = After augmenting and normalizing our support vectors, we get: T]0.3 ,0.5 ,0.1[1 =φ , T]3.3 ,4.5 ,0.1[2 =φ and T]0.3 ,4.5 ,0.1[,3 −−=φ\nStep 3: Constructing the normalized kernel matrix Our normalized kernel matrix is T\njijiK φφ ., = { }3,2,1, ∈ji Using MATLAB instructions:\nq =[1,5,3,;1,5.4,3.3;-1,-5.4,-3] k=q*transpose(q)\nwe get:\n   \n\n   \n =\n39.1640.06-37.0-\n40.06-41.0537.9\n37.0-37.935.0\n, jiK\nStep 4: Finding Lagrangian coefficients We need to solve for the Lagrangian coefficients jα in\nijjiK 1, =α\n⇒\n   \n\n   \n\n=    \n\n   \n\n   \n\n   \n\n1\n1\n1\n*\n39.1640.06-37.0-\n40.06-41.0537.9\n37.0-37.935.0\n3\n2\n1 α α α\n⇒\n   \n\n   \n\n   \n\n   \n\n=    \n\n   \n −\n1\n1\n1\n*\n39.1640.06-37.0-\n40.06-41.0537.9\n37.0-37.935.0 1\n3\n2\n1 α α α\nWe find a solution to our Lagrange coefficients: 1α , 2α and 3α\n=    \n\n   \n\n3\n2\n1 α α α\n   \n\n   \n\n49.72\n37.78-\n93.5\nStep 5: computing the optimum augmented weight vector\nOur final augmented weight vector is â\n∑ =\n= 3\n1 ˆ i iia φα = [6.0, -5 ,20/3] T\nStep 6: Constructing the optimum linear Discriminant function Our Discriminant function becomes: G(x) = â .[1,x1,x2] T= 6 -5x1 + (20/3)x2 =0 Which is equivalent to: x2 = (3/4)x1 – 9/10 Step 7: Confirming the solution In order to confirm the solution of our optimum linear Discriminant function, we find the distance or margin of all support vectors to the optimum Discriminant line is:\n)ˆˆ/()*ˆ( 2\n3\n2 2 aaa T i += φρ = 0.12, for i = 1,2,3 Since the margins of each support vectors to the optimum Discriminant line are equal, we have confirmed the correct solution. The figure below summarizes the results of steps 1 through 7 by depicting the Feature Space plot and the optimum linear decision Boundary."
    }, {
      "heading" : "4.4: Applying R.R.E Algorithm to the “Support2” Dataset Versus L.S.V.M & Fisher Linear Discriminant",
      "text" : "In section 4.3, we used a dataset (“Support1”) that conveniently allowed us to apply linear S.V.M, now we draw our attention to a data scenario that compromises the functionality of both the Fisher Linear Discriminant and linear S.V.M. We apply R.R.E under the conditions presented in 4.2. The “support2’data was constructed from scratch: A visual representation of this data is seen below:\nR.R.E generates a symmetric decision surface below:\nAfter implementing R.R.E, we obtain the contour diagrams of the feature space presented below:\nThe result above demonstrates how powerful R.R.E is because it is able to produce both linear and non-linear optimum margins. If a Linear S.V.M is applied to “suppot2” data, it would produce inadequate results because the data is not linearly separable. The Fisher Linear Discriminant would fail as well because the means of each category are equivalent ( T]10,10[21 == µµ ). Note: Non-linear S.V.M could potentially produce decent results as long us we initially project our data to some higher dimension as a preliminary step to separate data."
    }, {
      "heading" : "5 Comparing R.R.E to a 2-2-1 Neural Network in application to the popular XOR Problem",
      "text" : "The popular XOR problem is a classic problem that can not be solved by linear classifiers/Perceptrons. We attempt to solve the XOR problem by employing the R.R.E algorithm and then to compare results to a solution of a Neural Network of modest complexity. We are using a Neural Network as a ‘benchmark’ because it is conventionally used in solving linearly non-separable classification problems. We use a 2- 2-1 Neural Network because it is simple, yet computationally sufficient with respect to solving the XOR problem."
    }, {
      "heading" : "5.1: Applying R.R.E Algorithm to the XOR problem",
      "text" : "Our initial Discriminant Function is:\n∑∑ −−−−−− −= j xxxxnf i xxxxnf k jk T jkjik T iki epepxG )())(( 1 )())(( 2)( λλ 1Txi ∈∀ , 2Tx j ∈∀ and kk Vx ∈ Assuming equal unitary categorical cost and a variance reduction function of f(ni) = f(nj) = ni = nj, our Discriminant function reduces to:\n∑∑ −−−−−− −= j xxxxn i xxxxn k jk T jkjik T iki eexG )()()()( )( 1Txi ∈∀ , 2Tx j ∈∀\nwhere\n            −      − = 1 1 , 1 1 1T ,\n                  − − = 1 1 , 1 1 2T 2== ji nn and 1=λ\nUsing our training data as our test data, the table below summarizes the performance of the R.R.E algorithm in application to the XOR problem.\nThe decision surface of the R.R.E Discriminant function is shown below.\nFigure 5.1: Mesh decision surface of R.R.E in application to the XOR problem Projecting the surface above onto the x1-x2 plane, we get the following.\nFigure 5.1b: projection of R.R.E decision surface onto the feature space (in application to the XOR problem) An aesthetically alternative representation of the surface above is shown below:\nFigure 5.1c: Decision surface of R.R.E in application to the XOR problem\nThe decision surfaces shown above indeed show the behaviour of the algorithm’s Discriminant function, but what is of\nmore interest is the decision boundaries because they visually depict the separation of decision regions. In the diagram below, the decision boundary is seen when the contour height is zero (straight green lines labelled ‘0’) which is equivalent to the Discriminant function being zero.\nFigure 5.1d: Contour diagram of R.R.E in application to the XOR problem"
    }, {
      "heading" : "5.2: Solving the XOR problem using a 2-2-1 Neural Network",
      "text" : "A 2-2-1 Neural Network was constructed from first principles using the batch back propagation algorithm for solving the XOR problem.\nGiven the following conditions:\n-The two given batch inputs are: x1 =[-1,-1,1,1] x2=[-1,1,-1,1] - The desired (batch) target is [-1,1,1,-1]. - We used a learning rate η = 0.1, a threshold (θ) of 0.001 and a hyperbolic-tan sigmoidal activation function. - The arbitrary chosen initial hidden weights are:\n   \n\n   \n =\n3̂.0\n4.0\n2.0\n5̂.0\n3.0\n1.0\njiW (Input to hidden layer weights, hats indicate bias weights)\n   \n\n   \n\n=\n9̂2̂.0\n31.0\n27.0\nkjW (Hidden to output layer weights, hats indicate bias weights)\nAfter running the script for the Neural Network, we verify that network converges after 32 Epochs where the final weight values indeed satisfy the XOR operation as (target ≈ Z(out)).\nThe decision surface generated by the neural network is presented below:\nLike wise, the diagram below shows the contour diagram of the decision surface above. We can see the decision boundary is seen when the contour height is zero (straight green lines)"
    }, {
      "heading" : "5.3: Overall Comparison",
      "text" : "Tabular comparison between the two algorithms is summarized in the table below.\nAchieving target values Note it is pointless to calculate percentage error of each algorithm because the Zouts in the table above can be made arbitrarily close to the target values by adjusting certain parameters. For the Neural Network, we can make our threshold/criterion very small and adjust our learning rate accordingly. For the R.R.E algorithm, we can use redundant training (duplication), we can also use a higher auxiliary sensitivity factor (λ =3, to achieve all |Zout| = 1) or\nalternatively, we can use a higher order variance reduction function f(n). Minimal training abilities A meaningful point to consider is that both algorithms obtain acceptable results through different mechanisms, but the R.R.E consistently requires minimal training of only one step while the Neural Network would normally require more iterations (epochs) - not unless the learning rate is perfectly on point (very rare), in which case it will require one iteration as well. Decision making In terms of decision making for a single test point, the forward feedback of a Neural Network has a computational complexity correlated with the number of weights, while the R.R.E has a computational complexity correlated with the number of training points. Usually the number of training points are 10-20 times the number of weights (adaptive parameters) in order to minimize over-fitting in a Neural Network. Therefore if we adhere to this rule, the R.R.E is generally more computationally expensive in classifying than a Neural Network of comparable complexity. General training R.R.E is non-iterative, requires minimal training and is generally computationally superior to a Neural Network during training. We have ignored the data normalization requirement of a Neural Network which provides an additional argument in favour of R.R.E."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We see that R.R.E is a powerful algorithm, but unlike much other learning algorithms, it is non-iterative and defers all its training computation to its discriminant function where it becomes computationally expensive while classifying. Although R.R.E achieves stellar results on different fronts, work has to be done to reduce the computational complexity of its Discriminant function. One suggested way to resolve this is using ‘training data filtering’ as suggested in section 2.9.1. Another way would be to use a subset of training points/terms to be included in the Discriminant function - an intuitive suggestion would be to use the training points that have the lowest dissimilarity\nwith the test point in question as they have the largest influence, but that would mean that we would have to come up with a robust system, possibly a look-up table that can efficiently, store, find and compare all training points to a test point before inclusion to the Discriminant function."
    }, {
      "heading" : "7 Acknowledgments",
      "text" : "I graciously thank Prof. Anastasios N. Venetsanopoulos1 for proofreading a preliminary version of this manuscript in addition to offering a valuable graduate level course (EE8209) in Intelligent Systems that equipped me with the background to tackle this project. Three data sets used in this project were courteously provided in the EE8209 course. I thank Dr. Alp Kucukelbir for generously taking the time to read this manuscript (in Sept 2014) and for suggesting constructive comments that are yet to be implemented."
    }, {
      "heading" : "8 Bibliography",
      "text" : "[1] Bishop, Christopher M. (2006). Pattern Recognition and Machine Learning. Springer. [2] Cortes, C.; Vapnik, V. (1995). \"Support-vector networks\". Machine Learning 20 (3): 273. doi:10.1007/BF00994018. [3] Duda, R. O.; Hart, P. E.; Stork, D. H. (2000). Pattern Classification (2nd ed.). Wiley Interscience. ISBN 0-471- 05669-3. MR 1802993. [4] EE8209 course material, Ryerson University, (Winter 2012). [5] Fisher, R. A. (1936). \"The Use of Multiple Measurements in Taxonomic Problems\". Annals of Eugenics 7 (2): 179–188. doi:10.1111/j.1469-1809.1936.tb02137.x. hdl:2440/15227. [6] McCulloch, Warren; Walter Pitts (1943). \"A Logical Calculus of Ideas Immanent in Nervous Activity\". Bulletin of Mathematical Biophysics 5 (4): 115–133. doi:10.1007/BF02478259. [7] Rosenblatt, Frank (1957), The Perceptron--a perceiving and recognizing automaton. Report 85-460-1, Cornell Aeronautical Laboratory.\n1 SUBMITTED TO EE8209 COURSE INSTRUCTOR ON APRIL 27 2012\nAppendices Appendix B1: “iris_setosa_versicolor” Normalized & Augmented Row Vectors 1.0000 5.1000 3.5000 1.0000 4.9000 3.0000 1.0000 4.7000 3.2000 1.0000 4.6000 3.1000 1.0000 5.0000 3.6000 1.0000 5.4000 3.9000 1.0000 4.6000 3.4000 1.0000 5.0000 3.4000 1.0000 4.4000 2.9000 1.0000 4.9000 3.1000 1.0000 5.4000 3.7000 1.0000 4.8000 3.4000 1.0000 4.8000 3.0000 1.0000 4.3000 3.0000 1.0000 5.8000 4.0000 1.0000 5.7000 4.4000 1.0000 5.4000 3.9000 1.0000 5.1000 3.5000 1.0000 5.7000 3.8000 1.0000 5.1000 3.8000 1.0000 5.4000 3.4000 1.0000 5.1000 3.7000 1.0000 4.6000 3.6000 1.0000 5.1000 3.3000 1.0000 4.8000 3.4000 1.0000 5.0000 3.0000 1.0000 5.0000 3.4000 1.0000 5.2000 3.5000 1.0000 5.2000 3.4000 1.0000 4.7000 3.2000 1.0000 4.8000 3.1000 1.0000 5.4000 3.4000 1.0000 5.2000 4.1000 1.0000 5.5000 4.2000 1.0000 4.9000 3.1000 1.0000 5.0000 3.2000 1.0000 5.5000 3.5000 1.0000 4.9000 3.1000 1.0000 4.4000 3.0000 1.0000 5.1000 3.4000 1.0000 5.0000 3.5000 1.0000 4.5000 2.3000 1.0000 4.4000 3.2000 1.0000 5.0000 3.5000 1.0000 5.1000 3.8000 1.0000 4.8000 3.0000 1.0000 5.1000 3.8000 1.0000 4.6000 3.2000 1.0000 5.3000 3.7000 1.0000 5.0000 3.3000 -1.0000 -7.0000 -3.2000 -1.0000 -6.4000 -3.2000 -1.0000 -6.9000 -3.1000 -1.0000 -5.5000 -2.3000 -1.0000 -6.5000 -2.8000 -1.0000 -5.7000 -2.8000 -1.0000 -6.3000 -3.3000 -1.0000 -4.9000 -2.4000 -1.0000 -6.6000 -2.9000 -1.0000 -5.2000 -2.7000 -1.0000 -5.0000 -2.0000 -1.0000 -5.9000 -3.0000 -1.0000 -6.0000 -2.2000 -1.0000 -6.1000 -2.9000 -1.0000 -5.6000 -2.9000 -1.0000 -6.7000 -3.1000 -1.0000 -5.6000 -3.0000 -1.0000 -5.8000 -2.7000 -1.0000 -6.2000 -2.2000 -1.0000 -5.6000 -2.5000 -1.0000 -5.9000 -3.2000 -1.0000 -6.1000 -2.8000 -1.0000 -6.3000 -2.5000 -1.0000 -6.1000 -2.8000 -1.0000 -6.4000 -2.9000 -1.0000 -6.6000 -3.0000 -1.0000 -6.8000 -2.8000 -1.0000 -6.7000 -3.0000 -1.0000 -6.0000 -2.9000 -1.0000 -5.7000 -2.6000 -1.0000 -5.5000 -2.4000 -1.0000 -5.5000 -2.4000 -1.0000 -5.8000 -2.7000 -1.0000 -6.0000 -2.7000 -1.0000 -5.4000 -3.0000 -1.0000 -6.0000 -3.4000 -1.0000 -6.7000 -3.1000 -1.0000 -6.3000 -2.3000 -1.0000 -5.6000 -3.0000 -1.0000 -5.5000 -2.5000 -1.0000 -5.5000 -2.6000 -1.0000 -6.1000 -3.0000 -1.0000 -5.8000 -2.6000 -1.0000 -5.0000 -2.3000 -1.0000 -5.6000 -2.7000 -1.0000 -5.7000 -3.0000 -1.0000 -5.7000 -2.9000 -1.0000 -6.2000 -2.9000 -1.0000 -5.1000 -2.5000 -1.0000 -5.7000 -2.8000 NON-NORMALIZED & UNAUGMENTED DATA SAVED AS: “iris_setosa_versicolor.mat”\nAppendix B2: “iris_versicolor_virginicaV2” Normalized & Augmented Row Vectors 1.0000 7.0000 3.2000 1.0000 6.0000 3.1000 1.0000 7.0000 3.1000 1.0000 5.5000 2.3000 1.0000 6.5000 2.8000 1.0000 5.7000 2.8000 1.0000 6.1000 3.3000 1.0000 4.9000 2.4000 1.0000 6.6000 2.9000 1.0000 5.2000 2.7000 1.0000 5.0000 2.0000 1.0000 5.4000 3.2000 1.0000 6.0000 2.2000 1.0000 6.1000 2.9000 1.0000 5.6000 2.9000 1.0000 6.6000 3.1000 1.0000 5.6000 3.0000 1.0000 5.4000 2.7000 1.0000 6.2000 2.2000 1.0000 5.6000 2.5000 1.0000 5.9000 3.2000 1.0000 6.1000 2.8000 1.0000 6.1000 2.3000 1.0000 6.1000 2.8000 1.0000 6.4000 2.9000 1.0000 6.6000 3.0000 1.0000 6.8000 2.8000 1.0000 6.6000 2.8000 1.0000 6.0000 2.9000 1.0000 5.7000 2.6000 1.0000 5.5000 2.4000 1.0000 5.5000 2.4000 1.0000 5.4000 2.7000 1.0000 6.0000 2.7000 1.0000 5.4000 3.0000 1.0000 6.0000 3.4000 1.0000 6.7000 2.9000 1.0000 6.3000 2.3000 1.0000 5.6000 3.0000 1.0000 5.5000 2.5000 1.0000 5.5000 2.6000 1.0000 6.1000 3.2000 1.0000 5.8000 2.6000 1.0000 5.0000 2.3000 1.0000 5.6000 2.7000 1.0000 5.7000 3.0000 1.0000 5.7000 2.9000 1.0000 6.2000 2.9000 1.0000 5.1000 2.5000 1.0000 5.7000 2.8000 -1.0000 -6.3000 -3.3000 -1.0000 -5.9000 -2.8000 -1.0000 -7.1000 -3.0000 -1.0000 -6.3000 -2.9000 -1.0000 -6.5000 -3.0000 -1.0000 -7.6000 -3.0000 -1.0000 -4.9000 -2.5000 -1.0000 -7.3000 -2.9000 -1.0000 -6.7000 -2.5000 -1.0000 -7.2000 -3.6000 -1.0000 -6.5000 -3.2000 -1.0000 -6.4000 -2.7000 -1.0000 -6.8000 -3.0000 -1.0000 -5.7000 -2.5000 -1.0000 -5.8000 -2.8000 -1.0000 -6.4000 -3.2000 -1.0000 -6.5000 -3.0000 -1.0000 -7.7000 -3.8000 -1.0000 -7.7000 -2.6000 -1.0000 -6.0000 -2.6000 -1.0000 -6.9000 -3.2000 -1.0000 -5.6000 -2.8000 -1.0000 -7.7000 -2.8000 -1.0000 -6.3000 -2.7000 -1.0000 -6.7000 -3.3000 -1.0000 -7.2000 -3.2000 -1.0000 -6.2000 -2.8000 -1.0000 -6.1000 -3.0000 -1.0000 -6.4000 -2.8000 -1.0000 -7.2000 -3.0000 -1.0000 -7.4000 -2.8000 -1.0000 -7.9000 -3.8000 -1.0000 -6.4000 -2.8000 -1.0000 -6.3000 -2.8000 -1.0000 -6.1000 -2.6000 -1.0000 -7.7000 -3.0000 -1.0000 -6.3000 -3.4000 -1.0000 -6.4000 -3.1000 -1.0000 -6.0000 -3.0000 -1.0000 -6.9000 -3.1000 -1.0000 -6.7000 -3.1000 -1.0000 -6.9000 -3.1000 -1.0000 -5.9000 -2.8000 -1.0000 -6.8000 -3.2000 -1.0000 -6.7000 -3.3000 -1.0000 -6.7000 -3.0000 -1.0000 -6.3000 -2.5000 -1.0000 -6.5000 -3.0000 -1.0000 -6.2000 -3.4000\n-1.0000 -5.9000 -3.0000 NON-NORMALIZED & UNAUGMENTED DATA SAVED AS: “iris_versicolor_virginicaV2.mat”\nAppendix B3: “Support1” Normalized & Augmented Row Vectors 1.0000 5.1000 3.5000 1.0000 4.9000 3.0000 1.0000 4.7000 3.2000 1.0000 4.6000 3.1000 1.0000 5.0000 3.6000 1.0000 5.4000 3.9000 1.0000 4.6000 3.4000 1.0000 5.0000 3.4000 1.0000 4.4000 2.9000 1.0000 4.9000 3.1000 1.0000 5.4000 3.7000 1.0000 4.8000 3.4000 1.0000 4.8000 3.0000 1.0000 4.3000 3.0000 1.0000 5.8000 4.0000 1.0000 5.7000 4.4000 1.0000 5.4000 3.9000 1.0000 5.1000 3.5000 1.0000 5.7000 3.8000 1.0000 5.1000 3.8000 1.0000 5.4000 3.6000 1.0000 5.1000 3.7000 1.0000 4.6000 3.6000 1.0000 5.1000 3.3000 1.0000 4.8000 3.4000 1.0000 5.0000 3.0000 1.0000 5.0000 3.4000 1.0000 5.2000 3.5000 1.0000 5.2000 3.4000 1.0000 4.7000 3.2000 1.0000 4.8000 3.1000 1.0000 5.4000 3.3000 1.0000 5.2000 4.1000 1.0000 5.5000 4.2000 1.0000 4.9000 3.1000 1.0000 5.0000 3.2000 1.0000 5.5000 3.5000 1.0000 4.9000 3.1000 1.0000 4.4000 3.0000 1.0000 5.1000 3.4000 1.0000 5.0000 3.5000 1.0000 4.5000 3.0000 1.0000 4.4000 3.2000 1.0000 5.0000 3.5000 1.0000 5.1000 3.8000 1.0000 4.8000 3.0000 1.0000 5.1000 3.8000 1.0000 4.6000 3.2000 1.0000 5.3000 3.7000 1.0000 5.0000 3.3000 -1.0000 -7.0000 -3.2000 -1.0000 -6.4000 -3.2000 -1.0000 -6.9000 -3.1000 -1.0000 -5.5000 -2.3000 -1.0000 -6.5000 -2.8000 -1.0000 -5.7000 -2.8000 -1.0000 -6.3000 -3.3000 -1.0000 -4.9000 -2.4000 -1.0000 -6.6000 -2.9000 -1.0000 -5.2000 -2.7000 -1.0000 -5.0000 -2.0000 -1.0000 -5.9000 -3.0000 -1.0000 -6.0000 -2.2000 -1.0000 -6.1000 -2.9000 -1.0000 -5.6000 -2.9000 -1.0000 -6.7000 -3.1000 -1.0000 -5.6000 -3.0000 -1.0000 -5.8000 -2.7000 -1.0000 -6.2000 -2.2000 -1.0000 -5.6000 -2.5000 -1.0000 -5.9000 -3.2000 -1.0000 -6.1000 -2.8000 -1.0000 -6.3000 -2.5000 -1.0000 -6.1000 -2.8000 -1.0000 -6.4000 -2.9000 -1.0000 -6.6000 -3.0000 -1.0000 -6.8000 -2.8000 -1.0000 -6.7000 -3.0000 -1.0000 -6.0000 -2.9000 -1.0000 -5.7000 -2.6000 -1.0000 -5.5000 -2.4000 -1.0000 -5.5000 -2.4000 -1.0000 -5.8000 -2.7000 -1.0000 -6.0000 -2.7000 -1.0000 -5.4000 -3.0000 -1.0000 -6.0000 -3.4000 -1.0000 -6.7000 -3.1000 -1.0000 -6.3000 -2.3000 -1.0000 -5.6000 -3.0000 -1.0000 -5.5000 -2.5000 -1.0000 -5.5000 -2.6000 -1.0000 -6.1000 -3.0000 -1.0000 -5.8000 -2.6000 -1.0000 -5.0000 -2.3000 -1.0000 -5.6000 -2.7000 -1.0000 -5.7000 -3.0000 -1.0000 -5.7000 -2.9000 -1.0000 -6.2000 -2.9000 -1.0000 -5.1000 -2.5000\n-1.0000 -5.7000 -2.8000 NON-NORMALIZED & UNAUGMENTED DATA SAVED AS: “Support1.mat”"
    } ],
    "references" : [ {
      "title" : "Pattern Recognition and Machine Learning",
      "author" : [ "Bishop", "Christopher M" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2006
    }, {
      "title" : "Support-vector networks",
      "author" : [ "C. Cortes", "V. Vapnik" ],
      "venue" : "Machine Learning",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1995
    }, {
      "title" : "Pattern Classification (2nd ed.)",
      "author" : [ "R.O. Duda", "P.E. Hart", "D.H. Stork" ],
      "venue" : "Wiley Interscience",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2000
    }, {
      "title" : "The Use of Multiple Measurements in Taxonomic Problems",
      "author" : [ "R.A. Fisher" ],
      "venue" : "Annals of Eugenics",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1936
    }, {
      "title" : "A Logical Calculus of Ideas Immanent in Nervous Activity",
      "author" : [ "McCulloch", "Warren", "Walter Pitts" ],
      "venue" : "Bulletin of Mathematical Biophysics",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1943
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "It is then compared to Linear Support Vector Machines [2] on two types of data sets as well.",
      "startOffset" : 54,
      "endOffset" : 57
    }, {
      "referenceID" : 2,
      "context" : "Lastly, it is compared to a Neural Network ([3],[6]) of comparable complexity for a non-linearly separable case (XOR problem).",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 4,
      "context" : "Lastly, it is compared to a Neural Network ([3],[6]) of comparable complexity for a non-linearly separable case (XOR problem).",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 0,
      "context" : "See [1]and [3] for details on the Perceptron Criterion Algorithm, Linear Support Vector machines, the Linear Fisher Discriminant ([5]) and Neural Networks.",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 2,
      "context" : "See [1]and [3] for details on the Perceptron Criterion Algorithm, Linear Support Vector machines, the Linear Fisher Discriminant ([5]) and Neural Networks.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 3,
      "context" : "See [1]and [3] for details on the Perceptron Criterion Algorithm, Linear Support Vector machines, the Linear Fisher Discriminant ([5]) and Neural Networks.",
      "startOffset" : 130,
      "endOffset" : 133
    }, {
      "referenceID" : 0,
      "context" : ") ) ( = =η η k , a threshold or criterion of θ=0 and an initial weight initial a r = [0, 0, 1].",
      "startOffset" : 85,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : ") ) ( = =η η k , a threshold or criterion of θ=0 and an initial weight initial a r = [0, 0, 1].",
      "startOffset" : 85,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "-The two given batch inputs are: x1 =[-1,-1,1,1] x2=[-1,1,-1,1]",
      "startOffset" : 37,
      "endOffset" : 48
    }, {
      "referenceID" : 0,
      "context" : "-The two given batch inputs are: x1 =[-1,-1,1,1] x2=[-1,1,-1,1]",
      "startOffset" : 37,
      "endOffset" : 48
    }, {
      "referenceID" : 0,
      "context" : "-The two given batch inputs are: x1 =[-1,-1,1,1] x2=[-1,1,-1,1]",
      "startOffset" : 52,
      "endOffset" : 63
    }, {
      "referenceID" : 0,
      "context" : "-The two given batch inputs are: x1 =[-1,-1,1,1] x2=[-1,1,-1,1]",
      "startOffset" : 52,
      "endOffset" : 63
    }, {
      "referenceID" : 0,
      "context" : "- The desired (batch) target is [-1,1,1,-1].",
      "startOffset" : 32,
      "endOffset" : 43
    }, {
      "referenceID" : 0,
      "context" : "- The desired (batch) target is [-1,1,1,-1].",
      "startOffset" : 32,
      "endOffset" : 43
    } ],
    "year" : 2014,
    "abstractText" : "A fast Non-linear and non-iterative learning and classification algorithm is synthesized and validated. This algorithm named the \"Reverse Ripple Effect(R.R.E)\", achieves 100% learning accuracy but is computationally expensive upon classification. The R.R.E is a (deterministic) algorithm that super imposes Gaussian weighted functions on training points. In this work, the R.R.E algorithm is compared against known learning and classification techniques/algorithms such as: the Perceptron Criterion algorithm, Linear Support Vector machines, the Linear Fisher Discriminant and a simple Neural Network. The classification accuracy of the R.R.E algorithm is evaluated using simulations conducted in MATLAB. The R.R.E algorithm's behaviour is analyzed under linearly and non-linearly separable data sets. For the comparison with the Neural Network, the classical XOR problem is considered. This is a raw manuscript proposed and submitted by the author to the EE8209 Course Instructor in Winter 2012. EE8209 Course Instructor: Prof. Anastasios N. Venetsanopoulos. Copyright © 2014, by the author. All rights reserved.",
    "creator" : "PrimoPDF http://www.primopdf.com"
  }
}