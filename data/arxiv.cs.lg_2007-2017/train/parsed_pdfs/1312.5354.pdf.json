{
  "name" : "1312.5354.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Classification of Human Ventricular Arrhythmia in High Dimensional Representation Spaces",
    "authors" : [ "Yaqub Alwan", "Michael J. Curtis" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n31 2.\n53 54\nv2 [\ncs .C\nE ]\n2 8\nJu l 2\n01 4\nIndex Terms—Cardiac arrhythmias, tachycardia, fibrillation, classification, SVM ensembles.\nI. INTRODUCTION\nACCORDING to the World Health Organisationdata, cardiovascular disease is the leading cause of death in middle and high income countries, and among the top ten causes of death in low income countries [1]. Development of effective drug treatments that may prevent cardiac arrhythmia is therefore a high-priority challenge for modern pharmacology. For the development of such treatments it is crucial to have a clear understanding of what distinguishes different forms of arrhythmia, and based on that, establish their precise definitions. However, it is evident that although unequivocal ventricular fibrillation (VF), sustained and lethal, is incontestable in electrocardiogram (ECG) recordings, clinicians differ fundamentally about the diagnosis and appellation of transient polymorphic ventricular tachyarrhythmias, with experts in a landmark report unable to agree on whether VF, polymorphic ventricular tachycardia (VT) or torsade de pointes (TDP) best described a range of human tachyarrhythmias in a blinded test of ECG records [2]. This attests to limitations in definitions/appellation. Given that mechanisms of these tachyarrhythmias may differ [3] and responses to drugs may vary from benefit\nto proarrhythmia, depending on the type [4], errors in diagnosis due to unequivocal appellations are potentially hazardous. To allow preclinical research to be translatable, a definition was recently proposed to discriminate between VF, including brief and transient VF, and other polymorphic ventricular tachyarrhythmias [5]. This definition is not, however, readily transformed into an algorithm for automatic rhythm detection. Therefore, in the present study we develop novel algorithms for ventricular tachyarrhythmia classification and use them to assess whether it is possible to improve precision and accuracy of discrimination between VF and VT.\nThere have been many studies into the topic of differentiating sinus rhythm (SR) from VF, however fewer studies attempt to differentiate VT from VF. From a therapeutic point of view being able to differentiate between VF and VT is very important since they respond to interventions differently and VF is often lethal, while VT is often not. For VF and VT detection, Thakor et al. developed an algorithm which first applies a hard threshold to transform an ECG segment into a binary sequence, and then performs a sequential hypothesis test on the average number of zero crossings until a decision is made [6]. In [7], the authors proposed an algorithm which uses the energy distribution information in a wavelet transform domain to differentiate between VF, VT, and a VT-VF class which contains realisations that are difficult to categorise as either VT or VF. On the other hand, an estimate of the area occupied in the bispectral representation is proposed for classification between VF, VT, SR and atrial fibrillation in [8]. The standard deviations of the peak amplitudes and peak distances in a cross correlation between a window of ECG and a short window immediately prior is used to classify VT from VF in [9]. An algorithm for VF detection based on empirical mode decomposition (EMD), which creates a lower dimensional representation of ECG waveforms based on the energy in the first EMD component and its spectral entropy, was proposed in [10]. Counting the time between ECG turning points was proposed [11] to differentiate fast-VT, slow-VT and VF for use in automatic implantable cardiovertor defibrillators (AICDs). A comparison of ten methods for differentiating between\n2 non-VF and VF, for use in an automated external defibrillator (AED), was presented in [12]. The same authors subsequently proposed a phase space method [13] and demonstrate that it outperforms all methods studied in [12] in its capability to discriminate VF from nonVF segments. While all these previous works have been yielding gradual improvements, the problem of differentiating between SR, VT and VF is still not solved sufficiently accurately, the main difficulty being in differentiating between VT and VF [14]. Some of these studies even resort to creating a category specifically for the examples which are difficult to distinguish [7], [11]. Often, studies are conducted with limited or preselected data. In addition, all existing classification algorithms use heuristics to derive some low-dimensional representations of ECG signals and decision parameters, rather than provide a data-driven insight into what distinguishes one arrhythmia from another.\nThere is therefore a need for systematic investigation of classification of cardiac arrhythmias using representations which involve minimal information reduction, or data driven dimension reduction and classification using well established and understood statistical methods. We focus on discrimination between SR, VT, and VF, using as few heuristics as possible. In a preliminary study we considered classification in the domain of the ECG signal, and its Fourier magnitude spectra, using linear discriminant analysis (LDA), penalised discriminant analysis (PDA) and quadratic discriminant analysis (QDA), combined with principal component analysis (PCA) for data driven dimension reduction [14]. We concluded that there is benefit in considering non-linear class boundaries, but that QDA may not be the most suitable type of non-linearity, and that the training data was insufficient to obtain good generalization. In an attempt to address these issues, in the present study we considered classification with the same representation spaces using support vector machines (SVMs) [15].\nOne issue of interest is the selection of observation length which is most suitable for discrimination, whilst simultaneously trying to minimise detection time. In order to avoid introducing low-dimensional heuristic features, classification is performed directly in the space of ECG waveforms, and their Fourier magnitude spectra. Further, lower-dimensional representations obtained by projecting magnitude spectra onto respective principal component (PC) subspaces are also considered, in order to facilitate learning of non-linear boundaries using relatively limited training data. Even with this dimension reduction, the lowest representation dimension considered in this study is 10, which is significantly higher dimension than features vectors used in prior art. Experimental\nresults reported in Section IV demonstrate the benefits of considering such higher-dimensional representations for classification purposes.\nThe paper is organised as follows. In Section II we review a reference prior work, provide rationale for shorter observation windows, and specify dimensionreduction methods used. Section III provides details of the SVM classification framework used. Experimental procedure and results are reported in Section IV. Section V summarises the paper and draws conclusions."
    }, {
      "heading" : "II. GENERAL CONSIDERATIONS",
      "text" : "Given an ECG segment\nx = {x[n], n1 ≤ n ≤ n2} ,\nit is desired to be able to label it as being SR, VT or VF. For comparison, in this paper the phase space feature representation proposed in [13] is considered, since the authors conducted a thorough investigation and demonstrated its superior performance in terms of accuracy and numerical complexity compared to previously published algorithms."
    }, {
      "heading" : "A. Reference prior art",
      "text" : "The phase space algorithm (PSA) [13] aims at diagnosing whether a defibrillation shock should be delivered, which amounts to classifying ECG segments as VF or non-VF. The phase representation is formed by taking discretised values of samples of x as pairs (x1[n], x2[n]) in R2, where\nx1[n] = x[n]\nx2[n] = x[n− k]\nwhile k is selected to correspond to 0.5 s1. The discretisation step is chosen such that the complete range of x1[n] and x2[n] each take up to 401 unique values. The number N(x) of visited boxes in this phase space is then found, and finally, the ratio\nη(x) = N(x)\nNmax\nbetween the number of visited boxes and the total number of boxes Nmax = 40 × 40 is compared to an empirically determined threshold ηthresh = 0.151. If this threshold is exceeded, VF is decided, otherwise non-VF is decided. The representation space formed by N(x) (one-dimensional space) is referred to as PSA. We\n1These parameters are all selected by the original work, [13]\n3 introduce a modification where the phase space is formed by pairs\nx1[n] = x[n]\nx2[n] = x[n]− x[n− 1]\nagain discretised so that each take up to 40 unique values. This corresponds to the standard notion of a phase space, and it may be more robust to variations in heart rate. This modification is referred to as phase space modified (PSM). In Section IV results are reported for both versions of the phase space representation in comparison to other representations introduced here."
    }, {
      "heading" : "B. Observation length",
      "text" : "One of the important issues that needs to be investigated is the appropriate observation length for reliable classification of cardiac arrhythmias. Longer windows contain more information, and that should lead to higher classification accuracy, up to a point beyond which increasing observation length does not provide any additional discriminating information. This plateau can be expected to be followed by a decline in classification accuracy when windows are long enough to include transitions between ECG classes. For fast and reliable diagnosis it is of interest to simultaneously minimise observation length and maximise classification accuracy. However, a systematic investigation of this issue is lacking in prior studies.\nThe phase space method in its original formulation [13] counts the number of visited boxes over 8 s segments of ECG signals. Several other studies also form their respective feature vectors using 8 s observations [12], 6 s observations [9], or over 5 s observations [6]. Physiological considerations, on the other hand, suggest that shorter ECG segments should suffice. According to [16], VT is considered to occur if 4 or more consecutive QRS complexes precede their corresponding P-wave, independent of the rate. Assuming a heart rate of 60 beats per minute or higher in humans, a 2 s window should be sufficient to capture 2 normal beats. Thus, at least 3 premature QRS complexes would occur in the same 2 s interval, and since VT is usually accompanied by an increased heart rate, quite often 2 s should also be sufficient to capture 4 or more premature QRS complexes. For VF, QRS complexes are no longer discernible [16], which suggests the rate of cardiac deflections (not heart rate, since the notion is not applicable) is even higher than that of VT. Therefore, a 2 s window should be sufficient for capturing the disorder of VF also. Hence, this study will be centred around 2 s windows, while 0.5 s, 1 s, and 4 s windows will be also\nconsidered in order to assess effects of observation length on the classification accuracy and draw some conclusions on its optimal value."
    }, {
      "heading" : "C. Dimension reduction",
      "text" : "In order to avoid any bias due to preconceptions on what features are relevant for arrhythmia classification, classification directly in the domain of ECG waveforms is considered as a starting point. Further, Fourier magnitude spectra of ECG segments are considered as they provide representations invariant to time shifts while preserving most of the information contained in the original waveforms. At 100 Hz sampling, which is close to the minimal sampling frequency which does not cause apparent distortions of ECG signals, 4 s observation length results in 400-dimensional feature space (or 200- dimensional space if magnitude spectra are considered), which can make statistical inference challenging. This is dealt with by employing data-driven dimension reduction based on PCA. We performed PCA on magnitude spectra of each individual class, and formed sets of basis vectors by the union of top N principal components from each class. Since at least 5 principal components are required to capture at least 60% of the energy for each class, this is the lower limit considered. For the two class case, this forms a space of dimension 10, and 15 in the three-class case. The upper limit on the number of principal directions considered is 15, since already then the dimension of the complete representation for threeclass tasks becomes as high a 45, which exceeds the dimension of 0.5 s magnitude spectra. Since class labels are utilised, this step is performed as a supervised step in experiments reported in IV, only having access to the training set for the purposes of learning the basis vectors."
    }, {
      "heading" : "III. CLASSIFICATION USING SUPPORT VECTOR MACHINES",
      "text" : "Given a set of training data (x1, . . . ,xp) with corresponding class labels (y1, . . . , yp) , yi ∈ {+1,−1}, an SVM attempts to find a decision surface which jointly maximizes the margin between the two classes and minimizes the misclassification error on the training set. When the classes are linearly separable, these surfaces are linear and have the form\nf(x) = ∑\ni\naiyi〈x,xi〉+ b = 0, ai ∈ R + (1)\nwhere 〈·, ·〉 is the inner product in Rn, while the Lagrange multipliers ai and the bias b are optimized by the training algorithm. Non-linear separators between two classes are created by means of non-linear kernel functions K(·, ·). These functions compute inner products in\n4 higher dimensional spaces, without explicitly performing the mapping, where the data could potentially be linearly separable. Analogously to the linearly separable case, the decision surface is constructed according to\nf(x) = ∑\ni\naiyiK(x,xi) + b = 0 (2)\nand the class label of a test vector x is predicted to be the sign of the score function evaluated at x, i.e.\nC(x) = sgn(f(x)) .\nOne commonly used kernel function is the polynomial kernel, of the form\nKp(x, y) = (1 + c〈x, y〉) d, d ∈ N (3)\nwhere c and d are optimised using a grid search. Another kernel function is the radial basis function (RBF) kernel given by\nKr(x, y) = e −γ||x−y||2 , γ ∈ R+ (4)\nwhere γ is also optimised using a grid search."
    }, {
      "heading" : "A. Optimising SVM parameters",
      "text" : "Unlike with LDA and QDA, there are SVM parameters that need to be chosen optimally for best results. The idea is to avoid selecting parameters too finely tuned to the training data, while still giving good classification performance on unseen examples (test data). For SVMs using either the linear, polynomial, or RBF kernels, these parameters are:\nC: Trade-off between margin width and misclassified examples from the training data\nγ: RBF kernel parameter which controls the width of the Gaussian function. Small values of γ lead to increasing flexibility of the decision boundary, while large values of γ lead to decreases in flexibility.\nc, d: Polynomial kernel parameters which when increased, increase the flexibility of the decision boundary, and when small, decrease the flexibility of the decision boundary\nWhen performing the grid search, a grid with a coarse granularity is selected with two benefits: It reduces training time required and it prevents parameters being tuned too exactly to the training data. A commonly used strategy for selecting C is to search a logarithmic grid, e.g. C ∈ {10−N , 10−N+1, . . . , 10N} [17], [18]. We selected a smaller set of this range to search, depending on the kernel. For the linear kernel C was varied through 10N Dmean , N ∈ {0, . . . , 4}, where Dmean is the mean Euclidean distance between training points from different classes. For the polynomial and RBF kernels, C was varied over {100, . . . , 104}.\n70% 30% ︷ ︸︸ ︷︷ ︸︸ ︷\nTr V CV CV CV CV CV ︸ ︷︷ ︸︸ ︷︷ ︸\n33% 67%\nFig. 1. The data is partitioned into three groups; training, validation, and CV folds. After user selected parameters are estimated with sets Tr and V, these sets are discarded, and 5-fold cross validation is performed with the sets labelled CV\nThe RBF kernel parameter γ was selected such that a learned decision boundary is neither too flexible nor insufficiently flexible. An estimate for the center of a search region is given as\nγstart = − log10 Dmean . (5)\nThen, with center point specified by (5), the search region is selected as\nγsearch = 10 N , N ∈ [γstart − 2, γstart + 2] . (6)\nThe polynomial kernel parameters c and d were again chosen to enable sufficient flexibility. For this purpose, we chose d ∈ [2, 6], allowing increasing flexibility with polynomial degree. In order to limit the magnitude of the response of the polynomial kernel, we used the following estimate for the starting point of c;\ncstart = 1\nargmax k\n||xi|| 2 , (7)\nwhere xi are the training data points. Then, to allow optimisation, a logarithmic range around cstart was considered,\ncsearch = cstart · 2 2k, k ∈ [−3, . . . , 3] . (8)\nIn order to ensure we have an good estimate of generalisation accuracy with limited training data, we utilise data hold out, and cross validation. For that purpose, the data was partitioned according to the scheme shown in Fig. 1. For estimating user selected parameters, (e.g. the SVM cost parameter C, RBF parameter γ, polynomial kernel parameters c and d), one third of the data is ”held out” to be used for this estimation. Then, to estimate the generalisation accuracy, the remaining data is split into equally sized sets. One of each of the sets is held out, while the remainder is used for training a classifier (and estimating principal components, when relevant). The held out set is then used as a test set for recording classification accuracy. This is repeated with each of the sets used once as a test set. Then, the mean accuracy and standard error across all test sets can be computed.\n5 When comparing different classifiers, only the cross validation partitions are used for estimation of generalisation accuracy, even if the method did not require parameter estimation, i.e. QDA and LDA classifiers never see the data in the training and validation partitions."
    }, {
      "heading" : "B. Multiclass classification using SVMs",
      "text" : "For multiclass discrimination, binary SVM classifiers are combined via predefined error-correcting output code methods [19], [20]. To summarize the procedure briefly, N binary classifiers are trained to distinguish between M classes using a coding matrix WM×N , with elements wmn ∈ {0, 1,−1}. Classifier n is trained only on data of classes m for which wmn 6= 0, with sgn(wmn) as the class label. Then, the class assignment rule is given by\nC(x) = argmin m\nN∑\nn=1\nχ(wmnfn(x)) , (9)\nwhere fn(x) is the output of the nth classifier and χ is some loss function.\nThe error-correcting capability of a code is commensurate with the minimum Hamming distance between the rows of a coding matrix; if this minimum distance is δ, then the multiclass classifier will be able to correct any ⌊ δ−1\n2 ⌋ errors [19]. For the three class problem,\n{SR, V T, V F}, we consider all one-vs-one (pairwise) and all one-vs-all binary classifiers, which makes a total of six binary classifiers. Note that in the case of three classes, this exhausts all possible binary classifiers. The corresponding coding matrix in this case thus has the form\nW =\n\n 1 1 −1 1 1 0 1 −1 1 0 −1 1\n−1 1 1 −1 0 −1\n\n . (10)\nA number of loss functions were compared, including hinge: χ(z) = max(1 − z, 0), Hamming: χ(z) = [1 − sgn(z)]/2, exponential: χ(z) = e−z, and linear: χ(z) = −z. The hinge loss function performed best and therefore is the only loss function for which results are reported in Section IV-B. Even so, the differences of decoding with varying loss functions only changed by few percent, with exponential loss typically performing the worst, and linear loss performing almost as well as hinge loss."
    }, {
      "heading" : "C. Classifier ensembles",
      "text" : "Ensembles or committees of classifiers can often be combined to improve classification accuracy [18]. For that purpose we considered ensembles of decision values\nof binary SVM classifiers applied to ECG segments of a given length, taken with incremental shifts with respect to each other, e.g. 2 s segments taken over 4 s intervals with 0.5 s shifts to form ensembles of 5 decision values. The mean of decision values were then used as the corresponding values of fn(x) in the loss decoding given by (9). We also considered combining individual decision values within ensembles using median, majority vote, and maximum aggregation functions, but mean gave best results."
    }, {
      "heading" : "IV. EXPERIMENTAL PROCEDURE AND RESULTS",
      "text" : ""
    }, {
      "heading" : "A. Data and preprocessing",
      "text" : "1) Data sets: Data were taken from Physiobank [21], which maintains a large online repository of various physiological signals, including ECG signals. The databases used from Physiobank were the European ST-T Database (EDB) [22], the Creighton University Ventricular Tachyarrhythmia Database (CUDB) [23], the MIT-BIH Arrhythmia Database (MITDB) [24], the MIT-BIH Malignant Ventricular Arrhythmia Database (VFDB) [25]. Only data that were explicitly labelled as SR, VT or VF were used. Due to the fact that the databases EDB and MITDB do not contain many realisations of VT or VF, additional realisations of VT and VF are taken from VFDB, and further VF realisations from CUDB. Neither of these databases contain annotations that have been audited thoroughly, so they were only used to augment examples of ventricular arrhythmias, which are few in the other databases.\n2) Preprocessing: In all these databases, 250 Hz sampling rate is used, apart from MITDB where signals are sampled at 360 Hz. It is considered that most of the relevant information is contained in the 40 Hz baseband [26] and that preprocessing with a 30 Hz low pass filter does not affect experimental results [7], [10], [12], [13]. However, based on visual inspection of low-pass filtered data it was decided that 30 Hz cut-off frequency was too low, so 49 Hz low-pass filtering was used, followed by downsampling to 100 Hz. In addition to this, a 0.5 Hz high pass filter was applied to remove wandering baseline [26]. As in our previous study [14], all ECG records were normalised so that the squared sum of each record is equal to the number of samples in the record, thus making the variance of individual time samples equal to 1.\n3) Data balancing: Using rhythm annotations, either SR, VT, or VF were extracted from these databases. The continuous sequences of the rhythms were then segmented according to window length for the experiment, and shuffled randomly. Since there were many\n6 more examples of SR, this class was randomly subsampled to approximately the same amount as VT and VF, each of which had a total duration of approximately 6000 s. For several reasons, balanced sets of the three classes were used. First, it is hard to understand what the relevant class priors should be, since it is highly context dependent, and also very hard to estimate. For example, in an AICD, which is always on, the presence of normal rhythm is much higher than arrhythmia, but exactly how much higher is hard to quantify (e.g it depends on the specific patient’s predisposition to an arrhythmia, underlying causes, etc). On the other hand, an AED is meant for use in emergency situations, e.g. when a patient is unconscious or not breathing, which makes the relative exposure of such a device to ECG episodes of normal rhythm and arrhythmia considerably different, and could be uniform or even skewed towards arrhythmia. Secondly, the SVM classification framework, which is used in this study, does not support notion of priors in the formulation. Finally, balanced sets prevent falsely high classification accuracy obtained by capitalising on high number of realisations of one of the classes."
    }, {
      "heading" : "B. SVM classification results and comparison with QDA",
      "text" : "Fig. 2a, Fig. 2b and Fig. 2c show results of classification of non-VF vs VF, VT vs VF, and SR vs VT vs VF, respectively in the time, magnitude spectra, reduced magnitude spectra, PSA, and PSM representation spaces. This classification experiment was performed using 2 s observation windows, as our preliminary work showed that there is minor benefit in using longer segments [14]. To assess benefits of more flexible non-linear class boundaries offered by the SVM framework, we considered SVM classification using polynomial and RBF kernels in comparison with linear kernels and QDA.\nFirst it can be observed that classification using magnitude spectra or their reduced versions achieves much higher accuracy than classification using timedomain waveforms or PSA/PSM representations. This is in agreement with results of our preliminary analysis which used LDA and QDA classification [14]. Hence, time-domain ECG waveforms, PSA and PSM were not considered any further. In most cases at least 5% improvement in classification accuracy over QDA or linear SVMs is achieved by use of SVMs with non-linear kernel functions (Fig. 2).\nCorresponding sensitivity values (not included in the paper) revealed a bias in classification, usually towards SR. The average sensitivities for VT and VF did not exceed 90%, despite achieving a best accuracy of 91% with a very small standard error. The bias was more\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nA cc\nur ac\ny\nTime Sam\nples Mag Spe c\nMag Spe\nc 15 PC Mag Spe c 10 PC Mag Spe c 5P C PSA PSM\nQDA Linear SVM Polynomial SVM RBF SVM\n(a)\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nA cc\nur ac\ny\nTime Sam\nples Mag Spe c\nMag Spe\nc 15 PC Mag Spe c 10 PC Mag Spe c 5P C PSA PSM\nQDA Linear SVM Polynomial SVM RBF SVM\n(b)\n7 0.5s 1s 2s 4s 0.4 0.5 0.6 0.7 0.8 0.9 1 A cc ur ac y Mag Spec Mag Spec 15PC Mag Spec 10PC Mag Spec 5PC\nFig. 3. Average cross-validated accuracies with errorbars for classification between SR, VT and VF using 0.5, 1, 2 and 4 second observation lengths in the magnitude spectra and projections of magnitude spectra onto principal component spaces. Classification is performed with RBF kernel SVM\npronounced with certain classifiers (QDA) and representation spaces (time-domain ECG, phase space representations).\nHaving established that the best performing representations were the magnitude spectra and their subspaces, and that SVMs with RBF kernels achieved highest accuracy, the issue of window length was revisited. Fig. 3 shows results of SR versus VT versus VF classification\n3s 4s 5s 6s 0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nA cc\nur ac\ny\n2s Win/0.5s Offset 2s Win/0.25s Offset 1s Win/0.5s Offset 1s Win/0.25s Offset\nFig. 4. Average cross-validated accuracies with errorbars for classification between SR, VT and VF using 3, 4, 5 and 6 second observation lengths in the magnitude spectra representation space with RBF SVM classifiers. Ensembles were obtained by using 2 second or 1 second windows, and 0.5 second or 0.25 second offsets.\nin magnitude spectra representation spaces using SVMs with RBF kernels for observation lengths of 0.5 s, 1 s, 2 s, and 4 s. The corresponding sensitivities of individual classes are shown in TABLE I. The overall accuracy and the sensitivities improved with increasing observation lengths up to 2 s when a performance plateau is attained, in agreement with our preliminary study in which LDA, and QDA were used [14]. The fact that increasing the segment length from 2 s to 4 s did not affect classification accuracy inspired forming ensembles of classifiers acting on segments taken with incremental shifts over a larger observation window.\nFig. 4 shows results of classification between SR, VT and VF using SVM decision values averaged over an ensemble of ECG segments, extracted from longer windows, as specified in Section III-C. These shorter segments were transformed to the best performing representation space, magnitude spectra, and classified using SVMs with RBF kernels. For this purpose 1 s and 2 s segments for classification were considered, taken with 0.25 s and 0.5 s shifts from 3 s, 4 s, 5 s and 6 s windows. For ensembles formed over 5 s or longer, all variants performed with 90% or greater sensitivity for all classes (TABLE II). The best performing ensemble was obtained with 1 s segments, shifted by 0.5 s, extracted from larger windows of 5 s. Average sensitivities obtained with these ensembles were above 93% for all classes. For these parameters, we show in Fig. 5 some examples of misclassified data. Fig. 5a shows three examples of rhythms labelled as VT by the databases, and classified as VF by the classifier; Fig. 5b shows three examples of rhythms labelled as VF by the databases, and classified\n8\nas VT by the classifier. In our opinion, these examples are classified correctly by the algorithm and mislabelled in the databases. Thus, the databases themselves impose a limitation on the best achievable accuracy, but also limit what is learnable from the data, particularly if considerable amounts of data are mislabelled."
    }, {
      "heading" : "V. CONCLUSION",
      "text" : "A systematic study of ECG rhythm classification was presented, to develop methods for accurate classification between SR, VT and VF. Classification was performed in the space of ECG waveforms, their magnitude spectra, and lower-dimensional approximations of magnitude spectra using projections onto their principal component spaces. All representation spaces are of much higher dimension than considered in previous studies. We found that classification accuracy improves with observation length up to about 2 s, where it reaches a plateau, which is significantly shorter than used in previous studies [9], [12], [13]. Since VF can be highly transient in some animal models this may assist translational research.\nAmong considered representation spaces and classification methods, magnitude spectra and SVM classifiers with RBF kernels achieved highest accuracy. In combination they achieved classification accuracy of 91% and sensitivity of at least 86% for each class using only 2 s\nsegments of ECG signals. However, ensembles of SVM classifiers applied to 1 s segments over a 5 s intervals reduced classifier bias and achieved 94% classification accuracy, with sensitivity for each class at 93% or higher."
    } ],
    "references" : [ {
      "title" : "Who — the top 10 causes of death",
      "author" : [ "W.H. Organization" ],
      "venue" : "http://www.who.int/mediacentre/factsheets/fs310/en/index.html, 2012, [Online; accessed 8-November-2012].",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Self-terminating ventricular tachyarrhythmias - a diagnostic dilemma?",
      "author" : [ "R. Clayton", "A. Murray", "P. Higham", "R. Campbell" ],
      "venue" : "The Lancet,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1993
    }, {
      "title" : "Phase 2 ventricular arrhythmias in acute myocardial infarction: a neglected target for therapeutic antiarrhythmic drug development and for safety pharmacology evaluation",
      "author" : [ "H. Clements-Jewery", "D. Hearse", "M. Curtis" ],
      "venue" : "Br. J. Pharmacol., vol. 145, no. 5, pp. 551–564, Jul 2005.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Pro- and antiarrhythmic effects of ATPsensitive potassium current activation on reentry during  9 early afterdepolarization-mediated arrhythmias",
      "author" : [ "M. Chang", "E. de Lange", "G. Calmettes", "A. Garfinkel", "Z. Qu", "J. Weiss" ],
      "venue" : "Heart Rhythm, vol. 10, no. 4, pp. 575–582, Apr 2013.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The lambeth conventions (ii): Guidelines for the study of animal and human ventricular and supraventricular arrhythmias",
      "author" : [ "M.J. Curtis", "J.C. Hancox", "A. Farkas", "C.L. Wainwright", "C.L. Stables", "D.A. Saint", "H. Clements-Jewery", "P.D. Lambiase", "G.E. Billman", "M.J. Janse", "M.K. Pugsley", "G.A. Ng", "D.M. Roden", "A.J. Camm", "M.J. Walker" ],
      "venue" : "Pharmacology & Therapeutics, vol. 139, no. 2, pp. 213–248, 2013.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Ventricular tachycardia and fibrillation detection by a sequential hypothesis testing algorithm",
      "author" : [ "N. Thakor", "Y.-S. Zhu", "K.-Y. Pan" ],
      "venue" : "IEEE Transactions on Biomedical Engineering, vol. 37, no. 9, pp. 837–843, September 1990.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "Wavelet-based features for characterizing ventricular arrhythmias in optimizing treatment options",
      "author" : [ "K. Balasundaram", "S. Masse", "K. Nair", "T. Farid", "K. Nanthakumar", "K. Umapathy" ],
      "venue" : "Annual International Conference of the IEEE Engineering in Medicine and Biology Society, September 2011, pp. 969–972.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "A quantitative analysis approach for cardiac arrhythmia classification using higher order spectral techniques",
      "author" : [ "L. Khadra", "A. Al-Fahoum", "S. Binajjaj" ],
      "venue" : "IEEE Transactions on Biomedical Engineering, vol. 52, no. 11, pp. 1840–1845, November 2005.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1840
    }, {
      "title" : "Distinction of ventricular fibrillation and ventricular tachycardia using cross correlation",
      "author" : [ "J. Ruiz", "E. Aramendi", "S. Ruiz de Gauna", "A. Lazkano", "L. Leturiondo", "J. Gutierrez" ],
      "venue" : "Computers in Cardiology, September 2003, pp. 729–732.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Ventricular fibrillation detection based on empirical mode decomposition",
      "author" : [ "B. Bai", "Y. Wang" ],
      "venue" : "5th International Conference on Bioinformatics and Biomedical Engineering, May 2011, pp. 1–4.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Discrimination of fast ventricular tachycardia from ventricular fibrillation and slow ventricular tachycardia for an implantable pacer-cardioverter-defibrillator",
      "author" : [ "W. Olson", "D. Peterson", "L. Ruetz", "B. Gunderson", "M. Fang- Yen" ],
      "venue" : "Computers in Cardiology, September 1993, pp. 835–838.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Reliability of old and new ventricular fibrillation detection algorithms for automated external defibrillators",
      "author" : [ "A. Amann", "R. Tratnig", "K. Unterkofler" ],
      "venue" : "BioMedical Engineering OnLine, vol. 4, no. 1, p. 60, 2005.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Detecting ventricular fibrillation by time-delay methods",
      "author" : [ "——" ],
      "venue" : "IEEE Transactions on Biomedical Engineering, vol. 54, no. 1, pp. 174–177, Jan 2007.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "High-dimensional discriminant analysis of human cardiac arrhythmias",
      "author" : [ "Y. Alwan", "Z. Cvetković", "M.J. Curtis" ],
      "venue" : "Proceedings European Signal Processing Conference, 2013, In press.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Support-vector networks",
      "author" : [ "C. Cortes", "V. Vapnik" ],
      "venue" : "Machine Learning, 1995, pp. 273–297.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "The lambeth conventions: guidelines for the study of arrhythmias in ischaemia, infarction, and reperfusion",
      "author" : [ "M.J.A. Walker", "M.J. Curtis", "D.J. Hearse", "R.W.F. Campbell", "M.J. Janse", "D.M. Yellon", "S.M. Cobbe", "S.J. Coker", "J.B. Harness", "D.W.G. Harron", "A.J. Higgins", "D.G. Julian", "M.J. Lab", "A.S. Manning", "B.J. Northover", "J.R. Parratt", "R.A. Riemersma", "E. Riva", "D.C. Russell", "D.J. Sheridan", "E. Winslow", "B. Woodward" ],
      "venue" : "Cardiovascular Research, vol. 22, no. 7, pp. 447–455, 1988.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "Kernel Methods for Pattern Analysis",
      "author" : [ "J. Shawe-Taylor", "N. Cristianini" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2004
    }, {
      "title" : "The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd ed., ser",
      "author" : [ "T. Hastie", "R. Tibshirani" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2009
    }, {
      "title" : "Solving multiclass learning problems via error-correcting output codes",
      "author" : [ "T.G. Dietterich", "G. Bakiri" ],
      "venue" : "Journal of Artificial Intelligence Research, vol. 2, pp. 263–286, 1995.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Reducing multiclass to binary: a unifying approach for margin classifiers",
      "author" : [ "E.L. Allwein", "R.E. Schapire", "Y. Singer" ],
      "venue" : "Journal of Machine Learning Research, vol. 1, pp. 113–141, 2001.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Physiobank, physiotoolkit, and physionet : Components of a new research resource for complex physiologic signals",
      "author" : [ "A.L. Goldberger", "L.A.N. Amaral", "L. Glass", "J.M. Hausdorff", "P.C. Ivanov", "R.G. Mark", "J.E. Mietus", "G.B. Moody", "C.- K. Peng", "H.E. Stanley" ],
      "venue" : "Circulation, vol. 101, no. 23, pp. e215– e220, 2000.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "The european st-t database: standard for evaluating systems for the analysis of st-t changes in ambulatory electrocardiography",
      "author" : [ "A. Taddei", "G. Distante", "M. Emdin", "P. Pisani", "G.B. Moody", "C. Zeelenberg", "C. Marchesi" ],
      "venue" : "European Heart Journal, vol. 13, no. 9, pp. 1164–1172, 1992.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "Creigard, a new concept in computerized arrhythmia monitoring systems",
      "author" : [ "F. Nolle", "F. Badura", "J. Catlett", "R. Bowser", "M. Sk" ],
      "venue" : "Computers in Cardiology, vol. 13, pp. 515–518, 1986.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 1986
    }, {
      "title" : "The impact of the mit-bih arrhythmia database",
      "author" : [ "G. Moody", "R. Mark" ],
      "venue" : "Engineering in Medicine and Biology Magazine, IEEE, vol. 20, no. 3, pp. 45–50, June 2001.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Development and analysis of a ventricular fibrillation detector",
      "author" : [ "S. Greenwald" ],
      "venue" : "Master’s thesis, MIT Dept. of Electrical Engineering and Computer Science, 1986.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 1986
    }, {
      "title" : "Cardiac arrhythmia detection using dynamic time warping of ecg beats in e-healthcare systems",
      "author" : [ "B. Raghavendra", "D. Bera", "A. Bopardikar", "R. Narayanan" ],
      "venue" : "IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks, June 2011, pp. 1–6.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "ACCORDING to the World Health Organisation data, cardiovascular disease is the leading cause of death in middle and high income countries, and among the top ten causes of death in low income countries [1].",
      "startOffset" : 201,
      "endOffset" : 204
    }, {
      "referenceID" : 1,
      "context" : "However, it is evident that although unequivocal ventricular fibrillation (VF), sustained and lethal, is incontestable in electrocardiogram (ECG) recordings, clinicians differ fundamentally about the diagnosis and appellation of transient polymorphic ventricular tachyarrhythmias, with experts in a landmark report unable to agree on whether VF, polymorphic ventricular tachycardia (VT) or torsade de pointes (TDP) best described a range of human tachyarrhythmias in a blinded test of ECG records [2].",
      "startOffset" : 497,
      "endOffset" : 500
    }, {
      "referenceID" : 2,
      "context" : "Given that mechanisms of these tachyarrhythmias may differ [3] and responses to drugs may vary from benefit to proarrhythmia, depending on the type [4], errors in diagnosis due to unequivocal appellations are potentially hazardous.",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 3,
      "context" : "Given that mechanisms of these tachyarrhythmias may differ [3] and responses to drugs may vary from benefit to proarrhythmia, depending on the type [4], errors in diagnosis due to unequivocal appellations are potentially hazardous.",
      "startOffset" : 148,
      "endOffset" : 151
    }, {
      "referenceID" : 4,
      "context" : "To allow preclinical research to be translatable, a definition was recently proposed to discriminate between VF, including brief and transient VF, and other polymorphic ventricular tachyarrhythmias [5].",
      "startOffset" : 198,
      "endOffset" : 201
    }, {
      "referenceID" : 5,
      "context" : "sequence, and then performs a sequential hypothesis test on the average number of zero crossings until a decision is made [6].",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 6,
      "context" : "In [7], the authors proposed an algorithm which uses the energy distribution information in a wavelet transform domain to differentiate between VF, VT, and a VT-VF class which contains realisations that are difficult to categorise as either VT or VF.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 7,
      "context" : "On the other hand, an estimate of the area occupied in the bispectral representation is proposed for classification between VF, VT, SR and atrial fibrillation in [8].",
      "startOffset" : 162,
      "endOffset" : 165
    }, {
      "referenceID" : 8,
      "context" : "The standard deviations of the peak amplitudes and peak distances in a cross correlation between a window of ECG and a short window immediately prior is used to classify VT from VF in [9].",
      "startOffset" : 184,
      "endOffset" : 187
    }, {
      "referenceID" : 9,
      "context" : "An algorithm for VF detection based on empirical mode decomposition (EMD), which creates a lower dimensional representation of ECG waveforms based on the energy in the first EMD component and its spectral entropy, was proposed in [10].",
      "startOffset" : 230,
      "endOffset" : 234
    }, {
      "referenceID" : 10,
      "context" : "Counting the time between ECG turning points was proposed [11] to differentiate fast-VT, slow-VT and VF for use in automatic implantable cardiovertor defibrillators (AICDs).",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 11,
      "context" : "non-VF and VF, for use in an automated external defibrillator (AED), was presented in [12].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 12,
      "context" : "The same authors subsequently proposed a phase space method [13] and demonstrate that it outperforms all methods studied in [12] in its capability to discriminate VF from nonVF segments.",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 11,
      "context" : "The same authors subsequently proposed a phase space method [13] and demonstrate that it outperforms all methods studied in [12] in its capability to discriminate VF from nonVF segments.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 13,
      "context" : "While all these previous works have been yielding gradual improvements, the problem of differentiating between SR, VT and VF is still not solved sufficiently accurately, the main difficulty being in differentiating between VT and VF [14].",
      "startOffset" : 233,
      "endOffset" : 237
    }, {
      "referenceID" : 6,
      "context" : "Some of these studies even resort to creating a category specifically for the examples which are difficult to distinguish [7], [11].",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 10,
      "context" : "Some of these studies even resort to creating a category specifically for the examples which are difficult to distinguish [7], [11].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 13,
      "context" : "(PCA) for data driven dimension reduction [14].",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 14,
      "context" : "In an attempt to address these issues, in the present study we considered classification with the same representation spaces using support vector machines (SVMs) [15].",
      "startOffset" : 162,
      "endOffset" : 166
    }, {
      "referenceID" : 12,
      "context" : "For comparison, in this paper the phase space feature representation proposed in [13] is considered, since the authors conducted a thorough investigation and demonstrated its superior performance in terms of accuracy and numerical complexity compared to previously published algorithms.",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 12,
      "context" : "The phase space algorithm (PSA) [13] aims at diagnosing whether a defibrillation shock should be delivered, which amounts to classifying ECG segments as VF or non-VF.",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 12,
      "context" : "These parameters are all selected by the original work, [13]",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 12,
      "context" : "tion [13] counts the number of visited boxes over 8 s segments of ECG signals.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 11,
      "context" : "Several other studies also form their respective feature vectors using 8 s observations [12], 6 s observations [9], or over 5 s observations [6].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 8,
      "context" : "Several other studies also form their respective feature vectors using 8 s observations [12], 6 s observations [9], or over 5 s observations [6].",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 5,
      "context" : "Several other studies also form their respective feature vectors using 8 s observations [12], 6 s observations [9], or over 5 s observations [6].",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 15,
      "context" : "According to [16], VT is considered to occur if 4 or more consecutive QRS complexes precede their corresponding P-wave, independent of the rate.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 15,
      "context" : "For VF, QRS complexes are no longer discernible [16], which suggests the rate of cardiac deflections (not heart rate, since the notion is not applicable) is even higher than that of VT.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 16,
      "context" : ", 10} [17], [18].",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 17,
      "context" : ", 10} [17], [18].",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 1,
      "context" : "For this purpose, we chose d ∈ [2, 6], allowing increasing flexibility with polynomial degree.",
      "startOffset" : 31,
      "endOffset" : 37
    }, {
      "referenceID" : 5,
      "context" : "For this purpose, we chose d ∈ [2, 6], allowing increasing flexibility with polynomial degree.",
      "startOffset" : 31,
      "endOffset" : 37
    }, {
      "referenceID" : 18,
      "context" : "For multiclass discrimination, binary SVM classifiers are combined via predefined error-correcting output code methods [19], [20].",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 19,
      "context" : "For multiclass discrimination, binary SVM classifiers are combined via predefined error-correcting output code methods [19], [20].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 18,
      "context" : "The error-correcting capability of a code is commensurate with the minimum Hamming distance between the rows of a coding matrix; if this minimum distance is δ, then the multiclass classifier will be able to correct any ⌊ δ−1 2 ⌋ errors [19].",
      "startOffset" : 236,
      "endOffset" : 240
    }, {
      "referenceID" : 17,
      "context" : "Ensembles or committees of classifiers can often be combined to improve classification accuracy [18].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 20,
      "context" : "1) Data sets: Data were taken from Physiobank [21], which maintains a large online repository of various physiological signals, including ECG signals.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 21,
      "context" : "The databases used from Physiobank were the European ST-T Database (EDB) [22], the Creighton University Ventricular Tachyarrhythmia Database (CUDB) [23], the MIT-BIH Arrhythmia Database (MITDB) [24], the MIT-BIH Malignant Ventricular Arrhythmia Database (VFDB) [25].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 22,
      "context" : "The databases used from Physiobank were the European ST-T Database (EDB) [22], the Creighton University Ventricular Tachyarrhythmia Database (CUDB) [23], the MIT-BIH Arrhythmia Database (MITDB) [24], the MIT-BIH Malignant Ventricular Arrhythmia Database (VFDB) [25].",
      "startOffset" : 148,
      "endOffset" : 152
    }, {
      "referenceID" : 23,
      "context" : "The databases used from Physiobank were the European ST-T Database (EDB) [22], the Creighton University Ventricular Tachyarrhythmia Database (CUDB) [23], the MIT-BIH Arrhythmia Database (MITDB) [24], the MIT-BIH Malignant Ventricular Arrhythmia Database (VFDB) [25].",
      "startOffset" : 194,
      "endOffset" : 198
    }, {
      "referenceID" : 24,
      "context" : "The databases used from Physiobank were the European ST-T Database (EDB) [22], the Creighton University Ventricular Tachyarrhythmia Database (CUDB) [23], the MIT-BIH Arrhythmia Database (MITDB) [24], the MIT-BIH Malignant Ventricular Arrhythmia Database (VFDB) [25].",
      "startOffset" : 261,
      "endOffset" : 265
    }, {
      "referenceID" : 25,
      "context" : "It is considered that most of the relevant information is contained in the 40 Hz baseband [26] and that preprocessing with a 30 Hz low pass filter does not affect experimental results [7], [10], [12], [13].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 6,
      "context" : "It is considered that most of the relevant information is contained in the 40 Hz baseband [26] and that preprocessing with a 30 Hz low pass filter does not affect experimental results [7], [10], [12], [13].",
      "startOffset" : 184,
      "endOffset" : 187
    }, {
      "referenceID" : 9,
      "context" : "It is considered that most of the relevant information is contained in the 40 Hz baseband [26] and that preprocessing with a 30 Hz low pass filter does not affect experimental results [7], [10], [12], [13].",
      "startOffset" : 189,
      "endOffset" : 193
    }, {
      "referenceID" : 11,
      "context" : "It is considered that most of the relevant information is contained in the 40 Hz baseband [26] and that preprocessing with a 30 Hz low pass filter does not affect experimental results [7], [10], [12], [13].",
      "startOffset" : 195,
      "endOffset" : 199
    }, {
      "referenceID" : 12,
      "context" : "It is considered that most of the relevant information is contained in the 40 Hz baseband [26] and that preprocessing with a 30 Hz low pass filter does not affect experimental results [7], [10], [12], [13].",
      "startOffset" : 201,
      "endOffset" : 205
    }, {
      "referenceID" : 25,
      "context" : "5 Hz high pass filter was applied to remove wandering baseline [26].",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 13,
      "context" : "As in our previous study [14], all ECG records were normalised so that the squared sum of each record is equal to the number of samples in the record, thus making the variance of individual time samples equal to 1.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 13,
      "context" : "This classification experiment was performed using 2 s observation windows, as our preliminary work showed that there is minor benefit in using longer segments [14].",
      "startOffset" : 160,
      "endOffset" : 164
    }, {
      "referenceID" : 13,
      "context" : "This is in agreement with results of our preliminary analysis which used LDA and QDA classification [14].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 13,
      "context" : "The overall accuracy and the sensitivities improved with increasing observation lengths up to 2 s when a performance plateau is attained, in agreement with our preliminary study in which LDA, and QDA were used [14].",
      "startOffset" : 210,
      "endOffset" : 214
    }, {
      "referenceID" : 8,
      "context" : "We found that classification accuracy improves with observation length up to about 2 s, where it reaches a plateau, which is significantly shorter than used in previous studies [9], [12], [13].",
      "startOffset" : 177,
      "endOffset" : 180
    }, {
      "referenceID" : 11,
      "context" : "We found that classification accuracy improves with observation length up to about 2 s, where it reaches a plateau, which is significantly shorter than used in previous studies [9], [12], [13].",
      "startOffset" : 182,
      "endOffset" : 186
    }, {
      "referenceID" : 12,
      "context" : "We found that classification accuracy improves with observation length up to about 2 s, where it reaches a plateau, which is significantly shorter than used in previous studies [9], [12], [13].",
      "startOffset" : 188,
      "endOffset" : 192
    } ],
    "year" : 2014,
    "abstractText" : "We studied classification of human ECGs labelled as normal sinus rhythm, ventricular fibrillation and ventricular tachycardia by means of support vector machines in different representation spaces, using different observation lengths. ECG waveform segments of duration 0.5-4 s, their Fourier magnitude spectra, and lower dimensional projections of Fourier magnitude spectra were used for classification. All considered representations were of much higher dimension than in published studies. Classification accuracy improved with segment duration up to 2 s, with 4 s providing little improvement.We found that it is possible to discriminate between ventricular tachycardia and ventricular fibrillation by the present approach with much shorter runs of ECG (2 s, minimum 86% sensitivity per class) than previously imagined. Ensembles of classifiers acting on 1 s segments taken over 5 s observation windows gave best results, with sensitivities of detection for all classes exceeding 93%.",
    "creator" : "LaTeX with hyperref package"
  }
}