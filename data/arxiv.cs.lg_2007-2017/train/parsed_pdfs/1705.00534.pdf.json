{
  "name" : "1705.00534.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "SINGLE IMAGE DEPTH ESTIMATION BY DILATED DEEP RESIDUAL CONVOLUTIONAL NEURAL NETWORK AND SOFT-WEIGHT-SUM INFERENCE",
    "authors" : [ "Bo Li", "Yuchao Dai", "Huahui Chen", "Mingyi He" ],
    "emails" : [ "libo.npu@gmail.com" ],
    "sections" : [ {
      "heading" : "1. INTRODUCTION",
      "text" : "Single image depth estimation aims at predicting pixel-wise depth for a single color image, which has drawn increasing attentions in computer vision, virtual reality and robotic. It is a very challenging problem due to its ill-posedness nature. Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1–5].\nLi et al. [1] predicted the depth and surface normals from a color image by regression on deep CNN features in a patchbased framework. Liu et al. [2] proposed a CRF-CNN combined learning framework. Wang et al. [3] proposed a CNN architecture for joint semantic labeling and depth prediction. Recent works have shown that the depth estimation problem could benefit from a better CNN architecture design. Eigen et al. [4] proposed a multi-scale architecture that first predicts a coarse global output and then refines it using finer-scale local networks. Very recently, Cao et al. [5] demonstrated that formulating depth estimation as a classification task is better than direct regression. These works demonstrate that, network architecture design plays a central role in improving the performance.\nTo this end, a simple yet effective dilated deep residual CNN architecture is proposed, which could converge with much fewer training examples and model parametres. Furthermore, we analyze the statistic property of our network\n∗ libo.npu@gmail.com\noutput, and propose soft-weight-sum inference instead of the traditional hard-threshold method. At last, we conduct evaluations on widly used NYU Depth V2 dataset [6], and outperforms other state-of-the-art methods by a margin."
    }, {
      "heading" : "2. NETWORK ARCHITECTURE",
      "text" : "Our CNN architecture is illustrated in Fig. 1, in which the weights are initialized from a pre-trained 152 layers residual CNN [7]. The original network [7] was specially designed for image classification problem. In this work, we transform it to be suitable to our depth estimation task.\nFirstly, we remove all the fully connect layers. In this way, we greatly reduce the number of model parameters as more than 80% of the parameters are in the fully connect layers [4, 5]. Although, both [4] and [5] preserved the fully connect layers for long range context information, our experiments show that it is unnecessary in our network for the usage of dilated convolution. Secondly, we take advantage of the dilated convolution, which could expand the receptive field of the neuron without increasing the parameters. Thirdly, with dilated convolution, we could keep the spatial resolution of feature maps. Then, we concatenate intermediate feature maps with the final feature map directly. This skip connection design benefits the multi-scale feature fusion and boundary preserving.\n(1) Dilated Convolution: Recently, dilated convolution is successfully utilized in the CNN design by Yu et al. [8]. Specially:\nLetF : Z2 → R be a discrete function. Let Ωr = [r, r]2∩ Z2 and let k : Ωr → R be a discrete filter of size (2r + 1)2. The discrete convolution filter ∗ can be expressed as\n(F ∗ k)(p) = ∑\ns+t=p\nF (s)k(t). (1)\nWe now generalize this operator. Let l be a dilation factor and let ∗l be defined as\n(F ∗l k)(p) = ∑\ns+lt=p\nF (s)k(t). (2)\nar X\niv :1\n70 5.\n00 53\n4v 1\n[ cs\n.C V\n] 2\n7 A\npr 2\n01 7\nWe refer to ∗l as a dilated convolution or an l-dilated convolution. The conventional discrete convolution ∗ is simply the 1-dilated convolution.\n(2) Skip Connection: As the CNN is of hierarchical structure, which means high level neurons have larger receptive field and more abstract features, while the low level neurons have smaller receptive field and more boundary information. We propose to concatenate the high-level feature map and the inter-mediate feature map. The skip connection structure benefits both the multi-scale fusion and boundary preserving."
    }, {
      "heading" : "3. SOFT-WEIGHT-SUM INFERENCE",
      "text" : "We reformulate depth estimation as classification task by equally discretizing the depth value in log space as [5]. Specially, we train our network with the multinomial logistic loss E = − 1N ∑N n=1 log(p n k ) followed by softmax\npi = exp xi∑m\ni ′ =1 exp x i ′ . Here, N is the number of training sam-\nples, k the correspondent label of sample n, m is the number of bins.\nA typical predicted score distribution is given in Fig. 2a, where the non-zero score is centralized. Fig. 2b is the confusion matrix on the test set, which present a kind of diagonal dominant structure. In Table 1, we give the pixel-wise accuracy and Relative error (Rel) with respect to different number of discretization bins.\nThese statistic results show that: Even though the model can’t distinguish the detailed depth well, it still learns the correct concept of depth as the non-zero predicted score is centralized and around the right label. These statistic results also explain why increasing the number of bins could not improve the performance further, mainly due to the decrease of the pixel-wise accuracy.\nInspired by these statistic results, we propose the softweight-sum inference. It is worth noting that, this method transforms the predicted score to the continuous depth value in a nature way. Specially:\ndi = exp {wTpi}, (3)\nwhere w is the weight vector of depth bins. pi is the output score for sample i. In our experiments, we set the number of bins to 200."
    }, {
      "heading" : "4. EXPERIMENTS",
      "text" : "We test our method on the widely used NYU V2 dataset [6]. The raw dataset consists of 464 scenes, captured with a Microsoft Kinect, The official split consists of 249 training and 215 test scenes. We equally sample frames out of each training sequence, resulting in approximately 12k unique images. After off-line augmentations, our dataset comprises approximately 48k RGB-D image pairs.\nImplementation details: Our implementation is based on the CNN toolbox: caffe [9] with an NVIDIA Titian X GPU. The proposed network is trained by using stochastic gradient decent with batch size of 3 (This size is too small, thus we average the gradient of 5 iterations for one back-propagation), momentum of 0.9, and weight decay of 0.0004. Weights are\ninitialized by the pre-trained model from [7]. The network is trained with iterations of 50k by a fixed learning rate 0.001 in the first 30k iterations, then divided by 10 every 10k iterations.\nFor quantitative evaluation, we report errors obtained with the following error metrics, which have been extensively used. Denote d as the ground truth depth, d̂ as the estimated depth, and T denotes the set of all points in the images. • Threshold: % of di s.t. max ( d̂i di , di d̂i ) = δ < thr;\n• Mean relative error (rel): 1|T | ∑\nd∈T |d̂− d|/d; • Mean log10 error (log10):\n1 |T | ∑\nd∈T |log10 d̂− log10 d|; • Root mean squared error (rms):√\n1 |T | ∑ d∈T ‖d̂− d‖ 2 .\nHere d is the ground truth depth, d̂ is the estimated depth, and T denotes the set of all points in the images.\nQuantitative and qualitative evaluation of our method is presented in Table 2 and Fig. 3 respectively. Our method outperforms other state-of-the-art depth estimation methods by a large margin with much fewer training examples and model scale. It is worth noting that, without any post processing, our result is of high visual quality.\nTo further evaluate our method, we conduct experiments to analyze the contribution of each component and the results are illustrated in Table 3. From Table 3 we can see that dilated convolution, skip connection, and soft-weight-sum inference all contribute to final depth estimation. From Fig. 3, we could also observe that the soft-weight-sum inference is beneficial to smooth the depth map while keeping the boundary sharp."
    }, {
      "heading" : "5. CONCLUSION",
      "text" : "An adapted deep convolutional neural network architecture is proposed for single image depth estimation. We also propose\nthe soft-weight-sum inference instead of the hard-threshold method. Experimental results demonstrate that our proposed method achieves better performance than other state-of-theart methods on NYU Depth V2 dataset."
    }, {
      "heading" : "6. REFERENCES",
      "text" : "[1] Bo Li, Chunhua Shen, Yuchao Dai, A. van den Hengel, and Mingyi He, “Depth and surface normal estimation from monocular images using regression on deep features and hierarchical crfs,” in CVPR, jun 2015, pp. 1119– 1127.\n[2] Fayao Liu, Chunhua Shen, Guosheng Lin, and Ian Reid, “Learning depth from single monocular images using deep convolutional neural fields,” TPAMI, vol. 38, no. 10, pp. 2024–2039, 2016.\n[3] Peng Wang, Xiaohui Shen, Zhe Lin, Scott Cohen, Brian Price, and Alan L Yuille, “Towards unified depth and semantic prediction from a single image,” in CVPR, 2015, pp. 2800–2809.\n[4] David Eigen and Rob Fergus, “Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture,” in ICCV, 2015, pp. 2650– 2658.\n[5] Yuanzhouhan Cao, Zifeng Wu, and Chunhua Shen, “Estimating depth from monocular images as classification using deep fully convolutional residual networks,” [Online]. Avaliable: https://arxiv.org/abs/1605.02305, 2016.\n[6] Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus, “Indoor segmentation and support inference from rgbd images,” in ECCV, 2012, pp. 746–760.\n[7] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, “Deep residual learning for image recognition,” in CVPR, 2016, pp. 770–778.\n[8] Fisher Yu and Vladlen Koltun, “Multi-scale context aggregation by dilated convolutions,” in ICLR, 2016, pp. 1–10.\n[9] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell, “Caffe: Convolutional architecture for fast feature embedding,” in Proc. ACM Int. Conf. Multimedia, 2014, pp. 675–678."
    } ],
    "references" : [ {
      "title" : "Depth and surface normal estimation from monocular images using regression on deep features and hierarchical crfs",
      "author" : [ "Bo Li", "Chunhua Shen", "Yuchao Dai", "A. van den Hengel", "Mingyi He" ],
      "venue" : "CVPR, jun 2015, pp. 1119– 1127.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Learning depth from single monocular images using deep convolutional neural fields",
      "author" : [ "Fayao Liu", "Chunhua Shen", "Guosheng Lin", "Ian Reid" ],
      "venue" : "TPAMI, vol. 38, no. 10, pp. 2024–2039, 2016.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2024
    }, {
      "title" : "Towards unified depth and semantic prediction from a single image",
      "author" : [ "Peng Wang", "Xiaohui Shen", "Zhe Lin", "Scott Cohen", "Brian Price", "Alan L Yuille" ],
      "venue" : "CVPR, 2015, pp. 2800–2809.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture",
      "author" : [ "David Eigen", "Rob Fergus" ],
      "venue" : "ICCV, 2015, pp. 2650– 2658.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Estimating depth from monocular images as classification using deep fully convolutional residual networks",
      "author" : [ "Yuanzhouhan Cao", "Zifeng Wu", "Chunhua Shen" ],
      "venue" : "[Online]. Avaliable: https://arxiv.org/abs/1605.02305, 2016.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Indoor segmentation and support inference from rgbd images",
      "author" : [ "Nathan Silberman", "Derek Hoiem", "Pushmeet Kohli", "Rob Fergus" ],
      "venue" : "ECCV, 2012, pp. 746–760.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Deep residual learning for image recognition",
      "author" : [ "Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun" ],
      "venue" : "CVPR, 2016, pp. 770–778.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Multi-scale context aggregation by dilated convolutions",
      "author" : [ "Fisher Yu", "Vladlen Koltun" ],
      "venue" : "ICLR, 2016, pp. 1–10.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Caffe: Convolutional architecture for fast feature embedding",
      "author" : [ "Yangqing Jia", "Evan Shelhamer", "Jeff Donahue", "Sergey Karayev", "Jonathan Long", "Ross Girshick", "Sergio Guadarrama", "Trevor Darrell" ],
      "venue" : "Proc. ACM Int. Conf. Multimedia, 2014, pp. 675–678.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1–5].",
      "startOffset" : 161,
      "endOffset" : 166
    }, {
      "referenceID" : 1,
      "context" : "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1–5].",
      "startOffset" : 161,
      "endOffset" : 166
    }, {
      "referenceID" : 2,
      "context" : "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1–5].",
      "startOffset" : 161,
      "endOffset" : 166
    }, {
      "referenceID" : 3,
      "context" : "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1–5].",
      "startOffset" : 161,
      "endOffset" : 166
    }, {
      "referenceID" : 4,
      "context" : "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1–5].",
      "startOffset" : 161,
      "endOffset" : 166
    }, {
      "referenceID" : 0,
      "context" : "[1] predicted the depth and surface normals from a color image by regression on deep CNN features in a patchbased framework.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "[2] proposed a CRF-CNN combined learning framework.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] proposed a CNN architecture for joint semantic labeling and depth prediction.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] proposed a multi-scale architecture that first predicts a coarse global output and then refines it using finer-scale local networks.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[5] demonstrated that formulating depth estimation as a classification task is better than direct regression.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "At last, we conduct evaluations on widly used NYU Depth V2 dataset [6], and outperforms other state-of-the-art methods by a margin.",
      "startOffset" : 67,
      "endOffset" : 70
    }, {
      "referenceID" : 6,
      "context" : "1, in which the weights are initialized from a pre-trained 152 layers residual CNN [7].",
      "startOffset" : 83,
      "endOffset" : 86
    }, {
      "referenceID" : 6,
      "context" : "The original network [7] was specially designed for image classification problem.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 3,
      "context" : "In this way, we greatly reduce the number of model parameters as more than 80% of the parameters are in the fully connect layers [4, 5].",
      "startOffset" : 129,
      "endOffset" : 135
    }, {
      "referenceID" : 4,
      "context" : "In this way, we greatly reduce the number of model parameters as more than 80% of the parameters are in the fully connect layers [4, 5].",
      "startOffset" : 129,
      "endOffset" : 135
    }, {
      "referenceID" : 3,
      "context" : "Although, both [4] and [5] preserved the fully connect layers for long range context information, our experiments show that it is unnecessary in our network for the usage of dilated convolution.",
      "startOffset" : 15,
      "endOffset" : 18
    }, {
      "referenceID" : 4,
      "context" : "Although, both [4] and [5] preserved the fully connect layers for long range context information, our experiments show that it is unnecessary in our network for the usage of dilated convolution.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 7,
      "context" : "[8].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "The detail of the basic residual block could be refer to [7].",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 4,
      "context" : "We reformulate depth estimation as classification task by equally discretizing the depth value in log space as [5].",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 5,
      "context" : "We test our method on the widely used NYU V2 dataset [6].",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 8,
      "context" : "Implementation details: Our implementation is based on the CNN toolbox: caffe [9] with an NVIDIA Titian X GPU.",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 6,
      "context" : "initialized by the pre-trained model from [7].",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 0,
      "context" : "[1] 795 60M 62.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "[2] 795 130M 65.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] 795 - 60.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] 240k 200M 76.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[5] 240k 350M 80.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 0,
      "context" : "[1]",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] Ours hard Ours soft",
      "startOffset" : 0,
      "endOffset" : 3
    } ],
    "year" : 2017,
    "abstractText" : "This paper proposes a new residual convolutional neural network (CNN) architecture for single image depth estimation. Compared with existing deep CNN based methods, our method achieves much better results with fewer training examples and model parameters. The advantages of our method come from the usage of dilated convolution, skip connection architecture and soft-weight-sum inference. Experimental evaluation on the NYU Depth V2 dataset shows that our method outperforms other state-of-the-art methods by a margin.",
    "creator" : "LaTeX with hyperref package"
  }
}