{
  "name" : "1409.5340.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "paolo@liberatore.org" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n40 9.\n53 40\nv1 [\ncs .A\nI] 1\nKeywords: belief revision; belief merging; nonmonotonic reasoning; knowledge representation."
    }, {
      "heading" : "1 Introduction",
      "text" : "When integrating information coming from different sources, a distinction is made between revision [13, 5, 14, 28, 6] (new information more reliable than old) and merging [22, 4, 18] (same reliability). More generally, priorities or weights are assigned to the sources to indicate their reliability [26, 27, 30, 7]. Measures and aggregation functions allow for fine-grained policies of integration [16, 11, 18]. Families of operators are then defined, all depending in a way or another from the relative reliability of the sources. The two basic cases of non-iterated revision and merging result from giving priority to the new information or the same to all pieces of information to be incorporated, respectively. The strenght of information sources has been studied in the field of cognitive psychology, where it was determined to depend on the order in which the information is given [32], on the size of the group generating it [25] and other social factors [31].\nThe first time merging is done, the relative reliability of the pieces of information to be integrated cannot come other than from sources external to the merging process. However, subsequent mergings may then take advantage from the previous results.\nExample 1 The two long-range sensors of an unmanned vehicle detect an object. One of the two identifies it as a wall, the other one as a fence. As the vehicle approaches, the object enters the range of the vision system, which definitely concludes it to be a fence. The vehicle turns, and after some distance is traveled the two longrange sensors disagree again. How the previous conflict was resolved suggests that the second sensor is more precise than the first.\nA similar scenario is that of database fixing after integration: some databases are merged with equal reliability (in lack of information indicating one to be more reliable than the other), inconsistencies in the result detected and corrected by the operators or programmers. If the fixed database is the same of what would result from merging the original ones with some assumption about the relative reliability of the sources, that assumption can be considered correct, and one that should have been used in the first place. This way, integration and correction provide an ordering of the sources to be used when integrating other data coming from them.\nThe problem considered in this article is to estimate the reliability of formulae K1, . . . , Km so that their integration produces a given other formula R. Contrary to most work in belief revision, no new semantics for merging are introduced, and this is because the point is not on how to obtain R from K1, . . . , Km, but how to reckon the reliability of K1, . . . , Km from these formulae and R. This formula R is given, not the outcome of the process: it is the data from the vision system in the first example and the corrected database in the second. As an example:\n• two sources provide a and ¬a ∧ b; lacking information about their reliability, the result is the disjunction a ∨ (¬a ∧ b) = true;\n• the actual state of the world is detected to be ¬a ∧ b;\n• this formula ¬a ∧ b is the result of merging a and ¬a ∧ b when the source of the second is assumed more reliable;\n• other two formulae a ∧ c and b ∧ ¬c arrive from the same sources; given that the second is more reliable, merging produces b ∧ ¬c.\nThe procedure looks straightforward because it involves only two very simple formulae under a trivial semantics of merging by taking either one of them or their disjunction, depending on their relative reliability. If none of these possible outcomes coincide with the given formula then one may (more detailes are in Section 10):\n1. assume that R is not equal to the expected result of merging but a “more precise” formula, or that it represents incomplete information;\n2. take into account that some sources produce reliable information on some aspects of the domain and unreliable in others, so they may be split for example on the variables;\n3. check whether the result can be obtained using a different method of integration.\nThe present articles analyze the problem for two existing merging semantics: minimal sum of distances [18, 15, 17] and prioritized base merging [26, 27, 30], also called discrimin merging [7]. However, any other of the several existing merging semantics can be used [18, 7].\nFor merging based on sums of distances [18, 15, 17], a necessary and sufficient condition for R to be the result of merging K1 and K2 with some weights is given. This result allows to easily derive upper bounds on the complexity of obtainability, which is in Πpi+1 whenever checking distance is in Π p i or in Σ p i . This implies that the problem is in coNP for the drastic distance and in Πp2 for the Hamming distance. Hardness for these classes is proved. A tractable case for the Hamming distance is determined. Using the same necessary and sufficient condition, a local search algorithm for determining the weights is shown\nThe properties proved for prioritized base merging [26, 27, 30] are: some formulae R cannot be obtained from K1, . . . , Km even if R is the disjunction of some of the maximally consistent subsets of them; such a condition is only possible with m > 4; some other formulae R can be obtained only using n priorities levels, with an arbitrary n (that requires n+ 4 formulae); if the maximally consistent subsets form a Berge-acyclic graph, every disjunction of some of them is obtainable; an algorithm for producing the priority ordering in this case is given.\nIf all maximally consistent subsets have size two or less the problem becomes a problem on graphs, where weights are to be assigned to nodes in such a way some edges are selected and some other are excluded. In this case, a simple necessary and sufficient condition for obtainability exists: non-obtainability is the same as the presence of alternating cycles of edges.\nSurprisingly, complexity turns out not to be higher than that of computing the result of merging [9, 10, 19, 20, 27, 23] at least in some cases. For example, given a consistent R and K1, . . . , Km with constant m or with maximally consistent subsets of size two or less, checking whether R is obtainable is only coNP-complete, thus solvable within a reasonable size of formulae by modern SAT-solvers.\nThe article is organized as follows: a section introduces the basic settings, the following the definitions and results using the sums of distances and prioritized base merging, respectively, including an algorithm each. Then, the question on what to do if a given formula is not obtainable is considered. A final section draws some conclusions."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "The knowledge bases to be merged are denoted by K1, . . . , Km throughout this article. They are assumed to be consistent propositional formulae. The same for the expected result R, unless explicitly indicated otherwise.\nTwo merging semantics are considered in this article, the first based on the weighted sum of distances, the second on a priority ordering. Formula R is obtainable from K1, . . . , Km if it is the result of merging these formula with some weights or priorities. Using the first semantics, this amounts to checking the existence of weights such that R is the result of merging K1, . . . , Km with these weights. For the second semantics, the definition is the same with a priority ordering instead of the weights.\nObtainability means thatR is the result of mergingK1, . . . , Km with some relative reliability among these knowledge bases. Determining this reliability ordering is the aim of two algorithms, one for each of the considered merging semantics. What to do if R is not obtainable is considered in Section 10."
    }, {
      "heading" : "3 Weighted sum",
      "text" : "Model-based merging operators [18, 15, 17] work from a measure of the distance between models, selecting only the ones that are at minimal total distance from the knowledge bases. Different semantics result from different distances measures and different methods for combining them. Two measures of interest are [15, 29, 24]:\nDrastic distance: d(I, I) = 0, d(I, J) = 1 if J 6= I;\nHamming distance: d(I, J) is the number of variables evaluated differently by I and J .\nDistance measures extend to knowledge bases: d(I,K) is the minimal value of d(I, J) for J |= K. The drastic distance from a model to a knowledge base is therefore 0 if the model satisfies the base and 1 otherwise. The Hamming distance is the minimal number of variables that are assigned different values by the model and by a model of the knowledge base.\nDistances can be further extended from one to more knowledge bases in various ways. One is to define d(I,K1, . . . , Km) to be the sum of the distances d(I,Ki); other methods exists [18]. If the sources of the knowledge base differ in reliability, a weighted sum can be used in place of the sum [15, 17]. Let {w1, . . . , wm} be the weights, which are assumed positive integers (null, negative or real values can also be of interest, but are not considered in this article). The weighted distance from I to {K1, . . . , Km} is:\nd(I,K1, . . . , Km) = ∑\n1≤i≤m\nwi × d(I,Ki)\nAlternatively, the distance vector of I is the array (d(I,K1), . . . , d(I,Km)) and the weighted distance is obtained by multiplying it with the weight vector (w1, . . . , wm). Either way, merging selects the models of minimal weighted distance from the knowledge bases [29, 24, 15, 17].\nThe problem of obtainability is that of finding positive integers w1, . . . , wm such that the result of merging K1, . . . , Km is a given formula R. As usual, the complexity analysis is done on the decision version of this problem, that of checking the existence of such weights. The algorithm in Section 3.2 searches for actual values. Some considerations on what to do if they do not exist are in Section 10.\nThe following restriction is considered in this section: two knowledge bases only. In other words, m = 2, and the knowledge bases are K1 and K2. This restriction simplifies the definition to:\nd(I,K1, K2) = w1 × d(I,K1) + w2 × d(I,K2)\nFor every model I, its distance vector from {K1, K2} is (d(I,K1), d(I,K2)). Obtainability amounts to checking the existence of weights that produce the given result R. However, weights (1, 2) produce the same results of (2, 4), since the weighted distance of the first pair is double that of the second for every model; therefore, minimal models are the same. As a result, instead of a pair of weights w1 and w2 suffices to search for the value of their ratio\nw1 w2 . This is a simpler problem\nbecause such a value can be obtained by simple algebraic manipulation from two models of R in most cases. Otherwise, some constraints on its value derives from models of ¬R.\nThe following expression is useful for relating models, as it often coincides with w1 w2\nif I and J both satisfy R and gives a bound to this fraction if I does and J does not.\np(I, J ;K1, K2) = d(J,K2)− d(I,K2)\nd(I,K1)− d(J,K1)\nSince K1 and K2 are fixed in this section, p(I, J ;K1, K2) can be shortened to p(I, J). The knowledge bases K1 and K2 are clear from the context.\nProperty 1 Two models I and J have the same distance from {K1, K2} weighted by w1 and w2 if and only if either d(I,K1) = d(J,K1) and d(I,K2) = d(J,K2) or d(I,K1) 6= d(J,K1) and\nw1 w2 = p(I, J ;K1, K2).\nProof. The distance from I and J to K1 and K2 weighted by w1 and w2 is:\nd(I,K1, K2) = w1 × d(I,K1) + w2 × d(I,K1)\nd(J,K1, K2) = w1 × d(J,K1) + w2 × d(J,K1)\nIf these amounts coincide, then:\nw1 × d(I,K1) + w2 × d(I,K1) = w1 × d(J,K1) + w2 × d(J,K1)\nw1 × (d(I,K1)− d(J,K1)) = w2 × (d(J,K2)− d(I,K2))\nThis equation is true if d(I,K1) = d(J,K1) and d(I,K2) = d(J,K2). Otherwise, both sides can be divided by d(I,K1) = d(J,K1) and by w2, which by assumption is larger than zero, obtaining:\nw1 w2 = d(J,K2)− d(I,K2) d(I,K1)− d(J,K1)\nThe right-hand side of this equation is p(I, J ;K1, K2).\nThis property expresses a condition for I and J to have the same weighted distance from the knowledge bases. If R is the result of merging with weights w1 and w2, it holds for every two models I and J of it. In particular, I, J and L satisfy the result of merging only if p(I, J) and p(I, L) both coincide with w1\nw2 , which implies\np(I, J) = p(I, L). In other words, p(I, J) gives the value of w1 w2 , any other p(I, L) has to agree on it.\nProperty 2 Model I is closer than model M to {K1, K2} with weights w1 and w2 if and only if:\n• d(I,K1) = d(M,K1) and d(I,K2) < d(M,K2); or\n• d(I,K1)− d(M,K1) > 0 and w1 w2 < p(I,M ;K1, K2); or\n• d(I,K1)− d(M,K1) < 0 and w1 w2 > p(I,M ;K1, K2).\nProof. The distance is w1×d(I,K1)+w2×d(I,K1) for I and w1×d(M,K1)+w2× d(M,K1) for M . Therefore, I is closer than M to {K1, K2} if:\nw1 × d(I,K1) + w2 × d(I,K1) < w1 × d(M,K1) + w2 × d(M,K1)\nw1 × (d(I,K1)− d(M,K1)) < w2 × (d(M,K2)− d(I,K2))\nBy assumption, w2 is strictly positive. Therefore, both sides of this inequation can be divided by it. Instead, d(I,K1)−d(M,K1) may be positive, negative or zero. In latter case, d(I,K1) = d(M,K1), which implies that I is closer than M to the bases if and only if d(I,K2) < d(M,K2), regardless of the weights.\nIf d(I,K1)− d(M,K1) is positive, both sides of the inequation can be divided by it:\nw1 w2 < d(M,K2)− d(I,K2) d(I,K1)− d(M,K1) if d(I,K1)− d(M,K1) > 0\nThe inequation is w1 w2 < p(I,M ;K1, K2). In the other case, dividing both sides by\nthe negative number d(I,K1)− d(M,K1) changes < into >:\nw1 w2 > d(M,K2)− d(I,K2) d(I,K1)− d(M,K1) if d(I,K1)− d(M,K1) < 0\nThe inequation is w1 w2 > p(I,M ;K1, K2). These properties show that most pairs of models constraint the value of w1 w2 . In particular, two models of R are enough to uniquely fix it, unless they are at the same distance from K1. Models that do not satisfy R only generate inequations. If there are at least two models of R at different distances from K1 this is not a problem, as these determine w1\nw2 and what is left to do is check the inequations.\nOtherwise, more complex constraints among models not satisfying R may result. As an example, if all models of R are at distance (4, 4) and two models not of R at distance (1, 8) and (8, 1), then R is obtainable with w1 = w2 = 1. Instead, two other models not in R at distance (1, 5) and (5, 1) make R unobtainable.\nIf I, J, L |= R, then both p(I, J) and p(I, L) coincide with w1 w2 , and therefore coincide with each other: p(I, J) = p(I, L). For the same reason, if I, J |= R and L 6|= R, then p(I, J) < p(I, L) or p(I, J) > p(I, L), depending on the sign of d(I,K1)− d(L,K1).\nThese constraints are enough is R has at least two models with differing distance from K1. Otherwise, R does not set a value for\nw1 w2 , which can therefore be\nvaried to exclude models not satisfying R. In particular, two inequations of opposite comparison can be combined: if I |= R, M,N 6|= R, d(I,K1) − d(N,K1) > 0 and d(I,K1) − d(M,K1) < 0, then\nw1 w2 < p(I, N) and w1 w2 > p(I,M), leading to\np(I,M) < p(I, N).\nLemma 1 A satisfiable formula R is obtainable from {K1, K2} if and only if for all I, J, L |= R and M,N 6|= R, the following conditions hold:\n1. if d(I,K1) ≥ d(J,K1) then d(I,K2) ≤ d(J,K2)\n2. if d(I,K1) ≥ d(M,K1) then d(I,K2) < d(M,K2)\n3. p(I, J) = p(I, L) if d(I,K1)− d(J,K1) 6= 0 and d(I,K1)− d(L,K1) 6= 0\n4. p(I, J) < p(I,M) if d(I,K1)− d(J,K1) 6= 0 and d(I,K1)− d(M,K1) > 0\n5. p(I, J) > p(I,M) if d(I,K1)− d(J,K1) 6= 0 and d(I,K1)− d(M,K1) < 0\n6. p(I, N) < p(I,M) if d(I,K1)− d(M,K1) > 0 and d(I,K1)− d(N,K1) < 0\nProof. Assuming the conditions true, we derive values of w1 and w2 that make the result of merging being exactly R. Two cases are possible: in the first, all models of\nR have the same distance to K1 and the same distance to K2; in the second, at least two models of R have different distances.\nIf all models of R are at the same distance from K1 and from K2, then every pair of weights makes them having the same weighted distance. Therefore, the problem is only with models not in R, which must be at a greater distance. Let I, M and N be:\n• I is a model of R;\n• M is one of the models not satisfying R with a minimal value of p(I,M) among the ones with d(I,K1)− d(M,K1) > 0, if any;\n• N is one of the models not satisfying R with a maximal value of p(I, N) among the ones with d(I,K1)− d(N,K1) < 0, if any.\nBy the sixth condition of the lemma, in these conditions p(I, N) < p(I,M). If w1 w2\nis between p(I, N) and p(I,M), then w1 w2 is smaller than p(I,M ′) for every M ′ 6|= R with d(I,K1)− d(M ′, K1) > 0, thanks to the minimality of M . By Property 2, this implies that M ′ is further from the bases than I. The same applies to models N ′ with d(I,K1) − d(N ′, K1) < 0, thanks to the maximality of N . For the models L such that d(I,K1) − d(L,K1) = 0, the second condition of the lemma implies that d(I,K2) < d(L,K2), proving that they are further from the bases than I regardless of the weights.\nIf no such M or no such N exist, the corresponding constraint is void. This can be formalized by replacing p(I, N) with 0 and p(I,M) with n.\nA value between p(I,M) and p(I, N) is their average. However, this may be negative, and negative weights are not allowed. In this case, a different method can be employed.\nIf d(I, N) is negative, w1 w2 is determined as follows. Since d(I,K1) > d(M,K1), by the second condition of the lemma d(I,K2) < d(M,K2), which ensures that p(I,M) is strictly positive. By definition of this expression, its minimal positive value is 1\nn ,\nobtained by taking the minimal value of the numerator (1 or −1) and the maximal value of the denominator (n or −n). Since d(I, N) is negative, a value between it and 1\nn is 1 n+1 .\nIf d(I, N) is positive, this value may not work, but the average between it and d(I,M) is positive, and can therefore be used. Let p(I,M) = a\nb and p(I, N) = c d .\np(I, N) + p(I,M)\n2\n= a b + c d\n2\n= a\n2b +\nc\n2d\n= ad\n2bd +\ncb\n2bd\n= ad+ cb\n2bd\nSince this is the average between two positive values, it is positive. The numerator and the denominator may both be negative, but their absolute values produce the same fraction. Since this is w1\nw2 , the weights can be taken to be:\nw1 = |(d(N,K2)− d(I,K2))× (d(I,K1)− d(M,K1)) +\n(d(M,K2)− d(I,K2))× (d(I,K1)− d(N,K1))|\nw2 = |2× (d(I,K1)− d(M,K1))× (d(I,K1)− d(N,K1))|\nUsing such weights, every model not satisfying R is further from the bases than all models satisfying R, which proves that if all models of R have the same distances fromK1 and K2, then R is obtainable if the conditions in the statement of the lemma are true.\nIf there exists I and J such that d(I,K1) 6= d(I,K1), then w1 w2 is uniquely deter-\nmined by Property 1 to be p(I, J):\nw1 w2 = d(J,K2)− d(I,K2) d(I,K1)− d(J,K1)\nTwo values producing this fraction are:\nw1 = |d(J,K2)− d(I,K2)|\nw2 = |d(I,K1)− d(J,K1)|\nBy the first assumption of the lemma, if d(I,K1) − d(J,K1) is negative then\nd(I,K2)−d(J,K2) is positive, and vice versa. As a result, w1 w2 is d(J,K2)−d(I,K2) d(I,K1)−d(J,K1) despite the absolute values. Let L be another model of R. If d(I,K1) = d(L,K1), by the first condition of the lemma d(I,K2) = d(L,K2), which implies that I and L are at the same weighted distance from the bases regardless of the weights. Otherwise, d(I,K1) 6= d(I,K2), and Property 1 applies: if w1\nw2 = p(I, L) then I and L are at the same distance\nfrom the bases. But w1 w2 has been proved to be equal to p(I, J), and by the second assumption of the lemma p(I, J) = p(I, L). Let M 6|= R. By the assumptions of the lemma, p(I, J) < p(I,M) if d(I,K1) − d(M,K1) > 0 and p(I, J) > p(I,M) if d(I,K1)− d(M,K1) < 0. By Property 2, the distance from M to {K1, K2} is greater than that of I. That concludes the proof that if the conditions of the lemma are true then R is obtainable.\nIf some of the conditions of the lemma are falsified, then R is not obtainable from {K1, K2} with any weights. This is proved for each condition at time.\nThe first condition is false if d(I,K1) ≥ d(J,K1) but d(I,K2) > d(J,K2). In such conditions the weighted distance of I is less than that of J regardless of the weights, implying that J is not in the result of the merging in spite of J |= R.\nThe second condition is false if d(I,K1) ≥ d(M,K1) and d(I,K2) ≥ d(M,K2), which imply that the weighted distance of I is greater than or equal to that of M regardless of the weights, implying that either M is in the result of merging or I is not, while I |= R and M 6|= R.\nThe third condition is false if p(I, J) 6= p(I, L) for some I, J, L |= R with d(I,K1) 6= d(J,K1) and d(I,K1) 6= d(L,K1). By Property 1, I and J are at the same distance only if w1\nw2 is p(I, J); I and L are at the same distance only if it is\np(I, L). These are different, showing that no pair of weights makes I, J and L to be at the same weighted distance from the bases.\nThe fourth condition is false if d(I,K1) 6= d(J,K1), d(I,K1) > d(M,K1) and p(I, J) ≥ p(I,M). The first implies w1\nw2 = p(I, J) by Property 1 and I, J |= R,\nthe second that w1 w2 < p(I,M) by Property 2 and I |= R and M 6|= R. Therefore, p(I, J) < p(I,M), contradicting p(I, J) ≥ p(I,M).\nThe fifth condition is similar, with d(I,K1) < d(M,K1) implying w1 w2 > p(I,M),\nwhich together with w1 w2 = p(I, J) contradicts p(I, J) ≤ p(I,M). The sixth condition is false if d(I,K1) − d(N,K1) > 0, d(I,K1)− d(M,K1) < 0 and p(I,M) ≥ p(I, N). Since I |= R and M,N 6|= R, Property 2 applies: p(I,M) < w1 w2 < p(I, N), contradicting p(I,M) ≥ p(I, N).\nLemma 1 expresses obtainability in terms of a universally quantified condition containing d(I,Ki). If determining such a value is polynomial, the problem is in coNP. Two cases where this happens are:\n• d is the drastic distance;\n• d is the Hamming distance and both K1 and K2 are conjunctions of literals.\nIf d(I,Ki) is not polynomial to be determined, complexity increases. For the Hamming distance d(I,Ki) is the minimal number of literals that differ from I and a model of Ki. Obtainability amounts to:\n∀I, J, . . . ∀d1I , d 2 I , d 1 J , . . .\n(\n(∃I ′ |= K1 . d(I, I ′) ≤ d1I)∧ (∀I ′′ |= K1 . d(I, I ′′) ≥ d1I)\n)\n∧· · · → (conditions in Lemma 1)\nSince the quantifiers ∃I ′ and ∀I ′′ are inside the premise of an implication, they are negated. However, they are still two independent quantifiers. Therefore, this is a ∀∃QBF , which proves that obtainability is in Πp2. The same happens if checking d(I,Ki) ≤ x is in NP or in coNP. More generally, the complexity of obtainability is one level over the complexity of calculating the distance between a model and a knowledge base.\nTheorem 1 If determining d(I,K) ≤ x is in the complexity class Πpi or Σ p i , then obtainability of a satisfiable formula from two formulae with a weighted sum of distances is in Πpi+1.\nProof. By Lemma 1, obtainability can be expressed as formula with some universal quantifiers in the front ∀I, J, L,M,N and a formula F containing d(I,K1), d(I,K2), d(J,K1), etc. Equivalently:\n∀I, J, L,M,N ∀d1I , d 2 I , d 1 J , d 2 J , . . .\n(d(I,K1) ≤ d 1 I) ∧ ¬(d(I,K1) ≤ d 1 I − 1) ∧ (d(J,K1) ≤ d 1 J) ∧ ¬(d(J,K1) ≤ d 1 J − 1) ∧ ... → F [d(I,K1)/d 1 I , d(I,K2)/d 2 I , d(J,K1)/d 1 J , d(J,K2)/d 2 J , . . .]\nIf d can be calculated in polynomial time, the whole problem is in coNP. Otherwise, subformulae d(I,K1) ≤ d 1 I occur in the premise of an implication, so they are in fact negated. However, if each is in Πpi or in Σ p i , they can be expressed as an alternation of i quantifiers. The whole problem, with the universal quantifier in the front, is therefore in Πpi+1.\nThis theorem implies the three ad-hoc complexity results obtained above: that obtainability is in coNP for the drastic distance and for the Hamming distance when the knowledge bases are conjunctions of literals, and is in Πp2 in the general case for the Hamming distance. A general hardness result can be given from some assumptions about the distance function.\nA pseudodistance is a function such that d(I, J) = d(J, I), d(I, I) = 0 and d(I, J) > 0 for every J 6= I. Its extension to a distance from a knowledge base obeys: d(I,K) = 0 if I |= K and d(I,K) > 0 otherwise. If K1 and K2 have some common models, these have weighted distance 0 regardless of the weights. Since merging selects minimal models, in this case the result comprises exactly the common models. In particular, if K1 and K2 coincide, merge produces a formula equivalent to them. This holds for every pseudodistance, and can be used to prove that obtainability is coNP-hard for every pseudodistance.\nTheorem 2 Obtainability of a consistent formula from two knowledge bases is coNPhard for every pseudodistance.\nProof. The claim is proved by reduction from propositional unsatisfiability. Let F be a propositional formula. The corresponding obtainability problem is defined by K1 = K2 = y and R = y ∨ F , where y is a variable not in F . Since K1 and K2 coincide, the result of merging is y. If F is satisfied by a model I then R has a model I ∪ {¬y} that does not satisfy y. Vice versa, if F is unsatisfiable then R coincides with y.\nSince obtainability for drastic distance and Hamming distance from conjunctions of literals is in coNP, and these are pseudodistances, obtainability using them is coNP complete."
    }, {
      "heading" : "3.1 Weighted sum of Hamming distance",
      "text" : "The problem of obtainability with the Hamming distance is Πp2-hard. This is proved by reduction from the problem of establishing the validity of a formula ∀X∃Y.F . The translation is based on two main ideas:\n1. separate models having different evaluations of X by a large distance;\n2. for each evaluation of X , K1 and R contain the subformula Y ¬ ∧ Y ′¬ that sets\nall variables in Y and a copy of it Y ′ to false; K2 instead contains F ∧(Y 6≡ Y ′).\n✪\n✩\n✪\n✩\n✪\n✩\n✪\n✩\n✪\n✩\n✪\n✩\n♥ ♥\n♥\n❅❅\n❅❅\n❅❅\nY ¬Y ′¬\nF ∧ (Y 6≡ Y ′)\nX ′\nX ′′′\nX ′′\nThe second property makes the model of K1 being at distance n from K2, but only if R is satisfiable, and such models are in the result of merging with w1 >> w2. Formal proof follows.\nTheorem 3 Obtainability with the weighted sum of Hamming distance from two knowledge bases is Πp2-complete.\nProof. Membership follows from Theorem 1, since checking d(I,K) ≤ x is in NP for the Hamming distance. Indeed, d(I,K) ≤ x holds if there exists J |= K such that d(I, J) ≤ x, and the distance between two models can be determined in polynomial time.\nHardness is proved by reduction from the problem ∀∃QBF . First, the problem of checking the validity of ∀X∃Y.F remains hard even if F is known to be satisfiable. This is proved by reduction from the problem without the restriction: ∀X∃Y.G is valid if and only if ∀z∀X∃Y.G ∨ z is valid, where z is a new\nvariable: indeed, this formula is equivalent to (∀X∃Y.G ∨ ⊤) ∧ (∀X∃Y.G ∨ ⊥); the first part of this conjunction is tautological, the second is equivalent to the original QBF.\nSecond, the problem of checking the validity of ∀X∃Y.F with F satisfiable is reduced to obtainability. Let n = |X| = |Y | and Y ′, X1, . . . , X2n be each a set of n new variables.\nK1 = (X ≡ X1 ≡ · · · ≡ X2n) ∧ Y ¬ ∧ Y ′¬ K2 = (X ≡ X1 ≡ · · · ≡ X2n) ∧ (Y 6≡ Y ′) ∧ F\nR = K1\nThat the reduction works is proved in four steps:\n1. there are models with distance vector (0, n) or less;\n2. the distance between models of K1 or K2 differing in the evaluation of X is 2n or more;\n3. no model hsa distance vector (0, k) with k < n;\n4. a model of K1 is in the result of merging if and only if its evaluation of X satisfies F with some values of Y .\nFormula F is by assumption satisfiable. Let I be a model of it, and IX and IY\nits parts on X and Y , respectively. Replicating the values of IX on X1, . . . , X2n and adding Y ¬ and Y ′¬ results in a model of K1. The same values of X,X1, . . . , X2n with IY and its negations in Y ′ form a model of K2. If I\nY has k positive literals then its negated interpretation on Y ′ has n − k. That makes n positive literals, while the model of K1 has Y\n¬ and Y ′¬. Since these models coincide on X,X1, . . . , X2n, the distance from the model of K1 to K2 is at most n. Since the first is a model of K1, its distance vector is (0, n).\nSince both K1 and K2 contain X ≡ X1 ≡ · · · ≡ X2n, if two of their models differ even on a single variable in X they also differ on all its 2n copies. Therefore, models of K1 and K2 with different evaluations of X are at least 2n apart.\nTo prove that no model is at distance less that (0, n) suffices to consider the models of K1, since these are the only ones with 0 in the first position of the distance vector. Let I be a model of K1. By the previous property, models of K2 with a different evaluation of X are at distance 2n or more. The models with the same evaluation of X differ only on the values of Y . However, since K2 contains Y 6≡ Y ′, all models of K2 have exactly n positive literals in Y ∪ Y ′. Since K1 contains Y ¬ and Y ′¬, its models have all negative Y ∪Y ′. As a result, the distance between these models is n, leading to a distance vector (0, n).\nSince there are models with distance vector (0, n), and none at distance (0, k) with k < n, a model of K1 can be in the merge result only if it is at distance n from a model of K2. Every evaluation of X satisfies K1 with the same values copied to\nX1, . . . , X2n and Y ∪ Y ′ all set to false, and vice versa. Such model I is at distance 2n or more from models of K2 with a different evaluation of X , which are therefore irrelevant to the presence of I in the result of merging: only the models of K2 with the same evaluation over X matter. Such a model exists if and only if F is satisfiable for that evaluation of X . Moreover, Y 6≡ Y ′ forces every such model at distance n from I, making the model in the result of merging with weights (n+ 1, 1).\nThis was the fourth step of the proof. Since a model of K1 corresponds to an evaluation over X (and vice versa), and such a model can be in the result of merging if and only if F is consistent with that evaluation of X , the whole R is the result of merging if and only if ∀X∃Y.F is valid."
    }, {
      "heading" : "3.2 Local search algorithm",
      "text" : "An algorithm using local search is shown. It employs two elements of the proof of Lemma 1 to obtain w1\nw2 or some bounds on its value. No assumption is made over\nd(I,K) other than the availability of a procedure to determine it; in the case of drastic distance this is straightforward, as it amounts to check whether I |= K; for the Hamming distance, since the problem is NP-complete, an approximate method can be used instead. Once w1\nw2 is determined, the knowledge bases are merged and\nthe result checked for equivalence to R. This final check is necessary because the procedure to find models that constraint w1\nw2 is incomplete: not all models of R and\nof ¬R are checked. Property 1 ensures that if two models of R are such that the denominator of p(I, J) is not null, then w1 w2\n= p(I, J). Two such models can be looked upon using local search. During the run of the procedure, models that do not satisfy R are used to establish or refine bounds on the value of w1\nw2 . This is useful because, as\nProperty 2 shows, even if for all pairs of models of R the denominator of p(I, J) is zero, the models that do not satisfy R still constrain w1\nw2 .\nSumming up, local search search does two things at the same time:\n1. looks for two models I and J of R such that p(I, J) has a non-zero denominator;\n2. if a model I of R has been found, for every model M of ¬R found during the search p(I,M) is calculated and used to refine two bounds.\nIn the following algorithm, conditions involving I are to be considered false if I is unassigned, for example when the algorithm starts. The result is w1\nw2 or the\nspecial value “unobtainable”; the first is assumed to be returned as a pair of integers, rather than a (possibly truncated) rational value. The maximal distance between two models is denoted by n; this is 1 for the drastic distance and the number of variables for the Hamming distance. This is also the maximal value of p(I, J) and the reason why a is initialized to n+ 1.\n1. a = n+ 1; b = −n− 1\n2. iter = 0\n3. if iter%restart = 0 set O=random model\n4. change O by local search for a model of R (see below)\n5. if O |= R and I is unassigned set I = O\n6. if O |= R and p(I, O) has a non-zero denominator, then:\n• if p(I, O) is positive and between a and b then return p(I, O)\n• otherwise return unobtainable\n7. if O 6|= R and d(I,K1)− d(O,K1) > 0 then a = min(a, p(I, O))\n8. if O 6|= R and d(I,K1)− d(O,K1) < 0 then b = max(b, p(I, O))\n9. if a < 0 or a ≤ b return unobtainable\n10. iter ++\n11. if iter < maxiter go to Step 3\n12. return a+b 2\nPoint 4 is a step of a local search for a model of R: for example, it may change the value of the variables increasing the most the number of clauses of R, when this formula is in CNF. More refined methods can be employed, such as making random moves with a certain probability, which may remain constant or decrease with the number of iterations.\nThis algorithm returns w1 w2 as a pair of integer numbers, which can be used as the weights w1 and w2. If merging with these weights produces R, then they are searched weights. Otherwise, if the value is returned from Step 6 then R is not obtainable. If it is returned from Step 12, then one may attempt some other value between a and b, or run the algorithm some more.\nSeveral variants may be considered.\n1. Step 4 looks for a model of R, but after a number of iterations without finding one that makes the denominator of p(I, O) different than zero, it makes sense to aim at minimizing a and maximizing b instead;\n2. models with a distance vector strictly greater than another cannot be in the result of merge; therefore, if they satisfy R then R is not obtainable; if they are not in R they can be neglected;\n3. instead of returning immediately after determining p(I, J) in Step 6, one may proceed with local search and check whether some other models of R and of ¬R satisfy the conditions of Lemma 1.\nThe algorithm is based on local search which, while not guaranteed to work in every possible case, is known to perform well in practice [1]. If weights w1 and w2 are found and merging with them produces R, then they are the correct weights. Furthermore, with Step 4 changing a single variable at time, the next models is likely to have different distance vector from the knowledge bases, which would make the algorithm terminate."
    }, {
      "heading" : "3.3 Tractable case",
      "text" : "This section shows a tractable case of obtainability: the measure is the Hamming distance, the knowledge bases are conjunctions of literals and the expected result of merging is an Horn or Krom formula.\nTheorem 4 If K1 and K2 are conjunctions of literals, determining whether a Horn or Krom formula R is obtainable by the weighted sum of the Hamming distances is in P.\nProof. For a model I and a variable x, let I · x denote a model that is identical to I except that x is assigned the value true. I · ¬x is the same with value false. The first step of the proof is a property of d(I,K) when K entails a literal or does not mention a variable.\nif K entails x then d(J · x,K) < d(J · ¬x,K); since K1 entails x, all its models set x to true; this hold in particular for every model J that is one of the closest to I; since I · ¬x and I · x have the same differing literals from J except for x, which is positive in J , then d(I · x,K1) < d(I · ¬x,K1); the same property holds when K entails ¬x;\nif K does not contain x then d(I · x,K) = d(I · ¬x,K); since K does not mention x, it it is satisfied by J · x if and only if it is satisfied by J · ¬x for every interpretation J ; therefore, if J is a model at a minimal distance from I then J · x is at minimal distance from I · x; the same holds for ¬x; therefore, d(I · x,K) = d(I · ¬x,K).\nThe second step of the proof relates merge result to the weighted distance of I ·x and I ·¬x. Both are based on merge being defined from the set of models of minimal weighted distance.\n1. if every model I · ¬x has greater weighted distance from {K1, K2} than I · x then the merge result implies x, and the same for ¬x; indeed, since every model where x is false is further than the same one where x is true, minimal models all have x true;\n2. if every model I is at the same weighted distance from {K1, K2} than I · x and I · ¬x then the merge result does not mention x; indeed, it this is true then minimal models are symmetric with respect to x and ¬x; the value of x is therefore irrelevant to the satisfaction of the merge result.\nThe claim can now be proved. Variables are divided in the three groups: those mentioned neither in K1 nor in K2; those occurring in a base but not with the opposite sign in the other; those occurring with opposite signs.\nIf neither K1 nor K2 mention x then for every I it holds d(I ·x,K1) = d(I ·¬x,K1) and d(I · x,K2) = d(I · ¬x,K2), which imply that I · x and I · ¬x have the same weighted distance regardless of the weights. This implies that the merge result does not mention x.\nIf x is in K1 and is not mentioned in K2, then d(I · x,K1) < d(I · ¬x,K1) and d(I ·x,K2) = d(I · ¬x,K2), which implies that I ·x has lower weighted distance that I · ¬x. If x is also in K2 then d(I · x,K2) < d(I · ¬x,K2), and the result is the same. In both cases, the result of the merge entails x.\nIf K1 |= x and K2 |= ¬x, then d(I · x,K1) < d(I · ¬x,K1) and d(I · x,K2) > d(I · ¬x,K2). The result of merge depends on the weights. If w1 > w2 then I · x has lower weighted distance than I · ¬x, proving that the merge result entails x. The same holds for all other literals that are in K1. In other words, if w1 > w2 then the result of merge contains all literals in K1 that occur with the opposite sign in K2. The same holds in reverse if w1 < w2: the result of merge contains all literals of K2. If w1 = w2 then I · x and I · ¬x have the same weighted distance, proving that the result of merge does not mention x.\nAs a result, if w1 > w2 then the result of merge contains not only the literals that are in K1 and do not occur negated in K2, but also the ones that occur negated in K2. The contrary happens if w1 < w2. If w1 = w2 then the result of merge does not contain the variables with opposite sign in K1 and K2. Each of these three possible results can be checked for equivalence with R in polynomial time because of the Horn or Krom restriction."
    }, {
      "heading" : "4 Priority base merging",
      "text" : "Priority base merging [26, 27, 30, 7] is a semantics that selects groups on formulae based on a priority ordering over them. Such an ordering over the knowledge bases K1, . . . , Km can be defined as a partition P of them (this representation is similar to the one used by Rott [30] for orderings over formulae); the classes of the partition are denoted P (1), P (2), P (3), . . . and are not empty. The lower the class Ki belongs to, the higher its reliability is. Such a partition allows comparing two sets of formulae: L ≡ N if and only if L and N are equal; L < N if and only if P (1)∩L = P (1)∩N , . . .P (i− 1)∩L = P (i− 1)∩N and P (i)∩L ⊃ P (i)∩N for some number i, possibly 1.\nThe maxsets of a set of formulae K1, . . . , Km are its maximally consistent subsets. Formally, M is a maxset of K1, . . . , Km if M is consistent, M ⊆ {K1, . . . , Km} and M ∪{Ki} is inconsistent for every Ki ∈ {K1, . . . , Km}\\M . Maxsets can be recast in terms of base remainder sets [2, 3].\nMerging K1, . . . , Km according to a priority ordering is disjoining the maxsets that are minimal according to the ordering [26, 27, 30, 7]. This is equivalent to disjoining the minimal consistent subsets, including the non-maximal ones.\nBy definition, the result of merging is always an or-of-maxsets. However, not all possible or-of-maxsets are produced by merging: some are not generated by any priority partition. Given an or-of-maxsets of K1, . . . , Km, the maxsets it contains are called selected, the others excluded. The aim is to find an ordering, if any, that makes the selected maxsets minimal and the other ones non-minimal.\nA formula R is obtainable from K1, . . . , Km if it can be obtained by merging these formulae. For the merging based on priority orderings, this amount to checking the existence of an ordering that makes the result of mergingK1, . . . , Km equal toR. This condition is equivalent to the existence of an ordering such that the minimal maxsets are exactly the selected ones. The difference between “selected” and “minimal” is that the first one is a requirement (the maxset is in the expected result R) while the second is a condition over a specific ordering (it makes the maxset minimal). Not all formulae are obtainable, and this will be formally proved.\nFor technical reasons, obtainability is extended to pairs (S,E) where both S and E are sets of sets of formulae. Such a pair is obtainable if there exists a priority ordering such that the sets in S are exactly the minimal ones among S ∪ E. Obtainability can be defined from this concept: R is obtainable if R ≡ ∨\nS, (S,E) is obtainable and S ∪ E is the set of all maxsets of K1, . . . , Km.\nGiven formulae R and K1, . . . , Km, the problem of obtainability is that of finding (search problem) or deciding the existence of (decision problem) a priority ordering such that R is the result of merging K1, . . . , Km with that ordering.\nAs usual, the complexity analysis is carried over the decision version of the problem, but the algorithm in Section 4.4 is aimed at finding the actual priority ordering, if one exists. Otherwise, Section 10 describes some possible courses of actions when the expected result is unobtainable.\nA number of properties related to obtainability are shown. The first ones are about maxsets in general, the other about the specific problem of obtaining a formula as the result of merging with an appropriate priority ordering."
    }, {
      "heading" : "4.1 Properties of maxsets",
      "text" : "A general property of maxsets is that they are pairwise inconsistent. This is quite a folklore result, and is proved here only for the sake of completeness.\nLemma 2 Two different maxsets of the same set of formulae are mutually inconsistent.\nProof. To the contrary, assume that M and N are two differing maxsets such that M ∪N is consistent. Since M and N differ, either M\\N or N\\M is not empty. In the first case, since M ∪N = N ∪ (M\\N), then N is consistent with other formulae not in N . This contradicts the assumption that N is a maxset: no formula can be be consistently added to N . A similar line proves the impossibility of the other case.\nLemma 3 If M is a maxset of K1, . . . , Km and I one of its models, then M = {Ki | I |= Ki}.\nProof. I is a model of M if it is a model of all formulae of M , that is, the formulae of M are a subsets of those satisfied by I. This proves that M ⊆ {Ki | I |= Ki}. If such a containment were strict, the formulae Ki that are not in M would be consistent with M because they are satisfied by I, contradicting the assumption that M is a maxset.\nWhen checking minimality using a priority ordering, considering all consistent subsets or only the maxsets does not make any difference, as the following lemma shows.\nLemma 4 If N ⊂ M then M is less than N according to every priority ordering.\nProof. If N ⊂ M then N ∩ P (i) ⊆ M ∩ P (i) for every i. Since the containment is strict, M\\N is not empty. Let Ki be an element of it, and j its class. Containment N ∩ P (i) ⊆ M ∩ P (i) holds for all i’s, including i = j. For this index, however, Ki 6∈ N∩P (j) while Ki ∈ M∩P (j), proving that M is strictly less than N according to the ordering.\nAs a result, minimal consistent subsets and minimal maxsets are the same. Also, a maxset is minimal if and only if is not less than another consistent subset.\nUsually, formulae to be merged are assumed to be consistent, when taken one at time. In such cases, the following lemma helps in identifying the minimal maxsets.\nLemma 5 For every maxset M that is minimal according to priority P it holds M ∩ P (1) 6= ∅.\nProof. To the contrary, assume that M ∩P (1) = ∅. By definition of priorities, P (1) is not empty. Let K be a formula of it. By the assumption that all formulae are consistent, {K} is consistent. Moreover, P (1)∩M ⊂ P (1)∩{K}, which by definition implies {K} < M , contradicting the assumption that M is minimal.\nIn words, minimal maxsets have at least a formula in the first class of the priority partition. This result depends on all formulae being consistent and no priority class being empty, both of which are assumed in this article.\nThe next lemma is useful for producing maxsets with some given property. It tells how to build formulae in such a way the maxsets are related in some way. In particular, it involves letters A,B,C,D, . . .. These are just arbitrary symbols. Given some sets of them, such that {A,B}, {B,C,D}, etc., one can build a formula for A, a formula for B, etc., in such a way the maxsets of these formulae are exactly the given sets {A,B}, {B,C,D}, etc. The only requirements is that none of these sets is contained in another: for example, if {A,B} is given then {A,B,C} cannot.\nLemma 6 Given some sets of letters, none of these sets contained in another, there exists a formula for each letter so that the maxsets of these formulae correspond to the given sets of letters.\nProof. For n sets, ⌈log n⌉ propositional variables are required. Each set of letters is associated an unique propositional interpretation; this is possible because by construction there are at least n propositional interpretations over these variables.\nFor each such interpretation, one can build a formula that is satisfied only by it. For example, if the interpretation makes x and y false and z true, the formula is ¬x ∧ ¬y ∧ z. Since each set of letters is associated a propositional interpretation, is also associated to the corresponding formula.\nIf letter L is in the sets S1, S2, . . ., and these sets corresponds to formulae F1, F2, . . ., the formula corresponding to L is their disjunction F1 ∨ F2 ∨ · · ·. As a result, the formula corresponding to the letter L is satisfied exactly by the interpretations of the sets S1, S2, . . ..\nBy construction, if a set of letters is associated to the interpretation I, then the formulae corresponding to the letters in the set are satisfied by I. This proves that each set of letters corresponds to a consistent set of formulae. This set is also maximally consistent because: a. no other formula is satisfied by that interpretation; and b. if all formulae of the set plus some others are satisfied by another interpretation, then the set corresponding to that interpretation strictly contains the considered one, contradicting the assumption that none of the sets strictly contains another.\nTo conclude the proof, the formulae do not have other maxsets. This is because the formulae are only satisfied by some of the interpretations corresponding to the sets of letters, and each of them is the only model of a maxset.\nIntuitively, this lemma proves that letters can be used in place of formulae, and sets of letters for their maxsets. Provided that no set is contained in another, it is always possible to build a set of formulae to use in place of the letters, and the sets of letters will be their maxsets. This method can be used for example to show that maxsets may form a sort of “cycles”. The first step is to define the sets of letters:\n1. {A,B}\n2. {A,C}\n3. {B,C}\nBinary sets can be drawn as edges of a graph, a graphical representation that will be used also in the rest of this article:❢ ❢\n❢❚❚❚ ✔✔✔ C\nA B\nInstead of showing formulae with maxsets having the given property, the maxsets are expressed as sets of letters, each representing a formula. Lemma 6 tells that such formulae exist, its proof how to build them. In this case, three sets require two variables, like x and y. The interpretations associated to the sets can be chosen arbitrarily, for example:\n• {A,B} ⇒ {x, y}\n• {A,C} ⇒ {x,¬y}\n• {B,C} ⇒ {¬x, y}\nSince A is in {A,B} and in {A,C}, its formula is one satisfied by the models of these two sets: {x, y} and {x,¬y}. For example, A is (x ∧ y) ∨ (x ∧ ¬y), which simplifies to x. In the same way, B = y and C = (x 6≡ y).\nThese formulae x, y, x 6≡ y have the required maxsets, each composed of exactly two formulae over three. From now on, this explicit construction of formulae from sets of letters representing their maxsets is generally not done, with Lemma 6 referenced as evidence that it is possible. This is first done in the proof of Lemma 10, showing that a formula that is an or of some maxsets may not be obtainable with any ordering.\nThe next two lemmas show that some results are easy to obtain: selecting all maxsets or just a single one.\nLemma 7 The priority ordering that gives maximal priority to all formulae makes all maxsets minimal.\nProof. A maxset M could be non-minimal only if there exist another maxset N such that N < M . If all formulae are in P (1), the definition of ordering of maxsets simplifies to: N < M if M ⊂ N . This contradicts the assumption that M is maximally consistent.\nLemma 8 The priority ordering that gives maximal priority to exactly the formulae of a maxset makes it the only minimal one.\nProof. By contradiction, if M is not minimal then N < M for some other maxset N . This implies either P (1) ∩M ⊆ P (1) ∩N or P (1) ∩M ⊂ P (1) ∩N . The latter contradicts P (1) = M . The former implies M ⊆ P (1) ∩N , which is only possible if M = N or M ⊂ N , and a maxset is never contained in another."
    }, {
      "heading" : "4.2 Properties of obtainability",
      "text" : "The following lemma expresses equivalent conditions for a maxset to be a disjunct of the result of merging.\nLemma 9 If R is obtainable by priority base merging from some formulae and M is a maxset of them, the following conditions are equivalent:\n• M is consistent with R;\n• M |= R;\n• M is selected in all orderings that generate R.\nProof. Since the maxsets are mutually inconsistent by Lemma 2, each model of R is contained in exactly a maxset M . Therefore, M is one of the disjuncts that form R if and only if it is consistent with R, and this holds in every ordering that generate R.\nBy definition, merging produces a disjunction of some of the maxsets, the minimal ones according to the priority ordering. A first question is whether all disjunctions of maxsets are obtainable with an appropriate ordering. The following lemma shows that the answer is no.\nThe counterexample uses four maxsets, of which two are selected and two excluded. “Selected” and “excluded” indicates whether a maxset is in the disjunction that is the expected result of merging. In other words, the required ordering has the selected maxsets as the minimal ones. If maxsets are binary, they can be depicted as a graph, where a crossed edge represents an excluded maxset:\n❢ ❢ ❢ ❢❅❅ ❅❅ A B\nCD\nLemma 10 No priority ordering selects {A,B} and {C,D} while excluding {B,C} and {D,A}.\nProof. By Lemma 6, letters and sets of letters can be used in place of formulae and their maxsets, respectively. The following maxsets are proved not be obtained by any ordering:\n1. {A,B} selected\n2. {B,C} excluded\n3. {C,D} selected\n4. {D,A} excluded\nIn words, no priority ordering makes the first and third maxsets minimal out of these four.\nTo the contrary, assume that such an ordering exists. By Lemma 5, since {A,B} is selected, either A or B is in the first class of the priority partition. For the same reason, either C or D is.\nThe first class cannot include both A and D, as otherwise {A,D} would be minimal. For the same reason, it cannot include both B and C, since {B,C} is excluded. The only remaining cases are A and C in the first class, or B and D. The second case is omitted by symmetry: it is the same as the first swapping A with B and C with D.\nIn the first case, B and D are not in the first class of the priority partition. Since both {A,B} and {C,D} are selected, if one of them is not in the second class either, so is the other. Since classes cannot be empty, B and D are in the second class:\nA C B D\nThis ordering selects {A,B} and {C,D} as required, but also {B,C}. This contradicts the assumption that {B,C} is excluded.\nBy Lemma 6, letters A,B,C,D can be replaced by formulae in such a way the four sets in the lemma represent their maxsets. The impossibility of selecting the first and third while excluding the second and fourth proves that the or of the first and third maxsets is not obtainable.\nCorollary 1 There exists R and K1, . . . , Km such that R is the disjunction of some of the maxsets of K1, . . . , Km but is not obtainable by priority base merging.\nAn application of Lemma 6 allows finding the actual formulae to use in place of A,B,C,D. The unobtainable result is then (A ∧B) ∨ (C ∧D). Formulae like these are later used as the basis of an hardness result.\nThe maxsets of this lemma form a cycle in which selected and excluded maxsets alternates. This condition is shown to be necessary and sufficient in the case of maxsets comprising two formulae or less.\nThe counterexample involves four formulae and four maxsets. This is the minimal condition for unobtainability: a result that is an or-of-maxsets is always obtainable if the formulae to be merged are three or less.\nTheorem 5 Every consistent or-of-maxsets is obtainable by priority base merging if the maxsets are less than four.\nProof. If a set of formulae has a single maxset, the only possible result of merge is the maxset itself, which is therefore always obtainable. With two maxsets, only two cases are possible: select one of them, or both. Lemma 8 and Lemma 7 cover both cases.\nWith three maxsets, these lemmas proves that selecting one or all of them is always possible. The only remaining case is that of two selected maxsets out of three. Let them be M , N , and L, where the first two are selected. Being maxsets, M has a formula not in L, and the same for N :\n• M\\L 6= ∅\n• N\\L 6= ∅\nIf M\\L and N\\L intersect, place this intersection in P (1) and all other formulae in P (2). This way, M and N have the same formulae in P (1) while L has none, proving that M and N are selected while L is not.\nIfM\\L and N\\L do not intersect, place their union in P (1) and all other formulae in P (2). This ordering guarantees that both M and N have formulae in P (1) while L has none, and that P (1) ∩M and P (1) ∩N are not contained one in the other.\nSince three formulae have at most three maxsets, this theorems proves that every consistent or-of-maxsets of three formulae is obtainable with an appropriate priority ordering.\nLemma 10 uses four formulae, indeed: {A,B}, {B,C}, {C,D}, {D,A}. The disjunction of the first three of these maxsets is also unobtainable: this can be proved in the same line as Lemma 10, and shows a case where all maxsets but one are unobtainable. In contrast, Lemma 7 and Lemma 8 state that a single maxset and all maxsets are always obtainable.\nThe four maxsets form a cycle, when seen as a graph: {A,B}, {B,C}, {C,D}, {D,A}. When considering maxsets comprising more than two elements, the notion of Berge– acyclicity [12] for hypergraphs ensure obtainability, as the next theorem shows.\nTheorem 6 Every disjunction of a nonempty subset of a set of maxsets that is Berge–acyclic is obtainable by priority base merging.\nProof. A set of sets that is Berge-acyclic can be seen as a tree of sets, where each set shares a single node with its parent and one with each of its children. A priority ordering can be build starting from a maxset, labeling its formulae and then moving to its children.\nAt each step, a set having a single labeled node is considered, and the labeling is extended to its other nodes. A label is either a single number n greater than one or a pair 1, n with n greater than one. The meaning of 1, n will be clarified later, but it roughly means that the node is part of a selected maxset whose other nodes are labeled n.\nThe procedure includes some choices, such as the root and a node in each set. It is however not nondeterministic, as it works for any of these choices; in other words, every choice can be resolved by taking arbitrary choices.\nThe procedure starts from the root. If this maxset is selected, an arbitrary one of its nodes is labeled 1, 2:\n❢ ❢❢ ❢ ❢\n✍\n✎\n✌\n☞ 1, 2\nIf it is excluded, an arbitrary one of its nodes is labeled 2: ❢ ❢ ❢❢✍\n✎\n✌\n☞ 2\nThe algorithm descends the tree. When moving from the parent to a child, the former is all labeled and the latter shares a single labeled node with it and its other\nnodes are unlabeled. Labels are added to them, and the procedure moves to the children.\nLabels are added to selected edges are follows: ❢ ❢❢ ❢\n✍\n✎\n✌\n☞ ✑ ✑✸ ❳❳❳❳③◗◗s n\nn n 1, n ❢ ❢ ❢ ❢✍\n✎\n✌\n☞ ✑\n✑✸ ❳❳❳❳③◗◗s n\nn\nn 1, n\nIn words, if the only label is n, an arbitrary one of the others is labeled 1, n and the remaining (if any) are labeled n. If the only label is 1, n, the others are labeled n.\nIf the considered set is excluded, labels are extended as follows: ❢ ❢ ❢ ❢✍\n✎\n✌\n☞ ✑ ✑✸\n❳❳❳❳③◗◗sn\nn\nn\nn\n❢ ❢ ❢ ❢✍\n✎\n✌\n☞ ✑\n✑✸ ❳❳❳❳③◗◗s1, n\nn+ 1\nn+ 1\nn+ 1\nIn words, if the only label is n, the others are n. If it is 1, n, the others are n+1. This labeling is iterated until all nodes are labeled. Labels then tell the class each formula goes into: 1, n means class one, n means class n. If the maxsets form a forest, which for example happens if there are isolated maxsets, the procedure is iterated on all its trees.\nThe procedure of labelling ensures that the following conditions hold:\n1. every maxset contains at most a label 1, n;\n2. if it does, the others are all n if selected or n+ 1 if excluded;\n3. otherwise, the maxset is excluded and its labels are equal to a value greater than one;\n4. every label 1, n is in at least a selected maxset, and every selected maxset contains at least a label 1, n.\nIn other words, every selected maxset contains a label 1, n and the remaining labels are n; every excluded maxset has either equal labels greater than one or a label 1, n and all others n+ 1; every 1, n label is in at least a selected maxset.\nThis way, selected maxsets are minimal because they contain a node in class one, the rest in class n, and all other maxsets containing the same node in class one have the others in class n. Excluded maxsets are not minimal because they either contain no formula in class one, or otherwise they contain a formula labeled 1, n, the others are in class n+ 1, and the node labeled 1, n is is in another maxset having formulae in class n.\nIn order to complete the proof, we show that the four conditions are ensured when the procedure start, and that none of its step makes them false.\nIf the first maxset is selected, its first label is 1, 2 and the others are 2. If it is excluded, all its labels are 2. The conditions therefore hold up to this point.\nAt each iteration:\n• if the maxset is selected, either has the initial node 1, n and is added n to the others, or it has n in the first node and is added 1, n to one of the others and n to the remaining one; this ensures that it contains at least a label 1, n and the others are all n;\n• if the maxset is excluded, it ends up with all labels n > 1, or with a single label 1, n and the others are n + 1.\nEither way, a set may contain a label 1, n only if it is the initial label, and then no other 1, m is ever added, or it is added in a single node of a selected set that has n has the initial label.\nFinally, a label 1, n is added only in a single case: on a selected set, if the initial node is labeled n. As a result, every 1, n is in a selected set that contains n has the other labels.\nWhile Berge-acyclic hypergraphs are obtainable, the converse is not always the case: some Berge-cyclic hypergraphs are obtainable. Contrasting Corollary 3, which proves that alternating cycles imply unobtainability for binary maxsets, in the general case alternating cycles may be obtainable:\n❢ ❢ ❢\n❢\n✓ ✓\n✓❙ ❙\n❙\n❅\n❅ ❅\n❅❅\nThe maxset on the top is selected, the other excluded. This hypergraph is Bergecyclic, yet is obtained with a two-classes priority ordering:\n❢ ❢ ❢\n❢\n✓ ✓\n✓❙ ❙\n❙\n❅\n❅ ❅\n❅❅\n1\n2 2\n2"
    }, {
      "heading" : "4.3 Binary maxsets",
      "text" : "A particular case of the problem of obtainability by priority base merging is when maxsets comprise at most two formulae. This may be guaranteed to hold in a specific domains, but the main reasons for studying this case are: first, it provides proofs of existence of some specific cases, such as one requiring n classes of priority for obtainability; second, it is a subcase where a necessary and sufficient condition for obtainability can be given, that of alternating cycles of maxsets; third, it provides\nguiding principles for a future study of the general case, where no such necessary and sufficient condition is known.\nWhen all maxsets comprise at most two formulae, they can be seen as a graph:\n• nodes are formulae;\n• isolated nodes are singleton maxsets;\n• edges are maxsets of two formulae.\nThis section is organized as follows:\n1. definitions and basic properties;\n2. transformations on graphs;\n3. properties of some specific graphs or subgraphs;\n4. proof that a graph is unobtainable if and only if it contains a cycle of alternating single excluded–odd sequence of selected edges.\nCycles are defined as closed paths: a sequence of edges ending where it started. They differ from simple cycles, which are not allowed to cross an edge more than once."
    }, {
      "heading" : "4.3.1 Definitions",
      "text" : "When all maxsets contain at most two formulae, the singletons can be excluded from consideration because of Lemma 2: {A} cannot be contained in any other maxset; therefore, inclusion or exclusion do not affect the other maxsets. What remains is a set binary maxsets, which can be seen as a graph where nodes are formulae and edges are maxsets. Some edges correspond to selected maxsets, the remaining ones to excluded maxsets.\nDefinition 1 A selected-excluded graph (abbreviated: se graph) is a graph whose edges are partitioned in two sets: selected and excluded.\nSince edges are maxsets, the distinction indicates which are required to be in the result of merging and which are not. Most of the proofs regarding binary maxsets employ assignments of some formulae to priority class.\nDefinition 2 A partially assigned se graph has some nodes assigned positive integer values. If all nodes are assigned the graph is totally assigned.\nIn a totally assigned se graph, all formulae are assigned a class. Therefore, one may determine the minimal edges (maxsets) and check whether they are exactly the selected ones.\nDefinition 3 A totally assigned graph is obtainable if the minimal edges according to the priority ordering obtained from the numbers assigned to the nodes are exactly the selected ones.\nThis definition may look tautological, but is rather close to the opposite. In a se graph, the selected edges are the maxsets that are required to be in the result of merging: if {A,B} |= R, the edge (A,B) is selected and vice versa. The values assigned to nodes may or may not make such a maxset minimal. If it is not, the edge is incorrectly excluded. Similarly, an excluded edge that is minimal according to the values is incorrectly selected. If no edge is incorrectly selected or excluded the ordering produces the required result.\nDefinition 4 A partially or totally assigned se graph G extends another one H if they have the same nodes and edges and all nodes assigned in H are also assigned in"
    }, {
      "heading" : "G to the same values.",
      "text" : "A se graph is therefore obtainable if and only if it can be extended to a totally assigned se graph that is obtainable. On totally assigned se graphs obtainability can be checked by determining the minimal maxsets according to the ordering given by the values."
    }, {
      "heading" : "4.3.2 Influence",
      "text" : "On totally assigned se graphs, one can check selection or exclusion of every edge by determining its minimality according the values. The following lemma shows which values affect the minimality of a particular edge.\nLemma 11 In a totally assigned se graph, minimality of an edge (a, b) depends only on:\n1. the values of a and b, and\n2. if the value of a is one and the value of b is not, on the values of the nodes linked to a;\n3. if the value of b is one and the value of a is not, on the values of the nodes linked to b.\nProof. If the values of a and b are both one, the edge is minimal no matter of what the other values are. If a and b are both greater than one, the edge is not minimal.\nOf the remaining case, suffices to consider a assigned to one and b to a larger value: the other is specular. If all nodes linked to a are greater or equal than b, then (a, b) is minimal. If one of them is lesser, it is not. In both cases, no other value of the graph affects the result.\nThis lemma could be also refined: of a node of value one, the only information that counts is the minimal values of nodes linked to it."
    }, {
      "heading" : "4.3.3 Value-depending transformations",
      "text" : "Se graphs can be simplified without affecting obtainability: the resulting graph is obtainable if and only if the original one is. Correctness is proved by a detour to the totally assigned graphs extending the original and resulting ones. In particular:\n• a partially assigned se graph is obtainable if and only if it can be extended to a totally assigned one that is also obtainable;\n• obtainability on totally assigned se graphs is verified by checking that the minimal edges are exactly the selected ones;\n• the transformations do not turn a minimal edge into a non-minimal one in the totally assigned se graphs, and vice versa;\n• in most cases, the transformations remove or add only edges that are correctly selected or excluded in the totally assigned se graph; otherwise, they replace correctly/incorrectly selected or excluded edges with edges that are equally correct or incorrect.\nAll this proves that the transformations are correct: they map a partially assigned se graph into another whose extensions to totally assigned se graphs correspond to the ones of the original graph, and this correspondence maps obtainable graphs into obtainable graphs and vice versa. As a result, the original graph is obtainable if and only if the resulting graph is. In most cases, obtainability is maintained simply because edge minimality is unaffected by the transformation.\nThe first simplification is disconnection, which is done in three different ways depending on the values.\nDisconnection, both greater than one.\n❢ ❢ ❢ ❢❅❅ ❍❍✟✟n > 1 m > 1 n > 1 m > 1 An edge between two nodes of value greater than one can be removed. In every extension to a totally assigned se graph, the edge is correctly excluded. Therefore, obtainability in both the graph before and after the change depends only on the minimality of the other edges.\nIf an edge does not touch the disconnected one, by Lemma 11 its minimality is unaffected by the change. But the lemma implies the same for edges touching the deleted one:❢ ❢❢ ❅❅ n > 1? m > 1\nIn this and the following figures, a question mark indicates that the edge may be selected or excluded, and the following reasoning holds in both cases.\nSince n > 1, minimality of the other edge depends on n only, and not on nodes linked to the one of value n. The presence of the removed edge is therefore irrelevant.\nDisconnection, one assigned one.\n❢ ❢ ❢ ❢❢♠❍❍ ✟✟ m > 11 1 ? ? m > 1m > 1\nThe double circle is a new node connected to none else. In this transformation, an edge between a node of value one and a node of value greater than one becomes an edge between the first and an isolated copy of the second.\nIn the totally assigned se graph extending the original one the edge may be minimal or not, but either way its status is not changed by the transformation, as its nodes maintain their value and its node of value one is connected to the same nodes as before. As a result, selection is either correct in both graphs or incorrect in both.\nRegarding the other edges, minimality is not changed by the disconnection. If one such edge does not touch the disconnected one, or touches the node greater than one, Lemma 11 tells that its minimality is not affected. But the same also holds for edges touching the node of value one, since this is connected to the same nodes as before, except that instead of the old node of value m is connected to a new node of value m.\nDisconnection, both assigned one.\n❢ ❢ ❢ ❢❢♠ ♠ ❢❍❍ ✟✟ 1 11 1 1 1\nThe double circles are new nodes, connected to none else. An edge between two nodes of value one is split in two, each linking one of the original nodes to an isolated copy of the second.\nThe original edge is correctly selected in the original graph, and the two new ones are correctly selected in the resulting one. Therefore, obtainability depends only on the minimality of the other edges, which will be proved to be unchanged by the transformation.\nBy symmetry and Lemma 11, the only relevant case is about edges touching the first node of the original edge. After the change, the node is still connected to the same other nodes and to a node of value one, as before. Therefore, minimality of the other edge is unaffected.\nMerging of selected edges.\n❢ ❢ ❢ ❢ ♠ ♠ ❢♠ ❢❍❍✟✟ n 1\nn 1\nn 1\nThe double circles indicate nodes connected to none else. The two original nodes of value one may be touched by other edges, which are connected to the merged node of value one after the transformation.\nIf any of the two nodes of value one is linked to one of value less than n, the same happens in the resulting edge, and vice versa. As a result, if any of the original edges\nis incorrectly selected so is the resulting edge, and vice versa. Therefore, remains to show that obtainability is unaffected by the change only if the two original nodes assigned one are not linked to a node of value less than n.\nSelection of edges not touching the nodes assigned one is not changed because of Lemma 11. Regarding the edges touching one of these, let k be the value of the other node:❢ ❢\n❢ ❢ ♠ ♠\n❢ ❢♠ ❢ ❢◗ ✑ n 1\nn 1\n? k\nn 1 ? k\nIn the original totally assigned se graph, all other nodes linked to the ones assigned one have values greater than n. As a result, the minimality of this edge depends only on whether k is equal to n or greater. The same happens in the resulting graph.\nMerging of excluded edges.\n❢ ❢ ♠ ♠ ❢♠ ❢❢ ❍❍✟✟ PPPP ✏✏ ✏✏ ❅❅ ❅❅ ❅❅ n 11 n > 1\nm > 1 In this figure, n ≤ m. Double circles indicates nodes connected to none else. If the node of value one is only connected to nodes of value greater or equal than n, then the original totally assigned se graph is unobtainable, and so is the graph resulting from the transformation. Therefore, the only situation where obtainability could be altered is then the node of value 1 is connected to at least a node of value less than n.\nAn edge that does not touch the node of value one is unaffected by the change by Lemma 11. Let k be the value of the other node of an edge touching it, and h the minimal values of nodes connected to the same node:\n❢ ❢ ♠ ♠ ❢ ❢♠ ❢❢❢ ❢❢ PPPP ✏✏ ✏✏ ❅❅ ❅❅ ❅❅ ❳❳❳❳ ❍❍ ✟✟ ❳❳❳❳ 1 n 1k\nh\n? k\nh\n?\nn > 1\nm > 1 Since by assumption h if the minimal value of nodes connected to the node of value 1, minimality of the edge of values 1, k only depends on whether k = h or not, in both the original and modified graph. This condition is not altered by the transformation.\nMerging of nodes of equal values, greater than one. In this case, no edge is added or removed. The point is therefore only to prove that selection of an edge touching one of the two nodes is unaffected by the transformation.\n❢ ❢ ❢❍❍ ✟✟ n > 1 n > 1 n > 1\nEdges not touching any of the two nodes are unaffected by Lemma 11. Regarding the ones that touch it, the following figure exemplifies the situation.\n❢ ❢ ❢ ❢ ❢\n❢ ❢ ❢ ❢ ✁ ✁ ✁ ✁ ❚ ❚ ❚❚ ❍❍ ✟✟ n > 1 n > 1 k\nl m\nn > 1 k\nl m\n?\n?? ? ?\n?\nBy Lemma 11, the edge from nodes of values n and k is minimal or not depending on the value of n, but not on the other nodes linked to the one of value n. Therefore, the new link to the node of value l does not influence to the minimality of the edge.\nIn the following, two transformations are shown that, contrary to the ones above, do not require any condition on the value of the nodes. They can be therefore applied to se graphs that are totally unassigned."
    }, {
      "heading" : "4.3.4 Unassigned graphs transformations",
      "text" : "The simplifications in the previous section assume knowledge of the values of nodes in the part of the graph to be changed. Some transformations that can be applied to unassigned se graphs are now presented. Contrary to the ones in the previous sections, these apply to nodes that are not assigned yet. They are valid no matter which values these nodes may take: they map obtainable graphs into obtainable graphs, and unobtainable graphs into unobtainable graphs.\nDefinition 5 The full disconnection of a node that is only touched by excluded edges is the replacement of the node with one for each of these edges.\n❅❅\n❅❅ ❅❅\n❅❅\n❅❅\n❅❅\n❅❅\n❅❅\n❅❅\n❅❅\n❢❢ ❢ ❢\n❢ ❢ ❢❢ ❢ ❢ ❢\n❢\n❢❢ ❢ ❢ ❙ ❙ ❙✓ ✓ ✓ ❙ ❙ ❙ ✓ ✓ ✓\n❍❍ ✟✟\nLemma 12 Full disconnection maps obtainable graphs into obtainable graphs, and vice versa.\nProof. The claim is proved by showing how to map values of the original node to values of its copies in the disconnected version of the graph. This is done as follows:\nthe single value is assigned to the copies; vice versa, if the copies have different values, set the original to their maximum.\nAs a preliminary result, if the value of the node of a non-minimal edge is increased, the edge remains non-minimal.\nIf the original graph is obtainable, there exists at least an extension of it to a totally assigned se graph that is obtainable. If the central node has value one, it is changed to two; the graph remains obtainable. The nodes of the graph that results from the transformation are assigned as follows: the copies of the node that is broken get the same value of the original node; all other values are left unchanged. By Lemma 11, these edges remain non-minimal, as they are still connected to a node of the same value greater than one. The edges connected to them are not changed either: even if the other node is assigned one, it is still connected to a node of the same value.\nIf the resulting graph is obtainable, it has at least an extension to an obtainable totally assigned se graph. The nodes that result from the disconnection may have the same value or not, and these values may even be all one. In the latter case, these values are all changed to two. Otherwise, they are all changed to the maximum of these values. This way, all these nodes are set to the same value. The original graph is then assigned values as follows: the node that was broken is assigned to the value of the resulting nodes; all others are the same. By Lemma 11, all edges touching the broken node remain non-minimal because they are still connected to a node of the same value greater than one; the other edges remains minimal or not for the same reason of the previous case.\nThe second transformation is about the removal of edges that do not participate in any cycle. Such edges form chains that may be isolated to the rest of the graph, or connected by one node only.\nDefinition 6 The removal of a tail is the deletion of a chain of edges that do not participate in any cycle.\nRemoving all such edges leads to a graph where every edge is part of some cycle.\nLemma 13 Removing tails does not alter obtainability.\nProof. The claim is proved for tails comprising a single edge. Longer tails can be dealt with by removing edges one at time, from the end to the beginning. That tails end is a consequence of the finiteness of the graphs and the lack of cycles containing them.\nRemoving an edge release a constraint: the edge is no longer required to be minimal if selected and non-minimal if excluded. As a result, if the original graph is obtainable, so is the one resulting from the transformation. Remains to prove the other direction: if the graph resulting from the removal is obtainable, the edge can be added back without violating obtainability.\nIf the graph after removal is obtainable, an obtainable totally assigned se graph extending it exists. Recovering the removed edge introduces either o node or two. It is shown that these can be assigned values so that obtainability is maintained.\nThe case of two nodes added back is only possible if the edge is connected to none else. In this case, the values can be set to both one for a selected edge or two for an excluded one.\nIn the other case, one of the nodes is also in the graph after removal, so it has a values. This could be equal to one or greater. In the first case, the edge could be selected or excluded. This leads to three possible cases, the first being:\n❢ ❢❜❜❜ ✧\n✧ ✧\n? n > 1\nA value is to be chosen for the reintroduced right node so that the totally assigned se graph remains obtainable. By Lemma 11, minimality of the other edges is not affected by the value of the right node, which can be therefore set to 1 if the edge is selected and 2 if excluded.\n❢ ❢❜❜❜ ✧\n✧ ✧\n❅❅ 1 m\nIn this second case, the left node is one and the edge is excluded: the other node is assigned to a value that is greater than all other nodes connected to the left one.\n❢ ❢❜❜❜ ✧\n✧ ✧\n1 m\nThis is the third case. If the node of value 1 is connected via another selected edge to a node of value n, set m = n. If it is only touched by excluded edges, set m = 1.\nAnother transformation is the zigzag folding, where a chain of selected edges is reduced to a single one by merging the first, third, fifth, etc. node of the chain and the second, fourth, etc.\nCorrectness is proved in two steps: first, a sequence of selected edges has alternating values (n−m−n−m−· · ·) in every obtainable totally assigned se graph; second, by a sequence of transformations, this result is used to prove that the sequence can be folded into a single selected edge.\nLemma 14 The nodes of a chain of selected edges in a totally assigned obtainable graph has alternating values, that is, n−m− n−m− n−m− · · ·.\nProof. Let n, m and k be the values of three consecutive nodes of the chain. The claim follows from k = n for every possible values of n and m.\n❢ ❢ ❢ ...n m k Various cases are possible:\n• n > 1: by Lemma 5, in every selected edge at least one node has value 1; therefore, m = 1; if k < n, then (1, k) is preferred over (1, n); if l > n, the converse happens; since both edges are selected, k = n;\n• n = 1, m = 1: if k greater than 1, then (1, 1) is preferred over (1, k); therefore, k = 1;\n• n = 1, m > 1: the edge values (m, k) is selected; by Lemma 5, one between m and k is 1; since m > 1, if follows that k = 1, which is the same as n.\nSince the alternation holds for every triple of consecutive nodes, it holds for the whole chain.\nThis property implies that, regardless of the values of the other nodes of the graph, the only way to produce a correct assignment is by setting the nodes of the chain to values that alternate between two values.\nDefinition 7 Given a se graph, a zigzag folding of a chain of selected edges is the merging of all nodes of odd position and nodes of even position.\n❢ ❢ ❢ ❢ ❢ ❢ ❢ ✓ ✓ ✓❙ ❙ ❙✓ ✓ ✓❙ ❙ ❙ ◗ ✑\nLemma 15 The zigzag folding maps obtainable graphs into obtainable graphs and vice versa.\nProof. In every totally assigned se graph extending the given one, the nodes of the chain have alternating values n−m− n−m− · · · by Lemma 14. By Lemma 5, one between n and m is one. The other may be one or greater.\nLet n = 1 and m > 1. Disconnecting all edges of the chain produces:\n❢ ❢ ❢ ❢ ✁\n✁ ✁ ❆ ❆ ❆\n✁ ✁ ✁ ❆ ❆ ❆ ❆ ❆ ❆ ✁ ✁ ✁\n... 1 m 1 m\nA B C D ⇒\n❢ ❢ ❢ ❢❢♠ ❢♠ ❢♠ ✁ ✁ ✁ ❆ ❆ ❆ ✁ ✁ ✁ ❆ ❆ ❆ ✁ ✁ ✁ ❆ ❆ ❆ ... 1 m 1 mm m m\nA B C D In this figure, A indicates the connections of the first node of the chain, B to the second, etc. Merging of selected edges and nodes of value greater than one collapse the nodes into two ones:\n❢ ❢ ❢ ❢❢♠ ❢♠ ❢♠ ✁\n✁ ✁ ❆ ❆ ❆ ✁ ✁ ✁ ❆ ❆ ❆\n✁ ✁ ✁ ❆ ❆ ❆\n... 1 m 1 mm m m\nA B C D ⇒\n❢ ❢❢♠ ✚\n✚✚ ✓\n✓ ✓\n✓ ✓\n✓ ✂ ✂ ✂\n❍❍❍❅ ❅\n1 mm\nC D\nB A\nThe two nodes of value m can be then merged back by applying disconnection in reverse: ❢ ❢❢♠\n✚ ✚✚ ✓ ✓\n✓\n✓ ✓\n✓ ✂ ✂ ✂\n❍❍❍❅ ❅\n1 mm\nC D\nB A\n⇒\n❢ ❢ ✚\n✚✚ ✓\n✓ ✓\n✓ ✓\n✓ ✂ ✂ ✂\n❍❍❍❅ ❅\n1 m\nC D\nB A\nThe same can be done if n = m = 1, or m = 1 and n > 1. This proves that, regardless of the two values of the nodes of the chain, obtainability is the same if the chain is folded in a zigzag manner. In other words:\n1. for every se graph, every obtainable totally assigned se graph extending it has alternating values for the nodes of the chain;\n2. no matter what these values are, obtainability is not altered by folding the chain.\nTherefore, folding turns an obtainable graph into an obtainable graph. If the original graph is instead unobtainable, still has extensions to totally assigned se graph with alternating values for the chain; however, these extensions incorrectly select or exclude some edge. This condition is not changed by the folding, either.\nThis lemma proves that every chain of selected edges can be turned into a single edge. The same can be done iteratively until the graph is left with no such a chain, so that no selected edge touches another one. Excluded edges may still form chains of arbitrary length, though."
    }, {
      "heading" : "4.3.5 Forced values",
      "text" : "Some graphs requires values to obey some simple conditions for obtaining the expected result.\nLemma 16 In any obtainable total assigned se graph containing a triangle of selected edges, the nodes of the triangle have value one.\nProof. A triangle of selected edges is also a chain:❢ ❢ ❢❜❜❜ ✧ ✧ ✧\nLet n, m, and k be the values of these nodes. By Lemma 14, n = k. But also m = n, as the sequence is n − m − k − n. Since either n or m is equal to one by Lemma 5, it follows n = m = 1 and also k = n = 1.\nThe following lemma shows that values are forced to increase in a chain of edges that are alternatively excluded and selected. In this configuration, if the first node is assigned 1 the values are 1− n− 1−m− k − · · · with 1 < n < m < k < . . .. At a minimum, these values are 2, 3, 4, etc.\n❢ ❢ ❢ ❢❅❅ ❅❅ ...1 2 1 3 Lemma 17 In any obtainable total assigned se graph containing a chain of alternating excluded-selected edges with the first node assigned one, the values of the other even nodes are one and of the even nodes are strictly increasing.\nProof. The chain begins with value 1 and an excluded edge:\n❢ ❢ ❢ ❢❅❅ ❅❅ ...1 The next node cannot be one, as otherwise the edge would have values 1 and 1, so it would be minimal. Let n > 1 be the value of this node:❢ ❢ ❢ ❢❅❅ ❅❅ ...1 n > 1 The second edge is selected: by Lemma 5, it has at least a node assigned one. Since n > 1, this cannot be other than the third node:\n❢ ❢ ❢ ❢❅❅ ❅❅ ...1 1n > 1 The values of the second edge are n > 1 and 1. The third edge also has the node\nassigned 1. In order to be non-minimal, the other value has to be greater than n:\n❢ ❢ ❢ ❢❅❅ ❅❅ ...1 1n > 1 n > 1 The proof can be iterated indefinitely, showing that each node of odd position has value one, and each node of even position has a value that is greater than the node two positions on the left of it."
    }, {
      "heading" : "4.3.6 Graphs requiring n values to be obtainable",
      "text" : "Several results are affected by whether values are equal to one or greater. This may suggest that what really matters about a value is whether it is one or not. In some cases, for example, a priority ordering the produces the expected result can be obtained by placing a formula for each maxset in class one, and all remaining ones in class two. This is however not always the case, as the next lemma shows: some graphs can be obtained only with n priority classes.\nLemma 18 For every n there exists a graph that is only obtained by assignments with at least n different values.\nProof. The graph is as follows, where the chain is 2n long:❢ ❢ ❢ ❢ ❢ ❢❜❜❜ ✧ ✧ ✧ ❅❅ ❅❅ ...\nBy Lemma 16, the nodes of the triangle have value one in all totally assigned se graph extending this one. This also holds for the starting node of the chain, making Lemma 14 applicable. The values of the chain are therefore 1, n > 1, 1, m > n, 1, k > m, . . . Since the chain is 2n long, it contains n strictly increasing values.\nWhen this lemma on graphs is recast in terms of formulae, it shows a sort of counterexample to the converse of Property 5: a priority ordering cannot always obtained by choosing one formula for each maxset to place in class one. To the contrary, some results can be obtained only with a large number of classes.\nCorollary 2 For any n, there exists R and K1, . . . , Km such that R is obtainable by priority base merging from K1, . . . , Km only with priority partitions having n classes or more."
    }, {
      "heading" : "4.3.7 Unobtainable graphs",
      "text" : "Lemma 19 A graph containing a cycle of alternating (single excluded edge)–(chain of odd selected edges) is unobtainable.\nProof. By Lemma 15, chains of odd selected edges can be folded into a single edge where the first and last nodes are the same. After this transformation, the cycle becomes a sequence of alternating excluded and selected edges. An arbitrary selected edge can be taken as the starting point:❢ ❢ ❢❢ ❅❅ ❅❅ ...... n m\nLemma 5 tells that one among n and m is equal to one for the edge to be selected. It can be assumed m = 1, the other case is symmetric proceeding right-to-left.\n❢ ❢ ❢❢ ❅❅ ❅❅ ...... n 1 By Lemma 14, the next values are alternating between one and an increasing\nvalue. As an example, choosing the least possible values:\n❢ ❢ ❢❢ ❢ ❢❅❅ ❅❅ ❅❅ ... n 1 312 ... The values at the end of excluded edges are increasing. Following the cycle, n\ngets its value, for example 10:\n❢ ❢ ❢❢ ❢ ❢❅❅ ❅❅ ❅❅ ... 1 312 ...1 10 The first edge has values 1 and 10, the next one has the same node of value one and another of value 2. Therefore, the second is minimal and the first is not, opposite to the requirement.\nThe following lemma shows a necessary and sufficient condition to obtainability.\nLemma 20 A graph is obtainable if and only if the result of applying full disconnection, removal of tails and zigzag folding as far as possible is an empty graph.\nProof. These operations does not change obtainability. An empty graph is obtainable, as it does not contain edges on which selection can be incorrect; therefore, if the transformations lead to an empty graph, the original one is obtainable.\nIn the other way around, if the resulting graph is not empty:\n1. every node is touched by at least two edges, as otherwise the single edge would have been deleted by removal of tails;\n2. every node is touched by exactly one selected edge and one or more excluded edges; otherwise, two selected edges would have been folded, and excluded edges only separated by full disconnection.\nAs a result of the second point, if the graph is not empty it contains at least a selected edge. For the graph to be obtainable, either one or its two nodes has to be assigned one by Lemma 5. The other node may be one or a greater value.\n❢ ❢n1 1 The case in which the values are reversed is identical. By the first property of this graph, the node of value 1 is touched by at last\nanother edge, which is excluded because of the second property.\n❢ ❢ ❢❅❅ n1 1 n2 > n1 By Lemma 17, n2 is greater than n1, as otherwise the first edge would not be selected and the second not excluded. By the two properties of the graph, the node of value n2 is connected to at least a selected edge:\n❢ ❢ ❢ ❢❅❅ n1 1 1n2 > n1 The last node is in turn connected to an excluded edge: ❢ ❢ ❢ ❢ ❢❅❅ ❅❅ n1 1 1n2 > n1 n3 > n2 Again, n3 > n2 by Lemma 17. The sequence proceeds alternating selected and excluded edges. By Lemma 17, the nodes at the end of a selected edge have value 1, the others have increasing values. Since every node is touched by at least two edges in this graph, the sequence can be extended indefinitely, until it reaches a node that it already crossed.❢\n✻\n✲\nSince the path is alternating, one of the two horizontal edges is selected and the other is excluded, leading to two possible cases. Since no node is touched by more than one selected edge, the one leading back to it is excluded:❢ ❅❅\n❅❅\n✲\n✻\n❢❅❅ ❅❅ ✻\n✲\nAll values on the path obey the rules of Lemma 17: one at the end of a selected edge, increasing the others.\n❢ ❢ ❢ ❅❅ ❅❅ ✻ ✲\nm\n1 1 ❢ ❢ ❢ ❅❅ ❅❅\n✲\n✻\n1\nm\nk\nIn the first case, the vertical excluded edge is incorrectly selected. In the second case, by Lemma 17 m is greater than k because it is later in the sequence; as a result, the vertical selected edge is incorrectly excluded.\nThis proves that assigning the first selected edge values n1 and 1 leads to unobtainability. But the same happens, by symmetry, if these values are reversed.\nLemma 19 shows that a graph is unobtainable if it contains an alternating cycle. A proof similar to the one of the last lemma allows reversing this result, if cycles are allowed to follow an edge twice in opposite directions. An example where this is necessary is:❢\n❢ ❢ ❢ ❢ ❢\n❢ ❢ ❜ ❜ ❜ ✧ ✧ ✧ ✧ ✧ ✧ ❜ ❜ ❜❅❅ ❅❅ ❅❅ ❅❅ ❅❅\nNone of the three transformations can be applied, as the graph contains no tails, no chain of selected edges, and no node connected to excluded edges only. The graph is therefore unobtainable. However, the only alternating cycles crosses the chain of three edges in the middle twice, once left-to-right and once right-to-left.\nLemma 21 If a graph is unobtainable, it contains an alternating (single excluded edge)–(chain of odd selected edges) cycle that contains the same edge at most twice.\nProof. The claim is proved in two parts: first, the transformations do not add or remove alternating cycles; second, if the resulting graph is not empty, it contains an alternating cycle. By Lemma 19, if the graph is unobtainable then the resulting graph is not empty; therefore, the original graph also has an alternating chain.\n• full disconnection does not open alternating cycles, as every node in them is touched by a selected edge (no consecutive excluded edges); it does not create a new one either, as it only disconnect edges;\n• tail removal only remove edges, so it never creates a new cycle; it does not touch existing cycles, alternating or otherwise;\n• zigzag foldings do change cycles; however, it turns every path of odd selected edges into another path of selected edges of length one, and one is still an odd number; in the same way, paths of even edges are turned into paths of zero length; as a result, a cycle exists after the change if and only if it existed beforehand, and it is alternating if it was.\nThe second part of the proof shows that a non-empty graph resulting from applying the three transformations contains an alternating cycle. In particular, one alternating between single excluded edges and single selected edges. This is shown with a proof similar to the one of the previous theorem, with a difference. If the path reaches one of its previous nodes, this is not the end of the cycle if this would lead to two consecutive excluded edges:❢ ❅❅\n❅❅\n✲\n✻\nIf the edge after the node is selected, the cycle could be closed as an alternating one. This being not the case, the path is continued on the left:❢ ❅❅\n❅❅\n✲\n✛\nThe sequence can continue indefinitely. Since there are only a finite number of edges and only two directions for each edge, at some point the sequence comes back to an edge in the same direction it followed it before. The cycle is closed at that point.\nSince the existence of an alternating cycle implies unobtainability but is also implied by it, it is a characterization of this property.\nCorollary 3 A graph is unobtainable if and only if it contains a cycle of alternating (single excluded edge)-(chain of odd selected edges) that crosses the same edge at most twice.\nExpressed in terms of maxsets, it leads to the following corollary.\nCorollary 4 Formula R is unobtainable from a set K1, . . . , Km having no maxset of size greater than two if and only if a cycle of (single maxset not in R)-(chain of odd maxsets in R) that crosses the same maxset at most twice exists."
    }, {
      "heading" : "4.4 Algorithm",
      "text" : "Theorem 6 ensures that every or-of-maxsets is obtainable if the maxsets form a Bergeacyclic hypergraph. The following algorithm combines the method for iteratively labeling formulae with the search for maxsets. It is guaranteed to work if the maxsets form a Berge–acyclic hypergraph, but may also produce a correct result if they do not.\nAlgorithm 1\n1. for each pair of formulae Ki, Kj, determine its consistency\n2. set L = ∅\n3. M = {Ki, Kj}, where {Ki, Kj} is consistent, Ki ∈ L and Kj 6∈ L; if such a pair does not exists (e.g., L = ∅) then M = {Ki} with Ki 6∈ L; if L contains all Ki’s, stop\n4. choose Kj such that {Ki, Kj} is consistent for every Ki ∈ M ; if no such Kj exists, go to Step 7\n5. if M ∪ {Kj} is inconsistent, go Step 4 and choose another Kj\n6. M = M ∪ {Kj} and go to Step 4\n7. L = L ∪M\n8. if M |= R, then:\n(a) if no formula of M is labeled, then label one with 1, 2 and the others with 2;\n(b) if a formula is labeled 1, n and the others are unlabeled, label the others n\n(c) if a formula is labeled n and the others are unlabeled, label one of the others 1, n and the others n\n(d) otherwise, the set of maxsets is not acyclic: terminate with error\n9. if M 6|= R\n(a) if no formula of M is labeled, label all of them 2\n(b) if a formula is labeled 1, n and the others are unlabeled, label the others n + 1\n(c) if a formula is labeled n and the others and unlabeled, label the others n\n(d) otherwise, the set of maxsets is not acyclic: terminate with error\n10. go to Step 3"
    }, {
      "heading" : "If a formula is labeled 1, n its priority class is one; if it is labeled n, it is n. If",
      "text" : "the result of merging with this priority ordering is R, then R is obtainable.\nThe final check is necessary unless R is guaranteed to be an or-of-maxsets. The algorithm includes some choices (e.g., “choose Kj”, “label one node with 1,2”) but is not nondeterministic: arbitrary choices can be taken.\nEntailment M |= R can be replaced by the consistency M ∪ {R}. The algorithm can be improved by caching the inconsistent sets M ∪ {Kj} detected in Step 5, especially the small ones. This information can be useful when later checking another M ′∪{Kj}: if M ∪{Kj} ⊆ M ′∪{Kj}, unsatisfiability is established at no additional cost.\nTheorem 7 If the maxsets of K1, . . . , Km are Berge-acyclic, Algorithm 1 establishes the obtainability of R from them and outputs a priority ordering that generates R if one exists.\nProof. The algorithm works by iteratively generating a new maxset M from a labeled formula, and then labeling its other formulae according to the rules of Theorem 6.\nIn particular, during the algorithm the following conditions hold:\n• all formulae of the maxsets found so far are labeled;\n• L is the union of the maxsets found so far;\n• M is a subset of a maxset not (yet) in L.\nAt the beginning these conditions are vacuously true, as no maxset has been found and no formula is labeled. No step violates them: Step 3 guarantees that every generated M is a new maxset, as it is built upon at least a formula that is not in the previous ones; Step 7 is reached only when M is a maxset, ensuring the validity of the first of three conditions; the two following steps label the formulae of this newly found maxset.\nSince labeling is performed as in Theorem 6, if the set of maxsets is acyclic and R is an or-of-maxsets, the result is a priority ordering generating R.\nIf the maxsets are not Berge-acyclic, the algorithm stops when it reaches a maxset that already contains two or more labels. In some cases, there is no way it could continue. For example, there is no way to extend labels 1, n and 1, m with n 6= m to the rest of a selected maxset. In the other cases, such as two labels greater than one, the algorithm may still continue and obtain a correct ordering."
    }, {
      "heading" : "4.5 Complexity",
      "text" : "A necessary condition to obtainability is that the formula to obtain is the disjunction of some maxsets of the formulae to be merged. An obvious way to check this is to consider all possible sets of subsets of formulae, checking that each of them is maximally consistent, and that their disjunction is equivalent to the result to obtain. However, the problem can be reformulated in a much simper way using some properties of maxsets.\nLemma 22 Formula R is an or-of-maxsets of K1, . . . , Km if and only if, for every I ∈ Mod(R), it holds M |= R and M ∪ {Ki} |= ⊥ for every Ki 6∈ M , where M = {Ki | I |= Ki}.\nProof. By Lemma 2, maxsets do not share models. Therefore, if R is an or-ofmaxsets then each of its models is in exactly one maxset. In particular, Lemma 3 tells that M = {Ki | I |= Ki} is the maxset containing I, if any. The additional\nconditions ensure that M is actually a maxset (no other formula is consistent with it) and that the disjunction of such M ’s do not include models not in R.\nAs a consequence of this property, checking whether R is an or-of-maxsets is not harder than propositional entailment.\nTheorem 8 Checking whether R is an or-of-maxsets of K1, . . . , Km is in coNP.\nProof. Let X be the set of variables. By Lemma 22, the property can be checked by considering each model I over X , building M = {Ki | I |= Ki} and verifying a number of independent entailments: M |= R and M ∪ {Ki} |= ⊥ for every Ki 6∈ M . Since M can be built in polynomial time from I, the subproblem is equivalent to a single validity check, and can therefore be expressed in terms of a QBF in the form ∀Y.F . Since the whole problem is to check this for every model I over X , it is equivalent to ∀X∀Y.F , and is therefore in coNP.\nHardness holds even in with only two formulae to be merged.\nTheorem 9 Checking whether R is an or-of-maxsets of a set of two formulae is coNP-hard.\nProof. The claim is proved by reduction from the problem of establishing the unsatisfiability of a formula F . Reduction is as follows: formula F is inconsistent if and only if R = ¬c is an or-of-maxsets of A = ¬c and B = c∨ (d∧F ), where c and d are two new variables, not occurring in F .\nRegardless, A∧B is ¬c∧ d∧F by resolution. As result, if F is inconsistent so is A ∧ B. Therefore, the maxsets are {A} and {B}. Since R is the same as A, it can be seen as the disjunction of the single element {A}.\nIf F is consistent, so is A ∧ B. Therefore, the only maxset is {A,B}, which is equivalent to A ∧ B = ¬c ∧ d ∧ F . Model {c = false, d = false} falsifies this formula while satisfying R. Therefore, R is not an or-of-maxsets.\nThese results do not require R to be consistent. If it is not, R is still an or-ofmaxsets, as ∨\n∅ = ⊥. However, this case is not allowed as a result of merging: an inconsistent formula is never obtainable.\nBy Lemma 5, if the formulae are three or less then every consistent or-of-maxset is obtainable. By definition, obtainable formulae are or-of-maxsets. Therefore, the last theorem also proves the complexity of obtainability in this case.\nCorollary 5 Checking whether a consistent formula is obtainable by priority base merging from two formulae is coNP-hard.\nUnfortunately, Theorem 8 does not extend to obtainability. Indeed, while verifying whether a formula is an or-of-maxsets can be done “locally”, by checking each model I and its maxset M at time, obtainability is a global conditions over the maxsets: one of them may be selected or not depending on the others. This makes the problem harder than checking whether a formula is an or-of-maxsets.\nTheorem 10 Checking whether a formula is obtainable by priority base merging is in Σp3.\nProof. By Lemma 3, for every model I of a maxset M it holds M = {Ki | I |= Ki}. This provides a way for expressing the problem of obtainability ofR fromK1, . . . , Km: there exists a priority ordering P such that every model ofR corresponds to a minimal maxset and every model of ¬R corresponds to a subset that is either non-minimal or not a maxset at all.\nFormally, for every model I of R the set M = {Ki | I |= Ki} should be a minimal maxset. By Lemma 4, this is equivalent to M being not greater than another consistent subset N . In other words, for every N ⊆ {K1, . . . , Km} either N is inconsistent or it is not less than M according to P . Comparing according to P can be done in polynomial time, as it amounts to checking which formulae of M and N are in P (1), P (2), etc. The quantifiers are all universal; therefore, the subproblem can be expressed as a ∀QBF .\nRegarding the models I not of R, the set M = {Ki | I |= Ki} should not be a minimal consistent subset according to P . Since M is consistent (because it has the model I), this is equivalent to the existence of another consistent subset N that is less than it according to the ordering. This second subproblem is therefore in the form: ”for all I 6|= R there exists N ⊆ {Ki}, etc. As a result, it can be expressed as a ∀∃QBF .\nBoth these conditions have to hold for a priority ordering P : the problem is to establish the existence of a P such that both hold. As a result, the whole problem is expressed as a ∃∀∃QBF , and is therefore in Σp3.\nThe following result shows that even with four formulae (the smallest case of unobtainable consistent or-of-maxsets) obtainability is coNP-hard even if the formula is assumed to be a consistent or-of-maxsets.\nTheorem 11 Checking whether R is obtainable by priority base merging from four formulae is coNP-hard, and this result holds even assuming that R is a consistent or-of-maxsets.\nProof. The claim is proved by reduction from propositional unsatisfiability. By Lemma 10, R = (A∧B) ∨ (C ∧D) is not obtainable from A,B,C,D if the maxsets are {A,B}, {B,C}, {C,D} and {D,A}. Lemma 6 gives the following formulae:\n• A = (x ∧ y) ∨ (¬x ∧ ¬y)\n• B = (x ∧ y) ∨ (x ∧ ¬y)\n• C = (x ∧ ¬y) ∨ (¬x ∧ y)\n• D = (¬x ∧ y) ∨ (¬x ∧ ¬y)\nThe maxset {D,A} is equivalent to ¬x∧¬y. A formula F can be added to it by changing D and A:\n• A′ = (x ∧ y) ∨ (¬x ∧ ¬y ∧ F )\n• B = (x ∧ y) ∨ (x ∧ ¬y)\n• C = (x ∧ ¬y) ∨ (¬x ∧ y)\n• D′ = (¬x ∧ y) ∨ (¬x ∧ ¬y ∧ F )\nThis provides the required reduction from propositional unsatisfiability to obtainability. Indeed, if x and y are two new variables, not occurring in F , then F is unsatisfiable if and only if R = (A′ ∧ B) ∨ (C ∧D′) is obtainable from A′, B, C,D′.\nThe maxsets of the four formulae are {A′, B} ≡ x∧y, {B,C} ≡ x∧¬y, {C,D′} ≡ ¬x∧ y and, if F is consistent, {D′, A′} ≡ ¬x∧¬y ∧F . As a result, if F is consistent then maxsets are as in Lemma 10, and R is therefore unobtainable. Otherwise, there are only three maxsets, and R is the disjunction of two of them. Lemma 5 ensures that every or-of-maxsets is obtainable in this case.\nObtainability depends on the existence of orderings over the maxsets, which may be exponentially many. This number reduces to quadratic if the maxsets comprise at most two formulae.\nTheorem 12 Checking whether a consistent or-of-maxsets is obtainable by priority base merging is in coNP if all maxsets comprise at most two formulae.\nProof. The result is unobtainable if the graph of maxsets is unobtainable, which by Corollary 3 is equivalent to the presence of an alternating cycle. Since the nodes are formulae, this condition can be reformulated as: there exists a sequence of formulae A1, B1, A2, B2, . . ., each appearing at most twice, such that:\n1. every pair of consecutive formulae is consistent: Ai ∧ Bi 6|= ⊥, Bi ∧ Ai+1 6|= ⊥, . . . ; checking that such pairs are also maximally consistent is unnecessary by the assumption that no maxset contains more than two formulae;\n2. Ai ∧ Bi ∧ R 6|= ⊥: by Lemma 9, this is equivalent to {Ai, Bi} being selected;\n3. either Bi ∧Ai+1 6|= R or Ai+1 ∧Bi+1 ∧R 6|= ⊥; still by Lemma 9, this condition is equivalent to: if {Bi, Ai+1} is selected, so is {Ai+1, Bi+1}.\nSelection can be expressed both as M |= R and M ∧ R 6|= ⊥. Using the first condition when the requirement is negated and the second when it is positive allows expressing unobtainability in terms of non-entailment only. In particular, it is reformulated as the existence of such a cycle that satisfies a number of conditions based on non-entailment. Therefore, unobtainability is in NP, and obtainability in coNP.\nThis allows for a precise characterization of complexity for the case of binary maxsets.\nCorollary 6 Checking whether a consistent or-of-maxsets is obtainable by priority base merging is coNP complete if all maxsets comprise at most two formulae."
    }, {
      "heading" : "4.6 Constant number of formulae",
      "text" : "Unobtainability is monotonic with respect to the excluded sets: adding new ones and enlarging the existing ones does not change unobtainability. The following lemma concerns the obtainability of a pair (S,E), where S and E are sets of sets of formulae, not necessarily maxsets and not necessarily all of them. The definition is repeated here for the sake of readability: (S,E) is obtainable if there exists an ordering that makes S to coincide with the set of minimal sets among S∪E. In other words, (S,E) is obtainable if there exists an ordering that makes the sets in S to be the minimal ones among S ∪ E.\nLemma 23 If S and E are sets of sets such that none is contained in another and (S,E) is not obtainable so is (S,E ′), where E ′ is the result of adding some sets of formulae to E and some formulae to some sets of E.\nProof. Given the assumption of no mutual containment, every pair (S, ∅) is obtainable by placing all formulae of S in class one. Therefore, unobtainability is due to the presence of E: every partition that selects S also selects some N ∈ E. By definition, this means that N is minimal according to the ordering: for every M ∈ S, the two sets N and M coincide up to class n − 1 but N ∩ P (n) 6⊆ M ∩ P (n) for some class n, possibly n = 1. Adding formulae to N or new sets to E does not change this condition.\nObtainability can be defined as follows: there exists a set S such that the result is equivalent to ∨\nS, S is a subset of maxsets and (S,E) is obtainable, where E are the maxsets not in S. In the case of a constant number of formulae, their sets and therefore maxsets are in constant number as well. Quantifying over them does not therefore increase the complexity of the problem.\nHowever, the remaining quantifications are not all of the same kind. For example, the condition that R is an or-of-maxsets is:\nR is an or-of-maxsets of {K1, . . . , Km} m\n∃S ⊆ 2{K1,...,Km} such that R ≡ ∨\nS ∀M ∈ S . M 6|= ⊥ and ∀K 6∈ M . M ∪ {K} |= ⊥\nThe quantifiers over S, M and K are not a problem because the choice are on sets of constant cardinality. Instead, the formula M 6|= ⊥ is an existential quantification (there exists a model satisfying all formulae of M) while all others are universal (e.g. all models satisfying M also satisfy ∨\nS). Such a quantifier can be removed by relaxing the condition over M , accepting some other ones. This is the technique used by Nebel [27] for the generalized closedworld assumption (GCWA) and the WIDTIO revision: instead of considering only the sets specified by the definition, allow others that do not affect the final result. Omitting details, GCWA(T ) is T with a certain set of literals F added; what made determining the exact complexity of the problem GCWA(T ) |= A difficult was that\nchecking membership of a single literal in F is already Πp2-hard, thus requiring a polynomial calls to a Πp2 oracle for T ∪ F |= A. Nebel [27] overcome this difficulty by switching from F to its supersets: T ∪ F 6|= A if and only if T ∪ S 6|= A for some S ⊇ F . In spite of the seeming increase of complexity, the problem is simplified because checking whether S ⊇ F is in Σp2. Therefore, the whole non-entailment problem is in Σp2, as it amounts to guess a set S satisfying a condition in Σ p 2 and a model that satisfies T ∪ S but not A. In a nutshell, the core of the method is: ”instead of the specific set F use a group that includes it, provided that the other sets do not affect the final result”.\nIn the present case, the key point is that if S contains an inconsistent set M , then ∨\nS = {M} ∨ ∨ (S\\{M}) = ⊥ ∨ ∨ (S\\{M}) = ∨\n(S\\{M}): inconsistent sets do not contribute to the disjunction. As a result, the condition can be relaxed by allowing such sets M : requiring that M is a maxset is changed into just M ∪ {K} |= ⊥ for every K 6∈ M . The M ’s satisfying this condition are either maxsets or inconsistent sets of formulae, but the latter do not affect ∨ S.\nR is an or-of-maxsets of {K1, . . . , Km} m\n∃S ⊆ 2{K1,...,Km} such that R ≡ ∨\nS ∀M ∈ S ∀K 6∈ M . M ∪ {K} |= ⊥\nThis condition contains only universal quantifiers: R ≡ ∨\nS is equivalent to “every model satisfying R also satisfies ∨\nS and vice versa”; M ∪{K} |= ⊥ is “every model falsifies M ∪ {K}”. The quantifiers over S, M and K are choices over sets of constant cardinality, so they do not affect complexity. They can be replaced by conjunctions and disjunctions.\nAs a result, checking whether R is an or-of-maxsets is in coNP for a constant number of formulae. This fact is subsumed by Theorem 8, which states the same for any number of formulae. However, with some changes the condition extends to obtainability, for which no similar result hold in the general case. Lemma 23 ensure the correctness of relaxing.\nLemma 24 R is obtainable by priority base merging from K1, . . . , Km if and only if there exists a nonempty S ⊆ 2{K1,...,Km} such that:\n1. R ≡ ∨ S;\n2. ∀M ∈ S, ∀K 6∈ M , M ∪ {K} |= ⊥;\n3. ∀E ⊆ 2{K1,...,KM}, either ∃M ∈ E such that M |= ⊥ or ∃M ∈ E such that M ⊆ M ′ for some M ′ ∈ S or (S,E) is obtainable.\nProof. The first two points are equivalent to R being an or-of-maxsets. The third resembles the definition of obtainability, but E is not the set of maxsets not in S.\nRather, if the condition is false is an arbitrary set of consistent subsets such that (S,E) is not obtainable.\nLemma 23 however ensures that such a set E can be enlarged by adding arbitrary new sets and arbitrary new formulae to existing sets, and the pair (S,E) remains unobtainable. As a result, if there exists E such that (S,E) is unobtainable, E can be added formulae and sets to make it the set of maxsets not in S.\nR obtainable. The three conditions above hold for S equal to the set of selected maxsets. This choice makes the first and second points true. If the third point were false, then (S,E) would be unobtainable for some set of consistent sets E such that none of its element is contained in one of S. Since an N ∈ E is not contained in a selected maxset, it can be enlarged to make it a maxset, and that would be an excluded one. Adding the other excluded maxsets, E is turned into the set of excluded maxsets E ′. By Lemma 23, since (S,E) is unobtainable so is (S,E ′), contradicting the assumption that R is obtainable.\nR unobtainable. If R is not an or-of-maxsets, then for no S points 1 and 2 hold. Otherwise, R is an or-of-maxsets S but (S,E) is not obtainable, where E is the set of the other maxsets. For such E the third point of the condition is violated.\nThe condition of this lemma only contains universal quantifier, apart the ones on sets of constant size. The complexity of the problem is the obvious consequence of this.\nCorollary 7 Checking obtainability by priority base merging from a constant number of formulae is in coNP.\nOnce obtainability is established, the problem is to find the ordering generating the result. This problem can be recast as that of checking whether a partial assignment of formulae to classes can be extended to form an ordering generating the required result of merging.\nTheorem 13 Checking whether a priority ordering can be extended to generate R as the result of merging a constant number of formulae K1, . . . , Km is coNP complete.\nProof. The problem is hard with an empty ordering, as it is equivalent to obtainability. It is also in coNP: it is the same as obtainability by adding the condition that the ordering extends the given one. In the statement of Lemma 24, the only point where the ordering matters is when (S,E) is checked to be obtainable. Therefore, the problem can be expressed by simply changing the subcondition “(S,E) is obtainable” into “(S,E) is obtained by an ordering extending the given partial one” in the statement of Lemma 24. Since the additional check has cost linear in the number of the formulae, complexity remains the same.\nA related question is whether a priority ordering can be uniquely extended to generate the required result. This amounts to finding such an ordering, if any, and then checking that no other priority ordering would do the same.\nTheorem 14 Checking whether a priority ordering not extending a given one generates R as the result of merging a constant number of formulae K1, . . . , Km is coNPcomplete.\nProof. Lemma 24 expresses this problem by changing the condition that (S,E) is obtainable to its obtainability with an ordering not extending the given one. This proves that the problem is in coNP.\nHardness is proved using three formulae with maxsets {A,B}, {A,C}, and {B,C}, where the latter is excluded and only exists if a formula F is satisfiable.\n❢ ❢\n❢❍❍❍❍❍ ✟✟\n✟✟ ✟\n❅❅\nB\nC\nA\nIf the third maxset exists, the only ordering excluding it while selecting the other two is the one containing A in class one and B and C in class two. Indeed, if both B and C are in class one, by Lemma 7 {B,C} would be selected. If A and B are in class one and C is not, {A,B} would be excluded. Since either A or B is in class one by Lemma 8, the only remaining case is A in class one. The other two formulae B and C cannot be in different classes, as otherwise one between {A,B} and {A,C} would be excluded. Therefore, the only ordering obtaining the required result has A in class one and B and C in class two.\nThe same ordering selects the same two maxsets even if the third maxset does not exists. Since the result is the disjunction of all maxsets, Lemma 7 applies: it is also obtained by placing all three formulae in class one. Therefore, a second ordering selects {A,B} and {A,C} in this case.\nThe problem is therefore that of generating formulae such that {B,C} is consistent if and only if a formula F is. Lemma 6, with F added to {B,C}, gives:\nA = (x ∧ ¬y) ∨ (¬x ∧ ¬y)\nB = (x ∧ ¬y) ∨ (x ∧ y ∧ F )\nC = (¬x ∧ ¬y) ∨ (x ∧ y ∧ F )\nThe set of all three formulae is inconsistent, as A is only satisfied by partial models {x = true, y = false} and {x = false, y = false}, while C is falsified by the first and B by the second. Pairs of formulae are all consistent:\n{A,B} = x ∧ ¬y\n{A,C} = ¬x ∧ ¬y\n{B,C} = x ∧ y ∧ F\nThe third is consistent if and only if F is consistent. As a result, the maxsets {A,B} and {A,C} always exist, and are selected when the required result is R = ¬y because they are consistent with it. The third maxset {B,C} only exists if F is consistent, and if this is the case is excluded because it is inconsistent with R.\nAs shown before, R is uniquely obtainable if and only if {B,C} is not a maxset, which is equivalent to the inconsistency of F . As a result, unique obtainability is coNP-hard."
    }, {
      "heading" : "5 What to do in case of unobtainability",
      "text" : "After establishing obtainability, the next step is to determine the weights or priority ordering. The algorithms in Section 3.2 and Section 4.4 searches for them, but of course cannot find anything in case of unobtainability. The question that remain is therefore: what to do in this case?\nVarious possibilities exist. One is to relax the condition that R is exactly the outcome of merging, still maintaining that R is a formula that is known to be true. Lifting equivalence and only requiring consistency is coherent with this principle: R does not discriminate among its models, so each could be the actual state of the world. An integration that results in a formula containing one of the them is still consistent with the assumptions.\nLemma 25 There exists a priority partition such that merging K1, . . . , Km is consistent with R if and only if R is consistent with one of the maxsets of K1, . . . , Km.\nProof. If one of the maxsets is consistent with R, the ordering of Lemma 8 allows selecting it only. The result of merging is equal to this maxset, which by assumption is consistent with R.\nIn the other way around, if R is consistent with the result of merging K1, . . . , Km with some ordering, since this result is the disjunction of some of the maxsets, then R is consistent with at least a maxset.\nEven when merging is not supposed to be a process of search of a single propositional model, a similar idea can be applied. Assuming that the situation is characterized by a set of models, both the result of merging and R result from bounding it as close as possible. The difference is that R is known to be correct, so it contains all these models, while merging only aims at doing the same. Under this assumption, the problem is to find an ordering such that the set of models of R is strictly contained into the result of revision. Since what is known about this set is only that R contains it, the result of merging should be implied by R. Unfortunately, this condition does not constraint the ordering at all.\nLemma 26 Merging K1, . . . , Km with some priority ordering is entailed by R if and only if R entails the disjunction of all maxsets.\nProof. If R entails the disjunction of all maxsets, such a disjunction can be obtained as the result of the revision by the ordering in Lemma 7. Vice versa, if R entails the result of merging K1, . . . , Km with some ordering, since this result is the disjunction of some maxsets, then R also entails the disjunction of all maxsets.\nRequiring that R is entailed by the result of merging or consistent with it gives no information about the relative reliability of the sources. To obtain such an information some additional constraint is needed, such as R being as close as possible to the result of merging, possibly also implying or being consistent with it. In other words, the aim moves from obtaining R with the appropriate priorities to approximating it as much as possible.\nIf a result is unobtainable, another possible line of action is to consider whether the given pieces of knowledge produce it using a different merging mechanism. In other words, instead of using merging by priorities, one of the many other systems [18, 28, 16, 11, 14, 22] may be employed instead.\nAnother possible solution is to split sources based on the variables. If a renowed computer scientist tells some property of computational classes and that the fastest way to go a certain restaurant is to turn left at the next turn, the first information should be assigned higher priority than the second, as there is no a priori reason why an expert in computing should know the roads better than anyone else. According to this principle, when a result is not obtainable some source Ki may be split into {K1i , . . . , K r i }, for example using a partition of the variables to decide which part of Ki goes into K 1 i , which in K 2 i , etc.\nA totally different direction is to lift the assumption that R is a formula known with certainty. Instead, it could be just a formula coming from a source of high reliability. Obtainability then generalizes to the case where no such source may be available [21].\nEven with all these alternatives, it is still possible that the known information R cannot be obtained from the knowledge bases. For example, no semantics allows obtaining R = x from K1 = ¬x and K2 = ¬x. This is however a rational outcome: if the knowledge bases totally agree, merging should produce them as the result, no matter by which weights, priorities or other relative reliability measure. If x is true, then two knowledge bases equal to ¬x are just useless. Unobtainability provides significant information even in this case: the sources are unreliable, and can therefore be ignored from this point on."
    }, {
      "heading" : "6 Conclusions",
      "text" : "In this article, the problem of establishing the relative reliability of knowledge bases given the result of their merge is studied. This is in a way a reverse of the usual problem of merging them, in a similar way as abduction [8] reverses implication: from some information one attempts at deriving what has generated it.\nTwo semantics for merging are considered for this inversion: sums of distances [18, 15, 17] and priority base merging [26, 27, 30, 7]. In a way, these can be considered at the extreme opposite of the spectrum of the many possible semantics for merging [18,\n7]: the first is numeric, model-based and majority-obeying; the second is qualitative (priority-based), syntax-dependent and not majority-obeying. The idea of obtaining reliability information, in whichever form they are expressed, can be however applied to other semantics for merging.\nThe main result proved for the semantics based on the sum of distances is an equivalent formulation for the condition of K1 and K2 generating R with some weights. From this, complexity upper bounds follow, as well as the core of a local search algorithm for determining weights. In particular, whenever the distance measure used is in Πpi or in Σ p i , obtainability is in Π p i+1. Two relevant measures are the drastic and the Hamming distances, for which the problem is proved coNP and Πp2-complete, respectively. A tractable subcase is proved.\nThe complexity analysis on priority base merging shows that obtainability is not harder than computing the result of merging with a fixed priority ordering for the considered subcases. Given that obtainability is the existence of a priority ordering generating a given result, at a first looks it may seem harder. Most of the problems in belief revision are at the second level of the polynomial hierarchy [9, 10, 19, 27, 23], even in some simple restrictions like two formulae to be integrated. In contrast, obtainability proved coNP complete with a constant number of formulae or with maxsets of two or less formulae. The problem of obtainability in general is however still open, so it may prove harder. If Corollary 3 extends in some form from graphs to hypergraphs, obtainability may be still in coNP in the general case.\nWhat to do if the result is not obtainable? Various alternatives are outlined: relax the condition that R is exactly the result of merging, use another semantics of merging (for example, if R is unobtainable with priority merging one may try the weighted sum of Hamming distances), split the sources (for example, by the variables), lift the assumption that R is known with certainty. However, in some cases a result should not be obtainable, like when all sources agree on x and the result is ¬x; in such cases, unobtainability still provide the useful warning that the sources are unreliable.\nWhile the present article concentrates on obtainability, a sensible question is whether a given result is uniquely obtainable or not; another question is whether it can be obtained not with arbitrary weights or priorities, but some obeying some constraints, such as the weight of a base being greater than that of another."
    } ],
    "references" : [ {
      "title" : "Local Search in Combinatorial Optimization",
      "author" : [ "E. Aarts", "J.K. Lenstra" ],
      "venue" : "Interscience Series in Discrete Mathematics and Optimization. John Wiley and sons",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "On the logic of theory change: Partial meet contraction and revision functions",
      "author" : [ "C.E. Alchourrón", "P. Gärdenfors", "D. Makinson" ],
      "venue" : "Journal of Symbolic Logic, 50:510–530",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1985
    }, {
      "title" : "On the link between partial meet, kernel, and infra contraction and its application to Horn logic",
      "author" : [ "R. Booth", "Meyer T.A", "I.J. Varzinczak", "Wassermann R" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "Social choice theory",
      "author" : [ "S. Chopra", "A. Ghose", "T. Meyer" ],
      "venue" : "belief merging, and strategy-proofness. Information Fusion, 7(1):61–79",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "On the logic of iterated belief revision",
      "author" : [ "A. Darwiche", "J. Pearl" ],
      "venue" : "Artificial Intelligence Journal, 89(1–2):1–29",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Revising beliefs on the basis of evidence",
      "author" : [ "J.P. Delgrande" ],
      "venue" : "International Journal of Approximate Reasoning, 53(3):396–412",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Iterated revision as prioritized merging",
      "author" : [ "J.P. Delgrande", "D. Dubois", "J. Lang" ],
      "venue" : "Proceedings, Tenth International Conference on Principles of Knowledge Representation and Reasoning, KR-2006, pages 210–220",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "On the complexity of propositional knowledge base revision",
      "author" : [ "T. Eiter", "G. Gottlob" ],
      "venue" : "updates and counterfactuals. Artificial Intelligence Journal, 57:227– 270",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "The complexity of nested counterfactuals and iterated knowledge base revisions",
      "author" : [ "T. Eiter", "G. Gottlob" ],
      "venue" : "Journal of Computer and System Sciences, 53(3):497– 512",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Disjunctive merging: Quota and gmin merging operators",
      "author" : [ "P. Everaere", "S. Konieczny", "P. Marquis" ],
      "venue" : "Artificial Intelligence Journal, 174(12–13):824–849",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Degrees of acyclicity for hypergraphs and relational database schemes",
      "author" : [ "R. Fagin" ],
      "venue" : "Journal of the ACM, 30:514–550",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1983
    }, {
      "title" : "Knowledge in Flux: Modeling the Dynamics of Epistemic States",
      "author" : [ "P. Gärdenfors" ],
      "venue" : "Bradford Books, MIT Press, Cambridge, MA",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "Iterated belief revision",
      "author" : [ "Y. Jin", "M. Thielscher" ],
      "venue" : "revised. Artificial Intelligence Journal, 171(1):1–18",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Distance-based merging: a general framework and some complexity results",
      "author" : [ "S. Konieczny", "J. Lang", "P. Marquis" ],
      "venue" : "Proceedings of the Eighth International Conference on Principles of Knowledge Representation and Reasoning ",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "DA merging operators",
      "author" : [ "S. Konieczny", "J. Lang", "P. Marquis" ],
      "venue" : "Artificial Intelligence Journal, 157(1–2):49–79",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "DA merging operators",
      "author" : [ "S. Konieczny", "J. Lang", "P. Marquis" ],
      "venue" : "Artificial Intelligence, 157(1-2):49–79",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Logic based merging",
      "author" : [ "S. Konieczny", "R.P. Pérez" ],
      "venue" : "Journal of Philosophical Logic, 40(2):239–270",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "The complexity of belief update",
      "author" : [ "P. Liberatore" ],
      "venue" : "Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence (IJCAI’97), pages 68– 73",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "The complexity of iterated belief revision",
      "author" : [ "P. Liberatore" ],
      "venue" : "Proceedings of the Sixth International Conference on Database Theory (ICDT’97), pages 276–290",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Belief revision by reliability assessment",
      "author" : [ "P. Liberatore" ],
      "venue" : "Manuscript",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Arbitration (or how to merge knowledge bases)",
      "author" : [ "P. Liberatore", "M. Schaerf" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering, 10(1):76–90",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Belief revision and update: Complexity of model checking",
      "author" : [ "P. Liberatore", "M. Schaerf" ],
      "venue" : "Journal of Computer and System Sciences, 62(1):43–72",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Knowledge base merging by majority",
      "author" : [ "J. Lin", "A.O. Mendelzon" ],
      "venue" : "pages 195– 218. Springer",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Are we wise about the wisdom of crowds? the use of group judgments in belief revision",
      "author" : [ "A.E. Mannes" ],
      "venue" : "Management Science, 55(8):1267–1279",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Syntax-Based Approaches to Belief Revision",
      "author" : [ "B. Nebel" ],
      "venue" : "pages 52–88. Cambridge University Press",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "How hard is it to revise a knowledge base? In D",
      "author" : [ "B. Nebel" ],
      "venue" : "Dubois and H. Prade, editors, Belief Change, volume 3 of Handbook of Defeasible Reasoning and Uncertainty Management Systems, pages 77–145. Springer",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Belief revision",
      "author" : [ "P. Peppas" ],
      "venue" : "pages 317–359. Elsevier",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "On the semantics of arbitration",
      "author" : [ "P. Revesz" ],
      "venue" : "International Journal of Algebra and Computation, 7:133–160",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Belief contraction in the context for the general theory of rational choice",
      "author" : [ "H. Rott" ],
      "venue" : "Journal of Symbolic Logic, 58(4):1426–1450",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "The detrimental effects of power on confidence",
      "author" : [ "K. See", "W. Morrison", "N. Rothman", "J. Soll" ],
      "venue" : "advice taking, and accuracy. Organizational Behavior and Human Decision Processes, 116(2):272–285",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Human belief revision and order effect",
      "author" : [ "H. Wang", "J. Zhang", "T.R. Johnson" ],
      "venue" : "Proceedings of the 22th Annual Conference of the Cognitive Science Society",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2000
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "When integrating information coming from different sources, a distinction is made between revision [13, 5, 14, 28, 6] (new information more reliable than old) and merging [22, 4, 18] (same reliability).",
      "startOffset" : 99,
      "endOffset" : 117
    }, {
      "referenceID" : 4,
      "context" : "When integrating information coming from different sources, a distinction is made between revision [13, 5, 14, 28, 6] (new information more reliable than old) and merging [22, 4, 18] (same reliability).",
      "startOffset" : 99,
      "endOffset" : 117
    }, {
      "referenceID" : 12,
      "context" : "When integrating information coming from different sources, a distinction is made between revision [13, 5, 14, 28, 6] (new information more reliable than old) and merging [22, 4, 18] (same reliability).",
      "startOffset" : 99,
      "endOffset" : 117
    }, {
      "referenceID" : 26,
      "context" : "When integrating information coming from different sources, a distinction is made between revision [13, 5, 14, 28, 6] (new information more reliable than old) and merging [22, 4, 18] (same reliability).",
      "startOffset" : 99,
      "endOffset" : 117
    }, {
      "referenceID" : 5,
      "context" : "When integrating information coming from different sources, a distinction is made between revision [13, 5, 14, 28, 6] (new information more reliable than old) and merging [22, 4, 18] (same reliability).",
      "startOffset" : 99,
      "endOffset" : 117
    }, {
      "referenceID" : 20,
      "context" : "When integrating information coming from different sources, a distinction is made between revision [13, 5, 14, 28, 6] (new information more reliable than old) and merging [22, 4, 18] (same reliability).",
      "startOffset" : 171,
      "endOffset" : 182
    }, {
      "referenceID" : 3,
      "context" : "When integrating information coming from different sources, a distinction is made between revision [13, 5, 14, 28, 6] (new information more reliable than old) and merging [22, 4, 18] (same reliability).",
      "startOffset" : 171,
      "endOffset" : 182
    }, {
      "referenceID" : 16,
      "context" : "When integrating information coming from different sources, a distinction is made between revision [13, 5, 14, 28, 6] (new information more reliable than old) and merging [22, 4, 18] (same reliability).",
      "startOffset" : 171,
      "endOffset" : 182
    }, {
      "referenceID" : 24,
      "context" : "More generally, priorities or weights are assigned to the sources to indicate their reliability [26, 27, 30, 7].",
      "startOffset" : 96,
      "endOffset" : 111
    }, {
      "referenceID" : 25,
      "context" : "More generally, priorities or weights are assigned to the sources to indicate their reliability [26, 27, 30, 7].",
      "startOffset" : 96,
      "endOffset" : 111
    }, {
      "referenceID" : 28,
      "context" : "More generally, priorities or weights are assigned to the sources to indicate their reliability [26, 27, 30, 7].",
      "startOffset" : 96,
      "endOffset" : 111
    }, {
      "referenceID" : 6,
      "context" : "More generally, priorities or weights are assigned to the sources to indicate their reliability [26, 27, 30, 7].",
      "startOffset" : 96,
      "endOffset" : 111
    }, {
      "referenceID" : 14,
      "context" : "Measures and aggregation functions allow for fine-grained policies of integration [16, 11, 18].",
      "startOffset" : 82,
      "endOffset" : 94
    }, {
      "referenceID" : 9,
      "context" : "Measures and aggregation functions allow for fine-grained policies of integration [16, 11, 18].",
      "startOffset" : 82,
      "endOffset" : 94
    }, {
      "referenceID" : 16,
      "context" : "Measures and aggregation functions allow for fine-grained policies of integration [16, 11, 18].",
      "startOffset" : 82,
      "endOffset" : 94
    }, {
      "referenceID" : 30,
      "context" : "The strenght of information sources has been studied in the field of cognitive psychology, where it was determined to depend on the order in which the information is given [32], on the size of the group generating it [25] and other social factors [31].",
      "startOffset" : 172,
      "endOffset" : 176
    }, {
      "referenceID" : 23,
      "context" : "The strenght of information sources has been studied in the field of cognitive psychology, where it was determined to depend on the order in which the information is given [32], on the size of the group generating it [25] and other social factors [31].",
      "startOffset" : 217,
      "endOffset" : 221
    }, {
      "referenceID" : 29,
      "context" : "The strenght of information sources has been studied in the field of cognitive psychology, where it was determined to depend on the order in which the information is given [32], on the size of the group generating it [25] and other social factors [31].",
      "startOffset" : 247,
      "endOffset" : 251
    }, {
      "referenceID" : 16,
      "context" : "The present articles analyze the problem for two existing merging semantics: minimal sum of distances [18, 15, 17] and prioritized base merging [26, 27, 30], also called discrimin merging [7].",
      "startOffset" : 102,
      "endOffset" : 114
    }, {
      "referenceID" : 13,
      "context" : "The present articles analyze the problem for two existing merging semantics: minimal sum of distances [18, 15, 17] and prioritized base merging [26, 27, 30], also called discrimin merging [7].",
      "startOffset" : 102,
      "endOffset" : 114
    }, {
      "referenceID" : 15,
      "context" : "The present articles analyze the problem for two existing merging semantics: minimal sum of distances [18, 15, 17] and prioritized base merging [26, 27, 30], also called discrimin merging [7].",
      "startOffset" : 102,
      "endOffset" : 114
    }, {
      "referenceID" : 24,
      "context" : "The present articles analyze the problem for two existing merging semantics: minimal sum of distances [18, 15, 17] and prioritized base merging [26, 27, 30], also called discrimin merging [7].",
      "startOffset" : 144,
      "endOffset" : 156
    }, {
      "referenceID" : 25,
      "context" : "The present articles analyze the problem for two existing merging semantics: minimal sum of distances [18, 15, 17] and prioritized base merging [26, 27, 30], also called discrimin merging [7].",
      "startOffset" : 144,
      "endOffset" : 156
    }, {
      "referenceID" : 28,
      "context" : "The present articles analyze the problem for two existing merging semantics: minimal sum of distances [18, 15, 17] and prioritized base merging [26, 27, 30], also called discrimin merging [7].",
      "startOffset" : 144,
      "endOffset" : 156
    }, {
      "referenceID" : 6,
      "context" : "The present articles analyze the problem for two existing merging semantics: minimal sum of distances [18, 15, 17] and prioritized base merging [26, 27, 30], also called discrimin merging [7].",
      "startOffset" : 188,
      "endOffset" : 191
    }, {
      "referenceID" : 16,
      "context" : "However, any other of the several existing merging semantics can be used [18, 7].",
      "startOffset" : 73,
      "endOffset" : 80
    }, {
      "referenceID" : 6,
      "context" : "However, any other of the several existing merging semantics can be used [18, 7].",
      "startOffset" : 73,
      "endOffset" : 80
    }, {
      "referenceID" : 16,
      "context" : "For merging based on sums of distances [18, 15, 17], a necessary and sufficient condition for R to be the result of merging K1 and K2 with some weights is given.",
      "startOffset" : 39,
      "endOffset" : 51
    }, {
      "referenceID" : 13,
      "context" : "For merging based on sums of distances [18, 15, 17], a necessary and sufficient condition for R to be the result of merging K1 and K2 with some weights is given.",
      "startOffset" : 39,
      "endOffset" : 51
    }, {
      "referenceID" : 15,
      "context" : "For merging based on sums of distances [18, 15, 17], a necessary and sufficient condition for R to be the result of merging K1 and K2 with some weights is given.",
      "startOffset" : 39,
      "endOffset" : 51
    }, {
      "referenceID" : 24,
      "context" : "Using the same necessary and sufficient condition, a local search algorithm for determining the weights is shown The properties proved for prioritized base merging [26, 27, 30] are: some formulae R cannot be obtained from K1, .",
      "startOffset" : 164,
      "endOffset" : 176
    }, {
      "referenceID" : 25,
      "context" : "Using the same necessary and sufficient condition, a local search algorithm for determining the weights is shown The properties proved for prioritized base merging [26, 27, 30] are: some formulae R cannot be obtained from K1, .",
      "startOffset" : 164,
      "endOffset" : 176
    }, {
      "referenceID" : 28,
      "context" : "Using the same necessary and sufficient condition, a local search algorithm for determining the weights is shown The properties proved for prioritized base merging [26, 27, 30] are: some formulae R cannot be obtained from K1, .",
      "startOffset" : 164,
      "endOffset" : 176
    }, {
      "referenceID" : 7,
      "context" : "Surprisingly, complexity turns out not to be higher than that of computing the result of merging [9, 10, 19, 20, 27, 23] at least in some cases.",
      "startOffset" : 97,
      "endOffset" : 120
    }, {
      "referenceID" : 8,
      "context" : "Surprisingly, complexity turns out not to be higher than that of computing the result of merging [9, 10, 19, 20, 27, 23] at least in some cases.",
      "startOffset" : 97,
      "endOffset" : 120
    }, {
      "referenceID" : 17,
      "context" : "Surprisingly, complexity turns out not to be higher than that of computing the result of merging [9, 10, 19, 20, 27, 23] at least in some cases.",
      "startOffset" : 97,
      "endOffset" : 120
    }, {
      "referenceID" : 18,
      "context" : "Surprisingly, complexity turns out not to be higher than that of computing the result of merging [9, 10, 19, 20, 27, 23] at least in some cases.",
      "startOffset" : 97,
      "endOffset" : 120
    }, {
      "referenceID" : 25,
      "context" : "Surprisingly, complexity turns out not to be higher than that of computing the result of merging [9, 10, 19, 20, 27, 23] at least in some cases.",
      "startOffset" : 97,
      "endOffset" : 120
    }, {
      "referenceID" : 21,
      "context" : "Surprisingly, complexity turns out not to be higher than that of computing the result of merging [9, 10, 19, 20, 27, 23] at least in some cases.",
      "startOffset" : 97,
      "endOffset" : 120
    }, {
      "referenceID" : 16,
      "context" : "Model-based merging operators [18, 15, 17] work from a measure of the distance between models, selecting only the ones that are at minimal total distance from the knowledge bases.",
      "startOffset" : 30,
      "endOffset" : 42
    }, {
      "referenceID" : 13,
      "context" : "Model-based merging operators [18, 15, 17] work from a measure of the distance between models, selecting only the ones that are at minimal total distance from the knowledge bases.",
      "startOffset" : 30,
      "endOffset" : 42
    }, {
      "referenceID" : 15,
      "context" : "Model-based merging operators [18, 15, 17] work from a measure of the distance between models, selecting only the ones that are at minimal total distance from the knowledge bases.",
      "startOffset" : 30,
      "endOffset" : 42
    }, {
      "referenceID" : 13,
      "context" : "Two measures of interest are [15, 29, 24]:",
      "startOffset" : 29,
      "endOffset" : 41
    }, {
      "referenceID" : 27,
      "context" : "Two measures of interest are [15, 29, 24]:",
      "startOffset" : 29,
      "endOffset" : 41
    }, {
      "referenceID" : 22,
      "context" : "Two measures of interest are [15, 29, 24]:",
      "startOffset" : 29,
      "endOffset" : 41
    }, {
      "referenceID" : 16,
      "context" : ", Km) to be the sum of the distances d(I,Ki); other methods exists [18].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 13,
      "context" : "If the sources of the knowledge base differ in reliability, a weighted sum can be used in place of the sum [15, 17].",
      "startOffset" : 107,
      "endOffset" : 115
    }, {
      "referenceID" : 15,
      "context" : "If the sources of the knowledge base differ in reliability, a weighted sum can be used in place of the sum [15, 17].",
      "startOffset" : 107,
      "endOffset" : 115
    }, {
      "referenceID" : 27,
      "context" : "Either way, merging selects the models of minimal weighted distance from the knowledge bases [29, 24, 15, 17].",
      "startOffset" : 93,
      "endOffset" : 109
    }, {
      "referenceID" : 22,
      "context" : "Either way, merging selects the models of minimal weighted distance from the knowledge bases [29, 24, 15, 17].",
      "startOffset" : 93,
      "endOffset" : 109
    }, {
      "referenceID" : 13,
      "context" : "Either way, merging selects the models of minimal weighted distance from the knowledge bases [29, 24, 15, 17].",
      "startOffset" : 93,
      "endOffset" : 109
    }, {
      "referenceID" : 15,
      "context" : "Either way, merging selects the models of minimal weighted distance from the knowledge bases [29, 24, 15, 17].",
      "startOffset" : 93,
      "endOffset" : 109
    }, {
      "referenceID" : 0,
      "context" : "The algorithm is based on local search which, while not guaranteed to work in every possible case, is known to perform well in practice [1].",
      "startOffset" : 136,
      "endOffset" : 139
    }, {
      "referenceID" : 24,
      "context" : "Priority base merging [26, 27, 30, 7] is a semantics that selects groups on formulae based on a priority ordering over them.",
      "startOffset" : 22,
      "endOffset" : 37
    }, {
      "referenceID" : 25,
      "context" : "Priority base merging [26, 27, 30, 7] is a semantics that selects groups on formulae based on a priority ordering over them.",
      "startOffset" : 22,
      "endOffset" : 37
    }, {
      "referenceID" : 28,
      "context" : "Priority base merging [26, 27, 30, 7] is a semantics that selects groups on formulae based on a priority ordering over them.",
      "startOffset" : 22,
      "endOffset" : 37
    }, {
      "referenceID" : 6,
      "context" : "Priority base merging [26, 27, 30, 7] is a semantics that selects groups on formulae based on a priority ordering over them.",
      "startOffset" : 22,
      "endOffset" : 37
    }, {
      "referenceID" : 28,
      "context" : ", Km can be defined as a partition P of them (this representation is similar to the one used by Rott [30] for orderings over formulae); the classes of the partition are denoted P (1), P (2), P (3), .",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 1,
      "context" : "Maxsets can be recast in terms of base remainder sets [2, 3].",
      "startOffset" : 54,
      "endOffset" : 60
    }, {
      "referenceID" : 2,
      "context" : "Maxsets can be recast in terms of base remainder sets [2, 3].",
      "startOffset" : 54,
      "endOffset" : 60
    }, {
      "referenceID" : 24,
      "context" : ", Km according to a priority ordering is disjoining the maxsets that are minimal according to the ordering [26, 27, 30, 7].",
      "startOffset" : 107,
      "endOffset" : 122
    }, {
      "referenceID" : 25,
      "context" : ", Km according to a priority ordering is disjoining the maxsets that are minimal according to the ordering [26, 27, 30, 7].",
      "startOffset" : 107,
      "endOffset" : 122
    }, {
      "referenceID" : 28,
      "context" : ", Km according to a priority ordering is disjoining the maxsets that are minimal according to the ordering [26, 27, 30, 7].",
      "startOffset" : 107,
      "endOffset" : 122
    }, {
      "referenceID" : 6,
      "context" : ", Km according to a priority ordering is disjoining the maxsets that are minimal according to the ordering [26, 27, 30, 7].",
      "startOffset" : 107,
      "endOffset" : 122
    }, {
      "referenceID" : 10,
      "context" : "When considering maxsets comprising more than two elements, the notion of Berge– acyclicity [12] for hypergraphs ensure obtainability, as the next theorem shows.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 25,
      "context" : "This is the technique used by Nebel [27] for the generalized closedworld assumption (GCWA) and the WIDTIO revision: instead of considering only the sets specified by the definition, allow others that do not affect the final result.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 25,
      "context" : "Nebel [27] overcome this difficulty by switching from F to its supersets: T ∪ F 6|= A if and only if T ∪ S 6|= A for some S ⊇ F .",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 16,
      "context" : "In other words, instead of using merging by priorities, one of the many other systems [18, 28, 16, 11, 14, 22] may be employed instead.",
      "startOffset" : 86,
      "endOffset" : 110
    }, {
      "referenceID" : 26,
      "context" : "In other words, instead of using merging by priorities, one of the many other systems [18, 28, 16, 11, 14, 22] may be employed instead.",
      "startOffset" : 86,
      "endOffset" : 110
    }, {
      "referenceID" : 14,
      "context" : "In other words, instead of using merging by priorities, one of the many other systems [18, 28, 16, 11, 14, 22] may be employed instead.",
      "startOffset" : 86,
      "endOffset" : 110
    }, {
      "referenceID" : 9,
      "context" : "In other words, instead of using merging by priorities, one of the many other systems [18, 28, 16, 11, 14, 22] may be employed instead.",
      "startOffset" : 86,
      "endOffset" : 110
    }, {
      "referenceID" : 12,
      "context" : "In other words, instead of using merging by priorities, one of the many other systems [18, 28, 16, 11, 14, 22] may be employed instead.",
      "startOffset" : 86,
      "endOffset" : 110
    }, {
      "referenceID" : 20,
      "context" : "In other words, instead of using merging by priorities, one of the many other systems [18, 28, 16, 11, 14, 22] may be employed instead.",
      "startOffset" : 86,
      "endOffset" : 110
    }, {
      "referenceID" : 19,
      "context" : "Obtainability then generalizes to the case where no such source may be available [21].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 16,
      "context" : "Two semantics for merging are considered for this inversion: sums of distances [18, 15, 17] and priority base merging [26, 27, 30, 7].",
      "startOffset" : 79,
      "endOffset" : 91
    }, {
      "referenceID" : 13,
      "context" : "Two semantics for merging are considered for this inversion: sums of distances [18, 15, 17] and priority base merging [26, 27, 30, 7].",
      "startOffset" : 79,
      "endOffset" : 91
    }, {
      "referenceID" : 15,
      "context" : "Two semantics for merging are considered for this inversion: sums of distances [18, 15, 17] and priority base merging [26, 27, 30, 7].",
      "startOffset" : 79,
      "endOffset" : 91
    }, {
      "referenceID" : 24,
      "context" : "Two semantics for merging are considered for this inversion: sums of distances [18, 15, 17] and priority base merging [26, 27, 30, 7].",
      "startOffset" : 118,
      "endOffset" : 133
    }, {
      "referenceID" : 25,
      "context" : "Two semantics for merging are considered for this inversion: sums of distances [18, 15, 17] and priority base merging [26, 27, 30, 7].",
      "startOffset" : 118,
      "endOffset" : 133
    }, {
      "referenceID" : 28,
      "context" : "Two semantics for merging are considered for this inversion: sums of distances [18, 15, 17] and priority base merging [26, 27, 30, 7].",
      "startOffset" : 118,
      "endOffset" : 133
    }, {
      "referenceID" : 6,
      "context" : "Two semantics for merging are considered for this inversion: sums of distances [18, 15, 17] and priority base merging [26, 27, 30, 7].",
      "startOffset" : 118,
      "endOffset" : 133
    }, {
      "referenceID" : 7,
      "context" : "Most of the problems in belief revision are at the second level of the polynomial hierarchy [9, 10, 19, 27, 23], even in some simple restrictions like two formulae to be integrated.",
      "startOffset" : 92,
      "endOffset" : 111
    }, {
      "referenceID" : 8,
      "context" : "Most of the problems in belief revision are at the second level of the polynomial hierarchy [9, 10, 19, 27, 23], even in some simple restrictions like two formulae to be integrated.",
      "startOffset" : 92,
      "endOffset" : 111
    }, {
      "referenceID" : 17,
      "context" : "Most of the problems in belief revision are at the second level of the polynomial hierarchy [9, 10, 19, 27, 23], even in some simple restrictions like two formulae to be integrated.",
      "startOffset" : 92,
      "endOffset" : 111
    }, {
      "referenceID" : 25,
      "context" : "Most of the problems in belief revision are at the second level of the polynomial hierarchy [9, 10, 19, 27, 23], even in some simple restrictions like two formulae to be integrated.",
      "startOffset" : 92,
      "endOffset" : 111
    }, {
      "referenceID" : 21,
      "context" : "Most of the problems in belief revision are at the second level of the polynomial hierarchy [9, 10, 19, 27, 23], even in some simple restrictions like two formulae to be integrated.",
      "startOffset" : 92,
      "endOffset" : 111
    } ],
    "year" : 2014,
    "abstractText" : "A common assumption in belief revision is that the reliability of the information sources is either given, derived from temporal information, or the same for all. This article does not describe a new semantics for integration but the problem of obtaining the reliability of the sources given the result of a previous merging. As an example, the relative reliability of two sensors can be assessed given some certain observation, and allows for subsequent mergings of data coming from them.",
    "creator" : "LaTeX with hyperref package"
  }
}