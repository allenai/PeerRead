{
  "name" : "1606.03289.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Tunable Online MUS/MSS Enumeration",
    "authors" : [ "Jaroslav Bend́ık", "Nikola Beneš", "Ivana Černá" ],
    "emails" : [ "xbendik@fi.muni.cz", "xbenes3@fi.muni.cz", "cerna@fi.muni.cz", "barnat@fi.muni.cz" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In various areas of computer science, such as constraint processing, requirements analysis, and model checking, the following problem often arises. We are given a set of constraints and are asked whether the set of constraints is feasible, i.e. whether all the constraints are satisfiable together. In requirements analysis, the constraints represent the requirements on a given system, usually described as formulae of a suitable logic, and the feasibility question is in fact the question whether all the requirements can actually be implemented at once. In some model checking systems, such as those using the counterexample-guided abstraction refinement (CEGAR) workflow, an infeasible constraint system may arise as a result of the abstraction’s overapproximation. In such cases where the set of constraints is infeasible, we might want to explore the reasons of infeasability. There are basically two approaches that can be used here. One is to try to extract a single piece of information explaining the infeasibility, such as a minimal unsatisfiable subset (MUS) or dually a maximal satisfiable subset (MSS) of the constraints. The other option is to try to enumerate all, or at least as many as possible, of these sets. In this work, we focus on the second approach. Enumerating multiple MUSes is sometimes desirable: in requirements analysis, this gives better insight into the inconsistencies among requirements; in CEGAR-based model checking more MUSes lead to a better refinement that can reduce the complexity of the whole procedure [1]. ar X iv :1 60 6. 03 28\n9v 1\n[ cs\n.A I]\n1 0\nJu n\n20 16\nThe enumeration of all MUSes or MSSes is generally intractable due to the potentially exponential number of results. It thus makes sense to study algorithms that are able to provide at least some of those within a given time limit. An even better option is to have an algorithm that produces MUSes or MSSes in an on-the-fly manner as soon as they are discovered. It is the goal of this paper to describe such an algorithm."
    }, {
      "heading" : "1.1 Related Work",
      "text" : "The list of existing work that focuses on enumerating multiple MUSes is short as most of the related work focused just on an extraction of a single MUS or even a non-minimal unsatisfiable subset. For example all of [15,6,17] uses information from a satisfiability solver to obtain an unsatisfiable subset but they do not guarantee its minimality. Moreover, the majority of the algorithms which enumerate all MUSes have been developed for specific constraint domains, mainly for Boolean satisfiability problems.\nExplicit checking The first algorithm for enumerating all MUSes we are aware of was developed by Hou [9] in the field of diagnosis and is built on explicit enumeration of every subset of the unsatisfiable constraint system. It checks every subset for satisfiability, starting from the complete constraint set and branching in a tree-like structure. The authors presented some pruning rules to skip irrelevant branches and avoid unnecessary work. Further improvements to this approach were made by Han and Lee [8] and also by de la Banda et. al. [3].\nCAMUS A state-of-the-art algorithm for enumerating all MUSes called CAMUS by Liffiton and Sakallah [14] is based on the relationship between MUSes and the so-called minimal correction sets (MCSes), which was independently pointed out by [2,5,12]. This relationship states that M ⊆ C is a MUS of C if and only if it is an irreducible hitting set of MCS(C). CAMUS works in two phases, first it computes all MCSes of the given constraint set, and then it finds all MUSes by computing all the irreducible hitting sets of these MCSes.\nA significant shortcoming of CAMUS is that the first phase can be intractable as the number of MCSes may be exponential in the size of the instance and all MCSes must be enumerated before any MUS can be produced. This makes CAMUS unsuitable for many applications which require only a few MUSes but want to get them quickly. Note that CAMUS is able to enumerate MSSes, as they are simply the complements of MCSes.\nMARCO The desire to enumerate at least some MUSes even in the generally intractable cases led to the development of two independent but nearly identical algorithms: MARCO [11] and eMUS [16]. Both algorithms were later joined and presented in [13] under the name of MARCO. MARCO is able to produce individual MUSes during its execution and it does it in a relatively steady rate.\nTo obtain each single MUS, MARCO first finds a subset U whose satisfiability is not known yet, checks it for satisfiability and if it is unsatisfiable, it is “shrunk” to a MUS. In the case that U is satisfiable, it is in a dual manner expanded into a MSS. The algorithm can be supplied with any appropriate shrink and expansion procedures; this makes MARCO applicable to any constraint satisfaction domain in general.\nCAMUS and MARCO were experimentally compared in [13] and the former has shown to be faster in enumerating all MUSes in the tractable cases. However, in the intractable cases, MARCO was able to provide at least some MUSes while CAMUS often provided none. One another algorithm, the Dualize and Advance (DAA) by Bailey and Stuckey [2] was also evaluated in these experiments. DAA is also based on the relationship between MCSes and MUSes and can produce both MUSes and MSSes during its execution; however, it has shown to be substantially slower than CAMUS in the case of complete MUSes enumeration and also slower than MARCO in the partial enumeration."
    }, {
      "heading" : "1.2 Our Contribution",
      "text" : "In this paper, we present our own algorithm for online enumeration of MUSes and MSSes in general constraint satisfaction domains that is able to outperform the current state-of-the-art MARCO algorithm. The core of the algorithm is based on a novel binary-search-based approach. Similarly to MARCO, the algorithm is able to directly employ arbitrary shrinking and expanding procedures. Moreover, our algorithm contains certain parameters that govern in which cases the shrinking and expanding procedures are to be used. We evaluate our algorithm on a variety of benchmarks that show that the algorithm indeed outperforms MARCO."
    }, {
      "heading" : "1.3 Outline of The Paper",
      "text" : "In Section 2 we state the problem we are solving in a formal way, defining all the necessary notions. In Section 3 we describe the algorithm in an incremental way, starting with the basic schema of MUS/MSS computation and gradually explaining the main ideas of our algorithm. Section 4 provides an experimental evaluation on a variety of benchmarks, comparing our algorithm against MARCO. The paper is concluded in Section 5."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "Our goal is to deal with arbitrary constraint satisfaction system. The input is given as a finite set of constraints C = {c1, c2, . . . , cn} with the property that each subset of C is either satisfiable or unsatisfiable. The definition of satisfiability may vary in different constraint domains, we only assume that if X ⊆ C is satisfiable, then all subsets of X are also satisfiable. The subsets of interest are defined in the following.\nDefinition 1 (MSS, MCS, MUS). Let C be a finite set of constraints and let N ⊆ C. N is a maximal satisfiable subset (MSS) of C if N is satisfiable and ∀c ∈ C \\ N : N ∪ {c} is unsatisfiable. N is a minimal correction set (MCS) of C if C \\N is a MSS of C. N is a minimal unsatisfiable subset (MUS) of C if N is unsatisfiable and ∀c ∈ N : N \\ {c} is satisfiable.\nNote that the maximality concept used here is set maximality, not maximum cardinality as in the MaxSAT problem. This means that there can be multiple MSSes with different cardinality. We use MUS(C), MCS(C), and MSS(C) to denote the set of all MUSes, MCSes, and MSSes of C, respectively. The formulation of our problem is the following: Given a finite set of constraints C, enumerate (all or at least as many as possible) members of MUS(C) and MSS(C). Note that due to the complementarity of MSS and MCS, this also enumerates all MCS(C).\nTo describe the ideas of our algorithm and illustrate its usage, we shall use Boolean satisfiability constraints in the following. In the examples, each of the constraints ci is going to be a clause (a disjunction of literals). The whole set of constraints can be then seen as a Boolean formula in conjunctive normal form.\nExample 1. We illustrate the concepts on a small example. Assume that we are given a set C of four Boolean satisfiability constraints c1 = a, c2 = ¬a, c3 = b, and c4 = ¬a∨¬b. Clearly, the whole set is unsatisfiable as the first two constraints are negations of each other. There are two MUSes: {c1, c2}, {c1, c3, c4}, three MSSes: {c1, c4}, {c1, c3}, {c2, c3, c4} and three MCSes: {c2, c3}, {c2, c4}, {c1}.\nThe powerset of C, i.e. the set of all its subsets, forms a lattice ordered via subset inclusion and denoted by P(C). In our algorithm we are going to deal with the so-called chains of the powerset and deal with local MUSes and MSSes, defined as follows.\nDefinition 2. Let C be a finite set of constraints. The sequence K = 〈N1, . . . Ni〉 is a chain in P(C) if ∀j : Nj ∈ P(C) and N1 ⊂ N2 ⊂ · · · ⊂ Ni. We say that Nk is a local MUS of K if Nk is unsatisfiable and ∀j < k : Nj is satisfiable. Similarly, we say that Nk is a local MSS of K if Nk is satisfiable and ∀j > k : Nj is unsatisfiable.\nNote that there is no local MUS if all subsets on the chain are satisfiable, and there is no local MSS if all subsets on the chain are unsatisfiable."
    }, {
      "heading" : "3 Algorithm",
      "text" : "In this section, we gradually present an online MUS/MSS enumeration algorithm. Consider first a naive enumeration algorithm that would explicitly check each subset of C for satisfiability, split the subsets of C into satisfiable and unsatisfiable subsets, and choose the maximal and minimal subsets of the two groups, respectively. The main disadvantage of this approach is the large number of satisifiability checks. Checking a given subset of C for satisfiability is usually\nan expensive task and the naive solution makes an exponentially many of these checks which makes it unusable.\nNote that the problem of MUS enumeration contains the solution to the problem of satisfiability of all subsets of C as each unsatisfiable subset of C is a superset of some MUS. This means that every algorithm that solves the problem of MUS enumeration has to make several satisfiability checks during its execution. These checks are usually done employing an external satisfiability solver. Clearly, the number of such external calls corresponds with the efficiency of the algorithm. It is therefore our goal to minimise the number of calls to the solver."
    }, {
      "heading" : "3.1 Basic Schema",
      "text" : "Recall that the elements of P(C) are partially ordered via subset inclusion and each element is either satisfiable or unsatisfiable. The key assumption on the constraint domain, as declared above, is that the partial ordering of subsets is preserved by the satisfiability of these subsets. If we thus find an unsatisfiable subset Nu of C then all supersets of Nu are also unsatisfiable; dually, if we find a satisfiable subset Ns of C then all subsets of Ns are also satisfiable. Moreover, none of the supersets of Nu can be a MUS and none of the subsets of Ns can be a MSS. In the following text we refer to this property as to the monotonicity of P(C), and to the elements of P(C) as to nodes.\nOur basic algorithm is described in pseudocode as Algorithm 1. The algorithm consists of two phases. In the first phase it determines the satisfiability of all nodes and extracts from P(C) a set of MSS candidates MSScan and a set of MUS candidates MUScan ensuring that MSS(C) ⊆ MSScan and MUS(C) ⊆ MUScan. In the second phase it reduces MSScan to MSS(C) and MUScan to MUS(C).\nDuring the execution of the first phase the algorithm maintains a classification of nodes; each node can be either unexplored or explored and some of the explored nodes can belong to MSScan or to MUScan. Explored nodes are those, whose satisfiability the algorithm already knows and unexplored are the others. The algorithm stores the unexplored nodes in the set Unex which initially contains all nodes from P(C). The first phase is iterative, the algorithm in each iteration selects some unexplored nodes Nodes, determines their satisfiability using an external satisfiability solver, and exploits the monotonicity of P(C) to deduce satisfiability of some other unexplored nodes. At the end of each iteration the algorithm updates the set Unex by removing from it the nodes whose satisfiability was decided in this iteration. Based on its satisfiability, every node from the set Nodes is added either into MSScan or MUScan.\nIn the pseudocode, we use Sup(N) to denote the set of all unexplored supersets of N including N and Sub(N) to denote the the set of all unexplored subsets of N including N . The notation Sup(N), Sub(N) is used to denote the complements of Sup(N) and Sub(N).\nClearly, the schema converges as the set of unexplored nodes decreases its size in every iteration. The schema also ensures that after the last iteration it holds\nAlgorithm 1: The basic schema of our algorithm\n1 Unex← P(C) 2 MSScan,MUScan ← ∅ 3 while Unex is not empty do 4 Nodes← some unexplored nodes 5 for each N ∈ Nodes do 6 if N is satisfiable then 7 MSScan ←MSScan ∪ {N} 8 Unex← Unex ∩ Sub(N) 9 else\n10 MUScan ←MUScan ∪ {N} 11 Unex← Unex ∩ Sup(N)\n12 extract MSSes from MSScan 13 extract MUSes from MUScan\nthat MUS(C) ⊆MUScan and MSS(C) ⊆MSScan. This is directly implied by the monotonicity of P(C) as no node whose satisfiability was deduced can be a MSS and dually no node whose unsatisfiability was deduced can be a MUS.\nIn the second phase our algorithm extracts all MUSes and MSSes from MUScan and MSScan. Both these extractions can be done by any algorithm that extracts the highest and the lowest elements from any partially ordered set. A trivial algorithm can just test each pair of elements for the subset inclusion and remove the undesirable elements, which can be done in time polynomial to the number of constraints in C and the size of the sets of candidates. We assume that this part of our algorithm is not as expensive as the rest of it, especially when each check for a satisfiability of a set of constraints may require solving an NP-hard problem. We therefore omit the discussion of the second phase in the following and focus solely on the way the set Nodes is chosen in each iteration and the way the unexplored nodes are managed."
    }, {
      "heading" : "3.2 Symbolic Representation of Nodes",
      "text" : "Our algorithm highly depends on an efficient management of nodes. In particular it needs to reclassify some nodes from unexplored to explored and build chains from the unexplored nodes. Probably the simplest way of managing nodes would be their explicit enumeration; however, there are exponentially many subsets of C = {c1, · · · , cn} and their explicit enumeration is thus intractable for large instances. We thus use a symbolic representation of nodes instead.\nWe use the fact that the powerset lattice P(C) can be seen and manipulated as a Boolean algebra. We thus encode the set of constraints C = {c1, . . . , cn} using a set of Boolean variables X = {x1, . . . , xn}. Each subset of C (i.e. each node in our algorithm) is then represented by a valuation of the variables of X. This allows us to represent sets of nodes using Boolean formulae over X. We\nuse f(Nodes) to denote the Boolean formula representing the set Nodes in the following.\nAs an example, consider a set of constraints C = {c1, c2, c3} and let Nodes = {{c1}, {c1, c2}, {c1, c3}} be a set of three nodes. Using the Boolean variables representation of C, we can encode the set Nodes using the Boolean formula f(Nodes) = x1 ∧ (¬x2 ∨ ¬x3).\nThe advantage of this representation is that we can efficiently perform set operations over sets of nodes. The union of two sets of nodes NodesA,NodesB is carried out as a disjunction and their intersection as a conjunction. To get an arbitrary node from a given set, say Unex, we use an external SAT solver (more details in the next subsection). Note that this means that our algorithm employs two external solvers: One is the constraint satisfaction solver that decides satisfiability of the nodes, one is the SAT solver that works with our Boolean description of the constraint set and is employed to produce unexplored nodes. To clearly distinguish between these two we shall in the following use the phrases “constraint solver” and “SAT solver” rigorously."
    }, {
      "heading" : "3.3 Unexplored Nodes Selection",
      "text" : "Let us henceforth denote one specific call to the constraint solver as a check. We now clarify which nodes our algorithm chooses in each of its iterations to be checked and which nodes it adds into the sets of candidates on MUSes and MSSes. We also extend the basic schema which was presented as Algorithm 1. We want to minimise the ratio of performed checks to the number of nodes in P(C). Every algorithm for solving the problem of MUSes enumeration has to perform at least as many checks as there are MUSes, so this ratio can never be zero. Also, it is impossible to achieve the ratio with a minimal value without knowing which nodes are satisfiable and which are not and this information is not a part of the input of our algorithm. Instead of minimising this overall ratio, our algorithm tends to minimise this ratio locally in each of its iterations.\nIn order to select the nodes which are checked in one specific iteration, our algorithm at first constructs an unexplored chain. An unexplored chain is a chain K = 〈N1, . . . , Nk〉 that contains only unexplored nodes and that cannot be extended by adding another unexplored nodes to its ends, i.e. N1 has no unexplored subset and Nk has no unexplored superset. The monotonicity of P(C) implies that either (i) all nodes of K are satisfiable, (ii) all nodes of K are unsatisfiable, or (iii) K has a local MSS and a local MUS, i.e. there is some j such that ∀0 ≤ i ≤ j : Ni is satisfiable and ∀k ≥ l > j : Nl is unsatisfiable. This allows us to employ binary search to find such j performing only logarithmically many checks in the length of the chain. Let us analyse the three possible cases:\n(i) all nodes of K are satisfiable, hence our algorithm deduces that all proper subsets of Nk are satisfiable and none of them can be a MSS, and it marks Nk as a MSS candidate;\n(ii) all nodes of K are unsatisfiable, hence our algorithm deduces that all proper supersets of N1 are unsatisfiable and none of them can be a MUS, and it marks N1 as a MUS candidate; or\nAlgorithm 2: The extended schema of our algorithm\n1 Unex← P(C) 2 MSScan,MUScan ← ∅ 3 while Unex is not empty do 4 K ← some unexplored chain 5 Nodes← processChain(K) 6 for each N ∈ Nodes do 7 if N is satisfiable then 8 MSScan ←MSScan ∪ {N} 9 Unex← Unex ∩ Sub(N)"
    }, {
      "heading" : "10 else",
      "text" : "11 MUScan ←MUScan ∪ {N} 12 Unex← Unex ∩ Sup(N)\n13 extract MSSes from MSScan 14 extract MUSes from MUScan\n(iii) Nj is the local MSS of K and Nj+1 is its local MUS, hence our algorithm deduces that all proper subsets of Nj are satisfiable, all proper supersets of Nj+1 are unsatisfiable, and it marks Nj as a MSS candidate and Nj+1 as a MUS candidate.\nAlgorithm 2 shows the extended schema of our algorithm which implements the above method for choosing nodes to be checked. At the beginning of each iteration the algorithm finds an unexplored chain K which is subsequently processed by the processChain method. This method finds the local MUS and local MSS of K (possibly only one of those) using binary search and returns them.\nTo construct an unexplored chain, our algorithm first finds a pair of unexplored nodes (N1, Nk) such that N1 ⊆ Nk and then builds a chain 〈N1, N2, . . . , Nk−1, Nk〉 by connecting these two nodes. The intermediate nodes N2, . . . , Nk−1 are obtained by adding one by one the constraints from Nk \\N1 to the node N1. We refer to each such pair of unexplored nodes (N1, Nk) that are the end nodes of some unexplored chain as to an unexplored couple.\nIn order to find an unexplored couple our algorithm asks for a member of Unex by employing the SAT solver (by asking for a model of the formula f(Unex)). Besides the capability of finding an arbitrary member of Unex, we require the following capability: For a given member Np ∈ Unex, the SAT solver should be able to produce a minimal Nq ∈ Unex such that Nq ⊆ Np, where minimal means that there is no other Nr with Nr ⊂ Nq. Similarly, we require the SAT solver to be able to produce maximal such Nq. One of the SAT solvers that satisfies our requirements is miniSAT [7] that allows the user to fix values of some variables and to select a default polarity of variables at decision points during solving. To obtain a minimal Nq which is a subset of Np, we set the default polarity of variables to False and fix the truth assignment to the variables that have been assigned False in Np. Similarly for the maximal case.\nWe now describe two approaches of obtaining unexplored couples, assuming that we employ a SAT solver satisfying the above requirements.\nBasic approach The Basic approach consists of two calls to the SAT solver. The first call asks the SAT solver for an arbitrary minimal member of Unex. If nothing is returned then there are no more unexplored nodes. Otherwise we obtain a node Nk which is minimal in Unex. We then ask the SAT solver for a maximal node Nl ∈ Unex such that Nl is a superset of Nk. The pair (Nk, Nl) is then the new unexplored couple.\nPivot based approach Supposing that the SAT solver works deterministically, a series of calls for maximal (minimal) nodes of Unex may return nodes from some local part of the search space that may lead to construction of unnecessarily short chains. In order to alleviate this disadvantage of the Basic approach we propose to first choose a pivot Np, an unexplored node which may be neither maximal nor minimal and which should be chosen somehow randomly. As the next step this approach asks the SAT solver for a minimal node Nl such that Nk ⊆ Np and for a maximal node Nl such that Np ⊆ Nl. The new unexplored couple is then (Nk, Nl). The randomness in choosing the node Np is expected to ensure that we hit a part of Unex with large chains.\nTo get the pivot, we create a random partial valuation by randomly fixing values of some variables and ask the SAT solver for a node that complies with this partial valuation. If the solver returns a node, we use it as the pivot. Clearly, giving the SAT solver a partial valuation may make it fail to find a node despite the fact that there still are some. Therefore, if the solver return nothing, we try to get the unexplored couple using the Basic approach."
    }, {
      "heading" : "3.4 Online MUS/MSS Enumeration",
      "text" : "The algorithm as presented until now is only able to provide MUSes and MSSes in the second phase, after it finished exploring all the nodes. We now describe the last piece of our final algorithm, namely the way of producing MUSes and MSSes during the execution of the first phase. To do so, we need to employ two procedures: The shrink procedure is an arbitrary method that can turn a unsatisfiable node Nu into a MUS. Dually, the grow procedure is a method that can turn a satisfiable node into MSS Ns. A simple variant of these two procedures is shown in Algorithms 3 and 4. The simple shrink (grow) method iteratively attempts to remove (add) constraints from Nu (Ns), checking each new set for satisfiability and keeping any changes that leave the set unsatisfiable (satisfiable). These simple variants serve just as illustrations, there are known efficient implementations of both shrink and grow for specific constraint domains; as an example see MUSer2 [4] which implements the shrink method for Boolean constraints systems.\nRecall that as a result of a processing a single chain K, our algorithm finds either a local MUS Nu, or a local MSS Ns, or both of them. To get a MUS (MSS) we propose to employ the shrink (grow) method on this local MUS (MSS). However, performing shrink (grow) on each local MUS (MSS) can be quite expensive\nAlgorithm 3: shrink(C,Nu)\n1 for c ∈ Nu do 2 if Nu \\ {c} is unsatisfiable then 3 Nu ← Nu \\ {c}\n4 return Nu\nAlgorithm 4: grow(C,Ns)\n1 for c ∈ C \\Ns do 2 if Ns ∪ {c} is satisfiable then 3 Ns ← Ns ∪ {c}\n4 return Ns\nAlgorithm 5: processChain(C,K = 〈N1, . . . , Nk〉) 1 find local MSS Ns and MUS Nu of K using binary search 2 if u < S(|K|) then 3 Nu ← shrink(Nu) 4 yieldMUS(Nu)\n5 if s > |K| −G(|K|) then 6 Ns ← grow(Ns) 7 yieldMSS(Ns)\n8 return {Nu, Ns} // Note that Nu or Ns may not exist\nand can significantly slow down our algorithm. The amount of time needed for performing one specific shrink (grow) of Nu (Ns) correlates with the position of Nu (Ns) on K; the closer Nu (Ns) is to the start (end) of K the bigger amount of time needed for the shrink (grow) can be expected.\nTherefore, we propose to shrink (grow) only some of the local MUSes (MSSes) based on their position on K. Let |K| be the length of K, u the index of Nu in K, and S : N→ N be an arbitrary user defined function. Our algorithm shrinks Nu into a MUS if and only if u < S(|K|). As an example, consider S(x) = x2 ; in such case Nu is shrunk only if it is contained in the first half of K. Similarly, let s be the index of local MSS Ns of chain K and G : N → N. The local MSS Ns is grown only if s > |K| −G(|K|), which for example for G(x) = x2 means that Ns is grown only if it is contained in the second half of K. The complexity of performing shrinks also depends on the type of constrained system that is being processed, therefore the concrete choice of S and G is left as a parameter of our algorithm. Algorithm 5 shows an extended version of the method processChain which is able to produces MUSes and MSSes during its execution based on the above mechanism."
    }, {
      "heading" : "3.5 Example Execution of Our Algorithm",
      "text" : "The following example explains the execution of our algorithm on a simple set of constraints. The example is illustrated in Fig. 1. Let C = {c1 = a, c2 = ¬a, c3 = b, c4 = ¬a ∨ ¬b}, S(x) = x, G(x) = x.\nInitially MSScan = ∅, MUScan = ∅ and all nodes are unexplored, i.e. f(Unex) = True. Figure 1 shows the values of control variables in each iter-\nation and also illustrates the current states of P(C). In order to save space we encode nodes as bitvectors, for example the node {c1, c3, c4} is written as 1011."
    }, {
      "heading" : "I. iteration",
      "text" : ""
    }, {
      "heading" : "II. iteration",
      "text" : ""
    }, {
      "heading" : "III. iteration",
      "text" : "After the last iteration of the first phase of our algorithm there is no model of f(Unex) (this means that Unex is empty), MSScan = {1010, 1001, 0111} and MUScan = {1100, 1011}. Because functions S and G were stated in this example as S(x) = x,G(x) = x, each candidate on MUS or MSS has been alredy shrunk or\ngrown to MUS or MSS, respectively, therefore MSS(C) = MSScan,MUS(C) = MUScan and the second phase of our algorithm can be omitted.\nNote that in the first iteration the node 1010 was found to be a MSS, which means (due to the definition of MSS) that all its supersets are unsatisfiable. One would use this fact to mark all supersets of 1010 as explored, however our algorithm does not do this because some of these subsets can be MUSes (1011 in this example). If we were interested only in MSS enumeration we could mark all supersets of each MSS as explored; dually in the case of only MUS enumeration."
    }, {
      "heading" : "4 Experimental Results",
      "text" : "We now demonstrate the performance of several variants of our algorithm on a variety of Boolean CNF benchmarks. In particular, we implemented in C++ both the Basic and the Pivot Based approach for constructing chains and we evaluated both these approaches using several variants of the functions S and G. We also give a comparison with MARCO algorithm [13].\nMARCO algorithm was presented by its authors in two variants, the basic variant and the optimised variant which is tailored for MUS enumeration. Both variants are iterative. The basic variant finds in each iteration an unexplored node, checks its satisfiability and based on the result the node is either shrunk into a MUS or grown into a MSS. Subsequently, MARCO uses the monotonicity of P(C) to deduce satisfiability of other nodes in the same way our algorithm does. The optimised variant differs from the basic variant in the selection of the unexplored node; it always selects a maximal unexplored node. If the node is unsatisfiable it is shrunk into a MUS, otherwise it is guaranteed to be a MSS. We used the optimised variant in our experiments. The pseudocodes of both variants can be found in [13].\nNote that both compared algorithms (MARCO and our algorithm) employ several external tools during their execution, namely a SAT solver for finding the unexplored nodes, a constraint solver to decide the satisfiability of constraint sets, and the two procedures shrink and grow mentioned above. The list of external tools coincides for both algorithms. Therefore, we reimplemented MARCO algorithm in C++ to ensure that the two algorithms use the same implementations of the shrink and grow methods and the same solvers. As both the SAT solver and constraint solver we used the miniSAT tool [7] and we used the simple implementation of the shrink and grow methods as described earlier. Note that there are some efficient implementations of the shrink and grow methods for Boolean constraints, however, in general there might be no effective implementation these methods. That is why we used the simple implementations.\nAs an experimental data we used a collection of 294 unsatisfiable Boolean CNF Benchmarks that were taken from the MUS track of the 2011 SAT competition1. The benchmarks range in their size from 70 to 16 million constraints and from 26 to 4.4 million variables and were drawn from a variety of domains and applications. All experiments were run with a time limit of 60 seconds.\n1 http://www.cril.univ-artois.fr/SAT11/\nDue to the potentially exponentially many MUSes and/or MSSes in each instance, the complete MUS and MSS enumeration is generally intractable. Moreover, even outputting a single MUS/MSS can be intractable for larger instances as it naturally includes solving the satisfiability problem, which is for Boolean instances NP-complete. Table 1 shows in how many instances the variants of our algorithm were able to output at least one MUS or MSS. MARCO was able to output at least one MUS and one MSS in 51 instances whereas several variants of our algorithm were able to output some MSSes in about 150 instances and some MUSes in up to 60 instances. Some of the 296 instances are just intractable for the solver which is not able to perform even a single consistency check within the used time limit. The other significant factor that affected the results is the complexity of the shrink method. MARCO in every iteration either ”hits” a satisfiable node and directly outputs it as an MSS or waits till the shrink method shrinks the unsatisfiable node into a MUS. Therefore, each call of the shrink method can suspend the execution for a nontrivial time.\nOne can see that our algorithm also suffers from the possibly very expensive shrink calls and performs very poorly when the S function is set to S(x) = x. On the other hand, the variants that perform only the “easier” shrinks by setting S to be S(x) < x achieved better results. The grow method is generally cheaper to perform than the shrink method as checking whether an addition of a constraint to a satisfiable set of constraints makes this set unsatisfiable is usually cheaper than the dual task. No significant difference between the Basic and the Pivot based approach was captured in this comparison.\nAnother comparison can be found in Table 2 that shows the 5% trimmed sums of outputted MSSes and MUSes (summed over all of the 294 instances), i.e. 5% of the instances with the least outputted MSSes (MSSes) and 5% of the instances with the most outputted MSSes (MSSes) were discarded. All variants of our algorithm were noticeably better in MSS enumeration than MARCO. In the case of MUS enumeration MARCO outperformed these variants of our algorithm that shrink only some of the local MUSes, i.e. variants where S(x) = 0.6x and S(x) = 0.4x. However, the variants with S(x) = x and S(x) = 0.8x performed better, especially the variant with G(x) = 0.2x, S(x) = x outputted about three times more MUSes than MARCO. In this comparison, there is already some notable difference between the Basic and the Pivot based approach. The Pivot based approach seems to be better for MUS enumeration whereas the Basic approach is more suitable for the MSS enumeration. As the Pivot based approach is randomized its performance may vary if it is run repeatedly on the same instances; result of a single run may be misleading. Therefore, we ran all tests of the Pivot based approach repeatedly and the tables show the average values.\nBesides the number of outputted MUSes/MSSes within a given time limit, we also compared our algorithm with MARCO in the case of complete MUS/MSS enumeration. We used the generator of Boolean CNF formulae from [10] to generate tractable instances with a size of 30 to 40 constraints, 15 instances per each size. The graphs in Fig. 2 show the time comparison of MARCO and our algorithm using the Pivot based approach with S and G set to S(x) = 0.2x and\nG(x) = 0.8x. All of the instances were tractable which means that both phases of our algorithm were executed. Some of the MUSes and MSSes were output in the online manner, the rest of them were extracted from the candidate sets in the second phase.\nSummarised, our algorithm outperformed MARCO both in the online MUS and MSS enumeration and in the complete MUS and MSS enumeration. Also, the results show that the choice of the functions S and G greatly affect the efficiency of our algorithm. The faster the S (G) grows, the more effort is made to output MUSes (MSSes). Also, it may be worth to always perform at least the “easy” grows (shrinks) even if we want to output only MUSes (MSSes), because each shrink (grow) also helps to reduce the space of unexplored nodes."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we have presented a novel algorithm for online enumeration of MUSes and MSSes which is applicable to any type of constraint system. The core of the algorithm is based on a novel binary-search-based approach which allows the algorithm to efficiently explore the space of all subsets of a given set of constraints. We have made an experimental comparison with MARCO, the stateof-the-art algorithm for online MUS and MSS enumeration. The results show that our algorithm is better both for online enumeration and also in the case of complete enumeration. Our algorithm can be built on a top of any consistency solver and can employ any implementation of the shrink and grow methods, therefore any future advance in this areas can be reflected in the performance of our algorithm.\nOne direction of future research is to aim at parallel processing of the search space in order to improve the performance of our approach; there are usually many disjoint unexplored chains that can be processed concurrently. Another\npossible direction is to focus on some specific types of constraint systems and customise our algorithm to be more efficient for these systems."
    } ],
    "references" : [ {
      "title" : "Reveal: A formal verification tool for verilog designs",
      "author" : [ "Z.S. Andraus", "M.H. Liffiton", "K.A. Sakallah" ],
      "venue" : "LPAR. Lecture Notes in Computer Science, vol. 5330, pp. 343–352. Springer",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Discovery of minimal unsatisfiable subsets of constraints using hitting set dualization",
      "author" : [ "J. Bailey", "P.J. Stuckey" ],
      "venue" : "Practical Aspects of Declarative Languages, pp. 174–186. Springer",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Finding all minimal unsatisfiable subsets",
      "author" : [ "M.G. de la Banda", "P.J. Stuckey", "J. Wazny" ],
      "venue" : "Proceedings of the 5th ACM SIGPLAN international conference on Principles and practice of declaritive programming. pp. 32–43. ACM",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "MUSer2: An efficient MUS extractor",
      "author" : [ "A. Belov", "J. Marques-Silva" ],
      "venue" : "Journal on Satisfiability, Boolean Modeling and Computation 8, 123–128",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Consistent subsets of inconsistent systems: structure and behaviour",
      "author" : [ "E. Birnbaum", "E.L. Lozinskii" ],
      "venue" : "J. Exp. Theor. Artif. Intell. 15(1), 25–46",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Restoring satisfiability or maintaining unsatisfiability by finding small unsatisfiable subformulae",
      "author" : [ "R. Bruni", "A. Sassano" ],
      "venue" : "Electronic Notes in Discrete Mathematics 9, 162–173",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "An extensible sat-solver",
      "author" : [ "N. Eén", "N. Sörensson" ],
      "venue" : "SAT. Lecture Notes in Computer Science, vol. 2919, pp. 502–518. Springer",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Deriving minimal conflict sets by cs-trees with mark set in diagnosis from first principles",
      "author" : [ "B. Han", "S. Lee" ],
      "venue" : "IEEE Trans. Systems, Man, and Cybernetics, Part B 29(2), 281–286",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "A theory of measurement in diagnosis from first principles",
      "author" : [ "A. Hou" ],
      "venue" : "Artif. Intell. 65(2), 281–328",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "CNFgen formula generator",
      "author" : [ "M. Lauria" ],
      "venue" : "http://massimolauria.github.io/ cnfgen/,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2016
    }, {
      "title" : "Enumerating infeasibility: Finding multiple muses quickly",
      "author" : [ "M.H. Liffiton", "A. Malik" ],
      "venue" : "Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems, 10th International Conference, CPAIOR 2013, Yorktown Heights, NY, USA, May 18-22, 2013. Proceedings. Lecture Notes in Computer Science, vol. 7874, pp. 160–175. Springer",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Identifying conflicts in overconstrained temporal problems",
      "author" : [ "M.H. Liffiton", "M.D. Moffitt", "M.E. Pollack", "K.A. Sakallah" ],
      "venue" : "IJCAI. pp. 205–211. Professional Book Center",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Fast, flexible MUS enumeration",
      "author" : [ "M.H. Liffiton", "A. Previti", "A. Malik", "J. Marques-Silva" ],
      "venue" : "Constraints pp. 1–28",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Algorithms for computing minimal unsatisfiable subsets of constraints",
      "author" : [ "M.H. Liffiton", "K.A. Sakallah" ],
      "venue" : "Journal of Automated Reasoning 40(1), 1–33",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "AMUSE: a minimally-unsatisfiable subformula extractor",
      "author" : [ "Y. Oh", "M.N. Mneimneh", "Z.S. Andraus", "K.A. Sakallah", "I.L. Markov" ],
      "venue" : "DAC. pp. 518–523. ACM",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Partial MUS enumeration",
      "author" : [ "A. Previti", "J. Marques-Silva" ],
      "venue" : "Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence, July 14-18, 2013, Bellevue, Washington, USA. AAAI Press",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Extracting small unsatisfiable cores from unsatisfiable boolean formula",
      "author" : [ "L. Zhang", "S. Malik" ],
      "venue" : "SAT 3",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Enumerating multiple MUSes is sometimes desirable: in requirements analysis, this gives better insight into the inconsistencies among requirements; in CEGAR-based model checking more MUSes lead to a better refinement that can reduce the complexity of the whole procedure [1].",
      "startOffset" : 271,
      "endOffset" : 274
    }, {
      "referenceID" : 14,
      "context" : "For example all of [15,6,17] uses information from a satisfiability solver to obtain an unsatisfiable subset but they do not guarantee its minimality.",
      "startOffset" : 19,
      "endOffset" : 28
    }, {
      "referenceID" : 5,
      "context" : "For example all of [15,6,17] uses information from a satisfiability solver to obtain an unsatisfiable subset but they do not guarantee its minimality.",
      "startOffset" : 19,
      "endOffset" : 28
    }, {
      "referenceID" : 16,
      "context" : "For example all of [15,6,17] uses information from a satisfiability solver to obtain an unsatisfiable subset but they do not guarantee its minimality.",
      "startOffset" : 19,
      "endOffset" : 28
    }, {
      "referenceID" : 8,
      "context" : "Explicit checking The first algorithm for enumerating all MUSes we are aware of was developed by Hou [9] in the field of diagnosis and is built on explicit enumeration of every subset of the unsatisfiable constraint system.",
      "startOffset" : 101,
      "endOffset" : 104
    }, {
      "referenceID" : 7,
      "context" : "Further improvements to this approach were made by Han and Lee [8] and also by de la Banda et.",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 2,
      "context" : "[3].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 13,
      "context" : "CAMUS A state-of-the-art algorithm for enumerating all MUSes called CAMUS by Liffiton and Sakallah [14] is based on the relationship between MUSes and the so-called minimal correction sets (MCSes), which was independently pointed out by [2,5,12].",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 1,
      "context" : "CAMUS A state-of-the-art algorithm for enumerating all MUSes called CAMUS by Liffiton and Sakallah [14] is based on the relationship between MUSes and the so-called minimal correction sets (MCSes), which was independently pointed out by [2,5,12].",
      "startOffset" : 237,
      "endOffset" : 245
    }, {
      "referenceID" : 4,
      "context" : "CAMUS A state-of-the-art algorithm for enumerating all MUSes called CAMUS by Liffiton and Sakallah [14] is based on the relationship between MUSes and the so-called minimal correction sets (MCSes), which was independently pointed out by [2,5,12].",
      "startOffset" : 237,
      "endOffset" : 245
    }, {
      "referenceID" : 11,
      "context" : "CAMUS A state-of-the-art algorithm for enumerating all MUSes called CAMUS by Liffiton and Sakallah [14] is based on the relationship between MUSes and the so-called minimal correction sets (MCSes), which was independently pointed out by [2,5,12].",
      "startOffset" : 237,
      "endOffset" : 245
    }, {
      "referenceID" : 10,
      "context" : "MARCO The desire to enumerate at least some MUSes even in the generally intractable cases led to the development of two independent but nearly identical algorithms: MARCO [11] and eMUS [16].",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 15,
      "context" : "MARCO The desire to enumerate at least some MUSes even in the generally intractable cases led to the development of two independent but nearly identical algorithms: MARCO [11] and eMUS [16].",
      "startOffset" : 185,
      "endOffset" : 189
    }, {
      "referenceID" : 12,
      "context" : "Both algorithms were later joined and presented in [13] under the name of MARCO.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 12,
      "context" : "CAMUS and MARCO were experimentally compared in [13] and the former has shown to be faster in enumerating all MUSes in the tractable cases.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 1,
      "context" : "One another algorithm, the Dualize and Advance (DAA) by Bailey and Stuckey [2] was also evaluated in these experiments.",
      "startOffset" : 75,
      "endOffset" : 78
    }, {
      "referenceID" : 6,
      "context" : "One of the SAT solvers that satisfies our requirements is miniSAT [7] that allows the user to fix values of some variables and to select a default polarity of variables at decision points during solving.",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 3,
      "context" : "These simple variants serve just as illustrations, there are known efficient implementations of both shrink and grow for specific constraint domains; as an example see MUSer2 [4] which implements the shrink method for Boolean constraints systems.",
      "startOffset" : 175,
      "endOffset" : 178
    }, {
      "referenceID" : 12,
      "context" : "We also give a comparison with MARCO algorithm [13].",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 12,
      "context" : "The pseudocodes of both variants can be found in [13].",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 6,
      "context" : "As both the SAT solver and constraint solver we used the miniSAT tool [7] and we used the simple implementation of the shrink and grow methods as described earlier.",
      "startOffset" : 70,
      "endOffset" : 73
    }, {
      "referenceID" : 9,
      "context" : "We used the generator of Boolean CNF formulae from [10] to generate tractable instances with a size of 30 to 40 constraints, 15 instances per each size.",
      "startOffset" : 51,
      "endOffset" : 55
    } ],
    "year" : 2016,
    "abstractText" : "In various areas of computer science, the problem of dealing with a set of constraints arises. If the set of constraints is unsatisfiable, one may ask for a minimal description of the reason for this unsatisifiability. Minimal unsatisfiable subsets (MUSes) and maximal satisfiable subsets (MSSes) are two kinds of such minimal descriptions. The goal of this work is the enumeration of MUSes and MSSes for a given constraint system. As such full enumeration may be intractable in general, we focus on building an online algorithm, which produces MUSes/MSSes in an on-the-fly manner as soon as they are discovered. The problem has been studied before even in its online version. However, our algorithm uses a novel approach that is able to outperform the current state-of-the art algorithms for online MUS/MSS enumeration. Moreover, the performance of our algorithm can be adjusted using tunable parameters. We evaluate the algorithm on a set of benchmarks.",
    "creator" : "LaTeX with hyperref package"
  }
}