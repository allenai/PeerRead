{
  "name" : "1706.02179.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Learning to Represent Mechanics via Long-term Extrapolation and Interpolation",
    "authors" : [ "Sébastien Ehrhardt", "Aron Monszpart", "Andrea Vedaldi", "Niloy Mitra" ],
    "emails" : [ "vedaldi}@robots.ox.ac.uk", "n.mitra}@cs.ucl.ac.uk" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Animals can make remarkably accurate and fast predictions of physical phenomena in order to perform activities such as navigate, prey, or burrow. However, the nature of the mental models used to perform such predictions remains unclear and is still actively researched [9].\nIn contrast, science has developed an excellent formal understanding of physics; for example, mechanics is nearly perfectly described by Newtonian physics. While the constituent laws are simple and accurate, applying them to the description of a physical scenario is anything but trivial. First, the scenario needs to be abstracted (e.g., by segmenting the scene into rigid objects, estimating physical parameters such as mass, linear and angular velocity, etc., deciding which equations to apply, and so on). Then, prediction still requires the numerical integration of complex systems of equations. It is unlikely that this is the process of mental modeling followed by natural intelligences.\nIn an effort to develop model of physics that are more suitable for artificial intelligence, several authors have looked at the problem of learning physical predictors using deep neural networks. As a notable example, the recent Neural Physics Engine (NPE) [5] uses a neural network to learn the state transition function of mechanical systems. The state itself is handcrafted and includes physical parameters such as positions, velocities, and masses of rigid bodies. While this approach works well, a limitation is that it does not allow the network to learn its own abstraction of the physical system. This may prevent the model from learning efficient approximations of physics that are likely required to scale to complex real-world scenarios.\nIn this work, we ask whether a representation of the physical state of a mechanical system can be learned implicitly by a neural network, and whether this can be used to perform more accurate\nar X\niv :1\n70 6.\n02 17\n9v 2\n[ cs\n.C V\n] 8\nJ un\npredictions. Compared to methods such as NPE, learning such a model is more challenging as no direct observations of the state of the system are available for training. Instead, the state is a hidden variable that must be inferred while solving a task for which supervision can be provided. As an example of such a task, we consider here the problem of long-term physical extrapolation.\nOur approach to extrapolation is to develop a recurrent neural network architecture that not only contains an implicit representation of the state of the system, but is also able to evolve it through time. This differs from methods such as NPE that predict instantaneous variations of the system state, which are integrated in long-term predictions a-posteriori, after learning is complete. We show that accounting for the integration process during learning allows the network to learn an implicit representation of physics. Furthermore, we show that, in relatively complex physical setups, the resulting predictions can be competitive to a modified version of NPE, even when the inputs to the extrapolator are visual observations of the physical system instead of a direct knowledge of its initial state.\nSince physical extrapolation is inherently ambiguous, we allow the model to explicitly estimate its prediction uncertainty by estimating the variance of a Gaussian observation model. We show that this modification further improves the quality of long-term predictions.\nEmpirically, we push our model by considering scenarios beyond the “flat” ones considered in most recent papers, such as objects sliding on planes and colliding, and look for the first time at the case of an object rolling on a non-trivial 3D shape, namely a bowl of varying shape and orientation, where both linear and angular momenta are tightly coupled.\nAs a final benefit of learning with long-term physical predictions, we show that our model is able, with minimal modifications, to learn not only to extrapolate physical trajectories, but also to interpolate them. Remarkably, interpolation is still obtained by computing the trajectory in a feed-forward manner, from the first to the last time step.\nThe rest of the paper is organized as follows. The relation of our work to the literature is discussed in section 2. The detailed structure of the proposed neural networks is given and motivated in section 3. These networks are extensively evaluated on a large dataset of simulated physical experiments in section 5. A summary of our finding can be found in section 6."
    }, {
      "heading" : "2 Related work",
      "text" : "In this work we address the problem of long-term prediction from observation in a physical environment without voluntary perturbation, which is done by an implicit learning of physical laws. Our work is closely related to a range of recent works in the machine learning community.\nLearning intuitive physics. To the best of our knowledge [4] was the first approach to tackle intuitive physics with the aim to answer a set of intuitive questions (e.g., will it fall?) using physical simulations. Their simulations, however, used a sophisticated physics engine that incorporates prior knowledge about Newtonian physical equations. More recently [17] also used static images and a graphics rendering engine (Blender) to predict movements and directions of forces from a single RGB image. Motivated by the recent success of deep learning for image processing (e.g., [12, 10]), they used a convolutional architecture to understand dynamics and forces acting behind the scenes from a static image and produced a “most likely motion\" rendered from a graphics engine. In a different framework, [14] and [15] also used the power of deep learning to extract an abstract representation of the concept of stability of block towers purely from images. These approaches successfully demonstrated that not only was a network able to accurately predict the stability of the block tower but in addition, it could identify the source of the instability. Other approaches such as [2] or [7] also attempted to learn intuitive physics of objects through manipulation. These approaches, however, do not attempt to precisely model the evolution of the physical world.\nLearning dynamics. Learning the evolution of an object’s position also implies to learn about the object’s dynamics regardless of any physical equations. While most successful techniques used LSTM-s [11], recent approaches show that propagation can also be done using a single crossconvolution kernel. The idea was further developed in [27] in order to generate a next possible image frame from a single static input image. The concept has been shown to have promising performance regarding longer term predictions on the moving MNIST dataset in [6]. The work of [19] also shows that an internal hidden state can be propagated through time using a simple deep recurrent architecture.\nThese results motivated us to propagate tensor based state representations instead of a single vector representation using a series of convolutions. Adversarial losses have also been used in [18] which shows good results in video segmentation. In the future we also aim to experiment with approaches inspired by [27].\nLearning physics. The works of [26] and its extension [25] propose methods to learn physical properties of scenes and objects. However, in [26] the MCMC sampling based approach assumes the complete knowledge of the physical equations to estimate the correct physical parameters. In [25] deep learning has been used more extensively to replace the MCMC based sampling but this work also employs an explicit encoding and computation of physical laws to regress the output of their tracker. [22] also used physical laws to predict the movement of a pillow from unlabelled data though their approach was only applied to a fixed number of frames.\nIn another related approach [8] attempted to build an internal representation of the physical world. Using a billiard board with an external simulator they built a network which observing four frames and an applied force, was able to predict the 20 next object velocities. Generalization in this work was made using an LSTM in the intermediate representations. The process can be interpreted as iterative since frame generation is made to provide new inputs to the network. This can also be seen as a regularization process to avoid the internal representation of dynamics to decay over time which is different to our approach in which we try to build a stronger internal representation that will attempt to avoid such decay.\nOther research attempted to abstract the physics engine enforcing the laws of physics as neural network models. [3] and [5] were able to produce accurate estimations of the next state of the world. Although the results look plausible and promising, reported results show in [5] that accurate long-term predictions are still difficult. Note, that their process is an iterative one as opposed to ours, which propagates an internal state of the world through time similarly to [20].\nApproximate physics with realistic output. Other approaches also focused on learning to generate realistic future scenarios ([24] and [13]), or inferring collision parameters from monocular videos [16]. In these approaches the authors used physics based losses to produce visually plausible yet erroneous results. They however show promising results and constructed new losses taking into account additional physical parameters other than velocity. Note also that in [3] an energy-based loss has been used. It can be seen as a way to explicitly incorporate a knowledge of physics in the network while we aim to understand if we can make accurate prediction without explicit physics knowledge."
    }, {
      "heading" : "3 Method",
      "text" : "In this section, we propose a new neural network model (see Fig. 1) that performs predictions in mechanical systems. Let yt be a vector of physical measurements taken at time t, such as the position of an object whose motion we would like to track. Physical systems satisfy a Markov condition, in the sense that there exists a state vector ht such that 1) measurements yt = g(ht) can be predicted from the value of the state and 2) the state at the next time step ht+1 = f(ht) depends only on the current value of the state ht. Uncertainty in the model can be encoded by means of transition p(ht+1|ht) and observation p(yt|ht) probabilities, resulting in a hidden Markov model. Approaches such as NPE [5] start from an handcrafted definition of the state ht. For instance, in order to model a scenario with two balls colliding, one may choose ht to contain the position and velocity of each ball. In this case, the observation function g may be as simple as extracting the position components from the state vector. The goal of NPE is then to learn a neural network approximator φ of the transition function f . In practice, the authors of [5] suggest that it is often easier to predict a rate of change ∆t for some of the physical parameters (e.g. the balls’ velocities), which can then be integrated to update the state: ht+1 = f̃(ht,∆t) where f̃ is an hand-crafted integrator and the neural predictor estimates the change ∆t = φ(ht).\nWhile these approaches have several advantages [5], there are several limitations too. First, approaches such as NPE require to handcraft the state representation ht. Even in the simple case of the colliding balls, the choice of state is ambiguous; for example, one could include in the state the radius, mass and elasticity and friction coefficients. In more complex situations, choosing a good state representation may be rather difficult. Overall, this choice is best left to learning. Second, the state must be observable during training in order to learn the transition function. Third, learning does not account\nfor the effect of accumulating errors through integration as integration is applied only after learning. Finally, the initial value of the state h0 must be known in order to initialize the predictor, whereas in many applications one would like to start from sensory inputs xt such as images of the physical system [8].\nWe propose here an approach to address these difficulties. We assume that the state ht is a hidden variable, to be determined as part of the learning process. Since the ht cannot be observed, the transition function ht+1 = f(ht) cannot be estimated directly as in the NPE. Instead, it must be inferred as a good explanation of the physical measurements yt. Since the evolution of the state ht cannot be learned by observing measurement yt in isolation, we supervise the system by explaining sequences y[0,T ) = (y0, . . . , yT−1). This requires to move the integration step inside the network, which we do by mean of a recurrent neural network architecture. This has the added advantage of making learning aware of the integration process, which helps improving accuracy.\nThe model is analogous to a Hidden Markov Model. Recall that such models are often learned by maximizing the likelihood of the observations after marginalizing the hidden state.1 However, since we are interested in extrapolating future observations from past ones, we consider instead long-term extrapolation as supervisory signal. In order to do so we learn: 1) a transition function ht+1 = φ(ht) that evolves the state through time, 2) a decoder function that maps the state ht to an observation yt = φdec(ht), and 3) an encoder function that estimates the state ht = φenc(x(t−T0,t]) from the T0 most recent sensor readings (alternatively ht = φenc(y(t−T0,t]) can use the T0 most recent observations).\nIn the experiments (section 5) we will show that the added flexibility of learning an internal state representation automatically can still provide a good prediction accuracy even when the complexity of the physical scenarios increases. The rest of the section discusses the three modules, encoder, transition, and decoder maps, as well as the loss function used for training. Further technical details can be found in section 5.\n(i) Encoder map: from images to state. The goal of the encoder map is to take T0 consecutive video frames recording the beginning of the object motion and to produce an estimate h0 = φenc(x(−T0,0])\n1 Formally, the Markov model is given by p(y[0,T )],h[0,T )) = p(h0)p(y0|h0) ∏T−2 t=0 p(ht+1|ht)p(yt+1|ht+1); traditionally, p can be learned as the maximizer of the log-likelihood maxp Ey[logEh[p(y,h)]], where we dropped the subscripts for compactness. Learning to interpolate/extrapolate can be done by considering subsets ȳ ⊂ y of the measurements as given and optimizing the likelihood of the conditional probability maxp Ey[logEh[p(y,h|ȳ)]].\nof the initial state of the physical system. In order to build this encoder, we follow [8] and concatenate the RGB channels of the T0 images in a single Hi×Wi× 3T0. The latter is passed to a convolutional neural network φenc outputting a feature tensor s0 ∈ RH×W×C , used as internal representation of the system. We also add to the state a vector p0 ∈ R2 to store the 2D projection of the object location on the image plane, so that ht = (st, pt).\n(ii) Transition map: evolving the state. The state ht is evolved through time by learning the transition function φ : ht 7→ ht+1, where h0 is obtained from the encoder map, so that ht = φt(φenc(x(−T0,0])). The state st is updated by using a convolutional network st+1 = φs(st) whereas pt is updated incrementally as pt+1 = pt + φp(st), where φp(st) is estimated using a single layer perceptron regressor. Hence (st+1, pt+1) = φ(st, pt) = (φs(st), pt + φp(st)). We found that explicitly incorporating an additive update significantly improves the performance of the model.\n(iii) Decoder map: from state to probabilistic predictions. Since we added for convenience the projected object position pt to the state, the decoder map ŷt = φdec(st, pt) = pt simply extracts and returns that part of the state. Training optimizes the average L2 distance between ground truth yt and predicted ŷt positions 1T ∑T−1 t=0 ‖ŷt − yt‖2.\nSince extrapolation is inherently ambiguous, the L2 prediction error increases with time, which may unbalance learning. In order to address this issue, we allow the model to explicitly and dynamically express its prediction uncertainty by outputting the mean and variance (µt,Σt) of a bivariate Gaussian observation model. The L2 loss is then replaced with the negative log likelihood − 1T ∑T−1 t=0 logN (yt;µt,Σt).\nIn order to estimate µt and Σt, the incremental state component pt = (µt, λ1,t, λ2,t, θt) is extended to include both the mean as well as the eigenvalues and rotation of the variance matrix Σt = R(θt)\n> diag(λ1,t, λ2,t)R(θt). In order to ensure numerical stability, eigenvalues are constrained to be in the range [0.01 . . . 100] by setting them as the output of a scaled and translated sigmoid λi,t = σλ,α(βi,t), where σλ,α(z) = λ/(1 + exp(−z)) + α."
    }, {
      "heading" : "4 Experimental setup",
      "text" : "In our experimental setup (Fig. 2), we consider a sphere rolling inside a 3D (bowl) surface. When the bowl is a hemisphere we refer to the setup as ‘Bowl,’ and in the more general case as ‘Ellipse’ (see Table 1).\nWe use p = (px, py, pz) ∈ R3 to denote a point in 3D space or a vector (direction). The camera center is placed at location (0, 0, cz), cz > 0 and looks downward along vector (0, 0,−1) using orthographic projection such that the point (px, py, pz) projects to a pixel (px, py) in the image.\nWe model the bowl as the bottom half of an ellipsoid given by x2/a2 + y2 + (z − 1)2 = 1 with its axes aligned to the XYZ axes and its bottom point being at the origin. We vary the ellipsoid\nshape by sampling a ∈ U [0.5, 1] for the ‘Ellipse’ case and setting a = 1 (i.e., a hemisphere) for the ‘Bowl’ case. The bowl is given a checker board pattern. Finally, the bowl is given a random rotation γ ∈ U [−π/2, π/2] only about the z-axis to randomly orient it. We consider a rolling object in the form of a ball with radius ρ = 0.04 with its center of mass at time t being located at qt = (qtx, q t y, q t z), so that its center of mass is imaged at pixel (q t x, q t y) at any time t. The ball has a fixed color texture attached to its surface, so it appears as a painted object. We initially position the ball at angles (θ, φ) with respect to the the bowl center, where the elevation θ is uniformly sampled in the range θ ∈ U [−9π/10,−π/2] and the azimuth φ ∈ U [−π, π]. We set the minimum elevation to −9π/10 to avoid starting the ball at the bottom of the bowl. In the end, the ball will be resting on the bowl surface. The ball is either textured with random color patches or uniformly colored in white in order to study the impact of observing the ball rotation.\nWe set the initial orientation of the ball by uniformly sampling its xyz Euler angles in [−π, π]. We set its initial velocity v by first sampling vx, vy uniformly in the range [5, 10], assigning each of vx, vy a random sign, and then projecting vector (vx, vy, 0) so that the resulting velocity vector is tangential to the underlying supporting bowl.\nNote that, while several parameters of the ball state are included in the observation vector yα[−T0,T ), these are not part of the state of the neural network, which is inferred automatically. The network itself is tasked with predicting part of these measurements, but their meaning is not hardcoded.\nSimulation setup. For efficiency, we extract multiple sub-sequences xα[−T0,T ) form a single longer simulation (training, test, and validation sets are completely independent). The simulator runs at 120fps for accuracy, but the data is subsampled to 40fps. We use Blender 2.77’s OpenGL renderer and the Blender Game Engine (relying on Bullet 2 as physics engine). The ball is a textured sphere with unit mass. We found that changing the friction parameter of the bowl or the ball does not influence the motion. Therefore, we added translation and rotation damping (both set to 0.1 in Blender) to the sphere’s animation properties in order to simulate energy loss due to friction. The simulation parameters were set as: max physics steps = 5, physics substeps = 3, max logic steps = 5, FPS = 120. Rendering used white environment lighting (energy = 0.7) and no other light source. The object color was set to a colored checkerboard texture in order to enable the visual perception of rotation. We used 70% the data for training, 15% for validation, and 15% for test. During training we start observation at a random time while it is fixed for test. The output images were stored as 128× 128 color JPEG files."
    }, {
      "heading" : "5 Experiments",
      "text" : ""
    }, {
      "heading" : "5.1 Baselines",
      "text" : "Least squares fit. We compare the performance of our methods to two simple least squares baselines: Linear and Quadratic. In both cases we fit two least squares polynomials to the screen-space coordinates of the first T = 10 frames, which are not computed but rather given as inputs. The polynomials are of first and second degree(s), respectively. Note, that being able to observe the first 10 frames is a large advantage compared to the networks, which only see the first T0 = 4 frames.\nNPE. NPE [5] training was done using available online code. We used the same training procedure as reported in [5]. NPE++ additionally takes angle and angular velocities as parameters and also predicts angular velocity. In the case of the elliptic bowl, both scaling and bowl rotation angle are given as input to the networks. In this case NPEs methods carry forward the estimated states via the network.\nWhile the previously mentioned methods start from state inputs, note that our models work with raw images as direct observation of the world. Physical properties are then deduced from the observation and then integrated through our Markov model. Thus we do not need a simulator to estimate parameters of the physical worlds (such as scaling and rotation angle in the NPE case) and can train our model on changing environment without requiring additional external measurements of the underlying 3D spaces."
    }, {
      "heading" : "5.2 Results",
      "text" : "Implementation details. The encoder network φenc is obtained by taking the ImageNet-pretrained VGG16 network [21] and retaining the layers up to conv5 (for an input image of size (Hi,Wi) = (128, 128, 3) this results in a (8, 8, 512) state tensor st). The filter weights of all layers except conv1 are retained for fine-tuning on our problem. conv1 is reinitialized as filters must operate on images with 3T0 channels. The transition network φs(st) uses a simple chain of two convolution layers (with 256 and 512 filters respectively, of size 3× 3, stride 1, and padding 1 interleaved by a ReLU layer. Network weights are initialized by sampling from a Gaussian distribution.\nTraining uses a batch size of 50 using the first 20 or 40 positions (and angular velocity when explicitly mentioned) of each video sequence using RMSProp [23]. In our methods we start with a learning rate of 10−5 and decrease learning rates by a factor of 10 when no improvements of the L2 position loss have been found after 100 consecutive epochs. Training is halted when the L2 loss hasn’t decreased after 200 successive epochs; 2,000 epochs were found to be usually sufficient for convergence. Note here than in every cases where we estimate the angular velocity the corresponding L2 loss on the latter is simply added to the network’s existing loss.\nSince during the initial phases of training the network is very uncertain, the model using the Gaussian log-likelihood loss was found to get stuck on solutions with very high variance Σ(t); to solve this issue, the regularizer λ ∑ t det Σ(t) was added to the loss, setting λ = 0.01.\nIn all our experiments we used Tensorflow [1] r0.12 on a single NVIDIA Titan X GPU. In the following we will refer to our model that has been trained optimizing on the L2 loss over positions as PhysNet otherwise ProbNet for log-likelihhod loss. When also predicting angular velocities the suffix ‘++’ is added to the name of the model.\nExtrapolation. Table 1 and Fig. 3 compare the baseline predictors and the four networks on the task of long term prediction of the object trajectory. All methods observed only the first T0 = 4 inputs (whether frames or object states) except for the linear and quadratic baselines, and aimed to extrapolate the trajectory to 40 time steps. In that sense predictions can be seen as ”long terms” relative to the number of inputs.\nTable 1 reports the average L2 errors at time Ttest = 20 and 40 for the different estimated parameters. However all of the methods can perform arbitrary long predictions. In particular our methods are only trained to predict 20 first positions and reveal to be still competitive with NPEs methods at T = 40.\nOur networks perform reasonably well compared to the NPEs methods using only images as inputs. In our scenario we can see the different NPEs as upper limits of our experiments since they do have access to the state space (complete or not). Furthermore adding angular velocity has shown to improve performances of our models while it decreases the accuracy of the NPE++ predictions in that case. Besides probability based losses show that our models were also able to predict uncertainty in its outputs even in the case of unobserved scenarios.\nIn addition training on a dataset where angular velocity was not explicitly seen (Ellipse no-texture in Table 1) shows that our models can still provide encouraging results in that case. It managed to accurately deduce angular velocity without seeing the ball spinning.\nInterpolation. In order to remove ambiguity of a short term observed motion one can just indicates the final desired state. In this experiment we concatenate to the first T0 = 4 input frames the last frame observed at T = 40 and give it as an input to a model with the same architecture as PhysNet. This model was then trained using the same aforementioned method with the only difference that we also extract last positions from the first extracted feature. While this idea is fairly simple it shows to be very efficient in practice as shown in Table 2 as it efficiently removed the motion ambiguity."
    }, {
      "heading" : "6 Conclusions",
      "text" : "In this paper we studied the possibility of abstracting the knowledge of physics using a single neural network with a recurrent architecture for long term predictions. We compared our model to strong baselines on the non-trivial motion of a ball rolling on a 3D bowl with different possible shapes. As opposed to other concurrent approaches we do not integrate physical quantities but implicitly encode the states in a feature vector that we can propagate through time.\nOur experiments on synthetic simulations indicate that we can still make reasonable predictions without requiring an explicit encoding of the state space. Besides they are also able to estimate a distribution over such parameters to account for uncertainty in the predictions. While keeping the same architecture we also show that we were able to remove motion ambiguity by showing the network its targeted final states. However, the internal state propagation mechanism is still limited by its ability to make accurate long term predictions outside observed regimes.\nIn the future we will aim to bring more robustness to our models by enforcing invariance to observed regimes to enable longer accurate predictions. Besides, a next obvious step will also be to test the framework on video footage obtained from real-world data in order to assess the ability to do so from visual data affected by real nuisance factors."
    } ],
    "references" : [ {
      "title" : "TensorFlow: Large-scale machine learning on heterogeneous systems",
      "author" : [ "Abadi" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2015
    }, {
      "title" : "Learning to Poke by Poking: Experiential Learning of Intuitive Physics",
      "author" : [ "Pulkit Agrawal", "Ashvin V Nair", "Pieter Abbeel", "Jitendra Malik", "Sergey Levine" ],
      "venue" : "In Proc. NIPS,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2016
    }, {
      "title" : "Interaction networks for learning about objects, relations and physics",
      "author" : [ "Peter Battaglia", "Razvan Pascanu", "Matthew Lai", "Danilo Jimenez Rezende" ],
      "venue" : "In Proc. NIPS,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2016
    }, {
      "title" : "Simulation as an engine of physical scene understanding",
      "author" : [ "Peter W Battaglia", "Jessica B Hamrick", "Joshua B Tenenbaum" ],
      "venue" : "PNAS, 110(45):18327–18332,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "A compositional object-based approach to learning physical dynamics",
      "author" : [ "Michael B Chang", "Tomer Ullman", "Antonio Torralba", "Joshua B Tenenbaum" ],
      "venue" : "arXiv preprint arXiv:1612.00341,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2016
    }, {
      "title" : "Dynamic filter networks",
      "author" : [ "Bert De Brabandere", "Xu Jia", "Tinne Tuytelaars", "Luc Van Gool" ],
      "venue" : "In Proc. NIPS,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2016
    }, {
      "title" : "Learning to perform physics experiments via deep reinforcement learning",
      "author" : [ "Misha Denil", "Pulkit Agrawal", "Tejas D Kulkarni", "Tom Erez", "Peter Battaglia", "Nando de Freitas" ],
      "venue" : "Deep Reinforcement Learning Workshop,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2016
    }, {
      "title" : "Learning visual predictive models of physics for playing billiards",
      "author" : [ "Katerina Fragkiadaki", "Pulkit Agrawal", "Sergey Levine", "Jitendra Malik" ],
      "venue" : "arXiv preprint arXiv:1511.07404,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2015
    }, {
      "title" : "Inferring mass in complex scenes by mental",
      "author" : [ "J.B. Hamrick", "P.W. Battaglia", "T.L. Griffiths", "J.B. Tenenbaum" ],
      "venue" : "simulation. Cognition,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2016
    }, {
      "title" : "Deep residual learning for image recognition",
      "author" : [ "Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun" ],
      "venue" : "In IEEE CVPR,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2016
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber" ],
      "venue" : "Neural Comput.,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1997
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton" ],
      "venue" : "In Proc. NIPS,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2012
    }, {
      "title" : "Datadriven fluid simulations using regression forests",
      "author" : [ "Ladický", "Jeong", "SoHyeon", "Barbara Solenthaler", "Marc Pollefeys", "Markus Gross" ],
      "venue" : "ACM Trans. on Graphics (TOG),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2015
    }, {
      "title" : "Learning physical intuition of block towers by example",
      "author" : [ "Adam Lerer", "Sam Gross", "Rob Fergus" ],
      "venue" : "arXiv preprint arXiv:1603.01312,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2016
    }, {
      "title" : "Visual stability prediction and its application to manipulation",
      "author" : [ "Wenbin Li", "Aleš Leonardis", "Mario Fritz" ],
      "venue" : "arXiv preprint arXiv:1609.04861,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2016
    }, {
      "title" : "SMASH: Physics-guided Reconstruction of Collisions from Videos",
      "author" : [ "Aron Monszpart", "Nils Thuerey", "Niloy Mitra" ],
      "venue" : "ACM Trans. on Graphics (TOG),",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2016
    }, {
      "title" : "Newtonian scene understanding: Unfolding the dynamics of objects in static images",
      "author" : [ "Roozbeh Mottaghi", "Hessam Bagherinezhad", "Mohammad Rastegari", "Ali Farhadi" ],
      "venue" : "In IEEE CVPR,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2016
    }, {
      "title" : "Predicting deeper into the future of semantic segmentation",
      "author" : [ "Natalia Neverova", "Pauline Luc", "Camille Couprie", "Jakob Verbeek", "Yann LeCun" ],
      "venue" : "arXiv preprint arXiv:1703.07684,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2017
    }, {
      "title" : "Deep tracking: Seeing beyond seeing using recurrent neural networks",
      "author" : [ "Peter Ondruska", "Ingmar Posner" ],
      "venue" : "In Proc. AAAI,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2016
    }, {
      "title" : "The predictron: End-to-end learning and planning",
      "author" : [ "David Silver", "Hado van Hasselt", "Matteo Hessel", "Tom Schaul", "Arthur Guez", "Tim Harley", "Gabriel Dulac-Arnold", "David Reichert", "Neil Rabinowitz", "André Barreto", "Thomas Degris" ],
      "venue" : "CoRR, abs/1612.08810,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2016
    }, {
      "title" : "Very deep convolutional networks for large-scale image recognition",
      "author" : [ "K. Simonyan", "A. Zisserman" ],
      "venue" : "In International Conference on Learning Representations,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2015
    }, {
      "title" : "Label-free supervision of neural networks with physics and domain knowledge",
      "author" : [ "Russell Stewart", "Stefano Ermon" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2016
    }, {
      "title" : "Lecture 6.5—RMSProp: Divide the gradient by a running average of its recent magnitude",
      "author" : [ "T. Tieleman", "G. Hinton" ],
      "venue" : "COURSERA: Neural Networks for Machine Learning,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2012
    }, {
      "title" : "Accelerating Eulerian Fluid Simulation With Convolutional Networks",
      "author" : [ "J. Tompson", "K. Schlachter", "P. Sprechmann", "K. Perlin" ],
      "venue" : "ArXiv e-print",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2016
    }, {
      "title" : "Physics 101: Learning physical object properties from unlabeled videos",
      "author" : [ "Jiajun Wu", "Joseph J Lim", "Hongyi Zhang", "Joshua B Tenenbaum", "William T Freeman" ],
      "venue" : "In Proc. BMVC,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2016
    }, {
      "title" : "Galileo: Perceiving physical object properties by integrating a physics engine with deep learning",
      "author" : [ "Jiajun Wu", "Ilker Yildirim", "Joseph J Lim", "Bill Freeman", "Josh Tenenbaum" ],
      "venue" : "In Proc. NIPS,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2015
    }, {
      "title" : "Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks",
      "author" : [ "Tianfan Xue", "Jiajun Wu", "Katherine L Bouman", "William T Freeman" ],
      "venue" : "In Proc. NIPS,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "However, the nature of the mental models used to perform such predictions remains unclear and is still actively researched [9].",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 4,
      "context" : "As a notable example, the recent Neural Physics Engine (NPE) [5] uses a neural network to learn the state transition function of mechanical systems.",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 3,
      "context" : "To the best of our knowledge [4] was the first approach to tackle intuitive physics with the aim to answer a set of intuitive questions (e.",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 16,
      "context" : "More recently [17] also used static images and a graphics rendering engine (Blender) to predict movements and directions of forces from a single RGB image.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 11,
      "context" : ", [12, 10]), they used a convolutional architecture to understand dynamics and forces acting behind the scenes from a static image and produced a “most likely motion\" rendered from a graphics engine.",
      "startOffset" : 2,
      "endOffset" : 10
    }, {
      "referenceID" : 9,
      "context" : ", [12, 10]), they used a convolutional architecture to understand dynamics and forces acting behind the scenes from a static image and produced a “most likely motion\" rendered from a graphics engine.",
      "startOffset" : 2,
      "endOffset" : 10
    }, {
      "referenceID" : 13,
      "context" : "In a different framework, [14] and [15] also used the power of deep learning to extract an abstract representation of the concept of stability of block towers purely from images.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 14,
      "context" : "In a different framework, [14] and [15] also used the power of deep learning to extract an abstract representation of the concept of stability of block towers purely from images.",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 1,
      "context" : "Other approaches such as [2] or [7] also attempted to learn intuitive physics of objects through manipulation.",
      "startOffset" : 25,
      "endOffset" : 28
    }, {
      "referenceID" : 6,
      "context" : "Other approaches such as [2] or [7] also attempted to learn intuitive physics of objects through manipulation.",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 10,
      "context" : "While most successful techniques used LSTM-s [11], recent approaches show that propagation can also be done using a single crossconvolution kernel.",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 26,
      "context" : "The idea was further developed in [27] in order to generate a next possible image frame from a single static input image.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 5,
      "context" : "The concept has been shown to have promising performance regarding longer term predictions on the moving MNIST dataset in [6].",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 18,
      "context" : "The work of [19] also shows that an internal hidden state can be propagated through time using a simple deep recurrent architecture.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 17,
      "context" : "Adversarial losses have also been used in [18] which shows good results in video segmentation.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 26,
      "context" : "In the future we also aim to experiment with approaches inspired by [27].",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 25,
      "context" : "The works of [26] and its extension [25] propose methods to learn physical properties of scenes and objects.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 24,
      "context" : "The works of [26] and its extension [25] propose methods to learn physical properties of scenes and objects.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 25,
      "context" : "However, in [26] the MCMC sampling based approach assumes the complete knowledge of the physical equations to estimate the correct physical parameters.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 24,
      "context" : "In [25] deep learning has been used more extensively to replace the MCMC based sampling but this work also employs an explicit encoding and computation of physical laws to regress the output of their tracker.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 21,
      "context" : "[22] also used physical laws to predict the movement of a pillow from unlabelled data though their approach was only applied to a fixed number of frames.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 7,
      "context" : "In another related approach [8] attempted to build an internal representation of the physical world.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 2,
      "context" : "[3] and [5] were able to produce accurate estimations of the next state of the world.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[3] and [5] were able to produce accurate estimations of the next state of the world.",
      "startOffset" : 8,
      "endOffset" : 11
    }, {
      "referenceID" : 4,
      "context" : "Although the results look plausible and promising, reported results show in [5] that accurate long-term predictions are still difficult.",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 19,
      "context" : "Note, that their process is an iterative one as opposed to ours, which propagates an internal state of the world through time similarly to [20].",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 23,
      "context" : "Other approaches also focused on learning to generate realistic future scenarios ([24] and [13]), or inferring collision parameters from monocular videos [16].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 12,
      "context" : "Other approaches also focused on learning to generate realistic future scenarios ([24] and [13]), or inferring collision parameters from monocular videos [16].",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 15,
      "context" : "Other approaches also focused on learning to generate realistic future scenarios ([24] and [13]), or inferring collision parameters from monocular videos [16].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 2,
      "context" : "Note also that in [3] an energy-based loss has been used.",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 4,
      "context" : "Approaches such as NPE [5] start from an handcrafted definition of the state ht.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 4,
      "context" : "In practice, the authors of [5] suggest that it is often easier to predict a rate of change ∆t for some of the physical parameters (e.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 4,
      "context" : "While these approaches have several advantages [5], there are several limitations too.",
      "startOffset" : 47,
      "endOffset" : 50
    }, {
      "referenceID" : 7,
      "context" : "Finally, the initial value of the state h0 must be known in order to initialize the predictor, whereas in many applications one would like to start from sensory inputs xt such as images of the physical system [8].",
      "startOffset" : 209,
      "endOffset" : 212
    }, {
      "referenceID" : 7,
      "context" : "In order to build this encoder, we follow [8] and concatenate the RGB channels of the T0 images in a single Hi×Wi× 3T0.",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 4,
      "context" : "We set its initial velocity v by first sampling vx, vy uniformly in the range [5, 10], assigning each of vx, vy a random sign, and then projecting vector (vx, vy, 0) so that the resulting velocity vector is tangential to the underlying supporting bowl.",
      "startOffset" : 78,
      "endOffset" : 85
    }, {
      "referenceID" : 9,
      "context" : "We set its initial velocity v by first sampling vx, vy uniformly in the range [5, 10], assigning each of vx, vy a random sign, and then projecting vector (vx, vy, 0) so that the resulting velocity vector is tangential to the underlying supporting bowl.",
      "startOffset" : 78,
      "endOffset" : 85
    }, {
      "referenceID" : 4,
      "context" : "NPE [5] training was done using available online code.",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 4,
      "context" : "We used the same training procedure as reported in [5].",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 20,
      "context" : "The encoder network φenc is obtained by taking the ImageNet-pretrained VGG16 network [21] and retaining the layers up to conv5 (for an input image of size (Hi,Wi) = (128, 128, 3) this results in a (8, 8, 512) state tensor st).",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 22,
      "context" : "Training uses a batch size of 50 using the first 20 or 40 positions (and angular velocity when explicitly mentioned) of each video sequence using RMSProp [23].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 0,
      "context" : "In all our experiments we used Tensorflow [1] r0.",
      "startOffset" : 42,
      "endOffset" : 45
    } ],
    "year" : 2017,
    "abstractText" : "While the basic laws of Newtonian mechanics are well understood, explaining a physical scenario still requires manually modeling the problem with suitable equations and associated parameters. In order to adopt such models for artificial intelligence, researchers have handcrafted the relevant states, and then used neural networks to learn the state transitions using simulation runs as training data. Unfortunately, such approaches can be unsuitable for modeling complex real-world scenarios, where manually authoring relevant state spaces tend to be challenging. In this work, we investigate if neural networks can implicitly learn physical states of real-world mechanical processes only based on visual data, and thus enable longterm physical extrapolation. We develop a recurrent neural network architecture for this task and also characterize resultant uncertainties in the form of evolving variance estimates. We evaluate our setup to extrapolate motion of a rolling ball on bowl of varying shape and orientation using only images as input, and report competitive results with approaches that assume access to internal physics models and parameters.",
    "creator" : "LaTeX with hyperref package"
  }
}