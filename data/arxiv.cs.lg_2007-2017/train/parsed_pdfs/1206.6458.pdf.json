{
  "name" : "1206.6458.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Batch Active Learning via Coordinated Matching",
    "authors" : [ "Javad Azimi", "Alan Fern", "Xiaoli Z. Fern", "Glencora Borradaile" ],
    "emails" : [ "AZIMI@EECS.OREGONSTATE.EDU", "AFERN@EECS.OREGONSTATE.EDU", "XFERN@EECS.OREGONSTATE.EDU", "GLENCORA@EECS.OREGONSTATE.EDU", "HEERINGA@CS.WILLIAMS.EDU" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "In this paper, we consider active learning of classification functions. We are given an initial set of m labeled examples Dl = {(x1, y1), (x2, y2), . . . , (xm, ym)}, where yi is the target label for input xi. In addition, we are given a pool of n unlabeled inputs Du = {x1, x2, . . . , xn} for which the labels can be queried. The problem of active learning is to select the most informative examples (queries) from Du to be labeled, so that the accuracy of the classifier increases quickly as the set of labeled examples grows. Active learning typically works in iterations, where each iteration builds a classifier based on the current training set, and then selects the examples to be labeled. The labeled\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nexamples will then be added to the training set and this procedure is repeated until we reach a good model or we exceed the labeling budget. Much existing active learning work has focused on a sequential instance of this framework where one example is selected to be labeled in each iteration. A number of sequential active learning methods have been developed that yield substantial empirical gains over their passive learning counterparts, including simple strategies such as the minimum margin and maximum uncertainty principles (Settles, 2009).\nBatch active learning differs from sequential methods by selecting a batch of k > 1 examples to be labeled at each iteration (Hoi et al., 2006b; Brinker, 2003; Guo & Schuurmans, 2007). This batch-mode of active learning is often preferable to sequential methods when each label takes substantial time but can be produced in parallel. Such scenarios may arise when labels require running wet lab experiments, careful human analysis, or expensive computational processes.\nA naive approach to batch active learning is to simply apply an existing sequential selection rule k times to generate a batch, e.g. selecting the k minimum margin examples. This approach, however, will often perform poorly since it will tend to ignore redundancy among selected examples. To address this issue, there has been a small amount of work on batch active learning, which provides different heuristic approaches for incorporating batch diversity into the selection method. For example, Brinker (2003) introduced an SVM-based batch approach, which selects a batch that minimizes the margin of the selected examples while maximizing their diversity. Hoi et al. (2006b; 2006a) chose a batch of examples that effectively maximizes the Fisher information of a classification model, which leads to a trade-off between uncertainty and diversity. Guo and Schuurmans (2007) posed batch active learning as a complex optimization problem that maximizes the discrimina-\ntive classification performance while taking into consideration the unlabeled examples. Unfortunately the resulting optimization problem is non-convex and requires heuristic fixes involving many parameters to work effectively. Recently, Guo (2010) introduced an approach that selects a batch of examples that maximizes the mutual information between unlabeled and labeled examples. The proposed combinatorial optimization problem is NP-hard and a heuristic algorithm is introduced to produce a solution.\nThis paper considers a general approach for batch active learning, which we refer to as “simulation matching”. We are motivated by the observation that sequential methods are generally more example-efficient than their batch counterparts, since each example is selected with more information. Indeed in theory the best sequential strategy will never be worse than the best batch strategy, since one could simulate the batch approach and then select the examples sequentially. Leveraging the availability of highly-effective sequential active learning methods, we view a given sequential method as a gold-standard whose performance, in terms of label efficiency, we would like to approach using batch selection. That is, we aim to come close to the perexample accuracy improvement of the sequential method but in less time (fewer iterations) via batch selection.\nFor this purpose, we use Monte-Carlo simulation to estimate the posterior distribution over examples selected by the sequential method, and then select a batch of k examples that “best matches” this distribution. A key contribution of our work is to instantiate the notion of “best match” by developing a novel matching objective called bounded coordinated matching. While we show that optimizing the objective is NP-Hard, we introduce an efficient greedy algorithm that optimizes the objective with an approximation bound. Our proposed algorithm is simple to implement and its scalability in terms of the number of unlabeled examples is similar to the base sequential policy. Experiments on eight benchmark datasets with different batch sizes demonstrate that the proposed approach is highly effective."
    }, {
      "heading" : "2. Simulation Matching for Batch Selection",
      "text" : "Given a dataset Dl of labeled examples, we now consider how to select the next batch of k examples to be labeled. A key issue in making this choice is to manage the tradeoff between selecting examples that individually look most informative for learning versus selecting a diverse set of examples. For instance, a common measure of informativeness is the margin, or class uncertainty, of an example with respect to the currently learned classifier. However, picking the top k most informative examples under such measures will often select clusters of nearby examples that are quite redundant. Previous work on batch active learning has considered various objective functions for capturing this trade-\noff and then searches for batches that approximately optimize those objectives.\nIn this work, we follow a different approach motivated by the fact that sequential active learning has been widely studied and a variety of computationally efficient and empirically effective sequential policies exist. For example, selecting the example with highest class uncertainty is often a simple yet highly effective baseline approach. The main idea behind our batch approach is to leverage such sequential policies by selecting a batch of k > 1 samples that “closely matches” the sequential policy’s expected behavior. This idea has been explored recently for the very different problem of batch Bayesian optimization (Azimi et al., 2011). In that work, it was also the case that good sequential policies were available. However, since that work was focused on function optimization, the notion of “closely matching” used there is not suitable for active learning. The main contribution of our work is to develop a principled adaptation of the approach to batch active learning and to demonstrate its effectiveness."
    }, {
      "heading" : "2.1. Sequential Policy Simulation",
      "text" : "Let π be a sequential active learning policy. Given a set of labeled examplesDl and unlabeled examplesDu, π returns the next example x ∈ Du to be labeled. We would like to “closely match” the behavior of π when applied for k steps. However, without the labels of the selected instance, we do not know how π would behave after the first example is selected. In particular, different label outcomes will likely lead π to select a different set of k examples. In this work, we assume the availability of a posterior distribution of the labels of any example x given Dl, which can be estimated using a probabilistic classifier. A k-step executions of π will result in a set of k selected examples from Du. Let Skπ be the random variable denoting the set of k examples resulting from such a k-step execution of π, which has a well defined distribution P kπ (·) over the subsets of Du.\nImportantly, it is generally straightforward to use MonteCarlo simulation to draw samples of Skπ . For example, this can be done by starting with Dl and selecting the first example x1 using π. Then, we realize y1, the class label of x1, by sampling from the label posterior distribution of x1. This simulated labeled example is then added toDl and the process repeats for k − 1 additional iterations to obtain a total of k examples. Our batch policy is based on generating a number of samples of Skπ , which are used to define an objective for optimizing a batch of k experiments. Below we derive this objective and describe its optimization."
    }, {
      "heading" : "2.2. Coordinated Matching Objective",
      "text" : "Our goal is to select a batchB of k unlabeled examples that best “matches the behavior” of a base sequential policy π\nconditioned on the currently labeled examples. More precisely, we consider a batch B to be a good match if it has high probability (relative to other sets) under the dataset distribution P kπ . Unfortunately, for all but trivial sequential policies π, there will be no closed form for P kπ , which makes it challenging to directly optimize the probability of B. Thus, our approach is to first approximate P kπ via a simpler distribution Qk that captures essential aspects of P kπ and then return the batch B that is optimized under Q k.\nMatching Mixture Model. One naive choice for Qk would be to represent it as a latent mixture model, e.g. a Gaussian mixture model, from which k i.i.d. examples are drawn in order to produce a batch. While estimating such a model based on samples of Skπ would be relatively straightforward, e.g. via an EM algorithm, it would generally produce poor results. In particular, the i.i.d. nature of the model would typically assign high probability to batches containing redundant examples arising from the most probable Gaussian component. This fails to capture the highly dependent nature of examples in Skπ , which will typically avoid such redundancy.\nIn order to partially capture the dependencies in Skπ , we use a variant of the Gaussian Mixture Model (GMM), which we call the k-Matching Mixture Model (k-MMM). Similar to GMMs, a k-MMM model consists of a set of k n-dimensional Gaussian with mean vectors µ = {µ1, . . . , µk} and covariance matrices Σ = {Σ1, . . . ,Σk}. In contrast to the i.i.d generative process assumed by GMMs, a k-MMM generates a set of k points by sampling one point from each of the k components.\nGiven a k-MMM model and a set of k points S = {x1, . . . , xk}, there are k! possible ways that S can be generated, each corresponding to one possible matching of the k points to the k components. Given such a matching m, let m(i) denote the index of the model component that is matched to point xi and letM denote the set of all possible matchings. Assuming a uniform prior over possible matchings, the probability of observing S given a k-MMM Qk can be written as:\nQk(S) = ∑ m∈M Qk(S,m)\n= 1\nk! ∑ m∈M Qk(S | m)\n= 1\nk! ∑ m∈M k∏ i=1 f(xi;µm(i),Σm(i)),\n(1)\nwhere f is the Gaussian PDF.\nImportantly, unlike an i.i.d. model, the point sets generated by Qk can be highly dependent since there is a strict re-\nquirement that each component generates exactly a single point. In our application, this is useful in that it can capture distributions that assign higher probability to diverse datasets, which is a typical characteristic of P kπ .\nEstimating Qk. We now wish to select a k-MMM model Qk that best approximates our target distribution P kπ . To simplify this estimation problem, in this work, we limit our attention to models where the means are selected from the unlabeled examples Du and all of the Σi are equal to a known Σ1. Under these assumptions, we can view the problem of selecting Qk as a combinatorial problem of selecting the best subset of k points µ = {µ1, . . . , µk} from Du to serve as the component means. We will let Qkµ denote our model for a particular set µ. Our optimization objective is now to find the set µ that minimizes the KLdivergence KL(P kπ ||Qkµ), which is equivalent to minimizing the cross-entropy between the distributions given by H(P kπ , Q k µ) = E [ − logQkµ(Skπ) ] .\nThe resulting minimization problem is intractable due to the complicated nature of P kπ . However, we can sample from this distribution using simulation as described previously and generate a set of samples S = {S1, . . . , SN}, which can be used to approximate the expectation. Let Uk be the set of all size-k subsets of unlabeled examples inDu, our optimization objective can be formulated as follows.\narg min µ∈Uk\nH(P kπ , Q k µ) ≈ arg max\nµ∈Uk N∑ i=1 logQkµ(Si)\n= arg max µ∈Uk N∑ i=1 log ∑ m∈M Qkµ(Si,m)\nTo further simplify the above objective, we note that for the purpose of maximizing over the means µ,∑ m∈MQ k µ(Si,m) can be reasonably approximated by maxm∈MQ k µ(Si,m). This is because the value of Qkµ(Si,m) decays very quickly for non-optimal matchings, since such matchings will typically assign a data point in Si to a component with a distant mean. Thus, our objective is approximated by:\narg max µ∈Uk N∑ i=1 log max m∈M Qkµ(Si,m)\n= arg max µ∈Uk N∑ i=1 max m∈M logQkµ(Si,m)\n= arg min µ∈Uk N∑ i=1 min m∈M k∑ j=1 dΣ(xij , µm(j))\n(2)\nwhere xij is the j-th example in set Si, and the distance\n1Generally speaking, the values of the Σi may be set within a cross validation process, or via standard heuristic rules.\nAlgorithm 1 Greedy Supermodular Minimization Algorithm Require:Set function g, Finite set A. Ensure:µ ⊆ A such that |µ| = k\nµ← A while |µ| > k do x← arg minx∈µ g(µ \\ x) µ← µ \\ x end while return µ\ndΣ(x1, x2) = (x1−x2)′Σ−1(x1−x2) can be interpreted as the cost of matching x1 to x2. In our experiments, we use the identity matrix for Σ, resulting in Euclidean distance.\nThe above objective corresponds to a novel optimization problem that we call Bounded Coordinated Matching (BCM). Given a particular choice of µ, we find the minimum cost matching between µ and each set Si ∈ S. The overall cost of µ is the sum of all N costs, i.e.∑N i=1 minm∈M ∑k j=1 dΣ(xij , µm(j)) . The bounded coordinated matching problem involves finding the µ that achieves minimum overall cost. Since minimum cost matchings between two sets can be found in polynomial time via the Hungarian algorithm, the overall cost for any µ can be computed efficiently. Unfortunately, the problem of finding the optimizing set µ is NP-complete.\nTheorem 1. BCM is NP-complete (see appendix for the proof).\nFortunately, BCM allows for certain approximation guarantees to be made for a simple greedy algorithm, which we present in Section 3.\nSummary of Approach. To summarize, our overall approach is as follows. First, we use simulation to generateN independent sample trajectories S1, · · · , SN of a sequential active learning policy (we use the maximum entropy policy in our experiments). Second, we approximate the distribution generating these trajectories by Qkµ where the set µ is found by approximately optimizing Objective (2) (see next section for the optimization approach). Finally, given Qkµ we select a batch of k unlabeled data points B such that B = arg maxB maxm∈MQ k µ(B,m). Since we limited the choice of µ to subsets of the unlabeled data, it is easily verified that B is simply equal to µ, which is returned as the batch of examples for which to request labels."
    }, {
      "heading" : "3. Optimization Approach",
      "text" : "In this section we present a greedy approximation algorithm for BCM motivated by theoretical results on the minimization of non-increasing, supermodular set functions."
    }, {
      "heading" : "3.1. Greedy Approximation Algorithm",
      "text" : "Definition 1. Given a finite set A, a function on subsets of A, g : 2A → R+ is supermodular if for all A1 ⊆ A2 ⊆ A and x ∈ A\\A2, it holds that g(A1)−g(A1∪x) ≥ g(A2)− g(A2 ∪ x). In other words, a supermodular function demonstrates “diminishing returns” because adding an element to set A ⊆ A decreases the value of g(·) by at most as much as adding the element to a subset of A. In addition, a set function is non-increasing if for any set A and element x we have g(A) ≥ g(A ∪ {x}). It turns out that the problem of finding a size k subset of A that minimizes a non-increasing supermodular function g(·) can be approximately solved via a simple greedy algorithm. Algorithm 1 outlines this approach, which simply starts with all elements of A and iteratively removes the element whose removal leads to the smallest increase in g(·) until only k elements remain. We have the following known guarantee. Theorem 2. (Il’ev, 2001) Let g(·) be a monotonic nonincreasing supermodular function over subsets of the finite set A, |A| = m and g(A) = 0. Let µ be the set of the elements returned by the greedy algorithm 1 s.t |µ| = k, q = m− k and µ∗ = argminµ′⊆A,|µ′|=k g(µ′), then\ng(µ) ≤ 1 t\n[( q + t\nq\n)q − 1 ] g(µ∗) ≤ e\nt − 1 t g (µ∗) (3)\nwhere t is the steepness parameter of function g(·) which is defined as:\nt = s\ns− 1 s.t.\ns = max x∈A (g(∅)− g(x))− (g(A \\ x)− g(A)) g(∅)− g(x)\n(4)\nNotice that the approximation bound involves the steepness parameter t of g(·), which characterizes the rate of decrease of g(·). This is unavoidable because achieving a constant factor approximation guarantee is not possible unless P=NP (Nemhauser & Wolsey, 1999). Furthermore, this bound has been shown to be tight for any t (Il’ev, 2001). Note that this is in contrast to guarantees for greedy maximization of submodular functions (G. L. Nemhauser & Fisher, 1978) for which there are constant factor guarantees. In addition, the greedy algorithm we use is qualitatively different from the one used for submodular maximization, since it greedily removes elements from µ rather than greedily adding elements to µ.\nThe objective function corresponding to the BCM optimization problem (2) is the following function over subsets µ of the unlabeled data points Du:\ng(µ) = N∑ i=1 min m∈M k∑ j=1 dΣ(xij , µm(j)) (5)\nThe BCM problem corresponds to minimizing this function subject to |µ| = k. It is easily verified that this objective is a non-increasing supermodular function of µ. Further, since the points xij in the objective are elements of Du, we have that g(Du) = 0. Therefore, g(·) satisfies all of the properties for Theorem 2 and the greedy algorithm provides the corresponding guarantee. Thus, we use the above greedy algorithm applied to the function g(·) and set Du as our BCM optimizer, i.e. A = Du in Algorithm 1."
    }, {
      "heading" : "3.2. Accelerated Greedy Algorithm",
      "text" : "Each iteration of the greedy algorithm requires evaluating the cost function (Equation 5) for removing each element x from the current set µ, which is at most the size of Du. Each cost function evaluation involves finding N minimum cost matchings, between each of the Si and µ\\x (when µ \\ x is larger than Si, some elements of µ are unmatched), which can be done via N calls to the Hungarian algorithm. While polynomial, for a naive implementation, each iteration can be computationally expensive when Du is large. Fortunately, there are at least three ways to soundly speedup the computation, leading to drastic time reductions in our experience and allowing the computation to be independent of the size of Du.\nFirst, let µ be the current set and µi ⊆ µ be the set of elements in µ that are matched to Si in the minimum matching. It is easy to verify that g(µ) = g(∪iµi). This observation implies that instead of initializing µ to be the entire unlabeled data set Du, we can soundly initialize µ to be µ0 = ∪iSi since the minimum matching between Si and Du must be Si itself. Thus, the time complexity of the greedy algorithm under this initialization grows with the size of µ0 (the number of data points generated during simulation, which is at most N · k), rather than the potentially much larger Du. In other words, the run time of the greedy algorithm is independent of the size of Du, which is often quite large.\nSecond, for points x that are unpruned by the first rule, we can often avoid computing g(µ \\ x) by exploiting the supermodularity property. This idea is analogous to a similar speedup approach used for submodular maximization (Krause et al., 2008). From Definition 1, we can directly conclude that for A1 ⊆ A2 ⊆ A, g(A1 \\ x) − g(A1) ≥ g(A2 \\ x)− g(A2). We define the non-negative incremental difference of an instance x with respect to a set µ to be δ(µ, x) = g(µ\\x)−g(µ), which is the amount of increase of our objective function after removing a sample x from µ. Normally this incremental difference must be computed for all x ∈ µ in each iteration. However, by maintaining these incremental differences, we can often soundly avoid recomputing a large majority of them in any given iteration. The first iteration must compute the differences for\nall points in µ. We then sort the points in increasing order based on their incremental differences, and remove the first point. For the following iteration, we move on to the next point in the sorted list and recompute its incremental difference. If the value is still smaller than the remaining points, we can immediately remove this point from µ and proceed to the next iteration without recomputing any other differences. Otherwise, we proceed to evaluate the next points in the sorted list until finding one whose recomputed difference is less than the other stored differences and remove the point. The supermodular property guarantees that this approach makes the same choices as the full greedy algorithm, but effectively avoids a large number of difference computations in practice.\nFinally, for any point x that we need to compute its difference and hence evaluate g(µ\\x), we can reduce the cost of this computation by storing the set of maximum matchings between µ and the Si. In particular, rather than recomputing the maximum matching between µ \\ x and each Si from scratch, we can start with the current matching to Si. If the current matching does not involve x, then no recomputing is needed. Otherwise the matching can be updated with a single shortest path computation. This results in a reduction in time complexity at least by a factor of k compared to running the full Hungarian algorithm for each Si. Details are described in the supplementary material."
    }, {
      "heading" : "4. Scalability",
      "text" : "The computation of our batch selection approach can be divided into two stages: 1) Simulation of the sequential policy, and 2) Solving the resulting BCM problem. As the number of unlabeled data points n increases, the simulation time will also increase, since each simulation step involves applying a sequential policy, which typically considers each unlabeled point. For typical sequential policies, including the one in our experiments, the time complexity will grow linearly in n. Fortunately, theN simulations generated during the first stage are independent, which allows for easy parallelization, possibly resulting in a time reduction of a factor of N . That is, with parallelization there need not be any time overhead compared to running a typical sequential algorithm for k steps.\nFurther, as described previously the time complexity of the second stage does not depend on n, but rather on N · k. Overall, the scalability of the combined two stages in terms of n is similar to the underlying sequential base policy."
    }, {
      "heading" : "5. Experimental Results",
      "text" : "Datasets. In this section we evaluate our proposed batch active learning method using eight binary classification problems from the UCI machine learning repository (Asuncion & Newman, 2010) including (the number of sam-\nples and attributes are shown in the parenthesis for each dataset): Breast(569, 32), Ionosphere(351, 34), Pima(768, 8), German(1000, 24), Haberman(306, 3), Sonar(208, 60), EF(1543, 16) and MN(1575, 16). The EF and MN datasets are subsets of the original multi-class letter dataset, created by retaining only letters E and F, M and N respectively.\nBaseline Algorithms. To evaluate the efficacy of the proposed algorithm, we compare our algorithm against four baseline methods. For the first baseline, we consider the Fisher Information approach by Hoi et al.(Hoi et al., 2006b), one of the state-of-the-art methods in batch active learning. This method selects a batch that maximizes the Fisher information of a classification model (we use Kernel logistic regression in our experiments). The second baseline, which we call Maximum Uncertain, simply selects the top k most uncertain (as measured by class entropy) examples to form the batch. This simple batch algorithm is a commonly used baseline in batch active learning literatures. We further include the “random” policy in our comparison, which has demonstrated very competitive performance in prior batch active learning studies (Guo & Schuurmans, 2007). Finally, we also compare to the sequential policy that selects the example with the highest class entropy, which is also the base sequential method that our simulation matching algorithm tries to match. Note that we also compared our algorithm against SVM-D, which is another batch selection algorithm based on the minimum margin principle (Brinker, 2003). The results were not reported here since it was consistently worse than other baseline batch active learning approaches. Note that we were not able to compare results to two recent batch active learning methods (Guo & Schuurmans, 2007), and (Guo, 2010) because we were not able to acquire a working implementation of these algorithms, and both algorithms involve complex optimization procedures that are non-trivial to implement and tune.\nExperimental Setting. We use kernel logistic regression with an RBF kernel (kernel width= 0.05) as our classifier for all algorithms. We use N=20 simulated trajectories for each batch selection and consider batch sizes of 10 and 20. Each dataset is randomly divided into 70% training data and 30% testing data. Active learning is initialize with five random examples per class from train and iteratively selects batches of unlabeled examples in train to query. The classification accuracy is evaluated after each batch selection on the test data. The entire process is repeated for 50 independent runs and the average results are reported.\nEvaluation. We show the classification accuracy of different methods on the eight datasets in Figure 1(the batch size is shown in the parenthesis for each dataset). The x−axis indicates the number of queries and the y−axis represents the classification accuracy. First, let us focus on comparing\nour proposed method with the baseline batch methods including Fisher Information and Maximum Uncertain. We observe that, for most datasets, the learning curves produced by our method dominate the learning curves of the other batch methods. This is true for both batch sizes, but the improvements our method achieves is more significant and consistent for larger batch size of 20. Interestingly, we observe that Fisher Information and Maximum Uncertain results are sometimes dominated by random. For example, this is the case for Pima and German, where both methods performed consistently worse than random for both batch sizes. While surprising, this is actually consistent with what have been observed in a previous batch active learning study (Guo & Schuurmans, 2007). This suggests that it is actually non-trivial to design a batch active learning method that performs competitively to random in a consistent fashion. Notably, our proposed approach is the only method in our comparison that demonstrated this robustness, which is a highly desirable property of our method. In addition, the variance of our approach is quite small in our experiments. This is likely due to the average effect of using a set of simulations, which are processed in aggregate by the greedy optimizer. Among all data sets, Breast data set has the highest variance which is 0.006 and 0.0074 for batch size 10 and 20 respectively.\nWe also observe that the sequential method generally outperforms the batch methods (with a few exceptions) and more significantly for batch size 20. This is aligned with our expectation because a sequential approach makes more efficient use of the labeled examples when making selection choices. Interestingly, our proposed method is able to match the performance of sequential method reasonably well for many datasets, and even sometimes outperform sequential (e.g., Ionosphere and Breast). We conjecture this is due to the fact that our proposed method aggregates the outcome of many simulations, which may reduce the variance of the base sequential active learning procedure.\nComputational Time. We compute the CPU run time of selecting a batch of 20 examples in one of our largest data sets, MN, on a standard desktop computer with 2.13 GHz CPU (dual core) and 2 GB of memory. It takes less than 3 minutes using an un-optimized Matlab implementation. This time is reasonable for most applications of batch active learning, where labeling time is generally significant. As discussed previously, this time can be reduced via parallelization and will grow reasonably with the size of Du."
    }, {
      "heading" : "6. Conclusions",
      "text" : "In this paper, we introduce a novel method for batch active learning, which follows a recently proposed general approach named “simulation matching”. The basic idea behind simulation matching is to design batches of queries\nby imitating the behavior of a high-quality sequential policy via simulation. While this general approach has been successfully applied to the problem of batch Bayesian optimization, the notion of “matching” used in prior work is not suitable for active learning. We put forth a principled adaptation of the simulation matching approach to batch active learning. In essence, we consider Skπ , the set of k points selected by sequential policy π, to be a random variable. Because the distribution of Skπ is too complex to directly estimate, we draw samples from this distribution via simulation and approximate the distribution using a kMatching Mixture Model, which is then used to select the batch. This results in a combinatorial optimization problem that we call “bounded coordinated matching” (BCM), and we present an efficient algorithm that provides approximation guarantees. We evaluate the proposed approach on eight UCI datasets and the results show that our method is highly competitive compared to baseline methods."
    }, {
      "heading" : "A. Proof of Theorem 1",
      "text" : "Proof. Given S1, . . . , SN , where each Si contains a set of k points {xij}kj=1, the BCM objective function is:\nargmin µ⊂Du:|µ|=k N∑ i=1 min m∈M k∑ j=1 dΣ(xij , µm(j)) (6)\nConsider the following graph representation of the problem. We define a weighted bipartite G = (U, V,E) where V = {S1, S2, · · ·SN}, and U = Du representing the set of unlabeled examples. E ⊆ U × V is an edge set where the weight w(u, v) = dΣ(u, v). A coordinated matching on G is a subset of edges E′ ⊆ E such that, for 1 ≤ i ≤ t, (U × Si) ∩ E′ is a matching. The weight of a coordinated matching E′ is w(E′) = ∑ (u,v)∈E′ w(u, v). Given G and some integer k ≤ |U |, the bounded, coordinated matching problem (BCM) asks for a minimum weight coordinated matching such that the edges in the matching are, in total, incident to at most k vertices from U . Below we will turn this minimization problem into an equivalent maximization problem by replacing all the weights in G such that w′(u, v) = λ − w(u, v), where λ is a large constant to ensure all positive w′ values. It is easy to see that the solution of this maximization problem of BCM is also the solution to the original minimization problem.\nFocusing on the maximization problem, the decision version of the problem augments G and k with a weight W and asks if there exists a bounded, coordinated matching with weight W . We show that the decision version of maximizing BCM is NP-hard. We reduce from the wellknown 3-Dimensional Matching (3DM) problem which, given a set T ⊂ X × Y × Z where X , Y , and Z are disjoint and an integer k, asks if there exists a subset M ⊆ T of size at least k such that for any two distinct\nsets Mi,Mj ∈ M , Mi ∩ Mj = ∅. 3DM remains NPhard even when |X| = |Y | = |Z| = k (i.e. it becomes an exact-cover problem). The reduction is the natural one: create an unweighted, bipartite graphG = (U, V,E) where V = X ∪Y ∪Z and U = {u1, . . . , uk} is a set of k nodes. For every ti ∈ T where ti = {xi, yi, zi} add the edges {ui, xi}, {ui, yi}, {ui, zi} to E. It’s clear that T has has a 3-dimensional matching of size k if and only if 〈G, k〉 has a bounded, coordinated matching of weight 3k."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The authors acknowledge the support of the NSF under grants IIS-0812514, IIS-1055113, and IIS-0905678."
    } ],
    "references" : [ {
      "title" : "Batch bayesian optimization via simulation matching",
      "author" : [ "J. Azimi", "A. Fern", "X.Z. Fern" ],
      "venue" : null,
      "citeRegEx" : "Azimi et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Azimi et al\\.",
      "year" : 2011
    }, {
      "title" : "Incorporating diversity in active learning with support vector machines",
      "author" : [ "Brinker", "Klaus" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Brinker and Klaus.,? \\Q2003\\E",
      "shortCiteRegEx" : "Brinker and Klaus.",
      "year" : 2003
    }, {
      "title" : "An analysis of the approximations for maximizing submodular set functions",
      "author" : [ "G.L. Nemhauser", "L.A. Wolsey", "M.L. Fisher" ],
      "venue" : "Mathematical Programmingn,",
      "citeRegEx" : "Nemhauser et al\\.,? \\Q1978\\E",
      "shortCiteRegEx" : "Nemhauser et al\\.",
      "year" : 1978
    }, {
      "title" : "Discriminative batch mode active",
      "author" : [ "Y. Guo", "D. Schuurmans" ],
      "venue" : "learning. NIPS,",
      "citeRegEx" : "Guo and Schuurmans,? \\Q2007\\E",
      "shortCiteRegEx" : "Guo and Schuurmans",
      "year" : 2007
    }, {
      "title" : "Active instance sampling via matrix partition",
      "author" : [ "Guo", "Yuhong" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Guo and Yuhong.,? \\Q2010\\E",
      "shortCiteRegEx" : "Guo and Yuhong.",
      "year" : 2010
    }, {
      "title" : "Largescale text categorization by batch mode active learning",
      "author" : [ "Hoi", "Steven C. H", "Jin", "Rong", "Lyu", "Michael R" ],
      "venue" : "In WWW,",
      "citeRegEx" : "Hoi et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hoi et al\\.",
      "year" : 2006
    }, {
      "title" : "Batch mode active learning and its application to medical image classification",
      "author" : [ "Hoi", "Steven C. H", "Jin", "Rong", "Zhu", "Jianke", "Lyu", "Michael R" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Hoi et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hoi et al\\.",
      "year" : 2006
    }, {
      "title" : "An approximation guarantee of the greedy descent algorithm for minimizing a supermodular set function",
      "author" : [ "Il’ev", "Victor P" ],
      "venue" : "Discrete Applied Mathematics,",
      "citeRegEx" : "Il.ev and P.,? \\Q2001\\E",
      "shortCiteRegEx" : "Il.ev and P.",
      "year" : 2001
    }, {
      "title" : "Near-optimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies",
      "author" : [ "A. Krause", "A. Singh", "C. Guestrin" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Krause et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Krause et al\\.",
      "year" : 2008
    }, {
      "title" : "Integer and combinatorial optimization",
      "author" : [ "G.L. Nemhauser", "L.A. Wolsey" ],
      "venue" : null,
      "citeRegEx" : "Nemhauser and Wolsey,? \\Q1999\\E",
      "shortCiteRegEx" : "Nemhauser and Wolsey",
      "year" : 1999
    }, {
      "title" : "Active learning literature survey",
      "author" : [ "Settles", "Burr" ],
      "venue" : "Computer Sciences Technical Report 1648,",
      "citeRegEx" : "Settles and Burr.,? \\Q2009\\E",
      "shortCiteRegEx" : "Settles and Burr.",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "Guo and Schuurmans (2007) posed batch active learning as a complex optimization problem that maximizes the discrimina-",
      "startOffset" : 0,
      "endOffset" : 26
    }, {
      "referenceID" : 0,
      "context" : "This idea has been explored recently for the very different problem of batch Bayesian optimization (Azimi et al., 2011).",
      "startOffset" : 99,
      "endOffset" : 119
    }, {
      "referenceID" : 8,
      "context" : "This idea is analogous to a similar speedup approach used for submodular maximization (Krause et al., 2008).",
      "startOffset" : 86,
      "endOffset" : 107
    } ],
    "year" : 2012,
    "abstractText" : "We propose a novel batch active learning method that leverages the availability of high-quality and efficient sequential active-learning policies by approximating their behavior when applied for k steps. Specifically, our algorithm uses MonteCarlo simulation to estimate the distribution of unlabeled examples selected by a sequential policy over k steps. The algorithm then selects k examples that best matches this distribution, leading to a combinatorial optimization problem that we term “bounded coordinated matching”. While we show this problem is NP-hard, we give an efficient greedy solution, which inherits approximation bounds from supermodular minimization theory. Experiments on eight benchmark datasets show that the proposed approach is highly effective.",
    "creator" : "LaTeX with hyperref package"
  }
}