{
  "name" : "1312.7223.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Quality Estimation of English-Hindi Outputs using Naïve Bayes Classifier",
    "authors" : [ "Rashmi Gupta", "Nisheeth Joshi", "Iti Mathur" ],
    "emails" : [ "rsh.gupta06@gmail.com,", "nisheeth.joshi@rediffmail.com,", "mathur_iti@rediffmail.com," ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords— Quality Estimation, Confidence Estimation, Naïve Bayes.\nI. INTRODUCTION In this paper we have studied the confidence estimation for machine translation in which we find the quality scores of sentences. The main goal of confidence estimation is to judge the behaviour of the system output for a given input without any information about the expected output. Confidence Estimation for machine translation can be seen as a binary classification problem to distinguish between ‘good’ and ‘bad’ translations. The remaining section of the paper is organised as: Section 2 gives an overview of previous work on Quality Estimation. Section 3 describes the methodology of the system. Section 4 gives the Experimental settings. Section 5 gives tells us about the analysis and results.Section6 finally gives you the conclusion."
    }, {
      "heading" : "II. RELATED WORK",
      "text" : "Blatz.et al.[1] presents a number of experiments with CE at the sentence level based on annotations using automatic MT evaluation metrics. Repressors and classifiers are trained on features extracted for translations labeled according to National Institute of Standard and Technology (NIST) and Word Error Rate (WER). For classification, NIST scores are\nchosen to be threshold to label the 5th or 30th percentile of the examples as “good”. For regression, the estimated scores are mapped into two classes using the same thresholds. The results did not show to be helpful in a range of evaluation tasks. Quirk [2] uses classifiers and a pre-defined threshold for “bad” and “good” translations considering a small set of 350 translations manually labeled for quality. Specia et al.[3] use a number of “black box” (MT systemindependent) and “glass-box” (MT systemdependent) features to train a Partial Least Squares (PLS) regression algorithm to estimate both NIST and human scores. Gamon et al.[4] trained an SVM classifier using a number of linguistic features which were extracted from machine and human translations to differentiate between human and machine translations. Pado et.al.[5] used a regression algorithm along with features which contained textual entailment between the translation and the reference sentences. Soricut and Echihabi [6] focus on document level CE. The goal is to rank the documents according to their estimated quality and, given a threshold defined by the end-user, select the top n documents. Specia.et.al.[7] used 74 features to train a support vector machine classifier."
    }, {
      "heading" : "III. METHODOLOGY",
      "text" : ""
    }, {
      "heading" : "A. Naive Bayes",
      "text" : "Naïve Bayes is one of the most effective and efficient classification algorithms. In machine learning problems, a learner attempts to construct a classifier from a given set of training examples with class labels. Assume that F1, F2, F3.., Fn are n attributes. An example E is represented by a vector (f1,f2,….fK), where fi is the value of Fi. Let C represent the class variable which takes values excellent, good, average and poor. We use QE to represent the value that C\ntakes. A naïve Bayesian classifier is defined as follows-\nP(QE|F1,F2,F3,F4,……FN) = ( , , ,. .| )∗ ( )\n( , , , ,…… ) (1)\nQE = argmaxP(F1|QE)*P(F2|QE)*P(F3|QE).*P(FN|QE)* P(QE) (2)\nWhere, P(QE|F) is the posterior probability of class (target) given predictor (attribute). P(QE) is the prior probability of class. P(F|QE) is the likelihood which is the probability of predictor given class. P(F) is the prior probability of predictor. The value of (fi/QE) can be estimated from the training example which can be easily implemented by Naïve Bayes classifier."
    }, {
      "heading" : "B. Working of the system",
      "text" : "Naïve Bayes is a well known algorithm for classification problems. The list of the sets of attribute values and its corresponding category are given to the classifier and these constitute the training set. From the training data an independent probability is established. The probability gives the likelihood of each target class, given the occurrence of each value category from each input variable. When a new example is presented a value for the target function can be predicted based on the training instances. 1 Training step- Using the training samples the methods estimate the parameter of a probability distribution, assuming features are conditionally independent given the class.\n2 Testing step- for any unseen test sample, the method computes the posterior probability of that sample belongs to each class.\nAlgorithmic steps  Input sentences  Extract features from these input sentences.  These features and their corresponding\nlabels are provided to the learning algorithm.\n The model is trained using this learning algorithm (naive bayes classifier).\n Then raw data is taken and features are extracted from this raw data.\n This raw/ test data is provided to the trained model.\n We get the predicted label of the test data."
    }, {
      "heading" : "IV. EXPERIMENTAL SETTINGS",
      "text" : ""
    }, {
      "heading" : "A. Data Collection",
      "text" : "For development of the training system, we used a 3,300 sentence corpus that was built during ACL 2005 workshop on building and using parallel text : Data Driven machine translation and beyond, as the training corpus. The statistics of the corpus is shown in table I"
    }, {
      "heading" : "B. Features Used",
      "text" : "In this paper we have focused on using supervised machine learning in evaluation of MT engine outputs which does not use human reference translations. We have trained a Naïve Bayes classifier. In order to perform the task of confidence estimation across different machine translation systems we define a machine learning system which uses independent features which are extracted from the input (source) sentences and their corresponding translation (target) sentences. The set of 16 features are used in this paper are defined below-\n Number of token in the source sentence.  Number of token in the target sentence.  Average source token length.  Language model probability of source\nsentence.  Language model probability of target\nsentences.  Average number of occurrence of target\nwords within the target sentence.  Average number of translation per source\nword in the sentence.  Percentage of low frequency unigram in the\nsource language.\n Percentage of high frequency unigram in the source language.\n Percentage of low frequency bigram in the source language.\n Percentage of high frequency bigram in the source language.\n Percentage of high frequency trigram in the source language.\n Percentage of low frequency trigram in the source language.\n Percentage of unigram in the source sentence seen in the corpus.\n Number of punctuation marks in the source sentence.\n Number of punctuation marks in the target sentence.\nThe outputs from training corpus are registered against all the three machine translation engines. The judging criteria was same as used by Joshi et. al. [8]. All the sentences are judged on ten parameters using a scale between 0-4 scores by human translators. The ten parameters used in the evaluations are as follows-\n Translation of Gender and Number of the Noun(s).\n Identification of the Proper Noun(s).  Use of Adjectives and Adverbs\ncorresponding to the Nouns and Verbs.  Selection of proper words/synonyms\n(Lexical Choice).  Sequence of phrases and clauses in the\ntranslation.  Use of Punctuation Marks in the\ntranslation.  Translation of tense in the sentence.  Translation of Voice in the sentence.  Maintaining the semantics of the source\nsentence in the translation.  Fluency of translated text and\ntranslator’s proficiency.\nInterpretation of human scale5\n 1 = ideal  2 = perfect  3 = Acceptable\n 4 = Partially Acceptable  5 = Not Acceptable\nOnce the human evaluations of these outputs are done, we used these results along with the 16 features that were extracted from the English source sentences and Hindi MT outputs. We tested the classifiers using another corpus of 1300 sentences. The statistics of the test corpus is shown in table II.\nThe 1300 sentences were divided into 13 documents of 100 sentences each. We registered the outputs of the test corpus on all three machine translation engines and perform human evaluation on them."
    }, {
      "heading" : "V. ANALYSIS AND RESULTS",
      "text" : "For the evaluation of the system we converted the human evaluation of the system into grades. These grades are given in the table III.\nThe results of the classifier are computed on the basis of these grades, which gave us the same class."
    }, {
      "heading" : "A. Comparison of human evaluation and Naïve Bayes:",
      "text" : "The results produced by the naïve bayes classifier and the human evaluation are shown in table 4. This gives the number of times machine translation engine scored in each of the four categories. Table 5, shows the results of human evaluation for all the three MT\nengines. These four grades can also be converted into a numeric score to provide ranks to the MT outputs.\nTable 6 shows the comparison of results of human grades with the grades given by the classifier. If a human evaluator gave a good score to a sentence and the classifier also gave good to the same sentence then will counted it. More the human evaluator and the classifier can produce almost similar results to most of the judgments."
    }, {
      "heading" : "VI. CONCLUSION AND FUTURE WORK",
      "text" : "In this paper we have extracted 16 features from the input sentences and their translation and a quality score is obtained based on Bayesian inference produced from training data. In this paper we have shown that the Naïve Bayes classifier can predict the same level of outputs as that of human evaluator. Moreover in future we will improve the quality of the system by adding some more features and will study and evaluate the system in which we compare the rankings of the system given by the humans. The system which gives the same rank as given by the human will consider as the good system."
    } ],
    "references" : [ {
      "title" : "Confidence Estimation for Machine Translation",
      "author" : [ "Blatz", "John", "Erin Fitzgerald", "George Foster", "Simona Gandrabur", "Cyril Goutte", "Alex Kulesza", "Alberto  Sanchis", "Nicola Ueffing" ],
      "venue" : "In Proceedings of the 20th Conference on Computational Linguistics,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2004
    }, {
      "title" : "Training a Sentence-Level Machine Translation Confidence Measure",
      "author" : [ "Quirk", "Chris" ],
      "venue" : "In Proceedings of the 4th Conference on Language Resources and Evaluation,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2004
    }, {
      "title" : "Improving the confidence of Machine translation Quality Estimates",
      "author" : [ "Lucia Specia", "Craig Saunders", "Marco Turchi", "Zhuoran Wang", "John Shawe-Taylor" ],
      "venue" : "In proceeding of Machine Translation Summit XII,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "Sentence level MT evaluation without reference translations: beyond language modeling",
      "author" : [ "M. Gamon M. Aue A. Smets" ],
      "venue" : "In Proceedings of 10th meeting of the European association for machine translation,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2005
    }, {
      "title" : "Textual Entailment Features for Machine Translation Evaluation",
      "author" : [ "Sebastian Pado", "Michel Galley", "Dan Jurafsky", "Christopher D. Manning" ],
      "venue" : "In Proceedings of the 4 EACL Workshop on Statistical Machine Translation,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2009
    }, {
      "title" : "Trustrank: Inducing trust in automatic translations via ranking",
      "author" : [ "Soricut", "Radu", "Abdessamad Echihabi" ],
      "venue" : "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2010
    }, {
      "title" : "Estimating the Sentence-Level Quality of Machine Translation Systems",
      "author" : [ "Lucia Specia", "Nicola Cancedda", "Marc Dymetman", "MarcoTurchi", "Nello Cristianini" ],
      "venue" : "In Proceedings of the 13th Annual Conference of the EAMT,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2009
    }, {
      "title" : "Human and Automatic Evaluation of English to Hindi Machine Translation Systems. Advances in Computer Science, Engineering & Applications",
      "author" : [ "Nisheeth Joshi", "Hemant Darbari", "Iti Mathur" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "[1] presents a number of experiments with CE at the sentence level based on annotations using automatic MT evaluation metrics.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "Quirk [2] uses classifiers and a pre-defined threshold for “bad” and “good” translations considering a small set of 350 translations manually labeled for quality.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 2,
      "context" : "[3] use a number of “black box” (MT systemindependent) and “glass-box” (MT systemdependent) features to train a Partial Least Squares (PLS) regression algorithm to estimate both NIST and human scores.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] trained an SVM classifier using a number of linguistic features which were extracted from machine and human translations to differentiate between human and machine translations.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[5] used a regression algorithm along with features which contained textual entailment between the translation and the reference sentences.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "Soricut and Echihabi [6] focus on document level CE.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 6,
      "context" : "[7] used 74 features to train a support vector machine classifier.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[8].",
      "startOffset" : 0,
      "endOffset" : 3
    } ],
    "year" : 2013,
    "abstractText" : "In this paper we present an approach for estimating the quality of machine translation system. There are various methods for estimating the quality of output sentences, but in this paper we focus on Naïve Bayes classifier to build model using features which are extracted from the input sentences. These features are used for finding the likelihood of each of the sentences of the training data which are then further used for determining the scores of the test data. On the basis of these scores we determine the class labels of the test data. Keywords— Quality Estimation, Confidence Estimation, Naïve Bayes.",
    "creator" : null
  }
}