{
  "name" : "1305.1991.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "On the universality of cognitive tests",
    "authors" : [ "David L. Dowe", "José Hernández-Orallo" ],
    "emails" : [ "david.dowe@infotech.monash.edu.au", "jorallo@dsic.upv.es" ],
    "sections" : [ {
      "heading" : null,
      "text" : "The analysis of the adaptive behaviour of many different kinds of systems such as humans, animals and machines, requires more general ways of assessing their cognitive abilities. This need is strengthened by increasingly more tasks being analysed for and completed by a wider diversity of systems, including swarms and hybrids. The notion of universal test has recently emerged in the context of machine intelligence evaluation as a way to define and use the same cognitive test for a variety of systems, using some principled tasks and adapting the interface to each particular subject. However, how far can universal tests be taken? This paper analyses this question in terms of subjects, environments, space-time resolution, rewards and interfaces. This leads to a number of findings, insights and caveats, according to several levels where universal tests may be progressively more difficult to conceive, implement and administer. One of the most significant contributions is given by the realisation that more universal tests are defined as maximisations of less universal tests for a variety of configurations. This means that universal tests must be necessarily adaptive. Keywords: universal tests; human, animal, plant and machine intelligence; test interface; signal resolution; time."
    }, {
      "heading" : "1 Introduction",
      "text" : "The prominent physicist, Stephen W. Hawking, has long lost his ability to speak, but is relatively fortunate in having assistants who can follow his facial cues and in having speech-generation equipment. We are not aware of any deficiency in his input (hearing) senses, but we should not deny his notable intelligence merely on the grounds of his limited output (limited in both mode and speed) and how that would severely hinder him on conventional intelligence tests. Other cases, such as deaf-blind people and those enduring locked-in syndrome, are\nar X\niv :1\n30 5.\n19 91\nv1 [\ncs .A\nstunning examples of how an individual’s will to communicate can counteract many limitations of a hampered (or awkward) communication channel, through the development of new semantic signals and languages. Establishing communication through an unconventional channel can be a real challenge for a peer in those cases, and may take months, or years, to make the first semantic contact, with the subject(s) being considered ‘vegetative’ until that moment.\nAnother case is that of locked-in syndrome, a condition which Kate Allatt once had. She can now communicate normally, but she had been assumed to be in a vegetative state until it was realised that she could communicate — and spell out words— by blinking her eyes. A third case in the point is that of Canadian Scott Routley, again assumed to have been in a vegetative state until it was very recently discovered by examining MRI brain scans that he is able to hear and respond to “yes”/“no” questions via mental imagery. These cases describe people whose (auditory) input (or hearing) appears unaffected but whose intelligence would not be apparent if we did not allow for their slow output speed and their less than conventional modes of output.\nIt is now commonly agreed that intelligence is not specific to (some) humans. More and more life forms are attributed to also have some kinds or degrees of intelligence. The number and ranges of species claimed to be in this category have been increasing in the past decades, from mammals to molluscs, from swarms to plants [94]. Nonetheless, there is still an important debate on whether some of them just exhibit a very complex behaviour (evolutionary species adaptation) rather than a truly intelligent behaviour (individual, nonhardwired adaptation). This already complicated picture of intelligent forms is completed (or will be completed) by machines and robots of many kinds, some of them already flaunting some kinds of intelligent behaviour. Similarly, there is a recurrent debate on whether the behaviour is authentically intelligent or just pre-programmed. And, finally, to really make the picture full, we should also consider hybrids (e.g., people with pen and paper, with electronic devices and Internet connection, etc.) and communities (either homogeneous or heterogeneous), where the notions of intelligence and mind may diverge.\nIntelligence (or more generally, cognitive) tests are the scientific instruments to measure and categorise the kinds and degrees of intelligence (or more generally, cognitive abilities) of this variety of subjects. Comparative psychology has used many different types of tests to detect and compare abilities across species. Many tests are particular for some species (or even for some subpopulations or ages in a given species), and only a few have been used for many species, being very specific in terms of tasks or evaluated abilities. One of the most difficult issues is the configuration of an appropriate interface for each species or individual, in order to guarantee an appropriate administration of the tests, trying to ensure that the subject is focussing on solving a given task.\nWhen moving to the area of artificial intelligence, the use (or just the proposal) of the same test for natural and artificial subjects has been uncommon, apart from Turing’s imitation game [95], and the occasional application of IQ tests to specifically-devoted machines [24, 26, 25, 80, 10, 9]. It is only very recently that the construction of non-anthropocentric intelligence tests for ma-\nchines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].\nIn this context, [41] introduced the notion of ‘universal (intelligence) test’, as a test that could be administered to any kind of subject, at any speed, and interrupted anytime. The notion of a ‘test for all’ soon generated widespread interest [58, 6], even though the proposal highlights some concerns about the difficulty (or even the feasibility) of such an idea, especially if we consider the evolution of comparative psychology in the past century. In fact, a new discipline called universal psychometrics [46, 45] is suggested as an umbrella area of convergence for the general evaluation of cognitive abilities of any kind of subject (with or without universal tests).\nThe notion of universal tests does not, in principle, entail what these tests look like and how they are generated. Nonetheless, it has been recently argued [41, 46, 45] that the approach for universal tests must be based on computation and, more specifically, on algorithmic information theory (or SolomonoffKolmogorov complexity) and (two-part) compression [88, 99, 100]. This contrasts with the idea of applying anthropocentric tests for machines, such as the use of the Turing test or common IQ tests to evaluate artificial intelligence. While the reasons for the inadequacy of the Turing Test are easier to understand and have been spotted by many (see, e.g., [34]), the justification of why IQ tests are not for machines (or for biological systems other than humans) is more cumbersome [20].\nWhile most of the above work has been motivated by the lack of proper tools to evaluate machine intelligence (and other cognitive abilities), the same rationale and principles could be used for natural subjects. In particular, in this work we analyse the notion of universal intelligence test in a more abstract way and analyse how universal an intelligence test can be. In particular, we will try to answer several questions: Can a test cover any kind of natural or computational subject, operating at any signal resolution and time rates? What resolution aspects should we consider? How crucial is the interface in a universal test? How can we dare measure the intelligence of subjects that we struggle to detect? Do we need intelligence to detect and measure some other intelligent subjects? How are validity, reliability and efficiency affected by a generalisation of a test?\nIn what follows we will go through these questions with a most general perspective, by considering that subjects can be machines, humans, non-human animals, plants, and other natural, artificial or hybrid systems. We start in section 2 with an overview of the wide range of intelligence tests in natural systems and machines. Section 3 describes what a universal test is and how it depends on the use of different interfaces for different kinds of subjects. Section 4 further generalises this idea by discussing possible configurations of time and resolution, and sketches a general procedure for an adaptive universal test. Section 5 examines more extreme cases where we do not know the rewarding system or we do not even recognise (in the beginning) the agent we want to evaluate. Finally, section 6 introduces a hierarchy of test universality levels according to several factors. We discuss the difficulty of universal tests according to this hi-\nerarchy and their feasibility for more constrained (but easier) applications that are expected to be common in the near future."
    }, {
      "heading" : "2 Background",
      "text" : "Intelligence [91], in particular, and cognition [82], in more general terms, is nowadays associated with a diversity of species in the natural world. This diversity goes far beyond humans and the animal kingdom, as intelligence has also been recognised (or claimed) in swarms, plants, fungi, immune systems, bacteria, genome and metabolic systems1 [94]. Some of the arguments in favour of such a diversity of systems showing some kind of intelligent behaviour are based on examples of classical conditioning [32] or some kinds of complex behaviour [2], even though some of these findings and claims have also been disputed [79]. The controversy is stronger for the possibility and detection of extraterrestrial intelligence, and the possibility and construction of machine intelligence. Nevertheless, the terms artificial intelligence and machine cognition are used nowadays to describe systems which lack intelligence and possibly any authentic (embodied) cognition.\nMost of this controversy is originated by the lack of agreement of what intelligence is and how it should be measured. One important issue to understand this is the so-called intelligence anthropocentrism, where the very notion of intelligence (and cognition) is frequently said to be a human construct aimed at humans. Psychometrics (see, e.g., [91, 8]) is the most mature (and now robust) discipline in terms of intelligence evaluation, but it is also the most anthropocentric one. As for the measurement of intelligence and other cognitive abilities, one remarkable characteristic in psychometrics is that we can have different tests for the same ability, depending on the kind of subject. For instance, we have different tests for children, disabled people, etc. It is important to note that while the tests (the instruments) are different, the ultimate purpose is to measure the same ability. And here the problems arise, because it is easy to raise objections about whether a test corresponds to an ability2. It is also a source of controversy whether a minor detail in how the test is conceived (or just administered) could have important effects on the measured ability. Nonetheless, on occasions, the use of different tests and interfaces (e.g., a written or an oral test) for different subjects (e.g., a deaf person or a blind person, respectively) is the only way to measure the same ability.\nWhen looking at ways of evaluating cognitive abilities in a general way, comparative psychology (and cognition) [82, 83] is the place to look at. First, it has made a very important impact by looking at the problem in a less anthropocentric way. Second, it usually deals with the problem of using different tests for different species in order to measure the same ability. Third, it is an excellent\n1The kind of intelligence which is not associated with a centralised brain is sometimes known as non-neural.\n2This objection is often responded with statements such as “intelligence is what the intelligence tests measure” [7].\nsource of how interfaces can be designed, from individuals to swarms. However, its comparative character casts a shadow of relativity in the tests, as the correspondence between the ability and the tests is usually more empirical than theoretical.\nA very different approach is found in artificial intelligence. Over the past decades, there have been many proposals to evaluate AI artefacts or areas of the discipline: specific tests (Turing Test [95, 75], the total Turing Test [81] and other sensorimotor variations [74], the Bot Prize [51], CAPTCHAs [97], the machine intelligence quotient [105, 5], ... ), competitions (RL competition [101], Robocup [57], general game playing competition [30], planning competition [64], ...) and landmarks (Deep blue [13], Watson [28]).\nOf course, one can argue that different tests are required to measure different abilities (e.g., planning, visual recognition, natural language, etc.), but is it reasonable to have different tests for the same ability (e.g., intelligence or learning ability) if the subjects are different? As a response to this we should mention that there have been some advocates for the use of the same tests for (at least) humans and machines, namely the use of IQ tests for machines. The roots can be traced to the development and understanding of cognitive models, such as the works of Evans [24, 26, 25] and, indirectly, those of Simon and Kotovsky [84, 59]. Nowadays, there is a field known as “psychometric AI” —not to be confused with universal psychometrics [46, 45]—, where IQ tests are used to improve and evaluate artificial intelligence systems. Nonetheless, the most explicit vindication of the use of IQ tests for machines has been recently made by Detterman, editor of the Intelligence Journal, as a response [15] to specific domain tests and landmarks (such as Watson). In other words, this view claims that human-level intelligence should be measured with human-level intelligence tests, i.e., IQ tests.\nHowever, there are many objections to the use of IQ tests for non-human agents, not only for animals (see, e.g, [82, sec.1.1.4]) but most especially for machines (see [20] for a full discussion). The main argument is that it is possible to find or construct non-intelligent agents that can score well on classical IQ tests, as has been demonstrated with very small programs (in 2003, Sanghi and Dowe implemented a small program in Perl which could score relatively well on many IQ tests [80]). This raises serious doubts about the real implications of any non-human (natural or artificial) system that is evaluated using IQ tests (e.g., [22, 104]). It is not clear either that a generalisation or revision of current IQ tests to make them more general is a sound pathway, as we could end up with tests that work with a specific population or in terms of a current technology, but need to be updated recurrently as the population is enlarged and AI technology improves (as happens with the notion of Machine Intelligence Quotient [105, 5] or, more blatantly, with CAPTCHAs [97]).\nDespite the variety of tests for humans, non-human biological systems and machines, there is a thing in common for all these tests: they lack a formal (and in most cases, principled) notion of intelligence from which the tests are derived. In other words, the ability is finally defined from what the test measures instead of deriving a test from a principled definition of the ability. At most, for the\ntests discussed so far, there may be a conceptual analysis of the nuts and bolts of the ability prior to devising the task(s) that may correspond to the ability. However, even in these cases, the link is usually made at an non-mathematical level. Also, the derivation of task difficulty is not obtained from a mathematical definition of the ability but as a refinement of the experimental results of a given population. In the end, this is the same way that thermometers and other measuring devices were designed in the past, without precisely knowing the exact definition of the magnitude to be measured and the physical processes involved.\nAs an alternative to these approaches, in the past two decades, there have been several efforts to derive definitions and tests of intelligence from computational principles. The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100]. An example of one of these tests formally derived from computational principles is shown in Figure 1, which resembles some exercises found in IQ tests but with a principled generation and assessment of difficulty.\nThese works were followed some years later by Legg & Hutter [61], who built upon re-inforcement learning by also using AIT, putting a Solomonoff-weighted prior distribution over single-agent environments. A measure (or definition, but not a test) of intelligence could be theoretically obtained (in the limit) by seeing what score the agent would obtain after infinite time in each of the infinitely many environments. There are several issues about the feasibility and exact interpretation of such a measure, as raised by [50, 41], among others."
    }, {
      "heading" : "3 Interfaces",
      "text" : "From the previous series of contributions on definitions, measures and tests based on AIT, the project anYnt3 was set to analyse the possibility of constructing the first universal, formal, but at the same time practical, intelligence test. The term universal had been used and understood in different ways by many of the previous proposals, frequently in terms of concepts such as universal Turing machine, or the use of the term ‘universal distribution’ for any\n3http://users.dsic.upv.es/proy/anynt/\nSolomonoff-weighted prior distribution. In this project, however, the term ‘universal’ had a more common meaning and referred to the applicability of the test to any kind of individual, i.e., a test for all.\nPursuing this universality, taking into account the limitations of [61] and other previous approaches, [41] introduced an adaptive test which was anytime (able to be interrupted at anytime giving a more accurate result as more time is given) and also (supposedly) universal —i.e., applicable to machines, humans and non-human animals alike. While also based on algorithmic information theory, there are some distinctive features of this test, which distinguishes it from [61]. First, the class of environments is carefully selected to be discriminative. Second, while environments are randomly sampled from that class using an a priori distribution (starting with very simple environments), the complexity of the environments adapts to the subject’s performance. Third, the test also considers time and, similarly, the speed of interaction adapts to the subject’s performance. Finally, the result is not an average of results in all possible environments but an aggregation of how far an agent can reach in terms of the complexity and speed of the environment.\nWhile some of these features are related, we are mostly concerned in this paper about the alluded universality of the test. If feasible, this universality should allow the comparison of very different subjects with the same tests. As a first proof-of-concept, [54, 55] attempted an implementation of the test using the environment class introduced in [38]. Actually, humans and AI agents (using some classical reinforcement learning algorithms) were evaluated using the same test. While the exercises were exactly the same, the interface was adapted to each kind of agent. The general idea of a test for all was illustrated, but the results did not show a clear victory of humans over AI agents. There are several possible explanations for this [21, 44, 47, 53, 56, 48]: it was a prototype, it was not adaptive as the original proposal [41], there was no noise, patterns had low complexity, the environment class was quite limited, no social behaviour or other factors were evaluated, to name a few. In any case, the results do not indicate that the prototype is not a universal test, but rather that it does not measure intelligence properly.\nIn fact, the main feature of a universal test is that the task must be exactly the same while the interface has to be customised for each individual. In other words, a universal test is composed of a task and an infinite number of possible interfaces. Figure 2 shows this view of interfaces and tasks.\nThe application of a single task to different species is an everyday chore in\ncomparative psychology, as is the choice of interfaces that are able to engage an animal to do a task (typically by the use of rewards) without adulterating the task itself. However, when the number of species for a single test is limited, the task and the interface are sometimes blurred.\nThe meaning and emphasis of a universal (cognitive) test is the intention to apply the task to any possible agent: including humans, non-human animals, plants, communities, hybrids, ..., and most especially machines. Even for those agents that clearly lack the ability (e.g., a flea solving sudokus), the intention is to figure out a way to measure the ability and give a score. This most general way forces us to place the conception of a test in terms of a general, abstract and computational task. We start with an information-processing ability, define it properly as a set (or distribution) of tasks with a scoring system. Only after this, we may start thinking about interfaces to apply the task to any possible system. This computational approach is now also present in comparative and animal cognition, and particularly in animal evolutionary linguistics, constructing tasks about the kind of grammars (regular, context-free or contextual) several species are able to recognise [31, 76, 33, 23, 77]. From there, the evaluators figure out the best way of turning these tasks into tests by the use of appropriate interfaces.\nThis first understanding of what a universal test is and its possible application to any natural or artificial system also suggests that the question of whether universal tests are possible or not could be further refined into a more informative question: which tasks can be measured with a universal test and those that cannot. In principle, we may be able to construct universal tests for all information-processing tasks but, at the other extreme, it may also be the case that no universal test can be constructed for any task.\nBefore addressing this question (or the general question of this paper), we need to look at the interfaces more closely. One reasonable criterion for a fair interface is that it cannot add new information or hide existing information about the task. For instance, if one interface discloses part of the solution while another does not, then the test would be adulterated. One possible mathematical way of defining an interface is by the notion of bijection, as done in [46, 45]. Nonetheless, there might be computational costs associated with the bijection, so the mapping must have some other constraints.\nEven under these constraints, there are still many possible interface choices for a given agent. One typical approach is to find the best possible interface that does not add any additional information. For instance, humans and animals get much better scores when observations are represented in terms of environments they are used to, i.e., species or culture-friendly interfaces. For instance, Figure 3 shows two different interfaces for the test developed in [54, 55, 56]. While the information is the same and the (computational) effort to transform the observation from one to the other is straightforward, humans would typically score much better with the interface on the right.\nClearly, this search for the optimal interface for each species (or individual) can be applied to any natural and artificial agent. In artificial agents, exercises are usually presented in terms of data structures (arrays, sets, etc.) instead of visual interfaces, except for those tasks which are precisely evaluating vi-\nsual recognition or related abilities. For natural agents, things are becoming more and more complicated. The interfaces used for some animal species are extremely elaborate and, on many occasions, different interfaces are used for different individuals, according to the understanding and knowledge of the subject’s behaviour (e.g., in zoos, aquariums and natural parks, local curators are usually interviewed in order to decide which kind of interaction and rewards may be more appropriate for each individual). In the case of plants or other natural systems, the interfaces are certainly original. In fact, these interfaces are frequently the key to discover abilities in these systems [94][32][2][79] that were considered non-existent only a few years ago4. Humans are not an exception here either, as a great amount of imagination is needed to devise some tests for disabled people, especially for deaf-blinded, using tactile interfaces [3] or other approaches [69, 96, 78].\nIn general, the interface must pay attention to the sensorimotor characteristics of each agent, including other milieux, such as chemical sensors in animals and plants, and different kinds of data transformation for machines. Many failures in the past have been caused by important mismatches and misconceptions of how animals (and computers) should interact, with a strong anthropocentric bias in our interfaces5\nThis idea of devising a task and looking for optimal environments according to the knowledge that we have about each species and individual has been very fruitful, but it is painstaking in terms of the effort and time that is required to evaluate new species and life forms. Furthermore, this methodology faces more problems with machines, as we can imagine any computable behaviour and we can think of many different kinds of perception, as more and more sophisticated sensor devices are conceived.\nSo the grand question about the notion of an intelligent test is whether a test is able to evaluate a completely unknown agent. The general idea is that we can only assume some minimal information about the environment or milieu (either physical or virtual) where the agent is placed. From here, a real universal test should try to find the best interface (signals, time rate, resolution, rewards) which leads to the best score, without providing additional information about\n4Some of these ideas are being used in better interfaces across species, but also in a pursue of better interfaces between computers and animals [68].\n5The problem also happens in the other direction: evaluating humans with bit sequences is like evaluating (some) machines or animals with anthropocentric environments.\nthe task at hand. As a result, a totally universal, adaptive test requires a search in this vast area of time rates and resolutions. In the end, this is what animal cognition has done in the past decades in a manual (scientific-oriented) way. Is it possible to envisage such a process in an automated way, at least in some restricted contexts and for some abilities? In other words, if we are given an environment with some agents, is it possible to have a test that tries to find the interface to better evaluate the agents’ ability? This is what we explore next."
    }, {
      "heading" : "4 Time, resolution and universality through test",
      "text" : "adaptation\nIn comparative cognition, interfaces are usually associated with physical things: a cage with a small door, a peanut as reward, a set of cups, a touch screen, a light bulb, a set of ropes, etc. Thinking of a test that is able to adapt to all these possible physical configurations (and do this automatically) is far beyond reach. Instead of this, in this section, we will consider variations of the same physical (or virtual) ‘milieu’. For instance, given a screen we can think about many possible resolutions and colours, given an audio signal in a range of frequencies we can consider all the possible variations there. In fact, many human tests are still administered with a sheet of paper, and many different interfaces are still possible with this ‘rudimentary’ milieu.\nIf we focus on cognitive abilities as information-processing tasks we can fix the milieu and examine the possible variations around it. With this restriction, any interface is in the end a pair of input and output communication channels (in terms of information theory) with a given bandwidth. If we consider discrete interfaces, we can describe this in terms of the input/output resolution and a refresh rate6. For instance, considering time, if the task is the addition of two natural numbers lower than 10 represented in a unary system, and we agree on the representation of the numbers in the output channel, there is still the question of how much time the numbers are going to be displayed and how much time the agent is going to be allowed to give an answer. If we fix these values we make the evaluation possible for some agents but this also exclude others. For instance, plants are now claimed to do some kind of cognition [12], but their time-scale is much slower than those of animals.\nThe anytime test introduced in [41] arguably addresses part of the issue of time adaptively by starting with a very fast interaction rate and slowing it down as the results from the agent are not good. The direction of the time change (from very fast interaction to slower interaction) is reasonable as many agents would also react appropriately if the interaction is neither too fast nor too slow, and starting at fast interactions makes the adaptation feasible in finite time. While this is a first approach for making a universal test adaptive on time, there are more issues in terms of time-scale than those reflected by [41]. Also,\n6Although the terms are exactly the same for screens, we consider any possible milieu here, either auditive, visual or other.\nother kinds of resolutions are not considered. If we take a closer look at time rate, we see at least two time frames that could be (adaptively) increased/decreased:\n• Working time, which can be the time between questions and answers in a questionnaire-like test or it can be the time other agents (e.g., predators) take to make actions or the time the environment makes rewards available. This is in fact what [41] adapts. This time typically includes the time the agent needs to act (or write an answer).\n• Exposition time: the amount of time the agent gets to be given the information before it is removed7. This time frame is usually neglected unless this is the goal of a study on short-memory (or other kinds of memory abilities, such as photographic memory). However, if the exposition time frame is not appropriate, the agent may completely overlook some important data of a task.\nOn occasions we want a cognitive ability to consider time, such as measuring ‘reaction time’ [70]. But if time is not part of the ability (e.g., we may want to know the ability to sort a series of numbers, without considering speed) then we (or the test) need to find the optimal time windows for working and exposition time in order to make the test feasible. Let us use the term time configuration for the set of parameters for a given working and exposition time.\nA related, but different thing, is resolution. Although we typically think in terms of spatial resolution, it is very useful for the discussion that follows to think of a case where we consider an audio signal, where resolutions appear on the same signal, using, e.g., frequency and amplitude. For instance, figure 4 [103, 65] shows how a sound signal can carry many different types of information at several resolutions.\nNot only the resolution may be too coarse or too detailed for the agent to see any relevant pattern, but it can take infinitely many representations. Note that the detection of the appropriate resolution is different from any pattern that the signal may carry. This distinction is important, even though both things (resolution and pattern) are usually closely intertwined8. Nonetheless, while animals (including humans) usually have innate preprocessing systems that may be used to capture some resolutions (and ignore others) and see patterns in them, it is possible to disentangle one thing from the other. For instance, many\n7As an example of humans requiring more time than some animals, Ayumu the chimpanzee [52] is able to note the locations of the numbers 1 to 9 (of which there are 9! = 362880 possibilities) after only 60 milliseconds observation time. A large proportion of humans struggle just to see (and recall) the location of even one of these numbers in this time-frame. This also happens with other milieux, e.g., auditive signals, as the case of a non-native speaker requiring slower speech or repetitions.\n8The recognition of patterns depends on a correct resolution configuration. This is crucial to the notion of emergence, and can be translated to communication and interaction as well, since structures emerge from some low-level constituents that have no meaning by themselves. This recognition of patterns at a previously unknown resolution and time, and its relation with emergence, has also been explored (see, e.g., [29]), and can also be referred to the cognitive structures and constructs the agent is creating all along its life [36].\nartificial pattern (image, speech, etc.) recognition systems have preprocessing devices that render the information ready (e.g., a bitmap or spectrogram) for the analysis of patterns. Working with several resolutions and representations in order to find the most appropriate one may take important time overloads to process. This of course makes resolution and time also closely intertwined in real systems9.\nThe complexity of resolution and the appropriateness of representation is one of the major issues in artificial intelligence, pattern recognition and machine learning. This issue, however, has been neglected by most machine intelligence tests that we reviewed in section 2. Being conscious of these limitations, let us move forward by considering a communication channel for which we can define any possible resolution, each of them denoted by the term resolution configuration.\nFrom here, we just define a configuration θ as a pair of time configuration and resolution configuration. We want to evaluate a cognitive ability defined as a distribution of tasks M , i.e., a task class. Consider that we have a set (or distribution) of configurations Θ. Then we can define:\nU(π,M,Θ) = max θ∈Θ lim τ→∞ Υ(π,M, θ, τ) (1)\nwhere Υ(π,M, θ, τ) is any test on a family of tasks that is applicable to an agent π during time τ (for instance, time-bounded adaptations of [61] or some of the non-adaptive versions introduced in [41] or implemented in [54]). Eq. 1 above defines (or generalises) a universal test from a non-universal test. The expression\n9It is relevant to mention here that there are some recognition tasks (recognising distorted letters, as in CAPTCHAs) that do not correlate with some other (higher-level) abilities using those letters. In fact, the ability of recognising distorted letters is used as a CAPTCHA because machines are not able to do this well with current technology, not because distorted character recognition is a sign of intelligence.\nΥ(π,M, θ, τ) is an aggregate over the set of tasks M . This must be based on the result on single tasks, Υ(π, µ, θ, τ) and can be done in many different ways. One possibility is to weight by task probability: Υ(π,M, θ, τ) = Υ(π, µ, θ, τ)p(µ) (as in [61]), while another possibility is to define task difficulty and get the result in terms of this difficulty, as in [49, 34, 46, 45].\nThis maximisation can be translated into the goal of finding the configuration such that the test result is optimal for the subject. This leads to adaptive tests, which search for the appropriate configuration, or at least one that gives an approximation of Eq. 1 above. In the case we want the test to adapt, there is a need to have some interactive feedback from subject to testers, in terms of the score the subject is achieving. With this we are ready to introduce a first general procedure for an adaptive universal test. Figure 5 shows a general procedure for evaluating subject π in an adaptive way. The relevant part of the previous procedure is how we select tasks and configurations, especially after the first iteration, using the history of results and the tasks and configurations previously used. This can be seen as an extension/generalisation of [41] (and ultimately of [61] as well, with the appropriate modifications). For instance, if the agent’s score has been poor, we can either try to find a simpler task or change the configuration (which may imply a change in the time configuration, the resolution configuration or both). On the contrary, if the agent’s score has been good, we would be tempted to keep the configuration and change to a more difficult (or more informative) task.\nAn important question is how to obtain the final result of the test. Ideally, if we were able to evaluate all possible configurations and all possible tasks for an infinite amount of time τ each, the result would be calculated by taking the aggregated performance on the task class (using its distribution or the difficulty function) for the configuration that has given the best result. In practice, in finite time, the test should start with configurations not taking too much time (so τ can be small) and try as many resolutions as possible as the time configuration uses larger slots.\nSo, a universal test for an unknown agent would be a test that makes all the possible efforts to find a configuration with the evaluee at the best resolution and time configurations such that the subject can be evaluated in optimal conditions. Not coincidentally, this is what animal cognition usually does when designing\nan experiment, and, in the most difficult cases, finding the correct configuration may take decades. Also, as we will discuss in section 6, we are never sure that the right configuration has even been found.\nThese difficulties appear even though we have already considered that the (physical) communication milieu is fixed (e.g., a sound channel or a screen) and we have also assumed that we recognise the agent and know its reward system. As mentioned above, we are not going to consider every possible physical milieu. Instead, in what follows we will consider an environment including both the evaluator and the evaluee (e.g., the real world, but most especially, virtual words, such as games, social networks, etc., because of the possible applications and the higher feasibility of a test of this kind, see, e.g., [40])."
    }, {
      "heading" : "5 Making contact: detecting intelligence",
      "text" : "As said above, we now consider that evaluator and evaluee are agents in an environment. We assume that both can have effect on the environment through actions and they can perceive changes in the environment. This does not necessary mean that the environment has a spatial configuration where they can ‘move’, as in [38], but just that the possibility of interaction exists (e.g., an environment could just be a series of communication channels as in the matching pennies game, the Turing Test or any configuration in between [47]). We also consider that the evaluee has a goal or reward system that is determined by the things that happen in the environment. This setting is assumed in multi-agent systems, games and many other virtual, robotic or physical environments, from artificial intelligence to biology.\nA first situation we can consider is when we know the evaluee’s reward system so that the evaluator can directly use this by giving more or less rewards to the evaluee according to its performance. This sets an important advantage because we can condition the system to do things. Still, we do not know what communication channel or milieu to use, just how to administer rewards. So the big challenge here is to determine the way to communicate in the environment. In order to do this, the evaluator needs to perform actions in order to see some reactions from the evaluee, in order to understand how to ‘condition’ the evaluee (to try) to perform a task. With animals, we typically use food for this (to approach them, make them trust the evaluator, etc.).\nEven in a simplified virtual environment, as found in multi-agent systems or multiplayer games, recognising which channel the agents may use is not always easy. In general, there may be many possible channels, and communication can switch to more efficient communication channels with time10. The communication channel may be extremely original, as we can see in many examples of intraor inter-species communication, from primates [106] to bacteria [27]. Nonethe-\n10It is common that pre-established communication channels or protocols are omitted and agents end up communicating through other means that were originally not meant for communication (because the new channel is more efficient, can be concealed from other agents, or other reasons).\nless, there are many kinds of communication which are not usually recognised as such explicitly, as the communication that takes place whenever predators and preys meet, where the very movements and peer positions are an authentic exchange of information. In biology, there is a huge variety of ways of contact and communication, and many are still to be unveiled. In virtual or technological environments this diversity is also very large now.\nPerforming a universal test under these circumstances would imply a generalisation of the procedure in Figure 5 by including a variety of channels (along with the diversity of configurations and tasks). In order to determine that the channel is working we would still rely on the reward system and start with very easy tasks, in order to raise the probability that the evaluee makes a correct action (possibly by chance) so it can get positive rewards and then start ‘focussing’ on the task.\nStill, a much more challenging problem is when we do not know the agent’s reward system. Without knowing the agent’s goals (or rewarding system) we may detect reaction, but it is much more difficult to properly apply a test. The most natural option is to try to learn agent’s goals or rewards by observing habits, resistance to change, interacting, etc. This is again what ethologists can do, or what children do when playing with bugs or other animals in order to understand their behaviour. In order to automate this process (at least partially), there are several information-theoretic options that could be used to detect (and spur) agent-environment or agent-agent interaction [92, 102], but other approaches exist (relational dynamics, information structure, and many others). Independently of what technique is finally used (and whether they can work in general or not), if the evaluator is able to discover the agent’s goals then the test could start as in the previous case, using a generalisation of Figure 5. In this case, some information about the interaction that was used to determine the rewards could also be reused as history for the selection of milieu, time configuration and resolution configuration.\nFinally, the most challenging situation is when we have not even recognised the agent we want to evaluate. In this case, we are left in an environment (physical, robotic or virtual) and we need to discover whether there are intelligent forms there and try to evaluate them. One of the first caveats in this situation is that there may be many agents, and they can work collectively. As a consequence, even if we are able to recognise the individuals, we may fail at properly recognising intelligence if this only appears as an emergent property of the collection of agents and not of the individuals (as in swarm intelligence). The recognition of the goals/rewards of the collective and some way to communicate with it (in a unified way) is usually more difficult than the recognition of more integrated intelligent forms.\nEither in the form of an individual or a collective, this extremely challenging case has been occasionally discussed in biology but most especially in astro-biology. While astro-biology looks for physical signs of complex biological molecules, the detection of extraterrestrial intelligence through signals from outer space has been subject of much interest in the past decades. However, there is no clear methodology about how to do it (what to scan, as with the\nSETI project, and what to send, as with the Voyager space probes). Figure 6 shows an example of an outgoing message (as with the Voyager space probes) and an example of an alluded incoming message.\nOne problem is to recognise intelligence from such a transmission (in either way), and a related secondary problem is to be able to discern and interpret the message’s intended communication. The interpreting of such a message would presumably be best done by the (Bayesian) algorithmic information-theoretic approaches of Solomonoff prediction [88] and/or Minimum Message Length (MML) [99, 100, 98]. If the (algorithmic) information content (or SolomonoffKolmogorov complexity) of the communication is very low, this suggests something ultra-regular like a pulsar, analogous to a human repeating the same sound. If the Kolmogorov complexity is very high, this suggests unstructured random background gibberish, perhaps analogous to an incoherent human infant. For the message to stand out, it must be like, e.g., (human) language and have some structure without being totally repetitive. This should mean having some incrementality in its complexity, with sections of the message depending on previous sections. In terms of what to put in such a message or how to decode such a message, Wallace (private communication) [16] considered explaining arithmetic, then eventually Turing machines, the eventually the Lyman series and Hydrogen, etc. Solomonoff likewise wrote much about training sequences11 [87, 90, 86][89, sec.7(dolphin talk)]. This ‘contact’ problem corresponds very neatly to our extreme case of a universal intelligence test where a priori we do not even know about the existence of intelligence forms in an environment and, if they exist, where they are and what they look like. One important difference, though, is that in our case we\n11Although related, we should distinguish the goal of training sequence (turn a nonintelligent, possibly Turing-complete system into an intelligent system (see also [42, 43]) from the conception of a sequence such that it can be self-understood without common previous knowledge. We will discuss about this issue later on.\nassume the possibility of interaction12. This means that the principles could be the same, but the degree of repetition in the signals could be highly reduced when the interaction starts. When trying to systematise this, we could use yet another generalisation of the procedure in Figure 5 where the iteration would start looking for agents. The use of information-theoretic tools seems to be appropriate here as well. The mere recognition of an agent in these terms is ambitious as an agent can emerge (e.g., by autopoiesis) from very simple rules. For instance, these embodied, minimal cognitive agents have even been found (as gliders) in very minimalistic environments such as Conway’s game of life [4]. As there may be many different kinds of agents we may need tools to determine those that are merely interactive, cognitive or finally intelligent. Any procedure or test that could be able to eliminate those agents that are not good candidates for further levels would be useful. For instance, once an interactive system is found we could first determine whether we have a cognitive system, adapting some of the tasks of the cognitive decathlon and related approaches [1, 73, 72, 71, 85, 60, 11, 73] (although many of these approaches are focussed on evaluating cognitive architectures rather than evaluating actual cognitive systems through multi-factorial scores)."
    }, {
      "heading" : "6 Conclusions",
      "text" : "The difficulty of recognising (and ultimately) measuring intelligence would depend on a number of factors, as shown in Table 1. This table shows a gradual view which consists of five possible levels based on four criteria: knowledge of the configuration, milieu, rewards and agents. On occasions we may have some other combinations of these factors or we may have partial information about the configuration (or no information at all about the configuration but still some information about how the reward system works). Also, more information might be available for some agents than others. This suggests the use of Table 1 as an indication of the factors that need to be taken into account.\nThe less knowledge we have, the more difficulty the evaluation will be, and\n12This is also possible in theory with interstellar communication but with a very slow timeframe.\nwe will get lower reliability, efficiency and (probably) validity. In addition, there is also another factor that we need to consider: how the universal test is devised, depending on whether the test is conceived in a passive (as classical paper and pencil IQ tests), interactive (as games, computerised adaptive testing, the anytime test [41] or any generalisation of figure 5) or ultimately intelligent way. In this regard, the notion of an ‘intelligent intelligence test’ may sound strange but it is not new, as this is the way intelligence has been detected and evaluated for many centuries, as in interviews and other personal (psychological) assessments. In fact, the Turing test is one example of an ‘intelligent intelligence test’, since itself requires two intelligent subjects to evaluate a third.\nIt can be argued that the more intelligent the evaluator is the more effective the test can be. While this may be true (especially because a superintelligent being may be able to learn the best procedures to do intelligence testing as they are discovered), it raises many questions about reliability and validity, since an intelligent being may not follow a clear procedure or may not even be fair and objective in the assessment. As there is a subtle line between adaptability and intelligence, we prefer to envisage universal intelligence tests which are highly adaptive but follow a formal and standardised procedure.\nIn terms of reliability, we can also see (from the way the procedure in figure 5 works) that even when the proper configuration, milieu, reward system and agent are found then the assessment will still be an under-estimation13. This originates from the way the overall result of the test is understood: the procedure tries to find the best conditions for administering the test (i.e., the measure is a maximum). As a result, the evaluation is biassed to under-estimate intelligence (as has happened for many years for non-human intelligence and use to happen with other human cultures). This is a well-known problem in animal cognition (and also happens with other places where intelligence is sought, such as plants, bacteria, SETI, etc.). Moreover, this under-estimation also happens in human psychometrics, where the term “potential intelligence” is applied to “test potential” [67, 93, 63], (not to be confused with the term “potential intelligence” applied to the ability of becoming intelligent [42, 43]).\nFrom a computational point of view, we can say that evaluating intelligence (in a universal context) is, at most, semi-computable14. This comes from the fact that given an environment that may contain intelligence, there are infinitely many configurations, milieux, reward systems or agents, and there may always be some of them that have not been explored (because of the halting problem). In theory, we could turn this into a computable function or even a function that can be calculated in bounded space and time, by assuming that configurations, milieux, reward systems or agents are resource-bounded.\n13It is still possible to give over-estimations, such as humans assigning more intelligence to those animals or machines which have an android look, with anthropocentric sensorimotor components, as they look more intelligent than they really are. This issue is less frequent and there is always the possibility of double-checking (once the milieu, resolution, reward and agent are fixed).\n14As we do not consider intelligence a Boolean property but a quantitative one, we do not use the term semi-decidable here.\nFinally, there is a risk of over-estimation if the evaluator ends up training the agent instead of evaluating it. During a very long exploration for optimal configurations we may (inadvertently) train the agent we want to evaluate and make it more intelligent than it was. In fact, there are training sequences [87, 90, 86][89, sec.7(dolphin talk)] for any universal Turing machine such that the machine becomes intelligent (in fact, as much intelligent as we want, as it can simulate any behaviour, as shown and fully discussed in [42, 43]). So there is, in principle, a problem in making intelligence tests too long, as the agents can be domesticated (trained) to become intelligent15. If the agent is trained (or just domesticated), the test mixes actual and potential intelligence (in the sense of [42, 43]), and the reliability and validity of the test are highly compromised.\nLet us now summarise the results of our exploration about the limits and caveats of universal intelligence tests. We have seen how intricate the notion of universal intelligence test is and how difficult its implementation can be, as far as the challenge is set at the highest level in the hierarchy shown in Table 1. Nonetheless, the difficulty also depends on the environments and kinds of agents we want to explore. If we consider all possible natural and artificial agents in our physical world, a fully universal test working in a reasonable amount of time is just a theoretical idea. However, if we consider some simple environments (e.g., cellular automata, multi-agent environments or hybrids [39]) or situations where we have part of the information of the hierarchy shown in Table 1, we may still establish universal intelligence tests for those niches.\nIn fact, there are current situations where we need to determine the intelligence of a completely unknown agent. This is becoming more and more common in virtual environments, such as social networks, games, working groups, member authorisation procedures, etc., where we may find agents whose intelligence is completely unknown [40]. The Turing Test, custom IQ tests and CAPTCHAs are unsatisfactory in general terms (and will be less so as artificial intelligence advances). As new artificial agents, living organisms, collectives and hybrids thereof become mainstream, we will need to better understand the concept of test universality and devise more effective universal tests for intelligence and other cognitive abilities."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We would like to thank Paco Calvo for interesting discussions on plant intelligence and other kinds of non-neural intelligence, and for providing us with very useful pointers on this topic.\n15This problem can vanish for some artificial agents if they can be reinitialised for each iteration of the adaptive procedure."
    } ],
    "references" : [ {
      "title" : "The Newell test for a theory of cognition",
      "author" : [ "J. R Anderson", "C. Lebiere" ],
      "venue" : "Behavioral and Brain Sciences, 26(5):587–601",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Learning in bacteria",
      "author" : [ "P.B. Applewhite" ],
      "venue" : "fungi, and plants. Invertebrate learning, 3:179–186",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1975
    }, {
      "title" : "Tactile memory of deaf-blind adults on four tasks",
      "author" : [ "P. Arnold", "K. Heiron" ],
      "venue" : "Scandinavian journal of psychology, 43(1):73–79",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Autopoiesis and cognition in the game of life",
      "author" : [ "R.D. Beer" ],
      "venue" : "Artificial Life, 10(3):309–326",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Machine intelligence quotient: its measurements and applications",
      "author" : [ "Z. Bien", "W.C. Bang", "D.Y. Kim", "J.S. Han" ],
      "venue" : "Fuzzy sets and systems, 127(1):3–16",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Ultimate IQ: one test to rule them all",
      "author" : [ "C. Biever" ],
      "venue" : "New Scientist, 211",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Intelligence as the tests test it",
      "author" : [ "E.G. Boring" ],
      "venue" : "New Republic, pages 35–37",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1923
    }, {
      "title" : "Measuring the mind: Conceptual issues in contemporary psychometrics",
      "author" : [ "D. Borsboom" ],
      "venue" : "Cambridge University Press",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Psychometric artificial intelligence",
      "author" : [ "S. Bringsjord" ],
      "venue" : "Journal of Experimental & Theoretical Artificial Intelligence, 23(3):271–277",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "What is artificial intelligence? Psychometric AI as an answer",
      "author" : [ "S. Bringsjord", "B. Schimanski" ],
      "venue" : "International Joint Conference on Artificial Intelligence, pages 887–893",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Nonclassical connectionism should enter the decathlon",
      "author" : [ "F. Calvo-Garzón" ],
      "venue" : "Behavioral and Brain Sciences, 26(05):603–604",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Plants: adaptive behavior",
      "author" : [ "P. Calvo-Garzon", "F. Keijzer" ],
      "venue" : "root-brains, and minimal cognition. Adaptive Behavior, 19(3):155–171",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Deep Blue",
      "author" : [ "M. Campbell", "A.J. Hoane", "F. Hsu" ],
      "venue" : "Artificial Intelligence, 134(1-2):57 – 83",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Godel’s theorem and information",
      "author" : [ "G.J. Chaitin" ],
      "venue" : "International Journal of Theoretical Physics, 21(12):941–954",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1982
    }, {
      "title" : "A challenge to Watson",
      "author" : [ "D.K. Detterman" ],
      "venue" : "Intelligence, 39(2-3):77 – 78",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Foreword re C",
      "author" : [ "D.L. Dowe" ],
      "venue" : "S. Wallace. Computer Journal, 51(5):523 – 560, Sept 2008. Christopher Stewart WALLACE ",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "A computational extension to the Turing Test",
      "author" : [ "D.L. Dowe", "A.R. Hajek" ],
      "venue" : "Proceedings of the 4th Conference of the Australasian Cognitive Science Society, University of Newcastle, NSW, Australia",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "A computational extension to the Turing Test",
      "author" : [ "D.L. Dowe", "A.R. Hajek" ],
      "venue" : "Technical Report #97/322, Dept Computer Science, Monash University, Melbourne, Australia, 9pp, http://www.csse.monash.edu.au/publications/1997/tr-cs97-322-abs.html",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "A non-behavioural",
      "author" : [ "D.L. Dowe", "A.R. Hajek" ],
      "venue" : "computational extension to the Turing Test. In Intl. Conf. on Computational Intelligence & multimedia applications (ICCIMA’98), Gippsland, Australia, pages 101–106",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "IQ tests are not for machines",
      "author" : [ "D.L. Dowe", "J. Hernández-Orallo" ],
      "venue" : "yet. Intelligence, 40(2):77–81",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Compression and intelligence: social environments and communication",
      "author" : [ "D.L. Dowe", "J. Hernández-Orallo", "P.K. Das" ],
      "venue" : "J. Schmidhuber, K.R. Thórisson, and M. Looks, editors, Artificial General Intelligence, volume 6830, pages 204–211. LNAI series, Springer",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "A large-scale model of the functioning brain",
      "author" : [ "C. Eliasmith", "T.C. Stewart", "X. Choo", "T. Bekolay", "T. DeWolf", "C. Tang", "D. Rasmussen" ],
      "venue" : "Science, 338(6111):1202–1205",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "The myth of language universals: Language diversity and its importance for cognitive science",
      "author" : [ "N. Evans", "S.C. Levinson" ],
      "venue" : "Behavioral and Brain Sciences, 32(05):429–448",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A heuristic program of solving geometric analogy problems",
      "author" : [ "T. Evans" ],
      "venue" : "PhD thesis, Mass. Inst. Tech., Cambridge, Mass., U.S.A.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1963
    }, {
      "title" : "A heuristic program to solve geometric-analogy problems",
      "author" : [ "T. Evans" ],
      "venue" : "Proc. SJCC, volume 25, pages 327–339",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 1965
    }, {
      "title" : "A program for the solution of a class of geometric-analogy intelligence-test questions",
      "author" : [ "T.G. Evans" ],
      "venue" : "Technical report, DTIC Document, also appeared later in Minsky M. (ed.) Semantic Information Processing, pp. 271-353, Cambridge, Massachussets, 1968",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 1964
    }, {
      "title" : "et al",
      "author" : [ "M.J. Federle", "B.L. Bassler" ],
      "venue" : "Interspecies communication in bacteria. Journal of Clinical Investigation, 112(9):1291–1299",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "et al",
      "author" : [ "D. Ferrucci", "E. Brown", "J. Chu-Carroll", "J. Fan", "D. Gondek", "A.A. Kalyanpur", "A. Lally", "J.W. Murdock", "E. Nyberg", "J. Prager" ],
      "venue" : "Building Watson: An overview of the DeepQA project. AI Magazine, 31(3):59–79",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Partial information decomposition as a spatiotemporal filter",
      "author" : [ "B. Flecker", "W. Alford", "J.M. Beggs", "P.L. Williams", "R.D. Beer" ],
      "venue" : "Chaos: An Interdisciplinary Journal of Nonlinear Science, 21(3):037104–037104",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "General game playing: Overview of the AAAI competition",
      "author" : [ "M. Genesereth", "N. Love", "B. Pell" ],
      "venue" : "AI Magazine, 26(2):62",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "and Howard C",
      "author" : [ "T.Q. Gentner", "K.M. Fenn", "D. Margoliash" ],
      "venue" : "Nusbaum. Recursive syntactic pattern learning by songbirds. Nature, 440(7088):1204– 1207",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Classical conditioning of a plant: Mimosa pudica",
      "author" : [ "R.E. Haney" ],
      "venue" : "J. Biol. Psychol, 11:5–12",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 1969
    }, {
      "title" : "and T",
      "author" : [ "M.D. Hauser", "D. Barner" ],
      "venue" : "O’Donnell. Evolutionary linguistics: A new look at an old landscape. Language Learning and Development, 3(2):101–132",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Beyond the Turing Test",
      "author" : [ "J. Hernández-Orallo" ],
      "venue" : "J. Logic, Language & Information, 9(4):447–466",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Computational measures of information gain and reinforcement in inference processes",
      "author" : [ "J. Hernández-Orallo" ],
      "venue" : "AI Communications, 13(1):49–50",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Constructive reinforcement learning",
      "author" : [ "J. Hernández-Orallo" ],
      "venue" : "International Journal of Intelligent Systems, 15(3):241–264",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "On the computational measurement of intelligence factors",
      "author" : [ "J. Hernández-Orallo" ],
      "venue" : "A. Meystel, editor, Performance metrics for intelligent systems workshop, pages 1–8. National Institute of Standards and Technology, Gaithersburg, MD, U.S.A.",
      "citeRegEx" : "37",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "A (hopefully) non-biased universal environment class for measuring intelligence of biological and artificial systems",
      "author" : [ "J. Hernández-Orallo" ],
      "venue" : "M. Hutter et al., editor, Artificial General Intelligence, 3rd Intl Conf, pages 182–183. Atlantis Press, Extended report at http://users.dsic.upv.es/proy/anynt/unbiased.pdf",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Complexity distribution of agent policies",
      "author" : [ "J. Hernández-Orallo" ],
      "venue" : "arXiv preprint arXiv:1302.2056",
      "citeRegEx" : "39",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A short note on estimating intelligence from user profiles in the context of universal psychometrics: prospects and caveats",
      "author" : [ "J. Hernández-Orallo" ],
      "venue" : "arXiv preprint arXiv:1305.1655",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Measuring universal intelligence: Towards an anytime intelligence test",
      "author" : [ "J. Hernández-Orallo", "D.L. Dowe" ],
      "venue" : "Artificial Intelligence, 174(18):1508 – 1539",
      "citeRegEx" : "41",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Potential properties of Turing machines",
      "author" : [ "J. Hernández-Orallo", "D.L. Dowe" ],
      "venue" : "Technical Report, Dept Computer Science, Monash University, Melbourne, Australia",
      "citeRegEx" : "42",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "On potential cognitive abilities in the machine kingdom",
      "author" : [ "J. Hernández-Orallo", "D.L. Dowe" ],
      "venue" : "Minds and Machines",
      "citeRegEx" : "43",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "On more realistic environment distributions for defining",
      "author" : [ "J. Hernández-Orallo", "D.L. Dowe", "S. España-Cubillo", "M.V. Hernández- Lloreda", "J. Insa-Cabrera" ],
      "venue" : "evaluating and developing intelligence. In J. Schmidhuber, K.R. Thórisson, and M. Looks, editors, Artificial General Intelligence, volume 6830, pages 82–91. LNAI, Springer",
      "citeRegEx" : "44",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Universal psychometrics: Measuring cognitive abilities in the machine kingdom",
      "author" : [ "J. Hernández-Orallo", "D.L. Dowe", "M.V. Hernández-Lloreda" ],
      "venue" : "under review",
      "citeRegEx" : "45",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Measuring cognitive abilities of machines, humans and non-human animals in a unified way: towards universal psychometrics",
      "author" : [ "J. Hernández-Orallo", "D.L. Dowe", "M.V. Hernández-Lloreda" ],
      "venue" : "Technical Report 2012/267,",
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 2012
    }, {
      "title" : "Turing Tests with Turing machines",
      "author" : [ "J. Hernández-Orallo", "J. Insa", "D.L. Dowe", "B. Hibbard" ],
      "venue" : "Andrei Voronkov, editor, The Alan Turing Centenary Conference, volume 10, pages 140–156. EPiC Series",
      "citeRegEx" : "47",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Turing machines and recursive turing tests",
      "author" : [ "J. Hernández-Orallo", "J. Insa-Cabrera", "D.L. Dowe", "B. Hibbard" ],
      "venue" : "V. Muller and A. Ayesh, editors, AISB/IACAP 2012 Symposium “Revisiting Turing and his Test”, pages 28–33. The Society for the Study of Artificial Intelligence and the Simulation of Behaviour",
      "citeRegEx" : "48",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A formal definition of intelligence based on an intensional variant of Kolmogorov complexity",
      "author" : [ "J. Hernández-Orallo", "N. Minaya-Collado" ],
      "venue" : "Proc. Intl Symposium of Engineering of Intelligent Systems (EIS’98), pages 146– 163. ICSC Press",
      "citeRegEx" : "49",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Bias and no free lunch in formal measures of intelligence",
      "author" : [ "B. Hibbard" ],
      "venue" : "Journal of Artificial General Intelligence, 1(1):54–61",
      "citeRegEx" : "50",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A new design for a Turing Test for bots",
      "author" : [ "P. Hingston" ],
      "venue" : "Computational Intelligence and Games (CIG), 2010 IEEE Symposium on, pages 345–350. IEEE",
      "citeRegEx" : "51",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Working memory of numerals in chimpanzees",
      "author" : [ "S. Inoue", "T. Matsuzawa" ],
      "venue" : "Current Biology, 17(23):R1004–R1005",
      "citeRegEx" : "52",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "On measuring social intelligence: Experiments on competition and cooperation",
      "author" : [ "J. Insa-Cabrera", "J.L. Benacloch-Ayuso", "J. Hernández-Orallo" ],
      "venue" : "J. Bach, B. Goertzel, and M. Iklé, editors, AGI, volume 7716 of Lecture Notes in Computer Science, pages 126–135. Springer",
      "citeRegEx" : "53",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Comparing humans and AI agents",
      "author" : [ "J. Insa-Cabrera", "D.L. Dowe", "S. España-Cubillo", "M.V. Hernández- Lloreda", "J. Hernández-Orallo" ],
      "venue" : "J. Schmidhuber, K.R. Thórisson, and M. Looks, editors, Artificial General Intelligence, volume 6830, pages 122–132. LNAI, Springer",
      "citeRegEx" : "54",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Evaluating a reinforcement learning algorithm with a general intelligence test",
      "author" : [ "J. Insa-Cabrera", "D.L. Dowe", "J. Hernández-Orallo" ],
      "venue" : "J.A. Moreno J.A. Lozano, J.A. Gamez, editor, Current Topics in Artificial Intelligence. CAEPIA 2011. LNAI Series 7023, Springer",
      "citeRegEx" : "55",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "The anYnt project intelligence test : Lambda - one",
      "author" : [ "J. Insa-Cabrera", "J. Hernández-Orallo", "D.L. Dowe", "S. España", "M.V. Hernández-Lloreda" ],
      "venue" : "V. Muller and A. Ayesh, editors, AISB/IACAP 2012 Symposium “Revisiting Turing and his Test”, pages 20–27. The Society for the Study of Artificial Intelligence and the Simulation of Behaviour",
      "citeRegEx" : "56",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Robocup: The robot world cup initiative",
      "author" : [ "H. Kitano", "M. Asada", "Y. Kuniyoshi", "I. Noda", "E. Osawa" ],
      "venue" : "Proceedings of the first international conference on Autonomous agents, pages 340–347. ACM",
      "citeRegEx" : "57",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Who are you calling bird-brained? An attempt is being made to devise a universal intelligence test",
      "author" : [ "K. Kleiner" ],
      "venue" : "The Economist, 398",
      "citeRegEx" : "58",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "What makes some problems really hard: Explorations in the problem space of difficulty",
      "author" : [ "K. Kotovsky", "H.A. Simon" ],
      "venue" : "Cognitive Psychology, 22(2):143–183",
      "citeRegEx" : "59",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "Artificial intelligence and cognitive systems",
      "author" : [ "P. Langley" ],
      "venue" : "AISB Quarterly",
      "citeRegEx" : "60",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Universal intelligence: A definition of machine intelligence",
      "author" : [ "S. Legg", "M. Hutter" ],
      "venue" : "Minds and Machines, 17(4):391–444",
      "citeRegEx" : "61",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "An Approximation of the Universal Intelligence Measure",
      "author" : [ "S. Legg", "J. Veness" ],
      "venue" : "Proceedings of Solomonoff 85th memorial conference. Melbourne, Australia",
      "citeRegEx" : "62",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Potential intelligence or intelligence test potential? a question of empirical validity",
      "author" : [ "V.L. Little", "K.G. Bailey" ],
      "venue" : "Journal of Consulting and Clinical Psychology, 39(1):168",
      "citeRegEx" : "63",
      "shortCiteRegEx" : null,
      "year" : 1972
    }, {
      "title" : "The 3rd international planning competition: Results and analysis",
      "author" : [ "D. Long", "M. Fox" ],
      "venue" : "J. Artif. Intell. Res. (JAIR), 20:1–59",
      "citeRegEx" : "64",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Dolphin whistles: a functional misnomer revealed by heliox breathing",
      "author" : [ "P.T. Madsen", "F.H. Jensen", "D. Carder", "S. Ridgway" ],
      "venue" : "Biology letters, 8(2):211–213",
      "citeRegEx" : "65",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Text compression as a test for artificial intelligence",
      "author" : [ "M.V. Mahoney" ],
      "venue" : "Proceedings of the National Conference on Artificial Intelligence, AAAI, pages 970–970",
      "citeRegEx" : "66",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Potential intelligence: a learning theory approach to description and clinical implication",
      "author" : [ "A.R. Mahrer" ],
      "venue" : "The Journal of General Psychology, 59(1):59–71",
      "citeRegEx" : "67",
      "shortCiteRegEx" : null,
      "year" : 1958
    }, {
      "title" : "Animal-computer interaction: a manifesto",
      "author" : [ "C. Mancini" ],
      "venue" : "Interactions, 18(4):69–73",
      "citeRegEx" : "68",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Psychological evaluation of children who are deaf-blind: An overview with recommendations for practice",
      "author" : [ "H. Mar" ],
      "venue" : "DB-LINK",
      "citeRegEx" : "69",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "A metric for thought: A comparison of p300 latency and reaction time",
      "author" : [ "G. McCarthy", "E. Donchin" ],
      "venue" : "Science, 211(4477):77–80",
      "citeRegEx" : "70",
      "shortCiteRegEx" : null,
      "year" : 1981
    }, {
      "title" : "Is the Turing Test still relevant? A plan for developing the cognitive decathlon to test intelligent embodied behavior",
      "author" : [ "S.T. Mueller" ],
      "venue" : "19th Midwest Artificial Intelligence and Cognitive Science Conference, MAICS",
      "citeRegEx" : "71",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "and Julia M",
      "author" : [ "S.T. Mueller", "M. Jones", "B.S. Minnery" ],
      "venue" : "H. Hiland. The bica cognitive decathlon: A test suite for biologically-inspired cognitive agents. In Proceedings of Behavior Representation in Modeling and Simulation Conference, Norfolk",
      "citeRegEx" : "72",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Adapting the turing test for embodied neurocognitive evaluation of biologically-inspired cognitive agents",
      "author" : [ "S.T. Mueller", "B.S. Minnery" ],
      "venue" : "Proc. 2008 AAAI Fall Symposium on Biologically Inspired Cognitive Architectures",
      "citeRegEx" : "73",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Variations of the Turing Test in the age of internet and virtual reality",
      "author" : [ "F. Neumann", "A. Reichenberger", "M. Ziegler" ],
      "venue" : "KI 2009: Advances in Artificial Intelligence, pages 355–362. Springer",
      "citeRegEx" : "74",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "The Turing Test",
      "author" : [ "G. Oppy", "D.L. Dowe" ],
      "venue" : "Edward N. Zalta, editor, Stanford Encyclopedia of Philosophy. Stanford University",
      "citeRegEx" : "75",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Animal pattern-learning experiments: Some mathematical background",
      "author" : [ "G.K. Pullum", "J. Rogers" ],
      "venue" : "Ms. Radcliffe Institute for Advanced Study/Harvard University",
      "citeRegEx" : "76",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "For universals (but not finite-state learning) visit the zoo",
      "author" : [ "G.K. Pullum", "B.C. Scholz" ],
      "venue" : "Behavioral and Brain Sciences, 32(05):466–467",
      "citeRegEx" : "77",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A review and evaluation of research on the deaf-blind from perceptual",
      "author" : [ "J. Rönnberg", "E. Borg" ],
      "venue" : "communicative, social and rehabilitative perspectives. Scandinavian Audiology, 30(2):67–77",
      "citeRegEx" : "78",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Neural capacity in Mimosa pudica: a review",
      "author" : [ "P.R. Sanberg" ],
      "venue" : "Behavioral biology, 17(4):435–452",
      "citeRegEx" : "79",
      "shortCiteRegEx" : null,
      "year" : 1976
    }, {
      "title" : "A computer program capable of passing I.Q. tests",
      "author" : [ "P. Sanghi", "D.L. Dowe" ],
      "venue" : "Proc. of the Joint International Conference on Cognitive Science, 4th ICCS International Conference on Cognitive Science & 7th ASCS Australasian Society for Cognitive Science",
      "citeRegEx" : "80",
      "shortCiteRegEx" : "80",
      "year" : 2003
    }, {
      "title" : "The truly total Turing Test",
      "author" : [ "P. Schweizer" ],
      "venue" : "Minds and Machines, 8(2):263– 272",
      "citeRegEx" : "81",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Cognition",
      "author" : [ "S.J. Shettleworth" ],
      "venue" : "evolution, and behavior. Oxford University Press",
      "citeRegEx" : "82",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Fundamentals of Comparative Cognition",
      "author" : [ "S.J. Shettleworth", "P. Bloom", "L. Nadel" ],
      "venue" : "Oxford University Press",
      "citeRegEx" : "83",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Human acquisition of concepts for sequential patterns",
      "author" : [ "H.A. Simon", "K. Kotovsky" ],
      "venue" : "Psychological Review, 70(6):534",
      "citeRegEx" : "84",
      "shortCiteRegEx" : null,
      "year" : 1963
    }, {
      "title" : "Refining the cognitive decathlon",
      "author" : [ "R.L. Simpson Jr", "C.R. Twardy" ],
      "venue" : "Proceedings of the 8th Workshop on Performance Metrics for Intelligent Systems, pages 124–131. ACM",
      "citeRegEx" : "85",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Algorithmic probability",
      "author" : [ "R Solomonoff" ],
      "venue" : "heuristic programming and AGI. In Proc. 3rd Conf. on Artificial General Intelligence. Advances in Intelligent Systems Research, volume 10, pages 151–157",
      "citeRegEx" : "86",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Training sequences for mechanized induction",
      "author" : [ "R.J. Solomonoff" ],
      "venue" : "Selforganizing systems, eds., M. Yovit, G. Jacobi, and G. Goldsteins, 7:425– 434",
      "citeRegEx" : "87",
      "shortCiteRegEx" : null,
      "year" : 1962
    }, {
      "title" : "A formal theory of inductive inference",
      "author" : [ "R.J. Solomonoff" ],
      "venue" : "Part I. Information and control, 7(1):1–22",
      "citeRegEx" : "88",
      "shortCiteRegEx" : null,
      "year" : 1964
    }, {
      "title" : "Inductive Inference Research: Status",
      "author" : [ "R.J. Solomonoff" ],
      "venue" : "Spring 1967. RTB 154, Rockford Research, Inc., 140 1/2 Mt. Auburn St., Cambridge, Mass. 02138, July 1967",
      "citeRegEx" : "89",
      "shortCiteRegEx" : null,
      "year" : 1967
    }, {
      "title" : "Perfect training sequences and the costs of corruption - a progress report on induction inference research",
      "author" : [ "R.J. Solomonoff" ],
      "venue" : "Oxbridge Research",
      "citeRegEx" : "90",
      "shortCiteRegEx" : null,
      "year" : 1984
    }, {
      "title" : "Handbook of intelligence",
      "author" : [ "R.J. Sternberg (ed" ],
      "venue" : null,
      "citeRegEx" : "91",
      "shortCiteRegEx" : "91",
      "year" : 2000
    }, {
      "title" : "Quantifying patterns of agent–environment interaction",
      "author" : [ "D. Tarapore", "M. Lungarella", "G. Gómez" ],
      "venue" : "Robotics and Autonomous Systems, 54(2):150–158",
      "citeRegEx" : "92",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Predicting potential intelligence",
      "author" : [ "T.R. Thorp", "A.R. Mahrer" ],
      "venue" : "Journal of Clinical Psychology, 15(3):286–288",
      "citeRegEx" : "93",
      "shortCiteRegEx" : null,
      "year" : 1959
    }, {
      "title" : "Plant intelligence",
      "author" : [ "A. Trewavas" ],
      "venue" : "Naturwissenschaften, 92(9):401–413",
      "citeRegEx" : "94",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Computing machinery and intelligence",
      "author" : [ "A.M. Turing" ],
      "venue" : "Mind, 59:433–460",
      "citeRegEx" : "95",
      "shortCiteRegEx" : null,
      "year" : 1950
    }, {
      "title" : "Psychological evaluation and testing of children who are deaf-blind",
      "author" : [ "M. Vernon" ],
      "venue" : "School Psychology Digest,",
      "citeRegEx" : "96",
      "shortCiteRegEx" : "96",
      "year" : 1979
    }, {
      "title" : "Telling humans and computers apart automatically",
      "author" : [ "L. von Ahn", "M. Blum", "J. Langford" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "97",
      "shortCiteRegEx" : "97",
      "year" : 2004
    }, {
      "title" : "Statistical and Inductive Inference by Minimum Message Length",
      "author" : [ "C.S. Wallace" ],
      "venue" : "Springer-Verlag",
      "citeRegEx" : "98",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "An information measure for classification",
      "author" : [ "C.S. Wallace", "D.M. Boulton" ],
      "venue" : "Computer Journal, 11(2):185–194",
      "citeRegEx" : "99",
      "shortCiteRegEx" : null,
      "year" : 1968
    }, {
      "title" : "Minimum message length and Kolmogorov complexity",
      "author" : [ "C.S. Wallace", "D.L. Dowe" ],
      "venue" : "Computer Journal, 42(4):270–283",
      "citeRegEx" : "100",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "The Reinforcement Learning Competitions",
      "author" : [ "S. Whiteson", "B. Tanner", "A. White" ],
      "venue" : "The AI magazine, 31(2):81–94",
      "citeRegEx" : "101",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Information dynamics of evolved agents",
      "author" : [ "P.L. Williams", "R.D. Beer" ],
      "venue" : "From Animals to Animats 11, pages 38–49. Springer",
      "citeRegEx" : "102",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Intense ultrasonic clicks from echolocating toothed whales do not elicit anti–predator responses or debilitate the squid loligo pealeii",
      "author" : [ "M. Wilson", "R.T. Hanlon", "P.L. Tyack", "P.T. Madsen" ],
      "venue" : "Biology letters, 3(3):225– 227",
      "citeRegEx" : "103",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "A large-scale model of the functioning",
      "author" : [ "E. Yong" ],
      "venue" : "brain. Nature,",
      "citeRegEx" : "104",
      "shortCiteRegEx" : "104",
      "year" : 2012
    }, {
      "title" : "A fuzzy-algorithmic approach to the definition of complex or imprecise concepts",
      "author" : [ "L.A. Zadeh" ],
      "venue" : "International Journal of Man-machine studies, 8(3):249–291",
      "citeRegEx" : "105",
      "shortCiteRegEx" : null,
      "year" : 1976
    }, {
      "title" : "Interspecies semantic communication in two forest primates",
      "author" : [ "K. Zuberbühler" ],
      "venue" : "Proceedings of the Royal Society of London. Series B: Biological Sciences, 267",
      "citeRegEx" : "106",
      "shortCiteRegEx" : null,
      "year" : 1444
    } ],
    "referenceMentions" : [ {
      "referenceID" : 93,
      "context" : "The number and ranges of species claimed to be in this category have been increasing in the past decades, from mammals to molluscs, from swarms to plants [94].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 94,
      "context" : "When moving to the area of artificial intelligence, the use (or just the proposal) of the same test for natural and artificial subjects has been uncommon, apart from Turing’s imitation game [95], and the occasional application of IQ tests to specifically-devoted machines [24, 26, 25, 80, 10, 9].",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 23,
      "context" : "When moving to the area of artificial intelligence, the use (or just the proposal) of the same test for natural and artificial subjects has been uncommon, apart from Turing’s imitation game [95], and the occasional application of IQ tests to specifically-devoted machines [24, 26, 25, 80, 10, 9].",
      "startOffset" : 272,
      "endOffset" : 295
    }, {
      "referenceID" : 25,
      "context" : "When moving to the area of artificial intelligence, the use (or just the proposal) of the same test for natural and artificial subjects has been uncommon, apart from Turing’s imitation game [95], and the occasional application of IQ tests to specifically-devoted machines [24, 26, 25, 80, 10, 9].",
      "startOffset" : 272,
      "endOffset" : 295
    }, {
      "referenceID" : 24,
      "context" : "When moving to the area of artificial intelligence, the use (or just the proposal) of the same test for natural and artificial subjects has been uncommon, apart from Turing’s imitation game [95], and the occasional application of IQ tests to specifically-devoted machines [24, 26, 25, 80, 10, 9].",
      "startOffset" : 272,
      "endOffset" : 295
    }, {
      "referenceID" : 79,
      "context" : "When moving to the area of artificial intelligence, the use (or just the proposal) of the same test for natural and artificial subjects has been uncommon, apart from Turing’s imitation game [95], and the occasional application of IQ tests to specifically-devoted machines [24, 26, 25, 80, 10, 9].",
      "startOffset" : 272,
      "endOffset" : 295
    }, {
      "referenceID" : 9,
      "context" : "When moving to the area of artificial intelligence, the use (or just the proposal) of the same test for natural and artificial subjects has been uncommon, apart from Turing’s imitation game [95], and the occasional application of IQ tests to specifically-devoted machines [24, 26, 25, 80, 10, 9].",
      "startOffset" : 272,
      "endOffset" : 295
    }, {
      "referenceID" : 8,
      "context" : "When moving to the area of artificial intelligence, the use (or just the proposal) of the same test for natural and artificial subjects has been uncommon, apart from Turing’s imitation game [95], and the occasional application of IQ tests to specifically-devoted machines [24, 26, 25, 80, 10, 9].",
      "startOffset" : 272,
      "endOffset" : 295
    }, {
      "referenceID" : 16,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 17,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 48,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 18,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 65,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 33,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 36,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 34,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 60,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 40,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 53,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 20,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 43,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 54,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 61,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 46,
      "context" : "chines has received more attention [17, 18, 49, 19, 66, 34, 37, 35, 61, 41, 54, 21, 44, 55, 62, 47].",
      "startOffset" : 35,
      "endOffset" : 99
    }, {
      "referenceID" : 40,
      "context" : "In this context, [41] introduced the notion of ‘universal (intelligence) test’, as a test that could be administered to any kind of subject, at any speed, and interrupted anytime.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 57,
      "context" : "The notion of a ‘test for all’ soon generated widespread interest [58, 6], even though the proposal highlights some concerns about the difficulty (or even the feasibility) of such an idea, especially if we consider the evolution of comparative psychology in the past century.",
      "startOffset" : 66,
      "endOffset" : 73
    }, {
      "referenceID" : 5,
      "context" : "The notion of a ‘test for all’ soon generated widespread interest [58, 6], even though the proposal highlights some concerns about the difficulty (or even the feasibility) of such an idea, especially if we consider the evolution of comparative psychology in the past century.",
      "startOffset" : 66,
      "endOffset" : 73
    }, {
      "referenceID" : 45,
      "context" : "In fact, a new discipline called universal psychometrics [46, 45] is suggested as an umbrella area of convergence for the general evaluation of cognitive abilities of any kind of subject (with or without universal tests).",
      "startOffset" : 57,
      "endOffset" : 65
    }, {
      "referenceID" : 44,
      "context" : "In fact, a new discipline called universal psychometrics [46, 45] is suggested as an umbrella area of convergence for the general evaluation of cognitive abilities of any kind of subject (with or without universal tests).",
      "startOffset" : 57,
      "endOffset" : 65
    }, {
      "referenceID" : 40,
      "context" : "Nonetheless, it has been recently argued [41, 46, 45] that the approach for universal tests must be based on computation and, more specifically, on algorithmic information theory (or SolomonoffKolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 41,
      "endOffset" : 53
    }, {
      "referenceID" : 45,
      "context" : "Nonetheless, it has been recently argued [41, 46, 45] that the approach for universal tests must be based on computation and, more specifically, on algorithmic information theory (or SolomonoffKolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 41,
      "endOffset" : 53
    }, {
      "referenceID" : 44,
      "context" : "Nonetheless, it has been recently argued [41, 46, 45] that the approach for universal tests must be based on computation and, more specifically, on algorithmic information theory (or SolomonoffKolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 41,
      "endOffset" : 53
    }, {
      "referenceID" : 87,
      "context" : "Nonetheless, it has been recently argued [41, 46, 45] that the approach for universal tests must be based on computation and, more specifically, on algorithmic information theory (or SolomonoffKolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 243,
      "endOffset" : 256
    }, {
      "referenceID" : 98,
      "context" : "Nonetheless, it has been recently argued [41, 46, 45] that the approach for universal tests must be based on computation and, more specifically, on algorithmic information theory (or SolomonoffKolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 243,
      "endOffset" : 256
    }, {
      "referenceID" : 99,
      "context" : "Nonetheless, it has been recently argued [41, 46, 45] that the approach for universal tests must be based on computation and, more specifically, on algorithmic information theory (or SolomonoffKolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 243,
      "endOffset" : 256
    }, {
      "referenceID" : 33,
      "context" : ", [34]), the justification of why IQ tests are not for machines (or for biological systems other than humans) is more cumbersome [20].",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 19,
      "context" : ", [34]), the justification of why IQ tests are not for machines (or for biological systems other than humans) is more cumbersome [20].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 90,
      "context" : "Intelligence [91], in particular, and cognition [82], in more general terms, is nowadays associated with a diversity of species in the natural world.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 81,
      "context" : "Intelligence [91], in particular, and cognition [82], in more general terms, is nowadays associated with a diversity of species in the natural world.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 93,
      "context" : "This diversity goes far beyond humans and the animal kingdom, as intelligence has also been recognised (or claimed) in swarms, plants, fungi, immune systems, bacteria, genome and metabolic systems [94].",
      "startOffset" : 197,
      "endOffset" : 201
    }, {
      "referenceID" : 31,
      "context" : "Some of the arguments in favour of such a diversity of systems showing some kind of intelligent behaviour are based on examples of classical conditioning [32] or some kinds of complex behaviour [2], even though some of these findings and claims have also been disputed [79].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 1,
      "context" : "Some of the arguments in favour of such a diversity of systems showing some kind of intelligent behaviour are based on examples of classical conditioning [32] or some kinds of complex behaviour [2], even though some of these findings and claims have also been disputed [79].",
      "startOffset" : 194,
      "endOffset" : 197
    }, {
      "referenceID" : 78,
      "context" : "Some of the arguments in favour of such a diversity of systems showing some kind of intelligent behaviour are based on examples of classical conditioning [32] or some kinds of complex behaviour [2], even though some of these findings and claims have also been disputed [79].",
      "startOffset" : 269,
      "endOffset" : 273
    }, {
      "referenceID" : 90,
      "context" : ", [91, 8]) is the most mature (and now robust) discipline in terms of intelligence evaluation, but it is also the most anthropocentric one.",
      "startOffset" : 2,
      "endOffset" : 9
    }, {
      "referenceID" : 7,
      "context" : ", [91, 8]) is the most mature (and now robust) discipline in terms of intelligence evaluation, but it is also the most anthropocentric one.",
      "startOffset" : 2,
      "endOffset" : 9
    }, {
      "referenceID" : 81,
      "context" : "When looking at ways of evaluating cognitive abilities in a general way, comparative psychology (and cognition) [82, 83] is the place to look at.",
      "startOffset" : 112,
      "endOffset" : 120
    }, {
      "referenceID" : 82,
      "context" : "When looking at ways of evaluating cognitive abilities in a general way, comparative psychology (and cognition) [82, 83] is the place to look at.",
      "startOffset" : 112,
      "endOffset" : 120
    }, {
      "referenceID" : 6,
      "context" : "2This objection is often responded with statements such as “intelligence is what the intelligence tests measure” [7].",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 94,
      "context" : "Over the past decades, there have been many proposals to evaluate AI artefacts or areas of the discipline: specific tests (Turing Test [95, 75], the total Turing Test [81] and other sensorimotor variations [74], the Bot Prize [51], CAPTCHAs [97], the machine intelligence quotient [105, 5], .",
      "startOffset" : 135,
      "endOffset" : 143
    }, {
      "referenceID" : 74,
      "context" : "Over the past decades, there have been many proposals to evaluate AI artefacts or areas of the discipline: specific tests (Turing Test [95, 75], the total Turing Test [81] and other sensorimotor variations [74], the Bot Prize [51], CAPTCHAs [97], the machine intelligence quotient [105, 5], .",
      "startOffset" : 135,
      "endOffset" : 143
    }, {
      "referenceID" : 80,
      "context" : "Over the past decades, there have been many proposals to evaluate AI artefacts or areas of the discipline: specific tests (Turing Test [95, 75], the total Turing Test [81] and other sensorimotor variations [74], the Bot Prize [51], CAPTCHAs [97], the machine intelligence quotient [105, 5], .",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 73,
      "context" : "Over the past decades, there have been many proposals to evaluate AI artefacts or areas of the discipline: specific tests (Turing Test [95, 75], the total Turing Test [81] and other sensorimotor variations [74], the Bot Prize [51], CAPTCHAs [97], the machine intelligence quotient [105, 5], .",
      "startOffset" : 206,
      "endOffset" : 210
    }, {
      "referenceID" : 50,
      "context" : "Over the past decades, there have been many proposals to evaluate AI artefacts or areas of the discipline: specific tests (Turing Test [95, 75], the total Turing Test [81] and other sensorimotor variations [74], the Bot Prize [51], CAPTCHAs [97], the machine intelligence quotient [105, 5], .",
      "startOffset" : 226,
      "endOffset" : 230
    }, {
      "referenceID" : 96,
      "context" : "Over the past decades, there have been many proposals to evaluate AI artefacts or areas of the discipline: specific tests (Turing Test [95, 75], the total Turing Test [81] and other sensorimotor variations [74], the Bot Prize [51], CAPTCHAs [97], the machine intelligence quotient [105, 5], .",
      "startOffset" : 241,
      "endOffset" : 245
    }, {
      "referenceID" : 104,
      "context" : "Over the past decades, there have been many proposals to evaluate AI artefacts or areas of the discipline: specific tests (Turing Test [95, 75], the total Turing Test [81] and other sensorimotor variations [74], the Bot Prize [51], CAPTCHAs [97], the machine intelligence quotient [105, 5], .",
      "startOffset" : 281,
      "endOffset" : 289
    }, {
      "referenceID" : 4,
      "context" : "Over the past decades, there have been many proposals to evaluate AI artefacts or areas of the discipline: specific tests (Turing Test [95, 75], the total Turing Test [81] and other sensorimotor variations [74], the Bot Prize [51], CAPTCHAs [97], the machine intelligence quotient [105, 5], .",
      "startOffset" : 281,
      "endOffset" : 289
    }, {
      "referenceID" : 100,
      "context" : "), competitions (RL competition [101], Robocup [57], general game playing competition [30], planning competition [64], .",
      "startOffset" : 32,
      "endOffset" : 37
    }, {
      "referenceID" : 56,
      "context" : "), competitions (RL competition [101], Robocup [57], general game playing competition [30], planning competition [64], .",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 29,
      "context" : "), competitions (RL competition [101], Robocup [57], general game playing competition [30], planning competition [64], .",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 63,
      "context" : "), competitions (RL competition [101], Robocup [57], general game playing competition [30], planning competition [64], .",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 12,
      "context" : ") and landmarks (Deep blue [13], Watson [28]).",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 27,
      "context" : ") and landmarks (Deep blue [13], Watson [28]).",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 23,
      "context" : "The roots can be traced to the development and understanding of cognitive models, such as the works of Evans [24, 26, 25] and, indirectly, those of Simon and Kotovsky [84, 59].",
      "startOffset" : 109,
      "endOffset" : 121
    }, {
      "referenceID" : 25,
      "context" : "The roots can be traced to the development and understanding of cognitive models, such as the works of Evans [24, 26, 25] and, indirectly, those of Simon and Kotovsky [84, 59].",
      "startOffset" : 109,
      "endOffset" : 121
    }, {
      "referenceID" : 24,
      "context" : "The roots can be traced to the development and understanding of cognitive models, such as the works of Evans [24, 26, 25] and, indirectly, those of Simon and Kotovsky [84, 59].",
      "startOffset" : 109,
      "endOffset" : 121
    }, {
      "referenceID" : 83,
      "context" : "The roots can be traced to the development and understanding of cognitive models, such as the works of Evans [24, 26, 25] and, indirectly, those of Simon and Kotovsky [84, 59].",
      "startOffset" : 167,
      "endOffset" : 175
    }, {
      "referenceID" : 58,
      "context" : "The roots can be traced to the development and understanding of cognitive models, such as the works of Evans [24, 26, 25] and, indirectly, those of Simon and Kotovsky [84, 59].",
      "startOffset" : 167,
      "endOffset" : 175
    }, {
      "referenceID" : 45,
      "context" : "Nowadays, there is a field known as “psychometric AI” —not to be confused with universal psychometrics [46, 45]—, where IQ tests are used to improve and evaluate artificial intelligence systems.",
      "startOffset" : 103,
      "endOffset" : 111
    }, {
      "referenceID" : 44,
      "context" : "Nowadays, there is a field known as “psychometric AI” —not to be confused with universal psychometrics [46, 45]—, where IQ tests are used to improve and evaluate artificial intelligence systems.",
      "startOffset" : 103,
      "endOffset" : 111
    }, {
      "referenceID" : 14,
      "context" : "Nonetheless, the most explicit vindication of the use of IQ tests for machines has been recently made by Detterman, editor of the Intelligence Journal, as a response [15] to specific domain tests and landmarks (such as Watson).",
      "startOffset" : 166,
      "endOffset" : 170
    }, {
      "referenceID" : 19,
      "context" : "4]) but most especially for machines (see [20] for a full discussion).",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 79,
      "context" : "The main argument is that it is possible to find or construct non-intelligent agents that can score well on classical IQ tests, as has been demonstrated with very small programs (in 2003, Sanghi and Dowe implemented a small program in Perl which could score relatively well on many IQ tests [80]).",
      "startOffset" : 291,
      "endOffset" : 295
    }, {
      "referenceID" : 21,
      "context" : ", [22, 104]).",
      "startOffset" : 2,
      "endOffset" : 11
    }, {
      "referenceID" : 103,
      "context" : ", [22, 104]).",
      "startOffset" : 2,
      "endOffset" : 11
    }, {
      "referenceID" : 104,
      "context" : "It is not clear either that a generalisation or revision of current IQ tests to make them more general is a sound pathway, as we could end up with tests that work with a specific population or in terms of a current technology, but need to be updated recurrently as the population is enlarged and AI technology improves (as happens with the notion of Machine Intelligence Quotient [105, 5] or, more blatantly, with CAPTCHAs [97]).",
      "startOffset" : 380,
      "endOffset" : 388
    }, {
      "referenceID" : 4,
      "context" : "It is not clear either that a generalisation or revision of current IQ tests to make them more general is a sound pathway, as we could end up with tests that work with a specific population or in terms of a current technology, but need to be updated recurrently as the population is enlarged and AI technology improves (as happens with the notion of Machine Intelligence Quotient [105, 5] or, more blatantly, with CAPTCHAs [97]).",
      "startOffset" : 380,
      "endOffset" : 388
    }, {
      "referenceID" : 96,
      "context" : "It is not clear either that a generalisation or revision of current IQ tests to make them more general is a sound pathway, as we could end up with tests that work with a specific population or in terms of a current technology, but need to be updated recurrently as the population is enlarged and AI technology improves (as happens with the notion of Machine Intelligence Quotient [105, 5] or, more blatantly, with CAPTCHAs [97]).",
      "startOffset" : 423,
      "endOffset" : 427
    }, {
      "referenceID" : 33,
      "context" : "Figure 1: Examples of series of Kt complexity 9, 12, and 14 used in the C-test [34].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 13,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 16,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 178,
      "endOffset" : 206
    }, {
      "referenceID" : 17,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 178,
      "endOffset" : 206
    }, {
      "referenceID" : 48,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 178,
      "endOffset" : 206
    }, {
      "referenceID" : 18,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 178,
      "endOffset" : 206
    }, {
      "referenceID" : 33,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 178,
      "endOffset" : 206
    }, {
      "referenceID" : 36,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 178,
      "endOffset" : 206
    }, {
      "referenceID" : 34,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 178,
      "endOffset" : 206
    }, {
      "referenceID" : 87,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 382,
      "endOffset" : 395
    }, {
      "referenceID" : 98,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 382,
      "endOffset" : 395
    }, {
      "referenceID" : 99,
      "context" : "The relevance of (algorithmic) information theory (AIT), or Kolmogorov complexity, to this goal was first hinted at by Chaitin [14] before being independently elaborated upon in [17, 18, 49, 19, 34, 37, 35] with a series of tests noting the relevance and importance of the notions of (algorithmic) information theory (or Solomonoff-Kolmogorov complexity) and (two-part) compression [88, 99, 100].",
      "startOffset" : 382,
      "endOffset" : 395
    }, {
      "referenceID" : 60,
      "context" : "These works were followed some years later by Legg & Hutter [61], who built upon re-inforcement learning by also using AIT, putting a Solomonoff-weighted prior distribution over single-agent environments.",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 49,
      "context" : "There are several issues about the feasibility and exact interpretation of such a measure, as raised by [50, 41], among others.",
      "startOffset" : 104,
      "endOffset" : 112
    }, {
      "referenceID" : 40,
      "context" : "There are several issues about the feasibility and exact interpretation of such a measure, as raised by [50, 41], among others.",
      "startOffset" : 104,
      "endOffset" : 112
    }, {
      "referenceID" : 60,
      "context" : "Pursuing this universality, taking into account the limitations of [61] and other previous approaches, [41] introduced an adaptive test which was anytime (able to be interrupted at anytime giving a more accurate result as more time is given) and also (supposedly) universal —i.",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 40,
      "context" : "Pursuing this universality, taking into account the limitations of [61] and other previous approaches, [41] introduced an adaptive test which was anytime (able to be interrupted at anytime giving a more accurate result as more time is given) and also (supposedly) universal —i.",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 60,
      "context" : "While also based on algorithmic information theory, there are some distinctive features of this test, which distinguishes it from [61].",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 53,
      "context" : "As a first proof-of-concept, [54, 55] attempted an implementation of the test using the environment class introduced in [38].",
      "startOffset" : 29,
      "endOffset" : 37
    }, {
      "referenceID" : 54,
      "context" : "As a first proof-of-concept, [54, 55] attempted an implementation of the test using the environment class introduced in [38].",
      "startOffset" : 29,
      "endOffset" : 37
    }, {
      "referenceID" : 37,
      "context" : "As a first proof-of-concept, [54, 55] attempted an implementation of the test using the environment class introduced in [38].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 20,
      "context" : "There are several possible explanations for this [21, 44, 47, 53, 56, 48]: it was a prototype, it was not adaptive as the original proposal [41], there was no noise, patterns had low complexity, the environment class was quite limited, no social behaviour or other factors were evaluated, to name a few.",
      "startOffset" : 49,
      "endOffset" : 73
    }, {
      "referenceID" : 43,
      "context" : "There are several possible explanations for this [21, 44, 47, 53, 56, 48]: it was a prototype, it was not adaptive as the original proposal [41], there was no noise, patterns had low complexity, the environment class was quite limited, no social behaviour or other factors were evaluated, to name a few.",
      "startOffset" : 49,
      "endOffset" : 73
    }, {
      "referenceID" : 46,
      "context" : "There are several possible explanations for this [21, 44, 47, 53, 56, 48]: it was a prototype, it was not adaptive as the original proposal [41], there was no noise, patterns had low complexity, the environment class was quite limited, no social behaviour or other factors were evaluated, to name a few.",
      "startOffset" : 49,
      "endOffset" : 73
    }, {
      "referenceID" : 52,
      "context" : "There are several possible explanations for this [21, 44, 47, 53, 56, 48]: it was a prototype, it was not adaptive as the original proposal [41], there was no noise, patterns had low complexity, the environment class was quite limited, no social behaviour or other factors were evaluated, to name a few.",
      "startOffset" : 49,
      "endOffset" : 73
    }, {
      "referenceID" : 55,
      "context" : "There are several possible explanations for this [21, 44, 47, 53, 56, 48]: it was a prototype, it was not adaptive as the original proposal [41], there was no noise, patterns had low complexity, the environment class was quite limited, no social behaviour or other factors were evaluated, to name a few.",
      "startOffset" : 49,
      "endOffset" : 73
    }, {
      "referenceID" : 47,
      "context" : "There are several possible explanations for this [21, 44, 47, 53, 56, 48]: it was a prototype, it was not adaptive as the original proposal [41], there was no noise, patterns had low complexity, the environment class was quite limited, no social behaviour or other factors were evaluated, to name a few.",
      "startOffset" : 49,
      "endOffset" : 73
    }, {
      "referenceID" : 40,
      "context" : "There are several possible explanations for this [21, 44, 47, 53, 56, 48]: it was a prototype, it was not adaptive as the original proposal [41], there was no noise, patterns had low complexity, the environment class was quite limited, no social behaviour or other factors were evaluated, to name a few.",
      "startOffset" : 140,
      "endOffset" : 144
    }, {
      "referenceID" : 30,
      "context" : "This computational approach is now also present in comparative and animal cognition, and particularly in animal evolutionary linguistics, constructing tasks about the kind of grammars (regular, context-free or contextual) several species are able to recognise [31, 76, 33, 23, 77].",
      "startOffset" : 260,
      "endOffset" : 280
    }, {
      "referenceID" : 75,
      "context" : "This computational approach is now also present in comparative and animal cognition, and particularly in animal evolutionary linguistics, constructing tasks about the kind of grammars (regular, context-free or contextual) several species are able to recognise [31, 76, 33, 23, 77].",
      "startOffset" : 260,
      "endOffset" : 280
    }, {
      "referenceID" : 32,
      "context" : "This computational approach is now also present in comparative and animal cognition, and particularly in animal evolutionary linguistics, constructing tasks about the kind of grammars (regular, context-free or contextual) several species are able to recognise [31, 76, 33, 23, 77].",
      "startOffset" : 260,
      "endOffset" : 280
    }, {
      "referenceID" : 22,
      "context" : "This computational approach is now also present in comparative and animal cognition, and particularly in animal evolutionary linguistics, constructing tasks about the kind of grammars (regular, context-free or contextual) several species are able to recognise [31, 76, 33, 23, 77].",
      "startOffset" : 260,
      "endOffset" : 280
    }, {
      "referenceID" : 76,
      "context" : "This computational approach is now also present in comparative and animal cognition, and particularly in animal evolutionary linguistics, constructing tasks about the kind of grammars (regular, context-free or contextual) several species are able to recognise [31, 76, 33, 23, 77].",
      "startOffset" : 260,
      "endOffset" : 280
    }, {
      "referenceID" : 45,
      "context" : "One possible mathematical way of defining an interface is by the notion of bijection, as done in [46, 45].",
      "startOffset" : 97,
      "endOffset" : 105
    }, {
      "referenceID" : 44,
      "context" : "One possible mathematical way of defining an interface is by the notion of bijection, as done in [46, 45].",
      "startOffset" : 97,
      "endOffset" : 105
    }, {
      "referenceID" : 53,
      "context" : "For instance, Figure 3 shows two different interfaces for the test developed in [54, 55, 56].",
      "startOffset" : 80,
      "endOffset" : 92
    }, {
      "referenceID" : 54,
      "context" : "For instance, Figure 3 shows two different interfaces for the test developed in [54, 55, 56].",
      "startOffset" : 80,
      "endOffset" : 92
    }, {
      "referenceID" : 55,
      "context" : "For instance, Figure 3 shows two different interfaces for the test developed in [54, 55, 56].",
      "startOffset" : 80,
      "endOffset" : 92
    }, {
      "referenceID" : 53,
      "context" : "Figure 3: Two possible interfaces for the test in [54].",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 93,
      "context" : "In fact, these interfaces are frequently the key to discover abilities in these systems [94][32][2][79] that were considered non-existent only a few years ago.",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 31,
      "context" : "In fact, these interfaces are frequently the key to discover abilities in these systems [94][32][2][79] that were considered non-existent only a few years ago.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 1,
      "context" : "In fact, these interfaces are frequently the key to discover abilities in these systems [94][32][2][79] that were considered non-existent only a few years ago.",
      "startOffset" : 96,
      "endOffset" : 99
    }, {
      "referenceID" : 78,
      "context" : "In fact, these interfaces are frequently the key to discover abilities in these systems [94][32][2][79] that were considered non-existent only a few years ago.",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 2,
      "context" : "Humans are not an exception here either, as a great amount of imagination is needed to devise some tests for disabled people, especially for deaf-blinded, using tactile interfaces [3] or other approaches [69, 96, 78].",
      "startOffset" : 180,
      "endOffset" : 183
    }, {
      "referenceID" : 68,
      "context" : "Humans are not an exception here either, as a great amount of imagination is needed to devise some tests for disabled people, especially for deaf-blinded, using tactile interfaces [3] or other approaches [69, 96, 78].",
      "startOffset" : 204,
      "endOffset" : 216
    }, {
      "referenceID" : 95,
      "context" : "Humans are not an exception here either, as a great amount of imagination is needed to devise some tests for disabled people, especially for deaf-blinded, using tactile interfaces [3] or other approaches [69, 96, 78].",
      "startOffset" : 204,
      "endOffset" : 216
    }, {
      "referenceID" : 77,
      "context" : "Humans are not an exception here either, as a great amount of imagination is needed to devise some tests for disabled people, especially for deaf-blinded, using tactile interfaces [3] or other approaches [69, 96, 78].",
      "startOffset" : 204,
      "endOffset" : 216
    }, {
      "referenceID" : 67,
      "context" : "4Some of these ideas are being used in better interfaces across species, but also in a pursue of better interfaces between computers and animals [68].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 11,
      "context" : "For instance, plants are now claimed to do some kind of cognition [12], but their time-scale is much slower than those of animals.",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 40,
      "context" : "The anytime test introduced in [41] arguably addresses part of the issue of time adaptively by starting with a very fast interaction rate and slowing it down as the results from the agent are not good.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 40,
      "context" : "While this is a first approach for making a universal test adaptive on time, there are more issues in terms of time-scale than those reflected by [41].",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 40,
      "context" : "This is in fact what [41] adapts.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 69,
      "context" : "On occasions we want a cognitive ability to consider time, such as measuring ‘reaction time’ [70].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 102,
      "context" : "For instance, figure 4 [103, 65] shows how a sound signal can carry many different types of information at several resolutions.",
      "startOffset" : 23,
      "endOffset" : 32
    }, {
      "referenceID" : 64,
      "context" : "For instance, figure 4 [103, 65] shows how a sound signal can carry many different types of information at several resolutions.",
      "startOffset" : 23,
      "endOffset" : 32
    }, {
      "referenceID" : 51,
      "context" : "7As an example of humans requiring more time than some animals, Ayumu the chimpanzee [52] is able to note the locations of the numbers 1 to 9 (of which there are 9! = 362880 possibilities) after only 60 milliseconds observation time.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 28,
      "context" : ", [29]), and can also be referred to the cognitive structures and constructs the agent is creating all along its life [36].",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 35,
      "context" : ", [29]), and can also be referred to the cognitive structures and constructs the agent is creating all along its life [36].",
      "startOffset" : 118,
      "endOffset" : 122
    }, {
      "referenceID" : 60,
      "context" : "where Υ(π,M, θ, τ) is any test on a family of tasks that is applicable to an agent π during time τ (for instance, time-bounded adaptations of [61] or some of the non-adaptive versions introduced in [41] or implemented in [54]).",
      "startOffset" : 142,
      "endOffset" : 146
    }, {
      "referenceID" : 40,
      "context" : "where Υ(π,M, θ, τ) is any test on a family of tasks that is applicable to an agent π during time τ (for instance, time-bounded adaptations of [61] or some of the non-adaptive versions introduced in [41] or implemented in [54]).",
      "startOffset" : 198,
      "endOffset" : 202
    }, {
      "referenceID" : 53,
      "context" : "where Υ(π,M, θ, τ) is any test on a family of tasks that is applicable to an agent π during time τ (for instance, time-bounded adaptations of [61] or some of the non-adaptive versions introduced in [41] or implemented in [54]).",
      "startOffset" : 221,
      "endOffset" : 225
    }, {
      "referenceID" : 60,
      "context" : "One possibility is to weight by task probability: Υ(π,M, θ, τ) = Υ(π, μ, θ, τ)p(μ) (as in [61]), while another possibility is to define task difficulty and get the result in terms of this difficulty, as in [49, 34, 46, 45].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 48,
      "context" : "One possibility is to weight by task probability: Υ(π,M, θ, τ) = Υ(π, μ, θ, τ)p(μ) (as in [61]), while another possibility is to define task difficulty and get the result in terms of this difficulty, as in [49, 34, 46, 45].",
      "startOffset" : 206,
      "endOffset" : 222
    }, {
      "referenceID" : 33,
      "context" : "One possibility is to weight by task probability: Υ(π,M, θ, τ) = Υ(π, μ, θ, τ)p(μ) (as in [61]), while another possibility is to define task difficulty and get the result in terms of this difficulty, as in [49, 34, 46, 45].",
      "startOffset" : 206,
      "endOffset" : 222
    }, {
      "referenceID" : 45,
      "context" : "One possibility is to weight by task probability: Υ(π,M, θ, τ) = Υ(π, μ, θ, τ)p(μ) (as in [61]), while another possibility is to define task difficulty and get the result in terms of this difficulty, as in [49, 34, 46, 45].",
      "startOffset" : 206,
      "endOffset" : 222
    }, {
      "referenceID" : 44,
      "context" : "One possibility is to weight by task probability: Υ(π,M, θ, τ) = Υ(π, μ, θ, τ)p(μ) (as in [61]), while another possibility is to define task difficulty and get the result in terms of this difficulty, as in [49, 34, 46, 45].",
      "startOffset" : 206,
      "endOffset" : 222
    }, {
      "referenceID" : 40,
      "context" : "This can be seen as an extension/generalisation of [41] (and ultimately of [61] as well, with the appropriate modifications).",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 60,
      "context" : "This can be seen as an extension/generalisation of [41] (and ultimately of [61] as well, with the appropriate modifications).",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 39,
      "context" : ", [40]).",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 37,
      "context" : "This does not necessary mean that the environment has a spatial configuration where they can ‘move’, as in [38], but just that the possibility of interaction exists (e.",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 46,
      "context" : ", an environment could just be a series of communication channels as in the matching pennies game, the Turing Test or any configuration in between [47]).",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 105,
      "context" : "The communication channel may be extremely original, as we can see in many examples of intraor inter-species communication, from primates [106] to bacteria [27].",
      "startOffset" : 138,
      "endOffset" : 143
    }, {
      "referenceID" : 26,
      "context" : "The communication channel may be extremely original, as we can see in many examples of intraor inter-species communication, from primates [106] to bacteria [27].",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 91,
      "context" : "In order to automate this process (at least partially), there are several information-theoretic options that could be used to detect (and spur) agent-environment or agent-agent interaction [92, 102], but other approaches exist (relational dynamics, information structure, and many others).",
      "startOffset" : 189,
      "endOffset" : 198
    }, {
      "referenceID" : 101,
      "context" : "In order to automate this process (at least partially), there are several information-theoretic options that could be used to detect (and spur) agent-environment or agent-agent interaction [92, 102], but other approaches exist (relational dynamics, information structure, and many others).",
      "startOffset" : 189,
      "endOffset" : 198
    }, {
      "referenceID" : 87,
      "context" : "The interpreting of such a message would presumably be best done by the (Bayesian) algorithmic information-theoretic approaches of Solomonoff prediction [88] and/or Minimum Message Length (MML) [99, 100, 98].",
      "startOffset" : 153,
      "endOffset" : 157
    }, {
      "referenceID" : 98,
      "context" : "The interpreting of such a message would presumably be best done by the (Bayesian) algorithmic information-theoretic approaches of Solomonoff prediction [88] and/or Minimum Message Length (MML) [99, 100, 98].",
      "startOffset" : 194,
      "endOffset" : 207
    }, {
      "referenceID" : 99,
      "context" : "The interpreting of such a message would presumably be best done by the (Bayesian) algorithmic information-theoretic approaches of Solomonoff prediction [88] and/or Minimum Message Length (MML) [99, 100, 98].",
      "startOffset" : 194,
      "endOffset" : 207
    }, {
      "referenceID" : 97,
      "context" : "The interpreting of such a message would presumably be best done by the (Bayesian) algorithmic information-theoretic approaches of Solomonoff prediction [88] and/or Minimum Message Length (MML) [99, 100, 98].",
      "startOffset" : 194,
      "endOffset" : 207
    }, {
      "referenceID" : 15,
      "context" : "In terms of what to put in such a message or how to decode such a message, Wallace (private communication) [16] considered explaining arithmetic, then eventually Turing machines, the eventually the Lyman series and Hydrogen, etc.",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 86,
      "context" : "Solomonoff likewise wrote much about training sequences [87, 90, 86][89, sec.",
      "startOffset" : 56,
      "endOffset" : 68
    }, {
      "referenceID" : 89,
      "context" : "Solomonoff likewise wrote much about training sequences [87, 90, 86][89, sec.",
      "startOffset" : 56,
      "endOffset" : 68
    }, {
      "referenceID" : 85,
      "context" : "Solomonoff likewise wrote much about training sequences [87, 90, 86][89, sec.",
      "startOffset" : 56,
      "endOffset" : 68
    }, {
      "referenceID" : 41,
      "context" : "11Although related, we should distinguish the goal of training sequence (turn a nonintelligent, possibly Turing-complete system into an intelligent system (see also [42, 43]) from the conception of a sequence such that it can be self-understood without common previous knowledge.",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 42,
      "context" : "11Although related, we should distinguish the goal of training sequence (turn a nonintelligent, possibly Turing-complete system into an intelligent system (see also [42, 43]) from the conception of a sequence such that it can be self-understood without common previous knowledge.",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 3,
      "context" : "For instance, these embodied, minimal cognitive agents have even been found (as gliders) in very minimalistic environments such as Conway’s game of life [4].",
      "startOffset" : 153,
      "endOffset" : 156
    }, {
      "referenceID" : 0,
      "context" : "For instance, once an interactive system is found we could first determine whether we have a cognitive system, adapting some of the tasks of the cognitive decathlon and related approaches [1, 73, 72, 71, 85, 60, 11, 73] (although many of these approaches are focussed on evaluating cognitive architectures rather than evaluating actual cognitive systems through multi-factorial scores).",
      "startOffset" : 188,
      "endOffset" : 219
    }, {
      "referenceID" : 72,
      "context" : "For instance, once an interactive system is found we could first determine whether we have a cognitive system, adapting some of the tasks of the cognitive decathlon and related approaches [1, 73, 72, 71, 85, 60, 11, 73] (although many of these approaches are focussed on evaluating cognitive architectures rather than evaluating actual cognitive systems through multi-factorial scores).",
      "startOffset" : 188,
      "endOffset" : 219
    }, {
      "referenceID" : 71,
      "context" : "For instance, once an interactive system is found we could first determine whether we have a cognitive system, adapting some of the tasks of the cognitive decathlon and related approaches [1, 73, 72, 71, 85, 60, 11, 73] (although many of these approaches are focussed on evaluating cognitive architectures rather than evaluating actual cognitive systems through multi-factorial scores).",
      "startOffset" : 188,
      "endOffset" : 219
    }, {
      "referenceID" : 70,
      "context" : "For instance, once an interactive system is found we could first determine whether we have a cognitive system, adapting some of the tasks of the cognitive decathlon and related approaches [1, 73, 72, 71, 85, 60, 11, 73] (although many of these approaches are focussed on evaluating cognitive architectures rather than evaluating actual cognitive systems through multi-factorial scores).",
      "startOffset" : 188,
      "endOffset" : 219
    }, {
      "referenceID" : 84,
      "context" : "For instance, once an interactive system is found we could first determine whether we have a cognitive system, adapting some of the tasks of the cognitive decathlon and related approaches [1, 73, 72, 71, 85, 60, 11, 73] (although many of these approaches are focussed on evaluating cognitive architectures rather than evaluating actual cognitive systems through multi-factorial scores).",
      "startOffset" : 188,
      "endOffset" : 219
    }, {
      "referenceID" : 59,
      "context" : "For instance, once an interactive system is found we could first determine whether we have a cognitive system, adapting some of the tasks of the cognitive decathlon and related approaches [1, 73, 72, 71, 85, 60, 11, 73] (although many of these approaches are focussed on evaluating cognitive architectures rather than evaluating actual cognitive systems through multi-factorial scores).",
      "startOffset" : 188,
      "endOffset" : 219
    }, {
      "referenceID" : 10,
      "context" : "For instance, once an interactive system is found we could first determine whether we have a cognitive system, adapting some of the tasks of the cognitive decathlon and related approaches [1, 73, 72, 71, 85, 60, 11, 73] (although many of these approaches are focussed on evaluating cognitive architectures rather than evaluating actual cognitive systems through multi-factorial scores).",
      "startOffset" : 188,
      "endOffset" : 219
    }, {
      "referenceID" : 72,
      "context" : "For instance, once an interactive system is found we could first determine whether we have a cognitive system, adapting some of the tasks of the cognitive decathlon and related approaches [1, 73, 72, 71, 85, 60, 11, 73] (although many of these approaches are focussed on evaluating cognitive architectures rather than evaluating actual cognitive systems through multi-factorial scores).",
      "startOffset" : 188,
      "endOffset" : 219
    }, {
      "referenceID" : 40,
      "context" : "In addition, there is also another factor that we need to consider: how the universal test is devised, depending on whether the test is conceived in a passive (as classical paper and pencil IQ tests), interactive (as games, computerised adaptive testing, the anytime test [41] or any generalisation of figure 5) or ultimately intelligent way.",
      "startOffset" : 272,
      "endOffset" : 276
    }, {
      "referenceID" : 66,
      "context" : "Moreover, this under-estimation also happens in human psychometrics, where the term “potential intelligence” is applied to “test potential” [67, 93, 63], (not to be confused with the term “potential intelligence” applied to the ability of becoming intelligent [42, 43]).",
      "startOffset" : 140,
      "endOffset" : 152
    }, {
      "referenceID" : 92,
      "context" : "Moreover, this under-estimation also happens in human psychometrics, where the term “potential intelligence” is applied to “test potential” [67, 93, 63], (not to be confused with the term “potential intelligence” applied to the ability of becoming intelligent [42, 43]).",
      "startOffset" : 140,
      "endOffset" : 152
    }, {
      "referenceID" : 62,
      "context" : "Moreover, this under-estimation also happens in human psychometrics, where the term “potential intelligence” is applied to “test potential” [67, 93, 63], (not to be confused with the term “potential intelligence” applied to the ability of becoming intelligent [42, 43]).",
      "startOffset" : 140,
      "endOffset" : 152
    }, {
      "referenceID" : 41,
      "context" : "Moreover, this under-estimation also happens in human psychometrics, where the term “potential intelligence” is applied to “test potential” [67, 93, 63], (not to be confused with the term “potential intelligence” applied to the ability of becoming intelligent [42, 43]).",
      "startOffset" : 260,
      "endOffset" : 268
    }, {
      "referenceID" : 42,
      "context" : "Moreover, this under-estimation also happens in human psychometrics, where the term “potential intelligence” is applied to “test potential” [67, 93, 63], (not to be confused with the term “potential intelligence” applied to the ability of becoming intelligent [42, 43]).",
      "startOffset" : 260,
      "endOffset" : 268
    }, {
      "referenceID" : 86,
      "context" : "In fact, there are training sequences [87, 90, 86][89, sec.",
      "startOffset" : 38,
      "endOffset" : 50
    }, {
      "referenceID" : 89,
      "context" : "In fact, there are training sequences [87, 90, 86][89, sec.",
      "startOffset" : 38,
      "endOffset" : 50
    }, {
      "referenceID" : 85,
      "context" : "In fact, there are training sequences [87, 90, 86][89, sec.",
      "startOffset" : 38,
      "endOffset" : 50
    }, {
      "referenceID" : 41,
      "context" : "7(dolphin talk)] for any universal Turing machine such that the machine becomes intelligent (in fact, as much intelligent as we want, as it can simulate any behaviour, as shown and fully discussed in [42, 43]).",
      "startOffset" : 200,
      "endOffset" : 208
    }, {
      "referenceID" : 42,
      "context" : "7(dolphin talk)] for any universal Turing machine such that the machine becomes intelligent (in fact, as much intelligent as we want, as it can simulate any behaviour, as shown and fully discussed in [42, 43]).",
      "startOffset" : 200,
      "endOffset" : 208
    }, {
      "referenceID" : 41,
      "context" : "If the agent is trained (or just domesticated), the test mixes actual and potential intelligence (in the sense of [42, 43]), and the reliability and validity of the test are highly compromised.",
      "startOffset" : 114,
      "endOffset" : 122
    }, {
      "referenceID" : 42,
      "context" : "If the agent is trained (or just domesticated), the test mixes actual and potential intelligence (in the sense of [42, 43]), and the reliability and validity of the test are highly compromised.",
      "startOffset" : 114,
      "endOffset" : 122
    }, {
      "referenceID" : 38,
      "context" : ", cellular automata, multi-agent environments or hybrids [39]) or situations where we have part of the information of the hierarchy shown in Table 1, we may still establish universal intelligence tests for those niches.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 39,
      "context" : ", where we may find agents whose intelligence is completely unknown [40].",
      "startOffset" : 68,
      "endOffset" : 72
    } ],
    "year" : 2013,
    "abstractText" : "The analysis of the adaptive behaviour of many different kinds of systems such as humans, animals and machines, requires more general ways of assessing their cognitive abilities. This need is strengthened by increasingly more tasks being analysed for and completed by a wider diversity of systems, including swarms and hybrids. The notion of universal test has recently emerged in the context of machine intelligence evaluation as a way to define and use the same cognitive test for a variety of systems, using some principled tasks and adapting the interface to each particular subject. However, how far can universal tests be taken? This paper analyses this question in terms of subjects, environments, space-time resolution, rewards and interfaces. This leads to a number of findings, insights and caveats, according to several levels where universal tests may be progressively more difficult to conceive, implement and administer. One of the most significant contributions is given by the realisation that more universal tests are defined as maximisations of less universal tests for a variety of configurations. This means that universal tests must be necessarily adaptive.",
    "creator" : "LaTeX with hyperref package"
  }
}