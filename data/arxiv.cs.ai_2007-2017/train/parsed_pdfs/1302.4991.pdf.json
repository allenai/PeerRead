{
  "name" : "1302.4991.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Optimization of Inter-Subnet Belief Updating in Multiply Sectioned Bayesian Networks",
    "authors" : [ ],
    "emails" : [ "yxiang@cs.uregina.ca" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Recent developments show that Multiply Sectioned Bayesian Networks (MSBNs) can be used for diagnosis of natural systems as well as for model-based diagnosis of artificial systems. They can be applied to single-agent oriented reasoning systems as well as multi agent distributed reasoning systems.\nBelief propagation between a pair of subnets plays a central role in maintenance of global consistency in a MSBN. This paper studies the operation UpdateBelief, presented orig inally with MSBNs, for inter-subnet propaga tion. We analyze how the operation achieves its intended functionality, which provides hints for improving its efficiency.\nNew versions of UpdateBelief are then de fined that reduce the computation time for inter-subnet propagation. One of them is optimal in the sense that the minimum amount of computation for coordinating multi-linkage belief propagation is required. The optimization problem is solved through the solution of a graph-theoretic problem: the minimum weight open tour in a tree.\nKeywords: Bayesian networks, Belief propa gation, multi-agent reasoning.\n1 Introduction\nMultiply sectioned Bayesian networks (MSBNs) [9] is an extension of Bayesian networks (BNs) [4, 3, 1], orig inally developed for modular knowledge representation and more efficient inference computation in large ap plication domains [7]. The basic assumption of MS BNs is localization [9, 8, 7]: Subdomains of the tar get domain are loosely coupled such that evidence and queries focus on one subdomain for a period of time\nbefore shifting to a different subdomain. Based on lo calization, a MSBN represents a large domain by a set of interrelated Bayesian subnets, such that inference computation can be confined within one subnet at a time.\nTwo recent developments in probabilistic reasoning us ing BNs widened the scope of potential applicability of the MSBN representation/inference formalism.\nSrinivas [5] proposed a hierarchical approach for model-based diagnoses. The representation formalism used can be viewed as a special case of MSBNs. For example, the set of input nodes I, output node 0, mode node M, and dummy node D [5], which forms an interface between a higher level and a lower level in the hierarchy, is a d-sepset [9] . The 'composite joint tree' [5] corresponds to the 'hypertree' [9]. The way in which inference is performed in the composite join tree corresponds to the operation ShiftAttention [9] . There fore, his work showed that MSBNs can be applied to diagnosis of natural systems (e.g., human body [7]) as well as artificial systems (e.g., electronic circuits [5]).\nInstead of viewing a MSBN as representing multiple perspectives of a single reasoning agent, a MSBN can be viewed as representing multiple agents in a do main each of which holds one perspective of the do main. Following this semantics, Xiang [6] extended MSBNs to distributed multi-agent probabilistic rea soning, where multiple agents (subnets) collect local evidence asynchronously in parallel and exchange in formation infrequently to achieve a common goal. We shall sometime use the terms 'subnet' and 'agent' in terchangeably in the paper.\nGiven the widened applicability of the MSBN formal ism, this paper reexamines the key inference opera tion UpdateBelief [9] of MSBNs for propagating be lief from one subnet to another. We propose two new versions ofUpdateBelief to improve its efficiency. We compare the two improvements and indicate their trade-offs.\n566 Xiang\nSection 2 briefly reviews the MSBN formalism and de fines the concepts that the rest of the paper depends on. Section 3 describes the role of UpdateBelief intu itively, and analyzes how it achieves its intended func tionality by proving a theorem. Based on the hints provided by the proof, Section 4 proposes a new ver sion of UpdateBelief that reduces its computation time. Section 5 discusses intuitively the possibility of further efficiency improvement. The issue is then for mulated as an optimization problem in tree traversals with the solution given in Section 6. We summerize the difference of the three versions of UpdateBelief and their trade-offs in Section 7.\n2 Overview of MSBNs\nThis section briefly reviews the MSBN formalism. We shall use freely the formal results in [9, 6] , subject to some simplification, for concepts that the rest of the paper depends on.\nA MSBN M consists of a set of interrelated Bayesian subnets. Each subnet shares a non-empty set I of vari ables with at least one other subnet. This interfacing set I must be a d-sepset, which ensures that, when the pair of subnets is isolated from the rest of M, I renders the two subnets conditionally independent. Figure 1 (left) shows a three-subnet MSBN.\nSubnets of M are organized into a hypertree structure. The hypernodes are sub nets of M. The hyperlinks are d-sepsets between subnets. A hypertree structured M ensures that each hyperlink render the two parts of M that it connects conditionally independent. Fig ure 1 (middle) shows the hypertree organization of the MSBN in Figure 1 (left). Figure 1 (right) depicts a general hypertree structured MSBN.\nThe hypertree structured M is converted into a linked junction forest (LJF) F of the identical structure as its run time representation. Each hypernode in the hy pertree is a junction tree ( JT) (clique tree) converted\nfrom the corresponding subnet in the hypertree struc tured M. Evidence can be propagated between JTs of F by passing the probability distribution (PD) of I, which would not be efficient if the cardinality of I is large. The efficiency can be improved by exploiting the following structure internal to I.\nDefinition 1 (host tree) Let I be the d-sepset be tween JTs Ta and Tb . A host tree H of ra rela tive to Tb is obtained by recursively removing every leaf clique C of ra that satisfies one of the following conditions. {1} C n I = ¢. {2} C n I is a subset of another clique on the current H.\nH is the minimum subtree that contains I. Only cliques in H are involved directly with the evidence propagation between JTs. H is further reduced to a linkage tree for definition of propagation channels.\nDefinition 2 (linkage tree) Let I be the d-sepset between JTs ra and Tb . A linkage tree of Ta rel ative to Tb is obtained by recursively removing nodes (variables contained in a clique) or cliques from the host tree H of ra as follows. {1) If a node x ¢ I is contained in a single clique C, remove x from C. {2) If a clique C becomes a subset of an adjacent clique D after the above operation, union C into D.\nThe removal of x corresponds to a marginalization op eration on x. The union of C into D deletes C and the link (C, D) from H, and reconnects to D all cliques originally adjacent to C. Correct evidence propagation between JTs of F can be achieved iff every linkage tree contains exactly the nodes in the corresponding I.\nEach clique in a linkage tree L is a linkage. Each link age in L has a corresponding host clique C in H and hence the name host tree. The linkages in L are in dexed as L1, L2, ... in any order consistent with L. That is, for every i there is a unique j < i such that Lj is adjacent to L;.\nOptimization of belief updating in MSBNs 567\nFigure 2: A JT where each upper case letter represents a variable in the d-sepset, and each lower case letter represents a variable not in the d-sepset.\nFigure 3: The host tree (left) and linkage tree (right) of the JT in Figure 2.\nThe tree structure of L allows the PD on I (in the form of belief table B(J) ) be propagated between JTs by passing only belief tables on individual linkages since B(I) = TI B(Li )/ TI B(Rk) (see [9] for defini tions of operations on belief tables) where B(Lj) = l:u\\L. B(Uj) is the belief table of the linkage Lj J J whose host is Uj, and B ( Rk) is the belief table of a sepset {intersection of two adjacent cliques) in L. This may reduce the propagation traffic significantly when L consists of many small cliques.\nThe conversion of M into F ensures that the joint probability distribution (JPD) of F assembled from belief tables of F be equal to that of M.\nFigure 2 shows a JT whose d-sepset with an adjacent JT is I= {A, B, C, D, E, F, G, H, I , J , I<, L, M}. The host tree of the JT is shown in Figure 3 {left). The linkage tree is shown in Figure 3 (right). The clique at the lower left corner of Figure 3 {left) has been deleted since after the variable g in it is removed, it becomes a subset of clique c2 and itself is unioned into c2. The indexing of linkages are shown in Figure 3 (right) and, for each linkage, its host is labeled in Figure 3 {left) with the same index. Each linkage happens to be identical to its host in this example. But in general this is not the case.\nTo answer queries by efficient local computation in F , it must be made consistent. F is locally consistent if all JTs are internally consistent, i.e., when marginalized onto the same set of variables, different belief tables in\na JT yield the same PD. F is boundary consistent if each pair of adjacent JTs are consistent with respect to their d-sepset I. F is globally consistent iff it is both locally consistent and boundary consistent.\nA set of operations [9, 6] are developed to achieve consistency in F during evidential reasoning. Belief!nitialization establishes initial global con sistency. DistributeEvidence causes an outward be lief propagation within a JT, and brings the JT inter nally consistent after evidence on variables in a sin gle clique has been entered. UnifyBelief brings a JT internally consistent after evidence on variables in multiple cliques has been entered. EnterEvidence updates belief in a JT in light of new evidence, and brings the JT internally consistent again by calling either DistributeEvidence or UnifyBelief. AbsorbThroughLinkage brings two linkage hosts in different JTs into consistency. UpdateBelief up dates the belief of a JT T relative to an adjacent JT, and brings T internally consistent. In a single agent MSBN, ShiftAttention allows the user to enter mul tiple pieces of evidence into a JT of current atten tion, and, when the user shifts attention to a target JT, maintains consistency along the hyperpath in the hypertree structured F from the current JT to the target. In a multi-agent MSBN, CommunicateBelief regains global consistency after multiple agents have obtained evidence asynchronously in parallel. Both ShiftAttention and CommunicateBelief rely on UpdateBelief for inter-subnet belief propagation.\n568 Xiang\n3 Insight into the U pdateBelief Operation\nThe operation UpdateBelief plays a central role in inter-subnet communication. It is defined as follows.\nOperation 3 (U pdateBelief [9]) Let { L1, ... , Lm} be the set of linkages of a JT Ta relative to Tb. Let Ut and U;b be the linkage hosts of L; (i = 1, ... , m) in Ta and Tb, respectively. When UpdateBelief is initiated by ra relative to Tb, the following is performed. For each i (in ascending order) AbsorbThroughLinkage is called in U;a to absorb from ut through L;, followed by a DistributeEvidence called in Ut.\nIntuitively, UpdateBelief can be understood as fol lows. In order to bring two adjacent JTs into con sistency, we need to propagate the belief table B(I) from Tb to ra. Since the size of B(I) is exponential to the size of I, the propagation can be expensive. In multi-agent MSBNs with remotely located agents, we need to pass B(I) through communication channels. UpdateBelief makes use of conditional independence among members of the d-sepset, and propagates B(I) by only passing the belief tables B(L;), which are col lectively smaller in size when B(I) is large. For ex ample, if the d-sepset I contains ten binary variables, B(I) has a size of 1024. If I = L1 U L2 U L3 with each L; containing 5 variables, then the three belief tables on linkages have a total size 96.\nHowever, this savings in propagation traffic has a price to pay. The belief propagation over multiple linkages must be coordinated to achieve the intended effect. As analyzed in [9] , each AbsorbThroughLinkage should be followed by the operation DistributeEvidence in Ta. When Ta is large, DistributeEvidence per formed repeatedly can be expensive. Based on the argument \"communication is slower than computa tion\" [2] , the tradeoff is justified [6] by observing that DistributeEvidence involves only local computation within a subnet. Admitting that communication sav ings should be preferred over computation savings, this paper aims to improve the efficiency of the local com putation as much as possible.\nIn the original presentation of UpdateBelief [9], how the operation works is not fully analyzed. The proof of the following theorem gains further insight into this operation, and provides hints for improvement of its efficiency.\nTheorem 4 Let I be the d-sepset between JTs Ta and Tb. Let {L1, ... , Lm} be the set of linkages. Let the two JTs be internally consistent. Let B(Ia) (B(Ib)) be the belief table on I defined by marginalization of B(Ta) (B(Tb)).\nAfter UpdateBelief, B' (Ta) = B(Ta) * B(Ib)/ B(Ia), and ra is internally consistent.\nProof: We prove by induction on the index of link ages. AbsorbThroughLinkage in UpdateBelief is per formed by ra in the order L1, ... , Lm. After the per formance of AbsorbThroughLinkage through L1, we have B1(Ta) = B(Ta) * B(Lt)/ B(L�).\nAfter AbsorbThroughLinkage is performed through L2, we have B2(Ta) = B1(Ta) * B(L�)/ B1(L�). Note that the two B() in the right-hand side of the previous equation are now replaced by B1 (). The appearance of B1(L2) instead of B(L2) is due to the first DistributeEvidence that follows the first AbsorbThroughLinkage. After DistributeEvidence, Ta is internally consistent and B(L2) is updated into B1(L�). We also obtain the following equation:\nwhere 'na' signifies that the intersection is defined in Ta and so is the B().\nSubstituting B1(Ta) and B1(L2), we obtain\nB(Ta) * B(Lt) * B(L�)/ B(L1 nb L2) B(L�) * B(L�)jB(L1 na L2)\nB(Ta) * B(L1 Ub L2)\n' B(L1 ua L2)\nwhere the second equality holds because of the way in which linkages are defined and indexed (Section 2).\nAssume that, after AbsorbThroughLinkage is per formed through L; followed by DistributeEvidence, we have the following two equations.\nAfter AbsorbThroughLinkage is performed through L;+l, we have B;+l(Ta) = B;(Ta)*B(L�+l)/ B;(Lf+l).\nBy substituting B;(Ta) and B; (Lf+1), it yields\nwhere the second equality holds because of the way in which linkages are defined and indexed (Section 2).\nAfter the DistributeEvidence is performed, Ta is in ternally consistent, and it follows that\nFrom the inductive assumptions (1) and (2), we have now proven the conditions (3) and (4). Therefore, after AbsorbThroughLinkage is performed through the last linkage Lm, we obtain the updated belief\nwhere the last equality holds due to the way in which the linkage tree is defined. ra is internally consistent after the last DistributeEvidence. 0\n4 Efficiency Improvement of U pdateBelief\nIn the proof of Theorem 4, it is observed that the in ductive conclusion on B;+l(Lf+2) (equation (4)) can be proven as long as the host tree (Section 2) is made consistent after the AbsorbThroughLinkage through Li+l· The consistency of the entire JT is not neces sary. Hence belief propagation beyond the boundary of the host tree, as performed by DistributeEvidence, is not necessary. We therefore define a new oper ation DistributeEvidenceOnHostTree which is the same as DistributeEvidence except that it termi nates at the leaves of the host tree. For example, if DistributeEvidenceOnHostTree is called in the clique {A, B, D, E, F, G, I, J, L, M} in the JT of Fig ure 2 (labeled C2 in Figure 3 (left)) , the belief prop agation will proceed along two chains only: One from c2 to cl and the other from c2 to c4.\nReplacing DistributeEvidence by the new operation, we can define a new version of UpdateBelief.\nOperation 5 (UpdateBelie£2) Let { L1, . . . , Lm} be the set of linkages of a JT Ta relative to Tb. Let Ut and U;b be the linkage hosts of L; (i = 1, .. . , m) in ra and Tb, respectively. When UpdateBelief2 is initiated by Ta relative to Tb, the following is performed.\nFor i 1 through m, AbsorbThroughLinkage is called in Ut to absorb from U;b through L;. For i 1, . . . , m - 1, it is followed by DistributeEvidenceOnHostTree called in Ut. For i = m, it is followed by DistributeEvidence called in u:;..\nOptimization of belief updating in MSBNs 569\nCorollary 6 Let I be the d-sepset between JTs Ta and Tb. Let { L1 , ... , Lm} be the set of linkages. Let the two JTs be internally consistent. Let B(Ia) (B(Ib)) be the belief table on I defined by marginalization of B(Ta) (B(Tb)). After UpdateBelief2, B'(Ta) = B(Ta) * B(Ib)j B(Ia), and Ta is internally consistent.\nProof: After each DistributeEvidenceOnHostTree, the host tree is internally consistent. Hence, all inter mediate results on B;(Ta) and B;(Lf+1) in the proof of Theorem 4 are still valid except that Ta as a whole is not internally consistent until after the performance ofDistributeEvidence at the end ofUpdateBelief2.\n0\nUpdateBelief2 performs re peatedly DistributeEvidenceOnHostTree instead of DistributeEvidence. Computational savings are ob tained by not having to propagate belief beyond the host tree for a number of times proportional to the number of linkages. When the host tree is significantly smaller than the JT, the savings can also be significant.\n5 Further Improvement of U pdateBelief\nExamination of the proof of Theorem 4 shows that propagation of belief to the entire host tree is still un necessary. For the result of the theorem to be valid, it is sufficient to update B;_!(Lf+1) to B;(Lf+1), af ter AbsorbThroughLinkage through L;. This implies that, between two successive AbsorbThroughLinkage, it is sufficient to propagate the new belief only to the next host clique. Based on this idea, a more efficient UpdateBelief can be defined. We illustrate the new operation with an example.\nConsider the host tree in Figure 4. We assume that each clique is a host, and each clique is indexed by the index of the corresponding linkage. Suppose AbsorbThroughLinkage is performed in the order i = 1, .. . , 5. After AbsorbThroughLinkage through Lt, we propagate the new belief in cl to c2 (one inter clique propagation) . After AbsorbThroughLinkage through L2, we propagate the new belief in C2 to C1 and then to C3 (two inter-clique propagations) . Prop agating new belief this fashion, we need to perform 1 + 2+ 2+3 = 8 inter-clique belief propagations, before the AbsorbThroughLinkage through L5. Compared to\n570 Xiang\n4 + 4 + 4 + 4 = 16 inter-clique propagations needed in UpdateBelief2, there is an about 50% computational savings.\nAdditional savings can be obtained by optimizing the new operation. We note that AbsorbThroughLinkage is performed in the ascending order of linkage indexes. However, linkages can be indexed by any order consis tent with the host tree (Section 2). We therefore have the freedom to choose the order that can maximize the computational savings.\nIf we choose the order i = 5, 2, 1, 3, 4 for the host tree in Figure 4, we only need to perform 1 + 1 + 1 + 2 = 5 inter-clique belief propagations: Three propagations less than the previous order.\nIn the next section, we present the result on how to determine the optimal order of linkages (the order for performing AbsorbThroughLinkage) given a host tree.\n6 Optimization of U pdateBelief\nThe problem of finding the optimal order for the per formance of the operation AbsorbThroughLinkage in UpdateBelief can be abstracted as follows.\nProblem Statement 7 Given a weighted tree of n nodes, number the nodes from 1 to n such that '£7;;/ w(i, i + 1) is minimized, where w(i, i + 1) is the path weight from node i to node i + 1 according to the numbering.\nThe tree in this model corresponds to the given host tree. Each node corresponds to a host clique. The link weight corresponds to the amount of computation for propagating belief from one clique to an adjacent clique in the host tree. The model assumes that every node is a host. If this is not the case, the propagation through non-host nodes can be modeled into the link weights such that the resultant tree has no non-host node.\nWe define the concept tour to be used in solving the above problem.\nDefinition 8 (tour) A tour of a graph is a walk that visits each node at least once. A closed tour is a tour that starts and ends with the identical node. Oth erwise, it is an open tour.\nThe problem can now be equivalently expressed as fol lows.\nProblem Statement 9 Given a weighted tree of n nodes, find an open tour with the minimum weight.\nIn order to develop an algorithm that solves the above problem, we first study a closed tour, since, as will be\nshown, ( 1) the problem of a minimum weight closed tour can be solved easily; and (2) the minimum weight open tour has a simple relationship with the mini mum weight closed tour. To simplify the intermediate derivations, we assume that all link weights are identi cal. We then simply deal with a minimum length tour with the length of each link being one. We remove this assumption at the end.\nLemma 10 A closed tour of a tree with the minimum length traverses each link exactly twice.\nProof: We prove by induction. The statement is triv ially true for a tree with only one link. Assume that it is true for a tree with k link(s).\nConsider a tree with k + 1 links. For any leaf x and its adjacent node y, if we remove x and the link (x, y), the resultant subgraph is a tree with k link(s). By assumption, it has a minimum length closed tour that traverses each link exactly twice. To include x and (x, y) in the closed tour, one must at least travel from y to x and then come back. This completes a closed tour of the original tree with the minimum additional link traversal. 0\nFor example, a closed tour of the minimum length for the tree in Figure 5 is (Cs, C2, C6, C1, Cs, C1, C6, C2, C1, Cg, C10, Cg, C1, C3, C1, C4, C1, C2, Cs). The length of the tour is 18, which is twice of the number of links of the tree.\nWe define a terminal chain to be used in the following discussion.\nDefinition 11 A terminal chain in a tree is a path (a walk without repeated nodes) that terminates at both ends by leaf nodes.\nFor instance, one terminal chain in Figure 5 is (Cs, C2, C6, C1, C8). The simple open path (C10, C9, C1) is not a terminal chain, since C1 is not a leaf.\nWe now establish the relation between a minimum length closed tour and a minimum length open tour through a terminal chain.\nLemma 12 An open tour of a tree can be constructed such that its length is the length of a minimum length\nclosed tour minus that of a terminal chain.\nProof: It suffices to show that an open tour can be constructed by reconnecting a minimum length closed tour r such that a terminal chain is traversed only once.\nLet l be an arbitrary terminal chain in the tree. Start from one end of l and travel along the chain. For each internal node yin l, let the two adjacent nodes of yon l be x and z, and let the direction of the traversal be from x to z. At each y of degree 3 or more, traverse first an adjacent node u ( u :f. x and u :f. z) and the subtree rooted at u in the same way as in r . After returning to y from u, traverse another adjacent node v ( v :f. x and v :f. z) in the same fashion. After all adjacent nodes (other than x and z) of y have been exhausted, travel from y to z and continue along l. The open tour terminates when the other end of l is reached. The open tour travels the same set of links as r except that links on l are traversed only once.\n0\nWe illustrate the constructive proof using Figure 5. Suppose we are given the minimum length (18) closed tour (Cs, C2, C6, C1, Cs, C1, C6, C2, C1, Cg, C1o, Cg, C1, Ca, C1, C4, C1, C2, Cs) and a terminal chain (Cs, C2, C6, C1, Cs) of length 4. By reconnect ing the tour and traversing the chain only once, we obtain the open tour (Cs, C2, C1, Cg, C10, Cg, C1, Ca, C1, C4, C1, C2, C6, C1, Cs). It has the length 18-4 = 14.\nLemma 13 extends Lemma 12 to a minimum length open tour.\nLemma 13 An minimum length open tour of a tree has the length of a minimum length closed tour minus the length of a longest terminal chain.\nProof: Assume an open tour is constructed as in the proof of Lemma 12, which is based on a terminal chain of the longest length of all terminal chains. It is suf ficient to show that no single link traversal can be re moved from this tour such that it remains to be an open tour.\nEach link along the terminal chain is traversed only once. If any one of these link traversals is removed, the tour will be disconnected. Each link in a subtree other than the terminal chain is traversed twice, one of them travels away from the terminal chain, and the other travels towards the chain. If any of these link traversals is removed, the tour of the subtree will be disconnected. 0\nWe now remove the assumption of identical link weight and the result for the tour problem follows.\nOptimization of belief updating in MSBNs 571\nTheorem 14 An mznzmum weight open tour of a weighted tree can be constructed by modifying a mini mum weight closed tour such that a terminal chain of the maximum weight is traversed only once.\nProof: This is a direct extension of Lemma 13 to weighted trees. The replacement of length by weight is valid because Lemma 10, 12, 13 and their proofs are still valid if the term length is replaced by the term weight and weights are different. 0\nIn Figure 6, the terminal chain of the maximum weight (1 + 2 + 4 + 8 + 6 = 21) is (Cs, C7, c6, c2, cl , c4)· Therefore, a mm1mum weight open tour is (Cs, C1, C6, C2, Cs, C2, C1, Ca, C1, Cg, C1o, Cg, C1, C4) and the minimum weight is 2 * ( 1 + 2 + 4 + 4 + 8 + 3 + 2+6+4)-21=47.\nBased on Theorem 14, Algorithm 15 finds a minimum weight open tour for a given tree. The steps 1 through 5 of the algorithm find a terminal chain with the max imum weight. It can be viewed as a variation of Dijk stra's shortest-path algorithm in a tree. It differs from the latter in that it finds the longest (heavest) path between a non-predetermined pair of leaves. The step 6 constructs a minimum weight open tour in a way as described in the proof of Lemma 12. It also produces a numbering of nodes as stated in Problem Statement 7.\nThe algorithm has a complexity of 0( n2) for both time and space.\nFigure 7 illustrates Algorithm 15. The weighted tree is identical to that in Figure 6 up to a renaming of nodes. The renaming is performed such that the five leaves are indexed from 1 to 5, satisfying the input description of Algorithm 15. Note that the indexing of nodes in Figure 6 is consistent with the tree structure, but the indexing in Figure 7 is not.\nFollowing Algorithm 15, we obtain M[l..5] (18, 21, 20, 21, 19) as shown in Figure 7. Therefore, x = 2, y = 4 and a heavest terminal chain is one from v2 to v4. This is the same as we obtained earlier from Figure 6. The step 6 may (since the result is not unique) fill the array t as t(l..14] = (2, 8, 7, 6, 1, 6, 9, 5, 9, 10, 3, 10, 9, 4) which corresponds to the same minimum weight open tour as we obtained\n572 Xiang\nAlgorithm 15\nInput: A weighted tree of a set N of n > 2 nodes with m leaves VI, • • • , Vm and n - m > 0 internal nodes Vm+!1 • • • 1 Vn. Var: f[l..n, l..m), M(l..m) : array of reals; t[l..2n] : array of integers. Output: An open tour defined by tO and a numbering of nodes. begin\nend\n1 for j = 1 to m, do f[j, j] := 0 2 for j = 1 to m, do\nwhile there exists i ( 1 :::; i :::; m) and f[i, j] is undefined, do\nif v; is adjacent to a node Vk and f[k, j] is defined, then f[i,j] := f[k,j] + w(v;, vk )\n3 for i= 1 to m, do M[i] := maxj� 1 f[i,j] 4 Find the leaf Vx such that M[x] = max� 1 M[i] 5 for j = 1 to m, do\nif f[x,j] = M[x] then y := j, break 6 Travel along the terminal chain from Vx to vy.\nAt each internal node z on the chain, traverse each subtree rooted at an adjacent node {not on the chain} of z in a depth-first fashion. Record the index of a node in tO each time it is visited. Number each node as it is visited the first time.\n7 Return tO as the open tour and the numbering.\nearlier from Figure 6. The numbering produced is then (2, 8, 7, 6, 1, 9, 5, 10, 3, 4) which satisfies Problem State ment 7.\nTo use the open tour obtained for a new version of UpdateBelief, we must make sure that the order in which each node is visited the first time (the num bering of nodes returned by Algorithm 15) is consis tent with the tree structure. This order corresponds to the order in which linkages are indexed and the order in which AbsorbThroughLinkage will be performed. This condition is required in the proof of Theorem 4. As we can see that it is indeed true since the next node to number (in step 6 of Algorithm 15) is always adjacent to the subtree traversed so far.\nTheorem 16 summarizes the above discussion on Algo rithm 15. The proof is trivial given Theorem 14, and the equivalence of Problem Statement 7 and 9.\nTheorem 16 LetT be a weighted tree. The number ing of nodes generated by Algorithm 15 is consistent with T, and the open tour returned has the minimum weight.\nWe are now ready to define another improved ver sion of UpdateBelief. Since belief propagation to the host tree is not necessary, we define a new op eration DistributeEvidenceOnChain. It is the same as DistributeEvidence except we only propagate belief along a specified chain. We define the new UpdateBelief and state its correctness as follows.\nOperation 17 (UpdateBelief3) Let {L1, ... , Lm} be the set of linkages of a JT Ta relative to Tb. Let Ut and U;b be the linkage hosts of L; (i = 1, ... , m) in Ta and Tb, respectively. When UpdateBelief3 is ini tiated by ra relative to Tb I the following is performed.\nFor i 1 through m, AbsorbThroughLinkage is called in Ut to absorb from U;b through L; . For i = 1, ... , m - 1, it is followed by DistributeEvidenceOnChain called in Ut along the unique path from Ut to Ut+l. For i = m, it is fol lowed by DistributeEvidence called in u;:..\nCorollary 18 Let I be the d-sepset between JTs Ta and Tb. Let { L1 , ... , Lm} be the set of linkages in dexed according to the numbering produced by Algo rithm 15. Let the two JTs be internally consistent. Let B(Ia) (B(Jb)J be the belief table on I defined by marginalization of B(Ta) {B(Tb)).\nAfter UpdateBelief3, we have B'(Ta) = B(Ta) * B(Ib)jB(Ia), andTa is internally consistent.\nGiven a JT and a d-sepset with an adjacent JT, UpdateBelief3 is optimal in the sense that the min-\nimum amount of computation for coordinating multi linkage belief propagation is required.\n7 Comparison of Versions of U pdateBelief\nThis paper addresses the computation efficiency of be lief propagation between a pair of Bayesian subnets in a MSBN. Inter-sub net belief propagation involves the passage of the probability distribution on d-sepset I from one subnet to an adjacent subnet.\nA brute force method forms a large clique that con tains I in each subnet involved, and pass the belief table B(I) directly. It is computationally the most expensive, both locally and inter-subnet-wise.\nThe first improvement is UpdateBelief. Only belief tables on linkages are passed, which are collectively smaller than B(I). It reduces the inter-subnet traffic but still incurs expensive local computation to coordi nate belief propagation over multiple linkages.\nThe second improvement is UpdateBelief2. Mul tiple performances of DistributeEvidence are re placed by multiple performances of the opera tion DistributeEvidenceOnHostTree. Distribution beyond the host tree is saved at each perfor mance. The saving of inter-subnet traffic obtained by UpdateBelief is maintained while the efficiency of lo cal computation is improved.\nThe next improvement is UpdateBelief3. Multiple performances of DistributeEvidenceOnHostTree are replaced by multiple performances of the operation DistributeEvidenceOnChain. Each time, distribu tion to the entire host tree is reduced to distribution along a chain leading to the next host. It further improves the efficiency of local computation beyond UpdateBelief2, and incurs the minimum amount of computation to coordinate belief propagation over multiple linkages.\nOur analysis for the minimum weight open tour, which leads to the definition of UpdateBelief3, has assumed equal weights in traversing a link in both directions. The assumption may not hold since belief propagation between a pair of cliques may incur different amount of computations when performed in opposite directions. The results of this paper can be extended to cover the situation where weights differ at opposite directions. Due to the limited space, such discussion is beyond the scope of this paper.\nWe indicate that the savings in computation time are obtained by increased sophistication in con trol mechanisms. Replacement of the brute force method (equivalent to a single linkage propagation)\nOptimization of belief updating in MSBNs 573\nby UpdateBelief requires the coordination of multiple linkage propagation. Replacement of UpdateBelief by UpdateBelief2 requires additional control. Dis tribution is to be terminated at the leaves of the host tree. Finally, replacement of UpdateBelief2 by UpdateBelief3 requires more specific control. Distri bution must proceed along predetermined chains.\nAcknowledgements\nThis work is supported by the Dean's Research Fund ing from Faculty of Science, University of Regina, the General NSERC Grant from University of Regina, and Research Grant OGP0155425 from NSERC. I am also grateful to the suggestions from anonymous referees.\nReferences\n[1 ] E. Charniak. Bayesian networks without tears. AI Magazine, 12( 4) :50-63, 1991.\n[2] R. Davis and R.G. Smith. Negotiation as a metaphor for distributed problem solving. Arti ficial Intelligence, 20(1):63-109, 1983.\n[3] R.E. Neapolitan. Probabilistic Reasoning in Expert Systems. John Wiley and Sons, 1990.\n[4] J. Pearl. Probabilistic Reasoning in Intelligent Sys tems: Networks of Plausible Inference. Morgan Kaufmann, 1988.\n[5] S. Srinivas. A probabilistic approach to hierarchi cal model-based diagnosis. In Proc. Tenth Conf. Uncertainty in Artificial Intelligence, pages 538- 545, Seattle, Washington, 1994.\n[6] Y. Xiang. Distributed multi-agent probabilistic reasoning with Bayesian networks. In Z.W. Ras and M. Zemankova, editors, Methodologies for In telligent Systems, pages 285-294. Springer-Verlag, Oct. 1994.\n[7] Y. Xiang, B. Pant, A. Eisen, M. P. Beddoes, and D. Poole. Multiply sectioned Bayesian networks for neuromuscular diagnosis. Artificial Intelligence in Medicine, 5:293-314, 1993.\n[8] Y. Xiang, D. Poole, and M. P. Beddoes. Exploring locality in Bayesian networks for large expert sys tems. In Proc. Eighth Conference on Uncertainty in Artificial Intelligence, pages 344-351 , Stanford, CA, 1992.\n[9] Y. Xiang, D. Poole, and M. P. Beddoes. Multiply sectioned Bayesian networks and junction forests for large knowledge based systems. Computational Intelligence, 9(2):171-220, 1993."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2011,
    "abstractText" : "Recent developments show that Multiply Sectioned Bayesian Networks (MSBNs) can be used for diagnosis of natural systems as well as for model-based diagnosis of artificial systems. They can be applied to single-agent oriented reasoning systems as well as multi­ agent distributed reasoning systems. Belief propagation between a pair of subnets plays a central role in maintenance of global consistency in a MSBN. This paper studies the operation UpdateBelief, presented orig­ inally with MSBNs, for inter-subnet propaga­ tion. We analyze how the operation achieves its intended functionality, which provides hints for improving its efficiency. New versions of UpdateBelief are then de­ fined that reduce the computation time for inter-subnet propagation. One of them is optimal in the sense that the minimum amount of computation for coordinating multi-linkage belief propagation is required. The optimization problem is solved through the solution of a graph-theoretic problem: the minimum weight open tour in a tree.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}