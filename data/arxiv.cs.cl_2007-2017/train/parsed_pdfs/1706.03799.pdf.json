{
  "name" : "1706.03799.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "VERB PHYSICS: Relative Physical Knowledge of Actions and Objects",
    "authors" : [ "Maxwell Forbes", "Yejin Choi", "Paul G. Allen" ],
    "emails" : [ "mbforbes@cs.washington.edu", "yejin@cs.washington.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this paper, we present an approach to infer relative physical knowledge of actions and objects along five dimensions (e.g., size, weight, and strength) from unstructured natural language text. We frame knowledge acquisition as joint inference over two closely related problems: learning (1) relative physical knowledge of object pairs and (2) physical implications of actions when applied to those object pairs. Empirical results demonstrate that it is possible to extract knowledge of actions and objects from language and that joint inference over different types of knowledge improves performance."
    }, {
      "heading" : "1 Introduction",
      "text" : "Reading and reasoning about natural language text often requires trivial knowledge about everyday physical actions and objects. For example, given a sentence “Shanice could fit the trophy into the suitcase,” we can trivially infer that the trophy must be smaller than the suitcase even though it is not stated explicitly. This reasoning requires knowledge about the action “fit”—in particular, typical preconditions that need to be satisfied in order to perform the action. In addition, reasoning\nNatural language clues\n“She barged into the stable.”\nabout the applicability of various physical actions in a given situation often requires background knowledge about objects in the world, for example, that people are usually smaller than houses, that cars generally move faster than humans walk, or that a brick probably is heavier than a feather.\nIn fact, the potential use of such knowledge about everyday actions and objects can go beyond language understanding and reasoning. Many open challenges in computer vision and robotics may also benefit from such knowledge, as shown\nar X\niv :1\n70 6.\n03 79\n9v 2\n[ cs\n.C L\n] 1\n3 Ju\nl 2 01\n7\nin recent work that requires visual reasoning and entailment (Izadinia et al., 2015; Zhu et al., 2014). Ideally, an AI system should acquire such knowledge through direct physical interactions with the world. However, such a physically interactive system does not seem feasible in the foreseeable future.\nIn this paper, we present an approach to acquire trivial physical knowledge from unstructured natural language text as an alternative knowledge source. In particular, we focus on acquiring relative physical knowledge of actions and objects organized along five dimensions: size, weight, strength, rigidness, and speed. Figure 1 illustrates example knowledge of (1) relative physical relations of object pairs and (2) physical implications of actions when applied to those object pairs.\nWhile natural language text is a rich source to obtain broad knowledge about the world, compiling trivial commonsense knowledge from unstructured text is a nontrivial feat. The central challenge lies in reporting bias: people rarely states the obvious (Van Durme, 2010; Sorower et al., 2011; Gordon and Van Durme, 2013; Misra et al., 2016; Zhang et al., 2017), since it goes against Grice’s conversational maxim on the quantity of information (Grice, 1975).\nIn this work, we demonstrate that it is possible to overcome reporting bias and still extract the unspoken knowledge from language. The key insight is this: there is consistency in the way people describe how they interact with the world, which provides vital clues to reverse engineer the common knowledge shared among people. More concretely, we frame knowledge acquisition as joint inference over two closely related puzzles: inferring relative physical knowledge about object pairs while simultaneously reasoning about physical implications of actions.\nImportantly, four of five dimensions of knowledge in our study—weight, strength, rigidness, and speed—are either not visual or not easily recognizable by image recognition using currently available computer vision techniques. Thus, our work provides unique value to complement recent attempts to acquire commonsense knowledge from web images (Izadinia et al., 2015; Bagherinezhad et al., 2016; Sadeghi et al., 2015).\nIn sum, our contributions are threefold:\n• We introduce a new task in the domain of commonsense knowledge extraction from\nlanguage, focusing on the physical implications of actions and the relative physical relations among objects, organized along five dimensions. • We propose a model that can infer relations\nover grounded object pairs together with first order relations implied by physical verbs. • We develop a new dataset VERBPHYSICS\nthat compiles crowdsourced knowledge of actions and objects.1\nThe rest of the paper is organized as follows. We first provide the formal definition of knowledge we aim to learn in Section 2. We then describe our data collection in Section 3 and present our inference model in Section 4. Empirical results are given in Section 5 and discussed in Section 6. We review related work in Section 7 and conclude in Section 8."
    }, {
      "heading" : "2 Representation of Relative Physical Knowledge",
      "text" : ""
    }, {
      "heading" : "2.1 Knowledge Dimensions",
      "text" : "We consider five dimensions of relative physical knowledge in this work: size, weight, strength, rigidness, and speed. “Strength” in our work refers to the physical durability of an object (e.g., “diamond” is stronger than “glass”), while “rigidness” refers to the physical flexibility of an object (e.g., “glass” is more rigid than a “wire”). When considered in verb implications, size, weight, strength, and rigidness concern individual-level semantics; the relative properties implied by verbs in these dimensions are true in general. On the other hand, speed concerns stage-level semantics; its implied relations hold only during a window surrounding the verb (Carlson, 1977)."
    }, {
      "heading" : "2.2 Relative physical knowledge",
      "text" : "Let us first consider the problem of representing relative physical knowledge between two objects. We can write a single piece of knowledge like “A person is larger than a basketball” as\nperson >size basketball\nAny propositional statement can have exceptions and counterexamples. Moreover, we need to cope with uncertainties involved in knowledge acquisition. Therefore, we assume each piece of knowledge is associated with a probability distribution.\n1https://uwnlp.github.io/verbphysics/\nMore formally, given objects x and y, we define a random variable Oax,y whose range is {>, <,'} with respect to a knowledge dimension a ∈ {SIZE,WEIGHT,STRENGTH,RIGIDNESS,SPEED} so that:\nP(Oax,y = r), r ∈ {>, <,'}.\nThis immediately provides two simple properties:\nP(Ox,y = >) = P(Oy,x = <) P(Ox,x = ') = 1"
    }, {
      "heading" : "2.3 Physical Implications of Verbs",
      "text" : "Next we consider representing relative physical implications of actions applied over two objects. For example, consider an action frame “x threw y.” In general, following implications are likely to be true:\n“x threw y” =⇒ x >size y “x threw y” =⇒ x >weight y “x threw y” =⇒ x <speed y\nAgain, in order to cope with exceptions and uncertainties, we assume a probability distribution associated with each implication. More formally, we define a random variable F av to denote the implication of the action verb v when applied over its arguments x and y with respect to a knowledge dimension a so that:\nP(F sizethrew = >) := P(“x threw y”⇒ x >size y) P(Fwgtthrew = >) := P(“x threw y”⇒ x >wgt y)\nwhere the range of F sizethrew is {>, <,'}. Intuitively, F sizethrew represents the likely first order relation implied by “throw” over ungrounded (i.e., variable) object pairs.\nThe above definition assumes that there is only a single implication relation for any given verb with respect to a specific knowledge dimension. This is generally not true, since a verb, especially a common action verb, can often invoke a number of different frames according to frame semantics (Fillmore, 1976). Thus, given a number of different frame relations v1...vT associated with a verb v, we define random variables F with respect to a specific frame relation vt, i.e., F avt . We use this notation going forward.\nFrame Perspective on Verb Implications: Figure 2 illustrates the frame-centric view of physical implication knowledge we aim to learn. Importantly, the key insight of our work is inspired by Fillmore’s original manuscript on frame semantics (Fillmore, 1976). Fillmore has argued that “frames”—the contexts in which utterances are situated—should be considered as a third primitive of describing a language, along with a grammar and lexicon. While existing frame annotations such as FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005), and VerbNet (Kipper et al., 2000) provide rich frame knowledge associated\nwith a predicate, none of them provide the exact kind of physical implications we consider in our paper. Thus, our work can potentially contribute to these resources by investigating new approaches to automatically recover richer frame knowledge from language. In addition, our work is motivated by the formal semantics of Dowty (1991), as the task of learning verb implications is essentially that of extracting lexical entailments for verbs."
    }, {
      "heading" : "3 Data and Crowdsourced Knowledge",
      "text" : "Action Verbs: We pick 50 classes of Levin verbs from both “alternation classes” and “verb classes” (Levin, 1993), which corresponds to about 1100 unique verbs. We sort this list by frequency of occurrence in our frame patterns in the Google Syntax Ngrams corpus (Goldberg and Orwant, 2013) and pick the top 100 verbs.\nAction Frames: Figure 2 illustrates examples of action frame relations. Because we consider implications over pairwise argument relations for each frame, there are sometimes multiple frame relations we consider for a single frame. To enumerate action frame relations for each verb, we use syntactic patterns based on dependency parse by extracting the core components (subject, verb, direct object, prepositional object) of an action, then map the subject to an agent, the direct object to a theme, and the prepositional object to a goal.2 For those frames that involve an argument in a prepositional phrase, we create a separate frame for each preposition based on the statistics observed in the Google Syntax Ngram corpus.\nBecause the syntax ngram corpus provides only tree snippets without context, this way of enumerating potential frame patterns tend to overgenerate. Thus we refine our prepositions for each frame by taking either the intersection or union with the top 5 Google Surface Ngrams (Michel et al., 2011), depending on whether the frame was under- or over-generating. We also add an additional crowdsourcing step where we ask crowd workers to judge whether a frame pattern with a particular verb and preposition could plausibly be found in a sentence. This process results in 813 frame templates, an average of 8.13 per verb.\n2Future research could use an SRL parser instead. We use dependency parse to benefit from the Google Syntax Ngram dataset that provides language statistics over an extremely large corpus, which does not exist for SRL.\nObject Pairs: To provide a source of ground truth relations between objects, we select the object pairs that occur in the 813 frame templates with positive pointwise mutual information (PMI) across the Google Syntax Ngram corpus. After replacing a small set of “human” nouns with a generic HUMAN object, filtering out nouns labeled as abstract by WordNet (Miller, 1995), and distilling all surface forms to their lemmas (also with WordNet), the result is 3656 object pairs."
    }, {
      "heading" : "3.1 Crowdsourcing Knowledge",
      "text" : "We collect human judgements of the frame knowledge implications to use as a small set of seed knowledge (5%), a development set (45%), and a test set (50%). Crowd workers are given with a frame template such as “x threw y,” and then asked to list a few plausible objects (including people and animals) for the missing slots (e.g., x and y).3\n3This step is to prime them for thinking about the particular template; we do not use the objects they provided.\nWe then ask them to rate the general relationship that the arguments of the frame exhibit with respect to all knowledge dimensions (size, weight, etc.). For each knowledge dimension, or attribute, a, workers select an answer from (1) x >a y, (2) x <a y, (3) x 'a y, or (4) no general relation.\nWe conduct a similar crowdsourcing step for the set of object pairs. We ask crowd workers to compare each of the 3656 object pairs along the five knowledge dimensions we consider, selecting an answer from the same options above as with frames. We reserve 50% of the data as a test set, and split the remainder up either 5% / 45% or 20% / 30% (seed / development) to investigate the effects of different seed knowledge sizes on the model.\nStatistics for the dataset are provided in Table 1. About 90% of the frames as well as object pairs had 2/3 agreement between workers. After removing frame/attribute combinations and object pairs that received less than 2/3 agreement, or were selected by at least 2/3 workers to have no relation, we end up with roughly 400–600 usable frames and 2100–2500 usable object pairs per attribute."
    }, {
      "heading" : "4 Model",
      "text" : "We model knowledge acquisition as probabilistic inference over a factor graph of knowledge. As shown in Figure 3, the graph consists of multiple substrates (page-wide boxes) corresponding to different knowledge dimensions (shown only three of them —strength, size, weight—for brevity). Each substrate consists of two types of sub-graphs: verb subgraphs and object subgraphs, which are connected through factors that quantify action–object compatibilities. Connecting across substrates are factors that model inter-dependencies across different knowledge dimensions. In what follows, we describe each graph component."
    }, {
      "heading" : "4.1 Nodes",
      "text" : "The factor graph contains two types of nodes in order to capture two classes of knowledge. The first type of nodes are object pair nodes. Each object pair node is a random variable Oax,y which captures the relative strength of an attribute a between objects x and y.\nThe second type of nodes are frame nodes. Each frame node is a random variable F avt . This corresponds to the verb v used in a particular type of frame t, and captures the implied knowledge the\nframe vt holds along an attribute a. All random variables take on the values {>, <,'}. For an object pair node Oax,y, the value represents the belief about the relation between x and y along the attribute a. For a frame node F avt , the value represents the belief about the relation along the attribute a between any two objects that might be used in the frame vt.\nWe denote the sets of all object pair and frame random variables O and F , respectively."
    }, {
      "heading" : "4.2 Action–Object Compatibility",
      "text" : "The key aspect of our work is to reason about two types of knowledge simultaneously: relative knowledge of grounded object pairs, and implications of actions related to those objects. Thus we connect the verb subgraphs and object subgraphs through selectional preference factors ψs between two such nodes Oax,y and F a vt if we find evidence from text that suggests objects x and y are used in the frame vt. These factors encourage both random variables to agree on the same value.\nAs an example, consider a node Osizep,b which represents the relative size of a person and a basketball, and a node F sizethrewdobj which represents the relative size implied by an “x threw y” frame. If we find significant evidence in text that “[person] threw [basketball]” occurs, we would add a selectional preference factor to connect Osizep,b with F sizethrewdobj and encourage them towards the same value. This means that if it is discovered that people are larger than basketballs (the value >), then we would expect the frame “x threw y” to entail x >size y (also the value >)."
    }, {
      "heading" : "4.3 Semantic Similarities",
      "text" : "Some frames have relatively sparse text evidences to support their corresponding knowledge acquisition. Thus, we include several types of factors based on semantic similarities as described below.\nCross-Verb Frame Similarity: We add a group of factors ψv between two verbs v and u (to connect a specific frame of v with a corresponding frame of u) based on the verb-level similarities.\nWithin-Verb Frame Similarity: Within each verb v, which consists of a set of frame relations v1, ...vT , we also include frame-level similarity factors ψf between vi and vj . This gives us more evidence over a broader range of frames when textual evidence might be sparse.\nf a o v\ns\nObject Similarity: As with verbs, we add factors ψo that encourage similar pairs of objects to take the same value. Given that each node represents a pair of objects, finding that x and y are similar yields two main cases in how to add factors (aside from the trivial case where the variable Oax,y is given a unary factor to encourage the value ').\n1. If nodes Ox,z and Oy,z exist, we expect objects x and y to both have a similar relation to z. We add a factor that encourages Ox,z and Oy,z to take the same value. The same is true if nodes Oz,x and Oz,y exist.\n2. On the other hand, if nodesOx,z andOz,y exist, we expect these two nodes to reach the opposite decision. In this case, we add a factor that encourages one node to take the value > if the other prefers the value <, and vice versa. (For the case of ', if one prefers that value, then both should.)"
    }, {
      "heading" : "4.4 Cross-Knowledge Correlation",
      "text" : "Some knowledge dimensions, such as size and weight, have a significant correlation in their implied relations. For two such attributes a and b, if the same frame F avi and F b vi exists in both graphs,\nwe add a factor ψa between them to push them towards taking the same value."
    }, {
      "heading" : "4.5 Seed Knowledge",
      "text" : "In order to kick off learning, we provide a small set of seed knowledge among the random variables in {O,F} with seed factors ψseed. These unary seed factors push the belief for its associated random variable strongly towards the seed label."
    }, {
      "heading" : "4.6 Potential Functions",
      "text" : "Unary Factors: For all frame and object pair random variables in the training set, we train a maximum entropy classifier to predict the value of the variable. We then use the probabilities of the classifier as potentials for seed factors given to all random variables in their class (frame or object pair). Each log-linear classifier is trained separately per attribute on a featurized vector of the variable:\nP(r|Xa) ∝ ewa·f(Xa)\nThe feature function is defined differently according to the node type:\nf(Oap,q) := 〈g(p), g(q)〉 f(F avt) := 〈h(t), g(v), g(t)〉\nHere g(x) is the GloVe word embedding (Pennington et al., 2014) for the word x (t is the frame relation’s preposition, and g(t) is simply set to the zero vector if there is no preposition) and h(t) is a one-hot vector of the frame relation type. We use GloVe vectors of 100 dimensions for verbs and 50 dimensions for objects and prepositions (the dimensions picked based on development set).\nBinary Factors: In the case of all other factors, we use a “soft 1” agreement matrix with strong signal down the diagonals: > ' <> 0.7 0.1 0.2\n' 0.15 0.7 0.15 < 0.2 0.1 0.7 "
    }, {
      "heading" : "4.7 Inference",
      "text" : "After our full graph is constructed, we use belief propagation to infer the assignments of frames and object pairs not in our training data. Each message µ is a vector where each element is the probability that a random variable takes on each value x ∈ {>, <,'}. A message passed from a random variable v to a neighboring factor f about the value x is the product of the messages from its other neighboring factors about x:\nµv→f (x) ∝ ∏\nf ′∈N(v)\\{f}\nµf ′→v(x)\nA message passed from a factor f with potential ψ to a random variable v about its value x is a marginalized belief about v taking value x from the other neighboring random variables combined\nwith its potential: µf→v(x) ∝ ∑\nx:x[v]=x\nψ(x) ∏\nv′∈N(f)\\{v}\nµv′→f (x[v ′])\nAfter stopping belief propagation, the marginals for a node can be computed and used as a decision for that random variable. The marginal for v taking value x is the product of its surrounding factors’ messages:\nv(x) ∝ ∏\nf∈N(v)\nµf→v(x)"
    }, {
      "heading" : "5 Experimental Results",
      "text" : "Factor Graph Construction: We first need to pick a set of frames and objects to determine our set of random variables. The frames are simply the subset of the frames that were crowdsourced in the given configuration (e.g., seed + dev), with “soft 1” unary seed factors (the gold label indexed row of the binary factor matrix) given only to those in the seed set. The same selection criteria and seed factors are applied to the crowdsourced object pairs.\nFor lexical similarity factors (ψv, ψo), we pick connections based on the cosine similarity scores of GloVe vectors thresholded above a value chosen based on development set performance. Attribute similarity factors (ψa) are chosen based on sets of frames that reach largely the same decisions on the seed data (95%). Frame similarity factors (ψf ) are added to pairs of frames with linguistically similar constructions. Finally, selectional preference\nAttr\napprox max width\nFrame gloss Score Example model predictions (frame) (dev set) Ex\n___ opened ___ size1 PERSON set ___ upon ___ wgt2 ___ stood on ___ str3 PERSON arrived on ___ rgd4 ___ put up ___ spd5\n'> <\nclose\njust wrong + easy for humans to judge\nbad data; nonsensical comparison\ncould go either way (interesting physics things going on here)\nsome polysemy / either way possible\nPERSON drove ___ for ___ size6 PERSON stopped ___with ___ wgt7\n___ lived at ___ str8 ___ snipped off ___ rgd9 ___ caught ___ spd10\n'> <\nFigure 4: Example model predictions on dev set frames. The model’s confidence is shown by the bars on the right. The correct relation is highlighted in orange (6–10 are failure cases for the model). If there are two blanks, the relation is between them. If there is only one blank, the relation\nis between PERSON and the blank. Note that ' receives minuscule weight because it is never the correct value for frames in the seed set.\nfactors (ψs) are picked by using a threshold (also tuned on the development set) of pointwise mutual information (PMI) between the frames and the object pairs’ occurrences in the Google Syntax Ngram corpus.\nFor each task, we consider the set of factors to include in each model a hyperparameter, which is also tuned on the development set.\nBaselines: Baselines include making a RANDOM choice, picking between >, <, and '), picking the MAJORITY label, and a maximum entropy classifier based on the embedding representations (EMB-MAXENT) defined in Section 4.6.\nInferring Knowledge of Actions: Our first experiment is to predict knowledge implied by new frames. In this task, 5% of the frames are available as seed knowledge. We experiment with two different sets of seed knowledge for the object pair data: OUR MODEL (A) uses only 5% of the object pair data as seed, and OUR MODEL (B) uses 20%.\nThe full results for the baseline methods and our model are given in the upper half of Table 2. Our model outperforms the baselines on all attributes except for the speed, which has a highly skewed label distribution to allow the majority baseline to\nperform well. Ablations are given in Table 3, and sample correct predictions from the development set are shown in examples 1–5 of Figure 4.\nInferring Knowledge of Objects: Our second experiment is to predict the correct relations of new object pairs. The data for this task is the inverse of before: 5% of the object pairs are available as seed knowledge, and we experiment with both 5% (OUR MODEL (A)) and 20% (OUR MODEL (B)) frames given as seed data. Again, both are independently tuned on the development data. Results for this task are presented in the lower half of Table 2. While OUR MODEL (A) is competitive with the strongest baseline, introducing the additional frame data allows OUR MODEL (B) to reach the highest accuracy."
    }, {
      "heading" : "6 Discussion",
      "text" : "Metaphorical Language: While our frame patterns are intended to capture action verbs, our templates also match senses of those verbs that can be used with abstract or metaphorical arguments, rather than directly physical ones. One example from the development set is “x contained y.” While x and y can be real objects, more abstract senses of “contained” could involve y as a “forest fire” or even a “revolution.” In these instances, x >size y is plausible as an abstract notion: if some entity can contain a revolution, we might think that entity as “larger” or “stronger” than the revolution.\nError analysis: Examples 6–10 in Figure 4 highlight failure cases for the model. Example\n6 shows a case where the comparison is nonsensical because “for” would naturally be followed by a purpose (“He drove the car for work.”) or a duration (“She drove the car for hours.”) rather than a concrete object whose size is measurable. Example 7 highlights an underspecified frame. One crowd worker provided the example, “PERSON stopped the fly with {the jar / a swatter},” where fly <weight {jar, swatter}. However, two crowd workers provided examples like “PERSON stopped their car with the brake,” where clearly car >weight brake. This example illustrates complex underlying physics we do not model: a brake—the pedal itself—is used to stop a car, but it does so by applying significant force through a separate system.\nThe next two examples are cases where the model nearly predicts correctly (8, e.g., “She lived at the office.”) and is just clearly wrong (9, e.g., “He snipped off a locket of hair”). Example 10 demonstrates a case of polysemy where the model picks the wrong side. In the phrase, “She caught the runner in first,”, it is correct that she >speed runner. However, the sense chosen by the crowd workers is that of, “She caught the baseball,” where indeed she <speed baseball."
    }, {
      "heading" : "7 Related work",
      "text" : "Several works straddle the gap between IE, knowledge base completion, and learning commonsense knowledge from text. Earlier works in these areas use large amounts of text to try to extract general statements like “A THING CAN BE READABLE” (Gordon et al., 2010) and frequencies of events (Gordon and Schubert, 2012). Our work focuses on specific domains of knowledge rather than general statements or occurrence statistics, and develops a frame-centric approach to circumvent reporting bias. Other work uses a knowledge base and scores unseen tuples based on similarity to existing ones (Angeli and Manning, 2013; Li et al., 2016), or extends it by inferring new facts from unstructured text using natural language inference (Angeli and Manning, 2014). Zhang et al. (2017) predict the likelihood of entailed commonsense statements extracted from a large text corpus. In contrast to the above, our work seeks to induce several novel types of graded physical knowledge which lack existing databases.\nA number of recent works combine multimodal input to learn visual attributes (Bruni et al.,\n2012; Silberer et al., 2013), extract commonsense knowledge from web images (Tandon et al., 2016), and overcome reporting bias (Misra et al., 2016). In contrast, we focus on natural language evidence to reason about attributes that are both in (size) and out (weight, rigidness, etc.) of the scope of computer vision. Yet other works mine numerical attributes of objects (Narisawa et al., 2013; Takamura and Tsujii, 2015; Davidov and Rappoport, 2010) and comparative knowledge from the web (Tandon et al., 2014). Our work uniquely learns verb-centric lexical entailment knowledge.\nA handful of works have attempted to learn the types of knowledge we address in this work. One recent work tried to directly predict several binary attributes (such “is large” and “is yellow”) from on off-the-shelf word embeddings, noting that accuracy was very low (Rubinstein et al., 2015). Another line of work addressed grounding verbs in the context of robotic tasks. One paper in this line acquires verb meanings by observing state changes in the environment (She and Chai, 2016). Another work in this line does a deep investigation of eleven verbs, modeling their physical effect via annotated images along eighteen attributes (Gao et al., 2016). These works are encouraging investigations into multimodal groundings of a small set of verbs. Our work instead grounds into a fixed set of attributes but leverages language on a broader scale to learn about more verbs in more diverse set of frames. In this, our work can be seen as exploring predicate lexical semantics in the vein of semantic proto-roles (Dowty, 1991; Kako, 2006; Reisinger et al., 2015), but instead affording pairwise, physical relations between roles ."
    }, {
      "heading" : "8 Conclusion",
      "text" : "We presented a novel take on verb-centric frame semantics to learn implied physical knowledge latent in verbs. Empirical results confirm that by modeling changes in physical attributes entailed by verbs together with objects that exhibit these properties, we are able to better infer new knowledge in both domains."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE1256082, in part by DARPA CwC program through ARO (W911NF-15-1-0543), the NSF\ngrant (IIS-1524371), and gifts by Google and Facebook. The authors thank the anonymous reviewers for their thorough and insightful comments."
    } ],
    "references" : [ {
      "title" : "Philosophers are mortal: Inferring the truth of unseen facts",
      "author" : [ "Gabor Angeli", "Christopher D Manning." ],
      "venue" : "CoNLL. pages 133–142.",
      "citeRegEx" : "Angeli and Manning.,? 2013",
      "shortCiteRegEx" : "Angeli and Manning.",
      "year" : 2013
    }, {
      "title" : "Naturalli: Natural logic inference for common sense reasoning",
      "author" : [ "Gabor Angeli", "Christopher D Manning." ],
      "venue" : "EMNLP. pages 534–545.",
      "citeRegEx" : "Angeli and Manning.,? 2014",
      "shortCiteRegEx" : "Angeli and Manning.",
      "year" : 2014
    }, {
      "title" : "Are elephants bigger than butterflies? reasoning about sizes of objects",
      "author" : [ "Hessam Bagherinezhad", "Hannaneh Hajishirzi", "Yejin Choi", "Ali Farhadi." ],
      "venue" : "arXiv preprint arXiv:1602.00753 .",
      "citeRegEx" : "Bagherinezhad et al\\.,? 2016",
      "shortCiteRegEx" : "Bagherinezhad et al\\.",
      "year" : 2016
    }, {
      "title" : "The berkeley framenet project",
      "author" : [ "Collin F Baker", "Charles J Fillmore", "John B Lowe." ],
      "venue" : "Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics-",
      "citeRegEx" : "Baker et al\\.,? 1998",
      "shortCiteRegEx" : "Baker et al\\.",
      "year" : 1998
    }, {
      "title" : "Distributional semantics in technicolor",
      "author" : [ "Elia Bruni", "Gemma Boleda", "Marco Baroni", "NamKhanh Tran." ],
      "venue" : "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1. Association for Com-",
      "citeRegEx" : "Bruni et al\\.,? 2012",
      "shortCiteRegEx" : "Bruni et al\\.",
      "year" : 2012
    }, {
      "title" : "A unified analysis of the english bare plural",
      "author" : [ "Greg N Carlson." ],
      "venue" : "Linguistics and philosophy 1(3):413– 457.",
      "citeRegEx" : "Carlson.,? 1977",
      "shortCiteRegEx" : "Carlson.",
      "year" : 1977
    }, {
      "title" : "Extraction and approximation of numerical attributes from the web",
      "author" : [ "Dmitry Davidov", "Ari Rappoport." ],
      "venue" : "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, pages",
      "citeRegEx" : "Davidov and Rappoport.,? 2010",
      "shortCiteRegEx" : "Davidov and Rappoport.",
      "year" : 2010
    }, {
      "title" : "Thematic proto-roles and argument selection",
      "author" : [ "David Dowty." ],
      "venue" : "language pages 547–619.",
      "citeRegEx" : "Dowty.,? 1991",
      "shortCiteRegEx" : "Dowty.",
      "year" : 1991
    }, {
      "title" : "Frame semantics and the nature of language",
      "author" : [ "Charles J Fillmore." ],
      "venue" : "Annals of the New York Academy of Sciences 280(1):20–32.",
      "citeRegEx" : "Fillmore.,? 1976",
      "shortCiteRegEx" : "Fillmore.",
      "year" : 1976
    }, {
      "title" : "Physical causality of action verbs in grounded language understanding",
      "author" : [ "Qiaozi Gao", "Malcolm Doering", "Shaohua Yang", "Joyce Y Chai." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL). volume 1,",
      "citeRegEx" : "Gao et al\\.,? 2016",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2016
    }, {
      "title" : "A dataset of syntactic-ngrams over time from a very large corpus of english books",
      "author" : [ "Yoav Goldberg", "Jon Orwant." ],
      "venue" : "Second Joint Conference on Lexical and Computational Semantics (* SEM). volume 1, pages 241–247.",
      "citeRegEx" : "Goldberg and Orwant.,? 2013",
      "shortCiteRegEx" : "Goldberg and Orwant.",
      "year" : 2013
    }, {
      "title" : "Using textual patterns to learn expected event frequencies",
      "author" : [ "Jonathan Gordon", "Lenhart K Schubert." ],
      "venue" : "Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction. Association for Computa-",
      "citeRegEx" : "Gordon and Schubert.,? 2012",
      "shortCiteRegEx" : "Gordon and Schubert.",
      "year" : 2012
    }, {
      "title" : "Reporting bias and knowledge acquisition",
      "author" : [ "Jonathan Gordon", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the 2013 workshop on Automated knowledge base construction. ACM, pages 25–30.",
      "citeRegEx" : "Gordon and Durme.,? 2013",
      "shortCiteRegEx" : "Gordon and Durme.",
      "year" : 2013
    }, {
      "title" : "Learning from the web: Extracting general world knowledge from noisy text",
      "author" : [ "Jonathan Gordon", "Benjamin Van Durme", "Lenhart K Schubert." ],
      "venue" : "Collaboratively-Built Knowledge Sources and AI.",
      "citeRegEx" : "Gordon et al\\.,? 2010",
      "shortCiteRegEx" : "Gordon et al\\.",
      "year" : 2010
    }, {
      "title" : "Logic and conversation",
      "author" : [ "HP Grice." ],
      "venue" : "P. Cole and J. Morgan, editors, Syntax and Semantics. Academic Press, New York, volume 3: Speech Acts.",
      "citeRegEx" : "Grice.,? 1975",
      "shortCiteRegEx" : "Grice.",
      "year" : 1975
    }, {
      "title" : "Segment-phrase table for semantic segmentation, visual entailment and paraphrasing",
      "author" : [ "Hamid Izadinia", "Fereshteh Sadeghi", "Santosh K Divvala", "Hannaneh Hajishirzi", "Yejin Choi", "Ali Farhadi." ],
      "venue" : "Proceedings of the IEEE International Confer-",
      "citeRegEx" : "Izadinia et al\\.,? 2015",
      "shortCiteRegEx" : "Izadinia et al\\.",
      "year" : 2015
    }, {
      "title" : "Thematic role properties of subjects and objects",
      "author" : [ "Edward Kako." ],
      "venue" : "Cognition 101(1):1–42.",
      "citeRegEx" : "Kako.,? 2006",
      "shortCiteRegEx" : "Kako.",
      "year" : 2006
    }, {
      "title" : "Class-based construction of a verb lexicon",
      "author" : [ "Karin Kipper", "Hoa Trang Dang", "Martha Palmer" ],
      "venue" : null,
      "citeRegEx" : "Kipper et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Kipper et al\\.",
      "year" : 2000
    }, {
      "title" : "English verb classes and alternations: A preliminary investigation",
      "author" : [ "Beth Levin." ],
      "venue" : "University of Chicago press.",
      "citeRegEx" : "Levin.,? 1993",
      "shortCiteRegEx" : "Levin.",
      "year" : 1993
    }, {
      "title" : "Commonsense knowledge base completion",
      "author" : [ "Xiang Li", "Aynaz Taheri", "Lifu Tu", "Kevin Gimpel." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL), Berlin, Germany, August. Association for Computa-",
      "citeRegEx" : "Li et al\\.,? 2016",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Quantitative analysis of culture using millions of digitized books. science",
      "author" : [ "Jean-Baptiste Michel", "Yuan Kui Shen", "Aviva Presser Aiden", "Adrian Veres", "Matthew K Gray", "Joseph P Pickett", "Dale Hoiberg", "Dan Clancy", "Peter Norvig", "Jon Orwant" ],
      "venue" : null,
      "citeRegEx" : "Michel et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Michel et al\\.",
      "year" : 2011
    }, {
      "title" : "Wordnet: a lexical database for english",
      "author" : [ "George A Miller." ],
      "venue" : "Communications of the ACM 38(11):39–",
      "citeRegEx" : "Miller.,? 1995",
      "shortCiteRegEx" : "Miller.",
      "year" : 1995
    }, {
      "title" : "Seeing through the human reporting bias: Visual classifiers from noisy humancentric labels",
      "author" : [ "Ishan Misra", "C Lawrence Zitnick", "Margaret Mitchell", "Ross Girshick." ],
      "venue" : "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
      "citeRegEx" : "Misra et al\\.,? 2016",
      "shortCiteRegEx" : "Misra et al\\.",
      "year" : 2016
    }, {
      "title" : "Is a 204 cm man tall or small? acquisition of numerical common sense from the web",
      "author" : [ "Katsuma Narisawa", "Yotaro Watanabe", "Junta Mizuno", "Naoaki Okazaki", "Kentaro Inui." ],
      "venue" : "ACL (1). pages 382– 391.",
      "citeRegEx" : "Narisawa et al\\.,? 2013",
      "shortCiteRegEx" : "Narisawa et al\\.",
      "year" : 2013
    }, {
      "title" : "The proposition bank: An annotated corpus of semantic roles",
      "author" : [ "Martha Palmer", "Daniel Gildea", "Paul Kingsbury." ],
      "venue" : "Computational linguistics 31(1):71– 106.",
      "citeRegEx" : "Palmer et al\\.,? 2005",
      "shortCiteRegEx" : "Palmer et al\\.",
      "year" : 2005
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D. Manning." ],
      "venue" : "Empirical Methods in Natural Language Processing (EMNLP). pages 1532– 1543. http://www.aclweb.org/anthology/D14-1162.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Semantic proto-roles",
      "author" : [ "Drew Reisinger", "Rachel Rudinger", "Francis Ferraro", "Craig Harman", "Kyle Rawlins", "Benjamin Van Durme." ],
      "venue" : "Transactions of the Association for Computational Linguistics 3:475–488.",
      "citeRegEx" : "Reisinger et al\\.,? 2015",
      "shortCiteRegEx" : "Reisinger et al\\.",
      "year" : 2015
    }, {
      "title" : "How well do distributional models capture different types of semantic knowledge? In ACL (2)",
      "author" : [ "Dana Rubinstein", "Effi Levi", "Roy Schwartz", "Ari Rappoport." ],
      "venue" : "pages 726–730.",
      "citeRegEx" : "Rubinstein et al\\.,? 2015",
      "shortCiteRegEx" : "Rubinstein et al\\.",
      "year" : 2015
    }, {
      "title" : "Viske: Visual knowledge extraction and question answering by visual verification of relation phrases",
      "author" : [ "Fereshteh Sadeghi", "Santosh K Kumar Divvala", "Ali Farhadi." ],
      "venue" : "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
      "citeRegEx" : "Sadeghi et al\\.,? 2015",
      "shortCiteRegEx" : "Sadeghi et al\\.",
      "year" : 2015
    }, {
      "title" : "Incremental acquisition of verb hypothesis space towards physical world interaction",
      "author" : [ "Lanbo She", "Joyce Y Chai." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL).",
      "citeRegEx" : "She and Chai.,? 2016",
      "shortCiteRegEx" : "She and Chai.",
      "year" : 2016
    }, {
      "title" : "Models of semantic representation with visual attributes",
      "author" : [ "Carina Silberer", "Vittorio Ferrari", "Mirella Lapata." ],
      "venue" : "ACL (1). pages 572–582.",
      "citeRegEx" : "Silberer et al\\.,? 2013",
      "shortCiteRegEx" : "Silberer et al\\.",
      "year" : 2013
    }, {
      "title" : "Inverting grice’s maxims to learn rules from natural language extractions",
      "author" : [ "Mohammad S Sorower", "Janardhan R Doppa", "Walker Orr", "Prasad Tadepalli", "Thomas G Dietterich", "Xiaoli Z Fern." ],
      "venue" : "Advances in neural information processing systems.",
      "citeRegEx" : "Sorower et al\\.,? 2011",
      "shortCiteRegEx" : "Sorower et al\\.",
      "year" : 2011
    }, {
      "title" : "Estimating numerical attributes by bringing together fragmentary clues",
      "author" : [ "Hiroya Takamura", "Jun’ichi Tsujii" ],
      "venue" : "In HLT-NAACL",
      "citeRegEx" : "Takamura and Tsujii.,? \\Q2015\\E",
      "shortCiteRegEx" : "Takamura and Tsujii.",
      "year" : 2015
    }, {
      "title" : "Acquiring comparative commonsense knowledge from the web",
      "author" : [ "Niket Tandon", "Gerard De Melo", "Gerhard Weikum." ],
      "venue" : "AAAI. pages 166–172.",
      "citeRegEx" : "Tandon et al\\.,? 2014",
      "shortCiteRegEx" : "Tandon et al\\.",
      "year" : 2014
    }, {
      "title" : "Commonsense in parts: Mining part-whole relations from the web and image tags",
      "author" : [ "Niket Tandon", "Charles Hariman", "Jacopo Urbani", "Anna Rohrbach", "Marcus Rohrbach", "Gerhard Weikum." ],
      "venue" : "AAAI. pages 243–250.",
      "citeRegEx" : "Tandon et al\\.,? 2016",
      "shortCiteRegEx" : "Tandon et al\\.",
      "year" : 2016
    }, {
      "title" : "Extracting implicit knowledge from text",
      "author" : [ "Benjamin D Van Durme." ],
      "venue" : "University of Rochester.",
      "citeRegEx" : "Durme.,? 2010",
      "shortCiteRegEx" : "Durme.",
      "year" : 2010
    }, {
      "title" : "Ordinal common-sense inference",
      "author" : [ "Sheng Zhang", "Rachel Rudinger", "Kevin Duh", "Ben Van Durme." ],
      "venue" : "Transactions of the Association for Computational Linguistics .",
      "citeRegEx" : "Zhang et al\\.,? 2017",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2017
    }, {
      "title" : "Reasoning about object affordances in a knowledge base representation",
      "author" : [ "Yuke Zhu", "Alireza Fathi", "Li Fei-Fei." ],
      "venue" : "European conference on computer vision. Springer, pages 408–424.",
      "citeRegEx" : "Zhu et al\\.,? 2014",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "in recent work that requires visual reasoning and entailment (Izadinia et al., 2015; Zhu et al., 2014).",
      "startOffset" : 61,
      "endOffset" : 102
    }, {
      "referenceID" : 37,
      "context" : "in recent work that requires visual reasoning and entailment (Izadinia et al., 2015; Zhu et al., 2014).",
      "startOffset" : 61,
      "endOffset" : 102
    }, {
      "referenceID" : 31,
      "context" : "The central challenge lies in reporting bias: people rarely states the obvious (Van Durme, 2010; Sorower et al., 2011; Gordon and Van Durme, 2013; Misra et al., 2016; Zhang et al., 2017), since it goes against Grice’s conversational maxim on the quantity of information (Grice, 1975).",
      "startOffset" : 79,
      "endOffset" : 186
    }, {
      "referenceID" : 22,
      "context" : "The central challenge lies in reporting bias: people rarely states the obvious (Van Durme, 2010; Sorower et al., 2011; Gordon and Van Durme, 2013; Misra et al., 2016; Zhang et al., 2017), since it goes against Grice’s conversational maxim on the quantity of information (Grice, 1975).",
      "startOffset" : 79,
      "endOffset" : 186
    }, {
      "referenceID" : 36,
      "context" : "The central challenge lies in reporting bias: people rarely states the obvious (Van Durme, 2010; Sorower et al., 2011; Gordon and Van Durme, 2013; Misra et al., 2016; Zhang et al., 2017), since it goes against Grice’s conversational maxim on the quantity of information (Grice, 1975).",
      "startOffset" : 79,
      "endOffset" : 186
    }, {
      "referenceID" : 14,
      "context" : ", 2017), since it goes against Grice’s conversational maxim on the quantity of information (Grice, 1975).",
      "startOffset" : 91,
      "endOffset" : 104
    }, {
      "referenceID" : 15,
      "context" : "Thus, our work provides unique value to complement recent attempts to acquire commonsense knowledge from web images (Izadinia et al., 2015; Bagherinezhad et al., 2016; Sadeghi et al., 2015).",
      "startOffset" : 116,
      "endOffset" : 189
    }, {
      "referenceID" : 2,
      "context" : "Thus, our work provides unique value to complement recent attempts to acquire commonsense knowledge from web images (Izadinia et al., 2015; Bagherinezhad et al., 2016; Sadeghi et al., 2015).",
      "startOffset" : 116,
      "endOffset" : 189
    }, {
      "referenceID" : 28,
      "context" : "Thus, our work provides unique value to complement recent attempts to acquire commonsense knowledge from web images (Izadinia et al., 2015; Bagherinezhad et al., 2016; Sadeghi et al., 2015).",
      "startOffset" : 116,
      "endOffset" : 189
    }, {
      "referenceID" : 5,
      "context" : "On the other hand, speed concerns stage-level semantics; its implied relations hold only during a window surrounding the verb (Carlson, 1977).",
      "startOffset" : 126,
      "endOffset" : 141
    }, {
      "referenceID" : 8,
      "context" : "This is generally not true, since a verb, especially a common action verb, can often invoke a number of different frames according to frame semantics (Fillmore, 1976).",
      "startOffset" : 150,
      "endOffset" : 166
    }, {
      "referenceID" : 8,
      "context" : "Importantly, the key insight of our work is inspired by Fillmore’s original manuscript on frame semantics (Fillmore, 1976).",
      "startOffset" : 106,
      "endOffset" : 122
    }, {
      "referenceID" : 3,
      "context" : "While existing frame annotations such as FrameNet (Baker et al., 1998), PropBank (Palmer et al.",
      "startOffset" : 50,
      "endOffset" : 70
    }, {
      "referenceID" : 24,
      "context" : ", 1998), PropBank (Palmer et al., 2005), and VerbNet (Kipper et al.",
      "startOffset" : 18,
      "endOffset" : 39
    }, {
      "referenceID" : 17,
      "context" : ", 2005), and VerbNet (Kipper et al., 2000) provide rich frame knowledge associated",
      "startOffset" : 21,
      "endOffset" : 42
    }, {
      "referenceID" : 7,
      "context" : "In addition, our work is motivated by the formal semantics of Dowty (1991), as the task of learning verb implications is essentially that of extracting lexical entailments for verbs.",
      "startOffset" : 62,
      "endOffset" : 75
    }, {
      "referenceID" : 18,
      "context" : "Action Verbs: We pick 50 classes of Levin verbs from both “alternation classes” and “verb classes” (Levin, 1993), which corresponds to about 1100 unique verbs.",
      "startOffset" : 99,
      "endOffset" : 112
    }, {
      "referenceID" : 10,
      "context" : "We sort this list by frequency of occurrence in our frame patterns in the Google Syntax Ngrams corpus (Goldberg and Orwant, 2013) and pick the top 100 verbs.",
      "startOffset" : 102,
      "endOffset" : 129
    }, {
      "referenceID" : 20,
      "context" : "Thus we refine our prepositions for each frame by taking either the intersection or union with the top 5 Google Surface Ngrams (Michel et al., 2011), depending on whether the frame was under- or over-generating.",
      "startOffset" : 127,
      "endOffset" : 148
    }, {
      "referenceID" : 21,
      "context" : "After replacing a small set of “human” nouns with a generic HUMAN object, filtering out nouns labeled as abstract by WordNet (Miller, 1995), and distilling all surface forms to their lemmas (also with WordNet), the result is 3656 object pairs.",
      "startOffset" : 125,
      "endOffset" : 139
    }, {
      "referenceID" : 25,
      "context" : "Here g(x) is the GloVe word embedding (Pennington et al., 2014) for the word x (t is the frame relation’s preposition, and g(t) is simply set to the zero vector if there is no preposition) and h(t) is a one-hot vector of the frame relation type.",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 13,
      "context" : "Earlier works in these areas use large amounts of text to try to extract general statements like “A THING CAN BE READABLE” (Gordon et al., 2010) and frequencies of events (Gordon and Schubert, 2012).",
      "startOffset" : 123,
      "endOffset" : 144
    }, {
      "referenceID" : 11,
      "context" : ", 2010) and frequencies of events (Gordon and Schubert, 2012).",
      "startOffset" : 34,
      "endOffset" : 61
    }, {
      "referenceID" : 0,
      "context" : "Other work uses a knowledge base and scores unseen tuples based on similarity to existing ones (Angeli and Manning, 2013; Li et al., 2016), or extends it by inferring new facts from unstructured text using natural language inference (Angeli and Manning, 2014).",
      "startOffset" : 95,
      "endOffset" : 138
    }, {
      "referenceID" : 19,
      "context" : "Other work uses a knowledge base and scores unseen tuples based on similarity to existing ones (Angeli and Manning, 2013; Li et al., 2016), or extends it by inferring new facts from unstructured text using natural language inference (Angeli and Manning, 2014).",
      "startOffset" : 95,
      "endOffset" : 138
    }, {
      "referenceID" : 1,
      "context" : ", 2016), or extends it by inferring new facts from unstructured text using natural language inference (Angeli and Manning, 2014).",
      "startOffset" : 102,
      "endOffset" : 128
    }, {
      "referenceID" : 0,
      "context" : "Other work uses a knowledge base and scores unseen tuples based on similarity to existing ones (Angeli and Manning, 2013; Li et al., 2016), or extends it by inferring new facts from unstructured text using natural language inference (Angeli and Manning, 2014). Zhang et al. (2017) predict the likelihood of entailed commonsense statements extracted from a large text corpus.",
      "startOffset" : 96,
      "endOffset" : 281
    }, {
      "referenceID" : 4,
      "context" : "A number of recent works combine multimodal input to learn visual attributes (Bruni et al., 2012; Silberer et al., 2013), extract commonsense knowledge from web images (Tandon et al.",
      "startOffset" : 77,
      "endOffset" : 120
    }, {
      "referenceID" : 30,
      "context" : "A number of recent works combine multimodal input to learn visual attributes (Bruni et al., 2012; Silberer et al., 2013), extract commonsense knowledge from web images (Tandon et al.",
      "startOffset" : 77,
      "endOffset" : 120
    }, {
      "referenceID" : 34,
      "context" : ", 2013), extract commonsense knowledge from web images (Tandon et al., 2016), and overcome reporting bias (Misra et al.",
      "startOffset" : 55,
      "endOffset" : 76
    }, {
      "referenceID" : 22,
      "context" : ", 2016), and overcome reporting bias (Misra et al., 2016).",
      "startOffset" : 37,
      "endOffset" : 57
    }, {
      "referenceID" : 23,
      "context" : "Yet other works mine numerical attributes of objects (Narisawa et al., 2013; Takamura and Tsujii, 2015; Davidov and Rappoport, 2010) and comparative knowledge from the web (Tandon et al.",
      "startOffset" : 53,
      "endOffset" : 132
    }, {
      "referenceID" : 32,
      "context" : "Yet other works mine numerical attributes of objects (Narisawa et al., 2013; Takamura and Tsujii, 2015; Davidov and Rappoport, 2010) and comparative knowledge from the web (Tandon et al.",
      "startOffset" : 53,
      "endOffset" : 132
    }, {
      "referenceID" : 6,
      "context" : "Yet other works mine numerical attributes of objects (Narisawa et al., 2013; Takamura and Tsujii, 2015; Davidov and Rappoport, 2010) and comparative knowledge from the web (Tandon et al.",
      "startOffset" : 53,
      "endOffset" : 132
    }, {
      "referenceID" : 33,
      "context" : ", 2013; Takamura and Tsujii, 2015; Davidov and Rappoport, 2010) and comparative knowledge from the web (Tandon et al., 2014).",
      "startOffset" : 103,
      "endOffset" : 124
    }, {
      "referenceID" : 27,
      "context" : "One recent work tried to directly predict several binary attributes (such “is large” and “is yellow”) from on off-the-shelf word embeddings, noting that accuracy was very low (Rubinstein et al., 2015).",
      "startOffset" : 175,
      "endOffset" : 200
    }, {
      "referenceID" : 29,
      "context" : "One paper in this line acquires verb meanings by observing state changes in the environment (She and Chai, 2016).",
      "startOffset" : 92,
      "endOffset" : 112
    }, {
      "referenceID" : 9,
      "context" : "Another work in this line does a deep investigation of eleven verbs, modeling their physical effect via annotated images along eighteen attributes (Gao et al., 2016).",
      "startOffset" : 147,
      "endOffset" : 165
    }, {
      "referenceID" : 7,
      "context" : "In this, our work can be seen as exploring predicate lexical semantics in the vein of semantic proto-roles (Dowty, 1991; Kako, 2006; Reisinger et al., 2015), but instead affording pairwise, physical relations between roles .",
      "startOffset" : 107,
      "endOffset" : 156
    }, {
      "referenceID" : 16,
      "context" : "In this, our work can be seen as exploring predicate lexical semantics in the vein of semantic proto-roles (Dowty, 1991; Kako, 2006; Reisinger et al., 2015), but instead affording pairwise, physical relations between roles .",
      "startOffset" : 107,
      "endOffset" : 156
    }, {
      "referenceID" : 26,
      "context" : "In this, our work can be seen as exploring predicate lexical semantics in the vein of semantic proto-roles (Dowty, 1991; Kako, 2006; Reisinger et al., 2015), but instead affording pairwise, physical relations between roles .",
      "startOffset" : 107,
      "endOffset" : 156
    } ],
    "year" : 2017,
    "abstractText" : "Learning commonsense knowledge from natural language text is nontrivial due to reporting bias: people rarely state the obvious, e.g., “My house is bigger than me.” However, while rarely stated explicitly, this trivial everyday knowledge does influence the way people talk about the world, which provides indirect clues to reason about the world. For example, a statement like, “Tyler entered his house” implies that his house is bigger than Tyler. In this paper, we present an approach to infer relative physical knowledge of actions and objects along five dimensions (e.g., size, weight, and strength) from unstructured natural language text. We frame knowledge acquisition as joint inference over two closely related problems: learning (1) relative physical knowledge of object pairs and (2) physical implications of actions when applied to those object pairs. Empirical results demonstrate that it is possible to extract knowledge of actions and objects from language and that joint inference over different types of knowledge improves performance.",
    "creator" : "LaTeX with hyperref package"
  }
}