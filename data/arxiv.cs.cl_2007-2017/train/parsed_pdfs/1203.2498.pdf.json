{
  "name" : "1203.2498.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Fault detection system for Arabic language",
    "authors" : [ "Houda AMRAOUI", "Riadh BOUSLIM", "HOUDA AMRAOUI", "RIADH BOUSLIMI" ],
    "emails" : [ "houda.amrawi@gmail.com", "bouslimi.riadh@hotmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "4 ème atelier international sur l’amazighe et les TIC\nFault detection system for Arabic language\nHouda AMRAOUI 1 , Riadh BOUSLIM 2\n1 University FSJEGJ Jendouba Tunisia\nhouda.amrawi@gmail.com\n2 University FSJEGJ Jendouba Tunisia\nbouslimi.riadh@hotmail.com\n1.Introduction\nThe study of natural language, especially Arabic, and mechanisms for the implementation of automatic processing is a fascinating field of study, with various potential applications. The importance of tools for natural language processing is materialized by the need to have applications that can effectively treat the vast mass of information available nowadays on electronic forms. Among these tools, mainly driven by the necessity of a fast writing in alignment to the actual daily life speed, our interest is on the writing auditors.\nThe morphological and syntactic properties of Arabic make it a difficult language to master, and explain the lack in the processing tools for that language. Among these properties, we can mention: the complex structure of the Arabic word, the agglutinative nature, lack of vocalization, the segmentation of the text, the linguistic richness, etc.\nIn that perspective, our project aims to develop a system to detect errors in spelling, structure and conjugation of the Arabic language. In this article we will proceed as follows. In the first section we’ll present some approaches used for the correction of errors. The second section will be devoted to detailed studies of our proposed system. In the last section, we’ll perform experimental tests to evaluate the performance of our system.\n2.State of the art\n2.1. MASPAR\nA multi-agent system is a system of agents’ group that communicate with one another to provide answers about a goal to achieve.\nMASPAR is a system of analysis of Arabic texts based on the approach of multi-agents. It consists of a set of agents, using a direct communication by sending messages. These agents work together in order to make syntaxes’ analysis of a sentence given by the user by determining its syntax composition. (tree, je ne sais pas si ca existe!!!c un mot relativement technique, il faut voir...)"
    }, {
      "heading" : "2.1.1. MASPAR System Limits",
      "text" : "The major drawback of such system is the time taken by the agents for communication and interaction.\n4 ème atelier international sur l’amazighe et les TIC\nOne might also note that the MASPAR system does not detect errors of conjugation. Also, it has a non-ergonomic interface."
    }, {
      "heading" : "3. Proposed System",
      "text" : ""
    }, {
      "heading" : "3.1. General Description",
      "text" : "Our system (Figure 1) is designed to detect errors in spelling, structure and conjugation in a non- vowelized Arabic text. It consists of five phases, each uses the information received from the previous phase to finally get a text containing the least number of mistakes.\nThe segmentation phase consists on dividing the text into sentences and then into words. The lexical phase subsequently receives the word and checks its existence in the database of words.\nAfter verifying that this word belongs to the language, the phase labelling associates the word it has received the possible morph syntactic labels, this makes the word ambiguous, hence the need to remove this ambiguity by passing phase disambiguation, which in applying certain rules, is used to assign to this word the most suitable label.\nTo correct the word “Wc”, we must compare it with the database of words that we have, if this word belongs to our dictionary, it means that “Wc” is a correct word otherwise our system will detect a misspelling.\nThe algorithm then verify the proper structure of this sentence, otherwise the system will detect a structure fault. Finally, our system is also capable to detect the faults of conjugation in a sentence.\nWe, first, introduce the general architecture of our system.\n4 ème atelier international sur l’amazighe et les TIC\nFigure 1 : Proposed system\nIntroduce the text\nReceiving text\nSegmentation\nSentence n Sentence 2 Sentence 1\nWord 1 Word 2 Word n\nLexical Analysis\nExists\nDetecting faults Labelling\nType (or types) of Word\nDisambiguation\nType unambiguous of Word 1\nType unambiguous of Word n\nSentence structure\nData base XML for\nData base XML of structural\nrules\nData base XML of\nconjugation rules\nText verified\n4 ème atelier international sur l’amazighe et les TIC"
    }, {
      "heading" : "3.2. Detailed Description",
      "text" : "When receiving an electronic text to analyze, our system launches the first phase which is segmentation. This phase begins with the identification of the text’ sentences based on punctuation signs then on the words in each sentence. Subsequently, the words in each sentence will be transferred one by one to the lexical phase.\nThis will verify whether the word belongs to the language or not by checking its existence in our database of words. Subsequently, the word is sent to the next phase. The phase label is responsible for providing possible morph syntactic characteristics of each received word (from the lexical phase). This means that a word can’t go to the labelling phase unless its belonging to our database has been confirmed within the lexical phase.\nBecause each word can have several labels, the analysis of the word can face certain ambiguity. That’s why we must use rules to reduce this ambiguity. Therefore, disambiguation phase is triggered to limit the number of labels associated with the word and assign a single label at a time.\nOnce the ambiguity is removed, we get into the final phase of the system which role is to apply rules that enable to compare the analyzed structures. This helps detect errors in structure and conjugation.\nALGORITHM Editor STARTERS: Wc: the word of the sentence\nPhrase: the input sentence BaseXml: the database contains dictionary words BaseReglesStruc: the database of structural rules BaseReglesConjug: the database according to the rules of conjugation\nSTART FOR each Phrase DO FOR each Wc of Phrase DO If (Wc, BaseXml) == false then Write (Wc 'is incorrect')\nOtherwise TypeD ReccupererType (Wc, BaseXMl)\nStructurephrase D Type\nEnd if End For Compare (Structurephrase, BaseReglesStruc) If (compare == true) then Write ('the structure of the sentence is not correct')\nOtherwise If the structure contains a verb then Apply (BaseReglesConjug, Structurephrase)\nEnd if If (Apply==false) then Write ('the combination is not correct')\nEnd if End if End For\nEND.\n4 ème atelier international sur l’amazighe et les TIC"
    }, {
      "heading" : "3.2.1. Segmentation",
      "text" : "This phase consists on dividing the text into sentences and the sentences into words based on markers at the beginning and the end, for example points, semicolons, colons…"
    }, {
      "heading" : "3.2.2. Lexical Analysis",
      "text" : "This phase checks the belonging of each word to the language, obtained from the segmentation phase based on the data base of the words available.\nVerify the existence of the base in the lexicon : We must ensure that the words introduced constitute the basics of the Arabic language. For that reason, we verify the existence of the base in the lexicon. We have to consult the database of Arabic words, if the extracted base coincides with a word from the database; we conclude that the word exists in Arabic."
    }, {
      "heading" : "3.2.3. Labelling",
      "text" : "This operation aims to add to the words linguistic information with morphological or syntactic nature in order to identify them.\nWe have presented several possible tags of the word minimum (prefix + base + suffix):\nHowever, the lack of vocalization does not accurately determine the proper etiquette of the word which causes a certain ambiguity. To reduce this ambiguity, we will proceed to the next step."
    }, {
      "heading" : "3.2.4. Disambiguation",
      "text" : "A disambiguation is needed to limit the number of labels of these words and subsequently improve the detection of grammatical errors.\nCompatibility Rules: It can reduce the ambiguity of a word by associating it with one type at a time, so the sentence containing the ambiguous word has more than a structure based on the number of labels that word. Subsequently, the system associates to the word the suitable type according to the structural rules."
    }, {
      "heading" : "3.2.5. Detecting faults",
      "text" : "For the detection of faults, we can use rules of grammar. These rules describe correct grammatical patterns. For this, we have defined a basic structure rules and another different basis for the conjugation rules. If some text does not match any rule, a structural or conjugal error is detected. To detect structural faults, we’ll compare our sentences’ structure with the basic structural rules, if this structure does not coincide with any rule, then a lack of structure will be detected, otherwise, if the structure is correct and if it contains a verb, since the combination only applies to the verb, our system will have access to our database conjugation, satisfies a certain compatibility between pre-and post-basic core that typically accompany the verb, if our sentence presents a bad combination when a fault is detected. In the end, the user receives a text containing errors detected with staining of these faults, each depending on the type of errors detected.\n4 ème atelier international sur l’amazighe et les TIC\n3.2.6.The databases used in the system\nXML database for the detection of spelling errors\nTo detect if the spelling of a given word is correct or not, the verification process run through the XML tree of the dictionary and compare the word with the word list file. It sets out below a portion of our base words.\nXML Data Base for the detection of structural faults\nAfter ascertaining that the specified words are spelled correctly, we assess at this level whether the sentence structure is coherent or not by comparing it with the base of the structures we have created an XML file with the following form:\nXML Data Base for detecting faults conjugation\nOur system can also detect conjugation errors. To handle this, we used an XML file as follows:\n4 ème atelier international sur l’amazighe et les TIC\n4.Test and Validation\nWe choose to assess the performance criteria that are available: the ergonomics and the response time chosen by our system.\nRegarding ergonomics, performance analyzers must have a user-friendly interface, presenting a number of functionality to help users better handle this interface to manage the features offered by the system.\nThe speed of response is another important constraint for parsers for, to be useful in the real world, they must return a response very quickly."
    }, {
      "heading" : "4.1. Experiments",
      "text" : "Our experiments on the system relate texts of Arabic literature in various fields. We introduced those relating to the field of Medicine, Marketing, Economics and Arabic grammar.\n(-): If no fault is detected.\n(+): If an error is detected.\nSentences Detection of spelling errors Detection of structural errors Detecting of conjugation errors\n45ا78 و :;<=>ا ?@7AB ل7Dأ FG HIJ@ باL5Mا\n(-) (-) (-)\n45ا78 و :<=>ا ?@7AB ل7Dأ FG FG HIJ@ و (+) (+) (+) (-)\n:N;OPQ ةSTUأ ?Q نWXYMا ZXU ن7AO@ [\\W]7>ا\n(-) (-) (-)\nتW_;<`>ا ?Q :57<=Q 7ه b@7XO>ا\n:cdYeوأ\n(+) (-) (-)\nوأ تW_;<`>ا ?Q :57=Q 7ه b@7XO>ا cdYeاءg<`>ا تWJhر ا7`JdB ،: (+) (-) (+)\n4 ème atelier international sur l’amazighe et les TIC\nن7JهkB Z> ZOYأ (-) (-) (+)\nا7JهkB Z> ZOYأ (-) (-) (-)\nصاL8أ نW<@إ kno@ (-) (-) (+)\nصاL8أ ?<@أ kno@ (-) (-) (-)\nنW<@إ ?_JهkB (-) (-) (+)\nنW<@إ pهkB (-) (-) (-)\nنWJهk@ ?> W<ه (-) (-) (+)\n:;<=>ا ا7JOA@ Z> (-) (-) (+)\n:;<=>ا ا7JOA@ Z> Zه (-) (-) (-)\npهk@ ?<@أ (-) (-) (+)\nل7Dأ FG HIJB ،Z;5 7ه FqL`>ا 7Ir>ا باL5Mا 45ا78 و :;<=>ا ?@7AB (-) (-) (-)\nنWA<>ا s>ذ uvQ FG نأ Lآk@ (-) (+) (-)\nTo evaluate the error detection, we use the rate of accuracy (standard indicator classification [4]). This indicator is between 0 and 1.One being the perfect result.\nTo calculate this index, we needed to appoint different sets.\nLet D be the total set of words, incorrect words D + and D-words correct. D + and D-form a partition of D. Let R be the set of words identified as erroneous. Some words are part of R + D D-other.\nThe precision is out as an index of the proportion of words identified as erroneous. Its formula is:\nDetection Accuracy = | D + ∩ R | / | R |"
    }, {
      "heading" : "4.2. Results and interpretations:",
      "text" : "We note that our system has a good detection for errors in spelling and structure. (Indicator precision = 1 for the detection of spelling errors and 0.75 for structures). Indeed, we get a quick response if the word entered is incorrect or the structure is wrong. We therefore have a very high proportion of errors actually detected. We can also note the good accuracy of the wrong word or structure which facilitates the coloration of errors.\nWe can also note that our system has a medium detection for errors in conjugation (Indicator accuracy = 0.56). This is for several reasons:\n4 ème atelier international sur l’amazighe et les TIC\n0\n20\n40\n60\n80\n100\nErrors detection\nDetection of spelling errors\nDetection of structural correction\nDetection of conjugation errors\nNote first the difficulty of the Arabic language in particular as regards to the conjugation.\nThen, our system took only where the verb is conjugated in the simple present and present Negation and verifies the compatibility between pre-and post-foundation bases with different personal pronouns. By cons, although the average conjugation fault detection, our system provides a new paradigm as it has treated the most difficult in the Arabic language is the conjugation.\nHistogram showing the percentages of detection system"
    }, {
      "heading" : "5. Conclusion and Perspectives",
      "text" : "The information retrieval and text mining in Arabic is a major challenge.\nWe are interested in this work to develop an application to detect errors in spelling, structure and conjugation in the Arabic text.\nThe development of this project allowed us to familiarize ourselves with the Java language, a language in the promising field of programming technologies. It allowed us to consolidate our knowledge on various techniques including manipulation of XML.\nThe work we have done is a response to the objectives set at the outset of the project. However, it can evolve by considering several extension elements.\nWe can consider adding propositions for the wrong words in order to improve the performance of our system. We can also add more functionality to our tool such as translating the input text from one language to another following the user's choice. We can also handle the case semantics and the texts vowels."
    }, {
      "heading" : "6. Bibliographie",
      "text" : "Aloulou C., Belguith H., Hadj Kacem A., and Hamami M. (2005). The Book System implementation\non a MASPAR approach MULTI-AGENT, Faculty of Economics and Management of Sfax.\nWilson W., Wei L. and Mohammed B. (2006). Scoring for Integrated Spelling Error Correction,\nAbbreviation expansion and Case Restoration in Dirty Text. School of Computer Science and\nEngineering Software University of Western Australia\nDouzidia Fuad S. (2004). Automatic summarization Arabic. University of Montreal: Department of\nComputer Science and Operations Research Faculty of Arts and Sciences\nGuillaume P. (2005) Fixed spelling in context. Compiegne University of Technology."
    } ],
    "references" : [ {
      "title" : "The Book System implementation on a MASPAR approach MULTI-AGENT, Faculty of Economics and Management of Sfax",
      "author" : [ "C. Aloulou", "H. Belguith", "A. Hadj Kacem", "M. Hamami" ],
      "venue" : null,
      "citeRegEx" : "Aloulou et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Aloulou et al\\.",
      "year" : 2005
    }, {
      "title" : "Scoring for Integrated Spelling Error Correction, Abbreviation expansion and Case Restoration in Dirty Text",
      "author" : [ "W. Wilson", "L. Wei", "B. Mohammed" ],
      "venue" : "School of Computer Science and Engineering Software University of Western Australia",
      "citeRegEx" : "Wilson et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Wilson et al\\.",
      "year" : 2006
    }, {
      "title" : "Automatic summarization Arabic",
      "author" : [ "S. Douzidia Fuad" ],
      "venue" : "University of Montreal: Department of Computer Science and Operations Research Faculty of Arts and Sciences",
      "citeRegEx" : "Fuad,? \\Q2004\\E",
      "shortCiteRegEx" : "Fuad",
      "year" : 2004
    }, {
      "title" : "Fixed spelling in context",
      "author" : [ "P. Guillaume" ],
      "venue" : "Compiegne University of Technology",
      "citeRegEx" : "Guillaume,? \\Q2005\\E",
      "shortCiteRegEx" : "Guillaume",
      "year" : 2005
    } ],
    "referenceMentions" : [ ],
    "year" : 2011,
    "abstractText" : "The study of natural language, especially Arabic, and mechanisms for the implementation of automatic processing is a fascinating field of study, with various potential applications. The importance of tools for natural language processing is materialized by the need to have applications that can effectively treat the vast mass of information available nowadays on electronic forms. Among these tools, mainly driven by the necessity of a fast writing in alignment to the actual daily life speed, our interest is on the writing auditors.",
    "creator" : "PrimoPDF http://www.primopdf.com"
  }
}