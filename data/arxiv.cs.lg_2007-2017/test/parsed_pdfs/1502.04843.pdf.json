{
  "name" : "1502.04843.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Generalized Gradient Learning on Time Series under Elastic Transformations",
    "authors" : [ "Brijnesh J. Jain" ],
    "emails" : [ "brijnesh.jain@gmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 2.\n04 84\n3v 1\n[ cs\n.L G\n] 1\n7 Fe\nb 20\n15\nGeneralized Gradient Learning on Time\nSeries under Elastic Transformations\nBrijnesh J. Jain\nTechnische Universität Berlin\nBerlin, Germany\ne-mail: brijnesh.jain@gmail.com\nThe majority of machine learning algorithms assumes that objects are represented as vectors. But often the objects we want to learn on are more naturally represented by other data structures such as sequences and time series. For these representations many standard learning algorithms are unavailable. We generalize gradient-based learning algorithms to time series under dynamic time warping. To this end, we introduce elastic functions, which extend functions on time series to matrix spaces. Necessary conditions are presented under which generalized gradient learning on time series is consistent. We indicate how results carry over to arbitrary elastic distance functions and to sequences consisting of symbolic elements. Specifically, four linear classifiers are extended to time series under dynamic time warping and applied to benchmark datasets. Results indicate that generalized gradient learning via elastic functions have the potential to complement the state-of-the-art in statistical pattern recognition on time series."
    }, {
      "heading" : "1. Introduction",
      "text" : "Statistical pattern recognition on time series finds many applications in diverse domains such as speech recognition, medical signal analysis, and recognition of gestures [4, 5]. A challenge in learning on time series consists in filtering out the effects of shifts and distortions in time. A common and widely applied approach to address invariance of shifts and distortions are elastic transformations such as dynamic time warping (DTW). Following this approach amounts in learning on time series spaces equipped with an elastic proximity measure. In comparison to Euclidean spaces, mathematical concepts such as the derivative of a function and a well-defined addition under elastic transformations are unknown in\ntime series spaces. Therefore gradient-based algorithms can not be directly applied to time series under elastic transformations. The weak mathematical structure of time series spaces bears two consequences: (a) there are only few learning algorithms that directly operate on time series under elastic transformation; and (b) simple methods like the nearest neighbor classifier together with the DTW distance belong to the state-of-the-art and are reported to be exceptionally difficult to beat [1, 10, 26]. To advance the state-of-the-art in learning on time series, first adaptive methods have been proposed. They mainly devise or apply different measures of central tendency of a set of time series under dynamic time warping [9, 17, 18, 15]. The individual approaches reported in the literature are k-means [7, 12, 13, 16, 25], self-organizing maps [23], and learning vector quantization [23]. These methods have been formulated in a problem-solving manner without a unifying theme. Consequently, there is no link to a mathematical theory that allows us to (1) place existing adaptive methods in a proper context, (2) derive adaptive methods on time series other than those based on a concept of mean, and (3) prove convergence of adaptive methods to solutions that satisfy necessary conditions of optimality. Here we propose generalized gradient methods on time series spaces that combine the advantages of gradient information and elastic transformation such that the above issues (1)–(3) are resolved. The key idea behind this approach is the concept of elastic function. Elastic functions extend non-differentiable functions on time series to piecewise smooth functions on matrices. Then learning on time series amounts in minimizing piecewise smooth risk functionals using generalized gradient methods proposed by [3, 14]. Specifically, we investigate elastic versions of logistic regression, (margin) perceptron learning, and linear support vector machine (SVM) for time series under dynamic time warping. We derive update rules and present different convergence results, in particular an elastic version of the perceptron convergence theorem. Though the main treatment focuses on univariate time series under DTW, we also show under which conditions the theory also holds for multivariate time series and sequences under arbitrary elastic transformations. We tested the four elastic linear classifiers to all two-class problems of the UCR time series benchmark dataset [8]. The results show that elastic linear classifiers on time series behave similarly as linear classifiers on vectors. Furthermore, our findings indicate that generalized gradient learning on time series spaces have the potential to complement the state-of-the-art in statistical pattern recognition on time series, because the simplest elastic methods are competitive with the best available methods."
    }, {
      "heading" : "2. Background",
      "text" : "This section compiles the necessary background material and serves to introduce the terminology and notations used throughout this paper. In Section 2.1, we define the DTW distance. Section 2.2 presents the problem of learning from examples, Section 2.3 introduces piecewise smooth functions, and Section 2.4 describes the generalized gradient method for minimizing piecewise smooth funcitons."
    }, {
      "heading" : "2.1. Dynamic Time Warping Distance",
      "text" : "By [n] we denote the set {1, . . . , n} for some n ∈ N. A time series of length n is an ordered sequence x = (x1, . . . , xn) with features xi ∈ R sampled at discrete points of time i ∈ [n]. To define the DTW distance between time series x and y of length n andm, resp., we construct a grid G = [n]× [m]. A warping path in grid G is a sequence φ = (t1, . . . , tp) consisting of points tk = (ik, jk) ∈ G such that\n1. t1 = (1, 1) and tp = (n,m) (boundary conditions)\n2. tk+1 − tk ∈ {(1, 0), (0, 1), (1, 1)} (warping conditions)\nfor all 1 ≤ k < p. A warping path φ defines an alignment between x and y by assigning elements xi of sequence x to elements yj of sequence y for all points (i, j) ∈ φ. The boundary condition enforces that the first and last element of both time series are assigned to one another accordingly. The warping condition summarizes what is known as the monotonicity and continuity condition. The monotonicity condition demands that the points of a warping path are in strict ascending lexicographic order. The continuity condition defines the maximum step size between two successive points in a path. The cost of aligning x = (x1, . . . , xn) and y = (y1, . . . , ym) along a warping path φ is defined by\ndφ(x,y) = ∑\n(i,j)∈φ\nc (xi, yj) ,\nwhere c(xi, yj) is the local transformation cost of aligning features xi and yj . Unless otherwise stated, we assume that the local transformation costs are given by c (xi, yj) = (xi − yj)2. Then the distance function\nd(x,y) = min φ dφ(x,y),\nis the dynamic time warping (DTW) distance between x and y, where the minimum is taken over all warping paths in G."
    }, {
      "heading" : "2.2. The Problem of Learning",
      "text" : "We consider learning from examples as the problem of minimizing a risk functional. To present the main ideas, it is sufficient to focus on supervised learning. Consider an input space X and output space Y. The problem of supervised learning is to estimate an unknown function f∗ : X → Y given a training set\nD = {(x1, y1), . . . , (xN , yN)} ⊆ X × Y,\nwhere the examples (xi, yi) ∈ X ×Y are drawn independent and identically distributed according to an underlying joint probability distribution P (x, y) on X × Y.\nTo measure how well a function f : X → Y predicts output values y from x, we introduce the risk\nR[f ] =\n∫\nX×Y\nℓ(y, f(x)) dP (x, y),\nwhere ℓ : Y × Y → R+ is a loss function that quantifies the cost of predicting f(x) when the true output value is y. The goal of learning is to find a function f : X → Y that minimizes the risk. The problem is that we can not directly compute the risk of f , because the probability distribution P (x, y) is unknown. But we can use the training examples to estimate the risk of f by the empirical risk\nRN [f ] = 1\nN\nN∑\ni=1\nℓ(yi, f(xi)).\nThe empirical risk minimization principle suggests to approximate the unknown function f∗ by a function\nfN = argmin f∈F RN [f ]\nthat minimizes the empirical risk over a fixed hypothesis space F ⊂ YX of functions f : X → Y. Under appropriate conditions on X , Y, and F , the empirical risk minimization principle is justified in the following sense: (1) a minimizer fN of the empirical risk exists, though it may not be unique; and (2) the risk R[fN ] converges in probability to the risk R[f∗] of the best but unknown function f∗ when the number N of training examples goes to infinity."
    }, {
      "heading" : "2.3. Piecewise Smooth Functions",
      "text" : "A function f : X → R defined on a Euclidean space X is piecewise smooth, if f is continuous and there is a finite collection of continuously differentiable functions\nR(f) = {fi : E → R : i ∈ I}\nindexed by the set I such that\nf(x) ∈ {fi(x) : i ∈ I}\nfor all x ∈ X . We call the collection R(f) a representation for f . A function fi ∈ R(f) satisfying fi(x) = f(x) is an active function of f at x. By Af (x) = {i ∈ I : fi(x) = f(x)} we denote the active index set of f at x. Piecewise smooth functions are closed under composition, scalar multiplication, finite sums, pointwise maximum and minimum operations. In particular, the maximum and minimum operations of a finite collection of differentiable functions allow us to construct piecewise smooth functions. Piecewise functions f are non-differentiable\non a set of Lebesgue measure zero, that is f is differentiable almost everywhere. In addition, they admit the notion of generalized gradient\n∂f(x) = con {∇fi(x) : i ∈ Af (x)}\nwhere conS denotes the convex hull of subset S ⊆ X and ∇fi(x) is the gradient of active function fi at x. At differentiable points x, the generalized gradient is of the form ∂f(x) = {∇f(x)}."
    }, {
      "heading" : "2.4. Generalized Gradient Methods",
      "text" : "Let Z ⊆ X some (sufficiently large) bounded convex constraint set. Consider the minimization problem\nmin x∈Z f(x), (1)\nwhere f is piecewise smooth. Let Z∗ denote the subset of solutions satisfying the necessary condition of optimality and f∗ = {f(x) : x ∈ Z∗} is the set of solution values. Consider the following iterative method, called generalized gradient method henceforth:\nx0 ∈ Z (2) xt+1 ∈ ΠZ ( xt − ηt · ∇fi ( xt )) (3)\ni ∈ Af ( xt ) , (4)\nwhere ΠZ is the multi-valued projection onto Z and ηt is the learning rate satisfying the conditions\nlim t→∞\nηt = 0 (5)\n∞∑\nt=0\nηt = ∞ (6)\nThe generalized gradient method minimizes a piecewise smooth function f by first selecting an active index i ∈ Af (x) of f at the current iterate xt and then performing a gradient-like update step. This procedure converges to a solution satisfying the necessary condition of optimality [3, 14]:\nTheorem 1 (Ermoliev-Norkin) The sequence (xt) generated by method (2)–(6) converges to the solution of problem (1) in the following sense:\n1. the limits points x̄ of (xt) with minimum value f(x̄) are contained in Z∗.\n2. the limits points f̄ of (f(xt)) are contained in f∗.\nErmoliev and Norkin also presented a consistency theorem under similar conditions when the problem is posed as that of a stochastic optimization problem [3, 14]."
    }, {
      "heading" : "3. Generalized Gradient Learning on Time Series Spaces",
      "text" : "In this section, we generalize gradient-based learning to time series spaces. Section 3.1 introduces elastic functions as a key concept. In Section 3.2, we describe a generic scheme of supervised generalized gradient learning. Section 3.3 discusses model selection. In Section 3.4, we investigate elastic linear classifiers. Then we advance to unsupervised generalized gradient learning in Section 3.5 and finally conclude with generalizations to other elastic proximity functions and arbitrary sequence data in Section 3.6."
    }, {
      "heading" : "3.1. Elastic Functions",
      "text" : "Functions f : T → R on time series under dynamic time warping are non-smooth, because the derivative of a function is undefined outside of normed vector spaces. To make derivatives available for functions on time series, we introduce the concept of elastic function, which links functions on time series to matrix spaces X = Rn×m. The matrix space X is the Euclidean space of all real (n ×m)-matrices with inner product\n〈X ,Y 〉 = ∑\ni,j\nxij · yij .\nfor all X ,Y ∈ X . The inner product induces the Euclidean norm\n‖X‖ = √ 〈X,X〉\nalso known as the Frobenius norm.1 The dimension n × m of X has the following meaning: the number n of rows refers to the maximum length of all time series from the training set D. The number m of columns is a problem dependent complexity parameter. We embed time series into a matrix from X along a warping path as illustrated in Figure 1. Suppose that x = (x1, . . . , xk) is a time series of length k ≤ n. By P(x) we denote the set of all warping paths in the grid G = [k]× [m] defined by the length k of time series x and the number m of columns of X . An elastic embedding of time series x into matrix W = (wij) along warping path φ ∈ P(x) is a matrix x ⊗φW = (xij) with elements\nxij = { xi : (i, j) ∈ φ wij : otherwise .\nIn the following, we consider examples of elastic functions based on embeddings. The first two examples are fundamental for extending a broad class of gradient-learning algorithms to time series spaces.\nExample 1 (Elastic Euclidean Distance) The elastic Euclidean distance is a distance function between a time series and a matrix defined by\nδ : T × X → R, (x,Y ) 7→ min φ∈P ‖x⊗φY − Y ‖,\n1We call ‖X‖ Euclidean norm to emphasize that we regard X as a Euclidean space.\nwhere x⊗φY is the matrix obtained by embedding x into Y along φ. See Figure 2 for an illustration.\nExample 2 (Elastic Inner Product) The elastic inner product is a similarity function between a time series and a matrix defined by\nσ : T × X → X , (x,W ) 7→ max φ∈P(x) 〈x⊗φ 0, W 〉 .\nObserve that φ embeds time series x into the zero-matrix 0.\nThe elastic Euclidean distance and elastic inner product are elastic proximities closely related to the DTW distance. The elastic Euclidean distance generalizes the DTW distance, and both elastic proximities have the same time and storage complexity as the DTW distance.\nThe next examples extend functions on vectors to elastic functions on time series by applying the elastic proximities in Example 1 and 2.\nExample 3 (Elastic Linear Function) Let Θ = X ×R be a set of parameters. An elastic linear function is a function of the form\nfθ : T → R, x 7→ b+ σ(x,W ),\nwith parameter θ = (W , b), where W is the weight matrix and b is the bias.\nExample 4 (Single-Layer Neural Network) Let Θ = X r × R2r+1 be a set of parameters. Consider the function\nfθ : T → R, x 7→ b+ r∑\ni=1\nwiσ(fi(x)),\nwhere σ is a sigmoid function, fi = fθi are elastic linear functions with parameters θi = (Wi, bi), and θ = (θ1, . . . , θr, w1, . . . , wr , b) summarizes all parameters. The function fθ implements a neural network for time series with r sigmoid units in the hidden layer and a single linear unit in the output layer.\nExample 5 Let Θ = XK be the set of parameters. Consider the function\nfθ : T → R, x 7→ min {δ(x,Y 1), . . . , δ(x,YK)}\nwith parameter θ = (Y 1 . . . ,YK).\nWith the examples in mind, we derive a definition of elastic functions. We begin with the simplest form of an elastic function as a function on time series parametrized by a single matrix. Concretely, let Θ = X be a set of parameters. Suppose that Fθ : X → R is a function defined on the Euclidean space X with parameter θ. An elastic function of Fθ based on matrix Z is a function fθ : T → R such that\nfθ(x) ∈ R(fθ,x) = {Fθ(x⊗φ Z) : φ ∈ P(x)} (7)\nfor all x ∈ T . We show that parametrized versions of Example 1 and 2 are elastic functions. To see this, we consider the Euclidean distance DY (X) = ‖X − Y ‖ as a function of X parametrized by Y . Then the function\nδY (x) = min φ∈P(x) ‖x⊗φY − Y ‖ = min φ∈P(x) DY (x⊗φY )\nsatisfies δY (x) ∈ R(δY ,x) = {DY (x⊗φY ) : φ ∈ P(x)}. This shows that the parametrized elastic Euclidean δY distance is an elastic function of the parametrized Euclidean distance DY (X) based on matrix Y . In this example, parameter matrix θ and base matrix Z coincide. Similarly, the parametrized elastic inner product σW is an elastic function of the parametrized inner product SW based on the zero-matrix 0. This example shows that parameter and base matrix may differ. Next, we extend the definition of an elastic function to the general case. For this we assume that Θ = X r × Rs is a set of parameters, where r ≥ 1 denotes the number of parameter matrices and s ≥ 0 is the number of real-valued parameters. Let Fθ : X → R be a function of the form\nFθ(X) = G ( F1(X), . . . , Fr(X) ) ,\nwhere G : Rr → R and F1, . . . , Fr : X → R are functions. An elastic function of Fθ based on matrices Z1, . . . ,Zr ∈ X is a function fθ : T → R such that fθ(x) ∈ R(fθ,x) for all x ∈ T , where\nR(fθ,x) = { G ( F1(x⊗φ1Z1), . . . , Fr(x⊗φrZr) ) : φ1, . . . , φr ∈ P(x) } .\nThe first definition of an elastic function with parameter set Θ = X is a special case of the general definition of an elastic function. This can be seen by setting G = id and F = F1. Thus, Examples 1 and 2 are elastic functions according to the general definition. By construction, Examples 3–5 are elastic functions."
    }, {
      "heading" : "3.2. Supervised Generalized Gradient Learning",
      "text" : "This section introduces a generic scheme of generalized gradient learning for time series under dynamic time warping.\nLet Θ = X r × Rs be a set of parameters. Consider a hypothesis space F of functions fθ : T → Y with parameter θ = (W1, . . . ,Wr, b) ∈ Θ. Suppose that D = {(x1, y1), . . . , (xN ), yN} ⊆ T × Y is a training set. According to the empirical risk minimization principle, the goal is to minimize\nRN [θ] = RN [fθ] =\nN∑\ni=1\nℓ(y, fθ(x))\nas a function of the parameter θ. The loss ℓ(y, fθ(x)) as a function of θ with parameter z = (x, y) can be written as\nℓz : Θ → R, θ 7→ ℓ(y, fθ(x)). (8)\nWe assume that the loss ℓz is piecewise smooth with representation\nR(ℓz) = {ℓΦ : Θ → R : Φ = (φ1, . . . , φr) ∈ Pr(x)}\nindexed by r-tuples of warping paths from P(x). The gradient ∇ℓΦ of an active function ℓΦ at θ is given by\n∇ℓΦ = (\n∂ℓΦ ∂W1 , . . . , ∂ℓΦ ∂Wr , ∂ℓΦ ∂b\n) ,\nwhere ∂ℓΦ/∂θi denotes the partial derivative of ℓΦ with respect to θi. The incremental update rule of the generalized gradient method is of the form\nW t+1i = W t i − ηt ·\n∂\n∂W ti ℓΦ\n( θt )\n(9)\nbt+1 = bt − ηt · ∂ ∂bt\nℓΦ ( θt )\n(10)\nfor all i ∈ [r]. Under the conditions of the Ermoliev-Norkin Theorem, the generalized gradient method for minimizing the empirical risk with loss function (8) using the batch version of update rule (9) and (10) converges to solutions satisfying necessary conditions of optimality."
    }, {
      "heading" : "3.3. Model Selection",
      "text" : "If the hypothesis space F is too complex for the given training set D, the learned model fN may have poor generalization performance (overfit). A common way to prevent overfitting consists in minimizing the regularized risk\nR̃N [f ] = RN [f ] + λΩ(f),\nwhere Ω(f) is the regularizer that punishes overly complex functions and λ ≥ 0 is the regularization parameter that controls the trade-off between minimizing the empirical risk RN [f ] and the complexity of f quantified by Ω(f). Piecewise smooth regularizers for primitive functions F on feature vectors directly carry over to piecewise smooth regularizers on elastic functions f of F on time series. Since piecewise smoothness is closed under addition, the regularized risk is piecewise smooth whenever the empirical risk and the regularizer are piecewise smooth. As an example consider the L2-regularizer for functions fθ ∈ F parametrized by a single matrix θ ∈ X . Then\nΩ (fθ) = ‖θ‖2,\nwhere ‖·‖ denotes the Euclidean (Frobenius) norm. Note that the squared Euclidean norm is smooth and the L1 norm is piecewise smooth. Other options for model selection are imposing global constraints such as the SakoeChiba band [21] that restricts the set of feasible warping paths to a band of certain width along the main diagonal of the grid. Such global constraints has been primarily introduced to improve computational efficiency. Recently, bandwidths have been treated as hyper-parameters and tuned for improving classification accuracy. Actually, these bandwidths can be treated as parameters that control the capacity of a classifier. For elastic function, the number of columns of the matrix space X is a similar parameter that controls the capacity as well as the computational complexity of a classifier."
    }, {
      "heading" : "3.4. Elastic Linear Classifiers",
      "text" : "Let Y = {±1} be the output space consisting of two class labels. An elastic linear classifier is a function of the form\nhθ : T → Y, x 7→ {\n+1 : fθ(x) ≥ 0 −1 : fθ(x) < 0 (11)\nwhere fθ(x) = b + σ(x,W ) is an elastic linear function and θ = (W , b) summarizes the parameters. We assign a time series x to the positive class if fθ(x) ≥ 0 and to the negative class otherwise. Depending on the choice of loss function ℓ(y, fθ(x)), we obtain different elastic linear classifiers as shown in Table 1. The loss function of elastic logistic regression is differentiable as a function of fθ and b, but piecewise smooth as a function of W . All other loss functions are piecewise smooth as a function of fθ, b and W . From the partial derivatives, we can construct the update rule of the generalized gradient method. For example, the incremental version of the generalized gradient method for the elastic perceptron loss is of the form\nW t+1 = W t + ηt yX (12)\nbt+1 = bt + ηt y, (13)\nwhere X = x⊗φ 0 and (x, y) is the training example at iteration t. From the factor I{ℓ>0} shown in Table 1 follows that update rule (12) and (13) are only applied when x is misclassified, that is when yfθ(x) < 0.\nWe present three convergence results. A proof is given in Appendix A.\nConvergence of generalized gradient method. The generalized gradient method for minimizing the empirical risk of an elastic linear classifier with convex loss converges to a local minimum under the assumptions of the Ermoliev-Norkin Theorem.\nConvergence of incremental generalized gradient method. The incremental generalized gradient method converges to a local minimum of the empirical risk of an elastic linear classifier with convex loss under the assumptions of the Ermoliev-Norkin Theorem.\nElastic margin perceptron convergence theorem. The perceptron convergence theorem states that the perceptron algorithm with constant learning rate finds a separating hyperplane, whenever the training patterns are linearly separable. A similar result holds for the elastic margin perceptron algorithm. A finite training set D ⊆ T ×Y is elastic-linearly separable, if there are parameters θ = (W , b) such that hθ(x) = y for all training examples (x, y) ∈ D. We say, D is elastic-linearly separable with margin ξ > 0 if\nmin (x,y)∈D\ny (b+ σ(x,W )) ≥ ξ.\nThen the following convergence theorem holds:\nTheorem 2 (Elastic Margin Perceptron Convergence Theorem) Suppose that D ⊆ T × Y is elastic-linearly separable with margin ξ > 0. Then the elastic margin perceptron algorithm with fixed learning rate η and margin-parameter λ ≤ ξ converges to a solution (W , b) that correctly classifies the training examples from D after a finite number of update steps, provided the learning rate is chosen sufficiently small."
    }, {
      "heading" : "3.5. Unsupervised Generalized Gradient Learning",
      "text" : "Several unsupervised learning algorithms such as, for example, k-means, self-organizing maps, principal component analysis, and mixture of Gaussians are based on the concept of (weighted) mean. Once we know how to average a set of time series, extension of mean-based learning methods to time series follows the same rules as for vectors. Therefore, it is sufficient to focus on the problem of averaging a set of time series. Suppose that D = {x1, . . . ,xN} ⊂ T is a set of unlabeled time series. Consider the sum of squared distances\nf(Y ) =\nN∑\ni=1\nδ2(xi,Y ), (14)\nwhere Y ∈ X is a matrix, and δ is the elastic Euclidean distance. A matrix Y∗ that minimizes f is an elastic mean of the set D and the minimum value f∗ = f(Y∗) is the variation of D. The update rule of the generalized gradient method is of the form\nY t+1 = Y t − ηt N∑\ni=1\n( Xi − Y t ) , (15)\nwhere X i = xi⊗φi Y t is the matrix obtained by embedding the i-th training example xi into matrix Y\nt along active warping path φi. Under the conditions of the ErmolievNorkin Theorem, the generalized gradient method for minimizing the f using update rule (15) is consistent in the mean and variation. We consider the special case, when the learning rate is constant and takes the form ηt = 1/N for all t ≥ 0. Then update rule (15) is equivalent to\nY t+1 = 1\nN\nN∑\ni=1\nXi, (16)\nwhere Xi is as in (15)."
    }, {
      "heading" : "3.6. Generalizations",
      "text" : "This section identifies some generalizations of the concept of elastic functions."
    }, {
      "heading" : "3.6.1. Generalization to other Elastic Distance Functions",
      "text" : "Elastic functions as introduced here are based on the DTW distance via embeddings along a set of feasible warping paths with squared differences as local transformation costs. The choice of distance function and local transformation cost is arbitrary. We can equally well define elastic functions based on proximities other than the DTW distance. Results on learning carry over whenever a proximity ρ on time series satisfies the following sufficient conditions: (1) ρ minimizes the costs over a set of feasible paths, (2) the cost of a feasible path is a piecewise smooth function as a function of the local transformation costs, and (3) the local transformation costs are piecewise smooth. With regard to the DTW distance, these generalizations include the Euclidean distance and DTW distances with additional constraints such as the Sakoe-Chiba band [21]. Furthermore, absolute differences as local transformation cost are feasible, because the absolute value function is piecewise smooth."
    }, {
      "heading" : "3.6.2. Generalization to Multivariate Time Series",
      "text" : "A multivariate time series is an ordered sequence x = (x1, . . . ,xn) consisting of feature vectors xi ∈ Rd. We can define the DTW distance between multivariate time series x and y as in the univariate case but replace the local transformation cost c(xi, yj) = (xi − yj)2 by c(xi,yj) = ‖xi − yj‖2. To define elastic functions, we embed multivariate time series into the set X = (Rd)n×m of vector-valued matrices X = (xij) with elements xij ∈ Rd. These adjustment preserve piecewise smoothness, because the Euclidean space X is a direct product of lower-dimensional Euclidean spaces."
    }, {
      "heading" : "3.6.3. Generalization to Sequences with Symbolic Attributes",
      "text" : "We consider sequences x = (x1, . . . , xn) with attributes xi from some finite set A of d attributes (symbols). Since A is finite, we can represent its attributes a ∈ A by d-dimensional binary vectors a ∈ {0, 1}d, where all but one element is zero. The unique non-zero element has value one and is related to attribute a. In doing so, we can reduce the case of attributed sequences to the case of multivariate time series. We can introduce the following local transformation costs\nc(xi, yj) = { 0 : xi = yj 1 : xi 6= yj .\nMore generally, we can define local transformation costs of the form\nc(xi, yj) = k(xi, xi)− 2k(xi, yj) + k(yj , yj),\nwhere k : A×A → R is a positive-definite kernel. Provided that the kernel is an inner product in some finite-dimensional feature space, we can reduce this generalization also to the case of multivariate time series.\nAlgorithm 1 (Mean Computation)\nInput:\n– sample D = {x1, . . . ,xN} ⊆ T\nProcedure:\n1. initialize Y ∈ Z\n2. repeat\n2.1. determine active warping paths φi that embed xi into Y 2.2. update Y ← υ(Y ,x1, . . . ,xN , φ1, . . . , φN ) 2.3. project Y ← π(Y ) to Z\nuntil convergence\nReturn:\n– approximation y of mean"
    }, {
      "heading" : "4. Relationship to Previous Approaches",
      "text" : "Previous work on adaptive methods either focus on computing or are based on a concept of (weighted) mean of a set of time series. Most of the literature is summarized in [9, 15, 16, 23]. To place those approaches into the framework of elastic functions, it is sufficient to consider the problem of computing a mean of a set of time series. Suppose that D = {x1, . . . ,xN} is a set of time series. Consider the sum of squared distances\ng(y) =\nN∑\ni=1\nd2(xi,y),\nwhere d is the DTW distance. Algorithm 1 outlines a unifying minimization procedure of g. The set Z in line 1 of the procedure consists of all matrices with n identical rows, where n is the maximum length of all time series from D. Thus, there is a one-to-one correspondence between time series from T and matrices from Z. By construction, we have g(y) = f(Y ), where Y ∈ Z is the matrix with all rows equal to y and f(Y ) is the elastic version of g defined in eq. (14). In line 2.1, we determine active warping paths of the elastic function f(Y ) that embed xi into matrix Y . By construction this step is equivalent to computing optimal warping paths for determining the DTW distance between xi and y. Line 2.2 updates matrix Y and line 2.3 projects the updated matrix Y to the feasible set Z. The last step is equivalent to constructing a time series from a matrix. Previous approaches differ in the form of update rule υ in line 2.2 and the projection π in line 2.3. Algorithmically, steps 2.2 and 2.3 usually form a single step in the sense that the composition ψ = π ◦ υ can not as clearly decomposed in two separate precessing steps as described in Algorithm 1. The choice of υ and π is critical for convergence analysis. Problems arise when the map υ does not select a generalized\ngradient and the projection π does not map a matrix from X to a closest matrix from Y. In these cases, it may be unclear how to define necessary conditions of optimality for the function g. As a consequence, even if steps 2.2 and 2.3 minimize g, we do not know whether Algorithm 1 converges to a local minimum of g. The same problems arise when studying the asymptotic properties of the mean as a minimizer of g. The situation is different for the elastic function f . When minimizing f , the set Z coincides with X . Since the function f is piecewise smooth, the map υ in line 2.2 corresponds to an update step of the generalized gradient method. The projection π in line 2.3 is the identity. The Ermoliev-Norkin Theorem provides sufficient conditions under which Algorithm 1 is consistent."
    }, {
      "heading" : "5. Experiments",
      "text" : "The goal of this section is to assess the performance of all four elastic linear classifiers presented in Section 3.4."
    }, {
      "heading" : "5.1. Experimental Setup.",
      "text" : "We considered all two-class problems of the UCR time series datasets [8]. Table 2 summarizes characteristic features of the datasets. We compared the four elastic linear classifiers of Section 3.4 against different variants of the nearest neighbor (NN) classifier with DTW distance. The variants of the NN classifiers differ in the choice of prototypes. The first variant uses all training examples as prototypes. The second and third variant learned one prototype per class from the training set using k-means as second variant and agglomerative hierarchical clustering as third variant [16]. The settings of the elastic linear classifiers were as follows: The dimension of the matrix space X was set to n×0.1n, where n is the length of the shortest (= longest) time series in the training set. Bias and weight matrix were initialized by drawing random numbers from the uniform distribution on the interval [−0.01,+0.01]. Parameters\nwere selected by k-fold cross validation on the training set of size N . We set k = 10 if N > 30 and k = N otherwise. The following parameters were selected: learning rate η for all elastic linear classifiers, margin ξ for elastic margin perceptron, and regularization parameter λ for elastic linear SVM. The parameters were selected from the following values\nη ∈ { 2−10, 2−9, . . . , 20 } , ξ ∈ { 10−7, 10−6, . . . , 101 } , λ ∈ { 2−10, 2−9, . . . , 2−1 } .\nThe final model was obtained by training the elastic linear classifiers on the whole training set using the optimal parameter(s). We assessed the generalization performance by applying the learned model to the test data. Since the performance of elastic linear classifiers depends on the random initialization of the bias and weight matrix, we repeated the last two steps 100 times, using the same selected parameters in each trial."
    }, {
      "heading" : "5.2. Results and Discussion.",
      "text" : "Table 3 summarizes the error rates of all elastic linear classifiers and nearest neighbor classifiers. Comparison of elastic linear classifiers and nearest neighbor methods is motivated by the following reasons: First, nearest neighbor classifiers belong to the state-of-the-art and are considered to be exceptionally difficult to beat [1, 10, 26]. Second, in Euclidean spaces linear classifiers and nearest neighbors are two simple but complementary approaches. Linear classifiers are computationally efficient, make strong assumptions about the data and therefore may yield stable but possibly inaccurate predictions. In contrast, nearest neighbor methods make very mild assumption about the data and therefore often yield accurate but possibly unstable predictions [6]. The first key observation suggests that overall generalization performance of elastic linear (EL) classifiers is comparable to the state-of-the-art NN classifier. This observation is supported by the same same number of green shaded rows (EL is better) and red shaded rows (NN is better) in Table 3. As reported by [10], ensemble classifiers of different elastic distance measures are assumed to be first approach that significantly outperformed the NN+ALL classifier on the UCR time series dataset. This result is not surprising, because in machine learning it is well known for a long time hat ensemble classifiers often perform better than their base classifiers for reasons explained in [2]. Since any base classifier can contribute to an ensemble classifier, it is feasible to restrict comparison to base classifiers such as the state-of-the-art NN+ALL classifier. The second key observation indicates that EL classifiers are clearly superior to NN classifiers with one prototype per class, denoted by NN1 henceforth. Evidence for this finding is provided by two results: first, AHC and KME performed best among several prototype selection methods for NN classification [16]; and second, error rates of EL classifiers are significantly better than those of NN+AHC and NN+KME for eight, comparable for two, and significantly worse for two datasets. The third key observation is that EL classifiers clearly better compromise between solution quality and computation time than NN classifiers. Findings reported by [24]\nindicate that more prototypes may improve generalization performance of NN classifiers. At the same time, more prototypes increase computation time, though the differences will decrease for larger number of prototypes by applying certain acceleration techniques. At the extreme ends of the scale, we have NN+ALL and NN1 classifiers. With respect to solution quality, the first key observation states that EL classifiers are comparable to the slowest NN classifiers using the whole training set as prototypes and clearly superior to the fastest NN classifiers using one prototype per class. To compare computational efficiency, we first consider the case without applying any acceleration techniques. We measure computational efficiency by the number of proximity calculations required to classify a single time series. This comparison is justified, because the complexity of computing a DTW distance and an elastic inner product are identical. Then EL classifiers are p-times faster than NN classifiers, where p is the number of prototypes. Thus the fastest NN classifiers effectively have the same computational effort as EL classifiers for arbitrary multi-class problems, but they are not competitive to EL classifiers according to the second key observation. Next, we discuss computational efficiency of both types of classifiers, when one applies acceleration techniques. For NN classifiers, two common techniques to decrease computation time are global constraints such as the Sakoe-Chiba band [21] and diminishing the number of DTW distance calculations by applying lower bounding technique [19, 20]. Both techniques can equally well be applied to EL classifiers, where lower-bounding techniques need to be converted to upper-bounding techniques. Furthermore, EL classifiers can additionally control the computational effort by the number m of columns of the matrix space. Here m was set to 10% of the length n of the shortest time series of the training set. The better performance of EL classifiers in comparison to NN1 classifiers is notable, because the decision boundaries that can be implemented by their counterparts in the Euclidean space are both the set of all hyperplanes. We assume that EL classifiers outperform NN1 classifiers for the following reason: First, learning prototypes by clustering minimizes a cluster criterion unrelated to the risk functional of a classification problem. Therefore the resulting prototypes may fail to discriminate the data for some problems. Second, in view of Algorithm 1, the prototypes learned by AHC or KME correspond to matrices of an n-dimensional subspace of X = Rn×n. The weight matrix learned by an elastic linear classifier is from a (n×m)-dimensional subspace of X , where m = 0.1 · n > 1 for all datasets. This shows that EL classifiers have higher capacity than NN1. The fourth key observation is that the strong assumption of elastic-linearly separable problems is appropriate for some problems in the time series classification. Error rates of elastic linear classifiers for Coffee, ItalyPowerDemand, and Wafer are below 5%. For these problems, the strong assumption made by EL classifiers is appropriate. For all other datasets, the high error rates of EL classifiers could be caused by two factors: first, the assumption that the data is elastic-linearly separable is inappropriate; and second, the number of training examples given the length of the time series is too low for learning (see ratio ρ in Table 2). Here further experiments are required. Finally, we observed that the different EL classifiers perform comparable with advantages for eLOGR and eLSVM. These findings correspond to similar findings for logistic regression and linear SVM in vector spaces.\nTo summarize, the results show that elastic linear classifiers are simple and efficient methods. They rely on the strong assumption that an elastic-linear decision boundary is appropriate. Therefore, elastic linear classifiers may yield inaccurate predictions when the assumptions are biased towards oversimplification and/or when the number of training examples is too low compared to the length of the time series. These findings are in line with those of linear classifiers in Euclidean space."
    }, {
      "heading" : "6. Conclusion",
      "text" : "This paper introduces generalized gradient methods for learning on time series under elastic transformations. This approach combines (a) the novel concept of elastic functions that links elastic proximities on time series to piecewise smooth functions with (b) generalized gradient methods for non-smooth optimization. Using the proposed scheme, we (1) showed how a broad class of gradient-based learning can be applied to time series under elastic transformations, (2) derived general convergence statements that justify the generalizations, and (3) placed existing adaptive methods into proper context. Exemplarily, elastic logistic regression, elastic (margin) perceptron learning, and elastic linear SVM have been tested on two-class problems and compared to nearest neighbor classifiers using the DTW distance. Despite the simplicity in terms of the decision boundary and the computational efficiency, elastic linear classifiers perform convincing. There is still room for improvement by controlling the capacity via the number of columns of the weight matrix and by applying different forms of regularization. The results indicate that adaptive methods based on elastic functions may complement the state-of-the-art in statistical pattern recognition on time series, in particular when powerful non-linear gradient-based methods such as deep learning are extended to time series under elastic transformations."
    }, {
      "heading" : "A. Proof of Convergence Results for Elastic Linear",
      "text" : "Classifiers\nSince affine functions are convex and the maximum of convex functions is also convex, the elastic inner product is convex. In addition, the composition of convex functions is convex. Therefore the loss functions of elastic linear classifiers are convex. Then the first convergence results is shown in [22].\nTo show the two other convergence statements, we assume that |D| = N . For each training example (xi, yi) ∈ D the loss\nℓi(θ) = ℓi (yi, b+ σ(xi,W ))\nis real-valued and convex, where θ = (W , b). Then there is a positive scalar Ci that bounds the subdifferential of ℓi at θ for all i ∈ [N ]. Suppose that\nC = max i=1,...,N Ci.\nThen from [11], Prop. 2.2. follows that the incremental generalized gradient method converges to a local minimum.\nTo show the Elastic Margin Perceptron Convergence Theorem, we assume that\nEN [θ] = N∑\ni=1\nℓi(θ)\nis the error without averaging operation, that is EN = N · RN . By assumption, the training set D is elastic-linearly separable. Then the minimum value E∗ of EN is zero. From [11], Prop. 2.1. follows\nlim t→∞\nEN (θ t) ≤ E∗ +\nη · C2\n2 =\nη · C2\n2 ,\nwhere η is the learning rate. Choosing η ≤ ξ/C2 gives\nlim t→∞\nEN(θ t) ≤\nξ 2 .\nSince ξ > 0, this implies that there is a t0 such that ℓt(θ t) < ξ for all t ≥ t0. Here, ℓt refers to example (xt, yt) ∈ D presented at iteration t. From this follows that all training examples are classified correctly after a finite number of update steps, provided that λ ≤ ξ."
    } ],
    "references" : [ {
      "title" : "A Complexity-Invariant Distance Measure for Time Series",
      "author" : [ "G.E. Batista", "X. Wang", "E.J. Keogh" ],
      "venue" : "SIAM International Conference on Data Mining, SDM,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2011
    }, {
      "title" : "Ensemble methods in machine learning",
      "author" : [ "T.G. Dietterich" ],
      "venue" : "Proceedings of the First International Workshop on Multiple Classifier Systems,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2000
    }, {
      "title" : "Stochastic generalized gradient method for nonconvex nonsmooth stochastic optimization",
      "author" : [ "Y. Ermoliev", "V. Norkin" ],
      "venue" : "Cybernetics and Systems Analysis,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1998
    }, {
      "title" : "A review on time series data mining",
      "author" : [ "T. Fu" ],
      "venue" : "Engineering Applications of Artificial Intelligence,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2011
    }, {
      "title" : "Pattern extraction for time series classification",
      "author" : [ "P. Geurts" ],
      "venue" : "Principles of Data Mining and Knowledge Discovery, pp",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2001
    }, {
      "title" : "The elements of statistical learning",
      "author" : [ "T. Hastie", "R. Tibshirani", "J. Friedman" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2001
    }, {
      "title" : "Time-series clustering by approximate prototypes",
      "author" : [ "V. Hautamaki", "P. Nykanen", "P. Franti" ],
      "venue" : "International Conference on Pattern Recognition,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2008
    }, {
      "title" : "The UCR Time Series Classification/Clustering Homepage: www.cs.ucr.edu/~eamonn/time_series_data",
      "author" : [ "E. Keogh", "Q. Zhu", "B. Hu", "Y. Hao", "X. Xi", "L. Wei", "C.A. Ratanamahatana" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2011
    }, {
      "title" : "The symmetric time-warping problem: From continuous to discrete Time Warps, String Edits and Macromolecules: The Theory and Practice of Sequence Comparison",
      "author" : [ "J.B. Kruskal", "M. Liberman" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1983
    }, {
      "title" : "Time series classification with ensembles of elastic distance measures",
      "author" : [ "J. Lines", "A. Bagnall" ],
      "venue" : "Data Mining and Knowledge Discovery,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2014
    }, {
      "title" : "Incremental subgradient methods for nondifferentiable optimization",
      "author" : [ "A. Nedic", "D.P. Bertsekas" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2001
    }, {
      "title" : "Inaccuracies of shape averaging method using dynamic time warping for time series data",
      "author" : [ "V. Niennattrakul", "C.A. Ratanamahatana" ],
      "venue" : "Computational Science — ICCS,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2007
    }, {
      "title" : "On Clustering Multimedia Time Series Data Using K-Means and Dynamic Time Warping",
      "author" : [ "V. Niennattrakul", "C.A. Ratanamahatana" ],
      "venue" : "International Conference on Multimedia and Ubiquitous Engineering,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2007
    }, {
      "title" : "Stochastic generalized-differentiable functions in the problem of nonconvex nonsmooth stochastic optimization",
      "author" : [ "V. Norkin" ],
      "venue" : "Cybernetics and Systems Analysis,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1986
    }, {
      "title" : "A global averaging method for dynamic time warping, with applications to clustering",
      "author" : [ "F. Petitjean", "A. Ketterlin", "P. Gancarski" ],
      "venue" : "Pattern Recognition,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2011
    }, {
      "title" : "Dynamic Time Warping Averaging of Time Series allows Faster and more Accurate Classification",
      "author" : [ "F. Petitjean", "G. Forestier", "G.I. Webb", "A.E. Nicholson", "Y. Chen", "E. Keogh" ],
      "venue" : "International Conference on Data Mining, ICDM,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2014
    }, {
      "title" : "Considerations in applying clustering techniques to speaker?independent word recognition",
      "author" : [ "L.R. Rabiner", "J.G. Wilpon" ],
      "venue" : "The Journal of the Acoustical Society of America,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1979
    }, {
      "title" : "Making time- series classification more accurate using learned constraints",
      "author" : [ "C.A. Ratanamahatana", "E.J. Keogh" ],
      "venue" : "SIAM International Conference on Data Mining,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2004
    }, {
      "title" : "Three myths about dynamic time warping data mining",
      "author" : [ "C.A. Ratanamahatana", "E.J. Keogh" ],
      "venue" : "SIAM International Conference on Data Mining,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2005
    }, {
      "title" : "Dynamic programming algorithm optimization for spoken word recognition",
      "author" : [ "H. Sakoe", "S. Chiba" ],
      "venue" : "IEEE Transactions on Acoustics, Speech, and Signal Processing,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1978
    }, {
      "title" : "Minimization Methods for Nondifferentiable Functions",
      "author" : [ "N.Z. Shor" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1985
    }, {
      "title" : "Self-organizing maps and learning vector quantization for feature sequences",
      "author" : [ "P. Somervuo", "T. Kohonen" ],
      "venue" : "Neural Processing Letters,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1999
    }, {
      "title" : "Experimental comparison of representation methods and distance measures for time series data",
      "author" : [ "X. Wang", "A. Mueen", "H. Ding", "G. Trajcevski", "P. Scheuermann", "E. Keogh" ],
      "venue" : "Data Mining and Knowledge Discovery,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2013
    }, {
      "title" : "A modified K-means clustering algorithm for use in isolated work recognition",
      "author" : [ "J.P. Wilpon", "L.R. Rabiner" ],
      "venue" : "IEEE Transactions on Acoustics, Speech and Signal Processing,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1985
    }, {
      "title" : "Fast time series classification using numerosity reduction",
      "author" : [ "X. Xi", "E. Keogh", "C. Shelton", "L. Wei", "C.A. Ratanamahatana" ],
      "venue" : "Proceedings of the 23rd International Conference on Machine Learning,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "Statistical pattern recognition on time series finds many applications in diverse domains such as speech recognition, medical signal analysis, and recognition of gestures [4, 5].",
      "startOffset" : 171,
      "endOffset" : 177
    }, {
      "referenceID" : 4,
      "context" : "Statistical pattern recognition on time series finds many applications in diverse domains such as speech recognition, medical signal analysis, and recognition of gestures [4, 5].",
      "startOffset" : 171,
      "endOffset" : 177
    }, {
      "referenceID" : 0,
      "context" : "The weak mathematical structure of time series spaces bears two consequences: (a) there are only few learning algorithms that directly operate on time series under elastic transformation; and (b) simple methods like the nearest neighbor classifier together with the DTW distance belong to the state-of-the-art and are reported to be exceptionally difficult to beat [1, 10, 26].",
      "startOffset" : 365,
      "endOffset" : 376
    }, {
      "referenceID" : 9,
      "context" : "The weak mathematical structure of time series spaces bears two consequences: (a) there are only few learning algorithms that directly operate on time series under elastic transformation; and (b) simple methods like the nearest neighbor classifier together with the DTW distance belong to the state-of-the-art and are reported to be exceptionally difficult to beat [1, 10, 26].",
      "startOffset" : 365,
      "endOffset" : 376
    }, {
      "referenceID" : 24,
      "context" : "The weak mathematical structure of time series spaces bears two consequences: (a) there are only few learning algorithms that directly operate on time series under elastic transformation; and (b) simple methods like the nearest neighbor classifier together with the DTW distance belong to the state-of-the-art and are reported to be exceptionally difficult to beat [1, 10, 26].",
      "startOffset" : 365,
      "endOffset" : 376
    }, {
      "referenceID" : 8,
      "context" : "They mainly devise or apply different measures of central tendency of a set of time series under dynamic time warping [9, 17, 18, 15].",
      "startOffset" : 118,
      "endOffset" : 133
    }, {
      "referenceID" : 16,
      "context" : "They mainly devise or apply different measures of central tendency of a set of time series under dynamic time warping [9, 17, 18, 15].",
      "startOffset" : 118,
      "endOffset" : 133
    }, {
      "referenceID" : 14,
      "context" : "They mainly devise or apply different measures of central tendency of a set of time series under dynamic time warping [9, 17, 18, 15].",
      "startOffset" : 118,
      "endOffset" : 133
    }, {
      "referenceID" : 6,
      "context" : "The individual approaches reported in the literature are k-means [7, 12, 13, 16, 25], self-organizing maps [23], and learning vector quantization [23].",
      "startOffset" : 65,
      "endOffset" : 84
    }, {
      "referenceID" : 11,
      "context" : "The individual approaches reported in the literature are k-means [7, 12, 13, 16, 25], self-organizing maps [23], and learning vector quantization [23].",
      "startOffset" : 65,
      "endOffset" : 84
    }, {
      "referenceID" : 12,
      "context" : "The individual approaches reported in the literature are k-means [7, 12, 13, 16, 25], self-organizing maps [23], and learning vector quantization [23].",
      "startOffset" : 65,
      "endOffset" : 84
    }, {
      "referenceID" : 15,
      "context" : "The individual approaches reported in the literature are k-means [7, 12, 13, 16, 25], self-organizing maps [23], and learning vector quantization [23].",
      "startOffset" : 65,
      "endOffset" : 84
    }, {
      "referenceID" : 23,
      "context" : "The individual approaches reported in the literature are k-means [7, 12, 13, 16, 25], self-organizing maps [23], and learning vector quantization [23].",
      "startOffset" : 65,
      "endOffset" : 84
    }, {
      "referenceID" : 21,
      "context" : "The individual approaches reported in the literature are k-means [7, 12, 13, 16, 25], self-organizing maps [23], and learning vector quantization [23].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 21,
      "context" : "The individual approaches reported in the literature are k-means [7, 12, 13, 16, 25], self-organizing maps [23], and learning vector quantization [23].",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 2,
      "context" : "Then learning on time series amounts in minimizing piecewise smooth risk functionals using generalized gradient methods proposed by [3, 14].",
      "startOffset" : 132,
      "endOffset" : 139
    }, {
      "referenceID" : 13,
      "context" : "Then learning on time series amounts in minimizing piecewise smooth risk functionals using generalized gradient methods proposed by [3, 14].",
      "startOffset" : 132,
      "endOffset" : 139
    }, {
      "referenceID" : 7,
      "context" : "We tested the four elastic linear classifiers to all two-class problems of the UCR time series benchmark dataset [8].",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 2,
      "context" : "This procedure converges to a solution satisfying the necessary condition of optimality [3, 14]:",
      "startOffset" : 88,
      "endOffset" : 95
    }, {
      "referenceID" : 13,
      "context" : "This procedure converges to a solution satisfying the necessary condition of optimality [3, 14]:",
      "startOffset" : 88,
      "endOffset" : 95
    }, {
      "referenceID" : 2,
      "context" : "Ermoliev and Norkin also presented a consistency theorem under similar conditions when the problem is posed as that of a stochastic optimization problem [3, 14].",
      "startOffset" : 153,
      "endOffset" : 160
    }, {
      "referenceID" : 13,
      "context" : "Ermoliev and Norkin also presented a consistency theorem under similar conditions when the problem is posed as that of a stochastic optimization problem [3, 14].",
      "startOffset" : 153,
      "endOffset" : 160
    }, {
      "referenceID" : 19,
      "context" : "Other options for model selection are imposing global constraints such as the SakoeChiba band [21] that restricts the set of feasible warping paths to a band of certain width along the main diagonal of the grid.",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 19,
      "context" : "With regard to the DTW distance, these generalizations include the Euclidean distance and DTW distances with additional constraints such as the Sakoe-Chiba band [21].",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 8,
      "context" : "Most of the literature is summarized in [9, 15, 16, 23].",
      "startOffset" : 40,
      "endOffset" : 55
    }, {
      "referenceID" : 14,
      "context" : "Most of the literature is summarized in [9, 15, 16, 23].",
      "startOffset" : 40,
      "endOffset" : 55
    }, {
      "referenceID" : 15,
      "context" : "Most of the literature is summarized in [9, 15, 16, 23].",
      "startOffset" : 40,
      "endOffset" : 55
    }, {
      "referenceID" : 21,
      "context" : "Most of the literature is summarized in [9, 15, 16, 23].",
      "startOffset" : 40,
      "endOffset" : 55
    }, {
      "referenceID" : 7,
      "context" : "We considered all two-class problems of the UCR time series datasets [8].",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 15,
      "context" : "The second and third variant learned one prototype per class from the training set using k-means as second variant and agglomerative hierarchical clustering as third variant [16].",
      "startOffset" : 174,
      "endOffset" : 178
    }, {
      "referenceID" : 0,
      "context" : "Comparison of elastic linear classifiers and nearest neighbor methods is motivated by the following reasons: First, nearest neighbor classifiers belong to the state-of-the-art and are considered to be exceptionally difficult to beat [1, 10, 26].",
      "startOffset" : 233,
      "endOffset" : 244
    }, {
      "referenceID" : 9,
      "context" : "Comparison of elastic linear classifiers and nearest neighbor methods is motivated by the following reasons: First, nearest neighbor classifiers belong to the state-of-the-art and are considered to be exceptionally difficult to beat [1, 10, 26].",
      "startOffset" : 233,
      "endOffset" : 244
    }, {
      "referenceID" : 24,
      "context" : "Comparison of elastic linear classifiers and nearest neighbor methods is motivated by the following reasons: First, nearest neighbor classifiers belong to the state-of-the-art and are considered to be exceptionally difficult to beat [1, 10, 26].",
      "startOffset" : 233,
      "endOffset" : 244
    }, {
      "referenceID" : 5,
      "context" : "In contrast, nearest neighbor methods make very mild assumption about the data and therefore often yield accurate but possibly unstable predictions [6].",
      "startOffset" : 148,
      "endOffset" : 151
    }, {
      "referenceID" : 9,
      "context" : "As reported by [10], ensemble classifiers of different elastic distance measures are assumed to be first approach that significantly outperformed the NN+ALL classifier on the UCR time series dataset.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 1,
      "context" : "This result is not surprising, because in machine learning it is well known for a long time hat ensemble classifiers often perform better than their base classifiers for reasons explained in [2].",
      "startOffset" : 191,
      "endOffset" : 194
    }, {
      "referenceID" : 15,
      "context" : "Evidence for this finding is provided by two results: first, AHC and KME performed best among several prototype selection methods for NN classification [16]; and second, error rates of EL classifiers are significantly better than those of NN+AHC and NN+KME for eight, comparable for two, and significantly worse for two datasets.",
      "startOffset" : 152,
      "endOffset" : 156
    }, {
      "referenceID" : 22,
      "context" : "Findings reported by [24]",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 19,
      "context" : "For NN classifiers, two common techniques to decrease computation time are global constraints such as the Sakoe-Chiba band [21] and diminishing the number of DTW distance calculations by applying lower bounding technique [19, 20].",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 17,
      "context" : "For NN classifiers, two common techniques to decrease computation time are global constraints such as the Sakoe-Chiba band [21] and diminishing the number of DTW distance calculations by applying lower bounding technique [19, 20].",
      "startOffset" : 221,
      "endOffset" : 229
    }, {
      "referenceID" : 18,
      "context" : "For NN classifiers, two common techniques to decrease computation time are global constraints such as the Sakoe-Chiba band [21] and diminishing the number of DTW distance calculations by applying lower bounding technique [19, 20].",
      "startOffset" : 221,
      "endOffset" : 229
    } ],
    "year" : 2017,
    "abstractText" : "The majority of machine learning algorithms assumes that objects are represented as vectors. But often the objects we want to learn on are more naturally represented by other data structures such as sequences and time series. For these representations many standard learning algorithms are unavailable. We generalize gradient-based learning algorithms to time series under dynamic time warping. To this end, we introduce elastic functions, which extend functions on time series to matrix spaces. Necessary conditions are presented under which generalized gradient learning on time series is consistent. We indicate how results carry over to arbitrary elastic distance functions and to sequences consisting of symbolic elements. Specifically, four linear classifiers are extended to time series under dynamic time warping and applied to benchmark datasets. Results indicate that generalized gradient learning via elastic functions have the potential to complement the state-of-the-art in statistical pattern recognition on time series.",
    "creator" : "LaTeX with hyperref package"
  }
}