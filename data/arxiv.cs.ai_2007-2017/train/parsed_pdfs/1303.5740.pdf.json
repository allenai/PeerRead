{
  "name" : "1303.5740.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "High Level Path Planning with Uncertainty",
    "authors" : [ "Runping Qi", "David Poole" ],
    "emails" : [ "qi@cs.", "poole@cs.ubc.ca" ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 INTRODUCTION\nFor high level path planning, digraphs (distance graphs) are usually used as a tool for environment modeling. In a digraph, vertices denote places (or landmarks), edges- vertex pairs- denote the routes between the place pairs, and the weight of an edge de notes the cost (or distance) between the two vertices of the edge. The path planning problem is formulated as a shortest path problem in digraphs.\nHowever, a major drawback of digraphs is the inabil ity to model uncertainties. If there is an edge between two vertices in a digraph, it is assumed that there is a direct route between the places represented by these vertices. But, in reality, we often encounter some sit uations where we are not sure about something. For example, we may know that there is a door between two rooms, but that door may be locked; we are not sure whether the door is open now, though we know that, according to past experience, the probability of\nthe door being open is about 0.8. Clearly, digraphs are not sufficient to model such situations.\nAs the first effort to extending the expressive power of digraphs, we propose in this paper a new kind of graphs, called U-graphs (uncertain graphs), and inves tigate path planning problems based on the U -graph model. A U-graph is an ordinary digraph augmented with a new kind of edges: switches. Like an edge, each switch connects a vertex pair and has a weight. In ad dition, each switch has a probability associated with it. The probability associated with a switch repre sents the probability that the connection between the two vertices of the switch is traversable.\nWith uncertainty being taken into consideration, the path planning problem is significantly different from the shortest path problem. Instead, a path planner needs to compute a \"navigation plan\" which can result in an optimal travel with respect to some predefined measures. The main difficulty in computing such an optimal travel strategy largely attributes to the on line nature of the problem, that is, an optimal strategy should be able to tell an agent what is the optimal next step, based on the incomplete knowledge known so far, in any possibly encountered situation.\nTraditionally, the quality of an on-line algorithm is measured based on two criteria [Bar-Noy and Schieber, 1991]: competitive ratio of the algorithm and worst case performance. In this paper, we adopt a new op timality criterion in terms of the expected cost for a given task, which we think is very suitable for naviga tion. We formulate a navigation problem as a finite state Markovian decision process. Markovian deci sion process was studied as a mathematical abstraction of certain types of dynamic systems [Derman, 1970] and as a branch of dynamic programming [Howard, 60] [Denardo, 1982]. With this formulation, the path planning problem amounts to the optimal first-passage problem for a Markovian decision process [Derman, 1970]. From this formulation, we derive an algorithm for path planning.\nThe rest of this paper is organized as follows. In the\n288 Qi and Poole\nnext section, U-graphs are formally introduced and world modeling based on U-graphs is briefly discussed. In Section 3, path planning in uncertain environments is addressed and an optimality criterion for navigation plans is informally presented. In Section 4, the path planning problem is formalized and a general path planning algorithm is derived. Section 5 discusses re lated work, and Section 6 concludes the paper with a brief discussion of our future work.\n2 U-GRAPH\nDefinition 1 A U-graph is (V, E, Su, pr, weight), where V is a finite set of vertices, E � V x V is a set of edges, S._. � V x V is a set of switches, pr a probability function from Su to [0, 1], and weight is a function from E U Su to R+.\nFor the purpose of clarity and simplicity, we assume that E and Su are mutually disjoint. For a U-graph (V, E, S._., pr, weight), its pessimistic induced graph is graph (V, E); its optimistic induced graph is graph (V, E US ... ). A U-graph is said to be disconnected wrt two vertices if there is no path be tween the two vertices in the optimistic induced graph.\nFor high level path planning, the essential knowledge a path planner needs to know about the environment is the topology and connectivity of the environment. The topological structure of an environment can be represented by a set of \"interesting places\" and the connectivity relationships among these places. These places can be abstracted as vertices and the connec tivity relationships abstracted as arcs in a U -graph. If it is uncertain whether the route between the two places is definitely traversable, this uncertainty can be abstracted by a switch. We say a switch is on if it is traversable, and a switch is off if it is not traversable. The probability that the route being traversable is as signed to the switch. The weight of the switch denotes the cost for an agent to go through the switch provided that it is on.\nAs an illustration of how to model a practical situation by a U-graph, let us consider a situation as shown in Figure 1-(a) , where two places A and B are on the two sides of a river, and usually connected by a bridge. However, it is not sure whether the bridge is broken or not, though it is known that the probability for the bridge being broken is 0.2. If the bridge is not broken, it will take about five minutes to cross the river. The connection between A and B can be represented as a switch, as shown in Figure 1-(b) . In the following discussion we make three assump tions about a U-graph. First, the probabilities of the switches in Su are mutually independent. Second, the status of the switches in Su is uncertain to the agent unless the agent is at either end vertex of the switch.\nWhen an agent is at one end of a switch s , the agent can reach the other end through the switch with the cost given by weight(s) if the switch is actually on, and cannot otherwise traverse the switch. Third, the status of any switch will not change after the agent discovers it. The first two assumptions are justifiable in most situations. The third assumption is also justi fiable because a U-graph is mainly used to represent the overall structure of an environment, and it is rea sonable to believe that changes in the overall structure of an environment are comparatively slow.\nThe third assumption above implies that, when the agent reaches one ending vertex of a switch in Su , the switch can be replaced by an edge with the same weight if the status of the switch turns out to be on, and can be deleted from the graph otherwise.\n3 PATH PLANNING WITH UNCERTAINTY\nAs a motivating example, let us consider the case shown in Figure 2. Suppose that an agent is at vertex A and is asked to go to vertex B. In order to accom plish this task, the first question to be answered is: \"which route should be taken?\" . Here are some possi ble answers.\nFirst, if the agent wants to minimize the cost in the worst case, it should take the upper route (edge AB) in the graph.\nSecond, if the agent would like to minimize the ex pected cost for accomplishing this task, there are two choices. The first one is to go to B through edge AB. Another one is as follows: go to C first; if CD is actu ally traversable, go to D then to B; otherwise go back to A, then go to B through edge AB. The expected cost for the first choice is d1 . The expected cost for the second choice is:\nThird, if the agent has a resource limit, it may want to choose a navigation plan which can maximize the\nAs we see from the above example, an agent may be subject to various constraints and want to achieve var ious objectives for a given navigation task. These con straints and objectives determine the optimality crite ria of plans. In this paper, we consider path planning problem wrt the criterion of minimization of the ex pected cost for achieving a given task.\nMore precisely, we state the navigation problem and the optimality criterion as follows. When given a task of going to vertex q from vertex p in a U-graph rep resentation of an environment, an agent is supposed to systematically explore the environment until either arriving at the goal position or finding out that there is actually no path to the goal position. The path plan ning problem is to determine a navigation plan which minimizes the expected cost required for exploring the environment.\n4 A FORMAL DEFINITION OF PATH PLANNING\nIn the present section, we model a navigation prob lem as a Markovian decision process [Derman, 1970], a navigation plan as a policy for the Markovian decision process, and give a precise definition of the expected cost for a navigation plan.\n4.1 Markovian Decision Model\nInformally, a Markovian decision process is an alter nating sequence of states of, and actions on, an evo lution system. At each point of time, the state of the system can be observed and classified, and an action, based on the observed state, can be taken. A policy is a prescription for taking action at each point in time.\nFormally, a Markovian decision process is a quadruple (I, K, w, q), where I denotes the space of the states that can be observed of a system, K = { I<;ji E I} , K; denotes the set of actions which may be taken in state i , w is a cost function and q is a transition function.\nThe laws of motion of the system are characterized by\nHigh Level Path Planning with Uncertainty 289\nthe transition function q . Whenever the system is in state i and action a is taken, then, regardless of its history, q(i, j, a) denotes the probability of the system being in state j at the next instant the system is ob served. It is assumed that Lj q(i, j, a) = 1 for any i E I and a E K; . A cost structure is superimposed on a Markovian decision process. Whenever the sys tem is in state i and action a is taken, a known cost w(i, a) is incurred. A deterministic policy for a Markovian decision pro cess can be thought as a function mapping from states to actions. For the purpose of this paper, we will only consider deterministic policies. For a Markovian deci sion process and a fixed policy R, let PR{Yi = i} be the probability of M being in state i at time t under the control of policy R. We define a set of random variables {W,, t = 0, 1, . . }:\nW1= w(i,R(i)) ifY,=i.\nThe expected cost at time t wrt policy R 1s:\nER{Wt} = _E PR{Yi = i}w(i, R(i)). i\nLet Yo = i be the initial state and let T T SR,T(i) = ER _E Wt = _E L PR{Yi = j}w(j, R(j)). t=O t=O j\nSR,T(i) is the expected total cost of operating the sys tem up to and including the time \"horizon\" t = T, given the initial state i and policy R . The opti mal first-passage problem is to find R that minimizes .\\R(i) = SR,r(i) , where r denotes the smallest pos itive value of t such that Y, = j , and j is one of the target states at which the process is stopped. This problem is was first formulated by Eaton and Zadeh [Eaton and Zadeh, 1962].\nLet Cv denote a class of all (deterministic) policies. Derman [Derman, 1970) proved that: if { w( i, a)} are non-negative, then there exists an R* E Cv such that\n.\\R.(i) = inf .\\R(i), i E I. RECv\nFor a given policy R, let X( R, i) denote the expected value of the total cost of reaching the target state from state i and R* denote the optimal policy. Thus, we have:\nand\nor\nX(R*, i) :S: X(R, i) (1)\nX(R, i)=E{w(i,a)+X(R, j)} (2)\nX(R, i) = w(i, a)+ L q(i , j, a) * X(R, j) (3) iEI\nfor all i E I , where a = R( i). Furthermore, if there exists another policy R' such that for some state i ,\n290 Qi and Poole\nX(R', i) < X(R, i) , then R must not be an optimal policy.\nThe behaviors of a Markovian decision process can be represented as a directed graph. Formally, the repre senting graph of the Markovian decision process M = (I, I<, w, q) is a directed graph RG(M) = (V, A1 UA2} defined as:\nand"
    }, {
      "heading" : "V = IU{s;ali E I; a E !<;};",
      "text" : ""
    }, {
      "heading" : "A1 = {(i, s;a)li E I; a E K;}",
      "text" : ""
    }, {
      "heading" : "A2 = {(s;.,j)li,j E I; a E I<;;q(i,j,a) > 0}",
      "text" : "In such a representing graph, a node i E I , called a state node, represents an observable state while node s;a , called a non-state node, represents a tempo rary state resulting from taking action a in state i . The next observable state after the temporary state is determined by a probability distribution q(i,j, a). Therefore we can attach action a as the label for arc (i, s;a) and probability q(i,j, a) as the label for arc (s;., j) .\nThe representing graph for a Markovian decision pro cess M starting with state i0, denoted by RG;0(M), is the largest subgraph of RG(M) such that any node in the subgraph is reachable from io.\nIn particular, the behaviors of a Markovian decision process controlled by a particular policy R can be represented by a directed graph RG( M, R) defined as: V =I U {s;ali E I;a E K;} and"
    }, {
      "heading" : "A1 = {(i,s;a)li E I; a E I<;;R(i) =a}",
      "text" : "and A2 is the same as the above. The represent ing graph for a Markovian decision process M con trolled by policy R starting with state i0 , denoted by RG;0(M, R), is the largest subgraph of RG(M, R) such that any node in the subgraph is reachable from io in the original graph.\nSuch a graph representation is quite useful. With this representation, we can study the properties of a Markovian decision process by studying its repre senting graph. More importantly, it can facilitate the derivation of the algorithm for computing the optimal plan for a given navigation task (see section 4.4).\n4.2 Some Related Concepts\nA configuration is a triple (G, nc, n9), where G is a U-graph, n0 and n9 are two vertices of the graph, representing the current position and the goal position respectively. An edge is said to be a current edge of a configuration if the current vertex of the configuration is one of the vertices of the edge. Similarly, a switch\nis said to be a current switch of a configuration if the current vertex of the configuration is one of the vertices of the switch. Let CE(C) and CS(C) denote the set of current edges and the set of current switches of configuration C respectively.\nA terminal configuration (or a terminal for short) is a configuration which satisfies either of the following two conditions:\n1. the shortest distance between nc and n9 in the optimistic induced graph (V, E U Su) is equal to the shortest distance between nc and n9 in the pessimistic induced graph (V, E);\n2. G is disconnected wrt to nc and n9•\nIn other words, a terminal is a configuration which is certain enough such that the agent can determine whether there is a path to the goal position, and be able to compute the optimal path if there is any. A terminal satisfying the first condition will be called a \"good\" terminal. A terminal satisfying the second condition will be called a \"bad\" terminal. A configu ration C is said to be an uncontrolled configuration if C S( C) is not empty. A configuration is controlled if it is not uncontrolled. Two kinds of transitions, namely uncontrolled and controlled transitions, can be defined respectively on uncontrolled and controlled configurations. For a controlled configuration C = (G, n0, n9} , suppose n1, ... , nk are the k (k > 0) neighbours of nc; we de fine k controlled transitions, t1, .. . , tk , corresponding to the k current edges. We denote by trans(C, t;) the configuration to which the i-th transition t; can lead from configuration C. We have:\ntrans(C,t;) = (G, n;,n9).\nFor an uncontrolled configuration C = (G, n0, n9), suppose G = (V,E,S,.,pr,weight) and CS(C) = {s1, ... , sk } is the set of k (k > 0) current switches of C ; we define 2k uncontrolled transitions corre sponding to all the possible combinations of the k switches' states. We denote by ONS,, the set of switches in CS(C) which are on, and by OF FS,, the set of switches in CS(C) which are off. We denote by p1, the probability that the transition t; can happen. Thus,\nand\nPt, = II pr(s) * II (1- pr(s))\ntrans(C, t;) = (G', 110, n9) where G' = (V, E', S�, pr', weight) , where E' = E U ONS,, and S� = S,.- CS(C).\nAs an example, Figure 3-( a) shows a controlled con figuration where the goal position is vertex q and the current position is indicated by a double-circle. Three\ncontrolled transitions are associated with this config uration, corresponding to going to vertices 2, 3, and 4 respectively. Suppose the transition of going to vertex 4 is chosen, then the next configuration, as shown in Figure 3-(b), is an uncontrolled one. With this un controlled configuration, four uncontrolled transitions are associated, corresponding to the possible combina tions of the states of switches s1 and s2 . The possible configurations to which these transitions can lead are shown in Figures 3-(c ), 3-(d), 3-(e) and 3-(f) respec tively.\nA controlled transition sequence T;j = tL, ... , tfi, k 2: 1 is said to be a generic transition from a controlled configuration i to a configuration j , if\nj = trans( ... trans(i, t}j), ... , t�j)· We use gtrans( i, T) to denote the configuration re sulting from taking generic transition T in i . For the above case, we have gtrans( i, T;j) = j. For a con trolled transition t, let c(t) denote the cost associated with t. The cost for a generic transition T;j , denoted by c(T;j) , is the sum of the costs of the constituent transitions of T;j . Note that, for a given controlled configuration i and a configuration j , there may exist zero, one or many generic transitions from i to j. The optimal generic transition from i to j is the one with the least cost. A configuration j is said to be a generic successor\nHigh Level Path Planning with Uncertainty 291\nof a controlled configuration i if there is a generic transition from i to j , and configuration j is either a terminal or is an uncontrolled configuration.\nIntuitively, a configuration captures the characteris tics of a situation, i.e. where the agent is now, where it wants to go and how much it knows about the en vironment. When an agent is in a controlled configu ration, it can decide which edge to traverse next, and therefore, has control over the selection of the next (controlled) transition. Furthermore, if an agent takes a longer perspective on its navigation in a controlled configuration it can find that it will either enter an un controlled configuration first or enter a terminal first. Thus, we can consider the set of the generic transitions from i to the generic successors of i as the set of the possible actions the agent can take in configuration i. Obviously, if an agent wants to reach configuration j, it should take the optimal generic transition from i to j . We use GT( i) to denote the set of the optimal transitions from i to the generic configurations of i . When an agent is in an uncontrolled configuration, it faces one or more uncertain switches, and it can ex amine the states of the uncertain switches. When the new information is available to the agent, a new con figuration is reached. Thus the agent has no control over which new configuration will be reached.\n4.3 Navigation Procedure as a Markovian Decision Process\nIf we regard all the controlled configurations which may be encountered during a navigation collectively as a state space, all the generic transitions associated with each state as the possible actions which may be taken in that state, and the uncontrolled transitions as the state transitions, then, we can consider a naviga tion procedure as a Markovian decision process, and a navigation plan as a policy for such a decision process. We now give a formal account of this idea.\nFor a given U-graph G = (V,E,S,.,pr, weight), let VSG(G) denote the following set: {(V,EUS�n,S�,pr, weight)IS�nus� <::; S,.;S�nnS� = ¢}. In words, V SG( G) denotes the collection of the vari ations of U-graph Gwhich are themselves U-graphs obtained by deleting some switches from S,. and mov ing some of the remaining switches from S,. to E .\nFor a given task of going from vertex p to vertex q in a U-graph G , let IC be (G, p, q), called the initial configuration, and I' be the set of all possible con trolled configurations defined as: I' {(G',p',q)IG' E VSG(G),p' E V, (G',p', q) is a controlled configuration}. Let f de note a special state called target state. Let I= I'U{f} be the state space.\nIn our current formulation, we consider GT( i) as the set of the possible actions that can be taken in state i ,\n292 Qi and Poole\ni.e. I<; = GT( i). We assume further that there exists a special action ao which is the only action that could be taken in a l l the terminals. That is, for any state i corresponding to a terminal configuration, I< i is { ao} and taking action a0 in state i will result in the target state f .\nFor any state i E I and an action a E K; , the proba bility q(i,j, a) is defined as:\nq(i,j,a) =\n1 if i is a terminal, j = f and a= ao; 1 if j = gtrans(i,a) and j is a terminal; Pt if gtrans(i, a) is an uncontrolled configuration and trans(gtrans(i, a), t) = j for some transition t in gtrans(i, a) 0 otherwise.\nwhere p1 is the probability of transition t .\nFor any state i E I , and an action a E K; , let w(i, a) denote the cost for taking action a in state i , which is defined as: { c(a) (. ) _ SD(G',n;,q) w z,a - 0 if i is not a terminal; if a = ao and i is a good terminal; otherwise.\nwhere n; is the current position of configuration i; c(a) is the cost of generic transition a; G' is the pes simistic induced graph of the U -graph of configuration i and SD(G',n;,q) is the shortest distance from ver tex n; to vertex q in graph G' .\nProposition 2 For a given navigation task of going from vertex p to vertex q in a U-graph G, let I, w, q , and K; for each i E I be constructed as above, and let I<= {K;fi E I } and M =(I, I<, w, q), then M 1s a Markovian decision process.\nDefinition 3 A navigation plan for a given naviga tion task is defined as a policy R for the Markovian decision process corresponding to the task.\nDefinition 4 The expected cost for a plan R lS given by >.R(IC) , as defined in Section 4.1, where IC is the initial configuration.\nDefinition 5 For a given task, the path planning problem is to find a policy which minimizes >.R(IC).\nFor a Markovian decision process M derived from a navigation problem, we make the following impor tant observation. That is: \"nature transitions\" always lead to new states. This means that, no matter what history the current state has, if an action (a generic transition) taken in this state will lead to an uncon trolled configuration which in turn will be led to a new controlled configuration (a new state), then this\nnew state is different than any of the states in the his tory. The intuitive meaning is that whenever an agent reaches an uncontrolled configuration, it will find new information about the states of the uncertain switches, therefore, the resultant configuration must be different than any one encountered before. This implies that RG;0(M), the representing graph of M , must be a directed acyclic graph (DAG).\n4.4 Computing the Optimal Policy for a Navigation Problem\nIn the literature, the optimal first-passage problem was solved through successive approximations [Der man, 1970] or through computing the fixed point of a set of recursive equations [Denardo, 1982] [Eaton and Zadeh, 1962]. Both approaches involve iterations. The computational complexity of each iteration in these methods is O(N * K), where N = [If is the size of state space and [{ is the average number of possible actions that may be taken in a state. There is not a good upper bound for iteration times.\nHowever, we can do much better for our case. As we mentioned earlier, the Markovian decision process M derived from a navigation task with initial state i0 can be represented by RG;0(M) which is a DAG. A node in such a DAG represents a configuration which is reachable from the start state (configuration) i0. The number of nodes in RG;0(M) is no greater than [I[ + 2:;;El[K;f even in the worst case. In the average case, the number of nodes is much smaller than the above bound, since, intuitively, many configurations may not be reachable from the initial configuration.\nNow, let us consider the structure of an optimal policy R*. Obviously, we can assume X( R*, f ) == 0. Since each state i corresponding to a terminal configura tion has only one action ao , then R*( i) :::: a0 , thus, X(R*,i) = w(i,a0), for every state i corresponding to a terminal.\nFor a state i with possible action set I<; , let J;. de note the set of the possible next states after action a is taken in state i , and J; = UaEK.Jia be the possible next states of state i. We have already known that: X(R*,i) :S X(R,i) and\nX(R, i) = w(i, a)+ \"L, q(i,j, a)* X(R, j) jei\nfor any policy R and all i E I , where a = R(i). Therefore, for a state i , suppose we already know X(R*,j) for all j E J;, and suppose a* = R*(i), then, w(i,a*) + 2:;j q(i,j,a*) * X(R*,j) must equal minaEK,{w(i,a) + 2:;j q(i,j,a) * X(R*,j)}. Conse quently, we have:\nX(R*,i) = min{w(i,a) + \"L,q(i,j,a) * X(R*,j)}. aEK, . J\n(4)\nThis means that the value of X ( R*, i) can be com puted easily if the values of X(R*, j) are known for those j E J;. Based on the above discussion, we obtain the following algorithm for computing R* and X(R*, i) for every i which is reachable from io in RG;,(M).\nAlgorithm Al\nInput: RG;,(M);\nOutput: RG;,(M, R*) and X(R*,-) defined on the state nodes in RG;,(M).\n1. ( Initialization) For each state i corresponding to a terminal configuration, set R * ( i) == ao and X(R*, i) == w(i, ao ) .\n2. If X(R*, i0) has been computed, stop, otherwise, go to the next step.\n3. For each state-node i , if X( R*, i) has not been computed and for all j E J;, X(R*, j) has been computed, compute R*(i) and X(R*, i) accord ing to equation ( 4); cut off all the \"non-optimal arcs\" incident from i .\n4. Go to step 2.\nRG;,(M, R*) can be obtained from the resultant graph by deleting all the nodes which are not reach able from i0. Obviously, the complexity of the above algorithm is linear in the size of RG;,(M). However, it should be noted that the size of RG;, ( M) can be exponential in the number of uncertain switches in a given U-graph.\n5 RELATED WORK\nAt the application aspect, our work is related to the large body of research on spatial knowledge repre sentation, path planning and navigation in AI and Robotics community. At the algorithmic aspect, our work is most closely related to some theoretical studies [Papadimitriou and Yannakakis, 1989] [Bar-Noy and Schieber, 1991].\nRelated work in AI: A number of approaches to path planning and navigation in uncertain environ ments have been proposed and many navigation sys tems for mobile robots have been built (e.g. [Arkin, 1989]; [Crowley, 1985]). However, in most of these systems, attention is primarily focused on the prob lem of how to make a robot capable of moving around in relatively small environments. Some notable ex ceptions are Kuipers' TOUR model [Kuipers, 1978], Kuipers and Levitt's COGNITIVE MAP [Kuipers and Levitt, 1988] for the representation of spatial knowl edge of large scale environments, and Levitt and Law ton's qualitative approach [Levitt and Lawton, 1990] to navigation in large scale environments.\nHigh Level Path Planning with Uncertainty 293\nWith respect to the express power, our U-graph model can express only the topological aspect of TOUR model in addition to a kind of uncertainty. While TOUR model supports both \"highway oriented\" nav igation and \"cross country\" navigation, the U-graph supports only the former.\nDean et a/ [Dean et a/., 1990] described a navigation system that also makes use of utility theory in navi gation planning. However, their stress was on how to coordinate task achieving activities and map building activities so that a group of navigation tasks in an un certain environment can be efficiently accomplished. In contrast, our planner is primarily concerned with the problem of finding the best way to accomplish a given navigation task.\nA major difference between our work and the other related work (e.g. [Levitt and Lawton, 1990]; [Dean et a/. , 1990]) lies in the fact that the outcome of our path planning algorithm is not just a simple path, but is a comprehensive navigation plan which is highly con ditional to the future states of the environment. In fact, the navigation plan generated by our path plan ner is somewhat similar to Schoppers' Universal Plan [Schoppers , 1989].\nSome related theoretical studies: In [Papadim itriou and Yannakakis, 1989] Papadimitriou and Yan nakakis first named the problem of travel under un certainty as the Canadian Traveller Problem (CTP). In their formulation, a traveller is given an unreliable graph (map) whose edges may disappear. They also assume that the traveller cannot know whether an edge is actually there unless he/she reaches an adjacent ver tex of the edge, and the status of an edge will not change after being revealed. The problem is to devise a travel strategy that results in an optimal travel ( ac cording to some predefined measure) from one vertex to another.\nThere is an obvious difference between our U -graphs and the uncertain graphs of the CTP with respect to environment modeling. In CTP, it is assumed that all the edges in a graph may disappear, and no informa tion is known about the likelihood of the presence of any edge. However, in our U-graphs, we can make an explicit distinction between the \"certain edges\" and the \"uncertain switches\". Furthermore, by restricting the uncertain switches to a comparatively small num ber, we can reasonably assume that the prior proba bilities of those uncertain switches can be obtained.\nBesides the difference with respect to environment modeling, Papadimitriou and Yannakakis defined their optimality criteria in terms of competitive ratio. The competitive ratio is used in the literature to measure the quality of on-line algorithms [Mannasse et a/., 1988]. Papadimitriou and Yannakakis showed that de vising an on-line travel strategy with a bounded com petitive ratio is PSPACE-complete. They also showed\n294 Qi and Poole\nthat the problem of devising a strategy that minimizes the expected ratio, provided that each edge in a graph has a presence probability, remains hard ( #P-hard and solvable in polynomial space) .\nBar-N oy and Schieber studied several interesting vari ations of the CTP [Bar-Noy and Schieber, 1991]. One variation is the k-Canadian Traveller Problem, which is a CTP with k as the upper bound on the number of the blocked roads (disappeared edges) . They gave a recursive algorithm to compute a travel strategy that guarantees the shortest worst-case travel time. The complexity of the algorithm is polynomial for any given constant k. They also proved that the problem is PSP ACE-complete when k is non-constant. Another variation Bar-Noy and Schieber studied is the Stochas tic Recoverable Canadian Traveller Problem. In this problem, it is assumed that blocked roads can be re opened in certain time. They presented a polynomial algorithm for devising a travel strategy that minimizes the expected travel time, under the assumption that for any edge e in a given graph, the recover time of e is less than the weight of any edge adjacent to it in the graph. Unfortunately, it is yet unclear how to relax this unrealistic assumption.\n6 CONCLUSION AND FUTURE WORK\nIn this paper, we present U -graphs as a tool for model ing uncertain environments and formulate a U-graph based navigation problem as a Markovian decision pro cess. This formulation contributes to a better under standing on the problem we try to solve. In addition, we present an optimality criterion for navigation plans and develop an algorithm for computing the optimal navigation plan wrt the criterion.\nFuture work can be carried out in several possible di rections. First, we will study some other reasonable optimality criteria for path planning with uncertainty. For example, the optimality criteria could be quite dif ferent from the one discussed in this paper if we assume that an agent is subject to a cost limit. Second, we hope that we can make use of the hierarchical prop erty of a given U-graph to cope with the complexity of the path planning with uncertainty. Third, we plan to derive some approximation algorithms having lower complexity, yet being able to compute reasonably good sub-optimal navigation plans for a given problem. An other kind of interesting future work is to incorporate our U-graph model into more general frameworks such as Kuipers' TOUR model [Kuipers, 1978] [Kuipers and Levitt, 1988].\nAcknowledgements\nWe would like to thank Ying Zhang and Andrew Csinger for their valuable comments on this paper.\nThe work presented in this paper was supported in part by NSERC grant under operation number OG P0044121.\nReferences\n[Arkin, 1989] R. C. Arkin. Navigational path planning for a vision based mobile robot. Robotica, 7, 1989.\n[Bar-Noy and Schieber, 1991] Amotz Bar-Noy and Baruch Schieber. The canadian traveller problem. In Proc. 2nd Annul ACM-SIAM Symposium on De screte Algorithms, 1991.\n[Crowley, 1985] J. L. Crowley. Navigation for an in telligent mobile robot. IEEE Robotics and A utoma tion, RA-1(1) , 1985.\n[Dean et a/., 1990] T. Dean, K. Basye, R. Chekaluk, S. Hyun, M. Lejter, and M. Randazza. Coping with uncertainty in control system for navigation and ex ploration. In Proc. of AAAI-90, 1990.\n[Denardo, 1982] Eric V. Denardo. Dynamic Program ming: models and applications. Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1982.\n[Derman, 1970] Cyrus Derman. Finite State Marko vian Decision Process. Academic Press New York and London, 1970.\n[Eaton and Zadeh, 1962] J. H. Eaton and L. A. Zadeh. Optimal pursuit strategies in discrete state probabilistic system. Trans. ASME Ser. D., Journal of Basic Engineering, 84, 1962.\n[Howard, 60] R. A. Howard. Dynamic Programming and Markov Processes. Technology Press, Cam bridge, Massachusetts, and Wiley New York, 60.\n[Kuipers and Levitt, 1988] Benjiarnin J. Kuipers and Tod S. Levitt. Navigation and mapping in large scale space. AI Magzine, 9(2), 1988.\n[Kuipers, 1978] B. J. Kuipers. Modeling spatial knowledge. Cognitive Science, 2, 1978.\n[Levitt and Lawton, 1990] T. S. Levitt and D. T. Law ton. Qualitative navigation for mobile robots. Arti ficial Intelligence, 44(3) , 1990.\n[Mannasse et a/., 1988] M. S. Mannasse, L. A. Mc Geoch, and D. D. Sleator. Competitive algorithms for on-line problems. In the 20th ACM Symp. on Theory of Computing, 1988.\n[Papadimitriou and Yannakakis, 1989] Christos H. Papadimitriou and Mihalis Yannakakis. Shortest paths without a map. In Proc. the 15th ICALP, Lecture Note in Camp. Sci. No. 372. Spring-Verlag, July 1989.\n[Schoppers, 1989] Marcel J. Schoppers. Represen tation and automatic synthesis of reaction plans. Technical Report UIUCDCS-R-89-1546, Depart ment of Computer Science, University of Illinois at Urbana-Champaign, 1989."
    } ],
    "references" : [ {
      "title" : "The canadian traveller problem",
      "author" : [ "Bar-Noy", "Schieber", "1991] Amotz Bar-Noy", "Baruch Schieber" ],
      "venue" : "In Proc. 2nd Annul ACM-SIAM Symposium on De­ screte Algorithms,",
      "citeRegEx" : "Bar.Noy et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Bar.Noy et al\\.",
      "year" : 1991
    }, {
      "title" : "Coping with uncertainty in control system for navigation and ex­ ploration",
      "author" : [ "T. Dean", "K. Basye", "R. Chekaluk", "S. Hyun", "M. Lejter", "M. Randazza" ],
      "venue" : "In Proc. of AAAI-90,",
      "citeRegEx" : "Dean et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Dean et al\\.",
      "year" : 1990
    }, {
      "title" : "Optimal pursuit strategies in discrete state probabilistic system",
      "author" : [ "Eaton", "Zadeh", "1962] J.H. Eaton", "L.A. Zadeh" ],
      "venue" : "Trans. ASME Ser. D., Journal of Basic Engineering,",
      "citeRegEx" : "Eaton et al\\.,? \\Q1962\\E",
      "shortCiteRegEx" : "Eaton et al\\.",
      "year" : 1962
    }, {
      "title" : "Navigation and mapping in large­ scale space",
      "author" : [ "Kuipers", "Levitt", "1988] Benjiarnin J. Kuipers", "Tod S. Levitt" ],
      "venue" : "AI Magzine,",
      "citeRegEx" : "Kuipers et al\\.,? \\Q1988\\E",
      "shortCiteRegEx" : "Kuipers et al\\.",
      "year" : 1988
    }, {
      "title" : "Qualitative navigation for mobile robots. Arti­",
      "author" : [ "Levitt", "Lawton", "1990] T.S. Levitt", "D.T. Law­ ton" ],
      "venue" : null,
      "citeRegEx" : "Levitt et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Levitt et al\\.",
      "year" : 1990
    }, {
      "title" : "Competitive algorithms for on-line problems",
      "author" : [ "M.S. Mannasse", "L.A. Mc­ Geoch", "D.D. Sleator" ],
      "venue" : "In the 20th ACM Symp. on Theory of Computing,",
      "citeRegEx" : "Mannasse et al\\.,? \\Q1988\\E",
      "shortCiteRegEx" : "Mannasse et al\\.",
      "year" : 1988
    }, {
      "title" : "Shortest paths without a map",
      "author" : [ "Papadimitriou", "Yannakakis", "1989] Christos H. Papadimitriou", "Mihalis Yannakakis" ],
      "venue" : "In Proc. the 15th ICALP, Lecture Note in Camp. Sci",
      "citeRegEx" : "Papadimitriou et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Papadimitriou et al\\.",
      "year" : 1989
    }, {
      "title" : "Represen­ tation and automatic synthesis of reaction plans",
      "author" : [ "Marcel J. Schoppers" ],
      "venue" : "Technical Report UIUCDCS-R-89-1546, Depart­ ment of Computer Science, University of Illinois at Urbana-Champaign,",
      "citeRegEx" : "Schoppers. 1989",
      "shortCiteRegEx" : null,
      "year" : 1989
    } ],
    "referenceMentions" : [ ],
    "year" : 2011,
    "abstractText" : "For high level path planning, environments are usually modeled as distance graphs, and path planning problems are reduced to com­ puting the shortest path in distance graphs. One major drawback of this modeling is the inability to model uncertainties, which are of­ ten encountered in practice. In this paper, a new tool, called U-graph, is proposed for environment modeling. A U-graph is an ex­ tension of distance graphs with the ability to handle a kind of uncertainty. By model­ ing an uncertain environment as a U-graph, and a navigation problem as a Markovian decision process, we can precisely define a new optimality criterion for navigation plans, and more importantly, we can come up with a general algorithm for computing optimal plans for navigation tasks.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}