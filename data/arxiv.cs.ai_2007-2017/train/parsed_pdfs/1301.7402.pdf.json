{
  "name" : "1301.7402.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "From Likelihood to Plausibility",
    "authors" : [ "Paul-Andre Monney", "Richard Royall" ],
    "emails" : [ "paul-andre.monney@unifr.ch" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Several authors have explained that the like lihood ratio measures the strength of the evi dence represented by observations in statisti cal problems. This idea works fine when the goal is to evaluate the strength of the avail able evidence for a simple hypothesis versus another simple hypothesis. However, the ap plicability of this idea is limited to simple hypotheses because the likelihood function is primarily defined on points - simple hy potheses - of the parameter space. In this paper we define a general weight of evidence that is applicable to both simple and compos ite hypotheses. It is based on the Dempster Shafer concept of plausibility and is shown to be a generalization of the likelihood ratio. Functional models are of a fundamental im portance for the general weight of evidence proposed in this paper. The relevant con cepts and ideas are explained by means of a familiar urn problem and the general analysis of a real-world medical problem is presented.\n1 The Problem\nIn a recent book, Richard Royall (11] explains that the likelihood ratio is the appropriate concept for measur ing the strength of the evidence represented by obser vations in statistical problems. He gives several very convincing arguments in favor of this idea and shows its relevance in the field of testing statistical hypothe ses. This interpretation of likelihood is based on Ian Hacking's law of likelihood (7] :\nIf hypothesis A implies that the probability that a ran dom variable X takes the value x is P A ( x), while hy pothesis B implies that the probability is PB(x), then the observation X = x is evidence supporting A over B if and only if PA(x) > PB(x), and the likelihood ratio,\nP A ( x) / PB ( x), measures the strength of that evidence (I. Hacking, 1965).\nTo elaborate on this idea we consider two spaces : the parameter space e and the observation space X. The set e is the set of possible values of the parameter variable t, whereas X is the set of possible values of the observable variable�· There is exactly one correct but unknown value of the parameter variable t. Fol lowing Dawid & Stone (1], a distributional model is the specification of conditional distributions Pe of the variable� given t = 0, i.e.\nP(� = xl t = 0) = Pe(x). (1)\nFor each value X in X, the function lx : e -+ (0, 1] given by lx(O) = Pe(x) is the likelihood function of the observation x. According to the law of likelihood, the observation X = x is evidence supporting the hypoth esis t = 0 over the hypothesis t = 0' if\n(2)\nand the weight of that evidence is precisely\nWx(O, O') := lx(O)/lx(O') . (3)\nThis defines a function\nWx : 0 X 0-+ (0, ooj (4)\nwhich is called the weight of evidence function. Given a distributional model and an observation x, we can compute the weight of evidence of a simple hypothesis H = {0} over a simple hypothesis H' = {0'}. But the weight of evidence is not defined for composite hypotheses (a hypothesis is composite if it contains more than one element). As Royall [11] says, in general the law of likelihood is silent for composite hypotheses. In the next section we are going to define a general notion of weight of evidence that is applicable to any kind of hypotheses. Of course, this general weight of evidence will be compatible with the likelihood ratio, i.e. when the general weight of evidence is applied to simple hypotheses the result is the likelihood ratio.\n2 Likelihood and Plausibility\nIn Monney [9] the classical notion of a functional model introduced by Bunke [4] and studied by Dawid & Stone [1] has been generalized to the so-called generalized functional models (abbreviated by G FM in this paper). It turns out that these models can be used to give a sound and reasonable definition of a general weight of evidence. Distributional models don't contain enough information to be able to compute weights of evidence for composite hypotheses. We need to leave the realm of distributional models and enter the more informa tive class of generalized functional models to reach that goal.\nA generalized functional model is a pair (!, P) where f is a function and p is a probability distribution. If n denotes the set of possible values of a random variable E, then the function f is a mapping f : e X n -+ X with f ( e, w) representing the value of the variable � that must necessarily be observed if e is the correct value of the parameter variable t and the realization of the random variable E is w. The distribution of E is the known probability measure p on n and in a GFM the function j is assumed to be known. By the way, note that a GFM can be seen as a parameterized particular causal theory in the sense of Pearl [10].\nThe observation of a value x for the variable � in a GFM generates some information about the unknown correct value of the parameter variable t. It turns out that this is a Dempster-Shafer belief function which will be denoted by 1-lx (Shafer [12], Kohlas & Monney [8]). More precisely, if\nvx(D) = {wED: :3 e E 0 such that j(e,w) = x}, (5) then for every w E Vx (D) there is a corresponding focal set of 1-lx given by\nfx(w) = {e E 0: j(e,w) = x}. (6)\nThe basic probability assignment (or m-function) mx of the belief function 1-lx is\nmx(F) = L {P(w)/P(vx(D)): rx(w) = F} (7) for all subsets F � e. The logic behind the derivation of these equations is given in Monney [9].\nFrom a GFM we can logically derive a unique distri butional model as follows. For every e E 0, let Pe be the probability distribution on X given by\nPe ( x) = P ( { w E n : J ( e, w) = x}) . ( s)\nThe plausibility function Plx associated with the belief function 1-lx has a very interesting property. Indeed, if lx denotes the likelihood function of the distributional\nFrom Likelihood to Plausibility 397\nmodel associated with the GFM when x is observed, then it can easily be verified that\nPlx(e) = c ·lx(e) (9)\nfor all e E 0, where c is a positive constant that does not depend on e. This means that the plausi bility function restricted to simple hypotheses is pro portional to the likelihood function of the associated distributional model. From this result, given an ob servation x, it is quite natural to define the weight of evidence of a general hypothesis H � e over a general hypothesis H' � e by\nWx(H,H') := Plx(H)/Plx(H') . (10)\nThen the weight of evidence of the simple hypothesis H = {e} over the simple hypothesis H' = {e'} is\nPlx(e)jPlx(e') c c · lx c e) ) 1 c c · lx c e')) lx(e)/lx(e'),\nwhich shows that the definition (10) extends to com posite hypotheses the weight of evidence for simple hypotheses given in (3).\nOf course, the concepts defined above for a single ob servation can easily be extended to the situation of several independent observations. First consider the case of distributional models. For all e E 8, let Pe be a distribution on X. In a total of r independent obser vations of the variable �, suppose that the value x is observed m times and the value x' is observed n times (m + n = r) . These observations are considered as in dependent realisations of the variable �- Given these observations, the likelihood of the parameter value e is\nm n lm,n(e) := II lx(e) ·II lx'(e). (11)\ni=l i=l\nThen the law of likelihood implies that the weight of evidence of e over e' is\nwm,n(e,e') lm,n (e) /lm,n( e') m n II wx(e,e') ·II wx'(e,e'). (12) i=l i=l\nHowever, within the given distributional model, the weight of evidence for composite hypotheses is not de fined.\nNow consider the same observations from the point of view of a GFM having the given distributions Pe as its associated distributional model. Since the observa tions are independent, it is reasonable to use Demp ster's rule of combination to combine the belief func tions coming from all the observations taken individ ually. The resulting belief function on e, which is de noted by 1-lm,n, represents the information generated\n398 Monney\non e based on all the observations made :\nIf Plm,n denotes the plausibility function of 1im,n, then it is natural to define the weight of evidence of a hypothesis H � 8 over a hypothesis H' � 8 by\nWm,n(H,H') := Plm,n(H)/Plm,n(H'). (14)\nBy theorem 4.9 of Kohlas & Monney [8], for all() E 8 we have\nm n Plm,n(B) = C ·(II lx(B) ·II lx'(B)) (15)\ni=l i=l\nwhere c is a positive constant which does not depend on (). This implies that the general definition of weight of evidence given in equation (14) generalizes to any type of hypothesis the weight of evidence for simple hypothesis given in equation (12) :\nPlm,n(()) = ft Wx ((), ()') . :ft Wx' ((), ()'). (16) Plm,n(B') i=l i=l\nIf the belief function 1im,n happens to be precise, i.e. all its focal sets are one-element subsets of e, then it can be proved that\n(H H') - LoeEH lm,n(B) (17) Wm,n ' - LoOEH' lm,n(B)\nAnother special case occurs when the belief function 1im,n is consonant, i.e. all its focal sets are nested. In this case we have\n1 max {lm,n(B) : () E H} ( ) Wm,n(H, H ) = max {lm,n(B) : () E H'} . 18\nThe last two equations are consequences of results on precise and consonant belief functions that can be found in Kohlas & Monney [8]. The situation where more than two different values x and x' are observed can be treated in a similar way.\n3 Functional and Distributional Models\nWe have seen that we need a generalized functional model to compute the weight of evidence for composite hypotheses. The problem is that in general there ex ist several GFM having the same associated distribu tional model. This means that if the initial knowledge is given in the form of a distributional model, then the weight of evidence will depend on the GFM that is cho sen to represent the given distributional model. To il lustrate this fact, we are going to consider a particular\ndistributional model and analyze two different GFM representing it. However, it should be mentionned that there is no reason why the initial knowledge should necessarily be given in the form of a distributional model. Any functional model that faithfully reflects the mechanism of the generation of the observed data can serve as an initial model.\nSuppose that an urn contains four balls which are ei ther black or white. We successively and randomly draw a ball from the urn and observe its color before it is placed back into the urn. Let ( denote the vari able indicating the color of the ball drawn. Suppose that we draw a total of r balls and that m happen to be white whereas n = r - m happen to be black. Based on these observations, what can be inferred on the correct value of the parameter variable t indicating the number of white balls in the urn ? In particular, what is the weight of the evidence represented by the observations with respect to certain hypotheses ? Let e = {0, 1, 2, 3, 4} denote the set of possible values of the variable t (the unknown number of white balls in the urn) and let X= {0, 1} denote the set of possible values of the observable variable ( where 1 represents white and 0 represents black. The distributional model for this problem is, for all () E 8,\n{ B/4 ifx=1 Pe(x)= 1- B/4 ifx=O. (19)\nThe classical binomial and Bayesian models (which re quires an additional prior distribution on e) can be used to make statistical inferences on e. But if we want to compute weights of evidence for any kind of hypotheses we need functional models. In the follow ing two subsections we are going to present two GFMs having Pe as their associated distributional model.\n3.1 A First GFM for the Urn Problem\nThe generalized functional model that will be pre sented in this subsection is inspired from the idea of conditional embedding proposed by Smets [14]. The method of conditional embedding is also described in Shafer [13]. Since we already have defined the variables t and (, we still have to specify the variable f. and its distribution along with the function f expressing what must necessarily be observed for each possible value of t and E. We take the variable f. to be indicating a particular relation between e and X. More precisely, the set of possible values of f. is n = {<pi, <p2, .. . , <ps} where each <pi is the indicator function of a certain subset Si of 8. In other words, <pi(()) = 1 if() E Si and 0 otherwise. The eight sets 81, ... , Ss are\n51= {4}, 5z = {1,4}, 53= {2,4}, 54= {3,4}, 55= {1,2,4}, 56= {1,3,4}, 57= {2,3,4},\n5s = {1,2,3,4}.\nThe distribution of E is defined to be\nP(cpi) = 3/32, P(cp2) = 1/32, P(cp3) = 3/32,\nP(cp4) = 9/32, P(cp5) = 1/32, P(cp5) = 3/32,\nP(cp1) = 9/32, P(cps) = 3/32.\nThe last piece of the GFM still missing is the function f : 6 x fl -t X. This function is defined by\nf(B, 'Pi)= 'Pi(B). (20)\nIt can easily be proved that the distributional model associated with this GFM is Pe given in (19).\nIf we observe a white ball (� = 1) in one draw, then the corresponding belief function 1{1 on e has eight focal sets which are\n{BEe: j(B,cpi) = 1}\n{ (} E 6 : 'Pi (B) = 1} 5i (21)\nfor all i = 1, ... , 8. Of course, the m-value of 5i is P(cpi) · We can show that if we observe only white balls in the r draws (i.e. m = r and n = 0), then the focal sets of the resulting belief function 1im,o are again 51, . . . , 5s and\nPlm,o( {1, 2}) Plm,o ( {2, 3}) Plm,o({1,3})\n(1/4)m + (1/2)m- (1/8)m (3/4)m + (1/2)m- (3/8)m (3/4)m + (1/4)m- (3/16r.\nThis can be used to compute the weights of evidence.\nThe case where only black balls are observed can be treated in a similar way.\nNow consider the situation where we draw r 2: 2 balls and m 2: 1 happen to be white and n 2: 1 happen to be black (r = m + n) . If 1io,n denotes the belief function resulting from the observation of the n black balls, then\n1im,n = 1im,O EB 1io,n (22)\nis the belief function corresponding to the observation of the black and white balls. Its plausibility function satisfies\nFrom Likelihood to Plausibility 399\nfor some positive constant K. Once again, this can be used to compute the weights of evidence as a function of m and n.\n3.2 A Second GFM for the Urn Problem\nAs in the previous model, let t denote the parameter variable indicating the number of white balls in the urn and � the observable variable indicating the color of the ball that is drawn (1 for white and 0 for black). In this model we assume that the four balls in the urn are numbered from 1 to 4. In addition, if there is (} white balls in the urn, we make the assumption that the white balls are numbered from 1 to (} and the black balls are numbered from (} + 1 to 4. This is an impor tant assumption that will permit us to easily specify a functional model. It is similar to the condition charac terizing the so-called structures of the first kind intro duced by Dempster [5, 6]. Since randomly drawing a ball in the urn is equivalent to randomly selecting the number of a ball, let E denote the variable represent ing the selected number and let n = { 1' 0 0 0 ' 4} denote the set of its possible values. Of course the distribu tion of E is P(w) = 1/4 for all w E n. To complete the specification of the GFM we define the function J: ex n -t x by\nj(B,w) = { 1 if w :S � (23) 0 otherwise\nbecause we necessarily observe a white ball if the ran domly selected number w is less than or equal to (}. Let's prove that the distributional model associated with this GFM is Pe given in (19). If x = 1, then we have\nP({w ED: j(B,w) = 1}) = P({w: w :S B}) = B/4.\nSimilarly, if x = 0, then we have\nP({w ED: f(B,w) = 0}) = P({w: w > B}) = 1- Bj4.\nIf we observe a white ball in one draw, then the cor responding belief function 1{1 on e has four focal sets which are\n{BE 6: f(B,w) = 1} { (} E 6 : w :S B} {w,w + 1, .. . ,4} (24)\nfor all w E D = {1, 2, 3, 4}. The m-value of each of these focal sets is 1/4. Note that 1i1 is a consonant belief function because its focal sets are nested.\nWe can show that if we observe only white balls in the r draws, then the focal sets of the resulting belief func tion 1im,O are again rl(w) for all WE fl = {1,2,3,4},\n400 Monney\nwhich shows that 1-lm,o is also a consonant belief func tion. Moreover, the m-value of the focal sets of 1-lm,o is given by\nmm,o({1,2,3,4}) = mm,o( {2, 3, 4})\nmm,o({3,4}) mm,o({4})\n(1/4)m (1/2)m- (1/4)m (3/4)m-(1/2)m 1-(3/4)m. (25)\nSince 1-lm,o is consonant, then by theorem 3. 7 of Kohlas & Monney [8] we have\nPlm,o(H) =max {Plm,o(B) : {} E H} (26)\nfor all H � e and\nPlm,o(B) = h(B)m = (B/4)m (27)\nfor all {} E 8 because it can be shown that c = 1 in equation (15). In particular we obtain\nPlm,o( {1, 2}) = Plm,o( {2, 3}) Plm,o({1,3})\n(1/2)m (3/4)m (3/4)m, (28)\nwhich in turn can be used to compute the weights of evidence.\nThe case where only black balls are observed can be treated in a similar way.\nNow consider the situation where we draw r 2:: 2 balls and m 2:: 1 happen to be white and n 2:: 1 happen to be black (r = m + n) . If 1-lo,n\ndenotes the belief function resulting from the observation of the n black balls, then\n1-lm,n = 1-lm,O EB 1-lo,n (29)\nis the belief function corresponding to the observation of the black and white balls. Its plausibility function satisfies\nwhere\nPlm,n( {1, 2}) Plm,n( {2, 3\n}) Plm,n( {1, 3})\nN12/K N23/K N13/K,\nN1 2 (1/4)m(3/4)n + (1/2)n((1/2)m- (1/4)m) N23 (1/4)n(3/4)m + (1/2)m((l/2)n-(1/4)n) N1 3 (1/4)m(3/4)n + (1/4)n((3/4)m-(1/4)m)\nand K is a constant. This in turn can be used to com pute the weights of evidence. Note that the plausibility degrees obtained in this model are different from those obtained in the model considered in the previous sub section, which implies that the weights of evidence are also different.\n4 Evidence About a Survival Rate\nIn this section we are going to generalize the last model to the situation where there is an arbitrary number of balls in the urn. However, in order to illustrate the applicability of the theory developed in this paper, we analyze a real-world example that gives a concrete significance to this urn problem. It is based on a real clinical problem from the early 1980s. The problem was to generate information about the survival rate of newborn babies with a certain critical health problem using a new treatment called extracorporeal membrane oxygenation (Bartlett et al. [2], Ware [15], Begg [3], see also Royall [11]). It had been shown that the survival rate with the old treatment is about 20% and scientists where quite confident that the new treatment might have a survival rate of at least 80%. Based on the observation of the effect of the new treatment on a few babies, the problem is to gauge the impact of this evidence for a survival rate of more than 80% versus a survival rate of 20%.\nThis problem is modelled in the following way. Con sider the population S of all babies suffering from this specific health problem and let L denote the subset consisting of those babies who would live with the new treatment. Assuming that there are N babies in the entire population S and {} babies in the subpopulation L, the survival rate is defined to be {} / N. Of course the number of surviving babies {} is unkown. Let t de note the variable indicating the number of babies who would survive with the new treatment. The set of pos sible values oft is e = {1, 2, . . . , N}. Let� denote the variable indicating the result of the new treatment on a baby in S. We define that � is 1 when the baby lives and 0 otherwise, so that the set of possible val ues of� is X= {0, 1}. Also, it is assumed that every baby in the population S has the same chance of being observed.\nUsing this information, the following distributional model between e and X can be defined : for all () E e,\nPe(1) = B/N, Pe(O) = 1- (B/N). (30)\nGiven some observations, Royall [11] determines the weight of evidence for the hypothesis H2 = {0.8 · N} over the hypothesis H{ = {0.2·N}. Since both of these hypotheses are simple, the distributional model is suf ficient to compute this value. However, here we want to determine the weight of evidence for the hypothesis H2 = {B : {} 2:: 0.8 · N} over the hypothesis H1 = H{. As we have seen, for this purpose we need a GFM hav ing Pe as its associated distributional model. First it is assumed that the babies in S are numbered from 1 to N in such a way that the babies in L are numbered first. In other words, the babies in L are numbered\nfrom 1 to () and the babies in S - L are numbered from () + 1 to N. Let E denote the variable represent ing the number of a baby randomly selected from S and let D = {1, ... , N} denote the set of its possible values. Of course P(w) = 1/N for all w E D. Then we are in a position to define the function f : e X n -+ X of the GFM by\nj((), w)= { 1 ifw:s;e 0 otherwise.\n(31)\nThis functions gives the result of the new treatment on the baby number w when there are () babies in the pop ulation L. The distributional model associated with this GFM is clearly Pe given in (30).\nSuppose that we observe a baby who lives whith the new treatment. From this evidence, what is the belief function 1-{1 on e that can be inferred ? It turns out that this is a consonant belief function whose focal sets are\n{() E 9: j((), w) = 1} { e E e : w :::::; e} {w, w + 1, . . . ,N} (32)\nfor all w E D. If [r .. s] represents the set of all inte gers between r and s (the limits are included), this shows that the focal sets of 1-l1 are Fi = [i .. N] for all i = 1, ... , N and the m-value of Fi is 1/ N for all i = 1, ... ,N.\nNow suppose that the new treatment is given to m babies and that they all live. If 1-lm,o denotes the belief function on e induced by these observations, then it can be shown that its focal sets are again Fi, i = 1, ... ,N, which shows that 1-lm,o is also a con sonant belief function. But what is the m-function of this belief function ? For i = 1, ... , N, let m�m) de note the m-value of the focal set Fi of 1-lm,O· Then Dempster's rule of combination implies that\ni-1 m�m) = (1/N)(i . m�m-1) + L mjm-1)) (33)\n!=1\nfor all i = 1, ... , N. Defining the N x N matrix\n0 0\nFrom Likelihood to Plausibility 401\nNote that the matrix T has the remarkable property of being stochastic, i.e. each of its columns sums to 1 and all its entries are non-negative. Considering the focal sets F1, ... , FN as theN states of a Markov chain, this implies that T is the transition matrix of a Markov chain Zt, t = 1, 2, ... with\nP(Zt = F;) = m�t). (35)\nOf course, the initial distribution of the chain is\nP(Z1 = F;) = m� l) = 1/N (36)\nfor all i = 1, ... , N. As a consequence of equation (34) we have\n(37)\nTherefore, to compute the m-function of 1-lm,o we have to compute the ( m -1 )-th power of the matrix T. For tunately, the matrix T has N different eigenvalues that are all real and by the Jordan decomposition method we obtain\nwhere\n-1 1 0\nM = 0\n0\nand\n1/N 0 0\nL = 0\n0\nThis implies that\nT= MLM-1\n0 -1 0 1 -1 0\n0 1\n0 2/N 0\n0 3/N 0\n0\n-1 0\n0 1\ni/N 0\n0 0\n1\n0 0\n0 1\n(38)\n(39) 1/N 1/N 2/N 1/N 1/N 0 3/N 0 0 and since Lm-1 is a diagonal matrix whose (i, i)-th element is (i/N)m-1, a little algebra shows that\nT= 1/N 1/N\n1/N 1/N 1/N\n1/N i/N 0 0\nNjN\nand the vector m(m) = (mlm) , ... , m}:;l)' (the prime means transpose), these equations can be written as\nm(m) = T . m(m-1). (34)\n(m) im - (i- 1)m m. = --::-- -'--� Nm\nfor all i = 1, ... , N.\n(40)\nWhen we observe that more and more babies survive with the new treatment and no one dies, i.e. when m tends to infinity, the m-function of 1-lm,o tends to the m-function m* given by m*( {N}) = 1 and m*(F;) = 0\n402 Monney\nfor the other focal sets Fi. But m * represents the be lief function asserting that N is surely the exact value of the parameter, which means that every baby will survive with the new treatment. Of course, this result is compatible with our intuition because if we observe more and more babies who survive with new treat ment (and never observe a baby who dies) , then we are more and more inclined to believe that the new treat ment will cure all babies. This asymptotic behavior of the belief function 1im,o is also a consequence of the fact that the state { N} is the only closed class of the Markov chain, i.e. it is an absorbing state of the chain.\nSince 1im,o is a consonant belief function and\nPlm,o(O) = (0/N)m (41)\nfor all 0 E 0, it is easy to compute the degree of plau sibility of any hypothesis H � 0 because\nPlm,o(H) =max {Plm,o(O) : 0 E H}. (42)\nThis in turn allows us to compute the weight of ev idence for any pair of hypotheses. For example, for the specific hypotheses H1 and H2 defined above we obtain\n(43)\nNow consider the situation where we observe a baby who does not survive with the new treatment. From this observation, what is the belief function 1io on 0 that can be inferred ? It turns out that this is a consonant belief function whose focal sets are Gi = [O .. (N- i)] for all i = 1, . . . , N and them-value of G i is 1 / N for all i = 1, . .. , N. Now suppose that the new treatment is given to n ba bies and that none of them survive. If 1io,n denote the belief function on e induced by these observations, then the focal sets of 1io,n are again Gi, i = 1, . . . , N, which shows that 1io,n is again a consonant belief func tion. But what is the m-function of this belief func tion ? If m�n) denotes the m-value of the focal set Gi of 1io,n, the Jordan decomposition method can be used to prove that\n(44)\nfor all i = 1, . . . , N because it is again possible to iden tify an underlying Markov chain. As above, this result can be used to compute 1io,n when n tends to infinity.\nSince 1io,n is a consonant belief function and\nPlo,n(O) = (1- (0/N))n (45)\nfor all 0 E 0, it is easy to compute the degree of plau sibility of any hypothesis H � 0 because\nPlo,n(H) =max {Plo,n(O) : 0 E H}. (46)\nThis in turn can be used to compute the weight of evidence for any pair of hypotheses. For example, we obtain\n( ) 0.2n n-1 Wo,n H2, H1 = O.B = 0.25 · 0.2 . (47)\nFinally, let's suppose that among r 2: 2 babies to which the new treatment is administered, a total of m 2: 1 live and a total of n 2: 1 die (m + n = r). Let\n1im,n = 1im,O EB 1io,n (48)\ndenote the belief function on e induced by these ob servations. In this case, it turns out that for all (i,j) in\n� = {(i,j) E 0 x 0: i + j :S N} (49)\nthe set Eii = [i .. (N- j)] is a focal set of 1im,n and its m-value is\nwhere\nN\nK 2.)zn- (l- l)n)(N -l)m 1=1 N\n2:)zm- (l -l)m)(N -l)n. 1=1\n(50)\nNote that the belief function 1im,n is no longer conso nant. If Plm,n denotes its plausibility function, then we can easily find that\nPl (0) = om(N-O)n\nm,n K (51)\nfor all 0 E 0. In addition, the degree of plausibility of [O .. r] and [l..r] are the same, and the degree of plausi bility of [r .. N] and [r .. (N- 1)] are the same. F inally, it can also be verified that\nPlm,n([l..r]) =\nPlm,n([r .. N]) =\nL�=l (zm-(l- l)m)(N -l)n K L:f-.-�r(zn- (l-l)n)(N -l)m\nK\nfor all r in {0, . . . , N} and\nPlm,n([r .. s]) = Plm,n([l..s]) + Plm,n([r .. N])- 1 (52)\nfor all r and s such that 0 ::; r ::; s :S N. These results can be used to compute the weight of evidence for any pair of hypotheses. For example, we obtain\nIf we collect the actual observations resulting from two studies about the effectiveness of the new treatment, we find that among r = 40 babies who received the new treatment a total of m = 39 babies survived and only n = 1 baby died. In this case we get\nA finer analysis of this function of N reveals that it stays approximately constant for N � 250 :\n(54)\nfor N � 250. This means that the weight of the available evidence for H2 versus H1 is approximately w = 5 · 1025. In order to give an intuitive interpreta tion to this value, consider an urn containing two balls which can be either black or white. If WW denotes the hypothesis that they are both white and BW denotes the hypothesis that there is one black and one white, then the weight of evidence w = 5 · 1025 is approxi mately the same as the weight of evidence for WW versus BW when we observe 85 white balls in 85 ran dom draws of a ball from the urn. This is pretty strong evidence for the hypothesis that the new treatment's survival rate is at least 80% versus the hypothesis that it is 20% (the old treatment's survival rate) .\n5 Conclusion\nWe have defined a general concept of weight of evi dence that is applicable to any kind of parametric hy pothesis. Classical distributional models do not con vey enough information to generate a natural and gen eral concept of weight of evidence. In other words, they are too coarse of a representation of the mechan ical process underlying the generation of the data ob served. Generalized functional models and the theory of belief functions are the appropriate tools for defining such a general concept. Finally, a weight of evidence can be given a concrete significance by finding a well understood and simple situation leading to the same weight of evidence.\nReferences\n[1] M. Stone A.P. Dawid. The functional-model ba sis of fiducial inference. The Annals of Statistics, 10(4):1054-1067, 1982.\n(2] R.H. Bartlett, D.W. Roloff, R.G. Cornell, A.F. Andrews, P.W. Dillon, and J.B. Zwischenberger. Extracorporeal circulation in neonatal respiratory failure : a prospective randomized study. Pedi atrics, 76:479-487, 1948.\nFrom Likelihood to Plausibility 403\n[3] C.R. Begg. On inferences from Wei's biased coin design for clinical trials (with discussion) . Biometrika, 77:467-484, 1990.\n[4] H. Bunke. Statistical inference: Fiducial and structural vs. likelihood. Math. Operationsforsch. u. Statist., 6:667-676, 1975.\n(5] A.P. Dempster. New methods for reasoning to wards posterior distributions based on sample data. Annals of Math. Statistics, 37:355-374, 1965.\n(6] A.P. Dempster. Upper and lower probability in ferences based on a sample from a finite univariate population. Biometrika, 54(3,4):515-528, 1967.\n(7] I . Hacking. Logic of Statistical Inference. Cam bridge Univ. Press, 1965.\n(8] J. Kohlas and P.A. Monney. A Mathematical Theory of Hints. An Approach to the Dempster Shaler Theory of Evidence, volume 425 of Lecture Notes in Economics and Mathematical Systems. Springer Verlag, 1995.\n[9] P.A. Monney. Support and plausibility degrees in generalized functional models. In P. Shenoy D. Geiger, editor, Uncertainty in Artificial Intel ligence, Proceedings of the Thirteenth Conference, pages 376-383. Morgan Kaufmann, 1997.\n[10] J. Pearl. Causation, action and counterfactuals. In M.L. Dalla Chiara et al., editor, Logic and Sci e ntific Methods, pages 355-375. Kluwer Academic Publishers, The Netherlands, 1997.\n(11] R. Royall. Statistical Evidence. A Likelihood Paradigm, volume 71 of Monographs on Statistics and Applied Probability. Chapman & Hall, 1997.\n[12] G. Shafer. A Mathematical Theory of Evidence. Princeton University Press, 1976.\n(13] G. Shafer. Belief functions and parametric mod els. J.R. Statistical Society, B, 44(3):322-352, 1982.\n(14] P. Smets. Un modele mathematico-statistique simulant le processus du diagnostic medical. PhD thesis, Free University of Brussels, 1978.\n[15] J .H. Ware. Investigating therapies of potentially great benefit: ECMO (with discussion) . Statisti cal Science, 4:298-340, 1989."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2011,
    "abstractText" : "Several authors have explained that the like­ lihood ratio measures the strength of the evi­ dence represented by observations in statisti­ cal problems. This idea works fine when the goal is to evaluate the strength of the avail­ able evidence for a simple hypothesis versus another simple hypothesis. However, the ap­ plicability of this idea is limited to simple hypotheses because the likelihood function is primarily defined on points simple hy­ potheses of the parameter space. In this paper we define a general weight of evidence that is applicable to both simple and compos­ ite hypotheses. It is based on the Dempster­ Shafer concept of plausibility and is shown to be a generalization of the likelihood ratio. Functional models are of a fundamental im­ portance for the general weight of evidence proposed in this paper. The relevant con­ cepts and ideas are explained by means of a familiar urn problem and the general analysis of a real-world medical problem is presented.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}