{
  "name" : "1401.3881.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Value of Information Lattice: Exploiting Probabilistic Independence for Effective Feature Subset Acquisition",
    "authors" : [ "Mustafa Bilgic", "Lise Getoor" ],
    "emails" : [ "mbilgic@iit.edu", "getoor@cs.umd.edu" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "We often need to make decisions and take appropriate actions in a complex and uncertain world. An important subset of decisions can be formulated as a classification problem, where an instance is described by a set of features and one of finite categorical options is chosen based on these features. Examples include medical diagnosis where the patients are described by lab tests and a diagnosis is to be made about the disease state of the patient, and spam detection where an email is described by its content and the email client needs to decide whether or not the email is spam.\nMuch research has been done on how to learn effective and efficient classifiers assuming that the features describing the entities are fully given. Even though this complete data assumption might hold on a few domains, in practice features that describe the entities often have missing values. In certain domains such as medical diagnosis where a decision is made based on a number of features that include laboratory test results, the missing feature values can be acquired at a cost by performing the related tests. In such cases, we need to decide which tests to perform in which order. The answer to this question, of course, depends on how important it is to get the correct classification decision. Put alternatively, the cost of an incorrect classification (e.g., a misdiagnosis) determines how much we are willing to spend on expensive tests. Thus, we need to devise a feature acquisition policy that can determine which tests to perform in which order and when to stop and make the\nc©2011 AI Access Foundation. All rights reserved.\nfinal classification decision so that the total incurred cost, the feature acquisition cost and the expected misclassification cost, is minimized.\nDevising the optimal policy in general requires considering all possible permutations of the features and their expected values. To provide some intuition, some features might be useful only if acquired together, and the cost and benefit of acquiring some features can depend on which other features have been acquired and what their values turned out to be. Because devising the optimal policy is intractable in general, previous work has been greedy (Gaag & Wessels, 1993; Yang, Ling, Chai, & Pan, 2006), has approximated value of information calculations (Heckerman, Horvitz, & Middleton, 1993), and has developed heuristic feature scoring techniques (Núñez, 1991; Turney, 1995).\nThe greedy approach, however, has at least two major limitations. First, because it considers each feature in isolation, it cannot accurately forecast the value of acquiring multiple features together, causing it to produce sub-optimal policies. Second, the greedy strategy assumes that features can be acquired sequentially and the value of a feature can be observed before acquiring the next one. This assumption, however, is often not very practical. For example, doctors typically order batches of measurements simultaneously such as blood count, cholesterol level, etc., and then possibly order another batch after the results arrive. These two limitations of the greedy approach make it necessary to reason with sets of features.\nReasoning with sets of features, on the other hand, poses serious tractability challenges. First of all, the number of subsets is exponential in the size of the feature set. Second, judging the value of acquiring a set of features requires taking an expectation over the possible values of the features in the set, which is also exponential in the number of the features. The good news, however, is that we do not need to consider all possible subsets of features in practice; certain features can render other features useless, while some features are useful only if acquired together. For example, an X-Ray might render a skin test useless for diagnosing tuberculosis. Similarly, a chest pain alone might not be useful for differentiating between a cold and a heart disease; it becomes useful only if it is combined with other features, such as a blood test.\nIn this article, we describe a data structure that discovers and exploits these types of constraints (features that render other features useless and features that are useful only if acquired together) from the underlying probability distribution. We propose Value of Information Lattice (VOILA) that reduces the space of all possible subsets by exploiting the constraints between the features. Additionally, VOILA makes it possible to share value of information calculations between different feature sets to reduce the computation time.\nThis article builds upon our earlier work (Bilgic & Getoor, 2007). Our contributions in this article include:\n• We introduce two additional techniques for sharing computations between different subsets of features. These new techniques are based on information caching and utilizing paths in the underlying Bayesian network.\n• We experiment with asymmetric misclassification costs in addition to the symmetric costs. The asymmetric setup reflects a more realistic case and provides new insights.\n• In addition to the feature acquisition costs defined by Turney (1995), we generate and experiment with synthetic feature costs. The synthetic feature costs capture\nmore complex feature acquisition costs and allows for leeway for various acquisition strategies to differ.\nThe remainder of this article is organized as follows. We describe the notation and problem formulation in Section 2. We describe how we can reduce the search space and share computations using VOILA in Section 3. We show experimental results in Section 4, discuss related work in Section 5, and discuss future work in Section 6. We then conclude in Section 7."
    }, {
      "heading" : "2. Notation and Problem Formulation",
      "text" : "Our main task is to classify a given instance that has missing feature values and incur the minimum acquisition and misclassification cost. Let the instance be described by a set of features X = {X1, X2, . . . , Xn} and let Y be the random variable representing its class. We assume that the joint probability distribution P (Y,X) is given and concern ourselves with feature acquisition during only inference (note that the conditional distribution P (Y |X) is not appropriate, as most features are assumed to be unobserved initially). For the purpose of this article, we assume that we are given a Bayesian network, but any joint probabilistic model that allows us to efficiently answer conditional independence queries can be used.\nIn the notation, a bold face letter represents a set of random variables and non-bold face letter represents a single random variable. For example X represents the set of features, whereas Xi ∈ X represents a feature in X and Y represents the class variable. Additionally, a capital letter represents a random variable, and a lowercase letter represents a particular value of that variable; this applies to both individual variables and sets of variables. For example, Y represents a variable, and y represents a particular value that Y can take.\nIn addition to the probabilistic model, we are also given the cost models that specify feature acquisition costs and misclassification costs. Formally, we assume that we have a feature acquisition cost function that given a subset of features, S, and the set of features whose values are known (evidence) E, returns a non-negative real number C(S | e). We also assume that we have a misclassification cost model that returns the misclassification cost cij incurred when Y is assigned yi when the correct assignment is yj . With these cost functions, we can model non-static feature acquisition costs; that is, the cost of acquiring the feature Xi can depend on what has been acquired so far and what their values are (e) as well what is acquired in conjunction with this feature (S \\ {Xi}). Moreover, the misclassification cost model does not assume symmetric costs; different kids of errors (false positives or negatives) can have different costs.\nFigure 1 shows a simple example configuration with two features, X1 and X2, and the class variable Y . In this simple example, the joint distribution P (X, Y ) is represented as a table, the feature costs are simple independent costs for X1 and X2, and the misclassification cost is symmetric where both types of misclassifications cost the same and correct classification does not cost anything.\nA diagnostic policy π is a decision tree where each node represents a feature and the branches from the nodes represent the possible values of the features. Each path of the policy, ps ∈ π, represents an ordered sequence feature values s. We will often use ps to represent an ordered version of s. Typically, the order of the features in the set will be important for computing the feature costs, as the cost of a feature can depend on the values\nof previously acquired features. The order of the features will be irrelevant for computing the probability P (s). An example conditional policy using the example configuration of Figure 1 is given in Figure 2.\nEach policy π has two types of costs: the feature acquisition cost and a misclassification cost. These costs are defined in terms of the costs associated with following the paths in the policy. We first describe how to compute the feature acquisition cost of a path and then describe how to compute the associated expected misclassification cost. Finally, we show how to compute the expected total cost of a policy using the total costs associated with each path.\nIn the most naive version, the feature cost of a path ps is the sum of the costs of the features that appear on the path. However, in practice, the cost of a feature can depend on which features have been acquired so far and the observed values of the acquired features. For example, performing the treadmill test (asking the patient to run a treadmill and measure his heart beat, etc.) can be riskier if we had ordered a cholesterol test and its result turned out to be high, putting the patient in high risk for heart disease. To account for these types of costs, the order of the features in ps matters, and the total feature cost of a path is the summation of the individual feature costs conditioned on the values of the features that precede the features in consideration:\nFC(ps) = n∑ j=1 C(ps[j] | ps[1 : j])\nwhere ps[j] represents the j th feature in ps and ps[1 : j] represents feature values 1 through j in ps. When we reach the end of a path, we need to make a classification decision. In this case, we simply utilize the Bayesian decision theory and choose the decision with minimum risk (i.e., misclassification cost). We find such a decision by using the probabilistic model to\ncompute the probability distribution P (Y | ps) and choose the value of Y that leads to the minimum expected cost. Note that the order of the features values do not matter in this case; that is P (Y | ps) = P (Y | s). The expected misclassification of a path, EMC(ps), is\ncomputed as follows:\nEMC(ps) = EMC(s) = min yi ∑ yj P (Y = yj | s)× cij (1)\nThe total cost that we incur by following a path of a policy is simply the sum of the feature and the expected misclassification costs of that path:\nTC(ps) = FC(ps) + EMC(ps)\nFinally, we compute the expected total cost of a policy π using the total costs of the individual paths ps ∈ π. Each path ps ∈ π has a probability of occurrence in real world. Such probability can be easily computed by the generative probability model that we assumed. It is simply P (s). The expected total cost of a policy is then the sum of the total cost of each path, TC(ps), weighted by the probability of following that path, P (s):\nETC(π) = ∑ ps∈π P (s)TC(ps) (2)\nThe objective of feature acquisition during inference is, given the joint probabilistic model and the cost models for acquisition and misclassification, find the policy that has the minimum expected total cost. However, building the optimal decision tree is known to be NP-complete (Hyafil & Rivest, 1976). Thus, most research have been greedy choosing the best feature that reduces the misclassification costs the most and has the lowest cost (e.g., Gaag & Wessels, 1993; Dittmer & Jensen, 1997) or have developed heuristic feature scoring techniques (e.g., Núñez, 1991; Tan, 1990).\nIn the greedy strategy, each path of the policy is extended with the feature that reduces the misclassification cost the most and that has the lowest cost. More specifically, the path ps is replaced with new paths ps∪x1i ,ps∪x2i , . . . ,ps∪xni where x 1 i , x 2 i , . . . , x n i are the values that Xi can take and Xi is the feature that has the highest benefit. We define the benefit of a feature Xi given a path ps as the reduction in the total cost of the path when the path is expanded with the possible values of Xi. More formally,\nBenefit(Xi | ps) , TC(ps)− n∑ j=1 P (xji | s)TC(ps∪xji )\n= FC(ps) + EMC(s)− n∑ j=1 P (xji | s) ( FC(p s∪xji ) + EMC(s ∪ xji ) )\n= FC(ps)−  n∑ j=1 P (xji | s)FC(ps∪xji ) + EMC(s)− n∑ j=1 P (xji | s)EMC(s ∪ x j i )\n= FC(ps)− (FC(ps) + C(Xi | s)) + EMC(s)− n∑ j=1 P (xji | s)EMC(s ∪ x j i )\n= −C(Xi | s) + EMC(s)− n∑ j=1 P (xji | s)EMC(s ∪ x j i )\nNote that, the last two terms are equivalent to the definition of expected value of information, EVI, (Howard, 1966):\nEV I(Xi | s) = EMC(s)− n∑ j=1 P (xji | s)EMC(s ∪ x j i ) (3)\nSubstituting EVI, the definition of benefit becomes very intuitive:\nBenefit(Xi | ps) = Benefit(Xi | s) = EV I(Xi | s)− C(Xi | s) (4)\nWith this definition, the greedy strategy iteratively finds the feature that has the highest positive benefit (value cost difference), acquires it, and stops acquisition when there are no more features with a positive benefit value.\nWe also note that it is straightforward to define EVI and Benefit for a set S′ of features just like we did for a single feature. The only difference is that the expectation needs to be taken over the joint assignments, s′, to the features in the set S′.\nEV I(S′ | s) = EMC(s)− ∑ s′ P (s′ | s)EMC(s ∪ s′) (5)\nand,\nBenefit(S′ | s) = EV I(S′ | s)− C(S′ | s) (6)\nThere are a few problems with the greedy strategy as we have mentioned earlier. First, it is short-sighted. There exist sets S ⊆ X such that Benefit(S) > ∑ Xi∈S Benefit(Xi). This is easier to see, for example, for the XOR function, Y = X1 XOR X2, where X1 and X2 alone are not useful but they are determinative together. Due to this relationship, a greedy policy is not guaranteed to be optimal. Moreover, the greedy policy can prematurely stop acquisition because no single feature seems to provide positive benefit.\nThe second problem with the greedy strategy is that we often need to acquire a set of features simultaneously. For example, a doctor orders a set of lab tests when s/he sends the patient to a lab, such as blood count, cholesterol level, etc. rather than ordering a single test, waiting for its result and ordering the next one. However, the traditional greedy strategy cannot handle reasoning with sets of features naturally.\nWe would like to be able to reason with sets of features for these two reasons. Our objective in this article is, given an existing potentially empty set of already observed features E and their observed values e, find the set that has the highest benefit:\nL(X | e) , argmax S⊆X\\E Benefit(S | e) (7)\nThere are two problems with this formulation: first, the number of subsets of X \\ E is exponential in the size of X \\E, and second, for each set S, we need to take an expectation over the joint assignments to all features in the set. We address these two problems using a data structure that we describe next.\n3. Value of Information Lattice (VOILA)\nVOILA makes reasoning with sets of features tractable by reducing the space of possible sets and allowing sharing of EVI computations between different sets. In this section, we will first explain how we can reduce the space and then explain techniques for computation sharing."
    }, {
      "heading" : "3.1 Reducing the Space of Possible Sets",
      "text" : "In most domains, there are often complex interactions between the features and the class label. Contrary to the Naive Bayes assumption, features are often not conditionally independent given the class label. Some features are useless once some other features are already acquired. For example a chest X-Ray is typically more determinative than a skin test for tuberculosis. Similarly, some features are useless alone unless they are accompanied with other features. For example, a chest pain alone might be due to a variety of sicknesses; if it is accompanied with high cholesterol, it could indicate a heart disease, whereas if it is combined with fever, a cold might be more probable. These types of interactions between the features allow us to reduce the space of candidate feature sets.\nAs we have mentioned in the problem formulation, we have assumed that we already have a joint probabilistic model over the features and the class variable, P (Y,X). We will find these two types of feature interactions by asking probabilistic independence queries using P (Y,X). Specifically, we assume that we are given a Bayesian network that represents P (Y,X). The Bayesian network will allow us to find these types of interactions through standard d-separation algorithms.\nDefinition 1 A set S ⊆ X \\E is irreducible with respect to evidence e if ∀Xi ∈ S, Xi is not conditionally independent of Y given e and S \\ {Xi}.\nGiven a Bayesian network over X and Y , it is straightforward to check irreducibility through d-separation (Pearl, 1988).\nProposition 1 Let S′ be a maximal irreducible subset of S with respect to e. Then, EV I(S | e) = EV I(S′ | e).\nProof: Let S′′ = S \\ S′. If S′ is a maximal irreducible set, S′ ∪ E d-separates Y and S′′. Otherwise, we could make S′ larger by including the non-d-separated element(s) from S′′ in S′. Thus, we have P (Y | e, s) = P (Y | e,S′,S′′) = P (Y | e,S′). Substitution in Equations 1 and 5 yields the desired property.\nNote that under the assumption that C(S′ | e) ≤ C(S | e) for any S′ ⊆ S, it suffices to consider only the irreducible sets to find the optimal solution to the objective function in Equation (7). VOILA is a data structure that contains only the irreducible feature subsets of X, with respect to a particular set of evidence e. We next define VOILA formally.\nDefinition 2 A VOILA V is a directed acyclic graph in which there is a node corresponding to each possible irreducible set of features, and there is a directed edge from a feature set S to each node that corresponds to a direct (maximal) subset of S. Other subset relationships in the lattice are then defined through the directed paths in V.\nFigure 3(a) shows a simple Bayesian network and its corresponding VOILA, with respect to the empty evidence set, is shown in Figure 3(b). Notice that the VOILA contains only the irreducible subsets given the Bayesian network; for instance, the VOILA does not contain sets that include both X1 and X2 because X1 d-separates X2 from Y . We also observe that the number of irreducible subsets is 9 in contrast to 24 = 16 possible subsets. Moreover, note that the largest subset size is now 3 in contrast to 4. Having smaller feature sets sizes has a dramatic effect on the value of information calculations. In fact, these savings can make solving the objective function optimally (Equation (7)) feasible in practice.\n3.2 Sharing EVI Calculations\nFinding the set S that has the highest Benefit (Equation 6) requires computing EV I(S) (Equation 5). However, computing EV I(S) requires taking an expectation over all possible values of the features in S. Moreover, searching for the best set among all the irreducible sets requires us to compute EVI for all irreducible sets. To make such computations tractable in practice, VOILA allows computation sharing between its nodes. In this article, we describe three possible ways of sharing computations between the nodes of VOILA."
    }, {
      "heading" : "3.2.1 Subset Relationships",
      "text" : "VOILA exploits the subset relationships between different feature sets in order to avoid computing EVI for some nodes. First of all, if there is a directed path from node S1 to S2 in VOILA, then S1 ⊃ S2 and thus EV I(S1 | e) ≥ EV I(S2 | e)1. Now assume that there is a directed path from Si to Sj and EV I(Si | e) = EV I(Sj | e). Then, all of the nodes on this path will also have the same EVI, thus we do not need to do the computation for those subsets. An algorithm that makes use of this observation is given in Algorithm 1.\nAlgorithm 1: Efficient EVI computation using VOILA.\nInput: VOILA V and current evidence E Output: VOILA updated with correct EVI values for all root node(s) S1 value← EV I(S | e); ub(S)← value; lb(S)← value2 ub(descendants(S))← value3\nfor all leaf node(s) S4 value← EV I(S | e); ub(S)← value; lb(S)← value5 lb(ancestors(S))← value6\nfor all node S where lb(S) 6= ub(S)7 value← EV I(S | e); ub(S)← value; lb(S)← value8 lb(ancestors(S))← value9 ub(descendants(S))← value10\nIt is important to point out that all nodes of VOILA are irreducible sets. Unless there are totally useless features that do not change P (Y ) when observed, then we should not have any two distinct nodes where the EVI values are exactly equal. However, this statement is true only if we do not have any context-specific independencies (independencies that hold only under certain assignments to the variables) in the underlying Bayesian network. In our description and implementation, we used standard d-separation at the variable level; one can imagine going one step further and define the irreducible sets through both the variable level d-separation and context specific independencies.\nIn order to share computations between different nodes of the lattice, we keep lower and upper bounds on the EVI of a node. The lower bound is determined by the values of the descendants of the node whereas the upper bound is determined by the values of its ancestors. First, we initialize these bounds by computing the value of the information at the boundary of the lattice, i.e., the root node(s) and the leaf node(s) (lines 1–6) 2. Then, we loop over the nodes whose upper bounds and lower bounds are not equal (line 7–10), computing their values and updating the bounds at their ancestors and descendants. The algorithm terminates when the upper bounds and lower bounds for all the nodes become tight. The order in which to choose the nodes in line 7 so that the number of sets for which a value is calculated is minimum is still an open question. A possible heuristic is to perform\n1. A superset has always a higher or equivalent EVI (Equation (5)) than its subset. 2. We do not need to compute EVI for all root nodes; it suffices to compute it for the node that corresponds\nto the Markov blanket of Y . This will be explained in more detail in the next section.\na binary search and choose a middle node on a path between two nodes for which the values have already been calculated."
    }, {
      "heading" : "3.2.2 Information Pathways at the Underlying Bayesian Network",
      "text" : "The second mechanism that VOILA uses to share EVI computations is through the edges in the underlying Bayesian network. We specifically make use of the following fact:\nProposition 2 For all S1 and S2, if S1 d-separates Y from S2 with respect to e, then EV I(S1 | e) ≥ EV I(S2 | e).\nProof: Consider S12 = S1∪S2. Because of the subset relationship, we know that EV I(S12 | e) ≥ EV I(S1 | e) and EV I(S12 | e) ≥ EV I(S2 | e).\nEV I(S12 | e) = EMC(Y | e)− ∑ s12 P (s12 | e)EMC(Y | e, s12)\n= EMC(Y | e)− ∑ s1 ∑ s2 P (s1, s2 | e)EMC(Y | e, s1, s2)\n= EMC(Y | e)− ∑ s1 ∑ s2 P (s1, s2 | e)EMC(Y | e, s1)\n= EMC(Y | e)− ∑ s1 P (s1 | e)EMC(Y | e, s1) = EV I(S1 | e) ≥ EV I(S2 | e)\nThe third line follows from the second by the fact that S1 d-separates Y from S2 and thus P (Y | s1, s2) = P (Y | s1).\nCorollary: The Markov blanket of Y , (i.e., Y ’s parents, Y ’s children, and Y ’s children’s other parents), is the set that has the highest EVI in our search space, as it d-separates all of the remaining variables from Y . Using this corollary, we do not need to compute the EVI for all root nodes in Algorithm 1; we can compute EVI for the root node that corresponds to the Markov blanket of Y and it serves as the upper bound for the EVI of the remaining root nodes.\nThese relationships can very well be exploited like we exploited the subset relationships above. Instead of just using the subset relationships, we can use both subset and independence relationships. One simple way to make use of Algorithm 1 without modification is to add edges between any S1 and S2 where the independence property holds. An example S1 and S2 according to our toy network in Figure 3(a) would be S1 = {X1} and S2 = {X2}. Thus, we can add a directed edge from X1 to X2 in our VOILA in Figure 3(b) and Algorithm 1 will work just fine."
    }, {
      "heading" : "3.2.3 Incremental Inference",
      "text" : "The third and the last mechanism that VOILA uses for computation sharing is through caching of probabilities at its nodes. For each candidate set S ∈ V, we need to compute EV I(S | e) which requires computing P (S | e) and EMC(Y | S, e). If we cache the\nconditional probabilities at each node of V, then to compute P (S | e), we find one of its supersets Si = S ∪ {Xi} and then compute P (S | e) = ∑ xi P (S, Xi = xi | e).\nComputing EMC(Y | S, e) requires computing P (Y | S, e). To perform this computation efficiently, we cache the state of the junction tree at each node of the VOILA. Then, we find a subset, Sj , such that S = Sj ∪ {Xj}. We compute P (Y | S, e) by integrating the extra evidence to the junction tree at node Sj that is used to compute P (Y | Sj , e).\n3.3 Constructing VOILA\nEfficient construction of VOILA is not a straightforward task. The brute force approach would be to enumerate all possible subsets of X \\E and for each subset check whether it is irreducible. However, this brute force approach is clearly impractical. Because the number of nodes in VOILA is expected to be much fewer than the number of possible subsets of X\\E, if we can be smart about which sets we consider for inclusion in V, we can construct it more efficiently. That is, instead of generating all possible candidates and checking whether they are irreducible or not, we try to generate only irreducible sets. We first introduce the notion of a dependency constraint and then explain how we can use dependency constraints to efficiently construct VOILA.\nDefinition 3 A dependency constraint for a feature Xi ∈ S with respect to S and E is the constraint on S ∪E that ensures a dependency between Xi and Y exists.\nFor instance, in our running example, a dependency constraint for X2 is ¬X1; in other words, in order for X2 to be relevant, X1 should not be included in S ∪ E. Similarly, the dependency constraint for X4 is X3, meaning that X3 must be included in S∪E. Specifically, a dependency constraint for a feature Xi requires that all Xj on the path from Y to Xi not to be included in S∪E if Xj is not part of a v-structure; if Xj is part of a v-structure, then either Xj or one of its descendants must be included in S∪E (we refer to these latter constraints as positivity constraints). The algorithm that uses these ideas to compute the dependency constraints for each feature is given in Algorithm 2.\nAlgorithm 2: Dependency constraint computation for Xi.\nInput: Xi, Y Output: Dependency constraint for Xi, denoted DC(Xi) DC(Xi)← false1 for each undirected path pj between Xi and Y2 DCj(Xi)← true3 for each Xk on the path pj4 if Xk does not a cause a v-structure then5 DCj(Xi)← DCj(Xi) ∧ ¬Xk6 else7 DCj(Xi)← DCj(Xi) ∧ (Xk ∨Descendants(Xk))8\nDC(Xi)← DC(Xi) ∨DCj(Xi)9\nThese dependency constraints can be used to check whether a set is irreducible or potentially irreducible. Intuitively, a set is potentially irreducible if it is not irreducible but it is possible to make the set irreducible by adding more features into it. More formally,\nDefinition 4 A set S ⊆ X \\ E is potentially irreducible with respect to evidence e if, S is not irreducible but there exists a non-empty set of features S′ ⊆ X \\ {E ∪ S} such that S ∪ S′ is irreducible.\nPotential irreducibility is possible due to the non-monotonic nature of d-separation. That is, a feature that is d-separated from Y can become dependent if we consider it in combination with other features. For example, in our running example, {X4} is not irreducible, as X4 is d-separated from Y , whereas {X3, X4} is irreducible.\nWe use the dependency constraints to check whether a set is irreducible or potentially irreducible. Because a set S is irreducible only if a dependency between all of its elements and Y exists, the dependency constraint for the set S is the conjunction of the dependency constraints of its members. The irreducibility of S can be checked by setting the elements of S and E to “true” and setting the remaining elements of X to “false” and evaluating the set’s dependency constraint. In our running example, the dependency constraint for the set {X2, X4} is ¬X1∧X3. Assuming E = ∅, when we set the members of {X2, X4} to true, and set the remaining features, X1 and X3, to false, ¬X1 ∧X3 then evaluates to false and thus this set is not irreducible. This makes sense because given no evidence, X4 is independent of Y , so while {X2} is a useful feature set to consider for acquisition, {X2, X4} is not.\nChecking for potential irreducibility is very similar. Set the elements of S and E to true like we did above. Then, set the positivity constraints of the members of S to true. Finally, set everything else to false. Using the same example above, to check whether {X2, X4} is potentially irreducible, set X2 = true, X4 = true. Also set X3 = true because it is the positivity constraint for X4. Set the remaining features, that is X1, to false. Evaluating the constraint ¬X1 ∧X3 yields to true, showing that {X2, X4} is potentially irreducible (while it was not irreducible).\nGiven the definitions of irreducibility and potential irreducibility and the mechanisms to check for these properties through the notion of dependency constraints, we next describe the algorithm to construct VOILA.\nVOILA construction proceeds in a bottom up fashion, beginning with the lowest level, which initially contains only the empty set and constructs new irreducible feature sets by adding one feature at a time into the VOILA structure. Algorithm 3 gives the details of the algorithm. The algorithm keeps track of the irreducible feature sets IS, and the set of potentially irreducible feature sets PS. When we are done processing feature Xij , we remove from PS any potentially irreducible set that cannot become irreducible because Xij will not be re-considered (line 11).\n3.3.1 Analysis of VOILA Construction Algorithm\nThe construction algorithm inserts a node into the VOILA only if the corresponding set is irreducible (lines 6 and 7). Moreover, by keeping track of potentially irreducible sets (lines 8–10), we generate every possible irreducible set that can be generated. Thus, VOILA contains only and all of the possible irreducible subsets of X.\nAlgorithm 3: The VOILA construction algorithm.\nInput: Set of features X and class variable Y . Output: The VOILA data structure V, given E. Pick an ordering of elements of X = Xi1 , Xi2 , . . . , Xin1 IS← {∅}; PS← ∅2 for j = 1 to n3 for each S ∈ IS ∪PS4 S′ ← S ∪Xij ; DC(S′)← DC(S) ∧DC(Xij )5 if S′ is irreducible then6 IS← IS ∪ {S′}; Add a node corresponding to S′ to V7 else8\nif S′ is potentially irreducible then9 PS← PS ∪ {S′}10\nRemove from PS all sets that are no longer potentially irreducible11\nmax = size of largest S in IS; Ll = {S | S ∈ IS and |S| = l}12 for l = 0 to max− 113 for each S ∈ Ll14 for each S′ ∈ Ll+115 if S ⊂ S′ then16 Add an edge from S′ to S to V17\nThe worst-case running time of the algorithm is still exponential in the number of initially unobserved features, X \\ E, because number of irreducible sets can potentially be exponential. The running time in practice, though, depends on the structure of the Bayesian network that the VOILA is based upon and the ordering of the variables in line 1. For example, if the Bayesian network is naive Bayes, then all subsets are irreducible (no feature d-separates any other feature from the class variable); thus, the search space cannot be reduced at all. However, naive Bayes makes extremely strong assumptions which are unlikely to hold in practice. In fact, as we empirically show in the experiments section on five real-world datasets, features often are not conditionally independent given the class variable; there are more complex interactions between them and thus the number of irreducible subsets is substantially smaller than the number of all possible subsets.\nThe for loop at line 4 iterates over each irreducible and potentially irreducible sets that have been generated so far, and the number of potentially-irreducible sets generated depends on the ordering chosen. A good ordering processes features with literals with positivity constraints in other features’ dependency constraints earlier. That is, for each undirected path from Y to Xi that includes Xj in a v-structure, a good ordering puts Xj earlier in the ordering than everything between Xj and Xi. For instance, in our sample Bayesian network in Figure 3(a), we should consider X3 earlier than X4. We refer to an ordering as perfect if it satisfies all the positivity constraints. If a perfect ordering is used, VOILA construction algorithm never generates a potentially irreducible set. Unfortunately, it\nis not always possible to find a perfect ordering. A perfect ordering is not possible when two features have each other as a positivity constraint literal in their dependency constraints. This case occurs only when there is a loop from Y to Y that has two or more v-structures (Note that even though a Bayesian network is a directed acyclic graph, it can still contain loops, i.e., undirected cycles). A perfect ordering was possible in four of the five real world datasets that we used.\n3.4 Using VOILA for Feature-value Acquisition\nVOILA makes searching the space of all possible subsets tractable in practice. Using this flexibility, it is possible to devise several different acquisition policies. We describe two policies as example policies in this section.\nThe first acquisition policy aims to capture the practical setting where more than one feature is acquired at once. The policy can be constructed using VOILA as follows. Each path ps of the policy π (which is initially empty) is repeatedly extended by acquiring the set S′ ∈ V that has the best Benefit(S′ | s, e). The policy construction ends when no path can be extended, i.e., all candidate sets have non-positive Benefit values for each path of π.\nThe second acquisition policy adds a look-ahead capability to the greedy policy. That is, rather than repeatedly extending each path ps of policy π with the feature Xi that has the highest Benefit(Xi | s, e), we add a look-ahead capability, and first find the set S′ ∈ V that has the highest Benefit(S′ | s, e). Then, instead of acquiring all features in S′ all at once, like we did in the above policy, we find the feature Xi ∈ S′ that has the highest Benefit(Xi | s, e) and acquire it to extend ps."
    }, {
      "heading" : "4. Experiments",
      "text" : "We experimented with five real-world medical datasets that Turney (1995) described and used in his paper. These datasets are Bupa Liver Disorders, Heart Disease, Hepatitis, Pima Indians Diabetes, and Thyroid Disease, which are all available from the UCI Machine Learning Repository (Frank & Asuncion, 2010). The datasets had a varying number of features ranging from five to 20. Four out of five datasets had binary labels, whereas the Thyroid dataset had three labels.\nFor each dataset, we first learned a Bayesian Network that both provides the joint probability distribution P (Y,X) and efficiently answers conditional independence queries thorough d-separation (Pearl, 1988). We built a VOILA for each dataset using the learned Bayesian Network. We first present statistics on each dataset, such as the number of features and number of nodes in the VOILA, and then compare various acquisition policies."
    }, {
      "heading" : "4.1 Search Space Reduction",
      "text" : "Table 1 shows aggregate statistics about each dataset, describing the number of features, the number of all possible subsets, the number of subsets in VOILA, and the percent reduction in the search space. As this table shows, the number of irreducible subsets is substantially fewer than all possible subsets. For the Thyroid Disease dataset, for example, the number of possible subsets is over a million whereas the number of irreducible subsets is fewer than\nthirty thousand. This enormous reduction in the search space makes searching through the possible sets of features tractable in practice."
    }, {
      "heading" : "4.2 Expected Total Cost Comparisons",
      "text" : "We compared the expected total costs (Equation 2) of four different acquisition policies for each dataset. These policies are as follows:\n• No Acquisition: This policy does not acquire any features; it aims to minimize the expected misclassification cost based on the prior probability distribution of the class variable, P (Y ).\n• Markov Blanket: This policy acquires every relevant feature, regardless of the misclassification costs. The Market Blanket of Y in a Bayesian network is defined as Y ’s parents, children, and its children’s other parents (Pearl, 1988). Intuitively, it is the minimal set S ⊆ X such that Y ⊥ (X \\ S) | S.\n• Greedy: This policy repeatedly expands each path ps of an initially empty policy π by acquiring the feature Xi that has the highest positive Benefit(Xi | s) (Equation 4). The policy construction ends when no path can be extended with a feature with a positive Benefit value.\n• Greedy-LA: This policy adds a look-ahead capability to the Greedy strategy. This policy repeatedly expands each path ps of an initially empty policy π by first finding the set S′ that has the highest positive Benefit(S′ | s) (Equation 6) and then acquiring the feature Xi ∈ S′ that has the maximum Benefit(Xi | s) (Equation 4). The policy construction ends when no set with a positive Benefit value can be found for any path of the policy.\nThe feature costs for each dataset are described in detail by Turney (1995). In summary, each feature can either have an independent cost, or can belong to a group of features, where the first feature in that group incurs an additional cost. For example, the first feature from a group of blood measurements incurs the overhead cost of drawing blood from the patient. The feature costs are based on the data from Ontario Ministry of Health (1992).\nWe observed that most of the features were assigned the same cost. For example, four out of five features in the Bupa Liver Disorders dataset, 13 out of 19 features in the Hepatitis dataset, six out of eight features in the Diabetes dataset, and 16 out of 20 features in the Thyroid Disease dataset were assigned the same cost. When the costs are so similar, the problem is practically equivalent to finding the minimum size decision tree. To provide more structure into the feature acquisition costs, we also experimented with randomly generated feature and group costs. For each feature, we randomly generated a cost between 1 and 100, and for each group we generated a cost between 100 and 200. We repeated the experiments with three different seeds for each dataset.\nThe misclassification costs were not defined in the paper by Turney (1995). One reason could be that it is easier to define the feature costs, but defining the cost of a misclassification can be non-trivial. Instead, Turney tests different acquisition strategies using various misclassification costs. We follow a similar technique with a slight modification. We compare the above acquisition policies under both symmetric (cij = cji) and asymmetric misclassification costs. To be able to judge how the misclassification cost structure affects feature acquisition, we unify the presentation, and compare different acquisition strategies under the same a priori expected misclassification costs, as defined in Equation (1). Specifically, we compare the acquisition policies under various a priori EMC that are achieved by varying the cij accordingly. We show an example misclassification table for an EMC value of 1 in Table 2. For the real feature cost case, we varied the EMC between 0 and 2000, and varied it from 0 to 4000 for the synthetic feature cost case.\nWe compare the Greedy, Greedy-LA, and Markov Blanket policies by plotting how much cost each policy saves with respect to the No Acquisition policy. In the X axis of the plots, we vary a priori expected misclassification cost using the methodology we described above. We plot the savings on the Y axis. For each dataset, we plot four different scenarios: the cross product of {symmetric, asymmetric} misclassification costs, and {real, synthetic} feature costs.\nThe results for the Liver Disorders, Diabetes, Heart Disease, Hepatitis, and Thyroid Disease are given in Figures 4, 5, 6, 7, and 8 respectively. For each figure, symmetric misclassification cost scenarios are given in sub-figures (a) and (c), whereas the asymmetric\nmisclassification cost scenarios are presented in (b) and (d). Similarly, the real feature cost scenarios are given in (a) and (b) and the synthetic feature cost scenarios are presented in (c) and (d). We next summarize the results.\n• We found that the Greedy policy often prematurely stopped acquisition, performing even worse than the Markov Blanket strategy. This is true for most of the datasets, regardless of the feature and misclassification cost structures. The fact that the Greedy strategy can perform worse than Markov Blanket strategy is really troubling. At first, it might seem rather unintuitive that Greedy strategy can perform worse than Markov Blanket strategy. Part of the reason is that the features belong to groups and the first feature from its group incurs an overhead cost. In Greedy strategy where each feature is considered in isolation, the overhead costs can outweigh each single feature’s benefit, and because Greedy does not look ahead, it is reluctant to commit to acquiring the first feature from any group.\n• Greedy-LA strategy never performs worse than any other strategy under any setting.\n• The misclassification cost structure (symmetric or asymmetric) had a considerable effect on how the policies behaved. The differences between symmetric and asymmetric cases were particularly evident for datasets where the class distribution was more imbalanced, such as the Diabetes (Figure 5), Hepatitis (Figure 7), and the Thyroid Disease (Figure 8) datasets. The differences due to the misclassification cost structure can be summarized as follows:\n– When the class distribution is imbalanced and the misclassification cost is symmetric, acquiring more information cannot change the classification decisions easily due to the class imbalance, thus the features do not have high EVI values. On the other hand, if the misclassification costs are asymmetric, features tend to have higher EVI values. Thus, the Greedy and Greedy-LA strategies start acquiring features earlier in the X axis for the asymmetric cases compared to\ntheir symmetric counterparts. For example, for the Thyroid disease dataset with real feature costs, the Greedy strategy starts acquisition only when the EMC is greater than 600 for symmetric misclassification costs (Figure 8(a)) whereas it starts acquiring when the EMC reaches only 100 for the asymmetric case (Figure 8(b)). For the synthetic feature costs, the results are more dramatic; neither Greedy or Greedy-LA acquires any features for the symmetric cost case (Figure 8(c)), whereas they start acquisition when EMC = 200 for the asymmetric case (Figure 8(d)).\n– In the same realm with the above results, the slope of the savings for the asymmetric case is much higher compared to the symmetric case.\n– The misclassification cost structure causes differences between the Greedy and Greedy-LA policies in a few cases. For the Diabetes dataset Greedy policy performs worse when the misclassification costs are symmetric (Figures 5(a) and\n5(c)), whereas for the Hepatitis dataset, it performs worse for the asymmetric misclassification costs (Figures 7(b) and 7(d)).\n• The Greedy policy sometimes has an erratic, unpredictable, and unreliable performance as the expected misclassification changes. It possibly hits a local minima, gets out of it later, and hits local minima again (Figures 6 and 8(d)).\nWe finally present an aggregate summary of the results in Table 3. Table 3 shows how much the Greedy policy and the Greedy-LA policy saves over the Markov Blanket policy. The results are presented as the average saving over various intervals, such as [0-500). As this table also shows, the Greedy-LA policy never loses compared to the Markov Blanket policy, as one would expect. Additionally, the Greedy-LA policy wins over the Greedy policy for most of the cases, and it never looses. Finally, Greedy policy prematurely stops acquisition, having negative savings with respect to the Markov Blanket strategy."
    }, {
      "heading" : "5. Related Work",
      "text" : "Decision theoretic value of information calculations provide a principled methodology for information gathering in general (Howard, 1966; Lindley, 1956). Influence diagrams, for example, are popular tools for representing decisions and utility functions (Howard & Matheson, 1984). However, because devising the optimal acquisition policy (i.e., constructing the optimal decision tree) is intractable in general, most of the approaches to feature acquisition have been myopic (Dittmer & Jensen, 1997), greedily acquiring one feature at a time. The greedy approaches typically differ in i) the problem setup they assume, ii) the way the features are scored, and iii) the classification model being learned. We review existing work here, highlighting the differences between different techniques in these three dimensions.\nGaag and Wessels (1993) consider the problem of “evidence” gathering for diagnosis using a Bayesian Network. In their setup, they gather evidence (i.e., observe the values of the variables) until the hypothesis is confirmed or disconfirmed to a desired extent. They\npropose an acquisition algorithm that greedily computes the expected utility of acquiring a feature and chooses the one with the highest utility. They define the utility as the absolute value of the change in the probability distribution of the hypothesis being tested.\nIn more recent work, Sent and Gaag (2007) consider the problem of acquiring more than a single feature at each step. They define subgoals and cluster the features for each subgoal. The subgoals and clustering of the features are provided by the domain experts. Then, they in the non-myopic case, they pick a cluster by calculating their expected values. However,\nbecause clusters can be big, calculating the expected value of a cluster can be problematic; thus, they also provide a semi-myopic algorithm where they pick the cluster that has the best (myopic) feature.\nNúñez (1991) introduces a decision tree algorithm called EG2 that is sensitive to the feature costs. Rather than splitting the decision tree at a feature that has high information gain, EG2 chooses a feature that has least “information cost function,” which is defined as the ratio of a feature’s cost to its discriminative efficiency. EG2 is, however, is not directly optimized to balance the misclassification cost and feature acquisition cost; rather it is optimized for 0/1 loss while taking the feature costs into account. Similarly, Tan (1990) modifies the ID3 algorithm (Quinlan, 1986) to account for feature costs. Tan considers the domain where a robot needs to sense, recognize, and act, and the number of features is very large. For the robot to act efficiently, it needs to trade-off accuracy for efficiency.\nTurney (1995) builds a decision tree called ICET (standing for Inexpensive Classification with Expensive Tests) using a genetic search algorithm (Grefenstette, 1986) and using Núñez’s (1991) criteria to build C4.5 decision trees (Quinlan, 1993). Unlike Núñez, Turney takes misclassification costs into account (in addition to the feature costs) to evaluate a given decision tree and looks for a good decision tree using genetic search algorithms.\nYang et al. (2006) build cost-sensitive decision trees and Naive Bayes classifiers that take both feature costs and misclassification costs into account. Unlike Núñez (1991), who scores features based on information gain and cost ratio, Yang et al. score features based on expected reduction in the total cost (i.e., sum of the feature cost and the misclassification cost) on the training data. By doing so, they take feature costs and misclassification costs into account directly at learning time.\nBayer-Zubek (2004) formulates the feature acquisition problem as a Markov Decision Process and provides both greedy and systematic search algorithms to develop diagnostic policies. Bayer-Zubek takes both feature cost and misclassification costs into account and automatically finds an acquisition plan that balances the two costs. She introduces an admissible heuristic for AO* search and describes regularization techniques to reduce overfitting to the training data.\nSaar-Tsechansky, Melville, and Provost (2009) consider active feature acquisition for classifier induction. Specifically, they are given a training data with missing feature values, and a cost matrix that defines the cost of acquiring each feature value, they describe an incremental algorithm that can select the best feature to acquire iteratively to build a model that is expected to have high future performance. The utility of acquiring a feature is estimated in terms of expected performance improvement per unit cost. The two characteristics that make this work different from most of the previous work is that i) the authors do not assume a fixed budget a priori; rather they build the model incrementally, ii) each feature can have a different cost for each instance.\nFinally, Greiner, Grove, and Roth (2002) analyze the sample complexity of dynamic programming algorithms that performs value iteration to search for the best diagnostic policies. They analyze the problem of learning the optimal policy, using a variant of the probably-approximately-correct (PAC) model. They show that the learning can be achieved efficiently when the active classifier is allowed to perform only (at most) a constant number of tests and show that learning the optimal policy is often intractable in more general environments."
    }, {
      "heading" : "6. Future Work",
      "text" : "In this article, we have only scratched the surface of incorporating constraints between features in order to reduce the search space and make reasoning with sets tractable. We have discovered two types of constraints (features that render other features useless, and features that are useless without other features) purely from the underlying probability distribution. We have shown that these automatically discovered constraints helped reduce the search space dramatically. In practice, it is possible to discover additional types of constraints that can potentially be used reduce the search space further (for e.g., ordering constraints where certain procedures always precede other procedures). Constraints can also be defined based on observed feature values; for example, a treadmill test might not be performed for patients of old age. Patients can decline certain procedures and medications. Eliciting these constraints from the domain experts and utilizing them to further reduce the search space is a promising future direction.\nMost of the existing feature acquisition frameworks, including this one, are a major simplification of what happens in practice; we have assumed that acquiring the values of the features does not change the class value or values of other variables. However, in practice, feature value measurements can have “side-effects,” for example, in medical diagnosis while certain measurements are non-invasive and do not change the status of the patient, others might include medications that can affect the outcome. Similarly, in fault diagnosis and repair, the purpose is not only to diagnose but it is to repair the fault, so some actions can in fact repair the fault, in essence changing the class value. Taking these extra “side-effects” into account will make feature acquisition frameworks more realistic."
    }, {
      "heading" : "7. Conclusion",
      "text" : "The typical approach to feature acquisition has been greedy in the past primarily due to the sheer size of the possible subsets of features. We described a general technique that can optimally prune the search space by exploiting the conditional independence relationships between the features and the class variable. We empirically showed that exploiting the conditional independence relationships can substantially reduce the number of possible subsets. We also introduced a novel data structure called Value of Information Lattice (VOILA) that can both efficiently reduce the search space using the conditional independence relationships and also can share probabilistic inference computations between different subsets of features. By using VOILA, we were able to add a full look-ahead capability to the greedy acquisition policy, which would not be practical otherwise. We experimentally showed on five real-world medical datasets that the greedy strategy often stopped feature acquisition prematurely, performing worse than even a policy that acquires all the features."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank the reviewers for their helpful and constructive feedback. This material is based on work supported by the National Science Foundation under Grant No. 0746930."
    } ],
    "references" : [ {
      "title" : "Learning diagnostic policies from examples by systematic search",
      "author" : [ "V. Bayer-Zubek" ],
      "venue" : "In Annual Conference on Uncertainty in Artificial Intelligence",
      "citeRegEx" : "Bayer.Zubek,? \\Q2004\\E",
      "shortCiteRegEx" : "Bayer.Zubek",
      "year" : 2004
    }, {
      "title" : "VOILA: Efficient feature-value acquisition for classification",
      "author" : [ "M. Bilgic", "L. Getoor" ],
      "venue" : "In AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Bilgic and Getoor,? \\Q2007\\E",
      "shortCiteRegEx" : "Bilgic and Getoor",
      "year" : 2007
    }, {
      "title" : "Myopic value of information in influence diagrams",
      "author" : [ "S. Dittmer", "F. Jensen" ],
      "venue" : "In Annual Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Dittmer and Jensen,? \\Q1997\\E",
      "shortCiteRegEx" : "Dittmer and Jensen",
      "year" : 1997
    }, {
      "title" : "UCI machine learning repository",
      "author" : [ "A. Frank", "A. Asuncion" ],
      "venue" : null,
      "citeRegEx" : "Frank and Asuncion,? \\Q2010\\E",
      "shortCiteRegEx" : "Frank and Asuncion",
      "year" : 2010
    }, {
      "title" : "Selective evidence gathering for diagnostic belief networks",
      "author" : [ "L. Gaag", "M. Wessels" ],
      "venue" : "AISB Quarterly,",
      "citeRegEx" : "Gaag and Wessels,? \\Q1993\\E",
      "shortCiteRegEx" : "Gaag and Wessels",
      "year" : 1993
    }, {
      "title" : "Optimization of control parameters for genetic algorithms",
      "author" : [ "J. Grefenstette" ],
      "venue" : "IEEE Transactions on Systems, Man and Cybernetics,",
      "citeRegEx" : "Grefenstette,? \\Q1986\\E",
      "shortCiteRegEx" : "Grefenstette",
      "year" : 1986
    }, {
      "title" : "Learning cost-sensitive active classifiers",
      "author" : [ "R. Greiner", "A.J. Grove", "D. Roth" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Greiner et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Greiner et al\\.",
      "year" : 2002
    }, {
      "title" : "An approximate nonmyopic computation for value of information",
      "author" : [ "D. Heckerman", "E. Horvitz", "B. Middleton" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "Heckerman et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Heckerman et al\\.",
      "year" : 1993
    }, {
      "title" : "Readings on the Principles and Applications of Decision Analysis, chap. Influence Diagrams",
      "author" : [ "R.A. Howard", "J.E. Matheson" ],
      "venue" : null,
      "citeRegEx" : "Howard and Matheson,? \\Q1984\\E",
      "shortCiteRegEx" : "Howard and Matheson",
      "year" : 1984
    }, {
      "title" : "Information value theory",
      "author" : [ "R.A. Howard" ],
      "venue" : "IEEE Transactions on Systems Science and Cybernetics,",
      "citeRegEx" : "Howard,? \\Q1966\\E",
      "shortCiteRegEx" : "Howard",
      "year" : 1966
    }, {
      "title" : "Constructing optimal binary decision trees is NPComplete",
      "author" : [ "L. Hyafil", "R.L. Rivest" ],
      "venue" : "Information Processing Letters,",
      "citeRegEx" : "Hyafil and Rivest,? \\Q1976\\E",
      "shortCiteRegEx" : "Hyafil and Rivest",
      "year" : 1976
    }, {
      "title" : "On a measure of the information provided by an experiment",
      "author" : [ "D.V. Lindley" ],
      "venue" : "Annals of Mathematical Statistics,",
      "citeRegEx" : "Lindley,? \\Q1956\\E",
      "shortCiteRegEx" : "Lindley",
      "year" : 1956
    }, {
      "title" : "The use of background knowledge in decision tree induction",
      "author" : [ "M. Núñez" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Núñez,? \\Q1991\\E",
      "shortCiteRegEx" : "Núñez",
      "year" : 1991
    }, {
      "title" : "Schedule of benefits: Physician services under the health insurance act",
      "author" : [ "O.M. Health" ],
      "venue" : null,
      "citeRegEx" : "Health,? \\Q1992\\E",
      "shortCiteRegEx" : "Health",
      "year" : 1992
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems",
      "author" : [ "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "Pearl,? \\Q1988\\E",
      "shortCiteRegEx" : "Pearl",
      "year" : 1988
    }, {
      "title" : "Induction of decision trees",
      "author" : [ "J.R. Quinlan" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Quinlan,? \\Q1986\\E",
      "shortCiteRegEx" : "Quinlan",
      "year" : 1986
    }, {
      "title" : "C4.5: programs for machine learning",
      "author" : [ "J.R. Quinlan" ],
      "venue" : null,
      "citeRegEx" : "Quinlan,? \\Q1993\\E",
      "shortCiteRegEx" : "Quinlan",
      "year" : 1993
    }, {
      "title" : "Enhancing automated test selection in probabilistic networks",
      "author" : [ "D. Sent", "L.C. Gaag" ],
      "venue" : "In Proceedings of the 11th conference on Artificial Intelligence in Medicine,",
      "citeRegEx" : "Sent and Gaag,? \\Q2007\\E",
      "shortCiteRegEx" : "Sent and Gaag",
      "year" : 2007
    }, {
      "title" : "CSL: A cost-sensitive learning system for sensing and grasping objects",
      "author" : [ "M. Tan" ],
      "venue" : "In IEEE International Conference on Robotics and Automation",
      "citeRegEx" : "Tan,? \\Q1990\\E",
      "shortCiteRegEx" : "Tan",
      "year" : 1990
    }, {
      "title" : "Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm",
      "author" : [ "P.D. Turney" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Turney,? \\Q1995\\E",
      "shortCiteRegEx" : "Turney",
      "year" : 1995
    }, {
      "title" : "Test-cost sensitive classification on data with missing values",
      "author" : [ "Q. Yang", "C. Ling", "X. Chai", "R. Pan" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering,",
      "citeRegEx" : "Yang et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "Because devising the optimal policy is intractable in general, previous work has been greedy (Gaag & Wessels, 1993; Yang, Ling, Chai, & Pan, 2006), has approximated value of information calculations (Heckerman, Horvitz, & Middleton, 1993), and has developed heuristic feature scoring techniques (Núñez, 1991; Turney, 1995).",
      "startOffset" : 295,
      "endOffset" : 322
    }, {
      "referenceID" : 19,
      "context" : "Because devising the optimal policy is intractable in general, previous work has been greedy (Gaag & Wessels, 1993; Yang, Ling, Chai, & Pan, 2006), has approximated value of information calculations (Heckerman, Horvitz, & Middleton, 1993), and has developed heuristic feature scoring techniques (Núñez, 1991; Turney, 1995).",
      "startOffset" : 295,
      "endOffset" : 322
    }, {
      "referenceID" : 19,
      "context" : "• In addition to the feature acquisition costs defined by Turney (1995), we generate and experiment with synthetic feature costs.",
      "startOffset" : 58,
      "endOffset" : 72
    }, {
      "referenceID" : 18,
      "context" : ", Gaag & Wessels, 1993; Dittmer & Jensen, 1997) or have developed heuristic feature scoring techniques (e.g., Núñez, 1991; Tan, 1990).",
      "startOffset" : 103,
      "endOffset" : 133
    }, {
      "referenceID" : 9,
      "context" : "Note that, the last two terms are equivalent to the definition of expected value of information, EVI, (Howard, 1966):",
      "startOffset" : 102,
      "endOffset" : 116
    }, {
      "referenceID" : 14,
      "context" : "Given a Bayesian network over X and Y , it is straightforward to check irreducibility through d-separation (Pearl, 1988).",
      "startOffset" : 107,
      "endOffset" : 120
    }, {
      "referenceID" : 14,
      "context" : "For each dataset, we first learned a Bayesian Network that both provides the joint probability distribution P (Y,X) and efficiently answers conditional independence queries thorough d-separation (Pearl, 1988).",
      "startOffset" : 195,
      "endOffset" : 208
    }, {
      "referenceID" : 18,
      "context" : "We experimented with five real-world medical datasets that Turney (1995) described and used in his paper.",
      "startOffset" : 59,
      "endOffset" : 73
    }, {
      "referenceID" : 14,
      "context" : "The Market Blanket of Y in a Bayesian network is defined as Y ’s parents, children, and its children’s other parents (Pearl, 1988).",
      "startOffset" : 117,
      "endOffset" : 130
    }, {
      "referenceID" : 18,
      "context" : "The feature costs for each dataset are described in detail by Turney (1995). In summary, each feature can either have an independent cost, or can belong to a group of features, where the first feature in that group incurs an additional cost.",
      "startOffset" : 62,
      "endOffset" : 76
    }, {
      "referenceID" : 13,
      "context" : "The feature costs are based on the data from Ontario Ministry of Health (1992).",
      "startOffset" : 65,
      "endOffset" : 79
    }, {
      "referenceID" : 19,
      "context" : "The misclassification costs were not defined in the paper by Turney (1995). One reason could be that it is easier to define the feature costs, but defining the cost of a misclassification can be non-trivial.",
      "startOffset" : 61,
      "endOffset" : 75
    }, {
      "referenceID" : 9,
      "context" : "Decision theoretic value of information calculations provide a principled methodology for information gathering in general (Howard, 1966; Lindley, 1956).",
      "startOffset" : 123,
      "endOffset" : 152
    }, {
      "referenceID" : 11,
      "context" : "Decision theoretic value of information calculations provide a principled methodology for information gathering in general (Howard, 1966; Lindley, 1956).",
      "startOffset" : 123,
      "endOffset" : 152
    }, {
      "referenceID" : 4,
      "context" : "Gaag and Wessels (1993) consider the problem of “evidence” gathering for diagnosis using a Bayesian Network.",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 17,
      "context" : "In more recent work, Sent and Gaag (2007) consider the problem of acquiring more than a single feature at each step.",
      "startOffset" : 21,
      "endOffset" : 42
    }, {
      "referenceID" : 15,
      "context" : "Similarly, Tan (1990) modifies the ID3 algorithm (Quinlan, 1986) to account for feature costs.",
      "startOffset" : 49,
      "endOffset" : 64
    }, {
      "referenceID" : 5,
      "context" : "Turney (1995) builds a decision tree called ICET (standing for Inexpensive Classification with Expensive Tests) using a genetic search algorithm (Grefenstette, 1986) and using Núñez’s (1991) criteria to build C4.",
      "startOffset" : 145,
      "endOffset" : 165
    }, {
      "referenceID" : 16,
      "context" : "5 decision trees (Quinlan, 1993).",
      "startOffset" : 17,
      "endOffset" : 32
    }, {
      "referenceID" : 10,
      "context" : "Núñez (1991) introduces a decision tree algorithm called EG2 that is sensitive to the feature costs.",
      "startOffset" : 0,
      "endOffset" : 13
    }, {
      "referenceID" : 10,
      "context" : "Núñez (1991) introduces a decision tree algorithm called EG2 that is sensitive to the feature costs. Rather than splitting the decision tree at a feature that has high information gain, EG2 chooses a feature that has least “information cost function,” which is defined as the ratio of a feature’s cost to its discriminative efficiency. EG2 is, however, is not directly optimized to balance the misclassification cost and feature acquisition cost; rather it is optimized for 0/1 loss while taking the feature costs into account. Similarly, Tan (1990) modifies the ID3 algorithm (Quinlan, 1986) to account for feature costs.",
      "startOffset" : 0,
      "endOffset" : 550
    }, {
      "referenceID" : 10,
      "context" : "Núñez (1991) introduces a decision tree algorithm called EG2 that is sensitive to the feature costs. Rather than splitting the decision tree at a feature that has high information gain, EG2 chooses a feature that has least “information cost function,” which is defined as the ratio of a feature’s cost to its discriminative efficiency. EG2 is, however, is not directly optimized to balance the misclassification cost and feature acquisition cost; rather it is optimized for 0/1 loss while taking the feature costs into account. Similarly, Tan (1990) modifies the ID3 algorithm (Quinlan, 1986) to account for feature costs. Tan considers the domain where a robot needs to sense, recognize, and act, and the number of features is very large. For the robot to act efficiently, it needs to trade-off accuracy for efficiency. Turney (1995) builds a decision tree called ICET (standing for Inexpensive Classification with Expensive Tests) using a genetic search algorithm (Grefenstette, 1986) and using Núñez’s (1991) criteria to build C4.",
      "startOffset" : 0,
      "endOffset" : 835
    }, {
      "referenceID" : 4,
      "context" : "Turney (1995) builds a decision tree called ICET (standing for Inexpensive Classification with Expensive Tests) using a genetic search algorithm (Grefenstette, 1986) and using Núñez’s (1991) criteria to build C4.",
      "startOffset" : 146,
      "endOffset" : 191
    }, {
      "referenceID" : 4,
      "context" : "Turney (1995) builds a decision tree called ICET (standing for Inexpensive Classification with Expensive Tests) using a genetic search algorithm (Grefenstette, 1986) and using Núñez’s (1991) criteria to build C4.5 decision trees (Quinlan, 1993). Unlike Núñez, Turney takes misclassification costs into account (in addition to the feature costs) to evaluate a given decision tree and looks for a good decision tree using genetic search algorithms. Yang et al. (2006) build cost-sensitive decision trees and Naive Bayes classifiers that take both feature costs and misclassification costs into account.",
      "startOffset" : 146,
      "endOffset" : 466
    }, {
      "referenceID" : 4,
      "context" : "Turney (1995) builds a decision tree called ICET (standing for Inexpensive Classification with Expensive Tests) using a genetic search algorithm (Grefenstette, 1986) and using Núñez’s (1991) criteria to build C4.5 decision trees (Quinlan, 1993). Unlike Núñez, Turney takes misclassification costs into account (in addition to the feature costs) to evaluate a given decision tree and looks for a good decision tree using genetic search algorithms. Yang et al. (2006) build cost-sensitive decision trees and Naive Bayes classifiers that take both feature costs and misclassification costs into account. Unlike Núñez (1991), who scores features based on information gain and cost ratio, Yang et al.",
      "startOffset" : 146,
      "endOffset" : 621
    }, {
      "referenceID" : 0,
      "context" : "Bayer-Zubek (2004) formulates the feature acquisition problem as a Markov Decision Process and provides both greedy and systematic search algorithms to develop diagnostic policies.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 0,
      "context" : "Bayer-Zubek (2004) formulates the feature acquisition problem as a Markov Decision Process and provides both greedy and systematic search algorithms to develop diagnostic policies. Bayer-Zubek takes both feature cost and misclassification costs into account and automatically finds an acquisition plan that balances the two costs. She introduces an admissible heuristic for AO* search and describes regularization techniques to reduce overfitting to the training data. Saar-Tsechansky, Melville, and Provost (2009) consider active feature acquisition for classifier induction.",
      "startOffset" : 0,
      "endOffset" : 515
    }, {
      "referenceID" : 0,
      "context" : "Bayer-Zubek (2004) formulates the feature acquisition problem as a Markov Decision Process and provides both greedy and systematic search algorithms to develop diagnostic policies. Bayer-Zubek takes both feature cost and misclassification costs into account and automatically finds an acquisition plan that balances the two costs. She introduces an admissible heuristic for AO* search and describes regularization techniques to reduce overfitting to the training data. Saar-Tsechansky, Melville, and Provost (2009) consider active feature acquisition for classifier induction. Specifically, they are given a training data with missing feature values, and a cost matrix that defines the cost of acquiring each feature value, they describe an incremental algorithm that can select the best feature to acquire iteratively to build a model that is expected to have high future performance. The utility of acquiring a feature is estimated in terms of expected performance improvement per unit cost. The two characteristics that make this work different from most of the previous work is that i) the authors do not assume a fixed budget a priori; rather they build the model incrementally, ii) each feature can have a different cost for each instance. Finally, Greiner, Grove, and Roth (2002) analyze the sample complexity of dynamic programming algorithms that performs value iteration to search for the best diagnostic policies.",
      "startOffset" : 0,
      "endOffset" : 1287
    } ],
    "year" : 2011,
    "abstractText" : "We address the cost-sensitive feature acquisition problem, where misclassifying an instance is costly but the expected misclassification cost can be reduced by acquiring the values of the missing features. Because acquiring the features is costly as well, the objective is to acquire the right set of features so that the sum of the feature acquisition cost and misclassification cost is minimized. We describe the Value of Information Lattice (VOILA), an optimal and efficient feature subset acquisition framework. Unlike the common practice, which is to acquire features greedily, VOILA can reason with subsets of features. VOILA efficiently searches the space of possible feature subsets by discovering and exploiting conditional independence properties between the features and it reuses probabilistic inference computations to further speed up the process. Through empirical evaluation on five medical datasets, we show that the greedy strategy is often reluctant to acquire features, as it cannot forecast the benefit of acquiring multiple features in combination.",
    "creator" : "TeX"
  }
}