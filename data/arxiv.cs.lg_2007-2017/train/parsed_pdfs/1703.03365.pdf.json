{
  "name" : "1703.03365.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Learning Active Learning from Real and Synthetic Data",
    "authors" : [ "Ksenia Konyushkova", "Raphael Sznitman", "Pascal Fua" ],
    "emails" : [ "KSENIA.KONYUSHKOVA@EPFL.CH", "RAPHAEL.SZNITMAN@ARTORG.UNIBE.CH", "PASCAL.FUA@EPFL.CH" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Many modern machine learning techniques require large amounts of training data to reach their full potential. However, annotated data is hard and expensive to obtain, especially in specialized domains where only experts whose time is scarce and precious can provide reliable annotations. Active learning (AL) is an established way to ease the data collection process by automatically deciding which instances an annotator should label to train an algorithm as quickly as possible and with the minimal amount of annotation effort.\nOver the years many AL strategies have been developed for various tasks, without any one of them clearly outperforming all others in all cases. Consequently, a number\nof approaches have been proposed to automatically select the best strategy. Recent examples include bandit algorithms (Baram et al., 2004; Hsu & Lin, 2015), aggregating strategies whose experience can be transferred between domains (Chu & Lin, 2016), and approaches based on Reinforcement Learning (Ebert et al., 2012).\nA common limitation of all these approaches is that they cannot go beyond combining pre-existing, often handdesigned or computationally expensive, heuristics. In this paper, we propose to go further by allowing our method to discover the right strategies while being trained to discern effective AL approaches. In other words, our approach Learns Active Learning (LAL) and automatically comes up with task-appropriate query selection strategies.\nMore specifically, we formulate LAL as a regression problem. Given a trained classifier and its output for a specific sample with unknown label, we predict the reduction in generalization error that can be expected by adding the label to that point. In practice, we show that we can train such a regression function on synthetic data and generalize to the real data by taking features to be simple statistics, such as the variance of the classifier output or predicted probability distribution over possible labels for a specific datapoint. Furthermore, if one can provide a slightly larger initial set of annotated data, the regressor can be trained on it to help further extend the annotated set for very different classification tasks. We show that LAL works well on real data from several different domains such as biomedical imaging, economics, molecular biology, and high energy physics. It outperforms other methods without requiring hand-crafted heuristics."
    }, {
      "heading" : "2. Related Work",
      "text" : "The last decade has produced many different AL strategies. They include uncertainty sampling (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015),\nar X\niv :1\n70 3.\n03 36\n5v 1\n[ cs\n.L G\n] 9\nM ar\nquery-by-committee (Gilad-bachrach et al., 2005; Iglesias et al., 2011), expected model change (Settles, 2010; Sznitman & Jedynak, 2010; Vezhnevets et al., 2012), expected error (Joshi et al., 2012), and variance (Hoi et al., 2006) minimization, Bayesian AL (Houlsby et al., 2011). Among these, uncertainty sampling is both one of the simplest and one of the most popular. The intuition behind it is very natural as it proposes users to first label samples that are the most uncertain, that is, closest the classifier’s current decision boundary. This strategy and most of the methods mentioned above work very well in cases such as the ones of Figs. 1, 2 but often fail in the more difficult one of Fig. 4. While both examples are synthetic, analogous situations arise regularly in real data (Baram et al., 2004).\nIn general there are two main types of AL strategies: theoretically motivated approaches that are not always tractable in real applications (e.g. expected reduction in error, information theoretic approaches) and approaches that demonstrated empirical increase in performance but whose convergence is not well understood. Among AL methods designed to handle complex real-world situations, some cater to specific classifiers, such as those that rely on Gaussian Processes (Kapoor et al., 2007), and applications, such as natural language processing (Tong & Koller, 2002; Olsson, 2009), sequence labeling tasks (Settles & Craven, 2008), visual recognition (Luo et al., 2004; Long et al., 2015), semantic segmentation (Vezhnevets et al., 2012), foreground-background segmentation (Konyushkova et al., 2015), image delineation (Mosinska et al., 2016), and preference learning (Singla et al., 2016). However, there is no one algorithm that outperforms all others for all tasks and datasets (Settles & Craven, 2008). Moreover, various querying strategies aim to maximize different performance metrics as evidenced in the case of multi-class classification (Settles, 2010).\nAs a result, meta learning algorithms have been gaining in popularity in recent years (Tamar et al., 2016), but they are rarely designed to deal with AL scenarios. The few existing approaches tackle the problem by combining AL strategies. Baram et al. (2004) combine several known heuristics during the AL execution with the help of a bandit algorithm. This is made possible by the use of the maximum entropy criterion, which estimates the classification performance without labels during AL. Hsu & Lin (2015) extend this line of work but move the focus from datasamples as arms to heuristics as arms in the bandit process and use a new unbiased estimator of the test error, which enables it to outperform the previous method. Chu & Lin (2016) go further and suggest transferring the bandit-learnt combination of AL heuristics between different tasks. Another view on the problem is presented in Ebert et al. (2012), where they balance exploration and exploitation with a Markov decision process.\nThe common limitation of these approaches is that they do not go beyond combining already existing approaches and are not designed to automatically propose new heuristics, as LAL does."
    }, {
      "heading" : "3. Towards Data Driven Active Learning",
      "text" : "In this section we briefly introduce the standard Active Leaning (AL) framework along with uncertainty sampling (US), the most frequently-used heuristic to implement it (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015). Despite its simplicity, US often works remarkably well in practice. However, we will show that it displays an optimal behavior only in a limited number of situations and by this we will motivate the fact that one cannot rely on a single heuristic, no matter how good."
    }, {
      "heading" : "3.1. Active Learning (AL)",
      "text" : "While the generic machine learning task is to find the best statistical model given training data, the task of AL is to select which data should be annotated in order to learn the model as quickly as possible. In practice, this means that instead of asking experts to annotate all the available data, we select iteratively which datapoints should be annotated next. The goal is to reach the a comparable accuracy level faster.\nSuppose we are interested in classifying datapoints from a target dataset D̃ = {(x1, y1), . . . , (xN , yN )}, where xi is a d-dimensional feature representation of a datapoint and yi ∈ {0, 1} is its binary label. We choose a classifier f that can be trained on some Lt ⊂ D̃ to map features to labels fLt(xi) = ŷi through the predicted probability p(yi = y | Lt, xi). The standard AL procedure unfolds as follows.\n1. It starts with a small labeled training dataset Lt ⊂ D̃ with t = 0.\n2. A classifier fLt is trained using Lt.\n3. fLt is applied to the remainder of the data Ut for which annotations are unavailable.\n4. A query selection procedure picks an instance x∗ ∈ Ut to be annotated at the next iteration. Usually, x∗ maximizes a heuristic criterion based on the datasets Lt and Ut, along with the predictions of the current classifier p(yi = y | Lt, xi) for unlabeled samples xi ∈ Ut.\n5. x∗ is given a label y∗ by an expert, or an oracle in synthetic examples. We then take the new labeled set Lt+1 to be Lt∪ (x∗, y∗) and the new sets of unlabeled samples to be Ut+1 = Ut \\ x∗.\n6. Increment t, go back to step 2 and iterate until the desired accuracy is achieved or the number of iterations has reached a predefined limit."
    }, {
      "heading" : "3.2. Uncertainty Sampling",
      "text" : "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016). As discussed in Section 2, it is based on selecting first samples about which the current classifier is least certain. There are many definitions of maximum uncertainty but one of the most widely accepted is to select samples that maximize the entropy H over predicted classes. In other words, this means taking x∗ to be\narg max xi∈Ut\nH[p(yi = y | xi,Lt)] . (1)"
    }, {
      "heading" : "3.3. Success, Failure, and Motivation",
      "text" : "We now motivate our approach by presenting two toy examples, one in which US is empirically observed to be the optimal (greedy) solution and another one, where it makes suboptimal decisions. To this, let us consider a simple two-dimensional dataset D̃ that consists of two clouds of datapoints corresponding to two different classes: D̃ = {(xi, yi)}, where xi ∈ R2 and each class contains equal number of points, as shown in Fig. 1(a). The data in each cloud comes from a Gaussian distribution with a different mean but the same variance.\nLet us further assume that a dataset D̃′ from the same distribution is available for testing. We can initialize the AL procedure of Section 3.1 given one sample from each class and their respective labels L0 = {(x1, 0), (x2, 1)}. U0 comprises the remaining data points. We start with a simple logistic regression classifier f on L0 and then test it on D̃′. If D̃′ is big, the error on it can be considered as a good approximation to the generalization error. The loss of fL0 on D̃′ is `0 = ∑ (x′i,y ′ i)∈D̃′ `(ŷi, y ′ i), where ŷi = fL0(x ′ i). In this example we will consider simple 0/1 loss.\nConsider the US strategy that selects sample x∗ according to Eq. 1. In this case it would be a datapoint with probability of class 0 close to 0.5. Let us try to label every point x from U0 one by one, form a new labeled set Lx = L0 ∪ (x, y) and check what error a new classifier fLx yields on D̃′, that is, `x = ∑ (x′i,y ′ i)∈D̃′ (ŷi, y ′ i), where ŷi = fLx(x ′ i). The difference between errors obtained with classifiers constructed on L0 and Lx indicates how much the addition of a new datapoint x reduces the generalization error δ`(x,L0) = `0 − `x.\nWe repeat this experiment 10000 times and plot the mean (blue) and variance (red) of δ`(x,L0) in Fig. 1(c). The\npoints with pi closest to 0.5, the one that US picks, is indeed close to being the one that yields the greatest error reduction.\nNext, we repeat the above experiment, but with one class (y = 0) containing twice as many datapoints as the other (y = 1), as shown in Fig. 1(b). As before, we plot the average error reduction as a function of pi in Fig. 1(d). However, this time the values of pi that correspond to the largest expected error reduction are further from 0.5 than before and US becomes suboptimal. And the more unbalanced the two classes are, the more serious the bias becomes. In more complex and more realistic cases, there are many other factors such as label noise, outliers or shape of distribution that can further compound the problem,\nThis is why many query selection procedures take into account statistical properties of the datasets and classifier. However, there is no simple way to foresee the influence of all possible factors. Thus, in this paper, we suggest Learning Active Learning (LAL) by taking many factors into account to predict the potential error reduction. By treating the query selection module as a regressor we do not restrict ourselves to pre-existing AL heuristics but can construct new ones. This approach can be customized for any type of classifier and dataset. For instance, in the example of Section 3.3 we expect LAL to automatically adapt pi to the relative prevalence of the two classes without having to explicitly state such a rule. We will see in the results section that this is indeed one of the many thing that LAL can handle, even in much more complex real-world cases.\nAnother AL scenario where learning AL strategy from data is useful is warm start. It is largely overlooked in the literature but has a significant practical interest, especially in highly specialized domains as we consider. We assume that\nin order to understand if the machine learning based approach is possible in an application, some sufficient dataset D0 is made available prior to AL. However, further classification improvement can be very annotation costly. In this situation we can benefit from the available training dataD0 to learn a specialized LAL strategy."
    }, {
      "heading" : "4. Approach",
      "text" : "We now formulate LAL as a regression problem. We model the dependency between the state of the learning and the expected greedy improvement of the generalization error. To this end, given a representative dataset with ground truth available, we simulate an online learning procedure using a Monte-Carlo style approach. We further extend the approach to account for selection bias caused by AL.\nMore specifically, we split the dataset into training D and testing D′ data and use a small subset of labels from D to train an initial classifier, which performance is tested on D′. A number of parameters φ that characterizes the state of the classifier is evaluated. We then incorporate unused labels from D individually to retrain the classifier. This lets us correlate the increase in classification performance δ, or lack thereof, with the previously computed classifier parameters φ and parameters ψ of the newly added datapoint. We then repeat this process for different initializations, sizes of labeled subset, and initially selected samples. The iterative LAL strategy accounts for the bias introduce by AL into the training data and yields the best results as it will be shown in Sec. 6. We formalize this process in the remainder of the section."
    }, {
      "heading" : "4.1. Monte-Carlo LAL",
      "text" : "Let the representative dataset discussed above be split into a training D = {(xi, yi)} and a testing set D′ = {(x′i, y′i)} with xi ∈ Rd and yi ∈ {0, 1}. Let f be a classifier with a given training procedure.\nWe start the LAL Monte-Carlo procedure by splitting D into a labeled set Lτ of size τ and an unlabeled set Uτ containing the remaining points. We then train a classifier f on Lτ , resulting in a function fLτ that we use to predict class labels for elements x′ of the testing set D′ and estimate the test classification loss `τ . We further characterize the classifier state by recording k parameters φ1(Lτ ), . . . , φk(Lτ ), which are specific to particular classifier families and change as the training progresses. For example, they can be the parameters of the kernel function if f is kernel-based, average depths of the trees if f is a random forest, or prediction variability if f is an ensemble classifier.\nNext, we randomly select a new datapoint x from Uτ to form a new labeled set Lτ+1 = Lτ ∪ x and retrain.\nWe characterize the effect of a datapoint on the state of learning by instantiating r parameters ψ1(x), . . . , ψr(x). For example, they can include the predicted probability of class y, the distance to the closest point in the dataset or the distance to the closest labeled point. The new classifier fLτ+1 results in the test-set loss `τ+1. Finally, we record the difference between previous and new loss δ`(Lτ , x) = `τ − `τ+1. In the end, δ`(Lτ , x) is associated to the learning state in which it was received. The learning state is characterized by a vector ξ(Lτ , x) =[ φ1(Lτ ) . . . φk(Lτ ) ψ1(x) . . . ψr(x) ] , whose elements depend both on the state of the current classifier and on the datapoint, φ and ψ, respectively.\nNext, we repeat the whole sampling procedure for Q different initializations L1τ ,L2τ , . . . ,LQτ and T various labeled subset sizes τ = 2, . . . , T + 2. For each initialization q and iteration τ we sample M different datapoints xqτm each of which yields classifier/datapoint state pairs along with the reduction in error associated to them. This results in Q×M ×T MONTECARLOLAL observations ξqτm of dimensionality k + r that can be represented as a matrix Ξ whose lines are feature vectors: φ1(L12) . . . φk(L12) ψ1(x121 ) . . . ψr(x121 ) φ1(L12) . . . φk(L12) ψ1(x122 ) . . . ψr(x122 ) ... . . . ... ... . . . ... φ1(Lqτ ) . . . φk(Lqτ ) ψ1(xqτm ) . . . ψr(xqτm ) ... . . . ... ... . . .\n... φ1(LQT ) . . . φk(L Q T ) ψ1(x QT M ) . . . ψr(x QT M )  and associated vector ∆ of labels δ`(Lqτ , xmqτ ). Alg. 1 summarizes the steps of LAL data generation for a fixed τ and a given classifier f .\nOur next insight is that these observations lie on a smooth manifold and that similar states of the classifier correspond to similar behaviors when annotating similar samples. We thus formulate the task of predicting the potential error reduction of annotating a specific sample in a given the classifier state as a regression problem. We look for a mapping\ng : ξ(L, x)→ δ`(L, x). (2) Then MONTECARLOLAL strategy selects a datapoint with the highest error reduction potential at iteration t:\nx∗ = arg max xi∈Ut\ng( [ φ1(Lt) . . . ψr(xi) ] ). (3)\nNote that MONTECARLOLAL does not depend explicitly on the representative datasetD, but only on the chosen classifier and the choice of parameters φ and ψ. Therefore, it can be used to select samples that promise the greatest increase in classifier performance in domains D̃ other than the one we use to learn the strategy. Alg. 2 summarizes the MONTECARLOLAL learning procedure.\nAlgorithm 1 LALGENDATA Input: training dataset D, test dataset D′, classification procedure f , partitioning function SPLIT, size τ Initialize: Lτ , Uτ ← SPLIT(D, τ ) train a classifier fLτ estimate the test set loss `τ compute the classification state parameters φ ← φ1(Lτ ), . . . , φk(Lτ ) for m = 1 to M do\nselect xm ∈ Uτ form a new labeled dataset Lτ+1 ← Lτ ∪ xm compute the datapoint parameters ψ ← ψ1(xm), . . . , ψr(xm) train a classifier fLτ+1 estimate the new test loss `τ+1 compute the loss reduction δ`(Lτ , xm)← `τ − `τ+1 ξm ← {φ, ψ}\nend for Ξ← {ξm} Return: matrix of learning states Ξ ∈ RM×(k+r), vector of reductions in error ∆ ∈ RM×1\nAlgorithm 2 MONTECARLOLAL Input: iteration range {τmin, . . . , τmax}, classification procedure f SPLIT← random partitioning function Initialize: generate train set D and test dataset D′ for τ in {τmin, . . . τmax} do\nΞτ ,∆τ ← LALGENDATA (D,D′, f, SPLIT, τ ) end for Ξ,∆← {Ξτ}, {∆τ} train a regressor g : ξ(L, x)→ δ`(x,L) on data Ξ,∆ construct AL strategy A(g): x∗ = arg maxxi∈Ut g[ξ(Lt, xi)] Return: active learning strategy A(g)"
    }, {
      "heading" : "4.2. Iterative LAL",
      "text" : "MONTECARLOLAL strategy of Alg. 2 makes an implicit over-simplification in the way the dataset D is split into a labeled set Lτ and unlabeled set Uτ : No matter how many labeled samples τ are available, the labeled subset Lτ consists of randomly chosen samples. However, when MONTECARLOLAL is applied at iteration t of AL, the labeled set Lt is constructed of samples selected by it at previous iterations, which is therefore not random.\nTo account for this, we modify the approach of Section 4.1 as follows. We learn a different AL strategy Aτ at every iteration τ . Aτ tells us which datapoint should be selected at iteration t = τ − 2 of AL. When we execute iteration τ , we simulate AL procedure that start with 2 labeled samples and applies strategyA2, . . . ,Aτ to select 3, . . . , (τ + 1)-th\nAlgorithm 3 ITERATIVELAL Input: iteration range {τmin, . . . τmax}, classification procedure f SPLIT← random partitioning function Initialize: generate train set D and test dataset D′ for τ in {τmin, . . . , τmax} do\nΞτ ,∆τ ← LALGENDATA (D,D′, f, SPLIT, τ ) train a regressor gτ : ξ(L, x)→ δ`(x,L) on Ξτ ,∆τ SPLIT←A(gτ )\nend for Ξ,∆← {Ξτ ,∆τ} train a regressor g : ξ(L, x)→ δ`(x,L) on Ξ,∆ Return: active learning strategy A(g)\ndatapoints. In this way, samples at iteration τ + 1 depend on the samples at iteration τ and the sampling bias of AL is well represented in data Ξ,∆ from which the final strategy is leant. Alg. 3 depicts the final procedure."
    }, {
      "heading" : "5. LAL Strategies Implementation",
      "text" : "In this section we provide details about how we build the dataset Ξ,∆ to learn LAL strategies MONTECARLOLAL and ITERATIVELAL and select relevant features to instantiate the regression problem. We discuss the choice of classifier and regressor and provide values for key parameters for LAL procedure.\nRepresentative data for training LAL. Recall from Section 4.1 that we learn the mapping g of Eq. 2 from Ξ,∆ that was obtained from an example dataD that can be completely unrelated to the one on which we will do the AL D̃. Since the easiest way to obtain an example dataset is to synthesize it, we did this first and, as will be shown in the Results section, it turned out to be surprisingly effective.\nIn practice, we generate example 2-D datasets such as the ones depicted by Fig. 2 (a,b,c), where the 2 classes have Gaussian distributions with random means and variances and appear in various proportions. In our experiments, we set the size of training and test dataset to 400 and 4000 respectively and the imbalance between classes varies from 0.1 to 0.9. Each mean is drawn independently from a uniform distribution from 0 to 1 and the covariance is obtained by multiplying matrices whose entries are drawn uniformly between −0.5 and 0.5 with their transposes. We use 0/1 loss through LAL data generation.\nIn warm start experiments, we used a small (N0 << N ) subset of data of the domain for AL, on which we learn A(g) and initial AL classifier fL0 . We split them into training and test subsets and ran the LAL procedures as described in Sec. 4.1 and Sec. 4.2.\nChoice of classifier and regressor. We use Random Forest (RF) and Gaussian Process (GP) classifiers for f and RF and GP regressors for g in the corresponding experiments. Due to the dimensionality of real datasets, GP was only used in experiment with simulated data TwoGaussian-clouds.\nClassifier features. The vector ξ that characterize the state of the learning process is composed of the following features: a) predicted probability: p(yi = 0|Dt, xi) b) proportion of class 0 in Dt c) out-of-bag cross-validated accuracy of fDt d) variance of feature importances of fDt e) forest variance computed as variance of trees’ predictions on Ut f) average tree depth of the forest g) size of Lt.\nOnce the data Ξ,∆ was collected and regression solved, we can plot which features have the highest relative importance (Fig. 2 (d)).\nIn GP case we use a) predicted probability p(yi = 0|Dt, xi) b) predicted variance by GP c) variance and d) lengthscale of RBF kernel e) kernel density estimation for xi with respect to labeled and f) unlabeles samples g) size of Lt.\nParameters used to construct LAL. The LAL data generation parameters are set to the following values: M = 50, T = 48, Q = 500. Moreover, for every new initialization we use a new representative dataset from model of Fig. 2 (a-c) that insures that the learnt strategy can generalize to various problems."
    }, {
      "heading" : "6. Experiments",
      "text" : "We now compare the performance of LAL against several baselines both on synthetic and real data."
    }, {
      "heading" : "6.1. Baselines and Protocol",
      "text" : "We compare the following three versions of our approach:\n• LAL-MC-2D. LAL strategy learned as discussed in Sec. 4.1 where D is synthetic 2D dataset of Sec. 5. • LAL-iterative-2D. Similar to LAL-MC-2D but learnt according to Sec. 4.2. • LAL-MC-WS: Similar to LAL-MC-2D but D is a subset of the data D̃ on which AL is performed.\nagainst the following baselines:\n• Rs: random sampling. • Us: uncertainty sampling according to Sec. 3.2. • Kapoor: approach of Kapoor et al. (2007) that bal-\nances exploration against exploitation by incorporating mean and variance estimation of the GP classifier.\nIn our experiments we chose Us as our primary baseline because our approach makes use of the same information – predicted probability distribution over classes – as the datapoint features ψ. To compare against Kapoor, we included variance into ψ for a fair comparison.\nIn AL experiments we then select samples to be labeled from the training set and report the classification performance on the test set. When using LAL-MC-2D and LALiterative-2D, we begin with one sample from each of two classed to initialize AL. We will refer to this setting as a cold start. In LAL-MC-WS strategy we start with a larger training set, which we will refer to as a warm start.\nThen, we perform from 100 to 1800 AL iterations depending on the dataset size and the task complexity and repeat\neach experiment 50 − 100 times. In the figures below, we plot average classification quality as a function of the number of samples having been annotated.\nThe performance metrics we use are task-specific, they include classification accuracy, VOC score (Everingham et al., 2010), dice score (Gordillo et al., 2013), AMS score (Adam-Bourdarios et al., 2014) and area under ROC curve."
    }, {
      "heading" : "6.2. Synthetic Data",
      "text" : "We first demonstrate the performance of AL approach on the synthetic data generated using the model of Sec. 5, but previously unseen. Next we test our approach on the notoriously hard XOR-like datasets.\nTwo-Gaussian-clouds experiment. We generate 1000 new unseen datasets of the type depicted in Fig. 2 and test AL with GP and RF classifiers. Fig. 3 depicts the average test accuracy as a function of a number of labeled samples.\nIn case of both classifiers the proposed strategy is able to select datapoints that help to construct better classifiers\nquicker than Us heuristics. This experiment demonstrates that the LAL approach is robust to the type of chosen classifier f and parameters φ and ψ. Even in this simple task, when we are very close to the optimal performance, we can make better decisions by taking the learning state into account.\nXOR-like experiment XOR-like datasets are wellknown to be challenging for most machine learning techniques and AL is not an exception. Some works (Baram et al., 2004) report that various AL algorithms struggle with the type of tasks that is depicted in Fig. 4 (a), (b), (c). The reason for this is intuitively clear: any AL strategy relies on the prediction made by a classifier trained on available data. The prediction based on limited data is very distant from the ground truth in this case. When we have only two labeled instances in data like in Fig. 4 (a), at least two out of four groups of data are not represented in the training set at all. The classifier fL2 will guide further selection to refine the initial boundary and completely overlook the other two groups of datapoints. The task for AL becomes even more challenging when the XOR structure resembles a checkerboard as depicted in Fig. 4 (b). In the limiting case like this\nwe cannot expect to get better quality of prediction faster than with random sampling. Another XOR-like dataset that has more natural shape is the banana dataset from Rätsch et al. (2001). Note that these datasets do not resemble in the least the data used to train LAL, as can be seen by comparing Figs.2 and 4).\nFigs. 4(d), (e), (f) show the average performance of AL strategies for the classification tasks depicted by Figs. 4 (a), (b), (c). As expected, Us looses to Rs. Nevertheless, LALiterative-2D adapts its selection strategy to perform better or at least comparably to Rs for AL even under such adversarial conditions. In other words, even though LAL has never seen an XOR-like dataset during its training, it still performs well by adapting its selection strategy on the basis of the statistics of the samples it encounters."
    }, {
      "heading" : "6.3. Real Data",
      "text" : "We now turn to real data from the domains where annotating is hard because it requires special training and education. Note that all the datasets are of a very different nature that means that their feature distributions have nothing to do with the syntactic example of Sec. 5.\n• Striatum: 3D Electron Microscopy stack of rat neural tissue from striatum. The task is to detect and segment mitochondria in it (Lucchi et al., 2012; Konyushkova et al., 2015).\n• MRI: brain scans with MRI are obtained from BRATS competition (Menza et al., 2014). The task is to segment brain tumor in T1, T2, FLAIR, and postGadolinium T1 MR images.\n• Credit card: The task is to detect credit card fraud transactions in transaction made by European cardholders in September 2013 (Dal Pozzolo et al., 2015).\n• Splice: In this dataset from the domain of molecular biology, our task is to detect splice junctions in DNA sequences (Lorena et al., 2002).\n• Higgs: This dataset from the domain of high energy physics contains the data that simulates the ATLAS experiment (Adam-Bourdarios et al., 2014).\nCold Start AL. We start with a standard setup to benchmark AL algorithms. Fig. 5 depicts the results of applying Rs, Us, LAL-MC-2D, and LAL-iterative-2D in three datasets Striatum, MRI, Credit card. Recall that the LAL strategies still all rely on the same regressor learned from 2D synthetic data and have not been fine-tuned for the specific problems at hand.\nBoth LAL strategies outperform Us, with LAL-iterative2D being the best of the two. Considering that the LAL regressor was learned using a simple 2D synthetic dataset, it is in fact somewhat surprising that it can deal with much more complex and unrelated datasets. This is something we intend to investigate further.\nWarm Start AL. We now turn to a more realistic scenario where a larger dataset is available to train the initial classifier before beginning AL, as discussed in Section 3. We can take advantage of the larger initial training set to learn an AL strategy that is tailored for the problem at hand. This is valuable for applications where task or feature distribution is so different from synthetic data that AL strategy cannot be transfered, for example, for tasks where feature distributions contain missing or categorical variables. We tested LAL-MC-WS approach on the Splice and Higgs datasets by starting with 100 and 200 randomly selected datapoints. Fig. 6 demonstrates the learning curve for Us and for LAL. For Splice dataset we report accuracy and AUC and for Higgs dataset we report AMS score and AUC. We conclude that LAL approach is indeed useful in this problem settings."
    }, {
      "heading" : "7. Conclusion",
      "text" : "In this paper we introduced a new approach to AL that is driven by data – Learning Active Learning. We found out that a LAL that was exposed to AL experiments on simple 2D data can sometimes generalize surprisingly well to challenging new domains. The ability to learn LAL from a subset of data of interest allows to further extend applicability of our approach. LAL demonstrated robustness to the choice of type of classifier and features.\nIn future work we would like to incorporate more features into LAL that will allow to compare it to various exploration/exploitation strategies. Furthermore we would like to address issues of multi-class classification and batchmode AL."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We would like to thank Carlos Becker, Helge Rhodin and Lucas Maystre for their discussions and comments on the text."
    } ],
    "references" : [ {
      "title" : "The higgs boson machine learning challenge",
      "author" : [ "Adam-Bourdarios", "Claire", "Cowan", "Glen", "Germain", "Cécile", "Guyon", "Isabelle", "Kégl", "Balázs", "Rousseau", "David" ],
      "venue" : "In NIPS 2014 Workshop on High-energy Physics and Machine Learning,",
      "citeRegEx" : "Adam.Bourdarios et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Adam.Bourdarios et al\\.",
      "year" : 2014
    }, {
      "title" : "Online Choice of Active Learning Algorithms",
      "author" : [ "Baram", "Yoram", "El-Yaniv", "Ran", "K. Luz", "Kobi" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Baram et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Baram et al\\.",
      "year" : 2004
    }, {
      "title" : "Can active learning experience be transferred? 2016",
      "author" : [ "Chu", "Hong-Min", "Lin", "Hsuan-Tien" ],
      "venue" : "URL http: //arxiv.org/abs/1608.00667",
      "citeRegEx" : "Chu et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Chu et al\\.",
      "year" : 2016
    }, {
      "title" : "Calibrating probability with undersampling for unbalanced classification",
      "author" : [ "Dal Pozzolo", "Andrea", "Caelen", "Olivier", "Johnson", "Reid A", "Bontempi", "Gianluca" ],
      "venue" : "In Computational Intelligence,",
      "citeRegEx" : "Pozzolo et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Pozzolo et al\\.",
      "year" : 2015
    }, {
      "title" : "RALF: A Reinforced Active Learning Formulation for Object Class Recognition",
      "author" : [ "S. Ebert", "M. Fritz", "B. Schiele" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "Ebert et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Ebert et al\\.",
      "year" : 2012
    }, {
      "title" : "Query by Committee Made Real",
      "author" : [ "R. Gilad-bachrach", "A. Navot", "N. Tishby" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Gilad.bachrach et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Gilad.bachrach et al\\.",
      "year" : 2005
    }, {
      "title" : "State of the Art Survey on MRI Brain Tumor Segmentation",
      "author" : [ "N. Gordillo", "E. Montseny", "P. Sobrevilla" ],
      "venue" : "Magnetic Resonance in Medicine,",
      "citeRegEx" : "Gordillo et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Gordillo et al\\.",
      "year" : 2013
    }, {
      "title" : "Batch Mode Active Learning and Its Application to Medical Image Classification",
      "author" : [ "S.C. Hoi", "R. Jin", "J. Zhu", "M.R. Lyu" ],
      "venue" : "In International Conference on Machine Learning,",
      "citeRegEx" : "Hoi et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hoi et al\\.",
      "year" : 2006
    }, {
      "title" : "Bayesian active learning for classification and preference",
      "author" : [ "Houlsby", "Neil", "Huszár", "Ferenc", "Ghahramani", "Zoubin", "Lengyel", "Máté" ],
      "venue" : "learning. stat,",
      "citeRegEx" : "Houlsby et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Houlsby et al\\.",
      "year" : 2011
    }, {
      "title" : "Active learning by learning",
      "author" : [ "Hsu", "Wei-Ning", "Lin", "Hsuan-Tien" ],
      "venue" : "AAAI, pp. 2659–2665,",
      "citeRegEx" : "Hsu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2015
    }, {
      "title" : "Combining Generative and Discriminative Models for Semantic Segmentation",
      "author" : [ "J.E. Iglesias", "E. Konukoglu", "A. Montillo", "Z. Tu", "A. Criminisi" ],
      "venue" : "In Information Processing in Medical Imaging,",
      "citeRegEx" : "Iglesias et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Iglesias et al\\.",
      "year" : 2011
    }, {
      "title" : "Scalable Active Learning for Multiclass Image Classification",
      "author" : [ "A.J. Joshi", "F. Porikli", "N.P. Papanikolopoulos" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "Joshi et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Joshi et al\\.",
      "year" : 2012
    }, {
      "title" : "MultiClass Active Learning for Image Classification",
      "author" : [ "A.J. Joshi", "F. Porikli", "N. Papanikolopoulos" ],
      "venue" : "In Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Joshi et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Joshi et al\\.",
      "year" : 2009
    }, {
      "title" : "Active Learning with Gaussian Processes for Object Categorization",
      "author" : [ "A. Kapoor", "K. Grauman", "R. Urtasun", "T. Darrell" ],
      "venue" : "In International Conference on Computer Vision,",
      "citeRegEx" : "Kapoor et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Kapoor et al\\.",
      "year" : 2007
    }, {
      "title" : "Introducing Geometry into Active Learning for Image Segmentation",
      "author" : [ "K. Konyushkova", "R. Sznitman", "P. Fua" ],
      "venue" : "In International Conference on Computer Vision,",
      "citeRegEx" : "Konyushkova et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Konyushkova et al\\.",
      "year" : 2015
    }, {
      "title" : "Fully Convolutional Networks for Semantic Segmentation",
      "author" : [ "J. Long", "E. Shelhamer", "T. Darrell" ],
      "venue" : "In Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Long et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Long et al\\.",
      "year" : 2015
    }, {
      "title" : "Splice junction recognition using machine learning techniques",
      "author" : [ "Lorena", "Ana Carolina", "Batista", "Gustavo EAPA", "de Carvalho", "André Carlos Ponce Leon Ferreira", "Monard", "Maria Carolina" ],
      "venue" : "In WOB, pp",
      "citeRegEx" : "Lorena et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Lorena et al\\.",
      "year" : 2002
    }, {
      "title" : "Structured Image Segmentation Using Kernelized Features",
      "author" : [ "A. Lucchi", "Y. Li", "K. Smith", "P. Fua" ],
      "venue" : "In European Conference on Computer Vision,",
      "citeRegEx" : "Lucchi et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Lucchi et al\\.",
      "year" : 2012
    }, {
      "title" : "Active Learning to Recognize Multiple Types of Plankton",
      "author" : [ "T. Luo", "K. Kramer", "S. Samson", "A. Remsen", "D.B. Goldgof", "L.O. Hall", "T. Hopkins" ],
      "venue" : "In International Conference on Pattern Recognition,",
      "citeRegEx" : "Luo et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Luo et al\\.",
      "year" : 2004
    }, {
      "title" : "The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)",
      "author" : [ "B. Menza", "A Jacas" ],
      "venue" : "IEEE Transactions on Medical Imaging,",
      "citeRegEx" : "Menza and Jacas,? \\Q2014\\E",
      "shortCiteRegEx" : "Menza and Jacas",
      "year" : 2014
    }, {
      "title" : "Active Learning for Delineation of Curvilinear Structures",
      "author" : [ "A. Mosinska", "R. Sznitman", "P. Glowacki", "P. Fua" ],
      "venue" : "In Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Mosinska et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Mosinska et al\\.",
      "year" : 2016
    }, {
      "title" : "A Literature Survey of Active Machine Learning in the Context of Natural Language Processing",
      "author" : [ "F. Olsson" ],
      "venue" : "Swedish Institute of Computer Science,",
      "citeRegEx" : "Olsson,? \\Q2009\\E",
      "shortCiteRegEx" : "Olsson",
      "year" : 2009
    }, {
      "title" : "Soft margins for adaboost",
      "author" : [ "Rätsch", "Gunnar", "Onoda", "Takashi", "Müller", "K-R" ],
      "venue" : "Machine learning,",
      "citeRegEx" : "Rätsch et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Rätsch et al\\.",
      "year" : 2001
    }, {
      "title" : "Active Learning Literature Survey",
      "author" : [ "B. Settles" ],
      "venue" : "Technical report, University of Wisconsin–Madison,",
      "citeRegEx" : "Settles,? \\Q2010\\E",
      "shortCiteRegEx" : "Settles",
      "year" : 2010
    }, {
      "title" : "An Analysis of Active Learning Strategies for Sequence Labeling Tasks",
      "author" : [ "B. Settles", "M. Craven" ],
      "venue" : "In Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Settles and Craven,? \\Q2008\\E",
      "shortCiteRegEx" : "Settles and Craven",
      "year" : 2008
    }, {
      "title" : "Actively learning hemimetrics with applications to eliciting user preferences",
      "author" : [ "Singla", "Adish", "Tschiatschek", "Sebastian", "Krause", "Andreas" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Singla et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Singla et al\\.",
      "year" : 2016
    }, {
      "title" : "Active Testing for Face Detection and Localization",
      "author" : [ "R. Sznitman", "B. Jedynak" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "Sznitman and Jedynak,? \\Q2010\\E",
      "shortCiteRegEx" : "Sznitman and Jedynak",
      "year" : 2010
    }, {
      "title" : "Value iteration networks",
      "author" : [ "Tamar", "Aviv", "Levine", "Sergey", "Abbeel", "WU Pieter", "YI", "Thomas", "Garrett" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Tamar et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Tamar et al\\.",
      "year" : 2016
    }, {
      "title" : "Support Vector Machine Active Learning with Applications to Text Classification",
      "author" : [ "S. Tong", "D. Koller" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Tong and Koller,? \\Q2002\\E",
      "shortCiteRegEx" : "Tong and Koller",
      "year" : 2002
    }, {
      "title" : "Weakly Supervised Structured Output Learning for Semantic Segmentation",
      "author" : [ "A. Vezhnevets", "V. Ferrari", "J.M. Buhmann" ],
      "venue" : "In Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Vezhnevets et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Vezhnevets et al\\.",
      "year" : 2012
    }, {
      "title" : "Multi-Class Active Learning by Uncertainty Sampling with Diversity Maximization",
      "author" : [ "Y. Yang", "Z. Ma", "F. Nie", "X. Chang", "A.G. Hauptmann" ],
      "venue" : "International Journal of Computer Vision,",
      "citeRegEx" : "Yang et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Recent examples include bandit algorithms (Baram et al., 2004; Hsu & Lin, 2015), aggregating strategies whose experience can be transferred between domains (Chu & Lin, 2016), and approaches based on Reinforcement Learning (Ebert et al.",
      "startOffset" : 42,
      "endOffset" : 79
    }, {
      "referenceID" : 4,
      "context" : ", 2004; Hsu & Lin, 2015), aggregating strategies whose experience can be transferred between domains (Chu & Lin, 2016), and approaches based on Reinforcement Learning (Ebert et al., 2012).",
      "startOffset" : 167,
      "endOffset" : 187
    }, {
      "referenceID" : 12,
      "context" : "They include uncertainty sampling (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015), ar X iv :1 70 3.",
      "startOffset" : 34,
      "endOffset" : 109
    }, {
      "referenceID" : 23,
      "context" : "They include uncertainty sampling (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015), ar X iv :1 70 3.",
      "startOffset" : 34,
      "endOffset" : 109
    }, {
      "referenceID" : 30,
      "context" : "They include uncertainty sampling (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015), ar X iv :1 70 3.",
      "startOffset" : 34,
      "endOffset" : 109
    }, {
      "referenceID" : 5,
      "context" : "query-by-committee (Gilad-bachrach et al., 2005; Iglesias et al., 2011), expected model change (Settles, 2010; Sznitman & Jedynak, 2010; Vezhnevets et al.",
      "startOffset" : 19,
      "endOffset" : 71
    }, {
      "referenceID" : 10,
      "context" : "query-by-committee (Gilad-bachrach et al., 2005; Iglesias et al., 2011), expected model change (Settles, 2010; Sznitman & Jedynak, 2010; Vezhnevets et al.",
      "startOffset" : 19,
      "endOffset" : 71
    }, {
      "referenceID" : 23,
      "context" : ", 2011), expected model change (Settles, 2010; Sznitman & Jedynak, 2010; Vezhnevets et al., 2012), expected error (Joshi et al.",
      "startOffset" : 31,
      "endOffset" : 97
    }, {
      "referenceID" : 29,
      "context" : ", 2011), expected model change (Settles, 2010; Sznitman & Jedynak, 2010; Vezhnevets et al., 2012), expected error (Joshi et al.",
      "startOffset" : 31,
      "endOffset" : 97
    }, {
      "referenceID" : 11,
      "context" : ", 2012), expected error (Joshi et al., 2012), and variance (Hoi et al.",
      "startOffset" : 24,
      "endOffset" : 44
    }, {
      "referenceID" : 7,
      "context" : ", 2012), and variance (Hoi et al., 2006) minimization, Bayesian AL (Houlsby et al.",
      "startOffset" : 22,
      "endOffset" : 40
    }, {
      "referenceID" : 8,
      "context" : ", 2006) minimization, Bayesian AL (Houlsby et al., 2011).",
      "startOffset" : 34,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "While both examples are synthetic, analogous situations arise regularly in real data (Baram et al., 2004).",
      "startOffset" : 85,
      "endOffset" : 105
    }, {
      "referenceID" : 13,
      "context" : "Among AL methods designed to handle complex real-world situations, some cater to specific classifiers, such as those that rely on Gaussian Processes (Kapoor et al., 2007), and applications, such as natural language processing (Tong & Koller, 2002; Olsson, 2009), sequence labeling tasks (Settles & Craven, 2008), visual recognition (Luo et al.",
      "startOffset" : 149,
      "endOffset" : 170
    }, {
      "referenceID" : 21,
      "context" : ", 2007), and applications, such as natural language processing (Tong & Koller, 2002; Olsson, 2009), sequence labeling tasks (Settles & Craven, 2008), visual recognition (Luo et al.",
      "startOffset" : 63,
      "endOffset" : 98
    }, {
      "referenceID" : 18,
      "context" : ", 2007), and applications, such as natural language processing (Tong & Koller, 2002; Olsson, 2009), sequence labeling tasks (Settles & Craven, 2008), visual recognition (Luo et al., 2004; Long et al., 2015), semantic segmentation (Vezhnevets et al.",
      "startOffset" : 169,
      "endOffset" : 206
    }, {
      "referenceID" : 15,
      "context" : ", 2007), and applications, such as natural language processing (Tong & Koller, 2002; Olsson, 2009), sequence labeling tasks (Settles & Craven, 2008), visual recognition (Luo et al., 2004; Long et al., 2015), semantic segmentation (Vezhnevets et al.",
      "startOffset" : 169,
      "endOffset" : 206
    }, {
      "referenceID" : 29,
      "context" : ", 2015), semantic segmentation (Vezhnevets et al., 2012), foreground-background segmentation (Konyushkova et al.",
      "startOffset" : 31,
      "endOffset" : 56
    }, {
      "referenceID" : 14,
      "context" : ", 2012), foreground-background segmentation (Konyushkova et al., 2015), image delineation (Mosinska et al.",
      "startOffset" : 44,
      "endOffset" : 70
    }, {
      "referenceID" : 20,
      "context" : ", 2015), image delineation (Mosinska et al., 2016), and preference learning (Singla et al.",
      "startOffset" : 27,
      "endOffset" : 50
    }, {
      "referenceID" : 25,
      "context" : ", 2016), and preference learning (Singla et al., 2016).",
      "startOffset" : 33,
      "endOffset" : 54
    }, {
      "referenceID" : 23,
      "context" : "Moreover, various querying strategies aim to maximize different performance metrics as evidenced in the case of multi-class classification (Settles, 2010).",
      "startOffset" : 139,
      "endOffset" : 154
    }, {
      "referenceID" : 27,
      "context" : "As a result, meta learning algorithms have been gaining in popularity in recent years (Tamar et al., 2016), but they are rarely designed to deal with AL scenarios.",
      "startOffset" : 86,
      "endOffset" : 106
    }, {
      "referenceID" : 1,
      "context" : "Baram et al. (2004) combine several known heuristics during the AL execution with the help of a bandit algorithm.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 1,
      "context" : "Baram et al. (2004) combine several known heuristics during the AL execution with the help of a bandit algorithm. This is made possible by the use of the maximum entropy criterion, which estimates the classification performance without labels during AL. Hsu & Lin (2015) extend this line of work but move the focus from datasamples as arms to heuristics as arms in the bandit process and use a new unbiased estimator of the test error, which enables it to outperform the previous method.",
      "startOffset" : 0,
      "endOffset" : 271
    }, {
      "referenceID" : 1,
      "context" : "Baram et al. (2004) combine several known heuristics during the AL execution with the help of a bandit algorithm. This is made possible by the use of the maximum entropy criterion, which estimates the classification performance without labels during AL. Hsu & Lin (2015) extend this line of work but move the focus from datasamples as arms to heuristics as arms in the bandit process and use a new unbiased estimator of the test error, which enables it to outperform the previous method. Chu & Lin (2016) go further and suggest transferring the bandit-learnt combination of AL heuristics between different tasks.",
      "startOffset" : 0,
      "endOffset" : 505
    }, {
      "referenceID" : 1,
      "context" : "Baram et al. (2004) combine several known heuristics during the AL execution with the help of a bandit algorithm. This is made possible by the use of the maximum entropy criterion, which estimates the classification performance without labels during AL. Hsu & Lin (2015) extend this line of work but move the focus from datasamples as arms to heuristics as arms in the bandit process and use a new unbiased estimator of the test error, which enables it to outperform the previous method. Chu & Lin (2016) go further and suggest transferring the bandit-learnt combination of AL heuristics between different tasks. Another view on the problem is presented in Ebert et al. (2012), where they balance exploration and exploitation with a Markov decision process.",
      "startOffset" : 0,
      "endOffset" : 677
    }, {
      "referenceID" : 12,
      "context" : "In this section we briefly introduce the standard Active Leaning (AL) framework along with uncertainty sampling (US), the most frequently-used heuristic to implement it (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015).",
      "startOffset" : 169,
      "endOffset" : 244
    }, {
      "referenceID" : 23,
      "context" : "In this section we briefly introduce the standard Active Leaning (AL) framework along with uncertainty sampling (US), the most frequently-used heuristic to implement it (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015).",
      "startOffset" : 169,
      "endOffset" : 244
    }, {
      "referenceID" : 30,
      "context" : "In this section we briefly introduce the standard Active Leaning (AL) framework along with uncertainty sampling (US), the most frequently-used heuristic to implement it (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015).",
      "startOffset" : 169,
      "endOffset" : 244
    }, {
      "referenceID" : 12,
      "context" : "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016).",
      "startOffset" : 73,
      "endOffset" : 197
    }, {
      "referenceID" : 23,
      "context" : "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016).",
      "startOffset" : 73,
      "endOffset" : 197
    }, {
      "referenceID" : 30,
      "context" : "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016).",
      "startOffset" : 73,
      "endOffset" : 197
    }, {
      "referenceID" : 14,
      "context" : "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016).",
      "startOffset" : 73,
      "endOffset" : 197
    }, {
      "referenceID" : 20,
      "context" : "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016).",
      "startOffset" : 73,
      "endOffset" : 197
    }, {
      "referenceID" : 13,
      "context" : "• Kapoor: approach of Kapoor et al. (2007) that balances exploration against exploitation by incorporating mean and variance estimation of the GP classifier.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 6,
      "context" : ", 2010), dice score (Gordillo et al., 2013), AMS score (Adam-Bourdarios et al.",
      "startOffset" : 20,
      "endOffset" : 43
    }, {
      "referenceID" : 0,
      "context" : ", 2013), AMS score (Adam-Bourdarios et al., 2014) and area under ROC curve.",
      "startOffset" : 19,
      "endOffset" : 49
    }, {
      "referenceID" : 1,
      "context" : "Some works (Baram et al., 2004) report that various AL algorithms struggle with the type of tasks that is depicted in Fig.",
      "startOffset" : 11,
      "endOffset" : 31
    }, {
      "referenceID" : 22,
      "context" : "Another XOR-like dataset that has more natural shape is the banana dataset from Rätsch et al. (2001). Note that these datasets do not resemble in the least the data used to train LAL, as can be seen by comparing Figs.",
      "startOffset" : 80,
      "endOffset" : 101
    }, {
      "referenceID" : 17,
      "context" : "The task is to detect and segment mitochondria in it (Lucchi et al., 2012; Konyushkova et al., 2015).",
      "startOffset" : 53,
      "endOffset" : 100
    }, {
      "referenceID" : 14,
      "context" : "The task is to detect and segment mitochondria in it (Lucchi et al., 2012; Konyushkova et al., 2015).",
      "startOffset" : 53,
      "endOffset" : 100
    }, {
      "referenceID" : 16,
      "context" : "• Splice: In this dataset from the domain of molecular biology, our task is to detect splice junctions in DNA sequences (Lorena et al., 2002).",
      "startOffset" : 120,
      "endOffset" : 141
    }, {
      "referenceID" : 0,
      "context" : "• Higgs: This dataset from the domain of high energy physics contains the data that simulates the ATLAS experiment (Adam-Bourdarios et al., 2014).",
      "startOffset" : 115,
      "endOffset" : 145
    } ],
    "year" : 2017,
    "abstractText" : "In this paper, we suggest a novel data-driven approach to active learning: Learning Active Learning (LAL). The key idea behind LAL is to train a regressor that predicts the expected error reduction for a potential sample in a particular learning state. By treating the query selection procedure as a regression problem we are not restricted to dealing with existing AL heuristics; instead, we learn strategies based on experience from previous active learning experiments. We show that LAL can be learnt from a simple artificial 2D dataset and yields strategies that work well on real data from a wide range of domains. Moreover, if some domain-specific samples are available to bootstrap active learning, the LAL strategy can be tailored for a particular problem.",
    "creator" : "LaTeX with hyperref package"
  }
}