{
  "name" : "1605.03924.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Joint Embeddings of Hierarchical Categories and Entities",
    "authors" : [ "Yuezhang Li", "Ronghuo Zheng", "Tian Tian", "Zhiting Hu", "Rahul Iyer", "Katia Sycara" ],
    "emails" : [ "yuezhanl@andrew.cmu.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Hierarchies, most commonly represented as Tree or DAG structures, provide a natural way to categorize and locate knowledge in large knowledge bases (KBs). For example, WordNet, Freebase and Wikipedia use hierarchical taxonomy to organize entities into category hierarchies. These hierarchical categories could benefit applications such as concept categorization (Rothenhäusler and Schütze, 2009), document categorization (Gopal and Yang, 2013), object categorization (Verma et al., 2012), and link prediction in knowlegde graphs (Lin et al., 2015). In all of these applications, it is essential to have a good representation of categories and entities as well as a good semantic relatedness measure.\nExisting work does not use structured knowledge of KBs to embed representations of entities and categories into a semantic space. Current entity embedding methods cannot provide\nthe relatedness measure between entities and categories, although they successfully learn entity representations and relatedness measure between entities (Hu et al., 2015). Knowledge graph embedding methods (Wang et al., 2014; Lin et al., 2015) give embeddings of entities and relations but lack category representations and relatedness measure. Though taxonomy embedding methods (Weinberger and Chapelle, 2009; Hwang and Sigal, 2014) learn category embeddings, they primarily target documents classification not entity representations.\nIn this paper, we propose two models to simultaneously learn entity and category vectors from large-scale knowledge bases (KBs). They are Category Embedding model and Hierarchical Category Embedding model. The Category Embedding model (CE model) extends the entity embedding method of (Hu et al., 2015) by using category information with entities to learn entity and category embeddings. The Hierarchical Category Embedding model (HCE model) extends CE model to integrate the hierarchical structure of categories. It considers all ancestor categories of one entity. The final learned entity and category vectors can capture meaningful semantic relatedness between entities and categories.\nWe train the category and entity vectors on Wikipedia, and then evaluate our methods from two applications: concept categorization (Baroni and Lenci, 2010) and semantic relatedness (Finkelstein et al., 2001).\nThe organization of the research elements that comprise this paper, summarizing the above discussion, is shown in Figure 1.\nThe main contributions of our paper are summarized as follows. First, we incorporate category information into entity embeddings with the proposed CE model to get entity and category embeddings simultaneously. Second, we add category\nar X\niv :1\n60 5.\n03 92\n4v 1\n[ cs\n.C L\n] 1\n2 M\nay 2\n01 6\nhierarchies to CE model and develop HCE model to enhance the embeddings’ quality. Third, we propose a concept categorization method based on nearest neighbor classification that avoids the issues arising from disparity in the granularity of categories that plague traditional clustering methods. Fourth, our model can handle multiple-word concepts/entities1 such as “hot dog” and distinguish it from “dog”. Overall, our model outperforms state-of-the-art methods on both concept categorization and semantic relatedness."
    }, {
      "heading" : "2 Hierarchical Category Embedding",
      "text" : "In order to find representations for categories and entities that can capture their semantic relatedness, we use existing hierarchical categories and entities labeled with these categories, and explore two methods: 1) Category Embedding model (CE Model): it replaces the entities in the context with their directly labeled categories to build categories’ context; 2) Hierarchical Category Embedding (HCE Model): it further incorporates all ancestor categories of the context entities to utilize the hierarchical information."
    }, {
      "heading" : "2.1 Category Embedding (CE) Model",
      "text" : "Our category embedding (CE) model is based on the Skip-gram word embedding model(Mikolov et al., 2013). The skip-gram model aims at generating word representations that are good at predicting context words surrounding a target word in a sliding window. Previous work (Hu et al., 2015) extends the entity’s context to the whole article that describes the entity and acquires a set of entity pairs D = {(et, ec)}, where et denotes the target entity and ec denotes the context entity.\nOur CE model extends those approaches by incorporating category information. In KBs such as Wikipedia, category hierarchies are usually given as DAG or tree structures, and entities are categorized into one or more categories as leaves. Thus, in KBs, each entity et is labeled with one or more categories (c1, c2, ..., ck), k ≥ 1 and described by an article containing other context entities (see Data in Figure 1).\nTo learn embeddings of entities and categories simultaneously, we adopt a method that incorporates the labeled categories into the entities when predicting the context entities, similar to TWE1 model (Liu et al., 2015). For example, if et\n1In this paper, concepts and entities denote same thing.\nis the target entity in the document, its labeled categories (c1, c2, ..., ck) would be combined with the entity et to predict the context entities like ec1 and ec2 (see CE Model in Figure 1). For each target-context entity pair (et, ec), the probability of ec being context of et is defined as the following softmax:\nP (ec|et) = exp (et · ec)∑ e∈E exp (et · e) , (1)\nwhere E denotes the set of all entity vectors, and exp is the exponential function. For convenience, here we abuse the notation of et and ec to denote a target entity vector and a context entity vector respectively.\nSimilar to TWE-1 model, We learn the target and context vectors by maximizing the average log probability:\nL = 1 |D| ∑\n(ec,et)∈D\n[ logP (ec|et)\n+ ∑\nci∈C(et)\nlogP (ec|ci) ] , (2)\nwhere D is the set of all entity pairs and we abuse the notation of ci to denote a category vector, and C(et) denotes the categories of entity et."
    }, {
      "heading" : "2.2 Hierarchical Category Embedding(HCE) Model",
      "text" : "From the design above, we can get the embeddings of all categories and entities in KBs without capturing the semantics of hierarchical structure of categories. In a category hierarchy, the categories at lower layers will cover fewer but more specific concepts than categories at upper layers. To capture this feature, we extend the CE model to further incorporate the ancestor categories of the target entity when predicting the context entities (see HCE Model in Figure 1). If a category is near an entity, its ancestor categories would also be close to that entity. On the other hand, an increasing distance of the category from the target entity would decrease the power of that category in predicting context entities. Therefore, given the target entity et and the context entity ec, the objective is to maximize the following weighted\naverage log probability:\nL = 1 |D| ∑\n(ec,et)∈D\n[ logP (ec|et)\n+ ∑\nci∈A(et)\nwi logP (ec|ci) ] , (3)\nwhere A(et) represents the set of ancestor categories of entity et, and wi is the weight of each category in predicting the context entity. To implement the intuition that a category is more relevant to its closer ancestor, for example, “NBC Mystery Movies” is more relevant to “Mystery Movies” than “Entertainment”, we set wi ∝ 1l(cc,ci) where l(cc, ci) denotes the average number of steps going down from category ci to category cc, and it is constrained with ∑ iwi = 1.\nFigure 2 presents the results of our HCE model for DOTA-all data set (see Section 4.1.1). The visualization shows that our embedding method is able to clearly separate entities into distinct categories."
    }, {
      "heading" : "2.3 Learning",
      "text" : "Learning CE and HCE models follows the optimization scheme of skip-gram model (Mikolov et al., 2013). We use negative sampling to reformulate the objective function, which is then optimized through stochastic gradient descent (SGD).\nSpecifically, the likelihood of each context entity of a target entity is defined with the softmax function in Eq. 1, which iterates over all entities. Thus, it is computationally intractable. We apply the standard negative sampling technique to transform the objective function in equation (3) to equation (4) below and then optimize it through SGD:\nL = ∑\n(ec,et)∈D\n[ log σ(ec · et) + ∑ ci∈A(et) wi log σ(ec · ci) ]\n+ ∑\n(e′c,et)∈D′\n[ log σ(−e′c · et)\n+ ∑\nci∈A(et)\nwi log σ(−e′c · ci) ] , (4)\nwhere D′ is the set of negative sample pairs and σ(x) = 1/(1 + exp(−x)) is the sigmoid function."
    }, {
      "heading" : "3 Applications",
      "text" : "We test the quality of our category and entity embedding with two different applications: concept categorization and semantic relatedness."
    }, {
      "heading" : "3.1 Concept Categorization",
      "text" : "Concept2 categorization, also known as concept learning or noun categorization, is a process of assigning a concept to one candidate category, given a set of concepts and candidate categories. Traditionally, concept categorization is achieved by concept clustering due to the lack of category representations. Since our model can generate representations of categories, we propose a new method of using nearest neighbor (NN) classification to directly categorize each concept to a certain category."
    }, {
      "heading" : "3.1.1 Concept Clustering",
      "text" : "The concept clustering is defined as: given a set of single-word concepts like dog, cat, apple and the corresponding gold standard categorizations, apply a word space model to project all the concepts to a semantic space and perform clustering. The clustering results can be evaluated by comparing with the gold standard categorizations.\nPrevious methods (Almuhareb and Poesio, 2004; Almuhareb and Poesio, 2005) managed to learn the properties and attributes of a concept; for example, the concept dog has attributes of (dog color) and (dog size) and the properties of (dog brown) and (dog small). By representing these attributes and properties in a high-dimensional space, one can cluster concepts based on common attributes and properties."
    }, {
      "heading" : "3.1.2 Nearest Neighbor (NN) Classification",
      "text" : "Although the previous methods described above can generate vectors carefully designed for capturing relations and attributes, the number of vector dimensions can be very large for some methods: from 10,000+ to 1,000,000+, e.g., (Almuhareb and Poesio, 2005; Rothenhäusler and Schütze, 2009). Due to the large dimensionality, the applicable clustering methods are restricted to the ones that can scale to such high dimensions3. Other methods such as word embedding (Mikolov et al., 2013) may need lower dimensionality vectors but suffer from granularity problems. Therefore, we propose an alternative method, namely nearest neighbor (NN) classification, and evaluate comparative trade-offs (see Table 3).\n2In this paper, concept and entity denote the same thing. 3(Rothenhäusler and Schütze, 2009) use CLUTO (Karypis, 2002), a clustering toolkit optimized to cluster large-scale data in reasonable time, as their standard measurements.\nUsing NN classification, we categorize concepts by directly comparing concept vectors with candidate category vectors. Precisely, given a set of concepts E and a set of candidate categories C, we convert all concepts to concept vectors and all candidate categories to category vectors. Then we use the equation c = argminci∈C ||ci − e|| to assign the concept vector e with category c. Note that in this paper, concept and entity denote the same thing so concept vector is exactly the same as entity vector."
    }, {
      "heading" : "3.1.3 Evaluation Metrics",
      "text" : "Since purity works as a standard evaluation metric for clustering (Rothenhäusler and Schütze, 2009), to compare our model with the concept clustering, we also use purity to measure our model’s performance. Generally, purity is defined as:\npurity(Ω,G) = 1\nn ∑ k max j |ωk ∩ gj |, (5)\nwhere Ω denotes a clustering solution of n clusters, G is a set of gold standard classes, ωk represents the set of labels in a cluster and gj is the set of labels in a class. A higher purity indicates better model performance."
    }, {
      "heading" : "3.2 Semantic Relatedness",
      "text" : "We also evaluate the entity and category embeddings by semantic relatedness. Semantic relatedness measure is a process of assigning one relatedness score for one word pair. We use a set of standard semantic benchmarks. Those benchmarks consist of word pairs that have manually rated scores 0-10 for semantic relatedness. The model performance is assessed by calculating the correlation between scores generated by the model and the average scores given by human subjects.\nWe use the Spearman’s rank correlation coefficient (?) of human assigned scores and system assigned scores to evaluate our result. Note that scores given by humans are not necessarily the gold standard because of the differences among humans and the difficulty of giving a clear definition of word similarity. However, a good system should agree with humans to some extent and thus should have a relatively high correlation coefficient (Although when the coefficient is high enough, a higher coefficient would not necessarily reflect the better model). The Spearman correlation score is defined by the Pearson correlation coefficient between the ranked variables. For\nscores Xi, Yi that are in sample size n, we use xi and yi to denote the rankings of scores Xi, Yi. The Spearman correlation coefficient is defined as:\nρ = 1− 6 ∑n i=1(xi − yi)2\nn(n2 − 1) . (6)"
    }, {
      "heading" : "4 Experiments",
      "text" : "In the experiments, we use the dataset collected from Wikipedia on Dec. 1, 20154 as the training data. We preprocess the category hierarchy by pruning administrative categories and deleting bottom-up edges to construct a DAG. The final version of data contains 5,373,165 entities and 793,856 categories organized as a DAG with a maximum depth of 18. The root category is “main topic classifications”. We train category and entity vectors in various dimensions of 100, 200, 250, 300, 400, 500, with batch size B = 500 and negative sample size k = 10.\nWith the training dataset defined above, we conduct experiments on two applications: concept categorization and semantic relatedness."
    }, {
      "heading" : "4.1 Concept Categorization",
      "text" : "In this section, we first introduce datasets applied in concept categorization, and then show baselines followed by experimental results."
    }, {
      "heading" : "4.1.1 Datasets",
      "text" : "There are two datasets used in this experiment. The first one is the Battig test set introduced by (Baroni and Lenci, 2010), which includes 83 concepts from 10 categories. The Battig test set only contains single-word concepts without any multiple-word concepts (e.g., “table tennis”). Hence, using this dataset restricts the power of concept categorization to single-word level. We use this dataset because it has been used as a benchmark for most previous approaches for concept categorization.\nDue to the limitations of the Battig test set, we construct a new entity categorization dataset DOTA (Dataset Of enTity cAtegorization) with 450 entities categorized into 15 categories (refer to Appendix A). All the categories and entities are extracted from Wikipedia, so the resulting dataset does not necessarily contains only single-word entities. Thus, the dataset can be split into two parts, DOTA-single that contains 300 single-word entities categorized into 15 categories and DOTA-mult that\n4https://dumps.wikimedia.org/wikidatawiki/20151201/\ncontains 150 multiple-word entities categorized into the same 15 categories. We design the DOTA dataset based on the following principles:\n• Coverage vs Granularity: Firstly, the dataset should cover at least one category of Wikipedia’s main topics including “Culture”, “Geography”, “Health”, “Mathematics”, “Nature”, “People”, “Philosophy”, “Religion”, “Society” and “Technology”. Secondly, categories should be in different granularity, from large categories (e.g.,“philosophy”) to small categories (e.g., “dogs”). Large categories are ones that are located within 5 layers away from the root, medium categories are 6-10 layers away from the root, while small categories have distance of 11-18 to the root. Our dataset consists of 1/3 large categories, 1/3 medium categories, and 1/3 small categories.\n• Single-Words vs Multiple-Words: Previous concept categorization datasets only contain single-words. However, some concepts are multiple-words and cannot be simply represented by single-words. For example, the concept “hot dog” is very different from the concept “dog”. Word-level embedding cannot solve this problem without phrase recognition, while entity-level embedding can solve it naturally. Therefore, we make each category of the dataset contain 10 multiple-word entities and 20 single-word entities."
    }, {
      "heading" : "4.1.2 Baselines",
      "text" : "Word Embedding (WE) trained with neutral networks on large corpus provides a way to map a given text to a semantic space. We compare our entity and category embeddings with two word embeddings.\n• WEMikolov(Mikolov et al., 2013): (Baroni et al., 2014) conducted thorough experiments on word counts and predictive based methods on word representation. Their experimental results show that Mikolov’s word embedding achieves state-of-the-art results in concept categorization. We trained word embeddings with Mikolov’s word2vec toolkit5 on\n5https://code.google.com/archive/p/word2vec/\nthe same Wikipedia corpus as ours (1.7 million tokens) and then applied the Skip-gram model with negative sample size of 10 and window size of 5 to vector dimensionality of 100, 200, 250, 300, 400, 500 respectively. The best results of various parameter settings are reported in Table 1 and Table 2.\n• WESenna (Collobert et al., 2011): We downloaded this 50-dimension word embedding6\ntrained on Wikipedia over 2 months. We use this embedding as a baseline because it is also trained on Wikipedia.\nTo evaluate the advantage of utilizing category hierarchy in training entity and category embedding, we also compare our Hierarchical Category Embedding (HCE) model with our Category Embedding (CE) model that has no hierarchical information."
    }, {
      "heading" : "4.1.3 Results",
      "text" : "In the experiments, we used scikit-learn (Pedregosa et al., 2011) to perform clustering. We tested k-means and hierarchical clustering with different distance metrics (euclidean, cosine) and linkage criterion (ward, complete, average). We reported the best result across different clustering parameters in each experiment.\nTable. 1 shows the experimental results of the concept clustering method. It is clear that hierarchical category embedding (HCE) model outperforms other methods in all datasets. For singleword entity categorization in Battig and DOTAsingle, our HCE model gives a purity of 89% and 92% respectively; while for multiple-word entity categorization in DOTA-mult and DOTA-all, the corresponding purities are 91% and 89% (higher is better).\nThe excellent performance of our HCE model on DOTA-mult and DOTA-all lies in the fact\n6http://ronan.collobert.com/senna/\nthat it can naturally produce multiple-word entities. Since Mikolov’s word embeddings can also capture common phrases, it performs well on DOTA-mult dataset with a purity of 73%. However, the Senna word embeddings only contain single-words. To get the embeddings of multipleword, we use the mean word vectors to denote multiple-word embeddings. As the meaning of a multiple-word is not simply the aggregation of the meaning of the words it contains, the purity of using Senna drops dramatically from 61% on DOTA-single to 43% only on DOTA-mult.\nTable.2 shows the experimental results of the nearest neighbor (NN) classification method. The results indicate the feasibility of using category vectors to directly predict the concept categories without clustering entities. By changing the concept categorization method from concept clustering to nearest neighbor classification, our model still achieves a purity of 87% on Battig and around 90% on DOTA.\nTable.3 presents the best prediction results produced by our HCE model with two different methods, namely concept clustering and nearest neighbor (NN) classification.\nAs for the concept clustering approach, the general performance is very good except for one extreme case that many entities of geometry category are misclassified into algebra category. Refer to Figure 2, it is clear that because algebra category overlaps with geometry category, the concept clustering clusters them together. This phenomenon is caused by the difference in granularity of categories.\nAs for the nearest neighbor (NN) classification approach, we found an interesting phenomenon – several entities from other categories are misclassified into weather category. Referring to the work of (Radovanović et al., 2010; ?), this phenomenon is called hubness, which depicts that some vectors (“hubs”) tend to appear in the top neighbor lists of\nmany test items in high-dimensional space. In our case, the category vector “weather” tend to be a “hub” vector.\nBased on the analysis of these two methods above, we can conclude that the NN classifier can address granularity problem but suffers from the hubness problem, while concept clustering can deal with hubness but has the granularity problem."
    }, {
      "heading" : "4.2 Semantic relatedness",
      "text" : "We now introduce the datesets and baselines for measuring semantic relatedness and show the experimental results."
    }, {
      "heading" : "4.2.1 Datasets",
      "text" : "We use a set of standard datasets and preprocess them to fit our method. Our method requires mapping the words to corresponding Wikipedia entities or categories. For example, we map the word “cat” to the Wikipedia entity “cat” and the word “equipment” to the Wikipedia category “equipment”. Without loss of generality, we first match a word to a Wikipedia entity based on lexical similarity. If there is no matched entity, we match it to a Wikipedia category. However, it is difficult for this approah to map some words to a specific Wikipedia entity or category because of two reasons:\n• Wikipedia is a knowledge base that organizes categories and concepts, but some words like adjectives (e.g. smart/stupid) cannot be mapped to any Wikipedia entity or category. Moreover, our entity based approach cannot capture word pairs with lexical differences such as “swim/swimming”. We thus eliminate these kinds of words.\n• Some words are ambiguous so they have multiple corresponding entities in Wikipedia. For example, the word “doctor” can work as entity “Doctor(title)” that means the holder of an accredited doctoral graduate degree, and it can also be entity “Physician” that means a professional who practices medicine. Therefore, we simply discard all these ambiguous words.\nUsing the filtered datasets does not affect the fairness of our comparison, since we conduct all the other baselines on the same subsets.\nWS: The WordSim353 dataset is introduced by (Finkelstein et al., 2001). It contains 353\npairs of words and their semantic relatedness scores assigned by 13 to 16 human subjects. The work of (Agirre et al., 2009) splits the WS-353 dataset into two separate subsets: similarity subset (WSS) and relatedness subset (WSR). The former one contains tighter taxonomy relations (e.g., plane/car, student/professor) whereas the latter contains tighter topical relations (e.g., Jerusalem/Israel, OPEC/country). After data preprocessing, 184 pairs of words remain in WS353, 105 pairs in WSS-353 (202 pairs originally), and 125 pairs in WSR-353 (251 pairs originally).\nMEN: The work of (Bruni et al., 2014) constructed this dataset with 3000 word pairs that have semantic relatedness scores obtained by crowd-sourcing. After data preprocessing, there are 1508 pairs of words left.\nRG: A classic dataset contains 65 word pairs introduced by (Rubenstein and Goodenough, 1965). After data preprocessing, 28 pairs of words are left."
    }, {
      "heading" : "4.2.2 Baselines",
      "text" : "We compare our methods with some state-of-theart methods below.\nWN+NR: In (Radhakrishnan and Varma, 2013), word similarity measure is derived from Wikipedia category names integrated with WordNet similarity measure by performing regression using a Support Vector Machine. WN+NR1 and WN+NR2 are two of the best models reported in their paper.\nWEMikolov: As described in Section 4.1.2, we trained word embedding using Mikolov’s word2vec toolkit7 on the same Wikipedia corpus (1.7 million tokens) as ours to make them comparable. We use Skip-gram model with negative sample size of 10 and window size of 5 , with vector dimensionality of 100, 200, 250, 300, 400, 500. We report the best results obtained from various parameter settings in Table 4.\nWESenna (Collobert et al., 2011): We downloaded this 50-dimension word embedding8 trained on Wikipedia over 2 months."
    }, {
      "heading" : "4.2.3 Results",
      "text" : "Table 4 shows the experimental results of the semantic relatedness tasks. We can see that our HCE model yields best results of 57%, 69%, and 83% on WS, MEN and RG datasets. This performance suggests that entity and category embeddings can be used as an indicator of semantic relatedness between words. For WSS dataset, the result of our method is comparable with WN+NR1 method, which integrates WordNet similarity measures with the normalized representation of category names. We also found that Mikolov’s word embedding performs better than our method on WSR dataset, but performs worse than our method on WSS dataset. The reason may be that the WSR dataset concentrates on topical related words rather than taxonomy related words, and\n7https://code.google.com/archive/p/word2vec/ 8http://ronan.collobert.com/senna/\nour method can better capture taxonomy relationship than topic relationship."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we proposed a framework to learn entity and category embeddings to capture semantic relatedness between entities and categories. This framework can incorporate taxonomy hierarchy from large scale knowledge bases. Experiments on both concept categorization and semantic relatedness show that our approach outperforms state of the art approaches. In the future work, we aim at applying our method to more applications such as hierarchical document classification."
    }, {
      "heading" : "A The DOTA dataset: 300 single-word entities and 150 multi-word entities from 15 Wikipedia Categories",
      "text" : "Category Entities beverages juice, beer, milk, coffee, tea, cocktail, wine, liqueur, sake, vodka, mead, sherry, brandy, gin, rum, latte, whisky,\ncider, gose, rompope, orange juice, masala chai, green tea, black tea, herbal tea, coconut milk, corn syrup, soy milk, rose water, hyeonmi cha\nsports bowling, football, aerobics, hockey, karate, korfball, handball, floorball, skiing, cycling, racing, softball, shooting, netball, snooker, powerlifting, jumping, wallball, volleyball, snowboarding, table tennis, floor hockey, olympic sports, wheelchair basketball, crab soccer, indoor soccer, table football, roller skating, vert skating, penny football emotions love, anxiety, empathy, fear, envy, loneliness, shame, anger, annoyance, happiness, jealousy, apathy, resentment, frustration, belongingness, sympathy, pain, worry, hostility, sadness, broken heart, panic disorder, sexual desire, falling in love, emotional conflict, learned helplessness, chronic stress, anxiety sensitivity, mental breakdown, bike rage weather cloud, wind, thunderstorm, fog, snow, wave, blizzard, sunlight, tide, virga, lightning, cyclone, whirlwind, sunset, dust, frost, flood, thunder, supercooling, fahrenheit, acid rain, rain and snow mixed, cumulus cloud, winter storm, blowing snow, geomagnetic storm, blood rain, fire whirl, pulse storm, dirty thunderstorm landforms lake, waterfall, stream, river, wetland, marsh, valley, pond, sandstone, mountain, cave, swamp, ridge, plateau, cliff, grassland, glacier, hill, bay, island, glacial lake, drainage basin, river delta, stream bed, vernal pool, salt marsh, proglacial lake, mud volcano, pit crater, lava lake trees wood, oak, pine, evergreen, willow, vine, shrub, birch, beech, maple, pear, fir, pinales, lauraceae, sorbus, buxus, acacia, rhamnaceae, fagales, sycamore, alhambra creek, alstonia boonei, atlantic hazelwood, bee tree, blood banana, datun sahib, druid oak, new year tree, heart pine, fan palm algebra addition, multiplication, exponentiation, tetration, polynomial, calculus, permutation, subgroup, integer, monomial, bijection, homomorphism, determinant, sequence, permanent, homotopy, subset, factorization, associativity, commutativity, real number, abstract algebra, convex set, prime number, complex analysis, natural number, complex number, lie algebra, identity matrix, set theory geometry trigonometry, circle, square, polyhedron, surface, sphere, cube, icosahedron, hemipolyhedron, digon, midpoint, centroid, octadecagon, curvature, curve, zonohedron, cevian, orthant, cuboctahedron, midsphere, regular polygon, uniform star polyhedron, isogonal figure, icosahedral symmetry, hexagonal bipyramid, snub polyhedron, homothetic center, geometric shape, bragg plane, affine plane fish goldfish, gourami, koi, cobitidae, tetra, goby, danio, wrasse, acanthuridae, anchovy, carp, catfish, cod, eel, flatfish, perch, pollock, salmon, triggerfish, herring, cave catfish, coachwhip ray, dwarf cichlid, moray eel, coastal fish, scissortail rasbora, flagtail pipefish, armoured catfish, hawaiian flagtail, pelagic fish dogs spaniel, foxhound, bloodhound, beagle, pekingese, weimaraner, collie, terrier, poodle, puppy, otterhound, labradoodle, puggle, eurasier, drever, brindle, schnoodle, bandog, leonberger, cockapoo, golden retriever, tibetan terrier, bull terrier, welsh springer spaniel, hunting dog, bearded collie, picardy spaniel, afghan hound, brittany dog, redbone coonhound music jazz, blues, song, choir, opera, rhythm, lyrics, melody, harmony, concert, comedy, violin, drum, piano, drama, cello, composer, musician, drummer, pianist, hip hop, classical music, electronic music, folk music, dance music, musical instrument, disc jockey, popular music, sheet music, vocal music politics democracy, law, government, liberalism, justice, policy, rights, utilitarianism, election, capitalism, ideology, egalitarianism, debate, regime, globalism, authoritarianism, monarchism, anarchism, communism, individualism, freedom of speech, political science, public policy, civil society, international law, social contract, election law, social justice, global justice, group conflict philosophy ethics, logic, ontology, aristotle, plato, rationalism, platonism, relativism, existence, truth, positivism, metalogic, subjectivism, idealism, materialism, aesthetics, probabilism, monism, truth, existence, western philosophy, contemporary philosophy, cognitive science, logical truth, ancient philosophy, universal mind, visual space, impossible world, theoretical philosophy, internal measurement linguistics syntax, grammar, semantics, lexicon, speech, phonetics, vocabulary, phoneme, lexicography, language, pragmatics, orthography, terminology, pronoun, noun, verb, pronunciation, lexicology, metalinguistics, paleolinguistics, language death, historical linguistics, dependency grammar, noun phrase, comparative linguistics, word formation, cognitive semantics, syntactic structures, auxiliary verb, computational semantics vehicles truck, car, aircraft, minibus, motorcycle, microvan, bicycle, tractor, microcar, van, ship, helicopter, airplane, towing, velomobile, rocket, train, bus, gyrocar, cruiser, container ship, school bus, road train, tow truck, audi a6, garbage truck, hydrogen tank, light truck, compressed air car, police car"
    } ],
    "references" : [ {
      "title" : "A study on similarity and relatedness using distributional and wordnet-based approaches",
      "author" : [ "Eneko Agirre", "Enrique Alfonseca", "Keith Hall", "Jana Kravalova", "Marius Paşca", "Aitor Soroa." ],
      "venue" : "Proceedings of Human Language Technologies: The",
      "citeRegEx" : "Agirre et al\\.,? 2009",
      "shortCiteRegEx" : "Agirre et al\\.",
      "year" : 2009
    }, {
      "title" : "Attribute-based and value-based clustering: An evaluation",
      "author" : [ "Abdulrahman Almuhareb", "Massimo Poesio." ],
      "venue" : "EMNLP, volume 4, pages 158–165.",
      "citeRegEx" : "Almuhareb and Poesio.,? 2004",
      "shortCiteRegEx" : "Almuhareb and Poesio.",
      "year" : 2004
    }, {
      "title" : "Concept learning and categorization from the web",
      "author" : [ "Abdulrahman Almuhareb", "Massimo Poesio." ],
      "venue" : "Proc. of CogSci.",
      "citeRegEx" : "Almuhareb and Poesio.,? 2005",
      "shortCiteRegEx" : "Almuhareb and Poesio.",
      "year" : 2005
    }, {
      "title" : "Distributional memory: A general framework for corpusbased semantics",
      "author" : [ "Marco Baroni", "Alessandro Lenci." ],
      "venue" : "Computational Linguistics, 36(4):673–721.",
      "citeRegEx" : "Baroni and Lenci.,? 2010",
      "shortCiteRegEx" : "Baroni and Lenci.",
      "year" : 2010
    }, {
      "title" : "Don’t count, predict! a systematic comparison of context-counting vs",
      "author" : [ "Marco Baroni", "Georgiana Dinu", "Germán Kruszewski." ],
      "venue" : "context-predicting semantic vectors. In ACL (1), pages 238–247.",
      "citeRegEx" : "Baroni et al\\.,? 2014",
      "shortCiteRegEx" : "Baroni et al\\.",
      "year" : 2014
    }, {
      "title" : "Multimodal distributional semantics",
      "author" : [ "Elia Bruni", "Nam-Khanh Tran", "Marco Baroni." ],
      "venue" : "J. Artif. Intell. Res.(JAIR), 49(1-47).",
      "citeRegEx" : "Bruni et al\\.,? 2014",
      "shortCiteRegEx" : "Bruni et al\\.",
      "year" : 2014
    }, {
      "title" : "Natural language processing (almost) from scratch",
      "author" : [ "Ronan Collobert", "Jason Weston", "Léon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa." ],
      "venue" : "The Journal of Machine Learning Research, 12:2493–2537.",
      "citeRegEx" : "Collobert et al\\.,? 2011",
      "shortCiteRegEx" : "Collobert et al\\.",
      "year" : 2011
    }, {
      "title" : "Placing search in context: The concept revisited",
      "author" : [ "Lev Finkelstein", "Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin." ],
      "venue" : "Proceedings of the 10th international conference on World Wide Web, pages",
      "citeRegEx" : "Finkelstein et al\\.,? 2001",
      "shortCiteRegEx" : "Finkelstein et al\\.",
      "year" : 2001
    }, {
      "title" : "Recursive regularization for large-scale classification with hierarchical and graphical dependencies",
      "author" : [ "Siddharth Gopal", "Yiming Yang." ],
      "venue" : "Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data",
      "citeRegEx" : "Gopal and Yang.,? 2013",
      "shortCiteRegEx" : "Gopal and Yang.",
      "year" : 2013
    }, {
      "title" : "Entity hierarchy embedding",
      "author" : [ "Zhiting Hu", "Poyao Huang", "Yuntian Deng", "Yingkai Gao", "Eric P Xing." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural",
      "citeRegEx" : "Hu et al\\.,? 2015",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2015
    }, {
      "title" : "A unified semantic embedding: Relating taxonomies and attributes",
      "author" : [ "Sung Ju Hwang", "Leonid Sigal." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 271–279.",
      "citeRegEx" : "Hwang and Sigal.,? 2014",
      "shortCiteRegEx" : "Hwang and Sigal.",
      "year" : 2014
    }, {
      "title" : "Cluto-a clustering toolkit",
      "author" : [ "George Karypis." ],
      "venue" : "Technical report, DTIC Document.",
      "citeRegEx" : "Karypis.,? 2002",
      "shortCiteRegEx" : "Karypis.",
      "year" : 2002
    }, {
      "title" : "Learning entity and relation embeddings for knowledge graph completion",
      "author" : [ "Yankai Lin", "Zhiyuan Liu", "Maosong Sun", "Yang Liu", "Xuan Zhu." ],
      "venue" : "AAAI, pages 2181–2187.",
      "citeRegEx" : "Lin et al\\.,? 2015",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2015
    }, {
      "title" : "Topical word embeddings",
      "author" : [ "Yang Liu", "Zhiyuan Liu", "Tat-Seng Chua", "Maosong Sun" ],
      "venue" : null,
      "citeRegEx" : "Liu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean." ],
      "venue" : "Advances in neural information processing systems, pages 3111–3119.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Scikitlearn: Machine learning in python",
      "author" : [ "Fabian Pedregosa", "Gaël Varoquaux", "Alexandre Gramfort", "Vincent Michel", "Bertrand Thirion", "Olivier Grisel", "Mathieu Blondel", "Peter Prettenhofer", "Ron Weiss", "Vincent Dubourg" ],
      "venue" : null,
      "citeRegEx" : "Pedregosa et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Pedregosa et al\\.",
      "year" : 2011
    }, {
      "title" : "Extracting semantic knowledge from wikipedia category names",
      "author" : [ "Priya Radhakrishnan", "Vasudeva Varma." ],
      "venue" : "Proceedings of the 2013 workshop on Automated knowledge base construction, pages 109–114. ACM.",
      "citeRegEx" : "Radhakrishnan and Varma.,? 2013",
      "shortCiteRegEx" : "Radhakrishnan and Varma.",
      "year" : 2013
    }, {
      "title" : "Hubs in space: Popular nearest neighbors in high-dimensional data",
      "author" : [ "Miloš Radovanović", "Alexandros Nanopoulos", "Mirjana Ivanović." ],
      "venue" : "The Journal of Machine Learning Research, 11:2487– 2531.",
      "citeRegEx" : "Radovanović et al\\.,? 2010",
      "shortCiteRegEx" : "Radovanović et al\\.",
      "year" : 2010
    }, {
      "title" : "Unsupervised classification with dependency based word spaces",
      "author" : [ "Klaus Rothenhäusler", "Hinrich Schütze." ],
      "venue" : "Proceedings of the Workshop on Geometrical Models of Natural Language Semantics, pages 17–24. Association for Computational",
      "citeRegEx" : "Rothenhäusler and Schütze.,? 2009",
      "shortCiteRegEx" : "Rothenhäusler and Schütze.",
      "year" : 2009
    }, {
      "title" : "Contextual correlates of synonymy",
      "author" : [ "Herbert Rubenstein", "John B Goodenough." ],
      "venue" : "Communications of the ACM, 8(10):627–633.",
      "citeRegEx" : "Rubenstein and Goodenough.,? 1965",
      "shortCiteRegEx" : "Rubenstein and Goodenough.",
      "year" : 1965
    }, {
      "title" : "Visualizing data using t-sne",
      "author" : [ "Laurens Van der Maaten", "Geoffrey Hinton." ],
      "venue" : "Journal of Machine Learning Research, 9(2579-2605):85.",
      "citeRegEx" : "Maaten and Hinton.,? 2008",
      "shortCiteRegEx" : "Maaten and Hinton.",
      "year" : 2008
    }, {
      "title" : "Learning hierarchical similarity metrics",
      "author" : [ "Nakul Verma", "Dhruv Mahajan", "Sundararajan Sellamanickam", "Vinod Nair." ],
      "venue" : "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 2280–2287. IEEE.",
      "citeRegEx" : "Verma et al\\.,? 2012",
      "shortCiteRegEx" : "Verma et al\\.",
      "year" : 2012
    }, {
      "title" : "Knowledge graph and text jointly embedding",
      "author" : [ "Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen." ],
      "venue" : "EMNLP, pages 1591–1601. Citeseer.",
      "citeRegEx" : "Wang et al\\.,? 2014",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2014
    }, {
      "title" : "Large margin taxonomy embedding for document categorization",
      "author" : [ "Kilian Q Weinberger", "Olivier Chapelle." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 1737–1744.",
      "citeRegEx" : "Weinberger and Chapelle.,? 2009",
      "shortCiteRegEx" : "Weinberger and Chapelle.",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 18,
      "context" : "These hierarchical categories could benefit applications such as concept categorization (Rothenhäusler and Schütze, 2009), document categorization (Gopal and Yang, 2013), object categorization (Verma et al.",
      "startOffset" : 88,
      "endOffset" : 121
    }, {
      "referenceID" : 8,
      "context" : "These hierarchical categories could benefit applications such as concept categorization (Rothenhäusler and Schütze, 2009), document categorization (Gopal and Yang, 2013), object categorization (Verma et al.",
      "startOffset" : 147,
      "endOffset" : 169
    }, {
      "referenceID" : 21,
      "context" : "These hierarchical categories could benefit applications such as concept categorization (Rothenhäusler and Schütze, 2009), document categorization (Gopal and Yang, 2013), object categorization (Verma et al., 2012), and link prediction in knowlegde graphs (Lin et al.",
      "startOffset" : 193,
      "endOffset" : 213
    }, {
      "referenceID" : 12,
      "context" : ", 2012), and link prediction in knowlegde graphs (Lin et al., 2015).",
      "startOffset" : 49,
      "endOffset" : 67
    }, {
      "referenceID" : 9,
      "context" : "Current entity embedding methods cannot provide the relatedness measure between entities and categories, although they successfully learn entity representations and relatedness measure between entities (Hu et al., 2015).",
      "startOffset" : 202,
      "endOffset" : 219
    }, {
      "referenceID" : 22,
      "context" : "Knowledge graph embedding methods (Wang et al., 2014; Lin et al., 2015) give embeddings of entities and relations",
      "startOffset" : 34,
      "endOffset" : 71
    }, {
      "referenceID" : 12,
      "context" : "Knowledge graph embedding methods (Wang et al., 2014; Lin et al., 2015) give embeddings of entities and relations",
      "startOffset" : 34,
      "endOffset" : 71
    }, {
      "referenceID" : 23,
      "context" : "Though taxonomy embedding methods (Weinberger and Chapelle, 2009; Hwang and Sigal, 2014) learn category embeddings, they primarily target documents classification not entity",
      "startOffset" : 34,
      "endOffset" : 88
    }, {
      "referenceID" : 10,
      "context" : "Though taxonomy embedding methods (Weinberger and Chapelle, 2009; Hwang and Sigal, 2014) learn category embeddings, they primarily target documents classification not entity",
      "startOffset" : 34,
      "endOffset" : 88
    }, {
      "referenceID" : 9,
      "context" : "The Category Embedding model (CE model) extends the entity embedding method of (Hu et al., 2015) by using category information with entities to learn entity and category embeddings.",
      "startOffset" : 79,
      "endOffset" : 96
    }, {
      "referenceID" : 3,
      "context" : "We train the category and entity vectors on Wikipedia, and then evaluate our methods from two applications: concept categorization (Baroni and Lenci, 2010) and semantic relatedness (Finkelstein et al.",
      "startOffset" : 131,
      "endOffset" : 155
    }, {
      "referenceID" : 7,
      "context" : "We train the category and entity vectors on Wikipedia, and then evaluate our methods from two applications: concept categorization (Baroni and Lenci, 2010) and semantic relatedness (Finkelstein et al., 2001).",
      "startOffset" : 181,
      "endOffset" : 207
    }, {
      "referenceID" : 14,
      "context" : "Our category embedding (CE) model is based on the Skip-gram word embedding model(Mikolov et al., 2013).",
      "startOffset" : 80,
      "endOffset" : 102
    }, {
      "referenceID" : 9,
      "context" : "Previous work (Hu et al., 2015) extends the entity’s context to the whole article that describes the entity and acquires a set of entity pairs D = {(et, ec)}, where et denotes the target entity and ec denotes the context entity.",
      "startOffset" : 14,
      "endOffset" : 31
    }, {
      "referenceID" : 13,
      "context" : "To learn embeddings of entities and categories simultaneously, we adopt a method that incorporates the labeled categories into the entities when predicting the context entities, similar to TWE1 model (Liu et al., 2015).",
      "startOffset" : 200,
      "endOffset" : 218
    }, {
      "referenceID" : 14,
      "context" : "mization scheme of skip-gram model (Mikolov et al., 2013).",
      "startOffset" : 35,
      "endOffset" : 57
    }, {
      "referenceID" : 1,
      "context" : "Previous methods (Almuhareb and Poesio, 2004; Almuhareb and Poesio, 2005) managed to learn the properties and attributes of a concept; for example, the concept dog has attributes of (dog color) and (dog size) and the properties of",
      "startOffset" : 17,
      "endOffset" : 73
    }, {
      "referenceID" : 2,
      "context" : "Previous methods (Almuhareb and Poesio, 2004; Almuhareb and Poesio, 2005) managed to learn the properties and attributes of a concept; for example, the concept dog has attributes of (dog color) and (dog size) and the properties of",
      "startOffset" : 17,
      "endOffset" : 73
    }, {
      "referenceID" : 2,
      "context" : ", (Almuhareb and Poesio, 2005; Rothenhäusler and Schütze, 2009).",
      "startOffset" : 2,
      "endOffset" : 63
    }, {
      "referenceID" : 18,
      "context" : ", (Almuhareb and Poesio, 2005; Rothenhäusler and Schütze, 2009).",
      "startOffset" : 2,
      "endOffset" : 63
    }, {
      "referenceID" : 14,
      "context" : "Other methods such as word embedding (Mikolov et al., 2013) may need lower dimensionality vectors but suffer from granularity problems.",
      "startOffset" : 37,
      "endOffset" : 59
    }, {
      "referenceID" : 18,
      "context" : "(Rothenhäusler and Schütze, 2009) use CLUTO (Karypis, 2002), a clustering toolkit optimized to cluster large-scale data in reasonable time, as their standard measurements.",
      "startOffset" : 0,
      "endOffset" : 33
    }, {
      "referenceID" : 11,
      "context" : "(Rothenhäusler and Schütze, 2009) use CLUTO (Karypis, 2002), a clustering toolkit optimized to cluster large-scale data in reasonable time, as their standard measurements.",
      "startOffset" : 44,
      "endOffset" : 59
    }, {
      "referenceID" : 18,
      "context" : "Since purity works as a standard evaluation metric for clustering (Rothenhäusler and Schütze, 2009), to compare our model with the concept clustering, we also use purity to measure our model’s perfor-",
      "startOffset" : 66,
      "endOffset" : 99
    }, {
      "referenceID" : 3,
      "context" : "The first one is the Battig test set introduced by (Baroni and Lenci, 2010), which includes 83 concepts from 10 categories.",
      "startOffset" : 51,
      "endOffset" : 75
    }, {
      "referenceID" : 14,
      "context" : "• WEMikolov(Mikolov et al., 2013): (Baroni et al.",
      "startOffset" : 11,
      "endOffset" : 33
    }, {
      "referenceID" : 4,
      "context" : ", 2013): (Baroni et al., 2014) conducted thorough experiments on word counts and predictive based methods on word representation.",
      "startOffset" : 9,
      "endOffset" : 30
    }, {
      "referenceID" : 6,
      "context" : "• WESenna (Collobert et al., 2011): We downloaded this 50-dimension word embedding6 trained on Wikipedia over 2 months.",
      "startOffset" : 10,
      "endOffset" : 34
    }, {
      "referenceID" : 15,
      "context" : "(Pedregosa et al., 2011) to perform clustering.",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 7,
      "context" : "WS: The WordSim353 dataset is introduced by (Finkelstein et al., 2001).",
      "startOffset" : 44,
      "endOffset" : 70
    }, {
      "referenceID" : 0,
      "context" : "work of (Agirre et al., 2009) splits the WS-353 dataset into two separate subsets: similarity subset (WSS) and relatedness subset (WSR).",
      "startOffset" : 8,
      "endOffset" : 29
    }, {
      "referenceID" : 5,
      "context" : "MEN: The work of (Bruni et al., 2014) constructed this dataset with 3000 word pairs that have semantic relatedness scores obtained by crowd-sourcing.",
      "startOffset" : 17,
      "endOffset" : 37
    }, {
      "referenceID" : 19,
      "context" : "RG: A classic dataset contains 65 word pairs introduced by (Rubenstein and Goodenough, 1965).",
      "startOffset" : 59,
      "endOffset" : 92
    }, {
      "referenceID" : 16,
      "context" : "WN+NR: In (Radhakrishnan and Varma, 2013), word similarity measure is derived from Wikipedia category names integrated with WordNet similarity measure by performing regression using a Support Vector Machine.",
      "startOffset" : 10,
      "endOffset" : 41
    }, {
      "referenceID" : 6,
      "context" : "WESenna (Collobert et al., 2011): We downloaded this 50-dimension word embedding8 trained on Wikipedia over 2 months.",
      "startOffset" : 8,
      "endOffset" : 32
    } ],
    "year" : 2017,
    "abstractText" : "Due to the lack of structured knowledge applied in learning distributed representation of categories, existing work cannot incorporate category hierarchies into entity information. We propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. The framework allows to compute meaningful semantic relatedness between entities and categories. Compared with the previous state of the art, our framework can handle both single-word concepts and multipleword concepts with superior performance in concept categorization and semantic relatedness.",
    "creator" : "TeX"
  }
}