{
  "name" : "1510.07385.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n51 0.\n07 38\n5v 1\n[ cs\n.C L\n] 2\n6 O"
    }, {
      "heading" : "1 Introduction",
      "text" : "Online reputation is a key information for public figures and companies in order to react to the public opinions and to anticipate them. Indeed, knowing what make their reputation good or bad allows them to make informed decision. For instance a company may make additional efforts on its call centers if it notices that its consumers are unsatisfied.\nMonitoring online reputation of entities requires to be able to retrieve all opinions or reviews about them. Automatic approaches have then to deal with the noise generated by the recall-oriented retrieving techniques used. This noise is mainly the result of entity names ambiguity (e.g. jaguar which may refer to an animal or a car manufacturer). A classification step is required to filter out sources which do not actually mention the monitored entity. Topic\ndetection is necessary to identify which matter is discussed in the source and finally the polarity of it has to be estimated (is the opinion positive, neutral or negative?). Each of these three issues is an open problem. Moreover, systems have to be able to process large amounts of incoming new documents in a short time to provide fresh feedbacks. Sources commonly used are news web sites, blogs, forums or more recently social networks such as Twitter.\nWe propose three approaches to filter tweets on whether or not they refer to a given entity. These approaches rely on tweets content and meta-data associated to them (timestamp, user names, . . . ) as well as on the information contained about the entity in a knowledge base. We also investigate if combining systems outputs with merging algorithms can improve the overall performances and if different strategies may be applied to promote a measure or another.\nEach proposition is evaluated within the framework provided by the RepLab 2013 evaluation campaign and they all show competitive performances.\nThe remainder of this paper is organized as follows. Section 2 presents related works. Section 3 describes the proposed systems. Section 4 gives details about merging algorithms we used. Experiments are described in Section 5. In Section 6 we discuss the results before concluding in section 7."
    }, {
      "heading" : "2 Related Work",
      "text" : "A decade ago, a TREC task called ”Filtering” (Robertson and Soboroff, 2002) had the following definition: finding documents relevant to a query in a stream of data. Effective approaches\nwere inspired by information retrieval techniques to score documents (Okapi (Robertson and al, 2002), Rocchio (Schapire and al, 1998), ...).\nIn 2012, a new TREC task called ”Knowledge Base Acceleration” (KBA) (Frank and al, 2012) started with a more entity centric definition: filtering a time-ordered corpus for documents that are related to a set of entities from Wikipedia. The best performing approach used one classifier (SVM) by entity tracked with features representing whether or not a term is in a document, regardless of its frequency (Kjersten and McNamee, 2012). Training data have however to be provided for each new entity ”followed”. Another successful approach capture intrinsic characteristics of related documents by relying on document centric features, entity profile related features and time features (Bonnefoy and al, 2013).\nRecently information filtering on Twitter emerged. (Lee, 2012) for instance followed the evolution of big and short terms events, like natural disasters, in real-time. RepLab 2012 Filtering task (Amigò and al, 2012) follows the KBA 2012 definition but focus on Twitter as the source of incoming data (instead of news, blogs and forum posts). The submitted approaches rely on various sources of evidence like named entity recognition (Villena-Román and al, 2012), matches of terms between tweets and Wikipedia (Younus and al, 2012) or the importance of features specific to Twitter such as the presence of a user name in a tweet (Peetz and al, 2012) or the number of hashtags (Chenlo and al, 2012).\nMerging metrics or methods used in natural language processing (NLP) and information retrieval can be seen, as shown in (Lamontagne and Abi-zeid, 2006), as a multicriteria optimization problem: in particular, the ELECTRE methods (Figueira and al, 2005), which turned out to be efficient applied to industrial domains (Gourion and Josselin, 2012), have been transposed to an NLP context (Carrillo and al, 2012) opted for a voting method to combine their runs with (Chenlo and al, 2012)."
    }, {
      "heading" : "3 Methods",
      "text" : ""
    }, {
      "heading" : "3.1 Cosine distance (TF-IDF-Gini)",
      "text" : "The first approach consists in a supervised classification based on a cosine similarity. Vectors used to compute similarities are built using the Term Frequency-Inverse Document Frequency (TFIDF) (Salton and Buckley, 1988) and the Gini purity criterion (Torres and al, 2012).\nTweets are cleansed by removing hypertext links and punctuation marks, hashtags and @ before a user name. We have removed a set of tool-words and some entities ID. Terms are lower-cased. We generate a list of n-grams by using the Gini purity criterion.\nWe create terms (words or n-grams) models for both classes (related and unrelated tweets) and term frequencies are computed with the TF-IDF and Gini criterion. These models take into account the following meta-data: user id, entity id and language integrated as terms in the bag-of-terms of tweets.\nA cosine similarity measures the distance between the bag-of-terms of a tweet and the whole bag built for each class and ranks tweets according to this measure."
    }, {
      "heading" : "3.2 KNN with discriminant features",
      "text" : "The system tries to match each tweet in the test set with the K most similar tweets in the training set. Tweet similarity is computed using Jaccard measure on the bag-of-words discriminant representation of the tweets. As in section 3.1, each tweet is represented as a vector whose components are weighted according to TF-IDF and the Gini purity criterion. The process also takes into account tokens created from the meta-data (author, entity-id). The stoplist of section 3.1 has been used."
    }, {
      "heading" : "3.3 Adaptation KBA’12 system",
      "text" : "For the KBA filtering task, a state-of-the-art approach consist in capturing intrinsic characteristics of highly relevant documents by mean of three types of features: document centric features, entity’s profile features, and time features (Bonnefoy and al, 2013). Features are computed for each candidate document and, using a Random Forest classifier, used to determine if the document is related or not to a given entity.\nUnlike previous approaches it doesn’t require a new set of examples for each new entity. We want to measure the robustness of this approach by using it on another type of documents (i.e. tweets). No adjustments are made on it but tweets are however preprocessed: stop-words are deleted as well as @ before user names and hashtags are split. The classifier is trained on all related and unrelated examples for each type of entities (automotive, universities, banking and music/artists)."
    }, {
      "heading" : "4 Merging algorithms",
      "text" : "To improve the performances we use three ways of combining our systems outputs."
    }, {
      "heading" : "4.1 Linear combination of outputs score",
      "text" : "N systems are available. For each tweet T of the test set, one system j associates each label Lk with a confidence score sj(T,Lk) (j = 1, ..., N). The output entity label L is chosen according to the following rule :\nL = argmaxk\n\n\nN ∑\nj=1\nsj(T,Lk)\n\n (1)"
    }, {
      "heading" : "4.2 ELECTRE I method",
      "text" : "The goal of this method (Roy, 1991) is to choose the best label from the entire set of labels ranked according to the different systems.\nA relation S ⊂ L × L, denoted “over-ranking”, is defined on the label set L: a label l over-ranks another label l′ if l dominates l′ on an “important” number of systems and if l′ does not dominate “too much” l on the remaining systems.\nMore precisely, for each pair of labels (l, l′), a concordance index c(l, l′) is computed, corresponding to the proportion of systems where l dominates l′. l over-ranks l′ if c(l, l′) exceeds a concordance threshold, generally fixed around 2/3 and if l is not dominated by l′ on the remaining systems above a veto threshold, which has been fixed here to v = 0.5.\nThe set of the best labels, possibly empty and denoted as the kernel of the relation S , consists in the labels which are not overanked by others. If there is no, or more than one, label in the kernel, this method is discarded and the merging algorithm described in\nthe previous subsection, based on a linear combination of the scores, is applied."
    }, {
      "heading" : "4.3 PROMETHEE mono-criterion method",
      "text" : "This method relies on a concordance matrix: for each pair of labels (li, lj), the matrix coefficient cij corresponds to the concordance index c(li, lj) introduced in the previous subsection.\nFor each label li, two sums are computed: sl(li) = ∑ j cij and sc(li) = ∑\nj cji. sl(li) measures the tendency of li to dominate the other labels, and sl(li) the tendency of li to be dominated.\nThe final score of the label li is the difference sl(li) − sc(li) and the dominant label is the one whose score is maximal."
    }, {
      "heading" : "5 Experiments",
      "text" : ""
    }, {
      "heading" : "5.1 Replab 2013 Framework",
      "text" : "The corpus is a bilingual (English and Spanish) collection of tweets containing the name of one of the 61 entities selected in four domains: automotive, banking, universities and music/artists. Tweets have been collected by querying the Twitter search engine1. The dataset covers a period going from the 1st of June 2012 to the 31st of December 2012. 42,700 tweets have been provided for training purpose and 100,000 tweets for the evaluation. The training set is composed of the 700 first tweets retrieved for each entity. For each entity, at least 2,200 tweets have been collected.\nTweets, however, are not homogeneously distributed across the entities.\nSystems are evaluated according to the following measures: Accuracy, Reliability and Sensitivity (Amigò and al, 2013). Reliability is defined as precision of binary relationships predicted by the system with respect to those that derive from the gold standard; and Sensitivity is similarly defined as recall of relationships. A F-measure is then used to combine both scores.\nThese measures are well adapted to the task but are really severe on unbalanced datasets."
    }, {
      "heading" : "5.2 Results",
      "text" : "Table 1 shows results of our approaches against the official RepLab 2013 baseline and the median sys-\n1http://twitter.com/search\ntem among participants. The baseline2 is a supervised system that matches each tweet in the test set with the most similar tweet in the training set, and assumes that the annotations in the tweet from the training set are also valid for the tweet in the test set. Tweet similarity is computed using Jaccard distance and a straightforward bag-of-words representation of the tweets.\nThe method described in section 3.2 can be considered as an improved version of the baseline.\nTwo systems (KNN and KBA with a F-measure scores of respectively .381 and .341) have reached greater performances than the baseline on every measures. The confidence interval (.002 and .005 respectively for accuracy and F-Measure) computed following Polling Method (Voorhees, 1998) shows that the difference between the systems is significant.\nMerging strategies R-Elec (for ELECTRE) and R-LC (for Linear Combination) did not produce good selection rules since their performances remain lower than the best system taken alone.A natural merging strategy consisting in merging only the best systems on a development set gives better results (Naive LC and Naive Elec).\nMoreover, a multi pass strategy (MPMS) merging systems in pair before considering merging all pairs improves Sensitivity and thus the F-Measure (.400) despite of a loss in term of accuracy and reliability. Finally, merging only the best (OTB) runs on each measure gives quite similar improvements.\n2http://www.limosine-project.eu/events/replab2013\nThese results show that using merging strategies to combine different systems lead to improvements, whatever the metric chosen. The key observation is that it is possible to pick a merging strategy according to the metrics we choose to focus on. A quite naive merging strategy (Naive) seems to result in a better precision (improvements in both Accuracy and Reliability). On the contrary, adopting a multi pass strategy (MPMS) allow to give a highest priority to recall in both classes (i.e. Sensitivity). Finally, if a compromise is preferred, we saw that promoting systems that did well on each measure (OTB) is a good option."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper we presented some of the interesting features of the systems that we evaluated within the framework provided by RepLab 2013 as well as their performances. We proposed several combinations of them using different merging strategies in order to take benefit from the diversity of information offered by our systems. We also showed that these merging strategies have to be applied depending on the evaluation measures to offer in one hand the best results according to a specific measure or in the other hand to obtain a trade-off. Since a merging strategy cannot get the best score according to each metrics, we can accept a loss according to one metric if it has a real impact on the task official measures.\nA more advanced view would be to apply a specific merger entity by entity, especially for unbalanced entities."
    } ],
    "references" : [ {
      "title" : "A",
      "author" : [ "A. Davis", "A. Veloso" ],
      "venue" : "da Silva, W. M. Jr. and A. Laender. Named entity disambiguation in streaming data. Proceedings of the 50th meeting of the ACL",
      "citeRegEx" : "Davis and al2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "O’Riordan and G",
      "author" : [ "C A. Younus" ],
      "venue" : "Pasi. CIRGDISCO at RepLab2012 Filtering Task: A Two-Pass Approach for Company Name Disambiguation in Tweets. in proceedings of CLEF",
      "citeRegEx" : "Younus and al2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "The hltcoe approach to the trec 2012 kba track",
      "author" : [ "B. Kjersten", "P. McNamee" ],
      "venue" : "Proceedings of The 21th TREC",
      "citeRegEx" : "Kjersten and McNamee2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "The outranking approach and the foundations of ELECTRE methods",
      "author" : [ "B. Roy" ],
      "venue" : "Theory and Decision,",
      "citeRegEx" : "Roy.,? \\Q1991\\E",
      "shortCiteRegEx" : "Roy.",
      "year" : 1991
    }, {
      "title" : "Aide à la décision robuste pour la localisation d’un centre de traitement des déchets",
      "author" : [ "Gourion", "Josselin2012] D. Gourion", "D. Josselin" ],
      "venue" : "Comparaison de méthodes d’analyse multicritères. Annales de l’ISUP",
      "citeRegEx" : "Gourion et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gourion et al\\.",
      "year" : 2012
    }, {
      "title" : "Overview of RepLab 2012: Evaluating Online Reputation Management Systems",
      "author" : [ "E. Amigò", "A. Corujo", "J. Gonzalo", "E. Meij", "M. de Rijke" ],
      "venue" : "proceedings of CLEF",
      "citeRegEx" : "Amigò and al2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A General Evaluation Measure for Document Organization Tasks",
      "author" : [ "E. Amigò", "J. Gonzalo", "F. Verdejo" ],
      "venue" : "SIGIR",
      "citeRegEx" : "Amigò and al2013",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "1998",
      "author" : [ "Ellen M. Voorhees" ],
      "venue" : "Variations in Relevance Judgements and the Measurement of Retrieval Effectiveness. Information Processing and Management, 36(5), 697–716.",
      "citeRegEx" : "Voorhees1998",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Term weighting approaches in automatic text retrieval, pp 513–523",
      "author" : [ "Salton", "Buckley1988] G. Salton", "C. Buckley" ],
      "venue" : "Information Processing and Management",
      "citeRegEx" : "Salton et al\\.,? \\Q1988\\E",
      "shortCiteRegEx" : "Salton et al\\.",
      "year" : 1988
    }, {
      "title" : "Using an Emotion-based Model and Sentiment Analysis Techniques to Classify Polarity for Reputation",
      "author" : [ "J. Carrillo de Albornoz", "I. Chugur", "E. Amigò" ],
      "venue" : "proceedings of CLEF",
      "citeRegEx" : "Carrillo and al2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "FBM-Yahoo! at RepLab 2012",
      "author" : [ "J. Chenlo", "J. Atserias", "C. Rodriguez", "R. Blanco" ],
      "venue" : "proceedings of CLEF",
      "citeRegEx" : "Chenlo and al2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Building an entity-centric stream filtering test collection for trec 2012",
      "author" : [ "J. Frank", "M. Kleiman-Weiner", "D. Roberts", "F. Niu", "C. Zhang", "C. Ré" ],
      "venue" : "Proceedings of The 21th TREC",
      "citeRegEx" : "Frank and al2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Multiple Criteria Decision Analysis: State of the Art Surveys",
      "author" : [ "J. Figueira", "S. Greco", "M. Ehrgott" ],
      "venue" : "Springer Verlag",
      "citeRegEx" : "Figueira and al2005",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Mining spatio-temporal information on micro-blogging streams using a density-based online clustering method",
      "author" : [ "J. Lee" ],
      "venue" : "Expert Systems with Applications",
      "citeRegEx" : "Lee2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Bellot and F",
      "author" : [ "J M. Torres-Moreno", "P M. El-Beze" ],
      "venue" : "Bechet.",
      "citeRegEx" : "Torres and al2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A Weakly-Supervised Detection of Entity Central Documents in a Stream",
      "author" : [ "L. Bonnefoy", "V. Bouvier", "P. Bellot" ],
      "venue" : "SIGIR",
      "citeRegEx" : "Bonnefoy and al2013",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Combining Multiple Similarity Metrics Using a Multicriteria Approach",
      "author" : [ "Lamontagne", "Abi-zeid2006] L. Lamontagne", "I. Abi-zeid" ],
      "venue" : "Proceedings of ECCBR",
      "citeRegEx" : "Lamontagne et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Lamontagne et al\\.",
      "year" : 2006
    }, {
      "title" : "From Sentiment to Reputation ILPS at RepLab 2012",
      "author" : [ "M. Hendrike Peetz", "M. de Rijke", "A. Schuth" ],
      "venue" : "proceedings of CLEF",
      "citeRegEx" : "Peetz and al2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Kernel methods for document filtering",
      "author" : [ "N. Cancedda", "C. Goutte", "J.M. Renders", "N. Cesa-Bianchi", "A. Conconi", "Y. Li", "J. Shawe-Taylor", "A. Vinokourov", "T. Graepel", "C. Gentile" ],
      "venue" : "Proceedings of The 11th TREC",
      "citeRegEx" : "Cancedda and al2002",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "The trec 2002 filtering track report",
      "author" : [ "S. Robertson", "I. Soboroff" ],
      "venue" : "Proceedings of The 11th TREC",
      "citeRegEx" : "Robertson and Soboroff2002",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Microsoft cambridge at trec 2002: Filtering track",
      "author" : [ "S. Robertson", "S. Walker", "H. Zaragoza", "R. Herbrich" ],
      "venue" : "Proceedings of The 11th TREC",
      "citeRegEx" : "Robertson and al2002",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Boosting and rocchio applied to text filtering",
      "author" : [ "Schapire", "al1998] R. Schapire", "Y. Singer", "A. Singhal" ],
      "venue" : null,
      "citeRegEx" : "Schapire et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Schapire et al\\.",
      "year" : 1998
    }, {
      "title" : "Maximum likelihood estimation for filtering thresholds",
      "author" : [ "Zhang", "Callan2001] Y. Zhang", "J. Callan" ],
      "venue" : null,
      "citeRegEx" : "Zhang et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2001
    } ],
    "referenceMentions" : [ ],
    "year" : 2015,
    "abstractText" : "Twitter is now a gold marketing tool for entities concerned with online reputation. To automatically monitor online reputation of entities, systems have to deal with ambiguous entity names, polarity detection and topic detection. We propose three approaches to tackle the first issue: monitoring Twitter in order to find relevant tweets about a given entity. Evaluated within the framework of the RepLab2013 Filtering task, each of them has been shown competitive with state-of-the-art approaches. Mainly we investigate on how much merging strategies may impact performances on a filtering task according to the evaluation measure.",
    "creator" : "LaTeX with hyperref package"
  }
}