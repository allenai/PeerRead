{
  "name" : "1401.3872.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Second-Order Consistencies",
    "authors" : [ "Christophe Lecoutre", "Stéphane Cardon", "Julien Vion" ],
    "emails" : [ "lecoutre@cril.fr", "cardon@cril.fr", "julien.vion@univ-valenciennes.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "consistencies identifying inconsistent pairs of values) for constraint satisfaction. We build a full picture of the relationships existing between four basic second-order consistencies, namely path consistency (PC), 3-consistency (3C), dual consistency (DC) and 2-singleton arc consistency (2SAC), as well as their conservative and strong variants. Interestingly, dual consistency is an original property that can be established by using the outcome of the enforcement of generalized arc consistency (GAC), which makes it rather easy to obtain since constraint solvers typically maintain GAC during search. On binary constraint networks, DC is equivalent to PC, but its restriction to existing constraints, called conservative dual consistency (CDC), is strictly stronger than traditional conservative consistencies derived from path consistency, namely partial path consistency (PPC) and conservative path consistency (CPC). After introducing a general algorithm to enforce strong (C)DC, we present the results of an experimentation over a wide range of benchmarks that demonstrate the interest of (conservative) dual consistency. In particular, we show that enforcing (C)DC before search clearly improves the performance of MAC (the algorithm that maintains GAC during search) on several binary and non-binary structured problems."
    }, {
      "heading" : "1. Introduction",
      "text" : "Many decision problems are combinatorial by nature, and can be modelled using finite domain variables connected with constraints. Such models are formally represented as constraint networks (CNs) and finding a solution to a model is an instance of the NP-complete constraint satisfaction problem (CSP). The CSP is usually solved through systematic backtrack search, a fundamental technique in artificial intelligence. There have been considerable efforts during the last three decades to improve the practical efficiency of backtrack search.\nConsistencies are properties of constraint networks that can be exploited (enforced), before or during search, to filter the search space of problem instances by inference. Currently, the most successful consistencies are domain filtering consistencies (Debruyne & Bessiere, 2001; Bessiere, Stergiou, & Walsh, 2008). Common consistencies for binary CNs are arc consistency (AC, Mackworth, 1977) and singleton arc consistency (SAC, Bessiere & De-\nc©2011 AI Access Foundation. All rights reserved.\nbruyne, 2005). Example consistencies for non-binary CNs are generalized arc consistency (GAC, Mohr & Masini, 1988) and pairwise inverse consistency (PWIC, Stergiou & Walsh, 2006). Consistencies typically allow the identification of nogoods. A nogood is an instantiation of some variables that cannot lead to any solution. Identifying relevant nogoods as soon as possible when exploring the search space of an instance is recognized as an essential component of a backtracking search algorithm. A domain-filtering consistency is also called a first-order consistency, meaning that it only detects inconsistent values (1-sized nogoods): these values can be safely removed from the domains of the variables.\nThis paper is concerned with second-order consistencies that locally identify inconsistent pairs of values. The most studied second-order consistency is path consistency (PC, Montanari, 1974; Mackworth, 1977). For now, path consistency, and more generally higher order consistencies, are rather neglected by designers and developers of general constraint solvers. This is somewhat surprising since, for many tractable classes, strong path consistency (path consistency combined with arc consistency) is a sufficient condition to determine satisfiability (e.g., see Dechter, 1992; van Beek, 1992; Cooper, Cohen, & Jeavons, 1994; Zhang & Yap, 2006). Neglecting higher order consistencies may partly be due to the somewhat limited scope of these classes: exciting progress in this area has only been very recent (e.g., see Green & Cohen, 2008). However, path consistency has an important role in temporal reasoning. Indeed, for some classes of interval algebra, path consistency – adapted to temporal constraint networks (Allen, 1983) – is sufficient to decide satisfiability. Another possible reason for the low practical interest for path consistency, in the discrete constraint satisfaction field, is that path consistency enforcement modifies constraint relations, and more importantly, modifies the structure of the constraint graph. When a pair of values (a, b) for the variables (x, y) is found to be path-inconsistent, this information is recorded within the constraint network; if there is no constraint binding x with y, a new one is inserted, thus changing the constraint graph. For example, the instance scen-11 of the radio link frequency assignment problem (Cabon, de Givry, Lobjois, Schiex, & Warners, 1999) involves 680 variables and 4,103 constraints. Enforcing a second-order consistency on this network could at worst create (680 2 ) − 4,103 = 226,757 new constraints, which would be really counter-productive both in time and in space. The main apparent drawback of path consistency can be avoided by adopting a conservative approach, in which the search for inconsistent pairs of values is restricted to existing constraints. This is called conservative path consistency (CPC, Debruyne, 1999) when restricted to paths of length 2 in the constraint graph, and partial path consistency (PPC, Bliek & Sam-Haroud, 1999) when restricted to paths of arbitrary length in the constraint graph; CPC and PPC are equivalent when the constraint graph is triangulated.\nIn this paper, we study path consistency as well as three other basic second-order consistencies that are 3-consistency (3C, Freuder, 1978), dual consistency (DC, Lecoutre, Cardon, & Vion, 2007a) and 2-singleton arc consistency (2SAC, Bessiere, Coletta, & Petit, 2005). On binary constraint networks, DC is equivalent to PC – McGregor (1979) proposed an DC-like algorithm to establish (strong) path consistency – but when considering weaker conservative variants, we show that conservative dual consistency (CDC) is strictly stronger than PPC and CPC: CDC can filter out more inconsistent pairs of values (from existing constraints) than PPC or CPC. We build a full picture of the qualitative relationships existing between all those second-order consistencies (including the stronger 2SAC property, the conserva-\ntive restrictions and strong variants of all studied consistencies) for both binary CNs and non-binary CNs.\nInterestingly enough, (conservative) dual consistency benefits from some nice features: (1) as (C)DC is built on top of GAC, implementing a filtering algorithm to enforce it is rather easy, (2) for the same reason, all optimizations achieved on GAC algorithms these last years come for free, (3) we have the guarantee that GAC enforced on a CN that verifies the property (C)DC leaves the property unchanged. This is why our theoretical study is followed by the presentation of a general algorithm to enforce strong (C)DC and an experimental study to show the practical interest of using (C)DC (during a preprocessing step) when solving binary and non-binary problem instances with a search algorithm such as MAC (Sabin & Freuder, 1994).\nThe paper is organized as follows. Section 2 introduces technical background about constraint networks, nogoods and consistencies. In Section 3, we introduce (basic, conservative and strong) second-order consistencies, with a focus on path consistency and a possible misunderstanding about it. A qualitative study about second-order consistencies is conducted in Section 4. An algorithm to enforce (C)DC is proposed in Section 5, and experimental results are presented in Section 6. Finally, we conclude."
    }, {
      "heading" : "2. Technical Background",
      "text" : "This section provides technical background about constraint networks and consistencies."
    }, {
      "heading" : "2.1 Constraint Networks",
      "text" : "A (finite) constraint network (CN) P is composed of a finite set of n variables, denoted by vars(P ), and a finite set of e constraints, denoted by cons(P ). Each variable x has an associated domain, denoted by dom(x), that contains the finite set of values that can be assigned to x. Each constraint c involves an ordered set of variables, called the scope of c and denoted by scp(c). It is defined by a relation, denoted by rel(c), which contains the set of tuples allowed for the variables involved in c. The arity of a constraint c is the size of scp(c). The maximum domain size and the maximum arity for a given CN will be denoted by d and r, respectively. A binary constraint involves exactly 2 variables, and a non-binary constraint strictly more than 2 variables. A binary CN only contains binary constraints whereas a non-binary CN contains at least one non-binary constraint.\nThe initial domain of a variable x is denoted by dominit(x) whereas the current domain of x in the CN P is denoted by domP (x) or more simply dom(x) when the context is unambiguous. The initial relation of a constraint c is denoted by relinit(c) whereas the current relation is denoted by relP (c) or more simply rel(c). A constraint c is universal iff relinit(c) = Πx∈scp(c) dominit(x); a universal constraint imposes no restriction. We consider that for any variable x, we always have dom(x) ⊆ dominit(x), and for any constraint c, we always have rel(c) ⊆ relinit(c). To simplify, a pair (x, a) with x ∈ vars(P ) and a ∈ dom(x) is called a (current) value of P . Without any loss of generality, we only consider CNs that involve neither unary constraints (i.e., constraints involving a unique variable) nor\nconstraints of similar scope – CNs are normalized (Apt, 2003; Bessiere, 2006). The set of normalized CNs with neither unary constraints nor universal constraints1 is denoted by P.\nAn instantiation I of a set X = {x1, . . . , xk} of variables is a set {(x1, a1), . . . , (xk, ak)} such that ∀i ∈ 1..k, ai ∈ dominit(xi) ; the set X of variables occurring in I is denoted by vars(I) and each value ai is denoted by I[xi]. An instantiation I on a CN P is an instantiation of a set X ⊆ vars(P ); it is complete iff vars(I) = vars(P ), partial otherwise. I is valid on P iff ∀(x, a) ∈ I, a ∈ domP (x). An instantiation I covers a constraint c iff scp(c) ⊆ vars(I), and satisfies a constraint c with scp(c) = {x1, . . . , xr} iff (1) I covers c and (2) the tuple (a1, . . . , ar) is allowed by c, i.e., (a1, . . . , ar) ∈ rel(c), where ∀i ∈ 1..r, ai = I[xi]. A support (resp., a conflict) on a constraint c is a valid instantiation of scp(c) that satisfies (resp., does not satisfy) c. An instantiation I on a CN P is locally consistent iff (1) I is valid on P and (2) every constraint of P covered by I is satisfied by I. It is locally inconsistent otherwise. A solution of P is a complete instantiation on P that is locally consistent. An instantiation I on a CN P is globally inconsistent, or a nogood, iff it cannot be extended to a solution of P . It is globally consistent otherwise. We refer here to standard nogoods (e.g., see Dechter, 2003); they differ from nogoods coming with justifications (Schiex & Verfaillie, 1994) and from generalized ones (Katsirelos & Bacchus, 2003). Two CNs P and P ′ defined on the same variables are equivalent iff they have the same solutions.\nA CN is said to be satisfiable iff it admits at least one solution. The Constraint Satisfaction Problem (CSP) is the NP-complete task of determining whether a given CN is satisfiable or not. Thus, a CSP instance is defined by a CN which is solved either by finding a solution or by proving unsatisfiability. In many cases, a CSP instance can be solved by using a combination of search and inferential simplification (Dechter, 2003; Lecoutre, 2009). To solve a CSP instance, a depth-first search algorithm with backtracking can be applied, where at each step of the search, a variable assignment is performed followed by a filtering process called constraint propagation. Constraint propagation algorithms enforce some consistency property, they identify and record explicit nogoods in CNs. When identified nogoods are of size 1, they correspond to inconsistent values.\nIt is usual to refer to some properties of the (hyper)graphs that can be associated with any CN. On the one hand, the constraint (hyper)graph, also called macro-structure, associated with a (normalized) CN P consists of n vertices corresponding to the variables of P and also e (hyper)edges corresponding to the constraints of P : an (hyper)edge connects vertices corresponding to the variables in the scope of the constraint it represents. On the other hand, the compatibility (hyper)graph, also called micro-structure (Jégou, 1993), associated with a normalized CN P contains one vertex per value of P and one (hyper)edge per constraint support. It corresponds to a n-partite hypergraph with one part for each variable. Sometimes, incompatibility (hyper)graphs are used by authors where (hyper)edges correspond to conflicts instead of supports. In this paper, (hyper)edges for supports (resp., conflicts) will be drawn using solid (resp., dashed) lines.\nIt is sometimes helpful to use a homogeneous representation of a CN, wherein domains and also constraints are replaced by nogoods. The nogood representation of a CN is a set of nogoods, one for every value removed from the initial domain of a variable and one\n1. For our theoretical study, universal constraints can be safely ignored. In practice, any universal constraint c in a CN P may artificially be considered as non-universal: choose a variable x ∈ scp(c) and consider a dummy value ν such that ν ∈ dominit(x) \\ domP (x) and relinit(c) forbids one tuple involving (x, ν).\nfor every tuple forbidden by a constraint. More precisely, the nogood representation x̃ of a variable x is the set of instantiations { {(x, a)} | a ∈ dominit(x) \\ dom(x) } . The nogood representation c̃ of a constraint c, with scp(c) = {x1, . . . , xr}, is the set of instantiations{ {(x1, a1) , . . . , (xr, ar)} | (a1, . . . , ar) ∈ (∏ x∈scp(c) dominit(x) ) \\ rel(c) } . The nogood repre-\nsentation P̃ of a CN P is the set of instantiations (⋃ x∈vars(P ) x̃ ) ∪ (⋃ c∈cons(P ) c̃ ) .\nInstantiations in P̃ are explicit nogoods of P (recorded through domains and constraints). Notice that when a nogood is a superset of another one, it is subsumed. Intuitively, a nogood that is subsumed is not relevant as it is less general than at least another one, and two CNs are nogood-equivalent – a related definition is Definition 3.11 in the work of Bessiere (2006) – when they have the same canonical form, i.e., represent exactly the same set of “unsubsumed” nogoods. To relate CNs, we introduce a general partial order.2 Let P and P ′ be two CNs defined on the same variables (i.e., such that vars(P ) = vars(P ′)), P ′ P iff P̃ ′ ⊇ P̃ and P ′ ≺ P iff P̃ ′ ) P̃ . (P, ) is a partially ordered set (poset) because is reflexive, antisymmetric (remember that no CN in P can involve universal constraints) and transitive. As CNs are normalized and no unary or universal constraint is present, there is therefore only one manner to discard (or remove) an instantiation from a given CN, or equivalently to “record” a new explicit nogood in a CN. Given a CN P in P, and an instantiation I on P , P \\ I denotes the CN P ′ in P such that vars(P ′) = vars(P ), and P̃ ′ = P̃ ∪ {I}. P \\ I is an operation that retracts I from P and builds a new CN, not necessarily with the same set of constraints. Let us show how P ′ is built. If I ∈ P̃ , of course we have P ′ = P \\ I = P : this means that the instantiation I was already an explicit nogood of P . The interesting case is when I /∈ P̃ . If I corresponds to a value a for a variable x, i.e., I = {(x, a)}, it suffices to remove a from dom(x). If I corresponds to a tuple allowed by a constraint c of P , it suffices to remove this tuple from rel(c). Otherwise, we must introduce a new constraint whose associated relation contains all possible tuples (built from initial domains) except the one that corresponds to the instantiation I. Note that removing a tuple from a relation rel(c) can be a problem in practice if the constraint c is defined in intension (i.e., by a predicate). However, for binary nogoods (our concern), this is not a real problem because, except when variables have very large domains, it is always possible to translate (efficiently) an intensional constraint in extension."
    }, {
      "heading" : "2.2 Consistencies",
      "text" : "A consistency is a general property of a CN. When a consistency φ holds on a CN P , we say that P is φ-consistent. If φ and ψ are two consistencies, a CN P is said to be φ+ψconsistent iff P is both φ-consistent and ψ-consistent. A consistency φ is nogood-identifying iff the reason why a CN P is not φ-consistent is that some instantiations, which are not in P̃ , are identified as globally inconsistent by φ. Such instantiations correspond to (new identified) nogoods and are said to be φ-inconsistent (on P ). A kth-order consistency is a nogood-identifying consistency that allows the identification of nogoods of size k, where k ≥ 1 is an integer. kth-order consistency should not be confused with k-consistency (Freuder, 1978, 1982): k-consistency holds iff every locally consistent instantiation of a\n2. This partial order is general enough for our purpose, but note that more sophisticated partial orders (or preorders) exist (e.g., by taking account of subsumed nogoods).\nset of k − 1 variables can be extended to a locally consistent instantiation involving any additional variable. In our terminology, this is a (k − 1)th-order consistency.\nA domain-filtering consistency is a first-order consistency. A conservative consistency φ is a nogood-identifying consistency such that, for every given CN P , every φ-inconsistent instantiation on P corresponds to a tuple currently allowed by an explicit constraint of P . To compare the pruning capability of consistencies, we introduce a preorder (see Debruyne & Bessiere, 2001). A consistency φ is stronger than (or equal to) ψ iff whenever φ holds on a CN P , ψ also holds on P . φ is strictly stronger than ψ iff φ is stronger than ψ and there exists at least one CN P such that ψ holds on P but not φ. When some consistencies cannot be ordered (none is stronger that another), we say that they are incomparable.\nWe now briefly introduce a formal characterization of constraint propagation, based on the concept of stability (following Lecoutre, 2009). This formalism is also related to previous works about local consistencies and rules iteration (e.g., see Montanari & Rossi, 1991; Apt, 1999, 2003; Bessiere, 2006). It is usually possible to enforce φ on a CN P by computing the greatest φ-consistent CN smaller than or equal to P , while preserving the set of solutions. A consistency is well-behaved when for any CN P ∈P, the set {P ′ ∈P | P ′ is φ-consistent and P ′ P} admits a greatest element, denoted by φ(P ), that is equivalent to P and called the φ-closure of P . Enforcing φ on a CN P means computing φ(P ), and an algorithm that enforces φ is called a φ-algorithm. The property of stability is useful for proving that a nogood-identifying consistency is well-behaved.\nA nogood-identifying consistency φ is stable iff for every CN P ∈P, every CN P ′ ∈P such that P ′ P and every φ-inconsistent instantiation I on P , we have either I ∈ P̃ ′ or I is φ-inconsistent on P ′; the second condition for stability given by Lecoutre (2009) holds necessarily because of the choice of the poset in this paper. The fact that either I ∈ P̃ ′ or I is φ-inconsistent on P ′ guarantees that no φ-inconsistent instantiation on a CN can be missed when the CN is made tighter: either it is discarded (has become an explicit nogood of P ′) or it remains φ-inconsistent.\nTheorem 1. (Lecoutre, 2009) Any stable nogood-identifying consistency is well-behaved.\nThe stability of a nogood-identifying consistency φ provides a general procedure for computing the φ-closure of any CN: iteratively discard (in any order) φ-inconsistent instantiations until a fixed point is reached. Provided that the procedure is sound (each removal corresponds to a φ-inconsistent instantiation) and complete (each φ-inconsistent instantiation is removed), the procedure is guaranteed to compute φ-closures. More generally, when different reduction rules are used, each must be shown to be correct, monotonic and inflationary. We can then benefit from a generic iteration algorithm (Apt, 2003, Lemmas 7.5, 7.8 and Theorem 7.11). Stability under union can also be proved for a domain-filtering consistency, thus guaranteeing a fixed point (Bessiere, 2006). An interesting result follows:\nProposition 1. Let φ and ψ be two well-behaved (nogood-identifying) consistencies. φ is stronger than ψ iff for every CN P ∈P, we have φ(P ) ψ(P ).\nWe conclude this section with some well-known domain-filtering consistencies. First, let us introduce generalized arc consistency (GAC). A support (resp., a conflict) for a value (x, a) of P on a constraint c involving x is a support (resp., a conflict) I on c such that I[x] = a. A value (x, a) of P is GAC-consistent iff there exists a support for (x, a) on every\nconstraint of P involving x. P is GAC-consistent iff every value of P is GAC-consistent. We also say that a constraint c is GAC-consistent iff for every variable x in scp(c) and every value a in dom(x), (x, a) is GAC-consistent. For binary CNs, GAC is referred to as AC (Arc Consistency). Second, we introduce some “singleton” consistencies (Debruyne & Bessiere, 1997b; Prosser, Stergiou, & Walsh, 2000). When the domain of a variable of P is empty, P is clearly unsatisfiable, which is denoted by P = ⊥. The CN P |x=a is obtained from P by removing every value b 6= a from dom(x). A value (x, a) of P is SAC-consistent (SAC stands for Singleton Arc Consistent3) iff GAC (P |x=a) 6= ⊥ (this is called a singleton check). A value (x, a) of P is BiSAC-consistent iff GAC (P ia|x=a) 6= ⊥, where P ia is the CN obtained after removing every value (y, b) of P such that y 6= x and (x, a) /∈ GAC(P |y=b) (Bessiere & Debruyne, 2008). P is SAC-consistent (respectively, BiSAC-consistent) iff every value of P is SAC-consistent (respectively, BiSAC-consistent). BiSAC is strictly stronger than SAC, which is itself strictly stronger than GAC; BiSAC is also strictly weaker than strong path consistency (Bessiere & Debruyne, 2008). GAC, SAC and BiSAC are well-behaved; for example, SAC (P ) denotes the SAC-closure of the CN P ."
    }, {
      "heading" : "3. Second-Order Consistencies",
      "text" : "In this section, we introduce second-order consistencies. First, we start with the most famous one: path consistency. Then, we clarify some aspects of path consistency that are sometimes misrepresented in the literature, and introduce its known restricted forms. Finally, we introduce 3-consistency, dual consistency, and 2-singleton arc consistency as well as their conservative and strong variants."
    }, {
      "heading" : "3.1 Path Consistency",
      "text" : "Among the consistencies that allow us to identify inconsistent pairs of values, path consistency plays a central role. Introduced by Montanari (1974), its definition has sometimes been misinterpreted. The problem arises around the definition of a “path”, which must be understood as any sequence of variables, and not as a sequence of variables that corresponds to a path in the constraint graph. This ambiguity probably comes from Montanari’s original paper, in which reasoning from path consistency is achieved with respect to complete (or completion of) constraint graphs, although a footnote in the original paper indicates:\n“A path in a network is any sequence of vertices. A vertex can occur more than once in a path even in consecutive positions.”\nA precise definition of path is thus required. The definition of path below is used by Montanari (1974), Mackworth (1977) and Debruyne (1998), while the definition of graphpath is used, for example, by Tsang (1993) or Bessiere (2006). A path is an arbitrary sequence of variables, and a graph-path is defined to be a sequence of variables such that a binary constraint exists between any two variables adjacent in the sequence. For a binary CN P , a graph-path is thus a path in the constraint graph of P . For a non-binary CN P , if all non-binary constraints are discarded (ignored) then a path in the resulting constraint graph is a graph-path. It is important to note that any given variable may occur several times in a path (and so, in a graph-path). Figure 1 gives an illustration. 3. To limit the number of acronyms, we use SAC for both binary and non-binary CNs.\nDefinition 1 (Path). Let P be a CN.\nA path of P is a sequence 〈x1, . . . , xk〉 of variables of P such that x1 6= xk and k ≥ 2; the path is from variable x1 to variable xk, and k − 1 is the length of the path.\nA graph-path of P is a path 〈x1, . . . , xk〉 of P such that ∀i ∈ 1..k − 1, ∃c ∈ cons(P ) | scp(c) = {xi, xi+1}.\nA closed (graph-)path of P is a (graph-)path 〈x1, . . . , xk〉 of P such that ∃c ∈ cons(P ) | scp(c) = {x1, xk}.\nThe central concept of consistent paths is defined as follows:\nDefinition 2 (Consistent Path). Let P be a CN.\n• An instantiation {(x1, a1), (xk, ak)} on P is consistent on a path 〈x1, . . . , xk〉 of P iff there exists a tuple τ ∈ Πki=1 dom(xi) such that τ [x1] = a1, τ [xk] = ak and ∀i ∈ 1..k−1, {(xi, τ [xi]), (xi+1, τ [xi+1])} is a locally consistent instantiation4 on P . The tuple τ is said to be a support for {(x1, a1), (xk, ak)} on 〈x1, . . . , xk〉 (in P ).\n• A path 〈x1, . . . , xk〉 of P is consistent iff every locally consistent instantiation of {x1, xk} on P is consistent on 〈x1, . . . , xk〉.\nIn the example in Figure 2, 〈v, z, x〉 is a consistent path of P since for the locally consistent instantiation {(v, a), (x, b)} we can find b in dom(z) such that {(v, a), (z, b)} is locally consistent (this is trivial since there is an implicit universal binary constraint between v and z) and {(x, b), (z, b)} is locally consistent. Similarly, the second locally consistent instantiation {(v, b), (x, a)} can be extended to z. The closed graph-path 〈v, x, w〉 is not\n4. If xi = xi+1, then necessarily τ [xi] = τ [xi+1] because an instantiation cannot contain two distinct pairs involving the same variable.\nconsistent; the locally consistent instantiation {(v, b), (w, a)} cannot be extended to x. One might be surprised that 〈z, x, v, w, x, y〉 is consistent. It is important to note that we are free to select different values for x along the path. For example, for the locally consistent instantiation {(z, b), (y, a)}, we can find the support τ = (b, b, a, b, a, a) on 〈z, x, v, w, x, y〉. This tuple belongs to dom(z) × dom(x) × dom(v) × dom(w) × dom(x) × dom(y), satisfies τ [z] = b, τ [y] = a and all encountered binary constraints along the path. Along this path we have first (x, b) and subsequently (x, a).\nWe can now introduce the historical definition of path consistency (PC, Montanari, 1974; Mackworth, 1977).\nDefinition 3 (Path Consistency). A CN P is path-consistent, denoted PC-consistent, iff every path of P is consistent.\nThis definition is valid for non-binary CNs. Simply, non-binary constraints are ignored, as Dechter (2003) or Bessiere (2006) do, since in Definition 2, only pairs of variables are considered. Montanari has shown that it is sufficient to consider paths of length two (i.e., sequences of three variables) only. Note that it is not necessary for the constraint graph to be complete (but, when path consistency is enforced, the resulting CN may become complete).\nTheorem 2. (Montanari, 1974) A CN P is path-consistent iff every 2-length path of P (i.e., every sequence of three variables) is consistent.\nThis leads to the following classical definition:\nDefinition 4 (Path Consistency). Let P be a CN.\n• An instantiation5 {(x, a), (y, b)} on P is path-consistent, denoted PC-consistent, iff it is 2-length path-consistent, that is to say, iff there exists a value c in the domain of every third variable z of P such that {(x, a), (z, c)} and {(y, b), (z, c)} are both locally\n5. In this paper, when we refer to an instantiation of the form {(x, a), (y, b)}, we assume that x 6= y.\nconsistent; if {(x, a), (y, b)} is not path-consistent, it is said to be path-inconsistent or PC-inconsistent.\n• P is path-consistent iff every locally consistent instantiation {(x, a), (y, b)} on P is path-consistent."
    }, {
      "heading" : "3.2 Deep in Path Consistency",
      "text" : "Now, we show that path consistency may be easily misinterpreted, and we introduce consistency forms related to PC. A first natural question is: can we restrict our attention to graph-paths (see Definition 1)? The answer is given by the following observation.\nObservation 1. For some CNs, the following properties are not equivalent:\n(a) every path is consistent\n(b) every graph-path is consistent\nProof. Consider, for example, the CN depicted in Figure 3. This CN is not path-consistent since the locally consistent instantiation {(x, b), (z, a)} is not consistent on the path 〈x, y, z〉. If we now limit our attention to graph-paths, these consist only of the variables x and y (for example, 〈x, y〉, 〈x, y, x, y〉, . . . ) and there is no local inconsistency.\nHowever, for a binary CN that has a connected constraint graph (i.e., a constraint graph composed of a single connected component), the restriction to graph-paths is valid.\nProposition 2. Let P be a binary CN such that P 6= ⊥ and the constraint graph of P is connected. P is path-consistent iff every graph-path of P is consistent.\nProof. For one direction (⇒), this is immediate. If P is path-consistent, then by definition every path of P is consistent, including graph-paths.\nFor the other direction (⇐), we show that if every graph-path of P is consistent, then every 2-length path of P is consistent (and thus P is path-consistent using Theorem 2). In practical terms, we consider a locally consistent instantiation {(x, a), (y, b)} and show that for each third variable z of P , the following property Pr(z) holds: ∃c ∈ dom(z) such that {(x, a), (z, c)} and {(y, b), (z, c)} are both locally consistent instantiations. For each variable z three cases must be considered, depending of the existence of the constraints cxz, between x and z (i.e., such that scp(cxz) = {x, z}), and cyz, between y and z.\n(a) Both constraints exist: thus there exists a graph-path 〈x, z, y〉 and as this path is consistent by hypothesis, the property Pr(z) holds.\n(b) Neither constraint exist: P 6= ⊥ implies dom(z) 6= ∅, thus Pr(z) holds because cxz and cyz are implicit and universal.\n(c) Only the constraint cxz exists (similarly, only the constraint cyz exists): as the constraint graph is connected, there exists at least one graph-path from z to y, and consequently a graph-path from x to y of the form 〈x, z, . . . , y〉. This means that there is a value in dom(z) which is compatible with (x, a), by using the hypothesis (every graph-path is consistent). This value is also compatible with (y, b) because there is an implicit universal constraint between z and y. Hence, Pr(z) holds.\nUnsurprisingly (because of Observation 1), a binary CN P such that every 2-length graph-path of P is consistent, is not necessarily path-consistent. Of course, in the special case where the constraint graph is complete, the CN is path-consistent because every path of P is also a graph-path of P .\nObservation 2. For some CNs, the following properties are not equivalent:\n(a) every graph-path is consistent\n(b) every 2-length graph-path is consistent\nProof. See Figure 4.\nWe have the following proposition for 2-length graph-paths.\nProposition 3. Let P be a binary CN such that P 6= ⊥ and P is arc-consistent. P is path-consistent iff every 2-length graph-path of P is consistent.\nProof. The proof is similar to the proof of Proposition 2 by considering 2-length graph-paths instead of graph-paths. Only case (c) in the demonstration differs.\n(c) Only the constraint cxz exists (similarly, only the constraint cyz exists): as P is arcconsistent, there exists a value in dom(z) that is compatible with (x, a). Because there is an implicit universal constraint between z and y, this value is also compatible with (y, b). Hence, Pr(z) holds.\nTheorem 2 and Propositions 2 and 3 suggest that the historical definition of path consistency is appropriate since it corresponds to the strongest form of detection of local inconsistencies using the concept of path (even if considering graph-paths may seem more natural than considering paths). Unfortunately, path consistency has sometimes been misinterpreted. For example, Definition 3-11 in a work of Tsang (1993) links PC to graph-paths, and Proposition 3.39 in a work of Bessiere (2006) links PC to 2-length graph-paths, but Observations 1 and 2 (with Figure 4) show that this is not equivalent to Montanari’s definition. However, it is true that to check path consistency in practice, we only need to consider 2-length graph-paths, provided that binary constraints are arc-consistent.\nTwo different relation-filtering consistencies related to path consistency have been defined in terms of closed graph-paths. The first is partial path consistency (partial PC or PPC, Bliek & Sam-Haroud, 1999) and the second is conservative path consistency (conservative PC or CPC, Debruyne, 1999).\nDefinition 5 (Partial Path Consistency). A CN P is partially path-consistent, denoted PPC-consistent, iff every closed graph-path of P is consistent.\nDefinition 6 (Conservative Path Consistency). A CN P is conservative path-consistent, denoted CPC-consistent, iff every closed 2-length graph-path of P is consistent.\nFor binary constraints, PPC and CPC are equivalent when the constraint graph is triangulated: PPC was initially introduced to build a filtering algorithm that operates on triangulated graphs. A graph is triangulated (or chordal) iff every cycle composed of four or more vertices has a chord, which is an edge joining two vertices that are not adjacent in the cycle.\nProposition 4. (Bliek & Sam-Haroud, 1999) Let P be a binary CN P with a triangulated constraint graph. P is PPC-consistent iff P is CPC-consistent.\nEnforcing path consistency simply means discarding path-inconsistent instantiations (i.e., recording new explicit nogoods of size two) since we know that the PC-closure, denoted PC (P ), of any CN P exists (path consistency is well-behaved). To enforce path consistency it may be necessary to introduce new binary constraints, thus path consistency is not a conservative consistency. PPC and CPC differ in that only existing constraints are altered. As additional weak forms of path consistency, we find directional path consistency (Dechter & Pearl, 1988; Tsang, 1993) and pivot consistency (David, 1995), but they will not be discussed in this paper. Although these consistencies are attractive for controlling the practical inference effort in some situations, both consistencies require the introduction of a variable ordering, which restricts their applicability.\nFinally, two domain-filtering consistencies related to path consistency have also been defined: restricted path consistency (RPC, Berlandier, 1995) and max-restricted path consistency (MaxRPC, Debruyne & Bessiere, 1997a). MaxRPC is strictly stronger than RPC\nand is defined as follows: a value (x, a) of a CN P is max-restricted path consistent, denoted MaxRPC-consistent, iff for every binary constraint cxy of P involving x, there exists a locally consistent instantiation {(x, a), (y, b)} of scp(cxy) = {x, y} such that for every additional variable z of P , there exists a value c ∈ dom(z) such that {(x, a), (z, c)} and {(y, b), (z, c)} are both locally consistent. A CN P is MaxRPC-consistent iff every value of P is MaxRPC-consistent."
    }, {
      "heading" : "3.3 Additional Second-Order Consistencies",
      "text" : "In this section, we introduce second-order consistencies that are defined independently of path consistency. First, we recall 3-consistency (3C, Freuder, 1978).\nDefinition 7 (3-consistency). Let P be a CN.\n• An instantiation {(x, a), (y, b)} on P is 3-consistent, denoted 3C-consistent, iff there exists a value c in the domain of every third variable z of P such that {(x, a), (y, b), (z, c)} is locally consistent.\n• P is 3-consistent iff every locally consistent instantiation {(x, a), (y, b)} on P is 3- consistent.\nNote the difference with path consistency (see Definition 4): here, an instantiation of size 3 must be locally consistent (instead of two instantiations of size 2). It is known that 3C is equivalent to PC when no ternary constraint is present.\nWe now introduce dual consistency (Lecoutre et al., 2007a). Dual consistency, whose idea has initially been used by McGregor (1979), records inconsistent pairs of values identified by successive singleton checks. Just like singleton arc consistency, dual consistency is built on top of generalized arc consistency. Informally, a CN is dual-consistent iff each pair of values that is locally consistent is not detected inconsistent after assigning either of those two values and enforcing GAC. To simplify, we write (x, a) ∈ P iff (x, a) is a value of P , i.e., x ∈ vars(P ) ∧ a ∈ domP (x); when P = ⊥, we consider that for every pair (x, a), we have (x, a) /∈ P .\nDefinition 8 (Dual Consistency). Let P be a CN.\n• An instantiation {(x, a), (y, b)} on P is dual-consistent, denoted DC-consistent, iff (y, b) ∈ GAC (P |x=a) and (x, a) ∈ GAC (P |y=b).\n• P is DC-consistent iff every locally consistent instantiation {(x, a), (y, b)} on P is DC-consistent.\nWe may be interested by checks based on two simultaneous decisions (variable assignments): we obtain 2-singleton arc consistency (2SAC, Bessiere et al., 2005).\nDefinition 9 (2-Singleton Arc Consistency). Let P be a CN.\n• An instantiation {(x, a), (y, b)} on P is 2-singleton arc-consistent, denoted 2SACconsistent, iff GAC (P |{x=a,y=b}) 6= ⊥.\n• P is 2SAC-consistent iff every locally consistent instantiation {(x, a), (y, b)} on P is 2SAC-consistent.\n3-consistency, dual consistency and 2-singleton arc consistency are second-order consistencies, from which conservative restrictions can be naturally derived as follows. Definition 10 (Conservative Second-Order Consistency). Let P be a CN, and φ be a consistency in {3C,DC, 2SAC}. • An instantiation {(x, a), (y, b)} on P is conservative φ-consistent, denoted Cφ-consistent, iff either @c ∈ cons(P ) | scp(c) = {x, y} or {(x, a), (y, b)} is φ-consistent.\n• P is Cφ-consistent iff every locally consistent instantiation {(x, a), (y, b)} on P is Cφ-consistent.\nThus, we obtain three new second-order consistencies called conservative 3-consistency (C3C), conservative dual consistency (CDC, Lecoutre et al., 2007a) and conservative 2- singleton arc consistency (C2SAC). To illustrate the difference between a consistency φ and its conservative restriction Cφ, let us consider a CN P such that vars(P ) = {w, x, y, z} and cons(P ) = {cwx, cwz, cxyz}, where subscripts indicate constraint scopes. φ reviews (locally consistent instantiations of) all of the six possible distinct pairs of variables whereas Cφ reviews only the two pairs (w, x) and (w, z).\nWe shall also be interested in strong variants of second-order consistencies that additionally guarantee generalized arc consistency. For example, a binary CN is strong pathconsistent, denoted sPC-consistent, iff it is both arc-consistent and path-consistent; a CN is strong dual-consistent, denoted sDC-consistent iff it is both GAC-consistent and DCconsistent. s3C, s2SAC, sPPC, sCPC, sCDC, sC3C, sC2SAC are defined similarly. Definition 11 (Strong Second-Order Consistency). Let φ be a second-order consistency. A CN P is strong φ-consistent, denoted sφ-consistent, iff P is GAC+φ-consistent, i.e., both GAC-consistent and φ-consistent.\nA strong second-order consistency φ identifies both φ-inconsistent values (nogoods of size one) and φ-inconsistent pairs of values (nogoods of size two). Strictly speaking, this is not a second-order consistency but a “first+second” order consistency.\nIt is important to note that the closure of a CN can be computed for all second-order consistencies mentioned so far. All such consistencies can be proved to be stable, and consequently well-behaved. Proposition 5. PC, 3C, DC, 2SAC, PPC, CPC, C3C, CDC, C2SAC, as well as their strong variants, are consistencies that are well-behaved. Sketch of proof. Following Theorem 1, it is sufficient to show that all mentioned consistencies are stable (see Page 180). For each consistency φ among those mentioned in the proposition, when an instantiation I is φ-inconsistent on a CN P , necessarily if I is not an explicit nogood in a CN P ′ smaller than or equal to P , I is φ-inconsistent on P ′. For example, suppose that I = {(x, a), (y, b)} is DC-inconsistent on P . This means that (y, b) /∈ GAC (P |x=a) or (x, a) /∈ GAC (P |y=b). If I /∈ P̃ ′, we must then show that I is DC-inconsistent on P ′. But we necessarily have (y, b) /∈ GAC (P ′|x=a) GAC (P |x=a) or (x, a) /∈ GAC (P ′|y=b) GAC (P |y=b) because P ′ P . Hence, I is DC-inconsistent on P ′."
    }, {
      "heading" : "4. Relationships between Second-Order Consistencies",
      "text" : "This section studies the qualitative relationships between the second-order consistencies that we have presented, namely path consistency, 3-consistency, dual consistency, 2-singleton arc consistency, and their conservative and strong variants. This section is composed of three parts (subsections). We start with relationships between basic second-order consistencies (PC, 3C, DC, 2SAC). Then, we focus on relationships including conservative restrictions (PPC, CPC, C3C, CDC, C2SAC). Finally, we finish with strong second-order consistencies (sPC, s3C, sDC, s2SAC, sPPC, sCPC, sC3C, sCDC, sC2SAC).\nIn our previous works (Lecoutre et al., 2007a, 2007b), our study was limited to binary CNs. In this paper, we generalize our results to CNs of any arity, although some results are given specifically for binary CNs or non-binary CNs. When no precision is given, the results hold for the set of all possible binary and non-binary CNs (i.e., CNs with constraints of arbitrary arity)."
    }, {
      "heading" : "4.1 Results on Basic Second-Order Consistencies",
      "text" : "We start with the strongest (basic) second-order consistency of this paper, namely 2SAC.\nProposition 6. 2SAC is strictly stronger than DC, and strictly stronger than 3C.\nProof. Let P be a CN and I = {(x, a), (y, b)} be a locally consistent instantiation on P . On the one hand, if I is DC-inconsistent then either (y, b) /∈ GAC (P |x=a) or (x, a) /∈ GAC (P |y=b), which necessarily entails GAC (P |{x=a,y=b}) = ⊥. Consequently, I is 2SACinconsistent, and it follows that 2SAC is stronger than DC. On the other hand, if I is 3Cinconsistent then ∃z ∈ vars(P ) | ∀c ∈ dom(z), {(x, a), (y, b), (z, c)} is not locally consistent. In the CN P ′ = GAC (P |{x=a,y=b}), we necessarily have dom(z) = ∅ (because x and y are assigned and GAC is enforced), and thus P ′ = ⊥. This means that I is 2SAC-inconsistent, and it follows that 2SAC is stronger than 3C. Strictness is proved by Figure 5 that shows a binary CN that is DC-consistent, 3C-consistent but not 2SAC-consistent.6\nOn binary CNs, DC is equivalent to PC. This could be predicted since McGregor proposed an AC-based algorithm to establish sPC (1979). We show this in 2 steps.\nProposition 7. DC is strictly stronger than PC.\nProof. Let P be a CN and I = {(x, a), (y, b)} be a locally consistent instantiation on P . If I is path-inconsistent then ∃z ∈ vars(P ) | ∀c ∈ dom(z), {(x, a), (z, c)} or {(y, b), (z, c)} is not locally consistent (see Definition 4). In this case, we know that (y, b) /∈ GAC (P|x=a) since after enforcing GAC on P|x=a, every value c remaining in dom(z) is such that {(x, a), (z, c)} is consistent. Necessarily, by hypothesis, all these remaining values are incompatible with (y, b), thus b is removed from dom(y) when enforcing GAC. Hence I is dual-inconsistent, and it follows that DC is stronger than PC. Strictness is proved by Figure 6 that shows a non-binary CN that is PC-consistent but not DC-consistent.\nProposition 8. On binary CNs, DC is equivalent to PC.\n6. This result, as well as those of Figures 9 and 12, has been computer-checked.\nProof. From Proposition 7, we know that DC is stronger than PC. Now, we show that, on binary CNs, PC is stronger than DC, therefore we can conclude that DC and PC are equivalent. Let P be a binary CN and I = {(x, a), (y, b)} be a locally consistent instantiation on P . If I is dual-inconsistent then (y, b) /∈ AC (P|x=a), or symmetrically (x, a) /∈ AC (P|y=b). We consider the first case.\nLet us consider a filtering procedure F that iteratively removes (in any order) the values of P|x=a that are successively found to be arc-inconsistent up to a fixpoint. Such a procedure is guaranteed to compute AC (P|x=a) (cf. Apt, 2003; Lecoutre, 2009). Let H(k) be the following induction hypothesis: if (z, c) is one of the k first values removed by F,\nthen {(x, a), (z, c)} ∈ P̃ ′ with P ′ = PC (P ), i.e., {(x, a), (z, c)} is either initially locally inconsistent or identified as path-inconsistent (possibly after propagation).\nWe show that H(1) holds. If (z, c) is the first value removed by F, this means that (z, c) has no support on a binary constraint involving z and a second variable w. If {(x, a), (z, c)} is locally inconsistent, then H(1) holds trivially. Otherwise, necessarily w 6= x (because this would mean that (z, c) is not compatible with (x, a) since a has been assigned to x, so {(x, a), (z, c)} is initially locally inconsistent). Therefore {(x, a), (z, c)} clearly has no support on the path 〈x,w, z〉 and is thus path-inconsistent.\nWe now assume that H(k) is true and show that H(k+ 1) holds. If (z, c) is the k+ 1th value removed by F, this means that this removal involves a constraint binding z with another variable w. The value (z, c) has no support on this constraint, thus every value in dom(w) initially supporting (z, c), if any, is one of the k first values removed by F. By hypothesis this means that for any such value b, {(x, a), (w, b)} ∈ P̃ ′ with P ′ = PC (P ). In any case, we can now deduce that {(x, a), (z, c)} ∈ P̃ ′ and, as a special case, we can identify I as path-inconsistent. Consequently, every locally consistent instantiation on P that is in P̃ ′′ with P ′′ = DC(P ) is also in P̃ ′ with P ′ = PC (P ). We deduce that PC (P ) DC(P ) and also from Proposition 1 that PC is stronger than DC on binary CNs.\nNow, we consider 3-consistency. On binary CNs, it is well-known that 3-consistency is equivalent to path consistency. So, 3C is also equivalent to DC (since DC is equivalent to PC). On non-binary CNs, we have the following relationships with PC and DC.\nProposition 9. On non-binary CNs, 3C is incomparable with DC, and strictly stronger than PC.\nProof. On non-binary CNs, 3C is strictly stronger than PC (e.g., see Dechter, 2003, p. 69) because 3C also checks ternary constraints. When comparing 3C with DC, it appears that 3C cannot be stronger than DC because a CN composed of only one quaternary constraint\nthat is not GAC-consistent is necessarily 3-consistent (since there are no binary and ternary constraints) and not DC-consistent. On the other hand, DC cannot be stronger than 3C because Figure 7 shows a non-binary CN that is DC-consistent but not 3-consistent (there is no way of extending {(x, a), (y, a)} on z). Hence, 3C and DC are incomparable."
    }, {
      "heading" : "4.2 Results on Conservative Second-Order Consistencies",
      "text" : "Now, we consider conservative variants of the basic second-order consistencies. A first immediate result is that conservative consistencies are made strictly weaker than their unrestricted forms. However, it is worthwhile to mention that (strong) PPC was shown equivalent to (strong) PC on binary convex CNs with triangulated constraint graphs (Bliek & Sam-Haroud, 1999).\nProposition 10. 2SAC, DC, 3C and PC are respectively strictly stronger than C2SAC, CDC, C3C and PPC+CPC.\nProof. By definition, conservative consistencies are weaker. Strictness is proved by Figure 8 that shows a binary CN which is C2SAC-consistent (and CDC-consistent, C3C-consistent, PPC-consistent, CPC-consistent) but not PC-consistent (and not 3C-consistent, not DCconsistent and not 2SAC-consistent).\nProposition 11. PC, DC and 3C are incomparable with C2SAC.\nProof. On the one hand, PC cannot be stronger than C2SAC since Figure 5 shows a binary CN that is PC-consistent but not C2SAC-consistent. On the other hand, C2SAC cannot be stronger than PC since Figure 8 shows a binary CN that is C2SAC-consistent but not PC-consistent. We conclude that PC and C2SAC are incomparable. This is also valid for DC and 3C since only binary CNs are mentioned in this proof (and PC=DC=3C on binary CNs).\nProposition 12. C2SAC is strictly stronger than CDC, and strictly stronger than C3C.\nProof. The proof is similar to that of Proposition 6, considering initially a locally consistent instantiation I = {(x, a), (y, b)} which is CDC-inconsistent (and next C3C-inconsistent) and such that x is linked to y by a constraint.\nProposition 13. CDC is strictly stronger than PPC.\nProof. Assume that a CN P is CDC-consistent and consider a closed graph-path 〈x1, . . . , xp〉 of P . For every locally consistent instantiation {(x1, a1), (xp, ap)} on P , (xp, ap) ∈ P ′ with P ′ = GAC (P |x1=a1) since P is CDC-consistent. It also implies P ′ 6= ⊥. Therefore, in the context of P ′, there exists at least one value in each domain and since P ′ is generalized arc-consistent, there is clearly a value (xp−1, ap−1) of P ′ compatible with (xp, ap), a value (xp−2, ap−2) of P ′ compatible with (xp−1, ap−1), . . . , and a value (x1, a′1) of P ′ compatible with (x2, a2). Because domP\n′(x1) = {a1}, we have a′1 = a1, thus the locally consistent instantiation {(x1, a1), (xp, ap)} is consistent on the closed graph-path 〈x1, . . . , xp〉 of P . Hence P is PPC-consistent, thus CDC is stronger than PPC.\nThe fact that CDC is strictly stronger than PPC is shown by the CN P depicted in Figure 9. In Figure 9(c), P is shown to be CDC-inconsistent because the locally consistent instantiation {(x, a), (y, b)} is dual-inconsistent: (y, b) /∈ AC (P |x=a). In Figure 9(d), P is shown to be CPC-consistent because, for example, the locally consistent instantiation {(x, a), (y, b)} is consistent on all 2-length graph-paths linking x to y, namely, 〈x, z, y〉 and 〈x,w, y〉. Here, the constraint graph is triangulated, which means that CPC is equivalent to PPC. Hence we can deduce our result.\nProposition 14. On non-binary CNs, CDC is incomparable with C3C.\nProof. CDC cannot be stronger than C3C since Figure 7 shows a non-binary CN that is CDC-consistent but not C3C-consistent. Now, consider the CN of Figure 9 extended with a single ternary constraint involving new variables. This CN remains C3C-consistent (because\nthere is no binary constraint between these new variables), but is still not CDC-consistent. Hence, C3C cannot be stronger than CDC, and CDC and C3C are incomparable.\nProposition 15. On binary CNs, PPC is strictly stronger than C3C. On non-binary CNs, PPC is incomparable with C3C.\nProof. 1) Let P be a binary CN that is PPC-consistent (and different from ⊥ – this is a very weak restriction). We consider a locally consistent instantiation {(x, a), (y, b)} on P (such that there is a binary constraint involving x and y) and show that for every third variable z of P , the following property Pr(z) holds: ∃c ∈ dom(z) such that {(x, a), (z, c)} and {(y, b), (z, c)} are both locally consistent instantiations, which is equivalent to “{(x, a), (y, b), (z, c)} is locally consistent” since P is binary. If Pr holds, then {(x, a), (y, b)} is C3C-consistent. For each variable z, 3 cases must be considered, depending of the existence of the constraints cxz, between x and z, and cyz, between y and z.\n(a) Both constraints exist: thus, there exists a graph-path 〈x, z, y〉 and as this path is consistent by hypothesis, necessarily the property Pr(z) holds.\n(b) Neither constraint exist: P 6= ⊥ implies dom(z) 6= ∅, thus Pr(z) holds because cxz and cyz are implicit and universal.\n(c) Only the constraint cxz exists (similarly, only the constraint cyz exists). Consider the graph-path 〈x, z, x, y〉. By hypothesis, this graph-path is consistent. Hence, there exists a value c in dom(z) such that {(x, a), (z, c)} is locally consistent. We also know that{(y, b), (z, c)} is locally consistent because there is no constraint between y and z. We conclude that Pr(z) holds and PPC is stronger than C3C on binary CNs.\nFigure 10 proves strictness by showing a CN that is C3C-consistent but not PPC-consistent.\n2) For non-binary CNs, Figure 7 shows that PPC cannot be stronger than C3C: the CN is PPC-consistent but not C3C-consistent. Now, consider the CN of Figure 10 extended with a single ternary constraint involving new variables. This CN remains C3C-consistent (because there is no binary constraint between these new variables), but is still not PPC-consistent. Hence, C3C cannot be stronger than PPC, and PPC and C3C are incomparable.\nProposition 16. C3C is strictly stronger than CPC.\nProof. Let P be a CN that is C3C-consistent. Let 〈x, z, y〉 be a closed 2-length graph-path of P and {(x, a), (y, b)} be a locally consistent instantiation on P . Because P is C3Cconsistent, we know that there exists a value c in dom(z) such that {(x, a), (y, b), (z, c)} is locally consistent. Consequently, there exists a value c in dom(z) such that {(x, a), (z, c)} and {(y, b), (z, c)} are both locally consistent. We deduce that the path 〈x, z, y〉 is consistent, thus P is CPC-consistent and C3C is stronger than CPC. Figure 11 proves strictness by showing a binary CN that is CPC-consistent (there is no 3-clique) but not C3C-consistent.\nProposition 17. PPC is strictly stronger than CPC.\nProof. PPC is stronger than CPC by definition. Moreover, the binary CN in Figure 10 is CPC-consistent but not PPC-consistent. Because there is no 3-clique in its constraint graph, this CN is trivially CPC-consistent.\nProposition 18. On non-binary CNs, PC is incomparable with CDC.\nProof. On the one hand, consider the CN of Figure 8 extended with a single ternary GACconsistent constraint involving new variables. Because the additionnal constraint is GACconsistent, the CN remains CDC-consistent. However, it is not PC-consistent. We deduce that CDC cannot be stronger than PC (on non-binary CNS). On the other hand, Figure 6 proves that PC cannot be stronger than CDC: P is PC-consistent (because there is only one binary constraint) but not CDC-consistent ({(y, a), (z, a)} is CDC-inconsistent). We conclude that on non-binary CNs, PC and CDC are incomparable."
    }, {
      "heading" : "4.3 Results on Strong Second-Order Consistencies",
      "text" : "Before studying the relationships existing between strong variants of second-order consistencies, we observe that, in the binary case, enforcing AC on a path-consistent CN is sufficient\nto obtain a strong path-consistent CN. This well-known fact is also true in the general case for DC, CDC, 2SAC and C2SAC. We define φ ◦ ψ(P ) as being φ(ψ(P )).\nProposition 19. For any binary CN P , we have AC ◦ PC (P ) = sPC (P ).\nProof. In PC (P ), every locally consistent instantiation {(x, a), (y, b)} has a support on every third variable z. Hence, every value of PC (P ) in a locally consistent instantiation is arc-consistent. Consequently, when AC is enforced on PC (P ), no value present in a locally consistent instantiation (of size 2) can be removed, and PC is preserved.\nProposition 20. For any CN P , we have GAC ◦ DC (P ) = sDC (P ), GAC ◦ CDC (P ) = sCDC (P ), GAC ◦ 2SAC (P ) = s2SAC (P ) and GAC ◦ C2SAC (P ) = sC2SAC (P ).\nProof. Let P ′ = DC (P ) and P ′′ = GAC (P ′). For any singleton check GAC (P ′′|x=a) on P ′′, we have GAC (P ′′|x=a) = GAC (GAC (P ′)|x=a) = GAC (P ′|x=a). This means that the result of the singleton check for (x, a) on P ′′ is the same as the result of the singleton check for (x, a) on P ′. Since P ′ is DC-consistent, we can deduce that DC(P ′′) = P ′′. P ′′ being both GAC-consistent and DC-consistent, we have P ′′ = GAC ◦ DC(P ) = sDC(P ). A similar proof holds for CDC , 2SAC and C2SAC .\nIt has been shown that the schema of previous propositions does not hold for CPC and PPC (Lecoutre, 2009). For example, for some binary CNs P , we have AC ◦ CPC (P ) 6= sCPC (P ). Unsurprisingly, some relationships are preserved when strong variants are considered.\nProposition 21. Let φ and ψ be two second-order consistencies. If φ is stronger than ψ then sφ is stronger than sψ.\nProposition 22. We have:\n(a) s2SAC is strictly stronger than sDC, and strictly stronger than s3C.\n(b) sDC is strictly stronger than sPC.\n(c) s3C is strictly stronger than sPC.\n(d) s2SAC, sDC, s3C, and sPC are respectively strictly stronger than sC2SAC, sCDC, sC3C, and sPPC+sCPC.\n(e) sC2SAC is strictly stronger than sCDC, and strictly stronger than sC3C.\n(f) sCDC is strictly stronger than sPPC.\n(g) sPPC is strictly stronger than sCPC.\nProof. All illustrative CNs introduced previously are GAC-consistent (except for Figure 11), thus using Proposition 21, it suffices to consider: (a) Proposition 6 with Figure 5 for strictness, (b) Proposition 7 with Figure 6 for strictness, (c) Proposition 9 with Figure 7 for strictness, (d) Proposition 10 with Figure 8 for strictness, (e) Proposition 12 with Figure 5 for strictness, (f) Proposition 13 with Figure 9 for strictness, (g) Proposition 17 with Figure 10 for strictness.\nThe following result indicates that C3C and CPC are quite close properties. For arcconsistent CNs, they are equivalent.\nProposition 23. On binary CNs, sC3C is equivalent to sCPC.\nProof. From Propositions 16 and 21, we know that sC3C is stronger than sCPC. Now, we show that, on binary CNs, sCPC is stronger than sC3C. The proof is similar to that of Proposition 15 by considering a binary CN that is initially sCPC-consistent. Only case (c) in the demonstration differs:\n(c) Only the constraint cxz exists (similarly, only the constraint cyz exists): as P is arcconsistent, there exists a value in dom(z) that is compatible with (x, a). Because there is an implicit universal constraint between z and y, this value is also compatible with (y, b). Hence, Pr(z) holds.\nProposition 24. sPC, sDC and s3C are incomparable with sC2SAC.\nProof. In the proof of Proposition 11, the CNs of Figures 5 and 8 are GAC-consistent.\nProposition 25. On non-binary CNs, sPC is incomparable with sCDC.\nProof. In the proof of Proposition 18, the CNs of Figures 8 and 6 are GAC-consistent.\nFinally, we conclude this section by establishing some connections with SAC.\nProposition 26. sDC is strictly stronger than SAC+CDC\nProof. Let P be a CN that is sDC-consistent. Assume that a value (x, a) of P is SACinconsistent. This means that P ′ = GAC (P |x=a) = ⊥, and for every value (y, b), we have (y, b) /∈ P ′ (recall that no value belongs to ⊥). As P is DC-consistent by hypothesis, these nogoods are recorded in P meaning that for every variable y, we have a binary constraint cxy forbidding any tuple involving (x, a). We deduce that (x, a) is GAC-inconsistent, which contradicts our hypothesis (P sDC-consistent), and shows that sDC is stronger than SAC. As we know that DC is strictly stronger than CDC, we deduce that sDC is stronger than SAC+CDC. To prove strictness, it suffices to build a CN that is SAC-consistent, CDCconsistent but not DC-consistent (e.g., see Figure 8).\nProposition 27. On binary CNs, sCDC is strictly stronger than SAC.\nProof. Let P be a binary CN that is sCDC-consistent. Assume that a value (x, a) of P is SAC-inconsistent. This means that AC (P |x=a) = ⊥. As P is AC-consistent (since P is sCDC-consistent by hypothesis), necessarily x is involved in (at least) a binary constraint c (otherwise no propagation is possible to deduce AC (P |x=a) = ⊥). Consequently, there is no tuple allowed by c involving (x, a) since P is CDC-consistent (because when P ′ = ⊥, for every value (y, b), we consider (y, b) /∈ P ′). We deduce that (x, a) is AC-inconsistent. This contradiction shows that sCDC is stronger than SAC. To prove strictness, it suffices to observe that sCDC reasons with both inconsistent values and pairs of values.\nProposition 28. On binary CNs, SAC+CDC is equivalent to sCDC. On non-binary CNs, SAC+CDC is strictly stronger than sCDC.\nProof. Clearly, SAC+CDC is stronger than sCDC since SAC is stronger than GAC (and sCDC is GAC+CDC). On the other hand, sCDC is trivially stronger than CDC and we know from Proposition 27 that sCDC is stronger than SAC on binary CNs. We deduce that, on binary CNs, sCDC is stronger than SAC+CDC, and that SAC+CDC is equivalent to sCDC. For non-binary CNs, to show strictness, let us consider the non-binary CN depicted in Figure 6, but with the binary constraint cyz eliminated. The new obtained CN is GACconsistent, CDC-consistent (since there are no more binary constraints), and thus sCDCconsistent, but not SAC-consistent because GAC (P |y=a) = ⊥.\nProposition 29. On binary CNs, sCDC is incomparable with BiSAC.\nProof. On the one hand, BiSAC cannot be stronger than sCDC since Figure 9 shows a binary CN that is BiSAC-consistent (note that every value belongs to at least one solution) but not CDC-consistent. On the other hand, sCDC cannot be stronger than BiSAC since Figure 12\n2SAC s2SAC sC2SAC\nC2SAC 3C=DC=PC s3C=sDC=sPC BiSAC\nCDC sCDC=SAC+CDC SAC\nPPC sPPC MaxRPC\nC3C sCPC=sC3C AC=2C\nCPC\n(a) Consistencies restricted to binary CNs.\nshows a binary CN that is sCDC-consistent but not BiSAC-consistent. We conclude that sCDC and BiSAC are incomparable.\nSome results given in the general case (i.e., for CNs with constraints of arbitrary arity) also hold when only binary CNs are considered. This is the case for Propositions 6, 10, 11, 12, 13, 16, 17, 22 (except for cases (b) and (c)), 24 and 26 because binary CNs are used in their proofs. Figure 13 shows the relationships between (strong) second-order consistencies introduced in this paper, with a focus on binary CNs in Figure 13(a). In Figure 13(b), for the sake of clarity, s3C, sC3C, and sC2SAC are not inserted."
    }, {
      "heading" : "5. An Algorithm to Enforce s(C)DC",
      "text" : "In this section, we present a general algorithm to enforce strong (conservative) dual consistency. This algorithm is valid for both binary and non-binary CNs. This algorithm is called sCDC1 when it is used to enforce sCDC, and sDC1 when it is used to enforce sDC. Actually, on non-binary CNs, our sCDC1 algorithm enforces SAC+CDC, which is strictly stronger than sCDC. This extra strength comes for free from the exploitation of the singleton checks used to enforce CDC.\nAlgorithm 1: sCDC1/sDC1(P ): Boolean Input/Output: a CN P ; sCDC (SAC+CDC) or sDC is enforced on P Result: true iff P is strong (conservative) dual-consistent P ← GAC (P ) // GAC is initially enforced1 if P = ⊥ then return false2 x← first(vars(P ))3 marker ← x4 repeat5 if reviseVariable(P, x) then6 P ← GAC (P ) // GAC is maintained7 if P = ⊥ then return false8 marker ← x9\nx← nextCircular(x, vars(P ))10 until x = marker11 return true12\nAlgorithm 1 establishes strong (conservative) dual consistency on a given CN P . The learnxxx function called at Line 9 of Algorithm 2, which is used by Algorithm 1, is specialized either to learnpart (Algorithm 3) to enforce sCDC (SAC+CDC on non-binary CNs – we omit this precision from now on) or to learnfull (Algorithm 4) to enforce sDC on P . Basically, Algorithm 1 performs successive singleton checks until a fixed point is reached, and returns true iff P is strong (conservative) dual-consistent, i.e., iff sCDC (P ) 6= ⊥ (with learnpart) or sDC (P ) 6= ⊥ (with learnfull). GAC is enforced at line 1, and then a variable is considered at each turn of the main loop to establish the consistency. first(vars(P )) is the first variable of P in the lexicographical order, and nextCircular(x, vars(P )) is the variable of P right after x if any, or first(vars(P )) otherwise. These two functions allow circular iteration over the variables of P . For example, if vars(P ) = {x, y, z}, then the iteration has the form x, y, z, x, y, z. . . Of course, it is possible to control the order of variables from one iteration to the next using some heuristic.\nThe reviseVariable function (Algorithm 2) revises the given variable x by means of strong (conservative) dual consistency, i.e., explores all possible inferences with respect to x by performing singleton checks on values in dom(x). To achieve this, GAC is enforced on P |x=a for each value a in the domain of x (Line 3). If a is SAC-inconsistent, then a is removed from the domain of x (Line 5). Otherwise (Lines 7 to 10), for every variable y 6= x of P with at least one value deleted by constraint propagation, we try to learn nogoods by\nAlgorithm 2: reviseVariable(P ,x): Boolean effective ← false1 foreach value a ∈ domP (x) do2 P ′ ← GAC (P |x=a) // singleton check on (x, a)3 if P ′ = ⊥ then4 remove a from domP (x) // SAC-inconsistent value5 effective ← true6\nelse7 foreach variable y in vars(P ) | y 6= x ∧ domP (y) 6= domP ′(y) do8\nif learnxxx(P, (x, a), y,domP (y) \\ domP ′(y)) then9 effective ← true10\nreturn effective11\nAlgorithm 3: learnpart(P , (x, a), y, Deleted): Boolean if ∃cxy ∈ cons(P ) | scp(cxy) = {x, y} then1 conflicts ← ∅2 foreach b ∈ Deleted | (a, b) ∈ relP (cxy) do3 conflicts ← conflicts ∪ {(a, b)} // CDC-inconsistent pair4 if conflicts 6= ∅ then5 relP (cxy)← relP (cxy) \\ conflicts6 return true7\nreturn false8\nAlgorithm 4: learnfull(P , (x, a), y, Deleted): Boolean if ∃cxy ∈ cons(P ) | scp(cxy) = {x, y} then1 conflicts ← ∅2 foreach b ∈ Deleted | (a, b) ∈ relP (cxy) do3 conflicts ← conflicts ∪ {(a, b)} // CDC-inconsistent pair4 if conflicts 6= ∅ then5 relP (cxy)← relP (cxy) \\ conflicts6 return true7\nelse8 conflicts ← {(a, b) | b ∈ Deleted} // DC-inconsistent pairs9 Let cxy be a new constraint such that:10 • scp(cxy) = {x, y} • rel(cxy) = (dominit(x)× dominit(y)) \\ conflicts cons(P )← cons(P ) ∪ {cxy}11 return true12\nreturn false13\nmeans of functions learnpart or learnfull; the set of values of y deleted by propagation is passed as last parameter (in practice, using a stack to handle domains and a trailing mechanism, there is no need to explicitly compute the set of deleted values). The revision is effective for x if a value or a tuple is deleted (possibly after inserting a new constraint). The Boolean variable effective is introduced to track revision effectiveness. When the revision of x is effective, reviseVariable returns true at Line 6 of Algorithm 1, and GAC is re-established (Line 7). Any domain or relation wipe-out is detected at Line 8. A marker, initialized with the first variable of vars(P ) (Line 4) and updated whenever inferences are performed (Line 9), manages termination.\nBoth Algorithms 3 and 4 discard identified binary nogoods that correspond to CDCinconsistent pairs of values if the constraint cxy exists: every tuple (a, b) such that b is a deleted value (i.e., b for y is present in P but not in P ′) and (a, b) present in relP (cxy) is removed from relP (cxy). When enforcing sDC (with learnfull) and when no binary constraint exists between x and y, a new constraint is created. This constraint enforces the set of nogoods corresponding to DC-inconsistent pairs of values involving (x, a) and variable y. The new constraint accepts every pair of values except those that have been identified as conflicts. Notice that we know that there is at least one conflict since domP (y) 6= domP ′(y) at line 8 of Algorithm 2.\nProposition 30. Algorithm sCDC1 enforces sCDC on binary CNs and SAC+CDC on non-binary CNs; Algorithm sDC1 enforces sDC.\nProof. First, any inference performed by Algorithm 2 at Line 5 or by learnpart/learnfull is correct: such inferences correspond to clearly identified SAC-inconsistent values and (C)DCinconsistent pairs of values. Any inference directly performed by Algorithm 1 at Lines 1 and 7 is also safe because it corresponds to removing GAC-inconsistent values; remember that the overall algorithm enforces strong (C)DC, or SAC+CDC (and SAC is stronger than GAC). The fact that all possible inferences are performed is guaranteed by the fact that each time a revision is effective, the marker used in Algorithm 1 is updated; see Line 9. Also, any inference performed with respect to a pair (x, a) has no effect on GAC (P |x=b), where b is any other value in the domain of the variable x. Indeed, when b is assigned to x, all other values in the current domain of x are automatically removed. Combined with the enforcement of GAC, the assignment of a new value to x makes previous inferences related to other values of x without any effect. This is the reason why we can iterate over all values of x at Line 2 of Algorithm 2 in a unique pass.\nOne pass of Algorithm 1 means calling reviseVariable exactly once per variable.\nProposition 31. One pass of Algorithm 1 has a worst-case time complexity in O(enrdr+1) with learnpart (i.e., for sCDC1) and in O(enrdr+1 + n3d3) with learnfull (i.e., for sDC1).\nProof. The optimal worst-case time complexity of enforcing GAC is O(erdr) (Mohr & Masini, 1988). The worst-case time complexity of Lines 8–10 of Algorithm 2 is O(nd) with both learn methods. Besides,\n• with learnpart, no new constraint is inserted in P , the worst-case time complexity of one pass of Algorithm 1 is O(nd · (erdr + nd)). This reduces to O(enrdr+1) with the\nvery weak assumption that n ≤ er (otherwise, some variables would not be involved in any constraint);\n• with learnfull, we have to consider that O(n2) additional binary constraints may be added by the algorithm. So, we obtain O(enrdr+1 + n3d3).\nFor binary constraints (r = 2, which entails e < n2), we obtain:\nCorollary 1. For binary CNs, one pass of Algorithm 1 admits a worst-case time complexity in O(end3) with learnpart and in O(n3d3) with learnfull.\nWhen P is not already s(C)DC-consistent, several passes of Algorithm 1 are necessary. Thus,\n• with learnpart, the number of passes is bounded by O(ed2); one tuple being removed at each new pass. The worst-case time complexity of Algorithm 1 is then in O(e2nrdr+3) (O(e2nd5) for binary CNs);\n• with learnfull, the number of passes is bounded by O(n2d2); one tuple being removed at each new pass. The resulting worst-case time complexity is then O(en3rdr+3+n5d5) (O(n5d5) for binary CNs).\nThe overall time complexity of Algorithm 1 seems to be rather high but we have observed that very often a fixed point is quickly reached in practice (i.e., the number of passes empirically tends to be constant). We can also note that for sDC1 (i.e., Algorithm 1 with learnfull), it is possible to limit the cost of enforcing GAC at each singleton check. Indeed, when a singleton check on a pair (x, a) is performed, every nogood of size 2 including (x, a) is identified and recorded in the CN P . This means that just after the last instruction of each iteration of the foreach loop starting at Line 2 of Algorithm 2, P is such that after assigning again a to x, applying forward checking (any non-binary version, Bessiere, Meseguer, Freuder, & Larrosa, 2002) is enough to enforce GAC: we only need to consider binary constraints involving x and delete values that are not consistent with (x, a). This is studied in a paper by Lecoutre et al. (2007b).\nFinally, it is worthwhile to mention that Algorithm 1 does not require specific data structure. The only data structures required are those of the underlying (G)AC algorithm(s) and those for the representation of CNs. If eb denotes the number of binary constraints in a given CN, then sCDC1 may require O(ebd2) additional space to store new nogoods (if binary constraints were initially given in intension for example). sDC1 require O(n2d2) additional space, which may be a serious drawback for solving certain problems."
    }, {
      "heading" : "6. Experimental Results",
      "text" : "To show the practical interest of strong second-order consistencies, and in particular s(C)DC, we conducted several extensive experiments on Oracle Java 6 VMs running on a cluster of Intel Xeon 3.0GHz with 1GiB of RAM under Linux. To do this, we implemented sCPC, sCDC and sDC algorithms in our constraint solver AbsCon. These implementations are sCPC8, directly derived from PC8 (Chmeiss & Jégou, 1998), sCDC1 and sDC1 that correspond to Algorithm 1 with learnpart and learnfull, respectively. Some refinements of the\nalgorithm sDC1, as proposed by Lecoutre et al. (2007b), are also possible but will not be considered in this paper, mainly because such optimizations are rather marginal (a speedup of 10% on some problems) with respect to our main concern: showing that enforcing s(C)DC before search may pay off.\nThe AbsCon solver also features SAC preprocessing algorithms. We used SAC1 (Bessiere & Debruyne, 2005) and SAC3 (Lecoutre & Cardon, 2005) algorithms in some experiments. In AbsCon, the algorithms used to enforce (G)AC are AC3bit+rm (Lecoutre & Vion, 2008) for binary constraints, GAC3rm (Lecoutre & Hemery, 2007) for non-binary constraints defined in intension, and STR2 (Lecoutre, 2008) for non-binary constraints in extension. Besides, when possible, an optimization based on reasoning from the cardinality of conflict sets (Boussemart, Hemery, Lecoutre, & Sais, 2004b) was used. Of course, SAC1, SAC3, sCDC1 and sDC1 also benefit from the efficiency of these underlying (G)AC algorithms."
    }, {
      "heading" : "6.1 Preprocessing Performance on Random Problems",
      "text" : "We first evaluate the performance of various consistencies and algorithms on random instances. Random CNs are generated using Model B (Gent, MacIntyre, Prosser, Smith, & Walsh, 2001) to comply to five parameters: the number of variables n, the size of the domains d, the arity of the constraints r (r = 2 in our experiment), the density δ,7 and the tightness t (proportion of tuples forbidden by each constraint).\nFigure 14 gives some quantitative information about the relative strength of AC, sCPC, SAC, sCDC and sDC (= sPC) enforced on random binary CNs with n = 50 variables and d ∈ {10, 50} values per domain. Each plot in the figures represents the position of the phase transition of a given consistency for the generated instances; there are 50 instances generated for each (δ, t) pair, and we recall that the phase transition of a consistency φ occurs when 50% of the generated instances are detected as unsatisfiable when enforcing\n7. The density determines the number of constraints e = δ · (\nn r\n)\nφ. Phase transition for inverse consistency is also plotted as a baseline: a CN is inverseconsistent, or (1, n)-consistent, iff each value belongs to at least one solution. The obtained results show that sCPC is rather close to sCDC on such random instances, except when the tightness t ranges between 40% and 70%. Surprisingly, the difference between sCDC and sDC is so weak that it is not even visible on the graphs. Also, we can see that second-order consistencies become closer to inverse consistency when the size of the domains is lower.\nFigure 15 compares the CPU times required to establish sPC, sDC, sCPC and sCDC, on binary random CNs, using the algorithms sPC8, sDC1, sCPC8 and sCDC1, respectively. For each value of t, 50 instances have been generated, with either 50 values (topmost figures) or 90 values (bottommost figures) per variable. Leftmost pictures represent performances on CNs with density δ = 50 % and rightmost pictures on CNs with complete constraint graphs. In the latter case, all consistencies are equivalent; this is why only plots for sDC1 and sPC8 are given. The results are quite informative. On the one hand, they illustrate the very high performance of s(C)DC algorithms with respect to state-of-the-art s(C)PC algorithms, with a performance gap often over one order of magnitude on dense problems. On the other hand, the obtained results show that establishing sDC is not much harder than enforcing sCDC."
    }, {
      "heading" : "6.2 Impact of Second-Order Consistency Preprocessing on MAC",
      "text" : "Now, we turn to complete search algorithms. One of the most popular (systematic) search algorithms to solve CNs is called MAC (Sabin & Freuder, 1994). MAC interleaves inference and search since at each step of a depth-first exploration with backtracking, (generalized) arc consistency is maintained.8 At each step of search, MAC uses a variable ordering heuristic to select the next variable to be instantiated. Two representative variable ordering heuristics are the dynamic heuristic dom/ddeg (Bessiere & Régin, 1996) and the adaptive heuristic dom/wdeg (Boussemart, Hemery, Lecoutre, & Sais, 2004a). Today, enforcing (strong) second-order consistencies during search (basically, after each variable assignment) seems to be unrealistic. However, enforcing such consistencies in a preprocessing stage and before running MAC is an issue that deserves to be addressed; in this section, we attempt to provide some insight in this regard. If Φ denotes the consistency enforcing algorithm applied at preprocessing, this is denoted by Φ-MAC. The experimentation that we have conducted consists in comparing MAC, SAC1-MAC (and also SAC3-MAC), sCPC8-MAC, sCDC1MAC and sDC1-MAC; from now on called variants of MAC. It allows us to assess the practical impact of enforcing (strong) second-order consistencies at preprocessing on many series of structured (i.e., not random) binary and non-binary instances. These series as well as their description can be found at http://www.cril.fr/~lecoutre/benchmarks.html. We briefly introduce the main features of these series (listed in alphabetical order).\naim: series of instances with Boolean variables and ternary constraints. Initially, they were generated as Boolean formulas in DIMACS CNF (Conjunctive Normal Form) format.\nbqwh: series of satisfiable balanced quasi-group instances with holes (Gomes & Shmoys, 2002); domains of variables are small (usually, a few values) and constraints are binary.\n8. For simplicity, we shall use the acronym MAC whatever the arity of the constraints is.\ncomposed: series of instances randomly composed of a main (under-constrained) fragment and some auxiliary fragments (Lecoutre, Boussemart, & Hemery, 2004); there are 10 values per domain and constraints are binary.\ndriver: series of planning instances with costs converted from WCSP (Weighted CSP) to CSP; domains of variables are small (usually, a few values) and constraints are binary.\nehi: series of SAT instances converted into CSP using the dual method as described by Bacchus (2000); there are 7 values per domain and constraints are binary.\nlangford: series from the (generalized version of the) Langford problem; domains of variables are usually not small (up to 150 values) and constraints are binary.\nos-taillard: series of Open-Shop scheduling instances generated by J. Vion from Taillard’s paper (1993); domains are large and constraints are binary.\nprimes: series of instances involving prime numbers generated by M. van Dongen; domains of variables are not small and some constraints are non-binary.\nqcp / qwh: series from the Quasi-group Completion Problem (QCP) and the Quasi-group With Holes problem (QWH); domains are not very large and constraints are binary.\nqueensKnights: series of academic instances with queens and knights to be put on a chessboard (Boussemart et al., 2004a); some domains are large and constraints are binary.\nradar: realistic radar surveillance problems generated following the model of the Swedish institute of computer science (SICS); domains are small and constraints non-binary.\nrenault-mod: series of instances generated by K. Stergiou from a Renault Megane configuration problem; domains are diverse and constraints are non-binary.\nsadeh: series containing the five sets of job-shop scheduling instances studied by Sadeh & Fox (1996); domains are large and constraints are binary.\nscens11: series containing hard variants of the original scen11 instance from the Radio Link Frequency Assignment Problem (RLFAP, Cabon et al., 1999); domains are not small and constraints are binary.\nseries: series from the all-interval series problem; domains are diverse and constraints are binary or ternary.\nruler: series from the Golomb Ruler problem; domains are not small and constraints are binary, ternary or quaternary.\ntsp: series generated by R. Szymanek from the Travelling Salesperson problem; domains are large and constraints are binary or ternary.\nTables 1 and 3 show the results that we have obtained with the different variants of MAC (the third column is for MAC alone) equipped with the variable ordering heuristics dom/ddeg and dom/wdeg, respectively. For each series, the number nbs of instances solved by the five variants of MAC within the alloted time (20 minutes) as well as the total number nb of instances are given under the form nbs/nb in column #Inst. The mean CPU times displayed in these two tables is computed from the nbs instances identified for each series; when a variant solves some additional instances, this is indicated between brackets preceded by the + symbol. It is interesting to note that the SAC3 algorithm (Lecoutre & Cardon, 2005) sometimes permits to discover “lucky” solutions during preprocessing due to its greedy nature. When this happens, we show the increased number of solved instances behind /. For example, in Table 1, the first row indicates that 12 instances out of a set\nof 24 instances from series aim-200 have been solved by each of the five variants of MAC. sDC1-MAC solves these 12 instances with a mean CPU time computed at 54.2 seconds, and additionally solves 3 other instances of the series (within 20 minutes). Note that for each series, the mean CPU time of the best variant of MAC is printed in bold face: the best variant is the one that solves the highest number of instances within 20 minutes and in case of equality, the one that has the smallest mean CPU time.\nTables 2 and 4 provide details on solving various instances when enforcing second-order consistencies at preprocessing. For each problem instance, the total CPU time to solve it is given (this is > 1,200 when the instance cannot be solved within 20 minutes) as well as the time taken to enforce the consistency at preprocessing (pcpu between brackets). Additional information concern the memory requirement (expressed in MiB), the number of explored nodes and the number of values and tuples deleted at preprocessing (del v – del t). For sDC1, we also put the number of new binary constraints between brackets. For example, in Table 2, for solving the instance aim-100-1-6-sat, sDC1-MAC needs 0.47 s (0.12 s at preprocessing), 25MiB of memory, explores 100 nodes, deletes 100 values and 231 tuples at preprocessing (while adding 200 new binary constraints).\nTable 1 clearly shows that when the heuristic dom/ddeg is used, there is a real interest of making a strong propagation effort during preprocessing on many problems. Although MAC remains the most efficient approach on a few series (e.g., langford-2 and tsp-20), sCDC1-MAC and sDC1-MAC are proved here to be more robust than MAC. For example, on series aim200, radar-9-28 and series, sDC1-MAC largely outperforms MAC. Overall, sDC1-MAC solves 178−36 = 142 more instances than MAC. sCDC1-MAC and SAC1/3-MAC are comparable in terms of the number of solved instances. However, on some series (e.g., langford-3 and bqwh-18), sCDC1-MAC is clearly better than SAC1/3-MAC, even if the reverse is true for some other series (e.g., renault-mod and sadeh). It is also interesting to note that sCPC8MAC is almost always outperformed by sCDC1-MAC and sDC1-MAC. This is an expected result, as sCPC is weaker than sCDC (and a fortiori sDC), and s(C)DC algorithms benefit of underlying highly optimized (G)AC algorithms. On some series, adding new binary constraints in order to collect all identified nogoods of size 2 may be counterproductive. The conservative consistency sCDC is then a better option than sDC. For example, this is the case for driver and tsp-25 series.\nThe results given in Table 2 show the dramatic effect of a strong consistency at preprocessing on some instances. For example, after enforcing sCDC or sDC, MAC is able to directly find a solution to aim-100-1-6-sat. This is also the case for sDC1-MAC on series-12. However, sDC1 may require a significant amount of additional memory (to record new constraints). This may explain the relative inefficiency of sDC1-MAC on instances driver-02csat, driver-09-sat and scen11-f12, compared to sCDC1-MAC. Note that for renault-mod-8, sCDC1 and sDC1 alone are sufficient to detect unsatisfiability (the number of visited nodes is 0). However, the unsatisfiability of this instance is proved differently (i.e., following different propagation paths), which can explain why 95 and 72 values are respectively deleted when sCDC and sDC are enforced.\nTable 3 confirms that MAC equipped with the heuristic dom/wdeg is far more robust than dom/ddeg, as initially claimed by Boussemart et al. (2004a). As a result, on some series, enforcing a strong consistency (i.e. a consistency stronger than GAC) at preprocessing has a more limited impact. Nevertheless, overall, sDC1-MAC still increases the robustness\nof the solver. Concerning SAC3-MAC, it is important to note that its good behaviour is due to its opportunistic mechanism of finding solutions, and not to its inference capability as shown by the results of SAC1-MAC: SAC1-MAC solves 26 additional instances against 51 for SAC3-MAC. If sCDC1-MAC is outperformed by sDC1-MAC, note that on some series, it remains a good option because it does not perturbate the heuristic by adding new constraints (e.g., compare the number of nodes for solving instances scen11-f6 and scen11-f8 in Table 4) and its overhead at preprocessing is limited (compare for example the preprocessing time of sCDC1 and sDC1 for e0ddr1-4 and tsp-20-75 in Table 4).\nWhich lessons can be learned from this experimental study? A first one is that enforcing s(C)DC is most of the time far more efficient than enforcing s(C)PC. As our first experimental attempts (not presented in this paper) to enforce s(C)2SAC show that this is a very expensive approach, we do believe that s(C)DC is, for now, the best second-order consistency to be enforced at preprocessing.\nA second unsurprising lesson is that there are problems for which enforcing s(C)DC is not cost-effective. Basically, the cost of enforcing s(C)DC mainly depends on the total number of values to be tested9 as well as on the time complexity of the underlying GAC algorithm(s). For non-binary constraints, the time complexity of enforcing GAC usually increases with the arity of the constraints and for extensional constraints, the time complexity of enforcing GAC usually depends on the size of the tables. As a consequence, when a problem involves constraints of large arity and/or large tables, enforcing s(C)DC may become penalizing. This is the case for the renault-mod, tsp-20 and tsp-25 series in Table 3.\nA third lesson is that enforcing sDC at preprocessing tends to make the MAC algorithm more robust. To confirm this, Figure 16 shows two cactus-shaped plots that give some insight on the relative performance of the variants of MAC on the whole range of tested problem instances. These plots show that establishing sDC before searching for a solution using MAC enhances the robustness of the solver, especially when the variable ordering heuristic fails. With the dom/ddeg variable ordering heuristic, plain MAC is almost always worse than MAC with some second-order consistency established during the preprocessing. With the better dom/wdeg variable ordering heuristic, enforcing a second-order consistency is interesting for the hardest problems, those that require more than 50 seconds to be solved. A zoom in Figure 16(b) on MAC versus sDC1-MAC shows how the trend is reversed: after 50 seconds, sDC1-MAC solves more instances than MAC.\nWe conclude this section with an experiment on the hardest instances from the RLFAP series scens11 (see e.g., the results at http://www.cril.fr/{CPAI06,CPAI08,CPAI09}). Using the variable ordering heuristic dom/wdeg, we ran plain MAC, MAC with the symmetrybreaking method described by Lecoutre & Tabary (2009, denoted MACSB here), s(C)DCMAC, and finally MAC with both inference mechanisms. Enforcing sCDC permits to reduce the size of the search tree developed by MAC on these instances, but for sDC, this is less obvious (the added constraints perturbate the heuristic), as shown by Table 5. Interestingly, the joint use of the symmetry-breaking method reveals to be quite efficient here. Using both inference mechanisms, the unsatisfiability of all instances can be proved without any search effort (0 nodes in the sCDC1-MACSB and sDC1-MACSB columns). Note that SAC-MACSB builds a search tree for these problems, and it is not even possible to solve\n9. For example, we discarded the fapp series of problem instances, for which consistencies based on singleton checks are clearly not adapted because of the huge number of values.\nthe instance scen11-f1 with SAC1-MACSB (or SAC3-MACSB) equipped with the heuristic dom/ddeg, within 20 minutes."
    }, {
      "heading" : "7. Conclusion",
      "text" : "This paper is intended to give a better picture of second-order consistencies. For this purpose, we have studied the theoretical relationships existing between four basic second-order consistencies (and their variants), and we have shown that some of them can be reasonably enforced before search. However, in the next generation of constraint solvers, tractable classes of CSP instances will certainly have to be identified and exploited during search, in order to close, for example, certain nodes of the search tree in polynomial time. Because several theoretical results relate global consistency to second-order consistencies (e.g., strong 3-consistency), this should increase the importance of second-order consistencies.\nIn practical terms, there are some advantages of using (conservative) dual consistency. Algorithms to enforce strong (C)DC are rather easy to implement, and made efficient because of highly optimized underlying GAC algorithms. Used at preprocessing, they reveal to improve the robustness of a constraint solver on several hard structured problems. (C)2SAC is stronger than (C)DC, but a naive approach for establishing it requires several passes of O(n2d2) enforcements of GAC, which makes it ineffective. A perspective of this work is to devise efficient algorithms for (C)2SAC that could be competitive with (C)DC ones.\nFinally, as multi-core processors become increasingly common, parallel constraint solving should become more and more useful. In the near future, we may imagine that strong second-order consistencies could be used as basic components (with strong inference capabilities) of parallel solvers."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This paper is an extended revised version of earlier works (Lecoutre et al., 2007a, 2007b). We would like to thank the anonymous reviewers for their constructive remarks."
    } ],
    "references" : [ {
      "title" : "Maintaining knowledge about temporal intervals",
      "author" : [ "J. Allen" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "Allen,? \\Q1983\\E",
      "shortCiteRegEx" : "Allen",
      "year" : 1983
    }, {
      "title" : "The essence of constraint propagation",
      "author" : [ "K. Apt" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "Apt,? \\Q1999\\E",
      "shortCiteRegEx" : "Apt",
      "year" : 1999
    }, {
      "title" : "Principles of Constraint Programming",
      "author" : [ "K. Apt" ],
      "venue" : null,
      "citeRegEx" : "Apt,? \\Q2003\\E",
      "shortCiteRegEx" : "Apt",
      "year" : 2003
    }, {
      "title" : "Extending Forward Checking",
      "author" : [ "F. Bacchus" ],
      "venue" : "In Proceedings of CP’00,",
      "citeRegEx" : "Bacchus,? \\Q2000\\E",
      "shortCiteRegEx" : "Bacchus",
      "year" : 2000
    }, {
      "title" : "Improving domain filtering using restricted path consistency",
      "author" : [ "P. Berlandier" ],
      "venue" : "In Proceedings of IEEE-CAIA’95",
      "citeRegEx" : "Berlandier,? \\Q1995\\E",
      "shortCiteRegEx" : "Berlandier",
      "year" : 1995
    }, {
      "title" : "Constraint propagation",
      "author" : [ "C. Bessiere" ],
      "venue" : "In Handbook of Constraint Programming,",
      "citeRegEx" : "Bessiere,? \\Q2006\\E",
      "shortCiteRegEx" : "Bessiere",
      "year" : 2006
    }, {
      "title" : "Apprentissage de contraintes globales implicites",
      "author" : [ "C. Bessiere", "R. Coletta", "T. Petit" ],
      "venue" : "In Proceedings of JFPC’05,",
      "citeRegEx" : "Bessiere et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Bessiere et al\\.",
      "year" : 2005
    }, {
      "title" : "Optimal and suboptimal singleton arc consistency algorithms",
      "author" : [ "C. Bessiere", "R. Debruyne" ],
      "venue" : "In Proceedings of IJCAI’05,",
      "citeRegEx" : "Bessiere and Debruyne,? \\Q2005\\E",
      "shortCiteRegEx" : "Bessiere and Debruyne",
      "year" : 2005
    }, {
      "title" : "Theoretical analysis of singleton arc consistency and its extensions",
      "author" : [ "C. Bessiere", "R. Debruyne" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Bessiere and Debruyne,? \\Q2008\\E",
      "shortCiteRegEx" : "Bessiere and Debruyne",
      "year" : 2008
    }, {
      "title" : "On Forward Checking for non-binary constraint satisfaction",
      "author" : [ "C. Bessiere", "P. Meseguer", "E. Freuder", "J. Larrosa" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Bessiere et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Bessiere et al\\.",
      "year" : 2002
    }, {
      "title" : "MAC and combined heuristics: two reasons to forsake FC (and CBJ?) on hard problems",
      "author" : [ "C. Bessiere", "J. Régin" ],
      "venue" : "In Proceedings of CP’96,",
      "citeRegEx" : "Bessiere and Régin,? \\Q1996\\E",
      "shortCiteRegEx" : "Bessiere and Régin",
      "year" : 1996
    }, {
      "title" : "Domain filtering consistencies for non-binary constraints",
      "author" : [ "C. Bessiere", "K. Stergiou", "T. Walsh" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Bessiere et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Bessiere et al\\.",
      "year" : 2008
    }, {
      "title" : "Path consistency on triangulated constraint graphs",
      "author" : [ "C. Bliek", "D. Sam-Haroud" ],
      "venue" : "In Proceedings of IJCAI’99,",
      "citeRegEx" : "Bliek and Sam.Haroud,? \\Q1999\\E",
      "shortCiteRegEx" : "Bliek and Sam.Haroud",
      "year" : 1999
    }, {
      "title" : "Boosting systematic search by weighting constraints",
      "author" : [ "F. Boussemart", "F. Hemery", "C. Lecoutre", "L. Sais" ],
      "venue" : "In Proceedings of ECAI’04,",
      "citeRegEx" : "Boussemart et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Boussemart et al\\.",
      "year" : 2004
    }, {
      "title" : "Support inference for generic filtering",
      "author" : [ "F. Boussemart", "F. Hemery", "C. Lecoutre", "L. Sais" ],
      "venue" : "In Proceedings of CP’04,",
      "citeRegEx" : "Boussemart et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Boussemart et al\\.",
      "year" : 2004
    }, {
      "title" : "Efficient path-consistency propagation",
      "author" : [ "A. Chmeiss", "P. Jégou" ],
      "venue" : "International Journal on Artificial Intelligence Tools,",
      "citeRegEx" : "Chmeiss and Jégou,? \\Q1998\\E",
      "shortCiteRegEx" : "Chmeiss and Jégou",
      "year" : 1998
    }, {
      "title" : "Characterising tractable constraints",
      "author" : [ "M. Cooper", "D. Cohen", "P. Jeavons" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Cooper et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Cooper et al\\.",
      "year" : 1994
    }, {
      "title" : "Using pivot consistency to decompose and solve functional CSPs",
      "author" : [ "P. David" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "David,? \\Q1995\\E",
      "shortCiteRegEx" : "David",
      "year" : 1995
    }, {
      "title" : "Consistances locales pour les problÃĺmes de satisfaction de contraintes de grande taille",
      "author" : [ "R. Debruyne" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "Debruyne,? \\Q1998\\E",
      "shortCiteRegEx" : "Debruyne",
      "year" : 1998
    }, {
      "title" : "A strong local consistency for constraint satisfaction",
      "author" : [ "R. Debruyne" ],
      "venue" : "In Proceedings of ICTAI’99,",
      "citeRegEx" : "Debruyne,? \\Q1999\\E",
      "shortCiteRegEx" : "Debruyne",
      "year" : 1999
    }, {
      "title" : "From restricted path consistency to max-restricted path consistency",
      "author" : [ "R. Debruyne", "C. Bessiere" ],
      "venue" : "In Proceedings of CP’97,",
      "citeRegEx" : "Debruyne and Bessiere,? \\Q1997\\E",
      "shortCiteRegEx" : "Debruyne and Bessiere",
      "year" : 1997
    }, {
      "title" : "Some practical filtering techniques for the constraint satisfaction problem",
      "author" : [ "R. Debruyne", "C. Bessiere" ],
      "venue" : "In Proceedings of IJCAI’97,",
      "citeRegEx" : "Debruyne and Bessiere,? \\Q1997\\E",
      "shortCiteRegEx" : "Debruyne and Bessiere",
      "year" : 1997
    }, {
      "title" : "Domain filtering consistencies",
      "author" : [ "R. Debruyne", "C. Bessiere" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Debruyne and Bessiere,? \\Q2001\\E",
      "shortCiteRegEx" : "Debruyne and Bessiere",
      "year" : 2001
    }, {
      "title" : "From local to global consistency",
      "author" : [ "R. Dechter" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Dechter,? \\Q1992\\E",
      "shortCiteRegEx" : "Dechter",
      "year" : 1992
    }, {
      "title" : "Constraint processing",
      "author" : [ "R. Dechter" ],
      "venue" : null,
      "citeRegEx" : "Dechter,? \\Q2003\\E",
      "shortCiteRegEx" : "Dechter",
      "year" : 2003
    }, {
      "title" : "Network-based heuristics for constraint satisfaction problems",
      "author" : [ "R. Dechter", "J. Pearl" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Dechter and Pearl,? \\Q1988\\E",
      "shortCiteRegEx" : "Dechter and Pearl",
      "year" : 1988
    }, {
      "title" : "Synthesizing constraint expressions",
      "author" : [ "E. Freuder" ],
      "venue" : "Communication of the ACM,",
      "citeRegEx" : "Freuder,? \\Q1978\\E",
      "shortCiteRegEx" : "Freuder",
      "year" : 1978
    }, {
      "title" : "A sufficient condition for backtrack-free search",
      "author" : [ "E. Freuder" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Freuder,? \\Q1982\\E",
      "shortCiteRegEx" : "Freuder",
      "year" : 1982
    }, {
      "title" : "Completing quasigroups or latin squares: a structured graph coloring problem",
      "author" : [ "C. Gomes", "D. Shmoys" ],
      "venue" : "In Proceedings of Computational Symposium on Graph Coloring and Generalization",
      "citeRegEx" : "Gomes and Shmoys,? \\Q2002\\E",
      "shortCiteRegEx" : "Gomes and Shmoys",
      "year" : 2002
    }, {
      "title" : "Domain permutation reduction for constraint satisfaction problems",
      "author" : [ "M. Green", "D. Cohen" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Green and Cohen,? \\Q2008\\E",
      "shortCiteRegEx" : "Green and Cohen",
      "year" : 2008
    }, {
      "title" : "Decomposition of domains based on the micro-structure of finite constraint-satisfaction problems",
      "author" : [ "P. Jégou" ],
      "venue" : "In Proceedings of AAAI’93,",
      "citeRegEx" : "Jégou,? \\Q1993\\E",
      "shortCiteRegEx" : "Jégou",
      "year" : 1993
    }, {
      "title" : "Unrestricted nogood recording in CSP search",
      "author" : [ "G. Katsirelos", "F. Bacchus" ],
      "venue" : "In Proceedings of CP’03,",
      "citeRegEx" : "Katsirelos and Bacchus,? \\Q2003\\E",
      "shortCiteRegEx" : "Katsirelos and Bacchus",
      "year" : 2003
    }, {
      "title" : "Optimization of simple tabular reduction for table constraints",
      "author" : [ "C. Lecoutre" ],
      "venue" : "In Proceedings of CP’08,",
      "citeRegEx" : "Lecoutre,? \\Q2008\\E",
      "shortCiteRegEx" : "Lecoutre",
      "year" : 2008
    }, {
      "title" : "Constraint networks: techniques and algorithms. ISTE/Wiley",
      "author" : [ "C. Lecoutre" ],
      "venue" : null,
      "citeRegEx" : "Lecoutre,? \\Q2009\\E",
      "shortCiteRegEx" : "Lecoutre",
      "year" : 2009
    }, {
      "title" : "Backjump-based techniques versus conflict-directed heuristics",
      "author" : [ "C. Lecoutre", "F. Boussemart", "F. Hemery" ],
      "venue" : "In Proceedings of ICTAI’04,",
      "citeRegEx" : "Lecoutre et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Lecoutre et al\\.",
      "year" : 2004
    }, {
      "title" : "A greedy approach to establish singleton arc consistency",
      "author" : [ "C. Lecoutre", "S. Cardon" ],
      "venue" : "In Proceedings of IJCAI’05,",
      "citeRegEx" : "Lecoutre and Cardon,? \\Q2005\\E",
      "shortCiteRegEx" : "Lecoutre and Cardon",
      "year" : 2005
    }, {
      "title" : "Conservative dual consistency",
      "author" : [ "C. Lecoutre", "S. Cardon", "J. Vion" ],
      "venue" : "In Proceedings of AAAI’07,",
      "citeRegEx" : "Lecoutre et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Lecoutre et al\\.",
      "year" : 2007
    }, {
      "title" : "Path consistency by dual consistency",
      "author" : [ "C. Lecoutre", "S. Cardon", "J. Vion" ],
      "venue" : "In Proceedings of CP’07,",
      "citeRegEx" : "Lecoutre et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Lecoutre et al\\.",
      "year" : 2007
    }, {
      "title" : "A study of residual supports in arc consistency",
      "author" : [ "C. Lecoutre", "F. Hemery" ],
      "venue" : "In Proceedings of IJCAI’07,",
      "citeRegEx" : "Lecoutre and Hemery,? \\Q2007\\E",
      "shortCiteRegEx" : "Lecoutre and Hemery",
      "year" : 2007
    }, {
      "title" : "Lightweight detection of variable symmetries for constraint satisfaction",
      "author" : [ "C. Lecoutre", "S. Tabary" ],
      "venue" : "In Proceedings of ICTAI’09,",
      "citeRegEx" : "Lecoutre and Tabary,? \\Q2009\\E",
      "shortCiteRegEx" : "Lecoutre and Tabary",
      "year" : 2009
    }, {
      "title" : "Enforcing arc consistency using bitwise operations",
      "author" : [ "C. Lecoutre", "J. Vion" ],
      "venue" : "Constraint Programming Letters,",
      "citeRegEx" : "Lecoutre and Vion,? \\Q2008\\E",
      "shortCiteRegEx" : "Lecoutre and Vion",
      "year" : 2008
    }, {
      "title" : "Consistency in networks of relations",
      "author" : [ "A. Mackworth" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Mackworth,? \\Q1977\\E",
      "shortCiteRegEx" : "Mackworth",
      "year" : 1977
    }, {
      "title" : "Relational consistency algorithms and their application in finding subgraph and graph isomorphisms",
      "author" : [ "J. McGregor" ],
      "venue" : "Information Sciences,",
      "citeRegEx" : "McGregor,? \\Q1979\\E",
      "shortCiteRegEx" : "McGregor",
      "year" : 1979
    }, {
      "title" : "Good old discrete relaxation",
      "author" : [ "R. Mohr", "G. Masini" ],
      "venue" : "In Proceedings of ECAI’88,",
      "citeRegEx" : "Mohr and Masini,? \\Q1988\\E",
      "shortCiteRegEx" : "Mohr and Masini",
      "year" : 1988
    }, {
      "title" : "Network of constraints : Fundamental properties and applications to picture processing",
      "author" : [ "U. Montanari" ],
      "venue" : "Information Science,",
      "citeRegEx" : "Montanari,? \\Q1974\\E",
      "shortCiteRegEx" : "Montanari",
      "year" : 1974
    }, {
      "title" : "Constraint relaxation may be perfect",
      "author" : [ "U. Montanari", "F. Rossi" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Montanari and Rossi,? \\Q1991\\E",
      "shortCiteRegEx" : "Montanari and Rossi",
      "year" : 1991
    }, {
      "title" : "Contradicting conventional wisdom in constraint satisfaction",
      "author" : [ "D. Sabin", "E. Freuder" ],
      "venue" : "In Proceedings of CP’94,",
      "citeRegEx" : "Sabin and Freuder,? \\Q1994\\E",
      "shortCiteRegEx" : "Sabin and Freuder",
      "year" : 1994
    }, {
      "title" : "Variable and value ordering heuristics for the job shop scheduling constraint satisfaction problem",
      "author" : [ "N. Sadeh", "M. Fox" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Sadeh and Fox,? \\Q1996\\E",
      "shortCiteRegEx" : "Sadeh and Fox",
      "year" : 1996
    }, {
      "title" : "Nogood recording for static and dynamic constraint satisfaction problems",
      "author" : [ "T. Schiex", "G. Verfaillie" ],
      "venue" : "International Journal of Artificial Intelligence Tools,",
      "citeRegEx" : "Schiex and Verfaillie,? \\Q1994\\E",
      "shortCiteRegEx" : "Schiex and Verfaillie",
      "year" : 1994
    }, {
      "title" : "Inverse consistencies for non-binary constraints",
      "author" : [ "K. Stergiou", "T. Walsh" ],
      "venue" : "In Proceedings of ECAI’06,",
      "citeRegEx" : "Stergiou and Walsh,? \\Q2006\\E",
      "shortCiteRegEx" : "Stergiou and Walsh",
      "year" : 2006
    }, {
      "title" : "Benchmarks for basic scheduling problems",
      "author" : [ "E. Taillard" ],
      "venue" : "European journal of operations research,",
      "citeRegEx" : "Taillard,? \\Q1993\\E",
      "shortCiteRegEx" : "Taillard",
      "year" : 1993
    }, {
      "title" : "Foundations of constraint satisfaction",
      "author" : [ "E. Tsang" ],
      "venue" : null,
      "citeRegEx" : "Tsang,? \\Q1993\\E",
      "shortCiteRegEx" : "Tsang",
      "year" : 1993
    }, {
      "title" : "On the minimality and decomposability of constraint networks",
      "author" : [ "P. van Beek" ],
      "venue" : "In Proceedings of AAAI’92,",
      "citeRegEx" : "Beek,? \\Q1992\\E",
      "shortCiteRegEx" : "Beek",
      "year" : 1992
    }, {
      "title" : "Set intersection and consistency in constraint networks",
      "author" : [ "Y. Zhang", "R. Yap" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Zhang and Yap,? \\Q2006\\E",
      "shortCiteRegEx" : "Zhang and Yap",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 41,
      "context" : "The most studied second-order consistency is path consistency (PC, Montanari, 1974; Mackworth, 1977).",
      "startOffset" : 62,
      "endOffset" : 100
    }, {
      "referenceID" : 0,
      "context" : "Indeed, for some classes of interval algebra, path consistency – adapted to temporal constraint networks (Allen, 1983) – is sufficient to decide satisfiability.",
      "startOffset" : 105,
      "endOffset" : 118
    }, {
      "referenceID" : 0,
      "context" : "Indeed, for some classes of interval algebra, path consistency – adapted to temporal constraint networks (Allen, 1983) – is sufficient to decide satisfiability. Another possible reason for the low practical interest for path consistency, in the discrete constraint satisfaction field, is that path consistency enforcement modifies constraint relations, and more importantly, modifies the structure of the constraint graph. When a pair of values (a, b) for the variables (x, y) is found to be path-inconsistent, this information is recorded within the constraint network; if there is no constraint binding x with y, a new one is inserted, thus changing the constraint graph. For example, the instance scen-11 of the radio link frequency assignment problem (Cabon, de Givry, Lobjois, Schiex, & Warners, 1999) involves 680 variables and 4,103 constraints. Enforcing a second-order consistency on this network could at worst create (680 2 ) − 4,103 = 226,757 new constraints, which would be really counter-productive both in time and in space. The main apparent drawback of path consistency can be avoided by adopting a conservative approach, in which the search for inconsistent pairs of values is restricted to existing constraints. This is called conservative path consistency (CPC, Debruyne, 1999) when restricted to paths of length 2 in the constraint graph, and partial path consistency (PPC, Bliek & Sam-Haroud, 1999) when restricted to paths of arbitrary length in the constraint graph; CPC and PPC are equivalent when the constraint graph is triangulated. In this paper, we study path consistency as well as three other basic second-order consistencies that are 3-consistency (3C, Freuder, 1978), dual consistency (DC, Lecoutre, Cardon, & Vion, 2007a) and 2-singleton arc consistency (2SAC, Bessiere, Coletta, & Petit, 2005). On binary constraint networks, DC is equivalent to PC – McGregor (1979) proposed an DC-like algorithm to establish (strong) path consistency – but when considering weaker conservative variants, we show that conservative dual consistency (CDC) is strictly stronger than PPC and CPC: CDC can filter out more inconsistent pairs of values (from existing constraints) than PPC or CPC.",
      "startOffset" : 106,
      "endOffset" : 1903
    }, {
      "referenceID" : 2,
      "context" : "constraints of similar scope – CNs are normalized (Apt, 2003; Bessiere, 2006).",
      "startOffset" : 50,
      "endOffset" : 77
    }, {
      "referenceID" : 5,
      "context" : "constraints of similar scope – CNs are normalized (Apt, 2003; Bessiere, 2006).",
      "startOffset" : 50,
      "endOffset" : 77
    }, {
      "referenceID" : 24,
      "context" : "In many cases, a CSP instance can be solved by using a combination of search and inferential simplification (Dechter, 2003; Lecoutre, 2009).",
      "startOffset" : 108,
      "endOffset" : 139
    }, {
      "referenceID" : 33,
      "context" : "In many cases, a CSP instance can be solved by using a combination of search and inferential simplification (Dechter, 2003; Lecoutre, 2009).",
      "startOffset" : 108,
      "endOffset" : 139
    }, {
      "referenceID" : 30,
      "context" : "On the other hand, the compatibility (hyper)graph, also called micro-structure (Jégou, 1993), associated with a normalized CN P contains one vertex per value of P and one (hyper)edge per constraint support.",
      "startOffset" : 79,
      "endOffset" : 92
    }, {
      "referenceID" : 5,
      "context" : "11 in the work of Bessiere (2006) – when they have the same canonical form, i.",
      "startOffset" : 18,
      "endOffset" : 34
    }, {
      "referenceID" : 5,
      "context" : "This formalism is also related to previous works about local consistencies and rules iteration (e.g., see Montanari & Rossi, 1991; Apt, 1999, 2003; Bessiere, 2006).",
      "startOffset" : 95,
      "endOffset" : 163
    }, {
      "referenceID" : 33,
      "context" : "(Lecoutre, 2009) Any stable nogood-identifying consistency is well-behaved.",
      "startOffset" : 0,
      "endOffset" : 16
    }, {
      "referenceID" : 5,
      "context" : "Stability under union can also be proved for a domain-filtering consistency, thus guaranteeing a fixed point (Bessiere, 2006).",
      "startOffset" : 109,
      "endOffset" : 125
    }, {
      "referenceID" : 1,
      "context" : ", see Montanari & Rossi, 1991; Apt, 1999, 2003; Bessiere, 2006). It is usually possible to enforce φ on a CN P by computing the greatest φ-consistent CN smaller than or equal to P , while preserving the set of solutions. A consistency is well-behaved when for any CN P ∈P, the set {P ′ ∈P | P ′ is φ-consistent and P ′ P} admits a greatest element, denoted by φ(P ), that is equivalent to P and called the φ-closure of P . Enforcing φ on a CN P means computing φ(P ), and an algorithm that enforces φ is called a φ-algorithm. The property of stability is useful for proving that a nogood-identifying consistency is well-behaved. A nogood-identifying consistency φ is stable iff for every CN P ∈P, every CN P ′ ∈P such that P ′ P and every φ-inconsistent instantiation I on P , we have either I ∈ P̃ ′ or I is φ-inconsistent on P ′; the second condition for stability given by Lecoutre (2009) holds necessarily because of the choice of the poset in this paper.",
      "startOffset" : 31,
      "endOffset" : 892
    }, {
      "referenceID" : 40,
      "context" : "Introduced by Montanari (1974), its definition has sometimes been misinterpreted.",
      "startOffset" : 14,
      "endOffset" : 31
    }, {
      "referenceID" : 40,
      "context" : "Introduced by Montanari (1974), its definition has sometimes been misinterpreted. The problem arises around the definition of a “path”, which must be understood as any sequence of variables, and not as a sequence of variables that corresponds to a path in the constraint graph. This ambiguity probably comes from Montanari’s original paper, in which reasoning from path consistency is achieved with respect to complete (or completion of) constraint graphs, although a footnote in the original paper indicates: “A path in a network is any sequence of vertices. A vertex can occur more than once in a path even in consecutive positions.” A precise definition of path is thus required. The definition of path below is used by Montanari (1974), Mackworth (1977) and Debruyne (1998), while the definition of graphpath is used, for example, by Tsang (1993) or Bessiere (2006).",
      "startOffset" : 14,
      "endOffset" : 740
    }, {
      "referenceID" : 38,
      "context" : "The definition of path below is used by Montanari (1974), Mackworth (1977) and Debruyne (1998), while the definition of graphpath is used, for example, by Tsang (1993) or Bessiere (2006).",
      "startOffset" : 58,
      "endOffset" : 75
    }, {
      "referenceID" : 17,
      "context" : "The definition of path below is used by Montanari (1974), Mackworth (1977) and Debruyne (1998), while the definition of graphpath is used, for example, by Tsang (1993) or Bessiere (2006).",
      "startOffset" : 79,
      "endOffset" : 95
    }, {
      "referenceID" : 17,
      "context" : "The definition of path below is used by Montanari (1974), Mackworth (1977) and Debruyne (1998), while the definition of graphpath is used, for example, by Tsang (1993) or Bessiere (2006).",
      "startOffset" : 79,
      "endOffset" : 168
    }, {
      "referenceID" : 5,
      "context" : "The definition of path below is used by Montanari (1974), Mackworth (1977) and Debruyne (1998), while the definition of graphpath is used, for example, by Tsang (1993) or Bessiere (2006). A path is an arbitrary sequence of variables, and a graph-path is defined to be a sequence of variables such that a binary constraint exists between any two variables adjacent in the sequence.",
      "startOffset" : 171,
      "endOffset" : 187
    }, {
      "referenceID" : 41,
      "context" : "We can now introduce the historical definition of path consistency (PC, Montanari, 1974; Mackworth, 1977).",
      "startOffset" : 67,
      "endOffset" : 105
    }, {
      "referenceID" : 22,
      "context" : "Simply, non-binary constraints are ignored, as Dechter (2003) or Bessiere (2006) do, since in Definition 2, only pairs of variables are considered.",
      "startOffset" : 47,
      "endOffset" : 62
    }, {
      "referenceID" : 5,
      "context" : "Simply, non-binary constraints are ignored, as Dechter (2003) or Bessiere (2006) do, since in Definition 2, only pairs of variables are considered.",
      "startOffset" : 65,
      "endOffset" : 81
    }, {
      "referenceID" : 44,
      "context" : "(Montanari, 1974) A CN P is path-consistent iff every 2-length path of P (i.",
      "startOffset" : 0,
      "endOffset" : 17
    }, {
      "referenceID" : 47,
      "context" : "For example, Definition 3-11 in a work of Tsang (1993) links PC to graph-paths, and Proposition 3.",
      "startOffset" : 42,
      "endOffset" : 55
    }, {
      "referenceID" : 5,
      "context" : "39 in a work of Bessiere (2006) links PC to 2-length graph-paths, but Observations 1 and 2 (with Figure 4) show that this is not equivalent to Montanari’s definition.",
      "startOffset" : 16,
      "endOffset" : 32
    }, {
      "referenceID" : 51,
      "context" : "As additional weak forms of path consistency, we find directional path consistency (Dechter & Pearl, 1988; Tsang, 1993) and pivot consistency (David, 1995), but they will not be discussed in this paper.",
      "startOffset" : 83,
      "endOffset" : 119
    }, {
      "referenceID" : 17,
      "context" : "As additional weak forms of path consistency, we find directional path consistency (Dechter & Pearl, 1988; Tsang, 1993) and pivot consistency (David, 1995), but they will not be discussed in this paper.",
      "startOffset" : 142,
      "endOffset" : 155
    }, {
      "referenceID" : 32,
      "context" : "We now introduce dual consistency (Lecoutre et al., 2007a). Dual consistency, whose idea has initially been used by McGregor (1979), records inconsistent pairs of values identified by successive singleton checks.",
      "startOffset" : 35,
      "endOffset" : 132
    }, {
      "referenceID" : 42,
      "context" : "This could be predicted since McGregor proposed an AC-based algorithm to establish sPC (1979). We show this in 2 steps.",
      "startOffset" : 30,
      "endOffset" : 94
    }, {
      "referenceID" : 33,
      "context" : "Such a procedure is guaranteed to compute AC (P|x=a) (cf. Apt, 2003; Lecoutre, 2009).",
      "startOffset" : 53,
      "endOffset" : 84
    }, {
      "referenceID" : 33,
      "context" : "It has been shown that the schema of previous propositions does not hold for CPC and PPC (Lecoutre, 2009).",
      "startOffset" : 89,
      "endOffset" : 105
    }, {
      "referenceID" : 5,
      "context" : "This means that just after the last instruction of each iteration of the foreach loop starting at Line 2 of Algorithm 2, P is such that after assigning again a to x, applying forward checking (any non-binary version, Bessiere, Meseguer, Freuder, & Larrosa, 2002) is enough to enforce GAC: we only need to consider binary constraints involving x and delete values that are not consistent with (x, a). This is studied in a paper by Lecoutre et al. (2007b). Finally, it is worthwhile to mention that Algorithm 1 does not require specific data structure.",
      "startOffset" : 217,
      "endOffset" : 454
    }, {
      "referenceID" : 32,
      "context" : "In AbsCon, the algorithms used to enforce (G)AC are AC3bit+rm (Lecoutre & Vion, 2008) for binary constraints, GAC3rm (Lecoutre & Hemery, 2007) for non-binary constraints defined in intension, and STR2 (Lecoutre, 2008) for non-binary constraints in extension.",
      "startOffset" : 201,
      "endOffset" : 217
    }, {
      "referenceID" : 29,
      "context" : "algorithm sDC1, as proposed by Lecoutre et al. (2007b), are also possible but will not be considered in this paper, mainly because such optimizations are rather marginal (a speedup of 10% on some problems) with respect to our main concern: showing that enforcing s(C)DC before search may pay off.",
      "startOffset" : 31,
      "endOffset" : 55
    }, {
      "referenceID" : 3,
      "context" : "ehi: series of SAT instances converted into CSP using the dual method as described by Bacchus (2000); there are 7 values per domain and constraints are binary.",
      "startOffset" : 86,
      "endOffset" : 101
    }, {
      "referenceID" : 3,
      "context" : "ehi: series of SAT instances converted into CSP using the dual method as described by Bacchus (2000); there are 7 values per domain and constraints are binary. langford: series from the (generalized version of the) Langford problem; domains of variables are usually not small (up to 150 values) and constraints are binary. os-taillard: series of Open-Shop scheduling instances generated by J. Vion from Taillard’s paper (1993); domains are large and constraints are binary.",
      "startOffset" : 86,
      "endOffset" : 427
    }, {
      "referenceID" : 3,
      "context" : "ehi: series of SAT instances converted into CSP using the dual method as described by Bacchus (2000); there are 7 values per domain and constraints are binary. langford: series from the (generalized version of the) Langford problem; domains of variables are usually not small (up to 150 values) and constraints are binary. os-taillard: series of Open-Shop scheduling instances generated by J. Vion from Taillard’s paper (1993); domains are large and constraints are binary. primes: series of instances involving prime numbers generated by M. van Dongen; domains of variables are not small and some constraints are non-binary. qcp / qwh: series from the Quasi-group Completion Problem (QCP) and the Quasi-group With Holes problem (QWH); domains are not very large and constraints are binary. queensKnights: series of academic instances with queens and knights to be put on a chessboard (Boussemart et al., 2004a); some domains are large and constraints are binary. radar: realistic radar surveillance problems generated following the model of the Swedish institute of computer science (SICS); domains are small and constraints non-binary. renault-mod: series of instances generated by K. Stergiou from a Renault Megane configuration problem; domains are diverse and constraints are non-binary. sadeh: series containing the five sets of job-shop scheduling instances studied by Sadeh & Fox (1996); domains are large and constraints are binary.",
      "startOffset" : 86,
      "endOffset" : 1395
    }, {
      "referenceID" : 13,
      "context" : "Table 3 confirms that MAC equipped with the heuristic dom/wdeg is far more robust than dom/ddeg, as initially claimed by Boussemart et al. (2004a). As a result, on some series, enforcing a strong consistency (i.",
      "startOffset" : 121,
      "endOffset" : 147
    } ],
    "year" : 2011,
    "abstractText" : "In this paper, we propose a comprehensive study of second-order consistencies (i.e., consistencies identifying inconsistent pairs of values) for constraint satisfaction. We build a full picture of the relationships existing between four basic second-order consistencies, namely path consistency (PC), 3-consistency (3C), dual consistency (DC) and 2-singleton arc consistency (2SAC), as well as their conservative and strong variants. Interestingly, dual consistency is an original property that can be established by using the outcome of the enforcement of generalized arc consistency (GAC), which makes it rather easy to obtain since constraint solvers typically maintain GAC during search. On binary constraint networks, DC is equivalent to PC, but its restriction to existing constraints, called conservative dual consistency (CDC), is strictly stronger than traditional conservative consistencies derived from path consistency, namely partial path consistency (PPC) and conservative path consistency (CPC). After introducing a general algorithm to enforce strong (C)DC, we present the results of an experimentation over a wide range of benchmarks that demonstrate the interest of (conservative) dual consistency. In particular, we show that enforcing (C)DC before search clearly improves the performance of MAC (the algorithm that maintains GAC during search) on several binary and non-binary structured problems.",
    "creator" : "TeX"
  }
}