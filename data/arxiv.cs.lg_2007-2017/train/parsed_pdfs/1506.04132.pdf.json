{
  "name" : "1506.04132.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Stochastic Expectation Propagation",
    "authors" : [ "Yingzhen Li", "José Miguel Hernández-Lobato" ],
    "emails" : [ "yl494@cam.ac.uk", "jmh@seas.harvard.edu", "ret26@cam.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 6.\n04 13\n2v 1\n[ st\nat .M\nL ]\n1 2\nJu n"
    }, {
      "heading" : "1 Introduction",
      "text" : "Recently a number of methods have been developed for applying Bayesian learning to large datasets. Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6]. One family of approximation method has garnered less attention in this regard: Expectation propagation (EP) [7][8]. EP constructs a posterior approximation by iterating simple local computations that refine factors which approximate the posterior-contribution from each datapoint. At first sight, it therefore appears well suited to large-data problems: the locality of computation make the algorithm simple to parallelise and distribute, and good practical performance on a range of small-data applications suggest that it will be accurate [9, 10, 11]. On the other hand, there is a critical computational bottleneck in the standard EP approximation: each local approximating factor typically has the same complexity as the global approximation. This means that the EP algorithm has a memory overhead that grows with the number of data-points N , which makes it hard to scale rich models with many parameters to large-data settings (consider approximating the posterior distribution of a topic model with millions of parameters on a corpus containing billions of documents). The same pathology exists for the broader class of power-EP (PEP) algorithms [12] that includes variational message-passing [13]. The elegance of local computation has been bought at the price of having myriad local approximating factors. In contrast, variational inference (VI) methods [14, 15] utilise global approximations that are refined directly (rather than through local components) which prevents memory overheads from scaling with N .\nIs there ever a case for preferring EP (or PEP) to VI methods for large-data? We believe that there certainly is. First, EP can provide significantly more accurate approximations. It is well known that variational free-energy approaches are biased and often severely so [16] and for particular models the variational free-energy objective is pathologically ill-suited [11, 17]. Second, the fact that EP is truely\nlocal (to factors in the posterior distribution and not just likelihoods) means that it affords different opportunities for tractable algorithm design, as the updates can be simpler to approximate.\nAs EP appears to be the method of choice for some applications, researchers have attempted to push it to scale. One approach is to swallow the large computational burden and simply use large data-structures to store the approximating factors (e.g. TrueSkill [18]). This approach can only be pushed so far. A second approach is to use a simple variant of EP called assumed density filtering (ADF) which only requires a global approximation to be stored [19]. ADF, however, provides poorly calibrated uncertainty estimates [7] which was one of the main motivating reasons for developing EP in the first place. A third idea, complementary to the one described here, is to use approximating factors that have simpler structure (e.g. low rank, [20]). This reduces memory consumption (e.g. for Gaussian factors from O(ND2) to O(ND)), but does not stop the scaling with N . Another idea uses EP to carve up the dataset [5, 6] using approximating factors for collections of data-points. This results in coarse-grained, rather than local, updates and other methods must be used to compute them. (Indeed, the spirit of [5, 6] is to extend sampling methods to large-datasets, not EP itself.)\nThe question addressed in this paper is: can we have the best of both worlds? That is, accurate global approximations that are derived from truely local computation. For this purpose we develop an algorithm based upon the standard EP and ADF algorithms that maintains a global approximation which is updated in a local way. We call this class of algorithms stochastic EP (SEP) since it updates the global approximation with (damped) stochastic estimates on data sub-samples in an analogous way to SVI. Indeed, the generalisation of the algorithm to the PEP setting directly relates to SVI [3]. Tests on synthetic data indicate that SEP performs almost as well as full EP, but reduces the memory footprint by a factor of N , and that it has well calibrated uncertainty estimates, unlike ADF. We show how to extend the method to treat models with latent variables without compromising on accuracy or memory demands. Finally, we demonstrate the scalability and accuracy of the method on a number of real world and synthetic datasets."
    }, {
      "heading" : "2 Expectation Propagation and Assumed Density Filtering",
      "text" : "We begin by briefly reviewing the EP and ADF algorithms upon which our new method is based. Consider for simplicity observing a dataset comprising N i.i.d. samples D = {xn}Nn=1 from a probabilistic model p(x|θ) parametrised by an unknown D-dimensional vector θ that is drawn from a prior p0(θ). Exact Bayesian inference involves computing the (typically intractable) posterior distribution of the parameters given the data,\np(θ|D) ∝ p0(θ) N ∏\nn=1\np(xn|θ) ≈ q(θ) ∝ p0(θ) N ∏\nn=1\nfn(θ). (1)\nHere q(θ) is a simpler tractable approximating distribution that will be refined by EP. The goal of EP is to refine the approximate factors so that they capture the contribution of each of the likelihood terms to the posterior i.e. fn(θ) ≈ p(xn|θ). In this spirit, one approach would be to find each approximating factor fn(θ) by minimising the Kullback Leibler (KL) Divergence between the posterior and the distribution formed by replacing one of the likelihoods by its corresponding approximating factor, KL[p(θ|D)||p(θ|D)fn(θ)/p(xn|θ)]. Unfortunately, such an update is still intractable as it involves computing the full posterior. Instead, EP approximates this procedure by replacing the exact leave-one-out posterior p−n(θ) ∝ p(θ|D)/p(xn|θ) on both sides of the KL by the approximate leave-one-out posterior (called the cavity distribution) q−n(θ) ∝ q(θ)/fn(θ). Since this couples the updates for the approximating factors, the updates must now be iterated.\nIn more detail, EP iterates four simple steps. First, the factor selected for update is removed from the approximation to produce the cavity distribution. Second, the corresponding likelihood is included to produce the tilted distribution p̃n(θ) ∝ q−n(θ)p(xn|θ). Third EP updates the approximating factor by minimising KL[p̃n(θ)||q−n(θ)fn(θ)]. The hope is that the contribution the true-likelihood makes to the posterior is similar to the effect the same likelihood has on the tilted distribution. If the approximating distribution is in the exponential family, as is often the case, then the KL minimisation reduces to a moment-matching step [21] that we denote fn(θ) ← proj[p̃n(θ)]/q−n(θ). Finally, having updated the factor, it is included into the approximating distribution.\nWe summarise the update procedure for a single factor in Algorithm 1. Critically, the approximation step of EP involves local computations since one likelihood term is treated at a time. The assumption is that these local computations, although possibly requiring further approximation, are far simpler to\nhandle compared to the full posterior p(θ|D). In practice, EP often performs well when the updates are parallelised. Moreover, by using approximating factors for groups of data-points, and then running additional approximate inference algorithms to perform the EP updates (which could include nesting EP), EP carves up the data making it suitable for distributed approximate inference.\nThere is, however, one wrinkle that complicates deployment of EP at scale. Computation of the cavity distribution requires removal of the current approximating factor and this means that any implementation of EP must store them explicitly necessitating an O(N) memory footprint. One option is to simply ignore the removal step replacing the cavity distribution with the full approximation resulting in the ADF algorithm (see Algorithm 2). ADF has the advantage that only the global approximation need be maintained in memory, but as the moment matching step now over-counts the underlying approximating factor (consider the new form of the objective KL[q(θ)p(xn|θ)||q(θ)]) the variance of the approximation shrinks to zero as multiple passes are made through the dataset. Early stopping is therefore required to prevent overfitting and generally speaking ADF does not return uncertainties that are well-calibrated to the posterior. In the next section we introduce a new algorithm that sidesteps EP’s large memory demands whilst avoiding the pathological behaviour of ADF."
    }, {
      "heading" : "3 Stochastic Expectation Propagation",
      "text" : "In this section we introduce a new algorithm, inspired by EP, called Stochastic Expectation Propagation (SEP) that combines the benefits of local approximation (including tractability of updates, distributability, and parallelisability) with global approximation (reduced memory demands). The algorithm can be interpreted as a version of EP in which the approximating factors are tied, or alternatively as a corrected version of ADF that prevents overfitting.\nThe key idea is that, at convergence, the approximating factors in EP can be interpreted as parameterising a global factor, f(θ), that captures the average effect of a likelihood on the posterior f(θ)N △ =\n∏N n=1 fn(θ) ≈ ∏N n=1 p(xn|θ). In this spirit, the new algorithm employs direct iterative re-\nfinement of a global approximation comprising the prior and N copies of a single approximating factor, f(θ), that is q(θ) ∝ f(θ)Np0(θ).\nSEP uses updates that are analogous to EP’s in order to refine f(θ) in such a way that it captures the average effect a likelihood function has on the posterior. First the cavity distribution is formed by removing one of the copies of the factor, q−n(θ) ∝ q(θ)/f(θ). Second, the corresponding likelihood is included to produce the tilted distribution p̃n(θ) ∝ q−1(θ)p(xn|θ) and, third, EP finds an intermediate factor approximation by moment matching, fn(θ) ← proj[p̃n(θ)]/q−1(θ). Finally, having updated the factor, it is included into the approximating distribution. It is important here not to make a full update since fn(θ) captures the effect of just a single likelihood function p(xn|θ). Instead, damping should be employed to make a partial update f(θ) ← f(θ)1−ǫfn(θ)ǫ a natural choice uses ǫ = 1/N which can be interpreted as minimising KL[p̃n(θ)||p0(θ)f(θ)N ] in the moment update.\nSEP is summaried in Algorithm 3. Unlike ADF, the cavity is formed by dividing out f(θ) which captures the average affect of the likelihood and prevents the posterior from collapsing. Like ADF, however, memory allocation for f(θ) is unnecessary because it can be recovered from the approximate posterior, f(θ) ∝ (q(θ)/p0(θ)) 1 N and q−1(θ) ∝ q(θ)1− 1 N p0(θ) 1 N . When Gaussian approximating factors are used, for example, SEP reduces the storage requirement of EP from O(ND2) to O(D2) which is a substantial saving that enables models with many parameters to be applied to large datasets."
    }, {
      "heading" : "4 Algorithmic extensions to SEP and theoretical results",
      "text" : "SEP has been motivated from a practical perspective by the limitations inherent in EP and ADF. In this section we extend SEP in four orthogonal directions and through these extensions relate SEP to SVI. Many of the algorithms described in this section are summarised in Figure 2 and they are detailed in the supplementary material."
    }, {
      "heading" : "4.1 Parallel SEP: Relating the EP fixed points to SEP",
      "text" : "The SEP algorithm outlined above approximates one likelihood at a time which can be computationally slow. However, it is simple to parallelise the SEP updates by following the same recipe by which EP is parallelised. Consider a minibatch comprising M datapoints (for a full parallel (batch) update\nAlgorithm 1 EP\nAlgorithm 2 ADF\nAlgorithm 3 SEP\nuse M = N). First we form the cavity distribution for each likelihood. Unlike EP these are all identical. Next, in parallel, compute M intermediate factors fm(θ) ← proj[p̃m(θ)]/q−1(θ). In EP these intermediate factors become the new likelihood approximations and the approximation is updated to q(θ) = p0(θ) ∏ n6=m fn(θ) ∏ m fm(θ). In SEP, the same update is used for the approximating distribution, which becomes q(θ) ← p0(θ)fold(θ)N−M ∏ m fm(θ) and, by implication, the approximating factor is fnew(θ) = fold(θ) 1−M/N ∏M m=1 fm(θ) 1/N . One way of understanding parallel SEP is as a double loop algorithm. The inner loop produces intermediate approximations qm(θ) ← argminq KL(p̃m(θ)||q(θ)) △ = proj[p̃m(θ)] these are then combined in the outer loop: q(θ) ← argminq ∑M\nm=1 KL(q(θ)||qm(θ))+(N− M)KL[q(θ)||qold(θ)].\nFor M = 1 parallel SEP reduces to the original SEP algorithm. For M = N parallel SEP is equivalent to the so-called Averaged EP algorithm proposed in [22] as a theoretical tool to study the convergence properties of normal EP. This work showed that, under fairly restrictive conditions (likelihood functions that are log-concave and vary slowly as a function of the parameters), AEP converges to the same fixed points as EP in the large data limit (N → ∞).\nThere is another illuminating and arguable more direct connection between SEP and AEP. Since SEP’s approximating factor f(θ) converges, in expectation, to the geometric average of the intermediate factors f̄(θ) ∝ [ ∏N\nn=1 fn(θ)] 1 N , SEP converges in expectation to the same fixed points as AEP, and\ntherefore under certain conditions [22], to the same fixed points as EP. It is possible that there are more direct relationships between EP fixed points and SEP’s dynamics in expectation, but that is still an open question."
    }, {
      "heading" : "4.2 Stochastic Power EP: Relationships to variational methods",
      "text" : "The relationship between variational inference and stochastic variational inference [3] mirrors the relationship between EP and SEP. Can these relationships be made more formal? If the moment projection step in EP is replaced by a natural parameter matching step then the resulting algorithm is equivalent to the Variational Message Passing (VMP) algorithm [23] (and see supplementary material). Moreover, VMP has the same fixed points as variational inference [13] (since minimising the local variational KL divergences is equivalent to minimising the global variational KL).\nThese results carry over to the new algorithms with minor modifications. Specifically VMP can be transformed into SVMP by using the same (global) form of approximation as used by SEP. In the supplementary material we show that this algorithm is an instance of standard SVI and that it therefore has the same fixed points in expectation as VI. More generally, the procedure can be applied any member of the PEP family of algorithms, but care has to be taken when taking the limiting cases (see supplementary material). These results lend weight to the view that SEP is a natural stochastic generalisation of EP."
    }, {
      "heading" : "4.3 Distributed SEP: controlling granularity of the approximation",
      "text" : "EP uses a fine-grained approximation comprising a single factor for each likelihood. SEP, on the other hand, uses a coarse-grained approximation comprising a signal global factor to approximate the average effect of all likelihood terms. One might worry that SEP’s approximation is too severe if the dataset contains sets of data-points that have very different likelihood contributions (consider classifying handwritten digits into odd and even classes, for example). It might be more sensible in such cases to partition the dataset into K disjoint pieces {Dk = {xn} Nk n=Nk−1 }Kk=1 with N = ∑K\nk=1 Nk and use an approximating factor for each partition. If normal EP updates are used in this situation we arrive at the Distributed EP algorithm [5][6], but such updates are challenging as multiple likelihood terms must be included during each update necessitating additional approximations (e.g. MCMC). A simpler alternative uses SEP (or minibatch generalisations) inside each partition, which implies a posterior approximation of the form q(θ) ∝ p0(θ) ∏K k=1 fk(θ) Nk . The limiting cases of this algorithm, when K = 1 and K = N , recover SEP and EP respectively."
    }, {
      "heading" : "4.4 SEP with latent variables",
      "text" : "Many applications of EP involve latent variable models. Although this is not the main focus of the paper, we show that SEP is applicable in this case and that it prevents the memory footprint from scaling with N .\nConsider a model containing hidden variables, hn, associated with each observation p(xn,hn|θ) that are drawn i.i.d. from a prior p0(hn). The goal is to approximate the true posterior over parameters and hidden variables p(θ, {hn}|D) ∝ p0(θ) ∏\nn p0(hn)p(xn|hn, θ). Typically, EP would approximate the effect of each intractable term using a product of approximate factors, p(xn|hn, θ)p0(hn) ≈ fn(θ)gn(hn). Instead, SEP ties the approximate parameter factors p(xn|hn, θ)p0(hn) ≈ f(θ)gn(hn) yielding:\nq(θ, {hn}) △ ∝ p0(θ)f(θ)\nN N ∏\nn=1\ngn(hn). (2)\nCritically, as proved in supplementary material, the local factors gn(hn) do not need to be maintained in memory since the true posterior factorises over data-points. This means that all of the advantages of SEP carry over to more complex models involving latent variables."
    }, {
      "heading" : "5 Experiments",
      "text" : "The purpose of the experiments was to evaluate SEP on a number of datasets (synthetic and real-world, small and large) and on a number of models (probit regression, Mixture of Gaussians and Bayesian neural\nnetworks)."
    }, {
      "heading" : "5.1 Bayesian probit regression",
      "text" : "The first experiments considered a simple Bayesian classification problem and investigated the stability and quality of SEP in relation to EP and ADF as well as the effect of using mini-batches and varying the granularity of the approximation. The model comprised a probit likelihood function P (yn = 1|θ) = Φ(θTxn) and a Gaussian prior over the hyper-plane parameter p(θ) = N (θ;0, γI).\nThe first experiments used synthetic data comprisedN = 5, 000 datapoints {(xn,yn)}. The inputs xn were D = 4 dimensional and were either sampled from a single Gaussian distribution (Fig. 3(a)) or from a Mixture of Gaussians (MoGs) with J = 5 components (Fig. 3(b)) to investigate the sensitivity of the methods to the homogeneity of the dataset. The labels were produced by sampling from the generative model. Performance was measured by computing an approximation of KL(p(θ|D)||q(θ)) where p(θ|D) was replaced by a Gaussian that had the same mean and covariance as samples drawn from the posterior using the No-U-Turn sampler (NUTS) [24].\nResults in Fig. 3(a) indicate that EP is the best performing method and that ADF collapses towards a delta function at the posterior mean as expected. SEP converges to a solution which appears to be of similar quality to that obtained by EP for the dataset containing Gaussian inputs, but slightly worse when the MoGs was used. Variants of SEP that used larger mini-batches fluctuated less, but typically took longer times to converge (although for the small minibatches shown this effect is not clear). The utility of finer grained approximations depended on the homogeneity of the data. For the second dataset containing MoGs inputs (shown in Fig. 3(b)), finer grained approximations were found to be advantageous if the datapoints from each mixture component are assigned to the same approximating factor. Generally it was found that there is no advantage to retaining more approximating factors than there were clusters in the dataset.\nTo verify whether these conclusions about the granularity of the approximation hold in real datasets, we sampled N = 1, 000 datapoints for each of the digits in MNIST and performed odd-vs-even classification. Each digit class was assigned its own global approximating factor, K = 10. We compare the log-likelihood of a test set using ADF, SEP (K = 1), full EP and DSEP (K = 10) in Figure 3(c). EP and DSEP significantly outperform ADF. DSEP is slightly worse than full EP initially, however it reduces the memory to 0.001% of full EP without losing substantial accuracy. SEP’s accuracy was still increasing at the end of learning and was slightly better than ADF.\nFinally, we tested SEP’s performance on six small binary classification datasets from the UCI machine learning repository.1 We did not consider the effect of mini-batches or the granularity of the approximation, using K = M = 1. The classification results are summarised in Table 5.1. ADF performs reasonably well on the root mean square error (RMSE) metric, presumably because it tends to learn a good approximation to the posterior mode. However, the posterior variance is poorly approximated and therefore ADF returns poor test log-likelihood scores. EP achieves significantly higher test log-likelihood than ADF indicating that a superior approximation to the posterior variance is attained. Crucially, SEP performs very similarly to EP, implying that SEP is an accurate alternative to EP even though it is refining a cheaper global posterior approximation.\n1https://archive.ics.uci.edu/ml/index.html"
    }, {
      "heading" : "5.2 Mixture of Gaussians for clustering",
      "text" : "The small scale experiments on probit regression indicate that SEP performs well for fully-observed probabilistic models. Although it is not the main focus of the paper, we sought to test the flexibility of the method by applying it to a latent variable model, specifically a Mixture of Gaussians. A synthetic MoGs dataset containing N = 200 datapoints was constructed comprising J = 4 Gaussians. The means were sampled from a Gaussian distribution, p(µj) = N (µ;m, I), the cluster identity variables were sampled from a uniform categorical distribution p(hn = j) = 1/4, and each mixture component was isotropic p(xn|hn) = N (xn;µhn , 0.5\n2I). EP, ADF and SEP were performed to approximate the joint posterior over the cluster means {µj} and cluster identity variables {hn} (the other parameters were assumed known).\nFigure 4(a) visualises the approximate posteriors after 200 iterations. All methods return good estimates for the means, but ADF collapses towards a point estimate as expected. SEP, in contrast, captures the uncertainty and returns nearly identical approximations to EP. The accuracy of the methods is quantified in Fig. 4(b) by comparing the approximate posteriors to those obtained from the No-U-Turn sampler. These measures confirm that SEP approximates EP well."
    }, {
      "heading" : "5.3 Probabilistic back-propagation",
      "text" : "The final set of tests consider more complicated models and large datasets. Specifically we evaluate the methods for probabilistic-backpropagation (PBP) [4], a recent state-of-the-art method for scalable Bayesian learning in neural network models. Previous implementations of PBP perform several iterations of ADF over the training data. The moment-matching operations required by ADF are themselves\nintractable and they are approximated by first propagating the uncertainty on the synaptic weights forward through the network in a sequential way, and then computing the gradient of the marginal likelihood by backpropagation. Previous implementations of PBP are based on ADF to reduce the large memory cost that would be required by EP when the amount of available data is very large.\nWe performed several experiments to assess the accuracy of different implementations of PBP based on ADF, SEP and EP on regression datasets following the same experimental protocol as in [4].We considered neural networks with 100 hidden units and followed the same experimental protocol as described by [4]. Table 2 shows the average test RMSE and test log-likelihood for each method. Interestingly, SEP can outperform EP in this setting (possibly because the stochasticity enabled it to find better solutions better optima), and typically it performed similarly. Memory reductions using SEP instead of EP were large e.g. 694Mb for the Protein dataset and 65,107Mb for the Year dataset (see supplementary material for full details). Surprisingly ADF often outperformed EP, although the results presented for ADF use a near-optimal number of sweeps and further iterations generally degraded performance. ADF’s good performance is most likely due to an interaction with additional the moment-approximation that is required in PBP."
    }, {
      "heading" : "6 Conclusions and future work",
      "text" : "This paper has presented the stochastic expectation propagation method for reducing EP’s large memory consumption that is prohibitive for large datasets. We have connected the new algorithm to a number of existing methods including assumed density filtering, variational message passing, variational inference, stochastic variational inference and averaged EP. Experiments on Bayesian logistic regression (both synthetic and real world) and Mixture of Gaussians clustering indicated that the new method had an accuracy that was competitive with EP. Experiments on the probabilistic back-propagation on large real world regression datasets again showed that SEP comparably to EP with a vastly reduced memory footprint. Future experimental work will focus on developing data-partitioning methods to leverage finergrained approximations (DESP) that showed promising experimental performance and also mini-batch updates. Theoretical work will study the convergence properties of the new algorithms for which we only have limited results at present."
    }, {
      "heading" : "A Further theoretical results",
      "text" : "We described the extensions of stochastic expectation propagation (SEP) in the main text, and we provide more details in this section.\nA.1 Power EP and alpha-EP\nThe analysis of EP and variational inference (VI) relationships asks for an introduction of power EP (PEP). As a preparation let us consider the alpha-divergence first introduced in [25]\nDα(p(θ)||q(θ)) = 4\n1− α2\n(\n1−\n∫\nθ\np(θ) 1+α 2 q(θ) 1−α 2 dθ\n)\n. (3)\nThe two cases of KL-divergence also belongs to the family of alpha-divergence by definition:\nD1(p(θ)||q(θ)) △ = lim\nα→1 Dα(p(θ)||q(θ)) = KL[p(θ)||q(θ)], (4)\nD-1(p(θ)||q(θ)) △ = lim\nα→-1 Dα(p(θ)||q(θ)) = KL[q(θ)||p(θ)]. (5)\n[12] introduced alpha-EP as a generalisation of EP to alpha-divergences, which changes the moment matching step to alpha-projection [26] that returns the minimiser of the alpha divergenceDα(p̃n(θ)||q(θ)) wrt. q(θ) in Q. Examples include the previous defined moment projection proj[·] which takes α = 1, and information projection which chooses α = −1. However alpha-projections are difficult to compute in general, which motivates the power EP algorithm, summarised in Algorithm 4, as a practical alternative. [12] showed that power EP with power 1/β, β < ∞ returns a local optimum of the alpha divergence with α = −1 + 2/β when converged. However α = −1 or β = ∞ can be a pathological case if applying PEP since the above equivalence does not apply. In this sense VMP cannot be interpreted as a special case of power EP which takes α → −1. This observation extends to stochastic PEP as well (Algorithm 5). Instead we derive stochastic VMP in the spirit that SEP extends EP, which keeps the computational steps using current global estimate but tie all the local factors. We discuss this extension in detail in the next section and provide its connection to stochastic variational inference.\nA.2 Connecting SVMP to SVI\nWe first briefly sketch the VMP algorithm using EP framework but replacing the moment matching step with natural parameter matching. At time t we have the current estimate of the natural parameter λtq, which is defined as the sum of local variational parameters: λtq △ = λ0 + ∑N n=1 λ t n. Here λ0 represents the natural parameter of the prior distribution p0(θ) 2. VMP iteratively computes the update of each local estimate λt+1n in the following procedure. First VMP computes the expected sufficient statistics ŝn about datapoint xn using λ t q, then forms the gradient as though optimising the maximised evidence lower bound (ELBO) but with q−1(θ) as the prior:\n∇λqL = λ t −1 + ŝn − λq, (6)\nλt−1 = λ t q − λ t n. (7)\nNext VMP zeros the gradient and recovers the current update λt+1n = ŝn. The stochastic version of VMP, if extended in a way as SEP developed from EP, defines the global variational parameters as λtq △ = λ0 +Nλ\nt. It computes the expected sufficient statistics ŝn in the same way as VMP but changes the cavity to λt−1 = λ t q − λ\nt in the ELBO maximisation steps. Readers can verify that this returns the current update λt+1 = ŝn and, since we tie all the local updates, the global parameter update λt+1q = λ0 + Nλ\nt+1 = λ0 + N ŝn. In practice we perform a damped update, where a typical choice of step size is ǫ = 1/N like in SEP:\nλt+1q ← (1− 1\nN )λtq +\n1\nN (λ0 +Nλ\nt+1) = λ0 + (N − 1)λ t + ŝn. (8)\n2This notation implicitly assumes that the prior also belongs to the approximate distribution family Q. In general this does not have to be the case, however we can propose another factor to approximate p0(θ), and our result still applies.\nAlgorithm 4 PEP\n1: choose a factor fn to refine: 2: compute cavity distribution\nq −n(θ) ∝ q(θ)/fn(θ)\n1/β\n3: compute tilted distribution p̃n(θ) ∝ p(xn|θ) 1/βq −n(θ) 4: moment matching: fn(θ)← [proj[p̃n(θ)]/q−n(θ)] β 5: inclusion: q(θ)← q(θ)fn(θ)/f old n (θ)\nAlgorithm 5 Stochastic PEP\n1: choose a datapoint xn ∼ D: 2: compute cavity distribution\nq −1(θ) ∝ q(θ)/f(θ)\n1/β\n3: compute tilted distribution p̃n(θ) ∝ p(xn|θ) 1/βq −1(θ) 4: moment matching: fn(θ)← [proj[p̃n(θ)]/q−1(θ)] β 5: inclusion: q(θ)← q(θ)fn(θ)/f(θ) 6: implicit update:\nf(θ)← f(θ)1− 1 N fn(θ) 1 N\nOn the other hand, [27] summarises the stochastic variational algorithm as to compute the current update by zeroing the gradient\n∇λqL = λ0 +N ŝn − λq, (9)\nwhich returns λt+1q = λ0 + N ŝn as well. This implies that SVI, when using learning rate ǫ = 1/N , is equivalent to SVMP.\nA.3 SEP from a global approximation perspective\nWe relate SEP to a global approximation algorithm though it is computed in a truely local way. This framework utilises alpha divergence but on the global posterior, and we motivate it by describing VI and SVI as divergence minimisation. VI performs global optimisation on KL(q(θ)||p(θ|D)), and its stochastic version, SVI, can be interpreted as computing coordinate descent on KL(q(θ)||p(θ|{xn}\nN )) with the N replicates {xn}N . Similarly, we state SEP as a stochastic global optimisation procedure, which computes an iterative procedure to minimise alpha-divergenceDα(p(θ|{xn}N)||q(θ)) with α = -1+2/N . Indeed we can understand the inner-loop of AEP as PEP with power 1/N if considering f(θ)N as the “big factor” to approximate the likelihood term of xn raised to power N .\nHowever minimising the alpha-divergence between the true posterior p(θ|D) and the global approximation q(θ) recovers PEP on the whole dataset instead, and the factor to include in the tilted distribution changes to the intractable geometric average avg[{p(xn|θ)}] △ = [ ∏ n p(xn|θ)] 1/N . Readers might have noticed that the update of PEP on full dataset is given by q(θ) ← proj[avg[{p̃n(θ)}]]. In other words, we can interpret AEP as an approximation to the impractical batch PEP by interchanging computations, and we illustrate a geometric view for this in Fig. 5(a).\nIt is important to note that SEP/AEP in convergence does not minimise the alpha divergence globally. Like PEP, the inner-loop compute proj[p̃n(θ)], where one can show that it moves towards minimising Dα(p(θ|{xn}N)||qn(θ)) using the same techniques as before. However the outer-loop averages the natural parameters of the intermediate answers, which breaks the optimisation in the inner-loop. Furthermore, local/global optimisation of alpha divergence are inconsistent in terms of fixed point except α = −1, the divergence utilised in VI and VMP. Indeed we provide the fixed points conditions of AEP which shows its local approximation nature.\nTheorem 1. The fixed points of averaged EP, if exist, can be written as q(θ) = avg[{qn(θ)}], where\nqn(θ) = proj[p̃n(θ)]. (10)\nThese fixed points are also the fixed points of stochastic EP in expectation.\nProof. In each update SEP gives the same answers as AEP in expectation if initialised at the same starting point. Also as an analogy to normal EP, the stationary points of AEP ask for moment matching between tilted and intermediate distributions.\nThis fixed point theorem applies to stochastic PEP as well when α 6= −1, and importantly it also implies the pathology of constructing SVMP by limiting α to −1."
    }, {
      "heading" : "B Algorithmic design details",
      "text" : "B.1 Comparing the distributed methods\nWe have shown in the main paper that a proper design of data partitioning improves SEP’s approximation accuracy. This distributed algorithm is inspired by the Distributed EP (DEP) algorithm [5][6] presented in Algorithm 6. DEP first partitions the dataset into K disjoint pieces {Dk = {xi} Nk i=1} with N = ∑K i=1 Nk, which is well-justified since the true posterior can also be derived as\np(θ|D) ∝ p0(θ) K ∏\nk=1\np(Dk|θ), (11)\np(Dk|θ) = ∏\nxn∈Dk\np(xn|θ). (12)\nNext DEP assigns factors to each sub-datasets likelihood, i.e. q(θ) ∝ p0(θ) ∏\nk fk(θ) with each fk(θ) approximating p(Dk|θ). The projection step is no longer analytically tractable, as the tilted distribution with multiple datapoints lacks a simple form in general. Instead DEP computes moment matching by sampling methods, making it stochastic in the sense of moment approximation.\nTo have a deterministic counterpart of DEP, we consider SEP/AEP inside each partition. We name this approach as Distributed SEP/AEP (DSEP/DAEP) and provide a comparison in Fig. 5(b) with DEP and SEP using sampling protocol. Different from DEP, the approximate posterior for DSEP is defined as q(θ) ∝ p0(θ) ∏ k fk(θ) Nk , with fk(θ)\nNk approximating p(Dk|θ). The computations are almost the same as SEP/AEP except that the updates only modifies the copies of the corresponded subset. The two algorithms are also detailed in Algorithm 7 and 8, respectively. Like SEP, this guarantees the correct estimation of uncertainty level as SEP corrects ADF’s overfitting.\nB.2 SEP with latent variables\nIn this section we show the applicability of SEP to latent variables without scaling the memory consumption with N . We consider a model containing latent variables hn associated with each observation xn, which are drawn i.i.d. from a prior p0(hn). SEP proposes approximations to the true posterior over parameters and hidden variables\np(θ, {hn}|D) ∝ p0(θ) ∏\nn\np0(hn)p(xn|hn, θ) (13)\nby tying the factors for the global parameter θ but retaining the local factors for the hidden variables:\nq(θ, {hn}) △ ∝ p0(θ)f(θ)\nN N ∏\nn=1\ngn(hn). (14)\nAlgorithm 6 DEP\nAlgorithm 7 DSEP\nAlgorithm 8 DAEP\nIn other words, SEP uses f(θ)gn(hn) to approximate p(xn|hn, θ)p0(hn). Next we show a critical advantage of SEP on approximating latent variable posterior: the local factors gn(hn) do not need to be maintained in memory since the true posterior factorises over data-points. More formally, the cavity distribution is q−n(θ, {hn}) ∝ q(θ, {hn})/(f(θ)gn(hn)) and the tilted distribution is p̃n(θ, {hn}) ∝ q−n(θ, {hn})p(xn|hn, θ)p0(hn). This leads to the a moment-update that minimises\nKL[p0(θ)f(θ) N−1p(xn|hn, θ)p0(hn)\n∏\nm 6=n\ngm(hm)||p0(θ)f(θ) N−1f ′(θ)gn(hn)\n∏\nm 6=n\ngm(hm)].\nwith respect to f ′(θ)gn(hn). Importantly, the terms involving ∏\nm 6=n gm(hm) are cancelled, meaning that these factors do not need to be retained.\nIt is also possible to have latent variables globally shared or shared in a data piece Dk. But now we can extend SEP to these latent variables accordingly, which still provides computation gains in space complexity. In mathematical forms, assume hk a latent variable shared in Dk. Then we construct q(hk) ∝ p0(hk)gk(hk)Nk to approximate its posterior. This procedure still reduces memory by a factor of N −K."
    }, {
      "heading" : "C Further experimental results",
      "text" : "We also provide the memory consumption details for experiments using probabilistic back-propagation (PBP) in Table 7(a). We observe substantial memory reductions by running SEP instead of EP, while still attaining similar accuracies. Especially for Year, which is a typical large-scale dataset both in the number of observations N and the dimensionality D, SEP achieves tens of gigabytes savings. In fact we ran the test for EP using a machine with more than 100GB RAM, which reveals the incredibly huge memory requirement of full EP.\nAlthough not a main purpuse, we further test the performance of SEP with sampling methods to compute moments 3. We re-use the settings of probit regression but change the probit unit to sigmoid function, making the moment projection analytically intractable. We partition the dataset into K = 20 subsets {Dk}, construct the approximate posterior with local factors over the subsets, and tie them in SEP/AEP as before. Again as presented in Fig. 7(b), SEP performs almost as well as EP, which further justifies SEP even with sampling methods. Also AEP is indistinguishable from DEP, but it reduces memory by a factor of K.\n3code adjusted from ep-stan: https://github.com/gelman/ep-stan"
    } ],
    "references" : [ {
      "title" : "Distributed stochastic gradient mcmc",
      "author" : [ "Sungjin Ahn", "Babak Shahbaba", "Max Welling" ],
      "venue" : "In Proceedings of the 31st International Conference on Machine Learning",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2014
    }, {
      "title" : "Towards scaling up markov chain monte carlo: an adaptive subsampling approach",
      "author" : [ "Rémi Bardenet", "Arnaud Doucet", "Chris Holmes" ],
      "venue" : "In Proceedings of the 31st International Conference on Machine Learning",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2014
    }, {
      "title" : "Stochastic variational inference",
      "author" : [ "Matthew D. Hoffman", "David M. Blei", "Chong Wang", "John William Paisley" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "Probabilistic backpropagation for scalable learning of bayesian neural networks",
      "author" : [ "J.M. Hernández-Lobato", "Ryan P. Adams" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2015
    }, {
      "title" : "Expectation propagation as a way of life",
      "author" : [ "Andrew Gelman", "Aki Vehtari", "Pasi Jylänki", "Christian Robert", "Nicolas Chopin", "John P. Cunningham" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2014
    }, {
      "title" : "Distributed bayesian posterior sampling via moment sharing",
      "author" : [ "Minjie Xu", "Balaji Lakshminarayanan", "Yee Whye Teh", "Jun Zhu", "Bo Zhang" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2014
    }, {
      "title" : "Expectation propagation for approximate Bayesian inference",
      "author" : [ "T.P. Minka" ],
      "venue" : "Uncertainty in Artificial Intelligence, volume 17, pages 362–369",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Expectation consistent approximate inference",
      "author" : [ "Manfred Opper", "Ole Winther" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2005
    }, {
      "title" : "Assessing approximate inference for binary gaussian process classification",
      "author" : [ "Malte Kuss", "Carl Edward Rasmussen" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2005
    }, {
      "title" : "Expectation propagation for likelihood-free inference",
      "author" : [ "Simon Barthelmé", "Nicolas Chopin" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2014
    }, {
      "title" : "Gaussian probabilities and expectation propagation",
      "author" : [ "John P Cunningham", "Philipp Hennig", "Simon Lacoste-Julien" ],
      "venue" : "arXiv preprint arXiv:1111.6832,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2011
    }, {
      "title" : "Power EP",
      "author" : [ "T.P. Minka" ],
      "venue" : "Technical Report MSR-TR-2004-149, Microsoft Research, Cambridge",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Variational message passing",
      "author" : [ "John M Winn", "Christopher M Bishop" ],
      "venue" : "In Journal of Machine Learning Research,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2005
    }, {
      "title" : "An introduction to variational methods for graphical models",
      "author" : [ "Michael I Jordan", "Zoubin Ghahramani", "Tommi S Jaakkola", "Lawrence K Saul" ],
      "venue" : "Machine learning,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1999
    }, {
      "title" : "Variational algorithms for approximate Bayesian inference",
      "author" : [ "Matthew James Beal" ],
      "venue" : "PhD thesis, University of London,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2003
    }, {
      "title" : "Two problems with variational expectation maximisation for time-series models",
      "author" : [ "R.E. Turner", "M. Sahani" ],
      "venue" : "D. Barber, T. Cemgil, and S. Chiappa, editors, Bayesian Time series models, chapter 5, pages 109–130. Cambridge University Press",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Probabilistic amplitude and frequency demodulation",
      "author" : [ "Richard E. Turner", "Maneesh Sahani" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2011
    }, {
      "title" : "TrueskillTM: A bayesian skill rating system",
      "author" : [ "Ralf Herbrich", "Tom Minka", "Thore Graepel" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2006
    }, {
      "title" : "Stochastic models, estimation and control",
      "author" : [ "Peter S. Maybeck" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1982
    }, {
      "title" : "Sparse-posterior gaussian processes for general likelihoods",
      "author" : [ "Yuan Qi", "Ahmed H Abdel-Gawad", "Thomas P Minka" ],
      "venue" : "In Uncertainty and Artificial Intelligence (UAI),",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2010
    }, {
      "title" : "Methods of information geometry, volume 191",
      "author" : [ "Shun-ichi Amari", "Hiroshi Nagaoka" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2000
    }, {
      "title" : "Expectation propagation in the large-data limit",
      "author" : [ "Guillaume Dehaene", "Simon Barthelmé" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2015
    }, {
      "title" : "Divergence measures and message passing",
      "author" : [ "Thomas Minka" ],
      "venue" : "Technical Report MSR-TR-2005-173, Microsoft Research,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2005
    }, {
      "title" : "The no-u-turn sampler: Adaptively setting path lengths in hamiltonian monte carlo",
      "author" : [ "Matthew D Hoffman", "Andrew Gelman" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2014
    }, {
      "title" : "Differential-Geometrical Methods in Statistic",
      "author" : [ "Shun-ichi Amari" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1985
    }, {
      "title" : "Information geometry of α-projection in mean field approximation",
      "author" : [ "Shun-ichi Amari", "Shiro Ikeda", "Hidetoshi Shimokawa" ],
      "venue" : "Advanced Mean Field Methods,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2001
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].",
      "startOffset" : 34,
      "endOffset" : 40
    }, {
      "referenceID" : 1,
      "context" : "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].",
      "startOffset" : 34,
      "endOffset" : 40
    }, {
      "referenceID" : 2,
      "context" : "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].",
      "startOffset" : 115,
      "endOffset" : 118
    }, {
      "referenceID" : 3,
      "context" : "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].",
      "startOffset" : 149,
      "endOffset" : 152
    }, {
      "referenceID" : 4,
      "context" : "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].",
      "startOffset" : 221,
      "endOffset" : 227
    }, {
      "referenceID" : 5,
      "context" : "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].",
      "startOffset" : 221,
      "endOffset" : 227
    }, {
      "referenceID" : 6,
      "context" : "One family of approximation method has garnered less attention in this regard: Expectation propagation (EP) [7][8].",
      "startOffset" : 108,
      "endOffset" : 111
    }, {
      "referenceID" : 7,
      "context" : "One family of approximation method has garnered less attention in this regard: Expectation propagation (EP) [7][8].",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 8,
      "context" : "At first sight, it therefore appears well suited to large-data problems: the locality of computation make the algorithm simple to parallelise and distribute, and good practical performance on a range of small-data applications suggest that it will be accurate [9, 10, 11].",
      "startOffset" : 260,
      "endOffset" : 271
    }, {
      "referenceID" : 9,
      "context" : "At first sight, it therefore appears well suited to large-data problems: the locality of computation make the algorithm simple to parallelise and distribute, and good practical performance on a range of small-data applications suggest that it will be accurate [9, 10, 11].",
      "startOffset" : 260,
      "endOffset" : 271
    }, {
      "referenceID" : 10,
      "context" : "At first sight, it therefore appears well suited to large-data problems: the locality of computation make the algorithm simple to parallelise and distribute, and good practical performance on a range of small-data applications suggest that it will be accurate [9, 10, 11].",
      "startOffset" : 260,
      "endOffset" : 271
    }, {
      "referenceID" : 11,
      "context" : "The same pathology exists for the broader class of power-EP (PEP) algorithms [12] that includes variational message-passing [13].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 12,
      "context" : "The same pathology exists for the broader class of power-EP (PEP) algorithms [12] that includes variational message-passing [13].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 13,
      "context" : "In contrast, variational inference (VI) methods [14, 15] utilise global approximations that are refined directly (rather than through local components) which prevents memory overheads from scaling with N .",
      "startOffset" : 48,
      "endOffset" : 56
    }, {
      "referenceID" : 14,
      "context" : "In contrast, variational inference (VI) methods [14, 15] utilise global approximations that are refined directly (rather than through local components) which prevents memory overheads from scaling with N .",
      "startOffset" : 48,
      "endOffset" : 56
    }, {
      "referenceID" : 15,
      "context" : "It is well known that variational free-energy approaches are biased and often severely so [16] and for particular models the variational free-energy objective is pathologically ill-suited [11, 17].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 10,
      "context" : "It is well known that variational free-energy approaches are biased and often severely so [16] and for particular models the variational free-energy objective is pathologically ill-suited [11, 17].",
      "startOffset" : 188,
      "endOffset" : 196
    }, {
      "referenceID" : 16,
      "context" : "It is well known that variational free-energy approaches are biased and often severely so [16] and for particular models the variational free-energy objective is pathologically ill-suited [11, 17].",
      "startOffset" : 188,
      "endOffset" : 196
    }, {
      "referenceID" : 17,
      "context" : "TrueSkill [18]).",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 18,
      "context" : "A second approach is to use a simple variant of EP called assumed density filtering (ADF) which only requires a global approximation to be stored [19].",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 6,
      "context" : "ADF, however, provides poorly calibrated uncertainty estimates [7] which was one of the main motivating reasons for developing EP in the first place.",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 19,
      "context" : "low rank, [20]).",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 4,
      "context" : "Another idea uses EP to carve up the dataset [5, 6] using approximating factors for collections of data-points.",
      "startOffset" : 45,
      "endOffset" : 51
    }, {
      "referenceID" : 5,
      "context" : "Another idea uses EP to carve up the dataset [5, 6] using approximating factors for collections of data-points.",
      "startOffset" : 45,
      "endOffset" : 51
    }, {
      "referenceID" : 4,
      "context" : "(Indeed, the spirit of [5, 6] is to extend sampling methods to large-datasets, not EP itself.",
      "startOffset" : 23,
      "endOffset" : 29
    }, {
      "referenceID" : 5,
      "context" : "(Indeed, the spirit of [5, 6] is to extend sampling methods to large-datasets, not EP itself.",
      "startOffset" : 23,
      "endOffset" : 29
    }, {
      "referenceID" : 2,
      "context" : "Indeed, the generalisation of the algorithm to the PEP setting directly relates to SVI [3].",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 20,
      "context" : "If the approximating distribution is in the exponential family, as is often the case, then the KL minimisation reduces to a moment-matching step [21] that we denote fn(θ) ← proj[p̃n(θ)]/q−n(θ).",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 21,
      "context" : "For M = N parallel SEP is equivalent to the so-called Averaged EP algorithm proposed in [22] as a theoretical tool to study the convergence properties of normal EP.",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 21,
      "context" : "Since SEP’s approximating factor f(θ) converges, in expectation, to the geometric average of the intermediate factors f̄(θ) ∝ [ ∏N n=1 fn(θ)] 1 N , SEP converges in expectation to the same fixed points as AEP, and therefore under certain conditions [22], to the same fixed points as EP.",
      "startOffset" : 249,
      "endOffset" : 253
    }, {
      "referenceID" : 2,
      "context" : "The relationship between variational inference and stochastic variational inference [3] mirrors the relationship between EP and SEP.",
      "startOffset" : 84,
      "endOffset" : 87
    }, {
      "referenceID" : 22,
      "context" : "Can these relationships be made more formal? If the moment projection step in EP is replaced by a natural parameter matching step then the resulting algorithm is equivalent to the Variational Message Passing (VMP) algorithm [23] (and see supplementary material).",
      "startOffset" : 224,
      "endOffset" : 228
    }, {
      "referenceID" : 12,
      "context" : "Moreover, VMP has the same fixed points as variational inference [13] (since minimising the local variational KL divergences is equivalent to minimising the global variational KL).",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 4,
      "context" : "If normal EP updates are used in this situation we arrive at the Distributed EP algorithm [5][6], but such updates are challenging as multiple likelihood terms must be included during each update necessitating additional approximations (e.",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 5,
      "context" : "If normal EP updates are used in this situation we arrive at the Distributed EP algorithm [5][6], but such updates are challenging as multiple likelihood terms must be included during each update necessitating additional approximations (e.",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 23,
      "context" : "Performance was measured by computing an approximation of KL(p(θ|D)||q(θ)) where p(θ|D) was replaced by a Gaussian that had the same mean and covariance as samples drawn from the posterior using the No-U-Turn sampler (NUTS) [24].",
      "startOffset" : 224,
      "endOffset" : 228
    }, {
      "referenceID" : 3,
      "context" : "Specifically we evaluate the methods for probabilistic-backpropagation (PBP) [4], a recent state-of-the-art method for scalable Bayesian learning in neural network models.",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 3,
      "context" : "We performed several experiments to assess the accuracy of different implementations of PBP based on ADF, SEP and EP on regression datasets following the same experimental protocol as in [4].",
      "startOffset" : 187,
      "endOffset" : 190
    }, {
      "referenceID" : 3,
      "context" : "We considered neural networks with 100 hidden units and followed the same experimental protocol as described by [4].",
      "startOffset" : 112,
      "endOffset" : 115
    } ],
    "year" : 2015,
    "abstractText" : "Expectation propagation (EP) is a deterministic approximation algorithm that is often used to perform approximate Bayesian parameter learning. EP approximates the full intractable posterior distribution through a set of local-approximations that are iteratively refined for each datapoint. EP can offer analytic and computational advantages over other approximations, such as Variational Inference (VI), and is the method of choice for a number of models. The local nature of EP appears to make it an ideal candidate for performing Bayesian learning on large-scale datasets. However, EP has a crucial limitation in this context: the number approximating factors need to increase with the number of data-points, N , which entails a large computational burden. This paper presents an extension to EP, called stochastic expectation propagation (SEP), that maintains a global posterior approximation (like VI) but updates it in a local way (like EP). Experiments on a number of synthetic and real-world data indicate that SEP performs almost as well as full EP, but reduces the memory consumption by a factor of N .",
    "creator" : "LaTeX with hyperref package"
  }
}