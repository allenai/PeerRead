{
  "name" : "1405.3826.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Application of Methods for Syntax Analysis of Context-Free Languages to Query Evaluation of Logic Programs",
    "authors" : [ "Heike Stephan" ],
    "emails" : [ "heike.stephan@informatik.uni-halle.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n40 5.\n38 26\nv1 [\ncs .A\nI] 1\nAn extended abstract/ full version of a paper accepted to be presented at the Doctoral Consortium of the 30th International Conference on Logic Programming (ICLP 2014), July 19-22, Vienna, Austria\nKEYWORDS: Deductive Databases, Earley Deduction, Partial Deduction"
    }, {
      "heading" : "1 Introduction and problem description",
      "text" : "Deductive databases and related rule-based systems are of increasing interest nowadays (ontologies/ semantic web, artificial intelligence, business rules). Especially when large amounts of data have to be processed, an optimal runtime performance is crucial. This can be achieved by compiling the intensional database beforehand, ideally combined with partial evaluation of queries to the deductive database, also known as partial deduction. In this area, lots of work has already been done (see e. g. (Komorowski 1992)). Runtime performance can also be improved by tabling methods, also known as memoing or memoization techniques (e. g. the OLDT method (Tamaki and Sato 1986)), which reuse answers to equivalent subgoals and avoid their recomputation.\nOne approach that has not yet been taken full advantage of in the past is to make use of the structural similarity of sets of horn clauses, which form classic logic programs, and context-free grammars (see (Ullman 1992) for a good description of this connection). Especially for deductive databases the relationship is quite obvious: Intensional predicates correspond to nonterminal symbols and extensional predicates to terminal symbols of a grammar. A query to the database marks a start point corresponding to the start symbol of a grammar. With this, a query to a logic program can be seen as a call to a context-free\nthis task instead of consuming words.\nThe idea is to modify existing, powerful parsing and parser generation algorithms so that they can process logic programs. The rich knowledge of parser generation is thus of great value for the task of compiling queries to logic programs: A parser for a deterministic context-free language can move through a word and decide on its acceptance efficiently because all grammar derivations that are applicable when a new terminal symbol is read are compiled into the parser; a similar performance for a compiled query to a logic program is desirable. The existing query-evaluating or query-compiling methods look only at single or few similar rules; with applying parser-generation methods, all rules derivable using a database fact can be processed at once. For this reason, we can expect to be better than existing query-evaluation/ query-compilation methods if we employ parsing algorithms for query evaluation."
    }, {
      "heading" : "2 Background and overview of the existing literature",
      "text" : "Adapting parsing algorithms to sets of horn clauses has especially been done for definite clause grammars (DCGs)—and so remained in the community of computational linguistics—but the ideas may principally be transferred to logic programs in general. One option is to use algorithms related to the LR(k) algorithm developed by Knuth (Knuth 1965). The LR(k) algorithm is well known and widely used in compiler construction (for a detailed description, see a textbook on compiler construction as e. g. (Aho et al. 2007)). An adaptation to DCGs is presented e. g. byNilsson in (Nilsson 1986). Here, a logic program is first reduced to its underlying context-free grammar for which a LR(k) parser can be generated in traditional manner. The predicate arguments are added during parsing via an argument stack. Algorithms related to the LR(k) algorithm are attractive because, in contrast to pure top-down algorithms, they can be used on left recursive grammars. The main drawback is that the LR(k) algorithm heavily relies on looking ahead one or more characters of the input string in order to guarantee determinism of the generated parser. For the execution of logic programs no input string exists so that the class of programs for which a deterministic execution model can be created is quite small. Of course, one can choose to accept nondeterminism and still profit by being able to cope with left recursion.\nAnother useful parsing algorithm for evaluating a logic program is Earley Deduction by Pereira and Warren (Pereira and Warren 1983). This method is inspired by the Earley Algorithm (Earley 1970), a LR parsing algorithm derived from Knuth’s LR(k) parser generation algorithm and suitable for all context-free grammars. In contrast to the LR(k) algorithm, Earley Deduction is completely independent of looking ahead input characters. This makes Earley Deduction more attractive for the use in query evaluation than methods based on the LR(k) algorithm.\nPorter (Porter III 2009a; Porter III 2009b) tested Earley Deduction in the context of deductive databases and devised several optimizations for the derivation process. He introduced the notion of the schema of a rule which makes rules comparable independent of their actual data values. By this means, rules with the same schema can be collected in one data structure and indexed for easy access. Additionally, he suggested to precompile derivation steps to a set of simple instructions which can be applied to sets of rules.\nthe rules with which the comparison or reduction has to be performed. Nevertheless, Porter found that his optimizations significantly increase execution speed compared to näıve Earley Deduction."
    }, {
      "heading" : "3 Goal of the research",
      "text" : "The goal of research is to construct an automaton that models the evaluation process for a logic program in a similar way as a parser is generated automatically from a given grammar. The Earley-based methods are less restricted than the LR(k) related algorithms for parser generation and will therefore serve as a base for the method to be developed. The following problems have to be solved on the way to this goal:\n1. In contrast to Knuth’s LR(k) algorithm, neither the Earley parsing algorithm\nnor Earley Deduction are parser generation algorithms. There is no description of algorithms that generate parsers that execute the Earley parsing algorithm or Earley Deduction.\n2. In order to have a chance to perform better than existing tabling methods, we have\nto precompile as much of the query evaluation process as possible. This includes especially those derivations that are possible without retrieving new data from the extensional database. In Knuth’s LR(k) algorithm and in the Earley parsing algorithm, but not in Earley Deduction, the parser uses states that correspond to sets of partially processed grammar productions derivable after reading one terminal from the input string; reading a terminal leads to a state transition. This behaviour is also desirable for Earley Deduction.\n3. A parser or parser generator for a DCG—and thus also a query evaluator generator\nfor a logic program—has to cope with the problem of predicate arguments, which are not present in context-free grammars. Not only the status of the evaluation process has to be stored in a state, but also a part of the data from the extensional database. This leads to the unusual concepts of a parameterized state and a parameterized automaton, where the parameters are placeholders for data values retrieved at runtime.\nBy solving these problems, the state-transition feature of the original Earley Algorithm will be combined with the derivation of rules as in Earley Deduction to construct a generator for an automaton modeling the query evaluation process. So classical concepts of parser generation are employed for obtaining efficient means to compile a logic program into executable code, which implements the generated automaton.\nThe states of the automaton correspond to sets of rules derivable after reading one fact from the extensional database; input of an extensional database fact leads to a state transition. The idea is to represent such a rule set in a way that maps those parts of the rules that depend only on the program to constant symbols, leaving the data values as variables or parameters that are bound at runtime. The derivation operations are basically the same for different facts of the same extensional relation and can be computed at compile time. Thus several derivation steps can be processed at once and, additionally, reduced to a sequence of variable assignments and to few comparisons.\ntions as possible to the compilation phase. The execution of a program compiled in this way is expected to be faster than execution with Prolog, the Magic Set method (Bancilhon et al. 1986) or tabling methods, at least in the general case."
    }, {
      "heading" : "4 Preliminary results accomplished",
      "text" : "First results have already been published together with my advisor, Prof. S. Brass in (Stephan and Brass 2012) and (Brass and Stephan 2013). The Earley Deduction method is enhanced by a state transitions and by a generator for a parameterized finite automaton. It can be applied to a non-recursive or left-recursive Datalog program. The execution of the generated automaton performs query evaluation on the given extensional database. The states of this automaton can also be viewed as new Datalog predicates and the state transitions as Datalog rules, so we have a rewritten Datalog program. A bottom-up evaluation of this generated program corresponds to the execution of the parameterized automaton."
    }, {
      "heading" : "5 Current status of the research",
      "text" : "Currently I am preparing for publication a new version of the method that is able to deal with Datalog programs of the kind of the Same-Generations Program. I also have almost finished thoughts on a version of the method that is applicable to general logic programs, including negation as finite failure/stratified negation."
    }, {
      "heading" : "6 Open issues and expected achievements",
      "text" : "There are several ideas on how the versions of the Earley-based compilation methods can be implemented; there will have to be comparisons between those implementations as well as to other established implementations of Datalog and Prolog, especially those using tabling and Magic Sets. The expected improvement of runtime performance must be demonstrated. Furthermore, I am particularly interested in reapplying my compilation method to parser generation and examine how the logic programs that can be processed with the current version are connected to grammars for deterministic context-free languages. If those connections are sufficient, I intend to use the method as parser generator for attributed grammars."
    } ],
    "references" : [ {
      "title" : "Compilers: Principles, Techniques, and Tools, 2",
      "author" : [ "A.V. Aho", "M.S. Lam", "R. Sethi", "J.D. Ullman" ],
      "venue" : "ed. Pearson, Addison Wesley, Boston et al.",
      "citeRegEx" : "Aho et al\\.,? 2007",
      "shortCiteRegEx" : "Aho et al\\.",
      "year" : 2007
    }, {
      "title" : "Magic sets and other strange ways to implement logic programs (extended abstract)",
      "author" : [ "F. Bancilhon", "D. Maier", "Y. Sagiv", "J.D. Ullman" ],
      "venue" : "Proceedings of the Fifth ACM SIGACT-SIGMOD Symposium on Principles of Database Systems. PODS ’86. ACM, New York, NY, USA, 1–15.",
      "citeRegEx" : "Bancilhon et al\\.,? 1986",
      "shortCiteRegEx" : "Bancilhon et al\\.",
      "year" : 1986
    }, {
      "title" : "A variant of earley deduction with partial evaluation",
      "author" : [ "S. Brass", "H. Stephan" ],
      "venue" : "Web Reasoning and Rule Systems. Springer, 35–49.",
      "citeRegEx" : "Brass and Stephan,? 2013",
      "shortCiteRegEx" : "Brass and Stephan",
      "year" : 2013
    }, {
      "title" : "An efficient context-free parsing algorithm",
      "author" : [ "J. Earley" ],
      "venue" : "Communications of the ACM 13, 2 (Feb.), 94–102.",
      "citeRegEx" : "Earley,? 1970",
      "shortCiteRegEx" : "Earley",
      "year" : 1970
    }, {
      "title" : "On the translation of languages from left to right",
      "author" : [ "D.E. Knuth" ],
      "venue" : "Information and Control 8, 6 (Dezember), 607–639.",
      "citeRegEx" : "Knuth,? 1965",
      "shortCiteRegEx" : "Knuth",
      "year" : 1965
    }, {
      "title" : "An introduction to partial deduction",
      "author" : [ "J. Komorowski" ],
      "venue" : "Meta-Programming in Logic, A. Pettorossi, Ed. Lecture Notes in Computer Science, vol. 649. Springer Berlin Heidelberg, 49–69.",
      "citeRegEx" : "Komorowski,? 1992",
      "shortCiteRegEx" : "Komorowski",
      "year" : 1992
    }, {
      "title" : "AID: An alternative implementation of DCGs",
      "author" : [ "U. Nilsson" ],
      "venue" : "New Generation Computing 4, 383–399.",
      "citeRegEx" : "Nilsson,? 1986",
      "shortCiteRegEx" : "Nilsson",
      "year" : 1986
    }, {
      "title" : "Parsing as deduction",
      "author" : [ "F.C.N. Pereira", "D.H.D. Warren" ],
      "venue" : "Proceedings of the 21st annual meeting on Association for Computational Linguistics. ACL ’83. Association for Computational Linguistics, Stroudsburg, PA, USA, 137–144.",
      "citeRegEx" : "Pereira and Warren,? 1983",
      "shortCiteRegEx" : "Pereira and Warren",
      "year" : 1983
    }, {
      "title" : "1985/2009b. Optimizations to earley deduction for datalog programs",
      "author" : [ "III H.H. Porter" ],
      "venue" : "www.cs.pdx.edu/~harry/earley/datalog.pdf",
      "citeRegEx" : "Porter,? \\Q2012\\E",
      "shortCiteRegEx" : "Porter",
      "year" : 2012
    }, {
      "title" : "A variant of earley deduction with partial evaluation",
      "author" : [ "H. Stephan", "S. Brass" ],
      "venue" : "Proceedings of the 26th Workshop on Logic Programming. 21–31.",
      "citeRegEx" : "Stephan and Brass,? 2012",
      "shortCiteRegEx" : "Stephan and Brass",
      "year" : 2012
    }, {
      "title" : "Old resolution with tabulation",
      "author" : [ "H. Tamaki", "T. Sato" ],
      "venue" : "Third International Conference on Logic Programming, E. Shapiro, Ed. Lecture Notes in Computer Science, vol. 225. Springer Berlin Heidelberg, 84–98.",
      "citeRegEx" : "Tamaki and Sato,? 1986",
      "shortCiteRegEx" : "Tamaki and Sato",
      "year" : 1986
    }, {
      "title" : "The interface between language theory and database theory",
      "author" : [ "J.D. Ullman" ],
      "venue" : "Theoretical studies in computer science, J. D. Ullman, Ed. Academic Press Professional, Inc., San Diego, CA, USA, 133–151.",
      "citeRegEx" : "Ullman,? 1992",
      "shortCiteRegEx" : "Ullman",
      "year" : 1992
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "(Komorowski 1992)).",
      "startOffset" : 0,
      "endOffset" : 17
    }, {
      "referenceID" : 10,
      "context" : "the OLDT method (Tamaki and Sato 1986)), which reuse answers to equivalent subgoals and avoid their recomputation.",
      "startOffset" : 16,
      "endOffset" : 38
    }, {
      "referenceID" : 11,
      "context" : "One approach that has not yet been taken full advantage of in the past is to make use of the structural similarity of sets of horn clauses, which form classic logic programs, and context-free grammars (see (Ullman 1992) for a good description of this connection).",
      "startOffset" : 206,
      "endOffset" : 219
    }, {
      "referenceID" : 4,
      "context" : "One option is to use algorithms related to the LR(k) algorithm developed by Knuth (Knuth 1965).",
      "startOffset" : 82,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "(Aho et al. 2007)).",
      "startOffset" : 0,
      "endOffset" : 17
    }, {
      "referenceID" : 6,
      "context" : "byNilsson in (Nilsson 1986).",
      "startOffset" : 13,
      "endOffset" : 27
    }, {
      "referenceID" : 7,
      "context" : "Another useful parsing algorithm for evaluating a logic program is Earley Deduction by Pereira and Warren (Pereira and Warren 1983).",
      "startOffset" : 106,
      "endOffset" : 131
    }, {
      "referenceID" : 3,
      "context" : "This method is inspired by the Earley Algorithm (Earley 1970), a LR parsing algorithm derived from Knuth’s LR(k) parser generation algorithm and suitable for all context-free grammars.",
      "startOffset" : 48,
      "endOffset" : 61
    }, {
      "referenceID" : 1,
      "context" : "The execution of a program compiled in this way is expected to be faster than execution with Prolog, the Magic Set method (Bancilhon et al. 1986) or tabling methods, at least in the general case.",
      "startOffset" : 122,
      "endOffset" : 145
    }, {
      "referenceID" : 9,
      "context" : "Brass in (Stephan and Brass 2012) and (Brass and Stephan 2013).",
      "startOffset" : 9,
      "endOffset" : 33
    }, {
      "referenceID" : 2,
      "context" : "Brass in (Stephan and Brass 2012) and (Brass and Stephan 2013).",
      "startOffset" : 38,
      "endOffset" : 62
    } ],
    "year" : 2014,
    "abstractText" : "My research goal is to employ a parser generation algorithm based on the Earley parsing algorithm to the evaluation and compilation of queries to logic programs, especially to deductive databases. By means of partial deduction, from a query to a logic program a parameterized automaton is to be generated that models the evaluation of this query. This automaton can be compiled to executable code; thus we expect a speedup in runtime of query evaluation. An extended abstract/ full version of a paper accepted to be presented at the Doctoral Consortium of the 30th International Conference on Logic Programming (ICLP 2014), July 19-22, Vienna, Austria",
    "creator" : "LaTeX with hyperref package"
  }
}