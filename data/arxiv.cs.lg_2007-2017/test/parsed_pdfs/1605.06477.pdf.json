{
  "name" : "1605.06477.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "first.last@aalto.fi" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 5.\n06 47\n7v 1\n[ cs\n.L G\n] 2\n0 M\nay 2\nWe consider regression under the “extremely small n large p” condition. In particular, we focus on problems with so small sample sizes n compared to the dimensionality p, even n → 1, that predictors cannot be estimated without prior knowledge. Furthermore, we assume all prior knowledge that can be automatically extracted from databases has already been taken into account. This setup occurs in personalized medicine, for instance, when predicting treatment outcomes for an individual patient based on noisy high-dimensional genomics data. A remaining source of information is expert knowledge which has received relatively little attention in recent years. We formulate the inference problem of asking expert feedback on features on a budget, present experimental results for two setups: “small n” and “n=1 with similar data available”, and derive conditions under which the elicitation strategy is optimal. Experiments on simulated experts, both on simulated and genomics data, demonstrate that the proposed strategy can drastically improve prediction accuracy."
    }, {
      "heading" : "1 Introduction",
      "text" : "In the “small n large p” regression setting, the task is to make predictions based on few noisy samples of high-dimensional data. It is impossible to address this problem without relying on prior knowledge. Typically, prior knowledge is represented by known structures in data, such as groupings of variables in pathways, or sparsity. Still, for the extreme case of n → 1, none of them is sufficient, and not even their combination. In this case, a potential source of additional useful knowledge comes from human expertise, which is usually expensive to extract. In this paper we address the problem of how to efficiently elicit expert knowledge, under a restricted feedback budget, making the simplifying assumption that the user is able to provide exact information to queries."
    }, {
      "heading" : "1.1 Dealing with small n large p",
      "text" : "“Small n large p” data (also known as “fat data”) is characterised by a large number of predictors (p) that need to be estimated from few data (small sample size n). This situation is typical in medical data, where observations (such as drug responses) are very scarce, a very large number of potentially relevant covariates is available, from genomics measurements for instance, and additional data can only be obtained at a high cost.\nTo tackle this problem, and to efficiently constrain the selection of relevant features, machine learning algorithms typically rely on known structures in the data (for instance, networks, pathways, the linear structure of DNA). This type of prior knowledge can be taken into account with regularisation techniques (see, e.g., [10, 17]) or priors in Bayesian inference. Another efficient way to address the lack of data is to transfer knowledge across related tasks (see [15] for a survey)."
    }, {
      "heading" : "1.2 Expert Knowledge Elicitation",
      "text" : "Human judgement, and in particular expert knowledge, is often of crucial importance in decision making processes. Expert knowledge elicitation techniques have been widely studied in a wide range of application settings, from preference model elicitation [1, 4] to medical science and shipping industry [6, 20], as well as interactive learning for student modelling [5, 12].\nThe methodological choices needed in defining the expert feedback differ from application to application and depend on multiple conditions, such as (i) the available expert knowledge (e.g., What can one ask from the expert? How much should the expert be trusted?); (ii) the type of information to be obtained (e.g., learning a preference, estimating a quantity, answering a question, identifying risky options); (iii) knowledge extraction constraints (e.g., time/cost needed to get the answer, how many interactions/how much feedback can the expert provide).\nEliciting coefficients for linear regression methods has been shown to be efficient in previous related studies. An important line of work [9, 11] studies methods of quantifying subjective opinion about the coefficients of linear regression models. The prior knowledge is elicited through tasks that use hypothetical data and the assessment of credible intervals. These elicitation methods are shown to obtain prior distributions that represent well the expert’s opinion, but the use of expert knowledge is not explored further. In our approach, we elicit expert’s opinion more directly and this also allows to focus on more specific cost functions (such as reducing the prediction error for a specific target).\nIn Bayesian inference the prior distributions of the parameters are a natural way of expressing prior knowledge. In the studies on prior elicitation [13], some also on regression [14], the focus has often been on how to elicit reliable prior knowledge, after which the Bayesian inference machinery takes care of the rest. We ask the complementary question, of how efficiently can the knowledge elicitation be done, first given the simplifying assumption that the expert feedback is reliable. The order of inference is also reversed: we initialize from data and then improve with knowledge elicitation, whereas in prior elicitation the normal order would be the opposite. In the next stages of development, it will be important to combine both approaches, and then the Bayesian formulations will be natural."
    }, {
      "heading" : "1.3 Contributions and Outline",
      "text" : "In this work we propose to solve the “extremely small n, large p” problem for regression under the assumption that accurate expert knowledge is available but under a budget. As far as we know, this is the first study handling knowledge elicitation from this angle, aiming at sample sizes of n → 1. This setup is important in particular for personalized medicine but not restricted to it.\nThe remainder of the paper is organised as follows: In Section 2 we provide a detailed description of the expert knowledge elicitation scenario in which we address the lack of data problem in a regression task. We also state our assumptions about the use of the expert feedback. We then propose an effective algorithm for selecting on which features to ask expert feedback to reduce the loss the most, in Section 3. We analyse its optimality. In Section 4 we present simulations of the behaviour of our expert knowledge elicitation strategy in a simple synthetic\nsetting. Then, by simulating a knowledgeable user, we show the potential prediction improvement when using a genomics dataset, relevant for the personalized medicine settings. To demonstrate the more general use of the algorithm that we propose, we also study its behaviour for model extensions including: a restriction of the features on which the expert can provide feedback (Section 5.1) and by including noisy expert feedback (Section 5.2). Finally, we conclude and provide future work directions in Section 6."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "In this section we present the problem setup and introduce the first formulation for expert knowledge elicitation in a prediction task. In particular, we explicate our assumptions about the type of feedback that the expert can give. The framework was chosen to be as simple as possible while still capturing the essential elements of large p, small n data. For concreteness, we will describe the problem with terminology of treatment effectiveness prediction, but the setup is naturally more generally applicable."
    }, {
      "heading" : "2.1 Problem Description",
      "text" : "The goal is to improve prediction of the effect of a treatment on a target patient, by including feedback provided by an expert. Assume a small set of observation data, which can be used to learn an initial predictor. The set consists of n observed treatment responses y1, . . . , yn, stored in the vector Y ∈ R1×n, coming from n different patients i (i = 1, . . . , n) who had previously received the same treatment. Denote the matrix of genomic features with X , where the size of X is n × p, and on each row i = 1, . . . , n we have the p genomic features corresponding to patient i, denoted by xi. We focus on setups with p ≫ n. For the new “target” patient the same genomic measurements are available, denoted x∗ = [x∗(1) . . . x∗(p)], and the goal is to predict as accurately as possible the treatment response, denoted y∗."
    }, {
      "heading" : "2.2 Data Assumptions",
      "text" : "Linear Regression. We assume there is a linear relation between the genomic features of the patient and the expected result of the treatment. More precisely, we choose a linear regression setting, where for each patient i,\nyi = xiθ ⊤ + η, (1)\nwhere θ ∈ Rp is an unknown parameter underlying the linear function and η is i.i.d white noise, quantifying the inherent noise in the measurements of the drug effects for each patient. The coordinate θ(i) of the parameter vector encodes the weight or relevance that feature i has in computing the treatment response of a patient.\nSparsity. We assume that the weight vectors θ are s-sparse (s << p), or in other words that many of the features have zero weight or relevance in the drug response prediction. Note that sparsity is not necessary for expert knowledge elicitation, but is a widely used regularity assumption which enables handling even larger p. Sparsity assumption matches many problems having a small number of responsible mechanisms (for instance, mutations in the genetic cases).\n“Small n” and “n = 1” scenarios. An important data assumption is whether the true weight of a feature is the same for all patients (that is, do all observations (x1, y1), . . . , (xn, yn) come from the same distribution), or whether the target patient may be from a different distribution. We call the former the “small n scenario” and the latter the “n = 1 scenario”.\nA particularly useful variant of the n = 1 scenario is the “multiple n = 1 tasks scenario”, where each patient has his/her own (unknown) weight vector; for i 6= j, θi 6= θj , and\nyi = xiθ ⊤ i + η and yj = xjθ ⊤ j + η ′ , (2)\nwhere η and η′ come from N (0, 1). If we are willing to assume that all considered patients share the same sparse support of active genomic features (that is, features affecting the drug response) and that their corresponding weights are similar from patient to patient, then we can estimate an initial estimate for the weights θ∗ of the target patient from the other patients’ data.\nWe next explicate our assumptions about the information that can be extracted from an expert in the linear regression scenario."
    }, {
      "heading" : "2.3 Expert Feedback",
      "text" : "For clinical and behavioural variables, an expert may know how much they explain of the risk1. For linear regression, the fraction of variance explained is the square of the correlation coefficient (under simplifying assumptions). When the expert is more uncertain, he/she can give feedback on the importance of variables. For instance, some cancer genes and pathways are known, and given the patient’s treatment response history, it is possible to make educated guesses of which hypotheses of disease mechanisms remain as potential hypotheses. In these cases our formulation is an approximation for bringing in expert’s patient-specific prior knowledge.\nExpert knowledge. We assume that the expert is able to report the correct value of θ∗(i) when asked, but that answering requires a cost and hence we cannot simply ask correct values for the full θ∗. This kind of feedback is very informative and, as far as we know, has not been used in estimating parameters before. This assumption is very simplifying in the personalized medicine case, and requires that the expert either has important additional knowledge of the particular patient, or is able to use his/her expertise to infer the correct value from the shown data x∗ and the initial weight vector estimated based on the other patients. We later relax this assumption and provide an empirical study of the sensitivity to expert errors (Section 5.2) and to expert knowledge restricted to a subset of features (Section 5.1).\nFeedback use. In the simple formulation assuming accurate experts, the best way of taking into account the expert feedback on a feature i is to directly replace the feature weight of the estimated target parameter θ̂init (obtained from the data of other patients) with the targetspecific weight provided by the expert. Basically, if the expert gives feedback on θ∗(i), then we\nupdate the initial “small n” estimate (denoted θ̂init) by replacing its i-th coordinate with the feedback provided by the expert.\nFeedback cost. We assume this type of expert knowledge to be very expensive and we hence place a strict restriction on the number of features on which the expert can provide feedback. Denote by m the number of features for which the expert can give target-specific information (that is, the corresponding weight to be considered in estimating the drug response of the target patient). We refer to m as the feedback budget and we restrict it to a value much lower than\n1For instance, even wikipedia gives an estimate that obesity appears to be the cause of 20% of heart attacks.\nthe dimensionality of the data: m << p. Therefore, assuming the user does have the answer, the research problem we address here is that of identifying the m most informative features on which to elicit expert knowledge.\nAs our goal is to predict the drug response for patient x∗, it follows that the most informative feedback the expert can provide is what leads to minimizing the prediction error. We formalize this in the performance measure defined below."
    }, {
      "heading" : "2.4 Performance Measure",
      "text" : "Let θ̂A denote the estimate of θ ∗ produced by an algorithm A. We define the loss of A as the expected quadratic loss for the target patient x∗:\nLA = E[(x ∗θ̂⊤A − y ∗)2] = E[(x∗θ̂⊤A − x ∗θ∗⊤)2], (3)\nwhere the expectation is taken over all sources of noise, coming from the noisy drug effect observations and noisy selection of the features by the expert. Given the m interactions with the expert user, our goal is to get feedback about the most informative or relevant features, such that we minimize the target loss. The optimal algorithm A∗ is thus defined as: LA∗ = minA|θ̂init LA. It is important to highlight that the overall performance of an algorithm strictly depends on the estimate obtained from the training data on other patients θ̂init. In this work the focus is on finding expert knowledge elicitation strategies that enable maximally improving the target prediction, from the initially very imperfect estimate obtained from scarce data, possibly coming from different distributions."
    }, {
      "heading" : "3 Algorithm",
      "text" : "We propose to learn the regression parameters in two stages. First, an initial estimate θ̂init is learnt on the “small n large p” training data with appropriate regularization, efficiently capturing the information in that data set. The estimate is then improved by knowledge elicitation from an expert. The estimation error obtained with the initial estimate θ̂init is the baseline for comparing the potential improvement obtained by eliciting expert knowledge."
    }, {
      "heading" : "3.1 Description",
      "text" : "Given the assumed type of feedback (described in Section 2.3) and the budget constraint, the goal is to rapidly identify the features most useful in reducing the loss. After a closer look to the loss definition, we easily get the following intuitions on the behaviour of the algorithm:\n• Trivially, the algorithm should not ask feedback more than once on the same feature i, since the expert feedback is accurate and we get directly the right value for θ∗(i).\n• By decomposing the loss as a sum of p squared point-wise products, we can tell that it is most useful to reduce to 0 (through the expert feedback) the m largest feature products\nx∗(i) · ( θ∗ − θ̂init ) (i), which would correspond to getting feedback on the worst estimated\nfeatures in θ̂init.\nOf course, the true vector θ∗ is not available and the best proxy we can have for it is given by θ̂init. Therefore, we propose to use the available information on x\n∗ and the estimate of the weight vector, and we ask for expert feedback on the m largest features, as given by the point-wise product of x∗ and the θ̂init.\nFor each feature j = 1, . . . ,m, we replace the coordinate θ̂init(j) by the corresponding expert feedback. The rest of the p−m features remain the same. The algorithm outputs the vector thus obtained. We denote the result by θ̂final and the loss will be given by L = E[(x ∗ θ̂⊤ final\n− x∗θ∗⊤)2]. The pseudo code of the algorithm is presented in Algorithm 1.\nAlgorithm 1\nInput: {X ,Y} – n training data samples in Rp\nx∗ – feature vector representing the target m – expert elicitation feedback budget\nInitialization phase Output: θ̂init – estimated weight vector from data Expert elicitation phase Rank point-wise products of features for t = 1, . . . ,m do Elicit feedback on each of the t-th largest product feature Get the corresponding θ∗ coordinate: r = θ∗(i)\nReplace feature in the initial estimate: θ̂(i) = r end for Output θ̂final Goal: minimize L = (x∗⊤(θ̂final − θ∗))2."
    }, {
      "heading" : "3.2 Analysis",
      "text" : "We will next give conditions under which the elicitation sequence of Algorithm 1 is optimal. Denote ∆i = x\n∗(i)θ(i) − x∗(i)θ∗(i), and index the feature with the largest product of feature value and regression weight with c. The theorem below says essentially that assuming changes in regression parameters from learning set to the target patient are on average monotonically increasing as a function of the parameter size, choosing the largest product c decreases cost function more than any other choice on the average. An additional requirement is that if there are correlations between parameters, they cannot be stronger for others compared to c. The averages are over variation in the learning data set.\nTheorem 1. Denote c = argmaxk x ∗(k)θ(k) and assume E[∆2c ] ≥ E[∆ 2\ni ] and E[∆c∆k] ≥ E[∆i∆k] for all i 6= k 6= c. Then it holds that\nLθc∗ ≤ Lθi∗,\nwhere Lθ = E[(x ∗θ⊤ − y∗)2] and θi∗ = [θ(1), . . . , θ(i − 1), θ∗(i), θ(i+ 1), . . . , θ(p)]⊤.\nProof. Since Lθ = E[( ∑ k ∆k) 2],\nLθi∗ = E[( ∑\nk 6=i\n∆k) 2]\n= Lθ − 2E[∆i ∑\nk\n∆k] + E[∆ 2 i ].\nHence,\nLθc∗ − Lθi∗ = E[∆ 2 c ]− E[∆ 2 i ]− 2E[(∆c −∆i) ∑\nk\n∆k].\nThe expression within the last expectation is\n(∆c −∆i) ∑\nk\n∆k = (∆c −∆i)(∆c +∆i + ∑\nk 6=c,i\n∆k)\n= ∆2c −∆ 2 i + (∆c −∆i) ∑\nk 6=c,i\n∆k,\nand therefore\nLθc∗ − Lθi∗ = E[∆ 2 i ]− E[∆ 2 c ]− 2 ∑\nk 6=c,i\n(E[∆c∆k]− E[∆i∆k]) ≤ 0\nby the two assumptions.\nOptimality in a simple setting. We next illustrate the theorem in the simple setting where the target patient comes from the same distribution as the other patients. Then under reasonable regularity assumptions E[θ] = θ∗, and\nE[∆2i ] = x 2(i)E[θ2(i)]− 2x2(i)E[θ(i)]θ∗(i) + x2(i)θ∗2(i)\n= x2(i)(E[θ2(i)]− θ∗2(i))\n= V ar[x(i)θ(i)].\nSkipping analogous details,\nE[∆i∆k] = x(i)x(k)(E[θ(i)θ(k)] − θ ∗(i)θ∗(k)).\nHence the assumptions translate in this case to the intuitive requirements that variance in the largest features is the largest, and features are either not cross-correlated, or if they are, crosscorrelations with the largest feature are the strongest (on average)."
    }, {
      "heading" : "4 Experiments",
      "text" : "We illustrate the performance of Algorithm 1, to which we refer in the sequel by Largest Product Feature, in two experimental setups. We start with a simple synthetic setting (described in Section 4.1), then we use a genomics dataset for a more elaborate simulation (as described in Section 4.2). In both settings we compare the loss of Algorithm 1 to that of the following strategies:\n• No interaction: the baseline algorithm whose performance is given by the prediction error of θ̂init\n• Random: works by selecting at random (without repeat) m features of which to ask expert feedback\n• Largest Target Feature: asks feedback on the m largest coordinates of the target vector x∗.\nWhile No interaction and Random are typical baselines, Largest Target Feature is a naive approach of minimising the target loss, based solely on the absolute feature values of the target vector."
    }, {
      "heading" : "4.1 Synthetic Data",
      "text" : "Setting. We randomly generated the training set X having k = 1000 rows and 150 features from a normal distribution with mean 0 and variance 1. We also randomly sampled a sparse weight vector θ, such that 5 of its features are non-zero and come from a normal distribution with mean 0 and variance 1, while the remaining 145 features are 0. The output variable Y is then computed using n noisy observations of the dot product between θ and randomly selected vectors x ∈ X . We use the glmnet package [7] for estimating θ̂init, and we vary the number of training samples from 5 to 30, while the number of expert feedbacks that we assume we can obtain grows from 0 to 10. We randomly choose a target patient and compute the corresponding loss for each feedback value. We plot the average target loss over 100 randomly selected target patients.\nResults. Figure 1(a) shows the prediction performance in terms of a loss for a target sample in the “small n” scenario, with four different strategies. As expected, given that the expert is assumed to be able to give exact feedback, all strategies that use expert feedback show improvement in performance as the number of expert feedback grows and have better performance than the baseline (No Interaction) from the very first expert feedback. It can also be noticed that the initial estimate of the weight vector resulting using Largest Product Feature, after the first feedback is already better then the other strategies. Then, with increasing amount of feedbacks received, our algorithm shows increased improvement in performance as compared to other strategies.\nIn the “n = 1” scenario, with different regression parameter vectors for each patient, the improvement is slightly slower (because of the introduced bias in the initial estimate θ̂init) but still clearly better than with the other strategies (Figure 1(b)). It is important to mention that the θs (θ1, . . . , θk, one corresponding to each patient in X) were randomly generated, but to control the introduced bias we keep the same sparsity assumption for all weight vectors (the same 5 nonzero features) and we restrict the L2 norm of the difference between any pair of weight vectors θi 6= θj to be smaller than 0.5.\nFor both scenarios, here we only report the loss when the number of training samples used for computing θinit is 10, but in Appendix A we report more complete results."
    }, {
      "heading" : "4.2 GDSC Dataset",
      "text" : "We demonstrate the usefulness of our approach by also testing it on the genomics data in the GDSC dataset. Here we obtained results similar to the results seen from the synthetic data. In the following we briefly describe the contents of the dataset, then we explain how we simulated the ground truth. The plotted results (Figure 2) follow the same trends as in the synthetic data, again showing an improvement of all the strategies that use interaction, for all values of n.\nGenomics of Drug Sensitivity in Cancer (GDSC) data. We used the data from the Genomics of Drug Sensitivity in Cancer project by Wellcome Trust Sanger Institute (version release 5.0, June 2014, http://www.cancerrxgene.org) [19, 8] consisting of 124 drugs and a panel of 124 human cancer cell lines for which complete drug response measurements are available. Drug responses are summarised by log-transformed IC50 values (the drug concentration yielding 50% response, given as natural log of µM) from the dose response data measured at 9 different concentrations. The cancer cell lines, representative of human cancer cell models, are characterised by expression values quantifying the transcript levels of thousands of genes. For this study, we chose a subset of biologically relevant genes, whose mutational status has been\nshown to correlate with the drug responses [18]. For our study, we transformed the transcript counts of the genes to the log 2 scale.\nLearning a Pseudo-Ground Truth. When simulating expert feedback, on this data we used estimates computed from the full data as the correct answers the expert gives, when queried based on estimates from small n. To learn this “pseudo-ground truth,” we employed sparse linear regression using the glmnet package, which has been frequently used to identify genomic features of drug responses [2, 8]. The sparse linear regression formulation has two parameters that are to be optimized: α (elastic net mixing parameter) and λ (the penalty parameter). We fixed α = 1 assuming only few of the genomic features to be important for predictions. We inferred λ as follows: For each drug, we held out one cell line and performed a 10-fold cross validation procedure on the training data with 100 different λ values. The training data comprised of the gene expression values of all cell lines and their responses on this drug, except for the held-out cell line. We chose λmin that gave minimum error averaged over the 10 cross-validated folds. The estimates of θ were obtained by setting λ = λmin. We repeated this procedure for all drugs, thus the learnt θs are used as a pseudo-ground truth for our experiments.\nResults. For the plots on the GDSC dataset, for each amount of feedback and for each algorithm, the curve represents the average loss over 100 random iterations. The bars are showing the standard error of the mean. In each iteration, we randomly pick a set of 10 target patients and 10 drugs and we compute their corresponding losses. For each of the target patients we predicted the drug responses eliciting the expert knowledge of the user following the strategies presented in the beginning of Section 4. We also show the effect of varying the number of initial training samples, from 5 to 30.\nWhile the trends and the ordering of the performance of the algorithms do not change, we can notice that, as expected, the overall loss of the algorithms diminishes as n grows. In addition, when using the GDSC dataset the loss does not decrease to zero as fast as for the synthetic data."
    }, {
      "heading" : "5 Model Extensions",
      "text" : "To get more evidence about the behaviour of the algorithm, we proceed by relaxing the model in two central aspects. These relaxations also make the model applicable in a considerably wider set of practical scenarios. For the numerical simulations, unless specified otherwise, the setting remains the same as described in Section 4.1, for the “n=1” scenario."
    }, {
      "heading" : "5.1 Feedback on a subset of features",
      "text" : "We analysed the prediction performance of our approach when the expert can provide feedback only on a subset of features. To simulate that, we associate to each feature a value of either 1, meaning that the expert has knowledge on that feature (and can provide feedback), or 0, for the features on which the expert has no prior knowledge. The algorithm Largest Product (Subset) Feature selects the features on which to ask feedback as before, but if the selected feature is unknown by the expert (that is, its associated value is 0), then feedback is asked on the next “largest product feature” with an associated value 1. Basically, instead of receiving feedback on the m largest features, we now receive expert feedback on the m “largest product features” with associated value 1.\nThe analysis in Section 3.2 also holds for this more general setting, under the same assumptions. In fact, we again proceed by asking expert feedback on the features that allow to decrease the cost function more than any other choice (on average), since the features on which the expert has no knowledge would have no impact on the loss (if selected). Thus the algorithm preserves optimality, since by using the feedback budget on the m “largest product feature” with an associated value 1, we obtain the largest expected loss reduction.\nFigure 3 shows how the performance behaves when the percentage of features with associated value 1 is reduced from 90% to 50%.2 Each subplot corresponds to a different proportion of features (selected randomly) on which the expert has prior knowledge and can provide feedback. For instance “Feature Subset=90%” means that expert feedback is available on 90% of the features in the curve Largest Product (Subset) Feature.\nBased on the results, even in the more realistic cases in which the expert knowledge is restricted to a subset of the features, the results obtained by Largest Product (Subset) Feature are significantly better than the baseline No Interaction. Note that the other strategies remain unchanged, with no constraint on the features on which expert feedback can be received, and yet Largest Product (Subset) Feature outperforms them even with half of the total number of features."
    }, {
      "heading" : "5.2 Noisy Expert",
      "text" : "We simulated an experiment for the “n=1” scenario where each feedback is affected by normally distributed noise, centered and with variance between 0.1 and 0.5, encoding the expert uncertainty (the range of the (true) feature values is [0, 1]). The noisy feedback is used for all strategies. In the personalized medicine application, it is plausible to assume that the expert feedback has smaller variance in the weight of genomic features commonly known to be relevant, but much higher variance for rarely encountered genes and their mutations.\nIn Figure 4 we can see that Largest Product Feature is still better than the baseline No Interaction in the presence of noisy feedback. Though as the noise increases the difference between the prediction performance of our algorithm and the baseline decreases. This is expected,\n2Note that the plot for “Feature Subset=100%” would be precisely the Figure 1(b) (with overlapping green and magenta curves).\nsince as the expert provides noisier feedback on a feature i, θ̂(i)final might deviate even more from the true value of feature i than the θ̂(i)init. Regarding the other strategies, we can see that when the expert feedback has a variance greater than 0.3, the baseline has a better performance than Random, which asks feedback on features chosen at random (without repeat). For Largest Target Feature the difference with the baseline is even more significant. We can notice a decrease in performance with every additional feedback, for a noise variance of more than 0.3. This happens because when computing the loss, for the parameter features whose value is changed (from θ̂init(i) to θ̂final(i)), the introduced noise is then multiplied with one of the m largest features of the target patient x(i). For this strategy, the noisy feedbacks propagate the most and decrease the performance, leading to results worse than Random.\nAlthough a natural extension, strategies require much larger feedback budgets to obtain effective expert knowledge elicitation when the feedback is very noisy. In fact, the effect of a noisy feedback naturally reduces if one asks feedback multiple times on the same feature. But this would also imply a change in the assumptions about the structure in the data or about the number of experts that can be consulted. The design of an optimal strategy becomes more intricate in this scenario since it involves choosing the right balance between (a) obtaining noisy information about more coefficients, or (b) focusing on a smaller number of coefficients for which feedback is asked multiple times. This trade-off might also vary depending on the target, since its features will then propagate the uncertainty of the coefficients into the loss."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We have introduced a novel setup that brings together expert elicitation and the difficult “small n, large p” regression problem. Starting from noisy estimates based on extremely small\nsample sizes, we empirically demonstrated the prediction improvement that can be obtained by bringing in only a few expert feedbacks. More precisely, we considered a simplified problem formulation, where there is a strict budget constraint on exact expert feedback. The simplified problem setting is intended to be a starting point that opens up both new interesting theoretical questions and a line of applied work towards new solutions in the currently very timely problem of personalized medicine. Underlying the practically important goal of developing better predictions of treatment outcome for an individual patient, is the task of estimating predictors for the sample with n = 1, which requires creative solutions. New approaches of querying and incorporating available expert knowledge are naturally expected to have much wider applicability.\nFor future work, a sensible formulation for the “small n, large p” regression problem is to find the optimal expert queries for reducing the interval uncertainty for regression coefficients, with strategies recently studied and applied in reliability analysis problems [3]. Another particularly appealing future formulation is adaptive expert feedback elicitation, where after each feedback, the estimate is updated and the next feature is sampled taking into account the current estimate. Similar expert interaction approaches were shown to be effective for user intent modelling in [16]. Lastly, for the elicitation method proposed here, we intend to run a full-blown user study and test the actual assessments from experts."
    }, {
      "heading" : "A Supplemental Empirical Results",
      "text" : ""
    } ],
    "references" : [ {
      "title" : "Preference elicitation for general random utility models",
      "author" : [ "Hossein Azari Soufiani", "David C Parkes", "Lirong Xia" ],
      "venue" : "In Uncertainty in Artificial Intelligence: Proceedings of the 29th Conference,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2013
    }, {
      "title" : "The cancer cell line encyclopedia enables predictive modelling of anticancer drug sensitivity",
      "author" : [ "Jordi Barretina", "Giordano Caponigro", "Nicolas Stransky", "Kavitha Venkatesan", "Adam A Margolin", "Sungjoon Kim", "Christopher J Wilson", "Joseph Lehár", "Gregory V Kryukov", "Dmitriy 13  Sonkin" ],
      "venue" : "Nature, 483(7391):603–607,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2012
    }, {
      "title" : "Optimal expert elicitation to reduce interval uncertainty",
      "author" : [ "Nadia Ben Abdallah", "Sebastien Destercke" ],
      "venue" : "In AUAI press, editor, Uncertainty in Artificial Intelligence, Uncertainty In Artificial Intelligence (UAI)",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2015
    }, {
      "title" : "Preference-based rank elicitation using statistical models: The case of mallows",
      "author" : [ "Róbert Busa-Fekete", "Eyke Hüllermeier", "Balázs Szörényi" ],
      "venue" : "In Proceedings of the 31st International Conference on Machine Learning",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2014
    }, {
      "title" : "Using bayesian networks to manage uncertainty in student modeling",
      "author" : [ "Cristina Conati", "Abigail Gertner", "Kurt Vanlehn" ],
      "venue" : "User modeling and user-adapted interaction,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2002
    }, {
      "title" : "Incorporating expert knowledge when learning Bayesian network structure: a medical case study",
      "author" : [ "M Julia Flores", "Ann E Nicholson", "Andrew Brunskill", "Kevin B Korb", "Steven Mascaro" ],
      "venue" : "Artificial intelligence in medicine,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Regularization paths for generalized linear models via coordinate descent",
      "author" : [ "Jerome Friedman", "Trevor Hastie", "Rob Tibshirani" ],
      "venue" : "Journal of statistical software,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "Systematic identification of genomic markers of drug sensitivity in cancer cells",
      "author" : [ "Mathew J Garnett", "Elena J Edelman", "Sonja J Heidorn", "Chris D Greenman", "Anahita Dastur", "King Wai Lau", "Patricia Greninger", "I Richard Thompson", "Xi Luo", "Jorge Soares" ],
      "venue" : "Nature, 483(7391):570–575,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "Quantifying expert opinion in linear regression problems",
      "author" : [ "Paul H Garthwaite", "James M Dickey" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1988
    }, {
      "title" : "Statistical challenges of high-dimensional data",
      "author" : [ "Iain M Johnstone", "D Michael Titterington" ],
      "venue" : "Philosophical Transactions of the Royal Society of London A: Mathematical,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1906
    }, {
      "title" : "Interactive elicitation of opinion for a normal linear model",
      "author" : [ "Joseph B Kadane", "James M Dickey", "Robert L Winkler", "Wayne S Smith", "Stephen C Peters" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1980
    }, {
      "title" : "An interactive approach for Bayesian network learning using domain/expert knowledge",
      "author" : [ "Andrés R Masegosa", "Serafín Moral" ],
      "venue" : "International Journal of Approximate Reasoning,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Uncertain Judgements. Eliciting Experts",
      "author" : [ "Anthony O’Hagan", "Caitlin E. Buck", "Alireza Daneshkhah", "J. Richard Eiser", "Paul H. Garthwaite", "David J. Jenkinson", "Jeremy E. Oakley", "Tim Rakow" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2006
    }, {
      "title" : "Comparison of three expert elicitation methods for logistic regression on predicting the presence of the threatened brush-tailed rock-wallaby",
      "author" : [ "Rebecca A. O’Leary", "Samantha Low Choy", "Justine V. Murray", "Mary Kynn", "Robert Denham", "Tara G. Martin", "Kerrie Mengersen" ],
      "venue" : "Petrogale penicillata. Environmetrics,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2009
    }, {
      "title" : "A survey on transfer learning",
      "author" : [ "Sinno Jialin Pan", "Qiang Yang" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2010
    }, {
      "title" : "Interactive intent modeling: Information discovery beyond",
      "author" : [ "Tuukka Ruotsalo", "Giulio Jacucci", "Petri Myllymäki", "Samuel Kaski" ],
      "venue" : "search. Commun. ACM,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2014
    }, {
      "title" : "Regression shrinkage and selection via the lasso",
      "author" : [ "Robert Tibshirani" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1996
    }, {
      "title" : "Genomics of Drug Sensitivity in Cancer (GDSC): a resource for therapeutic biomarker discovery in cancer cells",
      "author" : [ "Wanjuan Yang", "Jorge Soares", "Patricia Greninger", "Elena J Edelman", "Howard Lightfoot", "Simon Forbes", "Nidhi Bindal", "Dave Beare", "James A Smith", "I Richard Thompson" ],
      "venue" : "Nucleic acids research,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2013
    }, {
      "title" : "Expert elicitation and Bayesian network modeling for shipping accidents: A literature review",
      "author" : [ "Guizhen Zhang", "Vinh V Thai" ],
      "venue" : "Safety Science,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : ", [10, 17]) or priors in Bayesian inference.",
      "startOffset" : 2,
      "endOffset" : 10
    }, {
      "referenceID" : 16,
      "context" : ", [10, 17]) or priors in Bayesian inference.",
      "startOffset" : 2,
      "endOffset" : 10
    }, {
      "referenceID" : 14,
      "context" : "Another efficient way to address the lack of data is to transfer knowledge across related tasks (see [15] for a survey).",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 0,
      "context" : "Expert knowledge elicitation techniques have been widely studied in a wide range of application settings, from preference model elicitation [1, 4] to medical science and shipping industry [6, 20], as well as interactive learning for student modelling [5, 12].",
      "startOffset" : 140,
      "endOffset" : 146
    }, {
      "referenceID" : 3,
      "context" : "Expert knowledge elicitation techniques have been widely studied in a wide range of application settings, from preference model elicitation [1, 4] to medical science and shipping industry [6, 20], as well as interactive learning for student modelling [5, 12].",
      "startOffset" : 140,
      "endOffset" : 146
    }, {
      "referenceID" : 5,
      "context" : "Expert knowledge elicitation techniques have been widely studied in a wide range of application settings, from preference model elicitation [1, 4] to medical science and shipping industry [6, 20], as well as interactive learning for student modelling [5, 12].",
      "startOffset" : 188,
      "endOffset" : 195
    }, {
      "referenceID" : 18,
      "context" : "Expert knowledge elicitation techniques have been widely studied in a wide range of application settings, from preference model elicitation [1, 4] to medical science and shipping industry [6, 20], as well as interactive learning for student modelling [5, 12].",
      "startOffset" : 188,
      "endOffset" : 195
    }, {
      "referenceID" : 4,
      "context" : "Expert knowledge elicitation techniques have been widely studied in a wide range of application settings, from preference model elicitation [1, 4] to medical science and shipping industry [6, 20], as well as interactive learning for student modelling [5, 12].",
      "startOffset" : 251,
      "endOffset" : 258
    }, {
      "referenceID" : 11,
      "context" : "Expert knowledge elicitation techniques have been widely studied in a wide range of application settings, from preference model elicitation [1, 4] to medical science and shipping industry [6, 20], as well as interactive learning for student modelling [5, 12].",
      "startOffset" : 251,
      "endOffset" : 258
    }, {
      "referenceID" : 8,
      "context" : "An important line of work [9, 11] studies methods of quantifying subjective opinion about the coefficients of linear regression models.",
      "startOffset" : 26,
      "endOffset" : 33
    }, {
      "referenceID" : 10,
      "context" : "An important line of work [9, 11] studies methods of quantifying subjective opinion about the coefficients of linear regression models.",
      "startOffset" : 26,
      "endOffset" : 33
    }, {
      "referenceID" : 12,
      "context" : "In the studies on prior elicitation [13], some also on regression [14], the focus has often been on how to elicit reliable prior knowledge, after which the Bayesian inference machinery takes care of the rest.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 13,
      "context" : "In the studies on prior elicitation [13], some also on regression [14], the focus has often been on how to elicit reliable prior knowledge, after which the Bayesian inference machinery takes care of the rest.",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 6,
      "context" : "We use the glmnet package [7] for estimating θ̂init, and we vary the number of training samples from 5 to 30, while the number of expert feedbacks that we assume we can obtain grows from 0 to 10.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 17,
      "context" : "org) [19, 8] consisting of 124 drugs and a panel of 124 human cancer cell lines for which complete drug response measurements are available.",
      "startOffset" : 5,
      "endOffset" : 12
    }, {
      "referenceID" : 7,
      "context" : "org) [19, 8] consisting of 124 drugs and a panel of 124 human cancer cell lines for which complete drug response measurements are available.",
      "startOffset" : 5,
      "endOffset" : 12
    }, {
      "referenceID" : 1,
      "context" : "To learn this “pseudo-ground truth,” we employed sparse linear regression using the glmnet package, which has been frequently used to identify genomic features of drug responses [2, 8].",
      "startOffset" : 178,
      "endOffset" : 184
    }, {
      "referenceID" : 7,
      "context" : "To learn this “pseudo-ground truth,” we employed sparse linear regression using the glmnet package, which has been frequently used to identify genomic features of drug responses [2, 8].",
      "startOffset" : 178,
      "endOffset" : 184
    }, {
      "referenceID" : 0,
      "context" : "5, encoding the expert uncertainty (the range of the (true) feature values is [0, 1]).",
      "startOffset" : 78,
      "endOffset" : 84
    }, {
      "referenceID" : 2,
      "context" : "For future work, a sensible formulation for the “small n, large p” regression problem is to find the optimal expert queries for reducing the interval uncertainty for regression coefficients, with strategies recently studied and applied in reliability analysis problems [3].",
      "startOffset" : 269,
      "endOffset" : 272
    }, {
      "referenceID" : 15,
      "context" : "Similar expert interaction approaches were shown to be effective for user intent modelling in [16].",
      "startOffset" : 94,
      "endOffset" : 98
    } ],
    "year" : 2017,
    "abstractText" : "We consider regression under the “extremely small n large p” condition. In particular, we focus on problems with so small sample sizes n compared to the dimensionality p, even n → 1, that predictors cannot be estimated without prior knowledge. Furthermore, we assume all prior knowledge that can be automatically extracted from databases has already been taken into account. This setup occurs in personalized medicine, for instance, when predicting treatment outcomes for an individual patient based on noisy high-dimensional genomics data. A remaining source of information is expert knowledge which has received relatively little attention in recent years. We formulate the inference problem of asking expert feedback on features on a budget, present experimental results for two setups: “small n” and “n=1 with similar data available”, and derive conditions under which the elicitation strategy is optimal. Experiments on simulated experts, both on simulated and genomics data, demonstrate that the proposed strategy can drastically improve prediction accuracy.",
    "creator" : "LaTeX with hyperref package"
  }
}