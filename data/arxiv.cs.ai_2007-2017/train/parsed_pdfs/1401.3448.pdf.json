{
  "name" : "1401.3448.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "AND/OR Multi-Valued Decision Diagrams (AOMDDs) for Graphical Models",
    "authors" : [ "Robert Mateescu", "Rina Dechter", "Radu Marinescu" ],
    "emails" : [ "MATEESCU@PARADISE.CALTECH.EDU", "DECHTER@ICS.UCI.EDU", "R.MARINESCU@4C.UCC.IE" ],
    "sections" : [ {
      "heading" : null,
      "text" : "els, we propose to augment Multi-Valued Decision Diagrams (MDD) with AND nodes, in order to capture function decomposition structure and to extend these compiled data structures to general weighted graphical models (e.g., probabilistic models). We present the AND/OR Multi-Valued Decision Diagram (AOMDD) which compiles a graphical model into a canonical form that supports polynomial (e.g., solution counting, belief updating) or constant time (e.g. equivalence of graphical models) queries. We provide two algorithms for compiling the AOMDD of a graphical model. The first is search-based, and works by applying reduction rules to the trace of the memory intensive AND/OR search algorithm. The second is inference-based and uses a Bucket Elimination schedule to combine the AOMDDs of the input functions via the the APPLY operator. For both algorithms, the compilation time and the size of the AOMDD are, in the worst case, exponential in the treewidth of the graphical model, rather than pathwidth as is known for ordered binary decision diagrams (OBDDs). We introduce the concept of semantic treewidth, which helps explain why the size of a decision diagram is often much smaller than the worst case bound. We provide an experimental evaluation that demonstrates the potential of AOMDDs."
    }, {
      "heading" : "1. Introduction",
      "text" : "The paper extends decision diagrams into AND/OR multi-valued decision diagrams (AOMDDs) and shows how graphical models can be compiled into these data-structures. The work presented in this paper is based on two existing frameworks: (1) AND/OR search spaces for graphical models and (2) decision diagrams."
    }, {
      "heading" : "1.1 AND/OR Search Spaces",
      "text" : "AND/OR search spaces (Dechter & Mateescu, 2004a, 2004b, 2007) have proven to be a unifying framework for various classes of search algorithms for graphical models. The main characteristic is the exploitation of independencies between variables during search, which can provide exponential speedups over traditional search methods that can be viewed as traversing an OR structure. The\nc©2008 AI Access Foundation. All rights reserved.\nAND nodes capture problem decomposition into independent subproblems, and the OR nodes represent branching according to variable values. AND/OR spaces can accommodate dynamic variable ordering, however most of the current work focuses on static decomposition. Examples of AND/OR search trees and graphs will appear later, for example in Figures 6 and 7.\nThe AND/OR search space idea was originally developed for heuristic search (Nilsson, 1980). In the context of graphical models, AND/OR search (Dechter & Mateescu, 2007) was also inspired by search advances introduced sporadically in the past three decades for constraint satisfaction and more recently for probabilistic inference and for optimization tasks. Specifically, it resembles the pseudo tree rearrangement (Freuder & Quinn, 1985, 1987), that was adapted subsequently for distributed constraint satisfaction by Collin, Dechter, and Katz (1991, 1999) and more recently by Modi, Shen, Tambe, and Yokoo (2005), and was also shown to be related to graph-based backjumping (Dechter, 1992). This work was extended by Bayardo and Miranker (1996) and Bayardo and Schrag (1997) and more recently applied to optimization tasks by Larrosa, Meseguer, and Sanchez (2002). Another version that can be viewed as exploring the AND/OR graphs was presented recently for constraint satisfaction (Terrioux & Jégou, 2003b) and for optimization (Terrioux & Jégou, 2003a). Similar principles were introduced recently for probabilistic inference, in algorithm Recursive Conditioning (Darwiche, 2001) as well as in Value Elimination (Bacchus, Dalmao, & Pitassi, 2003b, 2003a), and are currently at the core of the most advanced SAT solvers (Sang, Bacchus, Beame, Kautz, & Pitassi, 2004)."
    }, {
      "heading" : "1.2 Decision Diagrams",
      "text" : "Decision diagrams are widely used in many areas of research, especially in software and hardware verification (Clarke, Grumberg, & Peled, 1999; McMillan, 1993). A BDD represents a Boolean function by a directed acyclic graph with two terminal nodes (labeled 0 and 1), and every internal node is labeled with a variable and has exactly two children: low for 0 and high for 1. If isomorphic nodes were not merged, we would have the full search tree, also called Shannon tree, which is the usual full tree explored by a backtracking algorithm. The tree is ordered if variables are encountered in the same order along every branch. It can then be compressed by merging isomorphic nodes (i.e., with the same label and identical children), and by eliminating redundant nodes (i.e., whose low and high children are identical). The result is the celebrated reduced ordered binary decision diagram, or OBDD for short, introduced by Bryant (1986). However, the underlying structure is OR, because the initial Shannon tree is an OR tree. If AND/OR search trees are reduced by node merging and redundant nodes elimination we get a compact search graph that can be viewed as a BDD representation augmented with AND nodes."
    }, {
      "heading" : "1.3 Knowledge Compilation for Graphical Models",
      "text" : "In this paper we combine the two ideas, creating a decision diagram that has an AND/OR structure, thus exploiting problem decomposition. As a detail, the number of values is also increased from two to any constant. In the context of constraint networks, decision diagrams can be used to represent the whole set of solutions, facilitating solutions count, solution enumeration and queries on equivalence of constraint networks. The benefit of moving from OR structure to AND/OR is in a lower complexity of the algorithms and size of the compiled structure. It typically moves from being bounded exponentially in pathwidth pw∗, which is characteristic to chain decompositions or linear structures, to being exponentially bounded in treewidth w∗, which is characteristic of tree\nstructures (Bodlaender & Gilbert, 1991) (it always holds that w∗ ≤ pw∗ and pw∗ ≤ w∗ · logn, where n is the number of variables of the model). In both cases, the compactness result achieved in practice is often far smaller than what the bounds suggest.\nA decision diagram offers a compilation of a propositional knowledge-base. An extension of the OBDDs was provided by Algebraic Decision Diagrams (ADD) (Bahar, Frohm, Gaona, Hachtel, Macii, Pardo, & Somenzi, 1993), where the terminal nodes are not just 0 or 1, but take values from an arbitrary finite domain. The knowledge compilation approach has become an important research direction in automated reasoning in the past decade (Selman & Kautz, 1996; Darwiche & Marquis, 2002; Cadoli & Donini, 1997). Typically, a knowledge representation language is compiled into a compact data structure that allows fast responses to various queries. Accordingly, the computational effort can be divided between an offline and an online phase where most of the work is pushed offline. Compilation can also be used to generate compact building blocks to be used by online algorithms multiple times. Macro-operators compiled during or prior to search can be viewed in this light (Korf & Felner, 2002), while in graphical models the building blocks are the functions whose compact compiled representations can be used effectively across many tasks.\nAs one example, consider product configuration tasks and imagine a user that chooses sequential options to configure a product. In a naive system, the user would be allowed to choose any valid option at the current level based only on the initial constraints, until either the product is configured, or else, when a dead-end is encountered, the system would backtrack to some previous state and continue from there. This would in fact be a search through the space of possible partial configurations. Needless to say, it would be very unpractical, and would offer the user no guarantee of finishing in a limited time. A system based on compilation would actually build the backtrack-free search space in the offline phase, and represent it in a compact manner. In the online phase, only valid partial configurations (i.e., that can be extended to a full valid configuration) are allowed, and depending on the query type, response time guarantees can be offered in terms of the size of the compiled structure.\nNumerous other examples, such as diagnosis and planning problems, can be formulated as graphical models and could benefit from compilation (Palacios, Bonet, Darwiche, & Geffner, 2005; Huang & Darwiche, 2005a). In diagnosis, compilation can facilitate fast detection of possible faults or explanations for some unusual behavior. Planning problems can also be formulated as graphical models, and a compilation would allow swift adjustments according to changes in the environment. Probabilistic models are one of the most used types of graphical models, and the basic query is to compute conditional probabilities of some variables given the evidence. A compact compilation of a probabilistic model would allow fast response to queries that incorporate evidence acquired in time. For example, two of the most important tasks for Bayesian networks are computing the probability of the evidence, and computing the maximum probable explanation (MPE). If some of the model variables become assigned (evidence), these tasks can be performed in time linear in the compilation size, which in practice is in many cases smaller than the upper-bound based on the treewidth or pathwidth of the graph. Formal verification is another example where compilation is heavily used to compare equivalence of circuit design, or to check the behavior of a circuit. Binary Decision Diagram (BDD) (Bryant, 1986) is arguably the most widely known and used compiled structure.\nThe contributions made in this paper to knowledge compilation in general and to decision diagrams in particular are the following:\n1. We formally describe the AND/OR Multi-Valued Decision Diagram (AOMDD) and prove it to be a canonical representation for constraint networks, given a pseudo tree.\n2. We extend the AOMDD to general weighted graphical models.\n3. We give a compilation algorithm based on AND/OR search, that saves the trace of a memory intensive search and then reduces it in one bottom up pass.\n4. We present the APPLY operator that combines two AOMDDs and show that its complexity is at most quadratic in the input, but never worse than exponential in the treewidth.\n5. We give a scheduling order for building the AOMDD of a graphical model starting with the AOMDDs of its functions which is based on a Variable Elimination algorithm. This guarantees that the complexity is at most exponential in the induced width (treewidth) along the ordering.\n6. We show how AOMDDs relate to various earlier and recent compilation frameworks, providing a unifying perspective for all these methods.\n7. We introduce the semantic treewidth, which helps explain why compiled decision diagrams are often much smaller than the worst case bound.\n8. We provide an experimental evaluation of the new data structure.\nThe structure of the paper is as follows. Section 2 provides preliminary definitions, a description of binary decision diagrams and the Bucket Elimination algorithm. Section 3 gives an overview of AND/OR search spaces. Section 4 introduces the AOMDD and discusses its properties. Section 5 describes a search-based algorithm for compiling the AOMDD. Section 6 presents a compilation algorithm based on a Bucket Elimination schedule and the APPLY operation. Section 7 proves that the AOMDD is a canonical representation for constraint networks given a pseudo tree, and Section 8 extends the AOMDD to weighted graphical models and proves their canonicity. Section 9 ties the canonicity to the new concept of semantic treewidth. Section 10 provides an experimental evaluation. Section 11 presents related work and Section 12 concludes the paper. All the proofs appear in an appendix."
    }, {
      "heading" : "2. Preliminaries",
      "text" : "Notations A reasoning problem is defined in terms of a set of variables taking values from finite domains and a set of functions defined over these variables. We denote variables or subsets of variables by uppercase letters (e.g., X,Y, . . .) and values of variables by lower case letters (e.g., x, y, . . .). Sets are usually denoted by bold letters, for example X = {X1, . . . , Xn} is a set of variables. An assignment (X1 = x1, . . . , Xn = xn) can be abbreviated as x = (〈X1, x1〉, . . . , 〈Xn, xn〉) or x = (x1, . . . , xn). For a subset of variables Y, DY denotes the Cartesian product of the domains of variables in Y. The projection of an assignment x = (x1, . . . , xn) over a subset Y is denoted by xY or x[Y]. We will also denote by Y = y (or y for short) the assignment of values to variables in Y from their respective domains. We denote functions by letters f , g, h etc., and the scope (set of arguments) of the function f by scope(f)."
    }, {
      "heading" : "2.1 Graphical Models",
      "text" : "DEFINITION 1 (graphical model) A graphical model M is a 4-tuple, M = 〈X,D,F,⊗〉, where:\n1. X = {X1, . . . , Xn} is a finite set of variables; 2. D = {D1, . . . , Dn} is the set of their respective finite domains of values; 3. F = {f1, . . . , fr} is a set of positive real-valued discrete functions (i.e., their domains can\nbe listed), each defined over a subset of variables Si ⊆ X, called its scope, and denoted by scope(fi).\n4. ⊗ is a combination operator1 (e.g., ⊗ ∈ { ∏ , ∑\n,1} – product, sum, join), that can take as input two (or more) real-valued discrete functions, and produce another real-valued discrete function.\nThe graphical model represents the combination of all its functions: ⊗ri=1fi.\nSeveral examples of graphical models appear later, for example: Figure 1 shows a constraint network and Figure 2 shows a belief network.\nIn order to define the equivalence of graphical models, it is useful to introduce the notion of universal graphical model that is defined by a single function.\nDEFINITION 2 (universal equivalent graphical model) Given a graphical model M = 〈X,D,F1,⊗〉 the universal equivalent model of M is u(M) = 〈X,D,F2 = {⊗fi∈F1fi},⊗〉.\nTwo graphical models are equivalent if they represent the same function. Namely, if they have the same universal model.\nDEFINITION 3 (weight of a full and a partial assignment) Given a graphical model M = 〈X,D,F〉, the weight of a full assignment x = (x1, . . . , xn) is defined by w(x) = ⊗f∈Ff(x[scope(f)]). Given a subset of variables Y ⊆ X, the weight of a partial assignment y is the combination of all the functions whose scopes are included in Y (denoted by FY) evaluated at the assigned values. Namely, w(y) = ⊗f∈FYf(y[scope(f)]).\nConsistency For most graphical models, the range of the functions has a special zero value “0” that is absorbing relative to the combination operator (e.g., multiplication). Combining anything with “0” yields a “0”. The “0” value expresses the notion of inconsistent assignments. It is a primary concept in constraint networks but can also be defined relative to other graphical models that have a “0” element.\nDEFINITION 4 (consistent partial assignment, solution) Given a graphical model having a “0” element, a partial assignment is consistent if its cost is non-zero. A solution is a consistent assignment to all the variables.\nDEFINITION 5 (primal graph) The primal graph of a graphical model is an undirected graph that has variables as its vertices and an edge connects any two variables that appear in the scope of the same function.\nThe primal graph captures the structure of the knowledge expressed by the graphical model. In particular, graph separation indicates independency of sets of variables given some assignments to other variables. All of the advanced algorithms for graphical models exploit the graphical structure, by using a heuristically good elimination order, a tree decomposition or some similar method. We will use the concept of pseudo tree, which resembles the tree rearrangements introduced by Freuder and Quinn (1985):\n1. The combination operator can also be defined axiomatically (Shenoy, 1992).\nDEFINITION 6 (pseudo tree) A pseudo tree of a graph G = (X, E) is a rooted tree T having the same set of nodes X, such that every arc in E is a backarc in T (A path in a rooted tree starts at the root and ends at one leaf. Two nodes can be connected by a backarc only if there exists a path that contains both).\nWe use the common concepts and parameters from graph theory, that characterize the connectivity of the graph, and how close it is to a tree or to a chain. The induced width of a graphical model governs the complexity of solving it by Bucket Elimination (Dechter, 1999), and was also shown to bound the AND/OR search graph when memory is used to cache solved subproblems (Dechter & Mateescu, 2007).\nDEFINITION 7 (induced graph, induced width, treewidth, pathwidth) An ordered graph is a pair (G, d), where G = ({X1, . . . , Xn}, E) is an undirected graph, and d = (X1, . . . , Xn) is an ordering of the nodes. The width of a node in an ordered graph is the number of neighbors that precede it in the ordering. The width of an ordering d, denoted w(d), is the maximum width over all nodes. The induced width of an ordered graph, w∗(d), is the width of the induced ordered graph obtained as follows: for each node, from last to first in d, its preceding neighbors are connected in a clique. The induced width of a graph, w∗, is the minimal induced width over all orderings. The induced width is also equal to the treewidth of a graph. The pathwidth pw∗ of a graph is the treewidth over the restricted class of orderings that correspond to chain decompositions.\nVarious reasoning tasks, or queries can be defined over graphical models. Those can be defined formally using marginalization operators such as projection, summation and minimization. However, since our goal is to present a compilation of a graphical model which is independent of the queries that can be posed on it, we will discuss tasks in an informal manner only. For more information see the work of Kask, Dechter, Larrosa, and Dechter (2005).\nThroughout the paper, we will use two examples of graphical models: constraint networks and belief networks. In the case of constraint networks, the functions can be understood as relations. In other words, the functions (also called constraints) can take only two values, {0, 1}, or {false, true}. A 0 value indicates that the corresponding assignment to the variables is inconsistent (not allowed), and a 1 value indicates consistency. Belief networks are an example of the more general case of graphical models (also called weighted graphical models). The functions in this case are conditional probability tables, so the values of a function are real numbers in the interval [0, 1].\nExample 1 Figure 1(a) shows a graph coloring problem that can be modeled by a constraint network. Given a map of regions, the problem is to color each region by one of the given colors {red, green, blue}, such that neighboring regions have different colors. The variables of the problems are the regions, and each one has the domain {red, green, blue}. The constraints are the relation “different” between neighboring regions. Figure 1(b) shows the constraint graph, and a solution (A=red, B=blue, C=green, D=green, E=blue, F=blue, G=red) is given in Figure 1(a). A more detailed example will be given later in Example 8.\nPropositional Satisfiability A special case of a CSP is propositional satisfiability (SAT). A formula ϕ in conjunctive normal form (CNF) is a conjunction of clauses α1, . . . , αt, where a clause is a disjunction of literals (propositions or their negations). For example, α = (P ∨ ¬Q ∨ ¬R) is a clause, where P , Q and R are propositions, and P , ¬Q and ¬R are literals. The SAT problem is to decide whether a given CNF theory has a model, i.e., a truth-assignment to its propositions that does not violate any clause. Propositional satisfiability (SAT) can be defined as a CSP, where propositions correspond to variables, domains are {0, 1}, and constraints are represented by clauses, for example the clause (¬A ∨ B) is a relation over its propositional variables that allows all tuples over (A,B) except (A = 1, B = 0).\nCost Networks An immediate extension of constraint networks are cost networks where the set of functions are real-valued cost functions, and the primary task is optimization. Also, GAI-nets (generalized additive independence, Fishburn, 1970) can be used to represent utility functions. An example of cost functions will appear in Figure 19.\nDEFINITION 8 (cost network, combinatorial optimization) A cost network is a 4-tuple, 〈X,D,C, ∑\n〉, where X is a set of variables X = {X1, . . . , Xn}, associated with a set of discrete-valued domains, D = {D1, . . . , Dn}, and a set of cost functions C = {C1, . . . , Cr}. Each Ci is a real-valued function defined on a subset of variables Si ⊆ X. The combination operator, is ∑\n. The reasoning problem is to find a minimum cost solution.\nBelief Networks (Pearl, 1988) provide a formalism for reasoning about partial beliefs under conditions of uncertainty. They are defined by a directed acyclic graph over vertices representing random variables of interest (e.g., the temperature of a device, the gender of a patient, a feature of an object, the occurrence of an event). The arcs signify the existence of direct causal influences between linked variables quantified by conditional probabilities that are attached to each cluster of parentschild vertices in the network.\nDEFINITION 9 (belief networks) A belief network (BN) is a graphical model P = 〈X,D,PG, ∏\n〉, where X = {X1, . . . , Xn} is a set of variables over domains D = {D1, . . . , Dn}. Given a directed acyclic graph G over X as nodes, PG = {P1, . . . , Pn}, where Pi = {P (Xi | pa (Xi) ) } are conditional probability tables (CPTs for short) associated with each Xi, where pa(Xi) are the parents of Xi in the acyclic graph G. A belief network represents a probability distribution over X, P (x1, . . . , xn) = ∏n i=1 P (xi|xpa(Xi)). An evidence set e is an instantiated subset of variables.\nWhen formulated as a graphical model, functions in F denote conditional probability tables and the scopes of these functions are determined by the directed acyclic graph G: each function fi ranges over variable Xi and its parents in G. The combination operator is product, ⊗ = ∏\n. The primal graph of a belief network (viewed as an undirected model) is called a moral graph. It connects any two variables appearing in the same CPT.\nExample 2 Figure 2(a) gives an example of a belief network over 6 variables, and Figure 2(b) shows its moral graph . The example expresses the causal relationship between variables “Season” (A), “The configuration of an automatic sprinkler system” (B), “The amount of rain expected” (C), “The amount of manual watering necessary” (D), “The wetness of the pavement” (F ) and “Whether or not the pavement is slippery” (G). The belief network expresses the probability distribution P (A,B,C,D, F,G) = P (A) · P (B|A) · P (C|A) · P (D|B,A) · P (F |C,B) · P (G|F ). Another example of a belief network and CPTs appears in Figure 9.\nThe two most popular tasks for belief networks are defined below:\nDEFINITION 10 (belief updating, most probable explanation (MPE)) Given a belief network and evidence e, the belief updating task is to compute the posterior marginal probability of variable Xi, conditioned on the evidence. Namely,\nBel(Xi = xi) = P (Xi = xi | e) = α ∑\n{(x1,...,xi−1,xi+1,...,xn)|E=e,Xi=xi}\nn ∏\nk=1\nP (xk, e|xpak),\nwhere α is a normalization constant. The most probable explanation (MPE) task is to find a complete assignment which agrees with the evidence, and which has the highest probability among all such assignments. Namely, to find an assignment (xo1, . . . , x o n) such that\nP (xo1, . . . , x o n) = maxx1,...,xn\nn ∏\nk=1\nP (xk, e|xpak)."
    }, {
      "heading" : "2.2 Binary Decision Diagrams Review",
      "text" : "Decision diagrams are widely used in many areas of research to represent decision processes. In particular, they can be used to represent functions. Due to the fundamental importance of Boolean functions, a lot of effort has been dedicated to the study of Binary Decision Diagrams (BDDs), which are extensively used in software and hardware verification (Clarke et al., 1999; McMillan, 1993). The earliest work on BDDs is due to Lee (1959), who introduced the binary-decision program, that can be understood as a linear representation of a BDD (e.g., a depth first search ordering of the nodes), where each node is a branching instruction indicating the address of the next instruction for both the 0 and the 1 value of the test variable. Akers (1978) presented the actual graphical\nrepresentation and further developed the BDD idea. However, it was Bryant (1986) that introduced what is now called the Ordered Binary Decision Diagram (OBDD). He restricted the order of variables along any path of the diagram, and presented algorithms (most importantly the apply procedure, that combines two OBDDs by an operation) that have time complexity at most quadratic in the sizes of the input diagrams. OBDDs are fundamental for applications with large binary functions, especially because in many practical cases they provide very compact representations.\nA BDD is a representation of a Boolean function. Given B = {0, 1}, a Boolean function f : Bn → B, has n arguments, X1, · · · , Xn, which are Boolean variables, and takes Boolean values.\nExample 3 Figure 3(a) shows a table representation of a Boolean function of three variables. This explicit representation is the most straightforward, but also the most costly due to its exponential requirements. The same function can also be represented by a binary tree, shown in Figure 3(b), that has the same exponential size in the number of variables. The internal round nodes represent the variables, the solid edges are the 1 (or high) value, and the dotted edges are the 0 (or low) value. The leaf square nodes show the value of the function for each assignment along a path. The tree shown in 3(b) is unordered, because variables do not appear in the same order along each path.\nIn building an OBDD, the first condition is to have variables appear in the same order (A,B,C) along every path from root to leaves. Figure 3(c) shows an ordered binary tree for our function. Once an order is imposed, there are two reduction rules that transform a decision diagram into an equivalent one: (1) isomorphism: merge nodes that have the same label and the same children. (2) redundancy: eliminate nodes whose low and high edges point to the same node, and connect parent of removed node directly to child of removed node.\nApplying the two reduction rules exhaustively yields a reduced OBDD, sometimes denoted rOBDD. We will just use OBDD and assume that it is completely reduced.\nExample 4 Figure 4(a) shows the binary tree from Figure 3(c) after the isomorphic terminal nodes (leaves) have been merged. The highlighted nodes, labeled with C, are also isomorphic, and Figure 4(b) shows the result after they are merged. Now, the highlighted nodes labeled with C and B are redundant, and removing them gives the OBDD in Figure 4(c)."
    }, {
      "heading" : "2.3 Bucket Elimination Review",
      "text" : "Bucket Elimination (BE) (Dechter, 1999) is a well known variable elimination algorithm for inference in graphical models. We will describe it using the terminology for constraint networks, but BE\ncan also be applied to any graphical model. Consider a constraint network R = 〈X,D,C〉 and an ordering d = (X1, X2, . . . , Xn). The ordering d dictates an elimination order for BE, from last to first. Each variable is associated with a bucket. Each constraint from C is placed in the bucket of its latest variable in d. Buckets are processed from Xn to X1 by eliminating the bucket variable (the constraints residing in the bucket are joined together, and the bucket variable is projected out) and placing the resulting constraint (also called message) in the bucket of its latest variable in d. After its execution, BE renders the network backtrack free, and a solution can be produced by assigning variables along d. BE can also produce the solutions count if marginalization is done by summation (rather than projection) over the functional representation of the constraints, and join is substituted by multiplication.\nBE also constructs a bucket tree, by linking the bucket of each Xi to the destination bucket of its message (called the parent bucket). A node in the bucket tree typically has a bucket variable, a collection of constraints, and a scope (the union of the scopes of its constraints). If the nodes of the bucket tree are replaced by their respective bucket variables, it is easy to see that we obtain a pseudo tree.\nExample 5 Figure 5(a) shows a network with four constraints. Figure5(b) shows the execution of Bucket Elimination along d = (A,B,E,C,D). The buckets are processed from D to A.2 Figure 5(c) shows the bucket tree. The pseudo tree corresponding to the order d is given in Fig. 6(a).\n2. The representation in Figure 5 reverses the top down bucket processing described in earlier papers (Dechter, 1999).\nProcedure GeneratePseudoTree(G, d) input : graph G = (X, E); order d = (X1, . . . , Xn) output : Pseudo tree T Make X1 the root of T1 Condition on X1 (eliminate X1 and its incident edges from G). Let G1, . . . , Gp be the resulting connected2 components of G for i = 1 to p do3 Ti = GeneratePseudoTree (Gi, d|Gi )4 Make root of Ti a child of X15\nreturn T6"
    }, {
      "heading" : "2.4 Orderings and Pseudo Trees",
      "text" : "Given an ordering d, the structural information captured in the primal graph through the scopes of the functions F = {f1, . . . , fr} can be used to create the unique pseudo tree that corresponds to d (Mateescu & Dechter, 2005). This is precisely the bucket tree (or elimination tree), that is created by BE (when variables are processed in reverse d). The same pseudo tree can be created by conditioning on the primal graph, and processing variables in the order d, as described in Procedure GeneratePseudoTree. In the following, d|Gi is the restriction of the order d to the nodes of the graph Gi."
    }, {
      "heading" : "3. Overview of AND/OR Search Space for Graphical Models",
      "text" : "The AND/OR search space is a recently introduced (Dechter & Mateescu, 2004a, 2004b, 2007) unifying framework for advanced algorithmic schemes for graphical models. Its main virtue consists in exploiting independencies between variables during search, which can provide exponential speedups over traditional search methods oblivious to problem structure. Since AND/OR MDDs are based on AND/OR search spaces we need to provide a comprehensive overview for the sake of completeness."
    }, {
      "heading" : "3.1 AND/OR Search Trees",
      "text" : "The AND/OR search tree is guided by a pseudo tree of the primal graph. The idea is to exploit the problem decomposition into independent subproblems during search. Assigning a value to a variable (also known as conditioning), is equivalent in graph terms to removing that variable (and its incident edges) from the primal graph. A partial assignment can therefore lead to the decomposition of the residual primal graph into independent components, each of which can be searched (or solved) separately. The pseudo tree captures precisely all these decompositions given an order of variable instantiation.\nDEFINITION 11 (AND/OR search tree of a graphical model) Given a graphical model M = 〈X,D,F〉, its primal graph G and a pseudo tree T of G, the associated AND/OR search tree has alternating levels of OR and AND nodes. The OR nodes are labeled Xi and correspond to variables. The AND nodes are labeled 〈Xi, xi〉 (or simply xi) and correspond to value assignments. The structure of the AND/OR search tree is based on T . The root is an OR node labeled with the root of T . The children of an OR node Xi are AND nodes labeled with assignments 〈Xi, xi〉 that\nare consistent with the assignments along the path from the root. The children of an AND node 〈Xi, xi〉 are OR nodes labeled with the children of variable Xi in the pseudo tree T .\nExample 6 Figure 6 shows an example of an AND/OR search tree for the graphical model given in Figure 5(a), assuming all tuples are consistent, and variables are binary valued. When some tuples are inconsistent, some of the paths in the tree do not exist. Figure 6(a) gives the pseudo tree that guides the search, from top to bottom, as indicated by the arrows. The dotted arcs are backarcs from the primal graph. Figure 6(b) shows the AND/OR search tree, with the alternating levels of OR (circle) and AND (square) nodes, and having the structure indicated by the pseudo tree.\nThe AND/OR search tree can be traversed by a depth first search algorithm, thus using linear space. It was already shown (Freuder & Quinn, 1985; Bayardo & Miranker, 1996; Darwiche, 2001; Dechter & Mateescu, 2004a, 2007) that:\nTHEOREM 1 Given a graphical model M over n variables, and a pseudo tree T of depth m, the size of the AND/OR search tree based on T is O(n km), where k bounds the domains of variables. A graphical model of treewidth w∗ has a pseudo tree of depth at most w∗ logn, therefore it has an AND/OR search tree of size O(n kw ∗ log n).\nThe AND/OR search tree expresses the set of all possible assignments to the problem variables (all solutions). The difference from the traditional OR search space is that a solution is no longer a path from root to a leaf, but rather a tree, defined as follows:\nDEFINITION 12 (solution tree) A solution tree of an AND/OR search tree contains the root node. For every OR node, it contains one of its child nodes and for each of its AND nodes it contains all its child nodes, and all its leaf nodes are consistent."
    }, {
      "heading" : "3.2 AND/OR Search Graph",
      "text" : "The AND/OR search tree may contain nodes that root identical subproblems. These nodes are said to be unifiable. When unifiable nodes are merged, the search space becomes a graph. Its size becomes smaller at the expense of using additional memory by the search algorithm. The depth first search algorithm can therefore be modified to cache previously computed results, and retrieve them when the same nodes are encountered again. The notion of unifiable nodes is defined formally next.\nDEFINITION 13 (minimal AND/OR graph, isomorphism) Two AND/OR search graphs G and G′ are isomorphic if there exists a one to one mapping σ from the vertices of G to the vertices of G′ such that for any vertex v, if σ(v) = v′, then v and v′ root identical subgraphs relative to σ. An AND/OR graph is called minimal if all its isomorphic subgraphs are merged. Isomorphic nodes (that root isomorphic subgraphs) are also said to be unifiable.\nIt was shown by Dechter and Mateescu (2007) that:\nTHEOREM 2 A graphical model M has a unique minimal AND/OR search graph relative to a pseudo-tree T .\nThe minimal AND/OR graph of a graphical model G relative to a pseudo tree T is denoted by MT (G). Note that the definition of minimality used in the work of Dechter and Mateescu (2007) is based only on isomorphism reduction. We will extend it here by also including the elimination of redundant nodes. The previous theorem only shows that given an AND/OR graph, the merge operator has a fixed point, which is the minimal AND/OR graph. We will show in this paper that the AOMDD is a canonical representation, namely that any two equivalent graphical models can be represented by the same unique AOMDD given that they accept the same pseudo tree, and the AOMDD is minimal in terms of number of nodes.\nSome unifiable nodes can be identified based on their contexts. We can define graph based contexts for both OR nodes and AND nodes, just by expressing the set of ancestor variables in T that completely determine a conditioned subproblem. However, it can be shown that using caching based on OR contexts makes caching based on AND contexts redundant and vice versa, so we will only use OR caching. Any value assignment to the context of X separates the subproblem below X from the rest of the network.\nDEFINITION 14 (OR context) Given a pseudo tree T of an AND/OR search space, context(X) = [X1 . . . Xp] is the set of ancestors of X in T , ordered descendingly, that are connected in the primal graph to X or to descendants of X .\nDEFINITION 15 (context unifiable OR nodes) Given an AND/OR search graph, two OR nodes n1 and n2 are context unifiable if they have the same variable label X and the assignments of their contexts is identical. Namely, if π1 is the partial assignment of variables along the path to n1, and π2 is the partial assignment of variables along the path to n2, then their restriction to the context of X is the same: π1|context(X) = π2|context(X).\nThe depth first search algorithm that traverses the AND/OR search tree, can be modified to traverse a graph, if enough memory is available. We could allocate a cache table for each variable X , the scope of the table being context(X). The size of the cache table for X is therefore the product of the domains of variables in its context. For each variable X , and for each possible assignment to its context, the corresponding conditioned subproblem is solved only once and the computed value is saved in the cache table, and whenever the same context assignment is encountered again, the value of the subproblem is retrieved from the cache table. Such an algorithm traverses what is called the context minimal AND/OR graph.\nDEFINITION 16 (context minimal AND/OR graph) The context minimal AND/OR graph is obtained from the AND/OR search tree by merging all the context unifiable OR nodes.\nIt was already shown (Bayardo & Miranker, 1996; Dechter & Mateescu, 2004a, 2007) that:\nTHEOREM 3 Given a graphical model M, its primal graph G and a pseudo tree T , the size of the context minimal AND/OR search graph based on T , and therefore the size of its minimal AND/OR search graph, is O(n kw ∗ T\n(G)), where w∗T (G) is the induced width of G over the depth first traversal of T , and k bounds the domain size.\nExample 7 Let’s look at the impact of caching on the size of the search space by examining a larger example. Figure 7(a) shows a graphical model with binary variables and Figure 7(b) a pseudo tree that drives the AND/OR search. The context of each node is given in square brackets. The context minimal graph is given in Figure 7(c). Note that it is far smaller than the AND/OR search tree, which has 28 = 256 AND nodes at the level of M alone (because M is at depth 8 in the pseudo tree). The shaded rectangles show the size of each cache table, equal to the number of OR nodes that appear in each one. A cache entry is useful whenever there are more than one incoming edges into the OR node. Incidentally, the caches that are not useful (namely OR nodes with only one incoming arc), are called dead caches (Darwiche, 2001), and can be determined based only on the pseudo\ntree inspection, therefore a cache table need not be allocated for them. The context minimal graph can also explain the execution of BE along the same pseudo tree (or, equivalently, along its depth first traversal order). The buckets are the shaded rectangles, and the processing is done bottom up. The number of possible assignments to each bucket equals the number of AND nodes that appear in it. The message scope is identical to the context of the bucket variable, and the message itself is identical to the corresponding cache table. For more details on the relationship between AND/OR search and BE see the work of Mateescu and Dechter (2005)."
    }, {
      "heading" : "3.3 Weighted AND/OR Graphs",
      "text" : "In the previous subsections we described the structure of the AND/OR trees and graphs. In order to use them to solve a reasoning task, we need to define a way of using the input function values during the traversal of an AND/OR graph. This is realized by placing weights (or costs) on the OR-to-AND arcs, dictated by the function values. Only the functions that are relevant contribute to an OR-to-AND arc weight, and this is captured by the buckets relative to the pseudo tree:\nDEFINITION 17 (buckets relative to a pseudo tree) Given a graphical model M = 〈X,D,F,⊗〉 and a pseudo tree T , the bucket of Xi relative to T , denoted BT (Xi), is the set of functions whose scopes contain Xi and are included in pathT (Xi), which is the set of variables from the root to Xi in T . Namely,\nBT (Xi) = {f ∈ F|Xi ∈ scope(f), scope(f) ⊆ pathT (Xi)}.\nA function belongs to the bucket of a variable Xi iff its scope has just been fully instantiated when Xi was assigned. Combining the values of all functions in the bucket, for the current assignment, gives the weight of the OR-to-AND arc:\nDEFINITION 18 (OR-to-AND weights) Given an AND/OR graph of a graphical model M, the weight w(n,m)(Xi, xi) of arc (n,m) where Xi labels n and xi labels m, is the combination of all the functions in BT (Xi) assigned by values along the current path to the AND node m, πm. Formally, w(n,m)(Xi, xi) = ⊗f∈BT (Xi)f(asgn(πm)[scope(f)]).\nDEFINITION 19 (weight of a solution tree) Given a weighted AND/OR graph of a graphical model M, and given a solution tree t having the OR-to-AND set of arcs arcs(t), the weight of t is defined by w(t) = ⊗e∈arcs(t)w(e).\nExample 8 We start with the more straightforward case of constraint networks. Since functions only take values 0 or 1, and the combination is by product (join of relations), it follows that any ORto-AND arc can only have a weight of 0 or 1. An example is given in Figure 8. Figure 8(a) shows a constraint graph, 8(b) a pseudo tree for it, and 8(c) the four relations that define the constraint problem. Figure 8(d) shows the AND/OR tree that can be traversed by a depth first search algorithm that only checks the consistency of the input functions (i.e., no constraint propagation is used). Similar to the OBDD representation, the OR-to-AND arcs with a weight of 0 are denoted by dotted lines, and the tree is not unfolded below them, since it will not contain any solution. The arcs with a weight of 1 are drawn with solid lines.\nA\nE\nC\nB\nF\nD\n(a) Constraint graph\nA\nD\nB\nEC\nF\n(b) Pseudo tree\n0111 1011 1101 1001 1110 0010 1100 1000\nRABCCBA\n0111 1011 1101 0001 1110 1010 0100 1000\nRABEEBA\n0111 1011 1101 1001 1110 1010 1100 0000\nRAEFFEA\n1111 1011 0101 1001 0110 1010 1100 1000\nRBCDDCB\n(c) Relations\nExample 9 Figure 9 shows a weighted AND/OR tree for a belief network. Figure 9(a) shows the directed acyclic graph, and the dotted arc BC added by moralization. Figure 9(b) shows the pseudo tree, and 9(c) shows the conditional probability tables. Figure 9(d) shows the weighted AND/OR tree.\nAs we did for constraint networks, we can move from weighted AND/OR search trees to weighted AND/OR search graphs by merging unifiable nodes. In this case the arc labels should be also considered when determining unifiable subgraphs. This can yield context-minimal weighted AND/OR search graphs and minimal weighted AND/OR search graphs."
    }, {
      "heading" : "4. AND/OR Multi-Valued Decision Diagrams (AOMDDs)",
      "text" : "In this section we begin describing the contributions of this paper. The context minimal AND/OR graph (Definition 16) offers an effective way of identifying some unifiable nodes during the execution of the search algorithm. Namely, context unifiable nodes are discovered based only on their paths from the root, without actually solving their corresponding subproblems. However, merging based on context is not complete, which means that there may still exist unifiable nodes in the search graph that do not have identical contexts. Moreover, some of the nodes in the context\nA\nD\nB C\nE\n(a) Belief network\nA\nD\nB\nCE\n(b) Pseudo tree\n.2\n.7\n.5\n.4\nE=0\n.811\n.301\n.510\n.600\nE=1BA\n.1\n.4\nB=0\n.91\n.60\nB=1A\n.7\n.2\nC=0\n.31\n.80\nC=1A\n.4\n.6\nP(A)\n1\n0\nA\n.5\n.3\n.1\n.2\nD=0\n.511\n.701\n.910\n.800\nD=1CB\nP(E | A,B)P(D | B,C)\nP(B | A) P(C | A)P(A)\n(c) CPTs\nminimal AND/OR graph may be redundant, for example when the set of solutions rooted at variable Xi is not dependant on the specific value assigned to Xi (this situation is not detectable based on context). This is sometimes termed as “interchangeable values” or “symmetrical values”. As overviewed earlier, Dechter and Mateescu (2007, 2004a) defined the complete minimal AND/OR graph which is an AND/OR graph whose unifiable nodes are all merged, and Dechter and Mateescu (2007) also proved the canonicity for non-weighted graphical models.\nIn this paper we propose to augment the minimal AND/OR search graph with removing redundant variables as is common in OBDD representation as well as adopt notational conventions common in this community. This yields a data structure that we call AND/OR BDD, that exploits decomposition by using AND nodes. We present the extension over multi-valued variables yielding AND/OR MDD or AOMDD and define them for general weighted graphical models. Subsequently we present two algorithms for compiling the canonical AOMDD of a graphical model: the first is search-based, and uses the memory intensive AND/OR graph search to generate the context minimal AND/OR graph, and then reduces it bottom up by applying reduction rules; the second is inferencebased, and uses a Bucket Elimination schedule to combine the AOMDDs of initial functions by APPLY operations (similar to the apply for OBDDs). As we will show, both approaches have the same worst case complexity as the AND/OR graph search with context based caching, and also the same complexity as Bucket Elimination, namely time and space exponential in the treewidth of the problem, O(n kw ∗ ). The benefit of each of these generation schemes will be discussed.\nA\n(a) OBDD\n1 2 k\nA\n… (b) MDD\nFigure 10: Decision diagram nodes (OR)\nA\n… …\n(a) AOBDD\nA\n… … …… 1 2 k\n(b) AOMDD\nFigure 11: Decision diagram nodes (AND/OR)"
    }, {
      "heading" : "4.1 From AND/OR Search Graphs to Decision Diagrams",
      "text" : "An AND/OR search graph G of a graphical model M = 〈X,D,F,⊗〉 represents the set of all possible assignments to the problem variables (all solutions and their costs). In this sense, G can be viewed as representing the function f = ⊗fi∈Ffi that defines the universal equivalent graphical model u(M) (Definition 2). For each full assignment x = (x1, . . . , xn), if x is a solution expressed by the tree tx, then f(x) = w(tx) = ⊗e∈arcs(tx)w(e) (Definition 19); otherwise f(x) = 0 (the assignment is inconsistent). The solution tree tx of a consistent assignment x can be read from G in linear time by following the assignments from the root. If x is inconsistent, then a dead-end is encountered in G when attempting to read the solution tree tx, and f(x) = 0. Therefore, G can be viewed as a decision diagram that determines the values of f for every complete assignment x.\nWe will now see how we can process an AND/OR search graph by reduction rules similar to the case of OBDDs, in order to obtain a representation of minimal size. In the case of OBDDs, a node is labeled with a variable name, for example A, and the low (dotted line) and high (solid line) outgoing arcs capture the restriction of the function to the assignments A = 0 or A = 1. To determine the value of the function, one needs to follow either one or the other (but not both) of the outgoing arcs from A (see Figure 10(a)). The straightforward extension of OBDDs to multi-valued variables (multi-valued decision diagrams, or MDDs) was presented by Srinivasan, Kam, Malik, and Brayton (1990), and the node structure that they use is given in Figure 10(b). Each outgoing arc is associated with one of the k values of variable A.\nIn this paper we generalize the OBDD and MDD representations demonstrated in Figures 10(a) and 10(b) by allowing each outgoing arc to be an AND arc. An AND arc connects a node to a set of nodes, and captures the decomposition of the problem into independent components. The number of AND arcs emanating from a node is two in the case of AOBDDs (Figure 11(a)), or the domain size of the variable in the general case (Figure 11(b)). For a given node A, each of its k AND arcs can connect it to possibly different number of nodes, depending on how the problem decomposes based on each particular assignment of A. The AND arcs are depicted by a shaded sector that connects the outgoing lines corresponding to the independent components.\n… … ……\nA\n1 2 k…\n(a) Nonterminal meta-node\n0\n(b) Terminal meta-node 0\nWe define the AND/OR Decision Diagram representation based on AND/OR search graphs. We find that it is useful to maintain the semantics of Figure 11 especially when we need to express the redundancy of nodes, and therefore we introduce the meta-node data structure, which defines small portions of any AND/OR graph, based on an OR node and its AND children:\nDEFINITION 20 (meta-node) A meta-node u in an AND/OR search graph can be either: (1) a terminal node labeled with 0 or 1, or (2) a nonterminal node, that consists of an OR node labeled X (therefore var(u) = X) and its k AND children labeled x1, . . . , xk that correspond to the value assignments of X . Each AND node labeled xi stores a list of pointers to child meta-nodes, denoted by u.childreni. In the case of weighted graphical models, the AND node xi also stores the OR-toAND arc weight w(X,xi).\nThe rectangle in Figure 12(a) is a meta-node for variable A, that has a domain of size k. Note that this is very similar to Figure 11, with the small difference that the information about the value of A that corresponds to each outgoing AND arc is now stored in the AND nodes of the meta-node. We are not showing the weights in that figure. A larger example of an AND/OR graph with meta-nodes appears later in Figure 16.\nThe terminal meta-nodes play the role of the terminal nodes in OBDDs. The terminal metanode 0, shown in Figure 12(b), indicates inconsistent assignments, while the terminal meta-node 1, shown in figure 12(c) indicates consistent ones.\nAny AND/OR search graph can now be viewed as a diagram of meta-nodes, simply by grouping OR nodes with their AND children, and adding the terminal meta-nodes appropriately.\nOnce we have defined the meta-nodes, it is easier to see when a variable is redundant with respect to the outcome of the function based on the current partial assignment. A variable is redundant if any of its assignments leads to the same set of solutions.\nDEFINITION 21 (redundant meta-node) Given a weighted AND/OR search graph G represented with meta-nodes, a meta-node u with var(u) = X and |D(X)| = k is redundant iff:\n(a) u.children1 = . . . = u.childrenk and (b) w(X,x1) = . . . = w(X,xk).\nAn AND/OR graph G, that contains a redundant meta-node u, can be transformed into an equivalent graph G′ by replacing any incoming arc into u with its common list of children u.children1, absorbing the common weight w(X,x1) by combination into the weight of the parent meta-node corresponding to the incoming arc, and then removing u and its outgoing arcs from G. The value X = x1 is picked here arbitrarily, because they are all isomorphic. If u is the root of the\nProcedure RedundancyReduction input : AND/OR graph G; redundant meta-node u, with var(u) = X; List of meta-node parents of u,\ndenoted by Parents(u). output : Reduced AND/OR graph G after the elimination of u. if Parents(u) is empty then1 return independent AND/OR graphs rooted by meta-nodes in u.children1, and constant w(X,x1)2\nforall v ∈ Parents(u) (assume var(v) == Y ) do3 forall i ∈ {1, . . . , |D(Y )|} do4 if u ∈ v.childreni then5 v.childreni ← v.childreni \\ {u}6 v.childreni ← v.childreni ∪ u.children17 w(Y, yi)← w(Y, yi)⊗ w(X,x1)8\nremove u9\nreturn reduced AND/OR graph G10\nProcedure IsomorphismReduction input : AND/OR graph G; isomorphic meta-nodes u and v; List of meta-node parents of u, denoted by\nParents(u). output : Reduced AND/OR graph G after the merging of u and v. forall p ∈ Parents(u) do1 if u ∈ p.childreni then2 p.childreni ← p.childreni \\ {u}3 p.childreni ← p.childreni ∪ {v}4\nremove u5\nreturn reduced AND/OR graph G6\ngraph, then the common weight w(X,x1) has to be stored separately as a constant. Procedure RedundancyReduction formalizes the redundancy elimination.\nDEFINITION 22 (isomorphic meta-nodes) Given a weighted AND/OR search graph G represented with meta-nodes, two meta-nodes u and v having var(u) = var(v) = X and |D(X)| = k are isomorphic iff:\n(a) u.childreni = v.childreni ∀i ∈ {1, . . . , k} and (b) wu(X,xi) = wv(X,xi) ∀i ∈ {1, . . . , k}, (where wu, wv are the weights of u and v).\nProcedure IsomorphismReduction formalizes the process of merging isomorphic metanodes. Naturally, the AND/OR graph obtained by merging isomorphic meta-nodes is equivalent to the original one. We can now define the AND/OR Multi-Valued Decision Diagram:\nDEFINITION 23 (AOMDD) An AND/OR Multi-Valued Decision Diagram (AOMDD) is a weighted AND/OR search graph that is completely reduced by isomorphic merging and redundancy removal, namely:\n(1) it contains no isomorphic meta-nodes; and (2) it contains no redundant meta-nodes.\nExample 10 Figure 13 shows an example of applying the redundancy reduction rule to a portion of an AOMDD. On the left side, in Figure 13(a), the meta-node of variable B is redundant (we don’t show the weights of the OR-to-AND arcs, to avoid cluttering the figure). Any of the values {1, . . . , k} of B will lead to the same set of meta-nodes {c, d, . . . , y}, which are coupled in an AND arc. Therefore, the meta-node of B can be eliminated. The result is shown in Figure 13(b), where the meta-nodes {c, d, . . . , y} and z are coupled in an AND arc outgoing from A = 1.\nIn Figure 14 we show an example of applying the isomorphism reduction rule. In this case, the meta-nodes labeled with C in Figure 14(a) are isomorphic (again, we omit the weights). The result of merging them is shown in Figure 14(b).\nExamples of AOMDDs appear in Figures 16, 17 and 18. Note that if the weight on an OR-toAND arc is zero, then the descendant is the terminal meta-node 0. Namely, the current path is a dead-end, cannot be extended to a solution, and is therefore linked directly to 0."
    }, {
      "heading" : "5. Using AND/OR Search to Generate AOMDDs",
      "text" : "In Section 4.1 we described how we can transform an AND/OR graph into an AOMDD by applying reduction rules. In Section 5.1 we describe the explicit algorithm that takes as input a graphi-\ncal model, performs AND/OR search with context-based caching to obtain the context minimal AND/OR graph, and in Section 5.2 we give the procedure that applies the reduction rules bottom up to obtain the AOMDD."
    }, {
      "heading" : "5.1 Algorithm AND/OR-SEARCH-AOMDD",
      "text" : "Algorithm 1, called AND/OR-SEARCH-AOMDD, compiles a graphical model into an AOMDD. A memory intensive (with context-based caching) AND/OR search is used to create the context minimal AND/OR graph (see Definition 16). The input to AND/OR-SEARCH-AOMDD is a graphical model M and a pseudo tree T , that also defines the OR-context of each variable.\nEach variable Xi has an associated cache table, whose scope is the context of Xi in T . This ensures that the trace of the search is the context minimal AND/OR graph. A list denoted by LXi (see line 35), is used for each variable Xi to save pointers to meta-nodes labeled with Xi. These lists are used by the procedure that performs the bottom up reduction, per layers of the AND/OR graph (one layer contains all the nodes labeled with one given variable). The fringe of the search is maintained on a stack called OPEN. The current node (either OR or AND node) is denoted by n, its parent by p, and the current path by πn. The children of the current node are denoted by successors(n). For each node n, the Boolean attribute consistent(n) indicates if the current path can be extended to a solution. This information is useful for pruning the search space.\nThe algorithm is based on two mutually recursive steps: Forward (beginning at line 5) and Backtrack (beginning at line 29), which call each other (or themselves) until the search terminates. In the forward phase, the AND/OR graph is expanded top down. The two types of nodes, AND and OR, are treated differently according to their semantics.\nBefore an OR node is expanded, the cache table of its variable is checked (line 8). If the entry is not null, a link is created to the already existing OR node that roots the graph equivalent to the current subproblem. Otherwise, the OR node is expanded by generating its AND descendants. The OR-to-AND weight (see Definition 18) is computed in line 13. Each value xi of Xi is checked for consistency (line 14). The least expensive check is to verify that the OR-to-AND weight is non-zero. However, the deterministic (inconsistent) assignments in M can be extracted to form a constraint network. Any level of constraint propagation can be performed in this step (e.g., look ahead, arc consistency, path consistency, i-consistency etc.). The computational overhead can increase, in the hope of pruning the search space more aggressively. We should note that constraint propagation is not crucial for the algorithm, and the complexity guarantees are maintained even if only the simple weight check is performed. The consistent AND nodes are added to the list of successors of n (line 16), while the inconsistent ones are linked to the terminal 0 meta-node (line 19).\nAn AND node n labeled with 〈Xi, xi〉 is expanded (line 20) based on the structure of the pseudo tree. If Xi is a leaf in T , then n is linked to the terminal 1 meta-node (line 22). Otherwise, an OR node is created for each child of Xi in T (line 24).\nThe forward step continues as long as the current node is not a dead-end and still has unevaluated successors. The backtrack phase is triggered when a node has an empty set of successors (line 29). Note that, as each successor is processed, it is removed from the set of successors in line 42. When the backtrack reaches the root (line 32), the search is complete, the context minimal AND/OR graph is generated, and the Procedure BOTTOMUPREDUCTION is called.\nWhen the backtrack step processes an OR node (line 31), it saves a pointer to it in cache, and also adds a pointer to the corresponding meta-node to the list LXi . The consistent attribute of\nAlgorithm 1: AND/OR SEARCH - AOMDD input :M = 〈X,D,F〉; pseudo tree T rooted at X1; parents pai (OR-context) for every variable Xi. output : AOMDD ofM. forall Xi ∈ X do1\nInitialize context-based cache table CacheXi(pai) with null entries2 Create new OR node t, labeled with Xi; consistent(t)← true; push t on top of OPEN3 while OPEN 6= φ do4 n← top(OPEN); remove n from OPEN // Forward5 successors(n)← φ6 if n is an OR node labeled with Xi then // OR-expand7 if CacheXi(asgn(πn)[pai]) 6= null then8 Connect parent of n to CacheXi(asgn(πn)[pai]) // Use the cached pointer9\nelse10 forall xi ∈ Di do11 Create new AND node t, labeled with 〈Xi, xi〉12 w(X,xi)← ⊗\nf∈BT (Xi) f(asgn(πn)[pai]) 13 if 〈Xi, xi〉 is consistent with πn then // Constraint Propagation14 consistent(t)← true15 add t to successors(n)16 else17 consistent(t)← false18 make terminal 0 the only child of t19\nif n is an AND node labeled with 〈Xi, xi〉 then // AND-expand20 if childrenT (Xi) == φ then21 make terminal 1 the only child of n22 else23 forall Y ∈ childrenT (Xi) do24 Create new OR node t, labeled with Y25 consistent(t)← false26 add t to successors(n)27\nAdd successors(n) to top of OPEN28 while successors(n) == φ do // Backtrack29 let p be the parent of n30 if n is an OR node labeled with Xi then31 if Xi == X1 then // Search is complete32 Call BottomUpReduction procedure // begin reduction to AOMDD33\nCache(asgn(πn)[pai])← n // Save in cache34 Add meta-node of n to the list LXi35 consistent(p)← consistent(p) ∧ consistent(n)36 if consistent(p) == false then // Check if p is dead-end37 remove successors(p) from OPEN38 successors(p)← φ39\nif n is an AND node labeled with 〈Xi, xi〉 then40 consistent(p)← consistent(p) ∨ consistent(n);41\nremove n from successors(p)42 n← p43\nProcedure BottomUpReduction input : A graphical modelM = 〈X,D,F〉; a pseudo tree T of the primal graph, rooted at X1; Context\nminimal AND/OR graph, and lists LXi of meta-nodes for each level Xi. output : AOMDD ofM. Let d = {X1, . . . , Xn} be the depth first traversal ordering of T1 for i← n down to 1 do2 Let H be a hash table, initially empty3 forall meta-nodes n in LXi do4\nif H(Xi, n.children1, . . . , n.childrenki , w n(Xi, x1), . . . , w n(Xki , xki)) returns a meta-node5 p then merge n with p in the AND/OR graph6\nelse if n is redundant then7 eliminate n from the AND/OR graph8 combine its weight with that of the parent9\nelse10 hash n into the table H:11 H(Xi, n.children1, . . . , n.childrenki , w n(Xi, x1), . . . , w n(Xki , xki))← n12\nreturn reduced AND/OR graph13\nthe AND parent p is updated by conjunction with consistent(n). If the AND parent p becomes inconsistent, it is not necessary to check its remaining OR successors (line 38). When the backtrack step processes an AND node (line 40), the consistent attribute of the OR parent p is updated by disjunction with consistent(n).\nThe AND/OR search algorithm usually maintains a value for each node, corresponding to a task that is solved. We did not include values in our description because an AOMDD is just an equivalent representation of the original graphical model M. Any task over M can be solved by a traversal of the AOMDD. It is however up to the user to include more information in the meta-nodes (e.g., number of solutions for a subproblem)."
    }, {
      "heading" : "5.2 Reducing the Context Minimal AND/OR Graph to an AOMDD",
      "text" : "Procedure BottomUpReduction processes the variables bottom up relative to the pseudo tree T . We use the depth first traversal ordering of T (line 1), but any other bottom up ordering is as good. The outer for loop (starting at line 2) goes through each level of the context minimal AND/OR graph (where a level contains all the OR and AND nodes labeled with the same variable, in other words it contains all the meta-nodes of that variable). For efficiency, and to ensure the complexity guarantees that we will prove, a hash table, initially empty, is used for each level. The inner for loop (starting at line 4) goes through all the metanodes of a level, that are also saved (or pointers to them are saved) in the list LXi . For each new meta-node n in the list LXi , in line 5 the hash table H is checked to verify if a node isomorphic with n already exists. If the hash table H already contains a node p corresponding to the hash key (Xi, n.children1, . . . , n.childrenki , w n(Xi, x1), . . . , w n(Xki , xki)), then p and n are isomorphic and should be merged. Otherwise, if the new meta-node n is redundant, then it is eliminated from the AND/OR graph. If none of the previous two conditions is met, then the new meta-node n is hashed into table H .\nProposition 1 The output of Procedure BottomUpReduction is the AOMDD of M along the pseudo tree T , namely the resulting AND/OR graph is completely reduced.\nNote that we explicated Procedure BottomUpReduction separately only for clarity. In practice, it can actually be included in Algorithm AND/OR-SEARCH-AOMDD, and the reduction rules can be applied whenever the search backtracks. We can maintain a hash table for each variable, during the AND/OR search, to store pointers to meta-nodes. When the search backtracks out of an OR node, it can already check the redundancy of that meta-node, and also look up in the hash table to check for isomorphism. Therefore, the reduction of the AND/OR graph can be done during the AND/OR search, and the output will be the AOMDD of M.\nFrom Theorem 3 and Proposition 1 we can conclude:\nTHEOREM 4 Given a graphical model M and a pseudo tree T of its primal graph G, the AOMDD of M corresponding to T has size bounded by O(n kw ∗ T\n(G)) and it can be computed by Algorithm AND/OR-SEARCH-AOMDD in time O(n kw ∗ T\n(G)), where w∗T (G) is the induced width of G over the depth first traversal of T , and k bounds the domain size."
    }, {
      "heading" : "6. Using Bucket Elimination to Generate AOMDDs",
      "text" : "In this section we propose to use a Bucket Elimination (BE) type algorithm to guide the compilation of a graphical model into an AOMDD. The idea is to express the graphical model functions as AOMDDs, and then combine them with APPLY operations based on a BE schedule. The APPLY is very similar to that from OBDDs (Bryant, 1986), but it is adapted to AND/OR search graphs. It takes as input two functions represented as AOMDDs based on the same pseudo tree, and outputs the combination of initial functions, also represented as an AOMDD based on the same pseudo tree. We will describe it in detail in Section 6.2.\nWe will start with an example based on constraint networks. This is easier to understand because the weights on the arcs are all 1 or 0, and therefore are depicted in the figures by solid and dashed lines, respectively.\nExample 11 Consider the network defined by X = {A,B, . . . ,H}, DA = . . . = DH = {0, 1} and the constraints (where ⊕ denotes XOR): C1 = F∨H , C2 = A∨¬H , C3 = A⊕B⊕G, C4 = F∨G,\nC5 = B ∨ F , C6 = A ∨ E, C7 = C ∨ E, C8 = C ⊕ D, C9 = B ∨ C. The constraint graph is shown in Figure 15(a). Consider the ordering d = (A,B,C,D,E, F,G,H). The pseudo tree (or bucket tree) induced by d is given in Fig. 15(b). Figure 16 shows the execution of BE with AOMDDs along ordering d. Initially, the constraints C1 through C9 are represented as AOMDDs and placed in the bucket of their latest variable in d. The scope of any original constraint always appears on a\nAlgorithm 2: BE-AOMDD input : Graphical modelM = 〈X,D,F〉, where X = {X1, . . . , Xn}, F = {f1, . . . , fr} ; order\nd = (X1, . . . , Xn) output : AOMDD representing ⊗i∈Ffi T = GeneratePseudoTree(G, d);1 for i← 1 to r do // place functions in buckets2 place Gaomddfi in the bucket of its latest variable in d3 for i← n down to 1 do // process buckets4 message(Xi)← G aomdd 1 // initialize with AOMDD of 1 ;5 while bucket(Xi) 6= φ do // combine AOMDDs in bucket of Xi6 pick Gaomddf from bucket(Xi);7 bucket(Xi)← bucket(Xi) \\ {G aomdd f };8 message(Xi)← APPLY(message(Xi),G aomdd f )9\nadd message(Xi) to the bucket of the parent of Xi in T10\nreturn message(X1)11\npath from root to a leaf in the pseudo tree. Therefore, each original constraint is represented by an AOMDD based on a chain (i.e., there is no branching into independent components at any point). The chain is just the scope of the constraint, ordered according to d. For bi-valued variables, the original constraints are represented by OBDDs, for multiple-valued variables they are MDDs. Note that we depict meta-nodes: one OR node and its two AND children, that appear inside each gray node. The dotted edge corresponds to the 0 value (the low edge in OBDDs), the solid edge to the 1 value (the high edge). We have some redundancy in our notation, keeping both AND value nodes and arc-types (dotted arcs from “0” and solid arcs from “1”).\nThe BE scheduling is used to process the buckets in reverse order of d. A bucket is processed by joining all the AOMDDs inside it, using the APPLY operator. However, the step of elimination of the bucket variable is omitted because we want to generate the full AOMDD. In our example, the messages m1 = C1 ./ C2 and m2 = C3 ./ C4 are still based on chains, therefore they are OBDDs. Note that they contain the variables H and G, which have not been eliminated. However, the message m3 = C5 ./ m1 ./ m2 is not an OBDD anymore. We can see that it follows the structure of the pseudo tree, where F has two children, G and H . Some of the nodes corresponding to F have two outgoing edges for value 1.\nThe processing continues in the same manner. The final output of the algorithm, which coincides with m7, is shown in Figure 17(a). The OBDD based on the same ordering d is shown in Fig. 17(b). Notice that the AOMDD has 18 nonterminal nodes and 47 edges, while the OBDD has 27 nonterminal nodes and 54 edges."
    }, {
      "heading" : "6.1 Algorithm BE-AOMDD",
      "text" : "Algorithm 2, called BE-AOMDD, creates the AOMDD of a graphical model by using a BE schedule for APPLY operations. Given an order d of the variables, first a pseudo tree is created based on the primal graph. Each initial function fi is then represented as an AOMDD, denoted by Gaomddfi , and placed in its bucket. To obtain the AOMDD of a function, the scope of the function is ordered according to d, a search tree (based on a chain) that represents fi is generated, and then reduced by Procedure BottomUpReduction. The algorithm proceeds exactly like BE, with the only difference that the combination of functions is realized by the APPLY algorithm, and variables are not\neliminated but carried over to the destination bucket. The messages between buckets are initialized with the dummy AOMDD of 1, denoted by Gaomdd\n1 , which is neutral for combination.\nIn order to create the compilation of a graphical model based on AND/OR graphs, it is necessary to traverse the AND/OR graph top down and bottom up. This is similar to the inward and outward message passing in a tree decomposition. Note that BE-AOMDD describes the bottom up traversal explicitly, while the top down phase is actually performed by the APPLY operation. When two AOMDDs are combined, after the top chain portion of their pseudo tree is processed, the remaining independent branches are attached only if they participate in the newly restricted set of solutions. This amounts to an exchange of information between the independent branches, which is equivalent to the top down phase.\n6.2 The AOMDD APPLY Operation\nWe will now describe how to combine two AOMDDs. The APPLY operator takes as input two AOMDDs representing functions f1 and f2 and returns an AOMDD representing f1 ⊗ f2.\nIn OBDDs the apply operator combines two input diagrams based on the same variable ordering. Likewise, in order to combine two AOMDDs we assume that their pseudo trees are identical. This condition is satisfied by any two AOMDDs in the same bucket of BE-AOMDD. However, we present here a version of APPLY that is more general, by relaxing the previous condition from identical to compatible pseudo trees. Namely, there should be a pseudo tree in which both can be embedded. In general, a pseudo tree induces a strict partial order between the variables where a parent node always precedes its child nodes.\nDEFINITION 24 (compatible pseudo trees) A strict partial order d1 = (X, <1) over a set X is consistent with a strict partial order d2 = (Y, <2) over a set Y, if for all x1, x2 ∈ X ∩ Y, if x1 <2 x2 then x1 <1 x2. Two partial orders d1 and d2 are compatible iff there exists a partial order d that is consistent with both. Two pseudo trees are compatible iff the partial orders induced via the parent-child relationship, are compatible.\nFor simplicity, we focus on a more restricted notion of compatibility, which is sufficient when using a BE like schedule for the APPLY operator to combine the input AOMDDs (as described in Section 6). The APPLY algorithm that we will present can be extended to the more general notion of compatibility.\nDEFINITION 25 (strictly compatible pseudo trees) A pseudo tree T1 having the set of nodes X1 can be embedded in a pseudo tree T having the set of nodes X if X1 ⊆ X and T1 can be obtained from T by deleting each node in X \\ X1 and connecting its parent to each of its descendents. Two pseudo trees T1 and T2 are strictly compatible if there exists T such that both T1 and T2 can be embedded in T .\nAlgorithm APPLY (algorithm 3) takes as input one node from Gaomddf and a list of nodes from\nGaomddg . Initially, the node from G aomdd f is its root node, and the list of nodes from G aomdd g is in fact also made of just one node, which is its root. We will sometimes identify an AOMDD by its root node. The pseudo trees Tf and Tg are strictly compatible, having a target pseudo tree T .\nThe list of nodes from Gaomddg always has a special property: there is no node in it that can be the ancestor in T of another (we refer to the variable of the meta-node). Therefore, the list z1, . . . , zm\nAlgorithm 3: APPLY(v1; z1, . . . , zm) input : AOMDDs Gaomddf with nodes vi and G aomdd g with nodes zj , based on strictly compatible pseudo\ntrees Tf , Tg that can be embedded in T . var(v1) is an ancestor of all var(z1), . . . , var(zm) in T . var(zi) and var(zj) are not in ancestor-descendant relation in T , ∀i 6= j.\noutput : v1 ⊗ (z1 ∧ . . . ∧ zm), based on T . if H1(v1, z1, . . . , zm) 6= null then return H1(v1, z1, . . . , zm); // is in cache1 if (any of v1, z1, . . . , zm is 0) then return 02 if (v1 = 1) then return 13 if (m = 0) then return v1 // nothing to combine4 create new nonterminal meta-node u5 var(u)← var(v1) (call it Xi, with domain Di = {x1, . . . , xki} )6 for j ← 1 to ki do7 u.childrenj ← φ // children of the j-th AND node of u8 wu(Xi, xj)← w\nv1(Xi, xj) // assign weight from v19 if ( (m = 1) and (var(v1) = var(z1) = Xi) ) then10 tempChildren← z1.childrenj11 wu(Xi, xj)← w v1(Xi, xj)⊗ w z1(Xi, xj) // combine input weights12\nelse13 tempChildren← {z1, . . . , zm}14 group nodes from v1.childrenj ∪ tempChildren in several {v1; z1, . . . , zr}15 for each {v1; z1, . . . , zr} do16 y ← APPLY(v1; z1, . . . , zr)17 if (y = 0) then18 u.childrenj ← 0; break19\nelse20 u.childrenj ← u.childrenj ∪ {y}21\nif (u.children1 = . . . = u.childrenki ) and (w u(Xi, x1) = . . . = w u(Xi, xki)) then22 promote wu(Xi, x1) to parent23 return u.children1 // redundancy24\nif (H2(Xi, u.children1, . . . , u.childrenki , w u(Xi, x1), . . . , w u(Xki , xki)) 6= null) then25 return H2(Xi, u.children1, . . . , u.childrenki , w u(Xi, x1), . . . , w u(Xki , xki))26\n// isomorphism\nLet H1(v1, z1, . . . , zm) = u // add u to H127 Let H2(Xi, u.children1, . . . , u.childrenki , w u(Xi, x1), . . . , w u(Xki , xki)) = u // add u to H228 return u29\nfrom g expresses a decomposition with respect to T , so all those nodes appear on different branches. We will employ the usual techniques from OBDDs to make the operation efficient. First, if one of the arguments is 0, then we can safely return 0. Second, a hash table H1 is used to store the nodes that have already been processed, based on the nodes (v1, z1, . . . , zr). Therefore, we never need to make multiple recursive calls on the same arguments. Third, a hash table H2 is used to detect isomorphic nodes. This is typically split in separate tables for each variable. If at the end of the recursion, before returning a value, we discover that a meta-node with the same variable, the same children and the same weights has already been created, then we don’t need to store it and we simply return the existing node. And fourth, if at the end of the recursion we discover that we created a redundant node (all the children are the same and all the weights are the same), then we don’t store it, and return instead one of its identical lists of children, and promote the common weight.\nNote that v1 is always an ancestor of all z1, . . . , zm in T . We consider a variable in T to be an ancestor of itself. A few self explaining checks are performed in lines 1-4. Line 2 is specific for multiplication, and needs to be changed for other combination operations. The algorithm creates a new meta-node u, whose variable is var(v1) = Xi – recall that var(v1) is highest (closest to root) in T among v1, z1, . . . , zm. Then, for each possible value of Xi, line 7, it starts building its list of children.\nOne of the important steps happens in line 15. There are two lists of meta-nodes, one from each original AOMDD f and g, and we will refer only to their variables, as they appear in T . Each of these lists has the important property mentioned above, that its nodes are not ancestors of each other. The union of the two lists is grouped into maximal sets of nodes, such that the highest node in each set is an ancestor of all the others. It follows that the root node in each set belongs to one of the original AOMDD, say v1 is from f , and the others, say z1, . . . , zr are from g. As an example, suppose T is the pseudo tree from Fig. 15(b), and the two lists are {C,G,H} from f and {E,F} from g. The grouping from line 15 will create {C;E} and {F ;G,H}. Sometimes, it may be the case that a newly created group contains only one node. This means there is nothing more to join in recursive calls, so the algorithm will return, via line 4, the single node. From there on, only one of the input AOMDDs is traversed, and this is important for the complexity of APPLY, discussed below.\nExample 12 Figure 18 shows the result of combining two Boolean functions by an AND operation (or product). The input functions f and g are represented by AOMDDs based on chain pseudo trees, while the results is based on the pseudo tree that expresses the decomposition after variables A and B are instantiated. The APPLY operator performs a depth first traversal of the two input AOMDDs, and generates the resulting AOMDD based on the output pseudo tree. Similar to the case of OBDDs, a function or an AOMDD can be identified by its root meta-node. In this example the input meta-nodes have labels (A1, A2, B1, B2, etc.). The output meta-node labeled by A2B2 is\nthe root of a diagram that represents the function obtained by combining the functions rooted by A2 and B2."
    }, {
      "heading" : "6.3 Complexity of APPLY and BE-AOMDD",
      "text" : "We now provide a characterization of the complexity of APPLY, based on different criteria. The following propositions are inspired by the results that govern OBDD apply complexity, but are adapted for pseudo tree orderings.\nAn AOMDD along a pseudo tree can be regarded as a union of regular MDDs, each restricted to a full path from root to a leaf in the pseudo tree. Let πT be such a path in T . Based on the definition of strictly compatible pseudo trees, πT has corresponding paths πTf in Tf and πTg in Tg. The MDDs from f and g corresponding to πTf and πTg can be combined using the regular MDD apply. This process can be repeated for every path πT . The resulting MDDs, one for each path in T need to be synchronized on their common parts (on the intersection of the paths). The algorithm we proposed does all this processing at once, in a depth first search traversal over the inputs. Based on our construction, we can give a first characterization of the complexity of AOMDD APPLY as being governed by the complexity of MDD apply.\nProposition 2 Let π1, . . . , πl be the set of paths in T enumerated from left to right and let Gif and Gig be the MDDs restricted to path πi, then the size of the output of AOMDD apply is bounded by ∑\ni |G i f | · |G i g| ≤ n · maxi|G i f | · |G i g|. The time complexity is also bounded by\n∑\ni |G i f | · |G i g| ≤\nn ·maxi|G i f | · |G i g|.\nA second characterization of the complexity can be given, similar to the MDD case, in terms of total number of nodes of the inputs:\nProposition 3 Given two AOMDDs Gaomddf and G aomdd g based on strictly compatible pseudo trees, the size of the output of APPLY is at most O(| Gaomddf | · | G aomdd g |).\nWe can further detail the previous proposition as follows. Given AOMDDs Gaomddf and G aomdd g , based on compatible pseudo trees Tf and Tg and the common pseudo tree T , we define the intersection pseudo tree Tf∩g as being obtained from T by the following two steps: (1) mark all the subtrees whose nodes belong to either Tf or Tg but not to both (the leaves of each subtree should be leaves in T ); (2) remove the subtrees marked in step (1) from T . Steps (1) and (2) are applied just once (that is, not recursively). The part of AOMDD Gaomddf corresponding to the variables in Tf∩g is denoted by Gf∩gf , and similarly for G aomdd g it is denoted by G f∩g g .\nProposition 4 The time complexity of APPLY and the size of the output are O(|Gf∩gf | · |G f∩g g | + |Gaomddf | + |G aomdd g |).\nWe now turn to the complexity of the BE-AOMDD algorithm. Each bucket has an associated bucket pseudo tree. The top chain of the bucket pseudo tree for variable Xi contains all and only the variables in context(Xi). For any other variables that appear in the bucket pseudo tree, their associated buckets have already been processed. The original functions that belong to the bucket of Xi have their scope included in context(Xi), and therefore their associated AOMDDs are based\non chains. Any other functions that appear in bucket of Xi are messages received from independent branches below. Therefore, any two functions in the bucket of Xi only share variables in the context(Xi), which forms the top chain of the bucket pseudo tree. We can therefore characterize the complexity of APPLY in terms of treewidth, or context size of a bucket variable.\nProposition 5 Given two AOMDDs in the same bucket of BE-AOMDD, the time and space complexity of the APPLY between them is at most exponential in the context size of the bucket variable (namely the number of the variables in the top chain of the bucket pseudo tree).\nWe can now bound the complexity of BE-AOMDD and the output size:\nTHEOREM 5 The space complexity of BE-AOMDD and the size of the output AOMDD are O(n kw ∗\n), where n is the number of variables, k is the maximum domain size and w∗ is the treewidth of the bucket tree. The time complexity is bounded by O(r kw ∗\n), where r is the number of initial functions."
    }, {
      "heading" : "7. AOMDDs Are Canonical Representations",
      "text" : "It is well known that OBDDs are canonical representations of Boolean functions given an ordering of the variables (Bryant, 1986), namely a strict ordering of any CNF specification of the same Boolean function will yield an identical OBDD, and this property extends to MDDs (Srinivasan et al., 1990). The linear ordering of the variables defines a chain pseudo tree that captures the structure of the OBDD or MDD. In the case of AOBDDs and AOMDDs, the canonicity is with respect to a pseudo tree, transitioning from total orders (that correspond to a linear ordering) to partial orders (that correspond to a pseudo tree ordering). On the one hand we gain the ability to have a more compact compiled structure, but on the other hand canonicity is no longer with respect to all equivalent graphical models, but only relative to those graphical models that are consistent with the pseudo tree that is used. Specifically, if we start from a strict ordering we can generate a chain AOMDD that will be canonical relative to all equivalent graphical models. If however we want to exploit additional decomposition we can use a partial ordering captured by a pseudo-tree and create a more compact AOMDD. This AOMDD however is canonical relative to those equivalent graphical models that can accept the same pseudo tree that guided the AOMDD. In general, AOMDD can be viewed as a more flexible framework for compilation that allows both partial and total orderings. Canonicity is restricted to a subset of graphical models whose primal graph agrees with the partial order but it is relevant to a larger set of orderings which are consistent with the pseudo-tree.\nIn the following subsection we discuss the canonicity of AOMDD for constraint networks. The case of general weighted graphical models is discussed in Section 8."
    }, {
      "heading" : "7.1 AOMDDs for Constraint Networks Are Canonical Representations",
      "text" : "The case of constraint networks is more straightforward, because the weights on the OR-to-AND arcs can only be 0 or 1. We will show that any equivalent constraint networks, that admit the same pseudo tree T , have the same AOMDD based on T . We start with a proposition that will help prove the main theorem.\nProposition 6 Let f be a function, not always zero, defined by a constraint network over X. Given a partition {X1, . . . ,Xm} of the set of variables X (namely, Xi ∩ Xj = φ,∀ i 6= j, and X =\n∪mi=1X i), if f = f1 ⊗ . . .⊗ fm and f = g1 ⊗ . . .⊗ gm, such that scope(fi) = scope(gi) = Xi for all i ∈ {1, . . . ,m}, then fi = gi for all i ∈ {1, . . . ,m}. Namely, if f can be decomposed over the given partition, then the decomposition is unique.\nWe are now ready to show that AOMDDs for constraint networks are canonical representations given a pseudo tree.\nTHEOREM 6 (AOMDDs are canonical for a given pseudo tree) Given a constraint network, and a pseudo tree T of its constraint graph, there is a unique (up to isomorphism) AOMDD that represents it, and it has the minimal number of meta-nodes.\nA constraint network is defined by its relations (or functions). There exist equivalent constraint networks that are defined by different sets of functions, even having different scope signatures. However, equivalent constraint networks define the same function, and we can ask if the AOMDD of different equivalent constraint networks is the same. The following corollary can be derived immediately from Theorem 6.\nCorollary 1 Two equivalent constraint networks that admit the same pseudo tree T have the same AOMDD based on T ."
    }, {
      "heading" : "8. Canonical AOMDDs for Weighted Graphical Models",
      "text" : "Theorem 6 ensures that the AOMDD is canonical for constraint networks, namely for functions that can only take the values 0 or 1. The proof relied on the fact that the OR-to-AND weights can only be 0 or 1, and on Proposition 6 that ensured the unique decomposition of a function defined by a constraint network.\nIn this section we turn to general weighted graphical models. We can first observe that Proposition 6 is no longer valid for general functions. This is because the valid solutions (having strictly positive weight) can have their weight decomposed in more than one way into a product of positive weights.\nTherefore we raise the issue of recognizing nodes that root AND/OR graphs that represent the same universal function, even though the graphical representation is different. We will see that the AOMDD for a weighted graphical model is not unique under the current definitions, but we can slightly modify them to obtain canonicity again. We have to note that canonicity of AOMDDs for weighted graphical models (e.g., belief networks) is far less crucial than in the case of OBDDs that are used in formal verification. Even more than that, sometimes it may be useful not to eliminate the redundant nodes, in order to maintain a simpler semantics of the AND/OR graph that represents the model.\nThe loss of canonicity of AOMDD for weighted graphical models can happen because of the weights on the OR-to-AND arcs, and we suggest a possible way of re-enforcing it if a more compact and canonical representation is needed.\nExample 13 Figure 19 shows a weighted graphical model, defined by two (cost) functions, f(M,A,B) and g(M,B,C). Assuming the order (M,A,B,C), Figure 20 shows the AND/OR search tree on the left. The arcs are labeled with function values, and the leaves show the value of the corresponding full assignment (which is the product of numbers on the arcs of the path). We can\nsee that either value of M (0 or 1) gives rise to the same function (because the leaves in the two subtrees have the same values). However, the two subtrees can not be identified as representing the same function by the usual reduction rules. The right part of the figure shows the context minimal graph, which has a compact representation of each subtree, but does not share any of their parts.\nWhat we would like in this case is to have a method of recognizing that the left and right subtrees corresponding to M = 0 and M = 1 represent the same function. We can do this by normalizing the values in each level, and processing bottom up. In Figure 21 left, the values on the OR-to-AND arcs have been normalized, for each OR variable, and the normalization constant was promoted up to the OR value. In Figure 21 right, the normalization constants are promoted upwards again by multiplication. This process does not change the value of each full assignment, and therefore produces equivalent graphs.\nWe can see already that some of the nodes labeled by C can now be merged, producing the graph in Figure 22 on the left. Continuing the same process we obtain the AOMDD for the weighted graph, shown in Figure 22 on the right.\nWe can define the AOMDD of a weighted graphical model as follows:\nDEFINITION 26 (AOMDD of weighted graphical model) The AOMDD of a weighted graphical model is an AND/OR graph, with meta-nodes, such that: (1) for each meta-node, its weights sum to 1; (2) the root meta-node has a constant associated with it; (3) it is completely reduced, namely it has no isomorphic meta-nodes, and no redundant meta-nodes.\nThe procedure of transforming a weighted AND/OR graph into an AOMDD is very similar to Procedure BOTTOMUPREDUCTION from Section 5. The only difference is that when a new layer is processed, first the meta-node weights are normalized and promoted to the parent, and then the procedure continues as usual with the reduction rules.\nTHEOREM 7 Given two equivalent weighted graphical models that accept a common pseudo tree T , normalizing arc values together with exhaustive application of reduction rules yields the same AND/OR graph, which is the AOMDD based on T .\nFinite Precision Arithmetic The implementation of the algorithm described in this section may prove to be challenging on machines that used finite precision arithmetic. Since the weights are real-valued, the repeated normalization may lead to precision errors. One possible approach, which we also used in our experiments, is to define some ε-tolerance, for some user defined sufficiently small ε, and consider the weights to be equal if they are within ε of each other."
    }, {
      "heading" : "9. Semantic Treewidth",
      "text" : "A graphical model M represents a universal function F = ⊗fi. The function F may be represented by different graphical models. Given a particular pseudo tree T , that captures some of the structural information of F , we are interested in all the graphical models that accept T as a pseudo tree, namely their primal graphs only contain edges that are backarcs in T . Since the size of the AOMDD for F based on T is bounded in the worst case by the induced width of the graphical model along T , we define the semantic treewidth to be:\nDEFINITION 27 (semantic treewidth) The semantic treewidth of a graphical model M relative to a pseudo tree T denoted by swT (M), is the smallest treewidth taken over all models R that are equivalent to M, and accept the pseudo tree T . Formally, it is defined by swT (M) = minR,u(R)=u(M)wT (R), where u(M) is the universal function of M, and wT (R) is the induced width of R along T . The semantic treewidth of a graphical model, M, is the minimal semantic treewidth over all the pseudo trees that can express its universal function.\nComputing the semantic treewidth can be shown to be NP-hard.3\nTHEOREM 8 Computing the semantic treewidth of a graphical model M is NP-hard.\nTheorem 8 shows that computing the semantic treewidth is hard, and it is likely that the actual complexity is even higher. However, the semantic treewidth can explain why sometimes the minimal AND/OR graph or OBDD are much smaller than the exponential in treewidth or pathwidth upper bounds. In many cases, there could be a huge disparity between the treewidth of M and the semantic treewidth along T .\nExample 14 Figure 23(a) shows the two solutions of the 4-queen problem. The problem is expressed by a complete graph of treewidth 3, given in Figure 23(b). Figure 23(c) shows an equivalent problem (i.e., that has the same set of solutions), which has treewidth 1. The semantic treewidth of the 4-queen problem is 1.\nBased on the fact that an AOMDD is a canonical representation of the universal function of a graphical model, we can conclude that the size of the AOMDD is bounded exponentially by the semantic treewidth along the pseudo tree, rather than the treewidth of the given graphical model representation.\nProposition 7 The size of the AOMDD of a graphical model M is bounded by O(n kswT (M)), where n is the number of variables, k is the maximum domain size and swT (M) is the semantic treewidth of M along the pseudo tree T .\n3. We thank David Eppstein for the proof.\nExample 15 Consider a constraint network on n variables such that every two variables are constrained by equality (X = Y ). One graph representation is a complete graph, another is a chain and another is a tree. If the problem is specified as a complete graph, and if we use a linear order, the OBDD will have a linear size because there exists a representation having a pathwidth of 1 (rather than n).\nWhile the semantic treewidth can yield a much better upper bound on the AOMDD, it can also be a very bad bound. It is well known that the parity function on n variables has a very compact, chain-like OBDD representation. Yet, the only constraint network representation of a parity function is the function itself (namely a complete graph on all the variables), whose treewidth and semantic treewidth is its number of variables, n. The OBDD representation of the parity function suggests that the addition of hidden variables can simplify its presentation. We show an example in Figure 24. On the left side, in Figure 24(a) we have the OBDD representation of the parity function for four binary variables. A graphical model would represent this function by a complete graph on the four variables. However, we could add the extra variables M,N and P in Figure 24(b), sometimes called “hidden” variables, that can help decompose the model. In this case M can form a constraint together with A and B such that M represents the parity of A and B, namely M = 1 if A⊕B = 1, where ⊕ is the parity (XOR) operator. Similarly, N would capture the parity of M and C, and P would capture the parity of N and D, and would also give the parity of the initial four variables. The two structures are surprisingly similar. It would be interesting to study further the connection between hidden variables and compact AOBDDs, but we leave this for future work."
    }, {
      "heading" : "10. Experimental Evaluation",
      "text" : "Our experimental evaluation is in preliminary stages, but the results we have are already encouraging. We ran the search-based compile algorithm, by recording the trace of the AND/OR search, and then reducing the resulting AND/OR graph bottom up. In these results we only applied the reduction by isomorphism and still kept the redundant meta-nodes. We implemented our algorithms in C++ and ran all experiments on a 2.2GHz Intel Core 2 Duo with 2GB of RAM, running Windows."
    }, {
      "heading" : "10.1 Benchmarks",
      "text" : "We tested the performance of the search-based compilation algorithm on random Bayesian networks, instances from the Bayesian Network Repository and a subset of networks from the UAI’06 Inference Evaluation Dataset.\nRandom Bayesian Networks The random Bayesian networks were generated using parameters (n, k, c, p), where n is the number of variables, k is the domain size, c is the number of conditional probability tables (CPTs) and p is the number of parents in each CPT. The structure of the network was created by randomly picking c variables out of n and, for each, randomly picking p parents from their preceding variables, relative to some ordering. The remaining n − c variables are called root nodes. The entries of each probability table were generated randomly using a uniform distribution, and the table was then normalized. It is also possible to control the amount of determinism in the network by forcing a percentage det of the CPTs to have only 0 and 1 entries.\nBayesian Network Repository The Bayesian Network Repository4 contains a collection of belief networks extracted from various real-life domains which are often used for benchmarking probabilistic inference algorithms.\nUAI’06 Inference Evaluation Dataset The UAI 2006 Inference Evaluation Dataset5 contains a collection of random as well as real-world belief networks that were used during the first UAI 2006 Inference Evaluation contest. For our purpose we selected a subset of networks which were derived from the ISCAS’89 digital circuits benchmark.6 ISCAS’89 circuits are a common benchmark used in formal verification and diagnosis. Each of these circuits was converted into a Bayesian network by removing flip-flops and buffers in a standard way, creating a deterministic conditional probability table for each gate, and putting uniform distributions on the input signals."
    }, {
      "heading" : "10.2 Algorithms",
      "text" : "We consider two search-based compilation algorithms, denoted by AOMDD-BCP and AOMDDSAT, respectively, that reduce the context minimal AND/OR graph explored via isomorphism, while exploiting the determinism (if any) present in the network. The approach we take for handling the determinism is based on unit resolution over a CNF encoding (i.e., propositional clauses) of the zero probability tuples of the CPTs. The idea of using unit resolution during search for Bayesian networks was first explored by Allen and Darwiche (2003). AOMDD-BCP is conservative and applies only unit resolution at each node in the search graph, whereas AOMDD-SAT is more aggressive and detects inconsistency by running a full SAT solver. We used the zChaff SAT solver (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001) for both unit resolution as well as full satisfiability. For comparison, we also ran an OR version of AOMDD-BCP, called MDD-BCP.\nFor reference we also report results obtained with the ACE7 compiler. ACE compiles a Bayesian network into an Arithmetic Circuit (AC) and then uses the AC to answer multiple queries with respect to the network. An arithmetic circuit is a representation that is equivalent to AND/OR graphs (Mateescu & Dechter, 2007). Each time ACE compiler is invoked, it uses one of two algorithms as the basis for compilation. First, if an elimination order can be generated for the network having\n4. http://www.cs.huji.ac.il/compbio/Repository/ 5. http://ssli.ee.washington.edu/bilmes/uai06InferenceEvaluation 6. Available at: http://www.fm.vslib.cz/kes/asic/iscas/ 7. Available at: http://reasoning.cs.ucla.edu/ace\nsufficiently small induced width, then tabular variable elimination will be used as the basis. This algorithm is similar to the one discussed by Chavira and Darwiche (2007), but uses tables to represent factors rather than ADDs. If the induced width is large, then logical model counting will be used as the basis. Tabular variable elimination is typically efficient when width is small but cannot handle networks when the width is larger. Logical model counting, on the other hand, incurs more overhead than tabular variable elimination, but can handle many networks having larger treewidth. Both tabular variable elimination and logical model counting produce ACs that exploit local structure, leading to efficient online inference. When logical model counting is invoked, it proceeds by encoding the Bayesian network into a CNF (Chavira & Darwiche, 2005; Chavira, Darwiche, & Jaeger, 2006), simplifying the CNF, compiling the CNF into a d-DNNF, and then extracting the AC from the compiled d-DNNF. A dtree over the CNF clauses drives the compilation step.\nIn all our experiments we report the compilation time in seconds (time), the number of OR nodes in the context minimal graph explored (#cm), the number of meta-nodes of the resulting AOMDD (#meta), as well as the size of the AC compiled by ACE (#nodes). For each network we specify the number of variables (n), domain size (k), induced width (w∗) and pseudo tree depth (h). A ’-’ stands for exceeding the 2GB memory limit by the respective algorithm. The best performance points are highlighted."
    }, {
      "heading" : "10.3 Evaluation on Bayesian Networks",
      "text" : "Table 1 reports the results obtained for experiments with 50 Bayesian networks. The AOMDD compilers as well as ACE used the min-fill heuristic (Kjæaerulff, 1990) to construct the guiding pseudo tree and dtree, respectively."
    }, {
      "heading" : "10.3.1 BAYESIAN NETWORKS REPOSITORY",
      "text" : "We see that ACE is overall the fastest compiler on this domain, outperforming both AOMDD-BCP and AOMDD-SAT with up to several orders of magnitude (e.g., mildew, pigs). However, the diagrams compiled by ACE and AOMDD-BCP (resp. AOMDD-SAT) are comparable in size. In some cases, AOMDD-BCP and AOMDD-SAT were able to compile much smaller diagrams than ACE. For example, the diagram produced by AOMDD-BCP for the mildew network is 13 times smaller than the one compiled by ACE. In principle the output produced by ACE and AOMDD should be similar if both are guided by the same pseudo tree/dtree. Our scheme should be viewed as a compilation alternative which (1) extends decision diagrams and (2) mimics traces of search properties that may make this representation accessible. The OR compiler MDD-BCP was able to compile only 3 out of the 14 test instances, but their sizes were far larger than those produced by AOMDD-BCP. For instance, on the pathfinder network, AOMDD-BCP outputs a decision diagram almost 2 orders of magnitude smaller than MDD-BCP."
    }, {
      "heading" : "10.3.2 UAI’06 DATASET",
      "text" : "For each of the UAI’06 Dataset instances we picked randomly 30 variables and instantiated as evidence. We see that ACE is the best performing compiler on this dataset. AOMDD-BCP is competitive with ACE in terms of compile time only on 9 out the 16 test instances. AOMDD-SAT is able to compile the smallest diagrams for 6 networks only (e.g., BN 47, BN 49, BN 55, BN 57, BN 61, BN 67). As before, the difference in size between the compiled data-structures produces by MDD-BCP and AOMDD-BCP is up to 2 orders of magnitude in favor of the latter."
    }, {
      "heading" : "10.3.3 RANDOM NETWORKS",
      "text" : "The problem instances denoted by r75-1 through r75-10 were generated from a class of random belief networks with parameters (n = 75, k = 2, p = 2, c = 65). Similarly, the instances denoted by r100d25-1 through r100d25-10 belong to a class with parameters (n = 100, k = 2, p = 2, c = 90). In the latter case, det = 25% of the CPTs are deterministic, namely they contain only 0 and 1 probability tuples. These test instances were compiled without any evidence. We see that on this domain AOMDD-BCP/AOMDD-SAT were able to compile the smallest diagrams, which were on average about 2 times smaller than those produced by ACE. However, ACE was again the fastest compiler. Notice that the OR compiler MDD-BCP ran out of memory in all test cases."
    }, {
      "heading" : "10.4 The Impact of Variable Ordering",
      "text" : "As theory dictates, the AOMDD size is influenced by the quality of the guiding pseudo tree. In addition to the min-fill heuristic we also considered the hypergraph heuristic which constructs the pseudo tree by recursively decomposing the dual hypergraph associated with the graphical model. This idea was also explored by Darwiche (2001) for constructing dtrees that guide ACE.\nSince both the min-fill and hypergraph partitioning heuristics are randomized (namely ties are broken randomly), the size of the AOMDD guided by the resulting pseudo tree may vary significantly from one run to the next. Figure 25 displays the AOMDD size using hypergraph and min-fill based pseudo trees for 6 networks selected from Table 1, over 20 independent runs. We also record the average induced width and depth obtained for the pseudo trees (see the header of each plot in Figure 25). We see that the two heuristics do not dominate each other, namely the variance in output size is quite significant in both cases."
    }, {
      "heading" : "10.5 Memory Usage",
      "text" : "Table 2 shows the memory usage (in MBytes) of ACE, AOMDD-BCP and AOMDD-SAT, respectively, on the Bayesian networks from Table 1. We see that in some cases the AOMDD based compilers require far less memory than ACE. For example, on the “mildew” network, both AOMDDBCP and AOMDD-SAT use about 22 MB of memory to compile the AND/OR decision diagram, while ACE requires as much as 218 MB of memory. Moreover, the compiled AOMDD has in this case about one order of magnitude fewer nodes than that constructed by ACE. When comparing the two AND/OR search-based compilers, we observe that on networks with a significant amount of determinism, such as those from the UAI’06 Evaluation dataset, AOMDD-SAT uses on average two times less memory than AOMDD-BCP. The most dramatic savings in memory usage due to the aggressive constraint propagation employed by AOMDD-SAT compared with AOMDD-BCP can be seen on the “BN 67” network. In this case, the difference in memory usage between AOMDD-SAT and AOMDD-BCP is about 2 orders of magnitude in favor of the former."
    }, {
      "heading" : "11. Related Work",
      "text" : "The related work can be viewed along two directions: (1) the work related to the AND/OR search idea for graphical models and (2) the work related to compilation for graphical models that exploits problem structure.\nAn extensive discussion for (1) was provided in the previous work of Dechter and Mateescu (2007). Since this is not the focus of the paper, we just mention that the AND/OR idea was origi-\nnally developed for heuristic search (Nilsson, 1980). As mentioned in the introduction, the AND/OR search for graphical models is based on a pseudo tree that spans the graph of the model, similar to the tree rearrangement of Freuder and Quinn (1985, 1987). The idea was adapted for distributed constraint satisfaction by Collin et al. (1991, 1999) and more recently by Modi et al. (2005), and was also shown to be related to graph-based backjumping (Dechter, 1992). This work was extended by Bayardo and Miranker (1996), Bayardo and Schrag (1997) and more recently applied to optimization tasks by Larrosa et al. (2002). Another version that can be viewed as exploring the AND/OR graphs was presented recently for constraint satisfaction (Terrioux & Jégou, 2003b) and for optimization (Terrioux & Jégou, 2003a). Similar principles were introduced recently for probabilistic inference, in algorithm Recursive Conditioning (Darwiche, 2001) as well as in Value Elimination (Bacchus et al., 2003b, 2003a), and are currently at the core of the most advanced SAT solvers (Sang et al., 2004).\nFor direction (2), there are various lines of related research. The formal verification literature, beginning with the work of Bryant (1986) contains a very large number of papers dedicated to the study of BDDs. However, BDDs are in fact OR structures (the underlying pseudo tree is a chain) and do not take advantage of the problem decomposition in an explicit way. The complexity bounds for OBDDs are based on pathwidth rather than treewidth.\nAs noted earlier, the work of Bertacco and Damiani (1997) on Disjoint Support Decomposition (DSD) is related to AND/OR BDDs in various ways. The main common aspect is that both approaches show how structure decomposition can be exploited in a BDD-like representation. DSD is focused on Boolean functions and can exploit more refined structural information that is inherent to Boolean functions. In contrast, AND/OR BDDs assume only the structure conveyed in the constraint graph, and are therefore more broadly applicable to any constraint expression and also to graphical models in general. They allow a simpler and higher level exposition that yields graphbased bounds on the overall size of the generated AOMDD. The full relationship between these two formalisms should be studied further.\nMcMillan (1994) introduced the BDD trees, along with the operations for combining them. For circuits of bounded tree width, BDD trees have a linear space upper bound of O(|g|2w2 2w ), where |g| is the size of the circuit g (typically linear in the number of variables) and w is the treewidth. This bound hides some very large constants to claim the linear dependence on |g| when w is bounded. However, McMillan maintains that when the input function is a CNF expression BDD-trees have the same bounds as AND/OR BDDs, namely they are exponential in the treewidth only.\nTo sketch just a short comparison between McMillan’s BDD trees and AOMMDs, consider an example where we have a simple pseudo tree with root α, left child β and right child γ. Each of these nodes may stand for a set of variables. In BDD trees, the assignments to β are grouped into equivalence classes according to the cofactors generated by them on the remaining α and γ. For example assignments β1 and β2 are equivalent if they generate the same function on α and γ. The node β can be represented by a BDD whose leaves are the cofactors. The same is done for γ. The node α is then represented by a matrix of BDDs, where each column corresponds to a cofactor of β and each line to a cofactor of γ. By contrast, an AOMDD represents the node α as a BDD whose leaves are the cofactors (the number of distinct functions on β and γ) and then each cofactor is the root of a decomposition (an AND node) between β and γ. Moreover, the representations of β (as descendants of different cofactor of α) are shared as much as possible and the same goes for γ. This is only a high level description, that becomes slightly more complicated when redundant nodes are eliminated, but the idea remains the same.\nThe AND/OR structure restricted to propositional theories is very similar to deterministic decomposable negation normal form (d-DNNF) (Darwiche & Marquis, 2002; Darwiche, 2002). More recently, Huang and Darwiche (2005b) used the trace of the DPLL algorithm to generate an OBDD, and compared with the typical formal verification approach of combining the OBDDs of the input function according to some schedule. The structures that were investigated in that case are still OR. This idea is extended in our present work by the AND/OR search compilation algorithm.\nMcAllester, Collins, and Pereira (2004) introduced the case factor diagrams (CFD), which subsume Markov random fields of bounded tree width and probabilistic context free grammars (PCFG). CFDs are very much related to the AND/OR graphs. The CFDs target the minimal representation, by exploiting decomposition (similar to AND nodes) but also by exploiting context sensitive information and allowing dynamic ordering of variables based on context. CFDs do not eliminate the redundant nodes, and part of the cause is that they use zero suppression. There is no claim about CFDs being canonical forms, and also no description of how to combine two CFDs.\nThere are numerous variants of decision diagrams that are designed to represent integer-valued or real-valued functions. For a comprehensive view we refer the reader to the survey of Drechsler and Sieling (2001). Algebraic decision diagrams (ADDs) (Bahar et al., 1993) provide a compilation for general real-valued rather than Boolean functions. Their main drawback is that their size increases very fast if the number of terminals becomes large. There are several approaches that try to alleviate this problem. However the structure that they capture is still OR, and they do not exploit decomposition. Some alternatives introduce edge values (or weights) that enable more subgraph sharing. Edge-valued binary decision diagrams (EVBDDs) (Lai & Sastry, 1992) use additive weights, and when multiplicative weights are also allowed they are called factored EVBDDs (FEVBDDs) (Tafertshofer & Pedram, 1997). Another type of BDDs called K*BMDs (Drechsler, Becker, & Ruppertz, 1996) also use integer weights, both additive and multiplicative in parallel. ADDs have also been extended to affine ADDs (Sanner & McAllester, 2005), through affine transformations that can achieve more compression. The result was shown to be beneficial for probabilistic inference algorithms, such as tree clustering, but they still do not exploit the AND structure.\nMore recently, independently and in parallel to our work on AND/OR graphs (Dechter & Mateescu, 2004a, 2004b), Fargier and Vilarem (2004) and Fargier and Marquis (2006, 2007) proposed the compilation of CSPs into tree-driven automata, which have many similarities to our work. Their main focus is the transition from linear automata to tree automata (similar to that from OR to AND/OR), and the possible savings for tree-structured networks and hyper-trees of constraints due to decomposition. Their compilation approach is guided by a tree-decomposition while ours is guided by a variable-elimination based algorithms. And it is well known that Bucket Elimination and cluster-tree decomposition are in principle the same (Dechter & Pearl, 1989).\nWilson (2005) extended OBDDs to semi-ring BDDs. The semi-ring treatment is restricted to the OR search spaces, but allows dynamic variable ordering. It is otherwise very similar in aim and scope to our AOMDD. When restricting the AOMDD to OR graphs only, the two are closely related, except that we express BDDs using the Shenoy-Shafer axiomatization that is centered on the two operation of combination and marginalization rather then on the semi-ring formulation. Minimality in the formulation of Wilson (2005) is more general allowing merging nodes having different values and therefore it can capture symmetries (called interchangeability).\nAnother framework very similar to AOMDDs, that we became aware of only recently, is Probabilistic Decision Graphs (PDG) of Jaeger (2004). This work preceded most of the relevant work\nwe discussed above (Fargier & Vilarem, 2004; Wilson, 2005) and went somewhat unnoticed, perhaps due to notational and cultural differences. It is however similar in motivation, framework and proposed algorithms. We believe our AND/OR framework is more accessible. We define the framework over multi-valued domains, provide greater details in algorithms and complexity analysis, make an explicit connection with search frameworks, fully address the issues of canonicity as well as provide an empirical demonstration. In particular, the claim of canonicity for PDGs is similar to the one we make for AOMDDs of weighted models, in that it is relative to the trees (or forests) that can represent the given probability distribution.\nThere is another line of research by Drechsler and his group (e.g. Zuzek, Drechsler, & Thornton, 2000), who use AND/OR graphs for Boolean function representation, that may seem similar to our approach. However, the semantics and purpose of their AND/OR graphs are different. They are constructed based on the technique of recursive learning and are used to perform Boolean reasoning, i.e. to explore the logic consequences of a given assumption based on the structure of the circuit, especially to derive sets of implicants. The meaning of AND and OR in their case is related to the meaning of the gates/functions, while in our case the meaning is not related to the semantic of the functions. The AND/OR enumeration tree that results from a circuit according to Zuzek et al. (2000) is not related to the AND/OR decomposition that we discuss."
    }, {
      "heading" : "12. Conclusion",
      "text" : "We propose the AND/OR multi-valued decision diagram (AOMDD), which emerges from the study of AND/OR search spaces for graphical models (Dechter & Mateescu, 2004a, 2004b; Mateescu & Dechter, 2005; Dechter & Mateescu, 2007) and ordered binary decision diagrams (OBDDs) (Bryant, 1986). This data-structure can be used to compile any graphical model.\nGraphical models algorithms that are search-based and compiled data-structures such as BDDs differ primarily by their choices of time vs. memory. When we move from regular OR search space to an AND/OR search space the spectrum of algorithms available is improved for all time vs. memory decisions. We believe that the AND/OR search space clarifies the available choices and helps guide the user into making an informed selection of the algorithm that would fit best the particular query asked, the specific input function and the available computational resources.\nThe contribution of our work is: (1) We formally describe the AOMDD and prove that it is a canonical representation of a constraint network. (2) We extend the AOMDD to general weighted graphical models. (3) We give a compilation algorithm based on AND/OR search, that saves the trace of a memory intensive search (the context minimal AND/OR graph), and then reduces it in one bottom up pass. (4) We describe the APPLY operator that combines two AOMDDs by an operation and show that its complexity is quadratic in the input, but never worse than exponential in the treewidth. (5) We give a scheduling order for building the AOMDD of a graphical model starting with the AOMDDs of its functions which is based on a Variable Elimination algorithm. This guarantees that the complexity is at most exponential in the induced width (treewidth) along the ordering. (6) We show how AOMDDs relate to various earlier and recent compilation frameworks, providing a unifying perspective for all these methods. (7) We introduce the semantic treewidth, which helps explain why compiled decision diagrams are often much smaller than the worst case bound. Finally, (8) we provide a preliminary empirical demonstration of the power of the current scheme."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was done while Robert Mateescu and Radu Marinescu were at the University of California, Irvine. The authors would like to thank the anonymous reviewers for their constructive suggestions to improve the paper, David Eppstein for a useful discussion of complexity issues, and Lars Otten and Natasha Flerova for comments on the final version of the manuscript. This work was supported by the NSF grants IIS-0412854 and IIS-0713118, and the initial part by the Radcliffe fellowship 2005-2006 (through the partner program), with Harvard undergraduate student John Cobb.\nAppendix\nProof of Proposition 1 Consider the level of variable Xi, and the meta-nodes in the list LXi . After one pass through the meta-nodes in LXi (the inner for loop), there can be no two meta-nodes at the level of Xi in the AND/OR graph that are isomorphic, because they would have been merged in line 6. Also, during the same pass through the meta-nodes in LXi all the redundant meta-nodes in LXi are eliminated in line 8. Processing the meta-nodes in the level of Xi will not create new redundant or isomorphic meta-nodes in the levels that have been processed before. It follows that the resulting AND/OR graph is completely reduced. 2\nProof of Theorem 4 The bound on the size follows directly from Theorem 3. The AOMDD size can only be smaller than the size of the context minimal AND/OR graph, which is bounded by O(n kw ∗ T\n(G)). To prove the time bound, we have to rely on the use of the hash table, and the assumption that an efficient implementation allows an access time that is constant. The time bound of AND/OR-SEARCH-AOMDD is O(n kw ∗ T\n(G)), from Theorem 3, because it takes time linear in the output (we assume here that no constraint propagation is performed during search). Procedure BOTTOMUPREDUCTION (procedure 1) takes time linear in the size of the context minimal AND/OR graph. Therefore, the AOMDD can be computed in time O(n kw ∗ T\n(G)), and the result is the same for the algorithm that performs the reduction during the search. 2\nProof of Proposition 2 The complexity of OBDD (and MDD) apply is known to be quadratic in the input. Namely, the number of nodes in the output is at most the product of number of nodes in the input. Therefore, the number of nodes that can appear along one path in the output AOMDD can be at most the product of the number of nodes in each input, along the same path, |Gif | · |G i g|. Summing over all the paths in T gives the result. 2\nProof of Proposition 3 The argument is identical to the case of MDDs. The recursive calls in APPLY lead to combinations of one node from Gaomddf and one node from G aomdd g (rather than a list of nodes). The number of total possible such combinations is O(| Gaomddf | · | G aomdd g |). 2\nProof of Proposition 4 The recursive calls of APPLY can generate one meta-node in the output for each combination of\nnodes from Gf∩gf and G f∩g g . Let’s look at combinations of nodes from G f∩g f and G aomdd g \\ G f∩g g . The meta-nodes from Gaomddg \\ G f∩g g that can participate in such combinations (let’s call this set A) are only those from levels (of variables) right below Tf∩g. This is because of the mechanics of the recursive calls in APPLY. Whenever a node from f that belongs to Gf∩gf is combined with a node from g that belongs to A, line 15 of APPLY expands the node from f , and the node (or nodes) from A remain the same. This will happen until there are no more nodes from f that can be combined with the node (or nodes) from A, and at that point APPLY will simply copy the remaining portion of its output from Gaomddg . The size of A is therefore proportional to | G f∩g g | (because it is the layer of metanodes immediately below Gf∩gg ). A similar argument is valid for the symmetrical case. And there are no combinations between nodes in Gaomddg \\ G f∩g g and Gaomddg \\ G f∩g g . The bound follows from all these arguments. 2\nProof of Proposition 5 The APPLY operation works by constructing the output AOMDD from root to leaves. It first creates a meta-node for the root variable, and then recursively creates its children metanodes by using APPLY on the corresponding children of the input. The worst case that can happen is when the output is not reduced at all, and a recursive call is made for each possible descendant. This corresponds to an unfolding of the full AND/OR search tree based on the context variables, which is exponential in the context size. When the APPLY finishes the context variables, and arrives at the first branching in the bucket pseudo tree, the remaining branches are independent. Similar to the case of OBDDs, where one function occupies a single place in memory, the APPLY can simply create a link to the corresponding branches of the inputs (this is what happens in line 4 in the APPLY algorithm). Therefore, the time and space complexity is at most exponential in the context size. 2\nProof of Theorem 5 The space complexity is governed by that of BE. Since an AOMDD never requires more space than that of a full exponential table (or a tree), it follows that BE-AOMDD only needs space O(n kw ∗\n). The size of the output AOMDD is also bounded, per layers, by the number of assignments to the context of that layer (namely, by the size of the context minimal AND/OR graph). Therefore, because context size is bounded by treewidth, it follows that the output has size O(n kw ∗\n). The time complexity follows from Proposition 5, and from the fact that the number of functions in a bucket cannot exceed r, the original number of functions. 2\nProof of Proposition 6 It suffices to prove the proposition for m = 2. The general result can then be obtained by induction. It is essential that the function is defined by a constraint network (i.e., the values are only 0 or 1), and that the function takes value 1 at least for one assignment. The value 1 denotes consistent assignments (solutions), while 0 denotes inconsistent assignments. Suppose f = f1⊗f2. Let’s denote by x a full assignment to X, and by x1 and x2 the projection of x over X1 and X2, respectively. We can write x = x1x2 (concatenation of partial assignments). It follows that f(x) = f1(x1) ∗ f2(x2). Therefore, if f(x) = 1, it must be that f1(x1) = 1 and f2(x2) = 1. We claim that for any x1, f1(x\n1) = 1 only if there exists some x2 such that f(x1x2) = 1. Suppose by contradiction that there exist some x1 such that f1(x1) = 1 and f(x1x2) = 0 for any other x2. Since f is not always zero,\nit follows that f2 is not always zero, and therefore there must be some x2 for which f2(x2) = 1. This leads to a contradiction, and therefore the functions f1 and f2 are uniquely defined by f . 2\nProof of Theorem 6 The proof is by structural induction over the depth of the pseudo tree T . It follows the canonicity proofs for OBDDs (Bryant, 1986) and MDDs (Srinivasan et al., 1990), but extends them from linear orderings to tree orderings that capture function decomposition according to the pseudo tree T . The depth of T , along each of its paths from root to a leaf, is actually the size of the dependency set, or the set of variables on which the value of the function depends. Remember that the AOMDD is an AND/OR graph that is completely reduced. We will use the word function, denoted by f , to refer to the universal relation, or its characteristic function, defined by the constraint network.\nAssume the depth of T is 0. This means that the function does not depend on any variable, and must be one of the constants 0 or 1. Suppose the function is the constant 0. Then, it must be that the AOMDD does not contain the terminal meta-node 1, since all the nodes must be reachable along some path, and it would mean that the function can also evaluate to 1. Suppose the AOMDD contains a nonterminal meta-node, say labeled with X , where X can take k different values. It must be that all the k children meta-nodes of X are the terminal meta-node 0. If there are more than one terminal 0, then the AOMDD is not completely reduced. If there is only one 0, it follows that the meta-node labeled with X is redundant. Therefore, from all the above, it follows that the AOMDD representing the constant 0 is made of only the terminal 0. This is unique, and contains the smallest number of nodes. A similar argument applies for the constant 1.\nNow, suppose that the statement of the theorem holds for any constraint network that admits a pseudo tree of depth strictly smaller than p, and that we have a constraint network with a pseudo tree of depth equal to p, where p > 0. Let X be the root of T , having domain {x1, . . . , xk}. We denote by fi, where i ∈ {1, . . . , k}, the functions defined by the restricted constraint network for X = xi, namely fi = f |X=xi . Let Y1, . . . , Ym be the children of X in T . Suppose we have two AOMDDs of f , denoted by G and G′. We will show that these two AND/OR graphs are isomorphic.\nThe functions fi can be decomposed according to the pseudo tree T when the root X is removed. This can in fact be a forest of independent pseudo trees (they do not share any variables), rooted by Y1, . . . , Ym. Based on Proposition 6, there is a unique decomposition fi = f Y1 i ∗ . . . ∗ f Ym i , for all i ∈ {1, . . . , k}. Based on the induction hypothesis, each of the function f Yj i has a unique AOMDD. In the AND/OR graphs G and G′, if we look at the subgraphs descending from X = xi, they both are completely reduced and define the same function, fi, therefore there exists an isomorphic mapping σi between them. Let v be the root metanode of G and v′ the root of G′. We claim that G and G′ are isomorphic according to the following mapping:\nσ(u) =\n{\nv′, if u = v; σi(u), if u is in the subgraph rooted by 〈X,xi〉.\nTo prove this, we have to show that σ is well defined, and that it is an isomorphic mapping. If a meta-node u in G is contained in both subgraphs rooted by 〈X,xi〉 and 〈X,xj〉, Then the AND/OR graphs rooted by σi(u) and σj(u) are isomorphic to the one rooted at u, and therefore to each other. Since G′ is completely reduced, it does not contain isomorphic subgraphs, and therefore σi(u) = σj(u). Therefore σ is well defined.\nWe can now show that σ is a bijection. To show that it is one-to-one, assume two distinct metanodes u1 and u2 in G, with σ(u1) = σ(u2). Then, the subgraphs rooted by u1 and u2 are isomorphic\nto the subgraph rooted by σ(u1), and therefore to each other. Since G is completely reduced, it must be that u1 = u2. The fact that σ is onto and is an isomorphic mapping follows from its definition and from the fact that each σi is onto and the only new node is the root meta-node. Since the AOMDDs only contain one root meta-node (more than one root would lead to the conclusion that the root meta-nodes are isomorphic and should be merged), we conclude that G and G′ are isomorphic.\nFinally, we can show that among all the AND/OR graphs representing f , the AOMDD has minimal number of meta-nodes. Suppose G is an AND/OR graph that represents f , with minimal number of meta-nodes, but without being an AOMDD. Namely, it is not completely reduced. Any reduction rule would transform G into an AND/OR graph with smaller number of meta-nodes, leading to a contradiction. Therefore, G must be the unique AOMDD that represents f . 2\nProof of Corollary 1 The proof of Theorem 6 did not rely on the scopes that define the constraint network. As long as the network admits the decomposition induced by the pseudo tree T , the universal function defined by the constraint network will always have the same AOMDD, and therefore any constraint network equivalent to it that admits T will also have the same AOMDD. 2\nProof of Theorem 7 The constant that is associated with the root is actually the sum of the weights of all solutions. This can be derived from the definition of the weighted AOMDD. The weights of each meta-node are normalized (they sum to 1), therefore the values computed for each OR node by AND/OR search is always 1 (when the task is computing the sum of all solution weights). Therefore, the constant of the weighted AOMDD is always ∑\nx w(x) regardless of the graphical model. We will prove that weighted AOMDDs are canonical for functions that are normalized.\nAssume we have two different weighted AOMDDs, denoted by G1 and G2, for the same normalized function f . Let the root variable be A, with the domain {a1, . . . , ak}. Let x denote a full assignment to all the variables. Similar to the above argument for the root constant, because all the meta-nodes have normalized weights, it follows that w1(A, a1) = w2(A, a1) = ∑\nx|A=a1 f(x).\nThe superscript of w1 and w2 indicates the AOMDD, and the summation is over all possible assignments restricted to A = a1. It follows that the root meta-nodes are identical. For each value of the root variable, the restricted functions represented in G1 and G2 are identical, and we will recursively apply the same argument as above.\nHowever, for the proof to be complete, we have to discuss the case when a restricted function is decomposed into independent functions, according to the pseudo tree. Suppose there are two independent components, rooted by B and C. If one of them is the 0 function, it follows that the entire function is 0. We will prove that the meta-nodes of B in G1 and G2 are identical. If B has only one value b1 extendable to a solution, its weight must be 1 in both meta-nodes, so the meta-nodes are identical. If B has more than one value, suppose without loss of generality that the weights are different for the first value b1, and\nw1(B, b1) > w 2(B, b1). (1)\nSince f 6= 0, there must be a value C = c1 such that B = b1, C = c1 can be extended to a full solution. The sum of the weights of all these possible extensions is\n∑\nx|B=b1,C=c1\nf(x) = w1(B, b1) ∗ w 1(C, c1) = w 2(B, b1) ∗ w 2(C, c1). (2)\nFrom Equations 1 and 2 and the fact that the weight are non-zero, it follows that\nw1(C, c1) < w 2(C, c1). (3)\nFrom Equation 1, the fact that B has more than one value and the fact that the weights of B are normalized, it follows that there should be a value b2 such that\nw1(B, b2) < w 2(B, b2). (4)\nFrom Equations 3 and 4, it follows that\nw1(B, b2) ∗ w 1(C, c1) < w 2(B, b2) ∗ w 2(C, c1). (5)\nHowever, both sides of the Equation 5 represent the sum of weights of all solutions when B = b2, C = c1, namely ∑\nx|B=b2,C=c1 f(x), leading to a contradiction. Therefore, it must be that\nEquation 1 is false. Continuing the same argument for all values of B, it follows that the metanodes of B are identical, and similarly the meta-nodes of C are identical.\nIf the decomposition has more than two components, the same argument applies, when B is the first component and C is a meta-variable that combines all the other components. 2\nProof of Theorem 8 Consider the well known NP-complete problem of 3-COLORING: Given a graph G, is there a 3-coloring of G? Namely, can we color its vertices using only three colors, such that any two adjacent vertices have different colors? We will reduce 3-COLORING to the problem of computing the semantic treewidth of a graphical model. Let H be a graph that is 3-colorable, and has a nontrivial semantic treewidth. It is easy to build examples for H . If G is 3-colorable, then G ∪ H is also 3-colorable and will have a non-trivial semantic treewidth, because adding G will not simplify the task of describing the colorings of H . However, if G is not 3-colorable, then G ∪H is also not 3-colorable, and will have a semantic treewidth of zero. 2\nProof of Proposition 7 Since AOMDDs are canonical representations of graphical models, it follows that the graphical model for which the actual semantic treewidth is realized will have the same AOMDD as M, and therefore the AOMDD is bounded exponentially in the semantic treewidth. 2"
    } ],
    "references" : [ {
      "title" : "Binary decision diagrams",
      "author" : [ "S. Akers" ],
      "venue" : "IEEE Transactions on Computers, C-27(6), 509–516.",
      "citeRegEx" : "Akers,? 1978",
      "shortCiteRegEx" : "Akers",
      "year" : 1978
    }, {
      "title" : "New advances in inference by recursive conditioning",
      "author" : [ "D. Allen", "A. Darwiche" ],
      "venue" : "In Proceedings of the Nineteenth Conference on Uncertainty in Artificial Intelligence",
      "citeRegEx" : "Allen and Darwiche,? \\Q2003\\E",
      "shortCiteRegEx" : "Allen and Darwiche",
      "year" : 2003
    }, {
      "title" : "Algorithms and complexity results for #SAT and Bayesian inference",
      "author" : [ "F. Bacchus", "S. Dalmao", "T. Pitassi" ],
      "venue" : "In Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science",
      "citeRegEx" : "Bacchus et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Bacchus et al\\.",
      "year" : 2003
    }, {
      "title" : "Value elimination: Bayesian inference via backtracking search",
      "author" : [ "F. Bacchus", "S. Dalmao", "T. Pitassi" ],
      "venue" : "In Proceedings of the Nineteenth Conference on Uncertainty in Artificial Intelligence",
      "citeRegEx" : "Bacchus et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Bacchus et al\\.",
      "year" : 2003
    }, {
      "title" : "Algebraic decision diagrams and their applications",
      "author" : [ "R. Bahar", "E. Frohm", "C. Gaona", "G. Hachtel", "E. Macii", "A. Pardo", "F. Somenzi" ],
      "venue" : "In IEEE/ACM International Conference on Computer-Aided Design (ICCAD’93),",
      "citeRegEx" : "Bahar et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Bahar et al\\.",
      "year" : 1993
    }, {
      "title" : "A complexity analysis of space-bound learning algorithms for the constraint satisfaction problem",
      "author" : [ "R. Bayardo", "D. Miranker" ],
      "venue" : "In Proceedings of the Thirteenth National Conference on Artificial Intelligence",
      "citeRegEx" : "Bayardo and Miranker,? \\Q1996\\E",
      "shortCiteRegEx" : "Bayardo and Miranker",
      "year" : 1996
    }, {
      "title" : "Using CSP look-back techniques to solve real world SAT instances",
      "author" : [ "R.J. Bayardo", "R.C. Schrag" ],
      "venue" : "In Proceedings of the Fourteenth National Conference on Artificial Intelligence",
      "citeRegEx" : "Bayardo and Schrag,? \\Q1997\\E",
      "shortCiteRegEx" : "Bayardo and Schrag",
      "year" : 1997
    }, {
      "title" : "The disjunctive decomposition of logic functions",
      "author" : [ "V. Bertacco", "M. Damiani" ],
      "venue" : "In IEEE/ACM International Conference on Computer-Aided Design (ICCAD’97),",
      "citeRegEx" : "Bertacco and Damiani,? \\Q1997\\E",
      "shortCiteRegEx" : "Bertacco and Damiani",
      "year" : 1997
    }, {
      "title" : "Approximating treewidth, pathwidth and minimum elimination tree height",
      "author" : [ "H.L. Bodlaender", "J.R. Gilbert" ],
      "venue" : null,
      "citeRegEx" : "Bodlaender and Gilbert,? \\Q1991\\E",
      "shortCiteRegEx" : "Bodlaender and Gilbert",
      "year" : 1991
    }, {
      "title" : "Graph-based algorithms for Boolean function manipulation",
      "author" : [ "R.E. Bryant" ],
      "venue" : "IEEE Transactions on Computers, 35, 677–691.",
      "citeRegEx" : "Bryant,? 1986",
      "shortCiteRegEx" : "Bryant",
      "year" : 1986
    }, {
      "title" : "A survey on knowledge compilation",
      "author" : [ "M. Cadoli", "F.M. Donini" ],
      "venue" : "AI Communications,",
      "citeRegEx" : "Cadoli and Donini,? \\Q1997\\E",
      "shortCiteRegEx" : "Cadoli and Donini",
      "year" : 1997
    }, {
      "title" : "Compiling Bayesian networks with local structure",
      "author" : [ "M. Chavira", "A. Darwiche" ],
      "venue" : "In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Chavira and Darwiche,? \\Q2005\\E",
      "shortCiteRegEx" : "Chavira and Darwiche",
      "year" : 2005
    }, {
      "title" : "Compiling Bayesian networks using variable elimination",
      "author" : [ "M. Chavira", "A. Darwiche" ],
      "venue" : "In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Chavira and Darwiche,? \\Q2007\\E",
      "shortCiteRegEx" : "Chavira and Darwiche",
      "year" : 2007
    }, {
      "title" : "Compiling relational Bayesian networks for exact inference",
      "author" : [ "M. Chavira", "A. Darwiche", "M. Jaeger" ],
      "venue" : "International Journal of Approximate Reasoning,",
      "citeRegEx" : "Chavira et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Chavira et al\\.",
      "year" : 2006
    }, {
      "title" : "On the feasibility of distributed constraint satisfaction",
      "author" : [ "Z. Collin", "R. Dechter", "S. Katz" ],
      "venue" : "In Proceedings of the Twelfth International Conference of Artificial Intelligence",
      "citeRegEx" : "Collin et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Collin et al\\.",
      "year" : 1991
    }, {
      "title" : "Self-stabilizing distributed constraint satisfaction",
      "author" : [ "Z. Collin", "R. Dechter", "S. Katz" ],
      "venue" : "The Chicago Journal of Theoretical Computer Science,",
      "citeRegEx" : "Collin et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Collin et al\\.",
      "year" : 1999
    }, {
      "title" : "Recursive conditioning",
      "author" : [ "A. Darwiche" ],
      "venue" : "Artificial Intelligence, 125(1-2), 5–41.",
      "citeRegEx" : "Darwiche,? 2001",
      "shortCiteRegEx" : "Darwiche",
      "year" : 2001
    }, {
      "title" : "A logical approach to factoring belief networks",
      "author" : [ "A. Darwiche" ],
      "venue" : "Proceedings of the Eighth International Conference on Principles of Knowledge Representation and Reasoning (KR’02), pp. 409–420.",
      "citeRegEx" : "Darwiche,? 2002",
      "shortCiteRegEx" : "Darwiche",
      "year" : 2002
    }, {
      "title" : "A knowledge compilation map",
      "author" : [ "A. Darwiche", "P. Marquis" ],
      "venue" : "Journal of Artificial Intelligence Research (JAIR),",
      "citeRegEx" : "Darwiche and Marquis,? \\Q2002\\E",
      "shortCiteRegEx" : "Darwiche and Marquis",
      "year" : 2002
    }, {
      "title" : "Constraint networks",
      "author" : [ "R. Dechter" ],
      "venue" : "Encyclopedia of Artificial Intelligence, 276–285.",
      "citeRegEx" : "Dechter,? 1992",
      "shortCiteRegEx" : "Dechter",
      "year" : 1992
    }, {
      "title" : "Bucket elimination: A unifying framework for reasoning",
      "author" : [ "R. Dechter" ],
      "venue" : "Artificial Intelligence, 113, 41–85.",
      "citeRegEx" : "Dechter,? 1999",
      "shortCiteRegEx" : "Dechter",
      "year" : 1999
    }, {
      "title" : "AND/OR search spaces for graphical models",
      "author" : [ "R. Dechter", "R. Mateescu" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Dechter and Mateescu,? \\Q2007\\E",
      "shortCiteRegEx" : "Dechter and Mateescu",
      "year" : 2007
    }, {
      "title" : "Mixtures of deterministic-probabilistic networks and their AND/OR search space",
      "author" : [ "R. Dechter", "R. Mateescu" ],
      "venue" : "In Proceedings of the Twentieth Conference on Uncertainty in Artificial Intelligence",
      "citeRegEx" : "Dechter and Mateescu,? \\Q2004\\E",
      "shortCiteRegEx" : "Dechter and Mateescu",
      "year" : 2004
    }, {
      "title" : "The impact of AND/OR search spaces on constraint satisfaction and counting",
      "author" : [ "R. Dechter", "R. Mateescu" ],
      "venue" : "In Proceedings of the Tenth International Conference on Principles and Practice of Constraint Programming",
      "citeRegEx" : "Dechter and Mateescu,? \\Q2004\\E",
      "shortCiteRegEx" : "Dechter and Mateescu",
      "year" : 2004
    }, {
      "title" : "Tree clustering for constraint networks",
      "author" : [ "R. Dechter", "J. Pearl" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Dechter and Pearl,? \\Q1989\\E",
      "shortCiteRegEx" : "Dechter and Pearl",
      "year" : 1989
    }, {
      "title" : "K*BMDs: A new data structure for verification",
      "author" : [ "R. Drechsler", "B. Becker", "S. Ruppertz" ],
      "venue" : "In Proceedings of the 1996 European conference on Design and Test (ED&TC’96),",
      "citeRegEx" : "Drechsler et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Drechsler et al\\.",
      "year" : 1996
    }, {
      "title" : "Binary decision diagrams in theory and practice",
      "author" : [ "R. Drechsler", "D. Sieling" ],
      "venue" : "International Journal on Software Tools for Technology Transfer (STTT),",
      "citeRegEx" : "Drechsler and Sieling,? \\Q2001\\E",
      "shortCiteRegEx" : "Drechsler and Sieling",
      "year" : 2001
    }, {
      "title" : "On the use of partially ordered decision graphs in knowledge compilation and quantified boolean formulae",
      "author" : [ "H. Fargier", "P. Marquis" ],
      "venue" : "In Proceedings of The Twenty-First National Conference on Artificial Intelligence",
      "citeRegEx" : "Fargier and Marquis,? \\Q2006\\E",
      "shortCiteRegEx" : "Fargier and Marquis",
      "year" : 2006
    }, {
      "title" : "On valued negation normal form formulas",
      "author" : [ "H. Fargier", "P. Marquis" ],
      "venue" : "In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Fargier and Marquis,? \\Q2007\\E",
      "shortCiteRegEx" : "Fargier and Marquis",
      "year" : 2007
    }, {
      "title" : "Compiling CSPs into tree-driven automata for interactive",
      "author" : [ "H. Fargier", "M. Vilarem" ],
      "venue" : "solving. Constraints,",
      "citeRegEx" : "Fargier and Vilarem,? \\Q2004\\E",
      "shortCiteRegEx" : "Fargier and Vilarem",
      "year" : 2004
    }, {
      "title" : "Utility Theory for Decision Making",
      "author" : [ "P.C. Fishburn" ],
      "venue" : "Wiley, NewYork.",
      "citeRegEx" : "Fishburn,? 1970",
      "shortCiteRegEx" : "Fishburn",
      "year" : 1970
    }, {
      "title" : "Taking advantage of stable sets of variables in constraint satisfaction problems",
      "author" : [ "E.C. Freuder", "M.J. Quinn" ],
      "venue" : "In Proceedings of the Ninth International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Freuder and Quinn,? \\Q1985\\E",
      "shortCiteRegEx" : "Freuder and Quinn",
      "year" : 1985
    }, {
      "title" : "The use of lineal spanning trees to represent constraint satisfaction problems",
      "author" : [ "E.C. Freuder", "M.J. Quinn" ],
      "venue" : "Tech. rep. 87-41,",
      "citeRegEx" : "Freuder and Quinn,? \\Q1987\\E",
      "shortCiteRegEx" : "Freuder and Quinn",
      "year" : 1987
    }, {
      "title" : "On compiling system models for faster and more scalable diagnosis",
      "author" : [ "J. Huang", "A. Darwiche" ],
      "venue" : "In Proceedings of the 20th National Conference on Artificial Intelligence",
      "citeRegEx" : "Huang and Darwiche,? \\Q2005\\E",
      "shortCiteRegEx" : "Huang and Darwiche",
      "year" : 2005
    }, {
      "title" : "DPLL with a trace: From SAT to knowledge compilation",
      "author" : [ "J. Huang", "A. Darwiche" ],
      "venue" : "In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Huang and Darwiche,? \\Q2005\\E",
      "shortCiteRegEx" : "Huang and Darwiche",
      "year" : 2005
    }, {
      "title" : "Probabilistic decision graphs - combining verification and AI techniques for probabilistic inference",
      "author" : [ "M. Jaeger" ],
      "venue" : "International Journal of Uncertainty, Fuzziness and KnowledgeBased Systems, 12, 19–42.",
      "citeRegEx" : "Jaeger,? 2004",
      "shortCiteRegEx" : "Jaeger",
      "year" : 2004
    }, {
      "title" : "Unifying cluster-tree decompositions for reasoning in graphical models",
      "author" : [ "K. Kask", "R. Dechter", "J. Larrosa", "A. Dechter" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Kask et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Kask et al\\.",
      "year" : 2005
    }, {
      "title" : "Triangulation of graph-based algorithms giving small total state space",
      "author" : [ "U. Kjæaerulff" ],
      "venue" : "Tech. rep., University of Aalborg, Denmark.",
      "citeRegEx" : "Kjæaerulff,? 1990",
      "shortCiteRegEx" : "Kjæaerulff",
      "year" : 1990
    }, {
      "title" : "Disjoint pattern database heuristics",
      "author" : [ "R. Korf", "A. Felner" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Korf and Felner,? \\Q2002\\E",
      "shortCiteRegEx" : "Korf and Felner",
      "year" : 2002
    }, {
      "title" : "Edge-valued binary decision for multi-level hierarchical verification",
      "author" : [ "Lai", "Y.-T", "S. Sastry" ],
      "venue" : "In Proceedings of the Twenty Nineth Design Automation Conference,",
      "citeRegEx" : "Lai et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Lai et al\\.",
      "year" : 1992
    }, {
      "title" : "Pseudo-tree search with soft constraints",
      "author" : [ "J. Larrosa", "P. Meseguer", "M. Sanchez" ],
      "venue" : "In Proceedings of the European Conference on Artificial Intelligence",
      "citeRegEx" : "Larrosa et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Larrosa et al\\.",
      "year" : 2002
    }, {
      "title" : "Representation of switching circuits by binary-decision programs",
      "author" : [ "C. Lee" ],
      "venue" : "Bell System Technical Journal, 38, 985–999.",
      "citeRegEx" : "Lee,? 1959",
      "shortCiteRegEx" : "Lee",
      "year" : 1959
    }, {
      "title" : "The relationship between AND/OR search and variable elimination",
      "author" : [ "R. Mateescu", "R. Dechter" ],
      "venue" : "In Proceedings of the Twenty First Conference on Uncertainty in Artificial Intelligence",
      "citeRegEx" : "Mateescu and Dechter,? \\Q2005\\E",
      "shortCiteRegEx" : "Mateescu and Dechter",
      "year" : 2005
    }, {
      "title" : "AND/OR multi-valued decision diagrams (AOMDDs) for weighted graphical models",
      "author" : [ "R. Mateescu", "R. Dechter" ],
      "venue" : "In Proceedings of the Twenty Third Conference on Uncertainty in Artificial Intelligence",
      "citeRegEx" : "Mateescu and Dechter,? \\Q2007\\E",
      "shortCiteRegEx" : "Mateescu and Dechter",
      "year" : 2007
    }, {
      "title" : "Case-factor diagrams for structured probabilistic modeling",
      "author" : [ "D. McAllester", "M. Collins", "F. Pereira" ],
      "venue" : "In Proceedings of the Twentieth Conference on Uncertainty in Artificial Intelligence",
      "citeRegEx" : "McAllester et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "McAllester et al\\.",
      "year" : 2004
    }, {
      "title" : "Symbolic Model Checking",
      "author" : [ "K.L. McMillan" ],
      "venue" : "Kluwer Academic.",
      "citeRegEx" : "McMillan,? 1993",
      "shortCiteRegEx" : "McMillan",
      "year" : 1993
    }, {
      "title" : "Hierarchical representation of discrete functions with application to model checking",
      "author" : [ "K.L. McMillan" ],
      "venue" : "Computer Aided Verification, pp. 41–54.",
      "citeRegEx" : "McMillan,? 1994",
      "shortCiteRegEx" : "McMillan",
      "year" : 1994
    }, {
      "title" : "ADOPT: asynchronous distributed constraint optimization with quality guarantees",
      "author" : [ "P.J. Modi", "W. Shen", "M. Tambe", "M. Yokoo" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Modi et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Modi et al\\.",
      "year" : 2005
    }, {
      "title" : "Chaff: Engineering an efficient SAT solver",
      "author" : [ "M. Moskewicz", "C. Madigan", "Y. Zhao", "L. Zhang", "S. Malik" ],
      "venue" : "In Proceedings of the Thirty Eighth Design Automation Conference,",
      "citeRegEx" : "Moskewicz et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Moskewicz et al\\.",
      "year" : 2001
    }, {
      "title" : "Principles of Artificial Intelligence",
      "author" : [ "N.J. Nilsson" ],
      "venue" : "Tioga, Palo Alto, CA.",
      "citeRegEx" : "Nilsson,? 1980",
      "shortCiteRegEx" : "Nilsson",
      "year" : 1980
    }, {
      "title" : "Pruning conformant plans by counting models on compiled d-DNNF representations",
      "author" : [ "H. Palacios", "B. Bonet", "A. Darwiche", "H. Geffner" ],
      "venue" : "In Proceedings of the 15th International Conference on Planning and Scheduling",
      "citeRegEx" : "Palacios et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Palacios et al\\.",
      "year" : 2005
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems",
      "author" : [ "J. Pearl" ],
      "venue" : "Morgan Kaufmann.",
      "citeRegEx" : "Pearl,? 1988",
      "shortCiteRegEx" : "Pearl",
      "year" : 1988
    }, {
      "title" : "Combining component caching and clause learning for effective model counting",
      "author" : [ "T. Sang", "F. Bacchus", "P. Beame", "H. Kautz", "T. Pitassi" ],
      "venue" : "In Proceedings of the Seventh International Conference on Theory and Applications of Satisfiability Testing (SAT’04)",
      "citeRegEx" : "Sang et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Sang et al\\.",
      "year" : 2004
    }, {
      "title" : "Affine algebraic decision diagrams (AADDs) and their application to structured probabilistic inference",
      "author" : [ "S. Sanner", "D. McAllester" ],
      "venue" : "In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Sanner and McAllester,? \\Q2005\\E",
      "shortCiteRegEx" : "Sanner and McAllester",
      "year" : 2005
    }, {
      "title" : "Knowledge compilation and theory approximation",
      "author" : [ "B. Selman", "H. Kautz" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Selman and Kautz,? \\Q1996\\E",
      "shortCiteRegEx" : "Selman and Kautz",
      "year" : 1996
    }, {
      "title" : "Valuation-based systems for Bayesian decision analysis",
      "author" : [ "P. Shenoy" ],
      "venue" : "Operations Research, 40, 463–484.",
      "citeRegEx" : "Shenoy,? 1992",
      "shortCiteRegEx" : "Shenoy",
      "year" : 1992
    }, {
      "title" : "Algorithms for discrete function manipulation",
      "author" : [ "A. Srinivasan", "T. Kam", "S. Malik", "R.K. Brayton" ],
      "venue" : "In International conference on CAD,",
      "citeRegEx" : "Srinivasan et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Srinivasan et al\\.",
      "year" : 1990
    }, {
      "title" : "Factored edge-valued binary decision diagrams",
      "author" : [ "P. Tafertshofer", "M. Pedram" ],
      "venue" : "Formal Methods in System Design,",
      "citeRegEx" : "Tafertshofer and Pedram,? \\Q1997\\E",
      "shortCiteRegEx" : "Tafertshofer and Pedram",
      "year" : 1997
    }, {
      "title" : "Bounded backtracking for the valued constraint satisfaction problems",
      "author" : [ "C. Terrioux", "P. Jégou" ],
      "venue" : "In Proceedings of the Ninth International Conference on Principles and Practice of Constraint Programming",
      "citeRegEx" : "Terrioux and Jégou,? \\Q2003\\E",
      "shortCiteRegEx" : "Terrioux and Jégou",
      "year" : 2003
    }, {
      "title" : "Hybrid backtracking bounded by tree-decomposition of constraint networks",
      "author" : [ "C. Terrioux", "P. Jégou" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Terrioux and Jégou,? \\Q2003\\E",
      "shortCiteRegEx" : "Terrioux and Jégou",
      "year" : 2003
    }, {
      "title" : "Decision diagrams for the computation of semiring valuations",
      "author" : [ "N. Wilson" ],
      "venue" : "Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI’05), pp. 331–336.",
      "citeRegEx" : "Wilson,? 2005",
      "shortCiteRegEx" : "Wilson",
      "year" : 2005
    }, {
      "title" : "Boolean function representation and spectral characterization using AND/OR graphs. Integration",
      "author" : [ "A. Zuzek", "R. Drechsler", "M. Thornton" ],
      "venue" : "The VLSI journal,",
      "citeRegEx" : "Zuzek et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Zuzek et al\\.",
      "year" : 2000
    } ],
    "referenceMentions" : [ {
      "referenceID" : 49,
      "context" : "The AND/OR search space idea was originally developed for heuristic search (Nilsson, 1980).",
      "startOffset" : 75,
      "endOffset" : 90
    }, {
      "referenceID" : 19,
      "context" : "Specifically, it resembles the pseudo tree rearrangement (Freuder & Quinn, 1985, 1987), that was adapted subsequently for distributed constraint satisfaction by Collin, Dechter, and Katz (1991, 1999) and more recently by Modi, Shen, Tambe, and Yokoo (2005), and was also shown to be related to graph-based backjumping (Dechter, 1992).",
      "startOffset" : 318,
      "endOffset" : 333
    }, {
      "referenceID" : 16,
      "context" : "Similar principles were introduced recently for probabilistic inference, in algorithm Recursive Conditioning (Darwiche, 2001) as well as in Value Elimination (Bacchus, Dalmao, & Pitassi, 2003b, 2003a), and are currently at the core of the most advanced SAT solvers (Sang, Bacchus, Beame, Kautz, & Pitassi, 2004).",
      "startOffset" : 109,
      "endOffset" : 125
    }, {
      "referenceID" : 45,
      "context" : "2 Decision Diagrams Decision diagrams are widely used in many areas of research, especially in software and hardware verification (Clarke, Grumberg, & Peled, 1999; McMillan, 1993).",
      "startOffset" : 130,
      "endOffset" : 179
    }, {
      "referenceID" : 14,
      "context" : "In the context of graphical models, AND/OR search (Dechter & Mateescu, 2007) was also inspired by search advances introduced sporadically in the past three decades for constraint satisfaction and more recently for probabilistic inference and for optimization tasks. Specifically, it resembles the pseudo tree rearrangement (Freuder & Quinn, 1985, 1987), that was adapted subsequently for distributed constraint satisfaction by Collin, Dechter, and Katz (1991, 1999) and more recently by Modi, Shen, Tambe, and Yokoo (2005), and was also shown to be related to graph-based backjumping (Dechter, 1992).",
      "startOffset" : 51,
      "endOffset" : 523
    }, {
      "referenceID" : 5,
      "context" : "This work was extended by Bayardo and Miranker (1996) and Bayardo and Schrag (1997) and more recently applied to optimization tasks by Larrosa, Meseguer, and Sanchez (2002).",
      "startOffset" : 26,
      "endOffset" : 54
    }, {
      "referenceID" : 5,
      "context" : "This work was extended by Bayardo and Miranker (1996) and Bayardo and Schrag (1997) and more recently applied to optimization tasks by Larrosa, Meseguer, and Sanchez (2002).",
      "startOffset" : 26,
      "endOffset" : 84
    }, {
      "referenceID" : 5,
      "context" : "This work was extended by Bayardo and Miranker (1996) and Bayardo and Schrag (1997) and more recently applied to optimization tasks by Larrosa, Meseguer, and Sanchez (2002). Another version that can be viewed as exploring the AND/OR graphs was presented recently for constraint satisfaction (Terrioux & Jégou, 2003b) and for optimization (Terrioux & Jégou, 2003a).",
      "startOffset" : 26,
      "endOffset" : 173
    }, {
      "referenceID" : 5,
      "context" : "This work was extended by Bayardo and Miranker (1996) and Bayardo and Schrag (1997) and more recently applied to optimization tasks by Larrosa, Meseguer, and Sanchez (2002). Another version that can be viewed as exploring the AND/OR graphs was presented recently for constraint satisfaction (Terrioux & Jégou, 2003b) and for optimization (Terrioux & Jégou, 2003a). Similar principles were introduced recently for probabilistic inference, in algorithm Recursive Conditioning (Darwiche, 2001) as well as in Value Elimination (Bacchus, Dalmao, & Pitassi, 2003b, 2003a), and are currently at the core of the most advanced SAT solvers (Sang, Bacchus, Beame, Kautz, & Pitassi, 2004). 1.2 Decision Diagrams Decision diagrams are widely used in many areas of research, especially in software and hardware verification (Clarke, Grumberg, & Peled, 1999; McMillan, 1993). A BDD represents a Boolean function by a directed acyclic graph with two terminal nodes (labeled 0 and 1), and every internal node is labeled with a variable and has exactly two children: low for 0 and high for 1. If isomorphic nodes were not merged, we would have the full search tree, also called Shannon tree, which is the usual full tree explored by a backtracking algorithm. The tree is ordered if variables are encountered in the same order along every branch. It can then be compressed by merging isomorphic nodes (i.e., with the same label and identical children), and by eliminating redundant nodes (i.e., whose low and high children are identical). The result is the celebrated reduced ordered binary decision diagram, or OBDD for short, introduced by Bryant (1986). However, the underlying structure is OR, because the initial Shannon tree is an OR tree.",
      "startOffset" : 26,
      "endOffset" : 1637
    }, {
      "referenceID" : 9,
      "context" : "Binary Decision Diagram (BDD) (Bryant, 1986) is arguably the most widely known and used compiled structure.",
      "startOffset" : 30,
      "endOffset" : 44
    }, {
      "referenceID" : 55,
      "context" : "The combination operator can also be defined axiomatically (Shenoy, 1992).",
      "startOffset" : 59,
      "endOffset" : 73
    }, {
      "referenceID" : 31,
      "context" : "We will use the concept of pseudo tree, which resembles the tree rearrangements introduced by Freuder and Quinn (1985): 1.",
      "startOffset" : 94,
      "endOffset" : 119
    }, {
      "referenceID" : 20,
      "context" : "The induced width of a graphical model governs the complexity of solving it by Bucket Elimination (Dechter, 1999), and was also shown to bound the AND/OR search graph when memory is used to cache solved subproblems (Dechter & Mateescu, 2007).",
      "startOffset" : 98,
      "endOffset" : 113
    }, {
      "referenceID" : 19,
      "context" : "The induced width of a graphical model governs the complexity of solving it by Bucket Elimination (Dechter, 1999), and was also shown to bound the AND/OR search graph when memory is used to cache solved subproblems (Dechter & Mateescu, 2007). DEFINITION 7 (induced graph, induced width, treewidth, pathwidth) An ordered graph is a pair (G, d), where G = ({X1, . . . , Xn}, E) is an undirected graph, and d = (X1, . . . , Xn) is an ordering of the nodes. The width of a node in an ordered graph is the number of neighbors that precede it in the ordering. The width of an ordering d, denoted w(d), is the maximum width over all nodes. The induced width of an ordered graph, w∗(d), is the width of the induced ordered graph obtained as follows: for each node, from last to first in d, its preceding neighbors are connected in a clique. The induced width of a graph, w∗, is the minimal induced width over all orderings. The induced width is also equal to the treewidth of a graph. The pathwidth pw∗ of a graph is the treewidth over the restricted class of orderings that correspond to chain decompositions. Various reasoning tasks, or queries can be defined over graphical models. Those can be defined formally using marginalization operators such as projection, summation and minimization. However, since our goal is to present a compilation of a graphical model which is independent of the queries that can be posed on it, we will discuss tasks in an informal manner only. For more information see the work of Kask, Dechter, Larrosa, and Dechter (2005). Throughout the paper, we will use two examples of graphical models: constraint networks and belief networks.",
      "startOffset" : 99,
      "endOffset" : 1551
    }, {
      "referenceID" : 51,
      "context" : "Belief Networks (Pearl, 1988) provide a formalism for reasoning about partial beliefs under conditions of uncertainty.",
      "startOffset" : 16,
      "endOffset" : 29
    }, {
      "referenceID" : 45,
      "context" : "Due to the fundamental importance of Boolean functions, a lot of effort has been dedicated to the study of Binary Decision Diagrams (BDDs), which are extensively used in software and hardware verification (Clarke et al., 1999; McMillan, 1993).",
      "startOffset" : 205,
      "endOffset" : 242
    }, {
      "referenceID" : 40,
      "context" : "The earliest work on BDDs is due to Lee (1959), who introduced the binary-decision program, that can be understood as a linear representation of a BDD (e.",
      "startOffset" : 36,
      "endOffset" : 47
    }, {
      "referenceID" : 0,
      "context" : "Akers (1978) presented the actual graphical",
      "startOffset" : 0,
      "endOffset" : 13
    }, {
      "referenceID" : 20,
      "context" : "3 Bucket Elimination Review Bucket Elimination (BE) (Dechter, 1999) is a well known variable elimination algorithm for inference in graphical models.",
      "startOffset" : 52,
      "endOffset" : 67
    }, {
      "referenceID" : 9,
      "context" : "However, it was Bryant (1986) that introduced what is now called the Ordered Binary Decision Diagram (OBDD).",
      "startOffset" : 16,
      "endOffset" : 30
    }, {
      "referenceID" : 20,
      "context" : "The representation in Figure 5 reverses the top down bucket processing described in earlier papers (Dechter, 1999).",
      "startOffset" : 99,
      "endOffset" : 114
    }, {
      "referenceID" : 16,
      "context" : "It was already shown (Freuder & Quinn, 1985; Bayardo & Miranker, 1996; Darwiche, 2001; Dechter & Mateescu, 2004a, 2007) that: THEOREM 1 Given a graphical model M over n variables, and a pseudo tree T of depth m, the size of the AND/OR search tree based on T is O(n k), where k bounds the domains of variables.",
      "startOffset" : 21,
      "endOffset" : 119
    }, {
      "referenceID" : 19,
      "context" : "It was shown by Dechter and Mateescu (2007) that: THEOREM 2 A graphical model M has a unique minimal AND/OR search graph relative to a pseudo-tree T .",
      "startOffset" : 16,
      "endOffset" : 44
    }, {
      "referenceID" : 19,
      "context" : "It was shown by Dechter and Mateescu (2007) that: THEOREM 2 A graphical model M has a unique minimal AND/OR search graph relative to a pseudo-tree T . The minimal AND/OR graph of a graphical model G relative to a pseudo tree T is denoted by MT (G). Note that the definition of minimality used in the work of Dechter and Mateescu (2007) is based only on isomorphism reduction.",
      "startOffset" : 16,
      "endOffset" : 336
    }, {
      "referenceID" : 16,
      "context" : "Incidentally, the caches that are not useful (namely OR nodes with only one incoming arc), are called dead caches (Darwiche, 2001), and can be determined based only on the pseudo",
      "startOffset" : 114,
      "endOffset" : 130
    }, {
      "referenceID" : 19,
      "context" : "For more details on the relationship between AND/OR search and BE see the work of Mateescu and Dechter (2005). 3.",
      "startOffset" : 95,
      "endOffset" : 110
    }, {
      "referenceID" : 19,
      "context" : "As overviewed earlier, Dechter and Mateescu (2007, 2004a) defined the complete minimal AND/OR graph which is an AND/OR graph whose unifiable nodes are all merged, and Dechter and Mateescu (2007) also proved the canonicity for non-weighted graphical models.",
      "startOffset" : 23,
      "endOffset" : 195
    }, {
      "referenceID" : 9,
      "context" : "The APPLY is very similar to that from OBDDs (Bryant, 1986), but it is adapted to AND/OR search graphs.",
      "startOffset" : 45,
      "endOffset" : 59
    }, {
      "referenceID" : 9,
      "context" : "AOMDDs Are Canonical Representations It is well known that OBDDs are canonical representations of Boolean functions given an ordering of the variables (Bryant, 1986), namely a strict ordering of any CNF specification of the same Boolean function will yield an identical OBDD, and this property extends to MDDs (Srinivasan et al.",
      "startOffset" : 151,
      "endOffset" : 165
    }, {
      "referenceID" : 56,
      "context" : "AOMDDs Are Canonical Representations It is well known that OBDDs are canonical representations of Boolean functions given an ordering of the variables (Bryant, 1986), namely a strict ordering of any CNF specification of the same Boolean function will yield an identical OBDD, and this property extends to MDDs (Srinivasan et al., 1990).",
      "startOffset" : 310,
      "endOffset" : 335
    }, {
      "referenceID" : 1,
      "context" : "The idea of using unit resolution during search for Bayesian networks was first explored by Allen and Darwiche (2003). AOMDD-BCP is conservative and applies only unit resolution at each node in the search graph, whereas AOMDD-SAT is more aggressive and detects inconsistency by running a full SAT solver.",
      "startOffset" : 92,
      "endOffset" : 118
    }, {
      "referenceID" : 37,
      "context" : "The AOMDD compilers as well as ACE used the min-fill heuristic (Kjæaerulff, 1990) to construct the guiding pseudo tree and dtree, respectively.",
      "startOffset" : 63,
      "endOffset" : 81
    }, {
      "referenceID" : 11,
      "context" : "This algorithm is similar to the one discussed by Chavira and Darwiche (2007), but uses tables to represent factors rather than ADDs.",
      "startOffset" : 50,
      "endOffset" : 78
    }, {
      "referenceID" : 16,
      "context" : "This idea was also explored by Darwiche (2001) for constructing dtrees that guide ACE.",
      "startOffset" : 31,
      "endOffset" : 47
    }, {
      "referenceID" : 16,
      "context" : "This idea was also explored by Darwiche (2001) for constructing dtrees that guide ACE. Since both the min-fill and hypergraph partitioning heuristics are randomized (namely ties are broken randomly), the size of the AOMDD guided by the resulting pseudo tree may vary significantly from one run to the next. Figure 25 displays the AOMDD size using hypergraph and min-fill based pseudo trees for 6 networks selected from Table 1, over 20 independent runs. We also record the average induced width and depth obtained for the pseudo trees (see the header of each plot in Figure 25). We see that the two heuristics do not dominate each other, namely the variance in output size is quite significant in both cases. 10.5 Memory Usage Table 2 shows the memory usage (in MBytes) of ACE, AOMDD-BCP and AOMDD-SAT, respectively, on the Bayesian networks from Table 1. We see that in some cases the AOMDD based compilers require far less memory than ACE. For example, on the “mildew” network, both AOMDDBCP and AOMDD-SAT use about 22 MB of memory to compile the AND/OR decision diagram, while ACE requires as much as 218 MB of memory. Moreover, the compiled AOMDD has in this case about one order of magnitude fewer nodes than that constructed by ACE. When comparing the two AND/OR search-based compilers, we observe that on networks with a significant amount of determinism, such as those from the UAI’06 Evaluation dataset, AOMDD-SAT uses on average two times less memory than AOMDD-BCP. The most dramatic savings in memory usage due to the aggressive constraint propagation employed by AOMDD-SAT compared with AOMDD-BCP can be seen on the “BN 67” network. In this case, the difference in memory usage between AOMDD-SAT and AOMDD-BCP is about 2 orders of magnitude in favor of the former. 11. Related Work The related work can be viewed along two directions: (1) the work related to the AND/OR search idea for graphical models and (2) the work related to compilation for graphical models that exploits problem structure. An extensive discussion for (1) was provided in the previous work of Dechter and Mateescu (2007). Since this is not the focus of the paper, we just mention that the AND/OR idea was origi-",
      "startOffset" : 31,
      "endOffset" : 2107
    }, {
      "referenceID" : 49,
      "context" : "nally developed for heuristic search (Nilsson, 1980).",
      "startOffset" : 37,
      "endOffset" : 52
    }, {
      "referenceID" : 19,
      "context" : "(2005), and was also shown to be related to graph-based backjumping (Dechter, 1992).",
      "startOffset" : 68,
      "endOffset" : 83
    }, {
      "referenceID" : 16,
      "context" : "Similar principles were introduced recently for probabilistic inference, in algorithm Recursive Conditioning (Darwiche, 2001) as well as in Value Elimination (Bacchus et al.",
      "startOffset" : 109,
      "endOffset" : 125
    }, {
      "referenceID" : 52,
      "context" : ", 2003b, 2003a), and are currently at the core of the most advanced SAT solvers (Sang et al., 2004).",
      "startOffset" : 80,
      "endOffset" : 99
    }, {
      "referenceID" : 8,
      "context" : "The idea was adapted for distributed constraint satisfaction by Collin et al. (1991, 1999) and more recently by Modi et al. (2005), and was also shown to be related to graph-based backjumping (Dechter, 1992).",
      "startOffset" : 64,
      "endOffset" : 131
    }, {
      "referenceID" : 3,
      "context" : "This work was extended by Bayardo and Miranker (1996), Bayardo and Schrag (1997) and more recently applied to optimization tasks by Larrosa et al.",
      "startOffset" : 26,
      "endOffset" : 54
    }, {
      "referenceID" : 3,
      "context" : "This work was extended by Bayardo and Miranker (1996), Bayardo and Schrag (1997) and more recently applied to optimization tasks by Larrosa et al.",
      "startOffset" : 26,
      "endOffset" : 81
    }, {
      "referenceID" : 3,
      "context" : "This work was extended by Bayardo and Miranker (1996), Bayardo and Schrag (1997) and more recently applied to optimization tasks by Larrosa et al. (2002). Another version that can be viewed as exploring the AND/OR graphs was presented recently for constraint satisfaction (Terrioux & Jégou, 2003b) and for optimization (Terrioux & Jégou, 2003a).",
      "startOffset" : 26,
      "endOffset" : 154
    }, {
      "referenceID" : 2,
      "context" : "Similar principles were introduced recently for probabilistic inference, in algorithm Recursive Conditioning (Darwiche, 2001) as well as in Value Elimination (Bacchus et al., 2003b, 2003a), and are currently at the core of the most advanced SAT solvers (Sang et al., 2004). For direction (2), there are various lines of related research. The formal verification literature, beginning with the work of Bryant (1986) contains a very large number of papers dedicated to the study of BDDs.",
      "startOffset" : 159,
      "endOffset" : 415
    }, {
      "referenceID" : 2,
      "context" : "Similar principles were introduced recently for probabilistic inference, in algorithm Recursive Conditioning (Darwiche, 2001) as well as in Value Elimination (Bacchus et al., 2003b, 2003a), and are currently at the core of the most advanced SAT solvers (Sang et al., 2004). For direction (2), there are various lines of related research. The formal verification literature, beginning with the work of Bryant (1986) contains a very large number of papers dedicated to the study of BDDs. However, BDDs are in fact OR structures (the underlying pseudo tree is a chain) and do not take advantage of the problem decomposition in an explicit way. The complexity bounds for OBDDs are based on pathwidth rather than treewidth. As noted earlier, the work of Bertacco and Damiani (1997) on Disjoint Support Decomposition (DSD) is related to AND/OR BDDs in various ways.",
      "startOffset" : 159,
      "endOffset" : 777
    }, {
      "referenceID" : 2,
      "context" : "Similar principles were introduced recently for probabilistic inference, in algorithm Recursive Conditioning (Darwiche, 2001) as well as in Value Elimination (Bacchus et al., 2003b, 2003a), and are currently at the core of the most advanced SAT solvers (Sang et al., 2004). For direction (2), there are various lines of related research. The formal verification literature, beginning with the work of Bryant (1986) contains a very large number of papers dedicated to the study of BDDs. However, BDDs are in fact OR structures (the underlying pseudo tree is a chain) and do not take advantage of the problem decomposition in an explicit way. The complexity bounds for OBDDs are based on pathwidth rather than treewidth. As noted earlier, the work of Bertacco and Damiani (1997) on Disjoint Support Decomposition (DSD) is related to AND/OR BDDs in various ways. The main common aspect is that both approaches show how structure decomposition can be exploited in a BDD-like representation. DSD is focused on Boolean functions and can exploit more refined structural information that is inherent to Boolean functions. In contrast, AND/OR BDDs assume only the structure conveyed in the constraint graph, and are therefore more broadly applicable to any constraint expression and also to graphical models in general. They allow a simpler and higher level exposition that yields graphbased bounds on the overall size of the generated AOMDD. The full relationship between these two formalisms should be studied further. McMillan (1994) introduced the BDD trees, along with the operations for combining them.",
      "startOffset" : 159,
      "endOffset" : 1528
    }, {
      "referenceID" : 17,
      "context" : "The AND/OR structure restricted to propositional theories is very similar to deterministic decomposable negation normal form (d-DNNF) (Darwiche & Marquis, 2002; Darwiche, 2002).",
      "startOffset" : 134,
      "endOffset" : 176
    }, {
      "referenceID" : 4,
      "context" : "Algebraic decision diagrams (ADDs) (Bahar et al., 1993) provide a compilation for general real-valued rather than Boolean functions.",
      "startOffset" : 35,
      "endOffset" : 55
    }, {
      "referenceID" : 15,
      "context" : "The AND/OR structure restricted to propositional theories is very similar to deterministic decomposable negation normal form (d-DNNF) (Darwiche & Marquis, 2002; Darwiche, 2002). More recently, Huang and Darwiche (2005b) used the trace of the DPLL algorithm to generate an OBDD, and compared with the typical formal verification approach of combining the OBDDs of the input function according to some schedule.",
      "startOffset" : 135,
      "endOffset" : 220
    }, {
      "referenceID" : 15,
      "context" : "The AND/OR structure restricted to propositional theories is very similar to deterministic decomposable negation normal form (d-DNNF) (Darwiche & Marquis, 2002; Darwiche, 2002). More recently, Huang and Darwiche (2005b) used the trace of the DPLL algorithm to generate an OBDD, and compared with the typical formal verification approach of combining the OBDDs of the input function according to some schedule. The structures that were investigated in that case are still OR. This idea is extended in our present work by the AND/OR search compilation algorithm. McAllester, Collins, and Pereira (2004) introduced the case factor diagrams (CFD), which subsume Markov random fields of bounded tree width and probabilistic context free grammars (PCFG).",
      "startOffset" : 135,
      "endOffset" : 601
    }, {
      "referenceID" : 15,
      "context" : "The AND/OR structure restricted to propositional theories is very similar to deterministic decomposable negation normal form (d-DNNF) (Darwiche & Marquis, 2002; Darwiche, 2002). More recently, Huang and Darwiche (2005b) used the trace of the DPLL algorithm to generate an OBDD, and compared with the typical formal verification approach of combining the OBDDs of the input function according to some schedule. The structures that were investigated in that case are still OR. This idea is extended in our present work by the AND/OR search compilation algorithm. McAllester, Collins, and Pereira (2004) introduced the case factor diagrams (CFD), which subsume Markov random fields of bounded tree width and probabilistic context free grammars (PCFG). CFDs are very much related to the AND/OR graphs. The CFDs target the minimal representation, by exploiting decomposition (similar to AND nodes) but also by exploiting context sensitive information and allowing dynamic ordering of variables based on context. CFDs do not eliminate the redundant nodes, and part of the cause is that they use zero suppression. There is no claim about CFDs being canonical forms, and also no description of how to combine two CFDs. There are numerous variants of decision diagrams that are designed to represent integer-valued or real-valued functions. For a comprehensive view we refer the reader to the survey of Drechsler and Sieling (2001). Algebraic decision diagrams (ADDs) (Bahar et al.",
      "startOffset" : 135,
      "endOffset" : 1423
    }, {
      "referenceID" : 4,
      "context" : "Algebraic decision diagrams (ADDs) (Bahar et al., 1993) provide a compilation for general real-valued rather than Boolean functions. Their main drawback is that their size increases very fast if the number of terminals becomes large. There are several approaches that try to alleviate this problem. However the structure that they capture is still OR, and they do not exploit decomposition. Some alternatives introduce edge values (or weights) that enable more subgraph sharing. Edge-valued binary decision diagrams (EVBDDs) (Lai & Sastry, 1992) use additive weights, and when multiplicative weights are also allowed they are called factored EVBDDs (FEVBDDs) (Tafertshofer & Pedram, 1997). Another type of BDDs called K*BMDs (Drechsler, Becker, & Ruppertz, 1996) also use integer weights, both additive and multiplicative in parallel. ADDs have also been extended to affine ADDs (Sanner & McAllester, 2005), through affine transformations that can achieve more compression. The result was shown to be beneficial for probabilistic inference algorithms, such as tree clustering, but they still do not exploit the AND structure. More recently, independently and in parallel to our work on AND/OR graphs (Dechter & Mateescu, 2004a, 2004b), Fargier and Vilarem (2004) and Fargier and Marquis (2006, 2007) proposed the compilation of CSPs into tree-driven automata, which have many similarities to our work.",
      "startOffset" : 36,
      "endOffset" : 1263
    }, {
      "referenceID" : 4,
      "context" : "Algebraic decision diagrams (ADDs) (Bahar et al., 1993) provide a compilation for general real-valued rather than Boolean functions. Their main drawback is that their size increases very fast if the number of terminals becomes large. There are several approaches that try to alleviate this problem. However the structure that they capture is still OR, and they do not exploit decomposition. Some alternatives introduce edge values (or weights) that enable more subgraph sharing. Edge-valued binary decision diagrams (EVBDDs) (Lai & Sastry, 1992) use additive weights, and when multiplicative weights are also allowed they are called factored EVBDDs (FEVBDDs) (Tafertshofer & Pedram, 1997). Another type of BDDs called K*BMDs (Drechsler, Becker, & Ruppertz, 1996) also use integer weights, both additive and multiplicative in parallel. ADDs have also been extended to affine ADDs (Sanner & McAllester, 2005), through affine transformations that can achieve more compression. The result was shown to be beneficial for probabilistic inference algorithms, such as tree clustering, but they still do not exploit the AND structure. More recently, independently and in parallel to our work on AND/OR graphs (Dechter & Mateescu, 2004a, 2004b), Fargier and Vilarem (2004) and Fargier and Marquis (2006, 2007) proposed the compilation of CSPs into tree-driven automata, which have many similarities to our work. Their main focus is the transition from linear automata to tree automata (similar to that from OR to AND/OR), and the possible savings for tree-structured networks and hyper-trees of constraints due to decomposition. Their compilation approach is guided by a tree-decomposition while ours is guided by a variable-elimination based algorithms. And it is well known that Bucket Elimination and cluster-tree decomposition are in principle the same (Dechter & Pearl, 1989). Wilson (2005) extended OBDDs to semi-ring BDDs.",
      "startOffset" : 36,
      "endOffset" : 1886
    }, {
      "referenceID" : 4,
      "context" : "Algebraic decision diagrams (ADDs) (Bahar et al., 1993) provide a compilation for general real-valued rather than Boolean functions. Their main drawback is that their size increases very fast if the number of terminals becomes large. There are several approaches that try to alleviate this problem. However the structure that they capture is still OR, and they do not exploit decomposition. Some alternatives introduce edge values (or weights) that enable more subgraph sharing. Edge-valued binary decision diagrams (EVBDDs) (Lai & Sastry, 1992) use additive weights, and when multiplicative weights are also allowed they are called factored EVBDDs (FEVBDDs) (Tafertshofer & Pedram, 1997). Another type of BDDs called K*BMDs (Drechsler, Becker, & Ruppertz, 1996) also use integer weights, both additive and multiplicative in parallel. ADDs have also been extended to affine ADDs (Sanner & McAllester, 2005), through affine transformations that can achieve more compression. The result was shown to be beneficial for probabilistic inference algorithms, such as tree clustering, but they still do not exploit the AND structure. More recently, independently and in parallel to our work on AND/OR graphs (Dechter & Mateescu, 2004a, 2004b), Fargier and Vilarem (2004) and Fargier and Marquis (2006, 2007) proposed the compilation of CSPs into tree-driven automata, which have many similarities to our work. Their main focus is the transition from linear automata to tree automata (similar to that from OR to AND/OR), and the possible savings for tree-structured networks and hyper-trees of constraints due to decomposition. Their compilation approach is guided by a tree-decomposition while ours is guided by a variable-elimination based algorithms. And it is well known that Bucket Elimination and cluster-tree decomposition are in principle the same (Dechter & Pearl, 1989). Wilson (2005) extended OBDDs to semi-ring BDDs. The semi-ring treatment is restricted to the OR search spaces, but allows dynamic variable ordering. It is otherwise very similar in aim and scope to our AOMDD. When restricting the AOMDD to OR graphs only, the two are closely related, except that we express BDDs using the Shenoy-Shafer axiomatization that is centered on the two operation of combination and marginalization rather then on the semi-ring formulation. Minimality in the formulation of Wilson (2005) is more general allowing merging nodes having different values and therefore it can capture symmetries (called interchangeability).",
      "startOffset" : 36,
      "endOffset" : 2385
    }, {
      "referenceID" : 4,
      "context" : "Algebraic decision diagrams (ADDs) (Bahar et al., 1993) provide a compilation for general real-valued rather than Boolean functions. Their main drawback is that their size increases very fast if the number of terminals becomes large. There are several approaches that try to alleviate this problem. However the structure that they capture is still OR, and they do not exploit decomposition. Some alternatives introduce edge values (or weights) that enable more subgraph sharing. Edge-valued binary decision diagrams (EVBDDs) (Lai & Sastry, 1992) use additive weights, and when multiplicative weights are also allowed they are called factored EVBDDs (FEVBDDs) (Tafertshofer & Pedram, 1997). Another type of BDDs called K*BMDs (Drechsler, Becker, & Ruppertz, 1996) also use integer weights, both additive and multiplicative in parallel. ADDs have also been extended to affine ADDs (Sanner & McAllester, 2005), through affine transformations that can achieve more compression. The result was shown to be beneficial for probabilistic inference algorithms, such as tree clustering, but they still do not exploit the AND structure. More recently, independently and in parallel to our work on AND/OR graphs (Dechter & Mateescu, 2004a, 2004b), Fargier and Vilarem (2004) and Fargier and Marquis (2006, 2007) proposed the compilation of CSPs into tree-driven automata, which have many similarities to our work. Their main focus is the transition from linear automata to tree automata (similar to that from OR to AND/OR), and the possible savings for tree-structured networks and hyper-trees of constraints due to decomposition. Their compilation approach is guided by a tree-decomposition while ours is guided by a variable-elimination based algorithms. And it is well known that Bucket Elimination and cluster-tree decomposition are in principle the same (Dechter & Pearl, 1989). Wilson (2005) extended OBDDs to semi-ring BDDs. The semi-ring treatment is restricted to the OR search spaces, but allows dynamic variable ordering. It is otherwise very similar in aim and scope to our AOMDD. When restricting the AOMDD to OR graphs only, the two are closely related, except that we express BDDs using the Shenoy-Shafer axiomatization that is centered on the two operation of combination and marginalization rather then on the semi-ring formulation. Minimality in the formulation of Wilson (2005) is more general allowing merging nodes having different values and therefore it can capture symmetries (called interchangeability). Another framework very similar to AOMDDs, that we became aware of only recently, is Probabilistic Decision Graphs (PDG) of Jaeger (2004). This work preceded most of the relevant work",
      "startOffset" : 36,
      "endOffset" : 2654
    }, {
      "referenceID" : 60,
      "context" : "we discussed above (Fargier & Vilarem, 2004; Wilson, 2005) and went somewhat unnoticed, perhaps due to notational and cultural differences.",
      "startOffset" : 19,
      "endOffset" : 58
    }, {
      "referenceID" : 9,
      "context" : "Conclusion We propose the AND/OR multi-valued decision diagram (AOMDD), which emerges from the study of AND/OR search spaces for graphical models (Dechter & Mateescu, 2004a, 2004b; Mateescu & Dechter, 2005; Dechter & Mateescu, 2007) and ordered binary decision diagrams (OBDDs) (Bryant, 1986).",
      "startOffset" : 278,
      "endOffset" : 292
    }, {
      "referenceID" : 57,
      "context" : "we discussed above (Fargier & Vilarem, 2004; Wilson, 2005) and went somewhat unnoticed, perhaps due to notational and cultural differences. It is however similar in motivation, framework and proposed algorithms. We believe our AND/OR framework is more accessible. We define the framework over multi-valued domains, provide greater details in algorithms and complexity analysis, make an explicit connection with search frameworks, fully address the issues of canonicity as well as provide an empirical demonstration. In particular, the claim of canonicity for PDGs is similar to the one we make for AOMDDs of weighted models, in that it is relative to the trees (or forests) that can represent the given probability distribution. There is another line of research by Drechsler and his group (e.g. Zuzek, Drechsler, & Thornton, 2000), who use AND/OR graphs for Boolean function representation, that may seem similar to our approach. However, the semantics and purpose of their AND/OR graphs are different. They are constructed based on the technique of recursive learning and are used to perform Boolean reasoning, i.e. to explore the logic consequences of a given assumption based on the structure of the circuit, especially to derive sets of implicants. The meaning of AND and OR in their case is related to the meaning of the gates/functions, while in our case the meaning is not related to the semantic of the functions. The AND/OR enumeration tree that results from a circuit according to Zuzek et al. (2000) is not related to the AND/OR decomposition that we discuss.",
      "startOffset" : 45,
      "endOffset" : 1512
    }, {
      "referenceID" : 9,
      "context" : "It follows the canonicity proofs for OBDDs (Bryant, 1986) and MDDs (Srinivasan et al.",
      "startOffset" : 43,
      "endOffset" : 57
    }, {
      "referenceID" : 56,
      "context" : "It follows the canonicity proofs for OBDDs (Bryant, 1986) and MDDs (Srinivasan et al., 1990), but extends them from linear orderings to tree orderings that capture function decomposition according to the pseudo tree T .",
      "startOffset" : 67,
      "endOffset" : 92
    } ],
    "year" : 2008,
    "abstractText" : "Inspired by the recently introduced framework of AND/OR search spaces for graphical models, we propose to augment Multi-Valued Decision Diagrams (MDD) with AND nodes, in order to capture function decomposition structure and to extend these compiled data structures to general weighted graphical models (e.g., probabilistic models). We present the AND/OR Multi-Valued Decision Diagram (AOMDD) which compiles a graphical model into a canonical form that supports polynomial (e.g., solution counting, belief updating) or constant time (e.g. equivalence of graphical models) queries. We provide two algorithms for compiling the AOMDD of a graphical model. The first is search-based, and works by applying reduction rules to the trace of the memory intensive AND/OR search algorithm. The second is inference-based and uses a Bucket Elimination schedule to combine the AOMDDs of the input functions via the the APPLY operator. For both algorithms, the compilation time and the size of the AOMDD are, in the worst case, exponential in the treewidth of the graphical model, rather than pathwidth as is known for ordered binary decision diagrams (OBDDs). We introduce the concept of semantic treewidth, which helps explain why the size of a decision diagram is often much smaller than the worst case bound. We provide an experimental evaluation that demonstrates the potential of AOMDDs.",
    "creator" : "dvips(k) 5.96dev Copyright 2007 Radical Eye Software"
  }
}