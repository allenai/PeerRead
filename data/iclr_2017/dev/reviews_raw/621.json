{"conference": "ICLR 2017 conference submission", "title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "reviews": [{"is_meta_review": true, "comments": "This paper proposed COCONET, which is a neural autoregressive model with convolution, to do music composition task. This paper also proposed to use blocked Gibbs sampling instead of the ancestral sampling of the original NADE model to generate better pieces of music. The experimental results showed that the NLL of COCONET is better than the other baselines and the human evaluation task by Amazon\u2019s Mechanical Turk illustrated that the model can generate compelling music.\n\nIn general, I think the paper is good. Using NADE based model with convolution operations on music generation tasks and using blocked Gibbs sampling contains some kind of novelty. However, the novelty of the paper is incremental, since the blocked Gibbs sampling for NADE model is already proposed by Yao et al., (2014) and the using NADE based model for music modeling has also been proposed by Boulanger-Lewandowski  et al., (2012).", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "This paper applies an existing idea (Yao's block Gibbs sampling of NADE) to a music model. There is also prior art for applying NADE to music. The main novel and interesting result is that block Gibbs sampling (an approximation) actually improves performance, highlighting problems with NADE.\n \n This work is borderline for inclusion. The paper is mainly an application of existing ideas. The implications of the interesting results could perhaps have been explored further for a paper at a meeting on learning representations.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"TITLE": "Response to reviews", "OTHER_KEYS": "Cheng-Zhi Anna Huang", "comments": "Thank you all for your reviews!  \n\nWe share your concern regarding quantitative comparison to other works, and regarding the generality of our method.  We have looked into the datasets used in prior works, but found that their preprocessing severely degraded the musical structure. For example, the temporal granularity used in Boulanger-Lewandowski et al. is too coarse: in several pieces, discarding all notes that do not have their onsets on the eighth-note grid results in sparse notes with long stretches of silence between them. The pieces become unrecognizable, and (worse) non-musical.  Downsampling or blurring does not work in symbolic music like it does in images: music is more similar to language, and using a coarse grid is analogous to removing words from a sentence and asking a model to learn this new distribution of broken sentences. This turns it into a different task, and makes qualitative judgement of samples not very meaningful.\n\nWe also considered applying our method to image data as suggested. Unlike (symbolic) music which is discrete and intricately structured, the domain of images is smooth and forgiving of small errors. It is plausible that the NADE sampling approach generates fine images (indeed, that's what Yao et al. found), for reasons that don't carry over to our domain of interest, which is music.\n\nThe development of a larger-scale, more diverse and higher-quality MIDI music dataset is a major component of our ongoing project.  We nonetheless believe that the advances we show are of sufficient interest to justify publication at this time.", "IS_META_REVIEW": false, "DATE": "20 Jan 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer5", "TITLE": "Review", "is_meta_review": false, "comments": "The paper tackles the task of music generation. They use an orderless NADE model for the task of \"fill in the notes\". Given a roll of T timesteps of pitches, they randomly mask out some pitches, and the model is trained to predict the missing notes. This follows how the orderless NADE model can be trained. During sampling, one normally follows an ancestral sampling procedure. For this, an ordering is defined over outputs, and one runs the model on the current input, samples one of the outputs according to the order, adds this output to the next input, and continues this procedure until all outputs have been sampled. The key point of the paper is that this is a bad sampling strategy. Instead, they suggest the strategy of Yao et al. 2014, which uses a blocked Gibbs sampling approach. The blocked Gibbs strategy instead masks N inputs randomly and independently, samples them, and repeats this procedure. The point of this strategy is the make sure the sampling chain mixes well, which will happen for large N. However, since the samples are independent, having a large N gives incoherent samples. Thus, the authors follow an annealed schedule for N, making it smaller over time, which will eventually reduce to ancestral sampling (giving global structure to the sample). They conduct a variety of experiments involving both normal metrics and human evaluations, and find that this blocked Gibbs sampling outperforms other sampling procedures.\n\nThis is a well written paper - great job.\n\nMy main problem with the paper is that having read Uria and Yao, I don't know how much I have learned from this work in the context of this being an ICLR submission. If this was submitted to some computational music / art conference, this paper would be a clear accept. However, for ICLR, I don't see enough novelty compared with previous works this builds upon. Orderless NADE is an established model. The blocked Gibbs sampling and annealing scheme are basically the exact same one used in Yao. Thus, the main novelty of this paper is its application to the music domain, and finding that Yao's method works better for sampling music. This is a good contribution, but more tailored to those working in the music domain. If the authors found that these results also hold for other domains like images (e.g. on CIFAR / tiny Imagenet) and text (e.g. document generation), then I would change my mind and accept this paper for ICLR. Even just trying musical domains other than Bach chorales would be useful. However, as it stands, the experiments are not convincing enough.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "TITLE": "Review", "is_meta_review": false, "comments": "The paper presents a way to model the distribution of four-part Bach chorales using Convolutional Neural Networks. Furthermore it addresses the task of artificial music generation by sampling from the model using blocked Gibbs sampling and shows\n\nThe CNN model for the distribution seems very appropriate for the data at hand. Also the analysis of the proposed sampling schemes with the analogy between Gibbs sampling and human music composition are very interesting.\nI am not too sure about the evaluation though. Since the reported likelihoods are not directly comparable to previous work, I have difficulties judging the quality of the quantitative results.  For the human evaluation I would like to see the data for the direct comparisons between the models. E.g. How did NADE vs. Bach perform. Also I find the question: \u2018what piece of music do you prefer\u2019 a stronger test than the question \u2018what piece is more musical to you\u2019 because I don\u2019t really know what \u2018musical\u2019 means to the AMT workers.\n\nFinally, while I think the Bach Chorales are interesting musical pieces that deserve to be subject of the analysis but I find it hard to judge how well this modelling approach will transfer to other types of music which might have a very different data distribution.\n\nNevertheless, in conclusion, I believe this is an exciting model for an interesting task that produces non-trivial musical data.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "A nice work that apply NADE-based model to music composition", "is_meta_review": false, "comments": "This paper proposed COCONET, which is a neural autoregressive model with convolution, to do music composition task. This paper also proposed to use blocked Gibbs sampling instead of the ancestral sampling of the original NADE model to generate better pieces of music. The experimental results showed that the NLL of COCONET is better than the other baselines and the human evaluation task by Amazon\u2019s Mechanical Turk illustrated that the model can generate compelling music.\n\nIn general, I think the paper is good. Using NADE based model with convolution operations on music generation tasks and using blocked Gibbs sampling contains some kind of novelty. However, the novelty of the paper is incremental, since the blocked Gibbs sampling for NADE model is already proposed by Yao et al., (2014) and the using NADE based model for music modeling has also been proposed by Boulanger-Lewandowski  et al., (2012).\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "14 Dec 2016 (modified: 21 Jan 2017)", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Stopping criterion for sampling procedure and denoising model", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "", "IS_META_REVIEW": false, "DATE": "10 Dec 2016", "is_meta_review": false}, {"TITLE": "Nice paper", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "", "IS_META_REVIEW": false, "DATE": "08 Dec 2016", "is_meta_review": false}], "SCORE": 6, "authors": "Cheng-Zhi Anna Huang, Tim Cooijmans, Adam Roberts, Aaron Courville, Douglas Eck", "KEYWORDS": "NADE generative model of music, with new insights on sampling", "accepted": false, "id": ""}
