{
  "name" : "1401.5852.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Algorithms for Generating Ordered Solutions for Explicit AND/OR Structures",
    "authors" : [ "Priyankar Ghosh", "Amit Sharma", "P. P. Chakrabarti", "Pallab Dasgupta" ],
    "emails" : [ "priyankar@cse.iitkgp.ernet.in", "amit.ontop@gmail.com", "ppchak@cse.iitkgp.ernet.in", "pallab@cse.iitkgp.ernet.in" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "The use of AND/OR structures for modeling and solving complex problems efficiently has attracted a significant amount of research effort over the last few decades. Initially, AND/OR search spaces were mostly used in problem reduction search for solving complex problems, logical reasoning and theorem proving, etc., where the overall problem can be hierarchically decomposed into conjunction and disjunction of subproblems (Pearl, 1984; Nilsson, 1980). Subsequently, AND/OR structures were also applied in a variety of domains, e.g., for representing assembly plans (Homem de Mello & Sanderson, 1990), generating VLSI floor-plans (Dasgupta, Sur-Kolay, & Bhattacharya, 1995), puzzle solving (Fuxi, Ming, & Yanxiang, 2003), etc. Traditionally the algorithm AO* (Pearl, 1984; Nilsson, 1980; Martelli & Montanari, 1978, 1973; Chang & Slagle, 1971) has been used for searching implicitly defined AND/OR structures. An empirical study of AO* can be found in Bonet and Geffner’s (2005) work.\nIn the recent past there has been a renewed research interest towards the application of AND/OR structures. In various planning problems, including conditional planning to handle uncertainty, the AND/OR structure (Russell & Norvig, 2003) is a natural form\nc©2012 AI Access Foundation. All rights reserved.\nfor representation. The problem of generating solutions for such representations has been studied extensively (Hansen & Zilberstein, 2001; Jiménez & Torras, 2000; Chakrabarti, 1994). Dechter and Mateescu (2007) have presented the explicit AND/OR search space perspective for graphical models. Different search strategies (best first, branch and bound, etc.) over the AND/OR search spaces in graphical models are discussed by Marinescu and Dechter (2007b, 2006). AND/OR search spaces are also used for solving mixed integer linear programming (Marinescu & Dechter, 2005), 0/1 integer Programming (Marinescu & Dechter, 2007a), combinatorial optimization in graphical models (Marinescu & Dechter, 2009a, 2009b). AND/OR Multivalued Decision Diagrams (AOMDD), which combine the idea of Multi-Valued Decision Diagrams(MDD) and AND/OR structures, is presented by Mateescu, Dechter, and Marinescu (2008) and further research along this direction can be found in the work of Mateescu and Dechter (2008). AND/OR search spaces are also applied for solution sampling and counting (Gogate & Dechter, 2008). Smooth Deterministic Decomposable Negative Normal Forms (sd-DNNF) (Darwiche, 2001) exhibit explicit AND/OR DAG structure and have been used for various applications including compiling knowledge (Darwiche, 1999), estimating belief states (Elliott & Williams, 2006), etc.\nApart from the domains of planning, constraint satisfaction, knowledge based reasoning, etc., AND/OR structure based techniques are also widely used for various application based domains, e.g., web service composition (Gu, Xu, & Li, 2010; Shin, Jeon, & Lee, 2010; Gu, Li, & Xu, 2008; Ma, Dong, & He, 2008; Yan, Xu, & Gu, 2008; Lang & Su, 2005), vision and graphics tasks (Chen, Xu, Liu, & Zhu, 2006), etc. Lang and Su (2005) have described an AND/OR graph search algorithm for composing web services for user requirements. Ma et al. (2008) have advocated the use of AND/OR trees to capture dependencies between the inputs and outputs of the component web services and propose a top-down search algorithm to generate solutions of the AND/OR tree. Further research that uses AND/OR structures in the context of web service composition can be found in the works of Gu et al. (2010, 2008), Shin et al. (2010) and Yan et al. (2008). Chen et al. (2006) have applied explicit AND/OR structures for cloth modeling and recognition which is an important problem in vision and graphics tasks.\nSuch recent adoption of AND/OR search spaces for a wide variety of AI problems warrants further research towards developing suitable algorithms for searching AND/OR structures from different perspectives. In the general setting, the fundamental problem remains to find the minimum cost solution of AND/OR structures. For a given explicit AND/OR graph structure, the minimum cost solution is computed using either a topdown or a bottom-up approach. These approaches are based on the principle of dynamic programming and have complexity which is linear with respect to the size of the search space. Finding a minimum cost solution of an explicit AND/OR structure is a fundamental step for the approaches that use an implicit representation and systematically explore the search space. This is particularly the case for AO* (Nilsson, 1980) where the potential solution graph (psg) is recomputed every time from the current explicit graph after a node is expanded. In view of recent research where AND/OR structures are used and leveraged in a wide variety of problems ranging from planning domain to web service composition, the need for generating an ordered set of solutions of a given AND/OR structure becomes imminent. We briefly mention some areas where ordered solutions are useful.\nOrdered set of solutions of an explicit AND/OR DAG can be used to develop useful variants of the AO* algorithm. Currently in AO*, only the minimum cost solution is computed whereas several variants of the A* algorithm exist, where solutions are often sought within a factor of cost of the optimal solution. These approaches (Ebendt & Drechsler, 2009; Pearl, 1984) were developed to adapt the A* algorithm for using inadmissible heuristics, leveraging multiple heuristics (Chakrabarti, Ghose, Pandey, & DeSarkar, 1989), generating solutions quickly within bounded sub-optimality, etc. Typically these techniques order the Open list using one evaluation function, and the next element for expansion is selected from an ordered subset of Open using some other criterion. Similar techniques can be developed for AO* search if ordered set of potential solutions are made available. That set can be used for node selection and expansion instead of expanding nodes only from the current best psg. This opens up an interesting area with significant research potential where the existing variations of the A* algorithm can be extended for AND/OR search spaces.\nIn the context of model based programming, the problem of finding ordered set of solutions has significant importance. Elliott (2007) has used valued sd-DNNFs to represent the problem and proposed an approach to generate k-best solutions. Since valued sd-DNNFs have an AND/OR structure, the proposed approach is possibly the earliest algorithm for generating ordered set of solutions of an AND/OR structure. The problem of finding ordered set of solutions for graphical models is studied by Flerova and Dechter (2011, 2010). However these techniques use alternative representations for the algorithm, where AND/OR search spaces can be constructed (Dechter & Mateescu, 2007) for graphical models. Recent research involving AOMDD based representation on weighted structures suggested future extensions towards generalizing Algebraic Decision Diagrams and introduces the notion of cost in AOMDDs. We envisage that ordered set of solutions finds useful applications in the context of research around AND/OR decision diagram based representation.\nIn the domain of service composition, the primary motivation behind providing a set of alternative solutions ordered by cost is to offer more choices, while trading off the specified cost criterion (to a limited extent) in favor of other ‘unspecified’ criteria (primarily from the standpoint of quality). Shiaa, Fladmark, and Thiell (2008) have presented an approach for generating a ranked set of solutions for the service composition problem. Typically the quality criteria are subjective in nature and difficult to express in terms of a single scalar cost function which is able to combine the cost/price and the quality aspects together. These aspects of quality are often encountered in the context of serving custom user requirements where the user prefers to minimize the cost/price of the solution while preserving his/her preferences. For example, for booking a holiday package for a specific destination, a travel service portal typically offers a list of packages with various combinations of attractions, hotel options and meal plans ordered by a single cost criterion, namely, the cost of the package. In general any product/solution that is composed of a number of components has a compositional flavor similar to service composition and it becomes important to present the user a set of alternative solutions ordered by cost so that he/she can select the best alternative according to his/her preferences.\nDynamic programming formulations typically have an underlying AND/OR DAG structure, which had been formally studied in the past (Martelli & Montanari, 1973). Besides classical problems like matrix chain multiplication, many other real world optimization problems offer dynamic programming formulations, where alternative solutions ordered by cost\nare useful in practice. One example of such a problem is finding the secondary structure of RNA (Mathews & Zuker, 2004) which is an important problem in Bioinformatics. RNAs may be viewed as sequences of bases belonging to the set {Adenine(A), Cytocine(C), Guanine(G), Uracil(U)}. RNA molecules tend to loop back and form base pairs with itself and the resulting shape is called the secondary structure. The primary factor that influences the secondary structure of RNA is the number of base pairings (higher number of base pairings generally implies more stable secondary structure). Under the well established rules for base pairings, the problem of maximizing the number of base pairings has an interesting dynamic programming formulation. However, apart from the number of base pairings, there are other factors that influence the stability, but these factors are typically evaluated experimentally. Therefore, for a given RNA sequence, it is useful to compute a pool of candidate secondary structures (in decreasing order of the number of base pairings) that may be subjected to further experimental evaluation in order to determine the most stable secondary structure.\nThe problem of generating ordered set of solutions is well studied in other domains. For discrete optimization problems, Lawler (1972) had proposed a general procedure for generating k-best solutions. A similar problem of finding k most probable configurations in probabilistic expert systems is addressed by Nilsson (1998). Fromer and Globerson (2009) have addressed the problem of finding k maximum probability assignments for probabilistic modeling using LP relaxation. In the context of ordinary graphs, Eppstein (1990) has studied the problem of finding k-smallest spanning trees. Subsequently, an algorithm for finding k-best shortest paths has been proposed in Eppstein’s (1998) work. Hamacher and Queyranne (1985) have suggested an algorithm for k-best solutions to combinatorial optimization problems. Algorithms for generating k-best perfect matching are presented by Chegireddy and Hamacher (1987). Other researchers applied the k-shortest path problem to practical scenarios, such as, routing and transportation, and developed specific solutions (Takkala, Borndörfer, & Löbel, 2000; Subramanian, 1997; Topkis, 1988; Sugimoto & Katoh, 1985). However none of the approaches seems to be directly applicable for AND/OR structures. Recently some schemes related to ordered solutions to graphical models (Flerova & Dechter, 2011, 2010) and anytime AND/OR graph search (Otten & Dechter, 2011) have been proposed. Anytime algorithms for traditional OR search space (Hansen & Zhou, 2007) are well addressed by the research community.\nIn this paper, we address the problem of generating ordered set of solutions for explicit AND/OR DAG structure and present new algorithms. The existing method, proposed by Elliott (2007), works bottom-up by computing k-best solutions for the current node from the k-best solutions of its children nodes. We present a best first search algorithm, named Alternative Solution Generation (ASG) for generating ordered set of solutions. The proposed algorithm maintains a list of candidate solutions, initially containing only the optimal solution, and iteratively generates the next solution in non-decreasing order of cost by selecting the minimum cost solution from the list. In each iteration, this minimum cost solution is used to construct another set of candidate solutions, which is again added to the current list. We present two versions of the algorithm –\na. Basic ASG (will be referred to as ASG henceforth) : This version of the algorithm may construct a particular candidate solution more than once;\nb. Lazy ASG or LASG : Another version of ASG algorithm that constructs every candidate solution only once. In these algorithms, we use a compact representation, named signature, for storing the solutions. From the signature of a solution, the actual explicit form of that solution can be constructed through a top-down traversal of the given DAG. This representation allows the proposed algorithms to work in a top-down fashion starting from the initial optimal solution. Another salient feature of our proposed algorithms is that these algorithms work incrementally unlike the existing approach. Our proposed algorithms can be interrupted at any point of time during the execution and the set of ordered solutions obtained so far can be observed and subsequent solutions will be generated when the algorithms are resumed again. Moreover, if an upper limit estimate on the number of solutions required is known a priori, our algorithms can be further optimized using that estimate.\nThe rest of the paper is organised as follows. The necessary formalisms and definitions are presented in Section 2. In Section 3, we address the problem of generating ordered set of solutions for trees. Subsequently in Section 4, we address the problem of finding alternative solutions of explicit acyclic AND/OR DAGs in non-decreasing order of cost. We present two different solution semantics for AND/OR DAGs and discuss the existing approach as well as our proposed approach, along with a comparative analysis. Detailed experimental results, including the comparison of the performance of the proposed algorithms with the existing algorithm (Elliott, 2007), are presented in Section 5. We have used randomly constructed trees and DAGs as well as some well-known problem domains including the 5-peg Tower of Hanoi problem, the matrix-chain multiplication problem and the problem of finding the secondary structure of RNA as test domain. The time required and the memory used for generating a specific number of ordered solutions for different domains are reported in detail. In Section 6, we outline briefly about applying the proposed algorithms for implicitly specified AND/OR structures. Finally we present the concluding remarks in Section 7."
    }, {
      "heading" : "2. Definitions",
      "text" : "In this section, we describe the terminology of AND/OR trees and DAGs followed by other definitions that are used in this paper. Gαβ = 〈V,E〉 is an AND/OR directed acyclic graph, where V is the set of nodes and E is the set of edges. Here α and β in Gαβ refer to the AND nodes and OR nodes in the DAG respectively. The direction of edges in Gαβ is from the parent node to the child node. The nodes of Gαβ with no successors are called terminal nodes. The non-terminal nodes of Gαβ are of two types – i) OR nodes and ii) AND nodes . Vα and Vβ are the set of AND and OR nodes in Gαβ respectively, and nαβ = |V |, nα = |Vα|, and nβ = |Vβ |. The start (or root) node of Gαβ is denoted by vR. OR edges and AND edges are the edges that emanate from OR nodes and AND nodes respectively.\nDefinition 2.a [Solution Graph] A solution graph, S(vq), rooted at any node vq ∈ V , is a finite sub-graph of Gαβ defined as:\na. vq is in S(vq); b. If v′q is an OR node in Gαβ and v ′ q is in S(vq), then exactly one of its immediate\nsuccessors in Gαβ is in S(vq); c. If v′q is an AND node in Gαβ and v ′ q is in S(vq), then all its immediate successors in\nGαβ are in S(vq);\nd. Every maximal (directed) path in S(vq) ends in a terminal node; e. No node other than vq or its successors in Gαβ is in S(vq).\nBy a solution graph S of Gαβ we mean a solution graph with root vR. ⊓⊔ Definition 2.b [Cost of a Solution Graph] In Gαβ , every edge eqr ∈ E from node vq to node vr has a finite non-negative cost ce(〈vq, vr〉) or ce(eqr). Similarly every node vq has a finite non-negative cost denoted by cv(vq). The cost of a solution S is defined recursively as follows. For every node vq in S, the cost C(S, vq) is:\nC(S, vq) =\n \n\ncv(vq), if vq is a terminal node; cv(vq) + { C(S, vr) + ce(〈vq, vr〉) } , where vq is an OR node, and\nvr is the successor of vq in S;\ncv(vq) + ∑{ C(S, vj) + ce(〈vq, vj〉) } , where 1 ≤ j ≤ k, vq is an AND node\nwith degree k, and v1, . . . , vk are the immediate successors of vq in S.\nTherefore the cost of a solution S is C(S, vR) which is also denoted by C(S). We denote the optimal solution below every node vq as opt(vq). Therefore, the optimal solution of the entire AND/OR DAG Gαβ , denoted by Sopt, is opt(vR). The cost of the optimal solution rooted at every node vq in Gαβ is Copt(vq), which is defined recursively (for minimum cost objective functions) as follows:\nCopt(vq) =\n \n\ncv(vq), if vq is a terminal node; cv(vq) +min { Copt(vj) + ce(〈vq, vj〉) } , where 1 ≤ j ≤ k, vq is an OR node\nwith degree k, and v1, . . . , vk are the immediate successors of vq in Gαβ ;\ncv(vq) + ∑{ Copt(vj) + ce(〈vq, vj〉) } , where 1 ≤ j ≤ k, vq is an AND node\nwith degree k, and v1, . . . , vk are the immediate successors of vq in Gαβ .\nThe cost of the optimal solution Sopt of Gαβ is denoted by Copt(vR) or, alternatively, by Copt(Sopt). When the objective function needs to be maximized, instead of themin function, the max function is used in the definition of Copt(vq). ⊓⊔\nIt may be noted that it is possible to have more than one solution below an OR node vq to qualify to be the optimal one, i.e., when they have the same cost, and that cost is the minimum. Ties for the optimal solution below any such OR node vq are resolved arbitrarily and only one among the qualifying solutions (determined after tie-breaking) is marked as opt(vq).\nAn AND/OR tree, Tαβ = 〈V,E〉, is an AND/OR DAG and additionally satisfies the restrictions of a tree structure i.e., there can be at most one parent node for any node vq in Tαβ. In the context of AND/OR trees, we use eq to denote the edge that points to the vertex vq. An alternating AND/OR tree, T̂αβ = 〈V,E〉, is an AND/OR tree with the restriction that there is an alternation between the AND nodes and the OR nodes. Every child of an AND node is either an OR node or a terminal node, and every children of an OR node is either an AND node or a terminal node. We use the term solution tree to denote the solutions of AND/OR trees.\nWe also discuss a different solution semantics, namely tree based semantics, for AND/OR DAGs. Every AND/OR DAG can be converted to an equivalent AND/OR tree by traversing\nthe intermediate nodes in reverse topological order and replicating the subtree rooted at every node whenever the in-degree of the traversed node is more than 1. The details are shown in Procedure ConvertDAG. Suppose an AND/OR DAG Gαβ is converted to an equivalent AND/OR tree Tαβ . We define the solutions of Tαβ as the solutions of Gαβ under tree based semantics.\nProcedure ConvertDAG(Gαβ)\ninput : An AND/OR DAG Gαβ output: An equivalent AND/OR tree Tαβ Construct a list M , of non-terminal nodes of Gαβ , sorted in the reverse topological1 order; while M is not empty do2 vq ← Remove the first element of M ;3 /* Suppose Ein(vq) is the list of incoming edges of vq */ if InDegree(vq) > 1 then4 for i ← 2 to InDegree(vq) do5 et ← Ein(vq)[i];6 Replicate the sub-tree rooted at vq with v ′ q as the root;7 Modify the target node of et from vq to v ′ q;8 end9\nend10\nend11\nIn this paper we use the solution semantics defined in Definition 2.a as the default semantics for the solutions of AND/OR DAGs. When the tree based semantics is used, it is explicitly mentioned.\n2.1 Example\nv1 2, 89\nv2 3, 43\n〈1〉\nv3 2, 41\n〈2〉\nv4 40\n〈1〉\nv5 2, 35\n〈5〉 〈4〉\nv6 52\n〈1〉\nv7 3, 9\n〈4〉\nv8 17\n〈3〉\nv9\n5\n〈1〉\nv10\n7\n〈2〉\nFigure 2: AND/OR DAG\nWe present an example of an alternating AND/OR tree in Figure 1. In the figure, the terminal nodes are represented by a circle with thick outline. AND nodes are shown in the figures with their outgoing edges connected by a semi-circular curve in all the examples. The edge costs are shown by the side of each edge within an angled bracket. The cost of the terminal nodes are shown inside a box. For every non-terminal node vq, the pair of costs, cv(vq) and Copt(vq), is shown inside a rectangle.\nIn Figure 1 the optimal solution below every node is shown using by thick dashed edges with an arrow head. The optimal solution of the AND/OR tree can be traced by following these thick dashed edges from node v1. The cost of the optimal solution tree is 34. Also, Figure 2 shows an example of a DAG; the cost of the optimal solution DAG is 89."
    }, {
      "heading" : "3. Generating Ordered Solutions for AND/OR Trees",
      "text" : "In this section we address the problem of generating ordered solutions for trees. We use the notion of alternating AND/OR trees, defined in Section 2, to present our algorithms. An alternating AND/OR tree presents a succinct representation and so the correctness proofs are much simpler for alternating AND/OR trees. In Appendix C we show that every AND/OR tree can be converted to an equivalent alternating AND/OR tree with respect to the solution space.\nIt is worth noting that the search space of some problems (e.g. the search space of multipeg Tower of Hanoi problem) exhibit the alternating AND/OR tree structure. Moreover, the algorithms that are presented for alternating AND/OR trees work without any modification for general AND/OR trees. In this section, first we present the existing algorithm (Elliott, 2007) briefly, and then we present our proposed algorithms in detail."
    }, {
      "heading" : "3.1 Existing Bottom-Up Evaluation Based Method for Computing Alternative Solutions",
      "text" : "We illustrate the working of the existing method that is proposed by Elliott (2007) for computing alternative solutions for trees using an example of an alternating AND/OR tree. This method (will be referred as BU henceforth) computes the k-best solutions in a bottomup fashion. At every node, vq, k-best solutions are computed from the k-best solutions of the children of vq. The overall idea is as follows.\na. For an OR node vq, a solution rooted at vq is obtained by selecting a solution of a child. Therefore k-best solutions of vq are computed by selecting the top k solutions from the entire pool consisting of all solutions of all children. b. In the case of AND nodes, every child of an AND node vq will have at most k solutions. A solution rooted at an AND node vq is obtained by combining one solution from every child of vq. Different combinations of the solutions of the children nodes of vq generate different solutions rooted at vq. Among those combinations, top k combinations are stored for vq. In Figure 3 we show the working of the existing algorithm. At every intermediate node 2-best solutions are shown within rounded rectangle. At every OR node vq, the i\nth-best solution rooted at vq is shown as a triplet of the form – i︸︷︷︸ : < child, solidx >︸ ︷︷ ︸ , cost ︸︷︷︸ . For example, at node v1 the second best solution is shown as – 2 : 〈v2, 2〉, 37; which means\nthat the 2nd best solution rooted at v1 is obtained by selecting the 2 nd best solution of v2. Similarly, at every AND node vq, the i th solution rooted at vq is shown as a triplet of the form – i : |sol vec|, cost triplets. Here sol vec is a comma separated list of solution indices such that every element of sol vec corresponds to a child of vq. The j\nth element of sol vec shows the index of the solution of jth child. For example, the 2nd best solution rooted at v2 is shown as – 2 : |2, 1|, 32. This means the 2nd best solution rooted at v2 is computed using the 2nd best solution of the 1st child (which is v5) and the best solution (1 st) of the 2nd child (which is v6). Which index of sol vec corresponds to which child is shown by placing the child node name above every index position.\nThe existing method works with the input parameter k, i.e., the number of solutions to be generated have to be known a priori. Also this method is not inherently incremental in nature, thus does not perform efficiently when the solutions are needed on demand, e.g., at first, top 20 solutions are needed, then the next 10 solutions are needed. In this case the top 20 solutions will have to be recomputed while computing next 10 solutions, i.e., from the 21st solution to the 30th solution. Next we present our proposed top-down approach which does not suffer from this limitation."
    }, {
      "heading" : "3.2 Top-Down Evaluation Algorithms for Generating Ordered Solutions",
      "text" : "So far we have discussed the existing approaches which primarily use bottom-up approach for computing ordered solutions. Now we propose a top-down approach for generating alternative solutions in the non-decreasing order of cost. It may be noted that the top-down\napproach is incremental in nature. We use an edge marking based algorithm, Alternative Solution Generation (ASG), to generate the next best solutions from the previously generated solutions. In the initial phase of the ASG algorithm, we compute the optimal solution for a given alternating AND/OR tree T̂αβ and perform an initial marking of all OR edges. The following terminology and notions are used to describe the ASG algorithm. In the context of AND/OR trees, we use eq to denote the edge that points to the vertex vq. We will use the following definitions for describing our proposed top-down approaches.\nDefinition 3.c [Aggregated Cost] In an AND/OR DAG Gαβ , the aggregated cost, ca, for an edge eij from node vi to node vj , is defined as : ca(eij) = ce(eij) + Copt(vj). ⊓⊔\nMarking of an OR edge : The notion of marking an OR edge is as follows. For an OR node vq, L(vq) is the list of OR edges of vq sorted in non-decreasing order of the aggregated cost of the edges. We define δ(i,i+1) as the difference between the cost of OR edges, ei and ei+1, such that ei and ei+1 emanate from the same OR node vq, and ei+1 is the edge next to ei in L(vq). Procedure MarkOR describes the marking process for the OR edges of an OR node. Intuitively, a mark represents the cost increment incurred when the corresponding edge is replaced in a solution by its next best sibling. The OR edge having maximum aggregated cost is not marked.\nConsider a solution, Scur, containing the edge ei = (vq, vi), where ei ∈ Eopt(Scur). We mark ei with the cost increment which will be incurred to construct the next best solution from Scur by choosing another child of vq. In Figure 4 the marks corresponding to OR edges e2, e3, e9, e11, e13, and e14 are [e2 : 5], [e3 : 1], [e9 : 3], [e11 : 4], [e13 : 3], and [e14 : 6].\nProcedure MarkOR(vq)\nConstruct L(vq) ; /* List of OR edges of vq sorted in the non-decreasing order of ca1 values */ count ← number of elements in L(vq) ;2 for i ← 1 to i = count− 1 do3 ec ← L(vq)[i] ;4 en ← L(vq)[i + 1] ;5 δtmp = (ca(en)− ca(ec)) ;6 Mark ec with the pair [en : δtmp] ;7 end8\nDefinition 3.d [Swap Option] A swap option σij is defined as a three-tuple 〈ei, ej , δij〉 where ei and ej emanate from the same OR node vq, ej is the edge next to ei in L(vq), and δij = ca(ej)− ca(ei). Also, we say that the swap option σij belongs to the OR node vq. ⊓⊔\nConsider the OR node vq and the sorted list L(vq). It may be observed that in L(vq) every consecutive pair of edges forms a swap option. Therefore, if there are k edges in L(vq), k−1 swap options will be formed. At node vq, these swap options are ranked according to the rank of their original edges in L(vq). In Figure 4 the swap options are : σ(2,3) = 〈e2, e3, 5〉, σ(3,4) = 〈e3, e4, 1〉, σ(9,10) = 〈e9, e10, 3〉, σ(11,12) = 〈e11, e12, 4〉, σ(13,14) = 〈e13, e14, 3〉, and σ(14,15) = 〈e14, e15, 6〉. Consider the node v1 where L(v1) = 〈e2, e3, e4〉. Therefore, the swap options, σ(2,3) and σ(3,4), belong to v1. At node v1, the rank of σ(2,3) and σ(3,4) are 1 and 2 respectively.\nDefinition 3.e [Swap Operation] Swap operation is defined as the application of a swap option σij = 〈ei, ej , δij〉 to a solution Sm that contains the OR edge ei in the following way:\na. Remove the subtree rooted at vi from Sm. Let the modified tree be S ′ m. Edge ei is\nthe original edge of σij . b. Add the subtree opt(vj) to S ′ m, which is constructed at the previous step. Let the\nnewly constructed solution be S′′m. Edge ej is the swapped edge of σij. Intuitively, a swap operation σij = 〈ei, ej , δij〉 constructs a new solution S′m from Sm when Sm contains the OR edge ei. Moreover, the cost of S ′ m is increased by δij compared to cost of Sm if C(Sm, vi) = Copt(vi). ⊓⊔ Our proposed algorithms use a swap option based compact representation, named signature, for storing the solutions. Intuitively, any alternative solution can be described as a set of swap operations performed on the optimal solution Sopt. It is interesting to observe that while applying an ordered sequence of swap options, 〈σ1, · · · , σk〉, the application of each swap operation creates an intermediate alternative solution. For example, when the first swap option in the sequence, σ1, is applied to the optimal solution, Sopt, a new solution, say S1, is constructed. Then, when the 2\nnd swap option, σ2, is applied to S1, yet another solution S2 is constructed. Let Si denote the solution obtained by applying the swap options, σ1, · · · , σi, on Sopt in this sequence. Although, an ordered sequence of swap options, like 〈σ1, · · · , σk〉, can itself be used as a compact representation of an alternative solution, the following key points are important to observe. A. Among all possible sequences that generate a particular solution, we need to preclude\nthose sequences which contain redundant swap options (those swap options whose orig-\ninal edge is not present in the solution to which it is applied). This is formally defined later as superfluous swap options. Also the order of applying the swap options is another important aspect. There can be two swap options, σi and σj where 1 ≤ i < j ≤ k such that the source edge of σj belongs to the sub-tree which is included in the solution Si only after applying σi to Si−1. In this case, if we apply σj at the place of σi, i.e., apply σj directly to Si−1, it will have no effect as the source edge of σj is not present in Si−1, i.e., after swapping the location of σi and σj in the sequence, σj becomes a redundant swap option and the solution constructed would be different for the swapped sequence from the original sequence. We formally define an order relation on a pair of swap options based on this observation in the later part of this section and formalize the compact representation of the solutions based on that order relation. B. Suppose the swap option σj belongs to a node vpj . Now it is important to observe that the application of σj on Sj−1 to construct Sj, invalidates the application of all other swap options that belong to an OR edge in the path from the root node to vpj in the solution Sj . This is because in Sj the application of any such swap option which belongs to an OR edge in the path from the root node to vpj would make the swap at vpj redundant. In fact, for each swap option σi belonging to node vpi , where 1 ≤ i ≤ j, the application of all other swap options that belong to an OR edge in the path from the root node to vpi is invalidated in the solution Sj for the same reason. This condition restricts the set of swap options that can be applied on a particular solution. C. Finally, there can be two swap options σi and σj for 1 ≤ i < j ≤ k such that σi and σj are independent of each other, that is, (a) applying σi to Si−1 and subsequently the application of σj to Sj−1, and (b) applying σj to Si−1 and subsequently the application of σi to Sj−1, ultimately construct the same solution. This happens only when the original edges of both σi and σj are present in Si−1, thus application of one swap option does not influence the application of the other. However, it is desirable to use only one way to generate solution Sj . In Section 3.3, we propose a variation of the top-down approach (called LASG) which resolves this issue.\nDefinition 3.f [Order Relation R̂] We define an order relation, namely R̂, between a pair of swap options as follows.\na. If there is a path from vi to vr in T̂αβ , where ei and er are OR edges, σqi and σrj are\nswap options, then (σqi, σrj) ∈ R̂. For example, in Figure 4 (σ(3,4), σ(13,14)) ∈ R̂. b. If σpq = 〈ep, eq, δpq〉 and σrt = 〈er, et, δrt〉 are two swap options such that vq = vr,\nthen (σpq, σrt) ∈ R̂. In Figure 4 (σ(2,3), σ(3,4)) ∈ R̂. ⊓⊔\nImplicit Representation of the Solutions : We use an implicit representation for storing every solution other than the optimal one. These other solutions can be constructed from the optimal solution by applying a set of swap options to the optimal solution in the following way. If (σi, σj) ∈ R̂, σi has to be applied before σj. Therefore, every solution is represented as a sequence Σ̂ of swap options, where σi appears before σj in Σ̂ if (σi, σj) ∈ R̂. Intuitively the application of every swap option specifies that the swapped edge will be the part of the solution. Since the swap options are applied in the specific order R̂, it may so happen that an OR edge which had become the part of solution due to the application of an earlier swap option and may get swapped out due to the application of a later swap option.\nDefinition 3.g [Superfluous Swap Option] Consider a sequence of swap options Σ̂ = 〈σ1, · · · , σm〉 corresponding to a solution Sm. Clearly it is possible for a swap option, σi, where 1 ≤ i ≤ m, to be present in the sequence such that the original edge of σi is not present in the solution Si−1 which is constructed by the successive applications of swap options σ1, · · · , σi−1 to solution Sopt. Now the application of σi has no effect on Si−1, i.e., solution Si is identical to solution Si−1. Each such swap option σi is a superfluous swap option with respect to the sequence Σ̂ of swap options corresponding to solution Sm. ⊓⊔\nProperty 3.1 The sequence of swap options corresponding to a solution is minimal, if it has no superfluous swap option.\nThis property follows from the definition of superfluous swap options and the notion of the implicit representation of a solution.\nDefinition 3.h [Signature of a Solution] The minimal sequence of swap options corresponding to a solution, Sm, is defined as the signature, Sig(Sm), of that solution. It may be noted that for the optimal solution Sopt of any alternating AND/OR tree T̂αβ , Sig(Sopt) = {}, i.e., an empty sequence. It is possible to construct more than one signature for a solution, as R̂ is a partial order. It is important to observe that all different signatures for a particular solution are of equal length and the sets of swap options corresponding to these different signatures are also equal. Therefore the set of swap options corresponding to a signature is a canonical representation of the signature. Henceforth we will use the set notation for describing the signature of a solution.\nIn Figure 5 we show a solution, say S2, of the AND/OR tree shown in Figure 4. The solution is highlighted using thick dashed lines with arrow head. The pair, cv(vq), C(S2, vq),\nis shown within rectangles beside each node vq in solution S2, and we have used the rectangles with rounded corner whenever C(S2, vq) 6= Copt(vq). Since S2 is generated by applying the swap option σ(2,3) to solution Sopt, the signature of S2, Sig(S2) = 〈σ(2,3)〉. Consider another sequence, Σ̂2 = 〈σ(2,3), σ(9,10)〉, of swap options. It is worth noting that Σ̂2 also represents the solution S2. Here the second swap option in Σ̂2, namely σ9,10, can not be applied to the solution constructed by applying σ(2,3) to Sopt as the source edge of σ(9,10), e9, is not present in that solution. Hence σ(9,10) is a superfluous swap option for Σ̂2 .\nDefinition 3.i [Vopt and Eopt] For any solution graph Sm of an AND/OR DAG Gαβ , we define a set of nodes, Vopt(Sm), and a set of OR edges, Eopt(Sm), as:\na. Vopt(Sm) = { vq ∣ ∣ vq in Sm and solution graph Sm(vq) is identical to the solution graph\nopt(vq) }\nb. Eopt(Sm) = { epr ∣ ∣ OR edge epr in Sm, and vr ∈ Vopt(Sm) }\nClearly, for any node vq ∈ Vopt(Sm), if vq is present in Sopt, then – (a) the solution graph Sm(vq) is identical to the solution graph Sopt(vq), and (b) C(Sm, vq) = Copt(vq) ⊓⊔\nDefinition 3.j [Swap List] The swap list corresponding to a solution Sm, L(Sm), is the list of swap options that are applicable to Sm. Let Sig(Sm) = {σ1, · · · , σm} and ∀i, 1 ≤ i ≤ m, each swap option σi belongs to node vpi . The application of all other swap options that belong to the OR edges in the path from the root node to vpi is invalidated in the solution Sm. Hence, only the remaining swap options that are not invalidated in Sm can be applied to Sm for constructing the successor solutions of Sm.\nIt is important to observe that for a swap option σi, if the source edge of σi belongs to Eopt(Sm), the application is not invalidated in Sm. Hence, for a solution Sm, we construct L(Sm) by restricting the swap operations only on the edges belonging to Eopt(Sm). Moreover, this condition also ensures that the cost of a newly constructed solution can be computed directly form the cost of the parent solution and the δ value of the applied swap option. To elaborate, suppose solution S′m is constructed form Sm by applying σjk. The cost of S′m can be computed directly form C(Sm) and σjk as : C(S ′ m) = C(Sm) + δjk if ej ∈ Eopt(Sm). Procedure ComputeSwapList(Sm) describes the details of computing swap options for a given solution Sm. ⊓⊔\nProcedure ComputeSwapList(Sm) L(Sm) ← ∅; Compute Eopt(Sm);1 foreach OR edge ec in Eopt(Sm) do2 if there exists a swap option on edge ec then3 /* Suppose ec emanates from OR node vq such that ec = L(vq)[i]. Also ec is marked with the pair 〈δtmp, en〉, where en = L(vq)[i+ 1] */ σcn ← 〈ec, en, δtmp〉; Add σcn to L(Sm);4 end5\nend6\nThe swap list of the optimal solution, L(Sopt), in Figure 4, is {σ(2,3), σ(9,10)}. In the solution S1, shown in Figure 6, Vopt = {v6, v10}, because except node v6 and v10, for all other nodes vi in S1, opt(vi) 6= S1(vi). Here also rectangles with rounded corner are used when C(S1, vq) 6= Copt(vq). Therefore, Eopt = {e6, e10}. Since there exists no swap option\non the OR edges, e6 and e10, the swap list of solution S1, L(S1) = ∅. Hence, for a solution Sm, L(Sm) may be empty, though Vopt(Sm) can never be empty.\nAlthough we use the notation σij to denote a swap option with edge ei as the original edge and edge ej as the swapped edge, for succinct representation, we also use σ with a single subscript, such as σ3, σk, σij etc., to represent a swap option. This alternative representation of swap options does not relate to any edge.\nDefinition 3.k [Successors and Predecessors of a Solution] The set of successors and predecessors of a solution Sm is defined as:\na. Succ(Sm) = {S′m ∣ ∣ S′m can be constructed from Sm by applying a swap option that\nbelongs to the swap list of Sm} b. Pred(Sm) = {S′′m ∣ ∣ Sm ∈ Succ(S′′m)} ⊓⊔\nProperty 3.2 For any solution Sm of an alternating AND/OR tree T̂αβ the following statement holds: ∀S′m ∈ Pred(Sm), C(S′m) ≤ C(Sm)\nThe property follows from the definitions. One special case requires attention. Consider the case when C(S′m) = C(Sm) and S ′ m ∈ Pred(Sm). This case can only arise when a swap option of cost 0 is applied to Sm. This occurs in the case of a tie."
    }, {
      "heading" : "3.2.1 ASG Algorithm",
      "text" : "We present ASG, a best first search algorithm, for generating solutions for an alternating AND/OR tree in non-decreasing order of costs. The overall idea of this algorithm is as follows. We maintain a list, Open, which initially contains only the optimal solution Sopt. At any point of time Open contains a set of candidate solutions from which the next best\nsolution in the non-decreasing order of cost is selected. At each iteration the minimum cost solution (Smin) in Open is removed from Open and added to another list, named, Closed. The Closed list contains the set of ordered solutions generated so far. Then the successor set of Smin is constructed and any successor solution which is not currently present in Open as well as is not already added to Closed is inserted to Open. However as a further optimization, we use a sublist of Closed, named TList, to store the relevant portion of Closed such that checking with respect to the solutions in TList is sufficient to figure out whether the successor solution is already added to Closed. It is interesting to observe that this algorithm can be interrupted at any time and the set of ordered solutions computed so far can be obtained. Also, the algorithm can be resumed if some more solutions are needed. The details of ASG algorithm are presented in Algorithm 4.\nAlgorithm 4: Alternative Solution Generation (ASG) Algorithm\ninput : An alternating AND/OR tree T̂αβ output: Alternative solutions of T̂αβ in the non-decreasing order of cost Compute the optimal solution Sopt, perform OR edge marking and populate the1 swap options; Create three lists, Open, Closed, and TList, that are initially empty;2 Put Sopt in Open;3 lastSolCost ← C(Sopt);4 while Open is not empty do5 Smin ← Remove the minimum cost solution from Open ;6 if lastSolCost < C(Smin) then7 Remove all the elements of TList;8 lastSolCost ← C(Smin);9\nend10 Add Smin to Closed and TList;11 Compute the swap list, L(Smin), of Smin;12 /* Construct Succ(Smin) using L(Smin) and add new solutions to Open */ foreach σij ∈ L(Smin) do13 Construct Sm by applying σij to Smin;14 Construct the signature of Sm, Sig(Sm), by concatenating σij after Sig(Smin);15 /* Check whether Sm is already present in Open or in TList */ if (Sm not in Open) and (Sm not in TList) then16 Add Sm to Open;17 end18\nend19 Report the solutions in Closed;20\nThe pseudo-code from Line-1 to Line-4 computes the optimal solution Sopt, performs the marking of OR edges, populates the swap options, and initializes Open, Closed and TList. The loop in Line-10 is responsible for generating a new solution every time it is executed as long as Open is not empty. In Line-6 of the ASG algorithm, the solution that is the current minimum cost solution in Open (Smin) is selected and removed from Open. The TList is populated and maintained from Line-7 to Line-10. The loop in Line-13 generates\nthe successor solutions of Smin one by one and adds the newly constructed solutions to Open if the newly constructed solution is not already present in Open as well as not added to TList (Line-16 does the checking). The proof of correctness of Algorithm 4 is presented in Appendix A. We discuss the following issues related to Algorithm 4.\nChecking for Duplication : In order to check whether a particular solution Si is already present in Open or TList, the signature of Si is matched with the signatures of the solutions that are already present in Open and TList. It is sufficient to check the equality between the set of swap options in the respective signatures because that set is unique for a particular solution. It may be noted that TList is used as an optimization, which avoids searching the entire Closed list.\nResolving Ties : While removing the minimum cost solution from the Open list, a tie may be encountered among a set of solutions. Suppose there is a tie among the set Stie = {S1, · · · , Sk}. The ties are resolved in the favor of the predecessor solutions, that is,\n( ∀Si, Sj ∈ Stie ) , [ (If Si is the predecessor of Sj) ⇒ (Si is removed before Sj) ]\nFor all other cases the ties are resolved arbitrarily in the favor of the solution which was added to Open first."
    }, {
      "heading" : "3.2.2 Working of ASG Algorithm",
      "text" : "We illustrate the working of the ASG algorithm on the example AND/OR tree shown in Figure 4. The contents of the different lists obtained after first few iterations of outermost while loop are shown in Table 1. We use the signature of a solution for representation purpose. The solutions that are already present in Open and also constructed by expanding the current Smin, are highlighted with under-braces.\nBefore entering the outermost while loop (Line 5), ASG computes the optimal solution Sopt, populates the swap options, and inserts Sopt to Open. Thus, at this point of time, Open contains only the optimal solution Sopt; Closed and TList are empty. In the first iteration Sopt (the signature of Sopt is {}) is selected and removed from Open. Then the swap list of Sopt, L(Sopt), is computed. L(Sopt), consists of two swap options, namely σ(2,3) and σ(9,10). ASG adds two new solutions {σ(2,3)} and {σ(9,10)} to Open. Then solution Sopt is added to both Closed and TList.\nIn the next iteration, solution {σ(9,10)} which has the minimum cost among the solutions currently in Open, is selected and removed from Open, the swap list {σ(9,10)} is computed and subsequently {σ(9,10)} is added to Open and TList. As it happens, L({σ(9,10)}) = ∅ (owing to the fact that Eopt = {e6, e10} and there exists no swap option on the OR edges, e6 and e10), thus nothing else happens in this iteration. In the next iteration, solution {σ(2,3)} is removed from Open and ultimately solution {σ(2,3), σ(3,4)} is added to Open after adding {σ(2,3)} to Closed as well as to TList. Next two iterations proceed in a similar fashion. Now, consider the 6th iteration. In this iteration, solution {σ(2,3), σ(3,4), σ(11,12)} is removed from Open, and its successor set has only one solution, {σ(2,3), σ(3,4), σ(11,12), σ(13,14)}, which is already present in Open (inserted to Open in Iteration-5). Therefore, solution {σ(2,3), σ(3,4), σ(11,12), σ(13,14)} is not inserted to Open again. We have shown up to Iteration-7 in Table 1.\n3.3 Technique for Avoiding the Checking for Duplicates in Open\nIn this section, we present a technique to avoid the checking done before adding a newly constructed solution Sm to Open to determine whether Sm is already present in Open. We first explain the scenario with an example, which is a portion of the previous example shown in Figure 4. In Figure 7-10, the solutions are shown using thick dashed line with arrow head. Also the rectangles with rounded corner are used to highlight the fact that the corresponding node in the marked solution does not belong to the Vopt set of that solution.\nv42, 37\nv73, 11\n〈4〉\nv84, 17\n〈3〉\nv11\n6\n〈2〉\nv12\n9\n〈3〉\nv13\n12\n〈1〉\nv14\n15\n〈1〉 σ11,12 : 4 σ13,14 : 3\nFigure 7: Running Example\nv42, 44\nv73, 15\n〈4〉\nv84, 20\n〈3〉\nv11\n6\n〈2〉\nv12\n9\n〈3〉\nv13\n12\n〈1〉\nv14\n15\n〈1〉\nFigure 8: Solution S3\nConsider the solutions S1, S2 and S3 (shown in Figure 9, Figure 10 and Figure 8). Here (a) L(Sopt) = {σ(11,12), σ(13,14)}, (b) Succ(Sopt) = {S1, S2}, (c) Sig(S1) = {σ(13,14)}, (d) Sig(S2) = {σ(11,12)}, and (e) Sig(S3) = {σ(13,14), σ(11,12)}. Algorithm 4 constructs the solution S3 (shown in Figure 8) for adding to Open twice – (i) as a part of adding Succ(S1) to Open, and (ii) while adding Succ(S2) to Open.\nv42, 40\nv73, 11\n〈4〉\nv84, 20\n〈3〉\nv11\n6\n〈2〉\nv12\n9\n〈3〉\nv13\n12\n〈1〉\nv14\n15\n〈1〉 σ11,12 : 4\nFigure 9: Solution S1\nv42, 41\nv73, 15\n〈4〉\nv84, 17\n〈3〉\nv11\n6\n〈2〉\nv12\n9\n〈3〉\nv13\n12\n〈1〉\nv14\n15\n〈1〉 σ13,14 : 3\nFigure 10: Solution S2\nWe use the following definitions to describe another version of the ASG algorithm, which constructs the solutions in such a way that the check to find out whether a solution is already added to Open is avoided.\nDefinition 3.l [Solution Space DAG(SSDAG)] The solution space DAG of an alternating AND/OR tree T̂αβ is a directed acyclic graph (DAG), Gs = 〈V, E〉, where V is the set of all possible solutions of the AND/OR tree T̂αβ , and E is the set of edges which is defined as:\nE =\n   espm ∣ ∣ ∣ ∣ ∣ ∣ Sp, Sm ∈ V, and espm is a directed edge from node Sp to Sm, and\nSm ∈ Succ(Sp)\n \n\nClearly Sopt is the root node of Gs. ⊓⊔ Definition 3.m [Solution Space Tree and Completeness] A solution space tree of an alternating AND/OR tree T̂αβ is a tree T s = 〈Vt, E t〉 where Vt ⊆ V, where V is the set of all possible solutions of the AND/OR tree T̂αβ, and E t is the set of edges which is defined as:\nE t =\n \n\nespm ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ Sp, Sm ∈ Vt, and espm is a directed edge from node Sp to Sm, and\nSp ∈ Pred(Sm), and ∀S′p ∈ Pred(Sm), ( (Sp 6= S′p) ⇒ there is no edge between S′p and Sm ) .\n \n\nThe sibling set for a solution Sm, is denoted using Sib(T s, Sm). A solution space tree T s for an AND/OR tree is complete if Vt = V. ⊓⊔\nIt may be noted that the complete solution space tree of an alternating AND/OR tree is not necessarily unique. It is possible for an alternating AND/OR tree to have more than one complete solution space tree. However the solution space DAG for any AND/OR tree is unique.\nDefinition 3.n [Native Swap Options of a Solution] Consider a solution Sm of an alternating AND/OR tree T̂αβ . Suppose Sm is constructed by applying swap option σij to solution Sp. Since swap option σij = 〈ei, ej , δij〉 is used to construct Sm, AND node vj is present in Sm. The native swap options of solution Sm with respect to swap option σij , N (Sm, σij), is a subset of L(Sm), and comprises of the following swap options :\na. σjk, where σjk is the swap option on the edge ej b. each σt, if σt belongs to an OR node vq where vq is a node in Sm(vj)\nWe use the term N (Sm) to denote the native swap options when σij is understood from the context. Intuitively the native swap options for solution Sm are the swap options that become available immediately after applying σij, but were not available in the predecessor solution of Sm. ⊓⊔\nConsider the solution S4 shown in Figure 11 where Sig(S4) = {σ(2,3), σ(3,4), σ(13,14)}. The solution is highlighted using thick dashed lines with arrow head. We have used the rectangles with rounded corner beside each node vq in solution S4, where C(S4, vq) 6= Copt(vq). Suppose S4 is constructed form solution S3 (where Sig(S3) = {σ(2,3), σ(3,4)}) using swap option σ(13,14). Here N (S4, σ(13,14)) = {σ(14,15)} whereas L(S4) = {σ(11,12), σ(14,15)}. Now consider solution S6 where Sig(S6) = {σ(2,3), σ(3,4), σ(11,12), σ(13,14)). It is worth observing that applying only the native swap options to S4 instead of all swap options in L(S4) prevents the construction of solution S6 from solution S4. S6 can also be constructed by applying σ(13,14) to solution S5, where Sig(S5) = {σ(2,3), σ(3,4), σ(11,12)}. However, it may be noted that σ(13,14) is not a native swap option of solution S5."
    }, {
      "heading" : "3.3.1 Lazy ASG Algorithm",
      "text" : "The intuition behind the other version of the ASG algorithm is as follows. For a newly constructed solution Sm, we need to check whether Sm is already present in Open because Sm can be constructed as a part of computing the successor set of multiple solutions. Instead of using the entire swap list of a solution to construct all successors at once and then add those solutions to Open, using the native swap options for constructing a subset of the successor set ensures the following. The subset constructed using native swap options\nconsists of only those solutions that are currently not present in Open and thus can be added to Open without comparing with the existing entries in Open. The construction of each remaining successor solution S′m of Sm and then insertion to Open is delayed until every other predecessor solution of S′m is added to Closed.\nAlgorithm 5: Lazy ASG (LASG) Algorithm\ninput : An alternating AND/OR tree T̂αβ output: Alternative solutions of T̂αβ in the non-decreasing order of cost Compute the optimal solution Sopt, perform OR edge marking and populate the1 swap options; Create two lists, Open and Closed, that are initially empty;2 Put Sopt in the Closed list;3 Create a solution space tree T s with Sopt as root;4 Compute the swap list, L(Sopt), of Sopt;5 Construct Succ(Sopt) using L(Sopt);6 forall Sm ∈ Succ(Sopt) do7\nAdd Sm to Open;8 end9 while Open is not empty do10 Smin ← Remove the minimum cost solution from Open ;11 /* Suppose Smin is constructed from Sm applying swap option σij */ Add a node corresponding to Smin in T s and connect that node using an edge12 from Sm ; Compute the swap list L(Smin) and the list of native swap options N (Smin, σij);13 /* Expansion using native swap options */ foreach σtmp ∈ N (Smin, σij) do14 Construct Stmp from Smin by applying σtmp;15 Construct the signature of Stmp, Sig(Stmp), by concatenating σtmp after16 Sig(Smin); Add Stmp to Open;17 end18 /* Lazy Expansion */ forall Sp ∈ Sib(T s, Smin) do19 if σij ∈ L(Sp) then20 Construct S′p from Sp using σij ;21 Construct the signature of S′p, Sig(S ′ p), by concatenating σij after Sig(Sp);22 Add S′p to Open;23 end24\nend25 Add Smin to Closed;26 end27 Report the solutions in Closed;28\nThe solution space tree T s is maintained throughout the course of the algorithm to determine when every other predecessor of S′m is added to Closed. Based on this idea we\npresent a lazy version of ASG algorithm, named LASG. After selecting the minimum cost solution from Open, the algorithm explores the successor set of the current minimum cost solution in a lazy fashion. For a solution Sm, at first a subset of Succ(Sm) is constructed using only the native swap options of Sm. The other solutions that belong to Succ(Sm) are explored as late as possible as described above. For resolving ties, LASG algorithm uses the same strategy which is used by ASG algorithm. The details of LASG algorithm are presented in Algorithm 5. The proof of correctness of this algorithm is presented in Appendix B.\nConsider the example tree shown in Figure 7 and solutions S1 and S2 (shown in Figure 9 and Figure 10). Initially the Open will contain only Sopt and N (Sopt) = {σ(11,12), σ(13,14)}. When Sopt is selected from Open, both S1 and S2 is added to Open. Next S1 will be selected followed by S2. Since, N (S1) = ∅ and N (S2) = ∅, after selecting S1 or S2 no successor solutions are constructed using the native swap list. Among the predecessors of S3, S2 is added last to Closed. After selecting and removing S2 from Open, solution S3 is constructed from the previously selected predecessor S1 using the swap option σ(11,12) which is used to construct solution S2 from Sopt."
    }, {
      "heading" : "3.3.2 Working of LASG Algorithm (on AND/OR tree in Figure 4)",
      "text" : "Before entering the outermost while loop (Algorithm 5, Line 10), LASG computes the optimal solution Sopt and constructs Succ(Sopt). Then the solutions in Succ(Sopt) are added to Open and the contents of the Open becomes { {σ(2,3)}, {σ(9,10)} } . The contents of the different lists when a solution is added to Closed are shown in Table 2. The solutions are represented using their signatures. The solutions that are added to Open as a result of lazy expansion, are highlighted using under-brace.\nWhile generating the first four solutions, the contents of the different lists for LASG are identical to the contents of the corresponding lists of ASG (shown in Table 1). For\neach of these soltuions, the native swap list is equal to the actual swap list of that solution. It is worth noting that, unlike ASG, for LASG the outermost while loop starts after generating the optimal solution Sopt, thus while generating the same solution the iteration number for LASG is less than that of ASG by 1. In the 4th iteration, for solution S4 = {σ(2,3), σ(3,4), σ(13,14)} the native swap list is not equal to the swap list as described previously. The same holds true for solution S5 = {σ(2,3), σ(3,4), σ(11,12)} and solution S6 = {σ(2,3), σ(3,4), σ(13,14), σ(11,12)}. It is important to observe that LASG adds the solution S6 = {σ(2,3), σ(3,4), σ(13,14), σ(11,12)} to Open after the generation of solution S5 = {σ(2,3), σ(3,4), σ(11,12)} as a part of lazy expansion (highlighted using under-brace in Table 2). Whereas, the ASG algorithm adds S6 to Open after generating solution S4 = {σ(2,3), σ(3,4), σ(13,14)}."
    }, {
      "heading" : "3.4 Complexity Analysis and Comparison among ASG, LASG and BU",
      "text" : "In this section we present a complexity analysis of ASG and LASG and compare them with BU. We will use the following parameters in the analysis.\na. nαβ and nβ denote the total number of nodes and the number of OR nodes in an alternating AND/OR tree. b. d denotes the out degree of the OR node having maximum number of children. c. m denotes the maximum number of OR edges in a solution. d. o denotes the maximum size of Open. We will present the complexity analysis for\ngenerating c solutions. Therefore the size of Closed is O(c)."
    }, {
      "heading" : "3.4.1 Complexity of ASG",
      "text" : "Time Complexity : The time complexity of the major steps of Algorithm 4 are as follows.\na. Computing the first solution can be done in bottom-up fashion, thus requiring O(nαβ) steps. The edges emanating from an OR node are sorted in the non-decreasing order of aggregated cost to compute the marks of the OR edges, the marking process takes O ( nβ.d. log d ) . Since the value of d is not very large in general (can be upper bounded\nby a constant), O ( nβ.d. log d ) = O(nαβ).\nb. The number of swap options available to a solution can be at most equal to the number of OR edges in that solution. Thus, the swap list for every solution can be built in O(m) time. For c solutions, generating swap options take O(c.m). c. Since the size of the successor set of a solution can be m at most, the size of Open, o can at most be c.m. Also the size of the TList can at most be equal to c (the size of Closed). d. The Open list can be implemented using Fibonacci heap. Individual insert and delete operation on Open take O(1)(amortized) and O(lg o) time respectively. Hence, for inserting in the Open and deleting from Open altogether takes O(o. lg o) time which is O(c.m. log(c.m)). e. The checking for duplicates requires scanning the entire Open and TList. Since the length of TList can be at most c, for a newly constructed solution this checking takes O(c+ o) time and at most O(c+ o) solutions are generated. Since O(c+ o) is actually O(o), for generating c solutions, this step takes O(o)2 time. Also, the maximum value\nof o can be O(c.m). Thus, the time complexity of this step is O(c.m)2. Clearly this step dominates O(o. lg o) which is the total time taken for all insertions into the Open and deletions from Open. However, this time bound can be further improved if we maintain a hash map of the solutions in the Open and TList, and in this case the checking for duplicates can be done in O(o) time. In that case O(o. lg o) (total time taken for all insertions into the Open and deletions from Open) becomes dominant over the time required for checking for duplicates. f. An upper limit estimate of m could be made by estimating the size of a solution tree which is √ nαβ for regular and complete alternating AND/OR trees. It is important\nto observe that the value of m is independent of the average out degree of a node in T̂αβ .\nCombining the above factors together we get the time complexity of ASG algorithm as :\nO ( nαβ + o 2 ) = O ( nαβ + (c.m) 2 ) = O ( nαβ + c 2.nαβ ) = O(c2.nαβ)\nHowever if the additional hash map is used the time complexity is further reduced to :\nO ( nαβ + o. lg o ) = O ( nαβ + c. √ nαβ. lg(c.nαβ) ) = O ( nαβ + √ nαβ .(c. lg c+ c. lg nαβ) )\nSpace Complexity: The following data-structures primarily contribute to the space complexity of ASG algorithm.\na. Three lists, namely, Open, Closed, and TList are maintained throughout the course of the running ASG. This contributes a O(o+ c) factor, which is O(o). b. Since the number of swap options is upper bounded by the total number of OR edges, constructing the swap list contributes the factor, O(nβ.d) to the space complexity. Also marking a solution requires putting a mark at every OR node of the AND/OR tree, thus adding another O(nβ) space which is clearly dominated by the previous O(nβ.d) factor. c. Since the signature of a solution is essentially a set of swap options, the size of a signature is upper bounded by the total number of swap options available. Combining the Open and Closed list, altogether (c+ o) solutions need to be stored. Since (c+ o) is O(o), total space required for storing the solutions is O ( o.nβ .d ) .\nCombining the above factors together we get the space complexity of ASG algorithm as :\nO ( o+ nβ.d+ o.nβ.d ) = O(o.nβ .d)\nWhen an additional hash map is used to improve the time complexity, another additional O ( o.nβ .d ) space is required for maintaining the hash map. Although the exact space requirement is doubled, asymptotically the space complexity remains same."
    }, {
      "heading" : "3.4.2 Complexity of LASG",
      "text" : "Time Complexity : Compared to Algorithm 4, Algorithm 5 does not check for the duplicates and adds the solution to Open only when it is required. Therefore the other terms in the complexity remain the same except the term corresponding to the checking for duplicates. However, here T s is created and maintained during the course of Algorithm 5. Creating and maintaining the tree require O(c) time. Also during the lazy expansion the swap list of the previously generated sibling solutions are searched (Line 19 and Line 20 of Algorithm 5). The size of the swap list of any solution is O(m), where m is the maximum number of OR edges in a solution. Also there can be at most O(m) sibling solutions for a\nsolution. Therefore the complexity of the lazy expansion is O(c.m2). Since O(c.m2) is the dominant factor, the time complexity of LASG is O(c.m2) = O(c.nαβ).\nSpace Complexity : Compared to ASG algorithm, LASG algorithm does not maintain the TList. However LASG maintains the solution space tree T s whose size is equal to the Closed list, thus adding another O(c) factor to the space complexity incurred by ASG algorithm. It is interesting to observe that the worst case space complexity remains O(o+ nβ.d+ o.nβ .d) = O(o.nβ .d) which is equal to the space complexity of ASG algorithm."
    }, {
      "heading" : "3.4.3 Comparison with BU",
      "text" : "The time complexity of generating the c best solutions for an AND/OR tree is O(nαβ .c. log c) and the space complexity is O(nαβ.c). The detailed analysis can be found in the work of Elliott (2007). Since, nβ.d = O(nαβ), the space complexity of both ASG and LASG algorithm reduces to O(nαβ.c) and the time complexity of LASG is log c factor better than BU whereas the time complexity of ASG is quadratic with respect to c compared to the (c. log c) factor of BU. When an additional hash-map is used to reduce the time overhead of duplicate checking, ASG beats both LASG and BU both in terms time complexity, as both O(nαβ) and O (√ nαβ.(c. lg c+ c. lg nαβ) ) is asymptotically lower than O(nαβ.c. log c).\nHowever this worst case complexity is only possible for AND/OR trees where no duplicate solution is generated. Empirical results show that the length of Open, o hardly reaches O(c.m)."
    }, {
      "heading" : "4. Ordered Solution Generation for AND/OR DAGs",
      "text" : "In this section, we present the problem of generating solutions in non-decreasing order of cost for a given AND/OR DAG. We present the working of the existing algorithm for generating solution for both tree based semantics and default semantics. Next we present the modifications in ASG and LASG for handling DAG."
    }, {
      "heading" : "4.1 Existing Bottom-Up Algorithm",
      "text" : "Figure 12 shows an example working of the existing bottom-up approach, BU, on the AND/OR DAG in Figure 2. We use the notations that are used in Figure 3 to describe different solutions in Figure 12 and the generation of the top 2 solutions under tree-based semantics is shown.\nIt is important to notice that although BU correctly generates alternative solutions of an AND/OR DAGs under tree based semantics, BU may generate some solutions which are invalid under default semantics. In Figure 13 we present a solution of the AND/OR DAG in Figure 2. This solution is an example of such a solution which is correct under tree-based semantics but is invalid under default semantics. The solution DAG (highlighted using thick dashed lines with arrow heads) in Figure 13 will be generated as the 3rd solution of the AND/OR DAG in Figure 2 while running BU. At every non-terminal node, the entry (within rectangle) corresponding to the 3rd solution is highlighted using bold face. It may be noted that the terminal nodes, v9 and v10, are included in the solution DAG though both of them emanate from the same parent OR node. Therefore, this solution is not a valid one under default semantics.\nv12, 89 v2 v3 1 : |1, 1|, 89 2 : |2, 1|, 90\nv23, 43\n〈1〉\n1 : 〈v5, 1〉, 43 2 : 〈v4, 1〉, 44 v32, 41\n〈2〉\n1 : 〈v5, 1〉, 41 2 : 〈v5, 2〉, 44\nv4\n40\n〈1〉\nv52, 35\n〈5〉 〈4〉\nv7 v8 1 : |1, 1|, 35 2 : |2, 1|, 38\nv6\n52\n〈1〉\nv73, 9\n〈4〉\n1 : 〈v9, 1〉, 9 2 : 〈v10, 1〉, 12\nv8\n17\n〈3〉\nv9\n5\n〈1〉\nv10\n7\n〈2〉\nFigure 12: BU approach for AND/OR DAG\nv12, 89\nv2 v3 1 : |1, 1|, 89 2 : |2, 1|, 90\nv23, 43\n〈1〉\n2 : 〈v4, 1〉, 44 v32, 41\n〈2〉\n1 : 〈v5, 1〉, 41\nv4\n40\n〈1〉\nv52, 35\n〈5〉 〈4〉\nv7 v8\nv6\n52\n〈1〉\nv73, 9\n〈4〉\nv8\n17\n〈3〉\nv9\n5\n〈1〉\nv10\n7\n〈2〉\n3 : |1, 2|,92\n1 : 〈v5,1〉,43 2 : 〈v5,2〉,44\n1 : |1, 1|,35 2 : |2, 1|,38\n1 : 〈v2,1〉,34 2 : 〈v2,2〉,37\nFigure 13: A solution (tree based semantics)\nProposed Extension of BU to Generate Alternative Solutions under Default Semantics : We propose a simple top-down traversal and pruning based extension of BU to generate alternative solutions under default semantics. While generating the ordered solutions at any AND node vq by combining the solutions of the children, we do the following. For each newly constructed solution rooted at vq, a top-down traversal of that solution starting from vq is done to check whether more than two edges of an OR node are present in that particular solution (a violation of the default semantics). If such a violation of the default semantics is detected, that solution is pruned from the list of alternative solutions rooted at vq. Therefore, at every AND node, when a new solution is constructed, an additional top-down traversal is used to detect the semantics violation."
    }, {
      "heading" : "4.2 Top-Down Method for DAGs",
      "text" : "The proposed top-down approaches (ASG and LASG) are also applicable for AND/OR DAGs to generate alternative solution DAGs under default semantics. Only the method of computing the cost increment after the application of a swap option needs to be modified to incorporate the fact that an OR node may be included in a solution DAG through multiple paths from the root node. We use the notion of participation count for computing the cost increment.\nParticipation Count : The notion of participation count is applicable to the intermediate nodes of a solution DAG as follows. In a solution DAG, the participation count of an intermediate node, vq, is the total number of distinct paths connecting the root node, vR, and vq. For example, in Figure 14, the optimal solution DAG is shown using thick dashed lines with arrow heads, and the participation count for every intermediate OR nodes are shown within a circle beside the node.\nv1 2, 89\nv2 3, 43\n〈1〉\n1 v3 2, 41\n〈2〉\n1\nv4\n40\n〈1〉\nv5 2, 35\n〈5〉 〈4〉\n2 v6\n52\n〈1〉\nv7 3, 9\n〈4〉\n2 v8\n17\n〈3〉\nv9\n5\n〈1〉\nv10\n7\n〈2〉\nσ2,5,4 : 1 σ3,5,6 : 14\nσ7,9,10 : 3\nFigure 14: AND/OR DAG\nv1 2, 90\nv2 3, 44\n〈1〉\n1 v3 2, 41\n〈2〉\n1\nv4\n40\n〈1〉\nv5 2, 35\n〈5〉 〈4〉\n1 v6\n52\n〈1〉\nv7 3, 9\n〈4〉\n1 v8 17\n〈3〉\nv9\n5\n〈1〉\nv10\n7\n〈2〉\nσ3,5,6 : 14\nσ7,9,10 : 3\nFigure 15: Solution DAG S1\nWe use the notation σijk to denote a swap option in the context of AND/OR DAGs, where swap option σijk belongs to node vi, the source edge of the swap option is eij from node vi to node vj , and the destination edge is eik from node vi to node vk."
    }, {
      "heading" : "4.2.1 Modification in the Proposed Top-Down Approach",
      "text" : "The ASG algorithm is modified for handling AND/OR DAGs in the following way. The computation of the successor solution in Line 14 of Algorithm 4 is modified to incorporate the participation count of the OR node to which the applied swap option belongs. The overall method is shown in Algorithm 6(in the next page).\nIn order to apply LASG on AND/OR DAGs, apart from using the above mentioned modification for computing the cost of a newly generated solution, another modification is needed for computing the native swap options for a given solution. The modification is explained with an example. Consider the solution, S1, shown in Figure 15. S1 is highlighted using thick dashed lines with arrow heads. The pair, cv(vq), C(S1, vq), is shown within rectangles beside each node vq; rectangles with rounded corner are used when C(S1, vq) 6= Copt(vq). Swap option σ(2,5,4) was applied to Sopt to generate S1. After the application of swap option σ(2,5,4), the participation count of node v5 is decremented to 1. Therefore in S1 there is a path from the root node to node v5 and so node v5 is still present in S1. As a result, the swap option σ(7,9,10) is available to S1 with a participation count equal to 1 for node v7, whereas σ(7,9,10) is available to its parent solution Sopt with participation count 2 for node v7. In other words, σ(7,9,10) is not available to S1 and its parent solution Sopt with the same value of participation count for node v7. Therefore σ(7,9,10) becomes the native swap option of S1. The generalized definition of native swap options for a solution is presented below.\nDefinition 4.o [Native Swap Options of a Solution] Consider a solution Sm of an AND/OR DAG Gαβ , where Sm is constructed by applying swap option σhij to solution Sp. Since swap option σhij = 〈ehi, ehj , δhij〉 is used to construct Sm, AND node vj belongs\nto Sm. Similarly, if the participation count of node vi remains greater than zero after applying σhij to Sm, node vi belongs to Sm. The native swap options of solution Sm with respect to swap option σhij, N (Sm, σhij), a subset of L(Sm), comprises of the following swap options :\na. σhjk, where σhjk is the swap option on the edge ehj b. each σt, if σt belongs to an OR node vq where vq is a node in Sm(vj) c. each σ′t, if node vi is present in Sm and σ ′ t belongs to an OR node vq where vq is a\nnode in Sm(vi). We use the term N (Sm) to denote the native swap options when σhij is understood from the context. Intuitively the native swap options for solution Sm are the swap options that become available immediately after applying σhij , but were not available in the predecessor solution of Sm. ⊓⊔ Algorithm 6: ASG Algorithm for AND/OR DAGs\ninput : An AND/OR DAG Gαβ output: Alternative solutions of Gαβ in the non-decreasing order of cost Compute the optimal solution Sopt, perform OR edge marking and populate the1 swap options; Create three lists, Open, Closed, and TList, that are initially empty;2 Put Sopt in Open;3 lastSolCost ← C(Sopt);4 while Open is not empty do5 Smin ← Remove the minimum cost solution from Open;6 if lastSolCost < C(Smin) then7 Remove all the elements of TList;8 lastSolCost ← C(Smin);9\nend10 Add Smin to Closed and TList;11 Compute the swap list, L(Smin), of Smin;12 /* Construct Succ(Smin) using L(Smin) and add new solutions to Open */ foreach σij ∈ L(Smin) do13 Construct Sm by applying σij to Smin;14 Construct the signature of Sm, Sig(Sm), by concatenating σij after Sig(Smin);15 Let σij belongs to OR node vq, p is the participation count of vq, and δ is the16 cost increment for σij ; C(Sm) = C(Sm) + p× δ;17 /* Check whether Sm is already present in Open or in TList */ if (Sm not in Open) and (Sm not in TList) then18 Add Sm to Open;19 end20\nend21 Report the solutions in Closed;22\nIt is worth noting that Definition 4.o of native swap option is a generalization of the earlier definition of native swap option (Definition 3.n), defined in the context of trees. In\nthe case of trees, the participation count of any node can be at maximum 1. Therefore, after the application of a swap option to a solution, the participation count of the node, to which the original edge of the swap option points to, becomes 0. Therefore the third condition is never applicable for trees.\nLASG (Algo. 5) can be applied on AND/OR DAGs, with the mentioned modification for computing the cost of a newly generated solution and the general definition of native swap option to generate ordered solutions under default semantics."
    }, {
      "heading" : "4.2.2 Working of ASG and LASG Algorithm on AND/OR DAG",
      "text" : "We describe the working of ASG algorithm on the example DAG shown in Figure 2. Before entering the outermost while loop, TList and Closed are empty, and Open contains the optimal solution Sopt. The contents of the different lists obtained after first few cycles of outermost while loop are shown in Table 3. Each solution is represented by its signature. The solutions that are already present in Open and also constructed by expanding the current Smin, are highlighted with under-braces. For example, the solution {σ(2,5,4), σ(3,5,6)} which is added to Open in Iteration 2 (while constructing the successor solutions of {σ(2,5,4)}) constructed again in Iteration 5 while expanding solution {σ(3,5,6)}.\nNow we illustrate the working of LASG algorithm on the example DAG shown in Figure 2. The contents of the different lists when a solution is added to Closed are shown in Table 4. It is worth noting that for solution S1 = {σ2,5,4}, the swap list L(S1) = {σ(3,5,6), σ(7,9,10)} whereas the native swap list N (S1) = {σ(7,9,10)}. The solutions that are added to Open as a result of lazy expansion, are highlighted using under-brace. For example, in Iteration 7 LASG adds the solution S5 = {σ(2,5,4), σ(3,5,6)} to Open after the generation of solution S4 = {σ3,5,6} as a part of lazy expansion, whereas the ASG algorithm adds S5 to Open after generating solution S1 = {σ2,5,4}."
    }, {
      "heading" : "4.2.3 Generating Solutions under Tree Based Semantics",
      "text" : "Unlike the default semantics, ASG or LASG does not have any straight forward extension for generating solutions under tree based semantics. In Figure 13 we show an example solution which is valid under tree based semantics, but invalid under default semantics, because both OR edges emanating form the OR node v7, namely e(7,9) and e(7,10), are\npresent in this solution. These two OR edges are included in the solution through two different paths emanating form the root node, v1. As the existing bottom-up approach stores the alternative solutions at each node in terms of the solutions of the children of that node, this representation allows these different paths to be stored explicitly, thus making BU amenable for generating alternative solutions under tree-based semantics.\nOn the contrary, our approach works top-down using a compact representation (signature) for storing the solutions. In this signature based representation, it is currently not possible to store the fact that a particular OR node is included in the solution through two different paths which may select different child of that OR node. If we use the equivalent tree constructed form the given graph, our compact representation will work correctly, because in that case, each node would be reachable from the root node through at most one path. An AND/OR DAG can be converted to its equivalent AND/OR tree representation using procedure ConvertDAG (described in Section 2) and then ASG or LASG can be applied on the equivalent tree representation in order to generate the alternative solutions correctly under tree-based semantics. However, in the worst case, procedure ConvertDAG incurs a space explosion which will blow up the worst case complexity of both ASG and LASG algorithms. Using our compact representations to generate the ordered solutions under tree-based semantics for a given AND/OR DAG while containing the space explosion such that the worst case complexity of our algorithms remain comparable with BU turns out to be an interesting open problem."
    }, {
      "heading" : "5. Experimental Results and Observations",
      "text" : "To obtain an idea of the performance of the proposed algorithms and to compare with the existing approach, we have implemented the ASG, LASG and BU (existing bottom-up approach) and tested on the following test domains.\na. A set of synthetically generated AND/OR trees; b. Tower of Hanoi(TOH) problem; c. A set of synthetically generated AND/OR DAGs; d. Matrix-chain multiplication problem; and e. The problem of determining the secondary structure of RNA sequences.\nIt may noted that in our implementation of the ASG algorithm, we have implemented the more space efficient version of ASG algorithm (without a separate hash-map for storing the solutions in Open and Closed, thereby incurring an extra overhead in time for duplication checking). Another important point is that for every test case the reported running time of ASG and LASG for generating a particular number of solutions includes the time required for constructing the optimal solution graph. The details of the different test domains are as follows."
    }, {
      "heading" : "5.1 Complete Trees",
      "text" : "We have generated a set of complete d-ary alternating AND/OR trees by varying – (a) the degree of the non-terminal nodes (denoted by d), and (b) the height (denoted by h).\nThese trees can be viewed as the search space for a gift packing problem, where (a) the terminal nodes represent the cost of elementary items, (b) the OR nodes model a choice among the items (elementary or composite in nature)\nrepresented by the children, and (c) the AND nodes model the repackaging of the items returned by each of the children. Every packaging incurs a cost which is modeled by the cost of the intermediate AND nodes. Here the objective is to find the alternative gifts in the order of non-decreasing cost.\nTable 5 shows the time required for generating 100, 300, and 500 solutions for various complete alternating AND/OR trees. We have implemented the ASG, LASG and the existing bottom-up algorithm and the corresponding running time is shown in the column with the heading ASG, LASG and BU, respectively. We have used a time limit of 15 minutes\nand the entries marked with T denotes that the time-out occurred for those test cases. The space required for generating 100, 300, and 500 solutions is reported in Table 6. It can be observed that in terms of both time and space required, LASG outperforms both ASG and BU. Between ASG and BU, for most of the test cases BU performs better than ASG with respect to the time required for generating a specific number of solutions. The space requirement of ASG and BU for generating a specific number of solutions has an interesting correlation with the degree(d) and height(h) parameter of the tree. For low numerical values of the d and the h parameter, e.g., (d, h) combinations like (2, 7), (3, 5) etc., BU performs better than ASG. On the contrary, for the other combinations, where at least one of these d and h parameters has a high value, e.g., (d, h) combinations like (2, 17), (7, 5), (4, 9) etc., ASG outperforms BU."
    }, {
      "heading" : "5.1.1 Experimentation with Queue with Bounded Length",
      "text" : "Since the Open can grow very rapidly, both ASG and LASG incur a significant overhead in terms of time as well as space to maintain the Open list when the number of solutions to be generated is not known a priori. In fact, for ASG checking for duplicates in Open is actually the primary source of time complexity and storing the solutions in Open is a major contributing factor in space complexity. If the number of solutions that have to generated is known a priori, the proposed top-down approach can leverage the fact by using a bounded length queue for implementing Open. When a bounded length queue is used, the time requirement along with space requirement decreases significantly.\nWe show the effect of using bounded length queue to implement Open in Table 7 (reporting the time requirement) and in Table 8 (reporting the memory usage) for generating 100, 300, and 500 solutions, where the number of solutions to be generated are known beforehand. Table 7 and Table 8 show that in this case both ASG and LASG outperforms BU in terms of time as well as space requirements. Particularly, ASG performs very well in this setting, outperforming LASG in some cases."
    }, {
      "heading" : "5.1.2 Experimentation to Compare the Incremental Nature",
      "text" : "The proposed top-down algorithms are incremental in nature whereas the existing bottomup approach is not incremental. After generating a specified number of ordered solutions, our methods can generate the next solution incrementally without needing to restart itself, whereas the existing approach needs to be restarted. For example, after generating the first 10 ordered solutions, ASG and LASG generate the 11th solution directly from the data structures maintained so far by these algorithms and perform necessary updates to these data structures. Whereas, BU needs to be restarted with input parameter 11 for generating the 11th solution. In Table 9 we compare the time needed to generate the subsequent 11th solution and 12th solution incrementally after generating first 10 solutions. In order to have more clarity in the comparison among the running times of the respective algorithms, we have used higher precision (upto the 6th decimal place) while reporting the running time in Table 9. Clearly, both ASG and LASG outperform BU for generating the 11th and 12th solution in terms of the time requirement."
    }, {
      "heading" : "5.2 Multipeg Tower of Hanoi Problem",
      "text" : "Consider the problem of Multipeg Tower of Hanoi (Majumdar, 1996; Gupta, Chakrabarti, & Ghose, 1992). In this problem, ρ pegs are fastened to a stand. Initially γ disks rest on the source peg A with small disk on large disk ordering. The objective is to transfer all γ disks from A to the destination peg B with minimum legal moves. In a legal move, the topmost disk from any tower can be transferred to any other peg with a larger disk as the topmost disk. The problem of multi-peg tower of Hanoi can be solved recursively as follows.\na. Move recursively the topmost k (k varies from 1 to γ − 1) disks from A to some intermediate peg, I, using all the pegs. b. Transfer the remaining γ − k disks from A to B recursively, using the (ρ − 1) pegs available. c. Recursively move k disks that were transferred to I previously, from the intermediate peg I to B, using all the ρ pegs. It may be noted that there is a choice for the value of k, which may take any value from 1 to γ − 1. Solutions with different values of k may take different number of moves, and the solution which incurs minimum number of moves is the optimal solution. This choice of the value of k is modeled as an OR node, and for every such choice, the problem is divided into three sub-problems. This decomposition into sub-problems is modeled as an AND node. Therefore, the search spaces of the multi-peg Tower of Hanoi problem correspond to alternating AND/OR trees.\nWe have used the search space of 5 peg Tower of Hanoi problem with different number of disks, γ, and generated alternative solutions in non-decreasing order of cost using ASG and\nLASG algorithms. Here the cost function expresses the number of legal moves. The value of γ is varied from 8 to 13, and in Table 10 and in Table 11, we report the time required and space required, respectively, for generating 100, 300, and 500 solutions for every test cases. Experimental results show that the performance of ASG is similar to the performance of LASG with respect to both space and time. However ASG as well as LASG outperforms BU with respect to both time and space requirements."
    }, {
      "heading" : "5.3 Randomly Constructed AND/OR DAGs",
      "text" : "We have constructed a set of randomly generated AND/OR DAGs and evaluated the ASG, LASG, and BU algorithm for generating solutions under default semantics. We have used the proposed extension to the BU algorithm for generating solutions under default semantics.\nTable 12 and Table 13 compare the time required and space required for running ASG, LASG and BU for generating 100, 300, and 500 solutions for every test cases. The first and second columns of every row provide the size (nαβ) and the average out-degree (d) of the DAG. The results obtained for this test domain are similar to the results for randomly\nconstructed AND/OR trees. It may be noted that in terms of both time and space required, LASG outperforms both ASG and BU. Between ASG and BU, for most of the test cases BU performs better than ASG with respect to the time required for generating a specific number of solutions. Whereas, the space requirement of ASG and BU for generating a specific number of solutions has an interesting co-relation with the average degree(d) and the size (nαβ) parameter of the DAG. For low numerical values of the d and the nαβ parameter, e.g., (nαβ, d) combinations like (60, 2), (33, 3) etc., BU performs better than ASG. On the contrary, for the other combinations, where at least one of these nαβ and d parameter has a high value, e.g., (nαβ, d) combinations like (920, 2), (9624, 3), (40884, 4) etc., ASG outperforms BU."
    }, {
      "heading" : "5.4 Matrix-Chain Multiplication Problem",
      "text" : "We have also used the well-known matrix-chain multiplication (Cormen, Stein, Rivest, & Leiserson, 2001) problem for experimentation. The search space of the popular dynamic programming formulation of this problem correspond to AND/OR DAG.\nGiven a sequence of matrices, A1, A2, · · · , An, of n matrices where matrix Ai has dimension pi−1×pi, in this problem the objective is to find the most efficient way to multiply\nthese matrices. The classical dynamic programming approach works as follows. Suppose A[i,j] denotes matrix that results from evaluating the product, AiAi+1 · · ·Aj, and m[i, j] is the minimum number of scalar multiplications required for computing the matrix A[i,j]. Therefore, the cost of optimal solution is denoted by m[i, j] which can be recursively defined as :\nm[i, j] =\n \n\n0, if i = j;\nmin i≤k<j\n{ m[i, k] +m[k + 1, j] + pi−1 × pk × pj } , if i < j.\nThe choice of the value of k is modeled as OR node and for every such choice, the problem is divided into three sub-problems. This decomposition into sub-problems is modeled as an AND node. It is worth noting that unlike the search space of 5-peg ToH problem, the search space of the matrix-chain multiplication problem corresponds to AND/OR DAG. We have used the search space for different matrix sequences having varying length and generated alternative solutions in the order of non-decreasing cost. In Table 14, we report the time required and in Table 15, we report the memory used for generating 10, 15, and 20 solutions for every test cases.\nIn Table 14, for each test case, we also report the time required for constructing the explicit AND/OR DAG from the recursive formulation in the 2nd column, and the optimal solution construction time in the 3rd column. It is interesting to observe that the relative performance of ASG and LASG for this search space is very similar to that obtained for 5- peg ToH search space though this search space for this domain is AND/OR DAG. Both ASG and LASG perform approximately the same with respect to time and space requirement. However, the advantage of ASG as well as LASG over BU with respect to both time and space requirement is more significant in this domain."
    }, {
      "heading" : "5.5 Generating Secondary Structure for RNA",
      "text" : "Another relevant problem where the alternative solutions play an important role is the computation of the secondary structure of RNA. RNA molecules can be viewed as strings of bases, where each base belongs to the set {Adenine,Cytocine,Guanine, Uracil} (also denoted as {A,C,G,U}). RNA molecules tend to loop back and form base pairs with itself and the resulting shape is called secondary structure (Mathews & Zuker, 2004). The stability of the secondary structure largely depends on the number of base pairings (in general, larger number of base pairings implies more stable secondary structure). Although there are other factors that influence the secondary structure, it is often not possible to express these other factors using a cost function and they are typically evaluated empirically. Therefore, it is useful to generate a set of possible alternative secondary structures ordered by decreasing numbering of base pairings for a given RNA which can be further subjected to experimental evaluation.\nThe computation of the optimal secondary structure considering the underlying principle of maximizing the number of base-pairings has a nice dynamic programming formulation (Kleinberg & Tardos, 2005). Given an RNA molecule B = 〈b1b2 · · · bn〉 where each bi ∈ {A,C,G,U}, the secondary structure on B is a set of base pairings, D = {(i, j)}, where i, j ∈ {1, 2, · · · n}, that satisfies the following conditions:\na. if (i, j) ∈ D, then i+4 < j : This condition states that the ends of each pair in D are separated by at least four intermediate bases. b. The elements of any pair in D consists of either {A,U} or {C,G} (in either order). c. No base appears in more than one pairings, i.e., D is a matching. d. If (i, j) and (k, l) are two pairs in D, then it is not possible to have i < k < l < j, i.e.,\nno two pairings can cross each other.\nUnder the above mentioned conditions the dynamic programming formulation is as follows. Suppose P (i, j) denotes the maximum number of base pairings in a secondary structure on bi · · · bj. P (i, j) can be recursively defined as :\nP [i, j] =\n \n 0, if i+ 4 ≥ j, max {\nP [i, j − 1], max i≤k<j\n{ 1 + P [i, k − 1] + P [k + 1, j − 1] } , } if i+ 4 < j.\nHere, a choice of the value of k is modeled as an OR node and for every such choice, the problem is divided into three sub-problems. This decomposition into sub-problems is modeled as an AND node. We have experimented with the search space of this problem for the set of RNA molecule sequences obtained from the test-cases developed by Szymanski, Barciszewska, Barciszewski, and Erdmann (2005). The details of the test cases are shown in Table 16.\nFor every test cases, we report the time required in Table 17 for generating 5, 10, and 15 solutions. For the same setting, the space required is reported in Table 18. In Table 17, for each test case, we also report the time required for constructing the explicit AND/OR DAG from the recursive formulation in the 2nd column, and the time required for constructing the optimal solution time in the 3rd column. We use a high value of time-out (1800 seconds) in order to gather the running time required by BU. We limit the maximum solutions generated at 15 because for generating higher number of solutions, BU is timed out for most of the test cases. It is worth noting that the result obtained for this domain is very similar to the result obtained for the matrix-chain multiplication problem domain. Both space and time wise ASG and LASG perform similarly and they outperform BU significantly with respect to time as well as space requirement."
    }, {
      "heading" : "5.6 Observations",
      "text" : "The experimental data shows that the LASG algorithm generally outperforms the ASG algorithm and the existing bottom-up approach in terms of the running time for complete alternating AND/OR trees and AND/OR DAGs. Whereas, for the other problem domains, i.e., the 5-peg Tower of Hanoi problem, the matrix-chain multiplication problem, and the problem of determining secondary structure of RNA sequences, the overall performance of the ASG algorithm is similar to the performance of the LASG algorithm. This behavior can be explained from the average and maximum length statistics of Open list, reported in Table 19 - Table 23, for these above mentioned test domains.\nIn the case of complete trees and random DAGs, for ASG algorithm, the average as well as the maximum size of Open grows much faster than that of LASG algorithm (Table 19 and Table 20), with the increase in the size of the tree/DAG.\nSince ASG algorithm checks for the presence of duplicates while expanding a solution, the time required for duplication checking grows rapidly for these test domains. Hence, the overall time required for generating a specific number of solutions also increases rapidly (faster than both BU and LASG) with the increase in the size of the tree/DAG. As a result, BU outperforms ASG with respect to the time requirement for trees and DAGs. However\nthe memory used for generating a specific number of solutions increases moderately (slower than BU) with the increase in the size of the tree/DAG. Therefore with respect to space requirement, ASG outperforms BU for larger trees and DAGs.\nBetween LASG and BU, the time as well as the memory requirement of BU increases faster than that of LASG when the degree of the AND/OR tree or DAG increases. This happens because, for BU, the time taken for merging the sub-solutions at the AND nodes and memory required for storing alternative solutions that are rooted at different nodes increases rapidly with the increase in the degree of that node.\nOn the contrary, for the other test domains, 5-peg Tower of Hanoi problem, matrix-chain multiplication problem, and the probelm of finding secondary structure of RNA sequences, the average and the maximum size of Open for both ASG and LASG are comparable (Table 21, Table 22 and Table 23). Therefore, for the LASG algorithm, the time saved by avoiding the duplication checking is compensated by the extra overhead of maintaining the solution space tree and the checks required for lazy expansion. Hence the running time as well as the space requirement are almost same for both algorithms for these three above mentioned problem domains.\nMoreover, due to the low values of the average and the maximum size of Open, ASG outperforms BU with respect to both time requirement and memory used for these three test domains. For these three domains also, between LASG and BU, the time as well as the memory requirement of BU increases faster than that of LASG when the size of the search space (AND/OR tree or DAG) increases."
    }, {
      "heading" : "6. Ramifications on Implicitly Specified AND/OR Structures",
      "text" : "In this section, we briefly discuss use of our proposed algorithms for generation of alternative solutions in the non-decreasing order of cost for implicit AND/OR search spaces. One possible way is to extend the standard AO∗ for generating a given number of solutions, say k, as follows. Instead of keeping only one potential solution graph(psg), at any stage k psgs can be computed on the explicitly constructed search space and instead of expanding one node, k nodes, (that is, one node from each psg), can be expanded at once. After expanding the nodes, k psgs are recomputed once again. Since the cost of the nodes are often recomputed after expanding nodes, the swap options associated with any such node have to be updated after every such recomputation.\nAnother possible approach could be to run AO∗ until it generates the optimal solution. At this point of time the swap options can be computed on the explicit portion of the graph and swap option with minimum cost can be applied to the optimal solution. Then the resulting psg is again expanded further resulting in the expansion of the explicit graph. The swap options are re-evaluated to incorporate the cost update. Again the next best psg is computed. This process continues till the second best solution is derived. Now among the remaining successor psgs of the first solution and the successor psgs of second solution, the most promising psg is selected and expanded. This process continues till the third solution is found. Then the successor psgs are also added to the already existing pool of candidate psgs. These two broad steps, (a) selecting the next best psg from the pool of candidate psgs, and then (b) keeping on expanding the explicit graph till the next best solution is found, is continued till k solutions are found.\nIt is important to observe that both methods heavily depend on incorporating the updates in the explicit DAG like adding nodes, increase in the cost, etc., and recomputing the associated swap options along with the signatures that use those swap options. Handling dynamic updates in the DAG efficiently and its use in implicit AND/OR search spaces remains an interesting future direction."
    }, {
      "heading" : "7. Conclusion",
      "text" : "In our work we have presented a top-down algorithm for generating solutions of a given weighted AND/OR structure (DAG) in non-decreasing order of cost. Ordered solutions for AND/OR DAGs are useful for a number of areas including model based programming, developing new variants of AO*, service composition based on user preferences, real life problems having dynamic programming formulation, etc. Our proposed algorithm has two advantages – (a) it works incrementally, i.e., after generating a specific number of solutions, the next solution is generated quickly, (b) if the number of solutions to be generated is known a priori, our algorithm can leverage that to generate solutions faster. Experimental results show the efficacy of our algorithm over the state-of-the-art. This also opens up several interesting research problems and development of applications."
    }, {
      "heading" : "8. Acknowledgments",
      "text" : "We thank the anonymous reviewers and the editor, Prof. Hector Geffner, for their valuable comments which have enriched the presentation of the paper significantly. We also thank Prof. Abhijit Mitra, International Institute of Information Technology, Hyderabad, India, for his valuable inputs regarding the test domain involving secondary structure of RNA. We thank Aritra Hazra and Srobona Mitra, Research Scholar, Department of Comp. Sc. & Engg., Indian Institute of Technology Kharagpur, India, for proof reading the paper."
    }, {
      "heading" : "Appendix A. Proof of Correctness of Algorithm 4",
      "text" : "Lemma A.1 Every solution other than the optimal solution Sopt can be constructed from Sopt by applying a sequence of swap options according to the order R̂.\nProof: [Lemma A.1] Every solution other than Sopt of an alternating AND/ OR tree T̂αβ is constructed by choosing some non optimal edges at some OR nodes. Consider any other solution Sm, corresponding to which the set of non-optimal OR edges is Sβ and suppose |Sβ| = m. We apply the relation R to Sβ to obtain an ordered sequence Σ of OR edges where ∀e1, e2 ∈ Σ, e1 appears before e2 in Σ if (e1, e2) ∈ R. We show that there exists a sequence Σ̂ of swap options that can be constructed for Sβ . For every OR edge eij of Σ (here eij is the i\nth edge of Σ and 1 ≤ i ≤ m), we append the subsequence of OR edges ei1 , . . . , eij−1 before eij , where ei1 , . . . , eij are the OR edges that emanate from the same parent vq, and ei1 , . . . , eij−1 are the first ij − 1 edges in L(vq).\nWe get a sequence of OR edges Σaug from Σ by the above mentioned augmentation. Σaug is basically a concatenation of subsequences τ1, . . . , τm, where τi is a sequence of edges ei1 , . . . , eij such that ei1 , . . . , eij are the OR edges that emanate from the same parent vq, and ei1 , . . . , eij are the first ij edges in L(vq). We construct Σ̂ from Σaug as follows. From\nevery τi, we construct τ̂i = 〈σi1,i2 , . . . , σij−1,ij 〉, where σik,ik+1 = 〈eik , eik+1, δik ,ik+1〉 and i1 ≤ ik ≤ (ij −1). Σ̂ is constructed by concatenating every individual τ̂i. Hence there exists a sequence of swap options Σ̂ corresponding to every other solution Sm. ⊓⊔\nDefinition A.p [Default Path] From Lemma A.1, every non-optimal solution Sm can be constructed from the initial optimal solution by applying a sequence of swap options, Σ̂(Sm), according to the order R̂. The sequence of solutions that is formed following Σ̂(Sm) corresponds to a path from Sopt to Sm in SSDAG Gs. This path is defined as the default path, Pd(Sm), for Sm.\nLemma A.2 The SSDAG of an alternating AND/OR tree T̂αβ contains every alternative solution of T̂αβ.\nProof: [Lemma A.2] We prove this by induction on the length of the default path Pd of the solutions.\n[Basis (n = 1) :] Consider the swap list of Sopt. The solutions whose default path length is equal to 1 form the Succ(Sopt). Therefore these solutions are present in G.\n[Inductive Step :] Suppose the solutions whose default path length is less than or equal to n are present in G. We prove that the solutions having default path length equal to n+1 are also present in G. Consider any solution Sm where Pd(Sm) = n+1. Let Σ̂(Sm) = 〈σ1, · · · , σn, σn+1〉. Consider the solution S′m where Σ̂(S′m) = 〈σ1, · · · , σn〉. Since Pd(S′m) = n, S′m ∈ V, and swap option σn+1 ∈ L(S′m), there is a directed edge from S′m to Sm in Gs. Hence every solution having a default path length equal to n+ 1 is also present in G. ⊓⊔\nLemma A.3 For any alternating AND/OR tree T̂αβ , Algorithm 4 adds solutions to Closed (at Line 11) in non-decreasing order of cost.\nProof: [Lemma A.3] Consider the following invariants of Algorithm 4 that follow from the description of Algorithm 4.\na. The minimum cost solution from Open is always removed at Line 6 of Algorithm 4.\nb. The cost of the solutions that are added in Open, while exploring the successor set of a solution Sm (at Line 13 of Algorithm 4), are greater than or equal to C(Sm).\nFrom these two invariants it follows that Algorithm 4 adds solutions to Closed (at Line 11) in non-decreasing order of cost.\nLemma A.4 For any alternating AND/OR tree T̂αβ , for every node of the SSDAG of T̂αβ, Agorithm 4 generates the solution corresponding to that node.\nProof: [Lemma A.4] From Lemma A.3 it follows that Algorithm 4 generates the solutions in the non-decreasing order of cost. By generating a solution Sm, we mean adding Sm to Closed (at line 11 of Algorithm 4). For the purpose of proof by contradiction, let us assume that Algorithm 4 does not generate solution Sm. Also let Sm be the first occurrence of this\nscenario while generating solutions in the mentioned order. According to Lemma A.1, there exists a sequence of swap options Σ̂ = σ1, . . . , σk corresponding to Sm. Also consider the solution S′m whose sequence of swap options is Σ̂\n′ = σ1, . . . , σk−1. According to Property 3.2, C(S′m) ≤ C(Sm). Consider the following two cases:\na. C(S′m) < C(Sm): Since Sm is the first instance of the incorrect scenario, and Algorithm 4 generates the solutions in the non-decreasing order of cost, S′m is generated prior to Sm.\nb. C(S′m) = C(Sm): Since Algorithm 4 resolves the tie in the favor of the parent solution, and Sm is the first instance of the incorrect scenario – in this case also S ′ m will be\ngenerated prior to Sm.\nThe swap option σk belongs to the swap list of S ′ m. When S ′ m was generated by Algorithm 4, that is, when S′m was added to Closed, S ′ m was also expanded and the solutions which can be constructed from S′m applying one swap option, were added to the Open list. Since Sm was constructed from S′m applying one swap option σk, Sm was also added to the Open while exploring the successors of S′m. Therefore Sm will also be eventually generated by Algorithm 4 - a contradiction. ⊓⊔\nLemma A.5 For any alternating AND/OR tree T̂αβ , Algorithm 4 does not add any solution to Closed (at Line 11 of Algorithm 4) more than once.\nProof: [Lemma A.5] For the purpose of contradiction, let us assume that Sm is the first solution that is added to Closed twice. Therefore Sm must have been added to Open twice. Consider the following facts.\na. When Sm was added to Closed for the first time, the value of lastSolCost was C(Sm), and Sm was added to TList.\nb. From the description of Algorithm 4 it follows that the contents of TList are deleted only when the value of lastSolCost increases.\nc. From Lemma A.3 it follows that Algorithm 4 generates the solutions in non-decreasing order of cost. Hence, when Sm was generated for the second time, the value of lastSolCost did not change from C(Sm).\nFrom the above facts it follow that Sm was present in TList when Sm was added to Open for the second time. Since, while adding a solution to Open, Algorithm 4 checks whether it is present in TList (at Line 16 of Algorithm 4); Algorithm 4 must had done the same while adding Sm to Open for the second time. Therefore Sm could not be added Open for the second time – a contradiction. ⊓⊔\nTheorem A.1 ∀Sj ∈ V, Sj is generated (at Line 11) by Algorithm 4 only once and in the non-decreasing order of costs while ties among the solutions having same costs are resolved as mentioned before.\nProof: [Theorem A.1] Follows from Lemma A.2, Lemma A.3, Lemma A.4 and Lemma A.5. ⊓⊔"
    }, {
      "heading" : "Appendix B. Proof of Correctness of Algorithm 5",
      "text" : "Definition B.q [Reconvergent Paths in Solution Space DAG] Two paths, (i) p1 = S1i1 → · · · → S1in and (ii) p2 = S2i1 → · · · → S2im , in the SSDAG Gs of an alternating AND/OR tree T̂αβ are reconvergent if the following holds:\na. S1i1 = S 2 i1 , i.e. the paths start from the same node;\nb. S1in = S 1 im , i.e. the paths ends at the same node; c. (∀j ∈ [2, n− 1])(∀k ∈ [2,m− 1]), ( S1ij 6= S2ik ) ; i.e. the paths do not have any common\nintermediate node.\nDefinition B.r [Order on Generation Time] In the context of Algorithm 5, we define an order relation, ≺t⊂ V ×V, where (Sp, Sq) ∈≺t if Sp is generated by Algorithm 5 before Sq. Here V is set of vertices in SSDAG Gs of an alternating AND/OR tree T̂αβ .\nLemma B.1 Algorithm 5 adds the solutions to the Closed list in the non-decreasing order of costs.\nProof: [Lemma B.1] Consider the following invariants of Algorithm 5 that follow from the description of Algorithm 5.\na. The minimum cost solution from Open is always removed at line 11 of Algorithm 4.\nb. Algorithm 5 expands any solution, say Sp, in two phases. At the first phase Sp is expanded using the native swap options of Sp. The solutions that are added to Open as a result of the application of the native swap options, will have cost greater than or equal to C(Sp). In the second phase, i.e., during lazy expansion, Sp is again expanded using a non native swap option. A solution Sp may undergo the second phase κ times where 0 ≤ κ ≤ (|L(Sp)| − |N (Sp, σk)|) and σk is used to construct Sp. In every lazy expansion of Sp, a new solution is added to Open. Consider a solution Sm which is constructed from S′m using σj by Algorithm 5 where S ′ m ∈ Pred(Sm). Suppose swap\noption σi ∈ L(Sm), and σi /∈ N (Sm, σj), i.e., σi is not a native swap option of Sm. Clearly σi ∈ L(S′m). Suppose Sc and S′c are the successors of Sm and S′m respectively, constructed by the application of σi, i.e., S ′ m σi−→ S′c, and Sm σi−→ Sc. Also let S′c is added to Closed after Sm.\nConsider the fact that Algorithm 5 does not apply swap option σi to Sm, that is, Sc is not added to Open until S′c is added to Closed. Since C(S ′ m) ≤ C(Sm), C(S′c) ≤ C(Sc). According to Algorithm 5, σi is applied to Sm (during the lazy expansion), and Sc is added to Open right after S′c is added to Closed. Consider the time period between adding Sm and adding S ′ c to Closed. During that period, every solution that is added to Closed has cost between C(Sm) and C(S ′ c), i.e., the cost is less or equal to C(Sc). In general, the application of a swap option to add a solution to Open is delayed by such an amount of time, say ∆, so that all the solutions, which are added to Closed during this ∆ time interval, have cost less than or equal to the solution under consideration.\nFrom the above facts it follow that Algorithm 5 adds the solutions to the Closed list in non-decreasing order of costs. ⊓⊔\nLemma B.2 Any two reconvergent paths in the SSDAG Gs of an alternating AND/OR tree T̂αβ are of equal length.\nProof: [Lemma B.2] Consider the paths:\n(i) p1 = S1 σ1−→ Sp σ2−→ · · · σn−→ Sn, and (ii) p2 = S1 σ′1−→ S′p σ′2−→ · · · σ ′ m−−→ Sn.\nThe edges in the paths represent the application of a swap option to a solution. Now p1 and p2 start from the same solution and also end at the same solution. Therefore the sets of swap options that are used in these paths are also same. Hence the lengths of those paths are equal, that is, in the context of p1 and p2, n = m.\nLemma B.3 For any set of reconvergent paths of any length n, Algorithm 5 generates at most one path.\nProof: [Lemma B.3] The following cases are possible.\n[Case 1 (n = 2) :] Consider the following two paths:\n(i) p1 = S1 σ1−→ S2 σ2−→ S3, and (ii) p2 = S1 σ′1−→ S′2 σ′2−→ S3.\nIt is obvious that σ1 = σ ′ 2 and σ2 = σ ′ 1. Suppose S2 ≺t S′2. Here Algorithm 5 does not apply the swap option σ1 to S ′ 2. Therefore p2 is not generated by Algorithm 5.\n[Case 2 (Any other values of n) :] In this case, any path belonging to the set of reconvergent paths, consists of n different swap options, suppose σ1, · · · , σn. Also the start node and the end node of the paths under consideration are Sp and Sm. Consider the nodes in the paths having length 1 from Sp. Clearly there can be n such nodes.\nAmong those nodes, suppose Algorithm 5 adds Sp1 to Closed first, and Sp1 is constructed from Sp by applying swap option σ1. According to Algorithm 5, σ1 will not be applied to any other node that is constructed from Sp and is added to Closed after Sp1. Therefore, all those paths starting from Sp, whose second node is not Sp1, will not be generated by Algorithm 5. We can use the similar argument on the paths from Sp1 to Sm of length n− 1 to determine the paths which will not be generated by Algorithm 5. At each stage, a set of paths will not be grown further, and at most one path towards Sm will continue to grow. After applying the previous argument n times, at most one path from Sp to Sm will be constructed. Therefore Algorithm 5 will generate at most one path from Sp to Sm. ⊓⊔\nDefinition B.s [Connection Relation Rc and R̂c] We define connection relation, Rc, a symmetric order relation for a pair of OR nodes, vq and vr, belonging to an alternating AND/OR tree T̂αβ as:\n(vq, vr) ∈ Rc | if in T̂αβ there exists an AND node vp, from which there exist two paths, (i) p1 = vp → . . . → vq, and (ii) p2 = vp → . . . → vr\nSimilarly the connection relation, R̂c, is defined between two swap options as follows. Consider two swap options σiq and σjr, where σiq = 〈ei, eq, δiq〉 and σjr = 〈ej , er, δjr〉. Suppose OR edges ei and eq emanate from vp, and OR edges ej and er emanate from vt. Now (σiq, σjr) ∈ R̂c if (vp, vt) ∈ Rc. Definition B.t [Mutually Connected Set] For a solution Sm, a set Vm of OR nodes is mutually connected, if\n∀v1, v2 ∈ Vm, ( (v1 6= v2) ⇒ {(v1, v2) ∈ Rc} )\nConsider the set of OR nodes, Vm = {v1, · · · , vk}, where swap option σj belongs to vj and 1 ≤ j ≤ k. Here the set of swap options V̂m = {σ1, · · · , σk} is mutually connected.\nLemma B.4 Suppose Sm is a solution of an alternating AND/OR tree T̂αβ , Pred(Sm) = {S1, · · · , Sk}, and swap option σj is used to construct Sm from Sj where 1 ≤ j ≤ k. The swap options σ1, · · · , σk are mutually connected.\nProof: [Lemma B.4] Since Sm is constructed from S1, · · · , Sk by applying σ1, · · · , σk respectively, σ1, · · · , σk are present in the signature of Sm. Suppose set sσ = {σ1, · · · , σk}. We have to show that\n∀σa, σb ∈ sσ, ( (σa, σb) ∈ R̂c )\nFor the purpose of proof by contradiction, let us assume (σi1 , σi2) /∈ R̂c. Also Sm is constructed by applying σi1 and σi2 to Si1 and Si2 respectively. Consider the path p1 in SSDAG of T̂αβ which starts from Sopt and ends at Sm, and along p1, Si1 is the parent of Sm. Now along this path, σi2 is applied before the application of the swap option σi1 . Similarly consider the path p2 in SSDAG of T̂αβ which starts from Sopt and ends at Sm, and along p2, Si2 is the parent of Sm. Along this path, σi1 is applied before the application of the swap option σi2 .\nSuppose σi1 and σi2 belongs to OR node v1 and v2 respectively. Since along path p1, σi1 is the swap option which is applied last, Sm contains node v1. Similarly along path p2, σi2 is the swap option which is applied last. Hence Sm contains node v2. Therefore, there must be an AND node vr in T̂αβ, from which there exist paths to node v1 and v2 – implies that (σi1 , σi2) ∈ R̂c. We arrive at a contradiction that proves σ1, · · · , σk are mutually connected. ⊓⊔\nDefinition B.u [Subgraph of SSDAG] Consider a solution Sp of an alternating AND/OR tree T̂αβ and mutually connected set Vm of OR nodes in Sp, where ∀vq ∈ Vm, ( C(Sp, vq) = Copt(vq) ) . The subgraph Gssub(Sp, Vm) = 〈Vsub, Esub〉 of the SSDAG with respect to Sp and Vm is defined as follows. Vsub consists of only those solutions which can be constructed from Sp by applying a sequence of swap options belonging to Vm, and Esub is the set of edges corresponding to the swap options that belong to Vm.\nLemma B.5 The number of total possible distinct solutions at each level d in Gssub(Sp, Vm) is\n( n+d−2 n−1 ) , where |Vm| = n.\nProof: [Lemma B.5] Consider the swap options that belong to the nodes in Vm. With respect to these swap options, every solution Sr in Gssub(Sp, Vm) is represented by a sequence of numbers of length n, Seq(Sr), where every number corresponds to a distinct node in Vm. The numerical value of a number represent the rank of the swap option that is chosen for a node vq ∈ Vm. According to the representation, at each level:\ni. the sum of numbers in Seq(Sr) of a solution, Sr, is equal to the sum of numbers in Seq(S′r) of any other solution, S ′ r, in that same level;\nii. the sum of numbers in Seq(Sr) of a solution, Sr, is increased by 1 from the sum of numbers in Seq(S′′r ) of any solution, S ′′ p , of the previous level.\nHence, at the dth level, there are n slots and d − 1 increments that need to be made to Seq(Sr). This is an instance of the well known combinatorial problem of packing n+ d− 1 objects in n slots with the restriction of keeping at least one object per slot. This can be done in\n( n+d−2 n−1 ) ways. ⊓⊔\nTheorem B.1 The solution space tree constructed by Algorithm 5 is complete.\nProof: [Theorem B.1] For the purpose of contradiction, suppose Sm is the first solution which is not generated by Algorithm 5. Also Pred(Sm) = {Spi} and Sm can be constructed from Spi by applying σqi , where 1 ≤ i ≤ k. From Lemma B.4 it follows that the set of swap options {σqi | 1 ≤ i ≤ k} is mutually connected. Therefore the set of OR nodes Vm to which the swap options belong is also mutually connected. Suppose |Vm| = n.\nConsider the solution Sq, where Vm is mutually connected, and for 1 ≤ i ≤ k, every σqi belongs to the set of native swap options of Sq with respect the swap option that is used to construct Sq. Clearly\n∀vt ∈ Vm, ( C(Sq, vt) = Copt(vt) )\nWe argue that Sq is generated by Algorithm 5 because Sm is the first solution which is not generated by Algorithm 5. Consider the subtree T ssub of T s rooted at Sq, where only the edges corresponding to swap options that belong to Vm are considered. Now we prove that the number of solutions generated by Algorithm 5 at every level of T ssub is equal to the number of solutions at the same level in Gssub(Sq, Vm).\nConsider the solution Sq and the set Succ(Sq). Suppose Succ(Sq, Vm) is the set of successor solutions that are constructed from Sq by applying the swap options belonging to the nodes in Vm, and S ′ min is the minimum cost solution in Succ(Sq, Vm). According to Algorithm 5 initially Succ(S′min) is partially explored by using the set of native swap options of S′min. Any other non native swap option, σb, that belongs to the nodes in Vm, is used to explore Succ(S′min), right after the sibling solution of S ′ min, constructed by applying σb to Sq, is added to Closed. Consider the fact that for solution Sq, ∀vt ∈ Vm, ( C(Sq, vt) = Copt(vt) ) holds. Therefore all the swap options belonging to Vm will also be eventually used to explore the successors of S′min. Similarly the second best successor of Sq will be able use all but one swap option, σc, which is used to construct S ′ min.\nThe immediate children of S′min in T ssub will consist of all solutions, that can be obtained by the application of one swap option in Vm to S ′ min. The native swap list of S ′ min contains the swap option ranking next to σc. The swap options, that are used to construct the other\nn − 1 sibling solutions of S′min, will be used again during lazy expansion, which accounts for another n− 1 children of S′min. Hence there would be n children of S′min.\nSimilarly, the second best successor of Sq in T ssub will have n − 1 immediate children. The third best successor of Sq in T ssub will have n− 2 children and so on. Now the children of these solutions will again have children solutions of their own, increasing the number of solutions at each level of the tree. This way, with each increasing level, the number of solutions present in the level keeps increasing. We prove the following proposition as a part of proving Theorem B.1.\nProposition B.1 At any level d, the number of solutions N(d, n,T ssub) is given by\nN(d, n,T ssub) = n∑\nk=1\nN(d− 1, k,T ssub) = ( n+ d− 2 n− 1 )\nProof: [Proposition B.1] At second level, there are n solutions. These give rise to\nn∑\nk=1\nk\nsolutions at third level. Similarly at fourth level we have\nn∑\nk=1\nk +\nn−1∑\nk=1\nk +\nn−2∑\nk=1\nk....+ 1 = N(3, n,T ssub) +N(3, n − 1,T ssub) + ...+ 1\nWe can extend this to any level d and the result is as follows.\nN(1, n,T ssub) = 1 N(2, n,T ssub) = n N(3, n,T ssub) = n∑\nk=1\nk =\n( n+ 1\n2\n)\nN(4, n,T ssub) = n∑\nk=1\nN(3, k,T ssub) = ( n+ 2\n3\n)\nWe determine the number of solutions at any level of T ssub by induction on the depth d. [Basis (d = 1) :] Clearly, N(1, n,T ssub) = n. [Inductive Step :] Suppose, at dth level the number of solutions is ( n+d−2 n−1 ) = ( n+d−2 d−1 ) . Therefore at d+ 1th level,\nN(d+ 1, n,T ssub) = n∑\nk=1\nN(d, k,T ssub) = ( n+ d− 2 d− 1 ) + ( n+ d− 3 d− 1 ) + · · · + 1 = ( n+ d− 1 n− 1 )\nSince Algorithm 5 does not generate duplicate node, and from Proposition B.1 the number of solutions in Gssub(Sq, Vm) at any level is equal to the number of solutions in that level of T ssub, at any level the set of solutions in Gssub(Sq, Vm) is also generated by Algorithm 5 through T ssub. Therefore, the level, at which Sm belongs in Gssub(Sq, Vm), will also be generated by Algorithm 5. Therefore Sm will also be generated by Algorithm 5 – a contradiction which establishes the truth of the statement of Theorem B.1. ⊓⊔"
    }, {
      "heading" : "Appendix C. Conversion between AND/OR Tree and Alternating",
      "text" : "AND/OR Tree\nAn AND/OR tree is a generalization of alternating AND/OR tree where the restriction of strict alternation between AND and OR nodes are relaxed. In other words an intermediate OR node can be a child of another intermediate OR node and the similar parent child relation is also allowed for AND node. We present an algorithm to convert an AND/OR to an equivalent alternating AND/OR tree.\nWe use two operations namely, folding and unfolding for the conversions. Corresponding to every edge, a stack, update-list, is used for the conversions. In an AND/OR tree, consider two nodes, vq and vr, of similar type (AND/OR) and they are connected by an edge er. Edges, e1, · · · , ek emanate from er. [Folding OR Node :] Suppose vq and vr are OR nodes. The folding of vr is performed as follows.\n• The source of the edges e1, · · · , ek are changed from vr to vq and the costs are updated as ce(ei) ← ce(ei) + ce(er) + cv(vr) where 1 ≤ i ≤ k, that is the new cost is the sum of the old cost and the cost of the edge that points to the source of ei. The triplet 〈vr, cv(vr), ce(er)〉 is pushed into the update-list of ei, 1 ≤ i ≤ k.\n• The edge er along with node vr is removed from vq. [Folding AND Node :] Suppose vq and vr are AND nodes. The folding of vr is performed as follows.\n• The source of the edges e1, · · · , ek are changed from vr to vq. One of the edges among e1, · · · , ek, suppose ei, is selected arbitrarily and the cost is updated as ce(ei) ← ce(ei) + ce(er) + cv(vr) where 1 ≤ i ≤ k. The triplet 〈vr, cv(vr), ce(er)〉 is pushed into the update-list of ei, whereas the triplet 〈vr, 0, 0〉 is pushed into the update-list of ej , where 1 ≤ j ≤ k and j 6= i.\n• The edge er along with node vr is removed from vq. The unfolding operation is the reverse of the folding operation and it is same for both\nOR and AND nodes. It works on a node vq as follows.\nProcedure Unfold(node vq)\nforall edge ei that emanate from vq do1 if the update list of ei is not empty then2 〈vt, c1, c2〉 ← pop(update list of ei);3 if there exists no edge et from vq that points to the node vt then4 Create a node vt, and connect vt using edge et from vq;5 cv(vt) ← c1;6 ce(et) ← c2;7 else if c2 6= 0 then8 ce(et) ← c2;9\nend10\nend11\nFunction Convert takes the root node of AND/OR tree and transforms it to an equivalent alternating AND/OR tree recursively.\nFunction Convert(vq)\nif every child of vq is a terminal node then1 if vq and its parent vp are of same type then2 Apply fold operation to vq;3 end4\nelse5 foreach child vr of vq, where vr is an intermediate AND/OR node do6 Convert(vr); end7\nFunction Revert takes the root node of an alternating AND/OR tree and converts it to the original AND/OR tree recursively.\nFunction Revert(vq)\nif every child of vq is a terminal node then1 return;2 Perform unfold operation to vq;3 foreach child vr of vq do4 Revert(vr);5 end6\nThe overall process of generating alternative solutions of an AND/OR tree is as follows. The AND/OR tree is converted to an alternating AND/OR tree using Convert function, and the solutions are generated using ASG algorithm. The solutions are transformed back using the Revert function. The proof of correctness is presented below.\nC.1 Proof of Correctness\nSuppose in an AND/OR tree Tαβ two nodes, vq and vr, are of similar type (AND/OR) and they are connected by an edge er. Edges e1, · · · , ek emanate from er. Now fold operation is applied to vq and vr. Let T 1 αβ is the AND/OR tree which is generated by the application of the fold operation.\nLemma C.1 In the context mentioned above, we present the claim of in the following two propositions.\nProposition C.1 The set of solutions of Tαβ having node vq can be generated from the set of solutions of T 1αβ having node vq by applying the unfold operation to vq of the solutions of Tαβ .\nProposition C.2 For every solution S1m of T 1 αβ that contains node vq, there exists a solution Sm of Tαβ that can be generated from S 1 m by applying unfold to vq.\nProof: [Proposition C.1] We present the proof for the following cases. Consider any solution of Sm of Tαβ that contains node vq.\na. vq and vr are OR nodes: There are two cases possible.\n1. vr is absent from Sm: Since the fold operation modifies the edge er only, all the other edges from vq in Tαβ are also present in T 1 αβ. Therefore Sm will also\nbe present in the solution set of T 1αβ and it will remain unchanged after the application of unfold operation.\n2. vr is present in Sm: Since there are k distinct OR edges emanating from vr, let any one of those OR edges, say ei, is present in Sm. We prove that there is a solution S1m of T 1 αβ , such that the application of unfold operation to S 1 m will\ngenerate Sm. The application of fold operation to the node vr modifies the source and the cost of edge ei from vr to vq and ce(ei) to ce(ei)+ ce(er)+ cv(vr) in T 1 αβ . Suppose S1m is a solution of T 1 αβ , where the edge ei is present in S 1 m. Also other than the subtree rooted at vq, the remaining parts of S 1 m and Sm are identical with each other. Clearly S1m exists as a solution of T 1 αβ and the application of unfold operation to vq in S 1 m generates Sm.\nb. vq and vr are AND nodes: Since vq is an AND node Sm will contain all of the AND edges that emanate from vq. Therefore edge er and vr both will be present in Sm. Consider the solution S 1 m of T 1 αβ , such that the following holds.\n1. vq is present in S 1 m.\n2. The subtrees rooted at the children of vq other than vr in Sm are identical with the subtrees rooted at those children of vq in S 1 m. 3. Other than the subtree rooted at vq, remaining parts of S 1 m and Sm are identical\nwith each other.\nClearly S1m exists as a solution of T 1 αβ and the application of unfold operation to vq in S1m generates Sm.\nAny other solution S′m of Tαβ that does not contain node vq, is a valid solution for T 1 αβ as well. ⊓⊔\nProof: [Proposition C.2] We present the proof for the following cases. Consider any solution S1m of T 1 αβ that contains node vq.\na. vq and vr are OR nodes: Since vq is an OR node, exactly one OR edge ei of vq will belong to S1m. There are two cases possible.\n1. ei was not modified while folding vr in T 1 αβ: Since the fold operation modifies\nthe edge er and the OR edges of vr only, all the other edges from vq in Tαβ are also present in T 1αβ . Since ei was not modified during folding, the same solution S1m is also a valid solution for Tαβ . 2. ei was modified while folding vr in T 1 αβ: Suppose ei connects vq and vi in\nS1m. Apply the unfold operation to the node vq in S 1 m and generate solution Sm. The edge ei will be replaced with edge er which connects vq and vr and then ei will connect vr and vi. We argue that Sm is a valid solution of Tαβ since the\nsubtree rooted at vi is not modified by the sequence of – (a) the folding of vr to construct T 1αβ from Tαβ, and (b) the unfolding of vq to construct Sm from S 1 m.\nb. vq and vr are AND nodes: Since vq is an AND node, S 1 m will contain all of the\nAND edges that emanate from vq. There are two types of AND edges emanating from vq in T 1 αβ and they are (a) Type-1 : the edges from vq that are also present in Tαβ from vq, (b) Type-2 : the edges that are added to vq by folding and these edges are from vr in Tαβ. Apply the unfold operation to the node vq in S 1 m and generate solution Sm. Sm will contain Type-1 edges, and another edge er from vq. In Sm, vq and vr are connected by er and the Type-2 edges are originated from vr. We argue that Sm is a valid solution of Tαβ since the subtree rooted at nodes pointed by Type-2 edges are not modified by the sequence of – (a) the folding of vr to construct T 1 αβ from Tαβ , and (b) the unfolding of vq to construct Sm from S 1 m.\nClearly any solution S1 ′ m of T 1 αβ that does not contain node vq is valid solution for Tαβ as well. ⊓⊔\nLemma C.2 If function Convert is applied to the root node of any AND/OR tree Tαβ, an alternating AND/OR tree T̂αβ is generated.\nProof: [Lemma C.2] Function Convert traverses every intermediate node in a depth first manner. Consider any sequence of nodes, vq1 , vq2 , · · · , vqn of same type, where vqi is the parent of vqi+1 in Tαβ and 1 ≤ i < n. Obviously, the fold operation is applied to vqi+1 before vqi , where 1 ≤ i < n. In other words, the fold operation applied to the sequence of nodes in the reverse order and after folding vqi+1 , all the edges of vqi+1 are modified and moved to vqi , where 1 ≤ i < n. When the function call Convert(vq2) returns, all the edges of vq2 , · · · , vqn are already moved to vq1 and the sequence of nodes, vq1 , vq2 , · · · , vqn are flattened. Therefore, every sequence of nodes of same type are flattened, when the function call Convert(vR) returns, where vR is the root of Tαβ and an alternating AND/OR tree T̂αβ is generated.\nLemma C.3 If function Revert is applied to an alternating AND/OR tree T̂αβ , the updatelist of every edge in T̂αβ becomes empty.\nProof: [Lemma C.3] Follows from the description of Revert.\nTheorem C.1 For any AND/OR tree Tαβ , it is possible to construct an alternating AND/OR tree T̂αβ using function Convert, where the set of all possible solutions of Tαβ is generated in the order of their increasing cost by applying Algorithm 4 to T̂αβ , and then converting individual solutions using function Revert.\nProof: [Theorem C.1] According to Lemma C.2, after the application of function Convert to Tαβ an alternating AND/OR tree T̂αβ is generated. Consider the intermediate AND/OR trees that are the generated after folding every node in Tαβ. Let T 0 αβ, T 1 αβ , · · · , T nαβ are the sequence of AND/OR trees and T 0αβ = Tαβ , T̂αβ = T n αβ. Since T i αβ is generated from T i+1 αβ\nafter folding exactly one node in T iαβ , where 0 ≤ i < n, according to Lemma C.1, the solutions of T iαβ can be generated from T i+1 αβ by unfolding the same node. According to Lemma C.3, for any solution of T̂αβ, Revert unfolds every node vq in that solution, where vq was folded by Convert while transforming Tαβ to T̂αβ . Therefore the solutions of Tαβ can be generated from the solutions of T̂αβ."
    } ],
    "references" : [ {
      "title" : "An algorithm better than AO",
      "author" : [ "B. Bonet", "H. Geffner" ],
      "venue" : "In Proceedings of the 20th national conference on Artificial intelligence - Volume",
      "citeRegEx" : "Bonet and Geffner,? \\Q2005\\E",
      "shortCiteRegEx" : "Bonet and Geffner",
      "year" : 2005
    }, {
      "title" : "Algorithms for searching explicit AND/OR graphs and their applications to problem reduction search",
      "author" : [ "P.P. Chakrabarti" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Chakrabarti,? \\Q1994\\E",
      "shortCiteRegEx" : "Chakrabarti",
      "year" : 1994
    }, {
      "title" : "Increasing search efficiency using multiple heuristics",
      "author" : [ "P.P. Chakrabarti", "S. Ghose", "A. Pandey", "S.C. DeSarkar" ],
      "venue" : "Inf. Process. Lett.,",
      "citeRegEx" : "Chakrabarti et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Chakrabarti et al\\.",
      "year" : 1989
    }, {
      "title" : "An admissible and optimal algorithm for searching AND/OR graphs",
      "author" : [ "C.L. Chang", "J.R. Slagle" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Chang and Slagle,? \\Q1971\\E",
      "shortCiteRegEx" : "Chang and Slagle",
      "year" : 1971
    }, {
      "title" : "Algorithms for finding k-best perfect matchings",
      "author" : [ "C.R. Chegireddy", "H.W. Hamacher" ],
      "venue" : "Discrete Applied Mathematics,",
      "citeRegEx" : "Chegireddy and Hamacher,? \\Q1987\\E",
      "shortCiteRegEx" : "Chegireddy and Hamacher",
      "year" : 1987
    }, {
      "title" : "Composite templates for cloth modeling and sketching",
      "author" : [ "H. Chen", "Z.J. Xu", "Z.Q. Liu", "S.C. Zhu" ],
      "venue" : "In Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume",
      "citeRegEx" : "Chen et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2006
    }, {
      "title" : "Introduction to Algorithms (2nd edition). McGraw-Hill Higher Education",
      "author" : [ "T.H. Cormen", "C. Stein", "R.L. Rivest", "C.E. Leiserson" ],
      "venue" : null,
      "citeRegEx" : "Cormen et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Cormen et al\\.",
      "year" : 2001
    }, {
      "title" : "Compiling knowledge into decomposable negation normal form",
      "author" : [ "A. Darwiche" ],
      "venue" : "In Proceedings of the 16th international joint conference on Artifical intelligence - Volume",
      "citeRegEx" : "Darwiche,? \\Q1999\\E",
      "shortCiteRegEx" : "Darwiche",
      "year" : 1999
    }, {
      "title" : "Decomposable negation normal form",
      "author" : [ "A. Darwiche" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Darwiche,? \\Q2001\\E",
      "shortCiteRegEx" : "Darwiche",
      "year" : 2001
    }, {
      "title" : "VLSI floorplan generation and area optimization using and-or graph search",
      "author" : [ "P. Dasgupta", "S. Sur-Kolay", "B. Bhattacharya" ],
      "venue" : "In VLSI Design,",
      "citeRegEx" : "Dasgupta et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Dasgupta et al\\.",
      "year" : 1995
    }, {
      "title" : "AND/OR search spaces for graphical models",
      "author" : [ "R. Dechter", "R. Mateescu" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Dechter and Mateescu,? \\Q2007\\E",
      "shortCiteRegEx" : "Dechter and Mateescu",
      "year" : 2007
    }, {
      "title" : "Extracting the k best solutions from a valued And-Or acyclic graph",
      "author" : [ "P. Elliott" ],
      "venue" : null,
      "citeRegEx" : "Elliott,? \\Q2007\\E",
      "shortCiteRegEx" : "Elliott",
      "year" : 2007
    }, {
      "title" : "DNNF-based belief state estimation",
      "author" : [ "P. Elliott", "B. Williams" ],
      "venue" : "In Proceedings of the 21st national conference on Artificial intelligence - Volume",
      "citeRegEx" : "Elliott and Williams,? \\Q2006\\E",
      "shortCiteRegEx" : "Elliott and Williams",
      "year" : 2006
    }, {
      "title" : "Finding the k smallest spanning trees",
      "author" : [ "D. Eppstein" ],
      "venue" : "In Proc. 2nd Scandinavian Worksh. Algorithm Theory, No. 447 in Lecture Notes in Computer Science,",
      "citeRegEx" : "Eppstein,? \\Q1990\\E",
      "shortCiteRegEx" : "Eppstein",
      "year" : 1990
    }, {
      "title" : "Finding the k shortest paths",
      "author" : [ "D. Eppstein" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "Eppstein,? \\Q1998\\E",
      "shortCiteRegEx" : "Eppstein",
      "year" : 1998
    }, {
      "title" : "M best solutions over graphical models",
      "author" : [ "N. Flerova", "R. Dechter" ],
      "venue" : "In 1st Workshop on Constraint Reasoning and Graphical Structures",
      "citeRegEx" : "Flerova and Dechter,? \\Q2010\\E",
      "shortCiteRegEx" : "Flerova and Dechter",
      "year" : 2010
    }, {
      "title" : "Bucket and mini-bucket schemes for m best solutions over graphical models",
      "author" : [ "N. Flerova", "R. Dechter" ],
      "venue" : "In GKR 2011(a workshop of IJCAI",
      "citeRegEx" : "Flerova and Dechter,? \\Q2011\\E",
      "shortCiteRegEx" : "Flerova and Dechter",
      "year" : 2011
    }, {
      "title" : "An LP view of the m-best MAP problem",
      "author" : [ "M. Fromer", "A. Globerson" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS)",
      "citeRegEx" : "Fromer and Globerson,? \\Q2009\\E",
      "shortCiteRegEx" : "Fromer and Globerson",
      "year" : 2009
    }, {
      "title" : "A solution to billiard balls puzzle using ao algorithm and its application to product development",
      "author" : [ "Z. Fuxi", "T. Ming", "H. Yanxiang" ],
      "venue" : "Knowledge-Based Intelligent Information and Engineering Systems,",
      "citeRegEx" : "Fuxi et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Fuxi et al\\.",
      "year" : 2003
    }, {
      "title" : "Approximate solution sampling (and counting) on AND/OR spaces",
      "author" : [ "V. Gogate", "R. Dechter" ],
      "venue" : "In CP,",
      "citeRegEx" : "Gogate and Dechter,? \\Q2008\\E",
      "shortCiteRegEx" : "Gogate and Dechter",
      "year" : 2008
    }, {
      "title" : "Automatic service composition based on enhanced service dependency graph",
      "author" : [ "Z. Gu", "J. Li", "B. Xu" ],
      "venue" : "In Web Services,",
      "citeRegEx" : "Gu et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2008
    }, {
      "title" : "Service data correlation modeling and its application in data-driven service composition",
      "author" : [ "Z. Gu", "B. Xu", "J. Li" ],
      "venue" : "Services Computing, IEEE Transactions on,",
      "citeRegEx" : "Gu et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2010
    }, {
      "title" : "The Towers of Hanoi: generalizations, specializations and algorithms",
      "author" : [ "P. Gupta", "P.P. Chakrabarti", "S. Ghose" ],
      "venue" : "International Journal of Computer Mathematics,",
      "citeRegEx" : "Gupta et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 1992
    }, {
      "title" : "K best solutions to combinatorial optimization problems",
      "author" : [ "H.W. Hamacher", "M. Queyranne" ],
      "venue" : "Annals of Operations Research,",
      "citeRegEx" : "Hamacher and Queyranne,? \\Q1985\\E",
      "shortCiteRegEx" : "Hamacher and Queyranne",
      "year" : 1985
    }, {
      "title" : "Anytime heuristic search",
      "author" : [ "E.A. Hansen", "R. Zhou" ],
      "venue" : "J. Artif. Intell. Res. (JAIR),",
      "citeRegEx" : "Hansen and Zhou,? \\Q2007\\E",
      "shortCiteRegEx" : "Hansen and Zhou",
      "year" : 2007
    }, {
      "title" : "AND/OR graph representation of assembly plans",
      "author" : [ "L. Homem de Mello", "A. Sanderson" ],
      "venue" : "Robotics and Automation, IEEE Transactions on,",
      "citeRegEx" : "Mello and Sanderson,? \\Q1990\\E",
      "shortCiteRegEx" : "Mello and Sanderson",
      "year" : 1990
    }, {
      "title" : "An efficient algorithm for searching implicit AND/OR graphs with cycles",
      "author" : [ "P. Jiménez", "C. Torras" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Jiménez and Torras,? \\Q2000\\E",
      "shortCiteRegEx" : "Jiménez and Torras",
      "year" : 2000
    }, {
      "title" : "AND/OR graph and search algorithm for discovering composite web services",
      "author" : [ "Q.A. Lang", "Y. Su" ],
      "venue" : "International Journal of Web Services Research,",
      "citeRegEx" : "Lang and Su,? \\Q2005\\E",
      "shortCiteRegEx" : "Lang and Su",
      "year" : 2005
    }, {
      "title" : "A procedure for computing the k best solutions to discrete optimization problems and its application to the shortest path problem",
      "author" : [ "E.L. Lawler" ],
      "venue" : "Management Science,",
      "citeRegEx" : "Lawler,? \\Q1972\\E",
      "shortCiteRegEx" : "Lawler",
      "year" : 1972
    }, {
      "title" : "AND/OR tree search algorithm in web service composition",
      "author" : [ "X. Ma", "B. Dong", "M. He" ],
      "venue" : "PACIIA",
      "citeRegEx" : "Ma et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2008
    }, {
      "title" : "Generalized multi-peg Tower of Hanoi problem",
      "author" : [ "A.A.K. Majumdar" ],
      "venue" : "The Journal of the Australian Mathematical Society. Series B. Applied Mathematics,",
      "citeRegEx" : "Majumdar,? \\Q1996\\E",
      "shortCiteRegEx" : "Majumdar",
      "year" : 1996
    }, {
      "title" : "AND/OR branch-and-bound for solving mixed integer linear programming problems",
      "author" : [ "R. Marinescu", "R. Dechter" ],
      "venue" : "In CP,",
      "citeRegEx" : "Marinescu and Dechter,? \\Q2005\\E",
      "shortCiteRegEx" : "Marinescu and Dechter",
      "year" : 2005
    }, {
      "title" : "Memory intensive branch-and-bound search for graphical models",
      "author" : [ "R. Marinescu", "R. Dechter" ],
      "venue" : "In AAAI",
      "citeRegEx" : "Marinescu and Dechter,? \\Q2006\\E",
      "shortCiteRegEx" : "Marinescu and Dechter",
      "year" : 2006
    }, {
      "title" : "Best-first AND/OR search for 0/1 integer programming",
      "author" : [ "R. Marinescu", "R. Dechter" ],
      "venue" : "In CPAIOR,",
      "citeRegEx" : "Marinescu and Dechter,? \\Q2007\\E",
      "shortCiteRegEx" : "Marinescu and Dechter",
      "year" : 2007
    }, {
      "title" : "Best-first AND/OR search for graphical models",
      "author" : [ "R. Marinescu", "R. Dechter" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Marinescu and Dechter,? \\Q2007\\E",
      "shortCiteRegEx" : "Marinescu and Dechter",
      "year" : 2007
    }, {
      "title" : "AND/OR branch-and-bound search for combinatorial optimization in graphical models",
      "author" : [ "R. Marinescu", "R. Dechter" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Marinescu and Dechter,? \\Q2009\\E",
      "shortCiteRegEx" : "Marinescu and Dechter",
      "year" : 2009
    }, {
      "title" : "Memory intensive AND/OR search for combinatorial optimization in graphical models",
      "author" : [ "R. Marinescu", "R. Dechter" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Marinescu and Dechter,? \\Q2009\\E",
      "shortCiteRegEx" : "Marinescu and Dechter",
      "year" : 2009
    }, {
      "title" : "Additive AND/OR graphs",
      "author" : [ "A. Martelli", "U. Montanari" ],
      "venue" : "In Proceedings of the 3rd international joint conference on Artificial intelligence,",
      "citeRegEx" : "Martelli and Montanari,? \\Q1973\\E",
      "shortCiteRegEx" : "Martelli and Montanari",
      "year" : 1973
    }, {
      "title" : "Optimizing decision trees through heuristically guided search",
      "author" : [ "A. Martelli", "U. Montanari" ],
      "venue" : "Commun. ACM,",
      "citeRegEx" : "Martelli and Montanari,? \\Q1978\\E",
      "shortCiteRegEx" : "Martelli and Montanari",
      "year" : 1978
    }, {
      "title" : "AND/OR multi-valued decision diagrams for constraint networks",
      "author" : [ "R. Mateescu", "R. Dechter" ],
      "venue" : "In Concurrency, Graphs and Models,",
      "citeRegEx" : "Mateescu and Dechter,? \\Q2008\\E",
      "shortCiteRegEx" : "Mateescu and Dechter",
      "year" : 2008
    }, {
      "title" : "AND/OR multi-valued decision diagrams (AOMDDs) for graphical models",
      "author" : [ "R. Mateescu", "R. Dechter", "R. Marinescu" ],
      "venue" : "J. Artif. Intell. Res. (JAIR),",
      "citeRegEx" : "Mateescu et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Mateescu et al\\.",
      "year" : 2008
    }, {
      "title" : "RNA secondary structure prediction. In Encyclopedia of Genetics, Genomics, Proteomics and Bioinformatics",
      "author" : [ "D.H. Mathews", "M. Zuker" ],
      "venue" : null,
      "citeRegEx" : "Mathews and Zuker,? \\Q2004\\E",
      "shortCiteRegEx" : "Mathews and Zuker",
      "year" : 2004
    }, {
      "title" : "An efficient algorithm for finding the m most probable configurations in probabilistic expert systems",
      "author" : [ "D. Nilsson" ],
      "venue" : "Statistics and Computing,",
      "citeRegEx" : "Nilsson,? \\Q1998\\E",
      "shortCiteRegEx" : "Nilsson",
      "year" : 1998
    }, {
      "title" : "Principles of artificial intelligence",
      "author" : [ "N.J. Nilsson" ],
      "venue" : "Tioga Publishing Co",
      "citeRegEx" : "Nilsson,? \\Q1980\\E",
      "shortCiteRegEx" : "Nilsson",
      "year" : 1980
    }, {
      "title" : "Anytime AND/OR depth-first search for combinatorial optimization. In SoCS",
      "author" : [ "L. Otten", "R. Dechter" ],
      "venue" : null,
      "citeRegEx" : "Otten and Dechter,? \\Q2011\\E",
      "shortCiteRegEx" : "Otten and Dechter",
      "year" : 2011
    }, {
      "title" : "Heuristics: intelligent search strategies for computer problem solving",
      "author" : [ "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "Pearl,? \\Q1984\\E",
      "shortCiteRegEx" : "Pearl",
      "year" : 1984
    }, {
      "title" : "Artificial Intelligence: A Modern Approach (2nd edition edition)",
      "author" : [ "S. Russell", "P. Norvig" ],
      "venue" : "chap. Planning,",
      "citeRegEx" : "Russell and Norvig,? \\Q2003\\E",
      "shortCiteRegEx" : "Russell and Norvig",
      "year" : 2003
    }, {
      "title" : "An incremental graph-based approach to automatic service composition",
      "author" : [ "M.M. Shiaa", "J.O. Fladmark", "B. Thiell" ],
      "venue" : "IEEE International Conference on Services Computing,",
      "citeRegEx" : "Shiaa et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Shiaa et al\\.",
      "year" : 2008
    }, {
      "title" : "A sophisticated approach to composing services based on action dominance relation",
      "author" : [ "D.H. Shin", "H.B. Jeon", "K.H. Lee" ],
      "venue" : "In Services Computing Conference (APSCC),",
      "citeRegEx" : "Shin et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Shin et al\\.",
      "year" : 2010
    }, {
      "title" : "Routing algorithms for dynamic, intelligent transportation networks. Master’s thesis, Virginia",
      "author" : [ "S. Subramanian" ],
      "venue" : "Technical Univ., Dept. of Civil Engineering",
      "citeRegEx" : "Subramanian,? \\Q1997\\E",
      "shortCiteRegEx" : "Subramanian",
      "year" : 1997
    }, {
      "title" : "An algorithm for finding k shortest loopless paths in a directed network",
      "author" : [ "K. Sugimoto", "N. Katoh" ],
      "venue" : "Trans. Information Processing Soc. Japan,",
      "citeRegEx" : "Sugimoto and Katoh,? \\Q1985\\E",
      "shortCiteRegEx" : "Sugimoto and Katoh",
      "year" : 1985
    }, {
      "title" : "Dealing with additional constraints in the k-shortest path problem",
      "author" : [ "T. Takkala", "R. Borndörfer", "A. Löbel" ],
      "venue" : "In Proc. WM",
      "citeRegEx" : "Takkala et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Takkala et al\\.",
      "year" : 2000
    }, {
      "title" : "A k-shortest path algorithm for adaptive routing in communications",
      "author" : [ "D.M. Topkis" ],
      "venue" : "networks. Trans. Communications,",
      "citeRegEx" : "Topkis,? \\Q1988\\E",
      "shortCiteRegEx" : "Topkis",
      "year" : 1988
    }, {
      "title" : "Automatic service composition using AND/OR graph",
      "author" : [ "Y. Yan", "B. Xu", "Z. Gu" ],
      "venue" : "In E-Commerce Technology and the Fifth IEEE Conference on Enterprise Computing, E-Commerce and E-Services,",
      "citeRegEx" : "Yan et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Yan et al\\.",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 45,
      "context" : ", where the overall problem can be hierarchically decomposed into conjunction and disjunction of subproblems (Pearl, 1984; Nilsson, 1980).",
      "startOffset" : 109,
      "endOffset" : 137
    }, {
      "referenceID" : 43,
      "context" : ", where the overall problem can be hierarchically decomposed into conjunction and disjunction of subproblems (Pearl, 1984; Nilsson, 1980).",
      "startOffset" : 109,
      "endOffset" : 137
    }, {
      "referenceID" : 45,
      "context" : "Traditionally the algorithm AO* (Pearl, 1984; Nilsson, 1980; Martelli & Montanari, 1978, 1973; Chang & Slagle, 1971) has been used for searching implicitly defined AND/OR structures.",
      "startOffset" : 32,
      "endOffset" : 116
    }, {
      "referenceID" : 43,
      "context" : "Traditionally the algorithm AO* (Pearl, 1984; Nilsson, 1980; Martelli & Montanari, 1978, 1973; Chang & Slagle, 1971) has been used for searching implicitly defined AND/OR structures.",
      "startOffset" : 32,
      "endOffset" : 116
    }, {
      "referenceID" : 0,
      "context" : "An empirical study of AO* can be found in Bonet and Geffner’s (2005) work.",
      "startOffset" : 42,
      "endOffset" : 69
    }, {
      "referenceID" : 1,
      "context" : "The problem of generating solutions for such representations has been studied extensively (Hansen & Zilberstein, 2001; Jiménez & Torras, 2000; Chakrabarti, 1994).",
      "startOffset" : 90,
      "endOffset" : 161
    }, {
      "referenceID" : 8,
      "context" : "Smooth Deterministic Decomposable Negative Normal Forms (sd-DNNF) (Darwiche, 2001) exhibit explicit AND/OR DAG structure and have been used for various applications including compiling knowledge (Darwiche, 1999), estimating belief states (Elliott & Williams, 2006), etc.",
      "startOffset" : 66,
      "endOffset" : 82
    }, {
      "referenceID" : 7,
      "context" : "Smooth Deterministic Decomposable Negative Normal Forms (sd-DNNF) (Darwiche, 2001) exhibit explicit AND/OR DAG structure and have been used for various applications including compiling knowledge (Darwiche, 1999), estimating belief states (Elliott & Williams, 2006), etc.",
      "startOffset" : 195,
      "endOffset" : 211
    }, {
      "referenceID" : 43,
      "context" : "This is particularly the case for AO* (Nilsson, 1980) where the potential solution graph (psg) is recomputed every time from the current explicit graph after a node is expanded.",
      "startOffset" : 38,
      "endOffset" : 53
    }, {
      "referenceID" : 1,
      "context" : "The problem of generating solutions for such representations has been studied extensively (Hansen & Zilberstein, 2001; Jiménez & Torras, 2000; Chakrabarti, 1994). Dechter and Mateescu (2007) have presented the explicit AND/OR search space perspective for graphical models.",
      "startOffset" : 143,
      "endOffset" : 191
    }, {
      "referenceID" : 1,
      "context" : "The problem of generating solutions for such representations has been studied extensively (Hansen & Zilberstein, 2001; Jiménez & Torras, 2000; Chakrabarti, 1994). Dechter and Mateescu (2007) have presented the explicit AND/OR search space perspective for graphical models. Different search strategies (best first, branch and bound, etc.) over the AND/OR search spaces in graphical models are discussed by Marinescu and Dechter (2007b, 2006). AND/OR search spaces are also used for solving mixed integer linear programming (Marinescu & Dechter, 2005), 0/1 integer Programming (Marinescu & Dechter, 2007a), combinatorial optimization in graphical models (Marinescu & Dechter, 2009a, 2009b). AND/OR Multivalued Decision Diagrams (AOMDD), which combine the idea of Multi-Valued Decision Diagrams(MDD) and AND/OR structures, is presented by Mateescu, Dechter, and Marinescu (2008) and further research along this direction can be found in the work of Mateescu and Dechter (2008).",
      "startOffset" : 143,
      "endOffset" : 876
    }, {
      "referenceID" : 1,
      "context" : "The problem of generating solutions for such representations has been studied extensively (Hansen & Zilberstein, 2001; Jiménez & Torras, 2000; Chakrabarti, 1994). Dechter and Mateescu (2007) have presented the explicit AND/OR search space perspective for graphical models. Different search strategies (best first, branch and bound, etc.) over the AND/OR search spaces in graphical models are discussed by Marinescu and Dechter (2007b, 2006). AND/OR search spaces are also used for solving mixed integer linear programming (Marinescu & Dechter, 2005), 0/1 integer Programming (Marinescu & Dechter, 2007a), combinatorial optimization in graphical models (Marinescu & Dechter, 2009a, 2009b). AND/OR Multivalued Decision Diagrams (AOMDD), which combine the idea of Multi-Valued Decision Diagrams(MDD) and AND/OR structures, is presented by Mateescu, Dechter, and Marinescu (2008) and further research along this direction can be found in the work of Mateescu and Dechter (2008). AND/OR search spaces are also applied for solution sampling and counting (Gogate & Dechter, 2008).",
      "startOffset" : 143,
      "endOffset" : 974
    }, {
      "referenceID" : 1,
      "context" : "The problem of generating solutions for such representations has been studied extensively (Hansen & Zilberstein, 2001; Jiménez & Torras, 2000; Chakrabarti, 1994). Dechter and Mateescu (2007) have presented the explicit AND/OR search space perspective for graphical models. Different search strategies (best first, branch and bound, etc.) over the AND/OR search spaces in graphical models are discussed by Marinescu and Dechter (2007b, 2006). AND/OR search spaces are also used for solving mixed integer linear programming (Marinescu & Dechter, 2005), 0/1 integer Programming (Marinescu & Dechter, 2007a), combinatorial optimization in graphical models (Marinescu & Dechter, 2009a, 2009b). AND/OR Multivalued Decision Diagrams (AOMDD), which combine the idea of Multi-Valued Decision Diagrams(MDD) and AND/OR structures, is presented by Mateescu, Dechter, and Marinescu (2008) and further research along this direction can be found in the work of Mateescu and Dechter (2008). AND/OR search spaces are also applied for solution sampling and counting (Gogate & Dechter, 2008). Smooth Deterministic Decomposable Negative Normal Forms (sd-DNNF) (Darwiche, 2001) exhibit explicit AND/OR DAG structure and have been used for various applications including compiling knowledge (Darwiche, 1999), estimating belief states (Elliott & Williams, 2006), etc. Apart from the domains of planning, constraint satisfaction, knowledge based reasoning, etc., AND/OR structure based techniques are also widely used for various application based domains, e.g., web service composition (Gu, Xu, & Li, 2010; Shin, Jeon, & Lee, 2010; Gu, Li, & Xu, 2008; Ma, Dong, & He, 2008; Yan, Xu, & Gu, 2008; Lang & Su, 2005), vision and graphics tasks (Chen, Xu, Liu, & Zhu, 2006), etc. Lang and Su (2005) have described an AND/OR graph search algorithm for composing web services for user requirements.",
      "startOffset" : 143,
      "endOffset" : 1770
    }, {
      "referenceID" : 1,
      "context" : "The problem of generating solutions for such representations has been studied extensively (Hansen & Zilberstein, 2001; Jiménez & Torras, 2000; Chakrabarti, 1994). Dechter and Mateescu (2007) have presented the explicit AND/OR search space perspective for graphical models. Different search strategies (best first, branch and bound, etc.) over the AND/OR search spaces in graphical models are discussed by Marinescu and Dechter (2007b, 2006). AND/OR search spaces are also used for solving mixed integer linear programming (Marinescu & Dechter, 2005), 0/1 integer Programming (Marinescu & Dechter, 2007a), combinatorial optimization in graphical models (Marinescu & Dechter, 2009a, 2009b). AND/OR Multivalued Decision Diagrams (AOMDD), which combine the idea of Multi-Valued Decision Diagrams(MDD) and AND/OR structures, is presented by Mateescu, Dechter, and Marinescu (2008) and further research along this direction can be found in the work of Mateescu and Dechter (2008). AND/OR search spaces are also applied for solution sampling and counting (Gogate & Dechter, 2008). Smooth Deterministic Decomposable Negative Normal Forms (sd-DNNF) (Darwiche, 2001) exhibit explicit AND/OR DAG structure and have been used for various applications including compiling knowledge (Darwiche, 1999), estimating belief states (Elliott & Williams, 2006), etc. Apart from the domains of planning, constraint satisfaction, knowledge based reasoning, etc., AND/OR structure based techniques are also widely used for various application based domains, e.g., web service composition (Gu, Xu, & Li, 2010; Shin, Jeon, & Lee, 2010; Gu, Li, & Xu, 2008; Ma, Dong, & He, 2008; Yan, Xu, & Gu, 2008; Lang & Su, 2005), vision and graphics tasks (Chen, Xu, Liu, & Zhu, 2006), etc. Lang and Su (2005) have described an AND/OR graph search algorithm for composing web services for user requirements. Ma et al. (2008) have advocated the use of AND/OR trees to capture dependencies between the inputs and outputs of the component web services and propose a top-down search algorithm to generate solutions of the AND/OR tree.",
      "startOffset" : 143,
      "endOffset" : 1885
    }, {
      "referenceID" : 1,
      "context" : "The problem of generating solutions for such representations has been studied extensively (Hansen & Zilberstein, 2001; Jiménez & Torras, 2000; Chakrabarti, 1994). Dechter and Mateescu (2007) have presented the explicit AND/OR search space perspective for graphical models. Different search strategies (best first, branch and bound, etc.) over the AND/OR search spaces in graphical models are discussed by Marinescu and Dechter (2007b, 2006). AND/OR search spaces are also used for solving mixed integer linear programming (Marinescu & Dechter, 2005), 0/1 integer Programming (Marinescu & Dechter, 2007a), combinatorial optimization in graphical models (Marinescu & Dechter, 2009a, 2009b). AND/OR Multivalued Decision Diagrams (AOMDD), which combine the idea of Multi-Valued Decision Diagrams(MDD) and AND/OR structures, is presented by Mateescu, Dechter, and Marinescu (2008) and further research along this direction can be found in the work of Mateescu and Dechter (2008). AND/OR search spaces are also applied for solution sampling and counting (Gogate & Dechter, 2008). Smooth Deterministic Decomposable Negative Normal Forms (sd-DNNF) (Darwiche, 2001) exhibit explicit AND/OR DAG structure and have been used for various applications including compiling knowledge (Darwiche, 1999), estimating belief states (Elliott & Williams, 2006), etc. Apart from the domains of planning, constraint satisfaction, knowledge based reasoning, etc., AND/OR structure based techniques are also widely used for various application based domains, e.g., web service composition (Gu, Xu, & Li, 2010; Shin, Jeon, & Lee, 2010; Gu, Li, & Xu, 2008; Ma, Dong, & He, 2008; Yan, Xu, & Gu, 2008; Lang & Su, 2005), vision and graphics tasks (Chen, Xu, Liu, & Zhu, 2006), etc. Lang and Su (2005) have described an AND/OR graph search algorithm for composing web services for user requirements. Ma et al. (2008) have advocated the use of AND/OR trees to capture dependencies between the inputs and outputs of the component web services and propose a top-down search algorithm to generate solutions of the AND/OR tree. Further research that uses AND/OR structures in the context of web service composition can be found in the works of Gu et al. (2010, 2008), Shin et al. (2010) and Yan et al.",
      "startOffset" : 143,
      "endOffset" : 2250
    }, {
      "referenceID" : 1,
      "context" : "The problem of generating solutions for such representations has been studied extensively (Hansen & Zilberstein, 2001; Jiménez & Torras, 2000; Chakrabarti, 1994). Dechter and Mateescu (2007) have presented the explicit AND/OR search space perspective for graphical models. Different search strategies (best first, branch and bound, etc.) over the AND/OR search spaces in graphical models are discussed by Marinescu and Dechter (2007b, 2006). AND/OR search spaces are also used for solving mixed integer linear programming (Marinescu & Dechter, 2005), 0/1 integer Programming (Marinescu & Dechter, 2007a), combinatorial optimization in graphical models (Marinescu & Dechter, 2009a, 2009b). AND/OR Multivalued Decision Diagrams (AOMDD), which combine the idea of Multi-Valued Decision Diagrams(MDD) and AND/OR structures, is presented by Mateescu, Dechter, and Marinescu (2008) and further research along this direction can be found in the work of Mateescu and Dechter (2008). AND/OR search spaces are also applied for solution sampling and counting (Gogate & Dechter, 2008). Smooth Deterministic Decomposable Negative Normal Forms (sd-DNNF) (Darwiche, 2001) exhibit explicit AND/OR DAG structure and have been used for various applications including compiling knowledge (Darwiche, 1999), estimating belief states (Elliott & Williams, 2006), etc. Apart from the domains of planning, constraint satisfaction, knowledge based reasoning, etc., AND/OR structure based techniques are also widely used for various application based domains, e.g., web service composition (Gu, Xu, & Li, 2010; Shin, Jeon, & Lee, 2010; Gu, Li, & Xu, 2008; Ma, Dong, & He, 2008; Yan, Xu, & Gu, 2008; Lang & Su, 2005), vision and graphics tasks (Chen, Xu, Liu, & Zhu, 2006), etc. Lang and Su (2005) have described an AND/OR graph search algorithm for composing web services for user requirements. Ma et al. (2008) have advocated the use of AND/OR trees to capture dependencies between the inputs and outputs of the component web services and propose a top-down search algorithm to generate solutions of the AND/OR tree. Further research that uses AND/OR structures in the context of web service composition can be found in the works of Gu et al. (2010, 2008), Shin et al. (2010) and Yan et al. (2008). Chen et al.",
      "startOffset" : 143,
      "endOffset" : 2272
    }, {
      "referenceID" : 1,
      "context" : "The problem of generating solutions for such representations has been studied extensively (Hansen & Zilberstein, 2001; Jiménez & Torras, 2000; Chakrabarti, 1994). Dechter and Mateescu (2007) have presented the explicit AND/OR search space perspective for graphical models. Different search strategies (best first, branch and bound, etc.) over the AND/OR search spaces in graphical models are discussed by Marinescu and Dechter (2007b, 2006). AND/OR search spaces are also used for solving mixed integer linear programming (Marinescu & Dechter, 2005), 0/1 integer Programming (Marinescu & Dechter, 2007a), combinatorial optimization in graphical models (Marinescu & Dechter, 2009a, 2009b). AND/OR Multivalued Decision Diagrams (AOMDD), which combine the idea of Multi-Valued Decision Diagrams(MDD) and AND/OR structures, is presented by Mateescu, Dechter, and Marinescu (2008) and further research along this direction can be found in the work of Mateescu and Dechter (2008). AND/OR search spaces are also applied for solution sampling and counting (Gogate & Dechter, 2008). Smooth Deterministic Decomposable Negative Normal Forms (sd-DNNF) (Darwiche, 2001) exhibit explicit AND/OR DAG structure and have been used for various applications including compiling knowledge (Darwiche, 1999), estimating belief states (Elliott & Williams, 2006), etc. Apart from the domains of planning, constraint satisfaction, knowledge based reasoning, etc., AND/OR structure based techniques are also widely used for various application based domains, e.g., web service composition (Gu, Xu, & Li, 2010; Shin, Jeon, & Lee, 2010; Gu, Li, & Xu, 2008; Ma, Dong, & He, 2008; Yan, Xu, & Gu, 2008; Lang & Su, 2005), vision and graphics tasks (Chen, Xu, Liu, & Zhu, 2006), etc. Lang and Su (2005) have described an AND/OR graph search algorithm for composing web services for user requirements. Ma et al. (2008) have advocated the use of AND/OR trees to capture dependencies between the inputs and outputs of the component web services and propose a top-down search algorithm to generate solutions of the AND/OR tree. Further research that uses AND/OR structures in the context of web service composition can be found in the works of Gu et al. (2010, 2008), Shin et al. (2010) and Yan et al. (2008). Chen et al. (2006) have applied explicit AND/OR structures for cloth modeling and recognition which is an important problem in vision and graphics tasks.",
      "startOffset" : 143,
      "endOffset" : 2292
    }, {
      "referenceID" : 45,
      "context" : "These approaches (Ebendt & Drechsler, 2009; Pearl, 1984) were developed to adapt the A* algorithm for using inadmissible heuristics, leveraging multiple heuristics (Chakrabarti, Ghose, Pandey, & DeSarkar, 1989), generating solutions quickly within bounded sub-optimality, etc.",
      "startOffset" : 17,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "These approaches (Ebendt & Drechsler, 2009; Pearl, 1984) were developed to adapt the A* algorithm for using inadmissible heuristics, leveraging multiple heuristics (Chakrabarti, Ghose, Pandey, & DeSarkar, 1989), generating solutions quickly within bounded sub-optimality, etc. Typically these techniques order the Open list using one evaluation function, and the next element for expansion is selected from an ordered subset of Open using some other criterion. Similar techniques can be developed for AO* search if ordered set of potential solutions are made available. That set can be used for node selection and expansion instead of expanding nodes only from the current best psg. This opens up an interesting area with significant research potential where the existing variations of the A* algorithm can be extended for AND/OR search spaces. In the context of model based programming, the problem of finding ordered set of solutions has significant importance. Elliott (2007) has used valued sd-DNNFs to represent the problem and proposed an approach to generate k-best solutions.",
      "startOffset" : 165,
      "endOffset" : 979
    }, {
      "referenceID" : 1,
      "context" : "These approaches (Ebendt & Drechsler, 2009; Pearl, 1984) were developed to adapt the A* algorithm for using inadmissible heuristics, leveraging multiple heuristics (Chakrabarti, Ghose, Pandey, & DeSarkar, 1989), generating solutions quickly within bounded sub-optimality, etc. Typically these techniques order the Open list using one evaluation function, and the next element for expansion is selected from an ordered subset of Open using some other criterion. Similar techniques can be developed for AO* search if ordered set of potential solutions are made available. That set can be used for node selection and expansion instead of expanding nodes only from the current best psg. This opens up an interesting area with significant research potential where the existing variations of the A* algorithm can be extended for AND/OR search spaces. In the context of model based programming, the problem of finding ordered set of solutions has significant importance. Elliott (2007) has used valued sd-DNNFs to represent the problem and proposed an approach to generate k-best solutions. Since valued sd-DNNFs have an AND/OR structure, the proposed approach is possibly the earliest algorithm for generating ordered set of solutions of an AND/OR structure. The problem of finding ordered set of solutions for graphical models is studied by Flerova and Dechter (2011, 2010). However these techniques use alternative representations for the algorithm, where AND/OR search spaces can be constructed (Dechter & Mateescu, 2007) for graphical models. Recent research involving AOMDD based representation on weighted structures suggested future extensions towards generalizing Algebraic Decision Diagrams and introduces the notion of cost in AOMDDs. We envisage that ordered set of solutions finds useful applications in the context of research around AND/OR decision diagram based representation. In the domain of service composition, the primary motivation behind providing a set of alternative solutions ordered by cost is to offer more choices, while trading off the specified cost criterion (to a limited extent) in favor of other ‘unspecified’ criteria (primarily from the standpoint of quality). Shiaa, Fladmark, and Thiell (2008) have presented an approach for generating a ranked set of solutions for the service composition problem.",
      "startOffset" : 165,
      "endOffset" : 2227
    }, {
      "referenceID" : 49,
      "context" : "Other researchers applied the k-shortest path problem to practical scenarios, such as, routing and transportation, and developed specific solutions (Takkala, Borndörfer, & Löbel, 2000; Subramanian, 1997; Topkis, 1988; Sugimoto & Katoh, 1985).",
      "startOffset" : 148,
      "endOffset" : 241
    }, {
      "referenceID" : 52,
      "context" : "Other researchers applied the k-shortest path problem to practical scenarios, such as, routing and transportation, and developed specific solutions (Takkala, Borndörfer, & Löbel, 2000; Subramanian, 1997; Topkis, 1988; Sugimoto & Katoh, 1985).",
      "startOffset" : 148,
      "endOffset" : 241
    }, {
      "referenceID" : 22,
      "context" : "For discrete optimization problems, Lawler (1972) had proposed a general procedure for generating k-best solutions.",
      "startOffset" : 36,
      "endOffset" : 50
    }, {
      "referenceID" : 22,
      "context" : "For discrete optimization problems, Lawler (1972) had proposed a general procedure for generating k-best solutions. A similar problem of finding k most probable configurations in probabilistic expert systems is addressed by Nilsson (1998). Fromer and Globerson (2009) have addressed the problem of finding k maximum probability assignments for probabilistic modeling using LP relaxation.",
      "startOffset" : 36,
      "endOffset" : 239
    }, {
      "referenceID" : 13,
      "context" : "Fromer and Globerson (2009) have addressed the problem of finding k maximum probability assignments for probabilistic modeling using LP relaxation.",
      "startOffset" : 0,
      "endOffset" : 28
    }, {
      "referenceID" : 11,
      "context" : "In the context of ordinary graphs, Eppstein (1990) has studied the problem of finding k-smallest spanning trees.",
      "startOffset" : 35,
      "endOffset" : 51
    }, {
      "referenceID" : 11,
      "context" : "In the context of ordinary graphs, Eppstein (1990) has studied the problem of finding k-smallest spanning trees. Subsequently, an algorithm for finding k-best shortest paths has been proposed in Eppstein’s (1998) work.",
      "startOffset" : 35,
      "endOffset" : 213
    }, {
      "referenceID" : 11,
      "context" : "In the context of ordinary graphs, Eppstein (1990) has studied the problem of finding k-smallest spanning trees. Subsequently, an algorithm for finding k-best shortest paths has been proposed in Eppstein’s (1998) work. Hamacher and Queyranne (1985) have suggested an algorithm for k-best solutions to combinatorial optimization problems.",
      "startOffset" : 35,
      "endOffset" : 249
    }, {
      "referenceID" : 4,
      "context" : "Algorithms for generating k-best perfect matching are presented by Chegireddy and Hamacher (1987). Other researchers applied the k-shortest path problem to practical scenarios, such as, routing and transportation, and developed specific solutions (Takkala, Borndörfer, & Löbel, 2000; Subramanian, 1997; Topkis, 1988; Sugimoto & Katoh, 1985).",
      "startOffset" : 67,
      "endOffset" : 98
    }, {
      "referenceID" : 4,
      "context" : "Algorithms for generating k-best perfect matching are presented by Chegireddy and Hamacher (1987). Other researchers applied the k-shortest path problem to practical scenarios, such as, routing and transportation, and developed specific solutions (Takkala, Borndörfer, & Löbel, 2000; Subramanian, 1997; Topkis, 1988; Sugimoto & Katoh, 1985). However none of the approaches seems to be directly applicable for AND/OR structures. Recently some schemes related to ordered solutions to graphical models (Flerova & Dechter, 2011, 2010) and anytime AND/OR graph search (Otten & Dechter, 2011) have been proposed. Anytime algorithms for traditional OR search space (Hansen & Zhou, 2007) are well addressed by the research community. In this paper, we address the problem of generating ordered set of solutions for explicit AND/OR DAG structure and present new algorithms. The existing method, proposed by Elliott (2007), works bottom-up by computing k-best solutions for the current node from the k-best solutions of its children nodes.",
      "startOffset" : 67,
      "endOffset" : 913
    }, {
      "referenceID" : 11,
      "context" : "Detailed experimental results, including the comparison of the performance of the proposed algorithms with the existing algorithm (Elliott, 2007), are presented in Section 5.",
      "startOffset" : 130,
      "endOffset" : 145
    }, {
      "referenceID" : 11,
      "context" : "In this section, first we present the existing algorithm (Elliott, 2007) briefly, and then we present our proposed algorithms in detail.",
      "startOffset" : 57,
      "endOffset" : 72
    }, {
      "referenceID" : 11,
      "context" : "1 Existing Bottom-Up Evaluation Based Method for Computing Alternative Solutions We illustrate the working of the existing method that is proposed by Elliott (2007) for computing alternative solutions for trees using an example of an alternating AND/OR tree.",
      "startOffset" : 150,
      "endOffset" : 165
    }, {
      "referenceID" : 11,
      "context" : "The detailed analysis can be found in the work of Elliott (2007). Since, nβ.",
      "startOffset" : 50,
      "endOffset" : 65
    }, {
      "referenceID" : 30,
      "context" : "2 Multipeg Tower of Hanoi Problem Consider the problem of Multipeg Tower of Hanoi (Majumdar, 1996; Gupta, Chakrabarti, & Ghose, 1992).",
      "startOffset" : 82,
      "endOffset" : 133
    } ],
    "year" : 2012,
    "abstractText" : "We present algorithms for generating alternative solutions for explicit acyclic AND/OR structures in non-decreasing order of cost. The proposed algorithms use a best first search technique and report the solutions using an implicit representation ordered by cost. In this paper, we present two versions of the search algorithm – (a) an initial version of the best first search algorithm, ASG, which may present one solution more than once while generating the ordered solutions, and (b) another version, LASG, which avoids the construction of the duplicate solutions. The actual solutions can be reconstructed quickly from the implicit compact representation used. We have applied the methods on a few test domains, some of them are synthetic while the others are based on well known problems including the search space of the 5-peg Tower of Hanoi problem, the matrix-chain multiplication problem and the problem of finding secondary structure of RNA. Experimental results show the efficacy of the proposed algorithms over the existing approach. Our proposed algorithms have potential use in various domains ranging from knowledge based frameworks to service composition, where the AND/OR structure is widely used for representing problems.",
    "creator" : "dvips(k) 5.98 Copyright 2009 Radical Eye Software"
  }
}