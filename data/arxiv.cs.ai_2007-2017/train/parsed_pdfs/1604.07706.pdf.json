{
  "name" : "1604.07706.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Distributed Clustering of Linear Bandits in Peer to Peer Networks",
    "authors" : [ "Nathan Korda", "Balázs Szörényi", "Shuai Li" ],
    "emails" : [ "NATHAN@ROBOTS.OX.AC.UK", "SZORENYI.BALAZS@GMAIL.COM", "SHUAILI.SLI@GMAIL.COM" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Bandits are a class of classic optimisation problems that are fundamental to several important application areas. The most prominent of these is recommendation systems, and they can also arise more generally in networks (see, e.g., (Li et al., 2013; Hao et al., 2015)).\nWe consider settings where a network of agents are trying to solve collaborative linear bandit problems. Sharing experience can improve the performance of both the whole network and each agent simultaneously, while also increasing robustness. However, we want to avoid putting too much strain on communication channels. Communicating every piece of information would just overload these chan-\nProceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\nnels. The solution we propose is a gossip-based information sharing protocol which allows information to diffuse across the network at a small cost, while also providing robustness.\nSuch a set-up would benefit, for example, a small start-up that provides some recommendation system service but has limited resources. Using an architecture that enables the agents (the client’s devices) to exchange data between each other directly and to do all the corresponding computations themselves could significantly decrease the infrastructural costs for the company. At the same time, without a central server, communicating all information instantly between agents would demand a lot of bandwidth.\nMulti-Agent Linear Bandits In the simplest setting we consider, all the agents are trying to solve the same underlying linear bandit problem. In particular, we have a set of nodes V , indexed by i, and representing a finite set of agents. At each time, t:\n• a set of actions (equivalently, the contexts) arrives for each agent i, Dit ⊂ D and we assume the set D is a subset of the unit ball in Rd; • each agent, i, chooses an action (context) xit ∈ Dit, and receives a reward\nrit = (x i t) Tθ + ξit,\nwhere θ is some unknown coefficient vector, and ξit is some zero mean, R-subGaussian noise; • last, the agents can share information according to some protocol across a communication channel.\nWe define the instantaneous regret at each node i, and, respectively, the cumulative regret over the whole network to be:\nρit := ( xi,∗t )T θ − Erit, and Rt := t∑\nk=1\n|V |∑\ni=1\nρit,\nar X\niv :1\n60 4.\n07 70\n6v 3\n[ cs\n.L G\n] 7\nJ un\nwhere xi,∗t := arg maxx∈Dit x Tθ. The aim of the agents is to minimise the rate of increase of cumulative regret. We also wish them to use a sharing protocol that does not impose much strain on the information-sharing communication channel.\nGossip protocol In a gossip protocol (see, e.g., (Kempe et al., 2003; Xiao et al., 2007; Jelasity et al., 2005; 2007)), in each round, an overlay protocol assigns to every agent another agent, with which it can share information. After sharing, the agents aggregate the information and, based on that, they make their corresponding decisions in the next round. In many areas of distributed learning and computation gossip protocols have offered a good compromise between low-communication costs and algorithm performance. Using such a protocol in the multi-agent bandit setting, one faces two major challenges.\nFirst, information sharing is not perfect, since each agent acquires information from only one other (randomly chosen) agent per round. This introduces a bias through the unavoidable doubling of data points. The solution is to mitigate this by using a delay (typically of O(log t)) on the time at which information gathered is used. After this delay, the information is sufficiently mixed among the agents, and the bias vanishes.\nSecond, in order to realize this delay, it is necessary to store information in a buffer and only use it to make decisions after the delay has been passed. In (Szörényi et al., 2013) this was achieved by introducing an epoch structure into their algorithm, and emptying the buffers at the end of each epoch.\nThe Distributed Confidence Ball Algorithm (DCB) We use a gossip-based information sharing protocol to produce a distributed variant of the generic Confidence Ball (CB) algorithm, (Abbasi-Yadkori et al., 2011; Dani et al., 2008; Li et al., 2010). Our approach is similar to (Szörényi et al., 2013) where the authors produced a distributed -greedy algorithm for the simpler multi-armed bandit problem. However their results do not generalise easily, and thus significant new analysis is needed. One reason is that the linear setting introduces serious complications in the analysis of the delay effect mentioned in the previous paragraphs. Additionally, their algorithm is epoch-based, whereas we are using a more natural and simpler algorithmic structure. The downside is that the size of the buffers of our algorithm grow with time. However, our analyses easily transfer to the epoch approach too. As the rate of growth is logarithmic, our algorithm is still efficient over a very long timescale.\nThe simplifying assumption so far is that all agents are solving the same underlying bandit problem, i.e. finding the same unknown θ-vector. This, however, is often unre-\nalistic, and so we relax it in our next setup. While it may have uses in special cases, DCB and its analysis can be considered as a base for providing an algorithm in this more realistic setup, where some variation in θ is allowed across the network.\nClustered Linear Bandits Proposed in (Gentile et al., 2014; Li et al., 2016a;b), this has recently proved to be a very successful model for recommendation problems with massive numbers of users. It comprises a multi-agent linear bandit model agents’ θ-vectors are allowed to vary across a clustering. This clustering presents an additional challenge to find the groups of agents sharing the same underlying bandit problem before information sharing can accelerate the learning process. Formally, let {Uk}k=1,...,M be a clustering of V , assume some coefficient vector θk for each k, and let for agent i ∈ Uk the reward of action xit be given by\nrit = (x i t) Tθk + ξit.\nBoth clusters and coefficient vectors are assumed to be initially unknown, and so need to be learnt on the fly.\nThe Distributed Clustering Confidence Ball Algorithm (DCCB) The paper (Gentile et al., 2014) proposes the initial centralised approach to the problem of clustering linear bandits. Their approach is to begin with a single cluster, and then incrementally prune edges when the available information suggests that two agents belong to different clusters. We show how to use a gossip-based protocol to give a distributed variant of this algorithm, which we call DCCB.\nOur main contributions In Theorems 1 and 6 we show our algorithms DCB and DCCB achieve, in the multi-agent and clustered setting, respectively, near-optimal improvements in the regret rates. In particular, they are of order almost √ |V | better than applying CB without information sharing, while still keeping communication cost low. And our findings are demonstrated by experiments on realworld benchmark data."
    }, {
      "heading" : "2. Linear Bandits and the DCB Algorithm",
      "text" : "The generic Confidence Ball (CB) algorithm is designed for a single agent linear bandit problem (i.e. |V | = 1). The algorithm maintains a confidence ball Ct ⊂ Rd within which it believes the true parameter θ lies with high probability. This confidence ball is computed from the observation pairs, (xk, rk)k=1,...,t (for the sake of simplicity, we dropped the agent index, i). Typically, the covariance matrix At = ∑t k=1 xkx T k and b-vector, bt = ∑t k=1 rkxk, are sufficient statistics to characterise this confidence ball. Then, given its current action set, Dt, the agent selects the optimistic action, assuming that the true parameter sits in Ct, i.e. (xt,∼) = arg max(x,θ′)∈Dt×Ct{xTθ′}. Pseudocode for CB is given in the Appendix A.1.\nGossip Sharing Protocol for DCB We assume that the agents are sharing across a peer to peer network, i.e. every agent can share information with every other agent, but that every agent can communicate with only one other agent per round. In our algorithms, each agent, i, needs to maintain\n(1) a buffer (an ordered set)Ait of covariance matrices and an active covariance matrix Ãit, (2) a buffer Bit of b-vectors and an active b-vector b̃it,\nInitially, we set, for all i ∈ V , Ãi0 = I , b̃i0 = 0. These active objects are used by the algorithm as sufficient statistics from which to calculate confidence balls, and summarise only information gathered before or during time τ(t), where τ is an arbitrary monotonically increasing function satisfying τ(t) < t. The buffers are initially set to Ai0 = ∅, and Bi0 = ∅. For each t > 1, each agent, i, shares and updates its buffers as follows:\n(1) a random permutation, σ, of the numbers 1, . . . , |V | is chosen uniformly at random in a decentralised manner among the agents,1\n(2) the buffers of i are then updated by averaging its buffers with those of σ(i), and then extending them using their current observations2\nAit+1 = (( 1 2 (Ait +A σ(i) t ) ) ◦ ( xit+1 ( xit+1 )T)) ,\nBit+1 = (( 1 2 (Bit + B σ(i) t ) ) ◦ ( rit+1x i t+1 )) ,\nÃit+1 = Ã i t + Ã σ(i) t , and b̃ i t+1 = b̃ i t + b̃ σ(i) t .\n(3) if the length |Ait+1| exceeds t − τ(t), the first element ofAit+1 is added to Ãit+1 and deleted fromAit+1. Bit+1 and b̃it+1 are treated similarly.\nIn this way, each buffer remains of size at most t−τ(t), and contains only information gathered after time τ(t). The result is that, after t rounds of sharing, the current covariance matrices and b-vectors used by the algorithm to make decisions have the form:\nÃit := I +\nτ(t)∑\nt′=1\n|V |∑\ni′=1\nwi ′,t′ i,t x i′ t′x i′ t′ T ,\nand b̃it := τ(t)∑\nt′=1\n|V |∑\ni′=1\nwi ′,t′ i,t r i′ t′x i′ t′ .\nwhere the weights wi ′,t′\ni,t are random variables which are unknown to the algorithm. Importantly for our analysis, as\n1This can be achieved in a variety of ways. 2The ◦ symbol denotes the concatenation operation on two ordered sets: if x = (a, b, c) and y = (d, e, f), then x ◦ y = (a, b, c, d, e, f), and y ◦ x = (d, e, f, a, b, c).\na result of the overlay protocol’s uniformly random choice of σ, they are identically distributed (i.d.) for each fixed pair (t, t′), and ∑ i′∈V w i′,t′\ni,t = |V |. If information sharing was perfect at each time step, then the current covariance matrix could be computed using all the information gathered by all the agents, and would be:\nAt := I +\n|V |∑\ni′=1\nt∑\nt′=1\nxi ′\nt′\n( xi ′\nt′\n)T . (1)\nDCB algorithm The OFUL algorithm (Abbasi-Yadkori et al., 2011) is an improvement of the confidence ball algorithm from (Dani et al., 2008), which assumes that the confidence balls Ct can be characterised by At and bt. In the DCB algorithm, each agent i ∈ V maintains a confidence ball Cit for the unknown parameter θ as in the OFUL algorithm, but calculated from Ãit and b̃ i t. It then chooses its action, xit, to satisfy (x i t, θ i t) = arg max(x,θ)∈Dit×Cit x\nTθ, and receives a reward rit. Finally, it shares its information buffer according to the sharing protocol above. Pseudocode for DCB is given in Appendix A.1, and in Algorithm 1."
    }, {
      "heading" : "2.1. Results for DCB",
      "text" : "Theorem 1. Let τ(·) : t→ 4 log(|V | 32 t). Then, with probability 1− δ, the regret of DCB is bounded by\nRt ≤ (N(δ)|V |+ ν(|V |, d, t)) ‖θ‖2\n+ 4e2 (β(t) + 4R) √ |V |t ln ( (1 + |V |t/d)d ) ,\nwhere ν(|V |, d, t) := (d+1)d2(4|V | ln(|V | 32 t))3,N(δ) :=√ 3/((1− 2− 14 ) √ δ), and\nβ(t) := R √√√√ln (\n(1 + |V |t/d)d δ\n) + ‖θ‖2. (2)\nThe term ν(t, |V |, d) describes the loss compared to the centralised algorithm due to the delay in using information, while N(δ)|V | describes the loss due to the incomplete mixing of the data across the network.\nIf the agents implement CB independently and do not share any information, which we call CB-NoSharing, then it follows from the results in (Abbasi-Yadkori et al., 2011), the equivalent regret bound would be\nRt ≤|V |β(t) √ t ln ((1 + t/d)d) (3)\nComparing Theorem 1 with (3) tells us that, after an initial “burn in” period, the gain in regret performance of DCB over CB-NoSharing is of order almost √ |V |.\nCorollary 2. We can recover a bound in expectation from Theorem 1, by using the value δ = 1/ √ |V |t:\nE[Rt] ≤ O(t 1 4 ) + √ |V |t‖θ‖2\n+ 4e2 ( R √ ln ( (1 + |V |t/d)d √ |V |t ) + ‖θ‖2 + 4R )\n× √ |V |t ln ((1 + |V |t/d)d).\nThis shows that DCB exhibits asymptotically optimal regret performance, up to log factors, in comparison with any algorithm that can share its information perfectly between agents at each round."
    }, {
      "heading" : "COMMUNICATION COMPLEXITY",
      "text" : "If the agents communicate their information to each other at each round without a central server, then every agent would need to communicate their chosen action and reward to every other agent at each round, giving a communication cost of order d|V |2 per-round. We call such an algorithm CBInstSharing. Under the gossip protocol we propose each agent requires at most O(log2(|V |t)d2|V |) bits to be communicated per round. Therefore, a significant communication cost reduction is gained when log(|V |t)d |V |. Using an epoch-based approach, as in (Szörényi et al., 2013), the per-round communication cost of the gossip protocol becomes O(d2|V |). This improves efficiency over any horizon, requiring only that d |V |, and the proofs of the regret performance are simple modifications of those for DCB. However, in comparison with growing buffers this is only an issue after O(exp(|V |)) number of rounds, and typically |V | is large. While the DCB has a clear communication advantage over CB-InstSharing, there are other potential approaches to this problem. For example, instead of randomised neighbour sharing one can use a deterministic protocol such as RoundRobin (RR), which can have the same low communication costs as DCB. However, the regret bound for RR suffers from a naturally larger delay in the network than DCB. Moreover, attempting to track potential doubling of data points when using a gossip protocol, instead of employing a delay, leads back to a communication cost of order |V |2 per round. More detail is included in Appendix A.2."
    }, {
      "heading" : "PROOF OF THEOREM 1",
      "text" : "In the analysis we show that the bias introduced by imperfect information sharing is mitigated by delaying the inclusion of the data in the estimation of the parameter θ. The proof builds on the analysis in (Abbasi-Yadkori et al., 2011). The emphasis here is to show how to handle the extra difficulty stemming from imperfect information sharing, which results in the influence of the various rewards\nat the various peers being unbalanced and appearing with a random delay. Proofs of the Lemmas 3 and 4, and of Proposition 1 are crucial, but technical, and are deferred to Appendix A.3.\nStep 1: Define modified confidence ellipsoids. First we need a version of the confidence ellipsoid theorem given in (Abbasi-Yadkori et al., 2011) that incorporates the bias introduced by the random weights: Proposition 1. Let δ > 0, θ̃it := (Ãit)−1b̃it, W (τ) := max{wi ′,t′\ni,t : t, t ′ ≤ τ, i, i′ ∈ V }, and let\nCit := { x ∈ Rd :‖θ̃it − x‖Ãit ≤ ‖θ‖2 (4)\n+W (τ(t))R √ 2 log ( det(Ãit) 1 2 /δ )} .\nThen with probability 1− δ, θ ∈ Cit . In the rest of the proof we assume that θ ∈ Cit . Step 2: Instantaneous regret decomposition. Denote by (xit, θ i t) = arg maxx∈Dit,y∈Cit x\nTy. Then we can decompose the instantaneous regret, following a classic argument (see the proof of Theorem 3 in (Abbasi-Yadkori et al., 2011)):\nρit = ( xi,∗t )T θ − (xit)Tθ ≤ ( xit )T θit − (xit)Tθ\n= ( xit )T [( θit − θ̃it ) + ( θ̃it − θ )] ≤ ‖xit‖(Ãit)−1 [∥∥∥θit − θ̃it ∥∥∥ Ãit + ∥∥∥θ̃it − θ ∥∥∥ Ãit ] (5)\nStep 3: Control the bias. The norm differences inside the square brackets of the regret decomposition are bounded through (4) in terms of the matrices Ãit. We would like, instead, to have the regret decomposition in terms of the matrix At (which is defined in (1)). To this end, we give some lemmas showing that using the matrices Ãit is almost the same as using At. These lemmas involve elementary matrix analysis, but are crucial for understanding the impact of imperfect information sharing on the final regret bounds.\nStep 3a: Control the bias coming from the weight imbalance. Lemma 3 (Bound on the influence of general weights). For all i ∈ V and t > 0,\n‖xit‖2(Ãit)−1 ≤ e ∑τ(t) t′=1 ∑|V | i′=1 ∣∣∣wi′,t′i,t −1∣∣∣‖xit‖2(Aτ(t))−1 , and det ( Ãit ) ≤ e ∑τ(t) t′=1 ∑|V | i′=1\n∣∣∣wi′,t′i,t −1∣∣∣ det (Aτ(t)) . Using Lemma 4 in (Szörényi et al., 2013), by exploiting the random weights are identically distributed (i.d.) for each\nfixed pair (t, t′), and ∑ i′∈V w i′,t′\ni,t = |V | under our gossip protocol, we can control the random exponential constant in Lemma 3, and the upper bound W (T ) using the Chernoff-Hoeffding bound:\nLemma 4 (Bound on the influence of weights under our sharing protocol). Fix some constants 0 < δt′ < 1. Then with probability 1−∑τ(t)t′=1 δt′\n|V |∑\ni′=1\nτ(t)∑\nt′=1\n∣∣∣wi ′,t′ i,t − 1 ∣∣∣ ≤ |V | 32 τ(t)∑\nt′=1\n( 2(t−t ′)δt′ )− 12 ,\nand W (T ) ≤ 1 + max 1≤t′≤τ(t)\n{ |V | 32 ( 2(t−t ′)δt′ )− 12} .\nIn particular, for any δ ∈ (0, 1), choosing δt′ = δ2 t′−t\n2 , with probability 1− δ/(|V |3t2(1− 2−1/2)) we have\n|V |∑\ni′=1\nτ(t)∑\nt′=1\n∣∣∣wi ′,t′ i,t − 1 ∣∣∣ ≤ 1\n(1− 2− 14 )t √ δ ,\nand W (τ(t)) ≤ 1 + |V | 3 2\nt √ δ . (6)\nThus Lemma 3 and 4 give us control over the bias introduced by the imperfect information sharing. Combining them with Equations (4) and (5) we find that with probability 1− δ/(|V |3t2(1− 2−1/2)):\nρit ≤2eC(t)‖xit‖(Ai τ(t) )−1 (1 + C(t)) (7) × [ R √ 2 log ( eC(t) det ( Aτ(t) ) 1 2 δ−1 ) + ‖θ‖ ]\nwhere C(t) := 1/(1− 2−1/4)t √ δ\nStep 3b: Control the bias coming from the delay. Next, we need to control the bias introduced from leaving out the last 4 log(|V |3/2t) time steps from the confidence ball estimation calculation:\nProposition 2. There can be at most\nν(k) := (4|V | log(|V |3/2k))3(d+ 1)d(tr(A0) + 1) (8)\npairs (i, k) ∈ 1, . . . , |V | × {1, . . . , t} for which one of\n‖xik‖2A−1 τ(k) ≥ e‖xik‖2(Ak−1+∑i−1j=1 xjk(xjk)T)−1 ,\nor det ( Aτ(k) ) ≥ edet  Ak−1 + i−1∑\nj=1\nxjk(x j k) T\n  holds.\nStep 4: Choose constants and sum the simple regret. Defining a constant\nN(δ) := 1\n(1− 2− 14 ) √ δ ,\nwe have, for all k ≥ N(δ), C(k) ≤ 1, and so, by (7) with probability 1− (|V |k)−2δ/(1− 2−1/2)\nρik ≤2e‖xik‖A−1 τ(k)\n(9)\n×  2R √√√√√2 log  edet ( Aτ(k) ) 1 2\nδ\n + ‖θ‖2   .\nNow, first applying Cauchy-Schwarz, then step 3b from above together with (9), and finally Lemma 11 from (Abbasi-Yadkori et al., 2011) yields that, with probability 1− ( 1 + ∑∞ t=1(|V |t)−2/(1− 2−1/2) ) δ ≥ 1− 3δ,\nRt ≤N(δ)|V |‖θ‖2 +  |V |t t∑\nt′=N(δ)\n|V |∑\ni=1\n( ρit′ )2   1 2\n≤ (N(δ)|V |+ ν(|V |, d, t)) ‖θ‖2\n+ 4e2 (β(t) + 2R) [ |V |t t∑\nt′=1\nM∑\ni=1\n‖xit‖2(At)−1 ] 1 2\n≤ (N(δ)|V |+ ν(|V |, d, t)) ‖θ‖2 + 4e2 (β(t) + 2R) √ |V |t (2 log (det (At))),\nwhere β(·) is as defined in (2). Replacing δ with δ/3 finishes the proof."
    }, {
      "heading" : "PROOF OF PROPOSITION 2",
      "text" : "This proof forms the major innovation in the proof of Theorem 1. Let (yk)k≥1 be any sequence of vectors such that ‖yk‖2 ≤ 1 for all k, and letBn := B0+ ∑n k=1 yky T\nk, where B0 is some positive definite matrix. Lemma 5. For all t > 0, and for any c ∈ (0, 1), we have ∣∣∣ { k ∈ {1, 2, . . . } : ‖yk‖2B−1k−1 > c }∣∣∣\n≤ (d+ c)d(tr(B−10 )− c)/c2,\nProof. We begin by showing that, for any c ∈ (0, 1)\n‖yk‖2B−1k−1 > c (10)\ncan be true for only 2dc−3 different k.\nIndeed, let us suppose that (10) is true for some k. Let (e\n(k−1) i )1≤i≤d be the orthonormal eigenbasis for Bk−1,\nand, therefore, also for B−1k−1, and write yk = ∑d i=1 αiei. Let, also, (λ(k−1)i ) be the eigenvalues for Bk−1. Then,\nc < yTkB −1 k−1yk =\nd∑\ni=1\nα2i λ (k−1) i ≤ tr(B−1k−1),\n=⇒ ∃j ∈ {1, . . . , d} : α 2 j\nλ (k−1) j , 1 λ (k−1) j > cd ,\nwhere we have used that α2i < 1 for all i, since ‖yk‖2 < 1. Now,\ntr(B−1k−1)− tr(B−1k ) = tr(B−1k−1)− tr((Bk−1 + ykyTk)−1) > tr(B−1k−1)− tr((Bk−1 + α2jejeTj)−1)\n= 1 λ (k−1) j − 1 λ (k−1) j +α 2 j\n= α2j\nλ (k−1) j (λ (k−1) j +α 2 j )\n> ( d2c−2 + dc−1 )−1 > c 2\nd(d+c)\nSo we have shown that (10) implies that\ntr(B−1k−1) > c and tr(B −1 k−1)− tr(B−1k ) >\nc2\nd(d+ c) .\nSince tr(B−10 ) ≥ tr(B−1k−1) ≥ tr(B−1k ) ≥ 0 for all k, it follows that (10) can be true for at most (d+c)d(tr(B−10 )− c)c−2 different k.\nNow, using an argument similar to the proof of Lemma 3, for all k < t\n‖yk+1‖B−1 τ(k) ≤ e ∑k s=τ(k)+1 ‖ys+1‖B−1s ‖yk+1‖B−1k ,\nand det ( Bτ(t) ) ≤ e\n∑t k=τ(t)+1 ‖yk‖2B−1\nk det (Bt) .\nTherefore,\n‖yk+1‖B−1 τ(k) ≥ c‖yk+1‖B−1k or det(Bτ(k)) ≥ cdet(Bk)\n=⇒ k−1∑\ns=τ(k)\n‖ys+1‖B−1s ≥ ln(c)\nHowever, according to Lemma 5, there can be at most\nν(t) := ( d+ ln(c)∆(t) ) d ( tr ( B−10 ) − ln(c)∆(t) )( ∆(t) ln(c) )2\ntimes s ∈ {1, . . . , t}, such that ‖ys+1‖B−1s ≥ ln(c)/∆(t), where ∆(t) := max1≤k≤t{k − τ(k)}. Hence\n∑k s=τ(j)+1 ‖ys+1‖−1Bs ≥ ln(c) is true for at most\n∆(t)ν(|V |, d, t) indices k ∈ {1, . . . , t}.\nFinally, we finish by setting (yk)k≥1 = ◦t≥1(xit)|V |i=1."
    }, {
      "heading" : "3. Clustering and the DCCB Algorithm",
      "text" : "We now incorporate distributed clustering into the DCB algorithm. The analysis of DCB forms the backbone of the analysis of DCCB.\nDCCB Pruning Protocol In order to run DCCB, each agent i must maintain some local information buffers in addition to those used for DCB. These are:\nAlgorithm 1 Distributed Clustering Confidence Ball Input: Size of network |V |, τ : t→ t− 4 log2 t, α, λ Initialization: ∀i ∈ V , set Ãi0 = Id, b̃i0 = 0, Ai0 = Bi0 = ∅, and V i0 = V . for t = 0, . . .∞ do\nDraw a random permutation σ of {1, . . . , V } respecting the current local clusters for i = 1, . . . , |V | do\nReceive action set Dit and construct the confidence ball Cit using Ã i t and b̃ i t Choose action and receive reward: Find (xit+1, ∗) = arg max(x,θ̃)∈Dit×Cit x\nTθ̃, and get reward rit+1 from context x i t+1. Share and update information buffers: if ‖θ̂ilocal − θ̂jlocal‖ > cthreshλ (t)\nUpdate local cluster: V it+1 = V i t \\ {σ(i)}, V σ(i)t+1 = V σ(i) t \\ {i}, and reset according to (13)\nelseif V it = V σ(i) t Set Ait+1 = ( 1 2 (Ait +A σ(i) t ) ) ◦ (xit+1 ( xit+1 )T ) and Bit+1 = ( 1 2 (Bit + B σ(i) t ) ) ◦ (rit+1xit+1) else Update: Set Ait+1 = Ait ◦ (xit+1 ( xit+1 )T ) and Bit+1 = Bit ◦ (rit+1xit+1) endif Update local estimator: Ailocal,t+1 = A i local,t + xit+1 ( xit+1 )T , bilocal,t+1 = b i local,t + r i t+1x i t+1, and θ̂local,t+1 = ( Ailocal,t+1 )−1 bilocal,t+1\nif |Ait+1| > t − τ(t) set Ãit+1 = Ãit + Ait+1(1), Ait+1 = Ait+1 \\ Ait+1(1). Similarly for Bit+1.\nend for end for\n(1) a local covariance matrix Ailocal = A i local,t, a local b-\nvector bilocal = b i local,t,\n(2) and a local neighbour set V it .\nThe local covariance matrix and b-vector are updated as if the agent was applying the generic (single agent) confidence ball algorithm: Ailocal,0 = A0, b i local,0 = 0,\nAilocal,t = x i t(x i t) T +Ailocal,t−1,\nand bilocal,t = r i tx i t + b i local,t−1.\nDCCB Algorithm Each agent’s local neighbour set V it is initially set to V . At each time step t, agent i contacts one other agent, j, at random from V it , and both decide whether they do or do not belong to the same cluster. To do this\nDistributed Clustering of Linear Bandits in Peer to Peer Networks\nthey share local estimates, θ̂it = A i local,t −1 bilocal,t and θ̂ j t = Ajlocal,t −1 bjlocal,t, of the unknown parameter of the bandit problem they are solving, and see if they are further apart than a threshold function c = cthreshλ (t), so that if\n‖θ̂it − θ̂jt‖2 ≥ cthreshλ (t), (11)\nthen V it+1 = V i t \\ {j} and V jt+1 = V jt \\ {i}. Here λ is a parameter of an extra assumption that is needed, as in (Gentile et al., 2014), about the process generating the context sets Dit:\n(A) Each context set Dit = {xk}k is finite and contains i.i.d. random vectors such that for all, k, ‖xk‖ ≤ 1 and E(xkxTk) is full rank, with minimal eigenvalue λ > 0.\nWe define cthreshλ (t), as in (Gentile et al., 2014), by\ncthreshλ (t) := R √\n2d log(t) + 2 log(2/δ) + 1√ 1 + max {Aλ(t, δ/(4d)), 0}\n(12)\nwhere Aλ(t, δ) := λtδ − 8 log t+3δ − 2 √ t log t+3δ .\nThe DCCB algorithm is pretty much the same as the DCB algorithm, except that it also applies the pruning protocol described. In particular, each agent, i, when sharing its information with another, j, has three possible actions:\n(1) if (11) is not satisfied and V it = V j t , then the agents\nshare simply as in the DCB algorithm; (2) if (11) is not satisfied but V it 6= V jt , then no sharing or\npruning occurs. (3) if (11) is satisfied, then both agents remove each other\nfrom their neighbour sets and reset their buffers and active matrices so that\nAi = (0, 0, . . . , Ailocal),Bi = (0, 0, . . . , bilocal), and Ãi = Ailocal, b̃ i = bilocal, (13)\nand similarly for agent j.\nIt is proved in the theorem below, that under this sharing and pruning mechanism, in high probability after some finite time each agent i finds its true cluster, i.e. V it = U\nk. Moreover, since the algorithm resets to its local information each time a pruning occurs, once the true clusters have been identified, each cluster shares only information gathered within that cluster, thus avoiding introducing a bias by sharing information gathered from outside the cluster before the clustering has been identified. Full pseudo-code for\nDistributed Clustering of Linear Bandits in Peer to Peer Networks\nthey share local estimates, ✓̂it = A i local,t 1 bilocal,t and ✓̂ j t = Ajlocal,t 1\nbjlocal,t, of the unknown parameter of the bandit problem they are solving, and see if they are further apart than threshold function c = cthres (t), so that if\nk✓̂it ✓̂jtk2 cthres (t), (11)\nthen V it+1 = V i t \\ {j} and V jt+1 = V jt \\ {i}. Here is a parameter of an extra assumption that is needed, as in (Gentile et al., 2014), about the process generating the context sets Dit:\n(A) Each context set Dit = {xk}k is finite and contains i.i.d. random vectors such that for all, k, kxkk  1 and E(xkxTk) is full rank, with minimal eigenvalue > 0.\nWe define cthresh (t), as in (Gentile et al., 2014), by\ncthresh (t) := R p\n2d log(t) + 2 log(2/ ) + 1p 1 + max {A (t, /(4d)), 0}\n(12)\nwhere A (t, ) := t 8 log t+3 2 q t log t+3 .\nThe DCCB algorithm is pretty much the same as the DCB algorithm, except that it also applies the pruning protocol described. In particular, each agent, i, when sharing its information with another, j, has three possible actions:\n(1) if (11) is not satisfied and V it = V j t , then the agents\nshare simply as in the DCB algorithm; (2) if (11) is satisfied, then both agents remove each other\nfrom their neighbour sets and reset their buffer nd active matrices so that\nAi = (0, 0, . . . , Ailocal), Bi = (0, 0, . . . , bilocal), and Ãi = Ailocal, b̃ i = bilocal, (13)\nand similarly for agent j. (3) if (11) is not satisfied but V it 6= V jt , then no sharing or\npruning occurs.\nIt is proved in the theorem below, that under this sharing and pruning mechanism, in high probability after some finite time each agent i finds its true cluster, i.e. V it = U\nk. Moreover, since the algorithm resets to its local information each time a pruning occurs, once the true clusters have been identified, each cluster shares only information gathered within that cluster, thus avoiding introducing a bias by sharing information gathered from outside the cluster before the clustering has been identified. Full pseudo-code for the DCCB algorithm is given in Algorithm 1, and the differences with the DCB algorithm are highlighted in blue.\n1000 2000 3000 4000 5000 6000 7000 8000 9000 0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\nRounds\nR at\nio o\nf C um\n. R ew\nar ds\no f A\nlg . a\nga in\nst R\nAN\nDelicious Dataset\nDCCB CLUB CB−NoSharing CB−InstSharing\n0 2000 4000 6000 8000 10000 1\n2\n3\n4\n5\n6\n7\nRounds\nR at\nio o\nf C um\n. R ew\nar ds\no f A\nlg . a\nga in\nst R\nAN\nLastFM Dataset\nDCCB CLUB CB−NoSharing CB−InstSharing\n0 2000 4000 6000 8000 10000 0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\nRounds\nR at\nio o\nf C um\n. R ew\nar ds\no f A\nlg . a\nga in\nst R\nAN\nMovieLens Dataset\nDCCB CLUB CB−NoSharing CB−InstSharing\nFigure 1. H re we plot the performance of DCCB in comparison to CLUB, CB-NoSh ring and CB-InstSharing. The plots show the ratio of cumulative rewards achieved by the algorithms to the cumulative rewards achieved by the random algorithm."
    }, {
      "heading" : "3.1. Results for DCCB",
      "text" : "Theorem 6. Assume that (A) holds, and let γ denote the smallest distance between the bandit parameters θk. Then there exists a constant C = C(γ, |V |, λ, δ), such that with probability 1 − δ the total cumulative regret of cluster k when the agents employ DCCB is bounded by\nRt ≤ [ max {√ 2N(δ), C + 4 log2(|V | 3 2C) } |Uk|\n+ ν(|Uk|, d, t) ] ‖θ‖2\n+ 4e (β(t) + 3R) √ |Uk|t ln ( (1 + |Uk|t/d)d ) ,\nwhere N and ν are as defined in Theorem 1, and β(t) :=\nR √ 2 ln ( (1 + |Uk|t/d)d ) + ‖θ‖2.\nThe constant C(γ, |V |, λ, δ) is the time that you have to wait for the true clustering to have been identified,\nThe analysis follows the following scheme: When the true clusters have been correctly identified by all nodes, within each cluster the algorithm, and thus the analysis, reduces to the case of Section 2.1. We adapt results from (Gentile et al., 2014) to show how long it will be before the true clusters are identified, in high probability. The proof is deferred to Appendices A.4 and A.5."
    }, {
      "heading" : "4. Experiments and Discussion",
      "text" : "Experiments We closely implemented the experimental setting and dataset construction principles used in (Li et al., 2016a;b), and for a detailed description of this we refer the reader to (Li et al., 2016a). We evaluated DCCB on three real-world datasets against its centralised counterpart CLUB, and against the benchmarks used therein, CBNoSharing, and CB-InstSharing. The LastFM dataset comprises of 91 users, each of which appear at least 95 times. The Delicious dataset has 87 users, each of which appear at least 95 times. The MovieLens dataset contains 100 users, each of which appears at least 250 times. The performance was measured using the ratio of cumulative reward of each algorithm to that of the predictor which chooses a random action at each time step. This is plotted in in Figure 1. From the experimental results it is clear that DCCB performs comparably to CLUB in practice, and both outperform CB-NoSharing, and CB-InstSharing.\nRelationship to existing literature There are several strands of research that are relevant and complimentary to this work. First, there is a large literature on single agent linear bandits, and other more, or less complicated bandit problem settings. There is already work on distributed approaches to multi-agent, multi-armed bandits, not least\n(Szörényi et al., 2013) which examines -greedy strategies over a peer to peer network, and provided an initial inspiration for this current work. The paper (Kalathil et al., 2014) examines the extreme case when there is no communication channel across which the agents can communicate, and all communication must be performed through observation of action choices alone. Another approach to the multi-armed bandit case, (Nayyar et al., 2015), directly incorporates the communication cost into the regret.\nSecond, there are several recent advances regarding the state-of-the-art methods for clustering of bandits. The work (Li et al., 2016a) is a faster variant of (Gentile et al., 2014) which adopt the strategy of boosted training stage. In (Li et al., 2016b) the authors not only cluster the users, but also cluster the items under collaborative filtering case with a sharp regret analysis.\nFinally, the paper (Tekin & van der Schaar, 2013) treats a setting similar to ours in which agents attempt to solve contextual bandit problems in a distributed setting. They present two algorithms, one of which is a distributed version of the approach taken in (Slivkins, 2014), and show that they achieve at least as good asymptotic regret performance in the distributed approach as the centralised algorithm achieves. However, rather than sharing information across a limited communication channel, they allow each agent only to ask another agent to choose their action for them. This difference in our settings is reflected worse regret bounds, which are of order Ω(T 2/3) at best.\nDiscussion Our analysis is tailored to adapt proofs from (Abbasi-Yadkori et al., 2011) about generic confidence ball algorithms to a distributed setting. However many of the elements of these proofs, including Propositions 1 and 2 could be reused to provide similar asymptotic regret guarantees for the distributed versions of other bandit algorithms, e.g., the Thompson sampling algorithms, (Agrawal & Goyal, 2013; Kaufmann et al., 2012; Russo & Van Roy, 2014).\nBoth DCB and DCCB are synchronous algorithms. The work on distributed computation through gossip algorithms in (Boyd et al., 2006) could alleviate this issue. The current pruning algorithm for DCCB guarantees that techniques from (Szörényi et al., 2013) can be applied to our algorithms. However the results in (Boyd et al., 2006) are more powerful, and could be used even when the agents only identify a sub-network of the true clustering.\nFurthermore, there are other existing interesting algorithms for performing clustering of bandits for recommender systems, such as COFIBA in (Li et al., 2016b). It would be interesting to understand how general the techniques applied here to CLUB are."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We would like to thank the anonymous reviewers for their helpful comments. We would also like to thank Gergley Neu for very useful discussions. NK thanks the support from EPSRC Autonomous Intelligent Systems project EP/I011587. SL thanks the support from MIUR, QCRIHBKU, Amazon Research Grant and Tsinghua University. The research leading to these results has received funding from the European Research Council under the European Union’s Seventh Framework Programme (FP/2007-2013) / ERC Grant Agreement n. 306638."
    }, {
      "heading" : "A. Supplementary Material",
      "text" : "A.1. Pseudocode for the generic CB algorithm and the DCB algorithm\nAlgorithm 2 Confidence Ball Initialization: Set A0 = I and b0 = 0. for t = 0, . . .∞ do\nReceive action set Dt Construct the confidence ball Ct using At and bt Choose action and receive reward:\nFind (xt, ∗) = arg max(x,θ̃)∈Dt×Ct xTθ̃ Get reward rit from context x i t\nUpdate At+1 = At + xtxTt and bt+1 = bt + rtxt end for\nAlgorithm 3 Distributed Confidence Ball Input: Network V of agents, the function τ : t→ t− 4 log2(|V | 3 2 t).\nInitialization: For each i, set Ãi0 = Id and b̃i0 = 0, and the buffers Ai0 = ∅ and Bi0 = ∅. for t = 0, . . .∞ do\nDraw a random permutation σ of {1, . . . , |V |} for each agent i ∈ V do\nReceive action set Dit and construct the confidence ball Cit using Ãit and b̃it Choose action and receive reward:\nFind (xit+1, ∗) = arg max(x,θ̃)∈Dit×Cit x Tθ̃ Get reward rit+1 from context x i t+1.\nShare and update information buffers: Set Ait+1 = ( 1 2 (Ait +A σ(i) t ) ) ◦ (xit+1 ( xit+1 )T ) and Bit+1 = ( 1 2 (Bit + B σ(i) t ) ) ◦ (rit+1xit+1)\nif |Ait+1| > t− τ(t) set Ãit+1 = Ãit +Ait+1(1) and Ait+1 = Ait+1 \\ Ait+1(1). Similary for Bit+1. end for\nend for"
    }, {
      "heading" : "A.2. More on Communication Complexity",
      "text" : "First, recall that if the agents want to communicate their information to each other at each round without a central server, then every agent would need to communicate their chosen action and reward to every other agent at each round, giving a communication cost of O(d|V |2) bits per-round. Under DCB each agent requires at most O(log2(|V |t)d2|V |) bits to be communicated per round. Therefore, a significant communication cost reduction is gained when log(|V |t)d |V |. Recall also that using an epoch-based approach, as in (Szörényi et al., 2013), we reduce the per-round communication cost of the gossip-based approach to O(d2|V |). This makes the algorithm more efficient over any time horizon, requiring only that d |V |, and the proofs of the regret performance are simple modifications of the proofs for DCB. In comparison with growing buffers this is only an issue after O(exp(|V |)) number of rounds, and typically |V | is large. This is why we choose to exhibit the growing-buffer approach in this current work.\nInstead of relying on the combination of the diffusion and a delay to handle the potential doubling of data points under the randomised gossip protocol, we could attempt to keep track which observations have been shared with which agents, and thus simply stop the doubling from occurring. However, the per-round communication complexity of this is at least quadratic in |V |, whereas our approach is linear. The reason for the former is that in order to be efficient, any agent j, when sending information to an agent i, needs to know for each k which are the latest observations gathered by agent k that agent i already knows about. The communication cost of this is of order |V |. Since every agent shares information with somebody in each round, this gives per round communication complexity of order |V |2 in the network. A simple, alternative approach to the gossip protocol is a Round-Robin (RR) protocol, in which each agent passes the information it has gathered in previous rounds to the next agent in a pre-defined permutation. Implementing a RR protocol\nleads to the agents performing a distributed version of the CB-InstSharing algorithm, but with a delay that is of size at least linear in |V |, rather than the logarithmic dependence on this quantity that a gossip protocol achieves. Indeed, at any time, each agent will be lacking |V |(|V |−1)/2 observations. Using this observation, a cumulative regret bound can be achieved using Proposition 2 which arrives at the same asymptotic dependence on |V | as our gossip protocol, but with an additive constant that is worse by a multiplicative factor of |V |. This makes a difference to the performance of the network when |V | is very large. Moreover, RR protocols do not offer the simple generalisability and robustness that gossip protocols offer.\nNote that the pruning protocol for DCCB only requires sharing the estimated θ-vectors between agents, and adds at most O(d|V |) to the communication cost of the algorithm. Hence the per-round communication cost of DCCB remains O(log2(|V |t)d2|V |)."
    }, {
      "heading" : "A.3. Proofs of Intermediary Results for DCB",
      "text" : "Proof of Proposition 1. This follows the proof of Theorem 2 in (Abbasi-Yadkori et al., 2011), substituting appropriately weighted quantities.\nFor ease of presentation, we define the shorthand\nX̃ := ( √ w1y1, . . . , √ wnyn) and η̃ = ( √ w1η1, . . . , √ wnηn) T,\nwhere the yi are vectors with norm less than 1, the ηi are R-subgaussian, zero mean, random variables, and the wi are positive real numbers. Then, given samples ( √ w1y1, √ w1(θy1 + η1)), . . . , ( √ wnyn, √ wn(θyn + ηn)), the maximum likelihood estimate of θ is\nθ̃ : = (X̃X̃T + I)−1X̃(X̃Tθ + η̃)\n= (X̃X̃T + I)−1X̃η̃ + (X̃X̃T + I)−1(X̃X̃T + I)θ − (X̃X̃T + I)−1θ = (X̃X̃T + I)−1X̃η̃ + θ − (X̃X̃T + I)−1θ\nSo by Cauchy-Schwarz, we have, for any vector x,\nxT(θ̃ − θ) = 〈x, X̃η̃〉(X̃X̃T+I)−1 − 〈x, θ〉(X̃X̃T+I)−1 (14)\n≤ ‖x‖(X̃X̃T+I)−1 ( ‖X̃η̃‖(X̃X̃T+I)−1 + ‖θ‖(X̃X̃T+I)−1 ) (15)\nNow from Theorem 1 of (Abbasi-Yadkori et al., 2011), we know that with probability 1− δ\n‖X̃η̃‖2 (X̃X̃T+I)−1 ≤W 2R22 log\n√ det(X̃X̃T + I)\nδ2 .\nwhere W = maxi=1,...,n wi. So, setting x = (X̃X̃T + I)−1(θ̃ − θ), we obtain that with probability 1− δ\n‖θ̃ − θ‖(X̃X̃T+I)−1 ≤WR\n 2 log √ det(X̃X̃T + I)\nδ2\n  1 2\n+ ‖θ‖2\nsince 3\n‖x‖(X̃X̃T+I)−1‖θ‖(X̃X̃T+I)−1 ≤ ‖x‖2λ−1min(X̃X̃T + I)‖θ‖2λ−1min(X̃X̃T + I) ≤ ‖x‖2‖θ‖2.\nConditioned on the values of the weights, the statement of Proposition 1 now follows by substituting appropriate quantities above, and taking the probability over the distribution of the subGaussian random rewards. However, since this statement holds uniformly for any values of the weights, it holds also when the probability is taken over the distribution of the weights.\nProof of Lemma 3. Recall that Ãit is constructed from the contexts chosen from the first τ(t) rounds, across all the agents. Let i′ and t′ be arbitrary indices in V and {1, . . . , τ(t)}, respectively.\n(i) We have\ndet ( Ãit ) = det ( Ãit − ( wi ′,t′ i,t − 1 ) xi ′ t′ ( xi ′ t′ )T + ( wi ′,t′ i,t − 1 ) xi ′ t′ ( xi ′ t′ )T)\n= det ( Ãit − ( wi ′,t′ i,t − 1 ) xi ′ t′ ( xi ′ t′ )T)\n. ( 1 + ( wi ′,t′ i,t − 1 ) ‖xi′t′‖(Ãit−(wi′,t′i,t −1)xi′t′(xi′t′)T)−1 )\nThe second equality follows using the identity det(I + cB1/2xxTB1/2) = (1 + c‖x‖B), for any matrix B, vector x, and scalar c. Now, we repeat this process for all i′ ∈ V and t′ ∈ {1, . . . , τ(t)} as follows. Let (t1, i1), . . . , (t|V |τ(t), i|V |τ(t)) be an arbitrary enumeration of V × {1, . . . , τ(t)}, let B0 = Ãit, and Bs = Bs−1 − (wis,tsi,t − 1)xists ( xists )T for s = 1, . . . , |V |τ(t). Then B|V |τ(t) = Aτ(t), and by the calculation above we have\ndet ( Ãit ) = det ( Aτ(t) ) |V |τ(t)∏\ns=1\n( 1 + ( wis,tsi,t − 1 ) ‖xists‖(Bs)−1 )\n≤det ( Aτ(t) ) exp\n  |V |τ(t)∑\ns=1\n( wis,tsi,t − 1 ) ‖xists‖(Bs)−1\n \n≤ exp\n  τ(t)∑\nt′=1\n|V |∑\ni′=1\n∣∣∣wi ′,t′ i,t − 1 ∣∣∣   det ( Aτ(t) )\n(ii) Note that for vectors x, y and a matrix B, by the Sherman-Morrison Lemma, and Cauchy-Schwarz inequality we have that:\nxT(B + yyT)−1x = xTB−1x− x TB−1yyTB−1x 1 + yTB−1y ≥ xTB−1x− x TB−1xyTB−1y 1 + yTB−1y\n= xTB−1x(1 + yTB−1y)−1 (16)\nTaking\nB = ( Ãit − ( wi ′,t′ i,t − 1 ) xi ′ t′ ( xi ′ t′ )T) and y = √ wi ′,t′ i,t − 1xi ′ t′ ,\nand using that yTB−1y ≤ λmin(B)−1yTy, by construction, we have that, for any t′ ∈ {1, . . . , τ(t)} and i′ ∈ V ,\nxT ( Ãit )−1 x ≥ xT ( Ãit − ( wi ′,t′ i,t − 1 ) xi ′ t′ ( xi ′ t′ )T)−1 x(1 + |wi ′,t′ i,t − 1|)−1.\nPerforming this for each i′ ∈ V and t′ ∈ {1, . . . , τ(t)}, taking the exponential of the logarithm and using that log(1 + a) ≤ a like in the first part finishes the proof.\n3λmin( · ) denotes the smallest eigenvalue of its argument."
    }, {
      "heading" : "A.4. Proof of Theorem 6",
      "text" : "Throughout the proof let i denote the index of some arbitrary but fixed agent, and k the index of its cluster.\nStep 1: Show the true clustering is obtained in finite time. First we prove that with probability 1− δ, the number of times agents in different clusters share information is bounded. Consider the statements\n∀i, i′ ∈ V, ∀t, ( ‖θ̂ilocal,t − θ̂i ′ local,t‖ > cthreshλ (t) ) =⇒ i′ /∈ Uk (17)\nand,\n∀t ≥ C(γ, λ, δ) = cthreshλ −1 (γ\n2\n) , i′ /∈ Uk, ‖θ̂ilocal,t − θ̂i ′ local,t‖ > cthreshλ (t). (18)\nwhere cthreshλ andAλ are as defined in the main paper. Lemma 4 from (Gentile et al., 2014) proves that these two statements hold under the assumptions of the theorem with probability 1− δ/2. Let i be an agent in cluster Uk. Suppose that (17) and (18) hold. Then we know that at time t = dC(γ, λ, δ)e, Uk ⊂ V it . Moreover, since the sharing protocol chooses an agent uniformly at random from V it independently from the history before time t, it follows that the time until V it = U\nk can be upper bounded by a constant C = C(|V |, δ) with probability 1− δ/2. So it follows that there exists a constant C = C(|V |, γ, λ, δ) such that the event\nE := {(17) and (18) hold, and (t ≥ C(|V |, γ, λ, δ) =⇒ V it = Uk)}\nholds with probability 1− δ. Step 2: Consider the properties of the weights after clustering. On the event E, we know that each cluster will be performing the algorithm DCB within its own cluster for all t > C(γ, |V |). Therefore, we would like to directly apply the analysis from the proof of Theorem 1 from this point. In order to do this we need to show that the weights, wi ′,t′\ni,t , have the same properties after time C = C(γ, |V |, λ, δ) that are required for the proof of Theorem 1. Lemma 7. Suppose that agent i is in cluster Uk. Then, on the event E,\n(i) for all t > C(|V |, γ, λ, δ) and i′ ∈ V \\ Uk, wi ′,t′\ni,t = 0;\n(ii) for all t′ ≥ C(|V |, γ, λ, δ) and i′ ∈ Uk,∑i∈Uk w i′,t′\ni,C(|V |,γ) = |Uk|; (iii) for all t ≥ t′ ≥ C(|V |, γ, λ, δ) and i′ ∈ Uk, the weights wi ′,t′\ni,t , i ∈ Uk, are i.d..\nProof. See Appendix A.5.\nWe must deal also with what happens to the information gathered before the cluster has completely discovered itself. To this end, note that we can write, supposing that τ(t) ≥ C(|V |, γ, λ, δ),\nÃit := ∑\ni′∈Uk\nwi ′,C i,t\n|Uk| Ã i′ C +\nτ(t)∑\nt′=C+1\n∑\ni′∈Uk wi ′,t′ i,t x i′ t′\n( xi ′\nt′\n)T . (19)\nArmed with this observation we show that the fact that sharing within the appropriate cluster only begins properly after time C = C(|V |, γ, λ, δ) the influence of the bias is unchanged: Lemma 8 (Bound on the influence of general weights). On the event E, for all i ∈ V and t such that T (t) ≥ C(|V |, γ, λ, δ),\n(i) det ( Ãit ) ≤ exp ( τ(t)∑ t′=C ∑ i′∈Uk ∣∣∣wi ′,t′ i,t − 1 ∣∣∣ ) det ( Akτ(t) ) ,\n(ii) and ‖xit‖2(Ãit)−1 ≤ exp ( τ(t)∑ t′=C ∑ i′∈Uk ∣∣∣wi ′,t′ i,t − 1 ∣∣∣ ) ‖xit‖2( Ak τ(t) )−1 .\nProof. See Appendix A.5.\nThe final property of the weights required to prove Theorem 1 is that their variance is diminishing geometrically with each iteration. For the analysis of DCB this is provided by Lemma 4 of (Szörényi et al., 2013), and, using Lemma 7, we can prove the same result for the weights after time C = C(|V |, γ, λ, δ): Lemma 9. Suppose that agent i is in cluster Uk. Then, on the event E, for all t ≥ C = C(|V |, γ, λ, δ) and t′ < t, we have\nE ( (wj,t ′ i,t − 1)2 ) ≤ |U k| 2t−max{t′,C} .\nProof. Given the properties proved in Lemma 7, the proof is identical to the proof of Lemma 4 of (Szörényi et al., 2013).\nStep 3: Apply the results from the analysis of DCB. We can now apply the same argument as in Theorem 1 to bound the regret after time C = C(γ, |V |, λ, δ). The regret before this time we simply upper bound by |Uk|C(|V |, γ, λ, δ)‖θ‖. We include the modified sections bellow as needed.\nUsing Lemma 9, we can control the random exponential constant in Lemma 8, and the upper bound W (T ): Lemma 10 (Bound in the influence of weights under our sharing protocol). Assume that t ≥ C(γ, |V |, λδ). Then on the event E, for some constants 0 < δt′ < 1, with probability 1− ∑τ(t) t′=1 δt′\nτ(t)∑\nt′=C\n∑\ni′∈Uk\n∣∣∣wi ′,t′ i,t − 1 ∣∣∣ ≤ |Uk| 32 τ(t)∑\nt′=C\n√ 2−(t−max{t′,C})\nδt′ ,\nand W (τ(t)) ≤ 1 + max C≤t′≤τ(t)   |U k| 32 √ 2−(t−max{t′,C})\nδt′\n   .\nIn particular, for any 1 > δ > 0, choosing δt′ = δ2−(t−max{t ′,C})/2, and τ(t) = t − c1 log2 c2t we conclude that with probability 1− (c2t)−c1/2δ/(1− 2−1/2), for any t > C + c1 log2(c2C),\n∑\ni′∈Uk\nτ(t)∑\nt′=C\n∣∣∣wi ′,t′ i,t − 1 ∣∣∣ ≤ |U k| 32 (c2t)− c1 4\n(1− 2− 14 ) √ δ , and W (τ(t)) ≤ 1 + |U k| 32 (c2t)− c1 4√ δ . (20)\nThus lemmas 8 and 10 give us control over the bias introduced by the imperfect information sharing. Applying lemmas 8 and 10, we find that with probability 1− (c2t)−c1/2δ/(1− 2−1/2):\nρit ≤ 2 exp (\n|Uk| 32 (1− 2− 14 )c c1 4\n2 t c1 4\n√ δ\n) ‖xit‖(Ai\nτ(t)\n)−1 (21)\n.   ( 1 + |Uk| 32\n(1− 2− 14 )c c1 4 2 t c1 4 √ δ\n) R √√√√√2 log  exp ( |Uk| 32\n(1− 2− 14 )c c1 4 2 t c1 4 √ δ\n) det ( Aτ(t) ) 1 2\nδ\n + ‖θ‖     .\nStep 4: Choose constants and sum the simple regret. Choosing again c1 = 4, c2 = |V | 3 2 , and setting Nδ = 1\n(1−2− 14 ) √ δ ,\nwe have on the event E, for all t ≥ max{Nδ, C + 4 log2(|V | 3 2C)}, with probability 1− (|V |t)−2δ/(1− 2−1/2)\nρit ≤ 4e‖xit‖(Akt−1+∑i−1i′=1 xi′t (xi′t )T)−1 ( β(t) +R √ 2 ) ,\nwhere β(·) is as defined in the theorem statement. Now applying Cauchy-Schwarz, and Lemma 11 from (Abbasi-Yadkori et al., 2011) yields that on the event E, with probability 1− ( 1 + ∑∞ t=1(|V |t)−2/(1− 2−1/2) ) δ ≥ 1− 3δ,\nRt ≤ ( max{Nδ, C + 4 log2(|V | 3 2C)}+ 2 (4|V |d log (|V |t))3 ) ‖θ‖2\n+ 4e ( β(t) +R √ 2 )√ |Uk|t ( 2 log ( det ( Akt ))) .\nReplacing δ with δ/6, and combining this result with Step 1 finishes the proof."
    }, {
      "heading" : "A.5. Proofs of Intermediary Results for DCCB",
      "text" : "Proof of Lemma 7. Recall that whenever the pruning procedure cuts an edge, both agents reset their buffers to their local information, scaled by the size of their current neighbour sets. (It does not make a difference practically whether or not they scale their buffers, as this effect is washed out in the computation of the confidence bounds and the local estimates. However, it is convenient to assume that they do so for the analysis.) Furthermore, according to the pruning procedure, no agent will share information with another agent that does not have the same local neighbour set.\nOn the event E, there is a time for each agent, i, before time C = C(γ, |V |, λδ) when the agent resets its information to their local information, and their local neighbour set becomes their local cluster, i.e. V it = U\nk. After this time, this agent will only share information with other agents that have also set their local neighbour set to their local cluster. This proves the statement of part (i).\nFurthermore, since on eventE, after agent i has identified its local neighbour set, i.e. when V it = U k, the agent only shares with members of Uk, the statements of parts (ii) and (iii) hold by construction of the sharing protocol.\nProof of Lemma 8. The result follows the proof of Lemma 3. For the the iterations until timeC = C(γ, |V |, λδ) is reached, we apply the argument there. For the final step we require two further inequalities.\nFirst, to finish the proof of part (i) we note that,\ndet  (AkT −AkC) + ∑\ni′∈Uk\nw i′,C(γ,|V |) i,t\n|Uk| Ã i′ C\n  = det  AkT + ∑\ni′∈Uk\nwi ′,C i,t − 1 |Uk| Ã i′ C\n \n= det ( AkT ) det  I + ∑\ni′∈Uk\nwi ′,C i,t − 1 |Uk| A k T − 12 Ãi ′ CA k T − 12\n \n≤ det ( AkT ) det  I +   ∑\ni′∈Uk\n∣∣∣wi ′,C i,t − 1 ∣∣∣  AkT − 12 ∑\ni′∈Uk\nÃi ′\nC |Uk|A k T\n− 12   ≤ det ( AkT )  1 + ∑\ni′∈Uk\n∣∣∣wi ′,C i,t − 1 ∣∣∣   .\nFor the first equality we have used that |Uk|AkC = ∑ i′∈Uk Ã i′ C ; for the first inequality we have used a property of positive definite matrices; for the second inequality we have used that 1 upper bounds the eigenvalues of AkT −1/2 AkCA k T −1/2.\nSecond, to finish the proof of part (ii), we note that, for any vector x,\nxT  Akτ(t) + ∑\ni′∈Uk\nwi ′,C i,t − 1 |Uk| Ã i′ C\n  −1\nx\n= ( Akτ(t) − 12x )T  I + ∑\ni′∈Uk\nwi ′,C i,t − 1 |Uk| A k τ(t) − 12 Ãi ′ CA k τ(t) − 12\n  −1 (\nAkτ(t) − 12x\n)\n≥ ( Akτ(t) − 12x )T  I + ∑\ni′∈Uk\n∣∣∣wi ′,C i,t − 1 ∣∣∣ |Uk| A k τ(t) − 12 Ãi ′ CA k τ(t) − 12   −1 ( Akτ(t) − 12x )\n≥  1 + ∑\ni′∈Uk\n∣∣∣wi ′,C i,t − 1 ∣∣∣\n  −1\nxTAkτ(t) −1 x.\nThe first inequality here follows from a property of positive definite matrices, and the other steps follow similarly to those in the inequality that finished part (i) of the proof."
    } ],
    "references" : [ {
      "title" : "Improved algorithms for linear stochastic bandits",
      "author" : [ "Abbasi-Yadkori", "Yasin", "Pál", "Dávid", "Szepesvári", "Csaba" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Abbasi.Yadkori et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Abbasi.Yadkori et al\\.",
      "year" : 2011
    }, {
      "title" : "Thompson sampling for contextual bandits with linear payoffs",
      "author" : [ "Agrawal", "Shipra", "Goyal", "Navin" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Agrawal et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Agrawal et al\\.",
      "year" : 2013
    }, {
      "title" : "Randomized gossip algorithms",
      "author" : [ "Boyd", "Stephen", "Ghosh", "Arpita", "Prabhakar", "Balaji", "Shah", "Devavrat" ],
      "venue" : "IEEE/ACM Transactions on Networking (TON),",
      "citeRegEx" : "Boyd et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Boyd et al\\.",
      "year" : 2006
    }, {
      "title" : "Stochastic linear optimization under bandit feedback",
      "author" : [ "Dani", "Varsha", "Hayes", "Thomas P", "Kakade", "Sham M" ],
      "venue" : "In COLT, pp",
      "citeRegEx" : "Dani et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Dani et al\\.",
      "year" : 2008
    }, {
      "title" : "Online clustering of bandits",
      "author" : [ "Gentile", "Claudio", "Li", "Shuai", "Zappella", "Giovanni" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Gentile et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Gentile et al\\.",
      "year" : 2014
    }, {
      "title" : "An efficient approach to generating location-sensitive recommendations in adhoc social network environments",
      "author" : [ "Hao", "Fei", "Li", "Shuai", "Min", "Geyong", "Kim", "Hee-Cheol", "Yau", "Stephen S", "Yang", "Laurence T" ],
      "venue" : "IEEE Transactions on Services Computing,",
      "citeRegEx" : "Hao et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Hao et al\\.",
      "year" : 2015
    }, {
      "title" : "Gossipbased aggregation in large dynamic networks",
      "author" : [ "M. Jelasity", "A. Montresor", "O. Babaoglu" ],
      "venue" : "ACM Trans. on Computer Systems,",
      "citeRegEx" : "Jelasity et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Jelasity et al\\.",
      "year" : 2005
    }, {
      "title" : "Gossip-based peer sampling",
      "author" : [ "M. Jelasity", "S. Voulgaris", "R. Guerraoui", "A.M. Kermarrec", "M. van Steen" ],
      "venue" : "ACM Transactions on Computer Systems,",
      "citeRegEx" : "Jelasity et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Jelasity et al\\.",
      "year" : 2007
    }, {
      "title" : "Decentralized learning for multiplayer multiarmed bandits",
      "author" : [ "Kalathil", "Dileep", "Nayyar", "Naumaan", "Jain", "Rahul" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "Kalathil et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kalathil et al\\.",
      "year" : 2014
    }, {
      "title" : "Thompson sampling: An asymptotically optimal finitetime analysis",
      "author" : [ "Kaufmann", "Emilie", "Korda", "Nathaniel", "Munos", "Rémi" ],
      "venue" : "In Algorithmic Learning Theory,",
      "citeRegEx" : "Kaufmann et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kaufmann et al\\.",
      "year" : 2012
    }, {
      "title" : "Gossip-based computation of aggregate information",
      "author" : [ "D. Kempe", "A. Dobra", "J. Gehrke" ],
      "venue" : "In Proc. 44th Annual IEEE Symposium on Foundations of Computer Science",
      "citeRegEx" : "Kempe et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Kempe et al\\.",
      "year" : 2003
    }, {
      "title" : "A contextual-bandit approach to personalized news article recommendation",
      "author" : [ "Li", "Lihong", "Chu", "Wei", "Langford", "John", "Schapire", "Robert E" ],
      "venue" : "In Proceedings of the 19th international conference on World wide web,",
      "citeRegEx" : "Li et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2010
    }, {
      "title" : "Medicine rating prediction and recommendation in mobile social networks",
      "author" : [ "Li", "Shuai", "Hao", "Fei", "Mei", "Kim", "Hee-Cheol" ],
      "venue" : "In Proceedings of the International Conference on Grid and Pervasive Computing,",
      "citeRegEx" : "Li et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2013
    }, {
      "title" : "Graph clustering bandits for recommendation",
      "author" : [ "Li", "Shuai", "Gentile", "Claudio", "Karatzoglou", "Alexandros" ],
      "venue" : null,
      "citeRegEx" : "Li et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Collaborative filtering bandits",
      "author" : [ "Li", "Shuai", "Karatzoglou", "Alexandros", "Gentile", "Claudio" ],
      "venue" : "In The 39th SIGIR,",
      "citeRegEx" : "Li et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "On regret-optimal learning in decentralized multi-player multi-armed bandits",
      "author" : [ "Nayyar", "Naumaan", "Kalathil", "Dileep", "Jain", "Rahul" ],
      "venue" : null,
      "citeRegEx" : "Nayyar et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Nayyar et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning to optimize via posterior sampling",
      "author" : [ "Russo", "Daniel", "Van Roy", "Benjamin" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "Russo et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Russo et al\\.",
      "year" : 2014
    }, {
      "title" : "Contextual bandits with similarity information",
      "author" : [ "Slivkins", "Aleksandrs" ],
      "venue" : "JMLR,",
      "citeRegEx" : "Slivkins and Aleksandrs.,? \\Q2014\\E",
      "shortCiteRegEx" : "Slivkins and Aleksandrs.",
      "year" : 2014
    }, {
      "title" : "Gossip-based distributed stochastic bandit algorithms",
      "author" : [ "Szörényi", "Balázs", "Busa-Fekete", "Róbert", "Hegedűs", "István", "Ormándi", "Jelasity", "Márk", "Kégl" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Szörényi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Szörényi et al\\.",
      "year" : 2013
    }, {
      "title" : "Distributed online learning via cooperative contextual bandits",
      "author" : [ "Tekin", "Cem", "van der Schaar", "Mihaela" ],
      "venue" : "IEEE Trans. Signal Processing,",
      "citeRegEx" : "Tekin et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Tekin et al\\.",
      "year" : 2013
    }, {
      "title" : "Distributed average consensus with least-mean-square deviation",
      "author" : [ "L. Xiao", "S. Boyd", "Kim", "S.-J" ],
      "venue" : "Journal of Parallel and Distributed Computing,",
      "citeRegEx" : "Xiao et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Xiao et al\\.",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : ", (Li et al., 2013; Hao et al., 2015)).",
      "startOffset" : 2,
      "endOffset" : 37
    }, {
      "referenceID" : 5,
      "context" : ", (Li et al., 2013; Hao et al., 2015)).",
      "startOffset" : 2,
      "endOffset" : 37
    }, {
      "referenceID" : 10,
      "context" : ", (Kempe et al., 2003; Xiao et al., 2007; Jelasity et al., 2005; 2007)), in each round, an overlay protocol assigns to every agent another agent, with which it can share information.",
      "startOffset" : 2,
      "endOffset" : 70
    }, {
      "referenceID" : 20,
      "context" : ", (Kempe et al., 2003; Xiao et al., 2007; Jelasity et al., 2005; 2007)), in each round, an overlay protocol assigns to every agent another agent, with which it can share information.",
      "startOffset" : 2,
      "endOffset" : 70
    }, {
      "referenceID" : 6,
      "context" : ", (Kempe et al., 2003; Xiao et al., 2007; Jelasity et al., 2005; 2007)), in each round, an overlay protocol assigns to every agent another agent, with which it can share information.",
      "startOffset" : 2,
      "endOffset" : 70
    }, {
      "referenceID" : 18,
      "context" : "In (Szörényi et al., 2013) this was achieved by introducing an epoch structure into their algorithm, and emptying the buffers at the end of each epoch.",
      "startOffset" : 3,
      "endOffset" : 26
    }, {
      "referenceID" : 0,
      "context" : "The Distributed Confidence Ball Algorithm (DCB) We use a gossip-based information sharing protocol to produce a distributed variant of the generic Confidence Ball (CB) algorithm, (Abbasi-Yadkori et al., 2011; Dani et al., 2008; Li et al., 2010).",
      "startOffset" : 179,
      "endOffset" : 244
    }, {
      "referenceID" : 3,
      "context" : "The Distributed Confidence Ball Algorithm (DCB) We use a gossip-based information sharing protocol to produce a distributed variant of the generic Confidence Ball (CB) algorithm, (Abbasi-Yadkori et al., 2011; Dani et al., 2008; Li et al., 2010).",
      "startOffset" : 179,
      "endOffset" : 244
    }, {
      "referenceID" : 11,
      "context" : "The Distributed Confidence Ball Algorithm (DCB) We use a gossip-based information sharing protocol to produce a distributed variant of the generic Confidence Ball (CB) algorithm, (Abbasi-Yadkori et al., 2011; Dani et al., 2008; Li et al., 2010).",
      "startOffset" : 179,
      "endOffset" : 244
    }, {
      "referenceID" : 18,
      "context" : "Our approach is similar to (Szörényi et al., 2013) where the authors produced a distributed -greedy algorithm for the simpler multi-armed bandit problem.",
      "startOffset" : 27,
      "endOffset" : 50
    }, {
      "referenceID" : 4,
      "context" : "The Distributed Clustering Confidence Ball Algorithm (DCCB) The paper (Gentile et al., 2014) proposes the initial centralised approach to the problem of clustering linear bandits.",
      "startOffset" : 70,
      "endOffset" : 92
    }, {
      "referenceID" : 0,
      "context" : "DCB algorithm The OFUL algorithm (Abbasi-Yadkori et al., 2011) is an improvement of the confidence ball algorithm from (Dani et al.",
      "startOffset" : 33,
      "endOffset" : 62
    }, {
      "referenceID" : 3,
      "context" : ", 2011) is an improvement of the confidence ball algorithm from (Dani et al., 2008), which assumes that the confidence balls Ct can be characterised by At and bt.",
      "startOffset" : 64,
      "endOffset" : 83
    }, {
      "referenceID" : 0,
      "context" : "If the agents implement CB independently and do not share any information, which we call CB-NoSharing, then it follows from the results in (Abbasi-Yadkori et al., 2011), the equivalent regret bound would be",
      "startOffset" : 139,
      "endOffset" : 168
    }, {
      "referenceID" : 18,
      "context" : "Using an epoch-based approach, as in (Szörényi et al., 2013), the per-round communication cost of the gossip protocol becomes O(d2|V |).",
      "startOffset" : 37,
      "endOffset" : 60
    }, {
      "referenceID" : 0,
      "context" : "The proof builds on the analysis in (Abbasi-Yadkori et al., 2011).",
      "startOffset" : 36,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "First we need a version of the confidence ellipsoid theorem given in (Abbasi-Yadkori et al., 2011) that incorporates the bias introduced by the random weights: Proposition 1.",
      "startOffset" : 69,
      "endOffset" : 98
    }, {
      "referenceID" : 0,
      "context" : "Then we can decompose the instantaneous regret, following a classic argument (see the proof of Theorem 3 in (Abbasi-Yadkori et al., 2011)):",
      "startOffset" : 108,
      "endOffset" : 137
    }, {
      "referenceID" : 18,
      "context" : "Using Lemma 4 in (Szörényi et al., 2013), by exploiting the random weights are identically distributed (i.",
      "startOffset" : 17,
      "endOffset" : 40
    }, {
      "referenceID" : 0,
      "context" : "Now, first applying Cauchy-Schwarz, then step 3b from above together with (9), and finally Lemma 11 from (Abbasi-Yadkori et al., 2011) yields that, with probability 1− ( 1 + ∑∞ t=1(|V |t)−2/(1− 2−1/2) ) δ ≥ 1− 3δ,",
      "startOffset" : 105,
      "endOffset" : 134
    }, {
      "referenceID" : 4,
      "context" : "Here λ is a parameter of an extra assumption that is needed, as in (Gentile et al., 2014), about the process generating the context sets Di t:",
      "startOffset" : 67,
      "endOffset" : 89
    }, {
      "referenceID" : 4,
      "context" : "We define c λ (t), as in (Gentile et al., 2014), by",
      "startOffset" : 25,
      "endOffset" : 47
    }, {
      "referenceID" : 4,
      "context" : "Here is a parameter of an extra assumption that is needed, as in (Gentile et al., 2014), about the process generating the context sets Di t:",
      "startOffset" : 65,
      "endOffset" : 87
    }, {
      "referenceID" : 4,
      "context" : "We define c (t), as in (Gentile et al., 2014), by",
      "startOffset" : 23,
      "endOffset" : 45
    }, {
      "referenceID" : 4,
      "context" : "We adapt results from (Gentile et al., 2014) to show how long it will be before the true clusters are identified, in high probability.",
      "startOffset" : 22,
      "endOffset" : 44
    }, {
      "referenceID" : 18,
      "context" : "There is already work on distributed approaches to multi-agent, multi-armed bandits, not least (Szörényi et al., 2013) which examines -greedy strategies over a peer to peer network, and provided an initial inspiration for this current work.",
      "startOffset" : 95,
      "endOffset" : 118
    }, {
      "referenceID" : 8,
      "context" : "The paper (Kalathil et al., 2014) examines the extreme case when there is no communication channel across which the agents can communicate, and all communication must be performed through observation of action choices alone.",
      "startOffset" : 10,
      "endOffset" : 33
    }, {
      "referenceID" : 15,
      "context" : "Another approach to the multi-armed bandit case, (Nayyar et al., 2015), directly incorporates the communication cost into the regret.",
      "startOffset" : 49,
      "endOffset" : 70
    }, {
      "referenceID" : 4,
      "context" : ", 2016a) is a faster variant of (Gentile et al., 2014) which adopt the strategy of boosted training stage.",
      "startOffset" : 32,
      "endOffset" : 54
    }, {
      "referenceID" : 0,
      "context" : "Discussion Our analysis is tailored to adapt proofs from (Abbasi-Yadkori et al., 2011) about generic confidence ball algorithms to a distributed setting.",
      "startOffset" : 57,
      "endOffset" : 86
    }, {
      "referenceID" : 9,
      "context" : ", the Thompson sampling algorithms, (Agrawal & Goyal, 2013; Kaufmann et al., 2012; Russo & Van Roy, 2014).",
      "startOffset" : 36,
      "endOffset" : 105
    }, {
      "referenceID" : 2,
      "context" : "The work on distributed computation through gossip algorithms in (Boyd et al., 2006) could alleviate this issue.",
      "startOffset" : 65,
      "endOffset" : 84
    }, {
      "referenceID" : 18,
      "context" : "The current pruning algorithm for DCCB guarantees that techniques from (Szörényi et al., 2013) can be applied to our algorithms.",
      "startOffset" : 71,
      "endOffset" : 94
    }, {
      "referenceID" : 2,
      "context" : "However the results in (Boyd et al., 2006) are more powerful, and could be used even when the agents only identify a sub-network of the true clustering.",
      "startOffset" : 23,
      "endOffset" : 42
    } ],
    "year" : 2016,
    "abstractText" : "We provide two distributed confidence ball algorithms for solving linear bandit problems in peer to peer networks with limited communication capabilities. For the first, we assume that all the peers are solving the same linear bandit problem, and prove that our algorithm achieves the optimal asymptotic regret rate of any centralised algorithm that can instantly communicate information between the peers. For the second, we assume that there are clusters of peers solving the same bandit problem within each cluster, and we prove that our algorithm discovers these clusters, while achieving the optimal asymptotic regret rate within each one. Through experiments on several real-world datasets, we demonstrate the performance of proposed algorithms compared to the state-of-the-art.",
    "creator" : "LaTeX with hyperref package"
  }
}