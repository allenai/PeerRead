{
  "name" : "1602.01323.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "BICLUSTERING READINGS AND MANUSCRIPTS VIA NON-NEGATIVE MATRIX FACTORIZATION, WITH APPLICATION TO THE TEXT OF JUDE",
    "authors" : [ "JOEY MCCOLLUM", "STEPHEN BROWN" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Genealogical analysis has had a prominent role in New Testament (NT) textcritical theory even before it was popularized in the work of Westcott and Hort [1]. Indeed, one of the steps in their approach, that of classifying manuscripts (MSS) into families and texttypes based on their shared readings, goes back over a century-and-a-half earlier to the works of Mill, Bentley, and Bengel [2]. In theory, the rationale for this is that the more two MSS agree in their readings, the more likely they are to represent a close common ancestor or to have an exemplar-copy relationship themselves; the goal is that by grouping witnesses in this way, the critic can then weigh them according to how purely they represent their group or how derivative they are from common sources.\nThe theory is not without obstacles, however. Despite the emphasis they placed on the genealogical method, Westcott and Hort misused the method by overlooking the effects of contamination, or mixture of readings characteristic of different texttypes, on the genealogy they were attempting to derive [3]. It turns out that such mixture is somewhat ubiquitous. Indeed, as more MSS are discovered and studied, placing them into families and texttypes by hard assignment only blurs the lines between these groups even more.\nAn additional complication in the assignment of MSS to groups is the dual problem of assigning readings to groups. Any two witnesses will probably agree in a majority of their readings, so simply counting places of agreement is insufficient [4, 5]. In order to classify texts into well-defined, well-separated groups, we must determine which readings are the most significant for this purpose. So we must first determine the readings that the most characteristic MSS of a group share and that few or no other MSS share. But in order for us to do this, the MSS must be assigned to groups already. This leaves us with a problem of co-dependence: Characteristic MSS of a given type are determined by which characteristic readings they have,\nDate: February 1, 2016. 1991 Mathematics Subject Classification. 6U815. Key words and phrases. textual criticism, text analysis, text mining, text types, classification,\nmachine learning, nonnegative matrix factorization, NMF, New Testament, Jude. 1\nand characteristic readings of a given type are determined by which characteristic MSS attest to them.\nThese observations have spurred the increased use of approaches that exchange the assumptions of texttype theory for other assumptions. Seeing the benefits of these methods, some researchers have started to question the continued relevance of methods based on texttypes. Others have proposed to abandon the underlying theory altogether [6].\nYet the idea of texttypes has not been rejected universally. Epp, for one, has argued for its continued value [2]. More generally, the assumptions made by other methods introduce limitations of their own, some of which the theory of texttypes can overcome. It is also important to recognize that texttype-based methods and newer approaches are not mutually exclusive, but can be used in conjunction to achieve more refined results. We will elaborate on these points briefly. The main implication of our work with regard to theory, however, is that contamination and co-dependence are not truly insurmountable obstacles to texttype-based methods; as we will show, both issues can, in fact, be handled.\nIn this paper, we present non-negative matrix factorization (NMF) as a simple, unsupervised, and efficient computer-based method for isolating clusters of MSS and their most important readings simultaneously. It is a pre-genealogical method only, in the sense that it does not infer any directed relationships among readings, texts, or groups. As such, it is not intended to replace more complex genealogical methods, but to help researchers generate hypotheses that these methods can test and refine. In the first section, we review known classification methods with their advantages and disadvantages. In the second section, we show how NMF addresses the problems of contamination and co-dependence and discuss its advantages over other methods. (This section involves some mathematics, but the more technical details can be found in the references.) In the third section, we describe our application of NMF to Tommy Wasserman’s full collation of 560 MSS of the epistle of Jude [7]. In the last section, we show that the use of NMF in different settings yields results in the form of recognizable texttypes and families established in the literature."
    }, {
      "heading" : "2. State of the Art",
      "text" : "The history of textual criticism has seen the development of numerous classification methods. We will not attempt an exhaustive treatment here, but instead focus our attention on the following generalizations:\n(1) Base-text: This method, used in NT textual criticism at its earliest stages, classifies MS texts based on their deviations from a single base of readings. The base could be anything, but historically, it was the Textus Receptus (TR). Classes were formed based on their common agreements against the base text. (2) Quantitative: This method, introduced by Colwell [8], compares the text of each MS to that of every other MS. Similarity is generally measured as a simple count or proportion of readings at which two texts agree. The set of pairwise similarity measures is then used to group texts according to a variety of algorithms [9, 10]. (3) Profile: The Claremont Profile Method (CPM), developed by McReynolds and Wisse [11, 12], improves the efficiency and classification power of existing methods by taking identified groups and determining which patterns of readings provide the best “profile” for each group. These profiles can then be used to determine the most likely group of an unclassified text and the strength of a classified text’s group membership.\n(4) Factor Analysis: This method, which has been developed and put to use extensively at Andrews University [13, 14, 15], first determines the factors, or combinations of readings that are most correlated to one another among MS texts, and then groups MSS by their strongest factors. In this way, it combines the “text-side” approach of (2) with the “reading-side” approach of (3). (5) Stemmatic: Stemmatic methods aim for a more precise and structured classification of texts by examining changes in every variation unit between extant texts and nodes representing their potential ancestors. The goal is to construct an undirected stemma of maximum parsimony, or the fewest changed readings along all links of the stemma. Examples of these methods can be found in the recent work of Spencer, Wachtel, and Howe [16, 17]. (6) Coherence-based: The Coherence-Based Genealogical Method (CBGM), developed by Mink [18], improves (5) by producing directed stemmata that are robust to contamination. It starts by constructing a directed local stemma for the readings at each variation unit based on general agreement among readings’ witnesses and transcriptional probability, so that readings have prior and posterior relationships. Then, it constructs a directed local stemma for the texts at each unit based on their general agreement and their relative proportions of prior and posterior readings where they disagree. These first two steps are applied iteratively to account for the co-dependent relationship of “good” readings and “good” texts. Finally, the local stemmata of texts are merged to form a global stemma that optimizes the objective of simplicity (i.e., as few ancestors to a text as possible) under the constraint that the directed relationships of all readings are preserved. A useful introduction can be found in Wachtel’s recent feature on the method [19].\nWe will summarize each method’s advantages and disadvantages below. Method (1) is simple to understand, but it has many shortcomings. It requires the assumption of a base text, and it only defines groups in terms of their disagreements with this text, when their agreements might also be informative. Because it offers no procedure for deciding which readings are the most signficant in determining groups, it also fails to address the problem of co-dependence between readings and texts. Typically, the evaluation of which readings are important is done under human supervision and can be slow for a large number of readings. This method can account for contamination, but only after groups have been determined. A brief discussion of this method can be found in Ehrman’s essay on classification methods [5].\nMethod (2) presents easy-to-interpret results, requires no human supervision, and dispenses with the unnecessary assumption of a base text. Its major disadvantage is its computational cost: Building a table of pairwise similarity measures for n MSS requires (n2 − n)/2 comparisons, which becomes inconvenient for a large number of MSS. Because it counts readings rather than weighing them, it fails to address the problem of co-dependence. Typical clustering algorithms do not accommodate contamination.\nMethod (3) is much more efficient by design than (2), produces results that are simple to understand, and can identify and quantify contamination between groups in a MS’s text. Its greatest weakness is that it does not identify the groups to be profiled, but assumes that they are known.1 It therefore does not even attempt\n1CPM has, in fact, been criticized on the basis of its application with poorly-identified groups [20]. Because of this, it is best used in conjunction with methods like (2) or (4) [5].\nto address the problem of co-dependence. Finally, despite its efficiency, it is a supervised method, so it will not be as fast as some computer-based methods.\nMethod (4) is extremely efficient, is unsupervised, and does not require the assumption of a base text. As such, it could reasonably be said to supersede method (2) as a quantitative method. Furthermore, the way the method fits readings and texts together in factors may be considered an adequate approach to the problem of co-dependence. The drawback is that the results of factor analysis can be difficult to interpret: The method often assigns a negative coefficient for one or more groups to a text, and there is no obvious sense of what that means. The problem is that factor analysis does not provide a model that accounts for additive mixture between groups. Naturally, this becomes an obstacle to identifying contamination. For these reasons, factor analysis is often refined using method (3) [13, p. 37].\nMethod (5) is unsupervised, and it makes no assumptions about a base text. Furthermore, unlike methods (1)–(4), it avoids controversy over the use of texttypes by focusing instead on transmissional details at the level of individual texts and readings. The price of this level of detail, of course, is complexity in implementation: The construction of an optimal stemma is a computationally expensive task, so one must sacrifice accuracy to complete it in an acceptable amount of time. The other major disadvantage is that simple stemmata cannot account for contamination. In addition, simple stemmatic approaches make no statements about “good” texts or readings until one has to orient the stemma.\nMethod (6) accounts for the problems of contamination and co-dependence between texts and readings without requiring any assumptions about underlying texttypes. In other areas, however, it is lacking. First, it is a supervised method. Second, between the initialization of a pairwise MS coherence table and the supervised construction of local stemmata, the method is very time-consuming. Third, and perhaps most importantly, it requires the assumption of a working initial text, which for all practical purposes is tantamount to the base-text assumption of method (1). This assumption severely limits the scope of what can be achieved: CBGM can help refine existing hypotheses, but it cannot compare significantly different hypotheses. CBGM has risen to prominence relatively recently, having only been applied on a large scale to the catholic epistles and Acts. During that time, it has seen discussion as well as criticism.2\nAs we will show, NMF combines many of best qualities of methods (1)–(6). It does not rely on a base text. It is unsupervised and extremely fast, even with data as large as Wasserman’s Jude collation. It performs biclustering on MSS and readings at the same time, so it does not need a profile method to be applied on top of it. Most importantly, NMF finds an equilibrium in the co-dependent relationship of “good” witnesses and “good” readings, and it does so in a way that is robust to contamination between groups. As NMF models mixture additively, its results are easy to interpret. See Table 1 for a comparison of methods (1)–(6) and NMF.\nOf course, NMF relies on the assumptions of texttype theory, so it is subject to the criticisms of that theory. Even so, while a comprehensive discussion of texttype theory and its relevance is beyond the scope of this paper, it should be noted that the results of NMF can still be used to benefit other methods in the pre-processing stage. CBGM and other stemmatic methods, for instance, are often applied only to a sample of all available MSS and readings for the sake of time and computational resources; NMF can provide a smart selection of significant MSS and readings in this situation.\n2For more information, see Houghton’s survey [21] , Wasserman’s overview [22], and TC ’s featured articles on CBGM at rosetta.reltech.org/TC/v20/index.html."
    }, {
      "heading" : "3. Theoretical Basis",
      "text" : "NMF was popularized by Daniel D. Lee and H. Sebastian Seung in their 1999 paper [23]. Since then, it has found use in a wide array of fields (see [24] for a detailed survey). With regard to fields most relevant to textual criticism, it has found use in text mining for the purposes of document clustering and topic modeling [25] and in computational biology for the purposes of classifying gene expressions in DNA microarrays [26] and more recently for determining biological admixture, or ancestry, coefficients [27]. The following treatment of the mathematical basis of NMF is primarily a summary, but the interested reader is encouraged to refer to [28] for details.\nSuppose that we have a collation consisting of m readings (with readings in the same variation unit treated as distinct objects) and n MSS. A natural way to represent this collation is an m× n matrix, where the rows represent the readings and the columns represent MSS. A cell at row i and column j contains a 1 if MS j attests to reading i, and a 0 otherwise. We will call this collation matrix X. A small example of such a matrix is shown in Fig. 1.\nWe want to find k latent features underlying this data. In our case, the features are texttypes or textual families; the larger k is, the finer the groupings are. For the purposes of this application, we assume that the observed readings and MSS\nhave been generated by these hidden features. Fig. 2 gives an illustration of this model.\nm n m k n\nThe corresponding equation for this generative process is\n(1) X ≈ WH.\nHere, W, called the basis matrix, is an m×k matrix describing the makeup of each group in terms of linear combinations of readings, and H, called the coefficient or mixture matrix, is a k × n matrix describing the makeup of each MSS’s text in terms of linear combinations of groups. So our goal is to find group membership coefficients for readings and for texts that, when combined, explain the data as best as possible. Since the data matrix X is obviously non-negative and we want to describe it in terms of “sums of parts,” we restrict W and H to be non-negative, as well. This model has several advantages over standard clustering models: First, it allows readings and texts to belong to more than one cluster, which is critical for providing group profiles and dealing with contamination; second, it assigns weights to readings so that the ones more characteristic of a single cluster have higher priority than those shared among several; and third, it assigns weights to MSS, so we can see which ones are the strongest and purest representatives of their groups.\nThe “closeness” of the product WH to X can be measured in a variety of ways, but in this paper, we will use\n(2) ||X−WH||2F ,\nwhich is the squared Frobenius norm, or the total sum of squared differences between each cell of X and the corresponding cell of WH. So our goal in any factorization will be to minimize this quantity.\nHow, then, do we find W and H? We must first choose initial matrices W1 and H1 ourselves, either with random positive values in each cell or with an educated guess. Then we alternate between updating them using the following rules:\nWt+1 = arg minW≥0 ||X−WHt|| 2 F(3)\nHt+1 = argminH≥0 ||X−Wt+1H|| 2 F(4)\nIn other words, for each matrix in the factorization, we fix the values of the other matrix and choose new non-negative values for this matrix that minimize the value of function (2). Clearly, this means that the value of function (2) will never increase from one step to the next, but can only decrease or remain the same. Until we reach a point in the process where rules (3) and (4) no longer change anything, we iteratively update W using the current H and then update H using the new W. Our aim is that by repeating these alternating optimizations, we will eventually reach a fixed point in the process where function (2) is no longer improved by these updates.\nAt this point, the reader may recognize the lurking shadow of co-dependence between readings (W) and witnesses (H). How do we know that the loop of updates won’t reach a stable point before the objective function does? And what happens if the process never reaches a fixed point? As it turns out, such scenarios can never happen:\nTheorem ([29, 28]). Any limit point of the sequence {Wt,Ht}∞t=1 generated by rules (3) and (4) is a stationary point of function (2).\nFrom this theorem, we are guaranteed that our update process will not reach a stable point without the objective function doing the same. If we add any upper bound (it can be as large as we need to ensure accuracy) to the entries of W and H, then we can also guarantee that the update process has at least one limit point. So NMF with objective function (2), update rules (3) and (4), and (arbitrarily large) upper bounds on the matrix entries will always converge to a factorization that is at a stationary point of the objective function.3\nAs this analysis has shown, NMF provides a natural model for identifying textual families and more than adequately addresses the problems of contamination and co-dependence. With regard to contamination, it not only detects the degrees and sources of contamination in individual texts, but also quantifies the importance of specific readings to textual clusters. With regard to co-dependence, we have shown that NMF’s use of iterative refinement of group readings and group witnesses is guaranteed not only to stop, but to stop at a critical point of the function it is trying to minimize."
    }, {
      "heading" : "4. Application",
      "text" : "4.1. Data. We applied NMF to Tommy Wasserman’s comprehensive collation of the epistle of Jude [7]. We considered this a good testing ground for the method for several reasons:\n• The size of the collation, which might be prohibitive for more complex, supervised methods, can be handled efficiently and automatically by NMF.\n3It should be noted, however, that the process and the objective function may have more than one stationary point, meaning that one NMF run may reach a locally optimal, but not globally optimal, factorization. It is therefore important to run NMF with good initial guesses for W and H or to repeat it many times with different random guesses.\n• The collation is complete over nearly all readings and MSS.4 We can therefore avoid any biases associated with previous selections of “genealogically significant” readings and texts. Moreover, starting with virtually all available evidence, we can discover new readings and texts of significance and add confidence to existing ones whose significance we re-discover. • To the best of our knowledge, no other application of this scale has been done with Wasserman’s work. We hope that our work will spark continued research involving his collation and inspire work towards collations of equal scale elsewhere in the NT.\nThe collation covers 560 MSS, including 3 papyri and 38 lectionaries, across 360 variation units. In encoding the data, we ignored lacunae, partially lacunose or uncertain readings;5 readings from non-continuous-text sources such as correctors’ hands;6 and units contained within larger, overlapping omissions.7 All readings that were not skipped, including omissions, were then represented by their own row in the collation matrix, with MSS represented in columns. (See Fig. 1.) The result was a 1346× 560 matrix with 178887 non-zero entries.\nAfter running NMF on this matrix in different settings, we observed that highly lacunose MSS and singular readings were being isolated in their own clusters. This likely occurred because these witnesses and readings constituted outliers with high influence on the objective function of the factorization. To account for this, we removed all singular readings from consideration and treated all MSS with fewer than 300 readings as secondary, non-continuous texts. Filtering these out, we were left with a 789× 518 matrix with 155400 non-zero entries. The excluded MSS are listed on page 20.\n4.2. Prior Weights on Readings. We applied NMF to our collation matrix with the entries being weighed uniformly on the one hand, and using the inverse document frequency (IDF) scheme on the other hand. Uniform weighting, as its name suggests, weighs all readings equally prior to NMF; all entries of the matrix are therefore 0-1 entries. IDF weighting, developed to facilitate information retrieval in the context of terms and documents [31], is a heuristic that seeks to weigh individual terms by their specificity. While a theoretical justification of its use has been elusive [32], it has proven to be of great practical effectiveness in text mining tasks.\nThe definition is simple. If a term t occurs nt times among n documents, then we assign it a weight\n(5) IDF(t) = log n nt . Here, log is a logarithm that can be taken to any base greater than 1. With this weighting function, the more documents term t appears in, the less information it provides about any specific document. The word the is an example of such a term. If it appears in all n documents, then its IDF weight would be log(n/n) = log(1) = 0.\n4Wasserman notes that his apparatus does not record the most frequent orthographic variants, such as instances of movable nu, final vowel elisions in prepositions and conjunctions, itacisms, and other common vowel interchanges [7, p. 129–130]. But this is actually good for our purposes, since such readings are considered unimportant for MS classification [30, p. 27–28].\n5These readings contain underlying dots or brackets in Wasserman’s apparatus. 6Non-continuous texts pose the same problems for NMF that they do for other methods like CBGM. Nevertheless, once clusters have been determined for the continuous-text data, we can make inferences about the non-continuous-texts on the basis of their readings. See Appendix A for more details.\n7Another way to handle units contained in larger omissions would be to treat them as omissions themselves. We did not attempt to encode the data in this way, but the number of variation units in question is small enough that we do not expect significantly different results.\nMeanwhile, a word appearing in only a single document would have the larger weight log(n).\nIn our case, we would take readings as “terms.” The highest-specificity readings, then, would be those that occur more rarely, with singular readings receiving the highest prior weight. Balancing this out is the fact that singular readings are less informative about non-trivial clusters (i.e., those consisting of more than a single MS), which will lead NMF to give these readings a lower final weight than it gives to readings with attestation from slightly larger groups. Sometimes, however, singular readings will exert enough influence to bias the factorization towards outlying MSS. This is what initially happened with our data, as we showed in subsection 4.1. When this happens, it is prudent to perform outlier detection and removal, as we have done. Ultimately, in maximizing the cohesiveness of MS clusters, non-singular readings that are shared exclusively by the MSS in a given cluster are likely to become the most important readings. Meanwhile, readings that are common to multiple clusters will be given less weight and therefore will play less of a role in NMF.\nEach of these two weighting schemes is best suited for a different set of tasks. Uniform weighting is better in the context of clustering on the “whole picture” of readings and explaining as much of the variance between MSS as possible. This is applicable, for example, to the construction of a text-critical apparatus, where we want to group many MSS under a few sigla for the purpose of succinctness, while having to list as few exceptional cluster members as possible.8 IDF weighting is more useful in producing weighted profiles of textual families based on their most exclusive readings. In general, it is more aligned with human intuition in identifying textual groups, as we will see.\n4.3. Implementation. For ease of use, we stored all apparatus matrices, along with their row and column headers, as Microsoft Excel spreadsheets. For all computational work, we used release 3.5 of the Python programming language.9 To read and write data from and to Excel spreadsheets, we used the Python pandas package.10 For running NMF on our data, we chose to use nimfa, an open-source Python library [33]. This library best fit our needs because it offered a variety of NMF versions, including versions having the convergence guarantees summarized in section 3, numerous factor initialization methods, and factorization quality measures. For most of our data manipulation needs, including linear algebra for matrix operations, we used the SciPy stack of open-source Python modules for scientific computing.11 To factor our collation data in nimfa, we used the Lsnmf method, an implementation of the alternating least-squares formulation of NMF proposed by Lin [28]. We ran this with values of k ranging from 2 to 8 and a maximum iteration limit of 8000. We used a single run in each case, seeding it with NNDSVD initialization, a non-random initialization method that has been empirically shown to result in faster, lower-error factorizations [34]. We found that single runs initialized in this way matched the objective function values for hundreds to thousands of runs with random initialization, and in fact tended to give sparser factors.\nThis implementation of NMF was run separately on a platform with an Intel i7-4770 quad-core processor and 16GB of memory, which we will denote P1, and a platform with an Intel 2 Duo dual-core processor and 2GB of memory, which we\n8Of course, the more contaminated the scribal tradition is, the more exceptions one can expect to see in the apparatus. But even then, the level of compression achieved for the average reading may still outweigh the number of exceptions.\n9python.org/ 10pandas.pydata.org/ 11scipy.org/\nwill denote P2. The differences in performance between the two platforms will be detailed in the following sections."
    }, {
      "heading" : "5. Results",
      "text" : "5.1. Uniform-weighted results. Table 2 gives summary statistics for the uniformweight NMF runs and results for 2 ≤ k ≤ 8. In general, NMF obtained factorizations that explained much of the variance in the observed data, and it did so in a very short time.\nWe will now examine the results for k = 8 in detail. Table 9 lists the mixture coefficients for consistently-cited witnesses in the NA28 apparatus for Jude [36]. Note that the coefficients have not been normalized. We have left them as-is in order to preserve their absolute magnitude, which we can interpret as a “confidence score” for classification. If we were to divide each coefficient in a given row by the row-wise sum, we could interpret the scaled coefficients as mixture proportions. Under such normalization, MS 01 would be interpreted as 78% cluster 1, 15% cluster 2, 4% cluster 8, and 3% cluster 7.\nIn order to determine the textual groups represented by the clusters, it is instructive to look at their most representative witnesses. Tables 10–17 list the top 15 MSS in each cluster. For the purposes of profiling secondary witnesses, we will also want to know the most important readings in each cluster. Tables 18–25 list these readings in order of their coefficients.\nThe group behind cluster 1 is perhaps the easiest to identify: This cluster represents the Alexandrian texttype. Perhaps not surprisingly, one of its best representatives is 03 (B), with papyrus P72 being another leading member. The remaining top representatives include a handful of NA28’s consistently-cited witnesses. Uncials 01 (ℵ), 02 (A), and 04 (C) also fall under this cluster, but as Table 9 shows, they all have strong enough elements of mixture with other clusters that they do not make it to the top of the cluster’s list. The cluster contains 59 MSS in total.\nCluster 2 appears to be a mixture of two textual families identified in existing literature: f1739 and f2138 [37, p. 1136–1163, 1166–1175]. The former group has also been identified in 2 Peter [38, p. 45–47], and in the catholic epistles, it shares important readings with the old Georgian versions [39]. Its namesake is a consistently-cited witness in NA28. One of 1739’s scribes claimed to have copied it from an ancient codex, and scholars conjecture that its exemplar dates back at least\nto the fourth or fifth century. Further evidence for the family’s antiquity has been found in its close similarity to the text used by Origen [40]. The connection with Origen has led some to posit that f1739 represents the controversial “Caesarean” texttype in the catholic epistles [39]. The latter group has also been identified in 2 Peter [38, p. 51–53], and in James, 1 Peter, and 1 John, its core members have been shown to have a connection to the Harklean Syriac [41, 42]. So f1739 and f2138 both attest to early forms of several of the catholic epistles, and the same situation likely holds in Jude, as well. The cluster is small, at 22 MSS, but the witnesses are generally cohesive. The fact that their readings overlap enough for their MSS to be grouped together also suggests that f1739 and f2138 are closely related to each other in most variation units.\nCluster 3, as its witnesses make clear, represents the group of lectionaries. The existence of a distinct lectionary textual group has been recognized for some time [43], but a thorough examination of this group in the catholic epistles was long delayed. The first, and perhaps most extensive, work in this area was done by Junack [44]. Junack’s work confirmed the existence of a large and cohesive textual family among the Byzantine lectionaries. At least in the context of the epistle of Jude, our results based on Wasserman’s complete collation should give additional weight to these findings. Our results also agree with Junack’s identification of ℓ596 as an exceptionally non-Byzantine lectionary; in fact, Table 10 lists it as a strong representative of the Alexandrian texttype. The cluster does not consist exclusively of lectionaries, as it contains 41 MSS total, but the non-lectionary MSS are lower on the list due to mixture.\nCluster 4 clearly represents the Byzantine subgroup Kr, also known as f35, as can be seen from the overlap between Table 15 and the list of collated MSS for 2 John–Jude in [45]. This cluster is by far the largest, with 172 MSS assigned to it, and it exhibits great cohesion among its purest representatives. To its disadvantage, however, it contains no witnesses dating earlier than the tenth century.\nCluster 5 appears to represent another Byzantine subgroup, but it is unclear if it corresponds to any previously-known subgroup. While not as massive as cluster 4, it is still large with 101 MSS. Perhaps the most noticeable quality is that it appears to be the earliest Byzantine subgroup. It contains the following five ninth-century MSS: 1424 (H5,j = 1.3575), 049 (H5,j = 1.1871), 018 (K) (H5,j = 1.1231), 1862 (H5,j = 0.9247), and 1841 (H5,j = 0.6001).\nCluster 6 undoubtedly represents the textual family f453 [37, p. 1098–1101]. Its earliest witness is the tenth-century MS 307, but this same MS is also a consistentlycited witness in NA28 (see Table 9). This group was independently identified in the catholic epistles through stemmatic methods by Spencer, Wachtel, and Howe, who noted that it “contains states of text that are thought to be important for the formation of the Byzantine text” [16]. The family is of moderate size, containing 35 MSS.\nCluster 7 also looks Byzantine, but like cluster 5, its precise identity is unclear. Like cluster 5, it seems to represent a text earlier than that of cluster 4; its earliest witnesses are dated to the tenth century, but two prominent representatives of the group are uncials 056 and 0142, and both of these possess Alexandrian elements (quantifiable as cluster 1 mixture proportions of 15% and 23%, respectively). The cluster is of moderate size, consisting of 59 MSS.\nCluster 8 appears to be von Soden’s Kc Byzantine subgroup [46, p. 1761], as can be seen from the presence of the following Kc MSS in the cluster: 912 (von Soden’s α366), 390 (δ366), 2085 (α465), 234 (δ365), 42 (α107), 1594 (δ375), 1405 (α555), 51 (δ364), 223 (α186), 1860 (α377), 97 (α260), and 421 (α259). The cluster as established by NMF has no witnesses from earlier than the tenth century, and of\nits purest representatives, the oldest is the eleventh-century MS 42, but the group is large enough, with 29 members, and tight-knit enough, with generally strong mixture coefficients, that its archetype is surely older than the tenth century.\nThere are a few observations to make here. NMF on a uniform-weight collation matrix reveals a number of distinct subgroups not only of the Alexandrian texttype, but also of the Byzantine texttype. In particular, the Byzantine texttype splits into the lectionary group, Kr, Kc, and two additional groups. It should be noted, therefore, that the Byzantine MSS do not form a monolithic group in Jude. Clusters 5 and 7 form two more large, as-yet unknown Byzantine families. While we might expect one of these clusters to correspond to the larger, more general K group, the MSS traditionally assigned to that group are divided between both clusters. It may be the case that the K MSS are divided in Jude, with two thirds of the family siding with the oldest MSS in the group and one third taking the other side.\nA cross-reference from Tables 18–25 to Wasserman’s apparatus reveals that NMF in the uniform-weight setting tends to assign higher basis coefficients to common, widely-divided readings than it does to rarer readings exclusive to groups. This is the result of NMF trying to minimize the number of misclassified readings when all readings are all equal in weight. To minimize unexplained variance, readings are chosen on how cleanly they divide the entire body of MSS into their assigned clusters. For these reasons, an “important” reading in this setting will likely represent multiple clusters, but a given cluster can be uniquely identified by patterns of readings. This, in essence, reflects the methodology of Wisse and McReynolds’s original formulation of the Claremont Profile Method [11, 12]. While this has the unfortunate side-effect of not clustering readings as sparsely as we might like, it is useful for certain purposes. In particular, it allows us to identify widely-split variant units, which may represent early divisions in the scribal tradition, and to determine where different families side in these splits. Table 3 gives a short list of widely-divided readings and their support among uniform-weight NMF groups.\nAs an example, the Robinson-Pierpont Greek NT lists v9u24-28 and v16u14-16 as divided Byzantine readings and opts for Μωϋσέως and αὐτῶν, respectively, as the original readings [47]. While the K2/3 cluster is split in both cases and offers no strong evidence either way, Μωϋσέως has the support of Alex, f453, and Kc, and αὐτῶν has the support of f453 and Kc. The external evidence shows earlier and more diverse testimony in favor of Μωϋσέως, with the same situation to a lesser degree in favor of αὐτῶν.12 Valuing diversity of testimony, we therefore agree with Robinson and Pierpont’s textual decisions on the divided readings in Jude. The results of NMF may also reveal readings that have not yet been recognized as divided Byzantine readings; v1u4-8 and v5u12-20 are two candidates.13\nOf course, in other applications, we would want to identify readings that are individually more exclusive to their groups. In these cases, we view less common readings as more valuable a priori. Thus, to get sparser results, we must turn to NMF in the IDF-weight setting.\n5.2. IDF-weighted results. Table 4 gives summary statistics for the IDF-weight NMF runs and results for 2 ≤ k ≤ 8. Because IDF weighting assigns greater importance to less common readings, NMF tends to find more exclusive bases for clusters in this setting. Another positive effect of IDF weighting is that it allows NMF to isolate more distinctive clusters, often due to differences that uniformweight NMF overlooks. A disadvantage, as can be seen in Table 4, is that when the factorization sets aside especially rare readings for the sake of more common, cohesive ones, the high weight of the ignored readings reduces the explained variance of the model.14 For all k, an NMF run in this setting took at most a couple seconds on both platforms.\nWe will now examine the results for k = 8 in detail. Table 26 lists the mixture coefficients for consistently-cited in the NA28 apparatus for Jude [36]. As in the\n12We would not consider the agreement of Kr and Lect to be especially diverse, as they both are closely related to the Byzantine texttype. The only non-Byzantine support comes from f1739 + 2138 for Μωσέως and f1739 for αὐτῶν (the cluster’s support there is essentially split between f1739 and f2138). This relationship may be worth closer study in the future.\n13At these locations, Robinson-Pierpont gives only the readings Ἰησοῦ Χριστοῦ δοῦλος and ὑμᾶς ἅπαξ τοῦτο ὅτι ὁ κύριος, respectively. If we were to account for the readings of the other K subgroups here, we would include the readings Χριστοῦ Ἰησοῦ δοῦλος and ὑμᾶς τοῦτο ἅπαξ ὅτι ὁ κύριος, respectively, in the margin.\n14See subsection 4.2 for more details on the problem and how to address it.\nuniform-weight case, no normalization has been applied to the coefficients. Tables 27–34 list the most representative MSS in each cluster, and Tables 35–42 list the most representative readings for each cluster.\nCluster 1 clearly represents f2138. We also note that now the cluster contains no representatives from f1739, and for this reason, it now consists of only 24 MSS. An important observation in Table 26 is that uncial 04 (C) has its highest mixture coefficient in this cluster, which suggests that it shares many characteristic readings, or at least some high-weight characteristic readings, with f2138. The first few can be found in Table 35 and are the following: v24u18.2, v14u26-36.2, v23u2-22.17, and v25u24-30.1.\nCluster 2 appears to represent the majority of the Byzantine texttype, as 318 MSS are members of it. The group appears to be cohesive enough not to be split up when k = 8, but its mixture coefficients are also the lowest of any cluster by far, which suggests that there is variance among the members of the cluster. This likely arises in splits between Byzantine subgroups at common readings; in the IDF setting, these readings will have low enough weight not to split the cluster, but their total weight will suffice to produce noticeable variance within the group. Nevertheless, the characteristic readings of the cluster have strong coefficients, which indicates that uniquely Byzantine readings are shared even by the texttype’s different subgroups.\nCluster 3 represents f1739. The group is small, consisting of only 8 MSS, but this is the result of its being split apart from f2138. Uncial 04, while not a member of this cluster, still shares some significant readings with it. These readings include v5u4.2, v22u2-10.4, and v14u26-32.2.\nCluster 4 contains the Alexandrian witnesses. The cluster, which consists of 39 MSS, is slightly smaller than its counterpart in the uniform-weight setting. Due to more exclusive readings being assigned prominent places in the cluster basis, the order of the most representative witnesses has shifted somewhat. Notably, uncial 02 (A) and P72 are considered slightly more “Alexandrian” than 03 (B) in the IDF setting. A glance at Table 26 will reveal that 02 is relatively pure in its mixture coefficients, while 01 (ℵ), 03, and 04 all have at least some mixture with Cluster 7. We will revisit this in a moment.\nCluster 5 represents f453. The group consists of 22 MSS here, which is a bit smaller than it was from uniform-weight NMF. Like the other clusters, its readings should now be more exclusive to the group. Little else has changed.\nCluster 6 is obviously the lectionary group. It now consists of 73 MSS, which means that it may have borrowed some MSS placed elsewhere in the uniform-weight clusters. Its readings are now more exclusive to the group, but little is different otherwise.\nCluster 7 is a curious group consisting of only 13 MSS. Most of its members were lumped under the Alexandrian cluster in the uniform-weight setting, so it appears to have some relationship with the Alexandrian text. The top two MSS, 915 and 88, demonstrate a high level of agreement in both the catholic and Pauline epistles. In the catholics, they and a few other members of this cluster (442, 621, 1243, 1846, and 2492) read δι’ ὕδατος καὶ πνεύματος καὶ αἵματος in 1 John 5:6. In 1 Corinthians, 88 and 915 attest to an infamous variant that places 14:34–35 at the end of the chapter, with the only other Greek MS support coming from Western witnesses. Their support for that reading has led to much debate over whether or not they have a common source in a localized Western text and whether or not they support the theory that 1 Corinthians 14:34–35 is an interpolation [48, 49, 50]. Despite the rarity of some of its other readings, the cluster’s characteristic readings are shared by the Alexandrian uncials 01, 03, and 04, and 044 (Ψ), which suggests that the\ncluster preserves some ancient readings. As the cluster itself does not appear to have been identified in the literature, we will designate it by f915 here.\nCluster 8 is another unusual group, made up of 21 MSS. Most of its members were mixtures of multiple Byzantine subgroups in the uniform-weight setting, so it appears to represent a small and distinct branch of the Byzantine texttype. Its top representatives, MSS 618, 460, 177, 337, and 1738, are strong, pure representatives of the family. Some of the MSS themselves are noteworthy. Scrivener describes 618 as “valuable, but with many errors” [51, p. 294]; he finds a similar text in 460 and considers this MS “an important copy” [51, p. 291]. Apart from this, the cluster itself does not seem to have received much study. Lacking an existing name for it, we will designate it f618 in this paper. We observe one other connection between these MSS outside the catholic epistles, in the letter to the Romans. There, many of the family MSS contain the subscription πρὸς Ῥωμαίους ἐγράφη ἀπὸ Κορίνθου διὰ Φοίβης τῆς διακόνου τῆς ἐν Κεγχρέαις.15 In Jude, one of the group’s most characteristic readings, v3u40-46.2, is shared by P72, which may indicate ancient roots for the reading and possibly for the family. On further examination, however, this is the only significant group reading that P72 supports apart from the much lower-weight reading in v4u20,16 so the agreement is more likely coincidental.17 In this case, the best explanation for the agreement is that the reading arose independently in P72 and f618.\nWe will make some observations to conclude this section. While NMF in the uniform-weight setting succeeds at accounting for variance by giving more priority to common, widely divisive readings, NMF in the IDF setting does better at locating readings more exclusive to specific clusters. This, in turn, allows it to identify sparser reading bases and smaller MS groups.\nFor an illustration of this difference, please refer to Table 5, which gives a short list of widely-divided readings and their support among IDF-weighted NMF groups. Compare this to Table 3. Notice how splits among the groups formed tend to be more common for widely-divided readings in the IDF setting, while more distinctive group readings are identified in units with many readings, such as v5u12-20.\nIn general, the re-weighting of the observed data results in different clusters with sharper separation. While both weighting schemes isolate Alexandrian, f453, and lectionary clusters, IDF-weighted NMF compresses all previous subgroups of K into a single cluster, separates f1739 and f2138 appropriately, and identifies small subgroups of the Alexandrian and Byzantine texttypes with unique readings. For the purposes of identifying the most significant variation units and witnesses (e.g., to provide more refined and manageable inputs to CBGM or other more complex methods), this setting seems to be the most suitable.\n15Specifically, the f618 MSS with the Romans subscription include 618, 460, 177, 337 (which includes the subscription, but reorders many words and includes a reference to Tertius), 1738, 607 (which omits πρὸς Ῥωμαίους), 1874 (which changes the begining to ἡ πρὸς Ῥωμαίους ἐπιστολή and omits τῆς ἐν Κεγχρέαις), and 404 (which appears to omit τῆς ἐν Κεγχρέαις).\n16This unit concerns the inclusion or omission of the article τὸ, and all but a few witnesses (including most of f618) include the article, so this is probably an instance of independent errors producing agreement.\n17Further evidence for coincidental agreement is that Wasserman lists P72 as having a defective text reading here, with a corrector’s hand supplying not the reading of f618, but the reading shared by the majority of MSS. Besides this, in the other high-ranking variation units of f618, P72 either shares the majority reading or has a unique reading whose derivation from the f618 reading would be difficult to explain (e.g., in v5u12-20, v24u8-14, and v12u18). In other units, P72 alternatively adds to (v10u24), omits from (v14u22-24), or transposes (v18u24-34) the f618 reading, leaving us no indication that the scribe of P72 deviated from the f618 text in any consistent way."
    }, {
      "heading" : "6. Summary and Conclusions",
      "text" : "In this paper, we have shown how non-negative matrix factorization, or NMF, can effectively classify MSS and readings on texttype-based principles. While, as a pre-genealogical method, it cannot make inferences regarding prior and posterior textual relationships, it can be used to facilitate more complex genealogical methods by providing better selections of readings and witnesses for input. We have demonstrated the suitability of NMF for these tasks on both theoretical and empirical grounds.\nOn the theoretical side, NMF is able to cluster both readings and MSS by finding the best approximate factorization of the collation matrix. By alternatively optimizing the basis and coefficient factor matrices, it keeps the problem of codependence between readings and MSS under control. Since, for certain NMF update rules, this process can be proven to stop only when the objective function of the factorization reaches a critical point, we have a theoretical guarantee that co-dependence won’t cause an endless loop or result in arbitrarily bad clusters. Additionally, NMF provides an easy-to-interpret model that allows us to determine reading profiles for clusters and account for mixture between different clusters in MSS.\nOn the practical side, NMF provides fast, human-recognizable results for matrices in various weighted settings. NMF is able to factor a complete collation matrix of Jude for 518 MSS in less than 2 minutes in the uniform-weight setting, and in a matter of seconds in the IDF setting. As we have indicated, the uniform-weight setting provides good group classifications over widely-divided variation units, while the IDF-weight setting highlights the most distinctive readings of textual families.\nUsing NMF on Wasserman’s collation of Jude, we were able to classify many previously-unclassified MSS and verify several existing group classifications. In the uniform-weight setting, we identified a distinct textual family for lectionaries in Jude; we found further empirical justification for von Soden’s Kr and Kc groups, in addition to a subdivision of his K group; and we both verified the choices for the textual and marginal readings of Jude in [47] and proposed additional marginal readings based on the readings of the identified Byzantine subgroups. Meanwhile, in the IDF setting, we isolated characteristic MSS and readings for well-known groups, including the Alexandrian texttype, the Byzantine texttype, the lectionaries, f453, f1739, and f2138; we found two other groups, which we identified as f915 and f618; and we demonstrated that both f915 and f618 have family ties outside of the catholic epistles, suggesting that the classification made by NMF is legitimate.\nWe feel that NMF has tremendous potential as a tool for automatic, unsupervised, texttype-based textual criticism, and we wish to see it implemented in further studies. As we have attempted to show, its results can be fruitful in a multitude\nof applications, from organizing known collation data to performing exploratory analysis on what is yet unknown. We hope to find the new textual groupings and MS classifications done with NMF examined further and perhaps used as starting points for new research on the complex text of the epistle of Jude. It certainly deserves our greatest effort."
    }, {
      "heading" : "Appendix A. Classification of Lacunose MSS",
      "text" : "In Section 4.1, we explained that in the process of data selection, we regarded the texts of correctors and witnesses with fewer than 300 readings as non-continuous and therefore secondary. Table 6 lists the MSS from Wasserman’s collation that were too lacunose to be included. Because of their age, most papyri and uncials are so lacunose that they must be excluded in this way. This leaves us with an unfortunate situation, in which we have nothing to say about the MSS in which we are most interested.\nFortunately, we are not without a remedy. Once NMF on the primary set of continuous-text witnesses has produced a basis matrix W for cluster readings, we can use this matrix to classify the secondary witnesses by whatever readings they do have. If we take x⃗ to be a vector representing the readings of a single secondary witness that we want to classify, then the solution h⃗ to the least-squares equation\n(6) argmin h⃗≥0 ||x⃗−Wh⃗||2F\nwill contain the mixture coefficients for the witness represented by x⃗. Because the entries of h⃗ are required to be non-negative, we can interepret h⃗ as we interpreted the mixture matrix H for the primary witnesses.\nTo solve equation 6, we used SciPy’s optimize.nnls method for each MS in Table 6 individually, in both the uniform-weight case and the IDF-weight case. For the sake of space, we will not list the mixture coefficients of all MSS, but we will list the results for MS 2138 and the consistently-cited NA28 witnesses P74, P78, 025, and 1852. These results can be found in Tables 7 and 8.\nAs Table 7 shows, P74 and P78 are too lacunose to be classified with much confidence in the uniform-weight case. Uncial 025 (P) fares slightly better, exhibiting a moderate Alexandrian element and weaker lectionary and Kr elements. MSS 1852 and 2138, on the other hand, clearly belong to the f1739 + 2138 cluster.\nThe situation is not too different in the IDF-weighted setting, as Table 8 shows. As in the uniform-weight case, P74’s extant readings do not commend it to any cluster. The situation is nearly the same for P78; it has a slightly higher mixture coefficient for the f2138 cluster because it shares the group reading ἐπέχουσαι at v7u50, but it is otherwise too lacunose for us to determine any closer relationship. Uncial 025, like P78, is inconclusive. MS 1852 shares characteristic readings of both f2138 and the Alexandrian cluster. Finally, as we would expect, MS 2138 clearly belongs to the family bearing its name."
    }, {
      "heading" : "Appendix B. NMF Results",
      "text" : ""
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "The text-critical practice of grouping witnesses into families or texttypes often faces two obstacles: Contamination in the manuscript tradition, and co-dependence in identifying characteristic readings and manuscripts. We introduce non-negative matrix factorization (NMF) as a simple, unsupervised, and efficient way to cluster large numbers of manuscripts and readings simultaneously while summarizing contamination using an easy-to-interpret mixture model. We apply this method to an extensive collation of the New Testament epistle of Jude and show that the resulting clusters correspond to human-identified textual families from existing research.",
    "creator" : " XeTeX output 2016.02.03:0942"
  }
}