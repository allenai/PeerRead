{
  "name" : "1205.2610.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Probabilistic Structured Predictors",
    "authors" : [ "Shankar Vembu", "Thomas Gärtner", "Mario Boley" ],
    "emails" : [ "mario.boley}@iais.fraunhofer.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We consider MAP estimators for structured prediction with exponential family models. In particular, we concentrate on the case that efficient algorithms for uniform sampling from the output space exist. We show that under this assumption (i) exact computation of the partition function remains a hard problem, and (ii) the partition function and the gradient of the log partition function can be approximated efficiently. Our main result is an approximation scheme for the partition function based on Markov Chain Monte Carlo theory. We also show that the efficient uniform sampling assumption holds in several application settings that are of importance in machine learning."
    }, {
      "heading" : "1 Introduction",
      "text" : "We consider discriminative structured prediction models with an emphasis on predicting combinatorial structures. These structures find applications in machine learning problems such as multi-label classification (Elisseeff & Weston, 2001), multi-category hierarchical classification (Cesa-Bianchi et al., 2006), and label ranking (Dekel et al., 2003).\nLet X × Y be the domain of observations and labels, and let X = (x1, · · · , xm) ∈ Xm, Y = (y1, · · · , ym) ∈ Ym be the set of observations. Our goal is to estimate y|x using exponential families via\np(y|x, θ) = exp(〈φ(x, y), θ〉 − lnZ(θ|x)) ,\nwhere φ(x, y) are the joint sufficient statistics of x and y, and Z(θ|x) = ∑ y∈Y exp(〈φ(x, y), θ〉) is the partition function which takes care of the normalisation. We perform maximum-a-posteriori (MAP) parameter\nestimation by imposing a normal prior on θ. This leads to optimising the negative joint likelihood in θ and Y :\nθ̂ = argmin θ [− ln p(θ, Y |X)]\n= argmin θ\n[ λ‖θ‖2 + 1\nm m∑ i=1 [lnZ(θ|xi)− 〈φ(xi, yi), θ〉]\n] ,\n(1) where λ > 0 is the regularisation parameter. Throughout this paper, we assume that the `2 norm of the sufficient statistics and the parameters are bounded, i.e., ‖φ(x, y)‖ ≤ R and ‖θ‖ ≤ B, where R and B are constants (note that B can be bounded from above as shown in Appendix C). The difficulty in solving (1) lies in the computation of the partition function. The optimisation is typically performed using gradient descent techniques (and advancements thereof). We therefore also need to compute the gradient of the log partition function, which is the first order moment of the sufficient statistics, i.e., ∇θ lnZ(θ|x) = Ey∼p(y|x,θ)[φ(x, y)].\nComputing the log partition function and its gradient are in general NP-hard. In section 2, we will show that computing the partition function still remains NP-hard given a uniform sampler for Y. We therefore need to resort to approximation techniques to compute these quantities. Unfortunately, application of concentration inequalities do not yield approximation guarantees with polynomial sample size. In this work, we present Markov chain Monte Carlo (MCMC) based approximations for computing the partition function and the gradient of the log partition function with provable guarantees. There has been a lot of work in applying Monte Carlo algorithms using Markov chain simulations to solve ]P-complete counting and NP-hard optimisation problems. Recent developments include a set of mathematical tools for analysing the rates of convergence of Markov chains to equilibrium (see Randall (2003); Jerrum and Sinclair (1996) for surveys). To the best of our knowledge, these tools have not been applied in the design and analysis of structured prediction problems, but have been referred to as an\nimportant research frontier (Andrieu et al., 2003) for MCMC based machine learning problems in general."
    }, {
      "heading" : "1.1 Our Contributions",
      "text" : "We analyse discriminative probabilistic structured prediction models based on exponential families using MCMC theory. In particular,\n• we prove a hardness result for computing the partition function (Section 2);\n• we present an algorithm for approximating the partition function and the gradient of the log partition function with provable guarantees (Section 2);\n• we design a Markov chain that can be used to sample combinatorial structures from exponential family distributions considered in this work given that there exists an exact uniform sampler, and also perform a non-asymptotic analysis of its mixing time (Section 3);\n• we describe several combinatorial structures that find applications in machine learning problems, including multi-label classification, label ranking, and multi-category hierarchical classification (Section 4).\nNotation: We will use [[n]] to denote the set of integers {1, . . . , n}, || · || to denote the `2 norm of a vector, and | · | to denote the `1 norm if the argument is a vector, the absolute value if the argument is a scalar, and the cardinality if the argument is a set."
    }, {
      "heading" : "2 Computing the Partition Function: Hardness Result and Approximations",
      "text" : ""
    }, {
      "heading" : "2.1 Hardness of Computing the Partition Function",
      "text" : "Consider the output space of undirected cycles over a fixed set of vertices Σ, i.e., Y =⋃ U⊂Σ cyclic permutations(U). Let ψ : Y → RΣ×Σ with ψuv(y) = 1 if {u, v} ∈ y and 0 otherwise.\nTheorem 2.1 Computing the partition function of cyclic permutations is NP-hard.\nProof Suppose we can compute lnZ(θ) = ln ∑ y∈Y exp(〈ψ(y), θ〉) efficiently. Given an arbitrary graph G = (V,E) with adjacency matrix θ̄, let Σ = V and θ = θ̄ × ln(|V |! × |V |). We will show that G has a Hamiltonian cycle if and only if lnZ(θ) ≥ |V | × ln(|V |!× |V |).\nFirst, observe that |Y| < |V |!× |V |.\nNecessity: As the exponential function is positive and ln is monotone increasing, it follows that lnZ(θ) ≥ |V | × ln(|V |!× |V |).\nSufficiency: Suppose G has no Hamiltonian cycle. Then\nlnZ(θ) ≤ ln[|Y| × exp[(|V | − 1)× ln(|V |!× |V |)]] = ln |Y|+ (|V | − 1)× ln(|V |!× |V |) < |V | × ln(|V |!× |V |) .\nThis completes the proof.\nWe are interested in the class of problems for which sampling uniformly at random is easy, and cyclic permutations is one example of these. The following result shows that computing the partition function is hard even if we restrict the problem to this class. Essentially, it transfers the general NP-hardness result of computing the partition function to the restricted class of problems that we are interested in.\nCorollary 2.2 Computing the partition function of cyclic permutations remains NP-hard even if efficient algorithms for uniform sampling of cyclic permutations exist.\nIn the next section, we show how to approximate the partition function given that there exist efficient algorithms for uniform sampling."
    }, {
      "heading" : "2.2 Approximating the Partition Function",
      "text" : "As a first step towards approximating the partition function, we could consider using concentration inequalities. If we can sample uniformly at random from Y, then we can apply Hoeffding’s inequality to bound the deviation of the partition function Z(θ|x) from its finite sample expectation Ẑ(θ|x). Unfortunately, the bound obtained from using Hoeffding’s inequality is not useful due to its dependence on the size of the output space |Y|. We now present an algorithm that is a fully-polynomial randomised approximation scheme for approximating the partition function.\nDefinition 2.1 Suppose f : P → R+ is a function that maps problem instances P to positive real numbers. A randomised approximation scheme for P is a randomised algorithm that takes as input an instance p ∈ P and an error parameter > 0, and produces as output a number Q such that\nPr[(1− )f(p) ≤ Q ≤ (1 + )f(p)] ≥ 3 4 .\nA randomised approximation scheme is said to be fully polynomial (FPRAS) if it runs in time polynomial in the length of p and 1/ .\nWe exploit the intimate connection between counting and sampling problems (Jerrum et al., 1986) to approximately compute the partition function using sampling algorithms. The technique is based on a reduction from counting to sampling. The standard approach (Jerrum & Sinclair, 1996) is to express the quantity of interest, i.e., the partition function Z(θ|x), as a telescoping product of ratios of parameterised variants of the partition function. Let 0 = β0 < β1 · · · < βl = 1 denote a sequence of parameters also called as cooling schedule and express Z(θ|x) as a telescoping product\nZ(θ|x) Z(βl−1θ|x) × Z(βl−1θ|x) Z(βl−2θ|x) × · · · Z(β1θ|x) Z(β0θ|x) ×Z(β0θ|x) .\nDefine the random variable fi(y) = exp[(βi−1 − βi) 〈φ(x, y), θ〉] (we omit the dependence on x to keep the notation clear), for all i ∈ [[l]], where y is chosen according to the distribution πβi = p(y|x, βiθ). We then have Efi = ∑ y∈Y exp[(βi−1 − βi) 〈φ(x, y), θ〉] exp[βi 〈φ(x, y), θ〉] Z(βiθ|x)\n= Z(βi−1θ|x) Z(βiθ|x) ,\nwhich means that fi(y) is an unbiased estimator for the ratio ρi = Z(βi−1θ|x)/Z(βiθ|x). This ratio can now be estimated by sampling according to the distribution πβi and computing the sample mean of fi. The desideratum is an upper bound on the variance of this estimator. Having a low variance implies a small number of samples S to approximate each ratio. The final estimator is then the product of the reciprocal of the individual ratios in the telescoping product.\nWe now proceed with the derivation of an upper bound on the variance of the random variable fi, or more precisely on the quantity Bi = Varfi/(Efi)2. We first assume that Z(β0θ|x) = |Y| can be computed in polynomial time1. We use the following cooling schedule (Stefankovic et al., 2007): l = pdR||θ||e; βj = j/(pR‖θ‖) for all j ∈ [[l − 1]], where p is a constant integer ≥ 3, i.e., we let the cooling schedule to be of the following form:\n0, 1 q , 2 q , 3 q , · · · , pbR||θ||c q , 1 ,\nwhere q = pR‖θ‖ (and w.l.o.g. we assume that R||θ|| is non-integer and real). Given this cooling schedule, observe that exp(−1/p) ≤ fi ≤ exp(1/p), which follows\n1The assumption is true in all the applications we consider in this work. If it is not possible to compute |Y|, which is a counting problem, in polynomial time, we can still approximate it using the machinery introduced in this section.\nfrom the definition of the random variable fi, and also exp(−1/p) ≤ Efi = ρi ≤ exp(1/p). We are now ready to prove the bound on the quantity Bi.\nProposition 2.3 Bi = Varfi(Efi)2 ≤ exp(2/p), ∀ i ∈ [[l]].\nWe first need to prove the following lemma.\nLemma 2.4 exp(1/p)− 1 ≤ ρi ≤ exp(−1/p) + 1.\nProof a ≤ b⇒ exp(a)− exp(−a) ≤ exp(b)− exp(−b) as the exponential function is monotone increasing. Thus a ≤ 1/3⇒ exp(a) − exp(−a) ≤ exp(1/3) − exp(−1/3) < 1. Setting a = 1/p with p ≥ 3 and using the fact that exp(−1/p) ≤ ρi ≤ exp(1/p) for all i ∈ [[l]] proves the lemma.\nProof (of Proposition 2.3) Consider ρi ≥ exp(1/p)− 1 ≥ fi − 1. This implies fi − ρi ≤ 1. Next, consider ρi ≤ exp(−1/p) + 1 ≤ fi + 1. This implies fi − ρi ≥ −1. Combining these, we get |fi − ρi| ≤ 1, which implies Varfi ≤ 1, and therefore Varfi/(Efi)2 ≤ exp(2/p).\nEquipped with this bound, we are ready to design an FPRAS for approximating the partition function. We need to specify the sample size S in each of the Markov chain simulations needed to compute the ratios.\nTheorem 2.5 Suppose the sample size S = d65 −2l exp(2/p)e and suppose it is possible to sample exactly according to the distributions πβi , for all i ∈ [[l]], with polynomially bounded time. Then, there exists an FPRAS with as the error parameter for computing the partition function.\nProof The proof uses standard techniques described in (Jerrum & Sinclair, 1996). Let X(1)i , · · · , X (S) i be a sequence of S independent copies of the random variable fi obtained by sampling from the distribution πβi , and let X̄i = S−1 ∑S j=1X (j) i be the sample mean. We have EX̄i = Efi = ρi, and VarX̄i = S−1Varfi. The final estimator ρ = Z(θ|x)−1 is the random variable X = ∏l i=1 X̄i with EX = ∏l i=1 ρi = ρ. Now, consider\nVarX (EX)2\n= l∏\ni=1\n( 1 +\nVarX̄i (EX̄i)2\n) − 1\n≤ ( 1 + exp( 2p )\nS\n)l − 1\n≤ exp\n( l exp( 2p )\nS\n) − 1\n≤ 2/64 ,\nif we choose S = d65 −2l exp(2/p)e (because exp(a/65) ≤ 1 + a/64 for 0 ≤ a ≤ 1). By applying\nChebyshev’s inequality to X, we get\nPr[(|X − ρ|) > ( /4)ρ] ≤ 16 2 VarX (EX)2 ≤ 1 4 ,\nand therefore, with probability at least 3/4, we have( 1−\n4\n) ρ ≤ X ≤ ( 1 +\n4\n) ρ .\nThus, with probability at least 3/4, the partition function Z(θ|x) = X−1 lies within the ratio (1± ) of ρ−1. Polynomial run time immediately follows from the assumption that we can sample exactly according to the distributions πβi in polynomial time.\nWe have shown how to approximate the partition function under the assumption that there exists an exact sampler2. In fact, it suffices to have only an exact uniform sampler. As we will see in Section 3, it is possible to obtain exact samples from distributions of interest other than uniform if there exists an exact uniform sampler."
    }, {
      "heading" : "2.3 Approximating the Gradient of the Log Partition Function",
      "text" : "The optimisation problem (1) is typically solved using gradient descent methods which involves gradientvector multiplications. We now describe how to approximate the gradient-vector multiplication with provable guarantees using concentration inequalities. Let z be a vector in Rn (where n is also the dimension of the feature space φ(x, y)) with bounded `2 norm, i.e., ||z|| ≤ G, where G is a constant. The gradientvector multiplication is given as\n〈∇θ lnZ(θ|x), z〉 = Ey∼p(y|x,θ)[〈φ(x, y), z〉] .\nWe use Hoeffding’s inequality to bound the deviation of 〈∇θ lnZ(θ|x), z〉 from its estimate 〈d(θ|x), z〉 on a finite sample of size S, where\nd(θ|x) = 1 S S∑ i=1 φ(x, yi) ,\nand the sample is drawn according to p(y|x, θ).\nNote that by Cauchy-Schwarz’s inequality, we have | 〈φ(x, yi), z〉 | ≤ RG, for all i ∈ [[S]]. Applying Hoeffding’s inequality, we then obtain the following exponential tail bound: Pr(| 〈∇θ lnZ(θ|x)− d(θ|x), z〉 | ≥ ) ≤ 2 exp ( − 2S 2R2G2 ) .\n2A similar result can be derived by relaxing the exact sampling assumption and is described in Appendix A."
    }, {
      "heading" : "3 Sampling Techniques",
      "text" : "We now focus on designing sampling algorithms. These algorithms are needed (i) to compute the partition function using the machinery introduced in the previous section, and (ii) to do inference, i.e., predict structures, using the learned model by solving the optimisation problem argmaxy∈Y p(y|x, θ) for any x ∈ X . Sampling algorithms can be used for optimisation using the Metropolis process (Jerrum & Sinclair, 1996) and other methods like simulated annealing for convex optimisation (Kalai & Vempala, 2006) (note that these methods come with provable guarantees and are not heuristics).\nThe main contribution of this section is a generic, ‘meta’ approach that can be used to sample structures from distributions of interest given that there exists a uniform sampler. We start with the design of a Markov chain based on Metropolis process (Metropolis et al., 1953) to sample according to exponential family distributions p(y|x, θ) under the assumption that there exists an exact uniform sampler for Y. Consider the following chain Meta: If the current state is y, then\n1. select the next state z uniformly at random, and 2. move to z with probability min ( 1, p(z|x,θ)p(y|x,θ) ) .\nWe now analyse the mixing time of this chain using coupling from the past technique (Propp & Wilson, 1996; Huber, 1998). Coupling from the past (CFTP) is a technique to obtain an exact sample from the stationary distribution of a Markov chain. The idea is to simulate Markov chains forward from times in the past, starting in all possible states, as a coupling process. If all the chains coalesce at time 0, then Propp and Wilson (1996) showed that the current sample has the stationary distribution.\nTo apply CFTP for Meta, we need to bound the expected number of steps T until all Markov chains are in the same state. For the chain Meta, this occurs as soon as we update all the states, i.e., if we run all the parallel chains with the same random bits, once they are in the same state, they will remain coalesced. This happens as soon as they all accept an update (to the same state z) in the same step. First observe that, using Cauchy-Schwarz and triangle inequalities, we have\n∀y, y′ ∈ Y : |〈φ(x, y)− φ(x, y′), θ〉| ≤ 2BR .\nThe probability of an update is given by\nmin y,y′\n[1, p(y|x, θ)/p(y′|x, θ)] ≥ exp(−2BR) .\nWe then have\nET ≤1× exp[−2BR]+ 2× (1− exp[−2BR])× exp[−2BR]+ 3× (1− exp[−2BR])2 × exp[−2BR] + · · ·\nBy using the identity ∑∞\ni=0 i × ai = a−1/(a−1 − 1)2 with a = (1 − exp[−2BR]), we get ET ≤ exp(2BR). We now state the main result of this section.\nTheorem 3.1 The Markov chain Meta can be used to obtain an exact sample according to the distribution π = p(y|x, θ) with expected running time that satisfies ET ≤ exp(2BR).\nNote that the running time of this algorithm is random. To ensure that the algorithm terminates with a probability at least (1− δ), it is required to run it for an additional factor of O(ln(1/δ)) time (Huber, 1998). In this way, we can use this algorithm in conjunction with the approximation algorithm for computing the partition function resulting in an FPRAS.\nThe implication of this result is that we only need to have an exact uniform sampler in order to obtain exact samples from the distributions πβi , for all i ∈ [[l]], needed to approximate the partition function (cf. Theorem 2.5). As we will see in the next section, designing an exact uniform sampler is possible for several combinatorial structures that are of importance in machine learning problems.\nWe end this section with a few remarks on the bound in Theorem 3.1 and its practical implications. At first glance, we may question the usefulness of this bound because the constantsB andR appear in the exponent. But note that we can always set R = 1 by normalising the features. Also, the bound on R (cf. Appendix C) could be loose in practice as observed recently by Do et al. (2009), and thus the value of R could be way below its upper bound √ ln |Y|/λ. We could then employ techniques similar to those described in (Do et al., 2009) to design optimisation strategies that work well in practice. Also, note that the problem is mitigated to a large extent by setting λ ≥ ln |Y| and R = 1.\nWhile in this work we focused on designing a ‘meta’ approach for sampling, we would like to emphasise that it is possible to derive improved mixing time bounds by considering each combinatorial structure individually. For instance, Randall (2003) analysed the mixing time of a Markov chain to sample from the vertices of a hypercube uniformly at random. It is fairly straightforward to extend this chain to sample according to distributions πβi and also to analyse its mixing time using the technique of canonical paths (Jerrum & Sinclair, 1996)."
    }, {
      "heading" : "4 Application Settings",
      "text" : "We describe three combinatorial structures with their corresponding application settings in machine learning. For each of these structures, we show how to obtain exact samples uniformly at random. Together with the ‘meta’ approach presented in the previous section, it is then possible to obtain exact samples of these structures from exponential family distributions considered in this work. Therefore, we have all the necessary ingredients to approximate the partition function.\nVertices of a hypercube: The set of vertices of a hypercube is used as the output space in multi-label classification problems (see, for example, Elisseeff and Weston (2001)). An exact sample can be obtained uniformly at random by generating a sequence (of length d, the number of labels) of bits where each bit is determined by tossing an unbiased coin.\nPermutations: The set of permutations is used as the output space in label ranking problems (see, for example, Dekel et al. (2003)). An exact sample can be obtained uniformly at random by generating a sequence (of length d, the number of labels) of integers where each integer is sampled uniformly from the set [[d]] without replacement.\nSubtrees of a tree: Let T = (V,E) denote a directed, rooted tree with root r. Let T ′ denote a subtree of T rooted at r. Sampling such rooted subtrees from a rooted tree finds applications in multi-category hierarchical classification problems as considered by Cesa-Bianchi et al. (2006) and Rousu et al. (2006). We now present a technique to generate exact samples of subtrees uniformly at random. The technique comprises of two steps. First, we show how to count the number of subtrees in a tree. Next, we show how to use this counting procedure to sample subtrees uniformly at random. The second step is accomplished along the lines of a well-known reduction from uniform sampling to exact/approximate counting (Jerrum et al., 1986).\nFirst, we consider the counting problem. Let v ∈ V be a vertex of T and denote its set of children by δ+(v). Let f(v) denote the number of subtrees rooted at v. Now, f can be computed by using the following recursion:\nf(r) = 1 + ∏\nc∈δ+(r)\nf(c) . (2)\nNext, we consider the sampling problem. Note that any subtree can be represented by a d-dimensional vector in {0, 1}d, where d = |V |. A näıve approach to generate samples uniformly at random would be the following: generate a sequence of d bits where each bit is determined by tossing an unbiased coin; accept this\nsequence if it is a subtree (which can be tested in polynomial time). Clearly, this sample has been generated uniformly at random from the set of all subtrees. Unfortunately, this näıve approach will fail if the number of acceptances (subtrees) form only a small fraction of the total number of sequences which is 2d, because the probability that we encounter a subtree may be very small. This problem can be rectified by a reduction from sampling to counting, which we describe in the sequel.\nWe will use the term prefix to denote a subtree T ′ included by another subtree T ′′, both rooted at r. Let L(T ′) denote the set of leaves of T ′. We will reuse the term prefix to also denote the corresponding bit representation of the induced subtree T ′. The number of subtrees with T ′ as prefix can be computed using the recursive formula (2) and is given (with a slight abuse of notation) by f(T ′) = ( ∏ v∈L(T ′) f(v)) − |L(T ′)|. Now, we can generate a sequence of d bits where each bit u with a prefix v is determined by tossing an biased coin with success probability f(u)/f(v) and is accepted only if it forms a tree with its prefix. The resulting sequence is an exact sample drawn uniformly at random from the set of all subtrees."
    }, {
      "heading" : "5 Conclusions and Future Work",
      "text" : "The primary focus of this work was to rigorously analyse structured prediction models using tools from MCMC theory. We designed algorithms for approximating the partition function and the gradient of the log partition function with provable guarantees. We also presented a simple Markov chain based on Metropolis process that can be used to sample according to exponential family distributions given that there exists an exact uniform sampler. While in the application settings considered in this work, we were able to design an exact uniform sampler, we note that this may not be feasible in general for all applications. In such cases, we can design a Markov chain to obtain approximate samples from distributions of interest and also bound its mixing time. This is possible using coupling technique. Indeed, we show how to obtain approximate samples given that there exists an exact uniform sampler and the analysis is given in Appendix B. We note that the coupling technique is much more amenable than the coupling from the past technique to the problem of obtaining approximate samples from a non-uniform distribution given only approximate uniform samples.\nIf we were to solve the optimisation problem (1) using iterative techniques like gradient descent, then we have to run Markov chain simulations for every training example in order to compute gradients in any iteration of\nthe optimisation routine. We therefore argue for using online convex optimisation techniques (Hazan et al., 2007; Shalev-Shwartz et al., 2007) as these would result in fast, scalable algorithms for structured prediction. Furthermore, it would be interesting to analyse the effects of our approximation guarantees on the regret bounds and convergence rates of online algorithms. Further application settings include correlation clustering (Bansal et al., 2004) which corresponds to sampling equivalence relations. This setting has attracted a lot of attention recently in machine learning problems (Finley & Joachims, 2005; Haider et al., 2007)."
    }, {
      "heading" : "A Approximating the Partition Function using Approximate Samples",
      "text" : "In Section 2.2, we designed an FPRAS for approximating the partition function under the assumption that there exists an exact sampler. We now consider the case where we only have approximate samples resulting from a truncated Markov chain.\nWe first begin with some definitions. Let Ω denote the state space of a Markov chain with stationary distribution π and transition probability matrix P . The mixing time of a Markov chain is a measure of the time taken by the chain to converge to its stationary distribution. It is measured by the total variation distance between the distribution at time t and the stationary distribution.\nDefinition A.1 Let P t(u, v) denote the t-step probability of transition from u to v. The total variation distance at time t is\n||P t, π||tv = max u∈Ω 1 2 ∑ v∈Ω |P t(u, v)− π(u)| .\nDefinition A.2 For > 0, the mixing time τ( ) is given by\nτ( ) = min{t : ||P t ′ , π||tv ≤ , ∀ t′ ≥ t} .\nA Markov chain is rapidly mixing if the mixing time is bounded by a polynomial in the input and ln −1.\nWe are now ready to state the main result of this section.\nTheorem A.1 Suppose the sample size S = d65 −2l exp(2/p)e and suppose the simulation length Ti is large enough that the variation distance of the Markov chain from its stationary distribution πβi is at most /(5l exp(2/p)). Under the assumption that the chain is rapidly mixing, there\nexists an FPRAS with as the error parameter for computing the partition function.\nProof The proof again uses techniques described in (Jerrum & Sinclair, 1996). The bound Varfi/(Efi)2 ≤ exp(2/p) (from Proposition 2.3) w.r.t. the random variable fi will play a central role in the proof. We cannot use this bound per se to prove approximation guarantees for the partition function Z(θ|x). This is due to the fact that the random variable fi is defined w.r.t. the distribution πβi , but our samples are drawn from a distribution π̂βi resulting from a truncated Markov chain, whose variation distance satisfies |π̂βi − πβi | ≤ /5l exp(2/p). Therefore, we need to obtain a bound on Varf̂i/(Ef̂i)2, w.r.t. the random variable f̂i defined analogously to fi with samples drawn from the distribution π̂βi . An interesting observation is the fact that Lemma (2.4) still holds for ρ̂i, i.e., exp(1/p)− 1 ≤ ρ̂i ≤ exp(−1/p) + 1, for all integers p ≥ 3, and using similar analysis that followed Lemma (2.4), we get Varf̂i/(Ef̂i)2 ≤ exp(2/p), ∀ i ∈ [[l]].\nAlso, note that |π̂βi − πβi | ≤ /5l exp(2/p) implies |ρ̂i − ρi| ≤ /5l exp(1/p) (using the fact that exp(−1/p) ≤ ρi ≤ exp(1/p)). Therefore,\n(1− 5l )ρi ≤ ρ̂i ≤ (1 + 5l )ρi . (3)\nEquipped with these results, we are ready to compute the sample size S needed to obtain the desired approximation guarantee in the FPRAS. Let X(1)i , · · · , X (S) i be a sequence of S independent copies of the random variable f̂i obtained by sampling from the distribution π̂βi , and let X̄i = S −1∑S j=1X (j) i be the sample mean. We have EX̄i = Ef̂i = ρ̂i, and VarX̄i = S−1Varf̂i. The final estimator ρ̂ = Z(θ|x)−1 is the random variable X = ∏l i=1 X̄i with EX = ∏l i=1 ρ̂i = ρ̂. From (3), we have (1−\n4 )ρ ≤ ρ̂ ≤ (1 + 4 )ρ . (4)\nNow, consider\nVarX (EX)2\n= l∏\ni=1\n(1 + VarX̄i (EX̄i)2 )− 1\n≤ ( 1 + exp( 2p )\nS\n)l − 1\n≤ exp\n( l exp( 2p )\nS\n) − 1\n≤ 2/64 ,\nif we choose S = d65 −2l exp(2/p)e (because exp(a/65) ≤ 1 + a/64 for 0 ≤ a ≤ 1). By applying\nChebyshev’s inequality to X, we get\nPr[(|X − ρ̂|) > ( /4)ρ̂] ≤ 16 2 VarX (EX)2 ≤ 1 4 ,\nand therefore, with probability at least 3/4, we have\n(1− 4 )ρ̂ ≤ X ≤ (1 + 4 )ρ̂ .\nCombining the above result with (4), we see that with probability at least 3/4, the partition function Z(θ|x) = X−1 lies within the ratio (1 ± ) of ρ−1. Polynomial run time follows from the assumption that the Markov chain is rapidy mixing."
    }, {
      "heading" : "B Mixing Time Analysis of META using Coupling",
      "text" : "We will use the following lemma in our analysis.\nLemma B.1 (Aldous, 1983) (Coupling lemma) Suppose M is a countable, ergodic Markov chain. Let (P,Q) be a random process (the coupling). Suppose t : (0, 1]→ N is a function such that Pr(Pt( ) 6= Qt( )) ≤ , for all ∈ (0, 1], uniformly over the choice of initial state (P0, Q0). Then the mixing time τ( ) of M is bounded from above by t( ).\nTheorem B.2 The mixing time of Meta is bounded from above as follows:\nd(ln −1)/ ln(1− exp(−2BR))−1e .\nProof Using Cauchy-Schwarz and triangle inequalities, we have\n∀y, y′ ∈ Y : |〈φ(x, y)− φ(x, y′), θ〉| ≤ 2BR .\nThe probability of an update is\nmin y,y′\n[1, p(y|x, θ)/p(y′|x, θ)] ≥ exp(−2BR) .\nThe probability of not updating for T steps is therefore less than (1− exp(−2BR))T . Let\nt( ) = d(ln −1)/ ln(1− exp(−2BR))−1e .\nWe now only need to show that Pr(Pt( ) 6= Qt( )) = . Consider\nPr(Pt( ) 6= Qt( )) ≤ (1− exp(−2BR))(ln )/ ln(1−exp(−2BR))\n= exp[ln(1− exp(−2BR) + − 1 + exp(−2BR))] = .\nThe bound follows immediately from the Coupling Lemma (B.1)."
    }, {
      "heading" : "C Bounds on the Norm of the",
      "text" : "Parameter Vector\nWe derive a useful bound on the norm of the parameter vector θ. Let F (θ) = − ln p(θ, Y |X). Consider the optimisation problem (1) for MAP estimation:\nθ̂ = argmin θ F (θ)\n= argmin θ\n[ λ‖θ‖2 + 1\nm m∑ i=1 [lnZ(θ|xi)− 〈φ(xi, yi), θ〉]\n] .\nProposition C.1 The norm of the optimal parameter vector θ̂ is bounded from above as follows:\n||θ̂|| ≤ √\nln |Y| λ .\nProof Consider any (x, y) ∈ X × Y. Denote by `(θ, x, y) the loss function, where `(θ, x, y) = lnZ(θ|x)− 〈φ(x, y), θ〉 ≥ 0, and note that `(0, x, y) = ln |Y|. Therefore, the true regularised risk w.r.t. θ̂ and an underlying joint distribution D on X × Y is\nE(x,y)∼D[`(θ̂, x, y)] + λ||θ̂||22 ≤ F (0) = ln |Y| .\nThis implies that the optimal solution θ̂ of the above optimisation problem lies in the set {θ : ||θ|| ≤ √ ln |Y|/λ}."
    } ],
    "references" : [ {
      "title" : "Random walks on finite groups and rapidly mixing markov chains",
      "author" : [ "D. Aldous" ],
      "venue" : "Séminaire de probabilités de Strasbourg, 17, 243–297.",
      "citeRegEx" : "Aldous,? 1983",
      "shortCiteRegEx" : "Aldous",
      "year" : 1983
    }, {
      "title" : "An introduction to mcmc for machine learning",
      "author" : [ "C. Andrieu", "N. de Freitas", "A. Doucet", "M.I. Jordan" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Andrieu et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Andrieu et al\\.",
      "year" : 2003
    }, {
      "title" : "Incremental algorithms for hierarchical classification",
      "author" : [ "N. Cesa-Bianchi", "C. Gentile", "L. Zaniboni" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2006
    }, {
      "title" : "Loglinear models for label ranking",
      "author" : [ "O. Dekel", "C.D. Manning", "Y. Singer" ],
      "venue" : null,
      "citeRegEx" : "Dekel et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Dekel et al\\.",
      "year" : 2003
    }, {
      "title" : "Proximal regularization for online and batch learning",
      "author" : [ "C.B. Do", "Q.V. Le", "Foo", "C.-S" ],
      "venue" : "Proc. of ICML",
      "citeRegEx" : "Do et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Do et al\\.",
      "year" : 2009
    }, {
      "title" : "A kernel method for multi-labelled classification",
      "author" : [ "A. Elisseeff", "J. Weston" ],
      "venue" : null,
      "citeRegEx" : "Elisseeff and Weston,? \\Q2001\\E",
      "shortCiteRegEx" : "Elisseeff and Weston",
      "year" : 2001
    }, {
      "title" : "Supervised clustering with support vector machines",
      "author" : [ "T. Finley", "T. Joachims" ],
      "venue" : "Proc. of ICML",
      "citeRegEx" : "Finley and Joachims,? \\Q2005\\E",
      "shortCiteRegEx" : "Finley and Joachims",
      "year" : 2005
    }, {
      "title" : "Supervised clustering of streaming data for email batch detection",
      "author" : [ "P. Haider", "U. Brefeld", "T. Scheffer" ],
      "venue" : "Proc. of ICML",
      "citeRegEx" : "Haider et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Haider et al\\.",
      "year" : 2007
    }, {
      "title" : "Logarithmic regret algorithms for online convex optimization",
      "author" : [ "E. Hazan", "A. Agarwal", "S. Kale" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Hazan et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Hazan et al\\.",
      "year" : 2007
    }, {
      "title" : "Exact sampling and approximate counting techniques",
      "author" : [ "M. Huber" ],
      "venue" : "Proc. of STOC.",
      "citeRegEx" : "Huber,? 1998",
      "shortCiteRegEx" : "Huber",
      "year" : 1998
    }, {
      "title" : "The Markov chain Monte Carlo method: An approach to approximate counting and integration. In Hochbaum DS(ed) Approximation Algorithms for NP–hard Problems, 482–520",
      "author" : [ "M. Jerrum", "A. Sinclair" ],
      "venue" : "PWS Publishing,",
      "citeRegEx" : "Jerrum and Sinclair,? \\Q1996\\E",
      "shortCiteRegEx" : "Jerrum and Sinclair",
      "year" : 1996
    }, {
      "title" : "Random generation of combinatorial structures from a uniform distribution",
      "author" : [ "M.R. Jerrum", "L.G. Valiant", "V.V. Vazirani" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "Jerrum et al\\.,? \\Q1986\\E",
      "shortCiteRegEx" : "Jerrum et al\\.",
      "year" : 1986
    }, {
      "title" : "Simulated annealing for convex optimization",
      "author" : [ "A.T. Kalai", "S. Vempala" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "Kalai and Vempala,? \\Q2006\\E",
      "shortCiteRegEx" : "Kalai and Vempala",
      "year" : 2006
    }, {
      "title" : "Equation of state calculation by fast computing machines",
      "author" : [ "N. Metropolis", "A. Rosenbluth", "M. Rosenbluth", "A. Teller", "E. Teller" ],
      "venue" : "Journal of Chemical Physics,",
      "citeRegEx" : "Metropolis et al\\.,? \\Q1953\\E",
      "shortCiteRegEx" : "Metropolis et al\\.",
      "year" : 1953
    }, {
      "title" : "Exact sampling with coupled markov chains and applications to statistical mechanics",
      "author" : [ "J.G. Propp", "D.B. Wilson" ],
      "venue" : "Random Structures and Algorithms,",
      "citeRegEx" : "Propp and Wilson,? \\Q1996\\E",
      "shortCiteRegEx" : "Propp and Wilson",
      "year" : 1996
    }, {
      "title" : "Mixing",
      "author" : [ "D. Randall" ],
      "venue" : "Proc. of FOCS.",
      "citeRegEx" : "Randall,? 2003",
      "shortCiteRegEx" : "Randall",
      "year" : 2003
    }, {
      "title" : "Kernel-based learning of hierarchical multilabel classification models",
      "author" : [ "J. Rousu", "C. Saunders", "S. Szedmák", "J. Shawe-Taylor" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Rousu et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Rousu et al\\.",
      "year" : 2006
    }, {
      "title" : "Pegasos: Primal estimated sub-gradient solver for svm",
      "author" : [ "S. Shalev-Shwartz", "Y. Singer", "N. Srebro" ],
      "venue" : "Proc. of ICML",
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2007
    }, {
      "title" : "Adaptive simulated annealing: A near-optimal connection between sampling and counting",
      "author" : [ "D. Stefankovic", "S. Vempala", "E. Vigoda" ],
      "venue" : "Proc. of FOCS",
      "citeRegEx" : "Stefankovic et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Stefankovic et al\\.",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "These structures find applications in machine learning problems such as multi-label classification (Elisseeff & Weston, 2001), multi-category hierarchical classification (Cesa-Bianchi et al., 2006), and label ranking (Dekel et al.",
      "startOffset" : 170,
      "endOffset" : 197
    }, {
      "referenceID" : 3,
      "context" : ", 2006), and label ranking (Dekel et al., 2003).",
      "startOffset" : 27,
      "endOffset" : 47
    }, {
      "referenceID" : 14,
      "context" : "Recent developments include a set of mathematical tools for analysing the rates of convergence of Markov chains to equilibrium (see Randall (2003); Jerrum and Sinclair (1996) for surveys).",
      "startOffset" : 132,
      "endOffset" : 147
    }, {
      "referenceID" : 10,
      "context" : "Recent developments include a set of mathematical tools for analysing the rates of convergence of Markov chains to equilibrium (see Randall (2003); Jerrum and Sinclair (1996) for surveys).",
      "startOffset" : 148,
      "endOffset" : 175
    }, {
      "referenceID" : 1,
      "context" : "important research frontier (Andrieu et al., 2003) for MCMC based machine learning problems in general.",
      "startOffset" : 28,
      "endOffset" : 50
    }, {
      "referenceID" : 11,
      "context" : "We exploit the intimate connection between counting and sampling problems (Jerrum et al., 1986) to approximately compute the partition function using sampling algorithms.",
      "startOffset" : 74,
      "endOffset" : 95
    }, {
      "referenceID" : 18,
      "context" : "We use the following cooling schedule (Stefankovic et al., 2007): l = pdR||θ||e; βj = j/(pR‖θ‖) for all j ∈ [[l − 1]], where p is a constant integer ≥ 3, i.",
      "startOffset" : 38,
      "endOffset" : 64
    }, {
      "referenceID" : 13,
      "context" : "We start with the design of a Markov chain based on Metropolis process (Metropolis et al., 1953) to sample according to exponential family distributions p(y|x, θ) under the assumption that there exists an exact uniform sampler for Y.",
      "startOffset" : 71,
      "endOffset" : 96
    }, {
      "referenceID" : 9,
      "context" : "We now analyse the mixing time of this chain using coupling from the past technique (Propp & Wilson, 1996; Huber, 1998).",
      "startOffset" : 84,
      "endOffset" : 119
    }, {
      "referenceID" : 9,
      "context" : "We now analyse the mixing time of this chain using coupling from the past technique (Propp & Wilson, 1996; Huber, 1998). Coupling from the past (CFTP) is a technique to obtain an exact sample from the stationary distribution of a Markov chain. The idea is to simulate Markov chains forward from times in the past, starting in all possible states, as a coupling process. If all the chains coalesce at time 0, then Propp and Wilson (1996) showed that the current sample has the stationary distribution.",
      "startOffset" : 107,
      "endOffset" : 437
    }, {
      "referenceID" : 9,
      "context" : "To ensure that the algorithm terminates with a probability at least (1− δ), it is required to run it for an additional factor of O(ln(1/δ)) time (Huber, 1998).",
      "startOffset" : 145,
      "endOffset" : 158
    }, {
      "referenceID" : 4,
      "context" : "We could then employ techniques similar to those described in (Do et al., 2009) to design optimisation strategies that work well in practice.",
      "startOffset" : 62,
      "endOffset" : 79
    }, {
      "referenceID" : 4,
      "context" : "Appendix C) could be loose in practice as observed recently by Do et al. (2009), and thus the value of R could be way below its upper bound √ ln |Y|/λ.",
      "startOffset" : 63,
      "endOffset" : 80
    }, {
      "referenceID" : 15,
      "context" : "For instance, Randall (2003) analysed the mixing time of a Markov chain to sample from the vertices of a hypercube uniformly at random.",
      "startOffset" : 14,
      "endOffset" : 29
    }, {
      "referenceID" : 5,
      "context" : "Vertices of a hypercube: The set of vertices of a hypercube is used as the output space in multi-label classification problems (see, for example, Elisseeff and Weston (2001)).",
      "startOffset" : 146,
      "endOffset" : 174
    }, {
      "referenceID" : 3,
      "context" : "Permutations: The set of permutations is used as the output space in label ranking problems (see, for example, Dekel et al. (2003)).",
      "startOffset" : 111,
      "endOffset" : 131
    }, {
      "referenceID" : 11,
      "context" : "The second step is accomplished along the lines of a well-known reduction from uniform sampling to exact/approximate counting (Jerrum et al., 1986).",
      "startOffset" : 126,
      "endOffset" : 147
    }, {
      "referenceID" : 2,
      "context" : "Sampling such rooted subtrees from a rooted tree finds applications in multi-category hierarchical classification problems as considered by Cesa-Bianchi et al. (2006) and Rousu et al.",
      "startOffset" : 140,
      "endOffset" : 167
    }, {
      "referenceID" : 2,
      "context" : "Sampling such rooted subtrees from a rooted tree finds applications in multi-category hierarchical classification problems as considered by Cesa-Bianchi et al. (2006) and Rousu et al. (2006). We now present a technique to generate exact samples of subtrees uniformly at random.",
      "startOffset" : 140,
      "endOffset" : 191
    }, {
      "referenceID" : 8,
      "context" : "We therefore argue for using online convex optimisation techniques (Hazan et al., 2007; Shalev-Shwartz et al., 2007) as these would result in fast, scalable algorithms for structured prediction.",
      "startOffset" : 67,
      "endOffset" : 116
    }, {
      "referenceID" : 17,
      "context" : "We therefore argue for using online convex optimisation techniques (Hazan et al., 2007; Shalev-Shwartz et al., 2007) as these would result in fast, scalable algorithms for structured prediction.",
      "startOffset" : 67,
      "endOffset" : 116
    }, {
      "referenceID" : 7,
      "context" : "This setting has attracted a lot of attention recently in machine learning problems (Finley & Joachims, 2005; Haider et al., 2007).",
      "startOffset" : 84,
      "endOffset" : 130
    }, {
      "referenceID" : 0,
      "context" : "1 (Aldous, 1983) (Coupling lemma) Suppose M is a countable, ergodic Markov chain.",
      "startOffset" : 2,
      "endOffset" : 16
    } ],
    "year" : 2009,
    "abstractText" : "We consider MAP estimators for structured prediction with exponential family models. In particular, we concentrate on the case that efficient algorithms for uniform sampling from the output space exist. We show that under this assumption (i) exact computation of the partition function remains a hard problem, and (ii) the partition function and the gradient of the log partition function can be approximated efficiently. Our main result is an approximation scheme for the partition function based on Markov Chain Monte Carlo theory. We also show that the efficient uniform sampling assumption holds in several application settings that are of importance in machine learning.",
    "creator" : "TeX"
  }
}