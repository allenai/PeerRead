{
  "name" : "1301.3859.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Building a Stochastic Dynamic Model of Application Use",
    "authors" : [ ],
    "emails" : [ "pgorniak@cs.", "poole@cs.ubc.ca" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Many intelligent user interfaces employ applica tion and user models to determine the user's pref erences, goals and likely future actions. Such models require application analysis, adaptation and expansion. Building and maintaining such models adds a substantial amount of time and\nlabour to the application development cycle. We present a system that observes the interface of an unmodified application and records users' inter actions with the application. From a history of such observations we build a coarse state space of observed interface states and actions between them. To refine the space, we hypothesize sub states based upon the histories that led users to a given state. We evaluate the information gain of possible state splits, varying the length of the histories considered in such splits. In this way, we automatically produce a stochastic dynamic model of the application and of how it is used. To evaluate our approach, we present models de rived from real-world application usage data.\n1 Introduction\nArtificial Intelligence supplies a vast set of tools to be ap plied to the design of intelligent user interfaces. While our previous research (Gorniak 1998) as well as countless other projects sample indulgently from this set and often produce quite impressive results in their own environments (for example, see (Horvitz, Breese, Heckerman, Hovel and\nRommelse 1998) and (Albrecht, Zukerman, Nicholson and Bud 1997),) there emerge some new challenges when one attempts to apply these results to a new application.\n1. The research results often do not transfer easily to a new application.\n2. The actual implementation used in the research re lies upon a modified application. This modification\nis usually non-trivial, time-consuming to repeat and increases application complexity.\n3. Researchers work from various, often hand-crafted application models. In addition to the application building work in 2, an application designer needs to specify such a model. This process is often not straightforward and may rely on empirical data from\nuser trials. An application designer's primary task does not include designing such a model, and thus the task seems an added difficulty to him or her. Also, the model needs to be updated and will tend to lag behind the application during maintenance.\nWe are currently addressing these problems by investigat ing how much knowledge can be extracted from a user's interaction with an application without any prior informa tion about the application's purpose or structure and with out any modifications to the application (somewhat in the spirit of (Lieberman 1998).) We hypothesize that enough knowledge can be extracted to yield a detailed model of the application and its user. This model can then serve both as a knowledge source for other algorithms as well as provide a context under which to unite methods. Specifically, we endeavour to construct a detailed state space together with a stochastic policy for the user's behaviour and in this way describe the application structure and the user traversing it. An intelligent user interface, for example a help system, can access information about the user's context and goals from our model, and thus tailor its presentation to the user's needs. Most importantly, we set out to construct this model without modifying the application and without running ex plicit user trials. In fact, the system we present works as a wrapper to the Java runtime environment and is able to model the use of any Java application run on the system without customization of either the application or our sys tem.\nSome other application independent user models build no application model at all, and thus do not provide any automatic analysis of the application. They perform worse in cases where such application knowledge boosts\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 231\nperformance, such as future action prediction (Davison and Hirsh 1998). Others stop early on in their analysis and subsequently rely on application specific knowledge (Encarnacao 1997). We are not aware of other work that attempts to identify the current state of application and user without any knowledge or modification of the application. Related in the model building area is the next action predic tion work for web precaching by Zukerman, Albrecht and Nicholson (1999). They work with combinations of sim ple Markov models and based on request counts and do not identify the system's state in more detail. Our goal is also akin to some work in the areas of data mining and specif ically clustering. For example, Cadez, Heckerman, Meek, Smyth and White (2000) cluster users based on their web page request patterns for visualization purposes, but they do not build a detailed stochastic dynamic model like ours.\nLet us view the user as an agent. Our assumption is that we can and have observed this agent acting in an environment, namely using an application. Artificial Intelligence con cerns itself with agents acting in environments and worries about what decisions such agents should make. A common approach to such a problem consists of phrasing it in terms of states and actions between states and coming up with a policy that, perhaps stochastically, dictates which actions to take in which states (Boutilier, Dean and Hanks 1999). We are faced with the opposite problem: we see an agent acting in an environment and want to model the agent's decision process. We assume that the agent acts according to a pol icy. Each action is the result of some (possibly stochastic) function of what the agent observes and the agent's belief state. Our goal is to determine this policy and the state space to which it applies.\nPreviously, we have shown this approach to perform ex ceedingly well in predicting future user actions (Gorniak and Poole 2000). In that research we identified the user's state implicitly by finding the longest sequences in ob served history that match the actions the user just per formed, similar to (McCallum 1996). We ranked possible future actions according to the lengths of these matches. Our goal in the research presented here is to explicitly iden tify the states of user and application. This results in a detailed model of how one or many people are using the application. Such a model can help application designers analyse their applications and augment them with intelli gent extensions. For example, it is easy to learn about user behaviour and find unexpected consequences of a design decision. Or, in building an intelligent help system, the de signer can query our system for the user's current state and context, as well as our prediction for the user's future ac tions and then tailor the help to that scenario. Note that while we lean on some techniques from classification algo rithms, we are not dealing with a standard machine learning problem here. Our emphasis lies on a humanly readable and usable model. Therefore, we cannot offer a numeri-\ncal performance measure of how well our system performs its task. Instead, we illustrate that the model we infer for real application usage data provides a useful foundation for application analysis and extension.\nIn Section 2 we describe the motivation behind our state identification algorithm and compare it to its implicit sib ling, ONISI (On-Line Implicit State Identification (Gorniak and Poole 2000)). Section 3 describes the Java implemen tation of the work presented here. This implementation works as a wrapper to existing Java applications and is able to record their interfaces states as well as user actions with out modifications to the original application. Section 4 dis cusses the performance of this algorithm on real user data from an example application and analyses the resulting ap plication model. Finally, Section 5 concludes and points to future work.\n2 Explicit State Identification Algorithm\nOur implementation (see Section 3) supplies us with a record of observations of the application's interface states and the user's actions that lead from one observed interface state to another. That is, our recorded history consists of sequences of state observation/user action pairs. The ob served states are often very coarse in that they are nowhere close to fulfilling the Markov assumption. Users tend to take very different courses of actions from them according to different goals. Overall, our approach to automatically deriving a refined state space (as with ONISI in (Gorniak and Poole 2000)) consists of identifying behavioural pat terns that the user engages in and that predict future user actions well. However, to predict the next user action ON lSI was given the history sequence that just occurred and it proceeded to find long matches to it in recorded history, un der the (correct) assumption that users normally continue such patterns in identical ways. OFESI (Off-line Explicit State Identification), the algorithm discussed here, has a different goal. Rather than striving to predict the next ac tion accurately, its purpose is to identify meaningful states that explain overall user behaviour. As a consequence, ON lSI considers a single long match of a behavioural pattern an important predictor, but OFESI needs to group identified patterns into sets that delimit distinct user states.\nThis state refinement problem can be viewed as a classi fication task: given the occurrences of a state in recorded history, the action sequences that precede them, and the ac tions that follow them, how should we group the sequences such that the groups give us as much information as pos sible about what action will occur after the state? This problem sounds much akin to the problem of picking an attribute to split on in building a decision tree using ID3 (Quinlan 1986). However, the natural attributes to use in splitting a state are the action sequences preceding it. These attributes are many-valued, producing a split into a large\n232 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nnumber of substates. Instead, we would like to split the state into as many states 'as make sense', that is, as are use ful in capturing possible user intentions when reaching the observed interface state. We need to dynamically construct attributes with fewer values to predict substates.\nWe choose for OFESI to perform hierarchical binary splits of a state according to how much information such a split yields about the actions taken from it, and according to how many instances of such actions the new substates explain. Grouping the preceding action sequences in such a way supplies us with a new attribute with values that identify relevant substates well.\nFigure 1 depicts the schema OFESI employs in splitting a state. We initially consider all distinct fixed length history sequences that have preceded an interface state in recorded history. In the following discussion, a state is a set of such sequences together with the observed interface state they lead to. The length of these sequences is an input to the algorithm. We discuss the choice of length in Section 4. History also supplies us with a distribution over next ac tions that users chose in the state. In fact, each preceding action sequence carries such a distribution, their sum being the state's action distribution. We now split the set of pre ceding history sequences into two. For the resulting sets,\nwe sum the next action distributions of their constituent members to arrive at two distributions for the newly cre ated substates. In tum, we may choose to split the new substates again in a hierarchical fashion. There is likely to be some redundancy amongst the resulting sets. For exam ple, if all preceding sequences that end in the same action are grouped into one of the substates, that single action is enough to identify all these sequences. Thus, OFESI's last step examines the sequence sets for such redundancies and replaces groups of sequences with a shorter sequence wher ever possible.\nThe main question now is: how can we split the set of pre ceding fixed length sequences into two, such that the result ing sets convey as much information as possible about the next action? Just as in building a decision tree, we evalu ate possible sets according to their information gain. For a set of history sequences defining a state s the information needed to fully predict the next action if there are n actions possible overall is\nn\nI(s) = - L P8(a;) log Ps(a;) i=l\nwhere P8(a;) is the probability with which action i occurs in states, i.e. the number of times the action occurs in this state in history divided by the number of times the state occurs in history (Shannon and Weaver 1949).\nA new subset s1 of s leaves us with a remaining informa tion need of\nn\nR(sl) =- LPs,(aj)1ogP81(aj), j=l\nfor that part of the original state, so the split of s into sl and s2 yields an information gain of\nwhere P(si) is the probability with which the predictions grouped into substate s 1 occur. We need to split the set of action sequences into two subsets such that this value is maximized.\nWe use a form of stochastic local search to optimize infor mation gain of the subset split (Hoos 1998). Specifically, we initialize the search by splitting the history sequences leading to the interface state into two random subsets. Each search step moves exactly one sequence from one set to the other. To perform a step we pick the move that increases in formation gain the most with probability p and pick a ran dom move with probability 1 - p. We only move attributes that have not been moved for at least k steps, and reset the search process if information gain has not improved for m search steps. We discuss the parameter settings for this search in Section 4.4.\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 233\n//States are represented by sets of //action sequences leading to single //interface states. Given settings for Amin, Gmin, sequenceLength; OFESI () {\nFor each interface state s { Let resultingStates = {}; Find all actionSequences of\nlength sequenceLength that precede s;\nCall OFESI-split-state( actionSequences, resultingStates); Replace s by substates found in resultingStates;\nOFESI-split-state(actionSequences, resultingStates) {\nLet {gain, substatel, substate2} OFESI-binary-split( actionSequences); If gain > Gmin\nAND the number of actions predicted by each of statel and state2 is greater than Amin Call OFESI-split-state(statel, resultingStates); Call OFESI-split-state(state2, resultingStates) ; else { Append actionSequences to\nresultingStates;\nFigure 2: The OFESI Algorithm\nOFESI accepts the best split if it yields an information gain of at least Gmin and if for each set the sum of the action instances that set predicts is at least A min. This restricts splits to those that still yield a reasonable amount of infor mation about the actions taken from a state and avoids splits that do yield information, but create substates that explain an insignificant amount of actions. Both parameters can not be optimized in any objective sense, but rather depend on one's goals in using OFESI. We discuss their impact in Section 4.3.\nUpon a successful split, OFESI now considers each sub state as the new state to be split and continues splitting in this hierarchical fashion as long as each split fulfills the Gmin and Amin restrictions. Figures 2 and 3 outline\nGiven settings for searchSteps, p, k, m; OFESI-binary-split(actionSequences) Randomly split actionSequences into\nstatel, state2; Let gain = G(actionSequences, statel, state2); Let bestGain = gain; Let stagnantCount = 0; Let bestSplit = {statel, state2} For searchSteps number of times {\nWith probability p { Move action a that maximises\ngain improvement when moved between sets and hasn't been moved for k steps;\nelse { Move random action a;\nLet gain = G(actionSequences, statel, state2); If gain > bestGain { Let bestGain = gain; Let bestSplit = {statel,\nstate2}; Let stagnantCount = 0;\nelse { stagnantCount++;\nif(stagnantCount > m) Randomly split\nactionSequences into statel, state2;\nreturn {bestGain, bestSplit};\nJava's reflective capabilities and dynamic loading strategy make the language a prime candidate for an application in dependent approach (JDK 1998). It allows not only inspec tion of a structure of known visual components, but it can also inspect unknown components for state information. Java and JavaBeans introduced standard naming conven tions for object methods. For example, isVisibleO returns the visibility status of visual components, whereas getEn abledO returns whether they are currently useable. Com ponents derived from standard Abstract Window Toolkit\n234 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\ncomponents inherit these methods automatically, and other components should define them. Java's Reflection mech anism, on the other hand, allows one to check whether a given object includes one of these state-revealing methods, and lets one call this method without knowing the object's class. Finally, Java's dynamic loading of classes rids the de veloper of needing to link with or even know about classes that will be present at runtime. Using these tools, one can establish the user interface state of an application built us ing Java at runtime by dynamically linking into its code, examining the methods available in its objects and calling the methods relevant to the interface state. This process requires no modification of the targeted application at all.\nThe system used for the experiments presented below runs as a wrapper to a Java application. Before it starts the appli cation, it hooks itself into the application's event queue and thus sees all event activity within the Java Abstract Window Toolkit and components derived from it. It intercepts each such event that it considers an action (such as a button be ing pressed or a window closed) and records the observed state of the application's interface before and after the event occurs. In this way, this system establishes a state space of interface observations as a person uses the application and records a history consisting of actions and visited states at the same time.\nThe applications 1 under consideration here are educational AI applications. They were written to help undergraduate university students learn concepts in Artificial Intelligence. One application familiarizes the student with search prob lems and algorithms, the second deals with constraint sat isfaction problems and the third demonstrates backpropa gation neural network learning. In each, the student has the option to either load an example problem or to create his or her own problem by drawing a graph. He or she can then switch to a problem solution mode and step through the various algorithms at different levels of detail. The students used these applications to solve homework prob lems for an introductory AI course they were taking. Most of the assignment questions referred to a supplied exam ple problem, so the students tended to explore the problem creation facilities of the applications less than their solving functionality. The following discussion and results focus mainly on the application for search algorithms.\n4 Results and Discussion\nThere exists no obvious user-independent performance measure for the system presented here. Its usefulness de pends on the goals of the person employing the system, be it to debug an existing application, to design additional ap plication components or to simply perform a study of appli cation usage. We have evaluated the implicit version of our\n1The applications can be http://www.cs.ubc.ca/labsllci/Clspace/.\nfound at\nstate identification approach to predict future user actions in (Gorniak and Poole 2000) and we are currently work ing to apply the explicit version presented here to another problem that can benefit from explicit state identification, namely that of deriving structure for Hidden Markov Mod els (Rabiner 1989). In the following sections, we present the model OFESI derives for the search application and ar gue that it captures significant features of user behaviour.\n4.1 Observed State Space\nFigure 4 shows the state space of interface states our sys tem observes from users of the search algorithm applica tion. The figure represents the space exactly as recorded, except for that we have given the states meaningful names. Reflecting the division of the application into two modes, problem creation and problem solution mode, the graph exhibits two distinct components. The right hand compo nent corresponds to problem solution mode, whereas the left hand one corresponds to problem creation mode. The students were mainly using the application to solve prob lems that were given to them, so we recorded significantly more data for problem solution mode. The following dis cussion therefore focusses on the right hand subcomponent of Figure 4.\nIn this component, we see two distinct ways of examining search algorithms using this application. Students can ei ther step through a problem using a search algorithm, or they can show the result of the algorithm given the prob lem. At most times they can reset the search, which trans ports them back to the Problem Solution start state. Dur ing stepping, they can still ask to be shown the result at any time. Show Result and Goal Node Reached are the states in which dialog boxes are shown. We can distin guish two versions of these states, one in which the stu dent has stepped previously, and one in which the student asked to see the result directly from the Problem Solution state. While this graph is interesting, it tells us little about whether a student will choose to step or examine the re sult in Problem Solution state. We now demonstrate how OFESI splits states to give us exactly that information.\n4.2 State Splitting Results\nFirst, let us examine the state Stepping and how OFESI splits it. Table 1 lists the original next action distribution of this state.\nWe see that there are three main actions users choose from this state: They either step, fine step, or reset the search. Intuitively, we would like to split the state into three sub states, each predicted by an appropriate set of history se quences leading to it. Tables 2 and 3 show a substate OFESI suggests when considering history sequences of length one by giving the action sequences predicting the state and the action distribution in the state, respectively.\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 235\nFigure 4: Original Interface States Observed in Search Application\nThis substate is a result of the initial binary split of Step ping OFESI performs, which splits the state into one sub state predominantly predicting the Step action and another predicting the Fine Step action.\nThis substate makes sense, judging from the intuition be hind the action sequences that predict it (a user that stepped before is likely to step again), and from the next action dis tribution that is dominated by the Step action. This sub state will not be split again, but OFESI does split its dual substate in a hierarchical call into substates that predict the Fine Step action and the Reset Search action (it is predicted by the last state having been Goal Node Reached after Stepping.) As run here, with Gmin = 0.15, Amin = 10 and an action sequence length of one, OFESI suggests ex actly three states. We do not include the details for the other two substates for space reasons.\nThe choice of action sequence length constitutes a trade off between computational and explanatory complexity on the one hand and explanatory power on the other hand. That is, short action sequences (say, of length one) are easy to\nread and there are few of them, whereas there tend to be exponentially more sequences with each additional action considered. More longer sequences allow us to split the state at least as well, and usually better, than few shorter sequences, but due to their number the splitting process is computational more expensive and the resulting substates are hard to interpret based on the action sequences (they are still often easily interpretable from the actions they pre dict.) At the same time, overfitting may occur with longer action sequences in the sense that patterns peculiar to the training history may be used to identify substates.\nTable 4 shows the action distribution for the substate pre dicting the Step action as derived by OFESI run with se quence length four. It is clear that the split is cleaner -\nthere are no more Fine Step actions predicted by this state, and more Step actions predicted. We refrain from including the unwieldy set of action sequences that predicts this state.\nUpon examining this set we find that in essence OFESI was able to take into account features like that if the last action was Step, but the three before that were Fine Step, the user is likely to choose Fine Step next.\n4.3 Refined State Space\nFigure 5 shows the state space after running OFESI on the right hand component of state space shown in Figure 4. States are labelled by their original name followed by the most frequently occurring action in their next action distri\nbution if they are sub states of the originally observed inter face states. OFESI was run with Grnin = 0.15, Arnin = 10 and an action sequence length of 5. These parameters can be set differently according to one's goal in running OFESI. Generally, lower settings of G rnin will produce more states, but states at lower levels of the hierarchical split will tend not to contribute much to distinguishing between possible next actions. Lower settings of Arnin will also produce more states, but these states will tend to distinguish ac tions that occur less often. First, notice the three substates\nof the Stepping state as discussed in Section 4.2. In the same fashion, OFESI splits Problem Solution into four substates, according to whether the user is likely to Step or Fine Step through the problem, to ask to be shown the result or to reset the search. The last of these Problem So lution/ActionEvent on Reset Search is an artifact of the user interface design. The problem solution process is in its initial state if the user is in Problem Solution state, but\nusers ask for the process to be reset both after just having reset it and after switching search strategies or search op tions (as obvious from the action sequences OFESI attaches to the new substate.) Clearly, it is due to a flaw in the in terface that users engage in this behaviour. In general, the state space shown in Figure 5 presents much more detailed model of application use, and its states yield far more pre dictive power than the originally observed coarse interface states.\n4.4 Information Gain Optimization\nAs mentioned before, we employ stochastic local search to optimize information gain when splitting a state into two substates. The complexity of this search largely depends on the length of the action sequences considered. With sequences of length one, there are only few items to be grouped and most parameter settings find the optimal so lution quickly. With longer sequence the number of items in the groups tends to grow exponentially, and the search quickly becomes more complex. However, we found that\nwith sequences of length five the search rarely find better solutions after more than 500 steps. In addition, the im provements in later steps tend to be much smaller than in earlier ones and we do not necessarily care to find the op timal split as long as we find a very good one, so running the search to 500 steps, with a probability of random steps of 0.1 and restarting after the solution has not improved af ter 80 steps proved sufficient for our purposes. We do not\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 237\nclaim that these are in any way the optimal parameters, but they appear to work well enough in practise.\n5 Conclusion and Future Work\nWe have presented a system that observes user actions and application interface states from an unmodified applica tion. It deduces a coarse state space that the user is travers ing from this observed history and a stochastic policy that describes the user's behaviour. Together, these form a stochastic dynamic model of application use. Each inter face observed state has an associated next action distribu tion that potentially includes high frequencies for several actions. To enhance the model, we use OFESI to split states in a hierarchical fashion by optimizing the informa tion gain on the original next action distribution that such a split yields. We have shown this algorithm to split states recorded in user trials into substates of good predictive power. These substates form a new, more informative state space of the use of the application, and supply us with a more decisive policy.\nWhile the state spaces derived by OFESI are those one would wish for, we intend to prove the usefulness of our automatic application and user modeling strategy by aug menting one of our applications with a component that uses the model's information. We also intend to build an appli cation design and analysis tool that uses OFESI to produce a state space of an existing application and helps the appli cation designer in evaluating past design decisions based upon real application usage. In addition, an application de signer could add information to the state space, for example by giving states names or by grouping states into contexts, and could then interface to an API we provide to access information about the current state and context as well as future contexts and goals of the user.\nFinally, there is another area of research that could take advantage of a general way to infer meaningful states from a sequence of observations: Hidden Markov Mod els (Rabiner 1989). We are currently investigating whether OFESI as presented here can help in finding the optimal number of states for a Hidden Markov Model and give hints as to which observations each state should account for and where in the model it belongs.\nReferences\nAlbrecht, D. W., Zukerman, 1., Nicholson, A. E. and Bud, A.: 1997, Towards a bayesian model for keyhole plan recognition in large domains, User Modeling: Proceedings of the Sixth International Conference,\nUM97.\nBoutilier, C., Dean, T. and Hanks, S.: 1999, Decision theoretic planning: Structural assumptions and com-\nputational leverage, Journal of AI Research 11, 1-94.\nCadez, 1., Heckerman, D., Meek, C., Smyth, P. and White, S.: 2000, Visualization of navigation patterns on a web site using model based clustering, Technical Re port MSR-T R-00-18, Unversity of California, Irvine.\nDavison, B. D. and Hirsh, H.: 1998, Predicting sequences of user actions, Technical report, Rutgers, The State University of New York.\nEncarnacao, L.: 1997, Concept and Realization of intel ligent user support in interactive graphics applica tions, PhD thesis, Eberhard-Karls-Universitat Tiibin gen, Fakultiit fiir Informatik.\nGorniak, P. J.: 1998, Sorting email messages by topic. Project Report.\nGorniak, P. J. and Poole, D.: 2000, Predicting future us er actions by observing unmodified applications, Pro ceedings of the 17th National Conference on Artificial\nIntelligence, AAAI-2000.\nHoos, H. H.: 1998, Stochastic Local Search - Method, Models and Applications, PhD thesis, Technische Universitat Darmstadt.\nHorvitz, E., Breese, J., Heckerman, D., Hovel, D. and Rommelse, K.: 1998, The lumiere project: Bayesian user modeling for inferring the goals and needs of software users, Uncertainty in Artifical Intelligence, Proceedings of the Fourteenth Conference.\nJDK: 1998, Java Development Kit Documentation. URL: http:/ ljava.sun. com/products/jdk/1.1 /docs/\nLieberman, H.: 1998, Integrating user interface agents with conventional applications, Proceedings of the Inter national Conference on Intelligent User Interfaces, San Francisco.\nMcCallum, A. R.: 1996, Instance-based state identification for reinforcement learning, Technical report, Univer sity of Rochester.\nQuinlan, J.: 1986, Induction of decision trees, Machine Learning 1, 81-106.\nRabiner, L.: 1989, A tutorial on hidden markov models and selected applications in speech recognition, Proceed ings of the IEEE, Vol. 77(2).\nShannon, C. and Weaver, W.: 1949, The Mathematical The ory of Communication, University of Illionois Press, Urbana.\nZukerman, 1., Albrecht, D. and Nicholson, A.: 1999, Pre dicting users' requests on the www, User Model ing: Proceedings of the 7th International Conference, UM99."
    } ],
    "references" : [ {
      "title" : "Towards a bayesian model for keyhole plan recognition",
      "author" : [ "D.W. Albrecht", "Zukerman", "A.E. Nicholson", "A. Bud" ],
      "venue" : null,
      "citeRegEx" : "Albrecht et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Albrecht et al\\.",
      "year" : 1997
    }, {
      "title" : "Decision­ theoretic planning: Structural assumptions and",
      "author" : [ "C. Boutilier", "T. Dean", "S. Hanks" ],
      "venue" : null,
      "citeRegEx" : "Boutilier et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Boutilier et al\\.",
      "year" : 1999
    }, {
      "title" : "Predicting sequences of user actions, Technical report, Rutgers, The State University of New York",
      "author" : [ "B.D. Davison", "H. Hirsh" ],
      "venue" : null,
      "citeRegEx" : "Davison and Hirsh,? \\Q1998\\E",
      "shortCiteRegEx" : "Davison and Hirsh",
      "year" : 1998
    }, {
      "title" : "Concept and Realization of intel­",
      "author" : [ "L. Encarnacao" ],
      "venue" : null,
      "citeRegEx" : "Encarnacao,? \\Q1997\\E",
      "shortCiteRegEx" : "Encarnacao",
      "year" : 1997
    }, {
      "title" : "Sorting email messages by topic. Project Report",
      "author" : [ "P.J. Gorniak" ],
      "venue" : null,
      "citeRegEx" : "Gorniak,? \\Q1998\\E",
      "shortCiteRegEx" : "Gorniak",
      "year" : 1998
    }, {
      "title" : "Predicting future us­ er actions by observing unmodified",
      "author" : [ "P.J. Gorniak", "D. Poole" ],
      "venue" : null,
      "citeRegEx" : "Gorniak and Poole,? \\Q2000\\E",
      "shortCiteRegEx" : "Gorniak and Poole",
      "year" : 2000
    }, {
      "title" : "Stochastic Local Search - Method, Models and Applications, PhD thesis",
      "author" : [ "H.H. Hoos" ],
      "venue" : null,
      "citeRegEx" : "Hoos,? \\Q1998\\E",
      "shortCiteRegEx" : "Hoos",
      "year" : 1998
    }, {
      "title" : "The lumiere project: Bayesian user modeling for inferring the goals and needs of software",
      "author" : [ "E. Horvitz", "J. Breese", "D. Heckerman", "D. Hovel", "K. Rommelse" ],
      "venue" : null,
      "citeRegEx" : "Horvitz et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Horvitz et al\\.",
      "year" : 1998
    }, {
      "title" : "Integrating user interface agents with conventional applications",
      "author" : [ "H. Lieberman" ],
      "venue" : "Proceedings of the Inter­ national Conference on Intelligent User Interfaces, San Francisco",
      "citeRegEx" : "Lieberman,? \\Q1998\\E",
      "shortCiteRegEx" : "Lieberman",
      "year" : 1998
    }, {
      "title" : "Instance-based state identification for reinforcement learning, Technical report, Univer­ sity of Rochester",
      "author" : [ "A.R. McCallum" ],
      "venue" : null,
      "citeRegEx" : "McCallum,? \\Q1996\\E",
      "shortCiteRegEx" : "McCallum",
      "year" : 1996
    }, {
      "title" : "Induction of decision trees",
      "author" : [ "J. Quinlan" ],
      "venue" : "Machine Learning",
      "citeRegEx" : "Quinlan,? \\Q1986\\E",
      "shortCiteRegEx" : "Quinlan",
      "year" : 1986
    }, {
      "title" : "A tutorial on hidden markov models and selected applications in speech recognition",
      "author" : [ "L. Rabiner" ],
      "venue" : "Proceed­ ings of the IEEE,",
      "citeRegEx" : "Rabiner,? \\Q1989\\E",
      "shortCiteRegEx" : "Rabiner",
      "year" : 1989
    }, {
      "title" : "The Mathematical The­ ory of Communication, University of Illionois Press, Urbana",
      "author" : [ "C. Shannon", "W. Weaver" ],
      "venue" : null,
      "citeRegEx" : "Shannon and Weaver,? \\Q1949\\E",
      "shortCiteRegEx" : "Shannon and Weaver",
      "year" : 1949
    }, {
      "title" : "Pre­ dicting users' requests on the www",
      "author" : [ "Zukerman", "D. Albrecht", "A. Nicholson" ],
      "venue" : "User Model­ ing: Proceedings of the 7th International Conference,",
      "citeRegEx" : "Zukerman et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Zukerman et al\\.",
      "year" : 1999
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "While our previous research (Gorniak 1998) as well as countless other projects sample indulgently from this set and often",
      "startOffset" : 28,
      "endOffset" : 42
    }, {
      "referenceID" : 8,
      "context" : "spirit of (Lieberman 1998).",
      "startOffset" : 10,
      "endOffset" : 26
    }, {
      "referenceID" : 2,
      "context" : "performance, such as future action prediction (Davison and Hirsh 1998).",
      "startOffset" : 46,
      "endOffset" : 70
    }, {
      "referenceID" : 3,
      "context" : "Others stop early on in their analysis and subsequently rely on application specific knowledge (Encarnacao 1997).",
      "startOffset" : 95,
      "endOffset" : 112
    }, {
      "referenceID" : 2,
      "context" : "performance, such as future action prediction (Davison and Hirsh 1998). Others stop early on in their analysis and subsequently rely on application specific knowledge (Encarnacao 1997). We are not aware of other work that attempts to identify the current state of application and user without any knowledge or modification of the application. Related in the model building area is the next action predic­ tion work for web precaching by Zukerman, Albrecht and Nicholson (1999). They work with combinations of sim­ ple Markov models and based on request counts and do not identify the system's state in more detail.",
      "startOffset" : 47,
      "endOffset" : 477
    }, {
      "referenceID" : 2,
      "context" : "performance, such as future action prediction (Davison and Hirsh 1998). Others stop early on in their analysis and subsequently rely on application specific knowledge (Encarnacao 1997). We are not aware of other work that attempts to identify the current state of application and user without any knowledge or modification of the application. Related in the model building area is the next action predic­ tion work for web precaching by Zukerman, Albrecht and Nicholson (1999). They work with combinations of sim­ ple Markov models and based on request counts and do not identify the system's state in more detail. Our goal is also akin to some work in the areas of data mining and specif­ ically clustering. For example, Cadez, Heckerman, Meek, Smyth and White (2000) cluster users based on their web page request patterns for visualization purposes, but they do not build a detailed stochastic dynamic model like ours.",
      "startOffset" : 47,
      "endOffset" : 769
    }, {
      "referenceID" : 5,
      "context" : "Previously, we have shown this approach to perform ex­ ceedingly well in predicting future user actions (Gorniak and Poole 2000).",
      "startOffset" : 104,
      "endOffset" : 128
    }, {
      "referenceID" : 9,
      "context" : "In that research we identified the user's state implicitly by finding the longest sequences in ob­ served history that match the actions the user just per­ formed, similar to (McCallum 1996).",
      "startOffset" : 175,
      "endOffset" : 190
    }, {
      "referenceID" : 5,
      "context" : "In Section 2 we describe the motivation behind our state identification algorithm and compare it to its implicit sib­ ling, ONISI (On-Line Implicit State Identification (Gorniak and Poole 2000)).",
      "startOffset" : 169,
      "endOffset" : 193
    }, {
      "referenceID" : 5,
      "context" : "Overall, our approach to automatically deriving a refined state space (as with ONISI in (Gorniak and Poole 2000)) consists of identifying behavioural pat­ terns that the user engages in and that predict future user actions well.",
      "startOffset" : 88,
      "endOffset" : 112
    }, {
      "referenceID" : 10,
      "context" : "This state refinement problem can be viewed as a classi­ fication task: given the occurrences of a state in recorded history, the action sequences that precede them, and the ac­ tions that follow them, how should we group the sequences such that the groups give us as much information as pos­ sible about what action will occur after the state? This problem sounds much akin to the problem of picking an attribute to split on in building a decision tree using ID3 (Quinlan 1986).",
      "startOffset" : 464,
      "endOffset" : 478
    }, {
      "referenceID" : 12,
      "context" : "the number of times the action occurs in this state in history divided by the number of times the state occurs in history (Shannon and Weaver 1949).",
      "startOffset" : 122,
      "endOffset" : 147
    }, {
      "referenceID" : 6,
      "context" : "We use a form of stochastic local search to optimize infor­ mation gain of the subset split (Hoos 1998).",
      "startOffset" : 92,
      "endOffset" : 103
    }, {
      "referenceID" : 5,
      "context" : "found at state identification approach to predict future user actions in (Gorniak and Poole 2000) and we are currently work­ ing to apply the explicit version presented here to another problem that can benefit from explicit state identification, namely that of deriving structure for Hidden Markov Mod­ els (Rabiner 1989).",
      "startOffset" : 73,
      "endOffset" : 97
    }, {
      "referenceID" : 11,
      "context" : "found at state identification approach to predict future user actions in (Gorniak and Poole 2000) and we are currently work­ ing to apply the explicit version presented here to another problem that can benefit from explicit state identification, namely that of deriving structure for Hidden Markov Mod­ els (Rabiner 1989).",
      "startOffset" : 307,
      "endOffset" : 321
    }, {
      "referenceID" : 11,
      "context" : "Finally, there is another area of research that could take advantage of a general way to infer meaningful states from a sequence of observations: Hidden Markov Mod­ els (Rabiner 1989).",
      "startOffset" : 169,
      "endOffset" : 183
    } ],
    "year" : 2011,
    "abstractText" : "Many intelligent user interfaces employ applica­ tion and user models to determine the user's pref­ erences, goals and likely future actions. Such models require application analysis, adaptation and expansion. Building and maintaining such models adds a substantial amount of time and labour to the application development cycle. We present a system that observes the interface of an unmodified application and records users' inter­ actions with the application. From a history of such observations we build a coarse state space of observed interface states and actions between them. To refine the space, we hypothesize sub­ states based upon the histories that led users to a given state. We evaluate the information gain of possible state splits, varying the length of the histories considered in such splits. In this way, we automatically produce a stochastic dynamic model of the application and of how it is used. To evaluate our approach, we present models de­ rived from real-world application usage data.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}