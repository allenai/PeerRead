{
  "name" : "1610.07432.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Luana Bulat", "Anita L. Verő", "Stephen Clark" ],
    "emails" : [ "dkiela@fb.com", "ltf24@cam.ac.uk", "alv34@cam.ac.uk", "sc609@cam.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n61 0.\n07 43\n2v 1\n[ cs\n.A I]\n2 4\nO ct\n2 01\n6\nVirtual Embodiment: A Scalable Long-Term Strategy for Artificial Intelligence Research\nDouwe Kiela Facebook AI Research\nNew York, NY 10017, USA dkiela@fb.com\nLuana Bulat, Anita L. Verő, Stephen Clark Computer Laboratory, University of Cambridge\nCambridge CB3 0FD, UK {ltf24,alv34,sc609}@cam.ac.uk"
    }, {
      "heading" : "1 Introduction",
      "text" : "Meaning has been called the “holy grail” of a variety of scientific disciplines, ranging from linguistics to philosophy, psychology and the neurosciences [1]. The field of Artifical Intelligence (AI) is very much a part of that list: the development of sophisticated natural language semantics is a sine qua non for achieving a level of intelligence comparable to humans. Embodiment theories in cognitive science hold that human semantic representation depends on sensori-motor experience [2]; the abundant evidence that human meaning representation is grounded in the perception of physical reality leads to the conclusion that meaning must depend on a fusion of multiple (perceptual) modalities [3]. Despite this, AI research in general, and its subdisciplines such as computational linguistics and computer vision in particular, have focused primarily on tasks that involve a single modality. Here, we propose virtual embodiment as an alternative, long-term strategy for AI research that is multi-modal in nature and that allows for the kind of scalability required to develop the field coherently and incrementally, in an ethically responsible fashion.\nEmbodiment theory implies that the best way for acquiring human-level semantics is to have machines learn through (physical) experience: if we want to teach a system the true meaning of “bumping into a wall”, we simply have to have it bump into walls repeatedly. Although this scenario shares similarities with human language acquisition, it is not (yet) a viable route: our current machine learning paradigms do not allow for the required rate of learning to make such a scenario feasible. With modern day state-of-the-art deep learning systems requiring millions of samples to solve highly specific tasks that are trivial to humans, it is reasonable to speculate that it would take much longer than a human lifespan for a physically embodied agent to develop extensive linguistic capabilities, with current technology. We conjecture that such limitations apply to a much lesser extent to an agent that is virtually embodied.\nBy virtual embodiment we mean to say that agents may collectively or individually acquire semantics by being embodied in a virtual, rather than a physical, world. Concretely, rather than having a physical robot learn to understand the world by physically bumping into physical walls, we would have virtual agents bump into virtual walls in a virtual world. Such virtual embodiment offers several key advantages:\n1. Scalability and incremental development: The complexity of virtual worlds can develop in conjunction, i.e., scale, with the capabilities of artificial agents. This allows for a stepwise development towards general machine intelligence, rather than aiming for the end-goal without a concrete understanding of the challenges or consequences we will face when attempting to reach that end-goal.\n2. Long-term feasibility: The performance ceiling of any agent is a function of the complexity of the virtual environment. Virtual worlds may initially not be overly complex, but they can grow in complexity as technology develops. This allows for a focused long-term research strategy that is feasible now, but will remain challenging in years and decades to come.\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\n3. Rapid iteration: The fact that artificial agents are constrained by arbitrary parameters means that development can happen rapidly and iteratively, through agents learning from interacting both with humans and with each other. Rather than the extremes of either having one system solve small uni-modal tasks, or instead trying to solve the whole problem in a single attempt, we can improve iteratively, in an agile fashion, at great speed.\n4. No requirement for continuous human involvement: Although interaction is necessary for embodied learning, virtual interactions need not require human involvement at each step, but may rather happen between agents themselves. This unburdens humans by foregoing the need for a constant supervised signal, as is currently often seen in machine learning applications, which also facilitates rapid development.\n5. Ethical testability: Importantly, since artificial agents are exposed to a constrained environment, virtual worlds provide the ultimate testing ground for carefully fleshing out important ethical considerations in relation to artificial intelligence [4], without any potentially damaging immediate consequences in the physical world.\nFor these reasons, we propose virtual embodiment as one of the best and most feasible strategies for instigating a stepwise development towards artificial general intelligence. In particular, we advocate the development and use of “video games with a purpose” to facilitate virtual embodiment. In what follows, we briefly outline some of the background that led to this proposal, explain why video games are suitable for the current purposes and list the desiderata for virtual embodiment-compatible video games to facilitate research in artificial intelligence."
    }, {
      "heading" : "2 Grounding Semantics in Virtual Perception",
      "text" : "A fundamental problem of semantics is the grounding problem [5], which concerns the circularity in defining the meaning of a symbol through other symbols. In the context of Searle’s famous Chinese Room argument [6], it can be phrased as: is it possible to learn Chinese from nothing but a (very sophisticated) Chinese dictionary? Modern representation learning approaches, including the word embeddings that have become popular in natural language processing, are exponents of the distributional hypothesis [7], which stipulates that you “shall know the meaning of a word through the company that it keeps” [8]. In other words, semantic representation learning defines symbols through other symbols, which exposes it to the grounding problem. In contrast, there is abundant evidence that human meaning representation is grounded in physical reality and sensorimotor experience [9, 10, 11, 12, 13].\nMotivated by these theoretical considerations, the field of multi-modal semantics aims to ground semantic representations by introducing extra-linguistic, perceptual input into semantic models. Multimodal semantic models lead to practical improvements in a variety of natural language processing tasks, ranging from resolving linguistic ambiguity [14] to metaphor detection [15]. Beyond vision, there has also been work aimed towards auditory [16, 17] and even olfactory [18] grounding. However, most current multi-modal semantic models suffer from two important limitations. First, images and to a lesser extent sound files lack the element of time, whereas temporal and sequential input are central aspects of language understanding. Second, these approaches lack any interaction, which plays an important role in language acquisition: children learn basic language understanding by interacting with the environment, and build more intricate “reflective reasoning” on top of that foundation [19].\nThere has been work in linguistic grounding that allows for temporal aspects, for instance in videos [20, 21, 22], and both time and interaction, notably in the field of robotics [23, 24, 25]. However, robotics does not currently constitute a suitable platform for language learning, since physical embodiment is not yet feasible. Virtual embodiment does not suffer from the same limitations. There has been recent work on grounding in virtual worlds, notably in video games [26]. Work applying deep reinforcement learning to video games points the way towards agents learning from each other [27, 28, 29]. An alternative would be virtual or augmented reality, which offers the benefit of joint multi-modal data over time, but this crucially lacks the element of interaction.\nOur position is very much aligned with recent proposals for new directions in AI research [30, 31, 32, 33]. The particular problem of language features in these proposals to a varying extent, but we take it to be a core piece of any path toward artificial general intelligence, in line with recent attempts\nto make machines genuinely understand human language [34, 35]. We specifically advocate multiagent video games “with a purpose” [36], rather than alternative virtual worlds that lack gamification, since they provide interesting platforms for humans to engage with for extended periods of time, without the explicit purpose of teaching machines to achieve a certain task."
    }, {
      "heading" : "3 Desiderata",
      "text" : "It is worthwhile outlining the properties that video games might have if they are to be suitable platforms for developing AI through virtual embodiment. For that purpose, we propose a hierarchy1 of the types of embodied manifestations an agent might have in a world. The same type hierarchy applies both to physical and to virtual worlds:\n• Type 0: Agents perform basic first-order interactions with the world, with full or limited access to the objective world state. No intra-agent communication is required.\n• Type 1: As above, but without any state access. Communication may be used for sharing knowledge about the state of the world.\n• Type 2: As above, but with higher-order interactions, i.e., with an element of planning, strategy and non-monotonic reasoning. Communication is essential for sharing knowledge about the world.\n• Type 3: The world should be strictly non-deterministic and multi-modal. This makes communication essential for not only sharing knowledge about the world, but also for sharing plans and strategies.\n• Type 4: Agents should be multi-objective, that is, an agent’s objective or reward function should be a weighted function of various objectives or rewards, that depend both on the state of the world and current plans and strategy.\n• Type 5: Multi-objective agents interact with and communicate about a non-deterministic world in such a way that it allows for them to plan ahead and form and execute sophisticated strategies.\nThe final type of embodiment corresponds to what biological agents are capable of performing in the physical world. It is much too large a leap for current technologies to achieve, but the benefit of virtual embodiment is that we can grow the complexity of the world together with the sophistication of artificial agents, which makes virtual embodiment suitable for being AI’s next frontier. The real world is enormously complex, and performing common sense reasoning in such a complicated environment has long been one of AI’s classic problems in the shape of the frame problem [38]. The frame problem is a function of the world’s complexity, which makes it more manageable for virtual embodiment.\nMost recent work has not extended beyond Type 1 embodiment, which means that the field has a long way to go. Specifically in the context of video games, we believe that development can proceed more rapidly if they are of mixed agency, meaning that both humans and artificial systems control agents in the virtual world; and carefully designed as a level playing field with a human bias, such that human agents have a slight upper hand, which means that e.g. the superior memory of machines should not affect in-game performance and that machines can learn from humans. To our knowledge no video game currently exists that satisfies these properties and which facilitates Type 5 embodiment."
    }, {
      "heading" : "4 Conclusion",
      "text" : "We propose virtual embodiment, through video games, as a scalable long-term strategy for artificial intelligence research. Embodiment is essential for developing human-level natural language semantics, which we take to be a core aspect of artificial intelligence. Virtual embodiment allows for growing the complexity of virtual worlds in line with the sophistication of artificial agents, which makes it a suitable testing ground for artificial intelligence, in an ethically responsible manner.\n1Inspired by the Kardashev scale for the sophistication of civilizations [37]."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This research was enabled by the European Research Council PoC grant GROUNDFORCE."
    } ],
    "references" : [ {
      "title" : "Foundations of Language",
      "author" : [ "R. Jackendoff" ],
      "venue" : "Oxford University Press, Oxford",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "The role of sensory and motor information in semantic representation: A review",
      "author" : [ "Lotte Meteyard", "Gabriella Vigliocco" ],
      "venue" : "Handbook of cognitive science: An embodied approach,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2008
    }, {
      "title" : "Ethical issues in advanced artificial intelligence. Science Fiction and Philosophy: From Time Travel to Superintelligence",
      "author" : [ "Nick Bostrom" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2003
    }, {
      "title" : "The symbol grounding problem",
      "author" : [ "Stevan Harnad" ],
      "venue" : "Physica D,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1990
    }, {
      "title" : "Minds, brains and programs",
      "author" : [ "John R. Searle" ],
      "venue" : "Behavioral and Brain Sciences,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1980
    }, {
      "title" : "Distributional Structure",
      "author" : [ "Z. Harris" ],
      "venue" : "Word, 10(23):146—162",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1954
    }, {
      "title" : "A synopsis of linguistic theory",
      "author" : [ "John R. Firth" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1957
    }, {
      "title" : "Object properties and knowledge in early lexical learning",
      "author" : [ "Susan S Jones", "Linda B Smith", "Barbara Landau" ],
      "venue" : "Child development,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1991
    }, {
      "title" : "Perceptions of perceptual symbols",
      "author" : [ "Lawrence W Barsalou" ],
      "venue" : "Behavioral and brain sciences,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1999
    }, {
      "title" : "Grounding language in action",
      "author" : [ "Arthur M Glenberg", "Michael P Kaschak" ],
      "venue" : "Psychonomic bulletin & review,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2002
    }, {
      "title" : "Symbol interdependency in symbolic and embodied cognition",
      "author" : [ "Max M. Louwerse" ],
      "venue" : "Topics in Cognitive Science,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2008
    }, {
      "title" : "Situating abstract concepts. In Grounding cognition: The role of perception and action in memory, language, and thought, pages",
      "author" : [ "Lawrence W. Barsalou", "Katja Wiemer-Hastings" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2005
    }, {
      "title" : "Do You See What I Mean? Visual Resolution of Linguistic Ambiguities",
      "author" : [ "Yevgeni Berzak", "Andrei Barbu", "Daniel Harari", "Boris Katz", "Shimon Ullman" ],
      "venue" : "In Proceedings of EMNLP",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2015
    }, {
      "title" : "Black holes and white rabbits: Metaphor identification with visual features",
      "author" : [ "Ekaterina Shutova", "Douwe Kiela", "Jean Maillard" ],
      "venue" : "In Proceedings of NAACL-HTL 2016,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2016
    }, {
      "title" : "Sound-based distributional models",
      "author" : [ "A. Lopopolo", "E. van Miltenburg" ],
      "venue" : "In Proceedings of the 11th International Conference on Computational Semantics (IWCS 2015),",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2015
    }, {
      "title" : "Multi- and cross-modal semantics beyond vision: Grounding in auditory perception",
      "author" : [ "Douwe Kiela", "Stephen Clark" ],
      "venue" : "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2015
    }, {
      "title" : "Grounding semantics in olfactory perception",
      "author" : [ "Douwe Kiela", "Luana Bulat", "Stephen Clark" ],
      "venue" : "In Proceedings of ACL,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2015
    }, {
      "title" : "Object perception and object naming in early development",
      "author" : [ "Barbara Landau", "Linda Smith", "Susan Jones" ],
      "venue" : "Trends in cognitive sciences,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1998
    }, {
      "title" : "Understanding videos, constructing plots learning a visually grounded storyline model from annotated videos",
      "author" : [ "Arpan Gupta", "Praveen Srinivasan", "Jianbo Shi", "Larry S Davis" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2009
    }, {
      "title" : "Grounding action descriptions in videos",
      "author" : [ "Michaela Regneri", "Marcus Rohrbach", "Dominikus Wetzel", "Stefan Thater", "Bernt Schiele", "Manfred Pinkal" ],
      "venue" : "Transactions of the Association for Computational Linguistics,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2013
    }, {
      "title" : "A compositional framework for grounding language inference, generation, and acquisition in video",
      "author" : [ "Haonan Yu", "N. Siddharth", "Andrei Barbu", "Jeffrey Mark Siskind" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2015
    }, {
      "title" : "Grounding vision through experimental manipulation",
      "author" : [ "Paul Fitzpatrick", "Giorgio Metta" ],
      "venue" : "Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2003
    }, {
      "title" : "A short review of symbol grounding in robotic and intelligent systems",
      "author" : [ "Silvia Coradeschi", "Amy Loutfi", "Britta Wrede" ],
      "venue" : "KI-Künstliche Intelligenz,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2013
    }, {
      "title" : "Natural language communication with robots",
      "author" : [ "Jonathan Bisk", "Deniz Yuret", "Daniel Marcu" ],
      "venue" : "In Proceedings of NAACL,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2016
    }, {
      "title" : "Language understanding for textbased games using deep reinforcement learning",
      "author" : [ "Karthik Narasimhan", "Tejas D Kulkarni", "Regina Barzilay" ],
      "venue" : "In Proceedings of EMNLP,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2015
    }, {
      "title" : "Human-level control through deep reinforcement learning",
      "author" : [ "Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski" ],
      "venue" : "Nature, 518(7540):529–533,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2015
    }, {
      "title" : "Mastering the game of go with deep neural networks and tree",
      "author" : [ "David Silver", "Aja Huang", "Chris J Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot" ],
      "venue" : "search. Nature,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2016
    }, {
      "title" : "Towards multi-agent communication-based language learning",
      "author" : [ "Angeliki Lazaridou", "Nghia The Pham", "Marco Baroni" ],
      "venue" : null,
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2016
    }, {
      "title" : "A roadmap towards machine intelligence",
      "author" : [ "Tomas Mikolov", "Armand Joulin", "Marco Baroni" ],
      "venue" : "arXiv preprint arXiv:1511.08130,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2015
    }, {
      "title" : "Mazebase: A sandbox for learning from games",
      "author" : [ "Sainbayar Sukhbaatar", "Arthur Szlam", "Gabriel Synnaeve", "Soumith Chintala", "Rob Fergus" ],
      "venue" : "arXiv preprint arXiv:1511.07401,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2015
    }, {
      "title" : "Towards ai-complete question answering: A set of prerequisite toy tasks",
      "author" : [ "Jason Weston", "Antoine Bordes", "Sumit Chopra", "Alexander M Rush", "Bart van Merriënboer", "Armand Joulin", "Tomas Mikolov" ],
      "venue" : "arXiv preprint arXiv:1502.05698,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2015
    }, {
      "title" : "The malmo platform for artificial intelligence experimentation",
      "author" : [ "Matthew Johnson", "Katja Hofmann", "Tim Hutton", "David Bignell" ],
      "venue" : "In International joint conference on artificial intelligence (IJCAI),",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2016
    }, {
      "title" : "Teaching machines to read and comprehend",
      "author" : [ "Karl Moritz Hermann", "Tomas Kocisky", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2015
    }, {
      "title" : "Learning language games through interaction",
      "author" : [ "Sida I. Wang", "Percy Liang", "Christopher D. Manning" ],
      "venue" : "In Proceedings of ACL 2016,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2016
    }, {
      "title" : "Labeling images with a computer game",
      "author" : [ "Luis von Ahn", "Laura Dabbish" ],
      "venue" : "In CHI,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2004
    }, {
      "title" : "Kardashev. Transmission of information by extraterrestrial civilizations",
      "author" : [ "S Nikolai" ],
      "venue" : "Soviet Astronomy,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 1964
    }, {
      "title" : "Some philosophical problems from the standpoint of artificial intelligence",
      "author" : [ "John McCarthy", "Patrick J Hayes" ],
      "venue" : "Readings in artificial intelligence,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 1969
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Meaning has been called the “holy grail” of a variety of scientific disciplines, ranging from linguistics to philosophy, psychology and the neurosciences [1].",
      "startOffset" : 154,
      "endOffset" : 157
    }, {
      "referenceID" : 1,
      "context" : "Embodiment theories in cognitive science hold that human semantic representation depends on sensori-motor experience [2]; the abundant evidence that human meaning representation is grounded in the perception of physical reality leads to the conclusion that meaning must depend on a fusion of multiple (perceptual) modalities [3].",
      "startOffset" : 325,
      "endOffset" : 328
    }, {
      "referenceID" : 2,
      "context" : "Ethical testability: Importantly, since artificial agents are exposed to a constrained environment, virtual worlds provide the ultimate testing ground for carefully fleshing out important ethical considerations in relation to artificial intelligence [4], without any potentially damaging immediate consequences in the physical world.",
      "startOffset" : 250,
      "endOffset" : 253
    }, {
      "referenceID" : 3,
      "context" : "A fundamental problem of semantics is the grounding problem [5], which concerns the circularity in defining the meaning of a symbol through other symbols.",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 4,
      "context" : "In the context of Searle’s famous Chinese Room argument [6], it can be phrased as: is it possible to learn Chinese from nothing but a (very sophisticated) Chinese dictionary? Modern representation learning approaches, including the word embeddings that have become popular in natural language processing, are exponents of the distributional hypothesis [7], which stipulates that you “shall know the meaning of a word through the company that it keeps” [8].",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 5,
      "context" : "In the context of Searle’s famous Chinese Room argument [6], it can be phrased as: is it possible to learn Chinese from nothing but a (very sophisticated) Chinese dictionary? Modern representation learning approaches, including the word embeddings that have become popular in natural language processing, are exponents of the distributional hypothesis [7], which stipulates that you “shall know the meaning of a word through the company that it keeps” [8].",
      "startOffset" : 352,
      "endOffset" : 355
    }, {
      "referenceID" : 6,
      "context" : "In the context of Searle’s famous Chinese Room argument [6], it can be phrased as: is it possible to learn Chinese from nothing but a (very sophisticated) Chinese dictionary? Modern representation learning approaches, including the word embeddings that have become popular in natural language processing, are exponents of the distributional hypothesis [7], which stipulates that you “shall know the meaning of a word through the company that it keeps” [8].",
      "startOffset" : 452,
      "endOffset" : 455
    }, {
      "referenceID" : 7,
      "context" : "In contrast, there is abundant evidence that human meaning representation is grounded in physical reality and sensorimotor experience [9, 10, 11, 12, 13].",
      "startOffset" : 134,
      "endOffset" : 153
    }, {
      "referenceID" : 8,
      "context" : "In contrast, there is abundant evidence that human meaning representation is grounded in physical reality and sensorimotor experience [9, 10, 11, 12, 13].",
      "startOffset" : 134,
      "endOffset" : 153
    }, {
      "referenceID" : 9,
      "context" : "In contrast, there is abundant evidence that human meaning representation is grounded in physical reality and sensorimotor experience [9, 10, 11, 12, 13].",
      "startOffset" : 134,
      "endOffset" : 153
    }, {
      "referenceID" : 10,
      "context" : "In contrast, there is abundant evidence that human meaning representation is grounded in physical reality and sensorimotor experience [9, 10, 11, 12, 13].",
      "startOffset" : 134,
      "endOffset" : 153
    }, {
      "referenceID" : 11,
      "context" : "In contrast, there is abundant evidence that human meaning representation is grounded in physical reality and sensorimotor experience [9, 10, 11, 12, 13].",
      "startOffset" : 134,
      "endOffset" : 153
    }, {
      "referenceID" : 12,
      "context" : "Multimodal semantic models lead to practical improvements in a variety of natural language processing tasks, ranging from resolving linguistic ambiguity [14] to metaphor detection [15].",
      "startOffset" : 153,
      "endOffset" : 157
    }, {
      "referenceID" : 13,
      "context" : "Multimodal semantic models lead to practical improvements in a variety of natural language processing tasks, ranging from resolving linguistic ambiguity [14] to metaphor detection [15].",
      "startOffset" : 180,
      "endOffset" : 184
    }, {
      "referenceID" : 14,
      "context" : "Beyond vision, there has also been work aimed towards auditory [16, 17] and even olfactory [18] grounding.",
      "startOffset" : 63,
      "endOffset" : 71
    }, {
      "referenceID" : 15,
      "context" : "Beyond vision, there has also been work aimed towards auditory [16, 17] and even olfactory [18] grounding.",
      "startOffset" : 63,
      "endOffset" : 71
    }, {
      "referenceID" : 16,
      "context" : "Beyond vision, there has also been work aimed towards auditory [16, 17] and even olfactory [18] grounding.",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 17,
      "context" : "Second, these approaches lack any interaction, which plays an important role in language acquisition: children learn basic language understanding by interacting with the environment, and build more intricate “reflective reasoning” on top of that foundation [19].",
      "startOffset" : 257,
      "endOffset" : 261
    }, {
      "referenceID" : 18,
      "context" : "There has been work in linguistic grounding that allows for temporal aspects, for instance in videos [20, 21, 22], and both time and interaction, notably in the field of robotics [23, 24, 25].",
      "startOffset" : 101,
      "endOffset" : 113
    }, {
      "referenceID" : 19,
      "context" : "There has been work in linguistic grounding that allows for temporal aspects, for instance in videos [20, 21, 22], and both time and interaction, notably in the field of robotics [23, 24, 25].",
      "startOffset" : 101,
      "endOffset" : 113
    }, {
      "referenceID" : 20,
      "context" : "There has been work in linguistic grounding that allows for temporal aspects, for instance in videos [20, 21, 22], and both time and interaction, notably in the field of robotics [23, 24, 25].",
      "startOffset" : 101,
      "endOffset" : 113
    }, {
      "referenceID" : 21,
      "context" : "There has been work in linguistic grounding that allows for temporal aspects, for instance in videos [20, 21, 22], and both time and interaction, notably in the field of robotics [23, 24, 25].",
      "startOffset" : 179,
      "endOffset" : 191
    }, {
      "referenceID" : 22,
      "context" : "There has been work in linguistic grounding that allows for temporal aspects, for instance in videos [20, 21, 22], and both time and interaction, notably in the field of robotics [23, 24, 25].",
      "startOffset" : 179,
      "endOffset" : 191
    }, {
      "referenceID" : 23,
      "context" : "There has been work in linguistic grounding that allows for temporal aspects, for instance in videos [20, 21, 22], and both time and interaction, notably in the field of robotics [23, 24, 25].",
      "startOffset" : 179,
      "endOffset" : 191
    }, {
      "referenceID" : 24,
      "context" : "There has been recent work on grounding in virtual worlds, notably in video games [26].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 25,
      "context" : "Work applying deep reinforcement learning to video games points the way towards agents learning from each other [27, 28, 29].",
      "startOffset" : 112,
      "endOffset" : 124
    }, {
      "referenceID" : 26,
      "context" : "Work applying deep reinforcement learning to video games points the way towards agents learning from each other [27, 28, 29].",
      "startOffset" : 112,
      "endOffset" : 124
    }, {
      "referenceID" : 27,
      "context" : "Work applying deep reinforcement learning to video games points the way towards agents learning from each other [27, 28, 29].",
      "startOffset" : 112,
      "endOffset" : 124
    }, {
      "referenceID" : 28,
      "context" : "Our position is very much aligned with recent proposals for new directions in AI research [30, 31, 32, 33].",
      "startOffset" : 90,
      "endOffset" : 106
    }, {
      "referenceID" : 29,
      "context" : "Our position is very much aligned with recent proposals for new directions in AI research [30, 31, 32, 33].",
      "startOffset" : 90,
      "endOffset" : 106
    }, {
      "referenceID" : 30,
      "context" : "Our position is very much aligned with recent proposals for new directions in AI research [30, 31, 32, 33].",
      "startOffset" : 90,
      "endOffset" : 106
    }, {
      "referenceID" : 31,
      "context" : "Our position is very much aligned with recent proposals for new directions in AI research [30, 31, 32, 33].",
      "startOffset" : 90,
      "endOffset" : 106
    }, {
      "referenceID" : 32,
      "context" : "to make machines genuinely understand human language [34, 35].",
      "startOffset" : 53,
      "endOffset" : 61
    }, {
      "referenceID" : 33,
      "context" : "to make machines genuinely understand human language [34, 35].",
      "startOffset" : 53,
      "endOffset" : 61
    }, {
      "referenceID" : 34,
      "context" : "We specifically advocate multiagent video games “with a purpose” [36], rather than alternative virtual worlds that lack gamification, since they provide interesting platforms for humans to engage with for extended periods of time, without the explicit purpose of teaching machines to achieve a certain task.",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 36,
      "context" : "The real world is enormously complex, and performing common sense reasoning in such a complicated environment has long been one of AI’s classic problems in the shape of the frame problem [38].",
      "startOffset" : 187,
      "endOffset" : 191
    }, {
      "referenceID" : 35,
      "context" : "Inspired by the Kardashev scale for the sophistication of civilizations [37].",
      "startOffset" : 72,
      "endOffset" : 76
    } ],
    "year" : 2016,
    "abstractText" : "Meaning has been called the “holy grail” of a variety of scientific disciplines, ranging from linguistics to philosophy, psychology and the neurosciences [1]. The field of Artifical Intelligence (AI) is very much a part of that list: the development of sophisticated natural language semantics is a sine qua non for achieving a level of intelligence comparable to humans. Embodiment theories in cognitive science hold that human semantic representation depends on sensori-motor experience [2]; the abundant evidence that human meaning representation is grounded in the perception of physical reality leads to the conclusion that meaning must depend on a fusion of multiple (perceptual) modalities [3]. Despite this, AI research in general, and its subdisciplines such as computational linguistics and computer vision in particular, have focused primarily on tasks that involve a single modality. Here, we propose virtual embodiment as an alternative, long-term strategy for AI research that is multi-modal in nature and that allows for the kind of scalability required to develop the field coherently and incrementally, in an ethically responsible fashion.",
    "creator" : "LaTeX with hyperref package"
  }
}