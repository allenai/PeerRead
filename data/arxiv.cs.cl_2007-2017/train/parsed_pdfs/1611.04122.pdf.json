{
  "name" : "1611.04122.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Cross-lingual Dataless Classification for Languages with Small Wikipedia Presence",
    "authors" : [ "Yangqiu Song", "Stephen Mayhew" ],
    "emails" : [ "yqsong@cse.ust.hk", "mayhew2@illinois.edu", "danr@illinois.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n61 1.\n04 12\n2v 1\n[ cs\n.C L\n] 1"
    }, {
      "heading" : "1. Introduction",
      "text" : "Traditional document classification approaches, either monolingual or cross-lingual, use labeled documents to train a model, and apply the model to test documents. However, when we change the test documents’ language or change the label space from one domain to another, we need to re-train the classifiers. Thus, traditional approaches do not scale well in popular languages, and becomes completely infeasible if we want to classify documents in a small language into any ontology of categories.\nCross-lingual dataless document classification (CLDDC) provides a way to classify documents without (re-)training the model, and can thus easily adapt to new domains and many languages (Song, Upadhyay, Peng, & Roth, 2016). CLDDC only requires knowing\n∗. The term “dataless classification” was used due to historical reason. To be more concrete, it would be supervisionless, which means that we have no supervised training documents, but still we can do document classification. One would also think about the term labelless, however, we have the label names of the categories.\nthe English name or a short description of each classification category, and works by embedding the label (in English) and the document (in the other language) jointly into the same semantic space. CLDDC generalizes monolingual dataless classification (Chang, Ratinov, Roth, & Srikumar, 2008; Song & Roth, 2014) by making use of cross-lingual explicit semantic analysis (CLESA) (Potthast, Stein, & Anderka, 2008; Sorg & Cimiano, 2012), a generalization of the English explicit semantic analysis (ESA) (Gabrilovich & Markovitch, 2009). However, CLDDC depends heavily on the availability of large enough Wikipedia in the documents’ language, since it uses the language links in the Wikipedia title space between this language and English. Specifically, it has been applied to classify documents in 180 languages that have at least some Wikipedia presence (Song et al., 2016). There are more than 7,000 known spoken languages, and 2,287 of them have writing systems.1 This means that the CLDDC approach can only work on limited proportion of languages in the world.\nThis paper tackles the above challenge for languages with little or no presence in Wikipedia, which we call here small-Wikipedia languages (SWLs). One can think of multiple ways to facilitate classifying documents in SWLs into an English category ontology. Conceptually, the simplest way is to translate the SWL documents to English or a language with large Wikipedia presence (large-Wikipedia language, LWL), and then apply English dataless classification or CLDDC for the LWL. Unfortunately, this requires full document translation which, in turn, requires large amounts of parallel data in the two languages. This is unlikely to be available anytime soon. The available resources for training standalone machine translation tools are relatively very sparse. For example, Europarl2 covers 21 languages; Google Translate3 covers 103 languages.\nThe first contribution of this paper is that we show that bi-lingual dictionaries (aka “word-level translation”) can be used to support reliable document classification via CLDDC or dataless classification. This approach scales to many more languages: PanDictionary (Mausam, Soderland, Etzioni, Weld, Reiter, Skinner, Sammer, & Bilmes, 2010) or later Panlex4 has word mappings for thousands of languages.\n1. http://www.alphadictionary.com 2. http://www.statmt.org/europarl/ 3. https://translate.google.com 4. https://panlex.org/\nHowever, a natural question is, given an SWL document, which bi-lingual dictionary should we use to facilitate good classification into an English category ontology? Mapping to English may not be the best. For example, among the 169 languages in Wiktionary5 we can download, there are more than 800 language pairs with more than 1,000 language links, but only 59 of them are associated with English. This analysis, some key figures of it being summarized in Table 1, indicates that in order to facilitate classifying a SWL document into an English ontology, we may need to go through a bridge language, a LWL for which bi-lingual dictionaries are available.\nThe second contribution of this paper, is that we show how to choose the best LWL to serve as the bridge language between a given SWL and English. For example, for Hausa, a SWL, it turns out that if we can find a proper LWL, such as Arabic, then we can use the Arabic-English Wikipedia to perform CLDDC. Since Arabic is more similar to Hausa compared to English to Hausa, mapping of words from Hausa to Arabic can be better than English.\nWhile the idea of using a bridge (pivot) language is not new (Paul, Finch, & Sumita, 2013), in this paper we: (1) Systematically evaluate CLDDC using 88 languages, including 39 SWLs and 49 LWLs, and show that this approach successfully supports good classification of a large proportion of SWLs we tested. (2) We propose an automatic way to rank LWLs based on their ability to support good categorization of SWL documents. Specifically, we show how to use RankSVM (Herbrich, Graepel, & Obermayer, 2000; Chapelle & Keerthi, 2010) to learn from the language features to identify which LWLs should be effective as a bridge to a given SWL. Experiments show that this learning based method is significantly better than the use of handcrafted language similarities to rank the LWLs, and that, in many cases, it selects the best possible bridge."
    }, {
      "heading" : "2. Multilingual 20-newsgroups Data",
      "text" : "Since the existing benchmark data sets for multilingual document classification (Lewis, Yang, Rose, & Li, 2004; Hermann & Blunsom, 2014) focus on a small set of languages, to test the CLDDC in many languages, we use the data developed by (Song et al., 2016).6 They selected 100 documents from 20-newsgroups (Lang, 1995) which can be 100% correctly classified using the English dataless classification (Song & Roth, 2014), and used Google Translate API7 to translate these documents into 87 languages.8 We use the English label descriptions for the 20-newsgroups as in (Song & Roth, 2014). Thus, we fixed the English label space with 20 label descriptions.\nSuppose that the target documents are in a foreign language L out of the 87 languages. We use the intersection of the Wikipedia title pages linked between English and L to perform CLESA for CLDDC. We show the correlation between number of Wikipedia titles used in CLESA and the accuracy of CLDDC for 87 languages in Figure 1(b). As shown in Figure 1(b), the correlation score between the logarithm number of Wikipedia titles used in\n5. https://www.wiktionary.org/ 6. https://cogcomp.cs.illinois.edu/page/resource_view/104 7. https://github.com/mouuff/Google-Translate-API 8. We also filtered out Serbo-Croatian (sh) language since it has been deprecated and became a macrolan-\nguage for Croatian (hr), Serbian (sr), Bosnian (bs) and Montenegrin (sr).\nCLESA and the accuracy for 87 languages is ρ = 0.834 (p = 1.1×10−23). The classification result is significantly correlated with the logarithm number of Wikipedia titles.\nTo test whether Google translation will hurt the document quality, we perform the following evaluation. For the 100 documents in each language translated by Google, we translated them back to English again using Google Translate. Then we performed the English ESA based dataless classification (Song & Roth, 2014). A perfect translation should result in 100% accuracy. As shown in Figure 1(a), The average classification accuracy is 0.893 ± 0.019, which seems good enough for us to use the translated documents as our evaluation data. The correlation score between the logarithm number of Wikipedia titles used in CLESA and the accuracy of translated English documents for 87 languages is ρ = 0.604 (p = 5.6×10−10). It seems that Google translate’s performance is also correlated with the size of acquired resource.\nCLDDC can achieve relatively good performance when the number of Wikipedia titles is large. Since the correlation between CLDDC results and Wikipedia sizes is significant, we split the 87 languages based on the classification results. There are 39 languages with lower than 0.5 classification accuracy, while 48 with higher than 0.5 accuracy. Figure 2(a) has summarized the best bridged CLDDC for the 39 selected languages. In this paper, we call the 39 languages the SWLs and the 48 languages as well as English (in total 49) the LWLs."
    }, {
      "heading" : "3. Bridged Cross-lingual Dataless Classification",
      "text" : "In this section, we introduce the general idea of bridging SWL with LWLs, ans show some comparison results with other unsupervised learning or cross-lingual classification approaches using two typical languages."
    }, {
      "heading" : "3.1 Bridging SWLs with LWLs",
      "text" : "We first select two typical SWLs, i.e., Hausa and Uzbek, as examples to demonstrate how to use bridging languages to improve dataless classification. Hausa is a language under the Afro-Asiatic family and further under Chad. Uzbek is a language under the Middle Turkic family. Both of the writing systems are related to Arabic and Latin. The small number of Wikipedia pages, and therefore small shared semantic space, for these two languages (62 for Hausa and 3,082 for Uzbek after intersection with English Wikipedia), means that CLDDC will not be accurate. The results are summarized in Table 2. Indeed, classification results are not satisfactory (0.08 for Hausa and 0.40 for Uzbek).\nThe basic idea of bridged CLDDC is that if we can leverage some word level translation from SWLs to another language, we can use the other language to build ESA/CLESA and further perform dataless classification. Here we tried to use both English (3 million titles) and Arabic (77,631 intersected titles) to bridge Hausa and Uzbek. To compare dictionaries, we first used Google Translate to translate all the words (word by word) used in 20-newsgroups documents in Hausa and Uzbek to English. Then the dataless classification result using English ESA is 0.27 and 0.63 for Hausa and Uzbek respectively.\nTo test the CLDDC using Arabic as a bridging language, we use Google Translate to translate Hausa/Uzbek words into Arabic words. Then we map each document in Hausa/Uzbek to Arabic, and perform CLESA based on Arabic-English Wikipedia. The result of dataless classification is 0.75 and 0.79 for Hausa and Uzbek respectively. We presume that there are two potential reasons for Arabic being better than English. First, the Arabic-English intersected space may be less ambiguous than the original English space. The language links used by CLESA reduce the size of space of Wikipedia titles, but help to disambiguate the semantic meanings. Second, the word-to-word mappings for\nHausa/Uzbek-Arabic are better than those for Hausa/Uzbek-English because Hausa/Uzbek and Arabic are in the same writing system. To test the two above hypotheses, we also map Hausa/Uzbek to English and use the English part in the Arabic-English intersected Wikipedia to perform dataless classification. The results are 0.43 and 0.71 respectively, less than using the Arabic part but greater than using Hausa/Uzbek-English mapping for English Wikipedia. We summarize all the above results in Table 2.\nMoreover, to demonstrate the ability of bridged CLDDC, we also compared with CrossLanguage text classification using Structural Correspondence Learning (CLSCL) algorithm (Prettenhofer & Stein, 2010), which also uses word level mapping for cross-lingual document classification. We test on a one-shot learning setting (Li, Fergus, & Perona, 2006; Lake, Salakhutdinov, & Tenenbaum, 2015), which means that only one labeled document per class is used for training. Dataless classification can also be seen as a one-shot learning but the only example used for each label is just the label name or short description. To test the algorithm, we split the 100 documents into five folds. Then we used one fold in source language (e.g., English or Arabic) as supervised data which contains one document per class, used the other four folds in both languages as unsupervised data, and used the other four folds in target language (e.g., Hausa) for testing. The parameters were set to default values (φ = 30,m = 450) as in the code9 except for the reduced dimensionality k = 3 which corresponds to the least number of pivot (Prettenhofer & Stein, 2010) generated by the algorithm in our data. The mean and std based on five fold cross-validation are also shown in Table 2. It seems supervised learning based on only one document per class does not provide reasonably good results, simply because the known words in the training set cannot cover the words in the test set. Where as, our CLDDC mapped the original text to a common semantic space represented by Wikipedia, which relatively better overlaps between documents and labels. The results in (Song et al., 2016) also showed that CLDDC for LWLs is in general comparable to supervised classification trained based on 100 labeled document per class.\nMoreover, we also compare CLDDC with the traditional unsupervised clustering algorithm, K-means, over the TF-IDF features of documents (IDF was computed based each language’s 100 documents). Note that in dataless classification, we only need label names to classify the documents, but K-means needs to know a set of documents in the target language. When seeing more documents, CLDDC can also be further improved by bootstrapping (Song et al., 2016). We performed ten trials and average the results, using the purity metric to evaluate the accuracy of clustering. Purity is an average accuracy of each cluster assigned to the max corresponding ground truth label. It can be regarded as an upper-bound accuracy when we do not know the correspondence between the ground truth labels and the clustered labels. The clustering results are comparable for English, Arabic, and Hausa, but not as good as bridged CLDDC. In addition, from the results we can see that there is no clear clue about which language will have better clustering results."
    }, {
      "heading" : "4. Rank Bridging Languages",
      "text" : "Given the fact that for both Hausa and Uzbek, Arabic outperforms English for bridged CLDDC, and the fact that there are more local languages out of 7,000 languages in the\n9. https://github.com/pprett/nut\nworld that cannot be translated to English but may be able to be translated to local popular language, we want to evaluate which language can be the best language as a bridge for the SWLs. In Table 3, we show the top ten bridging languages for the target languages Hausa and Uzbek. All the translation of words are performed by Google Translate.10 The results show that Arabic is the best bridge for both languages. For all the 39 SWLs, we also checked the bridged results based on all the 49 LWLs, and we selected the best bridging languages and report the classification results.\nWe compare the original CLDDC results based on the SWL-English Wikpedia with the best LWL bridged CLDDC in Figure 2. We show the results using Google Translate in Figure 2(a). We also show the results using Panlex word translation in Figure 2(b). There are 8 out of 39 languages bridged CLDDC being worse than the original CLDDC using Google Translate, while there are 17 languages worse with Panlex translation. To further evaluate the quality of Panlex dictionaries, we traversed all the 6,134 distinctive language codes in Panlex. We found there are 1,671 languages with at least one word in the selected 100 documents in 20-newsgroups data that can be translated into English. The percentage of words that can be translated versus the number of expressions shown in Panlex is shown in Figure 3. It turns out that only 12.39% out of 1,671 languages has more than 10% words identified. This is why Panlex translation results are worse than Goolge Translate shown in Figure 2.\nBy analyzing the results in Table 3, we find some related languages in Latin writing system as Hausa and Uzbek, such as Spanish, Catalan, Indonesian, and Bulgarian, are ranked high. Some of the top bridging LWLs are in the same family with the target languages. For example, Arabic, Hebrew, and Hausa are in the Afro-Asiatic family. Moreover, region of the native speakers is also reflected. Persian speakers in Iran live relatively near to Uzbek speakers in Uzbekistan. However, writing system, language family, and region are not the only factors that affects the ranking. For example, Korean and Japanese are also ranked in\n10. Here we use Google Translate since it has consistent coverage across the evaluation data we used. Wiktionary (and other dictionaries) covers 1,000+ languages and makes our method a lot more scalable, but we have yet to systematically compare the quality of various dictionaries.\nthe top ten, but none of the above factors appears. Besides other linguistic factors, we also presume that either the size of Wikipedia or the less ambiguity of translation may help them result in relatively good accuracy. Then the remaining question is how to automatically select a good bridging LWL for the SWL document classification."
    }, {
      "heading" : "4.1 Similarity Ranking",
      "text" : "To automatically rank the bridging LWLs for SWLs, we first use the World Atlas of Language Structures (WALS)11 data as language features. The version we downloaded has 2,679 languages with 198 features including phonological, grammatical, and lexical properties. We removed latitude and longitude features thus resulting in 196 features. Given the above analysis, we found four features that are very useful compared to the others, which are genus, family, macro area, and country code. From these, we manually developed a similarity value for a pair of languages as follows:\nSl(L1, L2) = 50 · Igenus(L1, L2) +50 · Ifamily(L1, L2) +50 · Imacro area(L1, L2) +50 · Icountry code(L1, L2) + ∑\ni∈{others} Ii(L1, L2),\n(1)\nwhere Ii(L1, L2) = 1 means that two languages L1 and L2 share the same feature i. If one of the most important features is identified, we add a large value into the similarity value. We set the weight to be 50 with the heuristics that the number can be comparable to the number of 196 features.\nWe also want to incorporate the size of the Wikipedias since it correlated well with the performance of CLDDC. Therefore, we rank the languages with the size of Wikipedias:\nSw(L) = #Wikipedia Title in L. (2)\nIf Wikipedia size is the only factor, we will always use English as the bridging language. Besides the Wikipedia size, we also use the language links to rank the bridging languages:\nSll(L1, L2) = #Language links from L1 to L2. (3)\nTo combine the two ranking factors, since the scales of two similarity/size values are different, we first convert each similarity/size value to the rank value. A larger score denotes a more highly ranked language. We use Wl and Ww as the weights for each similarity. For example, German is ranked as second by Sw, and there are 49 candidate languages, then Ww(German) = (49 − 1)/49 = 0.980. Then we use the harmonic mean of two weights as the combined rank value:\nSh(L1, L2) = 2Wl(L1, L2)Ww(L2)\nWl(L1, L2) +Ww(L2) , (4)\nwhere we treat L1 as the SWL and L2 as the bridging LWL. We use the higher value of Sh to select better bridging LWLs."
    }, {
      "heading" : "4.2 RankSVM",
      "text" : "The above approaches for ranking the bridging LWLs are handcrafted similarities. We also tried to use machine learning to learn from the features and generalize to other languages.\n11. http://wals.info/\nSuppose we have a language pair Li and Lj . We can construct a feature vector xij based on the WALS data, where the rth feature is:\nx (r) ij = Ir(Li, Lj), (5)\nwhere the indicator function denotes both languages sharing the same WALS feature value.\nIf we consider Li as the SWL, and there are two candidates LWLs Lj and Lk, we can compare Lj and Lk based on their feature vectors by projecting them to a real value: w\nTxij and wTxik. Thus, if we have a lot of such pairs, we can build a support vector machine to learn the projection vector w:\n1 2 ‖w‖2 + C\n∑\ni∈{SWL},j,k∈{LWL}\nℓ(wTxij −w Txik) (6)\nwhere ℓ is the loss function ℓ(t) = max(0, 1 − t) (Chapelle & Keerthi, 2010) and C is the penalty parameter. Then given the learnt w, for any pair of LWLs Lj and Lk, we can evaluate which one is better to be used to bridge the SWL Li based on w Txij −w Txik."
    }, {
      "heading" : "4.3 Ranking Results",
      "text" : "Table 4 shows the results. “Original” row is the result for original CLDDC. We compute the mean and standard deviation for the 39 SWLs as well as the correlation of CLDDC with the best bridged CLDDC. The correlation value is negative. According to Figure 2(a), it seems the improvement over smaller original CLDDC accuracies is larger than the ones with larger CLDDC accuracies.\n“Majority Voting” row shows the results of using all the LWLs to vote for each dataless classification result. It shows that “Majority Voting” is significantly better than original CLDDC, and highly correlated with “Best Bridge” shown in next row.\n“Best Bridge (Google)” row shows the results of bridged CLDDC results with the best bridge LWLs. This is the upper-bound of all the other ranking based methods. We can also see from Figure 2(a) that the result is significantly better. Although the variance of the results is large, the t-test result still shows significance. “Best Bridge (Panlex)” shows no significant improvement over original CLDDC. However, Panlex has much more languages than Wikipedia and Google Translate. Thus, it might be still useful when there is something than no resource at all.\n“Linguistic” row shows the results of bridged LWLs ranked by Sh(L1, L2) in Eq. (1). It is significantly better than original CLDDC at 0.05 level.\n“Wikipedia Wikipedia language links” row shows the results ranked by Sll(L) in Eq. (2). Sll(L) is almost the same as Sw(L), since for most of the languages, English has the largest language link number. “Wikipedia size” row shows the results of bridged LWLs ranked by Sw(L) in Eq. (2). Sw(L) will always rank English as the bridge language. We have two interesting findings from the results. First, the ranking is not significantly better than original CLDDC, and worse than “Linguistic.” This means that, bridging SWLs with English by mapping only words may not be a better solution compared to using cross-lingual Wikipedia, even though the cross-lingual Wikipedia is not good enough. Second, the correlation value between “Wikipedia size” and “Best Bridge” is higher than the correlation value\nC r o ss-l in g u a l D a t a l e ss C l a ssif ic a t io n f o r L a n g u a g e s w it h S m a l l W ik ip e d ia P r e se n c e\n1 1\nbetween “Linguistic” and “Best Bridge.” However, the dependent correlation test (Howell, 2011)12 shows this improvement is not significant.\n“Combination” row shows the results of bridged LWLs ranked by Sw(L) in Eq. (4). The results show that combining the “Linguistic” and “Wikipedia size” features by hand shows no improvement over pure “Linguistic” features.\n“RankSVM” row shows the results using RankSVM. We split the SWLs into five folds. Then we perform a five-fold cross validation to generate the results. For each validation, we use 80% of the SWLs as training data, where each language has 49 LWLs accuracies. We use the 49 accuracies to generate 49 × 48/2 pairs. Then we use the learnt model to rank the other 20% SWLs. After the five-fold cross validation, we can rank all the SWLs based on the each learnt model. We tune the parameter of C using a grid search in {10−2, 10−1, . . . , 104}. The average result over 39 SWLs is significantly better than original CLDDC (p = 2.067 × 10−5) and “Majority Voting” (p = 0.014). The correlation with “Best Bridge” is also significantly better than “Linguistic” with “Best Bridge.” This means that machine learning based method is significantly better than the unsupervised voting and ranking with handcrafted similarities. By looking into the averaged weights of RankSVM in five fold cross validation, we select the five top weights with largest absolute values, which are: “Internally-headed relative clauses” (-0.3613), “Front Rounded Vowels” (0.1656), “Absence of Common Consonants” (0.1538), “Optional Double Negation in SVO languages” (-0.1402), “Number of Genders” (0.1385)."
    }, {
      "heading" : "5. Related Work",
      "text" : "In this section, we briefly survey some related work."
    }, {
      "heading" : "5.1 Cross-lingual Classification",
      "text" : "Cross-lingual document classification has attracted more attention recently in low-resource settings. where target language training data is minimal or unavailable. It is a natural sub-topic of transfer learning (Pan & Yang, 2010). In cross-lingual document classification, we train a classifier on labeled documents in the source language, and classify documents in the target language. Existing approaches either need a parallel corpus to train word embeddings for different languages (Hermann & Blunsom, 2014), require labeled documents in both source and target languages (Xiao & Guo, 2013), make use of machine translation techniques to translate words (Prettenhofer & Stein, 2010) or documents (Amini & Goutte, 2010), or combine different approaches (Shi, Mihalcea, & Tian, 2010). Among the existing approaches, word translation is the cheapest way, while document translation and annotation on the target domain are the most expensive. In the middle, parallel or comparable corpora may be used to learn a good word/document representation, which avoids document translation but can still find a correspondence between source and target languages.\nThe strength of cross-lingual document classification is that it can be generalized to multiple languages even in the absence of resources. However, when we change the label space from one domain to another, we should perform translation again and re-train the classifiers. Instead of using parallel corpus to train a classifier or train a translation model,\n12. We used the implementation here: https://github.com/psinger/CorrelationStats.\nour approach only needs the comparable corpus, Wikipedia, in different languages aligned with English. Then if a user can tell the name of the category, cross-lingual dataless classification can perform text classification on-the-fly. For LWLs, CLDDC is comparable to supervised learning method with about 100 to 200 labeled document per label (Song et al., 2016). CLDDC does not need training data in source language. Instead, it only needs the label names and the comparable corpus, Wikipedia, in different languages aligned with English. For LWLs, CLDDC is comparable to supervised learning method with about 100 to 200 labeled document per label (Song et al., 2016)."
    }, {
      "heading" : "5.2 Cross-lingual Representation Learning",
      "text" : "Clearly cross-lingual dataless classification is related to representation learning. Our current approach is based on ESA (Gabrilovich & Markovitch, 2009), which is built based on Wikipedia inverted index. Essentially, ESA is a distributional representation of documentlevel context of words. It regards each Wikipedia page as a concept corresponding to an entity, category, or topic. Then each word is represented by its related concepts. Crosslingual ESA leverages the language links in Wikipeida to relate pages in other languages to English. Then words or texts in two different languages (English and another) can be mapped to the same semantic space represented byWikipedia concepts. Recently, motivated by the simplicity and success of neural network based word embedding (Mikolov, Yih, & Zweig, 2013b; Mikolov, Sutskever, Chen, Corrado, & Dean, 2013a), multi-lingual (Al-Rfou’, Perozzi, & Skiena, 2013), or cross-lingual (Klementiev, Titov, & Bhattarai, 2012; Xiao & Guo, 2013; Hermann & Blunsom, 2014; Faruqui & Dyer, 2014; Lu, Wang, Bansal, Gimpel, & Livescu, 2015; Upadhyay, Faruqui, Dyer, & Roth, 2016) representation learning are also investigated. Other representations such as cross-lingual topic models (Mimno, Wallach, Naradowsky, Smith, & McCallum, 2009; Platt, Toutanova, & tau Yih, 2010; Zhang, Mei, & Zhai, 2010) or Brown clusters (Täckström, McDonald, & Uszkoreit, 2012) were also studied. Similar to cross-lingual classification, these representation learning approaches need either parallel corpora (Klementiev et al., 2012; Hermann & Blunsom, 2014), some labeled data in the target domain (Xiao & Guo, 2013), or words being (partially) aligned in a dictionary (Zhang et al., 2010).\nIt has been shown that CLESA outperforms one of popular the cross-lingual embedding approach (Hermann & Blunsom, 2014) on two benchmark datasets for CLDDC (Song et al., 2016)."
    }, {
      "heading" : "5.3 Pivot based Machine Translation",
      "text" : "Pivot language is used to help machine translation when there is no enough resources to train a translation model from source language to target language (Mann & Yarowsky, 2001; Cohn & Lapata, 2007; Utiyama & Isahara, 2007; Wu & Wang, 2009; Leusch, Max, Crego, & Ney, 2010; Paul et al., 2013). For example, Paul et al., (Paul et al., 2013) used 22 Indo-European and Asian languages to evaluate how to select a good pivot language for machine translation. They evaluated 45 features falling into eight categories. Besides the language family feature, they used more translation-relevant features such as length of sentence, reordering, overlap of vocabulary, etc. They showed that the final result is mostly affected by the source-pivot and pivot-target translation performance. They also mentioned\nmachine learning based method in the future work, but we are unaware of a follow-up paper that succeeded in doing it.\nDifferent from machine translation which needs the sentence level source-pivot and pivottarget translation, in cross-lingual classification, it is sufficient to use word dictionaries, making borrowing a bridging language more scalable to many languages and thus more practically useful. To the best of our knowledge, we have studied largest number of LWLs (49) and SWLs (39) with largest number of linguistic features (196)."
    }, {
      "heading" : "5.4 Zero/One-shot Learning",
      "text" : "Zero-shot learning (Palatucci, Pomerleau, Hinton, & Mitchell, 2009; Socher, Ganjoo, Manning, & Ng, 2013; Elhoseiny, Saleh, , & A.Elgammal, 2013; Romera-Paredes & Torr, 2015) and one-shot learning (Li et al., 2006; Lake et al., 2015) were first introduced in the computer vision community and are now recognized by the natural language processing community (Yazdani & Henderson, 2015; Lazaridou, Dinu, & Baroni, 2015). One-shot learning requires one example for training, while in zero-shot learning, the test data is different from the training data (e.g., a new label space). However, in contrast to the dataless scenario, both learning protocols require some training data. The dataless classification protocol, on the other hand, assumes no direct training data but only the label names or descriptions. Compared to one-shot learning, the labels can be relatively simpler. In addition, it relies on background data from external knowledge sources (like Wikipedia), that is used in an unsupervised way to generate a common semantic space."
    }, {
      "heading" : "6. Conclusion",
      "text" : "We studied the problem of CLDDC for SWLs. CLDDC uses English labels to classify documents in other languages and is scalable to many languages and adaptive to any label space. However, if Wikipedia for a language is not large enough, the performance is not acceptable. In this paper, we simply map the words in SWL documents to LWL words, and perform dataless classification based on LWLs. We systematically evaluate 39 SWLs and 49 LWLs. Experiments show that bridging the SWLs with LWLs can significantly improve the classification results. Moreover, learning from the existing ranking results can be generalized to other languages."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was supported by DARPA under agreement numbers HR0011-15-2-0025 and FA8750-13-2-0008. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of any of the organizations that supported the work."
    } ],
    "references" : [ {
      "title" : "Polyglot: Distributed word representations for multilingual nlp",
      "author" : [ "R. Al-Rfou", "B. Perozzi", "S. Skiena" ],
      "venue" : "In CoNLL,",
      "citeRegEx" : "Al.Rfou. et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Al.Rfou. et al\\.",
      "year" : 2013
    }, {
      "title" : "A co-classification approach to learning from multilingual corpora",
      "author" : [ "M. Amini", "C. Goutte" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Amini and Goutte,? \\Q2010\\E",
      "shortCiteRegEx" : "Amini and Goutte",
      "year" : 2010
    }, {
      "title" : "Importance of semantic representation: Dataless classification",
      "author" : [ "Chang", "M.-W", "L. Ratinov", "D. Roth", "V. Srikumar" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Chang et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Chang et al\\.",
      "year" : 2008
    }, {
      "title" : "Efficient algorithms for ranking with SVMs",
      "author" : [ "O. Chapelle", "S.S. Keerthi" ],
      "venue" : "Inf. Retr.,",
      "citeRegEx" : "Chapelle and Keerthi,? \\Q2010\\E",
      "shortCiteRegEx" : "Chapelle and Keerthi",
      "year" : 2010
    }, {
      "title" : "Machine translation by triangulation: Making effective use of multi-parallel corpora",
      "author" : [ "T. Cohn", "M. Lapata" ],
      "venue" : null,
      "citeRegEx" : "Cohn and Lapata,? \\Q2007\\E",
      "shortCiteRegEx" : "Cohn and Lapata",
      "year" : 2007
    }, {
      "title" : "Write a classifier: Zero shot learning using purely textual descriptions",
      "author" : [ "M. Elhoseiny", "B. Saleh" ],
      "venue" : "A.Elgammal",
      "citeRegEx" : "Elhoseiny and Saleh,? \\Q2013\\E",
      "shortCiteRegEx" : "Elhoseiny and Saleh",
      "year" : 2013
    }, {
      "title" : "Improving vector space word representations using multilingual correlation",
      "author" : [ "M. Faruqui", "C. Dyer" ],
      "venue" : "In EACL,",
      "citeRegEx" : "Faruqui and Dyer,? \\Q2014\\E",
      "shortCiteRegEx" : "Faruqui and Dyer",
      "year" : 2014
    }, {
      "title" : "Wikipedia-based semantic interpretation for natural language processing",
      "author" : [ "E. Gabrilovich", "S. Markovitch" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Gabrilovich and Markovitch,? \\Q2009\\E",
      "shortCiteRegEx" : "Gabrilovich and Markovitch",
      "year" : 2009
    }, {
      "title" : "Large margin rank boundaries for ordinal regression",
      "author" : [ "R. Herbrich", "T. Graepel", "K. Obermayer" ],
      "venue" : null,
      "citeRegEx" : "Herbrich et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Herbrich et al\\.",
      "year" : 2000
    }, {
      "title" : "Multilingual models for compositional distributed semantics",
      "author" : [ "K.M. Hermann", "P. Blunsom" ],
      "venue" : "In ACL,",
      "citeRegEx" : "Hermann and Blunsom,? \\Q2014\\E",
      "shortCiteRegEx" : "Hermann and Blunsom",
      "year" : 2014
    }, {
      "title" : "Statistical methods for psychology",
      "author" : [ "D.C. Howell" ],
      "venue" : "Cengage Learning",
      "citeRegEx" : "Howell,? \\Q2011\\E",
      "shortCiteRegEx" : "Howell",
      "year" : 2011
    }, {
      "title" : "Inducing crosslingual distributed representations of words",
      "author" : [ "A. Klementiev", "I. Titov", "B. Bhattarai" ],
      "venue" : "In COLING,",
      "citeRegEx" : "Klementiev et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Klementiev et al\\.",
      "year" : 2012
    }, {
      "title" : "Human-level concept learning through probabilistic program induction",
      "author" : [ "B.M. Lake", "R. Salakhutdinov", "J.B. Tenenbaum" ],
      "venue" : "Science,",
      "citeRegEx" : "Lake et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lake et al\\.",
      "year" : 2015
    }, {
      "title" : "Newsweeder: Learning to filter netnews",
      "author" : [ "K. Lang" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Lang,? \\Q1995\\E",
      "shortCiteRegEx" : "Lang",
      "year" : 1995
    }, {
      "title" : "Hubness and pollution: Delving into crossspace mapping for zero-shot learning",
      "author" : [ "A. Lazaridou", "G. Dinu", "M. Baroni" ],
      "venue" : "In ACL,",
      "citeRegEx" : "Lazaridou et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lazaridou et al\\.",
      "year" : 2015
    }, {
      "title" : "Multi-pivot translation by system combination",
      "author" : [ "G. Leusch", "A. Max", "J.M. Crego", "H. Ney" ],
      "venue" : "In 2010 International Workshop on Spoken Language Translation,",
      "citeRegEx" : "Leusch et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Leusch et al\\.",
      "year" : 2010
    }, {
      "title" : "Rcv1: A new benchmark collection for text categorization research",
      "author" : [ "D.D. Lewis", "Y. Yang", "T.G. Rose", "F. Li" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "Lewis et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2004
    }, {
      "title" : "One-shot learning of object categories",
      "author" : [ "F. Li", "R. Fergus", "P. Perona" ],
      "venue" : "IEEE Trans. Pattern Anal. Mach. Intell.,",
      "citeRegEx" : "Li et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2006
    }, {
      "title" : "Deep multilingual correlation for improved word embeddings",
      "author" : [ "A. Lu", "W. Wang", "M. Bansal", "K. Gimpel", "K. Livescu" ],
      "venue" : "In NAACL-HLT,",
      "citeRegEx" : "Lu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2015
    }, {
      "title" : "Multipath translation lexicon induction via bridge languages",
      "author" : [ "G.S. Mann", "D. Yarowsky" ],
      "venue" : null,
      "citeRegEx" : "Mann and Yarowsky,? \\Q2001\\E",
      "shortCiteRegEx" : "Mann and Yarowsky",
      "year" : 2001
    }, {
      "title" : "Panlingual lexical translation via probabilistic inference",
      "author" : [ "Mausam", "S. Soderland", "O. Etzioni", "D.S. Weld", "K. Reiter", "M. Skinner", "M. Sammer", "J. Bilmes" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Mausam et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Mausam et al\\.",
      "year" : 2010
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Mikolov et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Linguistic regularities in continuous space word representations",
      "author" : [ "T. Mikolov", "Yih", "W.-t", "G. Zweig" ],
      "venue" : "In HLT-NAACL,",
      "citeRegEx" : "Mikolov et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Polylingual topic models",
      "author" : [ "D. Mimno", "H.M. Wallach", "J. Naradowsky", "D.A. Smith", "A. McCallum" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Mimno et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Mimno et al\\.",
      "year" : 2009
    }, {
      "title" : "Zero-shot learning with semantic output codes",
      "author" : [ "M. Palatucci", "D. Pomerleau", "G.E. Hinton", "T.M. Mitchell" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Palatucci et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Palatucci et al\\.",
      "year" : 2009
    }, {
      "title" : "A survey on transfer learning",
      "author" : [ "S.J. Pan", "Q. Yang" ],
      "venue" : "IEEE Trans. on Knowledge and Data Engineering,",
      "citeRegEx" : "Pan and Yang,? \\Q2010\\E",
      "shortCiteRegEx" : "Pan and Yang",
      "year" : 2010
    }, {
      "title" : "How to choose the best pivot language for automatic translation of low-resource languages",
      "author" : [ "M. Paul", "A.M. Finch", "E. Sumita" ],
      "venue" : "ACM Trans. Asian Lang. Inf. Process.,",
      "citeRegEx" : "Paul et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Paul et al\\.",
      "year" : 2013
    }, {
      "title" : "Translingual document representations from discriminative projections",
      "author" : [ "J.C. Platt", "K. Toutanova", "W. tau Yih" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Platt et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Platt et al\\.",
      "year" : 2010
    }, {
      "title" : "A wikipedia-based multilingual retrieval model",
      "author" : [ "M. Potthast", "B. Stein", "M. Anderka" ],
      "venue" : "In ECIR,",
      "citeRegEx" : "Potthast et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Potthast et al\\.",
      "year" : 2008
    }, {
      "title" : "Cross-language text classification using structural correspondence learning",
      "author" : [ "P. Prettenhofer", "B. Stein" ],
      "venue" : "In ACL,",
      "citeRegEx" : "Prettenhofer and Stein,? \\Q2010\\E",
      "shortCiteRegEx" : "Prettenhofer and Stein",
      "year" : 2010
    }, {
      "title" : "An embarrassingly simple approach to zeroshot learning",
      "author" : [ "B. Romera-Paredes", "P.H.S. Torr" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Romera.Paredes and Torr,? \\Q2015\\E",
      "shortCiteRegEx" : "Romera.Paredes and Torr",
      "year" : 2015
    }, {
      "title" : "Cross language text classification by model translation and semi-supervised learning",
      "author" : [ "L. Shi", "R. Mihalcea", "M. Tian" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Shi et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Shi et al\\.",
      "year" : 2010
    }, {
      "title" : "Zero-shot learning through cross-modal transfer",
      "author" : [ "R. Socher", "M. Ganjoo", "C.D. Manning", "A.Y. Ng" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Socher et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "On dataless hierarchical text classification",
      "author" : [ "Y. Song", "D. Roth" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Song and Roth,? \\Q2014\\E",
      "shortCiteRegEx" : "Song and Roth",
      "year" : 2014
    }, {
      "title" : "Cross-lingual dataless classification for many languages",
      "author" : [ "Y. Song", "S. Upadhyay", "H. Peng", "D. Roth" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "Song et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2016
    }, {
      "title" : "Exploiting wikipedia for cross-lingual and multilingual information retrieval",
      "author" : [ "P. Sorg", "P. Cimiano" ],
      "venue" : "Data and Knowledge Engineering,",
      "citeRegEx" : "Sorg and Cimiano,? \\Q2012\\E",
      "shortCiteRegEx" : "Sorg and Cimiano",
      "year" : 2012
    }, {
      "title" : "Cross-lingual word clusters for direct transfer of linguistic structure",
      "author" : [ "O. Täckström", "R. McDonald", "J. Uszkoreit" ],
      "venue" : "In NAACL-HLT,",
      "citeRegEx" : "Täckström et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Täckström et al\\.",
      "year" : 2012
    }, {
      "title" : "Cross-lingual models of word embeddings: An empirical comparison",
      "author" : [ "S. Upadhyay", "M. Faruqui", "C. Dyer", "D. Roth" ],
      "venue" : null,
      "citeRegEx" : "Upadhyay et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Upadhyay et al\\.",
      "year" : 2016
    }, {
      "title" : "A comparison of pivot methods for phrase-based statistical machine translation",
      "author" : [ "M. Utiyama", "H. Isahara" ],
      "venue" : "In NAACL-HLT,",
      "citeRegEx" : "Utiyama and Isahara,? \\Q2007\\E",
      "shortCiteRegEx" : "Utiyama and Isahara",
      "year" : 2007
    }, {
      "title" : "Revisiting pivot language approach for machine translation",
      "author" : [ "H. Wu", "H. Wang" ],
      "venue" : "In ACL/IJCNLP,",
      "citeRegEx" : "Wu and Wang,? \\Q2009\\E",
      "shortCiteRegEx" : "Wu and Wang",
      "year" : 2009
    }, {
      "title" : "Semi-supervised representation learning for cross-lingual text classification",
      "author" : [ "M. Xiao", "Y. Guo" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Xiao and Guo,? \\Q2013\\E",
      "shortCiteRegEx" : "Xiao and Guo",
      "year" : 2013
    }, {
      "title" : "A model of zero-shot learning of spoken language understanding",
      "author" : [ "M. Yazdani", "J. Henderson" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Yazdani and Henderson,? \\Q2015\\E",
      "shortCiteRegEx" : "Yazdani and Henderson",
      "year" : 2015
    }, {
      "title" : "Cross-lingual latent topic extraction",
      "author" : [ "D. Zhang", "Q. Mei", "C. Zhai" ],
      "venue" : "In ACL,",
      "citeRegEx" : "Zhang et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 34,
      "context" : "Specifically, it has been applied to classify documents in 180 languages that have at least some Wikipedia presence (Song et al., 2016).",
      "startOffset" : 116,
      "endOffset" : 135
    }, {
      "referenceID" : 34,
      "context" : "Since the existing benchmark data sets for multilingual document classification (Lewis, Yang, Rose, & Li, 2004; Hermann & Blunsom, 2014) focus on a small set of languages, to test the CLDDC in many languages, we use the data developed by (Song et al., 2016).",
      "startOffset" : 238,
      "endOffset" : 257
    }, {
      "referenceID" : 13,
      "context" : "6 They selected 100 documents from 20-newsgroups (Lang, 1995) which can be 100% correctly classified using the English dataless classification (Song & Roth, 2014), and used Google Translate API7 to translate these documents into 87 languages.",
      "startOffset" : 49,
      "endOffset" : 61
    }, {
      "referenceID" : 34,
      "context" : "The results in (Song et al., 2016) also showed that CLDDC for LWLs is in general comparable to supervised classification trained based on 100 labeled document per class.",
      "startOffset" : 15,
      "endOffset" : 34
    }, {
      "referenceID" : 34,
      "context" : "When seeing more documents, CLDDC can also be further improved by bootstrapping (Song et al., 2016).",
      "startOffset" : 80,
      "endOffset" : 99
    }, {
      "referenceID" : 10,
      "context" : "” However, the dependent correlation test (Howell, 2011)12 shows this improvement is not significant.",
      "startOffset" : 42,
      "endOffset" : 56
    }, {
      "referenceID" : 34,
      "context" : "For LWLs, CLDDC is comparable to supervised learning method with about 100 to 200 labeled document per label (Song et al., 2016).",
      "startOffset" : 109,
      "endOffset" : 128
    }, {
      "referenceID" : 34,
      "context" : "For LWLs, CLDDC is comparable to supervised learning method with about 100 to 200 labeled document per label (Song et al., 2016).",
      "startOffset" : 109,
      "endOffset" : 128
    }, {
      "referenceID" : 11,
      "context" : "Similar to cross-lingual classification, these representation learning approaches need either parallel corpora (Klementiev et al., 2012; Hermann & Blunsom, 2014), some labeled data in the target domain (Xiao & Guo, 2013), or words being (partially) aligned in a dictionary (Zhang et al.",
      "startOffset" : 111,
      "endOffset" : 161
    }, {
      "referenceID" : 42,
      "context" : ", 2012; Hermann & Blunsom, 2014), some labeled data in the target domain (Xiao & Guo, 2013), or words being (partially) aligned in a dictionary (Zhang et al., 2010).",
      "startOffset" : 144,
      "endOffset" : 164
    }, {
      "referenceID" : 34,
      "context" : "It has been shown that CLESA outperforms one of popular the cross-lingual embedding approach (Hermann & Blunsom, 2014) on two benchmark datasets for CLDDC (Song et al., 2016).",
      "startOffset" : 155,
      "endOffset" : 174
    }, {
      "referenceID" : 26,
      "context" : "Pivot language is used to help machine translation when there is no enough resources to train a translation model from source language to target language (Mann & Yarowsky, 2001; Cohn & Lapata, 2007; Utiyama & Isahara, 2007; Wu & Wang, 2009; Leusch, Max, Crego, & Ney, 2010; Paul et al., 2013).",
      "startOffset" : 154,
      "endOffset" : 292
    }, {
      "referenceID" : 26,
      "context" : ", (Paul et al., 2013) used 22 Indo-European and Asian languages to evaluate how to select a good pivot language for machine translation.",
      "startOffset" : 2,
      "endOffset" : 21
    }, {
      "referenceID" : 17,
      "context" : "Elgammal, 2013; Romera-Paredes & Torr, 2015) and one-shot learning (Li et al., 2006; Lake et al., 2015) were first introduced in the computer vision community and are now recognized by the natural language processing community (Yazdani & Henderson, 2015; Lazaridou, Dinu, & Baroni, 2015).",
      "startOffset" : 67,
      "endOffset" : 103
    }, {
      "referenceID" : 12,
      "context" : "Elgammal, 2013; Romera-Paredes & Torr, 2015) and one-shot learning (Li et al., 2006; Lake et al., 2015) were first introduced in the computer vision community and are now recognized by the natural language processing community (Yazdani & Henderson, 2015; Lazaridou, Dinu, & Baroni, 2015).",
      "startOffset" : 67,
      "endOffset" : 103
    } ],
    "year" : 2016,
    "abstractText" : "This paper presents an approach to classify documents in any language into an English topical label space, without any text categorization training data. The approach, CrossLingual Dataless Document Classification (CLDDC) relies on mapping the English labels or short category description into a Wikipedia-based semantic representation, and on the use of the target language Wikipedia. Consequently, performance could suffer when Wikipedia in the target language is small. In this paper, we focus on languages with small Wikipedias, (Small-Wikipedia languages, SWLs). We use a word-level dictionary to convert documents in a SWL to a large-Wikipedia language (LWLs), and then perform CLDDC based on the LWL’s Wikipedia. This approach can be applied to thousands of languages, which can be contrasted with machine translation, which is a supervision heavy approach and can be done for about 100 languages. We also develop a ranking algorithm that makes use of language similarity metrics to automatically select a good LWL, and show that this significantly improves classification of SWLs’ documents, performing comparably to the best bridge possible.",
    "creator" : "dvips(k) 5.991 Copyright 2011 Radical Eye Software"
  }
}