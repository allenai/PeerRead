{
  "name" : "1610.07418.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Statistical Machine Translation for Indian Languages: Mission Hindi",
    "authors" : [ "Raj Nath Patel", "Prakash B. Pimpale" ],
    "emails" : [ "rajnathp@cdac.in", "prakash@cdac.in", "sasi@cdac.in" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In this paper, we present our experiments on SMT from Bengali, Marathi, Tamil, Telugu and English to Hindi. From the set of languages involved in the shared task, Bengali, Hindi and Marathi belong to IndoAryan family and Tamil and Telugu are from Dravidian language family. All languages except English, have the same flexibility towards word order, canonically following the SOV structure.\nWith reference to the morphology, Bengali, Marathi, Tamil, and Telugu are more agglutinative compared to Hindi. It is known that SMT produces more unknown words resulting in the bad translation quality if the morphological diver-\ngence between the source and target language is high. Koehn and Knight (2003), Popovic and Ney (2004) and Popović et al. (2006) have demonstrated ways to handle this issue with morphological segmentation of words before training the SMT system. To tackle the morphological divergence of Hindi with these languages we have explored Suffix Separation (SS) and Compound word Splitting (CS) as a pre-processing step.\nFor English to Hindi SMT, better alignment is achieved through the use of preordering developed by Patel et al. (2013) and stem as an alignment factor (Koehn and Hoang, 2007). The rest of the paper is organized as follows. In Section 2, we discuss our methodology, followed by data-set and experimental setup in section 3. Section 4 discusses experiments and results. Submitted systems to the shared task and error analysis are displayed in section 5 and 6 respectively, followed by conclusion and future work in section 7."
    }, {
      "heading" : "2 Methodology",
      "text" : "Our methodology to tackle morphological and structural divergence involves the use of the suffix separation, compound splitting, and reordering for the language pairs under study. These methods are briefly described below. Pseudocode for the suffix separation and compound word splitting is detailed in Algorithms 1 and 2 respectively."
    }, {
      "heading" : "2.1 Suffix Separation (SS)",
      "text" : "In this step, the source language words are preprocessed for suffix separation. We have considered only suffix from source language which corresponds to post-positions in Hindi. For example, in Marathi, 1’mahinyaaMnii’ is translated as ’mahiine meM’ in Hindi. In this case, we split\n1All Non-English (Marathi and Hindi) words have been written in Itrans using http://sanskritlibrary. org/transcodeText.html\nar X\niv :1\n61 0.\n07 41\n8v 1\n[ cs\n.C L\n] 2\n4 O\nct 2\n01 6\nAlgorithm 1 Suffix Separation 1: procedure SUFFIXSEP(word) 2: suffixSet← read file suffix list 3: splits← {word, “NULL”} 4: for suffix← suffixSet do 5: if then word.ENDSWITH = suffix & word.LENGTH > suffix.LENGTH 6: splits[0]← word.SUBSTRING(0, word.LASTINDEXOF(suffix)) 7: splits[1]← suffix return splits 8: end if 9: end for 10: end procedure\nAlgorithm 2 Compound Splitting 1: procedure COMPOUNDSPLIT 2: vocab← read monoligual corpus unique word list 3: for word← file do 4: for vcb← vocab do 5: if then word.ENDSWITH = vcb & word.LENGTH > vcb.LENGTH+5 6: compoundSuffix← vcb 7: Delete vcb for vocab return compoundSuffix 8: end if 9: end for 10: end for 11: end procedure\nthe word into ’mahiny + aaMnii’. Here, the suffix ’aaMnii’ corresponds to the word ’meM’ in Hindi. For this task, the list of suffixes is manually created with the linguistic expertise. When a word is subjected to SS, longest matching suffix from the list is considered for suffix separation. Suffix separation takes place only once for a word."
    }, {
      "heading" : "2.2 Compound Splitting (CS)",
      "text" : "In this step source language compound words are split into constituents, recursively. For example, in Marathi, a compound word ’daMtatajGYaaMkaDuuna’ is translated as ’danta visheShaGYa se’ in Hindi. In this case we split the source word into constituents, ’daMta’ , ’tajGYaaM’ and ’kaDuuna’. The list of the constituent suffixes for splitting is empirically prepared from a monolingual data. The compound suffix creation algorithm is very basic and simple, the pseudo code is detailed in Algoritm 2. A word is considered for compound suffix list, if it appears as a suffix in another word of the monolingual corpus."
    }, {
      "heading" : "2.3 Reordering (RO)",
      "text" : "It is based on the syntactic transformation of the English sentence parse tree according to the target language (Hindi) structure. We have used source side reordering developed by Patel et al. (2013), and Ramanathan et al. (2008)."
    }, {
      "heading" : "3 Data-set and Experimental Setup",
      "text" : "We now discuss training and testing corpus from health, tourism and general domains for be-hi, mrhi, ta-hi, te-hi, and en-hi language pairs, followed by preprocessing, SMT system setup and evaluation metrics for experiments."
    }, {
      "heading" : "3.1 Corpus for SMT Training and Testing",
      "text" : "For experiments, we have used corpus shared by ILSMT organizers, detailed in Table 1. Additional monolingual corpus of approx., 23K sentences (Khapra et al., 2010) is used to train the language model. The evaluation of the systems were done using Test1 data which was the development set. The quality of the submitted systems were estimated by the organizers against Test2 corpus."
    }, {
      "heading" : "3.2 Pre-Processing",
      "text" : "To tackle the morphological divergence between the source and target languages (Bengali/Marathi/Tamil/Telugu to Hindi), we used suffix separation and compound splitting, as ex-\nplained in section 2. To handle the structural divergence for English-Hindi SMT, we exploited source side preordering (Patel et al., 2013; Ramanathan et al., 2008)."
    }, {
      "heading" : "3.3 SMT System Set up",
      "text" : "The baseline system was setup using the phrasebased model ( (Brown et al., 1990; Marcu and Wong, 2002; Och and Ney, 2003; Koehn et al., 2003) and Koehn et al. (2007) was used for factored model. The language model was trained using KenLM (Heafield, 2011) toolkit with modified Kneser-Ney smoothing (Chen and Goodman, 1996). For factored SMT training, we used source and target side stem as an alignment factor. Stemming was done using lightweight stemmer (Ramanathan and Rao, 2003) for Hindi. For English, we used porter stemmer (Minnen et al., 2001)."
    }, {
      "heading" : "3.4 Evaluation Metrics",
      "text" : "We compared different experimental systems using BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and translation edit rate (TER) (Snover et al., 2006). For a MT system to be better, higher BLEU and NIST scores with lower TER are desired."
    }, {
      "heading" : "4 Experiments and Results",
      "text" : "In the following subsections, we present different experiments carried out for the shared task. We also study the impact of suffix separation, compound splitting and preordering on the SMT accuracy."
    }, {
      "heading" : "4.1 Impact of Suffix Separation and Compound Splitting",
      "text" : "Pre-processing of source words for suffix separation and compound word splitting results in better alignment and hence the better translation. The alignment improvements can be seen in the Table 2. Improvement in the translation quality can be observed in the various evaluation scores detailed in Table 3. From the table, we can infer that for be-hi and mr-hi, suffix separation have shown significant improvements over the baseline, whereas, compound word splitting has caused slight improvement. However, compound splitting has found to be more effective than suffix separation for ta-hi and te-hi.\nWe have also tried a combination of compound word splitting and suffix separation, serially. We observed improvements over the BL+SS\nand BL+CS for ta-hi and te-hi, across the evaluation scores. BL+SS is better than all other systems for be-hi, across the evaluation metrics, whereas, for mr-hi BL+CS+SS has highest BLEU and BL+SS has the best NIST and TER scores. Compound splitting for Bengali and Marathi can be further investigated to improve the systems."
    }, {
      "heading" : "4.2 Impact of Reordering",
      "text" : "Preordering of the source language sentence helps in the better alignment and decoding for English to Indian language (Ramanathan et al., 2008; Patel et al., 2013; Kunchukuttan et al., 2014) SMT. Table 4 details the results for the systems under study. We can see that BL+RO shows significant improvement over BL. Further, the factored SMT system with stem as alignment factor shows slight improvement in BLEU over the BL+RO, but other metrics show BL+RO is better compared to the factored system."
    }, {
      "heading" : "5 Submission",
      "text" : "In this section, we discuss evaluation scores of the submitted systems. We submitted BL+SS for behi and BL+CS+SS for all other language pairs except en-hi. For en-hi BL+RO+FACT is submitted as the final system. Table 5 summarizes the evaluation of the submission against Test1 and Test2."
    }, {
      "heading" : "6 Error Analysis",
      "text" : "A closer look at the performance of these systems to understand the utility of SS and CS has been done. We report a few early observations."
    }, {
      "heading" : "6.1 Superfluous Splitting",
      "text" : "With the suffix separation, the Marathi word like ’dilaavara’ is getting split into ’dilaa’ + ’vara’ which is a wrong split. As, ’dilaavara’ is a proper noun and hence should not have been split. We tried to overcome this error by avoiding suffix separation and compound splitting of NNP POS tagged words, but that was stopping many other valid candidates from pre-processing."
    }, {
      "heading" : "6.2 Bad Split",
      "text" : "The words like ’jarmaniitiila’ is getting split into ’jarmaniit + ’iila which actually should have been split into ’jarmanii +’tiila’. Similarly, many words on splitting have not given any valid Marathi word which causesed sparsity in training data up to some extent."
    }, {
      "heading" : "7 Conclusion and Future Work",
      "text" : "In this paper, we presented various systems for translation from Bengali, English, Marathi, Tamil\nand Telugu to Hindi. These SMT systems with the use of source side suffix separation, compound splitting and preordering showed significantly higher accuracy over the baseline. In future, we could investigate the formulation of more effective solutions for SS, CS and RO. Reasons for lower BLEU due to the combination of suffix separation and compound word splitting for Bengali and Marathi is another interesting case to study further."
    } ],
    "references" : [ {
      "title" : "A Statistical Approach to Machine Translation",
      "author" : [ "Brown et al.1990] Peter F Brown", "John Cocke", "Stephen A Della Pietra", "Vincent J Della Pietra", "Fredrick Jelinek", "John D Lafferty", "Robert L Mercer", "Paul S Roossin" ],
      "venue" : "Computational linguistics,",
      "citeRegEx" : "Brown et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 1990
    }, {
      "title" : "An Empirical Study of Smoothing Techniques for Language Modeling",
      "author" : [ "Chen", "Goodman1996] Stanley F Chen", "Joshua Goodman" ],
      "venue" : "In Proceedings of the 34th annual meeting on Association for Computational Linguistics,",
      "citeRegEx" : "Chen et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 1996
    }, {
      "title" : "Automatic Evaluation of Machine Translation Quality using N-gram Co-occurrence Statistics",
      "author" : [ "George Doddington" ],
      "venue" : null,
      "citeRegEx" : "Doddington.,? \\Q2002\\E",
      "shortCiteRegEx" : "Doddington.",
      "year" : 2002
    }, {
      "title" : "KenLM: Faster and Smaller Language Model Queries",
      "author" : [ "Kenneth Heafield" ],
      "venue" : "In Proceedings of the Sixth Workshop on Statistical Machine Translation,",
      "citeRegEx" : "Heafield.,? \\Q2011\\E",
      "shortCiteRegEx" : "Heafield.",
      "year" : 2011
    }, {
      "title" : "All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision",
      "author" : [ "Anup Kulkarni", "Saurabh Sohoney", "Pushpak Bhattacharyya" ],
      "venue" : "In Proceedings of the 48th Annual Meet-",
      "citeRegEx" : "Khapra et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Khapra et al\\.",
      "year" : 2010
    }, {
      "title" : "Factored translation models",
      "author" : [ "Koehn", "Hoang2007] Philipp Koehn", "Hieu Hoang" ],
      "venue" : "In EMNLP-CoNLL,",
      "citeRegEx" : "Koehn et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Koehn et al\\.",
      "year" : 2007
    }, {
      "title" : "Empirical Methods for Compound Splitting",
      "author" : [ "Koehn", "Knight2003] Philipp Koehn", "Kevin Knight" ],
      "venue" : "In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics-Volume",
      "citeRegEx" : "Koehn et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Koehn et al\\.",
      "year" : 2003
    }, {
      "title" : "Statistical Phrase-Based Translation",
      "author" : [ "Koehn et al.2003] Philipp Koehn", "Franz Josef Och", "Daniel Marcu" ],
      "venue" : "In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language",
      "citeRegEx" : "Koehn et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Koehn et al\\.",
      "year" : 2003
    }, {
      "title" : "Sata-anuvadak: Tackling multiway translation of indian languages",
      "author" : [ "Abhijit Mishra", "Rajen Chatterjee", "Ritesh Shah", "Pushpak Bhattacharyya" ],
      "venue" : null,
      "citeRegEx" : "Kunchukuttan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kunchukuttan et al\\.",
      "year" : 2014
    }, {
      "title" : "A Phrase-Based, Joint Probability Model for Statistical Machine Translation",
      "author" : [ "Marcu", "Wong2002] Daniel Marcu", "William Wong" ],
      "venue" : "In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume",
      "citeRegEx" : "Marcu et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Marcu et al\\.",
      "year" : 2002
    }, {
      "title" : "Applied morphological processing of english",
      "author" : [ "Minnen et al.2001] Guido Minnen", "John Carroll", "Darren Pearce" ],
      "venue" : "Natural Language Engineering,",
      "citeRegEx" : "Minnen et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Minnen et al\\.",
      "year" : 2001
    }, {
      "title" : "A Systematic Comparison of Various Statistical Alignment Models",
      "author" : [ "Och", "Ney2003] Franz Josef Och", "Hermann Ney" ],
      "venue" : "Computational linguistics,",
      "citeRegEx" : "Och et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Och et al\\.",
      "year" : 2003
    }, {
      "title" : "BLEU: A Method for Automatic Evaluation of Machine Translation",
      "author" : [ "Salim Roukos", "Todd Ward", "Wei-Jing Zhu" ],
      "venue" : "In Proceedings of the 40th annual meeting on association for computational linguis-",
      "citeRegEx" : "Papineni et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Reordering rules for english-hindi smt",
      "author" : [ "Patel et al.2013] Raj Nath Patel", "Rohit Gupta", "Prakash B Pimpale", "Sasikumar M" ],
      "venue" : "In Proceedings of the Second Workshop on Hybrid Approaches to Translation,",
      "citeRegEx" : "Patel et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Patel et al\\.",
      "year" : 2013
    }, {
      "title" : "Towards the Use of Word Stems and Suffixes for Statistical Machine Translation",
      "author" : [ "Popovic", "Ney2004] Maja Popovic", "Hermann Ney" ],
      "venue" : null,
      "citeRegEx" : "Popovic et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Popovic et al\\.",
      "year" : 2004
    }, {
      "title" : "Statistical Machine Translation of German Compound Words",
      "author" : [ "Popović et al.2006] Maja Popović", "Daniel Stein", "Hermann Ney" ],
      "venue" : "In Advances in Natural Language Processing,",
      "citeRegEx" : "Popović et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Popović et al\\.",
      "year" : 2006
    }, {
      "title" : "A Lightweight Stemmer for Hindi",
      "author" : [ "Ramanathan", "Durgesh D Rao" ],
      "venue" : "In The Proceedings of EACL",
      "citeRegEx" : "Ramanathan et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Ramanathan et al\\.",
      "year" : 2003
    }, {
      "title" : "Simple Syntactic and Morphological Processing Can Help English-Hindi Statistical Machine",
      "author" : [ "Ramanathan", "Jayprasad Hegde", "Ritesh M Shah", "Pushpak Bhattacharyya", "M Sasikumar" ],
      "venue" : null,
      "citeRegEx" : "Ramanathan et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Ramanathan et al\\.",
      "year" : 2008
    }, {
      "title" : "A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of association for machine translation in the Ameri",
      "author" : [ "Bonnie Dorr", "Richard Schwartz", "Linnea Micciulla", "John Makhoul" ],
      "venue" : null,
      "citeRegEx" : "Snover et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Snover et al\\.",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "Koehn and Knight (2003), Popovic and Ney (2004) and Popović et al. (2006) have demonstrated ways to handle this issue with morphological segmentation of words before training the SMT system.",
      "startOffset" : 52,
      "endOffset" : 74
    }, {
      "referenceID" : 13,
      "context" : "by Patel et al. (2013) and stem as an alignment factor (Koehn and Hoang, 2007).",
      "startOffset" : 3,
      "endOffset" : 23
    }, {
      "referenceID" : 13,
      "context" : "We have used source side reordering developed by Patel et al. (2013), and Ramanathan et al.",
      "startOffset" : 49,
      "endOffset" : 69
    }, {
      "referenceID" : 13,
      "context" : "We have used source side reordering developed by Patel et al. (2013), and Ramanathan et al. (2008). health tourism general training (TM) 24K 24K 48K training (LM) 71K 71K 71K test1 500 500 1000 test2 500 500 1000",
      "startOffset" : 49,
      "endOffset" : 99
    }, {
      "referenceID" : 4,
      "context" : ", 23K sentences (Khapra et al., 2010) is used to train the language model.",
      "startOffset" : 16,
      "endOffset" : 37
    }, {
      "referenceID" : 13,
      "context" : "To handle the structural divergence for English-Hindi SMT, we exploited source side preordering (Patel et al., 2013; Ramanathan et al., 2008).",
      "startOffset" : 96,
      "endOffset" : 141
    }, {
      "referenceID" : 17,
      "context" : "To handle the structural divergence for English-Hindi SMT, we exploited source side preordering (Patel et al., 2013; Ramanathan et al., 2008).",
      "startOffset" : 96,
      "endOffset" : 141
    }, {
      "referenceID" : 0,
      "context" : "The baseline system was setup using the phrasebased model ( (Brown et al., 1990; Marcu and Wong, 2002; Och and Ney, 2003; Koehn et al., 2003) and Koehn et al.",
      "startOffset" : 60,
      "endOffset" : 141
    }, {
      "referenceID" : 6,
      "context" : "The baseline system was setup using the phrasebased model ( (Brown et al., 1990; Marcu and Wong, 2002; Och and Ney, 2003; Koehn et al., 2003) and Koehn et al.",
      "startOffset" : 60,
      "endOffset" : 141
    }, {
      "referenceID" : 3,
      "context" : "The language model was trained using KenLM (Heafield, 2011) toolkit with modified Kneser-Ney smoothing (Chen and Goodman, 1996).",
      "startOffset" : 43,
      "endOffset" : 59
    }, {
      "referenceID" : 10,
      "context" : "For English, we used porter stemmer (Minnen et al., 2001).",
      "startOffset" : 36,
      "endOffset" : 57
    }, {
      "referenceID" : 0,
      "context" : "The baseline system was setup using the phrasebased model ( (Brown et al., 1990; Marcu and Wong, 2002; Och and Ney, 2003; Koehn et al., 2003) and Koehn et al. (2007) was used for factored model.",
      "startOffset" : 61,
      "endOffset" : 166
    }, {
      "referenceID" : 12,
      "context" : "We compared different experimental systems using BLEU (Papineni et al., 2002), NIST (Dodding-",
      "startOffset" : 54,
      "endOffset" : 77
    }, {
      "referenceID" : 18,
      "context" : "ton, 2002) and translation edit rate (TER) (Snover et al., 2006).",
      "startOffset" : 43,
      "endOffset" : 64
    }, {
      "referenceID" : 17,
      "context" : "Preordering of the source language sentence helps in the better alignment and decoding for English to Indian language (Ramanathan et al., 2008; Patel et al., 2013; Kunchukuttan et al., 2014) SMT.",
      "startOffset" : 118,
      "endOffset" : 190
    }, {
      "referenceID" : 13,
      "context" : "Preordering of the source language sentence helps in the better alignment and decoding for English to Indian language (Ramanathan et al., 2008; Patel et al., 2013; Kunchukuttan et al., 2014) SMT.",
      "startOffset" : 118,
      "endOffset" : 190
    }, {
      "referenceID" : 8,
      "context" : "Preordering of the source language sentence helps in the better alignment and decoding for English to Indian language (Ramanathan et al., 2008; Patel et al., 2013; Kunchukuttan et al., 2014) SMT.",
      "startOffset" : 118,
      "endOffset" : 190
    } ],
    "year" : 2016,
    "abstractText" : "This paper discusses Centre for Development of Advanced Computing Mumbai’s (CDACM) submission to the NLP Tools Contest on Statistical Machine Translation in Indian Languages (ILSMT) 2014 (collocated with ICON 2014). The objective of the contest was to explore the effectiveness of Statistical Machine Translation (SMT) for Indian language to Indian language and English-Hindi machine translation. In this paper, we have proposed that suffix separation and word splitting for SMT from agglutinative languages to Hindi significantly improves over the baseline (BL). We have also shown that the factored model with reordering outperforms the phrase-based SMT for EnglishHindi (en-hi). We report our work on all five pairs of languages, namely Bengali-Hindi (be-hi), Marathi-Hindi (mrhi), Tamil-Hindi (ta-hi), Telugu-Hindi (tehi), and en-hi for Health, Tourism, and General domains.",
    "creator" : "LaTeX with hyperref package"
  }
}