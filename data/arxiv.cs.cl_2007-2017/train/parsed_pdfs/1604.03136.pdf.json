{
  "name" : "1604.03136.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Shallow Parsing Pipeline for Hindi-English Code-Mixed Social Media Text",
    "authors" : [ "Arnav Sharma", "Sakshi Gupta", "Piyush Bansal", "Manish Shrivastava", "Radhika Mamidi", "Dipti M. Sharma" ],
    "emails" : [ "piyush.bansal}@research.iiit.ac.in", "dipti}@iiit.ac.in" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this study, the problem of shallow parsing of Hindi-English code-mixed social media text (CSMT) has been addressed. We have annotated the data, developed a language identifier, a normalizer, a part-of-speech tagger and a shallow parser. To the best of our knowledge, we are the first to attempt shallow parsing on CSMT. The pipeline developed has been made available to the research community with the goal of enabling better text analysis of Hindi English CSMT. The pipeline is accessible at 1."
    }, {
      "heading" : "1 Introduction",
      "text" : "Multilingual speakers tend to exhibit code-mixing and code-switching in their use of language on social media platforms. Code-Mixing is the embedding of linguistic units such as phrases, words or morphemes of one language into an utterance of another language whereas code-switching refers to the co-occurrence of speech extracts belonging to two different grammatical systems (Gumperz., 1982). Here we use code-mixing to refer to both the scenarios.\nHindi-English bilingual speakers produce huge amounts of CSMT. Vyas et al. (2014) noted that the complexity in analyzing CSMT stems from nonadherence to a formal grammar, spelling variations, lack of annotated data, inherent conversational nature of the text and of course, code-mixing. Therefore, there is a need to create datasets and Natural\n1http://bit.ly/csmt-parser-api\nLanguage Processing (NLP) tools for CSMT as traditional tools are ill-equipped for it. Taking a step in this direction, we describe the shallow parsing pipeline built during this study."
    }, {
      "heading" : "2 Background",
      "text" : "Bali et al. (2014) gathered data from Facebook generated by English-Hindi bilingual users which on analysis, showed a significant amount of codemixing. Barman et al. (2014) investigated language identification at word level on Bengali-HindiEnglish CSMT. They annotated a corpus with more than 180,000 tokens and achieved an accuracy of 95.76% using statistical models with monolingual dictionaries.\nSolorio and Liu (2008) experimented with POS tagging for English-Spanish Code-Switched discourse by using pre-existing taggers for both languages and achieved an accuracy of 93.48%. However, the data used was manually transcribed and thus lacked the problems added by CSMT. Vyas et al. (2014) formalized the problem, reported challenges in processing Hindi-English CSMT and performed initial experiments on POS tagging. Their POS tagger accuracy fell by 14% to 65% without using gold language labels and normalization. Thus, language identification and normalization are critical for POS tagging (Vyas et al., 2014), which in turn is critical further down the pipeline for shallow parsing as evident in Table 5.\nJamatia et al. (2015) also built a POS tagger for Hindi-English CSMT using Random Forests on 2,583 utterances with gold language labels and achieved an accuracy of 79.8%. In the monolin-\nar X\niv :1\n60 4.\n03 13\n6v 1\n[ cs\n.C L\n] 1\n1 A\npr 2\ngual social media text context, Gimpel et al. (2011) built a POS tagger for English tweets and achieved an accuracy of 89.95% on 1,827 annotated tweets. Owoputi et al. (2013) further improved this POS tagger, increasing the accuracy to 93%."
    }, {
      "heading" : "3 Data Preparation",
      "text" : "CSMT was obtained from social media posts from the data shared for Subtask 1 of FIRE-2014 Shared Task on Transliterated Search. The existing annotation on the FIRE dataset was removed, posts were broken down into sentences and 858 of those sentences were randomly selected for manual annotation.\nTable 1 and Table 2 show the distribution of the dataset at sentence and token level respectively. The language of 63.33% of the tokens in code-mixed sentences is Hindi. Based on the distribution, it is reasonable to assume that Hindi is the matrix language (Azuma, 1993; Myers-Scotton, 1997) in most of the code-mixed sentences."
    }, {
      "heading" : "3.1 Dataset examples",
      "text" : "1. hy... try fr sm gov job jiske forms niklte h... Gloss: Hey... try for some government job which forms give out... Translation: Hey... try for some government job which gives out forms...\n2. To tum divya bharti mandir marriage kendra ko donate karna Gloss: So you divya bharti temple marriage center to donate do\nTranslation: So you donate to divya bharti temple marriage center\nThe dataset is comprised of sentences similar to example 1 and 2. Example 1 shows codeswitching as the language switches from English to Hindi whereas example 2 shows codemixing as some English words are embedded in a Hindi utterance. Spelling variations (sm - some, gov - government), ambiguous words (To - So in Hindi or To in English) and non-adherence to a formal grammar (out of place ellipsis - ..., no or misplaced punctuation) are some of the challenges evident in analyzing the examples above."
    }, {
      "heading" : "3.2 Annotation",
      "text" : "Annotation was done on the following four layers:\n1. Language Identification: Every word was given a tag out of three ’en’, ’hi’ and ’rest’ to mark its language. Words that a bilingual speaker could identify as belonging to either Hindi or English were marked as ‘hi’ or ‘en’. The label ‘rest’ was given to symbols, emoticons, punctuation, named entities, acronyms, foreign words and words with sub-lexical codemixing like chapattis (Gloss: chapatti - bread) which is a Hindi word (chapatti) following English morphology (plural marker -s).\n2. Normalization: Words with language tag ‘hi’ in Roman script were labeled with their standard form in the native script of Hindi, Devanagari. Similarly, words with language tag ‘en’ were labeled with their standard spelling. Words with language tag ‘rest’ were kept as they are. This acted as testing data for our Normalization module.\n3. Parts-of-Speech (POS): Universal POS tagset (Petrov et al., 2011) was used to label the POS of each word as this tagset is applicable to both English and Hindi words. Sub-lexical codemixed words were annotated based on their context, since POS is a function of a word in a given context. For example, an English verb used as a noun in Hindi context is labeled as a noun.\n4. Chunking: A chunk tag comprises of chunk label and chunk boundary. The chunk label tagset is a coarser version of AnnCorra tagset (Bharati et al., 2006). Unlike AnnCorra, only one tag is used for all verb chunks in our tagset. Chunk boundary is marked using BI notation where ‘B-’ prefix indicates beginning of a chunk and ‘I-’ prefix indicates that the word is inside a chunk.\nThis whole dataset was annotated by eight HindiEnglish bilingual speakers. Two other annotators reviewed and cleaned it. To measure interannotator agreement, another annotator read the guidelines and annotated 25 sentences (334 tokens) from scratch. The inter-annotator agreement calculated using Cohen’s κ (Cohen, 1960) came out to be 0.97, 0.83 and 0.89 for language identification, POS tagging and shallow parsing respectively."
    }, {
      "heading" : "4 Shallow Parsing Pipeline",
      "text" : "Shallow parsing is the task of identifying and segmenting text into syntactically correlated word groups (Abney, 1992; Harris, 1957). Shallow parsing is a viable alternative to full parsing as shown by (Li and Roth, 2001). Our shallow parsing pipeline is composed of four main modules, as shown in Figure 1. These modules, in the order of their usage, are Language Identification, Normalization, POS Tagger and Shallow Parser.\nOur pipeline takes a raw utterance in Roman script as input on which each module runs sequentially. Twokenizer2 (Owoputi et al., 2013) which\n2http://www.ark.cs.cmu.edu/TweetNLP/\nperforms well on Hindi-English CSMT (Jamatia et al., 2015) was used to tokenize the utterance into words. The Language Identification module assigns each token a language label. Based on the language label assigned, the Normalizer runs the Hindi normalizer or the English/Rest normalizer. The POS tagger uses the output of the normalizer to assign each word a POS tag. Finally, the Shallow Parser assigns a chunk label with boundary.\nThe functionality and performance of each module is described in greater detail in the following subsections."
    }, {
      "heading" : "4.1 Language Identification",
      "text" : "While language identification at the document level is a well-established task (McNamee, 2005), identifying language in social media posts has certain challenges associated to it. Spelling errors, phonetic typing, use of transliterated alphabets and abbreviations combined with code-mixing make this problem interesting. Similar to (Barman et al., 2014), we performed two experiments treating language identification as a three class (‘hi’, ‘en’, ‘rest’) classification problem. The feature set comprised of - BNC: normalized frequency of the word in British National Corpus (BNC)3. LEXNORM: binary feature indicating presence of the word in the lexical normalization dataset released by Han et al. (2011). HINDI DICT: binary feature indicating presence of the word in a dictionary of 30,823 transliterated Hindi words as released by Gupta (2012). NGRAM: word n-grams. AFFIXES: prefixes and suffixes of the word.\nUsing these features and introducing a contextwindow of n-words, we trained a linear SVM. In another experiment we modeled language identification as a sequence labeling task, where we employed CRF into usage. The idea behind this was that\n3http://www.natcorp.ox.ac.uk/\ncode-mixed text has some inherent structure which is largely dictated by the matrix language of the text. The latter approach using CRF had a greater accuracy, which validated our hypothesis. The results of this module are shown in Table 3."
    }, {
      "heading" : "4.2 Normalization",
      "text" : "Once the language identification task was complete, there was a need to convert the noisy non-standard tokens (such as Hindi words inconsistently written in many ways using the Roman script) in the text into standard words. To fix this, a normalization module that performs language-specific transformations, yielding the correct spelling for a given word was built. Two language specific normalizers, one for Hindi and other for English/Rest, had two subnormalizers each, as described below. Both subnormalizers generated normalized candidates which were then ranked, as explained later in this subsection.\n1. Noisy Channel Framework: A generative model was trained to produce noisy (unnormalized) tokens from a given normalized word. Using the model’s confidence score and the probability of the normalized word in the background corpus, n-best normalizations were chosen. First, we obtained character alignments between noisy Hindi words in Roman script (Hr) to normalized Hindi wordsformat(Hw) using GIZA++ (Och and Ney, 2003) on 30,823 Hindi word pairs of the form (Hw - Hr) (Gupta et al., 2012). Next, a CRF classifier was trained over these alignments, enabling it to convert a character sequence from Roman to Devanagari using learnt letter transformations. Using this model, noisy Hr words were created for Hw words obtained from a dictionary of 1,17,789 Hindi words (Biemann et al., 2007). Finally, using the formula below, we computed the most probableHw for a given Hr.\nHw = argmaxHwip(Hwi |Hr) = argmaxHwip(Hr|Hwi)p(Hwi)\nwhere p(Hwi) is the probability of wordHwi in the background corpus.\n2. SILPA Spell Checker: This subnormalizer uses SILPA libindic spell-checker4 to compute the top 10 normalized words for a given input word.\nThe candidates obtained from these two systems are ranked on the basis of the observed precision of the systems. The top-k candidates from each system are selected if they have a confidence score greater than an empirically observed Λ. A similar approach was used for English text normalization, using the English normalization pairs from (Han et al., 2012) and (Liu et al., 2012) for the noisy channel framework, and Aspell5 as the spell-checker. Words with language tag ’rest’ were left unprocessed. The accuracy for the Hindi Normalizer was 78.25%, and for the English Normalizer was 69.98%. The overall accuracy of this module is 74.48%; P@n (Precision@n) for n=3 is 77.51% and for n=5 is 81.76%."
    }, {
      "heading" : "4.3 Part-Of-Speech Tagging",
      "text" : "Part-of-Speech (POS) tagging provides basic level of syntactic analysis for a given word or sentence. It was modeled as a sequence labeling task using CRF. The feature set comprised of - Baseline: Word based features - affixes, context and the word itself. LANG: Language label of the token. NORM: Normalized lexical features. TPOS: Output of Twitter POS tagger (Owoputi et al., 2013). HPOS: Output of IIIT’s Hindi POS tagger6. COMBINED: HPOS for Hindi words and TPOS for English and Rest. The results of POS Tagger are shown in Table 4.\n4https://github.com/libindic/ spellchecker\n5http://aspell.net/ 6http://ltrc.iiit.ac.in/showfile.php?\nfilename=downloads/shallow_parser.php"
    }, {
      "heading" : "4.4 Shallow Parsing",
      "text" : "A chunk comprises of two aspects - the chunk boundary and the chunk label. Shallow Parsing was modeled as three separate sequence labeling problems: Label, Boundary and Combined, for each of which a CRF model was trained. The feature set comprised of - POS: POS tag of the word. POS Context: POS tags in the context window of length 5, i.e., the two previous tags, current tag and next two tags. POS LEX: A special feature made up of concatenation of POS and LEX. NORMLEX: The word in its normalized form. The results of this module are shown in Table 5."
    }, {
      "heading" : "5 Pipeline Results",
      "text" : "The best performing model was selected from each module and was used in the pipeline. Table 6 tabulates the step by step accuracy of the pipeline calculated using 10 fold cross-validation."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "In this study, we have developed a system for HindiEnglish CSMT data that can identify the language of the words, normalize them to their standard forms, assign them their POS tag and segment them into chunks. We have released the system.\nIn the future, we intend to continue creating more annotated code-mixed social media data. We would\nalso like to improve upon the challenging problem of normalization of monolingual social Hindi sentences. Also, we would further extend our pipeline and build a full parser which has aplenty applications in NLP."
    } ],
    "references" : [ {
      "title" : "Parsing by chunks",
      "author" : [ "Steven P Abney." ],
      "venue" : "Springer.",
      "citeRegEx" : "Abney.,? 1992",
      "shortCiteRegEx" : "Abney.",
      "year" : 1992
    }, {
      "title" : "The frame-content hypothesis in speech production: Evidence from intrasentential code switching",
      "author" : [ "Shoji Azuma." ],
      "venue" : "Linguistics, 31(6):1071–1094.",
      "citeRegEx" : "Azuma.,? 1993",
      "shortCiteRegEx" : "Azuma.",
      "year" : 1993
    }, {
      "title" : "i am borrowing ya mixing ? an analysis of english-hindi code mixing in facebook",
      "author" : [ "Kalika Bali", "Jatin Sharma", "Monojit Choudhury", "Yogarshi Vyas." ],
      "venue" : "Proceedings of the First Workshop on Computational Approaches to Code Switching, pages 116–126, Doha,",
      "citeRegEx" : "Bali et al\\.,? 2014",
      "shortCiteRegEx" : "Bali et al\\.",
      "year" : 2014
    }, {
      "title" : "Code mixing: A challenge for language identification in the language of social media",
      "author" : [ "Utsab Barman", "Amitava Das", "Joachim Wagner", "Jennifer Foster." ],
      "venue" : "EMNLP 2014, page 13.",
      "citeRegEx" : "Barman et al\\.,? 2014",
      "shortCiteRegEx" : "Barman et al\\.",
      "year" : 2014
    }, {
      "title" : "Anncorra: Annotating corpora guidelines for pos and chunk annotation for indian languages",
      "author" : [ "Akshar Bharati", "Rajeev Sangal", "Dipti Misra Sharma", "Lakshmi Bai." ],
      "venue" : "LTRC-TR31.",
      "citeRegEx" : "Bharati et al\\.,? 2006",
      "shortCiteRegEx" : "Bharati et al\\.",
      "year" : 2006
    }, {
      "title" : "The leipzig corpora collection-monolingual corpora of standard size",
      "author" : [ "Chris Biemann", "Gerhard Heyer", "Uwe Quasthoff", "Matthias Richter." ],
      "venue" : "Proceedings of Corpus Linguistic.",
      "citeRegEx" : "Biemann et al\\.,? 2007",
      "shortCiteRegEx" : "Biemann et al\\.",
      "year" : 2007
    }, {
      "title" : "A coefficient of agreement for nominal scales",
      "author" : [ "Jacob Cohen." ],
      "venue" : "Educational and Psychological Measurement, 134:3746.",
      "citeRegEx" : "Cohen.,? 1960",
      "shortCiteRegEx" : "Cohen.",
      "year" : 1960
    }, {
      "title" : "Part-of-speech tagging for twitter: Annotation, features, and experiments",
      "author" : [ "Kevin Gimpel", "Nathan Schneider", "Brendan O’Connor", "Dipanjan Das", "Daniel Mills", "Jacob Eisenstein", "Michael Heilman", "Dani Yogatama", "Jeffrey Flanigan", "Noah A Smith" ],
      "venue" : null,
      "citeRegEx" : "Gimpel et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Gimpel et al\\.",
      "year" : 2011
    }, {
      "title" : "Discourse Strategies",
      "author" : [ "John J. Gumperz." ],
      "venue" : "Oxford University Press.",
      "citeRegEx" : "Gumperz.,? 1982",
      "shortCiteRegEx" : "Gumperz.",
      "year" : 1982
    }, {
      "title" : "Mining hindi-english transliteration pairs from online hindi lyrics",
      "author" : [ "Kanika Gupta", "Monojit Choudhury", "Kalika Bali." ],
      "venue" : "LREC, pages 2459–2465.",
      "citeRegEx" : "Gupta et al\\.,? 2012",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 2012
    }, {
      "title" : "Lexical normalisation of short text messages: Makn sens a# twitter",
      "author" : [ "Bo Han", "Timothy Baldwin." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Lan-",
      "citeRegEx" : "Han and Baldwin.,? 2011",
      "shortCiteRegEx" : "Han and Baldwin.",
      "year" : 2011
    }, {
      "title" : "Automatically constructing a normalisation dictionary for microblogs",
      "author" : [ "Bo Han", "Paul Cook", "Timothy Baldwin." ],
      "venue" : "Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning,",
      "citeRegEx" : "Han et al\\.,? 2012",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2012
    }, {
      "title" : "Co-occurrence and transformation in linguistic structure",
      "author" : [ "Zellig S Harris." ],
      "venue" : "Language, pages 283–340.",
      "citeRegEx" : "Harris.,? 1957",
      "shortCiteRegEx" : "Harris.",
      "year" : 1957
    }, {
      "title" : "Part-of-speech tagging for code-mixed englishhindi twitter and facebook chat messages",
      "author" : [ "Anupam Jamatia", "Björn Gambäck", "Amitava Das." ],
      "venue" : "Proceedings of Recent Advances in Natural Language Processing, page 239.",
      "citeRegEx" : "Jamatia et al\\.,? 2015",
      "shortCiteRegEx" : "Jamatia et al\\.",
      "year" : 2015
    }, {
      "title" : "Exploring evidence for shallow parsing",
      "author" : [ "Xin Li", "Dan Roth." ],
      "venue" : "Proceedings of the 2001 workshop on Computational Natural Language Learning-Volume 7, page 6. Association for Computational Linguistics.",
      "citeRegEx" : "Li and Roth.,? 2001",
      "shortCiteRegEx" : "Li and Roth.",
      "year" : 2001
    }, {
      "title" : "A broadcoverage normalization system for social media language",
      "author" : [ "Fei Liu", "Fuliang Weng", "Xiao Jiang." ],
      "venue" : "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 1035–1044. Association for",
      "citeRegEx" : "Liu et al\\.,? 2012",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2012
    }, {
      "title" : "Language identification: a solved problem suitable for undergraduate instruction",
      "author" : [ "Paul McNamee." ],
      "venue" : "Journal of Computing Sciences in Colleges, 20(3):94–101.",
      "citeRegEx" : "McNamee.,? 2005",
      "shortCiteRegEx" : "McNamee.",
      "year" : 2005
    }, {
      "title" : "Duelling languages: Grammatical structure in codeswitching",
      "author" : [ "Carol Myers-Scotton." ],
      "venue" : "Oxford University Press.",
      "citeRegEx" : "Myers.Scotton.,? 1997",
      "shortCiteRegEx" : "Myers.Scotton.",
      "year" : 1997
    }, {
      "title" : "A systematic comparison of various statistical alignment models",
      "author" : [ "Franz Josef Och", "Hermann Ney." ],
      "venue" : "Computational Linguistics, 29(1):19–51.",
      "citeRegEx" : "Och and Ney.,? 2003",
      "shortCiteRegEx" : "Och and Ney.",
      "year" : 2003
    }, {
      "title" : "Improved part-of-speech tagging for online conversational text with word",
      "author" : [ "Olutobi Owoputi", "Brendan O’Connor", "Chris Dyer", "Kevin Gimpel", "Nathan Schneider", "Noah A Smith" ],
      "venue" : null,
      "citeRegEx" : "Owoputi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Owoputi et al\\.",
      "year" : 2013
    }, {
      "title" : "A universal part-of-speech tagset",
      "author" : [ "Slav Petrov", "Dipanjan Das", "Ryan McDonald." ],
      "venue" : "arXiv preprint arXiv:1104.2086.",
      "citeRegEx" : "Petrov et al\\.,? 2011",
      "shortCiteRegEx" : "Petrov et al\\.",
      "year" : 2011
    }, {
      "title" : "Part-of-speech tagging for english-spanish code-switched text",
      "author" : [ "Thamar Solorio", "Yang Liu." ],
      "venue" : "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1051–1060. Association for Computational Linguistics.",
      "citeRegEx" : "Solorio and Liu.,? 2008",
      "shortCiteRegEx" : "Solorio and Liu.",
      "year" : 2008
    }, {
      "title" : "Pos tagging of english-hindi code-mixed social media content",
      "author" : [ "Yogarshi Vyas", "Spandana Gella", "Jatin Sharma", "Kalika Bali", "Monojit Choudhury." ],
      "venue" : "Proceedings of the First Workshop on Codeswitching, EMNLP.",
      "citeRegEx" : "Vyas et al\\.,? 2014",
      "shortCiteRegEx" : "Vyas et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "Code-Mixing is the embedding of linguistic units such as phrases, words or morphemes of one language into an utterance of another language whereas code-switching refers to the co-occurrence of speech extracts belonging to two different grammatical systems (Gumperz., 1982).",
      "startOffset" : 256,
      "endOffset" : 272
    }, {
      "referenceID" : 22,
      "context" : "Vyas et al. (2014) noted that the complexity in analyzing CSMT stems from nonadherence to a formal grammar, spelling variations, lack of annotated data, inherent conversational nature of the text and of course, code-mixing.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 22,
      "context" : "Thus, language identification and normalization are critical for POS tagging (Vyas et al., 2014), which in turn is critical further down the pipeline for shallow parsing as evident in Table 5.",
      "startOffset" : 77,
      "endOffset" : 96
    }, {
      "referenceID" : 7,
      "context" : "gual social media text context, Gimpel et al. (2011) built a POS tagger for English tweets and achieved an accuracy of 89.",
      "startOffset" : 32,
      "endOffset" : 53
    }, {
      "referenceID" : 7,
      "context" : "gual social media text context, Gimpel et al. (2011) built a POS tagger for English tweets and achieved an accuracy of 89.95% on 1,827 annotated tweets. Owoputi et al. (2013) further improved this POS tagger, increasing the accuracy to 93%.",
      "startOffset" : 32,
      "endOffset" : 175
    }, {
      "referenceID" : 1,
      "context" : "Based on the distribution, it is reasonable to assume that Hindi is the matrix language (Azuma, 1993; Myers-Scotton, 1997) in most of the code-mixed sentences.",
      "startOffset" : 88,
      "endOffset" : 122
    }, {
      "referenceID" : 17,
      "context" : "Based on the distribution, it is reasonable to assume that Hindi is the matrix language (Azuma, 1993; Myers-Scotton, 1997) in most of the code-mixed sentences.",
      "startOffset" : 88,
      "endOffset" : 122
    }, {
      "referenceID" : 20,
      "context" : "Parts-of-Speech (POS): Universal POS tagset (Petrov et al., 2011) was used to label the POS of each word as this tagset is applicable to both English and Hindi words.",
      "startOffset" : 44,
      "endOffset" : 65
    }, {
      "referenceID" : 4,
      "context" : "The chunk label tagset is a coarser version of AnnCorra tagset (Bharati et al., 2006).",
      "startOffset" : 63,
      "endOffset" : 85
    }, {
      "referenceID" : 6,
      "context" : "The inter-annotator agreement calculated using Cohen’s κ (Cohen, 1960) came out to be 0.",
      "startOffset" : 57,
      "endOffset" : 70
    }, {
      "referenceID" : 0,
      "context" : "Shallow parsing is the task of identifying and segmenting text into syntactically correlated word groups (Abney, 1992; Harris, 1957).",
      "startOffset" : 105,
      "endOffset" : 132
    }, {
      "referenceID" : 12,
      "context" : "Shallow parsing is the task of identifying and segmenting text into syntactically correlated word groups (Abney, 1992; Harris, 1957).",
      "startOffset" : 105,
      "endOffset" : 132
    }, {
      "referenceID" : 14,
      "context" : "Shallow parsing is a viable alternative to full parsing as shown by (Li and Roth, 2001).",
      "startOffset" : 68,
      "endOffset" : 87
    }, {
      "referenceID" : 19,
      "context" : "Twokenizer2 (Owoputi et al., 2013) which",
      "startOffset" : 12,
      "endOffset" : 34
    }, {
      "referenceID" : 13,
      "context" : "performs well on Hindi-English CSMT (Jamatia et al., 2015) was used to tokenize the utterance into words.",
      "startOffset" : 36,
      "endOffset" : 58
    }, {
      "referenceID" : 16,
      "context" : "While language identification at the document level is a well-established task (McNamee, 2005), identifying language in social media posts has certain challenges associated to it.",
      "startOffset" : 79,
      "endOffset" : 94
    }, {
      "referenceID" : 3,
      "context" : "Similar to (Barman et al., 2014), we performed two experiments treating language identification as a three class (‘hi’, ‘en’, ‘rest’) classification problem.",
      "startOffset" : 11,
      "endOffset" : 32
    }, {
      "referenceID" : 3,
      "context" : "Similar to (Barman et al., 2014), we performed two experiments treating language identification as a three class (‘hi’, ‘en’, ‘rest’) classification problem. The feature set comprised of BNC: normalized frequency of the word in British National Corpus (BNC)3. LEXNORM: binary feature indicating presence of the word in the lexical normalization dataset released by Han et al. (2011). HINDI DICT: binary feature indicating presence of the word in a dictionary of 30,823 transliterated Hindi words as released by Gupta (2012).",
      "startOffset" : 12,
      "endOffset" : 383
    }, {
      "referenceID" : 3,
      "context" : "Similar to (Barman et al., 2014), we performed two experiments treating language identification as a three class (‘hi’, ‘en’, ‘rest’) classification problem. The feature set comprised of BNC: normalized frequency of the word in British National Corpus (BNC)3. LEXNORM: binary feature indicating presence of the word in the lexical normalization dataset released by Han et al. (2011). HINDI DICT: binary feature indicating presence of the word in a dictionary of 30,823 transliterated Hindi words as released by Gupta (2012). NGRAM: word n-grams.",
      "startOffset" : 12,
      "endOffset" : 524
    }, {
      "referenceID" : 18,
      "context" : "First, we obtained character alignments between noisy Hindi words in Roman script (Hr) to normalized Hindi wordsformat(Hw) using GIZA++ (Och and Ney, 2003) on 30,823 Hindi word pairs of the form (Hw - Hr) (Gupta et al.",
      "startOffset" : 136,
      "endOffset" : 155
    }, {
      "referenceID" : 9,
      "context" : "First, we obtained character alignments between noisy Hindi words in Roman script (Hr) to normalized Hindi wordsformat(Hw) using GIZA++ (Och and Ney, 2003) on 30,823 Hindi word pairs of the form (Hw - Hr) (Gupta et al., 2012).",
      "startOffset" : 205,
      "endOffset" : 225
    }, {
      "referenceID" : 5,
      "context" : "Using this model, noisy Hr words were created for Hw words obtained from a dictionary of 1,17,789 Hindi words (Biemann et al., 2007).",
      "startOffset" : 110,
      "endOffset" : 132
    }, {
      "referenceID" : 11,
      "context" : "A similar approach was used for English text normalization, using the English normalization pairs from (Han et al., 2012) and (Liu et al.",
      "startOffset" : 103,
      "endOffset" : 121
    }, {
      "referenceID" : 15,
      "context" : ", 2012) and (Liu et al., 2012) for the noisy channel framework, and Aspell5 as the spell-checker.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 19,
      "context" : "TPOS: Output of Twitter POS tagger (Owoputi et al., 2013).",
      "startOffset" : 35,
      "endOffset" : 57
    } ],
    "year" : 2016,
    "abstractText" : "In this study, the problem of shallow parsing of Hindi-English code-mixed social media text (CSMT) has been addressed. We have annotated the data, developed a language identifier, a normalizer, a part-of-speech tagger and a shallow parser. To the best of our knowledge, we are the first to attempt shallow parsing on CSMT. The pipeline developed has been made available to the research community with the goal of enabling better text analysis of Hindi English CSMT. The pipeline is accessible at 1.",
    "creator" : "LaTeX with hyperref package"
  }
}