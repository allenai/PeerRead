{
  "name" : "1202.3698.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Extended Lifted Inference with Joint Formulas",
    "authors" : [ "Udi Apsel" ],
    "emails" : [ "apsel@cs.bgu.ac.il", "brafman@cs.bgu.ac.il" ],
    "sections" : [ {
      "heading" : null,
      "text" : "The First-Order Variable Elimination (FOVE) algorithm allows exact inference to be applied directly to probabilistic relational models, and has proven to be vastly superior to the application of standard inference methods on a grounded propositional model. Still, FOVE operators can be applied under restricted conditions, often forcing one to resort to propositional inference. This paper aims to extend the applicability of FOVE by providing two new model conversion operators: the first and the primary is joint formula conversion and the second is just-different counting conversion. These new operations allow efficient inference methods to be applied directly on relational models, where no existing efficient method could be applied hitherto. In addition, aided by these capabilities, we show how to adapt FOVE to provide exact solutions to Maximum Expected Utility (MEU) queries over relational models for decision under uncertainty. Experimental evaluations show our algorithms to provide significant speedup over the alternatives."
    }, {
      "heading" : "1 Introduction",
      "text" : "Probabilistic graphical models have been widely used over the last two decades in real-world and research applications. One of their sought after features is the ability to compactly represent a set of interdependencies among random variables, providing a platform for efficient inference methods for both exact [1] and approximate [16] inference.\nProbabilistic Relational Models (PRM) extend the propositional models by introducing the concept of domain entities, along with a richer language which depicts the properties of each entity and the various interactions which they exhibit. Naturally, it is desirable, and often much more efficient, to apply inference directly to the relational model,\nthus avoiding an explicit extraction of the propositional model. The act of exploiting the high level structure in relational models is called lifted inference. This task can be carried out by a family of exact lifted inference algorithms, which are based on the idea of First-Order Variable Elimination (FOVE) [12, 3, 9].\nAn important task which is closely related to probabilistic inference, is decision making under uncertainty. The tight connection between the two tasks is exemplified in the influence diagram model [7], a popular model for decision making. Influence diagrams extend probabilistic models by adding decision and utility components to probabilistic graphical models. The quality of a decision, a set of assignments to decision variables in the influence diagram, is measured by its Expected Utility (EU). Under this principle, the best decision is achieved by maximizing the expected utility, a task that has been studied for both exact resolution [5] and approximation [11]. In the relational models realm, the study of decision making in influence diagrams has focused mainly on first-order MDP [14].\nThe goal of this paper is to extend the applicability of FOVE in two directions. First, we enrich the set of operators used by FOVE, by (a) introducing a novel model conversion method called joint formula conversion, and (b) generalizing the known counting conversion [9] operator to support the conversion of just-different atoms [4]. Joint formula conversion is a procedure which couples together pairs of atomic formulas, by replacing all their occurrences in the model with a new formula, whose range is a Cartesian product of the original pair. As we explain and demonstrate empirically, the conversion allows a subsequent use of efficient inference operators: counting conversion [9] and inversion [3], where previously one would resort to grounding. Additionally, the combination of (a) and (b) allows further lifting in cases that were previously considered hard for lifted inference.\nSecond, we present a solution to decision making in firstorder influence diagrams [7] based on the FOVE algorithm, the first lifted solution to the best of our knowledge. Our method applies a variation of C-FOVE [9] that computes\nmaximum expected utility (MEU) [5]. We show that variations of counting conversion and inversion can lift theMEU computation, much like in the belief assessment and MPE tasks. Similarly to other FOVE variations, experimental evaluations show our lifted method to be substantially more efficient than the propositional alternative.\nWe note that recent works [6, 8, 15] demonstrate the advantage of exploiting the logical structure of first-order formulas (e.g. MLN features [13], preference rules [2]) for the benefit of efficient lifted inference. FOVE, on the other hand, operates under no assumption on the logical structure of the first-order formulas which compose the relational model. A comprehensive comparison study between these different approaches has yet to be conducted."
    }, {
      "heading" : "2 Model Representation",
      "text" : "Based on Markov Logic Decision Network (MLDN) [10] and the work of Milch et al. [9], we present a first-order model which depicts two types of variables: random variables and decision variables, and two types of factors – probability factors and utility factors."
    }, {
      "heading" : "2.1 Atoms, Constraints and Parfactors",
      "text" : "Each variable induced by the model corresponds to a ground atom of the form p(c1, . . . , cn), where p is a predicate of finite range, range(p), and c1, . . . , cn are constant symbols. An atomic formula p(t1, . . . , tn) where ti is a constant or a logical variable, is called an atom. Each logical variable X is bound by a domain dom(X) with cardinality |dom(X)|, or |X|. LV (α) is the set of logical variables referred by α, where α is a formula or a set of formulas. Under a set of assignments v, the notation α(v) is used to depict the values assigned to α.\nA factor f is a pair (A, η), consisting of a set of ground formulas and a potential function η : ∏\nα∈A range(α) → R. Under a set of assignments v, the weight of factor f is wf (v) = η(α1(v), . . . ,αm(v)), where A = {α1, . . . ,αm}. A substitution θ over a set of logical variables L maps each variable in L to a constant symbol or a logical variable. αθ depicts the result of applying a substitution θ on α.\nA constraint C is a pair (F,L), where F is an equational formula on logical variables set L. gr(L : C) is a set of substitutions on L under constraint C, where all logical variables of L are substituted with a constant. Similarly to previous work [9], we require the constraints to be in some normal form, where for each logical variable X , |X : C| has a fixed value regardless of the binding of other logical variables in C. We use var(α) to depict the set of variables specified by α under the set of substitutions gr(L : C), and in-order to distinguish between the two types of variables in var(α), rv(α) is used to depict the set of random vari-\nables in α, and dv(α) depicts the set of decision variables.\nA parfactor g is a tuple (L,C,A, η), comprised of a set of logical variables, a constraint on L, a set of formulas and a potential, respectively. Applying a substitution θ over parfactor g results in g′ = (L′, C ′, Aθ, η), whereL′ andC ′ are obtained by applying substitution on its logical variables, and dropping those mapped to constants. A ground substitution of a parfactor is a factor which was generated by a substitution over all the logical variables. The model contains two types of parfactors, probability and utility, which depict a set of probability and utility factors upon grounding. As a convention, φ depicts a potential of a probability parfactor, and µ depicts a potential of a utility parfactor.\nThe weight of parfactor g, depicted by wg(v), is determined according to its type. The weight of a probability parfactor is wg(v) = ∏\nf∈gr(g) wf (v), and the weight of a utility parfactor is wg(v) = ∑\nf∈gr(g) wf (v). For convenience and clarity, we use the abbreviation η(α1(L1), . . . ,αi(Li), C) to represent a parfactor constrained by C, which contains a set of formulas α1, . . . ,αi with their respective variable scopes L1, . . . , Li. For instance, the notation φ1(s(X), t(Y,X), {X \"= Y }) represents a probability parfactor whose properties are L = {X,Y }, C = ({X \"= Y }, {X,Y }), A = {s, t}, and η = φ1. An alternative notation for constraint C is CX #=Y ."
    }, {
      "heading" : "2.2 Counting Formulas and Histograms",
      "text" : "Counting formulas express a numerical distribution of values on a portion of a formula’s groundings, by counting the number of groundings that are assigned each possible value. Instead of covering each possible assignment, the counting formulas are oblivious to the specific permutations which conform to the count formation. The notation of counting formulas is #X:C [α] where α is the counted atom, X is the counted logical variable, and C is the parfactor’s constraint over the counted population. For example, formula #Y :{X #=Y }[friends(X,Y )] counts the Y population of any given X in atom friends(X,Y ), under constraint X \"= Y . The range of a counting formula γ = #X:C [α], depicted by range(γ), is a set of all possible histograms. A histogram is a set of non-negative integer counters, each corresponding to a specific assignment in range(α), where the sum of all counters is |X : C|."
    }, {
      "heading" : "3 Joint Formula Conversion",
      "text" : ""
    }, {
      "heading" : "3.1 Definition",
      "text" : "A joint formula is a composite of two formulas (atoms or counting formulas), whose range of assignments is a Cartesian product of the range of its components. For example, j(X,Y ) = 〈a(X,Y ), b(Y,X)〉 depicts a joint formula of atoms a(X,Y ) and b(Y,X), over logical variables X\nand Y . If a and b are boolean atoms with range(a) = range(b) = {0, 1}, then range(j) = {0, 1}× {0, 1}. The joined formulas must be of the same type. Namely, both must be decision formulas or random variable formulas.\nJoint formula conversion is the replacement of all instances of a joint formula’s components with the joint formula itself. Similarly to shattering [3], it can be applied at the beginning or during the inference task. The conversion conserves the assignment space of the original model, such that each assignment to ground atoms in the original model is mapped to a single respective assignment in the converted model, and vise versa. Both assignments, in the original model and in the converted model, yield the same results in all parfactors. For example, in a two parfactor model φ(a(X,Y ), b(Y,X)) and µ(p(Z), a(X,Y )), a joint formula conversion for j(X,Y ) = 〈a(X,Y ), b(Y,X)〉 converts the model to φ′(j(X,Y ), j(X,Y )) and µ′(p(Z), j(X,Y )), such that under each assignment 〈va, vb〉 to a ground of j, the converted potentials yield the same values as their original counterparts under assignments va and vb to grounds of a and b, respectively. Parfactor φ′ is compressed further to φ′′(j(X,Y )), since it contains two identical instances of j. The example is illustrated in Table 1."
    }, {
      "heading" : "3.2 Motivation and Example Applications",
      "text" : "In a sense, joint formula conversion is counter-intuitive. Most lifting operators aim to reduce the variable assignment space, or to restructure the model without introducing unnecessary dependencies between variables. Joint formula conversion does the opposite – it deliberately introduces dependencies between formulas. However, this modification in structure may allow the inference task to benefit from lifting operators that would not be used otherwise. More specifically, joint formula conversion is highly efficient in cases where lifting operators are well defined on the joint formula, but not applicable on the separate components of the joint formula.\nLet us demonstrate this with the task of summingout all the random variables from a given parfactor, φ(a(X,Y ), b(Y,X), c(X,Z), d(Z)). Since both counting conversion and inversion are inapplicable in this case, some grounding operation must be applied. However, this overhead can be avoided by applying a joint formula conversion, for which j(X,Y ) = 〈a(X,Y ), b(Y,X)〉. The conversion yields parfactor φ′(j(X,Y ), c(X,Z), d(Z)), which in turn can be resolved by a sequence of lifting operators: (a) Applying counting conversion over j(X,Y ) w.r.t. Y . (b) Eliminating c(X,Z) by inversion. (c) Applying counting conversion over d(Z) w.r.t. Z. (d) Eliminating #Y [j(X,Y )] by inversion. (e) Eliminating #Z [d(Z)] by inversion. The amount of work that was invested in the joint formula conversion is therefore negligible compared with the overall computational benefit.\nIn Section 4, we introduce a variant of counting conversion which allows the conversion of just-different atoms. This newly introduced variation, combined with joint formulas, extends the scope of lifted inference in FOVE even further. For example, Figure 1 presents the group cohesiveness problem, where each member of a given group is examined according to two characteristics: affinity to sports and affinity to alcohol. The problem can be represented by two parfactors: φ1(sportsFan(X), drinks(Y ), friends(X,Y ), CX #=Y ) – the chance of two individuals being friends, and φ2(friends(X,Y ), cohesive, CX #=Y ) – the chance of a group being cohesive.\nIn order to find out what are the chances of a group being cohesive, all variables but cohesive need to be summedout from the model. We start by fusing φ1 and φ2 into φ(sportsFan(X), drinks(Y ), friends(X,Y ), cohesive, CX #=Y ), and eliminating friends(X,Y ) by inversion, resulting in φ′(sportsFan(X), drinks(Y ), cohesive, CX #=Y ). Since counting conversion and inversion are both inapplicable in the model’s current form, we apply a joint formula conversion with j(X) = 〈sportsFan(X), drinks(X)〉. The conversion results in φ′′(j(X), j(Y ), cohesive, CX #=Y ), and can be followed by a counting conversion of the j instances, which are just-different atoms. Hence, the model is converted to φ′′′(#X [j(X)], cohesive), and the inference task resumes without resorting to grounding."
    }, {
      "heading" : "3.3 Logical Variables Mapping",
      "text" : "A logical variables mapping (or simply, mapping) between two formulas α and β, depicted by Mα,β , is an isomorphism from the ordered set of logical variables of α, 'LV (α) = 〈α[1], . . . ,α[|LV (α)|]〉, to the ordered set of logical variables of β, 'LV (β) = 〈β[1], . . . ,β[|LV (β)|]〉, where α[i] and β[j] depict the i-th and j-th logical variables of α and β under argument list ordering, respectively. Pairing of logical variables from α and β is allowed only in cases where they have the same domain. For example, a possible mapping between a(X,Y ) and b(W,Z) is Ma,b = {a[1] ↔ b[2], a[2] ↔ b[1]}, provided that dom(X) = dom(Z) and dom(Y ) = dom(W ). We use Mα→β : 'L to depict a permutation of 'L according to the mapping from α variables to β variables. In the given example,Ma→b : 〈Z,M〉 = 〈M,Z〉.\nA full mapping between α and β is a mapping over all the logical variables of both formulas, and a joint formula conversion is defined according to such a mapping. For example, in model φ(a(X,Y ), b(Y,X)), a joint formula conversion over mapping Ma,b = {a[1] ↔ b[2], a[2] ↔ b[1]} results in the joint formula j(X,Y ) = 〈a(X,Y ), b(Y,X)〉, and in a following conversion φ′(j(X,Y ), j(X,Y )), which can be simplified further to φ′′(j(X,Y )). On the other hand, a joint formula conversion of the same model over a different mapping, Ma,b = {a[1] ↔ b[1], a[2] ↔ b[2]}, results in the conversion φ′(j(X,Y ), j(Y,X)), yielding no computational gain. Hence, joint formula conversions do not necessarily result in a more efficient inference, and their use should be considered only in cases where computational gain is guaranteed."
    }, {
      "heading" : "3.4 Usage and Computational Complexity",
      "text" : "In the context of current C-FOVE implementations, where a greedy algorithm is used to determine which operator to apply next, joint formulas can simply be used when (a) all other lifting attempts fail, and (b) their placement allows subsequent counting conversions and inversions. However, given the proper heuristics, joint formula conversion can be applied at any phase of the inference task.\nThe computational complexity of joint formula conversion is bounded byO(k ·rn+1), where r is the maximum assignment range of any formula in the model, k is the number of parfactors which consist of the joint formulas components, and n is the maximum number of formulas in any of the subject parfactors."
    }, {
      "heading" : "3.5 Joint Shattering",
      "text" : "Before applying a joint formula conversion, a joint shattering has to be carried-out. Joint shattering is identical to the already known shattering [3] process, only that the\nformulas which are about to be joined, α and β, are shattered w.r.t. their instances under the joint formula. Namely, the joint shattering splits the set of parfactors in the model, such that parfactors which contain α( 'Lα) are treated as if they contained β( 'Lβ) as well, where 'Lβ = Mα→β : 'Lα. Similarly, parfactors which contain β( 'Lβ) are treated as if they contained α( 'Lα). Let us demonstrate this with an example. Assume a model φ(a(X,Y ), b(X,Z), CX #=Z) which is about to be applied with a joint formula conversion over mapping Ma,b = {a[1] ↔ b[1], a[2] ↔ b[2]}, where dom(X) = dom(Y ) = dom(Z) = {x1, x2}. A joint formula j(X,Y ) = 〈a(X,Y ), b(X,Y )〉 cannot be placed in the model’s current form, for two reasons. The first, is that there are no constraints which prevent an equality betweenX and Y , hence j(x1, x1) is a possible ground of j in one of the converted parfactor’s grounding. However, j(x1, x1) implies that the set of random variables in the original model includes b(x1, x1), which is untrue. A second reason is that the placement of j would result in parfactor φj(j(X,Y ), j(X,Z), CX #=Z), where the two instances of j entail two sets of ground variables which are neither disjoint nor equal.\nA joint shattering of φ(a(X,Y ), b(X,Z), CX #=Z) treats the parfactor as if it contained both a(X,Z) and b(X,Y ). In this case, the parfactor is split on substitution Y/X , where two parfactors are created: φ1(a(X,X), b(X,Z), CX #=Z), and φ2(a(X,Y ), b(X,Z)), C{X #=Y,X #=Z}). a(X,X) here is practically a different formula than a(X,Y ) where X \"= Y , since the sets of grounds for both are disjoint. Placing the joint formula in the model’s current form should yield parfactors φ1j (a(X,X), j(X,Z), CX #=Z) and φ2j (j(X,Y ), j(X,Z)), C{X #=Y,X #=Z})."
    }, {
      "heading" : "4 Just-Different Counting Conversion",
      "text" : "The notion of just-different atoms was introduced by Braz et al. [4] for the purpose of counting elimination, but has yet to be exploited for the purpose of counting conversion. As mentioned earlier, the combination of counting conversion of just-different atoms with joint formulas, extends the scope of lifted inference and provides motivation to explore this variation of counting conversion. For the purpose of simplicity and clarity, we present a version which converts pairs of just-different atoms. Note that the procedure can be generalized to any number of just-different atom. The simple case of counting conversion, where a single formula is converted, is directly derived from this more general case.\nLet parfactor gη contain two instances of formula α: α1 = α(X,L) and α2 = α(Y, L), where X and Y are logical variables, L is a set of logical variables, X \"∈ L and Y \"∈ L. Let any ground substitution of L produce a set of just-different atoms, namely: for each given substitution of L, choosing one substitution of X restricts Y in only one substitution, and vice versa. An example of such a par-\nfactor is φ(α(Z,X),α(Z, Y ), CX #=Y ). Finally, let both X and Y be owned exclusively by their α instances, such that no other formula in g contains neither X nor Y .\nA counting conversion of formulas α1 and α2 over logical variables X and Y in parfactor gη is a conversion of gη = (Lη, Cη, Aη, η) to gη′ = (Lη′ , Cη′ , Aη′ , η′), by replacing the two α instances with an arity-reduced counting formula#X:Cη [α], and defining a potential η′, such that in probability parfactors\nη′(N, b1, . . . , bk) = ∏\na1,a2∈range(α)\nη(a1, a2, b1, . . . , bk) #(N,a1,a2)\n(1) and in utility parfactors\nη′(N, b1, . . . , bk) = ∑\na1,a2∈range(α)\nη(a1, a2, b1, . . . , bk) ·#(N, a1, a2)\n(2) Where\n#(N, a1, a2) =\n{\n#(N, a1) · ( #(N, a2)− 1 )\na1 = a2 #(N, a1) ·#(N, a2) a1 #= a2\n(3) a1 and a2 are assignments to grounds of α1 and α2, b1, . . . , bk are assignments to grounds of all other formulas, and histogram N = {n1, . . . , nr} is a set of counters for each possible assignment of a ground of α under the conditions r = |range(α)| and\n∑r i=1 ni = |X : C|.\n#(N, a) depicts the value of the entry which counts assignment a. The rest of gη′ properties are obtained by Lη′ = Lη \\ {X,Y }, Aη′ = Aη \\ {α1,α2}, and Cη′ = Cη↓Lη′ (the projection of the remaining logical variables). A number comb(N) is then attributed to each histogram N\ncomb(N) = |X : C|! ∏\na∈range(α) #(N, a)! (4)\nWhere comb(〈χ1,χ2〉) = comb(χ1) · comb(χ2) in joint formulas, and comb(χ) = 1 in atoms."
    }, {
      "heading" : "5 FOVE for MEU",
      "text" : "To capture relational decision making settings, we use a model based on Markov Logic Decision Network (MLDN) [10]. The model includes probability and utility parfactors, and two types of formulas: random variable formulas and decision formulas."
    }, {
      "heading" : "5.1 MEU",
      "text" : "Formally,G = Gφ∪Gµ, whereGφ contains a set of probability parfactors, andGµ contains a set of utility parfactors. The expected utility (EU) of model G under assignment vd to (all) its decision variables is given by:\neu[G](vd) = 1\nZ\n∑\nrv(G)\n∏\ng∈Gφ\nwg(vd) · ∑\ng∈Gµ\nwg(vd) (5)\nIn our setting, we can ignore Z, which is the normalizing constant of the MLDN. The maximum expected utility (MEU) of model G is given by\nmeu[G] = (\nargmax vd eu[G](vd) , max vd\neu[G](vd) ) (6)\nTo illustrate this model, consider Figure 2 which depicts a first-order decision problem, where a product planner has to decide on a line of products for the enterprise market. We seek a decision that maximizes the expect profit, i.e., one with maximum expected utility. The planner needs to determine each product’s set of features and market price, and does so by examining the profile of each of the potential buyers – their yearly revenue and their demand for each of the expected products. In our model, the problem is represented by two parfactors: φ(features(X), price(X), revenue(Y ), demand(Y,X)) and µ(price(X), demand(Y,X)). φ depicts probability weights of various interactions between variables, and µ depicts the utility portion (profit). The set of decision variables is represented by atoms features(X) and price(X), and the set of random variables is represented by revenue(Y ) and demand(Y,X)."
    }, {
      "heading" : "5.2 Challenges in Lifted MEU Computation",
      "text" : "Lifted MEU introduces several challenges which do not exist in ”normal” lifted inference. The first challenge stems from the presence of two types of formulas, decision and random variables, for which separate elimination procedures are defined. Notably, random variable atoms are eliminated by summing-out their effect on the network, whereas decision atoms are maximized-out from the network [5]. Consequently, the number comb(N) which is typically attributed to each histogram N , serves no part in the elimination process of decision formulas. Additionally, decision formulas can be eliminated only from parfactors which contain no random variable formulas.\nThe second challenge arises from the two separate parts of the MEU expression, which depict the weights of two type of parfactors: probability and utility. The complex structure forces the inversion procedure to be more complicated than in belief assessment, but most importantly – it poses a significant restriction on the inversion of decision formulas: decision formulas can be eliminated by inversion\nonly when contained in one type of parfactors. This restriction increases the importance of joint formula conversion, which allows counting conversion to be applied where normally such a use would not be allowed. Joint formulas are in no way a panacea for this inherent nature of the problem, however, without joint formulas many MEU computation tasks unnecessarily resort to propositionalization."
    }, {
      "heading" : "5.3 Framework",
      "text" : "Given a model G, we begin by choosing which operator to apply. We have three lifting operators at our disposal: inversion elimination, counting conversion and joint formula conversion. We also have two grounding operators: propositionalization and counting expansion, which are carriedout identically to C-FOVE. After applying the operator of choice, we are left with a transformed model, G′, whose MEU solution entails the original model’s MEU.\nWe continue to apply some operator of choice, repeatedly, until all remaining formulas are (a) decision formulas, and (b) ground formulas. Counting formulas with no active logical variables are considered to be ground formulas as well. Lastly, an exhaustive search is issued on the assignment space, in-order to find the maximizing assignments of the remaining ground formulas. A final backward phase, similar to the one used in lifted MPE [4], resolves the assignments of the eliminated decision formulas."
    }, {
      "heading" : "5.4 Inversion Elimination",
      "text" : "Let Gα denote the set of parfactors which contain formula α in model G. Inversion elimination [3] of formula α can be applied to modelG under three conditions: (a) ModelG is shattered w.r.t. α. (b) For each g ∈ Gα, α contains all the logical variables of g. (c) The set of formulas in each g ∈ Gα contains only one instance of α. Inversion eliminates α from the model and produces a residual model G′. During the elimination procedure, product fusion and summation fusion are repeatedly used, forming a parfactor with a single instance of α which contains all the logical variables of its container parfactor. Product fusion is defined in [3], and summation fusion is a similar procedure, with the distinction of summing potentials instead of applying multiplication. We now define formally, the procedure for eliminating random variable formulas, and the procedure for the elimination of decision formulas."
    }, {
      "heading" : "5.4.1 Eliminating Random Variable Formulas",
      "text" : "We assume formula α to reside in both probability and utility parfactors1. We start by merging all probability parfac-\n1If this is not the case, a ”stub” parfactor η(α) is added to the model, such that α will then be contained in both types of parfactors. All table entries in a stub probability parfactor are 1, and all table entries in a stub utility parfactor are 0.\ntors which contain α into gφ = (Lφ, Cφ, Aφ,φ), using a product fusion. Let gµ = (Lµ, Cµ, Aµ, µ) be some utility parfactor which contains α, and let gσ = (Lσ, Cσ, Aσ,σ) be a product fusion of gφ with gµ. Let Lαφ and Lασ denote the set of logical variables which are unique to α in parfactors gφ and gσ , respectively. A parfactor gφ′ = (Lφ′ , Cφ′ , Aφ′ ,φ′) is obtained by calculating\nφsum(b1, . . . , bk) = ∑\na∈range(α)\ncomb(a) · φ(a, b1, . . . , bk) (7)\nFollowed by\nφ′(b1, . . . , bk) = φ sum(b1, . . . , bk) |Lαφ :Cφ| (8)\nWhere Aφ′ = Aφ \\ {α}, Lφ′ = Lφ \\ Lαφ , and Cφ′ = Cφ\n↓ Lφ′ . As a convention, b1, . . . , bk depict k assignments to all formulas in the subject parfactor, except formula α. Next, for each of the gµ parfactors, a respective gµ′ = (Lµ′ , Cµ′ , Aµ′ , µ′) is obtained by calculating\nσsum(b1, . . . , bn) = ∑\na∈range(α)\ncomb(a) · σ(a, b1, . . . , bn) (9)\nFollowed by\nµ′(b1, . . . , bn) = σsum(b1, . . . , bn) φsum(b1, . . . , bk) · |Lασ : Cσ| (10)\nWhereAµ′ = Aµ\\{α}, Lµ′ = Lµ\\Lασ , andCµ′ = Cµ ↓ Lµ′ . Note that k ≤ n, since Aφ ⊆ Aσ as a result of gσ being a fusion of gφ with gµ. Finally, a residual model G′ is obtained by replacing gφ with gφ′ , and replacing each of the gµ parfactors with its respective gµ′ .\nEquations 8 and 10 instruct of exponentiation and multiplication in the combined domain sizes of the removed logical variables. In effect, these operations express the nature of inversion, where numerous variables are eliminated simultaneously. We demonstrate this with a two parfactor model φ(p(X), q(X,Y )) and µ(r(Y ), q(X,Y )), for which we aim to eliminate random variable atom q(X,Y ). The elimination of q(X,Y ) is conducted in several steps. First, φsum is obtained by φsum = ∑\nq φ. Since the elimination of q removes logical variable Y from parfactor φ(p(X), q(X,Y )), φ′ is obtained by φ′ = (φsum)|Y |. Next, we fuse φ(p(X), q(X,Y )) with µ(r(Y ), q(X,Y ), resulting in σ(p(X), r(Y ), q(X,Y )). σsum is then obtained by σsum = ∑\nq φ · µ. Here, a removal of q from σ(p(X), r(Y ), q(X,Y )) does not reduce the set of logical variables. Hence, µ′ is obtained by µ′ = σ sum\nφsum , without multiplication. A numerical example is given in Table 2."
    }, {
      "heading" : "5.4.2 Eliminating Decision Formulas",
      "text" : "Here, two additional precondition are required: (a) formula α is contained exclusively in utility parfactors or probability parfactors, but not in both. (b) All formulas which share\na parfactor with α are decision formulas. Next, all parfactors which contain α are fused into gη = (Lη, Cη, Aη, η). gη is obtained by a product fusion if α is contained in probability parfactors, and by a summation fusion otherwise. A parfactor gη′ = (Lη′ , Cη′ , Aη′ , η′) is then calculated by maximizing-out the entries of α, as follows\nη′ = (\nmax α\nη )|Lαη :C| in probability parfactors (11)\nη′ = (\nmax α\nη ) · |Lαη : C| in utility parfactors (12)\nLαη depicts the set of logical variables which are unique to α in gη , Aη′ = Aη \\ {α}, Lη′ = Lη \\ Lαη , and Cη′ = Cη\n↓ Lη′ . The assignment to α which formed each entry in η′ is recorded for a backward phase. Finally, a residual model G′ is obtained by replacing gη with gη′ .\nLet us examine model φ(e(X), d(X,Y )), where both e and d are decision atoms. d(X,Y ) is eliminated from the model by calculating φ′ = maxd φ|Y |, and recording the assignments to d which yield the result entries. The exponentiation in |Y | is the result of logical variable Y being removed from the parfactor. The example is illustrated in Table 3."
    }, {
      "heading" : "6 Experimental Evaluation",
      "text" : "We present results of three sets of experiments, all conducted on a E7400 Intel duo core machine, with 2.8GHz CPU speed and 3Gb of RAM. The propositional variable elimination for MEU was implemented in Java, with emphasis on performance, using a minimum deficiency heuristics [1] for variable ordering. Our lifted inference implementation is based on the Bayesian Logic Inference (BLOG) Engine, as found in http://people.csail. mit.edu/milch/blog/index.html, and was implemented in Java as well. Joint formula conversions were injected manually, prior to running the inference task.\nFigure 3 depicts the results of lifted probabilistic inference in model φ(p(X), q(X), r(Y ), s(Y )). As can be seen, without joint formulas the model resorts to propositional inference and the problem becomes intractable. By introducing the joint formula j(X) = 〈p(X), q(X)〉, the problem is quickly solved. Figure 4 compares the results of propositional MEU vs. lifted MEU, in model φ1(p(Y ), q(X,Y ), d(Z)), φ2(e(X), r(X)), µ(e(X), q(X,Y )), where d and e are decision atoms. Here, as in other FOVE variants, computation time is polynomial in the varying sizes of the domain, whereas computation time for the propositional algorithm is exponential in the size of the domain.\nIn Figure 5, three inference methods are compared: propositional inference, lifted inference, and lifted inference with joint formulas. Here, the propositional algorithm outperforms the lifted algorithm, but with the addition of joint formulas, the lifted algorithm outperforms the propositional algorithm, similarly to previous figures. A closer examination reveals the reason. The input model contains parfactors φ(d(X), e(X), p(X)), µ1(q(X,Y1), q(X,Y2), p(X)) and µ2(e(X), r(X), f(X)), where d, e and f are decision atoms. Elimination of r(X) by inversion, followed by the elimination of f(X) by inversion, results in parfactor µ′2(e(X)). Two counting conversions of q instances over Y1 and Y2, result in parfactor µ′1(#Y1 [q(X,Y1)], p(X)), where #Y1 [q(X,Y1)] is then eliminated by inversion to construct parfactor µ′′1(p(X)). Since p(X) is included in both φ and µ′′1 , its elimination by inversion converts both parfactors into φ′(d(X), e(X)), and µ′′′1 (d(X), e(X)).\nAt this phase, the decision atoms d(X) and e(X) cannot be eliminated by inversion, since they both reside in probability parfactors as well as in utility parfactors. Moreover, the fact that d(X) appears with e(X) in the same parfactor, prevents a counting conversion of both d(X) and e(X). The lifted algorithm resolves this conflict by grounding all the instances of the decision atoms, and continuing with a propositional model. However, the propositional algorithm was implemented much more efficiently than the lifted algorithm, which accounts for the performance gap between the two implementations. Once a joint formula j(X) = 〈d(X), e(X)〉 replaces all instances of d and e, the X logical variable could be counted out, resulting in instances of#X [j(X)], and in an efficient lifted inference."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We introduced a novel contribution to the field of lifted inference, a model conversion method called joint formula conversion, and a following contribution which extends the counting conversion procedure. We then demonstrated how the new methods accelerates the task of lifted inference in some models. The use of joint formulas need not be limited to exact inference. In fact, we believe that the notion\n0\n1\n2\n3\n4\n5 x 10 4\nDomain sizes of X, Y and Z\npropositional inference lifted inference\n(decision atoms in asterisk)\nof joint formulas is generic enough to be adopted by some other relational models, such as relational MDP.\nOur second contribution, the C-FOVE adaptation for MEU, is the first algorithm, to the best of our knowledge, to lift MEU computation. One interesting aspect of lifted MEU is that it generalizes many common probabilistic inference tasks. MPE and belief assessment, for instance, are both private cases of MEU computation, but more importantly – lifted MAP estimation, which has yet to be introduced, can be defined as a private case of lifted MEU, where the computational model contains only probability parfactors."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank the anonymous reviewers for their comments and useful suggestions. The authors were partly supported by ISF Grant 1101/07, the Paul Ivanier Center for Robotics Research and Production Management, and the Lynn and William Frankel Center for Computer Science."
    } ],
    "references" : [ {
      "title" : "Nonserial Dynamic Programming",
      "author" : [ "U. Bertele", "F. Brioschi" ],
      "venue" : "Academic Press, Inc.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1972
    }, {
      "title" : "Relational preference rules for control",
      "author" : [ "R.I. Brafman" ],
      "venue" : "Artif. Intell., 175(7-8):1180–1193",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Lifted firstorder probabilistic inference",
      "author" : [ "R. de Salvo Braz", "E. Amir", "D. Roth" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2005
    }, {
      "title" : "Mpe and partial inversion in lifted probabilistic variable elimination",
      "author" : [ "R. de Salvo Braz", "E. Amir", "D. Roth" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2006
    }, {
      "title" : "A new perspective on algorithms for optimizing policies under uncertainty",
      "author" : [ "R. Dechter" ],
      "venue" : "AIPS, pages 72–81",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Exploiting logical structure in lifted probabilistic inference",
      "author" : [ "V. Gogate", "P. Domingos" ],
      "venue" : "AAAI 2010 Workshop on Statistical and Relational Artificial Intelligence (STAR-AI)",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Influence diagrams",
      "author" : [ "R.A. Howard", "J.E. Matheson" ],
      "venue" : "Decision Analysis, 2(3):127–143",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Lifted inference seen from the other side : The tractable features",
      "author" : [ "A. Jha", "V. Gogate", "A. Meliou", "D. Suciu" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Lifted probabilistic inference with counting formulas",
      "author" : [ "B. Milch", "L.S. Zettlemoyer", "K. Kersting", "M. Haimes", "L.P. Kaelbling" ],
      "venue" : "AAAI, pages 1062–1068",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "A language for relational decision theory, in proceedings of the international workshop on statistical relational learning",
      "author" : [ "A. Nath", "P. Domingos" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2009
    }, {
      "title" : "Efficient belief propagation for utility maximization and repeated inference",
      "author" : [ "A. Nath", "P. Domingos" ],
      "venue" : "AAAI",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "First-order probabilistic inference",
      "author" : [ "D. Poole" ],
      "venue" : "IJ- CAI, pages 985–991",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Markov logic networks",
      "author" : [ "M. Richardson", "P. Domingos" ],
      "venue" : "Machine Learning, 62(1-2):107–136",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Practical solution techniques for first-order mdps",
      "author" : [ "S. Sanner", "C. Boutilier" ],
      "venue" : "Artif. Intell., 173(5- 6):748–788",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Lifted Probabilistic Inference by First-Order Knowledge Compilation",
      "author" : [ "G. Van den Broeck", "N. Taghipour", "W. Meert", "J. Davis", "L. De Raedt" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2011
    }, {
      "title" : "Generalized belief propagation",
      "author" : [ "J.S. Yedidia", "W.T. Freeman", "Y. Weiss" ],
      "venue" : "NIPS, pages 689–695",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2000
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "One of their sought after features is the ability to compactly represent a set of interdependencies among random variables, providing a platform for efficient inference methods for both exact [1] and approximate [16] inference.",
      "startOffset" : 192,
      "endOffset" : 195
    }, {
      "referenceID" : 15,
      "context" : "One of their sought after features is the ability to compactly represent a set of interdependencies among random variables, providing a platform for efficient inference methods for both exact [1] and approximate [16] inference.",
      "startOffset" : 212,
      "endOffset" : 216
    }, {
      "referenceID" : 11,
      "context" : "This task can be carried out by a family of exact lifted inference algorithms, which are based on the idea of First-Order Variable Elimination (FOVE) [12, 3, 9].",
      "startOffset" : 150,
      "endOffset" : 160
    }, {
      "referenceID" : 2,
      "context" : "This task can be carried out by a family of exact lifted inference algorithms, which are based on the idea of First-Order Variable Elimination (FOVE) [12, 3, 9].",
      "startOffset" : 150,
      "endOffset" : 160
    }, {
      "referenceID" : 8,
      "context" : "This task can be carried out by a family of exact lifted inference algorithms, which are based on the idea of First-Order Variable Elimination (FOVE) [12, 3, 9].",
      "startOffset" : 150,
      "endOffset" : 160
    }, {
      "referenceID" : 6,
      "context" : "The tight connection between the two tasks is exemplified in the influence diagram model [7], a popular model for decision making.",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 4,
      "context" : "Under this principle, the best decision is achieved by maximizing the expected utility, a task that has been studied for both exact resolution [5] and approximation [11].",
      "startOffset" : 143,
      "endOffset" : 146
    }, {
      "referenceID" : 10,
      "context" : "Under this principle, the best decision is achieved by maximizing the expected utility, a task that has been studied for both exact resolution [5] and approximation [11].",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 13,
      "context" : "In the relational models realm, the study of decision making in influence diagrams has focused mainly on first-order MDP [14].",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 8,
      "context" : "First, we enrich the set of operators used by FOVE, by (a) introducing a novel model conversion method called joint formula conversion, and (b) generalizing the known counting conversion [9] operator to support the conversion of just-different atoms [4].",
      "startOffset" : 187,
      "endOffset" : 190
    }, {
      "referenceID" : 3,
      "context" : "First, we enrich the set of operators used by FOVE, by (a) introducing a novel model conversion method called joint formula conversion, and (b) generalizing the known counting conversion [9] operator to support the conversion of just-different atoms [4].",
      "startOffset" : 250,
      "endOffset" : 253
    }, {
      "referenceID" : 8,
      "context" : "As we explain and demonstrate empirically, the conversion allows a subsequent use of efficient inference operators: counting conversion [9] and inversion [3], where previously one would resort to grounding.",
      "startOffset" : 136,
      "endOffset" : 139
    }, {
      "referenceID" : 2,
      "context" : "As we explain and demonstrate empirically, the conversion allows a subsequent use of efficient inference operators: counting conversion [9] and inversion [3], where previously one would resort to grounding.",
      "startOffset" : 154,
      "endOffset" : 157
    }, {
      "referenceID" : 6,
      "context" : "Second, we present a solution to decision making in firstorder influence diagrams [7] based on the FOVE algorithm, the first lifted solution to the best of our knowledge.",
      "startOffset" : 82,
      "endOffset" : 85
    }, {
      "referenceID" : 8,
      "context" : "Our method applies a variation of C-FOVE [9] that computes",
      "startOffset" : 41,
      "endOffset" : 44
    }, {
      "referenceID" : 4,
      "context" : "maximum expected utility (MEU) [5].",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 5,
      "context" : "We note that recent works [6, 8, 15] demonstrate the advantage of exploiting the logical structure of first-order formulas (e.",
      "startOffset" : 26,
      "endOffset" : 36
    }, {
      "referenceID" : 7,
      "context" : "We note that recent works [6, 8, 15] demonstrate the advantage of exploiting the logical structure of first-order formulas (e.",
      "startOffset" : 26,
      "endOffset" : 36
    }, {
      "referenceID" : 14,
      "context" : "We note that recent works [6, 8, 15] demonstrate the advantage of exploiting the logical structure of first-order formulas (e.",
      "startOffset" : 26,
      "endOffset" : 36
    }, {
      "referenceID" : 12,
      "context" : "MLN features [13], preference rules [2]) for the benefit of efficient lifted inference.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 1,
      "context" : "MLN features [13], preference rules [2]) for the benefit of efficient lifted inference.",
      "startOffset" : 36,
      "endOffset" : 39
    }, {
      "referenceID" : 9,
      "context" : "Based on Markov Logic Decision Network (MLDN) [10] and the work of Milch et al.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 8,
      "context" : "[9], we present a first-order model which depicts two types of variables: random variables and decision variables, and two types of factors – probability factors and utility factors.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "Similarly to previous work [9], we require the constraints to be in some normal form, where for each logical variable X , |X : C| has a fixed value regardless of the binding of other logical variables in C.",
      "startOffset" : 27,
      "endOffset" : 30
    }, {
      "referenceID" : 2,
      "context" : "Similarly to shattering [3], it can be applied at the beginning or during the inference task.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 0,
      "context" : "A logical variables mapping (or simply, mapping) between two formulas α and β, depicted by Mα,β , is an isomorphism from the ordered set of logical variables of α, ' LV (α) = 〈α[1], .",
      "startOffset" : 177,
      "endOffset" : 180
    }, {
      "referenceID" : 0,
      "context" : ",α[|LV (α)|]〉, to the ordered set of logical variables of β, ' LV (β) = 〈β[1], .",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 0,
      "context" : "For example, a possible mapping between a(X,Y ) and b(W,Z) is Ma,b = {a[1] ↔ b[2], a[2] ↔ b[1]}, provided that dom(X) = dom(Z) and dom(Y ) = dom(W ).",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 1,
      "context" : "For example, a possible mapping between a(X,Y ) and b(W,Z) is Ma,b = {a[1] ↔ b[2], a[2] ↔ b[1]}, provided that dom(X) = dom(Z) and dom(Y ) = dom(W ).",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 1,
      "context" : "For example, a possible mapping between a(X,Y ) and b(W,Z) is Ma,b = {a[1] ↔ b[2], a[2] ↔ b[1]}, provided that dom(X) = dom(Z) and dom(Y ) = dom(W ).",
      "startOffset" : 84,
      "endOffset" : 87
    }, {
      "referenceID" : 0,
      "context" : "For example, a possible mapping between a(X,Y ) and b(W,Z) is Ma,b = {a[1] ↔ b[2], a[2] ↔ b[1]}, provided that dom(X) = dom(Z) and dom(Y ) = dom(W ).",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "For example, in model φ(a(X,Y ), b(Y,X)), a joint formula conversion over mapping Ma,b = {a[1] ↔ b[2], a[2] ↔ b[1]} results in the joint formula j(X,Y ) = 〈a(X,Y ), b(Y,X)〉, and in a following conversion φ′(j(X,Y ), j(X,Y )), which can be simplified further to φ′′(j(X,Y )).",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 1,
      "context" : "For example, in model φ(a(X,Y ), b(Y,X)), a joint formula conversion over mapping Ma,b = {a[1] ↔ b[2], a[2] ↔ b[1]} results in the joint formula j(X,Y ) = 〈a(X,Y ), b(Y,X)〉, and in a following conversion φ′(j(X,Y ), j(X,Y )), which can be simplified further to φ′′(j(X,Y )).",
      "startOffset" : 98,
      "endOffset" : 101
    }, {
      "referenceID" : 1,
      "context" : "For example, in model φ(a(X,Y ), b(Y,X)), a joint formula conversion over mapping Ma,b = {a[1] ↔ b[2], a[2] ↔ b[1]} results in the joint formula j(X,Y ) = 〈a(X,Y ), b(Y,X)〉, and in a following conversion φ′(j(X,Y ), j(X,Y )), which can be simplified further to φ′′(j(X,Y )).",
      "startOffset" : 104,
      "endOffset" : 107
    }, {
      "referenceID" : 0,
      "context" : "For example, in model φ(a(X,Y ), b(Y,X)), a joint formula conversion over mapping Ma,b = {a[1] ↔ b[2], a[2] ↔ b[1]} results in the joint formula j(X,Y ) = 〈a(X,Y ), b(Y,X)〉, and in a following conversion φ′(j(X,Y ), j(X,Y )), which can be simplified further to φ′′(j(X,Y )).",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 0,
      "context" : "On the other hand, a joint formula conversion of the same model over a different mapping, Ma,b = {a[1] ↔ b[1], a[2] ↔ b[2]}, results in the conversion φ′(j(X,Y ), j(Y,X)), yielding no computational gain.",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 0,
      "context" : "On the other hand, a joint formula conversion of the same model over a different mapping, Ma,b = {a[1] ↔ b[1], a[2] ↔ b[2]}, results in the conversion φ′(j(X,Y ), j(Y,X)), yielding no computational gain.",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 1,
      "context" : "On the other hand, a joint formula conversion of the same model over a different mapping, Ma,b = {a[1] ↔ b[1], a[2] ↔ b[2]}, results in the conversion φ′(j(X,Y ), j(Y,X)), yielding no computational gain.",
      "startOffset" : 112,
      "endOffset" : 115
    }, {
      "referenceID" : 1,
      "context" : "On the other hand, a joint formula conversion of the same model over a different mapping, Ma,b = {a[1] ↔ b[1], a[2] ↔ b[2]}, results in the conversion φ′(j(X,Y ), j(Y,X)), yielding no computational gain.",
      "startOffset" : 119,
      "endOffset" : 122
    }, {
      "referenceID" : 2,
      "context" : "Joint shattering is identical to the already known shattering [3] process, only that the formulas which are about to be joined, α and β, are shattered w.",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "Assume a model φ(a(X,Y ), b(X,Z), CX #=Z) which is about to be applied with a joint formula conversion over mapping Ma,b = {a[1] ↔ b[1], a[2] ↔ b[2]}, where dom(X) = dom(Y ) = dom(Z) = {x1, x2}.",
      "startOffset" : 125,
      "endOffset" : 128
    }, {
      "referenceID" : 0,
      "context" : "Assume a model φ(a(X,Y ), b(X,Z), CX #=Z) which is about to be applied with a joint formula conversion over mapping Ma,b = {a[1] ↔ b[1], a[2] ↔ b[2]}, where dom(X) = dom(Y ) = dom(Z) = {x1, x2}.",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 1,
      "context" : "Assume a model φ(a(X,Y ), b(X,Z), CX #=Z) which is about to be applied with a joint formula conversion over mapping Ma,b = {a[1] ↔ b[1], a[2] ↔ b[2]}, where dom(X) = dom(Y ) = dom(Z) = {x1, x2}.",
      "startOffset" : 138,
      "endOffset" : 141
    }, {
      "referenceID" : 1,
      "context" : "Assume a model φ(a(X,Y ), b(X,Z), CX #=Z) which is about to be applied with a joint formula conversion over mapping Ma,b = {a[1] ↔ b[1], a[2] ↔ b[2]}, where dom(X) = dom(Y ) = dom(Z) = {x1, x2}.",
      "startOffset" : 145,
      "endOffset" : 148
    }, {
      "referenceID" : 3,
      "context" : "[4] for the purpose of counting elimination, but has yet to be exploited for the purpose of counting conversion.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "To capture relational decision making settings, we use a model based on Markov Logic Decision Network (MLDN) [10].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 4,
      "context" : "Notably, random variable atoms are eliminated by summing-out their effect on the network, whereas decision atoms are maximized-out from the network [5].",
      "startOffset" : 148,
      "endOffset" : 151
    }, {
      "referenceID" : 3,
      "context" : "A final backward phase, similar to the one used in lifted MPE [4], resolves the assignments of the eliminated decision formulas.",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 2,
      "context" : "Inversion elimination [3] of formula α can be applied to modelG under three conditions: (a) ModelG is shattered w.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 2,
      "context" : "Product fusion is defined in [3], and summation fusion is a similar procedure, with the distinction of summing potentials instead of applying multiplication.",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 0,
      "context" : "The propositional variable elimination for MEU was implemented in Java, with emphasis on performance, using a minimum deficiency heuristics [1] for variable ordering.",
      "startOffset" : 140,
      "endOffset" : 143
    } ],
    "year" : 2011,
    "abstractText" : "The First-Order Variable Elimination (FOVE) algorithm allows exact inference to be applied directly to probabilistic relational models, and has proven to be vastly superior to the application of standard inference methods on a grounded propositional model. Still, FOVE operators can be applied under restricted conditions, often forcing one to resort to propositional inference. This paper aims to extend the applicability of FOVE by providing two new model conversion operators: the first and the primary is joint formula conversion and the second is just-different counting conversion. These new operations allow efficient inference methods to be applied directly on relational models, where no existing efficient method could be applied hitherto. In addition, aided by these capabilities, we show how to adapt FOVE to provide exact solutions to Maximum Expected Utility (MEU) queries over relational models for decision under uncertainty. Experimental evaluations show our algorithms to provide significant speedup over the alternatives.",
    "creator" : "dvips(k) 5.99 Copyright 2010 Radical Eye Software"
  }
}