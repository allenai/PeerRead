{
  "name" : "1706.02209.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Improving Max-Sum through Decimation to Solve Loopy Distributed Constraint Optimization Problems",
    "authors" : [ "J. Cerquides", "R. Emonet", "J.A. Rodriquez-Aguilar" ],
    "emails" : [ "cerquide@iiia.csic.es", "jar@iiia.csic.es", "remi.emonet@univ-st-etienne.fr", "picard@emse.fr" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In the context of multi-agent systems, distributed constraint optimization problems (DCOP) are a convenient to model coordination issues agents have to face, like resource allocation, distributed planning or distributed configuration. In a DCOP, agents manage one or more variables they have to assign a value (e.g. a goal, a decision), while taking into account constraints with other agents. Solving a DCOP consists in making agents communicate as to minimize the violation of these constraints. Several solution methods exist to solve such problems, from complete and optimal solutions, to approximate ones.When dealingwith larger scales (thousands of variables), approximate methods are solutions of choice. Indeed, complete methods, like ADOPT or DPOP, suffer exponential computation and/or communication cost in general settings [10,15]. As a consequence, in some large settings, approximate methods are better candidates, as evidenced by the extensive literature on the subject (see [1] for a complete review). One major difficulty for approximate method to solve DCOP is the presence of cycles in the constraint graph (or factor graph). Among the aforementioned methods, inference-based ones, like Max-Sum [3] and its extensions like [16], have demonstrated good performance even on loopy settings. However, there exists some cases, with numerous loops or large induced width of the constraint graph, where they perform badly, which translates into a larger number of messages, a longer time to convergence and a final solution with bad quality.\nOne original approach to cope with loopy graphs is to break loops by decimating variables during the solving process. Decimation is a method inspired by statistical physics, and applied in belief-propagation, which consists in fixing the value of a variable, using the marginal values as the decision criteria to select the variable to decimate [13]. The decimation is processed regularly after the convergence of a classical belief-propagation procedure. In [11], decimation has been used in the constraint satisfaction framework, for solving centralized k-satisfiability problems [11]. Inspired by this concept, we propose a general framework for applying decimation in the DCOP setting. Other works proposed Max-Sum_AD_VP as to improve Max-Sum performance on loopy graphs [20]. The idea is to perform the inferencemechanism through an overlay directed\nar X\niv :1\n70 6.\n02 20\n9v 1\n[ cs\n.M A\n] 7\nJ un\n2 01\n7\nacyclic graph, to remove loops, and to alternating the direction of edges at a fixed frequency as to improve the sub-optimal solution found with the previous direction. One mechanism within one of these extensions, namely value propagation, can be viewed as a temporary decimation.\nAgainst this background, the main goal of this paper is to propose a general framework for installing decimation in Max-Sum for solving DCOP. More precisely, we make the following contributions:\n1. We propose a parametric solution method, namely DeciMaxSum, to implement decimation in Max-Sum. It takes three fundamental parameters for decimation: (i) a policy stating when to trigger decimation, (ii) a policy stating which variables to decimate, and (iii) a policy stating which value to assign to decimated variables. The flexibility of DeciMaxSum comes from the fact that any policy from (1i) can be combined with any policy from (1ii) and (1iii). 2. We propose a library of decimation policies; some inspired by the state-of-the-art and some original ones. Many combinations of policies are possible, depending on the problem to solve. 3. We implement and evaluate some of these combinations of decimation policies on classical DCOP benchmarks (meeting scheduling and Ising models), against state-of-the-art methods like standard Max-Sum and Max-Sum_AD_VP.\nThe rest of the paper is organized as follows. Section 2 expounds some background on DCOP and expounds the decimation algorithm from which our algorithm DeciMaxSum is inspired. Section 3 defines the general framework of DeciMaxSum, and several examples of decimation policies. Section 4 presents results and analyses of experimenting DeciMaxSum, with different combinations of decimation policies, against Max-Sum and Max-Sum_AD_VP. Finally, Section 5 concludes this paper with some perspectives."
    }, {
      "heading" : "2 Background",
      "text" : "This section expounds the DCOP framework and some related belief-propagation algorithms from the literature are discussed concerning the mechanisms to handle cycles in constraint graphs."
    }, {
      "heading" : "2.1 Disributed Constraint Optimization Problems",
      "text" : "One way to model the coordination problem between smart objects is to formalize the problem as a distributed constraint optimization problem.\nDefinition 1 (DCOP). A discrete Distributed Constraint Optimization Problem (or DCOP) is a tuple 〈A,X ,D, C, µ〉, where: A = {a1, . . . , a|A|} is a set of agents; X = {x1, . . . , xN} are variables owned by the agents;D = {Dx1 , . . . ,DxN} is a set of finite domains, such that variable xi takes values in Dxi = {v1, . . . , vk}; C = {u1, . . . , uM} is a set of soft constraints, where each ui defines a utility ∈ R ∪ {−∞} for each combination of assignments to a subset of variables Xi ⊆ X (a constraint is initially known only to the agents involved); µ : X → A is a function mapping variables to their associated agent. A solution to the DCOP is an assignment X ∗ = {x∗1, . . . , x∗N} to all variables that maximizes the overall sum of costs4:\nM∑ m=1 um(Xm) (1)\n4 Note that the notion of cost can be replaced by the notion of cost∈ R∪{+∞}. In this case, solving a DCOP is a minimization problem of the overall sum of costs.\nAs highlighted in [1], DCOPs have been widely studied and applied in many reference domains, and have many interesting features: (i) strong focus on decentralized approaches where agents negotiate a joint solution through local message exchange; (ii) solution techniques exploit the structure of the domain (by encoding this into constraints) to tackle hard computational problems; (iii) there is a wide choice of solutions for DCOPs ranging from complete algorithms to suboptimal algorithms.\nA binary DCOP can be represented as a constraint graph, where vertices represent variables, and edge represent binary constraints. In the case of n-ary constraints, a DCOP can be represented as a factor graph: an undirected bipartite graph in which vertices represent variables and constraints (called factors), and an edge exists between a variable and a constraint if the variable is in the scope of the constraint.\nDefinition 2 (Factor Graph). A factor graph of a DCOP as in Def. 1, is a bipartite graph FG = 〈X , C, E〉, where the set of variable vertices corresponds to the set of variablesX , the set of factor vertices corresponds to the set constraints C, and the set of edges isE = {eij | xi ∈ Xj}.\nWhen the graph representing the DCOP contains at least a cycle, we call it a cyclic DCOP; otherwise, it is acyclic.\nA large literature exists on algorithms for solving DCOPs which fall into two categories. On the one hand, complete algorithms like ADOPT and its extensions [9], or inference algorithms like DPOP [15] or ActionGDL [19], are optimal, but mainly suffer from expensive memory (e.g. exponential for DPOP) or communication (e.g. exponential for ADOPT) load –which we may not be able to afford in a constrained infrastructure, like in sensor networks. On the other hand, approximate algorithms like Max-Sum [3] or MGM [8] have the great advantage of being fast with a limited memory print and communication load, but losing optimality in some settings –e.g. Max-Sum is optimal on acyclic DCOPs, and may achieve good quality guarantee on some settings.\nThe aforementioned algorithms mainly exploit the fact that an agent’s utility (or constraint’s cost) depends only on a subset of other agents’ decision variables, and that the global utility function (or cost function) is a sum of each agent’s utility (constraint’s cost). In this paper, we are especially interested in belief-propagation-based algorithms, like Max-Sum, where the notion of marginal values describes the dependency of the global utility function on variables."
    }, {
      "heading" : "2.2 From Belief-Propagation to Max-Sum",
      "text" : "Belief propagation (BP), i.e. sum-product message passing method, is a potentially distributed algorithm for performing inference on graphical models, and can operate on factor graphs representing a product of M factors [7]: F (x) = ∏M m=1 fm(Xm) . The sum-product algorithm provides an efficient local message passing procedure to compute the marginal functions of all variables simultaneously. The marginal function, zn(xn) describes the total dependency of the global function F (x) on variable xn: zn(xn) = ∑ {x′},n′ 6=n F (Xn′).\nBP operates iteratively propagating messages mi→j (tables associating marginals to each value of variables) along the edges of the factor graph.When the factor graph is a tree, BP algorithm computes the exact marginals and converge in a finite number a steps depending on the diameter of the graph [7]. Max-product is an alternative version of sum-product which computes the maximum value instead of the sum.\nBuilt as a derivative of max-product, Max-Sum is an approximate algorithm to solve DCOP [3]. The main evolution is the way messages are assessed, to pass from product to sum operator through logarithmic translation. And as a consequence, Max-Sum computes an assignment X ∗\nAlgorithm 1: The BP-guided decimation algorithm from [11] Data: A factor graph representing a k-satisfiability problem Result: A feasible assignment X ∗ or FAIL\n1 initialize BP messages 2 U ← ∅ 3 for t = 1, . . . , n do 4 run BP until the stopping criterion is met 5 choose xi ∈ X \\ U uniformly at random 6 compute the BP marginal zi(xi) 7 choose x∗i distributed according to zi 8 fix xi = x∗i 9 U ← U ∪ {xi}\n10 simplify the factor graph 11 if a contradiction is found, return FAIL\n12 return X ∗\nthat maximizes the DCOP objective in Equation 1. Depending on the DCOP to solve, MaxSum may be used with two different termination rules: (i) continue until convergence (no more exchanged messages, because when a variables or a factor receives twice the same message from the same emitter it does not propagates); (ii) propagate message for a fixed number of iterations per agent. Max-Sum is optimal on tree-shaped factor graphs, and still perform well on cyclic settings. But there exist problems for which Max-Sum does not converge or converge to a sub-optimal state. In fact, on cyclic settings [3] identify the following behaviors: (i) agents converge to fixed states that represent either the optimal solution, or a solution close to the optimal, and the propagation of messages ceases; (ii) agents converge as above, but the messages continue to change slightly at each update, and thus continue to be propagated around the network; (iii) neither the agents’ preferred states, nor the messages converge and both display cyclic behavior.\nAs to improve Max-Sum performance on cyclic graphs, [20] proposed two extensions to Max-Sum: (i) Max-Sum_AD which operates Max-Sum on a directed acyclic graph built from the factor graph, and alternates direction at a fixed rate (a parameter of the algorithm); (ii) MaxSum_AD_VP which operates Max-Sum_AD and propagates current values of variables when sending Max-Sum messages so that factors receiving the value only consider this value instead of the whole domain of the variable. These two extensions, especially the second one, greatly improves the quality of the solution: Max-Sum_AD_VP found solutions that approximate the optimal solution by a factor of roughly 1.1 on average. However, the study does not consider the number of exchanged messages, or the time required to converge and terminate MaxSum_AD_VP."
    }, {
      "heading" : "2.3 BP-guided Decimation",
      "text" : "In this paper, we propose to take inspiration from work done in computational physics [13], as to cope with cyclicity in DCOP. Notably, [5] introduced the notion of decimation in constraint satisfaction, especially k-satisfiability, where variables are binary, xi ∈ {0, 1}, and each constraint requires k of the variables to be different from a specific k-uple. Authors proposed a class of algorithms, namely message passing-guided decimation procedure, which consists in iterating the following steps: (1) run a message passing algorithm, like BP ; (2) use the result to choose a variable index i , and a value x∗i for the corresponding variable; (3) replace the constraint satisfaction problem with the one obtained by fixing xi to x∗i . The BP-guided decimation procedure is shown in Algorithm 1, whose performances are analysed in [11,13].\nBP-guided decimation operates on the factor graph representing the k-satisfiability problem to solve. At each step, the variable to decimate is randomly chosen among the remaining variables. The chosen variable xi is assigned a value determined by random sampling according to its marginal zi. After decimation, the factor graph is simplified: some edges are no more relevant, and factors can be sliced (columns corresponding to removed variables are deleted). In some settings, BP-guided decimation may fail, if random choices assign a value to a variable which is not consistent with other decimated variables.\nSome comments can be made on this approach. First, relying on marginal values is a key feature, and is the core of the “BP-guided” nature of this method. Marginal values are exploited to prune the factor graph. Second, while in the seminal work of [11], this procedure is used to solve satisfiability problems, the approach can easily be implemented to cope with optimization problems. For instance, the inference library libDAI proposes an implementation of decimation for discrete approximate inference in graphical models [12], which was amongst the three winners of the UAI 2010 Approximate Inference Challenge5."
    }, {
      "heading" : "2.4 State of a Factor Graph Representation",
      "text" : "The previous BP-based algorithm operates on factor graph representing the problem. “Operates” means that the algorithms create a data structure representing the factor graphwhich evolves with time : marginal values change, variables disappear, messages are sent/received, etc. Commonly, the logical representation of a factor graph is a set of nodes connected depending on the connectivity of the graph. Each such node has a state which stores some useful values.\nDefinition 3. The current state FGt at time t of a factor graph FG = 〈X , C, E〉 is the composition of all the current states of the data structures used by the BP-based algorithm to operate on the related factor graph, including the marginal values zi, the messages mi→j , the set of decimated variables U , and other algorithm-specific data.\nWe can consider that for a given problem, many factor graph states may exist. We denoteS the set of possible factor graph states, and S(FG) ⊂ S the set of possible states for the factor graph FG.\n3 DeciMaxSum: Extending Max-Sum with Decimation\nWhile mainly designed as a centralized algorithm and studied on k-SAT problems, BP-guided decimation could be utilized for solving DCOP with a few modifications. To the best of our knowledge, this approach has never been proposed for improving Max-Sum algorithm. Here we expound the core contribution of this paper, namely the DeciMaxSum framework and its components."
    }, {
      "heading" : "3.1 Principles",
      "text" : "The main idea is to extend the BP-guided decimation algorithm from [11] in order to define a more general framework, in which other BP-based existing algorithms could fit. First, the main focus is decimation, which means assigning a value to a variable as to remove it from the problem. As the name suggests, there is no way back when a variable has been decimated –unlike search algorithms, where variable assignments can be revised following a backtrack, for instance. Therefore, triggering decimation is an impacting decision. This is why our framework\n5 http://www.cs.huji.ac.il/project/UAI10/\nis mainly based on answering three questions: (i) when is decimation triggered, (ii) which variable(s) to decimate, (iii) which value to assign to the decimated variable(s)? Several criteria can be defined for answering each question, and the DeciMaxSum specifies such criteria as decimation policies, that are fundamental parameters of the decimation procedure.\nDefinition 4 (Decimation Policy). A decimation policy is a tuple π = 〈Θ,Φ, Υ, Λ〉 where:\n– Θ : S→ {0, 1} is the condition to trigger the decimation process, namely the trigger policy, – Φ : S→ 2X is a filter policy which selects some candidate variables to decimate, – Υ : X ×S→ {0, 1} is the condition to perform decimation on a variable, namely perform policy, – Λ : X ×S→ DX is the assignment policy, which assigns a value to a given variable.\nA rich population of decimation-based algorithm can be modeled through this framework by combining decimation policies. For instance, one can consider a DeciMaxSum instance, which (i) triggers decimation once BP has converged, (ii) chooses randomly a variable to decimated within the whole set of non-decimated variables, and (iii) samples the value of the decimated variable depending on its marginal values (used as probability distribution). By doing so, we result in the classical BP-guided decimation algorithm from [11] . However, as many more decimation policies can be defined and combined, we fall into a more general framework generating a whole family of algorithms.\n3.2 DeciMaxSum as an Algorithm\nWe can summarize the DeciMaxSum framework using Algorithm 2. It is a reformulation of BPguided decimation, parameterized with a decimation policy. Here decimation is not necessarily triggered at the convergence (or time limit) of BP. Criterion Θ may relies on other components of the state of the factor graph. Contrary to classical BP-guided decimation, there may be several variables to decimate at the same time (like in some variants of DSA orMGM) and that variables can be chosen in an informed manner (and not randomly), using criterion Υ . Values assigned to decimated variables, are not necessarily chosen stochastically, but are assigned using the function Λ that can be deterministic (still depending on the current state of the FG). Since, here we’re not in the k-satisfiability case, but in an optimization case, there is no failure (only suboptimality), contrary to Algorithm 1. Finally, once all variables have been decimated, the output consists in decoding the state FGt, i.e. getting the values assigned to decimated variables. This means that finally DeciMaxSum is performing decoding while solving the problem, which is not a common feature in other DCOP algorithms, like classical Max-Sum or DSA. Indeed, once these algorithms halt, a decoding phase must be performed to extract the solution from the variables’ states.\nWhile presented as a classical algorithm, let us note that decimation is meant to be implemented in a distributed and concurrent manner, depending on the decimation policy components. The rest of the section details and illustrates each of these decimation policies component with some examples."
    }, {
      "heading" : "3.3 Triggering Decimation (Θ criterion)",
      "text" : "In the original approach proposed by [11], decimation is triggered once BP has converged. In a distributed settings and diffusing algorithms like BP, this can be implemented using termination detection techniques.\nΘconverge(s) def= { 1, if s is quiescent 0, otherwise (2)\nAlgorithm 2: The DeciMaxSum framework as an algorithm Data: A factor graph FG = 〈X , C, E〉, a decimation policy π = 〈Θ,Φ, Υ, Λ〉 Result: A feasible assignment X ∗\n1 initialize BP messages 2 U ← ∅ 3 while U 6= X do 4 run BP until decimation triggers, i.e. Θ(FGt) = 1 // Sect. 3.3 5 choose variables to decimate, X ′ = {xi ∈ Φ(FGt) | Υ (xi, FGt)} // Sect. 3.4 6 for xi ∈ X ′ do // Sect. 3.5 7 xi ← Λ(xi, FGt) 8 U ← U ∪ {xi} 9 simplify FGt // remove variables, slice factors\n10 return X ∗ by decoding U\nThis trigger consists in detecting the quiescence of the current state of the factor graph. This means no process is enabled to perform any locally controlled action and there are no messages in the channels [6]. Algorithms like DijkstraScholten can detects such global state by implementing a send/receive network algorithm, based on the same graph than FG [6]. Note that such techniques generates extra communication load for termination detection-dedicated messages.\nDue to the Max-Sum behavior on loopy factor graphs, convergence may not be reached [20]. The common workaround is to run BP for a fixed number of iterations in case there is no convergence. Setting this time limit (namely LIMIT) might be really problem-dependent.\nΘtime(s) def= { 1, if time(s) = LIMIT 0, otherwise (3)\nIn synchronous settings (all variables and factors are executed synchronously, step by step), getting the iteration number of the current state of the FG, time(s), can done in a distributed manner, as usually done in Max-Sum. In the asynchronous case, one can either (i) use a shared clock, or (ii) count locally outcoming messages within each variables, and once a variable has sent a limit number of messages, decimation is triggered.\nIn some settings with strong time or computation constraints (e.g. sensor networks [3], internet-of-things [17]), waiting convergence is not affordable. Indeed, BP may generate a lot of messages. Therefore, we may consider decimating before convergence at a fixed rate (e.g. each 10 iterations), or by sharing a fixed iteration budget amongst the variables (e.g. each 1000 iterations divided by the number of variables). We can even consider a varying decimation speed (e.g. faster at the beginning, and lower at the end, as observed in neural circuits in the brain [14]).\nΘfrequency(s) def= { 1, if time(s) mod f(s) = 0 0, otherwise (4)\nwhere f is a function of the current state of the system, for instance :\n– f(s) = RATE, with a predefined decimation frequency, – f(s) = BUDGET/|X |, with a predefined computation budget, – f(s) = 2× time(s), for an decreasing decimation frequency.\nFinally, another approach could be to trigger decimation once a loop in the FG is detected. Indeed, decimation is used here to cope with loops, so decimating variables, which could potentially break loops, seems a good approach.\nΘloop(s) def= { 1, if ∃xi ∈ X , |loop(xi)| > 1 0, otherwise (5)\nwhere loop(xi) is the set of agents in the same first loop that xi just discovered. Detecting loops in the FG can be implemented during BP, by adding some metadata on the BP messages, like done in the DFS-tree construction phase of algorithms like DPOP or ADOPT."
    }, {
      "heading" : "3.4 Deciding the Subset of Variables to Decimate (Φ and Υ criteria)",
      "text" : "Now our system has detected decimation should be triggered, the following question is “which variables to decimate?” In [11], the variable is chosen randomly in a uniform manner, while in [12], the variable with a the maximum entropy over its marginal values (the most determined variable) is selected. Obviously, exploiting the marginal values, build throughout propagation is a good idea.\nFrom which subset choosing the candidate variables to decimate? Both [11] and [12] select the only variable to decimate amongst the whole set of non-decimated variables (cf. line 5 in Algorithm 1). Here, Φ criterion is specified as follows:\nΦall(s) def=X \\ U (6)\nHowever, this selection on the whole set of variables can be discussed when using local decimation triggers, like loop detection. In such case, selecting the variables to decimate within the agents in the loop, or the one which detected the loop sounds better. Another approach is to consider selecting agents depending on the past state of the system. For instance, if a variable has been decimated, good future candidates for decimation could be its direct neighbors in the FG:\nΦneighbors(s) def={x ∈ X \\ U | neighbors(x) ∩ U 6= ∅} (7)\nwith neighbors(xi) = {xj ∈ X | j 6= i,∃eik, ekj ∈ E}.\nWhich criteria to decide whether the variable decimate? Now, we have to specify the Υ criterion used to decide which candidates decimate. In [11], it is fully random: it does not depends on the current state of the variables. It corresponds to make each variable roll a dice and choosing the greatest draw:\nΥmax_rand(xi, s) def= { 1, if ∀xj 6= xi ∈ X , rand(xi) > rand(xj) 0, otherwise (8)\nwhere rand(x) stands for the output of a random number generator (namely sample) using a uniform distribution (e.g. U [0, 1]).\nIn [12], the variable with the maximal entropy over its marginal values is selected. This means the variable for which marginal values seems to be the most informed, in the Shannon’s Information Theory sense, is chosen:\nΥmax_entropy(xi, s) def= { 1, if ∀xj 6= xi ∈ X , H(zi(xi)) > H(zj(xj)) 0, otherwise (9)\nwith H(zk(xk)) = − ∑\nd∈Dk zk(xk)(d) log(zk(xk)(d)). From this, other criteria can be derived. For instance, instead of using entropy, one can\nconsider the maximal normalized marginal value:\nΥmax_marginal(xi, s) def=\n{ 1, if ∀xj 6= xi ∈ X ,max\nd∈Di (zi(xi)(d)) > max d∈Di (zj(xj)(d))\n0, otherwise (10)\nIf several variables can be decimated at the same time, one may consider selecting the set of variable having an entropy or a normalized marginal value greater than a given threshold, to only decimate variable which are “sufficiently” determined. Hence, this approach requires setting another parameter (namely THRESHOLD):\nΥthreshold_entropy(xi, s) def= { 1, if H(zi(xi)) > THRESHOLD 0, otherwise (11)\nOf course, many combination of the aforementioned criteria, and other criteria could be considered in our framework. We don’t discuss here criteria like in DSA which does not rely on marginal values, but on stochastic decision.\nWhich subset of variables the decision to decimate a variable depends on? Behind this question lies the question of coordinating the variable selection. Indeed, if computing criterion Υ does not depend on the decision of other variables, the procedure is fully distributable at low communication cost, as for policies like (11). At the contrary, if the decision requires to be aware of the state of other variables, as for policies like (8), (9) and (10), the procedure will require some system-scale coordination messages. In [11] and [12], decimation only concerns all the variables, from which only one will be chosen. This requires a global coordination, or a distributed leader election protocol which may require an underlying network (ring, spanning tree, etc.), like the one used for quiescence detection, to propagate election messages [6].\nIn some cases, the decimation decision might be at local scale, when variables will make their decision depending on the decision of their direct neighbors, or variables in the same loop. In this case, less coordination messages will be required. For instance, if considering decimating variables in a loop, only variables in the loop will implement a leader election protocol. All policies, from (8) to (10), could be extended in the same manner, by replacing X by loop(xi), neighours(xi), or any subset of X . For instance:\nΥmax_rand_loop(xi, s) def= { 1, if ∀xj 6= xi ∈ loop(xi), rand(xi) > rand(xj) 0, otherwise (12)"
    }, {
      "heading" : "3.5 Deciding the Values to Assign To Decimated Variables (Λ criterion)",
      "text" : "Now variables to decimate have been selected, the question is “which values to assign?” Usually, in BP-based algorithms, the simplest way to select values for variables, after propagation, is to assign valueswithmaximalmarginal value (or utility). [12] is using such a criterion for inference:\nΛmax_marginal(xi, s) def= argmax\nd∈Di zi(xi)(d) (13)\nWhile, the policy is deterministic, in [11] the choice of the value is a random choice using the marginal values as a probability distribution:\nΛsample_marginal(xi, s) def= sample(zi(xi)) (14)\nOnce again, these are only some examples of policies exploiting BP, and one can easily specify many more."
    }, {
      "heading" : "4 Experiments",
      "text" : "In this section we evaluate the performance of different combinations of decimation policies in DeciMaxSum, on a classical optimization model (Ising model), against classical Max-Sum [3] and its extension Max-Sum_AD_VP [20], we have implemented in our own framework."
    }, {
      "heading" : "4.1 Ising Model",
      "text" : "Since we are interested in evaluating our algorithms in the presence of strong dependencies among the values of variables, we evaluate them on Ising model which is a widely used benchmark in statistical physics [4]. We use here the same settings than [18]. Here, constraint graphs are rectangular grids where each binary variable xi is connected to its four closer neighbors (with toroidal links which connect opposite sides of the grid), and is constrained by a unary cost ri. The weight of each binary constraint rij is determined by first sampling a value κij from a uniform distribution U [−β, β] and then assigning\nrij(xi, xj) = { κij if xi = xj −κij otherwise\nThe β parameter controls the average strength of interactions. In our experiments we set β to 1.6. The weight for each unary constraint ri is determined by sampling κi from a uniform distribution U [−0.05, 0.05] and then assigning ri(0) = κi and ri(1) = −κi."
    }, {
      "heading" : "4.2 Results and Analysis",
      "text" : "In this section we analyse results of differentDeciMaxSum combinations to solve squared-shape Ising problems with side size varying from 10 to 20 (e.g. 100 to 400 variables). We implemented the following combinations:\n– 11 DeciMaxSum instances with different decimation policies using the following criteria: • trigger policies (Θ criterion):\n∗ Θconverge (from equation 2, noted converge), ∗ rate-based Θfrequency (from equation 4, noted 2-periodic, 3-periodic, 5-periodic, 10-\nperiodic, 20-periodic, and 100-periodic), ∗ budget-based Θfrequency (from equation 4, noted periodic),\n• filter policy (Φ criterion): ∗ the one that selects the whole set of variables as potential variables to decimate (i.e. Φall from equation 6), • perform policies (Υ criterion): ∗ Υmax_rand (from equation 8, noted random), ∗ Υmax_entropy (from equation 9, noted max_entropy), • assignment policies (Λ criterion): ∗ deterministic Λmax_marginal (from equation 13, noted deterministic), ∗ sampled Λsample_marginal (from equation 14, noted sampling),\n– MaxSum, as defined in [3], – MaxSum_AD, as defined in [20], – MaxSum_AD_VP, as defined in [20], – Montanari-Decimation, as defined in [11], – Mooij-Decimation, as defined in [12].\nFigure 1 presents two performance metrics (final total cost and total number of exchanged messages). Considering optimality of the final solutions obtained by the different solution methods and DeciMaxSum instances, what appears is that very fast decimation combined with a deterministic decimation of the most determined variable (max_entropy) presents the best cost. Besides, very fast decimation also imply that few messages are exchanged compared to other solution methods, since decimation cuts message propagations. However, all the solution methods (except Montanari-Decimation and Mooij-Decimation) tend to a comparable number of exchanged messages."
    }, {
      "heading" : "5 Conclusions",
      "text" : "In this paper we have investigated how to extend Max-Sum method for solving distributed constraint optimization problems, by taking inspiration from the decimation mechanisms used to solve k-satisfiability problems by belief-propagation. We propose a parametric method, namely DeciMaxSum, which can be set up with different decimation policies stating when to trigger decimation,which variables to decimate, andwhich value to assign to decimated variables. In this paper, we propose a library of such policies that can be combined to produce different versions of DeciMaxSum. Our empirical results on different benchmarks show that some combinations of decimation policies outperform classical Max-Sum and its extension Max-Sum_AD_VP, specifically design to handle loops.DeciMaxSum outputs better quality solutions in a reasonable number of message propagation.\nThere are several paths to future research. First, we only explore a limited set of decimation policies. We wish to investigate more complex ones, especially policies trigger when loops are detected by agents. In fact, since our overarching goal is to cope with loops, detecting them at the agent level seems a reasonable approach to initiate decimation in a cyclic network. This approach will require agents to implement cycle-detection protocol, by sending message history, while propagating marginals. In such a setting, several decimation election may arise concurrently in the graph. Second, we would like to generalize DeciMaxSum framework to consider MaxSum_AD_VP as a particular case of decimation: iterated decimation. Finally, we plan to applied\nDeciMaxSum on real world applications, with strong loopy nature, like the coordination of smart objects in IoT [17] or decentralized energy markets in the smart grid [2]."
    } ],
    "references" : [ {
      "title" : "A tutorial on optimization formulti-agent systems",
      "author" : [ "J. Cerquides", "A. Farinelli", "P. Meseguer", "S.D. Ramchurn" ],
      "venue" : "The Computer Journal 57(6),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2014
    }, {
      "title" : "Designing a marketplace for the trading and distribution of energy in the smart grid",
      "author" : [ "J. Cerquides", "G. Picard", "J. Rodríguez-Aguilar" ],
      "venue" : "International Conference on Autonomous Agents and Multiagent Systems (AAMAS). pp. 1285–1293. International Foundation for Autonomous Agents and Multiagent Systems",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2015
    }, {
      "title" : "Decentralised coordination of low-power embedded devices using the max-sum algorithm",
      "author" : [ "A. Farinelli", "A. Rogers", "A. Petcu", "N.R. Jennings" ],
      "venue" : "In: International Conference on Autonomous Agents and Multiagent Systems",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2008
    }, {
      "title" : "Convergent tree-reweighted message passing for energy minimization",
      "author" : [ "V. Kolmogorov" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence 28(10), 1568–1583",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Gibbs states and the set of solutions of random constraint satisfaction problems",
      "author" : [ "F. Krzakala", "A. Montanari", "F. Ricci-Tersenghi", "G. Semerjian", "L. Zdeborova" ],
      "venue" : "Proceedings of the National Academy of Science 104, 10318–10323",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Disributed Algorithms",
      "author" : [ "N. Lynch" ],
      "venue" : "Morgan Kaufmann",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Information Theory, Inference and Learning Algorithms",
      "author" : [ "D.J.C. Mackay" ],
      "venue" : "Cambridge University Press, first edition edn.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Distributed algorithms for dcop: A graphical-game-based approach",
      "author" : [ "R. Maheswaran", "J. Pearce", "M. Tambe" ],
      "venue" : "Proceedings of the 17th International Conference on Parallel and Distributed Computing Systems (PDCS), San Francisco, CA. pp. 432– 439",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "ADOPT: Asynchronous Distributed Constraint Optimization with Quality Guarantees",
      "author" : [ "P.J. Modi", "W. Shen", "M. Tambe", "M. Yokoo" ],
      "venue" : "Artificial Intelligence 161(2), 149–180",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "ADOPT: Asynchronous distributed constraint optimization with quality guarantees",
      "author" : [ "P. Modi", "W. Shen", "M. Tambe", "M. Yokoo" ],
      "venue" : "Artificial Intelligence Journal",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Solving constraint satisfaction problems through belief propagationguided decimation",
      "author" : [ "A. Montanari", "F. Ricci-Tersenghi", "G. Semerjian" ],
      "venue" : "CoRR abs/0709.1667",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2007
    }, {
      "title" : "libDAI: A free and open source C++ library for discrete approximate inference in graphical models",
      "author" : [ "J.M. Mooij" ],
      "venue" : "Journal of Machine Learning Research",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2010
    }, {
      "title" : "Information, Physics, and Computation",
      "author" : [ "M. Mézard", "A. Montanari" ],
      "venue" : "Oxford University Press",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Decreasing-rate pruning optimizes the construction of efficient and robust distributed networks",
      "author" : [ "S. Navlakha", "A.L. Barth", "Z. Bar-Joseph" ],
      "venue" : "PLOSComputational Biology 11(7),",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2015
    }, {
      "title" : "A scalable method for multiagent constraint optimization",
      "author" : [ "A. Petcu", "B. Faltings" ],
      "venue" : "International Joint Conference on Artificial Intelligence (IJCAI’05). pp. 266–271",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Bounded approximate decentralised coordination via the max-sum algorithm",
      "author" : [ "A. Rogers", "A. Farinelli", "R. Stranders", "N. Jennings" ],
      "venue" : "Artificial Intelligence 175(2),",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2011
    }, {
      "title" : "Using message-passing DCOP algorithms to solve energy-efficient smart environment configuration problems",
      "author" : [ "P. Rust", "G. Picard", "F. Ramparany" ],
      "venue" : "International Joint Conference on Artificial Intelligence (IJCAI). AAAI Press",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Divide and coordinate: solving dcops by agreement",
      "author" : [ "M. Vinyals", "M. Pujol", "J. Rodríguez-Aguilar", "J. Cerquides" ],
      "venue" : "International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS’10). pp. 149–156. IFAAMAS, Canada",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Constructing a unifying theory of dynamic programming dcop algorithms via the generalized distributive law. Autonomous Agents and Multi-Agent Systems",
      "author" : [ "M. Vinyals", "J. Rodriguez-Aguilar", "J. Cerquides" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2010
    }, {
      "title" : "Max/min-sum distributed constraint optimization through value propagation on an alternating DAG",
      "author" : [ "R. Zivan", "H. Peled" ],
      "venue" : "International Conference on Autonomous Agents and Multiagent Systems,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "Indeed, complete methods, like ADOPT or DPOP, suffer exponential computation and/or communication cost in general settings [10,15].",
      "startOffset" : 123,
      "endOffset" : 130
    }, {
      "referenceID" : 14,
      "context" : "Indeed, complete methods, like ADOPT or DPOP, suffer exponential computation and/or communication cost in general settings [10,15].",
      "startOffset" : 123,
      "endOffset" : 130
    }, {
      "referenceID" : 0,
      "context" : "As a consequence, in some large settings, approximate methods are better candidates, as evidenced by the extensive literature on the subject (see [1] for a complete review).",
      "startOffset" : 146,
      "endOffset" : 149
    }, {
      "referenceID" : 2,
      "context" : "Among the aforementioned methods, inference-based ones, like Max-Sum [3] and its extensions like [16], have demonstrated good performance even on loopy settings.",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 15,
      "context" : "Among the aforementioned methods, inference-based ones, like Max-Sum [3] and its extensions like [16], have demonstrated good performance even on loopy settings.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 12,
      "context" : "Decimation is a method inspired by statistical physics, and applied in belief-propagation, which consists in fixing the value of a variable, using the marginal values as the decision criteria to select the variable to decimate [13].",
      "startOffset" : 227,
      "endOffset" : 231
    }, {
      "referenceID" : 10,
      "context" : "In [11], decimation has been used in the constraint satisfaction framework, for solving centralized k-satisfiability problems [11].",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 10,
      "context" : "In [11], decimation has been used in the constraint satisfaction framework, for solving centralized k-satisfiability problems [11].",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 19,
      "context" : "Other works proposed Max-Sum_AD_VP as to improve Max-Sum performance on loopy graphs [20].",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 0,
      "context" : "As highlighted in [1], DCOPs have been widely studied and applied in many reference domains, and have many interesting features: (i) strong focus on decentralized approaches where agents negotiate a joint solution through local message exchange; (ii) solution techniques exploit the structure of the domain (by encoding this into constraints) to tackle hard computational problems; (iii) there is a wide choice of solutions for DCOPs ranging from complete algorithms to suboptimal algorithms.",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 8,
      "context" : "On the one hand, complete algorithms like ADOPT and its extensions [9], or inference algorithms like DPOP [15] or ActionGDL [19], are optimal, but mainly suffer from expensive memory (e.",
      "startOffset" : 67,
      "endOffset" : 70
    }, {
      "referenceID" : 14,
      "context" : "On the one hand, complete algorithms like ADOPT and its extensions [9], or inference algorithms like DPOP [15] or ActionGDL [19], are optimal, but mainly suffer from expensive memory (e.",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 18,
      "context" : "On the one hand, complete algorithms like ADOPT and its extensions [9], or inference algorithms like DPOP [15] or ActionGDL [19], are optimal, but mainly suffer from expensive memory (e.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 2,
      "context" : "On the other hand, approximate algorithms like Max-Sum [3] or MGM [8] have the great advantage of being fast with a limited memory print and communication load, but losing optimality in some settings –e.",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 7,
      "context" : "On the other hand, approximate algorithms like Max-Sum [3] or MGM [8] have the great advantage of being fast with a limited memory print and communication load, but losing optimality in some settings –e.",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 6,
      "context" : "sum-product message passing method, is a potentially distributed algorithm for performing inference on graphical models, and can operate on factor graphs representing a product of M factors [7]: F (x) = ∏M m=1 fm(Xm) .",
      "startOffset" : 190,
      "endOffset" : 193
    }, {
      "referenceID" : 6,
      "context" : "When the factor graph is a tree, BP algorithm computes the exact marginals and converge in a finite number a steps depending on the diameter of the graph [7].",
      "startOffset" : 154,
      "endOffset" : 157
    }, {
      "referenceID" : 2,
      "context" : "Built as a derivative of max-product, Max-Sum is an approximate algorithm to solve DCOP [3].",
      "startOffset" : 88,
      "endOffset" : 91
    }, {
      "referenceID" : 10,
      "context" : "Algorithm 1: The BP-guided decimation algorithm from [11]",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 2,
      "context" : "In fact, on cyclic settings [3] identify the following behaviors: (i) agents converge to fixed states that represent either the optimal solution, or a solution close to the optimal, and the propagation of messages ceases; (ii) agents converge as above, but the messages continue to change slightly at each update, and thus continue to be propagated around the network; (iii) neither the agents’ preferred states, nor the messages converge and both display cyclic behavior.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 19,
      "context" : "As to improve Max-Sum performance on cyclic graphs, [20] proposed two extensions to Max-Sum: (i) Max-Sum_AD which operates Max-Sum on a directed acyclic graph built from the factor graph, and alternates direction at a fixed rate (a parameter of the algorithm); (ii) MaxSum_AD_VP which operates Max-Sum_AD and propagates current values of variables when sending Max-Sum messages so that factors receiving the value only consider this value instead of the whole domain of the variable.",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 12,
      "context" : "In this paper, we propose to take inspiration from work done in computational physics [13], as to cope with cyclicity in DCOP.",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 4,
      "context" : "Notably, [5] introduced the notion of decimation in constraint satisfaction, especially k-satisfiability, where variables are binary, xi ∈ {0, 1}, and each constraint requires k of the variables to be different from a specific k-uple.",
      "startOffset" : 9,
      "endOffset" : 12
    }, {
      "referenceID" : 10,
      "context" : "The BP-guided decimation procedure is shown in Algorithm 1, whose performances are analysed in [11,13].",
      "startOffset" : 95,
      "endOffset" : 102
    }, {
      "referenceID" : 12,
      "context" : "The BP-guided decimation procedure is shown in Algorithm 1, whose performances are analysed in [11,13].",
      "startOffset" : 95,
      "endOffset" : 102
    }, {
      "referenceID" : 10,
      "context" : "Second, while in the seminal work of [11], this procedure is used to solve satisfiability problems, the approach can easily be implemented to cope with optimization problems.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 11,
      "context" : "For instance, the inference library libDAI proposes an implementation of decimation for discrete approximate inference in graphical models [12], which was amongst the three winners of the UAI 2010 Approximate Inference Challenge5.",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 10,
      "context" : "The main idea is to extend the BP-guided decimation algorithm from [11] in order to define a more general framework, in which other BP-based existing algorithms could fit.",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 10,
      "context" : "By doing so, we result in the classical BP-guided decimation algorithm from [11] .",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 10,
      "context" : "In the original approach proposed by [11], decimation is triggered once BP has converged.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 5,
      "context" : "This means no process is enabled to perform any locally controlled action and there are no messages in the channels [6].",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 5,
      "context" : "Algorithms like DijkstraScholten can detects such global state by implementing a send/receive network algorithm, based on the same graph than FG [6].",
      "startOffset" : 145,
      "endOffset" : 148
    }, {
      "referenceID" : 19,
      "context" : "Due to the Max-Sum behavior on loopy factor graphs, convergence may not be reached [20].",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 2,
      "context" : "sensor networks [3], internet-of-things [17]), waiting convergence is not affordable.",
      "startOffset" : 16,
      "endOffset" : 19
    }, {
      "referenceID" : 16,
      "context" : "sensor networks [3], internet-of-things [17]), waiting convergence is not affordable.",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 13,
      "context" : "faster at the beginning, and lower at the end, as observed in neural circuits in the brain [14]).",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 10,
      "context" : "Now our system has detected decimation should be triggered, the following question is “which variables to decimate?” In [11], the variable is chosen randomly in a uniform manner, while in [12], the variable with a the maximum entropy over its marginal values (the most determined variable) is selected.",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 11,
      "context" : "Now our system has detected decimation should be triggered, the following question is “which variables to decimate?” In [11], the variable is chosen randomly in a uniform manner, while in [12], the variable with a the maximum entropy over its marginal values (the most determined variable) is selected.",
      "startOffset" : 188,
      "endOffset" : 192
    }, {
      "referenceID" : 10,
      "context" : "From which subset choosing the candidate variables to decimate? Both [11] and [12] select the only variable to decimate amongst the whole set of non-decimated variables (cf.",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 11,
      "context" : "From which subset choosing the candidate variables to decimate? Both [11] and [12] select the only variable to decimate amongst the whole set of non-decimated variables (cf.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 10,
      "context" : "In [11], it is fully random: it does not depends on the current state of the variables.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "U [0, 1]).",
      "startOffset" : 2,
      "endOffset" : 8
    }, {
      "referenceID" : 11,
      "context" : "In [12], the variable with the maximal entropy over its marginal values is selected.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 10,
      "context" : "In [11] and [12], decimation only concerns all the variables, from which only one will be chosen.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 11,
      "context" : "In [11] and [12], decimation only concerns all the variables, from which only one will be chosen.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 5,
      "context" : "), like the one used for quiescence detection, to propagate election messages [6].",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 11,
      "context" : "[12] is using such a criterion for inference:",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "While, the policy is deterministic, in [11] the choice of the value is a random choice using the marginal values as a probability distribution:",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 2,
      "context" : "In this section we evaluate the performance of different combinations of decimation policies in DeciMaxSum, on a classical optimization model (Ising model), against classical Max-Sum [3] and its extension Max-Sum_AD_VP [20], we have implemented in our own framework.",
      "startOffset" : 183,
      "endOffset" : 186
    }, {
      "referenceID" : 19,
      "context" : "In this section we evaluate the performance of different combinations of decimation policies in DeciMaxSum, on a classical optimization model (Ising model), against classical Max-Sum [3] and its extension Max-Sum_AD_VP [20], we have implemented in our own framework.",
      "startOffset" : 219,
      "endOffset" : 223
    }, {
      "referenceID" : 3,
      "context" : "Since we are interested in evaluating our algorithms in the presence of strong dependencies among the values of variables, we evaluate them on Ising model which is a widely used benchmark in statistical physics [4].",
      "startOffset" : 211,
      "endOffset" : 214
    }, {
      "referenceID" : 17,
      "context" : "We use here the same settings than [18].",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 2,
      "context" : "Φall from equation 6), • perform policies (Υ criterion): ∗ Υmax_rand (from equation 8, noted random), ∗ Υmax_entropy (from equation 9, noted max_entropy), • assignment policies (Λ criterion): ∗ deterministic Λmax_marginal (from equation 13, noted deterministic), ∗ sampled Λsample_marginal (from equation 14, noted sampling), – MaxSum, as defined in [3], – MaxSum_AD, as defined in [20], – MaxSum_AD_VP, as defined in [20], – Montanari-Decimation, as defined in [11], – Mooij-Decimation, as defined in [12].",
      "startOffset" : 350,
      "endOffset" : 353
    }, {
      "referenceID" : 19,
      "context" : "Φall from equation 6), • perform policies (Υ criterion): ∗ Υmax_rand (from equation 8, noted random), ∗ Υmax_entropy (from equation 9, noted max_entropy), • assignment policies (Λ criterion): ∗ deterministic Λmax_marginal (from equation 13, noted deterministic), ∗ sampled Λsample_marginal (from equation 14, noted sampling), – MaxSum, as defined in [3], – MaxSum_AD, as defined in [20], – MaxSum_AD_VP, as defined in [20], – Montanari-Decimation, as defined in [11], – Mooij-Decimation, as defined in [12].",
      "startOffset" : 382,
      "endOffset" : 386
    }, {
      "referenceID" : 19,
      "context" : "Φall from equation 6), • perform policies (Υ criterion): ∗ Υmax_rand (from equation 8, noted random), ∗ Υmax_entropy (from equation 9, noted max_entropy), • assignment policies (Λ criterion): ∗ deterministic Λmax_marginal (from equation 13, noted deterministic), ∗ sampled Λsample_marginal (from equation 14, noted sampling), – MaxSum, as defined in [3], – MaxSum_AD, as defined in [20], – MaxSum_AD_VP, as defined in [20], – Montanari-Decimation, as defined in [11], – Mooij-Decimation, as defined in [12].",
      "startOffset" : 418,
      "endOffset" : 422
    }, {
      "referenceID" : 10,
      "context" : "Φall from equation 6), • perform policies (Υ criterion): ∗ Υmax_rand (from equation 8, noted random), ∗ Υmax_entropy (from equation 9, noted max_entropy), • assignment policies (Λ criterion): ∗ deterministic Λmax_marginal (from equation 13, noted deterministic), ∗ sampled Λsample_marginal (from equation 14, noted sampling), – MaxSum, as defined in [3], – MaxSum_AD, as defined in [20], – MaxSum_AD_VP, as defined in [20], – Montanari-Decimation, as defined in [11], – Mooij-Decimation, as defined in [12].",
      "startOffset" : 462,
      "endOffset" : 466
    }, {
      "referenceID" : 11,
      "context" : "Φall from equation 6), • perform policies (Υ criterion): ∗ Υmax_rand (from equation 8, noted random), ∗ Υmax_entropy (from equation 9, noted max_entropy), • assignment policies (Λ criterion): ∗ deterministic Λmax_marginal (from equation 13, noted deterministic), ∗ sampled Λsample_marginal (from equation 14, noted sampling), – MaxSum, as defined in [3], – MaxSum_AD, as defined in [20], – MaxSum_AD_VP, as defined in [20], – Montanari-Decimation, as defined in [11], – Mooij-Decimation, as defined in [12].",
      "startOffset" : 502,
      "endOffset" : 506
    }, {
      "referenceID" : 16,
      "context" : "DeciMaxSum on real world applications, with strong loopy nature, like the coordination of smart objects in IoT [17] or decentralized energy markets in the smart grid [2].",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 1,
      "context" : "DeciMaxSum on real world applications, with strong loopy nature, like the coordination of smart objects in IoT [17] or decentralized energy markets in the smart grid [2].",
      "startOffset" : 166,
      "endOffset" : 169
    } ],
    "year" : 2017,
    "abstractText" : "In the context of solving large distributed constraint optimization problems (DCOP), belief-propagation and approximate inference algorithms are candidates of choice. However, in general, when the factor graph is very loopy (i.e. cyclic), these solution methods suffer from bad performance, due to non-convergence and many exchanged messages. As to improve performances of the Max-Sum inference algorithm when solving loopy constraint optimization problems, we propose here to take inspiration from the belief-propagation-guided decimation used to solve sparse random graphs (k-satisfiability). We propose the novel DeciMaxSum method, which is parameterized in terms of policies to decide when to trigger decimation, which variables to decimate, and which values to assign to decimated variables. Based on an empirical evaluation on a classical BP benchmark (the Ising model), some of these combinations of policies exhibit better performance than state-of-the-art competitors.",
    "creator" : "LaTeX with hyperref package"
  }
}