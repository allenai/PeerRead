{
  "name" : "1312.1760.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Towards Normalizing the Edit Distance Using a Genetic Algorithms–Based Scheme",
    "authors" : [ "Muhammad Marwan", "Muhammad Fuad" ],
    "emails" : [ "marwan.fuad@iet.ntnu.no" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Edit Distance, Normalized Edit Distance, Genetic Algorithms, Sequential Data."
    }, {
      "heading" : "1 Introduction",
      "text" : "Similarity search is an important problem in computer science. This problem has many applications in data mining, computational biology, pattern recognition, and others. In this problem a pattern or a query is given and the task is to retrieve the data objects in the database that are “close” to that query according to some semantics that quantify that closeness. This closeness or similarity is depicted using a principal concept which is the similarity measure or its more powerful form; the distance metric.\nBecause of its topological properties, the metric model (reflexivity, non-negativity, symmetry, triangle inequality) has been widely used to process similarity queries, but later other models were proposed.\nThe edit distance is the main distance used to measure the similarity between two strings. It is defined as the minimum number of delete, insert, and change operations needed to transform string S into string T.\nBut the edit distance has its limitations because it considers local similarity only and does not imply any global level of similarity. ____________________________________ This work was carried out during the tenure of an ERCIM “Alain Bensoussan” Fellowship Programme. This Programme is supported by the Marie-Curie Co-funding of Regional, National and International Programmes (COFUND) of the European Commission.\nIn [10], [11], and [12] we presented two new extensions of the edit distance. These new extensions consider a global level of similarity which the edit distance didn’t consider. But the parameters used with these two distances were defined using basic heuristics, which substantially limited the search space.\nIn this paper we propose a new extension of the edit distance. This extension aims to normalize the edit distance using an approach that relates it directly to the edit distance. The new distance uses the genetic algorithms as an optimization method to set the parameters it uses.\nSection 2 of this paper presents the related work. Section 3 introduces the new distance. Section 4 validates it through different experiments and Section 5 concludes the paper."
    }, {
      "heading" : "2 Related Work",
      "text" : "Strings, also called sequences or words, are a way of representing data. This data type exists in many fields of computer science such as molecular biology where DNA sequences are represented using four nucleotides which correspond to the four bases: adenine (A), cytosine (C), guanine (G) and thymine (T). This can be expressed as a 4- symbol alphabet. Protein sequences can also be represented using a 20-symbol alphabet which corresponds to the 20 amino acids.\nWritten languages are also expressed in terms of alphabets with letters (26 in English). Spoken languages are represented using phonemes (40 in English). Texts use alphabets with a very large size (the vocabulary items of a language). These examples show that strings are ubiquitous.\nOne of the main distances used to handle sequential data is the edit distance (ED) [13], also called the Levenshtein distance, which is defined as the minimum number of delete, insert, and substitute operations needed to transform string S into string R .\nFormally, ED is defined as follows: Let Σ be a finite alphabet, and let *Σ be the set of strings onΣ . Given two strings ns....ssS 21= and mr....rrR 21= defined on\n*Σ . An elementary edit operation is defined as a pair: ( ) ( )λλ ,b,a ≠ , where a and b are strings of lengths 0 and 1, respectively. The elementary edit operation is usually denoted ba → and the three elementary edit operations are λ→a (deletion)\nb→λ (insertion) and ba → (substitution) . Those three operations can be weighted by a weighting function γ which assigns a nonnegative value to each of these operations. This function can be extended to edit transformations mT...TTT 21= .\nThe edit distance between S and R can then be defined as:\nED (S, R) = {γ (T)| T is an edit transformation of S into R } (1)\nED is the main distance measure used to compare two strings and it is widely used in many applications. Fig. 1 shows the edit distance between the two strings { }N,A,W,R,A,MS =1 and { }D,A,U,FS =2\nED has a few drawbacks; the first is that it is a measure of local similarities in which matches between substrings are highly dependent on their positions in the strings [5]. In fact, the edit distance is based on local procedures both in the way it is defined and also in the algorithms used to compute it. Another drawback is that ED does not consider the length of the two strings.\nSeveral modifications have been proposed to improve ED. In [10], [11], and [12] two new extensions of ED; the extended edit distance (EED) and the multi-resolution extended edit distance (MREED) were proposed. These two distances add a global level of similarity to that of ED by including the frequency of characters or bi-grams when computing the distance. The problem with these two distances is that they use parameters which are set using basic heuristics which makes the search process ineffective.\nIt is worth mentioning that the two distances EED and MREED, as well as ED, are all metric distances.\nAnother important modification is the normalized edit distance (NED) [8]. The rationale behind this distance is that the length of the two strings should be taken into account when computing the distance between them. An editing path P between two strings S and R , of lengths n and m, respectively ( mn ≤ ), is a sequence of ordered pairs of integers ( )kk j,i , where mk ≤≤0 , that satisfies the following :\ni- Sik ≤≤0 , ;Rjk ≤≤0\n( ) ( ) ( ) ( )R,Sj,i,,j,i mm == 0000 ii- ,ii kk 10 1 ≤−≤ − 10 1 ≤−≤ −kk jj , 1≥∀k iii- 111 ≥−+− −− kkkk jjii\nThe weights can be associated to paths as follows:\n( ) ( )∑ = +→+= −−\nm\nk kjkiR,S j...Ri...SP kk 1 11 11 γω\nIt follows that:\nED (S, R) =min {ω (P)| P is an edit transformation of S into R }\nLet ( ) ( ) ( )PL/PPˆ ωω = , where L is the length of P , the normalized edit distance NDE is defined as:\n( ) ( ){ }PˆminR,SNDE ω= (2)\nAn important notice about this definition is that it is expressed in terms of paths and not in terms of the edit operations.\nIt has been shown in [8] that NDE is not a distance metric."
    }, {
      "heading" : "3 Genetic Algorithms-based Normalization of the Edit Distance (GANED)",
      "text" : "ED we presented in Section 2 was mainly introduced to apply to spelling errors. This makes the edit operations a main component of ED. NDE, although takes into consideration the lengths of the two strings, which is an important modification in our opinion, is based on a different principle than that of ED, which, we think, causes it to lose some of the principal characteristics of ED.\nIn this work we present a new modification of the edit distance that also takes the lengths of the strings into account. However, our proposed distance uses a completely different approach than that of NDE. Our new distance is directly related to the edit distance. In fact, the new distance is a lower bound of the edit distance."
    }, {
      "heading" : "3.1 GANED",
      "text" : "LetΣ be a finite alphabet, and let *Σ be the set of strings on Σ . Let n be an integer, and let )S(anf be the frequency of the n-gram na in S , and )T( an f be the frequency of the\nn-gram na in T , where S ,T are two strings in *Σ .\nThe GANED distance between S and T is defined as:\n( ) ( )\n( ) ( )( ) ( ) ( )\n( )\n⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦\n⎤\n⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣\n⎡\n+\n⎟⎟ ⎟ ⎠\n⎞\n⎜⎜ ⎜ ⎝\n⎛ −+\n−×=\n∑ ∑ = ∈\nTSn\nnf,fmin\nT,SEDT,SGANED\nT,Smax\nn\nT a S a\nAa n nn\nn n1\n12\n1\nλ\n(3)\nwhere S , T are the lengths of the two strings S ,T respectively, and where [ ]10,n ∈λ . nλ are called the frequency factors.\nNotice that\n( ) ( )( ) ( ) ( ) ( )\n∑ ∑ = ∈\n+≤ ⎟⎟ ⎟ ⎠\n⎞\n⎜⎜ ⎜ ⎝\n⎛ −+≤ T,Smax\nn\nT a S a\nAa n TSnnf,fmin nn\nn n1\n120 λ\nSo ED is multiplied by a factor whose value varies between 0 and 1, so GANED as presented in (3) includes a form of normalization. In fact: ( ) ( )R,SEDR,SGANED ≤≤0 can be written as ( )( ) 10 ≤≤ R,SED R,SGANED which is the\ncommon form of normalization, and we could have expressed our new distance in the latter form. However, instead of imposing a condition that the two strings be different (thus ED=0), we preferred to introduce the new distance in the form shown in (3).\nNotice also that GANED is a lower bound of ED, so the relation between the two distances is direct.\nAs mentioned in Section 1, the idea of considering the frequency of characters or bi-grams in computing the distance has previously been proposed in [10], [11], and [12]. However, the definition of the frequency factors remains problematic in these three works. On the one hand, the search space they use is very limited, and on the other hand, generalizing the distances proposed in [10], [11], and [12] using the same basic heuristics to define the frequency factors makes this process inefficient yet limited to very small regions in the search space.\nGANED uses one very powerful optimization method; the genetic algorithms, to define the frequency factors nλ . The use of the genetic algorithms makes the search more effective."
    }, {
      "heading" : "3.2 The Genetic Algorithms",
      "text" : "The Genetic Algorithms are a member of a large family of stochastic algorithms called Evolutionary Algorithms (EAs) which are population-based optimization algorithms inspired by nature, particularly the theory of evolution. In Fig. 2 we show the members of the EAs. These members differ in implementation but they use the same principle.\nOf the EAs family, GAs are the most widely known. GAs have the following elements: a population of individuals (also called chromosomes), selection according to fitness, crossover to produce new offspring, and random mutation of new offspring [9]. GAs create an environment in which a population of individuals, representing solutions to a particular problem, is allowed to evolve under certain rules towards a state that minimizes, in terms of optimization, the value of a function which is usually called the fitness function or the objective function.\nThere are a large number of variations of GAs. In the following we present a description of the simple, classical GAs. GAs start by defining the problem variables\n(genes) and the fitness function. These variables can be bounded or unbounded. A particular combination of variables produces a certain value of the fitness function and the objective of GAs is to find the combination that gives the best value of the fitness function. The terminology “best” implies that there is more than one solution and the solutions are not of equal value [2].\nAfter defining the variables and the fitness function GAs start by randomly generating a number pSize of individuals, or chromosomes. This step is called initialization.\nGAs were originally proposed to be binary coded to imitate the genetic encoding of natural organisms [15]. But later other encoding schemes were presented. The most widely used scheme is real-valued encoding. In this scheme a candidate solution is represented as a real-valued vector in which the dimension of the chromosomes is constant and equal to the dimension of the solution vectors [1]. This dimension is denoted by nPar. The fitness function of each chromosome is evaluated. The next step is selection. The purpose of this procedure is to determine which chromosomes are fit enough to survive and possibly produce offspring. This is decided according to the fitness function of the chromosome in that the higher the fitness function is the more chance it has to be selected for mating. There are several selection methods such as the roulette wheel selection, random selection, rank selection, tournament selection, and others [9]. The percentage of chromosomes selected for mating is denoted by sRate. Crossover is the next step in which offspring of two parents are produced to enrich the population with fitter chromosomes. There are several\napproaches to perform this process, the most common of which is single-point crossover and multi-point crossover.\nWhile crossover is the mechanism that enables the GA to communicate and share information about fitter chromosomes, it is not sufficient to efficiently explore the search space. Mutation, which is a random alteration of a certain percentage mRate of chromosomes, is the other mechanism which enables the GA to examine unexplored regions in the search space. It is important to keep a balance between crossover and mutation. High crossover rate can cause converging to local minima and high mutation rate can cause very slow convergence.\nNow that a new generation is formed, the fitting function of the offspring is calculated and the above procedures repeat for a number of generations nGen or until a stopping criterion terminates the algorithm."
    }, {
      "heading" : "4 Empirical Evaluation",
      "text" : "We tested the new distance GANED on time series because this is our field of expertise, but we believe GANED is highly applicable in bioinformatics and text mining.\nTime series data are normally numeric, but there are different methods to transform them to symbolic data. The most important symbolic representation method of time series is the Symbolic Aggregate approXimation (SAX) [7]. The first step of SAX is to normalize the time series because SAX is based on the assumption that normalized time series have a Guassian distribution, so SAX can only be applied to normalized time series. The second step is to reduce the dimensionality of the time series by using a time series representation method called Piecewise Aggregate Approximation (PAA) [3], [14]. This PAA representation of the time series is then discretized. This is achieved by determining the breakpoints. The number of the breakpoints is related to the desired alphabet size and their locations are obtained using statistical lookup tables.\nThe distance between the resulting time series after applying the above steps is computed using the following relation:\n( ) ( )( )∑ =\n≡ N\ni ii r̂,ŝdistN nR̂,ŜMINDIST 1 2 (4)\nWhere n is the length of the original time series, N is the number of segments, Ŝ and R̂ are the symbolic representations of the two time series S and R , respectively, and where the function )(dist is implemented by using the appropriate lookup table.\nWe tested our new distance GANED on time series classification task based on the first nearest-neighbor (1-NN) rule using leaving-one-out cross validation. This means that every time series is compared to the other time series in the dataset. If the 1-NN does not belong to the same class, the error counter is incremented by 1.\nWe conducted experiments using datasets of different sizes and dimensions available at UCR [4].\nAs indicated earlier, we tested GANED on symbolically represented time series This means that the time series were transformed to symbolic sequences using the first three step of SAX presented earlier in this section, but instead of using MINDIST given in relation (4), we use our distance GANED. The parameters nλ in the definition of GANED (relation (3)) are defined using GAs. This means that for each value of the alphabet size we formulate a GAs optimization problem where the fitness function is the classification error, and the parameters of the optimization problem are nλ . Practically n can take any value that does not exceed that of the shortest string of the two strings S ,T . However, in the experiments we conducted { }321 ,,n∈ because these are the values of interest for time series. The values of nλ varied in the interval [ ]10, .\nNotice that GANED can be applied to strings of different lengths, which is one of its advantages since most similarity measures in time series mining are applied only to time series of the same length.\nFor the GAs we used, the population size pSize was 12, the number of generations nGen was set to 20. The mutation rate mRate was 0.2 and the selection rate sRate was 0.5. The dimension of the problem nPar depends on the number of parameters used in GANED (as mentioned earlier, they were tested for { }321 ,,n∈ ). Table 1 summarizes the symbols used in the experiments together with their corresponding values.\nFor each dataset we use GAs on the training datasets to get the vector nλ that minimizes the classification error on these training datasets, and then we utilize this optimal nλ vector on the corresponding testing datasets to get the final classification error for each dataset.\nWe compared GANED with MINDIST. This means after we represent the time series symbolically as indicated at the beginning of this section we classify them using GANED first then using MINDIST. We chose to compare GANED with MINDIST because we used the same symbolic representation that MINDIST uses. However, GANED can be used\nwith any sequential data.\nIt is important to mention however that MINDIST has a lower complexity than that of GANED.\nIn Table 2 we present some of the results we obtained for alphabet size equal to 3, 10, and 20, respectively. pSize Population size 12 nGen Number of generations 20 mRate Mutation rate 0.2 sRate Selection rate 0.5 nPar Number of parameters varies\nTable 1. The symbol table together with the corresponding values used in the experiments.\nTable 2 (continued)\nGun_Point\nGANED MINDIST\nα\nngr\nam\nnλ Classification Error Classification\nError 1 [0.19728] 0.193 2 [0.95798 0.58518] 0.193 3\n3 [0.40628 0.95213 0.68035] 0.2\n0.307\n1 [0.98445] 0.147 2 [0.93927 0.99038] 0.127 10\n3 [0.15187 0.40029 0.24364] 0.12\n0.233\n1 [0.16625] 0.06 2 [0.5852 0.0038735] 0.06 20\n3 [0.32809 0.42736 0.12747]] 0.06\n0.12\nOlive Oil\nGANED MINDIST\nα\nngr\nam\nnλ Classification Error Classification\nError 1 [0.70608] 0.4 2 [0.53732 0.14595] 0.4 3\n3 [0.96676 0.15111 0.0015139] 0.4\n0.833\n1 [0.76393] 0.667 2 [0.2953 0.41039] 0.667 10\n3 [0.97014 0.29259 0.080068] 0.667\n0.833\n1 [0.028529] 0.267 2 [0.93581 0.20714] 0.233 20\n3 [0.18231 0.09461 0.68031] 0.233\n0.833\nTrace\nGANED MINDIST\nα\nngr\nam\nnλ Classification Error Classification\nError 1 [0.96149] 0.27 2 [0.80699 0.14789] 0.26 3\n3 [0.89336 0.01668 0.3959] 0.26\n0.54\n1 [0.76432] 0.08 2 [0.42505 0.64252] 0.09 10\n3 [0.95513 0.93675 0.99434] 0.04\n0.42\n1 [0.92115] 0.1 2 [0.89948 0.8597] 0.12 20\n3 [0.69135 0.21079 0.9382] 0.12\n0.36\nAs we can see from the results, the classification errors of GANED are smaller than those of MINDIST for all the datasets and for all values of the alphabet size. The results of other datasets in the archive were similar."
    }, {
      "heading" : "5 Conclusion and Perspectives",
      "text" : "In this paper we presented a new normalized edit distance. This new distance, GANED, is related directly to the edit distance and it takes into account the length of the two strings. The particularity of our new distance is that it uses an optimization algorithm; the genetic algorithms, to set the values of its parameters. We tested the new distance by comparing it to another distance applied to strings and we showed how our new distance GANED has a better performance.\nThe new distance was applied in this work to symbolically represented time series. However, we believe other applications might be more appropriate for our new distance."
    } ],
    "references" : [ {
      "title" : "Genetic Algorithms and Genetic Programming Modern Concepts and Practical Applications",
      "author" : [ "M. Affenzeller", "S. Winkler", "S. Wagner", "A. Beham" ],
      "venue" : "Chapman and Hall/CRC",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Practical Genetic Algorithms with CD-ROM",
      "author" : [ "R.L. Haupt", "S.E. Haupt" ],
      "venue" : "Wiley-Interscience,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Dimensionality Reduction for Fast Similarity Search in Large Time Series Databases",
      "author" : [ "E Keogh", "K Chakrabarti", "M. Pazzani", "Mehrotra" ],
      "venue" : "J. of Know. and Inform. Sys.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Scatter Search: Methodology and Implementations in C",
      "author" : [ "M Laguna", "R. Marti" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2003
    }, {
      "title" : "A Symbolic Representation of Time Series, with Implications for Streaming Algorithms",
      "author" : [ "J. Lin", "E. Keogh", "S. Lonardi", "B.Y. Chiu" ],
      "venue" : "DMKD",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2003
    }, {
      "title" : "Computation of Normalized Edit Distances and Applications",
      "author" : [ "A. Marzal", "E.E.Vidal" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence, 15(9):926–932, September",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "An Introduction to Genetic Algorithms",
      "author" : [ "M. Mitchell" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1996
    }, {
      "title" : "Extending the Edit Distance Using Frequencies of Common Characters",
      "author" : [ "Muhammad Fuad", "M.M", "P.F. Marteau" ],
      "venue" : "19th International Conference on Database and Expert Systems Applications - DEXA'08, Lecture Notes in Computer Science, 2008, Volume 5181/2008, 1-5 September,2008, Turin, Italy",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "The Extended Edit Distance Metric",
      "author" : [ "M.M. Muhammad Fuad", "P.F. Marteau" ],
      "venue" : "Sixth International Workshop on Content-Based Multimedia Indexing (CBMI",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2008
    }, {
      "title" : "The Multi-resolution Extended Edit Distance",
      "author" : [ "Muhammad Fuad", "M.M", "P.F. Marteau" ],
      "venue" : "Third International ICST Conference on Scalable Information Systems, Infoscale, 2008, ACM Digital Library, June 4-6, 2008. Vico Equense, Italy",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "The String-to-String Correction Problem",
      "author" : [ "R. Wagner", "M.J. Fischer" ],
      "venue" : "Journal of the Association for Computing Machinery,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1974
    }, {
      "title" : "Fast Time Sequence Indexing for Arbitrary Lp norms",
      "author" : [ "B Yi", "K.", "C. Faloutsos" ],
      "venue" : "Proceedings of the 26st International Conference on Very Large Databases, Cairo, Egypt",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Introduction to Evolutionary Algorithms",
      "author" : [ "X. Yu", "M. Gen" ],
      "venue" : "Springer,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "In [10], [11], and [12] we presented two new extensions of the edit distance.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 8,
      "context" : "In [10], [11], and [12] we presented two new extensions of the edit distance.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 9,
      "context" : "In [10], [11], and [12] we presented two new extensions of the edit distance.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 10,
      "context" : "One of the main distances used to handle sequential data is the edit distance (ED) [13], also called the Levenshtein distance, which is defined as the minimum number of delete, insert, and substitute operations needed to transform string S into string R .",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 7,
      "context" : "In [10], [11], and [12] two new extensions of ED; the extended edit distance (EED) and the multi-resolution extended edit distance (MREED) were proposed.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 8,
      "context" : "In [10], [11], and [12] two new extensions of ED; the extended edit distance (EED) and the multi-resolution extended edit distance (MREED) were proposed.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 9,
      "context" : "In [10], [11], and [12] two new extensions of ED; the extended edit distance (EED) and the multi-resolution extended edit distance (MREED) were proposed.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 5,
      "context" : "Another important modification is the normalized edit distance (NED) [8].",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 5,
      "context" : "It has been shown in [8] that NDE is not a distance metric.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 7,
      "context" : "As mentioned in Section 1, the idea of considering the frequency of characters or bi-grams in computing the distance has previously been proposed in [10], [11], and [12].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 8,
      "context" : "As mentioned in Section 1, the idea of considering the frequency of characters or bi-grams in computing the distance has previously been proposed in [10], [11], and [12].",
      "startOffset" : 155,
      "endOffset" : 159
    }, {
      "referenceID" : 9,
      "context" : "As mentioned in Section 1, the idea of considering the frequency of characters or bi-grams in computing the distance has previously been proposed in [10], [11], and [12].",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 7,
      "context" : "On the one hand, the search space they use is very limited, and on the other hand, generalizing the distances proposed in [10], [11], and [12] using the same basic heuristics to define the frequency factors makes this process inefficient yet limited to very small regions in the search space.",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 8,
      "context" : "On the one hand, the search space they use is very limited, and on the other hand, generalizing the distances proposed in [10], [11], and [12] using the same basic heuristics to define the frequency factors makes this process inefficient yet limited to very small regions in the search space.",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 9,
      "context" : "On the one hand, the search space they use is very limited, and on the other hand, generalizing the distances proposed in [10], [11], and [12] using the same basic heuristics to define the frequency factors makes this process inefficient yet limited to very small regions in the search space.",
      "startOffset" : 138,
      "endOffset" : 142
    }, {
      "referenceID" : 6,
      "context" : "GAs have the following elements: a population of individuals (also called chromosomes), selection according to fitness, crossover to produce new offspring, and random mutation of new offspring [9].",
      "startOffset" : 193,
      "endOffset" : 196
    }, {
      "referenceID" : 1,
      "context" : "The terminology “best” implies that there is more than one solution and the solutions are not of equal value [2].",
      "startOffset" : 109,
      "endOffset" : 112
    }, {
      "referenceID" : 12,
      "context" : "GAs were originally proposed to be binary coded to imitate the genetic encoding of natural organisms [15].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 0,
      "context" : "In this scheme a candidate solution is represented as a real-valued vector in which the dimension of the chromosomes is constant and equal to the dimension of the solution vectors [1].",
      "startOffset" : 180,
      "endOffset" : 183
    }, {
      "referenceID" : 6,
      "context" : "There are several selection methods such as the roulette wheel selection, random selection, rank selection, tournament selection, and others [9].",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 4,
      "context" : "The most important symbolic representation method of time series is the Symbolic Aggregate approXimation (SAX) [7].",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 2,
      "context" : "The second step is to reduce the dimensionality of the time series by using a time series representation method called Piecewise Aggregate Approximation (PAA) [3], [14].",
      "startOffset" : 159,
      "endOffset" : 162
    }, {
      "referenceID" : 11,
      "context" : "The second step is to reduce the dimensionality of the time series by using a time series representation method called Piecewise Aggregate Approximation (PAA) [3], [14].",
      "startOffset" : 164,
      "endOffset" : 168
    } ],
    "year" : 2012,
    "abstractText" : "The normalized edit distance is one of the distances derived from the edit distance. It is useful in some applications because it takes into account the lengths of the two strings compared. The normalized edit distance is not defined in terms of edit operations but rather in terms of the edit path. In this paper we propose a new derivative of the edit distance that also takes into consideration the lengths of the two strings, but the new distance is related directly to the edit distance. The particularity of the new distance is that it uses the genetic algorithms to set the values of the parameters it uses. We conduct experiments to test the new distance and we obtain promising results.",
    "creator" : "PScript5.dll Version 5.2.2"
  }
}