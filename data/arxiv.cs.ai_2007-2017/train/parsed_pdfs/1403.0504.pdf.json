{
  "name" : "1403.0504.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "A Compilation Target for Probabilistic Programming Languages",
    "authors" : [ "Brooks Paige", "Frank Wood" ],
    "emails" : [ "BROOKS@ROBOTS.OX.AC.UK", "FWOOD@ROBOTS.OX.AC.UK" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Compilation is source to source transformation. We use the phrase intermediate representation to refer to a target language for a compiler. This paper introduces a C-language library that makes possible a C-language intermediate representation for probabilistic programming languages that can itself be compiled to executable machine code. We call this intermediate language probabilistic C. Probabilistic C can be compiled normally and uses only macros and posix operating system libraries (Open Group, 2004a) to implement general-purpose, scalable, parallel probabilistic programming inference. Note that in this paper we do not show how to compile any existing probabilistic programming languages (i.e. IBAL (Pfeffer, 2001), BLOG (Milch et al., 2007), Church (Goodman et al., 2008), Figaro (Pfeffer, 2009), Venture (Mansinghka et al., 2013), or Anglican (Wood et al., 2014)) to this intermediate representation; instead we leave this to future work noting that there is a wealth of readily available resources on language to language compilation that could be leveraged to do this. We instead characterize the performance of the intermediate representation itself by writing programs directly in probabilistic C and then testing them on computer architectures\nand programs that illustrate the capacities and trade-offs of both the forward inference strategies probabilistic C employs and the operating system functionality on which it depends.\nProbabilistic C programs compile to machine executable meta-programs that perform inference over the original program via forward methods such as sequential Monte Carlo (Doucet et al., 2001) and particle MCMC variants (Andrieu et al., 2010). Such inference methods can be implemented in a sufficiently general way so as to support inference over the space of probabilistic program execution traces using just posix operating system primitives."
    }, {
      "heading" : "1.1. Related work",
      "text" : "The characterization of probabilistic programming inference we consider here is the process of sampling from the a posteriori distribution of execution traces arising from stochastic programs constrained to reflect observed data. This is the view taken by the Church (Goodman et al., 2008), Venture (Mansinghka et al., 2013), and Anglican (Wood et al., 2014) programming languages among others. In such languages, models for observed data can be described purely in terms of a forward generative process.\nMarkov chain Monte Carlo (MCMC) is used by these systems to sample from the posterior distribution of program execution traces. Single-site Metropolis Hastings (MH) (Goodman et al., 2008) and particle MCMC (PMCMC) (Wood et al., 2014) are two such approaches. In the latter it was noted that a fork-like operation is a fundamental requirement of forward inference methods for probabilistic programming, where fork is the standard posix operating system primitive (Open Group, 2004b). Kiselyov & Shan (2009) also noted that delimited continuations, a user-level generalization of fork could be used for inference, albeit in a restricted family of models."
    }, {
      "heading" : "2. Probabilistic Programming",
      "text" : "Any program that makes a random choice over the course of its execution implicitly defines a prior distribution over its random variables; running the program can be interpreted as drawing a sample from the prior. Inference in\nar X\niv :1\n40 3.\n05 04\nv1 [\ncs .A\nI] 3\nM ar\n2 01\n4\n#include \"probabilistic.h\"\nint main(int argc, char **argv) {\ndouble var = 2; double mu = normal_rng(1, 5);\nobserve(normal_lnp(9, mu, var)); observe(normal_lnp(8, mu, var));\np r e d i c t f(\"mu,%f\\n\", mu);\nreturn 0; }\nFigure 1. Two data points, distributed according to a Gaussian with unknown mean µ. We place a N (1, 5) prior on µ, and observe two data points drawn fromN (µ, 2).\nprobabilistic programs involves conditioning on observed data, and characterizing the posterior distribution of the random variables given data. We introduce probabilistic programming capabilities into C by providing a library with two functions: observe which conditions the program execution trace given the log-likelihood of a data point, and predict which marks expressions for which we want posterior samples. Any random number generator and sampling library can be used for making random choices in the program, any numeric log likelihood value can be passed to an observe, and any C expression which can be printed can be reported using predict. The library includes a single macro which renames main and wraps it in another function that runs the original in an inner loop in the forward inference algorithms to be described.\nFigure 1 shows a simple probabilistic C program for estimating the posterior distribution for the mean of a Gaussian, conditioned on two observed data points y1, y2, corresponding to the model\nµ ∼ N (1, 5), y1, y2 iid∼ N (µ, 2). (1)\nWe observe the data y1, y2 and predict the posterior distribution of µ. The functions normal rng and normal lnp in Figure 1 return (respectively) a normallydistributed random variate and the log probability density of a particular value, with mean and variance parameters mu and var. The observe statement requires only the logprobability of the data points 8 and 9 conditioned on the current program state; no other information about the likelihood function or the generative process. In this program we predict the posterior distribution of a single value mu.\nAlthough C is a comparatively low-level language, it can nonetheless represent many well-known generative models concisely and transparently. A hidden Markov model example is shown in Figure 2, in which N observed data points y1:N are drawn from an underlying Markov chain with K latent states, each with Gaussian emission distributions with mean µk, and a (known) K ×K state transition\nmatrix T , such that\nz0 ∼ Discrete([1/K, . . . , 1/K]) (2) zn|zn−1 ∼ Discrete(Tzn−1) (3) yn|zn ∼ N (µzn , σ2). (4)\nBayesian nonparametric models can also be represented concisely; in Figure 3 we show a generative model for an infinite mixture of Gaussians, using a Chinese restaurant process (CRP) to sample non-negative integer partition assignments φn for each data point y1, . . . , yN . For each partition, mean and variance parameters µφn , σ 2 φn\nare drawn from a Normal-Gamma prior; the data points yn themselves are drawn from a normal distribution with parameters φn, with the full generative model\nφn ∼ CRP(α) (5) 1/σ2φn ∼ Gamma(1, 1) (6) µφn |σ2φn ∼ N (0, σ 2 φn) (7)\nyn|φn, µφn , σ2φn ∼ N (µφn , σ 2 φn). (8)"
    }, {
      "heading" : "2.1. Operating system primitives",
      "text" : "Inference proceeds by drawing posterior samples from the space of program execution traces. We define an execution\ntrace as the sequence of memory states (stack frames and allocated memory contents) that arises during the sequential step execution of machine instructions.\nThe algorithms we propose for inference in probabilistic programs map directly onto standard computer operating system constructs, exposed in POSIX-compliant operating systems including Linux, BSD, and Mac OS X. The cornerstone of our approach is POSIX fork (Open Group, 2004b). When a process forks, it clones itself, creating a new process with an identical copy of the execution state of the original process, and identical source code; both processes then continue with normal program execution completely independently from the point where fork was called. While copying program execution state may naı̈vely sound like a costly operation, this actually can be rather efficient: when fork is called, a lazy copy-on-write procedure is used to avoid deep copying the entire program\nmemory. Instead, initially only the pagetable is copied to the new process; when an existing variable is modified in the new program copy, then and only then are memory contents duplicated. The overall cost of forking a program is proportional to the fraction of memory which is rewritten by the child process (Smith & Maguire, 1988).\nUsing forkwe can branch a single program execution state and explore many possible downstream execution paths. Each of these paths runs as its own process, and will run in parallel with other processes. In general, multiple processes run in their own memory address space, and do not communicate or share state. We handle inter-process communication via a small shared memory segment; the details of what global data must be stored are provided later.\nSynchronization between processes is handled via mutual exclusion locks (mutex objects). Mutexes become particularly useful for us when used in conjunction with a synchronized counter to create a barrier, a high-level blocking construct which prevents any process proceeding in execution state beyond the barrier until some fixed number of processes have arrived."
    }, {
      "heading" : "3. Inference",
      "text" : ""
    }, {
      "heading" : "3.1. Probability of a program execution trace",
      "text" : "To notate the probability of a program execution trace, we enumerate all N observe statements, and the associated observed data points y1, . . . , yN . During a single run of the program, some total number N ′ random choices x′1, . . . ,x ′ N ′ are made. While N\n′ may vary between individual executions of the program, we require is that N is constant. That is, valid probabilistic models correspond to probabilistic C program with the same number of observe directive calls on every program execution. As it is left to the programmer (or potentially the compiler; see Section 5 for a brief discussion of this point) it is quite easy to write models in probabilistic C that are statistically difficult to reason about. This is the primary reason for proposing probabilistic C as a compilation target. In many probabilistic programming languages, for instance Anglican (Wood et al., 2014) and Venture (Mansinghka et al., 2013), such constraints are explicitly imposed by the language itself.\nThe observations yn can appear at any point in the program source code and define a partition of the random choices x′1:N ′ into N subsequences x1:N , where each xn contains all random choices made up to observing yn but excluding any random choices prior to observation yn−1. We can then define the probability of any single program execution trace as\np(y1:N ,x1:N ) = N∏ n=1 g(yn|x1:n)f(xn|x1:n−1) (9)\nIn this manner, any model with a generative process that can be described in arbitrary C code can be represented in this sequential form in the space of program execution traces.\nEach observe statement takes as its argument ln g(yn|x1:n). Each quantity of interest in a predict statement corresponds to some deterministic function h(·) of all random choices x1:N made during the execution of the program. Given a set of S posterior samples {x(s)1:N}, we can approximate the posterior distribution of the predict value as\nh(x1:N ) ≈ 1\nS S∑ s=1 h(x (s) 1:N ). (10)"
    }, {
      "heading" : "3.2. Sequential Monte Carlo",
      "text" : "Forward simulation-based algorithms are a natural fit for probabilistic programs: run the program and report executions that match the data. Sequential Monte Carlo (SMC, sequential importance resampling) forms the basic building block of other, more complex particle-based methods, and can itself be used as a simple approach to probabilistic programming inference. SMC approximates a target density p(x1:N |y1:N ) as a weighted set of L realized trajectories x`1:N such that\np(x1:N |y1:N ) ≈ L∑ `=1 w`Nδx`1:N (x1:N ). (11)\nFor most probabilistic programs of interest, it will be intractable to sample from p(x1:N |y1:N ) directly. Instead, noting that (for n > 1) we have the recursive identity\np(x1:n|y1:n) (12) = p(x1:n−1|y1:n−1)g(yn|x1:n)f(xn|x1:n−1),\nwe sample from p(x1:N |y1:N ) by iteratively sampling from each p(x1:n|y1:n), in turn, from 1 through N . At each n, we construct an importance sampling distribution by proposing from some distribution q(xn|x1:n−1, y1:n); in probabilistic programs we find it convenient to propose directly from the executions of the program, i.e. each sequence of random variates xn is jointly sampled from the program execution state dynamics\nx`n ∼ f(xn|x a`n−1 1:n−1) (13)\nwhere a`n−1 is an “ancestor index,” the particle index 1, . . . , L of the parent (at time n−1) of x`n. The unnormalized particle importance weights at each observation yn are simply the observe data likelihood\nw̃`n = g(y1:n,x ` 1:n) (14)\nAlgorithm 1 Parallel SMC program execution Assume: N observations, L particles\nlaunch L copies of the program (parallel) for n = 1 . . . N do\nwait until all L reach observe yn (barrier) update unnormalized weights w̃1:Ln (serial) if ESS < τ then\nsample number of offspring O1:Ln (serial) set weight w̃1:Ln = 1 (serial) for ` = 1 . . . L do\nfork or exit (parallel) end for else set all number of offspring O`n = 1 (serial) end if continue program execution (parallel) end for wait until L program traces terminate (barrier) predict from L samples from p̂(x1:L1:N |y1:N ) (serial)\nwhich can be normalized as\nw`n = w̃`n∑L `=1 w̃ ` n . (15)\nAfter each step n, we now have a weighted set of execution traces which approximate p(x1:n|y1:n). As the program continues, traces which do not correspond well with the data will have weights which become negligibly small, leading in the worst case to all weight concentrated on a single execution trace. To counteract this deficiency, we resample from our current set of L execution traces after each observation yn, according to their weights w`n. This is achieved by sampling a count O`n for the number of “offspring” of a given execution trace ` to be included at time n + 1; any sampling scheme must ensure E[O`n] = w`n. Sampling offspring counts O`n is equivalent to sampling ancestor indices a`n. Program execution traces with no offspring are killed; program execution traces with more than one offspring are forked multiple times. After resampling, all weights w`n = 1.\nWe only resample if the effective sample size\nESS ≈ 1∑ `(w ` n) 2 (16)\nis less than some threshold value τ ; we choose τ = L/2.\nIn probabilistic C, each observe statement forms a barrier: parallel execution cannot continue until all particles have arrived at the observe and have reported their current unnormalized weight. As execution traces arrive at the observe barrier, they take the number of particles which have already reached the current observe as a (temporary)\nunique identifier. Program execution is then blocked as the effective sample size is computed and the number of offspring are sampled. The number of offspring are stored in a shared memory block; when the number of offspring are computed, each particle uses the identifier assigned when reaching the observe barrier to retrieve (asynchronously) from shared memory the number of children to fork. Particles with no offspring wait for any child processes to complete execution, and terminate; particles with only one offspring do not fork any children but continue execution as normal.\nThe SMC algorithm is outlined in Algorithm 1, with annotations for which steps are executed in parallel, serially, or form a barrier. After a single SMC sweep is complete, we sample values for each predict, and then (if desired) repeat the process, running a new independent particle filter, to draw an additional batch of samples."
    }, {
      "heading" : "3.3. Particle Metropolis-Hastings",
      "text" : "Particle Markov chain Monte Carlo, introduced in Andrieu et al. (2010), uses sequential Monte Carlo to generate highdimensional proposal distributions for MCMC. The most simple formulation is the particle independent MetropolisHastings algorithm. After running a single particle filter sweep, we compute an estimate of the marginal likelihood,\nẐ ≡ p(y1:N ) ≈ N∏ n=1\n[ 1\nL L∑ `=1 w`n\n] . (17)\nWe then run another iteration of sequential Monte Carlo which we use as a MH proposal; we estimate the marginal likelihood Ẑ ′ of the new proposed particle set, and then with probability min(1, Ẑ ′/Ẑ) we accept the new particle set and output a new set of predict samples, otherwise outputting the same predict samples as in the previous iteration.\nThe inner loop of Algorithm 2 is otherwise substantially similar to SMC."
    }, {
      "heading" : "3.4. Particle Gibbs",
      "text" : "Particle Gibbs is a particle MCMC technique that has SMC at its core as well. It has better theoretical statistical convergence properties than PIMH, but may suffer due to degeneracy concerns in some models, and requires additional computational overhead. We initialize particle Gibbs by running a single sequential Monte Carlo sweep, and then alternate between\n1. sampling a single execution trace x̂1:M from the set of L weighted particles, and\n2. running a “conditional” SMC sweep, in which we\nAlgorithm 2 Parallel PIMH program execution Assume: M iterations, N observations, L particles\nfor m = 1 . . .M do launch L copies of the program (parallel) for n = 1 . . . N do\nwait until all L reach an observe (barrier) update unnormalized weights w̃1:L (serial) if ESS < τ then\nupdate proposal evidence estimate Ẑ ′ (serial) sample number of offspring O1:Ln (serial) set weight w̃1:Ln = 1 (serial) for ` = 1 . . . L do\nfork or exit (parallel) end for else set all number of offspring O`n = 1 (serial) end if continue program execution (parallel) end for wait until L program traces terminate (barrier) accept or reject new particle set (serial) predict from L samples from p̂(x1:L1:N |y1:N ) (serial) store current particle set x and evidence Ẑ (serial) continue to next iteration (parallel)\nend for\ngenerate L−1 new particles in addition to the retained x̂1:M .\nThe implementation based on operating system primitives is described in algorithms 3 and 4. The challenge here is that we must “retain” an execution trace, which we can later revisit to resume and branch arbitrarily many times. This is achieved by spawning off a “control” process at every observation point, which from then on manages the future of that particular execution state.\nAs before, processes arrive at an observe barrier, and when all particles have reached the observe we compute weights, and sample offspring counts O`n. Particles with O`n = 0 terminate, but new child processes are no longer spawned right away. Instead, all remaining particles fork a new process whose execution path immediately diverges from the main codebase and enters the retain and branch loop in Algorithm 4. This new process takes responsibility for actually spawning the O`n new children. The spawned child processes (and the original process which arrived at the observe barrier) wait (albeit briefly) at a new barrier marking the end of observe n, not continuing execution until all new child processes have been launched.\nProgram execution continues to the next observe, during which the retain / branch process waits until a full particle set reaches the end of the program. Once final weights w̃1:LN\nAlgorithm 3 Parallel Particle Gibbs program execution Assume: M iterations, N observations, L particles\nfor m = 1 . . .M do L′ ← L if m = 1, otherwise L− 1 launch S′ copies of the program (parallel) for n = 1 . . . N do\nwait until all L′ reach an observe (barrier) compute weights for all particles (serial) if m > 1 then\nsignal num offspring to retained trace (serial) end if for ` = 1 . . . L′ do\nspawn retain / branch process [Algo. 4] (parallel) end for wait until L particles finish branching (barrier) continue program execution (parallel) end for wait until L program traces terminate (barrier) predict from L samples from p̂(x1:L1:N |y1:N ) (serial) select and signal particle to retain (serial) wait until N processes are ready to branch (barrier) continue to next iteration (parallel)\nend for\nare computed, we sample (according to weight) from the final particle set to select a single particle to retain during the next SMC iteration. When the particle is selected, a signal is broadcast to all retain / branch loops indicating which process ids correspond to the retained particle; all except the retained trace exit.\nThe retain / branch loop now goes into waiting again (this time for a branch signal), and we begin SMC from the top of the program. As we arrive at each observe n, we only sample L− 1 new offspring to consider: we guarantee that at least one offspring is spawned from the retained particle at n (namely, the retained execution state at n + 1). However, depending on the weights, often sampling offspring will cause us to want more than a single child from the retained particle. So, we signal to the retained particle execution state at time n the number of children to spawn; the retain / branch loop returns to its entry point and resumes waiting, to see if the previously retained execution state will be retained yet again.\nNote that in particle Gibbs, we must resample (select offspring and reset weights w`n = 1) after every observation in order to be able to properly align the retained particle on the next iteration through the program."
    }, {
      "heading" : "4. Experiments",
      "text" : "We now turn to benchmarking probabilistic C against existing probabilistic programming engines, and evaluate the\nAlgorithm 4 Retain and Branch inner loop Assume: input initial C > 0 children to spawn is retained← false while true do\nif C = 0 and not is retained then discard this execution trace, exit else {C ≥ 0} spawn C new children end if wait for signal which resets is retained if is retained then\nwait for signal which resets C else\ndiscard this execution trace, exit end if\nend while\nrelative strengths of the three inference algorithms in Section 3. We find that compilation improves performance by 100 times or more over interpreted versions of the same inference algorithm. We also find evidence that suggests that optimising operating systems to support probabilistic programming usage could yield significant performance improvements as well.\nThe programs/models we use in our experiments are chosen to be sufficiently simplistic that we can compute the exact posterior distribution of interest analytically. Given the true posterior distribution p, we measure sampler performance by the KL-divergence KL(p̂||p), where p̂ is our Monte Carlo estimate. The first benchmark program we consider is a hidden Markov model (HMM) very similar to that of Figure 2, where we predict the marginal distributions of each latent state. The HMM used in our experiments here is larger; it has the same model structure, but with K = 10 states and 50 sequential observations, and each state k = 1, . . . , 10 has a Gaussian emission distribution with µk = k−1 and σ2 = 4. The second benchmark is the CRP mixture of Gaussians program in Figure 3, where we predict the number of different classes."
    }, {
      "heading" : "4.1. Comparative performance of inference engines",
      "text" : "We begin by benchmarking against two existing probabilistic programming engines: Anglican, as described in (Wood et al., 2014), which also implements particle Gibbs, but is an interpreted language based on Scheme, implemented in Clojure, and running on the JVM; and probabilistic-js1, a compiled system implementing the inference approach in (Wingate et al., 2011), which runs Metropolis-Hastings over each individual random choice in the program execution trace. The interpreted particle Gibbs engine is mul-\n1https://github.com/dritchie/probabilistic-js\ntithreaded, and we run it with 100 particles and 8 simultaneous threads; the Metropolis-Hastings engine only runs on a single core. In Figure 4 we compare inference performance in both of these existing engines to our particle Gibbs backend, running with 100 and 1000 particles, in an 8 core cloud computing environment on Amazon EC2, running on Intel Xeon E5-2680 v2 processors. Our compiled probabilistic C implementation of particle Gibbs runs over 100 times faster that the existing interpreted engine, generating good sample sets in on the order of tens of seconds.\nThe probabilistic C inference engine implements particle Gibbs, SMC, and PIMH sampling, which we compare in Figure 5 using both 100 and 1000 particles.\nFigures 4 and 5 plot wall clock time against KL-divergence. We use all generated samples as our empirical posterior distribution in order to produce as fair a comparison as possible. In all engines, results are reasonably stable across runs; shaded regions denote minimum and maximum values over\nmultiple runs, with the median marked as a dark line. A sampler which is correctly drawing samples from the target density will show an approximately linear decrease in KLdivergence on such log-log plots. The methods based on sequential Monte Carlo do not provide any estimate of the posterior distribution until completing a single initial particle filter sweep; for large numbers of particles this may be a non-trivial amount of time. In contrast, the MH sampler begins drawing samples effectively immediately, although it may take a large number of individual steps before converging to the correct stationary distribution; individual Metropolis-Hastings samples are likely to be more autocorrelated, but producing each one is faster."
    }, {
      "heading" : "4.2. Performance characteristics across multiple cores",
      "text" : "As the probabilistic C inference engine offloads much of the computation to underlying operating system calls, we characterize the limitations of the OS implementation by\ncomparing time to completion as we vary the number of cores. Tests for the hidden Markov model across core count (all on EC2, all with identical Intel Xeon E5-2680 v2 processors) are shown in Figure 6."
    }, {
      "heading" : "5. Discussion",
      "text" : "Probabilistic C is a method for performing inference in probabilistic programs. Methodologically it derives from the forward methods for performing inference in statistical models based on sequential Monte Carlo and particle Markov chain Monte Carlo. We have shown that it is possible to efficiently and scalably implement this particular kind of inference strategy using existing, standard compilers and posix compliant operating system primitives.\nWhat most distinguishes Probabilistic C from prior art is that it is highly compatible with modern computer architectures, all the way from operating systems to central processing units (in particular their virtual memory operations), and, further, that it delineates a future research program for scaling the performance of probabilistic programming systems to large scale problems by investigating systems optimizations of existing computer architectures. Note that this is distinct but compatible with approaches to optimizing probabilistic programming systems by compilation optimizations, stochastic hardware, and dependency tracking with efficient updating of local execution trace subgraphs. It may, in the future, be possible to delineate model complexity and hardware architecture regimes in which each approach is optimal; we assert that, for now, it is unclear what those regimes are or will be. This paper is but one step towards such a delineation.\nSeveral interesting research questions remain: (1) Is it more sensible to write custom memory management and use threads than fork and processes as we have done? The main contribution of this paper is to establish a probabilistic programming system implementation against a standardized, portable abstraction layer. It might be possible to eke out greater performance by capitalizing on the fact modern architectures are optimised for parallel threads more so than parallel processes; however, exploiting this would entail implementing memory management de facto equivalent in action to fork which may lead to lower portability. (2) Would shifting architectures to small page sizes help? There is a bias towards large page size support in modern computer architectures. It may be that the system use characteristics of probabilistic programming systems might provide a counterargument to that bias or inspire the creation of tuned end-to-end systems. Forking itself is lightweight until variable assignment which usually require manipulations of entire page tables. Large pages require large amounts of amortisation in order to absorb the cost of copying upon stochastic variable assignment. Smaller pages could potentially yield higher efficiencies. (3) What characteristics of process synchronisation can be improved specifically for probabilistic programming systems? This is both a systems and machine learning question. From a machine learning perspective we believe it may be possible to construct efficient sequential Monte Carlo algorithms that do not synchronize individual threads at observe barriers and instead synchronize in a queue. On a systems level it begs questions about what page replacement strategies to consider; perhaps entirely changing the page replacement schedule to reflect rapid process rather than thread multiplexing across cores.\nIt is the case that probabilistic C on its own allows programmers to easily write models that are very difficult to reason about statistically. For this reason we are not, in this paper, making a claim about a new probabilistic programming language – rather, in a programming languages sense, we at most claiming an intermediate representation compilation target that implements a particular style of inference that is natively parallel and possible to optimise by system architecture choice. It is possible (as helpfully pointed out by Vikash Mansinghka) that compiler optimisation techniques such as checking to see whether or not the program is natively in “static single assignment” form (Appel, 1998) can help avoid statistically ambiguous programs being allowed (at compilation). This we leave as future work. Further (as helpfully pointed out by Noah Goodman), programming languages constructs such as delimited continuations (Felleisen, 1988) can be thought of as user level abstractions of fork, and as such might provide, in the context of statistically safer languages, similar functionality at the user rather than system level."
    } ],
    "references" : [ {
      "title" : "Particle Markov chain Monte Carlo methods",
      "author" : [ "Andrieu", "Christophe", "Doucet", "Arnaud", "Holenstein", "Roman" ],
      "venue" : "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
      "citeRegEx" : "Andrieu et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Andrieu et al\\.",
      "year" : 2010
    }, {
      "title" : "SSA is functional programming",
      "author" : [ "Appel", "Andrew W" ],
      "venue" : "SIGPLAN notices,",
      "citeRegEx" : "Appel and W.,? \\Q1998\\E",
      "shortCiteRegEx" : "Appel and W.",
      "year" : 1998
    }, {
      "title" : "Sequential Monte Carlo methods in practice",
      "author" : [ "Doucet", "Arnaud", "De Freitas", "Nando", "Gordon", "Neil" ],
      "venue" : null,
      "citeRegEx" : "Doucet et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Doucet et al\\.",
      "year" : 2001
    }, {
      "title" : "The theory and practice of first-class prompts",
      "author" : [ "Felleisen", "Mattias" ],
      "venue" : "In Proceedings of the 15th ACM SIGPLANSIGACT symposium on Principles of programming languages,",
      "citeRegEx" : "Felleisen and Mattias.,? \\Q1988\\E",
      "shortCiteRegEx" : "Felleisen and Mattias.",
      "year" : 1988
    }, {
      "title" : "A language for generative models",
      "author" : [ "Goodman", "Noah D", "Mansinghka", "Vikash K", "Roy", "Daniel M", "Bonawitz", "Keith", "Tenenbaum", "Joshua B. Church" ],
      "venue" : "In In UAI, pp",
      "citeRegEx" : "Goodman et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Goodman et al\\.",
      "year" : 2008
    }, {
      "title" : "Monolingual probabilistic programming using generalized coroutines",
      "author" : [ "Kiselyov", "Oleg", "Shan", "Chung-chien" ],
      "venue" : "In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009),",
      "citeRegEx" : "Kiselyov et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Kiselyov et al\\.",
      "year" : 2009
    }, {
      "title" : "Venture: an interactive, Turing-complete probabilistic programming",
      "author" : [ "Mansinghka", "Vikash", "Selsam", "Daniel", "Perov", "Yura" ],
      "venue" : "URL http:// probcomp.csail.mit.edu/venture/",
      "citeRegEx" : "Mansinghka et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mansinghka et al\\.",
      "year" : 2013
    }, {
      "title" : "BLOG: Probabilistic models with unknown objects",
      "author" : [ "Milch", "Brian", "Marthi", "Bhaskara", "Russell", "Stuart", "Sontag", "David", "Ong", "Daniel L", "Kolobov", "Andrey" ],
      "venue" : "Statistical relational learning,",
      "citeRegEx" : "Milch et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Milch et al\\.",
      "year" : 2007
    }, {
      "title" : "IBAL: A probabilistic rational programming language",
      "author" : [ "Pfeffer", "Avi" ],
      "venue" : "In IJCAI, pp",
      "citeRegEx" : "Pfeffer and Avi.,? \\Q2001\\E",
      "shortCiteRegEx" : "Pfeffer and Avi.",
      "year" : 2001
    }, {
      "title" : "Figaro: An object-oriented probabilistic programming language. Charles River Analytics",
      "author" : [ "Pfeffer", "Avi" ],
      "venue" : "Technical Report,",
      "citeRegEx" : "Pfeffer and Avi.,? \\Q2009\\E",
      "shortCiteRegEx" : "Pfeffer and Avi.",
      "year" : 2009
    }, {
      "title" : "Effects of copy-on-write memory management on the response time of UNIX fork operations",
      "author" : [ "Smith", "Jonathan M", "Maguire", "Jr.", "Gerald Q" ],
      "venue" : "COMPUTING SYSTEMS,",
      "citeRegEx" : "Smith et al\\.,? \\Q1988\\E",
      "shortCiteRegEx" : "Smith et al\\.",
      "year" : 1988
    }, {
      "title" : "Lightweight implementations of probabilistic programming languages via transformational compilation",
      "author" : [ "Wingate", "David", "Stuhlmueller", "Andreas", "Goodman", "Noah D" ],
      "venue" : "In Proceedings of the 14th international conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "Wingate et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Wingate et al\\.",
      "year" : 2011
    }, {
      "title" : "A new approach to probabilistic programming inference",
      "author" : [ "Wood", "Frank", "van de Meent", "Jan Willem", "Mansinghka", "Vikash" ],
      "venue" : "In Proceedings of the 17th International conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "Wood et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Wood et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "IBAL (Pfeffer, 2001), BLOG (Milch et al., 2007), Church (Goodman et al.",
      "startOffset" : 27,
      "endOffset" : 47
    }, {
      "referenceID" : 4,
      "context" : ", 2007), Church (Goodman et al., 2008), Figaro (Pfeffer, 2009), Venture (Mansinghka et al.",
      "startOffset" : 16,
      "endOffset" : 38
    }, {
      "referenceID" : 6,
      "context" : ", 2008), Figaro (Pfeffer, 2009), Venture (Mansinghka et al., 2013), or Anglican (Wood et al.",
      "startOffset" : 41,
      "endOffset" : 66
    }, {
      "referenceID" : 12,
      "context" : ", 2013), or Anglican (Wood et al., 2014)) to this intermediate representation; instead we leave this to future work noting that there is a wealth of readily available resources on language to language compilation that could be leveraged to do this.",
      "startOffset" : 21,
      "endOffset" : 40
    }, {
      "referenceID" : 2,
      "context" : "Probabilistic C programs compile to machine executable meta-programs that perform inference over the original program via forward methods such as sequential Monte Carlo (Doucet et al., 2001) and particle MCMC variants (Andrieu et al.",
      "startOffset" : 169,
      "endOffset" : 190
    }, {
      "referenceID" : 0,
      "context" : ", 2001) and particle MCMC variants (Andrieu et al., 2010).",
      "startOffset" : 35,
      "endOffset" : 57
    }, {
      "referenceID" : 4,
      "context" : "This is the view taken by the Church (Goodman et al., 2008), Venture (Mansinghka et al.",
      "startOffset" : 37,
      "endOffset" : 59
    }, {
      "referenceID" : 6,
      "context" : ", 2008), Venture (Mansinghka et al., 2013), and Anglican (Wood et al.",
      "startOffset" : 17,
      "endOffset" : 42
    }, {
      "referenceID" : 12,
      "context" : ", 2013), and Anglican (Wood et al., 2014) programming languages among others.",
      "startOffset" : 22,
      "endOffset" : 41
    }, {
      "referenceID" : 4,
      "context" : "Single-site Metropolis Hastings (MH) (Goodman et al., 2008) and particle MCMC (PMCMC) (Wood et al.",
      "startOffset" : 37,
      "endOffset" : 59
    }, {
      "referenceID" : 12,
      "context" : ", 2008) and particle MCMC (PMCMC) (Wood et al., 2014) are two such approaches.",
      "startOffset" : 34,
      "endOffset" : 53
    }, {
      "referenceID" : 4,
      "context" : "Single-site Metropolis Hastings (MH) (Goodman et al., 2008) and particle MCMC (PMCMC) (Wood et al., 2014) are two such approaches. In the latter it was noted that a fork-like operation is a fundamental requirement of forward inference methods for probabilistic programming, where fork is the standard posix operating system primitive (Open Group, 2004b). Kiselyov & Shan (2009) also noted that delimited continuations, a user-level generalization of fork could be used for inference, albeit in a restricted family of models.",
      "startOffset" : 38,
      "endOffset" : 378
    }, {
      "referenceID" : 12,
      "context" : "In many probabilistic programming languages, for instance Anglican (Wood et al., 2014) and Venture (Mansinghka et al.",
      "startOffset" : 67,
      "endOffset" : 86
    }, {
      "referenceID" : 6,
      "context" : ", 2014) and Venture (Mansinghka et al., 2013), such constraints are explicitly imposed by the language itself.",
      "startOffset" : 20,
      "endOffset" : 45
    }, {
      "referenceID" : 0,
      "context" : "Particle Markov chain Monte Carlo, introduced in Andrieu et al. (2010), uses sequential Monte Carlo to generate highdimensional proposal distributions for MCMC.",
      "startOffset" : 49,
      "endOffset" : 71
    }, {
      "referenceID" : 12,
      "context" : "We begin by benchmarking against two existing probabilistic programming engines: Anglican, as described in (Wood et al., 2014), which also implements particle Gibbs, but is an interpreted language based on Scheme, implemented in Clojure, and running on the JVM; and probabilistic-js1, a compiled system implementing the inference approach in (Wingate et al.",
      "startOffset" : 107,
      "endOffset" : 126
    }, {
      "referenceID" : 11,
      "context" : ", 2014), which also implements particle Gibbs, but is an interpreted language based on Scheme, implemented in Clojure, and running on the JVM; and probabilistic-js1, a compiled system implementing the inference approach in (Wingate et al., 2011), which runs Metropolis-Hastings over each individual random choice in the program execution trace.",
      "startOffset" : 223,
      "endOffset" : 245
    } ],
    "year" : 2017,
    "abstractText" : "Forward inference techniques such as sequential Monte Carlo and particle Markov chain Monte Carlo for probabilistic programming can be implemented in any programming language by creative use of standardized operating system functionality including processes, forking, mutexes, and shared memory. Exploiting this we have defined, developed, and tested a probabilistic programming language intermediate representation language we call probabilistic C, which itself can be compiled to machine code by standard compilers and linked to operating system libraries yielding an efficient, scalable, portable probabilistic programming compilation target. This opens up a new hardware and systems research path for optimizing probabilistic programming systems.",
    "creator" : "LaTeX with hyperref package"
  }
}