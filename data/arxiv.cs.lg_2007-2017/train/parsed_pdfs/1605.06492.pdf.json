{
  "name" : "1605.06492.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Linear-memory and Decomposition-invariant Linearly Convergent Conditional Gradient Algorithm for Structured Polytopes",
    "authors" : [ "Dan Garber", "Ofer Meshi" ],
    "emails" : [ "meshi}@ttic.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "1. large memory requirement due to the need to store an explicit convex decomposition of the current iterate, and as a consequence, large running-time overhead per iteration\n2. the worst case convergence rate depends unfavorably on the dimension\nIn this work we present a new conditional gradient variant and a corresponding analysis that improves on both of the above shortcomings. In particular:\n1. both memory and computation overheads are only linear in the dimension\n2. in case the optimal solution is sparse, the new convergence rate replaces a factor which is at least linear in the dimension in previous works, with a linear dependence on the number of non-zeros in the optimal solution\nAt the heart of our method, and corresponding analysis, is a novel way to compute decomposition-invariant away-steps. While our theoretical guarantees do not apply to any polytope, they apply to several important structured polytopes that capture central concepts such as paths in graphs, perfect matchings in bipartite graphs, marginal distributions that arise in structured prediction tasks, and more. Our theoretical findings are complemented by empirical evidence which shows that our method delivers state-of-the-art performance."
    }, {
      "heading" : "1 Introduction",
      "text" : "The efficient reduction of a constrained convex optimization problem to a constrained linear optimization problem is an appealing algorithmic concept, in particular for large-scale problems. The reason is that for many feasible sets of interest, the problem of minimizing a linear function over the set admits much more efficient methods than its non-linear convex counterpart. Prime examples for this phenomenon include various structured polytopes that arise in combinatorial optimization, such as the path polytope of a graph (aka the unit flow polytope), the perfect matching polytope of a bipartite graph, and the base polyhedron of a matroid, for which we have highly efficient combinatorial algorithms for linear minimization that rely heavily on the specific rich structure of the polytope [22]. At the same time, minimizing a non-linear convex function over these sets usually requires the use of generic interior point solvers that are oblivious to the specific combinatorial structure of the underlying set, and as a result, are often\nar X\niv :1\n60 5.\n06 49\n2v 1\n[ m\nat h.\nO C\n] 2\n0 M\nay 2\n01 6\nmuch less efficient. Another important example includes structured sets of matrices such as the spectrahedron, i.e., convex-hull of unit-trace positive semidefinite matrices, or the nuclear ball that are central to many machine learning problems, such as matrix completion, for which linear optimization amounts to computing the leading eigenvector or leading pair of singular vectors, whereas, algorithms for non-linear convex optimization over these sets often rely on very expensive singular value decompositions. Indeed, it is for this reason, that the conditional gradient (CG) method (aka Frank-Wolfe algorithm), a method for constrained convex optimization that is based on solving linear subproblems over the feasible domain, has regained much interest in recent years in the machine learning, signal processing and optimization communities. It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].\nAs part of the regained interest in the conditional gradient method, there is also a recent effort to understand the convergence rates and associated complexities of conditional gradientbased methods, which is in general far less understood than other first-order methods, e.g., the projected gradient method. It is known, already from the first introduction of the method by Frank and Wolfe in the 1950’s [5], and the somewhat later work of Polyak and Levitin [20], that the method converges with a rate of roughly O(1/t) for minimizing a smooth convex function over a convex and compact set, which matches the rate of the standard projected gradient method for the same setting. However, it is not clear if this convergence rate improves under an additional standard strong-convexity assumption. In fact, certain lower bounds, such as in [18, 6], suggest that such improvement, even if possible, should come with a worse dependence on the problem’s parameters (e.g., the dimension), which is a phenomena that does not occur for the projected gradient method, for instance. Nevertheless, over the past years, various works tried to design natural variants of the CG method that converge provably faster under the additional strong convexity assumption, or a slightly weaker assumption, without dramatically increasing the per-iteration complexity, which is the main appeal for these methods. For instance, GuéLat and Marcotte [8] showed that a CG variant which uses the concept of away-steps converges exponentially fast in case the objective function is strongly convex, the feasible set is a polytope, and the optimal solution is located in the interior of the set. A similar result was presented by Beck and Teboulle [3] who considered a specific problem they refer to a the convex feasibility problem over an arbitrary convex set. They also obtained a linear convergence rate under the assumption that an optimal solution that is far enough from the boundary of the set exists. In both of these works, the exponent depends on the distance of the optimal solution from the boundary of the set, which in general can be arbitrarily small. Later, Ahipasaoglu, Sun and Todd [1] showed that in the specific case of minimizing a smooth and strongly convex function over the unit simplex, a variant of the CG method which also uses away-steps, converges with a linear rate. Unfortunately, it is not clear from their analysis how this rate depends on natural parameters of the problem such as the dimension and the condition number of the objective function.\nRecently, Garber and Hazan presented the first natural linearly-converging CG variant for polytopes without any restricting assumptions on the location of the optimum. The exponent in their convergence rate depends on various geometric parameters of the polytope [6]. It is important to note, that while, in theory, these geometric parameters can result in an arbitrarily bad convergence rate, for polytopes for which it makes sense to apply the CG method, i.e., there exists an highly efficient algorithm to solve the linear subproblems, such as polytopes that arise in combinatorial optimization problems, these parameters are quite reasonable and can be efficiently computed. In a follow-up work, Lacoste-Julien and Jaggi [15, 16] gave a refined affine-invariant analysis of an algorithm presented in [8] which also uses away steps, and showed that it also converges exponentially fast in the same setting as the Garber-Hazan\nresult. In a later work, Beck and Shtern [2] gave a different, duality-based, analysis for the algorithm of [8], and showed that it can be applied to a wider class of functions than purely strongly convex functions. However, the explicit dependency of their convergence rate on the dimension is suboptimal, compared to [6, 16]. Aside from the polytope case, Garber and Hazan have shown recently that in case the feasible set is strongly-convex and the objective function satisfies certain strong convexity-like proprieties, then the standard CG method converges with an accelerated rate of O(1/t2) [7].\nDespite the exponential improvement in convergence rate in the polytope case obtained in recent results, all of these results suffer from two major drawbacks. First, while in terms of the number of calls per-iteration to the linear optimization oracle, these methods match the standard CG method, i.e., a single call per iteration, the overhead of other operations both in terms of running times and memory requirements is significantly worse. The reason is that in order to apply the so-called away-steps, which all methods use in order to obtain the accelerated rate, they require to maintain at all times an explicit decomposition of the current iterate into vertices of the polytope. Maintaining such a decomposition and computing the away-steps, even with efficient implementations of incremental decomposition procedures, such as suggested in [2], require both memory and per-iteration runtime overheads that are at least quadratic in the dimension. This is much worse than the standard CG method, whose memory and runtime overheads are only linear in the dimension. Second, the convergence rate of all previous linearly convergent CG methods depends explicitly on the dimension. While it is known that this dependency is unavoidable in certain cases, e.g., when the optimal solution is, informally speaking, dense (see for instance the lower bound in [6]), it is not clear that such an unfavorable dependence is mandatory when the optimum is sparse.\nIn this paper, we revisit the application of CG variants to smooth and strongly-convex optimization over polytopes. We introduce a new variant which overcomes both of the above shortcomings from which all previous linearly-converging variants suffer. The main novelty of our method, which is the key to its improved performance, is that unlike previous variants, it is decomposition-invariant, i.e., it does not require to maintain an explicit convex decomposition of the current iterate. This principle proves to be crucial both for eliminating the memory and runtime overheads, as well as to obtaining shaper convergence rates for instances that admit a sparse optimal solution.\nWe give a detailed comparison of our method to previous art in Table 1. We also provide empirical evidence that the proposed method delivers state-of-the-art performance on several tasks of interest. While our method is less general than previous ones, i.e., our theoretical guarantees do not hold for arbitrary polytopes, they readily apply for many structured polytopes that capture important concepts such as paths in graphs, perfect matchings in bipartite graphs, Markov random fields, and more. We also specify how to apply the method to arbitrary polytopes, but without giving formal convergence guarantees."
    }, {
      "heading" : "1.1 Organization of the paper",
      "text" : "The rest of this paper is organized as follows. In Section 2 we give preliminaries and notation, and present the exact setting considered in this paper. In Section 3 we briefly present the conditional gradient method and its previous away-steps-based variants, and present our new method: a decomposition-invariant pairwise conditional gradient algorithm. In this section we also give our main theorem which details the novel convergence rate of our method. In Section 4 we briefly describe several important polytopes that fall into our assumptions, and detail the application of our method for optimization over these polytopes. In Section 5 we give a complete analysis of our method and prove the main theorem. In Section 6 we detail how to apply our\napproach to a broader class of polytopes, though we do not complement our algorithm with a convergence rate result in this case. We also show that our requirement that the objective function is strongly convex can be relaxed, and that our results in fact hold for a broader class of functions. In Section 7 we introduce a lower-bound for conditional gradient-based methods, that shows that for certain problems with a sparse optimal solution, our method is nearly optimal. Finally, in Section 8 we present empirical evidence which demonstrates the performance of our method."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "Definition 1. We say that a function f(x) : Rn → R is α-strongly convex w.r.t. a norm ‖ · ‖, if for all x, y ∈ Rn it holds that\nf(y) ≥ f(x) +∇f(x) · (y − x) + α 2 ‖x− y‖2.\nDefinition 2. We say that a function f(x) : Rn → R is β-smooth w.r.t. a norm ‖ · ‖, if for all x, y ∈ Rn it holds that\nf(y) ≤ f(x) +∇f(x) · (y − x) + β 2 ‖x− y‖2.\nThe first-order optimality condition implies that for a α-strongly convex f , if x∗ is the unique minimizer of f over a convex and compact set K ⊂ Rn, then for all x ∈ K it holds that\nf(x)− f(x∗) ≥ α 2 ‖x− x∗‖2. (1)\nThroughout this work we let ‖·‖ denote the standard euclidean norm. Given a point x ∈ Rn, we let card(x) denote the number of non-zero entries in x."
    }, {
      "heading" : "2.1 Setting",
      "text" : "In this work we consider the following optimization problem:\nmin x∈P f(x).\nWe make the following assumptions on f and P:\n• f(x) is α-strongly convex and β-smooth with respect to the `2 norm.\n• P is a polytope which satisfies the following two properties:\n1. P can be described algebraically as P = {x ∈ Rn |x ≥ 0, Ax = b} . 2. All vertices of P lie on the hypercube {0, 1}n.\nWe let x∗ denote the (unique) minimizer of f over P, and we let D denote the Euclidean diameter of P, namely, D = maxx,y∈P ‖x− y‖. We let V denote the set of vertices of P, where according to our assumptions, it holds that V ⊂ {0, 1}n.\nWhile the polytopes that satisfy the above assumptions are not completely general, these assumptions already capture several important concepts such as paths in graphs, perfectmatchings, Markov random fields, and more. Indeed, a surprisingly large number of applications from machine learning, signal processing and other domains formulate optimization problems in this category (e.g., [12, 14, 16]). We give detailed examples of such polytopes in Section 4. Importantly, the above assumptions allow us to get rid of the dependency of the convergence rate on certain geometric parameters (such as ψ, ξ in [6] or the pyramidal width in [15, 16]), which can be polynomial in the dimension, and hence result in an impractical convergence rate. Finally, for many of these polytopes, the vertices are sparse, i.e., for any vertex v ∈ V, card(v) << n. In this case, when the optimum x∗ can be decomposed as a convex combination of only a few vertices (and thus, sparse by itself), we get a sharper convergence rate that depends on the sparsity of x∗ and not explicitly on the dimension, as in previous works.\nWe believe that our theoretical guarantees could be well extended to more general polytopes and we leave this extension for future work."
    }, {
      "heading" : "3 Our Approach",
      "text" : "In order to better communicate our ideas, we begin by first briefly introducing the standard conditional gradient method and its accelerated away-steps-based variants. We discuss both the blessings and shortcomings of these away-steps-based variants in Subsection 3.1. Then, in Subsection 3.2, we present our new method, a decomposition-invariant away-steps-based conditional gradient algorithm, and discuss how it addresses the major shortcomings of previous away-steps-based variants."
    }, {
      "heading" : "3.1 The conditional gradient method and acceleration via away-steps",
      "text" : "The standard conditional gradient algorithm is given below (Algorithm 1). It is well known that when setting the step-size ηt in an appropriate way, the worst case convergence rate of the method is O(βD2/t) [12]. This convergence rate is tight for the method in general, see for instance [18].\nConsider the iterate of Algorithm 1 on iteration t, and let xt = ∑k\ni=1 λivi be its convex decomposition into vertices of the polytope P. Note that Algorithm 1, implicitly discounts each coefficient λi by a factor (1 − ηt), in favor of the new added vertex vt. A different approach,\nAlgorithm 1 Conditional Gradient\n1: Let x1 be some vertex in V 2: for t = 1... do 3: vt ← arg minv∈V v · ∇f(xt) 4: choose a step-size ηt ∈ (0, 1] 5: xt+1 ← (1− ηt)xt + ηtvt 6: end for\nis not to decrease all vertices in the decomposition of xt uniformly, but to more-aggressively decrease vertices that are worse than others, with respect to some computable measure, such as their product with the gradient direction. This key principle proves to be crucial to breaking the 1/t rate of the standard method, and to achieve a linear convergence rate under certain strong-convexity assumptions, as described in the recent works [6, 16, 2]. For instance, in [6] it was shown, via the introduction of the concept of a Local Linear Optimization Oracle, that using such a non-uniform reweighing rule, in fact approximates a certain proximal problem, that together with the shrinking effect of strong convexity, as captured by Eq. (1), yields a linear convergence rate. We refer to these methods as away-step-based CG methods. As a concrete example, which will also serve as a basis for our new method, we bring the pairwise variant recently studied in [16], which applies this principle in Algorithm 2, given below 1. Note that Algorithm 2 decreases the weight of exactly one vertex in the decomposition: that with the largest product with the gradient.\nIt is important to note that since previous away-step-based CG, unlike the original CG method, do not decrease the coefficients in the convex decomposition of the current iterate uniformly, they all require to explicitly store and maintain a convex decomposition of the current iterate. This issue raises two main disadvantages:\nSuperlinear memory and running-time overheads Storing a decomposition of the current iterate as a convex combination of vertices of the polytope generally requires O(n2) memory. While the away-step-based variants increase the size of the decomposition by at most a single vertex per iteration, they also typically exhibit linear convergence after performing at least O(n) steps [6, 16, 2], and thus, this O(n2) estimate still holds. Moreover, since these methods require i) to find the worse vertex in the decomposition, in terms of dot-product with current gradient direction, and ii) to update this decomposition on each iteration (even when using sophisticated update techniques such as in [2]), the per-iteration over-head in terms of computation time of these methods is also at least O(n2).\nDecomposition-specific performance While the choice of new vertex to be added in Algorithms 1 is independent of a specific representation of the current iterate xt as a convex combination of vertices of the polytope, the choice of away-step in Algorithm 2 does depend on the specific decomposition that is maintained by the algorithm. Since the feasible point xt may admit several different convex decompositions, committing to one such decomposition, might result in sub-optimal away-steps. Ideally, the away-steps, much like the standard CG methods, will be independent of any specific decomposition. As observable in Table 1, for certain problems in which the optimal solution is sparse, all analyses of previous away-steps-based variants are significantly suboptimal, since they all depend explicitly on the dimension, which seems to\n1While the convergence rate of this pairwise variant, established in [16], despite being linear, is significantly worse than other away-step-based variants, here we show on the contrary, that a proper analysis yields state-ofthe-art performance guarantees.\nbe an unavoidable side-effect of being decomposition-dependent. On the other hand, the fact that our new approach is decomposition-invariant allows us to obtain sharper convergence rates for such instances.\nAlgorithm 2 Pairwise Conditional Gradient\n1: Let x1 be some vertex in V 2: for t = 1... do 3: let ∑kt i=1 a (i) t v (i) t be an explicitly maintained convex decomposition of xt 4: v+t ← arg minv∈V v · ∇f(xt) 5: jt ← arg minj∈[kt] v (j) t · (−∇f(xt)) 6: choose a step-size ηt ∈ (0, a(jt)t ] 7: xt+1 ← xt + ηt(v+t − v (jt) t ) 8: update the convex decomposition of xt+1 9: end for"
    }, {
      "heading" : "3.2 A new decomposition-invariant pairwise conditional gradient method",
      "text" : "Our main observation is that in many cases of interest, given a feasible iterate xt, one can in-fact compute an optimal away-step from xt without relying on any single specific decomposition. This observation allows us to overcome both of the main disadvantages of previous away-stepbased CG variants. Our algorithm, which we refer to as a decomposition-invariant pairwise conditional gradient (DICG), is given below in Algorithm 3.\nAlgorithm 3 Decomposition-invariant Pairwise Conditional Gradient\n1: input: sequence of step-sizes {ηt}t≥1 2: let x0 be an arbitrary point in P 3: x1 ← arg minv∈V v · ∇f(x0) 4: for t = 1... do 5: v+t ← arg minv∈V v · ∇f(xt) 6: define the vector ∇̃f(xt) ∈ Rm as follows:\n∇̃f(xt)i := { ∇f(xt)i if xt > 0 −∞ if xt = 0\n7: v−t ← arg minv∈V v · ( −∇̃f(xt) ) 8: choose a new step-size η̃t using one of the following two options:\nOption 1: predefined step-size let δt be the smallest natural such that 2 −δt ≤ ηt, and set a new step-size η̃t ← 2−δt\nOption 2: line-search γt ← maxγ∈[0,1]{xt + γ(v+t − v − t ) ≥ 0}, η̃t ← minη∈(0,γt] f(xt + η(v + t − v − t ))\n9: xt+1 ← xt + η̃t(v+t − v − t )\n10: end for\nThe following observation details the optimality of away-steps taken by Algorithm 3.\nObservation 1 (optimal away-steps in Algorithm 3). Consider an iteration t of Algorithm 3 and suppose that the iterate xt is feasible. Let xt = ∑k i=1 λivi for some integer k, be an\nirreducible way of writing xt as a convex sum of vertices of P, i.e., λi > 0 for all i ∈ [k]. Then it holds that\n∀i ∈ [k] : vi · ∇f(xt) ≤ v−t · ∇f(xt), γt ≥ min{xt(i) | i ∈ [n], xt(i) > 0}. Proof. Let xt = ∑k\ni=1 λivi be a convex decomposition of xt into vertices of P, for some integer k, where each λi is positive. Note that it must hold that for any j ∈ [n] and any i ∈ [k], xt(j) = 0 ⇒ vi(j) = 0, since by our assumption on P, V ⊂ Rn+. The observation then follows directly from the definition of v−t .\nThe following theorem which details the convergence rate of Algorithm 3 is the main theorem of this paper.\nTheorem 1. Let M1 = √ α 8card(x∗) and M2 = βD2 2 . Consider running Algorithm 3 with Option"
    }, {
      "heading" : "1 for the step-size, and suppose that",
      "text" : "∀t ≥ 1 : ηt = M1\n2 √ M2\n( 1− M 2 1\n4M2\n) t−1 2\n.\nThen the iterates of Algorithm 3 are always feasible and satisfy:\n∀t ≥ 1 : f(xt)− f(x∗) ≤ βD2\n2 exp\n( − α\n8βD2card(x∗) t\n) .\nThe following corollary of Theorem 1 shows that the so-called duality gap, defined as gt := (xt− v+t ) ·∇f(xt), which serve as a certificate of the sub-optimality of the iterates of Algorithm 3, also converges with a linear rate.\nCorollary 1. For any iteration t of Algorithm 3, define the dual gap gt := (xt − v+t ) · ∇f(xt), and observe that, since f(x) is convex, ht ≤ gt. Then, for any t which satisfies: ht ≤ βD 2\n2 , it holds that\ngt ≤ √ 2βD2ht.\nWe now turn to make several remarks regarding Algorithm 3 and Theorem 1:\n• Note that on any iteration t of the algorithm, aside from the computation of the gradient vector ∇f(xt) and the two calls to the linear optimization oracle of P, all other computations, when using the first option for choosing the step-size, can be carried out in O(n) time and space. This is much more efficient than previous linearly convergent CG variant, such as those in [6, 16, 2], which typically require at least additional O(n2) time and space per iteration, since they require to maintain an explicit convex decomposition of the iterates.\n• Note that despite the different parameters of the problem at hand (e.g., α, β,D, card(x∗)), running the algorithm with Option 1 for choosing the step-size, for which the guarantee of Theorem 1 holds, requires the knowledge of a single parameter, i.e., M1/ √ M2. In\nparticular, it is an easy consequence that running the algorithm with an estimate M ∈ [0.5M1/ √ M2, M1/ √ M2], will only affect the leading constant in the convergence rate listed in the theorem. Hence, M1/ √ M2 could be efficiently estimated via a logarithmicscale search.\n• Theorem 1 improves significantly over the convergence rate established for the pairwise conditional gradient variant in [16]. In particular, the number of iterations to reach an error in the analysis of [16] depends linearly on |V|!, where |V| is the number of vertices of P."
    }, {
      "heading" : "4 Examples of Polytopes",
      "text" : "In this section we turn to survey several important examples of structured polytopes that fit the assumptions detailed in Subsection 2.1 and detail the application of Algorithm 3 to optimization over these polytopes.\nUnit Simplex The simplex in Rn is the set of all distributions over n elements, i.e. the set:\nSn = {x ∈ Rn |x ≥ 0 , n∑ i=1 xi = 1}.\nAlternatively, Sn is the convex hull of all standard basis vectors in Rn. It is easy to verify that D = √ 2.\nLinear minimization over the simplex is trivial and can be carried out by a single pass over the non-zero elements in the linear objective. In particular, computing v−t in Algorithm 3 simply amounts to finding the largest (signed) entry in ∇f(xt) which corresponds to a non-zero entry in xt, and thus is even more efficient than computing the standard CG direction v + t .\nFlow polytope Let G be a directed acyclic graph (DAG) with a set of vertices V such that |V | = n, and a set of edges E such that |E| = m, and let s, t be two vertices in V which we refer to as the source and the target, respectively. The s− t flow polytope, denoted here by Fst, is the set of all unit s− t flows in G, where for each point x ∈ Fst and i ∈ [m], the entry xi is the amount of flow through edge i according to the flow x. Fst is also known as the s− t path polytope since it is the convex hull of all identifying vectors of paths from s to t in the graph G. It is easy to verify that that D < √ 2n.\nSince Fst is the convex hull of paths, linear minimization is straightforward: given a linear objective c ∈ Rm, we need to find the identifying vector of the lightest s − t path in G with respect to the edge weights induced by c. Since the graph G is a DAG, this could be carried out in O(m) time [22]. In particular, computing the direction v−t in Algorithm 3 over the flow polytope, amounts to finding the lightest s − t path in G with respect to the gradient vector ∇f(xt), under the constraint that all edges on the path are assigned non-zero flow by xt. Thus, we can compute v−t by running a shortest s − t path algorithm after removing all edges with zero flow from the graph. Thus, as in the simplex case, computing v−t is even more efficient than computing the standard direction v+t .\nIt is also important to note that when G is not extremely sparse, i.e., when m = ω(n), it holds for every vertex v of Fst that card(v) << m. Thus, if x∗ can be expressed as a combination of only a few paths, i.e., it corresponds to a sparse flow, it holds that card(x∗) is much smaller than the standard dimension of the problem m.\nPerfect Matchings polytope Let G be a bipartite graph with n vertices on each side and m crossing edges. The perfect matching polytope, denoted here by M, is the convex hull of all identifying vectors of perfect matchings in G. In case the two sides of G are fully connected, this polytope is also known as the Birkhoff polytope - the set of all n×n doubly stochastic matrices, i.e. matrices with non-negative real entries whose entries along any row and any column add up to 1. It easily follows that D ≤ √ 2n.\nIn order to minimize a linear objective over M, we need to find a minimum-weight perfect matching in a bipartite graph, where the edge weights are induced by the linear objective. This could be carried out via combinatorial algorithms in min{Õ( √ nm), O(n3)} time [22]. As in the flow polyope, in this case also, computing v−t is even more efficient than computing v + t , since it\namounts to finding a minimum weight perfect matching after all edges that are zero-valued in xt are removed from the graph.\nAs in the flow polytope, in case G is not trivially sparse, i.e., when m = ω(n), it holds that if x∗ could be expressed as a combination of only a few matchings in G, then card(x∗) << m, where m is the dimension of the problem.\nMarginal polytope In Graphical Models several optimization problems are defined for variables representing marginal distributions over subsets of model variables. There exists a set of linear constraints, known as the marginal polytope, which guarantees that these variables are legal marginals of some global distribution [25]. For example, the learning problem in Max-Margin Markov Networks is defined as a quadratic program over the marginal polytope [24].\nFor general graphical models the marginal polytope consists of an exponential number of constraints. Fortunately, for some models, such as tree-structured graphs, the polytope can be characterized by a polynomial number of local consistency constraints, known as the local marginal polytope [25]. Consider a set of discrete variables (y1, . . . , yn), and denote by µc(yc) the marginal probability of an assignment to a subset of these variables yc. Then the local marginal polytope is defined as:\nML = { µ ≥ 0 : ∑ yc\\i\nµc(yc) = µi(yi) ∀c, i ∈ c, yi∑ yi µi(yi) = 1 ∀i\n}\nFor tree-structured graphsML is known to have only integral vertices [25], so it has the desired form assumed in Section 2.1.\nIn this case D = √\n2|C|, where C is the number of subsets yc (factors in the graphical model). In many interesting cases linear optimization over the marginal polytope can be implemented efficiently via dynamic programming. For example, for chain-structured graphs the Viterbi algorithm is used. Finally, we note that computing the direction v−t in Algorithm 3 can often be cheaper than computing v+t , since the restriction to the support of xt can eliminate many of the possible configurations of marginals."
    }, {
      "heading" : "5 Analysis",
      "text" : "In this section we turn to analyze the performance of Algorithm 3, and prove Theorem 1. Throughout this section we let ht denote the approximation error of Algorithm 3 on iteration t, for any t ≥ 1, i.e., ht = f(xt)− f(x∗)."
    }, {
      "heading" : "5.1 Feasibility of the iterates generated by Algorithm 3",
      "text" : "We start by proving that the iterates of Algorithm 3 are always feasible. While feasibility is straightforward when using the the line-search option to set the step-size (Option 2), it is less obvious when using the first option.\nObservation 2. Suppose that on some iteration t of Algorithm 3, the iterate xt is feasible, and that the step-size is chosen using Option 1. Then, if for all i ∈ [n] for which xt(i) 6= 0 it holds that xt(i) ≥ η̃t, then the following iterate xt+1 is also feasible.\nProof. From the optimality of v−t it follows that for any i ∈ [n], if xt(i) = 0, then v − t (i) = 0 (note in particular that any vertex with positive weight in some convex decomposition of xt must satisfy this condition). Thus, from our assumption on the size of positive entries in xt,\nand since v−t ∈ {0, 1}n, it follows that the vector wt := xt − η̃tv − t , satisfies: wt ≥ 0. Since v + t is feasible it also follows that xt+1 = wt + η̃t ≥ 0. Finally, since xt, v−t , v + t are all feasible, it also holds that Axt+1 = b. Thus, xt+1 is feasible.\nLemma 1 (feasibility of iterates under Option 1). Suppose that the sequence of step-sizes {ηt}t≥1 is monotonically non-increasing, and contained in the interval [0, 1]. Then, the iterates generated by Algorithm 3 using Option 1 for setting the step-size, are always feasible.\nProof. We are going to prove by induction that on each iteration t there exists a non-negative integer-valued vector st ∈ Nn, such that for any i ∈ [n], it holds that xt(i) = 2−δtst(i). The lemma then follows by applying Observation 2, and since by definition, η̃t = 2\n−δt . The base case t = 1 holds since x1 is a vertex of P and thus for any i ∈ [n] we have that x1(i) ∈ {0, 1} (recall that V ⊂ {0, 1}n). On the other hand, since η1 ≤ 1, it follows that δ1 ≥ 0. Thus, there indeed exists a non-negative integer-valued vector s1, such that x1 = 2\n−δ1s1. Suppose now that the induction holds for some t ≥ 1. Since by definition of v−t , subtracting η̃tv − t from xt can only decrease positive entries in xt (see proof of Observation 2), and both v−t , v + t are vertices of P (and thus in {0, 1}n), and η̃t = 2−δt , it follows that each entry i in xt+1 is given by:\nxt+1(i) = 2 −δt  st(i) if st(i) ≥ 1 & v−t (i) = v+t (i) = 1 or v−t (i) = v+t (i) = 0 st(i)− 1 if st(i) ≥ 1 & v−t (i) = 1 & v+t (i) = 0 st(i) + 1 if v − t (i) = 0 & v + t (i) = 1\nThus, xt+1 can also be written in the form 2 −δt s̃t+1 for some s̃t+1 ∈ Nn. By definition of\nδt and the monotonicity of {ηt}t≥1, we have that 2 −δt\n2−δt+1 is a positive integer. Thus, setting\nst+1 = 2−δt\n2−δt+1 s̃t+1, the induction holds also for t+ 1."
    }, {
      "heading" : "5.2 Bounding the per-iteration error-reduction of Algorithm 3",
      "text" : "The following technical lemma is the key to deriving the linear convergence rate of our method, and in particular, to deriving the improved dependence on the sparsity of x∗, instead of the dimension. At a high-level, the lemma translates the `2 distance between two feasible points into a `1 distance in a simplex defined over the set of vertices of the polytope, which as we will show, is a natural way to measure distances for conditional gradient-based methods.\nLemma 2. Let x, y ∈ P. There exists a way to write x as a convex combination of vertices of P, x = ∑k i=1 λivi for some integer k, such that y can be written as y = ∑k i=1(λi−∆i)vi+( ∑k i=1 ∆i)z\nwith ∆i ∈ [0, λi] ∀i ∈ [k],z ∈ P, and ∑k i=1 ∆i ≤ √ card(y)‖x− y‖.\nProof. Consider writing y as some convex combination of vertices, y = ∑s\ni=1 γiui for some appropriate integer s. Applying Lemma 5.3. from [6], it follows that we can write x as\nx = s∑ i=1 (γi − ∆̃i)ui + ( s∑ i=1 ∆̃i)z̃, (2)\nwhere ∆̃i ∈ [0, γi]∀i ∈ [s], z̃ ∈ P, and for every i with ∆̃i > 0 there exists ji ∈ [n] such that z̃(ji) = 0 and ui(ji) > 0. Since each ui is a vertex of P and thus a point of the {0, 1}-hypercube, it further follows that ui(ji) = 1. Let C = {ji | i ∈ [s]}. Observe that |C| ≤ card(y). Now, we\nhave that\n‖x− y‖2 = ‖ s∑ i=1 ∆̃i(ui − z̃)‖2 ≥ ∑ j∈C ( s∑ i=1 ∆̃i(ui(j)− z̃(j)) )2 = ∑ j∈C ( s∑ i=1 ∆̃iui(j) )2\n≥ 1 |C| ∑ j∈C s∑ i=1 ∆̃iui(j) 2 ≥ 1 |C| ( s∑ i=1 ∆̃i )2 .\nRearranging we have that\ns∑ i=1 ∆̃i ≤ √ |C|‖x− y‖ ≤ √ card(y)‖x− y‖. (3)\nNote that using the convex decomposition of x as in Eq. (2), and the bound in Eq. (3) it follows that we can rewrite y as a convex decomposition as suggested in the lemma.\nLemma 3. Consider the iterates of Algorithm 3, when the step-sizes are chosen using Option 1. Let M1 = √ α 8card(x∗) and M2 = βD2 2 . For any t ≥ 1 it holds that\nht+1 ≤ ht − ηtM1h1/2t + η2tM2.\nProof. Define ∆t =\n√ 2card(x∗)ht α , and note that from Eq. (1) we have that ∆t ≥ √\ncard(x∗)‖xt − x∗‖. As a first step, we are going to show that the point yt := xt + ∆t(v + t − v − t ) satisfies:\nyt · ∇f(xt) ≤ x∗ · ∇f(xt). From Lemma 2 it follows that we can write x as a convex combination xt = ∑k i=1 λivi and\nwrite x∗ as x∗ = ∑k i=1(λi −∆i)vi + ∑k i=1 ∆iz, where ∆i ∈ [0, λi], z ∈ P, and ∑k\ni=1 ∆i ≤ ∆t. It holds that\n(yt − xt) · ∇f(xt) = ∆t(v+t − v − t ) · ∇f(xt) ≤ k∑ i=1 ∆i(v + t − v − t ) · ∇f(xt)\n≤ k∑ i=1 ∆i(z − vi) · ∇f(xt) = (x∗ − xt) · ∇f(xt),\nwhere the first inequality follows since (v+t −v − t ) ·∇f(xt) ≤ 0, and the second inequality follows from the optimality of v+t and v − t (Observation 1). Rearranging, we have that indeed\n( xt + ∆t(v + t − v − t ) ) · ∇f(xt) ≤ x∗ · ∇f(xt), (4)\nas needed. Observe now that from the definition of η̃t it follows for any t ≥ 1 that ηt2 ≤ η̃t ≤ ηt. Using\nthe smoothness of f(x) we have that\nht+1 = f(xt + η̃t(v + t − v − t ))− f(x∗)\n≤ ht + η̃t(v+t − v − t ) · ∇f(xt) +\nη̃2t β\n2 ‖v+t − v − t ‖2\n≤ ht + η̃t(v+t − v − t ) · ∇f(xt) +\nη̃2t βD 2\n2\n≤ ht + ηt 2 (v+t − v − t ) · ∇f(xt) +\nη2t βD 2\n2\n= ht + ηt\n2∆t\n( (xt + ∆t(v + t − v − t )− xt ) · ∇f(xt) + η̃2t βD 2\n2\n≤ ht + ηt 2∆t (x∗ − xt) · ∇f(xt) +\nη2t βD 2\n2\n≤ ht − ηt\n2∆t ht +\nη2t βD 2\n2\n= ht − ηt √ α 2 √ 2card(x∗)ht ht + η2t βD 2 2 ,\nwhere the third inequality follows since (v+t −v − t ) ·∇f(xt) ≤ 0, the forth inequality follows from Eq. (4), the fifth inequality follows from convexity of f(x), and the last equality follows from plugging the value of ∆t."
    }, {
      "heading" : "5.3 Proof of Theorem 1",
      "text" : "We now turn to prove Theorem 1. Afterwards, we prove Corollary 1.\nProof. We are first going to prove the convergence rate stated in the theorem, assuming that all iterates are feasible. Then we will show that for our choice of step-sizes, indeed the iterates are feasible. We are going to prove by induction that there exist c0, c1 such that for all t ≥ 1 it holds that ht ≤ c0(1− c1)t−1. Clearly for the base case we must require that c0 ≥ h1.\nSuppose now that the induction holds for some t ≥ 1. Let us set\nηt = M1 2M2 √ c0(1− c1) t−1 2 . (5)\nUsing Lemma 3 and the induction hypothesis we have that\nht+1 ≤ ht − M21 2M2\n√ c0(1− c1)t−1h1/2t +\nM21 4M2 c0(1− c1)t−1\n≤ ht − M21 2M2 ht + M21 4M2 c0(1− c1)t−1\n= ht\n( 1− M 2 1\n2M2\n) +\nM21 4M2 c0(1− c1)t−1\n≤ c0(1− c1)t−1 ( 1− M 2 1\n4M2\n) ,\nwhere the induction hypothesis was used in both the second and third inequalities. In the third inequality we have also used the fact that\nM21 2M2 = α 8βcard(x∗)D2 < 1, (6)\nwhere the inequality follows since α ≤ β and both card(x∗), D are at least 1. Thus, if we set c1 = M21 4M2\n, the induction follows. We now turn to figure out c0. Using the smoothness of f(x) and the choice of x1 in Algorithm 3, we have that\nh1 = f(x1)− f(x∗) = f(x0 + (x1 − x0))− f(x∗)\n≤ f(x0)− f(x∗) + (x1 − x0) · ∇f(x0) + β‖x0 − x1‖2\n2\n≤ f(x0)− f(x∗) + (x∗ − x0) · ∇f(x0) + β‖x0 − x1‖2 2 ≤ βD 2 2 ,\nwhere the last inequality follows from the convexity of f(x).\nThus, we can set c0 = βD2\n2 = M2, which completes the proof of the convergence rate. Now, it remains to prove that indeed all iterates are feasible. First note that the sequence {ηt}t≥1, as defined in Eq. (5) is monotonically non-increasing. Furthermore, plugging the values M1,M2, c0, we have that\nη1 = M1 √ c0\n2M2 =\n1\n2 √ M21 M2 = 1 2 √ α 4βD2card(x∗) ≤ 1,\nwhere the inequality follows similarly to the one in Eq. (6). Thus, our choice of step-size sequence {ηt}t≥1 satisfies the conditions of Lemma 1, and thus it follows that all iterates of Algorithm 3 are feasible.\nWe now prove Corollary 1.\nProof. Fix an iteration t. Using the β-smoothness of f(x) we have that\n∀η ∈ (0, 1] : f(x∗) ≤ f(xt + η(v+t − xt)) ≤ f(xt) + η(v + t − xt) · ∇f(xt) +\nη2βD2\n2 .\nRearranging we have that\n∀η ∈ (0, 1] : gt = (xt − v+t ) · ∇f(xt) ≤ 1\nη ht +\nηβD2\n2 .\nThus, when √\n2ht βD2 ≤ 1, we can set η = √ 2ht βD2 in the above inequality, and obtain the corollary."
    }, {
      "heading" : "6 Extensions",
      "text" : "In this section we detail two extensions of our result: i) relaxing the specific structure of the polytope P considered in Subsection 2.1, and ii) relaxing the strong convexity requirement on the objective function f(x)."
    }, {
      "heading" : "6.1 Extension of Algorithm 3 to arbitrary polytopes",
      "text" : "In this subsection we detail how to extend our approach to a broader class of polytopes. While proving rigorous guarantees for this extension is beyond the scope of this paper and left for future work, the encouraging experimental results for Algorithm 3 with line-search, suggest that this extended variant, for which line-search is also possible, may also exhibit favorable\nempirical performance. Towards this end, in this subsection we consider minimizing a smooth and strongly-convex function over an arbitrary polytope P which we assume is given in the following way:\nP = {x ∈ Rn |A1x = b1, A2x ≤ b2},\nwhere A2 is m× n. We assume that given a point x ∈ Rn, we have an efficient way to evaluate the vector A2x, which is indeed the case for most structured polytopes of interest.\nAlgorithm 4 Decomposition-invariant Pairwise Conditional Gradient with Line-search for Arbitrary Polytopes\n1: let x0 be an arbitrary point in P 2: x1 ← arg minv∈V v · ∇f(x0) 3: for t = 1... do 4: v+t ← arg minv∈V v · ∇f(xt) 5: define the vector c ∈ Rm as follows:\nci := { 0 if A2(i) · xt < b2(i) ∞ if A2(i) · xt = b2(i)\n6: v−t ← arg minv∈V (−∇f(xt)) · v + c>A2v 7: γt ← max{γ ∈ [0, 1] |A2(xt + γ(v+t − v − t )) ≤ b2} 8: ηt ← arg minη∈[0,γt] f(xt + η(v + t − v − t )) 9: xt+1 ← xt + ηt(v+t − v − t )\n10: end for\nObservation 3 (optimal away-step for an arbitrary polytope). Consider an iteration t of Algorithm 4 and suppose that the iterate xt is feasible. Let xt = ∑k i=1 λivi for some integer k, be a irreducible way of writing xt as a convex sum of vertices of P, i.e., λi > 0 for all i ∈ [k]. Then it holds that\n∀i ∈ [k] : vi · ∇f(xt) ≤ v−t · ∇f(xt), γt > 0.\nMoreover, there exists a convex decomposition of xt that assigns a weight at least γt to v − t .\nProof. Let xt = ∑k\ni=1 λivi be a decomposition of xt into vertices of P such that λi > 0 for all i ∈ [k]. Observe that for any j ∈ [m] and i ∈ [k] it holds that A2(j) · xt = b2(j)⇒ A2(j) · vi = b2(j). Note that by definition of the vector c and v − t it holds that\nv−t ∈ arg max v∈V ∇f(xt) · v − c>A2v ≡ arg max v∈V ∇f(xt) · v + c>(b2 −A2v)\n≡ arg maxv∈{y∈V | ∀j∈[m]:A2(j)·xt=b2(j)⇒A2(j)·y=b2(j)}v · ∇f(xt). (7)\nThus, it follows that for all i ∈ [k], v−t · ∇f(xt) ≥ vi · ∇f(xt). In order to prove the second part of the observation, we note that from the RHS of Eq. (7) it follows that there exists γt > 0 such that indeed xt−γtv−t ≤ (1−γt)b2. To see this, consider some j ∈ [m]. If A2(j) · xt = b2(j), then from the RHS of Eq. (7), it follows that A2(j) · v−t = b2(j) and thus, for any γt it holds that A2(j) ·(xt−γtv−t ) = (1−γt)b2(j). Otherwise, there exists some j > 0 such that A2(j) ·v−t ≤ b2(j)− j . Thus, for small enough, yet positive γt we will have that A2(j) · (xt − γtv−t ) ≤ (1− γt)b2(j). Since it clearly also holds that A1(xt − γtv − t ) = (1− γt)b1, we have that the vector wt := xt−γtv−t satisfies: wt ∈ (1−γt)P. Hence, wt can be decomposed\nas wt = ∑q\ni=1 γ̃iṽi, where q is a positive integer and for all i ∈ [q], λ̃i > 0, ṽi is a vertex of P, and ∑q i=1 λ̃i = 1 − γt. Thus, since v − t is a vertex of P, it follows that xt = wt + γtv − t admits\nthe convex decomposition ∑q\ni=1 λ̃iṽi + γtv − t , as needed.\nThe following lemma is an immediate consequence of the choice of γt in Algorithm 4.\nLemma 4. The iterates of Algorithm 4 are always feasible."
    }, {
      "heading" : "6.2 Relaxing the strong convexity of the objective function",
      "text" : "Until now we have assumed that the objective function f is strongly convex. However, as can be observed from our analysis, the only consequence of strong convexity that we relied on in our analysis, is Eq. (1). Indeed, there exist functions which are not strongly convex, that under certain conditions, still satisfy Eq. (1), and thus are compatible with our method and analysis.\nFollowing the work of Beck and Shtern [2], we can consider a broader class of objective functions, namely functions that take the following form:\nf(x) = g(Ax) + b · x, (8)\nwhere A ∈ Rm×n, and g : Rm → R is smooth and strongly convex. In [2] (Lemma 2.5) it was shown, using an application of Hoffman’s lemma, that there exists a constant κ which depends both on the condition number of g and the parameters A, b, such that for any feasible point x, it holds that\nmin y∈P∗\n‖x− y‖2 ≤ κ (f(x)− f∗) , (9)\nwhere P∗ ⊂ P, is the set of all feasible points that minimize f(x) over P, and f∗ is the minimum value of f(x) over P.\nIt is easy to verify that Eq. (9) can be readily used in our analysis instead of Eq. (1), and thus our results extend to handle objectives of the form given in Eq. (8).\nWe note that now, the dependency in our analysis and in Theorem 1 on the strong convexity parameter α will be replaced with κ, and the dependency on card(x∗) will be replaced with maxy∈P∗ card(y)."
    }, {
      "heading" : "7 Lower Bound for Problems with a Sparse Solution",
      "text" : "In this section we present a simple lower bound on the approximation error of, informally speaking, any natural conditional gradient variant that when initialized with a vertex of the feasible set, its iterate after t iterations admits a convex decomposition into at most t + 1 vertices of the polytope. That is, on each iteration, at most a single new vertex is added to the decomposition. The lower bound shows that there exists a 1-smooth and 1-strongly convex function f , for which, any such CG variant which is applied to the minimization of f over the unit simplex, must take Ω(card(x∗)) steps before entering the linear convergence regime. To date, none of the previous analyses of linearly converging CG variants matches this lower bound since, in this exact setting, they all require, in worst-case, Ω(n) steps before entering the linear convergence regime, i.e., number of steps that is independent of card(x∗).\nTo the best of our knowledge, Algorithm 3 and the corresponding Theorem 1 are the first to match this lower bound. We emphasize that the idea behind the construction of this lower bound is well known and follows almost immediately from previous constructions, such as those in [12, 6].\nLemma 5. Fix an even integer k ∈ [n], and consider the optimization problem\nmin x∈Sn {f(x) := 1 2 ‖x− 1 k 1k‖2},\nwhere Sn denotes the unit simplex in Rn, i.e., Sn := {x ∈ Rn |x ≥ 0, ‖x‖1 = 1}, and 1k is a vector in Rn, defined as:\n1k(i) = { 1 if 1 ≤ i ≤ k 0 else\nObserve that x∗ = 1k1k is the unique minimizer of f over Sn. Then, any point x ∈ Sn, for which it holds that card(x) ≤ k/2 satisfies:\nf(x)− f(x∗) ≥ 1 4k .\nProof. Fix a point x ∈ Sn for which it holds that card(x) ≤ k/2. In order to lower bound the approximation error of x, it suffices to consider the entries which are zero for x and non-zero for x∗. Thus, we have that\nf(x) ≥ 1 2 · k 2 · ( 0− 1 k )2 = 1 4k ."
    }, {
      "heading" : "8 Experiments",
      "text" : "In this section we illustrate the performance of our algorithm in numerical experiments. We use the two experimental settings from [16], which include a constrained Lasso problem and a video co-localization problem. In addition, we test our algorithm on a learning problem related to an optical character recognition (OCR) task from [24]. In each setting we compare the performance of our algorithm (DICG) to standard conditional gradient (CG), as well as to the fast away (ACG) and pairwise (PCG) variants [16]. For the baselines in the first two settings we use the publicly available code from [16], to which we add our own implementation of Algorithm 3. Similarly, for the OCR problem we extend code from [21], kindly provided by the authors. For all algorithms we use line-search to set the step size.\nLasso In the first example the goal is to solve the problem: minx∈M ‖Āx − b̄‖2, where M is a scaled `1 ball. Notice that the constraints M do not match the required structure of P, however, with a simple change of variables we can obtain an equivalent optimization problem over the simplex. We generate the random matrix Ā and vector b̄ as in [16]. In Figure 1 (left, top) we observe that our algorithm (DICG) converges similarly to the pairwise variant PCG and faster than the other baselines. This is expected since the away direction v− in DICG (Algorithm 3) is equivalent to the away direction in PCG (Algorithm 2) in the case of simplex constraints.\nVideo co-localization The second example is a quadratic program over the flow polytope, originally proposed in [14]. This is an instance of P that is mentioned in Section 4 in the appendix. As can be seen in Figure 1 (middle, top), in this setting our proposed algorithm significantly outperforms the baselines, as a result of finding a better away direction v−. Figure 1\n(middle, bottom) shows convergence on a time scale, where the difference between the algorithms is even larger. One reason for this difference is the costly search over the history of vertices maintained by the baseline algorithms. Specifically, the number of stored vertices grows fast with the number of iterations and reaches 1222 for away steps and 1438 for pairwise steps (out of 2000 iterations).\nOCR We next conduct experiments on a structured SVM learning problem resulting from an OCR task. The constraints in this setting are the marginal polytope corresponding to a chain graph over the letters of a word (see [24]), and the objective function is quadratic. Notice that the marginal polytope has a concise characterization in this case and also satisfies our assumptions (see Section 4 in the appendix for more details). For this problem we actually run Algorithm 3 in a block-coordinate fashion, where blocks correspond to training examples in the dual SVM formulation [17, 21]. In Figure 1 (right, top) we see that our DICG algorithm is comparable to the PCG algorithm and faster than the other baselines on the iteration scale. Figure 1 (right, bottom) demonstrates that in terms of actual running time we get a noticeable speedup compared to all baselines. We point out that for this OCR problem, both ACG and PCG each require about 5GB of memory to store the explicit decomposition in the implementation that we used, so using DICG instead results in significant memory savings."
    } ],
    "references" : [ {
      "title" : "Linear convergence of a modified frank-wolfe algorithm for computing minimum-volume enclosing ellipsoids",
      "author" : [ "S. Damla Ahipasaoglu", "Peng Sun", "Michael J. Todd" ],
      "venue" : "Optimization Methods and Software,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2008
    }, {
      "title" : "Linearly convergent away-step conditional gradient for non-strongly convex functions",
      "author" : [ "Amir Beck", "Shimrit Shtern" ],
      "venue" : "arXiv preprint arXiv:1504.05002,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2015
    }, {
      "title" : "A conditional gradient method with linear rate of convergence for solving convex linear systems",
      "author" : [ "Amir Beck", "Marc Teboulle" ],
      "venue" : "Math. Meth. of OR,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2004
    }, {
      "title" : "Lifted coordinate descent for learning with trace-norm regularization",
      "author" : [ "Miroslav Dud́ık", "Zäıd Harchaoui", "Jérôme Malick" ],
      "venue" : "Journal of Machine Learning Research - Proceedings Track,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "An algorithm for quadratic programming",
      "author" : [ "M. Frank", "P. Wolfe" ],
      "venue" : "Naval Research Logistics Quarterly,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1956
    }, {
      "title" : "A linearly convergent conditional gradient algorithm with applications to online and stochastic optimization",
      "author" : [ "Dan Garber", "Elad Hazan" ],
      "venue" : "CoRR, abs/1301.4666,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2013
    }, {
      "title" : "Faster rates for the frank-wolfe method over strongly-convex sets",
      "author" : [ "Dan Garber", "Elad Hazan" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning, ICML 2015,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2015
    }, {
      "title" : "Some comments on Wolfe’s ‘away step",
      "author" : [ "Jacques GuéLat", "Patrice Marcotte" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1986
    }, {
      "title" : "Large-scale image classification with trace-norm regularization",
      "author" : [ "Zäıd Harchaoui", "Matthijs Douze", "Mattis Paulin", "Miroslav Dud́ık", "Jérôme Malick" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2012
    }, {
      "title" : "Projection-free online learning",
      "author" : [ "Elad Hazan", "Satyen Kale" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2012
    }, {
      "title" : "Variance-reduced and projection-free stochastic optimization",
      "author" : [ "Elad Hazan", "Haipeng Luo" ],
      "venue" : "CoRR, abs/1602.02101,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2016
    }, {
      "title" : "Revisiting frank-wolfe: Projection-free sparse convex optimization",
      "author" : [ "Martin Jaggi" ],
      "venue" : "In Proceedings of the 30th International Conference on Machine Learning,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Sulovský. A simple algorithm for nuclear norm regularized problems",
      "author" : [ "Martin Jaggi", "Marek" ],
      "venue" : "In Proceedings of the 27th International Conference on Machine Learning,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2010
    }, {
      "title" : "Efficient image and video co-localization with Frank-Wolfe algorithm",
      "author" : [ "Armand Joulin", "Kevin Tang", "Li Fei-Fei" ],
      "venue" : "In Computer Vision–ECCV",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2014
    }, {
      "title" : "An affine invariant linear convergence analysis for frank-wolfe algorithms",
      "author" : [ "Simon Lacoste-Julien", "Martin Jaggi" ],
      "venue" : "CoRR, abs/1312.7864,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2013
    }, {
      "title" : "On the global linear convergence of Frank-Wolfe optimization variants",
      "author" : [ "Simon Lacoste-Julien", "Martin Jaggi" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2015
    }, {
      "title" : "Blockcoordinate frank-wolfe optimization for structural svms",
      "author" : [ "Simon Lacoste-Julien", "Martin Jaggi", "Mark W. Schmidt", "Patrick Pletscher" ],
      "venue" : "In Proceedings of the 30th International Conference on Machine Learning,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2013
    }, {
      "title" : "The complexity of large-scale convex programming under a linear optimization oracle",
      "author" : [ "Guanghui Lan" ],
      "venue" : "CoRR, abs/1309.5550,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2013
    }, {
      "title" : "A hybrid algorithm for convex semidefinite optimization",
      "author" : [ "Sören Laue" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2012
    }, {
      "title" : "Constrained minimization methods",
      "author" : [ "Evgeny S Levitin", "Boris T Polyak" ],
      "venue" : "USSR Computational mathematics and mathematical physics,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1966
    }, {
      "title" : "Minding the gaps for block frank-wolfe optimization of structured svm",
      "author" : [ "Anton Osokin", "Jean-Baptiste Alayrac", "Puneet K. Dokania", "Simon Lacoste-Julien" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2016
    }, {
      "title" : "Combinatorial Optimization - Polyhedra and Efficiency",
      "author" : [ "A. Schrijver" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2003
    }, {
      "title" : "Large-scale convex minimization with a low-rank constraint",
      "author" : [ "Shai Shalev-Shwartz", "Alon Gonen", "Ohad Shamir" ],
      "venue" : "In Proceedings of the 28th International Conference on Machine Learning,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2011
    }, {
      "title" : "Max-margin Markov networks",
      "author" : [ "B. Taskar", "C. Guestrin", "D. Koller" ],
      "venue" : "In Advances in Neural Information Processing Systems. MIT Press,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2003
    }, {
      "title" : "Graphical Models, Exponential Families, and Variational Inference",
      "author" : [ "M. Wainwright", "M.I. Jordan" ],
      "venue" : "Now Publishers Inc.,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2008
    }, {
      "title" : "Distance metric learning with eigenvalue optimization",
      "author" : [ "Yiming Ying", "Peng Li" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "Prime examples for this phenomenon include various structured polytopes that arise in combinatorial optimization, such as the path polytope of a graph (aka the unit flow polytope), the perfect matching polytope of a bipartite graph, and the base polyhedron of a matroid, for which we have highly efficient combinatorial algorithms for linear minimization that rely heavily on the specific rich structure of the polytope [22].",
      "startOffset" : 420,
      "endOffset" : 424
    }, {
      "referenceID" : 12,
      "context" : "It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].",
      "startOffset" : 128,
      "endOffset" : 166
    }, {
      "referenceID" : 16,
      "context" : "It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].",
      "startOffset" : 128,
      "endOffset" : 166
    }, {
      "referenceID" : 3,
      "context" : "It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].",
      "startOffset" : 128,
      "endOffset" : 166
    }, {
      "referenceID" : 8,
      "context" : "It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].",
      "startOffset" : 128,
      "endOffset" : 166
    }, {
      "referenceID" : 9,
      "context" : "It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].",
      "startOffset" : 128,
      "endOffset" : 166
    }, {
      "referenceID" : 22,
      "context" : "It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].",
      "startOffset" : 128,
      "endOffset" : 166
    }, {
      "referenceID" : 18,
      "context" : "It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].",
      "startOffset" : 128,
      "endOffset" : 166
    }, {
      "referenceID" : 25,
      "context" : "It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].",
      "startOffset" : 128,
      "endOffset" : 166
    }, {
      "referenceID" : 10,
      "context" : "It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].",
      "startOffset" : 128,
      "endOffset" : 166
    }, {
      "referenceID" : 13,
      "context" : "It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14].",
      "startOffset" : 128,
      "endOffset" : 166
    }, {
      "referenceID" : 4,
      "context" : "It is known, already from the first introduction of the method by Frank and Wolfe in the 1950’s [5], and the somewhat later work of Polyak and Levitin [20], that the method converges with a rate of roughly O(1/t) for minimizing a smooth convex function over a convex and compact set, which matches the rate of the standard projected gradient method for the same setting.",
      "startOffset" : 96,
      "endOffset" : 99
    }, {
      "referenceID" : 19,
      "context" : "It is known, already from the first introduction of the method by Frank and Wolfe in the 1950’s [5], and the somewhat later work of Polyak and Levitin [20], that the method converges with a rate of roughly O(1/t) for minimizing a smooth convex function over a convex and compact set, which matches the rate of the standard projected gradient method for the same setting.",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 17,
      "context" : "In fact, certain lower bounds, such as in [18, 6], suggest that such improvement, even if possible, should come with a worse dependence on the problem’s parameters (e.",
      "startOffset" : 42,
      "endOffset" : 49
    }, {
      "referenceID" : 5,
      "context" : "In fact, certain lower bounds, such as in [18, 6], suggest that such improvement, even if possible, should come with a worse dependence on the problem’s parameters (e.",
      "startOffset" : 42,
      "endOffset" : 49
    }, {
      "referenceID" : 7,
      "context" : "For instance, GuéLat and Marcotte [8] showed that a CG variant which uses the concept of away-steps converges exponentially fast in case the objective function is strongly convex, the feasible set is a polytope, and the optimal solution is located in the interior of the set.",
      "startOffset" : 34,
      "endOffset" : 37
    }, {
      "referenceID" : 2,
      "context" : "A similar result was presented by Beck and Teboulle [3] who considered a specific problem they refer to a the convex feasibility problem over an arbitrary convex set.",
      "startOffset" : 52,
      "endOffset" : 55
    }, {
      "referenceID" : 0,
      "context" : "Later, Ahipasaoglu, Sun and Todd [1] showed that in the specific case of minimizing a smooth and strongly convex function over the unit simplex, a variant of the CG method which also uses away-steps, converges with a linear rate.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 5,
      "context" : "The exponent in their convergence rate depends on various geometric parameters of the polytope [6].",
      "startOffset" : 95,
      "endOffset" : 98
    }, {
      "referenceID" : 14,
      "context" : "In a follow-up work, Lacoste-Julien and Jaggi [15, 16] gave a refined affine-invariant analysis of an algorithm presented in [8] which also uses away steps, and showed that it also converges exponentially fast in the same setting as the Garber-Hazan",
      "startOffset" : 46,
      "endOffset" : 54
    }, {
      "referenceID" : 15,
      "context" : "In a follow-up work, Lacoste-Julien and Jaggi [15, 16] gave a refined affine-invariant analysis of an algorithm presented in [8] which also uses away steps, and showed that it also converges exponentially fast in the same setting as the Garber-Hazan",
      "startOffset" : 46,
      "endOffset" : 54
    }, {
      "referenceID" : 7,
      "context" : "In a follow-up work, Lacoste-Julien and Jaggi [15, 16] gave a refined affine-invariant analysis of an algorithm presented in [8] which also uses away steps, and showed that it also converges exponentially fast in the same setting as the Garber-Hazan",
      "startOffset" : 125,
      "endOffset" : 128
    }, {
      "referenceID" : 1,
      "context" : "In a later work, Beck and Shtern [2] gave a different, duality-based, analysis for the algorithm of [8], and showed that it can be applied to a wider class of functions than purely strongly convex functions.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 7,
      "context" : "In a later work, Beck and Shtern [2] gave a different, duality-based, analysis for the algorithm of [8], and showed that it can be applied to a wider class of functions than purely strongly convex functions.",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 5,
      "context" : "However, the explicit dependency of their convergence rate on the dimension is suboptimal, compared to [6, 16].",
      "startOffset" : 103,
      "endOffset" : 110
    }, {
      "referenceID" : 15,
      "context" : "However, the explicit dependency of their convergence rate on the dimension is suboptimal, compared to [6, 16].",
      "startOffset" : 103,
      "endOffset" : 110
    }, {
      "referenceID" : 6,
      "context" : "Aside from the polytope case, Garber and Hazan have shown recently that in case the feasible set is strongly-convex and the objective function satisfies certain strong convexity-like proprieties, then the standard CG method converges with an accelerated rate of O(1/t2) [7].",
      "startOffset" : 270,
      "endOffset" : 273
    }, {
      "referenceID" : 1,
      "context" : "Maintaining such a decomposition and computing the away-steps, even with efficient implementations of incremental decomposition procedures, such as suggested in [2], require both memory and per-iteration runtime overheads that are at least quadratic in the dimension.",
      "startOffset" : 161,
      "endOffset" : 164
    }, {
      "referenceID" : 5,
      "context" : ", when the optimal solution is, informally speaking, dense (see for instance the lower bound in [6]), it is not clear that such an unfavorable dependence is mandatory when the optimum is sparse.",
      "startOffset" : 96,
      "endOffset" : 99
    }, {
      "referenceID" : 4,
      "context" : "#LOO calls runtime memory Frank & Wolfe [5] βD 2 1 n n Garber & Hazan [6] nβD 2 α log(1/ ) 1 n 2 n2 Lacoste-Julien & Jaggi [16] nβD 2 α log(1/ ) 1 n 2 n2 Beck & Shtern [2] n 2βD2 α log(1/ ) 1 n 2 n2 This paper card(x ∗)βD2 α log(1/ ) 2 n n",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 5,
      "context" : "#LOO calls runtime memory Frank & Wolfe [5] βD 2 1 n n Garber & Hazan [6] nβD 2 α log(1/ ) 1 n 2 n2 Lacoste-Julien & Jaggi [16] nβD 2 α log(1/ ) 1 n 2 n2 Beck & Shtern [2] n 2βD2 α log(1/ ) 1 n 2 n2 This paper card(x ∗)βD2 α log(1/ ) 2 n n",
      "startOffset" : 70,
      "endOffset" : 73
    }, {
      "referenceID" : 15,
      "context" : "#LOO calls runtime memory Frank & Wolfe [5] βD 2 1 n n Garber & Hazan [6] nβD 2 α log(1/ ) 1 n 2 n2 Lacoste-Julien & Jaggi [16] nβD 2 α log(1/ ) 1 n 2 n2 Beck & Shtern [2] n 2βD2 α log(1/ ) 1 n 2 n2 This paper card(x ∗)βD2 α log(1/ ) 2 n n",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 1,
      "context" : "#LOO calls runtime memory Frank & Wolfe [5] βD 2 1 n n Garber & Hazan [6] nβD 2 α log(1/ ) 1 n 2 n2 Lacoste-Julien & Jaggi [16] nβD 2 α log(1/ ) 1 n 2 n2 Beck & Shtern [2] n 2βD2 α log(1/ ) 1 n 2 n2 This paper card(x ∗)βD2 α log(1/ ) 2 n n",
      "startOffset" : 168,
      "endOffset" : 171
    }, {
      "referenceID" : 5,
      "context" : "To get lower complexity and memory requirements for the algorithms in [6, 16, 2], we assume they all employ an algorithmic version of Carathodory’s theorem to maintain a convex decomposition of the iterate to at most n + 1 vertices, as fully detailed in [2].",
      "startOffset" : 70,
      "endOffset" : 80
    }, {
      "referenceID" : 15,
      "context" : "To get lower complexity and memory requirements for the algorithms in [6, 16, 2], we assume they all employ an algorithmic version of Carathodory’s theorem to maintain a convex decomposition of the iterate to at most n + 1 vertices, as fully detailed in [2].",
      "startOffset" : 70,
      "endOffset" : 80
    }, {
      "referenceID" : 1,
      "context" : "To get lower complexity and memory requirements for the algorithms in [6, 16, 2], we assume they all employ an algorithmic version of Carathodory’s theorem to maintain a convex decomposition of the iterate to at most n + 1 vertices, as fully detailed in [2].",
      "startOffset" : 70,
      "endOffset" : 80
    }, {
      "referenceID" : 1,
      "context" : "To get lower complexity and memory requirements for the algorithms in [6, 16, 2], we assume they all employ an algorithmic version of Carathodory’s theorem to maintain a convex decomposition of the iterate to at most n + 1 vertices, as fully detailed in [2].",
      "startOffset" : 254,
      "endOffset" : 257
    }, {
      "referenceID" : 15,
      "context" : "We note that the bound on number of iterations in the analysis of [16] does not depend explicitly on the dimension n, but on the squared inverse pyramidal width of P, which is difficult to evaluate.",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 11,
      "context" : ", [12, 14, 16]).",
      "startOffset" : 2,
      "endOffset" : 14
    }, {
      "referenceID" : 13,
      "context" : ", [12, 14, 16]).",
      "startOffset" : 2,
      "endOffset" : 14
    }, {
      "referenceID" : 15,
      "context" : ", [12, 14, 16]).",
      "startOffset" : 2,
      "endOffset" : 14
    }, {
      "referenceID" : 5,
      "context" : "Importantly, the above assumptions allow us to get rid of the dependency of the convergence rate on certain geometric parameters (such as ψ, ξ in [6] or the pyramidal width in [15, 16]), which can be polynomial in the dimension, and hence result in an impractical convergence rate.",
      "startOffset" : 146,
      "endOffset" : 149
    }, {
      "referenceID" : 14,
      "context" : "Importantly, the above assumptions allow us to get rid of the dependency of the convergence rate on certain geometric parameters (such as ψ, ξ in [6] or the pyramidal width in [15, 16]), which can be polynomial in the dimension, and hence result in an impractical convergence rate.",
      "startOffset" : 176,
      "endOffset" : 184
    }, {
      "referenceID" : 15,
      "context" : "Importantly, the above assumptions allow us to get rid of the dependency of the convergence rate on certain geometric parameters (such as ψ, ξ in [6] or the pyramidal width in [15, 16]), which can be polynomial in the dimension, and hence result in an impractical convergence rate.",
      "startOffset" : 176,
      "endOffset" : 184
    }, {
      "referenceID" : 11,
      "context" : "It is well known that when setting the step-size ηt in an appropriate way, the worst case convergence rate of the method is O(βD2/t) [12].",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 17,
      "context" : "This convergence rate is tight for the method in general, see for instance [18].",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 5,
      "context" : "This key principle proves to be crucial to breaking the 1/t rate of the standard method, and to achieve a linear convergence rate under certain strong-convexity assumptions, as described in the recent works [6, 16, 2].",
      "startOffset" : 207,
      "endOffset" : 217
    }, {
      "referenceID" : 15,
      "context" : "This key principle proves to be crucial to breaking the 1/t rate of the standard method, and to achieve a linear convergence rate under certain strong-convexity assumptions, as described in the recent works [6, 16, 2].",
      "startOffset" : 207,
      "endOffset" : 217
    }, {
      "referenceID" : 1,
      "context" : "This key principle proves to be crucial to breaking the 1/t rate of the standard method, and to achieve a linear convergence rate under certain strong-convexity assumptions, as described in the recent works [6, 16, 2].",
      "startOffset" : 207,
      "endOffset" : 217
    }, {
      "referenceID" : 5,
      "context" : "For instance, in [6] it was shown, via the introduction of the concept of a Local Linear Optimization Oracle, that using such a non-uniform reweighing rule, in fact approximates a certain proximal problem, that together with the shrinking effect of strong convexity, as captured by Eq.",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 15,
      "context" : "As a concrete example, which will also serve as a basis for our new method, we bring the pairwise variant recently studied in [16], which applies this principle in Algorithm 2, given below 1.",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 5,
      "context" : "While the away-step-based variants increase the size of the decomposition by at most a single vertex per iteration, they also typically exhibit linear convergence after performing at least O(n) steps [6, 16, 2], and thus, this O(n2) estimate still holds.",
      "startOffset" : 200,
      "endOffset" : 210
    }, {
      "referenceID" : 15,
      "context" : "While the away-step-based variants increase the size of the decomposition by at most a single vertex per iteration, they also typically exhibit linear convergence after performing at least O(n) steps [6, 16, 2], and thus, this O(n2) estimate still holds.",
      "startOffset" : 200,
      "endOffset" : 210
    }, {
      "referenceID" : 1,
      "context" : "While the away-step-based variants increase the size of the decomposition by at most a single vertex per iteration, they also typically exhibit linear convergence after performing at least O(n) steps [6, 16, 2], and thus, this O(n2) estimate still holds.",
      "startOffset" : 200,
      "endOffset" : 210
    }, {
      "referenceID" : 1,
      "context" : "Moreover, since these methods require i) to find the worse vertex in the decomposition, in terms of dot-product with current gradient direction, and ii) to update this decomposition on each iteration (even when using sophisticated update techniques such as in [2]), the per-iteration over-head in terms of computation time of these methods is also at least O(n2).",
      "startOffset" : 260,
      "endOffset" : 263
    }, {
      "referenceID" : 15,
      "context" : "As observable in Table 1, for certain problems in which the optimal solution is sparse, all analyses of previous away-steps-based variants are significantly suboptimal, since they all depend explicitly on the dimension, which seems to While the convergence rate of this pairwise variant, established in [16], despite being linear, is significantly worse than other away-step-based variants, here we show on the contrary, that a proper analysis yields state-ofthe-art performance guarantees.",
      "startOffset" : 303,
      "endOffset" : 307
    }, {
      "referenceID" : 0,
      "context" : "Option 2: line-search γt ← maxγ∈[0,1]{xt + γ(v t − v − t ) ≥ 0}, η̃t ← minη∈(0,γt] f(xt + η(v + t − v − t ))",
      "startOffset" : 32,
      "endOffset" : 37
    }, {
      "referenceID" : 5,
      "context" : "This is much more efficient than previous linearly convergent CG variant, such as those in [6, 16, 2], which typically require at least additional O(n2) time and space per iteration, since they require to maintain an explicit convex decomposition of the iterates.",
      "startOffset" : 91,
      "endOffset" : 101
    }, {
      "referenceID" : 15,
      "context" : "This is much more efficient than previous linearly convergent CG variant, such as those in [6, 16, 2], which typically require at least additional O(n2) time and space per iteration, since they require to maintain an explicit convex decomposition of the iterates.",
      "startOffset" : 91,
      "endOffset" : 101
    }, {
      "referenceID" : 1,
      "context" : "This is much more efficient than previous linearly convergent CG variant, such as those in [6, 16, 2], which typically require at least additional O(n2) time and space per iteration, since they require to maintain an explicit convex decomposition of the iterates.",
      "startOffset" : 91,
      "endOffset" : 101
    }, {
      "referenceID" : 15,
      "context" : "• Theorem 1 improves significantly over the convergence rate established for the pairwise conditional gradient variant in [16].",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 15,
      "context" : "In particular, the number of iterations to reach an error in the analysis of [16] depends linearly on |V|!, where |V| is the number of vertices of P.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 21,
      "context" : "Since the graph G is a DAG, this could be carried out in O(m) time [22].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 21,
      "context" : "This could be carried out via combinatorial algorithms in min{Õ( √ nm), O(n3)} time [22].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 24,
      "context" : "There exists a set of linear constraints, known as the marginal polytope, which guarantees that these variables are legal marginals of some global distribution [25].",
      "startOffset" : 160,
      "endOffset" : 164
    }, {
      "referenceID" : 23,
      "context" : "For example, the learning problem in Max-Margin Markov Networks is defined as a quadratic program over the marginal polytope [24].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 24,
      "context" : "Fortunately, for some models, such as tree-structured graphs, the polytope can be characterized by a polynomial number of local consistency constraints, known as the local marginal polytope [25].",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 24,
      "context" : "For tree-structured graphsML is known to have only integral vertices [25], so it has the desired form assumed in Section 2.",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 0,
      "context" : "Suppose that the sequence of step-sizes {ηt}t≥1 is monotonically non-increasing, and contained in the interval [0, 1].",
      "startOffset" : 111,
      "endOffset" : 117
    }, {
      "referenceID" : 5,
      "context" : "from [6], it follows that we can write x as",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 0,
      "context" : "ci := { 0 if A2(i) · xt < b2(i) ∞ if A2(i) · xt = b2(i) 6: v− t ← arg minv∈V (−∇f(xt)) · v + cA2v 7: γt ← max{γ ∈ [0, 1] |A2(xt + γ(v t − v − t )) ≤ b2} 8: ηt ← arg minη∈[0,γt] f(xt + η(v + t − v − t )) 9: xt+1 ← xt + ηt(v t − v − t ) 10: end for",
      "startOffset" : 114,
      "endOffset" : 120
    }, {
      "referenceID" : 1,
      "context" : "Following the work of Beck and Shtern [2], we can consider a broader class of objective functions, namely functions that take the following form:",
      "startOffset" : 38,
      "endOffset" : 41
    }, {
      "referenceID" : 1,
      "context" : "In [2] (Lemma 2.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 11,
      "context" : "We emphasize that the idea behind the construction of this lower bound is well known and follows almost immediately from previous constructions, such as those in [12, 6].",
      "startOffset" : 162,
      "endOffset" : 169
    }, {
      "referenceID" : 5,
      "context" : "We emphasize that the idea behind the construction of this lower bound is well known and follows almost immediately from previous constructions, such as those in [12, 6].",
      "startOffset" : 162,
      "endOffset" : 169
    }, {
      "referenceID" : 15,
      "context" : "We use the two experimental settings from [16], which include a constrained Lasso problem and a video co-localization problem.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 23,
      "context" : "In addition, we test our algorithm on a learning problem related to an optical character recognition (OCR) task from [24].",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 15,
      "context" : "In each setting we compare the performance of our algorithm (DICG) to standard conditional gradient (CG), as well as to the fast away (ACG) and pairwise (PCG) variants [16].",
      "startOffset" : 168,
      "endOffset" : 172
    }, {
      "referenceID" : 15,
      "context" : "For the baselines in the first two settings we use the publicly available code from [16], to which we add our own implementation of Algorithm 3.",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 20,
      "context" : "Similarly, for the OCR problem we extend code from [21], kindly provided by the authors.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 15,
      "context" : "We generate the random matrix Ā and vector b̄ as in [16].",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 13,
      "context" : "Video co-localization The second example is a quadratic program over the flow polytope, originally proposed in [14].",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 23,
      "context" : "The constraints in this setting are the marginal polytope corresponding to a chain graph over the letters of a word (see [24]), and the objective function is quadratic.",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 16,
      "context" : "For this problem we actually run Algorithm 3 in a block-coordinate fashion, where blocks correspond to training examples in the dual SVM formulation [17, 21].",
      "startOffset" : 149,
      "endOffset" : 157
    }, {
      "referenceID" : 20,
      "context" : "For this problem we actually run Algorithm 3 in a block-coordinate fashion, where blocks correspond to training examples in the dual SVM formulation [17, 21].",
      "startOffset" : 149,
      "endOffset" : 157
    } ],
    "year" : 2016,
    "abstractText" : "Recently, several works have shown that natural modifications of the classical conditional gradient method (aka Frank-Wolfe algorithm) for constrained convex optimization, provably converge with a linear rate when: i) the feasible set is a polytope, and ii) the objective is smooth and strongly-convex. However, all of these results suffer from two significant shortcomings: 1. large memory requirement due to the need to store an explicit convex decomposition of the current iterate, and as a consequence, large running-time overhead per iteration 2. the worst case convergence rate depends unfavorably on the dimension In this work we present a new conditional gradient variant and a corresponding analysis that improves on both of the above shortcomings. In particular: 1. both memory and computation overheads are only linear in the dimension 2. in case the optimal solution is sparse, the new convergence rate replaces a factor which is at least linear in the dimension in previous works, with a linear dependence on the number of non-zeros in the optimal solution At the heart of our method, and corresponding analysis, is a novel way to compute decomposition-invariant away-steps. While our theoretical guarantees do not apply to any polytope, they apply to several important structured polytopes that capture central concepts such as paths in graphs, perfect matchings in bipartite graphs, marginal distributions that arise in structured prediction tasks, and more. Our theoretical findings are complemented by empirical evidence which shows that our method delivers state-of-the-art performance.",
    "creator" : "LaTeX with hyperref package"
  }
}