{
  "name" : "1602.07264.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Multivariate Biomarker for Parkinson’s Disease",
    "authors" : [ "Giancarlo Crocetti", "Michael Coakley", "Phil Dressner", "Wanda Kellum" ],
    "emails" : [ "wk59882w}@pace.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "the objective of selecting a set of genes (possibly small) that would help in the detection and classification of samples from patients affected by Parkinson Disease. We performed a complete data analysis and during the exploratory phase, we selected a list of differentially expressed genes. Despite their association with the diseased state, we could not use them as a biomarker tool. Therefore, our research was extended to include a multivariate analysis approach resulting in the identification and selection of a group of 20 genes that showed a clear potential in detecting and correctly classify Parkinson Disease samples even in the presence of other neurodegenerative disorders.\nKeywords—Genes, machine learning, data mining, multivariate\nanalysis, biomarker, Parkinson’s Diseases\nI. INTRODUCTION\nWe will analyze the microarray expression data of patients affected by Parkinson’s disease (PD) with the goal of identifying a biomarker for this condition. The expression dataset used in this research is the Parkinson_105_from_CEL.xls file [1] containing the data from the GEO accession GSE6613 generated using the MAS5 algorithm.\nThe dataset contains a total of 22,283 measurements of gene expression from samples belonging to three distinct groups of people for a total of 105 samples:\n1. Parkinson’s disease group (50 patients) 2. Healthy control group. (22) 3. Neurodegenerative control group. (33)\nThe disease control group (3) contains samples from patients with various neurodegenerative diseases: from Alzheimer to system atrophy. This control group might have characteristics that mimic symptoms of PD and will help to increase the specificity of the resulting biomarker.\nII. DATA PREPARATION\nThe sample’s columns in the original dataset have been renamed in order to easily identify the class to which each sample belongs. In particular the name for each sample has been prefixed with HC, ND or PD where:\nHC: Health Control sample ND: Neurodegenerative sample\nPD: Parkinson Disease sample\nThe prefix is followed by a sequence number for a unique\nidentification within the same group.\nExample: “HC_01_log_z” represents a healthy control\nsamples that has been transformed and standardized.\nBefore any scaling and/or normalization on the data we removed probesets whose expression measurements are not reliable or represent experimental noise. As filtering method we used the “filtering by Present calls” with a threshold of 25%. Relaxing this threshold to a value of 25% is reasonable due to the high number of samples in the dataset as suggested in [2]:\n“For data sets with 3-4 samples 50% Present spares most of\nthe probe sets significant at p 0.001 and those probes sets found most consistently. For more samples, relaxing the\nthreshold to 25% fraction Present is reasonable”.\nAfter the filtering phase the number of probesets dropped from 23,283 to 8,100. During this process, we also eliminated probesets with expression amplitude below the noise level (<100) since they represent nothing but noise.\nThe data was, then, analyzed and as expected it showed a strong right-skewness. In figure 1 we can see the effect of the logarithmic transformation on one of the control sample.\nthe ith probeset expression levels.\nWe used the z-score for normalizing the data, but also to detect the presence of possible outliers. During this process we were able to find some anomalous values in the dataset. By anomalous value we mean an observation that appears to be inconsistent when compared with values belonging to the same class for the same gene. We marked as possible outlier any value with an absolute z score value greater than 5.\nAn example of possible outlier can be found in the 49th sample for the 200028_at probeset in the Parkinson class. In this case the expression level is too low when compared to the other measurement in the same class. In fact, the average expression value in this class is 215.216; however the expression value for this particular sample is 30.72 indicating a possible defective probe.\nSince outliers might negatively influence analysis results we decided to investigate more closely and found a total of 643 outliers. How to deal with outliers in microarray data is not a straightforward topic, so we decided to replace these values with the average within their respective class: this might not be the best solution, however, it will limit the influence of such anomalous values during the data processing phase, especially in cases of algorithms sensitive to outliers.\nAs input in the next phases we prepared a dataset that:\n- Does not contain unreliable or noise probesets. - Does not contain outlier. - Contains normalized and standardized value.\nWe decided on these characteristics by noticing that almost all algorithms have better performance with a dataset that has been normalized and standardized. By “better performance” we mean at least one of the following:\n- An improvement on processing time. - An improvement on classification.\nIII. EXPLORATORY DATA ANALYSIS\nWe performed the univariate analysis with the goal of building a ranking of differentially expressed genes. We point out that this result is a univariate result in which each gene is considered in isolation and excluding its (possibly important) interaction with all other genes in the dataset; consequently the list of genes resulting from this task should not be used as biomarker in a classification system.\nThe problem of building a biomarker for Parkinson disease\nwill be considered in the next sections.\nFor the basic exploratory analysis we process our data using\nthe “GenePattern” application from the MIT institute [3].\nFor each gene, the application uses a test statistic to calculate the difference in gene expression between classes and then computes a p-value to estimate the significance of the test statistic score. Because testing tens of thousands of genes simultaneously increases the possibility of mistakenly identifying a non-differentially expressed gene as a differentially expressed gene (a false positive), GenePattern corrects for multiple hypothesis testing by computing both false discovery rates (FDR) and family-wise error rates (FWER) adjusted using the Bonferroni/Hochberg method. Researchers using GenePattern generally identify differentially expressed genes based on FDR rather than the more conservative FWER.\nThe first list of differentially expressed genes was obtained by running the dataset using the adjusted ANOVA F-test statistic with 1,000 permutations on all three sample classes. In order to compare results we ran the same test using the SNR (Signal to Noise Ratio) and the results were identical showing that, for this dataset, the adjusted ANOVA F-test and SNR results coincided when compared to the final ranking of genes.\nThe test statistics are defined in GenePattern as the\nfollowing:\nt-Test:\nwhere Ab are the group averages, A,B the group\nstandard deviations, and nA, nB the group sizes.\nSNR:\nwhere AB are the group averages and A,B the group\nstandard deviations\nThe application of this technique on a multiclass dataset\ngenerated a list of genes that:\n- Are up-regulated in PD (Parkinson Disease) when\ncompared with the other classes\n- Are up-regulated in the other classes but down-regulated\nin PD. The result of this analysis does not indicate which class contains the up-regulated gene(s), so a further analysis is warrant between the healthy control and the neurodegenerative samples.\nadjusted FDR (Bonferroni/Hochberg) less than 0.01.\nWe conclude this section by displaying the heat map of the top 40 genes as in figure 3. It was our intention to display the heat map for all 60 genes, but it would have been impossible to fit in this page.\nIn the image we can clearly distinguish areas in which the genes in each class are up or down regulated. The difference is more evident between samples in the Parkinson class when compared with the other two. More importantly we can clearly distinguish the difference in expression levels of genes between the Parkinson and the neuro-degenerative classes. This might be an important finding since the neuro-degenerative class has been introduced in the dataset in order to verify the prediction power of any biomarker for Parkison disease.\nIV. MULTIVARIATE MODELLING\nIn this section we will try to build a subset of features (as small as possible) that will be used as a multivariate classification model that will differentiate classes represented in the data set.\nMultivariate analysis considers the simultaneous effect of genes instead of stopping to the influence of single genes, which is typical of univariate approaches [4].\nFor this particular task we used the feature selection of\nWeka [5] ver. 3.4 called “Attribute Selection”.\nWeka provides a rich set of multivariate algorithms and we\nconsidered:\n Wrapper Subset Evaluator (WSE): implementation of\nforward wrapper method for feature selection for the creation\nof an optimal subset.\n Correlation-based Feature Selection (CFS): evaluation of\ndifferent combinations of features to identify an optimal\nsubset. The feature subsets are generated using different\nsearch techniques. We used Best First and Greedy search\nmethods with a forward direction.\n R-Support Vector Machine (RSVM): SVM in its recursive\nversion.\nIn all cases, we used 10 folds cross-validation method during the feature selection process, and in table 2 we report the parameters used in configuring the various algorithms in order to produce the feature subset.\nused with its default value.\nIn order to validate each model we used the “Weka Flow Knowledge” environment that allows the creation of crossvalidation set and verify the classification model as shown in figure 4.\nThe “Cross Validation Fold Maker” performs a crossvalidation, in which feature selection is performed during training of each model.\nWe noticed that each model performs better with its own particular classifier: so WSE performs better with NaiveBayes, CFS achieves high classification rates using neural networks LVQ while SVM performs well with SMO.\nFrom the results in table 3, we can see how the RSVM algorithm performed better than WSE and CFS even though WSE provided the smallest subset with only 6 genes.\nThe higher classification rate for the SVM is due to its capability of correctly identify the difference between ND and PD, something that is missing from WSE and CFS which incorrectly misclassified many healthy tissues.\nThe many algorithms had many options and tuning parameters and we are confident that all three classification\nmodels could be improved both at the feature selection and classification levels.\nV. CONCLUSIONS AND FURTHER WORK\nMultivariate models are a necessary tools in genomic\nstudies that could be applied for the detection and identification of neurodegenerative conditions like Parkinson’s disease.\nAmong the algorithms tested in this study, RSVM clearly\ncame out as an effective model to adopt in biomarker discovery, with the important ability of successfully discriminate between PD and other neurodegenerative diseases.\nThe identification of a small multivariate set of genes\nassociated to PD is an important step forward in Genomics, but this research cannot stop here, and the natural next step is to look for the biological interpretation of this result."
    } ],
    "references" : [ {
      "title" : "Dziuda, Data Mining for Genomics and Proteomics",
      "author" : [ "M. D" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Multivariate analysis considers the simultaneous effect of genes instead of stopping to the influence of single genes, which is typical of univariate approaches [4].",
      "startOffset" : 161,
      "endOffset" : 164
    } ],
    "year" : 2015,
    "abstractText" : "In this study, we executed a genomic analysis with the objective of selecting a set of genes (possibly small) that would help in the detection and classification of samples from patients affected by Parkinson Disease. We performed a complete data analysis and during the exploratory phase, we selected a list of differentially expressed genes. Despite their association with the diseased state, we could not use them as a biomarker tool. Therefore, our research was extended to include a multivariate analysis approach resulting in the identification and selection of a group of 20 genes that showed a clear potential in detecting and correctly classify Parkinson Disease samples even in the presence of other neurodegenerative disorders. Keywords—Genes, machine learning, data mining, multivariate analysis, biomarker, Parkinson’s Diseases",
    "creator" : "Microsoft® Word 2013"
  }
}