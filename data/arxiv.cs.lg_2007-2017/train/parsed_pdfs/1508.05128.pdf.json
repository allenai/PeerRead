{
  "name" : "1508.05128.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Lifted Relational Neural Networks",
    "authors" : [ "Gustav Šourek", "Vojtěch Aschenbrenner", "Ondřej Kuželka" ],
    "emails" : [ "souregus@fel.cvut.cz", "v@asch.cz", "zelezny@fel.cvut.cz", "KuzelkaO@cardiff.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Relational learning, Lifted models, Neural networks"
    }, {
      "heading" : "1. Introduction",
      "text" : "Lifted models also known as templated models have attracted significant attention recently (Kimmig et al., 2015) in areas such as statistical relational learning. Lifted models define patterns from which specific (ground) models can be unfolded. For example, a lifted Markov network model (Richardson and Domingos, 2006) may express that friends of smokers tend to be smokers and such a pattern then constrains the probabilistic relationships in all sets of\n∗ Corresponding author.\nc© G. Šourek, V. Aschenbrenner, F. Železný & O. Kuželka.\nar X\niv :1\n50 8.\n05 12\n8v 2\nvertices corresponding to particular friends-smokers in the derived ground Markov network. The lifted patterns are typically encoded in relational logic-based languages.\nHere we contribute a method for (deep) lifted feed-forward neural network learning, in which the ground network structure is unfolded from a set of weighted rules in relational logic. The relational rules are instantly interpretable and can be handcrafted by a domain expert or learned, e.g. through techniques of inductive logic programming (De Raedt, 2008). Weights of the ground neural networks are determined by the weighted relational rules and can be learned by stochastic gradient descent algorithm. This means that weights between different ground neurons constructed from the same relational rule are tied in our framework, similarly to how weights are shared in lifted graphical models in statistical relational learning or how weights are tied together by application of filters in convolutional neural networks in deep learning.\nA salient property of our approach distinguishing it from previous studies on adapting neural networks for relational learning is that the ground network structure depends not only on the relational rule set but also on a particular example, i.e., different networks are constructed for different examples to exploit their particular relational properties. However, the different networks share their weights as these are all bound to the relational rules, and so weight-updates performed for one training example are reflected in networks produced for other examples, which allows the model to learn directly from relational data.\nThe main advantage of the presented approach is that it can effectively learn weights of latent relational structures. This is a difficult task for existing lifted systems based on probabilistic inference because there one typically needs to run expensive expectation maximization algorithms in order to learn parameters when latent structures are present. On the other hand, deep neural networks, which we exploit in our work, have been shown to effectively learn latent structures, although obviously only in the ground non-relational settings. By combining relational logic with deep neural networks, we obtain a framework flexible enough to learn weights of latent relational structures, which we also verify experimentally. While there have been several works combining propositional or relational logic with neural networks (Towell et al., 1990; Botta et al., 1997; França et al., 2014), none of the existing methods is able to learn weights of latent non-ground relational structures1.\nThe rest of the paper is organized as follows. The next section briefly summarizes the preliminaries regarding relational logic and the assumed neural network paradigm. Section 3 explains the principles of the proposed Lifted Relational Neural Networks method. Section 4 describes useful modeling constructs. In Section 5, we show how weight-learning is implemented in it. Section 6 places the presented methods in the context of existing works. In Section 7, we subject the method to comparative experimental evaluation on relational learning benchmarks and then conclude the paper."
    }, {
      "heading" : "2. Preliminaries",
      "text" : "A first-order logic theory is a set of formulas formed from constants, variables, functions, and predicates (Smullyan, 1995). Constant symbols represent objects in the domain of interest (e.g. alice) and will be written in lower-case. Variables (e.g. Person) range over the\n1. What we mean by latent relational structures will be better explained in Section 4 where we present several types of latent structures which can be used in our framework.\nobjects in the domain and will be written with capitalized first letter. Function symbols will not be used in this paper. Predicate symbols represent relations among objects in the domain or their attributes. A term may be a constant or variable (or a function symbol applied to a tuple of terms). An atom is a predicate symbol applied to a tuple of terms (e.g. friends(X, bob)). Formulas are constructed from atoms using logical connectives and quantifiers. A ground term is a term containing no variables. A ground atom is an atom having only ground terms as arguments (e.g. friends(alice, bob)). A literal is an atom or a negation of an atom (which is also called a negative literal). A clause is a universally quantified disjunction of literals. When there is no risk of confusion, we will not write the universal quantifiers explicitly. A clause with exactly one positive literal is a definite clause. A definite clause with no negative literals (i.e. consisting of just one literal) is called a fact. A definite clause h∨¬b1 ∨ · · · ∨ ¬bk can also be written as an implication h← b1 ∧ · · · ∧ bk. The literal h is then called head and the conjunction b1 ∧ · · · ∧ bk is called body. We will sometimes call definite clauses, which are not facts, rules.\nGiven a first-order logic theory, the set of all ground atoms which can be constructed using the constants, function symbols and predicates present in the theory is its Herbrand base. A Herbrand interpretation, also called possible world, assigns a truth value to each possible ground atom from a given Herbrand base. A set of formulas is satisfiable if there exists at least one world in which all formulas from the set are true; such a world is its Herbrand model. A satisfiable set of definite clauses has a least Herbrand model and this model is unique. The least Herbrand model of a function-free set of definite clauses (i.e. a Datalog theory) can be constructed in finite number of steps using the immediate-consequence operator (Van Emden and Kowalski, 1976). Immediate consequence operator Tp maps the space of Herbrand interpretations over some Herbrand base B back to itself as Tp : I(B) 7→ I(B). The mapping of Tp is directly prescribed by the theory P such that for I ∈ I(B) the Tp(I) = {h|(h ← b1 ∧ · · · ∧ bk) ∈ P} and b1 ∧ · · · ∧ bk ⊆ I. In other words the operator Tp expands the current set of true atoms (interpretation I) with their immediate consequences as prescribed by the rules in P.\nAn artificial neural network (NN) is a biologically inspired mathematical model, consisting of interconnected processing units called neurons, each of which is associated with an activation function gi ∈ G from some predefined family of differentiable functions. Neural network then defines a mapping f : Rm 7→ Rn of input space to target space vectors, parameterized by a set of weights wlj ∈ R. Following the pattern of neural interconnections, the mapping f can be seen as a composition of activation functions gi ∈ G. For feed forward neural networks it is typically a hierarchical compound of non-linear weighted sums gi( ∑ j w l jgj( ∑ k w l+1 k gk(. . .))), which can be conveniently depicted as a weighted directed acyclic graph of neurons (e.g. Fig 3). By adapting the weights wij ∈ W the model can be learned to approximate some target function t : Rm 7→ Rn. This is typically performed by some sort of gradient descent minimization of a given cost function cost : {W,D} 7→ R capturing discrepancy between f and t upon some set of training samples (xd, t(xd)) ∈ D."
    }, {
      "heading" : "3. Lifted Relational Neural Networks",
      "text" : "A lifted relational neural network (LRNN) N is a set of weighted definite clauses, i.e. pairs (Ri, wi) where Ri is a function-free definite clause and wi is a real number. When N is a\nset of weighted definite clauses, N ∗ will denote the corresponding set of the definite clauses without weights, i.e. N ∗ = {C : (C,w) ∈ N}. The set N must satisfy the following nonrecursiveness2 requirement: there must exist a strict ordering ≺ of predicates such that if there is a rule with a predicate p1 in the head and a predicate p2 in the body then p1 ≺ p2.\nGiven a LRNN N , let H be the least Herbrand model of N ∗. We define grounding of the LRNN N as N = {(hθ ← b1θ ∧ · · · ∧ bkθ, w) : (h ← b1 ∧ · · · ∧ bk, w) ∈ N and {hθ, b1θ, . . . , bkθ} ⊆ H}. That is, N is defined as the set of ground definite clauses which can be obtained by grounding rules from the LRNN and which are active in the least Herbrand model of N ∗ (a rule is active in H if its body is true in H). As already outlined in Introduction, LRNNs are templates for creating ground neural networks. The requirement that ground rules should be active in H is beneficial for practice because it provides us with flexibility in controlling complexity of the constructed neural networks.\nExample 1 Let\nN ={(mother(C,M)← parent(C,M) ∧ female(M), 1), (father(C,F )← parent(C,F ) ∧male(F ), 2), (female(alice), 1), (parent(bob, alice), 1), (parent(eve, alice), 1)}.\nThen for its grounding we have\nN ={(mother(bob, alice)← parent(bob, alice) ∧ female(alice), 1), (mother(eve, alice)← parent(eve, alice) ∧ female(alice), 1), (female(alice), 1), (parent(bob, alice), 1), (parent(eve, alice), 1)}.\nNotice that N does not contain the predicates male/1 or father/2 as there are no ground atoms based on them in the least Herbrand model of N .\nDefinition 1 Let N be a LRNN, and let N be its grounding. Let g∨, g∧ and g∗∧ be families of multivariate functions with exactly one function for each number of arguments. The ground neural network of N is a feedforward neural network constructed as follows.\n• For every ground atom h occurring in N , there is a neuron Ah, called atom neuron. The activation functions of atom neurons are from the family g∨.\n• For every ground fact (h,w) ∈ N , there is a neuron F(h,w), called fact neuron, which has no input and always outputs a constant value.\n• For every ground rule hθ ← b1θ ∧ · · · ∧ bkθ ∈ N ∗ , there is a neuron Rhθ←b1θ∧···∧bkθ,\ncalled rule neuron. It has the atom neurons Ab1θ, . . . , Abkθ as inputs, all with weight 1. The activation functions of rule neurons are from the family g∧.\n2. The reason why we do not allow recursion will be clearer when we explain weight learning in the next section. Here, we just note that whereas rule sets without recursion will lead to optimization problems solvable by an algorithm which is basically a modified back-propagation algorithm, rule sets with recursion would lead to more complicated optimization problems which would not directly allow us to exploit existing results on training feedforward neural networks.\n• For every rule (h ← b1 ∧ · · · ∧ bk, w) ∈ N and every hθ ∈ H, there is a neuron Agghθ(h←b1∧···∧bk,w), called aggregation neuron. Its inputs are all rule neurons\nRhθ′←b1θ′∧···∧bkθ′ where hθ = hθ ′ with all weights equal to 1. The activation functions of the aggregation neurons are from the family g∗∧.\n• Inputs of an atom neuron Ahθ are the aggregation neurons Agghθ(h←b1∧···∧bk,w) and fact neurons F(hθ,w). The weights of the input neurons are the respective w’s.\nExample 2 Let us consider the following LRNN\nN ={(foal(A)← parent(A,P ) ∧ horse(P ), wm), (foal(A)← sibling(A,S) ∧ horse(S), wn), (horse(dakotta), w1), (horse(cheyenne), w2), (horse(aida), w3),\n(parent(star, aida), w6), (parent(star, cheyenne), w5), (sibling(star, dakotta), w4)}.\nThe LRNN N and its ground neural network are shown in Fig. 1.\nWhat distinguishes LRNNs from ordinary neural networks the most is the following property. Having a pre-trained LRNN N described by some general rules, we can extend it with description of a particular case to obtain a ground neural network and then use the latter for prediction. This is similar in spirit to lifted graphical models.\nExample 3 For instance, N may describe general rules for explosiveness of molecules (e.g. represented by a predicate explosive) and M1 and M2 may be sets of (weighted) facts describing two particular molecules. Then to use the LRNN N for predicting whether M1 and M2 are explosive, we can simply construct ground NNs of N ∪M1 and N ∪M2, and compute the output of the respective atom neurons explosive1 ∈ N ∪M1 and explosive2 ∈ N ∪M2. As a distinctive feature of lifted models, the two ground LRNNs for the two example molecules may have very different size and structure because the least Herbrand models\nof N ∗ ∪M∗1 and of N ∗ ∪M∗2, which determine the structures of the ground LRNNs, may be very different (because the structure and the size of the molecules described by M1 and M2 are different). An illustration of this effect, for two example molecules and a template N from Fig. 2, is displayed in Fig. 3.\nDepending on the used families of activation functions g∨, g∧ and g ∗ ∧, we can obtain neural networks with different behavior. For intuitiveness, in order for rules (h← b1 ∧ · · · ∧ bk, w) to behave similarly to “if-then” rules, we should prefer the outputs of rule neurons to be high (e.g. close to 1) if and only if all the inputs from the atom neurons corresponding to the literals from the body of the rule have high outputs. Similarly, we should prefer the output of the atom neurons, which should intuitively behave similarly to disjunction, to be high if and only if at least one of the rule neurons or fact neurons, which are inputs for the given atom neuron, has high output. Logical operators from various fuzzy logics (Klir and Yuan, 1995) may serve as an inspiration for selecting suitable activation functions.\nExample 4 In Goedel fuzzy logic, conjunction b1∧· · ·∧ bk, where bi are fuzzy logic literals, is given as mini bi and disjunction b1 ∨ · · · ∨ bk is given as maxi bi. To emulate reasoning in Goedel logic, we could simply set g∧(b1, . . . , bk) = mini bi, g ∗ ∧(b1, . . . , bm) = maxi bi, and g∨(b1, . . . , bm) = maxi bi. Here, the output of any rule neuron Rh←b1∧···∧bk is the minimum value which makes the fuzzy truth value of the implication h ← b1 ∧ · · · ∧ bk equal to 1 in the Goedel fuzzy logic. Likewise, the output of any aggregation neuron is the minimum value which makes the fuzzy truth value of all the respective ground implications equal to 1 simultaneously. This way, LRNNs can emulate fuzzy logic programming.\nNext, we introduce two particular collections of activation functions inspired by fuzzy logic which will be used in the experiments (note that the activation functions shown in the above example would not be very suitable for gradient-based learning).\nDefinition 2 (Max-Sigmoid Activation Functions) The Max-Sigmoid (MS) collection of activation functions is composed of the following three families of functions: g∧(b1, . . . , bk) = sigm (∑k i=1 bi − k + b0 ) , g∗∧(b1, . . . , bm) = maxi bi, and g∨(b1, . . . , bk) = sigm (∑k i=1 bi + b0 ) .\nThe rationale for this family of activation functions is as follows. As already mentioned, the activation function g∧ should have high output if and only if all its inputs are high. To achieve this, we can crudely approximate Lukasiewicz fuzzy conjunction, which is given as max{0, b1 + · · · + bk − k + 1}, by the function sigm (b1 + · · ·+ bk − k + b0). A plot of the function sigm (b1 + · · ·+ bk − k + 1) is shown, for k = 2, in the left panel of Fig. 4. The activation function g∗∧ outputs the value equal to the highest of its inputs. Example 5 illustrates that this can be seen as finding the best “match” of a pattern (rule). The activation function g∨ should have high output if at least one of the inputs is high or if all inputs are somewhat high. To satisfy this, we can crudely approximate Lukasiewicz fuzzy disjunction, which is given as min{1, b1+· · ·+bk} by the function sigm (b1 + · · ·+ bk + b0). A plot of the function sigm (b1 + · · ·+ bk + 0) is shown in the right panel of Fig. 4. Example 6 illustrates the intuition for the activation function g∨.\nExample 5 Let us consider the LRNN\nN ={(hasBrightEdge← isBright(E), 1), (isBright(E)← edge(E,U, V ) ∧ bright(U) ∧ bright(V ), 1), (bright(U)← yellow(U), 2), (bright(U)← red(U), 1), (bright(U)← blue(U), 0.5)}.\nLet us also have a set G describing a graph with colored vertices.\nG ={(edge(e1, v1, v2), 1), (edge(e2, v2, v3), 1), (edge(e3, v3, v4), 1), (edge(e4, v4, v1), 1), (red(v1), 1), (blue(v2), 1), (yellow(v3), 1), (yellow(v4), 1)}\nThe output of the atom neuron AhasBrightEdge will only depend on the “brightest edge”, i.e. in this case on the edge e3. The output would be the same for any other colored graph G′, which would also contain an edge connecting two yellow vertices. Thus, for instance, if we considered some physicochemical property of atoms (e.g. their partial charge) instead of brightness of colors, and molecules instead of colored graphs, the corresponding networks could detect presence of a molecular substructure similar to a prescribed pattern.\nExample 6 Let us have the LRNN\nN ={(highPressure(X)← stressed(X), 1), (highPressure(X)← obese(X), 1), (highPressure(X)← exercises(X),−1)}\nand the set of weighted facts P = {(stressed(alice), 1), (obese(alice), 1), (stressed(bob), 1), (exercises(bob), 1)}. Outputs of aggregation neurons corresponding to rules from N with the same predicate in the head are combined using the activation functions g∨. Intuitively, rules and facts with the same predicate in the head can be seen as forming a logistic regression on the values given by the aggregation neurons from the lower layers. When the LRNN has just one layer, as in this example, one can achieve the same effect using techniques from propositionalization (Krogel et al., 2003) – treating the bodies of the rules as features and feeding them as attributes to a logistic regression classifier. However, as soon as the LRNN\nhas more layers, this effect cannot be emulated using propositionalization. In this particular example, if we construct the ground LRNN of N ∪ P then the output of the atom neuron AhighPressure(alice) will be higher than the output of the atom neuron AhighPressure(bob) (because alice is stressed and obese whereas bob is just stressed and exercises).\nThe Max-Sigmoid activation function is obviously not the only one possible. It is useful when we are interested in detecting one or more patterns (such as the existence of an edge as bright as possible in Example 5) but less useful in situations similar to the one depicted in the next example.\nExample 7 Let us consider the following simple LRNN for predicting individuals infected by flu\nN ={(hasFlu(A)← friends(A,B) ∧ hasFluDiagnosed(B), 1)}\nand a set of weighted ground facts P about a group of people and their friendships. If we constructed the ground neural networks of N ∪ P using the activation functions from the Max-Sigmoid family then the prediction of whether an individual has flu would be entirely based on the existence of at least one person who already had flu diagnosed. It would be obviously more meaningful to base the predictions on the fraction of one’s friends who had flu diagnosed.\nA family of activation functions which are more appropriate in situations similar to to the one described in the above example is given by the next definition.\nDefinition 3 (Avg-Sigmoid Activation Functions) The Avg-Sigmoid (AS) collection of activation functions is composed of the following three families of functions: g∧(b1, . . . , bk) = sigm (∑k i=1 bi − k + b0 ) , g∗∧(b1, . . . , bm) = 1 m ∑m i=1 bi, and g∨(b1, . . . , bk) = ∑k i=1 bi + b0.\nAnother advantage of the Avg-Sigmoid family of activation functions over the MaxSigmoid family is also that the functions from the Avg-Sigmoid family are everywhere differentiable (which simplifies learning). We note that other activation function families based on combinations of different aggregation functions might also be exploited for LRNN learning."
    }, {
      "heading" : "4. Some LRNN Modeling Constructs",
      "text" : "In this section we describe several constructs which are easy in LRNNs but which would be difficult or impossible to implement in other existing frameworks combining logic and neural networks solely because, unlike LRNNs, the other frameworks do not allow simultaneous learning of target and auxiliary predicates. Moreover, while somewhat similar constructs could in principle be used in probabilistic logic programming systems such as Problog (De Raedt et al., 2007), when learning, they would require running costly EM algorithms which repeatedly need to perform computationally expensive probabilistic inference."
    }, {
      "heading" : "4.1. Implicit Soft Clustering",
      "text" : "In many domains one needs to create clusters of certain objects in order to achieve good generalization. This is the case e.g. in prediction of adverse effects of drugs where significant improvements in predictive accuracy were gained by methods which were able to create auxiliary clusters of similar drugs (Davis et al., 2012). However, the existing methods are still rather ad-hoc, relying on greedy discrete clustering. In LRNNs it is easy to define predicates representing these clusters, to train their weights automatically and use them for prediction of target predicates as illustrated by the following example.\nExample 8 Let us suppose that, similarly to (Davis et al., 2012), we have temporal data about patients, drugs which the patients took and time instants when changes in health occurred. Let us also assume that we have a set of general rules like:\nw (1) 1 : effect(P,AE, T2) ← took(P,D1, T1) ∧ period(T1, T2, T ) ∧ shortPeriod(T )∧\n∧took(P,D2, T2) ∧ drugGroup1(D1) ∧ drugGroup2(D2)∧ ∧effectGroup1(AE) . . .\nw (2) 1 : effectGroup1(E) ← headache(E) w (2) 2 : effectGroup1(E) ← sneezing(E)\n. . .\nUsing the Max-Sigmoid family of aggregation functions, weight learning in this LRNN can implicitly create clusters of drugs which interact adversely with other clusters of drugs and clusters of adverse effects corresponding to these combinations of drugs, as well as appropriate definition for the predicate shortPeriod.\nWhile we were not able to perform experiments in the domain described in the above example because the data are not available for privacy reasons, we perform a simpler set of experiments in organic chemistry domains where the implicitly created soft clusters correspond to groups of atom types and atomic bond types. We describe these experiments in detail in Section 7. There we show that useful clusters are indeed created automatically by weight learning in LRNNs. One of the reasons for discussing the example about adverse effects of drugs here (in spite of the unavailability of the data) is to indicate that the machinery of LRNNs is very promising for existing problems for which only rather ad-hoc solutions exist currently."
    }, {
      "heading" : "4.2. Soft Matching",
      "text" : "The next example explains the notion of a construct called soft matching and how it can be modeled in LRNNs.\nExample 9 Let us again consider the example about predicting flu. Let us suppose that we have the reasonable rule that if X is in a group of 4 people who are mutual friends and all of them have flu symptoms then X has flu\nw (1) 1 : hasFlu(X) ← clique(W,X, Y, Z) ∧ fluSymptoms(W ) ∧ fluSymptoms(X)∧\n∧fluSymptoms(Y ) ∧ fluSymptoms(Z).\nHowever, it is probably not necessary for W , X, Y and Z to be mutually friends in order for this rule to make sense. The rule is still valid, but maybe with lower certainty, if two of these four people are not actually friends, or maybe even if there are two such pairs or more. This is easily expressible in LRNNs by suitably defining the predicate clique and automatically learning the respective weights:\nw (2) 1 : clique(W,X, Y, Z) ← f(W,X) ∧ f(W,Y ) ∧ f(W,Z) ∧ f(X,Y ) ∧ f(X,Z) ∧ f(Y,Z) w (3) 1 : f(X,Y ) ← friends(X,Y ) ∧ friends(Y,X) w (3) 2 : f(X,Y ) ← friends(X,Y ) w (3) 3 : f(X,Y ).\nHere, the predicate friends is assumed to be part of description of examples and soft matching of cliques is facilitated by the definition of the predicate f based on it. Using the activation functions from the Max-Sigmoid family for the predicates hasFlu and f, we can obtain the desired behavior with suitable weights."
    }, {
      "heading" : "4.3. Other LRNN Concepts",
      "text" : "While soft clustering and soft matching are probably the modeling concepts which would be used most often in practice, there are other modeling concepts which are easily implementable with LRNNs. One such other concept is low dimensional approximation of sets of (hyper)graph patterns which share structure but not labels, as exemplified below.\nExample 10 Let us consider the problem of predicting a property, e.g. toxicity, of organic molecules which depends on presence of substructures from certain rather large set. If the patterns have the same structure, e.g. they are all aromatic six-rings with substitutions3 at some positions, one could in principle use probabilistic modeling to approximate this set by a probability distribution on the substitutions at different places so that the substitutions which are jointly occurring in the set of patterns would have high probability and the other substitutions small probability. While this probabilistic modeling approach is possible, it requires us to explicitly have the set of patterns. If the set of patterns should correspond to a latent concept, we would have to resort to EM. On the other hand, similar approximations to the latent set of patterns can be modeled in LRNNs quite easily. For instance, if we want to capture pair-wise dependencies of substitutions in neighboring atoms, we can first define auxiliary binary predicates\nw (1) 1 : e1(carbon, nitrogen), w (1) 2 : e1(carbon, oxygen), . . .\nThen, we can define a predicate\nw (2) 1 : sixRing(A,B,C,D,E, F )← ring(A,B,C,D,E, F )∧e1(A,B)∧e2(B,C)∧. . . e6(F,A)\n3. The basic aromatic six-ring is the benzene ring which is a ring of six carbon atoms, each connected to a hydrogen atom, connected by aromatic bonds. If some of the carbon atoms is replaced by another atom, we speak of a substitution.\nand similar predicates for five-rings and other structures, and then construct rules for prediction of the property of interest (toxicity in this case) as follows:\nw1 : toxic(M)← atom(M,A) ∧ atom(M,B) ∧ · · · ∧ atom(M,F ) ∧ sixRing(A,B,C,D,E, F ) w2 : toxic(M)← atom(M,A) ∧ atom(M,B) ∧ · · · ∧ atom(M,E) ∧ fiveRing(A,B,C,D,E) . . .\nWeight learning can then simultaneously adjust weights of the latent auxiliary predicates as well as the target predicates (we show this experimentally in Section 7).\nExploiting the process of grounding of the lifted template, facilitating weight sharing in the ground networks, LRNNs can also emulate principal structures of convolutional neural networks (Krizhevsky et al., 2012) as the next example shows.\nExample 11 Let us consider a structure of the popular Convolutional Neural Network architecture composed of sparse convolutional layers alternated with max-pooling. Within the sparse layer, the weights corresponding to a single convolution filter are effectively bound to the same value while the filter is repeated across. Within selected subregions, the resulting feature-map values are then aggregated with application of max-pooling, i.e. only the maximal values from each feature-map region are propagated further. This structural idea can be efficiently encoded by LRNN and generalized for feature maps (images) of varying size with the choice of Max-Sigmoid function family and a simple lifted template defined as follows\nw (1) 0 : f1 ← left(A),mid(B), right(C), next(A,B), next(B,C) w (2) 1 : left(X) ← f0(X) w (2) 2 : mid(X) ← f0(X) w (2) 3 : right(X) ← f0(X)\nwhich corresponds to a convolution filter f1 that can be bound to an arbitrary number of relational patterns, in this case simple linear segments of three neighboring features (A,B,C), of the input feature-map defined as a linearly ordered set of weighted facts about feature f0 values (f0(X), vx) (i.e. values vx of pixels X = {1 . . . n}). The choice of Max-Sigmoid family then ensures max-aggregation to be applied on top of each such a convolutional layer. Visualization of a grounding of this template on a particular feature-map (image I) of five (n = 5) consecutive values (pixels) is provided in Fig 5.\nOther concepts which we do not describe in detail due to lack of space include e.g. relational auto-encoders."
    }, {
      "heading" : "5. Weight Learning",
      "text" : "Let us have a LRNN N and a set of training examples E = {E1, . . . , Em} where each Ej is some structure represented by a set of weighted propositions (e.g. left part of Fig. 2), i.e. a LRNN containing only facts4. Let us also have a set Q = {{(q11, t11), . . . , (q1k1 , t 1 k1\n)} , . . . , {(qm1 , tm1 ), . . . , (qmkm , t m km )}} where qji are ground atoms, which we call training query\n4. The restriction of learning from facts only is actually not necessary but it will simplify this presentation.\natoms, and tji are their target values. For any query atom q j i , let y j i denote the output of the atom neuron A qji\nin the ground neural network of N ∪ Ej . The goal of the learning process is to find weights wh of the rules (and possibly facts) in N minimizing cost J on the training query atoms J(Q) = ∑m j=1 ∑kj i=1 cost(y j i , t j i ) where cost is some predefined cost function which measures the discrepancy between the output of the atom neurons of the training query atoms and their desired target values. Similarly to conventional NNs, weight adaptation is performed by gradient descent steps\nwh ← wh − γ ∂J(Q) ∂wh\nwhere γ is some given learning rate. The main difference is that in the case of LRNNs, the ground neural networks may be very different for different learning examples Ej . However, this is not a fundamental problem because the weights for all the ground neural networks N ∪ Ej are fully specified in the LRNN N .\nExample 12 Let us demonstrate for clarity a sample scenario with Avg-Sigmoid activation function family and a mean square error cost function, i.e. with each step we aim to decrease5\nJ(Q) = 1 2 m∑ j=1 kj∑ i=1 ( sigm(tji )− sigm(y j i ) )2\n5. In this example, we pass the output from the output atom neurons and the target values through a sigmoid. This is useful when learning with the Avg-Sigmoid activation function family. An alternative would be to use cross-entropy as error function.\nwhere the target values tji are given by Q and outputs y j i of individual atom neurons Aqji are calculated as\nA qji = ∑ k wk Agg qji (h←b1∧···∧bnk ,wk) − wA q j i\nwhere Agg qji (h←b1∧···∧bnk ,wk) denotes the outputs of aggregation neurons forming the inputs of A qji with respective rule weights wk, and wA q j i denotes the offset of activation function of the atom neuron A qji . Since we have chosen the Avg-Sigmoid function family, the outputs of aggregation neurons are further calculated as\nAgg qji (h←b1∧···∧bnk ,wk) = 1 l l∑ m=1 R qji←b1θm∧···∧bnkθm\nwhere R qji←b1θm∧···∧bnkθm denotes outputs of respective input rule neurons formed from all different groundings (substitutions θm) of the rule Rhθm←b1θm∧···∧bnkθm where hθm = q j i . The output of the rule neurons can finally be calculated as\nR qji←b1θm∧···∧bnkθm = sigm   nk∑ o=1 A bjoθm − nk \nwhere A bjoθm denotes output of another (regular) atom neuron from the lower layers of the ground network N ∪ Ej corresponding to one of the ground body literals boθm of the respective ground rule qji ← b1θm ∧ · · · ∧ bnkθm. The calculation of Abjoθm can further be carried out in a recursive manner until the fact neurons F(h,w) are reached with fixed constant values defined by E (or possibly N ). We note that the whole evaluation composed of differentiable functions and the gradient ∂J(Q)∂wh can thus be calculated using regular chain rule.\nMoreover, the weights from N can be repeated multiple times within a single N ∪ Ej , but since recursion is not allowed, the same weight can appear at most once on any simple path from a fact neuron to an atom neuron. Therefore it is possible to learn the weights using conventional online stochastic gradient descent algorithm6, except that the increments for the shared weights must be accumulated, which is a simple consequence of linearity of partial differentiation. The same principle is exploited e.g. in learning of convolutional neural networks (Example 11).\nRemark 4 Let us consider a ground N ∪ Ej as a regular feed forward neural network Nj with some weights wk ∈ Wj in the network being shared, i.e. bound to the same value, with the restriction that each particular weight wk appears at most once on any simple path from input ej to output yj. Let the activation functions of layers l of Nj be f l ∈ F j from some\n6. Learning is slightly more complicated for LRNNs with the Max-Sigmoid family of activation functions because the max operator introduces non-differentiable points to the optimization problem.\nset of differentiable functions. Let further wik denote particular occurrences of some shared weight wk, then we might express the output of the network as\nyj = f 1 ( . . .+ wakf 2 (. . .) + . . .+ wmf 2 ( · · ·+ wbkf3 (. . .) + . . . ) + . . . ) where ”. . .” correspond to expressions with no wk occurrence. Considering each wk occurrence separately as an independent variable, we have\n∂yj ∂wak =\n∂ ( f1 ( wakf 2(. . .) ))\n∂wak = f1′(. . .)f2(. . .)\n∂yj ∂wbk =\n∂ ( f1 ( wmf 2 ( wbkf 3 (. . .) )))\n∂wbk = f1′(. . .) wmf 2′ (. . .) f3 (. . .)\nConsidering all occurrences of wik as a single variable wk, we have\n∂yj ∂wk =\n∂ ( f1 ( wkf 2(. . .) + wmf 2 ( wkf 3 (. . .) )))\n∂wk = f1′ (. . .)\n( f2 (. . .) + wmf 2′ (. . .) f3 (. . .) )\ni.e., we see that ∂yj ∂wk = ∂yj ∂wak + ∂yj ∂wbk which follows also directly from additivity of the differentiation operator (keeping in mind that there is only one occurrence of wk on any simple path from an atom neuron to a fact neuron). Therefore gradient can be computed for the ground neural networks created from a given LRNN in the standard way and then the components corresponding to a particular weight wk can be accumulated.\nSpecifically, our weight-learning algorithm works as follows. First, it grounds the given LRNN N w.r.t. every example Ej from the dataset which gives it a set of ground neural networks N ∪ Ej with shared weights (it keeps the information about the origin of each weight so that it could update the respective weights in the template in each step of the iteration). It then iterates over the ground networks in a random order, computes gradient of the error function for the current particular example given the current weights in the template, updates the weights accordingly and continues iterating these steps (i.e., the standard stochastic gradient descent procedure). In order to reduce the risk of getting stuck in poor quality local optima, we also employ a restart strategy for this algorithm."
    }, {
      "heading" : "6. Related Work",
      "text" : "The main inspiration for the work presented in this paper are lifted graphical models such as Markov logic networks (Richardson and Domingos, 2006) or Bayesian logic programs (Kersting and De Raedt, 2001). However, none of these existing lifted graphical models is particularly well suited for learning parameters of latent relational structures. Our approach is also generally related to prior art in combining logical rules with neural networks, also\nknown as neural-symbolic integration (d’Avila Garcez et al., 2012), such as in the KBANN system. While the KBANN (Towell et al., 1990) also constructs the network structure from given rules, these rules are propositional rather than relational and do not serve as a lifted template. Therefore it is impossible to learn relational latent structures such as soft clustering of first-order-logic constants. A more recent system CILP++(França et al., 2014) utilizes a relational representation, which is however converted into a propositional form through a propositionalization technique (Krogel et al., 2003). This again means that latent relational structures such as those exemplified in Section 4 cannot be learned by CILP++ either. A somewhat more closely related paper on FONN (Botta et al., 1997) also designs a technique forming a network from relational rule set, however this rule set is flat, producing only 1-layer (shallow) networks in which relational patterns are not hierarchically aggregated. While there are many other approaches of neural-symbolic integration aiming at relational (and first-order) representations (Bader and Hitzler, 2005), e.g. based on the CORE method (Hölldobler et al., 1999), they typically search for a uniform model of the logic program in scope and thus principally differ from the presented lifted modeling approach.\nWhile standard feed-forward neural networks can be seen as a special case of LRNNs, since any such a fixed neural architecture can be encoded in a corresponding ground rule set with respective activation functions, a salient aspect of our method is that it allows for learning from structured (relational) examples, rather than just attribute vectors. There has been previous work on adapting neural networks to cope with certain facets of relational representations. For example, extension to multi-instance learning was presented in (Ramon and De Raedt, 2000). A similarly directed work (Blockeel and Uwents, 2004) facilitated aggregative reasoning to process sets of related tuples from relational database as a sequence through recurrent neural network structure, which was also presented for more general structures in (Scarselli et al., 2009). These approaches are principally different from the presented method as they do not follow the lifted modeling strategy to cope with variations in structure of relational samples. More loosely related works arise also in the neural networks community, where various recursive auto-encoders based on the idea of “reduced descriptions” (Hinton, 1990) are trained to encode structured data. Another line of work are convolutional neural networks (LeCun et al., 1998) and techniques of indirect encoding (Clune et al., 2011), exploiting patterns and regularities in neural connections to create more compressed representations of large neural networks. However, these approaches are still geared towards learning from fixed-length propositional rather than relational data."
    }, {
      "heading" : "7. Experiments",
      "text" : "In this section we describe experiments performed on 78 datasets of organic molecules: Mutagenesis dataset (Lodhi and Muggleton, 2005), four datasets from the predictive toxicollogy challenge and 73 NCI-GI datasets (Ralaivola et al., 2005). The Mutagenesis dataset contains 188 molecules with labels denoting their mutagenicity. A number of the results published on the mutagenesis dataset use extended set of features, providing additional expert knowledge on relational properties of molecules, degrading the role of learning capabilities in relational models. We do not use any of the extra features as we utilize only atom-bond information. The predictive toxicology challenge dataset (PTC) (Helma et al.,\n2001) is composed of four datasets of molecules labeled by their toxicity for female rats (fr), mouse (fm) and male rat (mr) and mouse (mm). Each of the NCI-GI datasets contains several thousands of molecules labeled by their ability to inhibit growth of different types of tumors. We compare performance of LRNNs to state-of-the-art relational learners kFOIL (Landwehr et al., 2006) and nFOIL (Landwehr et al., 2007), where kFOIL combines relational rule learninng with support vector machines and nFOIL combines relational rule learning with naive Bayes learning.\nFor LRNNs we use a simple hand-crafted template which is based on the idea of implicit soft clustering described in Section 4.1 and is principally identical to the template discussed in Figure 2. The template defines 3 predicates for clusters of atom types and 3 predicates for clusters of bond types. The three predicates representing atom-type clusters are composed of exhaustive lists of atom types occurring in the datasets, e.g. w (1) 1 : atgr1(X) ← o(X), w (1) 1 : atgr1(X) ← br(X), . . . and similarly the predicates representing bond-type clusters are composed of exhaustive lists of bond types occurring in the datasets. These predicates are then used in definitions of predicates for different types of small chains of atoms of length 3, e.g. chain1← atgr1(X) ∧ bond(X,Y,B1) ∧ atgr1(Y ) ∧ bond(Y, Z,B2) ∧ atgr2(Z) ∧ bondgr1(B1) bondgr2(B2). These are finally used to define the target predicate, e.g. toxic. Using such a generic template for all the datasets, we make sure that there is no additional expert knowledge involved 7. The idea is that in the process of learning, useful latent relational concepts are created within the neural network by the means of weight adaptation rather than by explicit enumeration, in contrast to propositional approaches and ILP (De Raedt, 2008). Indeed, none of the rules used in this template is useful on itself for prediction as a hard logic rule without weight adaptation.\nTo set the parameters of LRNNs we use the empirical risk minimization principle on the training cross-validation folds to select the parameters such as step size, restarts, number of iterations, etc. This way we obtain unbiased estimates of performance of our methods since test data is never involved in parameter selection. The time for training a LRNN was in the order of few hours for the larger NCI-GI datasets. The results of the experiments are summarized in Figure 6. LRNNs perform clearly the best of the algorithms in terms of accuracy as they have lower prediction error than kFOIL and nFOIL on significant majority of datasets. We also tried to compare LRNNs with another recent algorithm combining logic and neural networks, called CILP++ (França et al., 2014), but we didn’t find it to perform well on our relational datasets as we were not able to obtain, using CILP++, accuracy significantly higher than simple majority class error on any of the datasets8.\nFor demonstration, we provide visualization of the latent grouping (clustering) LRNN layers for the Mutagenesis and for the PTC-mr datasets in Fig. 7. It is apparent from the learned weights in figures that the hidden layers are indeed learning useful latent groupings of atom types. It is interesting to note that on the Mutagenesis dataset, one of the learned groupings of atom types gives all atoms almost the same weight, which actually makes sense because it corresponds to a “wild-card” atom type. On the other hand, no similar behavior\n7. I.e., the template does not relate to any specific property of molecules and might be as well used for other classification tasks, too. 8. While relatively reasonable results for Mutagenesis were reported in (França et al., 2014), the expertknowledge attributes were used in the experiments reported therein, which might explain the discrepancy between the results.\nis typically found for the other datasets, which we have checked for different seeds of the PRNG used for initialization of weights.\nIn order to test the modeling concept described in Section 4.3, we performed an additional experiment with the Mutagenesis dataset. We used almost exactly the same template as in Example 10 but instead of ring structures we used chains of varying lengths (up to 5 atoms). We trained the resulting LRNN to optimize the template’s weights, however here we were more interested in extracting the learned patterns. We determined the chains of atoms which gave the highest output for the learned latent predicates. We obtained the following atom chain structures: C-C-F, N-O, C-Cl, C-Br, C-C-O, O-N-C. At least some of\nthese structures appear to be directly relevant for the mutagenicity as they contain organic structures containing halogen atoms (Br, F and Cl). The other structures may be relevant to mutagenicity in combination with other structures."
    }, {
      "heading" : "8. Conclusions",
      "text" : "In this paper, we have introduced a method combining relational-logic representations with feedforward neural networks. The introduced method is close in spirit to lifted graphical models as it can be viewed as providing a lifted model for construction of ground neural networks. The performed experiments indicate that it is possible to achieve state-of-the-art predictive accuracies by weight learning with very generic templates and that it is able to induce notable auxiliary concepts. There are many directions for future work, including structure learning, transfer learning or studying different collections of activation functions. An important future direction is also the question of extending LRNNs to support recursion."
    }, {
      "heading" : "Acknowledgments",
      "text" : "GS and FŽ are supported by Cisco sponsored research project “Modelling network traffic with relational features”. While with CTU, OK was supported by the Czech Science Foundation through project P202/12/2032 and now by a grant from the Leverhulme Trust (RPG-2014-164)."
    } ],
    "references" : [ {
      "title" : "Dimensions of Neural-symbolic Integration - A Structured Survey",
      "author" : [ "Sebastian Bader", "Pascal Hitzler" ],
      "venue" : "arXiv preprint,",
      "citeRegEx" : "Bader and Hitzler.,? \\Q2005\\E",
      "shortCiteRegEx" : "Bader and Hitzler.",
      "year" : 2005
    }, {
      "title" : "Using neural networks for relational learning",
      "author" : [ "H Blockeel", "W Uwents" ],
      "venue" : "In ICML-2004 Workshop on Statistical Relational Learning and its Connection to Other Fields,",
      "citeRegEx" : "Blockeel and Uwents.,? \\Q2004\\E",
      "shortCiteRegEx" : "Blockeel and Uwents.",
      "year" : 2004
    }, {
      "title" : "Combining first order logic with connectionist learning",
      "author" : [ "M Botta", "Giordana A", "R Piola" ],
      "venue" : "In Proceedings of the 14th International Conference on Machine Learning,",
      "citeRegEx" : "Botta et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Botta et al\\.",
      "year" : 1997
    }, {
      "title" : "On the performance of indirect encoding across the continuum of regularity",
      "author" : [ "Jeff Clune", "Kenneth O. Stanley", "Robert T. Pennock", "Charles Ofria" ],
      "venue" : "IEEE Trans. Evolutionary Computation,",
      "citeRegEx" : "Clune et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Clune et al\\.",
      "year" : 2011
    }, {
      "title" : "Neural-Symbolic Learning Systems: Foundations and Applications",
      "author" : [ "Artur S. d’Avila Garcez", "Krysia Broda", "Dov M. Gabbay" ],
      "venue" : null,
      "citeRegEx" : "Garcez et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Garcez et al\\.",
      "year" : 2012
    }, {
      "title" : "Demand-driven clustering in relational domains for predicting adverse drug events",
      "author" : [ "Jesse Davis", "Vı́tor Santos Costa", "Elizabeth Berg", "David Page", "Peggy L. Peissig", "Michael Caldwell" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "Davis et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Davis et al\\.",
      "year" : 2012
    }, {
      "title" : "Logical and Relational Learning",
      "author" : [ "Luc De Raedt" ],
      "venue" : null,
      "citeRegEx" : "Raedt.,? \\Q2008\\E",
      "shortCiteRegEx" : "Raedt.",
      "year" : 2008
    }, {
      "title" : "Problog: A probabilistic prolog and its application in link discovery",
      "author" : [ "Luc De Raedt", "Angelika Kimmig", "Hannu Toivonen" ],
      "venue" : "IJCAI",
      "citeRegEx" : "Raedt et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Raedt et al\\.",
      "year" : 2007
    }, {
      "title" : "Fast relational learning using bottom clause propositionalization with artificial neural networks",
      "author" : [ "Manoel VM França", "Gerson Zaverucha", "Artur S dAvila Garcez" ],
      "venue" : "Machine learning,",
      "citeRegEx" : "França et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "França et al\\.",
      "year" : 2014
    }, {
      "title" : "The predictive toxicology challenge 2000–2001",
      "author" : [ "Christoph Helma", "Ross D. King", "Stefan Kramer", "Ashwin Srinivasan" ],
      "venue" : null,
      "citeRegEx" : "Helma et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Helma et al\\.",
      "year" : 2001
    }, {
      "title" : "Mapping part-whole hierarchies into connectionist networks",
      "author" : [ "Geoffrey E. Hinton" ],
      "venue" : null,
      "citeRegEx" : "Hinton.,? \\Q1990\\E",
      "shortCiteRegEx" : "Hinton.",
      "year" : 1990
    }, {
      "title" : "Approximating the semantics of logic programs by recurrent neural networks",
      "author" : [ "Steffen Hölldobler", "Yvonne Kalinke", "Hans Peter Störr" ],
      "venue" : null,
      "citeRegEx" : "Hölldobler et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Hölldobler et al\\.",
      "year" : 1999
    }, {
      "title" : "Towards combining inductive logic programming with bayesian networks",
      "author" : [ "Kristian Kersting", "Luc De Raedt" ],
      "venue" : "In Inductive Logic Programming, 11th International Conference,",
      "citeRegEx" : "Kersting and Raedt.,? \\Q2001\\E",
      "shortCiteRegEx" : "Kersting and Raedt.",
      "year" : 2001
    }, {
      "title" : "Lifted graphical models: a survey",
      "author" : [ "A Kimmig", "L Mihalkova", "L Getoor" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Kimmig et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kimmig et al\\.",
      "year" : 2015
    }, {
      "title" : "Fuzzy sets and fuzzy logic, volume 4",
      "author" : [ "George Klir", "Bo Yuan" ],
      "venue" : "Prentice Hall New Jersey,",
      "citeRegEx" : "Klir and Yuan.,? \\Q1995\\E",
      "shortCiteRegEx" : "Klir and Yuan.",
      "year" : 1995
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing",
      "author" : [ "Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton" ],
      "venue" : null,
      "citeRegEx" : "Krizhevsky et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Comparative evaluation of approaches to propositionalization",
      "author" : [ "Mark-A Krogel", "Simon Rawles", "Filip Železný", "Peter A Flach", "Nada Lavrač", "Stefan Wrobel" ],
      "venue" : null,
      "citeRegEx" : "Krogel et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Krogel et al\\.",
      "year" : 2003
    }, {
      "title" : "kFOIL: learning simple relational kernels",
      "author" : [ "N. Landwehr", "A. Passerini", "L. De Raedt", "P. Frasconi" ],
      "venue" : "Proceedings of the 21st national conference on Artificial intelligence,",
      "citeRegEx" : "Landwehr et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Landwehr et al\\.",
      "year" : 2006
    }, {
      "title" : "Integrating naive bayes and foil",
      "author" : [ "Niels Landwehr", "Kristian Kersting", "Luc De Raedt" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Landwehr et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Landwehr et al\\.",
      "year" : 2007
    }, {
      "title" : "Gradient-based learning applied to document recognition",
      "author" : [ "Yann LeCun", "Léon Bottou", "Yoshua Bengio", "Patrick Haffner" ],
      "venue" : null,
      "citeRegEx" : "LeCun et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "LeCun et al\\.",
      "year" : 1998
    }, {
      "title" : "Is mutagenesis still challenging",
      "author" : [ "Huma Lodhi", "Stephen Muggleton" ],
      "venue" : "ILP-Late-Breaking Papers,",
      "citeRegEx" : "Lodhi and Muggleton.,? \\Q2005\\E",
      "shortCiteRegEx" : "Lodhi and Muggleton.",
      "year" : 2005
    }, {
      "title" : "Graph kernels for chemical informatics",
      "author" : [ "Liva Ralaivola", "Sanjay J. Swamidass", "Hiroto Saigo", "Pierre Baldi" ],
      "venue" : "Neural Netw.,",
      "citeRegEx" : "Ralaivola et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Ralaivola et al\\.",
      "year" : 2005
    }, {
      "title" : "Multi instance neural networks",
      "author" : [ "J Ramon", "L De Raedt" ],
      "venue" : "In Proceedings of the ICML Workshop on Attribute-Value and Relational Learning,",
      "citeRegEx" : "Ramon and Raedt.,? \\Q2000\\E",
      "shortCiteRegEx" : "Ramon and Raedt.",
      "year" : 2000
    }, {
      "title" : "The graph neural network model",
      "author" : [ "Franco Scarselli", "Marco Gori", "Ah Chung Tsoi", "Markus Hagenbuchner", "Gabriele Monfardini" ],
      "venue" : "IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council,",
      "citeRegEx" : "Scarselli et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Scarselli et al\\.",
      "year" : 2009
    }, {
      "title" : "Refinement of approximate domain theories by knowledge-based neural networks",
      "author" : [ "Geofrey G Towell", "Jude W Shavlik", "Michiel O Noordewier" ],
      "venue" : "In Proceedings of the eighth National conference on Artificial intelligence,",
      "citeRegEx" : "Towell et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Towell et al\\.",
      "year" : 1990
    }, {
      "title" : "The semantics of predicate logic as a programming language",
      "author" : [ "Maarten H Van Emden", "Robert A Kowalski" ],
      "venue" : "Journal of the ACM (JACM),",
      "citeRegEx" : "Emden and Kowalski.,? \\Q1976\\E",
      "shortCiteRegEx" : "Emden and Kowalski.",
      "year" : 1976
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "Introduction Lifted models also known as templated models have attracted significant attention recently (Kimmig et al., 2015) in areas such as statistical relational learning.",
      "startOffset" : 104,
      "endOffset" : 125
    }, {
      "referenceID" : 24,
      "context" : "While there have been several works combining propositional or relational logic with neural networks (Towell et al., 1990; Botta et al., 1997; França et al., 2014), none of the existing methods is able to learn weights of latent non-ground relational structures1.",
      "startOffset" : 101,
      "endOffset" : 163
    }, {
      "referenceID" : 2,
      "context" : "While there have been several works combining propositional or relational logic with neural networks (Towell et al., 1990; Botta et al., 1997; França et al., 2014), none of the existing methods is able to learn weights of latent non-ground relational structures1.",
      "startOffset" : 101,
      "endOffset" : 163
    }, {
      "referenceID" : 8,
      "context" : "While there have been several works combining propositional or relational logic with neural networks (Towell et al., 1990; Botta et al., 1997; França et al., 2014), none of the existing methods is able to learn weights of latent non-ground relational structures1.",
      "startOffset" : 101,
      "endOffset" : 163
    }, {
      "referenceID" : 14,
      "context" : "Logical operators from various fuzzy logics (Klir and Yuan, 1995) may serve as an inspiration for selecting suitable activation functions.",
      "startOffset" : 44,
      "endOffset" : 65
    }, {
      "referenceID" : 16,
      "context" : "When the LRNN has just one layer, as in this example, one can achieve the same effect using techniques from propositionalization (Krogel et al., 2003) – treating the bodies of the rules as features and feeding them as attributes to a logistic regression classifier.",
      "startOffset" : 129,
      "endOffset" : 150
    }, {
      "referenceID" : 5,
      "context" : "in prediction of adverse effects of drugs where significant improvements in predictive accuracy were gained by methods which were able to create auxiliary clusters of similar drugs (Davis et al., 2012).",
      "startOffset" : 181,
      "endOffset" : 201
    }, {
      "referenceID" : 5,
      "context" : "Example 8 Let us suppose that, similarly to (Davis et al., 2012), we have temporal data about patients, drugs which the patients took and time instants when changes in health occurred.",
      "startOffset" : 44,
      "endOffset" : 64
    }, {
      "referenceID" : 15,
      "context" : "Exploiting the process of grounding of the lifted template, facilitating weight sharing in the ground networks, LRNNs can also emulate principal structures of convolutional neural networks (Krizhevsky et al., 2012) as the next example shows.",
      "startOffset" : 189,
      "endOffset" : 214
    }, {
      "referenceID" : 24,
      "context" : "While the KBANN (Towell et al., 1990) also constructs the network structure from given rules, these rules are propositional rather than relational and do not serve as a lifted template.",
      "startOffset" : 16,
      "endOffset" : 37
    }, {
      "referenceID" : 8,
      "context" : "A more recent system CILP++(França et al., 2014) utilizes a relational representation, which is however converted into a propositional form through a propositionalization technique (Krogel et al.",
      "startOffset" : 27,
      "endOffset" : 48
    }, {
      "referenceID" : 16,
      "context" : ", 2014) utilizes a relational representation, which is however converted into a propositional form through a propositionalization technique (Krogel et al., 2003).",
      "startOffset" : 140,
      "endOffset" : 161
    }, {
      "referenceID" : 2,
      "context" : "A somewhat more closely related paper on FONN (Botta et al., 1997) also designs a technique forming a network from relational rule set, however this rule set is flat, producing only 1-layer (shallow) networks in which relational patterns are not hierarchically aggregated.",
      "startOffset" : 46,
      "endOffset" : 66
    }, {
      "referenceID" : 0,
      "context" : "While there are many other approaches of neural-symbolic integration aiming at relational (and first-order) representations (Bader and Hitzler, 2005), e.",
      "startOffset" : 124,
      "endOffset" : 149
    }, {
      "referenceID" : 11,
      "context" : "based on the CORE method (Hölldobler et al., 1999), they typically search for a uniform model of the logic program in scope and thus principally differ from the presented lifted modeling approach.",
      "startOffset" : 25,
      "endOffset" : 50
    }, {
      "referenceID" : 1,
      "context" : "A similarly directed work (Blockeel and Uwents, 2004) facilitated aggregative reasoning to process sets of related tuples from relational database as a sequence through recurrent neural network structure, which was also presented for more general structures in (Scarselli et al.",
      "startOffset" : 26,
      "endOffset" : 53
    }, {
      "referenceID" : 23,
      "context" : "A similarly directed work (Blockeel and Uwents, 2004) facilitated aggregative reasoning to process sets of related tuples from relational database as a sequence through recurrent neural network structure, which was also presented for more general structures in (Scarselli et al., 2009).",
      "startOffset" : 261,
      "endOffset" : 285
    }, {
      "referenceID" : 10,
      "context" : "More loosely related works arise also in the neural networks community, where various recursive auto-encoders based on the idea of “reduced descriptions” (Hinton, 1990) are trained to encode structured data.",
      "startOffset" : 154,
      "endOffset" : 168
    }, {
      "referenceID" : 19,
      "context" : "Another line of work are convolutional neural networks (LeCun et al., 1998) and techniques of indirect encoding (Clune et al.",
      "startOffset" : 55,
      "endOffset" : 75
    }, {
      "referenceID" : 3,
      "context" : ", 1998) and techniques of indirect encoding (Clune et al., 2011), exploiting patterns and regularities in neural connections to create more compressed representations of large neural networks.",
      "startOffset" : 44,
      "endOffset" : 64
    }, {
      "referenceID" : 20,
      "context" : "Experiments In this section we describe experiments performed on 78 datasets of organic molecules: Mutagenesis dataset (Lodhi and Muggleton, 2005), four datasets from the predictive toxicollogy challenge and 73 NCI-GI datasets (Ralaivola et al.",
      "startOffset" : 119,
      "endOffset" : 146
    }, {
      "referenceID" : 21,
      "context" : "Experiments In this section we describe experiments performed on 78 datasets of organic molecules: Mutagenesis dataset (Lodhi and Muggleton, 2005), four datasets from the predictive toxicollogy challenge and 73 NCI-GI datasets (Ralaivola et al., 2005).",
      "startOffset" : 227,
      "endOffset" : 251
    }, {
      "referenceID" : 17,
      "context" : "We compare performance of LRNNs to state-of-the-art relational learners kFOIL (Landwehr et al., 2006) and nFOIL (Landwehr et al.",
      "startOffset" : 78,
      "endOffset" : 101
    }, {
      "referenceID" : 18,
      "context" : ", 2006) and nFOIL (Landwehr et al., 2007), where kFOIL combines relational rule learninng with support vector machines and nFOIL combines relational rule learning with naive Bayes learning.",
      "startOffset" : 18,
      "endOffset" : 41
    }, {
      "referenceID" : 8,
      "context" : "We also tried to compare LRNNs with another recent algorithm combining logic and neural networks, called CILP++ (França et al., 2014), but we didn’t find it to perform well on our relational datasets as we were not able to obtain, using CILP++, accuracy significantly higher than simple majority class error on any of the datasets8.",
      "startOffset" : 112,
      "endOffset" : 133
    }, {
      "referenceID" : 8,
      "context" : "While relatively reasonable results for Mutagenesis were reported in (França et al., 2014), the expertknowledge attributes were used in the experiments reported therein, which might explain the discrepancy between the results.",
      "startOffset" : 69,
      "endOffset" : 90
    } ],
    "year" : 2015,
    "abstractText" : "We propose a method combining relational-logic representations with neural network learning. A general lifted architecture, possibly reflecting some background domain knowledge, is described through relational rules which may be handcrafted or learned. The relational rule-set serves as a template for unfolding possibly deep neural networks whose structures also reflect the structures of given training or testing relational examples. Different networks corresponding to different examples share their weights, which co-evolve during training by stochastic gradient descent algorithm. The framework allows for hierarchical relational modeling constructs and learning of latent relational concepts through shared hidden layers weights corresponding to the rules. Discovery of notable relational concepts and experiments on 78 relational learning benchmarks demonstrate favorable performance of the method.",
    "creator" : "LaTeX with hyperref package"
  }
}