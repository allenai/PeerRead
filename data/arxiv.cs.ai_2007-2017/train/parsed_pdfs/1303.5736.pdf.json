{
  "name" : "1303.5736.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Management of Uncertainty in th� Mult�-L�vel . Monitoring and Diagnosis of the Time of Fhght Scmtillatwn Array",
    "authors" : [ "Robert K. Paasch" ],
    "emails" : [ "paasch@kepler.me.orst.edu", "aagogino@euler." ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 INTRODUCTION\nThe Time of Flight Scintillation Array is a sub-at?mic particle detector used at Lawrence Berkeley N atwnal Laboratory (LBL) for studies in relativistic he3:vy-ion physics. With operating costs for these expenmen�s exceeding $60 000 per hour, it is important that this detector oper�te correctly, and that any failures be identified and remediated as quickly as possible. But with approximately 5000 components, and over 500 output channels producing a Mbyte of data every 10 seconds the monitoring and diagnosis of this detector system \\s difficult for human operators to accomplish within the real time constraints.\nWhile the automation of the monitoring and diagnos tic process was desirable, the scale of the Time of Flight Scintillation Array combined with real time con straints and uncertain system relationships presented a particular challenge to automated monitoring and di agnosis. The scale of the detector requires the average time spent monitoring an individual output channel\n(or probe) and diagnosing an indivi?ual compo�ent be small in order to meet the real time constramts. The uncertain nature of the relationship between the output data and the component states indicates an ev idential reasoning approach, which may be contrary to the small average time requirement if applied to every component.\nWe present a general multi-level �r.ch!tecture. developed to efficiently and non-determimstJcally diagnose large scale sensor-based. systems _\nin real. time, and d� scribe the implementatiOn of this architecture to di agnose the Time of Flight Scin�illa.tion Array. The diagnostic system, the TOF Vah?atwn System, com bines a single monitoring level wit� two model-?ased diagnostic reasoning levels to prov1d.e both effiCiency and robustness in the face of uncertamty. The system consists of: 1) a statistical monitoring level using tradi tional chi-squared testing on data samples; 2) a model based reasoning level operating on Boolean channel states (OK and BAD) with a data base of connec tivity information to produce an ordered, reduced set of suspect components; and 3) a model-based reason ing level that extracts considerably more information from the data channels, and uses qualitative behav ioral system information operating on the reduced set of suspect components to produce an evidential map ping to individual component failure state beliefs. The system systematically extracts more information from a reduced set of channels to provide a more detailed diagnosis. The system was developed to be scalable to diagnose similar detector system� two orde.rs o! mag nitude more complex, and ongomg work IS directed toward extending the system for use on a Time Pro jection Chamber at LBL and for possible use on the Superconducting Supercollider.\nWe believe the TOF Validation System is unique among sensor-based diagnostic expert systems devel oped to date, first due to the scale and complexity �f the TOF Scintillation Array, second due to the multi level nature of it's diagnostic reasoning, and third in the consideration and management of uncertainty at all levels of reasoning. The general methodology\n258 Paasch and Agogino\nshould be applicable to a broad range of monitoring and diagnostic problems where at least a qualitative model of the system is known.\nIn the following sections we will discuss other related research, describe the TOF Scintillation Array, present the general diagnostic system architecture, then dis cuss the management of uncertainty at the individual levels. We also describe the implementation of the generalized architecture and methodologies to develop the TOF Validation System.\n2 BACKGROUND LITERATURE\nIn the development of an automated real-time sensor based multi-level monitoring and diagnostic system, a broad variety of research and implementation issues must be addressed and so there exists a wealth of prior research work that is relevant to this research. This work builds on that of Agogino (1988a, b) and Rege (1986) in the area of real time sensor-based diagnostic expert systems. Rege describes IDES (Influence Dia gram Expert System) and an application to a simple sensor-based pump diagnostic problem. Agogino de scribes the application ofiDES to the real time sensor based diagnosis of a milling machine and Ramamurthy (1990) to drilling applications.\nOur view of multi-level diagnostic knowledge is similar to that of Milne (1985, 1987), who states that the diag nostic knowledge can exist at one or more of four levels: compiled, functional, behavioral and structural . Al though compiled diagnostic knowledge systems often implicitly contain knowledge about structure and/or function, it is the explicit use of structural, behavioral or functional knowledge that delineates those diagnos tic knowledge systems. Milne states that \"the basic knowledge required for diagnosis is the set of malfunc tions and relations between the observations and mal functions\". A compiled knowledge diagnostic system is a system that has this knowledge explicitly given to it. A structural diagnostic system is a system that is explicitly given structural or connectivity information, and likewise functional and behavioral diagnostic sys tems are explicitly given functional or behavioral in formation. While Milne uses multiple levels to catego rize knowledge representation, we have explicitly used these same levels to describe a diagnostic architecture.\nChandrasekaran (1983), Davis (1983), Fink (1985a, b, 1987), and Searl (1987) all address compiled verses deep (structural, behavioral and functional) knowledge based diagnosis. The research by Fink is particularly relevant to this research in that she describes a system that combines knowledge from more than one level, although the application described in that research is several orders of magnitude simpler than the TOF Scintillation Array. Searl makes explicit use of both structure and function in the development of the di agnostic expert system for the space shuttle described\nin Searl (1985).\nWhen a diagnostic reasoning system depends on sen sor information, the problem of sensor validation must be addressed. Chandrasekaran (1988) addresses sen sor validation in compiled systems, and introduces a \"meta-level\" of compiled information that constitutes a level of redundancy based on expectations derived during diagnosis. Searl (1987) shows that with the use of knowledge of structure and function one is able to regard sensor validation as a subset of the more gen eral diagnostic process and therefore validate sensors the same as diagnosing any other component, an ob servation that we were able to confirm in this research.\n3 TIME OF FLIGHT\nSCINTILLATION ARRAY\nThe TOF Scintillation Array is part of the Heavy Ion Superconducting Spectrometer (HISS) experiments at Lawrence Berkeley Laboratory. The TOF Scintilla tion Array consists of 136 plastic scintillation slats, 272 photomultiplier tubes, and associated electron ics. As atomic particles produced by an experimental \"event\" pass through a particular slat, light photons are produced. The duration of an event is measured in nanoseconds, and the associated photons migrate to the ends of the slat and the produce electrical sig nals in the two photomultiplier tubes that are ampli fied 106 times. The signal is split and sent to both an Analog to Digital Converter (ADC) and a Time to Digital Converter (TDC). Digital outputs from the ADCs and TDCs are sent directly to magnetic tape, although sampling is possible. Because of the tremen dous amount of data produced by and the scale of the TOF Scintillation Array, it can be difficult to monitor and diagnose even for an expert in the Wall's oper ation. Proposed detector systems for the Supercon ducting Supercollider would be humanly impossible to monitor and diagnose without assistance.\n4 SYSTEM ARCHITEC TURE\nDifficulty in diagnosing large scale systems comes from a combination of both the complexity of the system and from the external constraints on the time al lowed for diagnosis. Diagnostic systems using com piled knowledge (such as heuristic, rule-based systems) are difficult to implement for large scale systems due to the difficulties in acquiring and implementing large numbers of rules, rule conflict resolution, and difficul ties in updating and appending the rule base. Also, as the number of rules increases, diagnostic time can increase. If the time to diagnose a failure is of little or no concern, then large, complex rule based systems may be a viable option, but this is not the case for this application.\nWhen a system model is available, model based diag nostic systems can provide increased flexibility in han dling system changes. But if the reasoning strategies applied to the entire system are too complex, model based diagnostic systems may also require too much time when diagnosing large scale systems.\nThe generalizable architecture we propose for large scale sensor-based systems closely mimics the meth ods by which an expert might diagnose a problem: first a quick look at all the probe outputs to get a gen eral idea of what components might have failed, then a more detailed look at specific probes to determine the exact component and the specific failure type. This architecture consist of four main functional modules as shown in Figure 1.\nA monitoring module would sample the probe (sensor) outputs, comparing these outputs to historical values. 'When the monitoring module detects an abnormal ity, the structural reasoning module is alerted. Us ing a connectivity model of the system and the probe output comparisons from the statistical analyzer, the structural reasoning module performs a \"rough cut\" diagnosis that produces a short list of suspect com ponents. This short list is sent to the behavioral rea soning module. Using the short list of suspect compo-\nManagement of Uncertainty 259\nnents, this module retrieves the original probe outputs of all probes related to these components from the sta tistical analyzer, and using a functional model of the system produces a list of specific failure types for spe cific suspect components, ordered by degree of belief. A compiled reasoning model provides assistance in in terpretation and repair.\nPossible applications of this architecture include sen sor validation in process control, fault location in com plex electomechanical systems and control of food or chemical proccessing. We have applied this architec ture to the monitoring and diagnosis of the Time of Flight Scintillation Array. In this implementation of the architecture, a data acquisition and signal process ing unit compiles averages for ADC and TDC values for 1000 events, and a statistical analyzer compares these averages to archived values from the expected value generator with a chi-squared test. Probes that fail the test are flagged as \"BAD\", and the structural reasoning module started. This module assumes struc tural dependencies among the components based on connectivity (structure).\nThe term \" structural dependency\" in this context means that the effective state of a component is de pendent on a preceding component. This dependency could occur when a component provides a data output that is the data input to a succeeding component, or if a component cannot operate if the preceding compo nent has failed (such as when the preceding component supplies power to the succeeding component).\nFrom the list of \" BAD\" probes from the statistical an alyzer, and connectivity knowledge stored in the con nectivity model, the structural diagnoser produces a short list of suspect components. The behavioral di agnosis module is then started with the list of suspect components. For each suspect component, this mod ule solicits additional information from the statistical analyzer about trending of data from select groups of probes affected by the components under considera tion, and compares those trends to expected trend ing (from the behavioral model) for individual failure types for the specific class of component using eviden tial algorithms. The final list of suspect components, with the types of failure, is presently sent directly to an output display. The compiled reasoning module has not been implemented.\n5 MANAGEMENT OF\nUNCERTAINTY AT THE\nMONIT ORING LEVEL\nThe monitoring module addresses the question of whether the Time of Flight Scintillation Array is func tioning correctly or not. Uncertainty exists at this level due to the highly stochastic nature of particle physics experiments.\n260 Paasch and Agogino\nIn this case the monitoring process is abetted by the tremendous amount of data produced by the exper iment. Samples of statistically significant size (typi cally 1000 events) can be collected rapidly. These sam ples are compared to expected norms (10 samples of 1000 events collected with the system assumed to be functioning correctly) using standard chi-square test ing. These tests establish whether an individual data probe is OK or BAD. Statistical analysis validated the suitability of the chi-square test for determining the state of a probe (Paasch 1990).\n6 MANAGEMENT OF\nUNCERTAINTY AT THE\nSTRUC TURAL REASONING\nLEVEL\nThe structural reasoning module has the responsibil ity for reducing the set of suspect components from a set of all components in the system to a set that can be efficiently diagnosed by the behavioral reasoning module within the real time constraints. The largest reduction in the suspect set occurs in this module. In the TOF Validation System, this module reduces the suspect component set from 5000 components to ap proximately 10. Detailed information on this module is included in Hall (1989).\nThe structural reasoning module assumes two possible component states (OK and BAD), and two possible observations per observation probe (OK and BAD). We justify this simplification of component states on the basis of highest common denominator. All compo nents can use OK and BAD, while failure type may be component specific. Also, in the structural reasoning module a rough diagnosis is acceptable, and the lump ing of components into either OK or BAD is sufficient. As for the observations per probe, OK or BAD may be all the information available from some extracted features such as the chi-square test used by the moni toring module.\nUncertainty in the probe state is addressed at the mon itoring level by statistical methods. Uncertainty in the component state is addressed to some degree at this level, and again at the behavioral reasoning level. At this level we deterministically assume that if a compo nent has all dependent probes in state OK then that component is in state OK and is removed as a sus pect. This assumption is justified by the statistical significance of the sample size used in the monitoring module.\nIf a component has one or more dependent probes in state BAD, then that component can be included as a suspect. Uncertainty about the individual states of the components on the reduced suspect list can be han dled by ranking the suspect components by the BAD probe to total probe ratio: a component with four\nprobes dependent upon it and three of those probes assumed BAD would rank ahead of a component with eight dependent probes of which four are BAD .. Mul tiple component failures would increase the size of the suspect list. The possibility of multiple failures would decrease with the time to collect a sample.\nIf two or more suspect components have identical sig natures (affect the same probes) we cannot discrimi nate between component failures, an ambiguity would exist, and thus would present a failure class. For the TO F Scintillation Array the worst case is three am biguous states (i.e. single components failures). Com piled information in the form of prior probabilities can handle this ambiguity, or a secondary diagnosis (de tailed in the next section) can be performed.\n7 MANAGEMENT OF\nUNCERTAINTY AT THE\nBEHAVIORAL REASONING\nLEVEL\nAlthough the structural reasoning module efficiently produces a limited set of suspect components and can order that list, a more detailed diagnosis may be de sired. The structural reasoning module is sensitive to the breakpoint value between BAD and OK channels, in the best of circumstances it may produce a sus pect component list with some ambiguity, and it pro vides no information the specific type of component failure. The behavioral reasoning module was incor porated into the general architecture to address these problems. This module by itself would be adequate for the diagnosis of small scale systems, but is too compu tationally inefficient to operate on a large set of suspect components in real time.\nWith the apparent complexity of the system greatly reduced, the behavior module can operate in numer ous ways. The behavioral reasoning architecture we present incorporates a behavioral model to produce expected observation values for the different failure types, a methodology to compare expected values to actual values, and a methodology to relate that com parison to the system states. In the TOF Validation System, the later two methodologies are implemented in the behavioral diagnoser.\nThe behavioral model can exist on many different lev els. The compilation of historical data, keeping track of failures by type, would result in a compiled behav ioral model relating system state directly to observ ables. At this level the knowledge would be consid ered shallow: compiled knowledge of system operation as a whole, with little or no knowledge of deeper sys tem operation. At the other extreme would be the deep analytical model: every component in the sys tem, and every relationship between components is modeled analytically, with a resultant complex math-\nematical equation for the system rigorously relating system state to observables. Between these two ex tremes there are a number of possibilities, including qualitative models, data models based on experiential, first principle, compiled knowledge, and hybrid mod els.\nNumerical comparison methodologies such as chi square or Z distribution can work for numerical obser vations, and Boolean sensor outputs can be compared directly with expected outputs on a match/no-match basis, with the result mapped directly to increase or decrease a belief.\nRelational methodologies would generally involve some sort of mapping from comparison value to evidential value. This mapping could be as simple as a table look up, or could involve qualitative or quantitative relational algorithms.\nOne possible feature of a behavioral reasoning mod ule, implemented in the TOF Validation System, is the continuous mapping made between data values and hypothesis belief. The structural reasoning module as sumes that belief is discrete, as this is a Boolean map ping. For example, if probability were used, p(t = BADly < limit) = 0 and p(t = BADly> limit) = 1, where t is a probe state, y is the probe data value, and \"limit\" is the established breakpoint between OK and BAD. But the argument can be made that the uncertainty mapping in this and other cases is contin uous. Intuitively, p(t = BADly) might increase as y increases. More importantly, we can relate the individ ual component failure states, si, to the probe values. For each evidence type for each hypothesis, an algo rithm could be found that relates p(sily) to the value of y. A plot of such an algorithm is shown in Figure 2. In this case the likelihood of the hypothesis, H, increases as the value of the feature, x, increases, but the like lihood might also decrease with an increasing feature value, or it might increase with any feature change, or be related in other ways. The tradeoff to using a continuous evidential approach may be computational complexity and the inability to invert.\nEvidential methodologies are used to combine the evi dence produced by the relational algorithms, and could be based on Bayesian probabilities, Certainty Factors and Dempster-Shafer, at the preference of the expert or system developers. Each individual observation contributes an individual belief or likelihood for each system state hypothesis, these are then combined to give a final belief or likelihood for each system state hypothesis. The final belief or likelihood for each sys tem state could then be used on either an absolute or relative basis.\nThe behavioral reasoning module as implemented in the TOF Validation System uses numerical, relational and evidential sub-levels. A qualitative behavioral model is based on the experts first principle and expe-\nriential knowledge of the TOF Scintillation Array. To compare current with expected data features a sim ple Z distribution comparison ( z= (x - xavg)/sx ) is used. The behavioral diagnoser then uses four continu ous quantitative relational algorithms, one for each ex pected direction of data trending (increasing, decreas ing, either direction, and no change) to relate t?e data to evidential belief. These algorithms are modified for individual component failure state/ data feature rela tionships by parameters to reflect the desired eviden tial weighting, slope and cutoff value as determined by the expert. The algorithms can be made to behave in a nearly discrete manner when appropriate. At the preference of the expert, the present implementation uses certainty factors as an evidential methodology. The conversion to Bayesian probabilities is straight forward with the addition of the assessment of prior probabilities (Beckerman 1986).\n8 IMPLEMENTATION\nThe architecture was implemented by the development and testing of individual modules that were then com bined to form the TOF validation System. The data acquisition and signal processing unit was coded in a combination of FORTRAN and C. All other modules were coded in C. The system runs on the HISS experi ment's VAX computers operating under VMS. A more detailed description of the implementation and use of the validation system may be found in Hall (1989), Olson (1990), and Paasch (1988, 1990).\n9 SUMMARY\nThis paper presents a multi-level diagnostic architec ture particularly well suited for the diagnosis of large scale systems with real time constraints. While the\n262 Paasch and Agogino\nidea of multi-level diagnosis is not new, we believe this system is unique in that the inherent complexity and scale of the application required that multiple levels be used in this case to achieve the requisite efficiency while maintaining diagnostic detail and the ability to manage uncertainty.\nIn implementing a multi-level diagnostic system, we have found that the individual diagnostic levels have strengths and weaknesses that are complementary and generalizable. Structural reasoning systems can be fairly robust, and can be designed in a generic manner so that changes in the structure of the components are reflected as changes in a mapping database. Due to the inherent ambiguity, structural reasoning appears to best lend itself to a rough, first pass, preliminary diagnosis. Uncertainty at this level exists as ambigu ity between system states and as uncertainty in the probe feature value to symbolic value mapping.\nBehavioral reasoning systems, especially analytic sys tems derived from first and second engineering prin ciples and incorporating structural knowledge, can be very robust. The construction of a reasoning system from behavioral knowledge can be difficult, however, due to incomplete information on the operation of a complex system and the difficulty in rigorously map ping from evidence to belief. Uncertainty exists in this mapping, and in the accuracy of the system model. Behavioral reasoning systems might need to incorpo rated various levels of compiled behavioral informa tion, making the design of a general framework more difficult.\nWe do not feel that compiled systems by themselves are appropriate for the diagnosis of real time large scale systems because of complexity and inflexibility. How ever, compiled reasoning levels have been considered for this application to interpret the output from the behavioral reasoning module and to guide the repair process.\nAs the application of diagnostic reasoning systems to more complex systems becomes possible, it becomes apparent that these reasoning systems will incorpo rate a preprocessing level combined with multiple lev els of diagnostic reasoning: structural, behavioral, and compiled. Each level has specific strengths and weak nesses, and in this research a combination has proven to provide the most intelligent, efficient, flexible, and robust system for diagnosing large scale real-time sys tems like the TOF Scintillation Array and proposed detectors for the Superconducting Supercollider.\nAcknowledgements\nThe authors would like to thank Dennis Hall, Bill Greiman and Doug Olson from Lawrence Berkeley Na tional Laboratory for their guidance and consultation throughout this research. The authors greatly appre ciate the support of the Director, Office of Energy\nResearch, Scientific Computing Staff, of the United States Department of Energy, under Contract Num ber DE-AC03-76SF00098, and by the National Science Foundation, under grant DMC-8451622.\nReferences\nAgogino, A. M., S. Srinivas and K. M. Schneider (1988a),\"Multiple Sensor Expert System for Diagnos tic Reasoning, Monitoring and Control of Mechanical Systems,\" Mechanical Systems and Signal Processing, Volume 20, Number 2, pages 165 to 185.\nAgogino, A. M., R. Guha and S. Russell (1988b), \"Sen sor Fusion Using Influence Diagrams and Reasoning by Analogy: Application to Milling Machine Monitoring and Control,\" AIENG88- Third International Confer ence on Applications of Artificial Intelligence in Engi neering, August 8 - 11, 1988, Stanford CA.\nChandrasekaran, B. and W. F. Punch (1988), \"Data Validation During Diagnosis, A Step Beyond Tradi tional Sensor Validation,\" Proceedings of the Sev enth National Conference on Artificial Intelligence, St. Paul, MN, August 1988, pages 778 - 782.\nChandrasekaran, B. and S. Mittal (1983), \"Deep Verses Compiled Knowledge Approaches to Diagnostic Problem Solving,\" International Journal of Man Ma chine Studies, Volume 19, Number 5, pages 425 - 436.\nDavis, R. (1983), \"Reasoning from First Principles in Electronic Troubleshooting,\" International Journal of Man Machine Studies, Volume 19, Number 5, pages 403 - 423.\nDavis, R., et a! (1982), \"Diagnosis Based on Descrip tion of Structure and Function,\" Proceedings of the First National Conference on Artificial Intelligence, Pittsburgh, PA, July 1982, pages 137 - 142.\nFink, P. K. and J. C. Lusth (1987), \" Expert Systems and Diagnostic Expertise in the Mechanical and Elec trical Domains,\" IEEE Transactions on Systems, Man, and Cybernetics, Volume 17, Number 3, pages 340- 349.\nFink, P. K., J. C. Lusth and J. W. Duran (1985a), \"A General Expert System Design for Diagnostic Problem Solving,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, Volume 7, Number 5, pages 553 - 560.\nFink, P. K. (1985b), \" Control and Integration of Di verse Knowledge in a Diagnostic Expert System,\" Pro ceedings of the Ninth International Joint Conference on Artificial Intelligence, Los Angeles, CA, August 1985, pages 426 - 431.\nHall, D., et a! (1989), \" A Fault Location System for a Time of Flight Detector Array,\" Computer Physics Communications, Volume 57, pages 499- 502.\nHeckerman, D. E.(1986),\" Probabilistic Interpretations for MYCIN's Certainty Factors,\" Uncertainty in Arti ficial Intelligence, Lemmer, J. and Kana!, L., Editors, North Holland, 1986, pages 9 - 20.\nMilne, R. (1987), \"Strategies for Diagnosis,\" IEEE Transactions on Systems, Man, and Cybernetics, Vol ume 17, Number 3, pages 337 - 339.\nMilne, R. (1985), \"Fault Diagnosis Through Respon sibility,\" Proceedings of the Ninth International Joint Conference on Artificial Intelligence, Los Angeles, CA, August 1985, pages 423 - 425.\nOlson, D., et a! (1990), \"Experience Using an Auto mated Fault Location System with a Time of Flight Wall Detector Array,\" Proceeding of the International Conference on Computing in High Energy Physics, Santa Fe, New Mexico, 1990.\nPaasch, R. K., and A. Padgaonkar (1988), \"Time of Flight Validation System,\" Preliminary Report, Lawrence Berkeley Laboratory, Berkeley, CA, Septem ber 30, 1988.\nPaasch, R. K. (1990), \"Management of Uncertainty in Sensor Based Diagnostic Expert Systems,\" Ph.D. Dissertation, Department of Mechanical Engineering, University of California, Berkeley, February 1990.\nRamamurthy, K., D. Shaver and A. M. Agogino (1990), \"Real Time Expert System for Predictive Di agnostics and Control of Drilling Operations,\" Pro ceedings of the Sixth IEEE Conference on AI Applica tions, Santa Barbara, CA, March 5-9, 1990, Volume 1 pages 63 - 68 and Volume 2 (visuals) pages 113 - 117.\nRege, A. and A. M. Agogino (1986), \"Sensor Inte grated Expert System for Manufacturing and Process Diagnostics,\" Knowledge Based Systems for Manufac turing, S. C.-Y Lu and R. Komanduri, Editors, ASME, PED, Volume 34, pages 67 - 83.\nSearl, E. A., J. R. Jamieson and C. I. Delaune (1987), \"Diagnosis and Sensor Validation Through Knowledge of Structure and Function,\" IEEE Transactions Sys tems, Man, and Cybernetics, Volume 17, Number 3, pages 360 - 368.\nSearl, E. A., J. R. Jamieson and C. I. Delaune (1985), \"A Fault Detection and Isolation Method Applied to Liquid Oxygen Loading for the Space Shuttle,\" Pro ceedings of the Ninth International Joint Conference on Artificial Intelligence, Los Angeles, CA, August 1985, pages 414 - 416.\nManagement of Uncertainty 263"
    } ],
    "references" : [ {
      "title" : "Sen­ sor Fusion Using Influence Diagrams and Reasoning by Analogy: Application to Milling Machine Monitoring and Control,\" AIENG88",
      "author" : [ "A.M. Agogino", "R. Guha", "S. Russell" ],
      "venue" : "Third International Confer­ ence on Applications of Artificial Intelligence in Engi­",
      "citeRegEx" : "Agogino et al\\.,? \\Q1988\\E",
      "shortCiteRegEx" : "Agogino et al\\.",
      "year" : 1988
    }, {
      "title" : "Deep Verses Compiled Knowledge Approaches to Diagnostic Problem Solving,",
      "author" : [ "MN Paul" ],
      "venue" : "International Journal of Man Ma­ chine Studies, Volume 19, Number",
      "citeRegEx" : "Paul,? \\Q1988\\E",
      "shortCiteRegEx" : "Paul",
      "year" : 1988
    }, {
      "title" : "Reasoning from First Principles in Electronic Troubleshooting,\" International Journal of Man Machine Studies",
      "author" : [ "R. Davis" ],
      "venue" : "Volume 19, Number",
      "citeRegEx" : "Davis,? \\Q1983\\E",
      "shortCiteRegEx" : "Davis",
      "year" : 1983
    }, {
      "title" : "1985b), \" Control and Integration of Di­ verse Knowledge in a Diagnostic Expert System,\" Pro­",
      "author" : [ "P.K. Fink" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "Fink,? \\Q1985\\E",
      "shortCiteRegEx" : "Fink",
      "year" : 1985
    }, {
      "title" : " A Fault Location System for a Time of Flight Detector Array,",
      "author" : [ "CA Angeles" ],
      "venue" : "Computer Physics Communications,",
      "citeRegEx" : "Angeles,? \\Q1985\\E",
      "shortCiteRegEx" : "Angeles",
      "year" : 1985
    }, {
      "title" : "Probabilistic Interpretations for MYCIN's Certainty Factors,\" Uncertainty in Arti­",
      "author" : [ "D. Heckerman" ],
      "venue" : null,
      "citeRegEx" : "Heckerman,? \\Q1986\\E",
      "shortCiteRegEx" : "Heckerman",
      "year" : 1986
    }, {
      "title" : "Fault Diagnosis Through Respon­ sibility,",
      "author" : [ "R. Milne" ],
      "venue" : "Transactions on Systems, Man, and Cybernetics, Vol­ ume 17,",
      "citeRegEx" : "Milne,? \\Q1985\\E",
      "shortCiteRegEx" : "Milne",
      "year" : 1985
    }, {
      "title" : "Experience Using an Auto­ mated Fault Location System with a Time of Flight Wall Detector Array,",
      "author" : [ "D. Olson" ],
      "venue" : "Proceeding of the International Conference on Computing in High Energy Physics,",
      "citeRegEx" : "Olson,? \\Q1985\\E",
      "shortCiteRegEx" : "Olson",
      "year" : 1985
    }, {
      "title" : "Management of Uncertainty in Sensor Based Diagnostic Expert Systems,\" Ph.D. Dissertation, Department of Mechanical Engineering, University of California, Berkeley",
      "author" : [ "R.K. Paasch" ],
      "venue" : null,
      "citeRegEx" : "Paasch,? \\Q1990\\E",
      "shortCiteRegEx" : "Paasch",
      "year" : 1990
    }, {
      "title" : "Sensor Inte­ grated Expert System for Manufacturing and Process Diagnostics,\" Knowledge Based Systems for Manufac­",
      "author" : [ "A. Rege", "A.M. Agogino" ],
      "venue" : null,
      "citeRegEx" : "Rege and Agogino,? \\Q1986\\E",
      "shortCiteRegEx" : "Rege and Agogino",
      "year" : 1986
    }, {
      "title" : "Diagnosis and Sensor Validation Through Knowledge of Structure and Function,",
      "author" : [ "E.A. Searl", "J.R. Jamieson", "C.I. Delaune" ],
      "venue" : "IEEE Transactions Sys­ tems, Man, and Cybernetics, Volume 17,",
      "citeRegEx" : "Searl et al\\.,? \\Q1987\\E",
      "shortCiteRegEx" : "Searl et al\\.",
      "year" : 1987
    }, {
      "title" : "A Fault Detection and Isolation Method Applied to Liquid Oxygen Loading for the Space Shuttle,",
      "author" : [ "E.A. Searl", "J.R. Jamieson", "C.I. Delaune" ],
      "venue" : "Pro­ ceedings of the Ninth International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Searl et al\\.,? \\Q1985\\E",
      "shortCiteRegEx" : "Searl et al\\.",
      "year" : 1985
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Chandrasekaran (1983), Davis (1983), Fink (1985a, b, 1987), and Searl (1987) all address compiled verses deep (structural, behavioral and functional) knowledge based diagnosis.",
      "startOffset" : 23,
      "endOffset" : 36
    }, {
      "referenceID" : 2,
      "context" : "Chandrasekaran (1983), Davis (1983), Fink (1985a, b, 1987), and Searl (1987) all address compiled verses deep (structural, behavioral and functional) knowledge based diagnosis.",
      "startOffset" : 23,
      "endOffset" : 77
    }, {
      "referenceID" : 8,
      "context" : "Statistical analysis validated the suitability of the chi-square test for determining the state of a probe (Paasch 1990).",
      "startOffset" : 107,
      "endOffset" : 120
    }, {
      "referenceID" : 7,
      "context" : "A more detailed description of the implementation and use of the validation system may be found in Hall (1989), Olson (1990), and Paasch (1988, 1990).",
      "startOffset" : 112,
      "endOffset" : 125
    } ],
    "year" : 2011,
    "abstractText" : "We present a general architecture for the monitoring and diagnosis of large scale sensor-based systems with real time diagnos­ tic constraints. This architecture is multi­ leveled, combining a single monitoring level based on statistical methods with two model­ based diagnostic levels. At each level, sources of uncertainty are identified, and integrated methodologies for uncertainty management are developed. The general architecture was applied to the monitoring and diagnosis of a specific nuclear physics detector at Lawrence Berkeley National Laboratory that contained approximately 5000 components and pro­ duced over 500 channels of output data. The general architecture is scalable, and work is ongoing to apply it to detector systems one and two orders of magnitude more complex.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}