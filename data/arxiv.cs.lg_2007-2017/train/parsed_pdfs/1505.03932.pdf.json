{
  "name" : "1505.03932.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Using Ensemble Models in the Histological Examination of Tissue Abnormalities",
    "authors" : [ "Giancarlo Crocetti", "Michael Coakley", "Phil Dressner", "Wanda Kellum" ],
    "emails" : [ "wk59882w}@pace.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "abnormalities on histological samples do exists, with an active debate on the cost associated with false negative diagnosis (underdiagnosis) and false positive diagnosis (overdiagnosis). Current models tend to underdiagnose, failing to recognize a potentially fatal disease.\nThe objective of this study is to investigate the possibility of automatically identifying abnormalities in tissue samples through the use of an ensemble model on data generated by histological examination and to minimize the number of false negative cases.\nKeywords—Histology, data mining, CART, logistic regression,\nensemble model, classification, breast cancer\nI. INTRODUCTION\nBreast cancer screening is conducted to detect cancerous cells before a person has symptoms. As part of a breast cancer prevention screening, if a lump is found, a fine-needle aspiration biopsy (FNAB) is performed, a technique which has been used widely in the evaluation of non-palpable breast lesions [1].\nTypically, biopsy tissue samples from breast cancer are examined visually by a pathologist, who is looking for cancerous tissues with abnormal characteristics. However, the manual detection and quantification of such abnormality is still a tedious and laborious task. Today, automated image analysis systems can evaluate cytology features derived directly from a digital scan of breast FNAB slides [2].\nAccuracy levels from manual analysis of samples has wide levels of accuracy ranging from 62.2% to 89.2% [1], while automatic methods based on three-factor Cox multivariate analysis [3] and clustering solutions [4] achieved much higher and consistent results with accuracies levels reaching 98%. Although such results are a definite improvement over manual diagnostic procedures, they still contain 2% of false negatives representing a failure of recognizing the associated sample as malignant, which can carry disastrous consequences.\nIn this study we are evaluating the performance of a model based on Classification and Regression Trees (CART) and Logistic Regression for the detection of malignancy in breast cancer tissues using an ensemble approach with the objective of reducing or eliminating the number of false negatives.\nII. THE DATA\nIn this study we utilized the Wisconsin Breast Cancer Dataset downloaded from the UC-Irvine machine learning archive [5] which contains 569 samples classified either as benign or malignant.\nEach record consists of the following 12 attributes, containing tissue identification and outcome (attributes 1-2) and cellular characteristics (attributes 3-12):\n1. Id 2. Diagnosis 3. Radius (mean of distances from center to points on the\nperimeter) 4. Texture (standard deviation of gray-scale values) 5. Perimeter 6. Area 7. Smoothness (local variation in radius lengths) 8. Compactness (perimeter2 / area - 1.0) 9. Concavity (severity of concave portions of the contour) 10. Concave points (number of concave portions of the contour) 11. Symmetry 12. Fractal dimension (fdimension) (\"coastline approximation\"\n- 1)\nThe class to predict is “Diagnosis” and all attributes, with the exception of Id, will be considered as inputs. The attribute “Id” is excluded since it is used as a record ID and, therefore, completely unrelated to the experiment.\nOut of the 569 records we generated:\na) A training set contains examination from 448 patients. b) A test set contains examination from 121 patients.\nIII. EXPLORATORY DATA ANALYSIS"
    }, {
      "heading" : "A. Outlier Detection",
      "text" : "All the histological data is of good quality with the absence of missing values or outliers. For the detection of outliers we employed a Z-Score model which required the calculation of the following quantities:\n\uD835\uDC65∗ = \uD835\uDC65 − \uD835\uDF07\uD835\uDC65\n\uD835\uDF0E\uD835\uDC65\nWith this method we did identify few observations that fell outside the traditional [-4,+4] interval and, therefore, flagged as potential outliers [6], but after a careful review we decided to consider these values as valid, even though they were outside of the range."
    }, {
      "heading" : "B. Normality Assumption",
      "text" : "Before proceeding with the modeling phase, we checked whether or not the variables satisfied the normality assumption, and indeed this was the case for all variables as shown in figure 1.\nIn order to further guarantee the quality of the data we calculated the Skewness and Kurtosis (i.e., peakness) measures for each variable and verified they were within the interval [- 2/+2] considered the acceptable range for such statistics.\nAs reflected in their skewness levels, the variables displayed acceptable levels of symmetric; however, in terms of Kurtosis we had two variables that exceeded such range: area and fdimension, due to their long tails; a minor issue which was resolved with data normalization."
    }, {
      "heading" : "C. Data Normalization",
      "text" : "Due to the large variations in the variables’ range, we decided to normalize the data by applying a min-max transformation:\n\uD835\uDC65∗ = \uD835\uDC65 − \uD835\uDC5A\uD835\uDC56\uD835\uDC5B\uD835\uDC65\n\uD835\uDC5A\uD835\uDC4E\uD835\uDC65\uD835\uDC65 − \uD835\uDC5A\uD835\uDC56\uD835\uDC5B\uD835\uDC65\nThis transformation brought all the variables within the interval [0,1], guaranteeing that none of the variable will have higher influence due to their larger values [6]."
    }, {
      "heading" : "D. Correlation Analysis",
      "text" : "When calculating the Pearson correlation among the\nattributes, we found some strong correlation as shown in table 1.\nmedium-high correlation with radius (0.687), it was strongly correlated with the other variables. Consequently, we decided to retain radius_mean_transformed and drop the other attributes.\nIV. CLUSTERING\nWith the use of the K-means clustering algorithm, we derived a new cluster attribute which divided the data in two cluster solution as shown in figure 2.\npercentage of normal samples, an indication that this attribute might have some predictive power.\nWhen considering which attribute played a more\nimportant role in generating this cluster solution we can see, from figure 3, that compactness, smoothness and symmetry played an important role which was also confirmed by comparing their cell distribution between clusters as shown in figure 4.\nFIGURE 3. ATTRIBUTE IMPORTANCE\nFIGURE 4. CELL DISTRIBUTION FOR COMPACTNESS, SMOOTHNESS, AND SYMMETRY\nV. MODELLING\nBecause of the continuous nature of attributes and the binary type of the targeted class, we decided to utilize the\nfollowing models:\nCART – Decision Tree Logistic Regression\nEach model performed quite well as we can see from the\nconfusion matrixes in table 2 and the error rates in table 3\nCART, even though we also have 2 false negative in Logistic Regression which is more costly than any other misclassification type (failure in detecting a cancerous sample).\nFor the CART model is interested to take a look at the\nsimple rules this model generated as in the following:\nAs we can see both radius and compactness play a very\nimportant role in the detection of abnormal tissues, even though, as mentioned earlier, the number of false positive is quite large.\nIn order to improve these results we thought of adopting an\nensemble strategy by leveraging the confidence interval measures produced by these models.\nEnsemble models have been considered an important\ndevelopment in Data Mining [7] and proven to improve model accuracy that is “easier and more powerful than judicious algorithm selection” [8].\nIn this particular we applied a voting scheme in which the\nprediction with the highest confidence wins.\nWhen this ensemble model is put at work we were able to\nsubstantially improve the result as shown in table 4.\nNot only did we reduce considerably the total number of misclassifications, but we also improved the overall error rate associated to the predictive model, in fact:\n\uD835\uDC42\uD835\uDC63\uD835\uDC52\uD835\uDC5F\uD835\uDC4E\uD835\uDC59\uD835\uDC59 \uD835\uDC52\uD835\uDC5F\uD835\uDC5F\uD835\uDC5C\uD835\uDC5F \uD835\uDC5F\uD835\uDC4E\uD835\uDC61\uD835\uDC52 = 4 + 1\n121 = 0.04 = 4%\n\uD835\uDC39\uD835\uDC4E\uD835\uDC59\uD835\uDC60\uD835\uDC52 \uD835\uDC5B\uD835\uDC52\uD835\uDC54\uD835\uDC4E\uD835\uDC61\uD835\uDC56\uD835\uDC63\uD835\uDC52 \uD835\uDC5F\uD835\uDC4E\uD835\uDC61\uD835\uDC52 = 1\n77 = 0.01 = 1%\n\uD835\uDC39\uD835\uDC4E\uD835\uDC59\uD835\uDC60\uD835\uDC52 \uD835\uDC5D\uD835\uDC5C\uD835\uDC60\uD835\uDC56\uD835\uDC61\uD835\uDC56\uD835\uDC63\uD835\uDC52 \uD835\uDC5F\uD835\uDC4E\uD835\uDC61\uD835\uDC52 = 4\n44 = 0.9 = 9%\nThese are quite good numbers even with a false positive\nrate close to 10%, representing cases that need to be reviewed in order to confirm the diagnosis.\nVI. CONCLUSIONS\nThe automatic classification of abnormal tissue samples is\nof paramount importance in helping physicians and other medical personnel in the diagnosis process.\nThe voting-based ensemble model derived through the\ncombination of decision trees and logistic regression proved to be a very efficient way of helping in improving the detection of abnormal biopsy samples.\nThe very low false negative rate of 1% is a clear indication\nthat this problem can be solved by the generation of high quality classification solutions, representing an improvement when compared to other classification systems developed in the past.\nREFERENCES\n[1] E. D. Pisano, L. L. Fajardo, D. J. Caudry, N. Sneige, W. J. Frable, W. A.\nBerg, I. Tocino, S. J. Schnitt, J. L. Connolly, C. A. Gatsonis, and B. J. McNeil, Fine-Needle Aspiration Biopsy of Nonpalpable Breast Lesions in a Multicenter Clinical Trial, Radiology, 2001, Vol. 219, Issue 3, pp. 785-792\n[2] W. H. Wolberg, W. N. Street, O. L. Mangasarian, Breast Cytology Diagnosis Via Digital Image Analysis, Dept. of Surgery, Universit of Wisconsin, 1993\n[3] W. Wolberg, W.N. Street, O.L. Mangasarian, Importance of nuclear morphology in breast cancer prognosis, Clinical Cancer Research, (1999) Vol. 5, 3542-3548\n[4] B. Lantz, “Machine Learning with R”, Packt Publishing, 2013\n[5] UCI-Machine Learning Repository, http://archive.ics.uci.edu/ml/\n[6] D. Larose, Discovering Knowledge in Data, Wiley, 2005.\n[7] G. Seni and J. F. Elder, Ensemble Methods in Data Mining, Morgan & Claypool Publishers, 2009.\n[8] J. F. Elder and S. S. Lee, Bundling Heterogeneous Classifiers with Advisor Perceptrons, University of Idaho, Technical Report, Oct. 1997."
    } ],
    "references" : [ {
      "title" : "Fine-Needle Aspiration Biopsy of Nonpalpable Breast Lesions in a Multicenter Clinical Trial",
      "author" : [ "E.D. Pisano", "L.L. Fajardo", "D.J. Caudry", "N. Sneige", "W.J. Frable", "W.A. Berg", "I. Tocino", "S.J. Schnitt", "J.L. Connolly", "C.A. Gatsonis", "B.J. McNeil" ],
      "venue" : "Radiology",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Breast Cytology Diagnosis Via Digital Image Analysis, Dept. of Surgery",
      "author" : [ "W.H. Wolberg", "W.N. Street", "O.L. Mangasarian" ],
      "venue" : "Universit of Wisconsin,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1993
    }, {
      "title" : "Importance of nuclear morphology in breast cancer prognosis",
      "author" : [ "W. Wolberg", "W.N. Street", "O.L. Mangasarian" ],
      "venue" : "Clinical Cancer Research, ",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Machine Learning with R",
      "author" : [ "B. Lantz" ],
      "venue" : "Packt Publishing,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "Discovering Knowledge in Data",
      "author" : [ "D. Larose" ],
      "venue" : "Wiley",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Ensemble Methods in Data Mining",
      "author" : [ "G. Seni", "J.F. Elder" ],
      "venue" : "Morgan & Claypool Publishers",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Bundling Heterogeneous Classifiers with Advisor Perceptrons, University of Idaho",
      "author" : [ "J.F. Elder", "S.S. Lee" ],
      "venue" : "Technical Report,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1997
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "As part of a breast cancer prevention screening, if a lump is found, a fine-needle aspiration biopsy (FNAB) is performed, a technique which has been used widely in the evaluation of non-palpable breast lesions [1].",
      "startOffset" : 210,
      "endOffset" : 213
    }, {
      "referenceID" : 1,
      "context" : "Today, automated image analysis systems can evaluate cytology features derived directly from a digital scan of breast FNAB slides [2].",
      "startOffset" : 130,
      "endOffset" : 133
    }, {
      "referenceID" : 0,
      "context" : "2% [1], while automatic methods based on three-factor Cox multivariate analysis [3] and clustering solutions [4] achieved much higher and consistent results with accuracies levels reaching 98%.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 2,
      "context" : "2% [1], while automatic methods based on three-factor Cox multivariate analysis [3] and clustering solutions [4] achieved much higher and consistent results with accuracies levels reaching 98%.",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 3,
      "context" : "2% [1], while automatic methods based on three-factor Cox multivariate analysis [3] and clustering solutions [4] achieved much higher and consistent results with accuracies levels reaching 98%.",
      "startOffset" : 109,
      "endOffset" : 112
    }, {
      "referenceID" : 4,
      "context" : "2 With this method we did identify few observations that fell outside the traditional [-4,+4] interval and, therefore, flagged as potential outliers [6], but after a careful review we decided to consider these values as valid, even though they were outside of the range.",
      "startOffset" : 149,
      "endOffset" : 152
    }, {
      "referenceID" : 0,
      "context" : "This transformation brought all the variables within the interval [0,1], guaranteeing that none of the variable will have higher influence due to their larger values [6].",
      "startOffset" : 66,
      "endOffset" : 71
    }, {
      "referenceID" : 4,
      "context" : "This transformation brought all the variables within the interval [0,1], guaranteeing that none of the variable will have higher influence due to their larger values [6].",
      "startOffset" : 166,
      "endOffset" : 169
    }, {
      "referenceID" : 5,
      "context" : "Ensemble models have been considered an important development in Data Mining [7] and proven to improve model accuracy that is “easier and more powerful than judicious algorithm selection” [8].",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 6,
      "context" : "Ensemble models have been considered an important development in Data Mining [7] and proven to improve model accuracy that is “easier and more powerful than judicious algorithm selection” [8].",
      "startOffset" : 188,
      "endOffset" : 191
    } ],
    "year" : 2014,
    "abstractText" : "Classification models for the automatic detection of abnormalities on histological samples do exists, with an active debate on the cost associated with false negative diagnosis (underdiagnosis) and false positive diagnosis (overdiagnosis). Current models tend to underdiagnose, failing to recognize a potentially fatal disease. The objective of this study is to investigate the possibility of automatically identifying abnormalities in tissue samples through the use of an ensemble model on data generated by histological examination and to minimize the number of false negative cases. Keywords—Histology, data mining, CART, logistic regression, ensemble model, classification, breast cancer",
    "creator" : "Microsoft® Word 2013"
  }
}