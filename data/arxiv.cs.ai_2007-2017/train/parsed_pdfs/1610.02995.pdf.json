{
  "name" : "1610.02995.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Extrapolation and learning equations",
    "authors" : [ "Georg Martius", "Christoph H. Lampert" ],
    "emails" : [ "gmartius@ist.ac.at", "chl@ist.ac.at" ],
    "sections" : [ {
      "heading" : null,
      "text" : "a hypothesis set without attempting to gain insight into the mechanism connecting inputs and outputs. In the natural sciences, however, finding an interpretable function for a phenomenon is the prime goal as it allows to understand and generalize results. This paper proposes a novel type of function learning network, called equation learner (EQL), that can learn analytical expressions and is able to extrapolate to unseen domains. It is implemented as an end-to-end differentiable feed-forward network and allows for efficient gradient based training. Due to sparsity regularization concise interpretable expressions can be obtained. Often the true underlying source expression is identified."
    }, {
      "heading" : "Introduction",
      "text" : "The quality of a model is typically measured by its ability to generalize from a training set to previously unseen data from the same distribution. In regression tasks generalization essentially boils down to interpolation if the training data is sufficiently dense. As long as models are selected correctly, i. e. in a way to not overfit the data, the regression problem is well understood and can – at least conceptually – be considered solved. However, when working with data from real-world devices, e. g. controlling a robotic arm, interpolation might not be sufficient. It could happen that future data lies outside of the training domain, e. g. when the arm is temporarily operated outside of its specifications. For the sake of robustness and safety it is desirable in such a case to have a regression model that continues to make good predictions, or at least does not fail catastrophically. This setting, which we call extrapolation generalization, is the topic of the present paper.\nWe are particularly interested in regression tasks for systems that can be described by real-valued analytic expression, e. g. mechanical systems such as a pendulum or a robotic arm. These are typically governed by a highly nonlinear function but it is nevertheless possible, in principle, to infer their behavior on an extrapolation domain from their behavior elsewhere. We make two main contributions: 1) a new type of network that can learn analytical expressions and is able to extrapolate to unseen domains and 2) a model selection strategy tailored to the extrapolation setting.\nThe following section describes the setting of regression and extrapolation. Afterwards we introduce our method and discuss the architecture, its training, and its relation to prior art. We present our results in the Section Experimental evaluation and close with conclusions."
    }, {
      "heading" : "Regression and extrapolation",
      "text" : "We consider a multivariate regression problem with a training set {(x1, y1), . . . , (xN , yN )} with x ∈ Rn, y ∈ Rm. Because our main interest lies on extrapolation in the context of learning the dynamics of physical systems we assume the data originates from an unknown analytical function (or system of functions), φ : Rn → Rm with additive zero-mean noise, ξ, i. e. y = φ(x) + ξ and Eξ = 0. The function φ may, for instance, reflect a system of ordinary differential equations that govern the movements of a robot arm or the like. The general task is to learn a function ψ : Rn → Rm that approximates the true functional relation as well as possible in the squared loss sense, i. e. achieves minimal expected error E‖ψ(x)− φ(x)‖2. In practice, we only have particular examples of the function values available and measure the quality of predicting in terms of the empirical error on training or test data D,\nE(D) = 1\nN N∑ i=1 ‖ψ(xi)− yi‖2 . (1)\nar X\niv :1\n61 0.\n02 99\n5v 1\n[ cs\n.L G\n] 1\n0 O\nct 2\n01 6\nIf training and test data are sampled from the same distribution then we speak about an interpolation problem. In the extrapolation setting the training data is assumed to cover only a limited range of the data domain. In the example of the robot arm, for instance, the training may be restricted to a certain joint angle range or maximal velocity. For testing we want to make predictions about the unseen domains, e. g. for higher velocities. As usual, we split the data that is available at training time into a part for model training and a part for validation or model selection.\nLearning a network for function extrapolation The main model we propose is a multi-layered feed-forward network with computational units specifically designed for the extrapolation regression tasks. For an L-layer network, there are L− 1 hidden layers, each consisting of a linear mapping followed by non-linear transformations. For simplicity of notation, we explain the network as if each hidden layer had the same structure (k′ inputs, k outputs). In practice, each layer can be designed independently of the others, of course, as long as input/output dimensions match.\nThe linear mapping at level l maps the k′-dimensional input y(l−1) to the d-dimensional intermediate representation z given by\nz(l) = W (l)y(l−1) + b(l), (2)\nwhere y(l−1) is the output of the previous layer, with the convention y(0) = x. The weight matrix W (l) ∈ Rd×k′ and the bias vector b(l) ∈ Rd are free parameters that are learned during training. The non-linear transformation contains u unary units, fi : R→ R, for i = 1, . . . , u, and v binary units, gj : R× R→ R for j = 1, . . . , v. Their outputs are concatenated to form the layer output\ny(l) := ( f1(z (l) 1 ), f2(z (l) 2 ), . . . , fu(z (l) u ),\ng1(z (l) u+1, z (l) u+2), . . . , gv(z (l) u+2v−1, z (l) u+2v)\n) . (3)\nIn total, the nonlinear stage has k = u+ v outputs and d = u+ 2v inputs. The unary units, f1, . . . , fu receive the respective component, z1, . . . , zu as inputs, and each unit may be one of the following base functions as specified in a fixed type parameter Ii ∈ {0, 1, 2, 3}\nfi(zi) :=  zi if Ii = 0, sin(zi) if Ii = 1, cos(zi) if Ii = 2, sigm(zi) if Ii = 3,\nfor i = 1, . . . , u, (4)\nwhere sigm(z) = 11+e−z is the standard sigmoid function. The binary units, g1, . . . , gv receive the remaining component, zu+1, . . . , zu+2v, as input in pairs of two. They are multiplication units that compute the product of their two input values:\ngj(zu+2j−1, zu+2j) := zu+2j−1 · zu+2j for j = 1, . . . , v. (5)\nFinally, the L-th and last layer computes the regression values by a linear read-out\ny(L) := W (L)y(L−1) + b(L). (6)\nThe architecture is depicted in Fig. 1. We call the new architecture Equation Learner (EQL) and denote the function it defines by ψ."
    }, {
      "heading" : "Discussion of the architecture",
      "text" : "The proposed network architecture differs in two main aspects from typical feed-forward networks: the existence of multiplication units and the possibility of sine and cosine as nonlinearities for the unary units. Both design choices are motivated by our objective of learning a system of equations that govern a physical system and can extrapolate to new parts of the input space.\nSigmoid nonlinearities are the canonical choice of activation function for artificial neural networks (ANN) and proved to be successful. In fact, we include sigmoids in our architecture, making it a super class of ANNs. However, they were typically disabled by the training procedure corresponding to their absence in the considered physical equations. Other, predominantly local nonlinearities, in particular radial basis functions [Broomhead and Lowe, 1988] we do not include, since one cannot expect them to extrapolate at all. Further nonlinearities, such as (square)\nroots and logarithms, could in principle be useful for learning physical equations, but they pose problems because their domains of definition is restricted to positive inputs. We leave the task of incorporating them in a principled way to future work.\nThe ability to multiply two values is a second crucial component of our network architecture. Again, it is inspired by the typical form of physical equations, where multiplication of components is arguably second common basic operation after addition (which the linear layers can perform). Multiplication was introduced into neural networks long ago as product-units [Durbin and Rumelhart, 1989] and Pi-Sigma-unit [Shin and Ghosh, 1991]. The product-units have large fan-in that compute products over all their inputs, potentiated by the respective weights. The result is typically the behavior of a high order polynomial, which are powerful function approximators, but rarely occur in physical equations. Polynomials are also known to require careful fine-tuning in order not to overfit, which makes them a risky choice for the purpose of extrapolation. The Pi-Sigma units are multiplication units with a fixed number of factors and our multiplication units are a special for 2 factors. We find that multiplying just two values at a time is well adjusted to the task we aim at, as it allows to control the maximal degree of the learned polynomial by the depth of the network.\nFinally, each layer of the network contains unary units that act as identity maps, which in particular gives the network the option to learn functions with smaller number of nonlinearities than the total network depths."
    }, {
      "heading" : "Network training",
      "text" : "The EQL is fully differentiable in its free parameters θ = {W (1), . . . ,W (L), b(1), . . . , b(L)}, which allows us to train it in an end-to-end fashion using back-propagation. We adopt a Lasso-like objective [Tibshirani, 1996],\nL(D) = 1\nN |D|∑ i=1 ‖ψ(xi)− yi‖2 + λ L∑ l=1 ∣∣W (l)∣∣ 1 , (7)\nthat is, a linear combination of L2 loss and L1 regularization, and apply a stochastic gradient descent algorithm with mini-batches and Adam [Kingma and Ba, 2015] for calculating the updates:\nθt+1 = θt + Adam ( ∂L(D(t))\n∂θ , α\n) , (8)\nwhere D(t) denotes the current mini-batch and α is the stepsize parameter. The choice of Adam is not critical and standard stochastic gradient descent also works. In all numerical experiments we use α = 0.001 and a mini-batch size of 20.\nThe role of the L1 regularization is to encourage networks with sparse connections, matching the intuition that a typical formula describing a physical system contains only a small number of terms, each operating only on a few variables. However, in a non-convex setting where local minima are likely to occur, this type of regularization can have an undesirable side-effect: during the course of the optimization the weights hardly ever change their sign. The reason is that the regularization leads to a constant rate of weight decay whereas the counteracting derivative with respect to the square loss is proportional to the backpropagated error signal and the input to the unit. The latter contributions are often smaller along paths with small weights, such that many weights go to zero and stay there. Additionally, any non-zero regularization term causes the learned weights to reflect a trade-off between minimizing the loss and the regularizer. Although, this can lead to improved generalization, it also results in a systematic underestimation of the function values.\nTherefore, we follow a hybrid regularization strategy: at the beginning of the training procedure (t < t1) we use no regularization (λ = 0), such that parameters can vary freely and reach reasonable starting points. Afterwards, we\nswitch on the regularization by setting λ to a nonzero value, which has the effect that a sparse network structure emerges. Finally, for the last steps of the training (t > t2) we disable L1 regularization (λ = 0) but enforce the same L0 norm of the weights. This is achieved by keeping all weights w ∈W 1...L that are close to 0 at 0, i. e. if |w| < 0.001 then w = 0 during the remaining epochs. This ensures that the learned model finds not only a function of the right parametric form, but also fits the observed values as closely as possible. We observed that the exact choice of breakpoints t1 and t2 is not critical. In practice, we use t1 = 14T and t2 = 19 20T , where T is total number of update steps. T was selected large enough to ensure convergence. Note, that convergence to a sparse structure is important here, so early stopping will be disadvantageous."
    }, {
      "heading" : "Model selection for extrapolation",
      "text" : "EQL networks have a number of hyper-parameters, e. g. the number of layers, the number of units and the regularization constant. Unfortunately, standard techniques for model selection, such as evaluation on a hold-out set or cross-validation, will not be optimal for our purpose, since they rely on interpolation quality. In order to extrapolate the network has to find the “right” formula. But how can we tell? Using Occams razor principle: the simplest formula is most likely the right one. Intuitively, if we have the choice between cos(x) and its truncated power series approximation 1− x2/2 + x4/24, the first one is preferred. We use the number of active hidden units in the network as a proxy for the complexity of the formula, see Appendix A1 for details. One could also think of differentiating between the unit types. In any case, this argumentation is only correct if the model explains the data well, i. e. it has a low validation error. So we have a dual objective to minimize, which we solve by ranking the instances w. r. t. validation error and sparsity and select the one with the smallest L2 norm (in rank-space), see Eq. (15).\nFurthermore, the optimization process may only find a local optimum of the training objective, which depends on the initialization of the parameters. We use independent runs to quantify expected performance deviations."
    }, {
      "heading" : "Related work",
      "text" : "In the field of machine learning, regression is often treated as a black box process of identifying a suitable realvalued function from a hypothesis set, e. g. a reproducing kernel Hilbert space for Gaussian Processes Regression (GPR) [Williams and Rasmussen, 2006] or Support Vector Regression (SVR) [Smola and Schölkopf, 2004], or a multi-layer network of suitable expressive power [Specht, 1991]. The goal is to find a prediction function that leads to a small expected error on future data, not necessarily to gain insight into the mechanism of how the output values derive from the inputs. The goal of finding an interpretable function is rather common in the natural sciences, such as biology, where high noise levels and strong inter-system variability often make it important to rely on external prior knowledge, and finding a “biologically plausible” model is often preferable over finding one that makes the highest prediction accuracy. As a consequence, model classes are often highly constrained, e. g. allowing only for sparse linear models.\nThe task of learning a true, nonlinear, functional dependence from observing a physical system, has received little attention in the machine learning literature so far, but forms the basis of the field of system identification. There, typically the functional form of the system is known and only the parameters have to be identified. Another approach is to model the time evolution with autoregressive models or higher order convolution integrals (Volterra series) but learning analytic formulas is not common.\nCausal learning is an area of recent research that aims at identifying a causal relation between multiple observables, which are typically the result of a physical process. Classically, this tasks reduces to finding a minimal graphical model based only on tests of conditional independence [Pearl, 2000]. Although very successful in some fields, this classical approach only provides a factorization of the problem, separating causes and effects, but it leaves the exact functional dependency unexplained. Recent extensions of causal learning can take a functional view, but typically do not constrain the regression functions to physically plausible ones, but rather constrain the noise distributions [Peters et al., 2014]. The topic of learning a regression function with emphasis on extrapolation performance has not been studied much in the literature so far. Existing work on time series prediction deals with extrapolation in the temporal domain, i. e. predict the next value(s) [Wiener, 1949]. By our nomenclature, this is typically rather an interpolation task, when the prediction is based on the behaviour of the series at earlier time steps but with similar value distribution [Györfi et al., 2013; Müller et al., 1997]. Extrapolating in the data domain implies that the data distribution at prediction time will differ from the data distribution at training time. This is traditionally called the domain adaptation setting. In particular, since we assume a common labeling function, our setting would fall under the covariate shift setting [Quionero-Candela et al., 2009]. Unfortunately, this connection is not particularly useful for our problem. As domain adaptation typically does not make additional assumptions about how the data distribution may change, existing methods need access to some unlabeled data from the test distribution already at training time [Ben-David et al., 2010]. In our setting this is not possible to obtain.\nOn the technical level, EQL networks are an instance of general feed-forward networks for function approximation [Bishop, 1995]. In contrast to recent trends towards deep learning [Bengio, 2009; Bengio et al., 2013], our goal is not to learn any data representation, but to learn a function which compactly represents the input-output relation and generalizes between different regions of the data space, like a physical formula. Structurally, EQL networks resemble sum-product networks (SPNs) [Poon and Domingos, 2012] and Pi-Sigma networks (PSNs) [Shin and Ghosh, 1991], in the sense that both are based on directed acyclic graphs with computational units that allows for summation and multiplication. Otherwise, SPNs are different as they act as efficient alternative to probabilistic graphical models for representing probability distributions, whereas EQL networks are meant for the classical task of function approximation. In PSNs each output needs to be passed through multiplicative units, whereas in EQL multiplication is optional.\nFinding equations for observations is also known as symbolic regression where a search is performed in a certain function space, typically done with evolutionary computation. With these techniques it is possible to discover physical laws such as invariants and conserved quantities [Schmidt and Lipson, 2009]. Unfortunately, the computational complexity/search time explodes for larger expressions and high-dimensional problems. We attempt to circumvent this by modeling it as a gradient based optimization problem. Related to symbolic regression is finding mathematical identities for instance to find computationally more efficient expressions. In [Zaremba et al., 2014] this was done using machine learning to overcome the potentially exponential search space."
    }, {
      "heading" : "Experimental evaluation",
      "text" : "We demonstrate the ability of EQL to learn physically inspired models with good extrapolation quality by experiments on synthetic and real data. For this, we implemented the network training and evaluation procedure in python based on the theano framework [Theano Development Team, 2016]. We will make the code for training and evaluation public after acceptance of the manuscript.\nPendulum. We first present the results of learning the equations of motion for a very simple physical system: a pendulum. The state space of a pendulum is X = R× R where the first value is the angle of the pole in radians and the second value is the angular velocity. In the physics literature, these are usually denoted as (θ, ω), but for our purposes, we call them (x1, x2) in order to keep the notation consistent between experiments. The pendulum’s dynamic behavior is governed by the following two ordinary differential equations:\nẋ1 = x2 and ẋ2 = −g sin(x1) , (9)\nwhere g = 9.81 is the gravitation constant. We divide each equation by g in order to balance the output scales and form a regression problem with two output values, y1 = 1gx2 and y2 = − sin(x1). As training data, we sample 1000 points uniformly in the hypercube [−h, h] × [−h, h] for h = 2. Note that this domain contains more than half of a sine period, so it should be sufficient to identify the analytic expression. The target values are disturbed by Gaussian noise with standard derivation σ = 0.01. We also define three test sets, each with 1000 points. The interpolation test set is sampled from the same data distribution as the training set. The extrapolation (near) test set contains data sampled uniformly from the data domain [− 3\n2 h, 3 2 h]× [− 3 2 h, 3 2 h] \\ [−h, h]× [−h, h], which is relatively near the training region and the extrapolation (far) test set extends the region to further outside: [−2h, 2h]× [−2h, 2h]\\ [−h, h]× [−h, h]. We train a 2-layer EQL and perform model selection among the hyper-parameters: the regularization strength λ ∈ 10{−7,−6.3,−6,−5.3,−5,−4.3,−4,−3.3,−3} and the number of nodes 1 4 u = v ∈ {1, 3, 5}. All weights are randomly initialized from a normal distribution with\nσ = √\n1/(k′ + d). The unit selection I is set such that all unit types are equally often. To ensure convergence we chose T = 10000 epochs. We compare our algorithm to a standard multilayer perceptron (MLP) with tanh activation functions and possible hyperparameters: λ as for EQL, number of layers L ∈ {2, 3}, and number of neurons k ∈ {5, 10, 20}. A second baseline is given by epsilon support vector regression (SVR) [Basak et al., 2007] with two hyperparameters C ∈ 10{−3,−2,−1,0,1,2,3,3.5} and ∈ 10{−3,−2,−1,0} using radial basis function kernel with width γ ∈ {0.05, 0.1, 0.2, 0.5, 1.0}.\nNumeric results are reported in Tab. 1. As expected all models are able to interpolate well with a test error on the order of the noise level (σ = 0.01). For extrapolation however, the performance differ between the approaches. For MLP the prediction quality decreases quickly when leaving the training domain. SVR remains a bit better in the near extrapolation but also fails catastrophically on the far extrapolation data. EQL, on the other hand, extrapolates well, both near and far away from the training domain. The reasons can be seen in Figure 2: while the MLP and SVR simply learns a function that interpolates the training values, EQL finds the correct functional expression and therefore predicts the correct values for any input data.\nModel selection is performed to determine λ as above, u = v ∈ {3, 5}, (MLP: k ∈ {5, 10, 20}) and layer number L ∈ {2, 3}.\nRobotic arms. A more complicated task is to learn the forward kinematics of multi-segment robotic arms. We consider planar arms with 3, 4, and 5 joints, where each segment is 0.5 units long. For training the arm is controlled by sinusoidal joint target angles with amplitude in [−π/2, π/2], each joint with a different frequency. The number of data points are: 3000, 6000, and 18000 for the 3, 4, and 5 segment arms respectively, with added noise as above. For testing extrapolation performance the amplitude [−π, π] was used. Note that the extrapolation space is much larger than the training space. The task is to predict the coordinates of the end-effector of the arms (kin-3-end, kin-4-end) and the coordinates of all segment positions kin-5-all. The numerical results, see Tab. 2, shows that our method is able to extrapolate in these cases. Model selection as above with u = v ∈ {10, 20}, (MLP: k ∈ {10, 50}) and layer number L ∈ {2, 3, 4}. To illustrate the dependence on the amount of noise and the number of available training points we provide a quantification in Appendix A2. In short, increasing noise can be compensated by increasing amount of data to keep the performance.\nLearning complex formula. In order to find out whether EQL can also learn more complicated formulas, we consider three examples with four-dimensional input and one-dimensional output:\ny = 1/3 (sin(πx1) + sin (2πx2 + π/8) + x2 − x3x4) F-1 (10) y = 1/3 ( sin(πx1) + x2 cos(2πx1 + π/4) + x3 − x24 ) F-2 (11)\ny = 1/3 ((1 + x2) sin(πx1) + x2x3x4) F-3 (12)\nThe first equation requires only one hidden layer to be represented. The second equation and third equation should requires two hidden layers. In particular, F-2 contains a product of x2 and cos and F-3 contains a product of three terms, and we use it to test if our restriction to only pairwise product units causes problems for more complex target functions. We follow the same procedure as in the pendulum case for building training and test sets, though with h = 1 as input data range. We use 10000 points for training set and validation set (90%-10% split) and 5000 points for each of the test sets. Model selection for EQL is performed as above using the number of layers L ∈ 2, 3, 4. The number of units is set to 14u = v = 10. For the MLP, we select L and λ from the same set as above as well as k ∈ {10, 30}.\nTable 3 shows the numerical results. Again, all methods are able to interpolate, but only EQL achieves good extrapolation results, except for equation F-3. There it settles in 9 out of 10 cases into a local minimum and finds only an approximating equation that deviates outside the training domain. Interestingly, if we restrict the base functions to not contain cosine, the algorithm finds the right formula. Note, the sparsity of the correct formula is lower than those of the approximation, so it should be selected if found. Figure Fig. 4 illustrates the performance and the learned networks visually. It shows one of the model-selected instances for each case. For F-1 the correct formula was identified, so correct predictions can be made even far outside the training region (much further than illustrated). For F-2 the network provided us with a surprise, because it yields good extrapolation performance with only one hidden layer! How can it implement x2 cos(ax1 + b)? Apparently it uses 1.21 cos(ax1 + π + b+ 0.41x2) + sin(ax1 + b+ 0.41x2) which is a good approximation for x2 ∈ [−2, 2]. The sparsity of this solution is 5 whereas the true solution needs at least 6, which explains its selection. For F-3 the suboptimal local minima uses some strange way of approximating (1 + x2) sin(x1) using (x1 + x1x2) cos(βx1), which deviates fast, however the true solution would be sparser but was not found. Only if we remove cosine from the base functions we get always the correct formula, see Fig. 4(c).\nX-Ray transition energies. As a further example we consider data measured in atomic physics. When shooting electron beams onto atoms one can excite them and they consequently emit x-ray radiation with characteristic peak energies. For each element/isotope these energies are different as they correspond to the potential difference between the electron shells, such that one can identify elements in a probe this way. The data is taken from [Deslattes et al., 2003], where we consider one specific transition, called the K α2 line, because it was measured for all elements. The true relationship between atomic number Z and transition energies is complicated, as it involves many body interactions and no closed-form solution exists. Nevertheless we can find out which relationships our system proposes. It is known that the main relationship is K α2 ∝ Z2 according to Moseley’s law. Further correction\nterms for elements with larger Z are potentially of higher order. We have data for elements with 10 ≤ Z ≤ 100, which is split into training/validation sets in the range [10, 91] (70/10 data points) and extrapolation test set in the interval [92, 100] (14 data points because of isotops). Since we have so little data we evaluate the performance for 10 independent training/validation splits. The data is scaled to lie in [0, 1], i. e. x = Z/100 and y = Kα2/100000. Model selection is here based on validation error only. The selection for sparsity and validation error only yields the Z2 relationship. Mini-batch size is 2 here and T = 50000 was used. Figure 5 presents the data, the predictions, the learned formulas and the numerical results. EQL and SVR achieve similar performance and MLP is significantly worse. However, EQL also yields interpretable formulas, see Fig. 5(e) that can be used to gain insights into the potential relationship.\nPoor extrapolation out of model class — cart-pendulum system Let us now go beyond our assumptions and consider cases where the true target function is not an element of the hypothesis set.\nConsider a pendulum attached to a cart that can move horizontally along a rail but that is attached to a spring damper system, see Fig. 6(a). The system is parametrized by 4 unknowns: the position of the cart, the velocity of the cart, the angle of the pendulum and the angular velocity of the pendulum. We combine these into a four-dimensional vector x = (x1, . . . , x4).\nWe set up a regression problem with four outputs from the corresponding system of ordinary differential equations where y1 = ẋ1 = x3, y2 = ẋ2 = x4 and\ny3 = −x1 − 0.01x3 + x24 sin (x2) + 0.1x4 cos (x2) + 9.81 sin (x2) cos (x2)\nsin2 (x2) + 1 , (13)\ny4 = −0.2x4 − 19.62 sin (x2) + x1 cos (x2) + 0.01x3 cos (x2)− x24 sin (x2) cos (x2)\nsin2 (x2) + 1 .\nThe formulas contain divisions which are not included in our architecture due to their singularities. To incorporate them in a principled manner is left for future work. Thus, the cart-pendulum dynamics is outside the hypothesis class. In this case we cannot expect great extrapolation performance and this is confirmed by the experiments. In Fig. 6(b,c) the extrapolation performance is illustrated by slicing through the input space. The near extrapolation performance is still acceptable for both EQL and MLP, but as soon as the training region is left further even the best instances differ considerably from the true values, see also the numeric results in Tab. 4. The SVR is performing poorly also for near extrapolation range. Inspecting the learned expressions we find that the sigmoid functions are rarely used."
    }, {
      "heading" : "Conclusions",
      "text" : "We presented a new network architecture called EQL that can learn analytic expressions that typically occur in equations governing physical, in particular mechanical, systems. The network is fully differentiable, which allows\nend-to-end training using backpropagation. By sequencing L1 regularization and fixing L0 norm we achieve sparse representations with unbiased estimation of factors within the learned equations. We also introduce a model selection procedure specifically designed to select for good extrapolation quality by a multiobjective criterion based on validation error and sparsity. The proposed method is able to learn functional relations and extrapolate them to unseen parts of the data space, as we demonstrate by experiments on synthetic as well as real data. The approach learns concise functional forms that may provide insights into the relationships within the data, as we show on physical measurements of x-ray transition energies.\nThe optimization problem is nontrivial and has many local minima. We have shown cases where the algorithm is not reliably finding the right equation but instead finds an approximation only, in which case extrapolation may be poor.\nIf the origin of the data is not in the hypothesis class, i. e. the underlying expression cannot be represented by the network, good extrapolation performance cannot be achieved. Thus it is important to increase the model class by incorporating more base functions which we will address in future work alongside the application to larger examples. We expect good scaling capabilities to larger systems due to the gradient based optimization. Apart from the extrapolation we also expect improved interpolation results in high-dimensional spaces, where data is less dense."
    }, {
      "heading" : "Acknowledgments",
      "text" : "GM received funding from the People Programme (Marie Curie Actions) of the European Union’s Seventh Framework Programme (FP7/2007-2013) under REA grant agreement no. [291734]."
    }, {
      "heading" : "Appendix",
      "text" : ""
    }, {
      "heading" : "A1: Model selection details",
      "text" : ""
    }, {
      "heading" : "Quantifying sparsity",
      "text" : "We actually want a measure of complexity of the formula, however, since it is not clear what is the right choice of a measure, we use the sparsity instead, by counting the number of active/used hidden units denoted by s. For a given network phi we get\ns(φ) = L∑ l=1 k∑ i=1 Θ(|W (l)i,· | ∗ |W (l+1) ·,i | − 0.01) , (14)\nwhere Θ is the heavyside function and 0.01 is an arbitrary threshold. For the multiplication units the norm of the incoming weights for both inputs are added (omitted to avoid clutter in the formula)."
    }, {
      "heading" : "Selection criteria",
      "text" : "As stated in the main text, we strive to choose the model that is both simple and has good performance in terms of the validation set. Since both quantities have different scales, we proposed to choose them based on their ranking. Let rv(φ) and rs(φ) be the ranks of the network φ w. r. t. the validation error and sparsity s(φ)respectively, then the network with minimal squared rank norm is selected:\narg min φ\n[ rv(φ)2 + rs(φ)2 ] (15)\nIn Fig. 7 the extrapolation performance of all considered networks for the kin2D-3 dataset is visualized in dependence of validation error and the sparsity. It becomes evident that the best performing networks are both sparse and have a low validation error."
    }, {
      "heading" : "A2: Dependence on noise and number of data points",
      "text" : "In order to understand how the method depends on the amount of noise and the number of datapoints we scan through the two parameters and present the empirical results in Fig. 8. In general the method is robust to noise and as expected, more noise can be compensated by more data."
    } ],
    "references" : [ {
      "title" : "Support vector regression",
      "author" : [ "D. Basak", "S. Pal", "D.C. Patranabis" ],
      "venue" : "Neural Information Processing-Letters and Reviews,",
      "citeRegEx" : "Basak et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Basak et al\\.",
      "year" : 2007
    }, {
      "title" : "A theory of learning from different domains",
      "author" : [ "S. Ben-David", "J. Blitzer", "K. Crammer", "A. Kulesza", "F. Pereira", "J.W. Vaughan" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Ben.David et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Ben.David et al\\.",
      "year" : 2010
    }, {
      "title" : "Learning deep architectures for AI",
      "author" : [ "Y. Bengio" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "Bengio.,? \\Q2009\\E",
      "shortCiteRegEx" : "Bengio.",
      "year" : 2009
    }, {
      "title" : "Representation learning: A review and new perspectives",
      "author" : [ "Y. Bengio", "A. Courville", "P. Vincent" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),",
      "citeRegEx" : "Bengio et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2013
    }, {
      "title" : "Neural networks for pattern recognition",
      "author" : [ "C.M. Bishop" ],
      "venue" : null,
      "citeRegEx" : "Bishop.,? \\Q1995\\E",
      "shortCiteRegEx" : "Bishop.",
      "year" : 1995
    }, {
      "title" : "Radial basis functions, multi-variable functional interpolation and adaptive networks",
      "author" : [ "D.S. Broomhead", "D. Lowe" ],
      "venue" : "Technical report, DTIC Document,",
      "citeRegEx" : "Broomhead and Lowe.,? \\Q1988\\E",
      "shortCiteRegEx" : "Broomhead and Lowe.",
      "year" : 1988
    }, {
      "title" : "X-ray transition energies: new approach to a comprehensive evaluation",
      "author" : [ "R.D. Deslattes", "E.G. Kessler Jr.", "P. Indelicato", "L. De Billy", "E. Lindroth", "J. Anton" ],
      "venue" : "Reviews of Modern Physics,",
      "citeRegEx" : "Deslattes et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Deslattes et al\\.",
      "year" : 2003
    }, {
      "title" : "Product units: A computationally powerful and biologically plausible extension to backpropagation networks",
      "author" : [ "R. Durbin", "D.E. Rumelhart" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Durbin and Rumelhart.,? \\Q1989\\E",
      "shortCiteRegEx" : "Durbin and Rumelhart.",
      "year" : 1989
    }, {
      "title" : "Nonparametric curve estimation from time series, volume 60",
      "author" : [ "L. Györfi", "W. Härdle", "P. Sarda", "P. Vieu" ],
      "venue" : null,
      "citeRegEx" : "Györfi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Györfi et al\\.",
      "year" : 2013
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "D. Kingma", "J. Ba" ],
      "venue" : "In in Proceedings of ICLR,",
      "citeRegEx" : "Kingma and Ba.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Predicting time series with support vector machines",
      "author" : [ "K.-R. Müller", "A.J. Smola", "G. Rätsch", "B. Schölkopf", "J. Kohlmorgen", "V. Vapnik" ],
      "venue" : "In Artificial Neural Networks (ICANN),",
      "citeRegEx" : "Müller et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Müller et al\\.",
      "year" : 1997
    }, {
      "title" : "Causal discovery with continuous additive noise models",
      "author" : [ "J. Peters", "J. Mooij", "D. Janzing", "B. Schölkopf" ],
      "venue" : "Journal of Machine Learning Research (JMLR),",
      "citeRegEx" : "Peters et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2014
    }, {
      "title" : "Dataset shift in machine learning",
      "author" : [ "J. Quionero-Candela", "M. Sugiyama", "A. Schwaighofer", "N.D. Lawrence" ],
      "venue" : null,
      "citeRegEx" : "Quionero.Candela et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Quionero.Candela et al\\.",
      "year" : 2009
    }, {
      "title" : "Distilling free-form natural laws from experimental data",
      "author" : [ "M. Schmidt", "H. Lipson" ],
      "venue" : "Science, 324(5923):81–85,",
      "citeRegEx" : "Schmidt and Lipson.,? \\Q2009\\E",
      "shortCiteRegEx" : "Schmidt and Lipson.",
      "year" : 2009
    }, {
      "title" : "The pi-sigma network : An efficient higher-order neural network for pattern classification and function approximation",
      "author" : [ "Y. Shin", "J. Ghosh" ],
      "venue" : "In in Proceedings of the International Joint Conference on Neural Networks,",
      "citeRegEx" : "Shin and Ghosh.,? \\Q1991\\E",
      "shortCiteRegEx" : "Shin and Ghosh.",
      "year" : 1991
    }, {
      "title" : "A tutorial on support vector regression",
      "author" : [ "A.J. Smola", "B. Schölkopf" ],
      "venue" : "Statistics and computing,",
      "citeRegEx" : "Smola and Schölkopf.,? \\Q2004\\E",
      "shortCiteRegEx" : "Smola and Schölkopf.",
      "year" : 2004
    }, {
      "title" : "A general regression neural network",
      "author" : [ "D.F. Specht" ],
      "venue" : "IEEE Transactions on Neural Networks (TNN),",
      "citeRegEx" : "Specht.,? \\Q1991\\E",
      "shortCiteRegEx" : "Specht.",
      "year" : 1991
    }, {
      "title" : "Regression shrinkage and selection via the lasso",
      "author" : [ "R. Tibshirani" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "Tibshirani.,? \\Q1996\\E",
      "shortCiteRegEx" : "Tibshirani.",
      "year" : 1996
    }, {
      "title" : "Extrapolation, interpolation, and smoothing of stationary time series, volume 2",
      "author" : [ "N. Wiener" ],
      "venue" : null,
      "citeRegEx" : "Wiener.,? \\Q1949\\E",
      "shortCiteRegEx" : "Wiener.",
      "year" : 1949
    }, {
      "title" : "Gaussian processes for machine learning",
      "author" : [ "C.K.I. Williams", "C.E. Rasmussen" ],
      "venue" : null,
      "citeRegEx" : "Williams and Rasmussen.,? \\Q2006\\E",
      "shortCiteRegEx" : "Williams and Rasmussen.",
      "year" : 2006
    }, {
      "title" : "Learning to discover efficient mathematical identities",
      "author" : [ "W. Zaremba", "K. Kurach", "R. Fergus" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "Zaremba et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zaremba et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "Other, predominantly local nonlinearities, in particular radial basis functions [Broomhead and Lowe, 1988] we do not include, since one cannot expect them to extrapolate at all.",
      "startOffset" : 80,
      "endOffset" : 106
    }, {
      "referenceID" : 7,
      "context" : "Multiplication was introduced into neural networks long ago as product-units [Durbin and Rumelhart, 1989] and Pi-Sigma-unit [Shin and Ghosh, 1991].",
      "startOffset" : 77,
      "endOffset" : 105
    }, {
      "referenceID" : 14,
      "context" : "Multiplication was introduced into neural networks long ago as product-units [Durbin and Rumelhart, 1989] and Pi-Sigma-unit [Shin and Ghosh, 1991].",
      "startOffset" : 124,
      "endOffset" : 146
    }, {
      "referenceID" : 17,
      "context" : "We adopt a Lasso-like objective [Tibshirani, 1996],",
      "startOffset" : 32,
      "endOffset" : 50
    }, {
      "referenceID" : 9,
      "context" : "that is, a linear combination of L2 loss and L1 regularization, and apply a stochastic gradient descent algorithm with mini-batches and Adam [Kingma and Ba, 2015] for calculating the updates:",
      "startOffset" : 141,
      "endOffset" : 162
    }, {
      "referenceID" : 19,
      "context" : "a reproducing kernel Hilbert space for Gaussian Processes Regression (GPR) [Williams and Rasmussen, 2006] or Support Vector Regression (SVR) [Smola and Schölkopf, 2004], or a multi-layer network of suitable expressive power [Specht, 1991].",
      "startOffset" : 75,
      "endOffset" : 105
    }, {
      "referenceID" : 15,
      "context" : "a reproducing kernel Hilbert space for Gaussian Processes Regression (GPR) [Williams and Rasmussen, 2006] or Support Vector Regression (SVR) [Smola and Schölkopf, 2004], or a multi-layer network of suitable expressive power [Specht, 1991].",
      "startOffset" : 141,
      "endOffset" : 168
    }, {
      "referenceID" : 16,
      "context" : "a reproducing kernel Hilbert space for Gaussian Processes Regression (GPR) [Williams and Rasmussen, 2006] or Support Vector Regression (SVR) [Smola and Schölkopf, 2004], or a multi-layer network of suitable expressive power [Specht, 1991].",
      "startOffset" : 224,
      "endOffset" : 238
    }, {
      "referenceID" : 11,
      "context" : "Recent extensions of causal learning can take a functional view, but typically do not constrain the regression functions to physically plausible ones, but rather constrain the noise distributions [Peters et al., 2014].",
      "startOffset" : 196,
      "endOffset" : 217
    }, {
      "referenceID" : 18,
      "context" : "predict the next value(s) [Wiener, 1949].",
      "startOffset" : 26,
      "endOffset" : 40
    }, {
      "referenceID" : 8,
      "context" : "By our nomenclature, this is typically rather an interpolation task, when the prediction is based on the behaviour of the series at earlier time steps but with similar value distribution [Györfi et al., 2013; Müller et al., 1997].",
      "startOffset" : 187,
      "endOffset" : 229
    }, {
      "referenceID" : 10,
      "context" : "By our nomenclature, this is typically rather an interpolation task, when the prediction is based on the behaviour of the series at earlier time steps but with similar value distribution [Györfi et al., 2013; Müller et al., 1997].",
      "startOffset" : 187,
      "endOffset" : 229
    }, {
      "referenceID" : 12,
      "context" : "In particular, since we assume a common labeling function, our setting would fall under the covariate shift setting [Quionero-Candela et al., 2009].",
      "startOffset" : 116,
      "endOffset" : 147
    }, {
      "referenceID" : 1,
      "context" : "As domain adaptation typically does not make additional assumptions about how the data distribution may change, existing methods need access to some unlabeled data from the test distribution already at training time [Ben-David et al., 2010].",
      "startOffset" : 216,
      "endOffset" : 240
    }, {
      "referenceID" : 4,
      "context" : "On the technical level, EQL networks are an instance of general feed-forward networks for function approximation [Bishop, 1995].",
      "startOffset" : 113,
      "endOffset" : 127
    }, {
      "referenceID" : 2,
      "context" : "In contrast to recent trends towards deep learning [Bengio, 2009; Bengio et al., 2013], our goal is not to learn any data representation, but to learn a function which compactly represents the input-output relation and generalizes between different regions of the data space, like a physical formula.",
      "startOffset" : 51,
      "endOffset" : 86
    }, {
      "referenceID" : 3,
      "context" : "In contrast to recent trends towards deep learning [Bengio, 2009; Bengio et al., 2013], our goal is not to learn any data representation, but to learn a function which compactly represents the input-output relation and generalizes between different regions of the data space, like a physical formula.",
      "startOffset" : 51,
      "endOffset" : 86
    }, {
      "referenceID" : 14,
      "context" : "Structurally, EQL networks resemble sum-product networks (SPNs) [Poon and Domingos, 2012] and Pi-Sigma networks (PSNs) [Shin and Ghosh, 1991], in the sense that both are based on directed acyclic graphs with computational units that allows for summation and multiplication.",
      "startOffset" : 119,
      "endOffset" : 141
    }, {
      "referenceID" : 13,
      "context" : "With these techniques it is possible to discover physical laws such as invariants and conserved quantities [Schmidt and Lipson, 2009].",
      "startOffset" : 107,
      "endOffset" : 133
    }, {
      "referenceID" : 20,
      "context" : "In [Zaremba et al., 2014] this was done using machine learning to overcome the potentially exponential search space.",
      "startOffset" : 3,
      "endOffset" : 25
    }, {
      "referenceID" : 0,
      "context" : "A second baseline is given by epsilon support vector regression (SVR) [Basak et al., 2007] with two hyperparameters C ∈ 10{−3,−2,−1,0,1,2,3,3.",
      "startOffset" : 70,
      "endOffset" : 90
    }, {
      "referenceID" : 13,
      "context" : "For that we use recorded trajectories of a real double pendulum [Schmidt and Lipson, 2009].",
      "startOffset" : 64,
      "endOffset" : 90
    }, {
      "referenceID" : 6,
      "context" : "The data is taken from [Deslattes et al., 2003], where we consider one specific transition, called the K α2 line, because it was measured for all elements.",
      "startOffset" : 23,
      "endOffset" : 47
    } ],
    "year" : 2016,
    "abstractText" : "In classical machine learning, regression is treated as a black box process of identifying a suitable function from a hypothesis set without attempting to gain insight into the mechanism connecting inputs and outputs. In the natural sciences, however, finding an interpretable function for a phenomenon is the prime goal as it allows to understand and generalize results. This paper proposes a novel type of function learning network, called equation learner (EQL), that can learn analytical expressions and is able to extrapolate to unseen domains. It is implemented as an end-to-end differentiable feed-forward network and allows for efficient gradient based training. Due to sparsity regularization concise interpretable expressions can be obtained. Often the true underlying source expression is identified. Introduction The quality of a model is typically measured by its ability to generalize from a training set to previously unseen data from the same distribution. In regression tasks generalization essentially boils down to interpolation if the training data is sufficiently dense. As long as models are selected correctly, i. e. in a way to not overfit the data, the regression problem is well understood and can – at least conceptually – be considered solved. However, when working with data from real-world devices, e. g. controlling a robotic arm, interpolation might not be sufficient. It could happen that future data lies outside of the training domain, e. g. when the arm is temporarily operated outside of its specifications. For the sake of robustness and safety it is desirable in such a case to have a regression model that continues to make good predictions, or at least does not fail catastrophically. This setting, which we call extrapolation generalization, is the topic of the present paper. We are particularly interested in regression tasks for systems that can be described by real-valued analytic expression, e. g. mechanical systems such as a pendulum or a robotic arm. These are typically governed by a highly nonlinear function but it is nevertheless possible, in principle, to infer their behavior on an extrapolation domain from their behavior elsewhere. We make two main contributions: 1) a new type of network that can learn analytical expressions and is able to extrapolate to unseen domains and 2) a model selection strategy tailored to the extrapolation setting. The following section describes the setting of regression and extrapolation. Afterwards we introduce our method and discuss the architecture, its training, and its relation to prior art. We present our results in the Section Experimental evaluation and close with conclusions. Regression and extrapolation We consider a multivariate regression problem with a training set {(x1, y1), . . . , (xN , yN )} with x ∈ R, y ∈ R. Because our main interest lies on extrapolation in the context of learning the dynamics of physical systems we assume the data originates from an unknown analytical function (or system of functions), φ : R → R with additive zero-mean noise, ξ, i. e. y = φ(x) + ξ and Eξ = 0. The function φ may, for instance, reflect a system of ordinary differential equations that govern the movements of a robot arm or the like. The general task is to learn a function ψ : R → R that approximates the true functional relation as well as possible in the squared loss sense, i. e. achieves minimal expected error E‖ψ(x)− φ(x)‖2. In practice, we only have particular examples of the function values available and measure the quality of predicting in terms of the empirical error on training or test data D,",
    "creator" : "LaTeX with hyperref package"
  }
}