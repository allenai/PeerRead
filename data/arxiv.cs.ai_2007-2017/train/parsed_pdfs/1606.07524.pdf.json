{
  "name" : "1606.07524.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Preference at First Sight",
    "authors" : [ "Chanjuan Liu" ],
    "emails" : [ "chanjuan.pkucs@gmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "R. Ramanujam (Ed.): TARK 2015 EPTCS 215, 2016, pp. 207–226, doi:10.4204/EPTCS.215.15\nc© C. Liu This work is licensed under the Creative Commons Attribution License.\nPreference at First Sight\nChanjuan Liu School of Computer Science and Technology, Dalian University of Technology\nInstitute for Logic, Language and Computation, University of Amsterdam\nchanjuan.pkucs@gmail.com\nWe consider decision-making and game scenarios in which an agent is limited by his/her computational ability to foresee all the available moves towards the future – that is, we study scenarios with short sight. We focus on how short sight affects the logical properties of decision making in multi-agent settings. We start with single-agent sequential decision making (SSDM) processes, modeling them by a new structure of ‘preference-sight trees’. Using this model, we first explore the relation between a new natural solution concept of Sight-Compatible Backward Induction (SCBI) and the histories produced by classical Backward Induction (BI). In particular, we find necessary and sufficient conditions for the two analyses to be equivalent. Next, we study whether larger sight always contributes to better outcomes. Then we develop a simple logical special-purpose language to formally express some key properties of our preference-sight models. Lastly, we show how shortsight SSDM scenarios call for substantial enrichments of existing fixed-point logics that have been developed for the classical BI solution concept. We also discuss changes in earlier modal logics expressing ‘surface reasoning’ about best actions in the presence of short sight. Our analysis may point the way to logical and computational analysis of more realistic game models."
    }, {
      "heading" : "1 Introduction",
      "text" : "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine. Making decisions is central to agents’ routine and usually, they need to make multiple decisions over time. Indeed, a current situation is a result of past sequentially linked decisions, each impacted by the preceding choices.\nIt is quite natural in sequential decision-making scenarios, particularly, in large systems, that agents may have some uncertainties and limitations on their precise view of the environment. The current literature [9, 28] has studied uncertainty which an agent faces in recognizing possible outcomes after taking an action and the probabilities associated with these outcomes, as well as the partial observability of what the actual state is like. In addition to these, a realistic aspect that affects a SSDM process is the short-sightedness of the agent, which blocks a full view of all the available actions. Short sight plays a critical role in such a situation, since, while making a choice, the ability to foresee a variety of alternatives and predict future decision sequences for each of them, may make a significant difference. Nonetheless, such restrictions have not been discussed systematically yet in decision theory or game theory.\nIn [14], a game-theoretic framework called games with short sight was proposed. This framework explicitly models players’s limited foresight in extensive games and calls for a new solution termed as Sight-Compatible Backward Induction (SCBI). However, many essential issues related to sight remain unclear, such as: What is the exact role of sight? Will the outcome be better when sight is larger? What is the relation between SCBI and classical backward induction(BI)? There are also unexplored issues\npertaining to logical aspects. Which minimal logic is needed for formally characterizing a short-sight framework? Are existing logics for BI still applicable, or can they be extended to fit short-sight scenarios? How different are the logical properties of the game frames for SCBI and for BI? Without such a logical analysis, the framework of [14] does not suffice for disclosing the general features of short sight and the changes it brings about in thinking about decisions and games. Additionally, in multi-player games, short sight has to interact with many other factors, such as agents’ mutual knowledge and interactive decisions and moves.\nHaving said this, we still start by focusing on short sight in single-agent sequential decision-making process. For this, we propose a model of ‘preference-sight trees’ (P-S trees). As the term says, a P-S tree combines the agent’s preference and its sight, as both are essential to decision problems [33]. We will study how the two are correlated, and cooperate to act on decision-making processes and their final outcomes.\nAs a preliminary illustration, consider the connection between larger sight and better outcome. A first impression might be that an agent will always perform better with larger sight. Surprisingly, this is not always true. Sometimes, one can see much further into the future but receive a small payoff, while having one’s vision restricted to a limited set of future alternatives yields a better payoff. Example 1.1 Alice has to make sequential decisions at two stages (shown in Figure 1). For each stage, she can choose either L or R. Assume that the preference order (from most preferable to least preferable) among the four outcomes is RR,LL,RL,LR. Now consider two cases:\nCase 1. At the start, Alice sees two paths, LR and RL. She chooses R since it initiates RL which is preferable to LR. At the second-stage, Alice then foresees RR and RL. She happily makes the best decision RR.\nCase 2. Alice sees more, e.g., LL, LR, and RL, immediately at the first stage. Therefore she thinks that L is a better initial choice than R. Consequently, at the second-stage, she can only choose from LL and LR.\nConclusion: Even though Alice could see more in Case 2, she ultimately obtains a less preferable outcome.\nThis example demonstrates some of the crucial features that govern SSDM situations: 1) What an agent can foresee plays a crucial role in the decision-making process, since her sight determines the set of available choices. 2) Sight also updates her preferences over the options, and thereby the outcomes obtained in rational play. 3) Although in Case 2, Alice does not get the best result, we can say that, given her sight, she plays optimally in a local sense. In other words, this is a rational plan for her, even though it is not equivalent to the rational outcome of classical decision theory or game theory [29].\nIn this paper, we address all three challenges, but first we clarify our approach. To focus on sight, we ignore other factors such as the probability of moves by Nature. Also, we model the outcome of a decision as completely determined, or in other words, possible outcomes for each alternative and the probability corresponding to each outcome are encapsulated as a black box."
    }, {
      "heading" : "2 Modeling Single-agent sequential decision-making",
      "text" : "We begin by defining a structure called preference-sight tree for modelling single-agent sequential decision-making (SSDM) processes. Using this model, we then clarify the role that sight plays by discussing a series of changes it produces in agent’s preferences, decision-making procedures and their outcomes."
    }, {
      "heading" : "2.1 Models",
      "text" : "There are two kinds of models for decision-making scenarios corresponding to two perspectives. One is an explicit model from the perspective of Nature, or an outsider/designer; the other is the implicit model from the perspective of the agent involved, or an insider/decider. The former is complete and perfect in the sense that the outsider holds a full view of all the options together with the objective quality of these options, and thus can explicitly specify the reward of each situation for the decision-maker. In contrast with this, the latter’s views are possibly limited to a near future, especially in large-scale surroundings. Moreover, owing to limited foresight, the agent may also reason mistakenly about the quality of different choices, leading to what we call subjective preference.\nBoth the above perspectives are essential: the former offers a whole picture of the environment, the latter shows the actual play of the decider. In this section, we first introduce an explicit model of preference trees. After this, by endowing such trees with the agent’s view of the process and his/her subjective preference in this view, we formulate an integrated model of preference-sight trees which allows us to model both perspectives together."
    }, {
      "heading" : "2.1.1 Preference trees (P trees)",
      "text" : "A preference tree is a decision tree with only two elements: histories and preferences. Each history corresponds to a situation resulting from previous decision actions, and a preference represents the objective quality of each of these situations. To ensure the existence of backward induction solutions, we confine ourselves to finite histories.\nDefinition 2.1 (Preference tree) A preference tree is a tuple T = (H, ) where\n• H is a non-empty set of finite sequences of actions, called histories. ◦ The empty sequence ε is a member of H; ◦ If (ak)k=1,...,K ∈ H and L < K then (ak)k=1,...,L ∈ H; • is a total order over H. Let A denote the set of all actions. Any history h can be written as a sequence of actions: (ak)k=1,...,n, where each ak ∈ A. If there is no an+1 s.t. (ak)k=1,...,n+1 ∈ H, then history (ak)k=1,...,n is a terminal one. The set of terminal histories is denoted Z. The set of actions that are available at h is denoted A(h)⊆ A. For any histories h,h′, if h is a prefix of h′ we write h h′. The strict part of is , with h1 h2 if h1 h2 and not h2 h1 for any two histories h1 and h2. Accordingly, h1 ∼ h2 iff h1 h2 and h2 h1.\nSeveral remarks need to be made on the role of preference relations in the above definition: (1) Instead of defining preference merely over terminal histories, we have defined it over all histories, an idea going back to [19]. Here preference over intermediate histories is necessary for our aim of modelling an agent’s decision-making under limited foresight, which usually consists of intermediate histories.\n(3) For convenience, we do not strictly differentiate the two main views of preference: qualitative and quantitative. Although we use qualitative order generally, we sometimes switch to numerical payoff when it is advantageous.1"
    }, {
      "heading" : "2.1.2 Preference-sight Trees (P-S trees)",
      "text" : "P tree is an explicit model for decision-making scenarios which is independent of an agent. However, for an agent, the tree may appear differently in his/her limited view. [14] proposes the idea of short sight, where the authors use a sight function to denote the set of states that players can actually see at every position in an extensive game. Let us start by adapting their technique to preference trees.\nDefinition 2.2 Let T = (H, ) be a preference tree. A sight function for T is a function s : H→ 2H\\{ /0} satisfying s(h)⊆ H|h and |s(h)|< ω , where H|h represents the set of histories extending h. As a special case, h ∈ H|h.\nIn words, the function s assigns to each history h a finite subset of all available histories extending h.\nThe first effect that sight produces is as follows: Given a P tree, for any history h, a sight function always gives us a restricted tree.\nDefinition 2.3 Let T = (H, ) be a preference tree. Given any history h of T , a visible tree Th of T at h is a tuple (Hh, h), where Hh = s(h), i.e., Hh captures the decider’s view of the decision tree; h represents the subjective preference over Hh.\nA visible tree is actually an implicit model in our earlier terms. Hh also contains a set of terminal histories Zh, which are those without successors in s(h). Note that typically, the Zh are non-terminal for T .\nFurther, the preference order h is different from the objective preference . In fact, the formation of h is an update via a bottom-to-top process in terms of an agent’s sight. This updating process involves leaving the payoffs of Zh as the same as their objective payoffs, then updating the payoffs of other histories in Hh backwards, starting from the leaf nodes and proceeding towards the root of the tree.\nThe reason why we employ such an updating process is that, while the objective payoffs reflect the goodness of these situations, they are not the actual reward that an agent can get if he/she chooses this option. At each decision point, the subjective payoff of one available option is inherited from the best reachable terminal histories of the current visible tree. Therefore, the preference relation h in Th is not always consistent with the preference relation in T .\nThis updating process is described by Algorithm 1:\n*For convenience, here we use payoffs P to represent rewards.\nFact 2.1 Let T = (H, ) be a P tree. Each visible tree Th = (Hh, h) is a P tree.\nCorrespondingly, we denote the prefix relation in Th by h, and the actions that are available at h by Ah(h).\nFinally we proceed to define our model of preference-sight trees. A preference-sight tree allows us not only to represent the outsider’s view, i.e., (H, ), but also to derive a series of implicit models, i.e., (Hh, h), one for each h.\n1There is a debate on whether preference and utilities are the same [18, 7]. Here we adopt the operational understanding of utility and do not distinguish it from preference.\nAlgorithm 1: Preference updating in visible trees 1 PU(T,h,s)\nInput: A P tree T = (H, ) (or T = (H,P)), current history h, and a sight function s Output: A visible tree Th = (Hh, h) or (Th = (Hh,Ph))\n2 begin 3 H ∩ s(h)→ Hh; 4 for any z ∈ Zh /* Keep the payoffs of terminal histories unchanged */ do 5 P(z)→ Ph(z); 1→ flag[z]; 6 while flag[h] == 0 do 7 for any h′ ∈ Hh do 8 if (for all (h′a) ∈ Hh, flag[(h′a)] == 1) /* If all of its children have been visited, reset its payoff as the highest one among them */ 9 then\n10 max{Ph(h′a)}→ Ph(h′); 1→ flag[h′];\n11 Return Th;\nDefinition 2.4 (Preference-sight tree) A preference-sight tree (P-S tree) is a tuple (T,s), where T = (H, ) is a preference tree and s a sight function for T .\nIn P-S trees, an agent’s sight should satisfy the following properties: First, if an agent can see a given future history, then he/she can also see any intermediate history up to that point. Second, if the agent can see a history two steps forward, then after moving one step ahead, he/she can still see it. These features are formally stated as follows.\nFact 2.2 (Properties of sight function) Let (T,s) be a P-S tree. For all h,h′,h′′ ∈ H, with h h′ h′′, s satisfies :\nDC (Downward-Closed): if h′′ ∈ s(h), then h′ ∈ s(h).\nNF (Non-Forgetting): if h′′ ∈ s(h), then h′′ ∈ s(h′)."
    }, {
      "heading" : "2.2 Solution concepts",
      "text" : "Solution concepts are at the center of all choice problems. In what follows, we define two solution concepts for P-S trees, adapted from [30, 14]. After this, we investigate the conditions for their equivalence."
    }, {
      "heading" : "2.2.1 BI history and SCBI history",
      "text" : "Backward Induction (BI) is well-known in game theory [30]. The process runs like this. First, one determines the optimal strategy of the player who makes the last move of the game. Using this information, one can then determine the optimal action of the next-to-last moving player. The process continues backwards in this way until all players’ actions have been determined in the whole game. Its adaptation to single-agent decision-making process becomes a maximality problem for the agent involved.\nIn a P-S tree, we say that one history h is max in a set of histories Γ⊆H, if h ∈ Γ and for any other history h′ in Γ, it holds that h h′, and we write this as h ∈ max Γ. The strict part for max is max .\nDefinition 2.5 (BI history) Let (T,s) be a P-S tree. A history h∗ ∈ Z is a BI history of T , iff h∗ ∈max Z. Also, we use BI to denote the set of BI histories in T .\nA BI history of a P-S tree is a terminal history that is most preferable or equivalently, that has a maximal payoff.\nBackward induction precludes short-sight, while in practice it is impossible for an agent to foresee all final outcomes all the time. In [14], a new solution concept was proposed to capture optimal play of short-sighted players: sight-compatible subgame perfect equilibrium. The main idea is that at each decision point, the current player chooses a locally optimal move by a local BI analysis within the visible part. Here, we adapt this notion to P-S trees, yielding the sight-compatible backward induction history.\nDefinition 2.6 (SCBI history) Let (T,s) be a P-S tree. A history h∗ ∈ Z is a Sight-Compatible Backward Induction history (SCBI history) of T , iff for each history h with h h∗, and the action a following h, i.e., (ha) h∗, we have that ∃z ∈max Zh such that (ha) z. Also, we use SCBI to denote the set of SCBI histories in T .\nThe difference between SCBI and BI histories is obvious. A BI history is one with highest payoff among the set of terminal histories in the P-S tree, while for a SCBI history every restriction of it should be a local BI history for the visible tree. Thus, BI histories are the BI outcomes for the objective model (H, ), while SCBI histories are a combination of best responses to all subjective models (Hh, h). Typically it is the case that SCBI 6= BI.\nExample 2.1 Consider the P-S tree (T,s) in Figure 2, where s(ε) = {L}, and s(L) = {LR}. It is easy to check that BI 6= SCBI, since BI = {LL}, while SCBI = {LR}.\nHowever, sometimes the two notions can be equivalent.\nExample 2.2 Consider a P-S tree, with T and s shown by Figure 3 (a), and Figure 3 (b) respectively. In (b) the three dotted circles represent s(ε), s(L) and s(R). For histories L and R, their objective payoffs in (a) are 1 and 2, respectively. However, in Tε , the subjective payoff of L is updated to 3 and R to 2. Obviously, BI = SCBI = {LL}."
    }, {
      "heading" : "2.2.2 Equivalence condition",
      "text" : "Then an interesting question on BI and SCBI histories arises: are there conditions under which the two will be equivalent? To get a feeling for this, a first attempt at an answer looks for a condition related to consistency between subjective and objective preferences.\nTwo histories are said to be ‘preference-sight consistent’ if the subjective preference in each sightrestricted tree is consistent with the objective preference over them: Definition 2.7 (Preference-sight consistency) Let (T,s) be a P-S tree, and Th be the visible tree at an arbitrary history h. Then for any two histories h1, h2 of Th, we say (h1,h2) satisfies preference-sight consistency at h iff\nh1 h2 iff h1 h h2 If for any history h ∈ T , the pair of arbitrary two histories (h1,h2) in Th is preference-sight consistent\n(at h), then we say (T,s) is preference-sight consistent.\nIs preference-sight consistency an appropriate condition for BI = SCBI? We have the following observation:\nFact 2.3 Preference-sight consistency does not guarantee that BI = SCBI.\nProof 2.4 Consider Figure 2. Suppose that s(R) contains only one successor. Then it is easy to see that (T,s) is preference-sight consistent. However, BI 6= SCBI.\nNext, does the other direction hold? Fact 2.5 Preference-sight consistency does not follow from BI = SCBI.\nProof 2.6 The situation in Figure 3 is a counterexample, in which BI = SCBI = {LL}, but (T,s) is not preference-sight consistent, since R L and L ε R.\nWhat is the exact condition for BI = SCBI? From the failure of preference-sight consistency, we can draw a lesson. In Figure 2, the main reason for (T,s) being inconsistent is that at history L, the branch LL, which in fact forms a BI history, is non-observable to the agent. This tells us that the one with maximal payoff should always be visible. Consider then the example in Figure 3. Here all the options are within agent’s sight, but we notice that although the path LL following L finally turns out to be better than that following R, which makes subjectively L ε R, the objective payoff of L itself is lower than R. Thus, it fails to imply the consistency between preference and sight.\nBased on the above analysis, we now isolate necessary and sufficient conditions for BI = SCBI. First, we define an auxiliary property of sight-reachability, which intuitively reflects whether each restriction of a history is visible. Definition 2.8 (Sight-reachability) A BI history h∗ is sight-reachable if, for all (ha) h∗, we have (ha) ∈ Hh, where h,h′ are histories, and a is an action following h. Theorem 2.7 (Equivalence Theorem) For any P-S tree (T,s), SCBI= BI iff the following conditions are satisfied:\nI). Any history h∗ ∈ BI is sight-reachable. II). Any history h∗ ∈ BI is locally optimal: For any history (hh′) h∗, if (hh′) ∈ Zh, then (hh′) ∈\nmax Zh and for any other (hh′′) ∈ Zh, (hh′)∼ (hh′′) iff ∃z ∈ BI such that (hh′′) z.\nProof 2.8 (⇒) I). We show that every h∗ ∈ BI is sight reachable. That is, for all (hh′) h∗, it holds that (ha) ∈ Hh. By SCBI= BI, we know that any history h∗ in BI, is also in SCBI. By Definition 2.6, for each of its prefix h, h∗h is max in Zh. So h ∗ h is in Zh. In addition, by non-emptiness of\nZh, h∗h is not an empty sequence. Thus, for all (ha) h ∗, it holds that (ha) ∈ Hh. So h∗ ∈ BI is sight-reachable.\nTo show condition II), take any h∗ in BI, we have that it is in SCBI. Thus, for all (hh′) h∗, if (hh′) ∈ Zh, then (hh′) is max in Zh. Moreover, for any (hu) ∈ Zh such that (hh′)∼ (hu), we have (hu) is a prefix of a BI history, i.e., (hu) ∈ BIh. For suppose not, then (hu) is not a prefix of SCBI history. Then it must be (hh′) (hu). Contradict.\n(⇐) Suppose conditions I) and II) are satisfied. It suffices to show (a)“every BI history is SCBI history of T ”, and (b) “ every SCBI history is BI history of T ”.\nFor (a), take any BI history h∗. By I), all BI histories are sight reachable. Further by II), for all (hh′) h∗, if (hh′) ∈ Zh, then (hh′) is max in Zh. This is to say that for each of its prefix h, h∗h is max in Zh. By definition 2.6, h∗ is a SCBI history. For (b), take any SCBI history h∗. We can show it is a BI history, i.e., h∗ is max in Z. For suppose not, then there exists a BI history h′ such that h′ h∗. Notice that there must be some history u which is the common prefix of h∗ and h′. Since h′ is a BI history, by condition I) and II), we know that h′u h∗u. Then h∗u is not a prefix of a SCBI history. Thus, h∗ is not a SCBI history. Contradiction."
    }, {
      "heading" : "2.2.3 More sight, better outcome?",
      "text" : "We have seen earlier on that, SCBI may loss global optimality. The BI history definitely has a maximal payoff, while it might not be the case for SCBI, since each action is chosen with a limited sight. So BI SCBI holds without exception, in the sense that any BI history is no worse than any SCBI history. One might conjecture that more sight always contributes to better outcomes. Yet, the fact below falsifies this.\nFact 2.9 Let T be a P tree. Also, let s1 and s2 be two sight functions for T satisfying s1(h) ⊆ s2(h) for any history h in T . Take any two SCBI histories z1 and z2 of (T,s1) and (T,s2) respectively. Then the following three cases are all possible: a) z1 z2; b) z2 z1; c) z1 ∼ z2.\nProof 2.10 Case (a) has been shown in Example 1.1. Case (b): Obviously, Figure 2 offers an instance for this. Case (c): The scenario depicted in Figure 3 is an example.2\nIn conclusion, full sight guarantees a maximal payoff. However, with short sight, increase of sight does not always improve the outcome. The added sight may bring misleading information, e.g., a branch which is temporarily nicer but actually unpromising, and finally gives rise to an even worse outcome. Still, this does not mean that SCBI is deficient: rather, these observations seem realistic for real agents. These issues will be discussed further in Section 4."
    }, {
      "heading" : "3 A Logical Analysis",
      "text" : "After modelling decision-making with short sight by preference tree models, it is instructive to see what a logical language looks like for reasoning about these models, especially the role of sight in a SSDM process. So far, no such logic has been proposed, though logics of game-theoretic structures have been extensively studied – see [22, 20] – while there are a few preliminary logic analyses of sight on its own, [10, 27]. In this section, we design a minimal and natural logical system that supports reasoning about sight in the context of single-agent decision-making processes, characterizing basic properties of preference-sight trees, and formally capturing the results in the previous section."
    }, {
      "heading" : "3.1 Syntax and Semantics",
      "text" : "To reason about the key ingredients (i.e., histories, preferences, and sights) of a P-S tree, we take P(T,s) as a set of propositional letters, which at least contains the following 2:\n• h for each history h.\n• h1 ≥ h2 encoding the preference relation of the agent over all histories, and the strict part of which is h1 > h2.\n• s(h) encoding the sight at each history h in T .\nBased on P(T,s), we give a language L for reasoning about P-S trees. In L , we have a key dynamic operator [!ϕ] for restricting to the worlds satisfying ϕ , and a universal modality with Aϕ saying that ϕ is true in every world.\nDefinition 3.1 (Preference-sight language) Take any set of atomic letters P(T,s). The preference-sight language L is given by the following BNF, where p ∈ P(T,s):\nϕ ::= p |¬ϕ |ϕ ∧ψ |[!ϕ]ψ | Aϕ.\nWe write 〈!ϕ〉ϕ to abbreviate ¬[!ϕ]¬ϕ .\nDefinition 3.2 (Preference-sight models) For a P-S tree (T,s), a preference-sight model M(T,s) is a tuple (H, ,V ) where the following holds:\n• H is the set of possible worlds, one for each history, • is the reachability (prefix) relation among worlds, • V : PT → ρ(H) is an evaluation function satisfying: (1) ∀h ∈ H, V (h) = {h′|h′ h}.\n(2) V (h1 ≥ h2) = { H, IF h1 h2, /0, Otherwise. (3) ∀h ∈ H, V (s(h)) = ⋃\nh′∈s(h) V (h′).\nIntuitively, h is true at all the worlds leading to h. h1 ≥ h2 is true everywhere if h1 h2, and nowhere otherwise. Finally, V (s(h)) is a union of the worlds that make the given atom true for at least one element of s(h).\nThere seems to be nothing striking in this syntax. However, given the special role of atoms, the natural model update differs from the usual one in dynamic-epistemic logic.\nDefinition 3.3 (Model update) Given a preference-sight model M(T,s) = (H, ,V ) and a set X ⊂ H, the updated model M(T,s)!X produced by the restriction of X is defined as a tuple (X , ∩X2,V!X), where 3\nV!X(p) = { V!X(h1 ≥ h2), IF p is of the form h1 ≥ h2 V (p)∩X , Otherwise\n2The idea of defining h is motivated by [1], where the authors define an atomic sentence o for each leaf in a game tree. 3In this definition, ZX denotes the terminal histories in X , i.e., the set of histories that have no successors in X .\nV!X(h1 ≥ h2) =  X , IF V (z1 ≥ z2) = H, where z1 ∈ max {z ∈ ZX |h1 z}, z2 ∈ max {z ∈ ZX |h2 z}\n/0, Otherwise\nM(T,s)!X is the update of the model M (T,s) restricting the set of states to X , and the valuation function accordingly. But crucially, the valuation for preference atoms in the new model reflects the updating process in the visible tree of Algorithm 1. In the following, we omit superscripts (T,s).\nThe semantics for this language is basically standard, [8], so we only mention the truth condition of [!ϕ]ψ:\nLet M be a preference-sight model. For any state h in M,\nM,h |= [!ϕ]ψ iff M,h |= ϕ ⇒M!ϕ ,h |= ψ.\nValidity of formulas is defined as usual, cf. [8]."
    }, {
      "heading" : "3.2 Main characterization results",
      "text" : "Despite its simplicity, L can express our results in previous sections concerning properties and solutions of P-S trees. We introduce some helpful syntactic abbreviations, and then state our main characterization results.\n• Zh = ∨ { z | z ∈ Zh}.\n• max≥X= ∨ { h | h ∈ X , and h h′ for ∀h′ ∈ X}.\n• BI = ∨ { z | z ∈ BI} (BI holds at T ’s BI histories).\n• SCBI = ∨ { z | z ∈ SCBI}, that is, the formula SCBI holds at the SCBI histories of T .\nProposition 3.1 Let (T,s) be a P-S tree and M be a L -model for it. Then (T,s) is preference-sight consistent iff the following formula is valid in M:∧\nh ∧ h1∈Hh ∧ h2∈Hh ((h1 ≥ h2→ [!s(h)]h1 ≥ h2)∧\n(〈!s(h)〉h1 ≥ h2→ h1 ≥ h2))\nLemma 3.2 For any P-S tree (T,s) and model M for it, a BI history h∗ is sight-reachable if and only if the following formula holds in M:\n(SR) : ∧ h ∧ a∈A(h) (A((ha)→ h∗)→ (A((ha)→ s(h)))).\nProof 3.3 (⇒) Suppose that BI history h∗ is sight-reachable. By Definition 2.8, we have that, for all (ha) h∗, it holds that (ha) ∈ s(h), where h,h′ are histories, and a is an action following h. More formally, (ha) h∗ can be defined by the formula A((ha)→ h∗) in the sense that, in T , for all h and a ∈ A(h), (ha) h∗ iff M |= A((ha)→ h∗). And similarly (ha) ∈ s(h) is defined by A((ha)→ s(h)). Thus if a BI history h∗ is sight-reachable, then M |= ∧ h ∧\na∈A(h)(A((ha)→ h∗)→ (A((ha)→ s(h)))). The other direction can be proved in a similar way. 2\nLemma 3.4 Let (T,s) be a P-S tree and M be a L -model for it. A BI history h∗ is locally optimal iff the following formula is valid in M:\n(LO) : ( ∧ h ∧ (hh′)∈Zh (A((hh′)→ h∗)→\n(A((hh′)→max Zh)∧∧ (hh′′)∈Zh ((hh′)∼ (hh′′)↔ ∨ z∈BI (A((hh′′)→ z))))).\nProof 3.5 (⇐) Suppose BI history h∗ is locally optimal. Then for (hh′) h∗, if (hh′) ∈ Zh, we have (hh′) is max in Zh. And for any (hh′′), (hh′′) ∼ (hh′) iff ∃z ∈ BI s.t. (hh′′) z. Similar with the above proposition, A((hh′)→ h∗) captures that (hh′) h∗. And A((hh′′)→ z) shows that (hh′′) z. Finally, ((hh′)→max Zh) demonstrates that (hh′) is max in Zh. Direction (⇒) uses a similar check.\nProposition 3.6 (L -characterization of equivalence) Let (T,s) be a preference-sight tree and M a model for it. Then the following formula is valid in M:\n|= (A(BI↔ SCBI))↔∧ h∗∈Z ((A(h∗→ BI))→ (SR∧LO))\nProof 3.7 Direction (⇒). We need to prove the following: 1) (A(BI↔ SCBI))→ ∧ h∗∈Z(A(h∗→ BI)→ SR).\n2) (A(BI↔ SCBI))→ ∧\nh∗∈Z(A(h∗→ BI)→ LO). For 1). It is equivalent to prove that, for any h∗ ∈ Z, (BI↔ SCBI)∧(A(h∗→BI))→ SR. Suppose ¬(SR). Then ∃(ha) h∗, and (ha) /∈ Th, and so, at h, the branch leading to h∗ is not visible in Th. Thus, the BI history in Th could not be a branch leading to h∗. By the definition SCBI, it follows that h∗ /∈ SCBI. However, by h∗→ BI we know that h∗ is a BI history. This contradicts BI↔ SCBI.\n2) can be proved in a similar style.\nDirection (⇐). Suppose that ¬(A(BI↔ SCBI)). Then (a): ∃z∗ ∈ BI and z∗ /∈ SCBI, or (b) : ∃z∗ ∈ SCBI and z∗ /∈ BI.\nIf (a), then, by the antecedent, we have that: ∀(ha) z∗,(ha) ∈ Hh. Also, ∀(hh′) ∈ Zh and (hh′) h∗, it holds that (hh′) ∈max Zh. Then it directly follows that z∗ is a SCBI history. Contradiction.\nIf (b), then take any z ∈ BI, which shares a prefix u with z∗, i.e., u z and u z∗. By the antecedent, we have zu ∈ max Zh. Since z∗ /∈ BI, it follows that zu > z∗u. Then z∗ /∈ SCBI. Once more, we have a contradiction. 2"
    }, {
      "heading" : "3.3 Valid principles",
      "text" : "The operator [!ϕ] makes L a PAL-like language. However, the special model-update makes it different from standard PAL [11]. This suggests a close look at what is and what is not valid in preference-sight models.\nFirst, some axioms in standard PAL do not hold in preference-sight models. For example, the !ATOM axiom, [!ϕ]p↔ (ϕ → p), is not valid when it is of the form below.\nProposition 3.8 The following is not valid in preference-sight models, where h,h1,h2 represent arbitrary histories.\n!Sight-Preference : [!s(h)]h1 ≥ h2↔ (s(h)→ h1 ≥ h2).\nProof 3.9 For a counterexample, consider the tree T in Figure ??. It is easy to see that in the model M for T , M |= [!s(ε)]h1 ≥ h2 and M 2 s(ε)→ h1 ≥ h2, since there exists a state ε such that M,ε |= s(ε) and M,ε 2 h1 ≥ h2.\nThis proposition says that subjective preference in visible trees is not necessarily consistent with objective preference.\nNow let us see some interesting valid principles and their intuitive interpretations.\nLemma 3.10 The formulas shown in Table 1 are valid, where h,h1,h2, and h3 are arbitrary histories.\nProof 3.11 We only prove some cases, proofs for the others are trivial or standard. For Ts. Take any state u with M,u |= h. Then u∈V (h). As the sight function is reflexive, i.e., h∈ s(h), it holds that V (h)⊆ V (s(h)). So u ∈ V (s(h)). Thus, M,u |= s(h). For T M. Take any state u, any history h and any z ∈ Z, and suppose M,u |= A(z→ h). Then for any u′, u′ ∈ V (z) implies that u′ ∈ V (h). Thus, V (z) ⊆ V (h). It follows that z ∈ V (h). Given that z is terminal, by the definition of V (h), it must be that h = z. Thus, M,u |= A(h→ z).\nFor DC. Take any state u, suppose for some h1 h2 h3, M,u |= A(h3 → s(h1)). Then we know V (h3) ⊆ V (s(h1)). It follows that h3 ∈ s(h1). As the sight function is downward closed, we have h2 ∈ s(h1). Thus, M,u |= A(h2→ s(h1)).\nFor !ATOM\\SP. Take any state u, and let M,u |= [!ϕ]p where ϕ is not of the form !s(h) and p is not of the form h1 ≥ h2. It holds that M,u |= ϕ implies that M!ϕ ,u |= p. By Definition 3.3, M!ϕ ,u |= p iff M,u |= p. Therefore, M,u |= ϕ implies M,u |= p. Equivalently, then, M,u |= ϕ → p. 2\nInterpretation of valid principles. Each of these axioms has some intuitive appeal. T≥, 4 and to≥ show the reflexivity, transitivity and totality of the preference relation, respectively. Likewise, Ts says that sight is reflexive. DC characterizes the (downward-closure) property of sight. NF encodes the nonforgetting property of sight. TM guarantees that terminal histories of the P-S tree are actually terminal. One further interesting point is that there is no correspondence of TM for terminal histories of visible trees.\nFact 3.12 The following formula is not valid in preference-sight models:∧ u ∧ z∈Zu ∧ h(A(z→ h)→ A(h→ z)).\nOther validities in the table are axioms for standard PAL. We postpone the study of a complete axiomatization of the logic L until future work.\nTo conclude this section, in L , the ingredients including histories, preferences and sights are encoded as primitive propositions. Various earlier phenomena in P-S trees can thus be captured in a simple, direct and intuitive manner. This special-purpose logic, as we will see soon, is model-dependent, but it can also be formulated generically."
    }, {
      "heading" : "4 Background in game logics",
      "text" : "In this section, we relate our logic L to existing logics for classical game theory, showing how ideas can be combined where useful. Since so far we have been working with BI and SCBI histories, we first define strategies for P-S trees: A strategy for a P-S tree (T,s) is a function σ : H → A such that σ(h) ∈ A(h). That is, σ assigns each history h an action that follows h. In particular, for a visible tree Th, a ‘local strategy’ σh is a restriction of σ to Th, such that σh(h′) = σ(h′) for any h′ ∈ Th."
    }, {
      "heading" : "4.1 Generic formulation of L",
      "text" : "In applied logic for structure analysis, there exist two extremes, viz. model-dependent ‘local languages’ and ‘generic languages’ that work across models. For a generic logic, a definition of a property π is a formula ϕ such that for all models M, M has property π iff M |= ϕ . For a local language, such a formula can depend on a given model M: there exists a formula ϕM which depends on M, such that any model M has the property π iff M |= ϕM. However, in this case, the defining formula can be trivial. For example, one might define ϕM simply as follows.\nϕM = { >, if M satisfies π ⊥, Otherwise\nIn this subsection, using a well-known Rationality property as an example, we discuss how modeldependent our earlier language L is, and then show how it can be formulated in a generic way. We first recall the results on classical BI. Given that we have been dealing with single-agent cases until now, in this Section, we will adapt the results from the literature on multi-player games to the single-player case.\nThe BI strategy [2, 3] is the largest subrelation σ of the total move relation that has at least one successor at each node, while satisfying the rationality (RAT) property:\nRAT No alternative move for the player yields an outcome via further play with σ that is strictly better than all the outcomes resulting from starting at the current move and then playing σ all the way down the tree.\nAs argued in [2, 3], this rationality assumption is a confluence property for action and preference:\nCF ∀x∀y(xσy→∀z(x move z→ ∃u(end(u)∧ yσ∗u∧∀v((end(v)∧ zσ∗v)→ u≥ v))))\nWe can observe that there is also a corresponding rationality property for the local BI strategies that constitute an SCBI, which should however now express a confluence property for action, preference and sight. Specifically, for a P-S tree, each local BI strategy for the visible tree Th at h is the largest subrelation σh of the total move relation in Th, satisfying 1) σh has at least one successor at each h′ ∈ Th, and 2) the following rationality property holds:\nRATS In the visible tree, there is one outcome obtained by playing σh from the start to the end, that is no worse than all the outcomes yielded from any alternative first move followed by further play with σh.\nThis confluence property involving sight is expressible as follows in our language L :\nProposition 4.1 Let (T,s) be a P-S tree, and let M be any model for it. M satisfies RATS iff M validates the following L -formula, where σh is the BI strategy for visible tree at h and where (h(σh)k) stands for the history reached from h after executing σh for k times.\nCFSM ∧ h ∨ z∈Zh ∨ k=l(z)−l(h) (A((h(σh)k)↔ z)\n→ ( ∧\na′∈Ah(h) ∧ z′∈Zh ∧ m=l(z′)−l(ha′) (A((ha′(σh)m)↔ z′))→\nz≥ z′)),\nProof 4.2 We first claim that at state h ∈ H, for any terminal history z ∈ Zh, and h′ ∈ Hh, A(h′ ↔ z) implies that h′ = z. This is straightforward since A(h′ ↔ z) demonstrates that prefixes of h′ are the same with those of z, which means that h′ = z. Then M |= CFSM says that there is a terminal history zh following h by playing a local BI strategy σh, such that z z′ for any other z′ ∈ Zh which follows an alternative first move a′ ∈ Ah(h) via further play of σh. Therefore, we know that M satisfies RATS. 2\nHowever, compared with the generic logic in [4, 3, 2], the given definition in our logic is local. It is obvious that CF, the formula defining the property RAT, is insensitive to models – while our CFSM relies on a given model for its ranges of big disjunctions and conjunctions, and in its model-dependent notations like s(h) and h1 ≥ h2. Still, it is also clearly true that our definition is not as trivial as the earlier local trick. Therefore, our logic L seems somewhere between the two extremes of locality and genericity. This feeling can be made precise by moving to a closely related truly generic first-order logic.\nThe relevant modified formula involves some natural auxiliary predicates. x y says that x is a prefix of y; x^y means that x can see y. Corresponding to the BI relation σ , yσ(x)z says that from y, z is a local backward induction move in the visible tree at x; σ k describes σ being composed for k times with k ∈ N 4; move and ≥ are still the move relation and preference relation, respectively, of the game.\nProposition 4.3 Any model M satisfies RATS iff it validates the following formula.\nCFS(FO): ∀x{(∃y(x y))→ ∀u[(xσ(x)u)→∀t((x move t ∧ x^t)→\n∃z((x^z∧¬∃z′(z z′∧ x^z′)∧∃k(u(σ(x))kz))∧ ∀v((x^v∧¬∃v′(v v′∧ v^v′)∧∃l(t(σ(x))lv))→\n∧z≥ v)))]}. 4Here xσ ky is the abbreviation of ∃y1∃y2 · · ·∃yk(xσy1∧ y1σy2∧·· ·∧ yk−1σyk ∧ (yk = y)).\nProof 4.4 It is easy to show that M |= CFS(FO) iff M |= CFSM.2\nIn summary, incorporating basic elements of P-S trees directly into first-order syntax makes L intuitive and natural.\nEven so, other logics exist for dealing with further aspects of game trees and solution procedures, and we will discuss a few examples in what follows with a view to how they behave in the presence of sight."
    }, {
      "heading" : "4.2 Solution procedures and fixed-point logics",
      "text" : "Recursive solution procedures naturally correspond to definitions in existing fixed-point logics, such as the widely used system LFP(FO). An LFP(FO) formula mirroring the recursive nature of BI is constructed in [4, 6] to define the classical BI relation, based on the above property RAT. Now, we have shown that sight-restricted SCBI, too, is a recursive game solution procedure. Can LFP(FO) be used to define SCBI as well – and if so, how?\nThe answer is yes, but we need an extension. Rather than a binary relation bi as in [4, 6], characterizing SCBI needs a ternary relation. First, we define the local BI relation in visible trees, which will be denoted by bisight. For any states x,y,z, bisight(x,y,z) means that in the visible tree at x, the local BI strategy is bisight, which chooses z when the current state is y. It is then obvious that bisight should satisfy the following simple first-order definable property, requiring the relevant states to be visible and reachable:\nbisight(x,y,z)→ see(x,y)∧ see(x,z)∧move(y,z).\nThe intuition of bisight(x,y,z) is then captured as follows:\n∀x∀y∀z(bisight(x,y,z)→∀t((see(x, t)∧move(y, t)) → (∃u(endsight(x,u)∧bi∗sight(x,z,u)∧∀v((endsight(x,v)∧\nbi∗sight(x, t,v))→ u≥ v))))).\nNotice that all occurrences of bisight in the above formulas are still syntactically positive. This allows us to define local BI strategy bisight with LFP(FO).\nProposition 4.5 The strategy bisight can be defined as the relation R in the following LFP(FO) formula.\nνR,xyz•∀x∀y∀z(R(x,y,z)→∀t((see(x, t)∧move(y, t)) → (∃u(endsight(x,u)∧R∗(x,z,u)∧∀v((endsight(x,v)∧\nR∗(x, t,v))→ u≥ v))))).\nIt can be proved formally that bisight is a greatest-fixed-point of the above formula. Based on bisight, we now proceed to show that the SCBI relation is LFP(FO) definable.\nCorollary 4.6 The SCBI relation scbi for a P-S tree can be represented in the following formula: ∀x∀y(scbi(x,y)↔ bisight(x,x,y)).\nAs in the original classical case, this LFP(FO) definability of scbi exposes an intersection between the logical foundation of computation and the recursive nature of sight-compatible backward induction solutions for P-S trees."
    }, {
      "heading" : "4.3 Modal surface logic of best action",
      "text" : "In contrast with detailed formalism of solutions with LFP(FO), there is the modal surface logic of [5], which enables direct and natural reasoning about best actions without considering the underlying details of recursive computation. First of all, we list its modalities for classical BI. [bi] and [BI] encode the BI move and BI paths respectively. [best]ϕ says that ϕ is true in some successor of the current node that can be reached in one step via the bi move.\nM,h |= end iff h ∈ Z. M,h |= [move]ϕ iff ∀ h′ = (ha) with a ∈ A(h), M,h′ |= ϕ . M,h |= [best]ϕ iff for all h′ with h′ ∈ bi(h), M,h′ |= ϕ . M,h |= [bi]ϕ iff for all h′ with h′ ∈ bi(h), M,h′ |= ϕ . M,h |= [bi∗]ϕ iff M,u |= ϕ for all u with u ∈ (bi)∗(h). M,h |= [BI]ϕ iff for all z with z ∈ BI, M,z |= ϕ .\nThe above logic is still applicable in our setting, but it requires substantial extension for sight-related concepts. In accordance with [bi] and [BI], we use [scbi] and [SCBI] as operators for the SCBI strategy and SCBI path, respectively. For the local BI strategy and path in visible trees, the modalities are [bisight] and [BIsight]. Moreover, recall that M!s(h) is the updated model obtained in the way of Definition 3.3.\nM,h |= [scbi]ϕ iff for all h′ with h′ ∈ scbi(h), M,h′ |= ϕ . M,h |= [SCBI]ϕ iff for all h′ with z ∈ SCBI, M,z |= ϕ . M,h |= [!sight]ϕ iff M!s(h),h |= ϕ. M!s(h),u |= endsight iff u ∈ Zh. M!s(h),u |= [movesight]ϕ iff for ∀u′ = (ua) with a ∈ Ah(u), M!s(h),u′ |= ϕ . M!s(h),u |= [bestsight]ϕ iff M,u′ |= ϕ for ∀u′ ∈ bih(u). M!s(h),u |= [bisight]ϕ iff M,u′ |= ϕ for ∀u′ ∈ bih(u). M!s(h),u |= [(bisight)∗]ϕ iff M!s(h),u′ |= ϕ for all u′, such that u′ ∈ (bih)∗(u). M,h |= [BIsight]ϕ iff for all z with z ∈ BIh, M,z |= ϕ .\nWe give a few illustrations of new issues that arise now.\nCapturing the SCBI strategy For a start, we are now able to characterize the SCBI strategy, in a similar vein as the frame correspondence for the classical BI strategy in [5]. Proposition 4.7 The BI strategy is the unique relation bi satisfying this modal axiom for all propositions p:\n(〈bi∗〉(end∧ p))→ ([move][σ∗](end∧〈≤〉p)) Along the same lines, we can express the SCBI strategy in P-S trees based on the idea that each scbi move coincides with a local BI move within the current visible tree. Proposition 4.8 The SCBI strategy is the relation scbi satisfying the following axioms for all propositions p:\n(1) 〈scbi〉p↔ [!sight]〈bisight〉p.\n(2) [!sight](〈(bisight)∗〉(endsight∧ p)→ [movesight]〈(bisight)∗〉(endsight∧〈≤〉p)).\nBest action and preference-consistency Turning to properties of frames for the extended modal logic of best action with sight, there are interesting differences when comparing SCBI and classical BI. To see this, we employ operators 〈best〉, 〈bestsight〉, 〈bi∗〉, 〈scbi∗〉 and (bisight)∗. Now we can make some interesting comparisons. Proposition 4.9 For classical backward induction, the axiom 〈best〉〈bi∗〉ϕ ↔ 〈bi∗〉ϕ holds.\nHowever, the new frames do not have the corresponding axiom for the SCBI strategy, since the actions it recommends are not necessarily the actual best actions according to BI. Even in visible trees, this is also not true. Proposition 4.10 The following formulas are not valid:\n(a) 〈best〉〈scbi∗〉ϕ ↔ 〈scbi∗〉ϕ. (b) [!sight](〈best〉〈(bisight)∗〉ϕ ↔ 〈(bisight)∗〉ϕ).\nNevertheless, there is a certain coherence between the local BI strategy and local best actions returned by it. Proposition 4.11 The following formula is valid: [!sight](〈bestsight〉〈(bisight)∗〉ϕ ↔ 〈(bisight)∗〉ϕ).\nAs for the preference relation, SCBI has a property that classical BI lacks: local BI moves never conflict with the preferences in submodels. In other words, within a visible tree, the initial move determined by the local BI strategy is more preferable for the agent than any other first move.\nProposition 4.12 For SCBI, it holds that [!sight](〈bestsight〉ϕ → [movesight]〈≤〉ϕ). For BI, although it returns a final optimal path, there is no guarantee that its intermediate histories be preferable. Proposition 4.13 For BI, the following does not hold: 〈best〉ϕ → [move]〈≤〉ϕ. Path terminality and optimality Using a similar style of modal analysis, we can make the following observations concerning the obvious operators [BI], [SCBI] and [BI]sight .\nProposition 4.14 We have the following three facts: (a) The formula[BI]ϕ → [BI][BI]ϕ is valid. (b) For SCBI, the following formula does not hold: [BIsight]ϕ → [BIsight][BIsight]ϕ. (c) The formula [SCBI]ϕ → [SCBI][SCBI]ϕ is valid.\nHere (a) says that from a BI outcome only a terminal history can be reached; (b) shows that the local BI history may not be a terminal history of the whole tree, and (c) says the SCBI history for the whole tree is always terminal.\nAnother phenomenon regarding these operators is the local optimality of SCBI at the cost of being more realistic than BI. We have mentioned this point already in Section 2.2.4: now we can present a precise formal version. Proposition 4.15 Let σ be any strategy profile, (a). For BI, the following is valid: 〈BI〉ϕ → [σ ]〈≤〉ϕ. (b). The following does not hold: 〈SCBI〉ϕ → [σ ]〈≤〉ϕ. (c). For SCBI, it holds that [!sight](〈BIsight〉ϕ → [σsight]〈≤sight〉ϕ).\nHere (a) shows the global optimality of the BI path. (b) and (c) together say the SCBI path is not globally optimal, but each move on this path leads to a locally optimal path.\nAltogether, this section has shown the broad logical foundations of our framework, embedding our local language in existing broader generic formalisms, but also enriching and extending these frameworks with aspects of short sight."
    }, {
      "heading" : "5 Toward Multi-player games",
      "text" : "While our models and results are about single-agent sequential decision-making processes, we believe they are applicable well beyond that. They can be naturally extended to multi-player extensive gamescenarios with short sight. For such a game model, we can build on [14], which makes an assumption that the current player only knows his own sight, and that he believes other players can see as much as he can see and will play according to this belief. That is, this model precludes more complex forms of interactive knowledge and reasoning. But using this same assumption, our model in this paper can be extended to multi-player cases directly. The only thing we have to do is add agent-labeling to SSDM: even though players can change with time, everything including sight, preference, and actions can be modeled from the current player’s perspective.\nWe will not state any results for the extended multi-player model since they are quite similar to what we have shown already. The case where we drop the above assumption and allow a more free modeling of players’ mutual knowledge and beliefs about sight and preference would be more interesting. We will leave this for future work."
    }, {
      "heading" : "6 Discussion and Conclusion",
      "text" : "Though motivated by single-agent decision-making process, we have gone towards a much more general goal In the process, our analysis significantly adds to current connections between logic, computation, and game solutions.\nIn many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16]. This approach generalizes the classical representation of extensive games by modeling players who may not be aware of all the paths. While [14] shows that games with short sight are a well-behaved subclass of games with awareness, there exists a fundamental difference in focus. Players in the latter approach may be unaware of some branches but they can always see some terminal histories, while in the former, players’ sight may only include intermediate histories, ruling out all terminal ones. Moreover, we have shown how short-sight games allow for a natural coexistence of two views of a game, that of insiders and that of outsiders. Having said this, it is clearly an interesting issue to see if our approach in this paper can be extended to cover awareness.\nAnother obvious interface for our logics are heuristic evaluation approaches for intermediate nodes used by the AI community for computational game-solving, [25, 12, 33]. This, too, is a connection that deserves further exploration.\nThere are many additional topics to pursue. We already mentioned multi-player scenarios with nontrivial interactive reasoning about other agents’ preferences, sights, and strategies. This has also been identified as a key task for epistemic game theory, [31]."
    }, {
      "heading" : "Acknowledgments",
      "text" : "I thank Fenrong Liu for our fruitful collaboration on earlier versions of this paper. Paolo Turrini provided crucial insights on short-sight games and their connections with games and computation, which we are partly exploring together. Sonja Smets provided helpful comments overall. But especially, I thank Johan van Benthem for our longstanding contacts on the logic of short-sight games: Section 4 of this paper owes a lot to his many suggestions and observations. This work is supported by the China Scholarship Council and NSFC grant No.61472369."
    } ],
    "references" : [ {
      "title" : "Keep ‘hoping’ for rationality: a solution to the backward induction paradox",
      "author" : [ "Alexandru Baltag", "Sonja Smets", "Jonathan A. Zvesper" ],
      "venue" : "Synthese 169(2),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2009
    }, {
      "title" : "Exploring a Theory of Play",
      "author" : [ "Johan van Benthem" ],
      "venue" : "Proc. of TARK,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2011
    }, {
      "title" : "Game Solution, Epistemic Dynamics and Fixed-Point Logics",
      "author" : [ "Johan van Benthem", "Amélie Gheerbrant" ],
      "venue" : "Fundam. Inform",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2010
    }, {
      "title" : "Preference logic, conditionals, and solution concepts in games",
      "author" : [ "Johan van Benthem", "Sieuwert Van Otterloo", "Olivier Roy" ],
      "venue" : "Modality Matters: Twenty-Five Essays in Honour of Krister Segerberga, University of Uppsala,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2006
    }, {
      "title" : "Toward a Theory of Play: A Logical Perspective on Games and Interaction",
      "author" : [ "Johan van Benthem", "Eric Pacuit", "Olivier Roy" ],
      "venue" : "Games 2(1),",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Decision Theory and Rationality",
      "author" : [ "J.L. Bermúdez" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2009
    }, {
      "title" : "Modeling and Solving Sequential Decision Problems with Uncertainty and Partial Information",
      "author" : [ "Blai Tirant Bonet Bretto" ],
      "venue" : "Ph.D. thesis, Department of Computer Science,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2004
    }, {
      "title" : "A Logic of Sights",
      "author" : [ "Cedric Degremont", "Soumya Paul", "Nicholas Asher" ],
      "venue" : "Journal of Logic and Computation",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2014
    }, {
      "title" : "Dynamic Epistemic Logic. Synthese library",
      "author" : [ "Hans van Ditmarsch", "Wiebe van der Hoek", "Barteld Kooi" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2007
    }, {
      "title" : "The Alpha-Beta Heuristic",
      "author" : [ "D. Edwards", "T. Hart" ],
      "venue" : "Technical Report 30,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1963
    }, {
      "title" : "Games with Unawareness",
      "author" : [ "Yossi Feinberg" ],
      "venue" : "Stanford Graduate School of Busirness Paper No",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2012
    }, {
      "title" : "Reasoning About Knowledge of Unawareness Revisited",
      "author" : [ "Joseph Y. Halpern", "Leandro C. Rêgo" ],
      "venue" : "Proceedings of the 12th Conference on Theoretical Aspects of Rationality and Knowledge,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2009
    }, {
      "title" : "Extensive Games with Possibly Unaware Players",
      "author" : [ "Joseph Y. Halpern", "Leandro C. Rêgo" ],
      "venue" : "Mathematical Social Sciences",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2014
    }, {
      "title" : "Extensive games with possibly unaware players",
      "author" : [ "Joseph Y. Halpern", "Leandro Chaves Rêgo" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2006
    }, {
      "title" : "Decision Theory -A Brief Introduction",
      "author" : [ "Sven Ove Hansson" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1994
    }, {
      "title" : "A Modal Characterization of Nash Equilibrium",
      "author" : [ "Paul Harrenstein", "Wiebe van der Hoek", "John-Jules Meyer", "Cees Witteveen" ],
      "venue" : "Fundam. Inf",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2003
    }, {
      "title" : "On modal logic interpretations of games",
      "author" : [ "Paul Harrenstein", "Wiebe Van Der Hoek", "John jules Meyer", "Cees Witteveen" ],
      "venue" : "Procs ECAI",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2002
    }, {
      "title" : "Dynamic unawareness and rationalizable behavior",
      "author" : [ "Aviad Heifetz", "Martin Meier", "Burkhard C. Schipper" ],
      "venue" : "Games and Economic Behavior",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2013
    }, {
      "title" : "Modal logic for games and information",
      "author" : [ "W. van der Hoek", "M. Pauly" ],
      "venue" : "Handbook of Modal Logic, Elsevier,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2006
    }, {
      "title" : "Sequential Decision Making with Adaptive Utility",
      "author" : [ "Brett Houlding" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2008
    }, {
      "title" : "Generating Scenario Trees for Multistage Decision Problems",
      "author" : [ "Kjetil Høyland", "Stein W. Wallace" ],
      "venue" : "Management Science 47(2),",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2001
    }, {
      "title" : "Properties of forward pruning in game-tree search. In: proceedings of the 21st national conference on Artificial intelligence - Volume 2, AAAI’06",
      "author" : [ "Yew Jin Lim", "Wee Sun Lee" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2006
    }, {
      "title" : "Algorithms for Sequential Decision-making",
      "author" : [ "Michael Lederman Littman" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1996
    }, {
      "title" : "A Logic for Extensive Games with Short Sight",
      "author" : [ "Chanjuan Liu", "Fenrong Liu", "Kaile Su" ],
      "venue" : "LORI, pp. 332–336,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2013
    }, {
      "title" : "A tutorial introduction to decision theory",
      "author" : [ "D. Warner North" ],
      "venue" : "IEEE Transactions on Systems Science and Cybernetics,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1968
    }, {
      "title" : "A Course in Game Theory. MIT Press. Available at https: //mitpress.mit.edu/books/course-game-theory",
      "author" : [ "Martin J Osborne", "Ariel Rubinstein" ],
      "venue" : null,
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 1994
    }, {
      "title" : "An Introduction to Decision Theory, 1 edition. Cambridge Introductions to Philosophy",
      "author" : [ "Martin Peterson" ],
      "venue" : null,
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.",
      "startOffset" : 173,
      "endOffset" : 200
    }, {
      "referenceID" : 19,
      "context" : "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.",
      "startOffset" : 173,
      "endOffset" : 200
    }, {
      "referenceID" : 24,
      "context" : "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.",
      "startOffset" : 173,
      "endOffset" : 200
    }, {
      "referenceID" : 14,
      "context" : "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.",
      "startOffset" : 173,
      "endOffset" : 200
    }, {
      "referenceID" : 6,
      "context" : "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.",
      "startOffset" : 173,
      "endOffset" : 200
    }, {
      "referenceID" : 22,
      "context" : "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.",
      "startOffset" : 173,
      "endOffset" : 200
    }, {
      "referenceID" : 20,
      "context" : "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.",
      "startOffset" : 173,
      "endOffset" : 200
    }, {
      "referenceID" : 6,
      "context" : "The current literature [9, 28] has studied uncertainty which an agent faces in recognizing possible outcomes after taking an action and the probabilities associated with these outcomes, as well as the partial observability of what the actual state is like.",
      "startOffset" : 23,
      "endOffset" : 30
    }, {
      "referenceID" : 24,
      "context" : "The current literature [9, 28] has studied uncertainty which an agent faces in recognizing possible outcomes after taking an action and the probabilities associated with these outcomes, as well as the partial observability of what the actual state is like.",
      "startOffset" : 23,
      "endOffset" : 30
    }, {
      "referenceID" : 15,
      "context" : "Several remarks need to be made on the role of preference relations in the above definition: (1) Instead of defining preference merely over terminal histories, we have defined it over all histories, an idea going back to [19].",
      "startOffset" : 221,
      "endOffset" : 225
    }, {
      "referenceID" : 14,
      "context" : "1There is a debate on whether preference and utilities are the same [18, 7].",
      "startOffset" : 68,
      "endOffset" : 75
    }, {
      "referenceID" : 5,
      "context" : "1There is a debate on whether preference and utilities are the same [18, 7].",
      "startOffset" : 68,
      "endOffset" : 75
    }, {
      "referenceID" : 25,
      "context" : "In what follows, we define two solution concepts for P-S trees, adapted from [30, 14].",
      "startOffset" : 77,
      "endOffset" : 85
    }, {
      "referenceID" : 25,
      "context" : "Backward Induction (BI) is well-known in game theory [30].",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 18,
      "context" : "So far, no such logic has been proposed, though logics of game-theoretic structures have been extensively studied – see [22, 20] – while there are a few preliminary logic analyses of sight on its own, [10, 27].",
      "startOffset" : 120,
      "endOffset" : 128
    }, {
      "referenceID" : 16,
      "context" : "So far, no such logic has been proposed, though logics of game-theoretic structures have been extensively studied – see [22, 20] – while there are a few preliminary logic analyses of sight on its own, [10, 27].",
      "startOffset" : 120,
      "endOffset" : 128
    }, {
      "referenceID" : 7,
      "context" : "So far, no such logic has been proposed, though logics of game-theoretic structures have been extensively studied – see [22, 20] – while there are a few preliminary logic analyses of sight on its own, [10, 27].",
      "startOffset" : 201,
      "endOffset" : 209
    }, {
      "referenceID" : 23,
      "context" : "So far, no such logic has been proposed, though logics of game-theoretic structures have been extensively studied – see [22, 20] – while there are a few preliminary logic analyses of sight on its own, [10, 27].",
      "startOffset" : 201,
      "endOffset" : 209
    }, {
      "referenceID" : 0,
      "context" : "2The idea of defining h is motivated by [1], where the authors define an atomic sentence o for each leaf in a game tree.",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 8,
      "context" : "However, the special model-update makes it different from standard PAL [11].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 1,
      "context" : "The BI strategy [2, 3] is the largest subrelation σ of the total move relation that has at least one successor at each node, while satisfying the rationality (RAT) property: RAT No alternative move for the player yields an outcome via further play with σ that is strictly better than all the outcomes resulting from starting at the current move and then playing σ all the way down the tree.",
      "startOffset" : 16,
      "endOffset" : 22
    }, {
      "referenceID" : 1,
      "context" : "As argued in [2, 3], this rationality assumption is a confluence property for action and preference:",
      "startOffset" : 13,
      "endOffset" : 19
    }, {
      "referenceID" : 2,
      "context" : "2 However, compared with the generic logic in [4, 3, 2], the given definition in our logic is local.",
      "startOffset" : 46,
      "endOffset" : 55
    }, {
      "referenceID" : 1,
      "context" : "2 However, compared with the generic logic in [4, 3, 2], the given definition in our logic is local.",
      "startOffset" : 46,
      "endOffset" : 55
    }, {
      "referenceID" : 2,
      "context" : "An LFP(FO) formula mirroring the recursive nature of BI is constructed in [4, 6] to define the classical BI relation, based on the above property RAT.",
      "startOffset" : 74,
      "endOffset" : 80
    }, {
      "referenceID" : 4,
      "context" : "An LFP(FO) formula mirroring the recursive nature of BI is constructed in [4, 6] to define the classical BI relation, based on the above property RAT.",
      "startOffset" : 74,
      "endOffset" : 80
    }, {
      "referenceID" : 2,
      "context" : "Rather than a binary relation bi as in [4, 6], characterizing SCBI needs a ternary relation.",
      "startOffset" : 39,
      "endOffset" : 45
    }, {
      "referenceID" : 4,
      "context" : "Rather than a binary relation bi as in [4, 6], characterizing SCBI needs a ternary relation.",
      "startOffset" : 39,
      "endOffset" : 45
    }, {
      "referenceID" : 3,
      "context" : "In contrast with detailed formalism of solutions with LFP(FO), there is the modal surface logic of [5], which enables direct and natural reasoning about best actions without considering the underlying details of recursive computation.",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 3,
      "context" : "Capturing the SCBI strategy For a start, we are now able to characterize the SCBI strategy, in a similar vein as the frame correspondence for the classical BI strategy in [5].",
      "startOffset" : 171,
      "endOffset" : 174
    }, {
      "referenceID" : 11,
      "context" : "In many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16].",
      "startOffset" : 118,
      "endOffset" : 138
    }, {
      "referenceID" : 13,
      "context" : "In many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16].",
      "startOffset" : 118,
      "endOffset" : 138
    }, {
      "referenceID" : 17,
      "context" : "In many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16].",
      "startOffset" : 118,
      "endOffset" : 138
    }, {
      "referenceID" : 10,
      "context" : "In many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16].",
      "startOffset" : 118,
      "endOffset" : 138
    }, {
      "referenceID" : 12,
      "context" : "In many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16].",
      "startOffset" : 118,
      "endOffset" : 138
    }, {
      "referenceID" : 21,
      "context" : "Another obvious interface for our logics are heuristic evaluation approaches for intermediate nodes used by the AI community for computational game-solving, [25, 12, 33].",
      "startOffset" : 157,
      "endOffset" : 169
    }, {
      "referenceID" : 9,
      "context" : "Another obvious interface for our logics are heuristic evaluation approaches for intermediate nodes used by the AI community for computational game-solving, [25, 12, 33].",
      "startOffset" : 157,
      "endOffset" : 169
    } ],
    "year" : 2016,
    "abstractText" : "We consider decision-making and game scenarios in which an agent is limited by his/her computational ability to foresee all the available moves towards the future – that is, we study scenarios with short sight. We focus on how short sight affects the logical properties of decision making in multi-agent settings. We start with single-agent sequential decision making (SSDM) processes, modeling them by a new structure of ‘preference-sight trees’. Using this model, we first explore the relation between a new natural solution concept of Sight-Compatible Backward Induction (SCBI) and the histories produced by classical Backward Induction (BI). In particular, we find necessary and sufficient conditions for the two analyses to be equivalent. Next, we study whether larger sight always contributes to better outcomes. Then we develop a simple logical special-purpose language to formally express some key properties of our preference-sight models. Lastly, we show how shortsight SSDM scenarios call for substantial enrichments of existing fixed-point logics that have been developed for the classical BI solution concept. We also discuss changes in earlier modal logics expressing ‘surface reasoning’ about best actions in the presence of short sight. Our analysis may point the way to logical and computational analysis of more realistic game models.",
    "creator" : "LaTeX with hyperref package"
  }
}