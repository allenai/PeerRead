{
  "name" : "1302.4948.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Testing Identifiability of Causal Effects",
    "authors" : [ "David Galles" ],
    "emails" : [ "galles@cs.", "judea@cs." ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 Introduction\nAssume we need to replace an expert operating a com plex production plant. Before we take charge, we are given a blue print of the plant, together with explana tions on the functions of the various dials and knobs, and we are able to observe the expert in actual opera tion over a long period of time. During this period, we record the dials which the expert consults prior to tak ing actions, we understand the function of those dials but we cannot observe the actual reading on each of those dials. The data we are able to collect during the observation period include: the actions taken by the agent, the readings of some of the dials, and the out come of various performance indicators. Our problem is to predict, on the basis of the data thus collected, the effect of a given action on the performance of the plant.\nThe problem of learning from the performance of other agents is that one is never sure whether an observed response is due to the agent's action or due to events that triggered that action and simultaneously caused the response. Such events are called \"confounders\" , and they present a major problem in the analysis of observational studies in the social and health sciences. For example, we cannot be sure if it was the drug that caused the patient to vomit, or the some prior condi tion which the doctor tried to treat by prescribing the\n•navid Galles is a graduate student\ndrug. Similarly, we cannot tell whether higher taxes are responsible for the current recession or the eco nomic indicators which government experts consulted before raising taxes.\nThe standard techniques of dealing with confounders is to adjust for possible variations in those environmental factors which might trigger the actions. This mounts to conditioning the observed distribution on the var ious levels of those factors, evaluating the action in each level separately, then taking the ( weighted) av erage over those levels. However, in problems like the one describe above some of the confounding factors are unobservable, hence they cannot be conditioned on.\nThe techniques developed in this paper will enable us to recognize, by graphical means, whether a given ac tion can be evaluated from joint distributions on ob served quantities and, if the answer is positive, decide which quantities should be measured, and how to ad just for them. Technically speaking, the task accom plished parallels the identification of recursive struc tural equations in the presence of unmeasured vari ables. However, whereas traditional theories of identi fiability deal exclusively with estimating coefficients in parametric equations, the identifiability problem solved in this paper is nonparametric; no assumptions are made regarding the functional forms of the struc tural equations or the distributions of the errors.1\nCast in terms of probabilistic networks, the problem addressed in this paper is the evaluation of the effects of an atomic action, do(X = x) , when the causal dia gram is not fully specified. We are given the topology of the diagram but not the conditional probabilities on all variables. Numerical probabilities are given to only a subset of variables which are deemed \"observ able\" , while those deemed \"unobservable\" serve only to specify possible connections among observed quan tities, but are not given numerical probabilities.\n1 Naturally, non parametric identifiability is not con cerned with values of numerical parameters but with the ultimate purpose to which parameters are being used in structural models, namely, the analysis of actions and causal effects.\n186 Galles and Pearl\nThe semantics behind causal diagrams and their re lations to actions and belief networks have been dis cussed in prior publications [Pearl and Verma, 1991, Goldszmidt and Pearl, 1992, Druzdel and Simon, 1993, Pearl 1993, Spirtes et al., 1993, Pearl 1994a]. In (Spirtes et a� for example, it was shown how causal networks can be used to facilitate quantitative predic tions of the effects of interventions, including interven tions that were not contemplated during the network's construction.2 A previous UAI paper (Pearl, 1994b] reviews this aspect of causal networks, and proposes a calculus for deriving probabilistic assessments of the effects of actions in the presence of unmeasured vari ables. This calculus can be used to check or search for a proof that the effect of one variable on another is identifiable, namely, that it is possible to obtain a consistent estimate of the probability of Y under the condition that X is set to x by external intervention, from data involving only observed variables. This pa per systematizes the search for such a proof.\nWe provide a polynomial time graph-based method of determining whether the effect of one variable on an other is identifiable.3 If identifiability is confirmed, the method can provide closed-form expressions for the distribution of the outcome variable Y under the external manipulation of the control variable X. The derived expression, denoted, P(y[do(x)), invokes only measured probabilities as obtained, for example, by recording past performance of other acting agents. Al though the actions of those agents may have been trig gered by hidden factors, unseen by the analyst, the im pact of X on Y can still be predicted consistently, us ing observed variables only. If Y stands for a goal vari able, then the probability of reaching the goal through each action do(X = x) can be determined consistently from such partial observations.\n2 Notation and Technical Background\n2.1 Causal theories, actions, causal effect, and identifiability\nDefinition 1 A causal theory is a 4-tuple\nT =< V, U, P(u), {!;} > where\n(i) V = {X1, . .. , Xn} is a set of observed variables\n(ii) U = {U1, .. . , Um} is a set of unobserved variables which represent disturbances, abnormalities or assumptions,\n(iii) P(u) is a distribution function over U1, . . . , Um, and\n2In contrast to influence diagrams which, lacking causal interpretation, require that action be contemplated in ad vance and incorporated as decision nodes in the diagrams.\n3 An extension of our analysis to the case of multiple actions (sequential or concurrent) is reported in [Pearl and Robins, 1995]\n(iv) {fi} is a set of n deterministic functions, each of the form\n1, . . . , n (1)\nWe will assume that the set of equations in (iv) has a unique solution for Xi , ... , Xn, given any value of the disturbances U1, ... , Um. Therefore the distribu tion P(u) induces a unique distribution on the observ ables, which we denote by PT(v).\nWe will consider concurrent actions of the form do(X = x) , where X � V is a set of variables and x is a set of values from the domain of X. In other words, do( X = x) represents a combination of actions that forces the variables in X to attain the values x.\nDefinition 2 {Effect of actions) The effect of the ac tion do( X = x) on a causal theory T is given by a subtheory Tx ofT , where Tx obtains by deleting from T all equations corresponding to variables in X and substituting the equations X = x instead.\nDefinition 3 (causal effect) Given two disjoint sub sets of variables, X � V andY � V, the causal effect of X on Y, denoted PT(Yix), is a function from the domain of X to the space of probability distributions on Y, such that\nPT(Yix) = PT,.(Y) (2)\nfor each realization x of X. In other words for each x E dom(X), the causal effect PT(Yix) gives the distribution ofY induced by the action do(X x) .\nNote that causal effects are defined relative to .a given causal theory T, though the subscript T is often sup pressed for brevity.\nDefinition 4 (identifiability) The causal effect of X on Y is said to be identifiable if the quantity P(y[x) can be computed uniquely from any positive distribu tion of the observed variables, that is, if for every pair of theories T1 an T2 such that PT, (v) = PT2(v) > 0, we have PT,(y!x) = PT2(yix)\nIdentifiability means that P(ylx) can be estimated consistently from an arbitrarily large sample randomly drawn from the distribution of the observed variables.\nDefinition 5 (back-door path) A path from X to Y in a graph G is said to be a back-door path if it con tains an arrow into X.\nFigure 1 illustrates a simple causal theory in the form of a diagram. It describes the causal relationships among the season of the year (Xi), whether rain falls (X2), whether the sprinkler is on (Xa), whether the pavement would get wet (X4), and whether the pave ment would be slippery (X5). All variables in this figure are binary, taking a value of either true or false,\nexcept the root variable X1 which can take one of four values: Spring, Summer, Fall, or Winter. Here, the absence of a direct link between xl and x5, for exam ple, captures our understanding that the influence of seasonal variations on the slipperiness of the pavement is mediated by other conditions (e.g., the wetness of the pavement). @ SE A S ON\nThe theory corresponding to Figure 1 consists of five functions, each representing an autonomous mecha msm:\nu1 x4 h(X1, U2) X5 /3(X1,U3)\nTo represent the action \"turning the sprinkler ON\", do(X3 =ON), we delete the equation x3 = fs(xl, U3) from the theory of Eq. (3), and replace it with X3 = ON. The resulting subtheory, Tx3=0N, contains all the information needed for computing the effect of the actions on other variables. For example, it is easy to see from this subtheory that the only variables affected by the action are X4 and X5, that is, the descendant of the manipulated variable x3.\nThe probabilistic analysis of causal theories becomes particularly simple when two conditions are satisfied:\n1. The theory is recursive, i.e., there exists an or dering of the variables V = {X 1, ... , Xn} such that each X; is a function of a subset pa; of its predecessors\nX; = /;(pa;, U;),\n2. The disturbances U1, ... , Un are mutually inde pendent, U; II Uj, which also implies (from the exogeneity of the U; 's)\nU; _II {X1, ... , X;_t} (5)\nThese two conditions, also called Markovian, are the basis of Bayesian networks [Pearl, 1988] and they en able us to compute causal effects directly from the conditional probabilities P(x;lpa;), without specifying\nTesting Identifiability of Causal Effects 187\nthe functional form of the functions /;, or the distri butions P( u; ) of the disturbances. This is seen imme diately from the following observations:\nThe distribution induced by any Markovian theory T is given by the product\nwhere pa; are the direct predecessors (called parents) of X; in the diagram. On the other hand the distribu tion induced by the The sub theory Tx', representing 1 the action do(Xj = xj) is also Markovian, hence it also induces a product-like distribution\nPT,/. (x1, ... , Xn) 1\n{ ll P( ·I ) _ P(x1, . . . ,x,.) = O if.j x, pa; - P(xi \\pa) if Xj = xj if Xj :j:. xj\n( 7)\nwhere the partial product reflects the surgical removal of Xi= /j(pai, Uj) from the theory of Eq. ( 4).\nIn the example of Figure 1, the pre-action distribution is given by the product\nwhile the surgery corresponding to the action do(X3 = ON) amounts to deleting the link X1 --+ X3 from the graph and fixing the value of X3 to ON, yielding the post-action distribution:\nPT(x1, x2, x4, x5ldo(X3 =ON))\n= P(x1) P(x2lxt) P(x4lx2, X3 =ON) P(x5lx4) ( 9)\nNote the difference between the action do(X3 = ON) and the observation X3 = ON. The latter is en coded by ordinary Bayesian conditioning, while the former by conditioning a mutilated graph, with the link X1 --+ X3 removed. This mirrors indeed the dif ference between seeing and doing: after observing that the sprinkler is ON, we wish to infer that the season is dry, that it probably did not rain, and so on; no such inferences should be drawn in evaluating the effects of the deliberate action \"turning the sprinkler ON\". The amputation of X3 = /s(X1, U3) from (3) ensures the suppression of any abductive inferences from any of the action's consequences.\n2.2 Action Calculus\nThe identifiability of causal effects demonstrated in Section 2.1 relies critically on the Markovian assump tions ( 4) and (5). If a variable that has two descen dants in the graph is unobserved, the disturbances in the two equations are no longer independent, the\n188 Galles and Pearl\nMarkovian property ( 4) is violated and identifiabil ity may be destroyed. This can be seen easily from Eq. ( 7); if any parent of the manipulated variable Xj is unobserved, one cannot estimate the conditional probability P( x j IPaj), and the effect of the action do(Xj = Xj) may not be predictable from the observed distribution P( x1, ... , xn)· Fortunately, certain causal effects are identifiable even in situations where mem bers of paj are be unobservable, and these situations can be recognized through the action calculus intro duced in [Pearl, 1994a].\nLet X, Y, and Z be arbitrary disjoint sets of nodes in a DAG G. We say that X and Y are independent given Z inG, denoted (X II YIZ)a, if the set Z d-separates X from Y in G. We denote by Gx the graph obtained by deleting from G all arrows pointing to nodes in X. Likewise, we denote by G x the graph obtained by deleting from G all arrows emerging from nodes in X. To represent the deletion of both incoming and outgoing arrows, we use the notation Gx�: Finally,\nthe expression P(ylx, z) � P(y, zlx)/ P(zlx) stands for the probability of Y = y given that Z = z is observed and X is held constant at x.\nTheorem 1 Let G be the directed acyclic graph as sociated with a Markovian causal theory, and let P( · ) stand for the probability distribution induced by that theory. For any disjoint subsets of variables X, Y, Z, and W we have:\nRule 1 Insertion/ deletion of observations\nP(ylx, z, w) = P(ylx, w) if (Y II ZIX, W)a-- X ( 10)\nRule 2 Action/observation exchange\nP(ylx, i, w) = P(ylx, z, w) if (Y II ZIX, W)a-- xz (llf\nRule 3 Insertion/ deletion of actions\nP(ylx, z, w) = P(ylx, w) if (Y _ II ZIX, W)ax, z<w> ( 12) where Z(W) is the set of Z-nodes that are not ancestors of any W-node in Gx·\nEach of the inference rules above follows from the ba sic interpretation of the \"x\" operator as a replacement of the causal mechanism that connects X to its pre action parents by a new mechanism X = x introduced by the intervening force. The result is a submodel characterized by the subgraph Gx (named \"manipu lated graph\" in (Spirtes et al. 1993]) which supports all three rules.\nCorollary 1 A causal effect q: P(y1, ... , Yklx1, ... , Xm) is identifiable in a model characterized by a graph G if\nthere exists a finite sequence of transformations, each conforming to one of the inference rules in Theorem 1, which reduces q into a standard ( i.e., hat-free) proba bility expression involving observed quantities. D\nAlthough Theorem 1 and Corollary 1 require the Markovian property, they can also be applied to re cursive non Markovian theories, because such theo ries become Markovian if we consider the unobserved variables as part of the analysis, and represent them as nodes in the graph. To demonstrate, assume that variable X1 in Figure 1 is unobserved, rendering the disturbances u3 and u2 dependent, since these terms now include the common influence of X 1. Theorem 1 tells us that the causal effect P(x4lx3) is identifiable, because:\nRule 3 permits the reduction\nwhile Rule 2 permits the exchange\nP(x41x3, x2) = P(x41x3, x2)\nThis gives\nwhich is a \"hat-free\" expresswn, involving only ob served quantities.\nIn the sequel we will represent confounding unmea sured variables by dashed arcs. For example, the arc between X and B2 in Figure 2 stands for an unmea sured variable variable U that is a common cause of X and B2.\n3 A Graphical Criterion for Testing Identifiability\nTo avoid excessive notation, the rest of the paper will consistently refer to queries P(ylx) that satisfies Cor rolary 1 as \"identifiable\" with the understanding that it represents sufficient but not ( yet) neccessary con dition for semantical identifiability as in Definition 4. The two notions would be equivalent if the rules in Theorem 1 where complete.\nTheorem 2 A necessary and sufficient condition for the identifiability of P(ylx) in a graph G is that G satisfies one of the following four conditions :\n1. There is no directed path from X to Y in G.\n2. There is no back-door path from X to Y in G, that is (X _II Y)a�·\n3. There exists a set of nodes B that blocks all back door paths from X toY such that P(bli:) is iden tifiable. ( A special case of this condition occurs when B consists entirely of non-descendants of X, in which case P(bli:) reduces immediately to P(b)).\n4. There exist sets of nodes Z1 and Z2 such that : • No element of Z2 is a descendant of X • Z1 blocks every directed path from X to Y,\nie., (Y II XIZdG--- Z1 X • z2 blocks all back-door paths between zl and\nY in Gy, ie., (Y II Z1IZ2)G- , - xz, • Z2 blocks all back-door paths between X and\nZ1, ie., (X _II Z1IZ2)G�, A special case of Condition 4 occurs when Z2 = 0 and there is no back door path from X to Z1 or from Z1 toY.\nProof of Theorem 2\nWe first prove the sufficiency of the four conditions above, then turn to prove their necessity.\n• Condition 1: If there is no directed path from X to Y in G, then (Y _II X)G.x. So, by Rule 3, P(yli:) = P(y), and the query is identifiable.\n• Condition 2: This follows directly from Rule 1 : If (Y II X)G x, then we can immediately change P(yli: )to P(Yfx). Thus, the query is identifiable.\n• Condition 3: If there is a set of nodes B that blocks all back-door paths from X to Y, then we can rewrite P(yli:) as Lb P(yli:, b)P(bli:). Since B blocks all back-door paths from X to Y, it must be the case that (Y II XIB)Gx, so, by Rule 2, we can rewrite P(ylx;b) as P(yl-;,b). If the query (bli:) is identifiable, then the original query must also be identifiable. See Figure 2 for examples.\n• Condition 4: (See Figure 3 for examples). If there is a set of nodes zl that block all directed paths from X to Y, and a set of nodes z2 that block all back-door paths be tween Y and Z1 in Gx, expanding P(yli:) =\nTesting Identifiability of Causal Effects 189\nLz,,z2 P(yli:, Z1, z2)P(z1, z2li:). we can rewrite P(ylx,z1,z2) as P(ylx,z1,z2) using Rule 2, since all back-door paths between zl and y are blocked by z2 in G X 0 We can re duce P(yli:,zl,zz) to P(ylz1,z2) using Rule 3, since (Y II XIZ1, Zz)G- --· We can rewrite - Zt X(Z2) P(ylz1,z2) as P(ylz1,z2) if (Y II Z1IZ2)Gz. - _!. The only way that this independence cannot hold is if there is a path from Y to Z1 through X, since (Y I I Z1IZ2)G- . However, we can block - xz, this path by conditioning and summing over X to get Lx' P(ylz1, z2, x')P(x'lz1, z2). Now we can rewrite P(ylz1, z2, x') as P(ylz1, z2, x') using Rule 2. P(x'lz1, z2) can be rewritten as P(x'lzz) us ing Rule 3, since Z1 is a child of X and the graph is acyclic. So, the query can be rewritten as Lz,,z2 Lx' P(ylz1, Zz, x')P(x'lz2)P(z1, z2li:). P(z1, zzlx) = P(zzlx)P(ziii:, z2). Since Z2 con sists of non-descendants of X, we can rewrite P(z2li:) as P(zz) using Rule 3. Since Z2 blocks all back-door paths from X to Z1, we can rewrite P(z1lx,z2) as P(z1lx,zz) using Rule 2. The entire querry can thus be rewritten as Lz,,z2 Lx' P(ylz1, z2, x')P(x'lzz)P(zllx, zz)P(zz).\nIt remains to prove that the conditions of Theorem 2 are necessary. This may be shown by contradiction\nProof Sketch - We will assume that there exists a query P(yli:) and a graph G such that : 1. None of the conditions of Theorem 2 hold, and 2. There exists a finite sequence of application of inference rules which removes all hats from the variables in the query. We will show that these two assumptions lead to a contradiction, hence, if all four conditions of Theorem 2 fail, there must not be a finite sequence of inference rules that reduces the query to a hat-free expression.\nProof Outline :\nI (Y II XIZ, W)G- , so rule 2 can be applied to - zx remove the hat from X.\n190 Galles and Pearl\nA There is a directed path from Z to Y 1 Cannot add z using rule 3 2 Cannot add z using rule 2\nB There is a directed path from Z to X 1 Cannot remove z using rule 2 2 Cannot remove z using rule 3\nII (Y II XIZ, W)a- -, so rule 3 can be applied - Z X(W) to remove x\nA Cannot add z using rule 3 B Cannot add z using rule 2\nAssume that there exists a querry P(ylx) and a graph G such that none of the conditions of Theorem 2 hold, but the query is still identifiable. Since P(ylx) is iden tifiable, there must be some finite sequence of infer ence rules that removes the hat from x. That means, there must be some (possibly empty) set of variables Z and W such that either (Y II XIZ, W)a- , so we - zx can reduce P(ylx, z, w) to P(ylx, z, w) via Rule 2, or (Y II XIZ, W)a- -, so we can reduce P(ylx, z, w) - Z X(W) to P(ylz, w) using Rule 3. We will look at each of these two cases in turn.\nCase 1: First, consider (Y II XIZ, W)a- . By as-- zx sumption, P(ylx) is identifiable, and the hat is re moved from X by an application of Rule 2. This implies a series of rule applications to P(ylx) which results in P(ylx, z, w) , such that (Y II XIZ, W)a- . - zx We will look at the restrictions on Z, W that are im posed by both the failure of the conditions of Theo rem 2 to hold, and the assumption that P(ylx) can be transformed to P(ylx, z, w) by a series of rule ap plications. We will also make the assumption that Z and W are minimal. If they are not, then there exists a minimal Z' and W', in which superfluous nodes are removed, which would also work - so proving that no minimal Z and W exist implies that no Z or W exist.\nIf (Y II XIZ, W)ax, then there would exist a block able back-door path, and Condition 3 of Theorem 2 would have held. We also know (Y II XIZ, W)a- , - zx by assumption. These two independence assertions imply that Z conducts a back-door path that is not blocked by W. That is, there is a back-door path be tween X andY that has a head-to-head junction in Z. Each element of Z must also block a back-door path from X to Y, since Z is minimal. This implies that there is a directed path from Z to X, or from Z to Y (Figure 4):\nProof that there is a directed path from Z to X or from Z toY :\nSince we know that Z must block a back-door path from X to Y, there must be a path from Z to X or from Z to Y that starts in an arrow that is incident away from Z. All of the head-to-head junctions along this path must either be in W or have descendants in\nW. If there are no such head-to-head junction paths, then there is a directed path from Z to X or Y. If there is a head-to-head junction, then consider the W that unblocks this junction. This W must itself block a back-door path from X to Y. So, there must be a path from W to either X or Y that starts with an arc incident away from W. This path is either a directed path from W to X or Y, or has a head-to-head junction that is also a member of W, or is an ancestor of a member of W. Since the graph is acyclic, there must eventually be a W that has a directed path to X or\nY that is a descendant of Z - thus there is a directed path from Z to either X or Y.\nWe now look at the two cases; Case lA: a directed path exists from Z to Y, Case lB: a directed path exists from Z to X\nCase lA: A directed path exists from Z toY.\nBy our assumption, there must be a sequence of rules to transform P(ylx) to P(ylx, z, w) . There are two ways to add z to this expression- either directly using Rule 3, or by first conditioning on Z and then adding a hat to it by using rule 2.\nCase IA1: First we look at using Rule 3. If there is a directed path from Z to Y (Figure 4a), then (Y M ZIX)a- -· No element of W can block this - X Z path from Y to Z, since that would require W to be a descendant of Z, and (Y IY ZIX, W)a-. So Rule 3 - X cannont be invoked to add z to the expression.\nCase IA2: We need to first condition on Z, and then add the hat to it using Rule 2. In order for us to add the hat to Z using rule 2, there needs to be a W' such that (Y _II ZIW',X)a:xz· Above, we proved that given our assumptions, there must be an unblocked path from Y to X that has a head-to-head junction at Z, and no member of W that blocks it, so W' 'l:. W. If we condition on a W' that allows us to add the hat to Z, we must then remove it to obtain P(ylx, z, w) so that we can remove the hat from x. However, we are not able to remove this W'. We cannot remove W' using rule 1, since (Y IY W'IX, Z, W)a- _, and if we - xz add some W\" that d-separates Y from W', then we would not be able to remove W\".\nThus we cannot add z to P(ylx) by first conditioning on Z and then adding a hat to it using Rule 2 if there is a directed path from Z to Y.\nCase IB: A directed path exists from Z to X. If there is a directed path from Z to X (Figure 4b), we will assume that we can can add z to P(ylx) to get P(ylx, z), and condition on W to get P(ylx, z, w) . We can then remove the hat from x using Rule 2 to get P(ylx, z, w) . Now we will prove that there is no way to remove z from the expression. Since there is a back-door path from X to Y that has a head-to-head junction at Z, there must be an back-door path from Z to Y.\nCase IBl: If we could remove the hat from Z using Rule 2, then we could block the back door path from Z to Y - and hence we could block the back-door path from X to Y, and Condition 3 would have held. Case IB2: If we could remove i directly using Rule 3, then there would have to be some set of nodes that blocked the directed path from Z to X, and both (Y _II XIZ, W)c-zx and (Y Jt XIZ, W)c� would not be true. -\nCase II: Now consider (Y II XIZ, W)c- --· We , - Z X(W) will try to find a set of rule applications that transforms P(ylx) into P(ylx, i, w) when none of the con ditions of Theorem 2 hold. Z must block all di rected paths from X to Y. If it did not, then W would have to block a directed path, but that would make W a descendant of X, so X(W) = 0, and thus (Y II XIZ, W)c-, and above we proved that this - z could not happen if any of the conditions of Theorem 2 held. There are two ways to add i to P(ylx) - ei ther directly using Rule 3, or by conditioning on Z and then adding a hat to it using Rule 2. We will look at each of these in turn.\nCase IIA: First, we will try to add z directly by us ing Rule 3. To do this, there must be some W such that (Y II ZIW, X)c- -· Since there is a directed - X Z(W) path from Z toY, W must be a descendant of Z, thus (Y II ZIW, X)c- So, W blocks all back-door paths - X between Z and Y in G x. Once x has been removed from P(ylx, z, w) to obtain P(yli, w) , we need to re move i, or remove the hat from Z. We cannot re move the hat from Z directly by using rule 3, since (Y IY ZIW, X)c-, because Z(W) = 0, and there is - Z(W) a back door path from Z to Y through X. If we could remove the hat from Z by using rule 2, then Condition 4 would have held. So, we cannot add i directly using Rule 3 if any of the conditions of Theorem 2 hold. Case liB: Next, we will try to condition on Z, and then add a hat to it using Rule 2. However, if this was possible then there would have to be a W that blocked back door paths between X and Z, and blocked back door paths between Z and Y - and then Condition 4\nTesting Identifiability of Causal Effects 191\nwould have held.\nThus, if none of the conditions of Theorem 2 hold, the query must not be identifiable.\nRemark: The criterion in Theorem 2 is complete only if the inference rules themselves are complete. The ap pendix shows that the graphical conditions which li cense each of the rules in Theorem 1 are the tightest possible. However, the possibility still remains that some strange exchange of hatted and non-hatted vari ables would be licensed by some graph, and not reach able by successive applications of Rules 1-3.\n4 Remarks on Efficiency\nIn implementing Theorem 2 as a systematic method of determining identifiability, Conditions 3 and 4 would seem to require an exhaustive search. To prove that Condition 3 does not hold, for instance, we need to prove that no blocking set B can exist. Fortunately, the following theorems allow us to significantly prune the search space, so as to render the test tractable.\nTheorem 3 If, for one minimal set B;, P(b;lx) is identifiable, then for any other minimal set Bj, P(bj lx) is also identifiable.\nTheorem 3 allows us to test Condition 3 with a single minimal blocking set B. If B meets the requirements for Condition 3, then the query is identifiable, other wise Condition 3 cannot be satisfied.\nTheorem 4 Let Y1 and Y2 be two subsets of nodes such that either no nodes Y1 are descendants of X, or all nodes Y1 and Y2 are decendants of X and all nodes Y1 are nondescendants of Y2. Then, there ex ists a reducing sequence for P(y1, Y2lx) (per Corollary 1} if and only if there are reducing sequences for both P(y1lx) and P(y2lx,y1).\nz\nFigure 5: Theorem 2 Ensures a reducing sequence for P(y2lx, yl) and P(ydx), although none exists for P(y1lx,y2).\nIt is possible that P(y1, y2lx) will pass the test in The orem 2 if we apply the procedure to both P(y21x, Y1) and P(y2lx), but if we try to apply the test to P(y1 !x, Y2), we will not find a reducing sequence of rules. Figure 5 shows just such an example. Theorem 4, however, guarantees that, if there is a reducing se quence for P(y1, Y2lx) then we should always be able to\n192 Galles and Pearl\nfind such a sequence for both P(y1jx) and P(y2!x, Y1) by proper choice of Y1.\nTheorem 5 If there exists a set Z1 that meets all of the requirements for Z1 in Condition 4, then the set consisting of the children of X intersected with the an cestors of Y will also meet all of the requirements for Z1 in Condition 4.\nTheorem 5 removes the need to search for Z1 in Con dition 4 of Theorem 2.\nProof of Theorem 3\nIf, for one minimal set Bi, P(b;jx) is identifiable, then for any other minimal set Bj, P(bj ji:) is also identifi able.\nWe will use the following lemma :\nLemma 1 If the query P(yjx) is identifiable, and a set of nodes Z lies on a directed path from X to Y, then the query P(z!x) is identifiable.\nProof (By Contradiction) : Assume that there is a minimal set B such that (Y II XIB)ax and the query P(blx) is identifiable. Assume that there is another minimal set K such that (K II X!B)ax, and the query P(k!x) is not identifiable-.-\nConsider all (undirected) paths from X to Y in G x. Every element of B and K must lie along one of these paths, since the sets are minimal. In addition, at least one member of K must be a descendant of X, other wise P(klx) would be identifiable. In fact, any mem ber of K that is a descendant of X needs to lie on a directed path from X to Y.\nProof that any member of K that is a descendant of X lies on a directed path from X to Y :\nIf a member K 1 of K was a descendant of X but did not lie on a directed path from X to Y, then there must be a head-to-head junction along the path from K1 to Y. This path would have to be unblocked by some other member K2 of K. Since K is minimal, there must be some unblocked path from some descendant of K2 to Y that K blocks. This implies that there is either a directed path from one of the descendants of K2 toY, which would make K1 an ancestor of Y, or there must be a head-to-head junction on the path from K2 to Y that is unblocked by some other mem ber K3 of K. There is either an infinite series of K s between K 1 and Y, or else a directed path from K 1 to Y (see Figure 6). Let K' be the subset of I< that lies on a directed path from X to Y, and let K\" = K \\ I<'. We know that P(kjx) = P(k'jx, k\") * P(k\"jx), and that P(k\"jx) = P(k\"). So, P(k'jx, k\") must not be identifiable. Since f{ is minimal, I<' must block some back-door path,\nand that back-door path must also be blocked by some member of B. There are two possibilities : either the path that K' blocks has a head-to-head junction that is not unblocked by B, or there is some member of B which blocks the same path. An illustration of these two cases can be found in Figure 7. Looking at each of these in turn :\nCase 1 : There is a head-to-head junction that is not unblocked in B, but is unblocked in K. Call this junction J. Since J{ is minimal, the element of I< that unblocks this path (either equal to J, or one of J 's descendants) must lie on some unblocked path from Y to X in G x. If this is the case, then there must be an unblockedpath through J's descendants that also goes through J, which means there must be some element B' of B that blocks the path between J and X in G x. (See Figure 8) We can condition and sum over this B' to get :\nP(k'lx, k\") = L P(k'!x, k\", b') * P(b'!x, k\") b'\nL P(k'!x, k\", b') * P(b'!x, k\") b'\nby using Rule 2. So the query P(b'jx, k\") must not be identifiable. Thus B' must be a descendant of X, otherwise P(b'jx, k\") = P(b'jk''). So, P(b'!x) is iden tifiable, but P(b'jx, k\") is not. Therefore, K\" must disallow the blocking of a back-door path from X to B'. Then there must be a back-door path from X to B' that has a head-to-head junction, and that junc tion has a descendant in K\", but not in B. This is\nimpossible- since I< is minimal, the descendant of the head-to-head junction must block a back-door path from X to Y. B must block that same path, meaning the path from X to B' was unblocked by B as well as by I<\".\nCase 2: There is a member B' of B that blocks the same back-door path as K'. The path could be blocked by B' either between X and K', or between K' and Y (See Figure 9). If the path is blocked by B' between X and K', we have the same contradiction as in Case 1 above. If it is blocked by B' between K' andY, then B' lies on a directed path from X to Y. From Lemma 1, we know that P(k'ix) must be identifiable. That means that K\" must disallow either Condition 3 or 4 of the Theorem 2. If it blocks Condition 3, then K\" must conduct a back-door path from X to K'. That means that there must be some member of K\" that is at a head-to-head junction along a path from I<' to X in G x, or is a descendant of that junction. Using the sameargument as above, since f{ is minimal, the path blocked by K\" must also be blocked by B, and thus the head-to-head junction must be unblocked by B as well. Any unblockable back-door path from X to I<' will also be an unblockable back-door path from X to B', since B' is a direct descendant of K'. However, we know that there cannot be a back-door path from X to B' that is unblockable when we condition on B, - thus there cannot be a back-door path from X to K' that is unblockable when we condition on I<\"\nIf I<\" disallows Condition 4, then there must be some other set of nodes R that blocks every directed path from X to K'. K\" must unblock a back-door path\nTesting Identifiability of Causal Effects 193\nfrom X to R or from R to K'. As above, if a back door path from X to R (and thus from X to K' ) is un blocked by K\", it will also be unblocked by B. So, K\" must unblock a back-door path from R to K'. Since J{ is minimal, there must be a path from a descen dant of R to X in G x. So, there must also be a path from Y to X in G x that passes through R and K'. Since the back-doo�path from X to K' must not be blockable ( since a blockable back-door path was inval idated above), B must block the path from Y to I<'. But then there would not be a back-door path from R to J{' that is blockable when conditioning on B, but unblockable when conditioning on K\".\nSo, if any minimal set B blocks all back-door paths from X to Y, and the query P(bix) is identifiable, then if any other minimal set J{ also blocks all back door paths from X to Y, then P(kix) must also be identifiable.\nProof of Lemma 1 :\nIf the query P(yix) is identifiable, and a set of nodes Z lies on a directed path from X to Y, then the query P(zix) must be identifiable.\nIf the query P(yix) is identifiable, one of the four con ditions of Theorem 2 must have been satisfied. Look ing at each in turn :\nCondition 2 - If there is no path from Y to X in G x, then there cannot be a path from any of Y's ancestors to X in G x, since any path from X to Z would be part of a path from X to Y.\nCondition 1 - If there is no directed path from Y to X, then there cannot be a Z that lies along a directed path from Y to X, and the lemma is trivially true.\nCondition 3 - If there is a set B that blocks all back door paths from X to Y, then : any back-door path from X to Z will also be a back-door path from X toY. B must block this back-door path from X and Y. If B blocks the path between X and Z, then B also blocks the back-door path from X to Z, and the query P(zix) is identifiable. If B blocks the path between Z and Y, then we can use the fact that the query P(blx) must be identifiable. If P(bix) is identifiable by Condition 4, then P(zix) must also be identifiable by Condition 4, since the variables that meet the specifications for Z1 in condition 4 for P(bix) will also meet the spec ifications for Zt in Condition 4 for P(zix). If P(bji:) is identifiable by Condition 3, then there is some B' that blocks the back-door path from X to B, either between X and Z, in which case P(zix) is identifiable, or between Z and B'. Since there are a finite number of links between Z and Y, eventually the back-door path from X to Z must be blocked, and the query P(zix) is identifiable. Condition 4 - If there exists a set Z1 and Z2, Z can either come before Zt or after Zt. If it comes after Z1, then the conditions that held for Y will also hold\n194 Galles and Pearl\nfor Z, and the query will be identifiable. If it comes before Z1, then { Z1, Z2} will block all back-door paths from X to Z, and the query will also be identifiable. Proof of Theorem 4\n(By Contradiction). Let Y1 and Y2 be two subsets of nodes such that either no nodes Y1 are descendants of X, or all nodes Y1 and Y2 are decendants of X and all nodes Y1 are non descendants of Y2. Assume that there exists a reducing sequence for both P(yzli:) and P(ylji:,yz), but not for P(yzli:,y1). There are 3 possible cases :\nCase 1: Y1 and Y2 are both non-descendants of X. In this case, P(ylji:,yz) = P(YIIYz) and is thus identifiable. Case 2: Yz is a descendant of X, but Y1 is not. In this case, Y1 must unblock a back-door path from X to Y1 which cannot be blocked by conditioning on other variables. But if this is the case, then there must be an unblockable back-door path from X to Y1. Since Y1 is a descendant of X, that would make P(y1ji:, yz) unidentifiable. Case 3: Y1 and Y2 are both descendants of X. Y1 cannot unblock a back-door path from X to Yz since Y1 is an ancestor of Yz. Thus P(y2ji:) must be unidentifiable, and thus P(yzji:, yl) is also unidentifiable.\nProof of Theorem 5\nIf there exists a set Z1 that meets all of the require ments for Z1 in Condition 4 of Theorem 2, then the set consisting of the direct descendants of X intersected with the ancestors of Y will also meet all of the re quirements for Z1 in Condition 4.\nAssume that there exists some set Z1, which does not consist entirely of children of X, such that Z1 blocks all directed paths from X to Y , and there also exists a set Zz that blocks all back-door paths from X to Z1 in G, and all back-door paths from Z1 to Y in G x. Let Z� be the intersection of the children of X with the ancestors of y. z� clearly blocks all directed paths from X to Y . Any back-door path from X to Z� must also be part of a back-door path from X to some member of Z1, since every member of Z1 must be either a member of Zf or a descendant of some member of Z�. Since Zz consists of non-descendants of X, Z2 must block all back-door paths from X to Z1 between X and Zf - so Zz also blocks all back-door paths from X to Z�. Similarly, all back-door paths from Zf to Y are also part of back-door paths from zl to y' which are also blocked by Z2.\n5 Complexity Analysis\nUsing the results of Section 4, we can show that the identifiability test provided by Theorem 2 can be im plemented in polynomial time. We will show that each\nof the four conditions in Theorem 2 can be tested in polynomial time.\n1. Since d-separation can be determined in time O(V + E), Condition 2 can be tested in polyno mial time\n2. Again, since d-separation can be determined in time O(V +E), Condition 1 can be tested in poly nomial time\n3. Theorem 3 allows us to test a single minimal blocking set to determine if Condition 3 holds. Thus, we need to find a minimal blocking set be tween two variables. This can be done in polyno mial time as follows :\n(a) Set R1 =X and Rz =pax (b) For each r E R2 that has a confounding (two\nheaded) link to a member of R1, remove r from Rz, add r's parents to R2, and add r to R1\n(c) If Rz n Y -::J 0, return FAIL. (d) Set R3 = Y and R4 =pay (e) For each r E R4 that has a confounding (two\nheaded) link to a member of R3, remove r from R4, add r's parents to R4, and add r to R3\n(f) If R4 n X -::J 0, return FAIL. (g) Set B = Rz U R4 (h) If (Y Jt XI B), return Fail. (i) For each member b of B, if (Y _II XIB \\ b),\nremove b from B. (j) If anything was removed from B in step i, Go\nTo step i. (k) Return B.\n4. To test condition 4, we need to find a set of vari ables Z1 and Z2. Theorem 5 gives us a constant time method to choose Z1. To find Z2, we need only find a blocking set that is not a descendant of X. We can do this by labeling the descendants of X \"unobservable\" and using the method above for finding a minimal blocking set.\n6 Conclusions\nAlthough this paper focuses on the task of testing identifiability, it should be emphasized that whenever identifiability is confirmed by the test, a closed-form formula for P(yji:) can easily be assembled using the inference rules invoked in the test. Details of this con struction are not shown explicitly in the paper, but can be found in [Pearl, 1994a, Pearl, 1994b]. In view of this construction, we now have a polynomial-time method of assessing the ramification of actions, given a qualitative causal diagram together with a proba bility distribution on a set of observed variables. As mentioned in the introduction, the main application of this result in AI settings lies in enabling one agent\nto learn to act by passively observing the performance of other acting agents, even in cases where the actions of those other agents are predicated on factors that are not visible to the learner. If the learner is permit ted to act as well as observe, the task becomes much easier of course, because the topology of the diagram can also be inferred, at least partially. Immediate ap plications to cause effect analysis of nonexperimental data in the social and medical sciences are discussed in [Pearl, 1994a].\n7 Appendix\nThe conditions which license each of the rules of The orem 1 are the tightest possible :\n(Y _II ZIX, W)ax if P(ylx, z, w) = P(ylx, z)\nSince the d-separation condition is valid for any re cursive model, including the submodel represented by Gx, the conditional independence P(ylx, z, w) = P(ylx, z) implies (Y II ZIX, W)a-· - X\n(Y II ZIX, W)a- if P(ylx, z, w) = P(ylx, z, w) - X�\nConsider the augmented diagram G' that has the intervention arcs Fz -+ Z added. P(ylx, z, w) = P(ylx, z, w) implies that (Y II FziX, Z, W)a:_. If - X there is a path from Y to Z that is unblocked by {X, W} in Gy, it must not .end in an arrow incident to Z, otherwise (Y II FziX, Z, W)a:.... would not hold. - X Since every path from Y to Z that is not blocked by {X, W} in Gy must pass through an arrow leaving Z, (Y II ZIX, W)a- . - X�\n(Y II ZIX, W)a-- if P(ylx, z, w) = P(ylx, w) - X Z(W)\nAgain consider G' with intervention arcs Fz -+ Z added. P(ylx, z, w) = P(ylx, w) implies that (Y II FziX, W)a:_. So, any path from Z to Y that - X is not blocked by {X, W} in Gx, must end in an arrow pointing to Z, otherwise (Y 11 FziX, W)a:.... would - X not hold. In addition, if there is a path from some Z' of Z to Y that does end in an arrow pointing to Z', then W must not be a descendant of Z', otherwise (Y II FziX, W)a:.... would not hold. Thus the only - X paths from Y to Z must end in an arrow pointing at Z, and must end in some member of Z(W). Thus, (Y II ZIX, W)a--- X Z(W)\nAcknowledgements\nThe research was partially supported by Air Force grant #AFOSR/F496209410173, NSF grant #IRI-\nTesting Identifiability of Causal Effects 195\n9420306, and Rockwell/Northrop Micro grant #94- 100. Max Chickering provided much valuable assis tance with the proofs in this document. We thank James Robins for commenting on the first draft of this paper.\nReferences\n[Druzdzel and Simon, 1993] M.J. Druzdzel and H.A. Simon. Causality in Bayesian belief. In D. Heck erman and A. Mamdani, editors, Proceedings of the Ninth Conference on Uncertainty in Artificial Intel ligence, pages 3-11, San Mateo, CA, 1993. Morgan Kaufmann.\n[Goldszmidt and Pearl, 1992] M. Goldszmidt and Pearl. Rank-based systems: A simple approach to belief revision, belief update, and rea soning about evidence and actions. In B. Nebel, C. Rich, and W. Swartout, editors, Proceedings of the Third International Conference on Know/edge Representation and Reasoning, pages 661-672, San Mateo, CA, October 1992. Morgan Kaufmann Pub lishers.\n[Pearl and Robins, 1995] J. Pearl and J. Robins. Probabilistic evaluation of sequential plans from causal models with hidden variables. Technical Report R-219U, Computer Science Department, UCLA, 1995. To appear in UAI-95.\n[Pearl and Verma, 1991] J. Pearl and T. Verma. A theory of inferred causation. In J .A. Allen, R. Fikes, and E. Sandewall, editors, Principles of Knowledge Representation and Reasoning: Proceedings of the 2nd International Conference, pages 441-452, San Mateo, CA, 1991. Morgan Kaufmann.\n[Pearl, 1988] J. Pearl. Probabilistic Reasoning in In telligence Systems. Morgan Kaufmann, San Mateo, CA, 1988. (Revised 2nd printing, 1 992).\n[Pearl, 1993] J. Pearl. From Bayesian networks to causal networks. In Proceedings of the Adaptive Computing and Information Processing Seminar, pages 25-27, Brunei Conference Centre, London, January 1993. See also Statistical Science, Vol. 8 No. 3, 266-269, 1993.\n[Pearl, 1994a] J. Pearl. Causal diagrams for empirical research. Technical Report R-218, UCLA Computer Science Department, October 1994. To appear in Biometrika.\n[Pearl, 1994b] J. Pearl. A probabilistic calculus of actions. In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, pages 454- 462, San Mateo, CA, 1994. Morgan Kaufmann Pub lishers.\n[Spirtes et al., 1993] P. Spirtes, C. Glymour, and R. Schienes. Causation, Prediction, and Search. Springer-Verlag, New York, 1993."
    } ],
    "references" : [ {
      "title" : "Causality in Bayesian belief",
      "author" : [ "Druzdzel", "Simon", "1993] M.J. Druzdzel", "H.A. Simon" ],
      "venue" : null,
      "citeRegEx" : "Druzdzel et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Druzdzel et al\\.",
      "year" : 1993
    }, {
      "title" : "Technical Report R-219U",
      "author" : [ "J. Pearl", "J. Robins. Probabilistic evaluation of sequential plans from causal models with hidden variables" ],
      "venue" : "Computer Science Department, UCLA,",
      "citeRegEx" : "Pearl and Robins. 1995",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "A theory of inferred causation",
      "author" : [ "Pearl", "Verma" ],
      "venue" : "Principles of Knowledge Representation and Reasoning: Proceedings of the 2nd International Conference,",
      "citeRegEx" : "Pearl and Verma,? \\Q1991\\E",
      "shortCiteRegEx" : "Pearl and Verma",
      "year" : 1991
    }, {
      "title" : "Probabilistic Reasoning in In­ telligence Systems",
      "author" : [ "J. Pearl" ],
      "venue" : "Morgan Kaufmann, San Mateo, CA,",
      "citeRegEx" : "Pearl. 1988",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "pages 25-27",
      "author" : [ "J. Pearl. From Bayesian networks to causal networks. In Proceedings of the Adaptive Computing", "Information Processing Seminar" ],
      "venue" : "Brunei Conference Centre, London, January",
      "citeRegEx" : "Pearl. 1993",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Technical Report R-218",
      "author" : [ "J. Pearl. Causal diagrams for empirical research" ],
      "venue" : "UCLA Computer Science Department, October",
      "citeRegEx" : "Pearl. 1994a",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "pages 454462",
      "author" : [ "J. Pearl. A probabilistic calculus of actions. In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence" ],
      "venue" : "San Mateo, CA,",
      "citeRegEx" : "Pearl. 1994b",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Causation",
      "author" : [ "P. Spirtes", "C. Glymour", "R. Schienes" ],
      "venue" : "Prediction, and Search. Springer-Verlag, New York",
      "citeRegEx" : "Spirtes et al.. 1993",
      "shortCiteRegEx" : null,
      "year" : 1993
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "3 An extension of our analysis to the case of multiple actions (sequential or concurrent) is reported in [Pearl and Robins, 1995] (iv) {fi} is a set of n deterministic functions, each of the form",
      "startOffset" : 105,
      "endOffset" : 129
    }, {
      "referenceID" : 3,
      "context" : "These two conditions, also called Markovian, are the basis of Bayesian networks [Pearl, 1988] and they en­ able us to compute causal effects directly from the conditional probabilities P(x;lpa;), without specifying Testing Identifiability of Causal Effects 187",
      "startOffset" : 80,
      "endOffset" : 93
    }, {
      "referenceID" : 5,
      "context" : ", xn)· Fortunately, certain causal effects are identifiable even in situations where mem­ bers of paj are be unobservable, and these situations can be recognized through the action calculus intro­ duced in [Pearl, 1994a].",
      "startOffset" : 206,
      "endOffset" : 220
    }, {
      "referenceID" : 5,
      "context" : "Immediate ap­ plications to cause effect analysis of nonexperimental data in the social and medical sciences are discussed in [Pearl, 1994a].",
      "startOffset" : 126,
      "endOffset" : 140
    } ],
    "year" : 2011,
    "abstractText" : "This paper concerns the probabilistic evalu­ ation of the effects of actions in the presence of unmeasured variables. We show that the identification of causal effect between a sin­ gleton variable X and a set of variables Y can be accomplished systematically, in time polynomial in the number of variables in the graph. When the causal effect is identifiable, a closed-form expression can be obtained for the probability that the action will achieve a specified goal, or a set of goals.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}