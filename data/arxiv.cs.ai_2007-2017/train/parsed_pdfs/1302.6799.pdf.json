{
  "name" : "1302.6799.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Integrating Planning and Execution in Stochastic Domains",
    "authors" : [ "Richard Dearden", "Craig Boutilier" ],
    "emails" : [ "dearden@cs.", "cebly@cs." ],
    "sections" : null,
    "references" : [ {
      "title" : "The *-minimax search procedure for trees containing chance nodes",
      "author" : [ "B.W. Ballard" ],
      "venue" : "Artificial Intelligence, 21:327-350. Boutilier, C. and Dearden, R. 1994. Using abstractions for decision-theoretic planning with time constraints.",
      "citeRegEx" : "Ballard,? 1983",
      "shortCiteRegEx" : "Ballard",
      "year" : 1983
    }, {
      "title" : "Deliberation scheduling for time-critical deci­ sion making",
      "author" : [ "T. Dean", "L.P. Kaelbling", "J. Kirman", "A. Nicholson" ],
      "venue" : "Proceedings of the Twelfth National Conference on Artificial Intelligence, Seattle",
      "citeRegEx" : "Dean et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Dean et al\\.",
      "year" : 1993
    }, {
      "title" : "Planning with deadlines in stochastic domains",
      "author" : [ "T. Dean", "L.P. Kaelbling", "J. Kirman", "A. Nicholson" ],
      "venue" : "Proceedings of the Eleventh National Conference on Artificial Intelligence, pages 574-579, Washington, D.C.",
      "citeRegEx" : "Dean et al\\.,? 1993b",
      "shortCiteRegEx" : "Dean et al\\.",
      "year" : 1993
    }, {
      "title" : "Strips: A new ap­ proach to the application of theorem proving to prob­ lem solving",
      "author" : [ "R.E. Fikes", "N.J. Nilsson" ],
      "venue" : "Artificial Intelligence, 2:189-208.",
      "citeRegEx" : "Fikes and Nilsson,? 1971",
      "shortCiteRegEx" : "Fikes and Nilsson",
      "year" : 1971
    }, {
      "title" : "Dynamic Probabilistic Systems",
      "author" : [ "R.A. Howard" ],
      "venue" : "Wi­ ley, New York.",
      "citeRegEx" : "Howard,? 1971",
      "shortCiteRegEx" : "Howard",
      "year" : 1971
    }, {
      "title" : "Real-time heuristic search",
      "author" : [ "R.E. Korf" ],
      "venue" : "Artificial Intelligence, 42:189-211.",
      "citeRegEx" : "Korf,? 1990",
      "shortCiteRegEx" : "Korf",
      "year" : 1990
    }, {
      "title" : "An al­ gorithm for probabilistic planning",
      "author" : [ "N. Kushmerick", "S. Hanks", "D. Weld" ],
      "venue" : "Technical Report 93-06-04, University of Washington, Seattle.",
      "citeRegEx" : "Kushmerick et al\\.,? 1993",
      "shortCiteRegEx" : "Kushmerick et al\\.",
      "year" : 1993
    }, {
      "title" : "Heuristics: Intelligent Search Strategies for Computer Problem Solving",
      "author" : [ "J. Pearl" ],
      "venue" : "Addison-Wesley, Read­ ing, Massachusetts.",
      "citeRegEx" : "Pearl,? 1984",
      "shortCiteRegEx" : "Pearl",
      "year" : 1984
    }, {
      "title" : "Do the Right Thing: Studies in Limited Rationality",
      "author" : [ "S.J. Russell", "E. Wefald" ],
      "venue" : "MIT Press, Cam­ bridge.",
      "citeRegEx" : "Russell and Wefald,? 1991",
      "shortCiteRegEx" : "Russell and Wefald",
      "year" : 1991
    }, {
      "title" : "Abstraction in planning",
      "author" : [ "J.D. Tenenberg" ],
      "venue" : "Allen, J",
      "citeRegEx" : "Tenenberg,? 1991",
      "shortCiteRegEx" : "Tenenberg",
      "year" : 1991
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "In (Dean et al. 1993b) it is suggested that domain-specific heuristics will aid in initial envelope selection and envelope alteration.",
      "startOffset" : 3,
      "endOffset" : 22
    }, {
      "referenceID" : 5,
      "context" : "This is the basic idea behind for example, Korf's real-time heuristic search algorithm (1990). · In stochastic domains there is an­ other important reason for interleaving execution into the planning process, namely, to restrict the search space to the actual outcomes of probabilistic actions.",
      "startOffset" : 43,
      "endOffset" : 94
    }, {
      "referenceID" : 2,
      "context" : "1 Since we are interleaving plan construction and plan execution, the time required to plan is significant when measuring success; but as a first approximation we can represent this type of sit­ uation with the reward function (Dean et al. 1993b): R(s) = 0 if s E Sg and R(s) = -1 otherwise.",
      "startOffset" : 227,
      "endOffset" : 246
    }, {
      "referenceID" : 5,
      "context" : "The use of caching here is similar to that of Learning RTA * search (Korf 1990).",
      "startOffset" : 68,
      "endOffset" : 79
    }, {
      "referenceID" : 0,
      "context" : "This search technique is related to the *-minimax algorithm of Ballard (1983). As we shall see in Section 3.",
      "startOffset" : 63,
      "endOffset" : 78
    }, {
      "referenceID" : 8,
      "context" : "The poten­ tially improved performance of a deeper search has to be weighed against the time required to perform the search (Russell and Wefald 1991).",
      "startOffset" : 124,
      "endOffset" : 149
    }, {
      "referenceID" : 0,
      "context" : "Determining the value of a state is analogous to the MAX step in minimax, while calculating the value of an action can be th ought of as an AVERAGE step, which replaces the MIN step (see also (Ballard 1983)).",
      "startOffset" : 192,
      "endOffset" : 206
    }, {
      "referenceID" : 5,
      "context" : "Expectation pruning is closely related to what Korf (1990) calls alpha-pruning.",
      "startOffset" : 47,
      "endOffset" : 59
    }, {
      "referenceID" : 9,
      "context" : "In some cases abstractions of actions and states may already be available (Tenenberg 1991).",
      "startOffset" : 74,
      "endOffset" : 90
    }, {
      "referenceID" : 3,
      "context" : "If abstract actions (possibly macro-operators (Fikes and Nilsson 1971)) are already available, we need to find clusters to which the actions apply.",
      "startOffset" : 46,
      "endOffset" : 70
    }, {
      "referenceID" : 7,
      "context" : "In none of the domains we have tested has searching deeper produced a worse pol­ icy, although this may not be the case in general (see (Pearl 1984) for a proof of this for minimax search).",
      "startOffset" : 136,
      "endOffset" : 148
    }, {
      "referenceID" : 1,
      "context" : "In par­ ticular, further comparison to exact methods like pol­ icy iteration and heuristic methods like the envelope approach of Dean et al. (1993b) would be useful.",
      "startOffset" : 129,
      "endOffset" : 149
    }, {
      "referenceID" : 8,
      "context" : ", as in (Russell and Wefald 1991) ) .",
      "startOffset" : 8,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "reconstruction phase of the recurrent deliberation model of Dean et al. (1993a).",
      "startOffset" : 60,
      "endOffset" : 80
    }, {
      "referenceID" : 7,
      "context" : "We also hope to investigate the performance of this approach in other types of domains, including high-level robot navigation, and scheduling problems, and to further investigate the theoretical properties of the algorithm, especially through analysis of the value of deeper searching in producing better plans (Pearl 1984).",
      "startOffset" : 311,
      "endOffset" : 323
    } ],
    "year" : 2011,
    "abstractText" : "We investigate planning in time-critical do­ mains represented as Markov Decision Pro­ cesses, showing that search based techniques can be a very powerful method for finding close to optimal plans. ·To reduce the compu­ tational cost of planning in these domains, we execute actions as we construct the plan, and sacrifice optimality by searching to a fixed depth and using a heuristic function to esti­ mate the value of states. Although this paper concentrates on the search algorithm, we also discuss ways of constructing heuristic func­ tions suitable for this approach. Our results show that by interleaving search and execu­ tion, close to optimal policies can be found without the computational requirements of other approaches.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}