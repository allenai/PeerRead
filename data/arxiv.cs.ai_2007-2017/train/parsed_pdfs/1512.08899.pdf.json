{
  "name" : "1512.08899.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Modeling Variations of First-Order Horn Abduction in Answer Set Programming",
    "authors" : [ "Peter Schüller" ],
    "emails" : [ "peter.schuller@marmara.edu.tr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n51 2.\n08 89\n9v 3\n[ cs\n.A I]\n3 0\nO ct"
    }, {
      "heading" : "1 Introduction",
      "text" : "Abduction [Pei55] is reasoning to the best explanation, which is an important topic in diverse areas such as diagnosis, planning, and natural language understanding (NLU).\nWe here focus on a variant of abduction, used in NLU, where the primary concern is to find an explanation of a given input (sentence) with respect to an objective function. Knowledge is expressed in First Order (FO) Horn logic axioms. For example ‘a father of somebody is male’ can be expressed as follows, where capital letters are variables which are universally quantified unless explicitly indicated otherwise.\ninst(X,male)⇐ fatherof (X,Y ).\nAbduction aims to find a set of explanatory atoms that make a set of goal atoms true with respect to a background theory (i.e., a set of axioms). If inst(tom,male) is part of a goal then abduction can explain this goal atom with the atom fatherof (tom,mary) where mary is another person of interest. Using abduction, we can interpret whole natural language texts, for example ‘Mary lost her father. She is depressed.’ can be interpreted using knowledge about losing a person, death of a person, and being depressed, such that we obtain an abductive explanation that represents ‘Mary’s father died, and this is the reason for her depression’.\n∗This work is a significant extension of [Sch15]; major additions are preference relations Coh and Wa, revised encodings, increase performance, on-demand constraints, and flexible value invention. This work has been supported by Scientific and Technological Research Council of Turkey (TUBITAK) Grant 114E777.\nAbductive reasoning in FO Horn logic yields an infinite space of potential inferences, because backward reasoning over axioms can produce existentially quantified variables, which can introduce new terms (value invention). For example the above axiom is transformed as follows.\ninst(X,male) ⇒ ∃Y : fatherof (X,Y ).\nTo achieve decidability, we need to limit value invention, which leads to a challenging trade-off: the more we limit value invention, the more (potentially optimal) solutions we lose.\nA second challenge in FO logic is, that terms (input and invented) can be equivalent to other terms. Equivalent terms make distinct atoms equivalent, which is used in an inference called factoring. In the above example, we can say that is(mary , depressed) is factored with is(she, depressed) under the assumption that the equivalence mary = she holds.\nA crucial issue when using abduction for NLU is the choice of an appropriate preference among possible abductive explanations. Cardinality minimality of the set of abduced atoms is a frequently used preference, however in NLU two other preferences have turned out to be more effective: coherence [NM90, Ng92], and weighted abduction [Sti89, HSME93, SM11], which are based on a proof graph induced by back-chaining and unification operations.\nSeveral tools for realizing abduction with such preferences exist: Phillip, based on Integer Linear Programming (ILP) [YII+15] and its precursor Henry-n700 [II13] as well as an approach based on Markov Logic [BHD+11]. The problem of termination is solved in [BHD+11] by instantiating existential terms only with terms from the input (no value invention), while [II13, YII+15] solves the issue by inventing a new term only if no previously invented term is present in the head of the axiom.\nUnfortunately, using only input terms eliminates many valid solutions in NLU applications, for example when processing a text about a son and a grandfather, we would be unable to perform reasoning about the father (because it does not exist as a constant). The alternative approach of blocking value invention if an invented value is involved in the rule improves the situation, however it is an ad hoc solution and its implications on solution quality have not been formally or experimentally analyzed.\nIn addition to decidability issues, global consistency constraints are necessary to yield practically meaningful abductive explanations, however existing solvers Henry-n700 and Phillip realize each possible form of a global constraint (e.g., unique slot values) in a separate checking procedure and make it difficult to experiment with additional constraints.\nTowards overcoming some of these problems, we realize abduction in the declarative formalism of Answer Set Programming (ASP) [Lif08] which allows modular modeling of combinatorial problems based on clearly defined formal semantics. Primary motivation for this work is to obtain a more flexible framework where variations of Skolemization, objective functions and global constraints on abduction can be studied easily and where novel preferences can be studied, such as [Sch14] that can comfortably be represented in ASP but not in other solvers. Our secondary motivation is, to use ASP for realizing a task that it is not typically used for, and to study how far we can go in this task.\nRealizing FO Horn abduction in ASP poses further challenges for the following reasons:(i) ASP semantics is based on the Unique Names Assumption (UNA), which means that distinct terms cannot be equivalent (e.g., mary = she is not expressible in a built-in feature of ASP); moreover (ii) ASP rules have no built-in support for existential variables in rule heads, which is necessary for value invention during back-chaining as shown above. In particular, Skolemization using function symbols, i.e., replacing ∃Y : fatherof (X,Y ) by fatherof (X, sk(X)) where sk is a new function symbol, does not guarantee a finite instantiation.\nWe tackle the above challenges and present an ASP framework for solving FO Horn abduction problems for objective functions weighted abduction, coherence, and cardinality minimality. We describe insights on the structure of the problem as well as insights on the efficiency of straightforward versus more involved ASP formulations. Our formulation allows a fine-grained configuration of Skolemization for tackling cyclic background theories, moreover it permits the usage of global constraints of any form that is expressible in ASP. Experiments show, that our framework is faster than the state-of-the-art solver Phillip [YII+15] on the Accel benchmark [NM92] for plan recognition in NLU.\nIn detail, we make the following contributions.\n• We provide a novel uniform formalization of abduction with preference relations weighted abduction, coherence, and cardinality minimality (Section 2).\n• We present an ASP encoding that realizes back-chaining in ASP by deterministically representing an abductive proof graph and guessing which parts of that graph to use. For value invention we use uninterpreted function terms, and we explicitly represent an equivalence relation between terms to model unification (Section 3.2).\n• We describe canonicalization operations on proof graphs, show that they do not eliminate optimal solutions, and use these transformations for encoding factoring efficiently (Section 3.3).\n• We present an alternative ASP encoding which does not represent a proof graph, instead it generates abduced atoms, defines truth using axioms, and tests if goals are reproduced (Section 3.4).\n• We give ASP encodings for realizing the objective functions weighted abduction, coherence, and cardinality minimality (Section 3.5).\n• We study an alternative method for value invention by replacing uninterpreted function terms with external computations. This provides us with a fine-grained control over Skolemization, which is more flexible than state-of-the-art solutions for achieving decidability. We formalize this extension using the HEX formalism, and show termination guarantees for arbitrary (i.e., including cyclic) knowledge bases (Section 4.1).\n• We apply a technique used to increase performance of the Henry-n700 solver [II13] for weighted abduction to our encodings by introducing on-demand constraints for transitivity of the equivalence relation and for ensuring acyclicity of the proof graph. We formalize this using HEX and describe an algorithm for computing optimal models in the presence of on-demand constraints using the Python API of Clingo [GKKS14] (Section 4.2).\n• We perform computational experiments on the Accel benchmark [NM92] where we measure and discuss resource consumption in terms of space, time, and solver-internal statistics, as well as solution quality in terms of the objective function (Section 5). For experimental evaluation we use the Python API of Clingo, Gringo [GKKS11] with either Clasp [GKK+15] or Wasp [ADLR15], and the Phillip [YII+15] solver for weighted abduction which is based on C++ and Integer Linear Programming (ILP).\nWe discuss related work in Section 6 and conclude in Section 7. Appendices provide additional information: all ASP encodings in their complete version; verbose listing of rewriting and answer set of the running example; proofs for correctness of encodings; and algorithms for realizing on-demand constraints.\nOur framework, including experimental instances and algorithms, is available online.1"
    }, {
      "heading" : "2 Preliminaries",
      "text" : "We give a brief introduction of abduction in general and variations of First Order Horn abduction as used in Natural Language Processing, describe the Accel benchmark which contains instances of such reasoning problems, and give preliminaries of ASP and HEX.\nIn the following, in logical expressions and ASP rules we write variables starting with capital letters and constants starting with small letters."
    }, {
      "heading" : "2.1 Abduction and Preferences on Abductive Explanations",
      "text" : "Abduction, originally described in [Pei55], can be defined logically as follows: given a set B of background knowledge axioms and an observation O, find a set H of hypothesis atoms such that B and H are consistent and reproduce the observation, i.e., B ∪H 6|= ⊥ and B ∪H |= O. In this work we formalize axioms and observations in First Order logic: the observation O (also called ‘goal’) is an existentially quantified conjunction of atoms\n∃V1, . . . , Vk : o1(V1, . . . , Vk)∧ · · · ∧ om(V1, . . . , Vk) (1)\n1https://bitbucket.org/knowlp/asp-fo-abduction\nand an axiom in B is a Horn clause of form\nq(Y1, . . . , Ym) ⇐ p1(X 1 1 , . . . , X 1 k1 )∧ · · · ∧ pr(X r 1 , . . . , X r kr ). (2)\nwhere X = ⋃\n1≤ i≤ r\n⋃\n1≤ j ≤ kr X ij is the set of variables in the body, Y =\n⋃\n1≤ i≤m Yi is the set of\nvariables in the head, Y ⊆X and we implicitly quantify universally over X . In the variant of abduction we consider here, the set H of hypotheses can contain any predicate from the theory B and the goal O, hence existence of a solution is trivial. A subset S of constants from B is declared as ‘sort names’ that cannot be equivalent with other constants. Given B, O, and S, we call the tuple (B,O, S) an abduction instance. Unless otherwise indicated, we assume that B is acyclic.\nExample 1 (Running Example). Consider the following text\n‘Mary lost her father. She is depressed.’\nwhich can be encoded as the following observation, to be explained by abduction.\nname(m,mary)∧lost(m, f)∧fatherof (f,m)∧inst(s, female)∧is(s, depressed) (3)\nGiven the set of axioms\ninst(X,male) ⇐ fatherof (X,Y ) (4)\ninst(X, female) ⇐ name(X,mary) (5)\nimportantfor (Y,X) ⇐ fatherof (Y,X) (6)\ninst(X, person) ⇐ inst(X,male) (7)\nis(X, depressed) ⇐ inst(X, pessimist) (8)\nis(X, depressed) ⇐ is(Y, dead)∧ importantfor (Y,X) (9)\nlost(X,Y ) ⇐ is(Y, dead)∧ importantfor (Y,X)∧ inst(Y, person) (10)\nand sort names\nperson male female dead depressed (11)\nwe can use abduction to conclude the following: (a) loss of a person here should be interpreted as death, (b) ‘she’ refers to Mary, and (c) her depression is because of her father’s death because her father was important for her.\nWe obtain these because we can explain (3) by the following abductive explanation which contains atoms and equivalences.\nname(m,mary) fatherof (f,m) is(f, dead) m = s (12)\nThe first two atoms directly explain goal atoms. We can explain the remaining goal atoms using inference from rules and factoring (which represents unification in a certain reasoning direction).\ninst(f,male) [infered via (4) using (12)] (13)\ninst(m, female) [infered via (5) using (12)] (14)\ninst(s, female) [goal, factored from (14) using (12)]\nimportantfor (f,m) [infered via (6) using (12)] (15)\ninst(f, person) [infered via (7) using (13)] (16)\nis(m, depressed) [infered via (9) using (12) and (15)] (17)\nis(s, depressed) [goal, factored from (17) using (12)]\nlost(m, f) [goal, infered via (10) using (12), (15), and (16)] (18)\nNote that there are additional possible inferences but they are not necessary to explain the goal atoms. Moreover, there are several other abductive explanations, for example to abduce all goal atoms, or to abduce inst(m, pessimist) and lost(m, f) instead of abducing is(f, dead).\nPreferred explanations. In the presence of multiple possible explanations, we are naturally interested in obtaining a set of preferred explanations. In this work we consider three preference formulations: (Card) cardinality-minimality of abduced atoms, (Coh) ‘coherence’ as described in [NM92] and in slight variation in more detail in [NM90], and (Wa) ‘weighted abduction’ as initially formulated in [HSME93].\nCoh is based on connectedness between observations and explanations, while Wa finds a trade-off between least-specific and most-specific abduction, depending on the explanatory power of more specific atoms. Both objective functions are based on an inference procedure that induces a proof graph by means of backchaining and unification.\nTowards formalizing these preference functions, we next formalize such an inference procedure. The following definitions are based on [Sti89, IOIH14] but additionally define an explicit proof graph corresponding to the inferences leading to a hypothesis. Here we consider only single-head axioms.\nDefinition 1. A hypothesis is a conjunction of atoms or equivalences between terms. Given an abduction instance A=(B,O, S) the set Ĥ(A) of all hypotheses of A is the largest set containing hypotheses obtained by extending H= {O} using back-chaining and unification.\nBack-chaining: given an atom P which is part of a hypothesis (P ∈H , H ∈H), such that P unifies with the head Q= q(Y1, . . . , Ym) of an axiom (2) with substitution θ, back-chaining adds to H a new hypothesis H ∧P ′1 ∧ · · · ∧P ′ r, where P ′ i is the substituted version θ(pi(X i 1, . . . , X i ki ) of the i-th body atom of axiom (2). Unification: given hypothesis H ∈H with distinct atoms P,Q∈H that unify under substitution θ such that all X 7→Y ∈ θ obey X,Y /∈S, unification adds hypothesis H∧ ∧ {X= Y |X 7→Y ∈ θ} to H.\nNote that Ĥ(A) is potentially infinite. We sometimes leave A implicit.\nExample 2 (continued). Three hypotheses for the abduction instance in Example 1 are(a) the original goal G as shown in (3), which intuitively means that we do not justify any atom in the goal by inference, instead we abduce all atoms in the goal; (b) the hypothesis G ∧ is(f, dead) ∧ m= s ∧ inst(f,male)∧inst(m, female)∧importantfor (f,m)∧inst(f, person)∧is(m, depressed) which corresponds to (13)–(18) and includes the abductive explanation (12); and (c) the hypothesis G ∧ name(s,mary) ∧ m= s ∧ inst(f, person) ∧ inst(f,male) ∧ fatherof (f, n2) ∧m=n2 ∧ is(n1, dead) ∧ f =n1 ∧ is(f, dead) ∧ importantfor (f,m) ∧ importantfor (n1,m) which applies Skolemization during back-chaining and represents a variation of explanation (12). Details about this hypothesis can be found in Example 3 and in Figure 1.\nA hypothesis H ∈ Ĥ does not contain any information about how it was generated. For the purpose of describing the cost function formally, we define proof graphs G wrt. hypotheses H .\nDefinition 2. Given an abduction instance A=(B,O, S), a proof graph G wrt. a hypothesis H∈ Ĥ(A) is an acyclic directed graph consisting of nodes N(G)= {P ∈H |P is not an equality} and edges E(G) are recursively defined by the inference operations used to generate atoms P ∈H :(a) back-chaining of P induces an edge from all body atoms P ′i to P , and (b) unification of P with Q induces either an edge from P to Q or an edge from Q to P .\nWe denote by A(G)= {a∈N(G) | ∄b : (b, a)∈E(G)} the set of nodes that are neither back-chained nor unified. Note that the term ‘factoring’ is used to denote unification with direction, this is discussed in detail in [Sti89]. There can be multiple proof graphs with respect to a single hypothesis, and these graphs differ only by factoring directions. Figure 1 depicts a proof graph which is discussed in Example 3.\nIntuitively, an edge in the proof graph shows how an atom is justified: by inference over an axiom (backchaining) or by equivalence with another atom (factoring).\nEquipped with these definitions, we next formalize the objective functions of interest.\nDefinition 3. Given a proof graph G wrt. a hypothesis H of an abduction instance (B,O, S), • Card= |A(G)|, • Coh= |{(a, b) |a, b∈O, a< b, and ∄n∈N(G) such that from n we can reach both a and b in G}| where the relation < is an arbitrary fixed total order over O (e.g., lexicographic order),\n• Wa= ∑\na∈A(G) min cost(a), where cost : N(G) → 2 R labels each atom in the graph with a set of\ncost values.\nFor the definition of cost in Wa we require that each axioms of form (2) has weights w1, . . . , wr corresponding to its body atoms, and initial costs ic(o) for each observation o∈O.\nThen cost is initialized with ∅ for each node and recursively defined as follows: • goal nodes o∈O obtain cost cost(o)= cost(o)∪{ic(o)}; • if P was back-chained with an axiom with body atoms P ′1, . . . , P ′ r and c= min cost(P ), then c is\nadded to each body atom P ′i after adjusting it using the respective cost multiplier wi, formally cost(P ′i )= cost(P ′ i )∪ {c ·wi} for 1≤ i≤ r; • if P was unified with Q such that there is a factoring edge (Q,P )∈G from Q to P , then we add the smallest cost at P to Q: cost(Q)= cost(Q)∪{min cost(P )}.\nNote that the formalization in [IOIH14, above (1)] assigns unification cost to the equality, but does not use that cost in case of multiple unifications, hence we do not use such a formalization. Moreover, deleting cost values from the hypothesis with higher cost in a unification (as shown in [IOIH14, Fig. 1, ‘Output’ vs ‘Backward-chaining’]) contradicts the formalization as a cost ‘function’ that maps hypotheses to costs. Therefore our formalization defines cost to map from atoms in a hypothesis to multiple ‘potential’ costs of that hypothesis. Note that due to acyclicity of the graph, no cost in cost recursively depends on itself, and that back-chaining can create hypothesis atoms containing a part of the goal, therefore goal nodes can have a cost lower than that goal’s initial cost (e.g., fatherof (f,m) in Figure 1).\nThe formalization in this section was done to provide a basis for showing correctness of canonicalization operations on proof graphs and for showing correctness of ASP encodings. To the best of our knowledge, no precise formal description of proof graphs and associated costs of Coh and Wa exists in the literature, therefore we here attempt to formally capture the existing descriptions [NM92, HSME93, II13].\nExample 3 (continued). The proof graph of Example 1 is depicted in Figure 1 where we also show the set of costs of each node using objective Wa. The total cost of this graph is 100$+48$+40$=188$. Objective Card has cost 3 because we abduce 3 atoms, and objective Coh has cost 6: let goal node set A= {inst(s, female), name(m,mary)} and B= {fatherof (f,m), lost(m, f), is(s, depressed)}, then nodes within A and within B are reachable from some node, however pairs {(a, b) |a∈A, b∈B} of nodes are not reachable from any node, and each of these |A| · |B|=6 pairs incurs cost 1.\nNote that in this work we consider only hypotheses and proof graphs where an atom is either justified by a single inference, or by a single factoring, or not at all (then it is abduced).\nComputational Complexity. Existence of an abductive explanation is trivial, because we can abduce any atom and the goal is the trivial explanation. However, finding the optimal abductive explanation with respect to an objective function is not trivial. With unlimited value invention and cyclic theories the problem of finding the optimal explanation is undecidable, as we cannot bound the size of the proof graph or the number of additionally required constants for finding the optimal solution.\nTo the best of our knowledge, the computational complexity of deciding whether an abductive explanation is optimal wrt. one of the objective functions Card, Coh, and Wa, has not been formally studied so far, although for Card related results exist. Section 6 discusses related complexity results.\n2.2 Accel Benchmark\nThe Accel benchmark2 [NM92, Ng92] contains a knowledge base with 190 axioms of form (2), defines a set of sort names that observe the UNA, and contains 50 instances (i.e., goals) with between 5 and 26 atoms in a goal (12.6 atoms on average). Axioms contain a single head and bodies vary between 1 and 11 atoms (2.2 on average). Accel axioms contain no weights and goal atoms contain no initial costs. For experiments with Wa we follow existing practice (cf. [II13]) and set initial costs to ic(o)= 100$ for all o∈O and for each axiom we set weights to sum up to 1.2, i.e., we set wi =1.2/r, 1≤ i≤ r.\nIn addition to axioms, goals, and sort names, Accel contains constraints that forbid certain combinations of atoms to become abduced at the same time (assumption nogoods) and constraints that enforce functionality for certain predicate symbols (unique slot axioms). We next give two examples.\nExample 4. An example for an assumption nogood is, that we are not allowed to abduce an event G to be part of a ‘go’ event S, and at the same time abduce that a person P is the ‘goer’ of G.\n6 ∃S,G, P : {go_step(S,G), goer (G,P )}∈H for all H ∈ Ĥ (19)\nAn example for a unique slot axiom is, that the ‘goer’ of an event must be unique.\n6 ∃G,P1, P2 : P1 6= P2 ∧{goer(G,P1), goer (G,P2)}∈H for all H ∈ Ĥ (20)"
    }, {
      "heading" : "2.3 Answer Set Programming",
      "text" : "We assume familiarity with ASP [GL88, Lif08, EIK09, GKKS12] and give only brief preliminaries of HEX programs [EFI+16] which extend the ASP-Core-2 standard [CFG+12]. We will use programs with (uninterpreted) function symbols, aggregates, choices, and weak constraints. Syntax. Let C, X , and G be mutually disjoint sets of constants, variables, and external predicate names, which we denote with first letter in lower case, upper case, and starting with ‘& ’, respectively. Constant names serve as constant terms, predicate names, and names for uninterpreted functions. The set of terms T is recursively defined, it is the smallest set containing N∪C ∪X as well as uninterpreted function terms of form f(t1, . . . , tn) where f ∈C and t1, . . . , tn ∈T . An ordinary atom is of the form p(t1, . . . , tn), where p∈C, t1, . . . , tn ∈T , and n ≥ 0 is the arity of the atom. An aggregate atom is of the form X =#agg{ e1; . . . ; ek } with variable X ∈X , aggregation function #agg ∈{#min ,#max}, k≥ 1 and each aggregate element ei, 1≤ i≤k, is of the form t : a or t with t∈T and a an atom. An external atom is of the form &f [y1, . . . , yn](x1, . . . , xm), where y1, . . . , yn, x1, . . . , xm ∈T are two lists of terms (called input and output lists, resp.), and &f ∈ G is an external predicate name. An external atom provides a way for deciding the truth value of an output tuple depending on the input tuple and a given interpretation. A term or atom is ground if it contains no sub-terms that are variables.\nA rule r is of the form α1 ∨ · · · ∨ αk ← β1, . . . , βn,notβn+1, . . . ,notβm where m, k ≥ 0, αi, 0≤ i≤ k is an ordinary atom and βj , 0≤ j≤m is an atom, and we let H(r) = {α1, . . . , αk} and B(r) = {β1, . . . , βn,notβn+1, . . . ,notβm}. A program is a finite set P of rules. A rule r is a constraint, if k=0 and m 6=0, and a fact if m=0.\n2Available at ftp://ftp.cs.utexas.edu/pub/mooney/accel .\nA weak constraint is of form β1, . . . , βn,notβn+1, . . . ,notβm. [w@1, t1, . . . , tk] where all βj are atoms, and all ti are terms such that each variable in some ti is contained in some βj (note that 1 in w@1 shows the ‘level’ which we do not use). Semantics. Semantics of a HEX program P are defined using its Herbrand Base HBP and its ground instantiation grnd(P ). An aggregate literal in the body of a rule accumulates truth values from a set of atoms, e.g., C =#min{4; 2 : p(2)} is true wrt. an interpretation I ⊆HBP iff p(2)∈ I and C =2 or p(2) /∈ I and C =4. Using the usual notion of satisfying a rule given an interpretation, the FLP-reduct [FPL11] fP I reduces a program P using an answer set candidate I: fP I = {r∈ grnd(P ) | I |=B(r)}. I is an answer set of P (I ∈AS(P )) iff I is a minimal model of fP I . Weak constraints define that an answer set I has cost equivalent to the term w for each distinct tuple t1, . . . , tk of constraints that have a satisfied body wrt. I. Answer sets of the lowest cost are preferred. Safety and Splitting. Programs must obey syntactic safety restrictions (see [CFG+12]) to ensure a finite instantiation. In presence of loops over external atoms, HEX programs additionally must obey restrictions to ensure finite instantiation. A splitting set [LT94] of a program P is any set U of literals such that, for every rule r∈P , if H(r)∩U 6= ∅ then B(r)⊆U . The set of rules r∈P such that B(r)⊆U is called the bottom bU (P ) of P relative to U . Given splitting set U of program P , I ∈AS (P ) iff I =X ∪Y where X ∩Y = ∅, X ∈AS(bU (P )), and Y ∈AS(eU (P \\ bU (P ), X)) where eU (Q, J) partially evaluates Q wrt. J . Splitting sets were lifted to HEX in [EIST06, EFI+16]. Syntactic Sugar. Anonymous variables of form ‘_’ are replaced by new variable symbols. Choice constructions can occur instead of rule heads, they generate a set of candidate solutions if the rule body is satisfied; e.g., 1≤{p(a); p(b); p(c)}≤ 2 in the rule head generates all solution candidates where at least 1 and at most 2 atoms of the set are true. The bounds can be omitted. In choices, the colon symbol ‘:’ can be used to generate a list of elements (similar as in aggregates), for example {p(X) : q(X),not r(X)} encodes a guess over all p(X) such that q(X) is true and r(X) is not true."
    }, {
      "heading" : "3 ASP Encodings",
      "text" : "We next describe ASP encodings for modeling abduction with partial UNA and value invention. All encodings consist of a deterministic part that instantiates all atoms that can potentially used to build a hypothesis, i.e., to justify the goal. Some encodings also explicitly represent inferences leading to these atoms. All encodings guess an equivalence relation over all terms in these ‘potentially interesting’ atoms, to handle term equivalence. In Bwd encodings, the actually used proof graph is nondeterministically guessed, while encoding Fwd-A performs a guess of abduced atoms and checks if the goals become true given these atoms. Variations of Bwd encodings perform factoring in different ways. We next give common aspects of all encodings, then give each encoding in detail, and finally provide a summary of differences between encodings (Table 1).\nA detailed example containing a rewriting of our running example and an answer set corresponding to Figure 1 is given in the appendix.\nWe represent an atom of the form p(a, b) as a term c(p, a, b), which allows us to quantify over predicates using ASP variables (e.g., c(P,X, Y )). We represent each atom in a goal (1) as a fact\ngoal (c(o1, v1, . . . , vk)). (21)\nwhere vi /∈S are constants corresponding to existentially quantified variables Vi. We mark each sort name s∈S using a fact\nsortname(s). (22)\nExample 5 (continued). Goal and sort names of our running example are represented as\ngoal(c(name,m,mary)). goal (c(lost ,m, f)). goal(c(fatherof , f,m)).\ngoal(c(inst , s, female)). goal (c(is , s, depressed)). sortname(person).\nsortname(male). sortname(female). sortname(dead). sortname(depressed)."
    }, {
      "heading" : "3.1 Rules common to all encodings",
      "text" : "Goals are potential interesting facts, i.e., potential nodes of the proof graph:\npot(X)← goal(X). (23)\nPotential interesting facts provide potentially relevant terms in the Herbrand Universe (HU).\nhu(X)← pot(c(_, X,_)). (24)\nhu(X)← pot(c(_,_, X)). (25)\nNote that (24) and (25) assume, that all atoms in B and O have arity 2. This assumption is made only in these two rules, which can be generalized easily to arbitrary arities.\nWe call terms in HU that are not sort names ‘User HU’, represent them in predicate uhu, and guess a relation eq among pairs of these terms.\nuhu(X)←hu(X),not sortname(X). (26)\n{ eq(A,B) : uhu(A), uhu(B), A 6=B }← . (27)\nRelation eq holds symmetric on HU, and it is a reflexive, symmetric, and transitive (equivalence) relation.\neq(A,A)←hu(A). (28)\n← eq(A,B),not eq(B,A). (29)\n← eq(A,B), eq(B,C), A 6=B,B 6=C,A 6=C,not eq(A,C). (30)\nNote, that we will later create instantiations of constraint (30) in a lazy manner (on-demand), therefore we use a constraint to ensure transitivity, and not a rule.\n3.2 Bwd: Defining Back-chaining Proof Graph, Guess Active Parts\nWe next encode the maximal back-chaining proof graph from Definition 2 in ASP by:(i) deterministically defining the maximum possible potential proof graph by back-chaining from the goal and creating new constants when required; (ii) guessing which parts of the proof graph are used, i.e., which atoms are back-chained over which axioms, and which bodies of axioms must therefore be justified; (iii) factor atoms with other atoms and mark the remaining atoms as abduced.\nPotential Proof Graph. Building the potential proof graph is realized by rewriting each axiom of form (2) into a deterministic definition of potential inferences from the axiom’s head atom, and defining which body atoms become part of the hypothesis due to such an inference.\nWe first give this rewriting as an example and then formally.\nExample 6. Axiom (9) from our running example is translated into the following rules.\nmayInferVia(r1, c(is , X, depressed), l(Y ))←\npot(c(is , X, depressed)), Y = s(r1, “Y ”, X). (31)\ninferenceNeeds(c(is , X, depressed), r1, c(importantfor , Y,X))←\nmayInferVia(r1, c(is , X, depressed), l(Y )). (32)\ninferenceNeeds(c(is , X, depressed), r1, c(is , Y, dead))←\nmayInferVia(r1, c(is , X, depressed), l(Y )). (33)\nHere r1 is a unique identifier for axiom (9). Rule (31) defines all possible substitutions of the axiom, including value invention via Skolemization which is represented in the last argument of mayInferVia in the term l(· · · ). Rules (32) and (33) define which body atoms become part of the hypothesis because of back-chaining. Note that Skolemization is here realized with an uninterpreted function term s(r1, “Y ”, X) that takes as arguments the unique axiom identifier r1, the name of the skolemized existential variable “Y ” (to skolemize several variables in one axiom independently), and all variables (here only X) in the body of the axiom.\nFor each body atom that can be added to the hypothesis by an inference, inferenceNeeds(Head , Rule,Body) is defined. To allow back-chaining from Body , we define Body as potentially interesting.\npot(P )← inferenceNeeds(_,_, P ) (34)\nAxioms rewritten as in (31)–(33) together with (23) and (34) form a deterministic ASP program, that, given a set of goal atoms goal (A), defines the union of all possible proof graphs.\nThis graph is finite under the assumption that the knowledge base is acyclic, i.e., that no circular inferences are possible over all axioms in the knowledge base. (For reasons of presentation we will maintain this assumption while presenting the basic encodings and eliminate the assumption in Section 4.1.)\nFor readability we gave the rewriting in Example 6. Formally, an axiom of form (2) is rewritten into\nmayInferVia(a, c(q, Y1, . . . , Ym), l(Z1, . . . , Zv))←\npot(c(q, Y1, . . . , Ym)), Z1 = s(a, 1, Y1, . . . , Ym), . . . , Zv = s(a, v, Y1, . . . , Ym)\ninferenceNeeds(c(q, Y1, . . . , Ym), a, c(pi, X i 1, . . . , X i ki ))← (35)\nmayInferVia(a, c(q, Y1, . . . , Ym), l(Z1, . . . , Zv)) for i∈{1, . . . , r}\nwhere a is a unique identifier for that particular axiom, Z1, . . . , Zv =X \\Y is the set of variables occurring in the body but not in the head, and the second argument of the uninterpreted function s(·) is a unique identifier for each skolemized variable in this axiom.\nLemma 1. Given an abduction instance A=(B,O, S), let Pbos(A)=Pb∪Po∪Ps where Pb is the rewriting of each axiom in B as (35), Po the rewriting of O as (21), and Ps the rewriting of S as (22). Let Pbpt (A) = Pbos(A)∪ {(23), (34)}. Then Pbpt(A) has a single answer set I that represents the union of all proof graphs of all hypotheses of A that are generated by back-chaining according to Def. 2, with nodes {P | pot(P )∈ I} and edges {(Q,P ) |mayInferVia(R,P, L)∈ I, inferenceNeeds(P,R,Q)∈ I}.\nRepresenting a Hypothesis. Based on the potential proof graph defined above, we now formulate in ASP the problem of guessing a hypothesis, i.e., selecting a connected part of the potential proof graph as a solution to the abduction problem. Nodes of the proof graph are represented as true(·).\nIf an atom P is a goal, it is true.\ntrue(P )← goal(P ). (36)\nIf an atom P is true, it is back-chained (infer (·)), factored, or abduced (the latter two represented as fai).\n1≤{ infer(P ) ; fai(P ) }≤ 1← true(P ). (37)\nEach atom P that is marked as inferred in the proof graph, has to be back-chained via exactly one axiom R.\n1≤{ inferVia(R,P ) : mayInferVia(R,P,_) }≤ 1← infer(P ). (38)\nIf back-chaining an atom P would add body atom Q to the hypothesis, then we define Q as true.\ntrue(Q)← inferVia(R,P ), inferenceNeeds(P,R,Q). (39)\nThis encoding guesses the back-chaining part of a particular proof graph and hypothesis.\nProposition 2. Given an abduction instance A = (B,O, S), let Pgp consist of rules (36)–(39). Then answer sets AS(Pbpt (A)∪Pgp) correspond 1-1 with proof graphs G induced by hypotheses H ∈ Ĥ(A) via back-chaining: edges E(G) are represented as inferVia(·, ·), nodes N(G) as true(·), back-chained atoms as infer (·), and other atoms in fai(·)."
    }, {
      "heading" : "3.3 Factoring",
      "text" : "So far we merely encoded the back-chaining part of proof graphs. It remains to deal with unification, which allows us to identify those atoms in a hypothesis that incur a cost in Card and Wa because they must be abduced. For that we use rules (24)–(30) which guess an equivalence relation eq(·, ·) over the Herbrand Universe such that constants that are not sort names can be equivalent with other constants.\nLemma 3. Given an abduction instance A = (B,O, S), let Peq consist of rules (24)–(30). Then AS(Pbpt(A)∪Peq) contains one answer set for each equivalence relation on the HU of I ∈AS(Pbpt(A)) represented in predicate eq such that sort names are singleton equivalence classes.\nAtoms that are not back-chained are represented as fai(P ). These must either be unified or abduced.\n3.3.1 Bwd-G: Guess Factoring\nThis method guesses whether an atom is factored or abduced and represents for factored atoms with which other atom they have been unified. As the deterministically defined proof graph does not contain factoring between inference steps, we require factoring with inferred atoms to obtain all possible proof graphs. (We discuss and relax this restriction in Section 3.3.3.)\nFor an atom in H that is not inferred, we guess if it is factored or abduced.\n1≤{ factor (P ) ; abduce(P ) }≤ 1← fai(P ). (40)\nIf a factored atom A1 = c(P, S1, O1) unifies with an inferred atom A2 = c(P, S2, O2) that is not below A1 in the proof graph, then represent that A1 is factored via A2.\nfactorVia(c(P, S1, O1), c(P, S2, O2))← factor (c(P, S1, O1)), infer (c(P, S2, O2)),\nnot below (c(P, S2, O2), c(P, S1, O1)), eq(S1, S2), eq(O1, O2). (41)\nWe define below (A1, A2) as a partial order over atoms such that A1 is below A2 whenever inference of A1 requires A2, and whenever A1 is factored via A2. Intuitively, ‘below’ can be read as ‘closer to goal nodes’.\nbelow(P,Q)← inferVia(R,P ), inferenceNeeds(P,R,Q). (42)\nbelow(A,C)← below (A,B), below (B,C). (43)\nbelow(P,Q)← factorVia(P,Q). (44)\nNote that without not below (· · · ) in (41), we would obtain cyclic proof graphs where an atom justifies itself. This would affect all objective functions we study, therefore we need to eliminate such cases.\nIf a factored atom unifies with an abduced atom, represent that this is the case.\nfactorVia(c(P, S1, O1), c(P, S2, O2))←\nfactor (c(P, S1, O1)), abduce(c(P, S2, O2)), eq(S1, S2), eq(O1, O2). (45)\nFinally, we require that all factored atoms are unified with another atom.\nfactorOk (P )← factorVia(P,_). (46)\n← factor (P ),not factorOk (P ). (47)\nWe do not prove correctness of Bwd-G, as encoding Bwd-A is similar and has better performance.\n3.3.2 Bwd-AI: Abduced/Inferred Cluster Factoring\nAs an alternative to guessing which atoms are factored and which are abduced, we next define deterministically, that every atom that can be factored with an inferred atom must be factored with that atom, and that all remaining sets X of atoms that unified wrt. eq are factored with the (lexicographically) smallest atom in that equivalence class X of atoms, in the following called ‘cluster’.\nTo that end, instead of (41) we use the following rule.\nfactorViaI (c(P, S1, O1), c(P, S2, O2))← fai(c(P, S1, O1)), infer (c(P, S2, O2)),\nnot below (c(P, S2, O2), c(P, S1, O1)), eq(S1, S2), eq(O1, O2). (48)\nWe represent atoms that are factored via inferred atoms using predicate factorI and we represent what remains to be factored or abduced in fa. Moreover, we define that factorViaI entails factorVia .\nfactorI (P )← factorViaI (P,_). (49)\nfa(P )← fai(P ),not factorI (P ). (50)\nfactorVia(A,B)← factorViaI (A,B). (51)\nNext we deal with these remaining atoms: we define a partial order over atoms that unify under equivalence eq and factor these clusters with the (lexicographically) smallest element as follows.\nfactorCluster (c(P, S2, O2), c(P, S1, O1))← fa(c(P, S1, O1)), fa(c(P, S2, O2)), eq(S1, S2),\nc(P, S1, O1)<c(P, S2, O2), eq(O1, O2). (52)\nfactorClusterAbove(A)← factorCluster (A,_). (53)\nfactorVia(A,B)← factorCluster (A,B),\nnot factorClusterAbove(B). (54)\nNote that (52) defines the partial order, (53) represents elements that are not the smallest in the cluster, and (54) maps the partial order into factorVia using the smallest element as the atom that all others are unified with. Finally, we define below using rules (42)–(44), and we define that every hypothesis atom that could not be factored is abduced.\nfactor (P )← factorVia(P,_). (55)\nabduce(P )← fa(P ),not factor (P ). (56)\nNote that this encoding represents a restricted set of solutions compared to the previous one, however because of the symmetry of unification, by fixing the direction of factoring we merely canonicalize solutions and cannot lose optimal solutions.\nExample 7 (continued). To illustrate, that the factoring method of Bwd-AI does not eliminate optimal solutions, consider the arc between the abduced atom fatherof (f,m) and the factored atom fatherof (f, n2) in Figure 1: if we reverse this arc, then the former becomes factored and the latter abduced. The number of abduced atoms stays the same, therefore Card is not affected; reachability stays the same so Coh is not affected; and costs propagate the other direction: fatherof (f,m)48$, 100$ obtains cost via (6) and initial goal cost; fatherof (f, n2) 48$, 57$ obtains cost from factoring and via (4), so Wa remains unchanged. Similarly, the factoring edge between name(m,mary) and name(s,mary) could be reversed: then name(m,mary)100$ obtains only initial goal cost and we would abduce name(s,mary)100$, 120$ and minimum cost of Wa remains 100$ for these nodes, moreover the number of abduced atoms (Card) and reachability (Coh) stays the same.\nFor reversing factoring arcs between two non-abduced atoms, consider reversing the arc between importantfor (f,m) and importantfor (n1,m) in Figure 1: reversing that arc makes the former atom factored (with costs 40$) and the latter abduced (with costs 40$ and 60$), and back-chaining using (6) can be done from importantfor (n1,m) instead, which yields the abduced atom fatherof (n1,m) 48$, 57$, 100$ instead of fatherof (f,m). Note that fatherof (f, n2) can still be factored with that new abduced atom as f =n1. .\nAs we are solving an optimization problem, dealing with a subset of solutions that has been canonicalized (by enforcing an arbitrary order on factoring) can be an advantage for efficiency, as certain symmetric solutions are automatically excluded.\nWe do not prove correctness of this factoring variant, as the following variant has better performance.\n3.3.3 Bwd-A: Abduced Cluster Factoring\nFinally, we apply an even stronger canonicalization to the proof graph: we assume factoring only happens with abduced atoms. We first show, that every proof graph, that contains factoring with an inferred atom, can be transformed into a proof graph where inferences between factored atom and abduced atoms is duplicated and all factoring is done with abduced atoms.\nExample 8 (continued). The proof graph in Figure 1 can be transformed into a graph where factoring happens only with abduced atoms: instead of factoring atom importantfor (n1,m)\n60$ with atom importantfor (f,m)40$, 60$, we can back-chain from the former over axiom (6) which yields the atom fatherof (n1,m)\n72$ in the graph. This atom can now be factored with fatherof (f,m) at the top, which obtains the set {48$, 72$, 100$} of costs and therefore keeps the same minimum cost.\nImportantly, the metrics we consider do not change when we perform this canonicalization.\nProposition 4. Given a proof graph G of a hypothesis H ∈ Ĥ(A) of an abduction instance A, there is a proof graph G′ and hypothesis H ′ of same cost wrt. Card, Coh, Wa where factoring is only performed with atoms in A(G′).\nProof. We show how to push factoring edges closer to abduced atoms without changing the objective function value. As the graph is acyclic, this operation can be continued until we only unify with abduced atoms.\nGiven an atom P ∈H and an edge (P,Q)∈E(G) of factoring Q with P using substitution θ, and P /∈A(G). Then either (i) P is factored with Q′, i.e., (Q′, P )∈E(G), or (ii) P is back-chained on axiom r with k body atoms, i.e., (P ′i , P )∈E(G) for 1≤ i≤ k. In case (i) we can factor Q with Q\n′ instead of with P , which pushes factoring one edge closer to abduced atoms. This does not affect Card as A(G)=A(G′), reachability stays the same so Coh is not affected, and the minimal cost of P and Q is propagated to Q′ as before the change, so Wa is not affected. In case (ii) we can back-chain from Q with axiom r, creating edges (θ−1(P ′i ), Q), adding nodes θ −1(P ′i ) to G ′ if they do not exist (implicitly they are already contained in H due to equivalences) and adding factoring edges from (P ′i , θ −1(P ′i )) to G\n′. This reduces the number of inference edges between factored and abduced atoms in the graph by 1. Similar as before, reachability and number of abduced atoms stays constant. For Wa, cost might increase for θ−1(P ′i ) but stays the same for Q′. Therefore, we do not lose optimal solutions by restricting factoring to abduced atoms.\nBy a similar argument, the order of factoring in such a proof graph does not matter, so we can also canonicalize factoring direction.\nProposition 5. Given a proof graph G of a hypothesis H where factoring is only performed with atoms in A(G), an abduced atom P ∈A(G), and atoms Q1, . . . , Qk that are factored with P . Then we can swap an arbitrary Qi, 1≤ i≤ k, with P , factor all other Qj, j 6= i with Qi, factor P with Qi, and all objective functions stay the same.\nProof. As all Q1, . . . , Qk, P unify, we can arbitrarily choose one of them as representative and factor all others with it. This does not increase the number of abduced atoms in Card, this does not affect reachability in Coh, and costs of all atoms are propagated to the chosen representative, and the minimum cost in Wa stays the same.\nTo realize this canonicalization, we use rules (52)–(56) and add the following rule, such that every atom that is not back-chained is factored with abduced atoms if possible, otherwise abduced.\nfa(P )← fai(P ). (57)\nNote that this encoding does not require any guesses to determine what is factored and what is abduced, moreover there is no need for the definition of below .\nProposition 6. Given an abduction instance A = (B,O, S), let PBwd-A(A)=Pbpt(A)∪Pgp ∪Peq ∪ Pc where Pc = {(52)–(56),(57)}, then answer sets AS (PBwd-A(A)) of PBwd-A(A) are in 1-1 correspondence with proof graphs G and hypotheses H ∈ Ĥ(A) where factoring is performed only with A(G) and only with lexicographically smaller atoms.\n3.4 Fwd-A: Guess Abduced Atoms, Forward Inference, Check Goal\nThe previous encodings are based on explicitly representing proof graphs. We next describe an encoding that is more in the spirit of the generate-define-test paradigm of Answer Set Programming [Lif02]: we again propagate potentially interesting truth values, however we do not keep track of the inferences. We guess which of these potentially interesting truth values is abduced or factored, and use another rewriting of the axioms to reproduce their semantics, i.e., we define that the head of an axiom is true if all its bodies are true. Finally we check that all goals become true. For example axiom (9) is translated into\ninfer (c(is , X, depressed))← true(c(importantfor , Y,X)), true(c(is , Y, dead)). (58)\npot(c(importantfor , Y,X))← pot(c(is , X, depressed)), Y = s(r1, y,X). (59)\npot(c(is , Y, dead))← pot(c(is , X, depressed)), Y = s(r1, y,X). (60)\nwhere r1 again is a unique identifier for axiom (9). We guess potential atoms as factored or abduced, define truth from factoring, abducing, and inference, and require that goals are true.\n{ fai(X) : pot(X) }← . (61)\ntrue(X)← fai(X). (62)\ntrue(X)← infer(X). (63)\n← goal(A),not true(A). (64)\nThis realizes abduction in the classical generate-define-test way. The only thing missing is factoring to determine which atoms actually need to be abduced. For that we add the following rule to define which atoms are factored or abduced.\nfa(X)← fai(X),not infer (X). (65)\nWe complete the encoding by cluster factoring rules (52)–(56) and common rules (23)–(30). Because we do not have an explicit representation of the proof tree, only the Card metric is applicable. Moreover, we cannot factor with inferred atoms as there is no way to rule out circular inference, hence we only study the most restricted factoring variant.\nFor readability we gave the rewriting as an example. Formally, an axiom of form (2) is rewritten into\ninfer (c(q, Y1, . . . , Ym))← true(c(p1, X 1 1 , . . . , X 1 k1 )), . . . , true(c(pr, X r 1 , . . . , X r kr )). pot(c(pi, X i 1, . . . , X i k1 ))←Z1 = s(a, 1, Y1, . . . , Ym), . . . , Zv = s(a, v, Y1, . . . , Ym),\npot(c(q, Y1, . . . , Ym)). for i∈{1, . . . , r}\nwhere a is a unique identifier for that particular axiom and Z1, . . . , Zv =X \\Y. Note that this means that the resulting rules will all be safe.\nWe do not prove correctness of this encoding as it is only applicable to Card and does not have good performance compared with other encodings."
    }, {
      "heading" : "3.5 Encodings for Preferred Solutions",
      "text" : "We next describe program modules that realize objective functions when we add them to the previously given encodings.\nCardinality Minimality. For realizing objective Card we use the following weak constraint.\nabduce(P ). [1@1, P ] (66)\nCoherence Metric. For Coh we represent which nodes are reachable from which goal node.\nreach(P, P )← goal (P ). (67)\nreach(Q,From)← reach(P,From), inferVia(R,P ), inferenceNeeds(P,R,Q). (68)\nreach(Q,From)← reach(P,From), factorVia(P,Q). (69)\nWe represent pairs of distinct goal atoms that have a common reachable atom, and we create a weak constraint that incurs a cost corresponding to pairs of goal atoms without a common reachable atom.\nreachFromBoth(P,Q)← goal (P ), goal (Q), P <Q, reach(N,P ), reach(N,Q). (70)\ngoal(P ), goal (Q), P <Q,not reachFromBoth(P,Q). [1@1, P,Q] (71)\nWeighted Abduction. For realizing Wa we represent potential costs as an integers. We seed cost with $100 for goal atom assumption cost.\npcost(P, 100)← goal (P ). (72)\nAs common practice for applying Wa to Accel, we realize axiom costs such that body cost factors sum up to 1.2. For that we require for each axiom R a fact numberOfBodyAtoms(R,N) to be defined such that N is the number of body atoms of R. We also require a minimum cost of 1 which prevents spurious very deep proof trees from being optimal due to cost 0 at abduced atoms.\npcost(Q,Mc)← inferVia(R,P ), inferenceNeeds(P,R,Q), (73)\nMc=#max { (C ∗ 6/5)/N ; 1 }, pcost(P,C), numberOfBodyAtoms(R,N).\nThese computations are handled during instantiation. They can be generalized to assumption weights that are individually given for each axiom as facts, without causing a change the rest of the encoding.\nWe propagate cost across factoring edges, define cost to be the minimum cost found at all abduced atoms, and minimize that cost using a weak constraint.\npcost(Q,C)← factorVia(P,Q), pcost(P,C). (74)\ncost(P,C)← abduce(P ), C =#min { Ic : pcost(P, Ic) }. (75)\ncost(P,C). [C@1, P ] (76)\nProposition 7. Let PCard = {(66)}, PCoh = {(67)–(71)}, and PWa = {(72)–(76)}. Then the cost of answer sets I ∈ AS(PBwd-A(A)∪PCard), I ∈ AS(PBwd-A(A)∪PCoh), and I ∈ AS (PBwd-A(A)∪ PWa) is the objective function Card(G), Coh(G), and Wa(G), respectively, of the proof graph G represented in I, where for Wa costs are rounded to integers and at least 1."
    }, {
      "heading" : "3.6 Summary",
      "text" : "Table 1 gives an overview of our encodings. Encodings in the Bwd family deterministically represent the maximal potential proof graph and all its inferences, while Fwd-A represents only atoms in the hypothesis. Justification of atoms in the proof graph is ensured from goals to abducibles (backward) in the Bwd encodings, and from abduced atoms to goals (forward) in Fwd-A. The type of justification of\ngoals and atoms in the hypothesis is nondeterministically guessed as one of three classes by Bwd-Gand one of two classes by Bwd-AI and Bwd-A. Fwd-A guesses truth of abduced or factored atoms (two classes). Factoring is canonicalized to various extent, and acyclicity of factoring is implicitly ensured in Bwd-A and Fwd-A but is encoded explicitly in other encodings."
    }, {
      "heading" : "4 Extensions",
      "text" : "The ASP encodings given so far are realized in pure ASP-Core-2 syntax and do not require additional features specific to particular solver tools. However, these encodings have two drawbacks: they can represent only acyclic theories, and they have performance issues related to the size of instantiation of the transitivity constraint for eq . We next formalize two extensions of these encodings and describe their computational realization.\nIn Section 4.1 we introduce Flexible Value Invention for fine-grained control of Skolemization, which makes our encodings applicable to cyclic theories. In Section 4.2 we show how to replace certain constraints in our encodings with lazy variants to reduce grounding size and potentially improve evaluation performance. Both extensions are described formally in the HEX formalism. Section 4.3 discusses how we realized these extensions using the Python library of Clingo."
    }, {
      "heading" : "4.1 Flexible Value Invention for Cyclic Knowledge Bases",
      "text" : "The encodings in Section 3 assume that the knowledge base is acyclic, which ensures finite proof trees and a finite instantiation of our ASP encodings in the presence of Skolemization with Uninterpreted Function terms as done in our axiom rewritings.\nExample 9. As an example of a cyclic knowledge base consider the following two axioms\np(A, b) ⇐ q(A,C), t(C, b). (r1)\nt(D, b) ⇐ p(D, b). (r2)\nwhere a goal of p(a, b) yields the following infinite backward chaining instantiation of axioms in the proof tree\np(a, b) ⇐ q(a, s(r1, “C”, a)), t(s(r1, “C”, a), b). (via r1)\nt(s(r1, “C”, a), b) ⇐ p(s(r1, “C”, a), b). (via r2)\np(s(r1, “C”, a), b) ⇐ q(s(r1, “C”, a), s(r1, “C”, s(r1, “C”, a))),\nt(s(r1, “C”, s(r1, “C”, a)), b). (via r1)\nt(s(r1, “C”, s(r1, “C”, a)), b) ⇐ p(s(r1, “C”, s(r1, “C”, a)), b). (via r2)\n...\nwhere C is first skolemized as s(r1, “C”, a) (see (31)) but then used again to back-chain over the first axiom which leads to another Skolemization. This leads to undecidability as we cannot know when we have generated ‘enough’ distinct variables to find the optimal solution.\nThe Accel benchmark is described as being acyclic [NM92] however it contains one cyclic axiom and this contains a comment that suggests that the respective axiom has been added after publication of [NM92]. To evaluate Accel, or any cyclic theory with our encodings, we therefore need to exclude axioms to break cycles, or infinite instantiations will occur. However, in knowledge representation, knowledge is sometimes naturally expressed in cyclic axioms, and we would like to handle such knowledge bases. In particular the cyclic axioms in Accel are required to obtain correct solutions for some instances, so we do not want to dismiss such axioms.\nWe next use external atoms instead of uninterpreted function symbols to achieve a Flexible Value Invention where we can control when to block value invention. By blocking certain value inventions, we ensure a finite instantiation of our encoding which thereby allows computation of optimal solutions. If we do not use cyclic axioms and limit value invention, we obtain a subset of all acyclic proof graphs and a sound approximation of the optimal solution. If we use cyclic axioms, they extend the proof graph in\nways that are impossible with acyclic axioms. The variations of Flexible Value Invention (shown in the following) permit usage of cyclic axioms and allow for controlling the trade-off between instantiation size and distance from the optimal solution.\nFor Flexible Value Invention, we first outsource value invention into an external atom &skolem . Formally, instead of skolemizing variables Zv ∈X \\ Y in the rewriting (35) as\nZv = s(a, v, Y1, . . . , Ym) (77)\nwhere a is the axiom identifier, v is the variable index, and Y1, . . . , Ym are head variables, we use\n&skolem [a, v, Y1, . . . , Ym](Zv). (78)\nExample 10. Instead of (31) in the Bwd encodings (Example 6), we rewrite into the rule\nmayInferVia(r1, c(is , X, depressed), l(Y ))←\npot(c(is , X, depressed)),&skolem [r1, “Y ”, X ](Y ) (79)\nand instead of (59) and (60) in the Fwd-A encoding we rewrite the body elements of the axiom into\npot(c(importantfor , Y,X))← pot(c(is , X, depressed)),&skolem [r1, “Y ”, X ](Y ).\npot(c(is , Y, dead))← pot(c(is , X, depressed)),&skolem [r1, “Y ”, X ](Y ).\nThis way we outsource Skolemization, i.e., building a new unique constant term Zv from terms a, v, Y1, . . . , Ym — or the decision not to build such a term — to an external computation. We next realize several Skolemization methods that limit value invention in different ways.\nThe original Skolemization with uninterpreted functions can be emulated by defining f&skolem as\nf&sk∞(I, R, V, Y1, . . . , Ym, Z) = 1 iff Z = s(R, V, Y1, . . . , Ym).\nThis shows that we can still express the original Skolemization (without guaranteeing decidability).\nExample 11 (continued). The external atom &sk∞[r1, “Y ”, X ](Y ) is true iff Y = s(r1, “Y ”, X). This means that instantiating (31), which contains an uninterpreted function, and instantiating (79), which contains an external computation, will create the same ground Skolem terms.\nA simple way for ensuring termination is the following function.\nf &skP 1 (I, R, V, Y1, . . . , Ym, Z) = 1 iff\n{\nZ = s(R, V, Y1, . . . , Ym) and no Yi, 1≤ i≤m, is of the form s(·, ·, · · · ).\n(80)\nThis prevents value invention if any of the terms Y1, . . . , Ym is an invented value, which is a very restrictive criterion: it blocks all value invention where at least one parent is an invented value.\nExample 12 (continued). The external atom &skP 1\n[r1, “Y ”, X ](Y ) is true if Y = s(r1, “Y ”, X) and X is not a term of form s(· · ·). Instantiating rule (79) with X =m then yields a single external atom &skP 1\n[r1, “Y ”,m](s(r1, “Y ”,m)) which evaluates to true. Therefore, the rule head is instantiated as mayInferVia(r1, c(is ,m, depressed), l(s(r1, “Y ”,m))). Assume that we have an additional axiom which contains is(X, depressed) in the head and is(X, dead) or importantfor (X,Z) in the body. Such an axiom allows cyclic back-chaining over is(X, depressed), which yields another instantiation of (79) with body literals pot(c(is , s(r1, “Y ”,m), depressed)) and &sk P1 [r1, “Y ”, s(r1, “Y ”,m)](Y ). In this case the external atom will not be true for any ground term Y : it blocks Skolemization as the input term is already a Skolem term. Without this blocking (e.g., with &sk∞) we would obtain an infinite instantiation.\nWe can extend f &skP 1 to block value invention only if some grandparent is an invented value.\nf &skP 2 (I, R, V, Y1, . . . , Ym, Z) = 1 iff\n\n\n Z = s(R, V, Y1, . . . , Ym) and no Yi, 1≤ i≤m, is of the form s(·, ·, U1, . . . , Uk) with some Uj , 1≤ j≤ k, of the form s(·, ·, · · · ). (81)\nThis can be further generalized to f &skP i , where i∈{1, 2, . . .}, indicates that in the i−1-th nesting level of terms Yi, 1≤ i≤m, terms must not be invented values. P 1 corresponds to the method used in Henry-n700 for achieving termination (Naoya Inoue 2015, personal communication).\nExternal oracle functions f &skP i , 1≤ i, guarantee finite instantiation of cyclic abduction problems.\nProposition 8. Given a cyclic or acyclic abduction instance A=(B,O, S), let PBwd-A P i(A) be the program PBwd-A(A) after replacing all body atoms of form (77) by body atoms of form (78) where &skolem =&skP i , then grnd(PBwd-A P i(A)) is finite for i∈{1, 2, . . .}.\nProof. PBwd-A P i(A) is finite and contains only safe rules, therefore the only source of infinite instantiation can be the instantiation of terms of unlimited depth. Except for the first rule in the axiom rewriting (35), all rules have heads with term nesting level equal or lower than in the body, hence the only rule that can generate terms of unlimited depth is the first in (35). In that rule, term l(· · · ) is created, but it is only used in the other rewritten rules in (35) where only the arguments of l(· · · ) are used, and in (38), where this term is discarded, therefore l(· · · ) cannot be infinitely nested. The only source of terms of infinite depth is the external atom of form &skP i\n[a, i, Y1, . . . , Ym](Zi) and it causes infinite instantiation only if f &skP\ni (I, R, V, Y1, . . . , Ym, Z) is true for infinitely many distinct terms Z. f&skPi is 1 only if no input Yi, 1≤ i≤m, has a subterm at nesting level i− 1 that is of form s(· · · ), and R, V can be a finite number of constants from PP 1\nBwd-A (A). Moreover there is a finite number of terms that can be built from constants\nin PBwd-A P i(A) with function symbol s, and not having a subterm of form s(· · · ) below nesting level i − 1. Hence there is a finite number of tuples R, V, Y1, . . . , Ym for which f&skPi evaluates to true. As Z depends on R, V, Y1, . . . , Ym, f&skPi evaluates to true for a finite number of tuples R, V, Y1, . . . , Ym, Z and instantiation is finite with respect to a given program PBwd-A P i(A).\nLimiting value invention this way is not the only way: nontermination of value invention always involves a certain rule and a certain existential variable of that rule being instantiated over and over again in a cycle. Therefore, we next formulate an external Skolemization oracle that blocks Skolemization only if a child term was generated for the same rule and variable.\nf &skG 1 (I, R, V, Y1, . . . , Ym, Z) = 1 iff\n{\nZ = s(R, V, Y1, . . . , Ym) and no Yi, 1≤ i≤m, has a sub-term of form s(R, V, · · · ).\n(82)\nThis function also ensures finite instantiation.\nProposition 9. Given a cyclic or acyclic abduction instance A=(B,O, S), let PBwd-A G1(A) be the program PBwd-A(A) after replacing all body atoms of form (77) by body atoms of form (78) where &skolem =&skG 1 , then grnd(PBwd-A G1(A)) is finite for i∈{1, 2, . . .}.\nProof. As in the proof of Proposition 8, the only reason for infinite instantiation can be the external atom. Assume towards a contradiction, that the instantiation is infinite. Then f\n&skG 1 (I, R, V, Y1, . . . , Ym, Z)\nmust be true for an infinite number of terms Z. As we have a finite number of constants in PBwd-A G1(A) and Z is instantiated using this set of constants and function symbols of form s(· · · ) with finite arity, for an infinite number of terms we require infinite nesting depth of terms of form s(· · · ). As the set of possible tuples (R, V ) used as inputs of f\n&skG 1 is finite, we must repeat (R, V ) in some subterms of Z\nto reach an infinite amount of them. However f &skG 1 is false for such terms, contradiction.\nAs before, we can further generalize to f &skG i where i∈{1, 2, . . .} indicates that a Skolem term may contain at most i layers of sub-terms from the same rule and variable."
    }, {
      "heading" : "4.2 On-Demand Constraints",
      "text" : "In the set of rules common to all encodings (Section 3.1), we represented transitivity of the equivalence relation eq as a constraint (30) instead of using the more commonly used rule\neq(A,C)← eq(A,B), eq(B,C), A 6=B,B 6=C,A 6=C.\nThe formulation as a constraint allows us to eliminate (30) from the encoding and lazily create only those instances of (30) that are violated during the search for the optimal solution. Such a lazy instantiation\nis easy for constraints but not supported for rules in current solvers, as adding a new rule changes the solver representation (usually the Clark completion) of all rules with the same head in the program.\nFormally we represent lazy constraints in HEX (cf. [EFI+16, 2.3.1]) by replacing (30) with a constraint\n←not &transitive[eq ](). (83)\nwhere the external computation oracle is defined as follows:\nf&transitive(I, p) = 1 iff the relation {(A,B) | p(A,B)∈ I} is transitive. (84)\nMoreover, if we find a transitivity violation, i.e., a new triple (A,B,C) such that {p(A,B), p(B,C)}⊆ I and p(A,C) /∈ I, we add a new nogood into the solver that prevents p(A,B)∧ p(B,C)∧¬p(A,C) for future answer set candidates.\nSimilarly, we can ensure that below is a partial order, by replacing (43) with a guess of the relevant part of the extension of predicate below3 as follows\n{ below (Q,P ) }← fai(P ), infer (Q).\nand require acyclicity of below using a constraint of form (83) with external atom &acyclic[below ](), an oracle function that is true iff relation {(A,B) | p(A,B)∈ I} is acyclic, and nogood generation for all basic cycles in that relation."
    }, {
      "heading" : "4.3 Implementation",
      "text" : "We formulated Flexible Value Invention and On-Demand Constraints using HEX as a formal framework. In preliminary experiments we identified a performance problem in the dlvhex solver that was not possible to fix easily, therefore we decided to realize the extensions using the Python libraries of Gringo and Clasp [GKKS14]. This posed additional challenges that we discuss next.\nFlexible Skolemization. Flexible Skolemization can be realized purely during instantiation by replacing external atoms of the form &skolem [a, i, Y1, . . . , Ym](Zi) by the expression Zi = @skolem(a, i, Y1, . . . , Ym) and implementing a Python function skolem that generates constants according to the various semantic definitions for limited value invention that are described in Section 4.1.\nNote that we can only handle this kind of external atoms in grounding because the value of the oracle function f&skolem does not depend on the interpretation I.\nOn-demand Constraints. Different from Flexible Skolemization, on-demand constraints are handled during solving. For that, Clasp provides an interface for registering a callback function which receives answer set candidates. In that callback we can add nogoods to the solver. However, answer set enumeration modes of the current Python API of Clasp do not work well together with this idea: either we enumerate models of increasing quality, or we enumerate models without using the objective function. In the former case an on-demand constraint can invalidate the first model of optimal quality, which causes no further answer set candidates to be found, (there are no better ones). The latter case is a blind search for better solutions which is prohibitively slow.\nTo realize on-demand constraints with reasonable efficiency, we created algorithm FindOptimalModel which first finds an optimistic bound for the objective function and then backtracks to worse bounds using on-demand constraints. This algorithm is of interest only until the Clasp API supports changing enumeration mode or objective bound from within the callback, hence we show details only in the appendix.\nGlobal Constraints of Accel. A final implementation aspect is the realization of global constraints of the Accel benchmark.\n3I.e., the part used in (41) and (48).\nAssumption nogoods and unique-slot constraints can be represented uniformly for all encodings in ASP constraints. We here show the encoding strategy by means of examples. Assumption nogoods as exemplified in (19) are encoded in ASP as\n← abduce(c(go_step, S,G1)), abduce(c(goer , G2, P )), eq(G1, G2)\nwhere we take into account term equivalence. Unique slot axioms as exemplified in (20) are encoded in ASP as\n← true(c(goer , G1, P1)), true(c(goer , G2, P2)), eq(G1, G2), P1 <P2,not eq(P1, P2)\nwhere we take into account term equivalence both for the entity that must be the same to violate the constraint (G1, G2), and for the entity that is enforced to be unique, i.e., must not be the same to violate the constraint (P1, P2). Note that condition P1 <P2 achieves symmetry breaking during instantiation."
    }, {
      "heading" : "5 Experimental Evaluation",
      "text" : "We evaluated the above encodings, on-demand constraints, and flexible value invention using the Accel benchmark described in Section 2.2. The encodings and instances we used in experiments are available online.4 The benchmarks were performed on a computer with 48 GB RAM and two Intel E5-2630 CPUs (total 16 cores) using Ubuntu 14.04. As solvers we used the Python API of Clingo5 4.5.46 [GKKS14] to implement on-demand constraints and flexible Skolemization as described in Section 4.3, and we tested pure ASP encodings also with Gringo5 4.5.46 [GKKS11] as grounder and both solvers Clasp5 3.1.4 [GKK+15] and Wasp7 version f9d436 [ADLR15]. We also make experiments to compare with state-of-theart approaches Henry-n7008 version 4b0d900 [II13] and its successor Phillip9 version 5612b13 [YII+15]. Each run was limited to 5 minutes and 5 GB RAM, HTCondor was used as a job scheduling system, each run was repeated 5 times and no more than 8 jobs were running simultaneously. For Clasp we used the setting --configuration=crafty which turned out to be superior to all other preset configurations of Clasp. For Wasp we used the default configuration (core-based OLL algorithm) which performs equal or better compared with other settings (note in particular, that configurations basic, mgd, and opt for option --weakconstraints-algorithm perform clearly worse than the default).\nIn the following tables, columns Opt, To, and Mo give the number of instances for which an optimal solution was found, the timeout was reached, and the memory limit was exceeded, respectively. These numbers are summed over instances and averaged over runs. Columns T and M show time (seconds) and memory (MB) requirement, averaged over instances and runs.\nThe remaining columns show detailed diagnostics of the solver and objective function, where provided by the respective tool. Tgrd and Tslv give grounding and solving time, respectively, as reported by running first Gringo and then Clasp or Wasp. In experiments with the Python implementation, Tgrd includes solver preprocessing which cannot be separated from grounding in Clasp API, and Tslv contains pure search time. Further metrics are only available if an optimal solution could be found and proved as optimal: Obj shows the objective function, |Odc| the number of on-demand constraints, |Sk | the number of created Skolem constants, |Chc|/|Conf | the number of choices and conflicts encountered, and |Ru| the number of rules in the program. To permit a meaningful comparison of these values, we average them over the 17 easiest instances. We only show averages if all runs found the optimum solution, otherwise we write ‘*’. For large numbers, K and M abbreviate 103 and 106.\nPreliminary encodings in [Sch15] were able to represent acyclic theories and therefore only suitable for objective Card. Equivalence was represented by a relation between terms and representative terms in the respective equivalence class (BackCh) or not at all (Simpl). We will not make numerical comparisons as the performance of BackCh and Simpl is significantly worse than the performance of encodings in this work in all cases (in particular memory is exhausted in more than 50% of instances with Clasp).\n4https://bitbucket.org/knowlp/asp-fo-abduction 5http://potassco.sourceforge.net/ 6Including a patch that will be contained in future versions and eliminates a bug with aggregates. 7https://github.com/alviano/wasp/ 8https://github.com/naoya-i/henry-n700 9https://github.com/kazeto/phillip\nBasic ASP Encodings. Table 2 shows experimental results for encodings Bwd-G, Bwd-AI, Bwd-A, and Fwd-A for objectives Card, Coh, and Wa using Gringo for grounding and Clasp (C) or Wasp (W) for solving. For Wa we also compare with Phillip (P). Bwd-G performs worst with respect to all metrics, it performs significantly worse than Bwd-AI with Clasp, while it performs just a bit below Bwd-AI with Wasp. Bwd-A performs best with respect to all metrics, and for Card, Wasp performs nearly the same with the Fwd-A encoding.\nComparing Clasp and Wasp shows that Wasp is able to find the optimal solution faster than Clasp except in cases where Wasp exceeds the 5GB memory limit, which happens mainly for the encodings containing a higher amount of guesses (Bwd-G, Bwd-AI). Another difference is the number of choices and conflicts: Wasp generates fewer choices for Card and Coh, but more choices for Wa, moreover Wasp often generates more conflicts. These differences on the same encoding can be explained by different ASP optimization algorithms: for Clasp the used (default) configuration BB is based on adding constraints to a relaxation of the instance, while for Wasp the used (default) configuration OLL is based on unsatisfiable cores (for a discussion of optimization approaches, see [ADMSR15]).\nDue to its unfavorable performance, we omit results for Bwd-G in the following. The Henry-n700 solver realizes Wa and on the Accel benchmark results of around 10 sec per instance have been reported [II13]. Phillip is the successor of Henry-n700 and adds heuristics for a partial instantiation of the most relevant portions of the proof graph [YII+15]. We experimented with Henry-n700 and Phillip on the original Accel knowledge base. Unfortunately we were not able to reproduce the results reported for Henry-n700: as shown in the table, all 50 instances timed out, moreover an ILP solution was found only for 4 instances and the costs of these solutions where more than 25% above the optimal result. As we had problems with the Gurobi license, we used the open-source ‘lpsolve’ ILP backend in experiments, however Gurobi cannot improve the situation much because most instances timed out during instantiation. From the authors of Henry-n700 and Phillip we obtained a transformed version of Accel that was used to produce their published results; unfortunately that rewriting is incompatible with the current version of Henry-n700 as well as Phillip, however we noticed that the rewriting makes some simplifying assumptions on Accel: it interprets constants in goals as sort names, i.e., distinct entities in the goal can never denote the same entity (which makes, e.g., coreference resolution impossible); moreover sort names are compiled into predicates which creates many distinct predicates of lower\narity and makes instantiation easier. Also assumption constraints are not realized. For reasoning with the complete set of rules in Accel, our approach is significantly faster than the state-of-the-art solver Phillip.\nSkolemization. Table 3 compares the encodings and objectives from Table 2 with their counterparts using Python Skolemization. For a fair comparison, we here do not compare with pure Gringo+Clasp, but we use our algorithm in Python in both cases (even for ASP encodings that do not use Python Skolemization): this explains differences to Table 2 and why we do not experiment with Wasp here. For these and previous experiments we use only acyclic axioms and do not limit Skolemization, so the only difference between the program is the shape of constant symbols: nested uninterpreted function terms of form s(·, ·, ·) versus constants of form pi, i∈N, generated with Python. Although Python Skolemization provides higher flexibility than uninterpreted function terms, there is no noticeable effect on efficiency of the 17 easiest instances, and across all 50 instances, Python Skolemization has a positive effect on efficiency of the Bwd-AI and Fwd-A encodings, while performance of the most efficient encoding Bwd-A is unchanged.\nIt is not apparent why some encodings improve performance with Python Skolemization. Structurally, the instantiated program entering the solver is exactly the same in both Skolemization methods, except for Skolem constants instead of uninterpreted function terms in the symbol table. However, we additionally observed, that the order of rules created by Gringo changes between both Skolemization methods. From this we conclude that the order of rules matters, and that there is potential for optimization in solvers, moreover this suggests that Clasp is sensitive to the order of rules it consumes before solving. (We conjecture, that efficiency is not affected by the form of strings in the symbol table.)\nWe conclude that in addition to the flexibility of Python Skolemization we can gain efficiency.\nOn-Demand Constraints. Table 4 shows experimental results for comparing two methods for ensuring acyclicity of the relation below and transitivity of the relation eq . The rows with (R) use encodings as given in Section 3 while those with (O) use on-demand constraints as described in Section 4.2. For a fair comparison, all runs were performed with algorithms based on the Clasp Python API (Section 4.3).\nWe observe that on-demand constraints significantly reduce instantiation time and memory usage in all encodings and all objective functions. We can see the difference between instantiating the full encodings or encodings without rules (30) and (43) in column Tgrd . We observe that instantiating transitivity and acyclicity dominates the instantiation time, and that back-chaining in ASP is fast. Therefore we did not perform experiments for creating the proof graph outside ASP (this would correspond to the architecture of Phillip, where the proof graph is created in C++ and solved in ILP).\nInterestingly, for the Coh objective, encoding Bwd-AI outperforms Bwd-A with on-demand constraints (although by a small amount, and although the instantiation time of the easiest 17 instances of Bwd-A is smaller than the one of Bwd-AI).\nAs reported in the ILP-based solvers Henry-n700 and Phillip, on-demand constraints turn out to be important for managing bigger instances in this reasoning problem: we observe increased performance and a significant reduction in memory usage.\nCyclic Theories and Limited Skolemization. Table 5 shows the results of experiments with cyclic theories and limited value invention as defined in Section 4.1. For encoding Bwd-A and all objective functions, we evaluate the acyclic theory with unlimited f&sk∞ Skolemization, and the theory including the cyclic axiom with parent- and rule-based Skolemization limits f&skα with α∈{P\n1, P 2, G1, G2}. We show only Coh and Wa with Bwd-A, because Card and other encodings show the same trends. We observe that time (T ) and memory (M ) usage, number of generated Skolem constants (|Sk |), grounding time (Tgrd), and size of the instantiation (|Ru|), are ordered P 1 <P 2 <∞<G1 <G2 for both objective functions. Solving time (Tslv ), choices (|Chc|), and conflicts (|Conf |), are also nearly always ordered like that.\nRegarding the objective function, the ∞ method does not use the (single) cyclic axiom in Accel, while the other methods use that axiom. P 1 and P 2 permit a limited amount of value invention based on invented values, and allow fewer inferences than ∞ on the acyclic axioms, which results in a higher cost of the optimal solution. G1 and G2 block value invention only when it reaches the same rule (not other rules), therefore they allow a superset of the inferences of ∞. This explains, why Obj of ∞ is above the one of P2 and below the one of G1 (recall that we display Obj only for the 17 instances where all runs found the optimum).\nRegarding efficiency, one or two generations of invented values across rules (G1, G2) drastically increase memory exhaustion, while strictly limiting value invention (P 1) makes the problem easy to solve and impairs solution quality.\nGlobal Constraints. Table 6 shows a comparison between realizing unique-slot constraints and assumption constraints in ASP constraints versus not considering these constraints.\nGlobal constraints have no significant effect on efficiency. We see no effect on the objective function when removing global constraints. This seems counterintuitive: more constraints should intuitively increase cost of the optimal solution. It turns out that these cases are rare: we can observe an increased cost of optimal solutions if we limit Skolemization using method P 1. We conclude that global constraints in the Accel benchmark have a small impact on solution quality.\nOther Experiments. For combining on-demand constraints with optimization, we also investigated alternatives to algorithm FindOptimalModel (see Section 4.3 and the appendix) where we used Clasp assumptions and Clasp externals for deactivating certain optimization criteria during some parts of the search. These alternatives perform significantly worse, moreover they are involved and require rewriting weak constraints into normal rules, therefore we decided to omit further details about these experiments.\nRealizing global constraints ofAccel also in an on-demand manner did not yield significantly different results from using the pure ASP versions, therefore we omit these results from the presentation.\nWe experimented with projecting answer sets to the atoms that are relevant for the objective function, which yielded a significant reduction in log file size (because we print the solution) but no significant reduction in time or memory."
    }, {
      "heading" : "6 Related Work",
      "text" : "The idea of abduction goes back to Peirce [Pei55] and was later formalized in logic. Abductive Logic Programming (ALP) is an extension of logic programs with abduction and integrity constraints. Kakas et al. [KKT92] discuss ALP and applications, in particular they relate Answer Set Programming and abduction. Fung et al. describe the IFF proof procedure [FK97] which is a FOL rewriting that is sound and complete for performing abduction in a fragment of ALP with only classical negation and specific safety constraints. Denecker et al. [DdS98] describe SLDNFA-resolution which is an extension of SLDNF resolution for performing abduction in ALP in the presence of negation as failure. They describe a way to ‘avoid Skolemization by variable renaming’ which is exactly what we found to increase performance in flexible Skolemization (recall that we create numbered constants pi instead of structured terms s(· · · ) in Python). Kakas et al. describe the A-System for evaluating ALP using an algorithm that interleaves instantiation of variables and constraint solving [KVD01]. The CIFF framework [MTS+09] is conceptually similar to the A-System but it allows a more relaxed use of negation. The SCIFF framework [ACG+08] relaxes some restrictions of CIFF and provides facilities for modeling agent interactions. In [GLR+15], SCIFF was used to realize semantics of Datalog± [CGL09] which natively supports existentials in rule heads (i.e., value invention) as opposed to ASP. The focus of SCIFF is on finding abductive explanations, while our focus is to find preferred abductive explanations according to objective functions. Realizing objective functions requires modifying the SCIFF engine (Evelina Lamma 2015, personal communication) therefore we did not perform experiments comparing SCIFF with our encodings.\nImplementations of ALP, have in common that they are based on evaluation strategies similar to Prolog [MTS+09]. In [MTS+09], CIFF is compared with ASP on the example of n-queens and the authors emphasize that CIFF has more power due to its partial non-ground evaluation. However, they use a nonoptimized n-queens encoding for that comparison, and optimized n-queens encodings for Clingo[GKKS12] are known to yield orders of magnitude better performance than naive encodings, hence partial nonground evaluation is not necessarily a guarantee for better performance. Different from CIFF and earlier ALP implementations, our approach instantiates one Boolean variable for each node in the potential proof graph and then searches for the best solution, while methods that create nodes on demand (such as CIFF) can completely eliminate certain nodes from instantiation, while instantiating other nodes multiple times.\nThe AAA (ATMS-based Abduction Algorithm) reasoner [Ng92, NM92] combines Prolog resolution with ATMS-based caching for realizing abduction. For Accel, AAA realizes Card and Coh metrics and enforces assumption-nogoods and unique-slot constraints in dedicated (imperative) procedures.\nThe Henry-n700 reasoner [II13] realizesWa by creating an ILP instance with C++ using back-chaining and then finding optimal solutions for the ILP instance. The newest version of Henry-n700 is called Phillip [YII+15]; this solver adds heuristics that partially instantiate the proof tree according to relatedness between predicates (although without formal proof of the correctness or worst-case approximation error). This two-step approach is similar to our approach in ASP: our encodings cause the ASP grounder to perform back-chaining in the knowledge base, and after instantiation the solver searches for optimal solutions satisfying all rules and constraints. A big performance improvement for Henry-n700 was the usage of Cutting Plane Inference [II13]. We mimic the approach with on-demand constraints in ASP, and we can observe similar improvements in instantiation size and time, however solve time increases by a larger amount for many instances, hence this approach is not sufficient for achieving a corresponding performance boost in ASP. Within the ASP community, on-demand constraints are related to methods of lazy instantiation of ASP programs, as done in the solvers ASPeRiX [LBSG15], OMiGA [DtEF+12], Galliwasp [MG13], and recently also in the IDP system [DDSB15]. These systems apply lazy instantiation to all rules and constraints in the program, whereas we make only certain problematic constraints lazy.\nProbabilistic abduction was realized in Markov Logic [RD06] in the Alchemy system [KSR+10] al-\nthough without value invention [BHD+11, SM11], i.e., existential variables in rule heads are naively instantiated with all ground terms in the program. A corresponding ASP encoding for the non-probabilistic case for Card exists [Sch15, Simpl], however it shows prohibitively bad performance.\nThe termination proofs we do are related to the notion of Liberal Safety in HEX programs [EFKR13], however Liberal Safety requires either specific acyclicity conditions (which are absent in our encodings), or conditions on finiteness of the domain of certain attributes of the external atom (that our Skolemization atoms do not fulfill). Hence we had to prove termination without using Liberal Safety.\nIn the area of Automated Theorem Proving, algorithms search for finite models (or theorems, unsatisfiability proofs) in full first order logic without enforcing UNA and including native support for Skolemization (cf. [Sut09]). These algorithms focus on finding a feasible solution and do not contain support for preferences (optimization criteria). However, the main emphasis of our abduction problems is to find solutions with optimal cost (recall that our problems always have the trivial solution to abduce all input atoms). To tackle our abduction problem with such theorem provers, it would be necessary to transform the optimization problem into a decision problem and perform a search over the optimization criterion, calling the prover several times. Related to theorem proving, a hypertableaux algorithm for coreference resolution is described in [BK00]. This algorithm is inspired by weighted abduction, however it does not use preferences and relies solely on inconsistency for eliminating undesired solutions.\nComputational Complexity. The complexity of abduction in propositional theories in the presence of the Card objective has been analyzed in [BATJ91, EG95], and in [EGL97], the propositional case of abduction in logic programs is studied and extended to function-free logic programming abduction (Sec. 6), under the restriction that only constants from observations and knowledge base (there called ‘manifestations’ and ‘program’) are used and that the UNA holds for all terms. However, in our variant of abduction the optimal solution may use a set (of unspecified size) of constants that are not present in the input and there is potential equality among certain input constants and constants originating in value invention. Hence, existing results can be seen as lower bounds for hardness but do not directly carry over to our scenario.\nIn an acyclic theory, our reasoning problem is related to non-recursive negation-free Datalog theories and non-recursive logic programming with equality, which has been studied (although not with respect to abductive reasoning) in [DEGV01].\nCreating the largest possible proof graph for a given goal and knowledge base can be done by reversing axioms and evaluating them with the goal; the complexity of this problem (definite not range-restricted logic program without function symbols) was shown to be PSPACE-complete [VV98, Thm. 4.1]."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We have created a flexible and publicly available framework for realizing variations of cost-based FO Horn abduction represented in the declarative reasoning framework of Answer Set Programming [Lif08] that allows us (i) to modularly encode additional objective functions based on the abductive proof graph, and (ii) to add global constraints of arbitrary complexity and size. Our encodings use a modular translation of axioms into ASP rules, i.e., each axiom can be translated independent from other axioms. As preference relations we realized cardinality-minimality, coherence [NM92], and weighted abduction [HSME93, Sti89]. We evaluated our framework on the Accel benchmark [NM92] and found that we have significantly higher performance than state-of-the-art solver Phillip [YII+15] which is the successor system of Henry-n700[II13]. In our experiments, Wasp [ADLR15] solves instances faster than Clasp [GKK+15], however Wasp uses more memory for programs with a high degree of nondeterminism.\nFor realizing value invention we experimented with uninterpreted functions and with external computations providing new values to the program. Performing Skolemization with external computations provides fine-grained control for deciding when to instantiate a term and when to refuse further instantiation. This allows us to ensure and formally prove decidability when performing abduction in cyclic FO Horn knowledge bases. Fortunately, this flexibility does not impair computational efficiency.\nAn important topic in this research is encoding the proof graph. Usually, in ASP we are not interested in the order of inferences made in the program or in the dependencies or equivalences between atoms — those are handled transparently in the solver. However, for modeling preference functions Coh and Wa, which are defined on proof graphs, we must explicitly represent a proof graph, including back-chaining\nand unification, in our ASP encoding. We also experiment with an alternative encoding (Fwd-A) for representing objective Card: this encoding performs abduction without representing a proof graph, it is based on forward inference, has good performance with the Wasp solver.\nThe Bwd-A encoding performs best, intuitively because it makes the most strict canonicalization operations on the graph by requiring factoring to happen only with abduced atoms. Proof cost is not affected by this canonicalization, however proof graphs will contain duplicate inferences for atoms that are equivalent due to term equivalence: these atoms could be first factored and inferred later. Yet this seemingly wasteful proof graph does not diminish performance in ASP, because we anyway need to instantiate the whole potential proof graph, so all inferences trees are available even if we do permit factoring anywhere in the tree. Postponing factoring to abduced atoms has the effect that we need to handle term equivalence only for these atoms, which is an advantage for efficiency.\nAs ASP provides no native support for term equivalence, we encode equivalence and unification explicitly. We guess an equivalence relation and check its reflexivity, symmetry, transitivity with constraints. Explicit representation of transitivity of equivalence has been shown to be a major performance issue in Henry-n700, as it causes instantiation of a cubic amount of rules [II13]. This performance issue also becomes apparent in our ASP representation, and we apply the solution from Henry-n700 to our encodings by using on-demand constraints, which we describe formally in the HEX formalism [EFI+16]. Realizing on-demand constraints in presence of optimization is nontrivial in current solvers, and we describe an algorithm based on the Python API of Clingo[GKKS14]. On-demand constraints significantly reduce memory usage by partially instantiating transitivity constraints of the term equivalence relation (note that the potential proof graph is still fully instantiated). This is consistent with results reported for Henry-n700 and Phillip for weighted abduction [II13] with ILP as a solver backend and not surprising as ASP and ILP are related methods for solving combinatorial problems [LJN12].\nFuture work. The major motivation for this work was to obtain a more flexible framework where variations of objective functions and constraints on abduction can be studied. In the future we intend to perform research in this direction. Moreover we want to apply our encodings to other datasets like the one derived from the Recognizing Textual Entailment (RTE) [DGM06] challenge.\nAmong the encodings we experiment with, the most obvious and straightforward encoding (Bwd-G) has the worst performance, and small encoding changes as well as bigger changes, that realize symmetry breaking based on a theoretical analysis of the problem, are required for achieve acceptable performance (Bwd-A). Interestingly, the Wasp solver is able to compensate for the more nondeterministic representation: it performs similar on Bwd-G and Bwd-AI encodings, opposed to Clasp which performs significantly worse on Bwd-G. We conclude that automatic program optimization and supporting tools for diagnosing performance issues are open problems in ASP and fruitful topics for future work."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank Naoya Inoue, Evelina Lamma, Christoph Redl, and the anonymous reviewers and RCRA workshop participants for constructive feedback about this work. We thank Mario Alviano, Carmine Dodaro, Roland Kaminski, and Benjamin Kaufmann for support regarding Clasp, Gringo, and Wasp."
    }, {
      "heading" : "8 Appendix: Complete Encodings",
      "text" : "We give full encodings in the following.\nComplete Encoding Bwd. Each axiom of form (2) is rewritten into the following set of ASP rules:\nmayInferVia(a, c(q, Y1, . . . , Ym), l(Z1, . . . , Zv))←\npot(c(q, Y1, . . . , Ym)), Z1 = s(a, 1, Y1, . . . , Ym), . . . , Zv = s(a, v, Y1, . . . , Ym)\ninferenceNeeds(c(q, Y1, . . . , Ym), a, c(pi, X i 1, . . . , X i ki ))←\nmayInferVia(a, c(q, Y1, . . . , Ym), l(Z1, . . . , Zv)) for i∈{1, . . . , r}\nwhere a is a unique identifier for that particular axiom and Z1, . . . , Zv =X \\Y. The encoding contains the following rules.\npot(X)← goal(X).\npot(P )← inferenceNeeds(_,_, P )\ntrue(P )← goal(P ).\n1≤{ infer (P ) ; fai(P ) }≤ 1← true(P ).\n1≤{ inferVia(R,P ) : mayInferVia(R,P,_) }≤ 1← infer (P ).\ntrue(Q)← inferVia(R,P ), inferenceNeeds(P,R,Q).\nhu(X)← pot(c(_, X,_)).\nhu(X)← pot(c(_,_, X)).\nuhu(X)←hu(X),not sortname(X).\n{ eq(A,B) : uhu(A), uhu(B), A 6=B }← .\neq(A,A)←hu(A).\n← eq(A,B),not eq(B,A).\n← eq(A,B), eq(B,C), A 6=B,B 6=C,A 6=C,not eq(A,C).\nComplete Factoring Encoding Bwd-G.\nbelow(P,Q)← inferVia(R,P ), inferenceNeeds(P,R,Q).\nbelow(P,Q)← factorVia(P,Q).\nbelow (A,C)← below (A,B), below (B,C).\n1≤{ factor (P ) ; abduce(P ) }≤ 1← fai(P ).\nfactorVia(c(P, S1, O1), c(P, S2, O2))← factor (c(P, S1, O1)), infer (c(P, S2, O2)), eq(S1, S2),\neq(O1, O2),not below (c(P, S2, O2), c(P, S1, O1)).\nfactorVia(c(P, S1, O1), c(P, S2, O2))← factor (c(P, S1, O1)), abduce(c(P, S2, O2)),\neq(S1, S2), eq(O1, O2).\nfactorOk (P )← factorVia(P,_).\n← factor (P ),not factorOk (P ).\nComplete Factoring Encoding Bwd-AI.\nbelow (P,Q)← inferVia(R,P ), inferenceNeeds(P,R,Q).\nbelow (P,Q)← factorVia(P,Q).\nbelow(A,C)← below (A,B), below (B,C).\nfactorViaI (c(P, S1, O1), c(P, S2, O2))← fai(c(P, S1, O1)), infer (c(P, S2, O2)), eq(S1, S2),\neq(O1, O2),not below (c(P, S2, O2), c(P, S1, O1)).\nfactorI (P )← factorViaI (P,_).\nfa(P )← fai(P ),not factorI (P ).\nfactorVia(A,B)← factorViaI (A,B).\nfactorCluster (c(P, S2, O2), c(P, S1, O1))← fa(c(P, S1, O1)), fa(c(P, S2, O2)), eq(S1, S2),\neq(O1, O2), c(P, S1, O1)<c(P, S2, O2).\nfactorClusterAbove(A)← factorCluster (A,_).\nfactorVia(A,B)← factorCluster (A,B),\nnot factorClusterAbove(B).\nfactor (P )← factorVia(P,_).\nabduce(P )← fa(P ),not factor (P ).\nComplete Factoring Encoding Bwd-A.\nfa(P )← fai(P ).\nfactorCluster (c(P, S2, O2), c(P, S1, O1))← fa(c(P, S1, O1)), fa(c(P, S2, O2)), eq(S1, S2),\neq(O1, O2), c(P, S1, O1)<c(P, S2, O2).\nfactorClusterAbove(A)← factorCluster (A,_).\nfactorVia(A,B)← factorCluster (A,B),\nnot factorClusterAbove(B).\nfactor (P )← factorVia(P,_).\nabduce(P )← fa(P ),not factor (P ).\nComplete Encoding Fwd-A. Each axiom of form (2) is rewritten into the following set of ASP rules:\ninfer (c(q, Y1, . . . , Ym))← true(c(p1, X 1 1 , . . . , X 1 k1 )), . . . , true(c(pr, X r 1 , . . . , X r kr )). pot(c(pi, X i 1, . . . , X i k1 ))←Z1 = s(a, 1, Y1, . . . , Ym), . . . , Zv = s(a, v, Y1, . . . , Ym),\npot(c(q, Y1, . . . , Ym)). for i∈{1, . . . , r}\nwhere a is a unique identifier for that particular axiom and Z1, . . . , Zv =X \\Y. The encoding Fwd-A then contains the following rules.\npot(X)← goal(X).\n{ fai(X) : pot(X) }← .\ntrue(X)← fai(X).\ntrue(X)← infer(X).\n← goal(A),not true(A).\nfa(X)← fai(X),not infer(X).\nhu(X)← pot(c(_, X,_)).\nhu(X)← pot(c(_,_, X)).\nuhu(X)←hu(X),not sortname(X).\n{ eq(A,B) : uhu(A), uhu(B), A 6=B }← .\neq(A,A)←hu(A).\n← eq(A,B),not eq(B,A).\n← eq(A,B), eq(B,C), A6=B,B 6=C,A6=C,not eq(A,C).\nfactorCluster (c(P, S2, O2), c(P, S1, O1))← fa(c(P, S1, O1)), fa(c(P, S2, O2)), eq(S1, S2),\neq(O1, O2), c(P, S1, O1)<c(P, S2, O2).\nfactorClusterAbove(A)← factorCluster (A,_).\nfactorVia(A,B)← factorCluster (A,B),\nnot factorClusterAbove(B).\nfactor (P )← factorVia(P,_).\nabduce(P )← fa(P ),not factor (P )."
    }, {
      "heading" : "9 Appendix: Running Example ASP Encoding and Answer Set",
      "text" : "We next give the ASP input instance for our running example (Example 1) when used with Bwd encodings. We then give representative parts of an answer set describing the abductive explanation shown in Figure 1."
    }, {
      "heading" : "9.1 Rewriting of Axioms, Goal, and Sortnames",
      "text" : "As described in Section 3, given the an abduction instance A=(B,O, S) of Example 1 we create the following ASP code.\nWe represent the goal in terms of facts (21).\ngoal(c(name,m,mary)). goal (c(lost ,m, f)). goal (c(fatherof , f,m)).\ngoal(c(inst , s, female)). goal (c(is , s, depressed)).\nWe represent sort names as follows.\nsortname(depressed). sortname(dead). sortname(person).\nsortname(female). sortname(male).\nAccording to the rewriting (35) in Section 3.2, we rewrite axioms of Example 1 as follows. Axiom (4) ‘inst(X,male)⇐ fatherof (X,Y )’ is rewritten into the following ASP rules.\nmayInferVia(r4, c(inst , X,male), l(Y ))← pot(c(inst , X,male)), Y = s(r4, “Y ”, X).\ninferenceNeeds(c(inst , X,male), r4, c(fatherof , X, Y ))←\nmayInferVia(r4, c(inst , X,male), l(Y )).\nnumberOfBodyAtoms(r4, 1).\nNote the Skolemization of variable Y which exists only in the body of (4) but not in the head. Also note that we use rule identifiers that are synchronized with the original axiom numbers, i.e., for (4) we use r4.\nAxiom (5) ‘inst(X, female)⇐name(X,mary)’ is rewritten into the following ASP rules.\nmayInferVia(r5, c(inst , X, female), l)← pot(c(inst , X, female)).\ninferenceNeeds(c(inst , X, female), r5, c(name, X,mary))←\nmayInferVia(r5, c(inst , X, female), l).\nnumberOfBodyAtoms(r5, 1).\nNote that in this axiom there is no Skolemization, so l has no arguments (however we still need it to keep the arity of mayInferVia the same throughout the encoding.\nAxiom (6) ‘importantfor (Y,X)⇐ fatherof (Y,X)’ is rewritten into the following ASP rules.\nmayInferVia(r6, c(importantfor , Y,X), l)←pot(c(importantfor , Y,X)).\ninferenceNeeds(c(importantfor , Y,X), r6, c(fatherof , Y,X))←\nmayInferVia(r6, c(importantfor , Y,X), l).\nnumberOfBodyAtoms(r6, 1).\nAxiom (7) ‘inst(X, person)⇐ inst(X,male)’ is rewritten into the following ASP rules.\nmayInferVia(r7, c(inst , X, person), l)← pot(c(inst , X, person)).\ninferenceNeeds(c(inst , X, person), r7, c(inst , X,male))←mayInferVia(r7, c(inst , X, person), l).\nnumberOfBodyAtoms(r7, 1).\nAxiom (8) ‘is(X, depressed)⇐ inst(X, pessimist)’ is rewritten into the following ASP rules.\nmayInferVia(r8, c(is , X, depressed), l)← pot(c(is , X, depressed)).\ninferenceNeeds(c(is , X, depressed), r8, c(inst , X, pessimist))←\nmayInferVia(r8, c(is , X, depressed), l).\nnumberOfBodyAtoms(r8, 1).\nAxiom (9) ‘is(X, depressed)⇐ is(Y, dead)∧ importantfor (Y,X)’ is rewritten as follows.\nmayInferVia(r9, c(is , X, depressed), l(Y ))← pot(c(is , X, depressed)), Y = s(r9, “Y ”, X).\ninferenceNeeds(c(is , X, depressed), r9, c(importantfor , Y,X))←\nmayInferVia(r9, c(is , X, depressed), l(Y )).\ninferenceNeeds(c(is , X, depressed), r9, c(is , Y, dead))←\nmayInferVia(r9, c(is , X, depressed), l(Y )).\nnumberOfBodyAtoms(r9, 2).\nAxiom (10) ‘lost(X,Y )⇐ is(Y, dead)∧ importantfor (Y,X)∧ inst(Y, person)’ is rewritten into the following ASP rules.\nmayInferVia(r10, c(lost , X, Y ), l)← pot(c(lost , X, Y )).\ninferenceNeeds(c(lost , X, Y ), r10, c(inst , Y, person))←mayInferVia(r10, c(lost , X, Y ), l).\ninferenceNeeds(c(lost , X, Y ), r10, c(importantfor , Y,X))←mayInferVia(r10, c(lost , X, Y ), l).\ninferenceNeeds(c(lost , X, Y ), r10, c(is , Y, dead))←mayInferVia(r10, c(lost , X, Y ), l).\nnumberOfBodyAtoms(r10, 3)."
    }, {
      "heading" : "9.2 Example Answer Set",
      "text" : "We next give parts of the answer set representing the abductive explanation depicted in Figure 1. We show an answer set of the encoding Bwd-G which does not perform any canonicalization and therefore can produce the proof graph in Figure 1 (other encodings will produce larger proof graphs with the same cost for this instance).\nNote that the encoding produces Skolem terms s(r9, “Y ”, s) and s(r4, “Y ”, f), which, for practical reasons, have been displayed in Figure 1 as n1 and n2, respectively.\nDeterministically determined Atoms. Based on the rewriting of axioms (previous section) and the goal atoms, the truth of atoms of form pot(·), mayInferVia(·, ·, ·), and inferenceNeeds(·, ·, ·), is deterministically determined via rules (23) and (34).\nIn our example we obtain the following true atoms in the answer set.\npot(c(fatherof , f, s(r4, “Y ”, f))) pot(c(fatherof , f,m))\npot(c(fatherof , s(r9, “Y ”, s), s)) pot(c(importantfor , f,m))\npot(c(importantfor , s(r9, “Y ”, s), s)) pot(c(inst , f, female))\npot(c(inst , f,male)) pot(c(inst , f, person)) pot(c(inst , s, female))\npot(c(is , s(r9, “Y ”, s), dead)) pot(c(inst , s, pessimist)) pot(c(is , f, dead))\npot(c(is , s, depressed)) pot(c(lost ,m, f)) pot(c(name, f,mary))\npot(c(name,m,mary)) pot(c(name, s,mary))\nmayInferVia(r4, c(inst , f,male), l(s(r4, “Y ”, f))) mayInferVia(r5, c(inst , f, female), l)\nmayInferVia(r5, c(inst , s, female), l) mayInferVia(r6, c(importantfor , f,m), l)\nmayInferVia(r6, c(importantfor , s(r9, “Y ”, s), s), l) mayInferVia(r7, c(inst , f, person), l)\nmayInferVia(r8, c(is , s, depressed), l)\nmayInferVia(r9, c(is , s, depressed), l(s(r9, “Y ”, s))) mayInferVia(r10, c(lost ,m, f), l)\ninferenceNeeds(c(inst , f,male), r4, c(fatherof , f, s(r4, “Y ”, f)))\ninferenceNeeds(c(inst , f, female), r5, c(name, f,mary))\ninferenceNeeds(c(inst , s, female), r5, c(name, s,mary))\ninferenceNeeds(c(importantfor , f,m), r6, c(fatherof , f,m))\ninferenceNeeds(c(importantfor , s(r9, “Y ”, s), s), r6, c(fatherof , s(r9, “Y ”, s), s))\ninferenceNeeds(c(inst , f, person), r7, c(inst , f,male))\ninferenceNeeds(c(is , s, depressed), r8, c(inst , s, pessimist))\ninferenceNeeds(c(is , s, depressed), r9, c(is , s(r9, “Y ”, s), dead))\ninferenceNeeds(c(is , s, depressed), r9, c(importantfor , s(r9, “Y ”, s), s))\ninferenceNeeds(c(lost ,m, f), r10, c(inst , f, person))\ninferenceNeeds(c(lost ,m, f), r10, c(importantfor , f,m))\ninferenceNeeds(c(lost ,m, f), r10, c(is , f, dead))\nFrom these atoms, hu(·), and uhu(·) are deterministically determined using rules (24)–(26).\nhu(m) hu(female) hu(person) hu(depressed)\nhu(f) hu(male) hu(pessimist) hu(s(r4, “Y ”, f))\nhu(s) hu(mary) hu(dead) hu(s(r9, “Y ”, s))\nuhu(f) uhu(m) uhu(mary) uhu(pessimist)\nuhu(s) uhu(s(r4, “Y ”, f)) uhu(s(r9, “Y ”, s))\nGoal atoms are deterministically defined as true by (36).\ntrue(c(name,m,mary)) true(c(inst , s, female)) true(c(lost ,m, f))\ntrue(c(fatherof , f,m)) true(c(is , s, depressed))\nTruth Justification. The Bwd-G encodings requires a justification for each true value, this justification is nondeterministically guessed to be either infer (·), factor (·), or abduce(·) by rules (37) and (40). Justifying an atom by inference performs another nondeterministic guess with (38) about the concrete axiom used for that inference, which is represented in inferVia(·, ·) and defines more atoms of form true(·) to be true (and hence their need to be justified) with (39).\nIn the answer set representing Figure 1, this guess contains the following true atoms (we omit fai(·)).\ninfer (c(inst , f,male)) inferVia(r4, c(inst , f,male))\ninfer (c(inst , s, female)) inferVia(r5, c(inst , s, female))\ninfer (c(importantfor , f,m)) inferVia(r6, c(importantfor , f,m))\ninfer (c(inst , f, person)) inferVia(r7, c(inst , f, person))\ninfer (c(is , s, depressed)) inferVia(r9, c(is , s, depressed))\ninfer (c(lost ,m, f)) inferVia(r10, c(lost ,m, f))\nfactor (c(name, s,mary)) factor (c(fatherof , f, s(r4, “Y ”, f)))\nfactor (c(is , s(r9, “Y ”, s), dead)) factor (c(importantfor , s(r9, “Y ”, s), s))\nabduce(c(name,m,mary)) abduce(c(fatherof , f,m))\nabduce(c(is , f, dead))\ntrue(c(name, s,mary)) true(c(inst , f, person))\ntrue(c(inst , f,male)) true(c(fatherof , f, s(r4, “Y ”, f)))\ntrue(c(is , s(r9, “Y ”, s), dead)) true(c(is , f, dead))\ntrue(c(importantfor , f,m)) true(c(importantfor , s(r9, “Y ”, s), s))\nTerm Equivalence. Independent from justification of true atoms, an equivalence relation over all potential terms is nondeterministically guessed by means of rules (27)–(30).\nThe answer set representing Figure 1 contains the following true atoms for eq(·, ·) These atoms represent two equivalence classes {m, s, s(r4, “Y ”, f)} and {f, s(r9, “Y ”, s)} that have more than one element, and singleton equivalence classes for sort names and other constants.\neq(male,male) eq(female, female) eq(dead , dead)\neq(mary ,mary) eq(person , person) eq(pessimist , pessimist)\neq(f, f) eq(f, s(r9, “Y ”, s) eq(depressed , depressed)\neq(m,m) eq(m, s) eq(m, s(r4, “Y ”, f))\neq(s,m) eq(s, s) eq(s, s(r4, “Y ”, f))\neq(s(r4, “Y ”, f),m) eq(s(r4, “Y ”, f), s) eq(s(r4, “Y ”, f), s(r4, “Y ”, f))\neq(s(r9, “Y ”, s), f) eq(s(r9, “Y ”, s), s(r9, “Y ”, s))\nFactoring. For each atom that was guessed as factored, rules (41)–(46) define factorVia(·, ·) and factorOk (·) for atoms that can be factored with infered or abduced atoms while respecting eq(·, ·) and acyclicity. For acyclicity, the partial order defined by the graph is represented in below (·, ·), which is true for every pair of atoms such that the first atom is reachable via arcs from the second atom. The representation of Figure 1 contains the following true atoms.\nfactorVia(c(name, s,mary), c(name,m,mary))\nfactorVia(c(is , s(r9, “Y ”, s), dead), c(is , f, dead))\nfactorVia(c(importantfor , s(r9, “Y ”, s), s), c(importantfor , f,m))\nfactorVia(c(fatherof , f, s(r4, “Y ”, f)), c(fatherof , f,m))\nfactorOk (c(name, s,mary)) factorOk (c(is , s(r9, “Y ”, s), dead))\nfactorOk (c(importantfor , s(r9, “Y ”, s), s)) factorOk (c(fatherof , f, s(r4, “Y ”, f)))\nbelow (c(inst , s, female), c(name,m,mary)) below(c(inst , s, female), c(name, s,mary))\nbelow (c(name, s,mary), c(name,m,mary)) below(c(lost ,m, f), c(inst , f, person))\nbelow (c(lost ,m, f), c(importantfor , f,m)) below(c(lost ,m, f), c(is , f, dead))\nbelow (c(lost ,m, f), c(inst , f,male)) below(c(lost ,m, f), c(fatherof , f,m))\nbelow (c(lost ,m, f), c(fatherof , f, s(r4, “Y ”, f))) below(c(inst , f, person), c(inst , f,male))\nbelow (c(inst , f, person), c(fatherof , f,m)) below(c(is , s, depressed), c(is , f, dead))\nbelow (c(inst , f,male), c(fatherof , f, s(r4, “Y ”, f))) below(c(inst , f,male), c(fatherof , f,m))\nbelow (c(is , s, depressed), c(importantfor , f,m)) below(c(is , s, depressed), c(fatherof , f,m))\nbelow (c(importantfor , f,m), c(fatherof , f,m))\nbelow(c(fatherof , f, s(r4, “Y ”, f)), c(fatherof , f,m))\nbelow(c(is , s(r9, “Y ”, s), dead), c(is , f, dead))\nbelow(c(inst , f, person), c(fatherof , f, s(r4, “Y ”, f)))\nbelow(c(is , s, depressed), c(is , s(r9, “Y ”, s), dead))\nbelow(c(is , s, depressed), c(importantfor , s(r9, “Y ”, s), s))\nbelow(c(importantfor , s(r9, “Y ”, s), s), c(fatherof , f,m))\nbelow(c(importantfor , s(r9, “Y ”, s), s), c(importantfor , f,m))\nFor representing the cost of the solution wrt. objective Wa, (72) defines the following goal costs.\npcost(c(name,m,mary), 100) pcost(c(lost ,m, f), 100) pcost(c(fatherof , f,m), 100)\npcost(c(inst , s, female), 100) pcost(c(is , s, depressed), 100)\nCost propagation via inferences is done by (73) which makes the following atoms true.\npcost(c(name, s,mary), 120) pcost(c(inst , f, person), 40)\npcost(c(importantfor , f,m), 40) pcost(c(is , f, dead), 40)\npcost(c(inst , f,male), 48) pcost(c(fatherof , f, s(r4, “Y ”, f)), 57)\npcost(c(is , s(r9, “Y ”, s), dead), 60) pcost(c(importantfor , s(r9, “Y ”, s), s), 60)\npcost(c(fatherof , f,m), 48) pcost(c(fatherof , f,m), 72)\nNote that the cost of 72$ is not shown in Figure 1 because it is not contained in the definition of proof graph (Definition 2). In the Proof of Proposition 7 we argue that including these costs in ASP only adds further (higher) costs to each atom, hence the minimal costs and therefore the optimal solution remain unchanged. Note that we include these costs (i.e., we omit one more minimization step) for efficiency reasons.\nCost propagation via factoring is realized in (74) and makes the following atoms true.\npcost(c(name,m,mary), 120) pcost(c(fatherof , f,m), 57)\npcost(c(is , f, dead), 60) pcost(c(importantfor , f,m), 60)\nActual cost is defined from potential cost via (75) which yields the following true atoms.\ncost(c(name,m,mary), 100) cost(c(fatherof , f,m), 48) cost(c(is , f, dead), 40)\nFrom these atoms, the constraint (76) obtains the overall cost of 188 for this answer set."
    }, {
      "heading" : "10 Appendix: Proofs for ASP Encoding Correctness",
      "text" : "Proof of Lemma 1 (Sketch): Pbpt (A) does not contain not and its rules are not expanding term depth except for the first rule of (35). As B is acyclic, by construction of Pbpt(A) there are no loops over (35), grnd(Pbpt (A)) is finite, and AS(Pbpt (A)) = {I} has a single answer set I. The representation of proof graphs is achieved as follows: atoms A= p(a, b) that can be back-chained are represented as pot(c(p, a, b))∈ I: We proceed by induction on the distance d of back-chaining from observations. (Base: d=0) Due to (23) all atoms p(a, b)∈O are true as pot(c(p, a, b))∈ I. (Step: d ⇒ d+1) Assuming that A = q(a, b), A∈H , H ∈ Ĥ, is represented as pot(c(q, a, b))∈ I, this causes an instantiation of the first rule in (35), which defines mayInferVia(r, c(q, a, b), l(z1, . . . , zv)) true in I. This represents potential backchaining from q(a, b) over an axiom identified by r using substitution θ = {Z1 7→ z1, . . . , Zv 7→ zv} where Z1, . . . , Zv are variables occurring only in the body of r. Truth of mayInferVia(r, c(q, a, b), l(z1, . . . , zv)) causes truth of inferenceNeeds(c(q, a, b), r, c(p1, x 1 1, x 1 2) where pi is the predicate and x j i are the substituted variables at position i in body atom j of axiom r, analogous to backward chaining in Def. 1. Due to truth of inferenceNeeds(c(q, a, b), r, c(pi, x j i , x j i+1)) and due to (34), all body atoms θ(pi(X i 1, . . . , X i ki )) added to some H ∈ Ĥ in Def. 1 become represented as pot(c(pi, x j i , x j i+1)∈ I. (Conclusion) We conclude that I contains all atoms p(a, b) in hypotheses generated from observations represented as pot(c(p, a, b))∈ I. Moreover, mayInferVia(· · · ) represents potential back-chaining and inferenceNeeds(· · · ) represents the body atoms that are added to a hypothesis by a particular backchaining.\nProof of Proposition 2 (Sketch): We write Pbpt for Pbpt (A). Pbpt is a bottom of Pbpt ∪Pgp and therefore each I ∈AS(Pbpt ∪Pgp) is such that I = I ′ ∪ Ig where I ′ ∈AS(Pbpt ) and Ig contains only predicates infer , fai , inferVia, true. (36) defines for all o∈O, o = p(a, b), that true(c(p, a, b))∈ Ig. (37) defines that every atom P with true(P )∈ Ig, either infer (P )∈ Ig or fai(P )∈ Ig (i.e., two answer set candidates are generated). (38) defines that every atom P with infer(P )∈ Ig is marked as inferred via a particular axiom along an edge mayInferVia(R,P, Z)∈ I ′ of the potential proof graph, and represents this inference as inferVia(R,P ) where R is the axiom identifier. (39) defines that for each inferVia(R,P ) the corresponding required body atoms X i1, . . . , X i ki represented as inferenceNeeds(P,R, c(pi, X i 1, . . . , X i k)∈ I ′ are defined as true(c(pi, X i 1, . . . , X i k))∈ Ig. As defining these as true, they again must be represented as infer or fai due to (37). Due to minimality\nof answer sets, all atoms marked as true, infer , and fai are reachable from objectives o∈O which are also represented as true(·)∈ Ig. The set of hypotheses is inductively built from observations and any combination of backchaining over axioms from these observations and atoms obtained from backchaining, exactly as the set of atoms marked as true in Ig is inductively defined from observations and any choice about back-chaining in (37). Therefore, answer sets and proof graphs are in 1-1 correspondence.\nProof of Lemma 3 (Sketch): We write Pbpt for Pbpt(A). Peq does not define predicates present in Pbpt, hence Pbpt is a bottom wrt. Pbpt ∪Peq (see [LT94]) and I ′ ∈AS(Pbpt ∪Peq) is such that I ′ = I ∪ Ie where I ∈AS(Pbpt) and Ie contains only predicates eq, hu , and uhu. All constants c in argument positions of hypotheses are represented in hu(c) due to (24)–(25), those that are not sort names are additionally represented in uhu(c) due to (26). (27) guesses a relation eq(c, c′) a solution candidate for all pairs (c, c′) of constants with c 6= c′ that do not contain sort names. Finally, (28) defines eq to be reflexive for all constants (including sort names), and (29)/(30) exclude answer sets where the represented relation eq is not symmetric/transitive. Therefore, only those relations remain that are reflexive, symmetric, and transitive, i.e., equivalence relations.\nProof of Proposition 6 (Sketch): Let Pgpeq(A) = Pbpt(A)∪Pgp ∪Peq , then Pbpt (A)∪Pgp and Pbpt (A)∪Peq are bottoms wrt. Pgpeq(A), and Pgp and Peq do not have common head atoms, hence both Prop. 2 and Prop. 3 apply to answer sets I ∈AS(Pgpeq(A)), viz. each I is in 1-1 correspondence with some proof graph G and hypothesis H ∈ Ĥ(A) and moreover represents some equivalence relation over all constants of the proof graph in I, moreover all proof graphs originating in back-chaining are covered. Furthermore, Pgpeq(A) is a bottom wrt. PBwd-A(A), therefore each answer set I\n′ ∈AS (PBwd-A(A)) is such that I ′ = Igpeq ∪ I where Igpeq ∈AS(Pgpeq(A)) and I contains predicates defined by Pc based on Igpeq . Pc contains only stratified negation. (57) defines fa(P ) to be true iff fai(P )∈ Igpeq , hence iff atom P is not inferred in H . For all atoms P,Q∈H that are not inferred, (52) defines factorCluster (P,Q) to be true if P and Q unify under eq represented in Igpeq , Q is lexicographically smaller than P , and neither P nor Q were back-chained in G, i.e., they would be abduced unless they can be factored. Note that, given a set X of atoms that unify wrt. eq (called a ‘cluster’), (52) defines a relation that contains factorCluster (s1, s2) for all s1, s2 ∈X where s2 <s1. (53) represents all constants in all clusters that can be factored with a smaller element. (54) uses constants that have no such smaller element as representatives and defines factorVia(s, s′) for all s, s′ ∈X where s′ is the smallest element of the respective cluster X . Finally, every atom s that was unified with a representative s′ in factorVia(s, s′) is represented as factored factor (s) by (55) and those atoms that are neither factored nor inferred are defined as abduce(s) by (56). Hence, in the answer set I ′ ∈AS (PBwd-A(A)), all atoms s∈H that (i) are not back-chained on, i.e., are not marked as inferred, and that (ii) can be unified with a lexicographically smaller atom s′, are marked as factor (s)∈ I ′, and the factoring edge (s, s′)∈E(G) is represented as factorVia(s, s′)∈ I ′. Those atoms s∈H that are neither factored nor inferred are marked as abduce(s)∈ I ′. As I ∈AS(Pgpeq(A)) is in 1-1 correspondence with proof graphs based on backchaining and some equivalence relation, and Pc adds to that the representation of factored and abduced atoms (factor (·) and abduce(·)) and factoring edges factorVia(·, ·), I ′ ∈AS (PBwd-A(A)) is in 1-1 correspondence with proof graphs based on back-chaining and unification, and the equivalence relation that supports this unification.\nProof of Proposition 7 (Sketch): (Card) (66) causes cost |{a | abduce(a)∈ I}| and abduce(a)∈ I iff a is neither inferred nor factored. As being abduced is equivalent with the absence of edges factorVia(a, a′)∈ I and edges inferVia(r, a)∈ I, (66) produces cost Card(G) for an answer set I representing G.\n(Coh) (67) seeds a definition of reachability from goal nodes in predicate reach, (68) defines reachability across those inference edges that correspond with inferences actually done in the proof graph represented in I, and (69) defines reachability across factoring edges. As a result reach(a, o) is true for atom a∈H and observation o∈O iff o is reachable from a in G. (70) defines reachFromBoth(o, o′)∈ I iff o, o′ ∈O, o<o′, and there is some atom a∈H such that a is reachable from o and o′. The if direction is ensured by rule satisfaction, the only if direction is ensured by answer set minimality. Finally, weak constraint (71) attaches cost 1 for each distinct pair o, o′ of observation nodes where no node reachable from both o and o′ exists in G. This exactly corresponds to the definition of Coh.\n(Wa) (72) defines potential cost of 100 for objective nodes o∈O. (73) defines potential cost of 1.2 · c/n for each body atom of back-chaining, given that the back-chained atom had potential cost c and\nAlgorithm 1: OnModelWithoutOptimization(Model m, Clasp control object c)\n1 violations := FindOnDemandViolations(m) 2 foreach v ∈ violations do add nogood forbidding violation v to c 3 if violations = ∅ then print m\nwas back-chained over a rule with n body atoms. (74) defines that for atoms p, q where p was factored with q, q obtains all potential costs from p. Potential cost includes all costs obtained from reachable nodes, including the minimum cost in case of factoring. Therefore, the minimum costs propagated for unification as described in Def. 3 is represented as potential cost, along with bigger costs. Rule (75) represents for each abduced atom, i.e., for each a∈A(G) for G represented in I, the minimum over all potential costs of a. Hence, cost(p, c)∈ I iff p∈A(G), and c is the cost of abduced atom p∈H according to Wa. (76) sums up costs of distinct atoms p, hence cost Wa(G) is assigned to I."
    }, {
      "heading" : "11 Appendix: Realizing On-Demand Constraints with Optimiza-",
      "text" : "tion\nIf we solve a problem without weak constraints, i.e., without optimization, realizing on-demand constraints is simple: we register the callback OnModelWithoutOptimization (Algorithm 1) to Clasp. This callback checks on-demand constraints in FindOnDemandViolations (which is an applicationspecific algorithm), adds nogoods for violated constraints, and prints (or otherwise processes) the answer set if no constraint was violated. The first model we print this way is the first model that does not violate on-demand constraints.\nHowever, in the presence of optimization, Clasp has two modes that are both unsuitable with ondemand constraints: in mode (opt) each answer set updates the optimization bound and subsequent answer sets must be better; in mode (enum) we have to explicitly specify a bound and answer set candidates of same or better quality are found. With (opt) it can happen that the first answer set with optimal cost violates an on-demand constraint, so we discard that model, but the solver will not find further models with same cost, but no models with better cost exist, so we will not find any models (even if some exist). With (enum) the search is blind as better models are found only by chance. A straightforward and more elegant solution would be, to update the bound only for good answer sets in the on_model callback, but the API currently does not allow this.\nTo solve this problem we created algorithm FindOptimalModel (Algorithm 2) for finding an optimal model with on-demand constraints. This algorithm first grounds the program P in line 1, then uses (opt) mode to find an optimistic bound (optimisticCost ) for the cost of the optimal model in lines 2–4 using callback OnModelFindBound (Algorithm 3). This callback records the cost of the best encountered model candidate and the best model that does not violate on-demand constraints (bestModel ). This search aggressively updates the bound and also uses on-demand constraints. If no optimistic cost is set, the callback was never called and we return UNSAT (line 5). If the cost of the best found feasible model is the optimal cost, we directly return this model as optimal solution (line 6). Otherwise, we enter a loop that enumerates models using callback OnModelFindSolution (Algorithm 4). The loop increases the optimization bound of the solver by one in each iteration, until an answer set that does not violate on-demand constraints can be found. Our abduction instances always have some solution, so we will find that solution and leave the endless loop in line 13. To make the algorithm terminate in the general case where on-demand constraints might eliminate all solutions, we can obtain the worst-case cost from the instantiation of all weak constraints, and abort the loop once we increment tryingCost to that cost.\nAlgorithm 2: FindOptimalModel (ASP Program P )\nglobal: optimisticCost , bestModelCost , bestModel 1 Gringo.ground(P ) 2 optimisticCost , bestModelCost , bestModel := undef , undef , undef 3 Clasp.mode := opt // models must be strictly better than previously found models 4 Clasp.solve(on_model=OnModelFindBound) 5 if optimisticCost 6= undef then return (UNSAT ,−1) 6 if bestModelCost = optimisticCost then return (OPT , bestModel ) 7 tryingCost , bestModel := bestModelCost , undef 8 repeat 9 Clasp.mode := enum // finds models with equal or better cost 10 Clasp.opt_bound := tryingCost // cost bound for models 11 Clasp.models := 0 // find all models, not only the first one 12 Clasp.solve(on_model=OnModelFindSolution) 13 if bestModel 6=undef then return (OPT , bestModel ) 14 else tryingCost := tryingCost + 1 15 until forever\nAlgorithm 3: OnModelFindBound(Model m, Clasp control object c)\nglobal: optimisticCost , bestModelCost , bestModel 1 violations := FindOnDemandViolations(m) 2 foreach v ∈ violations do add nogood forbidding violation v to c 3 optimisticCost := m.cost 4 if violations = ∅ then 5 bestModelCost := m.cost 6 bestModel := m\nAlgorithm 4: OnModelFindSolution(Model m, Clasp control object c)\nglobal: bestModelCost 1 violations := FindOnDemandViolations(m) 2 foreach v ∈ violations do add nogood forbidding violation v to c 3 if violations = ∅ then 4 bestModel := m 5 add nogood forbidding ∅ to c // make problem inconsistent, abort search"
    } ],
    "references" : [ {
      "title" : "Verifiable agent interaction in abductive logic programming: The SCIFF framework",
      "author" : [ "Marco Alberti", "Federico Chesani", "Marco Gavanelli", "Evelina Lamma", "Paola Mello", "Paolo Torroni" ],
      "venue" : "ACM Transactions on Computational Logic,",
      "citeRegEx" : "Alberti et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Alberti et al\\.",
      "year" : 2008
    }, {
      "title" : "Advances in WASP",
      "author" : [ "Mario Alviano", "Carmine Dodaro", "Nicola Leone", "Francesco Ricca" ],
      "venue" : "In International Conference on Logic Programming and Non-monotonic Reasoning (LPNMR),",
      "citeRegEx" : "Alviano et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Alviano et al\\.",
      "year" : 2015
    }, {
      "title" : "Optimum stable model search: algorithms and implementation",
      "author" : [ "Mario Alviano", "Carmine Dodaro", "Joao Marques-Silva", "Francesco Ricca" ],
      "venue" : "Journal of Logic and Computation,",
      "citeRegEx" : "Alviano et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Alviano et al\\.",
      "year" : 2015
    }, {
      "title" : "The computational complexity of abduction",
      "author" : [ "Tom Bylander", "Dean Allemang", "Michael C Tanner", "John R Josephson" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Bylander et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Bylander et al\\.",
      "year" : 1991
    }, {
      "title" : "Implementing Weighted Abduction in Markov Logic",
      "author" : [ "James Blythe", "Jerry R Hobbs", "Pedro Domingos", "Rohit J Kate", "Raymond J Mooney" ],
      "venue" : "In International Conference on Computational Semantics (IWCS),",
      "citeRegEx" : "Blythe et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Blythe et al\\.",
      "year" : 2011
    }, {
      "title" : "Abducing Coreference by Model Construction",
      "author" : [ "Peter Baumgartner", "Michael Kühn" ],
      "venue" : "Journal of Language and Computation,",
      "citeRegEx" : "Baumgartner and Kühn.,? \\Q2000\\E",
      "shortCiteRegEx" : "Baumgartner and Kühn.",
      "year" : 2000
    }, {
      "title" : "ASP-Core-2 Input language format",
      "author" : [ "Francesco Calimeri", "Wolfgang Faber", "Martin Gebser", "Giovambattista Ianni", "Roland Kaminski", "Thomas Krennwallner", "Nicola Leone", "Francesco Ricca", "Torsten Schaub" ],
      "venue" : "Technical report,",
      "citeRegEx" : "Calimeri et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Calimeri et al\\.",
      "year" : 2012
    }, {
      "title" : "Datalog+/-: A Unified Approach to Ontologies and Integrity Constraints",
      "author" : [ "Andrea Calì", "Georg Gottlob", "Thomas Lukasiewicz" ],
      "venue" : "In International Conference on Database Theory,",
      "citeRegEx" : "Calì et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Calì et al\\.",
      "year" : 2009
    }, {
      "title" : "SLDNFA: An abductive procedure for abductive logic programs",
      "author" : [ "Marc Denecker", "Danny de Schreye" ],
      "venue" : "The Journal of Logic Programming,",
      "citeRegEx" : "Denecker and Schreye.,? \\Q1998\\E",
      "shortCiteRegEx" : "Denecker and Schreye.",
      "year" : 1998
    }, {
      "title" : "Lazy Model Expansion: Interleaving Grounding with Search",
      "author" : [ "Broes De Cat", "Marc Denecker", "Peter Stuckey", "Maurice Bruynooghe" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Cat et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Cat et al\\.",
      "year" : 2015
    }, {
      "title" : "Complexity and expressive power of logic programming",
      "author" : [ "Evgeny Dantsin", "Thomas Eiter", "Georg Gottlob", "Andrei Voronkov" ],
      "venue" : "ACM Computing Surveys,",
      "citeRegEx" : "Dantsin et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Dantsin et al\\.",
      "year" : 2001
    }, {
      "title" : "The PASCAL Recognising Textual Entailment Challenge",
      "author" : [ "Ido Dagan", "Oren Glickman", "Bernardo Magnini" ],
      "venue" : "In Machine Learning Challenges,",
      "citeRegEx" : "Dagan et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dagan et al\\.",
      "year" : 2006
    }, {
      "title" : "OMiGA: An Open Minded Grounding On-The-Fly Answer Set Solver",
      "author" : [ "Minh Dao-tran", "Thomas Eiter", "Michael Fink", "Gerald Weidinger", "Antonius Weinzierl" ],
      "venue" : "In Logics in Artificial Intelligence (JELIA),",
      "citeRegEx" : "Dao.tran et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Dao.tran et al\\.",
      "year" : 2012
    }, {
      "title" : "A model building framework for Answer Set Programming with external computations",
      "author" : [ "Thomas Eiter", "Michael Fink", "Giovambattista Ianni", "Thomas Krennwallner", "Christoph Redl", "Peter Schüller" ],
      "venue" : "Theory and Practice of Logic Programming,",
      "citeRegEx" : "Eiter et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Eiter et al\\.",
      "year" : 2016
    }, {
      "title" : "Liberal Safety for Answer Set Programs with External Sources",
      "author" : [ "Thomas Eiter", "Michael Fink", "Thomas Krennwallner", "Christoph Redl" ],
      "venue" : "In AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Eiter et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Eiter et al\\.",
      "year" : 2013
    }, {
      "title" : "The Complexity of Logic-Based Abduction",
      "author" : [ "Thomas Eiter", "Georg Gottlob" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Eiter and Gottlob.,? \\Q1995\\E",
      "shortCiteRegEx" : "Eiter and Gottlob.",
      "year" : 1995
    }, {
      "title" : "Abduction from logic programs: Semantics and complexity",
      "author" : [ "Thomas Eiter", "Georg Gottlob", "Nicola Leone" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "Eiter et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Eiter et al\\.",
      "year" : 1997
    }, {
      "title" : "Answer Set Programming: A Primer",
      "author" : [ "Thomas Eiter", "Giovambattista Ianni", "Thomas Krennwallner" ],
      "venue" : "In Reasoning Web Summer School, Lecture Notes in Computer Science,",
      "citeRegEx" : "Eiter et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Eiter et al\\.",
      "year" : 2009
    }, {
      "title" : "Effective Integration of Declarative Rules with External Evaluations for Semantic-Web Reasoning",
      "author" : [ "Thomas Eiter", "Giovambattista Ianni", "Roman Schindlauer", "Hans Tompits" ],
      "venue" : "In European Semantic Web Conference (ESWC),",
      "citeRegEx" : "Eiter et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Eiter et al\\.",
      "year" : 2006
    }, {
      "title" : "The IFF proof procedure for abductive logic programming",
      "author" : [ "Tze Ho Fung", "Robert Kowalski" ],
      "venue" : "The Journal of Logic Programming,",
      "citeRegEx" : "Fung and Kowalski.,? \\Q1997\\E",
      "shortCiteRegEx" : "Fung and Kowalski.",
      "year" : 1997
    }, {
      "title" : "Semantics and complexity of recursive aggregates in answer set programming",
      "author" : [ "Wolfgang Faber", "Gerald Pfeifer", "Nicola Leone" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Faber et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Faber et al\\.",
      "year" : 2011
    }, {
      "title" : "Progress in clasp Series 3",
      "author" : [ "Martin Gebser", "Roland Kaminski", "Benjamin Kaufmann", "Javier Romero", "Torsten Schaub" ],
      "venue" : "In International Conference on Logic Programming and Non-monotonic Reasoning (LPNMR),",
      "citeRegEx" : "Gebser et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gebser et al\\.",
      "year" : 2015
    }, {
      "title" : "Advances in gringo series 3",
      "author" : [ "Martin Gebser", "Roland Kaminski", "Arne König", "Torsten Schaub" ],
      "venue" : "In International Conference on Logic Programming and Non-monotonic Reasoning (LPNMR),",
      "citeRegEx" : "Gebser et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Gebser et al\\.",
      "year" : 2011
    }, {
      "title" : "Answer Set Solving in Practice",
      "author" : [ "Martin Gebser", "Roland Kaminski", "Benjamin Kaufmann", "Torsten Schaub" ],
      "venue" : null,
      "citeRegEx" : "Gebser et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gebser et al\\.",
      "year" : 2012
    }, {
      "title" : "Clingo = ASP + Control: Extended Report",
      "author" : [ "Martin Gebser", "Roland Kaminski", "Benjamin Kaufmann", "Torsten Schaub" ],
      "venue" : "Technical report, University of Potsdam,",
      "citeRegEx" : "Gebser et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Gebser et al\\.",
      "year" : 2014
    }, {
      "title" : "The Stable Model Semantics for Logic Programming",
      "author" : [ "Michael Gelfond", "Vladimir Lifschitz" ],
      "venue" : "In International Conference and Symposium on Logic Programming (ICLP/SLP),",
      "citeRegEx" : "Gelfond and Lifschitz.,? \\Q1988\\E",
      "shortCiteRegEx" : "Gelfond and Lifschitz.",
      "year" : 1988
    }, {
      "title" : "An abductive Framework for Datalog+/- Ontologies",
      "author" : [ "Marco Gavanelli", "Evelina Lamma", "Fabrizio Riguzzi", "Elena Bellodi", "Riccardo Zese", "Giuseppe Cota" ],
      "venue" : "In International Conference on Logic Programming (ICLP), Technical Communications,",
      "citeRegEx" : "Gavanelli et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gavanelli et al\\.",
      "year" : 2015
    }, {
      "title" : "Interpretation as abduction",
      "author" : [ "Jerry R Hobbs", "Mark Stickel", "Paul Martin", "Douglas Edwards" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Hobbs et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Hobbs et al\\.",
      "year" : 1993
    }, {
      "title" : "ILP-based Inference for Cost-based Abduction on Firstorder Predicate Logic",
      "author" : [ "Naoya Inoue", "Kentaro Inui" ],
      "venue" : "Journal of Natural Language Processing,",
      "citeRegEx" : "Inoue and Inui.,? \\Q2013\\E",
      "shortCiteRegEx" : "Inoue and Inui.",
      "year" : 2013
    }, {
      "title" : "Weighted Abduction for Discourse Processing Based on Integer Linear Programming",
      "author" : [ "Naoya Inoue", "Ekaterina Ovchinnikova", "Kentaro Inui", "Jerry Hobbs" ],
      "venue" : "In Plan, Activity, and Intent Recognition,",
      "citeRegEx" : "Inoue et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Inoue et al\\.",
      "year" : 2014
    }, {
      "title" : "Abductive Logic Programming",
      "author" : [ "A C Kakas", "R A Kowalski", "F Toni" ],
      "venue" : "Journal of Logic and Computation,",
      "citeRegEx" : "Kakas et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Kakas et al\\.",
      "year" : 1992
    }, {
      "title" : "The Alchemy system for statistical relational AI",
      "author" : [ "S Kok", "M Sumner", "M Richardson", "P Singla", "H Poon", "Lowd D", "J Wang", "A Nath", "P Domingos" ],
      "venue" : "Technical report,",
      "citeRegEx" : "Kok et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Kok et al\\.",
      "year" : 2010
    }, {
      "title" : "A-System: Problem solving through abduction",
      "author" : [ "Antonis C. Kakas", "Bert Van Nuffelen", "Marc Denecker" ],
      "venue" : "In International Joint Conference on Artificial Intelligence (IJCAI),",
      "citeRegEx" : "Kakas et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Kakas et al\\.",
      "year" : 2001
    }, {
      "title" : "Asperix, a first order forward chaining approach for answer set computing",
      "author" : [ "Claire Lefèvre", "Christopher Béatrix", "Igor Stéphan", "Laurent Garcia" ],
      "venue" : "Theory and Practice of Logic Programming,",
      "citeRegEx" : "Lefèvre et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lefèvre et al\\.",
      "year" : 2015
    }, {
      "title" : "Answer set programming and plan generation",
      "author" : [ "Vladimir Lifschitz" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Lifschitz.,? \\Q2002\\E",
      "shortCiteRegEx" : "Lifschitz.",
      "year" : 2002
    }, {
      "title" : "What Is Answer Set Programming",
      "author" : [ "Vladimir Lifschitz" ],
      "venue" : "In AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Lifschitz.,? \\Q2008\\E",
      "shortCiteRegEx" : "Lifschitz.",
      "year" : 2008
    }, {
      "title" : "Answer set programming via mixed integer programming",
      "author" : [ "Guohua Liu", "Tomi Janhunen", "I Niemelä" ],
      "venue" : "In Principles of Knowledge Representation and Reasoning (KR),",
      "citeRegEx" : "Liu et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2012
    }, {
      "title" : "Splitting a Logic Program",
      "author" : [ "Vladimir Lifschitz", "Hudson Turner" ],
      "venue" : "International Conference on Logic Programming (ICLP),",
      "citeRegEx" : "Lifschitz and Turner.,? \\Q1994\\E",
      "shortCiteRegEx" : "Lifschitz and Turner.",
      "year" : 1994
    }, {
      "title" : "Galliwasp: A goal-directed answer set solver. In Logic-Based Program Synthesis and Transformation (LoPSTR)",
      "author" : [ "Kyle Marple", "Gopal Gupta" ],
      "venue" : null,
      "citeRegEx" : "Marple and Gupta.,? \\Q2013\\E",
      "shortCiteRegEx" : "Marple and Gupta.",
      "year" : 2013
    }, {
      "title" : "The CIFF Proof Procedure for Abductive Logic Programming with Constraints: Theory, Implementation and Experiments",
      "author" : [ "Paolo Mancarella", "Giacomo Terreni", "Fariba Sadri", "Francesca Toni", "Ulle Endriss" ],
      "venue" : "Theory and Practice of Logic Programming,",
      "citeRegEx" : "Mancarella et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Mancarella et al\\.",
      "year" : 2009
    }, {
      "title" : "A General Abductive System with Applications to Plan Recognition and Diagnosis",
      "author" : [ "Hwee Tou Ng" ],
      "venue" : "Phd thesis, University of Texas at Austin,",
      "citeRegEx" : "Ng.,? \\Q1992\\E",
      "shortCiteRegEx" : "Ng.",
      "year" : 1992
    }, {
      "title" : "On the Role of Coherence in Abductive Explanation",
      "author" : [ "Hwee Tou Ng", "Raymond J Mooney" ],
      "venue" : "In National Conference on Artificial Intelligence,",
      "citeRegEx" : "Ng and Mooney.,? \\Q1990\\E",
      "shortCiteRegEx" : "Ng and Mooney.",
      "year" : 1990
    }, {
      "title" : "Abductive Plan Recognition and Diagnosis: A Comprehensive Empirical Evaluation",
      "author" : [ "Hwee Tou Ng", "Raymond J Mooney" ],
      "venue" : "In Knowledge Representation and Reasoning (KR),",
      "citeRegEx" : "Ng and Mooney.,? \\Q1992\\E",
      "shortCiteRegEx" : "Ng and Mooney.",
      "year" : 1992
    }, {
      "title" : "Abduction and Induction",
      "author" : [ "C S Peirce" ],
      "venue" : "In Philosophical Writings of Peirce,",
      "citeRegEx" : "Peirce.,? \\Q1955\\E",
      "shortCiteRegEx" : "Peirce.",
      "year" : 1955
    }, {
      "title" : "Tackling Winograd Schemas by Formalizing Relevance Theory in Knowledge Graphs",
      "author" : [ "Peter Schüller" ],
      "venue" : "In International Conference on Principles of Knowledge Representation and Reasoning (KR),",
      "citeRegEx" : "Schüller.,? \\Q2014\\E",
      "shortCiteRegEx" : "Schüller.",
      "year" : 2014
    }, {
      "title" : "Modeling Abduction over Acyclic First-Order Logic Horn Theories in Answer Set Programming: Preliminary Experiments",
      "author" : [ "Peter Schüller" ],
      "venue" : "In International Workshop on Experimental Evaluation of Algorithms for Solving Problems with Combinatorial Explosion (RCRA),",
      "citeRegEx" : "Schüller.,? \\Q2015\\E",
      "shortCiteRegEx" : "Schüller.",
      "year" : 2015
    }, {
      "title" : "Abductive Markov Logic for Plan Recognition",
      "author" : [ "Parag Singla", "Raymond J Mooney" ],
      "venue" : "In AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Singla and Mooney.,? \\Q2011\\E",
      "shortCiteRegEx" : "Singla and Mooney.",
      "year" : 2011
    }, {
      "title" : "Rationale and methods for abductive reasoning in natural-language interpretation",
      "author" : [ "Mark Stickel" ],
      "venue" : "In Natural Language and Logic,",
      "citeRegEx" : "Stickel.,? \\Q1989\\E",
      "shortCiteRegEx" : "Stickel.",
      "year" : 1989
    }, {
      "title" : "The TPTP problem library and associated infrastructure: the FOF and CNF parts, v3.5.0",
      "author" : [ "Geoff Sutcliffe" ],
      "venue" : "Journal of Automated Reasoning,",
      "citeRegEx" : "Sutcliffe.,? \\Q2009\\E",
      "shortCiteRegEx" : "Sutcliffe.",
      "year" : 2009
    }, {
      "title" : "Complexity of nonrecursive logic programs with complex values",
      "author" : [ "S. Vorobyov", "A. Voronkov" ],
      "venue" : "Proceedings of the seventeenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems,",
      "citeRegEx" : "Vorobyov and Voronkov.,? \\Q1998\\E",
      "shortCiteRegEx" : "Vorobyov and Voronkov.",
      "year" : 1998
    }, {
      "title" : "Boosting the Efficiency of First-Order Abductive Reasoning Using Pre-estimated Relatedness between Predicates",
      "author" : [ "Kazeto Yamamoto", "Naoya Inoue", "Kentaro Inui", "Yuki Arase", "Jun’ichi Tsujii" ],
      "venue" : "International Journal of Machine Learning and Computing,",
      "citeRegEx" : "Yamamoto et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Yamamoto et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "We study abduction in First Order Horn logic theories where all atoms can be abduced and we are looking for preferred solutions with respect to three objective functions: cardinality minimality, coherence, and weighted abduction. We represent this reasoning problem in Answer Set Programming (ASP), in order to obtain a flexible framework for experimenting with global constraints and objective functions, and to test the boundaries of what is possible with ASP. Realizing this problem in ASP is challenging as it requires value invention and equivalence between certain constants, because the Unique Names Assumption does not hold in general. To permit reasoning in cyclic theories, we formally describe fine-grained variations of limiting Skolemization. We identify term equivalence as a main instantiation bottleneck, and improve the efficiency of our approach with on-demand constraints that were used to eliminate the same bottleneck in state-of-the-art solvers. We evaluate our approach experimentally on the ACCEL benchmark for plan recognition in Natural Language Understanding. Our encodings are publicly available, modular, and our approach is more efficient than state-of-the-art solvers on the ACCEL benchmark.",
    "creator" : "LaTeX with hyperref package"
  }
}