{
  "name" : "1610.02633.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Enabling Medical Translation for Low-Resource Languages",
    "authors" : [ "Ahmad Musleh", "Nadir Durrani", "Irina Temnikova", "Preslav Nakov", "Stephan Vogel", "Osama Alsaad" ],
    "emails" : [ "amusleh@qf.org.qa", "ndurrani@qf.org.qa", "itemnikova@qf.org.qa", "pnakov@qf.org.qa", "svogel@qf.org.qa", "osama.alsaad@qatar.tamu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n61 0.\n02 63\n3v 1\n[ cs\n.C L\n] 9\nO ct\n2 01\nKeywords: Machine Translation, medical translation, doctor-patient communication, resource-poor languages, Hindi."
    }, {
      "heading" : "1 Introduction",
      "text" : "In recent years, Qatar’s booming economy has resulted in rapid growth in the number of migrant workers needed for the growing number of infrastructure projects. These workers, who mainly come from the southern parts of Asia, usually know little or no English and do not know any Arabic either. This results in a communication barrier between them and the natives. More serious situation arises in the case of medical emergency. This causes serious problems as the public administration and services in Qatar mostly use Arabic and English. According to a 2012 report by the Weill Cornell Medical College (WCMC1) in Qatar [15], almost 78% of the patients visiting the Hamad Medical Corporation (HMC, the main health-care provider in Qatar) did not speak Arabic or English. The study also pointed out that the five most spoken languages in Qatar in 2012 were (in that order) Nepali, Urdu, Hindi, English, and Arabic. The report also pointed out that even though HMC currently uses medical interpreters to overcome this problem, their number is not sufficient. This has urged the authorities to look into technology for alternatives.\n1 http://qatar-weill.cornell.edu\nIn this paper, we propose a solution to bridge this language gap. We present our preliminary effort towards developing a Statistical Machine Translation (SMT) system for doctor-patient communication in Qatar. The success of a data-driven system largely depends upon the availability of in-domain data.\nThis makes our task non-trivial as we are dealing with a low-resourced language pair and furthermore with the medical domain. We decided to focus on Hindi, one of the languages under question. Our decision was driven by the fact, that Hindi and Urdu are closely-related languages, often considered dialects of each other, and people from Nepal and other South-Asian countries working in Qatar typically understand Hindi. Moreover, we have access to more HindiEnglish parallel data than for any other language pair involving the top-5 most spoken languages in Qatar.\nOur focus in this paper is on data collection and data generation (Sections 3 and 4). We collected data from various sources (Section 3), including (i) Wikimedia (Wikipedia, Wiktionary, and OmegaWiki) parallel English-Hindi data, (ii) doctor-patient dialogues from YouTube videos, and movie subtitles, and (iii) parallel medical terms from BabelNet and MeSH. Moreover, we synthesized Hindi-English parallel data from Urdu-English data, by translating the Urdu part into Hindi. The approach is described in Section 4. Our results show improvement of up to +1.45 when using synthesized data, and up to +1.66, when concatenating the mined dictionaries on top of the synthesized data (Section 5).\nMoreover, Section 2 provides an overview of related work on machine translation for doctor-patient dialogues and briefly discusses the Machine Translation (MT) approaches for low-resource languages; Section 5 presents the results of the manual evaluation, and Section 6 provides the conclusions and discusses directions for future work."
    }, {
      "heading" : "2 Related Work",
      "text" : "Below we first describe some MT applications for doctor-patient communication. Then, we present more general research on MT for the medical domain."
    }, {
      "heading" : "2.1 Bi-directional Doctor↔Patient Communication Applications",
      "text" : "We will first describe the pre-existing MT systems for doctor-patient communication, particularly the ones that required data collection for under-resourced languages. Several MT systems facilitating doctor-patient communication have been built in the past [3,13,5,14,20,17]. Most of them are still prototypes, and only few have been fully deployed. Some of these systems work with underresourced languages [3,14,20,17]. Moreover, their solution relies on mapping the utterances to an interlingua, instead of using SMT.\nMedSLT [3] is an interlingua-based speech-to-speech translation system. It covers a restricted set of domains, and covers English, French, Japanese, Spanish, Catalan, and Arabic. The system can translate doctor’s questions/statements to the patient, but not the responses by the patient back to the doctor.\nConverser [5] is a commercial doctor-patient speech-to-speech bidirectional MT system for the English↔Spanish language pair. It has been deployed in several US hospitals and has the following features: users can correct the automatic speech recognition (ASR) and MT outputs, back-translation (re-translation of the translation) to the user is made to allow this. The system maps concepts to a lexical database specially created from various sources, and also allows “translation shortcuts” (i.e., translation memory of previous translations that do not need verification).\nJibbigo [13] is a travel and medical speech-to-speech MT system, deployed as an iPhone mobile app. Jibbigo allows English-to-Spanish and Spanish-to-English medical speech-to-speech translation.\nS-MINDS [14] is a two-way doctors-patient MT system, which uses an inhouse “interpretation” software. It matches the ASR utterances to a finite set of concepts in the specific semantic domain and then paraphrases them. In case the utterance cannot be matched, the system uses an SMT engine.\nAccultran [20] is an automatic translation system prototype, which features back translation to the doctor and yes/no or multiple-choice questions (MCQs) to the patient. It allows the doctor to confirm the translation to the patient, and has a cross cultural adviser. It flags sensitive utterances that are difficult to translate to the patient. The system maps the utterances to SNOMED-CT or Clinical Document Architecture (CDA-2) standards, which are used as an interlingua.\nIBM MASTOR [17] is a speech-to-speech MT system for two language pairs (English-Mandarin and English-dialectal Arabic), which relies on ASR, SMT, and Speech Synthesis components. It works both on laptops and PDAs.\nEnglish-Portugese SLT [37] is an English-Portuguese speech-to-speech MT system, composed of an ASR, MT (relying on HMM) and speech synthesis. It works as an online service and as a mobile application.\nNone of the above systems handles the top-5 languages of interest to Qatar."
    }, {
      "heading" : "2.2 Uni-directional Doctor↔Patient Communication Applications",
      "text" : "Besides the above-described MT systems, there are a number of mobile or web applications, which are based on pre-translated phrases. The phrases are prerecorded by professionals or native speakers and can be played to the patient. Most of these applications work only in the doctor-to-patient direction. The most popular ones are UniversalDoctor2, MediBabble3, Canopy4, MedSpeak, Mavro Emergency Medical Spanish5, and DuoChart6.\nUnfortunately, these applications do not allow free, unseen, or spontaneous translations, and do not cover the language pairs of interest for Qatar. Moreover, some of them (e.g., UniversalDoctor) require a paid subscription.\n2 http://www.universaldoctor.com 3 http://medibabble.com 4 http://www.canopyapps.com 5 http://mavroinc.com/medical.html 6 http://duochart.com"
    }, {
      "heading" : "2.3 General Research in Medical Machine Translation",
      "text" : "A number of systems have been developed and participated in the WMT’14 Medical translation task. It is a Cross-Lingual Information Retrieval (CLIR) task divided into two sub-tasks: (i) translation of user search queries, and (ii) translation of summaries of retrieved documents:\nA system described in [12], part of the Khresmoi project7, uses the phrasebased Moses and standard methods for domain adaptation. [25] also uses the phrase-basedMoses system and achieved the highest BLEU score for the EnglishGerman intrinsic query translation evaluation. Another system [26] combined web-crawled in-domain monolingual data and a bilingual lexicon in order to complement the limited in-domain parallel corpora. A third one [34] proposed a terminology translation system for the query translation subtask and used 6 different methods for terminology extraction. A fourth system [35] used a combination of n-gram based NCODE and phrase-based Moses to the subtask of sentence translation. The system of [40] applied a combination of domain adaptation techniques on the medical summary sentence translation task and achieved the first and the second best BLEU scores. Then, the system of [44] used the Moses phrase-based system and worked on the medical summary WMT’14 task and experimented with translation models, re-ordering models, operation sequence models, and language models, as well as with data selection. A study on quality analysis of machine translation systems in medical domain was carried in [27]. Most of this work focused on European language pairs and did not cover languages of interest to us, nor did it involve low-resource languages in general."
    }, {
      "heading" : "3 Data Collection",
      "text" : "As the main problem of low resource languages is data collection [24,30], we have adopted a variety of approaches, in order to collect as much parallel EnglishHindi data as possible."
    }, {
      "heading" : "3.1 Wiki Dumps",
      "text" : "We downloaded, extracted and mined all language links from Wikipedia,8 Wiktionary,9 and OmegaWiki10 in order to provide a one-to-one word mapping from English into Hindi. We then extracted page links and language links from Wikipedia and Wiktionary. Moreover, we used OmegaWiki to provide a bilingual word dictionary containing the word, its synonyms, its translation, and its lexical, terminological and ontological forms. We extracted the data using two OmegaWiki sources: bilingual dictionaries and an SQL database dump. Table 1 shows the number of Hindi words we collected from all three sources.\n7 http://www.khresmoi.eu 8 http://www.wikipedia.org 9 http://www.wiktionary.org 10 http://www.omegawiki.org"
    }, {
      "heading" : "3.2 Doctor-Patient YouTube Videos and Movie Subtitles",
      "text" : "We used a mixed approach to extract doctor-patient dialogues from medical YouTube subtitles. As using the YouTube-embedded automatic subtitling is inefficient, the dialogues of the videos were first extracted by manually typing the audio found in the videos. However, as this process was very time consuming, we started a screenshot session in order to collect all the visual representations of the subtitles. Next, the subtitles were extracted using Tesseract,11 an open source Optical Character Recognition (OCR) reader provided by Google, on the screenshots captured. The subtitles were then manually corrected, translated into Hindi using Google Translate, and post-edited by a Hindi native speaker. This resulted in a parallel corpus of medical dialogues with 11,000 Hindi words (1,200 sentences). These sentences were later used for tuning and testing our MT system. Additionally, we used a web crawler to extract a small number of non-medical parallel English-Hindi movie subtitles (nine movies) from Open Subtitles.12"
    }, {
      "heading" : "3.3 BabelNet and MeSH",
      "text" : "We extracted medical terms from BabelNet [32] using their API. As Medical Subject Headings (MeSH13) represents the largest source of Medical terms, we downloaded their dumps and extracted the 198,958 MeSH terms which we overlapped with the previously mined results of Wiki Dumps."
    }, {
      "heading" : "4 Data Synthesis",
      "text" : "Hindi and Urdu are closely-related languages that share grammatical structure and largely overlap in vocabulary. This provides strong motivation to transform an Urdu-English parallel data into Hindi-English by translating the Urdu part into Hindi. We made use of the Urdu-English segment of the Indic multi-parallel corpus [36], which contains about 87,000 sentence pairs. The Hindi-English segment of this corpus is a subset of the parallel data that was made available for the WMT’14 translation task, but its English side is completely disjoint from the English side of the Urdu-English segment.\n11 https://github.com/tesseract-ocr 12 http://www.opensubtitles.com 13 http://www.ncbi.nlm.nih.gov/mesh\nInitially, we trained an Urdu-to-Hindi SMT system using the tiny EMILLE14 corpus [1]. However, we found this system to be useless for translating the Urdu part of the Indic data due to domain mismatch and the high proportion of Outof-Vocabulary (OOV) words (approximately 310,000 tokens). Thus, in order to reduce data sparseness, we synthesized additional phrase tables using interpolation and transliteration."
    }, {
      "heading" : "4.1 Interpolation",
      "text" : "We built two phrase translation tables p(ūi|ēi) and p(ēi|h̄i), from Urdu-English (Indic corpus) and Hindi-English (HindEnCorp [2]) bitexts. Given the phrase table for Urdu-English p(ūi|ēi) and the phrase table for English-Hindi p(ēi|h̄i), we induced an Urdu-Hindi phrase table p(ūi|h̄i) using the model [39,43]:\np(ūi|h̄i) = ∑\nēi\np(ūi|ēi)p(ēi|h̄i) (1)\nThe number of entries in the baseline Urdu-to-Hindi phrase table were approximately 254,000. Using interpolation, we were able to build a phrase table containing roughly 10M phrases. This reduced the number of OOV tokens from 310K to approximately 50,000."
    }, {
      "heading" : "4.2 Transliteration",
      "text" : "As Urdu and Hindi are written in different scripts (Arabic and Devanagri, respectively), we added a transliteration component to our Urdu-to-Hindi system. While it can be used to translate all 50,000 OOV words, previous research has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs [29,31,38,41,42]. Following [9], we transliterate all Urdu words to Hindi and hypothesize n-best transliterations, along with regular translations. The idea is to generate novel Hindi translations that may be absent from the regular and interpolated phrase table, but for which there is evidence in the language model. Moreover, the overlapping evidence in the translation and transliteration phrase tables improves the overall system.\nWe learn an unsupervised transliteration model [10] from the word-alignments of Urdu-Hindi parallel data. We were able to extract around 2,800 transliteration pairs. To learn a richer transliteration model, we additionally fed the interpolated phrase table, as described above, to the transliteration miner. We were able to mine about 21,000 additional transliteration pairs and to build an Urdu-Hindi character-based model from it. In order to fully capitalize on the large overlap in Hindi–Urdu vocabulary, we transliterated each word in the Urdu test data to Hindi and we produced a phrase table with 100-best transliterations. We then used the two synthesized (triangulated and transliterated) phrase tables along with the baseline Urdu-to-Hindi phrase table in a log-linear model.\n14 EMILLE contains about 12,000 sentences of comparable data in Hindi and Urdu. We were able to align about 7,000 sentences to build an Urdu-to-Hindi system.\nTable 2 shows development results from training an Urdu-to-Hindi SMT system. By adding interpolated phrase tables and transliteration, we obtain a very sizable gain of +3.35 over the baseline Urdu→Hindi system. Using our best Urdu-to-Hindi system (Bu,hTgTr), we translated the Urdu part of the multiIndic corpus to form a Hindi-English bi-text. This yielded a synthesized bi-text of ≈87,000 Hindi-English sentence pairs. Detailed analysis can be found in [7]."
    }, {
      "heading" : "5 Experiments and Evaluation",
      "text" : ""
    }, {
      "heading" : "5.1 Machine Translation",
      "text" : "5.1.1 Baseline Data We trained the Hindi-English systems using HindiEnglish parallel data [2] composed by compiling several sources including the Hindi-English segment of the Indic parallel corpus. It contains 287,202 parallel sentences, and 4,296,007 Hindi and 4,026,860 English tokens. We used 635 sentences (6,111 tokens) for tuning and 636 sentences (5,231) for testing, collected from doctor-patient communication dialogues in YouTube videos. The sentences were translated into Hindi by a human translator. We trained interpolated language models using all the English and Hindi monolingual data made available for the WMT’14 translation task: 287.3M English and 43.4M Hindi tokens.\n5.1.2 Baseline System We trained a phrase-based system using Moses [22] with the following settings: a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments [33], an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [19] used at runtime, 100-best translation options, MBR decoding [23], Cube Pruning [21] using a stack size of 1,000 during tuning and 5,000 during testing. We tuned with the k-best batch MIRA [4]. We additionally used msd-bidirectional-fe lexicalized reordering, a 5-gram OSM [11], class-based models [8]15 sparse lexical and domain features [18], a distortion limit of 6, and the no-reordering-over-punctuation heuristic. We used an unsupervised transliteration model [10] to transliterate the OOV words. These are state-of-the-art settings, as used in [6].\n5.1.3 Results Table 3 shows the results when adding the synthesized HindiEnglish bi-text on top of the baseline system (+Syn). The synthesized data was simply concatenated to the baseline data to train the system. We also tried building phrase tables (+PT) separately from the baseline data and from the synthesized one and used as a separate features in the log-linear model as done in [28,29,41,42]. We found that concatenating synthetic data with the baseline data directly was superior to training a separate phrase-table from it. We obtained improvements of up to +1.45 by adding synthetic data.\nTable 4 shows the results from adding the mined dictionaries to the baseline system. The baseline system (B0) used in this case is the best system in Table 3. Again, we simply concatenated the dictionaries with the baseline data and we gained improvements of up to +1.66 BLEU points absolute. Cumulatively, by using dictionaries and synthesized phrase-tables, we were able to obtain statistically significant improvements of more than 3 BLEU points."
    }, {
      "heading" : "5.2 Manual Evaluation",
      "text" : "In addition to the above evaluation, we ran a small manual evaluation experiment, using the Appraise platform [16]. The two sections below describe the results of the Hindi-to-English (Section 5.2.1) and the English-to-Hindi (Section 5.2.2) evaluations.\n5.2.1 Hindi-to-English The evaluation was conducted by 3 monolingual English speakers, using 321 randomly selected sentences, divided into three batches of evaluation. Similar to the setup at evaluation campaigns such as WMT, the evaluators were shown the translations and references.\n15 We used mkcls to cluster the data into 50 clusters.\nThe evaluators were asked to assign one of the following three categories to each translation: (a) helpful in this situation, (b) misleading, and (c) doubtful that people will understand it. As shown in Table 5, over 37% of the cases were classified as helpful (good translations), 39% as doubtful (mediocre), and 24% as misleading (really bad translations). Annotators did not always agree, e.g., Judge 1 and Judge 2 were more lenient than Judge 3.\n5.2.2 English-to-Hindi In order to check the output of the English-to-Hindi system, we asked a bilingual judge to evaluate 328 sentences. She was asked to classify the sentences in the same categories as for the Hindi-English evaluation. Table 6 shows the results; we can see that 55.8% of the sentences were found helpful in this situation. This is hardly because English-Hindi system was any better, but more likely because the human evaluator was lenient. Unfortunately, we could not find a second Hindi speaker to evaluate our translations, and thus we could not calculate inter-annotator agreement.\n5.2.3 Analysis In order to understand the problems with the Hindi output, we conducted an error analysis on 100 sentences classifying the errors into the following categories:\n– missing/untranslated words; – wrongly translated words; – word order problems; – other error types, e.g., extra words.\nTable 7 shows the results. We can see that most of the problems are associated with word order problems (84%) or wrongly translated words (74%)."
    }, {
      "heading" : "6 Conclusions",
      "text" : "We presented our preliminary efforts towards building a Hindi↔English SMT system for facilitating doctor-patient communication. We improved our baseline system using two approaches, namely (i) additional data collection, and (ii) automatic data synthesis. We mined useful dictionaries from Wikipedia in order to improve the coverage of our system. We made use of the relatedness between Hindi and Urdu to generate synthetic Hindi-English bi-texts by automatically translating 87,000 Urdu sentences into Hindi. Both our data collection and our synthesis approach worked well and have shown significant improvements over the baseline system, yielding a total improvement of +3.11 BLEU points absolute for English-to-Hindi and +2.07 for Hindi-to-English. We also carried out human evaluation for the best system. In the error analysis of the Hindi outputs, we found that most errors were due to ordering of the words in the output, or to wrong lexical choice.\nIn future work, we plan to collect more data for Hindi, but also to synthesize Urdu data. We further plan to develop a system for Nepali-English. Finally, we would like to add Automatic Speech Recognition (ASR) and Speech Synthesis components in order to build a fully-functional speech-to-speech system, which we would test and gradually deploy for use in real-world scenarios."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The authors would like to thank Naila Khalisha and Manisha Bansal for their contributions towards the project."
    } ],
    "references" : [ {
      "title" : "EMILLE, A 67-Million Word Corpus of Indic Languages: Data Collection, Mark-up and Harmonisation",
      "author" : [ "Paul Baker", "Andrew Hardie", "Tony McEnery", "Hamish Cunningham", "Robert J. Gaizauskas" ],
      "venue" : "In Proceedings of the Third International Language Resources and Evaluation Conference,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2002
    }, {
      "title" : "Hindi-English and Hindi-only Corpus for Machine Translation",
      "author" : [ "Ondřej Bojar", "Vojtěch Diatka", "Pavel Rychlý", "Pavel Straňák", "Aleš Tamchyna", "Dan Zeman" ],
      "venue" : "In Proceedings of the Ninth International Language Resources and Evaluation Conference,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2014
    }, {
      "title" : "Many-to-many multilingual medical speech translation on a PDA",
      "author" : [ "Pierrette Bouillon", "Glenn Flores", "Maria Georgescul", "Ismahene Sonia Halimi Mallem", "Beth Ann Hockey", "Hitoshi Isahara", "Kyoko Kanzaki", "Yukie Nakao", "Emmanuel Rayner", "Marianne Elina Santaholma", "Marianne Starlander", "Nikos Tsourakis" ],
      "venue" : "In Proceedings of the Eighth Conference of the Association for Machine Translation in the Americas,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2008
    }, {
      "title" : "Batch Tuning Strategies for Statistical Machine Translation",
      "author" : [ "Colin Cherry", "George Foster" ],
      "venue" : "In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "Converser: Highly Interactive Speech-to-Speech Translation for Healthcare",
      "author" : [ "Mike Dillinger", "Mark Seligman" ],
      "venue" : "In Proceedings of the COLING-ACL 2006 Workshop on Medical Speech Translation,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2006
    }, {
      "title" : "Edinburgh’s Phrase-based Machine Translation Systems for WMT-14",
      "author" : [ "Nadir Durrani", "Barry Haddow", "Philipp Koehn", "Kenneth Heafield" ],
      "venue" : "In Proceedings of the ACL 2014 Ninth Workshop on Statistical Machine Translation,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2014
    }, {
      "title" : "Improving Machine Translation via Triangulation and Transliteration",
      "author" : [ "Nadir Durrani", "Philipp Koehn" ],
      "venue" : "In Proceedings of the 17th Annual Conference of the European Association for Machine Translation,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2014
    }, {
      "title" : "Investigating the Usefulness of Generalized Word Representations in SMT",
      "author" : [ "Nadir Durrani", "Philipp Koehn", "Helmut Schmid", "Alexander Fraser" ],
      "venue" : "In Proceedings of the 25th Annual Conference on Computational Linguistics,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2014
    }, {
      "title" : "Hindi-toUrdu Machine Translation through Transliteration",
      "author" : [ "Nadir Durrani", "Hassan Sajjad", "Alexander Fraser", "Helmut Schmid" ],
      "venue" : "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2010
    }, {
      "title" : "Integrating an Unsupervised Transliteration Model into Statistical Machine Translation",
      "author" : [ "Nadir Durrani", "Hassan Sajjad", "Hieu Hoang", "Philipp Koehn" ],
      "venue" : "In Proceedings of the 15th Conference of the European Chapter of the ACL,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2014
    }, {
      "title" : "The Operation Sequence Model – Combining N-Gram-based and Phrasebased Statistical Machine Translation",
      "author" : [ "Nadir Durrani", "Helmut Schmid", "Alexander Fraser", "Philipp Koehn", "Hinrich Schütze" ],
      "venue" : "Computational Linguistics,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2015
    }, {
      "title" : "Machine Translation of Medical Texts in the Khresmoi Project",
      "author" : [ "Ondrej Dušek", "Jan Hajic", "Jaroslava Hlavácová", "Michal Novák", "Pavel Pecina", "Rudolf Rosa", "Aleš Tamchyna", "Zdenka Urešová", "Daniel Zeman" ],
      "venue" : "In Proceedings of the 52nd Annual Meeting of the Association of Computational Linguistics,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2014
    }, {
      "title" : "Jibbigo: Speech-to-Speech Translation on Mobile Devices",
      "author" : [ "Matthias Eck", "Ian Lane", "Ying Zhang", "Alex Waibel" ],
      "venue" : "In Proceedings of IEEE Spoken Language Technology Workshop,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2010
    }, {
      "title" : "Speech to Speech Translation for Medical Triage in Korean",
      "author" : [ "Farzad Ehsani", "Jim Kimzey", "Demitrios Master", "Karen Sudre", "Hunil Park" ],
      "venue" : "In Proceedings of the COLING-ACL 2006 Workshop on Medical Speech Translation,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2006
    }, {
      "title" : "Cultural Competence Springs Up in the Desert: The Story of the Center for Cultural Competence in Health Care at Weill Cornell Medical College in Qatar",
      "author" : [ "Maha Elnashar", "Huda Abdelrahim", "Michael D Fetters" ],
      "venue" : "Academic Medicine,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2012
    }, {
      "title" : "Appraise: An Open-source Toolkit for Manual Evaluation of MT Output",
      "author" : [ "Christian Federmann" ],
      "venue" : "The Prague Bulletin of Mathematical Linguistics,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2012
    }, {
      "title" : "IBM MASTOR System: Multilingual Automatic Speech-to-Speech Translator",
      "author" : [ "Yuqing Gao", "Liang Gu", "Bowen Zhou", "Ruhi Sarikaya", "Mohamed Afify", "Hong-Kwang Kuo", "Wei-Zhong Zhu", "Yonggang Deng", "Charles Prosser", "Wei Zhang" ],
      "venue" : "In Proceedings of the COLING-ACL 2006 Workshop on Medical Speech Translation,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2006
    }, {
      "title" : "Sparse Lexicalised features and Topic Adaptation for SMT",
      "author" : [ "Eva Hasler", "Barry Haddow", "Philipp Koehn" ],
      "venue" : "In Proceedings of the Seventh International Workshop on Spoken Language Translation,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2012
    }, {
      "title" : "KenLM: Faster and Smaller Language Model Queries",
      "author" : [ "Kenneth Heafield" ],
      "venue" : "In Proceedings of the Sixth Workshop on Statistical Machine Translation,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2011
    }, {
      "title" : "Automated Interpretation of Clinical Encounters with Cultural Cues and Electronic Health Record Generation",
      "author" : [ "Daniel T. Heinze", "Alexander Turchin", "V. Jagannathan" ],
      "venue" : "In Proceedings of the COLING-ACL 2006 Workshop on Medical Speech Translation,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2006
    }, {
      "title" : "Forest Rescoring: Faster Decoding with Integrated Language Models",
      "author" : [ "Liang Huang", "David Chiang" ],
      "venue" : "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2007
    }, {
      "title" : "Moses: Open Source Toolkit for Statistical Machine Translation",
      "author" : [ "Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens", "Chris Dyer", "Ondrej Bojar", "Alexandra Constantin", "Evan Herbst" ],
      "venue" : "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2007
    }, {
      "title" : "Minimum Bayes-Risk Decoding for Statistical Machine Translation",
      "author" : [ "Shankar Kumar", "William J. Byrne" ],
      "venue" : "In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2004
    }, {
      "title" : "Crisis MT: Developing a Cookbook for MT in Crisis Situations",
      "author" : [ "William D. Lewis", "Robert Munro", "Stephan Vogel" ],
      "venue" : "In Proceedings of the EMNLP’11 Sixth Workshop on Statistical Machine Translation,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2011
    }, {
      "title" : "Postechs System Description for Medical Text Translation Task",
      "author" : [ "Jianri Li", "Se-Jong Kim", "Hwidong Na", "Jong-Hyeok Lee" ],
      "venue" : "In Proceedings of the Ninth Workshop on Statistical Machine Translation,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2014
    }, {
      "title" : "Domain Adaptation for Medical Text Translation Using Web Resources",
      "author" : [ "Yi Lu", "Longyue Wang", "Derek F Wong", "Lidia S. Chao", "Yiming Wang", "Francisco Oliveira" ],
      "venue" : "In Proceedings of the Ninth Workshop on Statistical Machine Translation,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2014
    }, {
      "title" : "Machine Translation in Medicine. A Quality Analysis of Statistical Machine Translation in the Medical Domain",
      "author" : [ "Jordi Serrano Pons" ],
      "venue" : "In Proceedings of the 1st Virtual International Conference on Advanced Research in Scientific Areas,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2012
    }, {
      "title" : "Improving English-Spanish Statistical Machine Translation: Experiments in Domain Adaptation, Sentence Paraphrasing, Tokenization, and Recasing",
      "author" : [ "Preslav Nakov" ],
      "venue" : "In Proceedings of the Third Workshop on Statistical Machine Translation,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2008
    }, {
      "title" : "Improved Statistical Machine Translation for Resource-poor Languages Using Related Resource-rich Languages",
      "author" : [ "Preslav Nakov", "Hwee Tou Ng" ],
      "venue" : "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2009
    }, {
      "title" : "Improving statistical machine translation for a resource-poor language using related resource-rich languages",
      "author" : [ "Preslav Nakov", "Hwee Tou Ng" ],
      "venue" : "Journal of Artificial Intelligence Research (JAIR),",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2012
    }, {
      "title" : "Combining Word-level and Character-level Models for Machine Translation Between Closely-related Languages",
      "author" : [ "Preslav Nakov", "Jörg Tiedemann" ],
      "venue" : "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers - Volume 2,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2012
    }, {
      "title" : "BabelNet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network",
      "author" : [ "Roberto Navigli", "Simone Paolo Ponzetto" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2012
    }, {
      "title" : "A Systematic Comparison of Various Statistical Alignment Models",
      "author" : [ "Franz J. Och", "Hermann Ney" ],
      "venue" : "Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2003
    }, {
      "title" : "The DCU Terminology Translation System for the Medical Query Subtask at WMT14",
      "author" : [ "Tsuyoshi Okita", "Ali Hosseinzadeh Vahid", "Andy Way", "Qun Liu" ],
      "venue" : "In Proceedings of the ACL 2014 Workshop on Statistical Machine Translation,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2014
    }, {
      "title" : "LIMSI@WMT14 Medical Translation Task",
      "author" : [ "Nicolas Pécheux", "Li Gong", "Quoc Khanh Do", "Benjamin Marie", "Yulia Ivanishcheva", "Alexandre Allauzen", "Thomas Lavergne", "Jan Niehues", "Aurélien Max", "Francois Yvon" ],
      "venue" : "In Proceedings of the ACL 2014 Workshop on Statistical Machine Translation,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2014
    }, {
      "title" : "Constructing Parallel Corpora for Six Indian Languages via Crowdsourcing",
      "author" : [ "Matt Post", "Chris Callison-Burch", "Miles Osborne" ],
      "venue" : "In Proceedings of the Seventh Workshop on Statistical Machine Translation,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2012
    }, {
      "title" : "Speech-to-Speech Translation to Support Medical Interviews",
      "author" : [ ],
      "venue" : "PhD thesis, Universidade de Lisboa, Portugal,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2013
    }, {
      "title" : "Analyzing the Use of Character-Level Translation with Sparse and Noisy Datasets",
      "author" : [ "Jörg Tiedemann", "Preslav Nakov" ],
      "venue" : "In Proceedings of the International Conference Recent Advances in Natural Language Processing,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2013
    }, {
      "title" : "A Comparison of Pivot Methods for PhraseBased Statistical Machine Translation",
      "author" : [ "Masao Utiyama", "Hitoshi Isahara" ],
      "venue" : "In Proceedings of the 2007 Meeting of the North American Chapter of the Association for Computational Linguistics,",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 2007
    }, {
      "title" : "Combining Domain Adaptation Approaches for Medical Text Translation",
      "author" : [ "Longyue Wang", "Yi Lu", "Derek F Wong", "Lidia S Chao", "Yiming Wang", "Francisco Oliveira" ],
      "venue" : "In Proceedings of the Ninth Workshop on Statistical Machine Translation,",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2014
    }, {
      "title" : "Source Language Adaptation for Resource-Poor Machine Translation",
      "author" : [ "Pidong Wang", "Preslav Nakov", "Hwee Tou Ng" ],
      "venue" : "In Proceedings of the 2012 Joint Conference 14 Authors Suppressed Due to Excessive Length on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2012
    }, {
      "title" : "Source Language Adaptation Approaches for Resource-Poor Machine Translation",
      "author" : [ "Pidong Wang", "Preslav Nakov", "Hwee Tou Ng" ],
      "venue" : "Computational Linguistics,",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2016
    }, {
      "title" : "Pivot Language Approach for Phrase-Based Statistical Machine Translation",
      "author" : [ "HuaWu", "Haifeng Wang" ],
      "venue" : "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,",
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 2007
    }, {
      "title" : "Experiments in Medical Translation Shared Task at WMT 2014",
      "author" : [ "Jian Zhang", "Xiaofeng Wu", "Iacer Calixto", "Ali Hosseinzadeh Vahid", "Xiaojun Zhang", "Andy Way", "Qun Liu" ],
      "venue" : "In Proceedings of the Ninth Workshop on Statistical Machine Translation,",
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "According to a 2012 report by the Weill Cornell Medical College (WCMC) in Qatar [15], almost 78% of the patients visiting the Hamad Medical Corporation (HMC, the main health-care provider in Qatar) did not speak Arabic or English.",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 2,
      "context" : "Several MT systems facilitating doctor-patient communication have been built in the past [3,13,5,14,20,17].",
      "startOffset" : 89,
      "endOffset" : 106
    }, {
      "referenceID" : 12,
      "context" : "Several MT systems facilitating doctor-patient communication have been built in the past [3,13,5,14,20,17].",
      "startOffset" : 89,
      "endOffset" : 106
    }, {
      "referenceID" : 4,
      "context" : "Several MT systems facilitating doctor-patient communication have been built in the past [3,13,5,14,20,17].",
      "startOffset" : 89,
      "endOffset" : 106
    }, {
      "referenceID" : 13,
      "context" : "Several MT systems facilitating doctor-patient communication have been built in the past [3,13,5,14,20,17].",
      "startOffset" : 89,
      "endOffset" : 106
    }, {
      "referenceID" : 19,
      "context" : "Several MT systems facilitating doctor-patient communication have been built in the past [3,13,5,14,20,17].",
      "startOffset" : 89,
      "endOffset" : 106
    }, {
      "referenceID" : 16,
      "context" : "Several MT systems facilitating doctor-patient communication have been built in the past [3,13,5,14,20,17].",
      "startOffset" : 89,
      "endOffset" : 106
    }, {
      "referenceID" : 2,
      "context" : "Some of these systems work with underresourced languages [3,14,20,17].",
      "startOffset" : 57,
      "endOffset" : 69
    }, {
      "referenceID" : 13,
      "context" : "Some of these systems work with underresourced languages [3,14,20,17].",
      "startOffset" : 57,
      "endOffset" : 69
    }, {
      "referenceID" : 19,
      "context" : "Some of these systems work with underresourced languages [3,14,20,17].",
      "startOffset" : 57,
      "endOffset" : 69
    }, {
      "referenceID" : 16,
      "context" : "Some of these systems work with underresourced languages [3,14,20,17].",
      "startOffset" : 57,
      "endOffset" : 69
    }, {
      "referenceID" : 2,
      "context" : "MedSLT [3] is an interlingua-based speech-to-speech translation system.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 4,
      "context" : "Converser [5] is a commercial doctor-patient speech-to-speech bidirectional MT system for the English↔Spanish language pair.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 12,
      "context" : "Jibbigo [13] is a travel and medical speech-to-speech MT system, deployed as an iPhone mobile app.",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 13,
      "context" : "S-MINDS [14] is a two-way doctors-patient MT system, which uses an inhouse “interpretation” software.",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 19,
      "context" : "Accultran [20] is an automatic translation system prototype, which features back translation to the doctor and yes/no or multiple-choice questions (MCQs) to the patient.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 16,
      "context" : "IBM MASTOR [17] is a speech-to-speech MT system for two language pairs (English-Mandarin and English-dialectal Arabic), which relies on ASR, SMT, and Speech Synthesis components.",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 36,
      "context" : "English-Portugese SLT [37] is an English-Portuguese speech-to-speech MT system, composed of an ASR, MT (relying on HMM) and speech synthesis.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 11,
      "context" : "It is a Cross-Lingual Information Retrieval (CLIR) task divided into two sub-tasks: (i) translation of user search queries, and (ii) translation of summaries of retrieved documents: A system described in [12], part of the Khresmoi project, uses the phrasebased Moses and standard methods for domain adaptation.",
      "startOffset" : 204,
      "endOffset" : 208
    }, {
      "referenceID" : 24,
      "context" : "[25] also uses the phrase-basedMoses system and achieved the highest BLEU score for the EnglishGerman intrinsic query translation evaluation.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 25,
      "context" : "Another system [26] combined web-crawled in-domain monolingual data and a bilingual lexicon in order to complement the limited in-domain parallel corpora.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 33,
      "context" : "A third one [34] proposed a terminology translation system for the query translation subtask and used 6 different methods for terminology extraction.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 34,
      "context" : "A fourth system [35] used a combination of n-gram based NCODE and phrase-based Moses to the subtask of sentence translation.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 39,
      "context" : "The system of [40] applied a combination of domain adaptation techniques on the medical summary sentence translation task and achieved the first and the second best BLEU scores.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 43,
      "context" : "Then, the system of [44] used the Moses phrase-based system and worked on the medical summary WMT’14 task and experimented with translation models, re-ordering models, operation sequence models, and language models, as well as with data selection.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 26,
      "context" : "A study on quality analysis of machine translation systems in medical domain was carried in [27].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 23,
      "context" : "As the main problem of low resource languages is data collection [24,30], we have adopted a variety of approaches, in order to collect as much parallel EnglishHindi data as possible.",
      "startOffset" : 65,
      "endOffset" : 72
    }, {
      "referenceID" : 29,
      "context" : "As the main problem of low resource languages is data collection [24,30], we have adopted a variety of approaches, in order to collect as much parallel EnglishHindi data as possible.",
      "startOffset" : 65,
      "endOffset" : 72
    }, {
      "referenceID" : 31,
      "context" : "We extracted medical terms from BabelNet [32] using their API.",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 35,
      "context" : "We made use of the Urdu-English segment of the Indic multi-parallel corpus [36], which contains about 87,000 sentence pairs.",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 0,
      "context" : "Initially, we trained an Urdu-to-Hindi SMT system using the tiny EMILLE corpus [1].",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 1,
      "context" : "We built two phrase translation tables p(ūi|ēi) and p(ēi|h̄i), from Urdu-English (Indic corpus) and Hindi-English (HindEnCorp [2]) bitexts.",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 38,
      "context" : "Given the phrase table for Urdu-English p(ūi|ēi) and the phrase table for English-Hindi p(ēi|h̄i), we induced an Urdu-Hindi phrase table p(ūi|h̄i) using the model [39,43]:",
      "startOffset" : 163,
      "endOffset" : 170
    }, {
      "referenceID" : 42,
      "context" : "Given the phrase table for Urdu-English p(ūi|ēi) and the phrase table for English-Hindi p(ēi|h̄i), we induced an Urdu-Hindi phrase table p(ūi|h̄i) using the model [39,43]:",
      "startOffset" : 163,
      "endOffset" : 170
    }, {
      "referenceID" : 28,
      "context" : "While it can be used to translate all 50,000 OOV words, previous research has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs [29,31,38,41,42].",
      "startOffset" : 204,
      "endOffset" : 220
    }, {
      "referenceID" : 30,
      "context" : "While it can be used to translate all 50,000 OOV words, previous research has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs [29,31,38,41,42].",
      "startOffset" : 204,
      "endOffset" : 220
    }, {
      "referenceID" : 37,
      "context" : "While it can be used to translate all 50,000 OOV words, previous research has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs [29,31,38,41,42].",
      "startOffset" : 204,
      "endOffset" : 220
    }, {
      "referenceID" : 40,
      "context" : "While it can be used to translate all 50,000 OOV words, previous research has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs [29,31,38,41,42].",
      "startOffset" : 204,
      "endOffset" : 220
    }, {
      "referenceID" : 41,
      "context" : "While it can be used to translate all 50,000 OOV words, previous research has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs [29,31,38,41,42].",
      "startOffset" : 204,
      "endOffset" : 220
    }, {
      "referenceID" : 8,
      "context" : "Following [9], we transliterate all Urdu words to Hindi and hypothesize n-best transliterations, along with regular translations.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 9,
      "context" : "We learn an unsupervised transliteration model [10] from the word-alignments of Urdu-Hindi parallel data.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 6,
      "context" : "Detailed analysis can be found in [7].",
      "startOffset" : 34,
      "endOffset" : 37
    }, {
      "referenceID" : 1,
      "context" : "1 Baseline Data We trained the Hindi-English systems using HindiEnglish parallel data [2] composed by compiling several sources including the Hindi-English segment of the Indic parallel corpus.",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 21,
      "context" : "2 Baseline System We trained a phrase-based system using Moses [22] with the following settings: a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments [33], an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [19] used at runtime, 100-best translation options, MBR decoding [23], Cube Pruning [21] using a stack size of 1,000 during tuning and 5,000 during testing.",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 32,
      "context" : "2 Baseline System We trained a phrase-based system using Moses [22] with the following settings: a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments [33], an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [19] used at runtime, 100-best translation options, MBR decoding [23], Cube Pruning [21] using a stack size of 1,000 during tuning and 5,000 during testing.",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 18,
      "context" : "2 Baseline System We trained a phrase-based system using Moses [22] with the following settings: a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments [33], an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [19] used at runtime, 100-best translation options, MBR decoding [23], Cube Pruning [21] using a stack size of 1,000 during tuning and 5,000 during testing.",
      "startOffset" : 246,
      "endOffset" : 250
    }, {
      "referenceID" : 22,
      "context" : "2 Baseline System We trained a phrase-based system using Moses [22] with the following settings: a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments [33], an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [19] used at runtime, 100-best translation options, MBR decoding [23], Cube Pruning [21] using a stack size of 1,000 during tuning and 5,000 during testing.",
      "startOffset" : 311,
      "endOffset" : 315
    }, {
      "referenceID" : 20,
      "context" : "2 Baseline System We trained a phrase-based system using Moses [22] with the following settings: a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments [33], an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [19] used at runtime, 100-best translation options, MBR decoding [23], Cube Pruning [21] using a stack size of 1,000 during tuning and 5,000 during testing.",
      "startOffset" : 330,
      "endOffset" : 334
    }, {
      "referenceID" : 3,
      "context" : "We tuned with the k-best batch MIRA [4].",
      "startOffset" : 36,
      "endOffset" : 39
    }, {
      "referenceID" : 10,
      "context" : "We additionally used msd-bidirectional-fe lexicalized reordering, a 5-gram OSM [11], class-based models [8] sparse lexical and domain features [18], a distortion limit of 6, and the no-reordering-over-punctuation heuristic.",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 7,
      "context" : "We additionally used msd-bidirectional-fe lexicalized reordering, a 5-gram OSM [11], class-based models [8] sparse lexical and domain features [18], a distortion limit of 6, and the no-reordering-over-punctuation heuristic.",
      "startOffset" : 104,
      "endOffset" : 107
    }, {
      "referenceID" : 17,
      "context" : "We additionally used msd-bidirectional-fe lexicalized reordering, a 5-gram OSM [11], class-based models [8] sparse lexical and domain features [18], a distortion limit of 6, and the no-reordering-over-punctuation heuristic.",
      "startOffset" : 143,
      "endOffset" : 147
    }, {
      "referenceID" : 9,
      "context" : "We used an unsupervised transliteration model [10] to transliterate the OOV words.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 5,
      "context" : "These are state-of-the-art settings, as used in [6].",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 27,
      "context" : "We also tried building phrase tables (+PT) separately from the baseline data and from the synthesized one and used as a separate features in the log-linear model as done in [28,29,41,42].",
      "startOffset" : 173,
      "endOffset" : 186
    }, {
      "referenceID" : 28,
      "context" : "We also tried building phrase tables (+PT) separately from the baseline data and from the synthesized one and used as a separate features in the log-linear model as done in [28,29,41,42].",
      "startOffset" : 173,
      "endOffset" : 186
    }, {
      "referenceID" : 40,
      "context" : "We also tried building phrase tables (+PT) separately from the baseline data and from the synthesized one and used as a separate features in the log-linear model as done in [28,29,41,42].",
      "startOffset" : 173,
      "endOffset" : 186
    }, {
      "referenceID" : 41,
      "context" : "We also tried building phrase tables (+PT) separately from the baseline data and from the synthesized one and used as a separate features in the log-linear model as done in [28,29,41,42].",
      "startOffset" : 173,
      "endOffset" : 186
    }, {
      "referenceID" : 15,
      "context" : "In addition to the above evaluation, we ran a small manual evaluation experiment, using the Appraise platform [16].",
      "startOffset" : 110,
      "endOffset" : 114
    } ],
    "year" : 2016,
    "abstractText" : "We present research towards bridging the language gap between migrant workers in Qatar and medical staff. In particular, we present the first steps towards the development of a real-world HindiEnglish machine translation system for doctor-patient communication. As this is a low-resource language pair, especially for speech and for the medical domain, our initial focus has been on gathering suitable training data from various sources. We applied a variety of methods ranging from fully automatic extraction from the Web to manual annotation of test data. Moreover, we developed a method for automatically augmenting the training data with synthetically generated variants, which yielded a very sizable improvement of more than 3 BLEU points absolute.",
    "creator" : "LaTeX with hyperref package"
  }
}