{
  "name" : "1206.4657.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Projection-free Online Learning",
    "authors" : [ "Elad Hazan", "Satyen Kale" ],
    "emails" : [ "ehazan@ie.technion.ac.il", "sckale@us.ibm.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Besides the computational advantage, other desirable features of our algorithms are that they are parameter-free in the stochastic case and produce sparse decisions. We apply our algorithms to computationally intensive applications of collaborative filtering, and show the theoretical improvements to be clearly visible on standard datasets."
    }, {
      "heading" : "1. Introduction",
      "text" : "In recent years the online convex optimization model has become a prominent paradigm for online learning. Within this paradigm, the Online Gradient Descent algorithm of Zinkevich (2003), and its close cousin Stochastic Gradient Descent, have been successfully applied to many problems in theory and practice.\nWhile these algorithms are usually very efficient, a computational bottleneck that limits their applicability in several applications is the projection step in the algorithm. Specifically, whenever we take a step that causes the current iterate to leave the convex domain of interest, thus leading to an infeasible point, we project the point back into the domain in order to\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nrestore feasibility. This projection step implies finding the nearest point in the domain in `2 distance, and in the general amounts to solving a convex quadratic program over the domain.\nIn many settings of practical interest, while solving convex quadratic programs is out of the question, linear optimization can be carried out efficiently. In this paper we give efficient online learning algorithms that replace the projection step with a linear optimization step for a variety of settings, as given in the following theorem:\nTheorem 1.1. There is an algorithm scheme for online convex optimization that performs one linear optimization over the convex domain per iteration, and with appropriate modifications for each setting, obtains the following regret bounds:\nStochastic Adversarial\nSmooth costs Õ( √ T ) O(T 3/4) Non-smooth costs Õ(T 2/3) O(T 3/4)\nFurthermore, in each iteration t, the algorithm maintains an explicit, efficiently sampleable distribution over at most t boundary points with expectation equal to the current iterate.\nThe above theorem entails several appealing advantages over the existing methods for online learning, as we detail below:\nComputational efficiency. In several learning domains of interest projection steps are computationally very expensive. One prominent example is online collaborative filtering, where the domain of interest is the set of all positive semidefinite matrices of bounded trace. Projecting into this set amounts to computing the singular value decomposition (SVD) of the matrix to be projected, whereas linear optimization is finding the top singular vectors, a much more efficient operation.\nParameter free. Since the basic primitive of our algorithm is linear optimization rather than gradient\nsteps and projections, our algorithms in the stochastic case are naturally parameter-free. In particular there is no parameter corresponding to the learningrate. This makes it particularly easy to implement, since no parameter tuning is necessary.\nEfficient representation and Sparsity. Another computational issue with standard projected gradient descent methods is more subtle: frequently the domain of interest is the convex hull of “integer” decision points in Euclidean space (for example, in the online shortest paths problem (Awerbuch & Kleinberg, 2008)). In such problems, points in the convex hull represent distributions over integer decision points, and to output a valid decision point we must be able to sample from such distributions. Typically, this requires being able to decompose points in the interior of the convex hull as explicit convex combinations of boundary points, and then sampling from the induced distribution. Such a decomposition may also require a lot of computational effort (for example, in the online shortest paths problem, this decomposition amounts to computing a flow decomposition in a network).\nIn contrast, our algorithm explicitly maintains a distribution over the vertices (or more generally boundary points) of the decision set, thereby eliminating the need for any further decomposition. In fact, in round t the distribution is supported on at most t boundary points, thus giving a form of sparsity."
    }, {
      "heading" : "1.1. Some Appropriate Convex Domains",
      "text" : "In several interesting online learning scenarios the underlying decision sets do not admit “practically efficient” projections. We list several interesting examples of such decision sets below.\nBounded Trace Norm Matrices. The set of matrices with bounded trace norm is a common decision set for applications such as matrix completion and collaborative filtering. For example, consider the set K of m × n matrices of trace norm bounded by some parameter τ . Computing the projection of a matrix X requires computing the SVD of X, which requires O(nm2) time in general assuming m ≤ n. Linear optimization over K amounts to computing the top singular vectors of the matrix defining the objective, which can be done much faster: typically, linear time in the number of non-zero entries in the matrix.\nFlow polytope. Given a directed acyclic graph G with n nodes and m edges with a specified source node s and a sink node t, consider the set of all paths from s to t. Any such path can be represented as a vector in Rm by its indicator vector over edges. Let K be\nthe convex hull of all such path vectors. This can be equivalently described as the set K of all unit flows from s to t, which can be represented as a polytope in Rm with O(m + n) linear inequalities. This set K arises in the online shortest paths problem (Awerbuch & Kleinberg, 2008). Computing the projection of a vector on K amounts to solving a quadratic program on this polytope, for which the most efficient algorithm known takes O(n3.5) time. Linear optimization on K is much easier: it amounts to finding the shortest path from s to t given weights on the edges, and can be done in linear time using dynamic programming.\nMatroid polytope. Given a matroid M = (E, I), where |E| = n, any independent set A ∈ I can be represented as a vector in Rn by its indicator vector. The matroid polytope K is defined to be the convex hull of all such indicator vectors of independent sets. This polytope can be defined using O(2n) linear inequalities. Computing a projection on K is therefore a difficult operation (although polynomial time, see (Nagano, 2007)). Linear optimization over K is very easy however: there is a simple greedy algorithm (see, e.g. Schrijver (2003)), amounting to sorting the coordinates of the objective vector, which solves it in O(n log(n)) time.\nRotations. Consider the set of all n×n rotation matrices. These are orthogonal matrices of determinant 1. Let K be the convex hull of all rotation matrices. This set K arises in the online learning of rotations problem (Hazan et al., 2010). Computing the projection of a matrix on K is very difficult since there is no succinct description1 of K. However, linear optimization on K is a classic problem known as Wahba’s problem (Wahba, 1965), and can be solved using one singular value decomposition. The only method of computing projections on K that we know of uses the ellipsoid method with linear optimization."
    }, {
      "heading" : "1.2. Discussion of Main Result",
      "text" : "Our main result is that assuming it is possible to do linear optimization over the convex domain efficiently, we can obtain good algorithms (in the sense of obtaining sublinear regret) for online convex optimization over the domain using an online version of the classic Frank-Wolfe algorithm (Frank & Wolfe, 1956).\nThe above statement needs clarification: Zinkevich (2003) shows (via his Online Gradient Descent algorithm) that it is possible to do online convex optimization solving one quadratic program over the domain per step. Since quadratic optimization can be\n1At least, none that we are aware of, other than (Sanyal et al., 2011) for the special case of 3 dimensions.\nreduced to a polynomial number of linear optimizations via the ellipsoid algorithm, we can therefore do online convex optimization solving a polynomial number of linear programs over the domain per step. In contrast, we show (via our Online Frank-Wolfe algorithm) that it is possible to do online convex optimization solving one linear program over the domain per step. This yields immediate computational benefits.\nAnother computational benefit comes from the fact that the algorithm automatically computes a distribution over boundary points for the iterates. In fact, if we simply want to sample from the distribution, then there is a very natural procedure for doing that: with a certain explicitly specified probability (viz. t−a, see Algorithm 1), we replace the current boundary point with a new one that is computed in the current iteration in the linear optimization. This also automatically gives a lazy versions of the algorithm, in which the chosen decision point is updated very infrequently.\nOur regret bounds are always sublinear, but not always optimal (with the exception of the stochastic, smooth case, where we obtain optimal regret bounds via our methods). Thus, theoretically we have slower convergence, in terms of number of iterations, to the optimal decision point, but the computational savings per iteration lead to a faster algorithm overall. This is validated by our experiments in Section 5."
    }, {
      "heading" : "1.3. Related Work",
      "text" : "The closest work related to ours is that of Kalai & Vempala (2005). They give an algorithm (previously considered by Hannan (1957)) for online linear optimization which performs one linear optimization over the decision set in each iteration. The striking feature of their work is they are able to show optimal O( √ T ) regret bounds even for adversarial costs, although the limitation of their work is that the algorithm specifically works only for linear cost functions. They also give lazy versions of their algorithm via a careful correlation of randomness from one iteration to the next. In comparison, our algorithm has a very natural lazy implementation (simply replace the previous decision point with a new one with an explicitly specified probability) which, in our opinion, is significantly simpler.\nOur results build upon the work of Clarkson (2010), Hazan (2008) and Jaggi (2011), who worked out the Frank-Wolfe technique for the problem of minimizing a single, static smooth convex cost function over a convex domain. We show how to extend their techniques to handle online, changing cost functions in stochastic and adversarial settings, and also show how to handle non-smooth functions."
    }, {
      "heading" : "2. Preliminaries",
      "text" : "Online convex optimization. The problem of interest is online convex optimization (see the survey of Hazan (2011) for more details). Iteratively in each round t = 1, 2, . . . , T a learner is required to produce a point xt from a convex, compact set K ⊂ Rn. In response, an adversary produces a convex cost function ft : K → R, and the learner suffers the cost ft(xt). The goal of the learner is to produce points xt so that the regret,\nRegret := ∑T t=1ft(xt)−minx∈K ∑ tft(x),\nis sublinear in T . If the cost functions are stochastic, regret is measured using the expected cost function f = E[ft] instead of the actual costs.\nWe assume that the set K diameter bounded by D and it is possible to efficiently minimize a linear function, viz. computing arg minx∈K v · x for some given vector v ∈ Rn is easy. The cost functions ft are assumed to be L-Lipchitz, i.e. for any two points x,y ∈ K, we have |ft(x)− ft(y)| ≤ L‖x− y‖. Definition 2.1. Let f : Rn 7→ R be an arbitrary convex function which is also L-lipchitz. f is called β-smooth if for all x,y ∈ K we have\nf(x + y) ≤ f(x) +∇f(x) · y + β‖y‖2.\nf is called σ-strongly convex if for all x,y ∈ K we have\nf(x + y) ≥ f(x) +∇f(x) · y + σ‖y‖2.\nNote that if f is twice differentiable, then β is upper bounded by the largest eigenvalue of the Hessian of f . The above definition together with first order optimality conditions imply that for a σ-strongly convex function f , if x∗ = arg minx∈K f(x), then\nf(x)− f(x∗) ≥ σ‖x− x∗‖2. (1)\nSmoothed functions. Let B and S denote the unit ball and unit sphere in Rn respectively. Given δ > 0, let the δ-smoothing of a function f (c.f. (Flaxman et al., 2005)) be:\nf̂δ(x) = Eu∈B[f(x + δu)],\nwhere u is chosen uniformly at random from B. We are implicitly assuming that f is defined on all points within distance δ of K. The following lemma (proof in the full version of this paper) shows that f̂δ is a good smooth approximation of f :\nLemma 2.1. If f is convex and L-Lipschitz, then the function f̂δ has the following properties:\n1. f̂δ is convex and L-Lipschitz. 2. For any x ∈ K, ∇f̂δ(x) = dδEu∈B[f(x + δu)u]. 3. For any x ∈ K, ‖∇f̂δ(x)‖ ≤ dL. 4. f̂δ is dL δ -smooth. 5. For any x ∈ K, |f(x)− f̂δ(x)| ≤ δL.\nK-Sparsity. A feature of our algorithms is that they predict with sparse solutions, where sparsity is defined in the following manner. Definition 2.2. Let K ⊆ Rn be a convex, compact set and let x ∈ K. We say that x is t-sparse w.r.t K if it can be written as a convex combination of t boundary points of K.\nAll our algorithms produce t-sparse prediction at iteration t w.r.t. the underlying decision set K."
    }, {
      "heading" : "3. Algorithm and Analysis",
      "text" : ""
    }, {
      "heading" : "3.1. Algorithm.",
      "text" : "Algorithm 1 Online Frank-Wolfe (OFW)\n1: Input parameter: constant a ≥ 0. 2: Initialize x1 arbitrarily. 3: for t = 1, 2, . . . , T do 4: Play xt and observe ft. 5: Compute Ft = 1 t ∑t τ=1fτ . 6: Compute vt ← arg minx∈K{∇Ft(xt) · x}. 7: Set xt+1 = (1− t−a)xt + t−avt. 8: end for"
    }, {
      "heading" : "3.2. Analysis.",
      "text" : "Define ∆t = Ft(xt) − Ft(x∗t ), where Ft = 1t ∑t τ=1fτ as defined in step 1 of the algorithm, and x∗t = arg minx∈K Ft(x). The regret bounds all follow from the following general theorem:\nTheorem 3.1. Assume that for t = 1, 2, . . . , T , the function ft is L-Lipschitz, Bt\n−b-smooth for some constants b ∈ [−1, 1/2] and B ≥ 0, and St−s-strongly convex for some constants s ∈ [0, 1) and S ≥ 0. Then in Algorithm 1, for all t > 1, we have\n∆t ≤ Ct−d,\nfor both the following values of C and d: (C, d) = ( max{9D2B, 3LD}, 1+b2 ) and (C, d) = ( max{9D2B, 36L2/S, 3LD}, 2+2b−s3 ) ."
    }, {
      "heading" : "In either case, this bound is obtained by setting a =",
      "text" : "d− b in Algorithm 1.\nProof. First, we note that d ≤ 1 and a ≥ 0 in either case since b ∈ [−1, 1/2] and s ∈ [0, 1), so that t−a ∈ [0, 1] and hence all iterates lie in K. We prove the lemma by induction on t for either values of C and d. The statement is true for t = 1 since f1 is L-Lipschitz, so C ≥ LD ≥ L‖x1−x∗1‖ ≥ f1(x1)− f1(x∗1) = ∆1. So assume that for some t ≥ 1, we have ∆t ≤ Ct−d. Now by convexity of Ft we have\nFt(x ∗ t ) ≥ Ft(xt) +∇Ft(xt) · (x∗t − xt)\nSince x∗t ∈ K, we have that ∇Ft(xt)·x∗t ≥ ∇Ft(xt)·vt. From both observations:\n(vt − xt) · ∇Ft(xt) ≤ (x∗t − xt) · ∇Ft(xt) ≤ Ft(x∗t )− Ft(xt) = −∆t. (2)\nSince ft is Bt −b-smooth, the smoothness of Ft is bounded by 1t ∑t τ=1Bτ\n−b ≤ 3Bt−b for b ≤ 1/2. We now have\nFt(xt+1) = Ft(xt + t −a(vt − xt))\n≤ Ft(xt) + t−a(vt − xt) · ∇Ft(xt) + 3D2Bt−b−2a\n(by 3Bt−b-smoothness)\n≤ Ft(xt)− t−a∆t + 3D2Bt−b−2a,\nusing (2). Using the inequality Ft(x ∗ t ) ≤ Ft(x∗t+1) in the bound above we get:\nFt(xt+1)− Ft(x∗t+1) ≤ (1− t−a)∆t + 3D2Bt−b−2a\n≤ (1− t−a)Ct−d + 3D2Bt−b−2a\n(By induction hypothesis)\n= Ct−d − Ctb−2d + 3D2Btb−2d\n(Since a = d− b)\n≤ Ct−d − 2 3 Ctb−2d, (3)\nsince C ≥ 9D2B. In Lemma 3.1, we show the following bound using the strong convexity of the ft functions and the parameter choices:\nft+1(xt+1)− ft+1(x∗t+1) ≤ 2\n3 Ct1+b−2d.\nMultiplying (3) by t, adding the above bound, and dividing by t+ 1, we get\nFt+1(xt+1)− Ft+1(x∗t+1) ≤ t\nt+ 1 Ct−d ≤ C(t+ 1)−d,\nsince d ≤ 1, thus completing the induction.\nLemma 3.1. In the setup of Theorem 3.1, assuming ∆t ≤ Ct−d, we have\nft+1(xt+1)− ft+1(x∗t+1) ≤ 2\n3 Ct1+b−2d.\nProof. Since ft is σt-strongly convex, the strong convexity of Ft is at least\n1\nt\n∑t τ=1στ = 1\nt\n∑t τ=1Sτ −s ≥ St−s,\nsince τ−s ≥ t−s for all τ ≤ t. Thus, since x∗t = arg minx∈K Ft(x), we have by (1):\nCt−d ≥ ∆t = Ft(xt)− Ft(x∗t ) ≥ St−s‖xt − x∗t ‖2,\nwhich implies that ‖xt − x∗t ‖ ≤ √ C/Sts/2−d/2. By a similar argument, since by a simple calculation (details in the full version of this paper) we have Ft+1(x ∗ t ) − Ft+1(x ∗ t+1) ≤ LDt+1 , we conclude that\n‖x∗t − x∗t+1‖ ≤ √ (LD/S)(t+ 1)s−1 ≤ √ C/Sts/2−d/2,\nsince C ≥ 3LD, s < 1 and d ≤ 1. Thus, using the triangle inequality and the trivial bound ‖xt−x∗t+1‖ ≤ D, we get ‖xt − x∗t+1‖ ≤ min{2 √\n(C/S)ts/2−d/2, D} ≤ C 3L t1+b−2d,\nsince C ≥ 36L2/S if d = 2+2b−s3 , and C ≥ 3LD if d = 1+b2 . Furthermore, we have\n‖xt+1 − xt‖ = t−a‖vt − xt‖\n≤ Dt−a = Dtb−d ≤ C 3L t1+b−2d,\nsince C ≥ 3LD and d ≤ 1. So by triangle inequality, we have\n‖xt+1 − x∗t ‖ ≤ 2C\n3L t1+b−2d.\nSince ft+1 is L-Lipschitz, we get the required bound."
    }, {
      "heading" : "4. Regret Bounds",
      "text" : ""
    }, {
      "heading" : "4.1. Stochastic Costs",
      "text" : "Assume now that the cost functions ft are sampled i.i.d. from some unknown distribution, and let f∗ = E[ft], and let x ∗ = arg minx∈K f ∗(x)."
    }, {
      "heading" : "4.1.1. Smooth Stochastic Costs",
      "text" : "Theorem 4.1. For β-smooth stochastic convex loss functions ft, there is an algorithm such that with probability at least 1− δ, its regret is bounded as follows :∑T\nt=1f ∗(xt)− f∗(x∗) = O((D2β + LD) √ nT log(nT/δ) log(T )).\nProof. For β-smooth stochastic convex loss functions ft, the algorithm is OFW applied to the functions ft with parameter settings that we specify now. First, ft is β-smooth, so we can set B = β and b = 0. Since we make no assumptions about the strong convexity of ft, so we can set S = 0, and s = 0. For these settings, the optimal values of the parameters are d = 1+b2 = 1/2, a = d − b = 1/2, and C = max{9D2β, 3LD}. Thus, for all t, we have:\nFt(xt)− Ft(x∗t ) ≤ C/ √ t.\nThis implies that for the optimal point x∗ we have\nFt(xt)− Ft(x∗) ≤ C/ √ t. (4)\nIn (Shalev-Shwartz et al., 2009), Theorem 5, the following is proved:\nTheorem 4.2. With probability at least 1−δ, for any x ∈ K and for all t = 1, 2, . . . , T we have\n|Ft(x)− f∗(x)| ≤ LD √ n log(n/δ) log(t)/t.\nUsing this theorem and (4), we conclude that with proability at least 1− δ, we have f∗(xt)− f∗(x∗) ≤ C/ √ t+ 2LD √ n log(nt/δ) log(t)/t.\nSumming up from t = 1 to T , we get that the regret is O(C √ nT log(nT/δ) log(T )) with probability at least 1− δ."
    }, {
      "heading" : "4.1.2. Non-smooth Stochastic Costs",
      "text" : "Theorem 4.3. For non-smooth stochastic convex loss functions ft, there is an algorithm such with probability at least 1− δ, its regret is bounded as follows:∑T\nt=1f ∗(xt)− f∗(x∗) =\nO( √ nLDT 2/3 + LD √ nT log(nT/δ) log(T )).\nProof. For non-smooth stochastic convex loss functions ft, the algorithm is OFW applied to the δtsmoothing of ft, i.e. the functions f̂t,δt for δt =√ nDt−1/3. The function f̂t,δt is nL δt = ( √ nL/D)t1/3\nsmooth, so B = √ nL/D and b = −1/3. Since we make\nno assumptions about the strong convexity of f̂t,δt , so we can set S = 0, and s = 0. For these settings, the optimal values of the parameters are d = 1+b2 = 1/3, a = d − b = 2/3 and C = max{9 √ nLD, 3LD} = 9 √ nLD. Thus for all t, we have:\nF̂t(xt)− F̂t(x∗t ) ≤ 9 √ nLDt−1/3,\nwhere F̂t(x) = 1 t ∑t τ=1f̂τ,δτ (x). Thus, for the optimal point x∗, we have\nF̂t(xt)− F̂t(x∗) ≤ 9 √ nLDt−1/3.\nSince |f̂t(x)− ft(x)| ≤ δtL = √ nLDt−1/3, we have\n|F̂t(x)−Ft(x)| ≤ 1\nt\n∑t τ=1 √ nLDτ−1/3 ≤ 3 √ nLDt−1/3.\nUsing the above two bounds we get that\nFt(xt)− Ft(x∗) ≤ 15 √ nLDt−1/3.\nFrom this point, arguing as in the proof of Theorem 4.1, we conclude that the regret is O( √ nLDT 2/3+ LD √ nT log(nT/δ) log(T )) with probability at least 1− δ."
    }, {
      "heading" : "4.2. Adversarial Cost Functions",
      "text" : "Theorem 4.4. For adversarial cost functions ft (smooth or non-smooth), there is an algorithm that has the following regret bound. For any x∗ ∈ K we have: ∑T\nt=1ft(xt)− ft(x ∗) ≤ 57LDT 3/4.\nProof. We apply the OFW algorithm to the functions f̂t defined as follows. Suppose the algorithm plays point xt in round t, and the adversary provides the cost function ft. Define\nf̂t(x) = ∇ft(xt) · x + σt‖x− x1‖2,\nwhere σt = (L/D)t −1/4 and ∇ft(xt) is a subgradient of ft at xt such that ‖∇ft(xt)‖ ≤ L.\nWe now estimate the Lipschitz, smoothness, and strong convexity parameters for f̂t. First, ∇f̂t(x) = ∇ft(xt)+(2L/D)t−1/4(x−x1). Since ft is L-Lipschitz, ‖∇ft(xt)‖ ≤ L, and ‖x − x1‖ ≤ D, impying that ‖∇f̂t(x)‖ ≤ 3L, which implies that f̂t is 3L-Lipschitz. Next, note that\nf̂t(x + y)− f̂t(x) = ∇ft(xt) · y + 2σt(x− x1) · y + σt‖y‖2\n= ∇f̂t(x) · y + σt‖y‖2.\nThus f̂t is (L/D)t −1/4-smooth, so we set B = L/D and b = 1/4. Also it is (L/D)t−1/4-strongly convex, so we set S = L/D and s = 1/4. For these settings, the optimal values of the parameters are d = 2+2b−s3 = 3/4, a = d−b = 1/4 and C = max{9D2B, 36L2/S, 3LD} = 36LD. Thus by Theorem 3.1, for all t, we have:\n∆t = F̂t(xt)− F̂t(x∗t ) ≤ 36LDt−3/4, (5)\nwhere F̂t(x) = 1 t ∑t τ=1f̂τ (x), x ∗ t = arg minx∈K F̂t(x).\nKalai & Vempala (2005) prove that the “Be-TheLeader” algorithm has no regret. In particular, since the x∗t = arg minx∈K 1 t ∑t τ=1f̂τ (x), we have, for any x∗ ∈ K, ∑T t=1f̂t(x ∗ t ) ≤ ∑T t=1f̂t(x ∗). (6)\nBy strong convexity and since x∗t = arg minx∈K F̂t(x), we have\nF̂t(xt)− F̂t(x∗t ) ≥ σt‖xt − x∗t ‖2.\nThis implies that ‖xt − x∗t ‖ ≤ √ ∆t/σt ≤ 6Dt−1/4,\nusing (5). Next, since f̂t is 3L-Lipschitz we get\n∀t : f̂t(xt) ≤ f̂t(x∗t ) + 18LDt−1/4.\nSumming up from t = 1 to T , using the bound∑T t=1t\n−1/4 ≤ 3T 3/4 and (6), we get that∑T t=1f̂t(xt)− f̂t(x ∗) ≤ 54LDT 3/4,\nwhich implies that∑T t=1∇ft(xt) · (xt − x ∗)\n≤ 54LDT 3/4 + ∑T t=1σt‖x\n∗ − x1‖2 ≤ 57LDT 3/4, (7)\nsince ∑T t=1σt = ∑T t=1t\n−1/4 ≤ 3T 3/4 and ‖x∗−x1‖2 ≤ D2. By convexity of ft, we have\nft(xt)− ft(x∗) ≤ ∇ft(xt) · (xt − x∗).\nPlugging this into (7), we get the stated bound."
    }, {
      "heading" : "5. Experiments",
      "text" : "To evaluate the performance benefits of OFW over OGD, we experimented with a simple test application, viz. online collaborative filtering. This problem is the following. In each round, the learner is required to produce an m × n matrix X with trace norm (i.e. sum of singular values) bounded by τ , a parameter. This matrix is to be interpreted as supplying by users i ∈ [m] rating for each item j ∈ [n]. The adversary then chooses an entry (i, j) and reveals the true rating for it, viz. y ∈ R. The learner suffers the squared loss (X(i, j) − y)2. The goal is to compete with the set of all m × n matrices of trace norm bounded by τ . The offline version of this problem has been extensively studied in recent times, see e.g. Candes & Recht (2009), Jaggi & Sulovský (2010), Srebro et al. (2010),\nLee et al. (2010), Salakhutdinov & Srebro (2010) and Shamir & Shalev-Shwartz (2011).\nAs mentioned previously, OGD requires computing the SVD of the matrix in each iteration, an O(nm2) time operation (assuming m ≤ n), whereas OFW requires computing the top singular vector pair, an operation that in practice runs in near-linear time in the number of non-zero entries of the matrix.\nDatasets. We used two publicly available datasets:\n1. MovieLens100K (GroupLens): 100000 ratings in {1, 2, 3, 4, 5} by 943 users on 1682 movies. 2. Jester1 (Goldberg et al., 2001): first 100000 ratings in [−10, 10] by 24983 users on 100 jokes.\nFor simplicity, the sequence of entries (i, j) chosen by the adversary is the same as the original sequence in these datasets. We also experimented with a 1000 × 1000 randomly generated matrix.\nImplementation. We implemented the smooth, stochastic version of the OFW algorithm, even though the cost functions are not necessarily stochastic, mainly because of its faster convergence rate (in case of stochastic costs) and ease of implementation being parameter-free. We implemented the OGD and OFW algorithms in the most straightforward fashion in MATLAB, using the sparse matrices whenever possible, and the svd function for OGD and the svds function for OFW with a tolerance of 10−5. The running\ntimes were obtained on an 2.33GHz Intel R© Xeon R© CPU. All experiments were run in MATLAB in singlethreaded mode using the -singleCompThread option. To ensure that the OFW and OGD runs completed in a reasonable amount of time (a few hours), we ran 100000 OFW iterations for both datasets, and only the first 10000 and 20000 OGD iterations for MovieLens100K and Jester1 respectively. The trace norm bounds used were 5000 and 200 respectively with no tuning.\nResults. Figure 1 shows the results of our experiments. It can be clearly seen from the left plots that OFW is significantly faster than OGD, completing all its 100000 iterations much before the far fewer OGD iterations. Not only is it faster per iteration, surprisingly given that the costs are not stochastic, OFW also reduces the average squared loss faster than OGD, as can be seen from the middle plots. The right plots show that OFW is consistently around 35 times faster than OGD for the MovieLens100K dataset and around 6 times faster for the Jester1 dataset, and in fact this ratio keeps increasing as the number of iterations increases and the matrix parameter becomes more and more dense. This is reasonable since computing the SVD of a dense matrix requires much more effort than for a sparser matrix. The reason OGD is only about 6 times faster than OFW for Jester1 is because the matrix involved is tall-and-skinny, hav-\ning only 100 columns, thus making the svd function almost as fast as the svds function. In our experiments with 1000× 1000 randomly generated matrices we found that OFW was as much as 150 times faster than OGD."
    }, {
      "heading" : "6. Conclusions and Open Problems",
      "text" : "In this paper, we gave an efficient algorithmic scheme for online convex optimization that performs one linear optimization per iteration rather than one quadratic optimization. The advantages over traditional gradient-descent techniques are speed of implementation, parameter-independence, explicit sampling scheme for iterates, sparsity, and natural lazy implementation. The disadvantage is that the provable regret bounds are not always optimal. The major open problem left is to improve the regret bounds, or show lower bounds on the number of linear optimizations necessary to obtain optimal regret with only one linear-optimization operation per iteration."
    } ],
    "references" : [ {
      "title" : "Online linear optimization and adaptive routing",
      "author" : [ "B. Awerbuch", "R.D. Kleinberg" ],
      "venue" : "J. Comput. Syst. Sci.,",
      "citeRegEx" : "Awerbuch and Kleinberg,? \\Q2008\\E",
      "shortCiteRegEx" : "Awerbuch and Kleinberg",
      "year" : 2008
    }, {
      "title" : "Exact matrix completion via convex optimization",
      "author" : [ "E. Candes", "B. Recht" ],
      "venue" : "Foundations of Computational Mathematics,",
      "citeRegEx" : "Candes and Recht,? \\Q2009\\E",
      "shortCiteRegEx" : "Candes and Recht",
      "year" : 2009
    }, {
      "title" : "Coresets, sparse greedy approximation, and the Frank-Wolfe algorithm",
      "author" : [ "K.L. Clarkson" ],
      "venue" : "ACM Trans. Algorithms,",
      "citeRegEx" : "Clarkson,? \\Q2010\\E",
      "shortCiteRegEx" : "Clarkson",
      "year" : 2010
    }, {
      "title" : "Online convex optimization in the bandit setting: gradient descent without a gradient",
      "author" : [ "A. Flaxman", "A.T. Kalai", "H.B. McMahan" ],
      "venue" : "In SODA,",
      "citeRegEx" : "Flaxman et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Flaxman et al\\.",
      "year" : 2005
    }, {
      "title" : "An algorithm for quadratic programming",
      "author" : [ "M. Frank", "P. Wolfe" ],
      "venue" : "Naval Research Logistics Quarterly,",
      "citeRegEx" : "Frank and Wolfe,? \\Q1956\\E",
      "shortCiteRegEx" : "Frank and Wolfe",
      "year" : 1956
    }, {
      "title" : "Eigentaste: A constant time collaborative filtering algorithm",
      "author" : [ "K.Y. Goldberg", "T. Roeder", "D. Gupta", "C. Perkins" ],
      "venue" : "Inf. Retr.,",
      "citeRegEx" : "Goldberg et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Goldberg et al\\.",
      "year" : 2001
    }, {
      "title" : "Approximation to bayes risk in repeated play",
      "author" : [ "J. Hannan" ],
      "venue" : "Contributions to the Theory of Games, III: 97–139,",
      "citeRegEx" : "Hannan,? \\Q1957\\E",
      "shortCiteRegEx" : "Hannan",
      "year" : 1957
    }, {
      "title" : "Sparse approximate solutions to semidefinite programs",
      "author" : [ "E. Hazan" ],
      "venue" : "In LATIN, pp",
      "citeRegEx" : "Hazan,? \\Q2008\\E",
      "shortCiteRegEx" : "Hazan",
      "year" : 2008
    }, {
      "title" : "The convex optimization approach to regret minimization",
      "author" : [ "E. Hazan" ],
      "venue" : "Optimization for machine learning,",
      "citeRegEx" : "Hazan,? \\Q2011\\E",
      "shortCiteRegEx" : "Hazan",
      "year" : 2011
    }, {
      "title" : "Learning rotations with little regret",
      "author" : [ "E. Hazan", "S. Kale", "M.K. Warmuth" ],
      "venue" : "In COLT, pp",
      "citeRegEx" : "Hazan et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Hazan et al\\.",
      "year" : 2010
    }, {
      "title" : "Convex optimization without projection",
      "author" : [ "M. Jaggi" ],
      "venue" : "steps. CoRR,",
      "citeRegEx" : "Jaggi,? \\Q2011\\E",
      "shortCiteRegEx" : "Jaggi",
      "year" : 2011
    }, {
      "title" : "A simple algorithm for nuclear norm regularized problems",
      "author" : [ "M. Jaggi", "M. Sulovský" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Jaggi and Sulovský,? \\Q2010\\E",
      "shortCiteRegEx" : "Jaggi and Sulovský",
      "year" : 2010
    }, {
      "title" : "Efficient algorithms for online decision problems",
      "author" : [ "A. Kalai", "S. Vempala" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Kalai and Vempala,? \\Q2005\\E",
      "shortCiteRegEx" : "Kalai and Vempala",
      "year" : 2005
    }, {
      "title" : "Practical large-scale optimization for max-norm regularization",
      "author" : [ "J. Lee", "B. Recht", "R. Salakhutdinov", "N. Srebro", "J.A. Tropp" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Lee et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2010
    }, {
      "title" : "Faster parametric submodular function minimization algorithm and applications",
      "author" : [ "K. Nagano" ],
      "venue" : "Mathematical Engineering Technical Reports,",
      "citeRegEx" : "Nagano,? \\Q2007\\E",
      "shortCiteRegEx" : "Nagano",
      "year" : 2007
    }, {
      "title" : "Collaborative filtering in a non-uniform world: Learning with the weighted trace norm",
      "author" : [ "R. Salakhutdinov", "N. Srebro" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Salakhutdinov and Srebro,? \\Q2010\\E",
      "shortCiteRegEx" : "Salakhutdinov and Srebro",
      "year" : 2010
    }, {
      "title" : "Stochastic convex optimization",
      "author" : [ "S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridharan" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2009
    }, {
      "title" : "Collaborative filtering with the trace norm: Learning, bounding, and transducing",
      "author" : [ "O. Shamir", "S. Shalev-Shwartz" ],
      "venue" : "JMLR - Proceedings Track,",
      "citeRegEx" : "Shamir and Shalev.Shwartz,? \\Q2011\\E",
      "shortCiteRegEx" : "Shamir and Shalev.Shwartz",
      "year" : 2011
    }, {
      "title" : "Smoothness, low noise and fast rates",
      "author" : [ "N. Srebro", "K. Sridharan", "A. Tewari" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Srebro et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Srebro et al\\.",
      "year" : 2010
    }, {
      "title" : "Problem 65-1, a least squares estimate of satellite attitude",
      "author" : [ "G. Wahba" ],
      "venue" : "SIAM Review,",
      "citeRegEx" : "Wahba,? \\Q1965\\E",
      "shortCiteRegEx" : "Wahba",
      "year" : 1965
    }, {
      "title" : "Online convex programming and generalized infinitesimal gradient ascent",
      "author" : [ "M. Zinkevich" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Zinkevich,? \\Q2003\\E",
      "shortCiteRegEx" : "Zinkevich",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 20,
      "context" : "Within this paradigm, the Online Gradient Descent algorithm of Zinkevich (2003), and its close cousin Stochastic Gradient Descent, have been successfully applied to many problems in theory and practice.",
      "startOffset" : 63,
      "endOffset" : 80
    }, {
      "referenceID" : 14,
      "context" : "Computing a projection on K is therefore a difficult operation (although polynomial time, see (Nagano, 2007)).",
      "startOffset" : 94,
      "endOffset" : 108
    }, {
      "referenceID" : 9,
      "context" : "This set K arises in the online learning of rotations problem (Hazan et al., 2010).",
      "startOffset" : 62,
      "endOffset" : 82
    }, {
      "referenceID" : 19,
      "context" : "However, linear optimization on K is a classic problem known as Wahba’s problem (Wahba, 1965), and can be solved using one singular value decomposition.",
      "startOffset" : 80,
      "endOffset" : 93
    }, {
      "referenceID" : 11,
      "context" : "Computing a projection on K is therefore a difficult operation (although polynomial time, see (Nagano, 2007)). Linear optimization over K is very easy however: there is a simple greedy algorithm (see, e.g. Schrijver (2003)), amounting to sorting the coordinates of the objective vector, which solves it in O(n log(n)) time.",
      "startOffset" : 95,
      "endOffset" : 223
    }, {
      "referenceID" : 20,
      "context" : "The above statement needs clarification: Zinkevich (2003) shows (via his Online Gradient Descent algorithm) that it is possible to do online convex optimization solving one quadratic program over the domain per step.",
      "startOffset" : 41,
      "endOffset" : 58
    }, {
      "referenceID" : 6,
      "context" : "They give an algorithm (previously considered by Hannan (1957)) for online linear optimization which performs one linear optimization over the decision set in each iteration.",
      "startOffset" : 49,
      "endOffset" : 63
    }, {
      "referenceID" : 2,
      "context" : "Our results build upon the work of Clarkson (2010), Hazan (2008) and Jaggi (2011), who worked out the Frank-Wolfe technique for the problem of minimizing a single, static smooth convex cost function over a convex domain.",
      "startOffset" : 35,
      "endOffset" : 51
    }, {
      "referenceID" : 2,
      "context" : "Our results build upon the work of Clarkson (2010), Hazan (2008) and Jaggi (2011), who worked out the Frank-Wolfe technique for the problem of minimizing a single, static smooth convex cost function over a convex domain.",
      "startOffset" : 35,
      "endOffset" : 65
    }, {
      "referenceID" : 2,
      "context" : "Our results build upon the work of Clarkson (2010), Hazan (2008) and Jaggi (2011), who worked out the Frank-Wolfe technique for the problem of minimizing a single, static smooth convex cost function over a convex domain.",
      "startOffset" : 35,
      "endOffset" : 82
    }, {
      "referenceID" : 7,
      "context" : "The problem of interest is online convex optimization (see the survey of Hazan (2011) for more details).",
      "startOffset" : 73,
      "endOffset" : 86
    }, {
      "referenceID" : 3,
      "context" : "(Flaxman et al., 2005)) be:",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 16,
      "context" : "In (Shalev-Shwartz et al., 2009), Theorem 5, the following is proved:",
      "startOffset" : 3,
      "endOffset" : 32
    }, {
      "referenceID" : 10,
      "context" : "Candes & Recht (2009), Jaggi & Sulovský (2010), Srebro et al.",
      "startOffset" : 23,
      "endOffset" : 47
    }, {
      "referenceID" : 10,
      "context" : "Candes & Recht (2009), Jaggi & Sulovský (2010), Srebro et al. (2010),",
      "startOffset" : 23,
      "endOffset" : 69
    }, {
      "referenceID" : 5,
      "context" : "Jester1 (Goldberg et al., 2001): first 100000 ratings in [−10, 10] by 24983 users on 100 jokes.",
      "startOffset" : 8,
      "endOffset" : 31
    } ],
    "year" : 2012,
    "abstractText" : "The computational bottleneck in applying online learning to massive data sets is usually the projection step. We present efficient online learning algorithms that eschew projections in favor of much more efficient linear optimization steps using the Frank-Wolfe technique. We obtain a range of regret bounds for online convex optimization, with better bounds for specific cases such as stochastic online smooth convex optimization. Besides the computational advantage, other desirable features of our algorithms are that they are parameter-free in the stochastic case and produce sparse decisions. We apply our algorithms to computationally intensive applications of collaborative filtering, and show the theoretical improvements to be clearly visible on standard datasets.",
    "creator" : "LaTeX with hyperref package"
  }
}