{
  "name" : "1302.1533.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Model Reduction Techniques for Computing Approximately Optimal Solutions for Markov Decision Processes",
    "authors" : [ "Thomas Dean", "Robert Givan", "Sonia Leach" ],
    "emails" : [ "sml]@cs.brown.edu" ],
    "sections" : null,
    "references" : [ {
      "title" : "D",
      "author" : [ "D.P. Bertsekas", "Castanon" ],
      "venue" : "A.",
      "citeRegEx" : "Bertsekas and Castanon. 1989",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "Minimal state graph generation",
      "author" : [ "Bouajjani et al", "1992] Bouajjani", "J.­ C. Fernandez", "N. Halbwachs", "P. Raymond", "C. Rate" ],
      "venue" : "Science of Computer Programming",
      "citeRegEx" : "A. et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "A. et al\\.",
      "year" : 1992
    }, {
      "title" : "Craig and Dearden",
      "author" : [ "Boutilier" ],
      "venue" : "Richard",
      "citeRegEx" : "Boutilier and Dearden. 1994",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Planning under uncertainty: Structural as­ sumptions and computational leverage",
      "author" : [ "Boutilier et al", "1995a] Boutilier", "Craig", "Thomas Dean", "Steve Hanks" ],
      "venue" : "In Proceed­ ings of the Third European Workshop on Planning",
      "citeRegEx" : "Craig et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Craig et al\\.",
      "year" : 1995
    }, {
      "title" : "Exploit­ ing structure in policy construction",
      "author" : [ "Boutilier et al", "1995b] Boutilier", "Craig", "Richard Dearden", "Moises Goldszmidt" ],
      "venue" : "In Proceedings IJCAI",
      "citeRegEx" : "Craig et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Craig et al\\.",
      "year" : 1995
    }, {
      "title" : "David; McMillan",
      "author" : [ "Jerry Burch", "Edmund M. Clarke", "Long" ],
      "venue" : "Kenneth L.; and Dill, David L.",
      "citeRegEx" : "Burch et al.. 1994",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Thomas and Givan",
      "author" : [ "Dean" ],
      "venue" : "Robert",
      "citeRegEx" : "Dean and Givan. 1997",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Thomas and Kanazawa",
      "author" : [ "Dean" ],
      "venue" : "Keiji",
      "citeRegEx" : "Dean and Kanazawa. 1989",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "Sonia; and Dean",
      "author" : [ "Givan, Robert", "Leach" ],
      "venue" : "Thomas",
      "citeRegEx" : "Givan et al.. 1997",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "J",
      "author" : [ "J.G. Kemeny", "Snell" ],
      "venue" : "L.",
      "citeRegEx" : "Kemeny and Snell. 1960",
      "shortCiteRegEx" : null,
      "year" : 1960
    }, {
      "title" : "Steve; and Weld",
      "author" : [ "Kushmerick, Nicholas", "Hanks" ],
      "venue" : "Daniel",
      "citeRegEx" : "Kushmerick et al.. 1995",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Online minimization of tran­",
      "author" : [ "nakakis", "Mihalis" ],
      "venue" : null,
      "citeRegEx" : "nakakis and Mihalis,? \\Q1992\\E",
      "shortCiteRegEx" : "nakakis and Mihalis",
      "year" : 1992
    }, {
      "title" : "Iter­ ative aggregation-disaggregation procedures for dis­ counted semi-Markov reward processes. Operations Research 33(3):589-605",
      "author" : [ "Schweitzer et al", "1985] Schweitzer", "Paul J", "Martin L. Puter­ man", "Kyle W. Kindle" ],
      "venue" : null,
      "citeRegEx" : "J. et al\\.,? \\Q1985\\E",
      "shortCiteRegEx" : "J. et al\\.",
      "year" : 1985
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "cesses has its origins in automata theory [Hartmanis and Stearns, 1966] and stochastic processes [Kemeny and Snell, 1960] and has surfaced more recently in the work on model checkin� in computer-aided verifica­ tion [Burch et al.",
      "startOffset" : 97,
      "endOffset" : 121
    }, {
      "referenceID" : 6,
      "context" : "Building on the work of Lee and Yannakakis [ 1992], we have shown [Dean and Givan, 1997] that several existing algorithms are asymptotically equivalent to first constructing the minimal reduced MDP and then solving this MDP using traditional methods that op­ erate on the flat (unfactored) representations.",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 8,
      "context" : "Although BMOPs are introduced here to represent approximate aggre­ gations, they are interesting in their own right and are discussed in more detail in [Givan et al., 1997], The model reduction algorithms and bounded parameter MDP solution methods can be combined to find ap­ proximately optimal solutions to large factored MOPs, varying E to trade time and space for solution quality.",
      "startOffset" : 152,
      "endOffset" : 172
    }, {
      "referenceID" : 8,
      "context" : "We will write of bounding the (optimal or policy specific) value of a state in a BMDP-by this we mean providing an up­ per or lower bound on the corresponding state value over the entire family of MDPs :F M· For a more thor­ ough treatment of BMDPs, please see [Givan et al., 1997].",
      "startOffset" : 261,
      "endOffset" : 281
    }, {
      "referenceID" : 10,
      "context" : "Factored Representations In the remainder of this paper, we make use of Bayesian networks [Pearl, 1988] to encode implicit (or factored) representa­ tions; however, our methods apply to other factored representations such as probabilistic STRIPS opera­ tors [Kushmerick et al., 1995].",
      "startOffset" : 258,
      "endOffset" : 283
    }, {
      "referenceID" : 7,
      "context" : "[Dean and Kanazawa, 1989] The state-transition probabilities are now factored as",
      "startOffset" : 0,
      "endOffset" : 25
    }, {
      "referenceID" : 8,
      "context" : "Bounded parameter MDPs are interesting objects and we explore them at greater length in [Givan et al., 1997].",
      "startOffset" : 88,
      "endOffset" : 108
    } ],
    "year" : 2011,
    "abstractText" : "We present a method for solving implicit (factored) Markov decision processes (MDPs) with very large state spaces. We intro­ duce a property of state space partitions which we call f-homogeneity. Intuitively, an f-homogeneous partition groups together states that behave approximately the same under all or some subset of policies. Borrow­ ing from recent work on model minimization in computer-aided software verification, we present an algorithm that takes a factored representation of an MDP and an 0 � f � I and computes a factored f-homogeneous par­ tition of the state space. This partition defines a family of related MOPs-those MOP's with state space equal to the blocks of the partition, and transition probabilities \"appro:X:imately\" like those of any (original MDP) state in the source block. To formally study such families of MDPs, we introduce the new notion of a \"bounded parameter MDP\" (BMDP), which is a fam­ ily of (traditional) MOPs defined by speci­ fying upper and lower bounds on the transi­ tion probabilities and rewards. We describe algorithms that operate on BMDPs to find policies that are approximately optimal with respect to the original MDP. In combination, our method for reducing a large implicit MDP to a possibly much smaller BMDP using an f-homogeneous par­ tition, and our methods for selecting actions in BMDP's constitute a new approach for an­ alyzing large implicit MOP's. Among its ad­ vantages, this new approach provides insight into existing algorithms to solving implicit MDPs, provides useful connections to work in automata theory and model minimization, and suggests methods, which involve vary­ ing f, to trade time and space (specifically in terms of the size of the corresponding state space) for solution quality.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}