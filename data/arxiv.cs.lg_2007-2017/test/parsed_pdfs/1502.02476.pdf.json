{
  "name" : "1502.02476.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "An Infinite Restricted Boltzmann Machine",
    "authors" : [ "Marc-Alexandre Côté", "Hugo Larochelle" ],
    "emails" : [ "MARC-ALEXANDRE.COTE@USHERBROOKE.CA", "HUGO.LAROCHELLE@USHERBROOKE.CA" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Over the years, machine learning research has produced a large variety of latent variable probabilistic models, analysing and modelling data of various kind. These include mixture models, factor analysis models, latent dynamical models, and many others. Such models usually require that the dimensionality of the latent representation be specified and fixed during learning. Adapting this quantity to data is then considered as a separate process, that takes the form of model selection and is normally treated as an additional hyper-parameter to tune.\nFor this reason, more recently, there has been a lot of work on extending these models such that the dimensionality of the latent space can be treated as an adaptive quantity during training. These extensions, often referred to as ”infinite” models, are non-parametric in nature and can arbitrarily adapt their capacity to the training data (see Orbanz & Teh (2010) for a brief overview).\nProceedings of the 31 st International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).\nWhile most latent variable models have been extended to one or more infinite variants, a notable exception is the restricted Boltzmann machine (RBM). The RBM is an undirected graphical model for binary vector observations, where the latent representation is itself a binary vector (often referred to as a hidden layer). The RBM (and its extensions to non-binary vectors) have been successfully applied to a large variety of problems and data, such as images (Ranzato et al., 2010), movie user preferences (Salakhutdinov et al., 2007), motion capture data (Taylor et al., 2011), text data (Dahl et al., 2012) and many others. One explanation for the lack of literature on RBMs with an adaptive hidden layer size comes from its undirected nature. Indeed, undirected models tend to be less amenable to a Bayesian treatment of learning, on which relies the vast majority of the literature on infinite models.\nOur main contribution in this paper is thus a proposal for an infinite RBM. While our proposal is not based on a Bayesian formulation, it does correspond to the infinite limit of a finite-sized model and behaves in such a way that it effectively adapts its capacity as training progresses.\nFirst, we propose a finite extension of the RBM that is sentitive to the position of each unit in its hidden layer. This is achieved by introducing a random variable that represents the number of hidden units intervening in the RBM’s energy function. Then, thanks to the introduction of an energy cost for using each additional unit, we show that taking the infinite limit of the total number of hidden units is well defined. We describe an approximate maximum likelihood training algorithm for this infinite RBM, based on (Persistent) Contrastive Divergence, which results in a procedure where hidden units are implicitly added as training progresses. Finally, we empirically report how this model behaves in practice and show that it can achieve performance that is competitive to a traditional RBM on the binarized MNIST and Caltech101 Silhouettes datasets. ar X\niv :1\n50 2.\n02 47\n6v 1\n[ cs\n.L G\n] 9\nF eb\n2 01\n5"
    }, {
      "heading" : "2. Restricted Boltzmann Machine",
      "text" : "We start by describing the basic RBM model, which we will build on to derive its ordered and infinite versions.\nAn RBM is a generative stochastic neural network composed of two layers: a visible layer v and a hidden layer h. The two layers are fully connected to each other, while connections within a layer are not allowed. This means each visible unit is connected to all hidden units via undirected weighted connections (Figure 2).\nGiven a binary RBM with D visible units and K hidden units, the set of visible vectors is V = {0, 1}D, whereas the set of hidden vectors is H = {0, 1}K . In an RBM model, each configuration (v,h) ∈ V×H has an associated energy value defined by the following function:\nE(v,h) = −hTWv − vTbv − hTbh (1)\nThe parameters Θ = {W,bv,bh} of this model are the weights W (K×D matrix), the visible unit biases bv (D× 1 vector) and the hidden unit biases bh (K × 1 vector).\nA probability distribution over visible and hidden vectors is then defined in terms of this energy function, as follows:\nP (v,h) = 1\nZ e−E(v,h) (2) Z = ∑ v′∈V ∑ h′∈H e−E(v ′,h′) (3)\nWe see from Equation (3) that the partition functionZ (normalizing constant) is intractable, as it requires summing over all possible 2(D+K) configurations.\nThe probability distribution of a visible vector is obtained by marginalizing over all configurations of hidden vectors. One interesting property of the RBM is that the numerator of the marginal P (v) is actually tractable:\nP (v) = 1\nZ ∑ h′∈H e−E(v,h ′) = 1 Z e−F (v) (4)\nF (v) = −vTbv − K∑ i=1 soft+(Wi·v + bhi ) (5)\nwith soft+(x) = ln(1 + ex) and the notation Wi· designates the ith row of W, likewise for columns W·j . This allows for an equivalent definition of the RBM model in terms of what is known as the free energy F (v). However, the partition function still requires summing over all configurations of visible vectors, which is intractable even for moderate values of D.\nRBMs can be learned as generative models, to assign high probability (i.e. low energy) to training observations and low probability otherwise. One approach is to optimize the\naverage negative log-likelihood (NLL) for a set of examples D = {vn}Nn=1:\nf(Θ,D) = 1 N N∑ n=1 − lnP (vn). (6)\nThe gradient of this objective has a simple form, which is often referred to as the combination of positive and negative phases:\n∇θf(Θ,D) = 1\nN N∑ n=1\n∇θF (vn)︸ ︷︷ ︸ Positive phase\n− ∑ v′∈V\nP (v′)∇θF (v′)︸ ︷︷ ︸ Negative phase\nwhere\n∇WF (v) = E[h|v]vT = ĥ(v)vT (7)\n∇bhF (v) = E[h|v] = ĥ(v) (8) ∇bvF (v) = v (9)\nand where ĥ(v) = σ(Wv + bh) with σ(·) representing the sigmoid function σ(x) = 11+e−x applied element-wise on a vector.\nIntuitively, the positive phase pushes up the probability of examples coming from our training set, whereas the negative phase lowers the probability of examples generated by the model. Much like the partition function, the negative phase is intractable to compute. To overcome this limitation we approximate the expectation under P (v) with an average of S samples S = {v̂s}Ss=1 drawn from P (v) i.e. the model.\n∇θf(Θ,D) ≈ 1\nN N∑ n=1\n∇θF (vn)︸ ︷︷ ︸ Positive phase\n− 1 S S∑ s=1\n∇F (v̂s)︸ ︷︷ ︸ Negative phase\nMoreover, mini-batch training is usually employed and consists in replacing the positive phase average by one over a small subset of the training set, different for every training update.\nSampling from P (v) can be achieved using block Gibbs sampling, by alternating between sampling v ∼ P (v|h) and h ∼ P (h|v). This can be done efficiently because RBMs have no connections within a layer, meaning that hidden units are conditionally independent given the visible units and vice versa. The conditional distributions of a binary RBM are Bernoulli distributions with parameters\nP (hi = 1|v) = σ(Wi·v + bhi ) (10) P (vj = 1|h) = σ(hTW·j + bvj) (11)\nIn theory, the Markov chain should be run until equilibrium before drawing a sample for every training update, which\nis highly inefficient. Thus, Constrastive Divergence (CD) learning is often employed, where we initialize the update’s Gibbs chains to the training examples in the mini-batch and only perform T steps of Gibbs sampling (Hinton, 2002). Another approach, referred to as stochastic approximation or Persistent CD (Tieleman, 2008), is to not reinitialize the Gibbs chains between updates."
    }, {
      "heading" : "3. Ordered Restricted Boltzmann Machine",
      "text" : "The model we propose is a variant of the RBM where the hidden units h are ordered from left to right, with this order being taken into account by the energy function. We refer to this model as an ordered RBM (oRBM). The oRBM takes hidden unit order into account by introducing a random variable z that can be understood as the effective number of hidden units participating to the energy. Hidden units are selected starting from the left and the selection of each hidden unit is associated with an incremental cost in energy.\nMore concretely, we define the energy function of the oRBM as\nE(v,h, z) = −vTbv − z∑ i=1 hi(Wi·v + b h i )− βi (12)\nwhere z represents the number of selected hidden units that are active and βi is a energy penalty for selecting each ith hidden unit. Different choices for the per unit energy penalty could be used. In our experiments, we parametrized it as βi = βsoft+(bhi ), where β is a global hyper-parameter. As we will see, this parametrization will allow us to consider the case of an infinite pool of hidden units.\nIntuitively, the penalty term forces the model to avoid using more hidden units than needed, prioritizing smaller networks. Having the penalty depend on the hidden biases also implies that the selection of a hidden units will mostly be controlled by the values taken by the connections W. Higher values of the bias of a hidden unit will not increase its probability of being selected. In other words, for the model to increase its capacity and better fit the training\ndata, it will have to learn better filters.\nAs with the RBM, the probability distribution of the data P (v) is defined in terms of its energy function. For this, we have to specify the set of legal values for v, h and z. Since, for a given z, the value of the energy is irrelevant for the dimensions of h from z to K, we will assume they are set to 0. There is thus a coupling between the value of z and the legal values of h. We will note Hz = {h ∈ H|hk = 0 ∀k > z} the legal values of h for a given z. As for z, it can vary in {1, . . . ,K}, and v ∈ V as usual.\nThe joint probability over v, h and z is thus:\nP (v,h, z) = 1\nZ e−E(v,h,z) (13)\nZ = K∑ z′=1 ∑ v′∈V ∑ h′∈Hz′ e−E(v ′,h′,z′) (14)\nAs for the marginal distribution P (v) of the oRBM model, it can also be written in terms of a free energy. Indeed, in a derivation similar to the case of the RBM, we can show that:\nP (v) = 1\nZ K∑ z=1 ∑ h∈Hz e−E(v,h,z) = 1 Z K∑ z=1 e−F (v,z)\n(15)\nF (v, z) = −vTbv − z∑ i=1 soft+(Wi·v + bhi )− βi (16)\nThis gives us a free energy where only the hidden units have been marginalized. We can also derive a formulation where the free energy depends only on v:\nP (v) = 1\nZ K∑ z=1 e−F (v,z) = 1 Z e−F (v) (17)\nF (v) = log ( K∑ z=1 e−F (v,z) ) (18)\nIt should be noticed that, in the oRBM, z does not correspond to the number of hidden units assumed to have generated all observations. Instead, the model allows for different observations having been generated by a different number of hidden units. Specifically, for a given v, the conditional distribution over the corresponding value of z is\nP (z|v) = exp(−F (v, z))∑K z′ exp(−F (v, z′)) . (19)\nAs for the conditional distribution over the hidden units, given a value of z it takes the same form as for the regular RBM, except for unselected hidden units which are forced\nto zero:\nP (hi = 1|v, z) =\n{ σ(Wi·v + b h i ) if i ≤ z\n0 otherwise (20)\n(21)\nSimilarly, the distribution of v given a value of the hidden layer and z reflects that of the RBM:\nP (vj = 1|h, z) = σ ( z∑ i=1 Wijhi + b v j ) (22)\nTo train the oRBM, we can also rely on either CD or Persistent CD for estimating the parameter gradients based\non Equation 10. Defining 1z = [ z︷ ︸︸ ︷ 1, . . . , 1, 0, . . . , 0]T and cdf(z|v) = [P (z < 1|v), . . . , P (z < K|v)]T , the free energy gradients are then slightly modified as follows:\n∇WF (v) = E[h 1z|v]vT (23)\n= (ĥ(v) (1− cdf(z|v)))vT\n∇bhF (v) = E[(h− σ(bh)) 1z|v] (24)\n= (ĥ(v)− σ(bh)) (1− cdf(z|v)) ∇bvF (v) = v . (25)\nCompared to the RBM, computing these gradients thus requires one additional quantity: the vector of cumulative probabilities cdf(z|v). Fortunately, this quantity can be efficiently computed, in O(K), by first computing the vector of required P (z|v) probabilities and performing a cumulative sum.\nThe gradients are also approximated using CD, but sampling from P (v) slightly differs from the RBM as we need to consider z in the Markov chain. With the oRBM, Gibbs steps alternate between sampling (h, z) ∼ P (h, z|v) and v ∼ P (v|h, z). Sampling from P (h, z|v) is done in two steps, z ∼ P (z|v) followed by h ∼ P (h|v, z).\nDuring training, what we observe is that the hidden units are each trained gradually, in sequence, from left to right. This effect is mainly due to the multiplicative term\n(1− cdf(z|v)) in the hidden unit parameter updates of Equations 23 and 24, which is monotonically decreasing. Effectively, the model is thus growing in capacity during training, until its maximum capacity of K hidden units."
    }, {
      "heading" : "4. Infinite Restricted Boltzmann Machine",
      "text" : "This capacity growing behaviour of the oRBM begs for the question: could we achieve a similar effect without having to specify (at least theoretically) a maximum capacity to the model? It turns out that we can, by taking the limit of K → ∞. For this reason, we refer to this model as the infinite RBM (iRBM).\nThis limit is made possible thanks to two modeling choices. The first is the assumption that weights are initialized to zero. This, of course, is necessary since we cannot store an infinite number of hidden layer weights and biases.\nThe second key choice is our parametrization of the perunit energy penalty βi, which will ensure that the infinite sums required in computing probabilities will be convergent. For instance, consider the case of the conditional P (z|v):\nP (z|v) = exp(−F (v, z)) Z(v) = exp(−F (v, z))∑∞ z′ exp(−F (v, z′))\n(26)\nLet’s note l the number of effectively trained hidden units, i.e. the number of hidden weights that have left their zerovalued initialization. Then, we can split the normalization constant Z(v) of Equation 26 into two parts, split at z = l,\nas follows: l∑ z=1 exp(−F (v, z)) + ∞∑ z=l+1 exp(−F (v, z))\n= l∑ z=1 exp(−F (v, z))\n+ ∞∑ z=l+1 exp\n( −F (v, l) +\nz∑ i=l+1 soft+(Wi·v + bhi )− βi\n)\n= l∑ z=1 exp(−F (v, z))\n+ exp(−F (v, l)) ∞∑ z=1\nexp((1− β)soft+(0))z︸ ︷︷ ︸ Geometric series\n(27)\nwhere Equation 27 is obtained by exploiting the fact that all weights and biases of hidden units at position l + 1 and higher are zero. By constraining β > 1, the geometric series of Equation 27 is finite and can be analytically computed. This in turn implies that P (z|v) is tractable and can be sampled from. Following a similar reasoning, the global partition function Z can be shown to be finite, thus yielding a properly defined joint distribution.\nAs for learning, it can be done mostly by following the procedure of the oRBM, i.e. minimizing the NLL with stochastic gradient descent using CD or Persistent CD to approximate the gradients. One slight modification is required however. Indeed, since the free energy gradient for the hidden weights and biases can be non-zero for all (infinite) hidden units, we cannot use the gradient of Equations 23 and 24 for all hidden units.\nTo avoid this issue, we consider the following observation. Instead of using the derivative of F (v), we could instead use the derivative of F (v, z), where z is obtained by sampling from P (z|v):\n∇WF (v, z) = E[h 1z|z,v]vT (28)\n= (ĥ(v) 1z)vT\n∇bhF (v, z) = E[(h− σ(bh)) 1z|z,v] (29)\n= (ĥ(v)− σ(bh)) 1z\nwhere denotes the element-wise product.\nIn this case, all weights and biases with an index greater than the sampled z have a gradient of zero, i.e. do not require any update. Moreover, the expectation of these gradients with respect to z (conditioned on v) are the gradients of F (v), making them unbiased in this respect. This comes at the cost of higher variance in the updates. But thanks to this observation, we are justified to use a hybrid approach,\nwhere we use the F (v) gradients only for the units with index less or equal than l, and ”use” the gradient of F (v, z) for the other units, i.e. leave them set to zero.\nFinally, attention must be paid to the potential issue of the number of weights growing unboundedly during training. There are several ways we could avoid this. One would be to add L1 regularization on the weights and hidden biases, so that parameters could shrink back to zero. Another would be to use a form of early stopping, where the quality of the model would be tracked on a validation set and training would be stopped when performance would cease to improve (Desjardins et al., 2011).\nFor practical reasons (such as to ensure an efficient implementation of the model on the GPU), we replaced such capacity control mechanisms with a few, more practical, heuristics. First, if the Gibbs sampling chain ever samples a value for z that is greater than l, then we clamp its value to l+ 1 and only increment l by one. Intuitively, this corresponds to ”adding” a single hidden unit. This avoids filling all the memory in the (unlikely) event where we’d draw a large value of z. When adding a hidden unit, its associated weights and biases are initialized to zero. Also, to simulate the effect of L1 regularization that would allow superfluous units to shrink back to zero, whenever the norm of the weights of the lth hidden unit was below some threshold (we use 10−6 in all our experiments), we would clamp the unit back to zero and decrement l."
    }, {
      "heading" : "5. Related Work",
      "text" : "This work falls within the research literature on discovering extensions of the original RBM model to different contexts and objectives. Of note here is the implicit mixture of RBMs (Nair & Hinton, 2008). Indeed, the oRBM can be interpreted as a special case of an implicit mixture of RBMs. Writing P (v) as\nP (v) = K∑ z=1 P (z)P (v|z) (30)\nwe see that the oRBM is an implicit mixture of K RBMs, where each RBM has a different number of hidden units (from 1 toK) and the weights are tied between RBMs. The prior P (z) represents the probability of using the zth RBM and is also derived from the energy function. However, as in the implicit mixture of RBMs, P (z) is intractable as it would require the value of the partition function. That said, the work of Nair & Hinton (2008) is otherwise very different and did not address the question of having an RBM with adaptive capacity.\nThe oRBM also bears some similarity with autoencoders trained by a nested version of dropout (Rippel et al., 2014). Nested dropout works by stochastically selecting the num-\nber of hidden units used to reconstruct an input example at training time, and so independently for each update and example. Rippel et al. (2014) showed that this defines a learning objective that makes the solution identifiable and no longer invariant to hidden unit permutation. In addition to being concerned with a different type of neural network model, this work doesn’t discuss the case of an unbounded and adaptive hidden layer size.\nWelling et al. (2003) proposed a self supervised boosting approach, which is applicable to the RBM and in which hidden units are sequentially added and trained. However, like boosting in general and unlike the iRBM, this procedure trains each hidden unit greedily instead of jointly, which could lead to much larger networks than necessary. Moreover, the procedure is not easily generalizable to online learning.\nWhile the work on unsupervised neural networks with adaptive hidden layer size is otherwise relatively scarse, there’s been much more work in the context of supervised learning. There is the well known work of Fahlman & Lebiere (1990) on Cascade-Correlation networks. More recently, Zhou et al. (2012) proposed a procedure for learning discriminative features with a denoising autoencoder (a model related to the RBM). The procedure is also applicable to the online setting. It relies on invoking two heuristics that either add or merge hidden units during training. We note that the iRBM framework could easily be generalized to discriminative and hybrid training as in Zhou et al. (2012). The corresponding mecanisms for adding and merging units would then be implicitly derived from gradient descent on the corresponding supervised training objective.\nFinally, we highlight that our model is not based on a Bayesian formulation, as most of the literature on infinite models. On the other hand, it does correspond to the infinite limit of a finite-sized model and yields a model that can increase its size with training."
    }, {
      "heading" : "6. Experiments",
      "text" : "We compare the performance of the oRBM and the iRBM with the classic RBM on two datasets: binarized MNIST (Salakhutdinov & Murray, 2008) and CalTech101 Silhouettes (Marlin et al., 2010). All NLL results of this section were obtained by estimating the logpartition function ln Ẑ using Annealed Importance Sampling (AIS) (Salakhutdinov & Murray, 2008) with 100,000 intermediate distributions and 5,000 chains. As an additional validation step, samples were generated from the best models and visually inspected. The code to reproduce the experiments of the paper is available on github1.\n1http://github.com/MarcCote/iRBM\nEach model was trained with mini-batch stochastic gradient descent using either CD(k) or PCD(k) where k ∈ {1, 10, 25} represents the numbers of Gibbs steps between parameter updates. Mini-batches contained 64, 100 or 128 examples. We tried several learning rates: 10−1, 10−2, 10−3 and 3 × 10−2. We used the ADAGRAD stochastic gradient update (Duchi et al., 2011), a perdimension learning rate method, to train the oRBMs and the iRBM. Having different learning rates for different hidden units is important, since units positioned earlier in the hidden layer will approach convergence faster than units to their right, and thus will benefit from a learning rate decaying more rapidly. We tested the previous learning rates and always set ADAGRAD’s epsilon parameter to 10−2. Furthermore, we observed that using weight decay helps the iRBM as it pushes unused filters (often the rightmost units) towards zero allowing the model to shrink if needed. We tested different values for the regularization’s factor λ: 0, 10−2, 10−3, 10−5. We also varied β found in the penalty term of the oRBM and the iRBM as follows: 1.01, 1.1, 1.25, 2. Rather then doing a grid search, we manually explored the hyper-parameters space and validated the models on the validation set."
    }, {
      "heading" : "6.1. Binarized MNIST",
      "text" : "The MNIST dataset2 is composed of 70,000 images of size 28x28 pixels representing handwritten digits (0-9). Images have been stochastically binarized according to their pixel intensity as in Salakhutdinov & Murray (2008). We use the same split as in Larochelle & Murray (2011), corresponding to 50,000 examples for training, 10,000 for validation and 10,000 for testing.\nEach model was trained for 500 epochs and the best results for the RBM, oRBM and iRBM are reported in Table 1. The best RBM with 500 hidden units uses CD(25). It was trained by Salakhutdinov & Murray (2008)3, but we re-estimated its partition function to follow the same procedure as the rest of our experiments. The best oRBM with 500 units was trained using PCD(10) and the following hyper-parameters: β = 1.1, λ = 0, learning rate\n2http://yann.lecun.com/exdb/mnist 3http://www.cs.toronto.edu/∼rsalakhu/rbm ais.html\nof 3 × 10−2 and a batch size of 64. The best iRBM stopped at 866 hidden units with non-zero weights and was trained using PCD(25) and the following hyper-parameters: β = 1.01, λ = 10−5, learning rate of 3× 10−2 and a batch size of 64.\nFrom Table 1, we see that both the oRBM and the iRBM models are competitive with the original RBM. Note that the confidence interval on the average NLL assumes the log-partition function estimate has no variance and only reflects the confidence of a finite sample average. By taking the uncertainty about the partition function into account, the interval would be larger.\nFigure 5 compares the filters obtained from a traditional RBM and an iRBM. The ordering effect is clearly apparent. The ordering is even more apparent when observing the hidden unit filters during training. We generated a video of this visualization, illustrating the filter values and the\ngenerated negative samples at epochs 1, 10, 50 and 100. See following link: http://goo.gl/LGQDaI.\nFigure 6 illustrates the conditional distribution P (z|v) for different images v. As explained in Section 3, we see that different input images are related to different values for the number z of used units.\nFigure 4 shows the samples obtained from these models and compares them against some examples of the test set. Interestingly, we’ve observed that Gibbs sampling can mix much more slowly with the oRBM. The reason is the addition of variable z increases the dependence between states and thus hurts the convergence of Gibbs sampling. In particular, we observed that when the Gibbs chain is in a state corresponding to a noisy image without any structure, it can require many steps before stepping out of this region of the input space. Yet, comparing the free energy of such random images and images that resemble digits confirmed that these random images have significantly higher free energy (and thus are unlikely samples of the model). Figure 6 also confirms the high dependence between z and v: the distribution of the unstructured image is peaked at z = 1, while all digits prefer values of z greater than 250. To fix this issue, we’ve found that simply initializing the Gibbs chain to z = K was sufficient. We used this to sample the trained oRBM model of Figure 4."
    }, {
      "heading" : "6.2. CalTech101 Silhouettes",
      "text" : "The CalTech101 Silhouettes dataset4 (Marlin et al., 2010) is composed of 8,671 images of size 28x28 binary pixels, representing object silhouettes (101 classes). The dataset is divided in three subsets: 4,100 examples for training, 2,264 for validation and 2,307 for testing.\nEach model was trained for 1000 epochs and the best results for the RBM, oRBM and iRBM are reported in Table 2. Again, the oRBM and the iRBM models reach competitive performance compared to the RBM. The best RBM with 500 hidden units was trained by Marlin et al. (2010) and uses the PCD instead of CD. We re-estimated its partition function to follow the same procedure as the rest of our experiments. The best oRBM with 500 units was trained using PCD(25) and the following hyper-parameters: β = 1.01, λ = 10−3, learning rate of 10−2 and a batch size of 100. After training, the best iRBM had 845 hidden units with non-zero weights. It was trained using PCD(10) and the following hyper-parameters: β = 1.1, λ = 10−3, learning rate of 10−2 and a batch size of 100. Samples from all three models, as well as test set samples, are illustrated in Figure 7."
    }, {
      "heading" : "7. Conclusion",
      "text" : "We proposed novel extensions of the RBM, the ordered RBM and the infinite RBM, where the latter is derived from the former by taking the infinite limit of its hidden layer size. We presented a training procedure, derived from Contrastive Divergence, such that training the iRBM yields a learning procedure where the effective hidden layer size\n4http://people.cs.umass.edu/∼marlin/data.shtml\ncan grow with training.\nIn future work, we are interested in generalizing the idea of a growing latent representation to structures other than a flat vector representation. We are currently exploring extensions of the RBM allowing for a tree-structured latent representation. We believe a similar construction, involving a similar z random variable, should allow us to derive a training algorithm that also learns the latent representation’s size."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank NSERC for supporting this research and Stanislas Lauly for making the iRBM’s training video."
    } ],
    "references" : [ {
      "title" : "Training Restricted Boltzmann Machines on Word Observations",
      "author" : [ "Dahl", "George E", "Adams", "Ryan P", "Larochelle", "Hugo" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning (ICML",
      "citeRegEx" : "Dahl et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Dahl et al\\.",
      "year" : 2012
    }, {
      "title" : "The cascadecorrelation learning architecture",
      "author" : [ "Fahlman", "Scott E", "Lebiere", "Christian" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "Fahlman et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Fahlman et al\\.",
      "year" : 1989
    }, {
      "title" : "Training products of experts by minimizing contrastive divergence",
      "author" : [ "Hinton", "GE" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Hinton and GE.,? \\Q2002\\E",
      "shortCiteRegEx" : "Hinton and GE.",
      "year" : 2002
    }, {
      "title" : "The Neural Autoregressive Distribution Estimator",
      "author" : [ "Larochelle", "Hugo", "Murray", "Iain" ],
      "venue" : null,
      "citeRegEx" : "Larochelle et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Larochelle et al\\.",
      "year" : 2011
    }, {
      "title" : "Inductive Principles for Restricted Boltzmann Machine Learning",
      "author" : [ "Marlin", "Benjamin M", "Swersky", "Kevin", "Chen", "Bo", "de Freitas", "Nando" ],
      "venue" : "Proc. Intl. Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "Marlin et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Marlin et al\\.",
      "year" : 2010
    }, {
      "title" : "Implicit Mixtures of Restricted Boltzmann Machines",
      "author" : [ "Nair", "Vinod", "Hinton", "Geoffrey" ],
      "venue" : "NIPS, pp",
      "citeRegEx" : "Nair et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Nair et al\\.",
      "year" : 2008
    }, {
      "title" : "Bayesian Nonparametric Models",
      "author" : [ "Orbanz", "Peter", "Teh", "Yee Whye" ],
      "venue" : "In Encyclopedia of Machine Learning. Springer,",
      "citeRegEx" : "Orbanz et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Orbanz et al\\.",
      "year" : 2010
    }, {
      "title" : "Factored 3-way restricted boltzmann machines for modeling natural images",
      "author" : [ "Ranzato", "MarcAurelio", "Krizhevsky", "Alex", "Hinton", "Geoffrey E" ],
      "venue" : "Journal of Machine Learning Research - Proceedings Track,",
      "citeRegEx" : "Ranzato et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Ranzato et al\\.",
      "year" : 2010
    }, {
      "title" : "Learning Ordered Representations with Nested Dropout",
      "author" : [ "O Rippel", "MA Gelbart", "Adams", "RP" ],
      "venue" : "arXiv preprint arXiv:1402.0915,",
      "citeRegEx" : "Rippel et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Rippel et al\\.",
      "year" : 2014
    }, {
      "title" : "On the quantitative analysis of Deep Belief Networks",
      "author" : [ "Salakhutdinov", "Ruslan", "Murray", "Iain" ],
      "venue" : "Proceedings of the 25th Annual International Conference on Machine Learning (ICML",
      "citeRegEx" : "Salakhutdinov et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Salakhutdinov et al\\.",
      "year" : 2008
    }, {
      "title" : "Restricted Boltzmann machines for collaborative filtering",
      "author" : [ "Salakhutdinov", "Ruslan", "Mnih", "Andriy", "Hinton", "Geoffrey" ],
      "venue" : "In Proceedings of the 24th International Conference on Machine Learning (ICML",
      "citeRegEx" : "Salakhutdinov et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Salakhutdinov et al\\.",
      "year" : 2007
    }, {
      "title" : "Two distributed-state models for generating high-dimensional time series",
      "author" : [ "Taylor", "Graham W", "Hinton", "Geoffrey E", "Roweis", "Sam T" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Taylor et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Taylor et al\\.",
      "year" : 2011
    }, {
      "title" : "Training restricted Boltzmann machines using approximations to the likelihood gradient",
      "author" : [ "Tieleman", "Tijmen" ],
      "venue" : "ICML; Vol. 307, pp",
      "citeRegEx" : "Tieleman and Tijmen.,? \\Q2008\\E",
      "shortCiteRegEx" : "Tieleman and Tijmen.",
      "year" : 2008
    }, {
      "title" : "Self supervised boosting",
      "author" : [ "Welling", "Max", "Zemel", "Richard S", "Hinton", "Geoffrey E" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "Welling et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Welling et al\\.",
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "The RBM (and its extensions to non-binary vectors) have been successfully applied to a large variety of problems and data, such as images (Ranzato et al., 2010), movie user preferences (Salakhutdinov et al.",
      "startOffset" : 138,
      "endOffset" : 160
    }, {
      "referenceID" : 10,
      "context" : ", 2010), movie user preferences (Salakhutdinov et al., 2007), motion capture data (Taylor et al.",
      "startOffset" : 32,
      "endOffset" : 60
    }, {
      "referenceID" : 11,
      "context" : ", 2007), motion capture data (Taylor et al., 2011), text data (Dahl et al.",
      "startOffset" : 29,
      "endOffset" : 50
    }, {
      "referenceID" : 0,
      "context" : ", 2011), text data (Dahl et al., 2012) and many others.",
      "startOffset" : 19,
      "endOffset" : 38
    }, {
      "referenceID" : 8,
      "context" : "The oRBM also bears some similarity with autoencoders trained by a nested version of dropout (Rippel et al., 2014).",
      "startOffset" : 93,
      "endOffset" : 114
    }, {
      "referenceID" : 8,
      "context" : "Rippel et al. (2014) showed that this defines a learning objective that makes the solution identifiable and no longer invariant to hidden unit permutation.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 8,
      "context" : "Rippel et al. (2014) showed that this defines a learning objective that makes the solution identifiable and no longer invariant to hidden unit permutation. In addition to being concerned with a different type of neural network model, this work doesn’t discuss the case of an unbounded and adaptive hidden layer size. Welling et al. (2003) proposed a self supervised boosting approach, which is applicable to the RBM and in which hidden units are sequentially added and trained.",
      "startOffset" : 0,
      "endOffset" : 339
    }, {
      "referenceID" : 8,
      "context" : "Rippel et al. (2014) showed that this defines a learning objective that makes the solution identifiable and no longer invariant to hidden unit permutation. In addition to being concerned with a different type of neural network model, this work doesn’t discuss the case of an unbounded and adaptive hidden layer size. Welling et al. (2003) proposed a self supervised boosting approach, which is applicable to the RBM and in which hidden units are sequentially added and trained. However, like boosting in general and unlike the iRBM, this procedure trains each hidden unit greedily instead of jointly, which could lead to much larger networks than necessary. Moreover, the procedure is not easily generalizable to online learning. While the work on unsupervised neural networks with adaptive hidden layer size is otherwise relatively scarse, there’s been much more work in the context of supervised learning. There is the well known work of Fahlman & Lebiere (1990) on Cascade-Correlation networks.",
      "startOffset" : 0,
      "endOffset" : 965
    }, {
      "referenceID" : 8,
      "context" : "Rippel et al. (2014) showed that this defines a learning objective that makes the solution identifiable and no longer invariant to hidden unit permutation. In addition to being concerned with a different type of neural network model, this work doesn’t discuss the case of an unbounded and adaptive hidden layer size. Welling et al. (2003) proposed a self supervised boosting approach, which is applicable to the RBM and in which hidden units are sequentially added and trained. However, like boosting in general and unlike the iRBM, this procedure trains each hidden unit greedily instead of jointly, which could lead to much larger networks than necessary. Moreover, the procedure is not easily generalizable to online learning. While the work on unsupervised neural networks with adaptive hidden layer size is otherwise relatively scarse, there’s been much more work in the context of supervised learning. There is the well known work of Fahlman & Lebiere (1990) on Cascade-Correlation networks. More recently, Zhou et al. (2012) proposed a procedure for learning discriminative features with a denoising autoencoder (a model related to the RBM).",
      "startOffset" : 0,
      "endOffset" : 1032
    }, {
      "referenceID" : 8,
      "context" : "Rippel et al. (2014) showed that this defines a learning objective that makes the solution identifiable and no longer invariant to hidden unit permutation. In addition to being concerned with a different type of neural network model, this work doesn’t discuss the case of an unbounded and adaptive hidden layer size. Welling et al. (2003) proposed a self supervised boosting approach, which is applicable to the RBM and in which hidden units are sequentially added and trained. However, like boosting in general and unlike the iRBM, this procedure trains each hidden unit greedily instead of jointly, which could lead to much larger networks than necessary. Moreover, the procedure is not easily generalizable to online learning. While the work on unsupervised neural networks with adaptive hidden layer size is otherwise relatively scarse, there’s been much more work in the context of supervised learning. There is the well known work of Fahlman & Lebiere (1990) on Cascade-Correlation networks. More recently, Zhou et al. (2012) proposed a procedure for learning discriminative features with a denoising autoencoder (a model related to the RBM). The procedure is also applicable to the online setting. It relies on invoking two heuristics that either add or merge hidden units during training. We note that the iRBM framework could easily be generalized to discriminative and hybrid training as in Zhou et al. (2012). The corresponding mecanisms for adding and merging units would then be implicitly derived from gradient descent on the corresponding supervised training objective.",
      "startOffset" : 0,
      "endOffset" : 1420
    }, {
      "referenceID" : 4,
      "context" : "We compare the performance of the oRBM and the iRBM with the classic RBM on two datasets: binarized MNIST (Salakhutdinov & Murray, 2008) and CalTech101 Silhouettes (Marlin et al., 2010).",
      "startOffset" : 164,
      "endOffset" : 185
    }, {
      "referenceID" : 4,
      "context" : "CalTech101 Silhouettes The CalTech101 Silhouettes dataset4 (Marlin et al., 2010) is composed of 8,671 images of size 28x28 binary pixels, representing object silhouettes (101 classes).",
      "startOffset" : 59,
      "endOffset" : 80
    }, {
      "referenceID" : 4,
      "context" : "CalTech101 Silhouettes The CalTech101 Silhouettes dataset4 (Marlin et al., 2010) is composed of 8,671 images of size 28x28 binary pixels, representing object silhouettes (101 classes). The dataset is divided in three subsets: 4,100 examples for training, 2,264 for validation and 2,307 for testing. Each model was trained for 1000 epochs and the best results for the RBM, oRBM and iRBM are reported in Table 2. Again, the oRBM and the iRBM models reach competitive performance compared to the RBM. The best RBM with 500 hidden units was trained by Marlin et al. (2010) and uses the PCD instead of CD.",
      "startOffset" : 60,
      "endOffset" : 569
    } ],
    "year" : 2017,
    "abstractText" : "We present a mathematical construction for the restricted Boltzmann machine (RBM) in which the hidden layer size is adaptive and can grow during training. This is obtained by first extending the RBM to be sensitive to the ordering of its hidden units. Then, thanks to a carefully chosen definition of the energy function, we show that the limit of infinitely many hidden units is well defined. As in a regular RBM, approximate maximum likelihood training can be performed, resulting in an algorithm that naturally and adaptively adds trained hidden units during learning. We empirically study the behaviour of this infinite RBM, showing that its performance is competitive to that of the RBM.",
    "creator" : "LaTeX with hyperref package"
  }
}