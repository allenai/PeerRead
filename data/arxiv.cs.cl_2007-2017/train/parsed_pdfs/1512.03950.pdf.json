{
  "name" : "1512.03950.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Hidden Markov Model Based System for Entity Extraction from Social Media English Text at FIRE 2015",
    "authors" : [ "Kamal Sarkar" ],
    "emails" : [ "jukamal2001@yahoo.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "University as part of the participation in FIRE 2015 task: Entity Extraction from Social Media Text - Indian Languages (ESM-IL). The tool that we have developed for the task is based on Trigram Hidden Markov Model that utilizes information like gazetteer list, POS tag and some other word level features to enhance the observation probabilities of the known tokens as well as unknown tokens. We submitted runs for English only. A statistical HMM (Hidden Markov Models) based model has been used to implement our system. The system has been trained and tested on the datasets released for FIRE 2015 task: Entity Extraction from Social Media Text - Indian Languages (ESM-IL). Our system is the best performer for English language and it obtains precision, recall and F-measures of 61.96, 39.46 and 48.21 respectively.\nCategories and Subject Descriptors\nH.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval; H.3.4 Systems and Software; H.2.3 [Database Management]: Languages-Query Languages\nGeneral Terms\nLanguages, Performance, Experimentation\nKeywords Named Entity Recognition, Entity Extraction, Social Media, HMM."
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "The objective of named entity recognition is to identify and classify every word/term in a document into some predefined categories like person name, location name, organization name, miscellaneous name (date, time, percentage and monetary expressions etc.) etc.\nNER is an important task, having applications in Information Extraction, Question Answering, Machine Translation, Summarization, Cross-lingual information access and other NLP applications. Over the past decade, Indian language content on various social media( twitter, facebook etc.) is rapidly increasing. When the different companies are interested to ascertain public views on their products and services, they need natural language processing software systems which identify entities and relations among the entities. So, there is a need for automatic entity extraction system.\nThis paper presents a description of HMM (Hidden Markov Model) based system for Entity Extraction from Social Media Text in Indian Languages. This named entity recognition system (NER) considers a variety of entity types: artifact, entertainment, facilities, location, locomotive, materials, organization, person, plants, count, distance, money, quantity, date, day, period, time and year, month, Living thing and Sday.\nThe task “Entity Extraction from Social Media Text - Indian Languages (ESM-IL)” was defined to build the NER systems for four Indian languages - English, Malayalam, Tamil and Hindi for which training data and test data were provided. We have participated for English language only.\nThe earliest works on named entity recognition (NER) primarily uses two major approaches to NER: Rule based (Linguistic) approaches and Machine Learning (ML) based approaches.\nThe rule based approaches typically use a set of hand crafted\nrules [1][2][3].\nMachine learning (ML) based techniques for NER make use of a large amount of NE annotated training data to acquire higher level language knowledge from the labeled data. Several ML techniques have already been applied for the NER tasks such as Markov Model (HMM) [4], Maximum Entropy (MaxEnt) [5][6], Conditional Random Field (CRF)[7] etc.\nThe hybrid approaches that combines different ML approaches are also used. Srihari et al.(2000) [8] combines MaxEnt, Hidden Markov Model (HMM) and handcrafted rules to build an NER system.\nNER systems also use gazetteer lists for identifying names. Both the linguistic approach [1][3] and the ML based approach[5][8] may use gazetteer lists.\nThe NER tasks for Hindi have been presented in [9][10][11].\nA discussion on the training data is given in Section 2. The HMM based NER system is described in Section 3. Various features used in NER are then discussed. Next we present the experimental results and related discussions in Section 5. Finally Section 6 concludes the paper."
    }, {
      "heading" : "2. TRAINING DATA PREPARATION",
      "text" : "The training data released for the FIRE shared task contains two files: one file contains the raw text file and another file contains the NE annotation file in which each row has 6 columns: tweet-id, user-id, NE-tag, NE raw string, NE-start index and NE_length. Index column is the starting character position of NE calculated\nfor each tweet. The participants are instructed to produce the output in the same format after testing the system on the test data. Our system uses the two files supplied for training data and converts the data into the IOB format before training and the data converted in IOB (Inside, Outside and Beginning) format (a format used for the CoNLL-2003 shared task on NER) is used for training. IOB format uses a B−XXX tag that indicates the first word of an entity type XXX and I−XXX that is used for subsequent words of an entity. The tag “O” indicates the word is outside of an NE (i.e., not a part of a named entity)."
    }, {
      "heading" : "3. HMM BASED NAMED ENTITY TAGGING",
      "text" : "A named entity recognizer based on Hidden Markov Model (HMM) finds the best sequence of NE tags 1 nt that is optimal for\na given observation sequence 1\nno . The tagging problem becomes\nequivalent to searching for\n1\n1 1 1arg max ( | ) ( ) n\nn n n\nt\nP o t P t (by the\napplication of Bayes’ law), that is, we need to compute:\n1\n1 1 1 1 ˆ arg max ( | ) ( )\nn\nn n n n\nt\nt P o t P t (1).\nWhere 1 nt is a tag sequence and 1 no is an observation sequence,\n1( ) nP t is the prior probability of the tag sequence and\n1 1( | ) n nP o t is the likelihood of the word sequence.\nIn general, HMM based sequence labeling tasks such as POS tagging use words in a sentence as an observation sequence [12] 13]. But, we use MontyTagger [14] to assign POS tags to the data released for the task, that is, some additional information such as POS for each token in a tweet becomes now available. We also use some other information such as whether the token contains any digit, whether the token contains any hash tag or not etc. We use this information in a form of meta tag (details are presented in the subsequent sections). We use gazetteer information also. If any token is found in the specific gazetteer list, we use the gazetteer tag in place of POS tag (details are presented in the subsequent sections).\nUnlike the traditional HMM based NER system, to use this additional information for named entity recognition task, we consider a triplet as an observation symbol: <word, POStag/gazetteer tag , meta-tag >. This is a pseudo token used as an observed symbol, that is, for a tweet of n words, the corresponding observation sequence will be as follows:\n(<word1, X-tag1, meta-tag1>, <word2, X-tag2, meta-tag2>, <word3, X-tag3, meta-tag3>, .........., <wordn, X-tagn, meta-tagn>) . Here an observation symbol oi corresponds to <wordi, X-tagi, meta-tagi> and X-tag can be either POS tag or gazetteer tag).\nSince Equation (1) is too hard to compute directly, HMM taggers follows Markov assumption according to which the probability of a tag is dependent only on short memory (a small, fixed number of previous tags). For example, a bigram tagger considers that the probability of a tag depends only on the previous tag\nFor our proposed trigram model, the probability of a tag depends on two previous tags and thus 1( ) nP t is computed as:\n1 1 2 1\n( ) ( | , ) n n\ni i i i P t P t t t    (2)\nDepending on the assumption that the probability of a word appearing is dependent only on its own tag, 1 1( | ) n nP o t can be\nsimplified to:\n1 1 1\n( | ) ( | ) n n n\ni i i P o t P o t   (3)\nPlugging the above mentioned two equations (2) and (3) into (1) results in the following equation by which a bigram tagger estimates the most probable tag sequence:\n1 1\n1 1 1 1 1 1 ˆ arg max ( | ) ( ) arg max ( | ) ( | ) n n\nn n n n n\ni i i i it t\nt P t o P t P o t P t t  \n   (4)\nWhere: the tag transition probabilities, 1( | )i iP t t  , represent the\nprobability of a tag given the previous tag. ( | )i iP o t represents\nthe probability of an observed symbol given a tag. Considering a special tag tn+1 to indicate the end sentence boundary and two special tags t-1 and t0 at the starting boundary of the sentence and adding these three special tags to the tag set [15], gives the following equation for NE tagging:\n1\n1\n1 1 1 1\n1 2 1 1\nˆ arg max ( | ) ( )\narg max[ ( | ) ( | , )] ( | )\nn\nn\nn n n n\nt\nn\ni i i i i n n it\nt P t o P t\nP o t P t t t P t t   \n \n (5)\nThe equation (5) is still computationally expensive because we need to consider all possible tag sequence of length n. So, dynamic programming approach is used to compute the equation (5).\nAt the training phase of HMM based NE tagging, observation probability matrix and tag transition probability matrix are created. Architecture of our developed NE tagger is shown in Figure 1."
    }, {
      "heading" : "3.1 Computing Tag Transition Probabilities",
      "text" : "As we can see from the equation (4), to find the most likely tag sequence for an observation sequence, we need to compute two kinds of probabilities: tag transition probabilities and word likelihoods or observation probabilities.\nOur developed trigram HMM tagger requires to compute tag\ntrigram probability, 1 2( | , )i i iP t t t  , which is computed by the\nmaximum likelihood estimate from tag trigram counts. To overcome the data sparseness problem, tag trigram probability is smoothed using deleted interpolation technique [13][15] which uses the maximum likelihood estimates from counts for tag trigram, tag bigram and tag unigram."
    }, {
      "heading" : "3.2 Computing Observation Probabilities",
      "text" : "The observation probability of a observed triplet <word, X-tag, meta-tag >, which is the observed symbol in our case, is computed using the following equation [12][13]. ( , )\n( ) ( | )\nC o t\nC o P o t  (7)"
    }, {
      "heading" : "3.3 Viterbi Decoding",
      "text" : "The task of a decoder is to find the best hidden state sequence given an input HMM and a sequence of observations.\nThe Viterbi algorithm is the most common decoding algorithm used for HMM based tagging task. This is a standard application of the classic dynamic programming algorithm[16].\nGiven a tag transition probability matrix and the observation probability matrix, Viterbi decoding (used at the testing phase) accepts a tweet in Indian language and finds the most likely tag sequence for the test tweet which is also X-tagged and Meta tagged. Here a tweet is submitted to the viterbi as the observation sequence of triplets:\n(<word1, X-tag1, meta-tag1>, <word2, X-tag2, meta-tag2>, <word3, X-tag3, meta-tag3>, .........., <wordn, X-tagn, meta-tagn>) . Here an observation symbol oi corresponds to <wordi, X-tagi, meta-tagi> and X-tag can be either POS tag or gazetteer tag).\nAfter assigning the tag sequence to the observation sequence as\nmentioned above, X-tag and meta-tag information are removed from the output and thus the output for an input sentence is converted to a NE-tagged sentence.\nWe have used the Viterbi algorithm presented in [16] for finding the most likely tag sequence for a given observation sequence.\nOne of the important problems to apply Viterbi decoding algorithm is how to handle unknown triplets in the input. The unknown triplets are triplets which are not present in the training set and hence their observation probabilities are not known. To handle this problem, we estimate the observation probability of an unknown one by analyzing X-tag, meta-tag and the suffix of the word associated with the corresponding the triplet. We estimate the observation probability of an unknown observed triplet in the following ways:\nThe observation probabilities of unknown triplet < word, X-tag, meta-tag> corresponding to a word in the input sentence are decided according to the suffix of a pseudo word formed by adding X-tag and meta-tag to the end of the word. We find the observation probabilities of such unknown pseudo words using suffix analysis of all rare pseudo words (frequency <=2) in the training corpus for the concerned language [13][15]."
    }, {
      "heading" : "4. SPECIAL TAGS",
      "text" : ""
    }, {
      "heading" : "4.1 Meta Tag",
      "text" : "Each token has some properties by which one token differs from another. For example, a token may only consist of digits or it may contain hash. To capture such information specific to a token, we use Meta tag. For example, if a token is consisting of only digits, meta tag that we will assign to the token is ALLDIGITS which we write ALDT in short.\nThe various meta tags that we use for our task are described below. Meta tag for a token is determined using the following rules which are fired in the following order.\nMeta-tag=”YYYY”(default) if the first letter of the token is a capital letter then metatag = \"ICAP\" end if\nif the first token is abbreviation then metatag = \"ABBR\" End If\nif contains \"#\" at the begining of the token and the first character after hash is a capital letter then\nmetatag = \"CHAS\"\nElseIf contains \"#\" at the begining of the token Then metatag = \"HASH\" End If\nif contains \"@\" at the begining of the token then\nmetatag = \"ATSY\"\nEnd If\nIf last charater is a colon(\":\") And the first letter is capital then\nmetatag = \"CCOL\"\nElseIf last charater is a colon(\":\") Then\nmetatag = \"COLN\"\nEnd If\nif contains hyphen and the first character is capital then\nmetatag = \"CHYP\"\nElseIf hyphen occurs after 3 characters from the begining then\nmetatag = \"HYPH\"\nEnd If\nif the token is 4 digits then\nmetatag = \"DFOR\"\nElseIf the token is two digits then\nmetatag = \"DTWO\"\nElseIf the token is one digit then\nmetatag = \"DONE\"\nElseIf token contains at least one digit then\nmetatag = \"DIGT\"\nEnd If\nIf contains one comma and contains at least one digit then\nmetatag = \"DCOM\"\nElseIf the last character is a comma and first character is capital then metatag = \"CLCO\" ElseIf contains one comma at the end of the token then\nmetatag = \"LCOM\"\nElseIf contains more than one comma and first character is capital then\nmetatag = \"CMCO\"\nEnd If\nIf token contains all dots then\nmetatag = \"ALDT\"\nEnd If"
    }, {
      "heading" : "4.2 Gazetteer tag",
      "text" : "In earlier sections, we have mentioned that POS tag for a token is replaced by a gazetteer tag if the token is found in a particular gazetteer list. if the length of a raw word is greater than equal to 2 , before searching in the gazetteer list, we remove from the token the symbols such as \",\",\".\",\":\",\"#\" and \"@\". The description of gazetteer list is shown in Table 1.\nperson names\nBlocation A list of first words\nextracted from list of location names\n1243\nIlocation A list of words extracted\nfrom a list of location names where a extracted word is not the first word of the location name\n257\nfacilities A list of facility names\nsuch as school, college etc.\n14\nmonths A list of English month\nnames\n12\ndays A list of English day\nnames\n7\nperiod A list of words indicating\n“period” such as “month”, “year” etc.\n34\nCount expressions A list of words indicating “count” 58\nMonetary expressions A list of words indicating monetary expressions\nsuch as lakh, crore etc.\n18\nWe follow the following rules for assigning this type of tag to the token:\nX-tag=POS-tag (default tag)\nif Token is found in the BPerson list then\nX-tag=\"BPER\"\nelseif Token is found in the IPerson list then\nX-tag = \"IPER\"\nelseif Token is found in Blocation list then\nX-tag=\"BLOC\"\nelseif Token is found in ILocation list then\nX-tag = \"ILOC\"\nelseif Token is found in the list of facilities then\nX-tag=\"FACI\"\nelseif Token is found in the list of month names then\nX-tag = \"MONT\"\nelseif Token is found in the list of day names then\nX-tag= \"DAYS\"\nelseif Token is found in the list of period indicating expressions then\nX-tag = \"PERD\"\nelseif Token is found in the list of expression denoting countthen\nX-tag = \"COUN\"\nelseif Token is found in the list of monetary expressions then\nX-tag = \"MONY\"\nEnd If\n5. EVALUATION AND RESULTS\nWe train separately our developed named entity recognizer based on the training data and tune the parameters of our system on the training data for the English language. After learning the tuning parameters, we test our system on the test data for the concerned language. The description of the data for English language is shown in the Table2\nAfter getting the NE-tagged output in IOB format from the HMM model, we observed that the NE tagged output contains some occurrences of a sequence of I-XXXs where the left boundary of each such sequence is a transition from the tag “O” to I-XXXs (but, according to the IOB format, the left boundary of a named entity is a transition from any tag to B-XXX).\nTable2. The description of the data for English language\nLanguage Total of tweets NE Types\nTraining data Test data\nEnglish 11003 9641 21\nWe have also observed that the word sequence to which this type of tag sequence is assigned is not really a named entity. So, considering this as the errors of the model, we replace such a sequence of I-XXXs in the output by a sequence of “o”. After applying this post-processing on the output produced by the HMM model, the final output file is generated.\nOur developed NER system has been evaluated using the traditional precision (P), recall (R) and F-measure (F). For training, tuning and testing our system, we have used the dataset for English language, released by the organizers of the ESM-IL task- FIRE 2015. The organizers of the ESM-IL task- FIRE 2015 released the data in two phases: in the first phase, training data is released along with the corresponding NE annotation file. In the second phase, the test data is released and no NE annotation file is provided. The contestants are instructed to generate NE annotation file for test data using their developed systems. NE annotation file for test data was finally sent to the organizers for evaluation. The organizers evaluate the different runs submitted by the various teams and send the official results to the participating teams.\nWe have shown in Table 3 the results obtained by our submitted run indicated by team id “KSarkar – JU”. As we can see from the table, our system outperforms the other systems participated in the ESM-IL task. Table 3 only shows the FIRE 2015 official results for English language only. The overall FIRE 2015 official results for ESM-IL task including all languages are shown in Table 4."
    }, {
      "heading" : "6. CONCLUSION",
      "text" : "This paper describes a named entity recognition system for Entity Extraction from Social Media Text in English language. The features such as Gazetteer list, POS tag and some other word level features have been introduced into the HMM model. The experimental results show that our system is the best performer among the systems participated in the ESM-IL task for English language. The named entity recognition system has been developed using Visual Basic platform so that a suitable user interface can be designed for the novice users. The system has been designed in such a way that only changing the training corpus in a file can make the system portable to a new Indian\nlanguage."
    } ],
    "references" : [ {
      "title" : "The New York University System MUC- 6 or Where’s the syntax",
      "author" : [ "R. Grishman" ],
      "venue" : "In Proceedings of the Sixth Message Understanding Conference",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1995
    }, {
      "title" : "Internal and external evidence in the identification and semantic categorization of proper names",
      "author" : [ "D.D. McDonald" ],
      "venue" : "In B. Boguraev and J. Pustejovsky, editors, Corpus Processing for Lexical Acquisition,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1996
    }, {
      "title" : "Evaluationof an algorithm for the recognition and classification of proper names",
      "author" : [ "T. Wakao", "R. Gaizauskas", "Y. Wilks" ],
      "venue" : "In Proceedings of COLING-96",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1996
    }, {
      "title" : "Nymble: A High Performance Learning Name-finder",
      "author" : [ "D.M. Bikel", "S. Miller", "R. Schwartz", "R. Weischedel" ],
      "venue" : "In Proceedings of the Fifth Conference on Applied Natural Language Processing,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1997
    }, {
      "title" : "A Maximum Entropy Approach to Named Entity Recognition",
      "author" : [ "A. Borthwick" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1999
    }, {
      "title" : "Named Entity Recognition in Hindi using MEMM",
      "author" : [ "N. Kumar", "P. Bhattacharyya" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2006
    }, {
      "title" : "Rapid Development of Hindi Named Entity Recognition using Conditional Random Fields and Feature Induction (Short Paper)",
      "author" : [ "Li", "Wei", "A. McCallum" ],
      "venue" : "In ACM Transactions on Computational Logic",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2004
    }, {
      "title" : "A Hybrid Approach for Named Entity and Sub-Type Tagging",
      "author" : [ "R. Srihari", "C. Niu", "Li", "Wei" ],
      "venue" : "In Proceedings of the sixth conference on Applied natural language processing",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2000
    }, {
      "title" : "Language Independent Named Entity Recognition Combining Morphological and Contextual Evidence",
      "author" : [ "S. Cucerzan", "D. Yarowsky" ],
      "venue" : "In Proceedings of the Joint SIGDAT Conference on EMNLP and VLC,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1999
    }, {
      "title" : "Rapid Development of Hindi Named Entity Recognition using Conditional Random Fields and Feature Induction (Short Paper)",
      "author" : [ "Li", "Wei", "A. McCallum" ],
      "venue" : "Vira - Charotar",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2004
    }, {
      "title" : "A conditional random field approach for named entity recognition in Bengali and Hindi",
      "author" : [ "Ekbal A", "S. Bandyopadhyay" ],
      "venue" : "Linguistic Issues in Language Technology,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2009
    }, {
      "title" : "A practical part-of-speech tagger for Bengali",
      "author" : [ "Sarkar K", "V. Gayen" ],
      "venue" : "In Proceedings of the third International conference on Emerging Applications of Information Technology (EAIT),",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2012
    }, {
      "title" : "An HMM based named entity recognition system for indian languages: the JU system at ICON 2013.",
      "author" : [ "V. Gayen", "K. Sarkar" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "MontyLingua: an end to end natural language processor with common sense",
      "author" : [ "H. Liu" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2004
    }, {
      "title" : "TnT – A statistical part-of-speech tagger",
      "author" : [ "T. Brants" ],
      "venue" : "In proceedings of the 6 Applied NLP Conference,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2000
    }, {
      "title" : "Speech and Language Processing: An Intoduction to Natural Language Processing, Computational Linguistics and Speech Recognition, Preason Education Series",
      "author" : [ "D. Jurafsky", "J.H. Martin" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "The rule based approaches typically use a set of hand crafted rules [1][2][3].",
      "startOffset" : 68,
      "endOffset" : 71
    }, {
      "referenceID" : 1,
      "context" : "The rule based approaches typically use a set of hand crafted rules [1][2][3].",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 2,
      "context" : "The rule based approaches typically use a set of hand crafted rules [1][2][3].",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 3,
      "context" : "Several ML techniques have already been applied for the NER tasks such as Markov Model (HMM) [4], Maximum Entropy (MaxEnt) [5][6], Conditional Random Field (CRF)[7] etc.",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 4,
      "context" : "Several ML techniques have already been applied for the NER tasks such as Markov Model (HMM) [4], Maximum Entropy (MaxEnt) [5][6], Conditional Random Field (CRF)[7] etc.",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 5,
      "context" : "Several ML techniques have already been applied for the NER tasks such as Markov Model (HMM) [4], Maximum Entropy (MaxEnt) [5][6], Conditional Random Field (CRF)[7] etc.",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 6,
      "context" : "Several ML techniques have already been applied for the NER tasks such as Markov Model (HMM) [4], Maximum Entropy (MaxEnt) [5][6], Conditional Random Field (CRF)[7] etc.",
      "startOffset" : 161,
      "endOffset" : 164
    }, {
      "referenceID" : 7,
      "context" : "(2000) [8] combines MaxEnt, Hidden Markov Model (HMM) and handcrafted rules to build an NER system.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "Both the linguistic approach [1][3] and the ML based approach[5][8] may use gazetteer lists.",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 2,
      "context" : "Both the linguistic approach [1][3] and the ML based approach[5][8] may use gazetteer lists.",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 4,
      "context" : "Both the linguistic approach [1][3] and the ML based approach[5][8] may use gazetteer lists.",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 7,
      "context" : "Both the linguistic approach [1][3] and the ML based approach[5][8] may use gazetteer lists.",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 8,
      "context" : "The NER tasks for Hindi have been presented in [9][10][11].",
      "startOffset" : 47,
      "endOffset" : 50
    }, {
      "referenceID" : 9,
      "context" : "The NER tasks for Hindi have been presented in [9][10][11].",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 10,
      "context" : "The NER tasks for Hindi have been presented in [9][10][11].",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 11,
      "context" : "In general, HMM based sequence labeling tasks such as POS tagging use words in a sentence as an observation sequence [12] 13].",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 13,
      "context" : "But, we use MontyTagger [14] to assign POS tags to the data released for the task, that is, some additional information such as POS for each token in a tweet becomes now available.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 14,
      "context" : "Considering a special tag tn+1 to indicate the end sentence boundary and two special tags t-1 and t0 at the starting boundary of the sentence and adding these three special tags to the tag set [15], gives the following equation for NE tagging:",
      "startOffset" : 193,
      "endOffset" : 197
    }, {
      "referenceID" : 12,
      "context" : "To overcome the data sparseness problem, tag trigram probability is smoothed using deleted interpolation technique [13][15] which uses the maximum likelihood estimates from counts for tag trigram, tag bigram and tag unigram.",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 14,
      "context" : "To overcome the data sparseness problem, tag trigram probability is smoothed using deleted interpolation technique [13][15] which uses the maximum likelihood estimates from counts for tag trigram, tag bigram and tag unigram.",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 11,
      "context" : "The observation probability of a observed triplet <word, X-tag, meta-tag >, which is the observed symbol in our case, is computed using the following equation [12][13].",
      "startOffset" : 159,
      "endOffset" : 163
    }, {
      "referenceID" : 12,
      "context" : "The observation probability of a observed triplet <word, X-tag, meta-tag >, which is the observed symbol in our case, is computed using the following equation [12][13].",
      "startOffset" : 163,
      "endOffset" : 167
    }, {
      "referenceID" : 15,
      "context" : "This is a standard application of the classic dynamic programming algorithm[16].",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 15,
      "context" : "We have used the Viterbi algorithm presented in [16] for finding the most likely tag sequence for a given observation sequence.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 12,
      "context" : "We find the observation probabilities of such unknown pseudo words using suffix analysis of all rare pseudo words (frequency <=2) in the training corpus for the concerned language [13][15].",
      "startOffset" : 180,
      "endOffset" : 184
    }, {
      "referenceID" : 14,
      "context" : "We find the observation probabilities of such unknown pseudo words using suffix analysis of all rare pseudo words (frequency <=2) in the training corpus for the concerned language [13][15].",
      "startOffset" : 184,
      "endOffset" : 188
    } ],
    "year" : 2015,
    "abstractText" : "This paper presents the experiments carried out by us at Jadavpur University as part of the participation in FIRE 2015 task: Entity Extraction from Social Media Text Indian Languages (ESM-IL). The tool that we have developed for the task is based on Trigram Hidden Markov Model that utilizes information like gazetteer list, POS tag and some other word level features to enhance the observation probabilities of the known tokens as well as unknown tokens. We submitted runs for English only. A statistical HMM (Hidden Markov Models) based model has been used to implement our system. The system has been trained and tested on the datasets released for FIRE 2015 task: Entity Extraction from Social Media Text Indian Languages (ESM-IL). Our system is the best performer for English language and it obtains precision, recall and F-measures of 61.96, 39.46 and 48.21 respectively.",
    "creator" : "Microsoft® Office Word 2007"
  }
}