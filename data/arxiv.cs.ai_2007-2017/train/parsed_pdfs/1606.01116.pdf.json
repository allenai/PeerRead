{
  "name" : "1606.01116.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "THE BELIEF NOISY-OR MODEL APPLIED TO NETWORK RELIABILITY ANALYSIS",
    "authors" : [ "KUANG ZHOU" ],
    "emails" : [ "kzhoumath@163.com", "arnaud.martin@univ-rennes1.fr", "quanpan@nwpu.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems c© World Scientific Publishing Company"
    }, {
      "heading" : "THE BELIEF NOISY-OR MODEL APPLIED TO NETWORK RELIABILITY ANALYSIS",
      "text" : ""
    }, {
      "heading" : "KUANG ZHOU",
      "text" : "Northwestern Polytechnical University\nXi’an, Shaanxi 710072, China\nDRUID, IRISA, University of Rennes 1\nRue E. Branly, 22300 Lannion, France\nkzhoumath@163.com"
    }, {
      "heading" : "ARNAUD MARTIN",
      "text" : "DRUID, IRISA, University of Rennes 1\nRue E. Branly, 22300 Lannion, France arnaud.martin@univ-rennes1.fr"
    }, {
      "heading" : "QUAN PAN",
      "text" : "Northwestern Polytechnical University\nXi’an, Shaanxi 710072, China quanpan@nwpu.edu.cn\nReceived (received date)\nRevised (revised date)\nOne difficulty faced in knowledge engineering for Bayesian Network (BN) is the quantification step where the Conditional Probability Tables (CPTs) are determined. The number of parameters included in CPTs increases exponentially with the number of parent variables. The most common solution is the application of the so-called canonical gates. The Noisy-OR (NOR) gate, which takes advantage of the independence of causal interactions, provides a logarithmic reduction of the number of parameters required to specify a CPT. In this paper, an extension of NOR model based on the theory of belief functions, named Belief Noisy-OR (BNOR), is proposed. BNOR is capable of dealing with both aleatory and epistemic uncertainty of the network. Compared with NOR, more rich information which is of great value for making decisions can be got when the available knowledge is uncertain. Specially, when there is no epistemic uncertainty, BNOR degrades into NOR. Additionally, different structures of BNOR are presented in this paper in order to meet various needs of engineers. The application of BNOR model on the reliability evaluation problem of networked systems demonstrates its effectiveness.\nKeywords: Evidential network; Belief Noisy-OR; Conditional belief function; Uncertainty; Network reliability\n1\nar X\niv :1\n60 6.\n01 11\n6v 1\n[ cs\n.A I]\n3 J\nun 2\n01 6"
    }, {
      "heading" : "1. Introduction",
      "text" : "Bayesian Network (BN) is a probabilistic graphical model that represents a set of random variables and their conditional dependencies via a directed acyclic graph (DAG)1. BN can be used to learn causal relationships and gain understanding of a problem domain. It allows probabilistic beliefs to be updated automatically when new information becomes available. BN is also able to represent multi-attribute correlated variables and to perform relevant simulations or diagnoses. Owing these advantages, it has been widely applied on the problem of reliability or safety analysis for both static and dynamic systems2–5.\nIn BN, Conditional Probability Tables (CPTs) should be defined to measure the relationships between variables. However, it has been pointed out that it is usually difficult to quantify the CPTs due to the complexity6. One of the most appropriate solutions to this problem is the Noisy-OR (NOR) gate, which can be attributed to Pearl 7 . Traditional NOR can only deal with the binary variables. Srinivas 8 extended NOR for n-ary input and output variables, and arbitrary functions other than Boolean OR function can be used. But it has not taken into account the uncertainty on parameters and the state which often exists in practice. Considering such uncertainty, Fallet et al. 9 proposed the imprecise extensions of Noisy OR (ImNOR) thereafter. Nevertheless, there are still some problems for ImNOR which will be discussed in detail later.\nThe theory of belief functions, also called Dempster–Shafer Theory (DST), offers a mathematical framework for modeling uncertainty and imprecise information10. Belief functions are widely employed in various fields, such as data classification11–13, data clustering14–17, social network analysis18–21 and statistical estimation22–24. The concept of evidential networks, which is a combination of belief function theory and Bayesian network, is proposed to model system reliability with imprecise knowledge25;26. Recently, Yaghlane and Mellouli 27 presented another definition of evidential networks based on Transferable Belief Model (TBM)28, Dempster-Shafer rule of combination, and binary joint trees.\nThe objective of this work is to enrich the existing NOR structures by integrating several types of uncertainty. Under the framework of belief functions, the Belief Noisy-OR (BNOR) model is put forward. The uncertainty of variable states can be expressed by the power set of discernment frame. The uncertainty of parameters is described by probability intervals based on which the basic belief assignments are determined. The model can model causal connections among variables as well as taking random and epistemic uncertainty into account. The proposed BNOR model can be implemented in evidential networks26, and belief reasoning is proceeded through evoking junction tree inference algorithms25;26.\nThe remainder of this paper is organized as follows. In Section 2, the basic knowledge about Noisy-OR gate and Dempster–Shafer theory is briefly introduced. The BNOR model is presented in detail in Section 3. In order to show the effectiveness of BNOR in real practice, Section 4 discusses about how to apply BNOR\non the problem of network reliability evaluation. Conclusions are drawn in the final section."
    }, {
      "heading" : "2. Background",
      "text" : "In this section some related preliminary knowledge will be presented. The definition of Noisy-OR gate will be described first, then some basis of belief function theory will be recalled.\n2.1. Noisy-OR model\nThe Noisy-OR structure was introduced by Pearl 7 to reduce the elicitation effort in building a Bayesian network. The general properties of the Noisy-OR function and its generalizations were captured by Heckerman and Breese 29 in their definition of causal independence.\nLet us consider a binary variable Y with n binary parent variables Xi (see Figure 1-a). These variables can be either “True” (T ) or “False” (F ). Each Xi exerts its influence on Y independently. To build a Bayesian network, X must be associated with a probability distribution p(Y |X1, · · · , Xn). The number of independent parameters included in the complete specification of p(Y |X1, · · · , Xn) is 2n. The Noisy-OR function is an attractive way where we can use fewer parameters to specify p(Y |X1, · · · , Xn). The idea is to start with n probability values pi, which is the probability that {Y = T} conditional on {Xi = T} and {Xj = F} for j 6= i, i.e.,\npi = p { Y = T ∣∣∣Xi = T, {Xj = F}nj=1,j 6=i} . (1)\nProbability pi is often called “link probability” and illustrates the fact that the causal dependency between Xi and Y can be inhibited. If the state of variable Xi is T , then there is chance 1−pi that it is flipped to F ; If Xi is F , then it stays with F . Denote the result of flipping (or not) Xi by ξi, i = 1, 2, · · · , n (see Figure 1-b), then\np(Y = α|X1,X2, · · · , Xn) = ∑\nα1∨···∨αn=α p(ξ1 = α1|X1) · · · p(ξn = αn|Xn), (2)\nwhere the values of α, αi are either T or F . A Noisy-OR function is thus a disjunction of “noisy” versions of Xi 30. Let XT be the set of Xi whose state is “True”, and XF be the set of Xi which are “False”. The distribution of Y conditional on X1, X2, · · · , Xn is\np (Y = T |X1, X2, · · · , Xn) = 1− ∏\ni:Xi∈XT\n(1− pi). (3)\nWe can see the number of independent parameters required for the conditional probability function is reduced from 2n to 2n31. The following example shows how to create CPTs by the use of NOR gate. Example 1. Let us consider the Alarm System (see Figure 2). Both a burglar (B) and an earthquake (E) can set the alarm (A) off but neither always do so. The mechanism of the burglar and earthquake is different, thus they can be regarded as independent causes. Variable B ′ (respectively, E ′ ) describes the result after flipping (or not) of B (respectively, E). Assume all variables are binary with values {T, F}, where T represents the corresponding event happens, while F means not.\nApparently, A is F only if both the occurrence of burglar and earthquake do\nnot evoke the alarm due to inhibition. Using the Noisy-OR model, we can get,\np(A = F |B,E) = ∏ i∈XT (1− pi), (4)\nThe conditional probability on {A = T} can be obtained easily:\np(A = T |B,E) = 1− ∏ i∈XT (1− pi). (5)\nThe following CPT can be got using Eqs. (4) and (5).\n2.2. Belief function theory\nTo apply the theory of belief functions, we consider a set of q mutually exclusive & exhaustive elements, called the frame of discernment, defined by\nΘ = {θ1, θ2, · · · , θq}. (6)\nLet X be a variable taking values in Θ. The function m : 2Θ → [0, 1] is said to be the basic belief assignment (bba) on 2Θ, if it satisfies:\n∑ A⊆Θ m(A) = 1, (7)\nand\nm(∅) = 0. (8)\nThe constraint on ∅ defined by Eq. (8) is not mandatory. It assumes that one and only one element in Θ is true (closed-world assumption). In the case where m(∅) 6= 0, the model accepts that none of the elements could be true (open-world assumption)28. The closed-world assumption is accepted hereafter. Every A ∈ 2Θ such that m(A) > 0 is called a focal element. Uncertain and imprecision knowledge about the actual value of X can be represented by a bba distributed on 2Θ:\nMX = [m (A1) ,m (A2) , · · · ,m (A2q−1)] , (9)\nwhere A1, A2, · · · , A2q−1 are the elements of 2Θ arranged by natural order. The credibility and plausibility functions are derived from a bbam as in Eqs. (10) and (11).\nBel(A) = ∑ B⊆A m(B), ∀A ⊆ Θ, (10)\nPl(A) = ∑\nB∩A6=∅\nm(B), ∀A ⊆ Θ. (11)\nBel(A) measures the minimal belief on A justified by available information on B(B ⊆ A) , while Pl(A) is the maximal belief on A justified by information on B which are not contradictory with A (A ∩ B 6= ∅). The bba can be recovered from credibility functions through the fast Möbius transformations32:\nm(A) = ∑ B⊆A (−1)|A−B|Bel(B),∀A ⊆ Θ (12)\nThe relations between Bel and Pl can be established as follows:\nBel(A) = 1− Pl(A) , P l(A) = 1−Bel(A), (13)\nwhere A denotes the complementary set of A. Bel(A) is often called the doubt in A. Let Pr(A) denote the probability of the hypothesis A, it is easy to get:\nBel(A) ≤ Pr(A) ≤ Pl(A). (14)\nProbability Pr(A) belongs to the interval [Bel(A), P l(A)] but its exact value remains unknown. The bounding property (14) has been well defined in the work of Shafer10.\nFerson et al. 33 argued that each Dempster-Shafer structure specifies a unique probability-box (p-box), and that each p-box specifies an equivalent class of Dempster-Shafer structure26. P-boxes are sometimes considered as a granular approach of imprecise probabilities34, which are arbitrarily sets of probability distributions. Probability interval [P (A), P (A)], which is the restricted case of p-box26, can also be used to describe the imprecision of a probability measure. The relation between a probability interval and a bba can be directly obtained26:\n[P (A), P (A)] = [Bel(A), P l(A)]. (15)\nBelief functions can be transformed into probability distribution functions by Smets method36, where each mass of belief m(A) is equally distributed among the elements of A. This leads to the concept of pignistic probability, BetP . For all θi ∈ Θ, we have\nBetP (θi) = ∑\nA⊆Θ|θi∈A\nm(A)\n|A|(1−m(∅)) , (16)\nwhere |A| is the cardinality of set A (number of elements of Θ in A). Pignistic probabilities can help us make a decision."
    }, {
      "heading" : "3. Belief Noisy-OR model",
      "text" : "We start with the discussion of the uncertainty problem in NOR model. One of the existing approaches to express the uncertain information in NOR is the ImNOR model proposed by Fallet et al. 9 . We will analyze the drawbacks of ImNOR and present a new NOR gate using the theory of belief functions.\n3.1. The uncertainty problem in NOR structure\nFrom an industrial point of view, it is classically accepted that observations made on the system are partially realized35. For example, it is difficult to determine whether an earthquake has happened, especially when the magnitude is small and the hypo-center is deep. In such a case, there is some uncertainty on the state of boolean parent variables and it is intuitive for experts to give a positive belief on the ignorant modality {T, F}. Simon and Weber 26 have investigated a solution based on evidential network and the theory of belief functions to take into account the uncertainty on the state of binary parent variables in AND/OR gates. Simon et al. 25 combined belief function theory with Bayesian reasoning to deal with this type of epistemic uncertainty. Based on Simon and Weber’s modelling formalization, Fallet et al. 9 proposed imprecise extensions of the Noisy-OR (ImNOR) structure to deal with the uncertainty on the state of variables and link probabilities.\nImNOR describes the uncertainty on variable state and link probabilities separately by calculating the lower bounds of the conditional probability P (X|Pa(X)), where Pa(X) denotes the parent nodes of X. Consider the causal network shown in Figure 1-a. As before, the discernment frame of each variable is {T, F}, and each Xi is interpreted as an independent “cause” of Y . We can express our epistemic uncertainty on variables’ state by assigning the basic belief to ignorant modality {T, F}. This modality indicates that the variable is exclusively in {T} or {F} state without distinguishing exactly in which state it is9. Different from Noisy-OR model, in ImNOR, each active Xi can evoke Y with unknown probability pi ∈ [piL, piU ], where piU − piL measures the degree of uncertainty on our knowledge of inhibition. Fallet provided us the formulas (see Eqs. (17)–(19)) to calculate the conditional belief mass functions1:\nm(Y = {T}|X1, X2, · · · , Xn) = 1− ∏\n{i:Xi={T}}\n(1− piL), (17)\nm(Y = {F}|X1, X2, · · · , Xn) = ∏\n{i:Xi={T}}\n(1− piU ) ∏\n{i:Xi={T, F} }\n(1− piU ), (18)\nm(Y = {T, F} |X1, X2, · · · , Xn) = ∏\n{i:Xi={T}}\n(1−piL)− ∏\n{i:Xi={T}}\n(1−piU ) ∏\n{i:Xi={T, F} }\n(1−piU ).\n(19)\nFrom Eq. (17), we can get: m (Y = {T}|X1 · · ·Xk = {T, F} · · ·Xn) = 1− ∏\n{i:Xi={T},i∈{1,2,··· ,k−1,k+1,··· ,n}}\n(1−piL),\n(20)\n1As the belief functions are defined on the power set of discernment frame, we use {T} ({F}) instead of T (F ) to denote variable state here.\nand m (Y = {T}|X1 · · ·Xk = {F} · · ·Xn) = 1− ∏\n{i:Xi={T},i∈{1,2,··· ,k−1,k+1,··· ,n}}\n(1−piL).\n(21)\nIt can be seen that the belief on the proposition that “variable Y is {T}” does not change when some prior precise information about the parent variables becomes available (The state of Xk changes from {T, F} to {T}):\nm(Y = {T}|X1, · · · , Xi = {T, F}, · · ·Xn) = m(Y = {T}|X1, · · · , Xi = {F}, · · · , Xn). (22)\nBesides, there is another defect for the above method when calculating the belief mass on the conditional events where there is no working components (Xi 6= T, i = 1, 2, · · · , n). For example, when we want to know\nm(Y |Xi = {F}, i = 1, 2, · · · , n− 1, Xn = {T, F}),\nthe following conditional belief mass functions can be got by Eq. (18):\nm(Y = {F}|Xi = {F}, i = 1, 2, · · · , n− 1, Xn = {T, F}) = 1− PnU , (23)\nm(Y = {F}|Xi = {T,F}, i = 1, 2, · · · , n− 1, Xn = {T, F}) = PnU . (24)\nAs can be seen, the lower bound of probability pn, pnL, has no effect on the final results. That is to say, the conditional belief mass assignment remains unchanged once the upper bound of pn is fixed no matter how long the uncertain interval is. This is against our common sense. Since the length of the interval measures the degree of uncertainty on the available information, the longer the interval is, more mass value should be given to the ignorant state {T, F}.\n3.2. Belief Noisy-OR structure\nWe introduce here the Belief Noisy-OR structure to express the epistemic uncertainty on the state of the variables and link probabilities at the same time. Consider the causal network where Xi, i = 1, 2, · · · , n are the parents of Y (Figure 1-a). Let us first discuss the uncertainty on link probability pi. This parametric uncertainty can be modeled by an interval [piL, piU ], with 0 ≤ piL ≤ pi ≤ piU ≤ 1. Thus the inhibition probability interval of Xi is [1−piU , 1−piL]. In order to use evidential reasoning, the probability intervals should be transformed to belief function structures. For convenience, n auxiliary variables, X ′\ni , i = 1, 2, · · · , n are introduced to represent the result of flipping or not Xi. From the boundary property of belief functions (Eq. (14)), we can get\nBel(X ′\ni = {T}|Xi = {T}) = piL, (25)\nPl(X ′\ni = {T}|Xi = {T}) = piU , (26)\nThe associated belief mass distribution can be easily determined by Eq. (12).\nThe corresponding conditional bba in 2Θ can be defined as:\nm(X ′ i = {T}|Xi = {T}) = Bel(X ′ i = {T}|Xi = {T}) = piL, (27)\nm(X ′ i = {F}|Xi = {T}) = Bel(X ′ i = {F}|Xi = {T}) (28)\n= 1− Pl(X ′\ni = {T}|Xi = {T}) (29) = 1− piU , (30)\nand\nm(X ′\ni = {T, F} |Xi = {T}) = piU − piL, (31)\nwhere Eq. (29) is obtained by the relation between Bel and Pl. Eqs. (27)–(31) express the uncertain knowledge of link probabilities and variable states together in the form of belief mass distributions.\nWhen Xi = {F}, Y is sure to stay in state {F} . Thus the bba conditioned Xi = {F} is easy to determine:\nm(X ′\ni = {T}|Xi = {F}) = 0, (32)\nm(X ′\ni = {F}|Xi = {F}) = 1, (33)\nm(X ′\ni = {T,F}|Xi = {F}) = 0. (34)\nHowever, the bba on the condition Xi = {T,F} is more complicated. The following equations with unknown parameters α, β, γ (α+β+γ = 1) are first given, and then the methods for designing the three parameters will be discussed later.\nm(X ′\ni = {T}|Xi = {T, F}) = α, (35)\nm(X ′\ni = {F}|Xi = {T, F}) = β, (36)\nm(X ′\ni = {T, F}|Xi = {T, F}) = γ. (37)\nEqs. (35)–(37) show that in BNOR, the belief on the uncertain state Xi = {T, F} may be flipped into all the possible states by different ratios. Parameters α, β, γ are adjustable.\nGenerally, the values of α, β, γ can be given by the proportions of belief mass on Xi = {T, F} which may be transferred to Xi = {T} (noted by λ1, 0 ≤ λ1 ≤ 1),\nXi = {F} (noted by λ2, 0 ≤ λ2 ≤ 1) and Xi = {T, F} (noted by λ3, 0 ≤ λ3 ≤ 1) (λ1 + λ2 + λ3 = 1) respectively:\nα = λ1m(X ′ i = {T}|Xi = {T}) = λ1piL, (38)\nβ = λ1m(X ′ i = {F}|Xi = {T}) + λ2 = λ1(1− piU ) + λ2, (39)\nγ = λ1m(X ′ i = {T, F}|Xi = {T}) + λ3 = λ1(piU − piL) + λ3. (40)\nParameter λ3 in Eq. (40) indicates the uncertainty on the state of Xi, and it should be in direct proportion to m(Xi = {T, F}) , η. It is easy to know that if η 6= 0, λ3 6= 0. For simplicity, let λ3 = η and λ1 = λ, λ2 = 1− λ− η, then,\nα = λm(X ′\ni = {T}|Xi = {T}) = λpiL, (41)\nβ = λm(X ′\ni = {F}|Xi = {T}) + (1− λ− η) = λ(1− piU ) + (1− λ− η), (42)\nγ = λm(X ′\ni = {T, F}|Xi = {T}) + η = λ(piU − piL) + η. (43)\nThis is similar to the optimistic coefficient method in the decision theory. So we call this general approach Optimistic coefficient-BNOR (OCBNOR), where λ (0 ≤ λ ≤ 1) is the optimistic coefficient.\nNote that Eqs. (41)–(43) propagate the uncertainty on variable state and link probabilities simultaneously. The ignorant modality Θ = {T, F} represents the uncertainty on the state and the belief mass assignment m(X ′\ni |Xi) deals with the uncertain information of link probabilities.\nDifferent λ values can be set to obtain results under various requirements. For instance, if we want to make an optimistic decision, the belief to Xi = {T, F} could transferred to X ′\ni = {T} as most as possible. Let λ = 1, then\nα = piL, β = 1− piU − η, γ = piU − piL + η. (44)\nThis structure is called Optimistic Belief Noisy-OR (OBNOR). By contrary, when a pessimistic decision is required, all the belief on Xi = {T, F} could transferred to the child state X ′\ni = {F}, thus\nα = 0, β = 1− η, γ = η, (45)\nwe call this model Pessimistic Belief Noisy-OR (PBNOR).\nThe decision-makers can make a compromise between optimism and pessimism. According to the idea of pignistic probability transformation36, the belief on the subsets of the discernment framework should be given to the single elements equally. Then we can get:\nα = 1\n2 m(X\n′ i = {T}|Xi = {T}) = 1\n2 piL, (46)\nβ = 1\n2 m(X\n′ i = {F}|Xi = {T}) + 1 2 − η = 1 2 (1− piU ) + 1 2 − η, (47)\nγ = 1\n2 m(X\n′ i = {T, F}|Xi = {T}) + η = 1\n2 (piU − piL) + η. (48)\nBNOR with the above α, β, γ is called Temperate Belief Noisy-OR (TBNOR) model. It is easy to see that OBNOR, PBNOR and TBNOR are special cases of OCBNOR.\nLeast Committed Belief Noisy-OR (LC-BNOR), just as the name implies, suggests us that the least committed belief mass function should be selected holding the view that one should never give more belief than justified. It satisfies a form of skepticism, of noncommitment, of conservatism in the allocation of the beliefs37. At this time,\nα = 0, β = 0, γ = 1. (49)\n3.3. From Bayesian Networks to Evidential Networks\nIn order to apply BNOR structure, it is important to find a relevant model to encode and to propagate the causal relations included in BNOR. Here the evidential network model proposed by Simon and Weber 26 is taken as a solution to implement BNOR. Similar to BN, evidential networks allow dealing with a lot of variables and modeling the dependencies between variables. From BNOR, the conditional mass distribution\nm(Y = {T}|Xi), m(Y = {F}|Xi), m(Y = {T, F}|Xi)\ncan be established, which plays a similar role as CPTs in Bayesian networks. If the prior belief mass values of the parent nodes X1, · · · , Xn are given, then the junction tree inference algorithm can be evoked to calculate the marginal mass distribution of the child node Y . Once the bba of Y is got, the belief and plausibility functions of Y can be obtained accordingly.\n3.4. The Pignistic probability and decision making\nThe transferable belief model (TBM)36 is an interpretation of the Dempster-Shafer theory of evidence, where beliefs can be held at two levels — credal level and pignistic level. When an agent has to select an optimal action among an exhaustive set of actions, rationality principles lead to the use of a probability measure. Therefore, when a decision has to be made, the bba obtained by BNOR model must be\ntransformed into a probability measure38. One of the most commonly used transformation approaches is Smets method shown in Eq. (16). In our cases, Θ = {T, F}. If the following bba is got,\nm(X = {T}) = m1,m(X = {F}) = m2,m(X = {T,F}) = m3, (50)\nwe can get the following pignistic probability:\nBetP (X = T ) = m1 + m3 2 , BetP (X = F ) = m2 + m3 2 . (51)\nIf the conditional belief mass functions is obtained,\nm(Y = {T}|X) = mX1 ,m(Y = {F}|X) = mX2 ,m(Y = {T,F}|X) = mX3 , (52)\nthe conditional pignistic probability can be got as follows:\nBetP (Y = T |X) = mX1 + mX3\n2 , BetP (Y = F |X) = mX2 + mX3 2 . (53)\nExample 2. Here we use the example of Alarm System again to illustrate the behavior of different BNOR models and ImNOR. The intervals of the link probabilities of burglar and earthquake are p1 ∈ (0.6, 0.8) and p2 ∈ (0.7, 0.9) respectively. The prior distribution of B and E are given:\nm(B = {T}) = 0.4,m(B = {F}) = 0.6,m(B = {T, F}) = 0,\nm(E = {T}) = 0.3,m(E = {F}) = 0.6,m(E = {T, F}) = 0.1.\nThe corresponding BNOR model is shown in Figure 3. The conditional mass function m(A|B,E) based on different BNOR models and ImOR are displayed in Tables 2–4. Figure 4 illustrates the value of m(A|B = {T}, E = {T,F}) by different schemes. It can be seen that, ImNOR provides a pessimistic decision for m(A = {T}|·), but an optimistic one for m(A = {F}|·). This is counter-intuitive as ImNOR holds opposite attitudes towards one event.\nFrom Table 2 we can see, by the use of ImNOR,\nm(A = {F}|B = {T}, E = {T}) = m(A = {F}|B = {T}, E = {T, F}), (54)\nbut by BNOR,\nm(A = {F}|B = {T}, E = {T}) < m(A = {F}|B = {T}, E = {T, F}). (55)\nEq. (55) fits with our common sense. As soon as we know the earthquake has happened for sure, the less belief should be holding for the proposition the alarm has not gone.\nLet the link probability of earthquake be p2 ∈ (0.7, 0.9), while the link probability of burglar is set to be p1 ∈ (α, 0.8). When α→ 0.8, the uncertainty on p1 becomes less. Consequently the uncertainty on the state of Alarm should also decrease. However, as shown in Figure 5, the values of m(A = {T, F}|B = {T, F}, E = {F}) and m(A = {T, F}|B = {T, F}, E = {T, F}) by ImNOR remain unchanged although the information for p1 becomes more precise. The corresponding results using BNOR show that the belief mass assigned to the uncertainty state of A decreases with the increasing precision of the information on p1. Specially, if there is no epistemic uncertainty on p2, and the uncertainty on p1 declines to 0 (α = 0.8), the belief mass given to A = {T, F} also becomes zero (see Figure 5-a).\nMarginal mass m(A) can be obtained by ImNOR and different BNORs, and the results are shown in Table 5 and Figure 6. It is shown that OBNOR provides optimistic results while PBNOR produces a pessimistic one. In order to make a compromise, we can adjust the optimistic coefficient (λ). Also the contradiction attitudes of ImNOR can be found here. Thus the BNOR methods are more reasonable and informative.\nUsing Eqs. (51) and (53), the (conditional) belief mass functions can be trans-\nferred to (conditional) pignistic probabilities. The results of\nBetP (A|B = {T}, E = {T,F})\nand BetP (A) are displayed in Figure 7. It can be seen that BNOR can provide us\nabundant information for decisions with different special requirements. By comparison, ImNOR is more temperate. This is due to the fact that ImNOR assigns more mass values to the vague state {T, F}. However, if we want to hold the principle that more belief should be given to the uncertain state, LC-BNOR is a better choice (see Figures 4-b and 6-b)."
    }, {
      "heading" : "4. Network reliability analysis",
      "text" : "In this section we will discuss the application of BNOR on the problem of network reliability analysis. The definition of network reliability and the traditional Bayesian solution are first recalled. Then the reliability evaluation strategy using BNOR model will be described in detail.\n4.1. Network reliability and Bayesian network solution\nThe network reliability considered here is two-terminal reliability, defined as the probability that there is an operative path between source nodes n1 and sink nodes nN in the network. Nodes are assumed to be operational at all times, and edge failures are assume to be statistically independent.\nLet graph G(N,E) represent a network, where N denotes the set of nodes and E is the set of links. For the network shown in Figure 8-a, N = {n1, n2, n3, n4}, E = {e1,e2, e3, e4}. Define |N | new variables, Ni, i = 1, 2, · · · , |N | , indicating whether the communication between n1 and ni is successful. Let N +(ni) = {nj | < nj , ni >∈ E}, for every element of which sets, nj , there is a path from nj to ni. And let E\n+(ni) = {ek =< nj , ni > |nj ∈ N+(ni)} denote the sets of edges directed to node ni.\nZhen et al. 39 presented a method for reliability evaluating of networks based on\nBN. The nodes and edges of BN can be created according to G(N,E):\n(1) The root nodes of BN are N1 and the edges in E. (2) The non-root nodes of BN are Ni, i 6= 1. And\nPa(Ni) = { Nj |nj ∈ N+(ni) } ∪ { ek|ek ∈ E+(ni) } . (56)\nBayesian networks’ inference algorithms can be evoked then to calculate the network reliability P (Ns). The BN framework for the network described in Figure 8-a can be seen in Figure 8-b.\n4.2. Reliability evaluation using BNOR\nFor the network shown in Figure 9, its reliability can be defined by the probability that there is a working path connected from n1 to n5. The network is operating if\nthe two terminal nodes n1 and n5 are connected by operational edges. Let S denote the state of the network. It has binary states with T (working) or F (fail). The values for failure rates of each edge are\nλe1 = λe3 = λe5 = 1.5 ∗ 10−3 h−1, λe2 = λe4 = λe6 = 1.8 ∗ 10−3 h−1.\nConsider the mission time t = 200 h. The probability distribution of each edge is given in Table 6.\nThe traditional Bayesian network approach is first adopted to calculate the reliability. Using the method described in Section 4.1, we can create a Bayesian network solution model (see Figure 10). By applying the Junction Tree (JT) inference algorithm, we can obtain the exact value of the network reliability p(S = T ) = 0.9148.\nIn the next two subsections, different BNOR structures (PBNOR, OBNOR, TBNOR, OCBNOR and LC-BNOR) will be applied to estimate the network reliability. The BNOR model for this network is shown in Figure 11. The fail of edge ei can be regarded as an inhibition. For example, in the network displayed in Figure 9, even if N2 is in the working state T , N5 may not in state T due to the fail of e2. The inhibition can be measured by link probabilities pei , i = 1, 2, · · · , 5.\n4.3. BNOR model, case with no epistemic uncertainty\nIf there is no epistemic uncertainty, neither on the variable state or on link probabilities, i.e.,\nm(N1 = {T, F}) = 0,\nand\npiL = piU = p(ei = T ), i = 1, 2, · · · , 6,\nthe same results can be obtained by the use of all BNORs and ImNOR:\nm(S = {T}) = 0.9148, m(S = {F}) = 0.0852, m(S = {T, F}) = 0.\nIt can be seen that, if there is no epistemic uncertainty introduced, the reliability estimation results previously obtained by traditional BN method can be recovered. This fact indicates that BNOR is a general extension of Noisy-OR structure in the\nframework of belief functions, and it is entirely compatible with the probabilistic solution. The Bel and Pl measures can be obtained by Eqs. (10) and (11) respectively. The following results can be obtained:\nBel(S = {T}) = 0.9148, p(S = T ) = 0.9148, P l(S = {T}) = 0.9148. (57)\n4.4. BNOR model, case with an epistemic uncertainty\nIn this test, the case with some epistemic uncertainty on link probabilities is considered. The lower and upper probability bounds of link probabilities pei are listed in Table 7. The results by five BNORs and ImNOR are illustrated in Table 8.\nIn Figures 12-a and 12-b, the results of the evaluation of the network system varying with the optimism coefficient λ are demonstrated. It can be found that when λ grows from 0 up to 1, the mass on “the system is working” (i.e., m(S = {T})) increases. On the contrary, m(S = {F}) decreases. This meets with our common sense of optimistic and pessimistic decisions. However, ImNOR provides opposite attitudes towards m(S = {T}) and m(S = {F}). The performance of ImNOR is similar to PBNOR for calculating m(S = {T}), while similar to OBNOR for calculating m(S = {F}).\nFigure 12-c illustrates that the mass assigned to the uncertain state {T, F} by LC-BNOR is larger than that by the other models. This is due to the principle LC-BNOR upholds is that one should never give more support than justified to any subset of the discernment frame.\nLet the interval of link probability pe1 be [0.7525, 0.8525] and the corresponding interval of pe2 be [0.6977, 0.6977]− [α,−α]. The length of the interval, 2α, reflects the degree of uncertainty to some extend. Figure 12-d depicts the mass assigned to the uncertain state m(S = {T, F}) varying with α. It can be seen that the uncertainty on system’s state increases with the increasing of α. LC-BNOR is the most sensitive to uncertainty variation among the six NOR models.\nIn this case, the credibility and plausibility measures on S = {T} are not the same, and they bound the network reliability. For example, if we use OCBNOR (λ = 0.6), from Table 8 we can see the belief mass assignment of the network state S:\nm(S = {T}) = 0.9082, m(S = {F}) = 0.0741, m(S = {T, F}) = 0.0177. (58)\nThe following results can be obtained:\nBel(S = {T}) = 0.9082, p(S = T ) = 0.9148, P l(S = {T}) = 0.9259. (59)\nFurther decisions can be made based on these uncertainty knowledge.\nThe information on credal level can be transformed to the pignistic level by Eq. (51) where the decisions can be made more easily. The probability distributions by different models are listed in Table 9. As it can be observed in Figure 13, with\nthe increasing of λ, the pignistic probability for S = T increases, on the other hand decreases for S = F . For S = T , OBNOR gives a upper bound and PBNOR gives a lower bound. While for S = F , OBNOR gives a lower bound and PBNOR gives a upper bound. This is in accordance with the optimistic and pessimistic principles. However, the attitude of ImNOR is ambiguous.\nTable 9. The probability distribution of the network system.\nS ImNOR LC-BNOR PBNOR OBNOR TBNOR OCBNOR(λ = 0.6) T 0.9152 0.9139 0.9090 0.9225 0.9157 0.9171 F 0.0848 0.0861 0.0910 0.0775 0.0843 0.0829\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.905\n0.91\n0.915\n0.92\n0.925\nB e tP (S = T )\nImNOR PBNOR OBNOR OCBNOR LCBNOR\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.075\n0.08\n0.085\n0.09\n0.095\nB e tP (S = F )\nImNOR PBNOR OBNOR OCBNOR LCBNOR\na. BetP (S = T ) b. BetP (S = F )\nFig. 13. The different BNOR structures for BetP (S).\n4.5. Discussion\nFrom the experimental results, it can be concluded that when there is no epistemic uncertainty in the network, BNOR degrades to the traditional Bayesian method. However, if there indeed exists imperfect knowledge, BNOR model can provide us more information in the form of lower bounds (Bel) and upper bounds (Pl). A pessimistic decision can be made according to the Bel value, which provides us the worst value of the network reliability. On the contrary, Pl is the maximum degree of belief that can support the connectivity of the network, from which an optimistic decision can be made. These measures are of great value when we have to make a compromise between risks and costs. Also these knowledge on the credal level can be transformed to the pignistic level through Smets method. Then common principles in decision theory such as the minimal expected cost (risk) criterion can be evoked."
    }, {
      "heading" : "5. Conclusion",
      "text" : "In this paper, the BNOR model under the framework of belief functions, as an extension of the traditional NOR model, is developed to express several kinds of uncertainty in the independent causal interactions. It is proved that BNOR can be implemented to propagate uncertain information through employing the Bayesian networks tools. In practice, BNOR is more flexible than existing NOR models because it offers a general Bayesian framework that allows us to adopt the exact inference algorithm in their original form without modification, and then by adjusting necessary parameters to obtain results which satisfy the special requirements of engineers. Finally, the application on the reliability evaluation problem of networked systems demonstrates the effectiveness of BNOR model.\nBNOR is applicable to systems with binary variables. An extension of BNOR suitable to multi-value variables should be regarded as a future development. Furthermore, the uncertainty on link probabilities may not be given in the form of intervals in practice. How to take advantage of the independence of causal interactions with different types of uncertain knowledge is another considerable problem to be investigated. This paper mainly focuses on theoretical work. Applications of BNOR on more complex situations will be considered in the future."
    }, {
      "heading" : "Acknowledgments.",
      "text" : "This work was supported by the National Natural Science Foundation of China (Nos.61135001, 61403310). The study of the first author in France was supported by the China Scholarship Council."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "One difficulty faced in knowledge engineering for Bayesian Network (BN) is the quantification step where the Conditional Probability Tables (CPTs) are determined. The number of parameters included in CPTs increases exponentially with the number of parent variables. The most common solution is the application of the so-called canonical gates. The Noisy-OR (NOR) gate, which takes advantage of the independence of causal interactions, provides a logarithmic reduction of the number of parameters required to specify a CPT. In this paper, an extension of NOR model based on the theory of belief functions, named Belief Noisy-OR (BNOR), is proposed. BNOR is capable of dealing with both aleatory and epistemic uncertainty of the network. Compared with NOR, more rich information which is of great value for making decisions can be got when the available knowledge is uncertain. Specially, when there is no epistemic uncertainty, BNOR degrades into NOR. Additionally, different structures of BNOR are presented in this paper in order to meet various needs of engineers. The application of BNOR model on the reliability evaluation problem of networked systems demonstrates its effectiveness.",
    "creator" : "LaTeX with hyperref package"
  }
}