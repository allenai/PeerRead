{
  "name" : "1706.00082.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Megapixel Size Image Creation using Generative Adversarial Networks",
    "authors" : [ "Marco Marchesi" ],
    "emails" : [ "marco.marchesi@happyfinish.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Since its appearance, Generative Adversarial Networks (GANs) [2] have received a lot of interest in the AI community. In image generation several projects showed how GANs are able to generate photorealistic images but the results so far didn’t look adequate for the quality standard of visual media production industry. We present an optimized image generation process based on a Deep Convolutional Generative Adversarial Networks (DCGANs), in order to create photorealistic high-resolution images (up to 1024x1024 pixels). Furthermore, the system was fed with a limited dataset of images, less than two thousand images. All these results give more clue about future exploitation of GANs in Computer Graphics and Visual Effects."
    }, {
      "heading" : "1 Introduction",
      "text" : "Generative Adversarial Networks are made by two neural networks competing each other. One, the generator G(z), it creates images starting from a latent space z of uniformly distributed random numbers, while the discriminator D(x) has to judge the images x it receives as fake or real. We train G(z) with the goal to fool D(x) with fake images, minimizing log 1 −D(G(z)). In order to do that, G(z) has to learn to produce images that are as much photorealistic as possible.\n∗marco.marchesi@happyfinish.com\nThis approach is a valid alternative to maximum likelihood techniques, because its conditions and constraints make feasible to run it as an unsupervised learning approach. By the contrary, training is still challenging and efforts are made to prevent both networks to fail. Several improvements have been introduced since the first GAN model. One of the first techniques was the minibatch discrimination that reduces the chance for the generator to collapse [4]. Other techniques aim to find a faster convergence, modeling the discriminator D(x) as an energy function [5] or introducing new loss definitions [1]."
    }, {
      "heading" : "2 The model",
      "text" : "The model we used is a DCGAN [3], implemented with Google TensorFlow, with a variable batch size depending of the size of the images we wanted to achieve. For training the discriminator we tested two slightly different datasets (1807 and 1796 images), composed by faces of women taken from magazines and social media. In fact the goal of this project was to generate an image that summarized how the new mums are wrongly represented by media in UK.\nFor doing that we faced a few challenges:\n• The dataset was restricted to less than 2k images, compared to that ones used on research, thus the system had to learn as much as possible from the limited amount of data. Furthermore, 70% of the images in the dataset was smaller than 512x512px, so the system had to\nar X\niv :1\n70 6.\n00 08\n2v 1\n[ cs\n.C V\n] 3\n1 M\nlearn mostly from upscaled images, inferring the high resolution details from the small set of bigger images.\n• We trained the system with a NVIDIA Pascal Titan X that was limited in storing a DCGAN able to generate megapixel size images (Fig.2). For this reason the batch size for the training process was a parameter, starting from 128 (for 192x192px) to 6 (for 1024x1024px).\n• The generated samples had to be photorealistic, to be used commercially, so the system had to limit the artifacts.\n• With our dataset, we found that bigger the ima-\nge size, easier for G(z) to diverge."
    }, {
      "heading" : "3 Training Process",
      "text" : "We generated images at different sizes, starting at 192x192px up to 1024x1024px (Fig.3). The\nmegapixel size has been produced for the first time, as long as the highest image size for GANs so far was 512px in width [6]. To do so, in brief we applied the following optimizations:\n1. To prevent the generator and the discriminator to diverge, we applied an additional step for updating alternatively the generator and the discriminator every 50 steps. In this way the loss for both networks oscillated (loss(D) < 1 and loss(G) < 3) on a limited interval but never diverged at any image size.\n2. For generating the samples, we limited the interval of the uniform distribution of the random inputs z. This solution reduced significantly the artifacts, as showed in Fig.4."
    }, {
      "heading" : "4 Conclusion and Future Work",
      "text" : "We briefly presented the optimization process made on a DCGAN model to generate bigger photorealistic images with a limited dataset. We reached the 1024x1024px size, almost 4x the previous result in research, limiting the artifacts in order to use the image in a creative process for a commercial campaign. We want to test if our improvements can be applied to any dataset. We aim to reduce the memory requirements for GANs, exploiting GPU parallelism, and we want to apply new convergence criteria to GANs, in order to generate even bigger photorealistic images. Further conditional probabilities will let us exploit GANs more widely in other computer graphics fields, like animation and visual effects."
    }, {
      "heading" : "Acknowledgement",
      "text" : "This research was part of a commercial project funded by MHPC."
    } ],
    "references" : [ {
      "title" : "BE- GAN: Boundary Equilibrium Generative Adversarial Networks",
      "author" : [ "D. Berthelot", "T. Schumm", "L. Metz" ],
      "venue" : "ArXiv e-prints,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2017
    }, {
      "title" : "Generative Adversarial Networks",
      "author" : [ "I.J. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2014
    }, {
      "title" : "Unsupervised representation learning with deep convolutional generative adversarial networks",
      "author" : [ "A. Radford", "L. Metz", "S. Chintala" ],
      "venue" : "CoRR, abs/1511.06434",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Improved techniques for training gans",
      "author" : [ "T. Salimans", "I.J. Goodfellow", "W. Zaremba", "V. Cheung", "A. Radford", "X. Chen" ],
      "venue" : "Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pages 2226–2234",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Energybased generative adversarial network",
      "author" : [ "J.J. Zhao", "M. Mathieu", "Y. LeCun" ],
      "venue" : "CoRR, abs/1609.03126",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Unpaired image-to-image translation using cycle-consistent adversarial networks",
      "author" : [ "J. Zhu", "T. Park", "P. Isola", "A.A. Efros" ],
      "venue" : "CoRR, abs/1703.10593",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Since its appearance, Generative Adversarial Networks (GANs) [2] have received a lot of interest in the AI community.",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 3,
      "context" : "One of the first techniques was the minibatch discrimination that reduces the chance for the generator to collapse [4].",
      "startOffset" : 115,
      "endOffset" : 118
    }, {
      "referenceID" : 4,
      "context" : "Other techniques aim to find a faster convergence, modeling the discriminator D(x) as an energy function [5] or introducing new loss definitions [1].",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 0,
      "context" : "Other techniques aim to find a faster convergence, modeling the discriminator D(x) as an energy function [5] or introducing new loss definitions [1].",
      "startOffset" : 145,
      "endOffset" : 148
    }, {
      "referenceID" : 2,
      "context" : "The model we used is a DCGAN [3], implemented with Google TensorFlow, with a variable batch size depending of the size of the images we wanted to achieve.",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 5,
      "context" : "megapixel size has been produced for the first time, as long as the highest image size for GANs so far was 512px in width [6].",
      "startOffset" : 122,
      "endOffset" : 125
    } ],
    "year" : 2017,
    "abstractText" : "Since its appearance, Generative Adversarial Networks (GANs) [2] have received a lot of interest in the AI community. In image generation several projects showed how GANs are able to generate photorealistic images but the results so far didn’t look adequate for the quality standard of visual media production industry. We present an optimized image generation process based on a Deep Convolutional Generative Adversarial Networks (DCGANs), in order to create photorealistic high-resolution images (up to 1024x1024 pixels). Furthermore, the system was fed with a limited dataset of images, less than two thousand images. All these results give more clue about future exploitation of GANs in Computer Graphics and Visual Effects.",
    "creator" : "LaTeX with hyperref package"
  }
}