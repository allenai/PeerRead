{
  "name" : "1105.5441.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Christer Backstrom" ],
    "emails" : [ "cba@ida.liu.se" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Journal of Arti cial Intelligence Research 9 (1998) 99{137 Submitted 10/97; published 9/98 Computational Aspects of Reordering PlansChrister B ackstr om cba@ida.liu.seDepartment of Computer and Information ScienceLink opings universitet, S-581 83 Link oping, SwedenAbstractThis article studies the problem of modifying the action ordering of a plan in orderto optimise the plan according to various criteria. One of these criteria is to make a planless constrained and the other is to minimize its parallel execution time. Three candidatede nitions are proposed for the rst of these criteria, constituting a sequence of increasingoptimality guarantees. Two of these are based on deordering plans, which means that or-dering relations may only be removed, not added, while the third one uses reordering, wherearbitrary modi cations to the ordering are allowed. It is shown that only the weakest oneof the three criteria is tractable to achieve, the other two being NP-hard and even di cultto approximate. Similarly, optimising the parallel execution time of a plan is studied bothfor deordering and reordering of plans. In the general case, both of these computations areNP-hard. However, it is shown that optimal deorderings can be computed in polynomialtime for a class of planning languages based on the notions of producers, consumers andthreats, which includes most of the commonly used planning languages. Computing op-timal reorderings can potentially lead to even faster parallel executions, but this problemremains NP-hard and di cult to approximate even under quite severe restrictions.1. IntroductionIn many applications where plans, made by man or by computer, are executed, it is impor-tant to nd plans that are optimal with respect to some cost measure, typically executiontime. Examples of such applications are manufacturing and error-recovery for industrialprocesses, production planning, logistics and robotics. Many di erent kinds of computa-tions can be made to improve the cost of a plan|only a few of which have been extensivelystudied in the literature. The most well-known and frequently used of these is schedul-ing. A plan tells which actions (or tasks) to do and in which order to do them, while aschedule assigns exact release times to these actions. The schedule must obey the actionorder prescribed by the plan and must often also satisfy further metric constraints such asdeadlines and earliest release times for certain actions. A schedule is feasible if it satis es allsuch metric constraints. It is usually interesting to nd a schedule that is optimal in somerespect, eg the feasible schedule having the shortest total execution time, or the schedulemissing the deadlines for as few actions as possible.In principle, planning and scheduling follow in sequence such that scheduling can beviewed as a post-processing step to planning|where planning is concerned with causalrelations and qualitative temporal relations between actions, while scheduling is concernedwith metric constraints on actions. In some planning systems, eg O-Plan (Currie & Tate,1991) and Sipe (Wilkins, 1988), both planning and scheduling are integrated into onesingle system. Similarly, temporal planners, eg Deviser (Vere, 1983) and IxTeT (Ghallab& Laruelle, 1994), can often reason also about metric constraints. This does not make itc 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.\nB ackstr omirrelevant to study planning and scheduling as separate problems, though, as can be seenfrom the vast literature on both topics. The two problems are of quite di erent characterand studying them separately gives important insight also into such integrated systems aswas just discussed. For instance, Drabble1 says that it is often very di cult to see whenO-Plan plans and when it schedules; it is easy to see that O-Plan works, but it is di cultto see why.A further complication in understanding the di erence between planning and scheduling,both for integrated systems and for systems with separated planning and scheduling, isthat certain types of computations fall into a grey zone between planning and scheduling.Planners are good at reasoning about e ects of actions and causal relationships betweenactions, but are usually very poor at reasoning about time and temporal relationshipsbetween actions. Schedulers, on the other hand, are primarily designed to reason abouttime and resource con icts, but have no capabilities for reasoning about causal dependenciesbetween actions. The problems in the grey zone require reasoning of both kinds, so neitherplanners nor schedulers can handle these problems properly. If these problems are notsolved, then the scheduler does not get su cient information from the planner to do thebest of the situation|the planner and the scheduler may fail in their cooperation to nd aplan with a feasible schedule, even when such a plan exists.This article focusses on one of these grey-zone problems, namely the problem of optimis-ing the action order of a plan to allow for better schedules. Whenever two actions con ictwith each other and cannot be allowed to execute in parallel, a planner must order theseactions. However, it usually does not have enough information and reasoning capabilitiesto decide which of the two possible orders is the best one, so it makes an arbitrary choice.One of the choices typically allows for a better schedule than the other one, so if the plannermakes the wrong choice it may prevent the scheduler from nding a good, or even feasible,schedule. This situation arises also when plans are made by a human expert, since it is dif- cult to see which choice of ordering is the best one in a large and complex plan. Planningsystems of today usually cannot do anything better than asking the planner for a new planif the scheduler fails to nd a feasible schedule. This is an expensive and unsatisfactorysolution, especially if there is no feedback from the scheduler to help the planner makinga more intelligent choice next time. Another solution which appears in the literature is touse a lter between the planner and scheduler which attempts to modify the plan order toput the scheduler in a better position. Such lters could remove certain over-commitmentsin the ordering, which will be referred to as deordering the plan, or even change the orderbetween certain actions, which will be referred to as reordering the plan.This article is intended to provide a rst formal foundation for studying this type ofproblems. It de nes a number of di erent optimality criteria for plan order modi cations,both with respect to the degree of over-committment in the ordering and with respect tothe parallel execution time, and it also provides computational results for computing suchmodi cations. The article also analyses some ltering algorithms suggested in the literaturefor doing such order modi cations.The remainder of this article is structured as follows. Section 2 introduces the conceptsand computations studied in this article by means of an example. Then Section 3 starts the1. Brian Drabble, personal communication, Aug. 1997.100\nComputational Aspects of Reordering Planstheoretical content of the article, de ning the two planning formalisms used in the followingsections. The problems of making a plan least-constrained are studied in Section 4 wheresome candidate de nitions for this concept are introduced and their computational proper-ties investigated. Section 5 de nes the concepts of parallel plans and parallel executions ofplans. This is followed by Section 6 where optimal deorderings and reorderings of parallelplans are introduced and the complexity of achieving such optimality is analysed. Section 7then studies how the complexity of these problems is a ected by restricting the language.This includes the positive result that an algorithm from the literature nds optimal de-orderings for a class of plans for most common planning languages. Some other lteringalgorithms from the literature as well as some planners incorporating some ordering opti-misation are discussed in Section 8. Finally, Section 9 discusses some aspects of this articleand some related work, while Section 10 concludes by a brief recapitulation of the results.2. ExampleIn order to illustrate the concepts and operations studied in this article a simple exampleof assembling a toy car will be used. The example is a variation of the example used byB ackstr om and Klein (1991), which is a much simpli ed version of an existing assembly linefor toy cars used for undergraduate laborations in digital control at Link oping University(for a description of this assembly line, see eg. Klein, Jonsson, & B ackstr om, 1995, 1998;Str omberg, 1991). The problem is to assemble a LEGO2 car from pre-assembled parts asshown in Figure 1. There is a chassis, a top and a set of wheels, the two latter to be mountedonto the chassis.Top Chassis Wheels CarFigure 1: Schematic assembly process for a toy carThe workpiece ow of the factory is shown in Figure 2. There are three storages, onefor each type of preassembled part, two workstations, number 1 for mounting the top andnumber 2 for mounting the wheels, and there is a car storage for assembled cars. Tops canbe moved from the top storage to workstation 1 and sets of wheels can be moved from the2. LEGO is a trade mark of the LEGO company 101\nB ackstr omwheels storage to workstation 2. Chassis can be moved from the chassis storage to eitherworkstation and also, possibly with other parts mounted, between the two workstations andfrom either workstation to the car storage. Furthermore, before mounting the wheels on achassis, the tyres must be in ated, so workstation 2 incorporates a compressed-air containerwhich must be pressurized before in ating the tyres (this is not shown in the gure).\nStorageWheels CarStorageChassisStorage\nTopStorage Workstation 2 Workstation 1\nFigure 2: Schematic lay-out of the toy-car factoryThis article is concerned with modifying the order between the actions in a given plan,and does not consider modifying also the set of actions. Hence, the example will assumethat a plan for assembling a toy car is given|whether this plan was produced by hand orby a planning algorithm is not important. It will also be assumed that this assembly plancontains exactly those actions listed in Table 1, in some order. Since most results in thisarticle are independent of the particular planning language used, no assumptions aboutthe planning language will be made in this example either. To make things simple, theobvious common-sense constraints on which plans are valid will be used. For instance, apart must be moved to a workstation before it is mounted there, the wheels must be in atedbefore being mounted and the air container must be pressurized before in ating the tyres.Furthermore, since a chassis can only be at one single place at a time, the top cannot bemounted in parallel with mounting the wheels, and neither of the mounting operations canbe done in parallel with moving either the chassis or the part to be mounted.The purpose of modifying the action order in a given plan is usually to optimize theplan in some aspect, for instance, to make the plan least constrained. Consider the totallyordered plan in Figure 3a, for producing a chassis with wheels, which is a subplan of theplan for assembling a car. Note that since the plan is totally ordered, all pairs of actionsare ordered, but the implicit transitive arcs are not shown in the gure. This plan is clearlyover-constrained. For instance, it is not necessary to move the set of wheels to workstation2 before pressurizing the air container, and removing this ordering constraint results inthe plan in Figure 3b. Note that orderings have only been removed|the arc from MvW2to IT existed already in the original plan, but was implicit by transitivity. A plan wheresome orderings have been removed will be referred to as a deordering of the original plan.102\nComputational Aspects of Reordering Plans Action Description DurationMvT1 Move top to workstation 1 1MvW2 Move wheels to workstation 2 1MvC1 Move chassis to workstation 1 2MvC2 Move chassis to workstation 2 2MvS Move chassis to car storage 3MtT Mount top on chassis 7MtW Mount wheels on chassis 4PAC Pressurize air container 5IT In ate tyres 4Table 1: Actions of the assembly planThis new plan is less constrained than the original plan, since it is now possible to movethe wheels and pressurize the air container in either order or, perhaps, even in parallel.However, further orderings can be removed; it is not necessary to in ate the wheels beforemoving the chassis to the workstation. Removing also this ordering results in the plan inFigure 3c, which is a least constrained deordering of the original plan in the sense thatit is not possible to remove any further ordering constraints and still have a valid plan.That is, if removing any further ordering constraint, it will be possible to sequence theactions in such a way that the plan will no longer have its intended result. In addition todeorderings, one may also consider arbitrary modi cations of the ordering relation, that is,both removing and adding relations. Such modi cations will be referred to as reorderings.Three di erents least-constrainment criteria for plans based on deorderings and reorderingswill be studied in Section 4, and the plan in Figure 3c happens to be optimal according toall three of these criteria.\nB ackstr omMaking a plan least constrained is clearly useful if certain actions can be executed inparallel. However, even in the case where no parallel execution is possible, it may still beworth making a plan least constrained. Although the partial order of this least constrainedplan must again be strengthened into a total order for execution purposes, this need not bethe same total order as in the original plan. Suppose the actions have temporal constaintslike deadlines and earliest release times and that a scheduler will post-process the plan totry nding a feasible schedule. It may then be the case that the original plan has no feasibleschedule, but a less constrained version of it can be sequenced into a feasible schedule. Theidea of a least constrained plan is that the scheduler will have as many alternative executionsequences as possible to choose from.The most important reason for modifying the action ordering of a plan, however, is toexecute the plan faster by executing actions in parallel whenever possible. For this purposeit is better to use the length of the optimal schedule for a plan as a measure, rather thansome measure on the ordering itself. Suppose the following car-assembly plan is givenhMvW2; PAC; IT;MvC2;MtW;MvT1;MvC1;MtT;MvSi:If the actions are executed sequentially in the given order, the minimum execution timeis the sum of the durations of the actions, that is 29 time units. However, just as in theprevious example this plan is over-constrained, since several of the actions could be executedin either order, or in parallel.It is possible to remove orderings as far as shown in Figure 4a, but no further, andstill have a valid plan (the implicit transitive orderings are not shown in the gure). Thisdeordered version of the original assembly plan can be scheduled to execute in 25 time unitsby exploiting parallelism whenever possible. An example of such a schedule is shown inFigure 3b. However, no faster execution is possible, since the plan contains a subsequenceof actions which cannot be parallelized and which has a total execution time of 25 timeunits.It is obvious from the schedule in Figure 4b that not many actions can be executed inparallel, and that the gain of deordering the plan is quite small. A much better performanceis possible if arbitrary modi cations to the action ordering are allowed, that is, if alsoreorderings are considered. For instance, in the assembly plan there is no particular reasonwhy the wheels should be mounted before the top is mounted, and it will be seen shortlythat much time can be saved by reversing the order of these two operations. A deorderingcannot do this, however, since removing the ordering between the wheel-mounting action(MtW) and the top-mounting action (MtT) would make these unordered. This would beinterpreted as if the two actions could be executed in parallel, which is not possible. Thisis also the reason why these actions must be ordered in the original plan. However, whenallowing arbitrary modi cations, the order between these two actions can be reversed, andFigure 5a shows such a reordering of the original plan. This plan can be scheduled toexecute in only 16 time units, which is a considerable improvement over both the originalplan and the optimal deordered version of it. An example of an optimal schedule is shownin Figure 5b. In fact, this plan is an optimal reordering in the sense that no other orderingof the actions results in a valid plan that can be scheduled to execute faster. The problemsof nding optimal deorderings and reorderings of plan with respect to parallel execution isthe main topic of this article, and are studied in Sections 5 to 7.104\nComputational Aspects of Reordering Plans\nMvC2 IT MtW MvC1 MtTMvT1MvW2 MvS 0 5 10 15 20 25\na) A deordering of the assembly plan admitting a shortestparallel execution time\nb) An optimal schedule for the plan above\nMvSMvW2 ITMvC2 MtW MvC1MvT1 MtTPAC PAC\nFigure 4: An optimal deordering of the assembly planIt is obvious that reordering is a more powerful operation than deordering, since thereordered plan in Figure 5a allows for a shorter schedule than the optimal deordering inFigure 4a. On the other hand, if the original plan had beenhMvT1;MvC1;MtT;MvS;MvW2; PAC; IT;MvC2;MtW i;then deordering would have been su cient for arriving at the optimal plan in Figure 5a.3. Planning FormalismsThis section de nes actions, plans and related concepts, which basically appear in twodi erent guises in this article. De nitions and tractability results will mostly be cast in ageneral, axiomatic framework in order to be as general and independent of formalism aspossible. Hardness results, on the other hand, will mostly be cast in a speci c formalism,Ground Tweak, and often subject to further restrictions, this in order to strengthen theresults. Both these formalisms are de ned below. In addition to these, a third formalismwill be used, but its de nition will be deferred until it is used, in Section 7.105\nB ackstr om\na) parallel execution time\nb) An optimal schedule for the plan above\nA reordering of the assembly plan admitting a shortestMvS MvW2 ITMvC2 MtWMvC1MvT1 MtT PAC\nMvC1 MvW2 ITMvT1 MtT MtWMvC2 MvS0 5 10 15 PAC\nFigure 5: An optimal reordering of the assembly plan3.1 The Axiomatic Planning FrameworkThe axiomatic framework makes only a minimum of assumptions about the underlying for-malism. It may be instantiated to any planning formalism that de nes some concept ofa planning problem a domain of entities called actions and a validity test. The planningproblem is assumed to consist of planning problem instances (ppis),3 with no further as-sumptions about the inner structure of these. The validity test is a truth-valued functiontaking a ppi and a sequence of actions as arguments. If the validity test is true for a ppi and an action sequence ha1; : : : ; ani, then the action sequence ha1; : : : ; ani is said to solve . While the inner structure of the ppis and the exact de nition of the validity test are cru-cial for any speci c planning formalism, many results in this article can be proven withoutmaking any such further assumptions. Results on the computational complexity of certainproblems will make an assumption about the complexity of the validity test, though. Basedon these concepts, the notion of plans can be de ned in the usual way.De nition 3.1 A total-order plan (t.o. plan) is a sequence P = ha1; : : : ; ani of actions,which can alternatively be denoted by the tuple hfa1; : : : ; ang; i where for 1 k; l n,ak al i k < l. Given a ppi , P is said to be -valid i the validity test is true for and P .3. This is the complexity-theoretic terminology for problems. Planning problem instances in the sense ofthis article are sometimes referred to as planning problems in the planning literature.106\nComputational Aspects of Reordering PlansA partial-order plan (p.o. plan) is a tuple P = hA; i where A is a set of actions and is a strict ( ie. irre exive) partial order on A. The validity test is extended to p.o. planss.t. given a ppi , P is -valid i hA; 0i is valid for every topological sorting 0 of .The actions of a t.o. plan must be executed in the speci ed order, while unorderedactions in a p.o. plan may be executed in either order. That is, a p.o. plan can be viewedas a compact representation for a set of t.o. plans. There is no implicit assumption thatunordered actions can be executed in parallel; parallel plans will be de ned in Section 5.p.o. plans will be viewed as directed acyclic graphs in gures with the transitive arcs oftentacitly omitted to enhance readability. Furthermore, all proofs and algorithms in this articleare based on this de nition, ie assuming the order of a plan is transitively closed, whilemany practical planners do not bother about transitive closures. This di erence does nota ect any of the results presented here.3.2 The Ground TWEAK FormalismThe Ground TWEAK (GT) formalism is the TWEAK language (Chapman, 1987) restrictedto ground actions. This formalism is a variation on propositional STRIPS and it is knownto be equivalent under polynomial transformation to most other common variants on propo-sitional STRIPS (B ackstr om, 1995). In brief, an action has a precondition and a postcon-dition, both being sets of ground literals.In order to de ne the GT formalism, the following two de nitions are required. Givensome set S, the notion Seqs(S) denotes the set of all sequences formed by members of S,allowing repetition of elements and including the empty sequence. The symbol `;' will beused to denote the sequence concatenation operator. Further, given a set P of propositionalatoms, the set LP of literals over P is de ned as LP = P [ f:p j p 2 Pg. Since no otherformulae will be allowed than atoms and negated atoms, a double negation ::p will betreated as identical to the unnegated atom p. Finally, given a set of literals L, the negationNeg(L) of L is de ned as Neg(L) = f:p j p 2 Lg[fp j :p 2 Lg and L is said to be consistenti there is no atom p s.t. both p 2 L and :p 2 L.De nition 3.2 An instance of the GT planning problem is a quadruple = hP;O; I;Giwhere P is a nite set of atoms; O is a nite set of operators of the form hpre; posti where pre; post LP are consistentand denote the pre and post condition respectively; I;G LP are consistent and denote the initial and goal state respectively.For o = hpre; posti O, we write pre(o) and post(o) to denote pre and post respectively. Asequence ho1; : : : ; oni 2 Seqs(O) of operators is called a GT plan (or simply a plan) over .De nition 3.3 The ternary relation valid Seqs(O) 2LP 2LP is de ned s.t. for arbi-trary ho1; : : : ; oni 2 Seqs(O) and S; T LP , valid(ho1; : : : ; oni; S; T ) holds i either1. n = 0 and T S or 107\nB ackstr om2. n > 0, pre(o1) S andvalid(ho2; : : : ; oni; (S Neg(post(o1)) [ post(o1); T ).A t.o. plan ho1; : : : ; oni 2 Seqs(O) solves i valid(ho1; : : : ; oni; I;G).An action is a unique instance of an operator, ie a set of actions may contain severalinstances of the same operator, and it inherits its pre- and post-conditions from the operatorit instantiates. Since all problems in this article will consider some xed set of actions, theatom and operator sets will frequently be tacitly omitted from the GT ppis. In gures,GT actions will be shown as boxes, with precondition literals to the left and postconditionliterals to the right.4. Least Constrained PlansIt seems to have been generally assumed in the planning community that there is no di er-ence between t.o. plans and p.o. plans in the sense that a t.o. plan can easily be convertedinto a p.o. plan and vice versa. However, while a p.o. plan can be trivially converted intoa t.o. plan in low-order polynomial time by topological sorting, it is less obvious that alsothe converse holds. At least three algorithms for converting t.o. plans into p.o. plans havebeen presented in the literature (Pednault, 1986; Regnier & Fade, 1991a; Veloso, P erez, &Carbonell, 1990) (all these algorithms will be analyzed later in this article). The claim thata t.o. plan can easily be converted into a p.o. plan is vacuously true since any t.o. plan isalready a p.o. plan, by de nition. Hence, no computation at all needs to be done. Thisis hardly what the algorithms were intended to compute, however. In order to be useful,such an algorithm must output a p.o. plan satisfying some interesting criterion, ideally someoptimality criterion. In fact, two of the algorithms mentioned above are claimed to produceoptimal plans according to certain criteria. For instance, Veloso et al. (1990, p. 207) claimtheir algorithm to produce least constrained plans. They do not de ne what they meanby this term, however, and theirs is hardly the only paper in the literature using this termwithout further de nition.Unfortunately, it is by no means obvious what constitutes an intuitive or good criterionfor when a p.o. plan is least constrained and, to some extent, this also depends on thepurpose of achieving least-constrainment. The major motivation for producing p.o. plansinstead of t.o. plans (see for instance Tate, 1975) is that a p.o. plan can be post-processedby a scheduler according to further criteria, such as release times and deadlines or resourcelimits. Either the actions are ordered into an (ideally) optimal sequence or, given criteria forparallel execution, into a parallel plan that can be executed faster than if the actions wereexecuted in sequence. In both cases, the less constrained the original plan is, the greateris the chance of arriving at an optimal schedule or optimal parallel execution respectively.Both of the algorithms mentioned above are motivated by the goal of exploiting possibleparallelism to decrease execution time.It is not only interesting to make t.o. plans partially ordered, but also to make partiallyordered plans more partially ordered, that is, to generalise the ordering. An algorithmfor this task has been presented in the literature in the context of case-based planning(Kambhampati & Kedar, 1994). Since t.o. plan are just a special case of p.o. plans, thissection will study the general problem of making partially ordered plans less constrained.108\nComputational Aspects of Reordering Plans4.1 Least-constrainment CriteriaThere is, naturally, an in nitude of possible de nitions of least-constrainment. Some seemmore reasonable than others, however. Three intuitively reasonable candidates are de nedand analyzed below. Although other de nitions are possible, it is questionable whetherconsiderably better or more natural de nitions, with respect to the purposes mentionedabove, can be de ned without using more information than is usually present in a t.o. orp.o. plan.De nition 4.1 Let P = hA; i and Q = hA; 0i be two p.o. plans and a ppi. Then,1. Q is a reordering of P wrt. i both P and Q are -valid.2. Q is a deordering of P wrt. i Q is a reordering of P and 0 3. Q is a proper deordering of P wrt. i Q is a reordering of P and 0 De nition 4.2 Given a ppi and two p.o. plans P = hA; i and Q = hA; 0i,1. Q is a minimal-constrained deordering of P wrt. i (a) Q is a deordering P wrt. and(b) there is no proper deordering of Q wrt. ;2. Q is a minimum-constrained deordering of P wrt. i (a) Q is a deordering P wrt. and(b) there is no deordering hA; 00iof Q wrt. s.t. j 00 j < j j;3. Q is a minimum-constrained reordering of P wrt. i (a) Q is a reordering P wrt. and(b) there is no reordering hA; 00iof Q wrt. s.t. j 00 j < j j;Note that the previous publication (B ackstr om, 1993) used the terms LC1-minimality forminimal-constrained deordering and LC2-minimality for minimum-constrained reordering.This change in terminology has been done with the hope that more will be gained in claritythan is lost by confusion.It is easy to see that minimum-constrainment is a stronger criterion than minimal-constrainment|any minimum-constrained deordering of a plan P is a minimal-constraineddeordering of P , but the opposite is not true. As an example, consider the plan in Figure 6a.If removing all ordering constraints from action C, the result is the plan in Figure 6b, whichis still valid. This plan has an order of size 3 (there is one implicit transitive order) and itis a minimal-constrained deordering since no further deordering can be made. It is not aminimum-constrained deordering, however, since if instead breaking the ordering constraintsbetween the subsequences AB and CB, the result is the plan in Figure 6c, which is also valid.This plan has an ordering of size 2 and it can easily be seen that it is a minimum-constraineddeordering, and that it happens to coincide with the minimum-constrained reordering inthis case. This coincidence is not always the case, however, since a reordering is allowed to109\nB ackstr omdo more modi cations than a deordering; a minimum deordering can obviously never havea smaller ordering relation than a minimum reordering. Examples of this di erence wasshown already in Section 2, where Figure 4a shows a minimum-constrained deordering andFigure 4b shows a minimum-constrained reordering. pA qp B q D qC qC q DpA qp B-pA qp B qC q D - - - - - b) A minimal deordering b) A minimum deordering\na) A total-order plan Figure 6: The di erence between minimal and minimum constrained deorderings.Other alternative de nitions of least-constrainment could be, for instance, to maximizethe unorderdness or to minimize the length of the longest chain in the modi ed plan. How-ever, to nd a de-/reordering which has as many pairs of unordered actions as possible is thedual of computing a minimum de-/reordering and it is, thus, already covered. Minimizingthe length of the longest chain is a condition which may be relevant when actions can beexecuted in parallel and the overall execution time is to be minimized. However, since thenumber of ordering constraints is quadratic in the length of a chain (because of transitivearcs), minimizing the size of the relation will often be a reasonable approximation of min-imizing the chain length. Furthermore, minimizing the longest chain is still a rather weakcondition for this purpose, so it is better to study directly the problem of nding shortestparallel executions of plans, which will be done later in this article.Another issue is whether to minimize the size of the ordering relation as given, or toreduce the transitive or reductive closure of it. Since plans may have super uous orderingswith no particular purpose, it is reasonable to standardize matters and either add all possibletransitive arcs, getting the transitive closure, or to remove all transitive arcs, getting thereductive closure. The choice between these two is not important for the results to beproven. However, minimizing the transitive closure will give a preference to plans withmany unordered short chains of actions over plans with a few long chains, and so seems tocoincide better with the term 'least constrained'.4.2 Computing Least-constrained PlansMinimal deordering is weaker than the two other least-constrainment criteria considered,but it is the least costly to achieve|it is the only one of the three criteria which can besatis ed by a polynomial-time modi cation to a plan.110\nComputational Aspects of Reordering PlansDe nition 4.3 The search problem Minimal-Constrained Deordering (MlCD) isde ned as follows:Given: A ppi and a -valid plan P .Output: A minimal-constrained deordering of P wrt. .Theorem 4.4 MlCD can be solved in polynomial time if validity for p.o. plans can betested in polynomial time.Proof: Consider algorithm MLD in Figure 7 and let Q = hA; 0i be the plan output bythe algorithm on input P = hA; i. The plan Q is obviously a valid deordering of P wrt. . It is further obvious from the termination condition in the while loop that there is noother ordering 00 0 s.t. hA; 00i is -valid. It follows that Q is a minimal-constraineddeordering. Since the algorithm obviously runs in polynomial time, the theorem follows.2Furthermore, if validity testing is expensive, this will be the dominating cost in the MLDalgorithm.Corollary 4.5 If validity testing for p.o. plans can be solved in time O(f(n)) for somefunction f(n), then MlCD can be solved in O(maxfn7=2; n2f(n)g) time.1 procedure MLD2 Input: A valid p.o. plan P = hA; i and a ppi 3 Output: A minimal deordering of P4 while there is some e 2 s.t. hA; ( feg)+i is -valid do5 remove e from 6 return hA; +i;Figure 7: The minimal-deordering algorithm MLDIn particular, note that plan validation is polynomial for the usual variant of propo-sitional STRIPS without conditional actions (Nebel & B ackstr om, 1994, Theorem 5.9).More precisely, this proof pertains to the Common Propositional STRIPS formalism (CPS)and, thus, holds also for the other common variants of propositional STRIPS, like GroundTWEAK (B ackstr om, 1995). Furthermore, note that in practice it may not be necessaryto compute the transitive closure either for the output plan or for validating a plan in thealgorithm.While minimum de-/reordering are stronger criteria than minimal deordering, they arealso more costly to achieve.De nition 4.6 The decision problem Minimum-Constrained Deordering (MmCD)is de ned as follows:Given: A ppi , a -valid plan P and an integer k 0.Question: Is there a deordering hA; i of P s.t. j j k?111\nB ackstr omDe nition 4.7 The decision problem Minimum-Constrained Reordering (MmCR)is de ned as follows:Given: A ppi , a -valid plan P and an integer k 0.Question: Is there a reordering hA; i of P s.t. j j k?Theorem 4.8 Minimum-Constrained Deordering is NP-hard.Proof: Proof by reduction from Minimum Cover (Garey & Johnson, 1979, p. 222),which is NP-complete. Let S = fp1; : : : ; png be a set of atoms, C = fC1; : : : ; Cmg a set ofsubsets of S and k jCj a positive integer. A cover of size k for S is a subset C 0 C s.t.jC 0j k and S [T2C0T . Construct, in polynomial time, the GT ppi = h;; frgi and the -valid t.o. plan P = ha1; : : : ; am; aSi where pre(ai) = ; and post(ai) = Ci for 1 i m,and further pre(aS) = S and post(aS) = frg. Obviously, S has a minimum cover of size ki there exists some -valid p.o. plan Q = hfa1; : : : ; am; aSg; i s.t. j j k, since onlythose actions contributing to the cover need remain ordered wrt. to aS 2Corollary 4.9 Minimum-Constrained Reordering is NP-hard.Corollary 4.10 Minimum-Constrained Deordering and Minimum-ConstrainedReordering both remain NP-hard even when restricted to GT plans where the actionshave only positive pre- and post-conditions.Theorem 4.11 If validity for p.o. plans is in some complexity class C, then Minimum-Constrained Deordering and Minimum-Constrained Reordering are in NPC.Proof: Guess a solution, verify that it is a de-/reordering and then validate it using anoracle for C. 2For most common planning formalisms without conditional actions and context-dependente ects, minimal de-/reordering is NP-complete.Theorem 4.12 If validity for p.o. plans can be tested in polynomial time, then Minimum-Constrained Deordering and Minimum-Constrained Reordering are NP-complete.Proof: Immediate from Theorems 4.8 and 4.11 and from Corollary 4.9. 2It follows immediately that the corresponding search problems, that is, the problems ofgenerating a minimum-constrained de-/reordering are also NP-hard (and even NP-equivalentif validity testing is tractable).Furthermore, MmCD and MmCR are not only hard to solve optimally, but even toapproximate. Neither of these problems is in the approximation class APX (Crescenzi& Panconesi, 1991), ie neither problem can be approximated within a constant factor.(Both here and elsewhere in this article the term approximation is used in the constructivesense, that is the results refer to the existence/non-existence of algorithms producing anapproximate solution in polynomial time). 112\nComputational Aspects of Reordering PlansTheorem 4.13 Minimum-Constrained Deordering and Minimum- ConstrainedReordering cannot be approximated within a constant unless NP 2 DTIME (npoly log n).Proof: Suppose there were a polynomial-time algorithm A approximating MmCD withina constant. Since the reduction in the proof of Theorem 4.8 preserves the solutions exactly,also approximations are preserved. Hence,Minimum Cover could be approximated withina constant, but this is impossible unless NP 2 DTIME (npoly log n) (Lund & Yannakakis,1994), which contradicts the assumption. The case forMmCR is a trivial consequence. 2If using the number of propositional atoms in the plan as a measure of its size, thisbound can be strengthened to (1 \") ln jPj for arbitrary \" unless NP 2 DTIME (nlog log n)by substituting such a result for Minimum Cover (Feige, 1996) in the proof above.5. Parallel PlansIn order to study the problem of nding a shortest parallel execution of a plan, the for-malisms used so far are not quite su cient. Since they lack a capability of modelling whenactions can be executed in parallel or not, it is impossible to say with any reasonable pre-cision how a certain action ordering will a ect the parallel execution time. Partial-orderplans are sometimes referred to as parallel plans in literature. This is misleading, however.That two actions are left unordered in such a plan means that they can be executed ineither order, without a ecting the validity of the plan, but in the general case there isno guarantee that the plan will remain valid also if the executions of the actions overlaptemporally. In some cases, unorderedness means that parallel or overlapping execution isallowed, while in other cases it does not mean that, depending on the action modelling andits underlying domain assumptions. In the rst case, the plan must have a stronger orderingcommittment, any two actions that must not have overlapping executions must be ordered,thus making the plan over-committed.In order to distinguish the two cases, a concept of parallel plans will be introduced below.A parallel plan is a partial-order plan with an extra relation, a non-concurrency relation,which tells which actions must not be executed in parallel. In this article two actions areconsidered parallel if their executions have any temporal overlap at all. Plans where allunordered actions can be executed in parallel constitute the special case of de nite parallelplans.De nition 5.1 A parallel plan is a triple P = hA; ;#i, where hA; i is a p.o. plan and# is an irre exive, symmetric relation on A. A de nite parallel p.o plan is a parallel planP = hA; ;#i s.t. # ( [ 1).Intuitively, a parallel plan is a p.o. plan extended with an extra relation, # (a non-concurrency relation), expressing which of the actions must not be executed in parallel.This relation is primarily intended to convey information about actions that are unorderedunder the relation, although it is allowed to relate also such actions. That is, the #relation is intended to capture information about whether two actions can be executed inparallel or not, in general. That two actions are ordered in a plan forbids executing themin parallel in this particular plan, but does not necessarily mean that the actions could not113\nB ackstr ombe executed in parallel under di erent circumstances. Planning algorithms frequently pro-duce overcommitted orderings on plans, and the whole purpose of this article is to study theproblem of optimizing plans by nding and removing such overcommitted orderings. Hence,there are no restrictions in general on the relation # in addition to those in De nition 5.1.For instance, a b does not imply that a#b. However, the non-concurrency relation willfrequently be constrained to satisfy the post-exclusion principle.De nition 5.2 A parallel GT plan P = hA; ;#i satis es the post-exclusion principlei for all actions a; b 2 A, a#b whenever there is some atom p s.t. p 2 post(a) and:p 2 post(b).The de nition of plan validity is directly inherited from p.o. plans.De nition 5.3 Given a ppi , a parallel plan hA; ;#i is -valid i the p.o. plan hA; iis -valid.The non-concurrency relation is, thus, not relevant for deciding whether a plan is valid ornot. Instead, it is used for constraining how parallel plans may be executed and it is thecore concept behind the de nition of parallel executions.Consider, for instance, the GT plan hfA;B;Cg; fhA;Big; fhB;Cigi which is shown inFigure 8 (arrows denote ordering relations and dashed lines denote nonconcurrency rela-tions). This plan is valid wrt. the ppi = h;; fr; sgi, that is the nal value of the atom qdoes not matter. Since B#C holds the actions B and C are constrained not to be executedin parallel, but may be executed in either order, that is, the plan is not de nite. This couldbe because the post-exclusion principle is employed, or for some other reason. AlthoughA#B does not hold the actions A and B clearly cannot be executed in parallel, since A Bholds. There are four ways to execute this plan, in either of the three sequences A,B,C;A,C,B and C,A,B, or by executing A and C in parallel, followed by B (unit length is as-sumed). Also note that this plan would no longer be valid if the goal contained either q or:q, since the nal truth value of q depends on the actual execution order. Furthermore,any reordering of the plan would have to keep the ordering constraint A B to satisfy thevalidity criterion, why it is not necessary to have the constraint A#B. It would do no harmhere to include this restriction, but in more complex plans it may be an over-constrainment,if there are several producers for the atom p to choose between, for instance. To sum up,the non-concurrency relation should primarily be used to mark which actions must not bein parallel in addition to those already forbidden to be in parallel because of validity.This framework for parallel plans admits expressing possible parallelism only; necessaryparallelism is out of the scope of this article and requires a planner having access to andbeing able to make use of further additional information, perhaps a temporal algebra.Furthermore, a set of non-concurrent actions can easily be expressed by making all actionsin the set pairwise non-concurrent, but the formalism is not su cient to say that k of theactions, but not more, in such a set may be executed in parallel. Similarly, it is not possibleto express that an action must executed before or after an interval, or that two sets ofactions must have non-overlapping executions.De nition 5.4 Let P = hA; ;#i be a parallel plan and let the function d : A 7! N denotethe duration of each action. A parallel execution of P is a function r : A 7! N, denotingrelease times for the actions in A, satisfying that for all a; b 2 A,114\nComputational Aspects of Reordering Plans A BC s:q#\nqp r Figure 8: A parallel plan1. if a b, then r(a) + d(a) r(b) and2. if a#b, then either(a) r(a) + d(a) r(b) or(b) r(b) + d(b) r(a).The length of the parallel execution is de ned as maxa2Afr(a) + d(a)g, ie, the latest nish-ing time of any action. A minimum parallel execution of plan is a parallel execution withminimum length among all parallel executions of the plan. The length of a parallel plan P ,denoted length(P ), is the length of the minimum parallel execution(s) for P .Obviously, every parallel plan has a parallel execution of length Pa2A d(a) (which is thetrivial case of sequential execution). Furthermore, in certain cases, hardness results will bestrengthened by restricting the duration function.De nition 5.5 The special case where d(a) = 1 for all a 2 A is referred to as the unittime assumption.Deciding whether a release-time function is a parallel execution is tractable.Theorem 5.6 Given a parallel plan P = hA; ;#i, a duration function d : A 7! N and arelease-time function r : A 7! N, it can be decided in polynomial time whether r is a parallelexecution for P and, in the case it is, what the length of this execution is.Proof: Trivial. 2Consider the plan in Figure 8 and three release-time functions r1, r2 and r3, de ned asfollows r1(A) = 1 r1(B) = 2 r1(C) = 3r2(A) = 1 r2(B) = 2 r2(C) = 1r3(A) = 1 r3(B) = 2 r3(C) = 2:Both r1 and r2 are parallel executions of the plan, while r3 is not. Furthermore, r2 isa minimum parallel execution for the plan, having length 2. However, computing theminimum parallel execution of a parallel plan is di cult in the general case.115\nB ackstr omDe nition 5.7 The decision problem Parallel Plan Length (PPL) is de ned as fol-lows:Given: A parallel plan P = hA; ;#i, a duration function d and an integer k.Question: Does P have a parallel execution of length k or shorter?Theorem 5.8 Parallel Plan Length is NP-hard.Proof: Hardness is proven by transformation from Graph K-Colourability (Garey& Johnson, 1979, p. 191), which is NP-complete. Let G = hV;Ei be an arbitrary undi-rected graph, where V = fv1; : : : ; vng. Construct, in polynomial time, a GT ppi as fol-lows. De ne the ppi = h;; fp1; : : : ; pngi. Also de ne the parallel plan P = hA; ;;#i,where A contains one action ai for each vertex vi 2 V , s.t. pre(ai) = ; and post(ai) =fpi; qig [ f:qj j fvi; vjg 2 Eg. Finally, let ai#aj i fvi; vjg 2 E, which satis es the post-exclusion principle. The plan P just constructed is obviously -valid. It is easy to see thatG is k-colourable i P has a parallel execution of length k wrt. since each colour of Gwill correspond to a unique release time in the parallel execution of P . 2Corollary 5.9 Parallel Plan Length remains NP-hard even when restricted to GT ac-tions with empty preconditions and under the assumption of unit time and the post-exclusionprinciple.Theorem 5.10 Parallel Plan Length is in NP.Proof: Guess a parallel execution. Then verify it, which can be done in polynomial timeaccording to Theorem 5.6. 2Computing a minimum parallel execution of a plan is tractable for the special case of de niteplans, however.Theorem 5.11 Parallel Plan Length can be solved in polynomial time for de niteparallel plans.Proof: Use the algorithm DPPL (Figure 9), which is a straightforward strati cationalgorithm for directed DAGs. 26. Reordering Parallel PlansHaving de ned the concept of parallel plan, it is possible to de ne concepts similar tothe previous least-constrainment criteria which are more appropriate for minimizing theexecution time of parallel plans.De nition 6.1 Let P = hA; ;#i and Q = hA; 0;#i be two parallel plans and a ppi.Then,1. Q is a parallel reordering of P wrt. i both P and Q are -valid;116\nComputational Aspects of Reordering Plans1 procedure DPPL2 Input: A de nite parallel plan P = hA; ;#i3 Output: A minimum parallel execution r for P4 Construct the directed graph G = hA; i5 for all a 2 A do6 r(a) 07 while A 6= ; do8 Select some node a 2 A without predecessors in A9 for all b 2 A s.t. a b do10 r(b) max(r(b); r(a) + d(a))11 A A fag12 return rFigure 9: Algorithm for computing a minimum parallel execution for de nite parallel plans.2. Q is a parallel deordering of P wrt. i Q is a parallel reordering of P and 0 ;3. Q is a minimum parallel reordering of P wrt. i (a) Q is a parallel reordering of P wrt. and(b) no other parallel reordering of P wrt. is of shorter length than Q;4. Q is a minimum parallel deordering of P wrt. i (a) Q is a parallel deordering of P wrt. and(b) no other parallel deordering of P wrt. is of shorter length than Q.Modifying plans to satisfy either of the latter two criteria is di cult in the general case,however.De nition 6.2 The decision problem Minimum Parallel Deordering (MmPD) is de- ned as follows.Given: a ppi , a parallel plan P , a duration function d and an integer k.Question: Does P have a deordering with a parallel execution of length k wrt. ?De nition 6.3 The decision problem Minimum Parallel Reordering (MmPR) is de- ned as follows.Given: a ppi , a parallel plan P , a duration function d and an integer k.Question: Does P have a reordering with a parallel execution of length k wrt. ?Theorem 6.4 Minimum Parallel Deordering is NP-hard.Proof: Similar to the proof of Theorem 6.4. Given a graph G and an integer k, constructa ppi and a plan P = hA; ;#i in the same way as in the proof of Theorem 5.8, butlet be an arbitrary total order on A. Obviously, P is -valid and Q = hA; ;;#i is adeordering of P s.t. no other deordering of P is shorter than Q. Hence, Q, and thus P , hasa deordering with a parallel execution of length k i G is k-colourable. 2117\nB ackstr omCorollary 6.5 Minimum Parallel Reordering is NP-hard.Corollary 6.6 Minimum Parallel Deordering and Minimum Parallel Reorder-ing remain NP-hard even when restricted to totally ordered GT plans and under the as-sumptions of unit time and simple concurrency.Note that the restriction to de nite input plans is covered by this corollary. If outputplans are also required to be de nite, then the reordering case remains NP-hard.Theorem 6.7 Minimum Parallel Reordering remains NP-hard also when the outputplan is restricted to be de nite.Proof: Reuse the proof for Theorem 6.4 as follows. Let r be a shortest parallel executionfor the plan Q and assume this execution is of length n. Construct an order 0 on A s.t.for all actions a; b 2 A, a 0 b i r(a) < r(b). Obviously the plan hA; 0;#i is a de niteminimum parallel reordering of P . It follows that P has a de nite parallel reordering oflength k i G is k-colourable. 2It is an open question whether minimum deordering remains NP-hard when also outputplans must be de nite, but an important special case is polynomial, as will be proven inthe next section.Theorem 6.8 Minimum Parallel Deordering and Minimum Parallel Reorder-ing are in NPC if validation of p.o. plans is in some complexity class C.Proof: Given a plan hA; ;#i, a duration function d and a parameter k, guess ade/reordering 0 and a release-time function r. Then verify, using an oracle for C, thathA; 0;#i is valid. Finally, verify that r is a parallel execution of length k, which ispolynomial according to Theorem 5.6. 2Theorem 6.9 Minimum parallel de-/reordering is NP-complete if p.o. plans can be vali-dated in polynomial time.Proof: Immediate from Theorems 6.4 and 6.8 and Corollary 6.5. 2The problems MmPD and MmPR are not only hard to solve optimally, but also toapproximate.Theorem 6.10 Minimum Parallel Deordering and Minimum Parallel Reorder-ing cannot be approximated within jAj1=7 \" for any \" > 0, unless P=NP.Proof: Suppose there were a polynomial-time algorithm A approximating MmCD withinjAj1=7 \" for some \" > 0. Then it is immediate from the proof of Theorem 6.4 that alsoGraph K-Colourability could be approximated within jAj1=7 \", which is impossibleunless P=NP (Bellare, Goldreich, & Sudan, 1995). 2With the same reasoning, this bound can be strengthened to jAj1 \", under the assumptionthat co-RP 6=NP (Feige & Kilian, 1996). 118\nComputational Aspects of Reordering Plans7. Restricted CasesSince the problems of computing minimum de-/reorderings are very di cult, and are evendi cult to approximate, an alternative way of tackling them could be to study restrictedcases. One special case already considered is the restriction to de nite plans only. While theproblem MmPR is still NP-complete under this restriction, it is an open question whetheralso MmPD is NP-complete. A positive result can be proven, though, to the e ect thatMmPD is polynomial for de nite plans for a large class of planning languages, includingmost of the commonly used ones. This result will be proven by generalising an algorithmfrom the literature for deordering total-order plans.Based on the (not necessarily true) argument that it is easier to generate a t.o. plan thana p.o. plan when using complex action representations, Regnier and Fade (1991a, 1991b)have presented an algorithm for converting a t.o. plan into a p.o. plan. The resulting planhas the property that all its unordered actions can be executed in parallel, that is, the planis de nite. The authors of the algorithm further claim that the algorithm nds all pairsof actions that can be executed in parallel and, hence, the plan can be post-processed to nd an optimal parallel execution. They do not de ne what they mean by this criterion,however.Incidentally, the algorithm proposed by Regnier and Fade is a special case of an algo-rithm earlier proposed for the same problem by Pednault (1986), who did not make anyclaims about optimality. If removing from Regnier and Fade's algorithm all details relevantonly for their particular implementation and planning language, the two algorithms coincideand they are thus presented here as one single algorithm, the PRF algorithm4 (Figure 10).PRF is slightly modi ed from the original algorithms. First, it does not assume that the in-put plan is totally ordered, since it turns out to be su cient that it is a de nite partial-orderplan. Second, PRF returns a parallel plan, rather than a p.o. plan|a harmless modi ca-tion since the only additional piece of information is the non-concurrency relation, whichis already given as input, either explicitly or implicitly. Third, PRF returns the transitiveclosure of its ordering relation. This is by no means necessary, and is motivated, as usual,by conforming to the de nitions of this article.1 procedure PRF;2 Input: A ppi , a -valid de nite p.o. plan hA; i and a non-concurrencyrelation #3 Output: A -valid parallel plan4 for all a; b 2 A s.t. a b do5 if a#b then6 Order a 0 b;7 return hA; 0+;#i;Figure 10: The PRF algorithmObviously, PRF computes a deordering of its input, and it is unclear whether it is pos-sible to compute a minimal de nite deordering in polynomial time. However, the algorithm4. Here and afterwards, the algorithms from the literature will be referred to by acronyms consisting of theinitials of its authors, in this case Pednault, Regnier and Fade.119\nB ackstr omhas been abstracted here to a very general formalism, and an analysis for restricted for-malisms reveals more about its performance. The language used by Regnier and Fade isunnecessarily restricted so the algorithm will be shown to work for a considerably moregeneral formalism, based on generalising and abstracting the concepts of producers, con-sumers and threats used in most common planners and planning languages, eg STRIPS andTWEAK. This formalism will be referred to as the Producer-Consumer-Threat formalism(PCT).Let prod(a; ) denote that a produces the condition , cons(a; ) that a consumes andthreat(a; ) that a is a threat to . To simplify the de nitions, the standard transformationwill be used of simulating the initial and goal states with actions. That is, every PCT plancontains an action ordered before all other actions which consumes nothing and producesthe initial state. Similarly, there is an action ordered after all other actions which consumesthe goal state and produces nothing. This means that the ppi is contained within the planitself, so all references to ppis can be omitted in the following. Validity of plans can thenbe de ned as follows.De nition 7.1 A t.o. PCT plan ha1; : : : ; ani is valid i for all i, 1 i n and allconditions s.t. cons(ai; ), there is some j, 1 j < i s.t. prod(aj ; ) and there is no k,j k i s.t. threat(ak; ). A p.o. PCT plan is valid i all topological sortings of it arevalid.Chapman's Modal-truth Criterion (MTC) (Chapman, 1987) can be abstracted to thePCT formalism and be analogously used for validating p.o. plans.De nition 7.2 The modal truth criterion (MTC) for a PCT plan hA; i is:8aC8 (cons(aC ; )!9aP (prod(aP ; ) ^ aP aC^8aT (threat(aT ; )!aC aT_9aW (prod(aW ; ) ^ aT aW ^ aW aC))))Theorem 7.3 The MTC holds for a PCT plan P i it is valid.Proof: Trivial generalization of the proofs leading to Theorem 5.9 in Nebel and B ackstr om(1994). 2Only a minimum of constraints for when two actions may not be executed in parallelwill be required. These constraints are obeyed by most planners in the AI literature.De nition 7.4 Simple concurrency holds if for all actions a, b s.t. a 6= b, the non-concurrency relation satis es the following three conditions1. prod(a; ) ^ cons(b; )! a#b2. prod(a; ) ^ threat(b; )! a#b3. cons(a; ) ^ threat(b; )! a#b 120\nComputational Aspects of Reordering PlansNote that it is not required that two producers, two consumers or two threats of the samecondition are non-concurrent, thus allowing, for instance, plans with multiple producers, egNebel and B ackstr om (1994, Fig. 4) and Kambhampati (1994). The axioms do not preventadding such restrictions, though. Furthermore, note that the de nition only states a nec-essary condition for non-concurrency|it is perfectly legal to add further non-concurrencyconstraints on the actions in a plan. It may also be worth noting that the MTC requiresproducers and threats to be ordered only if there is a correpsonding consumer, while ade nite plan satisfying the simple concurrency criterion always require them to be ordered.The following observation about PRF is immediate from the algorithm and will be usedin the proofs below.Observation 7.5 If hA; ;#i is the input to PRF and hA; 0;#i is the correspondingoutput, then it holds that a 0 b i a b and a#b.Based on this lemma, it can be proven that PRF preserves validity.Lemma 7.6 If the plan input to PRF is a valid PCT plan and # satis es the simpleconcurrency criterion, then the output plan is valid.Proof: Let P = hA; ;#i be the input plan and Q = hA; 0;#i the output plan. SinceP is valid, it follows from Theorem 7.3 that the MTC holds for P . Adding the impliedsimple-concurrency constraints to the MTC yields the following condition:8aC8 (cons(aC ; )!9aP (prod(aP ; ) ^ aP aC ^ aP#aC^8aT (threat(aT ; )!(aC aT ^ aC#aT )_9aW (prod(aW ; )^aT aW ^ aT#aW^aW aC ^ aW#aC)))).By applying Observation 7.5 this can be simpli ed to:8aC8 (cons(aC ; )!9aP (prod(aP ; ) ^ aP 0 aC^8aT (threat(aT ; )!aC 0 aT_9aW (prod(aW ; ) ^ aT 0 aW ^ aW 0 aC)))),which is the MTC for the plan Q. Once again using Theorem 7.3, it follows that Q is valid.2This allows for proving that PRF produces de nite minimum deorderings of de nite PCTplans under simple concurrency.Theorem 7.7 If using the PCT formalism and simple concurrency, then PRF produces aminimum-deordered de nite version of its input.121\nB ackstr omProof: Let P = hA; ;#i be the input plan, which is assumed valid and de nite, andQ = hA; 0;#i the output plan. It is obvious that 0 and it follows from Lemma 7.6 thatQ is valid, so Q is a deordering of P . It remains to prove that Q is a minimum deorderingof P .Suppose that P has a deordering R = hA; 00;#i s.t. j 00 j < j 0 j. Then, there mustbe some a; b 2 A s.t. a 0 b, but not a 00 b. It can be assumed that a 0 b is nota transitive arc in 0, since the transitive closure is anyway computed at the end of thealgorithm. Since the order 0 is produced by PRF, it follows from Observation 7.5 thata b and a#b. Because of the latter constraint, it is necessary that either, a 00 b orb 00 a holds, but only the former is possible since a b and R is a deordering of P . Thiscontradicts the assumption, so Q must be a minimum deordering of P . 2Since PRF is a polynomial algorithm, it follows that de nite minimum deorderings ofde nite PCT plans can be computed in polynomial time under simple concurrency. Fur-thermore, since PRF produces de nite plans it is possible to actually compute the shortestparallel execution e ciently.Theorem 7.8 If the plan input to PRF is a valid and de nite PCT plan satisfying thesimple concurrency criterion, then PRF outputs a de nite minimum deordering of this plan.Proof: PRF runs in polynomial time and obviously produces de nite parallel plans.Hence, it follows from Theorem 5.11 that a minimum parallel execution for the output plancan be found in polynomial time, which proves the theorem. 2It seems likely that this is what Regnier and Fade meant with their optimality claim, al-though for a special instance of the PCT formalism. This result says nothing about thedi culty of nding a minimum reordering of a plan, since PRF only considers deorderings.Since minimum deorderings do not approximate minimum reorderings well, it can be sus-pected that it is more di cult to compute the latter. The following theorem con rms thissuspicion, showing that the latter problem remains NP-hard under quite severe restrictions,including the following two.De nition 7.9 A GT action a is toggling i for all literals l 2 post(a), it is also the casethat :l 2 pre(a). A GT action a is unary i jpost(a)j = 1.Theorem 7.10 Minimum Parallel Reordering remains NP-hard even when restrictedto total-order GT plans with only toggling unary actions and under the assumption of unittime, simple concurrency and that no actions are redundant.The proof of this theorem appears in Appendix A.While minimum reorderings are more di cult to compute than minimum deorderings,they can also produce arbitrarily better results.Theorem 7.11 Minimum Parallel Deordering cannot approximate Minimum Par-allel Reordering within jAjk for any constant k 0.The proof of this theorem appears in Appendix A.122\nComputational Aspects of Reordering PlansCorollary 7.12 Minimum Parallel Deordering cannot approximate Minimum Par-allel Reordering within jAjk for any constant k 0 even when the problems are re-stricted to GT plans with only positive preconditions and under the assumption of simpleconcurrency.It may, thus, appear as though minimum reordering is a preferable, albeit more costly,operation than minimum deordering. However, if the plan modi cation is to be followedby scheduling, it is no longer obvious that a reordering is to prefer. Since scheduling maytake further information and constraints into account, eg upper and lower bounds on therelease time and limited resources, a feasible schedule for the original plan may no longer bea feasible schedule for a reordering of the same plan. That is, some or all feasible solutionsmay be lost when reordering a plan. In contrast to this, deordering a plan is harmlesssince all previously feasible schedules are preserved in the deordering. Of course, the de-/reordered plan may have new and better schedules than the old plan, which is why theproblems studied in this article are interesting at all. However, while minimum deorderingis a safe and, usually cheap, operation, minimum reordering is neither and must thus beapplied with more care. To nd a reordering of a plan with an optimum schedule wouldrequire combining minimum reordering and scheduling into one single computation, but itis out of the scope of this article to study such combinations. Su ce it to observe that sucha computation is never cheaper than either of its constituent computations.8. Related workThis section analyses and discusses some algorithms suggested in the literature for gener-alising the ordering of a plan, in addition to the PRF algorithm already analysed in thepreceeding section. Also some planners that generate plans with some optimality avouron the ordering are discussed.Some of the algorithms to be analysed use the common trick of simulating the initialstate and the goal of a planning instance by two extra operators, in the following way. LetP = hA; i be a plan and = hI;Gi a ppi, both in the GT language. Introduce two extraactions aI , with pre(aI) = ; and post(aI) = I, and aG, with pre(aG) = G and post(aG) = ;.De ne the plan Q = hA [ faI ; aGg; 0i where 0= [faI a; a aG j a 2 Ag[faI aGg,that is aI is ordered before all other actions and aG is ordered after all other actions. TheplanQ is a representation of both the plan P and the ppi . Such a combined representationwill be referred to as a self-contained plan. A self-contained plan is valid i it is valid wrt.to the ppi h;; ;i. It is trivial to convert a plan and a ppi into a corresponding self-containedplan and vice versa. Hence, both ways of representing a plan will be used alternatelywithout further notice.8.1 The VPC AlgorithmVeloso et al. (1990) have presented an algorithm (here referred to as VPC5) for convertingt.o. plans into `least-constrained' p.o. plans. They use the algorithm in the following context.First a total-order planner (NoLimit) is used to produce a t.o. plan. VPC converts this plan5. In the original publication the algorithm was named Build Partial Order.123\nB ackstr om1 procedure VPC;2 Input: a valid self-contained t.o. plan ha1; : : : ; aniwhere a1 = aI and an = aG3 Output: A self-contained valid p.o. plan4 for 1 i n do5 for p 2 pre(ai) do6 Find max k < i s.t. p 2 post(ak);7 if such a k exists then8 Order ak ai9 for :p 2 post(ai) do10 for 1 k < i s.t. p 2 pre(ak) do11 Order ak ai12 for each primary e ect p 2 post(ai) do13 for 1 k i s.t. :p 2 post(ak) do14 Order ai ak15 for 1 < i < n do16 Order aI ai and ai aG17 return hfa1; : : : ; ang; +i;Figure 11: The VPC algorithminto a p.o. plan which is then post-processed to determine which actions can be executedin parallel. The action language used is a STRIPS-style language allowing quanti ers andcontext-dependent e ects. However, the plans produced by the planner, and thus inputto VPC, are ground and without context-dependent e ects. That is, they are ordinarypropositional STRIPS plans. The VPC algorithm is presented in Figure 11, with a few minordi erences in presentation as compared to its original appearance: First, the algorithm ispresented in the GT formalism, in order to minimize the number of formalisms in this article,but all preconditions are assumed to be positive, thus coinciding with the original algorithm.Second, while the original algorithm returns the transitive reduction of the computed orderit instead returns the transitive closure here, an unimportant di erence in order to coincidewith the de nition of plans in this article. Furthermore, Veloso6 has pointed out that thepublished version of the VPC algorithm is incorrect and that a corrected version exists.The version presented in Figure 11 is this corrected version. A proposition is a primarye ect if it appears either in the goal or in the subgoaling chain of a goal proposition.VPC is a greedy algorithm which constructs an entirely new partial order by analysingthe action conditions, using the original total order only to guide the greedy strategy. Thealgorithm is claimed (Veloso et al., 1990, p. 207) to produce a `least-constrained' p.o. plan,although no de nition is given of what this means. Veloso7 has con rmed that the term `leastconstrained plan' was used in a `loose sense' and no optimality claim was intended. However,if this term is not de ned, then it is impossible to know what problem the algorithm isintended to solve or how to judge whether it makes any improvement over using no algorithmat all. In the absence of such a de nition from its authors, the algorithm will be analysedwith respect to the least-constrainment criteria de ned in Section 4. This is admittedly a6. Personal communication, oct. 1993.7. Veloso, ibid. 124\nComputational Aspects of Reordering Plans a bcpq p qrq s 1PPPPPPqP1 a b cpq p qr q s- -P2Figure 12: The p.o. plans in the failure example for VPC.somewhat unfair analysis, but it reveals some interesting facts about the algorithm, andabout what problems it does not solve. It is immediate from Theorem 4.8 and Corollary 4.9that VPC cannot be expected to produce minimum-constrained de-/reorderings. Perhapsmore surprisingly, VPC does not even guarantee that its output is a minimal -constraineddeordering of its input, a problem already proven trivially polynomial (Theorem 4.4). Thisis illustrated by the following example.Suppose a total-order planner is given the ppi = h;; fr; sgi as input. It may thenreturn either of the -valid t.o. plans ha; b; ci and ha; c; bi, with action conditions as shownin Figure 12. When used as input to VPC, these two t.o. plans will give quite di er-ent results|the plan ha; c; bi will be converted to the p.o. plan P1 in Figure 12, whilethe plan ha; b; ci will be converted to the p.o. plan P2 in Figure 12. That is, in the rstcase VPC produces a plan which is not only a minimal-constrained deordering but evena minimum-constrained deordering, while in the second case it does not even produce aminimal-constrained deordering.8The reason that VPC may fail to produce a minimal-constrained deordering is that ituses a non-admissible greedy strategy. Whenever it needs to nd an operator a achievingan e ect required by the precondition of another operator b, it chooses the last such actionordered before b in the input t.o. plan. However, there may be other actions earlier in theplan having the same e ect and being a better choice.8.2 The KK algorithmKambhampati and Kedar (1994) have presented an algorithm for generalising the order-ing of a p.o. plan, using explanation-based generalisation. The algorithm is based on rstconstructing a validation structure for the plan and then use this as a guide in the gen-eralisation phase. In the original paper, these computations are divided into two separatealgorithms (EXP-MTC and EXP-ORD-GEN), but are here compacted into one single al-gorithm, KK (Figure 13). Furthermore, the version presented here is restricted to groundGT plans, while the original algorithm can also handle partially instantiated plans. This isno restriction for the results to be shown below.The rst part of the KK algorithm constructs a validation structure V for the plan, thatis, an explanation for each precondition of every action in the plan. The validity criterionunderlying this phase is a simpli ed version of Chapmans modal-truth criterion (Chapman,8. Note that transitive arcs are omitted in the gures, so P2 really has an ordering relation of size three.Although this example would not work if plans had been de ned in the equally reasonable way thatordering relations should be intransitive, it is possible to construe similar examples also for this case.125\nB ackstr om 1 procedure KK2 Input: A valid self-contained p.o. plan hA; i3 Output: A deordering of the input plan4 comment Build a validation structure V for the plan5 V ;6 Let ha1; : : : ; ani be a topologically sorted version of hA; i7 for 1 i n do8 for p 2 pre(ai) do9 Find min k < i s.t.10 1. p 2 post(ak) and11 2. there is no j s.t. k < j < i and :p 2 post(aj)12 Add hak; p; aii to V13 comment Construct a generalised ordering 0 for the plan14 for each ha; bi 2 do15 Add ha; bi to 0 if either of the following holds16 1. a = aI or a = aG17 2. ha; p; bi 2 V for some p18 3. hc; p; ai 2 V and :p 2 post(b)19 4. hb; p; ci 2 V and :p 2 post(a)20 return hA; 0i Figure 13: The KK algorithm1987) without white knights. Since the algorithm is simpli ed to only handle ground planshere, an explanation is a causal link haP ; p; aCi, meaning that the action aP produces thecondition p which is consumed by the action aC . The algorithm constructs exactly onecausal link for each precondition, and it chooses the earliest producer of p preceeding aCwith no intervening action producing :p between this producer and aC . The second phaseof the algorithm builds a generalised ordering 0 for the plan based on this validationstructure. To put things simply, only those orderings of the original plan are kept whicheither correspond to a causal link in the validation structure or that is required to preventa threatening action to be unordered wrt. the actions in such a causal link.It turns out that also the KK algorithm fails in generating plans that are guaran-teed to be even minimal-constrained deorderings. Consider the t.o. plan hA;B;C;Diwith action conditions as indicated in Figure 14. This t.o. plan is valid for the ppih;; fr; s; t; ugi. Since the KK algorithm always chooses the earliest possible producerof a precondition for the validation structure, it will build the validation structurefhA; p;Di; hA; s; aGi; hB; q;Di; hB; t; aGi; hC; r; aGi; hD;u; aGig. Hence, the nal orderingproduced by KK will be as shown in Figure 14a. However, this plan is not a minimal-constrained deordering of the original plan, since it can be further deordered as shown inFigure 14b and remain valid. In this example, the input plan was totally ordered. In thecase of partially ordered input plans, the behaviour of the algorithm depends on the particu-lar topological order choosen. So the algorithm may or may not nd a minimal-constraineddeordering, but it is impossible to guarantee that it will succeed for all plans. Similarly, theauthors mention that one may consider di erent ways of constructing the validation struc-126\nComputational Aspects of Reordering Plansture. This would clearly also modify the behaviour and it remains an open question whetherit is possible to generate, in polynomial time, a validation structure that guarantees that aminimal-constrained deordering is constructed in the second phase of the algorithm. Find-ing a validation structure that guarantees a minimum-constrained deordering is obviouslyan NP-hard problem since the second phase of the algorithm is polynomial.psA qtB Dpq upsApqrC qtBZZZZ~ -Dq up qrC pa) Plan produced by KK b) Minimal deordered version of aFigure 14: Failure example for the KK algorithm8.3 Planners with Optimality GuaranteesThe planning algorithm Graphplan (Blum & Furst, 1997) has a notion of time steps andtries to pack as many non-interacting actions as possible into one single time step. Further-more, Graphplan nds the shortest plan, using the number of time steps as the measure.If assuming unit time and that all actions considered as non-interacting by Graphplancan be executed in parallel, then there is no plan having a shorter parallel execution thanthe plan produced by Graphplan. That is, Graphplan produces minimum reorderedparallel plans under these assumptions. The second assumption is no limitation in practice,since each non-concurrency relation can be encoded by introducing a new atom and lettingone of the interacting actions add it while the other one deletes it. The unit time assump-tion is more serious, however, especially since this assumption is likely not to hold in mostapplications. In the car-assembly scenario in Section 2, for instance, Graphplan wouldproduce a plan that corresponds to the plan in Figure 5. Hence, the plan produced underthe unit-time assumption happens to coincide with the optimal plan when taking actualexecution times into account. This is just a fortunate coincidence, however, depending onthe particular durations of actions in this example. Suppose instead that the durations ofthe actions are slightly di erent such that PAC has duration 2 and MvT1 has duration 8.Then the plan produced by Graphplan, which corresponds to the plan in Figure 5, doesnot have a faster schedule than 19 time units. This is not optimal since the plan in Figure 4can be scheduled to execute in 17 time units for these particular duration times. Further-more, it must be remembered that Graphplan is anyway restricted to those cases wherea GT-equivalent planning language is su cient, although recent improvements extend it to127\nB ackstr omsomewhat more expressive languages (Gazen & Knoblock, 1997; K ohler, Nebel, Ho man,& Dimopoulos, 1997).Knoblock (1994) has modi ed the UCPOP planner with a resource concept which makesit avoid unordered interacting actions. This means that the resulting planner producesde nite parallel plans. Knoblock further modi ed the evaluation heuristic of the search totake parallel execution time into account. It thus seems as if this planner might be able toproduce minimum reordered parallel plans, but the paper does not provide su cient detailsto determine whether this is the case. It is also unclear whether the heuristic can handleactions with di erent duration times.Yet another example is the polynomial-time planner for the SAS+-IAO planning lan-guage (Jonsson & B ackstr om, 1998) which produces plans which are minimum-constrainedreordered. That is, for this restricted formalism it is clearly possible to optimise the orderingin polynomial time.9. DiscussionThe previous section listed a few planning algorithms from the literature that produce orattempt to produce plans which are least constrained or minimum parallel reordered. Theydo so only under certain restrictions, though. Furthermore, plans are not always generated`from scratch', but can also be generated by modifying some already existing plan, referredto as case-based planning, or by repairing a plan that has failed during the execution phase.In such cases, the old plan may contain many ordering relations that will be obsolete inthe modi ed/repaired plan. In fact, the KK algorithm (Kambhampati & Kedar, 1994) ismotivated in the context of case-based planning. It is also important to remember thattoday, and probably for a long time into the future, very few plans are generated entirelyby computer programs. The vast majority of plans in various applications are designed byhumans, possibly with computer support. Already for quite small plans, it is very di cultfor a human to see whether the ordering constraints are optimal or not, so computer supportfor such analyses is vital for designing optimal plans. For the same reason, also hierarchical-task-network planners, eg O-Plan (Currie & Tate, 1991) and Sipe (Wilkins, 1988), produceplans where reordering actions could lead to better schedules. Such a planner often commitsto one of the two possible orderings for a pair of actions based on expert-knowledge rules.However, it is hardly possible for a human expert to design rules that in all situations willguarantee that the optimal ordering choice is made.On the coarseness level of complexity analysis it does not matter whether the tasksof planning, plan optimization and scheduling are integrated or separated since the totalresulting complexity will be the same in both cases|the latter two computations are at mostNP-complete and will, thus, be dominated by the planning, which is PSPACE-complete orworse. However, for good reasons this has not prevented the research community fromstudying planning and scheduling as separate problems, since understanding each problemin isolation also helps understanding the overall process. For the same reason, it is importantto also study separately the problems discussed and analysed in this article. Furthermore,on a more ne-grained, practical level there might be considerable di erences in e ciencybetween integrating the three computations and doing them separately. For instance, evenif all three computations take exponential time, each of the problems considered in isolation128\nComputational Aspects of Reordering Plansmay have fewer parameters, in which case it may be much more e cient to solve them inisolation. On the other hand, solving the whole problem at once may make it easier todo global optimisation. Which is the better will depend both on which methods are usedand on various properties of the actual application, and it seems unlikely that one of themethods should always be the better.As has been shown in this article, minimum reordering is a much better optimalitycriterion than minimum deordering, if only considering the overall parallel execution time.However, this is not necessarily true if also considering further metric constraints for subse-quent scheduling. Deordering a plan can only add to the number of feasible schedules, whilereordering may also remove some or, in the worst case, all feasible schedules. On the otherhand, reordering may also lead to new and better schedules not reachable via deordering.Deordering can thus be viewed as a safe and, sometimes, cheap way to allow for betterschedules, while reordering is an expensive method which has a potential for generatingconsiderably better plans, but which may also make things worse. If using reordering inpractice in cases where also metric scheduling constraints are involved, it seems necessaryto use feedback from the scheduler to control the reordering process, or to try other re-orderings. One could imagine a reordering algorithm which uses either heuristic search orrandomized local-search methods a la GSAT (Selman, Levesque, & Mitchell, 1992) to ndreorderings and then use the scheduler as evaluation function for the proposed reorderings.While the plan modi cations studied in this article may add considerably to the opti-mizations that are possible with traditional scheduling only, there is still a further potentialof optimization left to study|modifying not only the action order, but also the set of ac-tions. Such modi cation is already done in plan adaptation, but then only for generating anew plan from old cases, and optimizations in the sense of this article are not considered.Some preliminary studies of action-set modi cations appear in the literature, though. Finkand Yang (1992) study the problem of removing redundant actions from total-order plans,de ning a spectrum of redundancy criteria and analysing the complexity of achieving these.It is less clear that it is interesting to study action addition; adding actions to a plan couldobviously not improve the execution time of it if it is to be executed sequentially. However,in the case of parallel execution of plans it has been shown that adding actions to a plan cansometimes allow for faster execution (B ackstr om, 1994). Finally, if allowing both removaland addition of actions, an even greater potential for optimising plans seems available, butthis problems seems not yet studied in the literature.10. ConclusionsThis article studies the problem of modifying the action ordering of a plan in order tooptimise the plan according to various criteria. One of these criteria is to make a planless constrained and the other is to minimize its parallel execution time. Three candidatede nitions are proposed for the rst of these criteria, constituting a spectrum of increasingoptimality guarantees. Two of these are based on deordering plans, which means that or-dering relations may only be removed, not added, while the last one builds on reordering,where arbitrary modi cations to the ordering are allowed. The rst of the three candidates,subset-minimal deordering, is tractable to achieve, while the other two, deordering or re-129\nB ackstr omordering a plan to minimize the size of the ordering, are both NP-hard and even di cultto approximate.Similarly, optimising the parallel execution time of a plan is studied both for deorderingand reordering of plans. In the general case, both of these computations are NP-hard anddi cult to approximate. However, based on an algorithm from the literature it is shownthat optimal deorderings can be computed in polynomial time for de nite plans for a classof planning languages based on the notions of producers, consumers and threats, whichincludes most of the commonly used planning languages. Computing optimal reorderingscan potentially lead to even faster parallel executions, but this problem remains NP-hardand di cult to approximate even under quite severe restrictions. Furthermore, deorderinga plan is safe with respect to subsequent scheduling, while reordering a plan may removefeasible schedules, making deordering a good, but often suboptimal, approach in practice.AcknowledgementsTom Bylander, Thomas Drakengren, Mark Drummond, Alexander Horz, Peter Jonsson,Bernhard Nebel, Erik Sandewall, Sylvie Thibeaux and the anonymous referees providedhelpful comments on this article and previous versions of it. The research was supportedby the Swedish Research Council for Engineering Sciences (TFR) under grants Dnr. 92-143and 95-731.Appendix ATheorem 7.10 Minimum Parallel Reordering remains NP-hard even when restrictedto total-order GT plans with only toggling unary actions and under the assumption of unittime, simple concurrency and that no actions are redundant.Proof: Proof by reduction from 3SAT (Garey & Johnson, 1979, p. 259). Let P =fp1; : : : ; png be a set of atoms and C = fC1; : : : ; Cmg a set of clauses over P s.t. for1 i m, Ci = fli;1; li;2; li;3g is a set of three literals over P.First de ne the set of atomsQ = fpFi ; pTi ; qi j 1 i ng [ fci;j ; ri;j j 1 i n; 1 j 3g:Then de ne a GT ppi = hI;Gi with initial and goal states de ned asI = Neg(Q)G = fpFi ; pTi ;:qi j 1 i ng [ fci;j ;:ri;j j 1 i n; 1 j 3gAlso, for each atom pi 2 P, de ne four actions according to Table 2.Further, for each clause Ci 2 C, de ne nine actions according to Table 3 wherel i;j = ( pFk if li;j = :pkpTk if li;j = pk:Let A be the set of all 4n + 9m actions thus de ned. Clearly there is some total order s.t. the plan P = hA; i is -valid. It is also obvious that none of the actions is redundant.130\nComputational Aspects of Reordering PlansIt is a trivial observation that any parallel execution r of any -valid reordering of Pmust satisfy that for each i, 1 i n, eitherr(AFi ) < r(A+i ) < r(ATi ) < r(A i )or r(A+i ) < r(ATi ) < r(A i ) < r(AFi );and for each i, 1 i m,r(C+i;k1) < r(B+i;k1) < ( r(C i;k1)r(C+i;k2) ) < r(B+i;k2) < ( r(C i;k2)r(C+i;k3) ) < r(B+i;k3) < r(C i;k3);where k1; k2; k3 is a permutation of the numbers 1; 2; 3. (This is to be interpreted s.t. theactions C i;k1 and C+i;k2 can be released in either order, or simultaneously, and analogouslyfor the actions C i;k2 and C+i;k3).The remainder of this proof shall show that P can be reordered to have a parallelexecution of length 8 i the set C of clauses is satis able.if: Suppose C is satis able. Let I be a truth assignment for the atoms in P that satis esC. Wlg. assume I(pi) = T for all i. Further, for each clause Cj , let lj be any literal in Cjwhich is satis ed by I. Disregarding the action order for a moment, choose a release-timefunction r for the actions as follows. For 1 i n, letr(A+i ) = 0; r(ATi ) = 1; r(A i ) = 2; r(AFi ) = 3:Further, for each j, 1 j m, choose k1 s.t. lj;k1 2 Cj is satis ed by I (at least one suchchoice must exist by the assumption). Let lj;k2 and lj;k3 be the remaining two literals in Cj .Assign release times s.t. for 1 h 3,r(C+j;kh) = 2h 1; r(B+j;kh) = 2h ; r(C j;kh) = 2h+ 1:Now de ne the partial order 0 on A s.t. for all actions a; b 2 A, a 0 b i r(a) < r(b).Clearly, the plan hA; 0i is a -valid reordering of P and r is a parallel execution of length8 for hA; 0i. (Note that no other choice of I could force a longer execution, while there isan execution of length 7 in the case where C is satis ed by setting all atoms false.)operator precond. postcond.AFi :pFi ;:qi pFiATi :pTi ; qi pTiA+i :qi qiA i qi :qiTable 2: Generic actions for each atom pi in the proof of Theorem 7.10.131\nB ackstr om operator precond. postcond.B+i;1 l i;1; ri;1;:ri;2;:r1;3;:ci;1 ci;1B+i;2 l i;2;:ri;1; ri;2;:r1;3;:ci;2 ci;2B+i;3 l i;3;:ri;1;:ri;2; r1;3;:ci;3 ci;3C+i;1 :ri;1 ri;1C i;1 ri;1 :ri;1C+i;2 :ri;2 ri;2C i;2 ri;2 :ri;2C+i;3 :ri;3 ri;3C i;3 ri;3 :ri;3Table 3: Generic atoms for each clause Ci in the proof of Theorem 7.10.only if: Suppose C is not satis able. Further suppose that Q is a minimum reorderingof P and that r is a parallel execution of length 8 or shorter for Q. Wlg. assume that everyaction is released as early as possible by r. Then, according to the observation above itmust hold for each i, 1 i n, that eitherr(AFi ) = 0; r(A+i ) = 1; r(ATi ) = 2; r(A i ) = 3or r(A+i ) = 0; r(ATi ) = 1; r(A i ) = 2; r(AFi ) = 3:Hence, exactly one of the atoms pFi and pTi is true at time 2. Let p i denote this atom. Sincer is of length 8, it follows from the earlier observation that for all j, 1 j m, r(B+j;k) 2for some k, 1 k 3. Hence, lj;k = p i for some i, since Q is -valid and r is a parallelexecution for Q. De ne an interpretation I s.t. for all i, 1 i n,I(pi) = ( F; if p i = pFiT; otherwise :However, this interpretation is obviously a model for C, which contradicts the assumption.It follows that r must be of length 9 or longer.This concludes the proof and shows that C is satis able i P has a reordering with aparallel execution of length 8 or not. 2Theorem 7.11 Minimum Parallel Deordering cannot approximate MinimumParallel Reordering within jAjk for any constant k 0.Proof: The proof assumes GT plans and simple concurrency. First, de ne the genericactions aki (m), bki and cki (m) according to Table 10. Further, de ne recursively the genericplansP ki (m) = ( ha1(i 1)m+1(1); b0(i 1)m+1; c1(i 1)m+1(1); : : : ; a1im(1); b0im; c1im(1)i; for k = 1hak(i 1)m+1(m);P k 1(i 1)m+1(m); ck1(m); : : : ; akim(m);P k 1im (m); ckim(m)i; for k > 1:132\nComputational Aspects of Reordering PlansFurthermore, for arbitrary k; n > 0 de ne the ppi kn = hfpk1 ; : : : ; pkng; fqk1 ; : : : ; qkngi.Now, prove the claim that for arbitrary k; n > 0, the plan P k1 (n)1. is kn-valid,2. has no deordering of length less than 3nk +Pk 1i=1 2ni and3. has a reordering of length 2k + 1.Proof by induction over k.Base case (k=1): Choose an arbitrary n > 0. The plan P 11 (n) is obviously kn-valid andhas no deordering other than itself, which is of length 3n. Consider the reordering Q11(n) ofP 11 (n) with the same actions and with ordering relation de ned s.t. for all i, 1 i n,a1i (1) b0i c1i (1) and for all i, 1 < i n, a1i (1) b0i 1. This reordering is k(n)-valid andhas a parallel execution r11(n) of length 3, de ned s.t. for all i, 1 i n, r11(n)(a1i (1)) = 1,r11(n)(b0i ) = 2 and r11(n)(c1i (1)) = 3. (This plan is shown in Figure 15.) The claim is thussatis ed for the base case.Induction: Suppose the claim is satis ed for all l < k, for some k 1 and prove thatthe claim holds also for l = k. Choose an arbitrary n > 0. It follows from the inductionhypothesis that none of the subplans P k 11 (n) : : : ; P k 1n (n) can be deordered, so they haveto remain totally ordered. Furthermore, for all i, 1 i n, it is necessary that the actionaki (n) is ordered before the subplan P k 1i (n) and that the action cki (n) is ordered after it.It is also clear that for no i, 1 i n can the order cki (n) aki+1(n) be removed withoutmaking the plan invalid. Hence, P k1 (n) has no other deordering than itself, which is oflength nXi=1(2 + length(P k 1i (n)) = n(2 + length(P k 11 (n)))= 2n+ n(3nk 1 + k 2Xi=1 2ni) = 3nk + k 1Xi=1 2ni;which proves the deordering case of the claim.For the reordering case, de ne a reordering Qk1(n) of P k1 (n) with the same actions andwith ordering relation de ned as follows. For each subplan P k 1i (n) of P k1 (n), reorder itsactions so it has length 2(k 1)+1, which is possible according to the induction hypothesis.Further, for each i, 1 i n, and each j, (i 1)n+1 j in order aki (n) ak 1j (n) andck 1j (n) cki (n) (or aki+1(n) ak 1j (1) and ck 1j (1) cki (n) for the case k = 2). Hence, eachaction pre-condition post-conditionaki (m) fpki g fpk 1(i 1)m+1; : : : ; pk 1im ;:qk 1(i 1)mgbki fpki g fqki gcki (m) fqk 1(i 1)m+1; : : : ; qk 1im g post(cki (m)) = fqki g:Table 4: Generic actions for the proof of Theorem 7.11.133\nB ackstr om\n.XXXXXz : XXXXXz :........... ...........a22(n) c22(n)P 12 (n) :XXXXXz XXXXXz :........... ...........a2n(n) c2n(n)P 1n(n)\n- -\n-- - - :@@@@@@R @@@@@@RXXXXXXz ......... .................. .......... 1 1 :......... ......... b0n b02b01a11(1)a12(1) a1n(1) c11(1)c12(1) c1n(1)a 21(n) c21(n) p01 q01q02p02 p0n q0n q11 q1nq12:q0(n 1) :q01p11p12p1n P 11 (n) :q02 :q1n\n:q1(n 1)Figure 15: The reordering Q21(n) of the plan P 21 (n) as an example of the induction case inthe proof of Theorem 7.11 (solid arrows denote orderings required by producer-consumer relationships and are labelled with the atom produced/consumed,while dashed arrows denote ordering constraints to avoid threats and are la-belled with the possibly con icting atom).segment of the type aki (n);P k 1i (n); cki (n) is reordered to have length 2k + 1. Finally, foreach i, 1 i n, order aki (n) ak 1(i 1)n(n) (or aki (n) ak 1(i 1)n(1) for the case k = 2). Theplan Qk1(n) is k(n)-valid since the subplans P k 11 (n); : : : ; P k 1n (n) do not have any atomsin common and, thus, the # relation does not hold between any two actions belonging todi erent such subplans. This reordered plan can be executed under the parallel executionrki (n) de ned s.t. rki (n)(aki (n)) = 1, rki (n)(cki (n)) = 2k + 1 and for all i, 1 i n andall actions a0 2 Qk 1i (n), rki (n)(a0) = rk 1i (n)(a0) + 1. Since this is a parallel execution oflength 2k + 1 for the reordered plan, the claim holds also for k.This concludes the induction, so the claim holds for all k > 0. Since3nk +Pk 1i=1 2ni2k + 1 1(2k + 1)3k 1 jAjkfor all k > 0, the theorem holds. 2134\nComputational Aspects of Reordering PlansReferencesB ackstr om, C. (1993). Finding least constrained plans and optimal parallel executions isharder than we thought. In B ackstr om, C., & Sandewall, E. (Eds.), Current Trends inAI Planning: EWSP'93|2nd European Workshop on Planning, pp. 46{59 Vadstena,Sweden. IOS Press.B ackstr om, C. (1994). Executing parallel plans faster by adding actions. In Cohn,A. G. (Ed.), Proceedings of the 11th European Conference on Arti cial Intelligence(ECAI'94), pp. 615{619 Amsterdam, Netherlands. Wiley.B ackstr om, C. (1995). Expressive equivalence of planning formalisms. Arti cial Intelligence,76 (1{2), 17{34.B ackstr om, C., & Klein, I. (1991). Parallel non-binary planning in polynomial time. InReiter, R., & Mylopoulos, J. (Eds.), Proceedings of the 12th International Joint Con-ference on Arti cial Intelligence (IJCAI'91), pp. 268{273 Sydney, Australia. MorganKaufmann.Bellare, M., Goldreich, O., & Sudan, M. (1995). Free bits, PCPs and non-approximability|towards tighter results. In Proceedings of the 36th Annual IEEE Symposium on theFoundations of Computer Science (FOCS'95), pp. 422{431 Milwaukee, WI, USA.IEEE Computer Society.Blum, A. L., & Furst, M. L. (1997). Fast planning through planning graph analysis. Arti cialIntelligence, 90 (1{2), 281{300.Chapman, D. (1987). Planning for conjunctive goals. Arti cial Intelligence, 32 (3), 333{377.Crescenzi, P., & Panconesi, A. (1991). Completeness in approximation classes. Informationand Computation, 93 (2), 241{262.Currie, K., & Tate, A. (1991). O-Plan: The open planning architecture. Arti cial Intelli-gence, 52 (1), 49{86.Feige, U., & Kilian, J. (1996). Zero knowledge and the chromatic number. In 11th AnnualIEEE Conference on Computational Compelxity (CCC'96) Philadelphia, PA, USA.IEEE Computer Society.Feige, U. (1996). A threshold of lnn for approximating set cover (preliminary version). InProceedings of 28th Annual ACM Symposium on Theory of Computing (STOC'96),pp. 314{318 Philadelphia, PA, USA. ACM.Fink, E., & Yang, Q. (1992). Formalizing plan justi cations. In Proceedings of the 9th Con-ference of the Canadian Society for Computational Studies of Intelligence (CSCSI'92),pp. 9{14 Vancouver, BC, Canada.Garey, M., & Johnson, D. (1979). Computers and Intractability: A Guide to the Theory ofNP-Completeness. Freeman, New York.135\nB ackstr omGazen, C., & Knoblock, C. (1997). Combining the expressivity of UCPOP with the e ciencyof Graphplan. In Steel, & Alami (1997), pp. 221{233.Ghallab, M., & Laruelle, H. (1994). Representation and control in IxTeT, a temporalplanner. In Hammond (1994), pp. 61{67.Hammond, K. (Ed.). (1994). Proceedings of the 2nd International Conference on Arti cialIntelligence Planning Systems (AIPS'94), Chicago, IL, USA. AAAI Press.Jonsson, P., & B ackstr om, C. (1998). State-variable planning under structural restrictions:Algorithms and complexity. Arti cial Intelligence, 100 (1{2), 125{176.Kambhampati, S. (1994). Multi-contributor causal structures for planning: A formalizationand evaluation. Arti cial Intelligence, 69 (1{2), 235{278.Kambhampati, S., & Kedar, S. (1994). A uni ed framework for explanation-based gener-alization of partially ordered and partially instantiated plans. Arti cial Intelligence,67 (1), 29{70.Klein, I., Jonsson, P., & B ackstr om, C. (1995). Tractable planning for an assembly line.In Ghallab, M., & Milani, A. (Eds.), New Directions in AI Planning: EWSP'95|3rd European Workshop on Planning, Frontiers in AI and Applications, pp. 313{324Assisi, Italy. IOS Press.Klein, I., Jonsson, P., & B ackstr om, C. (1998). E cient planning for a miniature assemblyline. Arti cial Intelligence in Engineering, 13 (1), 69{81.Knoblock, C. (1994). Generating parallel execution plans with a partial-order planner. InHammond (1994).K ohler, J., Nebel, B., Ho man, J., & Dimopoulos, Y. (1997). Extending planning graphsto an ADL subset. In Steel, & Alami (1997), pp. 273{285.Lund, C., & Yannakakis, M. (1994). On the hardness of approximating minimization prob-lems. Journal of the ACM, 41 (5), 960{981.Nebel, B., & B ackstr om, C. (1994). On the computational complexity of temporal projec-tion, planning and plan validation. Arti cial Intelligence, 66 (1), 125{160.Pednault, E. P. D. (1986). Formulating multiagent, dynamic-world problems in the classicalplanning framework. In George , M., & Lansky, A. L. (Eds.), Reasoning about Ac-tions and Plans, Proceedings of the 1986 Workshop, pp. 47{82 Timberline, OR, USA.Morgan Kaufmann.Regnier, P., & Fade, B. (1991a). Complete determination of parallel actions and temporaloptimization in linear plans of action. In Hertzberg, J. (Ed.), European Workshopon Planning, Vol. 522 of Lecture Notes in Arti cial Intelligence, pp. 100{111 SanktAugustin, Germany. Springer. 136\nComputational Aspects of Reordering PlansRegnier, P., & Fade, B. (1991b). D etermination du parall elisme maximal et optimisationtemporelle dans les plans d'actions lin eaires. Revue d'intelligence arti cielle, 5 (2),67{88.Selman, B., Levesque, H., & Mitchell, D. (1992). A new method for solving hard satis -ability problems. In Proceedings of the 10th (US) National Conference on Arti cialIntelligence (AAAI'92), pp. 440{446 San Jos e, CA, USA. American Association forArti cial Intelligence.Steel, S., & Alami, R. (Eds.). (1997). 4th European Conference on Planning, ECP'97, Vol.1348 of Lecture Notes in Arti cial Intelligence, Toulouse, France. Springer.Str omberg, J.-E. (1991). Styrning av LEGO-bilfabrik. Andra omarbetade upplagan. De-partment of Electrical Engineering, Link oping University.Tate, A. (1975). Interacting goals and their use. In Proceedings of the 4th InternationalJoint Conference on Arti cial Intelligence (IJCAI'75), pp. 215{218 Tbilisi, USSR.IJCAI, William Kaufmann.Veloso, M. M., P erez, M. A., & Carbonell, J. G. (1990). Nonlinear planning with parallelresource allocation. In Sycara, K. P. (Ed.), Workshop on Innovative Approachesto Planning, Scheduling and Control, pp. 207{212 San Diego, CA, USA. MorganKaufmann.Vere, S. A. (1983). Planning in time: Windows and durations for activities and goals. IEEETransactions on Pattern Analysis and Machine Intelligence, PAMI-5 (3), 246{267.Wilkins, D. E. (1988). Practical Planning. Morgan Kaufmann, San Mateo, CA.\n137"
    } ],
    "references" : [ {
      "title" : "Finding least constrained plans and optimal parallel executions",
      "author" : [ "C. Backstrom" ],
      "venue" : null,
      "citeRegEx" : "Backstrom,? \\Q1993\\E",
      "shortCiteRegEx" : "Backstrom",
      "year" : 1993
    }, {
      "title" : "Executing parallel plans faster by adding actions",
      "author" : [ "C. Backstrom" ],
      "venue" : null,
      "citeRegEx" : "Backstrom,? \\Q1994\\E",
      "shortCiteRegEx" : "Backstrom",
      "year" : 1994
    }, {
      "title" : "Expressive equivalence of planning formalisms",
      "author" : [ "C. Backstrom" ],
      "venue" : "Arti cial Intelligence,",
      "citeRegEx" : "Backstrom,? \\Q1995\\E",
      "shortCiteRegEx" : "Backstrom",
      "year" : 1995
    }, {
      "title" : "Parallel non-binary planning in polynomial time",
      "author" : [ "C. om", "I. Klein" ],
      "venue" : null,
      "citeRegEx" : "om and Klein,? \\Q1991\\E",
      "shortCiteRegEx" : "om and Klein",
      "year" : 1991
    }, {
      "title" : "Fast planning through planning graph analysis",
      "author" : [ "A.L. Blum", "M.L. Furst" ],
      "venue" : null,
      "citeRegEx" : "Blum and Furst,? \\Q1997\\E",
      "shortCiteRegEx" : "Blum and Furst",
      "year" : 1997
    }, {
      "title" : "Planning for conjunctive goals",
      "author" : [ "D. Chapman" ],
      "venue" : "Arti cial Intelligence,",
      "citeRegEx" : "Chapman,? \\Q1987\\E",
      "shortCiteRegEx" : "Chapman",
      "year" : 1987
    }, {
      "title" : "Completeness in approximation classes",
      "author" : [ "P. Crescenzi", "A. Panconesi" ],
      "venue" : null,
      "citeRegEx" : "Crescenzi and Panconesi,? \\Q1991\\E",
      "shortCiteRegEx" : "Crescenzi and Panconesi",
      "year" : 1991
    }, {
      "title" : "O-Plan: The open planning architecture",
      "author" : [ "K. Currie", "A. Tate" ],
      "venue" : null,
      "citeRegEx" : "Currie and Tate,? \\Q1991\\E",
      "shortCiteRegEx" : "Currie and Tate",
      "year" : 1991
    }, {
      "title" : "Zero knowledge and the chromatic number",
      "author" : [ "U. Feige", "J. Kilian" ],
      "venue" : null,
      "citeRegEx" : "Feige and Kilian,? \\Q1996\\E",
      "shortCiteRegEx" : "Feige and Kilian",
      "year" : 1996
    }, {
      "title" : "A threshold of lnn for approximating set cover (preliminary version)",
      "author" : [ "U. Feige" ],
      "venue" : null,
      "citeRegEx" : "Feige,? \\Q1996\\E",
      "shortCiteRegEx" : "Feige",
      "year" : 1996
    }, {
      "title" : "Formalizing plan justi cations",
      "author" : [ "E. Fink", "Q. Yang" ],
      "venue" : "In Proceedings of the 9th Con-",
      "citeRegEx" : "Fink and Yang,? \\Q1992\\E",
      "shortCiteRegEx" : "Fink and Yang",
      "year" : 1992
    }, {
      "title" : "Computers and Intractability: A Guide to the Theory",
      "author" : [ "M. Garey", "D. Johnson" ],
      "venue" : null,
      "citeRegEx" : "Garey and Johnson,? \\Q1979\\E",
      "shortCiteRegEx" : "Garey and Johnson",
      "year" : 1979
    }, {
      "title" : "Combining the expressivity of UCPOP with the e ciency",
      "author" : [ "C. Gazen", "C. Knoblock" ],
      "venue" : null,
      "citeRegEx" : "Gazen and Knoblock,? \\Q1997\\E",
      "shortCiteRegEx" : "Gazen and Knoblock",
      "year" : 1997
    }, {
      "title" : "Representation and control in IxTeT, a temporal",
      "author" : [ "M. Ghallab", "H. Laruelle" ],
      "venue" : null,
      "citeRegEx" : "Ghallab and Laruelle,? \\Q1994\\E",
      "shortCiteRegEx" : "Ghallab and Laruelle",
      "year" : 1994
    }, {
      "title" : "State-variable planning under structural restrictions",
      "author" : [ "P. Jonsson", "C. Backstrom" ],
      "venue" : null,
      "citeRegEx" : "Jonsson and Backstrom,? \\Q1998\\E",
      "shortCiteRegEx" : "Jonsson and Backstrom",
      "year" : 1998
    }, {
      "title" : "Multi-contributor causal structures for planning: A formalization",
      "author" : [ "S. Kambhampati" ],
      "venue" : null,
      "citeRegEx" : "Kambhampati,? \\Q1994\\E",
      "shortCiteRegEx" : "Kambhampati",
      "year" : 1994
    }, {
      "title" : "A uni ed framework for explanation-based",
      "author" : [ "S. Kambhampati", "S. Kedar" ],
      "venue" : null,
      "citeRegEx" : "Kambhampati and Kedar,? \\Q1994\\E",
      "shortCiteRegEx" : "Kambhampati and Kedar",
      "year" : 1994
    }, {
      "title" : "Tractable planning for an assembly line",
      "author" : [ "I. Klein", "P. Jonsson", "C. Backstrom" ],
      "venue" : null,
      "citeRegEx" : "Klein et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Klein et al\\.",
      "year" : 1995
    }, {
      "title" : "E cient planning for a miniature assembly",
      "author" : [ "I. Klein", "P. Jonsson", "C. Backstrom" ],
      "venue" : null,
      "citeRegEx" : "Klein et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Klein et al\\.",
      "year" : 1998
    }, {
      "title" : "Generating parallel execution plans with a partial-order planner",
      "author" : [ "C. Knoblock" ],
      "venue" : null,
      "citeRegEx" : "Knoblock,? \\Q1994\\E",
      "shortCiteRegEx" : "Knoblock",
      "year" : 1994
    }, {
      "title" : "Extending planning graphs",
      "author" : [ "J. ohler", "B. Nebel", "J. Ho man", "Y. Dimopoulos" ],
      "venue" : null,
      "citeRegEx" : "ohler et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "ohler et al\\.",
      "year" : 1997
    }, {
      "title" : "On the hardness of approximating minimization",
      "author" : [ "C. Lund", "M. Yannakakis" ],
      "venue" : null,
      "citeRegEx" : "Lund and Yannakakis,? \\Q1994\\E",
      "shortCiteRegEx" : "Lund and Yannakakis",
      "year" : 1994
    }, {
      "title" : "On the computational complexity of temporal projec",
      "author" : [ "B. Nebel", "C. Backstrom" ],
      "venue" : null,
      "citeRegEx" : "Nebel and Backstrom,? \\Q1994\\E",
      "shortCiteRegEx" : "Nebel and Backstrom",
      "year" : 1994
    }, {
      "title" : "Formulating multiagent, dynamic-world problems in the classical",
      "author" : [ "E.P.D. Pednault" ],
      "venue" : null,
      "citeRegEx" : "Pednault,? \\Q1986\\E",
      "shortCiteRegEx" : "Pednault",
      "year" : 1986
    }, {
      "title" : "Complete determination of parallel actions and temporal",
      "author" : [ "P. Regnier", "B. Fade" ],
      "venue" : null,
      "citeRegEx" : "Regnier and Fade,? \\Q1991\\E",
      "shortCiteRegEx" : "Regnier and Fade",
      "year" : 1991
    }, {
      "title" : "A new method for solving hard satis ",
      "author" : [ "B. Selman", "H. Levesque", "D. Mitchell" ],
      "venue" : null,
      "citeRegEx" : "Selman et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Selman et al\\.",
      "year" : 1992
    }, {
      "title" : "Styrning av LEGO-bilfabrik. Andra omarbetade upplagan",
      "author" : [ "omberg", "J.-E" ],
      "venue" : null,
      "citeRegEx" : "omberg and J..E.,? \\Q1991\\E",
      "shortCiteRegEx" : "omberg and J..E.",
      "year" : 1991
    }, {
      "title" : "Interacting goals and their use",
      "author" : [ "A. Tate" ],
      "venue" : "In Proceedings of the 4th International",
      "citeRegEx" : "Tate,? \\Q1975\\E",
      "shortCiteRegEx" : "Tate",
      "year" : 1975
    }, {
      "title" : "Planning in time: Windows and durations for activities and goals",
      "author" : [ "S.A. Vere" ],
      "venue" : null,
      "citeRegEx" : "Vere,? \\Q1983\\E",
      "shortCiteRegEx" : "Vere",
      "year" : 1983
    }, {
      "title" : "Practical Planning",
      "author" : [ "D.E. Wilkins" ],
      "venue" : null,
      "citeRegEx" : "Wilkins,? \\Q1988\\E",
      "shortCiteRegEx" : "Wilkins",
      "year" : 1988
    } ],
    "referenceMentions" : [ {
      "referenceID" : 29,
      "context" : "In some planning systems, eg O-Plan (Currie & Tate, 1991) and Sipe (Wilkins, 1988), both planning and scheduling are integrated into one single system.",
      "startOffset" : 67,
      "endOffset" : 82
    }, {
      "referenceID" : 28,
      "context" : "Similarly, temporal planners, eg Deviser (Vere, 1983) and IxTeT (Ghallab & Laruelle, 1994), can often reason also about metric constraints.",
      "startOffset" : 41,
      "endOffset" : 53
    }, {
      "referenceID" : 0,
      "context" : "The example is a variation of the example used by Backstrom and Klein (1991), which is a much simpli ed version of an existing assembly line for toy cars used for undergraduate laborations in digital control at Link oping University (for a description of this assembly line, see eg.",
      "startOffset" : 50,
      "endOffset" : 79
    }, {
      "referenceID" : 5,
      "context" : "2 The Ground TWEAK Formalism The Ground TWEAK (GT) formalism is the TWEAK language (Chapman, 1987) restricted to ground actions.",
      "startOffset" : 83,
      "endOffset" : 98
    }, {
      "referenceID" : 2,
      "context" : "This formalism is a variation on propositional STRIPS and it is known to be equivalent under polynomial transformation to most other common variants on propositional STRIPS (Backstrom, 1995).",
      "startOffset" : 173,
      "endOffset" : 192
    }, {
      "referenceID" : 23,
      "context" : "plans have been presented in the literature (Pednault, 1986; Regnier & Fade, 1991a; Veloso, P erez, & Carbonell, 1990) (all these algorithms will be analyzed later in this article).",
      "startOffset" : 44,
      "endOffset" : 118
    }, {
      "referenceID" : 0,
      "context" : "j 00 j < j j; Note that the previous publication (Backstrom, 1993) used the terms LC1-minimality for minimal-constrained deordering and LC2-minimality for minimum-constrained reordering.",
      "startOffset" : 49,
      "endOffset" : 68
    }, {
      "referenceID" : 2,
      "context" : "More precisely, this proof pertains to the Common Propositional STRIPS formalism (CPS) and, thus, holds also for the other common variants of propositional STRIPS, like Ground TWEAK (Backstrom, 1995).",
      "startOffset" : 182,
      "endOffset" : 201
    }, {
      "referenceID" : 9,
      "context" : "2 If using the number of propositional atoms in the plan as a measure of its size, this bound can be strengthened to (1 \") ln jPj for arbitrary \" unless NP 2 DTIME (nlog log n) by substituting such a result for Minimum Cover (Feige, 1996) in the proof above.",
      "startOffset" : 225,
      "endOffset" : 238
    }, {
      "referenceID" : 23,
      "context" : "Incidentally, the algorithm proposed by Regnier and Fade is a special case of an algorithm earlier proposed for the same problem by Pednault (1986), who did not make any claims about optimality.",
      "startOffset" : 132,
      "endOffset" : 148
    }, {
      "referenceID" : 5,
      "context" : "Chapman's Modal-truth Criterion (MTC) (Chapman, 1987) can be abstracted to the PCT formalism and be analogously used for validating p.",
      "startOffset" : 38,
      "endOffset" : 53
    }, {
      "referenceID" : 0,
      "context" : "9 in Nebel and Backstrom (1994). 2 Only a minimum of constraints for when two actions may not be executed in parallel will be required.",
      "startOffset" : 15,
      "endOffset" : 34
    }, {
      "referenceID" : 0,
      "context" : "Computational Aspects of Reordering Plans Note that it is not required that two producers, two consumers or two threats of the same condition are non-concurrent, thus allowing, for instance, plans with multiple producers, eg Nebel and Backstrom (1994, Fig. 4) and Kambhampati (1994). The axioms do not prevent adding such restrictions, though.",
      "startOffset" : 235,
      "endOffset" : 285
    }, {
      "referenceID" : 14,
      "context" : "2 The KK algorithm Kambhampati and Kedar (1994) have presented an algorithm for generalising the ordering of a p.",
      "startOffset" : 19,
      "endOffset" : 48
    }, {
      "referenceID" : 29,
      "context" : "For the same reason, also hierarchicaltask-network planners, eg O-Plan (Currie & Tate, 1991) and Sipe (Wilkins, 1988), produce plans where reordering actions could lead to better schedules.",
      "startOffset" : 102,
      "endOffset" : 117
    }, {
      "referenceID" : 15,
      "context" : "B ackstr om somewhat more expressive languages (Gazen & Knoblock, 1997; K ohler, Nebel, Ho man, & Dimopoulos, 1997). Knoblock (1994) has modi ed the UCPOP planner with a resource concept which makes it avoid unordered interacting actions.",
      "startOffset" : 58,
      "endOffset" : 136
    }, {
      "referenceID" : 1,
      "context" : "However, in the case of parallel execution of plans it has been shown that adding actions to a plan can sometimes allow for faster execution (Backstrom, 1994).",
      "startOffset" : 141,
      "endOffset" : 160
    }, {
      "referenceID" : 7,
      "context" : "Fink and Yang (1992) study the problem of removing redundant actions from total-order plans, de ning a spectrum of redundancy criteria and analysing the complexity of achieving these.",
      "startOffset" : 0,
      "endOffset" : 21
    } ],
    "year" : 2011,
    "abstractText" : null,
    "creator" : "dvipsk 5.58f Copyright 1986, 1994 Radical Eye Software"
  }
}