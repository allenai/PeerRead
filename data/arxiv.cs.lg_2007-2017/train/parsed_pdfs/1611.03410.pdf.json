{
  "name" : "1611.03410.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Binomial Checkpointing for Arbitrary Programs with No User Annotation∗",
    "authors" : [ "Jeffrey Mark Siskind", "Barak A. Pearlmutter" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "Binomial Checkpointing for Arbitrary Programs with No User Annotation∗",
      "text" : "Jeffrey Mark Siskind† Barak A. Pearlmutter‡\nApril 2016\nHeretofore, automatic checkpointing at procedure-call boundaries [1], to reduce the space complexity of reverse mode, has been provided by systems like Tapenade [2]. However, binomial checkpointing, or treeverse [3], has only been provided in AD systems in special cases, e.g., through user-provided pragmas on DO loops in Tapenade, or as the nested taping mechanism in adol-c for time integration processes, which requires that user code be refactored. We present a framework for applying binomial checkpointing to arbitrary code with no special annotation or refactoring required. This is accomplished by applying binomial checkpointing directly to a program trace. This trace is produced by a general-purpose checkpointing mechanism that is orthogonal to AD.\nListing 1: Fortran example\nsubroutine f(x, y) n = 100003 y = x\nc$ad binomial -ckp n+1 30 1 do i = 1, n\nm = l(x, i) do j = 1, m\ny = y*y y = sqrt(y)\nend do end do end\nConsider the code fragment in Listing 1. This example, y = f(x), while contrived, is a simple caricature of a situation that arises commonly in practice, e.g., in adaptive grid methods. Here, the duration of the inner loop varies wildly as some function l(x, i) of the input and the outer loop index, perhaps 2⌊lg(n)⌋−⌊lg(1+(1007⌊3\nx⌋i mod n))⌋, that is small on most iterations of the outer loop but O(n) on a few iterations. Thus the optimality of the binomial schedule is violated. The issue is that the optimality of the binomial schedule holds at the level of primitive atomic computations but this is not reflected in the static syntactic structure of the source code. Often, the user is unaware or even unconcerned with the micro-level structure of atomic computations and does not wish to break the modularity of the source code to expose such. Yet the user may still wish to reap the benefits of an optimal binomial checkpointing schedule [4]. Moreover, the relative duration of different paths through a program may vary from loop iteration to loop iteration in a fashion that is data dependent, as shown by the above example, and not even statically determinable. We present an implementation strategy for checkpointing that does not require user placement of checkpoints and does not constrain checkpoints to subroutine boundaries, DO loops, or other syntactic program constructs. Instead, it can automatically and dynamically introduce a checkpoint at an arbitrary point in the computation that need not correspond to a syntactic program unit.\nWe have previously introduced vlad, a pure functional language with builtin AD operators for both forward and reverse mode. Here, we adopt slight variants of these operators with the following signatures.\nÐ→ J ∶ f x x́↦ y ý\n←Ð J ∶ f x ỳ ↦ y x̀\nThe Ð→ J operator calls a function f on a primal x with a tangent x́ to yield a primal y and a tangent ý. The ←Ð J operator calls a function f on a primal x with a cotangent ỳ to yield a primal y and a cotangent x́. Here, we restrict ourselves to the case where (co)tangents are ground data values, i.e., reals and (arbitrary) data structures containing reals and other scalar values, but not functions (i.e., closures). For our pur-\nposes, the crucial aspect of the design is that the AD operators are provided within the language, since these provide the portal to the checkpointing mechanism.\nIn previous work, we introduced Stalin∇, a highly optimizing compiler for vlad. Here, we formulate a simple evaluator (interpreter) for vlad (Fig. 1) and extend such to perform binomial checkpointing. The operators ◇ and ● range over the unary and binary basis functions respectively. This evaluator is written in what is known in the programming-language community as direct style, where functions (in this case E , denoting ‘eval’, A, denoting ‘apply’,\n∗Extended abstract presented at the AD 2016 Conference, Sep 2016, Oxford UK. †Corresponding Author, School of Electrical and Computer Engineering, Purdue University, qobi@purdue.edu ‡Dept of Computer Science, National University of Ireland Maynooth, barak@pearlmutter.net\nar X\niv :1\n61 1.\n03 41\n0v 1\n[ cs\n.P L\n] 1\n0 N\nov 2\n01 6\nand the implementations of Ð→ J and ←Ð J in the host) take inputs as function-call arguments and yield outputs as functioncall return values [5]. AD is performed by overloading the basis functions in the host, in a fashion similar to fadbad++ [6], x ⊳ x́ denotes recursively bundling a data structure containing primals with a data structure containing tangents, or alternatively recursively unbundling such when used as a binder, and y ⊲ ỳ denotes running the reverse sweep on the tape y with the output cotangent ỳ, or alternatively extracting the primal y and input cotangent x̀ from the tape when used as a binder y ⊲ x̀.\nWe introduce a new AD operator ✓ J to perform binomial checkpointing. The crucial aspect of the design is that the\nsignature (and semantics) of ✓ J is identical to ←Ð J ; they are completely interchangeable, differing only in the space/time complexity tradeoffs. This means that code need not be modified to switch back and forth between ordinary reverse mode and binomial checkpointing, save interchanging calls to ←Ð J and ✓ J .\nConceptually, the behavior of ✓ J is shown in Fig. 2. In this inductive definition, a function f is split into the composition of two functions g and h in step 1, the checkpoint u is computed by applying g to the input x in step 2, and the cotangent is computed by recursively applying ✓ J to h and g in steps 3 and 4. This divide-and-conquer behavior is terminated in a base case, when the function f is small, at which point the cotangent is computed with ←Ð J , in step 0. If step 1 splits a function f into two functions g and h that take the same\nnumber of computational steps, the recursive divide-and-conquer process yields the logarithmic asymptotic space/time complexity of binomial checkpointing.\nThe central difficulty in implementing the above is performing step 1, namely splitting a function f into two functions g and h, ideally ones that take the same number of computational steps. A sophisticated user can manually rewrite a subroutine f into two subroutines g and h. A sufficiently powerful compiler or source transformation tool might also be able to, with access to nonlocal program text. But an overloading system, with access only to local information, would not be able to.\nWe solve this problem by providing an interface to a general-purpose checkpointing mechanism orthogonal to AD.\nprimops f x↦ (y, n) Return y = f(x) along with the number n of steps needed to compute y. checkpoint f x n↦ u Run the first n steps of the computation of f(x) and return a checkpoint u. resume u↦ y If u = (checkpoint f x n), return y = f(x).\nThis interface allows (a) determining the number of steps of a computation, (b) interrupting a computation after a specified number of steps, usually half the number of steps determined by the mechanism in (a), and (c) resuming an interrupted computation to completion. A variety of implementation strategies for this interface are possible. We present one in detail momentarily and briefly discuss others below.\nIrrespective of how one implements the general-purpose checkpointing interface, one can use it to implement ✓ J as shown in Fig. 3. The function f is split into the composition of two functions g and h by taking g as λx.checkpoint f x n, where n is half the number of steps determined by primops f x, and h as λu.resume u.\nOne way of implementing the general-\npurpose checkpointing interface is to convert the evaluator from direct style to continuation-passing style (CPS, [7]), where functions (in this case E , A, Ð→ J , and ←Ð J in the host) take an additional continuation input k and instead of yielding outputs via function-call return, do so by calling the continuation with said output as arguments (Fig. 5). In such a style, functions never return; they just call their continuation. With tail-call merging, such corresponds to a computed go to and does not incur stack growth. This crucially allows the interruption process to actually return a checkpoint data structure containing the saved state of the evaluator, including its continuation, allowing the evaluation to be resumed by calling the evaluator with this saved state. This ‘level shift’ of return to calling a continuation allowing an actual return to constitute checkpointing interruption is analogous to the way backtracking is classically implemented in Prolog, with success implemented as calling a continuation and failure implemented as actual return. In our case, we further instrument the evaluator to thread two values as inputs and outputs: the count n of the number of evaluation steps, which is incremented at each call to E , and the limit l of the number of steps, after which a checkpointing interrupt is triggered.\nWith this CPS evaluator, it is possible to implement the general-purpose checkpointing interface (Fig. 4), not for programs in the host, but for programs in the target; hence our choice of formulating the implementation around an evaluator (interpreter).\nWe remove this restriction below. The implementation of primops calls the evaluator with no limit and simply counts the number of steps to completion. The implementation of checkpoint calls the evaluator with a limit that must be smaller than that needed to complete so a checkpointing interrupt is forced and the checkpoint data structure ⟦k, l, ρ, e⟧ is returned. The implementation of resume calls the evaluator with arguments from the saved checkpoint data structure.\nListing 2: vlad example\n(define (f x) (let ((n 100003)) (let outer ((i 1) (y x)) (if (> i n)\ny (outer (+ i 1)\n(let ((m (l x i))) (let inner ((j 1) (y y)) (if (> j m)\ny (inner (+ j 1)\n(sqrt (* y y)))))))))))\nWith this, it is possible to reformulate the Fortran example from Listing 1 in vlad (Listing 2). Then one achieves binomial checkpoint-\ning simply by calling ( ✓ J f 3 1).\nThe efficacy of our method can be seen in the plots (Fig. 5) of the space and time usage, relative to that for the leftmost datapoint, of the above Fortran and vlad examples with varying n. Tapenade was run without checkpointing, with manual checkpointing only around the body of the outer loop, with manual checkpointing only around the body of the inner loop, with manual checkpointing around the bodies of both loops, and with binomial checkpointing. vlad was run with ←Ð J and ✓ J . Note that Tapenade exhibits O(n) space and time usage for all cases, while vlad exhibits O(n) space and time usage with ←Ð J , but\nO(1) space usage and O(n) time usage with ✓ J . The space complexity of ✓ J is the sum of the space required for the checkpoints and the space required for the tape. For a general computation of length t and maximal live storage w, the former is O(w log t) while the latter is O(w). For the code in our example, t = O(n) and w = O(1), leading to the former being O(logn) and the latter being O(1). We observe O(1) space usage since the constant factors of the\nlatter overpower the former. The time complexity of ✓ J is the sum of the time required to (re)compute the primal and the time required to perform the reverse sweep. For a general computation, the former is O(t log t) while the latter is O(t). For the code in our example, the former is O(n logn) and the latter is O(n). We observe O(n) time usage since, again, the constant factors of the latter overpower the former.\nOther methods present themselves for implementing the general-purpose checkpointing interface. One can use posix fork() much in the same way that it has been used to implement the requisite nondeterminism in probabilistic programming languages like probabilistic c [8]. A copy-on-write implementation of fork(), as is typical, would make this reasonably efficient and allow it to apply in the host, rather than the target, and thus could be used to provide an overloaded implementation of binomial checkpointing in a fashion that was largely transparent to the user. Alternatively, direct-style code could be compiled into CPS using a CPS transformation. A compiler for a language like vlad can be constructed that generates target code in CPS that is instrumented with step counting, step limits, and checkpointing interruptions. A driver can be wrapped around such code to implement ✓ J . Existing high-performance compilers, like sml/nj [9], for functional languages like sml, already generate target code in CPS, so by adapting such to the purpose of AD with binomial checkpointing, it seems feasible to achieve high performance. In fact, the overhead of the requisite instrumentation for step counting, step limits, and checkpointing interruptions need not be onerous because the step counting, step limits, and checkpointing interruptions for basic blocks can be factored, and those for loops can be hoisted, much as is done for the instrumentation needed to support storage allocation and garbage collection in implementations like MLton [10], for languages like sml, that achieve very low overhead for automatic\nstorage management."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was supported, in part, by NSF grant 1522954-IIS and by Science Foundation Ireland grant 09/IN.1/I2637. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsors."
    } ],
    "references" : [ {
      "title" : "Automatic computation of derivatives with the use of the multilevel differentiating technique — I: Algorithmic basis",
      "author" : [ "Yu. M. Volin", "G.M. Ostrovskii" ],
      "venue" : "Computers and Mathematics with Applications,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1985
    }, {
      "title" : "The data-flow equations of checkpointing in reverse automatic differentiation",
      "author" : [ "Benjamin Dauvergne", "Laurent Hascoët" ],
      "venue" : "Computational Science – ICCS 2006,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2006
    }, {
      "title" : "Achieving logarithmic growth of temporal and spatial complexity in reverse automatic differentiation",
      "author" : [ "Andreas Griewank" ],
      "venue" : "Optimization Methods and Software,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1992
    }, {
      "title" : "Algorithm 799: Revolve: An implementation of checkpoint for the reverse or adjoint mode of computational differentiation",
      "author" : [ "Andreas Griewank", "Andrea Walther" ],
      "venue" : "ACM Transactions on Mathematical Software,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2000
    }, {
      "title" : "The discoveries of continuations",
      "author" : [ "John C Reynolds" ],
      "venue" : "Lisp and symbolic computation,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1993
    }, {
      "title" : "FADBAD, a flexible C++ package for automatic differentiation",
      "author" : [ "C. Bendtsen", "Ole Stauning" ],
      "venue" : "Technical Report IMM– REP–1996–17, Department of Mathematical Modelling,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1996
    }, {
      "title" : "Scheme: An interpreter for extended lambda calculus",
      "author" : [ "Gerald Jay Sussman", "Guy L. Steele", "Jr." ],
      "venue" : "AI Memo 349,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1975
    }, {
      "title" : "A compilation target for probabilistic programming languages",
      "author" : [ "Brooks Paige", "Frank Wood" ],
      "venue" : "In Proceedings of The 31st International Conference on Machine Learning,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2014
    }, {
      "title" : "Compiling with continuations",
      "author" : [ "Andrew W Appel" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2006
    }, {
      "title" : "Whole-program compilation in MLton",
      "author" : [ "Stephen Weeks" ],
      "venue" : "URL http://www.mlton.org/References.attachments/ 060916-mlton.pdf. Workshop on ML",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Heretofore, automatic checkpointing at procedure-call boundaries [1], to reduce the space complexity of reverse mode, has been provided by systems like Tapenade [2].",
      "startOffset" : 65,
      "endOffset" : 68
    }, {
      "referenceID" : 1,
      "context" : "Heretofore, automatic checkpointing at procedure-call boundaries [1], to reduce the space complexity of reverse mode, has been provided by systems like Tapenade [2].",
      "startOffset" : 161,
      "endOffset" : 164
    }, {
      "referenceID" : 2,
      "context" : "However, binomial checkpointing, or treeverse [3], has only been provided in AD systems in special cases, e.",
      "startOffset" : 46,
      "endOffset" : 49
    }, {
      "referenceID" : 3,
      "context" : "Yet the user may still wish to reap the benefits of an optimal binomial checkpointing schedule [4].",
      "startOffset" : 95,
      "endOffset" : 98
    }, {
      "referenceID" : 4,
      "context" : "and the implementations of Ð→ J and ←Ð J in the host) take inputs as function-call arguments and yield outputs as functioncall return values [5].",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 5,
      "context" : "AD is performed by overloading the basis functions in the host, in a fashion similar to fadbad++ [6], x ⊳ x́ denotes recursively bundling a data structure containing primals with a data structure containing tangents, or alternatively recursively unbundling such when used as a binder, and y ⊲ ỳ denotes running the reverse sweep on the tape y with the output cotangent ỳ, or alternatively extracting the primal y and input cotangent x̀ from the tape when used as a binder y ⊲ x̀.",
      "startOffset" : 97,
      "endOffset" : 100
    }, {
      "referenceID" : 6,
      "context" : "One way of implementing the generalpurpose checkpointing interface is to convert the evaluator from direct style to continuation-passing style (CPS, [7]),",
      "startOffset" : 149,
      "endOffset" : 152
    }, {
      "referenceID" : 7,
      "context" : "One can use posix fork() much in the same way that it has been used to implement the requisite nondeterminism in probabilistic programming languages like probabilistic c [8].",
      "startOffset" : 170,
      "endOffset" : 173
    }, {
      "referenceID" : 8,
      "context" : "Existing high-performance compilers, like sml/nj [9], for functional languages like sml, already generate target code in CPS, so by adapting such to the purpose of AD with binomial checkpointing, it seems feasible to achieve high performance.",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 9,
      "context" : "In fact, the overhead of the requisite instrumentation for step counting, step limits, and checkpointing interruptions need not be onerous because the step counting, step limits, and checkpointing interruptions for basic blocks can be factored, and those for loops can be hoisted, much as is done for the instrumentation needed to support storage allocation and garbage collection in implementations like MLton [10], for languages like sml, that achieve very low overhead for automatic",
      "startOffset" : 411,
      "endOffset" : 415
    } ],
    "year" : 2016,
    "abstractText" : "Heretofore, automatic checkpointing at procedure-call boundaries [1], to reduce the space complexity of reverse mode, has been provided by systems like Tapenade [2]. However, binomial checkpointing, or treeverse [3], has only been provided in AD systems in special cases, e.g., through user-provided pragmas on DO loops in Tapenade, or as the nested taping mechanism in adol-c for time integration processes, which requires that user code be refactored. We present a framework for applying binomial checkpointing to arbitrary code with no special annotation or refactoring required. This is accomplished by applying binomial checkpointing directly to a program trace. This trace is produced by a general-purpose checkpointing mechanism that is orthogonal to AD. Listing 1: Fortran example",
    "creator" : "LaTeX with hyperref package"
  }
}