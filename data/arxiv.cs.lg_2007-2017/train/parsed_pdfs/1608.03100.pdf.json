{
  "name" : "1608.03100.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Estimation from Indirect Supervision with Linear Moments",
    "authors" : [ "Aditi Raghunathan", "Roy Frostig", "John Duchi", "Percy Liang" ],
    "emails" : [ "ADITIR@STANFORD.EDU", "RF@CS.STANFORD.EDU", "JDUCHI@STANFORD.EDU", "PLIANG@CS.STANFORD.EDU" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Consider the problem of estimating a probabilistic graphical model from indirect supervision, where only a partial view of the variables is available. We are interested in indirect supervision for two reasons: first, one might not trust a data collector and wish to use privacy mechanisms to reveal only partial information about sensitive data (Warner, 1965; Evfimievski et al., 2004; Dwork et al., 2006; Duchi et al., 2013). Second, if data is generated by human annotators, say in a crowdsourcing setting, it can often be more cost-effective to solicit lightweight annotations (Oded & Tomás, 1998; Mann & McCallum, 2008; Quadrianto et al., 2008; Liang et al., 2009). In both cases, we trade statistical efficiency for another resource: privacy or annotator cost.\nIndirect supervision is naturally handled by defining a latent-variable model where the structure of interest is treated as a latent variable. While statistically sensible,\n1 This is an extended and updated version of our paper in Proceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\nlearning latent-variable models poses two computational challenges. First, maximum marginal likelihood requires non-convex optimization, where popular procedures such as gradient descent or Expectation Maximization (EM) (Dempster et al., 1977) are only guaranteed to converge to local optima. Second, even the computation of the gradient or performing the E-step can be intractable, requiring probabilistic inference on a loopy graphical model induced by the indirect supervision (Chang et al., 2007; Graça et al., 2008; Liang et al., 2009).\nIn this paper, we propose an approach that bypasses both computational obstacles for a class which we call linear indirectly-supervised learning problems. We lean on the method of moments (Pearson, 1894), which has recently led to advances in learning latent-variable models (Hsu et al., 2009; Anandkumar et al., 2013; Chaganty & Liang, 2014), although we do not appeal to tensor factorization. Instead, we express indirect supervision as a linear combination of the sufficient statistics of the model, which we recover by solving a simple noisy linear system. Once we have the sufficient statistics, we use convex optimization to solve for the model parameters. The key is that while supervision per example is indirect and leads to intractability, aggregation over a large number of examples renders the problem tractable.\nWhile our moments-based estimator yields computational benefits, we suffer some statistical loss relative to maximum marginal likelihood. In Section 5, we compare the asymptotic variance of marginal-likelihood and momentbased estimators, and provide some geometric insight into their differences in Section 6. Finally, in Section 7, we apply our framework empirically to our two motivating settings: (i) learning a regression model under local privacy constraints, and (ii) learning a part-of-speech tagger with lightweight annotations. In both applications, we show that our moments-based estimator obtains good accuracies. ar X\niv :1\n60 8.\n03 10\n0v 1\n[ st\nat .M\nL ]\n1 0\nA ug\n2 01"
    }, {
      "heading" : "2. Setup",
      "text" : "Notation. We use superscripts to enumerate instances in a data sample (e.g. x(1), . . . , x(n)), and square-bracket indexing to enumerate components of a vector or sequence: x[b] denotes the component(s) of x associated with b. For a real vector x ∈ Rd, we let x⊗2 def= xx>.\nModel. Consider the structured prediction task of mapping an input x ∈ X to some output y ∈ Y . We model this mapping using a conditional exponential family\npθ(y | x) = exp{φ(x, y)>θ −A(θ;x)}, (1)\nwhere φ : X × Y → Rd is the feature mapping, θ ∈ Rd is the parameter vector, and A(θ;x) = log ∑ y∈Y exp{φ(x, y)>θ} is the log-partition function. For concreteness, we specialize to conditional random fields (CRFs) (Lafferty et al., 2001) over collections of K-variate labels, where x = (x[1], . . . , x[L]) and y = (y[1], . . . , y[L]) ∈ [K]L; here L is the number of variables and K is the number of possible labels per variable. We let C ⊆ 2[L] be the set of cliques in the CRF, so that the features decompose into a sum over cliques: φ(x, y) = ∑ c∈C φc(y[c], x, c). As one particular example, if C consists of all nodes {{1}, . . . , {L}} and edges between adjacent nodes {{1, 2}, . . . , {L−1, L}}, the CRF is chain-structured.\nLearning from indirect supervision. In the indirectly supervised setting that is the focus of this paper, we do not have access to y but rather only observations o ∈ O, where o is drawn from a known supervision distribution S(o | y).\nFor each i = 1, . . . , n, let (x(i), y(i)) be drawn from some unknown data-generating distribution p∗ (by default, we do not assume the CRF is well-specified), and o(i) is drawn according to S(· | y(i)) as in Figure 1. The learning problem is then the natural one: given the training examples (x(1), o(1)), . . . , (x(n), o(n)), we wish to produce an estimate θ̂ for the model (1).\nMaximum marginal likelihood. The classic paradigm is to maximize the marginal likelihood:\nθ̂marg def = argmax\nθ Ê log∑ y∈Y S(o | y)pθ(y | x)  , (2)\nwhere Ê denotes an expectation over the training sample. While θ̂marg is often statistically efficient, there are two computational difficulties associated with this approach:\n1. The log-likelihood objective (2) is typically nonconvex, so computing θ̂marg exactly is in general intractable; see Section 6 for a more detailed discussion. Local algorithms like Expectation Maximization (Dempster et al., 1977) are only guaranteed to converge to local optima.\n2. Computing the gradient or the E-step requires computing p(y | x, o) ∝ pθ(y | x)S(o | y), which is intractable, not due to the model pθ, but to the supervision S. This motivates a number of relaxations (Graça et al., 2008; Liang et al., 2009; Steinhardt & Liang, 2015), but there are no guarantees on approximation quality.\nOur approach: moment-based estimation. We present a simple approach to circumvent the above issues for a restricted class of models, in the same vein as Chaganty & Liang (2014). To begin, consider the fully-supervised setting, where we observe examples {(x(i), y(i))}. In this case, we could maximize the likelihood Ê[log pθ(y | x)], solving argmaxθ{µ̂>θ − Ê[A(θ;x)]}, where µ̂ def = Ê[φ(x, y)] ∈ Rd are the sufficient statistics, which converge to µ∗ def= E[φ(x, y)]. Therefore, if we could construct a consistent estimate µ̂ of µ∗, then we could solve the same convex optimization problem used in the fully-supervised estimator.\nOf course, we do not have access to Ê[φ(x, y)]. Instead, in our (linearly) indirectly supervised setting, we are able to define an observation function β(x, o) ∈ Rd which is nonetheless in expectation equal to the population sufficient statistics:\nE[β(x, o) | x] = φ(x, y), E[β(x, o)] = µ∗. (3)\nIn general, we construct β(x, o) by solving a linear system. Putting the pieces together yields our estimator (Figure 2):\n1. Sufficient statistics: µ̂ = Ê[β(x, o)].\n2. Parameters: θ̂mom def = arg maxθ{µ̂− Ê[A(θ;x)]}.\nIn the next two sections, we describe the observation function β(x, o) for learning with local privacy (Section 3) and lightweight annotations (Section 4)."
    }, {
      "heading" : "3. Learning under local privacy",
      "text" : "Suppose we wish to estimate a conditional distribution pθ(y | x), where x is non-sensitive information about an individual and y contains sensitive information (for example, income or disease status). Individuals, because of a variety of reasons—mistrust, embarrassment, fear of discrimination—may wish to keep y private and instead release some o ∼ S(· | y). To quantify the amount of privacy afforded by S, we turn to the literature on privacy in databases and theoretical computer science (Evfimievski et al., 2004; Dwork et al., 2006) and say that S is α-differentially private if any two y, y′ have comparable probability (up to a factor of exp(α)) of generating o:\nsup o,y,y′ S(o | y) S(o | y′) ≤ exp(α). (4)\nWhat S should we employ? We first explore the classical randomized response (RR) mechanism (Section 3.1), and then develop a new mechanism that leverages the graphical model structure (Section 3.2)."
    }, {
      "heading" : "3.1. Classic randomized response",
      "text" : "Warner (1965) proposed the now-classical randomized response technique, which proceeds as follows: For some fixed (generally small) > 0, the respondent reveals y with probability and with probability 1 − draws a sample from a (known) base distribution u—generally uniform— over Y . Formally, the classical randomized response supervision is\nS(o | y) def= I[o = y] + (1− )u(o). (5)\nEstimation. Our goal is to construct a function β satisfying (3). Towards that end, let us start with what we can estimate and expand based on (5):\nE[φ(x, o)] = E[φ(x, y)] + (1− )E[φ(x, y′)], (6)\nwhere y′ ∼ u. Rearranging (6), we see that we can solve for µ∗ = E[φ(x, y)]. Indeed, if we define the observation function:\nβ(x, o) def =\nφ(x, o)− (1− )E[φ(x, y′) | x]\n, (7)\nwe can verify that E[β(x, o)] = µ∗.\nPrivacy. We can check that the ratio S(o | y)/S(o | y′) ≤ 1 + +(1− )u(o)(1− )u(o) , so classical randomized response is (1− ) mino u(o) -differentially private. For any distribution u, this value is at least 1− |Y|, a linear dependence on |Y|. In classical randomized response settings, |Y| = 2, which is unproblematic. In contrast, in structured prediction settings, the number of labels is exponential in the number of\nvariables (|Y| = KL), so we must take = O ( α |Y| ) . The asymptotic variance of θ̂mom scales as −2 (as will be shown in Section 5), which makes classical randomized response unusable for structured prediction."
    }, {
      "heading" : "3.2. Structured randomized response",
      "text" : "With this difficulty in mind, we recognize that we must somehow leverage the structure of the sufficient statistics vector φ(x, y) to perform estimation. In particular, we show that the supervision should only depend on the sufficient statistics:\nProposition 1. Let O be the set in which observations live. For any privacy mechanism S(o | x, y) that is αdifferentially private, there exists a mechanism S′(o′ | φ(x, y)) that is at least α-differentially private, and for any set A ⊆ O, we have\nP[o′ ∈ A | x] = P[o ∈ A | x], (8)\nwhere o′ ∼ S′(· | φ(x, y)) and o ∼ S(· | x, y).\nIn short, we can always construct S′ that only uses the sufficient statistics φ(x, y) but yields the same joint distribution over the pairs (x, o). Furthermore, S′ is at least as private as the original mechanism S. See Appendix A.1 for a proof.\nThis motivates a focus exclusively on mechanisms that use sufficient statistics, and in particular, we consider the following two structured randomized response mechanisms. Our schemes are both two-phase procedures that first binarize the sufficient statistics, and then release a set of observations inspired by Duchi et al.’s minimax optimal approach to estimating a multinomial distribution. For t > 0, let qt def = e t/2\n1+et/2 . Assume each coordinate of the statistics\nφ lies in the interval [0, c] for some positive scalar c. For i ∈ {1, . . . , d}, draw õ[i] as a Bernoulli variable with bias 1 cφ(x, y)[i]. Then:\n(Coordinate release) Draw a coordinate j ∈ {1, . . . , d} from a distribution pcr. Set ocr = õ[j] with probability qα, otherwise ocr = 1− õ[j]. Release the pair (j, ocr).\n(Per-value φ-RR) Denote by Ω(x, y) the support of õ given x, y, let δ def= supx,y,õ∈Ω(x,y) ‖õ‖1, and take any δ̄ ≥ δ. For j = 1, . . . , d, set opv[j] = õ[j] with probability qα/δ̄ , otherwise opv[j] = 1− õ[j]. Release the vector opv.\nBoth are α-differentially private (see Appendix A.1). For coordinate release, define the observation function\nβcr(x, (j, ocr)) def = p−1cr (j) ocr − 1 + qα 2qα − 1 c ej ,\nwhere ej denotes the j’th standard basis vector. For the per-\nvalue statistics scheme, define the observation function,\nβpv(x, opv) def = opv − 1 + qα/δ̄1 2qα/δ̄ − 1 c. (9)\nIn either case, we have that E[β(x, o)] = µ∗, as required by (3) for θ̂mom to be consistent.\nThe two schemes offer a tradeoff: when õ is dense, coordinate release is advantageous, as our best norm bound δ̄ may be as large as the dimension d, so although we reveal only a single coordinate at a time, we noise it by a lower-variance distribution qα rather than the qα/d noise of the per-value scheme. Meanwhile, per-value φ-RR enjoys lower variance when õ has low `1 norm. The latter case arises, for instance, if φ is a sparse binary vector as is common in structured prediction. Appendix A.3 and A.4 present more details about this tradeoff offered by the schemes.\nSummarizing, we have three randomized response schemes. Classical RR appeals only in unstructured problems with few outputs Y . In the structured setting, we can move to the sufficient statistics φ by Proposition 1, and exploit their structure with either of two schemes based on our knowledge of the 1-norm or sparsity of statistics φ."
    }, {
      "heading" : "4. Learning with lightweight annotations",
      "text" : "For a sequence labeling task, e.g., part-of-speech (POS) tagging, it can be tedious to obtain fully-labeled inputoutput sequences for training. This motivates a line of work which attempts to learn from weaker forms of annotation (Mann & McCallum, 2008; Haghighi & Klein, 2006; Liang et al., 2009). We focus on region annotations, where an annotator is asked to examine only a particular subsequence of the input and count the number of occurrences of some label (e.g., nouns). The rationale is that it is cognitively easier for the annotator to focus on one label at a time rather than annotating from a large tag set, and physically easier to hit a single yes/no or counter button than to select precise locations, especially in mobile-based crowdsourcing interfaces (Vaish et al., 2014). See Table 1 for an example.\nMore formally, the supervision S(o | y) is defined as follows: First, choose the starting position jstart uniformly from {1, . . . , L − w}, and set the ending position jend = jstart + w − 1, where w is a fixed window size. Let r = {jstart, . . . , jend} denote this region. Next, choose a sub-\nset of tags B uniformly from the tag set (e.g., {NN,DT}). From here, the observation o is generated deterministically: For each tag b ∈ B, the annotator counts the number of occurrences in the region: N [b] = |{j ∈ r : y[j] = b}|. The final observation is o = (r,B,N).\nIn this setting, not only is the marginal likelihood nonconvex, inference requires summing over possible ways of realizing the counts, which is exponential either in the window size w and |B|.\nEstimation. For our estimator to work, we make two assumptions:\n1. The node potentials only depend on x[j]: φj(y[j], x, j) = f(x[j], y[j]); and 2. Under the true conditional distribution, y[j] only depends on x[j]: p∗(y[j] | x) = p∗(y[j] | x[j]).\nThese are admittedly strong independence assumptions similar to IBM model 1 for word alignment (Brown et al., 1993) or the unordered translation model of Steinhardt & Liang (2015). Even though our model is fully factorized and lacks edge potentials, inference pθ(y | x, o) is expensive as conditioning on the indirect supervision o couples all of the y variables. This typically calls for approximate inference techniques common to the realm of structured prediction. Steinhardt & Liang (2015) developed a relaxation to cope with this supervision, but this still requires approximate inference via sampling and non-convex optimization.\nIn contrast to the local privacy examples, the new challenge is that the observation o does not provide enough information to evaluate a single node potential, even stochastically. So we cannot directly write µ∗ in terms of functions of the observations. As a bridge, define the localized conditional distributions: w∗(a, b) def= P[y[j] = b | x[j] = a], which by assumption 2 specify the entire conditional distribution. The sufficient statistics µ∗ can be written as in terms of w∗:\nµ∗ = E  L∑ j=1 ∑ b w∗(x[j], b)f(x[j], b)  . (10) We now define constraints that relate the observations o to w∗. Recall that each observation o includes a region r, a tag b, and a vector of counts N = [ ∑ j∈r I[y[j] = b]]b∈B , one for each tag b. For each input x ∈ X and tag b, we have the identity:\nE[N [b] | x, r] = ∑ j∈r w∗(x[j], b). (11)\nWhile we do not observe the LHS, we observe N [b], which is unbiased estimate of the RHS of (11). We can therefore\nsolve a regression problem with response N to recover a consistent estimate ŵ of w∗:\nŵ = arg min w n∑ i=1 ∑ b∈B(i)  ∑ j∈r(i) w(x(i)[j], b)−N (i)[b] 2 . (12)\nFor instance, the example in Table 1 contributes: (P[NN | fox] + P[NN | jumps] + · · ·+ P[NN | dog]− 2)2. Finally, we plug in ŵ into (10) obtain µ̂."
    }, {
      "heading" : "5. Asymptotic analysis",
      "text" : "We have two estimators: maximum marginal likelihood (θ̂marg), which is difficult to compute, requiring non-convex optimization and possibly intractable inference; and our moments-based estimator (θ̂mom), which is easy to compute, requiring only solving a linear system and convex optimization. In this section, we study and compare the statistical efficiency of θ̂marg and θ̂mom. For simplicity, we focus on unconditional setting where x is empty, and omit x in this section. We also assume our exponential family model is well-specified and that θ∗ are the true parameters. All expectations are taken with respect to y ∼ pθ∗ .\nRecall from (3) that E[β(o) | x] = φ(y). We can therefore think of β(o) as a “best guess” of φ(y). The following lemma provides the asymptotic variances of the estimators:\nProposition 2 (General asymptotic variances). Let I def= Cov[φ(y)] be the Fisher information matrix. Then\n√ n(θ̂marg − θ∗)\nd−→ N (0,Σmarg) and √ n(θ̂mom − θ∗) d−→ N (0,Σmom),\nwhere the asymptotic variances are\nΣmarg = (I − E[Cov[φ(y) | o]])−1, (13) Σmom = I−1 + I−1E[Cov[β(o) | y]]I−1. (14)\nLet us compare the asymptotic variances of θ̂marg and θ̂mom to that of the fully-supervised maximum likelihood estimator θ̂full, which has access to {(x(i), y(i))}, and satisfies√ n(θ̂full − θ∗) d−→ N (0, I−1).\nExamining the asymptotic variance of θ̂marg (13), we see that the loss in statistical efficiency with respect to maximum likelihood is the amount of variation in φ(y) not explained by o, Cov[φ(y) | o]. Consequently, if y is simply deterministic given o, then Cov[φ(y) | o] = 0, and θ̂marg achieves the statistically efficient asymptotic variance I−1.\nThe story with θ̂mom is dual to that for the marginal likelihood estimator. Considering the second term in expres-\nsion (14), we see that the loss of efficiency due to our observation model grows linearly in the variability of the observations β(o) not explained by y. Thus, unlike θ̂marg, even if y is deterministic given o (so o reveals full information about y), we do not recover the efficient covariance I−1. As a trivial example, let φ(y) = y ∈ {0, 1} and the observation o = [y, y + η]> for η ∼ N (0, 1), so that o contains a faithful copy of y, and let β(o) = o[1]+o[2]2 = y + η 2 . Then E[Cov[β(o) | y]] = 14 , and the asymptotic relative efficiency of θ̂mom to θ̂marg is 11+I−1/4 . Roughly, θ̂marg integrates posterior information about y better than θ̂mom does.\nProof. To compute Σmarg, we follow standard arguments in van der Vaart (1998). If `(o; θ) is the marginal log-likelihood, then a straightforward calculation yields ∇`(o, θ∗) = E[φ(y) | o] − E[φ(y)]. The asymptotic variance is the inverse of E[∇`(o, θ∗)∇`(o, θ∗)>] = Cov[E[φ(y) | o]]; applying the variance decomposition I = Cov[E[φ(y) | o]] + E[Cov[φ(y) | o]] gives (13).\nTo compute Σmom, recall that the moments-based estimator computes µ̂ = Ê[β(o)] and θ̂ = (∇A)−1(µ̂). Apply the delta method, where ∇(∇A)−1(µ∗) = (∇2A(θ∗))−1 = Cov[φ(y)]−1. Finally, decompose Cov[β(o)] = Cov[E[β(o) | y]] + E[Cov[β(o) | y]] and recognize that E[β(o) | y] = φ(y) to obtain (14).\nRandomized response. To obtain concrete intuition for Proposition 2, we specialize to the case where S is the randomized response (5). In this setting, β(o) = −1φ(o)− h for some constant vector h. Recall the supervision model: z ∼ Bernoulli( ), o = y if z = 1 and o = y′ ∼ u if z = 0. Lemma 1 (asymptotic variances (randomized response)). Under the randomized response model of (5), the asymptotic variance of θ̂marg is\nΣmom = I−1 + I−1HI−1, (15)\nH def = 1− 2 Cov[φ(y′)] + 1− E[(φ(y)− E[φ(y′)])⊗2].\nThe matrix H governs the loss of efficiency, which stems from two sources: (i) Cov[φ(y′)], the variance when we sample y′ ∼ u; and (ii) the variance in choosing between y and y′. If y′ and y have the same distribution, then H = I 1− 2 2 and Σmom = −2I−1.\nProof. We decompose Cov[β(o) | y] as\nE[Cov[β(o) | y, z] | y] + Cov[E[β(o) | y, z] | y] = E[ · 0 + (1− ) Cov[ −1φ(y′)] | y] + Cov[z −1φ(y) + (1− z)E[ −1φ(y′)] | y]\n= 1− 2 Cov[φ(y′)] + 1− (φ(y)− E[φ(y′)])⊗2,\n0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 ²\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nRe la\ntiv e\nEf fic\nie nc\ny\n0.0 0.2 0.4 0.6 0.8 1.0 ²\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nRe la\ntiv e\nEf fic\nie nc\ny\n(a) (b)\nFigure 3. The efficiency of θ̂mom relative to θ̂marg as varies for weak (a) and strong (b) signals θ.\nwhere we used β(y) = −1φ(y)− h.\nAn empirical plot. The Hájek-Le Cam convolution and local asymptotic minimax theorems give that θ̂marg is the most statistically efficient estimator. We now empirically study the efficiency of θ̂mom relative to θ̂marg, where Eff def = d−1 tr(ΣmargΣ −1 mom), the average of the relative variances per coordinate of θ̂marg to θ̂mom. We continue to focus on randomized response in the unconditional case.\nTo study the effect of , we consider the following probability model: we let y ∈ {1, 2, 3, 4}, define\nφ(1) = [ 0 0 ] , φ(2) = [ 0 1 ] , φ(3) = [ 1 0 ] , φ(4) = [ 1 1 ] ,\nand set pθ(y) ∝ exp(θ>φ(y)). We set θ = [2,−0.1]> and θ = [5,−1]> to represent weak and strong signals θ (the latter is harder to estimate, as the Fisher information matrix is much smaller); when θ = 0, the asymptotic variances are equal, Σmom = Σmarg. In Figure 3, we see that the asymptotic efficiency of θ̂mom relative to θ̂marg decreases as → 0, which is explained by the fact that—as we see in expression (13)—the θ̂marg estimator leverages the prior information about y based on θ∗, while as → 0, expression (15) is dominated by the 1/ 2 Cov[φ(y′)] term, where y′ is uniform. Moreover, as θ grows larger, the conditional covariance Cov[φ(y) | o] is much smaller than the covariance Cov[β(o) | y], so that we expect that Σmarg Σmom."
    }, {
      "heading" : "6. The geometry of two-step estimation",
      "text" : "We now provide some geometric intuition about the differences between θ̂marg and θ̂mom, establishing a connection between θ̂mom and the EM algorithm as a byproduct of our discussion. For concreteness, let Y = {1, . . . ,m} be a finite set and let P be the set of all distributions over Y (represented as m-dimensional vectors). Let F def= {pθ : θ ∈ Rd} ⊆ P be a natural exponential family over Y with pθ(y) ∝ exp(θ>φ(y)). See Figure 4 for an example where m = 3 and d = 2. Note that in the space of distributions, F is a non-convex set.\nLet O = {1, . . . , k} be the set of observations. We can represent the supervision function S(o | y) as a matrix S ∈ Rk×m. For p ∈ P , we can express the marginal distribution over o as q = Sp. Let q̂ = 1n ∑n i=1 δo(i) be the empirical distribution over observations.\nThe maximum marginal likelihood estimator can now be written succinctly as:\nθ̂marg = argmin p∈F\nKL (q̂‖Sp) . (16)\nWhile the KL-divergence is concave in p, the non-convex constraint set F makes the problem difficult.\nOur moment-based estimator θ̂mom can be viewed as a relaxation, where we first optimize over a relaxed set P and then project onto the exponential family:\nr̂ = argmin p∈P D(q̂, Sp), p̂ = argmin p∈F\nKL (r̂‖p) . (17)\nThe first step can be computed directly via r = S†q̂ if D is the squared Euclidean distance. If D is KL-divergence, we can use EM (see the composite likelihood objective of Chaganty & Liang (2014)), which converges to the global optimum. The result is a single distribution r̂ over y. The second step optimizes over p via θ, which is a convex optimization problem, resulting in p̂ corresponding to θ̂mom.\nComputing θ̂marg generally requires solving a non-convex optimization problem (see Figure 5 for an example). When\nS has full column rank and the model is well-specified, θ̂mom is consistent: we have that r̂ = p̂ = S†q̂\nP−→ S†Sp∗ = p∗. This means that eventually the KL projection of problem (17) is essentially an identity operation: we almost have r̂ ∈ F by the rank assumptions, making the problem easy. This assumption strongly depends on the well-specifiedness of the supervision; indeed, if q∗ 6= Sp for any p ∈ P , then ‖θ̂marg − θ̂mom‖ ≥ c > 0, for a constant c, even as n → ∞. We can relax the column rank assumption, however: S simply needs to contain enough information about the sufficient statistics, that is, if Φ = [φ(1) · · ·φ(m)] ∈ Rd×m is matrix of sufficient statistics, we require that Φ = SR for some matrix R.\nDeterministic supervision. When the supervision matrix S has full column rank, θ̂mom converges to θ∗. There are certainly cases where θ̂marg is consistent, but θ̂mom is not. What can we say about θ̂mom in this case?\nTo obtain intuition, consider the case the supervision is a deterministic function that maps y to o (region annotations is an example). In this case, every column of S is an indicator vector, and S† = S> diag(S1)−1 = S>(SS>)−1.\nHere, S† distributes probability mass evenly across all the y ∈ Y that deterministic map to o. In this case, θ̂mom simply corresponds to running one iteration of EM on the marginal likelihood, initializing with the uniform distribution over y (θ = 0). The E-step conditions on o and places uniform mass over consistent y, producing r̂; the M-step optimizes θ based on r̂."
    }, {
      "heading" : "7. Experiments",
      "text" : "Local privacy. Following Section 3, we consider locally private estimation of a structured model. We take linear regression as a simple such structured model: it corresponds to a pairwise random field over the inputs and the response. The sufficient statistics are edge features φi,j(xi, xj) = xixj and φi(xi, y) = xiy for each i, j ∈ [d].\nOn the housing dataset, the supervision o is given under the per-value RR scheme. On the songs dataset, õ is a dense vector, motivating the coordinate release scheme instead. We choose i ∈ [d] at random, with probability 12 reveal xiy and with probability 12 reveal [x 2 i , xixj , x 2 j ] with suitable\nnoise as described in Section 3.2. Note that the noising mechanism privatizes both input variables x as well as the response y.\nFigure 6 visualizes the average (over 10 trials) R2 coefficient of fit for linear regression on the test set,2 in response to varying the privacy parameter α.3 As expected, the efficiency degrades with increase in the privacy constraint, though for moderate values of α the loss is not significant.\nLightweight annotations. We experiment with estimating a conditional model for part-of-speech (POS) sequence tagging from lightweight annotations.4 Every example in the dataset reveals a sentence and the counts of all tags over a consecutive window. Following the modeling assumptions in Section 4, we use a CRF (per Section 2) with only node features:\nφj(y[j], x, j)[g, a, b] = ∑\ni∈[L],g∈G\nI[g(xi) = a, y[i] = b],\nwhere g is a function on the word (e.g., word, prefix, suffix and word signature).\nWhen the problem is fully supervised, we maximize the log-likelihood with stochastic gradient descent (SGD); in this case, estimation is convex and exact gradients can be tractably computed. Under count supervision, convexity of the marginal likelihood is not guaranteed. Although the model has no edge features, the indirect count supervision places an potential over the region in which counts are revealed (one enforcing that the tag sequence is compatible with the counts). This renders exact inference intractable, so we approximate it using beam search to compute stochastic gradients.5 The moment-based estimator is unaffected by this issue as it requires no inference and proceeds via a pair convex minimization programs; we minimize both using SGD.\nFigure 7 shows train and test accuracies as we make passes over the dataset. Typically, after sufficiently many passes, the marginal likelihood gains an advantage over the moment-based estimator. For small regions, we expect the beam search approximation to be accurate, and indeed the marginal likelihood estimator is dominant there. For larger regions, the moment-based estimator (i) achieves high accuracy early and (ii) dominates for several passes before the marginal likelihood estimator overtakes it. Altogether,\n2The (uncentered) R2 coefficient of parameters w in a linear regression with design X and labels Y is ‖Xw − Y ‖2/‖Y ‖2.\n3We use the housing (mlcomp.org/datasets/840) and songs (mlcomp.org/datasets/748) data from mlcomp.\n4We used the Wall Street Journal portion of the Penn Treebank. Sections 0-21 comprise the training set and 22-24 are test.\n5The dataset has 45 tag values. We use a beam of size 500 after analytically marginalizing nodes outside the region.\nthe experiment highlights that the moment-based estimator is favorable in computationally-constrained settings."
    }, {
      "heading" : "8. Related work and discussion",
      "text" : "This work was motivated by two use cases of indirect supervision: local privacy and cheap annotations. Each trades off statistical accuracy for another resource: privacy or annotation cost. Local privacy has its roots in classical randomized response for conducting surveys (Warner, 1965), which has been extended to the multivariate (Tamhane, 1981) and conditional (Matloff, 1984) settings. In the computer science community, differential privacy has emerged as a useful formalization of privacy (Dwork, 2006). We work with the stronger notion of local differential privacy (Evfimievski et al., 2004; Kasiviswanathan et al., 2011; Duchi et al., 2013). Our contribution here is two-fold: First, we bring local privacy to the graphical model setting, which provides an opportunity for the privacy mechanism to be sensitive to the model structure. While we believe our\nmechanisms are reasonable, an open question is designing optimal mechanisms in the structured case. Second, we connect privacy with other forms of indirect supervision.\nThe second use case is learning from lightweight annotations, which has taken many forms in the literature. Multiinstance learning (Oded & Tomás, 1998) is popular in computer vision, where it is natural to label the presence but not location of objects (Babenko et al., 2009). In natural language processing, there also been work on learning from structured outputs where, like this work, only counts of labels are observed (Mann & McCallum, 2008; Liang et al., 2009). However, these works resort to likelihood-based approaches which involve non-convex optimization and approximate inference, whereas in this work, we show that linear algebra and convex optimization suffice under modeling assumptions.\nQuadrianto et al. (2008) showed how to learn from label proportions of groups of examples, using a linear system technique similar to ours. However, they assume that the group is conditionally independent of the example given the label, which would not apply in our region-based annotation setup since our regions contain arbitrarily correlated inputs and heterogeneous labels. In return, we do need to make the stronger assumption that each label y[i] depends only on a discrete x[i], so that the credit assignment can be done using a linear program. An open challenge is to allow for heterogeneity with complex inputs.\nIndirect supervision arises more generally in latent-variable models, which arises in machine translation (Brown et al., 1993), semantic parsing (Liang et al., 2011), object detection (Quattoni et al., 2004), and other missing data problems in statistics (M & Naisyin, 2000). The indirect supervision problems in this paper have additional structure: we have an unknown model pθ and a known supervision function S. It is this structure allows us to obtain computationally efficient method of moments procedures.\nWe started this work to see how much juice we could squeeze out of just linear moment equations, and the answer is more than we expected. Of course, for more general latent-variable models beyond linearly indirectlysupervised problems, we would need more powerful tools. In recent years, tensor factorization techniques have provided efficient methods for a wide class of latent-variable models (Hsu et al., 2012; Anandkumar et al., 2012; Hsu & Kakade, 2013; Anandkumar et al., 2013; Chaganty & Liang, 2013; Halpern & Sontag, 2013; Chaganty & Liang, 2014). One can leverage even more general polynomialsolving techniques to expand the set of models (Wang et al., 2015). In general, the method of moments allows us to leverage statistical structure to alleviate computational intractability, and we anticipate more future developments along these lines.\nReproducibility. The code, data and experiments for this paper are available on Codalab at https: //worksheets.codalab.org/worksheets/ 0x6a264a96efea41158847eef9ec2f76bc/."
    }, {
      "heading" : "A. Details of privacy schemes",
      "text" : "A.1. Local privacy using sufficient statistics\nProof of Proposition 1. Because φ is a sufficient statistic, by definition there exists some channel Q(y | φ(x, y)) and a distribution Fθ(φ(x, y) | x) such that pθ(y | x) = Q(y | φ(x, y))Fθ(φ(x, y) | x). If we define\nS′(o | φ(x, y)) = ∑ y S(o | y)Q(y | φ(x, y)), (18)\nthen (8) follows by substitution and algebra:\nA.2. Privacy guarantees of proposed schemes\nIn order to show differential privacy of the two schemes proposed in Section 3, we first note that it suffices to have differential privacy of the observations o with respect to any (possibly random) data õ ∈ Õ processed given the private variable y such that y → õ→ o forms a Markov chain.\nTo see this, suppose Q is an α-differentially private channel taking the intermediate variable õ to o and fix any x ∈ X . Let R(· | y) be the distribution of õ given y ∈ Y . Now, for the end-to-end channel S,\nsup o,y,y′ S(o | y) S(o | y′) = sup o,y,y′ ∑ õ∈Õ Q(o | õ)R(õ | y)∑ õ∈Õ Q(o | õ)R(õ | y′)\n(19)\n≤ sup o,y,y′ maxõQ(o | õ) minõQ(o | õ)\n(20)\n≤ exp(α). (21)\nCoordinate release. Recall that in the coordinate release mechanism, we first pick a coordinate j and release observation ocr after flipping õ[j] with probability exp(α2 )\n1+exp(α2 ) .\nQ(ocr, j | õ) Q(ocr, j | õ′)\n= exp (α\n2 (|ocr − (1− õ[j])| − |ocr − (1− õ′[j])|)\n) (22)\n≤ exp(α), (23)\nwhere the final step is by the triangle inequality applied twice.\nPer-value φ-RR. Privacy of per-value φ-RR follows similarly.\nEach coordinate of o is flipped with probability qα δ̄\n= exp( α 2δ̄ )\n1+exp( α 2δ̄ ) , where δ̄ is chosen such that δ̄ ≤ ‖õ‖1, ‖õ′‖1 (see Section 3.2)\nQ(opv | õ) Q(opv | õ′)\n= exp ( α\n2δ̄ (‖opv − (1− õ)‖1 − ‖opv − (1− õ′)‖1)\n) (24)\n≤ exp(α). (25)\nA.3. Variance of moments-based estimator for different privacy schemes.\nFor simplicity, we once again consider the unconditional case (where x is empty) and assume φ ∈ {0, 1}d. Theorem 1 (Asymptotic variance (coordinate release)). The asymptotic variance of θ̂mom for α-differentially private coordinate release scheme, under a uniform coordinate sampling distribution pcr is\nΣcrmom = I−1 + I−1HcrI−1,\nwhere\nHcr = dqα(1− qα) (2qα − 1)2 I + E[ddiag(φ(y))2 − φ(y)⊗2], (26)\nAs in Lemma 1, the matrix Hcr governs the loss in efficiency under the coordinate release mechanism, which arises from two sources: (i) variance due to the stochastic flipping process and (ii) variance due to choosing a random coordinate for release.\nProof. When pcr is uniform, the observation function βcr(j, ocr) takes the following form.\nβcr(j, ocr) = d ocr − 1 + qα\n2qα − 1 ej .\nFrom (14), we have that Hcr = E[Cov[βcr(j, ocr) | y]].\nWe decompose Cov[β(j, ocr) | y] as\nE[Cov[β(j, ocr) | j, y] | y] + Cov[E[β(j, ocr) | j, y] | y]\n= d2 (2qα − 1)2 ( E[Cov[ocr ej | j, y] | y] + Cov[E[(ocr − 1 + qα) ej | j, y] | y] ) = d2\n(2qα − 1)2 E[diag(qα(1− qα)ej) | y] +\nd2\n(2qα − 1)2 Cov[[(2qα − 1)φ(y)[j] + 1− qα − 1 + qα]ej | y]\n= d2\n(2qα − 1)2 E[diag(qα(1− qα)ej) | y] + d2 Cov[φ(y)[j]ej | y]\n= dqα(1− qα) (2qα − 1)2 I + [ddiag(φ(y))2 − φ(y)⊗2],\nTheorem 2 (Asymptotic variance (per-value φ-RR)). The asymptotic variance of θ̂mom for α-differentially per-value φRR scheme is\nΣpvmom = I−1 + I−1HpvI−1, (27)\nHpv = qα/δ̄(1− qα/δ̄) (2qα/δ̄ − 1)2 I. (28)\nProof. From (9), we have\nβpv(x, opv) def = opv − 1 + qα/δ̄1 2qα/δ̄ − 1 .\nFrom (14), we know that Hpv = E[Cov[βpv(opv) | y]] = 1(2qα/δ̄−1)2E[Cov[opv | y]].\nEach entry opv[j] is chosen independently according to a Bernoulli distribution with parameter qα/δ̄ (if õ[i] = 1) or 1−qα/δ̄ (if õ[i] = 0), implying the claim.\nA.4. Comparison of the two schemes\nWe use tr(Hcr) and tr(Hpv) to quantitatively estimate the loss in efficiency of Σmom under the two privacy schemes.\nFor small x, approximate qx = e x/2 1+ex/2 locally as 12 + x 8 (via Taylor expansion). Substituting in (26) and (28) gives the following expressions for small α:\ntr(Hcr) ≈ 4d 2\nα2 + δ̄(d− 1). (29)\ntr(Hpv) ≈ 4dδ̄ 2\nα2 . (30)\nWhen δ̄ is constant (independent of d), tr(Hpv) grows linearly with d whereas tr(Hcr) grows quadratically with d. Therefore per-value φ-RR has smaller loss when φ has low l1 norm. Meanwhile, when δ̄ = O(d), tr(Hpv) = O(d3) and tr(Hcr) = O(d2). Hence coordinate release is a more appealing choice if φ is dense."
    } ],
    "references" : [ {
      "title" : "Two SVDs suffice: Spectral decompositions for probabilistic topic modeling and latent Dirichlet allocation",
      "author" : [ "A. Anandkumar", "D.P. Foster", "D. Hsu", "S.M. Kakade", "Y. Liu" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Anandkumar et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Anandkumar et al\\.",
      "year" : 2012
    }, {
      "title" : "Tensor decompositions for learning latent variable models",
      "author" : [ "A. Anandkumar", "R. Ge", "D. Hsu", "S.M. Kakade", "M. Telgarsky" ],
      "venue" : null,
      "citeRegEx" : "Anandkumar et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Anandkumar et al\\.",
      "year" : 2013
    }, {
      "title" : "Visual tracking with online multiple instance learning",
      "author" : [ "B. Babenko", "M. Yang", "S. Belongie" ],
      "venue" : "In Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "Babenko et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Babenko et al\\.",
      "year" : 2009
    }, {
      "title" : "The mathematics of statistical machine translation: Parameter estimation",
      "author" : [ "P.F. Brown", "S.A.D. Pietra", "V.J.D. Pietra", "R.L. Mercer" ],
      "venue" : "Computational Linguistics,",
      "citeRegEx" : "Brown et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 1993
    }, {
      "title" : "Spectral experts for estimating mixtures of linear regressions",
      "author" : [ "A. Chaganty", "P. Liang" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Chaganty and Liang,? \\Q2013\\E",
      "shortCiteRegEx" : "Chaganty and Liang",
      "year" : 2013
    }, {
      "title" : "Estimating latent-variable graphical models using moments and likelihoods",
      "author" : [ "A. Chaganty", "P. Liang" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Chaganty and Liang,? \\Q2014\\E",
      "shortCiteRegEx" : "Chaganty and Liang",
      "year" : 2014
    }, {
      "title" : "Guiding semisupervision with constraint-driven learning",
      "author" : [ "M. Chang", "L. Ratinov", "D. Roth" ],
      "venue" : "In Association for Computational Linguistics (ACL), pp",
      "citeRegEx" : "Chang et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Chang et al\\.",
      "year" : 2007
    }, {
      "title" : "Maximum likelihood from incomplete data via the EM algorithm",
      "author" : [ "Dempster A. P", "M.L. N", "D. R" ],
      "venue" : "Journal of the Royal Statistical Society: Series B,",
      "citeRegEx" : "P. et al\\.,? \\Q1977\\E",
      "shortCiteRegEx" : "P. et al\\.",
      "year" : 1977
    }, {
      "title" : "Local privacy and statistical minimax rates",
      "author" : [ "J.C. Duchi", "M.I. Jordan", "M.J. Wainwright" ],
      "venue" : "In Foundations of Computer Science (FOCS),",
      "citeRegEx" : "Duchi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Duchi et al\\.",
      "year" : 2013
    }, {
      "title" : "Differential privacy",
      "author" : [ "C. Dwork" ],
      "venue" : "In Automata, languages and programming,",
      "citeRegEx" : "Dwork,? \\Q2006\\E",
      "shortCiteRegEx" : "Dwork",
      "year" : 2006
    }, {
      "title" : "Calibrating noise to sensitivity in private data analysis",
      "author" : [ "C. Dwork", "F. McSherry", "K. Nissim", "A. Smith" ],
      "venue" : "In Proceedings of the 3rd Theory of Cryptography Conference,",
      "citeRegEx" : "Dwork et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2006
    }, {
      "title" : "Privacy preserving mining of association rules",
      "author" : [ "A. Evfimievski", "R. Srikant", "R. Agrawal", "J. Gehrke" ],
      "venue" : "Information Systems,",
      "citeRegEx" : "Evfimievski et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Evfimievski et al\\.",
      "year" : 2004
    }, {
      "title" : "Expectation maximization and posterior constraints",
      "author" : [ "J. Graça", "K. Ganchev", "B. Taskar" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Graça et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Graça et al\\.",
      "year" : 2008
    }, {
      "title" : "Prototype-driven learning for sequence models",
      "author" : [ "A. Haghighi", "D. Klein" ],
      "venue" : "In North American Association for Computational Linguistics (NAACL),",
      "citeRegEx" : "Haghighi and Klein,? \\Q2006\\E",
      "shortCiteRegEx" : "Haghighi and Klein",
      "year" : 2006
    }, {
      "title" : "Unsupervised learning of noisyor Bayesian networks",
      "author" : [ "Y. Halpern", "D. Sontag" ],
      "venue" : "In Uncertainty in Artificial Intelligence (UAI),",
      "citeRegEx" : "Halpern and Sontag,? \\Q2013\\E",
      "shortCiteRegEx" : "Halpern and Sontag",
      "year" : 2013
    }, {
      "title" : "Learning mixtures of spherical Gaussians: Moment methods and spectral decompositions",
      "author" : [ "D. Hsu", "S.M. Kakade" ],
      "venue" : "In Innovations in Theoretical Computer Science (ITCS),",
      "citeRegEx" : "Hsu and Kakade,? \\Q2013\\E",
      "shortCiteRegEx" : "Hsu and Kakade",
      "year" : 2013
    }, {
      "title" : "A spectral algorithm for learning hidden Markov models",
      "author" : [ "D. Hsu", "S.M. Kakade", "T. Zhang" ],
      "venue" : "In Conference on Learning Theory (COLT),",
      "citeRegEx" : "Hsu et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2009
    }, {
      "title" : "Identifiability and unmixing of latent parse trees",
      "author" : [ "D. Hsu", "S.M. Kakade", "P. Liang" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Hsu et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2012
    }, {
      "title" : "What can we learn privately",
      "author" : [ "S.P. Kasiviswanathan", "H.K. Lee", "K. Nissim", "S. Raskhodnikova", "A. Smith" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Kasiviswanathan et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Kasiviswanathan et al\\.",
      "year" : 2011
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling data",
      "author" : [ "J. Lafferty", "A. McCallum", "F. Pereira" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Lafferty et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Lafferty et al\\.",
      "year" : 2001
    }, {
      "title" : "Learning from measurements in exponential families",
      "author" : [ "P. Liang", "M.I. Jordan", "D. Klein" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Liang et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2009
    }, {
      "title" : "Learning dependency-based compositional semantics",
      "author" : [ "P. Liang", "M.I. Jordan", "D. Klein" ],
      "venue" : "In Association for Computational Linguistics (ACL), pp",
      "citeRegEx" : "Liang et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2011
    }, {
      "title" : "Inference for imputation",
      "author" : [ "R.J. M", "W. Naisyin" ],
      "venue" : "estimators. Biometrika,",
      "citeRegEx" : "M and Naisyin,? \\Q2000\\E",
      "shortCiteRegEx" : "M and Naisyin",
      "year" : 2000
    }, {
      "title" : "Generalized expectation criteria for semi-supervised learning of conditional random fields. In Human Language Technology and Association for Computational Linguistics (HLT/ACL)",
      "author" : [ "G. Mann", "A. McCallum" ],
      "venue" : null,
      "citeRegEx" : "Mann and McCallum,? \\Q2008\\E",
      "shortCiteRegEx" : "Mann and McCallum",
      "year" : 2008
    }, {
      "title" : "Use of covariates in randomized response settings",
      "author" : [ "N.S. Matloff" ],
      "venue" : "Statistics & Probability Letters,",
      "citeRegEx" : "Matloff,? \\Q1984\\E",
      "shortCiteRegEx" : "Matloff",
      "year" : 1984
    }, {
      "title" : "A framework for multipleinstance learning",
      "author" : [ "M. Oded", "L. Tomás" ],
      "venue" : "Advances in neural information processing systems,",
      "citeRegEx" : "Oded and Tomás,? \\Q1998\\E",
      "shortCiteRegEx" : "Oded and Tomás",
      "year" : 1998
    }, {
      "title" : "Estimating labels from label proportions",
      "author" : [ "N. Quadrianto", "A.J. Smola", "T.S. Caetano", "Q.V. Le" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Quadrianto et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Quadrianto et al\\.",
      "year" : 2008
    }, {
      "title" : "Conditional random fields for object recognition",
      "author" : [ "A. Quattoni", "M. Collins", "T. Darrell" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Quattoni et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Quattoni et al\\.",
      "year" : 2004
    }, {
      "title" : "Learning with relaxed supervision",
      "author" : [ "J. Steinhardt", "P. Liang" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Steinhardt and Liang,? \\Q2015\\E",
      "shortCiteRegEx" : "Steinhardt and Liang",
      "year" : 2015
    }, {
      "title" : "Randomized response techniques for multiple sensitive attributes",
      "author" : [ "A.C. Tamhane" ],
      "venue" : "Journal of the American Statistical Association (JASA),",
      "citeRegEx" : "Tamhane,? \\Q1981\\E",
      "shortCiteRegEx" : "Tamhane",
      "year" : 1981
    }, {
      "title" : "Twitch crowdsourcing: crowd contributions in short bursts of time",
      "author" : [ "R. Vaish", "K. Wyngarden", "J. Chen", "B. Cheung", "M.S. Bernstein" ],
      "venue" : "In Conference on Human Factors in Computing Systems (CHI),",
      "citeRegEx" : "Vaish et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Vaish et al\\.",
      "year" : 2014
    }, {
      "title" : "Asymptotic statistics",
      "author" : [ "A.W. van der Vaart" ],
      "venue" : null,
      "citeRegEx" : "Vaart,? \\Q1998\\E",
      "shortCiteRegEx" : "Vaart",
      "year" : 1998
    }, {
      "title" : "Estimating mixture models via mixture of polynomials",
      "author" : [ "S. Wang", "A. Chaganty", "P. Liang" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Wang et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2015
    }, {
      "title" : "Randomized response: A survey technique for eliminating evasive answer bias",
      "author" : [ "S.L. Warner" ],
      "venue" : "Journal of the American Statistical Association (JASA),",
      "citeRegEx" : "Warner,? \\Q1965\\E",
      "shortCiteRegEx" : "Warner",
      "year" : 1965
    } ],
    "referenceMentions" : [ {
      "referenceID" : 33,
      "context" : "We are interested in indirect supervision for two reasons: first, one might not trust a data collector and wish to use privacy mechanisms to reveal only partial information about sensitive data (Warner, 1965; Evfimievski et al., 2004; Dwork et al., 2006; Duchi et al., 2013).",
      "startOffset" : 194,
      "endOffset" : 274
    }, {
      "referenceID" : 11,
      "context" : "We are interested in indirect supervision for two reasons: first, one might not trust a data collector and wish to use privacy mechanisms to reveal only partial information about sensitive data (Warner, 1965; Evfimievski et al., 2004; Dwork et al., 2006; Duchi et al., 2013).",
      "startOffset" : 194,
      "endOffset" : 274
    }, {
      "referenceID" : 10,
      "context" : "We are interested in indirect supervision for two reasons: first, one might not trust a data collector and wish to use privacy mechanisms to reveal only partial information about sensitive data (Warner, 1965; Evfimievski et al., 2004; Dwork et al., 2006; Duchi et al., 2013).",
      "startOffset" : 194,
      "endOffset" : 274
    }, {
      "referenceID" : 8,
      "context" : "We are interested in indirect supervision for two reasons: first, one might not trust a data collector and wish to use privacy mechanisms to reveal only partial information about sensitive data (Warner, 1965; Evfimievski et al., 2004; Dwork et al., 2006; Duchi et al., 2013).",
      "startOffset" : 194,
      "endOffset" : 274
    }, {
      "referenceID" : 26,
      "context" : "Second, if data is generated by human annotators, say in a crowdsourcing setting, it can often be more cost-effective to solicit lightweight annotations (Oded & Tomás, 1998; Mann & McCallum, 2008; Quadrianto et al., 2008; Liang et al., 2009).",
      "startOffset" : 153,
      "endOffset" : 241
    }, {
      "referenceID" : 20,
      "context" : "Second, if data is generated by human annotators, say in a crowdsourcing setting, it can often be more cost-effective to solicit lightweight annotations (Oded & Tomás, 1998; Mann & McCallum, 2008; Quadrianto et al., 2008; Liang et al., 2009).",
      "startOffset" : 153,
      "endOffset" : 241
    }, {
      "referenceID" : 6,
      "context" : "Second, even the computation of the gradient or performing the E-step can be intractable, requiring probabilistic inference on a loopy graphical model induced by the indirect supervision (Chang et al., 2007; Graça et al., 2008; Liang et al., 2009).",
      "startOffset" : 187,
      "endOffset" : 247
    }, {
      "referenceID" : 12,
      "context" : "Second, even the computation of the gradient or performing the E-step can be intractable, requiring probabilistic inference on a loopy graphical model induced by the indirect supervision (Chang et al., 2007; Graça et al., 2008; Liang et al., 2009).",
      "startOffset" : 187,
      "endOffset" : 247
    }, {
      "referenceID" : 20,
      "context" : "Second, even the computation of the gradient or performing the E-step can be intractable, requiring probabilistic inference on a loopy graphical model induced by the indirect supervision (Chang et al., 2007; Graça et al., 2008; Liang et al., 2009).",
      "startOffset" : 187,
      "endOffset" : 247
    }, {
      "referenceID" : 16,
      "context" : "We lean on the method of moments (Pearson, 1894), which has recently led to advances in learning latent-variable models (Hsu et al., 2009; Anandkumar et al., 2013; Chaganty & Liang, 2014), although we do not appeal to tensor factorization.",
      "startOffset" : 120,
      "endOffset" : 187
    }, {
      "referenceID" : 1,
      "context" : "We lean on the method of moments (Pearson, 1894), which has recently led to advances in learning latent-variable models (Hsu et al., 2009; Anandkumar et al., 2013; Chaganty & Liang, 2014), although we do not appeal to tensor factorization.",
      "startOffset" : 120,
      "endOffset" : 187
    }, {
      "referenceID" : 19,
      "context" : "For concreteness, we specialize to conditional random fields (CRFs) (Lafferty et al., 2001) over collections of K-variate labels, where x = (x[1], .",
      "startOffset" : 68,
      "endOffset" : 91
    }, {
      "referenceID" : 12,
      "context" : "This motivates a number of relaxations (Graça et al., 2008; Liang et al., 2009; Steinhardt & Liang, 2015), but there are no guarantees on approximation quality.",
      "startOffset" : 39,
      "endOffset" : 105
    }, {
      "referenceID" : 20,
      "context" : "This motivates a number of relaxations (Graça et al., 2008; Liang et al., 2009; Steinhardt & Liang, 2015), but there are no guarantees on approximation quality.",
      "startOffset" : 39,
      "endOffset" : 105
    }, {
      "referenceID" : 11,
      "context" : "To quantify the amount of privacy afforded by S, we turn to the literature on privacy in databases and theoretical computer science (Evfimievski et al., 2004; Dwork et al., 2006) and say that S is α-differentially private if any two y, y′ have comparable probability (up to a factor of exp(α)) of generating o:",
      "startOffset" : 132,
      "endOffset" : 178
    }, {
      "referenceID" : 10,
      "context" : "To quantify the amount of privacy afforded by S, we turn to the literature on privacy in databases and theoretical computer science (Evfimievski et al., 2004; Dwork et al., 2006) and say that S is α-differentially private if any two y, y′ have comparable probability (up to a factor of exp(α)) of generating o:",
      "startOffset" : 132,
      "endOffset" : 178
    }, {
      "referenceID" : 20,
      "context" : "This motivates a line of work which attempts to learn from weaker forms of annotation (Mann & McCallum, 2008; Haghighi & Klein, 2006; Liang et al., 2009).",
      "startOffset" : 86,
      "endOffset" : 153
    }, {
      "referenceID" : 30,
      "context" : "The rationale is that it is cognitively easier for the annotator to focus on one label at a time rather than annotating from a large tag set, and physically easier to hit a single yes/no or counter button than to select precise locations, especially in mobile-based crowdsourcing interfaces (Vaish et al., 2014).",
      "startOffset" : 291,
      "endOffset" : 311
    }, {
      "referenceID" : 3,
      "context" : "These are admittedly strong independence assumptions similar to IBM model 1 for word alignment (Brown et al., 1993) or the unordered translation model of Steinhardt & Liang (2015).",
      "startOffset" : 95,
      "endOffset" : 115
    }, {
      "referenceID" : 3,
      "context" : "These are admittedly strong independence assumptions similar to IBM model 1 for word alignment (Brown et al., 1993) or the unordered translation model of Steinhardt & Liang (2015). Even though our model is fully factorized and lacks edge potentials, inference pθ(y | x, o) is expensive as conditioning on the indirect supervision o couples all of the y variables.",
      "startOffset" : 96,
      "endOffset" : 180
    }, {
      "referenceID" : 3,
      "context" : "These are admittedly strong independence assumptions similar to IBM model 1 for word alignment (Brown et al., 1993) or the unordered translation model of Steinhardt & Liang (2015). Even though our model is fully factorized and lacks edge potentials, inference pθ(y | x, o) is expensive as conditioning on the indirect supervision o couples all of the y variables. This typically calls for approximate inference techniques common to the realm of structured prediction. Steinhardt & Liang (2015) developed a relaxation to cope with this supervision, but this still requires approximate inference via sampling and non-convex optimization.",
      "startOffset" : 96,
      "endOffset" : 494
    }, {
      "referenceID" : 31,
      "context" : "To compute Σmarg, we follow standard arguments in van der Vaart (1998). If `(o; θ) is the marginal log-likelihood, then a straightforward calculation yields ∇`(o, θ∗) = E[φ(y) | o] − E[φ(y)].",
      "startOffset" : 58,
      "endOffset" : 71
    }, {
      "referenceID" : 33,
      "context" : "Local privacy has its roots in classical randomized response for conducting surveys (Warner, 1965), which has been extended to the multivariate (Tamhane, 1981) and conditional (Matloff, 1984) settings.",
      "startOffset" : 84,
      "endOffset" : 98
    }, {
      "referenceID" : 29,
      "context" : "Local privacy has its roots in classical randomized response for conducting surveys (Warner, 1965), which has been extended to the multivariate (Tamhane, 1981) and conditional (Matloff, 1984) settings.",
      "startOffset" : 144,
      "endOffset" : 159
    }, {
      "referenceID" : 24,
      "context" : "Local privacy has its roots in classical randomized response for conducting surveys (Warner, 1965), which has been extended to the multivariate (Tamhane, 1981) and conditional (Matloff, 1984) settings.",
      "startOffset" : 176,
      "endOffset" : 191
    }, {
      "referenceID" : 9,
      "context" : "In the computer science community, differential privacy has emerged as a useful formalization of privacy (Dwork, 2006).",
      "startOffset" : 105,
      "endOffset" : 118
    }, {
      "referenceID" : 11,
      "context" : "We work with the stronger notion of local differential privacy (Evfimievski et al., 2004; Kasiviswanathan et al., 2011; Duchi et al., 2013).",
      "startOffset" : 63,
      "endOffset" : 139
    }, {
      "referenceID" : 18,
      "context" : "We work with the stronger notion of local differential privacy (Evfimievski et al., 2004; Kasiviswanathan et al., 2011; Duchi et al., 2013).",
      "startOffset" : 63,
      "endOffset" : 139
    }, {
      "referenceID" : 8,
      "context" : "We work with the stronger notion of local differential privacy (Evfimievski et al., 2004; Kasiviswanathan et al., 2011; Duchi et al., 2013).",
      "startOffset" : 63,
      "endOffset" : 139
    }, {
      "referenceID" : 2,
      "context" : "Multiinstance learning (Oded & Tomás, 1998) is popular in computer vision, where it is natural to label the presence but not location of objects (Babenko et al., 2009).",
      "startOffset" : 145,
      "endOffset" : 167
    }, {
      "referenceID" : 20,
      "context" : "In natural language processing, there also been work on learning from structured outputs where, like this work, only counts of labels are observed (Mann & McCallum, 2008; Liang et al., 2009).",
      "startOffset" : 147,
      "endOffset" : 190
    }, {
      "referenceID" : 2,
      "context" : "Multiinstance learning (Oded & Tomás, 1998) is popular in computer vision, where it is natural to label the presence but not location of objects (Babenko et al., 2009). In natural language processing, there also been work on learning from structured outputs where, like this work, only counts of labels are observed (Mann & McCallum, 2008; Liang et al., 2009). However, these works resort to likelihood-based approaches which involve non-convex optimization and approximate inference, whereas in this work, we show that linear algebra and convex optimization suffice under modeling assumptions. Quadrianto et al. (2008) showed how to learn from label proportions of groups of examples, using a linear system technique similar to ours.",
      "startOffset" : 146,
      "endOffset" : 620
    }, {
      "referenceID" : 3,
      "context" : "Indirect supervision arises more generally in latent-variable models, which arises in machine translation (Brown et al., 1993), semantic parsing (Liang et al.",
      "startOffset" : 106,
      "endOffset" : 126
    }, {
      "referenceID" : 21,
      "context" : ", 1993), semantic parsing (Liang et al., 2011), object detection (Quattoni et al.",
      "startOffset" : 26,
      "endOffset" : 46
    }, {
      "referenceID" : 27,
      "context" : ", 2011), object detection (Quattoni et al., 2004), and other missing data problems in statistics (M & Naisyin, 2000).",
      "startOffset" : 26,
      "endOffset" : 49
    }, {
      "referenceID" : 17,
      "context" : "In recent years, tensor factorization techniques have provided efficient methods for a wide class of latent-variable models (Hsu et al., 2012; Anandkumar et al., 2012; Hsu & Kakade, 2013; Anandkumar et al., 2013; Chaganty & Liang, 2013; Halpern & Sontag, 2013; Chaganty & Liang, 2014).",
      "startOffset" : 124,
      "endOffset" : 284
    }, {
      "referenceID" : 0,
      "context" : "In recent years, tensor factorization techniques have provided efficient methods for a wide class of latent-variable models (Hsu et al., 2012; Anandkumar et al., 2012; Hsu & Kakade, 2013; Anandkumar et al., 2013; Chaganty & Liang, 2013; Halpern & Sontag, 2013; Chaganty & Liang, 2014).",
      "startOffset" : 124,
      "endOffset" : 284
    }, {
      "referenceID" : 1,
      "context" : "In recent years, tensor factorization techniques have provided efficient methods for a wide class of latent-variable models (Hsu et al., 2012; Anandkumar et al., 2012; Hsu & Kakade, 2013; Anandkumar et al., 2013; Chaganty & Liang, 2013; Halpern & Sontag, 2013; Chaganty & Liang, 2014).",
      "startOffset" : 124,
      "endOffset" : 284
    }, {
      "referenceID" : 32,
      "context" : "One can leverage even more general polynomialsolving techniques to expand the set of models (Wang et al., 2015).",
      "startOffset" : 92,
      "endOffset" : 111
    } ],
    "year" : 2016,
    "abstractText" : "In structured prediction problems where we have indirect supervision of the output, maximum marginal likelihood faces two computational obstacles: non-convexity of the objective and intractability of even a single gradient computation. In this paper, we bypass both obstacles for a class of what we call linear indirectly-supervised problems. Our approach is simple: we solve a linear system to estimate sufficient statistics of the model, which we then use to estimate parameters via convex optimization. We analyze the statistical properties of our approach and show empirically that it is effective in two settings: learning with local privacy constraints and learning from low-cost count-based annotations.1",
    "creator" : "LaTeX with hyperref package"
  }
}