{
  "name" : "1509.01899.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Integrate Document Ranking Information into Confidence Measure Calculation for Spoken Term Detection",
    "authors" : [ "Quan Liu", "Wu Guo", "Zhen-Hua Ling" ],
    "emails" : [ "quanliu@mail.ustc.edu.cn,", "guowu@ustc.edu.cn,", "zhling@ustc.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information search and retrieval—search process, selection process; I.2.7 [Artificial Intelligence]: Natural Language Processing\nGeneral Terms Algorithms, Management, Verification\nKeywords Spoken Term Detection, Speech Retrieval, Confidence Measure, Document Ranking, Speech Recognizer."
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Spoken term detection (STD) is a task designed for efficient keyword search (given text query) in a speech databases,\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$15.00.\nand plays a central role in information management and speech retrieval [12, 4, 6, 13]. State-of-the-art STD approaches include two subsystems. The first one is an automatic speech recognizer (ASR), which is used to transcribe the spoken utterances into text. The text transcriptions contain all the possibly recognized words with corresponding posterior probabilities [5, 12, 13]. The posterior probability as been one typical confidence measure plays a central role in keyword searching. The second subsystem is a keyword searcher which returns the results of term detection for each query term according to the decoded transcriptions. Formally, in STD applications, a confidence measure (CM) is defined to represent the reliability of each detected term occurrence, which is usually estimated by the recognizer [5, 12]. Relying on the confidence measure, the final term detection results could be obtained by threshold-based recall. However, when only limited training resources are available for building the ASR system, the accuracy of the recognizer and the reliability of the confidence measure are relatively low, which makes it difficult to find correct query results in the speech database.\nThis paper focuses on the calculation of confidence measure for STD when the speech recognizer has been built. In this situation, a one-pass retrieval candidate set can be obtained for each query. Each candidate contains the term occurrence location information and the corresponding confidence measure. The baseline system of this paper could then be evaluated on it directly by conducting standard score normalization and final decision [11, 13]. To improve the reliability of term occurrences, some recent efforts have attempted to do this work and have achieved some improvements on STD task. In [10, 9], the confidence measure of query occurrence is re-estimated based on the context consistency information. [19] proposed a two-stage cascaded machine learning approach for rescoring keyword search outputs for low resource languages. [20] proposed a modified logistic regression strategy for term detection optimization. Discriminative score normalization method was introduced to normalize confidence measures through discriminative modeling [14]. Moreover, another method was proposed in [8] to employ extra acoustic features for getting a better confidence measure.\nHowever, all these methods fail to utilize long-term contexts at document or topic level, which has been proved to be useful for some other information retrieval (IR) tasks [15, 23]. Clustering and latent topic models have also gained improvements over traditional vector space models for IR [21, 2]. Besides, the well known PageRank algorithm considers\nar X\niv :1\n50 9.\n01 89\n9v 2\n[ cs\n.C L\n] 1\n0 Se\np 20\n15\nthe hyperlink between every two pages and computes a converged importance score for each page [1]. Inspired by these work, this paper proposes to integrate document ranking information into the calculation of confidence measures of term occurrences for spoken term detection. The document ranking information is defined to be the topic relevance between the document and query term. For each query term, there are some documents tend to be more related to it because they are of a similar topic. When examining the accuracy of STD results, those topic-related documents tend to contain more correct hits. In detail, this information is quantized as a ranking weight for each document in this paper. Based on the one-pass retrieval candidates for a specific query term, we first sum up the confidence measures of all term occurrences in each document. The document ranking weights are then estimated by normalizing these sums and are further integrated into the original confidence measures through linear interpolation. Experiments on three standard STD tasks demonstrate the effectiveness of our proposed method.\nFor the rest of this paper, we will describe the related works of this paper in Section 2. The proposed algorithm for confidence measure calculation will be presented in Section 3. Section 4 and 5 are the experimental setup and results on three standard STD tasks. Finally, we will conclude our work in Section 6."
    }, {
      "heading" : "2. RELATED WORK",
      "text" : "There are some other work attempted to utilize long-term contexts for STD. In [3], they improved term detection performance based on the word burstiness in spoken conversational corpora. More recently, [22, 17] took advantage of word repetition to improve spoken term detection, having observed the phenomenon of word repetition within single documents. They leveraged the burstiness of keywords by taking the most confident keyword hypothesis in each document and interpolating with lower scoring hits. Although they had designed an effective method to determine the inter coefficients in their experiments, they focussed on intradocument term repetition, without paying attention to the inter-document contexts, e.g. the document ranking information used in this paper. The work in [7] is very similar to us since they also gave a high priority to the candidate segments that are included in highly ranked documents. However, they proposed to calculate the position dependent document weights recursively. This paper calculates document ranking weights in a more easier way and considers the inter document ranking information. In this paper, we will rank all documents in the speech database according to their relevance with a specific query term and incorporate such document ranking information into the calculation of confidence measures."
    }, {
      "heading" : "3. PROPOSED METHOD",
      "text" : "For an input query term, a set of one-pass retrieval candidates in the speech database is firstly generated following the conventional STD approach. Each term detection occurrence commonly contains location information and a confidence measure, while the location information usually includes the located document name (or ID), start time and duration time. For example, for term t, we use Oi to represent the location information of the i-th detection occurrence\nAlgorithm 1 Calculate Document Ranking Weights Given a Query Term\nInput: The set of one-pass retrieval candidates given query term t. Output: The document ranking weights for all documents in the database. Main procedure:\n1. Document Clustering Cluster the documents in all the hypothesized occurrences of term t by summing all the confidence measures in each document d:\nSd(t) = ∑ Oi∈d CMbase(t|Oi, d), (1)\nwhere Sd(t) can be viewed as the occurrence possibility of term t in document d. The maximum score Smax(t) for term t can also be obtained if we traverse all the documents.\nSmax(t) = max d∈all documents Sd(t). (2)\n2. Document Ranking The ranking weight Wd(t) for each document is calculated using the “relative-to-max” method, which is obtained by dividing Sd(t) by Smax(t):\nWd(t) = Sd(t)/Smax(t). (3)\nEnd\nof term t. If the location information indicates that this occurrence candidate belong to document d, then the confidence measure of the i-th term detection occurrence confidence measure can be denoted as CMbase(t|Oi, d). We use subscript “base” to emphasis that this measure is obtained from the one-pass retrieval candidate set. The confidence measure is designed to describe the reliability of a detected term occurrence, i.e., a correct query hit is expected to have a high confidence measure. However, when the ASR subsystem performs poorly, there may be many false alarms with high confidence measure as well as correct candidates with low confidence measure.\nBased on the idea we have described in the introduction section, we propose to use document ranking information to improve the calculation of confidence measures. The algorithm to estimate the document ranking weight Wd(t) for a input term t is described in Algorithm 1. After the calculation of document ranking weights, we re-estimate the confidence measure of each occurrence by combining the original one with the ranking weight of the document it belongs to. In this work, a linear interpolation is adopted as\nCMnew(t|Oi, d) = αWd(t) + (1− α)CMbase(t|Oi, d), (4)\nwhere the interpolation coefficient α for interpolation is consistent for all query terms, and it can be tuned using a development set. In short, the algorithm of confidence reestimation can be divided into three steps, i.e., document clustering, document ranking and confidence re-estimation."
    }, {
      "heading" : "4. EXPERIMENTAL SETUP",
      "text" : ""
    }, {
      "heading" : "4.1 Data Set and Evaluation Condition",
      "text" : "The experiments were conducted using three standard spoken term detection tasks, the STD 2006 English conver-\nsational telephone speech (CTS) evaluation set, the OpenKWS 2013 Vietnamese and the OpenKWS 2014 Tamil development sets1. The English CTS evaluation set included about 3 hours of speech, and the keyword set consisted of 411 keywords. The development sets of Vietnamese and Tamil included about 10 hours of speech respectively. The evaluation keyword set for Vietnamese consisted of 4065 keywords, with 901 of those keywords appearing in the development set and being used in our experiments. For the Tamil task, we used the kwlist3 keyword set supplied by IBM, which consisted of 2375 keywords. The intention of using three tasks was to evaluate the proposed algorithm using three very different languages, with different ASR accuracy, different amounts of training data and with variations in the sizes of keyword sets. The evaluation criterion used in the experiments was the Actual Term Weighted Value (ATWV) defined by NIST, using a cost function of the false alarm probability P(FA) and P(Miss), averaged over a set of queries2."
    }, {
      "heading" : "4.2 Automatic Speech Recognizer",
      "text" : "Our ASR engines were built using the DNN-HMM based acoustic modeling, which is the state-of-the-art approach for speech recognition [18].\nFor the English task, 309 hours of Switchboard speech were used to train the acoustic model, and the transcriptions of these speech files were used to train a 3-gram language model. The cross entropy criterion was used to train the DNN models. The word accuracy (ACC) of the ASR system on the evaluation set was 77.67%.\nFor the Vietnamese recognizer, two approaches were adopted to prevent the over-fitting problem in DNN training since the training corpus contains only about 70 hours of speech. The first approach was cross-lingual training, where we used a DNN model acquired from 1000 hours of Chinese CTS data to initialize the Vietnamese DNN parameters. Furthermore, the rectified linear unit (ReLU) activation function was used to replace the sigmoid function in the DNN model. The transcripts of the Vietnamese training files were then used to train a 2-gram language model. A word ACC of 45.76% was achieved on the development set. The strategy employed for the Tamil ASR engine was similar to that used for Vietnamese. The only difference was that the sequence training algorithm was applied in the DNN training for Tamil. A word ACC of 31.03% was achieved on the development set."
    }, {
      "heading" : "4.3 STD Indexer and Keyword Searcher",
      "text" : "We designed a toolkit named iSTD to build our keyword search subsystem for STD. We followed the work in [12, 13] to construct the inverted index based on confusion networks. The term occurrence candidates were then found by keyword searching on the inverted index. The confidence re-estimation algorithm proposed in this paper was also integrated into this toolkit."
    }, {
      "heading" : "5. EXPERIMENTAL RESULTS",
      "text" : "5.1 Effectiveness of Document Ranking 1http://www.nist.gov/itl/iad/mig/openkws.cfm 2http://www.itl.nist.gov/iad/mig/tests/std/2006/docs/std06evalplan-v10.pdf\nIn order to validate the rationality of applying the document ranking information to STD tasks, we examined the relationship between the performance of term detection and the document ranking positions. Here, the document ranking positions were derived by sorting all documents in descending order of the weights calculated following Algorithm 1. Figure 1 shows the correlation curve for the aforementioned Vietnamese STD task. The results were obtained by averaging over 901 query keywords. The correlation curves reveal that the documents with high document ranking weights usually have high precision and recall of term detection.\nIn addition, we calculated the Spearman rank correlation coefficient between the two performance measurement of term detection and the document ranking weights on the three STD tasks. The results are given in Table 1 and shows the existence of high correlations. All these results indicate that the document ranking information is strongly correlated with the STD performance and it is reasonable to integrate it into the calculation of confidence measures for the term detection."
    }, {
      "heading" : "5.2 Results of Tuning Interpolation Coefficients",
      "text" : "The interpolation coefficient α in (4) controls the balance between the document weights and the baseline confidence measures for a specific query term. To explore its practical effcets, the ATWVs on the development set of the Vietnamese STD task versus different interpolation coefficients were depicted in Fig. 2. We can see that a reasonable choice for α is within the range 0.05 to 0.4. In the next section, experimental results will be presented for different tasks, where α was tuned on the development and set to be 0.05, 0.1 and 0.15 for Tamil, Vietnamese and English respectively."
    }, {
      "heading" : "5.3 Results of STD Tasks",
      "text" : "We compared the proposed confidence measure re-estimation algorithm with the baseline system for the three STD tasks. The baseline system directly adopted the ASR posterior score as the confidence measure for each query term. Keywordspecific threshold was applied for all systems as the final decision recall method [16]. Experimental results are listed in Table 2. We can see that the proposed confidence reestimation approach achieves consistent improvements for all the three typical speech retrieval tasks. Considering the amount of training data available in these three tasks, the re-\nsults in Table 2 also indicate that the proposed confidence reestimation method is neither language-dependent, nor sensitive to the amounts of training resources."
    }, {
      "heading" : "6. CONCLUSIONS",
      "text" : "This paper has presented an algorithm to improve the calculation of confidence measures for spoken term detection. Inspired by the PageRank algorithm and the application of language models in the text information retrieval area, we propose to integrate the document ranking information into the calculation of confidence measures for term occurrences. The document ranking information indicates the topic relevance between each document and the query term, while topic-related documents are expected to contain more correct hits. Experiments on three standard STD tasks demonstrate the effectiveness of this algorithm by introducing document ranking information."
    }, {
      "heading" : "7. REFERENCES",
      "text" : "[1] S. Brin and L. Page. The anatomy of a large-scale\nhypertextual web search engine. Computer networks and ISDN systems, 30(1):107–117, 1998.\n[2] B. Chen. Latent topic modelling of word co-occurence information for spoken document retrieval. In Proc. ICASSP, pages 3961–3964. IEEE, 2009.\n[3] J. Chiu and A. I. Rudnicky. Using conversational word bursts in spoken term detection. In Proc. INTERSPEECH, pages 2247–2251, 2013.\n[4] J. G. Fiscus, J. Ajot, J. S. Garofolo, and G. Doddingtion. Results of the 2006 spoken term detection evaluation. In Proc. SIGIR, volume 7, pages 51–57, 2007.\n[5] H. Jiang. Confidence measures for speech recognition: A survey. Speech communication, 45(4):455–470, 2005.\n[6] J. Kohler, M. Larson, F. de Jong, W. Kraaij, and R. Ordelman. Spoken content retrieval: Searching spontaneous conversational speech. In ACM SIGIR Forum, volume 42, pages 66–75. ACM, 2008.\n[7] K. Konno, Y. Itoh, K. Kojima, M. Ishigame, K. Tanaka, and S.-w. Lee. High priority in highly ranked documents in spoken term detection. In Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2013 Asia-Pacific, pages 1–4. IEEE, 2013.\n[8] H.-y. Lee, P.-w. Chou, and L.-s. Lee. Improved open-vocabulary spoken content retrieval with word and subword lattices using acoustic feature similarity. Computer Speech & Language, 2014.\n[9] H.-y. Lee, T.-w. Tu, C.-P. Chen, C.-y. Huang, and L.-s. Lee. Improved spoken term detection using support vector machines based on lattice context consistency. In Proc. ICASSP, pages 5648–5651, 2011.\n[10] H. Li, J. Han, T. Zheng, and G. Zheng. A novel confidence measure based on context consistency for spoken term detection. In Proc. INTERSPEECH, 2012.\n[11] J. Mamou, J. Cui, X. Cui, M. J. F. Gales, B. Kingsbury, K. Knill, L. Mangu, D. Nolden, M. Picheny, B. Ramabhadran, R. Schlüter, A. Sethy, and P. C. Woodl. System combination and score normalization for spoken term detection. In Proc. ICASSP, pages 8272–8276, 2013.\n[12] J. Mamou, B. Ramabhadran, and O. Siohan. Vocabulary independent spoken term detection. In Proc. SIGIR, pages 615–622. ACM, 2007.\n[13] L. Mangu, B. Kingsbury, H. Soltau, H.-K. Kuo, and M. Picheny. Efficient spoken term detection using confusion networks. In Proc. ICASSP, pages 7844–7848, 2014.\n[14] V. T. Pham, H. Xu, N. F. Chen, S. Sivadas, B. P. Lim, E. S. Chng, and H. Li. Discriminative score normalization for keyword search decision. In Proc. ICASSP, pages 7078–7082, 2014.\n[15] J. M. Ponte and W. B. Croft. A language modeling approach to information retrieval. In Proc. SIGIR, pages 275–281. ACM, 1998.\n[16] Y. Proc. Wang and F. Metze. An in-depth comparison of keyword specific thresholding and sum-to-one score normalization. In INTERSPEECH, 2014.\n[17] J. Richards, M. Ma, and A. Rosenberg. Using word burst analysis to rescore keyword search candidates on low-resource languages. In Proc. ICASSP, pages 7824–7828, 2014.\n[18] F. Seide, G. Li, and D. Yu. Conversational speech transcription using context-dependent deep neural networks. In INTERSPEECH, pages 437–440, 2011.\n[19] V. Soto, L. Mangu, A. Rosenberg, and J. Hirschberg. A comparison of multiple methods for rescoring keyword search lists for low resource languages. In Proc. INTERSPEECH, 2014.\n[20] J. van Hout, L. Ferrer, D. Vergyri, N. Scheffer, Y. Lei, V. Mitra, and S. Wegmann. Calibration and multiple system fusion for spoken term detection using linear logistic regression. In Proc. ICASSP, pages 7188–7192,\n2014.\n[21] X. Wei and W. B. Croft. Lda-based document models for ad-hoc retrieval. In Proc. SIGIR, pages 178–185. ACM, 2006.\n[22] J. Wintrode and S. Khudanpur. Can you repeat that? using word repetition to improve spoken term detection. In Proc. ACL, pages 1316–1325. Association for Computational Linguistics, 2014.\n[23] C. Zhai and J. Lafferty. A study of smoothing methods for language models applied to information retrieval. ACM Transactions on Information Systems (TOIS), 22(2):179–214, 2004."
    } ],
    "references" : [ {
      "title" : "The anatomy of a large-scale hypertextual web search engine",
      "author" : [ "S. Brin", "L. Page" ],
      "venue" : "Computer networks and ISDN systems,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1998
    }, {
      "title" : "Latent topic modelling of word co-occurence information for spoken document retrieval",
      "author" : [ "B. Chen" ],
      "venue" : "In Proc. ICASSP,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "Using conversational word bursts in spoken term detection",
      "author" : [ "J. Chiu", "A.I. Rudnicky" ],
      "venue" : "In Proc. INTERSPEECH,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "Doddingtion. Results of the 2006 spoken term detection evaluation",
      "author" : [ "J.G. Fiscus", "J. Ajot", "J.S. Garofolo" ],
      "venue" : "In Proc. SIGIR,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2007
    }, {
      "title" : "Confidence measures for speech recognition: A survey",
      "author" : [ "H. Jiang" ],
      "venue" : "Speech communication,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2005
    }, {
      "title" : "Spoken content retrieval: Searching spontaneous conversational speech",
      "author" : [ "J. Kohler", "M. Larson", "F. de Jong", "W. Kraaij", "R. Ordelman" ],
      "venue" : "In ACM SIGIR Forum,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2008
    }, {
      "title" : "High priority in highly ranked documents in spoken term detection",
      "author" : [ "K. Konno", "Y. Itoh", "K. Kojima", "M. Ishigame", "K. Tanaka", "S.-w. Lee" ],
      "venue" : "In Signal and Information Processing Association Annual Summit and Conference (APSIPA),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2013
    }, {
      "title" : "Improved open-vocabulary spoken content retrieval with word and subword lattices using acoustic feature similarity",
      "author" : [ "H.-y. Lee", "P.-w. Chou", "L.-s. Lee" ],
      "venue" : "Computer Speech & Language,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2014
    }, {
      "title" : "Improved spoken term detection using support vector machines based on lattice context consistency",
      "author" : [ "H.-y. Lee", "T.-w. Tu", "C.-P. Chen", "C.-y. Huang", "L.-s. Lee" ],
      "venue" : "In Proc. ICASSP,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "A novel confidence measure based on context consistency for spoken term detection",
      "author" : [ "H. Li", "J. Han", "T. Zheng", "G. Zheng" ],
      "venue" : "In Proc. INTERSPEECH,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2012
    }, {
      "title" : "System combination and score normalization for spoken term detection",
      "author" : [ "J. Mamou", "J. Cui", "X. Cui", "M.J.F. Gales", "B. Kingsbury", "K. Knill", "L. Mangu", "D. Nolden", "M. Picheny", "B. Ramabhadran", "R. Schlüter", "A. Sethy", "P.C. Woodl" ],
      "venue" : "In Proc. ICASSP,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2013
    }, {
      "title" : "Vocabulary independent spoken term detection",
      "author" : [ "J. Mamou", "B. Ramabhadran", "O. Siohan" ],
      "venue" : "In Proc. SIGIR,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2007
    }, {
      "title" : "Efficient spoken term detection using confusion networks",
      "author" : [ "L. Mangu", "B. Kingsbury", "H. Soltau", "H.-K. Kuo", "M. Picheny" ],
      "venue" : "In Proc. ICASSP,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Discriminative score normalization for keyword search decision",
      "author" : [ "V.T. Pham", "H. Xu", "N.F. Chen", "S. Sivadas", "B.P. Lim", "E.S. Chng", "H. Li" ],
      "venue" : "In Proc. ICASSP,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2014
    }, {
      "title" : "A language modeling approach to information retrieval",
      "author" : [ "J.M. Ponte", "W.B. Croft" ],
      "venue" : "In Proc. SIGIR,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1998
    }, {
      "title" : "An in-depth comparison of keyword specific thresholding and sum-to-one score normalization",
      "author" : [ "Y. Proc. Wang", "F. Metze" ],
      "venue" : "In INTERSPEECH,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2014
    }, {
      "title" : "Using word burst analysis to rescore keyword search candidates on low-resource languages",
      "author" : [ "J. Richards", "M. Ma", "A. Rosenberg" ],
      "venue" : "In Proc. ICASSP,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2014
    }, {
      "title" : "Conversational speech transcription using context-dependent deep neural networks",
      "author" : [ "F. Seide", "G. Li", "D. Yu" ],
      "venue" : "In INTERSPEECH,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2011
    }, {
      "title" : "A comparison of multiple methods for rescoring keyword search lists for low resource languages",
      "author" : [ "V. Soto", "L. Mangu", "A. Rosenberg", "J. Hirschberg" ],
      "venue" : "In Proc. INTERSPEECH,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2014
    }, {
      "title" : "Calibration and multiple system fusion for spoken term detection using linear logistic regression",
      "author" : [ "J. van Hout", "L. Ferrer", "D. Vergyri", "N. Scheffer", "Y. Lei", "V. Mitra", "S. Wegmann" ],
      "venue" : "In Proc. ICASSP,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2014
    }, {
      "title" : "Lda-based document models for ad-hoc retrieval",
      "author" : [ "X. Wei", "W.B. Croft" ],
      "venue" : "In Proc. SIGIR,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2006
    }, {
      "title" : "Can you repeat that? using word repetition to improve spoken term detection",
      "author" : [ "J. Wintrode", "S. Khudanpur" ],
      "venue" : "In Proc. ACL,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2014
    }, {
      "title" : "A study of smoothing methods for language models applied to information retrieval",
      "author" : [ "C. Zhai", "J. Lafferty" ],
      "venue" : "ACM Transactions on Information Systems (TOIS),",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "and plays a central role in information management and speech retrieval [12, 4, 6, 13].",
      "startOffset" : 72,
      "endOffset" : 86
    }, {
      "referenceID" : 3,
      "context" : "and plays a central role in information management and speech retrieval [12, 4, 6, 13].",
      "startOffset" : 72,
      "endOffset" : 86
    }, {
      "referenceID" : 5,
      "context" : "and plays a central role in information management and speech retrieval [12, 4, 6, 13].",
      "startOffset" : 72,
      "endOffset" : 86
    }, {
      "referenceID" : 12,
      "context" : "and plays a central role in information management and speech retrieval [12, 4, 6, 13].",
      "startOffset" : 72,
      "endOffset" : 86
    }, {
      "referenceID" : 4,
      "context" : "The text transcriptions contain all the possibly recognized words with corresponding posterior probabilities [5, 12, 13].",
      "startOffset" : 109,
      "endOffset" : 120
    }, {
      "referenceID" : 11,
      "context" : "The text transcriptions contain all the possibly recognized words with corresponding posterior probabilities [5, 12, 13].",
      "startOffset" : 109,
      "endOffset" : 120
    }, {
      "referenceID" : 12,
      "context" : "The text transcriptions contain all the possibly recognized words with corresponding posterior probabilities [5, 12, 13].",
      "startOffset" : 109,
      "endOffset" : 120
    }, {
      "referenceID" : 4,
      "context" : "Formally, in STD applications, a confidence measure (CM) is defined to represent the reliability of each detected term occurrence, which is usually estimated by the recognizer [5, 12].",
      "startOffset" : 176,
      "endOffset" : 183
    }, {
      "referenceID" : 11,
      "context" : "Formally, in STD applications, a confidence measure (CM) is defined to represent the reliability of each detected term occurrence, which is usually estimated by the recognizer [5, 12].",
      "startOffset" : 176,
      "endOffset" : 183
    }, {
      "referenceID" : 10,
      "context" : "The baseline system of this paper could then be evaluated on it directly by conducting standard score normalization and final decision [11, 13].",
      "startOffset" : 135,
      "endOffset" : 143
    }, {
      "referenceID" : 12,
      "context" : "The baseline system of this paper could then be evaluated on it directly by conducting standard score normalization and final decision [11, 13].",
      "startOffset" : 135,
      "endOffset" : 143
    }, {
      "referenceID" : 9,
      "context" : "In [10, 9], the confidence measure of query occurrence is re-estimated based on the context consistency information.",
      "startOffset" : 3,
      "endOffset" : 10
    }, {
      "referenceID" : 8,
      "context" : "In [10, 9], the confidence measure of query occurrence is re-estimated based on the context consistency information.",
      "startOffset" : 3,
      "endOffset" : 10
    }, {
      "referenceID" : 18,
      "context" : "[19] proposed a two-stage cascaded machine learning approach for rescoring keyword search outputs for low resource languages.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[20] proposed a modified logistic regression strategy for term detection optimization.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "Discriminative score normalization method was introduced to normalize confidence measures through discriminative modeling [14].",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 7,
      "context" : "Moreover, another method was proposed in [8] to employ extra acoustic features for getting a better confidence measure.",
      "startOffset" : 41,
      "endOffset" : 44
    }, {
      "referenceID" : 14,
      "context" : "However, all these methods fail to utilize long-term contexts at document or topic level, which has been proved to be useful for some other information retrieval (IR) tasks [15, 23].",
      "startOffset" : 173,
      "endOffset" : 181
    }, {
      "referenceID" : 22,
      "context" : "However, all these methods fail to utilize long-term contexts at document or topic level, which has been proved to be useful for some other information retrieval (IR) tasks [15, 23].",
      "startOffset" : 173,
      "endOffset" : 181
    }, {
      "referenceID" : 20,
      "context" : "Clustering and latent topic models have also gained improvements over traditional vector space models for IR [21, 2].",
      "startOffset" : 109,
      "endOffset" : 116
    }, {
      "referenceID" : 1,
      "context" : "Clustering and latent topic models have also gained improvements over traditional vector space models for IR [21, 2].",
      "startOffset" : 109,
      "endOffset" : 116
    }, {
      "referenceID" : 0,
      "context" : "the hyperlink between every two pages and computes a converged importance score for each page [1].",
      "startOffset" : 94,
      "endOffset" : 97
    }, {
      "referenceID" : 2,
      "context" : "In [3], they improved term detection performance based on the word burstiness in spoken conversational corpora.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 21,
      "context" : "More recently, [22, 17] took advantage of word repetition to improve spoken term detection, having observed the phenomenon of word repetition within single documents.",
      "startOffset" : 15,
      "endOffset" : 23
    }, {
      "referenceID" : 16,
      "context" : "More recently, [22, 17] took advantage of word repetition to improve spoken term detection, having observed the phenomenon of word repetition within single documents.",
      "startOffset" : 15,
      "endOffset" : 23
    }, {
      "referenceID" : 6,
      "context" : "The work in [7] is very similar to us since they also gave a high priority to the candidate segments that are included in highly ranked documents.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 17,
      "context" : "Our ASR engines were built using the DNN-HMM based acoustic modeling, which is the state-of-the-art approach for speech recognition [18].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 11,
      "context" : "We followed the work in [12, 13] to construct the inverted index based on confusion networks.",
      "startOffset" : 24,
      "endOffset" : 32
    }, {
      "referenceID" : 12,
      "context" : "We followed the work in [12, 13] to construct the inverted index based on confusion networks.",
      "startOffset" : 24,
      "endOffset" : 32
    }, {
      "referenceID" : 15,
      "context" : "Keywordspecific threshold was applied for all systems as the final decision recall method [16].",
      "startOffset" : 90,
      "endOffset" : 94
    } ],
    "year" : 2015,
    "abstractText" : "This paper proposes an algorithm to improve the calculation of confidence measure for spoken term detection (STD). Given an input query term, the algorithm first calculates a measurement named document ranking weight for each document in the speech database to reflect its relevance with the query term by summing all the confidence measures of the hypothesized term occurrences in this document. The confidence measure of each term occurrence is then re-estimated through linear interpolation with the calculated document ranking weight to improve its reliability by integrating document-level information. Experiments are conducted on three standard STD tasks for Tamil, Vietnamese and English respectively. The experimental results all demonstrate that the proposed algorithm achieves consistent improvements over the state-of-the-art method for confidence measure calculation. Furthermore, this algorithm is still effective even if a high accuracy speech recognizer is not available, which makes it applicable for the languages with limited speech resources.",
    "creator" : "LaTeX with hyperref package"
  }
}