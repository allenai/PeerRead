{
  "name" : "1611.00685.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "marek.rosa@goodai.com", "jan.feyereisl@goodai.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "M . R O S A , J . F E Y E R E I S L & T H E G O O D A I T E A M\nA F R A M E W O R K F O R S E A R C H I N G F O R G E N E R A L A R T I F I C I A L I N T E L L I G E N C E\nV E R S I O N 1\nar X\niv :1\n61 1.\n00 68\n5v 1\n[ cs\n.A I]\n2 N\nov 2\n01 6\nVersions\n1.0 current version: initial release for the general public\n2.0 planned future version: additional illustrations demonstrating framework principles\n3.0 planned future version: additional mathematical formalizations and proofs\nCorrespondence: {marek.rosa,jan.feyereisl}@goodai.com\nCopyright © 2016 GoodAI\nwww.goodai.com\nThe LATEX template used in this document is licensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0. Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “as is” basis, without warranties or conditions of any kind, either express or implied. See the License for the specific language governing permissions and limitations under the License.\nFirst printing, November 2016\nAbstract\nThere is a significant lack of unified approaches to building generally intelligent machines. The majority of current artificial intelligence research operates within a very narrow field of focus, frequently without considering the importance of the ’big picture’. In this document, we seek to describe and unify principles that guide the basis of our development of general artificial intelligence. These principles revolve around the idea that intelligence is a tool for searching for general solutions to problems. We define intelligence as the ability to acquire skills that narrow this search, diversify it and help steer it to more promising areas. We also provide suggestions for studying, measuring, and testing the various skills and abilities that a human-level1 1 Despite its vagueness, and the lack of a\nuniversal definition, the term provides a notion of an ability of a machine to solve as many tasks to at least the same level of accuracy as most humans. intelligent machine needs to acquire. The document aims to be both implementation agnostic, and to provide an analytic, systematic, and scalable way to generate hypotheses that we believe are needed to meet the necessary conditions in the search for general artificial intelligence. We believe that such a framework is an important stepping stone for bringing together definitions, highlighting open problems, connecting researchers willing to collaborate, and for unifying the arguably most significant search of this century.\nIntroduction\nThe search for general artificial intelligence (AI) is one of the biggest challenges of this century2. In this document we seek to describe and 2 Brenden M Lake, Tomer D Ullman,\nJoshua B Tenenbaum, and Samuel J Gershman. Building Machines that learn and think like people. arXiv:1604.00289, pages 1–55, 2016; Tomas Mikolov, Armand Joulin, and Marco Baroni. A Roadmap towards Machine Intelligence. arXiv:1511.08130, pages 1–39, 2015; Marcus Hutter. Universal Artificial Intelligence: Sequential Decisions based on Algorithmic Probability. 2005; and Shane Legg and Marcus Hutter. Universal intelligence: A definition of machine intelligence. Minds and Machines, 17(4): 391–444, 2007a unify the main principles behind our approach to solving this enormous challenge.\nWe believe that to tackle such a challenge, one can first begin with a certain theory or a collection of ideas and beliefs that are more or less correct, yet can be somewhat vague, not well defined and possibly puzzling in some ways. Then, one can work backwards from those concepts, refine those ideas, progressively eliminating vagueness and eventually providing robust and clear definitions, ideally crystallizing in the main minimal tenets of the true underlying theory. These are in fact the analytic and constructive stages of Bertrand Russel’s philosophical method3, respectively. This document should currently be 3 Kevin Klement. Russell’s\nLogical Atomism, 2013. URL http://plato.stanford.edu/archives/ spr2016/entries/logical-atomism/ viewed as being in the early analytic stage and a work in progress. With time however, it will be continually refined, and eventually, we believe, developed into a robust framework for building intelligent machines, especially with the help of the community.\nWe start with the reasoning behind the creation of this framework, followed by as of yet informal definitions (cf. tables of definitions in the Appendix) of our understanding of intelligence and related concepts. We then propose a way to build and educate general AI systems quickly and effectively through gradual and guided learning. We conclude with a critical look at our proposal and identification of important next steps. We start with the very basics, the principles and sometimes even describe the obvious. This is however necessary, in order to unify the definitions and approaches and subsequently the thinking of the community interested in collaborating and allow for more rapid and better-defined progress, enhanced collaboration, and reduction of the search space for general artificial intelligence.\n6 a framework for searching for general ai\nWhat is the goal of this framework?\nThis framework will eventually provide a unified collection of principles, ideas, definitions and formalizations of our thoughts on the process of developing general artificial intelligence. It allows us to bring together all that we believe is important for defining a basis on which we and others can build. It will act as a common language that everyone can understand, and provide a starting point for a platform for further discussions and evolution of our ideas.\nWithin this document, we also provide a list of “next steps”: important research topics that we believe the community as a whole should focus on next in order to allow for significant progress in this field. With a separable definition of the problems we are tackling, the work can be split among various research groups (both internally as well as among external collaborators, academia, students, other research centers and hobbyists). This framework does not focus on narrow artificial intelligence (which solves very specific problems well), or on short-term commercialization. The aim is long-term, with possible exploitation of useful applications along the way.\nWho is this framework for?\nThis framework is for both a general and a technical audience. The aim is to make it accessible to everyone first, yet with enough detail eventually, that advanced readers should also benefit from it. No previous experience with AI or robotics is necessary at this stage. If something is not clear in this document, it means that we have failed finding an appropriate exposition for presenting our ideas. Please let us know so we can deliver a better explanation in the next edition.\nWhat is general AI and how can it be useful?\nWe view artificial intelligence (AI) systems as programs that are able to learn, adapt, be creative and solve problems. Some divide the field into narrow (weak) and general (strong) AI4. This somewhat contrived 4 Sam Adams, Itmar Arel, Joscha Bach, Robert Coop, Rod Furlan, Ben Goertzel, J Storrs Hall, Alexei Samsonovich, Matthias Scheutz, Matthew Schlesinger, Stuart C Shapiro, and John Sowa. Mapping the Landscape of Human-Level Artificial General Intelligence. AI Magazine, 33(1):25–42, 2012; John McCarthy. Generality in Artificial Intelligence. Commun. ACM, 30(12):1030–1035, 1987; Ben Goertzel and Cassio Pennachin. Artificial General Intelligence. 2007; and John McCarthy and Patrick J Hayes. Some philosophical problems from the standpoint of artificial intelligence. Readings in Artificial Intelligence, 1969\ndivision primarily highlights the difference in universality of the underlying technology. While narrow AI is usually able to solve only one specific problem and is unable to transfer skills from domain to domain, general AI aims for a human-level skill set5.5 Sandeep Rajani. Artificial Intelligence - Man or Machine. International Journal of Information Technology and Knowledge Management, 4(1):173 – 176, 2011 No one has developed a practical general AI yet. With general AI,\nhumankind will be able do many things we simply cannot do with our current level of technology. We will automate science, engineer-\nintroduction 7\ning, production, manufacturing, robots, entertainment, anything you can think of, and more. We believe that general AI will help us become better people, augment our own intelligence, and recursively self-improve.\nFoundations of general AI\nBuilding general artificial intelligence is a highly complex process, comprising of a large variety of heterogeneous challenges. Over the years, a variety of disparate ideas and definitions on how to tackle this process emerged6. To clarify and unify our thoughts and ideas that\n6 Marcus Hutter. Universal Artificial Intelligence: Sequential Decisions based on Algorithmic Probability. 2005; Samuel J Gershman, Eric J Horvitz, and Joshua B Tenenbaum. Computational rationality: A converging paradigm for intelligence in brains, minds, and machines. Science, 349(6245):273–278, 2015; Shane Legg and Marcus Hutter. A Collection of Definitions of Intelligence. In Proceedings of AGI 2006: Workshop on Concepts, Architectures and Algorithms, pages 17–24, Amsterdam, The Netherlands, The Netherlands, 2007b; Shane Legg and Marcus Hutter. Universal intelligence: A definition of machine intelligence. Minds and Machines, 17(4):391–444, 2007a; and Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building Machines that learn and think like people. arXiv:1604.00289, pages 1–55, 2016 govern the foundations and basis upon which we build, we first provide descriptions of the two core principles underlying our general AI development. What is intelligence?\nWe view intelligence as a problem solving tool that searches for solutions to problems in dynamic, complex and uncertain environments. This view, consistent with numerous existing perspectives [Hutter, 2005, Lake et al., 2016, Legg and Hutter, 2007b, Marblestone et al., 2016] , can be simplified even further: from a computational point of view, most solvable problems can be viewed as search and optimization problems7, and the goal of intelligence (or an intelligent agent) is 7 George Pólya. How to solve it: a new\naspect of mathematical method. 2004; and Marvin Minsky. Steps toward Artificial Intelligence. Proceedings of the IRE, 49(1): 8–30, 1961 to always find the best available solutions with as few resources and as quickly as possible [Gershman et al., 2015, Marblestone et al., 2016].\nWe believe that intelligence can achieve this by discovering skills (abilities, heuristics, shortcuts, tricks) that narrow the search space8, 8 Douglas B Lenat and Edward A Feigen-\nbaum. On the Thresholds of Knowledge. Artif. Intell., 47(1-3):185–250, 1991 diversify it, and efficiently help steer it towards areas that are potentially more promising9. 9 Yoshua Bengio. Evolving Culture Ver-\nsus Local Minima. In Growing Adaptive Machines, pages 109–138. 2014We argue that some of the most useful skills are the capacity to gradually acquire new skills - which helps in exploiting accumulated knowledge in order to speed up the acquisition of additional skills, the reuse of existing skills, and recursive self-improvement10. 10 Bas R Steunebrink, Kristinn R Thóris-\nson, and Jürgen Schmidhuber. Growing Recursive Self-Improvers. In AGI, pages 129–139, 2016; and Eric Nivel, Kristinn R Thórisson, Bas R Steunebrink, Haris Dindo, Giovanni Pezzulo, Manuel Rodríguez, Carlos Hernández, Dimitri Ognibene, Jürgen Schmidhuber, Ricardo Sanz, Helgi P Helgason, Antonio Chella, and Gudberg K Jonsson. Bounded Recursive Self-Improvement. arXiv:1312.6764, 2013 This way, the intelligent agent continually creates a repertoire of skills that are, essentially, building blocks for new, more complex skills. The possibly limitless accumulation of skills in an intelligent machine is naturally bounded by limited resources (time, memory, atoms,\n10 a framework for searching for general ai\nenergy, etc.). This additional constraint on intelligence results in favoring “efficient” skills and operation under bounded rationality [Gershman et al., 2015].\nIn addition to gradual learning, guided learning helps narrow the search, because at each step, an intelligent teacher guides the agent and hence the agent has to search for a new solution only within a small and useful area11, decreasing the number of candidate solutions,11 Jürgen Schmidhuber. PowerPlay: Training an Increasingly General Problem Solver by Continually Searching for the Simplest Still Unsolvable Problem. Front. Psychol., 4:313, 2013; Yoshua Bengio, Jerome Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In ICML, pages 41–48, 2009; Caglar Gulcehre and Yoshua Bengio. Knowledge Matters: Importance of Prior Information for Optimization. JMLR, 17 (8):1–32, 2016; Kai A. Krueger and Peter Dayan. Flexible shaping: How learning in small steps helps. Cognition, 110(3):380–394, 2009; and Vladimir Vapnik. Learning Using Privileged Information : Similarity Control and Knowledge Transfer. JMLR, 16:2023–2049, 2015 and thereby reducing the complexity of the search space [Alexander and Brown, 2015, Amodei et al., 2015, Zhang et al., 2016, Zaremba and Sutskever, 2015, 2014, Gulcehre et al., 2016]. On the other hand, without gradual or guided learning, if the agent is expected to find a solution to a complex problem too far from its current capabilities, it might never find a solution within any reasonable amount of time. What is a skill?\nA skill is any assumption about a problem that narrows and diversifies the search for a solution and points the search towards more promising areas. It is not guaranteed to be perfect, but sufficient to meet immediate goals, i.e. progress towards ideally a general solution. It can be thought of as akin to a continuum between Minsky’s notion of mental skills in his Society of Mind12 and Orallo’s cognitive abilities13.12 Marvin Minsky. The Society of Mind. 1986 13 José Hernández-Orallo. Evaluation in artificial intelligence: from task-oriented to ability-oriented measurement. Artificial Intelligence Review, pages 1–51, 2016\nFor the purpose of this framework, we see the following words as synonyms for a “skill”: ability, heuristic, behavior, strategy, solution, algorithm, shortcut, trick, approximation, exploiting structure in data, and more. This covers a wide variety of methods for helping to solve problems and might seem counter-intuitive at first. Nonetheless, our aim is to give a clear exposition of the generality of the notion of a “skill” as a problem-solving mechanism and a device for narrowing and diversifying the search for solutions from a variety of viewpoints.\nA skill can also be considered a bias. It constrains the search space or restricts behavior.\nSome skills can be general, yet simple (e.g. the ability to detect a simple pattern such as a line or edge) while others can be general and complex (e.g. the ability to navigate through an environment, the ability to understand and use language, etc.).\nOne possible way to compare the intelligence of various agents is to measure and compare the complexity and generality of problems they can solve14. Another way can be in terms of measuring the effective14 José Hernández-Orallo and Neus Minaya-Collado. A formal definition of intelligence based on an intensional variant of kolmogorov complexity. In Proceedings of International Symposium of Engineering of Intelligent Systems (EIS ’98), pages 146–163, 1998\nfoundations of general ai 11\nness as well as efficiency of their skills [Gershman et al., 2015] in terms of their sample complexity, the required computational cycles or their reuse of previously learned skills.\nWhy is gradual good?\nGiven a difficult task that needs to be solved, a good strategy to find a solution is to break it down into smaller problems which are easier to deal with. The same is true for learning15. It is much faster to 15 Yoshua Bengio, Jerome Louradour, Ro-\nnan Collobert, and Jason Weston. Curriculum learning. In ICML, pages 41– 48, 2009; and Ruslan Salakhutdinov, Joshua B Tenenbaum, and Antonio Torralba. Learning with Hierarchical-Deep Models. IEEE Trans. Pattern Anal. Mach. Intell., (8):1958–1971, 2013 learn things gradually than to try to learn a complex skill from scratch [Alexander and Brown, 2015, Amodei et al., 2015, Zhang et al., 2016, Zaremba and Sutskever, 2015, Gulcehre et al., 2016, Oquab et al., 2014, Sharif et al., 2014, Azizpour et al., 2015]. One example of this is the hierarchical decomposition of a task into subtasks and the gradual learning of skills necessary for solving each of them [Krueger and Dayan, 2009], progressing from the bottom of the hierarchy to the top16 16 Hrushikesh Mhaskar, Qianli Liao,\nand Tomaso Poggio. Learning Functions: When Is Deep Better Than Shallow. arXiv:1603.00988, (45):1–12, 2016; Hrushikesh Mhaskar and Tomaso Poggio. Deep vs. shallow networks : An approximation theory perspective. (054): 1–16, 2016; and Tomaso Poggio, Fabio Anselmi, and Lorenzo Rosasco. I-theory on depth vs width: hierarchical function composition. (041), 2015 [Pólya, 2004].\nFor instance, consider a newborn child which is given the task of learning to get to the airport. The chance that the child will learn to do this is very small, as the space of possible states and actions is simply too large to explore in a reasonable amount of time. But if she is taught gradually via simpler tasks, for instance learning how to crawl first and then walk, one increases the chances of success, as the child can then exploit these previously learned skills to try to get to the airport.\nTherefore, it is beneficial to build systems which learn gradually, and to be in control of the learning process by guiding their learning in specific ways. Guided learning therefore means showing the system which things make sense to learn at this moment and in which order [Gulcehre and Bengio, 2016, Bengio et al., 2009, Vapnik, 2015]. This reduces the necessity for exploration even further.\nAnother benefit of gradual learning is its generality. We do not have to specify a single global objective function (the main goal of AI) at the beginning, because we are teaching general skills, which can be used later for solving new tasks.\nIn the case of the child, she is initially taught to walk and open doors, even if its teachers (parents) do not yet know that she will need to get to the airport on her own, become a dentist, etc.\nIf general skills are taught gradually, the teacher might have bet-\n12 a framework for searching for general ai\nter control over the knowledge that is learned by the system. Later, if a user specifies a goal for the system, it is more likely that in order to fulfill it, the system will try to use the already learned skills rather than invent new behavior from scratch. In this way, the chances that the system would discover an unwanted or harmful strategy could be reduced, compared to standard single-objective learning17.17 Jessica Taylor. Quantilizers: A Safer Alternative to Maximizers for Limited Optimization. In AAAI Workshop, 2016\nThis is similar to teaching the child how to walk and open doors, and then to go to the airport. It is more likely that the child will try to solve the task by walking and opening doors, rather than trying to learn a completely new skill (like flying) from scratch, because that would be significantly more difficult to discover or potentially even impossible.\nGradual learning has a number of other benefits [Gulcehre et al., 2016, Gulcehre and Bengio, 2016, Bengio et al., 2009]18 over standard18 Sinno J Pan and Qiang Yang. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng., 22(10):1345–1359, 2010\n“static” learning that we believe outweigh its disadvantages (outlined in the critique of our approach in Section 9):\n• Optimizing a model that has few parameters and gradually building up to a model with many parameters is more efficient than starting with a model that has many parameters from the beginning19. 19 Kenneth O Stanley and Risto Miikkulainen. Evolving neural networks through augmenting topologies. Evol. Comput., 10(2):99–127, 2002\nAt each step, you only need to optimize/learn a smaller number of new parameters20. 20 Tianqi Chen, Ian Goodfellow, and Jonathon Shlens. Net2Net: Accelerating Learning via Knowledge Transfer. arXiv:1511.05641, pages 1–10, 2015 • There is no need for a priori knowledge of the system’s architecture21. Architecture size can correspond to the complexity of given21 Guanyu Zhou, Kihyuk Sohn, and Honglak Lee. Online Incremental Feature Learning with Denoising Autoencoders. JMLR W&CP, 22:1453–1461, 2012; Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive Neural Networks. arXiv:1606.04671, 2016; and Thushan Ganegedara, Lionel Ott, and Fabio Ramos. Online Adaptation of Deep Architectures with Reinforcement Learning. arXiv:1608.02292, 2016 problems (the architecture can start small and grow as needed22, in 22 Scott E Fahlman and Christian Lebiere. The Cascade-Correlation Learning Architecture. In NIPS, pages 524–532, 1990 contrast to an architecture of a pre-defined final size) • Reuse of existing skills is feasible and even encouraged23 23 Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Neural Module Networks. CVPR, pages 39–48, 2016a; and Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Learning to Compose Neural Networks for Question Answering. arXiv:1601.01705, 2016b • Once a skill is acquired, it is no longer relevant how long the skill took to discover. The cost of using an existing skill is notably smaller than searching for a skill from scratch.\nHow to build and educate general AI?\nA system capable of general AI will eventually exhibit a very large repertoire of ideally general skills. Designing such a system from scratch and learning all skills at once is infeasible. The effort is more attainable if the problem of learning and designing is deconstructed into several, less complicated “sub-problems” which we know how to tackle. For example, it is clear that we want the AI to understand and remember images, so it needs the ability to analyze them and a memory to store data. It is beneficial if the system is able to communicate with humans24, so it will need to read, write and understand 24 Tomas Mikolov, Armand Joulin, and\nMarco Baroni. A Roadmap towards Machine Intelligence. arXiv:1511.08130, pages 1–39, 2015 language. It will also need to learn and adapt to new things, and much more.\nSkills as building blocks towards general AI\nCurrently, our definition of skills is very broad and can encompass many concepts. Rather than individual skills, it is the gradual acquisition of skills, their interplay and the continuum of their functionality that is important.\nSkills can range from simple general or concrete (like the ability to recognize faces, add numbers, open doors, etc.) to more complex abstract as well as specialised ones (like the ability to build a model of the world, to compress spatial and temporal data, to receive an error signal and adapt accordingly, to acquire new knowledge without forgetting older knowledge, etc.). Due to our graduality requirement, the necessity of skills to only represent general abilities is sufficient, but not necessary. Skills might also provide a way to measure how well parts of the system work, as it is clear how to measure which system is better in understanding speech, classification, and game playing [Hernández-Orallo, 2016]. However, it is still unclear how to evaluate general AI as a whole25.\n25 José Hernández-Orallo. The measure of all minds : evaluating natural and artificial intelligence. Cambridge University Press, 2017; Stuart M. Shieber. Does the Turing Test Demonstrate Intelligence or Not? AAAI, pages 1539–1542, 2006; Virginia Savova and Leonid Peshkin. Is the turing test good enough? The fallacy of resource-unbounded intelligence. IJCAI, pages 545–550, 2007; and Kristinn R Thórisson, Jordi Bieger, Thröstur Thorarensen, Jóna S Siguroardóttir, and Bas R Steunebrink. Why Artificial Intelligence Needs a Task Theory — And What It Might Look Like. arXiv:1604.04660, 2016\n14 a framework for searching for general ai\nIntrinsic vs. Learned Skills\nSome of the skills that a general AI system will possess might be intrinsic, i.e. hard-coded by programmers, but most will be learned. Take, for example, the evolution of humans26. Evolution provided us26 Charles Darwin. On the origin of species by means of natural selection, or the preservation of favoured races in the struggle for life. London: John Murray, 1859\nwith certain very general intrinsic skills or predispositions, but most of what we know, we need to learn during our lifetimes - from our parents, the environment, or society. Those skills cannot be hard-coded because humans, just like an AI, need to be able to adapt to unknown future situations. Sometimes it is also easier to teach the desired skill through an appropriate curriculum, than to add it as a part of the design. On the other hand, letting the AI discover all skills by itself, especially very general ones, would be slow and inefficient27. This\n27 Andrea L Thomaz and Cynthia Breazeal. Reinforcement learning with human teachers: Evidence of feedback and guidance with implications for learning performance. AAAI, 6:1000–1005, 2006; Tim Brys, Anna Harutyunyan, Halit Bener Suay, Sonia Chernova, Matthew E Taylor, and Ann Nowe. Reinforcement learning from demonstration through shaping. IJCAI, page 26, 2015; and James Macglashan, Robert Loftin, Michael L Littman, David L Roberts, and Matthew E Taylor. A Need for Speed : Adapting Agent Action Speed to Improve Task Learning from Non-Expert Humans Categories and Subject Descriptors. In AMAS ’16, pages 957–965, Richland, SC, 2016\nmeans that our job is to identify essential skills and find efficient ways to transfer them to a general AI system - by hard-coding them or by teaching them. It is not necessary to find the best skills. Any skills which have the desired properties and which enable the AI to further learn and improve itself can move us closer to general AI.\nHow to optimize the process?\nJust like an AI has to use efficient and effective methods when searching for problem solutions, AI researchers must also look for shortcuts to narrow the search for a general AI architecture and an optimal learning curriculum, as we cannot effectively explore the entire space of all potential solutions. We can, for instance, draw inspiration from evolution [Bengio, 2014, Darwin, 1859]28, animal brains29, or other systems,28 Eric R. Kandel and James H. Schwartz. Principles of neural science. 2012 29 Junhyuk Oh, Valliappa Chockalingam, Satinder Singh, and Honglak Lee. Control of Memory, Active Perception, and Action in Minecraft. arXiv:1605.09128, 2016; and Koji Toda and Michael L Platt. Animal cognition: Monkeys pass the mirror test. Current Biology, 25(2): R64–R66, 2015 designs and processes30. Part of the problem is also which general AI 30 Norman S. Nise. Control Systems Engineering. 2015 architecture and skill set is easier for us to attain now, with our current knowledge and resources. This framework, roadmap and the institute (see following sections, respectively and Fig. 1) are all part of our approach for optimizing the process of searching for general AI. In other words, narrowing the search for the architecture and the learning curriculum. We can start asking questions like,“What is the minimal skill set that is sufficient for human-level general AI?” If we can optimize the process by cutting out all unnecessary skills31, we can get to our goal31 Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K Warmuth. Occam’s razor. Readings in machine learning, pages 201–204, 1990\nfaster. On the other hand, a learning algorithm alone wouldn’t be sufficient; we also need the thousands or millions of learned skills for a particular domain. Without them, the AI would not be able to start solving the problems we give it. For example, baking a cake is not likely to be a crucial skill for an AI system attempting to solve difficult medical problems, spending most of its time studying medical\nhow to build and educate general ai? 15\nFigure 1: Conceptual overview of our proposed approach to optimizing the process of building general AI. A framework defines the principles, ideas, methodologies and definitions that underlie our search for general AI. Roadmap defines a partially ordered set of skills (Si) which are either to be learned gradually in a guided way, or already be present in the system at its inception. The AI Roadmap Institute analyses different roadmaps (Rj) and frameworks to develop an understanding of the entire field and provide continual feedback and discussion about both, frameworks and roadmaps.\njournals. But a skill such as the ability to generalize to similar, but previously unseen situations is universal, and falls into the category of necessary skills for every general AI. Through continual feedback during architecture creation, learning of a curriculum, analyses and comparison by the institute and collaboration with the wider community, answers to many other questions, such as “How is our approach better compared to others?”, “Is the notion of skill sufficiently well defined?”, “Is the ordering structure of our curricula sufficiently rich?” and many others can be continually provided and refined.\nThe importance of a roadmap to general artificial intelligence\nOur roadmap to general AI is a collection of research milestones (cf. section \"Milestones\") that we deem essential for progress towards creating human-level intelligent machines. It is a separate, additional document and an essential entity32 to this framework. It can be seen 32 Marek Rosa, Martin Poliak, Jan Fey-\nereisl, Simon Andersson, Michal Vlasák, Martin Stránský, Orest Sota, and The GoodAI Collective. GoodAI Agent Development Roadmap - version 1.0. 2016. URL http://www.goodai.com/roadmap in Figure 5 in the Appendix. Currently, we partition our roadmap into two primary areas, containing three complementary parts: 1. Research and Development - how to get to general AI?\n• Architecture Roadmap - intrinsic skills and architecture design\n• Curriculum Roadmap - learned skills and gradual knowledge acquisition\n2. Future and Safety - what to expect next?\n• Safety/Futuristic Roadmap - how to keep humanity safe and the years leading up to and after general AI is reached\nFig. 2 puts these into context. It provides an overview of the entire roadmap to general AI.\nThe research and development roadmap (Architecture + Curriculum Roadmaps) are partially ordered lists of skills which our AI will need to be able to exhibit in order to achieve human-level intelligence. Ordering of skills is currently inspired by Piaget33, but other 33 John H Flavell, Patricia H Miller, and\nScott A Miller. Cognitive Development. 2002 hierarchies might also offer some additional insights34. Each skill or a 34 Timothy Z Keith and Matthew R Reynolds. Cattell-Horn-Carroll abilities and cognitive tests: What we’ve learned from 20 years of research. Psychology in the Schools, 47(7):635–650, 2010 set of skills represents a solution to a possibly open research problem. These problems can be distributed among different research groups, either internally at GoodAI, or amongst external researchers and collaborators.\nTo learn general skills, we can define what tasks the agent should be able to solve. Based on tasks that have not been solved yet, we can\n18 a framework for searching for general ai\nderive a research problem (what researchers should figure out). Solving this research problem results in at least one of the following:\n• a modified architecture which can solve the tasks (exhibits new intrinsic skill(s))\n• a modified architecture which can learn how to solve the tasks (exhibits new intrinsic and/or learned skill(s))\n• a modified curriculum, in which the system can learn to solve tasks (acquired new learned skill(s))\nNew skills very often depend and build upon previously acquired skills, so the research problems exhibit some intrinsic dependencies. We cannot simply skip to a skill in the middle of the roadmap and start acquiring it because this would go against the principle of reuse of previously learned skills. Such discontinuity might break the inherent dependency on previously learned skills. Instead, each skill is like a stepping stone to a subsequent skill. It is very important that an architecture that has the ability to solve problems (tasks in the roadmap) does not approach each problem in isolation [Pan and Yang, 2010]. On the contrary, the solution of a problem could ideally be directly based on the solutions of previous, simpler problems [Pan and Yang, 2010, Rusu et al., 2016], i.e. on previously learned skills Under such a graduality requirement, some problems that are \"solved\" in the traditional sense of the word (like chess or checkers) still remain open.\nthe importance of a roadmap to general artificial intelligence 19\nOur roadmap is a living document which will be updated as we work towards a set of milestones and evaluate them within this framework. The current version of this document is early-stage and a work in progress. We anticipate that more milestones and research directions will be entered into the roadmaps as our understanding matures, during agent learning, and ideally as a result of analyses produced by the proposed AI Roadmap Institute\nThere are still many parts missing, but we feel that it is better to engage with the community sooner rather than later [4]. The first version of the roadmap can be seen in the Appendix.\nMilestones\nOur research roadmap describes the stages of general AI development. In summary, there are five main stages of development that we will outline here for completeness. In each of the stages (shown in Table 1) we have an environment, a teacher, and an AI system. The environment and teacher work in tandem to teach the AI a set of useful, ideally general skills. In Table 1, each stage defines the end state of a milestone.\nGuidelines for working with the roadmap\nIn order to help guide the development of roadmaps and to provide concrete workflows for how we approached the creation of our roadmap, we will publish a detailed description of this process35. This 35 Simon Andersson, Martin Poliak, Mar-\ntin Stránský, and The GoodAI Collective. Building Curriculum Roadmaps for Artificial Agents - version 1.0. to be published, 2017 \"workflow\" document outlines a guideline for building curricula (sequences of problems) for the education of artificial agents. It also presents guidelines for building a system that learns to solve the problems in the curricula.\nOur motivating assumptions are that well-designed curricula can accelerate learning in agents as they do in humans. Furthermore, curriculum development, like software development, can benefit from being guided by a defined process. We expect that several guiding principles exist which are shared by all good implementations of incremental learning systems.\nWe believe that the following key questions are essential for building successful curricula:\n• How to come up with problems that will appear in the curriculum?\n20 a framework for searching for general ai\nthe importance of a roadmap to general artificial intelligence 21\n• How to determine the right time to present a problem in the curriculum?\n• How to decide that a problem is useful / not useful or is missing?\n• How to decide that two problems are similar / different?\n• How to correctly evaluate agent’s solution to a problem?\nThe “workflow” document contains four major sections focusing on answering the above questions and more.\n1. Creating problems/skills\n2. Creating curricula and using a curriculum roadmap\n3. Evaluating curricula\n4. Solving problems contained in the curricula\nFigure 3 highlights the importance of the creation of good curricula matched with the right architecture. We believe that efforts spent on both of these problems are equally important and go hand in hand. The workflow document provides some insight into this process in order to minimize the time and effort spent on converging to a humanlevel general AI system.\n22 a framework for searching for general ai\ntake to get there. This roadmap outlines challenges we expect to come across in our development and efforts to keep general AI safe, and how we will mitigate risks and difficulties we will face along the way.\nOur futuristic roadmap is a statement of openness and transparency from GoodAI, and aims to increase cooperation and build trust within the AI community by inspiring conversation and critical thought about human-level AI technology and the future of humankind. While our R&D roadmap is focused on the technical side of general AI development, this futuristic roadmap is focused on safety, society, the economy, freedom, the universe, ethics, people, and more.\nAI Roadmap Institute\nIn an attempt to provide a platform for better collaboration and understanding between AI researchers, we propose the creation of an independent AI Roadmap Institute. We are founding and starting this new initiative36 to collate and study various AI and general AI roadmaps 36 The GoodAI Collective. AI Roadmap\nInstitute. to be launched, [Accessed: 01- Nov-2016], 2016. URL http://www. goodai.com/ai-roadmap-institute proposed by those working in the field, map them into a common representation and therefore enable their comparison. The institute will use architecture-agnostic common terminology provided by this framework to compare the roadmaps, allowing research groups with different internal terminologies to communicate effectively.\nThe amount of research into AI has exploded over the last few years, with many new papers appearing daily. The Institute’s major output will be consolidating this research into a comprehensible visual summary which outlines the similarities and differences among roadmaps. It will identify where roadmaps branch and converge, show stages of roadmaps which need to be addressed by new research, and highlight examples of skills and testable milestones. This summary will be presented in a clear and comprehensible way to maximize its impact on as wide an audience as possible, minimizing the need for significant technical expertise, at least at its ’big picture’ level. It will be constantly updated and available for all who are interested. An overview of the Roadmap Institute, for illustrative purposes displayed using an example common representation based on our framework, can be seen in Figure 4 below.\nThese roadmaps will be described by the institute in an implementation agnostic manner. The roadmaps will show problems and any proposed solutions, and the implementations of others will be mapped out in a similar manner.\nThe institute is concerned with ’big picture’ thinking, without focusing on many of the local problems in the search for general AI. With a point of comparison among different roadmaps and with links to relevant research, the institute can highlight aspects of AI development where solutions exist or are needed. This means that other\nresearch groups can take inspiration from or suggest new milestones for the roadmaps.\nFinally, the institute is for the scientific community and everyone will be invited to contribute. It will phrase higher level concepts in an accessible and architecture-agnostic language, with more technical expressions made available to those who are interested.\nSchool for AI / Curriculum learning\nOur Roadmap to general AI is the basis for curricula that define the way in which our general AI system is to learn. The realization of such curricula is what our School for AI is for. Besides having hard-coded general intrinsic skills, we naturally expect the system to be able to learn. We will teach the AI new skills in a gradual and guided way using this School for AI which we are now developing.\nIn the School for AI, we first design an optimized set of learning tasks, or a \"curriculum\". The aim of the curriculum is to teach the AI system useful skills and abilities, so it does not have to discover them on its own. When the curriculum is ready, we subject the system to training. We evaluate its performance on learning tasks of the curriculum and use it to improve the curriculum itself as well as the set of learned and intrinsic skills.\nMain principles\nGradual learning means learning skills incrementally, where more complex skills are based on previously learned, possibly simpler, skills.\nGuided learning means that there is someone (a mentor or society) who has already discovered many skills for us, and we can learn these skills from them. Guided learning is extremely important, because without it, the AI would waste time exploring areas that evolution and society have already explored, or that we know are not useful or perhaps even dangerous.\nCurriculum requirements\nA good curriculum:\n1. Minimizes the time needed for getting the general AI into a desired target state. When the AI is in a target state, it can learn and evolve on its own;\n26 a framework for searching for general ai\n2. Is efficient - i.e. not more complex than necessary;\n3. Minimizes the number of skills that need to be hard-coded into the general AI.\nFinding the optimal curriculum for the AI is a multi-objective optimization problem. The better the curriculum, the faster the learning. However, it might not be possible to design a universally optimal curriculum (cf. the \"no free lunch theorem\"37), yet reaching for37 Cullen Schaffer. A conservation law for generalization performance. ICML, 1994\nhuman-level general AI might allow for avoiding this theoretical argument [Hernández-Orallo, 2016]. We are limited by the level of our current knowledge that we can transfer and by the eventual architecture of the general AI.\nHowever, we believe that a high-quality curriculum can optimize the learning process and allow for faster breakthroughs in AI over purely algorithmic advances.\nArtificial learning environment\nFor teaching the AI, we have created a simulated visual \"toy world\" with simplified physical laws that is grounded in simple language. We are designing our curriculum to teach the AI from the most basic rules of the world to the most complex ones, up to the point where it can start learning on its own.\nThe goal is not to teach the AI any arbitrary and specific facts about the world. On the contrary, it is to teach the AI useful and general skills for a more efficient understanding and exploration of the world, and for better and more general problem solving.\nDuring development of the School for AI, we encountered an interesting problem - how should we specify the tasks for the AI? When there little or no common language, it is very challenging and timeconsuming to explain what the AI needs to do. For this reason, we are also focusing on early language acquisition. To cut down on AI development time, we want to be able to efficiently communicate with it as soon as possible.\nGradual learning competition\nAs mentioned in Section , we believe that one of the most fundamental challenges in developing human-level intelligent machines is the creation of agents that have the ability to acquire and reuse skills and knowledge in a gradual manner. Unlike in an unconstrained setting, this problem continues to pose serious challenges under bounded resources38. To truly and quickly progress in this area, we propose the 38 Samuel J Gershman, Eric J Horvitz,\nand Joshua B Tenenbaum. Computational rationality: A converging paradigm for intelligence in brains, minds, and machines. Science, 349(6245): 273–278, 2015 injection of a monetary stimulus to the AI community in the form of a competition. We suggest launching the competition in two stages:\n1. Stage 1 - Identification of requirements, specifications and a set of evaluation tasks for gradual learning\n2. Stage 2 - Development and implementation of an agent that gradually learns and passes requirements defined in stage 1\nUpon completion, the winner will receive a significant monetary prize (millions of $), provided by us and potentially by other investors.\nDevelopment of theoretical foundations\nThere is nothing so practical as a good theory39. Having described our 39 Kurt Lewin understanding of intelligence, explained the importance of acquiring skills, and in particular learning in a gradual and guided manner, what are the theoretical foundations that underlie our ideas and proposed solutions?\nOur framework outlined in this document is in its first \"analytic\" stage according to Russell’s philosophical method [Klement, 2013]. It is very general and it neither adheres to one particular theory, nor subsumes it. This allows us to investigate and formalize our thoughts through the perspective of various differing theoretical approaches in its second \"constructive\" phase [Klement, 2013]. These include the following approaches which we are actively investigating:\n• Information Theory\n– Algorithmic Information Theory40\n40 Ming Li and Paul Vitanyi. An Introduction to Kolmogorov Complexity and Its Applications. 2013; Ray J Solomonoff. The discovery of algorithmic probability: A guide for the programming of true creativity. In EuroCOLT, pages 1– 22, 1995; and José Hernández-Orallo. Universal Psychometrics Tasks: difficulty, composition and decomposition. arXiv:1503.07587, 2015\n– Kolmogorov Complexity [Li and Vitanyi, 2013]\n– Minimum Description/Message Length41\n41 Jorma Rissanen. Modeling by shortest data description. Automatica, 14(5):465– 471, 1978; and Christopher S Wallace and David M Boulton. An Information Measure for Classification. Comput. J., 11(2): 185–194, 1968\n• Learning Theory\n– Vapnik-Chervonenkis Theory42\n42 Vladimir Vapnik. Statistical learning theory. 1998\n– Rademacher Complexity43\n43 Peter L Bartlett and Shahar Mendelson. Rademacher and Gaussian Complexities: Risk Bounds and Structural Results. In JMLR, volume 3, pages 463–482. Berlin, Heidelberg, 2002\n– Robust Generalization44 44 Rachel Cummings, Katrina Ligett, Aaron Roth, Kobbi Nissim, Aaron Roth, and Zhiwei Steven Wu. Adaptive Learning with Robust Generalization Guarantees. In COLT, pages 1–31, 2016 • Computational Mechanics and Statistical Physics\n– Structural complexity45 45 James P Crutchfield. Between order and chaos. Nat. Phys., 8(February):17–24, 2012 – e-machines and transducers46\n46 Nix Barnett, Barnett Nix, and James P Crutchfield. Computational Mechanics of Input-Output Processes: Structured Transformations and the epsilonTransducer. J. Stat. Phys., 161(2):404–451, 2015\n– Integrated Information47\n47 Giulio Tononi and Christof Koch. Consciousness: here, there and everywhere? Philos. Trans. R. Soc. Lond. B Biol. Sci., 370 (1668), 2015\nDespite fundamental links among many of the above approaches, formalizing our concepts, ideas and the framework as a whole through a\n30 a framework for searching for general ai\nvariety of theories allows us to examine and scrutinize our core concepts from different viewpoints. In this way, we hope to have a clearer picture of all the possibilities, as well as, limitations of our approaches.\nExamples of areas where we are beginning to observe benefits of such theoretical analyses:\n• Measures of gradual accumulation of skills\n• Task and curriculum complexity measures\n• Evaluating adaptive/growing architectures\nThis work is ongoing and will be continually added to this framework to provide solid theoretical foundations to much of the work that we undertake.\nRelated work\nAlthough there is a lack of unified perspectives on the building of general artificial intelligent machines, a number of works are important to mention here. Mikolov et al. proposed one of the more complete frameworks for building intelligent machines [Mikolov et al., 2015]. Their approach focuses on communication and learning in a simplified ’toy’ environment, similar to our School for AI, yet significantly more limited. Lake et al. [2016] on the other hand propose a more philosophical discussion of the limitations of current approaches. They argue that solving pattern recognition is not sufficient and that causal discovery is essential. Likewise, grounding models in the physical laws of the world and the exploitation of compositionality and learning-tolearn approaches are vital for rapid progress towards intelligent machines.\nIdeas about learning environments and curricula have been developed in a number of works. Bengio et al. [2009] initiated the BabyAI project and introduced curriculum learning: learning accelerated by presenting easy examples first and progressively increasing the difficulty. In the framework of Mikolov et al. [2015], learning in a simplified environment is also presented. In their work, however, the environment is defined by language only and no visual input is provided to the AI. An interesting discussion on the shortcomings of present AI systems and efforts at Facebook to build systems that learn for general AI is found in the work of Bordes et al.48. Project Malmo, an interac- 48 Antoine Bordes, Jason Weston, Sumit\nChopra, Tomas Mikolov, Armand Joulin, Sasha Rush, and Léon Bottou. Artificial Tasks for Artificial Intelligence. ICLR, 2015 tive 3D toy environment based on the game Minecraft is discussed in by Johnson et al. [2016]49. Thórisson et al. [2016] argue that a theory of\n49 Matthew Johnson, Katja Hofmann, Tim Hutton, and David Bignell. The Malmo Platform for Artificial Intelligence Experimentation. IJCAI, page 4246, 2016\nAI tasks can give us more rigorous ways of comparing and evaluating intelligent behavior. Stages of human cognitive development are described, for example, in Flavell et al. [2002]50. A thorough overview of\n50 John H Flavell, Patricia H Miller, and Scott A Miller. Cognitive Development. 2002\nevaluation environments, measures and challenges in AI is presented by Hernández-Orallo [2016].\nA number of developments in the field of AI and machine learning are of interest to our work. Due to the vast amount of exciting\n32 a framework for searching for general ai\nresearch conducted in this field in the last few years, only works that are particularly relevant are discussed.\nFor a brief overview of deep learning architectures, LeCun et al. [2015]51 provide a concise and high-level overview. For an in-depth51 Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436–444, 2015 analysis and reference of the field, the work of Schmidhuber [2015]52 52 Jürgen Schmidhuber. Deep learning in neural networks: an overview. Neural Netw., 61:85–117, 2015 is recommended. Of particular interest are growing architectures that learn new things while retaining existing knowledge. This area of research is closely related to our interest in gradual learning. Besides references provided throughout this framework, here we list additional related works. A systematic overview of a related field of ’transfer learning’ is provided by Pan and Yang [2010]. Schmidhuber [2013] presents a framework for automatically discovering problems inspired by playful behavior in animals and humans. Rusu et al. [2016]53 introduce progressive neural53 Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive Neural Networks. arXiv:1606.04671, 2016\nnetworks that adapt to new tasks by growing new columns. In earlier work, Fahlman and Lebiere [1990] demonstrated accelerated learning by adding one hidden neuron at the time, keeping the preceding hidden weights frozen. Similar additive learning capabilities are demonstrated for convolutional neural networks by Li and Hoiem [2016]54.54 Zhizhong Li and Derek Hoiem. Learning without Forgetting. arXiv:1606.09282, 2016\nNivel et al. [2013] prototype \"a machine that becomes increasingly better at behaving in under specified circumstances, in a goal-directed way, on the job, by modeling itself and its environment as experience accumulates\". Steunebrink et al. [2016] introduce Experience-based AI, a class of systems capable of continuous self-improvement. Architectures that can learn as much as possible of their structure from training data are also relevant for creating progressively growing agents. Zhou et al. [2012] introduce an algorithm for learning features incrementally and determining architecture complexity from data. In contrast, rather than using a simple heuristic, Cortes et al. [2016]55 propose a growing55 Corinna Cortes, Xavi Gonzalvo, Vitaly Kuznetsov, Mehryar Mohri, and Scott Yang. AdaNet: Adaptive Structural Learning of Artificial Neural Networks. arXiv:1607.01097, pages 1–18, 2016 neural network architecture algorithm exploiting theoretical bounds derived through a statistical learning complexity measure. Saxena and Verbeek [2016]56 propose a convolutional neural fabric that learns the 56 Shreyas Saxena and Jakob Verbeek. Convolutional Neural Fabrics. arXiv:1606.02492, 2016\nstructure of convolutional networks. Gradual learning in a toy environment and exploiting reinforcement learning can be found in the work of Oh et al. [2016].\nAnother important area is compositional learning, i.e. the ability to form knowledge about a particular subject by unifying knowledge about multiple other subjects that are already understood. Vincent et al. [2008]57 describe the use of denoising autoencoders to im57 Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. Extracting and composing robust features with denoising autoencoders. In ICML, pages 1096–1103, 2008\nprove the representational power of deep networks by composition. Andreas et al. [2016b] compose neural networks from component net-\nrelated work 33\nworks for a visual question answering task.\nLearning programs or algorithms are another form of compositional learning. Such methods allow an agent to represent and reuse procedural knowledge. Reed and de Freitas [2016] introduce neural programmer-interpreters able to compose hard-coded instructions into programs58. Similarly, Neelakantan et al. [2016] train an agent to per- 58 Scott Reed and Nando de Freitas. Neu-\nral Programmer-Interpreters. In ICLR, pages 1–13, 2016 form table lookups on data using a number of intrinsic operators59.\n59 Arvind Neelakantan, Quoc V. Le, and Ilya Sutskever. Neural Programmer: Inducing Latent Programs with Gradient Descent. ICLR, (2005):1–17, 2016\nKaiser and Sutskever [2015]’s neural GPU learns algorithms in a network that is wide rather than deep60; the parallelism makes for easier\n60 Łukasz Kaiser and Ilya Sutskever. Neural GPUs Learn Algorithms. arXiv:1511.08228, pages 1–9, 2015\ntraining and more efficient execution. Riedel et al. [2016] incorporates prior procedural knowledge as Forth program sketches with slots that can be filled with learned behavior61.\n61 Sebastian Riedel, Matko Bošnjak, and Tim Rocktäschel. Programming with a Differentiable Forth Interpreter. arXiv:1605.06640, 2016 Other works, not immediately relevant to the above topics but worth mentioning, are works that we believe are currently relevant to our progress towards general AI. Many works inspired by biology, namely neuroscience62, are of great interest. For example, spike-timing de- 62 Dharshan Kumaran, Demis Hassabis,\nand James L McClelland. What Learning Systems do Intelligent Agents Need? Complementary Learning Systems Theory Updated. Trends Cogn. Sci., 20(7): 512–534, 2016 pendent plasticity (STDP) is a biologically inspired approach with the potential to improve unsupervised learning63. Osogami and Otsuka\n63 Yoshua Bengio, Benjamin Scellier, Olexa Bilaniuk, Joao Sacramento, and Walter Senn. Feedforward Initialization for Fast Inference of Deep Generative Networks is biologically plausible. arXiv:1606.01651, pages 1–10, 2016; Benjamin Scellier and Yoshua Bengio. Towards a Biologically Plausible Backprop. arXiv:1602.05179, 2016; and Yoshua Bengio. Evolving Culture Versus Local Minima. In Growing Adaptive Machines, pages 109–138. 2014\n[2015] use it to learn temporal patterns with Boltzmann machines64.\n64 Takayuki Osogami and Makoto Otsuka. Learning dynamic Boltzmann machines with spike-timing dependent plasticity. arXiv:1509.08634, 2015\nIzhikevich [2007] addresses the problem of delayed reward in biological and artificial neural networks. George [2008] proposes a model of learning and recognition where temporal patterns are central. Wang [2003] provides an overview of approaches to the representation and processing of temporal patterns.\nCritical review\nThis section is an overview of some of the most relevant critiques of our framework, roadmap, ideas and approaches. This is an ongoing list, providing an active list of research problems that must be answered in order to support or refute our ideas and approach presented in this framework.\nOur own assessment of risks and disadvantages of our framework\n• Development Complexity - As highlighted in Figure 3, there is a trade-off between the complexity of an architecture and the amount of effort necessary for developing a successful curriculum. If we cannot find the optimal balance within this curriculum-architecture continuum, the approach could be exceedingly demanding on our side, for programmers, researchers as well as for the development of School for AI. Heavy supervision, non-sparse feedback or suboptimal biasing of the AI system, could result in decreasing efficiency of learning due to the infeasible demand on manpower required, for example, for supervision.\n• Development Bias - Gradual learning and objective-less search might result in biasing the architecture by what we teach it and in which order. If not incorporated sensibly, this could lead to sub-optimal solutions in cases when we could have learned a better skill directly. In our gradual learning example, we teach the child how to walk because we don’t know how to fly. But this does not mean that flying is impossible. On the contrary, flying could be a more efficient skill for the child, yet it might not discover such skill because it will simply walk every time.\nAssumptions\n• Skills in our roadmap, that remain \"open problems\", may be more difficult to distribute to the scientific community than we think. Traditionally, an open problem is defined as-is, standalone, without\n36 a framework for searching for general ai\ndependencies. In our case, however, we define as an open problem issues that may have been solved already, but not in a gradual and guided way. To find a solution (for an arbitrary problem in the roadmap) that works in a gradual and guided way, we might need to give to an external researcher our current AI implementation, so that improvements could be made in order to solve the open problem.\n• Similarly, solutions that will come from our research problems may not be easy to integrate by others. Unless a common representation for solutions exists, arbitrary solutions might be impossible to compare and combine.\n• The assumption of eventual removal of reward/feedback at later stages of the development of the AI system is currently lacking any form of guarantees that will ensure that the AI will continue its expected operation and not descend into chaos, or simply into a failure-mode, unable to solve any meaningful tasks. Intrinsically motivated methods for reinforcement learning investigate this problem to some degree65, but more insight is needed.65 Satinder Singh, Andrew G Barto, and Nuttapong Chentanez. Intrinsically motivated reinforcement learning. NIPS, 17 (2):1281–1288, 2004 Problems\n• Gradual learning is a very difficult problem that shares many of the same issues that exist in transfer, lifelong and incremental learning66. Among others, these include problems related to the transfer66 Sinno J Pan and Qiang Yang. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng., 22(10):1345–1359, 2010; Junhyuk Oh, Valliappa Chockalingam, Satinder Singh, and Honglak Lee. Control of Memory, Active Perception, and Action in Minecraft. arXiv:1605.09128, 2016; and Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive Neural Networks. arXiv:1606.04671, 2016 of existing knowledge within models as well as in between parts, namely, what, when and how to transfer both learned and potential knowledge in a practically feasible manner. Limitations\n• Without working theoretical formalizations of our framework, it might be difficult to obtain various necessary quantitative measures, such as task complexity measures, determination of optimal gradual skill acquisition, evaluation criteria and others.\n• Interplay between agent and curriculum development - there are many questions and issues that should be addressed:\n– Autonomous exploration - What if differently structured agents discover features of the world / skills in different order?\n– Impact of modifying a curriculum as we learn more about how the agent learns\ncritical review 37\n– Avoiding the \"incestuous circle\" if we modify the curriculum. Will multiple agent development streams help here?\n– Strive for a single optimal curricula, or multiple satisfactory ones?\nPerformance\n• There are some potential drawbacks of gradual learning from the computational efficiency point of view. For example, the fact that we do not know the size of an architecture a-priori limits us in the ability to efficiently optimize and exploit such a predefined space. This could also result in inefficient \"growing\" of an architecture that is unable to reuse parts of already learned knowledge that is not rooted in a suitable part of the solution space.\nGenerality\n• By imposing the necessity to acquire any skills that reduce the search space of solutions, we are inherently biasing our AI. This is beneficial when such bias has positive impact, for example in terms of data efficiency, i.e. faster learning / convergence. However, other undesirable biases might be introduced into the system. These could affect the development of our AI further down the line. This is another tradeoff that might be impossible to avoid completely, thus better control over which biases are introduced is desirable.\n• There is a tradeoff between the amount and types of intrinsic skills (and therefore speed of initial learning) and universality of the resulting architecture.\n• This framework and the associated roadmaps are our way of approaching the challenge of tackling development of general AI. Our thoughts and ideas might not be compatible enough with the ideas of others. In this case cooperation and collaboration may be limited, unless we adapt and adjust to some degree, based on feedback from the community.\nNext steps\nIn this section we suggest a number of near-term plans for general AI development that we deem important and will undertake next. These might not be the optimal set of next steps, however, they are a starting point from which we can build upon. We believe these should include:\n1. Framework and R&D Roadmap\n(a) More research groups, institutes and companies should publish their own frameworks and R&D roadmaps, in the spirit of what we propose in our framework, to encourage innovation, openness and progress\n(b) Framework:\n(i) Should be continually updated and refined\n(ii) Act as an internal as well as external research trace\n(iii) Increasingly provide multiple theoretical viewpoints on underlying ideas\n(c) Roadmap:\n(i) Additional skills should be continually added to cover yet unmapped areas\n(ii) Task theory should be developed to provide foundations for curricula, including evaluation\n2. Architecture Groups\n(a) Collaborate with researchers in Curriculum Groups\n(b) Successfully implement architectures that support \"gradual accumulation of skills\"\n(c) Test promising architectures on a subset of learning tasks specified in R&D roadmap\n3. Curriculum Groups\n(a) More learning tasks should be continually added (training and testing)\n40 a framework for searching for general ai\n4. AI Roadmap Institute (Q1 2017)\n(a) Publish first version of comparison of roadmaps\n(b) Start collaborative process of adding more roadmaps to the comparison\n(c) Raise awareness about AI roadmapping and ’big picture’ thinking in AI6767 Marek Rosa and Jan Feyereisl. Consolidating the search for general AI. In NIPS Workshop on Machine Intelligence, 2016 5. Open problems specified in our (or AI Roadmap Institute) roadmap\n(a) Outsource implementation / solutions\n6. Gradual learning competition (Launching Q1-Q2 2017)\nContributions\nThere is a significant lack of unified approaches to building generalpurpose intelligent machines. Comparable to the natural sciences68, 68 Heidi Ledford. How to solve the\nworld’s biggest problems. Nature, pages 1–12, 2015 most researchers, universities and institutes still operate within a very narrow field of focus69, frequently without consideration for the ’big 69 Alan L Porter and Ismael Rafols. Is sci-\nence becoming more interdisciplinary? Measuring and mapping six research fields over time. Scientometrics, 81(3): 719–745, 2009 picture’. We believe that our approach is one possible way of stepping out\nof this cycle and provide a fresh, unified perspective on building machines that learn to think. We hope to achieve this in a number of ways, each of which are equally relevant and essential for tackling different aspects of the building process:\n• Our framework provides a unified collection of principles, ideas, definitions and formalizations of our thoughts on the process of developing general AI. This allows us to consolidate all that we believe is important to define as a basis on which we and possibly others can build. This is an ongoing and open process and feedback from the community will be invaluable for further refinement and standardization. Ultimately, it could act as a common language that everyone can understand, and provide a starting point for a platform for further discussion and evolution of ideas relevant for building general AI.\n• Our roadmap is a principled approach to clearly outlining and defining a step-by-step guide for obtaining all skills that a human level intelligent machine will eventually need to possess. This includes their definitions, as well as the gradual order and way in which to achieve them through curricula of our ’School for AI’.\n• Our School for AI provides learning curricula - a principled, gradual and guided way of teaching a machine. This approach differs significantly from current approaches of narrowly focused, fixed datasets. We believe that gradual and guided learning are essential parts of data-efficient learning that are paramount to quick convergence towards a level of intelligence that is above current standards.\n• To compare and contrast existing approaches and roadmaps and\n42 a framework for searching for general ai\nfoster more effective distillation of knowledge about the process of building intelligent machines, our AI Roadmap Institute is a step towards an impartial research organization advancing the search for an optimal protocol for achieving general artificial intelligence.\n• To tackle one of the most fundamental challenges in developing human-level intelligent machines, we propose the creation of a gradual learning competition. We believe, this monetary-driven stimulus could provide a further boost for the community to push the limits of our understanding of this challenging topic.\nUsing a language that is consonant with our principles, the above are simply a set of skills for steering our search for general AI that we believe are important and will help us achieve significantly faster convergence towards developing truly intelligent machines.\nAPPENDIX\nProposed team structure\nOur ideal team is organized into five smaller working groups: Research Group, School Group, Software Engineers, Roadmapping Group and AI Safety team.\n• The research group’s focus is on the implementation of solutions to research topics, mostly focusing on growing topologies, modular networks, and the reuse of skills. Intrinsic skills are developed and implemented as part of this group.\n• The school group studies the skills that an AI needs to learn, and designs learning tasks for efficient education. The group also works on the R&D roadmap, mapping various curricula. This team will teach the AI learned skills.\n• The software engineers are responsible for the entire software infrastructure for both research and development. They handle developing novel frameworks and libraries as necessary and as required by other teams, supporting significant novel forms of computation and problem handling.\n• The internal roadmapping group studies various roadmaps developed internally as well as by the wider community. It has a general oversight of the landscape of the entire field of developing general AI and of the overall internal research process. It investigates and maps methods for combining and comparing new progress in the field.\n• The AI Safety team studies the safe path forward with our technology, and the mitigation of threats to our team and humankind as a whole. This team is creating an alliance of AI researchers committed to the safe development of AI and general AI, our futuristic roadmap, and more.\nDespite the need for close-knit collaboration among these groups, some research problems and developmental stages can be outsourced\n44 a framework for searching for general ai\nor distributed among a number of collaborators. Both the School and Safety groups are perfect examples of groups that can be extended to included external collaborators, research groups and institutions, and from which collaboration could foster stronger results.\nInformal Definitions\nTable A1 Definition\nFramework A unified collection of principles, ideas, definitions and formalizations that are believed essential for developing human-level general Artificial Intelligence\nThis document is an example of a framework. It is our attempt at unifying all the concepts, definitions and processes that we believe are necessary for the successful development of an intelligent machine.\nRoadmap A principled approach for defining and outlining a step-by-step guide for obtaining all skills that a human-level general AI will need to possess\nA roadmap defines a partially ordered list of tasks that allow for an agent to learn or acquire, in a gradual and guided way, skills that are related and of increasingly higher complexity. Some are already solved problems in the AI community, while others are open problems. One example is our R&D roadmap [62].\nAI Roadmap Institute A platform for mutual understanding and collaboration within the AI landscape\nAn initiative to collate and study the field of AI from a holistic perspective, mapping progress into common representations and allowing for easier overview (ideally visual), comparison and improved efficiency and progress in development of AI, fostering collaboration throughout.\nSchool for AI Our realization and a grounding of curricula defined in a roadmap\nAn optimized set of learning tasks, termed \"curriculum\" according to which an agent can learn useful skills in a gradual and guided way. Feedback from agent allows continual refinement of curriculum and allows for the search for an optimal trade-off between architectural and curriculum complexity.\nappendix 45\nTable A2 Definition\nIntelligence A problem-solving tool in complex, dynamic and uncertain environments\nAssuming that all problems can be posed as search and optimization problems, the goal of intelligence is to find the best available solution, given time and resource constraints. This usually requires narrowing the search space by the use of suitable skills.\nArtificial Intelligence A program that is able to learn, adapt, be creative and solve problems\n(system) Universal term encompassing both “narrow” (weak) and “general” (strong) AI, their difference being in the universality of the underlying technology. Narrow AI - able to solve only very limited set of specific problems General AI - aims for a human-level ability to solve problems\nHuman-Level (AI) System performing at least at the same level as most humans\nAn ability of a machine to solve as many of the same tasks to at least the same level of accuracy as most humans [Rajani, 2011].\nSkill A mechanism for narrowing down solution search space\nA skill is any mechanism that helps in the quest for solving a problem. From the point of view of mathematical optimization, it can be thought of as any assumption, approximation or a heuristic that reduces or simplifies the search space of all possible solutions to a given problem.\nIntrinsic Skill A hard-coded ability that solves a general class of problems\nUnlike learned skills, intrinsic skills are explicitly coded into an AI system by its creator. This allows for a repertoire of minimal skill set that is necessary for the AI to progress and develop further through gradual learning.\nLearned Skill An ability learned from experience (from data)\nSkills that are learned through the experience of solving tasks. The process of solving a task enables an AI system to learn the necessary mappings between the input (domain of the problem) and the output (solution of the task).\nLearning Task A problem whose solution enables or helps verify the acquisition of a skill(s)\nIn a curriculum, each skill is assumed to be attainable and testable through the successful solution of an associated learning task. e.g. Skill - anomaly detection Task - detection of a structure not conforming to the expected one\nCurriculum A partially ordered list of learning milestones (skills and tasks)\nA learning curriculum comprises of a partially ordered list of skills that an AI needs to acquire. Measuring the quality of a solution of tasks associated with a skill in a curriculum allows for one type of evaluation of the level of intelligence an AI system has acquired.\nGradual Learning Progressive learning of skills. Complex skills exploiting learned knowledge.\n(Curriculum Learning) Learning of skills one by one, where complex skills are based on previously learned skills. Learning curricula offer partially ordered lists of skills that are to be acquired in the predefined order. This order is due to the skill’s increasing complexity and interdependence.\nGuided Learning Directed acquisition of knowledge by an intelligent entity\nGuided learning, akin to shaping in childhood development, allows for direct control of the direction in which an AI system will gradually develop. Guidance allows for speeding up of the development of an AI system due to intrinsic transfer of knowledge that is present in instructions passed from a teacher to the AI system through guidance instructions.\n46 a framework for searching for general ai\nBibliography\nSam Adams, Itmar Arel, Joscha Bach, Robert Coop, Rod Furlan, Ben Goertzel, J Storrs Hall, Alexei Samsonovich, Matthias Scheutz, Matthew Schlesinger, Stuart C Shapiro, and John Sowa. Mapping the Landscape of Human-Level Artificial General Intelligence. AI Magazine, 33(1):25–42, 2012.\nWilliam H Alexander and Joshua W Brown. Hierarchical Error Representation: A Computational Model of Anterior Cingulate and Dorsolateral Prefrontal Cortex. Neural Computation, 27(11):2354–2410, 2015.\nDario Amodei, Rishita Anubhai, Eric Battenberg, Case Carl, Jared Casper, Bryan Catanzaro, Jingdong Chen, Mike Chrzanowski, Adam Coates, Greg Diamos, Erich Elsen, Jesse Engel, Linxi Fan, Christopher Fougner, Tony Han, Awni Hannun, Billy Jun, Patrick LeGresley, Libby Lin, Sharan Narang, Andrew Ng, Sherjil Ozair, Ryan Prenger, Jonathan Raiman, Sanjeev Satheesh, David Seetapun, Shubho Sengupta, Yi Wang, Zhiqian Wang, Chong Wang, Bo Xiao, Dani Yogatama, Jun Zhan, and Zhenyao Zhu. Deep-speech 2: Endto-end speech recognition in English and Mandarin. In JMLR W&CP, volume 48, page 28, 2015.\nSimon Andersson, Martin Poliak, Martin Stránský, and The GoodAI Collective. Building Curriculum Roadmaps for Artificial Agents - version 1.0. to be published, 2017.\nJacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Neural Module Networks. CVPR, pages 39–48, 2016a.\nJacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Learning to Compose Neural Networks for Question Answering. arXiv:1601.01705, 2016b.\nHossein Azizpour, Ali Sharif Razavian, Josephine Sullivan, Atsuto Maki, and Stefan Carlsson. From Generic to Specific Deep Representations for Visual Recognition. CVPR DeepVision Workshop, 2015.\n48 a framework for searching for general ai\nNix Barnett, Barnett Nix, and James P Crutchfield. Computational Mechanics of Input-Output Processes: Structured Transformations and the epsilon-Transducer. J. Stat. Phys., 161(2):404–451, 2015.\nPeter L Bartlett and Shahar Mendelson. Rademacher and Gaussian Complexities: Risk Bounds and Structural Results. In JMLR, volume 3, pages 463–482. Berlin, Heidelberg, 2002.\nYoshua Bengio. Evolving Culture Versus Local Minima. In Growing Adaptive Machines, pages 109–138. 2014.\nYoshua Bengio, Jerome Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In ICML, pages 41–48, 2009.\nYoshua Bengio, Benjamin Scellier, Olexa Bilaniuk, Joao Sacramento, and Walter Senn. Feedforward Initialization for Fast Inference of Deep Generative Networks is biologically plausible. arXiv:1606.01651, pages 1–10, 2016.\nAnselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K Warmuth. Occam’s razor. Readings in machine learning, pages 201– 204, 1990.\nAntoine Bordes, Jason Weston, Sumit Chopra, Tomas Mikolov, Armand Joulin, Sasha Rush, and Léon Bottou. Artificial Tasks for Artificial Intelligence. ICLR, 2015.\nTim Brys, Anna Harutyunyan, Halit Bener Suay, Sonia Chernova, Matthew E Taylor, and Ann Nowe. Reinforcement learning from demonstration through shaping. IJCAI, page 26, 2015.\nTianqi Chen, Ian Goodfellow, and Jonathon Shlens. Net2Net: Accelerating Learning via Knowledge Transfer. arXiv:1511.05641, pages 1–10, 2015.\nCorinna Cortes, Xavi Gonzalvo, Vitaly Kuznetsov, Mehryar Mohri, and Scott Yang. AdaNet: Adaptive Structural Learning of Artificial Neural Networks. arXiv:1607.01097, pages 1–18, 2016.\nJames P Crutchfield. Between order and chaos. Nat. Phys., 8(February): 17–24, 2012.\nRachel Cummings, Katrina Ligett, Aaron Roth, Kobbi Nissim, Aaron Roth, and Zhiwei Steven Wu. Adaptive Learning with Robust Generalization Guarantees. In COLT, pages 1–31, 2016.\nCharles Darwin. On the origin of species by means of natural selection, or the preservation of favoured races in the struggle for life. London: John Murray, 1859.\nbibliography 49\nScott E Fahlman and Christian Lebiere. The Cascade-Correlation Learning Architecture. In NIPS, pages 524–532, 1990.\nJohn H Flavell, Patricia H Miller, and Scott A Miller. Cognitive Development. 2002.\nThushan Ganegedara, Lionel Ott, and Fabio Ramos. Online Adaptation of Deep Architectures with Reinforcement Learning. arXiv:1608.02292, 2016.\nDileep George. How the Brain Might Work: a Hierarchical and Temporal Model for Learning and Recognition. Learning, page 191, 2008.\nSamuel J Gershman, Eric J Horvitz, and Joshua B Tenenbaum. Computational rationality: A converging paradigm for intelligence in brains, minds, and machines. Science, 349(6245):273–278, 2015.\nBen Goertzel and Cassio Pennachin. Artificial General Intelligence. 2007.\nCaglar Gulcehre and Yoshua Bengio. Knowledge Matters: Importance of Prior Information for Optimization. JMLR, 17(8):1–32, 2016.\nCaglar Gulcehre, Marcin Moczulski, Francesco Visin, and Yoshua Bengio. Mollifying Networks. arXiv:1608.04980, pages 1–11, 2016.\nJosé Hernández-Orallo. Universal Psychometrics Tasks: difficulty, composition and decomposition. arXiv:1503.07587, 2015.\nJosé Hernández-Orallo. Evaluation in artificial intelligence: from taskoriented to ability-oriented measurement. Artificial Intelligence Review, pages 1–51, 2016.\nJosé Hernández-Orallo. The measure of all minds : evaluating natural and artificial intelligence. Cambridge University Press, 2017.\nJosé Hernández-Orallo and Neus Minaya-Collado. A formal definition of intelligence based on an intensional variant of kolmogorov complexity. In Proceedings of International Symposium of Engineering of Intelligent Systems (EIS ’98), pages 146–163, 1998.\nMarcus Hutter. Universal Artificial Intelligence: Sequential Decisions based on Algorithmic Probability. 2005.\nEugene M. Izhikevich. Solving the distal reward problem through linkage of STDP and dopamine signaling. Cerebral Cortex, 17(10): 2443–2452, 2007.\nMatthew Johnson, Katja Hofmann, Tim Hutton, and David Bignell. The Malmo Platform for Artificial Intelligence Experimentation. IJCAI, page 4246, 2016.\n50 a framework for searching for general ai\nŁukasz Kaiser and Ilya Sutskever. Neural GPUs Learn Algorithms. arXiv:1511.08228, pages 1–9, 2015.\nEric R. Kandel and James H. Schwartz. Principles of neural science. 2012.\nTimothy Z Keith and Matthew R Reynolds. Cattell-Horn-Carroll abilities and cognitive tests: What we’ve learned from 20 years of research. Psychology in the Schools, 47(7):635–650, 2010.\nKevin Klement. Russell’s Logical Atomism, 2013. URL http://plato. stanford.edu/archives/spr2016/entries/logical-atomism/.\nKai A. Krueger and Peter Dayan. Flexible shaping: How learning in small steps helps. Cognition, 110(3):380–394, 2009.\nDharshan Kumaran, Demis Hassabis, and James L McClelland. What Learning Systems do Intelligent Agents Need? Complementary Learning Systems Theory Updated. Trends Cogn. Sci., 20(7):512–534, 2016.\nBrenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building Machines that learn and think like people. arXiv:1604.00289, pages 1–55, 2016.\nYann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436–444, 2015.\nHeidi Ledford. How to solve the world’s biggest problems. Nature, pages 1–12, 2015.\nShane Legg and Marcus Hutter. Universal intelligence: A definition of machine intelligence. Minds and Machines, 17(4):391–444, 2007a.\nShane Legg and Marcus Hutter. A Collection of Definitions of Intelligence. In Proceedings of AGI 2006: Workshop on Concepts, Architectures and Algorithms, pages 17–24, Amsterdam, The Netherlands, The Netherlands, 2007b.\nDouglas B Lenat and Edward A Feigenbaum. On the Thresholds of Knowledge. Artif. Intell., 47(1-3):185–250, 1991.\nMing Li and Paul Vitanyi. An Introduction to Kolmogorov Complexity and Its Applications. 2013.\nZhizhong Li and Derek Hoiem. Learning without Forgetting. arXiv:1606.09282, 2016.\nJames Macglashan, Robert Loftin, Michael L Littman, David L Roberts, and Matthew E Taylor. A Need for Speed : Adapting Agent Action\nbibliography 51\nSpeed to Improve Task Learning from Non-Expert Humans Categories and Subject Descriptors. In AMAS ’16, pages 957–965, Richland, SC, 2016.\nMarlos C. Machado and Michael Bowling. Learning Purposeful Behaviour in the Absence of Rewards. arXiv:1605.07700, 2016.\nAdam H Marblestone, Greg Wayne, and Konrad P Kording. Towards an integration of deep learning and neuroscience. arXiv:1606.03813, pages 1–61, 2016.\nJohn McCarthy. Generality in Artificial Intelligence. Commun. ACM, 30(12):1030–1035, 1987.\nJohn McCarthy and Patrick J Hayes. Some philosophical problems from the standpoint of artificial intelligence. Readings in Artificial Intelligence, 1969.\nHrushikesh Mhaskar and Tomaso Poggio. Deep vs. shallow networks : An approximation theory perspective. (054):1–16, 2016.\nHrushikesh Mhaskar, Qianli Liao, and Tomaso Poggio. Learning Functions: When Is Deep Better Than Shallow. arXiv:1603.00988, (45): 1–12, 2016.\nTomas Mikolov, Armand Joulin, and Marco Baroni. A Roadmap towards Machine Intelligence. arXiv:1511.08130, pages 1–39, 2015.\nMarvin Minsky. Steps toward Artificial Intelligence. Proceedings of the IRE, 49(1):8–30, 1961.\nMarvin Minsky. The Society of Mind. 1986.\nShakir Mohamed and Danilo Jimenez Rezende. Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning. In NIPS, pages 2125–2133, 2015.\nArvind Neelakantan, Quoc V. Le, and Ilya Sutskever. Neural Programmer: Inducing Latent Programs with Gradient Descent. ICLR, (2005): 1–17, 2016.\nNorman S. Nise. Control Systems Engineering. 2015.\nEric Nivel, Kristinn R Thórisson, Bas R Steunebrink, Haris Dindo, Giovanni Pezzulo, Manuel Rodríguez, Carlos Hernández, Dimitri Ognibene, Jürgen Schmidhuber, Ricardo Sanz, Helgi P Helgason, Antonio Chella, and Gudberg K Jonsson. Bounded Recursive SelfImprovement. arXiv:1312.6764, 2013.\n52 a framework for searching for general ai\nJunhyuk Oh, Valliappa Chockalingam, Satinder Singh, and Honglak Lee. Control of Memory, Active Perception, and Action in Minecraft. arXiv:1605.09128, 2016.\nMaxime Oquab, Léon Bottou, Ivan Laptev, and Josef Sivic. Learning and transferring mid-level image representations using convolutional neural networks. CVPR, 2014.\nTakayuki Osogami and Makoto Otsuka. Learning dynamic Boltzmann machines with spike-timing dependent plasticity. arXiv:1509.08634, 2015.\nSinno J Pan and Qiang Yang. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng., 22(10):1345–1359, 2010.\nTomaso Poggio, Fabio Anselmi, and Lorenzo Rosasco. I-theory on depth vs width: hierarchical function composition. (041), 2015.\nGeorge Pólya. How to solve it: a new aspect of mathematical method. 2004.\nAlan L Porter and Ismael Rafols. Is science becoming more interdisciplinary? Measuring and mapping six research fields over time. Scientometrics, 81(3):719–745, 2009.\nSandeep Rajani. Artificial Intelligence - Man or Machine. International Journal of Information Technology and Knowledge Management, 4(1):173 – 176, 2011.\nScott Reed and Nando de Freitas. Neural Programmer-Interpreters. In ICLR, pages 1–13, 2016.\nSebastian Riedel, Matko Bošnjak, and Tim Rocktäschel. Programming with a Differentiable Forth Interpreter. arXiv:1605.06640, 2016.\nJorma Rissanen. Modeling by shortest data description. Automatica, 14 (5):465–471, 1978.\nMarek Rosa and Jan Feyereisl. Consolidating the search for general AI. In NIPS Workshop on Machine Intelligence, 2016.\nMarek Rosa, Martin Poliak, Jan Feyereisl, Simon Andersson, Michal Vlasák, Martin Stránský, Orest Sota, and The GoodAI Collective. GoodAI Agent Development Roadmap - version 1.0. 2016. URL http://www.goodai.com/roadmap.\nAndrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive Neural Networks. arXiv:1606.04671, 2016.\nbibliography 53\nRuslan Salakhutdinov, Joshua B Tenenbaum, and Antonio Torralba. Learning with Hierarchical-Deep Models. IEEE Trans. Pattern Anal. Mach. Intell., (8):1958–1971, 2013.\nVirginia Savova and Leonid Peshkin. Is the turing test good enough? The fallacy of resource-unbounded intelligence. IJCAI, pages 545– 550, 2007.\nShreyas Saxena and Jakob Verbeek. Convolutional Neural Fabrics. arXiv:1606.02492, 2016.\nBenjamin Scellier and Yoshua Bengio. Towards a Biologically Plausible Backprop. arXiv:1602.05179, 2016.\nCullen Schaffer. A conservation law for generalization performance. ICML, 1994.\nJürgen Schmidhuber. PowerPlay: Training an Increasingly General Problem Solver by Continually Searching for the Simplest Still Unsolvable Problem. Front. Psychol., 4:313, 2013.\nJürgen Schmidhuber. Deep learning in neural networks: an overview. Neural Netw., 61:85–117, 2015.\nAli Sharif, Razavian Hossein, Azizpour Josephine, Sullivan Stefan, and K T H Royal. CNN Features off-the-shelf: an Astounding Baseline for Recognition. CVPRW, 2014.\nStuart M. Shieber. Does the Turing Test Demonstrate Intelligence or Not? AAAI, pages 1539–1542, 2006.\nSatinder Singh, Andrew G Barto, and Nuttapong Chentanez. Intrinsically motivated reinforcement learning. NIPS, 17(2):1281–1288, 2004.\nRay J Solomonoff. The discovery of algorithmic probability: A guide for the programming of true creativity. In EuroCOLT, pages 1–22, 1995.\nKenneth O Stanley and Risto Miikkulainen. Evolving neural networks through augmenting topologies. Evol. Comput., 10(2):99–127, 2002.\nBas R Steunebrink, Kristinn R Thórisson, and Jürgen Schmidhuber. Growing Recursive Self-Improvers. In AGI, pages 129–139, 2016.\nJessica Taylor. Quantilizers: A Safer Alternative to Maximizers for Limited Optimization. In AAAI Workshop, 2016.\nThe GoodAI Collective. AI Roadmap Institute. to be launched, [Accessed: 01-Nov-2016], 2016. URL http://www.goodai.com/ ai-roadmap-institute.\n54 a framework for searching for general ai\nAndrea L Thomaz and Cynthia Breazeal. Reinforcement learning with human teachers: Evidence of feedback and guidance with implications for learning performance. AAAI, 6:1000–1005, 2006.\nKristinn R Thórisson, Jordi Bieger, Thröstur Thorarensen, Jóna S Siguroardóttir, and Bas R Steunebrink. Why Artificial Intelligence Needs a Task Theory — And What It Might Look Like. arXiv:1604.04660, 2016.\nKoji Toda and Michael L Platt. Animal cognition: Monkeys pass the mirror test. Current Biology, 25(2):R64–R66, 2015.\nGiulio Tononi and Christof Koch. Consciousness: here, there and everywhere? Philos. Trans. R. Soc. Lond. B Biol. Sci., 370(1668), 2015.\nVladimir Vapnik. Statistical learning theory. 1998.\nVladimir Vapnik. Learning Using Privileged Information : Similarity Control and Knowledge Transfer. JMLR, 16:2023–2049, 2015.\nPascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. Extracting and composing robust features with denoising autoencoders. In ICML, pages 1096–1103, 2008.\nChristopher S Wallace and David M Boulton. An Information Measure for Classification. Comput. J., 11(2):185–194, 1968.\nDeLiang Wang. Temporal Pattern Processing. The Handbook of Brain Theory and Neural Networks, 1163:1163–1167, 2003.\nWojciech Zaremba and Ilya Sutskever. Learning to Execute. ICLR, pages 1–25, 2014.\nWojciech Zaremba and Ilya Sutskever. Reinforcement Learning Neural Turing Machines. arXiv:1505.00521, pages 1–14, 2015.\nDingwen Zhang, Deyu Meng, and Junwei Han. Co-saliency Detection via A Self-paced Multiple-instance Learning Framework. IEEE Trans. Pattern Anal. Mach. Intell., 2016.\nGuanyu Zhou, Kihyuk Sohn, and Honglak Lee. Online Incremental Feature Learning with Denoising Autoencoders. JMLR W&CP, 22: 1453–1461, 2012."
    } ],
    "references" : [ {
      "title" : "Mapping the Landscape of Human-Level",
      "author" : [ "Sam Adams", "Itmar Arel", "Joscha Bach", "Robert Coop", "Rod Furlan", "Ben Goertzel", "J Storrs Hall", "Alexei Samsonovich", "Matthias Scheutz", "Matthew Schlesinger", "Stuart C Shapiro", "John Sowa" ],
      "venue" : "Artificial General Intelligence. AI Magazine,",
      "citeRegEx" : "Adams et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Adams et al\\.",
      "year" : 2012
    }, {
      "title" : "Hierarchical Error Representation: A Computational Model of Anterior Cingulate and Dorsolateral Prefrontal Cortex",
      "author" : [ "William H Alexander", "Joshua W Brown" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Alexander and Brown.,? \\Q2015\\E",
      "shortCiteRegEx" : "Alexander and Brown.",
      "year" : 2015
    }, {
      "title" : "Deep-speech 2: Endto-end speech recognition in English and Mandarin",
      "author" : [ "Prenger", "Jonathan Raiman", "Sanjeev Satheesh", "David Seetapun", "Shubho Sengupta", "Yi Wang", "Zhiqian Wang", "Chong Wang", "Bo Xiao", "Dani Yogatama", "Jun Zhan", "Zhenyao Zhu" ],
      "venue" : "In JMLR W&CP,",
      "citeRegEx" : "Prenger et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Prenger et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning to Compose Neural Networks for Question Answering",
      "author" : [ "Jacob Andreas", "Marcus Rohrbach", "Trevor Darrell", "Dan Klein" ],
      "venue" : null,
      "citeRegEx" : "Andreas et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Andreas et al\\.",
      "year" : 2016
    }, {
      "title" : "From Generic to Specific Deep Representations for Visual Recognition",
      "author" : [ "Hossein Azizpour", "Ali Sharif Razavian", "Josephine Sullivan", "Atsuto Maki", "Stefan Carlsson" ],
      "venue" : "CVPR DeepVision Workshop,",
      "citeRegEx" : "Azizpour et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Azizpour et al\\.",
      "year" : 2015
    }, {
      "title" : "Computational Mechanics of Input-Output Processes: Structured Transformations and the epsilon-Transducer",
      "author" : [ "Nix Barnett", "Barnett Nix", "James P Crutchfield" ],
      "venue" : "J. Stat. Phys.,",
      "citeRegEx" : "Barnett et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Barnett et al\\.",
      "year" : 2015
    }, {
      "title" : "Rademacher and Gaussian Complexities: Risk Bounds and Structural Results",
      "author" : [ "Peter L Bartlett", "Shahar Mendelson" ],
      "venue" : "In JMLR,",
      "citeRegEx" : "Bartlett and Mendelson.,? \\Q2002\\E",
      "shortCiteRegEx" : "Bartlett and Mendelson.",
      "year" : 2002
    }, {
      "title" : "Evolving Culture Versus Local Minima",
      "author" : [ "Yoshua Bengio" ],
      "venue" : "In Growing Adaptive Machines,",
      "citeRegEx" : "Bengio.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bengio.",
      "year" : 2014
    }, {
      "title" : "Curriculum learning",
      "author" : [ "Yoshua Bengio", "Jerome Louradour", "Ronan Collobert", "Jason Weston" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Bengio et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2009
    }, {
      "title" : "Feedforward Initialization for Fast Inference of Deep Generative Networks is biologically",
      "author" : [ "Yoshua Bengio", "Benjamin Scellier", "Olexa Bilaniuk", "Joao Sacramento", "Walter Senn" ],
      "venue" : "plausible. arXiv:1606.01651,",
      "citeRegEx" : "Bengio et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2016
    }, {
      "title" : "Reinforcement learning from demonstration through shaping",
      "author" : [ "Tim Brys", "Anna Harutyunyan", "Halit Bener Suay", "Sonia Chernova", "Matthew E Taylor", "Ann Nowe" ],
      "venue" : null,
      "citeRegEx" : "Brys et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Brys et al\\.",
      "year" : 2015
    }, {
      "title" : "Net2Net: Accelerating Learning via Knowledge Transfer",
      "author" : [ "Tianqi Chen", "Ian Goodfellow", "Jonathon Shlens" ],
      "venue" : null,
      "citeRegEx" : "Chen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2015
    }, {
      "title" : "Between order and chaos",
      "author" : [ "James P Crutchfield" ],
      "venue" : "Nat. Phys., 8(February):",
      "citeRegEx" : "Crutchfield.,? \\Q2012\\E",
      "shortCiteRegEx" : "Crutchfield.",
      "year" : 2012
    }, {
      "title" : "Adaptive Learning with Robust Generalization Guarantees",
      "author" : [ "Rachel Cummings", "Katrina Ligett", "Aaron Roth", "Kobbi Nissim", "Zhiwei Steven Wu" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Cummings et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Cummings et al\\.",
      "year" : 2016
    }, {
      "title" : "The Cascade-Correlation Learning Architecture",
      "author" : [ "Scott E Fahlman", "Christian Lebiere" ],
      "venue" : "In NIPS, pages 524–532,",
      "citeRegEx" : "Fahlman and Lebiere.,? \\Q1990\\E",
      "shortCiteRegEx" : "Fahlman and Lebiere.",
      "year" : 1990
    }, {
      "title" : "Online Adaptation of Deep Architectures with Reinforcement Learning",
      "author" : [ "Thushan Ganegedara", "Lionel Ott", "Fabio Ramos" ],
      "venue" : null,
      "citeRegEx" : "Ganegedara et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Ganegedara et al\\.",
      "year" : 2016
    }, {
      "title" : "How the Brain Might Work: a Hierarchical and Temporal Model for Learning and Recognition",
      "author" : [ "Dileep George" ],
      "venue" : null,
      "citeRegEx" : "George.,? \\Q2008\\E",
      "shortCiteRegEx" : "George.",
      "year" : 2008
    }, {
      "title" : "Computational rationality: A converging paradigm for intelligence in brains",
      "author" : [ "Samuel J Gershman", "Eric J Horvitz", "Joshua B Tenenbaum" ],
      "venue" : "minds, and machines. Science,",
      "citeRegEx" : "Gershman et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gershman et al\\.",
      "year" : 2015
    }, {
      "title" : "Knowledge Matters: Importance of Prior Information for Optimization",
      "author" : [ "Caglar Gulcehre", "Yoshua Bengio" ],
      "venue" : null,
      "citeRegEx" : "Gulcehre and Bengio.,? \\Q2016\\E",
      "shortCiteRegEx" : "Gulcehre and Bengio.",
      "year" : 2016
    }, {
      "title" : "Universal Psychometrics Tasks: difficulty, composition and decomposition",
      "author" : [ "José Hernández-Orallo" ],
      "venue" : null,
      "citeRegEx" : "Hernández.Orallo.,? \\Q2015\\E",
      "shortCiteRegEx" : "Hernández.Orallo.",
      "year" : 2015
    }, {
      "title" : "Evaluation in artificial intelligence: from taskoriented to ability-oriented measurement",
      "author" : [ "José Hernández-Orallo" ],
      "venue" : "Artificial Intelligence Review,",
      "citeRegEx" : "Hernández.Orallo.,? \\Q2016\\E",
      "shortCiteRegEx" : "Hernández.Orallo.",
      "year" : 2016
    }, {
      "title" : "The measure of all minds : evaluating natural and artificial intelligence",
      "author" : [ "José Hernández-Orallo" ],
      "venue" : null,
      "citeRegEx" : "Hernández.Orallo.,? \\Q2017\\E",
      "shortCiteRegEx" : "Hernández.Orallo.",
      "year" : 2017
    }, {
      "title" : "A formal definition of intelligence based on an intensional variant of kolmogorov complexity",
      "author" : [ "José Hernández-Orallo", "Neus Minaya-Collado" ],
      "venue" : "In Proceedings of International Symposium of Engineering of Intelligent Systems (EIS",
      "citeRegEx" : "Hernández.Orallo and Minaya.Collado.,? \\Q1998\\E",
      "shortCiteRegEx" : "Hernández.Orallo and Minaya.Collado.",
      "year" : 1998
    }, {
      "title" : "Universal Artificial Intelligence: Sequential Decisions based on Algorithmic Probability",
      "author" : [ "Marcus Hutter" ],
      "venue" : null,
      "citeRegEx" : "Hutter.,? \\Q2005\\E",
      "shortCiteRegEx" : "Hutter.",
      "year" : 2005
    }, {
      "title" : "Solving the distal reward problem through linkage of STDP and dopamine signaling",
      "author" : [ "Eugene M. Izhikevich" ],
      "venue" : "Cerebral Cortex,",
      "citeRegEx" : "Izhikevich.,? \\Q2007\\E",
      "shortCiteRegEx" : "Izhikevich.",
      "year" : 2007
    }, {
      "title" : "The Malmo Platform for Artificial Intelligence Experimentation",
      "author" : [ "Matthew Johnson", "Katja Hofmann", "Tim Hutton", "David Bignell" ],
      "venue" : "IJCAI, page",
      "citeRegEx" : "Johnson et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2016
    }, {
      "title" : "Principles of neural science",
      "author" : [ "Eric R. Kandel", "James H. Schwartz" ],
      "venue" : null,
      "citeRegEx" : "Kandel and Schwartz.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kandel and Schwartz.",
      "year" : 2012
    }, {
      "title" : "Cattell-Horn-Carroll abilities and cognitive tests: What we’ve learned from 20 years of research",
      "author" : [ "Timothy Z Keith", "Matthew R Reynolds" ],
      "venue" : "Psychology in the Schools,",
      "citeRegEx" : "Keith and Reynolds.,? \\Q2010\\E",
      "shortCiteRegEx" : "Keith and Reynolds.",
      "year" : 2010
    }, {
      "title" : "Flexible shaping: How learning in small steps helps",
      "author" : [ "Kai A. Krueger", "Peter Dayan" ],
      "venue" : null,
      "citeRegEx" : "Krueger and Dayan.,? \\Q2009\\E",
      "shortCiteRegEx" : "Krueger and Dayan.",
      "year" : 2009
    }, {
      "title" : "What Learning Systems do Intelligent Agents Need? Complementary Learning Systems Theory Updated",
      "author" : [ "Dharshan Kumaran", "Demis Hassabis", "James L McClelland" ],
      "venue" : "Trends Cogn. Sci.,",
      "citeRegEx" : "Kumaran et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kumaran et al\\.",
      "year" : 2016
    }, {
      "title" : "Building Machines that learn and think like people",
      "author" : [ "Brenden M Lake", "Tomer D Ullman", "Joshua B Tenenbaum", "Samuel J Gershman" ],
      "venue" : null,
      "citeRegEx" : "Lake et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Lake et al\\.",
      "year" : 2016
    }, {
      "title" : "How to solve the world’s biggest problems",
      "author" : [ "Heidi Ledford" ],
      "venue" : "Nature, pages",
      "citeRegEx" : "Ledford.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ledford.",
      "year" : 2015
    }, {
      "title" : "Universal intelligence: A definition of machine intelligence",
      "author" : [ "Shane Legg", "Marcus Hutter" ],
      "venue" : "Minds and Machines,",
      "citeRegEx" : "Legg and Hutter.,? \\Q2007\\E",
      "shortCiteRegEx" : "Legg and Hutter.",
      "year" : 2007
    }, {
      "title" : "A Collection of Definitions of Intelligence",
      "author" : [ "Shane Legg", "Marcus Hutter" ],
      "venue" : "In Proceedings of AGI 2006: Workshop on Concepts, Architectures and Algorithms,",
      "citeRegEx" : "Legg and Hutter.,? \\Q2007\\E",
      "shortCiteRegEx" : "Legg and Hutter.",
      "year" : 2007
    }, {
      "title" : "On the Thresholds of Knowledge",
      "author" : [ "Douglas B Lenat", "Edward A Feigenbaum" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Lenat and Feigenbaum.,? \\Q1991\\E",
      "shortCiteRegEx" : "Lenat and Feigenbaum.",
      "year" : 1991
    }, {
      "title" : "An Introduction to Kolmogorov Complexity and Its Applications",
      "author" : [ "Ming Li", "Paul Vitanyi" ],
      "venue" : null,
      "citeRegEx" : "Li and Vitanyi.,? \\Q2013\\E",
      "shortCiteRegEx" : "Li and Vitanyi.",
      "year" : 2013
    }, {
      "title" : "Learning without Forgetting",
      "author" : [ "Zhizhong Li", "Derek Hoiem" ],
      "venue" : null,
      "citeRegEx" : "Li and Hoiem.,? \\Q2016\\E",
      "shortCiteRegEx" : "Li and Hoiem.",
      "year" : 2016
    }, {
      "title" : "Learning Purposeful Behaviour in the Absence of Rewards",
      "author" : [ "Marlos C. Machado", "Michael Bowling" ],
      "venue" : null,
      "citeRegEx" : "Machado and Bowling.,? \\Q2016\\E",
      "shortCiteRegEx" : "Machado and Bowling.",
      "year" : 2016
    }, {
      "title" : "Towards an integration of deep learning and neuroscience",
      "author" : [ "Adam H Marblestone", "Greg Wayne", "Konrad P Kording" ],
      "venue" : null,
      "citeRegEx" : "Marblestone et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Marblestone et al\\.",
      "year" : 2016
    }, {
      "title" : "Generality in Artificial Intelligence",
      "author" : [ "John McCarthy" ],
      "venue" : "Commun. ACM,",
      "citeRegEx" : "McCarthy.,? \\Q1987\\E",
      "shortCiteRegEx" : "McCarthy.",
      "year" : 1987
    }, {
      "title" : "Some philosophical problems from the standpoint of artificial intelligence",
      "author" : [ "John McCarthy", "Patrick J Hayes" ],
      "venue" : "Readings in Artificial Intelligence,",
      "citeRegEx" : "McCarthy and Hayes.,? \\Q1969\\E",
      "shortCiteRegEx" : "McCarthy and Hayes.",
      "year" : 1969
    }, {
      "title" : "Deep vs. shallow networks : An approximation theory perspective",
      "author" : [ "Hrushikesh Mhaskar", "Tomaso Poggio" ],
      "venue" : null,
      "citeRegEx" : "Mhaskar and Poggio.,? \\Q2016\\E",
      "shortCiteRegEx" : "Mhaskar and Poggio.",
      "year" : 2016
    }, {
      "title" : "Learning Functions: When Is Deep Better Than Shallow",
      "author" : [ "Hrushikesh Mhaskar", "Qianli Liao", "Tomaso Poggio" ],
      "venue" : null,
      "citeRegEx" : "Mhaskar et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Mhaskar et al\\.",
      "year" : 2016
    }, {
      "title" : "Steps toward Artificial Intelligence",
      "author" : [ "Marvin Minsky" ],
      "venue" : "Proceedings of the IRE,",
      "citeRegEx" : "Minsky.,? \\Q1961\\E",
      "shortCiteRegEx" : "Minsky.",
      "year" : 1961
    }, {
      "title" : "The Society of Mind",
      "author" : [ "Marvin Minsky" ],
      "venue" : null,
      "citeRegEx" : "Minsky.,? \\Q1986\\E",
      "shortCiteRegEx" : "Minsky.",
      "year" : 1986
    }, {
      "title" : "Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning",
      "author" : [ "Shakir Mohamed", "Danilo Jimenez Rezende" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Mohamed and Rezende.,? \\Q2015\\E",
      "shortCiteRegEx" : "Mohamed and Rezende.",
      "year" : 2015
    }, {
      "title" : "Neural Programmer: Inducing Latent Programs with Gradient Descent",
      "author" : [ "Arvind Neelakantan", "Quoc V. Le", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "Neelakantan et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Neelakantan et al\\.",
      "year" : 2005
    }, {
      "title" : "Bounded Recursive SelfImprovement",
      "author" : [ "Eric Nivel", "Kristinn R Thórisson", "Bas R Steunebrink", "Haris Dindo", "Giovanni Pezzulo", "Manuel Rodríguez", "Carlos Hernández", "Dimitri Ognibene", "Jürgen Schmidhuber", "Ricardo Sanz", "Helgi P Helgason", "Antonio Chella", "Gudberg K Jonsson" ],
      "venue" : null,
      "citeRegEx" : "Nivel et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Nivel et al\\.",
      "year" : 2013
    }, {
      "title" : "Control of Memory, Active Perception, and Action in Minecraft",
      "author" : [ "Junhyuk Oh", "Valliappa Chockalingam", "Satinder Singh", "Honglak Lee" ],
      "venue" : null,
      "citeRegEx" : "Oh et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Oh et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning and transferring mid-level image representations using convolutional neural networks",
      "author" : [ "Maxime Oquab", "Léon Bottou", "Ivan Laptev", "Josef Sivic" ],
      "venue" : null,
      "citeRegEx" : "Oquab et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Oquab et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning dynamic Boltzmann machines with spike-timing dependent plasticity",
      "author" : [ "Takayuki Osogami", "Makoto Otsuka" ],
      "venue" : null,
      "citeRegEx" : "Osogami and Otsuka.,? \\Q2015\\E",
      "shortCiteRegEx" : "Osogami and Otsuka.",
      "year" : 2015
    }, {
      "title" : "A Survey on Transfer Learning",
      "author" : [ "Sinno J Pan", "Qiang Yang" ],
      "venue" : "IEEE Trans. Knowl. Data Eng.,",
      "citeRegEx" : "Pan and Yang.,? \\Q2010\\E",
      "shortCiteRegEx" : "Pan and Yang.",
      "year" : 2010
    }, {
      "title" : "I-theory on depth vs width: hierarchical function composition",
      "author" : [ "Tomaso Poggio", "Fabio Anselmi", "Lorenzo Rosasco" ],
      "venue" : null,
      "citeRegEx" : "Poggio et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Poggio et al\\.",
      "year" : 2015
    }, {
      "title" : "How to solve it: a new aspect of mathematical method",
      "author" : [ "George Pólya" ],
      "venue" : null,
      "citeRegEx" : "Pólya.,? \\Q2004\\E",
      "shortCiteRegEx" : "Pólya.",
      "year" : 2004
    }, {
      "title" : "Is science becoming more interdisciplinary? Measuring and mapping six research fields over time",
      "author" : [ "Alan L Porter", "Ismael Rafols" ],
      "venue" : null,
      "citeRegEx" : "Porter and Rafols.,? \\Q2009\\E",
      "shortCiteRegEx" : "Porter and Rafols.",
      "year" : 2009
    }, {
      "title" : "Artificial Intelligence - Man or Machine",
      "author" : [ "Sandeep Rajani" ],
      "venue" : "International Journal of Information Technology and Knowledge Management,",
      "citeRegEx" : "Rajani.,? \\Q2011\\E",
      "shortCiteRegEx" : "Rajani.",
      "year" : 2011
    }, {
      "title" : "Neural Programmer-Interpreters",
      "author" : [ "Scott Reed", "Nando de Freitas" ],
      "venue" : "In ICLR,",
      "citeRegEx" : "Reed and Freitas.,? \\Q2016\\E",
      "shortCiteRegEx" : "Reed and Freitas.",
      "year" : 2016
    }, {
      "title" : "Programming with a Differentiable Forth Interpreter",
      "author" : [ "Sebastian Riedel", "Matko Bošnjak", "Tim Rocktäschel" ],
      "venue" : null,
      "citeRegEx" : "Riedel et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Riedel et al\\.",
      "year" : 2016
    }, {
      "title" : "Modeling by shortest data",
      "author" : [ "Jorma Rissanen" ],
      "venue" : "description. Automatica,",
      "citeRegEx" : "Rissanen.,? \\Q1978\\E",
      "shortCiteRegEx" : "Rissanen.",
      "year" : 1978
    }, {
      "title" : "Consolidating the search for general AI",
      "author" : [ "Marek Rosa", "Jan Feyereisl" ],
      "venue" : "In NIPS Workshop on Machine Intelligence,",
      "citeRegEx" : "Rosa and Feyereisl.,? \\Q2016\\E",
      "shortCiteRegEx" : "Rosa and Feyereisl.",
      "year" : 2016
    }, {
      "title" : "Learning with Hierarchical-Deep Models",
      "author" : [ "Ruslan Salakhutdinov", "Joshua B Tenenbaum", "Antonio Torralba" ],
      "venue" : "IEEE Trans. Pattern Anal. Mach. Intell.,",
      "citeRegEx" : "Salakhutdinov et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Salakhutdinov et al\\.",
      "year" : 2013
    }, {
      "title" : "Is the turing test good enough? The fallacy of resource-unbounded intelligence",
      "author" : [ "Virginia Savova", "Leonid Peshkin" ],
      "venue" : null,
      "citeRegEx" : "Savova and Peshkin.,? \\Q2007\\E",
      "shortCiteRegEx" : "Savova and Peshkin.",
      "year" : 2007
    }, {
      "title" : "Towards a Biologically Plausible Backprop",
      "author" : [ "Benjamin Scellier", "Yoshua Bengio" ],
      "venue" : null,
      "citeRegEx" : "Scellier and Bengio.,? \\Q2016\\E",
      "shortCiteRegEx" : "Scellier and Bengio.",
      "year" : 2016
    }, {
      "title" : "A conservation law for generalization performance",
      "author" : [ "Cullen Schaffer" ],
      "venue" : null,
      "citeRegEx" : "Schaffer.,? \\Q1994\\E",
      "shortCiteRegEx" : "Schaffer.",
      "year" : 1994
    }, {
      "title" : "PowerPlay: Training an Increasingly General Problem Solver by Continually Searching for the Simplest Still Unsolvable Problem",
      "author" : [ "Jürgen Schmidhuber" ],
      "venue" : "Front. Psychol.,",
      "citeRegEx" : "Schmidhuber.,? \\Q2013\\E",
      "shortCiteRegEx" : "Schmidhuber.",
      "year" : 2013
    }, {
      "title" : "Deep learning in neural networks: an overview",
      "author" : [ "Jürgen Schmidhuber" ],
      "venue" : "Neural Netw.,",
      "citeRegEx" : "Schmidhuber.,? \\Q2015\\E",
      "shortCiteRegEx" : "Schmidhuber.",
      "year" : 2015
    }, {
      "title" : "CNN Features off-the-shelf: an Astounding Baseline for Recognition",
      "author" : [ "Ali Sharif", "Razavian Hossein", "Azizpour Josephine", "Sullivan Stefan", "K T H Royal" ],
      "venue" : "CVPRW,",
      "citeRegEx" : "Sharif et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Sharif et al\\.",
      "year" : 2014
    }, {
      "title" : "Does the Turing Test Demonstrate Intelligence or Not",
      "author" : [ "Stuart M. Shieber" ],
      "venue" : "AAAI, pages 1539–1542,",
      "citeRegEx" : "Shieber.,? \\Q2006\\E",
      "shortCiteRegEx" : "Shieber.",
      "year" : 2006
    }, {
      "title" : "Intrinsically motivated reinforcement learning",
      "author" : [ "Satinder Singh", "Andrew G Barto", "Nuttapong Chentanez" ],
      "venue" : "NIPS, 17(2):1281–1288,",
      "citeRegEx" : "Singh et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Singh et al\\.",
      "year" : 2004
    }, {
      "title" : "The discovery of algorithmic probability: A guide for the programming of true creativity",
      "author" : [ "Ray J Solomonoff" ],
      "venue" : "In EuroCOLT,",
      "citeRegEx" : "Solomonoff.,? \\Q1995\\E",
      "shortCiteRegEx" : "Solomonoff.",
      "year" : 1995
    }, {
      "title" : "Evolving neural networks through augmenting topologies",
      "author" : [ "Kenneth O Stanley", "Risto Miikkulainen" ],
      "venue" : "Evol. Comput.,",
      "citeRegEx" : "Stanley and Miikkulainen.,? \\Q2002\\E",
      "shortCiteRegEx" : "Stanley and Miikkulainen.",
      "year" : 2002
    }, {
      "title" : "Growing Recursive Self-Improvers",
      "author" : [ "Bas R Steunebrink", "Kristinn R Thórisson", "Jürgen Schmidhuber" ],
      "venue" : "In AGI,",
      "citeRegEx" : "Steunebrink et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Steunebrink et al\\.",
      "year" : 2016
    }, {
      "title" : "Quantilizers: A Safer Alternative to Maximizers for Limited Optimization",
      "author" : [ "Jessica Taylor" ],
      "venue" : "In AAAI Workshop,",
      "citeRegEx" : "Taylor.,? \\Q2016\\E",
      "shortCiteRegEx" : "Taylor.",
      "year" : 2016
    }, {
      "title" : "Reinforcement learning with human teachers: Evidence of feedback and guidance with implications for learning performance",
      "author" : [ "Andrea L Thomaz", "Cynthia Breazeal" ],
      "venue" : null,
      "citeRegEx" : "Thomaz and Breazeal.,? \\Q2006\\E",
      "shortCiteRegEx" : "Thomaz and Breazeal.",
      "year" : 2006
    }, {
      "title" : "Why Artificial Intelligence Needs a Task Theory ",
      "author" : [ "Kristinn R Thórisson", "Jordi Bieger", "Thröstur Thorarensen", "Jóna S Siguroardóttir", "Bas R Steunebrink" ],
      "venue" : "And What It Might Look Like",
      "citeRegEx" : "Thórisson et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Thórisson et al\\.",
      "year" : 2016
    }, {
      "title" : "Animal cognition: Monkeys pass the mirror test",
      "author" : [ "Koji Toda", "Michael L Platt" ],
      "venue" : "Current Biology,",
      "citeRegEx" : "Toda and Platt.,? \\Q2015\\E",
      "shortCiteRegEx" : "Toda and Platt.",
      "year" : 2015
    }, {
      "title" : "Consciousness: here, there and everywhere",
      "author" : [ "Giulio Tononi", "Christof Koch" ],
      "venue" : "Philos. Trans. R. Soc. Lond. B Biol. Sci.,",
      "citeRegEx" : "Tononi and Koch.,? \\Q2015\\E",
      "shortCiteRegEx" : "Tononi and Koch.",
      "year" : 2015
    }, {
      "title" : "Statistical learning theory",
      "author" : [ "Vladimir Vapnik" ],
      "venue" : null,
      "citeRegEx" : "Vapnik.,? \\Q1998\\E",
      "shortCiteRegEx" : "Vapnik.",
      "year" : 1998
    }, {
      "title" : "Learning Using Privileged Information : Similarity Control and Knowledge Transfer",
      "author" : [ "Vladimir Vapnik" ],
      "venue" : "JMLR, 16:2023–2049,",
      "citeRegEx" : "Vapnik.,? \\Q2015\\E",
      "shortCiteRegEx" : "Vapnik.",
      "year" : 2015
    }, {
      "title" : "Extracting and composing robust features with denoising autoencoders",
      "author" : [ "Pascal Vincent", "Hugo Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Vincent et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Vincent et al\\.",
      "year" : 2008
    }, {
      "title" : "An Information Measure for Classification",
      "author" : [ "Christopher S Wallace", "David M Boulton" ],
      "venue" : "Comput. J.,",
      "citeRegEx" : "Wallace and Boulton.,? \\Q1968\\E",
      "shortCiteRegEx" : "Wallace and Boulton.",
      "year" : 1968
    }, {
      "title" : "Temporal Pattern Processing",
      "author" : [ "DeLiang Wang" ],
      "venue" : "The Handbook of Brain Theory and Neural Networks,",
      "citeRegEx" : "Wang.,? \\Q2003\\E",
      "shortCiteRegEx" : "Wang.",
      "year" : 2003
    }, {
      "title" : "Learning to Execute",
      "author" : [ "Wojciech Zaremba", "Ilya Sutskever" ],
      "venue" : "ICLR, pages 1–25,",
      "citeRegEx" : "Zaremba and Sutskever.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zaremba and Sutskever.",
      "year" : 2014
    }, {
      "title" : "Reinforcement Learning",
      "author" : [ "Wojciech Zaremba", "Ilya Sutskever" ],
      "venue" : "Neural Turing Machines",
      "citeRegEx" : "Zaremba and Sutskever.,? \\Q2015\\E",
      "shortCiteRegEx" : "Zaremba and Sutskever.",
      "year" : 2015
    }, {
      "title" : "Co-saliency Detection via A Self-paced Multiple-instance Learning Framework",
      "author" : [ "Dingwen Zhang", "Deyu Meng", "Junwei Han" ],
      "venue" : "IEEE Trans. Pattern Anal. Mach. Intell.,",
      "citeRegEx" : "Zhang et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2016
    }, {
      "title" : "Online Incremental Feature Learning with Denoising Autoencoders",
      "author" : [ "Guanyu Zhou", "Kihyuk Sohn", "Honglak Lee" ],
      "venue" : "JMLR W&CP,",
      "citeRegEx" : "Zhou et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "This additional constraint on intelligence results in favoring “efficient” skills and operation under bounded rationality [Gershman et al., 2015].",
      "startOffset" : 122,
      "endOffset" : 145
    }, {
      "referenceID" : 17,
      "context" : "ness as well as efficiency of their skills [Gershman et al., 2015] in terms of their sample complexity, the required computational cycles or their reuse of previously learned skills.",
      "startOffset" : 43,
      "endOffset" : 66
    }, {
      "referenceID" : 28,
      "context" : "One example of this is the hierarchical decomposition of a task into subtasks and the gradual learning of skills necessary for solving each of them [Krueger and Dayan, 2009], progressing from the bottom of the hierarchy to the top16 16 Hrushikesh Mhaskar, Qianli Liao, and Tomaso Poggio.",
      "startOffset" : 148,
      "endOffset" : 173
    }, {
      "referenceID" : 53,
      "context" : "(041), 2015 [Pólya, 2004].",
      "startOffset" : 12,
      "endOffset" : 25
    }, {
      "referenceID" : 20,
      "context" : "Skills might also provide a way to measure how well parts of the system work, as it is clear how to measure which system is better in understanding speech, classification, and game playing [Hernández-Orallo, 2016].",
      "startOffset" : 189,
      "endOffset" : 213
    }, {
      "referenceID" : 51,
      "context" : "It is very important that an architecture that has the ability to solve problems (tasks in the roadmap) does not approach each problem in isolation [Pan and Yang, 2010].",
      "startOffset" : 148,
      "endOffset" : 168
    }, {
      "referenceID" : 37,
      "context" : "It also continues in self-exploration [Machado and Bowling, 2016], principally guided/biased by the skills/behaviors acquired in previous stages.",
      "startOffset" : 38,
      "endOffset" : 65
    }, {
      "referenceID" : 55,
      "context" : "Stage 4 Human-level general AI We have a fully developed general purpose AI that has a large repertoire of skills which are needed and can be directed toward any goal, solving as many tasks to at least the same level of accuracy as most humans [Rajani, 2011].",
      "startOffset" : 244,
      "endOffset" : 258
    }, {
      "referenceID" : 20,
      "context" : "ICML, 1994 human-level general AI might allow for avoiding this theoretical argument [Hernández-Orallo, 2016].",
      "startOffset" : 85,
      "endOffset" : 109
    }, {
      "referenceID" : 35,
      "context" : "– Kolmogorov Complexity [Li and Vitanyi, 2013] – Minimum Description/Message Length41 41 Jorma Rissanen.",
      "startOffset" : 24,
      "endOffset" : 46
    }, {
      "referenceID" : 30,
      "context" : "Lake et al. [2016] on the other hand propose a more philosophical discussion of the limitations of current approaches.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 7,
      "context" : "Bengio et al. [2009] initiated the BabyAI project and introduced curriculum learning: learning accelerated by presenting easy examples first and progressively increasing the difficulty.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 7,
      "context" : "Bengio et al. [2009] initiated the BabyAI project and introduced curriculum learning: learning accelerated by presenting easy examples first and progressively increasing the difficulty. In the framework of Mikolov et al. [2015], learning in a simplified environment is also presented.",
      "startOffset" : 0,
      "endOffset" : 228
    }, {
      "referenceID" : 7,
      "context" : "Bengio et al. [2009] initiated the BabyAI project and introduced curriculum learning: learning accelerated by presenting easy examples first and progressively increasing the difficulty. In the framework of Mikolov et al. [2015], learning in a simplified environment is also presented. In their work, however, the environment is defined by language only and no visual input is provided to the AI. An interesting discussion on the shortcomings of present AI systems and efforts at Facebook to build systems that learn for general AI is found in the work of Bordes et al.48. Project Malmo, an interac48 Antoine Bordes, Jason Weston, Sumit Chopra, Tomas Mikolov, Armand Joulin, Sasha Rush, and Léon Bottou. Artificial Tasks for Artificial Intelligence. ICLR, 2015 tive 3D toy environment based on the game Minecraft is discussed in by Johnson et al. [2016]49.",
      "startOffset" : 0,
      "endOffset" : 853
    }, {
      "referenceID" : 7,
      "context" : "Bengio et al. [2009] initiated the BabyAI project and introduced curriculum learning: learning accelerated by presenting easy examples first and progressively increasing the difficulty. In the framework of Mikolov et al. [2015], learning in a simplified environment is also presented. In their work, however, the environment is defined by language only and no visual input is provided to the AI. An interesting discussion on the shortcomings of present AI systems and efforts at Facebook to build systems that learn for general AI is found in the work of Bordes et al.48. Project Malmo, an interac48 Antoine Bordes, Jason Weston, Sumit Chopra, Tomas Mikolov, Armand Joulin, Sasha Rush, and Léon Bottou. Artificial Tasks for Artificial Intelligence. ICLR, 2015 tive 3D toy environment based on the game Minecraft is discussed in by Johnson et al. [2016]49. Thórisson et al. [2016] argue that a theory of",
      "startOffset" : 0,
      "endOffset" : 880
    }, {
      "referenceID" : 19,
      "context" : "2002 evaluation environments, measures and challenges in AI is presented by Hernández-Orallo [2016].",
      "startOffset" : 76,
      "endOffset" : 100
    }, {
      "referenceID" : 7,
      "context" : "For an in-depth 51 Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436–444, 2015 analysis and reference of the field, the work of Schmidhuber [2015]52 52 Jürgen Schmidhuber.",
      "startOffset" : 38,
      "endOffset" : 182
    }, {
      "referenceID" : 47,
      "context" : "A systematic overview of a related field of ’transfer learning’ is provided by Pan and Yang [2010]. Schmidhuber [2013] presents a framework for automatically discovering problems inspired by playful behavior in animals and humans.",
      "startOffset" : 79,
      "endOffset" : 99
    }, {
      "referenceID" : 47,
      "context" : "A systematic overview of a related field of ’transfer learning’ is provided by Pan and Yang [2010]. Schmidhuber [2013] presents a framework for automatically discovering problems inspired by playful behavior in animals and humans.",
      "startOffset" : 79,
      "endOffset" : 119
    }, {
      "referenceID" : 47,
      "context" : "A systematic overview of a related field of ’transfer learning’ is provided by Pan and Yang [2010]. Schmidhuber [2013] presents a framework for automatically discovering problems inspired by playful behavior in animals and humans. Rusu et al. [2016]53 introduce progressive neural 53 Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell.",
      "startOffset" : 79,
      "endOffset" : 250
    }, {
      "referenceID" : 14,
      "context" : "In earlier work, Fahlman and Lebiere [1990] demonstrated accelerated learning by adding one hidden neuron at the time, keeping the preceding hidden weights frozen.",
      "startOffset" : 17,
      "endOffset" : 44
    }, {
      "referenceID" : 14,
      "context" : "In earlier work, Fahlman and Lebiere [1990] demonstrated accelerated learning by adding one hidden neuron at the time, keeping the preceding hidden weights frozen. Similar additive learning capabilities are demonstrated for convolutional neural networks by Li and Hoiem [2016]54.",
      "startOffset" : 17,
      "endOffset" : 277
    }, {
      "referenceID" : 14,
      "context" : "In earlier work, Fahlman and Lebiere [1990] demonstrated accelerated learning by adding one hidden neuron at the time, keeping the preceding hidden weights frozen. Similar additive learning capabilities are demonstrated for convolutional neural networks by Li and Hoiem [2016]54. 54 Zhizhong Li and Derek Hoiem. Learning without Forgetting. arXiv:1606.09282, 2016 Nivel et al. [2013] prototype \"a machine that becomes increasingly better at behaving in under specified circumstances, in a goal-directed way, on the job, by modeling itself and its environment as experience accumulates\".",
      "startOffset" : 17,
      "endOffset" : 384
    }, {
      "referenceID" : 14,
      "context" : "In earlier work, Fahlman and Lebiere [1990] demonstrated accelerated learning by adding one hidden neuron at the time, keeping the preceding hidden weights frozen. Similar additive learning capabilities are demonstrated for convolutional neural networks by Li and Hoiem [2016]54. 54 Zhizhong Li and Derek Hoiem. Learning without Forgetting. arXiv:1606.09282, 2016 Nivel et al. [2013] prototype \"a machine that becomes increasingly better at behaving in under specified circumstances, in a goal-directed way, on the job, by modeling itself and its environment as experience accumulates\". Steunebrink et al. [2016] introduce Experience-based AI, a class of systems capable of continuous self-improvement.",
      "startOffset" : 17,
      "endOffset" : 613
    }, {
      "referenceID" : 14,
      "context" : "In earlier work, Fahlman and Lebiere [1990] demonstrated accelerated learning by adding one hidden neuron at the time, keeping the preceding hidden weights frozen. Similar additive learning capabilities are demonstrated for convolutional neural networks by Li and Hoiem [2016]54. 54 Zhizhong Li and Derek Hoiem. Learning without Forgetting. arXiv:1606.09282, 2016 Nivel et al. [2013] prototype \"a machine that becomes increasingly better at behaving in under specified circumstances, in a goal-directed way, on the job, by modeling itself and its environment as experience accumulates\". Steunebrink et al. [2016] introduce Experience-based AI, a class of systems capable of continuous self-improvement. Architectures that can learn as much as possible of their structure from training data are also relevant for creating progressively growing agents. Zhou et al. [2012] introduce an algorithm for learning features incrementally and determining architecture complexity from data.",
      "startOffset" : 17,
      "endOffset" : 870
    }, {
      "referenceID" : 14,
      "context" : "In earlier work, Fahlman and Lebiere [1990] demonstrated accelerated learning by adding one hidden neuron at the time, keeping the preceding hidden weights frozen. Similar additive learning capabilities are demonstrated for convolutional neural networks by Li and Hoiem [2016]54. 54 Zhizhong Li and Derek Hoiem. Learning without Forgetting. arXiv:1606.09282, 2016 Nivel et al. [2013] prototype \"a machine that becomes increasingly better at behaving in under specified circumstances, in a goal-directed way, on the job, by modeling itself and its environment as experience accumulates\". Steunebrink et al. [2016] introduce Experience-based AI, a class of systems capable of continuous self-improvement. Architectures that can learn as much as possible of their structure from training data are also relevant for creating progressively growing agents. Zhou et al. [2012] introduce an algorithm for learning features incrementally and determining architecture complexity from data. In contrast, rather than using a simple heuristic, Cortes et al. [2016]55 propose a growing 55 Corinna Cortes, Xavi Gonzalvo, Vitaly Kuznetsov, Mehryar Mohri, and Scott Yang.",
      "startOffset" : 17,
      "endOffset" : 1052
    }, {
      "referenceID" : 14,
      "context" : "In earlier work, Fahlman and Lebiere [1990] demonstrated accelerated learning by adding one hidden neuron at the time, keeping the preceding hidden weights frozen. Similar additive learning capabilities are demonstrated for convolutional neural networks by Li and Hoiem [2016]54. 54 Zhizhong Li and Derek Hoiem. Learning without Forgetting. arXiv:1606.09282, 2016 Nivel et al. [2013] prototype \"a machine that becomes increasingly better at behaving in under specified circumstances, in a goal-directed way, on the job, by modeling itself and its environment as experience accumulates\". Steunebrink et al. [2016] introduce Experience-based AI, a class of systems capable of continuous self-improvement. Architectures that can learn as much as possible of their structure from training data are also relevant for creating progressively growing agents. Zhou et al. [2012] introduce an algorithm for learning features incrementally and determining architecture complexity from data. In contrast, rather than using a simple heuristic, Cortes et al. [2016]55 propose a growing 55 Corinna Cortes, Xavi Gonzalvo, Vitaly Kuznetsov, Mehryar Mohri, and Scott Yang. AdaNet: Adaptive Structural Learning of Artificial Neural Networks. arXiv:1607.01097, pages 1–18, 2016 neural network architecture algorithm exploiting theoretical bounds derived through a statistical learning complexity measure. Saxena and Verbeek [2016]56 propose a convolutional neural fabric that learns the 56 Shreyas Saxena and Jakob Verbeek.",
      "startOffset" : 17,
      "endOffset" : 1411
    }, {
      "referenceID" : 14,
      "context" : "In earlier work, Fahlman and Lebiere [1990] demonstrated accelerated learning by adding one hidden neuron at the time, keeping the preceding hidden weights frozen. Similar additive learning capabilities are demonstrated for convolutional neural networks by Li and Hoiem [2016]54. 54 Zhizhong Li and Derek Hoiem. Learning without Forgetting. arXiv:1606.09282, 2016 Nivel et al. [2013] prototype \"a machine that becomes increasingly better at behaving in under specified circumstances, in a goal-directed way, on the job, by modeling itself and its environment as experience accumulates\". Steunebrink et al. [2016] introduce Experience-based AI, a class of systems capable of continuous self-improvement. Architectures that can learn as much as possible of their structure from training data are also relevant for creating progressively growing agents. Zhou et al. [2012] introduce an algorithm for learning features incrementally and determining architecture complexity from data. In contrast, rather than using a simple heuristic, Cortes et al. [2016]55 propose a growing 55 Corinna Cortes, Xavi Gonzalvo, Vitaly Kuznetsov, Mehryar Mohri, and Scott Yang. AdaNet: Adaptive Structural Learning of Artificial Neural Networks. arXiv:1607.01097, pages 1–18, 2016 neural network architecture algorithm exploiting theoretical bounds derived through a statistical learning complexity measure. Saxena and Verbeek [2016]56 propose a convolutional neural fabric that learns the 56 Shreyas Saxena and Jakob Verbeek. Convolutional Neural Fabrics. arXiv:1606.02492, 2016 structure of convolutional networks. Gradual learning in a toy environment and exploiting reinforcement learning can be found in the work of Oh et al. [2016].",
      "startOffset" : 17,
      "endOffset" : 1715
    }, {
      "referenceID" : 78,
      "context" : "Vincent et al. [2008]57 describe the use of denoising autoencoders to im57 Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 3,
      "context" : "Andreas et al. [2016b] compose neural networks from component net-",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 46,
      "context" : "Similarly, Neelakantan et al. [2016] train an agent to per58 Scott Reed and Nando de Freitas.",
      "startOffset" : 11,
      "endOffset" : 37
    }, {
      "referenceID" : 46,
      "context" : "Similarly, Neelakantan et al. [2016] train an agent to per58 Scott Reed and Nando de Freitas. Neural Programmer-Interpreters. In ICLR, pages 1–13, 2016 form table lookups on data using a number of intrinsic operators59. 59 Arvind Neelakantan, Quoc V. Le, and Ilya Sutskever. Neural Programmer: Inducing Latent Programs with Gradient Descent. ICLR, (2005):1–17, 2016 Kaiser and Sutskever [2015]’s neural GPU learns algorithms in a network that is wide rather than deep60; the parallelism makes for easier",
      "startOffset" : 11,
      "endOffset" : 355
    }, {
      "referenceID" : 46,
      "context" : "Similarly, Neelakantan et al. [2016] train an agent to per58 Scott Reed and Nando de Freitas. Neural Programmer-Interpreters. In ICLR, pages 1–13, 2016 form table lookups on data using a number of intrinsic operators59. 59 Arvind Neelakantan, Quoc V. Le, and Ilya Sutskever. Neural Programmer: Inducing Latent Programs with Gradient Descent. ICLR, (2005):1–17, 2016 Kaiser and Sutskever [2015]’s neural GPU learns algorithms in a network that is wide rather than deep60; the parallelism makes for easier",
      "startOffset" : 11,
      "endOffset" : 394
    }, {
      "referenceID" : 57,
      "context" : "Riedel et al. [2016] incorporates prior procedural knowledge as Forth program sketches with slots that can be filled with learned behavior61.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 7,
      "context" : "63 Yoshua Bengio, Benjamin Scellier, Olexa Bilaniuk, Joao Sacramento, and Walter Senn. Feedforward Initialization for Fast Inference of Deep Generative Networks is biologically plausible. arXiv:1606.01651, pages 1–10, 2016; Benjamin Scellier and Yoshua Bengio. Towards a Biologically Plausible Backprop. arXiv:1602.05179, 2016; and Yoshua Bengio. Evolving Culture Versus Local Minima. In Growing Adaptive Machines, pages 109–138. 2014 [2015] use it to learn temporal patterns with Boltzmann machines64.",
      "startOffset" : 10,
      "endOffset" : 442
    }, {
      "referenceID" : 23,
      "context" : "08634, 2015 Izhikevich [2007] addresses the problem of delayed reward in biological and artificial neural networks.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 16,
      "context" : "George [2008] proposes a model of learning and recognition where temporal patterns are central.",
      "startOffset" : 0,
      "endOffset" : 14
    }, {
      "referenceID" : 16,
      "context" : "George [2008] proposes a model of learning and recognition where temporal patterns are central. Wang [2003] provides an overview of approaches to the representation and processing of temporal patterns.",
      "startOffset" : 0,
      "endOffset" : 108
    }, {
      "referenceID" : 55,
      "context" : "Human-Level (AI) System performing at least at the same level as most humans An ability of a machine to solve as many of the same tasks to at least the same level of accuracy as most humans [Rajani, 2011].",
      "startOffset" : 190,
      "endOffset" : 204
    }, {
      "referenceID" : 19,
      "context" : "Prentice-Hall [4] Mikolov, Tomas; Joulin, Armand; Baroni, Marco, A Roadmap towards Machine Intelligence, Arxiv pre-print v2 [5] Hernández-Orallo, José, The Measure of All Minds: Evaluating Natural and Artificial Intelligence, Cambridge University Press (2016) E N V IR O N M E N T S DISCONTINUOUS 2D WORLD",
      "startOffset" : 128,
      "endOffset" : 260
    } ],
    "year" : 2016,
    "abstractText" : "There is a significant lack of unified approaches to building generally intelligent machines. The majority of current artificial intelligence research operates within a very narrow field of focus, frequently without considering the importance of the ’big picture’. In this document, we seek to describe and unify principles that guide the basis of our development of general artificial intelligence. These principles revolve around the idea that intelligence is a tool for searching for general solutions to problems. We define intelligence as the ability to acquire skills that narrow this search, diversify it and help steer it to more promising areas. We also provide suggestions for studying, measuring, and testing the various skills and abilities that a human-level1 1 Despite its vagueness, and the lack of a universal definition, the term provides a notion of an ability of a machine to solve as many tasks to at least the same level of accuracy as most humans. intelligent machine needs to acquire. The document aims to be both implementation agnostic, and to provide an analytic, systematic, and scalable way to generate hypotheses that we believe are needed to meet the necessary conditions in the search for general artificial intelligence. We believe that such a framework is an important stepping stone for bringing together definitions, highlighting open problems, connecting researchers willing to collaborate, and for unifying the arguably most significant search of this century.",
    "creator" : "LaTeX with hyperref package"
  }
}