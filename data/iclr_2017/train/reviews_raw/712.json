{"conference": "ICLR 2017 conference submission", "title": "A Neural Stochastic Volatility Model", "abstract": "In this paper, we show that the recent integration of statistical models with recurrent neural networks provides a new way of formulating volatility models that have been popular in time series analysis and prediction. The model comprises a pair of complementary stochastic recurrent neural networks: the generative network models the joint distribution of the stochastic volatility process; the inference network approximates the conditional distribution of the latent variables given the observable ones. Our focus in this paper is on the formulation of temporal dynamics of volatility over time under a stochastic recurrent neural network framework. Our derivations show that some popular volatility models are a special case of our proposed neural stochastic volatility model. Experiments demonstrate that the proposed model generates a smoother volatility estimation, and largely outperforms a widely used GARCH model on several metrics about the fitness of the volatility modelling and the accuracy of the prediction.", "reviews": [{"is_meta_review": true, "comments": "Thank you for an interesting read.\n\nI found the application of VRNN type generative model to financial data very promising. But since I don't have enough background knowledge to judge whether the performance gap is significant or not, I wouldn't recommend acceptance at this stage. \n\nTo me, the biggest issue for this paper is that I'm not sure if the paper contains significant novelty. The RNN-VAE combination has been around for more than a year and this paper does not propose significant changes to it. Maybe this paper fits better to an application targeting conference, rather than ICLR. But I'm not exactly sure about ICLR's acceptance criteria, and maybe the committee actually prefer great performances and interesting applications?", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "This paper presents an interesting application of variational methods for time series, in particular VRNN-like approaches, for stochastic volatility. Applications such as these are clearly in the scope of the conference, which was a point that one of the reviewer brought up. That said, questions of context, especially with regards to relation to different approaches, especially smoothing are relevant. Also, the number of methods GRACH and stochastic volatility is immense and this makes assessing the impact of this very hard to do and is more is needed to address this point. This paper is certainly interesting, but given these concerns, the paper is not yet rady for acceptance at the conference.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "A relevant contribution to time series modelling with flexible nonlinear models", "is_meta_review": false, "comments": "The authors propose a recurrent variational neural network approach to modelling volatility in financial time series. This model consists of an application of Chung et al.\u2019s (2015) VRNN model to volatility forecasting, wherein a Variational Autoencoder (VAE) structure is repeated at each time step of the series. \n\nThe paper is well written and easy to follow (although this reviewer suggests applying a spelling checking, since the paper contains a number of harmless typos). \n\nThe paper\u2019s main technical contribution is to stack two levels of recurrence, one for the latent process and one for the observables. This appears to be a novel, if minor contribution. The larger contribution is methodological, in areas of time series modelling that are both of great practical importance and have hitherto been dominated by rigid functional forms. The demonstration of the applicability and usefulness of general-purpose non-linear models for volatility forecasting would be extremely impactful.\n\nI have a few comments and reservations with the paper:\n1) Although not  mentioned explicitly, the authors\u2019 framework are couched in terms of carrying out one-timestep-ahead forecasts of volatility. However, many applications of volatility models, for instance for derivative pricing, require longer-horizon forecasts. It would be interesting to discuss how this model could be extended to forecast at longer horizons.\n \n2) In Section 4.4, there\u2019s a mention that a GARCH(1,1) is conditionally deterministic. This is true only when forecasting 1 time-step in the future. At longer horizons, the GARCH(1,1) volatility forecast is not deterministic. \n\n3) I was initially unhappy with the limitations of the experimental validation, limited to comparison with a baseline GARCH model. However, the authors provided more comparisons in the revision, which adds to the quality of the results, although the models compared against cannot be considered state of the art. It would be well advised to look into R packages such as `stochvol\u2019 and \u2018fGarch\u2019 to get implementations of a variety of models that can serve as useful baselines, and provide convincing evidence that the modelled volatility is indeed substantially better than approaches currently entertained by the finance literature.\n\n4) In Section 5.2, more details should be given on the network, e.g. number of hidden units, as well as the embedding dimension D_E (section 5.4)\n\n5) In Section 5.3, more details should be given on the data generating process for the synthetic data experiments. \n\n6) Some results in the appendix are very puzzling: around jumps in the price series, which are places where the volatility should spike, the model reacts instead by huge drops in the volatility (Figure 4(b) and (c), respectively around time steps 1300 and 1600). This should be explained and discussed.\n\nAll in all, I think that the paper provides a nice contribution to the art of volatility modelling. In spite of some flaws, it provides a starting point for the broader impact of neural time series processing in the financial community.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "25 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "Lack of smoothing for learning and lack of novelty", "is_meta_review": false, "comments": "\nThe authors propose a recurrent neural network approach for constructing a\nstochastic volatility model for financial time series. They introduce an\ninference network based on a recurrent neural network that computes the\napproximation to the posterior distribution for the latent variables given the\npast data. This variational approximation is used to maximize the marginal\nlikelihood in order to learn the parameters of the model. The proposed method\nis validated in experiments with synthetic and real-world time series, showing\nto outperform parametric GARCH models and a Gaussian process volatility model.\n\nQuality:\n\nThe method proposed seems technically correct, with the exception that in\nequation (19) the inference model is doing filtering and not smoothing, in the\nsense that the posterior for z_t' only depends on those other z_t and x_t\nvalues with t", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "TITLE": "An interesting application of RNN generative model to financial data", "is_meta_review": false, "comments": "Thank you for an interesting read.\n\nI found the application of VRNN type generative model to financial data very promising. But since I don't have enough background knowledge to judge whether the performance gap is significant or not, I wouldn't recommend acceptance at this stage. \n\nTo me, the biggest issue for this paper is that I'm not sure if the paper contains significant novelty. The RNN-VAE combination has been around for more than a year and this paper does not propose significant changes to it. Maybe this paper fits better to an application targeting conference, rather than ICLR. But I'm not exactly sure about ICLR's acceptance criteria, and maybe the committee actually prefer great performances and interesting applications?", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "14 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Lack of heavy tails in the 1 step-ahead predictive distribution of GARCH and evaluation approach", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "IS_META_REVIEW": false, "DATE": "08 Dec 2016", "is_meta_review": false}, {"TITLE": "comparison to recent methods", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "", "IS_META_REVIEW": false, "DATE": "29 Nov 2016", "is_meta_review": false}], "SCORE": 5, "authors": "Rui Luo, Xiaojun Xu, Weinan Zhang, Jun Wang", "KEYWORDS": "A novel integration of statistical models with recurrent neural networks providing a new way of formulating volatility models.", "accepted": false, "id": ""}
