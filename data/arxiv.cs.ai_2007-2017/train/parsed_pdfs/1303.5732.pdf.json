{
  "name" : "1303.5732.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Modification to Evidential Probability",
    "authors" : [ "Biilent Murtezaoglu", "Jerry Feldman", "Henry E. Kyburg" ],
    "emails" : [ "t@cs.rochester", "burg@cs." ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 Overview of the Problem\n1.1 An Example\nLet us consider a variant of the classic berries example.1 Suppose a hungry agent has access to the following information:\n• Between 70 and 90 percent of the red berries, sam pled at some time in the past, were found to be good to eat.\n• Between 30 and 50 percent of the berries picked on rainy days were found to be good to eat.\n• Between 70 and 75 percent of berries from this region, sampled at some time in the past, were found to be good to eat.\n• Between 35 and 45 percent of soft berries, sampled at some time in the past, were found to be good to eat.\n• The berries at hand now are both red and soft and picked from this region and furthermore today is a rainy day.\n1 Due to Jerry Feldman.\nThe agent's problem is deciding whether or not it should eat the berries it has. This decision involves two distinct levels of analysis; the first one is decid ing what indeed it can infer from its knowledge about berries in general about the particular berries it has, and the second one is, given its inferred knowledge about the berries it has, whether or not it should eat them.\nIt may be argued that de-coupling the inference and the decision procedures generally leads agents into lengthy computations even when the relevant utility values and practical concerns would dictate a certain decision, rendering the sophisticated inference proce dure futile. In the example the agent may be making a choice between starvation and food poisoning and therefore the utilities involved with the choices would, for a sane agent, dictate that it should eat the berries regardless of what it can infer about their edibility. We will not, however, concern ourselves with such is sues in this paper because the proposed method for this restricted case is computationally cheap.\nIn the example above, the agent has no knowledge of the subset relationships between the candidate refer ence classes. For instance, if it knew that the reel berries that it has statistics about were in fact both reel and soft, it could safely disregard the conflicting2 statistics about soft berries [Kyburg, 1983]. Or if it had access to the joint information about reel and soft berries found in this region on rainy days, it would not need to consider the conflicting statistics about the broader classes according to both Reichenbach and Kyburg. Our agent, however, does not have all the necessary bits of information conveniently available.\n1.2 The General Case\nSuppose we want to compute the probability of some object o having a target property T, and we have knowledge about the classes o belongs to and the in-\n2 Confiict, or disagreement, between two intervals [PI, ql] and [1'2. ,,,] is defined as the case where neither [PI, q,] <;:; [p,, q,] nor [p,, q,] <;:; (p1, q,].\nterval valued measure ofT in those classes. l\\1ore for mally, our knowledge base contains the following state n1ents:\n• Sentences denoting set memberships \"x E Y\" where >: is an object andY is a set.\n• Sentences denoting subset relationships classes \"Y C Z\" where Y and Z are sets. between\n• Sentences concerning proportions of sets of the form \"%(T, S) == [p, q ]\" where T and S are sets and p and q are some ap proximate representation of real numbers. These can be read as \" the measure or the proportion of elements of set S that have the property T is in the interval �,, q].\"\nUsing the above syntax and assumptions, we can state the general problem as follows\n• Tile knowledge base contains the sentences \"% (T, S1) == [p1, q1]\", \"% (T, S2) = [p2, q2]\", \"% (T, S3) = [p3, q3]\", ... , \"%(T,Sn-d = [Pn-1,qn-1]\", \"%(T,Sn) = [Pn,qn]\"\n• and either contains or entails through subset chaining the sentences \"oES1\" ,\"oES2\" ,\"oES3\" , . . . ,\"oESn-1\" \"o E Sn \"\n• We are interested in finding the probability of \"o E T\"\nSo S1, S2, S3, . . . , Sn-1, Sn are all candidate reference classes for the query. We are assuming that no other knowledge is available; in particular, knowledge about subset relationships between si 's is not available. If all the intervals [pi, qi] nest within each other, the so lution is trivial: the candidate with the narrowest in to·val would be the answer to the query. If, on the other hand, there are conflicts between the intervals, we cannot establish dominance using Kyburg's original rules [Kyburg, 1983] since we do not have the neces sary information about the subset relationships. One could give up and return the interval [0, 1] or resort to constructing various subsets of the cross products of the candidate reference classes. The first method is useless, 3 and variations of the second method admit clear-cut counter-examples [Kyburg, 1991].\n3Though it should be noted that we cannot establish better bounds on the interval by purely set theoretic pro cedures. It is entirely possible for the probability to be high for two candidate reference classes but very low in their intersection and vice versa. In other words1 since we do not how anything about the structures of or the relationsl1ips between the candidate reference classes, set\nKyburg used to endorse Loui's approach using sub sets of the cross products [Loui, 1986, Kyburg, 1987] , but he has changed his mind in recent years [Kyburg, 1991]. He argues that the strongest interval we can justifiably return is the narrowest interval cover that does not conflict with any member of the set of rele vant intervals. More formally, given a set of intervals where each member of the set conflicts with at least one other member, we construct an interval using the minimum of the lower endpoints and the maximum of higher endpoints. If there are wide intervals that don't conflict with any other interval in the original set, they can safely be disregarded since they are guaranteed to be as weak or weaker than the narrowest interval cover of the conflicting ones. Thus, in the berries example Kyburg would return the interval [0.30, 0.90] (fig. 1).\n2 The Proposed Solution\nOne can think of the procedure proposed in [Kyburg, 1991] as looking at pairs of candidate reference classes and constructing new candidates by taking the interval covers of the conflicting pairs as a means of settling the conflicts.4 This procedure can be repeated until there is an interval that does not conflict with any of the others. An inefficient but nevertheless illustrative way of computing the interval cover Kyburg would select is given by the following pseudo-code: 5\ntheory does not help us come up with non-trivial bounds for their intersection which the object belongs to.\n4 Nate that we do not have enough data to choose one candidate over another.\n5Since no information about the subset relationships be tween the classes is available, we will deal only with the intervals associated with the classes. Even when enough information is available for using Kyburg's rules, it is con ceivable that one could end up with a set of candidates rather than a single reference class. So the proposed pro cedure can be used as the last step of Kyburg's method in the general case.\n230 Murtezaoglu and Kyburg\nAlg. 1 A! g. 2\n0.0 0.5 1.0\nAs can be noticed from the pseudo-code, inter vals that are no longer candidates (i.e., they are \"marked\") can still interfere with the selection of other intervals. One upshot of this is that individ ual \"marked\" intervals prevent the selection of a nar rower cover even when their own cover would not have interfered. This interference from wide intervals is not desirable because it leads us to weaker con clusions. For example, if our set of intervals were {[0.3, 0.4], [0.0, 0.5), [0.4, 0.7), [0.4, 1.0]} (Fig. 2), we would have to return [0.0,1.0), but if we look at the set £' after the first iteration of the algorithm ( {[0.3, 0.7], [0.3,1.0], [0.0,0.7], [0.0,1.0]}), it is apparent that [0.3,0.7] is not challenged by any other interval con structed in this iteration. Now, favoring [0.3,0.7] over the conservative but useless [0.0,1.0] is appealing be cause it leads to a stronger result, but can we justify doing so? We can if we are willing to say that inter val covers reflect the information represented by their constituents. In the case of two con!licting intervals [0.0,0.5] and [0.4,0.7), we might argue that the cover [0.0,0.7] encodes all we know, given those two bits of information. If we do not go back and look at its constituents, the cover [0.0,0.7] does not interfere with the stronger cover [0.3,0.7] even though its constituents ([0.0,0.5] and [0.4,0.7]) would.\nConsidering the presence of confiicting evidence, the widening caused by taking covers of intervals is desir able in terms of the semantics one would like to at-\ntribute to intervals. Intuitively, one does expect con flicting piceces of evidence to weaken the conclusions, and the interval cover idea nicely captures that intu ition. One may not, however, want the weak pieces of evidence to undermine the stronger conclusions in dicated by the stronger pieces of evidence with which they are consistent. One way of preventing the weaker evidence from interfering is to disregard or delete the original intervals once we construct all the covers they cause to be constructed. On the other hand, one wants to use all the information available, and actually delet ing the constituents once the cover is constructed is not compatible with that ideal. It is not, however, alto gether unreasonable to buy into the former argument while keeping the latter in mind. While professing ig norance is a virtue, one should also be able to make the best of available information.\nAs is the case with Kyburg's method in [Kyburg, 1991], the reference class associated with the inter val we return can be any one of the candidate classes associated with the constituents of the cover.\nThe modified algorithm, which leads to less conserva tive conclusions, is as follows:\nAlgorithm 2\ninput: a set £. of intervals I; repeat\nC' := {} for every interval pair I,= [p;, qi], I1 = [J•,, q1] inC\nif I; conflicts with IJ then I':= [min(p;,p,),max(q;,q1)] C' := C' u {I'} mark both I; and I,\ndelete all the marked elements of C c :=cue'\nuntil C' = {} return the nan·owest un-mm·ked interval in C\nThis algorithm returns the narrowest interval cover whose set of constituents S � £ has the property that for any interval I E £- S, there is an interval I* E S that nests in and is at least as narrow as I. Having made that observation, we can write a more efficient version of the algorithm which illustrates this point.\nAlgorithm 2'\ninput: a list C of intervals I; sorted in ascending order of widtl C' := {} repeat\nextract the first unmarked interval I' from C C' := C' u {I*} for every remaining un-marked interval] in L\nif I agrees with I' then mark I\nuntil there are no more un-marked intervals in £. return interval cover of the intervals in C'\no.o 0.5 1.0\n-------------------------,\n�==------! ' ' �-------------------------: ,------------------------------�\n' ' ' ' ' ' ' ' ' ' ' '- ----------------------------- -�\n,.------------------- I ' ' ' ' ' ' ' ' ' -- ' �-----------------------)\nAJg. J •oooouooooouoouoo .. oooooooooonooouuu-oooooooooooooooooooooooooooooooooooooooooooooooo\nAlg. 2 ................................... ·-··········--····-···\nFigure 3: A picture of a more general case with many intervals. The dashed boxes represent sets of intervals with a common narrow sub-interval, which is denoted by a thick line.\n0.0 0.5 lD\nFigure 4: The case where there are no conflicts be tween the candidates.\nOne can think of each J* selected in the algorithm as representing the opinion of an independent agent who has access only to the set of intervals S* <;:; £ such that for every interval I E S*, I* <;:; I (Fig. 3). The cover of all such J* would give us the interval on which all such agents would agree6 Once again, the point can be made that those agents would not hold those opinions if they had access to what the other agents knew.\n2.1 Observations\nThe interval returned by the modified algorithm is never in conflict with the one returned by the origi nal and is at least as narrow. The modified algorithm does return the same result as the original in such cases as the following:\n• \\\"!hen there is no conflict between members of the original set of candidate intervals (Fig. 4). This is the most desirable case in that neither algorithm uses evidence combination to obtain a result.\n• \\Vhen there are no two nesting intervals in the original set of candidates (Fig. 5). Having no agreement at all among the pieces of evidence indicates that a very conservative conclusion is called for.\n6N ote that we are not requiring all members of S*'s to agree with each other.\n0.0\nA Modification to Evidential Probability 231\n0.5 1.0\n�==�--�------�\nFigure 5: The case where none of the candidates agree.\n• \\Vhen the set of narrowest intervals have members that are at the extreme ends of the wider intervals in which they nest (Fig. 6). As can be seen in the figure, having strong but extremely conflicting evidence leads to weak results.\n3 Conclusions\nAvoiding interference from conflicting unreliable data is a problem for autonomous agents except. when the designer can hand pick the relevant information. \\\"'e think playing it safe with large amounts of conflicting data causes pieces of weak evidence to unnecessarily weaken the results of the inference process. The pro posed algorithm leads to stronger results by favoring stronger conclusions when there is enough data to jus tify them.\nAcknowledgments\nResearch underlying this work has been supported in part by U.S. Army Communication-Electronics Com mand grant no. DAAD10-87-K-022, and NSF research grant no. IRI-9002659.\nReferences\n[Kyburg, 1983] Henry E. Kyburg, Jr. The reference class. Philosophy of Science, 50:374-397, 1983.\n[Kyburg, 1987] Henry E. Kyburg, Jr. Bayesian and non-bayesian evidential updating. AI Journal, (31):271-294, 1987.\n[Kyburg, 1991] Henry E. Kyburg, Jr. Evidential prob ability. In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (IJCAI91), 1991.\n[Loui, 1986] Ronald P. Loui. Computing reference classes. In AAAI Uncertainty Workshop, 1986."
    } ],
    "references" : [ {
      "title" : "Philosophy of Science",
      "author" : [ "Henry E. Kyburg", "Jr. The reference class" ],
      "venue" : "50:374-397,",
      "citeRegEx" : "Kyburg. 1983",
      "shortCiteRegEx" : null,
      "year" : 1983
    }, {
      "title" : "AI Journal",
      "author" : [ "Henry E. Kyburg", "Jr. Bayesian", "non-bayesian evidential updating" ],
      "venue" : "(31):271-294,",
      "citeRegEx" : "Kyburg. 1987",
      "shortCiteRegEx" : null,
      "year" : 1987
    }, {
      "title" : "Evidential prob­ ability",
      "author" : [ "Henry E. Kyburg", "Jr" ],
      "venue" : "Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (IJCAI91),",
      "citeRegEx" : "Kyburg. 1991",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "Computing reference classes",
      "author" : [ "Ronald P. Loui" ],
      "venue" : "AAAI Uncertainty Workshop,",
      "citeRegEx" : "Loui. 1986",
      "shortCiteRegEx" : null,
      "year" : 1986
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "For instance, if it knew that the reel berries that it has statistics about were in fact both reel and soft, it could safely disregard the conflicting2 statistics about soft berries [Kyburg, 1983].",
      "startOffset" : 182,
      "endOffset" : 196
    }, {
      "referenceID" : 0,
      "context" : "If, on the other hand, there are conflicts between the intervals, we cannot establish dominance using Kyburg's original rules [Kyburg, 1983] since we do not have the neces­ sary information about the subset relationships.",
      "startOffset" : 126,
      "endOffset" : 140
    }, {
      "referenceID" : 2,
      "context" : "The first method is useless, 3 and variations of the second method admit clear-cut counter-examples [Kyburg, 1991].",
      "startOffset" : 100,
      "endOffset" : 114
    }, {
      "referenceID" : 2,
      "context" : "Kyburg used to endorse Loui's approach using sub­ sets of the cross products [Loui, 1986, Kyburg, 1987] , but he has changed his mind in recent years [Kyburg, 1991] .",
      "startOffset" : 150,
      "endOffset" : 164
    }, {
      "referenceID" : 2,
      "context" : "One can think of the procedure proposed in [Kyburg, 1991] as looking at pairs of candidate reference classes and constructing new candidates by taking the interval covers of the conflicting pairs as a means of settling the conflicts.",
      "startOffset" : 43,
      "endOffset" : 57
    }, {
      "referenceID" : 2,
      "context" : "As is the case with Kyburg's method in [Kyburg, 1991], the reference class associated with the inter­ val we return can be any one of the candidate classes associated with the constituents of the cover.",
      "startOffset" : 39,
      "endOffset" : 53
    } ],
    "year" : 2011,
    "abstractText" : "Selecting the right reference class and the right interval when faced with conflicting candidates and no possibility of establish­ ing subset style dominance has been a prob­ lem for Kyburg's Evidential Probability sys­ tem. Various methods have been proposed by Loui and Kyburg to solve this problem in a way that is both intuitively appealing and justifiable within Kyburg's framework. The scheme proposed in this paper leads to stronger statistical assertions without sacri­ ficing too much of the intuitive appeal of Ky­ burg's latest proposal. 1 Overview of the Problem",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}