{
  "name" : "1705.05720.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Subjective Knowledge Acquisition and Enrichment Powered By Crowdsourcing",
    "authors" : [ "Rui Meng Hao", "Xin Lei Chen", "Yangqiu Song" ],
    "emails" : [ "rmeng@cse.ust.hk", "hxinaa@cse.ust.hk", "leichen@cse.ust.hk", "yqsong@cse.ust.hk" ],
    "sections" : [ {
      "heading" : "1. INTRODUCTION",
      "text" : "Motivation. In recent years, knowledge bases (KBs) have become increasingly popular and large-scale KBs have been constructed, such as Freebase [2], DBpedia [17], YAGO [10], KnowItAll [8], etc. The KBs encode information and knowledge of the real world in a structured, machine-understandable way which can empower various kinds of applications, especially Web and mobile search. Despite of containing millions of knowledge facts on large amount of entities and relations, the knowledge encoded by these KBs is limited in objective dimension. In other words, existing KBs have so far focused on encoding objective knowledge facts, which are factual and observable, such as FRUIT SHAPE, MOVIE DIRECTOR and so forth. In contrast, many real world queries are subjective, e.g., around 20% of product-related queries are labeled as\nbeing “subjective” by workers [19], 63% of location-based queries in mobile search are asking for subjective opinions [7], and need the corresponding subjective knowledge as the query answers. For example, there might exist such queries, “popular American singers” or “beautiful cities in Europe”, we refer the knowledge concerning popular singers and beautiful cities as the subjective knowledge. More specifically, subjective knowledge refers to the dominant opinion about whether a particular subjective property applies to entities of a particular type [25]. For instance, given a pair consists of a subjective property1 and a type from a KB (subjective property-type pair, ST pair), e.g., POPULAR and SINGER, we can find a list of instances of the type SINGER from the KB, e.g., ELVIS PRESLEY, where the dominant opinion of “whether Elvis Presley is a popular singer” is a piece of subjective knowledge. As this kind of information is missing in existing KBs, queries concerning such information cannot be satisfied. Fortunately, crowdsourcing, which has been recently proved to be successful for various human intrinsic tasks such as entity resolution [28], knowledge extraction [13], translation [31], etc., provides a natural and reliable way of obtaining the subjective knowledge by collecting opinions from workers.\nMany works have been done to perform KB enrichment, completion and population [9] [29] [4] [12] [11], but none of these works focus on the subjective dimension. For subjective knowledge acquisition, the state-of-the-art approach is to use information extraction techniques to mine the text of Web contents [25]. However, it only relies on machine-based technique and online Web data, and does not consider to incorporate the wisdom of the crowd and existing KB information. Thus, the precision is far from satisfactory, i.e. SURVEYOR has the precision of 77% [25]. To the best of our knowledge, we are the first to leverage the collaborative knowledge from both the crowd and existing KBs to perform subjective knowledge acquisition and KB enrichment in the subjective dimension.\nChallenge. Leveraging the power of the crowd for knowledge acquisition comes with the challenge of “How to resolve the conflict between large scale knowledge facts and the limited crowdsourcing resource?”. Real world KBs are often in very large scales, e.g., YAGO has 2,747,873 entities and 292,898 types, DBpedia has 2,531,369 entities and 827 types, while each crowdsourcing operation is associated with a monetary cost and is somewhat timeconsuming. Therefore, it is infeasible and costly to ask the crowd to carry the whole burden of subjective knowledge acquisition task. In our system CoSKA, we make use of the knowledge in existing KBs and the semantic relationship among subjective properties to perform knowledge inference and based on the inference power, the most beneficial questions are identified for crowdsourcing.\nFramework. The input of CoSKA is a list of ST pairs mined from the corpus and a KB. The output is a list of subjective knowl-\n1Typically expressed as an adjective\nar X\niv :1\n70 5.\n05 72\n0v 1\n[ cs\n.D B\n] 1\n6 M\nay 2\n01 7\nedge facts and enriched KB. CoSKA consists of three stages: ST pair selection, crowdsourced ST pair applying, and knowledge inference. The details of the framework is shown in Figure 1.\n1) ST Pair Selection: Given the large amount of ST pairs, we need to identify the benefit of each pair and select them judiciously for subsequent crowdsourced ST pair applying as the process needs the involvement of crowd workers. We first define some subjective knowledge inference rules. Then the ST pair selection problem is formulated as a Maximum Knowledge Inference Problem. We show that the problem is NP-hard and propose a diversity-aware forward greedy algorithm for ST pair selection.\n2) Crowdsourced ST Pair Applying: For each selected ST pair, the task of subjective knowledge acquisition is to identify the opinions that whether the subjective property can be applied to the instances of the type powered by crowdsourcing, referred as crowdsourced ST pair applying. However, asking the crowd for every instance is still too costly as a type could contain hundreds of thousands instances. In order to improve the scalability of the knowledge acquisition task, we formulate the crowdsourced ST pair applying as a binary classification problem. The objective knowledge of instances in existing KBs is selected as the features. We adopt a representative sampling strategy to sample a set of instances to ask the crowd and the classifier is trained based on the collected answers.\n3) Knowledge Inference: After the crowdsourced ST pair applying process, we have acquired a set of subjective knowledge facts. To further improve the scalability of our system and derive more subjective knowledge facts, we perform knowledge inference based on the subjective inference rules.\nThe acquired and inferred knowledge can be encoded into existing KBs to perform KB enrichment in the subjective dimension.\nIn summary, the contributions of our work are as follows:\n• We propose the problem of crowdsourced subjective knowledge acquisition and perform knowledge base enrichment in the subjective dimension, which bridges the gap between the subjective queries and existing knowledge bases encoding only objective knowledge.\n• We describe and implement our CoSKA system, consists of ST pair selection, crowdsourced ST pair applying and knowledge inference, for crowd-powered subjective knowledge acquisition.\n• We define subjective knowledge inference rules among ST pairs and formulate the ST pair selection problem as a Maximum Knowledge Inference Problem. We prove the problem is NP-hard and propose a diversity-aware forward greedy algorithm for ST pair selection.\n• To further resolve the conflict between large scale knowledge facts and the limited crowdsourcing resource, we formulate\nthe crowdsourced ST pair applying problem as a classification task and derive more knowledge facts based on the crowdsourced seed knowledge.\n• We conduct extensive experiments using real large-scale knowledge base and crowdsourcing platform and verify the effectiveness of CoSKA system.\nThe rest of the paper is organized as follows. In Section 2, we introduce preliminaries and give the formal definitions of subjective knowledge acquisition and enrichment. In Section 3, we present the methodology for ST pair selection. In Section 4, we describe the models for crowdsourced ST pair applying. The crowdsourcing mechanism design is illustrated in Section 5. Section 6 shows the experimental results on real KBs and crowdsourcing platform. The related works are introduced in Section 7. We conclude our work in Section 8."
    }, {
      "heading" : "2. PROBLEM DEFINITION",
      "text" : "A knowledge base is a repository of storing entities and relations in a real world scenario. Similar with [16], knowledge base is formally defined as follows.\nDEFINITION 1 (KNOWLEDGE BASE). A knowledge base KB is a tuple denoted by (E,L,R, P ), consisting of a collection of entities E, literals L, relations R holding between entities, and properties P holding between entities and literals. An entity e ∈ E can be a class or an instance.\nFigure 2 shows a toy example of a knowledge base. There are six entities - three classes, e.g., “lawyer”, “politician”, and “president”, and three instances, e.g., “Obama”, “Michelle ”, and “Gorge W. Bush”; the date “1961-8-4” and string “Barack Obama” are literals; there are three relations (“type”, “married”, and “subclassOf”) and two kinds of properties (“birthDate” and “fullName”).\nDEFINITION 2 (OBJECTIVE KNOWLEDGE). Objective knowledge is a fact of triple< s, po, o >, where s is an entity in a knowledge base, p is an objective property, and o is either an entity or a literal. Objective knowledge recording the real world facts, which is factual and observable.\nAs shown in the toy example of a KB of Figure 2, there are eight objective knowledge facts, e.g. < Obama, birthDate, “1961-8-4′′ > and < president, subclassOf, policitian >.\nAs mentioned in Section 1, the subjective knowledge refers to the dominant opinion about whether a particular subjective property applies to entities of a particular type [25]. Therefore, the combination of a subjective property and a certain type should be\nfigured out for subsequent subjective knowledge acquisition. We define it as the ST pair (subjective property-type pair).\nDEFINITION 3 (ST PAIR). An ST pair consists of a subjective property and a type, which corresponds to a class entity in the knowledge base, i.e. ST = (ps, T ). An ST pair for knowledge acquisition task indicates that the subjective property ps can be applied to the type T , namely, can be applied to the instances of the type T .\nFor example, an ST pair, ST = (big, City) indicates that the entities of the City type have the subjective property of big. Same for the ST pairs like (cute,Animal), (popular, Sport) and etc.\nDEFINITION 4 (SUBJECTIVE KNOWLEDGE). A subjective knowledge fact is a triple denoted by< s, ST, l >, where s is an entity in a knowledge base, ST is an ST pair consists of a subjective property and a type, and l is a label with value either be true or false.\nThe subjective knowledge has no ground truth, instead it has a dominant opinion which can be used to derive such knowledge. For example, if most people hold the opinion that “New York is a big city”, then we can derive a new subjective knowledge fact < NewY ork, (big, City), true >; otherwise, we will derive a new subjective knowledge fact < NewY ork, (big, City), false >.\nDEFINITION 5 (ST PAIR APPLYING). Given an ST pair, ST =< ps, T >, consists of a subjective property ps and a type T , and a knowledge base KB, ST pair applying refers to the process of deciding whether ps can be applied to the instances of type T in the KB, and the result is a list of subjective knowledge facts, Fs = {F1, F2, · · · , Fm}, where Fi = {ei, ST, l}.\nGiven a list of ST pairs, subjective knowledge acquisition refers to the process of performing ST pair applying for all the input ST pairs. The derived knowledge can be encoded into the existing KB to perform KB enrichment in the subjective dimension.\nDEFINITION 6 (SUBJECTIVE KNOWLEDGE ENRICHMENT). Given a knowledge base KB consisting objective knowledge facts FO , a list of ST pairs, ST = {ST 1, ST 2, · · · , STm}, the target is to enrich theKB with a list of subjective knowledge facts FS by performing subjective knowledge acquisition for the ST pairs.\nWe employ crowdsourcing for the subjective knowledge acquisition, specifically for the ST pair applying process. Due to the limited crowdsourcing resource, we need to crowdsource in an efficient and productive manner. In other words, for crowdsourced subjective knowledge acquisition, our target is to maximize the acquired knowledge under the crowdsourcing budget. Next, we define the Crowdsourced Subjective Knowledge Acquisition problem.\nDEFINITION 7 (CROWDSOURCED SUBJECTIVE KNOWLEDGE ACQUISITION). Given a list of ST pairs, a knowledge base and a crowdsourcing budget k (e.g. the number of crowdsourcing operation or monetary budget). The Crowdsourced Subjective Knowledge Acquisition (CoSKA) problem is to perform ST pair applying operations to acquire new subjective knowledge facts powered by crowdsourcing. The target is to maximize the number of derived knowledge facts under the given budget k.\nAs described in Section 1, we propose a three stage approach for CoSKA: ST pair selection, crowdsourced ST pair applying and knowledge inference. In next sections, we illustrate the details of each stage."
    }, {
      "heading" : "3. ST PAIR SELECTION",
      "text" : "In this section, we describe the ST pair selection problem concerning the knowledge inference power. We first introduce the ST pair extraction method; then, we introduce the subjective resemble relationship among ST pairs and define the knowledge inference rules based on the relationship. We then formulate the ST pair selection problem as a Maximum Knowledge Inference Problem which is NP-hard and propose a diversity-aware forward greedy algorithm for ST pair selection."
    }, {
      "heading" : "3.1 ST Pair Extraction",
      "text" : "As described, the input of our system CoSKA is a set of ST pairs, and an ST pair consists of a subjective property which is usually an “adjective” and a type which is usually a “noun phrase” and corresponds to a type (class) entity in the KB. For example, a pair of (big, city) is an ST pair as the big is an adjective and city can be mapped to a class entity in the knowledge base. In order to derive the commonly used ST pairs, we perform extraction from the news from New York Times. We use three years’ data which contains 167,958 news and 582,898,171 sentences. We process the data using NLP tools to identify adjective and noun phrase pairs. Similar with work [25], we use the synthetic patterns to extract information, i.e. ST pairs, from matched sentences. The pattern we adopted is shown in Figure 3. For example, given a sentence of “Snakes are dangerous animals”, an ST pair of < dangerous, animal > are extracted and the ST pair of < successful, film > can be extracted from sentence “Titanic is the most successful film of all time”.\nAfter extraction using the pattern, we map the type from the extracted pairs to the given knowledge bases through textual similarity and filter out pairs that have no mapped class entity. In total, there are 40,582 mapped ST pairs with DBpedia."
    }, {
      "heading" : "3.2 ST Pair Selection",
      "text" : "In order to reduce the number of ST pairs for crowdsourced subsequent ST pair applying and identify the most productive ST pairs in terms of the knowledge inference power. We define the Subjective Resemble Relationship among ST pairs as follows:\nDEFINITION 8 (ST PAIR SUBJECTIVE RESEMBLE RELATIONSHIP). Given two ST pairs , ST1 = (ps1, T1), ST2 = (p s 2, T2), a knowledge base KB and an object e, we define that ST1 and ST2 have the subjective resemble relationship on e, denoted as ST1 ≈e ST2 if the following condition satisfies:\n• Object e is an instance of both types , i.e., e ∈ Ikb(T1)∧ e ∈ Ikb(T2), where Ikb(T ) denotes the instances of type T in the KB.\n• There exist a “subclassOf” relationship among two types in the KB, denoted as < T1, subclassOf, T2 >∈ F(KB)∨ < T2, subclassOf, T1 >∈ F(KB).\n• If the two subjective properties are the same, synonymous or antonymous, denoted as ps1 ≈ ps2. If two subjective properties are synonymous or same, we have ps1 ≈+ ps2 and ps1 ≈− ps2 for antonymous.\nNote that there are two kinds of subjective resemble relationships, ST1 ≈+e ST2 and ST1 ≈−e ST2 , we have ST1 ≈+e ST2 if ps1 ≈+ ps2 and ST1 ≈−e ST2 if ps1 ≈− ps2.\nIf two ST pairs have the subjective resemble relationship on an entity, we can perform knowledge inference using the knowledge inference rule:\nLEMMA 1 (KNOWLEDGE INFERENCE RULE). If we have a knowledge fact ofF = {e, ST1, l} and two ST pairs where ST1 =< ps1, T1 >, ST2 =< p s 2, T2 >:\n• If ST1 ≈+e ST2, a new knowledge fact of F ′ = {e, ST2, l} can be inferred\n• If ST1 ≈−e ST2, a new knowledge fact of F ′ = {e, ST2, l′} can be inferred, where l′ = ¬l\nNext, we illustrate the ST Pair Subjective Resemble Relationship and the Knowledge Inference Rule through the following example.\nEXAMPLE 1. Given a knowledge base KB, four ST pairs, i.e., ST1 =< old, Politician >, ST2 =< young, President > , ST3 =< big, City >, ST4 =< large, City > and four instances e1={“Hillary Clinton”}, e2={“Barack Obama”} , e3={“New York”} and e4={”Los Angeles”}. Referring to the knowledge in KB, we have that: e1 is an instance of type “Politician”, e2 is an instance of type “Politician” and type “President”, and e3, e4 are instances of the type “City”, denoted as Type(e1)={“Politician”}, Type(e2)={“Politician”,“President”}, Type(e3)=Type(e4)={“City”}. Therefore, based on the Definition 8, we can have the following ST pair subjective resemble relationships:\n1). ST1 ≈−e2 ST2, as “young” and “old” are antonymous of each other, e2 is an instance of both type “President” and “Politician” and “President” is a subclass of “Politician” ;\n2). ST3 ≈+e3 ST4, as “big” and “large” are synonymous and the type of two ST pairs is “City” and e3 is an instance of “City”;\n3). Similarly, we also have ST3 ≈+e4 ST4\nBased on the ST pair subjective resemble relationships, we can infer new knowledge facts using the inference rule according to Lemma 1. If we have crowdsourced subjective knowledge facts of Fcr = {< e2, ST2, Y ES >,< e3, ST3, Y ES >} (“Barack Obama is a young president” and “New York is a big city”), we can get Finf =< e2, ST1, NO > (“Barack Obama is NOT an old politician”) and Finf =< e3, ST4, Y ES > (“New York is a large city”).\nBased on the subjective resemble relationship and the inference rule, we can construct a graph to model the ST pair subjective resemble relationship and the knowledge inference power.\nDEFINITION 9 (ST GRAPH MODEL). Given a knowledge base KB = (E,L,R, P ) and a set of ST pairsP = {ST1, ST2, · · · , STn}, we can construct a weighted graph G = {V,W}, where\n• Each vertex in V corresponds to an ST pair of P .\n• There is an undirected edge wij between node vi (STi) and vj (STj) if exists an instance e ∈ E(KB) and STi ≈e STj .\n• The weight of wij is the number of entities on which two corresponding ST pairs have the subjective resemble relationship, denoted as wij = |E| where, ∀e ∈ E , STi ≈e STj .\nFor the example shown in Example 1, we can have an ST graph with four vertices and two edges: G = {{v1, v2, v3, v4}, {w12, w34}}, where vi corresponds to STi and w12 = 1, w34 = 2.\nOur target of ST pair selection is to identify the most beneficial ST pairs for subsequent crowdsourced ST pair applying to increase the acquired subjective knowledge facts. In our work, based on the ST pair subjective resemble relationship and knowledge inference rules, we use the number of knowledge facts that can be inferred, i.e. the inference power, to measure the beneficial of selected ST pairs. Therefore, we formulate the ST pair selection problem as a Maximum Knowledge Inference Problem.\nDEFINITION 10 (MAXIMUM KNOWLEDGE INFERENCE PROBLEM). Given a knowledge baseKB and a set of ST pairs,P = {ST1, ST2, · · · , STm}, the target is to select k ST pairs to maximize the knowledge inference power.\nBased on the ST Graph Model defined in 9, the maximum knowledge acquisition problem is to select a set of nodes in the graph that maximize the total edge weight induced by the nodes. We can prove that the Maximum Knowledge Inference Problem is NP-hard by a reduction Densest k-Subgraph problem.\nTHEOREM 1. The Maximum Knowledge Inference Problem is NP-hard\nPROOF. Given an undirected graph G = (V,E), the Densest k-Subgraph (DkS) problem on G is the problem of finding a subset U ⊆ V of vertices of size k with the maximum induced average degree. The average degree of the subgraph will be denoted as 2|E(U)|/k. Here |E(U)| denotes the number of edges in the subgraph induced by U . We construct the instance of ST graph as follows: Given |V | ST pairs, each corresponds to a vertex inG, two ST pairs, STi, STj have the subjective resemble relationship on a single object if there is an edge between to corresponding nodes, vi, vj in G. Given the parameter k, the maximum knowledge inference problem is to select k nodes S∗ with maximum induced edge weight, ∑ e∈E(S∗)W (e) = |E(S\n∗)|. Therefore, under the same k, the optimal solution of the maximum knowledge acquisition problem is equivalent to that of Densest k-Subgraph problem\nThe maximum knowledge acquisition problem is NP-hard, a backwardgreedy strategy, which repeatedly removes a vertex with the minimum weighted-degree in the remaining graph, until exactly k vertices are left, has an worst case approximation ratio of [( 1\n2 + n 2k )2−\nO(n− 1 3 ), ( 1\n2 + n 2k )2 + O( 1 n )] for k in the range of [n 3 , n] and\n[2(n k −1)−O( 1 k ), 2(n k −1)+O( n k2 )] for k in the range of [0, n 3 ), where n is the number of vertex [1]. However, the backwardgreedy strategy is time consuming as it needs to iterate (|V | − k) times; moreover, the strategy does not consider the knowledge diversity, i.e. knowledge about different types, when making decisions, and therefore may results in top ST pairs share the same type. For example, in our experiment, we find that there are only two types from top 100 ST pairs by the backward-greedy strategy. In order to improve the efficiency and balance the subjective knowledge over various types, we propose a diversity-aware forward greedy strategy for ST pair selection: each time we select the pair with the maximum weight-degree, and add the pair to the result if the number of pairs with the same type does not exceed the given threshold.\nAlgorithm 1: Diversity-aware Forward Greedy Selection Input: ST Model Graph G = {V,W}, Parameter k and\nthreshold δ Output: A set of vertices S\n1 V ← ∅ 2 while |V| ≤ k do 3 v∗ ← argmaxv∈VWeightDegree(v) 4 T ← type(v∗) 5 if Num(V, T ) ≤ δ ∗ k then 6 V ← V ∪ v∗\n7 V ← V\\v∗\n8 return V\nThe procedure of the diversity-aware forward greedy algorithm is illustrated in Algorithm 1. There are k iterations (lines 2-7); in each iteration, we first pick the vertex with the maximum weightdegree (line 3); next, we check the number of vertices of the same type in the current result set, if the number dose not exceed the threshold, the vertex is added into the result set (lines 4-6). The complexity of Algorithm 1 is O(|V| · |W|)."
    }, {
      "heading" : "4. CROWDSOURCED ST PAIR APPLYING",
      "text" : "For a given ST pair, the task of subjective knowledge acquisition is to identify the dominant opinion of whether the subjective property can be applied to the instances of the type, referred as crowdsourced ST pair applying. However, asking the crowd for every instance is too costly as a type in a KB could contain hundreds of thousands instances. Therefore, we formulate the crowdsourced ST pair applying as a binary classification problem taking advantage of the knowledge in the KBs. For each instance, we decide whether the ST pair can be applied by the classification result.\nHowever, we do not have any labeled data for training the classifier. Therefore, we select a set of seed instances and ask the crowd to collect the corresponding subjective knowledge facts. We take the crowdsourced samples as the training data and train the classifier using the features extracted from the KB. As each type in a KB would have a set of properties/relations, we extract these properties/relations and list them in the crowdsourcing tasks, the crowd workers are also asked to mark which of the properties would affect the decision about whether the ST pair applies to the instances. Then, we filter out the properties/relations with votes less than a threshold and training the classifier on the remaining properties.\nWe adopt a representative sampling to sample the instances which explores the clustering structure of the large amount of unlabeled data and query the representative samples, i.e. samples from different clusters, as the training data. In our work, we cluster the instances using the knowledge from existing KBs and sample k instances for each ST pair."
    }, {
      "heading" : "5. CROWDSOURCING MECHANISM DESIGN",
      "text" : "In this section, we first describe the human intelligent task (HIT) interface of CoSKA, then we introduce the answer aggregation strategy.\nHIT Interface. Given an ST pair, we need to obtain the knowledge of whether a subjective property can be applied to the instances of the type. In order to reduce the cost, we design the task as a multiple choice question where each question contains 5 instances and the crowd worker is asked to select those that the given\nproperty can be applied. Furthermore, we list all the properties of the given type in each HIT and let the crowd worker to select the properties that would affect the decision. We compute the voting for each feature, and retain those with voting number exceeds the threshold (set through experimental studies) for further classification models. The HIT interface is shown in Figure 4. The illustrated HIT is for ST pair (big, City), we include five instances of the type “City” in each HIT, and ask the crowd to select the instances that has the attribute of “big”. Also, there are properties related to instances of type “City” in the KB, e.g., Country, areaLand, foundingDate, e.t.c, we list the properties and let the crowd workers to select relevant ones.\nAgreement-based Answer Aggregation. After all the HITs are answered, for each selected instance sample, we can collect a set of yes or no answers of whether the given subjective property can be applied to it. We compute the degree of the agreement on each task:\nA(I, ST ) = 1 |W | ∑ wi∈W V (I, wi) (1)\nwhere V (I, wi) = 1 if the worker answer is yes and 0 otherwise. The degree agreement of properties is computed in a similar way, and we retain the properties with agreement score at least θP as our subsequent classification features\nThe agreement score evaluates the confidence of the collected opinion among workers over the random answer. With the given threshold θA (which is set through experimental study, as the degree of agreement would vary with different ST pairs [25]), we derive the dominant opinion, denoted as (DO(I, ST )) of whether an ST pair ST applies to the instance I:\nDO(I, ps)= {\nyes if A(I, ST )− 0.5 ≥ θA no otherwise\n(2)\nAccording to Equation (2), we would obtain the positive opinion over the ST pair applies to an instance if the majority of the opinions is positive and this positive opinion has a high agreement (larger than θA)."
    }, {
      "heading" : "6. EXPERIMENTS",
      "text" : "In this section, we evaluate CoSkA on real knowledge base and crowdsourcing platform with extracted ST pairs. We describe the experimental setup in Section 6.1. Section 6.2 compares different methods for ST selection; Section 6.3 verifies the proposed approaches for crowdsourced ST pair applying; Section 6.4 shows the test results of the proposed knowledge inference approach.\n6.1 Experimental Setup\nKnowledge Base. We adopt DBpedia, which contains millions of knowledge facts (restricted to objective knowledge), classes (types) and instances as the KB in our experiments. The KB is represented as text files containing a list of triples of facts. The statistics DBpedia are given in Table 1. The KB offers information for mapping extracted ST pair to the KB types and subjective knowledge inference.\nCrowdsourcing Platform. We use the real crowdsorucing platform, Amazon Mechanical Turk (AMT) as the platform to conduct the subjective knowledge acquisition tasks. As mentioned in Section 5, each HIT is designed as a multiple choice question, each question is assigned to 5 workers and each worker would get a reward of $0.02 for answering the task. In addition, we would pay for the AMT platform $0.01 for each assignment. In our experimental settings, for each crowdsourced ST pair applying task, we would sample up to 200 instances. As illustrated in Figure 4, we include 5 instances in each HIT, therefore there are totally 200\n5 = 40 HITs\nwhich cost $6."
    }, {
      "heading" : "6.2 ST Pair Selection",
      "text" : "As illustrated in the Section 3, we adopt a diversity-based forward greedy algorithm in our work for ST pair selection (DivFGreedy). To evaluate the efficiency and the effectiveness of the propose algorithm, we use three metrics: 1). Induced Edge Weight of ST pairs, which indicates the inference power of selected ST pairs; 2). The number of different types of the ST pairs, which is used to evaluate the knowledge diversity; 3). Running time, which is recorded to demonstrate the efficiency of the algorithm. For comparison, we implement three other algorithms: backward greedy selection algorithm (BGreedy), forward greedy selection algorithm (FGreedy) and random selection algorithm (Random). We vary the number of selected ST pairs from 10∼100, and fix the threshold for the diversity-based forward greedy algorithm (Div-FGreedy) to 0.1 (the value of δ can be changed to satisfy the various diversity demand as the Div-FGreedy strategy can derive ST pairs with at least 1\nθ types), the results are shown in Figure 5.\nFrom Figure 5(a), we can find that the Random algorithm cannot achieve a good result, and the FGreedy and the Div-FGreedy algorithm outperform the BGreedy algorithm. We can observe that in our experiments, the FGreedy strategy has the best performance in terms of the inference power (induced edge weight). However, from Figure 5(b), we can see that the FGreedy algorithm would favor pairs with the same type as it does not consider the knowledge diversity, e.g. for the FGreedy algorithm, there would be only 5 types out of 100 selected ST pairs. The BGreedy strategy also has the same problem, e.g. the BGreedy only has 2 types out of 100 selected ST pairs. For the Div-FGreedy strategy, we have 16 types out of 100 selected ST pairs with the threshold set to 0.1. We can see that the Random strategy can select pairs with larger type numbers as it selects ST pairs randomly. However, it does not consider the inference power when selecting ST pairs and thus results in ST pairs with quite low inference power as shown in Figure 5(a). For the running time shown in Figure 5(c), we can observe that except for the BGreedy algorithm, all other three algorithms are quite efficient. To conclude, considering all three evaluation metrics, the Div-FGreedy algorithm can achieve a good inference power, guarantee the ST pair type diversity and is quite efficient.\n6.3 Crowdsourced ST Pair Applying\nFor crowdsourced ST pair applying, we need to ask the crowd for a set of seed subjective knowledge facts and train the classifier based on the collected samples and features. In our experiments, we select 5 ST pairs through Div-FGreedy algorithm as test cases to evaluate the accuracy of our approach 2. There are following configurations for the task: answer aggregation parameter θA, feature selection parameter θP and classification models, the settings are illustrated in Table 2, where we mark our default settings in bold font. As we have no ground truth, we use 5-fold cross validation to test the performance of our approach.\nEffect of Answer Aggregation Parameter. There are two parameters in terms of the answer aggregation: θA for opinion aggregation and θP for feature selection. We first fix θA = 0.1 (in our settings, θA = 0.1 means at lease 60% workers select the instance to have the given property), and vary the value of θP from 0.1∼0.5 to compare the classification accuracy. The results are shown in Figure 6 3. From the results, we can observe that the classification accuracy would change with various θP value, the reason is that different θP have different filter power, i.e. with larger value of θP , there would be less features remaining. Overall, the θP = 0.3 achieves best performance: from 0.1∼0.3, there is an increasing trend of the accuracy for three pairs (old,Building), (experienced,Athlete) and (popular,film), and for pair (cute,Animal), the accuracy does not have much difference; for larger values (0.3∼0.5), the accuracy would remain approximately the same. The reason is that the performance would change with different features (remained properties), and with lower value, less properties would be filtered therefore might retain those irrelevant properties as the training features.\nNext, we check the effect of θA on the classification accuracy. We set the θP to 0.3 and vary the values of θA according to Table 2, the classification accuracy results are illustrated in Figure 7. From the results we can observe that the classification models achieve best performance with the value of θA equals to 0.1, and would decrease as the value of θA increases. The reason is that with larger θA, we have stronger restriction for deriving the dominant opinion of whether the property applies to an instance. For example, in our settings, when θ = 0.5, we would only obtain the opinion that the property applies to the instance if all the 5 workers gives the “yes” answer, which might results in missing some positive training samples and affect the classification performance. Overall, the classification models achieve best performance with the value of θA to 0.1. Therefore, we set the default value of θA to 0.1.\nEffect of Classification Model. From the Figures 6 and 7, we can find that the performance of different classification models varies with different ST pairs. For pair (cute,Animal) different\n2Note that the workflow of crowdsourced ST pair applying is same for each ST pair, to acquire more knowledge facts, we can perform crowdsourced ST pair applying for a larger number of ST pairs 3Note that due to the space limit, we only show the results for four pairs and the result of (big,City) pair is summarized in Table 5\nmodels have similar performance; for pairs (old,Building) and (experienced,Athlete) the RBF-SVM achieves the best performance whereas for (popular,film), the DT model outperforms other approaches. We summarize the results of crowdsourced ST pair applying with the five pairs with all the parameters setting to the default value, the results are presented in Table 3. Overall, we can find that the RBF-SVM and DT model can achieve good performance for different ST pairs.\nTo justify the effectiveness of our approach for subjective knowledge acquisition, we compare our results with the state-of-the-art technique, Surveyor, proposed in [25]. The reported accuracy of the approach by Surveyor is 77%. Compared our results with the Surveyor approach, we can observe that except for the ST pair (cute,Animal), our approach can achieve better results, i.e. the pair (popular,Film) achieves accuracy of 79% and all the other three pairs can achieve the accuracy of over 80%. Therefore, our approach can perform accurate and scalable subjective knowledge acquisition with a low crowdsourcing budget (with up to 40 HITs and $6 for each ST pair)."
    }, {
      "heading" : "6.4 Knowledge Inference",
      "text" : "After the crowdsourced ST pair applying process, we have acquired a set of subjective knowledge facts, either collected from the crowd or obtained through the classification model. Then, we can perform knowledge inference to acquire more knowledge facts. Some resemble relationship of the selected ST pairs are shown in Table 4. In order to verify the effectiveness of our knowledge inference approach, we evaluate two metrics: the number of inferred facts and the accuracy of inferred facts. As we do not have the ground truth, we sample 100 facts for each pair and verify the correctness manually. We ask three students to label whether the fact is correct or not and derive the answer by majority voting. The results of the knowledge inference performance are shown in Table 5.\nFrom the results, we can observe that, on the one hand, large amount of knowledge facts could be inferred through the subjective knowledge inference approach; on the other hand, the inferred knowledge facts have high accuracy. Compare the accuracy results\nwith those presented in Table 3, we can observe that the inferred knowledge of each ST pair has close but higher accuracy than the facts acquired by crowdsourced ST pair applying, which confirms that our proposed knowledge inference process does not introduce significant noises and verifies the high quality of our knowledge inference rules. To conclude, our knowledge inference approach can help to derive more high quality knowledge facts compared with that only using the crowd and classification models in the crowdsourced ST pair applying process."
    }, {
      "heading" : "7. RELATED WORK",
      "text" : "In this section, we discuss the works related to subjective knowledge acquisition, knowledge base enrichment and crowdsourcing. Subjective knowledge acquisition is closely related to works that associating properties with entities. Some works have been conducted for commonsense knowledge acquisition [18] [15] [14] [24]. WebChild [23] presents a method for automatically constructing a large commonsense knowledge base, it contains triples that connect nouns with adjectives via fine-grained relations. Entitytagger [5], presented by Chakrabarti et al., automatically associate descriptive phrases, referred to as etags (entity tags), to each entity. Instead of subjective properties, these works focus on the less controversial and more objective properties, which is not related to obtaining dominant opinion. The most similar work is SURVEYOR, which mines the dominant opinion on the web content of whether a subjective property applies to a type. However, they does not consider to use the existing information in knowledge base and resorting to the crowd for subjective knowledge acquisition.\nValue of θ P\n0.1 0.2 0.3 0.4 0.5\nA cc\nu ra\ncy\n0.6\n0.62\n0.64\n0.66\n0.68\n0.7\n0.72\n0.74\n0.76\nAD DT RBF-SVM NN RF\n(a) Pair (cute,Animal)\nValue of θ P\n0.1 0.2 0.3 0.4 0.5\nA cc\nu ra\ncy\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\nAD DT RBF-SVM NN RF\n(b) Pair (old,Building)\nValue of θ P\n0.1 0.2 0.3 0.4 0.5\nA cc\nur ac\ny\n0.65\n0.7\n0.75\n0.8\nAD DT RBF-SVM NN RF\n(c) Pair (experienced,Athlete)\nValue of θ P\n0.1 0.2 0.3 0.4 0.5\nA cc\nu ra\ncy\n0.6\n0.65\n0.7\n0.75\n0.8\n0.85\nAD DT RBF-SVM NN RF\n(d) Pair (popular,Film)\n(a) Pair (cute,Animal)\n(b) Pair (old,Building)\n(c) Pair (experienced,Athlete)\n(d) Pair (popular,Film)\nFigure 7: Results on varying Opinion Aggregation Parameter (θA).\nKnowledge base enrichment, completion and population have been widely studied. There are two mainstreams: internal methods, which use only the knowledge contained in the knowledge base to predict missing information [27] [9]; external methods,which use sources of knowledge such as text corpora or other knowledge base to add new knowledge facts [30] [21] [12] [11]. However, these works are limited to add objective knowledge and neglect subjective knowledge. Moreover, they do not consider to make use of a natural source of knowledge, the crowd, to complete/enrich the existing knowledge base.\nRecently, the increasing popularity of crowdsourcing brings new trend to leverage the power of the crowd in knowledge acquisition, data integration and many other applications. Kondreddi et al. [13] proposes a hybrid approach that combines information extraction technique with human computation for knowledge acquisition. Marta et al. [22] presents a hybrid-genre workflow for games in crowdsourced knowledge acquisition process. Works [6] [3] [20] present approaches that use the wisdom of crowd to perform taxonomy construction. Crowdsourcing also proved to have good performance in applications such as entity resolution [28] [26], schema matching [33], translation [32] and so forth."
    }, {
      "heading" : "8. CONCLUSION",
      "text" : "In our work, we propose a system Crowdsourced subjective knowledge acquisition (CoSKA), for subjective knowledge acquisition powered by crowdsourcing and existing KBs. The acquired knowledge can be encoded into existing KBs to perform KB enrichment in the subjective dimension which can bridge the gap between existing objective knowledge and the subjective queries. Our CoSKA system, consists of three stages: ST pair selection, Crowdsourced ST pair applying and knowledge inference. To resolve the conflict between large scale knowledge facts and the limited crowdsourcing resource, we define subjective knowledge inference rules\namong ST pairs and perform knowledge inference to derive more knowledge facts. We formulate the ST pair selection problem as a Maximum Knowledge Inference Problem which is NP-hard and we propose a diversity-aware forward greedy algorithm for ST pair selection. The crowdsourced ST pair applying problem is formulated as a classification task to further improve the system scalability. Experimental results on real knowledge base and crowdsourcing platform verify that our system, CoSKA, could derive large amount accurate subjective knowledge facts with a comparative low crowdsourcing cost."
    }, {
      "heading" : "9. REFERENCES",
      "text" : "[1] Y. Asahiro, K. Iwama, H. Tamaki, and T. Tokuyama.\nGreedily finding a dense subgraph. Journal of Algorithms, 34(2):203–221, 2000.\n[2] K. D. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, pages 1247–1250, 2008.\n[3] J. Bragg, Mausam, and D. S. Weld. Crowdsourcing multi-label classification for taxonomy creation. In Proceedings of the First AAAI Conference on Human Computation and Crowdsourcing, HCOMP 2013, November 7-9, 2013, Palm Springs, CA, USA, 2013.\n[4] L. Bühmann and J. Lehmann. Pattern based knowledge base enrichment. In The Semantic Web - ISWC 2013 - 12th International Semantic Web Conference, Sydney, NSW, Australia, October 21-25, 2013, Proceedings, Part I, pages 33–48, 2013.\n[5] K. Chakrabarti, S. Chaudhuri, T. Cheng, and D. Xin. Entitytagger: automatically tagging entities with descriptive phrases. In Proceedings of the 20th International Conference\non World Wide Web, WWW 2011, Hyderabad, India, March 28 - April 1, 2011 (Companion Volume), pages 19–20, 2011.\n[6] L. B. Chilton, G. Little, D. Edge, D. S. Weld, and J. A. Landay. Cascade: crowdsourcing taxonomy creation. In 2013 ACM SIGCHI Conference on Human Factors in Computing Systems, CHI ’13, Paris, France, April 27 - May 2, 2013, pages 1999–2008, 2013.\n[7] M. Choy, J. Lee, G. Gweon, and D. Kim. Glaucus: Exploiting the wisdom of crowds for location-based queries in mobile environments. In Proceedings of the Eighth International Conference on Weblogs and Social Media, ICWSM 2014, Ann Arbor, Michigan, USA, June 1-4, 2014., 2014.\n[8] O. Etzioni, M. J. Cafarella, D. Downey, S. Kok, A. Popescu, T. Shaked, S. Soderland, D. S. Weld, and A. Yates. Web-scale information extraction in knowitall: (preliminary results). In WWW, pages 100–110, 2004.\n[9] L. A. Galárraga, C. Teflioudi, K. Hose, and F. M. Suchanek. AMIE: association rule mining under incomplete evidence in ontological knowledge bases. In 22nd International World Wide Web Conference, WWW ’13, Rio de Janeiro, Brazil, May 13-17, 2013, pages 413–422, 2013.\n[10] J. Hoffart, F. M. Suchanek, K. Berberich, and G. Weikum. YAGO2: A spatially and temporally enhanced knowledge base from wikipedia. Artif. Intell., 194:28–61, 2013.\n[11] H. Ji, T. Cassidy, Q. Li, and S. Tamang. Tackling representation, annotation and classification challenges for temporal knowledge base population. Knowl. Inf. Syst., 41(3):611–646, 2014.\n[12] H. Ji and R. Grishman. Knowledge base population: Successful approaches and challenges. In The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference, 19-24 June, 2011, Portland, Oregon, USA, pages 1148–1158, 2011.\n[13] S. K. Kondreddi, P. Triantafillou, and G. Weikum. Combining information extraction and human computing for crowdsourced knowledge acquisition. In ICDE, pages 988–999, 2014.\n[14] Y.-L. Kuo, J. Hsu, and F. Shih. Contextual commonsense knowledge acquisition from social content by crowd-sourcing explanations. In Proceedings of the Fourth AAAI Workshop on Human Computation, pages 18–24, 2012.\n[15] Y.-L. Kuo and J. Y.-j. Hsu. Resource-bounded crowd-sourcing of commonsense knowledge. In IJCAI Proceedings-International Joint Conference on Artificial Intelligence, volume 22, page 2470, 2011.\n[16] S. Lacoste-Julien, K. Palla, A. Davies, G. Kasneci, T. Graepel, and Z. Ghahramani. Sigma: simple greedy matching for aligning large knowledge bases. In The 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2013, Chicago, IL, USA, August 11-14, 2013, pages 572–580, 2013.\n[17] J. Lehmann, R. Isele, M. Jakob, A. Jentzsch, D. Kontokostas, P. N. Mendes, S. Hellmann, M. Morsey, P. van Kleef, S. Auer, and C. Bizer. Dbpedia - A large-scale, multilingual knowledge base extracted from wikipedia. Semantic Web, pages 167–195, 2015.\n[18] H. Liu and P. Singh. Conceptneta practical commonsense reasoning tool-kit. BT technology journal, 22(4):211–226, 2004.\n[19] J. McAuley and A. Yang. Addressing complex and subjective\nproduct-related queries with customer reviews. In Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016, pages 625–635, 2016.\n[20] R. Meng, Y. Tong, L. Chen, and C. C. Cao. CrowdTC: Crowdsourced taxonomy construction. In 2015 IEEE International Conference on Data Mining, ICDM 2015, Atlantic City, NJ, USA, November 14-17, 2015, pages 913–918, 2015.\n[21] A. G. Nuzzolese, A. Gangemi, V. Presutti, and P. Ciancarini. Type inference through the analysis of wikipedia links. In WWW2012 Workshop on Linked Data on the Web, Lyon, France, 16 April, 2012, 2012.\n[22] M. Sabou, A. Scharl, and M. Föls. Crowdsourced knowledge acquisition: Towards hybrid-genre workflows. Int. J. Semantic Web Inf. Syst., 9(3):14–41, 2013.\n[23] N. Tandon, G. de Melo, F. M. Suchanek, and G. Weikum. Webchild: harvesting and organizing commonsense knowledge from the web. In Seventh ACM International Conference on Web Search and Data Mining, WSDM 2014, New York, NY, USA, February 24-28, 2014, pages 523–532, 2014.\n[24] N. Tandon, G. de Melo, and G. Weikum. Acquiring comparative commonsense knowledge from the web. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July 27 -31, 2014, Québec City, Québec, Canada., pages 166–172, 2014.\n[25] I. Trummer, A. Y. Halevy, H. Lee, S. Sarawagi, and R. Gupta. Mining subjective properties on the web. In SIGMOD, pages 1745–1760, 2015.\n[26] N. Vesdapunt, K. Bellare, and N. N. Dalvi. Crowdsourcing algorithms for entity resolution. PVLDB, 7(12):1071–1082, 2014.\n[27] J. Völker and M. Niepert. Statistical schema induction. In The Semantic Web: Research and Applications - 8th Extended Semantic Web Conference, ESWC 2011, Heraklion, Crete, Greece, May 29-June 2, 2011, Proceedings, Part I, pages 124–138, 2011.\n[28] J. Wang, T. Kraska, M. J. Franklin, and J. Feng. CrowdER: Crowdsourcing entity resolution. PVLDB, 5(11):1483–1494, 2012.\n[29] R. West, E. Gabrilovich, K. Murphy, S. Sun, R. Gupta, and D. Lin. Knowledge base completion via search-based question answering. In 23rd International World Wide Web Conference, WWW ’14, Seoul, Republic of Korea, April 7-11, 2014, pages 515–526, 2014.\n[30] R. West, E. Gabrilovich, K. Murphy, S. Sun, R. Gupta, and D. Lin. Knowledge base completion via search-based question answering. In 23rd International World Wide Web Conference, WWW ’14, Seoul, Republic of Korea, April 7-11, 2014, pages 515–526, 2014.\n[31] O. Zaidan and C. Callison-Burch. Crowdsourcing translation: Professional quality from non-professionals. In ACL, pages 1220–1229, 2011.\n[32] O. F. Zaidan and C. Callison-Burch. Crowdsourcing translation: Professional quality from non-professionals. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 1220–1229, 2011.\n[33] C. J. Zhang, L. Chen, H. V. Jagadish, and C. C. Cao. Reducing uncertainty of schema matching via crowdsourcing. PVLDB, 6(9):757–768, 2013."
    } ],
    "references" : [ {
      "title" : "Greedily finding a dense subgraph",
      "author" : [ "Y. Asahiro", "K. Iwama", "H. Tamaki", "T. Tokuyama" ],
      "venue" : "Journal of Algorithms,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2000
    }, {
      "title" : "Freebase: a collaboratively created graph database for structuring human knowledge",
      "author" : [ "K.D. Bollacker", "C. Evans", "P. Paritosh", "T. Sturge", "J. Taylor" ],
      "venue" : "In SIGMOD,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2008
    }, {
      "title" : "Crowdsourcing multi-label classification for taxonomy creation",
      "author" : [ "J. Bragg", "Mausam", "D.S. Weld" ],
      "venue" : "In Proceedings of the First AAAI Conference on Human Computation and Crowdsourcing, HCOMP 2013, November",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "Pattern based knowledge base enrichment",
      "author" : [ "L. Bühmann", "J. Lehmann" ],
      "venue" : "In The Semantic Web - ISWC 2013 - 12th International Semantic Web Conference,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "Entitytagger: automatically tagging entities with descriptive phrases",
      "author" : [ "K. Chakrabarti", "S. Chaudhuri", "T. Cheng", "D. Xin" ],
      "venue" : "In Proceedings of the 20th International Conference 8  on World Wide Web,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2011
    }, {
      "title" : "Cascade: crowdsourcing taxonomy creation",
      "author" : [ "L.B. Chilton", "G. Little", "D. Edge", "D.S. Weld", "J.A. Landay" ],
      "venue" : "In 2013 ACM SIGCHI Conference on Human Factors in Computing Systems, CHI ’13,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2013
    }, {
      "title" : "Glaucus: Exploiting the wisdom of crowds for location-based queries in mobile environments",
      "author" : [ "M. Choy", "J. Lee", "G. Gweon", "D. Kim" ],
      "venue" : "In Proceedings of the Eighth International Conference on Weblogs and Social Media,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2014
    }, {
      "title" : "Web-scale information extraction in knowitall: (preliminary results)",
      "author" : [ "O. Etzioni", "M.J. Cafarella", "D. Downey", "S. Kok", "A. Popescu", "T. Shaked", "S. Soderland", "D.S. Weld", "A. Yates" ],
      "venue" : "In WWW,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2004
    }, {
      "title" : "AMIE: association rule mining under incomplete evidence in ontological knowledge bases",
      "author" : [ "L.A. Galárraga", "C. Teflioudi", "K. Hose", "F.M. Suchanek" ],
      "venue" : "In 22nd International World Wide Web Conference,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2013
    }, {
      "title" : "YAGO2: A spatially and temporally enhanced knowledge base from wikipedia",
      "author" : [ "J. Hoffart", "F.M. Suchanek", "K. Berberich", "G. Weikum" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2013
    }, {
      "title" : "Tackling representation, annotation and classification challenges for temporal knowledge base population",
      "author" : [ "H. Ji", "T. Cassidy", "Q. Li", "S. Tamang" ],
      "venue" : "Knowl. Inf. Syst.,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "Knowledge base population: Successful approaches and challenges. In The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
      "author" : [ "H. Ji", "R. Grishman" ],
      "venue" : "Proceedings of the Conference,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2011
    }, {
      "title" : "Combining information extraction and human computing for crowdsourced knowledge acquisition",
      "author" : [ "S.K. Kondreddi", "P. Triantafillou", "G. Weikum" ],
      "venue" : "In ICDE,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Contextual commonsense knowledge acquisition from social content by crowd-sourcing explanations",
      "author" : [ "Y.-L. Kuo", "J. Hsu", "F. Shih" ],
      "venue" : "In Proceedings of the Fourth AAAI Workshop on Human Computation,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2012
    }, {
      "title" : "Resource-bounded crowd-sourcing of commonsense knowledge",
      "author" : [ "Y.-L. Kuo", "J.Y.-j. Hsu" ],
      "venue" : "In IJCAI Proceedings-International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2011
    }, {
      "title" : "Sigma: simple greedy matching for aligning large knowledge bases",
      "author" : [ "S. Lacoste-Julien", "K. Palla", "A. Davies", "G. Kasneci", "T. Graepel", "Z. Ghahramani" ],
      "venue" : "In The 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2013
    }, {
      "title" : "Dbpedia - A large-scale, multilingual knowledge base extracted from wikipedia",
      "author" : [ "J. Lehmann", "R. Isele", "M. Jakob", "A. Jentzsch", "D. Kontokostas", "P.N. Mendes", "S. Hellmann", "M. Morsey", "P. van Kleef", "S. Auer", "C. Bizer" ],
      "venue" : "Semantic Web,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2015
    }, {
      "title" : "Conceptneta practical commonsense reasoning tool-kit",
      "author" : [ "H. Liu", "P. Singh" ],
      "venue" : "BT technology journal,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2004
    }, {
      "title" : "Addressing complex and subjective  product-related queries with customer reviews",
      "author" : [ "J. McAuley", "A. Yang" ],
      "venue" : "In Proceedings of the 25th International Conference on World Wide Web, WWW 2016,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2016
    }, {
      "title" : "CrowdTC: Crowdsourced taxonomy construction",
      "author" : [ "R. Meng", "Y. Tong", "L. Chen", "C.C. Cao" ],
      "venue" : "IEEE International Conference on Data Mining,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2015
    }, {
      "title" : "Type inference through the analysis of wikipedia links",
      "author" : [ "A.G. Nuzzolese", "A. Gangemi", "V. Presutti", "P. Ciancarini" ],
      "venue" : "In WWW2012 Workshop on Linked Data on the Web,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    }, {
      "title" : "Crowdsourced knowledge acquisition: Towards hybrid-genre workflows",
      "author" : [ "M. Sabou", "A. Scharl", "M. Föls" ],
      "venue" : "Int. J. Semantic Web Inf. Syst.,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2013
    }, {
      "title" : "Webchild: harvesting and organizing commonsense knowledge from the web",
      "author" : [ "N. Tandon", "G. de Melo", "F.M. Suchanek", "G. Weikum" ],
      "venue" : "In Seventh ACM International Conference on Web Search and Data Mining,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2014
    }, {
      "title" : "Acquiring comparative commonsense knowledge from the web",
      "author" : [ "N. Tandon", "G. de Melo", "G. Weikum" ],
      "venue" : "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2014
    }, {
      "title" : "Mining subjective properties on the web",
      "author" : [ "I. Trummer", "A.Y. Halevy", "H. Lee", "S. Sarawagi", "R. Gupta" ],
      "venue" : "In SIGMOD,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2015
    }, {
      "title" : "Crowdsourcing algorithms for entity resolution",
      "author" : [ "N. Vesdapunt", "K. Bellare", "N.N. Dalvi" ],
      "venue" : "PVLDB, 7(12):1071–1082,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2014
    }, {
      "title" : "Statistical schema induction",
      "author" : [ "J. Völker", "M. Niepert" ],
      "venue" : null,
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2011
    }, {
      "title" : "CrowdER: Crowdsourcing entity resolution",
      "author" : [ "J. Wang", "T. Kraska", "M.J. Franklin", "J. Feng" ],
      "venue" : "PVLDB, 5(11):1483–1494,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2012
    }, {
      "title" : "Knowledge base completion via search-based question answering",
      "author" : [ "R. West", "E. Gabrilovich", "K. Murphy", "S. Sun", "R. Gupta", "D. Lin" ],
      "venue" : "In 23rd International World Wide Web Conference,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2014
    }, {
      "title" : "Knowledge base completion via search-based question answering",
      "author" : [ "R. West", "E. Gabrilovich", "K. Murphy", "S. Sun", "R. Gupta", "D. Lin" ],
      "venue" : "In 23rd International World Wide Web Conference,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2014
    }, {
      "title" : "Crowdsourcing translation: Professional quality from non-professionals",
      "author" : [ "O. Zaidan", "C. Callison-Burch" ],
      "venue" : "In ACL,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2011
    }, {
      "title" : "Crowdsourcing translation: Professional quality from non-professionals",
      "author" : [ "O.F. Zaidan", "C. Callison-Burch" ],
      "venue" : "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2011
    }, {
      "title" : "Reducing uncertainty of schema matching via crowdsourcing",
      "author" : [ "C.J. Zhang", "L. Chen", "H.V. Jagadish", "C.C. Cao" ],
      "venue" : null,
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "In recent years, knowledge bases (KBs) have become increasingly popular and large-scale KBs have been constructed, such as Freebase [2], DBpedia [17], YAGO [10], KnowItAll [8], etc.",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 16,
      "context" : "In recent years, knowledge bases (KBs) have become increasingly popular and large-scale KBs have been constructed, such as Freebase [2], DBpedia [17], YAGO [10], KnowItAll [8], etc.",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 9,
      "context" : "In recent years, knowledge bases (KBs) have become increasingly popular and large-scale KBs have been constructed, such as Freebase [2], DBpedia [17], YAGO [10], KnowItAll [8], etc.",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 7,
      "context" : "In recent years, knowledge bases (KBs) have become increasingly popular and large-scale KBs have been constructed, such as Freebase [2], DBpedia [17], YAGO [10], KnowItAll [8], etc.",
      "startOffset" : 172,
      "endOffset" : 175
    }, {
      "referenceID" : 18,
      "context" : ", around 20% of product-related queries are labeled as being “subjective” by workers [19], 63% of location-based queries in mobile search are asking for subjective opinions [7], and need the corresponding subjective knowledge as the query answers.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 6,
      "context" : ", around 20% of product-related queries are labeled as being “subjective” by workers [19], 63% of location-based queries in mobile search are asking for subjective opinions [7], and need the corresponding subjective knowledge as the query answers.",
      "startOffset" : 173,
      "endOffset" : 176
    }, {
      "referenceID" : 24,
      "context" : "More specifically, subjective knowledge refers to the dominant opinion about whether a particular subjective property applies to entities of a particular type [25].",
      "startOffset" : 159,
      "endOffset" : 163
    }, {
      "referenceID" : 27,
      "context" : "Fortunately, crowdsourcing, which has been recently proved to be successful for various human intrinsic tasks such as entity resolution [28], knowledge extraction [13], translation [31], etc.",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 12,
      "context" : "Fortunately, crowdsourcing, which has been recently proved to be successful for various human intrinsic tasks such as entity resolution [28], knowledge extraction [13], translation [31], etc.",
      "startOffset" : 163,
      "endOffset" : 167
    }, {
      "referenceID" : 30,
      "context" : "Fortunately, crowdsourcing, which has been recently proved to be successful for various human intrinsic tasks such as entity resolution [28], knowledge extraction [13], translation [31], etc.",
      "startOffset" : 181,
      "endOffset" : 185
    }, {
      "referenceID" : 8,
      "context" : "Many works have been done to perform KB enrichment, completion and population [9] [29] [4] [12] [11], but none of these works focus on the subjective dimension.",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 28,
      "context" : "Many works have been done to perform KB enrichment, completion and population [9] [29] [4] [12] [11], but none of these works focus on the subjective dimension.",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 3,
      "context" : "Many works have been done to perform KB enrichment, completion and population [9] [29] [4] [12] [11], but none of these works focus on the subjective dimension.",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 11,
      "context" : "Many works have been done to perform KB enrichment, completion and population [9] [29] [4] [12] [11], but none of these works focus on the subjective dimension.",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 10,
      "context" : "Many works have been done to perform KB enrichment, completion and population [9] [29] [4] [12] [11], but none of these works focus on the subjective dimension.",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 24,
      "context" : "For subjective knowledge acquisition, the state-of-the-art approach is to use information extraction techniques to mine the text of Web contents [25].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 24,
      "context" : "SURVEYOR has the precision of 77% [25].",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 15,
      "context" : "Similar with [16], knowledge base is formally defined as follows.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 24,
      "context" : "As mentioned in Section 1, the subjective knowledge refers to the dominant opinion about whether a particular subjective property applies to entities of a particular type [25].",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 24,
      "context" : "Similar with work [25], we use the synthetic patterns to extract information, i.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 0,
      "context" : "The maximum knowledge acquisition problem is NP-hard, a backwardgreedy strategy, which repeatedly removes a vertex with the minimum weighted-degree in the remaining graph, until exactly k vertices are left, has an worst case approximation ratio of [( 1 2 + n 2k )− O(n− 1 3 ), ( 1 2 + n 2k ) + O( 1 n )] for k in the range of [ 3 , n] and [2( k −1)−O( 1 k ), 2( k −1)+O( n k2 )] for k in the range of [0, n 3 ), where n is the number of vertex [1].",
      "startOffset" : 444,
      "endOffset" : 447
    }, {
      "referenceID" : 24,
      "context" : "With the given threshold θA (which is set through experimental study, as the degree of agreement would vary with different ST pairs [25]), we derive the dominant opinion, denoted as (DO(I, ST )) of whether an ST pair ST applies to the instance I:",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 24,
      "context" : "To justify the effectiveness of our approach for subjective knowledge acquisition, we compare our results with the state-of-the-art technique, Surveyor, proposed in [25].",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 17,
      "context" : "Some works have been conducted for commonsense knowledge acquisition [18] [15] [14] [24].",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 14,
      "context" : "Some works have been conducted for commonsense knowledge acquisition [18] [15] [14] [24].",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 13,
      "context" : "Some works have been conducted for commonsense knowledge acquisition [18] [15] [14] [24].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 23,
      "context" : "Some works have been conducted for commonsense knowledge acquisition [18] [15] [14] [24].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 22,
      "context" : "WebChild [23] presents a method for automatically constructing a large commonsense knowledge base, it contains triples that connect nouns with adjectives via fine-grained relations.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 4,
      "context" : "Entitytagger [5], presented by Chakrabarti et al.",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 26,
      "context" : "There are two mainstreams: internal methods, which use only the knowledge contained in the knowledge base to predict missing information [27] [9]; external methods,which use sources of knowledge such as text corpora or other knowledge base to add new knowledge facts [30] [21] [12] [11].",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 8,
      "context" : "There are two mainstreams: internal methods, which use only the knowledge contained in the knowledge base to predict missing information [27] [9]; external methods,which use sources of knowledge such as text corpora or other knowledge base to add new knowledge facts [30] [21] [12] [11].",
      "startOffset" : 142,
      "endOffset" : 145
    }, {
      "referenceID" : 29,
      "context" : "There are two mainstreams: internal methods, which use only the knowledge contained in the knowledge base to predict missing information [27] [9]; external methods,which use sources of knowledge such as text corpora or other knowledge base to add new knowledge facts [30] [21] [12] [11].",
      "startOffset" : 267,
      "endOffset" : 271
    }, {
      "referenceID" : 20,
      "context" : "There are two mainstreams: internal methods, which use only the knowledge contained in the knowledge base to predict missing information [27] [9]; external methods,which use sources of knowledge such as text corpora or other knowledge base to add new knowledge facts [30] [21] [12] [11].",
      "startOffset" : 272,
      "endOffset" : 276
    }, {
      "referenceID" : 11,
      "context" : "There are two mainstreams: internal methods, which use only the knowledge contained in the knowledge base to predict missing information [27] [9]; external methods,which use sources of knowledge such as text corpora or other knowledge base to add new knowledge facts [30] [21] [12] [11].",
      "startOffset" : 277,
      "endOffset" : 281
    }, {
      "referenceID" : 10,
      "context" : "There are two mainstreams: internal methods, which use only the knowledge contained in the knowledge base to predict missing information [27] [9]; external methods,which use sources of knowledge such as text corpora or other knowledge base to add new knowledge facts [30] [21] [12] [11].",
      "startOffset" : 282,
      "endOffset" : 286
    }, {
      "referenceID" : 12,
      "context" : "[13] proposes a hybrid approach that combines information extraction technique with human computation for knowledge acquisition.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "[22] presents a hybrid-genre workflow for games in crowdsourced knowledge acquisition process.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 5,
      "context" : "Works [6] [3] [20] present approaches that use the wisdom of crowd to perform taxonomy construction.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 2,
      "context" : "Works [6] [3] [20] present approaches that use the wisdom of crowd to perform taxonomy construction.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 19,
      "context" : "Works [6] [3] [20] present approaches that use the wisdom of crowd to perform taxonomy construction.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 27,
      "context" : "Crowdsourcing also proved to have good performance in applications such as entity resolution [28] [26], schema matching [33], translation [32] and so forth.",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 25,
      "context" : "Crowdsourcing also proved to have good performance in applications such as entity resolution [28] [26], schema matching [33], translation [32] and so forth.",
      "startOffset" : 98,
      "endOffset" : 102
    }, {
      "referenceID" : 32,
      "context" : "Crowdsourcing also proved to have good performance in applications such as entity resolution [28] [26], schema matching [33], translation [32] and so forth.",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 31,
      "context" : "Crowdsourcing also proved to have good performance in applications such as entity resolution [28] [26], schema matching [33], translation [32] and so forth.",
      "startOffset" : 138,
      "endOffset" : 142
    } ],
    "year" : 2017,
    "abstractText" : "Knowledge bases (KBs) have attracted increasing attention due to its great success in various areas, such as Web and mobile search. Existing KBs are restricted to objective factual knowledge, such as CITY POPULATION or FRUIT SHAPE, whereas, subjective knowledge, such as BIG CITY, which is commonly mentioned in Web and mobile queries, has been neglected. Subjective knowledge differs from objective knowledge in that it has no documented or observed ground truth. Instead, the truth relies on people’s dominant opinion. Thus, we can use the crowdsourcing technique to get opinion from the crowd. In our work, we propose a system, called crowdsourced subjective knowledge acquisition (CoSKA), for subjective knowledge acquisition powered by crowdsourcing and existing KBs. The acquired knowledge can be used to enrich existing KBs in the subjective dimension which bridges the gap between existing objective knowledge and subjective queries. The main challenge of CoSKA is the conflict between large scale knowledge facts and limited crowdsourcing resource. To address this challenge, in this work, we define knowledge inference rules and then select the seed knowledge judiciously for crowdsourcing to maximize the inference power under the resource constraint. Our experimental results on real knowledge base and crowdsourcing platform verify the effectiveness of CoSKA system.",
    "creator" : "LaTeX with hyperref package"
  }
}