{
  "name" : "1401.3844.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Multiattribute Auctions Based on Generalized Additive Independence",
    "authors" : [ "Yagil Engel", "Michael P. Wellman" ],
    "emails" : [ "yagile@ie.technion.ac.il", "wellman@umich.edu" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Multiattribute trading mechanisms extend traditional, price-only mechanisms by facilitating negotiation over a set of predefined attributes representing various non-price aspects of a deal. Rather than negotiate over a fully specified good or service, a multiattribute mechanism delays commitment to particular configurations until it extracts sufficient information on traders’ preferences. For example, a company’s procurement department may run a multiattribute auction to select a supplier of hard drives. Supplier offers may be evaluated not only over the price they offer, but also over features such as volume, RPM, access time, latency, transfer rate, and so on. In addition, suppliers may offer contracts differing in terms such as warranty, delivery time, and service.\nIn order to account for traders’ preferences, the auction mechanism must extract evaluative information over a complex domain of multidimensional configurations. Constructing and communicating a complete preference specification can pose a severe burden for even a\nc©2010 AI Access Foundation. All rights reserved.\nmoderate number of attributes, hence practical multiattribute auctions must either accommodate partial specifications, or support compact expression of preferences assuming some simplified form. By far the most popular multiattribute form to adopt is the simplest: an additive representation where overall value is a linear combination of values associated with each attribute. For example, several recent proposals for iterative multiattribute auctions (Beil & Wein, 2003; Bichler, 2001; David, Azoulay-Schwartz, & Kraus, 2002; Parkes & Kalagnanam, 2005) require additive preference representations.\nSuch additivity reduces the complexity of preference specification exponentially (compared to the general discrete case), but precludes expression of any interdependencies among the attributes. In practice, however, interdependencies among natural attributes are quite common. For example, the hard-drive buyer may exhibit complementary preferences for volume and access time (since the performance effect is more salient if much data is involved), or may view a strong warranty as a good substitute for high reliability ratings. Similarly, a seller’s production characteristics can easily violate additivity, for example if decreasing access time is technically more difficult for higher-capacity drives. In such cases an additive value function may not be able to provide an adequate approximation of real preferences.\nOn the other hand, fully general models are intractable, and multiattribute preferences typically exhibit some structure. Our goal, therefore, is to identify the subtler yet more widely applicable structured representations, and exploit these properties of preferences in trading mechanisms.\nWe propose an iterative auction mechanism based on just such a flexible preference structure. Our approach is inspired by the design of an iterative multiattribute procurement auction for additive preferences, due to Parkes and Kalagnanam (2005) (PK). PK present two auction designs: the first (NLD) makes no assumptions about traders’ preferences, and lets sellers bid on the full multidimensional attribute space. Because NLD maintains an exponential price structure, it is suitable only for small domains. The other auction (AD) assumes additive buyer valuation and seller cost functions. It collects sell bids per attribute level and for a single discount term. The price of a configuration is the sum of the prices of the chosen attribute levels minus the discount.\nThe auction we propose also supports compact price spaces, albeit for levels of clusters of attributes rather than singletons. We employ a preference decomposition based on generalized additive independence (GAI), a model flexible enough to accommodate interdependencies to the exact degree of accuracy desired, yet providing a compact functional form to the extent that interdependence can be limited.\nFirst, we build a direct, formally justified link from preference statements over priced outcomes to a generalized additive decomposition of the willingness-to-pay (wtp) function. After laying out this infrastructure, we employ this representation tool for the development of a multiattribute iterative auction mechanism that allows traders to express their complex preferences in GAI format. We then study the auction’s allocational, computational, and practical properties. Next, we present a simulation study of our proposed auction mechanism, in order to practically evaluate the economic and computational properties of GAI auctions. We simulate the auctions using random GAI utility functions, including some based on constrained preference structures often exhibited in applications. The simulations let us quantify the benefits of modeling preferences accurately using GAI, in comparison to\nusing an additive approximation. We show that under most circumstances, a GAI auction achieves significantly higher surplus than an auction that uses an additive approximation of preferences.\nAfter providing background on multiattribute preferences and multiattribute auctions (Section 2), we develop new multiattribute structures for wtp functions, supporting generalized additive decompositions (Section 3). We describe our auction mechanism in Section 4, followed by a detailed example in Section 5, and study the mechanism’s allocational, computational, and practical properties in Section 6. We present our simulation framework in Section 7, and discuss the experimental results in Section 8."
    }, {
      "heading" : "2. Background",
      "text" : "In this section we provide essential background on multiattribute preferences (Sections 2.1 and 2.2) and on multiattribute auctions (Section 2.3)."
    }, {
      "heading" : "2.1 Multiattribute Preferences and Utility",
      "text" : "Let Θ denote the space of possible outcomes, with ! a preference relation (weak total order) over Θ. Let A = {a0, . . . , an} be a set of attributes describing Θ. Each attribute a ∈ A has a domain D(a), so that Θ ⊆ ∏n i=1 D(ai). Capital letters denote subsets of attributes, small latin letters (with or without numeric subscripts) denote specific attributes, and X = A\\X. θ (and variations such as θ′ or θ̂) indicate specific outcome in Θ. An instantiation to a subset of attributes Y is denoted using prime signs (as in Y ′) or numerical superscript (as in Y 1). In particular, Y ′ is a projection on Y of some instantiations θ ∈ Θ. To represent an instantiation of subsets X,Y at the same time we use a sequence of instantiation symbols, as in X1Y 2.\nThe preference relation ! over outcomes is usually represented numerically by a value function v(·) (Keeney & Raiffa, 1976).\nDefinition 1 (Value Function). v : Θ → % is a value function representing ! if for any θ, θ′ ∈ Θ, v(θ) ≤ v(θ′) iff θ ! θ′.\nClearly, any monotonic transformation of v(·) is also a value function for !. In many cases it is useful to represent, beyond a simple preference order over outcomes, a notion of strength of preferences. A value function that expresses strength of preferences is called a cardinal value function. A measurable value function is a well-established cardinal value framework which posits the existence of a preference order !̂ over pairs of outcomes. For some θ ! θ′ and θ̂ ! θ̂′, the statement (θ, θ′) !̂ (θ̂, θ̂′) means that the strength of preference of θ̂′ over θ̂ is greater than or equal to that of θ′ over θ. Krantz, Luce, Suppes, and Tversky (1971) establish the set of axioms ensuring the existence of a utility function representing !̂.\nDefinition 2 (Measurable Value Function). A measurable value function (MVF) is a value function u : Θ → %, such that for any θ, θ′, θ̂, θ̂′ ∈ Θ, for which θ ! θ′ and θ̂ ! θ̂′, the following holds:\nu(θ′) − u(θ) ≤ u(θ̂′) − u(θ̂) ⇔ (θ, θ′) !̂ (θ̂, θ̂′). (1)\nHence the order over differences in values of u(·) correspond exactly to the order over preference differences. Note that an MVF can also be used as a value function representing !, because (θ′, θ) !̂ (θ′′, θ) iff θ′ ! θ′′, for any θ.\nIn auction theory and mechanism design, traders’ preferences are usually represented using a quasi-linear value function, such as v(θ, p) = u(θ)+p, where p represents a monetary outcome.1 The cardinal value function u(θ) expresses strength of preference, in that the difference u(θ′) − u(θ′′) corresponds to the additional amount a trader is willing to pay for θ′ relative to θ′′. For example, if θ′ represents a red Mercedes with a sunroof, and θ′′ denotes a blue Subaru with no sunroof, then u(θ′) − u(θ′′) is the strength of preference for the Mercedes configuration over the Subaru. If the Mercedes costs p′ and the Subaru p′′, then according to v(θ, p) the trader prefers the Mercedes deal iff u(θ′) − u(θ′′) ≥ p′ − p′′.\nIn fact, u(·) can be easily shown to be an MVF, where the preference differences correspond to differences in willingness-to-pay (Engel & Wellman, 2007). For this reason, we use MVF as the basis for utility in this work, and assume that traders’ willingness-to-pay (wtp) functions constitute an MVF.\nReasoning over full outcomes is hard in several ways. Most notably, it is difficult for humans to compare outcomes over many dimensions, and complex for machines to store and analyze preferences over a number of outcomes that is exponential in the number of attributes. It is therefore useful to consider preferences over the joint product of some Y ⊂ A, considering the rest of the attributes Y fixed on some predefined values. Such an order is also often referred to as a ceteris paribus preference order—one partial outcome is preferred to another all else being equal.\nDefinition 3 (Conditional Preference). Partial outcome Y 2 is conditionally preferred to partial outcome Y 1 given Y ′ , if Y 1Y ′ ! Y 2Y ′ . The conditional preference order over Y given Y ′ is denoted by !\nY ′ , hence Y 1Y\n′ ! Y 2Y ′ is abbreviated Y 1 !\nY ′ Y 2.\nIn general, conditional preferences may depend on the particular assignment chosen for the rest of the attributes. More precisely, if Y 1 ≺\nY ′ Y 2, we could still find that Y 2 ≺ Y ′′ Y 1\nfor some Y ′′ ,= Y ′ . When this is the case, one needs to maintain both conditional preference orders ! Y ′ and ! Y\n′′ , and hence in general this scheme might not yield any computational benefits. Fortunately, in many cases one can identify subsets Y for which this preference reversal does not occur, that is the preference order over Y is invariant to the instantiation of Y .\nDefinition 4 (Preferential Independence). Y is preferential independent (PI) of Y , written PI(Y, Y ), if for any Y 1 and Y 2, and for any Y ′ , Y ′′ , we have Y 1 !\nY ′ Y 2 iff Y 1 ! Y ′′\nY 2.\nFirst-order preferential independence (FOPI), independence of a single attribute from the rest, is a natural assumption in many domains. For example, in typical purchase decisions greater quantity or higher quality is more desirable regardless of the assignments to other attributes. Preferential independence of higher order, however, requires invariance of the tradeoffs among some attributes with respect to variation in others, a more stringent independence condition. The MPI condition, defined below, is over the global set of attributes A, and requires all possible subsets to be PI.\n1. We use the term trader when referring to either buyers or sellers.\nDefinition 5 (Mutual Preferential Independence). Attributes A are mutually preferential independent (MPI) iff for all Y ⊂ A, PI(Y, Y ).\nPreferential independence can greatly simplify the form of v.\nTheorem 1 (Debreu, 1959). A preference order over set of attributes A can be represented by an additive value function\nv(a1, . . . , an) = n∑\ni=1\nvi(ai),\niff A is mutually preferential independent.\nDyer and Sarin (1979) extend additivity theory to MVF, and specify the conditions under which u(·) as well has an additive structure as above. Effectively, additive forms used in trading mechanisms assume MPI over the full set of attributes, including the money attribute. Intuitively that means willingness-to-pay for levels of an attribute or attributes cannot be affected by the instantiation of other attributes. This sweeping condition rarely holds in practice (Von Winterfeldt & Edwards, 1986). Therefore, recent AI literature often relaxes the MPI assumption by imposing additivity only with respect to subsets of attributes which may overlap.\nDefinition 6 (Generalized Additive Independence). Let I1, . . . , Ig be (not necessarily disjoint) subsets of A, such that ⋃g i=1 Ii = A. The elements I1, . . . , Ig are called generalized additive independent (GAI) if there exist functions f1, . . . , fg such that,\nu(a1, . . . , an) = g∑\nr=1\nfr(Ir). (2)"
    }, {
      "heading" : "2.2 Related Work on Generalized Independence",
      "text" : "Our definition of GAI is somewhat nonstandard. Most literature defines a GAI condition for the expected utility function (von Neumann & Morgenstern, 1944). In that well-known model, a particular choice results in a lottery, that is a probability distribution over outcomes. The expected utility function represents a complete preference order over lotteries. Informally, the GAI definition requires preferences on lotteries over Θ to depend only on the margins over the subsets I1, . . . , Ig. The form of Eq. (2) is a result of that definition, obtained by Fishburn (1967). Fishburn not only introduces the functional decomposition, but also provides a well-defined form for the functional constituents f1, . . . , fg. Graphical models and elicitation procedures for GAI decomposable utility were developed within the expected utility framework (Bacchus & Grove, 1995; Boutilier, Bacchus, & Brafman, 2001; Gonzales & Perny, 2004; Braziunas & Boutilier, 2005). In addition, generalized additive utility models have been employed by Hyafil and Boutilier (2006) as an aid in direct revelation mechanisms, and by Robu, Somefun, and La Poutré (2005) for opponent modeling in bilateral multi-item negotiation.\nBacchus and Grove (1995), who in fact coined the term GAI, show that the decomposition can also be obtained as a result of a collection of local, easier to detect, binary\nindependence conditions. More specifically, they rely on a form called conditional additive independence, which, informally, corresponds to a GAI decomposition limited to two (overlapping) subsets X ⊂ A and Y ⊂ A. They prove that this condition can be expressed as a separation criterion on a graph whose nodes correspond to A, by the means of a perfect map (Pearl, 1988). Crucially, the utility function decomposes to GAI form over lower dimensional functions, each defined on a maximal clique of the graph. When combined with Fishburn’s work, their result provides a well-defined functional form that can be obtained from a collection of conditional additive independence conditions. This result relies on the form of lotteries as a basis for the utility function and the independence conditions.\nThe expression of willingness-to-pay requires a cardinal measure of preferences, yet without uncertainty, there is no need for an expected utility representation. We therefore invoke the MVF framework, and in Section 3, build on the additive decompositions for MVF developed by Dyer and Sarin (1979) to develop multiattribute preference structures for wtp. This development enables us to follow the footsteps of Fishburn (1967) and Bacchus and Grove (1995) and show that a well-defined GAI form for MVF can also be obtained using a collection of easy-to-detect binary independence conditions."
    }, {
      "heading" : "2.3 Multiattribute Auctions",
      "text" : "The distinguishing feature of a multiattribute auction is that the goods are defined by vectors of attributes. As above, we use A to denote a set of attributes describing the domain Θ. A configuration is a particular attribute vector, θ ∈ Θ. Multiattribute auctions are used primarily for procurement, as part of strategic sourcing processes (Sandholm, 2007). In the procurement model there is a single buyer, who has a utility function (representing willingness-to-pay) ub(θ) for purchasing θ ∈ Θ. There are m sellers s1, . . . , sm with utility functions ci : Θ → %, representing the cost for si to supply configurations in Θ to the buyer.\nDefinition 7 (Multiattribute Allocation Problem). The multiattribute allocation problem (Parkes & Kalagnanam, 2005) is:\nMAP = max i∈{1,...,m},θ∈Θ ub(θ) − ci(θ). (3)\nAn allocation (s∗i , θ ∗) solving MAP is said to maximize the surplus of the procurement problem. MAP can be decomposed to two subproblems: first find the most efficient configuration for each trader, and then find the trader whose efficient configuration yields the highest surplus. We call the first part the multiattribute matching problem (Engel, Wellman, & Lochner, 2006).\nDefinition 8 (Multiattribute Matching Problem). The multiattribute matching problem (MMP) for a buyer b and a seller si is:\nMMP(b, si) = arg max θ∈Θ ub(θ) − ci(θ).\nWe also call a configuration θ∗ selected by MMP(b, si) a bilaterally efficient configuration for si.\nMost of the theoretical work on surplus-maximizing multiattribute auctions relates in some way to the foundational work by Che (1993). In Che’s model, the good or service is characterized by a single quality attribute, and each seller has an independent private cost function over quality. The buyer announces a scoring rule to the sellers, by which price-quality offers will be evaluated. Che suggests several types of auctions, including the second-score auction, where the seller bidding highest score wins, and must provide a combination of price and quality that achieves the second-best score. In the second-score mechanism, bidding truthfully is an equilibrium in dominant strategies. In particular, Che shows that sellers bid on the quality that maximizes the difference between the buyer’s scoring rule and their own cost function; in other words, on the respective MMP solution. Branco (1997) generalizes Che’s model and some of his results to correlated costs.\nThis basic model was later generalized by several authors to account explicitly for multiple quality attributes, and usually restricting the scoring rule to be additive over the attributes (Bichler, 2001; David et al., 2002). Vulkan and Jennings (2000) suggest a modified version of English auctions (iterative auctions that require new bids to increment over current bid price) under which bidders are required to improve current score, rather than price. Sandholm and Suri (2006) consider the incorporation of non-price attributes in multi-item (combinatorial) auctions.\nThe literature surveyed above emphasizes that auctions require the buyer to reveal a scoring function prior to bidding. In order to achieve economic efficiency, this scoring function must convey the buyer’s full utility function ub(·). This is a major obstacle to practical adaption of these mechanisms. Procurement auctions are rarely an isolated event, and the buyer-supplier relationships usually evolve and change over time, during which suppliers may retain some market power, and take advantage of the information revealed by the buyer. Events are sometimes conducted on a recurrent basis, and several events may be conducted for related goods with correlated valuations. In addition, the buyer may wish to keep secret the way her utility may be discriminating for or against particular suppliers (Koppius, 2002).\nAs noted in Section 1, Parkes and Kalagnanam (2005) suggest an alternative approach, which employs prices over the space of configurations to drive traders to the efficient configurations. Auction NLD maintains a price for each θ ∈ Θ, and sellers bid for such full configuration in each round. Auction AD maintains a price for each level a′i ∈ D(ai). Prices are initially set to be high. In each round, sellers bid on a particular value for each attribute, and the auction selects a set of levels (again, per attribute) which are myopically buyer preferred in that round, that is, approximately maximize the buyer’s utility with respect to current prices. In addition, the auction maintains a discount factor that is applied to ensure that a single seller is eventually selected. The price of a configuration is defined as the sum of the prices of the chosen attribute levels minus the discount. After each round, prices of particular levels of particular attributes are decremented by a constant \", according to a set of price change rules, ensuring that the auction ultimately converges to an efficient solution.\nBoth auctions are shown to obtain optimal surplus (up to \"-proportional error), when all sellers bid myopically rather than strategically (we define this concept formally in Section 6.1). The myopic behavior is shown to be an ex-post Nash equilibrium. Auction NLD is fully expressive but not tractable when the number of attributes is large. Auction AD is computationally efficient, but its expressiveness is limited to additive preferences (see\ndiscussion following Theorem 1). When traders’ preferences are not additive, the welfare achieved by the auction is not necessarily optimal; that is, it does solve MAP optimally, but with respect to inaccurate utility functions. Moreover, it is not clear how this lack of expressiveness may affect the incentives of traders to act strategically.\nTheoretically, one could also use the well-known Vickrey-Clake-Grove (VCG) mechanism. Parkes and Kalagnanam define the sell-side VCG mechanism: all traders submit their full utility or cost functions, MAP is solved by the auction engine, and the winning seller pays according to her VCG price (definition of this pricing is provided in Section 6.1). In such an auction, traders can be allowed to use any compact preference structure, including GAI. However, this scheme suffers from the same disadvantages as any of the proposals that require full revelation of utility.\nTo summarize, no previously suggested surplus-maximizing multiattribute procurement auction is at the same time expressive (accommodates interdependencies between attributes), tractable (its computations do not depend on the fully exponential domain), and preserving of the buyer’s private information, meaning (minimally) that it does not require the buyer to reveal a full utility function before extracting any bids from sellers. Our proposed mechanism, as we show theoretically and using simulations, possesses attractive properties on all these criteria."
    }, {
      "heading" : "3. Detection of GAI Structure for Measurable Value Functions",
      "text" : "In this section we provide the basis for the application of GAI decomposition in procurement problems. In Section 3.1 we show how GAI can be obtained as a collection of local, weaker conditions which are based on invariance of willingness-to-pay. In Section 3.2 we use an example to demonstrate how this process can be used in procurement problems."
    }, {
      "heading" : "3.1 Difference Independence and GAI",
      "text" : "Dyer and Sarin (1979) introduce for measurable value an analog to additive independence, called difference independence. Our first step is to introduce a conditional generalization of their definition.\nDefinition 9 (Conditional Difference Independence). Let X,Y ⊂ A and X ∩ Y = ∅, and define Z = A \\ X ∪ Y . X is conditionally difference independent of Y , denoted as CDI(X,Y ), if for any Z ′ ∈ D(Z), and for any X1,X2 ∈ D(X), Y 1, Y 2 ∈ D(Y ),\n(X1Y 1Z ′,X2Y 1Z ′) ∼̂ (X1Y 2Z ′,X2Y 2Z ′), (4)\nwhere the symbol ∼̂ indicates that !̂ and 1̂ both hold.\nBy the definition of MVFs (1), the CDI condition (4) can be expressed equivalently in terms of measurable value:\nu(X1Y 1Z ′) − u(X2Y 1Z ′) = u(X1Y 2Z ′) − u(X2Y 2Z ′)\nThis condition states that the value, or willingness-to-pay, for a change in the assignment to X does not depend on the current assignment of Y , for any fixed value of Z.\nA CDI condition leads to a convenient decomposition of the MVF.\nLemma 2. Let u(A) be an MVF representing preference differences, with X,Y,Z as specified in Definition 9. Then CDI(X,Y ) iff\nu(A) = u(X0, Y, Z) + u(X,Y 0, Z) − u(X0, Y 0, Z),\nfor any arbitrary instantiations X0, Y 0.\nWith a single CDI condition, we can therefore replace the n-ary function u(X,Y,Z) with two lower-dimensional functions u(X0, Y, Z) and u(X,Y 0, Z). It is reasonable to assume that one can apply more CDI conditions to further decompose the resulting functions. In order to take full advantage of all existing CDI conditions, we introduce the notion of a dependency graph, which is a simplification of the concept of perfect map mentioned in Section 2.2.\nDefinition 10 (Dependency Graph). Let S denote a set, and R a binary relation over 2S . Then a graph G = (S, E) is a dependency graph for R if for any S1, S2 ⊂ S, it holds that (S1, S2) ∈ R iff for any a1 ∈ S1 and a2 ∈ S2, (a1, a2) /∈ E.\nHence the dependency graph expresses R as a separation criterion; two subsets have a direct connection iff they are not in R. A dependency graph for CDI can be constructed simply by removing any edge (a1, a2) for which CDI({a1}, {a2}); this is because CDI(S1, S2) holds iff CDI({a1}, {a2}) holds for any a1 ∈ S1 and a2 ∈ S2. We use the term CDI map for a dependency graph induced by a CDI relation.\nThe next theorem links the CDI condition, the CDI map, and a GAI decomposition over A. In fact, it establishes that the functional constituents of GAI decomposition for MVF are the same as the functional constituents of GAI decomposition for the expected utility model, as defined by Fishburn (1967). We adopt the following conventional notation. Let (a01, . . . , a 0 n) be a predefined vector called the reference outcome. For any I ⊆ A, the function u([I]) stands for the projection of u(A) to I where the rest of the attributes are fixed at their reference levels.\nTheorem 3 (CDI-GAI Theorem). Let G = (A,E) be a CDI map for A, and {I1, . . . , Ig} a set of (overlapping) maximal cliques of G. Then\nu(A) = g∑\nr=1\nfr(Ir), (5)\nwhere\nf1 = u([I1]), and (6)\nfor r = 2, . . . , g, fr = u([Ir]) + r−1∑\nj=1\n(−1)j ∑\n1≤i1<···<ij<r\nu([ j⋂\ns=1\nIis ∩ Ir]).\nAs a small example, Table 1 exhibits a utility function u(x1, x2, x3). Each of the three attributes has a boolean domain, that is D(xi) = {0, 1}. Let x0i and x 1 i denote the assignments 0 and 1 (respectively) to xi. We first observe that CDI({x1}, {x3}) holds because:2\n2. Note that x02 and x 1 2 correspond to Z ′ in Definition 9.\n1. The utility difference on values of x1 given x02 is 5, for both x 0 3 and x 1 3. More explicitly,\nu(x11, x 0 2, x 0 3) − u(x 0 1, x 0 2, x 0 3) = 5 − 0 = 5, and u(x 1 1, x 0 2, x 1 3) − u(x 0 1, x 0 2, x 1 3) = 8 − 3 = 5.\n2. Similarly, the difference on x1 given x12 is 4, for both x 0 3 and x 1 3.\nThough x1 and x3 are CDI of each other, we see that both depend on x2. For example, the differences mentioned above for x1 are 5 and 4 given x02 and x 1 2 (respectively), hence the difference on x1 given fixed x3 depends on the value of x2. The CDI map for this example therefore includes an edge (x1, x2) and an edge (x2, x3). The maximal cliques of this graph are I1 = {x1, x2} and I2 = {x2, x3}.\nTo obtain the numeric decomposition, we first define (x01, x 0 2, x 0 3) as reference values. Next, from (6), we get u1(I1) = u([I1]) = u(x1, x2, x03) and u2(I2) = u([I2]) − u([I1 ∩ I2]) = u(x01, x2, x3) − u(x 0 1, x2, x 0 3). The functions involved are given in Table 1. Note that the fifth and sixth columns are obtained from the appropriate values of the fourth column; for example, u(x01, x2, x3) for the line x1 = 1, x2 = 1, x3 = 0 is the value u(x1, x2, x3) in the line x1 = 0, x2 = 1, x3 = 0. It is easy to verify that indeed u(x, y, z) = u1(I1) + u2(I2).\nThe CDI-GAI Theorem provides an operational form of GAI, by establishing a GAI decomposition that can be obtained from a collection of simple CDI conditions. The assumption or detection of CDI conditions can be performed incrementally, until the MVF is decomposed to a reasonable dimension. The CDI conditions, in turn, based as they are on invariance of preference differences, are relatively intuitive to detect. This is particularly true when the differences carry a direct interpretation, as in the case of willingness-to-pay: we can check invariance of the monetary amount a buyer is willing to pay to get one outcome over the other.\nThe GAI decomposition can be depicted graphically using a clique graph of the CDI map, that is, a graph whose nodes correspond to maximal cliques of the CDI map. For our purposes it is convenient to use a particular clique graph called a tree decomposition (or junction tree). We introduce this well-known concept, and discuss its implications for GAI representation.\nDefinition 11 (Tree Decomposition). A tree decomposition for a graph G = (N,E) is a pair (T,I), where T = (Ψ, E) is an acyclic graph, I = {Ii | i ∈ Ψ} is a collection of\nsubsets of N , each corresponding to a node in T , and (i) ⋃\ni∈I Ii = N , (ii) for each edge (n1, n2) ∈ E, there exists Ii such that n1, n2 ∈ Ii, and (iii) (running intersection) for any i, j, k ∈ Ψ, if j is on the path from i to k in T then Ii ∩ Ik ⊆ Ij .\nAny graph can be tree-decomposed, typically in more than one way. For example, there can be a single node in I. The width of a tree decomposition is maxi∈I |Ii| − 1, and the treewidth of a graph is the minimum width among all its possible tree decompositions.\nIt is easy to show that any maximal clique of G is contained within some i ∈ I. Therefore, by Theorem 3, a utility function decomposes additively over the subsets I = {Ii | i ∈ Ψ}, where T = (Ψ, E) is a tree decomposition of the CDI map. The notion of GAI tree is adapted from the work of Gonzales and Perny (2004), who introduce GAI graphical models for the expected utility framework.\nDefinition 12 (GAI Tree). A GAI tree for u(·) is a tree decomposition of the CDI map of u(·).\nWe therefore refer to the elements I1, . . . , Ig of a GAI decomposition as the set I of a tree decomposition. The next subsection provides a qualitative example of the CDI concept, its dependency graph, and corresponding GAI tree.\nThe results of this section lay out the foundations for using GAI decomposition in multiattribute trading mechanisms. The results generalize additive MVF theory, and justify the application of methods developed under the expected utility framework (Bacchus & Grove, 1995; Boutilier et al., 2001; Gonzales & Perny, 2004; Braziunas & Boutilier, 2005) to representation of monetary value under certainty. Table 2 summarizes the acronym terminology introduced up to this point."
    }, {
      "heading" : "3.2 Employing GAI in Procurement",
      "text" : "In this section we demonstrate the process of obtaining a GAI decomposition from the collection of CDI conditions. In addition, this example is used to motivate our approach\nin comparison to the work of Parkes and Kalagnanam (2005). Consider a procurement department that wishes to purchase new hard drives (HD) for the desktops of a large number of employees. The buyer cares about several characteristics (attributes) of the hard drives and the particular terms of the procurement contract. Each attribute is listed with a designated attribute name (the first letter), and its domain. In some cases (e.g., attribute I) we use arbitrary symbols to represent domain elements, abstracting from the meaningful interpretation they are assumed to have in context.\nRPM (R) 3600, 4200, 5400 RPM\nTransfer rate (T) 3.4, 4.3, 5.7 MBS\nVolume (V) 60, 80, 120, 160 GB\nSupplier ranking (S) 1, 2, 3, 4, 5\nQuality rating (Q) (of the HD brand) 1, 2, 3, 4, 5\nDelivery time (D) 10, 15, 20, 25, 30, 35 days\nWarranty (W) 1, 2, 3 years\nInsurance (I) (for the case the deal is signed but not implemented) α1, α2, α3\nPayment timeline (P) 10, 30, 90 days\nCompatibility (C) (with existing hardware and software) β1, β2, β3\nConsider, for example, the pair of attributes Quality and Warranty. The value of warranty is different for different values of quality; it is higher when the quality is known to be low, and lower when the quality is known to be high. The two attributes therefore depend on each other. Furthermore, we might expect that Volume complements both Quality and Warranty. Larger hard drives are more prone to failures, making the quality and warranty more valuable. Similarly, there is interdependence between Supplier ranking and the contract insurance we buy, and between Supplier ranking and the warranty the supplier provides. Other reasonable dependencies are among Delivery, Insurance, and Payment timeline (e.g., later delivery requires better insurance, later payment reduces the need for insurance), and between Volume to the RPM and Transfer rate. Preferences over compatibility may not depend on any other attribute. The corresponding CDI map is depicted in Figure 1a. As described in Section 2.1, the utility function decomposes over the elements of a tree decomposition of the CDI map. Such a tree decomposition is depicted in Figure 1b. In this example the set of elements of the tree decomposition correspond exactly to the maximal cliques of the CDI map. In general the tree decomposition might include supersets of the maximal cliques, but the decomposition can obviously be maintained over the supersets as well.\nNon-additive traders, if required to deal with an additive price space as in auction AD (Parkes & Kalagnanam, 2005), face an exposure problem, somewhat analogous to traders with combinatorial preferences that participate in simultaneous auctions (Wellman, Osepayshvili, MacKie-Mason, & Reeves, 2008). Essentially, the problem can manifest itself\nin two ways. One type of exposure occurs from one auction round to another, as in the following two-attribute example. A seller’s conditional preference order over an attribute a may be optimized at an assignment a1 given that the other attribute b is at b1, but if the assignment of b changes, a1 may become arbitrarily suboptimal. Therefore bidding a1 and b1 may result in a poor allocation if the seller is outbid on b1 (and thus must resort to another assignment) but left winning a1. The second exposure occurs in any single round of the auction, if a trader bids on multiple configurations. For example, suppose configurations (a1, b1) and (a2, b2) are both optimal at the current prices. Because bids are collected independently for each attribute, a trader bidding on both may end up with configuration (a1, b2), which again, may be arbitrarily suboptimal.\nWe can prevent exposure on the sellers’ part by taking simple measures in the auction design. First, bids are collected anew each round, independently of previous rounds, hence the first problem is avoided. Sellers can likewise avoid the second problem by limiting themselves to bid on one configuration per round.\nOn the buyer’s side, this solution does not work because we require the buyer to bid a full set of optimal configurations in each round, in order to ensure the auction’s convergence (this becomes clearer in Section 6.1). To prevent buyer exposure, our auction design structures prices according to the buyer’s preferences, and the traders bid on clusters of interdependent attributes. In terms of the example above, if a and b are interdependent (meaning CDI({a}, {b}) does not hold), we should be able to bid on the cluster ab. If b in turn depends on c, we need another cluster bc. This is still simpler than a general pricing structure that solicits bids for the cluster abc. More generally, we find all reasonable CDI conditions which are correct for the buyer, obtain the corresponding GAI tree decomposition, and solicit bids for clusters of attributes corresponding to these GAI elements. In Section 4, we describe our auction design in detail, along with an example in Section 5. In Section 6.1, we prove that the auction terminates with an (approximately) optimal solution to MAP."
    }, {
      "heading" : "4. GAI Auctions",
      "text" : "Before introducing our auction design, we reiterate our model and notation, and provide a definition that facilitates the auction presentation."
    }, {
      "heading" : "4.1 Notations and Definitions",
      "text" : "In the procurement setting, a single buyer wishes to procure a single good, in some configuration θ ∈ Θ from one of the candidate sellers s1, . . . , sm. The buyer has some private valuation function ub : Θ → %+, and similarly each seller si has a private cost function, ci. Both ub(·) and ci(·) are MVFs, for which utility differences express differences in willingnessto-pay, as explained in Section 2.1. Assume that the buyer’s preferences are reflected in a GAI structure I1, . . . , Ig. We call an assignment to GAI element Ir a sub-configuration. We use θr to denote the sub-configuration formed by projecting configuration θ to element Ir.\nDefinition 13 (Consistent Cover). A collection of sub-configurations {α1, . . . ,αg}, where for each r ∈ {1, . . . , g}, αr is an instantiation of Ir, is a consistent cover if for any r, r′ ∈ {1, . . . , g}, and any attribute aj ∈ Ir ∩ Ir′ , αr and αr′ agree on the assignment to aj .\nIn words, a consistent cover is a collection of sub-configurations from which we can compose a valid configuration. A collection {α1, . . . ,αg} which is a consistent cover can equivalently be considered a configuration, which we denote by (α1, . . . ,αg). For example, consider a good with three attributes: a, b, c. Each attribute’s domain has two possible assignments (e.g., {a1, a2} is the domain of a). Let the GAI structure be I1 = {a, b}, I2 = {b, c}. Here, sub-configurations are assignments of the form a1b1, a1b2, b1c1, and so on. The set of sub-configurations {a1b1, b1c1} is a consistent cover, corresponding to the configuration a1b1c1. In contrast, the set {a1b1, b2c1} is inconsistent."
    }, {
      "heading" : "4.2 The GAI Auction",
      "text" : "We define an iterative, descending-price multiattribute auction that maintains a GAI pricing structure: that is, in any round t, there is a price pt(·), corresponding to each subconfiguration of each GAI element. The price pt(θ) of a configuration θ at round t is defined in terms of the sub-configuration prices and a global discount term ∆,\npt(θ) = g∑\nr=1\npt(θr) −∆. (7)\nImportantly, the elements θr may refer to overlapping attributes. Bidders submit subbids on sub-configurations and on the global discount ∆.3 Sub-bids are submitted in each round and they expire in the next round. A sub-bid in round t for configuration θr is automatically assigned the price pt(θr). The set of full bids of a seller contains all consistent covers that can be generated from that seller’s current set of sub-bids. The existence of a full bid over a configuration θ represents the seller’s willingness to accept the price pt(θ) for supplying θ.\nAt the start of the auction, the buyer reports (to the auction, not to sellers) a complete valuation function ub(·). Under GAI, this can be expressed in decomposed form (6) with local functions (fb,1, . . . , fb,g), such that ub(θ) = ∑ r fb,r(θr). The initial prices of subconfigurations are set at some level above the buyer’s valuations, that is, p1(θr) > fb,r(θr) for all θr. The discount ∆ is initialized to zero. The auction has the dynamics of a descending\n3. The discount term could be replaced with a uniform price reduction across all sub-configurations.\nclock auction: at each round t, bids are collected for current prices and then prices are reduced according to price rules. A seller is considered active in a round if the set of subbids she submitted contains at least one full bid. In round t > 1, only sellers who were active in round t − 1 are allowed to participate, and the auction terminates when no more than a single seller is active. We denote the set of sub-bids submitted by si by Bti , and the corresponding set of full bids is\nBti = {θ = (θ1, . . . , θg) ∈ Θ | {θ1, . . . , θg} ⊆ B t i}.\nIn the example of Section 4.1, a seller could submit sub-bids on a set of sub-configurations such as {a1b1, b1c1}, and that combines to a full bid on a1b1c1.\nThe auction proceeds in two phases. In the first phase (A), at each round t the auction computes a set of buyer-preferred sub-configurations Mt: those sub-configurations that are part of a configuration which is within \" of being profit-maximizing for the buyer at the current prices. Formally, we first define the buyer profit from a configuration θ as4\nπtb(θ) = ub(θ) − p t(θ).\nThe buyer-preferred set of sub-configurations is then defined by:\nMt = {θr | π t b(θ) ≥ max θ′∈Θ πtb(θ ′) − \", r = 1, . . . , g}.\nIn Section 6.2 we show how Mt can be computed efficiently. We stress that though Mt is a set of sub-configurations, the criterion for selecting them is based on the profit over full configurations. Profits over individual sub-configurations are meaningless outside the context of configurations.\nIn Phase A, the auction adjusts prices after each round, reducing the price of every sub-configuration that has received a bid but is not in the buyer’s preferred set. Let \" be the prespecified price decrement parameter. Specifically, the Phase A price change rule is applied to all θr ∈ ⋃m i=1 B t i \\M t:\npt+1(θr) ← p t(θr) −\n\" g . [A]\nLet M t denote the set of configurations that are consistent covers in Mt:\nM t = {θ = (θ1, . . . , θg) ∈ Θ | {θ1, . . . , θg} ⊆ M t}.\nThe auction switches to Phase B when all active sellers have at least one full bid in the buyer’s preferred set:\n∀i. Bti = ∅ ∨ B t i ∩ M t ,= ∅. [SWITCH]\nLet T be the round at which [SWITCH] becomes true. At this point, the auction selects the buyer-optimal full bid ηi for each seller si.\nηi = arg max θ∈BTi\n(πTb (θ)). (8)\n4. We drop the t superscript in generic statements involving price and profit functions, understanding that all usage is with respect to the (currently) applicable prices.\nIn Phase B, si may bid only on ηi. Sub-configuration prices are fixed at pT (·) during this phase. The only adjustment is to ∆, which is increased in every round by \". By (7), any increase of ∆ decreases the current price of each of the configurations ηi. The auction terminates when at most one seller (if exactly one, designate it sî) is active. The allocation is determined according to four distinct cases:\n1. All sellers drop out in Phase A (i.e., before rule [SWITCH] holds). The auction terminates with no allocation.\n2. All active sellers drop out in the same round in Phase B. Of all the sellers that dropped in the last round, the auction selects a seller si for which ub(ηi) − pT (ηi) is maximal, and designates that seller as the winner sî. With a single winner, the appropriate case 3 or 4 is applied.\n3. The auction terminates in Phase B with a final price above the buyer’s valuation, pT (ηî) − ∆ > ub(ηî). It is still possible that there is exactly one seller (the winning seller) whose cost is below the buyer’s valuation, in which case a trade with positive surplus is possible. Therefore, the auction offers the winner sî an opportunity to supply ηî at price ub(ηî).\n4. The auction terminates in Phase B with a final price pT (ηî)−∆ ≤ ub(ηî). This is the ideal situation, where the auction allocates the chosen configuration and seller at this resulting price.\nCollect a reported valuation, ub(·) from the buyer; Set high initial prices, p1(θr) on each sub-configuration θr, and set ∆ = 0; while not [SWITCH], and at least one active seller do\nCollect sub-bids from sellers; Compute Mt; Apply price change by [A];\nend Compute ηi; while more than one active seller do\nIncrease ∆ by \"; Collect bids on (ηi,∆) from sellers;\nend Implement allocation and payment to winning seller;\nAlgorithm 1: GAI-based multiattribute auction.\nThe overall auction is described by high-level pseudocode in Algorithm 1. The role of Phase A is to guide the traders to their efficient configurations (MMP solutions), by reducing prices on configurations that are chosen by at least one seller but not preferred by the buyer. The price reduction makes such configurations slightly less attractive to the seller and slightly more attractive to the buyer. Phase B is a one-dimensional competition over the profit that remaining seller candidates can provide to the buyer. In the next section we formalize these notions, and prove that Phase A indeed converges and that Phase B\nselects a seller whose efficient configuration yields (approximately) the highest surplus. In Section 6.2 we discuss the computational tasks associated with the auction."
    }, {
      "heading" : "5. GAI Auction Example",
      "text" : "We illustrate the auction with a simple three-attribute scenario, employing the two-element GAI structure I1 = {a, b}, I2 = {b, c}. Table 3 shows the GAI utilities for the buyer and the two sellers s1, s2. The efficient allocation is (s1, a1b2c1): the buyer’s valuation is 55+85 = 140 and the cost of s1 for this configuration (boldface in the table) is 30+65 = 95, hence the surplus is 45. The maximal surplus of the second-best seller, s2, is 25, achieved by a1b1c1, a2b1c1, and a2b2c2. We set all initial prices over I1 to 75, all initial prices over I2 to 90, and \" = 8, meaning that price reduction for sub-configurations (\"/g) is 4.\nFor the sake of the example we assume that each seller bids in each round on the configuration that maximizes her profit (price minus cost), with respect to prices of the current round. In the next section we provide formal definitions and prove incentive properties for this strategy.\nTable 4 shows the progress of Phase A. Initially all configuration have the same price (165), so sellers bid on their lowest-cost configuration—a2b1c1 for both (with profit 80 to s1 and 90 to s2)—realized by sub-bids on a2b1 and b1c1. M1 contains the sub-configurations a2b2 and b2c1 of the highest value configuration a2b2c1, which yields buyer profit of −10. As we show in the next section (Lemma 7), this maximum does not change throughout Phase A. Price is therefore decreased on a2b1 and b1c1. After the price change, the profit of s1 for a2b1c1 is 72, and because she has higher profit (74) on a1b2c2 she bids on a1b2 and b2c2. Now (round 2) their prices go down, reducing the profit on a1b2c2 to 66 and therefore in round 3 s1 prefers a2b1c2 (profit 67). Note that at this point the configuration a2b2c2 yields profit of −16 to the buyer, which is within \" of the maximal buyer’s profit (-10), hence b2c2 is marked to be in M3.\nAfter the next price change, the configurations a1b2c1 and a1b2c2 both become optimal for s1 (profit 66), and the sub-bids a1b2, b2c1 and b2c2 capture the two. These configurations stay optimal for another round (5), with profit 62. In round 5 the profit for configuration a1b2c1 is 140 − 157 = −17, which is within \" of maximizing the buyer’s profit, therefore the sub-configuration a1b2 is added to M5. At this point s1 has a full bid (in fact two full bids: a1b2c2 and a1b2c1) in M5, and she no longer changes her bids because the price of her optimal configurations does not decrease. Seller s2 however sticks to a2b1c1 during the\nfirst four rounds, switching to a1b1c1 in round 5. It takes four more rounds for s2 and Mt to converge (M9 ∩ B92 = {a 1b1c1}).\nAfter round 9, the auction sets η1 = a1b2c1 (which yields more buyer profit than a1b2c2) and η2 = a1b1c1. In the second phase, which starts at this point, the sellers compete on the amount of surplus they transfer to the buyer, whose profit consequently becomes positive. For the next round (10) ∆ = 8, increased by 8 for each subsequent round. Note that p9(a1b1c1) = 133, and c2(a1b1c1) = 90, therefore the profit of s2 at this point is 43. In round 15, ∆ = 48 meaning p15(a1b1c1) = 85 and that causes s2 to drop out because his profit becomes negative. This ends the auction, and sets the final allocation to (s1, a1b2c1) and pT (a1b2c1) = 157 − 48 = 109. That leaves the buyer with a profit of 31 and s1 with a profit of 14."
    }, {
      "heading" : "6. Analysis",
      "text" : "We analyze the economic properties of the auction in Section 6.1, and address practical and computational issues in Section 6.2."
    }, {
      "heading" : "6.1 Economic Properties",
      "text" : "We adopt the following assumptions for this discussion:\nA1 The optimal (seller, configuration) pair provides non-negative surplus.\nA2 ub(·) is the real utility function of the buyer.\nWhen the optimal solution to MAP (3) provides negative surplus and sellers do not bid below their cost, the auction terminates in Phase A, no trade occurs, and the auction is trivially efficient. Therefore Assumption A1 does not cause loss of generality. A2 can be interpreted as follows: given non-truthful buyer report, our efficiency results below apply to the face value of the buyer’s report rather than to the true utility."
    }, {
      "heading" : "6.1.1 Properties of the buyer’s profit function",
      "text" : "For µ ⊆ {1, . . . , g}, we define the (partial) profit from a set of of sub-configurations θµ corresponding to µ as\nπb(θµ) = ∑\nr∈µ\n(fb,r(θr) − p(θr)).\nThe functions f come from the GAI breakdown of ub as in (6).\nLemma 4. For any µ and its complement µ̄,\nπb(θ) = πb(θµ) + πb(θµ̄)\nProof. From (6) and from the definition of πb(θµ) we get\nπb(θ) = ∑\nr∈µ\n(fb,r(θr) − p(θr)) + ∑\nr∈µ̄\n(fb,r(θr) − p(θr)) = πb(θµ) + πb(θµ̄).\nIn round 5 of the example in the previous section, the sub-configuration a1b2 is placed in M because the configuration a1b2c1 is within \" of the maximal buyer profit −10. Actually, at that point not only a1b2c1 is added to M t, but also a1b2c2 whose buyer profit (−23) is not within \" of the maximum. If a1b2c2 is later selected as ηi for some si this could lead to additional efficiency loss, beyond \". The following lemma bounds this potential loss.\nLemma 5. Let Ψ be a set of configurations, all within \" of maximizing profit for a trader τ (buyer or seller) at given prices. Let Φ = {θr | θ ∈ Ψ, r ∈ {1, . . . , g}}. Then any consistent cover in Φ is within g\" of maximizing profit for τ under the same prices.\nIn particular, if Ψ includes only exactly optimal configurations, any consistent cover will be exactly optimal as well. The proof (in Appendix B.1) relies on our definition of the GAI decomposition as a tree decomposition, and uses the partial profit function defined above along with Lemma 4.\nThe bound above is tight, in that for any GAI tree and nontrivial domain we can construct an example set Ψ as above in which there exists a consistent cover whose utility is exactly g\" below the maximal.\nAs a result we get the following corollary.\nCorollary 6. ∀θ ∈ M t. πtb(θ) ≥ max\nθ′∈Θ πtb(θ ′) − g\"\nProof. Apply Lemma 5 for πtb: define Ψ as the set of configurations within \" of maxθ′∈Θ π t b(θ ′). Mt, by its definition, serves as Φ in the lemma. M t is then exactly the set of consistent covers over Φ, and hence each θ ∈ M t must be within g\" of the optimum maxθ′∈Θ πtb(θ ′).\nWe now show that, as noted in the example, the maximal profit of the buyer does not change during Phase A.\nLemma 7. maxθ∈Θ πtb(θ) = maxθ∈Θ π 1 b (θ) for any round t of Phase A.\nProof. Assume there exists some θ′ for which πt+1b (θ ′) > πtb(θ ′). Then necessarily pt+1(θ′) = pt(θ′) − δ for some δ > 0. The only price change is by Rule [A], meaning that some w ≤ g sub-configurations of θ′ are not in Mt, and δ = w\"g . In that case, by definition of M t,\nπtb(θ ′) < max θ∈Θ πtb(θ) − \".\nTherefore,\nπt+1b (θ ′) = πt(θ′) + δ = πt(θ′) +\nw\"\ng ≤ πt(θ′) +\ng\"\ng < max θ∈Θ πtb(θ).\nThis is true for any θ′ whose profit improves, therefore maxθ∈Θ πtb(θ) does not change during Phase A, and hence equals its value in round 1."
    }, {
      "heading" : "6.1.2 Straightforward bidding sellers",
      "text" : "We now turn our attention to the sellers’ behavior. We first define the profit function of seller si by πti(θ) = p t(θ) − ci(θ).\nDefinition 14 (Straightforward Bidder). A seller is called a straightforward bidder (SB) if at each round t she bids on Bti as follows: if maxθ∈Θ π t i(θ) < 0, then B t i = ∅. Otherwise select bti ∈ arg maxθ∈Θ π t i(θ), and set\nBti = {θr | θ ∈ b t i, r ∈ {1, . . . , g}}.\nIntuitively, SB sellers follow a myopic best response strategy, optimizing profit with respect to current prices. This approach was termed “straightforward” by Milgrom (2000) in the sense that agents bid myopically, rather than strategically anticipating subsequent price responses.\nSB sellers can choose any optimal configuration to bid on; none of the results proved below is affected by this choice. It is also important to note that SB sellers find their optimal full configuration bti, rather than optimize each GAI element separately. The configuration b t i is translated to its set of sub-configurations Bti . In order to calculate b t i, seller si needs to find the optimum of her current profit function. In Section 6.2 we show that this optimization problem is tractable under the assumption that ui(·), too, has a compact GAI structure.\nThe following is an immediate corollary of the definition of SB.\nCorollary 8. For SB seller si,\n∀t,∀θ ∈ Bti . π t i(θ) = max θ′∈Θ πti(θ ′).\nIn general, sellers’ preference structure may not coincide with the auction’s price structure. Nevertheless, Corollary 8 holds by definition of SB, because Bti (defined in Section 4.2) contains a single configuration which is the submitted bid bti. Alternatively, the definition of SB can be modified, so sellers with GAI preferences consistent with the auction’s price structure can bid on multiple optimal configurations (if such exist). If sellers bid on multiple configurations, this can speed up convergence. In that case bti denotes a set of submitted configurations, Bti denotes the respective collection of sub-configurations, and B t i is the set of consistent covers over Bti . Lemma 5 (with \" = 0) entails that Corollary 8 still holds. However, for simplicity of the analysis we retain Definition 14."
    }, {
      "heading" : "6.1.3 Efficiency given SB",
      "text" : "Lemma 9 states that through the price system and price change rules, Phase A leads the buyer and each of the sellers to their mutually efficient configuration. Formally, we are interested in maximizing the function σi : Θ → %, which represents the surplus ub(·)− ci(·). For any prices pt,\nσi(θ) = π t b(θ) + π t i(θ).\nLemma 9. For SB seller si, ηi is g\"-efficient:\nσi(ηi) ≥ max θ∈Θ σi(θ) − g\".\nProof. Configuration ηi is chosen to maximize the buyer’s profit out of Bti at the end of Phase A. Because Bti ∩ M\nt ,= ∅, a configuration ηi ∈ M t is available in Bti , hence one must be chosen to maximize buyer’s utility. For any θ̃, and for any ηi ∈ Bti , we get from Corollary 8,\nπTi (ηi) ≥ π T i (θ̃),\nand from Corollary 6, we get for any ηi ∈ M t,\nπTb (ηi) ≥ π T b (θ̃) − g\".\nBecause ηi ∈ Bti ∩M t we can add up the two inequalities and get σi(ηi) ≥ σi(θ̃)− g\", which is the desired result.\nBased on Phase B’s simple role as a single-dimensional bidding competition over the discount, we next assert that the overall result is efficient under SB, which in turn (Section 6.1.4) proves to be an approximately ex-post equilibrium strategy in the two phases.\nTheorem 10. Given a truthful buyer and SB sellers, the surplus of the final allocation is within (g + 1)\" of the maximal surplus.\nProof Sketch: we first establish that the auction must reach Phase B. To do that, we show that in each round of Phase A, a price of at least one sub-configuration is reduced, whereas by Lemma 7, maxθ∈Θ πtb(θ) does not change. The latter enforces a lower bound on how far prices can be reduced within Phase A, hence Phase A must terminate. Because initial prices are above the buyer’s valuation, a seller whose surplus (MMP solution) is positive cannot drop during that phase, so using Assumption A1 we show that the only way\nfor Phase A to terminate is by reaching condition [SWITCH]. Next, we show that for any two sellers, the surplus of the first to drop from the auction cannot be significantly higher than that of the one who stayed longer. This ensures that the winning seller is the efficient one, or one whose MMP surplus is almost maximal, and from Lemma 9 the auction must obtain (almost) all of that surplus. The full proof is given in Appendix B.2.\nThe bound guaranteed by Theorem 10 is a worst-case bound, and as shown experimentally in the following sections the auction typically achieves efficiency closer to the optimum. In the example of Section 5, the difference in the efficiencies of the two sellers is lower than the potential efficiency loss (as (g + 1)\" = 24). However, for that instance it is still guaranteed that s1 wins, either with the efficient allocation, or with a1b2c2 which provides a surplus of 39. The reason is that these are the only two configurations of s1 with surplus within g\" = 16 of the solution to MMP(b, s1), hence by Lemma 9 one of them must be chosen as η1. Both of these configurations provide more than \" surplus over s2’s most efficient configuration, and this is sufficient in order to win in Phase B.\nThe bound of Theorem 10 can be improved when the CDI map contains disconnected components. For example, when a fully additive decomposition (as assumed in previous literature) does exist, the CDI map contains a disconnected component for each attribute. To take advantage of this disconnectedness we create a separate tree decomposition for each disconnected components. The definition of M has to be adapted to apportion \" proportionally across the disconnected trees. Formally, we redefine Mt as follows.\nDefinition 15 (Buyer’s Preferred Set). Let G be comprised of trees G1, . . . , Gh. Let θj denote the projection of a configuration θ on the tree Gj , and gj the number of GAI elements in Gj . Similarly, Θj denotes the projection of Θ on Gj . Define\nMtj = {θr | π t b(θj) ≥ max θ′j∈Θj πtb(θ ′ j) − gj\n\" g , r ∈ Gj}.\nThe buyer’s preferred set is given by Mt = ⋃h\nj=1 M t j .\nLet ej = gj − 1 denote the number of edges in Gj . We define a connectivity parameter, e = maxj=1,...,h ej . It turns out that e + 1 can replace g in the approximation results. The first step is to replace Corollary 6 with this tighter bound on the optimality of configurations in M t.\nCorollary 11. ∀θ ∈ M t. πtb(θ) ≥ max\nθ′∈Θ πtb(θ ′) − (e + 1)\"\nProof. We apply Lemma 5 for each Gj , but with gj \" g instead of \", hence any consistent cover over Mtj is within gj \" ggj of maxθ′j∈Θj π t b(θ ′ j). From Lemma 4, we get that any consistent cover over Mt (meaning any configuration in M t) is within ∑h\nr=1 gj \" ggj of maxθ′∈Θ π t b(θ ′).\nAs e + 1 = maxj=1,...,h gj , this is bounded by \" g ∑h r=1 gj(e + 1) = \"(e + 1).\nWe can now obtain a tighter efficiency result.\nTheorem 12. Given a truthful buyer and SB sellers, the surplus of the final allocation is within (e + 2)\" of the maximal surplus.\nIn the fully additive case this loss of efficiency reduces to 2\". On the other extreme, if the CDI map is connected then e + 1 = g, reducing Theorem 12 to Theorem 10. If we do not assume any preference structure for the buyer, meaning that the CDI map is fully connected, then e = 0 and the efficiency loss is again proportional to \"."
    }, {
      "heading" : "6.1.4 Sellers’ incentives to use SB",
      "text" : "Following Parkes and Kalagnanam (2005), we relate our auction to the Vickrey-ClarkeGroves (VCG) mechanism to establish incentive properties for the sellers. In the one-sided multiattribute VCG auction, the buyer reports valuation ub, the sellers report cost functions ĉi, and the buyer pays the sell-side VCG payment to the winning seller.\nDefinition 16 (Sell-Side VCG Payment). Let (θ∗, i∗) be an optimal solution to MAP . Let (θ̃, ĩ) be the best solution to MAP when i∗ does not participate. The sell-side VCG payment is\nVCG(ub, ĉi) = ub(θ ∗) − max(0, ub(θ̃) − ĉ̃i(θ̃)).\nIt is well known that truthful bidding is a dominant strategy for sellers in the one-sided VCG auction. Parkes and Kalagnanam (2005) showed that the maximal regret for buyers from bidding truthfully in this mechanism is ub(θ∗) − ci∗(θ∗) − (ub(θ̃) − ĉ̃i(θ̃)), that is, the marginal product of the efficient seller.\nAs typical for iterative auctions, the VCG outcome is not exactly achieved, but the deviation is bounded by the minimal price change.\nDefinition 17 (δ-VCG Payment). A sell-side δ-VCG payment for MAP is a payment p such that\nVCG(ub, ĉi) − δ ≤ p ≤ VCG(ub, ĉi) + δ.\nWhen payment is guaranteed to be δ-VCG, sellers can affect their payment only within that range, hence their gain from falsely reporting cost is bounded by 2δ.\nLemma 13. When sellers are SB, the GAI auction payment is sell-side (e + 2)\"-VCG.\nIn the example of Section 5, the profit of the winner (14) is less than \" below his VCG profit 20. The proof (in Appendix B.4) also covers Case 3 in the allocation options of Section 4.2, in which we force the payment to equal ub(ηî).\nWe are now ready for our final result of this section, showing that the approximately efficient outcome guaranteed by Theorem 12 is achieved in an (approximate) ex-post Nash equilibrium.\nTheorem 14. SB is a (3e + 5)\" ex-post Nash equilibrium for sellers in the GAI auction. That is, sellers cannot gain more than (3e + 5)\" by deviating from SB, given that other sellers follow SB.\nIn order to exploit even this bounded potential gain, sellers need to know, for a given configuration in M t, whether it was explicitly selected as approximately optimal for the buyer, or it is a combination of sub-configurations from approximately optimal configurations. It seems highly unlikely for sellers to have such information. They are more likely to lose if they do not bid on their myopically optimal configurations."
    }, {
      "heading" : "6.2 Computation and Complexity",
      "text" : "The advantage of GAI auctions over an additive auction such as AD (Parkes & Kalagnanam, 2005) is in economic efficiency: by accommodating expressive bidding, the efficiency results are with respect to a more accurate utility function. In contrast, the key advantage with respect to an auction that does not employ preference structures, such as auction NLD (Parkes & Kalagnanam, 2005), is in computational efficiency. The property we show in this section is that all computations are exponential only in the size of the largest GAI element, rather than in |A|. In particular, the size of the price space the auction maintains is equal to the total number of sub-configurations. This number is exponential in the treewidth (plus one) of the original CDI map.5 To ensure computational tractability, one can define a priori a constant C, and force the treewidth of the CDI map to be bounded by C by ignoring some of the interdependencies. This is still much better than using an additive representation that ignores all interdependencies. The constant represents a tradeoff between economic and computational efficiency; a larger C supports a more accurate preference representation, but the GAI elements may be larger.\nFor the purpose of computational analysis, let I = ⋃g\nr=1 ∏ aj∈Ir D(aj), that is the col-\nlection of all sub-configurations. Since M t grows monotonically with t, näıve generation of the best outcomes sequentially might end up enumerating significant portions of the domain. Fortunately, this enumeration can be avoided, and the complexity of this computation (as well as the optimization performed by the seller) grows only with |I|, that is, no computation depends on the size of the exponential domain.\nTheorem 15. The computation of Mt can be performed in time O(g|I|2). Moreover, the total time spent on this task throughout the auction is O(g|I|(|I| + T )).\nWe obtain a bound on T , the number of rounds of Phase A, by comparing the sum of prices of all sub-configurations in rounds 1 and T .\nTheorem 16. The number of rounds required by the auction is bounded by\nT ≤ ∑\nθr∈I\np1(θr) g\n\" .\nProof. Let Σi = ∑\nθr∈I p i(θr) (the sum of prices of all sub-configurations in round i).\nAssume that Σi < 0 for some 1 ≤ i ≤ T . Then because ub(·) ≥ 0, there must exist θ ∈ Θ for which πib(θ) > 0. Because we chose initial prices such that for all θ ∈ Θ, π 1 b (θ) < 0, this contradicts Lemma 7. Therefore, ΣT ≥ 0, hence the sum of prices cannot be reduced by more than Σ1 =\n∑ θr∈I p\n1(θr) throughout the auction. Also, in each round at least one price is reduced by g\" . This leads to the required result.\nThis bound is rather loose—its purpose is to ensure that the number of rounds does not depend on the size of the non-factored domain. It depends on the number of subconfigurations, and on the result of dividing the initial price by the minimum price decrement. Usually Phase A converges much faster. Let the initial negative profit chosen by the auctioneer be m = maxθ∈Θ π1b (θ). In the worst case, Phase A needs to run until\n5. The use of the term treewidth is subject to using an optimal tree decomposition.\n∀θ ∈ Θ. πb(θ) = m. This happens for example when ∀θr ∈ I. pt(θr) = fb,r(θr) + m g . That implies that the closer the initial prices reflect the buyer’s valuation, the faster Phase A converges. One extreme choice is to set p1(θr) = fb,r(θr) + m g . That would make Phase A redundant, at the cost of full initial revelation of the buyer’s valuation (Section 2.3). Between this option and the other extreme, which is ∀α, α̂ ∈ I. p1(α) = p1(α̂), the auctioneer has a range of choices to determine the right tradeoff between convergence time and information revelation. In the example of Section 5, the choice of a lower initial price for the domain of I1 provides some speedup by revealing a harmless amount of information. In our simulations below, we also set constant initial prices within each GAI element.\nFurthermore, many domains have natural dependencies that are mutual to traders, in which case the price structure used by the auction may also accommodate sellers’ preference structures. If so, sellers can bid on multiple equally profitable configurations in each round, thus speeding up convergence, as discussed above in Section 6.1.\nWe also consider computational complexity of the SB strategy for sellers.\nTheorem 17. Let ρb denote the treewidth of the CDI map of ub(·), and let ρi denote the treewidth of the CDI map of ui(·). The optimization of ui(·) − p(·) takes time exponential in ρb + ρi in the worst case.\nProof. Consider the graph G which includes the union of the edges of the two CDI maps. The treewidth of G is ρb + ρi in the worst case. By definition, the price function p(·) is decomposed according to ub(·), hence ui(·)−p(·) decomposes according to the additive GAI factors of ui(·) and ub(·). Therefore, for any pair of attributes x and y which have a mutual factor in ui(·) − p(·), there is an edge x, y in G. It is well known that the complexity of combinatorial optimization is exponential only in the treewidth of such graph—for example, using cost networks (Dechter, 1997).\nOf potential concern may be the communication cost associated with the descending auction style. The sellers need to send their bids over and over again at each round. A simple change can be made to avoid much of the redundant communication: the auction can retain sub-bids from previous rounds on sub-configurations whose price did not change. Because combinations of sub-bids from different rounds can yield suboptimal configurations, each sub-bid should be tagged with the number of the latest round in which it was submitted, and only consistent combinations from the same round are considered to be full bids. With this implementation sellers need not resubmit their bid until a price of at least one of its sub-configurations has changed.\nTo summarize, GAI auctions are shown to perform well on the criteria mentioned in Section 2.3: they achieve approximate efficiency given reasonable incentive properties, they are expressive enough to accommodate preferences with interdependencies among attributes, they are tractable when the maximal size of GAI clusters is reasonably bounded, and they do not require full revelation of utility. Performance on this last criterion is quantified in the experimental part of the paper."
    }, {
      "heading" : "7. Experimental Design",
      "text" : "The main idea behind GAI auctions is to improve efficiency over auctions that assume additivity, when preferences are not additive. However, (given a fixed \") the theoretical\nefficiency guarantee of GAI auctions depends on e, the connectivity parameter of the GAI tree. This suggests a tradeoff: complex models more accurately represent true utility, but can increase approximation error due to higher connectivity. An obvious question is whether more accurate preference modeling is indeed more efficient, and in particular, whether GAI auctions are more efficient than additive auctions, given that the preferences are not additive. To address the question experimentally, we assume that the buyer’s preferences have some GAI structure, and compare the performance of GAI auctions that model this structure with the performance of auctions that are restricted to an additive representation. For the latter, we use an instance of GAI auction in which the pricing structure is additive, and name it the additive approximating auction (AP). This auction is similar in principle to auction AD (Parkes & Kalagnanam, 2005).6 To the best of our knowledge, AD is the only proposed instance of a surplus-maximizing multiattribute auction based on additive preferences, besides those that require full revelation of the buyer’s utility. In all of the experiments, sellers employ SB strategies.\nIn Section 7.1 we describe how random GAI utilities are drawn, and in Section 7.2 we extend the scheme to generate GAI utility functions that exhibit additional structure. In Section 7.3 we show how we obtain an additive approximation of these random functions, allowing us to simulate auction AD. The results of the simulations are presented in Section 8."
    }, {
      "heading" : "7.1 GAI Random Utility",
      "text" : "We performed simulations using randomly generated utility functions representing the buyer’s value function and sellers’ cost functions. Our random utility generation procedure follows the utility elicitation procedure suggested by Braziunas and Boutilier (2005), and uses a two-step process: first we create local utility functions over each GAI element, normalized to the range [0, 1]. Next, we draw scaling constants that represent the relative weight of each local function in the overall utility.\nMore formally, let ūr(Ir) = u([Ir]) denote a local utility function over Ir, each normalized to [0, 1]. Next, let f̄r(Ir) be defined according to the GAI functional form of Eq. (6), with u([Ir]) replaced with ūr(Ir), hence\nf̄1 = ū1(I1), and\nfor r = 2, . . . , g, f̄r = ūr(Ir) + r−1∑\nj=1\n(−1)j ∑\n1≤i1<···<ij<r\nūr([ j⋂\ns=1\nIis ∩ Ir]). (9)\nBraziunas and Boutilier (2005) show that for GAI-structured utility, there exist scaling constants λr ∈ [0, 1] such that\nū(A) = g∑\nr=1\nλrf̄r(Ir). (10)\n6. Both auctions employ an additive price space that drives bidders to their efficient configurations. AD is efficient up to ! when the buyer and all the sellers have additive preferences. GAI auctions are !-efficient given additive buyer’s preferences, and make no assumption regarding sellers’ preference. There are some more structural differences: (i) AD employs more complicated price change rules, in order to allow sellers to ignore some of the attributes, (ii) discounts can be used in any stage of AD, and the auction selects a provisional winner at each iteration.\nWe refer to the functions ūr(Ir) as subutility functions. Note that values of the form ūr([Iir ∩Iir′ ]) are drawn only once and used in both ūr(Ir) and ūr(Iir′ ). This representation lets us draw random GAI functions, for a given GAI tree structure, using the following steps:\n1. Draw random subutility functions ūr(Ir), r = 1, . . . , g in the range [0,1].\n2. Compute f̄r(·), r = 1, . . . , g using (9). 3. Draw random scaling constants λr, such that ∑g\nr=1 λr = 1, and compute ū(A) by (10).\nThe scaling constants represent the importance the decision maker accords to corresponding GAI elements in the overall decision. The procedure results in utilities that are normalized in [0, 1]. Finally, for each particular trader we draw mean µ and variance σ, and scale ū(·) to the range [µ− σ, µ + σ], resulting in the utility functions ub(·) and ui(·) for i = 1, . . . ,m."
    }, {
      "heading" : "7.2 Structured Subutility",
      "text" : "A subutility function in the model above may represent any valuation over the subspace. In practice we may often find additional structure within each GAI element. We introduce two structures which we consider most typical and generally applicable, and we use them for the simulations, along with completely random local functions.\nAs we argue in Section 2.1, typical purchase and sale decisions exhibit FOPI (first order preferential independence), meaning that most or all single attributes have a natural ordering of quality. For example, hard-drive buyers always prefer more memory, higher RPM, longer warranty, and so on. To implement FOPI, we let the integer values of each attribute represent its quality. For example, if a belongs to some GAI element Ir = {a, b}, we make sure that ūr(ai, b′) ≥ ūr(aj , b′) for any ai > aj , ai, aj ∈ D(a), and any b′ ∈ D(b). This must of course hold for any attribute a that is FOPI, and any GAI element Ir that includes a. We enforce the condition after all the values for that GAI element have been drawn, through a special-purpose sorting procedure, applied between steps 1 and 2 above.\nThe FOPI condition makes the random utility function more realistic, and in particular more appropriate to the target application. Once attributes exhibit FOPI, the dependencies among different attributes are likely to be framed as complements or substitutes. These concepts are known primarily in the context of combinatorial preferences, that is, preferences over combinations of distinct items. In the multiattribute framework, two attributes are complements if an improvement in the value of both is worth more than the sum of the same improvement in each separately. Two attributes are substitutes if it is the other way around. These concepts are meaningful only with respect to attributes that are FOPI, otherwise the notion of improvement is conditional on the value of other attributes.\nDefinition 18 (Complements and Substitutes). Let u(·) be a measurable value function over S′. Let a, b ∈ S′, and Z = S′ \\ {a, b}, and assume that a and b are each FOPI of the rest of the attributes. Attributes a and b are called complements if for any ai > aî (ai, aî ∈ D(a)) and any bj > bĵ (bj, bĵ ∈ D(b)), and any Z ′ ∈ D(Z),\nu(ai, bj , Z ′) − u(aî, bĵ , Z ′) > u(ai, bĵ , Z ′) − u(aî, bĵ , Z ′) + u(aî, bj , Z ′) − u(aî, bĵ , Z ′).\nAttributes a and b are substitutes if the inequality sign is (always) reversed.\nThis relationship between attributes is ruled out under an additive utility function, but admitted under a weaker independence condition, called mutual utility independence (MUI) (Keeney & Raiffa, 1976), which implies that the utility function can be either multiplicative or additive. If it is multiplicative, the utility function can be represented by n singledimensional functions, n scaling constants, and a single parameter k (the MUI-factor) that controls the strength of complementarity (k > 0) or substitutivity (k < 0) between all pairs of attributes within a GAI element (for k = 0 the set of attributes is additive).7 For experimental purposes, we assume that each attribute cluster (GAI element) exhibits MUI, and that the value of k is the same for all.\nIn an elicitation procedure, one would normally extract the MUI scaling constants from a user, and then compute k (Keeney & Raiffa, 1976). For our purposes, we first determine k according to the relationship we wish to impose on the attributes, and then draw MUI scaling constants that are consistent with this value. More explicitly, we draw random scaling constants, and then iteratively modify all the constants, until a set of constants is found that is consistent with k. The next step is to compute ūr(Ir) according to the MUI formula (Keeney & Raiffa, 1976). The ūr(Ir) (for all r) are in the range [0, 1], hence at this point we can proceed with steps 2 and 3 above. Note that in this procedure several distinct sets of scaling constants are used: the g constants used in step 3 scale the different GAI elements, whereas the MUI constants, per GAI element, scale the attributes within the element."
    }, {
      "heading" : "7.3 Additive Approximation",
      "text" : "Another issue for experiment design is how the additive auction (AP) behaves in the face of non-additive buyer preferences, specifically how would it select the approximately buyerpreferred sets of configurations. The approach we took is to come up with an additive function that approximates the buyer’s true utility function, and use it throughout the auction. We are not aware of a better strategy, but do not rule out the possibility that one exists.\nA natural approach to generate a linear approximation ∑\ni f̂i(·) for an arbitrary function ub(·) is to use linear regression. We define an indicator variable xij for every aij ∈ D(ai), and consider any value of an assignment as a data point. For example, the assignment a1j(1) , . . . , amj(m) creates the following data point:\nm∑\ni=1\n∑\naij∈D(ai)\ncijxij = u(a1j(1) , . . . , amj(m)),\nin which the value of the variable xij is 1 if j = j(i) and 0 otherwise. The coefficients cij result from the regression and represent the values to be used as f̂i(aij ).\nWhen the problem includes many attributes, it is not possible to consider all the points in Θ. Under the assumption that a compact GAI representation exists, it is sensible to expect that we could use fewer data points for the regression. We indeed found that a small\n7. We formalize this notion in Appendix D.\nrandom sample from the joint utility yields an approximation as effective as one based on all the points. More precisely, for the largest domain we tested (25 attributes, each with domain of size 4) we found that the efficiency of AP does not improve when increasing the number of sampled points beyond 200. We show a chart supporting this claim in Appendix E. Our experiments use 300 points for all instances.\nThis method of comparison probably overestimates the quality of an additive approximation. In general, we would not have the true utility function explicitly when we generate the approximation. Extraction or elicitation of the utility function is usually the most serious bottleneck of a multiattribute mechanism. Therefore, the major reason to use an additive approximation is to reduce the burden of elicitation. Hence in practice we would try to obtain the additive function directly, rather than obtain the full utility and then approximate it. The result of such process is somewhat unpredictable, because the elicitation queries may not be coherent: if willingness to pay for a1 depends on the value of b, then what is the willingness to pay for a1 when we do not know b? We therefore consider our experimental generation method biased in favor of the additive approximation."
    }, {
      "heading" : "8. Simulation Results",
      "text" : "We provide detailed results of our simulation study. Section 8.1 provides and analyses economic efficiency results. Section 8.2 covers the computational study, and results regarding revelation of private information are provided in Section 8.3."
    }, {
      "heading" : "8.1 Efficiency and GAI Structure",
      "text" : "We measure efficiency in terms of percentage of the MAP solution, which is the surplus achieved by the optimal seller-configuration pair. To evaluate the effect of preference modeling on efficiency, we vary structural parameters of the buyer’s GAI preferences: the connectivity factor e, and the size ξ of the largest GAI element. Performance depends on many additional factors, such as the size of attribute domains, number of sellers, amount of price decrement (\"), and the distribution from which utility functions are drawn. To isolate the primary structural parameters, we first tested how efficiency varies according to the choices of these side factors, for several fixed GAI structures with fully random subutility functions. As a result of these tests, we picked the following parameter values for the rest of the simulations: all valuations are drawn from a uniform distribution, with buyer mean set at 500. A mean for each seller is drawn uniformly from [500, 700]. The variance is set at 200 for all traders. We use the same domain size of 3 or 4 for all attributes, and number of sellers m = 5. Further explanation of the process leading to these choices is provided in the full report (Engel, 2008).\nIn the following experiment we used a roughly fixed GAI structure, with g = 6 elements and e = 5, (that is, the GAI structure is a tree, not a forest), and \" = 24 (meaning reduction of δ = 4 per sub-configuration). We vary the number of attributes by varying the size of each element. Figure 2a shows the efficiency obtained with respect to ξ, the size of the largest GAI element. As expected, the size of the GAI elements has negligible, or no effect on the efficiency of GAI auctions. It has a dramatic effect on the efficiency of AP. When ξ = 1, the decomposition is in fact additive and hence AP performs optimally. The performance then deteriorates as ξ increases.\nWe performed the same test when using utility in which all attributes are FOPI. With the FOPI restriction, the additive approximation is much more efficient relative to unconstrained random utility. When FOPI applies to a strict subset of the attributes, we would expect the efficiency of AP to fall somewhere between its efficiency under FOPI and the unrestricted case. Somewhat surprisingly, imposing FOPI renders the GAI auctions slightly less efficient. Nevertheless, the additive approximation achieves lower efficiency compared to the accurate preference modeling, with differences that pass the statistical significance test (P < 0.01), for ξ ≥ 3. Further, note that the performance of GAI auctions can always be improved using a smaller value of \" and δ = \"g , whereas this hardly improves performance of AP. With δ = 2, a statistically significant difference (with the same confidence level) is already detected for ξ ≥ 2. We used δ = 2 hereafter.\nThe next experiment (Figure 2b) measures efficiency as a function of e, for a given fixed ξ. We assume connected GAI trees, so e is the number of GAI elements minus one. We tested structures with e varying from 1 to 10, all elements of size 3 to 5, and ξ = 5 for all the structures.8 On a single element, the GAI auction is similar to NLD (Parkes & Kalagnanam, 2005), which is an auction that assigns a price to every point in the joint domain. Here e = 0, hence the efficiency of GAI is close to perfect. This structure is on the other extreme compared to an additive representation, and indeed the performance of AP is particularly inferior (only 70% efficient).\nWith more GAI elements, the efficiency of GAI auctions declines at a very slow pace. The theoretical potential error (e + 2)\", is mostly a result of efficiency loss of ηi for the winning seller, based on Lemma 5. Such efficiency loss may occur only if each sub-configuration in ηi belongs to a configuration that yields the lowest profit allowed in the buyer-preferred set—a particularly rare case. In practice, the loss is closer to eδ, which is a much smaller error.\nThe performance of AP improves as the number of elements grows while their maximal and average sizes are fixed. Intuitively, changing the structure that way takes it closer to\n8. We did not find the particular tree structure to be influential on the results; the final structure used in the reported results has a maximum of three children per node.\nan additive representation. Under FOPI, we see a similar phenomenon as before. However, the difference between GAI FOPI and AP FOPI, even for ten elements, is substantial and statistically significant.\nFigures 3a and 3b present efficiency as a function of the MUI-factor k, for complements and substitutes, respectively. We used a fixed GAI structure with four elements, the largest of which has four attributes, and imposed the same k on all elements. As expected, the stronger the complementarity among the attributes, the lower the efficiency of AP, whereas this relationship does not affect the efficiency of GAI auctions. For the case of substitutes, in contrast, the additive approximation performs well, as efficiency starts to deteriorate only for extreme values of k. Very roughly, we can say that when relationship among attributes (within each GAI element) is limited to (mild) substitutions, it could be a good idea to use an additive approximation. Unfortunately, our interpretation of the parameter k lacks quantitative scaling: there is no clear intuition of what the actual numbers mean, beyond the qualitative classification mentioned above.\nTo summarize this part, the experimental results show that GAI auctions yield significant efficiency improvement in comparison to an additive auction, on almost all classes of evaluations. Though the efficiency of an additive auction may come across as relatively high and perhaps sufficient, such an observation is misleading in several respects. (i) In large procurement events, 5–10% efficiency differences translate to large amounts of money. (ii) The wider efficiency loss of an additive auction (with no theoretical bound) may have an impact on incentives; SB may no longer be an approximate ex-post Nash equilibrium. (iii) Efficiency is expected to deteriorate for larger problems with larger GAI elements, and in particular if FOPI does not hold for many of the attributes. (iv) As argued in Section 7.3, we expect practical additive auctions to perform worse than AP with our tailored approximation."
    }, {
      "heading" : "8.2 Computational Analysis",
      "text" : "The computational tasks required by auction simulations were performed using the algorithms described in Appendix C. These algorithms have been suggested and applied for\ncombinatorial optimization problems before (Dechter, 1997; Nilsson, 1998), therefore the computational runtime to process a round is not of particular interest to this work. Instead, we focus on the number of rounds the auction requires. We tested the number of rounds required by auctions GAI and AP, under fully random and FOPI preferences, varying three of the parameters: ξ (size of largest GAI element), e (connectivity), and δ.\nThe complexity in terms of number of rounds is shown in Figure 4a (with respect to ξ) and Figure 4b (with respect to the number of elements). We observe that under FOPI the GAI auction takes much longer to converge, compared to the case of random preferences. The reason is that under FOPI, the sellers’ and the buyer’s preferences can in general be seen as opposites: at the same price, and for a specific attribute, the buyer prefers higher quality, whereas the sellers prefer lower quality (given fixed values for the rest of the attributes), and everyone agrees on the relative quality of attribute values. The apparent difference in the growth rate (the FOPI case seems to have a steeper curve) is somewhat misleading: for ξ = 8 (not shown) GAI under random preferences is already caught up with the same curve we see for the FOPI case. The number of rounds, as expected, grows exponentially with the size of the largest element. However, as observed from Figure 4b, this number does not grow quickly as a function of the number of elements, supporting the theoretical arguments of Section 6.2. Note also that the variance chosen for traders’ preferences is fixed, thus for a small number of elements the variance over them is wider, resulting in the large number of rounds required by GAI FOPI in that case.\nFor AP, the only implication of increasing ξ is the respective increase in the number of attributes. As a result, the complexity of AP (not shown) grows very slowly with the increase in ξ. For the FOPI case, with δ = 2, AP takes an average of 481 rounds for ξ = 1 (6 attributes) and 546 rounds for ξ = 6 (19 attributes). The numbers are slightly higher for random preferences (523 to 628).\nFor high-dimensional multiattribute auctions, we expect that participation would typically be automated through software bidding agents (Wellman, Greenwald, & Stone, 2007). Under these circumstances, an auction taking up to thousands of rounds should not cause a concern. However, if for some reason rounds are expensive, we might reconsider adopt-\ning additive auctions, and sacrifice efficiency in order to decrease the number of rounds. Alternatively, we could keep using GAI auctions and increase \" (and with it δ). The final experiment compares these two alternatives. We vary the level of \", in order to view efficiency as a function of the number of rounds (Figure 5). The GAI structure used for this experiment has e = 5 and ξ = 5.\nAs evident from the chart, in most cases GAI achieves better efficiency even for a fixed number of rounds. The only exception is when the budget of rounds is very small (under 200), and FOPI holds. In such case we need to pay with more rounds in order to get the higher efficiency.\nThe total computation time, carried out by a GAI auction with 10 elements, ξ = 5, d = 3, δ = 2, and the rest of the parameters fixed as above, is around 11 seconds on average, using an Intel Dual Core (2.00 Ghz) CPU, with 2048 MB RAM."
    }, {
      "heading" : "8.3 Information Revelation",
      "text" : "A key difference between the mechanism proposed here and most previous literature is in the extent to which the buyer is required to reveal preference information. In GAI auctions, the buyer does not need to reveal all of its private preference information up front. Of course, the price changes do reveal some of the buyer’s information. Another experimental question is therefore whether this mechanism significantly reduces the overall amount of information revealed by the buyer.\nPK study information revelation by both the buyer and the seller, under an additivity assumption. When the utility function is additive the amount of information revealed can be measured in terms of constraints on the linear weights. Sellers can infer bounds on the buyer’s set of weights, and the amount of information hidden from them is represented by the fraction of the simplex that satisfies those constraints. This simplex analysis is not possible for GAI utilities. We suggest an alternative geared towards the kind of information revealed by the GAI auctions.\nIn GAI auctions, the buyer’s private information is partially revealed through the selection of the buyer’s preferred set Mt. The auction does not need to announce this directly; in general the sellers can infer that a sub-configuration is in Mt only if it received a bid (usually sellers will observe this only for their own bids), yet its price does not change in the\nnext round. We therefore measure exactly that—for how many sub-configurations θr there was at least one round t such that θr ∈ Mt∩Bti for some i. More specifically, we define such a sub-configuration as revealed, and within each GAI element we measure the fraction of sub-configurations that are revealed by the end of the auction. This measurement overestimates the information that is actually revealed, as sellers can infer some bounds on relative preferences but not the precise values of the functions fb(·). Moreover, it assumes that each seller observes all bids (meaning that sellers share bid information with each other), an unrealistic event in practice.\nBased on this criterion, GAI auctions reveal on average 15%–25% of the buyer’s preferences when preferences exhibit FOPI, and 10%–15% when the subutilities are completely random. It does not seem to systematically depend on any other parameter we tested. This validates our claim as to the advantage that GAI auctions promise over second-score types of auctions."
    }, {
      "heading" : "9. Conclusions",
      "text" : "We propose a novel exploitation of preference structure in multiattribute auctions. Rather than assuming full additivity, or no structure at all, we model preferences using the generalized additive independence (GAI) decomposition. We show how a GAI representation can be constructed from relatively simple statements of willingness-to-pay, and develop an iterative auction mechanism directly relying on the decomposition. Our auction mechanism generalizes the preference modeling employed by Parkes and Kalagnanam (2005), while in essence retaining their information revelation properties. It allows for a range of tradeoffs between the accuracy of preference representation and computational complexity of the auction, as well as the tradeoff between buyer information revelation and the number of rounds required for convergence.\nWe performed a simulation study of our proposed multiattribute auctions, compared to a mechanism that assumes additive preferences. The study validated the usefulness of GAI auctions when preferences are non-additive but GAI, and allowed us to quantify the advantages for specific classes of preferences. In general, we found that our design yields significantly higher economic efficiency in comparison to additive auctions. When the GAI subutilities exhibit internal structures, such as FOPI, the efficiency loss of additive approximation is less severe, but in most cases the benefit of an accurate GAI model is still significant. Using an additive approximation may be a reasonable approach when the GAI structure is fairly similar to an additive one, or when the auction must terminate within a small number of rounds.\nThe tradeoff between expressive and compactness of preference representation is ubiquitous in applications involving preferences. On one hand, we would like to ask users for as little as possible information; on the other, users’ preference statements may not be accurate or even meaningful if they cannot express important dependencies. In such problems it could be useful to experimentally compare the accuracy of GAI and additive representations. The experimental methodologies used in this study, in particular the generation of random structured utility functions, and finding an additive approximation to GAI functions, may therefore prove applicable to a broader class of preference research problems in which this tradeoff exists."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was supported in part by NSF grants IIS-0205435 and IIS-0414710, and the STIET program under NSF IGERT grant 0114368. Yagil Engel was supported in part by the Aly Kaufman fellowship at the Technion. We thank anonymous reviewers for many useful comments and suggestions."
    }, {
      "heading" : "Appendix A. Proofs of Section 3.1",
      "text" : "Lemma 2. Let u(A) be an MVF representing preference differences, and let X,Y,Z define a partition of A. Then CDI(X,Y | Z) iff\nu(A) = u(X0, Y, Z) + u(X,Y 0, Z) − u(X0, Y 0, Z),\nfor arbitrary instantiations X0, Y 0.\nProof. Let X0, Y 0 be arbitrary instantiations.\nu(X,Y,Z) = u(X,Y,Z)−u(X0, Y, Z)+u(X0, Y, Z) = u(X,Y 0, Z)−u(X0, Y 0, Z)+u(X0, Y, Z)\nThe second equality holds iff for any X0, Y 0, CDI(X,Y | Z).\nTheorem 3 (CDI-GAI Theorem). Let G = (A,E) be a CDI map for A, and {I1, . . . , Ig} a set of overlapping maximal cliques. Then\nu(A) = g∑\nr=1\nfr(Ir), (A.1)\nwhere\nf1 = u([I1]), and (A.2)\nfor r = 2, . . . , g, fr = u([Ir]) + r−1∑\nj=1\n(−1)j ∑\n1≤i1<···<ij<r\nu([ j⋂\ns=1\nIis ∩ Ir]).\nProof. We actually prove a somewhat stronger result.\nClaim. Let G be a CDI map for utility function u(·). Let Q = {C1, . . . , Cw} denote the set of maximal cliques of G. Then,\nu(A) = w∑\nk=1\n(−1)k+1 ∑\n1≤i1<···<ik≤w\nu([ k⋂\ns=1\nCis ]). (A.3)\nLet G0 = (A,E0) be the complete graph over the nodes of G. By definition of CDI map, each edge (x, y) ∈ E0 \\ E implies CDI(x, y). We use induction on a series of edge removals. starting from the graph G0, at each step i we remove an edge in E0 \\ E to get graph Gi. After the last step i = |E0| − |E| and G|E 0|−|E| = G. We prove that the claim\nholds for each graph Gi. Since A is the only clique in G0, in step 0, Q0 = {A} and the claim trivially hold. Following the process for step 1 provides intuition as for how the final decomposition is obtained. We pick a pair of nodes (x, y) such that CDI(x, y). We use the notation S−a = S \\ {a} for any S ⊆ A and a ∈ A. By Lemma 2 ,\nu(A) = u(x, y,A−x,y) (A.4)\n= u(x0, y, A−x,y) + u(x, y0, A−x,y) − u(x0, y0, A−x,y) = u([A−x]) + u([A−y]) − u([A−x ∩ A−y]).\nThe set of maximal cliques of G1 is Q1 = {A−x, A−y}. Equation (A.4) shows that (A.3) holds for Q1.\nFor proving the induction step, we assume (A.3) holds at step i, and show they carry over to step i+1. Let (x, y) denote the edge removed in step i+1. Let Ĉ1, . . . , Ĉd (WLOG) indicate all the sets in Qi that include both x and y. Similar to (A.4), we observe that\nu([Ĉ1]) = u([Ĉ −x 1 ]) + u([Ĉ −y 1 ]) − u([Ĉ −x 1 ∩ Ĉ −y 1 ]). (A.5)\nSimilarly for any k = 1, . . . , wi − 1, and 1 < i1 < · · · < ik ≤ wi,\nu([ k⋂\ns=1\nĈis ∩ Ĉ1]) = u([ k⋂\ns=1\nĈis ∩ Ĉ −x 1 ])+u([\nk⋂\ns=1\nĈis ∩ Ĉ −y 1 ])−u([\nk⋂\ns=1\nĈis ∩ Ĉ −x 1 ∩ Ĉ −y 1 ]). (A.6)\nIn (A.3) (assumed to hold before this step) each term that includes Ĉ1 can be substituted according to (A.5) or (A.6). Doing so will result in (A.3) holding for the set (Qi \\ {Ĉ1}) ∪ {Ĉ−x1 , Ĉ −y 1 }.\nWe repeat the same operation for C2, . . . , Cd, and define the resulting collection\nQi+1 = (Qi \\ {Ĉ1, . . . , Ĉd}) ∪ {Ĉ −x 1 , Ĉ −y 1 , . . . , Ĉ −x d , Ĉ −y d }.\nAll elements in Qi+1 are subsets of elements in Qi, which are all maximal cliques of Gi. We now verify the induction property:\n• Any element in Qi+1 is a clique in Gi+1, because the only difference between Gi and Gi+1 is the removed edge (x, y), and no set in Qi+1 includes both x and y.\n• Any such clique in C ∈ Qi+1 is maximal, because it is a subset of a maximal clique of Ĉ ∈ Gi, and either: (i) y ∈ Ĉ and C = Ĉ \\ {x} or (ii) x ∈ Ĉ and C = Ĉ \\ {y}, or (iii)C = Ĉ. x and y are no longer connected so C remains maximal in all cases.\n• If M is a maximal clique in Gi+1, then M ⊆ Ĉ for some Ĉ ∈ Qi. Again either M = Ĉ, or M = Ĉ \\ {x}, or M = Ĉ \\ {y}, and in all three cases M is an element in Qi+1.\nThis proves the induction step. As a result, in the last step the decomposition (A.3) holds for the set Q = Q|E0|−|E|, which is the set of maximal cliques of G, and hence the claim is proved. Now define f1, . . . , fg according to (A.2). By the claim, we get that (A.1) holds."
    }, {
      "heading" : "Appendix B. Proofs of Section 6.1",
      "text" : "B.1 Proving Lemma 5\nLemma 5. Let Ψ be a set of configurations, all are within \" of maximizing profit for a trader τ at the a given price vector. Let Φ = {θr | θ ∈ Ψ, r ∈ {1, . . . , g}}. Then any consistent cover in Φ is within g\" of maximizing profit for τ at these prices.\nWe show that given a suboptimal consistent cover θ over Φ, we can find a suboptimal member in Ψ, contradicting the premise of the lemma. We do that by traversing the GAI tree in a depth-first manner, at each step we flip the sub-configurations corresponding to the elements of the subtree to a set of sub-configurations that have the same source configuration in Ψ as the parent of that subtree (thus “trimming” that subtree). This, as we show, results in another consistent cover that is also sub-optimal. Eventually we obtain a configuration in Ψ which is still suboptimal.\nFor that purpose we introduce the following notions:\n• The operator ⊕ turns a set of sub-configurations, which is a consistent cover, into a configuration:\n⊕{θ1, . . . , θg} = (θ1, . . . , θg).\n• Let θ be a consistent cover over Φ. The Ψ-source of an element θr is a configuration θ̂ ∈ Ψ from which it originated (meaning, θ̂r = θr).\n• The operation trim replaces some of the sub-configurations of a given configuration θ with a corresponding set of sub-configurations of a different configuration θ̂, according to the following rules. Let µi denote the indices of the GAI elements, corresponding to a subtree in the GAI-tree, whose root is the GAI element Ii. Let θ denote a consistent cover over Ψ. The operation Ψ-trim over θ and µi is defined if all the elements in θ corresponding to µi have the same Ψ-source. Formally, there exists θ̂ ∈ Ψ, such that ∀θr, if r ∈ µi then θi = θ̂i. Now, Let γ be the parent of Ii, or an arbitrary element outside µi if µi is disconnected from the rest of the graph. Let θ̂ ∈ Ψ be the source of θγ . Then\nΨ-trim(µi, θ) = ⊕{θr | r /∈ µ i} ∪ {θ̂r|r ∈ µ i}\nThat is we replace each of θr for r ∈ µi by the corresponding sub-configuration in θ̂, so that in the resulting configuration all the elements corresponding to µi have the same Ψ-source as the parent of Ii.\nLemma B.1. θ′ = Ψ-trim(µ, θ) is a consistent cover.\nProof. We need to show that any pair of sub-configurations in the set {θr | r /∈ µi}∪{θ̂r|r ∈ µi} are consistent, that is they assign the same value to any attribute that appear in both corresponding GAI elements.\nThe sub-configurations {θ̂r|r ∈ µi} are internally consistent because they have a mutual Ψ-source θ̂. The sub-configurations {θr | r /∈ µi} are internally consistent because they are all sub-configurations of θ. Let r1 ∈ µi and r2 /∈ µi denote indices of GAI elements, such that Ir1 ∩ Ir2 ,= ∅. Now, Ir1 is in a subtree whose root is Ii, whereas Ir2 is outside the subtree, so the path between them must go through Ii and its parent γ. Due to the\nrunning intersection property of the GAI tree, Ir1 ∩ Ir2 ⊆ Ii ∩ γ. The corresponding subconfigurations θ̂i and θγ must be consistent because θ̂ is also the Ψ-source of γ, hence θ̂r1 and θr2 must also be consistent.\nLemma B.2. Let Ψ and Φ be defined as in Lemma 5, and let θ denote a consistent cover in Φ. Then if θ′ = Ψ-trim(µi, θ) (for some i), then πτ (θ′) ≤ πτ (θ) + \".\nProof. Let θ̃ ∈ Ψ denote the single Ψ-source of {θr | r ∈ µi}. Let µ = µi and µ̄ = {1, . . . , g} \\ µ. If πτ (θ′) > πτ (θ) + \", then (using Lemma 4)\nπτ (θ ′) = πτ (θ ′ µ) + πτ (θ ′ µ̄) > πτ (θµ) + πτ (θµ̄) + \",\nand because θµ̄ = θ′µ̄, πτ (θ ′ µ) > πτ (θµ) + \".\nDefine the following cover:\nθ̂ = ⊕{θ′r | r ∈ µ} ∪ {θ̃r | r ∈ µ̄}\nθ̂ is a consistent cover–again (as in Lemma B.1) the only possible intersection between an element from θ′ and an element from θ̃ is between i (the root of µ = µi) and its parent γ. The corresponding sub-configurations θ′i and θ̃γ must be consistent for the following argument: θ̃i is consistent with θγ because they appear together in θ. θ′i is consistent with θγ because they have the same Ψ-source by definition of Ψ-trim. Hence θ̃i and θ′i assign the same values to the attributes in Ii ∩ Iγ . Now because θ̃i is consistent with θ̃γ , so must be θ′i. We get\nπτ (θ̂) = πτ (θ ′ µ) + πτ (θ̃µ̄) > πτ (θµ) + πτ (θ̃µ̄) + \" = πτ (θ̃) + \".\nThe last equation follows from the fact that all sub-configurations of θµ are from θ̃. This contradicts \"-optimality of θ̃ ∈ Ψ.\nProof of Lemma 5. Let θ1 be a consistent cover over Φ contradicting the lemma, meaning πτ (θ1) ≤ maxθ∈Θ πτ (θ) − g\". We first reorder the GAI elements as 1, . . . , g, according to the order corresponding to backtracking in Depth-First-Search: that is, starting from the leftmost leaf, next move to its siblings, next their parent, and in general once all children of a node Ii are visited, the next element to be visited is Ii. We perform a series of g − 1 Ψ-trim operations, resulting in a series θ1, . . . , θg. To do that, we must show that at each step i the operation Ψ-trim(µi, θi) is valid, that is the sub-configurations corresponding to µi have a mutual Ψ-source. If Ii is a leaf, then |µi| = 1 hence the elements of µi have a single source. Otherwise, θi is a result of trimming the subtrees of all children of Ii, hence by definition of Ψ-trim they all have the same Ψ-source as θii.\nNow, consider the resulting θg. We assumed πτ (θ1) < maxθ∈Θ πτ (θ) − g\", hence by applications of Lemma B.2 in each of the g − 1 Ψ-trim operations, we get πτ (θg) < maxθ∈Θ πτ (θ)− \". The last element θg is such that all its elements have a mutual Ψ-source, meaning θg ∈ Ψ. Therefore, we got a contradiction to the \"-optimality of Ψ.\nB.2 Proving Theorem 10\nIn order to prove Theorem 10 we need several additional claims.\nLemma B.3. The price of at least one sub-configuration must be reduced in every round of phase A.\nProof. In each round t < T of phase A there exists an active seller i for whom Bti ∩M t = ∅. However to be active in round t, Bti ,= ∅. Let θ̂ ∈ B t i . If ∀r.θ̂r ∈ M\nt, then θ̂ ∈ M t by definition of M t. Therefore there must be θ̂r ,∈ Mt.\nLemma B.4. The auction must reach phase B.\nProof. By Lemma B.3 some prices must go down in every round of phase A. Lemma 7 ensures a lower bound on how much prices can be reduced during phase A, therefore the auction either terminates in phase A or must reach condition [SWITCH].\nWe set the initial prices high such that maxθ∈Θ π1b (θ) < 0, and then maxθ∈Θ π t b(θ) < 0 during phase A by Lemma 7. By Assumption A2 the efficient allocation (θ∗, i∗) provides positive welfare, that is σi∗(θ∗) = πtb(θ ∗)+πti∗(θ ∗) > 0. si∗ is SB therefore she will leave the auction only when πti∗(θ ∗) < 0. This can happen only when πtb(θ\n∗) > 0, therefore si∗ does not drop in phase A. Because Phase A continues as long as at least one seller is active, the auction cannot terminate before reaching condition [SWITCH].\nFinally, the following lemma states that for any two sellers, the potential surplus of the first one to drop from the auction cannot be significantly higher than the potential surplus of the one that stayed longer.\nLemma B.5. If sellers si and sj are SB, and si is active at least as long as sj is active in phase B, then\nσi(ηi) ≥ max θ∈Θ σj(θ) − (g + 1)\".\nProof. From SB and the definition of phase B, sj drops when ∆ > πTj (ηj). If si did not drop before that point then πTi (ηi) ≥ ∆ − \" > π T j (ηj) − \". Because ηi ∈ M\nt, we get from Corollary 6 that,\nπTb (ηi) + π T i (ηi) ≥ max θ∈Θ πTb (θ) + π T j (ηj) − (g + 1)\".\nFrom Corollary 8, πTj (ηj) = maxθ∈Θ π T j (θ). Therefore\nσi(ηi) = π T b (ηi) + π T i (ηi) ≥ max θ∈Θ πTb (θ) + max θ∈Θ πTj (θ) − (g + 1)\" ≥ max θ∈Θ σj(θ) − (g + 1)\".\nTheorem 10. Given a truthful buyer and SB sellers, the surplus of the final allocation is within (g + 1)\" of the maximal surplus.\nProof. From Lemma B.4 the auction terminates with an allocation (si, ηi). From Lemma 9, the theorem is immediate in case the winning seller si is the efficient seller. Otherwise the efficient seller is sj who dropped before or with si. The result is now immediate from Lemma B.5.\nB.3 Proving Theorem 12\nWe first adapt Lemma 7, Lemma 9, and Lemma B.5 to use e + 1 instead of g.\nLemma B.6. maxθ∈Θ πtb(θ) does not change in any round t of phase A.\nProof. Let G be comprised of trees G1, . . . , Gh, let θ′j denote the projection of a configuration θ′ on the tree Gj , and let gj denote the number of GAI elements in Gj .\nAssume there exists some θ′j for which π t+1 b (θ ′ j) > π t b(θ ′ j). Then necessarily p t+1(θ′j) = pt(θ′j) − δ. For that to happen it must be the case that some w ≤ gj sub-configurations of θ′j are not in M t j , and δ = w\" g . In that case, by definition of M t j,\nπtb(θ ′ j) < max θj∈Θj πtb(θj) − gj\n\" g .\nTherefore,\nπt+1b (θ ′ j) = π t(θ′j) + δ = π t(θ′j) +\nw\"\ng ≤ πt(θ′j) +\ngj\"\ng < max θj∈Θj πtb(θj).\nThis is true for any θ′j whose profit improves, therefore maxθj∈Θj π t b(θj) does not change\nduring phase A. Now\nmax θ∈Θ πtb(θ) = max θ∈Θ\nh∑\nj=1\nπtb(θj) = h∑\nj=1\nmax θj∈Θj\nπtb(θj).\nThe last equality holds because the optimal values for disconnected components of the GAI tree are independent of each other. As a result, maxθ∈Θ πtb(θ) as well does not change during phase A.\nLemma B.7. For SB seller si, ηi is (e + 1)\"-efficient:\nσi(ηi) ≥ max θ∈Θ σi(θ) − (e + 1)\".\nThe proof is identical to the proof of Lemma 9, replacing g by e+1 and using Corollary 11 instead of Corollary 6.\nLemma B.8. If sellers si and sj are SB, and si is active at least as long as sj is active in phase B, then\nσi(ηi) ≥ max θ∈Θ σj(θ) − (e + 2)\".\nThe proof here too is identical to the proof of Lemma B.5, using Corollary 11 instead of Corollary 6.\nTheorem 12. Given a truthful buyer and SB sellers, the surplus of the final allocation is within (e + 2)\" of the maximal surplus.\nProof. The proof is identical to the proof of Theorem 10, replacing Lemmas 9 and B.5 with lemmas B.7 and B.8, respectively.\nB.4 Lemma 13 and Theorem 14\nLemma 13. When sellers are SB, the GAI auction payment is sell-side (e + 2)\"-VCG.\nProof. Trivially, we consider only the winning seller si. In the case that the final price is above buyer’s valuation the payment ub(ηi) is exactly the VCG payment. We can therefore assume that the final price is not above the buyer’s valuation, and the payment to the winning seller is pT (ηi) −∆. Let sj be the second best seller. sj drops before si, when the discount is ∆− \", hence,\n∆ + \" > πTj (ηj) = max θ∈Θ πTj (θ). (B.1)\nFrom Corollary 6, ub(ηi) − p\nT (ηi) ≥ max θ∈Θ πTb (θ) − (e + 1)\".\nTherefore (using (B.1) for the second inequality)\npT (ηi) −∆ ≤ ub(ηi) − max θ∈Θ πb(θ) + (e + 1)\"−∆ <\nub(ηi) − max θ∈Θ πTb (θ) + (e + 2)\"− max θ∈Θ πTj (θ) ≤ ub(ηi) − max θ∈Θ σj(θ) + (e + 2)\". (B.2)\nBow because sj’s survived in the auction until the discount was ∆− \",\n∆ ≤ πTj (ηj) + \".\nMeaning: pT (ηj) −∆ ≥ cj(ηj) − \". (B.3)\nFrom Corollary 6 ub(ηi) − p T (ηi) ≤ ub(ηj) − p T (ηj) + (e + 1)\".\nTherefore (using (B.3) for the second inequality)\npT (ηi) −∆ ≥ ub(ηi) − ub(ηj) + p T (ηj) − (e + 1)\"−∆ ≥\nub(ηi) − (ub(ηj) − cj(ηj)) − \"− (e + 1)\" ≥ ub(ηi) − max θ∈Θ σj(θ) − (e + 2)\". (B.4)\nEquations (B.2) and (B.4) place the payment pT (ηi) − ∆ within (e + 2)\" from si’s VCG payment.\nTheorem 14. SB is a (3e+5)\" ex-post Nash equilibrium for sellers in the GAI auction. That is, sellers cannot gain more than (3e+5)\" by deviating from SB, given that other sellers follow SB.\nLet s1 play some arbitrary strategy ρ1 against SB sellers s2, . . . , sn. If s1 does not win she would clearly have done no worse using SB, therefore we assume s1 wins η1 in final price p̃ and that she gains at least (3e + 5)\" from the trade. Let i ∈ 2, . . . n. The calculation of (B.2) assumed nothing on the winning trader’s strategy, therefore it applies here as well:\np̃ = pT (η1) −∆ ≤ ub(η1) − max θ σi(θ) + (e + 2)\". (B.5)\nNext, define the following cost function: ĉ1(η1) = p̃ − (2e + 3)\" and ĉ1(θ′) = ∞,∀θ′ ,= η1. Assume s1 plays SB for ĉ1.\nClaim. By playing SB assuming cost ĉ1, s1 is still the winner, and her profit (wrt to c1(·)) is within (2e + 3)\" of her profit playing ρ1.\nProof. Clearly, s1 bids only on η1. Let p̂(·) denote prices in the end of phase A in the new instance of the auction, let π̂b(·) denote the buyer’s profit, and let ∆̂ be the final discount. Now assume for a moment that prices reach s1’s limit, that is ∆̂ = π1(η1) = p̂(η1)− ĉ1(η1) = p̂(η1) − (p̃ − (2e + 3)\").\nNow (for the inequality, use p̂T (η1) = ub(η1) − π̂Tb (η1) and also (B.5)),\n∆̂ = p̂T (η1)− p̃ + (2e + 3)\" > ub(η1)− π̂ T b (η1)− (ub(η1)−max\nθ σi(θ) + (e + 2)\") + (2e + 3)\"\n= max θ\nσi(θ) − π̂ T b (η1) + (e + 1)\".\n(B.6)\nLet η̂i denote the configuration chosen for some seller si at the end of phase A in the new instance. Since η̂i ∈ MT in that instance, we get that π̂Tb (η̂i) ≥ π̂ T b (η1) − (e + 1)\". Therefore we can modify (B.6) to state,\n∆̂ > σi(η̂i) − π̂ T b (η̂i) = p̂ T (η̂i) − ci(η̂i), (B.7)\nmeaning that if prices reached the limit of s1, all the other sellers dropped off. That shows that s1 wins in the new instance as well. Furthermore, the lowest possible price paid to s1 is determined by ∆̂ = p̂(η1) − (p̃ − (2e + 3)\"), hence that price is at least p̃− (2e + 3)\".\nProof of Theorem 14. From Lemma 13:\np̂ ≤ V CG(ĉ1, c2, . . . , cn) + (e + 2)\".\nTruthful reporting is a dominant strategy for sellers in one-sided VCG auctions. Therefore\nV CG(ĉ1, c2, . . . , cn) ≤ V CG(c1, c2, . . . , cn).\nWith the result of the claim we get\np̃ ≤ p̂ + (2e + 3)\" ≤ V CG(c1, c2, . . . , cn) + (3e + 5)\".\nTherefore by playing ρ1, s1 could not have gained more than (3e + 5)\" above her worstcase payoff for playing SB with respect to her true cost c1."
    }, {
      "heading" : "Appendix C. Proofs of Section 6.2",
      "text" : "Theorem 15. The computation of Mt can be performed in time O(g|I|2). Moreover, the total time spent on this task throughout the auction is O(g|I|(|I| + T )).\nProof. For simplicity of notations we assume that there is a single (connected) GAI-tree. The extension to multiple connected components is immediate because each M tj is computed separately.\nThe functions ub and pt have the same GAI form, hence the function πtb = ub − p t has the same GAI form. As have been noted before (Boutilier et al., 2001), functions in\nGAI form can be optimized using variable elimination schemes in cost networks (Dechter, 1997). In fact, our GAI structure is already a tree, in which case the optimization is linear in the size of the domain which is |I|. However, Mt includes sub-configurations of all configurations within \" of maxθ πb(θ). To find it, we must find the maximum of πtb, add its sub-configurations to Mt, then find the best configuration which is not already in M t (that is, maximal in Θ \\ M t) and so on. This can be done by the following procedure, adapted from the work of Nilsson (1998):\n1. For i=1,. . . , g:\n• Define Θi = {θ ∈ Θ | θ1, . . . , θi−1 ∈ Mt and θi /∈ Mt}. • Find θi = arg maxθ∈Θi π t b(θ).\n2. The best configuration in Θ \\ M t is θ∗ = arg maxi=1,...,g πtb(θ i) (which means, a con-\nfiguration which has at least one sub-configuration not in Mt).\nIf πtb(θ ∗) ≥ maxθ∈Θ πtb(θ)− \", then each sub-configuration of θ ∗ that is not already in Mt is added to Mt. Otherwise, Mt is ready.\nThe procedure itself performs g optimizations, each takes linear in the size of the domain. This amounts to O(g|I|). Each time this procedure is done, either at least one sub-configuration is added to Mt, or Mt is ready. Therefore the number of times the procedure is done per round is bounded by the number of sub-configurations |I| plus one, giving the O(g|I|2) bound. Moreover, Mt is monotonically increasing in the auction. In each round, we start from the Mt computed in the previous round. Throughout the auction, each application of the procedure either yields a new sub-configuration in Mt, or terminates the round, so the total number of times the procedure is performed throughout the auction is bounded by |I| + T , leading to the overall bound of O(g|I|(|I| + T ))."
    }, {
      "heading" : "Appendix D. Relating the MUI condition to Complements and",
      "text" : "Substitutes\nThe definitions for the utility independence (UI) condition and MUI can be found elsewhere (Keeney & Raiffa, 1976).\nDefinition 19. A MUI-factor of a set A of MUI attributes is a solution to\n1 + k = n∏\ni=1\n(1 + kki).\nKeeney and Raiffa (1976) (KR) show that there is at most one MUI-factor in addition to zero (Appendix 6B of their text). This ensures the soundness of the following adaptation to their MUI representation theorem:9\nTheorem D.1. Let A be a set of MUI attributes.\n1. If the only MUI-factor of A is zero, then u(A) = ∑n\ni=1 kiui(ai).\n9. The theorem is adapted from the book of Keeney and Raiffa (1976), Theorem 6.1, page 289.\n2. Otherwise, let k ,= 0 be a MUI-factor. Then\nu(A) =\n∏n i=1[kkiui(ai) + 1] − 1\nk . (D.1)\nKR go on to point out that if k > 0 we can define u′(A) = 1 + ku(A), a strategically equivalent function to u(·), and turn (D.1) into a multiplicative representation. This can be done in a similar fashion for k < 0. Further, they show that if MUI is known to exist, one elicitation query is sufficient in order to determine whether the form of the function is additive or multiplicative.\nThe following relationship allow us to interpret the MUI factor with respect to complements and substitutes. The result generalizes and formalizes an intuition given by KR for the case of MUI between two attributes.\nTheorem D.2. Let A be a set of MUI attributes, such that there is a MUI-factor k ,= 0. Then k > 0 iff all pairs of attributes in A are complements, and k < 0 iff all pairs of attributes in A are substitutes.\nProof. The proof is based on the work of Keeney and Raiffa (1976), Theorem 6.1, as explained below.\nAssume that u(·) is normalized such that u(A0) = 0. For each attribute a ∈ A, let a = {a}, and we know UI(a, a). Utility independence of such form leads to the following functional form: there exist functions f and g such that,\nu(A) = f(a) + g(a)u(a, a0)\nWe instantiate this form with the assignment a0 and get\nu(a0, a) = f(a) + g(a)u(a0, a0) = f(a)\nHence f(a) = u(a0, a), and g(a) = u(A)−u(a 0,a)\nu(a,a0) (this development is done by KR). With\nu(A0) = 0, we get\ng(a) = u(A) − u(a0, a)\nu(a, a0) − u(a0, a0) . (D.2)\nIn proof of Theorem 6.1, KR define the MUI-factor as follows:\nk = g(a) − 1\nu(a0, a)\nThe denominator is always positive. Furthermore, as shown by (D.2), when g(a) > 1, u(A) − u(a0, a) > u(a, a0) − u(a0, a0). In particular it means that for any b ∈ a, a and b are complements, because the inequality holds when holding fixed all attributes in a but b. Similarly, when g(a) < 1, a and any b ∈ a are substitutes. Putting these pieces together, we get the desired result."
    }, {
      "heading" : "Appendix E. Optimal Regression Using a Small Sample",
      "text" : "We show an experiment supporting the claim in Section 7.3: a larger set of sampling points than the one we used for the linear regression of the utility function cannot improve the efficiency of AP. Figure 6 shows the efficiency of AP as a function of the number of sampling points used, for the largest domain we used in the experiments: 25 attributes with d = 4 (e = 9 and ξ = 5). Similar results were shown for other distributions and for FOPI preferences. This chart is a result of 150 experiments for each of 10 points on the x-axis, the largest number of tests we used."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2010,
    "abstractText" : "We develop multiattribute auctions that accommodate generalized additive independent (GAI) preferences. We propose an iterative auction mechanism that maintains prices on potentially overlapping GAI clusters of attributes, thus decreases elicitation and computational burden, and creates an open competition among suppliers over a multidimensional domain. Most significantly, the auction is guaranteed to achieve surplus which approximates optimal welfare up to a small additive factor, under reasonable equilibrium strategies of traders. The main departure of GAI auctions from previous literature is to accommodate non-additive trader preferences, hence allowing traders to condition their evaluation of specific attributes on the value of other attributes. At the same time, the GAI structure supports a compact representation of prices, enabling a tractable auction process. We perform a simulation study, demonstrating and quantifying the significant efficiency advantage of more expressive preference modeling. We draw random GAI-structured utility functions with various internal structures, generate additive functions that approximate the GAI utility, and compare the performance of the auctions using the two representations. We find that allowing traders to express existing dependencies among attributes improves the economic efficiency of multiattribute auctions.",
    "creator" : "dvips(k) 5.97 Copyright 2008 Radical Eye Software"
  }
}