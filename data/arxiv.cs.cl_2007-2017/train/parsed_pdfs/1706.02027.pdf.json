{
  "name" : "1706.02027.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Question Answering and Question Generation as Dual Tasks",
    "authors" : [ "Duyu Tang", "Nan Duan", "Tao Qin", "Zhao Yan", "Ming Zhou" ],
    "emails" : [ "dutang@microsoft.com", "nanduan@microsoft.com", "taoqin@microsoft.com", "v-zhaoya@microsoft.com", "mingzhou@microsoft.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 6.\n02 02\n7v 2\n[ cs\n.C L\n] 4\nA ug\n2 01"
    }, {
      "heading" : "Introduction",
      "text" : "Question answering (QA) and question generation (QG) are two fundamental tasks in natural language processing (Manning and Schütze 1999; Jurafsky and Martin 2000). Both tasks involve reasoning between a question sequence q and an answer sentence a. In this work, we take answer sentence selection (Yang, Yih, and Meek 2015) as the QA task, which is a fundamental QA task and is very important for many applications such as search engine and conversational bots. The task of QA takes a question sentence q and a list of candidate answer sentences as the input, and finds the top relevant answer sentence from the candidate list. The task of QG takes a sentence a as input, and generates a question sentence q which could be answered by a. It is obvious that the input and the output of these two tasks are (almost) reverse, which is referred to as “duality” in this paper. This duality connects QA and QG, and potentially could help these two tasks to improve each other.\nCopyright c© 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nIntuitively, QA could improve QG through measuring the relevance between the generated question and the answer. This QA-specific signal could enhance the QG model to generate not only literally similar question string, but also the questions that could be answered by the answer. In turn, QG could improve QA by providing additional signal which stands for the probability of generating a question given the answer. Moreover, QA and QG have probabilistic correlation as both tasks relate to the joint probability between q and a. Given a question-answer pair 〈q, a〉, the joint probability P (q, a) can be computed in two equivalent ways.\nP (q, a) = P (a)P (q|a) = P (q)P (a|q) (1)\nThe conditional distribution P (q|a) is exactly the QG model, and the conditional distribution P (a|q) is closely related to the QA model1. Existing studies typically learn the QAmodel and the QGmodel separately by minimizing their own loss functions, while ignoring the probabilistic correlation between them. Based on these considerations, we introduce a training framework that exploits the duality of QA and QG to improve both tasks. There might be different ways of exploiting the duality of QA and QG. In this work, we leverage the probabilistic correlation between QA and QG as the regularization term to influence the training process of both tasks. Specifically, the training objective of our framework is to jointly learn the QA model parameterized by θqa and the QG model parameterized by θqg by minimizing their loss functions subject to the following constraint.\nPa(a)P (q|a; θqg) = Pq(q)P (a|q; θqa) (2)\nPa(a) and Pq(q) are the language models for answer sentences and question sentences, respectively. We examine the effectiveness of our training criterion by applying it to strong neural network based QA and QG models. Specifically, we implement a generative QG model based on sequence-sequence learning, which takes an answer sentence as input and generates a question sentence in an end-to-end fashion. We implement a discriminative\n1In this work, our QA model is fqa(a, q; θqa). The conditional distribution P (a|q) could be derived from the QA model, which will be detailed in the next section.\nQA model based on recurrent neural network, where both question and answer are represented as continuous vector in a sequential way. As every component in the entire framework is differentiable, all the parameters could be conventionally trained through back propagation. We conduct experiments on three datasets (Yang, Yih, and Meek 2015; Rajpurkar et al. 2016; Nguyen et al. 2016). Empirical results show that our training framework improves both QA and QG tasks. The improved QA model performs comparably with strong baseline approaches on all three datasets."
    }, {
      "heading" : "The Proposed Framework",
      "text" : "In this section, we first formulate the task of QA and QG, and then present the proposed algorithm for jointly training the QA and QG models. We also describe the connections and differences between this work and existing studies."
    }, {
      "heading" : "Task Definition and Notations",
      "text" : "This work involves two tasks, namely question answering (QA) and question generation (QG). There are different kinds of QA tasks in natural language processing community. In this work, we take answer sentence selection (Yang, Yih, and Meek 2015) as the QA task, which takes a question q and a list of candidate answer sentences A = {a1, a2, ..., a|A|} as input, and outputs one answer sentence ai from the candidate list which has the largest probability to be the answer. This QA task is typically viewed as a ranking problem. Our QA model is abbreviated as fqa(a, q; θqa), which is parameterized by θqa and the output is a real-valued scalar. The task of QG takes a sentence a as input, and outputs a question q which could be answered by a. In this work, we regard QG as a generation problem and develop a generative model based on sequence-to-sequence learning. Our QG model is abbreviated as Pqg(q|a; θqg), which is parameterized by θqg and the output is the probability of generating a natural language question q."
    }, {
      "heading" : "Algorithm Description",
      "text" : "We describe the proposed algorithm in this subsection. Overall, the framework includes three components, namely a QA model, a QGmodel and a regularization term that reflects the duality of QA and QG. Accordingly, the training objective of our framework includes three parts, which is described in Algorithm 1. The QA specific objective aims to minimize the loss function lqa(fqa(a, q; θqa), label), where label is 0 or 1 that indicates whether a is the correct answer of q or not. Since the goal of a QA model is to predict whether a question-answer pair is correct or not, it is necessary to use negative QA pairs whose labels are zero. The details about the QA model will be presented in the next section. For each correct question-answer pair, the QG specific objective is to minimize the following loss function,\nlqg(q, a) = −logPqg(q|a; θqg) (3)\nwhere a is the correct answer of q. The negativeQA pairs are not necessary because the goal of a QG model is to generate\nAlgorithm 1 Algorithm Description\nInput: Language modelsPa(a) and Pq(q) for answer and question, respectively; hyper parameters λq and λa; optimizer opt Output: QA model fqa(a, q) parameterized by θqa; QG model Pqg(q|a) parameterized by θqg\nRandomly initialize θqa and θqg repeat Get a minibatch of positive QA pairs 〈qpi , a p i 〉 m i=1,\nwhere ai is the answer of qi; Get a minibatch of negative QA pairs 〈qni , a n i 〉 m i=1, where ani is not the answer of q n i ; Calculate the gradients for θqa and θqg .\nGqa = ▽θqa 1\nm\nm∑\ni=1\n[lqa(fqa(a p i , q p i ; θqa), 1)\n+ lqa(fqa(a n i , q n i ; θqa), 0) + λaldual(a p i , q p i ; θqa, θqg)] (4)\nGqg = ▽θqg 1\nm\nm∑\ni=1\n[ lqg(q p i , a p i )\n+ λqldual(q p i , a p i ; θqa, θqg)] (5)\nUpdate θqa and θqg θqa ← opt(θqa, Gqa), θqg ← opt(θqg , Gqg)\nuntil models converged\nthe correct question for an answer. The QG model will be described in the following section. The third objective is the regularization term which satisfies the probabilistic duality constrains as given in Equation 2. Specifically, given a correct 〈q, a〉 pair, we would like to minimize the following loss function,\nldual(a, q; θqa, θqg) = [logPa(a) + logP (q|a; θqg)\n− logPq(q)− logP (a|q; θqa)] 2 (6)\nwhere Pa(a) and Pq(q) are marginal distributions, which could be easily obtained through language model. P (a|q; θqg) could also be easily calculated with the markov chain rule:P (q|a; θqg) = ∏|q|\nt=1 P (qt|q<t, a; θqg), where the function P (qt|q<t, a; θqg) is the same with the decoder of the QG model (detailed in the following section). However, the conditional probabilityP (a|q; θqa) is different from the output of the QA model fqa(a, q; θqa). To address this, given a question q, we sample a set of answer sentencesA′, and derive the conditional probabilityP (a|q; θqa) based on our QA model with the following equation.\nP (a|q; θqa) =\nexp(fqa(a, q; θqa))\nexp(fqa(a, q; θqa)) + ∑ a′∈A′ exp(fqa(a ′, q; θqa)) (7)\nIn this way, we learn the models of QA and QG by minimizing the weighted combination between the original loss functions and the regularization term."
    }, {
      "heading" : "Relationships with Existing Studies",
      "text" : "Our work differs from (Yang et al. 2017) in that they regard reading comprehension (RC) as the main task, and regard question generation as the auxiliary task to boost the main task RC. In our work, the roles of QA and QG are the same, and our algorithm enables QA and QG to improve the performance of each other simultaneously. Our approach differs from Generative Domain-Adaptive Nets (Yang et al. 2017) in that we do not pretrain the QA model. Our QA and QG models are jointly learned from random initialization. Moreover, our QA task differs from RC in that the answer in our task is a sentence rather than a text span from a sentence. Our approach is inspired by dual learning (Xia et al. 2016; Xia et al. 2017), which leverages the duality between two tasks to improve each other. Different from the dual learning (Xia et al. 2016) paradigm, our framework learns both models from scratch and does not need task-specific pretraining. The recently introduced supervised dual learning (Xia et al. 2017) has been successfully applied to image recognition,machine translation and sentiment analysis. Our work could be viewed as the first work that leveraging the idea of supervised dual learning for question answering. Our approach differs from Generative Adversarial Nets (GAN) (Goodfellow et al. 2014) in two respects. On one hand, the goal of original GAN is to learn a powerful generator, while the discriminative task is regarded as the auxiliary task. The roles of the two tasks in our framework are the same. On the other hand, the discriminative task of GAN aims to distinguish between the real data and the artificially generated data, while we focus on the real QA task."
    }, {
      "heading" : "The Question Answering Model",
      "text" : "We describe the details of the question answer (QA) model in this section. Overall, a QA model could be formulated as a function fqa(q, a; θqa) parameterized by θqa that maps a question-answer pair to a scalar. In the inference process, given a q and a list of candidate answer sentences, fqa(q, a; θqa) is used to calculate the relevance between q and every candidate a. The top ranked answer sentence is regarded as the output. We develop a neural network based QA model. Specifically, we first represent each word as a low dimensional and real-valued vector, also known as word embedding (Bengio et al. 2003; Mikolov et al. 2013; Pennington, Socher, and Manning 2014). Afterwards, we use recurrent neural network (RNN) to map a question of variable length to a fixed-length vector. To avoid the problem of gradient vanishing, we use gated recurrent unit (GRU) (Cho et al. 2014) as the basic computation unit. The approach recursively calculates the hidden vector ht based on the current word vector e\nq t and the output vector ht−1 in the\nlast time step,\nzi = σ(Wze q i + Uzhi−1) (8) ri = σ(Wre q i + Urhi−1) (9) h̃i = tanh(Whe q i + Uh(ri ⊙ hi−1)) (10)\nhi = zi ⊙ h̃i + (1 − zi)⊙ hi−1 (11)\nwhere zi and ri are update and reset gates of s, ⊙ stands for element-wise multiplication, σ is sigmoid function. We use a bi-directional RNN to get the meaning of a question from both directions, and use the concatenation of two last hidden states as the final question vector vq . We compute the answer sentence vector va in the same way. After obtaining vq and va, we implement a simple yet effective way to calculate the relevance between questionsentence pair. Specifically, we represent a question-answer pair as the concatenation of four vectors, namely v(q, a) = [vq; va; vq ⊙ va; ec(q,a)], where ⊙ means element-wise multiplication, c(q, a) is the number of co-occurred words in q and a. We observe that incorporating the embedding of the word co-occurrence ec\nc(q,a) could empirically improve\nthe QA performance. We use an additional embedding matrix Lc ∈ R dc×|Vc|, where dc is the dimension of word cooccurrence vector and |Vc| is vocabulary size. The values of Lc are jointly learned during training. The output scalar fqa(a, q) is calculated by feeding v(q, a) to a linear layer followed by tanh. We feed fqa(a, q) to a softmax layer and use negative log-likelihood as the QA specific loss function. The basic idea of this objective is to classify whether a given question-answer is correct or not. We also implemented a ranking based loss functionmax(0, 1−fqa(q, a)+ fqa(q, a\n∗)), whose basic idea is to assign the correct QA pair a higher score than a randomly select QA pair. However, our empirical results showed that the ranking loss performed worse than the negative log-likelihood loss function. We use log-likelihood as the QA loss function in the experiment."
    }, {
      "heading" : "The Question Generation Model",
      "text" : "We describe the question generation (QG) model in this section. The model is inspired by the recent success of sequence-to-sequence learning in neural machine translation. Specifically, the QG model first calculates the representation of the answer sentence with an encoder, and then takes the answer vector to generate a question in a sequential way with a decoder. We will present the details of the encoder and the decoder, respectively. The goal of the encoder is to represent a variablelength answer sentence a as a fixed-length continuous vector. The encoder could be implemented with different neural network architectures such as convolutional neural network (Kalchbrenner and Blunsom 2013; Meng et al. 2015) and recurrent neural network (RNN) (Bahdanau, Cho, and Bengio 2014; Sutskever, Vinyals, and Le 2014). In this work, we use bidirectional RNN based on GRU unit, which is consistent with our QA model as described in Section 3. The concatenation of the last hidden vectors from both directions is used as the output of the encoder, which is also used as the initial hidden state of the decoder. The decoder takes the output of the encoder and generates the question sentence. We implement a RNN based decoder, which works in a sequential way and generates one question word at each time step. The decoder generates a word qt at each time step t based on the representation of a and the previously predicted question words q<t = {q1, q2, ..., qt−1}.\nThis process is formulated as follows.\np(q|a) =\n|q|∏\nt=1\np(qt|q<t, a) (12)\nSpecifically, we use an attention-based architecture (Luong, Pham, and Manning 2015), which selectively finds relevant information from the answer sentence when generating the question word. Therefore, the conditional probability is calculated as follows.\np(qt|q<t, a) = fdec(qt−1, st, ct) (13)\nwhere st is the hidden state of GRU based RNN at time step t, and ct is the attention state at time step t. The attention mechanism assigns a probability/weight to each hidden state in the encoder at one time step, and calculates the attention state ct through weighted averaging the hidden states of the encoder: ct = ∑|a|\ni=1 α〈t,i〉hi. When calculating the attention weight of hi at time step t, we also take into account of the attention distribution in the last time step. Potentially, the model could remember which contexts from answer sentence have been used before, and does not repeatedly use these words to generate the question words.\nα〈t,i〉 = exp [z(st, hi, ∑N j=1 α〈t−1,j〉hj)]∑H\ni′=1 exp [z(st, hi′ , ∑N j=1 α〈t−1,j〉hj)] (14)\nAfterwards, we feed the concatenation of st and ct to a linear layer followed by a softmax function. The output dimension of the softmax layer is equal to the number of top frequent question words (e.g. 30K or 50K) in the training data. The output values of the softmax layer form the probability distribution of the question words to be generated. Furthermore, we observe that question sentences typically include informative but low-frequency words such as named entities or numbers. These low-frequency words are closely related to the answer sentence but could not be well covered in the target vocabulary. To address this, we add a simple yet effective post-processing step which replaces each “unknown word” with the most relevant word from the answer sentence. Following (Luong et al. 2015), we use the attention probability as the relevance score of each word from the answer sentence. Copying mechanism (Gulcehre et al. 2016; Gu et al. 2016) is an alternative solution that adaptively determines whether the generated word comes from the target vocabulary or from the answer sentence.\nSince every component of the QG model is differentiable, all the parameters could be learned in an end-to-end way with back propagation. Given a question-answer pair 〈q, a〉, where a is the correct answer of the question q, the training objective is to minimize the following negative loglikelihood.\nlqg(q, a) = −\n|q|∑\nt=1\nlog[p(yt|y<t, a)] (15)\nIn the inference process, we use beam search to get the topK confident results, whereK is the beam size. The inference process stops when the model generates the symbol 〈eos〉 which stands for the end of sentence."
    }, {
      "heading" : "Experiment",
      "text" : "We describe the experimental setting and report empirical results in this section."
    }, {
      "heading" : "Experimental Setting",
      "text" : "We conduct experiments on three datasets, including MARCO (Nguyen et al. 2016), SQUAD (Rajpurkar et al. 2016), and WikiQA (Yang, Yih, and Meek 2015). The MARCO and SQUAD datasets are originally developed for the reading comprehension (RC) task, the goal of which is to answer a question with a text span from a document. Despite our QA task (answer sentence selection) is different from RC, we use these two datasets because of two reasons. The first reason is that to our knowledge they are the QA datasets that contains largest manually labeled questionanswer pairs. The second reason is that, we could derive two QA datasets for answer sentence selection from the original MARCO and SQUAD datasets, with an assumption that the answer sentences containing the correct answer span are correct, and vice versa. We believe that our training framework could be easily applied to RC task, but we that is out of the focus of this work. We also conduct experiments on WikiQA (Yang, Yih, and Meek 2015), which is a benchmark dataset for answer sentence selection. Despite its data size is relatively smaller compared with MARCO and SQUAD, we still apply our algorithm on this data and report empirical results to further compare with existing algorithms. It is worth to note that a common characteristic of MARCO and SQUAD is that the ground truth of the test is invisible to the public. Therefore, we randomly split the original validation set into the dev set and the test set. The\nstatistics of SQUAD and MARCO datasets are given in Table 1. We use the official split of the WikiQA dataset. We apply exactly the same model to these three datasets. We evaluate our QA system with three standard evaluation metrics: Mean Average Precision (MAP), Mean Reciprocal Rank (MRR) and Precision@1 (P@1) (Manning et al. 2008). It is hard to find a perfect way to automatically evaluate the performance of a QG system. In this work, we use BLEU-4 (Papineni et al. 2002) score as the evaluation metric, which measures the overlap between the generated question and the ground truth."
    }, {
      "heading" : "Implementation Details",
      "text" : "We train the parameters of the QA model and the QG model simultaneously. We randomly initialize the parameters in both models with a combination of the fan-in and fan-out (Glorot and Bengio 2010). The parameters of word embeddingmatrices are shared in the QAmodel and the QGmodel. In order to learn question and answer specific word meanings, we use two different embedding matrices for question words and answer words. The vocabularies are the most frequent 30K words from the questions and answers in the training data. We set the dimension of word embedding as 300, the hidden length of encoder and decoder in the QG model as 512, the hidden length of GRU in the QA model as 100, the dimension of word co-occurrence embedding as 10, the vocabulary size of the word co-occurrence embedding as 10, the hidden length of the attention layer as 30. We initialize the learning rate as 2.0, and use AdaDelta (Zeiler 2012) to adaptively decrease the learning rate. We use mini-batch training, and empirically set the batch size as 64. The sampled answer sentences do not come from the same passage. We get 10 batches (640 instances) and sort them by answer length for accelerating the training process. The negative samples come from these 640 instances, which are from different passages. In this work, we use smoothed bigram languagemodels as pa(a) and pq(q). We also tried trigram language model but did not get improved performance. Alternatively, one could also implement neural language model and jointly learn the parameters in the training process."
    }, {
      "heading" : "Results and Analysis",
      "text" : "We first report results on the MARCO and SQUAD datasets. As the dataset is splitted by ourselves, we do not have previously reported results for comparison. We compare with the following four baseline methods. It has been proven that\nword co-occurrence is a very simple yet effective feature for this task (Yang, Yih, and Meek 2015; Yin et al. 2016), so the first two baselines are based on the word co-occurrence between a question sentence and the candidate answer sentence. WordCnt and WgtWordCnt use unnormalized and normalized word co-occurrence. The ranker in these two baselines are trained with with FastTree, which performs better than SVMRank and linear regression in our experiments. We also compare with CDSSM (Shen et al. 2014), which is a very strong neural network approach to model the semantic relatedness of a sentence pair. We further compare with ABCNN (Yin et al. 2016), which has been proven very powerful in various sentence matching tasks. Basic QA is our QAmodel which does not use the duality between QA and QG. Our ultimate model is abbreviated as Dual QA. The QA performance on MARCO and SQUAD datasets are given in Table 2. We can find that CDSSM performs better than the word co-occurrence based method on MARCO dataset. On the SQUAD dataset, Dual QA achieves the best performance among all these methods. On the MARCO dataset, Dual QA performs comparably with ABCNN. We can find that Dual QA still yields better accuracy than Basic QA, which shows the effectiveness of the joint training algorithm. It is interesting that word co-occurrence based method (WgtWordCnt) is very strong and hard to beat on the MARCO dataset. Incorporating sophisticated features might obtain improved performance on both datasets, however, this is not the focus of this work and we leave it to future work.\nResults on the WikiQA dataset is given in Table 3. On this dataset, previous studies typically report results based on their deep features plus the number of words that occur both in the question and in the answer (Yang, Yih, and Meek 2015; Yin et al. 2016). We also follow this experimental protocol. We can find that our basic QA model is simple yet effective. The Dual QA model achieves comparably to strong baseline methods.\nTo give a quantitative evaluation of our training framework on the QG model, we report BLEU-4 scores on MARCO and SQUAD datasets. The results of our QGmodel with or without using joint training are given in Table 5. We can find that, despite the overall BLEU-4 scores are relatively low, using our training algorithm could improve the performance of the QG model.\nWe would like to investigate how the joint training process improves the QA and QG models. To this end, we analyze the results of development set on the SQUAD dataset. We randomly sample several cases that the Basic QA model gets the wrong answers while the Dual QA model obtains the correct results. Examples are given in Table 4. From these examples, we can find that the questions generated by Dual QG tend to have more word overlap with the correct question, despite sometimes the point of the question is not correct. For example, compared with the Basic QG model, the Dual QG model generates more informative words, such as “green” in the first example, “purpose” in the second example, and “how much” in the third example. We believe this helps QA because the QA model is trained to assign a higher score to the question which looks similar with the generated question. It also helps QG because the QA model is trained to give a higher score to the real question-answer pair, so that generating more answer-alike words gives the generated question a higher QA score.\nDespite the proposed training framework obtains some improvements on QA and QG, we believe the work could be further improved from several directions. We find that our QG model not always finds the point of the reference question. This is not surprising because the questions from these two reading comprehension datasets only focus on some spans of a sentence, rather than the entire sentence. Therefore, the source side (answer sentence) carries more information than the target side (question sentence). More-\nover, we do not use the answer position information in our QG model. Accordingly, the model may pay attention to the point which is different from the annotator’s direction, and generates totally different questions. We are aware of incorporating the position of the answer span could get improved performance (Zhou et al. 2017), however, the focus of this work is a sentence level QA task rather than reading comprehension. Therefore, despite MARCO and SQUAD are of large scale, they are not the desirable datasets for investigating the duality of our QA and QG tasks. Pushing forward this area also requires large scale sentence level QA datasets."
    }, {
      "heading" : "Discussion",
      "text" : "Wewould like to discuss our understanding about the duality of QA and QG, and also present our observations based on the experiments. In this work, “duality” means that the QA task and the QG task are equally important. This characteristic makes our work different from Generative Domain-Adaptive Nets (Yang et al. 2017) and Generative Adversarial Nets (GAN) (Goodfellow et al. 2014), both of which have a main task and regard another task as the auxiliary one. There are different ways to leverage the “duality” of QA and QG to improve both tasks. We categorize them into two groups. The first group is about the training process and the second group is about the inference process. From this perspective, dual learning (Xia et al. 2016) is a solution that leverages the duality in the training process. In particular, dual learning first pretrains the models for two tasks separately, and then iteratively fine-tunes the models. Our work also belongs to the first group. Our approach uses the duality as a regularization item to guide the learning of QA and QG models simultaneously from scratch. After the QA and QG models are trained, we could also use the duality to improve the inference process, which falls into the second group. The process could be conducted on separately trained models or the models that jointly trained with our approach. This is reasonable because the QAmodel could directly add one feature to consider q and q′, where q′ is the question generated by the QG model. The first example in Table 4 also motivates this direction. Similarly, the QA model could give each 〈q′, a〉 a score which could be assigned to each generated question q′. In this work we do not apply the duality in the inference\nprocess. We leave it as a future plan. This work could be improved by refining every component involved in our framework. For example, we use a simple yet effective QA model, which could be improved by using more complex neural network architectures (Hu et al. 2014; Yin et al. 2016) or more external resources. We use a smoothed language model for both question and answer sentences, which could be replaced by designed neural languagemodels whose parameters are jointly learned together with the parameters in QA and QG models. The QG model could be improved as well, for example, by developing more complex neural network architectures to take into account of more information about the answer sentence in the generation process. In addition, it is also very important to investigate an automatic evaluation metric to effectively measure the performance of a QG system. BLEU score only measures the literal similarity between the generated question and the ground truth. However, it does not measure whether the question really looks like a question or not. A desirable evaluation system should also have the ability to judge whether the generated question could be answered by input sentence, even if the generated question use totally different words to express the meaning."
    }, {
      "heading" : "Related Work",
      "text" : "Our work relates to existing studies on question answering (QA) and question generation (QG). There are different types of QA tasks including text-level QA (Yu et al. 2014), knowledge based QA (Berant et al. 2013), community based QA (Qiu and Huang 2015) and the reading comprehension (Rajpurkar et al. 2016; Nguyen et al. 2016). Our work belongs to text based QA where the answer is a sentence. In recent years, neural network approaches (Hu et al. 2014; Yu et al. 2014; Yin et al. 2016) show promising ability in modeling the semantic relation between sentences and achieve strong performances on QA tasks. Question generation also draws a lot of attentions in recent years. QG is very necessary in real application as it is always time consuming to create large-scale QA datasets. In literature, (Yao 2010) use Minimal Recursion Semantics (MRS) to represent the meaning of a sentence, and then realize the MSR structure into a natural language question. (Heilman 2011) present a overgenerate-and-rank framework consisting of three stages. They first transform a sentence into a simpler declarative statement, and then transform the statement to candidate questions by executing well-defined syntactic transformations. Finally, a ranker is used to select the questions of high-quality. (Chali and Hasan 2015) focus on generating questions from a topic. They first get a list of texts related to the topic, and then generate questions by exploiting the named entity information and the predicate argument structures of the texts. (Labutov, Basu, and Vanderwende 2015) propose an ontology-crowd-relevance approach to generate questions from novel text. They encode the original text in a low-dimensional ontology, and then align the question\ntemplates obtained via crowd-sourcing to that space. A final ranker is used to select the top relevant templates. There also exists some studies on generating questions from knowledge base (Song and Zhao 2016; Serban et al. 2016). For example, (Serban et al. 2016) develop a neural network approach which takes a knowledge fact (including a subject, an object, and a predicate) as input, and generates the question with a recurrent neural network. Recent studies also investigate question generation for the reading comprehension task (Du, Shao, and Cardie 2017; Zhou et al. 2017). The approaches are typically based on the encoder-decoder framework, which could be conventionally learned in an end-to-end way. As the answer is a text span from the sentence/passage, it is helpful to incorporate the position of the answer span (Zhou et al. 2017). In addition, the computer vision community also pays attention to generating natural language questions about an image (Mostafazadeh et al. 2016)."
    }, {
      "heading" : "Conclusion",
      "text" : "We focus on jointly training the question answering (QA) model and the question generation (QG) model in this paper. We exploit the “duality” of QA and QG tasks, and introduce a training framework to leverage the probabilistic correlation between the two tasks. In our approach, the “duality” is used as a regularization term to influence the learning of QA and QG models. We implement simple yet effective QA and QG models, both of which are neural network based approaches. Experimental results show that the proposed training framework improves both QA and QG on three datasets.\nAcknowledgments. We sincerely thank Wenpeng Yin for running the powerful ABCNN model on our setup."
    }, {
      "heading" : "Conference on Empirical Methods in Natural Language",
      "text" : "Processing (EMNLP), 1532–1543.\n[Qiu and Huang 2015] Qiu, X., and Huang, X. 2015. Convolutional neural tensor network architecture for communitybased question answering. In IJCAI, 1305–1311.\n[Rajpurkar et al. 2016] Rajpurkar, P.; Zhang, J.; Lopyrev, K.; and Liang, P. 2016. Squad: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, 2383–2392.\n[Serban et al. 2016] Serban, I. V.; Garcı́a-Durán, A.; Gulcehre, C.; Ahn, S.; Chandar, S.; Courville, A.; and Bengio, Y. 2016. Generating factoid questions with recurrent neural networks: The 30m factoid question-answer corpus. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 588–598.\n[Shen et al. 2014] Shen, Y.; He, X.; Gao, J.; Deng, L.; and Mesnil, G. 2014. A latent semantic model with convolutional-pooling structure for information retrieval. In Proceedings of the Conference on Information and Knowledge Management, 101–110.\n[Song and Zhao 2016] Song, L., and Zhao, L. 2016. Domain-specific question generation from a knowledge base. arXiv preprint arXiv:1610.03807.\n[Sutskever, Vinyals, and Le 2014] Sutskever, I.; Vinyals, O.; and Le, Q. V. 2014. Sequence to sequence learningwith neural networks. In Advances in neural information processing systems, 3104–3112.\n[Xia et al. 2016] Xia, Y.; He, D.; Qin, T.; Wang, L.; Yu, N.; Liu, T.-Y.; and Ma, W.-Y. 2016. Dual learning for machine\ntranslation. Advances in neural information processing systems.\n[Xia et al. 2017] Xia, Y.; Qin, T.; Chen, W.; Bian, J.; Yu, N.; and Liu, T.-Y. 2017. Dual supervised learning. arXiv preprint arXiv:1707.00415.\n[Yang et al. 2017] Yang, Z.; Hu, J.; Salakhutdinov, R.; and Cohen, W. W. 2017. Semi-supervised qa with generative domain-adaptive nets. arXiv preprint arXiv:1702.02206.\n[Yang, Yih, and Meek 2015] Yang, Y.; Yih, W.-t.; and Meek, C. 2015. Wikiqa: A challenge dataset for open-domain question answering. In EMNLP, 2013–2018. Citeseer.\n[Yao 2010] Yao, X. 2010. Question generation with minimal recursion semantics. Citeseer.\n[Yin et al. 2016] Yin, W.; Schtze, H.; Xiang, B.; and Zhou, B. 2016. Abcnn: Attention-based convolutional neural network for modeling sentence pairs. Transactions of the Association for Computational Linguistics 4:259–272.\n[Yu et al. 2014] Yu, L.; Hermann, K. M.; Blunsom, P.; and Pulman, S. 2014. Deep learning for answer sentence selection. arXiv preprint arXiv:1412.1632.\n[Zeiler 2012] Zeiler, M. D. 2012. Adadelta: an adaptive learning rate method. arXiv preprint arXiv:1212.5701.\n[Zhou et al. 2017] Zhou, Q.; Yang, N.; Wei, F.; Tan, C.; Bao, H.; and Zhou, M. 2017. Neural question generation from text: A preliminary study. arXiv preprint arXiv:1704.01792."
    } ],
    "references" : [ {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Cho Bahdanau", "D. Bengio 2014] Bahdanau", "K. Cho", "Y. Bengio" ],
      "venue" : "arXiv preprint arXiv:1409.0473",
      "citeRegEx" : "Bahdanau et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2014
    }, {
      "title" : "A neural probabilistic language model",
      "author" : [ "Bengio" ],
      "venue" : "Journal of Machine Learning Research 3:1137–1155",
      "citeRegEx" : "Bengio,? \\Q2003\\E",
      "shortCiteRegEx" : "Bengio",
      "year" : 2003
    }, {
      "title" : "Semantic parsing on freebase from questionanswer pairs",
      "author" : [ "Berant" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Berant,? \\Q2013\\E",
      "shortCiteRegEx" : "Berant",
      "year" : 2013
    }, {
      "title" : "S",
      "author" : [ "Y. Chali", "Hasan" ],
      "venue" : "A.",
      "citeRegEx" : "Chali and Hasan 2015",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Learning phrase representations using rnn encoder– decoder for statistical machine translation",
      "author" : [ "Cho" ],
      "venue" : "In Proceedings of the 2014 Conference on Empirical Methods in Natural",
      "citeRegEx" : "Cho,? \\Q2014\\E",
      "shortCiteRegEx" : "Cho",
      "year" : 2014
    }, {
      "title" : "Learning to ask: Neural question generation for reading comprehension",
      "author" : [ "Shao Du", "X. Cardie 2017] Du", "J. Shao", "C. Cardie" ],
      "venue" : null,
      "citeRegEx" : "Du et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Du et al\\.",
      "year" : 2017
    }, {
      "title" : "and Bengio",
      "author" : [ "X. Glorot" ],
      "venue" : "Y.",
      "citeRegEx" : "Glorot and Bengio 2010",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Y",
      "author" : [ "I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Bengio" ],
      "venue" : "2014. Generative adversarial nets. In Advances in neural information processing systems, 2672–",
      "citeRegEx" : "Goodfellow et al. 2014",
      "shortCiteRegEx" : null,
      "year" : 2680
    }, {
      "title" : "V",
      "author" : [ "J. Gu", "Z. Lu", "H. Li", "Li" ],
      "venue" : "O.",
      "citeRegEx" : "Gu et al. 2016",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Convolutional neural network architectures for matching natural language sentences",
      "author" : [ "Hu" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "Hu,? \\Q2014\\E",
      "shortCiteRegEx" : "Hu",
      "year" : 2014
    }, {
      "title" : "J",
      "author" : [ "D. Jurafsky", "Martin" ],
      "venue" : "H.",
      "citeRegEx" : "Jurafsky and Martin 2000",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "and Blunsom",
      "author" : [ "N. Kalchbrenner" ],
      "venue" : "P.",
      "citeRegEx" : "Kalchbrenner and Blunsom 2013",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Deep questions without deep understanding",
      "author" : [ "Basu Labutov", "I. Vanderwende 2015] Labutov", "S. Basu", "L. Vanderwende" ],
      "venue" : "In ACL",
      "citeRegEx" : "Labutov et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Labutov et al\\.",
      "year" : 2015
    }, {
      "title" : "Addressing the rare word problem in neural machine translation",
      "author" : [ "Luong" ],
      "venue" : "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Luong,? \\Q2015\\E",
      "shortCiteRegEx" : "Luong",
      "year" : 2015
    }, {
      "title" : "Effective approaches to attentionbased neural machine translation",
      "author" : [ "Pham Luong", "T. Manning 2015] Luong", "H. Pham", "C.D. andManning" ],
      "venue" : "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Luong et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Luong et al\\.",
      "year" : 2015
    }, {
      "title" : "and Schütze",
      "author" : [ "C.D. Manning" ],
      "venue" : "H.",
      "citeRegEx" : "Manning and Schütze 1999",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "C",
      "author" : [ "Manning" ],
      "venue" : "D.; Raghavan, P.; Schütze, H.; et al.",
      "citeRegEx" : "Manning et al. 2008",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Encoding source language with convolutional neural network for machine translation",
      "author" : [ "Meng" ],
      "venue" : "arXiv preprint arXiv:1503.01838",
      "citeRegEx" : "Meng,? \\Q2015\\E",
      "shortCiteRegEx" : "Meng",
      "year" : 2015
    }, {
      "title" : "Neural variational inference for text processing",
      "author" : [ "Yu Miao", "Y. Blunsom 2016] Miao", "L. Yu", "P. Blunsom" ],
      "venue" : "In International Conference on Machine Learning,",
      "citeRegEx" : "Miao et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Miao et al\\.",
      "year" : 2016
    }, {
      "title" : "G",
      "author" : [ "T. Mikolov", "I. Sutskever", "K. Chen", "Corrado" ],
      "venue" : "S.; and Dean, J.",
      "citeRegEx" : "Mikolov et al. 2013",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Generating natural questions about an image. arXiv preprint arXiv:1603.06059",
      "author" : [ "Mostafazadeh" ],
      "venue" : null,
      "citeRegEx" : "Mostafazadeh,? \\Q2016\\E",
      "shortCiteRegEx" : "Mostafazadeh",
      "year" : 2016
    }, {
      "title" : "2016. Ms marco: A human generated machine reading comprehension",
      "author" : [ "Nguyen" ],
      "venue" : null,
      "citeRegEx" : "Nguyen,? \\Q2016\\E",
      "shortCiteRegEx" : "Nguyen",
      "year" : 2016
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Papineni" ],
      "venue" : "In Proceedings of the 40th annual meeting on association for computational linguistics,",
      "citeRegEx" : "Papineni,? \\Q2002\\E",
      "shortCiteRegEx" : "Papineni",
      "year" : 2002
    }, {
      "title" : "C",
      "author" : [ "J. Pennington", "R. Socher", "Manning" ],
      "venue" : "D.",
      "citeRegEx" : "Pennington. Socher. and Manning 2014",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "and Huang",
      "author" : [ "X. Qiu" ],
      "venue" : "X.",
      "citeRegEx" : "Qiu and Huang 2015",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Squad: 100,000+ questions for machine comprehension of text",
      "author" : [ "Rajpurkar" ],
      "venue" : "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Rajpurkar,? \\Q2016\\E",
      "shortCiteRegEx" : "Rajpurkar",
      "year" : 2016
    }, {
      "title" : "I",
      "author" : [ "Serban" ],
      "venue" : "V.; Garcı́a-Durán, A.; Gulcehre, C.; Ahn, S.; Chandar, S.; Courville, A.; and Bengio, Y.",
      "citeRegEx" : "Serban et al. 2016",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "A latent semantic model with convolutional-pooling structure for information retrieval",
      "author" : [ "Shen" ],
      "venue" : "In Proceedings of the Conference on Information and Knowledge Management,",
      "citeRegEx" : "Shen,? \\Q2014\\E",
      "shortCiteRegEx" : "Shen",
      "year" : 2014
    }, {
      "title" : "and Zhao",
      "author" : [ "L. Song" ],
      "venue" : "L.",
      "citeRegEx" : "Song and Zhao 2016",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Q",
      "author" : [ "I. Sutskever", "O. Vinyals", "Le" ],
      "venue" : "V.",
      "citeRegEx" : "Sutskever. Vinyals. and Le 2014",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Dual learning for machine",
      "author" : [ "Xia" ],
      "venue" : null,
      "citeRegEx" : "Xia,? \\Q2016\\E",
      "shortCiteRegEx" : "Xia",
      "year" : 2016
    }, {
      "title" : "W",
      "author" : [ "Z. Yang", "J. Hu", "R. Salakhutdinov", "Cohen" ],
      "venue" : "W.",
      "citeRegEx" : "Yang et al. 2017",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Wikiqa: A challenge dataset for open-domain question answering",
      "author" : [ "Yih Yang", "Y. Meek 2015] Yang", "W.-t. Yih", "C. Meek" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Yang et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2015
    }, {
      "title" : "Abcnn: Attention-based convolutional neural network for modeling sentence pairs. Transactions of the Association for Computational Linguistics 4:259–272",
      "author" : [ "Yin" ],
      "venue" : null,
      "citeRegEx" : "Yin,? \\Q2016\\E",
      "shortCiteRegEx" : "Yin",
      "year" : 2016
    }, {
      "title" : "K",
      "author" : [ "Yu, L.", "Hermann" ],
      "venue" : "M.; Blunsom, P.; and Pulman, S.",
      "citeRegEx" : "Yu et al. 2014",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "M",
      "author" : [ "Zeiler" ],
      "venue" : "D.",
      "citeRegEx" : "Zeiler 2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Neural question generation from text: A preliminary study",
      "author" : [ "Zhou" ],
      "venue" : "arXiv preprint arXiv:1704.01792",
      "citeRegEx" : "Zhou,? \\Q2017\\E",
      "shortCiteRegEx" : "Zhou",
      "year" : 2017
    } ],
    "referenceMentions" : [ ],
    "year" : 2017,
    "abstractText" : "We study the problem of joint question answering (QA) and question generation (QG) in this paper. Our intuition is that QA and QG have intrinsic connections and these two tasks could improve each other. On one side, the QA model judges whether the generated question of a QG model is relevant to the answer. On the other side, the QG model provides the probability of generating a question given the answer, which is a useful evidence that in turn facilitates QA. In this paper we regard QA and QG as dual tasks. We propose a training framework that trains the models of QA and QG simultaneously, and explicitly leverages their probabilistic correlation to guide the training process of both models. We implement a QG model based on sequence-to-sequence learning, and a QA model based on recurrent neural network. As all the components of the QA and QG models are differentiable, all the parameters involved in these two models could be conventionally learned with back propagation. We conduct experiments on three datasets. Empirical results show that our training framework improves both QA and QG tasks. The improved QA model performs comparably with strong baseline approaches on all three datasets.",
    "creator" : "LaTeX with hyperref package"
  }
}