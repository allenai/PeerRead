{
  "name" : "1705.03916.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Solving Distributed Constraint Optimization Problems Using Logic Programming",
    "authors" : [ "Tiep Le", "Tran Cao Son", "Enrico Pontelli", "William Yeoh" ],
    "emails" : [ "wyeoh}@cs.nmsu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Under consideration in Theory and Practice of Logic Programming (TPLP).\nKEYWORDS: DCOP; DPOP; Logic Programming; ASP"
    }, {
      "heading" : "1 Introduction",
      "text" : "Distributed Constraint Optimization Problems (DCOPs) are optimization problems where agents need to coordinate the assignment of values to their “local” variables to maximize the overall sum of resulting constraint utilities (Modi et al. 2005; Petcu and Faltings 2005a; Mailler and Lesser 2004; Yeoh and Yokoo 2012). The process is subject to limitations on the communication capabilities of the agents; in particular, each agent can only exchange information with neighboring agents within a given topology. DCOPs are well-suited for modeling multi-agent coordination and resource allocation problems, where the primary interactions are between local subsets of agents. Researchers have used DCOPs to model various problems, such as the distributed scheduling of meetings (Maheswaran et al. 2004; Zivan et al. 2014), distributed allocation of targets to sensors in a network (Farinelli et al. 2008), distributed allocation of resources in disaster evacuation scenarios (Lass et al. 2008), the distributed management of power distribution networks (Kumar et al. 2009; Jain et al. 2012), the distributed generation of coalition structures (Ueda et al. 2010) and the distributed coordination of logistics operations (Léauté and Faltings 2011).\n1 This article extends our previous conference paper (Le et al. 2015) in the following manner: (1) It provides a more thorough description of the ASP-DPOP algorithm; (2) It elaborates on the algorithm’s theoretical properties with complete proofs; and (3) It includes additional experimental results.\nar X\niv :1\n70 5.\n03 91\n6v 1\n[ cs\n.M A\n] 1\nThe field has matured considerably over the past decade, since the seminal ADOPT paper (Modi et al. 2005), as researchers continue to develop more sophisticated solving algorithms. The majority of the DCOP resolution algorithms can be classified in one of three classes: (1) Search-based algorithms, like ADOPT (Modi et al. 2005) and its variants (Yeoh et al. 2009; Yeoh et al. 2010; Gutierrez et al. 2011; Gutierrez et al. 2013), AFB (Gershman et al. 2009), and MGM (Maheswaran et al. 2004), where the agents enumerate combinations of value assignments in a decentralized manner; (2) Inference-based algorithms, like DPOP (Petcu and Faltings 2005a) and its variants (Petcu and Faltings 2005b; Petcu and Faltings 2007; Petcu et al. 2007; Petcu et al. 2008), max-sum (Farinelli et al. 2008), and Action GDL (Vinyals et al. 2011), where the agents use dynamic programming techniques to propagate aggregated information to other agents; and (3) Sampling-based algorithms, like DUCT (Ottens et al. 2012) and D-Gibbs (Nguyen et al. 2013; Fioretto et al. 2014), where the agents sample the search space in a decentralized manner.\nThe existing algorithms have been designed and developed almost exclusively using imperative programming techniques, where the algorithms define a control flow, that is, a sequence of commands to be executed. In addition, the local solver employed by each agent is an “ad-hoc” implementation. In this paper, we are interested in investigating the benefits of using declarative programming techniques to solve DCOPs, along with the use of a general constraint solver, used as a black box, as each agent’s local constraint solver. Specifically, we propose an integration of Distributed Pseudo-tree Optimization Procedure (DPOP) (Petcu and Faltings 2005a), a popular DCOP algorithm, with Answer Set Programming (ASP) (Niemelä 1999; Marek and Truszczyński 1999) as the local constraint solver of each agent.\nThis paper provides the first step in bridging the areas of DCOPs and ASP; in the process, we offer novel contributions to both the DCOP field as well as the ASP field. For the DCOP community, we demonstrate that the use of ASP as a local constraint solver provides a number of benefits, including the ability to capitalize on (i) the highly expressive ASP language to more concisely define input instances (e.g., by representing constraint utilities as implicit functions instead of explicitly enumerating their extensions) and (ii) the highly optimized ASP solvers to exploit problem structure (e.g., propagating hard constraints to ensure consistency). For the ASP community, the paper makes the equally important contribution of increasing the applicability of ASP to model and solve a wide array of multi-agent coordination and resource allocation problems, currently modeled as DCOPs. Furthermore, it also demonstrates that general, off-the-shelf ASP solvers, which are continuously honed and improved, can be coupled with distributed message passing protocols to outperform specialized imperative solvers.\nThe paper is organized as follows. In Section 2, we review the basic definitions of DCOPs, the DPOP algorithm, and ASP. In Section 3, we describe in detail the structure of the novel ASP-based DCOP solver, called ASP-DPOP, and its implementation. Section 4 provides an analysis of the properties of ASP-DPOP, including proofs of soundness and completeness of ASP-DPOP. Section 5 provides some experimental results, while Section 6 reviews related work. Finally, Section 7 provides conclusions and indications for future work."
    }, {
      "heading" : "2 Background",
      "text" : "In this section, we present an overview of DCOPs, we describe DPOP, a complete distributed algorithm to solve DCOPs, and provide some fundamental definitions of ASP."
    }, {
      "heading" : "2.1 Distributed Constraint Optimization Problems",
      "text" : "A Distributed Constraint Optimization Problem (DCOP) (Modi et al. 2005; Petcu and Faltings 2005a; Mailler and Lesser 2004; Yeoh and Yokoo 2012) can be described as a tupleM = 〈X ,D,F ,A, α〉 where:\n• X = {x1, . . . , xn} is a finite set of (decision) variables; • D = {D1, . . . , Dn} is a set of finite domains, whereDi is the domain of the variable xi ∈ X , for 1 ≤ i ≤ n; • F = {f1, . . . , fm} is a finite set of constraints, where fj is a kj-ary function fj : Dj1 ×Dj2 × . . .×Djkj 7→ R ∪ {−∞} that specifies the utility of each combination of values of variables in its scope; the scope is denoted by scp(fj) = {xj1 , . . . , xjkj }; 2 • A = {a1, . . . , ap} is a finite set of agents; and • α : X 7→ A maps each variable to an agent.\nWe say that a variable x is owned by an agent a if α(x) = a. We denote with αi the set of all variables that are owned by an agent ai, i.e., αi = {x ∈ X |α(x) = ai}. Each constraint in F can be either hard, indicating that some value combinations result in a utility of −∞ and must be avoided, or soft, indicating that all value combinations result in a finite utility and need not be avoided. A value assignment is a (partial or complete) function x that maps variables of X to values in D such that, if x(xi) is defined, then x(xi) ∈ Di for i = 1, . . . , n. For the sake of simplicity, and with a slight abuse of notation, we will often denote x(xi) simply with xi. Given a constraint fj and a complete value assignment x for all decision variables, we denote with xfj the projection of x to the variables in scp(fj); we refer to this as a partial value assignment for fj . For a DCOP M, we denote with C(M) the set of all complete value assignments forM.\nA solution of a DCOP is a complete value assignment x for all variables such that\nx = argmax x∈C(M) m∑ j=1 fj(xfj ) (1)\nA DCOP can be described by its constraint graph—i.e., a graph whose nodes correspond to agents in A and whose edges connect pairs of agents who own variables in the scope of the same constraint.\nDefinition 1 (Constraint Graph) A constraint graph of a DCOP M = 〈X ,D,F ,A, α〉 is an undirected graph GM = (V,E) where V = A and\nE = {{a, a′} | {a, a′} ⊆ A,∃f ∈ F and {xi, xj} ⊆ X , such that {xi, xj} ⊆ scp(f), and α(xi) = a, α(xj) = a′}. (2)\n2 For the sake of simplicity, we assume a given ordering of variables.\nGiven the constraint graph GM and given a node a ∈ A, we denote with N(a) the neighbors of a, i.e.,\nN(a) = {a′ ∈ A | {a, a′} ∈ E}. (3)\nDefinition 2 (Pseudo-tree) A pseudo-tree of a DCOP is a subgraph of GM that has the same nodes as GM such that (i) the included edges (called tree edges) form a rooted tree, and (ii) two nodes that are connected to each other in GM appear in the same branch of the tree.\nThe edges of GM that are not included in a pseudo-tree are called back edges. Notice that tree edges connect a node with its parent and its children, while back edges connect a node with its pseudo-parents and pseudo-children—i.e., nodes closer to the root are parents or pseudo-parents, while those closer to the leaves are children or pseudo-children. A pseudotree of a DCOP can be constructed using distributed DFS algorithms (Hamadi et al. 1998) applied to the constraint graph of the DCOP.\nIn this paper, we say that two variables are constrained to each other if they are in the scope of the same constraint. Given a pseudo-tree, the separator of a node ai is, intuitively, the set of variables that (i) are owned by the ancestors of ai, and (ii) are constrained with some variables that are either owned by ai or the descendants of ai. Formally, in a pseudotree, the separator of a node ai, denoted by sepi, is:\nsepi = {xi′ ∈ X | α(xi′) = ai′ where ai′ is an ancestor of ai; and ∃xi′′ ∈ X , f ∈ F , such that ai′′ is either ai or a descendant of ai,\nα(xi′′) = ai′′ , and {xi′ , xi′′} ⊆ scp(f)} (4)\nWe denote with Pi, PPi, Ci, and PCi the parent, the set of pseudo-parents, the set of children, and the set of pseudo-children of a node ai, respectively. For simplicity, if A is a set of agents in A, we also denote with αA the set of variables in X that are owned by agents in A.\nExample 1 Figure 1(a) shows the constraint graph of a DCOPM = 〈X ,D,F ,A, α〉 where:\n• X = {x1, x2, x3}; • D = {D1, D2, D3} where Di = {0, 1} (1 ≤ i ≤ 3) is the domain of the variable xi ∈ X ; • F = {x1 cons x2, x1 cons x3, x2 cons x3} where, for each 1 ≤ i < j ≤ 3,\n— for the constraint xi cons xj we have that scp(xi cons xj) = {xi, xj}; — the utilities specified by the constraint xi cons xj are given in Figure 1(c).\n• A = {a1, a2, a3}; and • α maps each variable xi to agent ai.\nFigure 1(b) shows one possible pseudo-tree, where the dotted line is a back edge. In this pseudo-tree, P3 = a2, PP3 = {a1}, C1 = {a2}, PC1 = {a3}, and sep3 = {x1, x2}.\nIn a pseudo-tree T of a DCOP 〈X ,D,F ,A, α〉, given ai ∈ A let RTai be the set of constraints in F such that:\nRTai = {f ∈ F | scp(f) ⊆ αi ∪ αPi ∪ αPPi ∧ scp(f) ∩ αi 6= ∅} (5)\nIn the following, without causing any confusion, we often omit the superscript in RTai (i.e., Rai ) if there is only one pseudo-tree mentioned in the context.\nExample 2 Considering again the DCOP in Example 1 and its pseudo-tree in Figure 1(b), we have Ra3 = {x1 cons x3, x2 cons x3}."
    }, {
      "heading" : "2.2 The Distributed Pseudo-tree Optimization Procedure",
      "text" : "The Distributed Pseudo-tree Optimization Procedure (DPOP) (Petcu and Faltings 2005a) is a complete algorithm to solve DCOPs with the following three phases:3 Pseudo-tree generation, UTIL propagation and VALUE propagation.\n2.2.1 Phase 1: Pseudo-tree Generation Phase\nDPOP does not require the use of any specific algorithm to construct the pseudo-tree. However, in many implementations of DPOP, including those within the DCOPolis (Sultanik et al. 2007) and FRODO (Léauté et al. 2009) repositories, greedy approaches such as the Distributed DFS algorithm (Hamadi et al. 1998) are used.\nThe Distributed DFS algorithm operates as follows. First of all, the algorithm assigns a score to each agent, according to a heuristic function. It then selects an agent with the largest score as the root of the pseudo-tree. Once the root is selected, the algorithm initiates a DFS-traversal of the constraint graph, greedily adding the neighboring agent with the\n3 Here we detail an extended version of DPOP described in (Petcu and Faltings 2005a) which removes the assumption that each agent owns exactly one variable.\nlargest score as the child of the current agent. This process is repeated until all agents in the constraint graph are added to the pseudo-tree.\nThe agents’ scores can be chosen arbitrarily. A commonly used heuristic is the maxdegree heuristic h(ai):\nh(ai) = |N(ai)| (6)\nwhich sets an agent’s score to its number of neighbors. In situations where multiple agents have the same maximal score, the algorithm breaks ties according to a different heuristic, such as the variable-ID heuristic, which assigns to each agent a score that is equal to its unique ID. In our experiments, we use the max-degree heuristic and break ties with the variable-ID heuristic in the construction of the pseudo-tree.\n2.2.2 Phase 2: UTIL Propagation Phase\nThe UTIL propagation phase is a bottom-up process, which starts from the leaves of the pseudo-tree and propagates upward, following only the tree edges of the pseudo-tree. In this process, the agents send UTIL messages to their parents.\nDefinition 3 (UTIL Messages (Petcu 2009)) UTIL aj ai , the UTIL message sent by agent ai to agent aj , is a multi-dimensional matrix, with one dimension for each variable in sepi. With a slight abuse of notation, we denote with scp(UTILajai ) the set of variables in the message.\nInstead of using a multi-dimensional matrix, one can also flatten the multi-dimensional matrix into a table where each row of the table is for one combination of value assignment of variables in sepi and the respective utility for that combination. For simplicity, in this paper, we will represent UTIL messages under their tabular form. We can observe that it is always true that αj ∩ scp(UTIL aj ai ) 6= ∅. The semantics of such a UTIL message is similar to a constraint whose scope is the set of all variables in the context of the message (its dimensions). The size of such a UTIL message is the product of the domain sizes of variables in the context of the message.\nIntuitively, a UTIL message summarizes the optimal sum of utilities in its subtree for each value combination of variables in its separator. An agent ai computes its UTIL message by (i) summing the utilities in the UTIL messages received from its child agents and the utilities of constraints whose scopes are exclusively composed of the variables of ai and the variables in its separator (i.e., Rai ), and then (ii) projecting out the variables of ai, by optimizing over them. Algorithm 1 provides a formal description of Phase 2.\nAlgorithm 1 uses the JOIN operator (i.e., ⊕) and the PROJECTION operator (i.e., ⊥).\nDefinition 4 (JOIN ⊕ Operator) U = UTILaiak ⊕ UTIL ai al\nis the join of two UTIL matrices (constraints). U is also a matrix (constraint) with scp(U) = scp(UTILaiak) ∪ scp(UTIL ai al\n) as dimensions. For each possible combination x of values of variables in scp(U), the corresponding value of U(x) is the sum of the corresponding cells in the two source matrices, i.e., U(x) = UTILaiak(xUTILaiak ) + UTILaial (xUTILaial ) where xUTILaiak and xUTIL ai al\nare partial value assignments from x for all variables in scp(UTILaiak) and scp(UTIL ai al ), respectively.\nAlgorithm 1: DPOP Phase 2 (UTIL Propagation Phase) 1 Each agent ai does: 2 JOINPiai = null 3 forall ac ∈ Ci do 4 wait for UTILaiac message to arrive from ac 5 JOINPiai = JOIN Pi ai ⊕ UTIL ai ac // join UTIL messages from children as they arrive 6 end 7 JOINPiai = JOIN Pi ai ⊕ ( ⊕f∈Rai f ) // also join all constraints with parent/pseudo-parents 8 UTILPiai = JOIN Pi ai ⊥αi // use projection to eliminate its owned variables 9 Send UTILPiai message to its parent agent Pi\nSince UTIL messages can be seen as constraints, the ⊕ operator can be used to join UTIL messages and constraints.\nExample 3 Given 2 constraints x1 cons x3 and x2 cons x3 in Example 1, let JOINa2a3 = x1 cons x3 ⊕ x2 cons x3. It is possible to see that scp(JOINa2a3 ) = {x1, x2, x3}. The utility corresponding to x1 = x2 = x3 = 0 is JOINa2a3 (x1 = 0, x2 = 0, x3 = 0) = 5 + 5 = 10. Moreover, JOINa2a3 (x1 = 0, x2 = 0, x3 = 1) = 8 + 8 = 16.\nFor the ⊥ operator, knowing that αi ⊆ scp(JOINPiai ), JOIN Pi ai ⊥αi is the projection\nthrough optimization of the JOINPiai matrix along axes representing variables in αi.\nDefinition 5 (PROJECTION ⊥ Operator) Let αi be a set of variables where αi ⊆ scp(JOINPiai ), and let Xi be the set of all possible value combinations of variables in αi. A matrix U = JOINPiai ⊥αi is defined as: (i) scp(U) = scp(JOINPiai ) \\ αi, and (ii) for each possible value combination x of variables in scp(U), U(x) = maxx′∈Xi JOIN Pi ai (x, x ′).\nExample 4 Considering again JOINa2a3 in Example 3, let U = JOIN a2 a3 ⊥{x3}. We have scp(U) =\n{x1, x2}, and U(x1 = 0, x2 = 0) = max ( JOINa2a3 (x1 = 0, x2 = 0, x3 =\n0), JOINa2a3 (x1 = 0, x2 = 0, x3 = 1) ) = max(10, 16) = 16.\nAs an example for the computations in Phase 2 (UTIL propagation phase), we consider again the DCOP in Example 1.\nExample 5 In the DCOP in Example 1, the agent a3 computes its UTIL message, UTILa2a3 (see Table 1(a)), and sends it to its parent agent a2. The agent a2 then computes its UTIL message, UTILa1a2 (see Table 1(b)), and sends it to its parent agent a1. Finally, the agent a1 computes the optimal utility of the entire problem, which is 45.\n2.2.3 Phase 3: VALUE Propagation Phase\nPhase 2 finishes when the UTIL message reaches the root of the tree. At that point, each agent, starting from the root of the pseudo-tree, determines the optimal value for its variables based on (i) the computation from Phase 2, and (ii) (for non-root agent only) the VALUE message that is received from its parent. Then, it sends these optimal values to its child agents through VALUE messages. Algorithm 2 provides a formal description of Phase 3.\nA VALUE message that travels from the parent Pi to the agent ai, VALUEaiPi , contains the optimal value assignment for variables owned by either the parent agent or the pseudoparent agents of the agent ai.\nAlgorithm 2: DPOP Phase 3 (VALUE Propagation Phase) 1 Each agent ai do: 2 wait for VALUEaiPi(sep ∗ i ) message from its parent agent Pi // sep ∗ i is the optimal value\nassignment for all variables in sepi 3 α∗i ← argmaxαi∈Xi JOIN Pi ai (sep ∗ i , αi) // Xi is the set of all possible value combinations of\nvariables in αi 4 forall ac ∈ Ci do 5 let sep∗∗i be the partial optimal value assignment for variables in sepc from sep ∗ i 6 send VALUE(sep∗∗i , α ∗ i ) as VALUE ac ai message to its child agent ac 7 end\nExample 6 In the DCOP in Example 1, the agent a1 determines that the value with the largest utility for its variable x1 is 1, with a utility of 45, and then sends this information down to its child agent a2 in a VALUE message, i.e., VALUEa2a1(x1 = 1). Upon receiving that VALUE message, the agent a2 determines that the value for its variable x2 with the largest utility of the subtree rooted at the agent a2, assuming that x1 = 1, is 0, with a utility of 45. The agent a2 then sends this information down to its child agent a3, i.e., VALUEa3a2(x1 = 1, x2 = 0). Finally, upon receiving such VALUE message, the agent a3 determines that the value for its variable x3 with the largest utility of the subtree rooted at the agent a3, assuming that x1 = 1 and x2 = 0, is 0, with a utility of 25."
    }, {
      "heading" : "2.3 Answer Set Programming",
      "text" : "Let us provide some general background on Answer Set Programming (ASP) (see, for example, (Baral 2003; Gelfond and Kahl 2014) for more details).\nAn answer set program Π is a set of rules of the form\nc← a1, . . . , aj , not aj+1, . . . , not am (7)\nwhere 0 ≤ j ≤ m, for 1 ≤ i ≤ m each ai or c is a literal of a first order language L, and not represents negation-as-failure (naf). For a literal a, not a is called a naf-literal. For a rule of the form (7), the left and right hand sides of the rule are called the head and the body of the rule, respectively. Both the head and the body can be empty. When the head is empty, the rule is called a constraint. When the body is empty, the rule is called a fact. A literal (resp. rule) is a ground literal (resp. ground rule) if it does not contain any variable. A rule with variables is simply used as a shorthand for the set of its ground instances from the language L. Similarly, a non-ground program (i.e., a program containing some nonground rules) is a shorthand for all ground instances of its rules. Throughout this paper, we follow the traditional notation in writing ASP rules, where names that start with an upper case letter represent variables. For a ground instance r of a rule of the form (7), head(r) denotes the set {c}, while pos(r) and neg(r) denote {a1, . . . , aj} and {aj+1, . . . , am}, respectively.\nLetX be a set of ground literals.X is consistent if there is no atom a such that {a,¬a} ⊆ X . The body of a ground rule r of the form (7) is satisfied by X if neg(r) ∩ X = ∅ and pos(r) ⊆ X . A ground rule of the form (7) with nonempty head is satisfied by X if either its body is not satisfied byX or head(r)∩X 6= ∅. A constraint is satisfied byX if its body is not satisfied by X .\nFor a consistent set of ground literals S and a ground program Π, the reduct of Π w.r.t. S, denoted by ΠS , is the program obtained from Π by deleting (i) each rule that has a nafliteral not a in its body where a ∈ S, and (ii) all naf-literals in the bodies of the remaining rules. S is an answer set (or a stable model) of a ground program Π (Gelfond and Lifschitz 1990) if it satisfies the following conditions: (i) If Π does not contain any naf-literal (i.e., j = m in every rule of Π) then S is a minimal consistent set of literals that satisfies all the rules in Π; and (ii) If Π contains some naf-literals (j < m in some rules of Π) then S is an answer set of ΠS . Note that ΠS does not contain naf-literals, and thus its answer set is defined in case (i). A program Π is said to be consistent if it has some answer sets. Otherwise, it is inconsistent.\nThe ASP language includes also language-level extensions to facilitate the encoding of aggregates (min, max, sum, etc.).\nExample 7 Let us consider an ASP program Π that consists of two facts and one rule:\nint(5) ← (8) int(10) ← (9) max(U) ← U = #max{V : int(V )} (10)\nThe third rule uses an aggregate to determine the maximum in the set {V : int(V )}. Π has one answer set: {int(5), int(10),max(10)}. Thus, Π is consistent.\nMoreover, to increase the expressiveness of logic programming and simplify its use in\napplications, the syntax of ASP has been extended with choice rules. Choice rules are of the form:\nl {a1, . . . , am}u← am+1, . . . , an, not an+1, . . . , not ak (11)\nwhere l {a1, . . . , am}u is called a choice atom, l and u are integers, l ≤ u, 0 ≤ m ≤ n ≤ k, and each ai is a literal for 1 ≤ i ≤ k. This rule allows us to derive any subset of {a1, . . . , am}whose cardinality is between the lower bound l and upper bound uwhenever the body is satisfied. l or u can be omitted. If l is omitted, l = 0, and if u is omitted, u = +∞. Standard syntax for choice rules has been proposed and adopted in most stateof-the-art ASP solvers, such as CLASP (Gebser et al. 2007) and DLV (Citrigno et al. 1997).\nFigure 2 visualizes how to solve a problem using ASP. In more detail, the problem is encoded as an answer set program whose answer sets correspond to solutions. The answer set program, which may contains variables, is then grounded using an ASP grounder, e.g., GRINGO (Gebser et al. 2011). The grounding process employs smart techniques to reduce the size of the resulting ground program, e.g., removing literals from rules that are known to be true, removing rules that will not contribute to the computation of answer sets.\nExample 8 Let us consider an ASP program Π that consists of two facts and one rule:\nint(1) ← (12) int(−1) ← (13)\nisPositive(X) ← int(X), X > 0 (14)\nUsing a naive grounder that simply replaces consistently the variable X with the two constants 1 and −1, the ground program of Π consists of the two facts (12) and (13) and the two following ground rules:\nisPositive(1) ← int(1), 1 > 0 (15) isPositive(−1) ← int(−1),−1 > 0 (16)\nIt is easy to see that the ground rule (16) is unnecessary (i.e., its body cannot be satisfied\nby any set of literals due to the literal −1 > 0) and should be removed. In contrast, the ground program of Π obtained by GRINGO has only three facts: (12), (13), and\nisPositive(1) ← (17)\nWe observe that the unnecessary rule (16) is omitted since its body cannot be satisfied (i.e., −1 > 0), and the fact (17) is obtained from the rule (15) by removing all literals in its body because the grounder can determine as been always satisfied.\nAll the answer sets of the program produced by the ASP grounder are then computed by an ASP solver, e.g., CLASP (Gebser et al. 2007). The solutions to the original problem can be determined by properly interpreting the different answer sets computed, where each answer sets corresponds to one of the possible solutions to the original problem. For readers who are interested in how to solve an answer set program, the foundations and algorithms underlying the grounding and solving technology used in GRINGO and CLASP are described in detail in (Gebser et al. 2012; Kaufmann et al. 2016)."
    }, {
      "heading" : "3 ASP-DPOP",
      "text" : "ASP-DPOP is a framework that uses logic programming to capture the structure of DCOPs, and to emulate the computation and communication operations of DPOP. In particular, each agent in a DCOP is represented by a separate ASP program—effectively enabling the infusion of a knowledge representation framework in the DCOP paradigm.\nThe overall communication infrastructure required by the distributed computation of DPOP is expressed using a subset of the SICStus Prolog language (Carlsson, M. et al. 2015), extended with multi-threading and the Linda blackboard facilities. In ASP-DPOP, we use CLASP (Gebser et al. 2007), with its companion grounder GRINGO, as our ASP solver, being the current state-of-the-art for ASP. In this section, we will describe the structure of ASP-DPOP and its implementation."
    }, {
      "heading" : "3.1 The architecture of ASP-DPOP",
      "text" : "ASP-DPOP is an agent architecture that reflects the structure of DCOPs, where several agents reflect the computation and communication operations of DPOP. The internal structure of each ASP-DPOP agent, shown in Figure 3, is composed of two modules. The first\nmodule is the Specification Module (SM), that encloses an ASP program which captures a corresponding agent as specified in the DCOP—i.e., the agent’s name, the agent’s neighbors, the description of the variables owned by the agent, the description of the variables owned by the agent’s neighbors, and the description of the constraints whose scope include any of the variables owned by the agent.\nThe second module is the Controller Module (CM), encoded as a Prolog program. The CM instructs the agent to perform the communication operations of DPOP, such as cooperating with other agents to generate a pseudo-tree, waiting for UTIL messages from child agents, sending the UTIL message to the parent agent (if present), waiting for the VALUE message from the parent agent (if present), and sending the VALUE messages to the child agents.\nIn ASP-DPOP, each DCOP is represented by a set of ASP-DPOP agents; each agent is modeled by its knowledge bases, located at its SM and CM, and it interacts with other agents in accordance to the rules of its CM."
    }, {
      "heading" : "3.2 ASP-DPOP Implementation: Specification Module (SM)",
      "text" : "Let us describe how to capture the structure of a DCOP in the Specification Module of an ASP-DPOP agent using ASP. Let us consider a generic DCOPM = 〈X ,D,F ,A, α〉. We representM using a set of ASP-DPOP agents whose SMs are ASP programs {Πai | ai ∈ A}. We will show how to generate Πai for each agent ai. In the following, we say a and a′ in A are neighbors if there exists x and x′ in X such that α(x) = a, α(x′) = a′, and there is a f ∈ F such that {x, x′} ⊆ scp(f). Given a constraint f ∈ F , we say that f is owned by the agent ai if the scope of f contains some variables owned by the agent ai.4\nFor each variable xi ∈ X we define a collection L(xi) of ASP rules that includes:\n• A fact of the form\nvariable(xi)← (18)\nfor identifying the name of the variable; • For each d ∈ Di ∈ D, a fact of the form\nvalue(xi, d)← (19)\nfor identifying the possible values of xi. Alternatively, if the domainDi is an integer interval [lower bound . . . upper bound] we can use the additional facts of the form\nbegin(xi, lower bound)← (20) end(xi, upper bound)← (21)\nto facilitate the description of the domain Di. In such case, the value predicates similar to ones in (19) are achieved by the rule\nvalue(X,B..E) ← variable(X), begin(X,B), end(X,E) (22)\n4 The concept of ownership of a constraint is introduced to facilitate the representation of ASP-DPOP implementation. Intuitively, an agent should know about a constraint if the agent owns some variables that are in the scope of such constraint. Under this perspective, a constraint may be owned by several agents.\nIntuitively,B andE in (22) are variables that should be grounded with lower bound and upper bound from (20) - (21), respectively.\nFor each constraint fj ∈ F , where scp(fj) = {xj1 , . . . , xjkj }, we define a collection L(fj) of rules that includes:\n• A fact of the form\nconstraint(fj)← (23)\nfor identifying the name of the constraint; • For each variable x ∈ scp(fj), a fact of the form\nscope(fj , x)← (24)\nfor identifying the scope of the constraint; and • For each partial value assignment xfj for all variables in scp(fj), where vj1 , . . . , vjkj are the value assignments of the variables xj1 , . . . , xjkj , respectively, such that fj(xfj ) = u 6= −∞, a fact of the form\nfj(u, vj1 , . . . , vjkj )← (25)\nFor each partial value assignment xfj for all variables in scp(fj), where vj1 , . . . , vjkj are the value assignments of the variables xj1 , . . . , xjkj , respectively, such that fj(xfj ) = −∞, a fact of the form5\nfj(#inf , vj1 , . . . , vjkj )← (26)\nAlternatively, it is also possible to envision cases where the utility of a constraint is implicitly modeled by logic programming rules, as shown in the following example. It is important to mention that, considering a constraint fj ∈ F :\n(1) The order of variables (e.g., xj1 , . . . , xjkj ) in scp(fj), whose corresponding value assignments (e.g., vj1 , . . . , vjkj ) that appear in facts of the forms (25) and (26), needs to be consistent in all facts of the forms (25) and (26) that relate to the constraint fj ; and\n(2) The order of the facts of the form (24) that are added to L(fj) to identify the scope of the constraint fj needs to be consistent with the order of variables (e.g., xj1 , . . . , xjkj ) mentioned in (1).\nThese requirements (i.e., (1) and (2)) are critical, because they allow Controller Modules to understand which variables belong to what values that appear in the facts of the forms (25) and (26), when Controller Modules read L(fj). This is done because, in SICStus Prolog, the search rule is “search forward from the beginning of the program.” Therefore, the order of the predicates (i.e., facts) that are added to SICStus Prolog matters.\n5 #inf is a special constant representing the smallest possible value in ASP language.\nExample 9 Let us consider a constraint f whose scope is {x, x′}, and f specifies that the utility of value assignments x = v, x′ = v′ is v + v′. The facts of the form (25) for the constraint f can be modeled by the following rule\nf(V + V ′, V, V ′)← value(x, V ), value(x′, V ′) (27)\nFor each agent ai we define an ASP program Πai that includes:\n• A fact of the form\nagent(ai)← (28)\nfor identifying the name of the agent; • For each variable x ∈ X that is owned by the agent ai, a fact of the form\nowner(ai, x)← (29)\n• For each agent aj who is a neighbor of the agent ai, a fact of the form\nneighbor(aj)← (30)\n• For each variable x′ ∈ X that is owned by an agent aj who is a neighbor of the agent ai, a fact of the form\nowner(aj , x ′)← (31)\n• For each constraint fj ∈ F owned by the agent ai, the set of rules\nL(fj) (32)\n• For each variable x ∈ X that is in the scope of some constraints owned by the agent ai, the set of rules\nL(x) (33)"
    }, {
      "heading" : "3.3 ASP-DPOP Implementation: Encoding UTIL and VALUE Messages",
      "text" : "The ASP-DPOP framework emulates the computation and communication operations of DPOP, where each ASP-DPOP agent produces UTIL and VALUE messages, and forwards them to its parent and child agents, as DPOP does. In ASP-DPOP, UTIL and VALUE messages are encoded as ASP facts, as discussed in this subsection."
    }, {
      "heading" : "3.3.1 UTIL Messages",
      "text" : "In DPOP, each UTIL message sent from a child agent ai to its parent agent Pi is a matrix. In encoding a UTIL message in ASP-DPOP, we represent each cell of the matrix of the UTIL message, whose associated utility is not −∞, as an ASP atom of the form:\ntable max ai(u, vi1 , . . . , viki ) (34)\nwhich indicates that the optimal aggregate utility of the value assignments xi1 = vi1 , . . . , xiki = viki is u 6= −∞, where sepi = {xi1 , . . . , xiki}. In other words, the parent\nagent Pi knows that UTILPiai (xi1 = vi1 , . . . , xiki = viki ) = u 6= −∞ if it receives the fact table max ai(u, vi1 , . . . , viki ). It is important to know that the encoding of a UTIL message omits the cells whose associated utilities are −∞.\nIn addition to facts of the form (34), ai also informs Pi about variables in its separator. Thus, the encoding of the UTIL message sent from the agent ai to the agent Pi includes also atoms of the form:\ntable info(ai, ai1 , xi1 , lbi1 , ubi1) (35)\n· · · table info(ai, aiki , xiki , lbikiubiki ) (36)\nEach fact table info(ai, ait , xit , lbit , ubit) informs Pi that xit is a variable in the separator of ai whose domain is specified by lbit (lower bound) and ubit (upper bound) and whose owner is ait .\n6 It is also critical to note that the order of the atoms of the forms (35) - (36) matters, since such order will allow the respective Controller Module understand which variable belongs to the values stated in facts of the form (34) after reading such encoded UTIL messages.\nExample 10 Consider again the DCOP in Example 1. The UTIL message, sent from the agent a3 to the agent a2, in Table 1(a) is encoded as the set of the ASP atoms:\ntable max a3(16, 0, 0) (37)\ntable max a3(25, 0, 1) (38)\ntable max a3(25, 1, 0) (39)\ntable max a3(40, 1, 1) (40)\ntable info(a3, a1, x1, 0, 1) (41)\ntable info(a3, a2, x2, 0, 1) (42)\nExample 11 Similarly, considering again the DCOP in Example 1, the UTIL message sent from the agent a2 to the agent a1 in Table 1(b) is encoded as the set of ASP facts:\ntable max a2(33, 0) (43)\ntable max a2(45, 1) (44)\ntable info(a2, a1, x1, 0, 1) (45)"
    }, {
      "heading" : "3.3.2 VALUE Messages",
      "text" : "In DPOP, each VALUE message sent from a parent agent Pi to its child agents ai contains the optimal value assignment for variables owned by either the parent agent or the pseudoparent agents of the agent ai. Thus, in encoding a VALUE message, we use atoms of the\n6 For simplicity, we assume that the domains Di are integer intervals.\nform:\nsolution(a, x, v) (46)\nwhere v is the value assignment of the variable x owned by the agent a for an optimal solution.\nExample 12\nConsider again the DCOP in Example 1. The VALUE message sent from the agent a1 to the agent a2 is encoded as the ASP atom:\nsolution(a1, x1, 1) (47)\nSimilarly, the VALUE message sent from the agent a2 to the agent a3 is encoded as the set of the ASP atoms:\nsolution(a1, x1, 1) (48)\nsolution(a2, x2, 0) (49)"
    }, {
      "heading" : "3.4 ASP-DPOP Implementation: Controller Module (CM)",
      "text" : "The controller module in each ASP-DPOP agent ai, denoted by Cai , consists of a set of Prolog rules for communication (sending, receiving, and interpreting messages) and a set of rules for generating an ASP program that is used for the computations of a UTIL message and a VALUE message. In this subsection, we would like to discuss some code\nfragments to show how Cai is structured. 7 To begin with, we will show how Cai uses the Linda blackboard library of Prolog to exchange the messages. There are three types of messages exchanged through the Linda blackboard; they are tree, util, and value messages that are used in Phase 1, Phase 2, and Phase 3, respectively, of DPOP. For sending (resp. waiting for) a message, we use the built-in predicate out/1 (resp. in/1) provided by the Linda library of Prolog. Every message is formatted as message(From, To, Type,Data) where the arguments denote the agent who sends this message, the agent who should receive this message, the type of the message, and the data enclosed in the message, respectively. The implementation of the communication and the three phases of DPOP are described next."
    }, {
      "heading" : "3.4.1 Sending Messages",
      "text" : "The following Prolog rule generates a message of type t ∈ {tree, util, value}, with content d (Content), to be sent from an agent ai (From) to an agent ak (To):\n% sending message send_message(From,To,Type,Content) :-\nout(message(From,To,Type,Content))."
    }, {
      "heading" : "3.4.2 Waiting for Messages",
      "text" : "The following Prolog rule instructs agent ak (a k) to wait for a message:\n% waiting for a message wait_message(From,a_k,Type,Data):- in(message(From,a_k,Type,Data)).\nwhere From, Type, and Data will be unified with the name of the agent who sent this message, the type of the message, and the data enclosed in the message, respectively."
    }, {
      "heading" : "3.4.3 Creating the Pseudo-Tree: Phase 1",
      "text" : "In this phase, ASP-DPOP agents cooperate with each other to construct a pseudo-tree. For simplicity, we will show here the clauses in Cai for generating a pseudo-tree by initiating a DFS-traversal. We assume that the agent ai is not the root of the pseudo-tree. The agent ai waits for a tree message from an agent Parent. The content (Data) enclosed in such a tree message is the set of visited agents—i.e., the agents who have already started performing the DFS. Upon receiving a treemessage, ai will execute the following clauses:\n% pseudo-tree generation generate_tree(Parent, Data):-\nassign_parent(Parent), assign_pseudo_parent(Data), append(Data, [a_i], NewData), depth_first_search(Parent, NewData).\n7 The code listed in this section is a simplified version of the actual code for Cai , showing a condensed version of the clause bodies; however, it still gives a flavor of the implementation of Cai and should be sufficiently explanatory for the purpose of the controller module.\n% performing depth first search depth_first_search(Parent, Data):-\nfind_next(Data, Next_Agent), (Next_Agent == none ->\nsend_message(a_i, Parent, tree, Data) ; assign_child(Next_Agent), send_message(a_i, Next_Agent, tree, Data), wait_message(Next_Agent, a_i, tree, NewData), depth_first_search(Parent, NewData)\n).\nIntuitively, upon receiving a tree message from the agent Parent enclosed with data Data, the agent ai will execute the clause generate tree(Parent, Data). Specifically:\n• It executes the clause assign parent/1, where it adds to its Πai a fact of the form parent(Parent); • It executes the clause assign pseudo parent/1 which adds to its Πai facts of the form pseudo parent(X), where X is a neighboring agent of ai that appears in Data such that X 6= Parent; • It adds itself (i.e., a i) to the list of visited agents; • It starts performing a DFS, by executing the rule depth first search/2.\nIn order to perform a DFS, the agent ai will execute the rule find next/2 to select a neighboring agent that will be visited next; this selection is based on some heuristics (i.e., the unvisited neighbor agent with the greatest number of neighbors). If such an agent Next Agent exists (i.e., Next Agent 6= none), then ai will:\n• Execute the rule assign child/1, used to add to its Πai a fact of the form children(Next Agent); • Send a tree message to the agent Next Agent; • Wait for the reply message from the agent Next Agent, which will provide the\nupdated list NewData of visited agents; • Recursively execute the rule depth first search/2.\nOtherwise, if there is no agent Next Agent (i.e., Next Agent is equal to none), then the agent ai will reply a tree message to its agent Parent. This implies that the agent ai has finished performing DFS at its branch.\nWhen the agent ai is chosen to be the root of the pseudo-tree, it executes the rule generate tree(master, [ ]) immediately without waiting for the tree message from other agents. We note that an agent whose parent agent is master will be the root of the pseudo-tree. It is also worth to notice that, at the end of this phase, the information about the parent, pseudo-parents, and child agents of each agent ai are added to Πai via facts of the forms parent/1, pseudo parent/1, and children/1, respectively.\nLemma 1 In ASP-DPOP, Phase 1 requires a linear number of messages in n where n is the number of agents.\nProof We first prove that Phase 1 terminates. In fact, each agent ai in executing depth first search/2 will perform the rule find next/2 to select a neighboring agent, i.e., Next Agent, that is not in the set of visited agents to send a tree message to. Next Agent can be seen as an unvisited neighboring agent of the agent ai.\nThe agent ai then waits to receive the tree message from Next Agent enclosing an updated set of visited agents, and again send a tree message to another unvisited neighboring agent if it exists. We notice that the updated set of visited agents will be expanded with at least one agent that is Next Agent since Next Agent will add itself to the set of visited agents beyond receiving the tree message from the agent ai.\nTherefore, every agent ai will send at most |N(ai)| tree messages to its child agents, where N(ai) is the set of the neighboring agents of the agent ai. If there is no unvisited neighboring agent left, the agent ai will send a tree message to its parent agent together with the most updated set of visited agents, and terminates executing depth first search/2. Thus, it terminates performing the clause generate tree(Parent, Data). As a consequence, we can conclude that Phase 1 terminates.\nFurthermore, considering a pseudo-tree that is generated at the end of Phase 1. We can realize that the set of visited agents which are passing among agents is expanded with a non-root agent if and only if there is a tree message sent from a parent agent to its child agent downward the pseudo-tree. It is worth to remind that the agent who is selected to be the root of the pseudo-tree adds itself to the set of visited agents at the beginning. Thus, there are n − 1 tree messages that are sent downward the pseudo-tree. Moreover, every agent except the root agent will send exactly one tree message to its parent agent upward the pseudo-tree. Therefore, there are n− 1 tree messages that are sent upward the pseudotree. Accordingly, in total there are 2 × (n − 1) tree messages produced in Phase 1. This proves Lemma 1."
    }, {
      "heading" : "3.4.4 Computing the UTIL Message: Phase 2",
      "text" : "In the following, for simplicity, given an agent ai, we assume that ap = Pi. We will use ap and Pi interchangeably. In this phase, each ASP-DPOP agent generates an ASP program for computing the UTIL message that will be sent to its parent. In more detail, each agent ai executes the following clause:\n% Phase 2: UTIL Propagation Phase perform_Phase_2(ReceivedUTILMessages):-\ncompute_separator(ReceivedUTILMessages, Separator), assert(separatorlist(Separator)), compute_related_constraints(ConstraintList), assert(constraintlist(ConstraintList)), generate_UTIL_ASP(Separator, ConstraintList), solve_answer_set1(ReceivedUTILMessages, Answer), store(Answer), send_message(a_i, a_p, util, Answer).\nIn particular, each agent ai with a set of child agents Ci:\n• Waits to receive all of the UTIL messages from its children and combines them into a set of ASP facts. Let Mak be the encoding of the UTIL message UTIL ai ak\n. We define a list ReceivedUTILMessages as follows.\nReceivedUTILMessages = ⋃ a∈Ci Ma. (50)\nWhen ai is a leaf (Ci = ∅), we set ReceivedUTILMessages = [ ]. • Computes its separator sepi by executing compute separator/2. This is real-\nized using (i) the information about its parent and pseudo-parent agents added in Πai during Phase 1, and (ii) the information about ancestors of the agent ai that are directly connected with descendants of the agent ai, via facts of the form table info, contained in the UTIL messages received from its child agents; • Computes the set Rai (ConstraintList) of the related constraints (i.e., executing compute related constraints/1) that is defined as (5). • Generates the information for its UTIL message (i.e., executing generate UTIL ASP/2). Specifically, generate UTIL ASP/2 first creates a logic program, denoted by Iai , from the separator list, the constraint list, and the information from Mak where ak ∈ Ci. It then computes the answer set of Πai ∪ Iai ∪ ( ⋃ a∈Ci Ma) which contains the encoded UTIL message of the agent\nai. Assume that\n— sepi = {xs1 , . . . , xsk} (i.e., Separator = [xs1 , . . . , xsk ] is the separator list of ai); — Rai = {fr1 , . . . , frk′} and scp(frj ) = {xrj1 , . . . , xrjw } for 1 ≤ j ≤ k ′ (i.e.,\nConstraintList = [fr1 , . . . , frk′ ]); — Ci = {ac1 , . . . , acl} and each UTILaiact has xct1 , . . . , xctz as its dimensions\nfor 1 ≤ t ≤ l; and — ap is the parent agent of the agent ai.\ngenerate UTIL ASP/2 creates Iai with the following rules:\ntable row ai(U,Xs1 , . . . , Xsk )← fr1(Vr1 , Xr11 , . . . , Xr1w ),\n· · · frk′ (Vrk′ , Xrk′1 , . . . , Xrk′w ), Vr1 != #inf, · · · , Vrk′ != #inf, table max ac1(Uc1 , Xc11 , . . . , Xc1z ), · · · table max acl(Ucl , Xcl1 , . . . , Xclz ), U = Vr1 + · · ·+ Vrk′ + Uc1 + · · ·+ Ucl .\n(51)\ntable max ai(U,Xs1 , . . . , Xsk )← value(xs1 , Xs1), · · · value(xsk , Xsk ), table row ai( , Xs1 , . . . , Xsk ), U = #max{V : table row ai(V,Xs1 , . . . , Xsk )}.\n(52)\ntable info(ai, as1 , xs1 , lbs1 , ubs1). · · · table info(ai, ask , xsk , lbsk , ubsk ).\n(53)\ngenerate UTIL ASP/2 uses the information in UTILaiact and Πai to generate the facts (53). In addition, each variable in the rules (51)-(53) corresponds to a variable name (e.g., Xs1 corresponds to xs1 in the separator list; Xc11 corresponds to xc11 in dimensions of UTILaiac1 ; etc.). Therefore, due to the definition of the separator of ai and sepi = {xs1 , . . . , xsk}, Xs1 , . . . , Xsk are guaranteed to occur on the right hand side of (51). In other words, Iai is a safe program. Intuitively, the rule of the form (51) creates the joint table for ai—that is similar to the result of flattening ( ⊕act∈Ci UTIL ai act ) ⊕ ( ⊕f∈Rai f ) into a table— given\nUTILaiact and Rai . In addition, (52) computes the optimal utilities for each value combination of variables in the separator list. • Computes an answer set A of the program Πai ∪ Iai ∪ ⋃ a∈Ci Ma by executing\nsolve answer set1/2, and extracts from A the information for the UTIL message (i.e., Answer) that will be sent from the agent ai to the agent ap. • Asserts the information in Answer for later use in Phase 3 (i.e., executes store(Answer)). • Sends encoded UTILapai to the parent agent ap (i.e., executes send message/4).\nExample 13 As an example, we refer to the DCOP in Example 1. Specifically, we illustrate Ia2 generated by the agent a2. ReceivedUTILMessages for the agent a2 is the set of ASP facts given in Example 10, Separator = [x1], and ConstraintList = [x1 cons x2]. The program Ia2 includes the following rules:\ntable row a2(U,X1) ← x1 cons x2(V0, X1, X2), V0 != #inf ,\ntable max a3(V1, X1, X2),\nU = V0 + V1.\ntable max a2(U,X1) ← value(x1, X1), table row a2( , X1)\nU = #max{V : table row a2(V,X1)}. table info(a2, a1, x1, 0, 1) ←\nThe relationship between the ASP-based computation and Algorithm 1 is established in the following lemma.\nLemma 2 Let us consider a DCOPM, an agent ai ∈ A, and a pseudo-tree T . Let ai be an agent with Ci = {ac1 , . . . , acl} and Mact be the encoded UTIL ai act\nfor 1 ≤ t ≤ l. Furthermore, let us assume that ap is the parent of ai, sepi = {xs1 , . . . xsk}, and Rai = {fr1 , . . . , fr′k} and\nscp(frj ) = {xrj1 , . . . , xrjw } for 1 ≤ j ≤ k ′. Then, the program Πai ∪ Iai ∪ ( ⋃ a∈Ci Ma) has a unique answer set A and\n• table row ai(u, vs1 , . . . , vsk) ∈ A iff there exists a value combinationX for variables in scp(JOINPiai ) such that JOIN Pi ai (X) = u where {xs1 = vs1 , . . . , xsk =\nvsk} ⊆ X and u 6= −∞; and • table max ai(u, vs1 , . . . , vsk) ∈ A iff UTILPiai (xs1 = vs1 , . . . , xsk = vsk) = u\nand u 6= −∞.\nProof Since Iai is safe and Πai ∪ Iai ∪ ( ⋃ a∈Ci Ma) is a positive program, it has a unique answer set. By the definition of answer set, table row ai(u, vs1 , . . . , vsk) ∈ A iff that there exists a rule r of the form (51) such that table row ai(u, vs1 , . . . , vsk) is the head of r. It means that there exists a value assignment Y for the variables occurring in r such that the following conditions hold:\n• {xs1 = vs1 , . . . , xsk = vsk} ⊆ Y ; • for each 1 ≤ j ≤ k′, there exists vrj 6= #inf such that frj (vrj1 , . . . , vrjw ) = vrj and {xrj1 = vrj1 , . . . , xrjw = vrjw } ⊆ Y ; and • for each 1 ≤ t ≤ l, there exists uct such that table max act(uct , vct1 , . . . , vctz ) ∈ A and {xct1 = vct1 , . . . , xctz = vctz } ⊆ Y . By the construction of the algorithm, table max act(uct , vct1 , . . . , vctz ) ∈ A implies that UTIL ai act (xct1 = vct1 , . . . , xctz =\nvctz ) = uct and uct 6= −∞.\nThe conclusion of the first item follows directly from the definitions of the UTIL message and the ⊕ operator (Definitions 3-4) and the above conditions.\nThe second item of the lemma follows from the first item, the condition Vr1 != #inf , · · · , Vrk′ != #inf in the rule (51), and Definition 5.\nLemma 2 implies that Phase 2 of ASP-DPOP computes the same UTIL messages as DPOP, except that UTIL messages in ASP-DPOP omit the value assignments whose associated utilities are −∞."
    }, {
      "heading" : "3.4.5 Computing the VALUE Message: Phase 3",
      "text" : "Each ASP-DPOP agent computes the optimal value for its variables and sends an encoded VALUE message to its children. The process is described by the following Prolog rule:\n% Phase 3: VALUE Propagation Phase perform_Phase_3(ReceivedVALUEMessage):-\nseparatorlist(Separator), constraintlist(ConstraintList), generate_VALUE_ASP(Separator,ConstraintList), solve_answer_set2(ReceivedVALUEMessage, Answer), send_message_to_children(a_i, value, Answer).\nIn particular, the agent ai:\n• Waits to receive the encoded VALUE message, denoted by M ′Pi , from its parent agent Pi. If the agent ai does not have a parent, i.e., it is the root of the tree, we set ReceivedVALUEMessage = [ ]; • Retrieves sepi (i.e., Separator) computed in Phase 2; • Retrieves Rai (i.e., ConstraintList) computed in Phase 2; • Executes the rule generate VALUE ASP/2 to create an ASP program, denoted by I ′ai , from the separator list, the constraint list, and the information from Mak where ak ∈ Ci from Phase 2. Assume that\n— sepi = {xs1 , . . . , xsk} (i.e., Separator = [xs1 , . . . , xsk ] is the separator list of ai); — Rai = {fr1 , . . . , frk′} and scp(frj ) = {xrj1 , . . . , xrjw } for 1 ≤ j ≤ k ′ (i.e.,\nConstraintList = [fr1 , . . . , frk′ ]); — Ci = {ac1 , . . . , acl} and each UTILaiact has xct1 , . . . , xctz as its dimensions\nfor 1 ≤ t ≤ l; and — The set of variables owned by the agent ai is αi = {xi1 , . . . , xiq}.\ngenerate VALUE ASP/2 creates the logic program I ′ai with following rules:\n{row(U,Xi1 , . . . , Xiq )} ← solution(α(xs1), xs1 , Xs1), · · · solution(α(xsk ), xsk , Xsk ), table max ai(U,Xs1 , . . . Xsk ), fr1(Vr1 , Xr11 , . . . , Xr1w ),\n· · · frk′ (Vrk′ , Xrk′1 , . . . , Xrk′w ), table max ac1(Uc1 , Xc11 , . . . , Xc1z ), · · · table max acl(Ucl , Xcl1 , . . . , Xclz ), U == Vr1 + · · ·+ Vrk′ + Uc1 + · · ·+ Ucl .\n(54)\n← not 1{row(U,Xi1 , . . . , Xiq )}1. (55)\nsolution(ai, xi1 , Xi1) ← row(U,Xi1 , . . . , Xiq ). · · ·\nsolution(ai, xiq , Xiq ) ← row(U,Xi1 , . . . , Xiq ). (56)\nIntuitively, the rule of the form (54) and the constraint of the form (55) select an optimal row based on: (i) The computation as done in Phase 2 (i.e., using the facts of the form table max ai that are stored in Phase 2), and (ii) (for non-root agent only) the VALUE message that is received from its parent (i.e., facts of the form solution/3). The selected optimal row will define the optimal value of the variables using rules of the form (56). Similar argument for the safety of Iai allows us to conclude that I ′ai is also a safe program. • Executes solve answer set2/2, that executes the ASP solver to compute an\nanswer set of the program Πai ∪ I ′ai ∪M ′ Pi ∪ ( ⋃ a∈Ci Ma). From that answer set,\nit collects all facts of the form solution(a, x, v) and returns them as Answer—i.e., the encoding of the VALUE message from the agent ai to its child agents; • Executes send message to children/3 where it sends value message with Answer as its data to each child agent (i.e., executing the respected clauses send message/4 multiple times).\nExample 14 As an example, we refer to the DCOP in Example 1 to illustrate I ′a2 generated by the agent a2.ReceivedUTILMessages for the agent a2 is the set of ASP facts given in Example 10, Separator = [x1], ConstraintList = [x1 cons x2], and α2 = {x2}. The program I ′a2 includes following rules:\n{row(U,X2)} ← solution(a1, x1, X1), table max a2(U,X1),\nx1 cons x2(U0, X1, X2),\ntable max a3(U1, X1, X2)\nU == U0 + U1.\n← not 1{row(U,X2)}1. solution(a2, x2, X2) ← row(U,X2).\nLemma 3 Let us consider a DCOPM, and an agent ai ∈ A in a pseudo-tree T . Let ai be an agent with Ci = {ac1 , . . . , acl} and Mact be the encoding of UTIL ai act\nfor 1 ≤ t ≤ l. Furthermore, assume that Pi is the parent agent of the agent ai, sepi = {xs1 , . . . xsk}, Rai = {fr1 , . . . , fr′k} where scp(frj ) = {xrj1 , . . . , xrjw } for 1 ≤ j ≤ k\n′, αi = {xi1 , . . . , xiq}, and M ′Pi encodes VALUE ai Pi . Let Q = Πai ∪ I ′ai ∪M ′ Pi ∪ ( ⋃ a∈Ci Ma)). Then,\n• For each answer set A of Q, the assignment xij = vij where solution(ai, xij , vij ) ∈ A for 1 ≤ j ≤ q belongs to a solution of M; and • if xi1 = vi1 , . . . , xiq = viq is a value assignment for variables in αi that belongs to a solution ofM, which contains V ALUEaiPi , then Q has an answer set A containing {solution(ai, xij , vij ) | 1 ≤ j ≤ q} ∪M ′i .\nProof Based on the construction of I ′ai , it is possible to see that there exists at least one rule of the form (54) in Q. Observe that if the agent ai is the root of the pseudo-tree T . Then, M ′Pi = ∅ and the rule (54) does not contain the atom of the form solution(a, x, v). Since the program is safe and positive, we have that Q is consistent.\nBecause of the rule (55), each answer set A of Q contains exactly one atom of the form row(u, vi1 , . . . , viq ). Also, from the rule (54), we have that if row(u, vi1 , . . . , viq ) ∈ A then there exists some table max ai(u, vs1 , . . . , vsk) ∈ A which indicates that u is the optimal utility corresponding to the assignment xsi = vsi for 1 ≤ i ≤ k (Lemma 2). From the correctness of DPOP, this means that row(u, vi1 , . . . , viq ) encodes an optimal value assignment for variables owned by the agent ai. This proves the first item.\nAssume that xi1 = vi1 , . . . , xiq = viq is a value assignment for variables in αi that belongs to a solution of M, which contains V ALUEaiPi . Then, by the completeness of DPOP and Lemma 2, this implies that there exists some table max ai(u, vs1 , . . . , vsk) such that V ALUEaiPi contains xsi = vsi for 1 ≤ i ≤ k. As such, there must exist the values for frj (.) and table max act(.) such that there is a rule of the form (54) whose head is row(u, vi1 , . . . , viq ). This means thatQ has an answer set containing row(u, vi1 , . . . , viq ), which proves the second item of the lemma."
    }, {
      "heading" : "3.4.6 ASP-DPOP",
      "text" : "In this section, we will show the clause for ASP-DPOP agents to perform Phase 1, Phase 2, and Phase 3 consecutively. For simplicity, we omit the fragment of code of ASP-DPOP agents that allow them to cooperate with each other to select one agent as the root of the pseudo-tree—since it depends on the scores that are assigned to agents, according to a heuristic function.\nLet us remind that, if an agent ak is the root of the pseudo-tree, a fact of the form parent(master, a k) will be added to Πak . After an agent is selected as the root of the pseudo-tree, each agent will execute the clause start. Considering an agent ai, the clause start of the agent ai is described as follows:\n% Perform Phase 1, Phase 2, and Phase 3 start:-\n(parent(master, a_i) -> generate_tree(master, []) ; wait_message(Parent, a_i, tree, Data), generate_tree(Parent, Data) ), (children(_) ->\nget_UTILMessages_from_all_children(ReceivedUTILMessages), perform_Phase_2(ReceivedUTILMessages) ; perform_Phase_2([])\n), (parent(master, a_i) ->\nperform_Phase_3([]) ; wait_message(Parent, a_i, value, ReceivedVALUEMessage), perform_Phase_3(ReceivedVALUEMessage)\n).\nIn particular, each agent ai:\n• Checks whether ai is the root of the pseudo-tree; this is realized by checking whether the fact of the form parent(master, a i) is in Πai :\n— If the agent ai is the root of the pseudo-tree, it will execute generate tree(master, [ ]) that is defined in Section 3.4.3; otherwise, — If the agent ai is not the root of the pseudo-tree, it will execute\nwait message(Parent, a i, tree,Data). Upon receiving the tree message from the agent Parent who is later assigned as its parent agent, the agent ai will execute generate tree(Parent,Data) that is defined in Section 3.4.3.\n• Checks whether the agent ai is (resp. is not) a leaf of the pseudo-tree (i.e., this is realized by checking whether the fact of the form children/1 is not (resp. is) in Πai , respectively):\n— If the agent ai is not a leaf of the pseudo-tree, it executes get UTILMessages from all children(ReceivedUTILMessages). Intuitively, the clause get UTILMessages from all children/1 iteratively executes wait message(From, a i, util,Data) until the agent ai receives all utilmessages from all of its child agents. The contents (i.e.,Data) of all util messages are combined into ReceivedUTILMessages. Then the agent ai executes perform Phase 2(ReceivedUTILMessages) that is defined in Section 3.4.4; otherwise, — If the agent ai is a leaf of the pseudo-tree, it executes perform Phase 2([]) that is defined in Section 3.4.4.\n• Checks whether the agent ai is the root of the pseudo-tree or not:\n— If the agent ai is the root of the pseudo-tree, it executes perform Phase 3([]) that is defined in Section 3.4.5; otherwise, — If the agent ai is not the root of the pseudo-tree, it executes wait message(Parent, a i, value,ReceivedVALUEMessage) to wait for value message from its parent agent. Then the agent ai executes perform Phase 3(ReceivedVALUEMessage) that is defined in Section 3.4.5."
    }, {
      "heading" : "4 Theoretical Analysis",
      "text" : "In this section, we present some theoretical properties of ASP-DPOP including its soundness, completeness, and complexity."
    }, {
      "heading" : "4.1 Soundness and Completeness",
      "text" : "The soundness and completeness of ASP-DPOP follow from Lemmas (2)–(3) and the soundness and completeness of DPOP.\nProposition 1 ASP-DPOP is sound and complete in solving DCOPs.\nProof Let us summarize how ASP-DPOP solves a DCOPM:\n• In Phase 1, each ASP-DPOP agent runs distributed DFS to generate a pseudotree. At the end of this phase, the information about the parent, pseudo-parents, and child agents of each agent ai are added to Πai via facts of the forms parent/1, pseudo parent/1 and children/1, respectively;\n• In Phase 2, each ASP-DPOP agent ai: (i) waits to receive the encoding of UTIL messages from all of its child agents (for non-leaf agents only), and (ii) generates the ASP program Iai to compute its encoded UTIL message as an answer set of Πai ∪ Iai ∪ReceivedUTILMessages; • In Phase 3, each ASP-DPOP agent ai: (i) waits to receive the encoded VALUE message from its parent agent (for non-root agent only), and (ii) generates the ASP program I ′ai to compute its encoded VALUE message as an answer set of Πai ∪ I ′ ai ∪M ′ Pi ∪\nReceivedUTILMessages;\nThe soundness and completeness of ASP-DPOP follows from the soundness and completeness of DPOP and the following observations:\n• Phase 1 of ASP-DPOP generates a possible pseudo-tree ofM. • Assuming that ASP-DPOP and DPOP use the same pseudo-tree T then:\n− Phase 2 of ASP-DPOP computes the same UTIL messages as DPOP except that they omit the value assignments whose associated utilities are−∞ (Lemma 2). However, for DPOP, ignoring those value assignments in UTIL message will not affect DCOP solution since such value assignments are not included in any solution (i.e., otherwise the total utility is −∞). − Phase 3 of ASP-DPOP computes all possible solutions (VALUE messages) as\nDPOP (Lemma 3)."
    }, {
      "heading" : "4.2 Complexity",
      "text" : "Given d = max1≤i≤n |Di| and w∗ = max1≤i≤n |sepi| where n is the number of agents,8 we have the following properties:\nProperty 1 The number of messages required by ASP-DPOP is bounded by O(n).\nProof In ASP-DPOP, one can observe that: (1) Phase 1 requires a linear number of messages in n (Lemma 1); (2) Phase 2 requires (n− 1) UTIL messages; and (3) Phase 3 requires (n− 1) VALUE messages. Thus, the number of messages required by ASP-DPOP is bounded by O(n).\nProperty 2 The size of messages required by ASP-DPOP is bounded by O(dw∗).\n8 w∗ is also known as the induced width of a pseudo-tree (Dechter 2003).\nProof In ASP-DPOP, • Phase 1 produces messages whose size is linear in n. This is because the tree mes-\nsage is of the form send message(a i,Next Agent, tree,Data) where the content (Data) that dominates the size of the tree message is the set of visited agents whose size is linear in n; • Phase 2 produces encoded UTIL messages; each message consists of: (i) a fact of the\nform table max ai for each cell in the corresponding UTIL message in DPOP where its associated optimal utility is not −∞, and (ii) |sepi| facts of the form table info. Therefore, the size of encoded UTIL messages is bounded by O(dw∗) as the bounded size of UTIL messages in DPOP (Petcu and Faltings 2005a); and • Phase 3 produces encoded VALUE messages; each message consists of a fact of\nthe form solution/3 for each value assignment of a variable in the corresponding VALUE message in DPOP. Therefore, Phase 3 produces encoded VALUE messages whose sizes are bounded by O(|X |) = O(n) as we assume each agent owns exactly one variable.\nThus, the size of messages required by ASP-DPOP is bounded by O(dw∗)\nProperty 3 The memory requirements in ASP-DPOP are exponential and bounded by O(dw∗).\nProof In ASP-DPOP: • In Phase 1, the memory requirements are bounded by O(n) because it needs to keep track of the set of visited agents and the set of its neighboring agents; • In Phase 2, the memory requirements are bounded by O(dw∗) since, in computing the answer set of P = Πai ∪ Iai ∪ ReceivedUTILMessages, the ASP solver needs to ground all the rules of the forms (51) and (52), and these dominate the number of other facts or ground instances of other rules in P ; • In Phase 3, the memory requirements are bounded by O(dw∗) since, in computing the answer set of P ′ = Πai ∪ I ′ai ∪ M ′ Pi ∪ ReceivedUTILMessages, the ASP solver\nneeds to ground all rules of the form (54), where the number of facts of the form table max ai is bounded by O(dw ∗ ) (see Property 2). Moreover, the number of such ground instances dominates the number of other facts and ground instances of other rules in P ′.\nThus, the memory requirement in ASP-DPOP is exponential and bounded byO(dw∗)."
    }, {
      "heading" : "5 Experimental Results",
      "text" : "The goal of this section is to provide an experimental evaluation of ASP-DPOP. In particular, we compare ASP-DPOP against the original DPOP as well as other three implementations of complete DCOP solvers: Asynchronous Forward-Bounding (AFB), Hard Constraint-DPOP (H-DPOP), and Open-DPOP (ODPOP). AFB (Gershman et al. 2009) is a complete search-based algorithm to solve DCOPs. H-DPOP (Kumar et al. 2008) is a complete DCOP solver that, in addition, propagates hard constraints to prune the search space.\nODPOP (Petcu and Faltings 2006) is an optimization algorithm for DCOPs, which combines some advantages of both search-based algorithms and dynamic-programming-based algorithms. For completeness of the paper, in this section, we will first provide some background about these three solvers, discuss about FRODO platform (Léauté et al. 2009)—a publicly-available implementation of DPOP, AFB, and ODPOP—and then provide some experimental results."
    }, {
      "heading" : "5.1 Background on AFB",
      "text" : "The asynchronous forward-bounding algorithm (AFB) (Gershman et al. 2009), to the best of our knowledge, is the most recent complete search-based algorithm to solve DCOPs. AFB makes use of a Branch and Bound scheme to identify a complete value assignment that minimizes the aggregate utility of all constraints. To do so, agents expand a partial value assignment as long as the lower bound on its aggregate utility does not exceed the global bound, which is the aggregate utility of the best complete value assignment found so far.\nIn AFB, the state of the search process is represented by a data structure called Current Partial Assignment (CPA). The CPA starts empty at some initializing agent, which records the value assignment of its own variable and sends the CPA to the next agent. The aggregate utility of a CPA is the accumulated utility of constraints involving the value assignment it contains. Each agent, upon receiving a CPA, adds a value assignment of its own variable such that the CPA’s aggregate utility will not exceed the global upper bound. If it cannot find such an assignment, it backtracks by sending the CPA to the last assigning agent, requesting that agent to revise its value assignment.\nAgents in AFB process and communicate CPAs asynchronously. An agent that succeeds to expand the value assignment of the received CPA sends forward copies of the updated CPA, requesting all unassigned agents to compute lower bound estimates of the aggregate utility of the current CPA. The assigning agent will receive these estimates asynchronously over time, and use them to update the lower bound of the CPA. Using these bounds, the assigning agent can detect if any expansion of this partial value assignment in the current CPA will cause it to exceed the global upper bound, and in such cases it will backtrack. Additionally, a time stamp mechanism for forward checking is used by agents to determine the most updated CPA and to discard obsolete CPAs."
    }, {
      "heading" : "5.2 Background on H-DPOP",
      "text" : "In H-DPOP (Kumar et al. 2008), the authors consider how to leverage the hard constraints that may exist in the problem in a dynamic programming framework, so that only feasible partial assignments are computed, transmitted, and stored (Kumar et al. 2008). To this end, they encode combinations of assignments using Constrained Decision Diagrams (CDDs). Basically, CDDs eliminate all inconsistent assignments and only include utilities corresponding to value combinations that are consistent. The resulting algorithm, H-DPOP, a hybrid algorithm that is based on DPOP, uses CDDs to rule out infeasible assignments, and thus compactly represents UTIL messages.\nA CDD G = 〈Γ, G〉 encodes the consistent assignments for a set of constraints Γ in a\nrooted direct acyclic graph G = (V,E) by means of constraint propagation. A node in G is called a CDD node. The terminal nodes are either true or false implying consistent or inconsistent assignment, respectively. By default, a CDD represents consistent assignments omitting the false terminal.\nThe H-DPOP algorithm leverages the pruning power of hard constraints by using CDDs to effectively reduce the message size. As in DPOP, H-DPOP has three phases: the pseudotree construction, the bottom-up UTIL propagation, and top-down VALUE propagation. The pseudo-tree construction and VALUE propagation phases are identical to ones of DPOP. In the UTIL propagation phase, the UTIL message, instead of being a multidimensional matrix, is a CDDMessage.\nDefinition 6 A CDDMessage M ji sent by an agent ai to agent aj is a tuple 〈~u,G〉 where ~u is a vector of utilities, and G is a CDD defined over variables in sepi. The set of constraints for G is Γ = {fj | scp(fj) ⊆ sepi}.\nIn the UTIL propagation phase, H-DPOP defines different JOIN and PROJECTION operations. Observe that, based on Definition 6, an H-DPOP agent ai can access a constraint whose scope is a subset of its separator, but that is not owned by ai itself. For example, considering the DCOP in Example 1, in H-DPOP, the UTIL message sent from the agent a3 to the agent a2 will have information about the constraint x1 cons x2 that is not owned by the agent a3 since scp(x1 cons x2) = {x1, x2} ⊆ sep3. This might be undesirable in situations where distribution of the computation is tied to privacy of information."
    }, {
      "heading" : "5.3 Background on ODPOP",
      "text" : "ODPOP (Petcu and Faltings 2006) is an optimization algorithm for DCOP, which combines some advantages of both search-based algorithms and dynamic-programming-based algorithms. ODPOP always uses linear size messages, which is similar to search, and typically generates as few messages as DPOP. It does not always incur the worst complexity which is the same with the complexity of DPOP, and on average it saves a significant amount of computation and information exchange. This is achieved because agents in ODPOP use a best-first order for value exploration and an optimality criterion that allows them to prove optimality without exploring all value assignments for variables in their separator. ODPOP also has 3 phases as DPOP:\nPhase 1 (DFS traversal) is the same with Phase 1 in DPOP to construct a pseudo-tree. Phase 2 (ASK/GOOD) is an iterative, bottom-up utility propagation process where each agent repeatedly sends ASK messages to its child agents, asking for valuations (GOODs), until it is able to compute the suggested optimal value assignment (GOOD) for variables in its separator. It then sends that GOOD, together with the respective utility that is obtained in the subtree rooted at this agent, as a GOOD message to its parent agent. This phase finishes when the root received enough GOODs to determine the optimal value assignment for its variables.\nIn more detail, in Phase 2, any child agent delivers to its parent agent a sequence of GOOD messages, each of which explores a different value assignment for variables in its separator, together with the corresponding utility. In addition, ODPOP uses a method to\npropagate GOODs so that every agent always reports its GOODs in oder of non-increasing utility, provided that all of their child agents also follow this order. We can see that, DPOP agents receives all GOODs that are grouped in single messages (i.e., UTIL messages). In contrast, ODPOP agents send GOODs on demand (i.e., when it receives an ASK message) individually and asynchronously as long as GOODs have non-increasing utilities.\nAs a consequence, each ODPOP agent ai can determine when it has received enough GOODs from its child agents in order to be able to determine a GOOD to send to its parent agent Pi. At that time, ai will not send ASK message any more since any additional received GOODs will not affect the GOOD that was determined. If ai later receives more ASK message from Pi for having next GOOD, ai will continue to request more GOODs from its child agents until it can determine the next GOOD to report to Pi.\nSince GOODs are always reported in order of non-increasing utility, the first GOOD that is generated at the root agent is the optimal value assignment for its variable. As a consequence, the root agent will be able to generate this solution without having to consider all value assignments for its variables.\nPhase 3 (VALUE propagation) is similar to Phase 3 in DPOP. The root agent initiates the top-down VALUE propagation by sending a VALUE message to its child agents, informing them about its optimal value assignment for its variables. Subsequently, each agent ai′ , upon receiving a VALUE message, will determine its optimal value assignment for its variables based on the computation (in Phase 2) of the first GOOD message generated whose associated value assignment is consistent with the one in the received VALUE message."
    }, {
      "heading" : "5.4 Discussion on FRODO Platform",
      "text" : "In our experiment, we will compare the performance of ASP-DPOP against DPOP, AFB, and ODPOP; in particular, we use the implementation of the latter three systems that is publicly available in the FRODO platform (Léauté et al. 2009). It is important to observe that, at the implementation level, all DCOP solvers that are implemented within FRODO follow the simplifying assumption that each agent owns exactly one variable. This assumption is common practice in the DCOP literature (Modi et al. 2005; Petcu and Faltings 2005a; Gershman et al. 2009; Ottens et al. 2012). However, agents in DCOP problems used in our experiments own multiple variables. We will discuss in this subsection the preprocessing technique (i.e., decomposition, also known as virtual agents) that FRODO uses to transform a general DCOP with multiple variables per agent into a new DCOP with one variable per agent.\nFRODO creates a virtual agent for each variable in a DCOP. A distinct variable is assigned to each virtual agent, so that this formulation satisfies the simplifying assumption. We say that a virtual agent a′i belongs to a real agent ai in DCOP if the virtual agent a ′ i owns a variable that is owned by the real agent ai. In FRODO, the solving algorithm is executed on each virtual agent, while intra-agent messages (i.e., messages are passed between virtual agents that belong to the same real agent) are only simulated and discounted in the calculation of computation cost (e.g., number of messages and messages’ size).\nLet M be a DCOP with multiple variables per agent, and M ′ be a new DCOP with one variable per agent that is constructed from M . Let us assume that we apply DPOP to solve both M and M ′, using the same heuristics to construct the pseudo-trees. We can\nobserve that each node in the pseudo-tree used to solve M ′ represents a virtual agent, while each node in a pseudo-tree of ASP-DPOP represents a real agent. It is possible to see that, the number of inter-agent messages (i.e., messages that are passed between virtual agents that belong to different real agents) produced in solving M ′ may be greater than the number of UTIL messages produced in solving M , depending on their respective pseudo-trees. Therefore, to minimize the total number of inter-agent messages, FRODO constructs pseudo-trees where virtual agents that belong to the same real agent stay as close as possible to each other.\nIt is important to summarize that, to handle a general DCOP with multiple variables per agent, FRODO first transforms it into a new DCOP with one variable per agent (introducing virtual agents), and then executes the resolution algorithms on each agent of the new DCOP. To the best of our knowledge, there is not any formal discussion about the relationship between pseudo-trees whose nodes represent real agents and pseudo-trees whose nodes represent virtual agents. However, it is believed that given a pseudo-tree T ′ whose nodes represent virtual agents, there always exists a pseudo-tree T whose nodes represent real agents such that T is compatible with T ′. Intuitively, by compatible we mean that it is possible to construct T from T ′ as follows:\n• If the root of T ′ is a node representing the virtual agent a′i that belongs to a real agent ai, the root of T is the node representing ai; and • If there is at least one tree edge (resp. back edge) connecting two nodes that represent virtual agents a′i1 and a ′ i2\nin T ′, there is a tree edge (resp. back edge) connecting the two nodes that represent real agents ai1 and ai2 in T such that a ′ i1\nand a′i2 belong to ai1 and ai2 respectively.\nIt is worth to notice that, in our experiments, we ensure that all algorithms use the same heuristics to construct their pseudo-trees. We also observe that all pseudo-trees that are constructed using ASP-DPOP are compatible with the corresponding pseudo-trees that are constructed using FRODO."
    }, {
      "heading" : "5.5 Experimental Results",
      "text" : "We implement two versions of the ASP-DPOP algorithm—one that uses ground programs, which we call “ASP-DPOP (facts),” and one that uses non-ground programs, which we call “ASP-DPOP (rules).” In addition, as the observation made about H-DPOP in Section 5.2, we also implemented a variant of H-DPOP, called PH-DPOP, which stands for Privacybased H-DPOP, that restricts the amount of information that each agent can access to the amount common in most DCOP algorithms, including DPOP and ASP-DPOP. Specifically, agents in PH-DPOP can only access their own constraints and, unlike H-DPOP, cannot access their neighboring agents’ constraints.\nIn our experiments, we compare both versions of ASP-DPOP against DPOP (Petcu and Faltings 2005a), H-DPOP (Kumar et al. 2008), PH-DPOP, AFB (Gershman et al. 2009), and ODPOP (Petcu and Faltings 2006). We use a publicly-available implementation of DPOP, AFB, and ODPOP (Léauté et al. 2009) and an implementation of H-DPOP provided by the authors. We ensure that all algorithms use the same heuristics to construct their pseudo-trees for fair comparison. We measure the runtime of the algorithms using the\nsimulated runtime metric (Sultanik et al. 2007). All experiments are performed on a Quadcore 3.4GHz machine with 16GB of memory. If an algorithm fails to solve a problem, it is due to memory limitations; other types of failures are specifically stated. We conduct our experiments on random graphs (Erdös and Rényi 1959), where we systematically modify the domain-independent parameters, and on comprehensive optimization problems in power networks (Gupta et al. 2013).\n|X | DPOP H-DPOP PH-DPOP AFB ODPOP ASP-DPOP Solved Time Solved Time Solved Time Solved Time Solved Time Solved Time\n5 100% 36 100% 28 100% 31 100% 20 100% 31 100% 779 10 100% 204 100% 73 100% 381 100% 35 100% 164 100% 1,080 15 86% 39,701 100% 148 98% 67,161 100% 53 100% 3,927 100% 1,450 20 0% - 100% 188 0% - 100% 73 74%a 242,807 100% 1,777 25 0% - 100% 295 0% - 100% 119 0% - 100% 1,608\np1 DPOP H-DPOP PH-DPOP AFB ODPOP ASP-DPOP Solved Time Solved Time Solved Time Solved Time Solved Time Solved Time 0.4 100% 1,856 100% 119 100% 2,117 100% 46 100% 1,819 100% 1,984 0.5 100% 13,519 100% 120 100% 19,321 100% 50 100% 2,680 100% 1,409 0.6 94% 42,010 100% 144 100% 54,214 100% 51 100% 3,378 100% 1,308 0.7 56% 66,311 100% 165 88% 131,535 100% 54 100% 8,063 100% 1,096 0.8 20% 137,025 100% 164 62% 247,335 100% 60 100% 36,748 100% 1,073\n|Di| DPOP H-DPOP PH-DPOP AFB ODPOP ASP-DPOP\nSolved Time Solved Time Solved Time Solved Time Solved Time Solved Time 4 100% 782 100% 87 100% 1,512 100% 46 100% 285 100% 1,037 6 90% 28,363 100% 142 98% 42,275 100% 50 100% 4,173 100% 1,283 8 14% 37,357 100% 194 52% 262,590 100% 60 98% 71,512 100% 8,769 10 0% - 100% 320 8% 354,340 100% 70 78%b 227,641 100% 29,598 12 0% - 100% 486 0% - 100% 82 30%c 343,756 100% 60,190\np2 DPOP H-DPOP PH-DPOP AFB ODPOP ASP-DPOP Solved Time Solved Time Solved Time Solved Time Solved Time Solved Time 0.3 90% 38,114 100% 464 76% 189,431 100% 103 84%d 221,515 18% 120,114 0.4 86% 48,632 100% 265 84% 107,986 100% 71 94%e 109,961 86% 50,268 0.5 94% 38,043 100% 161 96% 71,181 100% 57 100% 14,790 92% 4,722 0.6 90% 31,513 100% 144 98% 68,307 100% 52 100% 13,519 100% 1,410 0.7 90% 39,352 100% 128 100% 49,377 100% 48 100% 1,730 100% 1,059 0.8 92% 40,526 100% 112 100% 62,651 100% 57 100% 1,137 100% 1,026\na ODPOP cannot solve 13 instances (out of 50 instances) in this experiment in which there are 12 instances unsolved due to timeout and 1 instance unsolved due to memory limitation. b ODPOP cannot solve 11 instances (out of 50 instances) in this experiment in which there are 10 instances unsolved due to timeout and 1 instance unsolved due to memory limitation. c ODPOP cannot solve 35 instances (out of 50 instances) in this experiment in which there are 29 instances unsolved due to timeout and 6 instance unsolved due to memory limitation. d ODPOP cannot solve 8 instances (out of 50 instances) in this experiment due to timeout. e ODPOP cannot solve 3 instances (out of 50 instances) in this experiment due to timeout.\nTable 2. Experimental Results on Random Graphs\nRandom Graphs: We create an n-node network, whose constraint density p1 produces bn · (n − 1) · p1c edges in total (Erdös and Rényi 1959). In our experiments, we vary the number of variables |X |, the domain size |Di|, the constraint density p1, and the constraint tightness p2. For each experiment, we vary only one parameter and fix the rest to their\n“default” values: |A| = 5, |X | = 15, |Di| = 6, p1 = 0.6, p2 = 0.6. The timeout is set to 5× 106 ms. Table 2 shows the percentage of instances solved (out of 50 instances) and the average simulated runtime (in ms) for the solved instances. We do not show the results for ASP-DPOP (rules), as the utilities in the utility table are randomly generated, leading to no differences w.r.t. ASP-DPOP (facts). We make the following observations:\n• ASP-DPOP is able to solve more problems than DPOP and is faster than DPOP when the problem becomes more complex (i.e., increasing |X |, |Di|, p1, or p2). The reason is that ASP-DPOP is able to prune a significant portion of the search space thanks to hard constraints. ASP-DPOP does not need to explicitly represent the rows in the UTIL table that are infeasible, unlike DPOP. The size of the search space pruned increases as the complexity of the instance grows, resulting in a larger difference between the runtime of DPOP and ASP-DPOP. • H-DPOP is able to solve more problems and solve them faster than DPOP, PHDPOP, and ASP-DPOP. The reason is that agents in H-DPOP utilize more information about the neighbors’ constraints to prune values. In contrast, agents in ASPDPOP and PH-DPOP only utilize information about their own constraints to prune values and agents in DPOP do not prune any values. • ASP-DPOP is able to solve more problems and solve them faster than PH-DPOP. The reason is that agents in PH-DPOP, like agents in H-DPOP, use constraint decision diagram (CDD) to represent their utility tables, and it is expensive to maintain and perform join and project operations on this data structure. In contrast, agents in ASP-DPOP are able to capitalize on highly efficient ASP solvers to maintain and perform operations on efficient data structures thanks to their highly optimized grounding techniques and use of portfolios of heuristics. • AFB is able to solve more problems and solve them faster than every other algorithm. We attribute this observation mainly to the relatively small number of variables in this experiment—i.e., the maximum number of variables in this experiment is 25 (see the first table in Table 2). • ASP-DPOP is able to solve more problems and solve them faster than ODPOP when the problem becomes more complex (i.e., increasing |X |, |Di|, p1, or p2). The reason is that ODPOP does not prune the search space based on hard constraints, unlike ASP-DPOP. On one hand, ODPOP intuitively sends each row of UTIL messages per time on demand and uses optimality criteria to prove optimality without exploring all value assignments for the respective variables. However, these techniques are not as efficient as pruning the search space in ASP-DPOP when the problem becomes more complex. Thus, ODPOP reaches a timeout in most of its unsolvable problems. It is also worth to observe that there are some problems that ODPOP cannot solve due to memory limitations. We attribute this to the fact that ODPOP maintains in its search space infeasible value assignments that result in a utility equal to −∞, and thus the search space of ODPOP is not as optimized as that of ASP-DPOP.\nAdditional Experiment Results on Random Graphs: We claimed earlier that AFB is able to solve more problems and solve them faster than every other algorithm, mainly due to the relative small number of variables in the experiments reported in Table 2. To directly confirm such claim, we extended our experiments on random graphs, by increasing the\nnumber of variables (i.e., |X | ≥ 150) and keeping the other parameters to their “default” values (i.e., |A| = 5, |Di| = 6, p1 = 0.6, p2 = 0.6).9 The timeout is also set to 5 × 106 ms. Table 3 shows the percentage of instances solved (out of 50 instances) and the average simulated runtime (in ms) for the solved instances. The runtime results for DPOP, H-DPOP, PH-DPOP, and ODPOP are not included in Table 3 because they run out of memory in solving all of the problems in this domain.10 We observe that ASP-DPOP is able to solve more problems than AFB (i.e., when |X | = 250) and solve them faster than AFB when |X | ≥ 200. We attribute this observation mainly to the large number of variables in this experiment. We also notice that AFB can scale up to solve problems of up to |X | = 200 (such scalability will not be seen in the experiment on power network problems described below). The main reason is that the problems in our experiment on random graphs are “purely hard” with the default values p1 = 0.6 and p2 = 0.6. This means that the size of the set of complete feasible value assignments, which are complete value assignments that do not result in a utility of +∞, is small (about less than 5 in all of the problems in this domain). AFB backtracks much earlier before it can achieves a complete feasible value assignment. As a result, AFB can solve problems with number of variables up to 200 before it exceeds the time out threshold.\nPower Network Problems: A customer-driven microgrid (CDMG), one possible instantiation of the smart grid problem, has recently been shown to subsume several classical power system sub-problems (e.g., load shedding, demand response, restoration) (Jain et al. 2012). In this domain, each agent represents a node with consumption, generation, and transmission preferences, and a global cost function. Constraints include the power balance and no power loss principles, the generation and consumption limits, and the capacity of the power line between nodes. The objective is to minimize a global cost function. CDMG optimization problems are well-suited to be modeled with DCOPs due to their distributed nature. Moreover, as some of the constraints in CDMGs (e.g., the power balance principle) can be described in functional form, they can be exploited by ASP-DPOP (rules). For this reason, both “ASP-DPOP (facts)” and “ASP-DPOP (rules)” are used in this domain.\nWe use three network topologies defined using the IEEE standards (IEEE Distribution Test Feeders 2014) and vary the domain size of the generation, load, and transmission variables of each agent from 5 to 31. The timeout is set to 106 ms. Figure 5 summarizes the runtime results. As the utilities are generated following predefined rules (Gupta et al.\n9 We thank one of the reviewers for his/her suggestion to have this additional experiment on random graphs. 10 It is worth to note that H-DPOP runs out of memory while constructing its CDDs in solving all of the problems\nin this domain.\n2013), we also show the results for ASP-DPOP (rules). Furthermore, we omit results for PH-DPOP because they have identical runtime—the amount of information used to prune the search space is identical for both algorithms in this domain. We also measure the size of UTIL messages, where we use the number of values in the message as units, and the intra-agent UTIL messages (i.e., messages are passed between virtual agents that belong to the same real agent) are accounted for fair comparison. Table 4 tabulates the results. We did not measure the size of VALUE messages since they are significantly smaller than UTIL messages. It is also worth to report that the number of UTIL messages that FRODO produces (discounting all intra-agent UTIL messages) is equal to the number of UTIL messages that ASP-DPOP produced in all power network problems in our experiments.\nThe results in Figure 5 are consistent with those shown earlier (except for AFB)—ASPDPOP is slower than DPOP and ODPOP when the domain size is small, but it is able to solve more problems than DPOP and ODPOP. We observe that, in Figure 5(b), DPOP is consistently faster than ASP-DPOP and is able to solve the same number of problems as ASP-DPOP. It is because the highest constraint arity in 34 bus topology is 5 while it is 6 in 13 and 37 bus topologies. Unlike in random graphs, H-DPOP is slower than the other algorithms in these problems. The reason is that the constraint arity in these problems is larger and the expensive operations on CDDs grow exponentially with the arity. We also observe that ASP-DPOP (rules) is faster than ASP-DPOP (facts). The reason is that the former is able to exploit the interdependencies between constraints to prune the search space. Additionally, ASP-DPOP (rules) can solve more problems than ASP-DPOP (facts). The reason is that the former requires less memory since it prunes a larger search space and, thus, ground fewer facts.\nThe runtime results for AFB are not included in Figure 5, since AFB exceeds the timeout in solving all of the problems in this domain; this contrasts to the results shown earlier for random graphs. The main reason is that the number of variables in the power network problems is large (i.e., |X | are 50, 134, and 146 in 13, 34, and 37 bus topologies, respectively in Figure 5).\nFinally, both versions of ASP-DPOP require smaller messages than both H-DPOP and DPOP. The reason for the former is that the CDD data structure of H-DPOP is significantly more complex than that of ASP-DPOP. The reason for the latter is that ASP-DPOP prunes portions of the search space while DPOP did not. In addition, since ASP-DPOP does not transform DCOP problems with multiple variables per agent to corresponding ones with one variable per agent, ASP-DPOP is able to exploit significantly more the interdependencies between constraints to prune the search space. Moreover, we can see that the largest UTIL message sizes in ODPOP are smaller than those of ASP-DPOP, but the total UTIL message sizes in ODPOP are larger than those of ASP-DPOP. The reason is that ODPOP sends only linear size message, but it needs to send many messages on demand."
    }, {
      "heading" : "5.6 Discussions on ASP-DPOP",
      "text" : "ASP-DPOP has been shown to be competitive with other algorithms in solving DCOPs in our experimental results. The benefits of using ASP-DPOP are accomplished by having ASP as its foundation. We will illustrate here the two main advantages of making use of ASP within ASP-DPOP:\n1. The use of the highly expressive ASP language to encode constraints in DCOPs; and 2. The ability to harness the highly optimized ASP grounder and solver to prune the\nsearch space based on hard constraints. In the rest of this section, we further discuss these advantages and relate them to the observations drawn from the experiments. These considerations are followed by a discussion of how ASP-DPOP alleviates the simplifying assumption of having a single variable per agent. Finally, at the end of this section, we analyze the privacy loss of ASP-DPOP.\nThe first advantage of using ASP within ASP-DPOP comes from the ability to use a very expressive logic language to encode the constraints in a DCOP. ASP-DPOP can represent constraint utilities as an implicit function instead of explicitly enumerating them. Thus, ASP-DPOP is particularly suitable to encode DCOPs whose constraint utilities are large and evaluated via implicit functions of the variables in their scopes (e.g., power network problems, smart grid problems). This can be seen clearly via Example 15.\nExample 15 Let us consider a constraint f representing the power loss principle in a power network problem, where scp(f) = {x1→2, x2→1} in which the domains of the variables x1→2 and x2→1 are D1→2 = [0, 2] and D2→1 = [−2, 0], respectively. Intuitively, the variable xi→j , where i, j ∈ {1, 2}, i 6= j, indicates the amount of power that node i transfers to (receives from) node j if xi→j ≥ 0 (resp. xi→j < 0). For example, x1→2 = 1 means that the node 1 transfers 1 unit of power to the node 2, and x2→1 = −1 specifies that the node 2 receives 1 unit of power from the node 1. By the power loss principle, if there is no loss, the amount of power transferred from one node is equal to the amount of power received in the other node (i.e., xi→j +xj→i = 0). However, if there is loss (i.e., xi→j +xj→i 6= 0), we assume that the cost (utility) of the power transmission is evaluated to be two times greater than the power unit loss. Formally, the utility of the constraint f is given implicitly as a function:\nf(x1→2, x2→1) = 2× |x1→2 + x2→1|. (57)\nFigure 6(a) enumerates all the utilities of the constraint f explicitly in a utility table, and Figure 6(b) presents an answer set program that models implicitly those utilities. We can see that while the utility table has 9 rows (i.e., the domain sizes of x1→2 and x2→1 are 3),\nthe answer set program consists of only 2 facts and 1 rule. If the domain sizes of x1→2 and x2→1 are 1000 (e.g.,D1→2 = [0, 999] andD1→2 = [−999, 0]), the utility table would have 10002 rows whereas the answer set program modeling implicitly such the same utilities still has 2 facts and 1 rule that are similar to ones in Figure 6(b)—i.e., it only updates the 2 facts (58) and (59) as follows:\nvalue(x1→2, 0 .. 999) ← (61) value(x2→1,−999 .. 0) ← (62)\nAs a consequence, using ASP within ASP-DPOP to encode DCOPs makes programs much more concise and compact. The encoding is declarative and can be easily extended and modified. Moreover, such encoding does not depend on the implementation of the algorithms (e.g., DPOP or H-DPOP), making programs more flexible and understandable. Specifically, if we change the algorithm to solve a DCOP, the Controller Module needs to be changed following the new algorithm, yet the Specification Module remains the same. In contrast, using imperative programming techniques, the “ad-hoc” implementation that is employed within each local solver might require different encodings of DCOPs for different used algorithms and different propagators for different types of constraints. For example, H-DPOP implementation needs a different data structure from DPOP implementation to deal with hard constraints.\nThe second advantage of using ASP as the foundation of ASP-DPOP is to harness the highly optimized ASP grounders and solvers to prune the search space, especially in the handling of hard constraints. As an example, consider the power network problem whose objective is to minimize a global cost function.11 A DCOP that encodes such type of power network problems can be formulated in terms of cost-as-utility minimization rather than reward-as-utility maximization. Thus, in this formulation the value assignments resulting in an infinite utility (i.e., +∞) should not be included in any DCOP solution; such value assignments are redundant and should be pruned. Example 16 shows how effectively an ASP grounder can prune the search space.\nExample 16 Consider a simple power network problem, where the aggregated cost needs to be minimized. The problem has two nodes (nodes 1 and 2). Let us assume that agent a1 and agent a2, which are the node 1 and the node 2, own the variables x1→2 and x2→1, respectively. These are described in Example 15. The problem has one constraint f representing the power loss principle, analogously to what described in Example 15. The only difference is that we do not allow losses in power transfers (i.e., if there is a loss, the corresponding cost is +∞). Thus, the utility (cost) of the constraint f now is evaluated as:\nf(x1→2, x2→1) = { 2× x1→2 if x1→2 + x2→1 = 0 +∞ otherwise\n(63)\nFigure 7 presents the ASP program12 to compute the UTIL message sent from the agent\n11 The previous formalization of ASP-DPOP focuses on maximizing the cost function; the switch to minimization problems requires trivial changes to the design of ASP-DPOP. 12 #sup is a special constant representing the largest possible value in the ASP language.\n2 to the agent 1, assuming that the agent 1 is the root of the respective pseudo-tree (i.e., the separator set of the agent 2 is sep2 = {x1→2}). It is important to observe that, since the objective is to minimize a global cost function, the ASP in Figure 7 is produced differently from the one that is generated by generate UTIL ASP/2 described in 3.4.4. Specifically, the differences are:\n• The predicates of the form table min ai are used instead of ones of the form table max ai; • U = #min{...} rather than U = #max{...} in (52) (i.e., computing the minimal\nutilities for each value combination of variables in the separator list); and • The conditions Vr1 != #sup, · · · , Vrk′ != #sup are used instead\nof Vr1 != #inf, · · · , Vrk′ != #inf in (51) (i.e., atoms of the form table row ai(u, vs1 , . . . , vsk) where u = #sup (i.e., the respective utilities are +∞) are not produced).\nAs a consequence, the encoded UTIL messages consist of facts of the forms table min ai (instead of table max ai) and table info.\nThe 9 facts (64)-(72) enumerate all utilities of the constraint f in which the 6 facts (67)- (72) are redundant since their corresponding utilities are +∞. With DPOP, the total size of the search space for computing its UTIL message is 9, which corresponds to the 9 facts (64)-(72), since DPOP does not do pruning. However, with ASP-DPOP, the corresponding total size of the search space is 3 since GRINGO, due to the condition\nV0 != #sup, grounds the rule (75) into only 3 facts:\ntable row a2(4, 2) ← (77) table row a2(2, 1) ← (78) table row a2(0, 0) ← (79)\nand an ASP solver will use these facts to generate the predicates table min a2 based on the rule (76). The different between the sizes of the search spaces of ASP-DPOP and DPOP are greater as the domain sizes of variables increase. For example, if the domain sizes of x1→2 and x2→1 are 1000, the total search space of DPOP is 10002 while the total search space of ASP-DPOP is just 1000.\nAs a consequence, and as clear from our experiments, ASP-DPOP is able to prune a significant portion of the search space, thanks to hard constraints, whereas DPOP does not. Moreover, as seen in Example 16, the size of the search space pruned increases as the complexity of the instance grows (i.e., increasing |X |, |Di|, p1, or p2). Thus, ASP-DPOP is able to solve more problems than DPOP and is faster than DPOP when the problem becomes more complex.\nThe pruning power of the ASP grounders and solvers enables also the generation of smaller UTIL messages in ASP-DPOP than those generated by DPOP. Let us consider a UTIL message M sent from an agent ai to an agent aj . A value assignment of variables in sepi is admissible if its corresponding optimal sum of utilities in the subtree rooted at ai is different than −∞.13 In DPOP, M consists of a utility, which is optimal, for each value assignment of variables in sepi (including both admissible and inadmissible value assignments). However, M in ASP-DPOP consists of a utility, which is optimal and different from −∞, for only each admissible value assignment of variables in sepi. This is because such inadmissible value assignments will not be included in any DCOP solution (i.e., otherwise the global cost is −∞).\nWe will not discuss in-depth technically what algorithms and computations are implemented within modern ASP grounders to optimize the grounding process, since they are beyond the scope of this paper. Readers who are interested in such algorithms and computations can find further information in (Gebser et al. 2012; Kaufmann et al. 2016). It is important to notice that such computations (e.g., for removing unnecessary rules and for omitting rules whose bodies cannot be satisfied) consume memory, take time, and are not trivial. Therefore, for DCOP problems with low constraint tightness, the runtime and memory that are used for those computations will dominate the runtime and memory that are saved from pruning the search space (e.g., see the row p2 = 0.3 in Table 2). This also explains why ASP-DPOP is slower than DPOP when the problem becomes less complex (i.e., decreasing |X |, |Di|, p1, or p2). Specifically, from the trend while decreasing p2 in Table 2, ASP-DPOP will not be able to compete with DPOP for cases where p2 ≤ 0.3.\nThe fact that ASP-DPOP solves DCOP problems with multiple variables per agent directly, without transforming them to problems with one variable per agent, deserves some discussions. It is easy to see that ASP-DPOP agents need to consider more variables and\n13 Or +∞ for minimization problems.\nthus more constraints. As a result, there are more interdependencies between constraints for ASP-DPOP to exploit. If the constraint tightness is high, the size of the search space pruned increases significantly. This can be seen in our power network experiment. On the other hand, dealing with more variables and more constraints also increases the search space. Therefore, if the constraint tightness does not provide sufficient pruning, the portion of the search space pruned does not properly balance the increase in the size of the search space; this may lead ASP-DPOP to require more memory than DPOP in solving such problems. This situation can be seen in experimental results on random graphs (i.e., decreasing p2). Solving DCOPs with multiple variables per agent without transforming them to problems with a single variable per agent was also investigated in (Fioretto et al. 2016).\nMaintaining privacy is a fundamental motivation for the use of DCOP. A detailed analysis of privacy loss in DCOP for some existing DCOP algorithms, including DPOP, can be found in (Greenstadt et al. 2006). For ASP-DPOP, it is not difficult to realize that DPOP and ASP-DPOP have the same privacy loss. The reason is that the content of UTIL messages (resp. VALUE messages) in DPOP—that are given under the tabular form (which are similar to those given under multi-dimensional matrix form)—is identical to the content of the UTIL messages (resp. VALUE messages) in ASP-DPOP—that are given in facts form. In fact, anything that is inferred from the fact form (in UTIL and VALUE messages of ASP-DPOP) can be inferred from the tabular form (in the respective messages of DPOP), and vice versa anything is inferred from tabular form can be inferred from fact form as well."
    }, {
      "heading" : "6 Related Work",
      "text" : "The use of declarative programs, specifically logic programs, for reasoning in multi-agent domains is not new. Starting with some seminal papers (Kowalski and Sadri 1999), various authors have explored the use of several different flavors of logic programming, such as normal logic programs and abductive logic programs, to address cooperation between agents (Kakas et al. 2004; Sadri and Toni 2003; Gelfond and Watson 2007; De Vos et al. 2005). Some proposals have also explored the combination between constraint programming, logic programming, and formalization of multi-agent domains (Dovier et al. 2013; Vlahavas 2002; Dovier et al. 2010a; Dovier et al. 2010b). Logic programming has been used in modeling multi-agent scenarios involving agents knowledge about other’s knowledge (Baral et al. 2010), computing models in the logics of knowledge (Pontelli et al. 2010), multi-agent planning (Son et al. 2009) and formalizing negotiation (Sakama et al. 2011). ASP-DPOP is similar to the last two applications in that (i) it can be viewed as a collection of agent programs; (ii) it computes solutions using an ASP solver; and (iii) it uses message passing for agent communication. A key difference is that ASP-DPOP solves multi-agent problems formulated as constraint-based models, while the other applications solve problems formulated as decision-theoretic and game-theoretic models.\nResearchers have also developed a framework that integrates declarative techniques with off-the-shelf constraint solvers to partition large constraint optimization problems into smaller subproblems and solve them in parallel (Liu et al. 2012). In contrast, DCOPs are problems that are naturally distributed and cannot be arbitrarily partitioned.\nASP-DPOP is able to exploit problem structure by propagating hard constraints and using them to prune the search space efficiently. This reduces the memory requirement of the algorithm and improves the scalability of the system. Existing DCOP algorithms that also propagate hard and soft constraints to prune the search space include H-DPOP that propagates exclusively hard constraints (Kumar et al. 2008), BrC-DPOP that propagates branch consistency (Fioretto et al. 2014), and variants of BnB-ADOPT (Yeoh et al. 2010; Gutierrez and Meseguer 2012b; Gutierrez et al. 2011) that maintains soft-arc consistency (Bessiere et al. 2012; Gutierrez and Meseguer 2012a; Gutierrez et al. 2013). A key difference is that these algorithms require algorithm developers to explicitly implement the ability to reason about the hard and soft constraints and propagate them efficiently. In contrast, ASP-DPOP capitalizes on general purpose ASP solvers to do so."
    }, {
      "heading" : "7 Conclusions and Future Work",
      "text" : "In this paper, we explored the benefits of using logic programming techniques as a platform to provide complete solutions of DCOPs. Our proposed logic programming-based algorithm, ASP-DPOP, is able to solve more problems and solve them faster than DPOP, its imperative programming counterpart. Aside from the ease of modeling, each agent in ASP-DPOP also capitalizes on highly efficient ASP solvers to automatically exploit problem structure (e.g., prune the search space using hard constraints). Experimental results show that ASP-DPOP is faster and can scale to larger problems than a version of H-DPOP (i.e., PH-DPOP) that maintains the level of privacy similar to that of ASP-DPOP. These results highlight the strengths of a declarative programming paradigm, where explicit modelspecific pruning rules are not necessary. In conclusion, we believe that this work contributes to the DCOP community, where we show that the declarative programming paradigm is a promising new direction of research for DCOP researchers, as well as the ASP community, where we demonstrate the applicability of ASP to solve a wide array of multi-agent problems that can be modeled as DCOPs.\nIn future work, we will explore two directions to deepen the use of logic programming in solving DCOPs:\n• Logic programming under different semantics: We will consider the advantages of other logic programming paradigms in solving DCOPs. One possibility is to use Constraint Logic Programming (CLP) (Jaffar and Maher 1994) instead of ASP. Since CLP is a merger of two declarative paradigms—constraint solving and logic programming—it seems well-suited to solve DCOPs. A preliminary investigation (Le et al. 2014) has shown that this technique can dramatically decrease run time. • Different representation of messages: We observe that the messages used in DPOP, and even ASP-DPOP, are represented explicitly—i.e., they are multi-dimensional matrices in DPOP and facts in ASP-DPOP. One of the reasons for this is that each agent performs the inference process for its subtree, enumerates explicitly all the results, and sends them to other agents. We are interested in investigating algorithms where agents coordinate with others via messages that are logic programs (e.g., ASP or CLP clauses). Specifically, in such an algorithm, each agent does the inference\npartially, for some specific interesting value assignment, and without enumerating all results. The rest of the computation will be encoded as logic programs and passed to other agents. Some agent who performs the complete inference process will propagate the search space based on the rules in the received messages as logic programs. We believe this will reduce the search space and the run time."
    }, {
      "heading" : "Acknowledgment",
      "text" : "This research is partially supported by NSF grants HRD-1345232 and DGE-0947465. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the sponsoring organizations, agencies, or the U.S. government. We would like to thank Akshat Kumar for sharing with us his implementation of H-DPOP."
    } ],
    "references" : [ {
      "title" : "Knowledge Representation, reasoning, and declarative problem solving with Answer sets",
      "author" : [ "C. BARAL" ],
      "venue" : "Cambridge University Press, Cambridge, MA.",
      "citeRegEx" : "BARAL,? 2003",
      "shortCiteRegEx" : "BARAL",
      "year" : 2003
    }, {
      "title" : "Modeling multi-agent scenarios involving agents knowledge about other’s knowledge using ASP",
      "author" : [ "C. BARAL", "G. GELFOND", "E. PONTELLI", "SON", "T.C." ],
      "venue" : "Proc. of AAMAS. 259–266.",
      "citeRegEx" : "BARAL et al\\.,? 2010",
      "shortCiteRegEx" : "BARAL et al\\.",
      "year" : 2010
    }, {
      "title" : "Including soft global constraints in DCOPs",
      "author" : [ "C. BESSIERE", "P. GUTIERREZ", "P. MESEGUER" ],
      "venue" : "Proc. of CP. 175–190.",
      "citeRegEx" : "BESSIERE et al\\.,? 2012",
      "shortCiteRegEx" : "BESSIERE et al\\.",
      "year" : 2012
    }, {
      "title" : "SICStus Prolog User’s Manual",
      "author" : [ "M CARLSSON" ],
      "venue" : "Swedish Institute of Computer Science.",
      "citeRegEx" : "CARLSSON,? 2015",
      "shortCiteRegEx" : "CARLSSON",
      "year" : 2015
    }, {
      "title" : "The dlv system: Model generator and application frontends",
      "author" : [ "S. CITRIGNO", "T. EITER", "W. FABER", "G. GOTTLOB", "C. KOCH", "N. LEONE", "C. MATEIS", "G. PFEIFER", "F. SCARCELLO" ],
      "venue" : "Proc. of the Workshop on Logic Programming. 128–137.",
      "citeRegEx" : "CITRIGNO et al\\.,? 1997",
      "shortCiteRegEx" : "CITRIGNO et al\\.",
      "year" : 1997
    }, {
      "title" : "LAIMA: A multi-agent platform using ordered choice logic programming",
      "author" : [ "M. DE VOS", "T. CRICK", "J.A. PADGET", "M. BRAIN", "O. CLIFFE", "J. NEEDHAM" ],
      "venue" : "Proc. of DALT.",
      "citeRegEx" : "VOS et al\\.,? 2005",
      "shortCiteRegEx" : "VOS et al\\.",
      "year" : 2005
    }, {
      "title" : "Constraint processing",
      "author" : [ "R. DECHTER" ],
      "venue" : "Elsevier Morgan Kaufmann.",
      "citeRegEx" : "DECHTER,? 2003",
      "shortCiteRegEx" : "DECHTER",
      "year" : 2003
    }, {
      "title" : "An Investigation of Multi-Agent Planning in CLP",
      "author" : [ "A. DOVIER", "A. FORMISANO", "E. PONTELLI" ],
      "venue" : "Fundamentae Informatica 105, 1-2, 79–103.",
      "citeRegEx" : "DOVIER et al\\.,? 2010a",
      "shortCiteRegEx" : "DOVIER et al\\.",
      "year" : 2010
    }, {
      "title" : "Multivalued Action Languages with Constraints in CLP(FD)",
      "author" : [ "A. DOVIER", "A. FORMISANO", "E. PONTELLI" ],
      "venue" : "Theory and Practice of Logic Programming 10, 2, 167–235.",
      "citeRegEx" : "DOVIER et al\\.,? 2010b",
      "shortCiteRegEx" : "DOVIER et al\\.",
      "year" : 2010
    }, {
      "title" : "Autonomous agents coordination: Action languages meet CLP() and Linda",
      "author" : [ "A. DOVIER", "A. FORMISANO", "E. PONTELLI" ],
      "venue" : "Theory and Practice of Logic Programming 13, 2, 149–173.",
      "citeRegEx" : "DOVIER et al\\.,? 2013",
      "shortCiteRegEx" : "DOVIER et al\\.",
      "year" : 2013
    }, {
      "title" : "On random graphs i",
      "author" : [ "P. ERDÖS", "A. RÉNYI" ],
      "venue" : "Publicationes Mathematicae Debrecen 6, 290.",
      "citeRegEx" : "ERDÖS and RÉNYI,? 1959",
      "shortCiteRegEx" : "ERDÖS and RÉNYI",
      "year" : 1959
    }, {
      "title" : "Decentralised coordination of low-power embedded devices using the Max-Sum algorithm",
      "author" : [ "A. FARINELLI", "A. ROGERS", "A. PETCU", "N. JENNINGS" ],
      "venue" : "Proc. of AAMAS. 639–646.",
      "citeRegEx" : "FARINELLI et al\\.,? 2008",
      "shortCiteRegEx" : "FARINELLI et al\\.",
      "year" : 2008
    }, {
      "title" : "GDGibbs: A GPU-based sampling algorithm for solving distributed constraint optimization problems (Extended Abstract)",
      "author" : [ "F. FIORETTO", "F. CAMPEOTTO", "L. DA RIN FIORETTO", "W. YEOH", "E. PONTELLI" ],
      "venue" : "Proc. of AAMAS.",
      "citeRegEx" : "FIORETTO et al\\.,? 2014",
      "shortCiteRegEx" : "FIORETTO et al\\.",
      "year" : 2014
    }, {
      "title" : "Improving DPOP with branch consistency for solving distributed constraint optimization problems",
      "author" : [ "F. FIORETTO", "T. LE", "W. YEOH", "E. PONTELLI", "SON", "T.C." ],
      "venue" : "Proc. of CP.",
      "citeRegEx" : "FIORETTO et al\\.,? 2014",
      "shortCiteRegEx" : "FIORETTO et al\\.",
      "year" : 2014
    }, {
      "title" : "Multi-variable agents decomposition for dcops",
      "author" : [ "F. FIORETTO", "W. YEOH", "E. PONTELLI" ],
      "venue" : "Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA. 2480–2486.",
      "citeRegEx" : "FIORETTO et al\\.,? 2016",
      "shortCiteRegEx" : "FIORETTO et al\\.",
      "year" : 2016
    }, {
      "title" : "Answer Set Solving in Practice",
      "author" : [ "M. GEBSER", "R. KAMINSKI", "B. KAUFMANN", "T. SCHAUB" ],
      "venue" : "Morgan and Claypool Publishers.",
      "citeRegEx" : "GEBSER et al\\.,? 2012",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2012
    }, {
      "title" : "Potassco: The potsdam answer set solving collection",
      "author" : [ "M. GEBSER", "B. KAUFMANN", "R. KAMINSKI", "M. OSTROWSKI", "T. SCHAUB", "M. SCHNEIDER" ],
      "venue" : "AI Commun. 24, 2 (Apr.), 107– 124.",
      "citeRegEx" : "GEBSER et al\\.,? 2011",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2011
    }, {
      "title" : "clasp: A conflict-driven answer set solver",
      "author" : [ "M. GEBSER", "B. KAUFMANN", "A. NEUMANN", "T. SCHAUB" ],
      "venue" : "Proc. of LPNMR. 260–265.",
      "citeRegEx" : "GEBSER et al\\.,? 2007",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2007
    }, {
      "title" : "Modeling cooperative multi-agent systems",
      "author" : [ "G. GELFOND", "R. WATSON" ],
      "venue" : "Proc. of ASP Workshop.",
      "citeRegEx" : "GELFOND and WATSON,? 2007",
      "shortCiteRegEx" : "GELFOND and WATSON",
      "year" : 2007
    }, {
      "title" : "Knowledge Representation, Reasoning, and the Design of Intelligent Agents",
      "author" : [ "M. GELFOND", "Y. KAHL" ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "GELFOND and KAHL,? 2014",
      "shortCiteRegEx" : "GELFOND and KAHL",
      "year" : 2014
    }, {
      "title" : "Logic programs with classical negation",
      "author" : [ "M. GELFOND", "V. LIFSCHITZ" ],
      "venue" : "Proc. of ICLP. 579–597.",
      "citeRegEx" : "GELFOND and LIFSCHITZ,? 1990",
      "shortCiteRegEx" : "GELFOND and LIFSCHITZ",
      "year" : 1990
    }, {
      "title" : "Asynchronous Forward-Bounding for distributed COPs",
      "author" : [ "A. GERSHMAN", "A. MEISELS", "R. ZIVAN" ],
      "venue" : "Journal of Artificial Intelligence Research 34, 61–88.",
      "citeRegEx" : "GERSHMAN et al\\.,? 2009",
      "shortCiteRegEx" : "GERSHMAN et al\\.",
      "year" : 2009
    }, {
      "title" : "Analysis of privacy loss in distributed constraint optimization",
      "author" : [ "R. GREENSTADT", "J.P. PEARCE", "M. TAMBE" ],
      "venue" : "Proceedings, The Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference, July 16-20, 2006, Boston, Massachusetts, USA. 647–653.",
      "citeRegEx" : "GREENSTADT et al\\.,? 2006",
      "shortCiteRegEx" : "GREENSTADT et al\\.",
      "year" : 2006
    }, {
      "title" : "Solving customer-driven microgrid optimization problems as DCOPs",
      "author" : [ "S. GUPTA", "P. JAIN", "W. YEOH", "S. RANADE", "E. PONTELLI" ],
      "venue" : "Proc. of the Distributed Constraint Reasoning Workshop. 45–59.",
      "citeRegEx" : "GUPTA et al\\.,? 2013",
      "shortCiteRegEx" : "GUPTA et al\\.",
      "year" : 2013
    }, {
      "title" : "Maintaining soft arc consistencies in BnB-ADOPT during search",
      "author" : [ "GUTIERREZ P.", "LEE J.", "LEI K.M.", "MAK T.", "MESEGUER P." ],
      "venue" : "Proc. of CP. 365–380. GUTIERREZ, P. AND MESEGUER, P. 2012a. Improving BnB-ADOPT-AC. In Proc. of AAMAS. 273–280.",
      "citeRegEx" : "P. et al\\.,? 2013",
      "shortCiteRegEx" : "P. et al\\.",
      "year" : 2013
    }, {
      "title" : "Removing redundant messages in n-ary BnB-ADOPT",
      "author" : [ "P. GUTIERREZ", "P. MESEGUER" ],
      "venue" : "Journal of Artificial Intelligence Research 45, 287–304.",
      "citeRegEx" : "GUTIERREZ and MESEGUER,? 2012b",
      "shortCiteRegEx" : "GUTIERREZ and MESEGUER",
      "year" : 2012
    }, {
      "title" : "Generalizing ADOPT and BnB-ADOPT",
      "author" : [ "P. GUTIERREZ", "P. MESEGUER", "W. YEOH" ],
      "venue" : "Proc. of IJCAI. 554–559.",
      "citeRegEx" : "GUTIERREZ et al\\.,? 2011",
      "shortCiteRegEx" : "GUTIERREZ et al\\.",
      "year" : 2011
    }, {
      "title" : "Distributed intelligent backtracking",
      "author" : [ "Y. HAMADI", "C. BESSIÈRE", "J. QUINQUETON" ],
      "venue" : "Proc. of ECAI. 219–223.",
      "citeRegEx" : "HAMADI et al\\.,? 1998",
      "shortCiteRegEx" : "HAMADI et al\\.",
      "year" : 1998
    }, {
      "title" : "Special issue: Ten years of logic programming constraint logic programming: a survey",
      "author" : [ "J. JAFFAR", "M.J. MAHER" ],
      "venue" : "The Journal of Logic Programming 19, 503 – 581.",
      "citeRegEx" : "JAFFAR and MAHER,? 1994",
      "shortCiteRegEx" : "JAFFAR and MAHER",
      "year" : 1994
    }, {
      "title" : "Optimum operation of a customerdriven microgrid: A comprehensive approach",
      "author" : [ "P. JAIN", "S. GUPTA", "S. RANADE", "E. PONTELLI" ],
      "venue" : "Proc. of PEDES.",
      "citeRegEx" : "JAIN et al\\.,? 2012",
      "shortCiteRegEx" : "JAIN et al\\.",
      "year" : 2012
    }, {
      "title" : "Agent Planning, negotiation and control of operation",
      "author" : [ "A. KAKAS", "P. TORRONI", "N. DEMETRIOU" ],
      "venue" : "Proc. of ECAI.",
      "citeRegEx" : "KAKAS et al\\.,? 2004",
      "shortCiteRegEx" : "KAKAS et al\\.",
      "year" : 2004
    }, {
      "title" : "Grounding and solving in answer set programming",
      "author" : [ "B. KAUFMANN", "N. LEONE", "S. PERRI", "T. SCHAUB" ],
      "venue" : "AI Magazine 37, 3, 25–32.",
      "citeRegEx" : "KAUFMANN et al\\.,? 2016",
      "shortCiteRegEx" : "KAUFMANN et al\\.",
      "year" : 2016
    }, {
      "title" : "Logic programming towards multi-agent systems",
      "author" : [ "R. KOWALSKI", "F. SADRI" ],
      "venue" : "Annals of Mathematics and Artificial Intelligence 25, 3-4, 391–419.",
      "citeRegEx" : "KOWALSKI and SADRI,? 1999",
      "shortCiteRegEx" : "KOWALSKI and SADRI",
      "year" : 1999
    }, {
      "title" : "Distributed constraint optimization with structured resource constraints",
      "author" : [ "A. KUMAR", "B. FALTINGS", "A. PETCU" ],
      "venue" : "Proc. of AAMAS. 923–930.",
      "citeRegEx" : "KUMAR et al\\.,? 2009",
      "shortCiteRegEx" : "KUMAR et al\\.",
      "year" : 2009
    }, {
      "title" : "H-DPOP: Using hard constraints for search space pruning in DCOP",
      "author" : [ "A. KUMAR", "A. PETCU", "B. FALTINGS" ],
      "venue" : "Proc. of AAAI. 325–330.",
      "citeRegEx" : "KUMAR et al\\.,? 2008",
      "shortCiteRegEx" : "KUMAR et al\\.",
      "year" : 2008
    }, {
      "title" : "Coordination of first responders under communication and resource constraints (Short Paper)",
      "author" : [ "R. LASS", "J. KOPENA", "E. SULTANIK", "D. NGUYEN", "C. DUGAN", "P. MODI", "W. REGLI" ],
      "venue" : "Proc. of AAMAS. 1409–1413.",
      "citeRegEx" : "LASS et al\\.,? 2008",
      "shortCiteRegEx" : "LASS et al\\.",
      "year" : 2008
    }, {
      "title" : "Logic and constraint logic programming for distributed constraint optimization",
      "author" : [ "T. LE", "E. PONTELLI", "T.C. SON", "W. YEOH" ],
      "venue" : "CoRR abs/1405.1734.",
      "citeRegEx" : "LE et al\\.,? 2014",
      "shortCiteRegEx" : "LE et al\\.",
      "year" : 2014
    }, {
      "title" : "Solving distributed constraint optimization problems with logic programming",
      "author" : [ "T. LE", "T.C. SON", "E. PONTELLI", "W. YEOH" ],
      "venue" : "Proc. of AAAI.",
      "citeRegEx" : "LE et al\\.,? 2015",
      "shortCiteRegEx" : "LE et al\\.",
      "year" : 2015
    }, {
      "title" : "Coordinating logistics operations with privacy guarantees",
      "author" : [ "T. LÉAUTÉ", "B. FALTINGS" ],
      "venue" : "Proc. of IJCAI. 2482–2487.",
      "citeRegEx" : "LÉAUTÉ and FALTINGS,? 2011",
      "shortCiteRegEx" : "LÉAUTÉ and FALTINGS",
      "year" : 2011
    }, {
      "title" : "FRODO 2.0: An open-source framework for distributed constraint optimization",
      "author" : [ "T. LÉAUTÉ", "B. OTTENS", "R. SZYMANEK" ],
      "venue" : "In Proc. of the Distributed Constraint Reasoning Workshop",
      "citeRegEx" : "LÉAUTÉ et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "LÉAUTÉ et al\\.",
      "year" : 2009
    }, {
      "title" : "Cologne: A declarative distributed constraint optimization platform",
      "author" : [ "LIU C.", "REN L.", "LOO B.T.", "MAO Y.", "BASU P." ],
      "venue" : "Proc. of the VLDB Endowment 5, 8, 752–763.",
      "citeRegEx" : "C. et al\\.,? 2012",
      "shortCiteRegEx" : "C. et al\\.",
      "year" : 2012
    }, {
      "title" : "Distributed algorithms for DCOP: A graphical game-based approach",
      "author" : [ "R. MAHESWARAN", "J. PEARCE", "M. TAMBE" ],
      "venue" : "Proc. of PDCS. 432–439.",
      "citeRegEx" : "MAHESWARAN et al\\.,? 2004",
      "shortCiteRegEx" : "MAHESWARAN et al\\.",
      "year" : 2004
    }, {
      "title" : "Taking DCOP to the real world: Efficient complete solutions for distributed event scheduling",
      "author" : [ "R. MAHESWARAN", "M. TAMBE", "E. BOWRING", "J. PEARCE", "P. VARAKANTHAM" ],
      "venue" : "Proc. of AAMAS. 310–317.",
      "citeRegEx" : "MAHESWARAN et al\\.,? 2004",
      "shortCiteRegEx" : "MAHESWARAN et al\\.",
      "year" : 2004
    }, {
      "title" : "Solving distributed constraint optimization problems using cooperative mediation",
      "author" : [ "R. MAILLER", "V. LESSER" ],
      "venue" : "Proc. of AAMAS. 438–445.",
      "citeRegEx" : "MAILLER and LESSER,? 2004",
      "shortCiteRegEx" : "MAILLER and LESSER",
      "year" : 2004
    }, {
      "title" : "Stable models and an alternative logic programming paradigm",
      "author" : [ "V. MAREK", "M. TRUSZCZYŃSKI" ],
      "venue" : "The Logic Programming Paradigm: a 25-year Perspective. 375–398.",
      "citeRegEx" : "MAREK and TRUSZCZYŃSKI,? 1999",
      "shortCiteRegEx" : "MAREK and TRUSZCZYŃSKI",
      "year" : 1999
    }, {
      "title" : "ADOPT: Asynchronous distributed constraint optimization with quality guarantees",
      "author" : [ "P. MODI", "SHEN", "W.-M.", "M. TAMBE", "M. YOKOO" ],
      "venue" : "Artificial Intelligence 161, 1–2, 149–180.",
      "citeRegEx" : "MODI et al\\.,? 2005",
      "shortCiteRegEx" : "MODI et al\\.",
      "year" : 2005
    }, {
      "title" : "Distributed Gibbs: A memory-bounded sampling-based DCOP algorithm",
      "author" : [ "D.T. NGUYEN", "W. YEOH", "LAU", "H.C." ],
      "venue" : "Proc. of AAMAS. 167–174.",
      "citeRegEx" : "NGUYEN et al\\.,? 2013",
      "shortCiteRegEx" : "NGUYEN et al\\.",
      "year" : 2013
    }, {
      "title" : "Logic programming with stable model semantics as a constraint programming paradigm",
      "author" : [ "I. NIEMELÄ" ],
      "venue" : "Annals of Mathematics and Artificial Intelligence 25, 3–4, 241–273.",
      "citeRegEx" : "NIEMELÄ,? 1999",
      "shortCiteRegEx" : "NIEMELÄ",
      "year" : 1999
    }, {
      "title" : "DUCT: An upper confidence bound approach to distributed constraint optimization problems",
      "author" : [ "B. OTTENS", "C. DIMITRAKAKIS", "B. FALTINGS" ],
      "venue" : "Proc. of AAAI. 528–534.",
      "citeRegEx" : "OTTENS et al\\.,? 2012",
      "shortCiteRegEx" : "OTTENS et al\\.",
      "year" : 2012
    }, {
      "title" : "A Class of Algorithms for Distributed Constraint Optimization",
      "author" : [ "A. PETCU" ],
      "venue" : "Frontiers in Artificial Intelligence and Applications, vol. 194. IOS Press.",
      "citeRegEx" : "PETCU,? 2009",
      "shortCiteRegEx" : "PETCU",
      "year" : 2009
    }, {
      "title" : "A scalable method for multiagent constraint optimization",
      "author" : [ "A. PETCU", "B. FALTINGS" ],
      "venue" : "Proc. of IJCAI. 1413–1420.",
      "citeRegEx" : "PETCU and FALTINGS,? 2005a",
      "shortCiteRegEx" : "PETCU and FALTINGS",
      "year" : 2005
    }, {
      "title" : "Superstabilizing, fault-containing multiagent combinatorial optimization",
      "author" : [ "A. PETCU", "B. FALTINGS" ],
      "venue" : "Proc. of AAAI. 449–454.",
      "citeRegEx" : "PETCU and FALTINGS,? 2005b",
      "shortCiteRegEx" : "PETCU and FALTINGS",
      "year" : 2005
    }, {
      "title" : "ODPOP: an algorithm for open/distributed constraint optimization",
      "author" : [ "A. PETCU", "B. FALTINGS" ],
      "venue" : "Proceedings, The Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference, July 16-20, 2006, Boston, Massachusetts, USA. 703–708.",
      "citeRegEx" : "PETCU and FALTINGS,? 2006",
      "shortCiteRegEx" : "PETCU and FALTINGS",
      "year" : 2006
    }, {
      "title" : "MB-DPOP: A new memory-bounded algorithm for distributed optimization",
      "author" : [ "A. PETCU", "B. FALTINGS" ],
      "venue" : "Proc. of IJCAI. 1452–1457.",
      "citeRegEx" : "PETCU and FALTINGS,? 2007",
      "shortCiteRegEx" : "PETCU and FALTINGS",
      "year" : 2007
    }, {
      "title" : "PC-DPOP: A new partial centralization algorithm for distributed optimization",
      "author" : [ "A. PETCU", "B. FALTINGS", "R. MAILLER" ],
      "venue" : "Proc. of IJCAI. 167–172.",
      "citeRegEx" : "PETCU et al\\.,? 2007",
      "shortCiteRegEx" : "PETCU et al\\.",
      "year" : 2007
    }, {
      "title" : "M-DPOP: Faithful distributed implementation of efficient social choice problems",
      "author" : [ "A. PETCU", "B. FALTINGS", "D. PARKES" ],
      "venue" : "Journal of Artificial Intelligence Research 32, 705–755.",
      "citeRegEx" : "PETCU et al\\.,? 2008",
      "shortCiteRegEx" : "PETCU et al\\.",
      "year" : 2008
    }, {
      "title" : "Logic programming for finding models in the logics of knowledge and its applications: A case study",
      "author" : [ "E. PONTELLI", "T.C. SON", "C. BARAL", "G. GELFOND" ],
      "venue" : "Theory and Practice of Logic Programming 10, 4-6, 675–690.",
      "citeRegEx" : "PONTELLI et al\\.,? 2010",
      "shortCiteRegEx" : "PONTELLI et al\\.",
      "year" : 2010
    }, {
      "title" : "Abductive logic programming for communication and negotiation amongst agents",
      "author" : [ "F. SADRI", "F. TONI" ],
      "venue" : "ALP Newsletter.",
      "citeRegEx" : "SADRI and TONI,? 2003",
      "shortCiteRegEx" : "SADRI and TONI",
      "year" : 2003
    }, {
      "title" : "A logical formulation for negotiation among dishonest agents",
      "author" : [ "C. SAKAMA", "T.C. SON", "E. PONTELLI" ],
      "venue" : "Proc. of IJCAI. 1069–1074.",
      "citeRegEx" : "SAKAMA et al\\.,? 2011",
      "shortCiteRegEx" : "SAKAMA et al\\.",
      "year" : 2011
    }, {
      "title" : "Logic programming for multiagent planning with negotiation",
      "author" : [ "T.C. SON", "E. PONTELLI", "C. SAKAMA" ],
      "venue" : "Proc. of ICLP. 99–114.",
      "citeRegEx" : "SON et al\\.,? 2009",
      "shortCiteRegEx" : "SON et al\\.",
      "year" : 2009
    }, {
      "title" : "DCOPolis: a framework for simulating and deploying distributed constraint reasoning algorithms",
      "author" : [ "E. SULTANIK", "R. LASS", "W. REGLI" ],
      "venue" : "Proc. of the Distributed Constraint Reasoning Workshop.",
      "citeRegEx" : "SULTANIK et al\\.,? 2007",
      "shortCiteRegEx" : "SULTANIK et al\\.",
      "year" : 2007
    }, {
      "title" : "Coalition structure generation based on distributed constraint optimization",
      "author" : [ "S. UEDA", "A. IWASAKI", "M. YOKOO" ],
      "venue" : "Proc. of AAAI. 197–203.",
      "citeRegEx" : "UEDA et al\\.,? 2010",
      "shortCiteRegEx" : "UEDA et al\\.",
      "year" : 2010
    }, {
      "title" : "Constructing a unifying theory of dynamic programming DCOP algorithms via the generalized distributive law",
      "author" : [ "M. VINYALS", "J. RODRÍGUEZ-AGUILAR", "J. CERQUIDES" ],
      "venue" : "Autonomous Agents and Multi-Agent Systems 22, 3, 439–464.",
      "citeRegEx" : "VINYALS et al\\.,? 2011",
      "shortCiteRegEx" : "VINYALS et al\\.",
      "year" : 2011
    }, {
      "title" : "MACLP: Multi Agent Constraint Logic Programming",
      "author" : [ "I. VLAHAVAS" ],
      "venue" : "Information Sciences 144, 1-4, 127–142.",
      "citeRegEx" : "VLAHAVAS,? 2002",
      "shortCiteRegEx" : "VLAHAVAS",
      "year" : 2002
    }, {
      "title" : "BnB-ADOPT: An asynchronous branch-andbound DCOP algorithm",
      "author" : [ "W. YEOH", "A. FELNER", "S. KOENIG" ],
      "venue" : "Journal of Artificial Intelligence Research 38, 85–133.",
      "citeRegEx" : "YEOH et al\\.,? 2010",
      "shortCiteRegEx" : "YEOH et al\\.",
      "year" : 2010
    }, {
      "title" : "Caching schemes for DCOP search algorithms",
      "author" : [ "W. YEOH", "P. VARAKANTHAM", "S. KOENIG" ],
      "venue" : "Proc. of AAMAS. 609–616.",
      "citeRegEx" : "YEOH et al\\.,? 2009",
      "shortCiteRegEx" : "YEOH et al\\.",
      "year" : 2009
    }, {
      "title" : "Distributed problem solving",
      "author" : [ "W. YEOH", "M. YOKOO" ],
      "venue" : "AI Magazine 33, 3, 53–65.",
      "citeRegEx" : "YEOH and YOKOO,? 2012",
      "shortCiteRegEx" : "YEOH and YOKOO",
      "year" : 2012
    }, {
      "title" : "Explorative anytime local search for distributed constraint optimization",
      "author" : [ "R. ZIVAN", "S. OKAMOTO", "H. PELED" ],
      "venue" : "Artificial Intelligence 212, 1–26.",
      "citeRegEx" : "ZIVAN et al\\.,? 2014",
      "shortCiteRegEx" : "ZIVAN et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 45,
      "context" : "Distributed Constraint Optimization Problems (DCOPs) are optimization problems where agents need to coordinate the assignment of values to their “local” variables to maximize the overall sum of resulting constraint utilities (Modi et al. 2005; Petcu and Faltings 2005a; Mailler and Lesser 2004; Yeoh and Yokoo 2012).",
      "startOffset" : 225,
      "endOffset" : 315
    }, {
      "referenceID" : 50,
      "context" : "Distributed Constraint Optimization Problems (DCOPs) are optimization problems where agents need to coordinate the assignment of values to their “local” variables to maximize the overall sum of resulting constraint utilities (Modi et al. 2005; Petcu and Faltings 2005a; Mailler and Lesser 2004; Yeoh and Yokoo 2012).",
      "startOffset" : 225,
      "endOffset" : 315
    }, {
      "referenceID" : 43,
      "context" : "Distributed Constraint Optimization Problems (DCOPs) are optimization problems where agents need to coordinate the assignment of values to their “local” variables to maximize the overall sum of resulting constraint utilities (Modi et al. 2005; Petcu and Faltings 2005a; Mailler and Lesser 2004; Yeoh and Yokoo 2012).",
      "startOffset" : 225,
      "endOffset" : 315
    }, {
      "referenceID" : 66,
      "context" : "Distributed Constraint Optimization Problems (DCOPs) are optimization problems where agents need to coordinate the assignment of values to their “local” variables to maximize the overall sum of resulting constraint utilities (Modi et al. 2005; Petcu and Faltings 2005a; Mailler and Lesser 2004; Yeoh and Yokoo 2012).",
      "startOffset" : 225,
      "endOffset" : 315
    }, {
      "referenceID" : 41,
      "context" : "Researchers have used DCOPs to model various problems, such as the distributed scheduling of meetings (Maheswaran et al. 2004; Zivan et al. 2014), distributed allocation of targets to sensors in a network (Farinelli et al.",
      "startOffset" : 102,
      "endOffset" : 145
    }, {
      "referenceID" : 67,
      "context" : "Researchers have used DCOPs to model various problems, such as the distributed scheduling of meetings (Maheswaran et al. 2004; Zivan et al. 2014), distributed allocation of targets to sensors in a network (Farinelli et al.",
      "startOffset" : 102,
      "endOffset" : 145
    }, {
      "referenceID" : 11,
      "context" : "2014), distributed allocation of targets to sensors in a network (Farinelli et al. 2008), distributed allocation of resources in disaster evacuation scenarios (Lass et al.",
      "startOffset" : 65,
      "endOffset" : 88
    }, {
      "referenceID" : 35,
      "context" : "2008), distributed allocation of resources in disaster evacuation scenarios (Lass et al. 2008), the distributed management of power distribution networks (Kumar et al.",
      "startOffset" : 76,
      "endOffset" : 94
    }, {
      "referenceID" : 33,
      "context" : "2008), the distributed management of power distribution networks (Kumar et al. 2009; Jain et al. 2012), the distributed generation of coalition structures (Ueda et al.",
      "startOffset" : 65,
      "endOffset" : 102
    }, {
      "referenceID" : 29,
      "context" : "2008), the distributed management of power distribution networks (Kumar et al. 2009; Jain et al. 2012), the distributed generation of coalition structures (Ueda et al.",
      "startOffset" : 65,
      "endOffset" : 102
    }, {
      "referenceID" : 61,
      "context" : "2012), the distributed generation of coalition structures (Ueda et al. 2010) and the distributed coordination of logistics operations (Léauté and Faltings 2011).",
      "startOffset" : 58,
      "endOffset" : 76
    }, {
      "referenceID" : 37,
      "context" : "1 This article extends our previous conference paper (Le et al. 2015) in the following manner: (1) It provides a more thorough description of the ASP-DPOP algorithm; (2) It elaborates on the algorithm’s theoretical properties with complete proofs; and (3) It includes additional experimental results.",
      "startOffset" : 53,
      "endOffset" : 69
    }, {
      "referenceID" : 45,
      "context" : "The field has matured considerably over the past decade, since the seminal ADOPT paper (Modi et al. 2005), as researchers continue to develop more sophisticated solving algorithms.",
      "startOffset" : 87,
      "endOffset" : 105
    }, {
      "referenceID" : 45,
      "context" : "The majority of the DCOP resolution algorithms can be classified in one of three classes: (1) Search-based algorithms, like ADOPT (Modi et al. 2005) and its variants (Yeoh et al.",
      "startOffset" : 130,
      "endOffset" : 148
    }, {
      "referenceID" : 65,
      "context" : "2005) and its variants (Yeoh et al. 2009; Yeoh et al. 2010; Gutierrez et al. 2011; Gutierrez et al. 2013), AFB (Gershman et al.",
      "startOffset" : 23,
      "endOffset" : 105
    }, {
      "referenceID" : 64,
      "context" : "2005) and its variants (Yeoh et al. 2009; Yeoh et al. 2010; Gutierrez et al. 2011; Gutierrez et al. 2013), AFB (Gershman et al.",
      "startOffset" : 23,
      "endOffset" : 105
    }, {
      "referenceID" : 26,
      "context" : "2005) and its variants (Yeoh et al. 2009; Yeoh et al. 2010; Gutierrez et al. 2011; Gutierrez et al. 2013), AFB (Gershman et al.",
      "startOffset" : 23,
      "endOffset" : 105
    }, {
      "referenceID" : 21,
      "context" : "2013), AFB (Gershman et al. 2009), and MGM (Maheswaran et al.",
      "startOffset" : 11,
      "endOffset" : 33
    }, {
      "referenceID" : 41,
      "context" : "2009), and MGM (Maheswaran et al. 2004), where the agents enumerate combinations of value assignments in a decentralized manner; (2) Inference-based algorithms, like DPOP (Petcu and Faltings 2005a) and its variants (Petcu and Faltings 2005b; Petcu and Faltings 2007; Petcu et al.",
      "startOffset" : 15,
      "endOffset" : 39
    }, {
      "referenceID" : 50,
      "context" : "2004), where the agents enumerate combinations of value assignments in a decentralized manner; (2) Inference-based algorithms, like DPOP (Petcu and Faltings 2005a) and its variants (Petcu and Faltings 2005b; Petcu and Faltings 2007; Petcu et al.",
      "startOffset" : 137,
      "endOffset" : 163
    }, {
      "referenceID" : 51,
      "context" : "2004), where the agents enumerate combinations of value assignments in a decentralized manner; (2) Inference-based algorithms, like DPOP (Petcu and Faltings 2005a) and its variants (Petcu and Faltings 2005b; Petcu and Faltings 2007; Petcu et al. 2007; Petcu et al. 2008), max-sum (Farinelli et al.",
      "startOffset" : 181,
      "endOffset" : 270
    }, {
      "referenceID" : 53,
      "context" : "2004), where the agents enumerate combinations of value assignments in a decentralized manner; (2) Inference-based algorithms, like DPOP (Petcu and Faltings 2005a) and its variants (Petcu and Faltings 2005b; Petcu and Faltings 2007; Petcu et al. 2007; Petcu et al. 2008), max-sum (Farinelli et al.",
      "startOffset" : 181,
      "endOffset" : 270
    }, {
      "referenceID" : 54,
      "context" : "2004), where the agents enumerate combinations of value assignments in a decentralized manner; (2) Inference-based algorithms, like DPOP (Petcu and Faltings 2005a) and its variants (Petcu and Faltings 2005b; Petcu and Faltings 2007; Petcu et al. 2007; Petcu et al. 2008), max-sum (Farinelli et al.",
      "startOffset" : 181,
      "endOffset" : 270
    }, {
      "referenceID" : 55,
      "context" : "2004), where the agents enumerate combinations of value assignments in a decentralized manner; (2) Inference-based algorithms, like DPOP (Petcu and Faltings 2005a) and its variants (Petcu and Faltings 2005b; Petcu and Faltings 2007; Petcu et al. 2007; Petcu et al. 2008), max-sum (Farinelli et al.",
      "startOffset" : 181,
      "endOffset" : 270
    }, {
      "referenceID" : 11,
      "context" : "2008), max-sum (Farinelli et al. 2008), and Action GDL (Vinyals et al.",
      "startOffset" : 15,
      "endOffset" : 38
    }, {
      "referenceID" : 62,
      "context" : "2008), and Action GDL (Vinyals et al. 2011), where the agents use dynamic programming techniques to propagate aggregated information to other agents; and (3) Sampling-based algorithms, like DUCT (Ottens et al.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 48,
      "context" : "2011), where the agents use dynamic programming techniques to propagate aggregated information to other agents; and (3) Sampling-based algorithms, like DUCT (Ottens et al. 2012) and D-Gibbs (Nguyen et al.",
      "startOffset" : 157,
      "endOffset" : 177
    }, {
      "referenceID" : 46,
      "context" : "2012) and D-Gibbs (Nguyen et al. 2013; Fioretto et al. 2014), where the agents sample the search space in a decentralized manner.",
      "startOffset" : 18,
      "endOffset" : 60
    }, {
      "referenceID" : 12,
      "context" : "2012) and D-Gibbs (Nguyen et al. 2013; Fioretto et al. 2014), where the agents sample the search space in a decentralized manner.",
      "startOffset" : 18,
      "endOffset" : 60
    }, {
      "referenceID" : 50,
      "context" : "Specifically, we propose an integration of Distributed Pseudo-tree Optimization Procedure (DPOP) (Petcu and Faltings 2005a), a popular DCOP algorithm, with Answer Set Programming (ASP) (Niemelä 1999; Marek and Truszczyński 1999) as the local constraint solver of each agent.",
      "startOffset" : 97,
      "endOffset" : 123
    }, {
      "referenceID" : 45,
      "context" : "A Distributed Constraint Optimization Problem (DCOP) (Modi et al. 2005; Petcu and Faltings 2005a; Mailler and Lesser 2004; Yeoh and Yokoo 2012) can be described as a tupleM = 〈X ,D,F ,A, α〉 where:",
      "startOffset" : 53,
      "endOffset" : 143
    }, {
      "referenceID" : 50,
      "context" : "A Distributed Constraint Optimization Problem (DCOP) (Modi et al. 2005; Petcu and Faltings 2005a; Mailler and Lesser 2004; Yeoh and Yokoo 2012) can be described as a tupleM = 〈X ,D,F ,A, α〉 where:",
      "startOffset" : 53,
      "endOffset" : 143
    }, {
      "referenceID" : 43,
      "context" : "A Distributed Constraint Optimization Problem (DCOP) (Modi et al. 2005; Petcu and Faltings 2005a; Mailler and Lesser 2004; Yeoh and Yokoo 2012) can be described as a tupleM = 〈X ,D,F ,A, α〉 where:",
      "startOffset" : 53,
      "endOffset" : 143
    }, {
      "referenceID" : 66,
      "context" : "A Distributed Constraint Optimization Problem (DCOP) (Modi et al. 2005; Petcu and Faltings 2005a; Mailler and Lesser 2004; Yeoh and Yokoo 2012) can be described as a tupleM = 〈X ,D,F ,A, α〉 where:",
      "startOffset" : 53,
      "endOffset" : 143
    }, {
      "referenceID" : 27,
      "context" : "A pseudotree of a DCOP can be constructed using distributed DFS algorithms (Hamadi et al. 1998) applied to the constraint graph of the DCOP.",
      "startOffset" : 75,
      "endOffset" : 95
    }, {
      "referenceID" : 50,
      "context" : "The Distributed Pseudo-tree Optimization Procedure (DPOP) (Petcu and Faltings 2005a) is a complete algorithm to solve DCOPs with the following three phases: Pseudo-tree generation, UTIL propagation and VALUE propagation.",
      "startOffset" : 58,
      "endOffset" : 84
    }, {
      "referenceID" : 60,
      "context" : "However, in many implementations of DPOP, including those within the DCOPolis (Sultanik et al. 2007) and FRODO (Léauté et al.",
      "startOffset" : 78,
      "endOffset" : 100
    }, {
      "referenceID" : 27,
      "context" : "2009) repositories, greedy approaches such as the Distributed DFS algorithm (Hamadi et al. 1998) are used.",
      "startOffset" : 76,
      "endOffset" : 96
    }, {
      "referenceID" : 50,
      "context" : "3 Here we detail an extended version of DPOP described in (Petcu and Faltings 2005a) which removes the assumption that each agent owns exactly one variable.",
      "startOffset" : 58,
      "endOffset" : 84
    }, {
      "referenceID" : 49,
      "context" : "Definition 3 (UTIL Messages (Petcu 2009)) UTIL aj ai , the UTIL message sent by agent ai to agent aj , is a multi-dimensional matrix, with one dimension for each variable in sepi.",
      "startOffset" : 28,
      "endOffset" : 40
    }, {
      "referenceID" : 0,
      "context" : "Let us provide some general background on Answer Set Programming (ASP) (see, for example, (Baral 2003; Gelfond and Kahl 2014) for more details).",
      "startOffset" : 90,
      "endOffset" : 125
    }, {
      "referenceID" : 19,
      "context" : "Let us provide some general background on Answer Set Programming (ASP) (see, for example, (Baral 2003; Gelfond and Kahl 2014) for more details).",
      "startOffset" : 90,
      "endOffset" : 125
    }, {
      "referenceID" : 20,
      "context" : "S is an answer set (or a stable model) of a ground program Π (Gelfond and Lifschitz 1990) if it satisfies the following conditions: (i) If Π does not contain any naf-literal (i.",
      "startOffset" : 61,
      "endOffset" : 89
    }, {
      "referenceID" : 17,
      "context" : "Standard syntax for choice rules has been proposed and adopted in most stateof-the-art ASP solvers, such as CLASP (Gebser et al. 2007) and DLV (Citrigno et al.",
      "startOffset" : 114,
      "endOffset" : 134
    }, {
      "referenceID" : 4,
      "context" : "2007) and DLV (Citrigno et al. 1997).",
      "startOffset" : 14,
      "endOffset" : 36
    }, {
      "referenceID" : 16,
      "context" : ", GRINGO (Gebser et al. 2011).",
      "startOffset" : 9,
      "endOffset" : 29
    }, {
      "referenceID" : 17,
      "context" : ", CLASP (Gebser et al. 2007).",
      "startOffset" : 8,
      "endOffset" : 28
    }, {
      "referenceID" : 15,
      "context" : "For readers who are interested in how to solve an answer set program, the foundations and algorithms underlying the grounding and solving technology used in GRINGO and CLASP are described in detail in (Gebser et al. 2012; Kaufmann et al. 2016).",
      "startOffset" : 201,
      "endOffset" : 243
    }, {
      "referenceID" : 31,
      "context" : "For readers who are interested in how to solve an answer set program, the foundations and algorithms underlying the grounding and solving technology used in GRINGO and CLASP are described in detail in (Gebser et al. 2012; Kaufmann et al. 2016).",
      "startOffset" : 201,
      "endOffset" : 243
    }, {
      "referenceID" : 17,
      "context" : "In ASP-DPOP, we use CLASP (Gebser et al. 2007), with its companion grounder GRINGO, as our ASP solver, being the current state-of-the-art for ASP.",
      "startOffset" : 26,
      "endOffset" : 46
    }, {
      "referenceID" : 6,
      "context" : "8 w∗ is also known as the induced width of a pseudo-tree (Dechter 2003).",
      "startOffset" : 57,
      "endOffset" : 71
    }, {
      "referenceID" : 50,
      "context" : "Therefore, the size of encoded UTIL messages is bounded by O(dw) as the bounded size of UTIL messages in DPOP (Petcu and Faltings 2005a); and • Phase 3 produces encoded VALUE messages; each message consists of a fact of the form solution/3 for each value assignment of a variable in the corresponding VALUE message in DPOP.",
      "startOffset" : 110,
      "endOffset" : 136
    }, {
      "referenceID" : 21,
      "context" : "AFB (Gershman et al. 2009) is a complete search-based algorithm to solve DCOPs.",
      "startOffset" : 4,
      "endOffset" : 26
    }, {
      "referenceID" : 34,
      "context" : "H-DPOP (Kumar et al. 2008) is a complete DCOP solver that, in addition, propagates hard constraints to prune the search space.",
      "startOffset" : 7,
      "endOffset" : 26
    }, {
      "referenceID" : 52,
      "context" : "ODPOP (Petcu and Faltings 2006) is an optimization algorithm for DCOPs, which combines some advantages of both search-based algorithms and dynamic-programming-based algorithms.",
      "startOffset" : 6,
      "endOffset" : 31
    }, {
      "referenceID" : 21,
      "context" : "The asynchronous forward-bounding algorithm (AFB) (Gershman et al. 2009), to the best of our knowledge, is the most recent complete search-based algorithm to solve DCOPs.",
      "startOffset" : 50,
      "endOffset" : 72
    }, {
      "referenceID" : 34,
      "context" : "In H-DPOP (Kumar et al. 2008), the authors consider how to leverage the hard constraints that may exist in the problem in a dynamic programming framework, so that only feasible partial assignments are computed, transmitted, and stored (Kumar et al.",
      "startOffset" : 10,
      "endOffset" : 29
    }, {
      "referenceID" : 34,
      "context" : "2008), the authors consider how to leverage the hard constraints that may exist in the problem in a dynamic programming framework, so that only feasible partial assignments are computed, transmitted, and stored (Kumar et al. 2008).",
      "startOffset" : 211,
      "endOffset" : 230
    }, {
      "referenceID" : 52,
      "context" : "ODPOP (Petcu and Faltings 2006) is an optimization algorithm for DCOP, which combines some advantages of both search-based algorithms and dynamic-programming-based algorithms.",
      "startOffset" : 6,
      "endOffset" : 31
    }, {
      "referenceID" : 45,
      "context" : "This assumption is common practice in the DCOP literature (Modi et al. 2005; Petcu and Faltings 2005a; Gershman et al. 2009; Ottens et al. 2012).",
      "startOffset" : 58,
      "endOffset" : 144
    }, {
      "referenceID" : 50,
      "context" : "This assumption is common practice in the DCOP literature (Modi et al. 2005; Petcu and Faltings 2005a; Gershman et al. 2009; Ottens et al. 2012).",
      "startOffset" : 58,
      "endOffset" : 144
    }, {
      "referenceID" : 21,
      "context" : "This assumption is common practice in the DCOP literature (Modi et al. 2005; Petcu and Faltings 2005a; Gershman et al. 2009; Ottens et al. 2012).",
      "startOffset" : 58,
      "endOffset" : 144
    }, {
      "referenceID" : 48,
      "context" : "This assumption is common practice in the DCOP literature (Modi et al. 2005; Petcu and Faltings 2005a; Gershman et al. 2009; Ottens et al. 2012).",
      "startOffset" : 58,
      "endOffset" : 144
    }, {
      "referenceID" : 50,
      "context" : "In our experiments, we compare both versions of ASP-DPOP against DPOP (Petcu and Faltings 2005a), H-DPOP (Kumar et al.",
      "startOffset" : 70,
      "endOffset" : 96
    }, {
      "referenceID" : 34,
      "context" : "In our experiments, we compare both versions of ASP-DPOP against DPOP (Petcu and Faltings 2005a), H-DPOP (Kumar et al. 2008), PH-DPOP, AFB (Gershman et al.",
      "startOffset" : 105,
      "endOffset" : 124
    }, {
      "referenceID" : 21,
      "context" : "2008), PH-DPOP, AFB (Gershman et al. 2009), and ODPOP (Petcu and Faltings 2006).",
      "startOffset" : 20,
      "endOffset" : 42
    }, {
      "referenceID" : 52,
      "context" : "2009), and ODPOP (Petcu and Faltings 2006).",
      "startOffset" : 17,
      "endOffset" : 42
    }, {
      "referenceID" : 60,
      "context" : "simulated runtime metric (Sultanik et al. 2007).",
      "startOffset" : 25,
      "endOffset" : 47
    }, {
      "referenceID" : 23,
      "context" : "We conduct our experiments on random graphs (Erdös and Rényi 1959), where we systematically modify the domain-independent parameters, and on comprehensive optimization problems in power networks (Gupta et al. 2013).",
      "startOffset" : 195,
      "endOffset" : 214
    }, {
      "referenceID" : 29,
      "context" : ", load shedding, demand response, restoration) (Jain et al. 2012).",
      "startOffset" : 47,
      "endOffset" : 65
    }, {
      "referenceID" : 15,
      "context" : "Readers who are interested in such algorithms and computations can find further information in (Gebser et al. 2012; Kaufmann et al. 2016).",
      "startOffset" : 95,
      "endOffset" : 137
    }, {
      "referenceID" : 31,
      "context" : "Readers who are interested in such algorithms and computations can find further information in (Gebser et al. 2012; Kaufmann et al. 2016).",
      "startOffset" : 95,
      "endOffset" : 137
    }, {
      "referenceID" : 14,
      "context" : "Solving DCOPs with multiple variables per agent without transforming them to problems with a single variable per agent was also investigated in (Fioretto et al. 2016).",
      "startOffset" : 144,
      "endOffset" : 166
    }, {
      "referenceID" : 22,
      "context" : "A detailed analysis of privacy loss in DCOP for some existing DCOP algorithms, including DPOP, can be found in (Greenstadt et al. 2006).",
      "startOffset" : 111,
      "endOffset" : 135
    }, {
      "referenceID" : 32,
      "context" : "Starting with some seminal papers (Kowalski and Sadri 1999), various authors have explored the use of several different flavors of logic programming, such as normal logic programs and abductive logic programs, to address cooperation between agents (Kakas et al.",
      "startOffset" : 34,
      "endOffset" : 59
    }, {
      "referenceID" : 30,
      "context" : "Starting with some seminal papers (Kowalski and Sadri 1999), various authors have explored the use of several different flavors of logic programming, such as normal logic programs and abductive logic programs, to address cooperation between agents (Kakas et al. 2004; Sadri and Toni 2003; Gelfond and Watson 2007; De Vos et al. 2005).",
      "startOffset" : 248,
      "endOffset" : 333
    }, {
      "referenceID" : 57,
      "context" : "Starting with some seminal papers (Kowalski and Sadri 1999), various authors have explored the use of several different flavors of logic programming, such as normal logic programs and abductive logic programs, to address cooperation between agents (Kakas et al. 2004; Sadri and Toni 2003; Gelfond and Watson 2007; De Vos et al. 2005).",
      "startOffset" : 248,
      "endOffset" : 333
    }, {
      "referenceID" : 18,
      "context" : "Starting with some seminal papers (Kowalski and Sadri 1999), various authors have explored the use of several different flavors of logic programming, such as normal logic programs and abductive logic programs, to address cooperation between agents (Kakas et al. 2004; Sadri and Toni 2003; Gelfond and Watson 2007; De Vos et al. 2005).",
      "startOffset" : 248,
      "endOffset" : 333
    }, {
      "referenceID" : 9,
      "context" : "Some proposals have also explored the combination between constraint programming, logic programming, and formalization of multi-agent domains (Dovier et al. 2013; Vlahavas 2002; Dovier et al. 2010a; Dovier et al. 2010b).",
      "startOffset" : 142,
      "endOffset" : 219
    }, {
      "referenceID" : 63,
      "context" : "Some proposals have also explored the combination between constraint programming, logic programming, and formalization of multi-agent domains (Dovier et al. 2013; Vlahavas 2002; Dovier et al. 2010a; Dovier et al. 2010b).",
      "startOffset" : 142,
      "endOffset" : 219
    }, {
      "referenceID" : 7,
      "context" : "Some proposals have also explored the combination between constraint programming, logic programming, and formalization of multi-agent domains (Dovier et al. 2013; Vlahavas 2002; Dovier et al. 2010a; Dovier et al. 2010b).",
      "startOffset" : 142,
      "endOffset" : 219
    }, {
      "referenceID" : 8,
      "context" : "Some proposals have also explored the combination between constraint programming, logic programming, and formalization of multi-agent domains (Dovier et al. 2013; Vlahavas 2002; Dovier et al. 2010a; Dovier et al. 2010b).",
      "startOffset" : 142,
      "endOffset" : 219
    }, {
      "referenceID" : 1,
      "context" : "Logic programming has been used in modeling multi-agent scenarios involving agents knowledge about other’s knowledge (Baral et al. 2010), computing models in the logics of knowledge (Pontelli et al.",
      "startOffset" : 117,
      "endOffset" : 136
    }, {
      "referenceID" : 56,
      "context" : "2010), computing models in the logics of knowledge (Pontelli et al. 2010), multi-agent planning (Son et al.",
      "startOffset" : 51,
      "endOffset" : 73
    }, {
      "referenceID" : 59,
      "context" : "2010), multi-agent planning (Son et al. 2009) and formalizing negotiation (Sakama et al.",
      "startOffset" : 28,
      "endOffset" : 45
    }, {
      "referenceID" : 58,
      "context" : "2009) and formalizing negotiation (Sakama et al. 2011).",
      "startOffset" : 34,
      "endOffset" : 54
    }, {
      "referenceID" : 34,
      "context" : "Existing DCOP algorithms that also propagate hard and soft constraints to prune the search space include H-DPOP that propagates exclusively hard constraints (Kumar et al. 2008), BrC-DPOP that propagates branch consistency (Fioretto et al.",
      "startOffset" : 157,
      "endOffset" : 176
    }, {
      "referenceID" : 12,
      "context" : "2008), BrC-DPOP that propagates branch consistency (Fioretto et al. 2014), and variants of BnB-ADOPT (Yeoh et al.",
      "startOffset" : 51,
      "endOffset" : 73
    }, {
      "referenceID" : 64,
      "context" : "2014), and variants of BnB-ADOPT (Yeoh et al. 2010; Gutierrez and Meseguer 2012b; Gutierrez et al. 2011) that maintains soft-arc consistency (Bessiere et al.",
      "startOffset" : 33,
      "endOffset" : 104
    }, {
      "referenceID" : 25,
      "context" : "2014), and variants of BnB-ADOPT (Yeoh et al. 2010; Gutierrez and Meseguer 2012b; Gutierrez et al. 2011) that maintains soft-arc consistency (Bessiere et al.",
      "startOffset" : 33,
      "endOffset" : 104
    }, {
      "referenceID" : 26,
      "context" : "2014), and variants of BnB-ADOPT (Yeoh et al. 2010; Gutierrez and Meseguer 2012b; Gutierrez et al. 2011) that maintains soft-arc consistency (Bessiere et al.",
      "startOffset" : 33,
      "endOffset" : 104
    }, {
      "referenceID" : 2,
      "context" : "2011) that maintains soft-arc consistency (Bessiere et al. 2012; Gutierrez and Meseguer 2012a; Gutierrez et al. 2013).",
      "startOffset" : 42,
      "endOffset" : 117
    }, {
      "referenceID" : 28,
      "context" : "One possibility is to use Constraint Logic Programming (CLP) (Jaffar and Maher 1994) instead of ASP.",
      "startOffset" : 61,
      "endOffset" : 84
    }, {
      "referenceID" : 36,
      "context" : "A preliminary investigation (Le et al. 2014) has shown that this technique can dramatically decrease run time.",
      "startOffset" : 28,
      "endOffset" : 44
    } ],
    "year" : 2017,
    "abstractText" : "This paper explores the use of Answer Set Programming (ASP) in solving Distributed Constraint Optimization Problems (DCOPs). The paper provides the following novel contributions: (1) It shows how one can formulate DCOPs as logic programs; (2) It introduces ASP-DPOP, the first DCOP algorithm that is based on logic programming; (3) It experimentally shows that ASP-DPOP can be up to two orders of magnitude faster than DPOP (its imperative programming counterpart) as well as solve some problems that DPOP fails to solve, due to memory limitations; and (4) It demonstrates the applicability of ASP in a wide array of multi-agent problems currently modeled as DCOPs. Under consideration in Theory and Practice of Logic Programming (TPLP).",
    "creator" : "LaTeX with hyperref package"
  }
}