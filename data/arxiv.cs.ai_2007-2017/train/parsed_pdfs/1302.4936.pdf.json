{
  "name" : "1302.4936.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Practical model-based diagnosis with qualitative possibilistic uncertainty",
    "authors" : [ "Didier Cayrac", "Didier Dubois", "Henri Prade" ],
    "emails" : [ "@irit.irit.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 INTRODUCTION AND RATIONALE\nDeveloping models of systems that are both expressive enough to support effective diagnosis and cheap enough to keep knowledge acquisition cost affordable in real world contexts remains an open problem. This seems to prevent a wide acceptance of model-based diagnosis in industry. Models of the system to be diagnosed traditionally consist of a description of its structure, in terms of components linked together, and of a description of the behavior of the individual components. On the one hand, acquisition of the structure is \"cheap\", as it can often be derived directly from design information (the detection of faults altering the structure of the system cannot be handled in this framework). On the other hand, the behavior of the individual components of the system is much more difficult to model in an appropriate way. Two approaches are usually followed: the correct behavior and I or the fault modes of each component are represented. The representation choice is conditioned to a large extent by the diagnostic approach chosen: consistency-based or abductive.\nConsistency-based diagnosis (Davis and Hamscher, 1988, deKleer and Williams, 1987) exploit a nominal behavior\nmodel to derive explanations that allow the restoration of the consistency of the predicted behavior with the observations. This approach requires an expensive model because it must allow an effective detection of the discrepancies between predicted and observed behaviors (i.e., real anomalies are indeed detected, and there are few spurious ones). We believe that the cost of a model capable of such a high quality simulation (and expressed in first order logic) would be prohibitive for most real world applications (except maybe digital circuitry), if it were even feasible.\nAbductive diagnosis (Poole, 1989) relies on a causal model between faults and manifestations, and looks for explanations (faults) that cause, or \"cover\" the symptoms observed. Explanation as consistency is a weaker notion than explanation as covering: the consistent explanations form a superset of the abductive explanations. Abductive diagnosis requires completeness of the identified fault modes (Console and Torasso, 1990). Proposals for handling incompleteness (Console et al., 1989) still require the identification of all possible sources of incompleteness, at the level of each rule, which makes their application unfit to vastly incomplete models.\nIf all observations were to be explained abductively, a model of the nominal and fault behavior of the system that is just as fine as for the consistency-based approach would be required. However, Console and Torasso also show that if only part of the observations (for instance, the abnormal ones) need to be abductively explained, a model describing how anomalies are propagated is sufficient.\nSection 2 distinguishes between fault detection and fault isolation, which require different kinds of knowledge. The approach to fault isolation we outline exploits vastly incomplete models, and allows the identification of fault modes which are not explicitly described. An ordinal representation of uncertainty based on possibility theory allows a qualitative and incomplete description of the component behaviors, at an appropriate level of abstraction. Section 3 presents the possibilistic logic treatment. The proposed approach is formalized in Section 4, and illustrated by a realistic example in Section 5.\n2 OVERVIEW OF THE APPROACH\nThe diagnostic problem at large (which may be\nPractical model-based diagnosis with qualitative possibilistic uncertainty 69\nsummarized by \"what is wrong with my system ?\") includes two goals: determining what is wrong from the \"outside\" point of view, i.e., identifying the symptoms, and determining what is wrong from the \"inside\" point of view, i.e., identifying the part of the system that is originally responsible for the symptoms. These two tasks (which often are not distinguished) actually make best use of different kinds of knowledge, and thus would benefit from being treated separately, with distinct models of the system. Indeed, sets of simple nominal behavior models of restricted scope are often sufficient for monitoring; besides, simple influence models describing anomaly propagation are sufficient for fault isolation if a well focused inference is used.\n2.1 FAULT DETECTION\nIn order to detect a fault (i.e., at first, to detect that something is wrong with the system), a model of the nominal, i.e., correct, behavior of the system is necessary. To put it plainly, \"you can't know that something is wrong if you don't know what the system is supposed to do when it is ok\". This task is often performed by some dedicated monitoring facilities. In the case of satellites, the telemetry flow is monitored in real time. Typically, the value of some observable parameter is compared to some thresholds, or its evolution is matched to a standard pattern. This model of the nominal behavior is thus a lot simpler than a simulator (either qualitative or numerical), and therefore preferred, as it is sufficient to fulfill the monitoring task.\nThe output from the· monitoring phase is a first set of symptoms (typically abnormal states of variables, or abnormal evolutions). Further analysis performed off line (for instance through additional probing or finer analysis of collected data) allows the discovery of additional symptoms. As this additional analysis is expensive, it should be focused, and driven by the fault isolation task.\nThis simple approach has only one drawback: using Model-Based terms, it generates discrepancies, but not conflicts (minimal sets of components of which at least one is faulty): fault hypotheses have to be generated in the fault isolation phase.\n2.2 FAULT ISOLATION\nAt this stage, given abnormal observations, we are looking for explanations in terms of anomalies inside the system, i.e., fault(s) of some parts of the system. The absence of a full-fledged nominal behavior model rules out the application of the conventional consistency-based approach. Abductive approach only requires a model describing how anomalies are propagated, but, as pointed out, it still demands exhaustive identification of: • fault modes of components • influences within components (i.e., how an anomaly in\ninput of a component affects its outputs).\nThese two constraints are relaxed, allowing more incompleteness in the model, while recovering all relevant explanations through focused consistency-based and/or\nabductive reasoning on the subset of the model relevant to the symptoms.\n2.2.1 IDENTIFICATION OF \"NEW'' FAULT MODES\nIn addition to conventional \"abducibles\" formed by identified fault modes of each component (e.g., relay \"stuck at 1 \", or \"stuck at 0\"), we also accept as diagnostic solutions abnormal states of the outputs of a given component. For instance, \"noisy output\" of a filter may be accepted as a fault hypothesis, even if no identified fault mode specifically predicts this abnormal output. This allows the characterization of fault modes that were not identified. The \"new\" fault modes are characterized by an abnormal signature on the component outputs. This information may be sufficient for repair, or an expert may decide whether they correspond to possible fault modes.\nPre-identified fault modes may be preferred, and thus get a higher priority in the discrimination. Among fault hypotheses formed by abnormal output of components, those associated to components for which the anomaly cannot be explained by anomalies located further upstream may be preferred. This heuristic preference order allows a better exploitation of the results (e.g., \"conventional\" abducibles come first).\nThe possibility of accepting as candidates the characterisation of possible abnormal behavior improves the exploitation of incomplete models, while the preference heuristics allow a sorting of the potentially numerous hypotheses generated.\n2.2.2 INCOMPLETE MODEL EXPLOITATION\nTo relax the completeness assumption on influences (anomaly propagation) within components, we propose to use a form of consistency-based reasoning on a relevant subset of the model, in complement to abductive reasoning. This relevant subset corresponds to a restriction of the model to the parts which are somehow related to observed symptoms (a formal definition of this approach is given in Section 4). A relevant consistent explanation is then a fault mode or an abnormal signature that belongs to this subset, and is consistent with all the observations.\nIntroducing uncertainty in the behavior representation avoids the need for complete elicitation of exceptional cases. It is also in agreement with incompleteness of the description of the diagnosed situation. In the following, we propose an ordinal representation of uncertainty of the behavior of individual components (Dubois and Prade, 1993, Cayrac et al., 1994a,b). It allows the expression of: • (more or less) certain influences between inputs and\noutputs (possibly taking into account the configuration of the component, e.g., \"on\" or \"off' for a relay) • (more or less) impossible influences (e.g., a given input cannot lead to a given output) It thus leaves room for influences that are (more or less) possible.\nThe basic principle of the reasoning used at the local (component) level is as follows: all abnormal inputs that may cause the abnormal output (i.e., the influence is not\n70 Cayrac, Dubois, and Prade\nimpossible) are gathered: they are relevant consistent explanations. Among these, the ones that (more or less) certainly cause the anomaly (i.e., the influence is certain) are preferred: they are abductive explanations.\n2.2.3 THE FAULT ISOLATION PROCESS\n• Hypotheses generation As no hypothesis is provided by the monitoring phase, it is necessary to generate them as a first step of fault isolation. We want to find disorders that are directly or indirectly \"related\" to the observed manifestations, i.e., components which may be responsible for the symptoms. The fact that a disorder is \"related\" to a manifestation can have two meanings: a strong (abductive) meaning, in which the hypotheses entails the manifestation, or a weaker (consistency-based) meaning, in which the hypothesis is just consistent with the symptom and there is a possible influence path between them (this notion will be formalized in the next section). We thus have to follow upstream \"influence paths\", and collect as candidates the acceptable disorders found on the way.\n• Additional manifestations prediction: The monitoring phase only provides an incomplete set of symptoms. It is therefore useful to generate additional expected manifestations for the fault hypotheses, in order to allow discrimination.\n• Probing and hypotheses discrimination: The expected manifestations are tested, and whether these new observations are entailed by or are consistent with the disorders is verified. This allows the update of the plausibility of the disorders: an inconsistent hypothesis will be rejected, a covering hypothesis (abductive solution) will be preferred over hypotheses that are just consistent with the symptoms.\nThis discussion suggests that a simple fault influence propagation model may be sufficient for the fault isolation task, given proper focusing. The ideas introduced are formalized in the next section.\n3 POSSIBILISTIC LOGIC APPROACH In possibilistic logic (Dubois et al., 1994a,b), classical logic formulas are weighted by lower bounds of the necessity degree with which the formula is held for true. A weighted formula (q>,a) is thus interpreted as the semantic constraint N(q>) � a where N is a necessity measure. A necessity measure is associated with a plausibility ordering of the possible interpretations of the world encoded by a so-called [0, 1 ] -valued possibility distribution 1t. 1t( oo) > 7t( oo') means that interpretation oo is more plausible than interpolation oo'. It is assumed that 3oo, 7t(OO)=l. Then N( q>)=min { 1-7t(oo)looF:-.q> }= 1-max { 7t(oo) I ooF: -.q>) }=1- Il(-.q>) where IT is the possibility measure (Zadeh, 1978) associated with 1t and the necessity of q> corresponds to the impossibility of -.q> . It follows that N(q>A\\jf ) = min(N(q>),N(\\jf)). N(q>) = 1 indicates that it is certain that q> is true N ( q>) = 0 indicates that q> is unknown.\nAutomated reasoning can be performed by means of an extended resolution principle in possibilistic logic:\nN(q>) � a, N('l') � f3 1-- N(Resolvent(q>,'lf)) � min(a,f3).\nA model-based diagnosis problem can be characterized by a logical theory SD describing the behavior of the system, a set of atoms CXT describing contextual data expressing the configurations of the components, and a set of literals OBS representing the observations to be explained. Two kinds of solutions are then defined, with 'G=SDuCXT: • consistency-based approach: an explanation H (this definition will not be elaborated here) is a solution iff: 'GuOBSuH is consistent • abductive approach: an explanation H is a solution iff\n'GuHr- OBS\nThe extension of the two above approaches to the handling of uncertainty using possibilistic logic is now briefly outlined.\nLet us consider a knowledge base 'G made of uncertain implication relations between possible disorders (explanations)�. i=1,m and effects, i.e., present or absent, manifestations mj, j=1,n. This is encoded by weighted clauses of the form\nN(-.di v mj) � aij>O and N(-.dk v -.mr) � \"-kr>O.\nBesides, we have a set OBS of uncertain observations represented by weighted formulas of the form\nN(m5) � (35 > 0 (present manifestations) N(-.mt) � Pt > 0 (absent manifestations).\nIt is assumed that 'Vi, 'v'j, 'v'r, N(-.di vmj)>O and N(-.di v -.mr)>O entail j;t:r, i.e., the behavioural knowledge is\ncoherent. In the approach presented in this paper, 'G can be interpreted as the behavior of a given component, the disorders being fault modes and abnormal inputs, and the manifestations being abnormal outputs. Applying the possibilistic resolution rule, we obtain\n'v'j, N(-.dj) � min(<Xjj•Pj) and 'v'r, N(-.dj)�min(A.ir•f3r)\nand thus\nN(-.dj) � max[maxj min(aij•Pj), maxr min(A.ir•f3r)l (1)\nThus from (1) we compute an upper bound of possibility degree of the explanation di. Il(dj)=1-N(-.dj) which is the level of consistency cons'(;(dj;OBS)�1-N(-.dj) of 'GuOBSu{dj} in the possibilistic setting. Indeed, in possibilistic logic the level of inconsistency (the complement to 1 of the level of consistency) of a knowledge base %u{ q>} is nothing but the greatest lower bound a such that N(-.q>)�a is compatible with the constraints on the necessity measure N encoding the pieces of knowledge in %.\nBesides, the possibilistic logic resolution rule applied to N(-.di v mj)�aij and N(di)=l (assuming that di is present) entails N(mj) � aij· Let M+ be the set of present manifestations such that N(mj)�f3j>O. Then in abductive\nPractical model-based diagnosis with qualitative possibilistic uncertainty 71\nreasoning we are interested in finding the di's such that \\fmje M+, 'Gu{ dj}1-mj. When the aij's and �j's are 0 or 1, di is an abductive explanation of mj if and only if\n�j � Clij = 1 (2)\nwhere a � b = 1 if a :s; b and a � b = 0 if a > b. This holds for any mj in M+, and di is an abductive explanation of M+ if and only if\nA*(di) = minj (�j � Clij) (3)\nis equal to 1 (otherwise it is zero). When Clij and �j take values intermediary between 0 and 1, (3) can be extended using Godel implication a � b = 1 if a :s; b and a � b = b if a > b. Then (3) expresses a coverage of the fuzzy set of manifestations more or less certainly observed by the fuzzy set of manifestations more or less certainly caused by di. Note that A* is not a necessity degree strictly speaking since A*(di)=l means only that di is highly plausible. Note that A*(di) = 1 as soon as �j :s; Clij• \\fj, i.e., when N(mj) ;;:: �j• is a set of valid deductions from the weighted clauses N(-.di v mj);;::Cljj and N(di)=l .\nIn the computation of abductive solutions, only observed manifestations are accounted for. Indeed, we do not wish to explain the nominal behavior. Moreover, negative causal knowledge is often scarce (i.e., many Air will be 0 in practice). It is easy to see that when A.ir=O, accounting for an absent manifestation (Pr >0) will destroy the abductive information in (3) since then Pr �Air is equal to 0.\n4 FORMAL DESCRIPTION\nThe model of the system consists of a description of its individual components and their behavior, and of the links defining the relation between them.\n4.1 COMPONENT DESCRIPTION\nThe components have identified inputs, outputs, configuration modes (i.e., states), and possibly identified fault modes. All these can be viewed as the parameters of the model. They will be represented as predicates defined on discrete domains.\nDef.l: A component Ci is characterized by: • A set of predicates describing:\n- its input { Ci_in 1, . . . ,ci_inm}, - its output {cj_outl····•cj_outp}, - its configuration mode Ci_state (if applicable), - its fault mode cj_fault.\n• A theory CDi concerning these predicates, expressed in possibilistic logic and describing its behavior: - how an abnormal input signature affects its outputs,\ngiven its configuration mode, - the impact of each identified fault mode on its outputs\nComponent is used here as a generic term: a component may be an actual electric component, or a whole equiment, or a function, etc.\nInput and output are defined on a set of abnormal states such as \"absent\", \"noisy\", \"at_zero\", etc. Nominal states need not to be represented, as they are not propagated. We consider that the system is static, i.e., that the configuration mode of the component does not change during the diagnostic session. Example of configuration modes of a relay: on/off. Examples of fault modes: stuck_at_zero, stuck_at_one, always_on, etc.\nAs we only require the explanation of abnormal observations, the behavior representation proposed (anomaly propagation) is sufficient. The information regarding the behavior of each component is kept separate, as this \"partitioning\" is exploited by the diagnostic task.\nIt should be noted that even if no gradual representation of uncertainty was used, we could distinguish between influences that are certain and those which are only possible. E.g., in Figure 1, the behavior of C 1, \"i 1 cannot cause an anomaly on 01, but may impact 02, and will impact 03\" would be expressed as CDt = {it(abnormal) � -,ot(abnormal), it(abnormal) � 03(abnormal)}. At the component level, it (abnormal) is an abductive explanation of 03 (abnormal), a consistent explanation of 02 (abnormal), and there is no explanation for o 1 (abnormal). Note: in this simple example, the component has only one input; in the general case, an abnormal input signature should be considered.\nFi�ure 1\nThe use of both consistency-based and abductive approaches at the component level captures of a form of incompleteness. However, as mentioned previously, a greater expressivity of uncertainty is desirable. We may for instance want to express that a fault mode is more likely to impact one output of the component than another, or distinguish unlikely impacts from those which are plainly impossible. The goal of this refinement is to allow a ranking of the diagnostic solutions, for instance through the identifications of fault hypotheses that are more or less consistent with the observations, or that more or less cover them.\nThe behavior CDi of the component Ci can thus be equivalently defined by: - a set of uncertain clauses encoded in possibilistic logic, - a global relation on the Cartesian product of the set of\nvariables formed by the input, output, configuration mode and fault mode of the component, weigthed in terms of necessity degrees (Cayrac et al. 1994a).\nA subset of the outputs of the components is assumed to be observable. However, some observations may be pervaded with uncertainty.\n72 Cayrac, Dubois, and Prade\n4. 2 LINKS BETWEEN COMPONENTS\nThe links describe the way in which the components are connected, and characterize their possible interactions. As components have distinct inputs and outputs, the links are directed. They just carry the value of the output of a component to some inputs of other components, without modification.\nDef.2: A link is a proposition of the form: Ci_OUtj(X) � Ck_inl(X) 1\\ • • • 1\\ Cp_inq(x) expressing that the output state Ci_out j(x) of the component Ci is propagated to the inputs Ck_ini(x), ... , Cp ing(x) of components Ck, ... , Cp.\nDef.3: The set LINKS contains all the links between the components of the system.\nAlthough this is usually not done in most model-based diagnostic approaches, we choose to identify the links as individual entities. Indeed, in case several components are related through more that one possible interaction path (e.g., two links exist between them), this allows to focus the reasoning to the relevant links.\nAs defined, the links only allow distribution of information (fan-out), but no fusion (fan-in). This limitation allows a clear separation between components, which encapsulate all the behavior, and the \"wiring\" represented by links. In a fan-in situation, when the effects can be superposed (they do not interfere) the relation can be represented by several links; when they do interfere, an additional component must be created.\n4. 3 THE DIAGNOSTIC PROBLEM\nDef.4: The model of the system, SD, is formed by the component behaviors and the links between them: SD = {CDt, ... ,CDn. LINKS}\nDef.5: We call context, CXT, the set of configuration modes of the components at the time of diagnosis. This is assumed to be known a priori: CXT = { cj_state(statek), ... }\nDef.6: We call set of observations, OBS, the set of the output states which have been observed. OBS is partitioned into two subsets M+ (manifestations whose presence is confirmed) and M- (those whose absence is confirmed). OBS = { Ci_outh(stateq) •. . . , -.cj_outk(statet) • . . . }\n= M+uM- ={mt •. . . , ...,mn····}\ncs_ouq (noisy) is an example of a present manifestation. It should be noted that an observation is here equivalent to an abnormal state of a link, as a link is tied to exactly one component output. The observations may also be more or less certain. M+ and M- are in fact fuzzy sets whose membership degrees are interpreted as certainty levels: N(ml) � f..lM+(mi), ... , N(...,mn) � f..LM-(mn) • . . .\nDe f . 7: A di agnostic problem is the tuple D P, formed by the model of the system, its configuration at the time of diagnosis, and the set of observations:\nDP = {SD, CXT, OBS}.\nIn addition to a possibilistic version of \"conventional\" abductive reasoning, we propose a form of possibilistic consistency-based reasoning. It exploits a theory formed by the behaviors of components that are on an upstream influence path and the relevant links between them. The following two definitions characterize its elements.\nThe set of possible influence paths leading to a manifestation m (given output state Cp_outq(stater) of a component Cp) is the subset REL_LINKS(m) of LINKS containing links that may propagate the cause of m. REL_LINKS(m) is defined recursively as follows: a link cj_outj(x) � Ck_inv(x) 1\\ • • • 1\\ cs_int(x) of LINKS belongs to REL_LINKS if and only if:\n- it is tied to an input cp_int(x) of Cp. and there is at least one state of this input that is (at least partially) consistent with m, i.e., with Cp_outq(stater):\npe {k, ... ,s}, and 3't, 3statey, CDpu{cp_int(statey)} is consistent to a strictly positive degree.\n- it is tied to the input C(J)_in't(x) of a component Cro of which an output C(J)_outA, matches the premise of one of the links of REL_LINKS, and there is at least one state s of cro_in't that is at least partially consistent with m and the model of the system (i.e., there is a possible influence path between cro _in't a n d cP-outq(stater)):\n3roe {k, ... ,s}, 3A., 3statey, C(J)_OUtA,(x) � . . . e REL_LINKS(m) and SD u {c00_int(statey)} u {cp_outq (stater)} is consistent to a stictly positive degree.\nREL_LINKS (relevant links) forms a restriction of the theory LINKS to the links that are relevant to a given symptom. This restriction is performed on the basis of possible influence paths between components (links), and inside them.\nT h e set REL_COMPS(m) of components relevant to a manifestation m (given output state C p _ o u tq (stater) of Cp ). contains Cp and all the components of which an output is tied to a possible influence path to m: REL_COMPS(m) = {Ci, i=p or\n3A., cj_outA,(x) � . . . e REL_LINKS(m)}\nREL_COMPS(m) contains all the components that may be responsible for the state observed on the output of a given component (manifestation m).\n4. 4 SINGLE FAULT SOLUTIONS"
    }, {
      "heading" : "An elementary solution d of the diagnostic",
      "text" : "problem DP is either: • a fault mode d=ci_fault(fault_modej) of component Ci, or • a set of abnormal states d={ Ci_outj(statek), ... } on the outputs of Ci, (and d(')QBS=0: d is not a trivial solution), such that: • d causes more or less certainly all present manifestations:\nPractical model-based diagnosis with qualitative possibilistic uncertainty 73\nSDuCXTu { d }1-M+ with a strictly positive necessity degree a, and SDu CXTu { d }uM - is completely consistent with the observations d is then an abductive explanation to the degree a of the abnormal observations. • there is a possible influence path between d and each present manifestation, and d is not completely inconsistent with the observations: d=ci_fault(fault_modej); 'Vme M+, Cie REL_COMPS(m) and SDuCXTu {d}uOBS is consistent to a srictly positive degree � or: 'VA., 'Vs such that Ci_out')..(s)e d, 'Vme M+, Ci_out')..(x) � . . . e REL_LINKS(m), and SDuCXTu{d}uOBS is consistent to a strictly positive degree �- d is then a relevant explanation consistent to the degree � with the observations.\nClearly, in the above expressions, SD can be replaced by its relevant (useful) parts: UmeM+[REL_LINKS{m)uREL_COMPS(m)).\nThe single fault solutions are thus fault modes or abnormal output signatures which: • (more or less) entail all the manifestations (abductive\nexplanations) • are (more or less) consistent with the observations, and\nthere exists an influence path between the hypothesis and each manifestation.\nThus, a ranking of more or less plausible solutions to the diagnosis problem is obtained.\n4.5 PROBING POINTS\nA n expected manifestation m with respect to a solution d of a diagnostic problem DP, any abnormal observable output state of a component,m=cj_ouq(statek), such that: SDuCXTu{d}1-m with a strictly positive necessity degree. m is then expected to be present when d is present. or: SDuCXTu{d}1--om with a strictly positive necessity degree. m is then expected to be absent when d is present.\nThe observation of whether an expected manifestation m is present or not allows the diagnostic system to check whether d is still a consistent and I or an abductive explanation: m is added to OBS.\n5 A REALISTIC EXAMPLE"
    }, {
      "heading" : "5.1 A SATELLITE SOLAR ARRAY EQUIPMENT",
      "text" : "The goal of the power regulation subsystem is to meet the power requirements of the equipments connected on the bus. A ladder of comparators connects as many solar arrays (S.A.) as necessary (Figure 2). When the voltage is too\nhigh on the power bus, S.A.'s are progressively disconnected. If, due to an anomaly, this is not enough, a protection resistor is connected to create an extra load. On the contrary, if all S.A.'s are connected and the power demand still cannot be met, the control system assumes that the sun is no longer visible (it is behind the Earth), and sends an eclipse signal to an on-board computer, so that batteries can be used to supply extra power. A simplified view of the contol system is given in Figure 3.\n5.2 MAIN COMPONENTS\nIn this example, we distinguish between analog and digital input/output. Analog i/o identified states are DEG and ABS (respectively for degraded and absent; only abnormal states are used). Digital i/o identified states are ZERO, ONE. Similar extremely simple sets of qualification turned out to be a good tradeoff between knowledge acquisition cost and solutions quality for the modeling of complex systems.\nWe choose to represent explicitly (more or less) certain and (more or less) impossible influences between inputs and outputs of components. The uncertainty is limited to the following qualitative levels: \"certain\", \"almost certain\", \"likely; \"possible\" (i.e., unknown); \"unlikely\", \"almost impossible\", \"impossible\". In other words, we use a discrete linearly ordered scale. In practice, levels of\n74 Cayrac, Dubois, and Prade\ncertainty of presence of, for instance, a manifestation m (f.!\nM + (m)), can be represented by a number: 1.0 for \"certain\", 0.8 for \"almost certain\", ... , 0.0 for \"possible\"; the levels of certainty of absence of m can be similarly encoded: 1.0 for \"impossible\", 0.8 for \"almost impossible\", ... , 0.0 for \"possible\". Note that only the ordering between these numbers is meaningful, and not their exact value. Since only purely ordinal operations such as min, max, order-reversing and Godel implication are used, the formulas used can be straightforwardly transposed from the [0, 1] scale to a discrete scale.\nBehavior of the components used in the simplified example:\nComparator: compi camp. out Q!if\nimm1;. ref (analog), in; (analog) Ql!.UllU;. out. (digital)\nbehavior: compi_ref(ABS) � compi_Out(ONE), certain\ncompi_ref(ABS)� compi_out(ZERO), impossible\ncompi_ref(DEG)� compi_out(ONE), likely\ncompi_in(ABS)� compi_out(ZERO), certain\ncompi_in(ABS)� compi_out(ONE), impossible Note: the behavior of the comparator is fully described when its \"ref\" or \"in\" input is ABS. However, when it \"ref\" input is DEG, the output may be ONE (likely) or, implicitly, ZERO (possible); when its \"in\" input is DEG, any output state is possible.\nSolar array section: solar_arrayi fokir _array i 4out\nQl!.UllU;. out. (analog)\nRelay: reli in ;!!}.; -..oout T\ncommand\n.imll!t. command (digital),in; (analog) Q!!1J.ll!1;. out. (digital) behavior: reli_state(ON)Areli_in(ABS)�reli_out(ABS), certain\nreli_state(ON)Areli_in(DEG)�reli_out(DEG), certain\nreli_state(OFF)Areli_in(ABS)�reli_out(ABS), impossible\nreli_state(OFF)Areli_in(DEG)�reli_out(DEG), impossible Note: nothing is said about the response of the relay to an ON or OFF command input since we do not represent the dynamic behavior of the components.\nVoltage source: sourcei\n� � � �\n� The voltage source gives in output a scale of voltages used as references for comparators. Its input is its alimentation. imm1;. alim (analog) llll1l2Y1.;. out}, out2, out3, ou4 (analog) behavior: for all j, sourcei_alim(ABS)� sourcei_outj(ABS), certain\nsourcei_alim(DEG)� sourcei_outo(DEG), unlikely\nsourcei_alim(DEG) � sourcei_out2(DEG), likely\nsourcei_alim(DEG) � sourcei_out3(DEG), likely\nGround: groundi\nQllUmt. out. (analog)\nResistor: resi res; in c:J'VV\"oout\nimm1;. in; (analog) QllUmt. out. (analog) behavior: resj_in(DEG) � resi_out(DEG), almost certain Note: nothing is said about the impact of an ABS input: the output may be ABS or DEG or neither one (all alternatives are completely possible)\n5.3 DIAGNOSTIC SESSION\nInitial symptom: OBS=M+={ (Eclipse_signal(ONE), certain)}: observation of an eclipse signal, which is abnormal because at this time the satellite is still facing the sun. CXT={rel()(OFF), relj(ON), rel2(0FF)}\nHypotheses generation phase\nFigure 4 shows the theory relevant to the original symptom. Hypotheses (which in this example consist only in abnormal output of some components) are denoted in boldface. Abductive explanations, computed using the Formula (3): D*={ (source_outJ(ABS), 1.0), (alim(ABS), 1.0),\n(source_outJ(DEG),0.3), (alim(ABS),0.3)}\nEclipse_signal(ONE) is a certain consequence of source_outJ(ABS) and alim( ABS) , but only a likely consequence of source_outJ(DEG) and alim(DEG). The former explanations, which are abductive explanations in the conventional sense, are thus preferred at this point.\nConsistent explanations, computed using the Formula (1) (all of them are fully consistent with the eclipse signal symptom): ,... D={ (source_out 3( ABSENT), possible),\n(source_outJ(DEGRADED),possible), (reso_out(DEGRADED ), possible), (rel]_out(DEGRADED),possible),\n(rel2_out( DEGRADED ),possible), (relo_out(DEGRADED),possible), (relo_out( ABSENT),possible ), (solar _array ]_out( DEGRADED ),possible), (solar _array J_out(ABSENT), possible), (alim(ABSENT),possible), (alim(DEGRADED),possible)}\nAdditional manifestation prediction phase\nA prediction phase allows the elicitation of additional manifestations that may further discriminate among pending hypotheses. Figure 5 summarizes this phase of the reasoning.\nThe additional manifestations predicted by the various fault hypotheses are therefore: obs_bus(DEG), obs_bus(ABS),\nPractical model-based diagnosis with qualitative possibilistic uncertainty 75\nobso(ONE), obsJ(ONE), obs2(0NE).\nAdditional manifestation probing phase\nD= {(source _out 3( ABS ), possible), (source _out 3( DEG ) , possible),\nWe observe: { (obs_bu s( DEG ) , almost certain), (obs_bus(ABS), impossible), (obso(ONE), impossible), (obs J( ONE), certain), (obs2(ZERO ), certain)}.\n(relo_out( ABS ),possible), (relo_out( DEG ), possible), (reso_out(DEG),possible),\n(ob s o ( Z ER O ) , certain), which is equivalent to (obso(ONE), impossible) is completely inconsistent with alim(ABS), which predicts (obso(ONE), certain) and (obso(ZERO), impossible), and partially inconsistent with alim( DEG), which predicts (obso(ONE), likely). The hypothesis alim(ABS) is therefore discarded and alim( DEG) is unlikely. Similarly, (obs_bus( ABS), impossible) is partially inconsistent with solar _array ]_out( ABSENT), which is therefore considered unlikely.\n(solar _array J_out(DEG),possible), (relj_out(DEG),possible), (rel2_out(DEG),possible), (solar _array J_out( ABS ), unlikely), (alim(DEG),unlikely)}\nThe other hypotheses remain completely possible, i.e., they are located on a possible influence path leading to some of the symptoms, and they are completely consistent with all the observed symptoms. However, no abductive hypothesis remains : s o u r c e j _ o u t 3 ( ABS) a n d source_out3(DEG) do not abductively explain the symptom (obs_bus(DEG), almost certain).\nsource_out3(ABS), source_out3(DEG) are rejected by the user because they cannot explain the abnormal bus voltage. solar _array J_out(DEG) is relevant: if the array is damaged, it will produce less power, and this may trigger the eclipse signal. It is preferred over relJ_out(DEG), which can be one of its manifestations.rel2_out(DEG) is quickly discarded by the user: an extra solar array connected cannot produce the symptoms observed. relj_out(DEG) is actually irrelevant, since the relay is off.\nConclusion of the diagnosis session - exploitation of the results\nrelo_out(ABS) and relo_out(DEG) are preferred over (reso _ o u t ( DEG ) ,possible), which may be their manifestations. relo_out(ABS) is in fact the explanation that is the closest to the real fault. Indeed, relo is actually faulty: it connected unduly reso to the power bus, causing the voltage to go down, and, as the bus was heavily loaded, triggering the eclipse signal.\n76 Cayrac, Dubois, and Prade\n6 CONCLUSION\nPreliminary ideas which led to the proposed approach were introduced in (Haziza, 1988), and experimented through the DIAMS project led by Matra Marconi Space since 1987. Its goal is the delivery of operational diagnostic support systems for satellites. Early experiments of model-based approaches were judged not fully satisfactory, especially with respect to the knowledge acquisition costs. During the last eight years, several systems were developed, based on the joint use of various diagnostic knowledge: fault trees, causal knowledge and functional (model-based) knowledge. They include one pre-operational version installed in the Telecom-2 satellite control center early 1994 (Brenot et al., 1993).\nIn this paper, we proposed a route that may improve the feasibility of operational applications of model-based reasoning. It allows the exploitation of a vastly incomplete model through well focused diagnostic strategies. However, it clearly falls in the scope of diagnostic support systems, as the number of possible hypotheses generated is clearly larger than if a complete model were available. However, we recover part of the lost discrimination power through the introduction of an ordinal treatment of uncertainty which enables to rank order the remaining candidates. Possibilistic logic seems to be well-adapted to contexts in which information is scarce or expensive to gather (significant incompleteness, absence of priors).\nReferences\nJ.M. Brenot, P. Caloud, L. Valluy, A. Gasquet (1993). On the design and development choices to bring to operation a diagnostic expert system for the Telecom 2 satellite. Proc. of the Tooldiag Inter. Conf. on Fault Diagnosis, Toulouse, France, 368-377.\nD. Cayrac, D. Dubois, M. Haziza, H. Prade (1994a). Possibility theory in \"fault mode effect analyses\" - A satellite fault diagnosis application-. Proc. of the 3rd IEEE Inter. Conf. on Fuzzy Systems (FUZZ-IEEE'94), June 26-29, 1176-1181\nD. Cayrac, D. Dubois, H. Prade (1994b). Qualitative and logical handling of uncertainty in a relational model for operational fault diagnosis. Proc. of the DX-94 5th Inter. Workshop on Principles of Diagnosis, New York State, Oct. 17-19, 47-55.\nL. Console, D. Theseider Dupre, P. Torasso (1989). A theory of diagnosis for incomplete causal models. Proc. 11th Inter. Joint Conf. on Artificial Intelligence (IJCA/'89), Detroit, Ml, 1311-1317.\nL. Console, P. Torasso (1990). Integrating models of the correct behavior into abductive diagnosis. Proc. 9th Europ. Conf. on Artificial Intelligence (ECA/'90), Stockholm, 160-166.\nR. Davis, W. Hamscher (1988). Model-based reasoning: Troubleshooting. In H.E. Shrobe (ed.), Exploring Artificial Intelligence, Morgan Kaufmann, 297-346.\nJ. De Kleer, B.C. Williams (1987). Diagnosing multiple faults. Artificial Intelligence 32:97-130.\nD. Dubois, J. Lang, H. Prade (1994a). Automated reasoning using possibilistic logic: Semantics, belief revision and varia�le certainty weights. IEEE Trans. on Knowledge and Data Engineering 6:64-69. D. Dubois, J. Lang, H. Prade (1994b). Possibilistic logic. In D.M. Gabbay et al. (eds.), Handbook of Logic in Artificial Intelligence and Logic Programming- Vol. 3:"
    }, {
      "heading" : "Nonmonotonic Reasoning and Uncertainty Reasoning,",
      "text" : "Clarendon Press, Oxford, 439-513.\nD. Dubois, H. Prade (1993). A fuzzy relation-based extension of Reggia's relational model for diagnosis. In D. Beckerman, E.H. Mamdani (eds), Proc. of the 9th Conf. on Uncertainty in Artificial Intelligence, Washington, July, 106-113.\nW. Hamscher, L. Console, J. De Kleer (Eds) (1992). Readings in Model-Based Diagnosis. Morgan Kaufmann, San Mateo, CA.\nM. Haziza (1988). An expert system shell for satellite fault isolation based on structure and behaviour. Proc."
    }, {
      "heading" : "ESTEC Workshop on Artificial Intelligence and",
      "text" : "Knowledge Based Systems for Space, Noodwijk, Netherlands.\nD. Poole (1989). Normality and faults in logic-based diagnosis. Proc. of the 11th Inter. Joint Conf on Artificial Intelligence (/JCA/'89), Detroit, Ml, 1304-1310.\nL.A. Zadeh (1978). Fuzzy sets as a basis for a theory of possibility. Fuzzy Sets and Systems 1:3-28."
    } ],
    "references" : [ {
      "title" : "On the design and development choices to bring to operation a diagnostic expert system for the Telecom 2 satellite",
      "author" : [ "J.M. Brenot", "P. Caloud", "L. Valluy", "A. Gasquet" ],
      "venue" : "Proc. of the Tooldiag Inter. Conf. on Fault Diagnosis, Toulouse, France, 368-377.",
      "citeRegEx" : "Brenot et al\\.,? 1993",
      "shortCiteRegEx" : "Brenot et al\\.",
      "year" : 1993
    }, {
      "title" : "Possibility theory in \"fault mode effect analyses\" - A satellite fault diagnosis application",
      "author" : [ "D. Cayrac", "D. Dubois", "M. Haziza", "H. Prade" ],
      "venue" : "Proc. of the 3rd IEEE Inter. Conf. on Fuzzy Systems (FUZZ-IEEE'94), June 26-29, 1176-1181",
      "citeRegEx" : "Cayrac et al\\.,? 1994a",
      "shortCiteRegEx" : "Cayrac et al\\.",
      "year" : 1994
    }, {
      "title" : "Qualitative and logical handling of uncertainty in a relational model for operational fault diagnosis",
      "author" : [ "D. Cayrac", "D. Dubois", "H. Prade" ],
      "venue" : "Proc. of the DX-94 5th Inter. Workshop on Principles of Diagnosis, New York State, Oct. 17-19, 47-55.",
      "citeRegEx" : "Cayrac et al\\.,? 1994b",
      "shortCiteRegEx" : "Cayrac et al\\.",
      "year" : 1994
    }, {
      "title" : "A theory of diagnosis for incomplete causal models",
      "author" : [ "L. Console", "D. Theseider Dupre", "P. Torasso" ],
      "venue" : "Proc. 11th Inter. Joint Conf. on Artificial Intelligence (IJCA/'89), Detroit, Ml, 1311-1317.",
      "citeRegEx" : "Console et al\\.,? 1989",
      "shortCiteRegEx" : "Console et al\\.",
      "year" : 1989
    }, {
      "title" : "Integrating models of the correct behavior into abductive diagnosis",
      "author" : [ "L. Console", "P. Torasso" ],
      "venue" : "Proc. 9th Europ. Conf. on Artificial Intelligence (ECA/'90), Stockholm, 160-166.",
      "citeRegEx" : "Console and Torasso,? 1990",
      "shortCiteRegEx" : "Console and Torasso",
      "year" : 1990
    }, {
      "title" : "Model-based reasoning: Troubleshooting",
      "author" : [ "R. Davis", "W. Hamscher" ],
      "venue" : "H.E. Shrobe (ed.), Exploring Artificial Intelligence, Morgan Kaufmann, 297-346.",
      "citeRegEx" : "Davis and Hamscher,? 1988",
      "shortCiteRegEx" : "Davis and Hamscher",
      "year" : 1988
    }, {
      "title" : "Diagnosing multiple faults",
      "author" : [ "J. De Kleer", "B.C. Williams" ],
      "venue" : "Artificial Intelligence 32:97-130.",
      "citeRegEx" : "Kleer and Williams,? 1987",
      "shortCiteRegEx" : "Kleer and Williams",
      "year" : 1987
    }, {
      "title" : "Automated reasoning using possibilistic logic: Semantics, belief revision and varia�le certainty weights",
      "author" : [ "D. Dubois", "J. Lang", "H. Prade" ],
      "venue" : "IEEE Trans. on Knowledge and Data Engineering 6:64-69.",
      "citeRegEx" : "Dubois et al\\.,? 1994a",
      "shortCiteRegEx" : "Dubois et al\\.",
      "year" : 1994
    }, {
      "title" : "Possibilistic logic",
      "author" : [ "D. Dubois", "J. Lang", "H. Prade" ],
      "venue" : "D.M. Gabbay et al. (eds.), Handbook of Logic in Artificial Intelligence and Logic Programming- Vol. 3: Nonmonotonic Reasoning and Uncertainty Reasoning, Clarendon Press, Oxford, 439-513.",
      "citeRegEx" : "Dubois et al\\.,? 1994b",
      "shortCiteRegEx" : "Dubois et al\\.",
      "year" : 1994
    }, {
      "title" : "A fuzzy relation-based extension of Reggia's relational model for diagnosis",
      "author" : [ "D. Dubois", "H. Prade" ],
      "venue" : "D. Beckerman, E.H. Mamdani (eds), Proc. of the 9th Conf. on Uncertainty in Artificial Intelligence, Washington, July, 106-113.",
      "citeRegEx" : "Dubois and Prade,? 1993",
      "shortCiteRegEx" : "Dubois and Prade",
      "year" : 1993
    }, {
      "title" : "Readings in Model-Based Diagnosis",
      "author" : [ "W. Hamscher", "L. Console", "J. De Kleer" ],
      "venue" : null,
      "citeRegEx" : "Hamscher et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Hamscher et al\\.",
      "year" : 1992
    }, {
      "title" : "An expert system shell for satellite fault isolation based on structure and behaviour",
      "author" : [ "M. Haziza" ],
      "venue" : "Proc. ESTEC Workshop on Artificial Intelligence and Knowledge Based Systems for Space, Noodwijk, Netherlands.",
      "citeRegEx" : "Haziza,? 1988",
      "shortCiteRegEx" : "Haziza",
      "year" : 1988
    }, {
      "title" : "Normality and faults in logic-based diagnosis",
      "author" : [ "D. Poole" ],
      "venue" : "Proc. of the 11th Inter. Joint Conf on Artificial Intelligence (/JCA/'89), Detroit, Ml, 1304-1310.",
      "citeRegEx" : "Poole,? 1989",
      "shortCiteRegEx" : "Poole",
      "year" : 1989
    }, {
      "title" : "Fuzzy sets as a basis for a theory of possibility",
      "author" : [ "L.A. Zadeh" ],
      "venue" : "Fuzzy Sets and Systems 1:3-28.",
      "citeRegEx" : "Zadeh,? 1978",
      "shortCiteRegEx" : "Zadeh",
      "year" : 1978
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "Abductive diagnosis (Poole, 1989) relies on a causal model between faults and manifestations, and looks for explanations (faults) that cause, or \"cover\" the symptoms observed.",
      "startOffset" : 20,
      "endOffset" : 33
    }, {
      "referenceID" : 4,
      "context" : "Abductive diagnosis requires completeness of the identified fault modes (Console and Torasso, 1990).",
      "startOffset" : 72,
      "endOffset" : 99
    }, {
      "referenceID" : 3,
      "context" : "Proposals for handling incompleteness (Console et al., 1989) still require the identification of all possible sources of incompleteness, at the level of each rule, which makes their application unfit to vastly incomplete models.",
      "startOffset" : 38,
      "endOffset" : 60
    }, {
      "referenceID" : 13,
      "context" : "q>) where IT is the possibility measure (Zadeh, 1978) associated with 1t and the necessity of q> corresponds to the impossibility of -.",
      "startOffset" : 40,
      "endOffset" : 53
    }, {
      "referenceID" : 1,
      "context" : "The behavior CDi of the component Ci can thus be equivalently defined by: - a set of uncertain clauses encoded in possibilistic logic, - a global relation on the Cartesian product of the set of variables formed by the input, output, configuration mode and fault mode of the component, weigthed in terms of necessity degrees (Cayrac et al. 1994a).",
      "startOffset" : 324,
      "endOffset" : 345
    }, {
      "referenceID" : 11,
      "context" : "Preliminary ideas which led to the proposed approach were introduced in (Haziza, 1988), and experimented through the DIAMS project led by Matra Marconi Space since 1987.",
      "startOffset" : 72,
      "endOffset" : 86
    }, {
      "referenceID" : 0,
      "context" : "They include one pre-operational version installed in the Telecom-2 satellite control center early 1994 (Brenot et al., 1993).",
      "startOffset" : 104,
      "endOffset" : 125
    } ],
    "year" : 2011,
    "abstractText" : "An .:tpproach to fault isolation that exploits vastly incomplete models is presented. It relies on separate descriptions of each component behavior, together with the links between them, which enables a focusing of the reasoning to the relevant part of the system. As normal observations do not need explanation, the behavior of the components is limited to anomaly propagation. Diagnostic solutions are disorders (fault modes or abnormal signatures) that are consistent with the observations, as well as abductive explanations. An ordinal representation of uncertainty based on possibility theory provides a simple exception­ tolerant description of the component behaviors. We can for instance distinguish effects that are more or less certainly present (or absent) and effects that are more or less possibly present (or absent) when a given anomaly is present. A realistic example illustrates the benefits of this approach.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}