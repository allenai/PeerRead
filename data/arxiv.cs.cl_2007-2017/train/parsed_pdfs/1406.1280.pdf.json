{
  "name" : "1406.1280.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Basis Identification for Automatic Creation of Pronunciation Lexicon for Proper Names",
    "authors" : [ "Sunil Kumar Kopparapu", "Laxmi Narayana" ],
    "emails" : [ "SunilKumar.Kopparapu@TCS.Com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Development of a proper names pronunciation lexicon is usually a manual effort which can not be avoided. Grapheme to phoneme (G2P) conversion modules, in literature, are usually rule based and work best for non-proper names in a particular language. Proper names are foreign to a G2P module. We follow an optimization approach to enable automatic construction of proper names pronunciation lexicon. The idea is to construct a small orthogonal set of words (basis) which can span the set of names in a given database. We propose two algorithms for the construction of this basis. The transcription lexicon of all the proper names in a database can be produced by the manual transcription of only the small set of basis words. We first construct a cost function and show that the minimization of the cost function results in a basis. We derive conditions for convergence of this cost function and validate them experimentally on a very large proper name database. Experiments show the transcription can be achieved by transcribing a set of small number of basis words. The algorithms proposed are generic and independent of language; however performance is better if the proper names have same origin, namely, same language or geographical region.\nIndex Terms\nProper name Lexicon, Pronunciation Dictionary, TTS, G2P, Basis Optimization, Span deficient basis, Rank\ndeficient basis\nI. INTRODUCTION\nbelsec:introduction Text to Speech (TTS) synthesis is an automated encoding process which converts text (a sequence of symbols conveying linguistic information), into speech (an acoustic waveform). The two major components of a TTS synthesizer are (a) natural language processing (NLP) module, which produces a phonetic transcription of the given text and (b) digital signal processing module, which transforms sequence of phones into speech [1]. Text normalization is the process of converting non-standard words like abbreviations, acronyms, dates, special symbols (for e.g. Dr, Mr, $700) into their corresponding graphemic representation [2]. Grapheme to\nSunil Kumar Kopparapu is with TCS Innovation Lab - Mumbai, Tata Consultancy Services, Yantra Park, Thane (West), Maharastra 400601. Email: SunilKumar.Kopparapu@TCS.Com\nar X\niv :1\n40 6.\n12 80\nv1 [\ncs .C\nL ]\n5 J\nun 2\n01 4\n2 phoneme (G2P) conversion is then performed on the normalized text. In general, an NLP module should be able to normalize the input text and map the grapheme representation of the text to a corresponding phonetic representation.\nA pronunciation dictionary provides a means to map a word into its elementary phonetic components which is a key for modeling TTS synthesis systems. The reason for this is that in general, a one to one correspondence between the orthographic representation of a word and its pronunciation is absent. However, the need for a pronunciation dictionary reduces by developing a set of predefined rules (called G2P rules) developed based on linguistic knowledge, that map a sequence of characters (graphemes) into a sequence of phones. The G2P rule base is a set of rules that modify the ’default mapping’ of the characters based on the ’context’ in which a particular phoneme occurs. Specific contexts are matched using rules. The system triggers the rule that best fits the current context [2]. G2P converters usually produce a significant number of mistakes when converting proper names which are often of a foreign origin [3]. The rule set developed is language dependent and hence an existing rule base for one language cannot automatically be used to generate the phonetic transcription of a word from another language. Proper names being foreign to the G2P rule base of any language, demand manual effort which is inevitable to obtain the phonetic transcription. Recently, Bonafonte et al [4] reported an average phonetic accuracy of 53% for proper names when a rule based methodology is used to construct a phonetic dictionary of proper names. Van den Heuvel et al [5] tried to automate the process of transcribing proper names by using a cascade of a general purpose G2P converter and a special purpose P2P (phoneme to phoneme) converter; the P2P converter learns from human expert knowledge. Though they report enhanced performance with the cascade system compared to direct rule based method, the performance of cascade system results in more than 30% of the name transcriptions being erroneous. In a manual effort, Font Llitjos and Black [6] adopted a web-based interface to improve pronunciation models as well as correct the pronunciations in the CMU dictionary by evaluating and collecting proper name pronunciations online. Font Llitjos and Black [7] [8] hypothesized that higher pronunciation accuracy can be achieved by adding the knowledge that people adapt their pronunciation according to where they think a proper name comes from, to a statistical model of pronunciation. The ONOMASTICA project [9] [10], a European wide research initiative, aims at the construction of multi-language pronunciation lexicon for proper names by upgrading the existing rule engines to cope with the problems posed by proper names. A significant part of the work was also devoted to the development of self-learning G2P conversion methods and the comparison of their performance with the one of rule-based methods.\nA general purpose G2P rule base cannot cater to proper names because such rule bases are developed for a particular language cannot be generalized to all kinds of words, especially for the proper names. This means, there is a need to develop a pronunciation dictionary for proper names. But the development of such a lexicon1 is not\n1We will use lexicon and dictionary interchangeably in this paper\n3 possible by having a mere rule set; it demands manual effort to generate phonetic transcriptions of a large set of names. A possible solution is to create a small set of words2 which when phonetically transcribed, manually, can span and hence transcribe all the proper names in a given database. Obviously, the choice of the words that have to be transcribed should be such that they occur frequently in the database of names.\nSeveral problems which were solved by constructing a cost function and finding the extremes (maxima, minima) are mentioned in literature (for e.g., [11], [12], [13]) This paper describes a method to enable construction of this set of words derived from the actual proper names database. We call it basis in a loose sense; taking cue from vector algebra. We construct a cost function which when minimized results in the identification of a basis. This can then be used in phonetic transcription of the full database of proper names. The rest of the paper is organized as follows. Section II formulates the identification of basis as an optimization problem. We also discuss the trivial cases of creation of a basis for proper names. Section 3 describes the proposed algorithms for basis creation of proper names. Section 4 presents experimental results and we conclude in Section 5 and also give future directions."
    }, {
      "heading" : "II. PROBLEM FORMULATION",
      "text" : "We address the following problem.\nGiven a proper name database of |N | names (e.g., {rama, krishna, narayana ...}), can we construct a smaller set of words (basis, e.g., {ra, na, krish, ya, ...}) automatically, such that all the |N | names can be formed by the words in the basis, namely\nrama = ra ⊕ ma3 krishna = krish ⊕ na narayana = na ⊕ ra ⊕ ya ⊕ na\n...\nGiven a database of proper names4, two trivial cases of building a pronunciation lexicon are possible. (a) At one extreme one could build a pronunciation lexicon by manually transcribing all the names in the proper names database and (b) On the other extreme one could have a pronunciation dictionary of the 26 letters of the English alphabet and use that to construct the pronunciation lexicon of all the names in the dictionary by concatenating the letters that make the name. Obviously, the first trivial case is manually intensive while the second trivial case is manually easy but introduces as many joins as the number of letters that make the name; as a result the pronunciation produced is feeble. The question that one is posing here is ”Is there an optimal set of words that one can identify and manually\n2Words could be names themselves or part of names 3⊕ represents a join 4The proper names are written in Roman script\n4 transcribe so that it can be used to produce a good pronunciation dictionary?”. In other words, is there an optimal set of words such that the need for manual transcription is small and at the same time the pronunciation of the names in the database is good? In this paper we construct a cost function which helps us achieve a set of words (we call it the basis because it has properties of a basis) which can be used to construct the pronunciation dictionary of the full set of proper names.\nWe make use of a restricted definition of basis (see Appendix A) to assist our problem formulation. In our case, the vector space is the complete set of names in the database and the basis is a set of words such that, one can construct a name in the database by joining one or more words from the basis. Further, no word in the basis can be formed by joining one or more words in the basis (Property 1, Appendix A). This is analogous to the scenario of concatenative speech synthesis where one looks for the longest possible speech unit to synthesize speech with minimal discontinuities.\nThe optimization required is that the number of entries in the basis should be as small as possible to minimize the manual effort to transcribe them and at the same time the number of basis words (joins) used to construct a name in the database should be small. These two requirements are contradicting and hence the need for optimization.\nLet N = {N1,N2, ...,N|N |} represent all the names in the proper names database and let B = {b1, b2, ..., b|B|} be the basis satisfying the linear independence property of Appendix A, namely for every bk ∈ B; bk can not be expressed as bi⊕bj⊕...⊕bl, using any bi, bj , ..., bl ∈ B and bi or bj or ... or bl 6= bk. This implies b1 ⊥ b2 ⊥ ... ⊥ b|B|. Additionally, for any name Np ∈ N , one can write\nNp = ⊕nbi bi ∈ B (1)\nThis is equivalent to saying that Np can be represented by a join of some n elements in the basis set B which results in Jp = (n− 1) joins. Thus the total number of joins, |J | required to construct the entire database of |N | names is\n|J | = |N |∑ p=1 Jp (2)"
    }, {
      "heading" : "A. Trivial cases",
      "text" : "As mentioned earlier, two trivial cases of construction of pronunciation dictionary are possible.\nCase (i): If the number of joins to construct the names is to be small then all the names in the database should be present in the basis set and this would result in the largest basis, say Bmax which would have all the |N | names in the database. Further there is a possibility that Bmax is not a basis in the sense defined in Appendix A. This is shown in Figure 1.\nCase (ii): The smallest possible basis Bmin would be the set of 26 letters in the English alphabet and this basis would definitely span the entire database of names, but the number of joins, |J | required to form the names in the database would be very large. This is shown in Figure 2.\nA typical plot of the number of elements in the basis |B| versus the total number of joins required to construct all the names in the database |J |, is shown in Figure 3 . The scenario depicted in Case (i) corresponds to the point A in Figure 3 and the Case (ii) corresponds to the point B in Figure 3. We believe that the cost of construction of basis would be maximum at these two extreme trivial cases. Probably there is a case between these two trivial solutions; like the knee point C at which the cost of construction of the basis would be minimum as shown in Figure 3 and 4 which can be achieved. We investigate if we can identify C in Figures 3 and 4. One has the choice of identifying the basis by starting from an initial basis. There are 4 different ways of initializing the basis. (a) start at point A, (b) start at point B, (c) choose some Binit and (d) start with B = null. We experiment with cases (c) and (d). Note that in both of these cases, we are traversing through only a portion of the curves shown in Figures 3 and 4 meaning starting at some point on the curve and reaching the knee point C.\nLet Binit be an initial basis. Then a name {Np}|N |p=1 in the database can, in Case (a), be completely represented by using some of the elements in the basis, namely, Np = bi⊕ bl⊕ ...⊕ bm, where bi, bl, ..., bm ∈ Binit and in Case (b) be partially represented, namely, Np = bi⊕nb⊕bm, where bi, bm ∈ Binit, and nb /∈ Binit. In Case (b), for Np to be representable using the basis, we need to necessarily add nb to Binit and further make sure that nb is orthogonal to all\n6\nthe elements in Binit, namely {bi}|Binit|i=1 . The addition of nb introduces an extra element into Binit, hence increasing size of the basis |Binit|+ 1. In reality we need to keep the size of basis as small as possible. The identification of an optimal basis set reduces to an optimization problem. Specifically, to optimize a function of |B| and |J |. Namely,\nC = f(|B|, |J |) = |B| {\n1 + |J | |N |\n} (3)\nwhere C is the cost of construction of the optimal basis B. Figure 4 shows the variation of the cost function C for different combinations of |B|5 and |J |. constructs the basis. This will be clearer in Section 4. Now the optimization problem can be stated as\nmin B {C} (4)\nmeaning, choose a basis B such that C is minimized. The object is to find the knee point C at which the cost (C) of construction of the optimal basis (B) corresponding to which the number of joins (J ) are ”reasonable”, would be minimum. The cost C, would be maximum at the two extreme points A and B in Figures 3 and 4. At point A,\n|B| = 26 and |J | = ∑|N |\ni=0 (li − 1) where li is the length of the name Ni. In this case, as |N | → ∞, |J | → ∞ and\nhence C → ∞. At point B, |B| = |N | and |J | = 0. In this case, as |N | → ∞, C → ∞.\n5Here, |B| is not a basis in a strict sense as defined in Appendix A\n7 This formulation seeks the construction of an optimum basis that can span the entire database which can be achieved with optimal values for the two parameters |B| and |J | together. The expectation is that the optimum basis is created at some knee point C on the curve shown in Figures 3 and 4, where the number of basis elements and the number of joins are optimal."
    }, {
      "heading" : "III. ALGORITHMS FOR THE CONSTRUCTION OF BASIS",
      "text" : "We propose two algorithms for the construction of the basis - one with a choice of initial basis (see Algorithm\n1) and the other with out an initial basis (see Algorithm 2).\nDefinitions\n• Rank deficient basis: The basis set is called rank deficient if it is non-orthogonal meaning, some of the members\nin the set can be constructed using other entries in the set. A rank deficient basis does not satisfy the linear independence property (Appendix A). • Span deficient basis: The basis set is called span deficient if it does not span the entire proper names database\nmeaning, all the names in the database can not be constructed using this set. A span deficient basis does not satisfy the spanning property (Appendix A)."
    }, {
      "heading" : "A. Algorithm 1",
      "text" : "Step 1, initialize Binit: The basis is initialized by sorting the |N | names in the database in the descending order of the number of occurrences in the database and then picking up all the names whose frequency of occurrence is greater than or equal to k% of the maximum frequency6. Step 2, isOrtho(Binit): Binit is checked for its orthogonality, namely, it is checked if any word in it can be completely constructed with a combination of other words in it. This task is accomplished by isOrtho(). Step 3, makeOrtho(Binit): If Binit is found to be rank deficient (non-orthogonal), there is a need to make it orthogonal. If an element is found to be completely constructed with other elements in the set Binit, that element is deleted from the set. This task is accomplished by a function named makeOrtho(). The process of orthogonalization of basis is described briefly in Appendix C. Step 4: Start an iteration of constructing the basis. Step 5, initialize Bm = Binit: We initialize a new set Bm with Binit. Bm will be used to store the new words (that are not in Binit) required to construct all the names in N if Binit is span deficient. Step 6, for each name Np ∈ N , we do the following. Step 7, forming Bp: Let Bp = {bp1, bp2, ..., b|Bp|} such that Bp ∈ B and can completely or partially construct the name Np in the database, namely, all the basis words in Bp are substrings7 of the name Np. Note that Bp can be a 6’Maximum frequency’ refers to the frequency of the name which occurs the most number of times in the database. 7We consider a word as a substring of a name if it is a part of the name or sometimes the name itself\n8 Algorithm 1 Pseudo-code N = {N1,N2, ...,Np, ...,N|N |} 1. initialize Binit = {b1, b2, · · · , bi, · · · , b|Binit|} 2. isOrtho(Binit) 3. Binit = makeOrtho(Binit) 4. do 5. initialize Bm = Binit 6. for each name Np ∈ N 7. {form Bp = {bp1, bp2, ..., bpk, ..., bp|Bp|}\nsuch that Bp ⊂ Binit and bpk is a substring of Np\n8. Identify all possible_sequences of Np using Bp {Np1,Np2, ...,Npl, ...,Npr} 9. collect all the new words 10. for each Npl,\nobtain_cost Cpl of Npl (Equation 16) end for\n11. choose Npl with minimum Cpl add new words in Npl to Bm end for 12. isOrtho(Bm) 13. Binit = makeOrtho(Bm) 14. goto step 5 15. until(|Bm| − |Binit|) < ) 16. Bopt = Binit\nnull set meaning there are no elements in the basis which is a substring of Np. In such a case Np should be added to the basis. Step 8, construction of possible sequences (Np) with Bp: Consider Bp is not empty; then the words in Bp may partially or completely construct Np (see Equation (1)). Let the name Np be constructed with Bp in r different ways as shown in Figure 5.\nAs seen in Figure 5 there are r possible sequences constructed for the name Np. The choice of the lth sequence is represented as Npl. For example, the sequence Np2 requires a new word np21 which is not in Bp, for successfully constructing Np, while Npl requires two new words np31 and np32 to construct Np, while Np1 and Npr completely construct the name without the aid of any new word being added to the existing basis. If more than one such representation of Np is possible using different combination of words in Bp, then a decision has to be taken as to which representation is to be retained. In such case, the selection depends on the cost of constructing the sequence.\nSome sequences might partially construct the name. Or sometimes, none of the sequences might completely construct the name. In the later case, there is a need to include some new words into the basis, to enable the basis to construct the name (and the entry should also be orthogonal to the existing basis as mentioned earlier). So, a decision has to be taken about which new word(s) should be added to the basis and what is the cost of such\naddition. Step 9, collect all the new words: The new words required by all the sequences formed for a name are collected and their frequency of occurrence is calculated. Note that even if more than one sequence formed for a name require a new word, the new word’s frequency is counted only once. Thus the maximum value of frequency for a new word would be |N | meaning that this new word is required by all the names in the proper name database.\nFor every name in the database, we have several possible sequences and a list of words which are not in the basis. We need to choose one of the r sequence choices to represent the name Np. The choice is one that results in (a) minimal number of joins and (b) adds minimal number of entries to the existing basis set (Binit). Observe that there is a need for optimality in choosing one of the r sequences. We construct a cost function to identify the optimal sequence choice. Step 10, obtaining cost for each word sequence Npl: Let the lth sequence (Npl) out of the r sequences that represent Np has ηpl number of words, {s1, s2, ..., sk, ..., sn} out of which ηnew are new and ηex belong to the existing basis, meaning ηpl = ηnew + ηex. If ηjoins is the number of joins in the lth sequence, then\nηjoins = (ηpl − 1) (5)\nLet L be the length (number of letters) of the name Np. The cost function Cpl is formulated as\nCpl = fpl(µ, ν, ηpl, ηnew, ηjoins, Pav, Fav, SAav) (6)\na function of the parameters of the word sequence Npl namely, µ, ν, ηjoins, ηnew, ηpl, Pav, Fav and SAav. And\n10\nwe choose the sequence Npl such that\nNpl = argmin (l)\n{ Cpl }\n1 ≤ l ≤ r (7)\nThe cost function Cpl is best described by looking at each element involved in the construction of Cpl. We identify the relevance of the features and the redundancy in them in the following discussion. µ is the average length of the words in a sequence which is given by\nµ = 1\nηpl npl∑ k=1 lk (8)\nwhere lk is the length of the kth word sk in Npl. Maximization of µ reduces the number of joins in the sequence. Observe that the component ∑ηpl\nk=1 lk = L. Hence, Equation (8) reduces to µ L = 1 ηpl . So, maximization of µ means\nminimization of ηpl (number of words in the sequence) which in turn reduces the number of joins, ηjoins (see Equation (5)) in the sequence Npl. Hence, considering one of these three parameters is sufficient in formulating the cost function. ν is the variance of the lengths of words in the sequence Npl and is given by\nν = 1\nηpl ηpl∑ k=1 (lk − µ)2 (9)\nPav is the average percentage of acceptance of the words in the sequence Npl and is given by\nPav = 1\nηpl ηpl∑ k=1 pdk (10)\nwhere pdk is the ’percentage demand’ of the word from all the r sequences formed for the present name namely, pdk is the percentage of r sequences formed for Np which require sk.\npdk = Number of sequences demanding sk\nr (11)\nFav which is defined only for the new words in the sequence, is the average frequency of occurrence of the new words in Npl and is given by\nFav = 1\nηnew ηnew∑ k=1 fk (12)\nwhere fk is the frequency of occurrence of the new word sk as a basis element, namely, fk is the percentage of names in the database that are in requirement of sk for their construction (even if one of the r sequences formed for Np requires the word). So, fk is given by\nfk = Number of names requiring sk\n|N | (13)\nfk of every new word is obtained in Step 9. SAav is a binary valued attribute named by ’Syntax rule acceptance’\n11\nand is defined for the new words in the sequence and checks if the word sk to be introduced into the basis follows the syntactic rules given in Appendix B. sak is set to 1 if sk follows the syntax rules and is set to 0 if it violates the syntax rules. ηak is the number of words following the syntactic rules out of the ηnew number of new words in the sequence Npl (while the remaining are violating) and is given by\nηak = ηnew∑ j=1 sak (14)\nSAav is the percentage of new words following the syntactic rules given in Appendix B and is given by\nSAav = ηak ηnew\n(15)\nIdeally, for any word in the sequence, the features lk and pdk should be maximum and for a new word to be included into the basis, its fk should be maximum and sak should be 1. We saw earlier that considering one of the three features µ, npl and njoins is sufficient. This implies that the 4 parameters µ, Pav, Fav and SAav defined for a word sequence should be maximized. In addition, the overall variance (ν) of the lengths of the words and the number of new words (ηnew) in the sequence should be minimized for the sequence to be optimal. In other words, the proportionality of the cost of constructing a name (cost of selecting one of the r sequences formed for a name) with the features of the word sequence is given as follows\nCpl ∝ ηpl\n∝ ηjoins\n∝ ηnew\n∝ ν ∝ 1 µ ∝ 1 Pav ∝ 1 Fav ∝ 1 SAav\nConsidering the redundancy in features and their relation with the cost of construction of a name, we write the function fpl as shown in Equation (15).\nfpl(µ, ν, ηnew, Pav, Fav, SAav) = λµ µ + λνν\n+λpPav + ληηnew( 1 Fav + 1SAav ) (16)\n12\nwhere λµ, λν , λp and λη are the weights assigned to µ, ν, Pav and the new words of the sequence respectively\nsuch that\nλµ + λν + λp + λη = 1 (17)\nWe define the weight set as Λ1 = {λµ, λν , λp, λη}. Note that different choices of Λ1 result in different basis sets. We choose that set which gives the minimal cost. Step 11, choose Npl with minimum Cpl: One sequence among the r sequences (formed for a name Np) which gives the minimum cost is selected (recall Equation (7)) and the new words, if any, present in the sequence, are stored separately (Bm in the pseudo code). This process is repeated for all the proper names in the database. After all the names in the database are constructed with the existing basis, we are left with a set of new words to be introduced into the basis. We also have the frequency of occurrence of each of the new words and which database name is in requirement of a new word.\nIn summary, for a given name, the list of candidates from the existing basis that can construct the present name is collected and the sequences which partially or completely construct the name are formed. Based on the cost function formulated, one of the sequences that represent the name is selected and new entries, are made into the existing basis if required. Step 12, isOrtho(Bm): After adding new elements to the existing basis (We add all the new words to Bm which is initialized to Binit - see Step 5), (Bm) is checked for its orthogonality (rank deficiency). Step 13, makeOrtho(Bm): If Bm is found to be rank deficient, it is made orthogonal using the function makeOrtho().\nBy constructing the names in N with the existing basis (not in a strict sense), we check its spanning property and if it is found to be span deficient, by minimizing the cost function, we add to it, the required words to make it span the entire database. Then we check for its orthogonality property using isOrtho() and make it orthogonal using makeOrtho().\nThis completes one iteration. Step 14, goto step 5: Once, an orthogonal basis is formed, the database of names are again constructed with the updated basis. In this iteration, if some database names are not completely constructed with the pruned basis, some new entries are again made in to the basis based on the cost function formulated. The new basis is again checked for its orthogonality and pruned if necessary. The procedure of constructing the names of the database with the pruned basis is repeated again. New entries are appended to the basis if required. Step 15, until(|Bm| − |Binit|) < : The process of growing and pruning of the basis (checking for the spanning and orthogonality properties of the loosely defined basis set) is stopped when no significant growth and redundancy in the basis are observed in successive iterations. Note that is a small positive value.\n13\nStep 16, B = Binit: The optimum basis for the generation of pronunciation dictionary for the set of proper names, is the set of words obtained in the last iteration of pruning of the basis.\n1) Conditions for convergence of the cost function: We saw in Section 2 that the cost of constructing the basis is maximum at the points A and B in Figure 4 and an optimal basis is achieved at the knee point C. If |Jinit| is the number of joins corresponding to the initial basis |Binit|, then (|Binit|, |Jinit|) is a point between the points A and C or B and C on the curve shown in Figure 3. The optimal basis Bopt is achieved at Step 14 in Algorithm 1 where the cost function converges to the knee point C. Note that in Algorithm 1, C is non increasing. Let the cost C at nth iteration be Cn and at (n+ 1)th iteration be Cn+1, then\nCn = |Bn| {\n1 + |Jn| |N | } Cn+1 = |Bn+1| { 1 + |Jn+1| |N | } .\nConvergence of the cost function is achieved when Cn+1 ≤ Cn or Cn − Cn+1 ≥ 0 which reduces to\n(|Bn| − |Bn+1|) + 1\n|N | (|Bn||Jn| − |Bn+1||Jn+1|) ≥ 0.\nThe cost function is convergent if and only if the conditions (18) and (19) are satisfied.\n|Bn+1| ≤ |Bn| (18)\n|Bn+1||Jn+1| ≤ |Bn||Jn| (19)\nThe convergence is validated through experiments in Section 4.\nubsectionAlgorithm 2\nAlgorithm 2 Pseudo-code N = {N1,N2, ...,Np, ...,N|N |} B = {} 1. for each name Np ∈ N 2. form all possible_sequences of Np\n{Np1,Np2, ...,Npl, ...,Npr} 3. for each Npl,\nobtain_cost Cpl of Npl end for\n4. choose Npl with minimum Cpl add new words in Npl to B 5. isOrtho(B) 6. Bopt = makeOrtho(B)\nend for\n14\nStep 1, for each name Np ∈ N we do the following. Step 2, construction of all possible sequences (Np):\nHere, we have no initial basis. We construct the name Np in all possible ways in which it can be constructed with its substrings8. An example is possible sequences of the name ’gopal’ are {g opal, go pal, gop al,\ngopa l, g o pal, g op al, g opa l, go p al, go pa l, gop a l, g o p al, g o pa l, g op a l, go p a l, g o p a l}. The sequences that have a single letter are excluded from this list. Step 3, obtaining cost for each word sequence Npl: In this case, the cost function Cpl is based on the parameters µ, ν, Pav and SAav9 and the function fpl is given by\nfpl(µ, ν, Pav, SAav)\n= λµ µ + λνν + λpPav + λs SAav\n(20)\nwhere λµ, λν , λp and λs are the weights assigned to µ, ν, Pav and the syntax of the words respectively such that\nλµ + λν + λp + λs = 1. (21)\nWe define the weight set as Λ2 = {λµ, λν , λp, λs}. Step 4, choose Npl with minimum Cpl: One sequence among the r sequences (formed for a name Np) which gives the minimum cost is selected (recall Equation (7)) and the words in the sequence are added to the basis. This process is repeated for all the proper names in the database. Step 5, 6: The basis thus formed is then checked for its orthogonality and made orthogonal using the functions isOrtho() and makeOrtho()."
    }, {
      "heading" : "IV. EXPERIMENTAL RESULTS AND DISCUSSION",
      "text" : ""
    }, {
      "heading" : "A. Proper names database",
      "text" : "For our experimentation, we used a database of proper names10 which consisted of 1, 63, 600 entries, majority of which are Indian names. Majority of the names were made up of two parts - a first name and a second name11. The first and surnames are considered as two different names and the duplicates are removed. So, to create a transcription dictionary one had to achieve transcription of these unique names. To test the performance of the proposed algorithm we further processed these unique names by removing names with two or less number of characters. This resulted in a set of |N | = 25884 unique names. 8substring is a part of the name 9The definitions of the parameters remain same as discussed in Algorithm 1. 10Company address book 11We did not distinguish between a first name and a surname for the set of experiments conducted. We believe that the proposed algorithm shows a better performance if we create separate basis for first names and surnames.\n15"
    }, {
      "heading" : "B. Basis construction",
      "text" : "The following results are obtained by using Algorithm 1 for the construction of basis. The names are first sorted in the descending order of their frequency of occurrence in the entire database. All the names whose frequency is greater than or equal to 40% of the maximum frequency are taken as Binit which resulted in |Binit| = 225 (Step 1; Algorithm 1). Using isOrtho() and makeOrtho(), Binit is checked for its orthogonality (see Appendix A) i.e., the words in Binit that can be constructed from the other words in Binit are removed from it. The process of orthogonalization of basis is described in Appendix C. This resulted in |Binit| = 224. This set is not strictly a basis because it doesn’t satisfy the Spanning Property (Property 2, Appendix A). The unique names in the database are then constructed by joining the words in Binit. For a given name in the database Np, the set of all names in the basis Binit, which are the sub-words of Np, Bp = {bp1, bp2, ..., bpk, ..., bp|Bp|} is first collected (Step 7, Algorithm 1). Many of the names in N had their substrings set, Bp empty. This is because the initial basis contains only 224 words out of which all are ‘complete names’. The probability of their occurrence as a part of other names is hence very low. This resulted in many new words being appended to the initial basis Binit which resulted in |B1| = 25476. Using isOrtho() and makeOrtho() |B1| is made orthogonal, and this reduced the size of |B1| to 10435. A significant growth and reduction in the size of basis is observed in this iteration. The above process of growing and pruning (orthogonalization) of the basis is repeated for a few iterations till no significant growth or reduction in the size of basis is observed. For the set of experiments conducted, we chose the weight set as Λ1 = {0.4, 0.2, 0.1, 0.3}. These values satisfy Equation (17). We chose this weight set as follows. The basis is constructed for 256 combinations of weights of the features of the cost function (16), each weight taking a value from [0, 0.1, 0.2, · · · , 0.9, 1]. The chosen weight set is the one which resulted in the minimal overall cost given by Equation ((3).\nRecall the cost function defined in Equation 3 which has to be minimized. Table 1 shows the basis size before and after orthogonalization (columns 2 and 3 respectively), the number of joins corresponding to the rank deficient basis (column 2) and the corresponding cost C. Figure 6 gives the actual variation of cost function |C| over 5 iterations of constructing the basis until convergence. Figure 7 shows the plot between |B| and |J | for the experimentation\n16\nperformed which resembles Figure 3. We observe from Table I that the conditions (18) and (19) derived for the convergence of the cost function are met in the experimentation. We see from Column 3 of Table I that the size of basis is decreasing over iterations which satisfies condition (18). We see from Column 5 of Table 1 that the product of basis size and number of joins (|Bm||J |) is also reducing with iterations. The variation of the product of |Bm| and |J | until convergence is shown in Figure 8.\nCompared to Algorithm 1, Algorithm 2 is simpler but computationally intensive. The results obtained by using Algorithm 2 are as follows. We chose Λ2 = {0.4, 0.3, 0.3, 0} based on experimentation. These values satisfy Equation (21). The obtained values for basis size and number of joins are |B| = 7174 and |J | = 38213. The results presented for both the algorithms are obtained by not considering the feature SAavg in the cost function."
    }, {
      "heading" : "C. Transcription of the optimal basis and the development of Pronunciation Lexicon",
      "text" : "Now the obtained basis set has to be transcribed manually. We followed the following process which is specific\n17\nto Indian languages. The basis words are written in Devanagari12 (Hindi) script. Using a lookup table, which maps Devanagari graphemes to phonetic symbols, the Devanagari script of the basis words is converted into Festival TTS[14] accepted DARPA format and Microsoft supported SAPI format. For the sake of consistency we had three people transcribe the basis separately and discuss among them to come up with a single set of transcription for all the basis words. One or more of these basis transcriptions are concatenated to generate the transcriptions of the proper names in the names database. Table II shows a few basis words and their corresponding transcriptions in DARPA and SAPI formats while Table III shows some proper names from the name database, their construction using the basis and the obtained phonetic transcriptions using the proposed algorithms.\n12a phonetic script\n18"
    }, {
      "heading" : "D. Accuracy of the system",
      "text" : "The next step is to ensure that the generated transcriptions obtained through manual transcription of the basis words are correct. The phonetic transcription of a proper name formed with two or more basis words will vary when a basis word has multiple possible pronunciations. This leads to a slight variation in the pronunciation of names. Note that the higher the occurrence of a basis word and the smaller its length, the greater is the possibility of variation in its pronunciation. The cost function formulated tries to maximize the length of the word which goes into the basis, thus minimizing the number of basis elements having multiple pronunciations. Nevertheless, the optimization process results in some basis words having multiple pronunciations which when used to generate transcriptions of names in the names database result in a slight variation in the pronunciation of names. They have to be taken care of manually when producing the final pronunciation lexicon of the names in the database. Our observation shows that the main source of multiple pronunciation arise in the presence of a vowel. While transcribing the basis words, sometimes, one may not be aware whether the vowel in the basis word is long or short. For example, in Table III, the basis word ra in the first name ramakanth should have a transcription r aa and in the second name rajeshwar, it should be transcribed as r a. Using the same transcription of ra for both the names leads to a slight variation in the pronunciation of one of them. However, for longer basis words the probability of multiple pronunciations is less.\nAfter transcribing the basis, as mentioned above, 200 names from the proper names database are selected randomly and their phonemic transcription is constructed by concatenating one or more words using the transcribed optimal basis. The obtained transcriptions are verified manually and the number of correctly transcribed names are computed. This shows that 85% of the names are correctly transcribed. The inaccuracy in the transcriptions of the remaining 15% names is due to the multiple pronunciations of some basis words, majorly due to the following reasons:\n(a) long vowels in the basis words transcribed as short vowels (and vice versa), (b) multiple pronunciations of phoneme /s/ and /t/ which can have a phonetic form of [/s/, /sh/] and [\n/t/,/T/ ] respectively.\nThe above is the case when different names with different pronunciations are spelled the same way. Also note that different people spell the same name in different ways inspite of having a unique pronunciation for the name. For example, an Indian name which has a phonetic spelling ch au d a r i is spelled in at least three different ways such as chaudary, chowdhari, chaudhari depending on a person’s choice. Note that the proposed system generates slightly different transcriptions for these three instances of the same name.\n19"
    }, {
      "heading" : "E. Comparison with Festival TTS G2P rule base",
      "text" : "Column 6 in Table III shows the phonetic transcriptions of the names obtained using the G2P rule base for the out of vocabulary (OOV) words used in the Festival TTS engine13. The results show that the transcriptions generated using the proposed method are found to be more accurate than the ones generated using the Festival TTS rule base. The proper names are also synthesized using these two kinds of transcriptions, (a) one obtained using the process discussed in this paper and (b) the one obtained using the G2P rule base used in Festival TTS, with the Festival TTS engine. The names synthesized using the transcriptions obtained by the proposed method are found to be perceptually better. The perception test was carried out by asking two persons who were not involved in the basis transcription process to listen to the synthesized proper names and rate the better of the two for each name (they had no idea which transcription was used in the synthesizing process.\nNote: The algorithms proposed in this paper are generic and are suitable for proper names of any language. However, the system performs better if used for a database of proper names of same origin or geographical area. For example, the performance of the system is good when used to transcribe a proper names database containing only Indian names or only Chinese names, but degrades when used for a database which has a mix of both Indian and Chinese proper names. The results presented above are for a database containing a majority of Indian names but not all. Extending the same principle, if the system is used only for a database of person names or place names and not a mixture of both, the performance would be better."
    }, {
      "heading" : "V. CONCLUSION",
      "text" : "Research on automatic G2P transcription has reported promising results for phonetic transcription of regular text, where G2P transcriptions follow certain rules. Generating phonetic transcriptions of proper names, where the general purpose G2P converter can not be applied directly, involves human endeavor. In this paper, an optimization approach for the automatic generation of pronunciation lexicon for proper names has been proposed. We first construct a cost function and the transcription problem reduces to one of minimizing the constructed cost function. Two algorithms for the identification of basis have been proposed and the conditions for the convergence of the cost function have been derived. Experimental results on real database of proper names validate the convergence conditions derived and hence show that the developed optimization framework helps in reducing the mundane task of transcribing proper names. The formulated frame work is general and hence not restricted to Indian proper names, though the experimentation has been carried out on an Indian name database. In fact, the framework is suitable for any database of proper names irrespective of language. Through experimental results we have demonstrated the working and the validity of the proposed approach.\n13We used the Festival TTS G2P facility which was readily accessible\n20"
    }, {
      "heading" : "APPENDIX A",
      "text" : "BASIS\nIn linear algebra, a basis B of a vector space V , by definition, is a set of linearly independent vectors that completely spans V . B = {b1, ..., bm} is said to be a basis of vector space V = {v1, ..., vn} if B has the following properties:\n• Linear independence property: If a1, ..., am are scalars and if a1b1 + ... + ambm = 0, then necessarily a1 =\n... = am = 0. This implies that b1, ..., bm are orthogonal or b1 ⊥ b2 ⊥ ... ⊥ bm;\n• Spanning property: For every vk in V it is possible to choose scalars, a1, ..., an such that vk = a1b1+...+anbn."
    }, {
      "heading" : "APPENDIX B",
      "text" : "SYNTACTIC RULES\nIt is advantageous to study/analyze the words syntactically before adding them in to the basis for if the resultant basis element is not following any syntax, its phonetic representation might not properly contribute to phonetically represent a longer name which is a super set of it. Syntactic knowledge is acquired by observing the sequences formed for a name. Some rules are illustrated below. V denotes a vowel and C denotes a consonant. If the word is of a particular format, the following decisions would be taken on its candidature for the basis. (Letters in bold represent the elements to be added to the basis).\n• CC reject\nThe pronunciation of a phone in a sequence of phones depends on the adjacent phones. Consonants depend on vowels for their pronunciation. So, the basis element cannot be a pure consonant sequence. Examples:\n– shashank sha+sha+nk – joseph - jose + ph – shantanu sha + nth + anu – sunny - su+nny\nAll the words which are pure consonant strings are avoided. In other words, a basis element must have at least one vowel.\n• VC OK • CV avoid • VV reject\nIntroducing a split between two vowels is also not reasonable, because most of the times, the combination of two vowel letters in English forms a diphthongs. They may be two characters but their combination is a single\n21\nsound. Example: shailendra - sha + ilendra\n• Introducing a split between sh, th, dh also should be avoided they are two characters but their combination is\na single phone/sound Example: bharati bharat + hi"
    }, {
      "heading" : "APPENDIX C",
      "text" : "ORTHOGONALIZATION OF BASIS\nThe following procedure is followed to make the basis orthogonal. Names in the basis are sorted in descending order of their lengths. For a word bi in the basis, a set of all words bik which is a substring of bi is collected, Bi = {bi1, bi2, ..., bik, ..., b|Bi|}. If Bi is empty, bi is retained in the basis. For the words whose Bi is not empty, elements of Bi are sorted in descending order of their lengths. One name bik from Bi is considered at a time and its position is fixed in the word bi. The remainder of bi is filled with bik in the order they appear in Bi. By the end of this process, bi must have been formed completely or partially with the available elements in Bi. With one bik at a time as the first element to occupy its place in bi, and filling the remainder of the name with Bi, we form |Bi| number of sequences for bi. If any one of the |Bi| sequences completely represents bi, then bi is deleted from Bi; else it is retained. The following example shows the sequences formed for the name, bi = krishna Bi = {krishn, krish, rish, kris, ris, ish, hna, na, kr, hn, is, ri, sh}\nkrishn partially constructed\nkrish na Fully constructed (1)\nrish na Partially constructed\nkris hna Fully constructed (2)\nris hna Partially constructed\nkr ish na Fully constructed (3)\nkris hna Fully constructed (4)\nkrish na Fully constructed (5)\nkr ish na Fully constructed (6)\nkris hn Partially constructed\nkr is hna Fully constructed (7)\nri hna Partially constructed\nkr sh na Partially constructed\nIn the above example, the word krishna in the existing basis can be constructed in 7 different ways with the\n22\nother existing basis elements. So, it is not necessary to have it in the basis and hence removed from the basis."
    }, {
      "heading" : "ACKNOWLEDGMENT",
      "text" : "The authors express their gratitude to Amol, Meghna and Imran for their assistance in transcribing the basis and\nevaluating the generated phonetic transcriptions."
    } ],
    "references" : [ {
      "title" : "High-quality Text-To-Speech synthesis: An Overview",
      "author" : [ "Thierry", "Dutoit" ],
      "venue" : "Journal of Elec. and Electronics Engineering, Australia: Special Issue on Speech Recognition and Synthesis, vol. 17, 1, pp. 25–37, 1997.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Grapheme to phoneme conversion for Tamil speech synthesis",
      "author" : [ "A.G. Ramakrishnan", "M. Laxmi Narayana" ],
      "venue" : "Proc. of Workshop in Image and Signal Processing (WISP-2007), IIT Guwahati, pp. 96–99, Dec 28-29 2007.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Development of a phoneme-to-phoneme (P2P) converter to improve the grapheme-to-phoneme (G2P) conversion of names",
      "author" : [ "Q. Yang", "J.-P. Martens", "N. Konings", "H. van den Heuvel" ],
      "venue" : "Proceedings LREC, 1 2006, pp. 287–292.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "The upc tts system description for the 2007 blizzard challenge",
      "author" : [ "B. Antonio", "A. Jordi", "D.A. Pablo", "D. Erro", "I. Esquerra", "A. Moreno", "J. Perez", "T. Polyakova" ],
      "venue" : "Proc. of Workshop in Image and Signal Processing (WISP-2007), vol. The Blizzard Challenge 2007 – Bonn, Germany, August 25, 2007.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Nanneke, “(G2P) conversion of names. what can we do (better)?",
      "author" : [ "H. van den Heuvel", "M. Jean-Pierre" ],
      "venue" : "INTERSPEECH",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2007
    }, {
      "title" : "Evaluation and collection of proper name pronunciations online",
      "author" : [ "A.F. Llitjs", "A.W. Black" ],
      "venue" : "In Proceedings of LREC2002, Las Palmas, Canary Islands, 2002, p. 247254.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Knowledge of language origin improves pronunciation accuracy of proper names",
      "author" : [ "A. Font", "Llitjos", "A. Black" ],
      "venue" : "Eurospeech, Aalborg, Denmark, vol. 3, pp. 1919–1922, 2001.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1919
    }, {
      "title" : "Knowledge of language origin improves pronunciation accuracy of proper names",
      "author" : [ "A.F. Llitjos", "A.W. Black" ],
      "venue" : "In Eurospeech, 2001, pp. 1919–1922.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Transcribing names with foreign origin in the onomastica project",
      "author" : [ "P. Onomastica", "G. Joakim" ],
      "venue" : "1995.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "The onomastica interlanguage pronunciation lexicon",
      "author" : [ "T. Onomastica", "Consortium" ],
      "venue" : "1995.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Optimizing sub-cost functions for segment selection based on perceptual evaluations in concatenative speech synthesis",
      "author" : [ "T. Toda", "H. Kawai", "M. Tsuzaki" ],
      "venue" : "IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. Proceedings. (ICASSP apos;04)., vol. 1, 17-21 May, 2004, pp. 657–660.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Perceptual evaluation of cost for segment selection in concatenative speech synthesis",
      "author" : [ "T. Toda", "H. Kawai", "M. Tsuzaki", "K. Shikano" ],
      "venue" : "Proceedings of IEEE Workshop on Speech Synthesis, 11-13 Sept 2002, pp. 183–186.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "An evaluation of cost functions sensitively capturing local degradation of naturalness for segment selection in concatenative speech synthesis",
      "author" : [ "——" ],
      "venue" : "Speech communication, vol. 48, no. 1, pp. 45–56, 2006.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Festival TTS",
      "author" : [ "Centre for Speech Technology Research at The University of Edinburgh" ],
      "venue" : "available at http://www.cstr.ed.ac.uk/projects/festival/.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 0
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "The two major components of a TTS synthesizer are (a) natural language processing (NLP) module, which produces a phonetic transcription of the given text and (b) digital signal processing module, which transforms sequence of phones into speech [1].",
      "startOffset" : 244,
      "endOffset" : 247
    }, {
      "referenceID" : 1,
      "context" : "Dr, Mr, $700) into their corresponding graphemic representation [2].",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 1,
      "context" : "The system triggers the rule that best fits the current context [2].",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 2,
      "context" : "G2P converters usually produce a significant number of mistakes when converting proper names which are often of a foreign origin [3].",
      "startOffset" : 129,
      "endOffset" : 132
    }, {
      "referenceID" : 3,
      "context" : "Recently, Bonafonte et al [4] reported an average phonetic accuracy of 53% for proper names when a rule based methodology is used to construct a phonetic dictionary of proper names.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 4,
      "context" : "Van den Heuvel et al [5] tried to automate the process of transcribing proper names by using a cascade of a general purpose G2P converter and a special purpose P2P (phoneme to phoneme) converter; the P2P converter learns from human expert knowledge.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 5,
      "context" : "In a manual effort, Font Llitjos and Black [6] adopted a web-based interface to improve pronunciation models as well as correct the pronunciations in the CMU dictionary by evaluating and collecting proper name pronunciations online.",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 6,
      "context" : "Font Llitjos and Black [7] [8] hypothesized that higher pronunciation accuracy can be achieved by adding the knowledge that people adapt their pronunciation according to where they think a proper name comes from, to a statistical model of pronunciation.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 7,
      "context" : "Font Llitjos and Black [7] [8] hypothesized that higher pronunciation accuracy can be achieved by adding the knowledge that people adapt their pronunciation according to where they think a proper name comes from, to a statistical model of pronunciation.",
      "startOffset" : 27,
      "endOffset" : 30
    }, {
      "referenceID" : 8,
      "context" : "The ONOMASTICA project [9] [10], a European wide research initiative, aims at the construction of multi-language pronunciation lexicon for proper names by upgrading the existing rule engines to cope with the problems posed by proper names.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 9,
      "context" : "The ONOMASTICA project [9] [10], a European wide research initiative, aims at the construction of multi-language pronunciation lexicon for proper names by upgrading the existing rule engines to cope with the problems posed by proper names.",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 10,
      "context" : ", [11], [12], [13]) This paper describes a method to enable construction of this set of words derived from the actual proper names database.",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 11,
      "context" : ", [11], [12], [13]) This paper describes a method to enable construction of this set of words derived from the actual proper names database.",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 12,
      "context" : ", [11], [12], [13]) This paper describes a method to enable construction of this set of words derived from the actual proper names database.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 13,
      "context" : "Using a lookup table, which maps Devanagari graphemes to phonetic symbols, the Devanagari script of the basis words is converted into Festival TTS[14] accepted DARPA format and Microsoft supported SAPI format.",
      "startOffset" : 146,
      "endOffset" : 150
    } ],
    "year" : 2014,
    "abstractText" : "Development of a proper names pronunciation lexicon is usually a manual effort which can not be avoided. Grapheme to phoneme (G2P) conversion modules, in literature, are usually rule based and work best for non-proper names in a particular language. Proper names are foreign to a G2P module. We follow an optimization approach to enable automatic construction of proper names pronunciation lexicon. The idea is to construct a small orthogonal set of words (basis) which can span the set of names in a given database. We propose two algorithms for the construction of this basis. The transcription lexicon of all the proper names in a database can be produced by the manual transcription of only the small set of basis words. We first construct a cost function and show that the minimization of the cost function results in a basis. We derive conditions for convergence of this cost function and validate them experimentally on a very large proper name database. Experiments show the transcription can be achieved by transcribing a set of small number of basis words. The algorithms proposed are generic and independent of language; however performance is better if the proper names have same origin, namely, same language or geographical region.",
    "creator" : "LaTeX with hyperref package"
  }
}