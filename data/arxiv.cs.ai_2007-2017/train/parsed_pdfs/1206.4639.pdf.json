{
  "name" : "1206.4639.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Adaptive Regularization for Weight Matrices",
    "authors" : [ "Koby Crammer", "Gal Chechik" ],
    "emails" : [ "KOBY@EE.TECHNION.AC.IL", "GAL.CHECHIK@BIU.AC.IL" ],
    "sections" : [ {
      "heading" : null,
      "text" : "with the dimension n of the matrix, and n tends to be large in real applications. We describe, analyze and experiment with two new algorithms for learning distribution of matrix models. Our first algorithm maintains a diagonal covariance over the parameters and can handle large covariance matrices. The second algorithm factors the covariance to capture inter-features correlation while keeping the number of parameters linear in the size of the original matrix. We analyze both algorithms in the mistake bound model and show a superior precision performance of our approach over other algorithms in two tasks: retrieving similar images, and ranking similar documents. The factored algorithm is shown to attain faster convergence rate."
    }, {
      "heading" : "1. Introduction",
      "text" : "Many machine learning tasks involve models in the form of a matrix. As an important example, consider the problem of linear metric learning where the dissimilarity between a pair of samples is measured using the Mahalanobis distance, parametrized by a positive semi-definite matrix. A second important example is the matrix model obtained when learning multiple linear classifiers regularized jointly, like in the case of object recognition with many classes.\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nMany algorithms were developed for learning these two tasks, including online algorithms developed recently in the context of classification and ranking costs (Davis et al., 2007; Jain et al., 2008; Chechik et al., 2009).\nWhile such linear matrix models are common for metric and multiclass learning, the broader class of ”vector” linear model are a popular choice in many domains since they provide a good balance between simplicity, scalability and performance. Methods to generate linear classifiers from data have flourished in the past decade, including SVMImportantly, when learning linear models, it was recently shown that modeling the second order information about the set of models (Crammer et al. (2009) and the references therein), or using this information during training (Duchi et al., 2010) improves the convergence rate of the learning algorithms as well as the performance of the resulting classifiers. These very effective methods were developed primarily for handling vector models, and were not designed to handle matrix models.\nAt first sight, problems that involve learning matrices could be handled directly using methods developed for learning vectors, including the second order methods described above. In practice however, matrix models often pose a challenge to scalability, since both their memory and their runtime complexity scale quadratically with the data dimensionality n. Modeling second order interactions between features may therefore require n4 parameters, limiting these methods to relatively low dimensional data.\nIn this paper we study second-order methods for learning matrix models and test them in the context of similarity learning. We describe AROMA (Adaptive Regularization Of MAtrix models) an online algorithm that learns a distribution of matrix models. Since maintaining a full covariance matrix over the parameters would not be feasible for large dimensions, we describe models that capture part of the covariance structure. We first describe a simple model with a diagonal covariance matrix. While this model scales well to large matrices, it fails to model correlations between features which could be crucial in some applications. We\nfurther describe a factored model which is still linear in the number of parameters (quadratic in the dimension), yet captures some of the correlations between features.\nIn the context of metric and similarity learning, AROMA can be used to learn a distribution over metrics, instead of a single metric. We evaluate AROMA in two tasks of retrieving images and documents by evaluating similarity between objects. We find that the two AROMA variants outperform competing methods by a large gap. Additionally, the more involved variant convergence faster than all other methods evaluated. As far as we know, this makes it the state-of-the-art method for the extensively studied task of linear similarity learning.\nNotation: In this work we often consider the bilinear form q>Wp where q ∈ Rm, p ∈ Rn and W ∈ Rm×n. Given such a matrix W , we denote by vec (W ) ∈ Rmn the vector generated by “stacking” the columns of the matrix W . Using this operator we can write the bilinear form as an inner product q>Wp = vec (W ) · vec ( pq> ) . We denote by x z the element-wise product of two vectors (or matrices) and by sum(A) the sum of the elements of the matrix or vector A. We denote by |x|0 to be the number of non-zero elements of the vector x, known as `0 norm.\nGiven two square matrices Λ ∈ Rm×m and Ω ∈ Rn×n we denote their Kronecker product by Λ⊗ Ω. This is a matrix of size mn × mn that is composed of blocks, where the (i, j)th block is Λi,jΩ. Finally, (Sx) refers to the equation x in a longer version of this manuscript provided online1."
    }, {
      "heading" : "2. Problem Setting",
      "text" : "We focus on the problem of learning a linear similarity measure between pairs of objects q ∈ Rm, p ∈ Rn, in the form of SW (q,p) = q>Wp. This similarity measure is related to metric learning models of the form (q − p)>W (q − p) for square matrices W , and becomes equivalent to it when all vectors p and q have a constant W -norm. Interestingly, the similarity measure SW (q,p) does not have to be symmetric, and may even be defined for objects from with different dimensions m 6= n (non-square W ). In general, it allows to learn a measure of relatedness between objects from different domains, like images and sounds or images and text (as in Grangier & Bengio, 2008). Importantly, when the vectors representing both query and object are sparse and contain only few elements, |q|0 = kq, |p|0 = kp computing the similarity score takes only kqkp operations instead of mn for dense vectors.\nWe address a weak-supervision setup where training is based on relative similarity. Here, we are allowed to sam-\n1webee.technion.ac.il/people/koby/ publications/aroma_icml12long.pdf\nple triplets of objects, each triplet containing a ”query object” q ∈ Rm and two candidate objects p+, p− ∈ Rn, where it is known that the object p+ is more related (or similar) to the query q than the other object p−.\nImportantly, the relative similarity learning setup does not assume that there exists an absolute numerical level of similarity between an object and a query, or that the learner has access to it. Training therefore assumes a weaker type of supervision, making it easier to collect labeled data either from human raters, or by collecting indirect data about association of object pairs. For example, two web pages can be ranked by their similarity to a third web page by the number of users visiting them within the same session.\nFormally, our goal is to learn a bi-linear similarity scoring function SW (q,p) = q>Wp parametrized by W ∈ Rm×n such that the total ordering induced by the similarity function over objects p would be consistent with the partial ordering information given about p− and a query q. A similar model was recently studied in different contexts (McFee & Lanckriet, 2012; Kulis et al., 2011; Weston et al., 2011).\nWe formalize training as a constrained optimization problem and require that this relation between the induced ranking and the partial information of ordering holds with a safety margin,\nSW (q,p+) ≥ SW (q,p−) + 1 . (1)\nMore specifically, we develop an online algorithm that allows to rank objects by their similarity to a ”query object” q. Like online prediction algorithms, online retrieval algorithms work in rounds. On round i, the algorithm receives a triplet composed of a query qi ∈ Rm and two possible outcomes p+i ,p − i ∈ Rn. The algorithm than outputs a single bit indicating which outcome is better for the given query. It then receives the correct answer and updates its model.\nTo learn a scoring function that obeys (1), we define a hinge loss over the triplet (q,p+,p−)\n`W (q,p +,p−) = max ( 0, 1− q>W (p+ − p−) ) .(2)\nIn what follows, we describe two online algorithms to minimize this loss while modeling the distribution of matrix models W . We first review previous work on learning such distributions for vector models."
    }, {
      "heading" : "3. Adaptive Regularization of Weights",
      "text" : "We first describe the AROW algorithm that was designed for binary classification of vector inputs x ∈ Rd and introduced by Crammer et al. (2009).\nThe key idea of AROW (Dredze et al., 2008, and its predecessors), is that instead of maintaing a single vectorw during learning, AROW maintains a distribution over possible\nmodels. Specifically, AROW maintains a Gaussian distribution over vectors denoted by N (w,Σ), where w ∈ Rd and Σ ∈ Rd×d. The mean w encodes the knowledge of the algorithm about the weight features (linear model), and is used to make predictions. The covariance Σ captures the notion of confidence in the weights, and is used during training to set an effective learning rate for features with different statistics. AROW was motivated by tasks in natural language processing, where many features are very rare and a few features are frequent.\nAROW is an online algorithm that works in rounds. On the i-th round, the algorithm receives an input xi ∈ Rd and employs its current model to make a prediction ŷi ∈ {±1}. It then receives the true label yi ∈ {±1} and suffers a loss `(yi, ŷi). Finally, the algorithm updates its prediction rule using the pair (xi, yi) and proceeds to the next round.\nAROW updates its current model parameters w and Σ by minimizing the following objective function\nLAROW = DKL (N (w,Σ) ‖N (wt−1,Σt−1)) (3)\n+ 1\n2r\n( max{0, 1− yix>i w} )2 + 1 2r x>i Σxi ,\nwhere DKL is the Kullback-Leibler divergence. This objective aims to find a model that classifies the sample (xi, yi) correctly, while keeping the distribution from changing abruptly at a single iteration.\nThe minimum of the objective in Eq. (3) was shown by Crammer et al. (2009) to be obtained by the update rule:\nwi = wi−1 + max\n( 0, 1− yix>i wi−1 ) x>i Σi−1xi + r Σi−1yixi, (4)\nΣi = Σi−1 − Σi−1xix\n> i Σi−1\nr + x>i Σi−1xi .\nAROW was shown to attain state-of-the-art performance on many problems (Crammer et al., 2009; Duchi et al., 2010) and its performance is analyzed both for full covariance matrices (Crammer et al., 2009) and diagonal covariance matrices (Orabona & Crammer, 2010). In the next section, and in this entire paper, we lift AROW to matrices, while maintaining both memory and speed efficiency."
    }, {
      "heading" : "4. Modeling Uncertainty over Matrices",
      "text" : "As with online classification learning, online retrieval algorithms work in rounds. At round i the algorithm receives a triplet composed of a query qi ∈ Rm and two possible outcomes p+i ,p − i ∈ Rn. The algorithm than outputs a single bit indicating which outcome is better for the given query. It then receives the correct answer and updates its model. For simplicity, we assume that the first outcome is always preferable, namely, given qi the algorithm should rank p+i\nover p−i . We now consider the problem of modeling uncertainty over matrices, in the context of online-learning similarity measures that obeys (1), and describe algorithms to minimize the loss in (2).\nA naive approach to model uncertainty over matrices would be to to use the linearity of the ranking function SW (q,p) in W , and write S as an inner product between two vectors q>Wp = vec (W ) ·vec ( pq> ) . Here, learning over matrices of dimension m× n is viewed simply as learning over vectors of dimension 1 ×mn. After transforming the matrix model into a vector, then the original AROW algorithm for vectors can be applied.\nUnfortunately, this approach requires to maintain the mean parameters as a vector of of sizemn and the full covariance matrix of size (mn) × (mn). Even for moderate dimension values of m and n, the size of a full covariance matrix m2n2 cannot be stored in memory. For instance, with m = n = 103, the dimension of the vectorized model is mn = 106 and the full covariance matrix requires 1012 parameters. Designing second order algorithms for matrices thus requires to model the covariance in a more compact way. We now discuss and develop two such compact representations and learning algorithms: a diagonal covariance, and a factorized covariance."
    }, {
      "heading" : "4.1. Diagonal Covariance",
      "text" : "Our first algorithm restricts the covariance matrices to be diagonal, using only mn non-zero elements (the size of the similarity measure W ). Denote by σ ∈ Rmn the diagonal elements of the covariance matrix. The update (4) becomes\nwi = wi−1 + max\n( 0, 1− yix>i wi−1 ) sum(x>i σi−1 xi) + r yiσi−1 xi\nand the covariance is,\nσi = σi−1 − σi−1 xi xi σi−1\nr + sum(x>i σi−1 xi) .\nWe denote by Σ ∈ Rm×n the covariance matrix that maintains one element per feature, and thus is diagonal-like, although it is rectangular in shape. We identify xi = qip>i , pi = p + i −p − i and yi = 1, to get the update in the notation used for matrix-similarity measures,\nWi = Wi−1 + αiΣi−1 ( qip > i ) where αi = max ( 0, 1− q>i Wi−1pi ) sum(qip>i Σi−1 qip>i ) + r (5)\nand Σi = Σi−1 − Σi−1 qip>i qip>i Σi−1 sum(qip>i Σi−1 qip>i ) + r .\n(6)\nAlgorithm 1: diagonal-AROMA\nInput parameters A scalar r Initialize W0 = 0 ∈ Rm×n , Σ0 = 1 ∈ Rm×n For i = 1, . . . , N\n• Sample a query qi ∈ Rm and two images p+i ,p − i ∈ R n, such that p+i should be ranked above p − i • Define pi = p+i − p − i • If 1 > q>i Wi−1pi then update: – Update Wi = Wi−1 + αiΣi−1 ( qip > i ) where\nαi = max(0,1−q>i Wi−1pi)\nsum(qip > i Σi−1 qip > i )+r\n(5)\n– Update Σi = Σi−1 − Σi−1 qip > i qip > i Σi−1\nsum(qip > i Σi−1 qip > i )+r\n(6)\nOutput: A weight matrix WN and its confidence ΣN\nFigure 1. The d-AROMA algorithm for similarity measures.\nWe call the algorithm d(iagonal)-AROMA for diagonalAdaptive Regularization Of MAtrix models, and it is summarized in Fig. 1. The memory required for d-AROMA is Θ(mn) - the space needed to store bothW and Σ. The time complexity is Θ(mn) as all operations involve componentwise operations between W and Σ; and p and q.\nBefore proceeding to describe the next algorithm we state a mistake bound for d-AROMA. LetM be the set of rounds for which the algorithm made a prediction mistake and let U be the set of example indices for which the algorithm made an update, yet no mistake occurred. Then,\nTheorem 1 Let V be any similarity matrix. Assume the algorithm is executed on any sequence then the total no. of mistakes it performs is bounded by,\n|M| ≤ ∑\ni∈M∪U max\n{ 0, 1− q>i V pi } − |U|\n+ √√√√‖V ‖2Fro + 1r m,n∑\nk=1,l=1\nV 2k,l ∑ iM∪U q2i,kp 2 i,l\n× √√√√r m,n∑ k=1,l=1 log (∑ iM∪U q 2 i,kp 2 i,l r + 1 ) + 2|U| .\nThe proof is omitted due to lack of space and is similar in spirit to the analysis in section 4.3 of Orabona & Crammer (2010). As in their, analysis we expect the bound to be small if either the combination of the kth feature of the query qi,k and of the lth feature of the output difference pi,l is rare (that is ∑ i∈M∪U q 2 i,kp 2 i,l is small), or that this combination is not useful for prediction, that is, V 2k,l is small. When most feature combinations fall under one\nof these two cases, we expect the second term in the first square-root term to be small and most of the values of the log function to be close to zero. Unlike the vector-variant of this analysis, here it is not required that the input features are sparse. Instead, we only require that for some inputs the query is sparse and for other inputs the difference between the objects is sparse, but not necessarily both."
    }, {
      "heading" : "4.2. Factored Covariance",
      "text" : "Our second approach to model the distribution of similarity matrices is based on factorizing the covariance matrix in a way that captures separately correlations in the ”input” (right side of the similarity matrix) and in the “output” (left side). To describe our second algorithm, we use the definition of a matrix-variate normal distribution (Gupta & Nagar, 1999).\nDefinition 1 A random matrix X ∈ Rm×n is said to have a matrix variate normal distribution with mean matrix W ∈ Rm×n and covariance matrix Ω ⊗ Λ where Λ ∈ Rm×m and Ω ∈ Rn×n are both symmetric and PSD, if vec (X) ∼ N (vec (W ) ,Ω⊗ Λ) . Matrix variate normal distributions are denoted by N (W,Ω⊗ Λ).\nGupta & Nagar (1999) show (Thm. 2.2.1) that the probability density of a matrix variate normal distribution is,\np(X|W,Ω,Λ) = (2π)− 1 2mn det (Λ) − 12n det (Ω) − 12m × exp { − 1 2 Tr ( Λ−1 (X −W ) Ω−1 (X −W )> )} . (7)\nWe derive our algorithm by revisiting the objective of AROW (3) and compute the three terms of that objective for our model. For the first term, we use (7) and obtain that the KL divergence between two matrix-variate normal distributions is (up to additive constants),\nDKL (N (W,Ω⊗ Λ) ‖N (Wi−1,Ωi−1 ⊗ Λi−1)) (8)\n= 1\n2 n log\n( det Λi−1\ndet Λ\n) + 1\n2 m log\n( det Ωi−1\ndet Ω ) + 1\n2 Tr ( Λ−1i−1Λ ) Tr ( Ω−1i−1Ω ) + 1 2 Tr ( Λ−1i−1 (W −Wi−1) Ω −1 i−1 (W −Wi−1) > ) .\nFor the second term of (3), we use q>Wp = vec (W ) · vec ( pq> ) as discussed above, to compute(\nmax { 0, 1− q>Wp })2 . (9)\nFinally, the third term is, vec ( pq> )> (Λ⊗ Ω)vec ( pq> ) = vec ( pq> )> vec ( Ωpq>Λ\n) = ( p>Ωp ) ( q>Λq ) , (10)\nwhere we used the identities vec (AXC) =( C> ⊗A ) vec (X) and vec ( A> )> vec (C) = Tr (AC). Combining (8), (9) and (10) we get the optimization problem describing the update of the algorithm,\n1 2 n log\n( det Λi−1\ndet Λ\n) + 1\n2 m log\n( det Ωi−1\ndet Ω\n) (11)\n+ 1 2 Tr ( Λ−1i−1 (W −Wi−1) Ω −1 i−1 (W −Wi−1) > ) + 1\n2r\n( max { 0, 1− q>Wp })2 + 1\n2 Tr ( Λ−1i−1Λ ) Tr ( Ω−1i−1Ω ) + 1 2r ( p>Ωp ) ( q>Λq ) .\nThe detailed derivation of the update steps is given in a long version 1. It yields our second algorithm, named f(actored)AROMA, which is summarized in Fig. 2. Using Woodbury identity it follows that both Ωi (13) and Λi (14) are PSD.\nIt is worth comparing the update for Ω (13) in Fig. 2 (S5) with the update of AROW for Σ (4). Both updates share the same formal structure, but use different constants. AROW uses the parameter r in the denominator of (4), while fAROMA uses mr/q>i Λi−1qi. Assuming ‖qi‖2 ≤ m we get that mr\nq>i Λi−1qi ≥ r. Furthermore, the lower the value\nof q>i Λi−1qi is, the larger is the value of the effective parameter mr/q>i Λi−1qi, which in turn reduces the effect of the update. In the extreme case if q>i Λi−1qi = 0 then Ωi = Ωi−1. Intuitively, the algorithm should decrease the total variance as more examples are observed. Yet, if the variance is already low due to low variance related to the query q>i Λi−1qi then there is no need to reduce the variance related to the output Ω, and vice versa. Following the symmetry between Ω and Λ, these observations also hold for the update of Λ (14) (S6).\nf-AROMA uses a total memory of mn+m2 + n2 to store the mean matrix W and the covariance matrices Ω,Λ. The time complexity is also mn + m2 + n2 since it involves addition to all elements of these matrices. Note that if m ≈ n both d-AROMA and f-AROMA have about the same asymptotic complexity, where the later requires storage and manipulation of one more matrix. When the dimensions m and n differ significantly, m n or n m, the complexity of f-AROMA larger than that of d-AROMA because f-AROMA scales quadratically both withm and n, while d-AROMA scales linearly with either parameters.\nWe conclude this section with a mistake bound similar to Theorem 1. Our analysis applies to the algorithm of Fig. 2 with two minor changes. First, it assumes a mistake driven version of the algorithm, namely, that the algorithm makes an update only when a mistake occurs. The condition for an update is therefore 0 > q>i Wi−1pi instead of 1 > q>i Wi−1pi. Second, from (12) (S4) we get that the\nAlgorithm 2: Factored-AROMA\nInput parameters: A scalar r Initialize: W0 = 0 ∈ Rm×n,Ω0 = I ∈ Rn,Λ0 = I ∈ Rm For i = 1, . . . , N\n• Sample a query qi ∈ Rm and two images p+i ,p − i ∈ R n, such that similarity(qi,p+i ) > similarity(qi,p − i ) • Define pi = p+i − p − i • If 1 > q>i Wi−1pi then update: Wi=Wi−1+ max {0, 1−qiWi−1pi} r+q>i Λi−1qip > i Ωi−1pi Λi−1qip > i Ωi−1 (12) Ωi=Ωi−1− q>i Λi−1qi\nmr+ ( q>i Λi−1qi )( p>i Ωi−1pi )Ωi−1pip>i Ωi−1 (13) Λi=Λi−1− p>i Ωi−1pi\nnr + ( p>i Ωi−1pi ) ( q>i Λi−1qi )Λi−1qiq>i Λi−1 (14) Output: A weight matrix WN and its confidence ΣN\nFigure 2. The f-AROMA algorithm for similarity measures.\nupdate of the factored-AROMA can be written as,\nΛ−1i−1WiΩ −1 i−1 = Λ −1 i−1Wi−1Ω −1 i−1\n+ max {0, 1− qiWi−1pi} r + ( q>i Λi−1qi ) ( p>i Ωi−1pi )qip>i , the analysis is for a version that uses the new matrices Λi and Ωi, that is,\nΛ−1i WiΩ −1 i = Λ −1 i−1Wi−1Ω −1 i−1\n+ max {0, 1− qiWi−1pi} r + ( q>i Λi−1qi ) ( p>i Ωi−1pi )qip>i . We are now ready to state the main theorem of this section.\nTheorem 2 Let V be any similarity matrix. Assume the algorithm is executed on any sequence of queries and objects, then the total number of mistakes that the algorithm performs is bounded by |M| ≤ ∑ i∈M max { 0, 1− q>i V pi } + 2 √ Tr ( V Ω−1N V >Λ−1N )\n× √ rmin{m log det ( Ω−1N ) , n log det ( Λ−1N ) } .\nTo understand the theorem, the matrices Ω−1N and Λ −1 N can be thought of as the second order moments of the objects pi and the queries qi respectively. From (13) (S5) and (14) (S6) we observe that these matrices are the sum of the identity matrix and a weighted sum of outer products of the objects and queries. The first term of the bound\nTr ( V Ω−1N V >Λ−1N )\nis small if either the rows of V are aligned with eigenvectors of Ω−1N associated with small values or the columns of V are aligned with eigenvectors of Λ−1N , but not necessarily both. This property, (see Sec. 3.1 of Cesa-Bianchi et al., 2005) holds for the input space of AROW, and also for a second order perceptron. For fAROMA, this property holds for any one of the subspaces, queries or objects.\nNext, the second term of the bound is small if either matrices Ω−1N and Λ −1 N are skewed. This is because the log det function is concave. A similar property holds also for Theorem 1 where we required that features from either spaces would be sparse or non-informative. That is, a property is required to hold only for one of the spaces (queries or objects) but not both.\nThe proof of the theorem relies on the following lemma, which extends Lemma 4 used in the analysis of AROW (Crammer et al., 2009)\nLemma 3 The following two bounds hold for the updates in (13) (S5) and (14) (S6), ∑ i (qiΛiqi) ( p>i Ωipi ) ≤\nmr log det ( Ω−1N ) and ∑ i (qiΛiqi) ( p>i Ωipi ) ≤\nnr log det ( Λ−1N ) Proof: We prove the first inequality. The second inequality can be proved similarly. Using (14) (S6) we get, q>i Λiqi ≤ q>i Λi−1qi = mr q>i Λi−1qi mr . Multiplying with(\np>i Ωipi )\nand summing over i we get,∑ i (qiΛiqi) ( p>i Ωipi ) ≤mr ∑ i qiΛi−1qi mr ( p>i Ωipi ) =mr\n∑ i\n( 1−\ndet Ω−1i−1 det Ω−1i\n) ≤−mr\n∑ i log ( det Ω−1i−1 det Ω−1i ) =mr log det Ω−1N ,\nwhere the first equality follows from Lemma D.1 of Cesa-Bianchi et al. (2005).\nProof sketch: (of Theorem 2) We build on previous approach (Orabona & Crammer, 2010) and have the following inequality, which generalizes Corollary 2 of Orabona & Crammer (2010) for matrices. |M| ≤ ∑ i∈M max { 0, 1− q>i V pi } + 2 √ Tr ( V Ω−1N V >Λ−1N )\n× √∑\ni∈M q>i Wi−1pi + ∑ i∈M (qiΛiqi) ( p>i Ωipi ) .\nThe first sum in the second square-root term is nonpositive, as for i ∈ M we have q>i Wi−1pi ≤ 0. We use Lemma 3 to bound the second square-root term with,\n√ rmin{m log det ( Ω−1N ) , n log det ( Λ−1N ) } , which concludes the proof."
    }, {
      "heading" : "5. Empirical Evaluation",
      "text" : "We evaluated diagonal and factored AROMA on two data sets. First, we learned a semantic similarity between pairs of images in the Caltech-256 dataset (Griffin et al., 2007). Second, we learned a similarity measure between pairs of text documents using the 20-newsgroups data collected by Lang (1995). In both tasks we used standard 5-fold cross validation and report the precision on the test set."
    }, {
      "heading" : "5.1. Image similarity in the Caltech256 dataset",
      "text" : "We first tested AROMA in an image similarity task using the Caltech256 dataset. This dataset consists of 30, 607 images that were obtained from Google image search and from PicSearch.com. Images were assigned to 257 categories and evaluated by humans in order to ensure image quality and relevance. To allow a direct comparisons with the previous literature, we only used here 50 classes.\nWe represent each image using a sparse code based on a bag of patch descriptors. Specifically, features are extracted by dividing each image into overlapping square patches, and describing each patch with edge and color histograms. For edge histograms, we used uniform Local Binary Patterns (uLBPs) (Ojala et al., 2002), which estimate a texture histogram of a patch by considering differences in intensity at circular neighborhoods centered on each pixel. We used uniform LBP8,2 patterns, which means that a circle of radius 2 is considered centered on each block, and bins corresponding to non uniform sequences are merged. LBP patterns were then concatenated with color histograms.\nTo form a sparse code, patch descriptors were mapped into codewords using a dictionary that was trained over a large set of images using k-means. Then, patch representations were collected to represent an image as a sparse code. Each local descriptor was represented as a discrete index, called visterm, and the image was represented as a bag-ofvisterms vector, in which components pi are related to the presence or absence of visterm i in p. The assignment of the weight pi of visterm i in image p was according to tfidf weights. This approach has been found successful (for a related task) by Grangier & Bengio (2008) and Chechik et al. (2009). We used a 1000-sized codebook, with a median of 27 non-zero values per image and a maximum of 129.\nWe compared the performance of AROMA with five other approaches. (1) HIER: Hierarchical semantic indexing, an approach that cleverly uses the known hierarchy among\nclass labels (Deng et al., 2011). (2) OASIS: An online similarity model based on a ranking cost across triplets, similar to the setup studied here (Chechik et al., 2009). It can be used to estimate the added benefit of using the covariance of the distribution in addition to the mean as AROMA does. (3) ITML/LEGO An online approach that succeeds to maintain a proper metric during learning in an efficient way (Davis et al., 2007) (4) LMNN: Large Margin Nearest neighbor, one of the early large margin metric learning methods (Weinberger et al., 2005). (5) Euclidean distance: equivalent to using the identity matrix W = I .\nThe left panel of Fig. 3 compares the precision obtained with d-AROMA and f-AROMA with all other competing methods. Diagonal and factorized AROMA perform very similarly, with a slightly higher performance for factored AROMA. Both methods are significantly better than all other methods at the head of the top ranked images. At the top ranked image, AROMA improves precision by 50% over the second best approach (OASIS, from 22% to 33%).\nThe middle panel of Fig. 3 traces the precision over the test set during training showing that convergence is achieved after 200K ∼ 500K iterations. In the beginning dAROMA was slightly better than f-AROMA, but later fAROMA converged faster. The right panel of Fig. 3 demonstrates that AROMA is largely robust to the choice of the regularizer r, with less than 5% change in precision across three orders of magnitude of r."
    }, {
      "heading" : "5.2. Document similarity, the 20 Newsgroups dataset",
      "text" : "In a second set of experiments we studied the problem of learning a similarity measure between pairs of text documents. This task has numerous applications, such as finding content on the web that is related to a given text document. In this dataset, documents are divided to 20 classes, with about 1, 000 documents in each class. Two documents were considered similar iff they share the same class labels.\nWe used the 20 newsgroups data set (Lang, 1995) and removed stop words but did not apply stemming. We se-\nlected 1, 000 terms that conveyed high information about the identity of the class (over the training set) using the infogain criterion (Yang & Pedersen, 1997). The selected features were normalized using tf-idf, and then represented each document as a bag of words.\nThe 20 newsgroups website proposes a split of the data into a train and test sets. We repeated splitting 5 times based on sizes of the proposed splits (a train-to-test ratio of 65% / 35%). We evaluated the learned similarity measures using a ranking criterion. We view every document in the test set q as a query, and rank the remaining test documents p by their similarity scores q>Wp. We then computed the precision (fraction of positives) at the top r ranked documents. We further computed the mean average precision (mAP), a widely used measure in the information retrieval community, which averages over different values of r.\nWith this dataset. we only compared with OASIS and ITML, the methods that achieved higher precision on the Caltech256 data. HIER requires to use a known hierarchy of classes which is not available for the 20NG dataset.\nThe left panel of Fig. 4 shows the precision at the top ranked similar document. Clearly both AROMA methods outperform ITML and OASIS by large. The middle panel of Fig. 4 traces precision as it progresses through the learning iterations. f-AROMA achieves higher precision than diagonal AROMA during most of the learning iterations, and in fact converges faster. d-AROMA reaches the same level after 500K iterations. Interestingly, AROMA learns much faster than OASIS: it takes OASIS ten times more steps to get to the same precision (this effect is also true for the mean average precision). This precision gain is preserved across a large regime of r values, as shown in the right panel of Fig. 4."
    }, {
      "heading" : "6. Summary",
      "text" : "We presented two algorithms that learn distribution over matrices. Both outperform state-of-the-art methods in two\ntasks, and model the covariance of the matrix distribution using a linear number of parameters. Diagonal-AROMA is likely to be superior when the variance of individual features is large relative to feature dependencies, and factoredAROMA is expected to be superior when the data has strong correlations across features, as with the Caltech256 data. Factored-AROMA also converged faster.\nAcknowledgements: KC gratefully acknowledges partia support by an Israeli Science Foundation grant ISF1567/10."
    } ],
    "references" : [ {
      "title" : "A secondorder perceptron algorithm",
      "author" : [ "N. Cesa-Bianchi", "A. Conconi", "C. Gentile" ],
      "venue" : "Siam Journal of Commutation,",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2005
    }, {
      "title" : "An online algorithm for large scale image similarity learning",
      "author" : [ "G. Chechik", "V. Sharma", "U. Shalit", "S. Bengio" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Chechik et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Chechik et al\\.",
      "year" : 2009
    }, {
      "title" : "Adaptive regularization of weighted vectors",
      "author" : [ "K. Crammer", "A. Kulesza", "M. Dredze" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Crammer et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Crammer et al\\.",
      "year" : 2009
    }, {
      "title" : "Information-theoretic metric learning",
      "author" : [ "J.V. Davis", "B. Kulis", "P. Jain", "S. Sra", "I.S. Dhillon" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Davis et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Davis et al\\.",
      "year" : 2007
    }, {
      "title" : "Hierarchical semantic indexing for large scale image retrieval",
      "author" : [ "J. Deng", "A.C. Berg", "L. Fei-Fei" ],
      "venue" : "In cvpr,",
      "citeRegEx" : "Deng et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Deng et al\\.",
      "year" : 2011
    }, {
      "title" : "Confidenceweighted linear classification",
      "author" : [ "M. Dredze", "K. Crammer", "F. Pereira" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Dredze et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Dredze et al\\.",
      "year" : 2008
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "J. Duchi", "E. Hazan", "Y. Singer" ],
      "venue" : "In COLT, pp",
      "citeRegEx" : "Duchi et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Duchi et al\\.",
      "year" : 2010
    }, {
      "title" : "Caltech-256 object category dataset",
      "author" : [ "G. Griffin", "A. Holub", "P. Perona" ],
      "venue" : "Technical Report 7694, California Institute of Technology,",
      "citeRegEx" : "Griffin et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Griffin et al\\.",
      "year" : 2007
    }, {
      "title" : "Matrix Variate Distributions",
      "author" : [ "A.K. Gupta", "D.K. Nagar" ],
      "venue" : "Chapman and Hall/CRC,",
      "citeRegEx" : "Gupta and Nagar,? \\Q1999\\E",
      "shortCiteRegEx" : "Gupta and Nagar",
      "year" : 1999
    }, {
      "title" : "Online metric learning and fast similarity search",
      "author" : [ "P. Jain", "B. Kulis", "I. Dhillon", "K. Grauman" ],
      "venue" : "In NIPS22,",
      "citeRegEx" : "Jain et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Jain et al\\.",
      "year" : 2008
    }, {
      "title" : "K.Saenko, and T.Darrell. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms",
      "author" : [ "B. Kulis" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Kulis,? \\Q2011\\E",
      "shortCiteRegEx" : "Kulis",
      "year" : 2011
    }, {
      "title" : "Learning to filter netnews",
      "author" : [ "K. Lang" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Lang,? \\Q1995\\E",
      "shortCiteRegEx" : "Lang",
      "year" : 1995
    }, {
      "title" : "Learning multi-modal similarity",
      "author" : [ "McFee", "Brian", "Lanckriet", "Gert" ],
      "venue" : "In JMLR,",
      "citeRegEx" : "McFee et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "McFee et al\\.",
      "year" : 2012
    }, {
      "title" : "Multiresolution gray-scale and rotation invariant texture classification with local binary patterns",
      "author" : [ "T. Ojala", "M. Pietikainen", "T. Maenpaa" ],
      "venue" : "IEEE tran. on pattern analysis and mach. intelligence,",
      "citeRegEx" : "Ojala et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Ojala et al\\.",
      "year" : 2002
    }, {
      "title" : "New adaptive algorithms for online classification",
      "author" : [ "F. Orabona", "K. Crammer" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Orabona and Crammer,? \\Q2010\\E",
      "shortCiteRegEx" : "Orabona and Crammer",
      "year" : 2010
    }, {
      "title" : "Distance metric learning for large margin nearest neighbor classification",
      "author" : [ "Weinberger", "Kilian Q", "Blitzer", "John", "Saul", "Lawrence K" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Weinberger et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Weinberger et al\\.",
      "year" : 2005
    }, {
      "title" : "Wsabie: Scaling up to large vocabulary image annotation",
      "author" : [ "J. Weston", "S. Bengio", "N. Usunier" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "Weston et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Weston et al\\.",
      "year" : 2011
    }, {
      "title" : "A comparative study on feature selection in text categorization",
      "author" : [ "Y. Yang", "J.O. Pedersen" ],
      "venue" : "In Machine learninginternational workshop,",
      "citeRegEx" : "Yang and Pedersen,? \\Q1997\\E",
      "shortCiteRegEx" : "Yang and Pedersen",
      "year" : 1997
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Abstract Algorithms for learning distributions over weight-vectors, such as AROW (Crammer et al., 2009) were recently shown empirically to achieve state-of-the-art performance at various problems, with strong theoretical guaranties.",
      "startOffset" : 81,
      "endOffset" : 103
    }, {
      "referenceID" : 3,
      "context" : "Many algorithms were developed for learning these two tasks, including online algorithms developed recently in the context of classification and ranking costs (Davis et al., 2007; Jain et al., 2008; Chechik et al., 2009).",
      "startOffset" : 159,
      "endOffset" : 220
    }, {
      "referenceID" : 9,
      "context" : "Many algorithms were developed for learning these two tasks, including online algorithms developed recently in the context of classification and ranking costs (Davis et al., 2007; Jain et al., 2008; Chechik et al., 2009).",
      "startOffset" : 159,
      "endOffset" : 220
    }, {
      "referenceID" : 1,
      "context" : "Many algorithms were developed for learning these two tasks, including online algorithms developed recently in the context of classification and ranking costs (Davis et al., 2007; Jain et al., 2008; Chechik et al., 2009).",
      "startOffset" : 159,
      "endOffset" : 220
    }, {
      "referenceID" : 6,
      "context" : "(2009) and the references therein), or using this information during training (Duchi et al., 2010) improves the convergence rate of the learning algorithms as well as the performance of the resulting classifiers.",
      "startOffset" : 78,
      "endOffset" : 98
    }, {
      "referenceID" : 2,
      "context" : "Methods to generate linear classifiers from data have flourished in the past decade, including SVMImportantly, when learning linear models, it was recently shown that modeling the second order information about the set of models (Crammer et al. (2009) and the references therein), or using this information during training (Duchi et al.",
      "startOffset" : 230,
      "endOffset" : 252
    }, {
      "referenceID" : 16,
      "context" : "A similar model was recently studied in different contexts (McFee & Lanckriet, 2012; Kulis et al., 2011; Weston et al., 2011).",
      "startOffset" : 59,
      "endOffset" : 125
    }, {
      "referenceID" : 2,
      "context" : "We first describe the AROW algorithm that was designed for binary classification of vector inputs x ∈ R and introduced by Crammer et al. (2009).",
      "startOffset" : 122,
      "endOffset" : 144
    }, {
      "referenceID" : 2,
      "context" : "(3) was shown by Crammer et al. (2009) to be obtained by the update rule:",
      "startOffset" : 17,
      "endOffset" : 39
    }, {
      "referenceID" : 2,
      "context" : "AROW was shown to attain state-of-the-art performance on many problems (Crammer et al., 2009; Duchi et al., 2010) and its performance is analyzed both for full covariance matrices (Crammer et al.",
      "startOffset" : 71,
      "endOffset" : 113
    }, {
      "referenceID" : 6,
      "context" : "AROW was shown to attain state-of-the-art performance on many problems (Crammer et al., 2009; Duchi et al., 2010) and its performance is analyzed both for full covariance matrices (Crammer et al.",
      "startOffset" : 71,
      "endOffset" : 113
    }, {
      "referenceID" : 2,
      "context" : ", 2010) and its performance is analyzed both for full covariance matrices (Crammer et al., 2009) and diagonal covariance matrices (Orabona & Crammer, 2010).",
      "startOffset" : 74,
      "endOffset" : 96
    }, {
      "referenceID" : 2,
      "context" : "The proof of the theorem relies on the following lemma, which extends Lemma 4 used in the analysis of AROW (Crammer et al., 2009)",
      "startOffset" : 107,
      "endOffset" : 129
    }, {
      "referenceID" : 0,
      "context" : "1 of Cesa-Bianchi et al. (2005).",
      "startOffset" : 5,
      "endOffset" : 32
    }, {
      "referenceID" : 7,
      "context" : "First, we learned a semantic similarity between pairs of images in the Caltech-256 dataset (Griffin et al., 2007).",
      "startOffset" : 91,
      "endOffset" : 113
    }, {
      "referenceID" : 7,
      "context" : "First, we learned a semantic similarity between pairs of images in the Caltech-256 dataset (Griffin et al., 2007). Second, we learned a similarity measure between pairs of text documents using the 20-newsgroups data collected by Lang (1995). In both tasks we used standard 5-fold cross validation and report the precision on the test set.",
      "startOffset" : 92,
      "endOffset" : 241
    }, {
      "referenceID" : 13,
      "context" : "For edge histograms, we used uniform Local Binary Patterns (uLBPs) (Ojala et al., 2002), which estimate a texture histogram of a patch by considering differences in intensity at circular neighborhoods centered on each pixel.",
      "startOffset" : 67,
      "endOffset" : 87
    }, {
      "referenceID" : 1,
      "context" : "This approach has been found successful (for a related task) by Grangier & Bengio (2008) and Chechik et al. (2009). We used a 1000-sized codebook, with a median of 27 non-zero values per image and a maximum of 129.",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 4,
      "context" : "class labels (Deng et al., 2011).",
      "startOffset" : 13,
      "endOffset" : 32
    }, {
      "referenceID" : 1,
      "context" : "(2) OASIS: An online similarity model based on a ranking cost across triplets, similar to the setup studied here (Chechik et al., 2009).",
      "startOffset" : 113,
      "endOffset" : 135
    }, {
      "referenceID" : 3,
      "context" : "(3) ITML/LEGO An online approach that succeeds to maintain a proper metric during learning in an efficient way (Davis et al., 2007) (4) LMNN: Large Margin Nearest neighbor, one of the early large margin metric learning methods (Weinberger et al.",
      "startOffset" : 111,
      "endOffset" : 131
    }, {
      "referenceID" : 15,
      "context" : ", 2007) (4) LMNN: Large Margin Nearest neighbor, one of the early large margin metric learning methods (Weinberger et al., 2005).",
      "startOffset" : 103,
      "endOffset" : 128
    }, {
      "referenceID" : 11,
      "context" : "We used the 20 newsgroups data set (Lang, 1995) and removed stop words but did not apply stemming.",
      "startOffset" : 35,
      "endOffset" : 47
    } ],
    "year" : 2012,
    "abstractText" : "Algorithms for learning distributions over weight-vectors, such as AROW (Crammer et al., 2009) were recently shown empirically to achieve state-of-the-art performance at various problems, with strong theoretical guaranties. Extending these algorithms to matrix models pose challenges since the number of free parameters in the covariance of the distribution scales as n with the dimension n of the matrix, and n tends to be large in real applications. We describe, analyze and experiment with two new algorithms for learning distribution of matrix models. Our first algorithm maintains a diagonal covariance over the parameters and can handle large covariance matrices. The second algorithm factors the covariance to capture inter-features correlation while keeping the number of parameters linear in the size of the original matrix. We analyze both algorithms in the mistake bound model and show a superior precision performance of our approach over other algorithms in two tasks: retrieving similar images, and ranking similar documents. The factored algorithm is shown to attain faster convergence rate.",
    "creator" : "LaTeX with hyperref package"
  }
}