{
  "name" : "1703.07929.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Diversification-Based Learning in Computing and Optimization",
    "authors" : [ "Fred Glover", "Jin-Kao Hao" ],
    "emails" : [ "glover@colorado.edu", "jin-kao.hao@univ-angers.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Diversification-Based Learning (DBL) derives from a collection of principles and methods\nintroduced in the field of metaheuristics that have broad applications in computing and\noptimization. We show that the DBL framework goes significantly beyond that of the more\nrecent Opposition-based learning (OBL) framework introduced in Tizhoosh (2005), which has\nbecome the focus of numerous research initiatives in machine learning and metaheuristic\noptimization. We unify and extend earlier proposals in metaheuristic search (Glover, 1997,\nGlover and Laguna, 1997) to give a collection of approaches that are more flexible and\ncomprehensive than OBL for creating intensification and diversification strategies in\nmetaheuristic search. We also describe potential applications of DBL to various subfields of\nmachine learning and optimization.\nKeywords: Learning-based optimization; diversification strategies; metaheuristic search."
    }, {
      "heading" : "1. Introduction",
      "text" : "Opposition-based learning (OBL) has become a source of numerous initiatives in the area of machine learning in artificial intelligence and associated initiatives to enhance metaheuristic search algorithms in optimization. Since its introduction in Tizhoosh (2005), a flood of proposals and studies have emerged to exploit its underlying ideas in a variety of contexts. (See for example, the surveys of Al-Qunaieer et al, 2010, Ergezer and Sikder, 2011, Xu et al., 2014a.)\nAn earlier framework introduced in the field of metaheuristic search (Glover, 1997; Glover and Laguna, 1997) provides a foundation that subsumes many of the OBL proposals, and gives a basis for additional enhancements. Starting from this foundation, we introduce a DiversificationBased Learning (DBL) framework that yields a collection of new strategies which enlarges those currently available in the OBL field. Accompanying this, we describe potential applications of DBL to various subfields of machine learning and optimization."
    }, {
      "heading" : "2. Background of Opposition-Based Learning",
      "text" : "The notion of an “opposite number” or “opposite vector” in OBL bears a close relationship to the notion of a complemented solution in binary optimization. The original OBL definition is as follows."
    }, {
      "heading" : "OBL Definition of an opposite number",
      "text" : "Relative to a given number x  [L, U], the opposite number is given by x = U + L – x.\nIt may be noted that in the case of a binary number x  [0, 1], this definition corresponds\nprecisely to the definition of the complement of x given by x = 1 – x. The definition extends to\nthe situation where x is a vector, i.e., x = (xj: j  N = {1, …, n}), by identifying bounds Lj and Uj for each component xj' of x, and generating a corresponding opposite value xj\" for each xj' to give the components of an opposite vector x\".\nSubsequently, we will describe other definitions of an opposite number drawn from the OBL literature which we will compare to new definitions we propose that are motivated by metaheuristic considerations of diversification.\nHistorically, OBL has found applications in continuous optimization and has been used to reinforce a number of population evolutionary metaheuristics. This is typically achieved by coupling the generation of a candidate solution with the generation of its corresponding opposite solution during the population initialization and solution evolution phases. For instance, under the framework of differential evolution, OBL was employed to generate a diverse set of initial solutions and extend the current population by including their opposite solutions during the evolution process (Rahnamayan et al, 2008a). The same approach was also applied to other general methods like particle swarm optimization (Han and He, 2007), artificial neural networks (Ventresca and Tizhoosh, 2009), reinforcement learning (Tizhoosh, 2006), and population-based incremental learning (Ventresca and H.R.Tizhoosh, 2008). The idea of using OBL to solve discrete optimization problems has become an object of study in recent years. For instance, several authors have investigated OBL within the framework of Biogeography-based optimization to provide approximation methods for traveling salesman and graph coloring problems (Ergezer and D. Simon, 2011, Xu et al, 2014b). OBL was also combined with the memetic search framework to solve the maximum diversity problem (Zhou et al, 2017). In these studies, several alternative definitions of an opposite solution have been suggested to adapt the OBL concept to these specific problems."
    }, {
      "heading" : "3. Related Framework from Metaheuristic Search",
      "text" : "As previously observed, the notion of an “opposite number” or “opposite vector” in OBL bears a close relationship to the notion of a complemented solution in binary optimization. As we will show in Section 4 below, there is a natural way to extend the definition of a binary complement\nto refer to numbers x  [L, U] (for general lower and upper bounds L and U) that give a\ndefinition of an opposite number different from the OBL definition (x = U + L – x) and that\npossesses useful features. First, however, we introduce a framework that can be used to exploit both the classical OBL definition and the new definitions we will subsequently introduce."
    }, {
      "heading" : "3.1 Opposite (Diverse) Collections Versus Opposite Solutions",
      "text" : "Within the setting of binary optimization, the paper Glover (1997) proposes several\ndiversification generators that start from an arbitrary binary vector x = (xj: j  N = {1, …, n}) and create a diverse collection D(x) of additional vectors that differ from x and from each other\nin various ways. (Each vector in D(x) is accompanied by its complement as a special case.) Consequently, from the perspective of opposition-based learning, this approach may be interpreted as replacing the notion of an opposite solution with the notion of a diverse\n(“opposite”) collection, as embodied in the criteria for diversity used to create D(x). (The\ndiversification generators in Glover (1997) for creating various collections D(x) are described in the Appendix, including generators to create diverse sets of permutation vectors in a sequencing context, to give a clearer idea of the kinds of criteria that can be relevant.)"
    }, {
      "heading" : "3.2 Diverse Collections and Feasibility",
      "text" : "A key insight for exploiting a collection of “opposites” embodied in a diverse collection comes\nfrom the observation that not all elements of a collection D(x) may be admissible or feasible relative to the requirements of a given setting – i.e., there may be constraints that exclude various\nelement x  D(x) from being relevant.\nLet xo denote a solution drawn from D(x)\\{x} (which may or may not be the complement of x) and let X denote the set of feasible solutions. Then it becomes useful to create a mapping that transforms an infeasible vector xo into a feasible vector which is “close to” xo.\nFor this, consider a proximity function fo(x) that embodies a measure of the proximity of x to xo. Then, for a given xo  D(x) such that xo is infeasible, we use a heuristic or exact method to\nMaximize fo(x): x  X (1)\nThe solution thus obtained will then take the place of xo as a member of the diverse set D(x).\nAn example of fo(x) given in Glover (1997) for the binary case is the simple linear function\nfo(x) = ∑(fj oxj: j  N) (2)\nwhere fj o > 0 if xj o = 1 and fj o < 0 if xj o = 0. Thus, an optimal solution to (1), which maximizes fo(x) subject to x  X, would set xj = 1 for fj o > 0 (hence for xj o = 1) and set xj = 0 for fj o < 0 (hence for xj o = 0) if such a solution were feasible, yielding xo itself.\nFor example, the simplest form of fo(x) is given by fj o = 1 if xj o = 1 and fj o = – 1 if xj o = 0, thus producing the objective\nMaximize ∑(xj : j  N: xj o = 1) – ∑(xj : j  N: xj o = 0)\nBy choosing positive and negative coefficients fj o different from 1 and – 1 it becomes possible to produce solutions that possess various desirable features. In the context of metaheuristic optimization, for instance, it can be useful to allow these coefficients to embody intensification and diversification goals, as where a positive fj o is made larger to more strongly emphasize setting xj = 1 (or a negative fj o is made smaller to more strongly emphasize setting xj = 0) according to a frequency memory that counts the number of times xj = xj o in solutions of various categories (e.g., high quality solutions) found in the past. Such fj o coefficients can be generated either deterministically or probabilistically as a function of frequency memory."
    }, {
      "heading" : "3.2.1 Useful and exploitable forms of X.",
      "text" : "As an alternative to stipulating that X represents the set of feasible solutions to a particular problem, we can instead stipulate that X represents a set of solutions derived from a problem relaxation. In this case, a solution x  X that minimizes fo(x) can be taken as a starting point for metaheuristic or exact algorithms that generate fully feasible solutions. In the metaheuristic setting, such algorithms may be based on neighborhood search, where feasibility can be embodied in the definitions of the neighborhoods employed. In Section 5 we discuss the use of metaheuristics for generating such solutions in greater detail.\nWhen fo(x) takes the form ∑(fj oxj: j  N) indicated in (2), a number of commonly occurring types of constraints allow fo(x) to be optimized very simply. We identify a few examples as follows."
    }, {
      "heading" : "Multiple Choice (GUB) Constraints",
      "text" : "These constraints are given by\n∑(xj : j  Ni) = 1, i  M\nwhere the sets Ni, i  M form a partition of N. Maximizing f o(x) over such constraints is accomplished by setting\nxj(i) = 1 for j(i)  Ni and xj = 0 for j  Ni\\{j(i)}\nwhere j(i) = arg max (fj o: j  Ni). When fj o has the elementary form where each fj o is 1 or – 1, then any j  Ni with fj o = 1 qualifies as j(i), and otherwise every j  Ni qualifies as j(i) (since all coefficients fj o for j  Ni are 0. Evidently, it is useful to differentiate among multiple optimal solutions by generating fj o coefficients that differ from 1 and – 1 (again, for instance, determined probabilistically or deterministically according to values of xj in past solutions)."
    }, {
      "heading" : "Generalized Multiple Choice Constraints.",
      "text" : "A generalized instance of the foregoing GUB constraints takes the form\n∑(xj : j  Ni) = mi, i  M\nwhere 0 < mi < |Ni| and, as before, the sets Ni, i  M, form a partition of N. The set of optimal solutions consist of those that satisfy\nxj = 1 if j  Ni(mi), i  M and xj = 0 otherwise\nwhere Ni(mi) consists of mi elements of Ni having the largest values of fj o."
    }, {
      "heading" : "A commonly encountered special case",
      "text" : "A frequently encountered version of the Generalized Multiple Choice Constraints occurs\nwhen M contains a single element, thus yielding a single constraint ∑(xj : j  N1) = m1. For the elementary instance of fo(x) where each fj o is 1 or – 1, an optimal solution is constructed simply by observing that the set N1(m1) is composed by selecting as many elements j  N as possible with fj o = 1 (equivalently, with xj o = 1) among the m1 elements of N1. The “opposite solution” proposed in Zhou et al. (2017) for the maximum diversity problem corresponds to such a solution.\nAdditional useful and commonly occurring types of constraints\nOther kinds of constraints that often arise in practical settings, and that can easily be\nexploited by special cases of the preceding framework, include various types of network flow structures, especially those embodied in network assignment and distribution constraints. Optimal solutions in these instances can be obtained by standard network optimization algorithms. Likewise, a wide class of problems is attended by multiple knapsack constraints, and a variety of metaheuristic approaches can be used to obtain approximately optimal solutions to (1) in these situations."
    }, {
      "heading" : "4. An Alternative Definition of Opposite Solution from the DBL perspective",
      "text" : "We first introduce a definition of an opposite solutions that generalizes the notion of a complementary solution and show that this definition has useful features that are missing from the classical OBL definition. Then we show how our definition can be embodied in a framework that generalizes the framework described in Section 3.\nOnce again consider the simplified situation where x is a number satisfying x  [L, U]. As an\nalternative to the OBL definition of an opposite value given by x = U + L – x, we introduce the following notation.\nLet Lo and Uo be values satisfying Lo  L and Uo ≤ U, with Lo ≤ Uo, as where Lo = Lo(λL) = L + λL(U – L) and U o = Uo(λU) = U – λU(U – L), for parameters λL and λU from the half-open interval [0, 0.5). (For example, if λL = λU = 0.2, then L o lies one fifth of the way from L to U and Uo lies one fifth of the way from U to L.)1\n1 When Lo and Uo are given as functions of parameters λL and λU, we normally do not choose λL and λU to be the same, which would cause Lo and Uo to differ by the same amount from L and U. The reason for this asymmetric treatment of Lo and Uo is because in many applications of optimization, L is given as a\nThen we define the “opposite” point x associated with x to be the value of x in the interval [Lo, Uo] that is farthest from x. More precisely:"
    }, {
      "heading" : "DBL Opposite Definition",
      "text" : "x = Lo if x  (Lo + Uo)/2 and x = Uo if x ≤ (Lo + Uo)/2\nWe observe that whenever x > (Lo+ Uo)/2 the foregoing definition gives x\" = Lo and whenever x< (Lo + Uo)/2 the definition gives x\" = Uo. (These outcomes also hold if x > Uo and if x < Lo.) Both Lo and Uo qualify as the opposite of x' when x' is the midpoint (Lo + Uo)/2, and in this case the tie between Lo and Uo can be settled arbitrarily.\nTo allow latitude in applying this definition, in the case where Lo and Uo are determined by reference to λL and λU, these parameters can be varied for different components of a vector by choosing λL and λU randomly from chosen intervals (e.g., such as [1/6, 1/3] or [1/5, 2/5]). When x and x are required to be integers, we stipulate that x be assigned the integer value closest to the value indicated by the preceding DBL Opposite Definition. In the special case of binary vectors, this convention implies that different values of λL and λU from the half-open interval [0, 0.5) all are equivalent to defining x to be the complement of x. However, different outcomes occur for more general continuous vectors and non-binary vectors.\nThe motivation for the preceding definition comes from two sources. First, this definition avoids\na drawback of the classical OBL definition x = U + L – x, as illustrated in the situation where\nx = 0.5(U + L). In this case the “opposite” of x is in fact the same as x. (For example, when x\n [0, 1] and takes the midpoint value x = 0.5, the opposite of x is also 0.5.) Moreover, the\ncloser x is to the interval midpoint, the less that x differs from x.\nBy contrast, according to our preceding definition, the values x = Lo and x = Uo both qualify as opposites of x when x lies halfway between Lo and Uo, as previously noted. This holds for the special case where Lo = L and Uo = U, which gives a direct comparison with the classical OBL definition.\nMore generally, we are motivated to choose Lo and Uo to differ from L and U because of an optimization strategy introduced in Glover and Martinson (1984) that progressively manipulates lower and upper bounds (therefore generating values that can be represented by Lo and Uo) which enables a complex optimization problem to be solved by solving a series of much simpler problem relaxations.2 Motivation is also provided by a parametric strategy for mixed integer programming (Glover, 2006) that imposes bounds through a parameterized objective function in\nlower bound that is frequently attained (characteristically, L = 0), whereas U is typically chosen larger than any value that x will normally receive. 2 In this case, the relaxations consisted of network relaxations.\nplace of a customary branching procedure, using adaptive memory strategies from tabu search to provide a control mechanism.3\nSeveral alternative definitions of an opposite solution from the OBL literature that invite comparison with the DBL definition are offered in the papers Rahnamayan et al. (2008a), Ergezer et al. (2009), Ergezer and D. Simon (2011), Rahnamayan and Wang (2009) and Wang et al (2009). All but one of these definitions fail to drive x\" away from x' in a manner that escapes being constrained by the midpoint of the interval, but instead generate a point at random that lies between this midpoint and another point (where the latter is either the point given by the classical OBL definition or the initial point x' itself). The definition that constitutes an exception, producing what is called the generalized opposite point in Wang et al. (2009), can be interpreted as attempting to drive x\" away from the midpoint, but has the curious weakness of failing to be invariant under translations of the bounds L and U. In addition, this approach often generates a point x\" that lies outside of the interval [L, U], which is then “repaired” by replacing x\" with a point selected at random from the [L, U] interval.4"
    }, {
      "heading" : "Broadened Definitions and the Max-Min Distance Principle",
      "text" : "We now consider several broader definitions of an opposite solution. In each of these, x\" is chosen to be the point farthest from x' subject to being constrained to lie in a specified interval of values.\nAs in Section 3.1 above, we consider the relation of x\" not just to a single value x' but to a diverse collection X', where we want x\" to be in opposition to (diversified in relation to) all values x' in X'. A reason for introducing such a conception of opposition stems from the fact that in population-based metaheuristics we seek new solutions that are meaningfully opposed to all points in the population. Thus we return to the perspective where x' and x\" are not single values, but vectors x' = (x1', x2', …, xn') and x\" = (x1\", x2\", …, xn\"). Then we apply the DBL definition of an opposite to the components xj' and xj\" of these vectors. Thus, the set X' now represents a collection of vectors (such as a population or sub-population in a population-based metaheuristic) rather than a collection of values.\nAn approach suggested in Glover (1994) provides a starting point for this extension, in which the\ngoal becomes to maximize the minimum distance of x\" from all points x'  X'. A variation is to\nmaximize a weighted sum of distances from the points x'  X', but in this case the weights must be selected judiciously. A simple sum of distances can lead to generating vectors that have unattractive features from the standpoint of making x\" meaningfully diverse relative to the points in X'.\nUtilizing this perspective, we provide a simple component-by-component procedure for generating x\" in opposition to (diverse from) the vectors in X'.\n3 Such strategies effectively augment diversification with intensification, and we later observe the relevance of joining these two processes in the present setting of a diversification-based approach for generating opposite solutions. 4 One other definition, in Xu et al. (2011), exhibits complications similar to those of Wang et al. (2009)."
    }, {
      "heading" : "The Max-Min Principle",
      "text" : "For each component xj of x, write the corresponding values xj' of the vectors x'  X' as xj 1, xj 2, …, xj r, for r = |X'|, where Lj ≤ xj 1 ≤ xj 2, …, ≤ xj r ≤ Uj. For simplicity, define xj 0 = Lj and xj r+1 = Uj."
    }, {
      "heading" : "The Max-Min Opposite x\" Relative to the set X'",
      "text" : "To determine each component xj\" of x\", identify an index h, 0 < h ≤ r + 1 that maximizes xj h – xj h – 1. If h = 1, let xj\" = xj 0 and if h = r + 1, let xj\" = xj r+1. Otherwise, let xj\" = (xj h + xj h – 1)/2.\nIt is easy to verify that this determination of xj\" maximizes the minimum distance from the values xj' for the vectors x'  X'. Moreover, relative to each component xj' of x', the result is equivalent to our earlier DBL definition if we stipulate that xj 0 = Lj o and xj r+1 = Uj o, where Uj o receives a value that lies between xj r and Uj and Lj o receives a value that lies between xj 1 and Lj.\nIn Section 6 we introduce definitions that apply to vectors as units rather than treating them component-by-component. Further use of the Max-Min Principle is described in the Appendix."
    }, {
      "heading" : "5. Generalizing the Framework of Section 3 to Handle Non-binary Vectors",
      "text" : "As a starting point, we observe that we may apply the DBL definition of an opposite solution to map the binary solutions of a diverse collection produced by a diversification generator (such as one of those described in the Appendix) into a diverse collection applicable to vectors x where xj  [Lj, Uj]. Specifically, we operate as follows.\nGenerating a diverse collection for non-binary vectors x\nBegin with an initial seed solution xs and denote the collection of diverse solutions\nassociated with xs by D#(xs), where to begin D#(xs) = {xs}\nMap xs into a binary seed solution ys where yj s = 0 if xj s ≤ (Lj + Uj)/2\nand yj s = 1 if xj s  (Lj + Uj)/2\nApply a diversification generator to ys to generate a diverse collection D(ys). Map each solution yo  D(ys) into a solution xo  D#(xs) (i.e, add xo to D#(xs)) by one of\nthe following rules: (R1) Set xj o = Lj o if yj o = 0 and xj o = Uj o if yj o = 1. (R2) Set xj o = xj s if yj o = yj s and otherwise set xj o = Lj o if yj o = 0 and\nxj o = Uj o if yj o = 1.\nIn the foregoing, it should be borne in mind that the values Lj o and Uj o of (R1) and (R2) may be chosen to take the form Lj o = Lj o(λL) = Lj + λL(Uj – Lj) and Uj o = Uj o(λU) = Uj – λU(Uj – Lj), as indicated in Section 4, where λL and λU are selected constants applied uniformly for all j  N or may be allowed to vary for each j  N (e.g., chosen randomly from a selected interval). We observe that if xs is represented by x, then the opposite solution x generated by the DBL definition is the same solution that will be generated by both (R1) and (R2) from the complement of ys."
    }, {
      "heading" : "Generalizing the Feasibility Mapping of Section 3.",
      "text" : "In order to map a solution xo  D#(xs)\\{xs} into a feasible solution, we generalize the approach of Section 3 as follows.\nAs in Section 3.2, we make use of a proximity function fo(x), which in this case we express in terms of a measure of distance between x and xo, and hence refer to minimization rather than maximization. Thus the objective becomes\nMinimize fo(x): x  X (3)\nwhere, for example, fo(x) takes the form\nfo(x) = ∑(fj o|xj – xj o|): j  N) (4)\nand fj o > 0 for all j  N. If xo is binary, then (3) and (4) are equivalent to (1) and (2). By this means, we create diverse collections of solutions that satisfy x  X. In the contexts normally used in OBL, where only a single opposite solution is generated for a given solution, it is natural to designate the opposite of xs to be xo."
    }, {
      "heading" : "6. Uses of Metaheuristics to Generate Opposite Solutions",
      "text" : "We identify several diversification methods for metaheuristics that are well-suited to generate solutions that qualify as opposite solutions. A useful feature of these methods is that the “opposite” solutions they produce retain feasibility when the metaheuristics yield feasible solutions (as where a neighborhood process preserves feasibility).\nCreating opposite solutions by neighborhood search with tabu search restrictions: A diversification strategy from tabu search (see, e.g., Glover and Laguna, 1993, 1997) periodically introduces a large tabu tenure to prevent the trajectory of neighboring solutions from reversing any of its component moves. By selecting the number of moves defined by “large,” it is possible to generate solutions that constitute varying levels of opposition relative to the solution that launched the trajectory. An extreme version of such an approach that uses an unbounded tabu tenure, and continues until no more moves are available to be selected, was found to be highly effective in Kelly et al. (1994). This outcome suggests that the use of large tabu tenures to identify opposite solutions deserves further exploration.\nBi-directional opposite solutions from exterior path relinking: Exterior path relinking (Glover, 2014; Duarte et al. 2015), is a population-based approach utilizing an initiating solution xI and a guiding solution xG, to creates a trajectory from xI to xG that goes beyond the guiding solution xG. By interchanging the roles of the initiating and guiding solutions, the process may be viewed as creating an opposite solution from the pairing (xI, xG) in one direction and also from the pairing (xG, xI) in the reverse direction, to create a bi-directional determination of opposite solutions. The path relinking approach can also be applied with multiple guiding solutions, and can be varied by choosing different distances beyond xG (or xI) for generating the opposite\nsolution. These distances have a built-in limit which identifies an “extreme opposite” analogous to complementing a 0-1 vector.\nGenerating opposite solutions from clustering: Clustering provides an important opportunity for organizing the generation of opposite solutions by metaheuristic processes (see, e.g., Glover, 1977; Glover and Laguna, 1993). For example, exterior path relinking trajectories can be created that select initiating and guiding solutions from different clusters to induce a stronger diversification effect than choosing them from a common cluster. Moreover, when initiating solutions and guiding solutions are generated this way, a solution generated on an interior trajectory (that is, a solution between xI and xG) that lies outside of the clusters can also qualify as being in opposition to xI and xG, according to its distance to the boundaries of the clusters containing xI and xG.5 This provides an additional distinction for classifying opposite solutions according to their intensification/diversification focus and invites research into the effect of this classification on generating useful opposite solutions in various contexts.\nCreating opposite solutions by extracting diverse subsets from larger populations: An alternative approach that provides a further basis for creating opposite solutions arises by generating a relatively large population by initial diversification strategies and then extracting mutually diverse subsets of points, based on criteria such as maximizing the minimum distance from other points in the set under construction. In a sequential procedure for extracting the points (Glover, 1994), these criteria can produce many ties for the element to be selected next, once a small number of elements have been selected. Even in the absence of ties such a constructive approach can ultimately create collections of points that can be improved according to the diversity criteria employed.\nDrawing on this observation, a variety of more sophisticated iterative approaches are introduced in Glover (2016) for obtaining collections of points that are more diverse than those found by simpler constructive methods. These approaches, which are developed in the context of creating seed points for clustering, can equally be applied in other contexts to produce solutions that satisfy useful criteria of opposition."
    }, {
      "heading" : "7. Conclusions",
      "text" : "The notion of “opposition” that gives rise to the definitions of an opposite solution introduced in opposition based learning (OBL) can be significantly extended by reference to earlier notions of diversification that have emerged in the area of metaheuristic search. The resulting diversification based learning (DBL) framework is not only more flexible than OBL, but overcomes limitations in the OBL definitions of an opposite solution. The DBL perspective further broadens the notion of opposition by conceiving it to refer not only to a single solution as an opposing partner of a given solution, but to refer to an “opposite collection” of solutions, as obtained by a diversification generator. These alternative notions lead to a model that allows the concept of opposition to operate within the context of feasibility, which is missing from the OBL framework except by the device of simply rejecting an infeasible opposite solution as\n5 The distance from a point x to a cluster boundary in this case can be defined as the distance to the point in the cluster closest to x.\ninadmissible, without offering a direct means of establishing a connection to feasibility. Finally, we demonstrate how earlier diversification ideas for binary vectors can be generalized in the DBL framework to apply equally to non-binary vectors, identifying a range of metaheuristic procedures that can produce solutions that can meaningfully qualify as opposite solutions. The enhanced scope and adaptability of DBL opens the possibility of creating applications of this framework in realms where OBL has been too narrow to find a use, and invites studies in the area of metaheuristics where the principles underlying DBL remain largely unexplored."
    }, {
      "heading" : "Appendix: Some Basic Diversification Generators for 0-1 Vectors",
      "text" : "We indicate two basic types of diversification generators, one for problems that can be formulated in a natural manner as optimizing a function of zero-one variables, and the other for problems that can more appropriately be formulated as optimizing a permutation of elements. The generators described here are a subset of those identified in Glover (1997), and more advanced forms of these generators, along with additional types, can be found in Glover (2017).\nThe following approaches embody the precept that diversification is not the same as randomization, and hence differ from the randomized approaches for creating variation that are proposed in connection with a variety of evolutionary approaches. The goal of diversification is to produce solutions that differ from each other in significant ways, and that yield productive (or “interesting”) alternatives in the context of the problem considered. By contrast, the goal of randomization is to produce solutions that may differ from each other in any way (or to any degree) at all, as long as the differences are entirely “unsystematic”. From the present viewpoint, a reliance on variation that is strategically generated can offer advantages over a reliance on variation that is distinguished only by its unpredictability."
    }, {
      "heading" : "Diversification Generators for Zero-One Vectors",
      "text" : "The first type of diversification generator takes a binary vector x as its seed solution, and generates\na collection of solutions associated with an integer h = 1, 2,..., h*, where h*  n - 1. (Recommended\nis h*  n/5.)\nWe generate two types of solutions, x' and x\" for each value of h, by the following rule:\nType 1 Solution: Let the first component x1 ' of x' be 1 – x1 and let x1+kh' = 1 - x1+kh for k =\n1, 2, 3,..., k*, where k* is the largest integer satisfying k*  n/h. Remaining components of x' equal 0.\nTo illustrate for x = (0,0,...,0): The values h = 1, 2 and 3 respectively yield x' = (1,1,...,1), (1,0,1,0,1\n...) and (1,0,0,1,0,0,1,0,0,1,....). This progression suggests the reason for preferring h*  n/5. As h becomes larger, the solutions x' for two adjacent values of h differ from each other proportionately less than when h is smaller. An option to exploit this is to allow h to increase by an increasing increment for larger values of h.\nType 2 Solution: Let x\" be the complement of x'.\nAgain to illustrate for x = (0,0,...,0): the values h = 1, 2 and 3 respectively yield x\"= (0,0,...,0), (0,1,0,1,....) and (0,1,1,0,1,1,0,...). Since x' duplicates x for h = 1, the value h = 1 can be skipped when generating x\".\nThe preceding design extends to generate additional solutions as follows. For values of h  3 the solution vector is shifted so that the index 1 is instead represented as a variable index q, which can take the values 1, 2, 3, ..., h. Continuing the illustration for x = (0,0,...,0), suppose h = 3. Then, in addition to x' = (1,0,0,1,0,0,1,...), the method also generates the solutions given by x' = (0,1,0,0,1,0,0,1,...) and (0,0,1,0,0,1,0,0,1....), as q takes the values 2 and 3.\nThe following pseudo-code indicates how the resulting diversification generator can be structured, where the parameter MaxSolutions indicates the maximum number of solutions desired to be generated. Comments within the code appear in italics, enclosed within parentheses.\nFirst Diversification Generator for Zero-One Solutions.\nNumSolutions = 0 For h = 1 to h*\nLet q* = 1 if h < 3, and otherwise let q* = h\n(q* denotes the value such that q will range from 1 to q*. We set q* = 1 instead of q* = h for h < 3 because otherwise the solutions produced for the special case of h < 3 will duplicate other solutions or their complements.)\nFor q = 1 to q*\nlet k* = (n-q)/h <rounded down> For k = 1 to k*\nxq+kh' = 1 – xq+kh\nEnd k\nIf h > 1, generate x\" as the complement of x'\n(x' and x\" are the current output solutions.)\nNumSolutions = NumSolutions + 2 (or + 1 if h = 1)\nIf NumSolutions  MaxSolutions, then stop generating solutions.\nEnd q\nEnd h\nThe number of solutions x' and x\" produced by the preceding generator is approximately q*(q*+1). Thus if n = 50 and h* = n/5 = 10, the method will generate about 110 different output solutions, while if n = 100 and h* = n/5 = 20, the method will generate about 420 different output solutions.\nSince the number of output solutions grows fairly rapidly as n increases, this number can be limited, while creating a relatively diverse subset of solutions, by allowing q to skip over various values between 1 and q*. The greater the number of values skipped, the less “similar” the successive solutions (for a given h) will be. Also, as previously noted, h itself can be incremented by a value that differs from 1."
    }, {
      "heading" : "For added variation:",
      "text" : "If further variety is sought, the preceding approach can be augmented as follows. Let h = 3,4,...,\nh*, for h  n - 2 (preferably h*  n/3). Then for each value of h, generate the following solutions.\nType 1A Solution: Let x1' = 1 – x1 and x2' = 1 – x2. Thereafter, let x1+kh' = 1 – x1+kh and let\nx2+kh' = 1 – x2+kh, for k = 1,2,...,k*, where k* is the largest integer such that 2 + kp  n. All other components of x' are the same as in x.\nType 2A Solution: Create x\" as the complement of x', as before.\nRelated variants are evident. The index 1 can also be shifted (using a parameter q) in a manner similar to that indicated for solutions of type 1 and 2."
    }, {
      "heading" : "A Sequential Diversification Generator",
      "text" : "The concept of diversification invites a distinction between solutions that differ from a given solution (e.g., a seed solution) and those that differ from each other.6 Our preceding comments refer chiefly to the second type of diversification, by their concern with creating a collection of solutions whose members exhibit certain contrasting features.\nDiversification of the first type can be emphasized in the foregoing design by restricting attention to the complemented solutions denoted by x\" when h becomes larger than 2. In general, diversification of the second type is supported by complementing larger numbers of variables in the seed solution. This type of diversification by itself is incomplete, and the relevance of diversification of the first type is important to heed in many situations.\n6 These distinctions have often been overlooked by the genetic algorithm community.\nA sequential diversification generator for 0-1 vectors that follows the prescription to maximize the minimum distance from preceding vectors is embodied in the following procedure. We say that a\nsolution y complements x over an index set J if yj = 1 – xj for j  J and yj = xj for j  N\\J.\nSequential (Max/Min) Diversification Generator\n1. Designate the seed solution x and its complement to be the first two solutions generated. 2. Partition the index set N = {1,…,n} for x into two sets N' and N\" that, as nearly as possible,\ncontain equal numbers of indexes. Create the two solutions x' and x\" so that x' complements x over N' and x\" complements x over N\".\n3. Define each subset of N that is created by the most recent partition of N to be a key subset. If no key subset of N contains more than 1 element, stop. Otherwise partition each key subset\nS of N into two sets S' and S\" that contain, as nearly as possible, equal numbers of elements. (For the special case where S may contain only 1 element, designate one of S' and S\" to be the same as S, and the other to be empty.) Overall, choose the designations S' and S\" so that the number of partitions with |S'| > |S\"| equals the number with |S\"| > |S'|, as nearly as possible.\n4. Let N' be the union of all subsets S' and let N\" be the union of all subsets S\". Create the complementary solutions x' and x\" relative to N' and N\" as in Step 2, and then return to\nStep 3. (The partition of each critical set into two parts in the preceding execution of Step 3 will cause the number of critical sets in the next execution of Step 3 to double.)\nThe foregoing process generates approximately 2(1 + log n) solutions. If n is a power of 2, every solution produced maximizes the minimum Hamming distance from all previous solutions generated. (This maxmin distance, measured as the number of elements by which the solutions differ, is n/2 for every iteration after the first two solutions are generated in Step 1. Such a maxmin value is also approximately achieved when n is not a power of 2.)\nIn particular, starting with k = n, and updating k at the beginning of Step 3 by setting k: = k/2 (rounding fractional values upward), the number of elements in each key subset is either k or k-1. Thus, the method stops when k = 1. The balance between the numbers of sets S' and S\" of different sizes can be achieved simply by alternating, each time a set S with an odd number of elements is encountered, in specifying the larger of the two members of the partition to be S' or S\".\nUseful variations result by partitioning N in different ways. Again, descriptions of these approaches may be found in Glover (1997)."
    }, {
      "heading" : "Diversification Generator for Permutation Problems",
      "text" : "Although permutation problems can be formulated as 0-1 problems, they constitute a special class that preferably should be treated somewhat differently. Assume that a given trial permutation P used as a seed is represented by indexing its elements so they appear in consecutive order, to yield P = (1,2, ..., n). Define the subsequence P(h:s), where s is a positive integer between 1 and h, to be given by P(h:s) = (s, s+h, s+2h, ..., s+rh), where r is the largest nonnegative integer such that s+rh\nn. Then define the permutation P(h), for h  n, to be P(h) = (P(h:h), P(h:h-1), ..., P(h:1))."
    }, {
      "heading" : "Illustration:",
      "text" : "Suppose P is given by\nP = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18)\nIf we choose h = 5, then P(5:5) = (5,10,15), P(5:4) = (4,9,14), P(5:3) = (3,8,13,18), P(5:2) = (2,7,12,17), P(5:1) = (1,6,11,16), to give:\nP(5) = (5, 10, 15, 4, 9, 14, 3, 8, 13, 18, 2, 7, 12, 17, 1, 6, 11, 16)\nSimilarly, if we choose h = 4 then P(4:4) = (4,8,12,16), P(4:3) = (3,7,11,15), P(4:2) = (2,6,10,14,18), P(4:1) = (1,5,9,13,17) to give:\nP(4) = (4, 8, 12, 16, 3, 7, 11, 15, 2, 6, 10, 14, 18, 1, 5, 9, 13, 17)\nIn this illustration we have allowed h to take the two values closest to the square root of n. These values are interesting based on the fact that, when h equals the square root of n, the minimum relative separation of each element from each other element in the new permutation is maximum, compared to the relative separation of exactly 1 in the permutation P. In addition, other useful types of separation result, and become more pronounced for larger values of n.\nIn general, for the goal of generating a diverse set of permutations, preferable values for h range from 1 to n/2. We also generate the reverse of the preceding permutations, denoted by P*(h), which we consider to be more interesting than P(h). The preference of P*(h) to P(h) is greater for smaller values of h. For example, when h = 1, P(h) = P and P*(h) is the reverse of P. (Also, P(n) = P*(1).) In sum, we propose a Diversification Generator for permutation problems to be one that generates a subset of the collection P(h) and P*(h), for h = 1 to n/2 (excluding P(1) = P)."
    } ],
    "references" : [ {
      "title" : "Opposition based computing - A survey,",
      "author" : [ "F.S. Al-Qunaieer", "H.R. Tizhoosh", "S. Rahnamayan" ],
      "venue" : "in: Proceedings of International Joint Conference on Neural Networks",
      "citeRegEx" : "Al.Qunaieer et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Al.Qunaieer et al\\.",
      "year" : 2010
    }, {
      "title" : "Survey of oppositional algorithms,",
      "author" : [ "M. Ergezer", "I. Sikder" ],
      "venue" : null,
      "citeRegEx" : "Ergezer and Sikder,? \\Q2011\\E",
      "shortCiteRegEx" : "Ergezer and Sikder",
      "year" : 2011
    }, {
      "title" : "Oppositional biogeography-based optimization for combinatorial problems,",
      "author" : [ "M. Ergezer", "D. Simon" ],
      "venue" : "in: Proceedings of Congress on Evolutionary Computation",
      "citeRegEx" : "Ergezer and Simon,? \\Q2011\\E",
      "shortCiteRegEx" : "Ergezer and Simon",
      "year" : 2011
    }, {
      "title" : "Heuristics for Integer Programming Using Surrogate Constraints,",
      "author" : [ "F. Glover" ],
      "venue" : "Decision Sciences,",
      "citeRegEx" : "Glover,? \\Q1977\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 1977
    }, {
      "title" : "Tabu Search for Nonlinear and Parametric Optimization (with Links",
      "author" : [ "F. Glover" ],
      "venue" : null,
      "citeRegEx" : "Glover,? \\Q1994\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 1994
    }, {
      "title" : "A Template for Scatter Search and Path Relinking,",
      "author" : [ "F. Glover" ],
      "venue" : "Artificial Evolution,",
      "citeRegEx" : "Glover,? \\Q1997\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 1997
    }, {
      "title" : "Parametric Tabu Search for Mixed Integer Programs,",
      "author" : [ "F. Glover" ],
      "venue" : "Computers and Operations Research,",
      "citeRegEx" : "Glover,? \\Q2006\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 2006
    }, {
      "title" : "Exterior Path Relinking for Zero-One Optimization,\" International Journal",
      "author" : [ "F. Glover" ],
      "venue" : null,
      "citeRegEx" : "Glover,? \\Q2014\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 2014
    }, {
      "title" : "Pseudo-Centroid Clustering,",
      "author" : [ "F. Glover" ],
      "venue" : "Soft Computing,",
      "citeRegEx" : "Glover,? \\Q2016\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 2016
    }, {
      "title" : "Diversification Methods in 0-1 Optimization,",
      "author" : [ "F. Glover" ],
      "venue" : null,
      "citeRegEx" : "Glover,? \\Q2017\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 2017
    }, {
      "title" : "Tabu Search,\" chapter in Modern Heuristic Techniques for Combinatorial Problems, C",
      "author" : [ "F. Glover", "M. Laguna" ],
      "venue" : null,
      "citeRegEx" : "Glover and Laguna,? \\Q1993\\E",
      "shortCiteRegEx" : "Glover and Laguna",
      "year" : 1993
    }, {
      "title" : "A netform system for resource planning in the U.S. bureau of land management,",
      "author" : [ "F. Glover", "R. Glover", "F. Martinson" ],
      "venue" : "Journal of the Operational Research Society,",
      "citeRegEx" : "Glover et al\\.,? \\Q1984\\E",
      "shortCiteRegEx" : "Glover et al\\.",
      "year" : 1984
    }, {
      "title" : "A novel opposition-based particle swarm optimization for noisy",
      "author" : [ "X.S.L. Han" ],
      "venue" : null,
      "citeRegEx" : "Han,? \\Q2007\\E",
      "shortCiteRegEx" : "Han",
      "year" : 2007
    }, {
      "title" : "A study of diversification strategies for the Quadratic Assignment Problem,",
      "author" : [ "J.P. Kelly", "M. Laguna", "F. Glover" ],
      "venue" : "Computers and Operations Research,",
      "citeRegEx" : "Kelly et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Kelly et al\\.",
      "year" : 1994
    }, {
      "title" : "Opposition-based differential evolution,",
      "author" : [ "S. Rahnamayan", "H.R. Tizhoosh", "M. Salama" ],
      "venue" : "IEEE Transactions Evolutionary Computation,",
      "citeRegEx" : "Rahnamayan et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Rahnamayan et al\\.",
      "year" : 2008
    }, {
      "title" : "Opposition versus randomness in soft computing techniques,",
      "author" : [ "S. Rahnamayan", "H.R. Tizhoosh", "M.M. Salama" ],
      "venue" : "Applied Soft Computing,",
      "citeRegEx" : "Rahnamayan et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Rahnamayan et al\\.",
      "year" : 2008
    }, {
      "title" : "Center-based sampling for population-based algorithms,",
      "author" : [ "S. Rahnamayan", "G.G. Wang" ],
      "venue" : "in: Proceedings of IEEE Congress on Evolutionary Computation,",
      "citeRegEx" : "Rahnamayan and Wang,? \\Q2009\\E",
      "shortCiteRegEx" : "Rahnamayan and Wang",
      "year" : 2009
    }, {
      "title" : "Opposition-based learning: A new scheme for machine intelligence,",
      "author" : [ "H.R. Tizhoosh" ],
      "venue" : "in: Proceedings of International Conference on Computational Intelligence for Modelling, Control and Automation, and International Conference on Intelligent Agents, Web Technologies and Internet Commerce",
      "citeRegEx" : "Tizhoosh,? \\Q2005\\E",
      "shortCiteRegEx" : "Tizhoosh",
      "year" : 2005
    }, {
      "title" : "Reinforcement learning based on actions and opposite actions,",
      "author" : [ "H.R. Tizhoosh" ],
      "venue" : null,
      "citeRegEx" : "Tizhoosh,? \\Q2006\\E",
      "shortCiteRegEx" : "Tizhoosh",
      "year" : 2006
    }, {
      "title" : "A diversity maintaining population-based incremental learning algorithm,",
      "author" : [ "M. Ventresca", "H.R. Tizhoosh" ],
      "venue" : "Information Sciences,",
      "citeRegEx" : "Ventresca and Tizhoosh,? \\Q2008\\E",
      "shortCiteRegEx" : "Ventresca and Tizhoosh",
      "year" : 2008
    }, {
      "title" : "Space transformation search: A new evolutionary technique,",
      "author" : [ "H. Wang", "Z.J. Wu", "Y. Liu", "J. Wang", "D.Z. Jiang", "L.L. Chen" ],
      "venue" : "in: Proceedings of ACM/SIGEVO Summit on Genetic and Evolutionary Computation, Shanghai China,",
      "citeRegEx" : "Wang et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2009
    }, {
      "title" : "A review of opposition based learning from 2005 to 2012,",
      "author" : [ "Q. Xu", "L. Wang", "N. Wang", "X. Hei", "L. Zhao" ],
      "venue" : "Engineering Applications of Artificial Intelligence,",
      "citeRegEx" : "315",
      "shortCiteRegEx" : "315",
      "year" : 2014
    }, {
      "title" : "Opposition-based memetic search for the maximum diversity problem,",
      "author" : [ "Y. Zhou", "J.-K. Hao", "B. Duval" ],
      "venue" : "IEEE Transactions on Evolutionary Computation,",
      "citeRegEx" : "Zhou et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "We show that the DBL framework goes significantly beyond that of the more recent Opposition-based learning (OBL) framework introduced in Tizhoosh (2005), which has become the focus of numerous research initiatives in machine learning and metaheuristic optimization.",
      "startOffset" : 137,
      "endOffset" : 153
    }, {
      "referenceID" : 16,
      "context" : "Since its introduction in Tizhoosh (2005), a flood of proposals and studies have emerged to exploit its underlying ideas in a variety of contexts.",
      "startOffset" : 26,
      "endOffset" : 42
    }, {
      "referenceID" : 5,
      "context" : "An earlier framework introduced in the field of metaheuristic search (Glover, 1997; Glover and Laguna, 1997) provides a foundation that subsumes many of the OBL proposals, and gives a basis for additional enhancements.",
      "startOffset" : 69,
      "endOffset" : 108
    }, {
      "referenceID" : 18,
      "context" : "The same approach was also applied to other general methods like particle swarm optimization (Han and He, 2007), artificial neural networks (Ventresca and Tizhoosh, 2009), reinforcement learning (Tizhoosh, 2006), and population-based incremental learning (Ventresca and H.",
      "startOffset" : 195,
      "endOffset" : 211
    }, {
      "referenceID" : 3,
      "context" : "Within the setting of binary optimization, the paper Glover (1997) proposes several diversification generators that start from an arbitrary binary vector x = (xj: j  N = {1, .",
      "startOffset" : 53,
      "endOffset" : 67
    }, {
      "referenceID" : 3,
      "context" : "Within the setting of binary optimization, the paper Glover (1997) proposes several diversification generators that start from an arbitrary binary vector x = (xj: j  N = {1, ..., n}) and create a diverse collection D(x) of additional vectors that differ from x and from each other in various ways. (Each vector in D(x) is accompanied by its complement as a special case.) Consequently, from the perspective of opposition-based learning, this approach may be interpreted as replacing the notion of an opposite solution with the notion of a diverse (“opposite”) collection, as embodied in the criteria for diversity used to create D(x). (The diversification generators in Glover (1997) for creating various collections D(x) are described in the Appendix, including generators to create diverse sets of permutation vectors in a sequencing context, to give a clearer idea of the kinds of criteria that can be relevant.",
      "startOffset" : 53,
      "endOffset" : 691
    }, {
      "referenceID" : 3,
      "context" : "An example of f(x) given in Glover (1997) for the binary case is the simple linear function f(x) = ∑(fj xj: j  N) (2)",
      "startOffset" : 28,
      "endOffset" : 42
    }, {
      "referenceID" : 22,
      "context" : "The “opposite solution” proposed in Zhou et al. (2017) for the maximum diversity problem corresponds to such a solution.",
      "startOffset" : 36,
      "endOffset" : 55
    }, {
      "referenceID" : 6,
      "context" : "Motivation is also provided by a parametric strategy for mixed integer programming (Glover, 2006) that imposes bounds through a parameterized objective function in",
      "startOffset" : 83,
      "endOffset" : 97
    }, {
      "referenceID" : 3,
      "context" : "More generally, we are motivated to choose L and U to differ from L and U because of an optimization strategy introduced in Glover and Martinson (1984) that progressively manipulates lower and upper bounds (therefore generating values that can be represented by L and U) which enables a complex optimization problem to be solved by solving a series of much simpler problem relaxations.",
      "startOffset" : 124,
      "endOffset" : 152
    }, {
      "referenceID" : 14,
      "context" : "Several alternative definitions of an opposite solution from the OBL literature that invite comparison with the DBL definition are offered in the papers Rahnamayan et al. (2008a), Ergezer et al.",
      "startOffset" : 153,
      "endOffset" : 179
    }, {
      "referenceID" : 14,
      "context" : "Several alternative definitions of an opposite solution from the OBL literature that invite comparison with the DBL definition are offered in the papers Rahnamayan et al. (2008a), Ergezer et al. (2009), Ergezer and D.",
      "startOffset" : 153,
      "endOffset" : 202
    }, {
      "referenceID" : 14,
      "context" : "Several alternative definitions of an opposite solution from the OBL literature that invite comparison with the DBL definition are offered in the papers Rahnamayan et al. (2008a), Ergezer et al. (2009), Ergezer and D. Simon (2011), Rahnamayan and Wang (2009) and Wang et al (2009).",
      "startOffset" : 153,
      "endOffset" : 231
    }, {
      "referenceID" : 14,
      "context" : "Several alternative definitions of an opposite solution from the OBL literature that invite comparison with the DBL definition are offered in the papers Rahnamayan et al. (2008a), Ergezer et al. (2009), Ergezer and D. Simon (2011), Rahnamayan and Wang (2009) and Wang et al (2009).",
      "startOffset" : 153,
      "endOffset" : 259
    }, {
      "referenceID" : 14,
      "context" : "Several alternative definitions of an opposite solution from the OBL literature that invite comparison with the DBL definition are offered in the papers Rahnamayan et al. (2008a), Ergezer et al. (2009), Ergezer and D. Simon (2011), Rahnamayan and Wang (2009) and Wang et al (2009). All but one of these definitions fail to drive x\" away from x' in a manner that escapes being constrained by the midpoint of the interval, but instead generate a point at random that lies between this midpoint and another point (where the latter is either the point given by the classical OBL definition or the initial point x' itself).",
      "startOffset" : 153,
      "endOffset" : 281
    }, {
      "referenceID" : 14,
      "context" : "Several alternative definitions of an opposite solution from the OBL literature that invite comparison with the DBL definition are offered in the papers Rahnamayan et al. (2008a), Ergezer et al. (2009), Ergezer and D. Simon (2011), Rahnamayan and Wang (2009) and Wang et al (2009). All but one of these definitions fail to drive x\" away from x' in a manner that escapes being constrained by the midpoint of the interval, but instead generate a point at random that lies between this midpoint and another point (where the latter is either the point given by the classical OBL definition or the initial point x' itself). The definition that constitutes an exception, producing what is called the generalized opposite point in Wang et al. (2009), can be interpreted as attempting to drive x\" away from the midpoint, but has the curious weakness of failing to be invariant under translations of the bounds L and U.",
      "startOffset" : 153,
      "endOffset" : 743
    }, {
      "referenceID" : 3,
      "context" : "An approach suggested in Glover (1994) provides a starting point for this extension, in which the goal becomes to maximize the minimum distance of x\" from all points x'  X'.",
      "startOffset" : 25,
      "endOffset" : 39
    }, {
      "referenceID" : 20,
      "context" : "(2011), exhibits complications similar to those of Wang et al. (2009).",
      "startOffset" : 51,
      "endOffset" : 70
    }, {
      "referenceID" : 3,
      "context" : ", Glover and Laguna, 1993, 1997) periodically introduces a large tabu tenure to prevent the trajectory of neighboring solutions from reversing any of its component moves. By selecting the number of moves defined by “large,” it is possible to generate solutions that constitute varying levels of opposition relative to the solution that launched the trajectory. An extreme version of such an approach that uses an unbounded tabu tenure, and continues until no more moves are available to be selected, was found to be highly effective in Kelly et al. (1994). This outcome suggests that the use of large tabu tenures to identify opposite solutions deserves further exploration.",
      "startOffset" : 2,
      "endOffset" : 556
    }, {
      "referenceID" : 7,
      "context" : "Bi-directional opposite solutions from exterior path relinking: Exterior path relinking (Glover, 2014; Duarte et al. 2015), is a population-based approach utilizing an initiating solution x and a guiding solution x, to creates a trajectory from x to x that goes beyond the guiding solution x.",
      "startOffset" : 88,
      "endOffset" : 122
    }, {
      "referenceID" : 10,
      "context" : "Generating opposite solutions from clustering: Clustering provides an important opportunity for organizing the generation of opposite solutions by metaheuristic processes (see, e.g., Glover, 1977; Glover and Laguna, 1993).",
      "startOffset" : 171,
      "endOffset" : 221
    }, {
      "referenceID" : 4,
      "context" : "In a sequential procedure for extracting the points (Glover, 1994), these criteria can produce many ties for the element to be selected next, once a small number of elements have been selected.",
      "startOffset" : 52,
      "endOffset" : 66
    }, {
      "referenceID" : 3,
      "context" : "Drawing on this observation, a variety of more sophisticated iterative approaches are introduced in Glover (2016) for obtaining collections of points that are more diverse than those found by simpler constructive methods.",
      "startOffset" : 100,
      "endOffset" : 114
    } ],
    "year" : 2017,
    "abstractText" : "Diversification-Based Learning (DBL) derives from a collection of principles and methods introduced in the field of metaheuristics that have broad applications in computing and optimization. We show that the DBL framework goes significantly beyond that of the more recent Opposition-based learning (OBL) framework introduced in Tizhoosh (2005), which has become the focus of numerous research initiatives in machine learning and metaheuristic optimization. We unify and extend earlier proposals in metaheuristic search (Glover, 1997, Glover and Laguna, 1997) to give a collection of approaches that are more flexible and comprehensive than OBL for creating intensification and diversification strategies in metaheuristic search. We also describe potential applications of DBL to various subfields of machine learning and optimization.",
    "creator" : "Microsoft® Word 2016"
  }
}