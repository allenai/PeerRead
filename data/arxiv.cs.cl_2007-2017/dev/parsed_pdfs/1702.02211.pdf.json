{
  "name" : "1702.02211.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 2.\n02 21\n1v 2\n[ cs\n.C L\n] 1\n1 Fe\nb 20\n17\nagnostic method for learning root-andpattern morphology in Semitic languages. We harness the syntactico-semantic information in distributed word representations to solve the long standing problem of root-and-pattern discovery in Semitic languages. The root-and-pattern morphological rules we learn in an unsupervised manner are validated by native speakers in Arabic, Hebrew, and Amharic. Further, the rules are used to construct an unsupervised root extractor called JZR, which we show to compare favorably with ISRI, a widely used and carefully engineered root extractor for Arabic."
    }, {
      "heading" : "1 Introduction",
      "text" : "Morphological analysis is a core task in natural language processing and hence of central interest in computational linguistics (Kurimo et al., 2010) with widespread applications benefits (Korenius et al., 2004; Skorkovská, 2012; Seddah et al., 2010; Semmar et al., 2006; Larkey et al., 2002). Computational approaches to morphological analysis for lemmatization and stemming rely on knowledge of the mapping from inflected forms to lemmas. However, the more widely used systems that learn these mappings are restricted to handle only concatenative morphology, learning overt affixes and their interactions with stems (Creutz and Lagus, 2005; Soricut and Och, 2015; Lee et al., 2011; Goldsmith, 2000; Pasha et al., 2014; Buckwalter, 2004). As an example, consider the agentive formation in Arabic (Table 1): (to write, ktb) in the root form to (writer, kAtib) in the agent form. Unlike in English, where the agentive\nformation occurs as a concatenation of the suffix “er”, in Arabic, the process involves applying a specific pattern (C1AC2iC3, in the notation of Section 2) to the root ktb to form the word kAtib. Such processes, which constitute a significant component in Semitic languages, are not captured by existing unsupervised systems. The focus of this study is a computational approach to an important non-concatenative process–that of root-and-pattern morphology.\nCurrent approaches for root-andpattern morphology involve rule-based root extraction (Khoja and Garside, 1999; Taghva et al., 2005; Ababneh et al., 2012; El-Beltagy and Rafea, 2011; Alhanini et al., 2011; Al-Shalabi and Evens, 1998), and others that require training data of word-root pairs (Attia et al., 2016; Al-Serhan and Ayesh, 2006), all developed for processing Arabic. The resource-intensive nature of these methods not only limits their wider applicability to other Semitic languages but also prevents from handling the productive process more generally.\nThis paper describes a language-agnostic (within the Semitic language family) algorithm that learns root-and-pattern, as well as concatenative morphology in an unsupervised manner resulting in a root extractor. A novel aspect of our approach is the use of word semantics made possible by relying on distributed word representations. Such a reliance on word representations permits a different mechanism of morpheme segmentation,\nwhich is being performed by an abstraction that is not obvious at the surface level. Qualitative analyses show perfect rules acquired for the 3 languages. Quantitative analyses of root extraction on Arabic show performance comparable to carefully engineered systems."
    }, {
      "heading" : "2 Root-and-Pattern Morphology Illustration",
      "text" : "We explain root-and-pattern morphology with an example. Our examples will take the form (English translation, English transliteration, Consonant-only transliteration), and transliteration will follow the standard in (Lagally, 1992). In Semitic languages, a pattern (bound morpheme) is applied to a root (free morpheme) to generate a word. In general, the roots consist of 3 consonants; example: (to write, kataba, ktb) (Aljlayl and Frieder, 2002). The patterns encode the placement of the 3 consonants with respect to the added letters, an example of which is, C1AC2iC3. Here, the vowel “A” is placed between the first and the second consonant and the vowel “i” between the second and the third consonant. Applying this pattern to the 3-consonant root in our example, the resulting word is (writer, kAtib, ktb). This pattern encodes the semantic role of “Agent” and hence kAtib is the agent of the verb kataba."
    }, {
      "heading" : "3 Learning of Morphological Rules",
      "text" : "The task of morphological rule learning is, given a corpus, we would like to extract patterns that govern root-and-pattern morphology as well as affixes that govern concatenative morphology. Our proposed method assumes three models. An orthographic model for concatenative morphology and an orthographic model for root-and-pattern morphology signal all possible morphological (candidate) rules and all possible (candidate) pairs of morphologically related words from an orthographic perspective. Then a semantic model validates whether a candidate rule is morphologically valid and whether a pair of words is morphologically related.\nExisting approaches towards root-and-pattern morphology in the literature tend to be a set of orthographic rules defining the model; the heavy reliance on expert linguistic rules naturally leads to poor coverage. Besides, the orthographic rules disregard the semantically motivated morpholog-\nical transformation. For example, in English, the pair of words (on, only) shows orthographically a morphological relation via the suffix “ly”. Disregarding semantic knowledge in such a situation would lead to a false morphological analysis. This motivates our approach which models the relation between roots, patterns, and words through a combination of orthographic rules and semantic information available in distributed word representations."
    }, {
      "heading" : "3.1 Orthographic Models",
      "text" : "To detect candidate morphological rules from an orthographic standpoint, we define two models, one for concatenative morphology, and one for root-and-pattern morphology."
    }, {
      "heading" : "3.1.1 Concatenative Morphology",
      "text" : "In concatenative morphology, affixes attach to a stem (Siegel, 1974). Thus we model concatenative morphology as the process of deletions from one end of the word followed by insertions on the same end. For example, the words (desk, maktab, mktb) and (the desk, almaktab, lmktb) are considered morphologically related from an orthographic standpoint whereby there was 0 deletions in the beginning of the word followed by two insertions (a,l). This would contribute to the candidate rule (prefix, φ, al). Another example would be the pair of words (the desk, almaktab, lmktb) and (and desk, wamaktab, wmktb). Based on this model, they would be linked via two deletions (a,l) and two insertions (w,a), and this pair would contribute to the rule (prefix, al, wa). We found a maximum of 6 insertions and deletions to be sufficient to model the concatenative relation."
    }, {
      "heading" : "3.1.2 Root-and-Pattern Morphology",
      "text" : "All Semitic languages share the following two properties of relations between roots and their pattern-derived words on an orthographic level (Greenberg, 1950):\n• Roots are predominantly tri-literal.\n• The root consonants (C1, C2, C3) retain their relative order after combining with a pattern\nto form a word.\nFor example, in Table 1, the word kAtib would be compared to the tri-literal root ktb, and consequently, the template C1AC2iC3 would be considered as a candidate root-and-pattern template."
    }, {
      "heading" : "3.2 Semantic Model",
      "text" : "Not every pair of words obeying the orthographic properties, constitutes a morphologically related pair. As an example, (gone, rA.h) and (wounds, jirA.h) are connected orthographically via the rule (prefix, φ, ji) although they’re not morphologically related. In order to ascertain that a pair of words obeying the orthographic properties are indeed morphologically related, we make use of the semantic relationship between the words via word representations. This is because word representations and their geometry in the vector space have been shown to encode syntactico-semantic relations (Mikolov et al., 2013b). For example, consider the two pairs: (1) ((wrote, kataba, ktb), (desk, maktab, mktb)), and, (2) ((played, la‘iba, l‘b), (playing field, mal‘ab, ml‘b)). We can verify that ~vkataba ´ ~vmaktab « ~vla‘iba ´ ~vmal‘ab, to confirm that orthographically related word pairs are indeed morphologically related, here through the pattern (maC1C2aC3) which means the place of the action. On the other hand, alluding to the previous example r = (prefix, φ, ji), difference vectors of elements of the support set of this rule would not show such regularities in the vector space."
    }, {
      "heading" : "3.3 Algorithmic Implementation",
      "text" : "Our approach is inspired by (Soricut and Och, 2015), which, being limited to concatenative morphology, serves as the primary mechanism to generate the concatenative morphological rules for the languages in our study. Our contribution is in adapting their approach to handle nonconcatanative morphology. Our system is implemented in 4 steps:\n1. Generation of the vocabulary set V and word\nembeddings from corpus (Word representation);\n2. Generation of candidate (root, derived) pairs\ngrouped into sets based on the underlying orthographic transformation. These sets represent the morphological rules in our system. (Candidate generation);\n3. Validation of candidate morphological rules\nusing the semantic and orthographic model (Validation of candidate rules).\n4. Validation of candidate rule elements as\nmorphologically related pairs of words (Validation of rule elements).\nThe result is a set of morphological rules and their elements, scored semantically and orthographically.\nStep 1: Word representation. We rely on a large enough corpus to generate a vocabulary set V made up of all the word types appearing in the corpus, which is then used to generate word embeddings for the vocabulary using an algorithm such asWord2Vec (Mikolov et al., 2013a) or Glove (Pennington et al., 2014).\nStep 2: Candidate generation. All pairs of words morphologically related by the same orthographic transformation are grouped into one set to represent a candidate morphological rule. For example, the concatenative rule r = (prefix, φ, “al”) would be represented by the support set SSr = {(maktab, almaktab), (jaras, aljaras), ...}. Similarly, the rule r = (maC1C2aC3), shown in Table 1, would have SSr = {(ktb, maktab), (l’b, mal’ab), ...}. We should note that not all generated rules in this step are valid morphologically. We refer to the set of all rules as R.\nStep 3: Validation of candidate rules. Due to the “overgeneration” of candidate rules in the previous step, we prune the rules using a semantic and an orthographic score. Formally, for a given rule r with support set SSr, scorer sem(r) = |{(w1, w2), (w3, w4) P SSr | cos(w4,w2 -w1 +w3)ą tcos sim}| divided by |SSr| 2, where tcos sim is a threshold appropriately chosen. Also, for every rule r, |SSr| reflects the quality of r from an orthographic point of view. This is captured via scorer orth(r) = |SSr|.\nStep 4: Validation of rule elements. The orthographic model not only overgenerates candidate rules but also overgenerates pairs of words belonging to a specific rule. As an example, consider the words (to go, zhb) and (religion, mazhab) – this pair belongs to the valid root-and-pattern rule guided by the pattern maC1C2aC3, and yet, the words are not morphologically related. To score instances within a rule r as valid instances we deploy this semantic score: scorew sem((w1, w2) P r) = |{(w3, w4) P SSr | cos(w4, w2 - w1 + w3) ą tcos sim}| divided by |SSr|. In other words, we check how well the difference vector of the pair of interest fits with the difference vectors of other pairs within the rule support set SSr."
    }, {
      "heading" : "4 JZR: Root Extractor",
      "text" : "We cast the root extraction task as an iterative optimization problem. Let Radd be all concatenative\nrules of the form (affix, φ, affix added), as well as all root-and-pattern rules, and Rrep be all concatenative rules of the form (affix, affix deleted, affix added). Given a word w whose root needs to be extracted, we search for rule r˚, the solution to the following optimization problem:\nmax r\nscorew semprq\nsubject to r P Radd\nscorer semprq ą tr sem\nscorer orthprq ą tr orth scorew semppw 1, wq P SSrq ą tw sem\nIn the above optimization problem, tr sem, tr orth, tw sem are tunable hyperparameters. The solution r˚ and w uniquely identify w1. Thus the system extracts w1 and iterates over w1 until it reaches a triliteral word. At any stage, if the optimization problem is infeasible we repeat it over Rrep instead of Radd. Note that we only consider rules which result in aw1 of length less thanw to correctly model the chain of morphological processes as well to guarantee convergence of algorithm.\nThe system presented here is readily adaptable to other morphological tasks, such as morpheme segmentation and morphological reinflection and not discussed in this paper."
    }, {
      "heading" : "5 Experiments and Results",
      "text" : "In this section, we evaluate our method in multiple ways on 3 different languages (Arabic, Hebrew, Amharic). We first evaluate our method qualitatively by checking the root-and-pattern rules it discovers in the 3 languages. Then we evaluate JZR quantitatively by comparing its accuracy against the widely used ISRI Arabic root extractor (Taghva et al., 2005) on a sample of 1200 words."
    }, {
      "heading" : "5.1 Experimental Setup",
      "text" : "For each of the three languages, we use the readily available Polyglot1 word representations and its vocabulary. These 64d word representations were created based on the Wikipedia in the respective language. Arabic and Hebrew embeddings were limited to the top 100K words whereas Amharic, being a low-resource language was restricted to the top 10K words. Our hyperparameters (tuned to ISRI output) were set to the following: tr sur = 20, tr sem = 0.1 , tw sem = 0.1, tcos sim = 0.5.\n1https://sites.google.com/site/rmyeid/projects/polyglot"
    }, {
      "heading" : "51.88% 45.63 % 61.63%",
      "text" : ""
    }, {
      "heading" : "5.2 Evaluation of Root-and-Pattern rules",
      "text" : "We validate root-and-pattern rules across the 3 languages by ranking the rules in terms of scorer semprq and have a native speaker of each language evaluate the top 30 rules. All 30 rules in each of the 3 languages were deemed correct, validating the language-agnosticity and performance of our unsupervised approach."
    }, {
      "heading" : "5.3 Intrinsic Evaluation on Arabic",
      "text" : "In this experiment, we consider 3 Arabic root extractors: JZR, JZR (limited), and ISRI, and evaluate them on a sample of 1200 words. JZR (limited) is a version of JZR limited to concatenative morphology. Comparison against it reflects the added value of the discovered root-and-pattern rules.\nFrom the results (summarized in Table 2), we notice: (1) JZR compares favorably with ISRI, a carefully engineered rule-based and languagespecific root extractor (2) Limiting JZR to concatenative morphology led to an 11.5% relative drop in scores. This reflects the significance of the non-concatenative rules captured by JZR. We also claim that this drop is an underestimate of the significance of the learned root-and-pattern rules. We discuss this claim in detail in Appendix A, along with further analyses of the results and sample outputs."
    }, {
      "heading" : "6 Conclusion",
      "text" : "This work presents an unsupervised method for the discovery of root-and-pattern morphology in Semitic languages. The discovered rules are used to extract Semitic roots, which are the basic units of these languages. Intrinsic and extrinsic evaluations of these rules allow us to validate our pattern discovery method as well as our root extraction method (JZR), with performance not too far from a rule-based language-specific (in this case Arabic) root extractor."
    }, {
      "heading" : "A Discussion",
      "text" : "We believe that the drop in performance when limiting JZR to concatenative morphology underestimates the abundance of root-and-pattern morphology in Arabic. The reason is that the way we define concatenative morphology could capture rootand-pattern morphology under strict conditions. For the purpose of illustration we have collected 5 representative examples into Table 3, where correct roots are boldfaced. To illustrate this underestimate, consider as an example, the second word in Table 3. All extractors were able to get the second example correct. Although, the word was derived using a pattern, JZR (limited) was still able to get it right since the stem change was close to the edge of the word. To illustrate this further, a word like kitAb is stripped first of the “i” using the rule (pre, ki, k), and similarly stripped of the “A” using a suffix rule. These cases are limited, since to extract such a rule, this pattern should appear frequently with a word starting (ending) with a “k” (“b”). The first example shows how the limitation to concatenative morphology prevented JZR (limited) from removing the pattern, leading to a non-root word. In the third example, JZR fails for using a valid rule on an invalid pair of words, which reflects the imperfections in the word embeddings’ linear structure.\nFor purposes of comparison, we also show oneto-one comparisons of performance in Table 4. Two key takeaways arise in this table. First, JZR (limited) never performs better than JZR, which shows the precision of discovered root-and-pattern\nrules. Second, JZR performed better than JZR (limited) on 63 occasions due to the discovery of root-and-pattern morphology. Moreover, it is interesting to see that on multiple occasions JZR performed better than ISRI, which shows that rulebased methods are insufficient and unsupervised methods are needed to fill the gap."
    } ],
    "references" : [ {
      "title" : "Building an ef",
      "author" : [ "Kanaan", "Alaa Al-Nobani" ],
      "venue" : null,
      "citeRegEx" : "Kanaan and Al.Nobani.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kanaan and Al.Nobani.",
      "year" : 2012
    }, {
      "title" : "Efficient estimation of word",
      "author" : [ "frey Dean" ],
      "venue" : null,
      "citeRegEx" : "Dean.,? \\Q2013\\E",
      "shortCiteRegEx" : "Dean.",
      "year" : 2013
    }, {
      "title" : "Using stemming in morphological analysis to improve arabic information retrieval",
      "author" : [ "Nasredine Semmar", "Meriama Laib", "Christian Fluhr." ],
      "venue" : "verbum ex machina page 317.",
      "citeRegEx" : "Semmar et al\\.,? 2006",
      "shortCiteRegEx" : "Semmar et al\\.",
      "year" : 2006
    }, {
      "title" : "Topics in English morphology",
      "author" : [ "Dorothy Carla Siegel" ],
      "venue" : "Ph.D. thesis, Massachusetts Institute of Technology",
      "citeRegEx" : "Siegel.,? \\Q1974\\E",
      "shortCiteRegEx" : "Siegel.",
      "year" : 1974
    }, {
      "title" : "Application of lemmatization and summarization methods in topic identification module for large scale language modeling data filtering",
      "author" : [ "Lucie Skorkovská." ],
      "venue" : "International Conference on Text, Speech and Dialogue. Springer, pages 191–198.",
      "citeRegEx" : "Skorkovská.,? 2012",
      "shortCiteRegEx" : "Skorkovská.",
      "year" : 2012
    }, {
      "title" : "Unsupervisedmorphology induction using word embeddings",
      "author" : [ "Radu Soricut", "Franz Och." ],
      "venue" : "Proc. NAACL.",
      "citeRegEx" : "Soricut and Och.,? 2015",
      "shortCiteRegEx" : "Soricut and Och.",
      "year" : 2015
    }, {
      "title" : "Arabic stemming without a root dictionary",
      "author" : [ "Kazem Taghva", "Rania Elkhoury", "Jeffrey S Coombs." ],
      "venue" : "ITCC (1). pages 152–157.",
      "citeRegEx" : "Taghva et al\\.,? 2005",
      "shortCiteRegEx" : "Taghva et al\\.",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : ", 2010) with widespread applications benefits (Korenius et al., 2004; Skorkovská, 2012; Seddah et al., 2010; Semmar et al., 2006; Larkey et al., 2002).",
      "startOffset" : 46,
      "endOffset" : 150
    }, {
      "referenceID" : 2,
      "context" : ", 2010) with widespread applications benefits (Korenius et al., 2004; Skorkovská, 2012; Seddah et al., 2010; Semmar et al., 2006; Larkey et al., 2002).",
      "startOffset" : 46,
      "endOffset" : 150
    }, {
      "referenceID" : 5,
      "context" : "However, the more widely used systems that learn these mappings are restricted to handle only concatenative morphology, learning overt affixes and their interactions with stems (Creutz and Lagus, 2005; Soricut and Och, 2015; Lee et al., 2011; Goldsmith, 2000; Pasha et al., 2014; Buckwalter, 2004).",
      "startOffset" : 177,
      "endOffset" : 297
    }, {
      "referenceID" : 6,
      "context" : "Current approaches for root-andpattern morphology involve rule-based root extraction (Khoja and Garside, 1999; Taghva et al., 2005; Ababneh et al., 2012; El-Beltagy and Rafea, 2011; Alhanini et al., 2011; Al-Shalabi and Evens, 1998), and others that require training data of word-root pairs (Attia et al.",
      "startOffset" : 85,
      "endOffset" : 232
    }, {
      "referenceID" : 3,
      "context" : "In concatenative morphology, affixes attach to a stem (Siegel, 1974).",
      "startOffset" : 54,
      "endOffset" : 68
    }, {
      "referenceID" : 5,
      "context" : "Our approach is inspired by (Soricut and Och, 2015), which, being limited to concatenative morphology, serves as the primary mechanism to generate the concatenative morphological rules for the languages in our study.",
      "startOffset" : 28,
      "endOffset" : 51
    }, {
      "referenceID" : 6,
      "context" : "Then we evaluate JZR quantitatively by comparing its accuracy against the widely used ISRI Arabic root extractor (Taghva et al., 2005) on a sample of 1200 words.",
      "startOffset" : 113,
      "endOffset" : 134
    } ],
    "year" : 2017,
    "abstractText" : "We present an unsupervised and languageagnostic method for learning root-andpattern morphology in Semitic languages. We harness the syntactico-semantic information in distributed word representations to solve the long standing problem of root-and-pattern discovery in Semitic languages. The root-and-pattern morphological rules we learn in an unsupervised manner are validated by native speakers in Arabic, Hebrew, and Amharic. Further, the rules are used to construct an unsupervised root extractor called JZR, which we show to compare favorably with ISRI, a widely used and carefully engineered root extractor for Arabic.",
    "creator" : "LaTeX with hyperref package"
  }
}