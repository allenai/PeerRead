{
  "name" : "1703.02527.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Online Learning to Rank in Stochastic Click Models",
    "authors" : [ "Masrour Zoghi", "Tomas Tunys", "Mohammad Ghavamzadeh", "Branislav Kveton", "Csaba Szepesvari", "Zheng Wen" ],
    "emails" : [ "<kveton@adobe.com>,", "<masrour@zoghi.org>." ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Learning to rank (LTR) is a core problem in information retrieval (Liu, 2011) and machine learning; with numerous applications in web search, recommender systems and ad placement. The goal of LTR is to present a list of K documents out of L that maximizes the satisfaction of the user. This problem has been traditionally solved by training supervised learning models on manually annotated relevance judgments. However, strong evidence suggests (Agichtein\n1Independent Researcher, Vancouver, BC, Canada (Part of this work was done during an internship at Adobe Research) 2Czech Technical University, Prague, Czech Republic 3DeepMind, Mountain View, CA, USA (This work was done while the author was at Adobe Research) 4Adobe Research, San Jose, CA, USA 5University of Alberta, Edmonton, AB, Canada. Correspondence to: Branislav Kveton <kveton@adobe.com>, Masrour Zoghi <masrour@zoghi.org>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\net al., 2006; Zoghi et al., 2016) that the feedback of users, that is clicks, can lead to major improvements over supervised LTR methods. In addition, billions of users interact daily with commercial LTR systems, and it is finally feasible to interactively and adaptive maximize the satisfaction of these users from clicks.\nThese observations motivated numerous papers on online LTR methods, which utilize user feedback to improve the quality of ranked lists. These methods can be divided into two groups: learning the best ranker in a family of rankers (Yue & Joachims, 2009; Hofmann et al., 2013), and learning the best list under some model of user interaction with the list (Radlinski et al., 2008a; Slivkins et al., 2013), such as a click model (Chuklin et al., 2015). The click model is a stochastic model of how the user examines and clicks on a list of documents. In this work, we focus on online LTR in click models and address a shortcoming of all past work on this topic.\nMore precisely, many algorithms have been proposed and analyzed for finding the optimal ranked list in the cascade model (CM) (Kveton et al., 2015a; Combes et al., 2015; Kveton et al., 2015b; Zong et al., 2016; Li et al., 2016), the dependent-click model (DCM) (Katariya et al., 2016), and the position-based model (PBM) (Lagree et al., 2016). The problem is that if the user interacts with ranked lists using a different click model, the theoretical guarantees cease to hold. Then, as we show empirically, these algorithms may converge to suboptimal solutions. This is a grave issue because it is well known that no single click model captures the behavior of an entire population of users (Grotov et al., 2015). Therefore, it is critical to develop efficient learning algorithms for multiple click models, which is the aim of this paper.\nWe make the following contributions:\n• We propose stochastic click bandits, a learning framework for maximizing the expected number of clicks in online LTR in a broad class of click models, which includes both the PBM (Richardson et al., 2007) and CM (Craswell et al., 2008). • We propose the first algorithm, BatchRank, that is guaranteed to learn the optimal solution in a diverse class of click models. This is of a great practical significance, as\nar X\niv :1\n70 3.\n02 52\n7v 2\n[ cs\n.L G\n] 2\n0 Ju\nn 20\n17\nit is often difficult or impossible to guess the underlying click model in advance. • We prove a gap-dependent upper bound on the regret of BatchRank that scales well with all quantities of interest. The key step in our analysis is a KL scaling lemma (Section 5.4), which should be of a broader interest. • We evaluate BatchRank on both CM and PBM queries. Our results show that BatchRank performs significantly better than RankedExp3 (Radlinski et al., 2008a), an adversarial online LTR algorithm; and is more robust than CascadeKL-UCB (Kveton et al., 2015a), an optimal online LTR algorithm for the CM.\nWe define [n] = {1, . . . , n}. For any sets A and B, we denote by AB the set of all vectors whose entries are indexed by B and take values from A. We use boldface letters to denote important random variables."
    }, {
      "heading" : "2. Background",
      "text" : "This section reviews two fundamental click models (Chuklin et al., 2015), models of how users click on an ordered list of K documents. The universe of all documents is represented by ground set D = [L] and we refer to the documents in D as items. The user is presented a ranked list, an ordered list of K documents out of L. We denote this list by R = (d1, . . . , dK) ∈ ΠK(D), where ΠK(D) ⊂ DK is the set of all K-tuples with distinct elements from D and dk is the k-th item in R. We assume that the click model is parameterized by L item-dependent attraction probabilities α ∈ [0, 1]L, where α(d) is the probability that item d is attractive. The items attract the user independently. For simplicity and without loss of generality, we assume that α(1) ≥ . . . ≥ α(L). The reviewed models differ in how the user examines items, which leads to clicks."
    }, {
      "heading" : "2.1. Position-Based Model",
      "text" : "The position-based model (PBM) (Richardson et al., 2007) is a model where the probability of clicking on an item depends on both its identity and position. Therefore, in addition to item-dependent attraction probabilities, the PBM is parameterized by K position-dependent examination probabilities χ ∈ [0, 1]K , where χ(k) is the examination probability of position k.\nThe user interacts with a list of itemsR = (d1, . . . , dK) as follows. The user examines position k ∈ [K] with probability χ(k) and then clicks on item dk at that position with probability α(dk). Thus, the expected number of clicks on listR is\nr(R) = K∑ k=1 χ(k)α(dk) .\nIn practice, it is often observed that χ(1) ≥ . . . ≥ χ(K)\n(Chuklin et al., 2015), and we adopt this assumption in this work. Under this assumption, the above function is maximized by the list of K most attractive items\nR∗ = (1, . . . ,K) , (1)\nwhere the k-th most attractive item is placed at position k.\nIn this paper, we focus on the objective of maximizing the number of clicks. We note that the satisfaction of the user may not increase with the number of clicks, and that other objectives have been proposed in the literature (Radlinski et al., 2008b). The shortcoming of all of these objectives is that none directly measure the satisfaction of the user."
    }, {
      "heading" : "2.2. Cascade Model",
      "text" : "In the cascade model (CM) (Craswell et al., 2008), the user scans a list of items R = (d1, . . . , dK) from the first item d1 to the last dK . If item dk is attractive, the user clicks on it and does not examine the remaining items. If item dk is not attractive, the user examines item dk+1. The first item d1 is examined with probability one.\nFrom the definition of the model, the probability that item dk is examined is equal to the probability that none of the first k − 1 items are attractive. Since each item attracts the user independently, this probability is\nχ(R, k) = k−1∏ i=1 (1− α(di)) . (2)\nThe expected number of clicks on list R is at most 1, and is equal to the probability of observing any click,\nr(R) = K∑ k=1 χ(R, k)α(dk) = 1− K∏ k=1 (1− α(dk)) .\nThis function is maximized by the list of K most attractive items R∗ in (1), though any permutation of [K] would be optimal in the CM. Note that the list R∗ is optimal in both the PBM and CM."
    }, {
      "heading" : "3. Online Learning to Rank in Click Models",
      "text" : "The PBM and CM (Section 2) are similar in many aspects. First, both models are parameterized by L item-dependent attraction probabilities. The items attract the user independently. Second, the probability of clicking on the item is a product of its attraction probability, which depends on the identity of the item; and the examination probability of its position, which is independent of the identity of the item. Finally, the optimal solution in both models is the list of K most attractive itemsR∗ in (1), where the k-th most attractive item is placed at position k.\nThis suggests that the optimal solution in both models can be learned by a single learning algorithm, which does not know the underlying model. We propose this algorithm in Section 4. Before we discuss it, we formalize our learning problem as a multi-armed bandit (Auer et al., 2002; Lai & Robbins, 1985)."
    }, {
      "heading" : "3.1. Stochastic Click Bandit",
      "text" : "We refer to our learning problem as a stochastic click bandit. An instance of this problem is a tuple (K,L, Pα, Pχ), where K is the number of positions, L is the number of items, Pα is a distribution over binary vectors {0, 1}L, and Pχ is a distribution over binary matrices {0, 1}ΠK(D)×K .\nThe learning agent interacts with our problem as follows. Let (At,Xt)Tt=1 be T i.i.d. random variables drawn from Pα ⊗ Pχ, where At ∈ {0, 1}L and At(d) is the attraction indicator of item d at time t; and Xt ∈ {0, 1}ΠK(D)×K andXt(R, k) is the examination indicator of position k in list R ∈ ΠK(D) at time t. At time t, the agent chooses a list Rt = (dt1, . . . ,dtK) ∈ ΠK(D), which depends on past observations of the agent, and then observes clicks. These clicks are a function of Rt, At, and Xt. Let ct ∈ {0, 1}K be the vector of click indicators on all positions at time t. Then\nct(k) = Xt(Rt, k)At(dtk)\nfor any k ∈ [K], the item at position k is clicked only if bothXt(Rt, k) = 1 andAt(dtk) = 1.\nThe goal of the learning agent is to maximize the number of clicks. Therefore, the number of clicks at time t is the reward of the agent at time t. We define it as\nrt = K∑ k=1 ct(k) = r(Rt,At,Xt) , (3)\nwhere r : ΠK(D) × [0, 1]L × [0, 1]ΠK(D)×K → [0,K] is a reward function, which we define for any R ∈ ΠK(D), A ∈ [0, 1]L, and X ∈ [0, 1]ΠK(D)×K as\nr(R, A,X) = K∑ k=1 X(R, k)A(dk) .\nWe adopt the same independence assumptions as in Section 2. In particular, we assume that items attract the user independently.\nAssumption 1. For any A ∈ {0, 1}L,\nP (At = A) = ∏ d∈D Ber(A(d);α(d)) ,\nwhere Ber(·; θ) denotes the probability mass function of a Bernoulli distribution with mean θ ∈ [0, 1], which we define as Ber(y; θ) = θy(1− θ)1−y for any y ∈ {0, 1}.\nMoreover, we assume that the attraction of any item is independent of the examination of its position.\nAssumption 2. For any listR ∈ ΠK(D) and position k,\nE [ct(k) |Rt = R] = χ(R, k)α(dk) ,\nwhere χ ∈ [0, 1]ΠK(D)×K and χ(R, k) = E [Xt(R, k)] is the examination probability of position k in listR.\nWe do not make any independence assumptions among the entries ofXt, and on other interactions ofAt andXt.\nFrom our independence assumptions and the definition of the reward in (3), the expected reward of listR is\nE [r(R,At,Xt)] = K∑ k=1 χ(R, k)α(dk) = r(R, α, χ) .\nWe evaluate the performance of a learning agent by its expected cumulative regret\nR(T ) = E [ T∑ t=1 R(Rt,At,Xt) ] ,\nwhere R(Rt,At,Xt) = r(R∗,At,Xt)− r(Rt,At,Xt) is the instantaneous regret of the agent at time t and\nR∗ = arg maxR∈ΠK(D) r(R, α, χ)\nis the optimal list of items, the list that maximizes the expected reward. To simplify exposition, we assume that the optimal solution, as a set, is unique."
    }, {
      "heading" : "3.2. Position Bandit",
      "text" : "The learning variant of the PBM in Section 2.1 can be formulated in our setting when\n∀R,R′ ∈ ΠK(D) : Xt(R, k) = Xt(R′, k) (4)\nat any position k ∈ [K]. Under this assumption, the probability of clicking on item dtk at time t is\nE [ct(k) |Rt] = χ(k)α(dtk) ,\nwhere χ(k) is defined in Section 2.1. The expected reward of list Rt at time t is\nE [rt |Rt] = K∑ k=1 χ(k)α(dtk) ."
    }, {
      "heading" : "3.3. Cascading Bandit",
      "text" : "The learning variant of the CM in Section 2.2 can be formulated in our setting when\nXt(R, k) = k−1∏ i=1 (1−At(di)) (5)\nfor any list R ∈ ΠK(D) and position k ∈ [K]. Under this assumption, the probability of clicking on item dtk at time t is\nE [ct(k) |Rt] = [ k−1∏ i=1 (1− α(dti)) ] α(dtk) .\nThe expected reward of list Rt at time t is\nE [rt |Rt] = K∑ k=1 [ k−1∏ i=1 (1− α(dti)) ] α(dtk) ."
    }, {
      "heading" : "3.4. Additional Assumptions",
      "text" : "The above assumptions are not sufficient to guarantee that the optimal list R∗ in (1) is learnable. Therefore, we make four additional assumptions, which are quite natural. Assumption 3 (Order-independent examination). For any listsR ∈ ΠK(D) andR′ ∈ ΠK(D), and position k ∈ [K] such that dk = d′k and {d1, . . . , dk−1} = { d′1, . . . , d ′ k−1 }\n, Xt(R, k) = Xt(R′, k).\nThe above assumption says that the examination indicator Xt(R, k) only depends on the identities of d1, . . . , dk−1. Both the CM and PBM satisfy this assumption, which can be validated from (4) and (5). Assumption 4 (Decreasing examination). For any listR ∈ ΠK(D) and positions 1 ≤ i ≤ j ≤ K, χ(R, i) ≥ χ(R, j).\nThe above assumption says that a lower position cannot be examined more than a higher position, in any list R. Both the CM and PBM satisfy this assumption. Assumption 5 (Correct examination scaling). For any list R ∈ ΠK(D) and positions 1 ≤ i ≤ j ≤ K, let α(di) ≤ α(dj) and R′ ∈ ΠK(D) be the same list as R except that di and dj are exchanged. Then χ(R, j) ≥ χ(R′, j).\nThe above assumption says that the examination probability of a position cannot increase if the item at that position is swapped for a less-attractive higher-ranked item, in any list R. Both the CM and PBM satisfy this assumption. In the CM, the inequality follows directly from the definition of examination in (2). In the PBM, χ(R, j) = χ(R′, j). Assumption 6 (Optimal examination). For any list R ∈ ΠK(D) and position k ∈ [K], χ(R, k) ≥ χ(R∗, k).\nThis assumption says that any position k is least examined if the first k − 1 items are optimal. Both the CM and PBM satisfy this assumption. In the CM, the inequality follows from the definition of examination in (2). In the PBM, we have that χ(R, k) = χ(R∗, k).\n4. Algorithm BatchRank The design of BatchRank (Algorithm 1) builds on two key ideas. First, we randomize the placement of items to avoid\nAlgorithm 1 BatchRank 1: // Initialization 2: for b = 1, . . . , 2K do 3: for ` = 0, . . . , T − 1 do 4: for all d ∈ D do 5: cb,`(d)← 0, nb,`(d)← 0\n6: A ← {1} , bmax ← 1 7: I1 ← (1,K), B1,0 ← D, `1 ← 0 8: for t = 1, . . . , T do 9: for all b ∈ A do\n10: DisplayBatch(b, t) 11: for all b ∈ A do 12: CollectClicks(b, t) 13: for all b ∈ A do 14: UpdateBatch(b, t)\nbiases due to the click model. Second, we divide and conquer; recursively divide the batches of items into more and less attractive items. The result is a sorted list of K items, where the k-th most attractive item is placed at position k.\nBatchRank explores items in batches, which are indexed by integers b > 0. A batch b is associated with the initial set of items Bb,0 ⊆ D and a range of positions Ib ∈ [K]2, where Ib(1) is the highest position in batch b, Ib(2) is the lowest position in batch b, and len(b) = Ib(2)− Ib(1) + 1 is number of positions in batch b. The batch is explored in stages, which we index by integers ` > 0. The remaining items in stage ` of batch b areBb,` ⊆ Bb,0. The lengths of the stages quadruple. More precisely, any item d ∈ Bb,` in stage ` is explored n` times, where n` = ⌈ 16∆̃−2` log T\n⌉ and ∆̃` = 2−`. The current stage of batch b is `b.\nMethod DisplayBatch (Algorithm 2) explores batches as follows. In stage ` of batch b, we randomly choose len(b) least observed items in Bb,` and display them at randomly chosen positions in Ib. If the number of these items is less than len(b), we mix them with randomly chosen more observed items, which are not explored. This exploration has two notable properties. First, it is uniform in the sense that no item in Bb,` is explored more than once than any other item in Bb,`. Second, any item in Bb,` appears in any list over Bb,` with that item with the same probability. This is critical to avoid biases due to click models.\nMethod CollectClicks (Algorithm 3) collects feedback. We denote the number of observations of item d in stage ` of batch b by nb,`(d) and the number of clicks on that item by cb,`(d). At the end of the stage, all items d ∈ Bb,` are observed exactly n` times and we estimate the probability of clicking on item d as\nĉb,`(d) = cb,`(d)/n` . (6)\nAlgorithm 2 DisplayBatch 1: Input: batch index b, time t\n2: `← `b, nmin ← mind∈Bb,` nb,`(d) 3: Let d1, . . . , d|Bb,`| be a random permutation of items Bb,` such that nb,`(d1) ≤ . . . ≤ nb,`(d|Bb,`|) 4: Let π ∈ Πlen(b)([len(b)]) be a random permutation of position assignments 5: for k = Ib(1), . . . , Ib(2) do 6: dtk ← dπ(k−Ib(1)+1)\nAlgorithm 3 CollectClicks 1: Input: batch index b, time t\n2: `← `b, nmin ← mind∈Bb,` nb,`(d) 3: for k = Ib(1), . . . , Ib(2) do 4: if nb,`(dtk) = nmin then 5: cb,`(dtk)← cb,`(dtk) + ct(k) 6: nb,`(dtk)← nb,`(dtk) + 1\nMethod UpdateBatch (Algorithm 4) updates batches and has three main parts. First, we compute KL-UCB upper and lower confidence bounds (Garivier & Cappe, 2011) for all items d ∈ Bb,` (lines 5–6),\nUb,`(d)← arg max q∈[ĉb,`(d), 1] {n`DKL(ĉb,`(d) ‖ q) ≤ δT } ,\nLb,`(d)← arg min q∈[0, ĉb,`(d)] {n`DKL(ĉb,`(d) ‖ q) ≤ δT } ,\nwhere DKL(p ‖ q) denotes the Kullback-Leibler divergence between Bernoulli random variables with means p and q, and δT = log T + 3 log log T . Then we test whether batch b can be safely divided into s more attractive items and the rest (lines 7–15). If it can, we split the batch into two new batches (lines 21–27). The first batch contains s items and is over positions Ib(1), . . . , Ib(1) + s − 1; and the second batch contains the remaining items and is over the remaining positions. The stage indices of new batches are initialized to 0. If the batch can be divided at multiple positions s, we choose the highest s. If the batch is not divided, we eliminate items that cannot be at position Ib(2) or higher with a high probability (lines 17–19).\nThe set of active batches is denoted by A, and we explore and update these batches in parallel. The highest index of the latest added batch is bmax. Note that bmax ≤ 2K, because any batch with at least two items is split at a unique position into two batches. BatchRank is initialized with a single batch over all positions and items (lines 6–7).\nNote that by the design of UpdateBatch, the following invariants hold. First, the positions of active batches A are a partition of [K] at any time t. Second, any batch contains at least as many items as is the number of the positions in\nAlgorithm 4 UpdateBatch 1: Input: batch index b, time t\n2: // End-of-stage elimination 3: `← `b 4: if mind∈Bb,` nb,`(d) = n` then 5: for all d ∈ Bb,` do 6: Compute Ub,`(d) and Lb,`(d) 7: Let d1, . . . , d|Bb,`| be any permutation of itemsBb,` such that Lb,`(d1) ≥ . . . ≥ Lb,`(d|Bb,`|) 8: for k = 1, . . . , len(b) do 9: B+k ← {d1, . . . , dk}\n10: B−k ← Bb,` \\B + k\n11: // Find a split at the position with the highest index 12: s← 0 13: for k = 1, . . . , len(b)− 1 do 14: if Lb,`(dk) > maxd∈B−k Ub,`(d) then 15: s← k 16: if (s = 0) and (|Bb,`| > len(b)) then 17: // Next elimination stage 18: Bb,`+1 ← { d ∈ Bb,` : Ub,`(d) ≥ Lb,`(dlen(b))\n}"
    }, {
      "heading" : "19: `b ← `b + 1",
      "text" : "20: else if s > 0 then 21: // Split 22: A ← A∪ {bmax + 1, bmax + 2} \\ {b} 23: Ibmax+1 ← (Ib(1), Ib(1) + s− 1) 24: Bbmax+1,0 ← B+s , `bmax+1 ← 0 25: Ibmax+2 ← (Ib(1) + s, Ib(2)) 26: Bbmax+2,0 ← B−s , `bmax+2 ← 0 27: bmax ← bmax + 2\nthat batch. Finally, when Ib(2) < K, the number of items in batch b is equal to the number of its positions."
    }, {
      "heading" : "5. Analysis",
      "text" : "In this section, we state our regret bound for BatchRank. Before we do so, we discuss our estimator of clicks in (6). In particular, we show that (6) is the attraction probability of item d scaled by the average examination probability in stage ` of batch b. The examination scaling preserves the order of attraction probabilities, and therefore BatchRank can operate on (6) in place of α(d)."
    }, {
      "heading" : "5.1. Confidence Radii",
      "text" : "Fix batch b, positions Ib, stage `, and items Bb,`. Then for any item d ∈ Bb,`, we can write the estimator in (6) as\nĉb,`(d) = 1\nn` ∑ t∈T Ib(2)∑ k=Ib(1) ct(k)1 { dtk = d } (7)\nfor some set of n` time steps T and its expected value is\nc̄b,`(d) = E [ĉb,`(d)] . (8)\nThe key step in the design of BatchRank is that we maintain confidence radii around (7). This is sound because the observations in (7),\n{Xt(Rt, k)At(d)}t∈{t∈T :dtk=d} (9)\nat any position k, are i.i.d. in time. More precisely, by the design of DisplayBatch, all displayed items from batch b are chosen randomly from Bb,`; and independently of the realizations ofXt(Rt, k) andAt(d), which are random as well. The last problem is that the policy for placing items at positions 1, . . . , Ib(1) − 1 can change independently of batch b because BatchRank splits batches independently. But this has no effect on Xt(Rt, k) because the examination of position k does not depend on the order of higher ranked items (Assumption 3)."
    }, {
      "heading" : "5.2. Correct Examination Scaling",
      "text" : "Fix batch b, positions Ib, stage `, and itemsBb,`. Since the examination of a position does not depend on the order of higher ranked items, and does not depend on lower ranked items at all (Assumption 3), we can express the probability of clicking on any item d ∈ Bb,` in (7) as\nc̄b,`(d) = α(d) |Sd| ∑ R∈Sd Ib(2)∑ k=Ib(1) χ(R, k)1{dk = k} , (10)\nwhere Sd = { (e1, . . . , eIb(2)) : d ∈ { eIb(1), . . . , eIb(2) } ,\n(eIb(1), . . . , eIb(2)) ∈ Πlen(b)(Bb,`) }\nis the set of all lists with permutations ofBb,` on positions Ib that contain item d, for some fixed higher ranked items e1, . . . , eIb(1)−1 /∈ Bb,`. Let d∗ ∈ Bb,` be any item such that α(d∗) ≥ α(d), and c̄b,`(d∗) and Sd∗ be defined analogously to c̄b,`(d) and Sd above. Then we argue that\nc̄b,`(d ∗)/α(d∗) ≥ c̄b,`(d)/α(d) , (11)\nthe examination scaling of a less attractive item d is never higher than that of a more attractive item d∗.\nBefore we prove (11), note that for any list R ∈ Sd, there exists one and only one list in Sd∗ that differs fromR only in that items d and d∗ are exchanged. Let this list be R∗. We analyze three cases. First, suppose that list R does not contain item d∗. Then by Assumption 3, the examination probabilities of d inR and d∗ inR∗ are the same. Second, let item d∗ be ranked higher than item d in R. Then by Assumption 5, the examination probability of d inR is not higher than that of d∗ in R∗. Third, let item d∗ be ranked lower than item d in R. Then by Assumption 3, the examination probabilities of d in R and d∗ in R∗ are the same, since they do not depend on lower ranked items. Finally, from the definition in (10) and that |Sd| = |Sd∗ |, we have that (11) holds."
    }, {
      "heading" : "5.3. Regret Bound",
      "text" : "For simplicity of exposition, let α(1) > . . . > α(L) > 0. Let αmax = α(1), and χ∗(k) = χ(R∗, k) for all k ∈ [K]. The regret of BatchRank is bounded below.\nTheorem 1. For any stochastic click bandit in Section 3.1 that satisfies Assumptions 1 to 6 and T ≥ 5, the expected T -step regret of BatchRank is bounded as\nR(T ) ≤ 192K 3L\n(1− αmax)∆min log T + 4KL(3e+K) ,\nwhere ∆min = mink∈[K] {α(k)− α(k + 1)}.\nProof. The key idea is to bound the expected T -step regret in any batch (Lemma 7 in Appendix). Since the number of batches is at most 2K, the regret of BatchRank is at most 2K times larger than that of in any batch.\nThe regret in a batch is bounded as follows. Let all confidence intervals hold, Ib be the positions of batch b, and the maximum gap in batch b be\n∆max = maxd∈{Ib(1),...,Ib(2)−1}[α(d)− α(d+ 1)] .\nIf the gap of item d in batch b is O(K∆max), its regret is dominated by the time that the batch splits, and we bound this time in Lemma 6 in Appendix. Otherwise, the item is likely to be eliminated before the split, and we bound this time in Lemma 5 in Appendix. Now take the maximum of these upper bounds."
    }, {
      "heading" : "5.4. Discussion",
      "text" : "Our upper bound in Theorem 1 is logarithmic in the number of steps T , linear in the number of items L, and polynomial in the number of positions K. To the best of our knowledge, this is the first gap-dependent upper bound on the regret of a learning algorithm that has sublinear regret in both the CM and PBM. The gap ∆min characterizes the hardness of sorting K + 1 most attractive items, which is sufficient for solving our problem. In practice, the maximum attraction probability αmax is bounded away from 1. Therefore, the dependence on (1− αmax)−1 is not critical. For instance, in most queries in Section 6, αmax ≤ 0.9.\nWe believe that the cubic dependence on K is not far from being optimal. In particular, consider the problem of learning the most clicked item-position pair in the PBM (Section 2.1), which is easier than our problem. This problem can be solved as a stochastic rank-1 bandit (Katariya et al., 2017b) by Rank1Elim. Now consider the following PBM. The examination probability of the first position is close to one and the examination probabilities of all other positions are close to zero. Then the T -step regret of Rank1Elim is\nO([K3 + K2L∆−1min] log T ) because µ = O(1/K), where µ is defined in Katariya et al. (2017b). Note that the gapdependent term nearly matches our upper bound.\nThe KL confidence intervals in BatchRank are necessary to achieve sample efficiency. The reason is, as we prove in Lemma 9 in Appendix, that\nχ(1−m)DKL(α ‖α∗) ≤ DKL(χα ‖χα∗)\nfor any χ, α, α∗ ∈ [0, 1] and m = max {α, α∗}. This implies that any two items with the expected rewards of χα and χα∗ can be distinguished inO(χ−1(α∗−α)−2) observations for any scaling factor χ, when m is bounded away from 1. Suppose that α < α∗. Then the expected per-step regret for choosing the suboptimal item is χ(α∗ − α), and the expected cumulative regret is O((α∗ − α)−1). The key observation is that the regret is independent of χ. This is a major improvement over UCB1 confidence intervals, which only lead to O(χ−1(α∗ − α)−1) regret. Because χ can be exponentially small, such a dependence is undesirable.\nThe elimination of items in UpdateBatch (lines 17–19) is necessary. The regret of BatchRank would be quadratic in L otherwise."
    }, {
      "heading" : "6. Experiments",
      "text" : "We experiment with the Yandex dataset (Yandex), a dataset of 35 million (M) search sessions, each of which may contain multiple search queries. Each query is associated with displayed documents at positions 1 to 10 and their clicks. We select 60 frequent search queries, and learn their CMs and PBMs using PyClick (Chuklin et al., 2015), which is an open-source library of click models for web search. In each query, our goal it to rerank L = 10 most attractive items with the objective of maximizing the expected number of clicks at the first K = 5 positions. This resembles a real-world setting, where the learning agent would only be allowed to rerank highly attractive items, and not allowed to explore unattractive items (Zoghi et al., 2016).\nBatchRank is compared to two methods, CascadeKL-UCB (Kveton et al., 2015a) and RankedExp3 (Radlinski et al., 2008a). CascadeKL-UCB is an optimal algorithm for learning to rank in the cascade model. RankedExp3 is a variant of ranked bandits (Section 7) where the base bandit algorithm is Exp3 (Auer et al., 1995). This approach is popular in practice and does not make any independence assumptions on the attractions of items.\nMany solutions in our queries are near optimal, and therefore the optimal solutions are hard to learn. Therefore, we decided to evaluate the performance of algorithms by their expected per-step regret, in up to 10M steps. If a solution is suboptimal and does not improve over time, its expected per-step regret remains constant and is bounded away from\nzero, and this can be easily observed even if the gap of the solution is small. We expect this when CascadeKL-UCB is applied to the PBM because CascadeKL-UCB has no guarantees in this model. The reported regret is averaged over periods of 100k steps to reduce randomness.\nWe report the performance of all compared algorithms on two CMs and one PBM in Figure 1. The plots are chosen to represent general trends in this experiment. In the CM, CascadeKL-UCB performs very well on most queries. This is not surprising since CascadeKL-UCB is designed for the CM. BatchRank often learns the optimal solution quickly (Figure 1a), but sometimes this requires close to T = 10M steps (Figure 1b). In the PBM, CascadeKL-UCB may converge to a suboptimal solution. Then its expected per-step regret remains constant and even RankedExp3 can learn a better solution over time (Figure 1c). We also observe that BatchRank outperforms RankedExp3 in all experiments.\nWe report the average performance of all compared algorithms in both click models in Figure 2. These trends confirm our earlier findings. In the CM, CascadeKL-UCB outperforms BatchRank; while in the PBM, BatchRank outperforms CascadeKL-UCB at T = 2M steps. The regret of CascadeKL-UCB in the PBM flattens and is bounded away from zero. This trend can be explained by the histograms in Figure 2. They show that CascadeKL-UCB converges to suboptimal solutions, whose regret is at least 10−3, in one sixth of its runs. The performance of BatchRank is more robust and we do not observe many runs whose regret is of that magnitude.\nWe are delighted with the performance of BatchRank. Although it is not designed to be optimal (Section 5.4), it is more robust than CascadeKL-UCB and clearly outperforms RankedExp3. The performance of CascadeKL-UCB is unexpectedly good. Although it does not have guarantees in the PBM, it performs very well on many queries. We plan to investigate this in our future work."
    }, {
      "heading" : "7. Related Work",
      "text" : "A popular approach to online learning to rank are ranked bandits (Radlinski et al., 2008a; Slivkins et al., 2013). The key idea in ranked bandits is to model each position in the recommended list as an individual bandit problem, which is then solved by a base bandit algorithm. This algorithm is typically adversarial (Auer et al., 1995) because the distribution of clicks on lower positions is affected by higher positions. We compare to ranked bandits in Section 6.\nOnline learning to rank in click models (Craswell et al., 2008; Chuklin et al., 2015) was recently studied in several papers (Kveton et al., 2015a; Combes et al., 2015; Kveton et al., 2015b; Katariya et al., 2016; Zong et al., 2016; Li et al., 2016; Lagree et al., 2016). In all of these papers, the\nattraction probabilities of items are estimated from clicks and the click model. The learning agent has no guarantees beyond this model.\nThe problem of finding the most clicked item-position pair in the PBM, which is arguably easier than our problem of finding K most clicked item-position pairs, can be solved as a stochastic rank-1 bandit (Katariya et al., 2017b;a). We discuss our relation to these works in Section 5.4.\nOur problem can be also viewed as an instance of partial monitoring, where the attraction indicators of items are unobserved. General partial-monitoring algorithms (Agrawal et al., 1989; Bartok et al., 2012; Bartok & Szepesvari, 2012; Bartok et al., 2014) are unsuitable for our setting because their computational complexity is polynomial in the number of actions, which is exponential in K.\nThe click model is a model of how the user interacts with a list of documents (Chuklin et al., 2015), and many such models have been proposed (Becker et al., 2007; Richardson et al., 2007; Craswell et al., 2008; Chapelle & Zhang, 2009; Guo et al., 2009a;b). Two fundamental click models are the CM (Craswell et al., 2008) and PBM (Richardson et al., 2007). These models have been traditionally studied separately. In this work, we show that learning to rank problems in these models can be solved by the same algorithm, under reasonable assumptions."
    }, {
      "heading" : "8. Conclusions",
      "text" : "We propose stochastic click bandits, a framework for online learning to rank in a broad class of click models that encompasses two most fundamental click models, the cascade and position-based models. In addition, we propose a computationally and sample efficient algorithm for solving our problems, BatchRank, and derive an upper bound on its T -step regret. Finally, we evaluate BatchRank on web search queries. Our algorithm outperforms ranked bandits (Radlinski et al., 2008a), a popular online learning to rank approach; and is more robust than CascadeKL-UCB (Kveton et al., 2015a), an existing algorithm for online learning to rank in the cascade model.\nThe goal of this work is not to propose the optimal algorithm for our setting, but to demonstrate that online learning to rank in multiple click models is possible with theoretical guarantees. We strongly believe that the design of BatchRank, as well as its analysis, can be improved. For instance, BatchRank resets its estimators of clicks in each batch, which is wasteful. In addition, based on the discussion in Section 5.4, our analysis may be loose by a factor of K. We hope that the practically relevant setting, which is introduced in this paper, will spawn new enthusiasm in the community and lead to more work in this area."
    }, {
      "heading" : "A. Notation",
      "text" : "Symbol Definition α(d) Attraction probability of item d αmax Highest attraction probability, α(1) A Binary attraction vector, where A(d) is the attraction indicator of item d Pα Distribution over binary attraction vectors A Set of active batches bmax Index of the last created batch Bb,` Items in stage ` of batch b ct(k) Indicator of the click on position k at time t cb,`(d) Number of observed clicks on item d in stage ` of batch b ĉb,`(d) Estimated probability of clicking on item d in stage ` of batch b c̄b,`(d) Probability of clicking on item d in stage ` of batch b, E [ĉb,`(d)] D Ground set of items [L] such that α(1) ≥ . . . ≥ α(L) δT log T + 3 log log T\n∆̃` 2 −`\nIb Interval of positions in batch b K Number of positions to display items len(b) Number of positions to display items in batch b L Number of items Lb,`(d) Lower confidence bound of item d, in stage ` of batch b n` Number of times that each item is observed in stage ` nb,` Number of observations of item d in stage ` of batch b ΠK(D) Set of all K-tuples with distinct elements from D r(R, A,X) Reward of listR, for attraction and examination indicators A and X r(R, α, χ) Expected reward of listR R = (d1, . . . , dK) List of K items, where dk is the k-th item inR R∗ = (1, . . . ,K) Optimal list of K items R(R, A,X) Regret of listR, for attraction and examination indicators A and X R(T ) Expected cumulative regret in T steps T Horizon of the experiment Ub,`(d) Upper confidence bound of item d, in stage ` of batch b χ(R, k) Examination probability of position k in listR χ∗(k) Examination probability of position k in the optimal listR∗\nX Binary examination matrix, where X(R, k) is the examination indicator of position k in listR Pχ Distribution over binary examination matrices"
    }, {
      "heading" : "B. Proof of Theorem 1",
      "text" : "Let Rb,` be the stochastic regret associated with stage ` of batch b. Then the expected T -step regret of MergeRank can be decomposed as\nR(T ) ≤ E [ 2K∑ b=1 T−1∑ `=0 Rb,` ]\nbecause the maximum number of batches is 2K. Let\nχ̄b,`(d) = c̄b,`(d)\nα(d) (12)\nbe the average examination probability of item d in stage ` of batch b. Let Eb,` = { Event 1: ∀d ∈ Bb,` : c̄b,`(d) ∈ [Lb,`(d),Ub,`(d)] ,\nEvent 2: ∀Ib ∈ [K]2, d ∈ Bb,`, d∗ ∈ Bb,` ∩ [K] s.t. ∆ = α(d∗)− α(d) > 0 :\nn` ≥ 16K\nχ∗(Ib(1))(1− αmax)∆2 log T =⇒ ĉb,`(d) ≤ χ̄b,`(d)[α(d) + ∆/4] ,\nEvent 3: ∀Ib ∈ [K]2, d ∈ Bb,`, d∗ ∈ Bb,` ∩ [K] s.t. ∆ = α(d∗)− α(d) > 0 :\nn` ≥ 16K\nχ∗(Ib(1))(1− αmax)∆2 log T =⇒ ĉb,`(d∗) ≥ χ̄b,`(d∗)[α(d∗)−∆/4] } be the “good event” in stage ` of batch b, where c̄b,`(d) is the probability of clicking on item d in stage ` of batch b, which is defined in (8); ĉb,`(d) is its estimate, which is defined in (7); and both χ∗ and αmax are defined in Section 5.3. Let Eb,` be the complement of event Eb,`. Let E be the “good event” that all events Eb,` happen; and E be its complement, the “bad event” that at least one event Eb,` does not happen. Then the expected T -step regret can be bounded from above as\nR(T ) ≤ E [ 2K∑ b=1 T−1∑ `=0 Rb,`1{E} ] + TP (E) ≤ 2K∑ b=1 E [ T−1∑ `=0 Rb,`1{E} ] + 4KL(3e+K) ,\nwhere the second inequality is from Lemma 2. Now we apply Lemma 7 to each batch b and get that\n2K∑ b=1 E [ T−1∑ `=0 Rb,`1{E} ] ≤ 192K 3L (1− αmax)∆min log T .\nThis concludes our proof."
    }, {
      "heading" : "C. Upper Bound on the Probability of Bad Event E",
      "text" : "Lemma 2. Let E be defined as in the proof of Theorem 1 and T ≥ 5. Then\nP (E) ≤ 4KL(3e+K) T .\nProof. By the union bound,\nP (E) ≤ 2K∑ b=1 T−1∑ `=0 P (Eb,`) .\nNow we bound the probability of each event in Eb,` and then sum them up.\nEvent 1\nThe probability that event 1 in Eb,` does not happen is bounded as follows. Fix Ib andBb,`. For any d ∈ Bb,`,\nP (c̄b,`(d) /∈ [Lb,`(d),Ub,`(d)]) ≤ P (c̄b,`(d) < Lb,`(d)) + P (c̄b,`(d) > Ub,`(d)) ≤ 2e ⌈ log(T log3 T ) log n` ⌉ T log3 T\n≤ 2e ⌈ log2 T + log(log3 T ) log T ⌉ T log3 T\n≤ 2e ⌈ 2 log2 T ⌉ T log3 T\n≤ 6e T log T ,\nwhere the second inequality is by Theorem 10 of Garivier & Cappe (2011), the third inequality is from T ≥ n`, the fourth inequality is from log(log3 T ) ≤ log T for T ≥ 5, and the last inequality is from ⌈ 2 log2 T ⌉ ≤ 3 log2 T for T ≥ 3. By the union bound,\nP (∃d ∈ Bb,` s.t. c̄b,`(d) /∈ [Lb,`(d),Ub,`(d)]) ≤ 6eL\nT log T\nfor any Bb,`. Finally, since the above inequality holds for any Bb,`, the probability that event 1 in Eb,` does not happen is bounded as above.\nEvent 2\nThe probability that event 2 in Eb,` does not happen is bounded as follows. Fix Ib andBb,`, and let k = Ib(1). If the event does not happen for items d and d∗, then it must be true that\nn` ≥ 16K\nχ∗(k)(1− αmax)∆2 log T , ĉb,`(d) > χ̄b,`(d)[α(d) + ∆/4] .\nFrom the definition of the average examination probability in (12) and a variant of Hoeffding’s inequality in Lemma 8, we have that\nP (ĉb,`(d) > χ̄b,`(d)[α(d) + ∆/4]) ≤ exp [−n`DKL(χ̄b,`(d)[α(d) + ∆/4] ‖ c̄b,`(d))] .\nFrom Lemma 9, χ̄b,`(d) ≥ χ∗(k)/K (Lemma 3), and Pinsker’s inequality, we have that\nexp [−n`DKL(χ̄b,`(d)[α(d) + ∆/4] ‖ c̄b,`(d))] ≤ exp [−n`χ̄b,`(d)(1− αmax)DKL(α(d) + ∆/4 ‖α(d))] ≤ exp [ −n` χ∗(k)(1− αmax)∆2\n8K\n] .\nFrom our assumption on n`, we conclude that\nexp [ −n` χ∗(k)(1− αmax)∆2\n8K\n] ≤ exp[−2 log T ] = 1\nT 2 .\nFinally, we chain all above inequalities and get that event 2 in Eb,` does not happen for any fixed Ib, Bb,`, d, and d∗ with probability of at most T−2. Since the maximum numbers of items d and d∗ are L and K, respectively, the event does not happen for any fixed Ib and Bb,` with probability of at most KLT−2. In turn, the probability that event 2 in Eb,` does not happen is bounded by KLT−2.\nEvent 3\nThis bound is analogous to that of event 2.\nTotal probability\nThe maximum number of stages in any batch in BatchRank is log T and the maximum number of batches is 2K. Hence, by the union bound,\nP (E) ≤ ( 6eL\nT log T + KL T 2 + KL T 2\n) (2K log T ) ≤ 4KL(3e+K)\nT .\nThis concludes our proof."
    }, {
      "heading" : "D. Upper Bound on the Regret in Individual Batches",
      "text" : "Lemma 3. For any batch b, positions Ib, stage `, setBb,`, and item d ∈ Bb,`,\nχ∗(k)\nK ≤ χ̄b,`(d) ,\nwhere k = Ib(1) is the highest position in batch b.\nProof. The proof follows from two observations. First, by Assumption 6, χ∗(k) is the lowest examination probability of position k. Second, by the design of DisplayBatch, item d is placed at position k with probability of at least 1/K.\nLemma 4. Let event E happen and T ≥ 5. For any batch b, positions Ib, set Bb,0, item d ∈ Bb,0, and item d∗ ∈ Bb,0 ∩ [K] such that ∆ = α(d∗)− α(d) > 0, let k = Ib(1) be the highest position in batch b and ` be the first stage where\n∆̃` <\n√ χ∗(k)(1− αmax)\nK ∆ .\nThen Ub,`(d) < Lb,`(d∗).\nProof. From the definition of n` in BatchRank and our assumption on ∆̃`,\nn` ≥ 16\n∆̃2` log T >\n16K\nχ∗(k)(1− αmax)∆2 log T . (13)\nLet µ = χ̄b,`(d) and suppose that Ub,`(d) ≥ µ[α(d) + ∆/2] holds. Then from this assumption, the definition of Ub,`(d), and event 2 in Eb,`,\nDKL(ĉb,`(d) ‖Ub,`(d)) ≥ DKL(ĉb,`(d) ‖µ[α(d) + ∆/2])1{ĉb,`(d) ≤ µ[α(d) + ∆/2]} ≥ DKL(µ[α(d) + ∆/4] ‖µ[α(d) + ∆/2]) .\nFrom Lemma 9, µ ≥ χ∗(k)/K (Lemma 3), and Pinsker’s inequality, we have that\nDKL(µ[α(d) + ∆/4] ‖µ[α(d) + ∆/2]) ≥ µ(1− αmax)DKL(α(d) + ∆/4 ‖α(d) + ∆/2)\n≥ χ ∗(k)(1− αmax)∆2\n8K .\nFrom the definition of Ub,`(d), T ≥ 5, and above inequalities,\nn` = log T + 3 log log T DKL(ĉb,`(d) ‖Ub,`(d)) ≤ 2 log T DKL(ĉb,`(d) ‖Ub,`(d)) ≤ 16K log T χ∗(k)(1− αmax)∆2 .\nThis contradicts to (13), and therefore it must be true that Ub,`(d) < µ[α(d) + ∆/2] holds.\nOn the other hand, let µ∗ = χ̄b,`(d∗) and suppose that Lb,`(d∗) ≤ µ∗[α(d∗) − ∆/2] holds. Then from this assumption, the definition of Lb,`(d∗), and event 3 in Eb,`,\nDKL(ĉb,`(d ∗) ‖Lb,`(d∗)) ≥ DKL(ĉb,`(d∗) ‖µ∗[α(d∗)−∆/2])1{ĉb,`(d∗) ≥ µ∗[α(d∗)−∆/2]}\n≥ DKL(µ∗[α(d∗)−∆/4] ‖µ∗[α(d∗)−∆/2]) .\nFrom Lemma 9, µ∗ ≥ χ∗(k)/K (Lemma 3), and Pinsker’s inequality, we have that\nDKL(µ ∗[α(d∗)−∆/4] ‖µ∗[α(d∗)−∆/2]) ≥ µ∗(1− αmax)DKL(α(d∗)−∆/4 ‖α(d∗)−∆/2)\n≥ χ ∗(k)(1− αmax)∆2\n8K .\nFrom the definition of Lb,`(d∗), T ≥ 5, and above inequalities,\nn` = log T + 3 log log T DKL(ĉb,`(d) ‖Lb,`(d∗)) ≤ 2 log T DKL(ĉb,`(d∗) ‖Lb,`(d∗)) ≤ 16K log T χ∗(k)(1− αmax)∆2 .\nThis contradicts to (13), and therefore it must be true that Lb,`(d∗) > µ∗[α(d∗)−∆/2] holds.\nFinally, based on inequality (11),\nµ∗ = c̄b,`(d\n∗)\nα(d∗) ≥ c̄b,`(d) α(d) = µ ,\nand item d is guaranteed to be eliminated by the end of stage ` because\nUb,`(d) < µ[α(d) + ∆/2]\n≤ µα(d) + µ ∗α(d∗)− µα(d)\n2\n= µ∗α(d∗)− µ ∗α(d∗)− µα(d) 2 ≤ µ∗[α(d∗)−∆/2] < Lb,`(d ∗) .\nThis concludes our proof.\nLemma 5. Let event E happen and T ≥ 5. For any batch b, positions Ib where Ib(2) = K, set Bb,0, and item d ∈ Bb,0 such that d > K, let k = Ib(1) be the highest position in batch b and ` be the first stage where\n∆̃` <\n√ χ∗(k)(1− αmax)\nK ∆\nfor ∆ = α(K)− α(d). Then item d is eliminated by the end of stage `.\nProof. Let B+ = {k, . . . ,K}. Now note that α(d∗)− α(d) ≥ ∆ for any d∗ ∈ B+. By Lemma 4, Lb,`(d∗) > Ub,`(d) for any d∗ ∈ B+; and therefore item d is eliminated by the end of stage `.\nLemma 6. Let E happen and T ≥ 5. For any batch b, positions Ib, and set Bb,0, let k = Ib(1) be the highest position in batch b and ` be the first stage where\n∆̃` <\n√ χ∗(k)(1− αmax)\nK ∆max\nfor ∆max = α(s)− α(s+ 1) and s = arg max d∈{Ib(1),...,Ib(2)−1} [α(d)− α(d+ 1)]. Then batch b is split by the end of stage `.\nProof. Let B+ = {k, . . . , s} and B− = Bb,0 \\ B+. Now note that α(d∗) − α(d) ≥ ∆max for any (d∗, d) ∈ B+ × B−. By Lemma 4, Lb,`(d∗) > Ub,`(d) for any (d∗, d) ∈ B+ ×B−; and therefore batch b is split by the end of stage `.\nLemma 7. Let event E happen and T ≥ 5. Then the expected T -step regret in any batch b is bounded as\nE [ T−1∑ `=0 Rb,` ] ≤ 96K 2L (1− αmax)∆max log T .\nProof. Let k = Ib(1) be the highest position in batch b. Choose any item d ∈ Bb,0 and let ∆ = α(k)− α(d).\nFirst, we show that the expected per-step regret of any item d is bounded by χ∗(k)∆ when event E happens. Since event E happens, all eliminations and splits up to any stage ` of batch b are correct. Therefore, items 1, . . . , k − 1 are at positions 1, . . . , k − 1; and position k is examined with probability χ∗(k). Note that this is the highest examination probability in batch b (Assumption 4). Our upper bound follows from the fact that the reward is linear in individual items (Section 3.1).\nWe analyze two cases. First, suppose that ∆ ≤ 2K∆max for ∆max in Lemma 6. Then by Lemma 6, batch b splits when the number of steps in a stage is at most\n16K\nχ∗(k)(1− αmax)∆2max log T .\nBy the design of DisplayBatch, any item in stage ` of batch b is displayed at most 2n` times. Therefore, the maximum regret due to item d in the last stage before the split is\n32Kχ∗(k)∆\nχ∗(k)(1− αmax)∆2max log T ≤ 64K 2∆max (1− αmax)∆2max log T = 64K2 (1− αmax)∆max log T .\nNow suppose that ∆ > 2K∆max. This implies that item d is easy to distinguish from item K. In particular,\nα(K)− α(d) = ∆− (α(k)− α(K)) ≥ ∆−K∆max ≥ ∆\n2 ,\nwhere the equality is from the identity\n∆ = α(k)− α(d) = α(k)− α(K) + α(K)− α(d) ;\nthe first inequality is from α(k)− α(K) ≤ K∆max, which follows from the definition of ∆max and k ∈ [K]; and the last inequality is from our assumption that K∆max < ∆/2. Now we apply the derived inequality and, by Lemma 5 and from the design of DisplayBatch, the maximum regret due to item d in the stage where that item is eliminated is\n32Kχ∗(k)∆\nχ∗(k)(1− αmax)(α(K)− α(d))2 log T ≤ 128K (1− αmax)∆ log T ≤ 64 (1− αmax)∆max log T .\nThe last inequality is from our assumption that ∆ > 2K∆max.\nBecause the lengths of the stages quadruple and BatchRank resets all click estimators at the beginning of each stage, the maximum expected regret due to any item d in batch b is at most 1.5 times higher than that in the last stage, and hence\nE [ T−1∑ `=0 Rb,` ] ≤ 96K 2 |Bb,0| (1− αmax)∆max log T .\nThis concludes our proof."
    }, {
      "heading" : "E. Technical Lemmas",
      "text" : "Lemma 8. Let (X1)ni=1 be n i.i.d. Bernoulli random variables, µ̄ = ∑n i=1Xi, and µ = E [µ̄]. Then\nP (µ̄ ≥ µ+ ε) ≤ exp[−nDKL(µ+ ε ‖µ)]\nfor any ε ∈ [0, 1− µ], and\nP (µ̄ ≤ µ− ε) ≤ exp[−nDKL(µ− ε ‖µ)]\nfor any ε ∈ [0, µ].\nProof. We only prove the first claim. The other claim follows from symmetry.\nFrom inequality (2.1) of Hoeffding (1963), we have that\nP (µ̄ ≥ µ+ ε) ≤\n[( µ\nµ+ ε\n)µ+ε( 1− µ\n1− (µ+ ε) )1−(µ+ε)]n for any ε ∈ [0, 1− µ]. Now note that[(\nµ\nµ+ ε\n)µ+ε( 1− µ\n1− (µ+ ε)\n)1−(µ+ε)]n = exp [ n [ (µ+ ε) log µ\nµ+ ε + (1− (µ+ ε)) log 1− µ 1− (µ+ ε) ]] = exp [ −n [ (µ+ ε) log µ+ ε\nµ + (1− (µ+ ε)) log 1− (µ+ ε) 1− µ ]] = exp[−nDKL(µ+ ε ‖µ)] .\nThis concludes the proof.\nLemma 9. For any c, p, q ∈ [0, 1],\nc(1−max {p, q})DKL(p ‖ q) ≤ DKL(cp ‖ cq) ≤ cDKL(p ‖ q) . (14)\nProof. The proof is based on differentiation. The first two derivatives of DKL(cp ‖ cq) with respect to q are\n∂\n∂q DKL(cp ‖ cq) = c(q − p) q(1− cq) , ∂2 ∂q2 DKL(cp ‖ cq) = c2(q − p)2 + cp(1− cp) q2(1− cq)2 ;\nand the first two derivatives of cDKL(p ‖ q) with respect to q are\n∂\n∂q [cDKL(p ‖ q)] = c(q − p) q(1− q) , ∂2 ∂q2 [cDKL(p ‖ q)] = c(q − p)2 + cp(1− p) q2(1− q)2 .\nThe second derivatives show that DKL(cp ‖ cq) and cDKL(p ‖ q) are convex in q for any p. Their minima are at q = p.\nNow we fix p and c, and prove (14) for any q. The upper bound is derived as follows. Since\nDKL(cp ‖ cx) = cDKL(p ‖x) = 0\nwhen x = p, the upper bound holds when cDKL(p ‖x) increases faster than DKL(cp ‖ cx) for any p < x ≤ q, and when cDKL(p ‖x) decreases faster than DKL(cp ‖ cx) for any q ≤ x < p. This follows from the definitions of ∂∂xDKL(cp ‖ cx) and ∂∂x [cDKL(p ‖x)]. In particular, both derivatives have the same sign and ∣∣ ∂ ∂xDKL(cp ‖ cx) ∣∣ ≤ ∣∣ ∂∂x [cDKL(p ‖x)]∣∣ for any feasible x ∈ [min {p, q} ,max {p, q}].\nThe lower bound is derived as follows. The ratio of ∂∂x [cDKL(p ‖x)] and ∂ ∂xDKL(cp ‖ cx) is bounded from above as\n∂ ∂x [cDKL(p ‖x)] ∂ ∂xDKL(cp ‖ cx) = 1− cx 1− x ≤ 1 1− x ≤ 1 1−max {p, q}\nfor any x ∈ [min {p, q} ,max {p, q}]. Therefore, we get a lower bound on DKL(cp ‖ cx) when we multiply cDKL(p ‖x) by 1−max {p, q}."
    } ],
    "references" : [ {
      "title" : "Improving web search ranking by incorporating user behavior information",
      "author" : [ "Agichtein", "Eugene", "Brill", "Eric", "Dumais", "Susan" ],
      "venue" : "In Proceedings of the 29th Annual International ACM SIGIR Conference,",
      "citeRegEx" : "Agichtein et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Agichtein et al\\.",
      "year" : 2006
    }, {
      "title" : "Asymptotically efficient adaptive allocation schemes for controlled i.i.d. processes: Finite parameter space",
      "author" : [ "Agrawal", "Rajeev", "Teneketzis", "Demosthenis", "Anantharam", "Venkatachalam" ],
      "venue" : "IEEE Transactions on Automatic Control,",
      "citeRegEx" : "Agrawal et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Agrawal et al\\.",
      "year" : 1989
    }, {
      "title" : "Gambling in a rigged casino: The adversarial multi-armed bandit problem",
      "author" : [ "Auer", "Peter", "Cesa-Bianchi", "Nicolo", "Freund", "Yoav", "Schapire", "Robert" ],
      "venue" : "In Proceedings of the 36th Annual Symposium on Foundations of Computer Science,",
      "citeRegEx" : "Auer et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Auer et al\\.",
      "year" : 1995
    }, {
      "title" : "Finite-time analysis of the multiarmed bandit problem",
      "author" : [ "Auer", "Peter", "Cesa-Bianchi", "Nicolo", "Fischer", "Paul" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Auer et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Auer et al\\.",
      "year" : 2002
    }, {
      "title" : "Partial monitoring with side information",
      "author" : [ "Bartok", "Gabor", "Szepesvari", "Csaba" ],
      "venue" : "In Proceedings of the 23rd International Conference on Algorithmic Learning Theory, pp",
      "citeRegEx" : "Bartok et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Bartok et al\\.",
      "year" : 2012
    }, {
      "title" : "An adaptive algorithm for finite stochastic partial monitoring",
      "author" : [ "Bartok", "Gabor", "Zolghadr", "Navid", "Szepesvari", "Csaba" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "Bartok et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Bartok et al\\.",
      "year" : 2012
    }, {
      "title" : "Partial monitoring - classification, regret bounds, and algorithms",
      "author" : [ "Bartok", "Gabor", "Foster", "Dean", "Pal", "David", "Rakhlin", "Alexander", "Szepesvari", "Csaba" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "Bartok et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bartok et al\\.",
      "year" : 2014
    }, {
      "title" : "Modeling contextual factors of click rates",
      "author" : [ "Becker", "Hila", "Meek", "Christopher", "Chickering", "David Maxwell" ],
      "venue" : "In Proceedings of the 22nd AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Becker et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Becker et al\\.",
      "year" : 2007
    }, {
      "title" : "A dynamic Bayesian network click model for web search ranking",
      "author" : [ "Chapelle", "Olivier", "Zhang", "Ya" ],
      "venue" : "In Proceedings of the 18th International Conference on World Wide Web,",
      "citeRegEx" : "Chapelle et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Chapelle et al\\.",
      "year" : 2009
    }, {
      "title" : "Click Models for Web Search",
      "author" : [ "Chuklin", "Aleksandr", "Markov", "Ilya", "de Rijke", "Maarten" ],
      "venue" : null,
      "citeRegEx" : "Chuklin et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chuklin et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning to rank: Regret lower bounds and efficient algorithms",
      "author" : [ "Combes", "Richard", "Magureanu", "Stefan", "Proutiere", "Alexandre", "Laroche", "Cyrille" ],
      "venue" : "In Proceedings of the 2015 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Sys-",
      "citeRegEx" : "Combes et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Combes et al\\.",
      "year" : 2015
    }, {
      "title" : "An experimental comparison of click positionbias models",
      "author" : [ "Craswell", "Nick", "Zoeter", "Onno", "Taylor", "Michael", "Ramsey", "Bill" ],
      "venue" : "In Proceedings of the 1st ACM International Conference on Web Search and Data Mining,",
      "citeRegEx" : "Craswell et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Craswell et al\\.",
      "year" : 2008
    }, {
      "title" : "The KL-UCB algorithm for bounded stochastic bandits and beyond",
      "author" : [ "Garivier", "Aurelien", "Cappe", "Olivier" ],
      "venue" : "In Proceeding of the 24th Annual Conference on Learning Theory, pp",
      "citeRegEx" : "Garivier et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Garivier et al\\.",
      "year" : 2011
    }, {
      "title" : "A comparative study of click models for web search",
      "author" : [ "Grotov", "Artem", "Chuklin", "Aleksandr", "Markov", "Ilya", "Stout", "Luka", "Xumara", "Finde", "de Rijke", "Maarten" ],
      "venue" : "In Proceedings of the 6th International Conference of the CLEF Association,",
      "citeRegEx" : "Grotov et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Grotov et al\\.",
      "year" : 2015
    }, {
      "title" : "Click chain model in web search",
      "author" : [ "Guo", "Fan", "Liu", "Chao", "Kannan", "Anitha", "Minka", "Tom", "Taylor", "Michael", "Wang", "Yi Min", "Faloutsos", "Christos" ],
      "venue" : "In Proceedings of the 18th International Conference on World Wide Web,",
      "citeRegEx" : "Guo et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2009
    }, {
      "title" : "Efficient multipleclick models in web search",
      "author" : [ "Guo", "Fan", "Liu", "Chao", "Wang", "Yi Min" ],
      "venue" : "In Proceedings of the 2nd ACM International Conference on Web Search and Data Mining, pp",
      "citeRegEx" : "Guo et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2009
    }, {
      "title" : "Probability inequalities for sums of bounded random variables",
      "author" : [ "Hoeffding", "Wassily" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Hoeffding and Wassily.,? \\Q1963\\E",
      "shortCiteRegEx" : "Hoeffding and Wassily.",
      "year" : 1963
    }, {
      "title" : "Reusing historical interaction data for faster online learning to rank for IR",
      "author" : [ "Hofmann", "Katja", "Schuth", "Anne", "Whiteson", "Shimon", "de Rijke", "Maarten" ],
      "venue" : "In Proceedings of the 6th ACM International Conference on Web Search and Data Mining,",
      "citeRegEx" : "Hofmann et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Hofmann et al\\.",
      "year" : 2013
    }, {
      "title" : "DCM bandits: Learning to rank with multiple clicks",
      "author" : [ "Katariya", "Sumeet", "Kveton", "Branislav", "Szepesvari", "Csaba", "Wen", "Zheng" ],
      "venue" : "In Proceedings of the 33rd International Conference on Machine Learning,",
      "citeRegEx" : "Katariya et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Katariya et al\\.",
      "year" : 2016
    }, {
      "title" : "Bernoulli rank-1 bandits for click feedback",
      "author" : [ "Katariya", "Sumeet", "Kveton", "Branislav", "Szepesvari", "Csaba", "Vernade", "Claire", "Wen", "Zheng" ],
      "venue" : "In Proceedings of the 26th International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Katariya et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Katariya et al\\.",
      "year" : 2017
    }, {
      "title" : "Stochastic rank-1 bandits",
      "author" : [ "Katariya", "Sumeet", "Kveton", "Branislav", "Szepesvari", "Csaba", "Vernade", "Claire", "Wen", "Zheng" ],
      "venue" : "In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "Katariya et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Katariya et al\\.",
      "year" : 2017
    }, {
      "title" : "Cascading bandits: Learning to rank in the cascade model",
      "author" : [ "Kveton", "Branislav", "Szepesvari", "Csaba", "Wen", "Zheng", "Ashkan", "Azin" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning,",
      "citeRegEx" : "Kveton et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kveton et al\\.",
      "year" : 2015
    }, {
      "title" : "Combinatorial cascading bandits",
      "author" : [ "Kveton", "Branislav", "Wen", "Zheng", "Ashkan", "Azin", "Szepesvari", "Csaba" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Kveton et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kveton et al\\.",
      "year" : 2015
    }, {
      "title" : "Multiple-play bandits in the position-based model",
      "author" : [ "Lagree", "Paul", "Vernade", "Claire", "Cappe", "Olivier" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Lagree et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Lagree et al\\.",
      "year" : 2016
    }, {
      "title" : "Asymptotically efficient adaptive allocation rules",
      "author" : [ "T.L. Lai", "Robbins", "Herbert" ],
      "venue" : "Advances in Applied Mathematics,",
      "citeRegEx" : "Lai et al\\.,? \\Q1985\\E",
      "shortCiteRegEx" : "Lai et al\\.",
      "year" : 1985
    }, {
      "title" : "Contextual combinatorial cascading bandits",
      "author" : [ "Li", "Shuai", "Wang", "Baoxiang", "Zhang", "Shengyu", "Chen", "Wei" ],
      "venue" : "In Proceedings of the 33rd International Conference on Machine Learning,",
      "citeRegEx" : "Li et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning to Rank for Information",
      "author" : [ "Liu", "Tie-Yan" ],
      "venue" : null,
      "citeRegEx" : "Liu and Tie.Yan.,? \\Q2011\\E",
      "shortCiteRegEx" : "Liu and Tie.Yan.",
      "year" : 2011
    }, {
      "title" : "Learning diverse rankings with multi-armed bandits",
      "author" : [ "Radlinski", "Filip", "Kleinberg", "Robert", "Joachims", "Thorsten" ],
      "venue" : "In Proceedings of the 25th International Conference on Machine Learning,",
      "citeRegEx" : "Radlinski et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Radlinski et al\\.",
      "year" : 2008
    }, {
      "title" : "How does clickthrough data reflect retrieval quality",
      "author" : [ "Radlinski", "Filip", "Kurup", "Madhu", "Joachims", "Thorsten" ],
      "venue" : "In Proceedings of the 17th ACM Conference on Information and Knowledge Management, pp",
      "citeRegEx" : "Radlinski et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Radlinski et al\\.",
      "year" : 2008
    }, {
      "title" : "Predicting clicks: Estimating the click-through rate for new ads",
      "author" : [ "Richardson", "Matthew", "Dominowska", "Ewa", "Ragno", "Robert" ],
      "venue" : "In Proceedings of the 16th International Conference on World Wide Web,",
      "citeRegEx" : "Richardson et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Richardson et al\\.",
      "year" : 2007
    }, {
      "title" : "Ranked bandits in metric spaces: Learning diverse rankings over large document collections",
      "author" : [ "Slivkins", "Aleksandrs", "Radlinski", "Filip", "Gollapudi", "Sreenivas" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Slivkins et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Slivkins et al\\.",
      "year" : 2013
    }, {
      "title" : "Interactively optimizing information retrieval systems as a dueling bandits problem",
      "author" : [ "Yue", "Yisong", "Joachims", "Thorsten" ],
      "venue" : "In Proceedings of the 26th International Conference on Machine Learning,",
      "citeRegEx" : "Yue et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Yue et al\\.",
      "year" : 2009
    }, {
      "title" : "Cascading bandits for large-scale recommendation problems",
      "author" : [ "Zong", "Shi", "Ni", "Hao", "Sung", "Kenny", "Ke", "Nan Rosemary", "Wen", "Zheng", "Kveton", "Branislav" ],
      "venue" : "In Proceedings of the 32nd Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Zong et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Zong et al\\.",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "These methods can be divided into two groups: learning the best ranker in a family of rankers (Yue & Joachims, 2009; Hofmann et al., 2013), and learning the best list under some model of user interaction with the list (Radlinski et al.",
      "startOffset" : 94,
      "endOffset" : 138
    }, {
      "referenceID" : 30,
      "context" : ", 2013), and learning the best list under some model of user interaction with the list (Radlinski et al., 2008a; Slivkins et al., 2013), such as a click model (Chuklin et al.",
      "startOffset" : 87,
      "endOffset" : 135
    }, {
      "referenceID" : 9,
      "context" : ", 2013), such as a click model (Chuklin et al., 2015).",
      "startOffset" : 31,
      "endOffset" : 53
    }, {
      "referenceID" : 10,
      "context" : "More precisely, many algorithms have been proposed and analyzed for finding the optimal ranked list in the cascade model (CM) (Kveton et al., 2015a; Combes et al., 2015; Kveton et al., 2015b; Zong et al., 2016; Li et al., 2016), the dependent-click model (DCM) (Katariya et al.",
      "startOffset" : 126,
      "endOffset" : 227
    }, {
      "referenceID" : 32,
      "context" : "More precisely, many algorithms have been proposed and analyzed for finding the optimal ranked list in the cascade model (CM) (Kveton et al., 2015a; Combes et al., 2015; Kveton et al., 2015b; Zong et al., 2016; Li et al., 2016), the dependent-click model (DCM) (Katariya et al.",
      "startOffset" : 126,
      "endOffset" : 227
    }, {
      "referenceID" : 25,
      "context" : "More precisely, many algorithms have been proposed and analyzed for finding the optimal ranked list in the cascade model (CM) (Kveton et al., 2015a; Combes et al., 2015; Kveton et al., 2015b; Zong et al., 2016; Li et al., 2016), the dependent-click model (DCM) (Katariya et al.",
      "startOffset" : 126,
      "endOffset" : 227
    }, {
      "referenceID" : 18,
      "context" : ", 2016), the dependent-click model (DCM) (Katariya et al., 2016), and the position-based model (PBM) (Lagree et al.",
      "startOffset" : 41,
      "endOffset" : 64
    }, {
      "referenceID" : 23,
      "context" : ", 2016), and the position-based model (PBM) (Lagree et al., 2016).",
      "startOffset" : 44,
      "endOffset" : 65
    }, {
      "referenceID" : 13,
      "context" : "This is a grave issue because it is well known that no single click model captures the behavior of an entire population of users (Grotov et al., 2015).",
      "startOffset" : 129,
      "endOffset" : 150
    }, {
      "referenceID" : 29,
      "context" : "We make the following contributions: • We propose stochastic click bandits, a learning framework for maximizing the expected number of clicks in online LTR in a broad class of click models, which includes both the PBM (Richardson et al., 2007) and CM (Craswell et al.",
      "startOffset" : 218,
      "endOffset" : 243
    }, {
      "referenceID" : 11,
      "context" : ", 2007) and CM (Craswell et al., 2008).",
      "startOffset" : 15,
      "endOffset" : 38
    }, {
      "referenceID" : 9,
      "context" : "This section reviews two fundamental click models (Chuklin et al., 2015), models of how users click on an ordered list of K documents.",
      "startOffset" : 50,
      "endOffset" : 72
    }, {
      "referenceID" : 29,
      "context" : "The position-based model (PBM) (Richardson et al., 2007) is a model where the probability of clicking on an item depends on both its identity and position.",
      "startOffset" : 31,
      "endOffset" : 56
    }, {
      "referenceID" : 9,
      "context" : "≥ χ(K) (Chuklin et al., 2015), and we adopt this assumption in this work.",
      "startOffset" : 7,
      "endOffset" : 29
    }, {
      "referenceID" : 11,
      "context" : "In the cascade model (CM) (Craswell et al., 2008), the user scans a list of items R = (d1, .",
      "startOffset" : 26,
      "endOffset" : 49
    }, {
      "referenceID" : 3,
      "context" : "Before we discuss it, we formalize our learning problem as a multi-armed bandit (Auer et al., 2002; Lai & Robbins, 1985).",
      "startOffset" : 80,
      "endOffset" : 120
    }, {
      "referenceID" : 18,
      "context" : "This problem can be solved as a stochastic rank-1 bandit (Katariya et al., 2017b) by Rank1Elim. Now consider the following PBM. The examination probability of the first position is close to one and the examination probabilities of all other positions are close to zero. Then the T -step regret of Rank1Elim is O([K + K2L∆−1 min] log T ) because μ = O(1/K), where μ is defined in Katariya et al. (2017b). Note that the gapdependent term nearly matches our upper bound.",
      "startOffset" : 58,
      "endOffset" : 403
    }, {
      "referenceID" : 9,
      "context" : "We select 60 frequent search queries, and learn their CMs and PBMs using PyClick (Chuklin et al., 2015), which is an open-source library of click models for web search.",
      "startOffset" : 81,
      "endOffset" : 103
    }, {
      "referenceID" : 2,
      "context" : "RankedExp3 is a variant of ranked bandits (Section 7) where the base bandit algorithm is Exp3 (Auer et al., 1995).",
      "startOffset" : 94,
      "endOffset" : 113
    }, {
      "referenceID" : 30,
      "context" : "A popular approach to online learning to rank are ranked bandits (Radlinski et al., 2008a; Slivkins et al., 2013).",
      "startOffset" : 65,
      "endOffset" : 113
    }, {
      "referenceID" : 2,
      "context" : "This algorithm is typically adversarial (Auer et al., 1995) because the distribution of clicks on lower positions is affected by higher positions.",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 11,
      "context" : "Online learning to rank in click models (Craswell et al., 2008; Chuklin et al., 2015) was recently studied in several papers (Kveton et al.",
      "startOffset" : 40,
      "endOffset" : 85
    }, {
      "referenceID" : 9,
      "context" : "Online learning to rank in click models (Craswell et al., 2008; Chuklin et al., 2015) was recently studied in several papers (Kveton et al.",
      "startOffset" : 40,
      "endOffset" : 85
    }, {
      "referenceID" : 10,
      "context" : ", 2015) was recently studied in several papers (Kveton et al., 2015a; Combes et al., 2015; Kveton et al., 2015b; Katariya et al., 2016; Zong et al., 2016; Li et al., 2016; Lagree et al., 2016).",
      "startOffset" : 47,
      "endOffset" : 192
    }, {
      "referenceID" : 18,
      "context" : ", 2015) was recently studied in several papers (Kveton et al., 2015a; Combes et al., 2015; Kveton et al., 2015b; Katariya et al., 2016; Zong et al., 2016; Li et al., 2016; Lagree et al., 2016).",
      "startOffset" : 47,
      "endOffset" : 192
    }, {
      "referenceID" : 32,
      "context" : ", 2015) was recently studied in several papers (Kveton et al., 2015a; Combes et al., 2015; Kveton et al., 2015b; Katariya et al., 2016; Zong et al., 2016; Li et al., 2016; Lagree et al., 2016).",
      "startOffset" : 47,
      "endOffset" : 192
    }, {
      "referenceID" : 25,
      "context" : ", 2015) was recently studied in several papers (Kveton et al., 2015a; Combes et al., 2015; Kveton et al., 2015b; Katariya et al., 2016; Zong et al., 2016; Li et al., 2016; Lagree et al., 2016).",
      "startOffset" : 47,
      "endOffset" : 192
    }, {
      "referenceID" : 23,
      "context" : ", 2015) was recently studied in several papers (Kveton et al., 2015a; Combes et al., 2015; Kveton et al., 2015b; Katariya et al., 2016; Zong et al., 2016; Li et al., 2016; Lagree et al., 2016).",
      "startOffset" : 47,
      "endOffset" : 192
    }, {
      "referenceID" : 1,
      "context" : "General partial-monitoring algorithms (Agrawal et al., 1989; Bartok et al., 2012; Bartok & Szepesvari, 2012; Bartok et al., 2014) are unsuitable for our setting because their computational complexity is polynomial in the number of actions, which is exponential in K.",
      "startOffset" : 38,
      "endOffset" : 129
    }, {
      "referenceID" : 4,
      "context" : "General partial-monitoring algorithms (Agrawal et al., 1989; Bartok et al., 2012; Bartok & Szepesvari, 2012; Bartok et al., 2014) are unsuitable for our setting because their computational complexity is polynomial in the number of actions, which is exponential in K.",
      "startOffset" : 38,
      "endOffset" : 129
    }, {
      "referenceID" : 6,
      "context" : "General partial-monitoring algorithms (Agrawal et al., 1989; Bartok et al., 2012; Bartok & Szepesvari, 2012; Bartok et al., 2014) are unsuitable for our setting because their computational complexity is polynomial in the number of actions, which is exponential in K.",
      "startOffset" : 38,
      "endOffset" : 129
    }, {
      "referenceID" : 9,
      "context" : "The click model is a model of how the user interacts with a list of documents (Chuklin et al., 2015), and many such models have been proposed (Becker et al.",
      "startOffset" : 78,
      "endOffset" : 100
    }, {
      "referenceID" : 11,
      "context" : "Two fundamental click models are the CM (Craswell et al., 2008) and PBM (Richardson et al.",
      "startOffset" : 40,
      "endOffset" : 63
    }, {
      "referenceID" : 29,
      "context" : ", 2008) and PBM (Richardson et al., 2007).",
      "startOffset" : 16,
      "endOffset" : 41
    } ],
    "year" : 2017,
    "abstractText" : "Online learning to rank is a core problem in information retrieval and machine learning. Many provably efficient algorithms have been recently proposed for this problem in specific click models. The click model is a model of how the user interacts with a list of documents. Though these results are significant, their impact on practice is limited, because all proposed algorithms are designed for specific click models and lack convergence guarantees in other models. In this work, we propose BatchRank, the first online learning to rank algorithm for a broad class of click models. The class encompasses two most fundamental click models, the cascade and position-based models. We derive a gap-dependent upper bound on the T -step regret of BatchRank and evaluate it on a range of web search queries. We observe that BatchRank outperforms ranked bandits and is more robust than CascadeKL-UCB, an existing algorithm for the cascade model.",
    "creator" : "LaTeX with hyperref package"
  }
}