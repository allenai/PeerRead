{
  "name" : "1312.6180.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Manifold regularized kernel logistic regression for web image annotation",
    "authors" : [ "W. Liu", "H. Liu", "Y. Wang", "K. Lu" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "With the rapid advance of Internet technology and smart devices, users often need to manage large amounts of multimedia information using smart devices, such as personal image and video accessing and browsing. These requirements heavily rely on the success of image (video) annotation, and thus large scale image annotation through innovative machine learning methods has attracted intensive attention in recent years. One representative work is support vector machine (SVM). Although it works well in binary classification, SVM has a non-smooth loss function and can not naturally cover multi-class case. In this paper, we propose manifold regularized kernel logistic regression (KLR) for web image annotation. Compared to SVM, KLR has the following advantages: (1) the KLR has a smooth loss function; (2) the KLR produces an explicit estimate of the probability instead of class label; and (3) the KLR can naturally be generalized to the multi-class case. We carefully conduct experiments on MIR FLICKR dataset and demonstrate the effectiveness of manifold regularized kernel logistic regression for image annotation. Index Terms- Manifold regularization, kernel logistic regression, Laplacian Eigenmaps, semi-supervised learning, image annotation."
    }, {
      "heading" : "1. Introduction",
      "text" : "Today, smart devices e.g. smart phone, table PC which equipped with a digital camera have become more and more popular, and people can easily produce millions or even billions of multimedia information such as personal photos or videos. However, it is not convenient to effectively manage the photos or videos at the semantic level, and therefore large scale image/video annotation through innovative machine learning methods has attracted intensive attention in recent years and been successfully deployed for many practical applications in multimedia, computer vision and image processing [14] [16] [17] 0. There are a number of machine leaning algorithms have been employed for image annotation. One of the representative methods is support vector machine (SVM) that tries to find a separating hyperplane to maximize the margin between two classes.[12] SVM usually minimizes a hinge loss to train the maximum-margin classifier. Although hinge loss is a convex function, it is not differentiable and can not naturally be generalized to multi-class cases[15] . On the other hand, it is a very expensive labor to label a large number of images to learn a robust model for image annotation. Then semi-supervised learning (SSL) has been employed for semi-automatic image annotation[7] [8] . SSL can improve the generalization ability with only a small number of labeled images by exploiting the intrinsic structure of all the training samples including labeled and unlabelled images[1] . The most traditional class of SSL methods is manifold regularization that\ntries to explore the geometry of intrinsic data probability distribution by penalizing the objective function along the potential manifold [1] [4] . Considering the above analysis, in this paper, we replace hinge loss in SVM with logistic loss and propose manifold regularized kernel logistic regression (KLR) for web image annotation. Particularly, we employ the representative Laplacian graph to exploit the geometry of the underlying manifold. Compared to SVM, manifold regularized KLR has the following immediate advantages: (1) the KLR has a smooth loss function; (2) the KLR produces an explicit estimate of the probability instead of class label; (3) the KLR can naturally be generalized to the multi-class case; and (4) Laplacian regularization can well utilize the intrinsic structure of the data distribution. We carefully conduct extensive experiments on the MIR FLICKR dataset. The experimental results verify the effectiveness of Laplacian regularized KLR for web image annotation by comparison with the baseline algorithms. The rest of this paper arranged as follows. Section 2 briefly reviews the related work of image classification. Section 3 presents the proposed manifold regularized KLR framework. Section 4 details the implementation of Laplacian regularized KLR. Section 5 demonstrates experimental results on the MIR FLICKR dataset. And Section 6 concludes the paper."
    }, {
      "heading" : "2. Related work",
      "text" : "In recent years, there are many algorithms been proposed for multimedia retrieval including image annotation/classification, video indexing, and 3D object retrieval etc.\nBriefly, the related image/video annotation methods can be divided into three categories based on the employed machine leaning schemes which are unsupervised, supervised, and semi-supervised learning. Unsupervised learning methods use unsupervised machine learning methods such as nonnegative matrix factorization [3] , clustering[10] to annotate images/videos. Supervised leaning methods such as support vector machines [13] , decision trees[11] aim to find the relationship between labels and visual features. Considering the growing large amount of samples, some active learning methods [14] are introduced to interactively select only effective samples for labeling. Considering the heavy user labeling effort, semi-supervised learning methods exploit both a small number of labeled samples and a large number of unlabeled samples to boost the generalization of learning model and receive more and more intensive attention recently [9] ."
    }, {
      "heading" : "3. Manifold regularized kernel logistic regression",
      "text" : "In semi-supervised image annotation, we are given a small number of labeled images\nand a large number of unlabeled images\n, where\nis the label of and denote the number of labeled and\nunlabeled images respectively. Typically, . Under the assumption of semi-supervised learning, the labeled images are drawn from a probability , and unlabeled images are simply drawn from the marginal distribution of where is a compact manifold . This assumption\nindicates that the conditional distribution varies smoothly along the geodesics in the underlying geometry of and then close images pairs induce similar conditional distribution pairs. The manifold assumption is widely employed in SSL because it is a key point to precisely explore the local geometry of the potential manifold. Then the SSL problem can be written as the following optimization problem by incorporating an additional regularization term to exploit the intrinsic geometry:\n(1)\nwhere is a general loss function, penalizes the classifier complexity in an appropriate reproducing kernel Hilbert space (RKHS) , is the manifold regularization term to penalize along the underlying manifold, and parameters and balance the loss function and regularization terms and respectively. Although there are different choices for the manifold regularization terms , Laplacian regularization is promising to preserve the local similarity. In this paper, we introduce the Laplacian regularized kernel logistic regression to web image annotation. In this paper, we employ logistic loss for the loss function to construct a kernel logistic regression (KLR) model. Logistic loss is equivalent to the cross entropy loss function. Some traditional loss functions are plotted in Figure 1. The dashdot line is 0-1 loss, the dotted line is Hinge loss, and the solid line is logistic loss. From Figure 1 we can see that the negative log-likelihood loss is smooth and has a similar shape to Hinge loss that used for the SVM. Hence it is expected that the KLR\nhas similar performance with the SVM.\nTherefore, we incorporate Laplacian regularized term into the objective function with logistic loss. And then we have the following equivalent optimization problem.\n(2)\nwhere , is the graph Laplacian given by\n. Here is a diagonal matrix given by where is\nthe edge weight matrix for data adjacency graph. Theorem 1: The minimization of (2) w.r.t. exits and has the following representation\n. (3)\nwhere is a valid kernel in RKHS. The representer theorem shows the solution of (2) exists and has the general form in terms of the expansion of both labeled and unlabeled images. The proof of this representer theorem can be sketched as below. Proof: Suppose the subspace is spanned by the kernels centered at labeled and unlabeled images and is the orthogonal\ncomplement of . Thus any can be represented as , wherein is the projection of onto and is the projection of onto . Then we have . On the other hand, is a valid (symmetric, positive definite) kernel in RKHS and graph Laplacian is semi-definite positive. Thus\nis a monotonically increasing real-valued function on . Then\nwe have . This implies that is minimized if lies in the subspace . Note the reproducing property of the kernel , then\n. Therefore, the solution of the optimization\nproblem (2) can be obtained when lies in the subspace , that is\n. This completes the proof of Theorem 1. ■\nSubstituting (3) into (2), we have the following Laplacian regularized kernel logistic regression\n. (4)\nBecause the objective function is differential, we have many iterate numerical solutions for problem (4), e.g. gradient descent algorithm, Newton-Raphson method. In the next section, we describe the conjugate gradient algorithm employed in this paper to solve problem (4)."
    }, {
      "heading" : "4. Algorithm",
      "text" : "In this section, we employ the conjugate gradient algorithm to optimize problem (4).\nThe gradient of the objective function in (4) can be written as:\nThen we have the optimization procedure of conjugate gradient algorithm as below: Step 1: Initialize . Step 2: Do\n,\n.\nUntil .\nStep 3: . The optimization of problem (4) is efficient and effective due to the smoothness character of the objective function. From the illustration of different loss functions in Figure 1, the logistic loss can achieve almost equivalent performance to hinge loss. In the following section we describe the comparison experiments."
    }, {
      "heading" : "5. Experiments",
      "text" : "To evaluate the effectiveness of the proposed algorithm, we carefully conduct web image annotation experiments on the MIR Flickr dataset [6] that is offered by the LIACS Medialab at Leiden University, the Netherlands and introduced by the ACM MIR Committee in 2008 as an ACM sponsored image retrieval evaluation. The dataset contains 25,000 images of 38 categories including animals, baby, baby*, bird, bird*, car, car*, clouds, clouds*, dog, dog*, female, female*, flower, flower*, food,\nindoor, lake, male, male*, night, night*, people, people*, plant_life, portrait, portrait*, river, river*, sea, sea*, sky, structures, sunset, transport, tree, tree*, water. Figure 2 shows some example images in the dataset.\nIn our experiments, 25000 images are randomly split into equal-sized two parts as training set and test set. And for the semi-supervised learning experiments, we randomly select the same number for positive and negative labeled samples for each class and all the rest samples are unlabeled ones.\nIn our experiment, we employ GIST descriptor extracted by Guillaumin [5] . GIST descriptor is a biologically-inspired image feature which describes image features from the visual cortex cognitive mechanism.\nWe compare the proposed Laplacian kernel logistic regression algorithm with some baseline algorithms including SVM classifier and kernel logistic regression method. For Laplacian kernel logistic regression method, parameter and are tuned from the candidate set .\nIn our experiments, we measure the performance by using the average precision\n(AP) and mean average precision (mAP). Particularly, AP and mAP are computed by using the PASCAL VOC method [2] .\nand\nWhere is the precision at recall . Figure 3 shows the average precision (AP) performance of some representative objects. Each subfigure of this figure shows the performance curves of a particular category from sky, sunset, structures, clouds, clouds*, animals, indoor, people*, tree, female, female*, male, transport, water. The x-coordinate of each subfigure is the number of the labeled (unlabelled) samples in the training set and the y-coordinate is the average precision. It shows that kernel logistic regression can achieve similar performance to SVM classifier and Laplacian kernel logistic regression outperforms the baselines in most cases.\nFigure 4 illustrates the mean average precision (mAP) boxplots of different methods. There are five subfigures each of which demonstrates the performance of a particular number of labeled and unlabeled samples. The mAP performance also shows that Laplacian kernel logistic regression algorithm performs better than baseline methods."
    }, {
      "heading" : "6. Conclusion",
      "text" : "This paper studies manifold regularized kernel logistic regression (KLR) for web image annotation. Technically, we develop Laplacian regularized kernel logistic regression and implement image annotation task on MIR Flickr dataset. Compared to the representative SVM classifier, the KLR has a smooth loss function and produces an explicit estimate of the probability instead of class label. The carefully conducted experiments demonstrate the effectiveness of manifold regularized kernel logistic regression for image annotation.\nIn the future, we will apply the proposed Laplacian regularized kernel logistic regression to other applications. We will also further extend the proposed method to other manifold regularizations and explore the relation of the different regularizations.\nReference [1] M. Belkin, P. Niyogi, and V. Sindhwan i, “Manifold regularization: A geometric\nframework for learning from labeled and unlabeled examples,” J. Mach. Learn. Res. vol. 7, no. 11, pp. 2399–2434, Nov. 2006.\n[2] M. Everingham, L. V. Gool, C. Williams, J. Winn, and A. Zisserman, the\nPASCAL Visual Object Classes Challenge 2007 (VOC2007). 2007\n[3] Naiyang Guan, Dacheng Tao, Zhigang Luo, Bo Yuan: NeNMF: An Optimal\nGradient Method for Nonnegative Matrix Factorization. IEEE Transactions on Signal Processing 60(6): 2882-2898 (2012)\n[4] N. Guan, D. Tao, Z. Luo, and B. Yuan, “Non-negative patch alignment\nframework,” IEEE Trans. Neural Netw. , vol. 22, no. 8, pp. 1218–1230, Aug. 2011\n[5] M. Guillaumin, J. Verbeek, and C. Schmid, “Multimodal semi-supervised\nlearning for image classification,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jul. 2010, pp. 902–909.\n[6] M. J. Huiskes and M. S. Lew, “The MIR flickr retrieval evaluation,” in Proc. 1st\nACM Int. Conf. Multimedia Inf. Retr., 2008, pp. 39–43.\n[7] Weifeng Liu, Dacheng Tao, \"Multiview Hessian Regularization for Image\nAnnotation,\" IEEE Transactions on Image Processing, vol. 22, pp. 2676 - 2687, 2013.\n[8] Weifeng Liu, Dacheng Tao, Jun Cheng, and Yuanyan Tang, \"Multiview Hessian\nDiscriminative Sparse Coding for Image Annotation,\" Computer Vision and Image Understanding, 2013.\n[9] Yong Luo, Dacheng Tao, Bo Geng, Chao Xu, Stephen J. Maybank: Manifold\nRegularized Multitask Learning for Semi-Supervised Multilabel Image Classification. IEEE Transactions on Image Processing 22(2): 523-536 (2013)\n[10] S. Papadopoulos, C. Zigkolis, Y. Kompatsiaris, and A. Vakali, “Cluster-Based\nLandmark and Event Detection for Tagged Photo Collections,” IEEE Multimedia, vol. 18, no. 1, pp. 52-63, 2011\n[11] J. R. Quinlan, “Induction of Decision Trees,” Machine Learning, vol. 1, no. 1,\npp. 81-106, 1986.\n[12] Dacheng Tao, Xiaoou Tang, Xuelong Li, Xindong Wu: Asymmetric Bagging\nand Random Subspace for Support Vector Machines-Based Relevance Feedback in Image Retrieval. IEEE Trans. Pattern Anal. Mach. Intell. 28(7): 1088-1099 (2006)\n[13] V. Vapnik, Statistical learning theory, 1998. [14] Zheng-Jun Zha, Meng Wang, Yan-Tao Zheng, Yi Yang, Richang Hong,\nTat-Seng Chua: Interactive Video Indexing With Statistical Active Learning. IEEE Transactions on Multimedia 14(1): 17-27 (2012)\n[15] Ji Zhu and Trevor Hastie， Kernel Logistic Regression and the Import Vector\nMachine. JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS, pp1081--1088,2001\n[16] Zheng-Jun Zha, Linjun Yang, Tao Mei, Meng Wang, Zengfu Wang: Visual\nquery suggestion. ACM Multimedia 2009: 15-24\n[17] Zheng-Jun Zha, Xian-Sheng Hua, Tao Mei, Jingdong Wang, Guo-Jun Qi,\nZengfu Wang: Joint multi-label multi-instance learning for image classification. CVPR 2008"
    } ],
    "references" : [ {
      "title" : "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples",
      "author" : [ "M. Belkin", "P. Niyogi", "V. Sindhwan i" ],
      "venue" : "J. Mach. Learn. Res. vol. 7, no. 11, pp. 2399–2434, Nov. 2006.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "NeNMF: An Optimal Gradient Method for Nonnegative Matrix Factorization",
      "author" : [ "Naiyang Guan", "Dacheng Tao", "Zhigang Luo", "Bo Yuan" ],
      "venue" : "IEEE Transactions on Signal Processing",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Non-negative patch alignment framework",
      "author" : [ "N. Guan", "D. Tao", "Z. Luo", "B. Yuan" ],
      "venue" : "IEEE Trans. Neural Netw. , vol. 22, no. 8, pp. 1218–1230, Aug. 2011",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Multimodal semi-supervised learning for image classification",
      "author" : [ "M. Guillaumin", "J. Verbeek", "C. Schmid" ],
      "venue" : "Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jul. 2010, pp. 902–909.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "The MIR flickr retrieval evaluation",
      "author" : [ "M.J. Huiskes", "M.S. Lew" ],
      "venue" : "Proc. 1st ACM Int. Conf. Multimedia Inf. Retr., 2008, pp. 39–43.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Multiview Hessian Regularization for Image  Annotation",
      "author" : [ "Weifeng Liu", "Dacheng Tao" ],
      "venue" : "IEEE Transactions on Image Processing, vol. 22, pp. 2676 - 2687, 2013.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Multiview Hessian Discriminative Sparse Coding for Image Annotation",
      "author" : [ "Weifeng Liu", "Dacheng Tao", "Jun Cheng", "Yuanyan Tang" ],
      "venue" : "Computer Vision and Image Understanding, 2013.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Manifold Regularized Multitask Learning for Semi-Supervised Multilabel Image Classification",
      "author" : [ "Yong Luo", "Dacheng Tao", "Bo Geng", "Chao Xu", "Stephen J. Maybank" ],
      "venue" : "IEEE Transactions on Image Processing",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2013
    }, {
      "title" : "Cluster-Based Landmark and Event Detection for Tagged Photo Collections",
      "author" : [ "S. Papadopoulos", "C. Zigkolis", "Y. Kompatsiaris", "A. Vakali" ],
      "venue" : "IEEE Multimedia, vol. 18, no. 1, pp. 52-63, 2011",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Induction of Decision Trees",
      "author" : [ "J.R. Quinlan" ],
      "venue" : "Machine Learning, vol. 1, no. 1, pp. 81-106, 1986.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1986
    }, {
      "title" : "Asymmetric Bagging and Random Subspace for Support Vector Machines-Based Relevance Feedback in Image Retrieval",
      "author" : [ "Dacheng Tao", "Xiaoou Tang", "Xuelong Li", "Xindong Wu" ],
      "venue" : "IEEE Trans. Pattern Anal. Mach. Intell",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2006
    }, {
      "title" : "Interactive Video Indexing With Statistical Active Learning",
      "author" : [ "Zheng-Jun Zha", "Meng Wang", "Yan-Tao Zheng", "Yi Yang", "Richang Hong", "Tat-Seng Chua" ],
      "venue" : "IEEE Transactions on Multimedia",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2012
    }, {
      "title" : "Kernel Logistic Regression and the Import Vector  Machine",
      "author" : [ "Ji Zhu", "Trevor Hastie" ],
      "venue" : "JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2001
    }, {
      "title" : "Joint multi-label multi-instance learning for image classification",
      "author" : [ "Zheng-Jun Zha", "Xian-Sheng Hua", "Tao Mei", "Jingdong Wang", "Guo-Jun Qi", "Zengfu Wang" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "However, it is not convenient to effectively manage the photos or videos at the semantic level, and therefore large scale image/video annotation through innovative machine learning methods has attracted intensive attention in recent years and been successfully deployed for many practical applications in multimedia, computer vision and image processing [14] [16] [17] 0.",
      "startOffset" : 354,
      "endOffset" : 358
    }, {
      "referenceID" : 13,
      "context" : "However, it is not convenient to effectively manage the photos or videos at the semantic level, and therefore large scale image/video annotation through innovative machine learning methods has attracted intensive attention in recent years and been successfully deployed for many practical applications in multimedia, computer vision and image processing [14] [16] [17] 0.",
      "startOffset" : 364,
      "endOffset" : 368
    }, {
      "referenceID" : 10,
      "context" : "[12] SVM usually minimizes a hinge loss to train the maximum-margin classifier.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "Although hinge loss is a convex function, it is not differentiable and can not naturally be generalized to multi-class cases[15] .",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 5,
      "context" : "Then semi-supervised learning (SSL) has been employed for semi-automatic image annotation[7] [8] .",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 6,
      "context" : "Then semi-supervised learning (SSL) has been employed for semi-automatic image annotation[7] [8] .",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 0,
      "context" : "intrinsic structure of all the training samples including labeled and unlabelled images[1] .",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 0,
      "context" : "tries to explore the geometry of intrinsic data probability distribution by penalizing the objective function along the potential manifold [1] [4] .",
      "startOffset" : 139,
      "endOffset" : 142
    }, {
      "referenceID" : 2,
      "context" : "tries to explore the geometry of intrinsic data probability distribution by penalizing the objective function along the potential manifold [1] [4] .",
      "startOffset" : 143,
      "endOffset" : 146
    }, {
      "referenceID" : 1,
      "context" : "Unsupervised learning methods use unsupervised machine learning methods such as nonnegative matrix factorization [3] , clustering[10] to annotate images/videos.",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 8,
      "context" : "Unsupervised learning methods use unsupervised machine learning methods such as nonnegative matrix factorization [3] , clustering[10] to annotate images/videos.",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 9,
      "context" : "Supervised leaning methods such as support vector machines [13] , decision trees[11] aim to find the relationship between labels and visual features.",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 11,
      "context" : "Considering the growing large amount of samples, some active learning methods [14] are introduced to interactively select only effective samples for labeling.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 7,
      "context" : "Considering the heavy user labeling effort, semi-supervised learning methods exploit both a small number of labeled samples and a large number of unlabeled samples to boost the generalization of learning model and receive more and more intensive attention recently [9] .",
      "startOffset" : 265,
      "endOffset" : 268
    }, {
      "referenceID" : 4,
      "context" : "To evaluate the effectiveness of the proposed algorithm, we carefully conduct web image annotation experiments on the MIR Flickr dataset [6] that is offered by the LIACS Medialab at Leiden University, the Netherlands and introduced by the ACM MIR Committee in 2008 as an ACM sponsored image retrieval evaluation.",
      "startOffset" : 137,
      "endOffset" : 140
    }, {
      "referenceID" : 3,
      "context" : "In our experiment, we employ GIST descriptor extracted by Guillaumin [5] .",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 0,
      "context" : "[1] M.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "2007 [3] Naiyang Guan, Dacheng Tao, Zhigang Luo, Bo Yuan: NeNMF: An Optimal Gradient Method for Nonnegative Matrix Factorization.",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 2,
      "context" : "IEEE Transactions on Signal Processing 60(6): 2882-2898 (2012) [4] N.",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 3,
      "context" : "2011 [5] M.",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 4,
      "context" : "[6] M.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[7] Weifeng Liu, Dacheng Tao, \"Multiview Hessian Regularization for Image",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[8] Weifeng Liu, Dacheng Tao, Jun Cheng, and Yuanyan Tang, \"Multiview Hessian Discriminative Sparse Coding for Image Annotation,\" Computer Vision and Image Understanding, 2013.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[9] Yong Luo, Dacheng Tao, Bo Geng, Chao Xu, Stephen J.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "IEEE Transactions on Image Processing 22(2): 523-536 (2013) [10] S.",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 9,
      "context" : "52-63, 2011 [11] J.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 10,
      "context" : "[12] Dacheng Tao, Xiaoou Tang, Xuelong Li, Xindong Wu: Asymmetric Bagging and Random Subspace for Support Vector Machines-Based Relevance Feedback in Image Retrieval.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[14] Zheng-Jun Zha, Meng Wang, Yan-Tao Zheng, Yi Yang, Richang Hong, Tat-Seng Chua: Interactive Video Indexing With Statistical Active Learning.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "IEEE Transactions on Multimedia 14(1): 17-27 (2012) [15] Ji Zhu and Trevor Hastie, Kernel Logistic Regression and the Import Vector",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 13,
      "context" : "ACM Multimedia 2009: 15-24 [17] Zheng-Jun Zha, Xian-Sheng Hua, Tao Mei, Jingdong Wang, Guo-Jun Qi, Zengfu Wang: Joint multi-label multi-instance learning for image classification.",
      "startOffset" : 27,
      "endOffset" : 31
    } ],
    "year" : 2013,
    "abstractText" : "With the rapid advance of Internet technology and smart devices, users often need to manage large amounts of multimedia information using smart devices, such as personal image and video accessing and browsing. These requirements heavily rely on the success of image (video) annotation, and thus large scale image annotation through innovative machine learning methods has attracted intensive attention in recent years. One representative work is support vector machine (SVM). Although it works well in binary classification, SVM has a non-smooth loss function and can not naturally cover multi-class case. In this paper, we propose manifold regularized kernel logistic regression (KLR) for web image annotation. Compared to SVM, KLR has the following advantages: (1) the KLR has a smooth loss function; (2) the KLR produces an explicit estimate of the probability instead of class label; and (3) the KLR can naturally be generalized to the multi-class case. We carefully conduct experiments on MIR FLICKR dataset and demonstrate the effectiveness of manifold regularized kernel logistic regression for image annotation.",
    "creator" : "Microsoft® Office Word 2007"
  }
}