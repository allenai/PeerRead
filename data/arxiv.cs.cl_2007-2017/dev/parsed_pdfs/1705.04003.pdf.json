{
  "name" : "1705.04003.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Content-based Approach for Vietnamese Spam SMS Filtering",
    "authors" : [ "Thai-Hoang Pham", "Phuong Le-Hong" ],
    "emails" : [ "hoangpt@fpt.edu.vn", "phuonglh@vnu.edu.vn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 5.\n04 00\n3v 1\n[ cs\n.C L\n] 1\n1 M\nay 2\nI. INTRODUCTION\nIn recent years, the explosion of the mobile network in Vietnam stimulated the use of Short Message Service (SMS). Spam through SMS has increased because the cost to the spammer is low and the response rate is higher than email. SMS spam is a serious problem in Vietnam because of the availability of unlimited and very cheap pre-paid SMS packages.\nAccording to a report in 2015 by BKAV1, an information security firm, there were 13.9 million spam messages sent to mobile phone users every day in Vietnam, and one out of two people received spam messages [1]. Meanwhile, there were at least 120 million active mobile users in the market according to a report of the Ministry of Information and Communication, which was released in 2015 [2].\nSpam SMS causes many issues for mobile users. They may suffer financial loss from these messages by reacting to them. Users may accidentally call to premium rate numbers or register for expensive services by replying to these messages. Moreover, they can be exposed to some risks by accessing harmful websites or downloading malwares. Mobile network operators also suffer financially because they may lose users or spend more on spam prevention.\nThere are many methods and systems for filtering spam messages for English in mobile networks [3], [4]. Most of them use machine learning approaches to analyze the content of messages and additional information to detect spam messages.\n1www.bkav.com.vn\nOne of the first systems was proposed by Graham [5], using Naive Bayes classifier to get a good result. This work led to the development and application of other machine learning algorithms to spam filtering. The state-of-the-art system for English can detect spam SMS with an accuracy of 97.5% with a good false positive of only 0.2% [6].\nIn this paper, we present the first system for Vietnamese spam SMS filtering with a good accuracy. We first propose a method for the preprocessing step because existing tools for Vietnamese preprocessing cannot give good accuracy on our dataset. We then experiment with vector representations and different classifiers to find the best model for this problem. Our system achieves an accuracy of about 94% when labelling spam messages while the misclassification rate of legitimate messages is relatively small, about 0.4%. This is an encouraging result, applicable in real-world applications and serves as a good baseline for further improvement of future systems.\nThe paper is structured as follows. Section II introduces briefly the task of filtering spam SMS. Section III describes the methodology of our system. Section IV presents our data and the evaluation results and discussion. Finally, Section V concludes the paper and suggests some directions for future work."
    }, {
      "heading" : "II. BACKGROUND",
      "text" : ""
    }, {
      "heading" : "A. Spam filtering system",
      "text" : "A SMS is a short text message that contains only a limited number of characters. The structure of this message is divided into the header and the body. The header contains some information about the subject, sender, and recipient while the body is the actual content of the message that we see on mobile phones.\nFigure 1 shows the pipeline of a usual spam filter. The processing chain of a filter can be divided into three components.\nThe first is preprocessing, where documents are processed to extract data for later use. The common preprocessing steps are tokenization, lemmatization and removing stop words. After preprocessing the raw text is transformed to vectors, each representing the content of one message. The most popular representations are bag of words and term frequency-inverse document frequency. The vectors are inputs to a machine learning model. After be trained, the model is able to label each new message as spam or not."
    }, {
      "heading" : "B. Spam filtering system for Vietnamese",
      "text" : "To our knowledge, there is some research on spam filtering for Vietnamese but none focused on SMS. Most of these systems are developed for filtering spam email [7], [8]. The best accuracy of those systems is about 92% but the false positive rate is not feasible in practical applications, about 6% [7]. Moreover, email has many characteristics different from SMS, so applying these systems directly to our task cannot give the best accuracy. For these reasons, we propose a system that focuses on filtering Vietnamese spam SMS."
    }, {
      "heading" : "III. METHODOLOGY",
      "text" : "SMS has some different characteristics compared to regular text such as email, the task of labelling spam SMS is harder than for email. Firstly the maximum length of an SMS message is only 160 characters, so the content-based approach for SMS is more difficult because there is less information. Secondly, subscribers do not usually use regular grammar to type a message. They use abbreviations, phonetic contractions, wrong punctuations, emoticons, etc. It makes the data sparse, and some preprocessing tools cannot be applied. Also, linguistic characteristics of the Vietnamese language are different from occidental languages. Thus, applying methods for English directly or using existing systems for detecting Vietnamese spam email cannot give the best performance.\nIn the following subsections, we present our main method, including preprocessing step, featurization and machine learning models."
    }, {
      "heading" : "A. Preprocessing",
      "text" : "1) Entity Tagging: The size of our corpus is relatively small and a lot of patterns in messages are not words in the dictionary. Thus, it is necessary to alleviate the sparseness of this data. We propose a new way to do this by grouping some similar patterns together. We define six groups, including date, phone, link, currency, emoticon and number. Date collects characters that describe time such as day, month, year, hour, etc. . .Phone detects phone numbers. Link and currency find and replace characters that represent web links and money. Mobile users use many emoticons in messages and we match them to similar emoticons of Facebook. After that, we replace all number in the corpus by the token number.\n2) Tokenization: Like many occidental languages, Vietnamese is based on the Latin alphabet. However in Vietnamese, the space symbol is not only used to separate words but also to separate syllables within the same word. The task of word segmentation plays an important role when detecting spam message because it helps to extract features more correctly. There are tools to solve this problem by detecting word\nboundaries such as vnTokenizer [9], JVnSegmenter [10]. These tools work well for regular text but they are not suitable for our dataset because of SMS usually uses an idiosyncratic language. Thus, we propose to use the phrase collocation method for the segmentation task on our dataset [11]. The score of two syllables wi, wj that are parts of the same word is given by:\nscore(wi, wj) = count(wiwj − δ)\ncount(wi) ∗ count(wj) (1)\nwhere δ is used as a discounting coefficient to prevents too many phrases consisting of very infrequent words to be formed.\nFor our system, we filter out all bigrams with total collected count lower than 10. The advantage of this method is that we need no pre-training data to train the tokenizer. It is based on only the statistics of syllables in our corpus.\nB. Vector Representation\nThe raw data type is text so we need to transform it to vector form to use in machine learning models. There are two common methods for converting from raw text to numeric vector - Bag of Words (BoW) and Term frequency-Inverse document frequency (Tf-Idf).\n1) Bag of words: Given the vocabulary set T = {t1, t2, ..., tN}, each document d in the corpus is represented as a N-dimensional vector X = [x1, x2, ..., xN ], where xi is the number of occurrences of ti in d.\n2) Term frequency-Inverse document frequency: Tf-Idf is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. Now, each xi in vector X is calculated by an equation:\nxi = nti,d log\n(\n|D|\nnti\n)\n(2)\nwhere D is a corpus, nti,d is the number of occurrences of ti in d and nti denotes the number of documents in which ti occurs.\n3) Feature Selection: Because the represented vector is sparse, it may reduce the performance of the classifier. To improve the accuracy of our system, we need a method to select the most representative features such as document frequency, information gain, term-frequency variance, etc. . . In our setting, we use document frequency because this common method has low computing cost.\n4) Length Feature: In our experiment, we found that the length feature is useful because the lengths of spam messages tend to be long."
    }, {
      "heading" : "C. Classifiers",
      "text" : "1) Baseline Classifier: Spam messages from mobile network operators are easy to detect because they have special tags in their contents. Thus, we collect these tags and label messages that have them as spam messages. Specifically, these tags are [QC*], (QC*), [TB*], (TB*) where * is a string or empty. We use this method as a baseline system for the evaluation task.\n2) Machine Learning Models: We trained some common machine learning models on our dataset and used them to detect spam messages. These models include Naive Bayes (NB), support vector machine (SVM), logistic regression (LR), decision tree (DT) and k-nearest neighbours (kNN)."
    }, {
      "heading" : "IV. EXPERIMENT",
      "text" : ""
    }, {
      "heading" : "A. Dataset",
      "text" : "We conduct experiments on a dataset containing 6599 messages manually annotated with labels. Our dataset is a collection of messages from two biggest mobile network operators in Vietnam - Viettel and Vinaphone. There are 5557 legitimate messages and 1042 spam messages in this dataset. Its dictionary has 7, 334 unique words. Spam message could be sent from either mobile network operators or other sources. The former are easy to detect because they have special tags in their contents. In our dataset about 70% of spam messages are from operators. The size of this corpus is comparable to some SMS datasets for English [4]. This dataset is made available for research purpose2."
    }, {
      "heading" : "B. Results and Discussions",
      "text" : "1) Evaluation Method: We use 5-fold cross-validation to evaluate our system. The final accuracy score is the average scores of the five runs.\nWe use statistical measures of the performance of a binary classification test in decision theory as measures for our system. The reason for using this method is the asymmetry in the misclassification costs. The error that the system incorrectly classifies spam message as legitimate is a minor problem while the error of labelling legitimate message as spam can be unacceptable. Thus, there is a trade-off between two types of errors. The sound system must satisfy both of two constraint - the good performance for spam filtering and the misclassification of the legitimate message is minimum.\nIn decision theory, two classes are positive (spam) and negative (legitimate). We measure two types of error by false positive rate and false negative rate. The numbers of spam and legitimate message in our dataset are nS and nL, the numbers of incorrect messages are nS,L and nL,S , respectively. From these, the false positive and negative rates are given by the following formulas:\nFPR = nL,S\nnL\nFNR = nS,L\nnS\n(3)\n2) Baseline System: Our baseline system uses a simple rule to detect spam messages by catching special tags in their contents. Table I presents the accuracy of this system.\nWe see that this system can detect only about 70% of the number of spam messages because there are lots of spam messages that have no special tags in their contents.\n3) Preprocessing: In the second experiment, we compare the performance of the system with or without preprocessing. The classifier we use is Support Vector Machine, and the representation is BoW.\nWithout preprocessing the vocabulary has 7334 words while using tokenization and entity tagging, the vocabulary size is reduced to 5998 words. It makes our corpus less sparse and more accurate because its size is smaller and words in Vietnamese is combined from one or more syllables. Table II shows the improvement when using the preprocessing technique.\nWe see that with preprocessing the accuracy of labelling spam message increases about 1.6%.\n4) Vector Representations: In the third experiment, we evaluate the performance of SVM with two common methods for representing text – BoW and Tf-Idf. The result is shown in Table III.\nFrom the information in above table, we can conclude that BoW is very more useful than Tf-Idf for this problem. Specifically, the accuracy when using BoW is better than using Tf-Idf about 15%.\n5) Classifiers: In the fourth experiment, we compare some machine learning models to find the best models for this task. Classifiers that we compare are support vector machine (SVM), naive bayes (NB), decision tree (DT), logistic regression (LR) and k-nearest neighbours (kNN) and the vector representation in this experiment is BoW. Table IV shows the accuracy of each model.\nNaive Bayes gives the best result for labelling spam message but its false positive rate is very high, about 3.75%.\nIt means that for each 100 legitimate messages, there are 3 messages that are labelled as spam. This rate is not acceptable in reality. In the rest, SVM gets the best result. Thus, we use SVM as a classifier for our system.\n6) Length feature and feature selection: We find that the length feature is useful for our system because the lengths of spam messages tend to be long. Document frequency is a good method to find the most useful features for classifying and make our system faster. Table V presents the accuracy of our system when adding length feature and set document frequency as 3."
    }, {
      "heading" : "V. CONCLUSION AND OUTLOOK",
      "text" : "In this paper, we have presented the first system for Vietnamese spam SMS filtering. Our system achieves a good accuracy of about 94% of detecting spam messages. This result is comparable to the accuracy of this task for English and outperforms performances of some systems for labelling Vietnamese spam email although classifying SMS is more complicated.\nIn the future, on the one hand, we plan to improve our system by enlarging our corpus so as to provide more data for the system. On the other hand, we would like to use some deep learning models such as convolution neural network and long-short term memory for detect spam messages because these models have been shown to give the best performance for many text classification problems [12], [13]."
    }, {
      "heading" : "ACKNOWLEDGMENT",
      "text" : "The authors would like to thank the CyRadar3 team for providing us the dataset for use in the experiments. The second author is partly funded by the Vietnam National University, Hanoi (VNU) under project number QG.15.04."
    } ],
    "references" : [ {
      "title" : "The review of network security situation",
      "author" : [ "B. Corporation" ],
      "venue" : "http://www.bkav.com.vn/hoi-dap/-/chi",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2015
    }, {
      "title" : "A review of machine learning approaches to spam filtering",
      "author" : [ "T.S. Guzella", "W.M. Caminhas" ],
      "venue" : "Expert Systems with Applications, vol. 36, no. 7, pp. 10 206–10 222, 2009.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "SMS spam filtering: methods and data",
      "author" : [ "S.J. Delany", "M. Buckley", "D. Greene" ],
      "venue" : "Expert Systems with Applications, vol. 39, no. 10, pp. 9899– 9908, 2012.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A plan for spam",
      "author" : [ "P. Graham" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2002
    }, {
      "title" : "Contributions to the study of SMS spam filtering: new collection and results",
      "author" : [ "J.M.G.H. Tiago A Almeida", "A. Yamakami" ],
      "venue" : "Proceedings of the 11th ACM symposium on Document engineering, California, United States, 2011, pp. 259–262.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Bayesian spam filtering for Vietnamese emails",
      "author" : [ "V.D. Lung", "T.N. Vu" ],
      "venue" : "Proceedings of the International Conference on Computer & Information Science, Kuala Lumpur, Malaysia, 2012, pp. 190–193.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Automated generation of ham rules for Vietnamese spam filtering",
      "author" : [ "Q.D. Dinh", "Q.A. Tran", "F. Jiang" ],
      "venue" : "Proceedings of the 7th IEEE Symposium on Computational Intelligence for Security and Defense Applications, Hanoi, Vietnam, 2014, pp. 1–5.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "A hybrid approach to word segmentation of Vietnamese texts",
      "author" : [ "P. Le-Hong", "T.M.H. Nguyen", "A. Roussanaly", "T.V. Ho" ],
      "venue" : "Language and Automata Theory and Applications, ser. Lecture Notes in Computer Science. Springer Berlin Heidelberg, 2008, vol. 5196, pp. 240–249.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Vietnamese word segmentation with CRFs and SVMs: An investigation",
      "author" : [ "N. Cam-Tu", "N. Trung-Kien", "P. Xuan-Hieu", "N. Le-Minh", "H. Quang- Thuy" ],
      "venue" : "Proceedings of the 20th Pacific Asia Conference on Language, Information and Computation, Wuhan, China, 2006.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean" ],
      "venue" : "Proceedings of the 26th Advances in Neural Information Processing Systems, Nevada, United States, 2013, pp. 3111–3119.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Supervised and semi-supervised text categorization using lstm for region embeddings",
      "author" : [ "R. Johnson", "T. Zhang" ],
      "venue" : "Proceedings of the 33rd International Conference on Machine Learning, New York, United States, 2016, pp. 526–534.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Character-level convolutional networks for text classification",
      "author" : [ "X. Zhang", "J. Zhao", "Y. LeCun" ],
      "venue" : "Proceedings of the 28th Advances in Neural Information Processing Systems, 2015, pp. 649–657.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "9 million spam messages sent to mobile phone users every day in Vietnam, and one out of two people received spam messages [1].",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 1,
      "context" : "There are many methods and systems for filtering spam messages for English in mobile networks [3], [4].",
      "startOffset" : 94,
      "endOffset" : 97
    }, {
      "referenceID" : 2,
      "context" : "There are many methods and systems for filtering spam messages for English in mobile networks [3], [4].",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 3,
      "context" : "vn One of the first systems was proposed by Graham [5], using Naive Bayes classifier to get a good result.",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 4,
      "context" : "2% [6].",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 5,
      "context" : "Most of these systems are developed for filtering spam email [7], [8].",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 6,
      "context" : "Most of these systems are developed for filtering spam email [7], [8].",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 5,
      "context" : "The best accuracy of those systems is about 92% but the false positive rate is not feasible in practical applications, about 6% [7].",
      "startOffset" : 128,
      "endOffset" : 131
    }, {
      "referenceID" : 7,
      "context" : "There are tools to solve this problem by detecting word boundaries such as vnTokenizer [9], JVnSegmenter [10].",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 8,
      "context" : "There are tools to solve this problem by detecting word boundaries such as vnTokenizer [9], JVnSegmenter [10].",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 9,
      "context" : "Thus, we propose to use the phrase collocation method for the segmentation task on our dataset [11].",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 2,
      "context" : "The size of this corpus is comparable to some SMS datasets for English [4].",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 10,
      "context" : "On the other hand, we would like to use some deep learning models such as convolution neural network and long-short term memory for detect spam messages because these models have been shown to give the best performance for many text classification problems [12], [13].",
      "startOffset" : 257,
      "endOffset" : 261
    }, {
      "referenceID" : 11,
      "context" : "On the other hand, we would like to use some deep learning models such as convolution neural network and long-short term memory for detect spam messages because these models have been shown to give the best performance for many text classification problems [12], [13].",
      "startOffset" : 263,
      "endOffset" : 267
    } ],
    "year" : 2017,
    "abstractText" : "Short Message Service (SMS) spam is a serious problem in Vietnam because of the availability of very cheap prepaid SMS packages. There are some systems to detect and filter spam messages for English, most of which use machine learning techniques to analyze the content of messages and classify them. For Vietnamese, there is some research on spam email filtering but none focused on SMS. In this work, we propose the first system for filtering Vietnamese spam SMS. We first propose an appropriate preprocessing method since existing tools for Vietnamese preprocessing cannot give good accuracy on our dataset. We then experiment with vector representations and classifiers to find the best model for this problem. Our system achieves an accuracy of 94% when labelling spam messages while the misclassification rate of legitimate messages is relatively small, about only 0.4%. This is an encouraging result compared to that of English and can be served as a strong baseline for future development of Vietnamese SMS spam prevention systems.",
    "creator" : "LaTeX with hyperref package"
  }
}