{
  "name" : "1506.06274.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Pose Estimation Based on 3D Models",
    "authors" : [ "Chuiwen Ma", "Hao Su", "Liang Shi" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Pose Estimation Based on 3D Models\nChuiwen Ma, Hao Su, Liang Shi"
    }, {
      "heading" : "1 Introduction",
      "text" : "This project aims to estimate the pose of an object in the image. Pose estimation problem is known to be an open problem and also a crucial problem in computer vision field. Many real-world tasks depend heavily on or can be improved by a good pose estimation. For example, by knowing the exact pose of an object, robots will know where to sit on, how to grasp, or avoid collision when walking around. Besides, pose estimation is also applicable to automatic driving. With good pose estimation of cars, automatic driving system will know how to manipulate itself accordingly. Moreover, pose estimation can also benefit image searching, 3D reconstruction and has a large potential impact on many other fields.\nPreviously, most pose estimation works were implemented on manually captured and labeled dataset, using multi-camera or depth camera. However, to create such a dataset is extremely time-consuming, laborsome, and also error-prone. Therefore, limited information can be learned from those datasets, and research-specific datasets lead to poor comparability among previous works. In this project, we instead utilized the power of 3D shape models. To be specific, we built a large, balanced and precisely labeled training dataset from ShapeNet [5], a large 3D model pool which contains millions of 3D shape models in thousands of object categories. By rendering 3D models into 2D images from different viewpoints, we can easily control the size, the pose distribution, and the precision of the dataset. A learning model trained on this dataset will help us better solve the pose estimation task.\nIn this work, we proposed a pose estimation system based on rendered image training set, which predicts the pose of objects in real image, with knowledge of object category and tight bounding box. Although the approach is generic, we chose chair to be our primary research object. Our system takes a properly cropped chair image as input, and outputs a probability vector on discretized pose space. Given a test image, we first divide it into a N × N overlapped patch grid. For each patch, a multi-class classifier is trained to estimate the probability of this patch to be pose v. Then,\nscores from all patches are combined to generate a probability vector for the whole image.\nAlthough we created a larger and more precise training dataset from rendered images, there is an obvious drawback of this approach — the statistical property of the training set and the test set are different. For instance, in the real world, there exists a prior probability distribution of poses, which might be non-uniform. Furthermore, even for feature complexity, real image features might be more diverse than rendered image features. In this project, we also focused on information transmission between 2D images and 3D models, therefore proposed a method to iteratively learn from classification results and in return improve classification algorithm. This novel approach revised the influence of different prior probability distribution in training and test set. Details and experiment results are shown in the following sections."
    }, {
      "heading" : "1.1 Related Works",
      "text" : "Object pose estimation is a classical problem in computer vision. In general, there are two typical research lines: one based on 2D representation and the other based on 3D information.\nAmong 2D based researches, [6,7,8] rely on point matching, which is now outdated. By linking together diagnostic parts of object from different views, [9] represents an object category as a collection of view-invariant regions. Sun et al. [10] and Su et al. [17] used a generative approach to group local features into parts and then learn part locations across viewpoints. [11] used a SIFT-like [18] spatial pyramids of histograms feature to train a SVM classifier for each discrete pose. Inspired by Deformable Part Model’s [12] success, [13] trained a DPM using a semi-latent approach, where the components correspond to discrete viewpoints. [15] used convolutional neural network features for the task of pose estimation. [16] proposed a Hough Forest based method for simultaneous object detection and continuous pose estimation. Those widely different works above, although gained some achievements, are not learning from structural information of objects like human.\nar X\niv :1\n50 6.\n06 27\n4v 1\n[ cs\n.C V\n] 2\n0 Ju\nn 20\n15\nRecently, 3D model based approach achieved good performance on pose estimation task. [19] extended deformable part models to 3D, where part appearances and spatial deformations are represented in 3D. Using an readymade approach, [20] first obtained a rough localization and viewpoint of the object, and then estimated a continuous pose by using annotated 3D CAD models. Hejrati et al. [21] estimated poses of cars using an explicit 3D shape model and viewpoint which is learned from structure-from-motion (SFM). In general, methods above rely on sophisticated handling of 3D models, due to the limitation of model amount.\nUp to our knowledge, there is no previous work that utilizes large 3D model database to solve pose estimation task."
    }, {
      "heading" : "2 Data Collection and",
      "text" : "Processing"
    }, {
      "heading" : "2.1 Training Data",
      "text" : "As we mentioned in Section 1, we collected our training data from ShapeNet, an emerging 3D shape model database. With 9,135135 semantically annotated 3D models in thousands of object categories, ShapeNet could provide abundant information for many vision tasks. In our task, we utilized those 5057 chair models in ShapeNet. For each model, we rendered it on 16 viewpoints, evenly distributed on the horizontal circle, shown in Figure 1.\nWe chose 4000 models, accordingly 64,000 images to build the training dataset, and leave the rest 1057 models to be our rendered image test set (validation set). Before extracting image features, we first resize the images to 112 × 112 pixels, and then divide it into 6 × 6 overlapped patch grid, with patch size\n32× 32 and patch stride 16 on both axes. After preprocessing, we extract a 576 dimensional HoG feature [2] from each patch, so the whole image can be represented by a 20736 dimensional feature vector. Those 64,000 feature vectors constituted our training dataset."
    }, {
      "heading" : "2.2 Test Data",
      "text" : "To comprehensively evaluate the performance of our learning algorithm, we built three different test sets with increasing level of test difficulty. They are rendered image test set, clean background real image test set and cluttered background real image test set.\nRendered image test set, as we mentioned in Sec. 2.1, consists of 1057×16 rendered images, which also comes from ShapeNet. Clean background and cluttered background real image test sets are collected from ImageNet [3], containing 1309 and 1000 images respectively, both with manually labeled ground truth of viewpoint. Some sample images are shown in Figure 3. Obviously, these three datasets are increasingly noisy and thus difficult to tackle.\nFor image preprocessing and feature extraction on the test sets, we used the same scheme as the train-\ning set. That is, convert each image into a 20736- dimensional HoG feature."
    }, {
      "heading" : "3 Model",
      "text" : "Rather than using global image feature as the input of classification, our pose estimation model is patch-based. By dividing image into patches and training a classifier for each patch, our model can be more robust to occlusion and background noise. Also, this approach reduced the feature dimension for each classifier, thus reduced the sample complexity. Actually, we did try global features, while the classification accuracy is 30% lower than patch based method on clean background test set, shown in Table 1. The mathematical representation of our patch based model is as follows.\nDefine Fi as the HoG feature of patch i, I = (F1, · · · , FN2) to be the HoG feature of the whole image, V = {1, · · · , V } to be the discretized pose space. For each patch, we build a classifier, which learns from training data, and gives a prediction of the conditional probability P (v|Fi). To respresent P (v|I) in P (v|Fi), i = 1, · · · , N2, we\nassume P (v|I) ∝ N2∏ i=1 P (v|Fi). So, we can calculate P (v|I) and the according v̄ using the following formula:\nP (v|I) =\nN2∏ i=1 P (v|Fi)\nV∑ v=1 N2∏ i=1 P (v|Fi)\nv̄ = arg max v\nP (v|I)\nIn sum, our model takes Fi, i = 1, · · · , N2 as input, and outputs P (v|I) and v̄."
    }, {
      "heading" : "4 Methods",
      "text" : ""
    }, {
      "heading" : "4.1 Learning Algorithms",
      "text" : ""
    }, {
      "heading" : "4.1.1 Random Forest",
      "text" : "In this project, we choose random forest [1] as a primary classification algorithm based on its following advantages:\n• Suitable for multiclass classification.\n• Non-parametric, easy to tune.\n• Fast, easy to parallel.\n• Robust, due to randomized processing.\nDuring classification, 36 random forest classifiers are trained for 36 patches. As a trade off between spatio-temporal complexity and performance, we set the forest size to be 100 trees. We also tuned the maximum depth of trees using cross-validation, where the optimal depth is 20. As a result, each random forest outputs a probability vector P (v|Fi). After Laplace smoothing, we calculated P (v|I), estimated the pose to be v̄ = arg max\nv P (v|I)."
    }, {
      "heading" : "4.2 Optimization",
      "text" : "Constructing training dataset from rendered images has many advantages, but there are also drawbacks. As I mentioned in Section 1, the prior probability of pose in real images can be highly different from that in rendered images. As we know, pose distribution in the training set is uniform, however, in real images, there are far more front view chairs than back view. Fortunately, this difference can be analyzed and modeled as follows."
    }, {
      "heading" : "4.2.1 Probability Calibration",
      "text" : "In classification step, each classifier Ci will output a probability vector P̃ (v|Fi). Using Bayesian formula, we have:\nP̃ (v|Fi) = P̃ (v)P̃ (Fi|v)\nP̃ (Fi)\nAlthough we may not learn P̃ (v), P̃ (F |v) and P̃ (F ) explicitly when training, we can use them to indicate the statistical property of training data. Whereas, the real P (v|Fi), which satisfies the following formula, could be different from P̃ (v|Fi). Here, P (v), P (Fi|v) and P (Fi) are statistical properties of the test set.\nP (v|Fi) = P (v)P (Fi|v)\nP (Fi)\nAssume the training data and the test data have at least some similarity. Specifically speaking, assume P (Fi|v) = P̃ (Fi|v), P (Fi) = P̃ (Fi), then we have:\nP (v|Fi) = P̃ (v|Fi) P (v)\nP̃ (v) ∝ P̃ (v|Fi)P (v)\nTo recover P (v|Fi), we just need to achieve a good estimation of P (v). One possible method might be randomly choosing some samples from the test set, and manually label the ground truth of viewpoint,\nregard the ground truth pose distribution of samples as an estimation of overall P (v). However, we still need to do some “labor work” — labeling.\nNoticing the above formula can also be written as:\nP (v|Fi) P (v) = P̃ (v|Fi) P̃ (v) ; P̃ (v) = 1 V , ∀v ∈ V\nwe came up with another idea to automatically improve the classification result. For P̃ (v|Fi), we have:\nP (v) > 1\nV ⇒ P̃ (v|Fi) < P (v|Fi)\nP (v) < 1\nV ⇒ P̃ (v|Fi) > P (v|Fi)\nThat means, when testing, frequently appeared poses are underestimated, while uncommon poses are overestimated. Here, we propose an iterative method to counterbalance this effect. Basically, we will use P̃ (v|Fi) to generate an estimation P̃ (v) of the prior distribution; assume P (v) and P̃ (v) have similar common views and uncommon views (in other words, P (v) and P̃ (v) have the same trend); smooth P̃ (v) to keep the trend while reduce fluctuation range; multiply the original P̃ (v|Fi) by smoothed P̃ (v); and iteratively repeat the above steps. Finally, due to the damping effect in combination step, P̃ (v) will converge, and P̃ (v|Fi) gets closer to P (v|Fi). Formulation of this iterative algorithm is as follows:\n1. Calculate P̃ (v|I(j)), j = 1, · · · ,m.\nP̃ (v|I(j)) =\nN2∏ i=1 P̃ (v|F (j)i )\nV∑ v=1 N2∏ i=1 P̃ (v|F (j)i )\n2. Accumulate P̃ (v|I(j)) on all test samples to calculate P̃ (v).\nP̃ (v) = 1\nm m∑ j=1 P̃ (v|I(j))\n3. Smooth P̃ (v) by factor α.\nP̃s(v) = P̃ (v) + α\n1 + 16α\n4. Estimate P (v|Fi) by letting:\nP̄ (v|Fi) = P̃ (v|Fi)P̃s(v)\n5. Use P̄ (v|Fi) to re-calculate P̃ (v|I(j)) in step 1, while remain P̃ (v|Fi) in step 4 unchanged, repeat the above steps."
    }, {
      "heading" : "4.2.2 Parameter Automatic Selection",
      "text" : "After several iterations, the algorithm will converge, and we’ll get a final estimation P̄ (v|Fi) of P (v|Fi). However, different α will lead to far different converging results, as shown in Figure 4. From experiment results in Figure 5 we observed that if α is too small, viewpoint with the highest initial probability P̃ (v) will soon beat other viewpoints, and P̃ (v) converges to a totally biased distribution. While, if α is too large, smoothing effect is too strong to influence P̄ (v|Fi), resulting in P̄ (v|Fi) = P̃ (v|Fi). However, there exists an intermediate value of α to maximize the classification accuracy and lead to an optimal estimation P̄ (v|Fi). In Figure 4 and 5, αopt is 0.8.\nTo solve the optimal α, we conducted deep analysis to the relationship between stable P̃ (v) and α. We found three patterns of relationship between P̃ (vj) and α, shown in Figure 6. For some viewpoints, P̃ (v) is almost monotonically increasing with respect to α, such as blue curves, some are monotonically decreas-\ning, such as the black curve, while others will decrease after first increase, such as the red curves. Recall the distribution change with respect to α in Figure 5, we found P̃ (v) will first approximate P (v) then be smoothed. Therefore, patterns with turning points are good reflection of this trend. Sum on those components, we get Figure 7, and take the turning point of the curve as our estimated ᾱ. Here ᾱ is 1, very close the optimal value αopt = 0.8."
    }, {
      "heading" : "5 Results",
      "text" : ""
    }, {
      "heading" : "5.1 Classification Performance",
      "text" : "In Table 1, our patch based random forest classification algorithm (denoted as RF) shows a promising\nclassification results on all three test sets. Under our scheme, random forest achieves 80% accuracy on clean background real image test set, and 77% on cluttered background test set. After calibrating the conditional probability P̃ (v|Fi) using automatically selected α (denoted as RFopt), performance on clean test set is boosted by 8%, as well 2% on cluttered set. The relatively low improvement on cluttered test set may result from our assumption of P̃ (Fi|v) = P (Fi|v) and P̃ (Fi) = P (Fi) are too strong for cluttered images.\nRow “RFGT” shows the result of calibrating P̃ (v|Fi) using ground truth P (v). Compared to our optimization approach, the accuracy is only 2% higher, indicating the effectiveness of our method.\nBesides, the “Global” row shows a terrible classification performance on global image features. Although it achieves best result on rendered images, performance drops significantly when testing on real images. One possible explanation might be that global classifier overfittingly learned the importance of patches from training set, while patch importance on real images is different. Figure 8 verified this hypothesis. In contrast, patch based method gives equal importance to all patches, hence reduced overfitting.\nFigure 9 shows the confusion matrix on three test sets respectively. From left to right, as test difficulty increases, confusion matrix becomes increasingly scattered. On rendered image test set, an in-\nteresting phenomenon is that some poses are often misclassified to poses with 90◦ difference with them, one possible explanation is that the shape of some chairs are like a square. Also, front view and backview are often misclassified, because they have similar appearance in feature space."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we proposed a novel pose estimation approach — learn from 3D models. We explained our model in Bayesian framework, and raised a new optimization method to transmit information from 2D images to 3D models. The promising experiment results verified the effectiveness of our scheme."
    }, {
      "heading" : "7 Future Work",
      "text" : "We have several ideas for the future work, described as follows:\n• Take into consideration the foreground and background information in the image, fully utilize the information in rendered images.\n• Further model the difference between three datasets, revise our inaccurate assumption.\n• Learn the discriminativeness of patches, give different weight for different patches.\n• Generalize our algorithm to occluded images, or different categories, see what will happen."
    } ],
    "references" : [ {
      "title" : "Random forests.",
      "author" : [ "Breiman", "Leo" ],
      "venue" : "Machine learning",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2001
    }, {
      "title" : "Histograms of oriented gradients for human detection.",
      "author" : [ "Dalal", "Navneet", "Bill Triggs" ],
      "venue" : "Computer Vision and Pattern Recognition,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2005
    }, {
      "title" : "Imagenet: A large-scale hierarchical image database.",
      "author" : [ "Deng", "Jia" ],
      "venue" : "Computer Vision and Pattern Recognition,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "Scikit-learn: Machine learning in Python.",
      "author" : [ "Pedregosa", "Fabian" ],
      "venue" : "The Journal of Machine Learning Research",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2011
    }, {
      "title" : "Point matching as a classification problem for fast and robust object pose estimation.",
      "author" : [ "Lepetit", "Vincent", "Julien Pilet", "Pascal Fua" ],
      "venue" : "Computer Vision and Pattern Recognition,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2004
    }, {
      "title" : "Pose estimation from corresponding point data.",
      "author" : [ "Haralick", "Robert M" ],
      "venue" : "Systems, Man and Cybernetics, IEEE Transactions on 19.6",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1989
    }, {
      "title" : "New algorithms for 2d and 3d point matching:: pose estimation and correspondence.",
      "author" : [ "Gold", "Steven" ],
      "venue" : "Pattern Recognition",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1998
    }, {
      "title" : "3D generic object categorization, localization and pose estimation.",
      "author" : [ "Savarese", "Silvio", "Fei-Fei Li" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2007
    }, {
      "title" : "A multi-view probabilistic model for 3d object classes.",
      "author" : [ "Sun", "Min" ],
      "venue" : "Computer Vision and Pattern Recognition,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2009
    }, {
      "title" : "Pose estimation for category specific multiview object localization.",
      "author" : [ "Ozuysal", "Mustafa", "Vincent Lepetit", "Pascal Fua" ],
      "venue" : "Computer Vision and Pattern Recognition,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2009
    }, {
      "title" : "Object detection with discriminatively trained part-based models.",
      "author" : [ "Felzenszwalb", "Pedro F" ],
      "venue" : "Pattern Analysis and Machine Intelligence, IEEE Transactions on 32.9",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2010
    }, {
      "title" : "Deformable part models revisited: A performance evaluation for object category pose estimation.",
      "author" : [ "Lopez-Sastre", "Roberto Javier", "Tinne Tuytelaars", "Silvio Savarese" ],
      "venue" : "Computer Vision Workshops (ICCV Workshops),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2011
    }, {
      "title" : "Discriminative mixture-of-templates for viewpoint classification.",
      "author" : [ "Gu", "Chunhui", "Xiaofeng Ren" ],
      "venue" : "VisionECCV",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2010
    }, {
      "title" : "Is 2D Information Enough For Viewpoint Estimation?.",
      "author" : [ "Ghodrati", "Amir", "Marco Pedersoli", "Tinne Tuytelaars" ],
      "venue" : "Proceedings of the British Machine Vision Conference. BMVA Press. Vol. 2. No",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2014
    }, {
      "title" : "All together now: Simultaneous object detection and continuous pose estimation using a hough forest with probabilistic locally enhanced voting.",
      "author" : [ "Redondo-Cabrera", "Carolina", "Roberto Lpez- Sastre", "Tinne Tuytelaars" ],
      "venue" : "Proceedings BMVC",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2014
    }, {
      "title" : "Learning a dense multi-view representation for detection, viewpoint classification and synthesis of object categories.",
      "author" : [ "Su", "Hao" ],
      "venue" : "Computer Vision,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2009
    }, {
      "title" : "Distinctive image features from scale-invariant keypoints.",
      "author" : [ "Lowe", "David G" ],
      "venue" : "International journal of computer vision",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2004
    }, {
      "title" : "3d2pm3d deformable part models.",
      "author" : [ "Pepik", "Bojan" ],
      "venue" : "VisionECCV",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2012
    }, {
      "title" : "Detailed 3d representations for object recognition and modeling.",
      "author" : [ "Zia", "M. Zeeshan" ],
      "venue" : "Pattern Analysis and Machine Intelligence, IEEE Transactions on 35.11",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2013
    }, {
      "title" : "Analyzing 3d objects in cluttered images.",
      "author" : [ "Hejrati", "Mohsen", "Deva Ramanan" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Among 2D based researches, [6,7,8] rely on point matching, which is now outdated.",
      "startOffset" : 27,
      "endOffset" : 34
    }, {
      "referenceID" : 5,
      "context" : "Among 2D based researches, [6,7,8] rely on point matching, which is now outdated.",
      "startOffset" : 27,
      "endOffset" : 34
    }, {
      "referenceID" : 6,
      "context" : "Among 2D based researches, [6,7,8] rely on point matching, which is now outdated.",
      "startOffset" : 27,
      "endOffset" : 34
    }, {
      "referenceID" : 7,
      "context" : "By linking together diagnostic parts of object from different views, [9] represents an object category as a collection of view-invariant regions.",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 8,
      "context" : "[10] and Su et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "[17] used a generative approach to group local features into parts and then learn part locations across viewpoints.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 9,
      "context" : "[11] used a SIFT-like [18] spatial pyramids of histograms feature to train a SVM classifier for each discrete pose.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[11] used a SIFT-like [18] spatial pyramids of histograms feature to train a SVM classifier for each discrete pose.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 10,
      "context" : "Inspired by Deformable Part Model’s [12] success, [13] trained a DPM using a semi-latent approach, where the components correspond to discrete viewpoints.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 11,
      "context" : "Inspired by Deformable Part Model’s [12] success, [13] trained a DPM using a semi-latent approach, where the components correspond to discrete viewpoints.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 13,
      "context" : "[15] used convolutional neural network features for the task of pose estimation.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "[16] proposed a Hough Forest based method for simultaneous object detection and continuous pose estimation.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "[19] extended deformable part models to 3D, where part appearances and spatial deformations are represented in 3D.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "Using an readymade approach, [20] first obtained a rough localization and viewpoint of the object, and then estimated a continuous pose by using annotated 3D CAD models.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 19,
      "context" : "[21] estimated poses of cars using an explicit 3D shape model and viewpoint which is learned from structure-from-motion (SFM).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 1,
      "context" : "After preprocessing, we extract a 576 dimensional HoG feature [2] from each patch, so the whole image can be represented by a 20736 dimensional feature vector.",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 2,
      "context" : "Clean background and cluttered background real image test sets are collected from ImageNet [3], containing 1309 and 1000 images respectively, both with manually labeled ground truth of viewpoint.",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "1 Random Forest In this project, we choose random forest [1] as a primary classification algorithm based on its following advantages: • Suitable for multiclass classification.",
      "startOffset" : 57,
      "endOffset" : 60
    } ],
    "year" : 2015,
    "abstractText" : "This project aims to estimate the pose of an object in the image. Pose estimation problem is known to be an open problem and also a crucial problem in computer vision field. Many real-world tasks depend heavily on or can be improved by a good pose estimation. For example, by knowing the exact pose of an object, robots will know where to sit on, how to grasp, or avoid collision when walking around. Besides, pose estimation is also applicable to automatic driving. With good pose estimation of cars, automatic driving system will know how to manipulate itself accordingly. Moreover, pose estimation can also benefit image searching, 3D reconstruction and has a large potential impact on many other fields.",
    "creator" : "LaTeX with hyperref package"
  }
}