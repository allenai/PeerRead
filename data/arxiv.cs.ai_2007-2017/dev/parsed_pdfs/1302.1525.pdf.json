{
  "name" : "1302.1525.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Incremental Pruning: A Simple, Fast, Exact Method for Partially Observable Markov Decision Processes",
    "authors" : [ "Anthony Cassandra", "Nevin L. Zhang" ],
    "emails" : [ "arc@cs.brown.edu", "lzhang@cs." ],
    "sections" : null,
    "references" : [ {
      "title" : "Acting optimally in partially observ­",
      "author" : [ "A.R. Cassandra", "L.P. Kaelbling", "M.L. Littman" ],
      "venue" : null,
      "citeRegEx" : "Cassandra et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Cassandra et al\\.",
      "year" : 1994
    }, {
      "title" : "Algorithms for Partially Observ­",
      "author" : [ "Cheng", "H.-T" ],
      "venue" : null,
      "citeRegEx" : "Cheng and H..T.,? \\Q1988\\E",
      "shortCiteRegEx" : "Cheng and H..T.",
      "year" : 1988
    }, {
      "title" : "Reinforcement learning with",
      "author" : [ "L. Chrisman" ],
      "venue" : null,
      "citeRegEx" : "Chrisman,? \\Q1992\\E",
      "shortCiteRegEx" : "Chrisman",
      "year" : 1992
    }, {
      "title" : "Cost-effective sensing dur­",
      "author" : [ "E.A. Hansen" ],
      "venue" : null,
      "citeRegEx" : "Hansen,? \\Q1994\\E",
      "shortCiteRegEx" : "Hansen",
      "year" : 1994
    }, {
      "title" : "Efficient dynamic-programming updates",
      "author" : [ "M.L. Littman", "A.R. Cassandra", "L.P. Kaelbling" ],
      "venue" : null,
      "citeRegEx" : "Littman et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Littman et al\\.",
      "year" : 1996
    }, {
      "title" : "Overcoming incomplete per­",
      "author" : [ "R.A. McCallum" ],
      "venue" : null,
      "citeRegEx" : "McCallum,? \\Q1993\\E",
      "shortCiteRegEx" : "McCallum",
      "year" : 1993
    }, {
      "title" : "A survey of partially observ­ able Markov decision processes: Theory, models, and algorithms",
      "author" : [ "G.E. Monahan" ],
      "venue" : "Management Science 28(1):1-16.",
      "citeRegEx" : "Monahan,? 1982",
      "shortCiteRegEx" : "Monahan",
      "year" : 1982
    }, {
      "title" : "Approximating op­ timal policies for partially observable stochastic do­ mains",
      "author" : [ "R. Parr", "S. Russell" ],
      "venue" : null,
      "citeRegEx" : "Parr and Russell,? \\Q1995\\E",
      "shortCiteRegEx" : "Parr and Russell",
      "year" : 1995
    }, {
      "title" : "A feasible computational ap­ proach to infinite-horizon partially-observed Markov decision problems",
      "author" : [ "K." ],
      "venue" : "Technical report, Georgia Insti­ tute of Technology, Atlanta, GA. Russell, S. J., and Norvig, P. 1994. Artificial Intel­",
      "citeRegEx" : "K.,? 1981",
      "shortCiteRegEx" : "K.",
      "year" : 1981
    }, {
      "title" : "Optimal control for partially observable Markov decision processes over an infinite horizon",
      "author" : [ "K. Prentice-Hall. Sawaki", "A. Ichikawa" ],
      "venue" : "ligence: A Modern Approach",
      "citeRegEx" : "Sawaki and Ichikawa,? \\Q1978\\E",
      "shortCiteRegEx" : "Sawaki and Ichikawa",
      "year" : 1978
    }, {
      "title" : "The opti­ mal control of partially observable Markov processes over a finite horizon. Operations Research 21:10711088",
      "author" : [ "R.D. Smallwood", "E.J. Sondik" ],
      "venue" : null,
      "citeRegEx" : "Smallwood and Sondik,? \\Q1973\\E",
      "shortCiteRegEx" : "Smallwood and Sondik",
      "year" : 1973
    }, {
      "title" : "The Optimal Control of Partially Observable Markov Processes",
      "author" : [ "E. Sondik" ],
      "venue" : "Ph.D. Dissertation, Stanford University. Sondik, E. J. 1978. The optimal control of partially observable Markov processes over the infinite horizon:",
      "citeRegEx" : "Sondik,? 1971",
      "shortCiteRegEx" : "Sondik",
      "year" : 1971
    }, {
      "title" : "Solu­ tion procedures for partially observed Markov deci­ sion processes",
      "author" : [ "III White", "C.C.", "W.T. Scherer" ],
      "venue" : "Operations Research 37(5):791-797.",
      "citeRegEx" : "White et al\\.,? 1989",
      "shortCiteRegEx" : "White et al\\.",
      "year" : 1989
    }, {
      "title" : "Partially observed Markov decision processes: A survey",
      "author" : [ "III White", "C.C." ],
      "venue" : "Annals of Operations Research 32.",
      "citeRegEx" : "White and C.,? 1991",
      "shortCiteRegEx" : "White and C.",
      "year" : 1991
    }, {
      "title" : "Planning in stochas­ tic domains: Problem characteristics and approxi­ mation",
      "author" : [ "N.L. Zhang", "W. Liu" ],
      "venue" : "Technical Report HKUST-CS96-31, Depart­ ment of Computer Science, Hong Kong University of Science and Technology.",
      "citeRegEx" : "Zhang and Liu,? 1996",
      "shortCiteRegEx" : "Zhang and Liu",
      "year" : 1996
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "There are many ways to approach this prob­ lem based on checking which information states can be reached (Washington 1996; Hansen 1994), search­ ing for good controllers (Platzman 1981), and using dynamic programming (Smallwood & Sondik 1973; Cheng 1988; Monahan 1982; Littman, Cassandra, & Kaelbling 1996).",
      "startOffset" : 105,
      "endOffset" : 135
    }, {
      "referenceID" : 6,
      "context" : "There are many ways to approach this prob­ lem based on checking which information states can be reached (Washington 1996; Hansen 1994), search­ ing for good controllers (Platzman 1981), and using dynamic programming (Smallwood & Sondik 1973; Cheng 1988; Monahan 1982; Littman, Cassandra, & Kaelbling 1996).",
      "startOffset" : 217,
      "endOffset" : 306
    }, {
      "referenceID" : 11,
      "context" : "Several algorithms for dynamic-programming updates have been proposed, such as one pass (Sondik 1971), exhaustive (Monahan 1982), linear support (Cheng 1988), and witness (Littman, Cassandra, & Kaelbling 1996).",
      "startOffset" : 88,
      "endOffset" : 101
    }, {
      "referenceID" : 6,
      "context" : "Several algorithms for dynamic-programming updates have been proposed, such as one pass (Sondik 1971), exhaustive (Monahan 1982), linear support (Cheng 1988), and witness (Littman, Cassandra, & Kaelbling 1996).",
      "startOffset" : 114,
      "endOffset" : 128
    }, {
      "referenceID" : 6,
      "context" : "Several algorithms for dynamic-programming updates have been proposed, such as one pass (Sondik 1971), exhaustive (Monahan 1982), linear support (Cheng 1988), and witness (Littman, Cassandra, & Kaelbling 1996). Cheng (1988) gave experimental evidence that the linear support algorithm is more efficient than the",
      "startOffset" : 115,
      "endOffset" : 224
    }, {
      "referenceID" : 8,
      "context" : "Littman, Cassandra and Kael­ bling (1996) compared the exhaustive algorithm, the linear support algorithm, and the witness algorithm and found that, except for tiny problems with approx­ imately 2 observations or 2 states, which all three al­ gorithms could solve quickly, witness was the fastest and had a number of superior theoretical properties.",
      "startOffset" : 23,
      "endOffset" : 42
    }, {
      "referenceID" : 14,
      "context" : "Recently, Zhang and Liu (1996) proposed a new method for dynamic-programming updates in POMDPS called incremental pruning.",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 8,
      "context" : "The algorithm is due to Lark (White 1991); Littman, Cassandra, & Kaelbling (1996) analyze the algorithm and describe the way that the argmax op­ erators need to be implemented for the analysis to hold (ties must be broken lexicographically).",
      "startOffset" : 27,
      "endOffset" : 82
    }, {
      "referenceID" : 6,
      "context" : "sets from the s� sets was essentially proposed by Monahan (1982) (under the name of \"Sondik's one­ pass algorithm\").",
      "startOffset" : 50,
      "endOffset" : 65
    }, {
      "referenceID" : 6,
      "context" : "Equation 13 is equiv­ alent to using Monahan's (1982) filtering algorithm in lNCPRUNE, Equation 15 is equivalent to using Lark's filtering algorithm (W hite 1991) in lNCPRUNE (i.",
      "startOffset" : 37,
      "endOffset" : 54
    }, {
      "referenceID" : 6,
      "context" : "The first is numerical precision!Vtl Reference 4 436 Parr & Russell (1995) 4 Russell & Norvig (1994) 20 Cassandra, Kaelbling, & Littman (1994) 14 McCallum (1993) 9 Kushmerick, Hanks, & Weld (1995) 438 481 Chrisman (1992) 258",
      "startOffset" : 115,
      "endOffset" : 143
    }, {
      "referenceID" : 4,
      "context" : "The first is numerical precision!Vtl Reference 4 436 Parr & Russell (1995) 4 Russell & Norvig (1994) 20 Cassandra, Kaelbling, & Littman (1994) 14 McCallum (1993) 9 Kushmerick, Hanks, & Weld (1995) 438 481 Chrisman (1992) 258",
      "startOffset" : 146,
      "endOffset" : 162
    }, {
      "referenceID" : 4,
      "context" : "The first is numerical precision!Vtl Reference 4 436 Parr & Russell (1995) 4 Russell & Norvig (1994) 20 Cassandra, Kaelbling, & Littman (1994) 14 McCallum (1993) 9 Kushmerick, Hanks, & Weld (1995) 438 481 Chrisman (1992) 258",
      "startOffset" : 146,
      "endOffset" : 197
    }, {
      "referenceID" : 2,
      "context" : "The first is numerical precision!Vtl Reference 4 436 Parr & Russell (1995) 4 Russell & Norvig (1994) 20 Cassandra, Kaelbling, & Littman (1994) 14 McCallum (1993) 9 Kushmerick, Hanks, & Weld (1995) 438 481 Chrisman (1992) 258",
      "startOffset" : 205,
      "endOffset" : 221
    } ],
    "year" : 2011,
    "abstractText" : "Most exact algorithms for general par­ tially observable Markov decision processes (POMDPs) use a form of dynamic program­ ming in which a piecewise-linear and con­ vex representation of one value function is transformed into another. We examine vari­ ations of the \"incremental pruning\" method for solving this problem and compare them to earlier algorithms from theoretical and em­ pirical perspectives. We find that incremen­ tal pruning is presently the most efficient ex­ act method for solving POMDPs.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}