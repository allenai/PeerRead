{
  "name" : "1302.4983.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Causal Inference in the Presence of Latent Variables and Selection Bias",
    "authors" : [ "Peter Spirtes", "Christopher Meek", "Thomas Richardson" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 INTRODUCTION\nThere are well known problems with drawing causal inferences from samples that have not been randomly selected. Spirtes et al. (1993) showed that otherwise correct discovery algorithms fail even in the large sam ple limit when samples are selected on the basis of fea tures with certain causal connections to the variables under study. For instance, if X and Y are indepen dent in a population, but a sample is selected from the population using some value of a variable Z that happens to be influenced by X andY, then X andY will have a statistical dependency in the sample (pro duced by conditioning on Z), that they do not have in the population. Cooper (1995) has given a number of more interesting examples of this kind involving la tent variables. Methods of representing selection bias, and special cases where selection bias is detectable from data were discussed in Wermuth, Cox, and Pearl (1994). An important question is whether there are any general, informative and reliable procedures for discovering causal relations when, for all the investi gator knows, both latent variables and selection bias may be at work. When selection bias does not apply, there is an algorithm, FCI, that under assumptions de scribed below will (in the large sample limit) almost certainly give such information including information about the existence or non-existence of causal path-\nways from one measured variable to another (Spirtes et al. 1993). We have shown that under a reinterpre tation of the output, the FCI algorithm also applies when selection bias may be present, but the output is then generally less informative than in cases known to be free of selection bias. We have also shown, how ever, that given information about conditional inde pendence and dependence relations between measured variables, even when latent variables and selection bias may be present, there are sufficient conditions for re liably concluding that there is a causal path from one variable to another, and sufficient conditions for reli ably concluding when no such causal path exists.\nThroughout this paper, sets of variables are in bold face, and defined terms in italics. Graph theoretic terms are defined in the appendix. The FCI algorithm and proofs of its correctness are described in detail in Spirtes et al. (1993). Due to lack of space we will not describe the algorithm here. In the main body of this paper we focus on explaining the adaptations and reinterpretations that selection bias requires for the in terpretation of the output. The theorems given in the Appendix to this paper are proved by straightforward if tedious adaptations to the selection bias case of the proofs, given in Spirtes et al. (1993), of the correctness of the FCI algorithm without selection bias.\n2 DIRECTED ACYCLIC GRAPHS\nFactor analysis models, path models with independent errors, recursive linear structural equation models with independent errors, and various kinds of latent vari able models are all instances of directed acyclic graph models. A directed acyclic graph (DAG) G with a set of vertices V can be given both a causal interpreta tion and a statistical interpretation. (See Pearl 1988, where under the statistical interpretation DAG mod els are called Bayesian networks; Spirtes et al. 1993; Wright 1934.) Take \"A is a direct cause of B in a mem ber of the population with respect to a set of variables V\" as primitive. If V is a set of variables, there is an edge from A to B in a causal DAG G for a pop ulation with variables V if and only if A is a direct cause of B relative to V for some member of that pop-\n500 Spirtes, Meek, and Richardson\nulation. A DAG G with a set of vertices V can also represent a set of probability measures over V subject to restrictions relating allowable measures on V to the graphical structure of G. Following the terminology of Lauritzen et al. 1990 we say that a probability mea sure over a set of variables V satisfies the local directed Markov property for a DAG G with vertices V if and only if for every W in V, W is independent of the set of all its non-parental non-descendants conditional on the set of its parents.\n3 REPRESENTATION OF\nSELECTION BIAS\nWe distinguish two different reasons why a sample dis tribution may differ from the population distribution from which it is drawn. The first is simply the fa miliar phenomenon of sample variation, or as we shall say, sample bias: for a given population distribution, the parameter estimates made from a finite random sample of variables do not in general exactly equal the population parameters. The second reason is that causal relationships between variables in V, on the one hand, and the mechanism by which individuals in the sample are selected from a population, on the other hand, may lead to differences between the expected parameter values in a sample and the population pa rameter values. In this case we will say that the differ ences are due to selection bias. Sampling bias tends to be remedied by drawing larger samples; selection bias does not. We will not consider the problems of sam ple bias in this paper; we will always assume that we are dealing with an idealized selected subpopulation of infinite size, but one which may be selection biased.\nFor the purposes of representing selection bias, follow ing Cooper (1995) we assume that for each measured random variable A, there is a binary random variable SA that is equal to one if the value of A has been recorded for that member of the population, and is equal to zero otherwise. If V is a set of variables, we will always suppose that V can be partitioned into three sets: the set 0 (standing for observed) of mea sured variables, the set S (standing for selection) of selection variables for 0, and the remaining variables L (standing for latent). In the marginal distribution over a subset X of 0 in a selected subpopulation, the set of selection variables S has been conditioned on, since its value is always equal to 1 in the se lected subpopulation. Hence for disjoint subsets X,\nY, and Z of 0, we will assume that we cannot deter mine whether XilZIY, but that we can determine whether XilZIY U (S = 1). (XilZIY means X is independent of Z given Y. If Y is empty, we simply write XilZ. If the only member of X is X, then we write XilZIY instead of {X}ilZIY.) There may be cases in which all of the variables in S always take on the same value; in such cases we will represent the selection with a single variable S.\nThe three causal DAGs for a given population shown in Figure 1 illustrate a number of different ways in which selection variables can be related to non-selection vari ables. The causal DAG in (i) would occur, for example, if the members of the population whose X values were recorded and the members of the population whose Y values were recorded were randomly selected by flips of a pair of independent coins. The DAG in (ii) would occur if the flip of a single coin was used to choose units which would have both their X and Y values recorded (i.e. Sx = Sv and there are no missing val ues in the sample). The DAG in (iii) would occur if, for example, X is years of education, and people with higher X values respond to a questionnaire about their education - and thus appear in the sample - more often than people with lower X values. We do not pre clude the possibility that a variable Y can be a cause of Sx for some variable X \"# Y, nor do we preclude the possibility that Sx can be a cause of two different variables.\nTo draw correct causal conclusions about the unse lected subpopulation which we have not seen, or about the whole population part of which we have not seen, some assumptions must be made. First, consider the case where one is interested in causal inferences about the whole population from the selected subpopulation. The notion of a causal graph, as we have defined it is relative to a set of variables and a population. Hence the causal graph of the whole population and the causal graph of the selected sub population may be dif ferent. For example, if a drug has no effect on survival in men, but it does have an effect on women, then there is an edge from drug to survival in the causal graph of the population, but no edge from drug to survival in the causal graph of a subpopulation of men. Because of this, in order to draw causal conclusions about ei ther the population or the unselected subpopulation from the causal graph of the selected subpopulation, we will make the following assumption:\nPopulation Inference Assumption: If V is a set of variables, then the causal graph over V of the popula tion is identical with the causal graphs over V of the selected subpopulation and the unselected subpopula tion.\nWe make several additional assumptions relating prob ability distributions to causal relationships which we introduce with the following example. The first princi ple simply states that in a causal DAG each variable is independent of its non-descendants (i.e. the variables it does not affect even indirectly) given its parents (i.e.\nCausal Inference in the Presence of Latent Variables and Selection Bias 501\nA A B A B\n(i) (ii) (iii)\nFigure 2: Representing selection bias\nits direct causes). However, it is important to realize that this principle does not apply to arbitrary sets of variables or to arbitrary subpopulations, as the fol lowing example shows. Let Pop' be a subpopulation of a population Pop, such that every member of Pop' is assigned the value S = 1. Suppose that (i) and (ii) in Figure 2 ate correct causal DAGs for Pop' (al though (ii) is more detailed), and that (iii) of Figure 2 is a correct causal DAG for Pop. (In figures we place latent variables in boxes and selection variables in cir cles.) Also suppose that A and B are dependent in both Pop' and Pop, but that A and B are dependent given T in Pop' but not in Pop.\n(i) of Figure 2 is a correct causal DAG because A is not a direct cause of B and B is not a direct cause of A. Note however, that it is incomplete, because it does not show that there is a latent common cause of A and B. Moreover, it is so incomplete that the local directed Markov Property does not hold for (i) because A and B are dependent in Pop'. DAG (ii) of Figure 2 is a more detailed picture of the causal relations between A and B. However, it is not the case that the causal DAG for the set of variables { A,B, T} satisfies the local directed Markov Property for (ii) in Pop', because A and B are dependent given T in Pop'. (iii) of Figure 2 is a more detailed causal DAG than either (i) or (ii). Moreover, {A,B,T,S} does satisfy the local directed Markov Property for (iii) of Figure 2 because in the population Pop (i.e. where we do not condition on S), A and B are independent given T. So by including latent variables and expanding the population from Pop' to Pop, we eventually reach a point where we find a population and a distribution over the variables in that population satisfying the local directed Markov Property for the causal DAG for that set of variables.\nCausal Markov Assumption: For each population Pop' and set of variables V', there is a population Pop from which Pop' is selected by S, a set V 2 V' U S, a causal graph G of Pop over V, and a distribution P (V) in Pop that satisfies the local directed Markov property for G. (We call such a set V causally sufficient for Pop', Pop, and S.)\nThe Causal Markov Assumption is entailed by many causal models commonly found in the statistical litera ture, including all recursive structural equation model with independent errors. (For an introduction to linear recursive structural equation models see Bollen 1989.) The Causal Markov Assumption does not generally\nhold when there are causal interactions between differ ent members of the population (as opposed to causal interactions among properties of individual members of the population), nor does it generally hold in pop ulations with feedback.\nThe Causal Faithfulness Assumption basically states that any conditional independence relation true in the subpopulation is true for structural reasons (i.e. be cause of the DAG structure), rather than because of the particular parameterization of the DAG.\nCausal Faithfulness Assumption: If Pop' is a sub population of Pop selected by S, V is a set of causally sufficient variables, G is a causal graph for population Pop with variables V, and P(V) is the distribution of V in Pop, then for any disjoint X, Y, and Z in V, X.ll.ZIY U (S = 1) only if the Causal Markov As sumption and S = 1 entails X.ll.ZIY U (S = 1). (In this case we say that P(V) is faithful to G in Pop' selected by S.)\nThe Causal Faithfulness Condition may fail for a num ber of reasons. It could be that some conditional in dependence relation holds for some particular param eterizations of the DAG and not others, rather than because of the graphical structure. It may also be vi olated when there are deterministic relationships be-: tween variables. However, Spirtes et al. (1993) and Meek (1995) have shown that under natural param eterizations of the linear normal structural equation models and discrete Bayesian networks, the set of pa rameterizations that lead to violations of faithfulness have Lebesgue measure 0.\nThe justification of axioms similar to these (without the restriction to conditioning on S) is discussed in Spirtes et al. (1993). As shown in subsequent sections, these assumptions will allow us to draw reliable infer ences about the causal graph of the population from the conditional independence relations in the selected subpopulation. H a conditional independence relation is true in every distribution that satisfies the local di rected Markov property for DAG G, we say that G en tails the conditional independence relation; similarly, if a. conditional dependence relation is true in every dis tribution that is faithful to DAG G, we say that G entails the conditional dependence relation.\n4 EXAMPLES\nWe now consider several different sets of conditional in dependence and dependence relations, and what they can tell us about the causal DAGs that generated them, under a variety of different assumptions.1\nGiven a causal graph G over a set of variables V, we\n1For readers interested in following the examples in some detail, under our assumptions, the conditional in dependence relations entailed by a DAG are given by the d-separation relation. See Pearl 1988 for details.\n502 Spirtes, Meek, and Richardson\nwill say there is no selection bias if and only if for any three disjoint sets of variables X, Y, and Z included in V\\S, G entails XilZIY US if and only if G en tails XilZIY. (Note that this does not in general en tail that the distributions in the selected subpopulation and the population are the same; it just entails that the same conditional independence relations hold in both.) This happens, for example, when the variables in S are causally unconnected to any other variables in V. In that case, when we depict a DAG in a figure we will omit the variables in S, and edges which have an endpoint in S.\nFor a given DAG G, and a division of the variable set V of G into observed (0), selection (S), and latent (L) variables, we will write G(O,S,L). We assume that the only conditional independence relations that can be tested are XilZIY U (S = 1), where X, Z, andY are subsets of 02; we will call this the set of observ able conditional independence relations. If X, Y, and Z are included in 0, and XilZIY U (S = 1), then we say it is an observed conditional independence re lation. Cond(O) is a set of conditional independence relations among variables in 0. A DAG G(O,S,L) en tails Cond(O) just when for each X, Y, and Z in cluded in 0, it entails XilZIY U (S = 1) if and only if XilZIY is in Cond(O). (Note that 0 is the same for all DAGs that entail Cond(O), but S is not. This is because we are allowing some DAGs to collapse multi ple selection variables into a single selection variable.) We will simply write Cond when the context makes it clear what 0 is. However, there may be many dif ferent DAGs that entail exactly the same Cond; the set of all DAGs that entail a given Cond we will call Equiv(Cond).\nImagine now that a researcher does not know what the correct causal DAG is, but can determine what Cond is, perhaps by performing hypothesis tests of conditional independence relations on the selected sub population. (As we will see later, because many of the members of Cond entail other members of Cond, only a fraction of the membership of Cond actually need be tested.) From this information alone, and the Causal Markov Assumption, the Causal Faithfulness Assumption, and the Population Inference Assump tion, the most he or she could conclude is that the true causal DAG is either Gt (O,St,LI) or G2(0,S2,L2) or Gs(O,S3,L3) or G4(0,S4,L4), etc., i.e. the true causal DAG is some member of Equiv(Cond). If Equiv(Cond) is large, then this information by itself is not very in teresting, unless the members of Equiv(Cond) all share some important features in common. However, as the following examples show, in some cases the members of Equiv(Cond) do share important features in common.\n2We are looking only at the subpopulation where all of the variables in 0 have recorded values. A more compli cated story could be told if when considering conditional independence relations among X, Z, andY we looked only at subpopulations where just the selection variables corre sponding to X, Z, and Y have values equal to 1.\nOur strategy, which is a generalization of the strat egy without selection bias described in Spirtes et al. (1993), will be to construct from Cond a graphical object called a partially oriented inducing path graph (POIPG), using the Causal Markov Assumption, the Causal Faithfulness Assumption, and the Population Inference Assumption. The POIPG (described in more detail in the examples and the Appendix) represents certain features that all of the DAGs in Equiv(Cond) share in common.3 From the constructed POIPG it is sometimes possible to infer that all of the DAGs in Equiv(Cond) share some other interesting features in common, e.g. they might all contain a directed path from A to B. If this is the case, then although from Cond we cannot tell exactly which DAG in Equiv(Cond) is the true causal DAG, because we know that all of the DAGs in Equiv( Cond) contain a directed path from A to B we can reliably conclude that in the true causal DAG A is a (possibly indirect) cause of B. This strategy is represented schematically in Figure 3. In the following examples we will apply this strategy to particular sets of observed conditional independence relations, and show what features of DAGs can be re liably inferred.\n4.1 Example 1\nWe will start out with a very simple example, in which the set of observed conditional independence relations is not very informative. (For simplicity, in all of the following examples we assume that all of the variables in S take on the same value, and hence can be repre sented by a single variable S.) Let 0 = {A,B}. and the set Condl of observed conditional independence relations is empty, i.e. Condl = 0. We now want to find out what DAGs are in Equiv(Condl). Let V be a set of causally sufficient variables. The simplest ex ample of such a DAG is when V = 0 = {A,B} and there is no selection bias. (That V = 0 and there is no selection bias is typically either an assumption or comes from background knowledge, since it is not in general possible to definitively confirm these condi-\n3POIPG s are generalizations of structures described (but not named) in Verma and Pearl1991 , and share some features in common with the representation scheme used in Wermuth, Cox, and Pearl 1994.\nCausal Inference in the Presence of Latent Variables and Selection Bias 503\ntions from the data alone.) Under these assumptions there are exactly two DAGs that entail Condl, labeled (i) and (ii) in Figure 4. In general, when there are no latent variables and no selection bias, there is an edge between A and B if and only if for all subsets X of 0\\ {A,B}, A and B are dependent given X U (S = 1).\nNow suppose that there are latent variables but no selection bias. Then, if we do not limit the number of latent variables in a DAG, there are an infinite number of DAGs that entail Condl, many of which do not contain an edge between A and B. Two such DAGs are shown in (iii) and (vi) of Figure 4. The examples in (iii) and (vi) of Figure 4 show that when there are latent variables it is not the case that there is an edge between A and B if and only if for all subsets X of 0\\ {A,B}, A and B are dependent given XUS. (Recall that if there is no selection bias that A and B are dependent given X U S if and only if A and B are dependent given X.)\nFinally, let us consider the case where there is selection bias. Examples of such DAGs in Equiv(Condl) are shown in (iv) and (v) of Figure 4.\nThe DAGs in Equiv(Condl) seem to have little in com mon, particularly when there is the possibility of both latent variables and selection bias. While there is a great variety of DAGs in Equiv(Condl), it is not the case that every DAG is in Equiv(Condl). For exam ple, a DAG G(O,S,L) with no edges at all is not in Equiv(Condl).\nIn Equiv(Condl), for each subset X of 0, A and B are dependent given X U S (in this example X is just the empty set). In general, for any 0, there is a simple graphical characterization of this condition. A DAG G(O,S,L) entails that for each subset X of 0, A and B are dependent given X U S if and only if a certain kind of undirected path between A and B exists in G(O,S,L). This undirected path is called an inducing path. U is an inducing path between A and B in 0 in DAG G( O,L,S) if and only if U is an acyclic undirected path between A and B such that every collider on U has a descendant in { A,B} US, and no non-collider on U except for the endpoints is in 0 U S. (A vertex V is a collider on an undirected path U if and only if two adjacent edges on U are into V, i.e. there exist variables X and Y on U, such that X ---+ V +---Y is a subpath of U.)\nThe orientation of an inducing path with endpoints X and Y is determined by whether or not the edges on the inducing path containing X and Y have arrow heads at X andY respectively. There are four possible orientations of inducing paths between A and B, all of which are shown in Figure 4. There are inducing paths that are out of A and out of B (e.g. the inducing path A ---+ S +---B in (iv)), inducing paths that are out of A and into B (e.g. the inducing path A ---+ B in (i) and the inducing path A ---+ S +--- T ---+ B in (v)), inducing paths that are out of B and into A (e.g. the inducing path B ---+ A in (ii)), and inducing paths that are into\nA and into B (e.g. the inducing path A +--- T ---+ B in (iii) and the inducing paths A +--- T ---+ B and A +--- U ---+ B in (vi)). Hence, if Condl is observed, it is possible to tell that there is an inducing path between A and B, but not what the orientation of the inducing path is. We represent this information in a partially oriented inducing path graph with the edge A o-o B. The fact that A and B are adjacent in the POIPG means that there is an inducing path between A and B; the \"o\" on each end of the edge means that we cannot tell what the orientation of the inducing path is. The existence and orientation of inducing paths is typically not par ticularly interesting information about the DAGs in Equiv(Condl). Can we tell anything more interesting about the causal relationship between A and B from the POIPG? In this case, the answer is no; however, the next example shows a case where more interesting conclusions can be drawn.\n4.2 Example 2\nLet 0 = {A,B,C,D} and Cond2 = {Dil {A,B}I {C}, A liB} and all of the other conditional indepen dence relations entailed by these. The only DAG in Equiv(Cond2) with no latent variables and no selec tion bias is (i) in Figure 5.\nNow suppose that we consider DAGs with latent vari ables so V \"I- 0, but there is no selection bias. In that case if there is no upper limit to the number of latent variables allowed, then there are an infinite number of DAGs in Equiv(Cond2), several of which are shown in (ii), (iii) and (iv) of Figure 5.\nSuppose that we now consider DAGs with selection bias. (v) and (vi) of Figure 4.2 are examples of DAGs that are in Equiv(Cond2) and have selection bias.\nIs there anything that all of the DAGs in Figure 4.2 have in common? There are no inducing paths be tween the pairs (A,D), (B,D) or (A,B) in any of the DAGs in Equiv( Cond2) because for each of these pairs there is a subset X of 0 such that they are indepen dent conditional on X U S. This is represented in the POIPG by the lack of edges between A and D, between B and D, and between A and B. Because for each sub set X of 0, A and C are dependent conditional on X U S, we can conclude that there is an inducing path between A and C. Moreover, in the DAGs in Figure 5 while some of the inducing paths are out of A, and others are into A, note that they are all into C. It can be shown that all of the inducing paths between A and C in all of the DAGs in Equiv(Cond2) are into C. In the POIPG representing Equiv(Cond2) we represent this by A o-t C. A and C are adjacent in the POIPG because there is an inducing path between A and C. The \"o\" on the A end of the edge means we cannot tell the orientation of the A end of the inducing path between A and C; the \">\" on the C end of the edge means that all of the inducing paths between A and C in all of the DAGs in Equiv(Cond2) are into C. It is also the case that all of the DAGs in Figure 5 have\n504 Spirtes, Meek, and Richardson\ninducing paths between C and D that are out of C and into D. It can be shown that all of the inducing paths between C and D in all of the DAGs in Equiv(Cond2) are out of C and into D. These facts are represented in the POIPG by the edge between C and D having a \">\" at the D end and a \"-\" at the C end.\nIt can be shown from the fact that the POIPG contains the edge C --t D that there is a directed path from C to D that does not contain any member of S in every DAG in Equiv(Cond2), i.e. C is a (possibly indirect) cause of D. It can also be shown that the POIPG of Equiv(Cond2) entails that there are no directed paths from D to A or from D to B in any of the DAGs in Equiv(Cond2), i.e. D is not a cause (either direct or indirect) of either A or B.\n4.3 Example 3\nFinally, consider an example in which 0 = {A,B,C,D}, and Cond3 = {Dil {A,B}, Ail {C,D}} and all of the other conditional independence relations entailed by these. There is no DAG in Equiv(Cond3) in which V = 0. Hence we can conclude that each DAG in Equiv(Cond3) either contains a latent variable. (i)\nand (ii) of Figure 6 are examples of DAGs with latent variables in Equiv(Cond3). Note that in each of them, there is a latent common cause of B and C, C is not a descendant of B, and B is not a descendant of C. As long as there is no selection bias, these properties can be shown to hold of any DAG in Equiv(Cond3).\nSuppose now that we also consider DAGs with selec tion bias. (iii) of Figure 6 is an example of a DAG with selection bias that is in Equiv(Cond3). Note that the inducing paths between B and C are into B and into C in every DAG in Figure 6; this can be shown to be the case for every inducing path between B and C in every DAG in Equiv(Cond3). Hence in the POIPG we have an edge B B C. Note that (iii) in Figure 6 does not contain a latent common cause of C and B. However, in each of the DAGs in Equiv(Cond3) C is not a descendant of B, and B is not a descendant of C; these properties can be shown to hold of any DAG in Equiv(Cond3), even when there are latent variables and selection bias. Hence if the conditional indepen dence relations in Cond3 are ever observed, it can be reliably concluded that even though there may be la tent variables and selection bias, and regardless of the causal connections of the latent variables and selection\nCausal Inference in the Presence of Latent Variables and Selection Bias 505\nvariables to other variables, in the causal DAG that generated Cond3, B is not a direct or indirect cause of C and C is not a direct or indirect cause of B.\n5 AN ALGORITHM FOR\nCONS TRUCTING POIPGs\nWe have seen that a POIPG contains valuable infor mation about the causal relationships between vari ables. However, the number of observable conditional independence relations grows exponentially with the number of members of 0. In addition, some of the in dependence relations are conditional on large sets of variables, and often these cannot be reliably tested on reasonable sample sizes. Is it possible to construct a POIPG?\nThe FCI algorithm (Spirtes et al. 1993) constructs correct POIPGs, under the Causal Markov Assump tion, the Causal Faithfulness Assumption, the assump tions of no selection bias, and that independence rela tions can be reliably tested. If the possibility of selec tion bias is allowed, the algorithm described in Spirtes et al. (1993) still gives the correct output, but the con clusions that one can draw from the POIPG are the slightly weaker ones described in the examples and the Appendix to this paper. In the worst case the FCI al gorithm is exponential time in the number of variables, even when the maximum number of vertices any given vertex is adjacent to is held fixed. However, on sim ulated data the algorithm can often be run on up to 100 variables provided the true graph is sparse. This is because it is not necessary to examine the entire set of observable conditional independence relations; many conditional independence relations are entailed by other conditional independence relations. The FCI algorithm relies on this fact to test a relatively small set of conditional independence relations, and test in dependence relations conditional on as few variables as possible.\n6 APPENDIX\nA directed graph is an ordered pair (V ,E) of vertices V and edges E, where each edge is an ordered pair of distinct vertices. The ordered pair (A,B) is an edge from A to B and is out of A and into B. If there is an edge from A to B then A is a parent of B. If there is an edge from A to B or from B to A, then A and B are adjacent. An undirected path between X1 and Xn in directed graph G is a sequence of vertices (X 1, ... , Xn) such that for 1 � i < n, xi and xi+1 are adjacent in G. Xi is a collider on undirected path U if and only if there are edges from Xi-1 and Xi+I to Xi on U. An undirected path U between X1 and Xn is into (out of) x1 if and only if the edge on u between xl and X2 is into (out of) X1, and similarly for Xn. A directed path from X1 to Xn in directed graph G is a sequence of vertices (X1, ... , Xn) such that for 1 � i < n, there is a directed edge from Xi to Xi+I in G. (A path may consist of a single vertex.) A path (directed or undirected) is acyclic if and only if it contains no vertex more than once. A directed graph is acyclic if every directed path in directed graph G is acyclic. A is an ancestor of B and B is a descendant of A if and only if A = B or there is a directed path from A to B.\nTheorem 1 generalizes results of Verma and Pearl (1991).\nTheorem 1 A DAG G(O,S,L) entails that for all subsets X of 0, A is dependent on B given (X U S) \\ {A, B} if and only if there is an inducing path be tween A and B.\nA DAG G'(O,S',L') is in Equiv(G(O,S,L)) if and only if for all disjoint subsets X, Y, and Z of 0, G(O,S,L) entails XilZJY U (S = 1) if and only if G'(O,S',L') entails XilZJY U (S' = 1).\nIn the following definition we use the symbol \"*\" as a wild-card symbol to denote any kind of edge endpoints in a partially oriented inducing path graph 1r; \"*\" itself never occurs in 1r. 1r is a partially oriented inducing\n506 Spirtes, Meek, and Richardson\npath graph of directed acyclic graph G(O,S,L) if and only if\n(i) the set of vertices in 7f equals 0;\n(ii) if there is any edge between A and B in 1r, it is one of the following kinds: A -? B, A o-? B, A o-o B, or A+-t B\n(iii) there is an edge between A and B in 7f if and only if for each G1(0,S',L') in Equiv(G(O,S,L)) there is an inducing path between A and B;\n(iv) there is at most one edge between any pair of vertices A and B in 1fj\n(v) if A -* B is in 1r, then for each G1(0,S',L') in Equiv(G(O,S,L)) every inducing path between A and B is out of A;\n(vi) if A *-? B is in 1r, then for each G1(0,S',L') in Equiv(G(O,S,L)) every inducing path between A and B is into B;\n(vii) if A *-* B *-* C is in 1r, then for each G1(0,S',L') in Equiv(G(O,S,L)) there is no pair of inducing paths U and V such that U is between A and B and into B, and V is between B and C and into B.\n(We sometime write A +--- B for B --t A, and A +-o B for B o-? A.)\nInformally, a directed path in a POIPG is a path that contains only \"-?\" edges pointing in the same direc tion.\nTheorem 2 If 1r is a partially oriented inducing path graph, and there is a directed path U from A to B in 7f, then in every DAG G(O,S,L) with POIPG 1r there is a directed path from A to B, and A has no descendant inS.\nTheorem 3 If 1r is a partially oriented inducing path graph and A B B in 7f, then there is a latent variable and no directed path from A to B and no directed path from B to A in any DAG G(O,S,L) with POIPG 1r.\nA semi-directed path from A to B in a partially oriented inducing path graph 1r is an undirected path acyclic U between A and B in which no edge contains an arrow head pointing towards A, (i.e. there is no arrowhead at A on U, and if X and Y are adjacent on the path, and X is between A and Y on the path, then there is no arrowhead at the X end of the edge between X andY). Theorems 4, 5, and 6 give information about what variables appear on causal paths between a pair of variables A and B, i.e. information about how those paths could be blocked.\nTheorem 4 If 1r is a partially oriented inducing path graph, and there is no semi-directed path from A to B in 1r that contains a member of C, then every di rected path from A to B in every DAG G(O,S,L) with POIPG 1r that contains a member of C also contains a member of S.\nTheorem 5 If 1r is a partially oriented inducing path graph, and there is no semi-directed path from A to B in 1r, then every directed path from A to B in every DAG G(O,S,L) with POIPG 7f contains a member of s.\nTheorem 6 If 1r is a partially oriented inducing path graph, and every semi-directed path from A to B con tains some member of C in 1r, then every directed path from A to B in every DAG G(O,S,L) with POIPG 1r contains a member of S U C.\nAcknowledgments\nWe would like to thank two anonymous referees for helpful comments on an earlier draft of this paper, and Clark Glymour and Greg Cooper for helpful con versations. Research for this paper was supported by the Office of Navel Research grant ONR #N00014-931-0568.\nReferences\nBollen, K. (1989). Structural Equations with latent variables. New York: Wiley.\nCooper, G. (1995). Causal discovery from data in the presence of selection bias. In Preliminary papers of the fifth international workshop on Artificial Intelligence and Statistics, Fort Lauderdale, FL, pp. 140-150.\nLauritzen, S., A. Dawid, B. Larsen, and H. Leimer (1990). Independence properties of directed Markov fields. Networks 20.\nMeek, C. (1995). Strong completeness and faithfulness in Bayesian networks. In Proceedings of Uncer tainty in Artificial Intelligence. To appear.\nPearl, J. (1988). Probabilistic Reasoning in Intelligent systems. San Mateo: Morgan-Kaufmann.\nSpirtes, P., C. Glymour, and R. Scheines (1993). Cau sation, Prediction, and Search. Springer-Verlag.\nVerma, T. and J. Pearl (1991). Equivalence and syn thesis of causal models. In Proceedings of the Sixth Conference in Art. Int., Mountain V iew, CA, pp. 220-227. Association for Uncertainty in AI.\nWermuth, N., D. Cox, and J. Pearl (1994). Expla nations for multivariate structures derived from univariate recursive regressions. Technical Report Report 94-1, University of Mainz.\nWright, S. (1934). The method of path coefficients. Annals of Mathematical Statistics 5."
    } ],
    "references" : [ {
      "title" : "Structural Equations with latent variables",
      "author" : [ "K. Bollen" ],
      "venue" : "New York: Wiley.",
      "citeRegEx" : "Bollen,? 1989",
      "shortCiteRegEx" : "Bollen",
      "year" : 1989
    }, {
      "title" : "Causal discovery from data in the presence of selection bias",
      "author" : [ "G. Cooper" ],
      "venue" : "Preliminary papers of the fifth international workshop on Artificial Intelligence and Statistics, Fort Lauderdale, FL, pp. 140-150.",
      "citeRegEx" : "Cooper,? 1995",
      "shortCiteRegEx" : "Cooper",
      "year" : 1995
    }, {
      "title" : "Independence properties of directed Markov fields",
      "author" : [ "S. Lauritzen", "A. Dawid", "B. Larsen", "H. Leimer" ],
      "venue" : "Networks 20.",
      "citeRegEx" : "Lauritzen et al\\.,? 1990",
      "shortCiteRegEx" : "Lauritzen et al\\.",
      "year" : 1990
    }, {
      "title" : "Strong completeness and faithfulness in Bayesian networks",
      "author" : [ "C. Meek" ],
      "venue" : "Proceedings of Uncer­ tainty in Artificial Intelligence. To appear.",
      "citeRegEx" : "Meek,? 1995",
      "shortCiteRegEx" : "Meek",
      "year" : 1995
    }, {
      "title" : "Probabilistic Reasoning in Intelligent systems",
      "author" : [ "J. Pearl" ],
      "venue" : "San Mateo: Morgan-Kaufmann.",
      "citeRegEx" : "Pearl,? 1988",
      "shortCiteRegEx" : "Pearl",
      "year" : 1988
    }, {
      "title" : "Equivalence and syn­ thesis of causal models",
      "author" : [ "T. Verma", "J. Pearl" ],
      "venue" : "Proceedings of the Sixth Conference in Art. Int., Mountain V iew, CA, pp. 220-227. Association for Uncertainty in AI.",
      "citeRegEx" : "Verma and Pearl,? 1991",
      "shortCiteRegEx" : "Verma and Pearl",
      "year" : 1991
    }, {
      "title" : "Expla­ nations for multivariate structures derived from univariate recursive regressions",
      "author" : [ "N. Wermuth", "D. Cox", "J. Pearl" ],
      "venue" : "Technical Report Report 94-1, University of Mainz.",
      "citeRegEx" : "Wermuth et al\\.,? 1994",
      "shortCiteRegEx" : "Wermuth et al\\.",
      "year" : 1994
    }, {
      "title" : "The method of path coefficients",
      "author" : [ "S. Wright" ],
      "venue" : "Annals of Mathematical Statistics 5.",
      "citeRegEx" : "Wright,? 1934",
      "shortCiteRegEx" : "Wright",
      "year" : 1934
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Cooper (1995) has given a number",
      "startOffset" : 0,
      "endOffset" : 14
    }, {
      "referenceID" : 4,
      "context" : "from data were discussed in Wermuth, Cox, and Pearl (1994). An important question is whether there are",
      "startOffset" : 46,
      "endOffset" : 59
    }, {
      "referenceID" : 1,
      "context" : "For the purposes of representing selection bias, follow­ ing Cooper (1995) we assume that for each measured random variable A, there is a binary random variable SA that is equal to one if the value of A has been recorded for that member of the population, and is equal to zero otherwise.",
      "startOffset" : 61,
      "endOffset" : 75
    }, {
      "referenceID" : 3,
      "context" : "(1993) and Meek (1995) have shown that under natural param­ eterizations of the linear normal structural equation models and discrete Bayesian networks, the set of pa­ rameterizations that lead to violations of faithfulness have Lebesgue measure 0.",
      "startOffset" : 11,
      "endOffset" : 23
    }, {
      "referenceID" : 4,
      "context" : "Theorem 1 generalizes results of Verma and Pearl (1991).",
      "startOffset" : 43,
      "endOffset" : 56
    } ],
    "year" : 2011,
    "abstractText" : "We show that there is a general, informative and reliable procedure for discovering causal relations when, for all the investigator knows, both latent variables and selection bias may be at work. Given information about con­ ditional independence and dependence rela­ tions between measured variables, even when latent variables and selection bias may be present, there are sufficient conditions for re­ liably concluding that there is a causal path from one variable to another, and sufficient conditions for reliably concluding when no such causal path exists.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}