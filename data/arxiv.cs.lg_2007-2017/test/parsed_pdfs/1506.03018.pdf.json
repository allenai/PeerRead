{
  "name" : "1506.03018.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "On the Uniform Convergence of Consistent Confidence Measures",
    "authors" : [ "Yihan Gao", "Aditya Parameswaran" ],
    "emails" : [ "ygao34@illinois.edu", "adityagp@illinois.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 6.\n03 01\n8v 1\n[ cs\n.L G\n] 9"
    }, {
      "heading" : "1 Introduction",
      "text" : "Many classification algorithms naturally produce confidence measures in the form of conditional probability of labels, e.g., the probability that y = 1 given the set of features x for a specific item. In standard PAC learning theory [11], these confidence measures are usually validated by bounding the expected value of some loss function (for example, the log-likelihood function). While expected loss is useful in comparing learning algorithms, little can be said about the meaning or interpretability of the confidence measures output by these algorithms.\nWe focus on characterizing the consistency of confidence measures. We want the confidence measures output by classification algorithms to be consistent in the sense that they correctly capture the belief of the algorithm in the output labels. For instance, if the algorithm outputs a label with confidence measure p n times across items, then the output label should be correct approximately np times overall. Consistent confidence measures have many applications: they can be used in decision making processes where misclassifications have asymmetric loss [4], in data processing pipelines where output of upstream classifiers are used in downstream programs [9, 5], or in adaptive data verification processes where instances are referred to a human verifier when the automatic classifier is not confident enough [14]. Overall, ensuring that these confidence measures are correctly calibrated or consistent allows the results of these classification algorithms to be interpretable by humans or algorithms, which is crucial in web, military, scientific, and industrial applications.\nThus, our core question is: what can we guarantee about the conditional probabilities produced by classifiers without assumptions on the underlying distribution? In this paper, we address this question from an agnostic PAC learning theory standpoint; thus, our results are theoretically sound\nand represent a valuable addition to our growing understanding of the principles of machine learning. Specifically, we make the following contributions towards addressing this question:\n• We formalize the notion of consistency of confidence measures with respect to the underlying distribution, and derive an empirical counterpart that can be directly evaluated on training data.\n• We establish the conditions under which the empirical consistency converges uniformly to the true consistency. We show that finite VC-dimension not only implies empirical error converges to true error uniformly, but also guarantees the consistency of confidence measures produced by empirically consistent classifiers.\n• We apply our result to a class of linear classifiers and show that we can achieve uniform convergence of consistency using essentially the same order of sample size implied by the standard argument based on VC-dimension [13]. Our analysis on linear classifiers validates the common practice of using logistic and probit regressions to learn consistent confidence measures. It also suggests that a larger class of functions, namely the collection of monotonically increasing continuous functions, can be used as the mapping function from linear predictors to conditional probabilities in these generalized linear classifiers.\n• We also show that maximizing log-likelihood is essentially optimizing the sum of two objectives: the mutual information between confidence measures and labels, and the consistency of confidence measures. These results improve our understanding about classifiers that produce conditional probabilities of labels in addition to label predictions.\nRelated Work. Despite the fundamental importance of confidence measures and the wide utility of these measures, the work in this space has been remarkably sparse. Some existing papers have considered the uniform convergence of the expected value of certain loss functions on confidence measures: Haussler [7] considered the expected loss of the action that we take based on confidence measures as opposed to confidence measures themselves; Agarwal et al. [2] studied the uniform convergence of the area under ROC curve. These expected losses are designed to evaluate the effectiveness of a classifier: lower expected loss means it makes less errors on average. We remark that effectiveness and consistency are orthogonal qualities of confidence measures: a classifier might be highly effective but with poor consistency and vice versa. Our work enables a potential trade-off between these two: in some applications, we might be willing to trade a little bit of effectiveness for higher consistency.\nRegarding the confidence of classification, Li et al. [8] proposed a learning framework that explicitly allows a classifier to respond “I don’t know”, but whenever it produces a label it must be correct.\nOur notion of consistency is similar to the notion of calibration in prediction theory [6, 1], where the goal is also to make predicted probability values match the empirical frequency of correct predictions. However, in prediction theory, the problem is formulated from a game-theoretic point of view: the sequence generator is assumed to be malevolent, and the goal is to design an algorithm to achieve this calibration guarantee no matter what strategy the sequence generator uses.\nTewari and Bartlett [12] studied the consistency of a conditional probability estimator. Their definition of consistency is that the algorithm should be able to correctly identify the label with highest conditional probability as the training data size increases. However, their work does not address the calibration of conditional probabilities."
    }, {
      "heading" : "1.1 Problem Statement",
      "text" : "Let X be a sample space and Y = {±1} be the set of labels. Let P be a probability measure defined on X × Y that specifies the joint distribution of sample x and its label y. Let Sn = {(x1, y1), . . . , (xn, yn)} be i.i.d. samples from (X × Y,P). Consider a set of classifiers H, so that each h ∈ H predicts a confidence measure h(x) ∈ [0, 1] indicating how likely the label y is 1 given x. We define the consistency measure of h with respect to P to be:\nc(h) = sup p1,p2 |P(p1 < h(x) ≤ p2, y = 1)− EP [1p1<h(x)≤p2h(x)]|\nThat is, for any p1, p2, the relative frequency of samples with y = 1 and p1 < h(x) ≤ p2 deviates at most c(h) away from what h(x) predicts. We define the empirical consistency measure of classifier\nh to be:\ncemp(h) = sup p1,p2\n| 1\nn\nn ∑\ni=1\n1p1<h(xi)≤p2,yi=1 − 1\nn\nn ∑\ni=1\nh(xi)1p1<h(xi)≤p2 |\nIn this paper we study the conditions under which, cemp(h) converges to c(h) uniformly for every h ∈ H. We are interested in the sample complexity m(ǫ, δ) for ǫ, δ > 0 such that:\n∀n > m(ǫ, δ),P(sup h∈H |c(h)− cemp(h)| > ǫ) < δ (1)"
    }, {
      "heading" : "1.2 Main Results",
      "text" : "The main result of this paper is the following theorem, listed here for convenience. (We will explain all notations and definitions in Section 2.) Theorem 1. Let H be a set of classifiers that predicts confidence measures, i.e., functions from X to [0, 1]. Suppose the Rademacher Complexity of H0 = {1p1<h(x)≤p2 : p1, p2 ∈ R, h ∈ H} satisfies:\nESnRSn(H0) +\n√\n2 ln(4/δ)\nn <\nǫ\n2 Then,\nP(sup h∈H |c(h)− cemp(h)| > ǫ) < δ\nThus, Theorem 1 relates the uniform convergence rate of consistency measure with the Rademacher Complexity of the class of induced binary classifiers H0. We also prove the following theorem that relates this Rademacher Complexity with VC-dimension of each induced classifier class: Theorem 2. Let H be a set of classifiers that predicts confidence measures. Suppose that every classifier h in H only outputs confidence measures chosen from a finite set P ∗:\n∀h ∈ H, ∀x ∈ X , h(x) ∈ P ∗\nand for all p1, p2 ∈ R, the VC-dimension of hypothesis space Hp1,p2 = {1p1<h(x)≤p2 : h ∈ H} is at most d, then for any sample Sn of size n with n > d+ 1 we have:\nRSn(H0) ≤\n√\n2d(ln n d + 1) + 4 ln(|P ∗|+ 1)\nn\nThus, overall, we can show that if for every p1, p2, the collection of induced classifiers 1p1<h(x)≤p2 has finite VC-dimension, then we can guarantee the uniform convergence of consistency of confidence measures.\nThe dependency on |P ∗| in Theorem 2 is necessary: we show examples in which d is small but RSn(H0) is large. However, this dependency should not cause any problem in practice, as in most applications we only need a finite precision of confidence measures. The logarithmic dependency on the size of P ∗ allow us to predict confidence measures with reasonably good precision without causing the sample complexity to blow up.\nThese two theorems are proved in Section 3, after we review definitions and results on VC-dimension and Rademacher Complexity in Section 2. Furthermore, we apply these theorems in Section 4 and Section 5 to derive several useful results:\n• In Section 4, we show that extending any hypothesis space by applying monotonically increasing continuous mapping on confidence measures does not increase the Rademacher Complexity of this hypothesis space.\n• Also in Section 4, we show that for all generalized linear classifiers, if their mapping functions from linear predictors to conditional probabilities are monotonically increasing and\nleft-continuous, then a generalization bound of order O( √\n(d lnn+ ln 1 δ )/n) can be de-\nrived for their consistency. This bound is of the same order as the generalization error bound derived from standard VC-dimension arguments.\n• We also study the problem of finding a monotonic mapping for any given classifier so that empirical inconsistency is minimized after calibration. In Section 5, we show that this problem can be solved efficiently by linear programming."
    }, {
      "heading" : "2 Preliminaries",
      "text" : ""
    }, {
      "heading" : "2.1 VC-dimension and Sauer’s Lemma",
      "text" : "Let A be a collection of random events, i.e., of subsets of X ×Y . Let Sn = {(x1, y1), . . . , (xn, yn)} be a set of samples from X × Y . Define the restriction of A to Sn as:\nASn = {A ∩ Sn : A ∈ A}\nWe say that A shatters Sn if the restriction of A to Sn contains all subsets of Sn:\n∀B ⊆ Sn, ∃A ∈ A, B = A ∩ Sn\nor equivalently, |ASn | = 2 |Sn| The VC-Dimension [13] of A is defined as the maximum number of samples that can be arranged so that A shatters them.\nSuppose the VC-dimension of A is finite, then Sauer’s Lemma [10][13] can be used to bound the size of ASn . Let the VC-dimension of A be d, then for any Sn:\n|ASn | ≤\nd ∑\ni=0\n(\nn\ni\n)\nand if n > d+ 1 then |ASn | ≤ (en/d) d (2)"
    }, {
      "heading" : "2.2 Rademacher Complexity",
      "text" : "Let H be a collection of functions from X × Y to [0, 1], the Rademacher Complexity [3] of H with respect to Sn is defined as:\nRSn(H) = 1\nn Eσ∼{±1}n [sup\nh∈H\nn ∑\ni=1\nσih(xi, yi)]\nRademacher Complexity can be used to characterize the uniform convergence rate of a collection of functions. Let Sn be i.i.d. samples of X × Y , then with probability of at least 1− δ [11]:\nsup h∈H\n| 1\nn\nn ∑\ni=1\nh(xi, yi)− Eh(x, y)| ≤ 2ESnRSn(H) +\n√\n2 ln(2/δ)\nn (3)\nsup h∈H\n| 1\nn\nn ∑\ni=1\nh(xi, yi)− Eh(x, y)| ≤ 2RSn(H) + 4\n√\n2 ln(4/δ)\nn (4)\nSometimes we also allow H to be collection of functions from X to [0, 1] in the above results. When used in this sense, we assume that the function will not use y label in the instance: h(x, y) = h(x)."
    }, {
      "heading" : "2.3 Massart Lemma",
      "text" : "Let H be a collection of functions from X × Y to [0, 1]. Let HSn be the restriction of H to Sn:\nHSn = {(h(x1, y1), h(x2, y2), . . . , h(xn, yn)) : h ∈ H}\nIf the cardinality of HSn is finite, then the Rademacher Complexity of H with respect to Sn can be bounded as follows [11]:\nRSn(H) ≤ sup a∈HSn ||a||2\n√\n2 ln |HSn |\nn (5)\nCombining with Sauer’s Lemma, it follows that if A is a collection of subsets of X × Y such that the VC-dimension of A is at most d, then\nRSn({1x∈A : A ∈ A}) ≤\n√\n2d(ln(n/d) + 1)\nn (6)"
    }, {
      "heading" : "3 Uniform Convergence of Consistency Measure",
      "text" : "In this section we prove Theorem 1 and sketch the proof of Theorem 2.\nFor later convenience, we define\nFS,p1,p2(h) = 1\nn\nn ∑\ni=1\n1p1<h(xi)≤p2,yi=1\nto be the relative frequency of event {p1 < h(x) ≤ p2, y = 1}. Define FD,p1,p2(h) = P(p1 < h(x) ≤ p2, y = 1) to be the probability of the same event.\nWe define ES,p1,p2(h) as the empirical expectation of h(x)1p1<h(x)≤p2 :\nES,p1,p2(h) = 1\nn\nn ∑\ni=1\nh(xi)1p1<h(xi)≤p2\nand ED,p1,p2(h) as the expectation of the same function: ED,p1,p2(h) = E[h(x)1p1<h(x)≤p2 ] When context is clear, subscripts p1 and p2 are dropped.\nUsing these notations, we can rewrite c(h) and cemp as follows: c(h) = sup\np1,p2 |FD(h)− ED(h)| cemp(h) = sup p1,p2 |FS(h)− ES(h)|\nProof of Theorem 1. First note that: | sup p1,p2 |FD(h)− ED(h)| − sup p1,p2 |FS(h)− ES(h)|| ≤ sup p1,p2 ||FD(h)− ED(h)| − |FS(h)− ES(h)||\n≤ sup p1,p2 |FD(h)− ED(h)−FS(h) + ES(h)| ≤ sup p1,p2 (|FD(h)−FS(h)|+ |ED(h)− ES(h)|)\n≤ sup p1,p2 |FD(h)−FS(h)|+ sup p1,p2 |ED(h)− ES(h)|\nTherefore it suffices to show that P( sup\nh,p1,p2 |FD(h)−FS(h)|+ sup h,p1,p2 |ED(h)− ES(h)| > ǫ) < δ\nWe will prove the following sufficient conditions:\nP( sup h,p1,p2\n|FD(h)−FS(h)| > ǫ\n2 ) <\nδ 2 and P( sup\nh,p1,p2\n|ED(h)− ES(h)| > ǫ\n2 ) <\nδ\n2\nDefine H1 = {1p1<h(x)≤p2,y=1 : p1, p2 ∈ R, h ∈ H}\nH2 = {h(x)1p1<h(x)≤p2 : p1, p2 ∈ R, h ∈ H}\nBy Equation (3), we only need to show that\nESnRSn(H1) +\n√\n2 ln(4/δ)\nn <\nǫ 2 and ESnRSn(H2) +\n√\n2 ln(4/δ)\nn <\nǫ\n2 For RSn(H1), we have:\nRSn(H1) = 1\nn Eσ∼{±1}n [ sup\np1,p2,h\nn ∑\ni=1\nσi1p1<h(xi)≤p2,yi=1]\n= 1\nn Eσ∼{±1}n [ sup\np1,p2,h\nn ∑\ni=1\nσi1p1<h(xi)≤p2Ezi∈{±1} max(zi, yi)]\n≤ 1\nn Eσ∼{±1}n,z∼{±1}n [ sup\np1,p2,h\nn ∑\ni=1\n1p1<h(xi)≤p2σi max(zi, yi)]\n= 1\nn Et∼{±1}n [ sup\np1,p2,h\nn ∑\ni=1\nti1p1<h(xi)≤p2 ] = RSn(H0)\nwhere the last step is because ti = σi max(zi, yi) is uniformly distributed over {±1} independent of the value of yi.\nFor RSn(H2), notice that h(x) = ∫ 1 0 1t<h(x)dt, therefore we have:\nRSn(H2) = 1\nn Eσ∼{±1}n [ sup\np1,p2,h\nn ∑\ni=1\nσih(xi)1p1<h(xi)≤p2 ]\n= 1\nn Eσ∼{±1}n [ sup\np1,p2,h\n∫ 1\n0\nn ∑\ni=1\nσi1t<h(xi)1p1<h(xi)≤p2dt]\n≤ 1\nn Eσ∼{±1}n\n∫ 1\n0 [ sup p1,p2,h\nn ∑\ni=1\nσi1max(p1,t)<h(xi)≤p2 ]dt\n≤ 1\nn Eσ∼{±1}n\n∫ 1\n0 [ sup p1,p2,h\nn ∑\ni=1\nσi1p1<h(xi)≤p2 ]dt\n= 1\nn Eσ∼{±1}n [ sup\np1,p2,h\nn ∑\ni=1\nσi1p1<h(xi)≤p2 ] = RSn(H0)\nCombining with the assumption in the theorem, we get the desired result.\nIn order to prove Theorem 2, we apply union bound to upper bound the cardinality of the restriction of H0 on Sn. Then we use Massart Lemma to prove upper bound of RSn(H0). The detailed proof can be found in the appendix.\nOne may wonder if we can prove bound of RSn(H0) that only depends on VC-dimension of Hp1,p2 but not |P ∗|. Unfortunately, this is not possible. The next example shows that RSn(H0) can be large even when every Hp1,p2 has constant VC-dimension.\nExample 1. Let π be arbitrary one-to-one mapping from {0, 1}n to {1, . . . , 2n}. Let H be the following hypothesis space:\nH = {hA(x) = π(A) − 121x∈A\n2n : A ⊆ Sn}\nOne can easily verify that for all p1, p2, the VC-dimension of Hp1,p2 is at most 2, but we have RSn(H0) = 1 2 ."
    }, {
      "heading" : "4 Generalization Bound for Linear Classifier",
      "text" : "In this section we study the consistency of confidence measures produced by a class of linear classifiers. We first present some lemmas that provide us the tools to simplify the analysis of Rademacher Complexity of certain hypothesis spaces.\nThe following lemma allows us to bound the Rademacher Complexity of H0 by bounding the Rademacher Complexity of all “one-sided” classifiers (i.e., classifiers that determines the label via a hard threshold on confidence measures), which is sometimes easier to analyze.\nLemma 1. Let H3 = {1h(x)≤p : p ∈ R, h ∈ H}, then RSn(H0) ≤ 2RSn(H3).\nSometimes we have learning algorithms that output confidence measures in real numbers (for example, linear classifier and SVM), the following lemma will be useful for analyzing these algorithms.\nLemma 2. Let HR be a collection of classifiers that output confidence measures in R, let M be the collection of all left-continuous monotonically increasing functions from R to [0, 1], define\nH4 = {1p1<m(h(x))≤p2 : p1, p2 ∈ R,m ∈ M, h ∈ HR}\nH5 = {1α<h(x)≤β : α, β ∈ R, h ∈ HR}\nThen, RSn(H4) = RSn(H5)\nThe proof of these two lemmas can be found in the appendix.\nNow we can reason about consistency of the following class of linear classifiers, which outputs confidence measures by first computing a linear predictor ωTx of feature vector x, then applying a monotonically increasing function f on the predictor to compute conditional probabilities:\nTheorem 3. Let X = Rm and M be the collection of all left-continuous monotonically increasing functions from R to [0, 1]. Let H = {f(wTx) : w ∈ Rm, f ∈ M}. Then for all n > m+ 2 we have\nRSn(H0) ≤ 2\n√\n2(m+ 1)(ln(n/(m+ 1)) + 1)\nn\nProof. By Lemma 2,\nRSn(H0) = RSn({1α<wTx≤β : α, β ∈ R, w ∈ R m})\nThen by Lemma 1,\nRSn({1α<wT x≤β : α, β ∈ R, w ∈ R m}) ≤ 2RSn({1wTx≤α : α ∈ R, w ∈ R m})\nThe latter hypothesis space is the linear separator space of m dimensional space, having VCdimension at most m+ 1. Therefore by Sauer’s Lemma and Massart Lemma:\nRSn({1wT x≤α : α ∈ R, w ∈ R m}) ≤\n√\n2(m+ 1)(ln(n/(m+ 1)) + 1)\nn\nCombining all, we get the desired result.\nCombining Theorem 3 with Theorem 1, we get the following result:\nCorollary 1. Let H be the same as in Theorem 3. For all n satisfying\nn > max( 32(m+ 1)(lnn− ln(m+ 1) + 1) + 8 ln 4 δ\nǫ2 ,m+ 2)\nwe have P(sup\nh∈H |c(h)− cemp(h)| > ǫ) < δ"
    }, {
      "heading" : "5 Learning Consistent Classifier",
      "text" : "In this section, we discuss methods to learn classifiers that have low inconsistency measures. In Section 5.1, we justify the use of log-likelihood as the objective function in learning consistent classifiers. In Section 5.2, we discuss the use of monotonic functions to calibrate existing classifiers and show that this problem leads to a linear programming formulation."
    }, {
      "heading" : "5.1 Maximum Likelihood Classifier",
      "text" : "The log-likelihood function of classifier h on Sn is defined as:\nLS(h) = 1\nn\nn ∑\ni=1\n[1yi=1 lnh(xi) + 1yi=−1 ln(1− h(xi))]\nThe expectation of log-likelihood is:\nLD(h) = EP [1y=1 lnh(x) + 1y=−1 ln(1− h(x))]\nConsider the random variable hx = h(x), rewrite the expected log-likelihood as:\nLD(h) =\n∫\nhx\n[P(y = 1|hx) lnhx +P(y = −1|hx) ln(1− hx)]dP\nDenote py|hx = P(y = 1|hx) as the conditional probability of y = 1 given hx. Denote DKL(p(y|hx)||hx) as the Kullback-Leibler divergence between p(y|hx) and distribution (hx, 1−hx):\nDKL(p(y|hx)||hx) = py|hx ln py|hx hx + (1− py|hx) ln 1− py|hx 1− hx\nThen after rearranging terms, we can derive the following equation:\nLD(h) = −H(y) +MI(y;hx)− EhxDKL(p(y|hx)||hx)\nwhere H(y) is the entropy of y and MI(y;hx) is the mutual information between y and hx. In other words, maximizing likelihood can be viewed as simultaneously maximizing the mutual information between confidence measure hx and label y and minimizing discrepancy between the predicted distribution (hx, 1− hx) and the actual distribution p(y|hx).\nWhile this fact intuitively justifies the use of maximum likelihood estimation (MLE) to learn consistent classifiers, as it turns out, MLE does not always minimize inconsistency.\nExample 2. Suppose X = {x1, x2}. Suppose that p(x1) = p(x2) = 0.5, p(y = 1|x1) = 0.05 and p(y = 1|x2) = 0.95. Among the two hypotheses h1 and h2 with h1(x1) = 0.01, h1(x2) = 0.99 and h2(x1) = 0.1, h2(x2) = 0.9, h1 is more consistent but h2 has higher likelihood."
    }, {
      "heading" : "5.2 Calibrating Confidence Measure with Monotonic Function",
      "text" : "As we have proved in Lemma 2, applying left-continuous monotonic mapping over existing confidence measures doesn’t increase the Rademacher Complexity of the original hypothesis space. Therefore, another natural approach is to learn such mappings to calibrate the confidence measures produced by any existing classifier.\nAssume that we are given classifier h : X → R, we want to find a left-continuous monotonically increasing function f from R to [0, 1] that minimizes empirical inconsistency measures cemp(f ◦ h). For simplicity, we assume that Sn = {(x1, y1), . . . , (xn, yn)} satisfies h(x1) < h(x2) < . . . < h(xn). If h(xi)s are not distinct, we can assign weights to samples and the algorithm remains the same. Then,\ncemp(f ◦ h) = 1\nn sup p1,p2 |\nn ∑\ni=1\n1p1<f(h(xi))≤p2(1yi=1 − f(h(xi)))|\n= 1\nn max a,b\n| ∑\na<i≤b\n(1yi=1 − f(h(xi)))|\nLet zi = f(h(xi)), then z1 ≤ z2 ≤ . . . ≤ zn, and we can rewrite the above equation as:\ncemp(f ◦ h) = 1\nn max a,b\n| ∑\na<i≤b\n(1yi=1 − zi)|\nThe right hand side can be rewritten as follows:\n1 n max a,b | ∑\na<i≤b\n(1yi=1 − zi)| = 1\nn max a\n∑\ni≤a\n(1yi=1 − zi)− 1\nn min a\n∑\ni≤a\n(1yi=1 − zi)\nTherefore, the optimal f can be found by solving the following linear optimization problem, which can be efficiently solved by standard LP algorithms:\nmin ξ1 + ξ2\ns.t. ξ1, ξ2 ≥ 0 0 ≤ z1 ≤ z2 ≤ . . . ≤ zn ≤ 1\n∀1 ≤ k ≤ n, ∑\ni≤k\nzi ≥ ∑\ni≤k\n1yi=1 − nξ1\n∀1 ≤ k ≤ n, ∑\ni≤k\nzi ≤ ∑\ni≤k\n1yi=1 + nξ2\nFinally, by extrapolating all points of the form (h(xi), zi), we get a continuous monotonic function f from R to [0, 1], which can be used to calibrate confidence measures of the given classifier h."
    } ],
    "references" : [ {
      "title" : "Blackwell approachability and low-regret learning are equivalent",
      "author" : [ "J. Abernethy", "P.L. Bartlett", "E. Hazan" ],
      "venue" : "arXiv preprint arXiv:1011.1936",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A uniform convergence bound for the area under the roc curve",
      "author" : [ "S. Agarwal", "S. Har-Peled", "D. Roth" ],
      "venue" : "Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics, pages 1–8",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Rademacher and gaussian complexities: Risk bounds and structural results",
      "author" : [ "P.L. Bartlett", "S. Mendelson" ],
      "venue" : "The Journal of Machine Learning Research, 3:463–482",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Pattern recognition and machine learning, volume 4. springer",
      "author" : [ "C.M. Bishop" ],
      "venue" : "New York,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2006
    }, {
      "title" : "Minimizing uncertainty in pipelines",
      "author" : [ "N.N. Dalvi", "A.G. Parameswaran", "V. Rastogi" ],
      "venue" : "NIPS",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Asymptotic calibration",
      "author" : [ "D.P. Foster", "R.V. Vohra" ],
      "venue" : "Biometrika, 85(2):379–390",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Decision theoretic generalizations of the pac model for neural net and other learning applications",
      "author" : [ "D. Haussler" ],
      "venue" : "Information and computation, 100(1):78–150",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "Knows what it knows: a framework for self-aware learning",
      "author" : [ "L. Li", "M.L. Littman", "T.J. Walsh", "A.L. Strehl" ],
      "venue" : "Machine learning, 82(3):399–443",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Beyond myopic inference in big data pipelines",
      "author" : [ "K. Raman", "A. Swaminathan", "J. Gehrke", "T. Joachims" ],
      "venue" : "Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 86–94. ACM",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "On the density of families of sets",
      "author" : [ "N. Sauer" ],
      "venue" : "Journal of Combinatorial Theory, Series A, 13(1):145–147",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1972
    }, {
      "title" : "Understanding Machine Learning: From Theory to Algorithms",
      "author" : [ "S. Shalev-Shwartz", "S. Ben-David" ],
      "venue" : "Cambridge University Press",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "On the consistency of multiclass classification methods",
      "author" : [ "A. Tewari", "P.L. Bartlett" ],
      "venue" : "The Journal of Machine Learning Research, 8:1007–1025",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "On the uniform convergence of relative frequencies of events to their probabilities",
      "author" : [ "V.N. Vapnik", "A.Y. Chervonenkis" ],
      "venue" : "Theory of Probability & Its Applications, 16(2):264–280",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1971
    }, {
      "title" : "Crowder: Crowdsourcing entity resolution",
      "author" : [ "J. Wang", "T. Kraska", "M.J. Franklin", "J. Feng" ],
      "venue" : "Proceedings of the VLDB Endowment, 5(11):1483–1494",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 10,
      "context" : "In standard PAC learning theory [11], these confidence measures are usually validated by bounding the expected value of some loss function (for example, the log-likelihood function).",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 3,
      "context" : "Consistent confidence measures have many applications: they can be used in decision making processes where misclassifications have asymmetric loss [4], in data processing pipelines where output of upstream classifiers are used in downstream programs [9, 5], or in adaptive data verification processes where instances are referred to a human verifier when the automatic classifier is not confident enough [14].",
      "startOffset" : 147,
      "endOffset" : 150
    }, {
      "referenceID" : 8,
      "context" : "Consistent confidence measures have many applications: they can be used in decision making processes where misclassifications have asymmetric loss [4], in data processing pipelines where output of upstream classifiers are used in downstream programs [9, 5], or in adaptive data verification processes where instances are referred to a human verifier when the automatic classifier is not confident enough [14].",
      "startOffset" : 250,
      "endOffset" : 256
    }, {
      "referenceID" : 4,
      "context" : "Consistent confidence measures have many applications: they can be used in decision making processes where misclassifications have asymmetric loss [4], in data processing pipelines where output of upstream classifiers are used in downstream programs [9, 5], or in adaptive data verification processes where instances are referred to a human verifier when the automatic classifier is not confident enough [14].",
      "startOffset" : 250,
      "endOffset" : 256
    }, {
      "referenceID" : 13,
      "context" : "Consistent confidence measures have many applications: they can be used in decision making processes where misclassifications have asymmetric loss [4], in data processing pipelines where output of upstream classifiers are used in downstream programs [9, 5], or in adaptive data verification processes where instances are referred to a human verifier when the automatic classifier is not confident enough [14].",
      "startOffset" : 404,
      "endOffset" : 408
    }, {
      "referenceID" : 12,
      "context" : "• We apply our result to a class of linear classifiers and show that we can achieve uniform convergence of consistency using essentially the same order of sample size implied by the standard argument based on VC-dimension [13].",
      "startOffset" : 222,
      "endOffset" : 226
    }, {
      "referenceID" : 6,
      "context" : "Some existing papers have considered the uniform convergence of the expected value of certain loss functions on confidence measures: Haussler [7] considered the expected loss of the action that we take based on confidence measures as opposed to confidence measures themselves; Agarwal et al.",
      "startOffset" : 142,
      "endOffset" : 145
    }, {
      "referenceID" : 1,
      "context" : "[2] studied the uniform convergence of the area under ROC curve.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[8] proposed a learning framework that explicitly allows a classifier to respond “I don’t know”, but whenever it produces a label it must be correct.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "Our notion of consistency is similar to the notion of calibration in prediction theory [6, 1], where the goal is also to make predicted probability values match the empirical frequency of correct predictions.",
      "startOffset" : 87,
      "endOffset" : 93
    }, {
      "referenceID" : 0,
      "context" : "Our notion of consistency is similar to the notion of calibration in prediction theory [6, 1], where the goal is also to make predicted probability values match the empirical frequency of correct predictions.",
      "startOffset" : 87,
      "endOffset" : 93
    }, {
      "referenceID" : 11,
      "context" : "Tewari and Bartlett [12] studied the consistency of a conditional probability estimator.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 0,
      "context" : "Consider a set of classifiers H, so that each h ∈ H predicts a confidence measure h(x) ∈ [0, 1] indicating how likely the label y is 1 given x.",
      "startOffset" : 89,
      "endOffset" : 95
    }, {
      "referenceID" : 0,
      "context" : ", functions from X to [0, 1].",
      "startOffset" : 22,
      "endOffset" : 28
    }, {
      "referenceID" : 12,
      "context" : "Define the restriction of A to Sn as: ASn = {A ∩ Sn : A ∈ A} We say that A shatters Sn if the restriction of A to Sn contains all subsets of Sn: ∀B ⊆ Sn, ∃A ∈ A, B = A ∩ Sn or equivalently, |ASn | = 2 |Sn| The VC-Dimension [13] of A is defined as the maximum number of samples that can be arranged so that A shatters them.",
      "startOffset" : 223,
      "endOffset" : 227
    }, {
      "referenceID" : 9,
      "context" : "Suppose the VC-dimension of A is finite, then Sauer’s Lemma [10][13] can be used to bound the size of ASn .",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 12,
      "context" : "Suppose the VC-dimension of A is finite, then Sauer’s Lemma [10][13] can be used to bound the size of ASn .",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 0,
      "context" : "2 Rademacher Complexity Let H be a collection of functions from X × Y to [0, 1], the Rademacher Complexity [3] of H with respect to Sn is defined as: RSn(H) = 1 n Eσ∼{±1}n [sup h∈H n",
      "startOffset" : 73,
      "endOffset" : 79
    }, {
      "referenceID" : 2,
      "context" : "2 Rademacher Complexity Let H be a collection of functions from X × Y to [0, 1], the Rademacher Complexity [3] of H with respect to Sn is defined as: RSn(H) = 1 n Eσ∼{±1}n [sup h∈H n",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 10,
      "context" : "samples of X × Y , then with probability of at least 1− δ [11]:",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 0,
      "context" : "2 ln(4/δ) n (4) Sometimes we also allow H to be collection of functions from X to [0, 1] in the above results.",
      "startOffset" : 82,
      "endOffset" : 88
    }, {
      "referenceID" : 0,
      "context" : "3 Massart Lemma Let H be a collection of functions from X × Y to [0, 1].",
      "startOffset" : 65,
      "endOffset" : 71
    }, {
      "referenceID" : 10,
      "context" : ", h(xn, yn)) : h ∈ H} If the cardinality of HSn is finite, then the Rademacher Complexity of H with respect to Sn can be bounded as follows [11]: RSn(H) ≤ sup a∈HSn ||a||2 √",
      "startOffset" : 140,
      "endOffset" : 144
    }, {
      "referenceID" : 0,
      "context" : "Let HR be a collection of classifiers that output confidence measures in R, let M be the collection of all left-continuous monotonically increasing functions from R to [0, 1], define H4 = {1p1<m(h(x))≤p2 : p1, p2 ∈ R,m ∈ M, h ∈ HR} H5 = {1α<h(x)≤β : α, β ∈ R, h ∈ HR} Then, RSn(H4) = RSn(H5)",
      "startOffset" : 168,
      "endOffset" : 174
    }, {
      "referenceID" : 0,
      "context" : "Let X = R and M be the collection of all left-continuous monotonically increasing functions from R to [0, 1].",
      "startOffset" : 102,
      "endOffset" : 108
    }, {
      "referenceID" : 0,
      "context" : "Assume that we are given classifier h : X → R, we want to find a left-continuous monotonically increasing function f from R to [0, 1] that minimizes empirical inconsistency measures cemp(f ◦ h).",
      "startOffset" : 127,
      "endOffset" : 133
    } ],
    "year" : 2017,
    "abstractText" : "Many classification algorithms produce confidence measures in the form of conditional probability of labels given the features of the target instance. It is desirable to be make these confidence measures calibrated or consistent, in the sense that they correctly capture the belief of the algorithm in the label output. For instance, if the algorithm outputs a label with confidence measure p for n times, then the output label should be correct approximately np times overall. Calibrated confidence measures lead to higher interpretability by humans and computers and enable downstream analysis or processing. In this paper, we formally characterize the consistency of confidence measures and prove a PAC-style uniform convergence result for the consistency of confidence measures. We show that finite VCdimension is sufficient for guaranteeing the consistency of confidence measures produced by empirically consistent classifiers. Our result also implies that we can calibrate confidence measures produced by any existing algorithms with monotonic functions, and still get the same generalization guarantee on consistency.",
    "creator" : "LaTeX with hyperref package"
  }
}