{
  "name" : "1301.6747.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Bayesian Control for Concentrating Mixed Nuclear Waste",
    "authors" : [ "Robert L. Welch" ],
    "emails" : [ "bwelch@gensym.com", "clasmith@d" ],
    "sections" : [ {
      "heading" : null,
      "text" : "INTRODUCTION\nMixed waste remediation is an example of an industrial operation that transforms input of low quality, high vari ability and uncertain composition into consistent and high quality output. Moreover, control of many of the process ing steps is dependent on an accurate knowledge of the composition of the material input. When control is not optimized, product quality may suffer, processing time may increase maintenance and repairs may be more fre quent, and severe damage to equipment is possible. Yet, obtaining accurate knowledge or estimates of the input stream composition may be impossible or time consum ing, may reduce throughput, and may increase costs. With this uncertainty, optimal control must balance the costs of obtaining more accurate knowledge about the input stream against costs of repair, maintenance, associated shut downs, and, generally, reduced throughput.\nHere, a Bayesian controller is used in real time to manage this tradeoff. A Bayesian network predicts the quality of the input stream. Sensor input is used to derive a posterior distribution of the input composition. From the latter, the optimal control setting is computed.\nComplexity Workarounds\nAlthough Bayesian networks provide superior representa tion and inference capabilities, it is also known that \"solving\" a Bayesian network is NP-hard (Cooper [1990]). Hence use of a Bayesian network for real-time control is problematic.\nA common work-around to Bayesian network complexity is to use approximate solutions often in the form of \"any time\" algorithms (Dean and Boddy [1994], Horvitz\n[ 1987], Ibarguengoytia et al [ 1998], Horsch and Poole [1998]). Here we demonstrate a different approach, one that has largely been ignored within the uncertainty in AI community, based on exploiting differences in the update frequency of sensor variables. A large complex Bayesian network is needed for assessment of the joint distribution of all system variables relevant to the real time decision problem. Yet only a small portion of the network is needed at run time for the most frequent control decisions. This reduced distribution corresponds to a conditional sub-network of the original Bayesian network, which can be evaluated, in real time, using standard exact solution methods.\nln this paper we apply this approach to the control of a process having both batch and continuous components. The staging of the batches provides ample time to update the larger Bayesian network and compile the smaller sub network used for control of the continuous processing of the batch.\nl.lHE SEITING: WASIE REMEDIATION We work with an example of the cleanup of buried nu clear waste. A burial site has received nuclear waste of various types in a random fashion over a number of years. The last addition was several decades ago, and by now container damage and leakage have resulted in an unde termined level of soil contamination. The task (see figure I) is to retrieve the waste and soil separately into large boxes ( 100 cu. ft.), then to assay each box for transuranic (TRU) contamination. This TRU assay uses a relatively slow, but relatively precise, neutron emission method. The boxes that exceed an assay threshold for TRU content are sent to further processing, those below the threshold are returned to the pit.\nThe high waste boxes move to vitrification; the high soil\nboxes are sent to a segmented gate, soil sorter (y-sort) to concentrate the contamination into a reduced volume. This device works by assaying small volumes (0.1 cu. ft.) of soil using a gamma detector, which provides a very rapid, but much less precise method. As before, high\n664 Welch and Smith\nlevel portions are sent to vitrification, low level portions are returned to the pit, after verification by the relatively precise neutron assay.\nThe objective of the Bayesian controller is to establish a sorting algorithm, which will optimize the operation of the soil sorter, under conditions of very high uncertainty.\nThe radioisotopes that are the source of ganuna are not the long lived TRU isotopes. Instead they accompany the TRU in proportions that vary with the type of waste. If the ratio of the gamma emitter to the neutron emitting TRU were known, then the bias in the sensor could be compen sated. However, depending on the origin of the TRU waste, the ratio of gamma emissions to neutron emissions can vary by factors of over I 04 among the types of wastes, and by a factor of I 0 within a waste type. In addition, the amount of contamination in any portion of soil under assay will vary significantly from sample to sample. A small speck of waste with a high gamma, low TRU contamination will provide a stronger signal, than a large bit of low ganuna, high TRU waste. The specifica tions, which must be met, are based on the slow, neutron emission analysis for TRU. These considerations make the gamma signal difficult to interpret. If the waste type where known, then a higher ganuna indicates a greater TRU contamination. But with mixed waste, a higher gamma may instead indicate presence of a waste type that is a high gamma emitter but has low TRU contamination.\nYet, operational and economic considerations are com pelling for using the ganuna emissions sensor for sorting. The primary cost considerations are the volume of the slag produced and the throughput of the sorter.\nAlthough the waste composition and the extent of the spread of contamination are not known with certainty, an imperfect prior estimate can be obtained from several sources: dump records, waste composition logs, process ing records, non intrusive surveys of the waste site, and the assays of process streams which are anterior and pos terior to the sorter.\nTherefore, in light of uncertainty about the composition of waste dispersed into the soil, we have considered the use of optimal Bayesian control to minimize the volume of material, which must be vitrified. Using Bayesian meth ods, assay and sensor readings lead to revised beliefs in the type of waste in the soil sample, thus to better control decision.\nThe same economic considerations that led to the selec tion of the ganuna sensor for its greater throughput also require that the sorter algorithm be fast, with a sub-second response between reading and control actuation.\n2 BAYESIAN NE1WORK BASED SOR1ER CONIROL\nAlthough uncertainty and improved knowledge of the composition of the waste and soil streams is important at several stages in the remediation process, we concentrate in this paper on the segmented sorter. The main charac teristics of this process control problem are the following:\nI. A multi criteria objective to achieve high throughput and low slag volume subject to maximum contamina tion constraints on soil returned to the pit and mini mal contamination of slag drums. The parameters are specified contractually.\n�l. II\nwe: waste com��i�oA(\nL �---;;;;)(ED-WASlE SOIL CONTAM !NATION CONCENTRATOR ]\nfriability sample contaminate density\nFIG 2A: WASlE CHARAClERISTICS\nSOIL ASSAY\nsample sensor\nFIG 20: CONTAMINATE CONCENTRATOR\n=\n� ., §\" (j 0 ::s a -\n:3' ... (j 0 ::s ,., � 5\" .....\n�- a:: �· >< ... Q.\n� ,., - ... e:\n� ., it\n� 8i\n666 Welch and Smith\nFigure 2. Displayed is the full Bayesian network for the contaminate concentrator model. Oval shaped nodes are continuous variables with conditional log Gaussian distributions. The upper bar chart (2E) shows the prior waste distribution from dump records. The mid dle chart (2F) shows the posterior waste composition (WC) after updating the network with the assay results (ACD). Lower chart (2G) and displayed network shows posterior distributions given the concentrator reading of a soil sample (SS & ACD). The two graphs show predicted sample contamination SCD given assay results (ACD) before (2H) and after (2J) observation of sample sensor (SS). At the concentrator (fig 20), the predicted soil sample contamination and sensor are shown. Even though the sensor reading is quite high (8.0), the model predicts a low contamination ( -34.5). The reason is that the high sensor reading is an indicator of high amounts of the wt-0 waste type, which has a high ratio of masking agent to contaminate. The nodes WC, L, M, Fare the nearest ancestral dis crete nodes to SCD and are, therefore, the source of the mixture distributions of SCD.\n2. Volume reduction can only be achieved with a small sort sample. TRU waste contamination is attached to soil particles. The contaminated particles could be uniformly distributed through the soil box but most likely the TRU waste is highly concentrated in small very active particles distributed irregularly in the box. The soil box assay only provides a total contamina tion measurement. Slag volume reduction is depend ent on the ability to pick out the small samples of soil that contain the highly active particles.\n3. Studies showed that the neutron sensor could not be effective with small samples and does not have the throughput required. The gamma sensor can achieve high throughput with small samples, but is biased as explained in the previous section.\n4. Uncertainty arises because of the unknown state of the buried waste, the location of various waste types in the pit, the state of the containers, amount of leak age and the transport mechanisms for penetration of waste into the surrounding soil. These factors con tribute to the contamination, dispersion and mixture composition of the soil input at the segmented sorter\nA Bayesian network representing variables involved in in situ leakage and transport and in-process assay and con centration of mixed waste was constructed from expert knowledge and a representative network is shown in Fig ure 2. This network can be partitioned into four compo nents.\nThe waste characteristics component (2A) begins with the root node (WC) representing the waste composition of a section of the pit from which a soil batch was extracted. The prior is assessed from a three-dimensional database of the pit. The soil surrounding the waste is collected into large bins (I 00 cu ft). Each bin is a batch of soil to be processed by the concentrator. The prior distribution of WC is assessed from dump records and is shown in the upper bar chart. The column of nodes represents various characteristics of the waste types. For display purposes, the charts show 5 waste types and 7 characteristics. In a typical application there would be several times those numbers.\nThe container condition sub-network (28) represents ex pert knowledge about the processes that can destroy con-\ntainer integrity and transport waste contamination into the surrounding soil. The potential for container leakage is affected both by the type of waste stored in the container and unknown events that may have occurred at the time of dumping up until the time of retrieval.\nThe average contamination of the batch is measured at an assay station. The assay sub-network (2C) predicts the assay results (ACD and AMD). The actual assay is as serted into the Bayesian network and the network is up dated. This results in a conditional posterior distribution over the mixtures of waste (WC) in the batch (middle bar chart - 2F), as well as the distribution of the sample con tamination (SCD) to be seen at the concentrator (graph 2H). Finally the concentrator sub-network predicts the radiation as measured by the concentrator sensor array (SS) as well as the actual contamination (SCD). As the batch is processed, the sensor array assesses the contami nation of small soil samples (0.1 cu ft). The small sample sensor value is input to the Bayes network for another update (chart 2G). This second update provides a predic tion of the actual sample contamination. (graph 2J) This prediction is the posterior probability distribution that is conditioned on the section of the pit where the batch was extracted, the information collected at the batch assay, the measured contamination of soil in the batch already proc essed, and the sensor reading for the current sample.\nFrom this derived posterior of the actual sample contami nation the expected loss of diverting the sample to the slag stream is compared with the expected loss of accepting it into the clean soil stream. The controller chooses the ac tion that minimizes the expected loss."
    }, {
      "heading" : "3. A DECISION RULE FOR OPTIMAL CONTROL.",
      "text" : "There are two actions for the controller: divert the sample to the slag stream or accept it as clean for the restoration of the pit. For simplicity, we assume that there is a rejec-\ntion threshold c such that if a sample is accepted as clean when in fact its contamination is greater than cthen a loss is incurred. Such a loss may be a penalty that is assessed or it may be the cost of reworking the sample when dis covered at a later point in the process. Similarly, rejecting a sample that is clean also incurs a loss, for example, the\nBayesian Control for Concentrating Mixed Nuclear Waste 667\ncost of unnecessary maintenance and storage. This loss matrix is displayed in Table I.\nA decision rule D maps information to action. The opti mal decision minimizes expected loss given the informa tion:\nD* (I)= arg min i A(d, c) dP(c I I) It is not hard to show that D* has the following form when A is given by table 1:\nD*(I) =divert iffP(c > c \\1) > Ao I A1•\n4. COMPILATION FOR A REAL TIME CONTROLLER\nIn theory, the Bayesian network of Figure 2, after updat ing with the assay and sensor observations, provides the distribution P( cii) = P(SCD I ACD, SS) needed for se lecting the best control decision. However, there are two practical complications.\n1. The network contains a mixture of discrete and con tinuous variables.\n2. Solving the network for each new value of the sensor requires too much computing resources for real time control.\n4.1 COMPLICATIONS IN A CG-NETWORK\nThe mixture of discrete and continuous variables can be handled using the cg-network algorithm proposed by Lau ritzen [1992]. However, the Lauritzen algorithm only pro vides an approximation, the closest Gaussian to the mix ture. This approximation can be very gross. Also, the al gorithm needs some minor alteration to accommodate near zero values. It is not hard to modifY the algorithm to ac commodate these problems (see appendix). However, the time for updating the full network did not meet the re quirements of the controller.\n4.2 A REAL TIME ALGORITHM FOR BATCH PROCESSING\nA Bayesian network is a representation of the joint distri bution of the variables in a problem. Many variables that are needed to assess the network are unobserved, hidden variables that give structure and meaning to the network. Among the observed variables there are differences in the frequency of observation. Such variations can be ex ploited in the control setting for efficient processing. Controls are determined at run time only by the most fre quently observed variables. Furthermore, only a few un observed variables have a direct impact on the control decision. Thus, by eliminating most variables through instantiation (of the less frequently observed variables) or integration (of the hidden variables), a large Bayesian network can often be reduced to a small network of only a few variables. This is the strategy employed in hierarchi cal control (Sethi and Zhang, 1994). The human nervous system is an example of a hierarchical control system.\nThe optimal control requires P(c I I), or P (SCD I ACD, SS) in our example. At run time while processing a soil batch, the assay variable is fixed, so that what is required is P (SCD I SS; ACD), the probability of the actual con tamination given the observed measured value, holding ACD constant. In the segmented sorter controller, the\nSCD\nFigure 3: Run-time network compiled from net work in figure 2.\nnetwork of figure 2 is reduced to that of figure 3 between the time a soil box leaves the soil assay station and is loaded into the sorter.\nThe joint distribution of figure 3 is fairly easily derived from the clique tree representation of figure 2 to obtain the clique tree for figure 3. The runtime network (figure 3) is updated with each sensor value and the resulting dis tribution of SCD is used to compute the optimal control decision as given above in section 3.\nWhen the variable SMD is also integrated out of the net work of figure 3, the result is a mixture bivariate distribu tion for SCD and SS. (Figure 4 ). Each component of the mixture has a positively sloped major axis, indicating a positive correlation between sensor and sample contami nation for a given waste type. However, the bivariate\n668 Welch and Smith\nGaussian that minimizes the Kullback-Liebler distance to this mixture has a negatively sloped major axis, indicating an inverse relation between sensor and contamination. This is a result of the high gamma, low neutron radiation from the waste type wt-0. Such waste has relatively short life and should not be included in long term slag storage and maintenance.\nA network like figure 3 is small enough that the network can be evaluated and a decision computed in less than a second, even with many waste types. If millisecond con trol decisions are required, the control decision rule can be computed as a function of the sensor reading, SS. The form of the rule will, in general, be a collection of real intervals {[sk, sk+tl } in which diversion of the sample to the slag stream is optimal. This rule is simple enough that it can be loaded onto the PLC (programmable logic con troller) implementing the divert action."
    }, {
      "heading" : "5. CONCLUSIONS",
      "text" : "Many control problems involve uncertainty about the meaning of sensory information. Bayesian networks pro vide the analysis upon which an optimal control solution can be calculated. The computational complexity that comes with the Bayesian method can be an obstacle to implementing a Bayesian network based controller. Nev ertheless, careful architectural design can reduce the re source requirements of runtime computation. In the ex ample studied in this paper, much of the computation can be completed off line, during the staging of batches in a batch process system. Essentially one recognizes that many of the variables in the original network, though im portant for the original assessment, can be absorbed into a\nmarginal distribution of variables that are either sensors that change during processing or key variables that are essential for making the control decision.\nComputation of the marginal joint distribution can be computed through a mixture of strategies. Often this can be accomplished by using the potentials of the cliques for the larger network. Adding arcs to the network or con straints on the triangulation of the network can help. Con ditioning methods as in footnote 1, and node elimination methods as found in the Shachter algorithm can also be employed.\nA batch processing system is the simplest example where differences in the observation frequency provide a strat egy for reducing the runtime computation of controls. Further study of network exact solution algorithms that are built for hierarchical control architectures holds promise for bringing the power of Bayesian networks to real time process control in highly uncertain environments.\nAcknowledgements\nThis proposed Bayesian control algorithm is in part based on a general problem identified by the authors while con sulting for Lockheed Martin Advanced Environmental Systems on a waste remediation project at the Idaho Na tional Environmental and Engineering Laboratory site. We greatly appreciate the opportunity provided by Lock heed. The application was prototyped using Bayes On Line™ from Gensym corporation.\nAppendix\nThe following algorithm will yield the exact distribution of a continuous node X in a cg-network conditioned on a set of observed nodes, Z.\nl . Update the network using Lauritzen's algorithm.\n2. In the reversed arc direction find the collection of ancestral discrete nodes, { o1 ••• Om} nearest to X.\n3. Set II= P(o1 I Z) as given by the solution in ( 1) for a given value of o1• Then instantiate o1 to that value.\n4. Recursively multiply the product II by P(oi I oi·l ... o1, Z) for some value of Oj. Then instantiate oi to that value.\n5. Repeat 4 until dm is reached. II is the joint probabil ity of all the possible sources of mixtures for X. Rec ord the mixture probability II and the mean and vari ance of X.\n6. When the recursion completes, the exact mixture dis tribution for X given Z has been obtained from the cg-network.\nThe repetitious updating of the network can be restricted to X and the continuous ancestors of X between X and { o1 ... Om}. This is often contained in a branch of the clique\nBayesian Control for Concentrating Mixed Nuclear Waste 669\ntree. Consequently, the updating in (4) need only be per formed within this branch of the clique tree.\nReferences\nCooper, G.F., 1990. The computational complexity of probabilistic inference in Bayesian networks is NP-hard. Artificial Intelligence, 42(2-3), 393-405.\nDean, T., and Boddy, M., 1994. An analysis of time de pendent planning, in Proceedings of ih National Confer ence on Artificial Intelligence.\nHorsch, M.C., and Poole, D. 1998. An anytime algorithm for decision making under uncertainty, in Proceedings of the 14th Conference on Uncertainty in Artificial Intelli gence, pp 246- 255.\nHorvitz, E., 1987, Reasoning about beliefs and actions under computational resource constraints, in Proceedings\nof J'd Conference on Uncertainty in Artificial Intelligence, pp 301-324.\nIbarguengoytia, P.H., Sucar, L.E., and Vadera, S., 1998, Any time probabilistic reasoning for sensor validation, Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence, pp 266 - 273.\nLauritzen, S., 1992, Propagation of probabilities, means, and variances in mixed graphical association models, Journal Of The American Statistical Association, pp 1098-1108.\nShachter, R.D., 1986, Evaluating influence diagrams, Op erations Research, 34(6) pp 871-882.\nSethi, S.P. and Zhang, Q., [1994) Hierarchical Decision Making in Stochastic Manufacturing Systems, Birkhauser"
    } ],
    "references" : [ {
      "title" : "The computational complexity of probabilistic inference in Bayesian networks is NP-hard",
      "author" : [ "G.F. Cooper" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Cooper,? \\Q1990\\E",
      "shortCiteRegEx" : "Cooper",
      "year" : 1990
    }, {
      "title" : "An analysis of time de­ pendent planning",
      "author" : [ "T. Dean", "M. Boddy" ],
      "venue" : "Proceedings of ih National Confer­ ence on Artificial Intelligence",
      "citeRegEx" : "Dean and Boddy,? \\Q1994\\E",
      "shortCiteRegEx" : "Dean and Boddy",
      "year" : 1994
    }, {
      "title" : "An anytime algorithm for decision making under uncertainty",
      "author" : [ "M.C. Horsch", "D. Poole" ],
      "venue" : "Proceedings of the 14th Conference on Uncertainty in Artificial Intelli­ gence,",
      "citeRegEx" : "Horsch and Poole,? \\Q1998\\E",
      "shortCiteRegEx" : "Horsch and Poole",
      "year" : 1998
    }, {
      "title" : "Reasoning about beliefs and actions under computational resource constraints",
      "author" : [ "E. Horvitz" ],
      "venue" : null,
      "citeRegEx" : "Horvitz,? \\Q1987\\E",
      "shortCiteRegEx" : "Horvitz",
      "year" : 1987
    }, {
      "title" : "Any time probabilistic reasoning for sensor validation",
      "author" : [ "P.H. Ibarguengoytia", "L.E. Sucar", "S. Vadera" ],
      "venue" : "Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Ibarguengoytia et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Ibarguengoytia et al\\.",
      "year" : 1998
    }, {
      "title" : "Propagation of probabilities, means, and variances in mixed graphical association models, Journal Of The American Statistical Association, pp 1098-1108",
      "author" : [ "S. Lauritzen" ],
      "venue" : null,
      "citeRegEx" : "Lauritzen,? \\Q1992\\E",
      "shortCiteRegEx" : "Lauritzen",
      "year" : 1992
    }, {
      "title" : "Evaluating influence diagrams",
      "author" : [ "R.D. Shachter" ],
      "venue" : "Op­ erations Research,",
      "citeRegEx" : "Shachter,? \\Q1986\\E",
      "shortCiteRegEx" : "Shachter",
      "year" : 1986
    }, {
      "title" : "Hierarchical Decision Making in Stochastic Manufacturing",
      "author" : [ "S.P. Sethi", "Q. Zhang" ],
      "venue" : null,
      "citeRegEx" : "Sethi and Zhang,? \\Q1994\\E",
      "shortCiteRegEx" : "Sethi and Zhang",
      "year" : 1994
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Although Bayesian networks provide superior representa­ tion and inference capabilities, it is also known that \"solving\" a Bayesian network is NP-hard (Cooper [1990]).",
      "startOffset" : 152,
      "endOffset" : 166
    }, {
      "referenceID" : 1,
      "context" : "A common work-around to Bayesian network complexity is to use approximate solutions often in the form of \"any­ time\" algorithms (Dean and Boddy [1994], Horvitz Clayton Smith University of Denver Research Institute Denver, Colorado 80208 clasmith@d u.",
      "startOffset" : 129,
      "endOffset" : 151
    }, {
      "referenceID" : 2,
      "context" : "[ 1987], Ibarguengoytia et al [ 1998], Horsch and Poole [1998]).",
      "startOffset" : 39,
      "endOffset" : 63
    }, {
      "referenceID" : 7,
      "context" : "This is the strategy employed in hierarchi­ cal control (Sethi and Zhang, 1994).",
      "startOffset" : 56,
      "endOffset" : 79
    } ],
    "year" : 2011,
    "abstractText" : "A control algorithm for batch processing of mixed waste is proposed based on conditional Gaussian Bayesian networks. The network is compiled during batch staging for real-time re­ sponse to sensor input.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}