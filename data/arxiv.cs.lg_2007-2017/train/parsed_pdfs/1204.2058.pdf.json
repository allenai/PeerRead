{
  "name" : "1204.2058.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Shalini Puri", "Sona Kaushik" ],
    "emails" : [ "eng.shalinipuri30@gmail.com", "sonakaushik22@gmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "DOI : 10.5121/ijdkp.2012.2201 1\nIn this new and current era of technology, advancements and techniques, efficient and effective text document classification is becoming a challenging and highly required area to capably categorize text documents into mutually exclusive categories. Fuzzy similarity provides a way to find the similarity of features among various documents. In this paper, a technical review on various fuzzy similarity based models is given. These models are discussed and compared to frame out their use and necessity. A tour of different methodologies is provided which is based upon fuzzy similarity related concerns. It shows that how text and web documents are categorized efficiently into different categories. Various experimental results of these models are also discussed. The technical comparisons among each model’s parameters are shown in the form of a 3-D chart. Such study and technical review provide a strong base of research work done on fuzzy similarity based text document categorization.\nKEYWORDS\nText Classification, Feature Extraction, Feature Clustering, Data Dimensionality, Fuzzy Similarity, Fuzzy Association, Membership Function, Data Sets"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Text categorization [1] [2] is an upcoming and vital field in today’s world which is most importantly required and demanded to efficiently categorize various text documents into different categories. Artificial Intelligence [3] – [5] provides many learning methods and paradigms to represent, interpret and acquire domain knowledge to help other documents in learning. Such categorization must produce the accurate and correct results with high performance. Due to the huge data size and complexity, data dimensionality reduction has also been a primary concern. Great levels of efforts have been put in this direction, so that the major problem of curse of dimensionality can be reduced.\nText documents clusterization [1] [2] [6] has been paid good attention. Many models and techniques have been developed for clustering. The clustering techniques can be applied to the web documents also. In this way, they can be categorized into their major and respective categories of business, stock, sports, cricket, movie, news and many more. Therefore, the unsupervised learning paradigm [6] is used to make the document clusters. It does not include any prior information and knowledge, that’ why it requires complex text processing techniques.\nNowadays, text classification [7] – [16] [19] - [28] is gaining more attention and focus for text categorization activities [17] [18] even at the overhead of increased cost. Research is also being done for the fuzzy association, signature, c-means, algorithms and methods for categorization tasks. Text classification with fuzzy logic base provides a better forum to sufficiently categorize\nthe text and web documents. It also results in justified solutions with reduced efforts. When it is combined with the feature clustering technique, it highly improves the representation of features. It further improves the storage performance and decreases the risks of feature ambiguity. Therefore, text classification techniques provide prior information and classification knowledge, so that classifiers can be made learnable to further categorize text and web documents. Many researchers are doing well in this area. Some of the applications in this field are, text classification system SECTCS (Smart English and Chinese Text Classification System) [8], segmenting handwritten text [9], nonlinear dimensionality reduction techniques [10] [11], complex linguistic features in context - sensitive text classification techniques [7] [12], cyber terrorism investigation [13], spam filtering [14] [15], topic spotting, email routing, language guessing, and many more. Text Classification and clustering are two opposite extremes with regard to the extent of human supervision they require. Real-life applications are considered somewhere in between, because unlabeled data is easy to collect but labelling data is more helpful.\nAs these techniques pay the attention on the accurate and correct categorization; they focus on the text pre-processing and document similarity analysis as well. During text pre-processing, the set of words are extracted to find out the concepts as features or words by using Verb-Argument Structures [6] or Pseudo Thesaurus [20]. In some research areas, bag-of-words [25] is found from the text documents. This word set is a huge collection of words that needs to be reduced further by using feature clustering [25] [28] methods. The resultant small collection of words is analyzed for the document similarity [16] [22] - [28]. If some of the documents are found similar, they are categorized into one. Many fuzzy similarity based models and algorithms have been introduced with the very nature of its membership functions [22] – [28], fuzzy association [24] [28], fuzzy C-means, production rules [19] [27]. Text classification using fuzzy based similarity is an essential task in today’s categorization forum and typically, getting a great attention in various related application fields and areas. Nowadays, such concerns have been the part of many applications and related studies. Some of the applications are related to the learning evaluation [28] and education learning styles [19].\nSection 2 discusses the key points and related aspects of theoretical background of fuzzy similarity based models and techniques. Section 3 discusses a technical comparative study on different fuzzy similarity based models. It discusses and shows various methods and their methodologies in detail. In section 4, an analytical discussion on the experimental results is given. Various results and their important concerns are discussed and shown with respect to different parameters. Finally, section 5 concludes the paper."
    }, {
      "heading" : "2. THEORETICAL BACKGROUND",
      "text" : "Over the last decades, fuzzy similarity based text document classification has got attention very much and considered as an important research area. Different techniques, models and ways are searched to design a best categorization system. Such field is not only used in the small level organizations, industries and corporate, but also covers a vast community all around the world. The new techniques, their collaboration and research always open a new paradigm towards the advancements.\nCurrent research studies show that fuzzy logic and its area of concerns provide efficient base for text categorization, dimensionality reduction, feature selection and extraction, and similarity analyzer related issues. Fuzzy logic is considered as a branch of logic especially designed for representing knowledge and human reasoning in such a way that it is amenable to processing by a computer [3]. The major concepts of fuzzy logic are fuzzy sets, linguistic variable, possibility distributions, and fuzzy if – then rules. Fuzziness or Degree of Uncertainty pertains to the uncertainty associated with a system, i.e., the fact that nothing can be predicted with exact\nprecision. Practically, the values of variables are not always precise; rather approximate values are more likely to be known. The vagueness can adequately be handled using fuzzy set theory. This theory provides a strict mathematical framework using which vague conceptual phenomena can be studied rigorously. It is also called the property of language [3] – [5]. Its main source is the imprecision involved in defining and using symbols. It is a property of models, computational procedures, and languages. Hence, a fuzzy set is a collection of distinct elements with a varying degree of relevance or inclusion."
    }, {
      "heading" : "2.1. Feature Clustering",
      "text" : "The concept of feature clustering [10] [11] [22] – [24] enhances the provision of text dimension criticality solution. It is an efficient way to compress the collected feature sets more, so that the resultant data can be handled and used properly without any loss. These clusters are represented either by the term of maximum frequency in a group (or cluster) [22] [24] or can be found by self constructing feature clustering algorithm [23]. Feature clustering is also done with the use of the pseudo-thesaurus by identifying each term [6] as noun, pronoun, adverb, adjective, delimiters etc. Researchers have shown that it helps to reduce the high dimensional data into smaller one adequately."
    }, {
      "heading" : "2.2. Fuzzy Association",
      "text" : "Fuzzy sets pay an important and vital role in text categorization. They are widely recognized as many real world relations are intrinsically fuzzy. Fuzzy association [24] [28] is used to discover important associations between different sets of attribute values. A fuzzy association rule A\nC is very strong if both A C and C A are strong."
    }, {
      "heading" : "2.3. Fuzzy Production Rules",
      "text" : "The novel method of rule-base construction and a rule weighting mechanism [19] [27] can result in a rule-base containing rules of different lengths, which is much more useful when dealing with high dimensional data sets."
    }, {
      "heading" : "2.4. Fuzzy Clustering and C-Means",
      "text" : "In fuzzy clustering [28], each point has a degree of belonging to clusters, as in fuzzy logic, rather than belonging completely to one cluster. Thus, points on the edge of a cluster may be in the cluster to a lesser degree than points in the centre of cluster."
    }, {
      "heading" : "2.5. Fuzzy Signatures",
      "text" : "Fuzzy signatures [26] are used in those applications and key areas which require the handling of complex structured data and interdependent feature problems. They can also used in special concerns where data is missing. So, this depicts many areas where objects with very complex and sometimes interdependent features are to be classified along with the evaluation of similarities and dissimilarities. This leads a complex decision model hard to construct effectively. Due to the very nature of fuzzy signatures of flexibility, it can be used for many text mining tasks, with the benefit of the hierarchical structuring; therefore, the text document classification models can be constructed [26]."
    }, {
      "heading" : "3. A TECHNICAL COMPARATIVE STUDY ON DIFFERENT FUZZY SIMILARITY BASED MODELS",
      "text" : "Research work on fuzzy similarity based models and techniques has taken a new turn for the text classification tasks with the involvement of different key concerns related to the fuzzy logic and sets. Therefore, these techniques provide better ways and solutions for categorization."
    }, {
      "heading" : "3.1. A Comparative Description on Various Proposed Techniques",
      "text" : "The comparative detailed description on different techniques is described in table 1. It defines the challenges and problems occurred in each model, which are the related key issues. These models focus on different concerned issues and necessities of the text classification area. The similarity technique shows the efficient similarity criteria used in the model.\nto include evolving information easily and to handle missing information. pattern among index terms.\n6.\n[27]\nChallenge in high dimensional systems to generate every possible rule with respect to all antecedent combinations. Proposed a method for rule generation, which can result in a rule-base containing rules of different lengths. Production rule matching.\nLearning Evaluation\n7.\n[28]\nIssues of expressing the fuzziness and uncertainty of domain knowledge and the semantic retrieval of fuzzy information. • Produced an extended fuzzy ontology model/ • Proposed a semantic query expansion technology to implement semantic information query based on the property\nvalues and the relationships of fuzzy concepts.\nSemantic similarity and semantic correlation in fuzzy concept analysis."
    }, {
      "heading" : "3.2. A Tour on Different Methodologies and Procedures",
      "text" : "Various methodologies and procedures are depicted in table 2. These methodologies are shown in steps. [22], [23], [24], and [25] show that text documents or web documents are considered for text classification which use a predefined set of classes initially in the training phase. In [22], [23] and [24], the text is pre-processed and cleaned to extract all important features. In [25], a bag of words is used and processed to get the word patterns. Next, the fuzzy similarity techniques are applied as shown in table 1. Finally, text is classified using the classifier. Different methods have implemented different procedures to categorize the text.\nThe use of fuzzy signature for the text classification of the non-segmented text [26] shows that how the non-segmentable text can be segmented and classified. In [27], a rule based weighting technique is used to efficiently perform the data mining tasks. The learning evaluation using the extended fuzzy ontology model [28] is provided for learning techniques based classification. The given models have the key concern of the feature set reduction and improve the overall system performance.\n[23]\nC o n\nst ru\nct ed\nC a te\ng o ri\nes f\no r\nT ex\ntu a l\nC la\nss if\nic a ti\no n\nU si\nn g F\nu zz\ny\nS im\nil a ri\nty a\nn d\nA g\ng lo\nm er\na ti\nv e\nH ie\nra rc\nh ic\na l\nM et\nh o d\ns\n[24]\nW eb\nD o cu\nm en\nt C\nla ss\nif ic\na ti\no n\nB a se\nd\no n\nF u\nzz y A\nss o\nci a ti\no n\n[25]\nA F\nu zz\ny S\nel f-\nC o n\nst ru\nct in\ng F\nea tu\nre C\nlu st\ner in\ng A\nlg o ri\nth m\nfo r\nT ex\nt C\nla ss\nif ic\na ti\no n\n[26]\nE x\np lo\nri n\ng T\nh e\nU se\no f\nF u\nzz y S\nig n\na tu\nre\nfo r\nT ex\nt M\nin in\ng\n[27]\nE ff\nic ie\nn t\nF u\nzz y\nR\nu le\nG en\ner a ti\no n\n: A\nN ew\nA p\np ro\na ch\nU si\nn g D\na ta\nM in\nin g P\nri n\nci p\nle s\na n\nd R\nu le\nW\nei g h\nti n\ng\n[28]\nF u\nzz y\nO n\nto lo\ng y G\nen e ra\nti o\nn M\no d\nel u\nsi n\ng F\nu zz\ny\nC lu\nst er\nin g f\no r\nL ea\nrn in\ng E\nv a lu\na ti\no n"
    }, {
      "heading" : "4. AN ANALYTICAL DISCUSSION ON EXPERIMENTAL RESULTS",
      "text" : "Various fuzzy similarity models for text classification have been successfully implemented. Their experimental results are shown and discussed in detail. The accuracy and performance parameters are evaluated and checked to see the utility of the methods and the current state - of – the - art."
    }, {
      "heading" : "4.1. Experimental Results: Data Sets and Evaluation",
      "text" : "The experiments and results found for various models are discussed in table 3. It shows total data sets used, total number of categories generated and the results found for each technique. The data sets are considered from the newsgroups, newspapers, different text document pages of corpus, portals, Reuters, and repositories. Different categories are built initially in the training phase. These techniques have used documents from small corpus to large corpora, and considered few categories to many categories.\nExperimental results found show that how the corresponding proposed technique is comparatively better than others. Some results have shown the performance and accuracy improvements, speed increase, reduced storage and many advantageous parameters.\n[24] Yahoo! : 350\nmost freque nt keywo rds from each categor y and total distinct keywo rds are 2033.\nODP: 350 most frequent keywords from each category and total distinct keywords are 1889. Government (gov), Health (health), News & Media (news), Recreation & Sports (rec), Science (sci), Social Science (sosci), Society & Culture (soc). ODP Portal 13 Categories Arts (art), Business (bus),\nComputers (com), Games (game), Health (health), Home (home), Kids and Teens (kid), News (news), Recreation (rec), Science (sci), Shopping (shop), Society (soc), Sports (sport).\nImprovement in Fuzzy over Vector Method: Yahoo (TM): 13.7%, Yahoo (BM): 31.3%, ODP (TM):17.7%,\nand ODP (BM): 32%.\n• For Accuracy Improvement\nof Vector Length of 10 in Yahoo!, TM: 17.9% and BM: 28.9%.\n• Used only English documents and\nignorance of NonEnglish docs( World, Regional).\n• Collected\napproximately 18,000 documents from each Web directory.\nData Sets Fuzzy Topm\nost\nFuzzy\nBottom\nmost\nVector Topmo\nst\nVe cto\nr\nBo tto m mo\nst\nY ah\no o ! 81.5 60.1 67.8 28. 8\nO D P\n84.8 78.1 67.1 46. 1\n[25]\na. 20 Newsgroups Data Set, about\n20,000 articles taken from the Usenet newsgroups. b. Reuters Corpus Volume 1 (RCV1)\nData Set, 804,414 news stories. c. Cade12 Data with skewed\ndistribution and the three most popular classes represent more than 50 percent of all documents.\n• In a, articles are evenly distributed over 20 classes,\nand each class has about 1,000 articles. Used two-thirds of the documents for training and the rest for testing.\n• After preprocessing, found 25,718 features, or words, for\nthis data set.\nProposed method runs faster and obtains better extracted features than other methods.\n• In a, for Execution time (sec.) of different methods on 20\nNewsgroups data. For 84 extracted features, only needs 17.68 seconds, but DC and IOC require 293.98 and 28,098.05 seconds.\n• Microaveraged Accuracy (Percent) of Different\nMethods: S-FFC gets 98.46 percent in accuracy for 20 extracted features. H-FFC and M-FFC perform well in accuracy all the time, except for the case of 20 extracted features.\n• MicroP, MicroR, and MicroF1 (percent): S-FFC\ncan get best results for MicroF1, followed by MFFC, H-FFC, and DC.\n• In b, dividing the documents by the “LYRL2004” split into\n23,149 training documents and 781,265 testing documents.\n• There are 103 Topic categories\nand the distribution of the\ndocuments over the classes.\n• In c, obtained a version of this\ndata set, 40,983 documents in\ntotal with 122,607 features\nfrom which two-thirds, 27,322\ndocuments, are split for\ntraining, and the remaining,\n13,661 documents, for testing. • In b, proposed method runs much faster than DC and\nIOC.\n• H-FFC, SFFC, and M-FFC perform well in accuracy all\nthe time.\nIn c, the proposed method runs much faster than DC and IOC.\n[26]\n• A corpus of 50 Thai Documents\nfrom Thai News Websites: 15 sport documents, 15 travel documents, 15 political documents and 5 education documents.\n• Generated FMSs by frequent max\nsubstring technique from the document dataset\n• Selection of 35 FSMs from\ndocument indexing.\nSample of FMs extracted from\n50 Documents\n• Competition, Athlete, Gold Medal, Semi final round, Sport\ntype, Score, Competition result, Competition timetable, Thai travel exhibition, Tourist Attraction, The tourism authority of Thailand.\n• 4 main Categories: Sports, Travel, Political and\nEducation.\n• 2 Methods to recognize 4 document categories:\nConstruct Fuzzy Signature with the use of membership function, construct 4 fuzzy signatures, one for each type of document, AS(Sport), AS(Travel), AS(Political), and AS(Education).\n• With the use of fuzzy approach, no overlapping of\nthe index terms occurred in the documents as in SelfOrganizing Maps (SOM).\n• Increased performance due to the use of Prior knowledge.\n• Total number of FM in Sports: 8, Travel: 3, Political:\n1 and Education: 0. Competition can be a part of Sports and Political.\n• To recognize documents in both methods, fuzzy signature\nof FMSs is: AS(Sport) → created by → Government, Education institution, nonprofit organization, Business, AS(Sport) → HTML keywords, AS(Sport) → Inbound links → Quantity, Categories, AS(Sport) → from 35 FMSs.\n[27]\nUsed a number of UCL ML repository data sets\n• Generated all the rules of length 1,\n2, 3, and 4 (i.e. having 1, 2, 3, and 4 number of antecedent conditions excluding don’t care).\n• Used 10CV technique: Case\nof n - fold cross validation.\n• Construction of a rule-base by\nselecting 100 candidate rules from each class\nSome statistics of the data sets used in computer simulations • Improves classification accuracy by considering\ncooperation in a rule-base tuned by rule weighting process.\n• Increasing the maximum length of rules in the initial\nrule-base improves the classification accuracy.\n• Comparing proposed classifier and best case of\nC4.5: Improvement of 0.7, 0.3, 5.5 and 3.3 in first 4 cases of the proposed classifier, but decreased accuracy of 4.5 in 5 th one.\nData set No. of\nAttrib\nute\nNo. of\nPatterns\nNo . of Cl ass es\nIris 4 150 3 Wine 13 178 3 Thyroid 5 215 3 Sonar 60 208 2 Bupa 6 345 2 Pima 8 768 2 Glass 9 214 6\nData Sets\nProposed Classifier C4.5 Classifier\nWorst Bes\nt\nIris 95.6 94 94.\n9\nPima 7.3 72.8 75 Sonar 82.2 67.4 76.\nusing the selection metric.\n7 Wine 97.7 92.2 94. 4 Glass 68.2 68.8 72.\n7\n[28]\nLearning Evaluation for Teaching Field\n• A set of categories {C1, C2,…, C7} ⊆ {Concept\nVocabulary Set}.\n• Concept Vocabulary Set Values: {excellent, good, bad,\nmedium, strong, high, low} and the semantic relationship of every concept pair.\n• Predefinitions: factor α = 0.5, Θ = 0, watt = 0, and Threshold\nValue δ = 0.9.\n• Calculations: semsim (c1, c2) = simheuristic(c1,\nc2) = 0.9\nsemcorr(c1,c2) = corrrelation(c1, c2) =1\nsem(c1,c2) = 0.95\n• Production of Concept Connected Graph with total\n28 Different entries in 7*7 matrix of C1 to C7, where the result found (without duplication of entries) as, total number of 0 is 8 times, 1 is 7 times, 0.5 is 4 times, 0.95 is 3 times, 0.8 is 3 times, 0.35 is 2 times, and 0.9 is 1 time.\n• Graph Flow and connections among concepts are, C1→C6,\nC5, C2, and C2→C4→C7→C3.\n• Performance Evaluation based on Precision.\n• Determining the relevance of the information and obtaining\nthe exact information.\n• Shows better results found in extended fuzzy ontology\nmodel than Classical Ontology Method.\nConsider Entity concept “student” a. Property Set: {learning attitude,\nlearning ability, text scores,…} b. Property Value set:\n• learning attitude ( very good,\nbasic good, bad, very bad, …).\n• learning ability (most strong,\nvery strong, strong, general weak, weak, great weak, …).\n• text scores (extremely high,\nhigh, medium, slight low, low, …)."
    }, {
      "heading" : "4.2. Various Experimental Results on the Models",
      "text" : "The experimental results of various models show their good performance and accuracy concerns. In figure 1, these models are discussed and their studies, results, comparisons of experimental results are shown. The bars in chart are individual and independent in their identity. These results are not compared with each other; they only provide their data, and respective details.\nFuzzy term-category relation [22] is shown by manipulating membership degree for the training data and the degree value for a test web page. Six measures are used and compared where the best performance was achieved by Einstein. Accuracy performance of these algorithms in the decreasing order is shown in figure 1. With this, the training data collected from different sources is normalized and pre-processed and then these measures are applied on it. Text categorization based on the Agglomerative Hierarchical Methodology [23] with the use of fuzzy logic. As for the use of the star and clique algorithms used in the agglomerative hierarchical methodology to identify the groups of text by specifying some type of relationship rule, they obtained similar results, but the clique algorithm showed a slight advantage when compared to the star, despite having created greater number of groupings. In figure 1, star and clique algorithms are compared for the parameters, number of categories, group of 10 or more texts and categories of only one text. Clique shows better results than star.\nTo automatically classify the web documents using the fuzzy association concept [24], the relationship is captured among different index terms in documents. This approach is compared with vector space model approach and it shows improved results than VSM. To see the effect of different keyword selections for category vectors, 2 different alternatives are there: Selecting from the most frequently occurred keywords(topmost) and selecting from the least frequently occurred keywords (bottommost) with varying vector lengths have been used. Yahoo! And ODP portals are compared with each other for the topmost and bottommost cases as shown in figure 1. In [25], a small part of the total result is shown in chart. It is only shown for a subsection of the 20 newsgroups.\n[26] discusses the simple category distribution in each of the 4 type of documents of sample data. In [27] and [28], the parameters are calculated as given in the table 3. In [27], Iris showed better results over others. In [28], to make the information semantization and to improve the accuracy of information retrieval, it adopted a fuzzy concept semantic analysis for clustering to generate learning evaluation ontology. It achieves high information retrieval and improves efficiency as compared to fuzzy ontology."
    }, {
      "heading" : "5. CONCLUSIONS",
      "text" : "In this paper, different fuzzy similarity related algorithms and methodologies are discussed in detail. Different researches depict good results with the underlying techniques, mechanisms and methodologies. The experimental results provide good fuzzy based text classification with high accuracy. These models focus on new kinds of different classification issues and techniques. Therefore, these research studies and their survey contribute in providing the information about advanced fuzzy classification, related models and techniques.\nThe analytical review provides a simple summary of the sources in an organizational pattern and combines both summary and synthesis to give a new interpretation of old material. Therefore, it aims to review the critical points of current knowledge of research work including substantive findings as well as theoretical and methodological contributions. Additionally, their experimental results and their parametric data are sufficiently described and compared independently. Such comparative studied and technical analysis charts provide a strong base to understand the use of fuzzy and its related concerns. Various experimental results have proven themselves good for the models and techniques. The utility of fuzzy logic and its areas give a good effect on text mining and text classification. Therefore, fuzzy similarity is used in many application areas and fields all around the world for categorization."
    }, {
      "heading" : "ACKNOWLEDGEMENTS",
      "text" : "We would like to give our special thanks to Asst. Prof. Pankaj Gupta, Dept. of Computer Science, Birla Institute of Technology, Noida Extension Centre, Uttar Pradesh, India and Dr. Vikas Saxena, Dept. of Computer Science, Jaypee Institute of Information Technology, Noida, Uttar Pradesh, India for their help and guidance."
    } ],
    "references" : [ {
      "title" : "An Efficient Concept-Based Mining Model for Enhancing Text Clustering",
      "author" : [ "Shady Shehata", "Fakhri Karray", "Mohamed S. Kamel" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2010
    }, {
      "title" : "Learning Context for Text Categorization",
      "author" : [ "Y.V. Haribhakta", "Parag Kulkarni" ],
      "venue" : "International Journal of Data Mining & Knowledge Management Process (IJDKP),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2011
    }, {
      "title" : "SECTCS: Towards improving VSM and Naive Bayesian Classifier",
      "author" : [ "Mingyu Lu", "Keyun Hul", "Yi Wu", "Yuchang Lu", "Lizhu" ],
      "venue" : "Zhoul,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2002
    }, {
      "title" : "Segmenting Handwritten Text Using Supervised Classification Techniques",
      "author" : [ "Yi Sun", "Timothy S. Butler", "Alex Shafarenko", "Rod Adams", "Martin Loomes", "Neil Davey" ],
      "venue" : "Proc. of IEEE International Joint Conference on Neural Networks,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2004
    }, {
      "title" : "Text Classification based on Nonlinear Dimensionality, Reduction Techniques and Support Vector Machines",
      "author" : [ "Lukui Shi", "Jun Zhang", "Enhai Liu", "Pilian He" ],
      "venue" : "Third IEEE International Conference on Natural Computation,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2007
    }, {
      "title" : "Comparing Dimension Reduction Techniques for Arabic Text Classification using BPNN Algorithm",
      "author" : [ "Fouzi Harrag", "Eyas El - Qawasmah", "Abdul Malik S. - Salman" ],
      "venue" : "First IEEE International Conference on Integrated Intelligent Computing (ICIIC),",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2010
    }, {
      "title" : "Using Complex Linguistic Features In Context - Sensitive Text Classification Techniques",
      "author" : [ "Alex K.S. Wong", "John W.T. Lee", "Daniel S. Yeung" ],
      "venue" : "Proc. of the Fourth IEEE International Conference on Machine Learning and Cybernetics,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2005
    }, {
      "title" : "Text Classification Techniques Used To Facilitate Cyber Terrorism Investigation",
      "author" : [ "David Allister Simanjuntak", "Heru Purnomo Ipung", "Charles Lim", "Anto Satriyo Nugroho" ],
      "venue" : "Second IEEE International Conference on Advances in Computing, Control, and Telecommunication Technologies (ACT), pp",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2010
    }, {
      "title" : "Spam or Ham”, Introduction to Artificial Intelligence Project",
      "author" : [ "M. Fong" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2008
    }, {
      "title" : "Text Document Classification: An Approach Based On Indexing",
      "author" : [ "B.S. Harish", "S. Manjunath", "D.S. Guru" ],
      "venue" : "International Journal of Data Mining & Knowledge Management Process (IJDKP),",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2012
    }, {
      "title" : "Distortion Based Algorithms For Privacy Preserving Frequent Item Set Mining",
      "author" : [ "K. Srinivasa Rao", "V. Chiranjeevi" ],
      "venue" : "International Journal of Data Mining & Knowledge Management Process (IJDKP),",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2011
    }, {
      "title" : "Data Quality Measurement on Categorical Data Using Genetic Algorithm",
      "author" : [ "J. Malar Vizhi", "T. Bhuvaneswari" ],
      "venue" : "International Journal of Data Mining & Knowledge Management Process (IJDKP),",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2012
    }, {
      "title" : "Classifying Modality Learning Styles based on Production Fuzzy Rules",
      "author" : [ "Rahmah Mokhtar", "Siti Norul Huda Sheikh Abdullah", "Nor Azan Mat Zin" ],
      "venue" : "IEEE International Conference on Pattern Analysis and Intelligent Robotics (ICPAIR),",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2011
    }, {
      "title" : "Facial Emotional Expressions of Life-like Character Based on Text Classifier and Fuzzy Logic",
      "author" : [ "Surya Sumpeno", "Mochamad Hariadi", "Mauridhi Hery Purnomo" ],
      "venue" : "IAENG International Journal of Computer Science",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2011
    }, {
      "title" : "Concept Mining of Semantic Web Services By Means Of Extended Fuzzy Formal Concept Analysis (FFCA)",
      "author" : [ "Giuseppe Fenza", "Vincenzo Loia", "Sabrina Senatore" ],
      "venue" : "IEEE International Conference on Systems,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2008
    }, {
      "title" : "A Comparative Study of Web-pages Classification Methods using Fuzzy Operators applied to Arabic Web-pages",
      "author" : [ "Ahmad T. Al-Taani", "Noor Aldeen K. Al - Awad" ],
      "venue" : "World Academy of Science, Engineering and Technology,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2005
    }, {
      "title" : "An Analysis of Constructed Categories for Textual Classification using Fuzzy Similarity and Agglomerative Hierarchical Methods",
      "author" : [ "Marcus Vinicius", "C. Guelpeli", "Ana Cristina", "Bicharra Garcia" ],
      "venue" : "Third International IEEE Conference Signal-Image Technologies and Internet-Based System (SITIS),",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2007
    }, {
      "title" : "Web Document Classification Based on Fuzzy Association",
      "author" : [ "Choochart Haruechaiyasak", "Mei-Ling Shyu", "Shu-Ching Chen", "Xiuqi Li" ],
      "venue" : "Proc. of Annual International Computer Software and Applications Conference (COMPSAC),",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2002
    }, {
      "title" : "A Fuzzy Self-Constructing Feature Clustering Algorithm for Text Classification",
      "author" : [ "Jung-Yi Jiang", "Ren-Jia Liou", "Shie-Jue Lee" ],
      "venue" : "IEEE Transactions On Knowledge And Data Engineering,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2011
    }, {
      "title" : "Exploring the Use of Fuzzy Signature for Text Mining",
      "author" : [ "Kok Wai Wong", "Todsanai Chumwatana", "Domonkos Tikk" ],
      "venue" : "IEEE International Conference on Fuzzy Systems (FUZZ),",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2010
    }, {
      "title" : "Efficient Fuzzy Rule Generation: A New Approach Using Data Mining Principles and Rule Weighting",
      "author" : [ "O. Dehzangi", "M.J. Zolghadri", "S.M.S. Taheri" ],
      "venue" : "Fakhrahmad,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2007
    }, {
      "title" : "Fuzzy Ontology Generation Model using Fuzzy Clustering for Learning Evaluation",
      "author" : [ "Qing Yang", "Wei Chen", "Bin Wen" ],
      "venue" : "IEEE International Conference on Granular Computing (GRC),",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Text documents clusterization [1] [2] [6] has been paid good attention.",
      "startOffset" : 38,
      "endOffset" : 41
    }, {
      "referenceID" : 0,
      "context" : "Therefore, the unsupervised learning paradigm [6] is used to make the document clusters.",
      "startOffset" : 46,
      "endOffset" : 49
    }, {
      "referenceID" : 1,
      "context" : "Nowadays, text classification [7] – [16] [19] - [28] is gaining more attention and focus for text categorization activities [17] [18] even at the overhead of increased cost.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 9,
      "context" : "Nowadays, text classification [7] – [16] [19] - [28] is gaining more attention and focus for text categorization activities [17] [18] even at the overhead of increased cost.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 12,
      "context" : "Nowadays, text classification [7] – [16] [19] - [28] is gaining more attention and focus for text categorization activities [17] [18] even at the overhead of increased cost.",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 21,
      "context" : "Nowadays, text classification [7] – [16] [19] - [28] is gaining more attention and focus for text categorization activities [17] [18] even at the overhead of increased cost.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 10,
      "context" : "Nowadays, text classification [7] – [16] [19] - [28] is gaining more attention and focus for text categorization activities [17] [18] even at the overhead of increased cost.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 11,
      "context" : "Nowadays, text classification [7] – [16] [19] - [28] is gaining more attention and focus for text categorization activities [17] [18] even at the overhead of increased cost.",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 2,
      "context" : "Some of the applications in this field are, text classification system SECTCS (Smart English and Chinese Text Classification System) [8], segmenting handwritten text [9], nonlinear dimensionality reduction techniques [10] [11], complex linguistic features in context - sensitive text classification techniques [7] [12], cyber terrorism investigation [13], spam filtering [14] [15], topic spotting, email routing, language guessing, and many more.",
      "startOffset" : 133,
      "endOffset" : 136
    }, {
      "referenceID" : 3,
      "context" : "Some of the applications in this field are, text classification system SECTCS (Smart English and Chinese Text Classification System) [8], segmenting handwritten text [9], nonlinear dimensionality reduction techniques [10] [11], complex linguistic features in context - sensitive text classification techniques [7] [12], cyber terrorism investigation [13], spam filtering [14] [15], topic spotting, email routing, language guessing, and many more.",
      "startOffset" : 166,
      "endOffset" : 169
    }, {
      "referenceID" : 4,
      "context" : "Some of the applications in this field are, text classification system SECTCS (Smart English and Chinese Text Classification System) [8], segmenting handwritten text [9], nonlinear dimensionality reduction techniques [10] [11], complex linguistic features in context - sensitive text classification techniques [7] [12], cyber terrorism investigation [13], spam filtering [14] [15], topic spotting, email routing, language guessing, and many more.",
      "startOffset" : 217,
      "endOffset" : 221
    }, {
      "referenceID" : 5,
      "context" : "Some of the applications in this field are, text classification system SECTCS (Smart English and Chinese Text Classification System) [8], segmenting handwritten text [9], nonlinear dimensionality reduction techniques [10] [11], complex linguistic features in context - sensitive text classification techniques [7] [12], cyber terrorism investigation [13], spam filtering [14] [15], topic spotting, email routing, language guessing, and many more.",
      "startOffset" : 222,
      "endOffset" : 226
    }, {
      "referenceID" : 1,
      "context" : "Some of the applications in this field are, text classification system SECTCS (Smart English and Chinese Text Classification System) [8], segmenting handwritten text [9], nonlinear dimensionality reduction techniques [10] [11], complex linguistic features in context - sensitive text classification techniques [7] [12], cyber terrorism investigation [13], spam filtering [14] [15], topic spotting, email routing, language guessing, and many more.",
      "startOffset" : 310,
      "endOffset" : 313
    }, {
      "referenceID" : 6,
      "context" : "Some of the applications in this field are, text classification system SECTCS (Smart English and Chinese Text Classification System) [8], segmenting handwritten text [9], nonlinear dimensionality reduction techniques [10] [11], complex linguistic features in context - sensitive text classification techniques [7] [12], cyber terrorism investigation [13], spam filtering [14] [15], topic spotting, email routing, language guessing, and many more.",
      "startOffset" : 314,
      "endOffset" : 318
    }, {
      "referenceID" : 7,
      "context" : "Some of the applications in this field are, text classification system SECTCS (Smart English and Chinese Text Classification System) [8], segmenting handwritten text [9], nonlinear dimensionality reduction techniques [10] [11], complex linguistic features in context - sensitive text classification techniques [7] [12], cyber terrorism investigation [13], spam filtering [14] [15], topic spotting, email routing, language guessing, and many more.",
      "startOffset" : 350,
      "endOffset" : 354
    }, {
      "referenceID" : 8,
      "context" : "Some of the applications in this field are, text classification system SECTCS (Smart English and Chinese Text Classification System) [8], segmenting handwritten text [9], nonlinear dimensionality reduction techniques [10] [11], complex linguistic features in context - sensitive text classification techniques [7] [12], cyber terrorism investigation [13], spam filtering [14] [15], topic spotting, email routing, language guessing, and many more.",
      "startOffset" : 376,
      "endOffset" : 380
    }, {
      "referenceID" : 0,
      "context" : "During text pre-processing, the set of words are extracted to find out the concepts as features or words by using Verb-Argument Structures [6] or Pseudo Thesaurus [20].",
      "startOffset" : 139,
      "endOffset" : 142
    }, {
      "referenceID" : 13,
      "context" : "During text pre-processing, the set of words are extracted to find out the concepts as features or words by using Verb-Argument Structures [6] or Pseudo Thesaurus [20].",
      "startOffset" : 163,
      "endOffset" : 167
    }, {
      "referenceID" : 18,
      "context" : "In some research areas, bag-of-words [25] is found from the text documents.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 18,
      "context" : "This word set is a huge collection of words that needs to be reduced further by using feature clustering [25] [28] methods.",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 21,
      "context" : "This word set is a huge collection of words that needs to be reduced further by using feature clustering [25] [28] methods.",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 9,
      "context" : "The resultant small collection of words is analyzed for the document similarity [16] [22] - [28].",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 15,
      "context" : "The resultant small collection of words is analyzed for the document similarity [16] [22] - [28].",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 21,
      "context" : "The resultant small collection of words is analyzed for the document similarity [16] [22] - [28].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 15,
      "context" : "Many fuzzy similarity based models and algorithms have been introduced with the very nature of its membership functions [22] – [28], fuzzy association [24] [28], fuzzy C-means, production rules [19] [27].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 21,
      "context" : "Many fuzzy similarity based models and algorithms have been introduced with the very nature of its membership functions [22] – [28], fuzzy association [24] [28], fuzzy C-means, production rules [19] [27].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 17,
      "context" : "Many fuzzy similarity based models and algorithms have been introduced with the very nature of its membership functions [22] – [28], fuzzy association [24] [28], fuzzy C-means, production rules [19] [27].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 21,
      "context" : "Many fuzzy similarity based models and algorithms have been introduced with the very nature of its membership functions [22] – [28], fuzzy association [24] [28], fuzzy C-means, production rules [19] [27].",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 12,
      "context" : "Many fuzzy similarity based models and algorithms have been introduced with the very nature of its membership functions [22] – [28], fuzzy association [24] [28], fuzzy C-means, production rules [19] [27].",
      "startOffset" : 194,
      "endOffset" : 198
    }, {
      "referenceID" : 20,
      "context" : "Many fuzzy similarity based models and algorithms have been introduced with the very nature of its membership functions [22] – [28], fuzzy association [24] [28], fuzzy C-means, production rules [19] [27].",
      "startOffset" : 199,
      "endOffset" : 203
    }, {
      "referenceID" : 21,
      "context" : "Some of the applications are related to the learning evaluation [28] and education learning styles [19].",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 12,
      "context" : "Some of the applications are related to the learning evaluation [28] and education learning styles [19].",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 4,
      "context" : "The concept of feature clustering [10] [11] [22] – [24] enhances the provision of text dimension criticality solution.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 5,
      "context" : "The concept of feature clustering [10] [11] [22] – [24] enhances the provision of text dimension criticality solution.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 15,
      "context" : "The concept of feature clustering [10] [11] [22] – [24] enhances the provision of text dimension criticality solution.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 17,
      "context" : "The concept of feature clustering [10] [11] [22] – [24] enhances the provision of text dimension criticality solution.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 15,
      "context" : "These clusters are represented either by the term of maximum frequency in a group (or cluster) [22] [24] or can be found by self constructing feature clustering algorithm [23].",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 17,
      "context" : "These clusters are represented either by the term of maximum frequency in a group (or cluster) [22] [24] or can be found by self constructing feature clustering algorithm [23].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 16,
      "context" : "These clusters are represented either by the term of maximum frequency in a group (or cluster) [22] [24] or can be found by self constructing feature clustering algorithm [23].",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 0,
      "context" : "Feature clustering is also done with the use of the pseudo-thesaurus by identifying each term [6] as noun, pronoun, adverb, adjective, delimiters etc.",
      "startOffset" : 94,
      "endOffset" : 97
    }, {
      "referenceID" : 17,
      "context" : "Fuzzy association [24] [28] is used to discover important associations between different sets of attribute values.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 21,
      "context" : "Fuzzy association [24] [28] is used to discover important associations between different sets of attribute values.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 12,
      "context" : "The novel method of rule-base construction and a rule weighting mechanism [19] [27] can result in a rule-base containing rules of different lengths, which is much more useful when dealing with high dimensional data sets.",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 20,
      "context" : "The novel method of rule-base construction and a rule weighting mechanism [19] [27] can result in a rule-base containing rules of different lengths, which is much more useful when dealing with high dimensional data sets.",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 21,
      "context" : "In fuzzy clustering [28], each point has a degree of belonging to clusters, as in fuzzy logic, rather than belonging completely to one cluster.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 19,
      "context" : "Fuzzy signatures [26] are used in those applications and key areas which require the handling of complex structured data and interdependent feature problems.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 19,
      "context" : "Due to the very nature of fuzzy signatures of flexibility, it can be used for many text mining tasks, with the benefit of the hierarchical structuring; therefore, the text document classification models can be constructed [26].",
      "startOffset" : 222,
      "endOffset" : 226
    }, {
      "referenceID" : 15,
      "context" : "[22] Comparative study of web-pages classification for Arabic Web-pages.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[23] • Challenge of ambiguity in systems to handle natural language.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "[24] The same word or vocabulary to describe different entities creates ambiguity, especially in the Web environment for large user population is large.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "[25] Need of a powerful method to reduce the dimensionality of feature vectors for text classification.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[26] Problem to identify the representation units as tokens using bag-of-words methods in some Asian Languages of non-segmented text.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "[27] Challenge in high dimensional systems to generate every possible rule with respect to all antecedent combinations.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "[28] Issues of expressing the fuzziness and uncertainty of domain knowledge and the semantic retrieval of fuzzy information.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "[22], [23], [24], and [25] show that text documents or web documents are considered for text classification which use a predefined set of classes initially in the training phase.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[22], [23], [24], and [25] show that text documents or web documents are considered for text classification which use a predefined set of classes initially in the training phase.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 17,
      "context" : "[22], [23], [24], and [25] show that text documents or web documents are considered for text classification which use a predefined set of classes initially in the training phase.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 18,
      "context" : "[22], [23], [24], and [25] show that text documents or web documents are considered for text classification which use a predefined set of classes initially in the training phase.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 15,
      "context" : "In [22], [23] and [24], the text is pre-processed and cleaned to extract all important features.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 16,
      "context" : "In [22], [23] and [24], the text is pre-processed and cleaned to extract all important features.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 17,
      "context" : "In [22], [23] and [24], the text is pre-processed and cleaned to extract all important features.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 18,
      "context" : "In [25], a bag of words is used and processed to get the word patterns.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 19,
      "context" : "The use of fuzzy signature for the text classification of the non-segmented text [26] shows that how the non-segmentable text can be segmented and classified.",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 20,
      "context" : "In [27], a rule based weighting technique is used to efficiently perform the data mining tasks.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 21,
      "context" : "The learning evaluation using the extended fuzzy ontology model [28] is provided for learning techniques based classification.",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 15,
      "context" : "[22]",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "6 [23]",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 17,
      "context" : "[24]",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "[25]",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "7 [26]",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 20,
      "context" : "[27]",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "[28]",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "[22] 50 Arabic Pages 10 Categories: Autobiography (Auto), Children's Stories (Child), Economics (Eco), Health and Medicine (Hlth), Interviews (Intrv), Religion (Rlg), Science (Scnc), Short Stories (Short), Sociology (Socio), Tourist and Travel (Trst).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[23] Used TeMario Corpus of 100 texts Data Used for Simulation: From Origin and Title 5 categories, each of 20 texts: from two Brazilian newspapers, Folha de São Paulo (Special, World, and Opinion) and Jornal do Brasil (Politics and International).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "9 [24] Yahoo! : 350 most freque nt keywo rds from each categor y and total distinct keywo rds are 2033.",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 18,
      "context" : "[25] a.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[26] • A corpus of 50 Thai Documents from Thai News Websites: 15 sport documents, 15 travel documents, 15 political documents and 5 education documents.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "[27] Used a number of UCL ML repository data sets",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "[28] Learning Evaluation for Teaching Field • A set of categories {C1,",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "Fuzzy term-category relation [22] is shown by manipulating membership degree for the training data and the degree value for a test web page.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 16,
      "context" : "Text categorization based on the Agglomerative Hierarchical Methodology [23] with the use of fuzzy logic.",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 17,
      "context" : "12 To automatically classify the web documents using the fuzzy association concept [24], the relationship is captured among different index terms in documents.",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 18,
      "context" : "In [25], a small part of the total result is shown in chart.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 19,
      "context" : "13 [26] discusses the simple category distribution in each of the 4 type of documents of sample data.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 20,
      "context" : "In [27] and [28], the parameters are calculated as given in the table 3.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 21,
      "context" : "In [27] and [28], the parameters are calculated as given in the table 3.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 20,
      "context" : "In [27], Iris showed better results over others.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 21,
      "context" : "In [28], to make the information semantization and to improve the accuracy of information retrieval, it adopted a fuzzy concept semantic analysis for clustering to generate learning evaluation ontology.",
      "startOffset" : 3,
      "endOffset" : 7
    } ],
    "year" : 2012,
    "abstractText" : "In this new and current era of technology, advancements and techniques, efficient and effective text document classification is becoming a challenging and highly required area to capably categorize text documents into mutually exclusive categories. Fuzzy similarity provides a way to find the similarity of features among various documents. In this paper, a technical review on various fuzzy similarity based models is given. These models are discussed and compared to frame out their use and necessity. A tour of different methodologies is provided which is based upon fuzzy similarity related concerns. It shows that how text and web documents are categorized efficiently into different categories. Various experimental results of these models are also discussed. The technical comparisons among each model’s parameters are shown in the form of a 3-D chart. Such study and technical review provide a strong base of research work done on fuzzy similarity based text document categorization.",
    "creator" : "PScript5.dll Version 5.2.2"
  }
}