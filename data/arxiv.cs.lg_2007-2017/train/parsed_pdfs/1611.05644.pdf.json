{
  "name" : "1611.05644.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Inverting The Generator Of A Generative Adversarial Network",
    "authors" : [ "Antonia Creswell", "Anil Anthony Bharath" ],
    "emails" : [ "ac2211@ic.ac.uk" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Generative adversarial networks (GANs) [10, 6] are a class of generative model which are able to generate realistic looking images of faces, digits and street numbers [10]. GANs involve training two networks: a generator, G, and a discriminator, D. The generator, G, is trained to generate images from a random vector z drawn from a prior distribution, P (Z). The prior is often chosen to be a normal or uniform distribution.\nRadford et al. [10] demonstrated that generative adversarial networks (GANs) learn a “rich linear structure\" meaning that algebraic operations in Z-space often lead to meaningful generations in image space. Since images represented in Z-space are often meaningful, direct access to a z ∈ Z for a given image, x ∈ X may be useful for discriminative tasks such as retrieval or classification. Recently, it has also become desirable to be able to access Z-space in order to manipulate original images [12]. Further, inverting the generator may provide interesting insights to highlight what the GAN model learns. Thus, there are many reasons that we may want to invert the generator.\nMapping from image space, X , to Z-space is non-trivial, as it requires inversion of the generator, which is often a many layered, non-linear model [10, 6, 1]. Dumoulin et al. [5] and Donahue et al. [3] proposed learning a third, decoder network alongside the generator and discriminator to map image samples back to Z-space. Collectively, they demonstrated results on MNIST, ImageNet, CIFAR10 and SVHN and CelebA. However, reconstructions of inversions are often poor. Specifically,\nWorkshop on Adversarial Training, NIPS 2016, Barcelona, Spain.\nar X\niv :1\n61 1.\n05 64\n4v 1\n[ cs\n.C V\n] 1\n7 N\nov 2\nreconstructions of inverted MNIST digits using methods of Donahue et al. [4], often fail to preserve style and character class. Drawbacks to this approach include the need to train a third network which increases the number of parameters that have to be learned, increasing the chances of over fitting. The need to train an extra network also means that inversion cannot be performed on pre-trained networks.\nWe propose an alternative approach to generator inversion which makes the following improvements:\n• We infer Z-space representations for images that when passed through the generator produce samples that are visually similar to those from which they were inferred. For the case of MNIST digits, our proposed inversion technique ensures that digits generated from inferred Z’s maintain both the style and character class of the image from which the Z was inferred, better than those in previous work [3].\n• Our approach can be applied to a pre-trained generator provided that the computational graph for the network is available.\nWe also show that batches of z samples can be inferred from batches of image samples, which improves the efficiency of the inversion process by allowing multiple images to be inverted in parallel. In the case where a network is trained using batch normalisation, it may also be necessary to invert a batch of z samples.\nInversion is achieved by finding a vector z ∈ Z which when passed through the generator produces an image that is very similar to the target image."
    }, {
      "heading" : "2 Method: Inverting The Generator",
      "text" : "For an image x ∈ <m×m we want to infer the Z-space representation, z ∈ Z, which when passed through the trained generator produces an image very similar to x. We refer to the process of inferring z from x as inversion. This can be formulated as a minimisation problem:\nz∗ = min z −Ex log[G(z)] (1)\nProvided that the computational graph for G(z) is known, z∗ can be calculated via gradient descent methods, taking the gradient of G w.r.t. z. This is detailed in Algorithm 1.\nAlgorithm 1 Algorithm for inferring z∗ ∈ <d, the latent representation for an image x ∈ <m×m. 1: procedure INFER(x) . Infer z∗ ∈ <d from x ∈ <m×m 2: z∗ ∼ Pz(Z) . Initialise z by sampling the prior distribution 3: while NOT converged do 4: L← −(x log[G(z∗)] + (1− x) log[1−G(z∗)]) . Calculate the error 5: z∗ ← z∗ − α∇zL . Apply gradient descent 6: end while 7: return z∗ 8: end procedure\nProvided that the generator is deterministic, each z value maps to a single image, x. A single z value cannot map to multiple images. However, it is possible that a single x value may map to several z representations, particularly if the generator collapses [11]. This suggests that there may be multiple possible z values to describe a single image. This is very different to a discriminative model, where multiple images, may often be described by the same representation vector [9], particularly when a discriminative model learns representations tolerant to variations.\nThe approach of Alg. 1 is similar in spirit to that of Mahendran et al. [9], however instead of inverting a representation to obtain the image that was responsible for it, we invert an image to discover the latent representation that generated it."
    }, {
      "heading" : "2.1 Effects Of Batch Normalisation",
      "text" : "GAN training is non-trivial because the optimal solution is a saddle point rather than a minimum [11]. It is suggested by Radford et al. [10] that to achieve more stable GAN training it is necessary to use batch normalisation [7]. Batch normalisation involves calculating a mean and standard deviation over a batch of outputs from a convolutional layer and adjusting the mean and standard deviation using learned weights. If a single z value is passed through a batch normalisation layer, the output of the layer may be meaningless. To prevent this problem, it would be ideal to use virtual batch normalisation [11], where statistics are calculated over a separate batch. However, we want to allow this technique to be applied to any pre-trained network - where virtual batch normalisation may not have been employed. To counteract the effects of batch normalisation, we propose inverting a mixed batch of image samples at a time. This not only has the desired effect of dealing with problems caused when using batch normalisation, but also allows multiple image samples to be inverted in parallel."
    }, {
      "heading" : "2.2 Inverting A Batch Of Samples",
      "text" : "Not only does inverting a batch of samples make sense when networks use batch normalisation, it is also a practical way to invert many images at once. We will now show that this approach is a legitimate way to update many z∗ values in one go.\nLet zb ∈ <B×n, zb = {z1, z2, ...zB} be a batch of B samples of z. This will map to a batch of image samples xb ∈ <B×m×m, xb = {x1, x2, ...xB}. For each pair (zi, xi), i ∈ {1...B}, a loss Li, may be calculated. The update for zi would then be zi ← zi − αdLidzi If reconstruction loss is calculated over a batch, then the batch reconstruction loss would be∑\ni={1,2...B} Li, and the update would be: ∇zbL = ∂ ∑ i∈{1,2,...B} Li\n∂(zb) (2)\n= ∂(L1 + L2...+ Li)\n∂(zb) (3)\n= dL1 dz1 , dL2 dz2 , ... dLB dzB\n(4)\nEach reconstruction loss depends only on G(zi), so Li depends only on zi, which means ∂Li∂zj = 0, for all i 6= j. Note that this may not strictly be true when batch normalisation is applied to outputs of convolutional layers in the generative model, since batch statistics are used to normalise these outputs. However, provided that the size of the batch is sufficiently large we assume that the statistics of a batch are approximately constant parameters for the dataset, rather than being dependant on the specific zj=1,...B values in the batch. This shows that zi is updated only by reconstruction loss Li, and the other losses do not contribute to the update of zi, making batch updates a valid approach."
    }, {
      "heading" : "2.3 Using Prior Knowledge Of P(Z)",
      "text" : "A GAN is trained to generate samples from a z ∈ Z where the distribution over Z is a chosen prior distribution, P (Z). P (Z) is often a Gaussian or uniform distribution. If P (Z) is a uniform distribution, U [a, b], then after updating z∗, it can be clipped to be between [a, b]. This ensures that z∗ lies in the probable regions of Z. If P (Z) is a Gaussian Distribution,N [µ, σ], regularisation terms may be added to the cost function, penalising samples that have statistics that are not consistent with P (Z) = N [µ, σ].\nz ∈ Z is a vector of length d. If each of the d values in z ∈ <d are drawn independently and from identical distributions, and provided that d is sufficiently large, we may be able to use statistics of values in z to add regularisation terms to the loss function. For instance, if P (Z) is a distribution with mean, µ and standard deviation σ, we get the new loss function:\nL(z, x) = Exlog[G(z)] + γ1||µ− µ̂||22 + γ2||σ − σ̂||22 (5)\nwhere µ̂ is the mean value of elements in z, σ̂ is the standard deviation of elements in z and γ1,2 are weights.\nSince d is often quite small (e.g. 100 [10]), it is unrealistic to expect the statistics of a single z to match those of the prescribed prior. However, since we are able to update a batch of samples at a time, we can calculate µ̂ and σ̂ over many samples in a batch to get more meaningful statistics."
    }, {
      "heading" : "3 Relation to Previous Work",
      "text" : "This approach of inferring z from x bears similarities to work of Zhu et al. [12]; we now highlight the differences between the two approaches and the benefits of our approach over that of Zhu et al. [12]. Primarily, we address issues related to batch normalisation by showing that a mixed batch of image samples can be inverted to obtain latent z encodings. Potential problems encountered when using batch normalisation are not discussed by Zhu et al. [12].\nThe generator of a GAN is trained to generate image samples x ∈ X from a z ∈ Z drawn from a prior distribution P (Z). This means that some z values are more probable that other z values. It makes sense, then, that the inferred z’s are also from (or at least near) P (Z). We introduce hard and soft constraints to be used during the optimisation process, to encourage inferred z’s to be likely under the prior distribution P (Z). Two common priors often used when training GAN’s are the uniform and normal distribution; we show that our method copes with both of these priors.\nSpecifically, Zhu et al. [12] calculate reconstruction loss, by comparing the features of x and G(z∗) extracted from layers of AlexNet, a CNN trained on natural scenes. This approach is likely to fail if generated samples are not of natural scenes (e.g. MNIST digits). Our approach considers pixel-wise loss, providing an approach that is generic to the dataset. Further, if our intention is to use the inversion to better understand the GAN model, it may be essential not to incorporate information from other pre-trained networks in the inversion process."
    }, {
      "heading" : "4 “Pre-trained” Models",
      "text" : "We train four models on two different datasets, MNIST and Omniglot [8]. In order to compare the effects of regularisation or clipping when using a normal or uniform prior distribution respectively, we train networks on each dataset, using each prior - totalling four models."
    }, {
      "heading" : "4.1 MNIST",
      "text" : "The MNIST dataset consists of 60k samples of hand written digits, 0 to 9. The dataset is split into 50k samples for training and 10k samples for testing. Both the training and testing dataset contains examples of digits 0 to 9.\nThe generator and discriminator networks for learning MNIST digits are detailed in Table 1. The networks were trained for 500 iterations with batch size 128, learning rate 0.002 using Adam updates. The networks are trained on 50k MNIST training samples, covering all 10 categories.\nFig. 1 shows examples of 100 random generations for MNIST networks trained using uniform and normal distributions."
    }, {
      "heading" : "4.2 Omniglot",
      "text" : "The Omniglot dataset [8] consists of characters from 50 different alphabets, where each alphabet has at least 14 different characters. The Omniglot dataset has a background dataset, used for training and a test dataset. The background set consists of characters from 30 writing systems, while the test dataset consists of characters from the other 20. Note, characters in the training and testing dataset come from different writing systems. The generator and discriminator networks for learning Omniglot characters [8] are the same as those used in previous work [2]. The network is trained only on the background dataset, for 2000 iterations with random batches of size 128, using Adam updates with learning rate 0.002. The latent encoding has dimension, d = 100."
    }, {
      "heading" : "5 Experiments",
      "text" : "These experiments are designed to evaluate the proposed inversion process. A valid inversion process should map an image sample, x ∈ X to a z∗ ∈ Z, such that when z∗ is passed through the generative part of the GAN, it produces an image, G(z∗), that is close to the original image, x.\nIn our experiments, we selected a random batch of images, x ∈ X , and applied inversion to the generator network using this batch. We performed inversion on four generators: Two trained to\ngenerate MNIST digits and two trained to generate Omniglot digits. For each case, the networks were trained to generate from z ∈ Z with P (Z) being either a uniform or a normal distribution. To invert a batch of image samples, we minimised the cost function described by Eqn. 1. In these experiments we examined the necessity of regularisation or clipping in the minimisation process. If samples may be inverted without the need for regularisation or clipping, then this technique may be considered general to the latent prior, P (Z), used to train the GAN.\nMinimising Binary Cross Entropy: We performed inversion where the cost function consisted only of minimising the binary cross entropy between the image sample and the reconstruction. For this approach to be general to the noise process used for latent space, we would hope that image samples may be inverted well by only minimising binary cross entropy and not using any hard or soft constraints on the inferred z’s.\nRegularisation and Clipping: GANs are trained to generate images from a prior distribution, P (Z). Therefore it may make sense to place some constraints on z’s inferred in the inversion process. However, the constraints needed depend on the distribution of the noise source. These experiments deal with two distributions, commonly used when training GANs, the uniform and Gaussian distributions. For generators trained using a uniform distribution we compare inversion with and with out clipping. For generators trained using a Gaussian distribution we compare inversion with and with out regularisation as described by Eqn. 5, using γ1,2 = 1."
    }, {
      "heading" : "5.1 Evaluation Methods",
      "text" : "To quantitatively evaluated the quality of image reconstruction by taking the mean absolute pixel error across all reconstructions for each of the reconstruction methods. For qualitative evaluation, we show pairs of x and their reconstruction, G(z∗). By visualising the inversions, we can assess to what extent the the digit or character identity is preserved. Also, with the MNIST dataset, we can visually assess whether digit style is also preserved."
    }, {
      "heading" : "6 Results",
      "text" : ""
    }, {
      "heading" : "6.1 MNIST",
      "text" : "Each MNIST digit is drawn in a unique style; a successful inversion of MNIST digits should preserve both the style and the identity of the digit. In Fig. 2, we show a random set of 20 pairs of original images, x, and their reconstructions, G(z∗). In general, the inversions preserve both style and identity well. Using visual inspection alone, it is not clear whether regularisation methods improve the inversion process or not. Table 2 records the absolute, mean reconstruction error. Results suggest that the regularisation techniques that we employed did not improve the inversion. This is a positive result, as this suggests that inversion may be possible without regularisation, meaning that the inversion process can be independent of the noise process used. This also suggests that regions just outside of P (Z) may also be able to produce meaningful examples from the data distribution."
    }, {
      "heading" : "6.2 Omniglot",
      "text" : "The Omniglot inversions are particularly challenging, as we are trying to find a set of z∗’s for a set of characters, x, from alphabets that were not in the training data. This is challenging the inversion process to invert samples from alphabets that it has not seen before, using information about alphabets that it has seen. The original and reconstructed samples are shown in Fig 3. In general, the reconstructions are sharp and able to capture fine details like small circles and edges. There is one\nsevere fail case in Fig 3 (b), where the top example has failed to invert the sample. A comparison of reconstruction error with and without regularisation is shown in Table 3. These results suggest that regularisation does not improve inversion, and good inversion is possible without regularisation."
    }, {
      "heading" : "7 Conclusion",
      "text" : "The generator of a GAN learns the mapping G : Z → X . It has been shown that z values that are close in Z-space produce images that are visually similar in image space, X [10]. It has also been shown that images along projections in Z-space also have visual similarities [10]. To exploit the structure of Z for discriminative tasks, it is necessary to invert this process, to obtain a latent\nencoding z ∈ Z for an image x ∈ X . Inverting the generator also reveals interesting properties of the learned generative model.\nWe suggest a process for inverting the generator of any pre-trained GAN, obtaining a latent encoding for image samples, provided that the computational graph for the GAN is available. We presented candidate regularisation methods than can be used depending on the prior distribution over the latent space. However, we found that for the MNIST and Omniglot datasets that it is not necessary to use regularisation to perform the inversion, which means that this approach may be more generally applied.\nFor GANs trained using batch normalisation, where only the gain and shift are learned but the mean and standard deviation are calculated on the go, it may not be possible to invert single image samples. If this is the case, it is necessary to invert batches of image samples. We show that it is indeed possible invert batches of image samples. Under reasonable assumptions, batch inversion is sensible because the gradient used to update a latent samples only depends on the reconstruction error of the latent sample that it is updating. Inverting batches may also make the inversion process more computationally efficient.\nOur inversion results for the MNIST and Omniglot dataset provide interesting insight into the latent representation. For example, the MNIST dataset consists of handwritten digits, where each digit is written in a unique style. Our results also suggest that both the identity and the style of the digit is preserved in the inversion process we propose here, indicating that the latent space preserves both these properties. These results suggest that latent encodings may be useful for applications beyond digit classification. Results using the Omniglot dataset show that even handwritten characters from alphabets never seen during training of a GAN can be projected into the latent space, with good reconstructions. This may have implications for one-shot learning."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We like to acknowledge the Engineering and Physical Sciences Research Council for funding through a Doctoral Training studentship."
    } ],
    "references" : [ {
      "title" : "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets",
      "author" : [ "Xi Chen" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2016
    }, {
      "title" : "Task Specific Adversarial Cost Function",
      "author" : [ "Antonia Creswell", "Anil A Bharath" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2016
    }, {
      "title" : "Adversarial Feature Learning",
      "author" : [ "Jeff Donahue", "Philipp Krähenbühl", "Trevor Darrell" ],
      "venue" : "arXiv preprint arXiv:1605.09782",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2016
    }, {
      "title" : "Long-term recurrent convolutional networks for visual recognition and description",
      "author" : [ "Jeffrey Donahue" ],
      "venue" : "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2015
    }, {
      "title" : "Adversarially Learned Inference",
      "author" : [ "Vincent Dumoulin" ],
      "venue" : "arXiv preprint arXiv:1606.00704",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2016
    }, {
      "title" : "Generative adversarial nets",
      "author" : [ "Ian Goodfellow" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2014
    }, {
      "title" : "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
      "author" : [ "Sergey Ioffe", "Christian Szegedy" ],
      "venue" : "Proceedings of The 32nd International Conference on Machine Learning",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2015
    }, {
      "title" : "Human-level concept learning through probabilistic program induction",
      "author" : [ "Brenden M Lake", "Ruslan Salakhutdinov", "Joshua B Tenenbaum" ],
      "venue" : "Science",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2015
    }, {
      "title" : "Understanding deep image representations by inverting them",
      "author" : [ "Aravindh Mahendran", "Andrea Vedaldi" ],
      "venue" : "IEEE conference on computer vision and pattern recognition (CVPR). IEEE",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2015
    }, {
      "title" : "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
      "author" : [ "Alec Radford", "Luke Metz", "Soumith Chintala" ],
      "venue" : "Proceedings of the 5th International Conference on Learning Representations (ICLR) - workshop track",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2016
    }, {
      "title" : "Improved Techniques for Training GANs",
      "author" : [ "Tim Salimans" ],
      "venue" : "Advances in Neural Information Processing Systems (to appear)",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2016
    }, {
      "title" : "Generative Visual Manipulation on the Natural Image Manifold",
      "author" : [ "Jun-Yan Zhu" ],
      "venue" : "European Conference on Computer Vision. Springer",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "Generative adversarial networks (GANs) [10, 6] are a class of generative model which are able to generate realistic looking images of faces, digits and street numbers [10].",
      "startOffset" : 39,
      "endOffset" : 46
    }, {
      "referenceID" : 5,
      "context" : "Generative adversarial networks (GANs) [10, 6] are a class of generative model which are able to generate realistic looking images of faces, digits and street numbers [10].",
      "startOffset" : 39,
      "endOffset" : 46
    }, {
      "referenceID" : 9,
      "context" : "Generative adversarial networks (GANs) [10, 6] are a class of generative model which are able to generate realistic looking images of faces, digits and street numbers [10].",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 9,
      "context" : "[10] demonstrated that generative adversarial networks (GANs) learn a “rich linear structure\" meaning that algebraic operations in Z-space often lead to meaningful generations in image space.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "Recently, it has also become desirable to be able to access Z-space in order to manipulate original images [12].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 9,
      "context" : "Mapping from image space, X , to Z-space is non-trivial, as it requires inversion of the generator, which is often a many layered, non-linear model [10, 6, 1].",
      "startOffset" : 148,
      "endOffset" : 158
    }, {
      "referenceID" : 5,
      "context" : "Mapping from image space, X , to Z-space is non-trivial, as it requires inversion of the generator, which is often a many layered, non-linear model [10, 6, 1].",
      "startOffset" : 148,
      "endOffset" : 158
    }, {
      "referenceID" : 0,
      "context" : "Mapping from image space, X , to Z-space is non-trivial, as it requires inversion of the generator, which is often a many layered, non-linear model [10, 6, 1].",
      "startOffset" : 148,
      "endOffset" : 158
    }, {
      "referenceID" : 4,
      "context" : "[5] and Donahue et al.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] proposed learning a third, decoder network alongside the generator and discriminator to map image samples back to Z-space.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4], often fail to preserve style and character class.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "For the case of MNIST digits, our proposed inversion technique ensures that digits generated from inferred Z’s maintain both the style and character class of the image from which the Z was inferred, better than those in previous work [3].",
      "startOffset" : 234,
      "endOffset" : 237
    }, {
      "referenceID" : 10,
      "context" : "However, it is possible that a single x value may map to several z representations, particularly if the generator collapses [11].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 8,
      "context" : "This is very different to a discriminative model, where multiple images, may often be described by the same representation vector [9], particularly when a discriminative model learns representations tolerant to variations.",
      "startOffset" : 130,
      "endOffset" : 133
    }, {
      "referenceID" : 8,
      "context" : "[9], however instead of inverting a representation to obtain the image that was responsible for it, we invert an image to discover the latent representation that generated it.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 10,
      "context" : "GAN training is non-trivial because the optimal solution is a saddle point rather than a minimum [11].",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 9,
      "context" : "[10] that to achieve more stable GAN training it is necessary to use batch normalisation [7].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 6,
      "context" : "[10] that to achieve more stable GAN training it is necessary to use batch normalisation [7].",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 10,
      "context" : "To prevent this problem, it would be ideal to use virtual batch normalisation [11], where statistics are calculated over a separate batch.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 9,
      "context" : "100 [10]), it is unrealistic to expect the statistics of a single z to match those of the prescribed prior.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 11,
      "context" : "[12]; we now highlight the differences between the two approaches and the benefits of our approach over that of Zhu et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12] calculate reconstruction loss, by comparing the features of x and G(z∗) extracted from layers of AlexNet, a CNN trained on natural scenes.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 7,
      "context" : "We train four models on two different datasets, MNIST and Omniglot [8].",
      "startOffset" : 67,
      "endOffset" : 70
    }, {
      "referenceID" : 7,
      "context" : "The Omniglot dataset [8] consists of characters from 50 different alphabets, where each alphabet has at least 14 different characters.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 7,
      "context" : "The generator and discriminator networks for learning Omniglot characters [8] are the same as those used in previous work [2].",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 1,
      "context" : "The generator and discriminator networks for learning Omniglot characters [8] are the same as those used in previous work [2].",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 9,
      "context" : "It has been shown that z values that are close in Z-space produce images that are visually similar in image space, X [10].",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 9,
      "context" : "It has also been shown that images along projections in Z-space also have visual similarities [10].",
      "startOffset" : 94,
      "endOffset" : 98
    } ],
    "year" : 2016,
    "abstractText" : "Generative adversarial networks (GANs) learn to synthesise new samples from a high-dimensional distribution by passing samples drawn from a latent space through a generative network. When the high-dimensional distribution describes images of a particular data set, the network should learn to generate visually similar image samples for latent variables that are close to each other in the latent space. For tasks such as image retrieval and image classification, it may be useful to exploit the arrangement of the latent space by projecting images into it, and using this as a representation for discriminative tasks. GANs often consist of multiple layers of non-linear computations, making them very difficult to invert. This paper introduces techniques for projecting image samples into the latent space using any pre-trained GAN, provided that the computational graph is available. We evaluate these techniques on both MNIST digits and Omniglot handwritten characters. In the case of MNIST digits, we show that projections into the latent space maintain information about the style and the identity of the digit. In the case of Omniglot characters, we show that even characters from alphabets that have not been seen during training may be projected well into the latent space; this suggests that this approach may have applications in one-shot learning.",
    "creator" : "LaTeX with hyperref package"
  }
}