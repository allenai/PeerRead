{
  "name" : "1512.09254.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Evolving Non-linear Stacking Ensembles for Prediction of Go Player Attributes",
    "authors" : [ "Josef Moudřı́k", "Roman Neruda" ],
    "emails" : [ "j.moudrik@gmail.com", "roman@cs.cas.cz" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n51 2.\n09 25\n4v 1\n[ cs\n.A I]\n3 1\nD ec\nI. INTRODUCTION\nThe field of computer Go is primarily focused on the problem of creating a program to play the game by finding the best move from a given board position [1]. We focus on analyzing existing game records with the aim of helping humans to play and understand the game better instead. In our previous work [2], we have presented a way to extract information rich features from sets of Go players’ games.\nThis paper presents machine-learning methodology we have devised to fully utilize these extracted features. We have used stacking ensembles with non-linear second-level learner. Both the members of the ensemble and the second-level learner are chosen by a genetic algorithm. The resulting model performs better than any single base-learner (see Section III) on its own, and also better than the best hand-tuned ensemble we have been able to come up with.\nAs the methods of this work are mainly domainindependent, we only give a brief introduction to Go-related specifics. Go is a two-player full-information board game played on a square grid (usually 19 × 19 lines) with black and white stones; the goal of the game is to surround territory and capture enemy stones. Different players tend to choose different strategies to achieve this, in Go terminology this is captured by the notion of playing style. Obviously, the players also vary in their proficiency, to which we refer to as strength. All these player attributes (various axes of style, and strength) can be mapped on a subset of real numbers [3]. In this paper, we use thusly defined regression domains as black-box datasets.\nThis paper is organized as follows. Section II gives overview of related work. Section III presents the learners (Sections\nIII-A and III-B) and the genetic algorithm (Section III-C). Section IV discusses performance measures used to compare various learners. Experiments and results are shown in Section V. Section VI discusses applications and future work."
    }, {
      "heading" : "II. RELATED WORK",
      "text" : "Ensemble approaches to machine-learning have been in researchers’ attention for over two decades. During the time, various approaches appeared. Some of them train one model on differently sampled data [4], as is the case of bagging [5] and the related random forests algorithm [6]. The schemes for combining such models in a voting-like manner seems to be well understood [7]. For example, in neural networks, these ideas have also recently been re-introduced in the form of a dropout [8].\nAnother approach to combine different models is boosting [9], where a (presumably weak) model is iteratively trained to specialize on hard instances. Stacking [10] on the other hand, uses a two-layered approach, where model on the second level learns to correct for mistakes that first level learners make. For classification, various ways of forming the features from the first level prediction have been proposed ([11], [12]), multi-response linear regression has been found to work well for second level learner. For regression task such as ours, simple linear second level models have been proposed by Breiman [13]. We are not aware of any use of non-linear models for second level predictors like we use in this work.\nPrediction of Go player attributes has until recently been limited to pre-defined questionnaires and simple methods [14], [15]. Universal approach to the problem has been introduced by our previous work [2] and [3]."
    }, {
      "heading" : "III. LEARNERS",
      "text" : "This section presents the machine learning framework we have used. The basic methods are well-documented in literature, so we only give a very brief overview here.\nSuppose we have a set of data\nTr = {(x1, y1), . . . , (xN , yN)}, ∀i : xi ∈ R p, yi ∈ R,978-1-4799-7560-0/15/$31 c©2015 IEEE\nand we want to find a function r which is able to predict the value yi from xi with a reasonable accuracy and can generalize this dependency to unseen pairs. The machine learning methods presented here are regarded as learners. For a given data Tr, the learner should output a regression function which performs the regression of the dependent variable, as learned from the data.\nOf course, some regression functions perform better than others. Mainly, this is because each learner has different (inherent) assumptions about the form of the function it is fitting; we call this the inductive bias (of the learner and the underlying model). Often, we deal with data where the underlying dependency and properties of the data are unknown, so it is hard to say whether assumptions of a particular model are right. To overcome this problem, usually a bunch of models is tried and the best one is chosen (according to some criterion).\nAnother approach, the one we use in this work, is not to choose the best, but rather try to combine the different models to create one higher-level method. Because different methods have different biases, they might be able to capture different dependencies in the data. If we combined the methods (base learners) usefully, we could get better performance than with the “use the best learner” approach, we understand this as ensemble learning."
    }, {
      "heading" : "A. Base Learners",
      "text" : "1) Mean Regression: is a very simple method, which we use as a reference for comparing performances of other learners. It simply outputs the mean of the y’s in the training set, and it is thus constant regardless of the input x.\nmean(x) = 1\n|Tr|\n∑\n(x′,y′)∈Tr\ny′\n2) Artificial Neural Networks: are a standard technique used for function approximation. The network is composed of simple computational units which are organized in a layered topology, as described e.g. in a monograph [16]. We have used a simple feedforward neural network with 20 hidden units in one hidden layer. The neurons have standard sigmoidal activation function and the network is trained using the RPROP algorithm [17] for at most 100 iterations (or until the error is smaller than 0.001). In both datasets used, the domain of the particular target variable (strength, style) was linearly rescaled to 〈−1, 1〉 prior to learning. Similarly, predicted outputs were rescaled back by the inverse mapping.\n3) k-Nearest Neighbor Regression: is another commonly used machine learning algorithm [18]. The assumption of this model is that we can deduce the dependent y by looking at vectors from the feature space that are close to the x.\nDefinition. For a fixed k and x, let the Nb = {x′1, . . . , x ′ k} denote a set of k closest vectors to x from the T with respect to some metric δ; let D be a vector of distances, such that Di = δ(x, x ′ i); for each x ′ i, let y ′ i be the associated dependent variable from the training set T .\nFor a given x, the idea is to find the nearest k vectors (the Nb set) from the training set, and then estimate the dependent variable y from the associated y′1, . . . , y ′ k.\nIn this work, we have used the Manhattan (p-1) and Euclidean (p-2) distances as δ. To infer the y, we define the model to be:\ny =\n∑k\ni=1 w(Di)y ′ i\n∑k i=1 w(Di) ,\nfor some weighting function w. We have used the inverse of the distance between x and the particular neighbor instance:\nw(Di) = 1/D α i ,\nwhere α is a parameter specifying the effect of increasing distance. When α is equal to zero, we obtain the averaging scheme, where the weights do not depend on the distance Di—all the k neighbors are valued equally. With increasing α, the x′i instances closer to x are preferred over more distant neighbors. When α goes to infinity, the method essentially becomes one-nearest neighbor.\n4) PLS: The family of partial least squares (PLS) methods assumes that the observed variables can be modelled by means of a few latent variables (their number is specified by a parameter l). The method projects the data onto this latent model in a way that minimizes error. The process is somewhat similar to Principal Component Regression.\nFor a good overview, see the work [19]. 5) Random Forests: utilize an ensemble of tree learners to predict the dependent value [6], [20]. Although this model is an ensemble itself, we treat is as a black box in this work.\nEach tree from the forest (of size N ) is trained on an independently chosen subset of training data, exactly as the bagging in Section III-B1 does. See the Breiman’s paper [6] for details."
    }, {
      "heading" : "B. Ensemble Learners",
      "text" : "1) Bagging: is a simple ensemble method introduced in [5]. The idea in bagging is to train a particular base learner bl on differently sampled data and aggregate the results. The method has one parameter t which specifies the number of data samples. Each of them is made by randomly choosing |Tr| elements from training set Tr with repetition. The base\nlearner bl is trained on each of these samples. The regression simply averages results from the t resulting models.\nPaper [5] discusses, that this procedure is especially useful for learners bl which are unstable—small perturbations in the data have big impact on the resulting model. Aggregating the bootstrapped models essentially introduces robustness to such models. Examples of learners where the bagging is beneficial are neural networks (where overfitting is often a serious problem) and regression trees (see Random Forests above).\n2) Stacking: is a more sophisticated approach. The original idea was pioneered by [10] and extended by [12], [13]. The method is basically a two level hierarchical model of learners with a clever scheme for training. The first level is composed by an ensemble of learners. The second level is a single learner which aggregates guesses from the 1st level models and outputs the final prediction. Figure 1 shows the topology.\nThe training dataset is divided into smaller parts (by crossvalidation, see Section IV-A). The 1st level learners are trained on some of them and their generalization biases are measured by testing their performance on the rest. The 2nd level learner learns to correct these—it learns what the correct output is, given what the 1st level predictors output. Algorithm 1 describes the procedure in more detail. Usually, the 2nd level learner is a simple linear regression, in this work we use nonlinear models as well.\nHaving diverse base learners (various models with different biases) often proves to increase the prediction performance. The performance of stacking is usually better than the best of the base learners on its own. It is not the case, however, that having badly performing learners in the ensemble does not worsen the performance. Choosing the right set of 1st level learners is very important if we are to attain the best performance, as is the choice of the 2nd level aggregating learner and the number of folds for the cross-validation step. Usually, all these parameters are hand-tuned; in this work, we use a genetic algorithm (Secion III-C)."
    }, {
      "heading" : "C. Evolving Stacking Ensembles",
      "text" : "We have discussed that ensemble learning might be beneficial in terms of performance. For stacking, it is desirable to\nAlgorithm 1: Stacking for Regression input : an ordered set of 1st level learners ensemble, a\nlevel 2 learner l2, training data Tr, number of folds Folds\noutput: regression function f\n/* Training set for the level 2 learner. */ 1 L2Tr ← {}; 2 foreach (Tr′, T s′) in CrossValidation(Tr, Folds)\ndo /* The level 1 learners trained on\nsplit Tr′. */ 3 L1 ← (ensemble0(Tr ′), . . . , ensemblen(Tr ′)); 4 foreach (x′, y′) in Ts′ do /* Responses of level 1 predictors\nto unseen x′ and the real reply y′. */\n5 L2Tr ← L2Tr ∪ {((L10(x ′), . . . , L1n(x ′)), y′)}; 6 end 7 end /* Train the level 1 learners on the real data. */ 8 L1 ← (ensemble0(Tr), . . . , ensemblen(Tr)); /* Train the level 2 learner on the prepared data. */ 9 L2 ← l2(L2Tr);\n10 return Compose(L1, L2);\nform the ensemble out of diverse base learners. The problem however is how to choose the learners into the ensemble. This becomes apparent once one tries to hand-tune the parameters of different base-learners, find the best combination of them and find the best aggregating 2nd level learner.\nWe have used a simple genetic algorithm (GA) to search the space of possible ensembles for the stacking. Genetic algorithms are an universal optimization tool, see [21] for a good tutorial. The general procedure is iterative. In each iteration, individuals (candidate solutions) are evaluated using a fitness function, and an intermediate population is formed by randomly choosing individuals, with probability proportional to the fitness (roulette selection). From this intermediate population, the population for the next step is taken by making pairwise crossover operation and mutation on the newly formed individuals.\nIn the text below, we operate with a set of base learners BL, from which we choose the learners into the ensemble. We should note that the set of base learners BL is not strictly limited to learners we have listed as base in Section III-A—we use both differently parameterized base learners and bagged neural networks.\nWe have used a very simple encoding for an individual. An individual is a triple of (I, Folds, ~v). The first two values I and Folds define the 2nd level learner. I is the index of the 2nd level aggregating learner in BL and Folds is the number\nof folds for the stacking procedure. The vector ~v of size |BL| marks a subset of BL that forms the ensemble: ~vi = 1 if the base learner BLi belongs to the ensemble; ~vi = 0 when it does not.\nWe have used two independent mutations to modify the individuals. Firstly, with probability PmM , we either change I to any of 1 . . . |BL|, or we change the number of Folds to 2 . . . 6, (MutateM in the pseudocode). Whether we change I , or Folds is decided using a further random coin toss. Secondly, with probability Pmv a random position i in v is selected and the bit vi is swapped, (MutateV in the pseudocode).\nThe crossover operation of parents P = (I, Folds, ~v) and P ′ = (I ′, Folds′, ~v′) selects a random position i ∈ {1 . . . |BL|} and outputs the following tuple\n(I, Folds, (v1, . . . , vi, v ′ i+1, . . . , v ′ |BL|))\nas the new individual. Please note that the index I (and number of Folds) of the 2nd level learner is taken from the first parent P . This is compensated for by the fact that crossover is always performed in pairs (lines 8 – 9 in Algorithm 2).\nThe fitness function we have used is inversely proportional to RMSE error of the resulting stacked ensemble.\nAlso, to make sure we do not lose the best solution, we have used elitism, which brings the top E individuals unchanged into the next generation."
    }, {
      "heading" : "IV. EVALUATING LEARNERS",
      "text" : "To compare performances of different regression functions (learners), we need a reliable metric. The goal is to estimate the performance of a particular regression function on real unseen data. We can estimate this performance by splitting the data into parts that are only used for training (Tr) and testing (Ts)."
    }, {
      "heading" : "A. Cross-Validation",
      "text" : "Cross-validation is a standard statistical technique for estimation of parameters. The idea is to split the data into k disjunct subsets (called folds), and then iteratively compose the training and testing sets and measure errors. In each of the k iterations, k-th fold is chosen as the testing data, and all the remaining k− 1 folds form the training data. The division into the folds is done randomly, and so that the folds have approximately the same size (in cases where the number of samples |D| is not divisible by k, some folds are slightly smaller than others). Please note that each sample from the data is a part of the testing fold exactly once (it is part of a training set k − 1 times). Refer to [22] for details."
    }, {
      "heading" : "B. Error Analysis",
      "text" : "A commonly used performance measure is the mean square error (MSE) which estimates variance of the error distribution. We use its square root (RMSE) which is an estimate of standard deviation of the predictions,\nRMSE =\n√ √ √ √ 1\n|Ts|\n∑\n(ev,y)∈Ts\n(predict(ev)− y)2,\nAlgorithm 2: Genetic Algorithm for finding optimal stacking ensemble\ninput : size of the population S, size of the elite E, probabilities of mutation PmM and Pmv, maximal number of steps Max output: The best individual.\n1 Pop ← RandomPopulation(S); /* The best individual so far. */ 2 Best ← {}; 3 foreach iteration in 1 . . .Max do 4 evaluation ← Fitness(Pop);\n/* PI is the intermediate population. */\n5 PI ← RouletteSelection(Pop, evaluation); /* PN is the intermediate population after Crossover. */ 6 PN ← {}; 7 foreach i in 1 . . . (S − E)/2 do 8 PN ← PN ∪ Crossover(PI[2 ∗ i], PI[2 ∗ i+ 1]) ; 9 PN ← PN ∪ Crossover(PI[2 ∗ i+ 1],\nPI[2 ∗ i]) ; 10 end /* Save the best individual. */ 11 Best ← TakeTop(Pop, evaluation, 1); /* Top E best continue unchanged. */ 12 Pop ← TakeTop(Pop, evaluation, E); 13 foreach individual in PN do 14 if Rnd(0,1) < PmM then 15 individual ←MutateM(individual); 16 end 17 if Rnd(0,1) < Pmv then 18 individual ←MutateV(individual); 19 end 20 Pop ← Pop ∪{individual}; 21 end 22 end 23 return Best;\nwhere the machine learning model predict is trained on the training data Tr and Ts denotes the testing data."
    }, {
      "heading" : "V. EXPERIMENTS AND RESULTS",
      "text" : ""
    }, {
      "heading" : "A. Strength",
      "text" : "One of the two major domains we have tested our framework on is the prediction of player strength. In the game of Go, strength (amateur) is measured by kyu (student) and dan (master) ranks. The kyu ranks decrease from about 20th kyu (absolute beginner) to 1st kyu (fairly strong player), the scale continues by dan ranks, 1 dan (somewhat stronger than 1 kyu), to 6 dan (a very strong player).\nDataset: We have collected a large sample of games from the public archives of the Kiseido Go server [23], the sample consists of over 100 000 records of games. The records were\ndivided by player’s strength and preprocessed as is detailed in [2]. Here, it is enough to note that the dataset consists of 120 independent pairs (x, y) for each of the 26 ranks, where x is the feature vector described in [2] (dimension of x was 1040), and y is the target variable, which is one number describing the rank (1-26).\nResults: In the process of finding the best learner, we started with a hand-tuned learner shown in Table IV. Using this learner (which we found to perform reasonably well, as shown in Table V-A) we evaluated different feature extractors (previous section). At first, the dataset was processed using the best feature extractors, which were concatenated to form the data T for regression.\nWe then used the genetic algorithm (Section III-C; abbreviated to GA) to find the best performing stacked ensemble. The initial population was seeded by the hand tuned learner. The parameters of the genetic algorithm are given in Table II.\nUnfortunately, the time needed for a single iteration was very large in this setting (see Discussion for more detailed treatment of the time complexity). To speed up the process, we used a sub-sampled dataset for computing the fitness during the GA (by randomly taking 1/10 prior to the running of the GA). We assume, that this is not a principal obstacle\nfor finding the best learner, since the down-sampling should degrade the performance of the learners systematically—the ordering of fitnesses is expected to be more or less the same, though the fitness values surely differ. The run of genetic algorithm took on average approximately 2.5 hours per iteration on a 4-core commodity laptop in this setting.\nThe performance of the best ensemble found by the GA (on the full dataset) are given in Table V-A along with other learners to compare performances. The resulting learner (Table III) is fairly complex as Figure 2 shows. Evolution of the RMSE error in time is given in Figure 3."
    }, {
      "heading" : "B. Style",
      "text" : "Apart from the strength estimation, we also tested the framework presented in this work to test prediction of playing styles of professional players. Playing style has different aspects, some of them are vaguely defined (for details, see [24]). Moreover, none of them has clear definition in a mathematical sense. To capture these notions at least approximately, we came up with four axes, whose ends correspond to opposing principles in traditional Go knowledge. Next, we used a questionnaire (submitted to domain experts) to find the style values for a set of well known professional players from the 20th century.\nStyle 1 10 Territoriality Moyo Territory Orthodoxity Classic Novel Aggressivity Calm Fighting\nThickness Safe Shinogi\nDataset: The collection of games in this dataset comes from the Games of Go on Disk (GoGoD) database by [25]. This database contains more than 70 000 games, spanning from the ancient times to the present. We chose a small subset of well known players (mainly from the 20th century) and asked some experts (professional and strong amateur players) to evaluate these players using a questionnaire. [26] The experts (Alexander Dinerchtein 3-pro, Motoki Noguchi 7-dan, Vladimı́r Daněk 5-dan and Vı́t Brunner 4-dan) were asked to\nvalue the players on four scales, each ranging from 1 to 10. For each of 24 professional players, we obtained 12 pairs (x, y), where x is the feature vector obtained from the games as described in [2] (dimension of x was 640), and y is one of the 4 styles—basically, we view the problem as 4 different regression problems which share the same feature vectors.\nResults: We used the genetic algorithm to determine the best ensemble learner. During the process, we have encountered over-fitting problems concerning the very small size of the dataset.\nAt first, we chose the parameters of the GA to be the same as in the problem of strength (Table II), with the exception of the fitness function. The RMSE error was computed in the same manner as in the style feature extraction (one learner for all the styles, the fitness of a learner is average RMSE on the different styles). Similarly to the case of strength, it turned out that it was not possible to use cross-validation on the full dataset because of time constraints. We tried to workaround this by subsampling the data prior to the experiment, but due to very small size of the dataset, this resulted in over-fitting of the resulting ensemble model.\nSecondly, we tried not to use the cross-validation, but to use proportional division scheme instead—the fitness is evaluated by randomly taking 70% of the dataset for training and the rest for testing; in each of the iterations, this is done anew to mitigate any effects caused by biased random split (dividing the dataset once prior to the run would cause over-fitting). Unfortunately, this too did not yield satisfactory results. Even though over-fitting was not the case, the genetic algorithm was not able to consistently improve the ensembles—the subsampled datasets in each of the iterations were too different to ensure that the best individuals from one iteration would have good chances in the next one. This rendered the genetic algorithm unsuccessful.\nConsequently we concluded, that the robust cross-validation with the full dataset is necessary and that we thus need to compensate for the increased resource consumption differently. We did this by limiting the population size to 10 individuals and most importantly, by limiting the ensemble to contain at most 5 base learners. Technically, this is done by randomly removing excess number of base learners from each individual at the end of each iteration. The parameters of the final genetic algorithm are listed in Table VI.\nThe performances of the best learners found are given in Table VII. The parameters of the models are omitted for brevity, see [3] for more. Development of the RMSE error in time is given in Figure 4. Each run of the genetic algorithm (for different styles) took approximately one hour of CPU time per iteration."
    }, {
      "heading" : "VI. DISCUSSION",
      "text" : "The results in both domains show that evolving stacking ensembles non-trivially improves upon the performance of the best hand tunes ensemble, circa by 1.5% for the case of strength and by 4% for the style domains (averaged over different styles). The resulting ensembles also show a lot of diversity.\nThe main drawback of the methods described is clearly the time consumed, which—even for such relatively small datasets—is in orders of hours per iteration. The main cause of this is the cross-validation performed at various levels, multiplying time complexity. At the outer level, it is run to obtain better error estimates. The cross-validation is also used\nin the inner loop during training Stacking ensembles, and moreover, in some of the base learners. In this extreme case, the complexity of training the base model is multiplied by number of Folds3. With some effort, the large sequential time could also be exchanged for large number of machines, since it is easy to train different folds in parallel. Furthermore, the time-complexity can be lowered by limiting the number of learners in the ensemble, or by restricting the base learners used by the stacking ensemble to be simple and fast models (with possible loss of precision).\nThe prediction of player attributes as demonstrated in this work has been (together with the feature extraction presented in [2]) combined in an online web application1, which evaluates games submitted by players and predicts their playing strength and style. The predicted strength is then used to recommend relevant literature and the playing style is utilized by recommending relevant professional players to review. So far, the web application has served thousands of players and it was generally very well received. We are aware of only two tools, that do something alike, both of them are however based on a predefined questionnaire. The first one is the tool of [14]—the user answers 15 questions and based on the answers he gets one of predefined recommendations. The second tool is not available at the time of writing, but the discussion at [15] suggests, that it computed distances to some professional players based on user’s answers to 20 questions regarding the style. We believe that our approach is more precise, both because it takes into account many different aspects of the games [2], and because the methods presented in this paper are able to use the information well."
    }, {
      "heading" : "VII. CONCLUSION",
      "text" : "The paper presents machine-learning algorithm which evolves non-linear stacking ensembles of learners. The algorithm is applied on two computer Go domains, prediction of player’s strength and different aspects of his style. In both these domains, the algorithm outperforms other methods, with the disadvantage of taking relatively large amount of time; solutions to this problem are proposed.\nVIII. IMPLEMENTATION\nThe code used in this work is released online as a part of GoStyle project [27]. The majority of the source code is implemented in the Python programming language [28].\nThe machine learning models were implemented and evaluated using the Orange Datamining suite [29] and the Fast Artificial Neural Network library FANN [30]. We used the Pachi Go engine [31] for the raw game processing."
    }, {
      "heading" : "Acknowledgment",
      "text" : "This research has been partially supported by the Czech Science Foundation project no. 15-18108S. J. Moudřı́k has been supported by the Charles University Grant Agency project no. 364015 and by SVV project no. 260 224.\n1http://gostyle.j2m.cz"
    } ],
    "references" : [ {
      "title" : "Achieving master level play in 9x9 computer go",
      "author" : [ "S. Gelly", "D. Silver" ],
      "venue" : "AAAI’08: Proceedings of the 23rd national conference on Artificial intelligence. AAAI Press, 2008, pp. 1537–1540.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Evaluating go game records for prediction of player attributes",
      "author" : [ "J. Moudřı́k", "P. Baudiš", "R. Neruda" ],
      "venue" : "IEEE Computational Intelligence in Games 2015. IEEE, 2015, pp. 162–168, in Print.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Meta-learning methods for analyzing go playing trends",
      "author" : [ "J. Moudřı́k" ],
      "venue" : "Master’s thesis, Charles University, Faculty of Mathematics and Physics, Prague, Czech Republic, 2013. [Online]. Available: http://www.j2m.cz/∼jm/master thesis.pdf",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Neural network ensembles",
      "author" : [ "L.K. Hansen", "P. Salamon" ],
      "venue" : "IEEE Transactions on Pattern Analysis & Machine Intelligence, no. 10, pp. 993–1001, 1990.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "Bagging predictors",
      "author" : [ "L. Breiman" ],
      "venue" : "Mach. Learn., vol. 24, no. 2, pp. 123–140, Aug. 1996. [Online]. Available: http://dx.doi.org/10.1023/A:1018054314350",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Random forests",
      "author" : [ "——" ],
      "venue" : "Machine Learning, vol. 45, no. 1, pp. 5–32, Oct. 2001.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "On combining classifiers",
      "author" : [ "J. Kittler", "M. Hatef", "R.P. Duin", "J. Matas" ],
      "venue" : "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 20, no. 3, pp. 226–239, 1998.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Improving neural networks by preventing co-adaptation of feature detectors",
      "author" : [ "G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R.R. Salakhutdinov" ],
      "venue" : "arXiv preprint arXiv:1207.0580, 2012.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A desicion-theoretic generalization of on-line learning and an application to boosting",
      "author" : [ "Y. Freund", "R. Schapire" ],
      "venue" : "Computational Learning Theory, ser. Lecture Notes in Computer Science, vol. 904. Springer Berlin Heidelberg, 1995, pp. 23–37. [Online]. Available: http://dx.doi.org/10.1007/3-540-59119-2 166",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Stacked generalization",
      "author" : [ "D.H. Wolpert" ],
      "venue" : "Neural Networks, vol. 5, pp. 241–259, 1992. [Online]. Available: http://www.machine-learning.martinsewell.com/ensembles/stacking/Wolpert1992.pdf",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "Issues in stacked generalization",
      "author" : [ "K.M. Ting", "I.H. Witten" ],
      "venue" : "1999.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "An extensible meta-learning approach for scalable and accurate inductive learning",
      "author" : [ "P.K.-W. Chan" ],
      "venue" : "Ph.D. dissertation, Columbia University, 1996.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Stacked regressions",
      "author" : [ "L. Breiman" ],
      "venue" : "Machine Learning, vol. 24, pp. 49–64, 1996. [Online]. Available: http://dx.doi.org/10.1007/BF00117832",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "What is your playing style? [Online]. Available: http://style.baduk.com",
      "author" : [ "A. Dinerchtein" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2012
    }, {
      "title" : "Neural Networks: A Comprehensive Foundation (2nd Edition), 2nd ed",
      "author" : [ "S. Haykin" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1998
    }, {
      "title" : "A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm",
      "author" : [ "M. Riedmiller", "H. Braun" ],
      "venue" : "IEEE International Conference on Neural Networks, 1993, pp. 586–591.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Nearest neighbor pattern classification",
      "author" : [ "T.M. Cover", "P.E. Hart" ],
      "venue" : "IEEE Transactions on Information Theory, vol. 13, no. 1, pp. 21–27, 1967.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1967
    }, {
      "title" : "Overview and recent advances in partial least squares",
      "author" : [ "R. Rosipal", "N. Krmer" ],
      "venue" : "in Subspace, Latent Structure and Feature Selection Techniques, Lecture Notes in Computer Science. Springer, 2006, pp. 34–51. [Online]. Available: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.85.7735",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Classification and regression trees",
      "author" : [ "L. Breiman", "O.R.A.J.H. Friedman", "C.J. Stone" ],
      "venue" : "Monterey, CA: Wadsworth & Brooks/Cole Advanced Books & Software,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1984
    }, {
      "title" : "A genetic algorithm tutorial",
      "author" : [ "D. Whitley" ],
      "venue" : "Statistics and computing, vol. 4, no. 2, pp. 65–85, 1994.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "A study of cross-validation and bootstrap for accuracy estimation and model selection.",
      "author" : [ "R. Kohavi" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1995
    }, {
      "title" : "KGS archives — kiseido go",
      "author" : [ "W. Shubert" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2013
    }, {
      "title" : "winter 2011) Games of Go on Disk — GoGoD Encyclopaedia and Database, Go players",
      "author" : [ "J. Fairbairn" ],
      "venue" : null,
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2011
    }, {
      "title" : "winter 2011) Games of Go on Disk — GoGoD Encyclopaedia and Database",
      "author" : [ "T.M. Hall", "J. Fairbairn" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2011
    }, {
      "title" : "On move pattern trends in a large go games corpus",
      "author" : [ "P. Baudiš", "J. Moudřı́k" ],
      "venue" : "Arxiv, CoRR, October 2012. [Online]. Available: http://arxiv.org/abs/1209.5251",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "GoStyle — Determine playing style in the game of Go",
      "author" : [ "J. Moudřı́k", "P. Baudiš" ],
      "venue" : null,
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2013
    }, {
      "title" : "Orange: Data mining toolbox in python",
      "author" : [ "J. Demšar" ],
      "venue" : "Journal of Machine Learning Research, vol. 14, pp. 2349–2353, 2013. [Online]. Available: http://jmlr.org/papers/v14/demsar13a.html",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Implementation of a fast artificial neural network library (fann)",
      "author" : [ "S. Nissen" ],
      "venue" : "Department of Computer Science University of Copenhagen (DIKU), Tech. Rep., 2003, http://fann.sf.net.",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "The field of computer Go is primarily focused on the problem of creating a program to play the game by finding the best move from a given board position [1].",
      "startOffset" : 153,
      "endOffset" : 156
    }, {
      "referenceID" : 1,
      "context" : "In our previous work [2], we have presented a way to extract information rich features from sets of Go players’ games.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 2,
      "context" : "All these player attributes (various axes of style, and strength) can be mapped on a subset of real numbers [3].",
      "startOffset" : 108,
      "endOffset" : 111
    }, {
      "referenceID" : 3,
      "context" : "Some of them train one model on differently sampled data [4], as is the case of bagging [5] and the related random forests algorithm [6].",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 4,
      "context" : "Some of them train one model on differently sampled data [4], as is the case of bagging [5] and the related random forests algorithm [6].",
      "startOffset" : 88,
      "endOffset" : 91
    }, {
      "referenceID" : 5,
      "context" : "Some of them train one model on differently sampled data [4], as is the case of bagging [5] and the related random forests algorithm [6].",
      "startOffset" : 133,
      "endOffset" : 136
    }, {
      "referenceID" : 6,
      "context" : "The schemes for combining such models in a voting-like manner seems to be well understood [7].",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 7,
      "context" : "For example, in neural networks, these ideas have also recently been re-introduced in the form of a dropout [8].",
      "startOffset" : 108,
      "endOffset" : 111
    }, {
      "referenceID" : 8,
      "context" : "Another approach to combine different models is boosting [9], where a (presumably weak) model is iteratively trained to specialize on hard instances.",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 9,
      "context" : "Stacking [10] on the other hand, uses a two-layered approach, where model on the second level learns to correct for mistakes that first level learners make.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 10,
      "context" : "For classification, various ways of forming the features from the first level prediction have been proposed ([11], [12]), multi-response linear regression has been found to work well for second level learner.",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 11,
      "context" : "For classification, various ways of forming the features from the first level prediction have been proposed ([11], [12]), multi-response linear regression has been found to work well for second level learner.",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 12,
      "context" : "For regression task such as ours, simple linear second level models have been proposed by Breiman [13].",
      "startOffset" : 98,
      "endOffset" : 102
    }, {
      "referenceID" : 13,
      "context" : "Prediction of Go player attributes has until recently been limited to pre-defined questionnaires and simple methods [14], [15].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 1,
      "context" : "Universal approach to the problem has been introduced by our previous work [2] and [3].",
      "startOffset" : 75,
      "endOffset" : 78
    }, {
      "referenceID" : 2,
      "context" : "Universal approach to the problem has been introduced by our previous work [2] and [3].",
      "startOffset" : 83,
      "endOffset" : 86
    }, {
      "referenceID" : 14,
      "context" : "in a monograph [16].",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 15,
      "context" : "The neurons have standard sigmoidal activation function and the network is trained using the RPROP algorithm [17] for at most 100 iterations (or until the error is smaller than 0.",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 16,
      "context" : "3) k-Nearest Neighbor Regression: is another commonly used machine learning algorithm [18].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 17,
      "context" : "For a good overview, see the work [19].",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 5,
      "context" : "5) Random Forests: utilize an ensemble of tree learners to predict the dependent value [6], [20].",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 18,
      "context" : "5) Random Forests: utilize an ensemble of tree learners to predict the dependent value [6], [20].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 5,
      "context" : "See the Breiman’s paper [6] for details.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 4,
      "context" : "1) Bagging: is a simple ensemble method introduced in [5].",
      "startOffset" : 54,
      "endOffset" : 57
    }, {
      "referenceID" : 4,
      "context" : "Paper [5] discusses, that this procedure is especially useful for learners bl which are unstable—small perturbations in the data have big impact on the resulting model.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 9,
      "context" : "The original idea was pioneered by [10] and extended by [12], [13].",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 11,
      "context" : "The original idea was pioneered by [10] and extended by [12], [13].",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 12,
      "context" : "The original idea was pioneered by [10] and extended by [12], [13].",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 19,
      "context" : "Genetic algorithms are an universal optimization tool, see [21] for a good tutorial.",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 20,
      "context" : "Refer to [22] for details.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 21,
      "context" : "Dataset: We have collected a large sample of games from the public archives of the Kiseido Go server [23], the sample consists of over 100 000 records of games.",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 1,
      "context" : "divided by player’s strength and preprocessed as is detailed in [2].",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 1,
      "context" : "Here, it is enough to note that the dataset consists of 120 independent pairs (x, y) for each of the 26 ranks, where x is the feature vector described in [2] (dimension of x was 1040), and y is the target variable, which is one number describing the rank (1-26).",
      "startOffset" : 154,
      "endOffset" : 157
    }, {
      "referenceID" : 22,
      "context" : "Playing style has different aspects, some of them are vaguely defined (for details, see [24]).",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 23,
      "context" : "Dataset: The collection of games in this dataset comes from the Games of Go on Disk (GoGoD) database by [25].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 24,
      "context" : "[26] The experts (Alexander Dinerchtein 3-pro, Motoki Noguchi 7-dan, Vladimı́r Daněk 5-dan and Vı́t Brunner 4-dan) were asked to value the players on four scales, each ranging from 1 to 10.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 1,
      "context" : "For each of 24 professional players, we obtained 12 pairs (x, y), where x is the feature vector obtained from the games as described in [2] (dimension of x was 640), and y is one of the 4 styles—basically, we view the problem as 4 different regression problems which share the same feature vectors.",
      "startOffset" : 136,
      "endOffset" : 139
    }, {
      "referenceID" : 2,
      "context" : "The parameters of the models are omitted for brevity, see [3] for more.",
      "startOffset" : 58,
      "endOffset" : 61
    }, {
      "referenceID" : 1,
      "context" : "The prediction of player attributes as demonstrated in this work has been (together with the feature extraction presented in [2]) combined in an online web application1, which evaluates games submitted by players and predicts their playing strength and style.",
      "startOffset" : 125,
      "endOffset" : 128
    }, {
      "referenceID" : 13,
      "context" : "The first one is the tool of [14]—the user answers 15 questions and based on the answers he gets one of predefined recommendations.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "We believe that our approach is more precise, both because it takes into account many different aspects of the games [2], and because the methods presented in this paper are able to use the information well.",
      "startOffset" : 117,
      "endOffset" : 120
    }, {
      "referenceID" : 25,
      "context" : "The code used in this work is released online as a part of GoStyle project [27].",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 26,
      "context" : "The machine learning models were implemented and evaluated using the Orange Datamining suite [29] and the Fast Artificial Neural Network library FANN [30].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 27,
      "context" : "The machine learning models were implemented and evaluated using the Orange Datamining suite [29] and the Fast Artificial Neural Network library FANN [30].",
      "startOffset" : 150,
      "endOffset" : 154
    } ],
    "year" : 2013,
    "abstractText" : "The paper presents an application of non-linear stacking ensembles for prediction of Go player attributes. An evolutionary algorithm is used to form a diverse ensemble of base learners, which are then aggregated by a stacking ensemble. This methodology allows for an efficient prediction of different attributes of Go players from sets of their games. These attributes can be fairly general, in this work, we used the strength and style of the players.",
    "creator" : "gnuplot 4.6 patchlevel 1"
  }
}