{
  "name" : "1709.03008.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Identifying Irregular Power Usage by Turning Predictions into Holographic Spatial Visualizations",
    "authors" : [ "Patrick Glauner", "Niklas Dahringer", "Oleksandr Puhachov", "Jorge Augusto Meira", "Petko Valtchev", "Radu State", "Diogo Duarte" ],
    "emails" : [ "jorge.meira}@uni.lu", "valtchev.petko@uqam.ca", "diogo.duarte@choiceholding.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Index Terms—Critical infrastructure, non-technical losses, time series classification, Microsoft HoloLens, spatial hologram.\nI. INTRODUCTION Critical infrastructure refers to assets that are essential for the functioning of a society and economy. They include power generation, transmission and distribution facilities. Losses in power grids can be grouped into technical losses, which appear naturally due to internal electrical resistance, and non-technical losses (NTL), which appear during power distribution. NTL include, but are not limited to, the following causes [1], [2]:\n• Meter tampering in order to record lower consumptions • Bypassing meters by rigging lines from the power source • Arranged false meter readings by bribing readers • Faulty or broken meters\nNTL can range up to 40% of the total electricity distributed in countries such as Brazil, India, Malaysia or Lebanon [3]. As\na consequence, electricity providers face financial losses as well as a decrease of stability and reliability in their power networks. It is for these reasons that electricity providers aim to reduce NTL in their networks by carrying out onsite inspections of customers that have potentially irregular behavior. To date, most NTL detection systems deployed in industry are based on expert knowledge rules [2]. In contrast, the predominant research direction reported in the recent research literature is the use of machine learning/data mining methods, which learn from customer data and known irregular behavior that was reported through inspection results. Due to the high costs per inspection and the limited number of possible inspections, electricity providers aim to maximize the return on investment (ROI) of inspections.\nIn this paper, we combine both worlds in a spatiotemporal approach that allows domain experts to visualize the prediction results of NTL classifiers in a holographic spatial visualization. An example of this outcome is depicted in Figure 1.\nar X\niv :1\n70 9.\n03 00\n8v 1\n[ cs\n.L G\n] 9\nS ep\nThe main contributions of this paper are: • We propose a novel and flexible framework to compute\na large number of domain-specific features and generic features from the noisy consumption time series of customers for NTL detection. • We retain the statistically meaningful features extracted from the noisy consumption data and optimize different classifiers to predict NTL. • We present a novel approach to put the prediction results into context by visualizing them in a 3D hologram that contains information about customers and their spatial neighborhood. This hologram can be visualized in a Microsoft HoloLens.\nThe entire process in our proposed NTL detection system is depicted in Figure 2. As an outcome, domain experts can put the results generated by the classifiers into the context of the data in order to make the final decisions of whether to inspect specific customers. We are confident that this approach will lead to an increase of both stability and reliability of power grids by making better use of the limited number of inspections as well as lead to a greater ROI of the limited number of inspections."
    }, {
      "heading" : "II. RELATED WORK",
      "text" : "State-of-the-art surveys on NTL detection are provided in [2], [4]. A data set of ~22K customers is used in [5] for training a neural network. It uses the average consumption of the previous 12 months and other customer features such as location, type of customer, voltage and whether there are meter reading notes during that period. On the test set, an accuracy of 0.8717, a precision of 0.6503 and a recall of 0.2947 are reported. Consumption profiles of 5K Brazilian industrial customer profiles are analyzed in [6]. Each customer profile contains 10 features including the demand billed, maximum demand, installed power, etc. In this setting, a SVM slightly outperforms k-nearest neighbors (KNN) and a neural network, for which test accuracies of 0.9628, 0.9620 and 0.9448, respectively, are reported. We have discussed the class imbalance and evaluation metric selection of NTL detection in [7] and shown that a large-scale machine learning approach outperforms rule-based Boolean and fuzzy logic expert systems. Covariate shift refers to the problem of training data (i.e. the set of inspection results) and production data (i.e. the set of customers to generate inspections for) having different distributions. We have shown in [8] that the sample of inspected customers may be biased, i.e. it does not represent the population of all customers. As a consequence, machine learning models trained on these inspection results may be biased as well and therefore may lead to unreliable predictions of whether customers cause NTL or not. Furthermore, we have shown that the neighborhoods of customers yield significant information in order to decide whether a customer causes a NTL or not [9], [10].\nIn the literature, different approaches for visualization of NTL are reported. In order to support the decision making, the visualization of the network topology on feeder level as\nwell as load curves on transformer level is proposed in [11]. In addition, the density of NTL in a 2D map is visualized in [12]. For analytics in power grids as a whole, the need for novel and more powerful visualization techniques is argued in [13]. The proposed approaches include heat maps and risk maps. All methods for visualization of NTL proposed in the literature focus only on 2D representations.\nWe are currently undergoing a paradigm shift in data visualization from not only 2D to 3D, but rather to augmented reality using holographic projections [14]. This shift allows to better understand and experience data [15]. Users are not constrained to looking at data on a screen, as they can interact with the data, e.g. walking around holograms to get a better understanding of Big Data sets. This comes with the benefit of increased productivity as users can use their hands to turn and manipulate objects rather than getting distracted caused by a change of focus from the screen to the input devices such as keyboards or mice [16]. A number of successful applications of holographic projections have been described in the literature including guided assembly instructions [17] as well as a combination of different geographical information\ndata sources in city management [16]. The literature also discusses the limitations of 3D visualizations, such as that users mistakenly may have greater confidence in the quality of the data [?]."
    }, {
      "heading" : "III. DETECTION OF NTL",
      "text" : ""
    }, {
      "heading" : "A. Data",
      "text" : "The data used in this paper comes from an electricity provider in Brazil and consists of 3.6M customers. The data contains 820K inspection results, such as inspection date, presence of fraud or irregularity, type of NTL and inspection notes. 620K customers have been inspected at least once and the remaining ~3M customers have never been inspected. Third, there are 195M meter readings from 2011 to 2016 such as consumption in kWh, date of meter reading and number of days between meter readings. From the 620K customers for which an inspection result is available, only the most recent inspection result is used in the experiments in Section IV. The available data per customer m is a complete time series of monthly meter readings of electricity consumption in kWh over the last N months before the most recent inspection, described as follows:\nC(m) = [C (m) 0 , ..., C (m) N−1],\nwhere C(m)N−1 is the most recent meter reading before the inspection. For greater N , less customers with a complete time series are available. In contrast, for smaller N , less information per customer is available."
    }, {
      "heading" : "B. Features",
      "text" : "In this section, we describe the features that we compute from a customer’s consumption time series C(m) for the detection of NTL.\n1) Difference Features: The intra year difference\nintra year (m) d = C (m) d − C (m) d−K ,\nfor K = 12, is the change of consumption to the consumption in the same month of the previous year. In total, there are N − 12 intra year difference features.\nThe intra year seasonal difference\nintra year seasonal (m) d = C (m) d −\n1 3 × d−K+1∑ k=d−K−1 C (m) k ,\nfor K = 12, is the change of consumption to the mean of the same season in the previous year. In total, there are N − 13 intra year seasonal difference features.\nThe fixed interval\nfixed interval (m) d = C (m) d −\n1\nK × d−1∑ k=d−K C (m) k ,\nfor K ∈ {3, 6, 12}, is the change of consumption to the mean consumption in a period of time directly before a meter reading. In total, there are 3×(N−12) fixed interval features. These features are inspired by [10], in which they are proposed only for the most recent meter reading. Instead, we compute these features for the entire consumption time series.\n2) Daily Averages: A daily average consumption feature during month d for customer m in kWh is:\ndaily avg (m) d =\nC (m) d\nR (m) d −R (m) d−1\n. (1)\nC (m) d is the consumption between the meter reading R (m) d of month d and the previous one R(m)d−1 in month d − 1. R\n(m) d − R (m) d−1 is the number of days between both meter readings of customer m. In total, there are N−1 daily average consumption features. This feature type is successfully used in a number of publications on NTL detection [7], [18]–[21]. It is therefore also relevant to our research.\n3) Generic Time Series Features: In order to catch more characteristics of the consumption time series, we compute 222 generic time series features from it, comprising:\n• Summary statistics, such as maximum, variance or kurtosis. • Characteristics from sample distribution, such as absolute energy, whether a distribution is symmetric or the number of data points above the median. • Observed dynamics, such as fast Fourier transformation coefficients, autocorrelation lags or mean value of the second derivative.\nThe full list of features is provided in [22]."
    }, {
      "heading" : "C. Feature Selection",
      "text" : "In total, 304 features are computed. In the subsequent learning phase, only the meaningful features should be used. One common dimensionality reduction method is the principal component analysis (PCA). However, time series, and in particular real-world data sets, are noisy, which can lead to poor performance of PCA [23]. It is for that reason that we do not use PCA for the feature selection. Instead, we employ hypothesis tests to the features in order to retain the ones that are statistically relevant. These tests are based on the assumption that a feature xk is meaningful for the prediction of the binary label vector y if xk and y are not statistically independent [24]. For binary features, we use Fisher’s exact test [25]. In contrast, for continuous features, we use the Kolmogorov-Smirnov test [26]."
    }, {
      "heading" : "D. Classifiers",
      "text" : "1) Decision Tree: Decision tree learners such as ID3 or C4.5 [27] recursively split the input space by choosing the remaining most discriminative feature of a data set. To predict, the learned tree is traversed top-down.\n2) Random Forest: A random forest [28] is an ensemble estimator that comprises a number of decision trees. Each tree is trained on a subsample of the data and feature set in order to control overfitting. In the prediction phase, a majority vote is made of the predictions of the individual trees.\n3) Gradient Boosted Tree: A gradient boosted tree [29] is also an ensemble of decision trees. The ensemble is boosted by combining weak classifiers (i.e. classifiers that work little better than a random guess) into a strong one. The ensemble is built by optimizing a loss function.\n4) Support Vector Machine: A support vector machine (SVM) [30] is a maximum margin classifier, i.e. it creates a maximum separation between classes. Support vectors hold up the separating hyperplane. In practice, they are just a small fraction of the training examples. Therefore, a SVM is often less prone to overfitting than other classifiers, such as a neural network [31]. The training of a SVM can be defined as a Lagrangian dual problem having a convex cost function. By default, the separating hyperplane is linear. Training of SVMs using a kernel to map the input to higher dimension is only feasible for several dozens of thousands of training examples in a realistic amount of time [32]. Therefore, for Big Data sets only a linear implementation of SVMs is practically usable [33]."
    }, {
      "heading" : "IV. EVALUATION",
      "text" : ""
    }, {
      "heading" : "A. Metric",
      "text" : "The performance measure used in the following experiments is the area under the receiver-operating curve (AUC) [34]. It plots the true positive rate or recall against the false positive rate. It is particularly useful for NTL detection, as it allows to handle imbalanced datasets and puts correct and incorrect inspection results in relation to each other. The superiority of the AUC over other metrics such as accuracy, precision or recall with respect to the problem of NTL detection has been witnessed in the literature [7]."
    }, {
      "heading" : "B. Experimental Setup",
      "text" : "We experimentally determined N = 24 months to work the best for the following experiments. Using N = 24 allows\nthe consumption data to reflect seasonality in the experiments. As a consequence, M = 150, 700 customers are retained for the experiments. This data set is imbalanced: 100,471 have a negative label (non-NTL), whereas 50,229 have a positive one (NTL). Therefore, 33.33% of the customers used in the following experiments have been found to cause NTL.\nWe train the decision tree (DT), random forest (RF), gradient boosted tree (GBT) and linear support vector machine (LSVM) classifiers as follows:\n• Handling class imbalance: We handle the class imbalance during training by assigning class weights to the examples of both classes in the training set:\nw0 = # examples\n# examplesC=0 , (2)\nw1 = # examples\n# examplesC=1 . (3)\n• Performing model selection: We want to find the model which is able to distinguish between NTL and non-NTL customers the best. For this, we optimize various parameters for every classifier. The complete list of parameters and considered values per classifier is depicted in Table I. We use randomized grid search, which samples from the joint distribution of model parameters. In contrast to grid search, randomized grid search does not try out all parameter values. We use 100 sampled models in every model selection. • Handling overfitting: We also employ model selection that splits the data set into k = 10 folds. This leads to a more reliable model for NTL detection. The AUC reported per model is the average of the AUCs of the k test sets.\nC. Implementation All computations were run on a server with 80 cores and 128 GB of RAM. The entire code was implemented in Python using scikit-learn [33] for machine learning. scikit-learn allows to distribute the training of the numerous classifiers among all cores. Using this infrastructure, the extraction of features took 6 hours. The feature selection took only 1 minute. The extensive model selection of classifiers took 4 days. In deployment, the training of classifiers will\nperform significantly faster as the extensive model selection needs to be performed only when a new data set is used. We have also noticed that about 90% of the training time was spent on the gradient boosted tree. Therefore, a significant speedup can be achieved in deployment when skipping the training of this classifier."
    }, {
      "heading" : "D. Feature Selection",
      "text" : "We first compute the features described in Section III and then perform the feature selection. In summary, there are three types of features: (1) generic time series (GTS) features, (2) daily average features (AVG) and (3) difference features (DIF) composed of fixed interval, intra year difference and intra year seasonal difference features. The numbers of features before and after selection are depicted in Table II. In total, 237 out of the 304 features are retained. The relevance of our hand-crafted difference features is confirmed: All intra year difference and intra year seasonal difference features are retained. In addition, 34 out of 36 fixed interval features are retained. The 2 features are not retained for K = 3, which is most likely due to the too short span of time they reflect. As a matter of fact, daily average features are widely used in the research literature on NTL detection. However, only 18 out of 23 daily average consumption features (i.e. 78%) are retained. The 5 daily average consumption features that are not retained are the ones for the first - i.e. the oldest - 6 months of the 24-month window. The statistical feature check leads to the conclusion that this type of feature is only useful for about 1.5 years of our data for NTL detection. In addition, 73% of the generic time series features are retained after the statistical relevance check. As these features are generic and not particularly made for NTL detection, it is to no surprise that the retention rate for these features is the lowest."
    }, {
      "heading" : "E. Classification Results",
      "text" : "We train the four classifiers on each of the GTS, AVG and DIF feature sets as well as on all combinations thereof. The test performance of the best model per experiment returned by the model selection is depicted in Table III. The best test AUC of 0.65977 is achieved for training the random forest classifier on the combination of the retained GTS, AVG and\nDIF features. In general, the random forest classifier works the best for every feature set. In total, we report the results of 28 experiments in Table III, both for the full feature sets as well as the retained feature sets. In 16 experiments, the feature selection leads to better results over using all features. Our observation can be explained by the “no free lunch theorem”, which states that no model is generally better than others [35]. However, our best result of 0.65977 is achieved for the retained feature set.\nGenerally, we observe that a combination of two or three feature sets leads to a better test result than for any of the respective single feature sets. An example to demonstrate this observation is as follows: The random forest classifier achieves test AUCs of 0.65726, 0.65248 and 0.65459 for the retained GTS, AVG and DIF features, respectively. It then achieves test AUCs of 0.65835, 0.65896, 0.65755 and 0.65977 for the retained GTS+AVG, GTS+DIF, AVG+DIF and GTS+AVG+DIF feature sets, respectively. Therefore, the test AUCs for each of the combined feature sets are greater than the test AUCs for any of the single feature sets."
    }, {
      "heading" : "F. Discussion",
      "text" : "Previous works that employ the widely-used daily average features established a baseline that only achieved an AUC of slightly above 0.5 [7], [36], i.e. slightly above chance, on real-world NTL detection data sets using linear classifiers. First and foremost, we want to highlight that increasing the performance of machine learning models on noisy real-world data sets is far more challenging than doing so on academic data sets that were created and curated in controlled environments. Furthermore, a small increase of the performance of a real-world model can lead to a major increase of the market value of a company. Our framework presented in this paper significantly outperforms the baselines established in the literature. As a consequence, our models lead to a better detection of NTL and thus to an increase of revenue and profit for electricity providers as well as an increase of stability and reliability in their critical infrastructure. Our NTL detection framework allows other electricity providers to apply our extensive feature extraction, feature selection and\nmodel selection techniques to their data sets, which can lead to potentially greater improvements of NTL detection in their power networks.\nIt is to our surprise that the gradient boosted tree classifier performs consistently worse than the random forest classifier in our experiments. In the literature, the gradient boosted tree is reported to often lead in a wide range of classification problems [29]. However, our observation can also be explained by the “no free lunch theorem”."
    }, {
      "heading" : "V. HOLOGRAPHIC VISUALIZATION OF NTL",
      "text" : "The NTL detection approach presented in Section III and evaluated in Section IV allows to predict whether customers cause NTL or not. It can then be used to trigger possible inspections of customers that have irregular electricity consumption patterns. Subsequently, technicians carry out inspections, which allow them to remove possible manipulations or malfunctions of the power distribution infrastructure. Furthermore, the fraudulent customers can be charged for the additional electricity consumed. Generally, carrying out inspections is costly, as it requires physical presence of technicians. In order to increase both the ROI of the limited number of inspections and the reliability and stability of the power grid, electricity providers in practice strongly rely on expert knowledge for making the decision of whether to inspect a customer or not [7]. As a consequence, electricity providers are reluctant to move to large-deployments of NTL detection systems based on machine learning. We therefore aim to combine automated statistical decision making for generating inspection proposals with incorporating knowledge of the domain experts at the electricity providers for making the final decisions of which customers to inspect."
    }, {
      "heading" : "A. HoloLens",
      "text" : "Mixed reality smartglasses such as the Microsoft HoloLens [37] depicted in Figure 3 allow users to combine holographic projections with the real world. The Hololens offers their user a new perception of 3D models and, perhaps, can provide a new meaning to it. Visualization of data through holograms has found its application in many areas. In medicine, future doctors can study human anatomy by looking at a representation of the human body and navigate through muscles, organs and skeletons [38]. The HoloLens has the ability to perform the holoportation, which allows to virtually place users to remote locations to see, hear and interact with others. Users can walk\naround holograms and interact with them using gaze, gestures or voice in the most natural way. Spatial sound allows hearing holograms even if they are behind the user, considering its position and direction of the sound. Spatial mapping features provide a real-world representation of surfaces, creating convincing holograms in augmented reality.\nB. Implementation\nWe created a 3D model using Google Earth Pro and Blender. Our model allows us to visualize customers and their neighborhood in a 3D spatial hologram that is depicted in Figure 4. A movie was recorded to capture the scene and all its objects from the different angles through Google Earth Pro. Afterwards, images were extracted in Windows Movie Maker from that movie at the best experimentally determined rate of 1 frame/sec. Then, those images were loaded in Blender, which in turn created a 3D FBX model. This model was exported to Unity. Holographic effects were implemented through HoloToolkit-Unity [39]. The GameObjects that handle input events implement the IInputHandler interface for tap and hold gestures. Classes that implement the IManipulationHandler interface handle manipulation gestures such as moving and rotating actions."
    }, {
      "heading" : "C. Results",
      "text" : "This application is used by domain experts at the electricity providers who perceive that customers are classified as either regular (green) or irregular (red). Domain experts can walk around a spatial hologram and observe the data from different directions. Using their hand, they can also interact with the\nhologram in different ways, such as zooming into or rotating the hologram as depicted in Figure 5.\nDomain experts can also learn more about a customer by tapping on it with their finger. The spatial hologram then also depicts the consumption profile of the respective customer over a selected period of time such as the previous 12 months. A customer with a predicted regular consumption profile is depicted in Figure 6. This customer’s consumption has only changed very little in the last 12 months. As a consequence, the machine learning system classified this customer as non-NTL (green). A customer with an irregular consumption profile is depicted in Figure 1. This customer’s consumption has undergone a significant drop over the last few months. Therefore, the machine learning system classified this customer as NTL (red). In both cases, domain experts can compare their observations with the prediction made by the machine learning system. If the prediction is not plausible, domain experts can choose not to follow the recommendation and therefore decide whether to inspect a customer. Our visualization allows domain experts to take the neighborhood of customers into account in order to decide which customers to inspect. Aside from the actual spatial visualization of satellite images of a neighborhood, domain experts can also visualize the consumption profile of neighbors as visualized in Figure 7 for comparing customers in order to decide whether to inspect a customer."
    }, {
      "heading" : "D. Discussion",
      "text" : "Our holographic spatial visualization of customers and their neighborhood comes with the benefit of increased productivity. It has previously been shown that the neighborhoods of customers yield significant information in order to decide whether a customer causes a NTL or not [9], [10]. There are many interpretations of this fact. For example, fraudulent customers may share their knowledge with neighbors or there may be a correlation between electricity theft and the level of prosperity of a neighborhood. Our system allows to increase the ROI of inspections as well as to increase both the reliability and stability of the power grid by incorporating expert knowledge in the decision making process. Also, domain experts can use their hands to turn and manipulate objects rather than getting distracted by a change of focus from the screen to the input devices such as a keyboard or mouse."
    }, {
      "heading" : "VI. CONCLUSION AND FUTURE WORK",
      "text" : "In this work, we have proposed a novel system for detecting non-technical losses (NTL) for a real-world data set of 3.6M customers. In the first stage, a machine learning system learns to predict whether a customer causes NTL or not. In order to do so, we have proposed to extract a number of domainspecific features from the noisy consumption data. We have shown the statistical relevance of these features over generic time series features. As a consequence, our machine learning system allows to detect NTL better than previous works described in the literature. In the second stage, we put the prediction results into context by visualizing further data of the customers and their neighborhoods in a spatial hologram using a Microsoft HoloLens. Using this hologram, domain experts can then review and amend the suggestions of which customers to inspect. As a result, they can make the final decisions of which customers to inspect in order to increase the ROI of the limited number of inspections.\nWe have previously referred to the main challenges to solve in order to advance NTL detection. We believe that covariate shift is one of the main impediments in advancing NTL detection. It has been argued that covariate shift is currently one of the main impediments in a wide range of real-world Big Data machine learning problems [40]. Therefore, reducing the covariate shift in the data should be a future priority in the detection of NTL. We therefore expect our models to perform better after the reduction of covariate shift. In order to make the visualization ready for large-scale production, we are planning to integrate other 3D data sources as well as to add compression algorithms such that large maps can be transferred to the HoloLens. We are also interested in visualizing other quantities, such as prosperity levels or credit worthiness, in the spatial holograms. We are also interested in exploring unsupervised methods in the future in order to build system that perform with only the availability of consumption data."
    }, {
      "heading" : "ACKNOWLEDGMENT",
      "text" : "We would like to thank Tamer Aidek and Yves Rangoni from CHOICE Technologies Holding Sàrl for contributing many good ideas to our discussions. This work has been partially funded by the Luxembourg National Research Fund."
    } ],
    "references" : [ {
      "title" : "Non-technical losses in power system: A review",
      "author" : [ "A. Chauhan", "S. Rajvanshi" ],
      "venue" : "Power, Energy and Control (ICPEC), 2013 International Conference on. IEEE, 2013, pp. 558–561.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The challenge of non-technical loss detection using artificial intelligence: A survey",
      "author" : [ "P. Glauner", "J.A. Meira", "P. Valtchev", "F. Bettinger" ],
      "venue" : "International Journal of Computational Intelligence Systems, vol. 10, no. 1, pp. 760–775, 2017.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "High performance computing for detection of electricity theft",
      "author" : [ "S.S.S.R. Depuru", "L. Wang", "V. Devabhaktuni", "R.C. Green" ],
      "venue" : "International Journal of Electrical Power & Energy Systems, vol. 47, pp. 21–30, 2013.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Solutions for detection of non-technical losses in the electricity grid: A review",
      "author" : [ "J.L. Viegas", "P.R. Esteves", "R. Melı́cio", "V. Mendes", "S.M. Vieira" ],
      "venue" : "Renewable and Sustainable Energy Reviews, vol. 80, pp. 1256–1268, 2017.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Fraud detection in electric power distribution networks using an ann-based knowledgediscovery process",
      "author" : [ "B.C. Costa", "B.L. Alberto", "A.M. Portela" ],
      "venue" : "International Journal of Artificial Intelligence & Applications, vol. 4, no. 6, p. 17, 2013.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Identification and feature selection of non-technical losses for industrial consumers using the software weka",
      "author" : [ "C.C.O. Ramos", "A.N. De Souza", "D.S. Gastaldello" ],
      "venue" : "Industry Applications (INDUSCON), 2012 10th IEEE/IAS International Conference on. IEEE, 2012, pp. 1–6.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Large-scale detection of non-technical losses in imbalanced data sets",
      "author" : [ "P. Glauner", "A. Boechat", "L. Dolberg" ],
      "venue" : "Innovative Smart Grid Technologies Conference (ISGT), 2016 IEEE Power & Energy Society. IEEE, 2016.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Is big data sufficient for a reliable detection of non-technical losses?",
      "author" : [ "P. Glauner", "A. Migliosi", "J. Meira", "P. Valtchev", "R. State", "F. Bettinger" ],
      "venue" : "in 19th International Conference on Intelligent System Applications to Power Systems (ISAP",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2017
    }, {
      "title" : "Neighborhood features help detecting non-technical losses in big data sets",
      "author" : [ "P. Glauner", "J. Meira", "L. Dolberg" ],
      "venue" : "3rd IEEE/ACM International Conference on Big Data Computing Applications and Technologies (BDCAT 2016), 2016.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Distilling provider-independent data for general detection of non-technical losses",
      "author" : [ "J. Meira", "P. Glauner", "R. State" ],
      "venue" : "Power and Energy Conference at Illinois (PECI), 2017. IEEE, 2017.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Assessment of the smart grids applied in reducing the cost of distribution system losses",
      "author" : [ "A. Abaide", "L. Canha", "A. Barin", "G. Cassel" ],
      "venue" : "Energy Market (EEM), 2010 7th International Conference on the European. IEEE, 2010, pp. 1–6.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Identification of nontechnical electricity losses in power distribution systems by applying techniques of information analysis and visualization",
      "author" : [ "J. Porras", "H. Rivera", "F. Giraldo", "B. Correa" ],
      "venue" : "IEEE Latin America Transactions, vol. 13, no. 3, pp. 659–664, 2015.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Data analytics in smart distribution networks: Applications and challenges",
      "author" : [ "F.C. Trindade", "L.F. Ochoa", "W. Freitas" ],
      "venue" : "Innovative Smart Grid Technologies-Asia (ISGT-Asia), 2016 IEEE. IEEE, 2016, pp. 574– 579.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Visualizing big data with augmented and virtual reality: challenges and research agenda",
      "author" : [ "E. Olshannikova", "A. Ometov", "Y. Koucheryavy", "T. Olsson" ],
      "venue" : "Journal of Big Data, vol. 2, no. 1, p. 22, 2015.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "The future of three-dimensional thinking",
      "author" : [ "M.A. Hoffman" ],
      "venue" : "Science, vol. 353, no. 6302, pp. 876–876, 2016.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Managing big city information based on webvrgis",
      "author" : [ "Z. Lv", "X. Li", "B. Zhang", "W. Wang", "Y. Zhu", "J. Hu", "S. Feng" ],
      "venue" : "IEEE Access, vol. 4, pp. 407– 415, 2016.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Evaluating the microsoft hololens through an augmented reality assembly application",
      "author" : [ "G. Evans", "J. Miller", "M.I. Pena", "A. MacAllister", "E. Winer" ],
      "venue" : "SPIE Defense+ Security. International Society for Optics and Photonics, 2017, pp. 101 970V–101 970V.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Nontechnical loss detection for metered customers in power utility using support vector machines",
      "author" : [ "J. Nagi", "K.S. Yap", "S.K. Tiong", "S.K. Ahmed", "M. Mohamad" ],
      "venue" : "IEEE transactions on Power Delivery, vol. 25, no. 2, pp. 1162–1171, 2010.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Improving svm-based nontechnical loss detection in power utility using the fuzzy inference system",
      "author" : [ "J. Nagi", "K.S. Yap", "S.K. Tiong" ],
      "venue" : "IEEE Transactions on power delivery, vol. 26, no. 2, pp. 1284–1285, 2011.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Nontechnical loss analysis for detection of electricity theft using support vector machines",
      "author" : [ "J. Nagi", "A. Mohammad", "K. Yap", "S. Tiong", "S. Ahmed" ],
      "venue" : "Power and Energy Conference, 2008. PECon 2008. IEEE 2nd International. IEEE, 2008, pp. 907–912.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Detection of abnormalities and electricity theft using genetic support vector machines",
      "author" : [ "J. Nagi", "K. Yap", "S. Tiong", "S. Ahmed", "A. Mohammad" ],
      "venue" : "TENCON 2008-2008 IEEE Region 10 Conference. IEEE, 2008, pp. 1–6.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Distributed and parallel time series feature extraction for industrial big data applications",
      "author" : [ "M. Christ", "A.W. Kempa-Liehr", "M. Feindt" ],
      "venue" : "arXiv preprint arXiv:1610.07717, 2016.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "A review on time series data mining",
      "author" : [ "T.-c. Fu" ],
      "venue" : "Engineering Applications of Artificial Intelligence, vol. 24, no. 1, pp. 164–181, 2011.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Feature selection filters based on the permutation test",
      "author" : [ "P. Radivojac", "Z. Obradovic", "A.K. Dunker", "S. Vucetic" ],
      "venue" : "ECML. Springer, 2004, pp. 334–346.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "On the interpretation of χ 2 from contingency tables, and the calculation of p",
      "author" : [ "R.A. Fisher" ],
      "venue" : "Journal of the Royal Statistical Society, vol. 85, no. 1, pp. 87–94, 1922.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 1922
    }, {
      "title" : "The kolmogorov-smirnov test for goodness of fit",
      "author" : [ "F.J. Massey Jr" ],
      "venue" : "Journal of the American statistical Association, vol. 46, no. 253, pp. 68–78, 1951.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 1951
    }, {
      "title" : "C4. 5: Programming for machine learning",
      "author" : [ "J.R. Quinlan" ],
      "venue" : "Morgan Kauffmann, p. 38, 1993.",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Random decision forests",
      "author" : [ "T.K. Ho" ],
      "venue" : "Document Analysis and Recognition, 1995., Proceedings of the Third International Conference on, vol. 1. IEEE, 1995, pp. 278–282.",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Xgboost: A scalable tree boosting system",
      "author" : [ "T. Chen", "C. Guestrin" ],
      "venue" : "Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. ACM, 2016, pp. 785–794.",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "An overview of statistical learning theory",
      "author" : [ "V.N. Vapnik" ],
      "venue" : "IEEE transactions on neural networks, vol. 10, no. 5, pp. 988–999, 1999.",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Support vector machine with adaptive parameters in financial time series forecasting",
      "author" : [ "L.-J. Cao", "F.E.H. Tay" ],
      "venue" : "IEEE Transactions on neural networks, vol. 14, no. 6, pp. 1506–1518, 2003.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "LIBSVM: A library for support vector machines",
      "author" : [ "C.-C. Chang", "C.-J. Lin" ],
      "venue" : "ACM Transactions on Intelligent Systems and Technology, vol. 2, pp. 27:1–27:27, 2011.",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Scikit-learn: Machine learning in Python",
      "author" : [ "F. Pedregosa", "G. Varoquaux", "A. Gramfort" ],
      "venue" : "Journal of Machine Learning Research, vol. 12, pp. 2825–2830, 2011.",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "The area under an roc curve with limited information",
      "author" : [ "W.B. van den Hout" ],
      "venue" : "Medical decision making, vol. 23, no. 2, pp. 160–166, 2003.",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "The lack of a priori distinctions between learning algorithms",
      "author" : [ "D.H. Wolpert" ],
      "venue" : "Neural computation, vol. 8, no. 7, pp. 1341–1390, 1996.",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Ntl detection of electricity theft and abnormalities for large power consumers in tnb malaysia",
      "author" : [ "J. Nagi", "K. Yap", "F. Nagi" ],
      "venue" : "Research and Development (SCOReD), 2010 IEEE Student Conference on. IEEE, 2010, pp. 202–206.",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Microsoft hololens",
      "author" : [ "M. Corporation" ],
      "venue" : "https://www.microsoft.com/ en-us/hololens, 2016, [Online; accessed July 3, 2017].",
      "citeRegEx" : "37",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Creating a holographic teaching tool",
      "author" : [ "A.G. Taylor" ],
      "venue" : "Develop Microsoft HoloLens Apps Now. Springer, 2016, pp. 185–193.",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Holotoolkit-unity",
      "author" : [ "M. Corporation" ],
      "venue" : "http://github.com/Microsoft/ HoloToolkit-Unity, 2017.",
      "citeRegEx" : "39",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Machine learning with big data: Challenges and approaches",
      "author" : [ "A. L’Heureux", "K. Grolinger", "H.F. ElYamany", "M. Capretz" ],
      "venue" : "IEEE Access, 2017.",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "NTL include, but are not limited to, the following causes [1], [2]:",
      "startOffset" : 58,
      "endOffset" : 61
    }, {
      "referenceID" : 1,
      "context" : "NTL include, but are not limited to, the following causes [1], [2]:",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 2,
      "context" : "NTL can range up to 40% of the total electricity distributed in countries such as Brazil, India, Malaysia or Lebanon [3].",
      "startOffset" : 117,
      "endOffset" : 120
    }, {
      "referenceID" : 1,
      "context" : "To date, most NTL detection systems deployed in industry are based on expert knowledge rules [2].",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 1,
      "context" : "State-of-the-art surveys on NTL detection are provided in [2], [4].",
      "startOffset" : 58,
      "endOffset" : 61
    }, {
      "referenceID" : 3,
      "context" : "State-of-the-art surveys on NTL detection are provided in [2], [4].",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 4,
      "context" : "A data set of ~22K customers is used in [5] for training a neural network.",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 5,
      "context" : "Consumption profiles of 5K Brazilian industrial customer profiles are analyzed in [6].",
      "startOffset" : 82,
      "endOffset" : 85
    }, {
      "referenceID" : 6,
      "context" : "We have discussed the class imbalance and evaluation metric selection of NTL detection in [7] and shown that a large-scale machine learning approach outperforms rule-based Boolean and fuzzy logic expert systems.",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 7,
      "context" : "We have shown in [8] that the sample of inspected customers may be biased, i.",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 8,
      "context" : "Furthermore, we have shown that the neighborhoods of customers yield significant information in order to decide whether a customer causes a NTL or not [9], [10].",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 9,
      "context" : "Furthermore, we have shown that the neighborhoods of customers yield significant information in order to decide whether a customer causes a NTL or not [9], [10].",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 10,
      "context" : "well as load curves on transformer level is proposed in [11].",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 11,
      "context" : "In addition, the density of NTL in a 2D map is visualized in [12].",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 12,
      "context" : "For analytics in power grids as a whole, the need for novel and more powerful visualization techniques is argued in [13].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 13,
      "context" : "visualization from not only 2D to 3D, but rather to augmented reality using holographic projections [14].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 14,
      "context" : "This shift allows to better understand and experience data [15].",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 15,
      "context" : "This comes with the benefit of increased productivity as users can use their hands to turn and manipulate objects rather than getting distracted caused by a change of focus from the screen to the input devices such as keyboards or mice [16].",
      "startOffset" : 236,
      "endOffset" : 240
    }, {
      "referenceID" : 16,
      "context" : "A number of successful applications of holographic projections have been described in the literature including guided assembly instructions [17] as",
      "startOffset" : 140,
      "endOffset" : 144
    }, {
      "referenceID" : 15,
      "context" : "data sources in city management [16].",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 9,
      "context" : "These features are inspired by [10], in which they are proposed only for the most recent meter reading.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 6,
      "context" : "This feature type is successfully used in a number of publications on NTL detection [7], [18]–[21].",
      "startOffset" : 84,
      "endOffset" : 87
    }, {
      "referenceID" : 17,
      "context" : "This feature type is successfully used in a number of publications on NTL detection [7], [18]–[21].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 20,
      "context" : "This feature type is successfully used in a number of publications on NTL detection [7], [18]–[21].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 21,
      "context" : "The full list of features is provided in [22].",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 22,
      "context" : "However, time series, and in particular real-world data sets, are noisy, which can lead to poor performance of PCA [23].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 23,
      "context" : "These tests are based on the assumption that a feature xk is meaningful for the prediction of the binary label vector y if xk and y are not statistically independent [24].",
      "startOffset" : 166,
      "endOffset" : 170
    }, {
      "referenceID" : 24,
      "context" : "For binary features, we use Fisher’s exact test [25].",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 25,
      "context" : "In contrast, for continuous features, we use the Kolmogorov-Smirnov test [26].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 26,
      "context" : "5 [27] recursively split the input space by choosing the remaining most discriminative feature of a data set.",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 27,
      "context" : "2) Random Forest: A random forest [28] is an ensemble estimator that comprises a number of decision trees.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 28,
      "context" : "3) Gradient Boosted Tree: A gradient boosted tree [29] is also an ensemble of decision trees.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 29,
      "context" : "4) Support Vector Machine: A support vector machine (SVM) [30] is a maximum margin classifier, i.",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 30,
      "context" : "Therefore, a SVM is often less prone to overfitting than other classifiers, such as a neural network [31].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 31,
      "context" : "Training of SVMs using a kernel to map the input to higher dimension is only feasible for several dozens of thousands of training examples in a realistic amount of time [32].",
      "startOffset" : 169,
      "endOffset" : 173
    }, {
      "referenceID" : 32,
      "context" : "Therefore, for Big Data sets only a linear implementation of SVMs is practically usable [33].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 33,
      "context" : "The performance measure used in the following experiments is the area under the receiver-operating curve (AUC) [34].",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 6,
      "context" : "witnessed in the literature [7].",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 32,
      "context" : "The entire code was implemented in Python using scikit-learn [33] for machine learning.",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 34,
      "context" : "Our observation can be explained by the “no free lunch theorem”, which states that no model is generally better than others [35].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 6,
      "context" : "5 [7], [36], i.",
      "startOffset" : 2,
      "endOffset" : 5
    }, {
      "referenceID" : 35,
      "context" : "5 [7], [36], i.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 36,
      "context" : "Microsoft HoloLens [37].",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 28,
      "context" : "In the literature, the gradient boosted tree is reported to often lead in a wide range of classification problems [29].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 6,
      "context" : "In order to increase both the ROI of the limited number of inspections and the reliability and stability of the power grid, electricity providers in practice strongly rely on expert knowledge for making the decision of whether to inspect a customer or not [7].",
      "startOffset" : 256,
      "endOffset" : 259
    }, {
      "referenceID" : 36,
      "context" : "Mixed reality smartglasses such as the Microsoft HoloLens [37] depicted in Figure 3 allow users to combine holographic projections with the real world.",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 37,
      "context" : "In medicine, future doctors can study human anatomy by looking at a representation of the human body and navigate through muscles, organs and skeletons [38].",
      "startOffset" : 152,
      "endOffset" : 156
    }, {
      "referenceID" : 38,
      "context" : "Holographic effects were implemented through HoloToolkit-Unity [39].",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 8,
      "context" : "a customer causes a NTL or not [9], [10].",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 9,
      "context" : "a customer causes a NTL or not [9], [10].",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 39,
      "context" : "It has been argued that covariate shift is currently one of the main impediments in a wide range of real-world Big Data machine learning problems [40].",
      "startOffset" : 146,
      "endOffset" : 150
    } ],
    "year" : 2017,
    "abstractText" : "Power grids are critical infrastructure assets that face non-technical losses (NTL) such as electricity theft or faulty meters. NTL may range up to 40% of the total electricity distributed in emerging countries. Industrial NTL detection systems are still largely based on expert knowledge when deciding whether to carry out costly on-site inspections of customers. Electricity providers are reluctant to move to large-scale deployments of automated systems that learn NTL profiles from data due to the latter’s propensity to suggest a large number of unnecessary inspections. In this paper, we propose a novel system that combines automated statistical decision making with expert knowledge. First, we propose a machine learning framework that classifies customers into NTL or non-NTL using a variety of features derived from the customers’ consumption data. The methodology used is specifically tailored to the level of noise in the data. Second, in order to allow human experts to feed their knowledge in the decision loop, we propose a method for visualizing prediction results at various granularity levels in a spatial hologram. Our approach allows domain experts to put the classification results into the context of the data and to incorporate their knowledge for making the final decisions of which customers to inspect. This work has resulted in appreciable results on a real-world data set of 3.6M customers. Our system is being deployed in a commercial NTL detection software.",
    "creator" : "LaTeX with hyperref package"
  }
}