{
  "name" : "1610.06053.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "taraka-rama.kasicheyanula@uni-tuebingen.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n61 0.\n06 05\n3v 1\n[ cs\n.C L\n] 1\n9 O\nct 2\n01 6"
    }, {
      "heading" : "1 Introduction",
      "text" : "Identification of cognates is an important task while establishing genetic relations between languages that are hypothesized to have descended from a single language in the past. For instance, English hound and German Hund are cognates which can be traced back to Proto-Germanic stage. Highly accurate automatic identification of cognates is desired for reducing the effort required in analyzing large language families such as Indo-European (Bouckaert et al., 2012) and Austronesian (Greenhill and Gray, 2009) can take up decades of effort, when performed by hand. A automatic cognate identification system can be helpful for historical linguists to analyze supposedly related language families and also fasten up the making of cognate databases which can be then be analyzed using Bayesian phylogenetic methods (Atkinson and Gray, 2006).\nIn this paper, we work with Swadesh word lists of multiple language groups and attempt to cluster related words together using a nonparametric process known as Chinese Restaurant Process (Gershman and Blei, 2012). We use the sound similarity matrix trained in an unsupervised fashion (Jäger, 2013) for the purpose of computing similarity between two words. The CRP based algorithm is similar to the CRP variant of the K-means algorithm introduced by\nKulis and Jordan (2011). Our CRP algorithm does not require any threshold and only has a single hyperparameter known as α which allows new clusters to be formed without the requirement of threshold or the number of clusters to be known beforehand.\nPrevious work by List et al. (2016) and Hauer and Kondrak (2011) employ a hand crafted or a machine learned word similarity measure to compute pair-wise distances between words. The pair-wise distance matrix is then supplied to a clustering algorithm such as average linkage clustering (Manning and Schütze, 1999) for inferring a tree structure of the words. The average linkage clustering algorithm is an agglomerative algorithm that merges individual clusters until a single cluster is left. The clustering process can be interrupted if the average similarity between two clusters falls below a predetermined threshold.\nThe agglomerative algorithm is simple and usually yields reasonable results across various language families (List, 2012). However, the method suffers from a major drawback that the threshold needs to be known beforehand for achieving high accuracy. In a recent paper, List et al. (2016) use a clustering algorithm known as InfoMap for the purpose of clustering cognates in Sino-Tibetan language groups. The InfoMap algorithm also requires a threshold for finding cognates. The authors find that the algorithm works well if the threshold is adjusted across language groups. In this paper, we compare our system against the LexStat system and show that our system yields comparable results.\nThe structure of the paper is as followed. We define the cognate clustering problem in section 2. In section 3, we describe the string alignment algorithm for the purpose of computing similarity between two strings. We describe our CRP algorithm in section 4. We describe the evaluation of our experiments and datasets in section 5. We present\nthe results of our experiments and discuss them in section 6. We conclude the paper in section 7."
    }, {
      "heading" : "2 Cognate clustering",
      "text" : "The phylogenetic inference methods require cognate judgments which are only available for a small number of well-studied language families such as Indo-European and Austronesian. For instance, the ASJP database (Brown et al., 2013)1 provides Swadesh word lists (of 40 length that are supposedly important for identifying genetic relationships between languages) transcribed in a uniform format for more than 60% of the world’s languages.2 An example of such a word list is given below:\nThe task at hand is to automatically cluster words according to genealogical relationship. This is achieved by computing similarities between all the word pairs belonging to a meaning and then supplying the resulting distance matrix as an input to a clustering algorithm. The clustering algorithm groups the words into clusters by optimizing a similarity criterion. The similarity between a word pair can be computed using supervised approaches (Hauer and Kondrak, 2011) or by using sequence alignment algorithms such as Needleman-Wunsch (Needleman and Wunsch, 1970) or Levenshtein distance (Levenshtein, 1966). An example of a pairwise distance matrix for meaning “all” is shown in table 2."
    }, {
      "heading" : "3 Sequence alignment",
      "text" : "The Needleman-Wunsch algorithm is the similarity counterpart of the Levenshtein distance. The Needleman-Wunsch algorithm maximizes similarity whereas Levenshtein distance minimizes the\n1asjp.clld.org 2However, the cognacy judgments are only available for a\nsubset of language families.\ndistance. In the Needleman-Wunsch algorithm, a character or sound segment match increases the similarity by 1 and a character mismatch has a weight of −1. In contrast to Levenshtein distance which treats insertion, deletion, and substitution equally, the Needleman-Wunsch algorithm introduces a gap opening (deletion operation) penalty parameter that has to be learned separately. A second parameter known as gap extension penalty has lesser penalty than the gap opening parameter and models the fact that deletions occur in chunks (Jäger, 2013).\nThe (vanilla) Needleman-Wunsch algorithm is not sensitive to segment pairs and a realistic algorithm should assign high similarity between sound correspondences such as /s/ ∼ /h/ than the sound pair /p/ ∼ /r/.\nIn dialectology (Wieling and Nerbonne, 2015), similarity between two segments is estimated using PMI. The PMI score of two sounds i and j is defined as followed:\nPMI(i, j) = log( p(i, j)\nq(i) · q(j) ) (1)\nwhere, p(i, j) is the relative frequency of i, j occurring at the same position in th aligned word pairs whereas, q(.) is the relative frequency of a sound in the whole word list. A positive PMI value indicates that a segment pair cooccurs together whereas, a negative PMI value indicates lack of cooccurrence. This can be interpreted as a strength of relatedness between two segments.\nIn this paper, we use the PMI matrix (of ASJP sound segments) inferred by Jäger (2013) for computing the similarity between a word pair. Jäger (2013) shows that the PMI matrix shows positive weights for sound pairs such as /p/ ∼ /b/, /t/ ∼ /d/, and /s/ ∼ /h/."
    }, {
      "heading" : "4 CRP",
      "text" : "In this section, we describe the CRP algorithm and motivate its suitability for cognate clustering.\nGiven a meaning M and the word similarity matrix S of dimensions N × N , the CRP algorithm works as follows. The CRP outputs K clusters and the clustering l1, . . . lK .\n1. Initially, assign a word wn to ln where K = N .\n2. Repeat until convergence:\n• For each word wn: – Remove wn from its cluster. – Compute snk the average similarity\nof wn to all words in cluster k. – If argmax\nk\nsnk < α assign wn to a\nnew cluster. – Else, assign wn to the cluster k\nwhere k = argmax k snk.\nThe current algorithm uses the criterion of average similarity to assign a word to a cluster. A word is assigned to the cluster with which it exhibits the highest average similarity. The intuition behind this decision is that the word should, on an average, be similar to the rest of the words in a cluster. 3\nThe magnitude of the α parameter determines the number of new clusters. A value of 0.01 is sufficient for the purpose of forming new clusters. The word similarity is always non-negative and we use a ReLU transformation (max(0, x)) that transforms negative similarity scores to 0. The CRP algorithm identifies cognate clusters of uneven sizes and can also form singleton clusters due to the simple initialization. In our experiments, we find that three full scans of the data are sufficient for the algorithm to reach a local maximum."
    }, {
      "heading" : "5 Experiments",
      "text" : "Baseline We use a vanilla Needleman-Wunsch with a gap opening penalty of −1 and a gap extension penalty of −0.5 as the baseline in our experiments.\nLexStat LexStat (List, 2012) is a system offering state-of-the-art alignment algorithms for aligning word pairs and clustering them into cognate sets. The LexStat system weighs matches between sounds using a handcrafted segment similarity matrix that is informed by historical linguistic literature.\n3The average similarity criterion can be modified to the maximum similarity criterion. This is commonly known as single linkage clustering (Manning and Schütze, 1999)."
    }, {
      "heading" : "5.1 Evaluation",
      "text" : "We evaluate the results of clustering analysis using B-cubed F-score (Amigó et al., 2009). The Bcubed scores are defined for each individual item as followed. The precision for an item is defined as the ratio between the number of cognates in its cluster to the total number of items in its cluster. The recall for an item is defined as the ratio between the number of cognates in its cluster to the total number of expert labeled cognates. The Bcubed precision and recall are defined as the average of the items’ precision and recall across all the clusters. Finally, the B-cubed F-score for a meaning, is computed as the harmonic mean of the average items’ precision and recall. The B-cubed Fscore for the whole dataset is given as the average of the B-cubed F-scores across all the meanings.\nBoth Hauer and Kondrak (2011) and List et al. (2016) use B-cubed F-scores to test their cognate clustering systems."
    }, {
      "heading" : "5.2 Datasets",
      "text" : "IELex database The Indo-European Lexical database was created by Dyen et al. (1992) and curated by Michael Dunn. The IELex database is not transcribed in uniform IPA and retains many forms transcribed in the Romanized IPA format of Dyen et al. (1992). We cleaned the IELex database of any non-IPA-like transcriptions and converted the cleaned subset of the database into ASJP format. The cleaned subset has 52 languages and 210 meanings.\nAustronesian vocabulary database The Austronesian Vocabulary Database (ABVD) (Greenhill and Gray, 2009) has word lists for 210 Swadesh concepts and 378 languages.4 The database does not have transcriptions in a uniform IPA format. We removed all symbols that do not appear in the standard IPA and converted the lexical items to ASJP format. For comparison purpose, we use randomly selected 100 languages’ dataset in this paper.5\nShort word lists with cognacy judgments Wichmann and Holman (2013) and List (2014) compiled cognacy wordlists for subsets of families from various scholarly sources such as comparative handbooks and historical linguistics’ articles. The details of this compilation is given below. For\n4http://language.psy.auckland.ac.nz/austronesian/ 5LexStat takes many hours to run on a dataset of 100 lan-\nguages.\neach dataset, we give the number of languages/the number of meanings in parantheses.\n• Wichmann and Holman (2013): Afrasian (21/40), Mayan (30/100), Mixe-Zoque (10/100), Mon-Khmer (16/100). • List (2014): ObUgrian (21/110; Hungarian excluded from Ugric sub-family)."
    }, {
      "heading" : "6 Results",
      "text" : "The B-cubed F-scores of different systems are shown in table 3. The CRP based PMI system performs better than LexStat on four datasets. The CRP algorithm performs slightly worse than the LexStat system on Austronesian and IndoEuropean language families by two points. The LexStat performs better than the PMI-CRP system only on the Ugric languages dataset. The LexStat system’s clustering threshold has been tuned on many smaller datasets whereas, the PMI-CRP does not require any tuning of the threshold and comes closer or performs better than the LexStat system. We also provide the average of Bcubed F-scores across different datasets. The results show that the PMI-CRP system is close to the performance of the LexStat system."
    }, {
      "heading" : "6.1 Match between predicted and obtained clusters",
      "text" : "We examine the match between the number of predicted clusters and the number of true clusters for the PMI-CRP system across meanings. We report the correlations in table 4. The correlations suggest that the number of predicted clusters correlate highly with the true number of clusters across datasets."
    }, {
      "heading" : "6.2 Error analysis",
      "text" : "In the case of Indo-European, the PMI-CRP system fails to group all the reflexes for the meaning\n“five”, “fingernail”, “three”, “two”, and “name” into a single cognate cluster. The reason for this behaviour is the extensive phonological change that affected cognates across the daughter subgroups. The LexStat system also shows similar behaviour when the true number of cognate clusters is 1."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper, we introduced a CRP based clustering algorithm that is threshold free. The program takes less than two minutes for clustering a large dataset of 100 languages such as Austronesian. We tested the algorithm on a wide range of language families and showed the algorithm yields close or better results than LexStat. Based on the results, we claim that the algorithm can be useful for the comparative linguists to analyze putative language relations at a quick pace.\nThe main limitation of the algorithm is that it fails to retrieve clusters for meanings such as “what”, “who”, and “we” (in Indo-European) which show high phonological divergence. In comparison, even LexStat makes mistakes when clustering these meanings. Whenever the reflexes show similar word forms, in the case of Mayan (meanings: “water” and “die”), the algorithm groups all the reflexes into a single cluster without any error.\nAs part of future work, we plan to use the CRP algorithm for clustering meanings across different language families available in the ASJP database and then supply the cognate clusters to a Bayesian phylogenetic inference software such as MrBayes (Ronquist and Huelsenbeck, 2003) for inferring Bayesian trees for the languages of the world."
    } ],
    "references" : [ {
      "title" : "Javier Artiles",
      "author" : [ "Enrique Amigó", "Julio Gonzalo" ],
      "venue" : "and Felisa Verdejo.",
      "citeRegEx" : "Amigó et al.2009",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Atkinson and Russell D",
      "author" : [ "D Quentin" ],
      "venue" : "Gray.",
      "citeRegEx" : "Atkinson and Gray2006",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "and Quentin D",
      "author" : [ "Remco Bouckaert", "Philippe Lemey", "Michael Dunn", "Simon J. Greenhill", "Alexander V. Alekseyenko", "Alexei J. Drummond", "Russell D. Gray", "Marc A. Suchard" ],
      "venue" : "Atkinson.",
      "citeRegEx" : "Bouckaert et al.2012",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Holman",
      "author" : [ "Cecil H. Brown", "Eric W" ],
      "venue" : "and Søren Wichmann.",
      "citeRegEx" : "Brown et al.2013",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Kruskal",
      "author" : [ "Isidore Dyen", "Joseph B" ],
      "venue" : "and Paul Black.",
      "citeRegEx" : "Dyen et al.1992",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "A tutorial on bayesian nonparametric models",
      "author" : [ "Gershman", "Blei2012] Samuel J Gershman", "David M Blei" ],
      "venue" : "Journal of Mathematical Psychology,",
      "citeRegEx" : "Gershman et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gershman et al\\.",
      "year" : 2012
    }, {
      "title" : "Greenhill and Russell D",
      "author" : [ "J Simon" ],
      "venue" : "Gray.",
      "citeRegEx" : "Greenhill and Gray2009",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Clustering semantically equivalent words into cognate sets in multilingual lists",
      "author" : [ "Hauer", "Kondrak2011] Bradley Hauer", "Grzegorz Kondrak" ],
      "venue" : "In Proceedings of 5th International Joint Conference on Natural Language Processing,",
      "citeRegEx" : "Hauer et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Hauer et al\\.",
      "year" : 2011
    }, {
      "title" : "Phylogenetic inference from word lists using weighted alignment with empirically determined weights",
      "author" : [ "Gerhard Jäger" ],
      "venue" : "Language Dynamics and Change,",
      "citeRegEx" : "Jäger.,? \\Q2013\\E",
      "shortCiteRegEx" : "Jäger.",
      "year" : 2013
    }, {
      "title" : "Revisiting k-means: New algorithms via bayesian nonparametrics",
      "author" : [ "Kulis", "Jordan2011] Brian Kulis", "Michael I Jordan" ],
      "venue" : "arXiv preprint arXiv:1111.0352",
      "citeRegEx" : "Kulis et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Kulis et al\\.",
      "year" : 2011
    }, {
      "title" : "Binary codes capable of correcting deletions, insertions and reversals",
      "author" : [ "Vladimir I. Levenshtein" ],
      "venue" : "In Soviet physics doklady,",
      "citeRegEx" : "Levenshtein.,? \\Q1966\\E",
      "shortCiteRegEx" : "Levenshtein.",
      "year" : 1966
    }, {
      "title" : "Philippe Lopez",
      "author" : [ "Johann-Mattis List" ],
      "venue" : "and Eric Bapteste.",
      "citeRegEx" : "List et al.2016",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "LexStat: Automatic detection of cognates in multilingual wordlists",
      "author" : [ "Johann-Mattis List" ],
      "venue" : "In Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH,",
      "citeRegEx" : "List.,? \\Q2012\\E",
      "shortCiteRegEx" : "List.",
      "year" : 2012
    }, {
      "title" : "Sequence comparison in historical linguistics. Düsseldorf University Press, Düsseldorf",
      "author" : [ "J.-M. List" ],
      "venue" : null,
      "citeRegEx" : "List.,? \\Q2014\\E",
      "shortCiteRegEx" : "List.",
      "year" : 2014
    }, {
      "title" : "Foundations of statistical Natural Language Processing",
      "author" : [ "Manning", "Hinrich Schütze" ],
      "venue" : null,
      "citeRegEx" : "Manning et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Manning et al\\.",
      "year" : 1999
    }, {
      "title" : "Needleman and Christian D",
      "author" : [ "B Saul" ],
      "venue" : "Wunsch.",
      "citeRegEx" : "Needleman and Wunsch1970",
      "shortCiteRegEx" : null,
      "year" : 1970
    }, {
      "title" : "Mrbayes 3: Bayesian phylogenetic inference under mixed models",
      "author" : [ "Ronquist", "John P Huelsenbeck" ],
      "venue" : null,
      "citeRegEx" : "Ronquist et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Ronquist et al\\.",
      "year" : 2003
    }, {
      "title" : "Languages with longer words have more lexical change. In Approaches to Measuring Linguistic Differences, pages 249–281",
      "author" : [ "Wichmann", "Holman2013] Søren Wichmann", "Eric W Holman" ],
      "venue" : null,
      "citeRegEx" : "Wichmann et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Wichmann et al\\.",
      "year" : 2013
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "In this paper, we introduce a threshold free approach, motivated from Chinese Restaurant Process, for the purpose of cognate clustering. We show that our approach yields similar results to a linguistically motivated cognate clustering system known as LexStat. Our Chinese Restaurant Process system is fast and does not require any threshold and can be applied to any language family of the world.",
    "creator" : "LaTeX with hyperref package"
  }
}