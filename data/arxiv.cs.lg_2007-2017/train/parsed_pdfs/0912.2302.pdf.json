{
  "name" : "0912.2302.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Synthesis of supervised classification algorithm using intelligent and statistical tools Supervised Classification",
    "authors" : [ "Ali DOUIK" ],
    "emails" : [ "Ali.douik@enim.rnu.tn", "Mourad.enim@yahoo.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In the other hand to refine their playing strategy such as in football, handball, volley ball, Rugby..., the coach need to have a maximum of technical-tactics information about the on-going of the game and the players. We propose in this paper a range of algorithms allowing the resolution of many problems appearing in the automated process of team identification, where each player is affected to his corresponding team relying on visual data. The developed system was tested on a match of the Tunisian national competition. This work is prominent for many next computer vision studies as it’s detailed in this study.\nKeywords-component; Soccer Singular value decomposition; Classification; artificial intelligence; supervised algorithm; Moments Matri\nI. INTRODUCTION In the last ten years, motion detection and analysis have\nbecome very important for a wide range of applications, especially since complex algorithms can nowadays be processed real-time. Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18]. Although a lot of research has done in this field on objects segmentation, still a lot of difficulties have to be considered in this area, especially to produce good results in changing circumstances. The main purpose of this paper assignment is to present an overview of objects segmentation techniques and classification.\nA large variety technique has developed and improved, K. Karman et al. used Kalman filter to model a dynamic background. Similarly K. Elgammal et al. [9] presented a nonparametric background model to model dynamic background. Toyama et. al. [10] used Wiener filter to make a linear prediction of the pixel intensity values, given the pixel historic. C. Wren et. al. [11], use a single Gaussian model per pixel and the parameters are updated by alpha blending. Unfortunately, these approaches fail in case the distribution of the background colour values do not fit into a single model. Ying Ming et al. [12] worked out a statistical algorithm inspired from the idea of Elgammel based on Cauchy distribution; they proved that ratios of intensity values between the background pixels and the current image pixels are adapted to Cauchy’s distribution. In fact it is characterized by a little wide form covering the tails of the histogram; on the other hand Gaussian distribution has an exponential form.\nSeveral works was done concerning classification, Pal et al. [21] proposed an SVM technique, their work reports the results of two experiments in which multi-class SVMs are compared with Maximum Likelihood (ML) and Artificial Neural Network (ANN) methods in terms of classification accuracy; SVM achieves a higher level of classification accuracy than either the ML or the ANN classifier.\nClassification by artificial vision in soccer sector has been largely mediatized and became a significant research topic. The result of a match has serious consequences on the club life and its external environment (media, sponsors...). To refine their play strategy [20], coach and the leaders need to have technical-tactics and relevant information [19] about events of the play as well as of the players. Indeed the use of the color in computer vision application is yet very recent, musical field [22], metals classification [23], road scenes analysis and sensing domain [16, 29, 8]. In this paper various supervised classification techniques were applied. They are based on intelligent tools as fuzzy and neuronal classification on the one hand, statistic and hybrid classification based respectively on moments difference and determination of three significant color components on the other hand. A comparative study about player recognition rates was elaborated enabling us to\nISSN : 0975-3397\nconceive an adequate method for football players classification at the aim to classify each player in his suitable class automatically.\nII. SEGMENTATION TECHNIQUES EASE OF USE"
    }, {
      "heading" : "A. Detection by histogram analysis",
      "text" : "In artificial vision field, colour images are taken by a video\ncamera and then digitized by a computer. Since the soccer video is taken by static camera, the supporter and useless information can be removed by delimiting the playing zone with an affine function. Objects identification in colour images is a relevant stage in classification study; therefore we begin by the background subtraction to detect players and then to classify each of them in its suitable class. The algorithm is based on the following stages:\n Convert the original image to standards rgb levels removing the light reflections.\n Detect the high and low thresholds of each histogram then carry out the threshold on the three chromatic levels.\n Apply a logical operator “AND” on the three levels and the original images."
    }, {
      "heading" : "B. Detection by statistical learning",
      "text" : "Detection by histogram analysis consists to segment colour\nimages and to remove useless information that have no contribution in classification phase. This method isn’t a good choice of segmentation for many applications as presented in figure 2. The major problem of this technique corresponds at the time when the background and foreground have the same characteristics, hence after thresholding histograms many false detection can be occurred: for example it can remove a large part of useful information hence we should develop an appropriate technique.\nBecause the parametric background model still lacks flexibility when dealing with non-static backgrounds, a highly flexible non-parametric technique is proposed for estimating background probabilities from many recent samples over time using Kernel density estimation.\nIn the non-parametric model all recently observed pixel values x1, x2…xN are modeled by probability density functions using a certain kernel estimator function, which is often chosen to be a Gaussian. The weighted sum of all these Gaussians results in the final probability density function of the pixel value xt:\n\nThe kernel estimator function K is chosen to be a Normal function (0, )N  with  being the kernel function bandwidth. For simplicity reasons the color channels within are assumed\nindependent, but each with their own kernel bandwidth 2j . Because of these assumptions the final density estimation can then be written as:\n\nWhen this probability is below a certain threshold, the pixel is classified as a foreground pixel. The threshold can be adjusted to achieve a desired proportion of false positives. In other kernel density estimation applications, the kernel bandwidth has to be dependent on the number of samples. When there are many samples the bandwidth should be smaller than if we have few one. However, in this case temporal properties are taken into account for determining the 2j of color channel j. For each color channel the median m of the absolute differences of each consecutive pairs of samples is calculated. We estimate  by:\n\nThis method guaranties that the local deviation is large when there are many large jumps between consecutive samples and smaller when this is not the case."
    }, {
      "heading" : "C. Singular Value Decomposition Approach [24]",
      "text" : "been applied on a soccer video images, the main problem that can be appears is the occurring of wrong detection pixels, indeed shadow pixels are detected as moving objects result to\n1\n1( ) ( ) N\nt t i i p x K x x n   \n2( ) 221 1Pr( ) 1 21 2 x xtj ij k jdx et jK i j       \n0,68 2 m \nISSN : 0975-3397\nan over segmentation that will be damage, many later works where this paper it’s registered, however this algorithm is extremely important because it’s a part of players classification and tracking on a soccer video.\nTwo major issues in the SVD technique: (1) carrying out a mathematical approach and (2) explain main advantage of the method proposed here and showing influences of the singular values choice on a treated output image, besides we will see the prominent contribution using SVD theory to restore and eliminate shadow, highlights and noise from camera displacement and changed circumstances.\n2) SVD approximation of an image The main objective of background segmentation technique is to use singular value decomposition of a given image A represented by a matrix Ap = [aij], when it can be decomposed into a product of three matrix Tk k kU S V as shown in figure 3. Where aij is the appearance frequency of chromaticity and intensity of background pixels (p= red, green, blue).\nSVD technique consists to reduce the size for each initial chromatic level from r to k rank by suppression of r-k column. Matrix S represents diagonally the singular values classified by decreasing orders. Low values have no influence on the total energy of A. Uk and Vk are orthogonal matrices issued from matrices U and V. The determined singular values for each plan were presented in frequency space. There representation proves that for each one corresponds a discrete frequency. The noise that can occur in the signal (in frequency space the amplitude of noise is constant) corresponds to a low amplitude of singular value whereas high amplitudes of these represents global signal energy.\n3) Confidence intervals research In this section, we describe the basic background model and the background subtraction process with singular value decomposition. It’s both used in the restoration or the reconstruction of an image, to increase the compactness distribution of different classes and also to provide useful image information.\nTo evaluate mathematical contribution of SVD, a quantification of global signal energy distribution according to the weight of each singular value Skk was done. The figure 4 illustrates the energy distribution E defined by:\n\n\nThe relative energy contained by each singular value K, noted pk is defined by:\n\nWhere the energy of the K singular value is equal to 2 .kkS\nAs it’s shown in figures 5a, 5b and 5c, the size of treated image will be deduced from the curves representing standard déviation of each colour levels according to the singular value decomposition. In fact a good choice of the size leads to reduce both compactness in different distributions and in computing time. According to figures 5a, 5b and 5c, we can denote two zones, the first one defined in the interval  0, kkl iS   where  kkl iS is the singular value limits corresponding to the linear part of the curve (i = red, blue, green), in this zone the curve presents a slope, beyond  kkl iS a second zone appears where the standard deviation varied slightly therefore the optimal singular value  ˆkkl iS must necessarily belong to the first zone of each curve.\nTable1 illustrates initial and improved standard deviations for three channels (RGB).\n2\n1\nk\nk i E A   \n2 k k k Sp E \nISSN : 0975-3397\nThe choice of singular values will be kept depending on two issues: the first one is the energy curve evaluated by figure 4 and the second one is the standard deviation curves of each chromatic level shown in figures 5a, 5b and 5c. In fact we specify for each component the singular value limit previewed. The table 2 shows confidence intervals as well as the limit and the optimal singular values that vary from a level to another.\npixel is considered as a foreground pixel if Pr( )x tht  . The threshold th is a global threshold over all the image that can be adjusted to achieve a desired percentage of false positives. The shadows detection as foreground regions is a source of confusion for subsequent phases of analysis. Color information [18] is useful for shadows suppression by separating color from lightness information. For a given three color variables, R, G and B, the chromaticity coordinates r, g and b(r=R/(R+G+B), g=G/(R+G+B), S=(R+G+B)/3). Consider the case where the background is completely static, and let the expected value for a pixel be  , ,r g si i i . Assume that this pixel is covered by shadow and let  , ,r g st t t be the observed value for this pixel at this frame. Then it is expected that 1 2/th s s tht i  .\nTo prove robustness of this algorithm, the figure 6 illustrates different player windows and shows how we can overcome segmentation (removing shadow pixels and pixels background having the same characteristics that those foreground pixels).\nIII. CLASSIFICATION ALGORITHMS A large variety of supervised classification algorithms was developed, ranged from statistical to intelligent tools and they operate on only color regions. Each one of them is expressed in\nadapted color system representation that will contribute to an optimal classification."
    }, {
      "heading" : "A. Hybrid classification",
      "text" : "The advantage of this algorithm is that the color will be represented in a system of the three most discriminating levels, in order to be able to separate the colour nuance distributions corresponding to pixel players from each team.\n1) Hybrid colour system After extraction of useful information which represents the pixel players, we separate the two classes using colorimetric analysis. Nevertheless traditional RGB space cannot be the most discriminating representation space. Indeed, other colour systems, deduced from the RGB components, can be more suitable according to the considered case. For this reason, treatment of pixel players in various colour systems leads to a hybrid space represented by the three best colour components.\n2) Method description N.Vandenbroucke [29] considered a multidimensional space composed of the chromatic levels currently used as the following:\nE = {R, V, B, r, v, b, X, Y, Z, I1, I2, I3, y, i, q, u, v, l, t, s}. In each level α (αE) the algorithm of discrimination is based on various phases:\n Select three training player windows J1A, J2A and J1B in the RGB system.\n Convert in the α level player windows.\n Calculate the average of pixel coordinates (x, y) representing each player:\nα (x, y): pixel value (x, y) in the plan α.\nR1A and S (R1A) are respectively area and surface of the player J1A.\nR2A and S (R2A) are respectively area and surface of the player J2A.\nR1B and S (R1B) are respectively area and surface of the player J1B.\nTherefore we can evaluate for each level α:\nα-average region for J1A: 11 1\n( , )\n( ) AR\nA A\nx y m\nS R \n  \nα-average region for J2A: 22 2\n( , )\n( ) AR\nA A\nx y m\nS R \n  \nα-average region for J1B: 11 1\n( , )\n( ) BR\nB B\nx y m\nS R \n  \n Calculate the distance between J1A and J2A as well as\nthe distance between J1A and J1B\nISSN : 0975-3397\n1 ,2 1 2A A A AD m m     \n1 ,1 1 1A B A BD m m     (7)\nWhere these expression 1 ,1A BD  and 1 ,2A AD  are respectively the distance between J1A,J2A and J1A,J1B in α level. The discriminating criterion adopted is determined as the difference D between these two distances:\n1 ,1 1 ,2A B A AD D D     (8)\nWe proceed with the same way for all α level from E set. The criterion value Classification in a descending order lead to the determination of the most discriminating chromatic components (table 3).\nAfter the conversion of RGB image for the players A and B in the hybrid system, the modelling phase consists in assigning to each P(x, y) of a level the average value of the pixels intensities for the corresponding level [30].\n4) Parameters and methodology The attributes used in this algorithm are the average values of each colorimetric component whereas the criteria of decision making are the Euclidian distance between A (s, v, b) and JA where A the coordinates for model A and JA current player to be classified (table 4)\n. Similarly we calculate the distances separating the model B from JB.\nThe membership’s decision of each player belonging to a team is specified by evaluating the distance that separates player window and the two models. Indeed, a very weak distance corresponds to players of the same cluster; the opposite case corresponds to two players of different cluster.\nThe results of classification by this method are illustrated in tables 5 with a very encouraging classification rate of around 93 %.\nTeam A 210 201 95 % Team B 210 195 92 %"
    }, {
      "heading" : "B. Difference moments algorithm (dmom)",
      "text" : "The colour moments are measurements that can be employed to differentiate images based on their colors characteristics. They provide a measurement of the similarity between color images. The parameter values of each model can be compared with the images constituting database. The colour moments [26] can be considered as a discriminating criterion between texture and color objects. In fact the colour distribution for these regions follows a certain density of probability (Gaussian).\n1) Used parameters In this method Sticker and Orengo [27] employed three\ncentral colour moments expressed as follows:\n The average: 1 1 N E Pi ijN j   \nWhere Ei is the average value of the player pixels to be classified\n Standard deviation: 2) )1( ( 1 iE N Pi ijN j    \ni represents the dispersion degree between pixels player and their average.\n Skewness: 33 ( ) )1 ( 1 iE N S Pi ijN j   \nSi represents the asymmetry degree between pixels player and their average.\n2) Methodology This method is carried out in HSV system (Hue, Saturation and Value). The moments of candidate image that are fixed to nine are evaluated for each level. The discriminating criterion between two images (reference and candidate image) is defined as the sum of differences between the moments distributions with a weighting factor expressed by the following equation:\n( , ) 11\n2 3 N A Bdmom JA MB W E Ei iij A B A BW W S Si i i ii i         \ndmom: represents the distance between two players.\nMA: Model for Player JA.\nwi: are the weights to be specified which are related to the specific case, they can be granted so that various preferences are given to various attributes of an image. They can be modified to increase or decrease the importance of a colorimetric component which appears to be interesting. Classification by this method is carried out through several stages as follows:\nStage 1: Convert image RGB to HSV.\nStage 2: Calculate the moments matrices of the two models (MA, MB).\nStage 3: Calculate the moments matrix of to classify each player.\nStage 4: Calculate the dmom for the following matrix of weights:\n1 2 1 1 2 1 1 2 1 W          \nWe calculate dmom between two models and a given object (player). It is well noticed that these distances to an attribute can contribute to make decision on classification.\n3) Experimental results The classification by moments difference technique for two clusters are elaborated, the results are illustrated in table 7, the global classification rate for two classes reaches 78 %.\nTeam B 210 200 95 %"
    }, {
      "heading" : "C. Fuzzy classification [31]",
      "text" : "Fuzzy logic is frequently used in computer vision, it may affect various applications. The most common among these are regulation, control and classification. Many fuzzy systems can be used in this context: Sugeno model, Tsukamoto model and Mamdani model (used in this algorithm).\n1) Statistical study With an extensible colour images database taken during the warming up time (at the beginning of the match), a statistical study [16] was elaborated allowing to establish correlation between parameters during classification. Figure 7a, 7b and 7c represents respectively the distribution curves of the intensities average values of the green (green_moy), the blue (blue_moy) and the red (red_moy).\nFigure 7. The intensities distribution of the three components (RGB) for two clusters\nThe distribution curves highlight the importance of each parameter during classification. Only the parameter red_moy presents an overlapping (Fig.7c), the two other parameters green_moy, blue_moy (Fig.7a and Fig.7b) haven't it, thus a statistical classification [25] can be used in this case.\n2) Methodology The fuzzy classification is done relying on the following\nstages:\n0,41 0,36 0,35 0,22 0,16 0,19 1.25 1.19 1.19 AM          \n0.76 0.70 0.74 0.10 0.08 0.10 0.01 0.01 0.01 BM          \nMoments Matrix of Player (JA) Moments Matrix of Player (JB)\n0.71 0.66 0.70 0.08 0.07 0.88 0.31 0.28 0.28 MA          \n0.40 0.33 0.32 0.25 0.17 0.20 0.84 0.74 0.74 MB          \n Inference rules: is a set of rules between the fuzzy subsets at the aim to draw deductions.\n Defuzzification: specifies the suitable output model according the inference rules, in fact the decision was made by calculating the gravity centre of the resulting function as illustrated in the following equation:\n\n3) Experimental results of classification\nThe classification by fuzzy technique gives the results illustrated in table 8. The global classification rate for the two classes reaches 97 %."
    }, {
      "heading" : "D. Neural Networks classification algorithm (NN) [32]",
      "text" : "Classification by artificial vision [28] in sports field became a significant research topic; it treated several problems that can result in an overlapping between various classes. The neural network is an information processing system inspired from cells organization of the human brain. In a neural network as represented in figure 9, we distinguish three types of neurons:\n Input neurons: they have the property to gather data whose source is apart from the network.\n Output neurons: define the output layer of the network. It contains as many neurons as the number of classes to be discriminated.\n Hidden neurons: they don’t have any relation with the external world, it is used to coordinate between the input and output neurons.\nSimilarly to human brain, the artificial neural networks can be learned by experiment: Indeed, the objective of supervised\nretropropagation algorithm is to minimize a cost function 'E' representing a quadratic error for an input-output. Where dK the desired output for the Kth neuron and SK the obtained output by the network [20].\n2( )k k k E d s   \nThe weight is obtained according equation (12) where α is a positive real that specifies the step of weights modification.\n1 . .t tij ij i jW W C S    \nTo carry out classification, we highlight relations between objects on the one hand, objects and their parameters on the other hand. In this section we present a classification by Neural Network (NN) learned with retropropagation algorithm. This technique allows discriminating clusters (players) present in color images issued from sports meeting. It can be summarized in 4 stages shown in figure10.\n2) Training phase The used parameters to classify player windows by this technique are the same used in dmom technique. For the training phase 9 parameters are used, the initial base was constituted by 560 regions in various positions among this base 300 represent two clusters C1 and C2, 260 represent respectively the C3 and C4 clusters. Indeed, NN allowed weights adjustment by retro-propagation algorithm until reaching a null error defined in last section. The training phase was done as follows: we selected several player windows from the training database, and extracted parameters will be used to classify these regions. The player windows contains respectively four classes C1, C2, C3 and C4 then the desired output are indexed respectively by 1, 2, 3 and 4. To appreciate the classification algorithm, the curves representing training error according epochs number on one hand in figure 11 and error according neurons of the hidden layer on the other hand has been evaluated in Figure 12.\n( )\n( )\ns z zdz Zs\ns z dz\n\n\n \n\nISSN : 0975-3397\nThe choice of the neurons number in the hidden layer depends on the training phase. Indeed, we must learn networks some models in many circumstance and various positions, each experience contains a different neurons number from hidden units, the choice taken is the first one leading to a weak training error. Figure 12 shows variation of training error according to neurons number in hidden layer.\n3) Validation phase In this stage we worked with a large amount of samples from our data base with the same color classification parameters. We made the simulation of the network that is already created in the training stage. In the validation network stage we evaluated by testing 546 players of the various classes and for the two sports meeting dividing it as follows: 161, 167, 114 and 104 player windows respectively for C1, C2, C3 and C4 clusters. Figure 13 represents many colour regions detected by the segmentation algorithm. This test allows appreciating the performances of the neuronal system. If the performances are not satisfactory, it will be necessary either to modify the network architecture, or to modify the training base. The obtained classification results are illustrated in table 9.\nAnother test was carried out by widening the training data base by increasing it from 130 to 180 player windows for each class of second meeting and from 150 to 200 for the two other classes, this test leads to improve the recognition rate in\nTable 10, indeed it reaches 100 % for the most classes (C1, C3, C4).\nFigure 13. Player windows for each cluster for many positions\nIV. CONCLUSION In this paper, many algorithms were elaborated to detect objects in colour images sequences issued from sports meeting. Several automatic classification systems were made to classify different color region representing football players. All classification techniques developed are supervised, we can discriminate on the one hand intelligent techniques such as neuronal and fuzzy algorithms and on the other hand hybrid algorithm based on the determination of a color representation system containing the three most significant components and using a metric distance in this base as a decision making approach taking in to account suitable established models. In fact, we can verify in this paper that RGB system is not always the suitable system for solving several problems raised by the researchers in computer vision field (e.g. overlapping, screening…). To overcome these problems, we determined three discriminating components (v, B, S) which are not from the same representation system and leads to a promising classification rates for various color regions. Indeed, we obtained with the intelligent tools good rates, 97% and 100% respectively for fuzzy and neuronal algorithms, while for hybrid technique it reaches a rate of 98%.\nV. REFERENCE [1] A. Senior. \"Tracking with Probabilistic Appearance Models\", ECCV\nworkshop on Performance Evaluation of Tracking and Surveillance Systems, pp. 48-55, 2002. [2] C. Stauffer and W.E.L. Grimson. \"Adaptive Background Mixture Models for Real-time Tracking\", Proc. IEEE Int'l Conf. on Computer Vision and Pattern Recognition: pp. 246- 252, 1999. [3] S.J. McKenna, S. Jabri, Z. Duric, A. Rosenfeld and H. Wechsler, \"Tracking Groups of People\", Computer Vision and Image Understanding 80, pp. 42-56, 2000. [4] R. Cucchiara, C. Grana, M. Picardi and A. Prati, \"Detecting Moving Objects, Ghosts, and Shadows in Video Streams\", IEEE Trans. Pattern Analysis and Machine Intelligence. 25(10): pp. 1337- 1342, 2003. [5] A. Mittal and L.S. Davis, \"M2 Tracker: A Multi-View Approach to Segmenting and Tracking People in a Clutter Scene\", International Journal of Computer Vision. 51(3): pp. 189-203, 2003.\nISSN : 0975-3397\n[6] D. Gutchess, M. Trajkovic, E. Cohen-Solal, D. Lyons and A. K. Jain, \"A Background Model Initialization Algorithm for Video Surveillance\", IEEE Int'l Conference on Computer Vision, 2001. [7] I. Haritaoglu, D. Harwood and L.S. Davis, \"W4: Real- Time Surveillance of People and Their Activities\", IEEE Trans. Pattern Analysis and Machine Intelligence. 22(8): pp. 809-830, 2000. [8] C.A. Shah, P. K. Varshney, and M. K. Arora, \"ICA mixture model algorithm for unsupervised classification of remote sensing imagery\", International Journal of Remote Sensing, 28(8), pp. 1711-1731, 2007. [9] A. Elgammal, R. Duraiswami, D. Harwood, and L. S. Davis, \"Background and Foreground Modeling Using Nonparametric Kernel Density Estimation for Visual Surveillance”, Proc. IEEE, 90(7), pp. 1151–1163, 2002. [10] K. Toyama, J. Krumm, B. Brumitt, and B. Meyers. \"Wallflower: principles and practice of background maintenance\", ICCV, pp. 255– 261, 1999. [11] C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland, \"Real-time tracking of the human body\", IEEE Trans. Pattern Anal. Machine Intell., 19, pp. 780-785, 1997. [12] Y. Ming, J. Jiang, J. Ming, \"Background Modeling and Subtraction Using a Local-Linear-Dependence-Based Cauchy Statistical Model\", Proc. VIIth Digital Image Computing: Techniques and Applications, Sun C., Talbot H., Ourselin S. and Adriaansen T. (Eds.), pp. 469-478, 2003. [13] Z. Zhao, A. Vashist, A. Elgammal, I. Muchnik, C. Kulikowski, \"Combinatorial and statistical methods for part selection for object recognition\", International Journal of Computer Mathematics, 84(9), Computer Vision and Pattern Recognition, pp. 1285-1297. 2007. [14] J. B. Hayet, \"Contribution to the navigation of a mobile robot on visual land- marks textured in a structured environment\", PHD thesis, university Paul Sabatier, Toulouse, Janvier 2003. [15] M. Antonie, O.R. Zaiane, and A. Coman, \"Application of data mining techniques for medical image classification\", Proc. 2nd Intl. Workshop on Multimedia Data mining (MDM/KDD’2001) in conjunction with Seventh ACM SIGKDD, pp. 94-101, August 2001. [16] L. Durieux, J. Kropácek, G.D. Grandi, and F. Achard, \" Object-oriented and textural image classification of the Siberia GBFM radar mosaic combined with MERIS imagery for continental scale land cover mapping\", International Journal of Remote Sensing, 28(18), pp. 4175- 4182. [17] J. Ferryman, M. Borg, D. Thirde, F. Fusier, V. Valentin, F. Bremond, M. Thonnat, J. Aguilera, and M. Kampel, \"Automated Scene Understanding for Airport Aprons\", In Australian Joint Conference on Artificial Intelligence, pp. 593–503, Sydney, Australia, 2005. [18] [18] T. Misu, S. Gohshi, Y. Izumi, Y. Fujita, and M. Naemura, \"Robust tracking of athletes using multiple features of multiple views\", Journal of WSCG, 12 (1–3), pp. 285–292, 2004. [19] [19] J.Assfalg, M. Bertini, C. Colombo, A. Del bimbo, W. Nunziati, \"Semantic annotation of soccer videos: Automatic highlights identification\", Computer Vision and Image understanding, pp. 285-305, Elsevier 2003. [20] F. Ramos, A. Junco and E. Espinosa, \"Soccer strategies that live in the B2B world of negotiation and decision-making\", International Journal on Decision Support Systems, 35, pp. 287– 310(2003). [21] M.Pal, and P. M. Mather, \"Support vector machines for classification in remote sensing\", International Journal of Remote Sensing, 26(5), pp. 1007-1011, 2005. [22] A. Meng, and J. Larsen, \"Decision time horizon for music genre classification using short time features\", EUSIPCO, pp. 1293–1296, Vienna, Austria, 2004. [23] K.Y. Choi, S.S. Kim, \"Morphological analysis and classification of types of surface corrosion damage by digital image processing\", Corrosion Science, 45, pp. 1-15, 2005. [24] M. MOUSSA JLASSI, A. Douik, H. MESSAOUD, \"Non-parametric Motion segmentation In Soccer Video Images\", 2nd International Conference on Electrical Engineering Design and Technologies, Hammamet, Tunisia, October 8-10, 2008,. [25] [25] J. Li and James Z. Wang, \"Automatic linguistic indexing of pictures by a statistical modeling approach\" IEEE Transaction on Pattern Analysis and Machine Intelligence, 25(9):1075–1088, 2003.\n[26] [26] H. Zhang and J. Feng, \"Color texture moment for content based image retrieval\", Proc. IEEE Intl Conf. on Image Processing, September, 2002. [27] M. Stricker, M. Orengo, \"Similarity of Color Images\", Proc. Storage and Retrieval for Image and Video Databases III, February 1995. [28] C. Vasquez, A. Hernandez, F. Mora, G. Carrault, and G. Passariello, \"Atrial activity enhancement by wiener filtering using an artificial neural network\", IEEE Trans. Biomed. Eng., 48, pp. 940–944, Aug. 2001. [29] S. L.Benfield, H. M. Guzman, , J. M. Mair, and J. A. T. Young, \" Mapping the distribution of coral reefs and associated sublittoral habitats in Pacific Panama: a comparison of optical satellite sensors and classification methodologies\", International Journal of Remote Sensing, 28(22), pp. 5047-5070, 2007. [30] Z. Jing, J. Tianzi, L. Bing, J. Xingpeng and Z. Huizhi. \"Systematic benchmarking of microarray data feature extraction and classification\". International Journal of Computer Mathematics, 85( 5), pp. 803-811, May 2008. [31] M. Moussa Jlassi, A. Douik and M. Annabi, \"Synthesis of Classification Supervised Algorithms for Players Identification During a Sports Meeting\", 14th IEEE International Conference on Electronics, Circuits and Systems, ICECS’07, Marrakech – Morocco, December 11-14, 2007. [32] M. Moussa Jlassi, A. Douik, H. Messaoud, \"Classification Supervisée par Approche Neuronale Application: reconnaissance des joueurs de football\", 5ème Conférence Internationale d’Electrotechnique et d’Automatique, JTEA’08, Hammamet – Tunisie, Mai 02-04, 2008.\nISSN : 0975-3397"
    } ],
    "references" : [ {
      "title" : "Tracking with Probabilistic Appearance Models",
      "author" : [ "A. Senior" ],
      "venue" : "ECCV workshop on Performance Evaluation of Tracking and Surveillance Systems,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2002
    }, {
      "title" : "Adaptive Background Mixture Models for Real-time Tracking",
      "author" : [ "C. Stauffer", "W.E.L. Grimson" ],
      "venue" : "Proc. IEEE Int'l Conf. on Computer Vision and Pattern Recognition:",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1999
    }, {
      "title" : "Tracking Groups of People",
      "author" : [ "S.J. McKenna", "S. Jabri", "Z. Duric", "A. Rosenfeld", "H. Wechsler" ],
      "venue" : "Computer Vision and Image Understanding",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2000
    }, {
      "title" : "Detecting Moving Objects, Ghosts, and Shadows in Video Streams",
      "author" : [ "R. Cucchiara", "C. Grana", "M. Picardi", "A. Prati" ],
      "venue" : "IEEE Trans. Pattern Analysis and Machine Intelligence",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2003
    }, {
      "title" : "Tracker: A Multi-View Approach to Segmenting and Tracking People in a Clutter Scene",
      "author" : [ "L.S.A. Mittal" ],
      "venue" : "International Journal of Computer Vision",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2003
    }, {
      "title" : "A Background Model Initialization Algorithm for Video Surveillance",
      "author" : [ "D. Gutchess", "M. Trajkovic", "E. Cohen-Solal", "D. Lyons", "A.K. Jain" ],
      "venue" : "IEEE Int'l Conference on Computer Vision,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2001
    }, {
      "title" : "W4: Real- Time Surveillance of People and Their Activities",
      "author" : [ "I. Haritaoglu", "D. Harwood", "L.S. Davis" ],
      "venue" : "IEEE Trans. Pattern Analysis and Machine Intelligence",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2000
    }, {
      "title" : "ICA mixture model algorithm for unsupervised classification of remote sensing imagery",
      "author" : [ "C.A. Shah", "P.K. Varshney", "M.K. Arora" ],
      "venue" : "International Journal of Remote Sensing,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2007
    }, {
      "title" : "Background and Foreground Modeling Using Nonparametric Kernel Density Estimation for Visual Surveillance",
      "author" : [ "A. Elgammal", "R. Duraiswami", "D. Harwood", "L.S. Davis" ],
      "venue" : "Proc. IEEE,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2002
    }, {
      "title" : "Wallflower: principles and practice of background maintenance",
      "author" : [ "K. Toyama", "J. Krumm", "B. Brumitt", "B. Meyers" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1999
    }, {
      "title" : "Real-time tracking of the human body",
      "author" : [ "C. Wren", "A. Azarbayejani", "T. Darrell", "A. Pentland" ],
      "venue" : "IEEE Trans. Pattern Anal. Machine Intell.,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1997
    }, {
      "title" : "Background Modeling and Subtraction Using a Local-Linear-Dependence-Based Cauchy Statistical Model",
      "author" : [ "Y. Ming", "J. Jiang", "J. Ming" ],
      "venue" : "Proc. VIIth Digital Image Computing: Techniques and Applications,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2003
    }, {
      "title" : "Combinatorial and statistical methods for part selection for object recognition",
      "author" : [ "Z. Zhao", "A. Vashist", "A. Elgammal", "I. Muchnik", "C. Kulikowski" ],
      "venue" : "International Journal of Computer Mathematics,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2007
    }, {
      "title" : "Contribution to the navigation of a mobile robot on visual land- marks textured in a structured environment\", PHD thesis, university",
      "author" : [ "J.B. Hayet" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2003
    }, {
      "title" : "Application of data mining techniques for medical image classification",
      "author" : [ "M. Antonie", "O.R. Zaiane", "A. Coman" ],
      "venue" : "Proc. 2nd Intl. Workshop on Multimedia Data mining (MDM/KDD’2001) in conjunction with Seventh ACM SIGKDD,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2001
    }, {
      "title" : "Automated Scene Understanding for Airport Aprons",
      "author" : [ "J. Ferryman", "M. Borg", "D. Thirde", "F. Fusier", "V. Valentin", "F. Bremond", "M. Thonnat", "J. Aguilera", "M. Kampel" ],
      "venue" : "In Australian Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2005
    }, {
      "title" : "Robust tracking of athletes using multiple features of multiple views",
      "author" : [ "T. Misu", "S. Gohshi", "Y. Izumi", "Y. Fujita", "M. Naemura" ],
      "venue" : "Journal of WSCG,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2004
    }, {
      "title" : "Nunziati, \"Semantic annotation of soccer videos: Automatic highlights identification",
      "author" : [ "J.Assfalg", "M. Bertini", "C. Colombo", "W.A. Del bimbo" ],
      "venue" : "Computer Vision and Image understanding,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2003
    }, {
      "title" : "Soccer strategies that live in the B2B world of negotiation and decision-making",
      "author" : [ "F. Ramos", "A. Junco", "E. Espinosa" ],
      "venue" : "International Journal on Decision Support Systems,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2003
    }, {
      "title" : "Support vector machines for classification in remote sensing",
      "author" : [ "M.Pal", "P.M. Mather" ],
      "venue" : "International Journal of Remote Sensing,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2005
    }, {
      "title" : "Decision time horizon for music genre classification using short time features",
      "author" : [ "A. Meng", "J. Larsen" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2004
    }, {
      "title" : "Morphological analysis and classification of types of surface corrosion damage by digital image processing",
      "author" : [ "K.Y. Choi", "S.S. Kim" ],
      "venue" : "Corrosion Science,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2005
    }, {
      "title" : "MESSAOUD, \"Non-parametric Motion segmentation In Soccer Video Images",
      "author" : [ "M. MOUSSA JLASSI", "H.A. Douik" ],
      "venue" : "2nd International Conference on Electrical Engineering Design and Technologies,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2008
    }, {
      "title" : "Automatic linguistic indexing of pictures by a statistical modeling approach",
      "author" : [ "J. Li", "James Z. Wang" ],
      "venue" : "IEEE Transaction on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2003
    }, {
      "title" : "Color texture moment for content based image retrieval",
      "author" : [ "H. Zhang", "J. Feng" ],
      "venue" : "Proc. IEEE Intl Conf. on Image Processing,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2002
    }, {
      "title" : "Similarity of Color Images\", Proc. Storage and Retrieval for Image and Video Databases",
      "author" : [ "M. Stricker", "M. Orengo" ],
      "venue" : null,
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1995
    }, {
      "title" : "Synthesis of Classification Supervised Algorithms for Players Identification During a Sports Meeting",
      "author" : [ "M. Moussa Jlassi", "A. Douik", "M. Annabi" ],
      "venue" : "IEEE International Conference on Electronics, Circuits and Systems,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2007
    }, {
      "title" : "Classification Supervisée par Approche Neuronale Application: reconnaissance des joueurs de football\", 5ème Conférence Internationale d’Electrotechnique et d’Automatique, JTEA’08",
      "author" : [ "M. Moussa Jlassi", "A. Douik", "H. Messaoud" ],
      "venue" : "Hammamet – Tunisie, Mai 02-04,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 112,
      "endOffset" : 127
    }, {
      "referenceID" : 1,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 112,
      "endOffset" : 127
    }, {
      "referenceID" : 2,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 112,
      "endOffset" : 127
    }, {
      "referenceID" : 3,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 112,
      "endOffset" : 127
    }, {
      "referenceID" : 4,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 112,
      "endOffset" : 127
    }, {
      "referenceID" : 5,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 156,
      "endOffset" : 162
    }, {
      "referenceID" : 6,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 156,
      "endOffset" : 162
    }, {
      "referenceID" : 13,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 183,
      "endOffset" : 187
    }, {
      "referenceID" : 14,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 207,
      "endOffset" : 211
    }, {
      "referenceID" : 15,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 225,
      "endOffset" : 229
    }, {
      "referenceID" : 12,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 251,
      "endOffset" : 255
    }, {
      "referenceID" : 16,
      "context" : "Examples of applications that use motion segmentation techniques are gesture recognition, tracking applications [1, 2, 3, 4, 5], video surveillance systems [6, 7], industry, robotics [14], the medical field [15], aeronautics [17], Pattern Recognition [13] and recently, sports sector [18].",
      "startOffset" : 284,
      "endOffset" : 288
    }, {
      "referenceID" : 8,
      "context" : "[9] presented a nonparametric background model to model dynamic background.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "[10] used Wiener filter to make a linear prediction of the pixel intensity values, given the pixel historic.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11], use a single Gaussian model per pixel and the parameters are updated by alpha blending.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12] worked out a statistical algorithm inspired from the idea of Elgammel based on Cauchy distribution; they proved that ratios of intensity values between the background pixels and the current image pixels are adapted to Cauchy’s distribution.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[21] proposed an SVM technique, their work reports the results of two experiments in which multi-class SVMs are compared with Maximum Likelihood (ML) and Artificial Neural Network (ANN) methods in terms of classification accuracy; SVM achieves a higher level of classification accuracy than either the ML or the ANN classifier.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "To refine their play strategy [20], coach and the leaders need to have technical-tactics and relevant information [19] about events of the play as well as of the players.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 17,
      "context" : "To refine their play strategy [20], coach and the leaders need to have technical-tactics and relevant information [19] about events of the play as well as of the players.",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 20,
      "context" : "Indeed the use of the color in computer vision application is yet very recent, musical field [22], metals classification [23], road scenes analysis and sensing domain [16, 29, 8].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 21,
      "context" : "Indeed the use of the color in computer vision application is yet very recent, musical field [22], metals classification [23], road scenes analysis and sensing domain [16, 29, 8].",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 7,
      "context" : "Indeed the use of the color in computer vision application is yet very recent, musical field [22], metals classification [23], road scenes analysis and sensing domain [16, 29, 8].",
      "startOffset" : 167,
      "endOffset" : 178
    }, {
      "referenceID" : 22,
      "context" : "Singular Value Decomposition Approach [24] 1) Introduction A non-parametric background modeling technique, has been applied on a soccer video images, the main problem that can be appears is the occurring of wrong detection pixels, indeed shadow pixels are detected as moving objects result to 1 1 ( ) ( ) N",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 17,
      "context" : "Blue plan 19 13 [0, 19]",
      "startOffset" : 16,
      "endOffset" : 23
    }, {
      "referenceID" : 16,
      "context" : "Color information [18] is useful for shadows suppression by separating color from lightness information.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 24,
      "context" : "The colour moments [26] can be considered as a discriminating criterion between texture and color objects.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 25,
      "context" : "1) Used parameters In this method Sticker and Orengo [27] employed three central colour moments expressed as follows:",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 26,
      "context" : "Fuzzy classification [31] Fuzzy logic is frequently used in computer vision, it may affect various applications.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 23,
      "context" : "7b) haven't it, thus a statistical classification [25] can be used in this case.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 27,
      "context" : "Neural Networks classification algorithm (NN) [32] 1) Introduction Classification by artificial vision [28] in sports field became a significant research topic; it treated several problems that can result in an overlapping between various classes.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 18,
      "context" : "Where dK the desired output for the K neuron and SK the obtained output by the network [20].",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 0,
      "context" : "REFERENCE [1] A.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 1,
      "context" : "[2] C.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] S.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] R.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[5] A.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "97 [6] D.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 6,
      "context" : "[7] I.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[8] C.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "[9] A.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "[10] K.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] C.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12] Y.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "[13] Z.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "[14] J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "[15] M.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "[17] J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[18] [18] T.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[18] [18] T.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 17,
      "context" : "[19] [19] J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "[19] [19] J.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 18,
      "context" : "[20] F.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[21] M.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "[22] A.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "[23] K.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 22,
      "context" : "[24] M.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 23,
      "context" : "[25] [25] J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 23,
      "context" : "[25] [25] J.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 24,
      "context" : "[26] [26] H.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 24,
      "context" : "[26] [26] H.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 25,
      "context" : "[27] M.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 26,
      "context" : "[31] M.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "[32] M.",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2009,
    "abstractText" : "A fundamental task in detecting foreground objects in both static and dynamic scenes is to take the best choice of color system representation and the efficient technique for background modeling. We propose in this paper a non-parametric algorithm dedicated to segment and to detect objects in color images issued from a football sports meeting. Indeed segmentation by pixel concern many applications and revealed how the method is robust to detect objects, even in presence of strong shadows and highlights. In the other hand to refine their playing strategy such as in football, handball, volley ball, Rugby..., the coach need to have a maximum of technical-tactics information about the on-going of the game and the players. We propose in this paper a range of algorithms allowing the resolution of many problems appearing in the automated process of team identification, where each player is affected to his corresponding team relying on visual data. The developed system was tested on a match of the Tunisian national competition. This work is prominent for many next computer vision studies as it’s detailed in this study. Keywords-component; Soccer Singular value decomposition; Classification; artificial intelligence; supervised algorithm; Moments Matri",
    "creator" : "PScript5.dll Version 5.2.2"
  }
}