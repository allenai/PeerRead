{
  "name" : "1701.08868.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Interaction Information for Causal Inference: The Case of Directed Triangle",
    "authors" : [ "AmirEmad Ghassami", "Negar Kiyavash" ],
    "emails" : [ "ghassam2@illinois.edu", "kiyavash@illinois.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Index Terms—Mutual information generalization, Interaction information, Causal inference\nI. INTRODUCTION\nMutual information is one of the fundamental informationtheoretic quantities which measures the co-dependence between two random variables. Mutual information could be generalized to the multivariate case in different ways. The most well known generalizations are total correlation [1] (also known as multi-information [2]), and interaction information [3], [4]. In this work, we focus on interaction information, another information theoretic quantity intimately related to mutual information. This quantity has been studied from different view points and under different names in the literature [3]–[7]. In the case of three random variables, interaction information is the gain (or loss) in information transmitted between any two of the variables, due to additional knowledge of the third random variable [3]. That is, interaction information is the difference between the conditional and unconditional mutual information between two of the variables, where the conditioning is on the third variable. It is important to note that unlike (conditional) mutual information which is always non-negative, interaction information can be negative. In fact, this is the property we take advantage of in this study. We will show that the sign of interaction information may be used to identify the direction of influence among variables, a fundamental problem of interest in causal inference. Other information-theoretic quantities such as entropy and directed information have also been proposed to infer causality in appropriate settings [8]–[12].\nLearning causal relations among variables is a canonical problem in several fields of science such as economics, biology, computer science, etc. In an observational setup, where\nperforming interventions is not possible, the main approach to identify direction of influences is to perform some sort of statistical dependency tests on data [13]. The triangle structure comprised of three variables on a cycle of length three is one of the most problematic structures. This is because of the fact that dependency tests, which are typically performed to find the directions, all fail in this setting. In Pearl’s language [13], this is because all triangles are in the same Markov equivalent class. We will show that under certain conditions, using the sign of interaction information, we can uniquely identify the underlying causal influences in a triangle structure.\nThe rest of the paper is organized as follows: In Section II we provide the formal definition of interaction information, as well as some of its properties. In Section III, after introducing the problem of our interest, a discussion regarding the sign of interaction information is provided. In the same section we outline our approach for identifying causal relationships among three variable structures, which could not be identified using merely conventional dependency tests. Our concluding remarks are stated in Section IV.\nII. INTERACTION INFORMATION\nThe general formula for interaction information for a set of variables V is defined as [6]\nI(V ) := ∑ U⊆V (−1)|U |+1H(U),\nwhere |U | denotes the cardinality of the subset U and H(·) is Shannon’s entropy function (note that H(∅) = 0). Intuitively, interaction information is the amount of information shared by all the variables together.\nFor the case of three variables, X , Y and Z:\nI(X;Y ;Z) = + [H(X) +H(Y ) +H(Z)]\n− [H(X,Y ) +H(X,Z) +H(Y, Z)] +H(X,Y, Z).\nHere, interaction information could be represented in terms of mutual information as follows [3]:\nar X\niv :1\n70 1.\n08 86\n8v 1\n[ cs\n.A I]\n3 0\nJa n\n20 17\nProposition 1. For the case of three variables, the interaction information could be written as\nI(X;Y ;Z) = I(X;Y )− I(X;Y |Z) = I(X;Z)− I(X;Z|Y ) = I(Y ;Z)− I(Y ;Z|X).\nUsing this formulation, one can see that in the case of three variables, interaction information quantifies how much the information shared between two variables defers from what they share if the third variable was known. Figure 1 depicts a graphical representation of the information-theoretic quantities of our interest.\nSeveral properties of interaction information in the case of three variables has been studied in the literature. Specifically, Yeung [5] showed that\n−min{I(X;Y |Z), I(X;Z|Y ), I(Y ;Z|X)} ≤ I(X;Y ;Z) ≤ min{I(X;Y ), I(X;Z), I(Y ;Z)}.\nWe refer readers to [14], where Tsujishita has provided a more in depth mathematical study of the bounds on interaction information as well as some other properties for this quantity.\nWe present another property of the interaction information in the following Lemma, which could be proven using the chain rule for mutual information.\nLemma 1. For the case of three variables, the interaction information could be written as\nI(X;Y ;Z) = I(X,Y ;Z)− I(X;Z|Y )− I(Y ;Z|X) = I(X,Z;Y )− I(X;Y |Z)− I(Z;Y |X) = I(Y,Z;X)− I(Y ;X|Z)− I(Z;X|Y ).\nLemma 1 may be interpreted as follows. Interaction information is the amount of information variables X and Y share with Z, minus the information that is shared between X and Z alone and the information shared between Y and Z alone. We will revisit this property in Section III."
    }, {
      "heading" : "III. APPLICATION TO CAUSAL INFERENCE",
      "text" : "A. preliminaries\nIn this subsection we introduce some definitions and concepts that we require later. Most of the definitions are adopted from [15].\nDefinition 1. a directed acyclic graph (DAG) is a finite directed graph with no directed cycles.\nDefinition 2. A Bayesian network structure G is a DAG whose nodes represent random variables X1, ..., Xn. Let PAXi denote the parents of Xi in G, and NDXi denote the variables in the graph that are not descendants of Xi. Then G encodes the following set of conditional independence assumptions:\nFor each variable Xi : (Xi ⊥ NDXi |PAXi).\nBayesian networks are commonly used to represent causal relationships among the set of variables [13], [16]. In such a representation, a directed edge from variable X to variable Y indicates that variable X is a direct cause of variable Y . Therefore, a DAG summarizes the causal relationships among the variables.\nDefinition 3. The skeleton of a Bayesian network graph G over the set of variables V is an undirected graph over V that contains an edge xy for every directed edge → xy in G.\nWe will focus on two skeletons in this work: P2 and triangle, which are paths of length two and cycles of length 3, both on three variables, respectively.\nDefinition 4. A distribution P is faithful to G if G represents all the independency relations contained in P .\nThroughout the rest of the paper, we assume the faithfulness assumption on the probability distribution.\nDefinition 5. Two graph structures G1 and G2 over V are Markov equivalent if every probability distribution that is compatible with one of the graphs is also compatible with the other. The set of all graphs over V is partitioned into a set of mutually exclusive and exhaustive Markov equivalence classes, which are the set of equivalence classes induced by the Markov equivalence relation.\nIn Subsection III-C, we need to be able to quantify the strength of a causal effect, which is an important topic of research on its own in the field of causal inference. For this purpose, we use the results from [17].\nLet G be a DAG on a set of variables V = {X1, X2, ..., Xn}. Following [17], we define the strength of the causal influence of a set of arrows S as\nCS := D(P‖PS),\nwhere, D(·‖·) denotes the Kullback-Leibler divergence, P is the joint distribution, and PS is the interventional distribution defined as follows. Set PASj as the set of those parents Xi\nof Xj for which (i, j) ∈ S and PASj as those for which (i, j) /∈ S. Set\nPS(xj |paSj ) = ∑ paSj P (xj |paSj , paSj )PΠ(paSj ),\nwhere PΠ(paSj ) for a given j denotes the product of marginal distributions of all variables in PASj . The interventional distribution is hence defined as\nPS(x1, ..., xn) := ∏ j PS(xj |paSj ).\nAs an example, in the first DAG in Figure 4, we have CX→Y = ∑ x,y,z P (x, y, z) log P (y|z, x)∑ x′ P (y|z, x′)P (x′) ."
    }, {
      "heading" : "B. P2 DAG",
      "text" : "There are 4 possible DAGs on the P2 skeleton for any ordered set of 3 variables (X,Y, Z), where in the skeleton, Y is connected to X and Z (see Figure 2). The structures in parts (a) and (b) are called a chain, (c) is called a fork, and (d) is called a v-structure. In a v-structure, the middle variable is called a collider.\nIt is known that in the observational setup, we can identify a DAG at most up to its Markov equivalent class [13]. Having the information about the skeleton of the DAG (which could be obtained from the correlations), using only dependency tests one can distinguish a v-structure from other three: If variables X and Z are dependent given Y , but independent when Y is not observed the true structure is a v-structure; otherwise, it will be one of the other three. Therefore, for the skeleton P2, the chain structure and the fork structure are in one Markov equivalence class, while the v-structure is in a different class.\nIn the following, we show that determining the correct Markov equivalent class in Figure 2, could also be performed by calculating the sign of the interaction information, which could be useful from algorithm design point of view. In general, as evident from Proposition 1, positive interaction information indicates that each one of the variables partially or completely constitutes the dependency between the other two variables. In Figure 2 parts (a) to (c), given Y , variables X and Z are independent. Hence we have\nI(X;Z) ≥ 0 and I(X;Z|Y ) = 0,\nwhich implies that I(X;Y ;Z) ≥ 0. On the other hand, negative interaction information indicates that observation of each one of the variables increases the correlation between the other two. In the v-structure (Figure 2 part (d)), variables X and Z are independent, but can be dependent conditioned on Y . Hence we have\nI(X;Z) = 0 and I(X;Z|Y ) ≥ 0,\nwhich implies that I(X;Y ;Z) ≤ 0. Therefore, knowing that the interaction information is positive or negative we can distinguish between the two Markov equivalent classes.\nNote that again in light of Proposition 1, in the v-structure in Figure 2(d), when X and Z are the common causes of a third variable Y , knowing X can increase the correlation between Z and Y , a result which may not be intuitive in the first glance.\nWe use an example from [15] to illustrate the case of negative interaction information. Suppose an exam is given to a student. The difficulty of the exam and the intelligence of the student are two independent variables. But, when the student’s grade is observed, this new variable correlates the difficulty of the exam and the student’s intelligence (see Figure 3). Consider the expression for interaction information represented in Lemma 1, with X =Difficulty, Y =Intelligence, and Z =Grade. From Proposition 1, since I(X;Y ) = 0, it is easy to see that the interaction information is negative. Therefore, the correlation between Difficulty and Grade when Intelligence is observed, and the correlation between Intelligence and Grade when Difficulty is observed are both high and their sum, over calculates the correlation between the pair (Difficulty, Intelligence) and Grade.\nC. Triangle DAG\nUnlike the structure in Figure 2, the triangle DAGs, which are DAGs on three variables whose skeleton is a cycle of length 3, are all in the same Markov equivalent class. Therefore, the dependency tests cannot distinguish between graphs with this structure. Nevertheless, triangle DAGs appear in many real-life problems and the ability to reconstruct this structure is of great interest in many fields. Figure 4 shows all the 6 possible triangle DAGs on the set of variables {X,Y, Z}. Note that the edge directions must not form a cycle, otherwise the structure will not be a DAG.\nIn this subsection we will show that under certain conditions, one can still categorize, or in some cases, even uniquely identify a triangle DAG using interaction information. We first observe the following property regarding the triangle DAGs:\nLemma 2. Any triangle DAG contains • Root Variable: Denoted by R, the variable which is the\ncause of the other two variables. • Sink Variable: Denoted by S, the variable which is the\neffect of the other two variables. • Bridge Variable: Denoted by B, the variable which is\nthe effect of the root variable and the cause of the sink variables.\nProof: Consider fixed labeling on the vertices. Since the graph is acyclic, either two of the arrows are oriented clockwise and the third one is oriented counter clockwise, or vice versa. In either case, two consecutive arrows will have the same direction. The vertex at the tail of the first arrow will be the root variable, the vertex at the head of the first arrow will be the bridge variable, and the vertex at the head of the second arrow will be the sink variable.\nOur extra requirement for distinguishing triangle DAGs is for the causal influence with the least strength to be weak. Weak here means the causal strength is less than the absolute value of the interaction information among the three variables. Denoting the strength of a causal influence by C, we require that Cmin < |I(R;B;S)|. Here, as mentioned in Subsection III-A, we need to be able to quantify the strength of a causal effect, for which we use the results from [17], which was described in Subsection III-A. The postulated quantity in [17] for causal influence strength implies that\nCR→B = I(R;B) CR→S ≥ I(R;S|B) CB→S ≥ I(B;S|R)\n(1)\nTheorem 1. If in a triangle DAG the interaction information among the variables is negative, and Cmin < |I(R;B;S)|, then only the causal influence between the Root variable and the Bridge variable is weak.\nProof: From (1), and Proposition 1, we have\nCR→B = I(R;B) < I(R;B|S) I(R;S) < I(R;S|B) ≤ CR→S I(B;S) < I(B;S|R) ≤ CB→S .\nTherefore by non-negativity of the mutual information, we have\nCR→S ≥ |I(R;B;S)|\nand CB→S ≥ |I(R;B;S)|.\nTherefore, since Cmin < |I(R;B;S)|, we must have\nCR→B < |I(R;B;S)|.\nTheorem 1 can be utilized in application using the following corollary:\nCorollary 1. If in a triangle DAG on variables X , Y and Z the interaction information among the variables is negative, and the causal influence between variables X and Z is weak, then\n1) the other two causal influences are not weak, 2) and the only possible triangle DAGs on {X,Y, Z} are\nthe ones depicted in Figure 5.\nIn some applications, due to prior knowledge about the system or temporal knowledge, the root variable is known. For instance, there is an attribute that the experimenter is randomizing as the root variable in a triangle structure; or by observing sample paths similar to the one shown in Figure 6 on a triangle structure, due to temporal information, the root variable could be recognized. That is, the experimenter observes that changing in the value of variable X causes variation in the value of variables Y and Z from the delay, while changing in the values of variables Y and Z do not vary the value of X .\nIn this case, the following corollary of Theorem 1 can be used to uniquely identify the true underlying causal DAG.\nCorollary 2. If in a triangle DAG on variables {X,Y, Z}, the interaction information among the variables is negative, and the causal influence between variables X and Z is weak and X is the root variable, then Z is the bridge variable and Y is the sink variable, and the only correct causal network among the variables is the DAG on the left side in Figure 5.\nAn example of the application of Corollary 2, would be in a medical examination, in which the clinician is aware of two side-effects of the medicine which is being tested, say, headache and insomnia, but the side effects themselves have influence on each other, and the direction of this influence is of interest."
    }, {
      "heading" : "IV. CONCLUSION",
      "text" : "We studied interaction information, which is a multivariate generalization of mutual information and indicates the amount of information shared in a set of variables, beyond the information which is shared in any proper subset of those variables. Unlike other conventional measures of information, interaction information can have a negative value. We used this property to discover causal relationships among a triplet of random variables. We provided a discussion regarding the sign of interaction information and proposed a strategy for classifying causal relationships, which could have not been identified using merely conventional dependency tests. Interaction information is not as thoroughly studied as its bivariate counterpart. A more comprehensive study of the advantages of this quantity in the field of causal inference, especially in the case of having more than three variables is\nconsidered as our future work."
    } ],
    "references" : [ {
      "title" : "Information theoretical analysis of multivariate correlation,",
      "author" : [ "S. Watanabe" ],
      "venue" : "IBM Journal of research and development,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1960
    }, {
      "title" : "Multivariate information transmission,",
      "author" : [ "W.J. McGill" ],
      "venue" : "Psychometrika, vol. 19,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1954
    }, {
      "title" : "The Transmission of Information: A Statistical Theory of Communication",
      "author" : [ "R.M. Fano" ],
      "venue" : "MIT Press, Cambridge, Massachussets",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1961
    }, {
      "title" : "A new outlook on shannon’s information measures,",
      "author" : [ "R.W. Yeung" ],
      "venue" : "IEEE transactions on information theory,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1991
    }, {
      "title" : "The co-information lattice,",
      "author" : [ "A.J. Bell" ],
      "venue" : "Proceedings of the Fifth International Workshop on Independent Component Analysis and Blind Signal Separation: ICA,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2003
    }, {
      "title" : "Quantifying and visualizing attribute interactions,",
      "author" : [ "A. Jakulin", "I. Bratko" ],
      "venue" : "arXiv preprint cs/0308002,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2003
    }, {
      "title" : "and T",
      "author" : [ "C.J. Quinn", "N. Kiyavash" ],
      "venue" : "P. Coleman, “Efficient methods to compute optimal tree approximations of directed information graphs,” IEEE Transactions on Signal Processing, vol. 61, no. 12, pp. 3173–3182",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "and K",
      "author" : [ "J. Etesami", "N. Kiyavash", "K. Zhang" ],
      "venue" : "Singhal, “Learning network of multivariate hawkes processes: A time series approach,” arXiv preprint arXiv:1603.04319",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "and T",
      "author" : [ "C.J. Quinn", "N. Kiyavash" ],
      "venue" : "P. Coleman, “Equivalence between minimal generative model graphs and directed information graphs,” in Information Theory Proceedings (ISIT), 2011 IEEE International Symposium on, pp. 293–297, IEEE",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "and B",
      "author" : [ "M. Kocaoglu", "A.G. Dimakis", "S. Vishwanath" ],
      "venue" : "Hassibi, “Entropic causal inference,” arXiv preprint arXiv:1611.04035",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "and T",
      "author" : [ "J. Etesami", "N. Kiyavash" ],
      "venue" : "Coleman, “Learning minimal latent directed information polytrees,” Neural Computation",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Causality",
      "author" : [ "J. Pearl" ],
      "venue" : "Cambridge university press",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "On triple mutual information,",
      "author" : [ "T. Tsujishita" ],
      "venue" : "Advances in applied mathematics,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1995
    }, {
      "title" : "Probabilistic graphical models: principles and techniques",
      "author" : [ "D. Koller", "N. Friedman" ],
      "venue" : "MIT press",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Causation",
      "author" : [ "P. Spirtes", "C.N. Glymour", "R. Scheines" ],
      "venue" : "prediction, and search. MIT press",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "B",
      "author" : [ "D. Janzing", "D. Balduzzi", "M. Grosse-Wentrup" ],
      "venue" : "Schölkopf, et al., “Quantifying causal influences,” The Annals of Statistics, vol. 41, no. 5, pp. 2324–2358",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "The most well known generalizations are total correlation [1] (also known as multi-information [2]), and interaction information [3], [4].",
      "startOffset" : 58,
      "endOffset" : 61
    }, {
      "referenceID" : 1,
      "context" : "The most well known generalizations are total correlation [1] (also known as multi-information [2]), and interaction information [3], [4].",
      "startOffset" : 129,
      "endOffset" : 132
    }, {
      "referenceID" : 2,
      "context" : "The most well known generalizations are total correlation [1] (also known as multi-information [2]), and interaction information [3], [4].",
      "startOffset" : 134,
      "endOffset" : 137
    }, {
      "referenceID" : 1,
      "context" : "This quantity has been studied from different view points and under different names in the literature [3]–[7].",
      "startOffset" : 102,
      "endOffset" : 105
    }, {
      "referenceID" : 5,
      "context" : "This quantity has been studied from different view points and under different names in the literature [3]–[7].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 1,
      "context" : "In the case of three random variables, interaction information is the gain (or loss) in information transmitted between any two of the variables, due to additional knowledge of the third random variable [3].",
      "startOffset" : 203,
      "endOffset" : 206
    }, {
      "referenceID" : 6,
      "context" : "Other information-theoretic quantities such as entropy and directed information have also been proposed to infer causality in appropriate settings [8]–[12].",
      "startOffset" : 147,
      "endOffset" : 150
    }, {
      "referenceID" : 10,
      "context" : "Other information-theoretic quantities such as entropy and directed information have also been proposed to infer causality in appropriate settings [8]–[12].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 11,
      "context" : "In an observational setup, where performing interventions is not possible, the main approach to identify direction of influences is to perform some sort of statistical dependency tests on data [13].",
      "startOffset" : 193,
      "endOffset" : 197
    }, {
      "referenceID" : 11,
      "context" : "In Pearl’s language [13], this is because all triangles are in the same Markov equivalent class.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 4,
      "context" : "The general formula for interaction information for a set of variables V is defined as [6]",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 1,
      "context" : "Here, interaction information could be represented in terms of mutual information as follows [3]: ar X iv :1 70 1.",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 3,
      "context" : "Specifically, Yeung [5] showed that",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 12,
      "context" : "We refer readers to [14], where Tsujishita has provided a more in depth mathematical study of the bounds on interaction information as well as some other properties for this quantity.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 13,
      "context" : "Most of the definitions are adopted from [15].",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 11,
      "context" : "Bayesian networks are commonly used to represent causal relationships among the set of variables [13], [16].",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 14,
      "context" : "Bayesian networks are commonly used to represent causal relationships among the set of variables [13], [16].",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 15,
      "context" : "For this purpose, we use the results from [17].",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 15,
      "context" : "Following [17], we define the strength of the causal influence of a set of arrows S as",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 11,
      "context" : "It is known that in the observational setup, we can identify a DAG at most up to its Markov equivalent class [13].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 13,
      "context" : "We use an example from [15] to illustrate the case of negative interaction information.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 15,
      "context" : "Here, as mentioned in Subsection III-A, we need to be able to quantify the strength of a causal effect, for which we use the results from [17], which was described in Subsection III-A.",
      "startOffset" : 138,
      "endOffset" : 142
    }, {
      "referenceID" : 15,
      "context" : "The postulated quantity in [17] for causal influence strength implies that",
      "startOffset" : 27,
      "endOffset" : 31
    } ],
    "year" : 2017,
    "abstractText" : "To be considered for the 2017 IEEE Jack Keil Wolf ISIT Student Paper Award. Interaction information is one of the multivariate generalizations of mutual information, which expresses the amount information shared among a set of variables, beyond the information, which is shared in any proper subset of those variables. Unlike (conditional) mutual information, which is always non-negative, interaction information can be negative. We utilize this property to find the direction of causal influences among variables in a triangle topology under some mild assumptions.",
    "creator" : "LaTeX with hyperref package"
  }
}