{
  "name" : "1603.09381.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "jerryli1981@gmail.com", "heng@uta.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 3.\n09 38\n1v 1\n[ cs\n.L G\n] 3\n0 M\nar 2\n01 6"
    }, {
      "heading" : "1 Introduction",
      "text" : "In the past few years, there has been much interest in applying neural network based deep learning techniques to solve all kinds of natural language processing (NLP) tasks. From low level tasks such as language modeling, POS tagging, named entity recognition, and semantic role labeling (Collobert et al., 2011; Mikolov et al., 2013), to high level tasks such as machine translation, information retrieval, semantic analysis (Kalchbrenner and Blunsom, 2013; Socher et al., 2011a; Tai et al., 2015) and sentence relation modeling tasks such as paraphrase identification and question answering (Socher et al., 2011b; Iyyer et al., 2014; Yin and Schutze, 2015). Deep representation learning has demonstrated its importance for these tasks. All the tasks get performance improvement via learning either word level representations or sentence level representations.\nIn this work, we brought deep representation learning technologies to the clinical domain. Specifically, we focus on clinical information extraction, using clinical notes and pathology reports\nfrom the Mayo Clinic. Our system will identify event expressions consisting of the following components:\n• The spans (character offsets) of the expression in the raw text\n• Contextual Modality: ACTUAL, HYPOTHETICAL, HEDGED or GENERIC\n• Degree: MOST, LITTLE or N/A\n• Polarity: POS or NEG\n• Type: ASPECTUAL, EVIDENTIAL or N/A\nThe input of our system consists of raw clinical notes or pathology reports like below:\nApril 23, 2014: The patient did not have any postoperative bleeding so we will resume chemotherapy with a larger bolus on Friday even if there is slight nausea.\nAnd output annotations over the text that capture the key information such as event mentions and attributes. Table 1 illustrates the output of clinical information extraction in details.\nTo solve this task, the major challenge is how to precisely identify the spans (character offsets) of the event expressions from raw clinical notes. Traditional machine learning approaches usually build a supervised classifier with features generated by the Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) 1. For example, BluLab system (Velupillai et al., 2015) extracted morphological(lemma), lexical(token), and syntactic(part-of-speech) features encoded from cTAKES. Although using the domain specific information extraction tools can improve the performance, learning how to use it well for\n1Apache cTAKES is a natural language processing system for extraction of information from electronic medical record clinical free-text\nclinical domain feature engineering is still very time-consuming. In short, a simple and effective method that only leverage basic NLP modules and achieves high extraction performance is desired to save costs.\nTo address this challenge, we propose a deep neural networks based method, especially convolution neural network (Collobert et al., 2011), to learn hidden feature representations directly from raw clinical notes. More specifically, one method first extract a window of surrounding words for the candidate word. Then, we attach each word with their part-of-speech tag and shape information as extra features. Then our system deploys a temporal convolution neural network to learn hidden feature representations. Finally, our system uses Multilayer Perceptron (MLP) to predict event spans. Note that we use the same model to predict event attributes."
    }, {
      "heading" : "2 Constructing High Quality Training Dataset",
      "text" : "The major advantage of our system is that we only leverage NLTK 2 tokenization and a POS tagger to preprocess our training dataset. When implementing our neural network based clinical information extraction system, we found it is not easy to construct high quality training data due to the noisy format of clinical notes. Choosing the proper tokenizer is quite important for span identification. After several experiments, we found ”RegexpTokenizer” can match our needs. This tokenizer can generate spans for each token via sophisticated regular expression like below,\nn l t k . t o k e n i z e . RegexpT oken ize r\n2http://www.nltk.org\n( ”\\w+ |\\ $ [\\ d \\ . ] + | \\ S+” )\nWe then use ”PerceptronTagger” as our part-ofspeech tagger due to its fast tagging speed. Note that when extracting context words, please make sure you deploy the same tokenization module instead of just splitting strings by space."
    }, {
      "heading" : "3 Neural Network Classifier",
      "text" : "Event span identification is the task of extracting character offsets of the expression in raw clinical notes. This subtask is quite important due to the fact that the event span identification accuracy will affect the accuracy of attribute identification. We first run our neural network classifier to identify event spans. Then, given each span, our system tries to identify attribute values."
    }, {
      "heading" : "3.1 Temporal Convolutional Neural Network",
      "text" : "The way we use temporal convlution neural network for event span and attribute classification is similar with the approach proposed by (Collobert et al., 2011). Generally speaking, we can consider a word as represented by K discrete features w ∈ D1 × · · · ×DK , where DK is the dictionary for the kth feature. In our scenario, we just use three features such as token mention, pos tag and word shape. Note that word shape features are used to represent the abstract letter pattern of the word by mapping lower-case letters to “x”, upper-case to “X”, numbers to “d”, and retaining punctuation. We associate to each feature a lookup table. Given a word, a feature vector is then obtained by concatenating all lookup table outputs. Then a clinical snippet is transformed into a word embedding matrix. The matrix can be fed to further 1-dimension convolutional neural network\nand max pooling layers. Below we will briefly introduce core concepts of Convoluational Neural Network (CNN).\nTemporal Convolution\nTemporal Convolution applies one-dimensional convolution over the input sequence. The onedimensional convolution is an operation between a vector of weights m ∈ Rm and a vector of inputs viewed as a sequence x ∈ Rn. The vector m is the filter of the convolution. Concretely, we think of x as the input sentence and xi ∈ R as a single feature value associated with the i-th word in the sentence. The idea behind the one-dimensional convolution is to take the dot product of the vector m with each m-gram in the sentence x to obtain another sequence c:\ncj = m T xj−m+1:j . (1)\nUsually, xi is not a single value, but a ddimensional word vector so that x ∈ Rd×n. There exist two types of 1d convolution operations. One was introduced by (Waibel et al., 1989) and also known as Time Delay Neural Networks (TDNNs). The other one was introduced by (Collobert et al., 2011). In TDNN, weights m ∈ Rd×m form a matrix. Each row of m is convolved with the corresponding row of x. In (Collobert et al., 2011) architecture, a sequence of length n is represented as:\nx1:n = x1 ⊕ x2 · · · ⊕ xn , (2)\nwhere ⊕ is the concatenation operation. In general, let xi:i+j refer to the concatenation of words xi,xi+1, . . . ,xi+j . A convolution operation involves a filter w ∈ Rhk, which is applied to a window of h words to produce the new feature. For example, a feature ci is generated from a window of words xi:i+h−1 by:\nci = f(w · xi:i+h−1 + b) , (3)\nwhere b ∈ R is a bias term and f is a non-linear function such as the hyperbolic tangent. This filter is applied to each possible window of words in the sequence {x1:h,x2:h+1, . . . ,xn−h+1:n} to produce the feature map:\nc = [c1, c2, . . . , cn−h+1] , (4)\nwhere c ∈ Rn−h+1.\nWe also employ dropout on the penultimate layer with a constraint on ℓ2-norms of the weight vector. Dropout prevents co-adaptation of hidden units by randomly dropping out a proportion p of the hidden units during forwardbackpropagation. That is, given the penultimate layer z = [ĉ1, . . . , ĉm], instead of using:\ny = w · z+ b (5)\nfor output unit y in forward propagation, dropout uses:\ny = w · (z ◦ r) + b , (6)\nwhere ◦ is the element-wise multiplication operator and r ∈ Rm is a masking vector of Bernoulli random variables with probability p of being 1. Gradients are backpropagated only through the unmasked units. At test step, the learned weight vectors are scaled by p such that ŵ = pw, and ŵ is used to score unseen sentences. We additionally constrain l2-norms of the weight vectors by rescaling w to have ||w||2 = s whenever ||w||2 > s after a gradient descent step."
    }, {
      "heading" : "4 Experimental Results",
      "text" : ""
    }, {
      "heading" : "4.1 Dataset",
      "text" : "We use the Clinical TempEval corpus 3 as the evaluation dataset. This corpus was based on a set of 600 clinical notes and pathology reports from cancer patients at the Mayo Clinic. These notes were manually de-identified by the Mayo Clinic to replace names, locations, etc. with generic placeholders, but time expression were not altered. The notes were then manually annotated with times, events and temporal relations in clinical notes. These annotations include time expression types, event attributes and an increased focus on temporal relations. The event, time and temporal relation annotations were distributed separately from the text using the Anafora standoff format. Table 2 shows the number of documents, event expressions in the training, development and testing portions of the 2016 THYME data."
    }, {
      "heading" : "4.2 Evaluation Metrics",
      "text" : "All of the tasks were evaluated using the standard metrics of precision(P), recall(R) and F1:\n3http://alt.qcri.org/semeval2016/task12/index.php?id=data\nP = |S ∩H|\n|S|\nR = |S ∩H|\n|H|\nF1 = 2 · P ·R\nP +R\n(7)\nwhere S is the set of items predicted by the system and H is the set of items manually annotated by the humans. Applying these metrics of the tasks only requires a definition of what is considered an ”item” for each task. For evaluating the spans of event expressions, items were tuples of character offsets. Thus, system only received credit for identifying events with exactly the same character offsets as the manually annotated ones. For evaluating the attributes of event expression types, items were tuples of (begin, end, value) where begin and end are character offsets and value is the value that was given to the relevant attribute. Thus, systems only received credit for an event attribute if they both found an event with correct character offsets and then assigned the correct value for that attribute (Bethard et al., 2015)."
    }, {
      "heading" : "4.3 Hyperparameters and Training Details",
      "text" : "Objective Function\nWe want to maximize the likelihood of the correct class. This is equivalent to minimizing the negative log-likelihood (NLL). More specifically, the label ŷ given the inputs xh is predicted by a softmax classifier that takes the hidden state hj as input:\np̂θ(y|xh) = softmax(W · xh + b)\nŷ = argmax y\np̂θ(y|xh) (8)\nAfter that, the objective function is the negative log-likelihood of the true class labels yk:\nJ(θ) = − 1\nm\nm∑\nk=1\nlog p̂θ(y k|xkh) +\nλ 2 ||θ||22 , (9)\nwhere m is the number of training examples and the superscript k indicates the kth example.\nHyperparameters We use Lasagne 4 deep learning framework. We first initialize our word representations using publicly available 300-dimensional Glove word vectors 5. We deploy CNN model with kernel width of 2, a filter size of 300, sequence length is 2 ∗ windows size+1, number filters is seqlen−kw+ 1, stride is 1, pool size is seqlen−filter size+1, cnn activation function is tangent, MLP activation function is sigmoid. MLP hidden dimension is 50. We initialize CNN weights using a uniform distribution. Finally, by stacking a softmax function on top, we can get normalized log-probabilities. Training is done through stochastic gradient descent over shuffled mini-batches with the AdaGrad update rule (Duchi et al., 2011). The learning rate is set to 0.05. The mini-batch size is 100. The model parameters were regularized with a perminibatch L2 regularization strength of 10−4."
    }, {
      "heading" : "4.4 Results and Discussions",
      "text" : "Table 3 shows results on the event expression tasks. Our initial submits RUN 4 and 5 outperformed the memorization baseline on every metric on every task. The precision of event span identification is close to the max report. However, our system got lower recall. One of the main reason is that our training objective function is accuracyoriented. Table 4 shows results on the phase 2 subtask."
    }, {
      "heading" : "5 Conclusions",
      "text" : "In this paper, we introduced a new clinical information extraction system that only leverage deep neural networks to identify event spans and their attributes from raw clinical notes. We trained deep neural networks based classifiers to extract clinical event spans. Our method attached each word\n4https://github.com/Lasagne/Lasagne 5http://nlp.stanford.edu/projects/glove/\nto their part-of-speech tag and shape information as extra features. We then hire temporal convolution neural network to learn hidden feature representations. The entire experimental results demonstrate that our approach consistently outperforms the existing baseline methods on standard evaluation datasets.\nOur research proved that we can get competitive results without the help of a domain specific feature extraction toolkit, such as cTAKES. Also we only leverage basic natural language processing modules such as tokenization and part-ofspeech tagging. With the help of deep representation learning, we can dramatically reduce the cost of clinical information extraction system development."
    } ],
    "references" : [ {
      "title" : "Semeval-2015 task 6: Clinical tempeval",
      "author" : [ "Leon Derczynski", "Guergana Savova", "James Pustejovsky", "Marc Verhagen" ],
      "venue" : "In International Workshop on Semantic Evaluation",
      "citeRegEx" : "Bethard et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Bethard et al\\.",
      "year" : 2015
    }, {
      "title" : "Natural language processing (almost) from scratch",
      "author" : [ "Jason Weston", "Léon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Collobert et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Collobert et al\\.",
      "year" : 2011
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "Duchi et al.2011] John Duchi", "Elad Hazan", "Yoram Singer" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Duchi et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Duchi et al\\.",
      "year" : 2011
    }, {
      "title" : "A neural network for factoid question answering over paragraphs",
      "author" : [ "Iyyer et al.2014] Mohit Iyyer", "Jordan Boyd-Graber", "Leonardo Claudino", "Richard Socher", "Hal Daumé III" ],
      "venue" : "In Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Iyyer et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Iyyer et al\\.",
      "year" : 2014
    }, {
      "title" : "Recurrent continuous translation models",
      "author" : [ "Kalchbrenner", "Blunsom2013] Nal Kalchbrenner", "Phil Blunsom" ],
      "venue" : "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Kalchbrenner et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Kalchbrenner et al\\.",
      "year" : 2013
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Mikolov et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Dynamic pooling and unfolding recursive autoencoders for paraphrase detection",
      "author" : [ "Eric H Huang", "Jeffrey Pennin", "Christopher D Manning", "Andrew Y Ng" ],
      "venue" : "In Advances in Neural Information Processing Sys-",
      "citeRegEx" : "Socher et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2011
    }, {
      "title" : "Semi-supervised recursive autoencoders for predicting sentiment distributions",
      "author" : [ "Jeffrey Pennington", "Eric H Huang", "Andrew Y Ng", "Christopher D Manning" ],
      "venue" : "In Proceedings of the Conference on Empiri-",
      "citeRegEx" : "Socher et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2011
    }, {
      "title" : "Improved semantic representations from tree-structured long short-term memory networks. arXiv preprint arXiv:1503.00075",
      "author" : [ "Tai et al.2015] Kai Sheng Tai", "Richard Socher", "Christopher D Manning" ],
      "venue" : null,
      "citeRegEx" : "Tai et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Tai et al\\.",
      "year" : 2015
    }, {
      "title" : "Blulab: Temporal information extraction for the 2015 clinical tempeval challenge",
      "author" : [ "Danielle L Mowery", "Samir Abdelrahman", "Lee Christensen", "Wendy W Chapman" ],
      "venue" : "In International Workshop on Semantic",
      "citeRegEx" : "Velupillai et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Velupillai et al\\.",
      "year" : 2015
    }, {
      "title" : "Phoneme recognition using time-delay",
      "author" : [ "Toshiyuki Hanazawa", "Geoffrey Hinton", "Kiyohiro Shikano", "Kevin J Lang" ],
      "venue" : null,
      "citeRegEx" : "Waibel et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Waibel et al\\.",
      "year" : 1989
    }, {
      "title" : "Multigrancnn: An architecture for general matching of text chunks on multiple levels of granularity",
      "author" : [ "Yin", "Schutze2015] Wenpeng Yin", "Hinrich Schutze" ],
      "venue" : "In Proceedings of th 53rd Annual Meeting of the Association",
      "citeRegEx" : "Yin et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Yin et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "From low level tasks such as language modeling, POS tagging, named entity recognition, and semantic role labeling (Collobert et al., 2011; Mikolov et al., 2013), to high level tasks such as machine translation, information retrieval, semantic analysis (Kalchbrenner and Blunsom, 2013; Socher et al.",
      "startOffset" : 114,
      "endOffset" : 160
    }, {
      "referenceID" : 5,
      "context" : "From low level tasks such as language modeling, POS tagging, named entity recognition, and semantic role labeling (Collobert et al., 2011; Mikolov et al., 2013), to high level tasks such as machine translation, information retrieval, semantic analysis (Kalchbrenner and Blunsom, 2013; Socher et al.",
      "startOffset" : 114,
      "endOffset" : 160
    }, {
      "referenceID" : 8,
      "context" : ", 2013), to high level tasks such as machine translation, information retrieval, semantic analysis (Kalchbrenner and Blunsom, 2013; Socher et al., 2011a; Tai et al., 2015) and sentence relation modeling tasks such as paraphrase identification and question answering (Socher et al.",
      "startOffset" : 99,
      "endOffset" : 171
    }, {
      "referenceID" : 3,
      "context" : ", 2015) and sentence relation modeling tasks such as paraphrase identification and question answering (Socher et al., 2011b; Iyyer et al., 2014; Yin and Schutze, 2015).",
      "startOffset" : 102,
      "endOffset" : 167
    }, {
      "referenceID" : 9,
      "context" : "For example, BluLab system (Velupillai et al., 2015) extracted morphological(lemma), lexical(token), and syntactic(part-of-speech) features encoded from cTAKES.",
      "startOffset" : 27,
      "endOffset" : 52
    }, {
      "referenceID" : 1,
      "context" : "To address this challenge, we propose a deep neural networks based method, especially convolution neural network (Collobert et al., 2011), to learn hidden feature representations directly from raw clinical notes.",
      "startOffset" : 113,
      "endOffset" : 137
    }, {
      "referenceID" : 1,
      "context" : "The way we use temporal convlution neural network for event span and attribute classification is similar with the approach proposed by (Collobert et al., 2011).",
      "startOffset" : 135,
      "endOffset" : 159
    }, {
      "referenceID" : 10,
      "context" : "One was introduced by (Waibel et al., 1989) and also known as Time Delay Neural Networks (TDNNs).",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 1,
      "context" : "The other one was introduced by (Collobert et al., 2011).",
      "startOffset" : 32,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "In (Collobert et al., 2011) architecture, a sequence of length n is represented as:",
      "startOffset" : 3,
      "endOffset" : 27
    }, {
      "referenceID" : 0,
      "context" : "Thus, systems only received credit for an event attribute if they both found an event with correct character offsets and then assigned the correct value for that attribute (Bethard et al., 2015).",
      "startOffset" : 172,
      "endOffset" : 194
    }, {
      "referenceID" : 2,
      "context" : "Training is done through stochastic gradient descent over shuffled mini-batches with the AdaGrad update rule (Duchi et al., 2011).",
      "startOffset" : 109,
      "endOffset" : 129
    } ],
    "year" : 2016,
    "abstractText" : "We report an implementation of a clinical information extraction tool that leverages deep neural network to annotate event spans and their attributes from raw clinical notes and pathology reports. Our approach uses context words and their partof-speech tags and shape information as features. Then we hire temporal (1D) convolutional neural network to learn hidden feature representations. Finally, we use Multilayer Perceptron (MLP) to predict event spans. The empirical evaluation demonstrates that our approach significantly outperforms baselines.",
    "creator" : "LaTeX with hyperref package"
  }
}