{
  "name" : "1703.05376.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Two-Timescale Stochastic Approximation Convergence Rates with Applications to Reinforcement Learning",
    "authors" : [ "Gal Dalal", "Balázs Szörényi", "Gugan Thoppe", "Shie Mannor" ],
    "emails" : [ "gald@tx.technion.ac.il", "szorenyi.balazs@gmail.com", "gugan.thoppe@gmail.com", "shie@ee.technion.ac.il" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Stochastic Approximation (SA) is the subject of an enormous literature, both theoretical and applied (Kushner & Yin, 1997). It is used for finding optimal points, fixed points, or zeros of a function for which only noisy access is available. Consequently, SA lies at the core of many machine learning algorithms and in particular Reinforcement Learning (RL) algorithms, especially when function approximation is used.\nThe most powerful analysis tool for SA algorithms has been the Ordinary Differential Equation (ODE) method (Borkar & Meyn, 2000). The underlying idea of the ODE method is that, under the right conditions, noise effects average out and the SA iterates closely track the trajectory of the so called limiting ODE. Classical results give a convenient recipe for showing convergence (Borkar & Meyn, 2000). Hence, many RL analyses are given in that form, especially when the state-space is large and function approximation is used (Sutton et al., 2009a,b, 2015; Bhatnagar et al., 2009b). Concentration bounds for SA are, however, scarce; in fact, they are nonexistent in the case of two-timescale SA. This gives the motivation for our work."
    }, {
      "heading" : "1.1 Related Work",
      "text" : "Two-timescale SA methods are prominent in RL (Peters & Schaal, 2008; Bhatnagar et al., 2009b; Sutton et al., 2009b). Nonetheless, as mentioned before, there are no concentration bounds for these types of algorithms. Below we briefly survey related finite sample analyses for single-timescale SA and asymptotic convergence results for two-timescale RL algorithms.\nA broad rigorous study of SA is given in (Borkar, 2008); in particular, it contains concentration bounds for single-timescale methods. A more recent work (Thoppe & Borkar, 2015) obtains tighter concentration bounds under weaker assumptions for single-timescale SA using a variational methodology called Alekseev’s Formula. In the context of RL, (Konda, 2002; Korda & Prashanth, 2015)\n∗Equal contribution\nar X\niv :1\n70 3.\n05 37\n6v 3\n[ cs\n.A I]\n7 S\nep 2\ndiscuss convergence rate for TD(0) when the stepsizes are set using knowledge about the system dynamics. We stress that our results are in similar flavor but for the two-timescale setup.\nNext, we relate to the relevant RL literature on two time-scale methods. We partition them into two principal classes: actor-critic and gradient Temporal Difference (TD). In an actor-critic setting, a policy is being evaluated by the critic in the fast timescale, and improved by the actor in the slow timescale (Peters & Schaal, 2008; Bhatnagar et al., 2009b). The second class, i.e., gradient TD methods, was introduced by (Sutton et al., 2009a). This work presented the GTD(0) algorithm, which is gradient descent version of TD(0); being applicable to the so called off-policy setting, it has a clear advantage over TD(0). Later variants, GTD2 and TDC, were reported to be faster than GTD(0) while enjoying its benefits. They were also shown to converge in the case of linear and non-linear function approximation (Sutton et al., 2009b; Bhatnagar et al., 2009a). In addition to convergence, there also exists a concentration result for the GTD family, though only for the single-timescale setting (Liu et al., 2015). That work introduced altered versions of GTD(0) and GTD2, presented them as gradient methods to some saddle-point optimization problem, and obtained concentration bounds using results from convex optimization. These algorithms differ from the original versions in two aspects: a projection step is used to keep the iterates in a convex set, and the learning rates are chosen to be of fixed ratio. The latter makes the altered algorithms single-timescale variants of the original ones."
    }, {
      "heading" : "1.2 Our Contributions",
      "text" : "Our main contributions are three-fold:\n• We provide the first concentration bound for two-timescale SA algorithms; specifically, we analyze the linear SA case. The analysis is provided as a general methodology that can be used in various fields as a ”hammer” in a plug-and-play fashion.\n• Particularly, we show how to use our tool to obtain concentration bounds for the twotimescale RL algorithms in the gradient TD family: GTD(0), GTD2, and TDC. We are the first to obtain concentration bounds for the above algorithms in their original form.\n• We do away with the usual square summability assumption on stepsizes (see Remark 1). Therefore, our tool is relevant for a broader family of stepsizes."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "In the following we present the generic two-timescale SA algorithm, state our goal and list our assumptions.\nA generic two-timescale linear SA is\nθn+1 = θn + αn[h1(θn, wn) +M (1) n+1], (1)\nwn+1 = wn + βn[h2(θn, wn) +M (2) n+1], (2)\nwhere αn, βn ∈ R are stepsizes, M (i)n ∈ Rd denotes noise, and each function hi : Rd × Rd → Rd is of the form hi(θ, w) = vi − Γiθ −Wiw (3) for a vector vi ∈ Rd and matrices Γi,Wi ∈ Rd×d. Our aim is to obtain concentration bounds for (1) and (2) under the following assumptions.\nA1 . W2 and X1 := Γ1 −W1W−12 Γ2 are positive definite (not necessarily symmetric). A2 . {αn} and {βn} are positive real numbers satisfying\n∞∑ n=0 αn = ∞∑ n=0 βn =∞, sup n {αn, βn, ηn} ≤ 1, lim n→∞ αn = lim n→∞ βn = lim n→∞ ηn = 0,\n(4) where ηn := αn/βn.\nA3 . {M (1)n }, {M (2)n } are martingale difference sequences w.r.t. the increasing family of σ−fields {Fn}, where Fn = σ(θ0, w0,M (1)1 ,M (2) 1 , . . . ,M (1) n ,M (2) n ). Also, there exist positive\nconstants m1 and m2 so that, for all n ≥ 0,∥∥∥M (1)n+1∥∥∥ ≤ m1(1 + ‖θn‖+ ‖wn‖), and ∥∥∥M (2)n+1∥∥∥ ≤ m2(1 + ‖θn‖+ ‖wn‖). Remark 1. Unlike most works, ∑ n≥0 α 2 n or ∑ n≥0 β 2 n need not be finite. Thus our analysis is applicable for a wider class of stepsizes; e.g., 1/nκ with κ ∈ (0, 1/2]. In (Borkar, 2008), on which much of the existing RL literature is based on, the square summability assumption is due to the Gronwall inequality. In contrast, in our work, we use the Variation of Parameters Formula (Lakshmikantham & Deo, 1998) for comparing the SA trajectory to appropriate trajectories of the limiting ODE; it is a stronger tool than Gronwall inequality.\nWe now briefly highlight relevant ideas used in (Borkar, 2008) to establish convergence for twotimescale SA in the context of (1) and (2), and describe how our approach builds upon it. Following terminology in pp. 64-65 (Borkar, 2008), since ηn → 0, {wn} is the fast transient and {θn} is the slow component. Hence, we consider (2) as a noisy discretization of the ODE\nẇ(t) = v2 − Γ2θ −W2w(t) (5) for fixed θ, and view (1) as an approximation of\nθ̇(t) = h1(θ(t), λ(θ(t))) = b1 −X1θ(t), (6) where b1 := v1 −W1W−12 v2 and λ(θ) := W −1 2 [v2 − Γ2θ]. Due toA1 , b1 and the function λ(·) are well defined. Moreover, λ(θ) and θ∗ := X−11 b1 are unique globally asymptotically stable equilibrium points of (5) and (6), respectively.\nLemma 1, p. 66, (Borkar, 2008) applied to (1) and (2) gives limn→∞ ‖wn − λ(θn)‖ = 0 under suitable assumptions. Building upon this, for analysis, we choose to deal with {zn} instead of {wn} directly, where zn := wn − λ(θn). Using (2), {zn} satisfies the iterative rule\nzn+1 = zn − βnW2zn + βnM (2)n+1 + λ(θn)− λ(θn+1). (7) As {θn} is the slow component, we shall consider (7) as a noisy discretization of the ODE\nż(s) = −W2z(s). (8) Since W2 is positive definite fromA1 , z∗ := 0 ∈ Rd is the unique globally asymptotically stable equilibrium of (8). Remark 2. We emphasize that working with {zn} instead of {wn} is the vital reason why our approach works. As θn evolves, the limiting ODE in (5) changes with it; on the other hand, (8) remains unchanged. This makes comparing (7) with (8) easier than comparing (2) with (5)."
    }, {
      "heading" : "3 Main Result",
      "text" : "Let q1, q2 > 0 be lower bounds on the real part of the eigenvalues of matricesX1 andW2, respectively. For n ≥ 0, let an := ∑n−1 k=0 α 2 ke −2q1 ∑n−1 i=k+1 αi and bn := ∑n−1 k=0 β 2 ke −2q2 ∑n−1 i=k+1 βi . These sums are obtained from the Azuma-Hoeffding concentration bound. Their behavior is dependent on stepsize choice; this is elaborated for a common stepsize family in Theorem 3.2. Theorem 3.1 (Main Result). Consider a linear two-timescale SA algorithm and stepsize sequences {α̂k}, {β̂k}. Let 1, 2 > 0 and let n0 be s.t.\nmax { sup n≥n0 β̂n, sup n≥n0 α̂n β̂n } ≤ g1 min{ 1, 2} and sup n≥n0 β̂n ≤ g2 1,\nfor constants g1 and g2, in accordance with A4 and A5 . Set {αn = α̂n+n0}, {βn = β̂n+n0} and pick n1 s.t. max{ ∑n1 k=0 αk, ∑n1 k=0 βk} ≥ T1( 1, 2), where T1 = O(max{ln( 1 1\n), ln( 1 2 )}) in accordance with (22). Then\nPr{‖θn − θ∗‖ ≤ 1, ‖zn‖ ≤ 2,∀n ≥ n1} ≥ 1− 2d2 ∑ n≥0 [ exp [ −c1 21 an ] + exp [ −c2 21 bn ] + exp [ −c3 22 bn ]] ,\nwhere c1, c2, c3 > 0 are suitable constants as defined in Theorem 4.2.\nRemark 3. The result introduces two key notions: n0 and n1.\n1. A large n0 ensures the stepsizes are small enough to mitigate the martingale noise of the SA trajectories; i.e., the additive SA noise {αnM (1)n+1} and {βnM (2) n+1} ∀n ≥ n0 is small w.h.p.\nThis concept is of the nature of previous single timescale finite sample analyses: Corollary 14, Chapter 4, (Borkar, 2008), and the more recent (Korda & Prashanth, 2015), Theorem 1.\n2. The quantity n1 is an intrinsic property of the limiting ODEs.\n(a) After n1 iterations, the two ODE trajectories θ(tn) and z(sn) hit the -neighborhoods of their respective solutions when started in balls of radius Rin1 and R in 2 around them.\nAs shown explicitly in Theorem 3.2, n1 also depends on n0, since larger n0 implies smaller stepsizes and hence more iterations.\n(b) After n1 iterations, as they closely follow their ODE trajectories due to the n0 shift, θn and zn will also respectively reach the above -neighborhoods and remain in it thereafter.\nThe fact that n1 ensures a deterministic event hints at why the high probability bound in Theorem 3.1 does not depend on n1, but rather solely on 1, 2, and n0.\nRemark 4. As can be seen by inspecting the constants in the theorem’s statement, they exhibit a relatively complex dependence on the problem-dependent parameters q1 and q2. A significant appearance of q1 and q2, however, is in the form of 1qi respectively multiplying the ln( 1 i ) terms in T1.\nTheorem 3.1 applies for a general setting, where the stepsizes are not of a specific family, and may not even be monotone. For a more explicit result, we obtain a closed-form expression of above bound for commonly used stepsizes. We demonstrate the generality of our result by choosing stepsizes that may not be square-summable, as usually was required by previous works.\nTheorem 3.2. Fix 1, 2 > 0, δ ∈ (0, 1). Let αn = (n+n0)−α and βn = (n+n0)−β ∀n ≥ 0, with 1 > α > β. Then for some\nn0 = Õ ( [1/min{ 1, 2}]2/min{β,2(α−β)} ln(1/δ) )\nand some n1 = Õ ( max { n0, (ln(1/ 1)) 1/(1−α) , (ln(1/ 2)) 1/(1−β) }) ,\nwe have Pr{‖θn − θ∗‖ ≤ 1, ‖zn‖ ≤ 2,∀n ≥ n1} ≥ 1− δ.\nRemark 5. As explained in Remark 3, the role of n0 is to ensure small enough stepsizes, while the role of n1 is to ensure sufficient proximity of the SA and ODE trajectories toward convergence. Given this, Theorem 3.2 exhibits several valuable tradeoffs in the choice of α and β:\n1. As α or β approach 0 (stepsizes approach constants), n0 blows up. This is since the stepsizes’ slow decay rate impairs i) their ability to mitigate the martingale noise; and hence ii) the ability of the SA trajectories to follow the ODE trajectories.\n2. As α and β get close to each other, n0 blows up since the two-timescale nature is nullified. In a two-timescale algorithm, convergence of zn to z∗ should be faster relative to that of θn to θ∗; this is ensured by the decay rate of the stepsize ratio ηn.\n3. As α or β approach 1, which is the largest value for which (4) is still satisfied, n1 blows up. This is since the stepsizes then decay too fast, impairing the speed of the ODE convergence; more accurately, (22) moves away from exponential nature to inverse polynomial.\nIt is also worth mentioning that again, as in Remark 4, the problem-dependent parameters q1 and q2 appear in the form of 1qi , respectively multiplying the ln( 1 i ) terms in n0 and n1.\nRemark 6. One can see that for αk = (k + n0)−α, we have an = O(n−α). A similar behavior can be shown for bn as well."
    }, {
      "heading" : "4 Linear Two Timescale SA Analysis",
      "text" : "As a first step, we define the linearly interpolated trajectories of the iterates in each timescale. Having a continuous version of the discrete SA algorithm enables our analysis.\nAll proofs for the results in this section are given in Appendix A."
    }, {
      "heading" : "4.1 Analysis Preliminaries",
      "text" : "Let t0 = s0 = 0 and for all n ≥ 0, tn+1 = tn + αn and sn+1 = sn + βn. (9)\nLet θ̄(·) be the linear interpolation of {θn} on {tn}; i.e., let θ̄(tn) = θn and, for τ ∈ (tn, tn+1), let\nθ̄(τ) = θ̄(tn) + (τ − tn) αn [θ̄(tn+1)− θ̄(tn)]. (10)\nAlso, let z̄(·) be the linear interpolation of {zn}, but on the time steps {sn}. For τ ∈ [tn, tn+1), let\nξ(τ) := sn + βn αn (τ − tn). (11)\nThe mapping ξ(·) linearly interpolates {sn} on {tn}. Let 1, 2, Rin1 , Rin2 > 0 be such that 1 < R in 1 , 2 < R in 2 , ‖θ0 − θ∗‖ ≤ Rin1 , ‖z0‖ ≤ Rin2 . (12)\nFor T > 0, define the event E(T ) := { ∥∥θ̄(t)− θ∗∥∥ ≤ 1 ∀t ≥ T + 1} ∩ {‖z̄(s)‖ ≤ 2 ∀s ≥ ξ(T ) + 1}, (13) Let θ(t), t ≥ 0, be the solution to (6) satisfying θ(0) = θ0. From (6) and standard ODE results, θ(t) = θ∗ + e−X1t(θ0 − θ∗), t ≥ 0. (14) Similarly define z(s). From (8), z(s) = e−W2sz0, s ≥ 0. (15) We begin with an outline of the proof of Theorem (3.1)."
    }, {
      "heading" : "Overall Analysis Outline",
      "text" : "The key idea in our analysis is that we compare the SA trajectories θ̄(t) and z̄(s) to their respective limiting ODE trajectories θ(t), z(s). If the stepsizes are small enough, it is harder for the noise to perturb the SA trajectory θ̄(t) away from the limiting ODE behavior. A similar relation holds between z̄(s) and z(s).\nProving Theorem 3.1 is done in two steps. First, we use the Variation of Constants (VoC) formula (Lakshmikantham & Deo, 1998) to quantify the distance of the perturbed trajectories θ̄(t) and z̄(s) from their unperturbed trajectories θ(t) and z(s); this is done by splitting the perturbations into three parts per each trajectory, as described in Section 4.3. Thus, we obtain upper bounds on\n∥∥θ̄(t)− θ(t)∥∥ and ‖z̄(s)− z(s)‖ . Second, exploiting the fact that the stepsizes are small enough and using AzumaHoeffding Martingale concentration inequality, we show that these upper bounds are small with very high probability for all t, s ≥ 0. More explicitly, when θ(t) and z(s) are sufficiently close to θ∗ and z∗ respectively, the same is also true for θ̄(t) and z̄(s) with high probability. A visualization of the process is given in Fig. 1."
    }, {
      "heading" : "4.2 A Smart Decomposition of The Event of Interest",
      "text" : "For an event E , let Ec be its complement. Fix sufficiently large T > 0. We will say later on how large it ought to be. Pick n1 > 0 such that\nT ≤ tn1+1 = n1∑ k=0 αk ≤ T + 1. (16)\nThis is possible as {αn} satisfies (4). Our aim here is to construct a superset for the event Ec(T ), defined in (13), which is easier for analysis. The superset additionally contains the information of what happens until time tn1 .\nRemark 7. By standard ODE literature, limt→∞ θ(t) = θ∗. As X1 is positive definite by A1 , d dt‖θ(t) − θ\n∗‖2 = −2(θ(t) − θ∗)>X1(θ(t) − θ∗) < 0; hence, ‖θ(t)− θ∗‖ ≤ Rin1 for all t ≥ 0. Likewise, lims→∞ z(s) = z∗ and ‖z(s)‖ ≤ Rin2 for all s ≥ 0.\nBy Remark 7, θ(t) stays in the Rin1−radius ball around θ∗ for all t ≥ 0, and z(s) stays in the Rin2−radius ball around z∗ for all s ≥ 0. However, the same cannot be said for θ̄(t) and z̄(s) due to the presence of noise. We will show instead that these lie with high probability in bigger but fixed radii balls Rout1 and R out 2 which we define below.\nFix Rout1 , R out 2 > 0 such that R out 1 > R in 1 , R out 2 > R in 2 ,\nRgap1 := R out 1 −Rin1 ≥ 1, and R gap 2 := R out 2 −Rin2 ≥ 2. (17)\nFor n ≥ 0, let\nρn+1 := sup τ∈[tn,tn+1] ∥∥θ̄(τ)− θ(τ)∥∥ , ρ∗n+1 := sup τ∈[tn,tn+1] ∥∥θ̄(τ)− θ∗∥∥ , (18) νn+1 := sup\nµ∈[sn,sn+1] ‖z̄(µ)− z(µ)‖ , ν∗n+1 := sup µ∈[sn,sn+1] ‖z̄(µ)‖ , (19)\nand define the (“good”) event Gn := { ∥∥θ̄(τ)− θ∗∥∥ ≤ Rout1 ∀τ ∈ [0, tn]} ∩ {‖z̄(µ)‖ ≤ Rout2 ∀µ ∈ [0, sn]}. (20)\nAdditionally, define the (“bad”) events Emid := {[\nsup 0≤n≤n1 ρn+1\n] ≥ Rgap1 } ∪ {[\nsup 0≤n≤n1 νn+1\n] ≥ Rgap2 } ,\nEafter := ⋃ n>n1 [ {ρ∗n+1 > 1} ∪ {ν∗n+1 > 2} ] .\nThe desired superset is now ready to be given below.\nLemma 4.1 (Decomposition of Event of Interest). The following relation holds for the event of interest, defined in (13). Ec(T ) ⊆ ⋃n1 n=0{Gn ∩ [{ρn+1 ≥ R gap 1 } ∪ {νn+1 ≥ R gap 2 }]} ∪⋃\nn>n1\n{ Gn ∩ [ {ρ∗n+1 ≥ 1} ∪ {ν∗n+1 ≥ 2} ]} .\nThe key advantage of this result is that the analysis can now be broken down into an incremental union of events, enabling easier analysis. Each event has an inductive structure: good up to time n (ensured by conditioning on Gn, where the iterates remain in bounded regions) and bad in the subsequent interval (θ̄(tn+1) and z̄(sn+1) leave the bounded regions). Moreover, using Lemma 4.1 to bound Pr{Ec(T )} results in a tight bound since the relation holds whenever the two-timescale iterates stay in the Rin balls. This happens w.h.p. due toA4 andA5 .\n4.3 Perturbation Bounds for {zn} and {θn} Our aim here is to use the VoC formula to bound ‖z̄(s)− z(s)‖ and ∥∥θ̄(t)− θ(t)∥∥. Then, use this to obtain bounds on νn+1 and ν∗n+1, and ρn+1 and ρ ∗ n+1 on the event Gn. This is a preparation step for applying Lemma 4.1. Through the rest of this section, the steps are described solely for the {zn} iterates, and are similarly applied for {θn}, as given in detail in Appendix A.2. When applying the VoC formula, we compare the perturbed trajectory z̄(s) to its unperturbed counterpart z(s). As we show below, the difference between them is due to three components, namely discretization error, martingale difference noise, and slow drift in the equilibrium of (5):\nχde(µ) := W2[z̄(µ)− zk], χmd(µ) := M\n(2) k+1,\nχsd(µ) := [λ(θk)− λ(θk+1)]/βk = W−12 Γ2[θk+1 − θk]/βk,\nfor k ≥ 0 and µ ∈ [sk, sk+1). To clarify on the role of χsd(µ), the drift is due to the fact that θn evolves and it is slow because {θn} is updated on the slow time scale {tn} (recall ηn → 0). In the case of {θn} iterates, the first two terms are similar, while the third is the error in tracking the equilibrium of (5). Recall that as θn evolves, the equilibrium of (5) changes. The tracking error is a function of zn which, from (7), is the difference between wn and λ(θn). Simple manipulations on (7) show that for all s ≥ 0, z̄(s) = z0 + ∫ s 0\n[−W2z̄(µ) + χ(µ)]dµ, where χ(µ) = χde(µ) + χmd(µ) + χsd(µ). Using the VoC formula, we have\nz̄(s) = z(s) + E2(s), (21)\nwhere E2(s) = Ede2 (s) +E md 2 (s) +E sd 2 (s) with E de 2 (s) =\n∫ s e−W2[s−µ]χde(µ)dµ, and similarly for\nEmd2 (s) and E sd 2 (s). The exponential term e −W2(s−µ) multiplying each perturbation is a consequence of using the VoC formula. We exploit this fact extensively in all our proofs. On Gn, to obtain bounds on νn+1 and ν∗n+1, it thus suffices to get bounds on the perturbation errors ∥∥Ede2 (·)∥∥ , ∥∥Emd2 (·)∥∥ , and\n∥∥Esd2 (·)∥∥ on the interval [sn, sn+1]. Those, and consequently the bounds on νn+1 and ν∗n+1 are obtained in Appendix A.2."
    }, {
      "heading" : "4.4 Concentration Bounds for Two Time Scale SA",
      "text" : "Summarizing Subsection 4.3, on the good event Gn, each of νn+1, ρn+1, ν∗n+1 and ρ ∗ n+1 is bounded from above by three kinds of terms: i) sum of Martingale differences, ii) exponentially decaying term and iii) stepsize based term. For large enough n, type i) terms are small with high probability due toA3 and the Azuma-Hoeffding martingale concentration inequality; type ii) terms are small for sufficiently large n; type iii) terms are small for small enough stepsizes. Based on this, we bring our main technical result in Theorem 4.2. Theorem 3.1 then follows trivially.\nSuppose the following additional assumptions on the stepsizes hold, with the constants taken from Appendix A.3.\nA4 . max { supk≥0 βk, supk≥0 ηk } ≤ min { 1 8 , 2 3 } /max{LzLθc , Lz}.\nA5 . supk≥0 βk ≤ 1/(4Lθb).\nThese assumptions may not hold for a general stepsize sequence. However, due to (4), they will be ensured by properly shifting the stepsize sequence as in Theorem 3.1.\nAssume that 1 ≤ 4Lθa and let R gap 1 = 4L θ a. Let N1 be large enough to satisfy\nK2R in 2 e −q2sN1 ≤ 2 3 and [K1Rin1 + L θ a]e −qtN1 ≤ 1 4 . (22)\nTheorem 4.2 (Main Technical Result). Fix n1 ≥ N1. Then\nPr{‖θn − θ∗‖ ≤ 1, ‖zn‖ ≤ 2,∀n ≥ n1} ≥ Pr{E(T )} ≥ 1− 2d2 ∑ n≥0 [ exp [ −c1 21 an ] + exp [ −c2 21 bn ] + exp [ −c3 22 bn ]] ,\nwhere c1 = (16K21d 3[Lmd1 ] 2)−1, c2 = (9K 2 2d 3[Lmd2 ] 2)−1, c3 = (64K 2 2 [L θ c ] 2d3[Lmd2 ] 2)−1."
    }, {
      "heading" : "5 Applications to Two-timescale RL",
      "text" : "In this section we show how our novel machinery implies concentration bounds on the standard two-timescale RL methods with linear function approximation, in a plug-and-play fashion. We consider the problem of policy evaluation and use the standard RL framework and notations, given in detail in Appendix A.4. We assume linear function approximation, i.e., V π(s) ≈ θ>φ(s), where φ(s) ∈ Rd is a feature vector at state s, and θ ∈ Rd is a parameter vector. For brevity, we denote φ(sn), φ(s ′ n) by φn, φ ′ n. We also relate to the matrices A = E[φ(φ− γφ′)>] and C = E[φφ>], and the vector b = E[rφ], where the expectations are w.r.t. the stationary distribution of the induced chain. We assume all rewards r(s) and feature vectors φ(s) are bounded: |r(s)| ≤ 1, ‖φ(s)‖ ≤ 1 ∀s ∈ S. Also, it is assumed that A and C are of full rank. These assumption are standard (see (Sutton et al., 2009a,b)). It is known that A is positive definite (Bertsekas, 2012). Also, by construction, C is positive semidefinite; thus, by the full-rank assumption it is actually positive definite.\nWe now present the GTD(0) algorithm, verify its related required assumptions, and obtain the necessary relevant constants to apply Theorem 3.2 for it. The GTD(0) algorithm (Sutton et al., 2009a) is designed to minimize the objective function JNEU(θ) = 12 (b−Aθ)\n>(b−Aθ) . The update rule of the algorithm takes the form of Equations (1) and (2) with h1(θ, w) = A>w , h2(θ, w) = b−Aθ − w , andM (1)n+1 = (φn − γφ′n)φ>nwn−A>wn ,M (2) n+1 = rnφn+φn[γφ ′ n−φn]>θn−(b−Aθn) . That is, in case of GTD(0), the relevant matrices in the update rules take the form Γ1 = 0,W1 = −A>, v1 = 0, and Γ2 = A, W2 = I, v2 = b. Additionally, X1 = Γ1 −W1W−12 Γ2 = A>A. By our assumption above, both W2 and X1 are symmetric positive definite matrices, and thus the real parts of their eigenvalues are also positive. It is also clear that\n‖M (1)n+1‖ ≤(1 + γ + ‖A‖)‖wn‖,\n‖M (2)n+1‖ =‖rnφn + φn[γφ′n − φn]>θn − (b−Aθn) ‖ ≤ 1 + ‖b‖+ (1 + γ + ‖A‖)‖θn‖ .\nConsequently, Assumption A3 is satisfied with constants m1 = (1 + γ + ‖A‖) and m2 = 1 + max(‖b‖, γ + ‖A‖). In a similar fashion, we perform the same steps for GTD2 and TDC (Sutton et al., 2009b) and summarize the results in Table 5. The detailed derivation is provided in Appendix A.4.\nWe now apply Theorem 3.2 for a specific choice of stepsizes and give it in a diminishing bound form, in similar spirit to Theorem 1 in (Korda & Prashanth, 2015). Let 1 = 2 = > 0 and δ ∈ (0, 1/3). Let α = 3/4, β = 1/2. Set n0 = C1 −1/4 ln 1δ , so that it satisfies the appropriate condition in Theorem 3.2. The resulting stepsizes are αn = (n+ n0)−3/4, βn = (n+ n0)−1/2. Let n1 = C2n0, satisfying the appropriate condition on n1 in Theorem 3.2. This choice is valid since( 1\n)4 ln 1δ ≥ ( ln 1 )4 . Applying Theorem 3.2 gives\nPr { max{‖θn − θ∗‖ , ‖zn‖} ≤ C1C2 [ ln(1/δ)\nn1\n]1/4 , ∀n ≥ n1 } ≥ 1− δ,\nwhere C1, C2 are problem-dependent constants that can be extracted using Table 5."
    }, {
      "heading" : "6 Discussion",
      "text" : "In this work we obtained the first concentration bound for two-timescale SA algorithms. We provide it as a general methodology that applies to all linear two-timescale SA algorithms. A natural extension\nto our methodology is considering the non-linear function-approximation case, in a similar fashion to (Thoppe & Borkar, 2015). Such a result can be of high interest due to the recently growing attractiveness of neural networks in the RL community. An additional direction for future research is extending to actor-critic RL algorithms, in addition to the gradient TD methods explored here."
    }, {
      "heading" : "A Supplementary Material",
      "text" : "This section contains all proofs of the lemmas and theorems presented in the paper, and provides additional technical results to support several of these proofs."
    }, {
      "heading" : "A.1 Proofs from Subsection 4.2",
      "text" : ""
    }, {
      "heading" : "Let R∗ :=",
      "text" : "∥∥X−11 ∥∥ ‖b1‖ so that ‖θ∗‖ ≤ R∗. (23) On Gn, for k ∈ {0, . . . , n}, ‖wk‖ ≤ ‖zk‖+ ‖λ(θ∗)‖+ ‖λ(θk)− λ(θ∗)‖ ≤ Rout2 +\n∥∥W−12 ∥∥ [ ‖v2‖+ ‖Γ2‖ [R∗+Rout1 ]] =: Rw2 . Proof of Lemma 4.1. By (16), as tn1+1 ≤ T + 1, Ec(T ) ⊆ Eafter. For any two events E1 and E2, as\nE1 = [E2 ∩ E1] ∪ [Ec2 ∩ E1] ⊆ E2 ∪ [Ec2 ∩ E1], we have Eafter ⊆ Emid ∪ [Ecmid ∩ Eafter]. Using Remark 7,{[\nsup 0≤k<n ρk+1\n] ≤ Rgap1 } ∩ {[\nsup 0≤k<n νk+1\n] ≤ Rgap2 } ⊆ Gn.\nfor all n ≥ 0. Hence by simple manipulations, we have\nEmid ⊆ n1⋃ n=0 { Gn ∩ [ {ρn+1 ≥ Rgap1 } ∪ {νn+1 ≥ R gap 2 } ] }.\nArguing similarly, one can see that\nEcmid ∩ Eafter ⊆ Gn1+1 ∩ Eafter ⊆\n⋃ n>n1 [ Gn ∩ [ {ρ∗n+1 ≥ 1} ∪ {ν∗n+1 ≥ 2} ]] ,\nwhere the last inequality follows as 1 ≤ Rout1 and 2 ≤ Rout2 . The desired result is now easy to see."
    }, {
      "heading" : "A.2 Proofs from Subsection 4.3",
      "text" : "For obtaining the bounds in this subsection, we first show worst-case bounds on the increments. For k ≥ 0, let Iθ(k) := ‖θk+1 − θk‖ /αk (24) and Iz(k) := ‖zk+1 − zk‖ /βk. (25) Lemma A.1 (Bounded Differences). Fix n ≥ 0. Then on Gn,\nsup 0≤k≤n Iθ(k) ≤ Jθ, sup 0≤k≤n Iz(k) ≤ Jz. (26)\nwhere Jθ = ‖v1‖+ ‖Γ1‖ [R∗ +Rout1 ] + ‖W1‖Rw2 +m1[1 +R∗ +Rout1 +Rw2 ] (27) and Jz := ‖W2‖Rout2 +\n∥∥W−12 ∥∥ ‖Γ2‖ Jθ +m2(1 +R∗ +Rout1 +Rw2 ). (28) Proof of Lemma A.1. Fix k ∈ {0, . . . , n}. On Gn, using (1),A3 , (23), (20), and (24), in that order,\nIθ(k) ≤ ‖v1 − Γ1θk −W1wk‖+ ∥∥∥M (1)k+1∥∥∥\n≤ ‖v1‖+ ‖Γ1‖ (‖θ∗‖+ ‖θk − θ∗‖) + ‖W1‖ ‖wk‖ +m1[1 + ‖θ∗‖+ ‖θk − θ∗‖+ ‖wk‖]\n≤ Jθ. (29)\nSimilarly, on Gn, using (7),A3 , (20), (4) fromA2 , (29), (23), and (24), in that order,\nIz(k) ≤ ‖W2‖ ‖zk‖+ ‖λ(θk)− λ(θk+1)‖ /βk + ∥∥∥M (2)k+1∥∥∥\n≤ ‖W2‖ ‖zk‖+ ∥∥[W2]−1∥∥ ‖Γ2‖ ηkIθ(k)\n+m2(1 + ‖θ∗‖+ ‖θk − θ∗‖+ ‖wk‖) ≤ Jz.\nSince k was arbitrary the result follows.\nLet q(1)(W2), . . . , q(d)(W2) be the eigenvalues of W2. Fix q2 ∈ (0, q′2), where q′2 := mini{real(q(i)(W2))}. Then from Corollary 3.6 (Teschl, 2004), there exists K2 ≥ 1 so that∥∥∥e−W2(s−µ)∥∥∥ ≤ K2e−q2(s−µ), ∀s ≥ µ. (30) For the rest of the results in this subsection we consider intermediate intervals [sn, sn+1]. The next lemma gives bounds on the three error terms of the interpolated trajectory z̄(s) at the extremes {sn, sn+1}.\nLemma A.2 (Perturbation Error Bounds for zn). Fix n ≥ 0. Then on Gn,\nsup `∈{n,n+1} ∥∥Ede2 (s`)∥∥ ≤ Lde2 [sup k≥0 βk ] ,\nsup `∈{n,n+1} ∥∥Esd2 (s`)∥∥ ≤ Lsd2 [sup k≥0 ηk ] ,∥∥Emd2 (sn+1)∥∥ ≤ K2 ∥∥Emd2 (sn)∥∥+ Lmd2 βn.\nwhere Lde2 := K2J z‖W2‖ q2 , Lsd2 := K2‖W−12 ‖‖Γ2‖Jθ q2 , Lmd2 := K2m2[1 +R ∗ +Rout1 +R w 2 ].\nThe previous lemma shows that for τ ∈ [sn, sn+1], z̄(τ) cannot deviate much from the ODE trajectory z(τ) if the stepsizes are small enough. In particular, it bounds the distance with decaying terms using Lemma A.2.\nLemma A.3 (ODE-SA Distance Bound for zn). Fix n ≥ 0. Then on Gn,\nνn+1 ≤K2 ∥∥Emd2 (sn)∥∥+ Lz max{sup\nk≥0 βk, sup k≥0 ηk\n} ,\nν∗n+1 ≤K2 ∥∥Emd2 (sn)∥∥+K2Rin2 e−q2(sn−) + Lz max{sup\nk≥0 βk, sup k≥0 ηk\n} ,\nwhere Lz = Lde2 + L md 2 + ‖W2‖Rin2 + Lsd2 .\nNext, we provide a technical lemma for later usage.\nLemma A.4. Let 0 < r0 < r1 < · · · < r`, let γi = ri+1 − ri for i = 0, . . . , ` − 1, let U be some d× d matrix, and let ρ : R→ R be some mapping. Assume that for some constant J it holds that ‖ρ(σ)‖ ≤ γiJ for any σ ∈ [ri, ri+1] and i = 0, . . . , ` − 1. Assume, furthermore that for some constants K > 0 and q0 > 0 it holds that ‖e−U(r−r0)‖ ≤ Ke−q0(r−r0) for any r > r0. Then∥∥∥∥∫ r`\nr0\ne−U(r`−σ)ρ(σ)dσ ∥∥∥∥ ≤ KJq0 [ sup i=0,...,`−1 γi ] .\nProof. The claim of the lemma follows easily as, due to the assumptions,∥∥∥∥∫ r` r0 e−U(r`−σ)ρ(σ)dσ ∥∥∥∥ ≤\n`−1∑ i=0 ∫ ri+1 ri ∥∥∥e−U(r`−σ)∥∥∥ ‖ρ(σ)‖ dσ ≤ KJ\n`−1∑ i=0 γj ∫ ri+1 ri e−q0(r`−σ)dσ\n≤ KJ [ sup\ni=0,...,`−1 γi ]∫ r`−r0 0 e−q0σdσ\n≤ KJ q0\n[ sup\ni=0,...,`−1 γi\n] .\nProof of Lemma A.2. Fix ` ∈ {n, n+ 1}. For the first claim of the lemma note that, by Lemma A.1, on Gn,∥∥χde(µ)∥∥ ≤ ‖W2‖ (µ− sk)Iz(k) ≤ ‖W2‖βkJz for µ ∈ [sk, sk+1), where Iz(k) is as in (25). The claim then follows easily by recalling (30), and applying Lemma (A.4) with ri = si, γi = βi, U = W2, ρ = χde, K = K2, q0 = −q2 and J = ‖W2‖ Jz .\nFor the second claim, let k ∈ {0, . . . , `− 1} and µ ∈ [sk, sk+1). With Iθ(k) as in (24),∥∥χsd(µ)∥∥ ≤ ηk ∥∥W−12 ∥∥ ‖Γ2‖ Iθ(k). Hence by Lemma A.1, on Gn, ∥∥χsd(µ)∥∥ ≤ ηk ∥∥W−12 ∥∥ ‖Γ2‖ Jθ. The claim then follows again by (30) and Lemma (A.4).\nFor the third claim, by its definition and the triangle inequality,∥∥Emd2 (sn+1)∥∥ ≤\n∥∥∥∥∫ sn+1 e−W2(sn+1−µ)χmd(µ)dµ∥∥∥∥ ≤\n∥∥∥∥e−W2βn ∫ sn e−W2(sn−µ)χmd(µ)dµ∥∥∥∥ +\n∥∥∥∥∫ sn+1 sn e−W2(sn+1−µ)χmd(µ)dµ ∥∥∥∥ . Applying (30) on both terms, we get that∥∥Emd2 (sn+1)∥∥ ≤ K2 ∥∥Emd2 (sn)∥∥+K2βn ∥∥∥M (2)n+1∥∥∥ . OnGn, usingA3 with (20), (23), and (24), we haveK2\n∥∥∥M (2)n+1∥∥∥ ≤ Lmd2 . The third claim follows. Proof of Lemma A.3. Let µ ∈ [sn, sn+1]. Then there exists κ ∈ [0, 1] so that\nz̄(µ) = (1− κ)z̄(sn) + κz̄(sn+1). Hence\n‖z̄(µ)− z(µ)‖ ≤ (1− κ) ‖z̄(sn)− z(µ)‖\n+κ ‖z̄(sn+1)− z(µ)‖ .\nUsing (8),\nz(µ) = z(sn) + ∫ µ sn [−W2 z(µ1)]dµ1,\nand\nz(sn+1) = z(µ) + ∫ sn+1 µ [−W2 z(µ1)]dµ1.\nCombining the above three relations, we have\n‖z̄(µ)− z(µ)‖ ≤(1− κ) ‖z̄(sn)− z(sn)‖\n+ κ ‖z̄(sn+1)− z(sn+1)‖\n+ ∫ sn+1 sn ‖W2‖ ‖z(µ1)‖dµ1.\nAs ‖z0‖ ≤ Rin2 , from Remark 7, ‖z(µ)‖ ≤ Rin2 for all s ≥ 0. Using this with (21), (30), the facts that K2 ≥ 1 and βn ≤ [supk≥0 βk], and Lemma A.2, the first claim follows:\nνn+1 ≤Lde2 [ sup k≥0 βk ] + Lsd2 [ sup k≥0 ηk ] + κLmd2 βn\n+ ((1− κ) + κK2) ∥∥Emd2 (sn)∥∥+ ‖W2‖βnRin2 .\n≤K2 ∥∥Emd2 (sn)∥∥+ Lz max{sup\nk≥0 βk, sup k≥0 ηk\n} . (31)\nFor the second claim observe that\n‖z̄(µ)‖ ≤ ‖z̄(µ)− z(µ)‖ + ‖z(µ)‖ .\nHence ν∗n+1 ≤ νn+1 + sup\nµ∈[sn,sn+1] ‖z(µ)‖ .\n‖z0‖ ≤ Rin2 , and hence using (15) and (30),\n‖z(µ)‖ ≤ K2Rin2 e−q2µ.\nCombining the above two relations with (31), the desired result is now easy to see.\nWe now reproduce the results of Lemma A.3, this time for {θn} instead of {zn}, and obtain bounds on ρn+1 and ρ∗n+1 on Gn.\nFor k ≥ 0 and τ ∈ [tk, tk+1), let\nζde(τ) := h1(θk, λ(θk))− h1(θ̄(τ), λ(θ̄(τ))) = X1[θ̄(τ)− θk],\nζmd(τ) := M (1) k+1,\nζ te(τ) := h1(θk, wk)− h1(θk, λ(θk)) = −W1zk.\nUsing simple manipulations on (1), for any t ≥ 0,\nθ̄(t) = θ0 + ∫ t 0 [ h1 ( θ̄(τ), λ(θ̄(τ)) ) + ζ(τ) ] dτ,\nwhere ζ(τ) = ζde(τ) + ζmd(τ) + ζ te(τ). These are respectively perturbations due to discretization, martingale difference noise, and error in tracking the equilibrium of (5). Recall that as θn evolves, the equilibria of (5) moves. The tracking error is a function of the zn which, from (7), is the difference between wn and λ(θn). By the VoC formula,\nθ̄(t) = θ(t) + E1(t), (32)\nwhere E1(t) = Ede1 (t) + E md 1 (t) + E te 1 (t) with\nEde1 (t) = ∫ t 0 e−X1(t−τ)ζde(τ)dτ,\nand similarly for Emd1 (t) and E te 1 (t). As in Subsection 4.3, to obtain bounds on ρn+1 and ρ ∗ n+1, it suffices to get bounds on ∥∥Ede1 (·)∥∥ , ∥∥Emd1 (·)∥∥ , and ‖Ete1 (·)‖ on the interval [tn, tn+1], on the event Gn.\nIn the same way as in (30), there exist q1 and K1 ≥ 1 so that∥∥∥e−X1(t−τ)∥∥∥ ≤ K1e−q1(t−τ), ∀t ≥ τ. (33) Fix q ∈ (0, qmin), where qmin := min{q1, q2} and q2 is from (30). The next lemma gives bounds on the three components of E1(t) at the extremes {tn, tn+1}. Lemma A.5 (Perturbation Error Bounds for θn). Fix n ≥ 0. Then on Gn,\nsup `∈{n,n+1} ∥∥Ede1 (t`)∥∥ ≤ Lde1 [sup k≥0 αk ] ,\nsup `∈{n,n+1} ‖Ete1 (t`)‖ ≤ Lte1a e−qtn + Lte1b [ sup k≥0 βk ] + Lte1c [ sup 0≤k≤n νk+1 ] ,∥∥Emd1 (tn+1)∥∥ ≤ K1 ∥∥Emd1 (tn)∥∥+ Lmd1 αn.\nwhere Lde1 := K1J θ‖X1‖ q1 , Lte1a := K1 ‖W1‖K2Rin2 1(qmin−q)e , L te 1b := K1 ‖W1‖ ‖W2‖Rin2 /q1, Lte1c := K1 ‖W1‖ /q1, Lmd1 := K1m1[1 +R∗ +Rout1 +Rw2 ].\nSimilarly to Subsection 4.3, the next lemma bounds ρn+1 and ρ∗n+1 with decaying terms using Lemma A.5. Lemma A.6 (ODE-SA Distance Bound for θn). Fix n ≥ 0. Then on Gn,\nρn+1 ≤K1 ∥∥Emd1 (tn)∥∥+ Lθa e−qtn + Lθb [sup\nk≥0 βk\n] + Lθc [ sup\n0≤k≤n νk+1\n] ,\nρ∗n+1 ≤K1 ∥∥Emd1 (tn)∥∥+ [K1Rin1 + Lθa]e−qtn + Lθb [sup\nk≥0 βk\n] + Lθc [ sup\n0≤k≤n νk+1\n] ,\nwhere Lθa = L te 1a, L θ c = L te 1c and L θ b := L de 1 + L md 1 + ‖X1‖Rin1 + Lte1b.\nWe first provide the following technical result for later usage. Lemma A.7 (Dominating Decay Rate Bound). Fix q ∈ (0, qmin) where qmin := min{q1, q2}. Then for n ≥ 0,\nn−1∑ k=0 ∫ tk+1 tk e−q1(tn−τ)e−q2ξ(τ)dτ ≤ 1 (qmin − q)e e−qtn .\nProof. From (4), βk ≥ αk ∀k ≥ 1. Using this and (11), ∀k ≥ 1 and τ ∈ [tk, tk+1], ξ(τ) − sk ≥ τ − tk. Hence for any τ ∈ [0, tn],\n−q1(tn − τ)− q2(ξ(τ)−) ≤ −qmin(tn − 0).\nNow, since 1αe is the maximum of xe −αx,\ntne −qmintn\n=tne −(qmin−q)tne−qtn\n≤ 1 (qmin − q)e e−qtn .\nThe desired result now follows.\nProof of Lemma A.5. For the first claim of the lemma fix ` ∈ {n, n + 1}. Let k ∈ {0, . . . , ` − 1} and τ ∈ [tk, tk+1). With Iθ(k) as in (24),∥∥ζde(τ)∥∥ ≤ ‖X1‖ (τ − tk)Iθ(k) ≤ αk ‖X1‖ Iθ(k). So by Lemma A.1, on Gn,\n∥∥ζde(τ)∥∥ ≤ αk ‖X1‖ Jθ. The first claim now follows by (33) and Lemma (A.4).\nFor proving the second claim of the lemma let ` = n. By triangle inequality,\n‖Ete1 (tn)‖ ≤ n−1∑ k=0 ∫ tk+1 tk ∥∥∥e−X1(tn−τ)∥∥∥∥∥ζ te(τ)∥∥ dτ. Using (33), it follows that\n‖Ete1 (tn)‖ ≤ K1 n−1∑ k=0 ∫ tk+1 tk e−q1(tn−τ) ∥∥ζ te(τ)∥∥dτ.\nFix k ∈ {0, . . . , n− 1} and τ ∈ [tk, tk+1). Then∥∥ζ te(τ)∥∥ ≤ ‖W1‖ ‖zk‖ . Using (11) and the triangle inequality,\n‖zk‖ ≤ ‖z(ξ(τ))‖\n+ ‖z(ξ(τ))− z(ξ(tk))‖ + ‖zk − z(ξ(tk))‖ .\nAs ‖z0‖ ≤ Rin2 , by (15) and (30), ‖z(ξ(τ))‖ ≤ K2Rin2 e−q2(ξ(τ)−). Remark 7 also implies that, as ‖z0‖ ≤ Rin2 , ‖z(s)‖ ≤ Rin2 for all s ≥ 0. Hence by (8), ‖z(ξ(τ))− z(ξ(tk))‖\n≤ ∥∥∥∥∥ ∫ ξ(τ) ξ(tk) [−W2] z(µ)dµ ∥∥∥∥∥ ≤ ‖W2‖Rin2 βk,\nwhere the last relation holds as [ξ(τ)− ξ(tk)] ≤ [sk+1 − sk]. Also note that, by (19), ‖zk − z(ξ(tk))‖ ≤ νk+1. Combining the above relations,∥∥ζ te(τ)∥∥ ≤ ‖W1‖ [ K2R in 2 e −q2(ξ(τ)−)\n+ ‖W2‖Rin2 βk + νk+1 ]\n≤ ‖W1‖ [ K2R in 2 e −q2(ξ(τ)−)\n+ ‖W2‖Rin2 [ sup k≥0 βk ] + [ sup 0≤k≤n−1 νk+1 ]] By Lemma A.7 and the fact that ∫ tn 0 e−q1(tn−τ)dτ ≤ 1/q1,\n‖Ete1 (tn)‖ ≤ Lte1ae−q(tn−0) + Lte1b [ sup k≥0 βk ] + Lte1c [ sup 0≤k≤n−1 νk+1 ] .\nA similar bound holds for ` = n+ 1. Since e−q(tn+1−0) ≤ e−q(tn−0), the second claim of the lemma follows.\nThe third claim of the lemma, bounding ∥∥Emd2 (sn+1)∥∥, follows in a similar way to the third claim of Lemma A.2.\nProof of Lemma A.6. Let τ ∈ [tn, tn+1]. Then arguing as in proof of Lemma A.3 and using (6), there exists κ ∈ [0, 1] such that ∥∥θ̄(τ)− θ(τ)∥∥\n≤ (1− κ) ∥∥θ̄(tn)− θ(tn)∥∥\n+κ ∥∥θ̄(tn+1)− θ(tn+1)∥∥\n+ ∫ tn+1 tn ‖X1‖ ‖θ(τ1)− θ∗‖ dτ1.\nSince ∥∥θ̄(0)− θ∗∥∥ ≤ Rin1 , from Remark 7, ‖θ(τ)− θ∗‖ ≤ Rin1 for all t ≥ 0. Using this with (32) and (30), the facts that K1 ≥ 1,\nαn ≤ [ sup k≥0 αk ] ≤ [ sup k≥0 βk ] ,\nand Lemma A.5, the first claim of the lemma follows: ρn+1 ≤Lde1 [ sup k≥0 βk ] + Lte1ae −q(tn−0) + Lte1b [ sup k≥0 βk ] + Lte1c [ sup\n0≤k≤n νk+1\n] + κLmd1 [ sup k≥0 βk ] + (κ+ (1− κ)K1)\n∥∥Emd1 (tn)∥∥ + ‖X1‖Rin1 [ sup k≥0 βk\n] ≤K1\n∥∥Emd1 (tn)∥∥+ Lθa e−q(tn−0) + Lθb [ sup k≥0 βk ] + Lθc [ sup 0≤k≤n νk+1 ] . (34)\nFor the second claim of the lemma, notice that∥∥θ̄(τ)− θ∗∥∥ ≤ ∥∥θ̄(τ)− θ(τ)∥∥ + ‖θ(τ)− θ∗‖ .\nThus, we have ρ∗n+1 ≤ ρn+1 + sup\nτ∈[tn,tn+1] ‖θ(τ)− θ∗‖ .∥∥θ̄(0)− θ∗∥∥ ≤ Rin1 , and hence using (14), ‖θ(τ)− θ∗‖ ≤ K1Rin1 e−q1(τ−0). Combining the above two relations and using (34) and the fact that q < q1, the second claim of the lemma follows."
    }, {
      "heading" : "A.3 Proofs from Subsection 4.4",
      "text" : "We first bring Lemmas A.8 to A.11 for proving Lemma A.12. Lemma A.8. For n ≥ 0,\n[Gn ∩ {νn+1 ≥ Rgap2 }] ⊆ [ Gn ∩ { K2 ∥∥Emd2 (sn)∥∥ ≥ 23 }] .\nProof. The desired result follows from Lemma A.3, (17), (A4), and the fact that 2/3 ≤ 2/2 ≤ Rgap2 /2.\nLemma A.9. Fix 0 ≥ N0. Then for n ≥ 0, [Gn ∩ {ρn+1 ≥ Rgap1 }]\n⊆ [ Gn ∩ { K1 ∥∥Emd1 (tn)∥∥ ≥ 14 }]∪\nn⋃ k=0 [ Gk ∩ { LθcK2 ∥∥Emd2 (sk)∥∥ ≥ 18 }] .\nProof. By Lemma A.6 and since Rgap1 = 4L θ a, L θ ae −q(tn−0) ≤ Rgap1 /4. Combined with (22) and (A5), we get that\n[Gn ∩ {ρn+1 ≥ Rgap1 }]\n⊆ [ Gn ∩ { K1 ∥∥Emd1 (tn)∥∥ ≥ Rgap14 }] ∪ [ Gn ∩ { Lθc [ sup\n0≤k≤n νk+1\n] ≥ R gap 1\n4\n}] .\nAs Rgap1 ≥ 1 due to (17), (A4) and Gn ⊆ Gk for all 0 ≤ k ≤ n, the desired result follows from Lemma A.3.\nLemma A.10. Fix n1 ≥ N1. Then for all n ≥ n1,\n[Gn ∩ {ν∗n+1 ≥ 2}] ⊆ [ Gn ∩ { K2 ∥∥Emd2 (sn)∥∥ ≥ 23 }] .\nProof. The desired result follows from Lemma A.3 and (22).\nLemma A.11. Fix n1 ≥ N1. Then for all n ≥ n1,\n[Gn ∩ {ρ∗n+1 ≥ 1}]\n⊆ [ Gn ∩ { K1 ∥∥Emd1 (tn)∥∥ ≥ 14 }]∪\nn⋃ k=0 [ Gk ∩ { LθcK2 ∥∥Emd2 (sk)∥∥ ≥ 18 }] . Proof. Arguing as in the proof of Lemma A.9, the desired result follows from the second claim in Lemma A.6, first claim in Lemma A.3, (17), (A4), (22) and (A5).\nLemma A.12 (Bound Form for Event of Interest). Let n1 ≥ N1. Then\nEc(T ) ⊆Emid ∪ Eafter ⊆ [ ∞⋃ n=0 [ Gn ∩ { K1 ∥∥Emd1 (tn)∥∥ ≥ 14 }] ]\n∪ [ ∞⋃ n=0 [ Gn ∩ { K2 ∥∥Emd2 (sn)∥∥ ≥ 23 }] ] ∪ [ ∞⋃ n=0 [ Gn ∩ { LθcK2 ∥∥Emd2 (sn)∥∥ ≥ 18 }] ] .\nProof of Lemma A.12. This desired result follows from Lemma 4.1 and the Lemmas A.8, A.9, A.10, and A.11 put together.\nLastly, to provide the proof of our main technical theorem, we give the two following lemmas. For n ≥ 0, let an := ∑n−1 k=0 α 2 ke −2q1(tn−tk+1).\nLemma A.13 (Azuma-Hoeffding for Emd1 ). Fix δ > 0. Then for any n ≥ 0,\nPr { Gn, ∥∥Emd1 (tn)∥∥ ≥ δ} ≤ 2d2 exp(− δ2d3[Lmd1 ]2an ) .\nProof. Let Ak,n be the matrix ∫ tk+1 tk\ne−X1(tn−τ)dτ with Aijk,n denoting its i, j−th entry. Let M\n(1) k+1(j) denote the j−th entry of M (1) k+1. On Gn, 1Gk = 1 for all 0 ≤ k ≤ n. So\nPr { Gn, ∥∥Emd1 (tn)∥∥ ≥ δ} = Pr { Gn,\n∥∥∥∥∥ n−1∑ k=0 Ak,nM (1) k+11Gk ∥∥∥∥∥ ≥ δ }\n≤ Pr {∥∥∥∥∥ n−1∑ k=0 Ak,nM (1) k+11Gk ∥∥∥∥∥ ≥ δ }\n≤ d∑ i=1 d∑ j=1 Pr {∥∥∥∥∥ n−1∑ k=0 Aijk,nM (1) k+1(j)1Gk ∥∥∥∥∥ ≥ δd√d } ,\nwhere the last relation is due to the union bound applied twice. On Gk, K1 ∥∥∥M (1)k+1∥∥∥ ≤ Lmd1 . Hence, on Gk, for any i, j ∈ {1, . . . , d}, using (33),\n|Aijk,n| |M (1) k+1(j)| ≤ ‖Ak,n‖ ‖Mk+1‖\n≤ K1Lmd1 αke−q1(tn−tk+1).\nUsing ∑n−1 k=0 α 2 ke −2q1(tn−tk+1) ≤ an, the desired result now follows from the Azuma-Hoeffding inequality. For n ≥ 0, let bn := ∑n−1 k=0 β 2 ke −2q2(sn−sk+1).\nLemma A.14 (Azuma-Hoeffding for Emd2 ). Fix δ > 0. Then for any n ≥ 0,\nPr { Gn, ∥∥Emd2 (sn)∥∥ ≥ δ} ≤ 2d2 exp(− δ2d3[Lmd2 ]2bn ) .\nProof. The proof follows similarly to that of Lemma A.13.\nOur main technical result directly follows from Lemma A.12.\nProof of Theorem 4.2. The proof follows from Lemmas A.12, A.13 and A.14."
    }, {
      "heading" : "A.4 Proofs from Section 5",
      "text" : "We begin with a presentation of the RL framework in this section. A MDP is defined by the 5-tuple (S,A, P,R, γ) (Sutton, 1988), where S is the set of states, A is the set actions, P = P (s′|s, a) is the transition kernel, R(s, a, s′) is the reward function, and γ ∈ (0, 1) is the discount factor. In each time-step, the process is in some state sn ∈ S, an action an ∈ A is taken, the system transitions to a next state s′n ∈ S according to a transition kernel P (sn, an, s′n), and an immediate reward rn is received according to R(sn, an, s′n). Let policy π : S → A be a stationary mapping from states to actions and V π(s) = Eπ[ ∑∞ n=0 γ\nnrn|s0 = s] be the value function at state s w.r.t π. In our policy evaluation setting the goal is to estimate the MDP’s value function V π(s) with respect to a given π using linear regression, i.e., V π(s) ≈ θ>φ(s), where φ(s) ∈ Rd is a feature vector at state s, and θ ∈ Rd is a parameter vector. For brevity, we omit the notation π and denote φ(sn), φ(s′n) by φn, φ ′ n. Finally, we introduce the notation δn = rn + γθ > n φ ′ n − θ>n φn."
    }, {
      "heading" : "A.5 GTD2",
      "text" : "The GTD2 algorithm (Sutton et al., 2009b) minimizes the objective function\nJMSPBE(θ) = 12 (b−Aθ) >C−1(b−Aθ). (35)\nThe update rule of the algorithm takes the form of Equations (1) and (2) with\nh1(θ, w) = A >w,\nh2(θ, w) = b−Aθ − Cw,\nand\nM (1) n+1 = (φn − γφ′n)φ>nwn −A>wn ,\nM (2) n+1 =rnφn + φn[γφ ′ n − φn]>θn − φnφ>nwn\n− [b−Aθn − Cwn] .\nThat is, in case of GTD2 the relevant matrices in the update rules take the form Γ1 = 0, W1 = −A>, v1 = 0, and Γ2 = A, W2 = C, v2 = b. Additionally, X1 = Γ1 −W1W−12 Γ2 = A>C−1A. By our assumptions, both W2 and X1 are symmetric positive definite matrices, and thus the real part of their eigenvalues are also positive. It is also clear that\n‖M (1)n+1‖ ≤(1 + γ + ‖A‖)‖wn‖,\n‖M (2)n+1‖ =‖rnφn − b+ [A+ φn(γφ′n − φn)>]θn − [φnφ>n − C]wn‖\n≤1 + ‖b‖+ (1 + γ + ‖A‖)‖θn‖ + (1 + ‖C‖)‖wn‖.\nConsequently, Assumption A3 is satisfied with constants m1 = (1 + γ + ‖A‖) and m2 = 1 + max(‖b‖, γ + ‖A‖, ‖C‖)."
    }, {
      "heading" : "A.6 TDC",
      "text" : "The TDC algorithm is designed to minimize (35), just like GTD2.\nThe update rule of the algorithm takes the form of Equations (1) and (2) with\nh1θ(θ, w) = b−Aθ + [A> − C]w , h2(θ, w) = b−Aθ − Cw ,\nand\nM (1) n+1 =rnφn + φn[γφ ′ n − φn]>θn − γφ′φ>wn\n− [b−Aθn + [A> − C]wn] ,\nM (2) n+1 =rnφn + φn[γφ ′ n − φn]>θn − φnφ>nwn\n− [b−Aθn + Cwn] .\nThat is, in case of TDC, the relevant matrices in the update rules take the form Γ1 = A, W1 = [C − A>], v1 = b, and Γ2 = A, W2 = C, v2 = b. Additionally, X1 = Γ1 − W1W−12 Γ2 = A − [C − A>]C−1A = A>C−1A. By our assumptions, both W2 and X1 are symmetric positive definite matrices, and thus the real part of their eigenvalues are also positive. It is also clear that\n‖M (1)n+1‖ ≤2 + (1 + γ + ‖A‖)‖θn‖ + (γ + ‖A‖+ ‖C‖)‖wn‖,\n‖M (2)n+1‖ =2 + (1 + γ + ‖A‖)‖θn‖+ (1 + ‖C‖)‖wn‖ .\nConsequently, AssumptionA3 is satisfied with constants m1 = (2 + γ + ‖A‖ + ‖C‖) and m2 = (2 + γ + ‖A‖+ ‖C‖)."
    } ],
    "references" : [ {
      "title" : "Dynamic Programming and Optimal Control",
      "author" : [ "D.P. Bertsekas" ],
      "venue" : "Vol II. Athena Scientific, fourth edition,",
      "citeRegEx" : "Bertsekas,? \\Q2012\\E",
      "shortCiteRegEx" : "Bertsekas",
      "year" : 2012
    }, {
      "title" : "Convergent temporal-difference learning with arbitrary smooth function approximation",
      "author" : [ "Bhatnagar", "Shalabh", "Precup", "Doina", "Silver", "David", "Sutton", "Richard S", "Maei", "Hamid R", "Szepesvári", "Csaba" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Bhatnagar et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Bhatnagar et al\\.",
      "year" : 2009
    }, {
      "title" : "Stochastic approximation: a dynamical systems viewpoint",
      "author" : [ "Borkar", "Vivek S" ],
      "venue" : null,
      "citeRegEx" : "Borkar and S.,? \\Q2008\\E",
      "shortCiteRegEx" : "Borkar and S.",
      "year" : 2008
    }, {
      "title" : "The ode method for convergence of stochastic approximation and reinforcement learning",
      "author" : [ "Borkar", "Vivek S", "Meyn", "Sean P" ],
      "venue" : "SIAM Journal on Control and Optimization,",
      "citeRegEx" : "Borkar et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Borkar et al\\.",
      "year" : 2000
    }, {
      "title" : "Actor-Critic Algorithms",
      "author" : [ "Konda", "Vijaymohan" ],
      "venue" : "PhD thesis, Department of Electrical Engineering and Computer Science, MIT,",
      "citeRegEx" : "Konda and Vijaymohan.,? \\Q2002\\E",
      "shortCiteRegEx" : "Konda and Vijaymohan.",
      "year" : 2002
    }, {
      "title" : "On td (0) with function approximation: Concentration bounds and a centered variant with exponential convergence",
      "author" : [ "Korda", "Nathaniel", "Prashanth", "LA" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Korda et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Korda et al\\.",
      "year" : 2015
    }, {
      "title" : "Stochastic Approximation Algorithms and Applications",
      "author" : [ "Kushner", "Harold J", "Yin", "G. George" ],
      "venue" : null,
      "citeRegEx" : "Kushner et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Kushner et al\\.",
      "year" : 1997
    }, {
      "title" : "Method of variation of parameters for dynamic systems",
      "author" : [ "Lakshmikantham", "Vangipuram", "Deo", "Sadashiv G" ],
      "venue" : null,
      "citeRegEx" : "Lakshmikantham et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Lakshmikantham et al\\.",
      "year" : 1998
    }, {
      "title" : "Finite-sample analysis of proximal gradient td algorithms",
      "author" : [ "Liu", "Bo", "Ji", "Ghavamzadeh", "Mohammad", "Mahadevan", "Sridhar", "Petrik", "Marek" ],
      "venue" : "In UAI,",
      "citeRegEx" : "Liu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning to predict by the methods of temporal differences",
      "author" : [ "Sutton", "Richard S" ],
      "venue" : "Machine learning,",
      "citeRegEx" : "Sutton and S.,? \\Q1988\\E",
      "shortCiteRegEx" : "Sutton and S.",
      "year" : 1988
    }, {
      "title" : "A convergent o (n) temporal-difference algorithm for off-policy learning with linear function approximation",
      "author" : [ "Sutton", "Richard S", "Maei", "Hamid R", "Szepesvári", "Csaba" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "Sutton et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Sutton et al\\.",
      "year" : 2009
    }, {
      "title" : "Fast gradient-descent methods for temporal-difference learning with linear function approximation",
      "author" : [ "Sutton", "Richard S", "Maei", "Hamid Reza", "Precup", "Doina", "Bhatnagar", "Shalabh", "Silver", "David", "Szepesvári", "Csaba", "Wiewiora", "Eric" ],
      "venue" : "In Proceedings of the 26th Annual International Conference on Machine Learning,",
      "citeRegEx" : "Sutton et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Sutton et al\\.",
      "year" : 2009
    }, {
      "title" : "An emphatic approach to the problem of off-policy temporal-difference learning",
      "author" : [ "Sutton", "Richard S", "Mahmood", "A Rupam", "White", "Martha" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Sutton et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sutton et al\\.",
      "year" : 2015
    }, {
      "title" : "Ordinary differential equations and dynamical systems",
      "author" : [ "Teschl", "Gerald" ],
      "venue" : null,
      "citeRegEx" : "Teschl and Gerald.,? \\Q2004\\E",
      "shortCiteRegEx" : "Teschl and Gerald.",
      "year" : 2004
    }, {
      "title" : "A concentration bound for stochastic approximation via alekseev’s formula",
      "author" : [ "Thoppe", "Gugan", "Borkar", "Vivek S" ],
      "venue" : null,
      "citeRegEx" : "Thoppe et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Thoppe et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "In addition to convergence, there also exists a concentration result for the GTD family, though only for the single-timescale setting (Liu et al., 2015).",
      "startOffset" : 134,
      "endOffset" : 152
    }, {
      "referenceID" : 0,
      "context" : "It is known that A is positive definite (Bertsekas, 2012).",
      "startOffset" : 40,
      "endOffset" : 57
    } ],
    "year" : 2017,
    "abstractText" : "Two-timescale Stochastic Approximation (SA) algorithms are widely used in Reinforcement Learning (RL). Their iterates have two parts that are updated with distinct stepsizes. In this work we provide a recipe for analyzing two-timescale SA. Using it, we develop the first convergence rate result for them. From this result we extract key insights on stepsize selection. As an application, we obtain convergence rates for two-timescale RL algorithms such as GTD(0), GTD2, and TDC.",
    "creator" : "LaTeX with hyperref package"
  }
}