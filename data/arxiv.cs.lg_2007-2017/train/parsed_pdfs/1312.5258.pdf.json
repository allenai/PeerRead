{
  "name" : "1312.5258.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "On the Challenges of Physical Implementations of RBMs",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "000 001 002 003 004 005 006 007 008 009 010 011 012 013 014 015 016 017 018 019 020 021 022 023 024 025 026 027 028 029 030 031 032 033 034 035 036 037 038 039 040 041 042 043 044 045 046 047 048 049 050 051 052 053 054\n055 056 057 058 059 060 061 062 063 064 065 066 067 068 069 070 071 072 073 074 075 076 077 078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 100 101 102 103 104 105 106 107 108 109"
    }, {
      "heading" : "1. Introduction",
      "text" : "A restricted Boltzmann machine (Smolensky, 1986) is a generative model that has found widespread application (Hinton et al., 2006; Bengio, 2012; Coates and Ng, 2011). One of the main difficulties limiting its effectiveness is that the log likelihood of the model is intractable (Long and Servedio, 2010).\nThe model may be trained using sampling-based approximations to the gradient of the log likelihood (Younes, 1998; Tieleman, 2008) however, drawing a fair sample from the model is also intractable (Long and Servedio, 2010).\nDrawing samples from an RBM on a classical digital computer is an active area of research (Salakhutdinov, 2010a; Desjardins et al., 2010; Cho et al., 2010). Existing approaches are based on Markov chain Monte Carlo procedures. The cost of drawing a fair sample using a Monte-\nPreliminary work. Under review by the International Conference on Machine Learning (ICML). Do not distribute.\nFigure 1. The D-Wave chimera graph seen from two different perspectives. On left is the traditional 2D representation. Its bipartite nature allows us to see it as an RBM with limited connectivity (right part of the figure). Units were colored according to which part of the partition they belong to.\nCarlo Markov Chain (MCMC) method may be high if the number of steps required to get a good sample is high. This occurs in practice because some RBMs represent distributions with modes that are separated by regions of extremely low probability, which the Markov chain crosses only rarely. This is particularly problematic because it interacts with the learning procedure in a vicious circle: as training progresses, parameters (weights and biases) gradually become larger, corresponding to sharper probabilities (higher near training examples, and smaller elsewhere), i.e., corresponding to sharper modes separated by zones of lower probability. Since training procedures based on approximating the log-likelihood gradient require sampling from the model (usually by MCMC), as training progresses sampling becomes more difficult (mixing more slowly between modes, i.e., more samples would be required to achieve the same level of variance in the MCMC estimator of the gradient), making the gradient less reliable and ar X iv :1\n31 2.\n52 58\nv1 [\nst at\n.M L\n] 1\n8 D\nec 2\n01 3\n110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219\n0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 σsampling\n80\n100\n120\n140\n160\n180\n200\nT es\nt N\nL L\nes ti\nm at\nor\nσtraining = 0.05 σtraining = 0.0\nFigure 2. Test NLL estimator of two RBMs trained with different weights and bias noise distributions when Gaussian noise is applied to parameters during sampling. For each noise level, NLL was computed for 5 different seeds.\nthus slowing down training.\nOne possible workaround is to construct a physical system whose natural behavior is to take on states with the desired probability. It is then possible to obtain the desired samples by observing the behavior of the system, rather than explicitly performing computations to simulate the dynamics of such a system. We refer to this approach as “physical computation.” It is similar in spirit to “analog computation” but we find that term inappropriate in this case, since the sampled states remain digital. Note that this is different from the idea of building an RBM “in hardware”–we are not merely advocating the use of an FPGA that specializes in performing the kinds of digital computations used for simulating an RBM.\nPhysical computation is a strategy being actively pursued by D-Wave Systems1 and DARPA’s UPSIDE program2. In particular, the D-Wave Two system can be viewed as a physical implementation of an RBM. Most approaches to physical computation share the property that they greatly simplify the complexity of a task that is difficult for digital computers, but also introduce many limitations that digital computers do not share. For instance, any physical implementation of an RBM will likely face:\n• Noisy parameters 1http://www.dwavesys.com/en/\nproducts-services.html 2http://www.darpa.mil/Our_Work/MTO/ Programs/Unconventional_Processing_of_ Signals_for_Intelligent_Data_Exploitation_ (UPSIDE).aspx\n0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 σsampling\n100\n120\n140\n160\n180\nT es\nt N\nL L\nes ti\nm at\nor\nNoisy weights and biases Noisy weights Noisy biases\nFigure 3. Test NLL estimator of a regularly-trained RBM when Gaussian noise is applied to parameters during sampling. For each noise level, NLL was computed for 5 different seeds. Noise on biases has practically no effect on performance compared to noise on weights.\n• Limited parameter range\n• Restricted architecture\nThis paper aims at getting a better understanding of the effect of these constraints on the training and performance of the physical RBM and ultimately, of the feasibility of the physical approach. In particular, we would like to address the following questions:\n• Which constraint has the most degrading effect on performance?\n• Under which circumstances can an analog implementation of the RBM be reasonably trained?\n• Are there ways to mitigate the degrading effects of constraints imposed by physical computation?\nCurrently, the only physical implementation of an RBM available is the D-Wave Two System. It suffers from all three of the limitations we wish to study. In order to study each limitation in isolation, we performed a suite of feasibility studies using a simulated physical computer, that we implemented in software on a GPU. Using a simulation allows us to observe what happens when a physical computer has noisy parameters, but not limited parameter range or architecture restrictions, etc. Because these experiments are performed in simulation, we do not capture the benefit of physical computation: faster, less correlated samples. Instead, we aim to characterize the potential detriments of\n220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329\n(a) σtest = 0.00 (b) σtest = 0.05 (c) σtest = 0.10\n(d) σtest = 0.00 (e) σtest = 0.05 (f) σtest = 0.10\nFigure 4. Conditional expectation samples after 100,000 Gibbs steps for an RBM trained without noise (top row) and for an RBM trained with Gaussian noise of standard deviation σ = 0.05 applied to weights and biases (bottom row), for different levels of noise added to parameters during sampling.\nphysical computation. In particular, by studying each constraint in isolation, we are able to infer their relative effect on performance and thereby offer guidance for how both hardware and algorithm designers can best focus their efforts on those properties of physical computation that impose the greatest barriers to its practical use."
    }, {
      "heading" : "2. Background and related work",
      "text" : "In this section, we provide some background on RBMs and on the D-Wave Two system, including previous approaches to implementing RBMs using D-Wave systems."
    }, {
      "heading" : "2.1. Restricted Boltzmann machines",
      "text" : "A restricted Boltzmann machine (RBM) is a probabilistic graphical model that represents a probability distribution over a vector of visible units v ∈ {0, 1}D and a vector of latent variables (“hidden units”) h ∈ {0, 1}N . As an energy-based model, the RBM uses an energy function E to represent a probability mass function:\n0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 σtraining\n90\n100\n110\n120\n130\n140\n150\nT es\nt N\nL L\nes ti\nm at\nor\nFigure 5. Test NLL estimator computed by sampling with no added parameter noise from RBMs trained with various parameter noise levels. For each noise level, 5 models were trained using the same hyperparameters but different seeds.\n(a) σtrain = 0.10 (b) σtrain = 0.30 (c) σtrain = 0.70\nFigure 6. Conditional expectation samples after 100,000 Gibbs steps three RBMs trained with different parameter noise levels. Sampling was done without adding noise to parameters.\np(v,h) = e−E(v,h)\nZ , Z = ∑ ṽ,h̃ e−E(ṽ,h̃). (1)\nIn particular, the energy function is\nE(v,h) = −bTv − cTh− hTWv (2)\nThis particular form of energy makes the computation of\n330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383\n385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439\n10−3 10−2 10−1 100 101 102\nMaximal parameter magnitude\n80\n100\n120\n140\n160\n180\n200\n220\nT es\nt N\nL L\nes ti\nm at\nor\nFigure 7. Test NLL estimator computed by sampling from RBMs trained with various magnitude constraints. For each magnitude level, 5 models were trained using the same hyperparameters but different seeds.\n(a) Max. mag. = 1.0 (b) Max mag. = 0.1 (c) Max mag. = 0.001\nFigure 8. Conditional expectation samples after 100,000 Gibbs steps for three RBMs trained with different parameter magnitude constraints.\nconditional probabilities trivial:\np(v | h) = 1 1 + exp(−b−WT · h)\n= sigmoid(b+WT · h),\np(h | v) = 1 1 + exp(−c−W · v)\n= sigmoid(c+W · v),\n(3)\nAlthough conditional sampling in an RBM is trivial, sampling from p(v,h) or from p(v) cannot be done in a single step and requires the use of Monte Carlo Markov chains, which in general becomes computationally expensive if the parameters W , b, and c are configured in a way that makes the Markov chain mix slowly.\n0.01 0.03 0.05 0.07 0.09 σtraining\n0.25\n0.5\n1.0\n2.0\n4.0\nM ax\nim u\nm p\nar am\net er\nam p\nli tu\nd e\n100\n105\n110\n115\n120\n125\n130\n135\n140\nT es\nt N\nL L\nes ti\nm at\nor\nFigure 9. Test NLL estimator for combinations of noise and magnitude constraints. In all cases, we the model was evaluated using the same σ as it was trained with.\nRBM Learning and Inference Given some dataset V (vt ∈ V for 1 ≤ t ≤ T ), training an RBM is most commonly done via an approximation to the gradient of the log-likelihood with respect to the model parameters θi, elements of the parameter vector θ:\n∂\n∂θi\n( T∑\nt=1\nlog p(vt)\n) = −\nT∑ t=1 〈 ∂ ∂θi E(vt,h) 〉 p(h|vt)\n+ T\n〈 ∂\n∂θi E(v,h) 〉 p(v,h) .\nThe log-likelihood gradient has two contributions: one in the “positive phase” with the expectation over p(h | vt) the model’s conditional hidden unit distribution given the data; the other in the “negative phase” with the expectation over the model’s full joint distribution p(v,h).\nWhile the expectation over the conditional distribution in the clamped condition is straightforward to compute, the same cannot be said of the expectation over the joint distribution in the unclamped condition. The evaluation of this expectation is intractable for all but very small RBMs where the sum over either all states of the visible layer or all states of the hidden layer is feasible to compute. In practice, we commonly resort to an approximation to this expectation via sampling. The persistent contrastive divergence (PCD) algorithm (also known as stochastic maximum likelihood) (Younes, 1998; Tieleman, 2008) uses a persistent Gibbs (MCMC) sampling scheme that sequentially samples from the conditionals p(h | v) and p(v | h) to recover samples from the joint distribution. These samples are then used in a Monte Carlo approximation of the negative phase contribution of the log likelihood gradient.\n440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493\n495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549\n0.0 0.2 0.4 0.6 0.8 1.0 Proportion of removed connections\n80\n100\n120\n140\n160\n180\n200\nT es\nt N\nL L\nes ti\nm at\nor\nFigure 10. Test NLL estimator computed by sampling from RBMs trained with varying amounts of removed connections (selected at random) in order to simulate a constrained architecture. For each magnitude level, 5 models were trained using the same hyperparameters but different seeds.\nWhile PCD has established itself as probably the most popular method of maximizing log likelihood in RBMs, it suffers from one important weakness. In many situations, as learning progresses and the model parameters begin to increase in magnitude, the Gibbs sampler at the heart of the negative phase contribution of the gradient can suffer from poor mixing properties. Generally, it occurs when the hidden and visible activations become highly correlated. Poor mixing in the Gibbs sampling induced Markov chain leads to poor sample diversity which in turn leads to poor estimates of the negative phase statistics which ultimately lead to a poor approximation of the likelihood gradient. This problem can be somewhat mitigated by increasing sample diversity through the use of multiple Gibbs sampling steps between gradient updates (a method known as PCD-k, where k is the number of Gibbs steps between gradient updates). Other attempts to mitigate the negative phase mixing issue include the use of auxilliary parameters (Tieleman and Hinton, 2009) and tempering methods (Salakhutdinov, 2010b; Desjardins et al., 2010; Cho et al., 2010).\nThe promise of a physical implementation of the RBM, in the sense that we consider here, is that we entirely sidestep the difficult mixing problem that occurs in the negative phase of training by aquiring fair, uncorrelated samples directly from a physical simulation of the RBM. In the next section we review the D-wave machine, to our knowledge the only physical implementation of a RBM-like model in existence.\n(a) 0.10 (b) 0.80 (c) 0.99\nFigure 11. Conditional expectation samples after 100,000 Gibbs steps for three RBMs trained with different proportions of removed connections."
    }, {
      "heading" : "2.2. The D-Wave machine",
      "text" : "The D-Wave Two system implements an Ising model (Ising, 1925). Specifically, it implements a probability distribution over a state vector s ∈ {−1, 1}512 with a quadratic energy function\nE(s) = sTJs+ gT s\nwhere J is analogous to the weights of a Boltzmann machine and g is analogous to its biases. The set of Ising model distributions with {−1, 1} states is isomorphic to the set of Boltzmann machine distributions with {0, 1} states. The conversion between the parameters of the two model families is a linear mapping. An RBM with {0, 1} states h and v encoded with weights W and biases b and c can be converted to use {−1, 1} states via the mapping:\nW ′ =W/4, b′i = 0.5bi + ∑ j Wij ,\nc′i = 0.5ci + ∑ j Wji.\nOne can easily draw samples from a Boltzmann machine using the D-Wave Two just by performing this linear conversion of the parameters prior to requesting the sample. The choice of parameterization does affect the learning dynamics of the stochastic gradient descent training algorithm, and the Boltzmann parameterization is usually better, so it is generally best to regard the model as a Boltzmann machine even if the interface to the sampling hardware uses the Ising model parameterization.\nThe actual probability distribution sampled by the D-Wave Two deviates slightly from p(s) ∝ exp(−E(s)). Moreover, it is difficult to control the value of J or g precisely. Both of these effects can be approximated reasonably well\n550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603\n605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659\nFigure 12. Two different ways of mapping pixels of an image to visible units of an RBM having a chimera connectivity. Pixel blocks involves mapping adjacent 2-by-2 blocks of pixels to adjacent, fully-connected groups of units while respecting the relative positions of blocks of pixels. Extended pixel blocks based around the same principle but makes the pixel blocks overlap in hope of capturing more long-range relationships.\nby adding Gaussian noise to J and g. To simulate the DWave Two with reasonable accuracy, the noise should be added to J once each time the value of J is changed to a new unique value, but the noise on g should be resampled every time a new sample is drawn3. This is the approach we take in our GPU-based simulator of the D-Wave Two. (One complication we do not attempt to model is that if the same value of J is requested twice, the error on J should be the same both times–it is not truly noise, but rather a deterministic error that has a Gaussian distribution when compared over multiple points in J space) Other approaches to physical computation, such as those explored by DARPA’s UPSIDE program, face similar issues with noise.\nThe D-Wave Two also imposes restrictions on the magnitude of each individual element of A and g. This is common to most approaches to physical computation.\nFinally, many elements of A are constrained to be zero. This is because the various elements of the state vector are physically laid out in a 2-D grid, and only nearby elements can interact with each other. Specifically, the connectivity of the graphical model is constrained to be a chimera graph as illustrated in Fig. 1. We observe that this chimera graph can be partitioned to form a bipartite graph. Under\n3Andrew Berkley, D-Wave Principal Scientist, personal communication\n(a) Pixel blocks (b) Extended pixel blocks\nFigure 13. Conditional expectation samples after 100,000 Gibbs steps for two RBMs trained with a chimera connectivity pattern and a) a pixel blocks pixel-to-units mapping and b) an extended pixel blocks pixel-to-units mapping.\nsuch a partition, the D-Wave Two comes very close to being an RBM. The only difference between this model and an RBM is that the noise on the biases causes the biases to be random variables rather than parameters of the model.\nDenil and de Freitas (2011) have also explored the use of D-Wave hardware for training RBMs. Like our work, their work is primarily a feasibility study based on software simulations. Their approach differs from ours in three respects: 1) We partition the D-Wave machine into visible and hidden states using a partitioning that makes the chimera graph bipartite, so the hardware implements an RBM. Denil and de Freitas (2011) used a different partitioning that allowed visible-visible and hidden-hidden interactions. 2) We train using sampling-based approximations to the log likelihood gradient, while they train using empirical derivatives of an autoencoder-like cost function. 3) Our focus is on understanding how detrimental each of the limitations of the DWave hardware is in isolation, while Denil and de Freitas (2011) focus on devising an algorithm that works reasonably well with all limitations in place simultaneously."
    }, {
      "heading" : "3. Methodological notes",
      "text" : "All models in this paper were trained using PCD-5 with the standard MNIST training set. Training examples were binarized every time they were presented by sampling from a binomial distribution. Unless explicitly stated, all models were trained using the same hyperparameters.\nNegative log-likelihood of all models in this paper is approximated using AIS. When noise is added to parameters, the expected AIS is computed by Monte Carlo, with test examples binarized by following the same method as with training examples.\n660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713\n715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769"
    }, {
      "heading" : "4. Simulating limitations",
      "text" : "We now describe our experiments using simulations of physical computation."
    }, {
      "heading" : "4.1. Noisy parameters",
      "text" : "Consider the case where we have a trained RBM, and we would like to draw samples from it using physical computation. In this case, we know that the model parameters represent the desired distribution well. However, when loaded into the physical computer, the parameters may not be preserved exactly. We simulate this by adding Gaussian noise to the parameters.\nSee Fig. 3 for a summary of the experimental results in this case. We find that noise on biases has negligible effect on NLL compared to noise on weights. This could be explained by the fact that the particular model used for this figure has bias values an order of magnitude greater than weights values. In that case, we should get similar NLL if we use roughly the same ratio between noise standard deviation and mean parameter magnitude for weights and biases. For example, sampling with a noise standard deviation of 0.05 on weights leads to a 6.5% increase of the estimator NLL compared to the one we get when sampling without noise; in comparison, when sampling with bias noise whose noise-to-bias-magnitude matches the previous noise-to-weight-magnitude, the test NLL estimator increases 125% compared to the baseline. However, since bias magnitudes tend to be higher than weight magnitude, we’re unlikely to see a case in which noise on biases hurts more than noise on weights. From these tests, we can observe two things: 1) Adding noise to the model parameters degrades its performance moderately, and 2) Noise on the biases is less harmful than noise on the weights.\nOf course, these were parameters that were trained to work well in the absence of noise. It is possible to learn different parameters, that are chosen to diminish the effect of extra noise. In order to do this, we trained an RBM using the simulated physical computer to draw the negative phase samples during training. The negative phase repels the model parameters from regions that produced poor samples. Using noise on the parameters while generating the negative phase samples increases the range of the repulsion–not only must the parameters not generate bad samples, noisy versions of the parameters must not do so either.\nWe compared how RBM performance evolves as we increase parameter noise during sampling with that of the RBM trained without noisy parameters (Fig. 2). Both weights and biases had the same noise distribution applied to them.\nWe find that training with noisy parameters helps reducing the degrading effect of sampling with noisy parameters.\nFor instance, by training with σ = 0.05 on parameters and sampling with the same σ, we were able to reduce NLL estimator increase by 0.5% in average when compared to training without noise. Furthermore, the benefits of training with noisy parameters before sampling with noisy parameters extends to noise levels greater than what the RBM was trained with.\nThe effect of training with noisy parameters is also qualitatively visible when looking at conditional expectation samples (Fig. 4). We observe that adding noise to parameters during sampling increases visual noise in samples, and also makes samples collapse to major modes. By training with noisy parameters, we are able to soften these effects, even when sampling with parameter noise greater than training noise.\nAs for how much parameter noise an RBM can support during training, we trained RBMs using various noise levels on weights and biases and computed their test NLL estimator when sampling with no added noise (Fig. 5).\nA noise level of σ = 0.1 is the biggest noise we could add before the RBM’s performance noticeably started to degrade. Fortunately, the D-Wave Two’s noise levels are below that at σ = 0.05."
    }, {
      "heading" : "4.2. Limited parameter range",
      "text" : "We now turn our attention to the parameter range constraint. We trained RBMs by forcing their parameter magnitude to stay below a certain threshold value and observed the effect of that value on test NLL (Fig. 7). Whenever parameter updates would bring a parameter outside of that range, it was clipped to the threshold value.\nWe find that a magnitude constraint higher than or equal to 1.0 has little to no effect on performance, but that forcing parameter’s magnitude to be smaller than that quickly degrades performance. Samples tend to be more prone to mode blurring as we decrease the range of allowed parameter values (Fig. 8)."
    }, {
      "heading" : "4.3. Combining noise and limited parameter range",
      "text" : "We combined noise and magnitude constraints together to see how they interact. We explored constraint space around reasonable noise and magnitude values defined by the DWave Two’s specifications and looked at how they affect NLL (Fig. 9). The two constraints appear to work well together. In fact, a model with high noise and small parameter values performs nearly as well as a standard RBM. We think that the constraint on parameter values may actually be helpful, because they force the RBM to find good weight vector directions that generalize well, rather than just scaling up its weights to overpower the noise.\n770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823\n825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879"
    }, {
      "heading" : "4.4. Limited connectivity",
      "text" : "We trained RBMs by forcing a random subset of weights to be zero and observed how it would affect test NLL (Fig. 10).\nIt turns out the RBM can cope with a reasonable amount of removed connections: even when half the weights are forced to be zero, test NLL only increases by about 6.6%. However, physical implementations will likely have very sparse connectivity; for instance, the connectivity pattern of a D-Wave machine (Fig. 1) applied to an RBM with 784 visible units and 784 hidden units is so that over 99% of its connections are removed. In the aforementioned experiment, 99% removed connections translates to a disappointing 199.2± 0.1 test NLL.\nWhen looking at samples (Fig. 11), we observe that the RBM’s representative power decreases as we force more weights to be zero, up to a point where samples don’t look like digits anymore.\nOn the other hand, physical implementations of an RBM will most likely have some kind of structure to their connectivity pattern, which means the results we get by forcing a random subset of the weights to be zero are somewhat pessimistic.\nWhen we try training an RBM with 784 visible units and 784 hidden units having a chimera connectivity pattern, results are much better. There are many ways to map pixels of an image to visible units of the model; we tried two that seemed the most logical (Fig. 12). The pixel blocks mapping lead to a test NLL of 101.73, while the extended pixel blocks mapping lead to a test NLL of 118.31. When we look at samples from both RBMs (Fig. 13), we see that digit structure is much better preserved than when we randomly force the same proportion of weights to be zero, although samples still barely look like digits. In all cases, the limited architecture seems to be the most damaging constraint studied in this paper."
    }, {
      "heading" : "5. Conclusion",
      "text" : "In this paper, we have performed a series of simulation experiments to determine the feasible of implementing an RBM using physical computation. We have evaluated the impact of three barriers to the success of physical computation: noise on the model parameters, limited range on the model parameters, and limited topology of the model. We have found that noise on the parameters moderately impairs standard learning algorithms, though this can be mitigated by training using the same sampler in the negative phase as will be used to draw samples at test time. We have found that the limits on the range of the parameters do not significantly impair the performance of the RBM. Finally\nand most significantly, we have found that restrictions on the topology of the model can seriously impair its performance. While the D-Wave Two’s chimera topology does perform well for the number of connections it has, the overall number of connections is still low enough to cause many difficulties. This suggests that quantum hardware designers should concentrate their efforts on increasing the number of connections between elements in the quantum computers, and quantum machine learning researchers should focus their efforts on designing approaches that can cope with restricted topology."
    } ],
    "references" : [ {
      "title" : "Deep learning of representations for unsupervised and transfer learning",
      "author" : [ "Y. Bengio" ],
      "venue" : "JMLR W&CP: Proc. Unsupervised and Transfer Learning challenge and workshop, volume 27, pages 17–36.",
      "citeRegEx" : "Bengio,? 2012",
      "shortCiteRegEx" : "Bengio",
      "year" : 2012
    }, {
      "title" : "Parallel tempering is efficient for learning restricted Boltzmann machines",
      "author" : [ "K. Cho", "T. Raiko", "A. Ilin" ],
      "venue" : "Proceedings of the International Joint Conference on Neural Networks (IJCNN 2010), Barcelona, Spain.",
      "citeRegEx" : "Cho et al\\.,? 2010",
      "shortCiteRegEx" : "Cho et al\\.",
      "year" : 2010
    }, {
      "title" : "The importance of encoding versus training with sparse coding and vector quantization",
      "author" : [ "A. Coates", "A.Y. Ng" ],
      "venue" : "ICML’2011.",
      "citeRegEx" : "Coates and Ng,? 2011",
      "shortCiteRegEx" : "Coates and Ng",
      "year" : 2011
    }, {
      "title" : "Toward the implementation of a quantum rbm",
      "author" : [ "M. Denil", "N. de Freitas" ],
      "venue" : "NIPS*2011 Workshop on Deep Learning and Unsupervised Feature Learning.",
      "citeRegEx" : "Denil and Freitas,? 2011",
      "shortCiteRegEx" : "Denil and Freitas",
      "year" : 2011
    }, {
      "title" : "Tempered Markov chain Monte Carlo for training of restricted Boltzmann machine",
      "author" : [ "G. Desjardins", "A. Courville", "Y. Bengio" ],
      "venue" : "JMLR W&CP: Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2010), vol-",
      "citeRegEx" : "Desjardins et al\\.,? 2010",
      "shortCiteRegEx" : "Desjardins et al\\.",
      "year" : 2010
    }, {
      "title" : "A fast learning algorithm for deep belief nets",
      "author" : [ "G.E. Hinton", "S. Osindero", "Y. Teh" ],
      "venue" : "Neural Computation, 18, 1527–1554.",
      "citeRegEx" : "Hinton et al\\.,? 2006",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2006
    }, {
      "title" : "Beitrag zur Theorie des Ferromagnetismus",
      "author" : [ "E. Ising" ],
      "venue" : "Zeitschrift fur Physik, 31, 253–258.",
      "citeRegEx" : "Ising,? 1925",
      "shortCiteRegEx" : "Ising",
      "year" : 1925
    }, {
      "title" : "Restricted Boltzmann machines are hard to approximately evaluate or simulate",
      "author" : [ "P.M. Long", "R.A. Servedio" ],
      "venue" : "Proceedings of the 27th International Conference on Machine Learning (ICML’10).",
      "citeRegEx" : "Long and Servedio,? 2010",
      "shortCiteRegEx" : "Long and Servedio",
      "year" : 2010
    }, {
      "title" : "Learning deep Boltzmann machines using adaptive MCMC",
      "author" : [ "R. Salakhutdinov" ],
      "venue" : "L. Bottou and M. Littman, editors, Proceedings of the Twenty-seventh International Conference on Machine Learning (ICML10), volume 1, pages 943–950. ACM.",
      "citeRegEx" : "Salakhutdinov,? 2010a",
      "shortCiteRegEx" : "Salakhutdinov",
      "year" : 2010
    }, {
      "title" : "Learning in Markov random fields using tempered transitions",
      "author" : [ "R. Salakhutdinov" ],
      "venue" : "NIPS’2010.",
      "citeRegEx" : "Salakhutdinov,? 2010b",
      "shortCiteRegEx" : "Salakhutdinov",
      "year" : 2010
    }, {
      "title" : "Information processing in dynamical systems: Foundations of harmony theory",
      "author" : [ "P. Smolensky" ],
      "venue" : "D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing, volume 1, chapter 6, pages 194– 281. MIT Press, Cambridge.",
      "citeRegEx" : "Smolensky,? 1986",
      "shortCiteRegEx" : "Smolensky",
      "year" : 1986
    }, {
      "title" : "Training restricted Boltzmann machines using approximations to the likelihood gradient",
      "author" : [ "T. Tieleman" ],
      "venue" : "W. W. Cohen, A. McCallum, and S. T. Roweis, editors, ICML 2008, pages 1064–1071. ACM.",
      "citeRegEx" : "Tieleman,? 2008",
      "shortCiteRegEx" : "Tieleman",
      "year" : 2008
    }, {
      "title" : "Using fast weights to improve persistent contrastive divergence",
      "author" : [ "T. Tieleman", "G. Hinton" ],
      "venue" : "ICML’2009.",
      "citeRegEx" : "Tieleman and Hinton,? 2009",
      "shortCiteRegEx" : "Tieleman and Hinton",
      "year" : 2009
    }, {
      "title" : "On the convergence of Markovian stochastic algorithms with rapidly decreasing ergodicity rates",
      "author" : [ "L. Younes" ],
      "venue" : "Stochastics and Stochastics Models, pages 177– 228.",
      "citeRegEx" : "Younes,? 1998",
      "shortCiteRegEx" : "Younes",
      "year" : 1998
    } ],
    "referenceMentions" : [ {
      "referenceID" : 10,
      "context" : "A restricted Boltzmann machine (Smolensky, 1986) is a generative model that has found widespread application (Hinton et al.",
      "startOffset" : 31,
      "endOffset" : 48
    }, {
      "referenceID" : 7,
      "context" : "One of the main difficulties limiting its effectiveness is that the log likelihood of the model is intractable (Long and Servedio, 2010).",
      "startOffset" : 111,
      "endOffset" : 136
    }, {
      "referenceID" : 13,
      "context" : "The model may be trained using sampling-based approximations to the gradient of the log likelihood (Younes, 1998; Tieleman, 2008) however, drawing a fair sample from the model is also intractable (Long and Servedio, 2010).",
      "startOffset" : 99,
      "endOffset" : 129
    }, {
      "referenceID" : 11,
      "context" : "The model may be trained using sampling-based approximations to the gradient of the log likelihood (Younes, 1998; Tieleman, 2008) however, drawing a fair sample from the model is also intractable (Long and Servedio, 2010).",
      "startOffset" : 99,
      "endOffset" : 129
    }, {
      "referenceID" : 7,
      "context" : "The model may be trained using sampling-based approximations to the gradient of the log likelihood (Younes, 1998; Tieleman, 2008) however, drawing a fair sample from the model is also intractable (Long and Servedio, 2010).",
      "startOffset" : 196,
      "endOffset" : 221
    }, {
      "referenceID" : 8,
      "context" : "Drawing samples from an RBM on a classical digital computer is an active area of research (Salakhutdinov, 2010a; Desjardins et al., 2010; Cho et al., 2010).",
      "startOffset" : 90,
      "endOffset" : 155
    }, {
      "referenceID" : 4,
      "context" : "Drawing samples from an RBM on a classical digital computer is an active area of research (Salakhutdinov, 2010a; Desjardins et al., 2010; Cho et al., 2010).",
      "startOffset" : 90,
      "endOffset" : 155
    }, {
      "referenceID" : 1,
      "context" : "Drawing samples from an RBM on a classical digital computer is an active area of research (Salakhutdinov, 2010a; Desjardins et al., 2010; Cho et al., 2010).",
      "startOffset" : 90,
      "endOffset" : 155
    }, {
      "referenceID" : 13,
      "context" : "The persistent contrastive divergence (PCD) algorithm (also known as stochastic maximum likelihood) (Younes, 1998; Tieleman, 2008) uses a persistent Gibbs (MCMC) sampling scheme that sequentially samples from the conditionals p(h | v) and p(v | h) to recover samples from the joint distribution.",
      "startOffset" : 100,
      "endOffset" : 130
    }, {
      "referenceID" : 11,
      "context" : "The persistent contrastive divergence (PCD) algorithm (also known as stochastic maximum likelihood) (Younes, 1998; Tieleman, 2008) uses a persistent Gibbs (MCMC) sampling scheme that sequentially samples from the conditionals p(h | v) and p(v | h) to recover samples from the joint distribution.",
      "startOffset" : 100,
      "endOffset" : 130
    }, {
      "referenceID" : 12,
      "context" : "ing issue include the use of auxilliary parameters (Tieleman and Hinton, 2009) and tempering methods (Salakhutdinov, 2010b; Desjardins et al.",
      "startOffset" : 51,
      "endOffset" : 78
    }, {
      "referenceID" : 9,
      "context" : "ing issue include the use of auxilliary parameters (Tieleman and Hinton, 2009) and tempering methods (Salakhutdinov, 2010b; Desjardins et al., 2010; Cho et al., 2010).",
      "startOffset" : 101,
      "endOffset" : 166
    }, {
      "referenceID" : 4,
      "context" : "ing issue include the use of auxilliary parameters (Tieleman and Hinton, 2009) and tempering methods (Salakhutdinov, 2010b; Desjardins et al., 2010; Cho et al., 2010).",
      "startOffset" : 101,
      "endOffset" : 166
    }, {
      "referenceID" : 1,
      "context" : "ing issue include the use of auxilliary parameters (Tieleman and Hinton, 2009) and tempering methods (Salakhutdinov, 2010b; Desjardins et al., 2010; Cho et al., 2010).",
      "startOffset" : 101,
      "endOffset" : 166
    }, {
      "referenceID" : 6,
      "context" : "The D-Wave Two system implements an Ising model (Ising, 1925).",
      "startOffset" : 48,
      "endOffset" : 61
    } ],
    "year" : 2017,
    "abstractText" : "Restricted Boltzmann machines (RBMs) are powerful machine learning models, but learning and some kinds of inference in the model require sampling-based approximations, which, in classical digital computers, are implemented using expensive MCMC. Physical computation offers the opportunity to reduce the cost of sampling by building physical systems whose natural dynamics correspond to drawing samples from the desired RBM distribution. Such a system avoids the burn-in and mixing cost of a Markov chain. However, hardware implementations of this variety usually entail limitations such as lowprecision and limited range of the parameters and restrictions on the size and topology of the RBM. We conduct software simulations to determine how harmful each of these restrictions is. Our simulations are designed to reproduce aspects of the D-Wave quantum computer, but the issues we investigate arise in most forms of physical computation.",
    "creator" : "LaTeX with hyperref package"
  }
}