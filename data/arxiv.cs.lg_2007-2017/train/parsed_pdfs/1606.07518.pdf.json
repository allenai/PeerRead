{
  "name" : "1606.07518.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "On the Solvability of Inductive Problems: A Study in Epistemic Topology",
    "authors" : [ "Alexandru Baltag", "Nina Gierasimczuk", "Sonja Smets" ],
    "emails" : [ "A.Baltag@uva.nl", "Nina.Gierasimczuk@gmail.com", "S.J.L.Smets@uva.nl" ],
    "sections" : [ {
      "heading" : null,
      "text" : "R. Ramanujam (Ed.): TARK 2015 EPTCS 215, 2016, pp. 81–98, doi:10.4204/EPTCS.215.7\nc© A. Baltag, N. Gierasimczuk & S. Smets This work is licensed under the Creative Commons Attribution License."
    }, {
      "heading" : "On the Solvability of Inductive Problems: A Study in",
      "text" : "Epistemic Topology\nAlexandru Baltag Nina Gierasimczuk Sonja Smets Institute for Logic, Language and Computation\nUniversity of Amsterdam, The Netherlands\nA.Baltag@uva.nl Nina.Gierasimczuk@gmail.com S.J.L.Smets@uva.nl\nWe investigate the issues of inductive problem-solving and learning by doxastic agents. We provide topological characterizations of solvability and learnability, and we use them to prove that AGM-style belief revision is “universal”, i.e., that every solvable problem is solvable by AGM conditioning."
    }, {
      "heading" : "1 Introduction",
      "text" : "When in the course of observations it becomes necessary for agents to arrive at a generalization, they should declare, along with their conjecture, the extent of their certainty. The problem of induction seems formidable if a standard of absolute certainty is imposed on the learner. Indeed, as is well-known in Philosophy of Science, the so-called problem of empirical underdetermination (i.e., the fact that typically the data are compatible with more than one hypothesis) rules out any chance of obtaining infallible knowledge in empirical research. But apart from the conclusions based on absolute certainty (cf. [13, 10, 15]), learners can produce hypotheses based on beliefs. It is thus strange that Formal Learning Theory and Belief Revision Theory developed completely independently from each other, and that they have generally maintained their distance ever since.\nHowever, there does exist a line of research that combines belief revision with learning-theoretic notions, line pursued by Kelly [21, 26], Kelly, Schulte and Hendricks [19], Martin and Osherson [28] and ourselves [13, 3, 4, 14]. In this paper we continue this research program, using topological characterizations and methods.\nAn inductive problem consists of a state space, a family of “potential observations”, and a “question” (i.e., a partition of the state space). These observations provide data for learning. The problem is solvable if there exists a learner that, after observing “enough” pieces of data, eventually stabilizes on the correct answer. A special case of solvability is learnability in the limit, corresponding to the solvability of the “ultimate” question: ‘What is the actual state of the world?’. This notion matches the usual learningtheoretic concept of identifiability in the limit [31, 16, 29].\nThe aim of the paper is twofold. First, we give topological characterizations of the notions of solvability (and learnability), in terms of topological separation principles. Intuitively, the ability to reliably learn the true answer to a question, is related to the possibility to “separate” answers by observations. The second goal is to use these topological results to look at the “solving power” of well-behaved doxastic agents, such as the ones whose beliefs satisfy the usual KD45 postulates of doxastic logic, as well as the standard AGM postulates of rational belief-revision [1]. We look at a particularly simple and canonical type of doxastic agent, who forms beliefs by AGM conditioning.\nOur main result is that AGM conditioning is universal for problem-solving, i.e., that every solvable problem can be solved by AGM conditioning. This means that (contrary to some prior claims), AGM\nbelief-revision postulates are not an obstacle to problem-solving. As a special case, it follows that AGM conditioning is also “universal for learning” (every learnable space can be learned by conditioning).1\nThe close connections between Epistemology and General Topology have already been noticed long ago [32, 20]. Based on these connections, Kevin Kelly started a far-reaching program [20, 22] meant to import ideas and techniques from both Formal Learning Theory and Topology into mainstream Epistemology, and show their relevance to the induction problem in Philosophy of Science. A further connection is the one with Ockham’s Razor, that would\n(...) guarantee that always choosing the simplest theory compatible with experience and hanging on to it while it remains the simplest is both necessary and sufficient for efficiency of inquiry. [22]\nSimplicity has been claimed to have topological characteristics—the simplicity order should in some way follow the structure imposed on the uncertainty range by possible tests and observations. It has also been linked with the notion of minimal mind change, where the learning agent keeps the conjecture changes to a minimum [20, 30].\nTaken together, our results can be seen as a vindication both of the general topological program in Inductive Epistemology [20, 22] and of the AGM Belief Revision Theory [1]. On the first front, our general topological characterizations of learning-theoretic concepts seem to confirm Kelly’s longstanding claim that Inductive Epistemology can be seen mathematically as a branch of General Topology. On the second front, our universality result seems to vindicate Belief Revision Theory as a canonical form of learning.2"
    }, {
      "heading" : "2 Epistemic Spaces and Inductive Problems",
      "text" : "Definition 1. An epistemic space is a pair S = (S,O) consisting of a state space S and a countable (or finite) set of observable properties (“data”) O ⊆ P(S). We denote by by Os := {O ∈ O | s ∈ O} the set of all observable properties (holding) at a given state s.\nOne can think of the states in S as “possible worlds”, in the tradition of Kripke and Lewis. The sets O ∈ O represent properties of the world that are in principle observable: if true, such a property will eventually be observed (although there is no upper bound on the time needed to come to observe it).\nTo keep things simple, we assume that at each step of the learning process only one property is observed. As for the countability of the set O , it is natural to think of observables as properties which can be expressed by means of a language or numerical coding system, generated from a grammar with a finite vocabulary. Any such family O will be (at most) countable.\nWe denote by O∩ the family of all finite intersections of observations from O , and by O∗ the family of all finite sequences of observations. Such a finite sequence σ = (O0,O1, . . . ,Oi) ∈ O∗ is called a data sequence, and its i-th component is denoted by σi := Oi. It is easy to see that both O∩ and O∗ are countable.\nA data stream is a countable sequence ~O = (O0,O1, . . .) ∈ Oω of data from O (here, ω is the set of natural numbers, so Oω is the set of all maps assigning an observable property to every natural number). We use the following notation: ~On is the n-th element in ~O; ~O[n] is the initial segment of ~O of length n,\n1This special case is a topological translation of one of our previous results [3, 4]. However, the result about problemsolving universality is not only new and much more general, but also much harder to prove, involving new topological notions and results.\n2And in the same time (if we adopt a “simplicity” interpretation of the prior), this last result can be seen as a vindication of Ockham’s razor (in line with Kevin Kelly’s program).\n(O0, . . . ,On−1); set(~O) := {O | O is an element of ~O} is the set of all data in ~O; ∗ is the concatenation operator on strings.\nThe intuition is that at stage n of a data stream, the agent observes the information in On. A data stream captures a possible future history of observations in its entirety, while a data sequence captures only a finite part of such a history.\nGiven a state s ∈ S, a data stream for s is a stream ~O ∈ Oω such that Os = {O ∈ O | ⋂n\ni=0 Oi ⊆ O for some n ∈ ω}. Such a stream is “sound” (every data in ~O is true at s) and “complete” (every true data is entailed by some finite set of observations in ~O).\nExample 1. Let our epistemic space S = (S,O) be the real numbers, with observable properties given by open intervals with rational endpoints: S := R, O := {(a,b) | a,b ∈ Q,a ≤ b}, where (a,b) := {x ∈ R | a < x < b}. For instance, observables may represent measurements of a physical quantity (such as a position along a one-dimensional line) that takes real numbers as its possible values. In such case, for any state x ∈ R and any two sequences an,bn ∈ Q of rational numbers, such that an ≤ x ≤ bn and both sequences converge to x, the sequence (a0,b0), . . . ,(an,bn), . . . is a (sound and complete) data stream for x.\nOther examples include standard n-dimensional Euclidean spaces, e.g., S = R3 with O consisting of all open balls with rational radius and center.\nDefinition 2. An inductive problem is a pair P = (S,Q) consisting of an epistemic space S = (S,O) together with a “question” Q, i.e., a partition3 of S. The cells Ai of the partition Q are called answers. Given s ∈ S, the unique A ∈ Q with s ∈ A is called the answer to Q at s, and denoted As. We say that a problem P′ = (S,Q′) is a refinement of another problem P= (S,Q) (or that the corresponding question Q′ is a refinement of the question Q) if every answer of Q is a disjoint union of answers of Q′.\nThe most refined question concerns the identity of the real world.\nExample 2. The learning question on a space S is Q = {{s} | s ∈ S} and corresponds to ‘What is the actual state?’.\nExample 3. Let S= (S,O), where S = {s, t,u,v), O = {U,V,P,Q}, with U = {s, t}, V = {s}, P = {u,v}, Q = {u}. Take the problem P = (S,Q), given by the question Q = {{t,u},{s,v}} depicted on the lefthand side of Figure 1. This can obviously be refined to obtain the problem P′ = (S,Q′) given by the learning question Q = {{s},{t},{u},{v}} for this space, as depicted on the right-hand side of Figure 1.\n3This means that ⋃\ni∈I Ai = S, and Ai ∩A j = /0 for all i 6= j."
    }, {
      "heading" : "3 Learning and Problem-Solving",
      "text" : "Definition 3. Let S = (S,O) be an epistemic space and let σ0, . . . ,σn ∈ O . An agent (also called a “learner”, or a “learning method”) is a map L that associates to any epistemic space S and any data sequence (σ0, . . . ,σn) some family LS(σ0, . . . ,σn) ⊆ P(S) of subsets of S, satisfying a “consistency” condition: /0 6∈ LS(σ0, . . . ,σn) whenever ⋂n i=o σi 6= /0.\nIntuitively, after observing the data sequence ~σ = (σ0, . . . ,σn), we can say that agent L believes a proposition P after observing the data sequence ~σ = (σ0, . . . ,σn), and write B~σL P iff P∈LS(σ0, . . . ,σn). We can also interpret this as a conditional belief, rather than as revised belief, the agent believes every P ∈ LS(σ0, . . . ,σn) conditional on σ0, . . . ,σn. However, in the end we are of course interested in the actual revised beliefs after observing the data, so the assumption in this case is that conditional beliefs guide the agent’s revision strategy: they “pre-encode” future belief revisions, to use a term coined by Johan van Benthem [6]. The above consistency simply means that each of the agent’s beliefs is consistent whenever the observed data are consistent.\nA doxastic agent is one whose set LS(σ0, . . . ,σn) of beliefs forms a (proper) filter on S when observing consistent data; in other words, her beliefs are (consistent when possible, and also) inferenceclosed (i.e., if P ⊆ Q and P ∈ LS(σ0, . . . ,σn), then Q ∈ LS(σ0, . . . ,σn)) and conjunctive (i.e., if P,Q ∈ LS(σ0, . . . ,σn) then (P ∩ Q) ∈ LS(σ0, . . . ,σn)). Hence, for any doxastic agent L and every consistent data sequence ~σ , the belief operator B~σ\nL (as defined above) satisfy the usual KD45 axioms of\ndoxastic logic. A standard agent is a doxastic agent L whose beliefs form a principal filter, i.e., all her beliefs are entailed by one “strongest belief”; formally, a doxastic agent L is standard iff for every data sequence ~σ over any epistemic space S there exists some set LS(~σ), such that\nLS(~σ) = {P ⊆ S | LS(~σ)⊆ P}.\nIt is easy to see that in this case, we must have LS(~σ) = ⋂ LS(~σ). Indeed, we can equivalently define a doxastic agent L to be standard iff ⋂\nLS(~σ) ∈ LS(~σ) holds for all data sequences ~σ . Standard agents are globally consistent whenever possible: ⋂ LS(σ0, . . . ,σn) 6= /0 whenever ⋂n\ni=o σi 6= /0. Traditional learning methods in Formal Learning Theory correspond to our standard agents, and they\nare typically identified with the map L (given by LS(σ0, . . . ,σn) := ⋂ LS(σ0, . . . ,σn)). From now on we follow this tradition, and refer to standard agents using the map L. But in general we do not restrict ourselves to standard agents.\nAn AGM agent is an agent L ≤ who forms beliefs by AGM conditioning, i.e., it comes endowed with a map that associates any epistemic space S some total preorder4 ≤S on S, called “prior” plausibility relation; and whose beliefs after observing any data sequence ~σ = (σ0, . . . ,σn) are given by\nL ≤ S (~σ) := {P ⊆ S | ∃s ∈\nn ⋂\ni=0\nσi ∀t ∈ n ⋂\ni=0\nσi (t ≤ s ⇒ t ∈ P)}.\nIntuitively, t ≤ s means that t is at least as plausible as s (according to our agent). So, an AGM agent believes P conditional on a data sequence ~σ iff P is true in all the states (consistent with the data) that are “plausible enough”.\n4A total preorder on S is a binary relation ≤ on S that is reflexive, transitive, and connected (i.e., for all s, t ∈ S, we have either s ≤ t or t ≤ s).\nIt is easy to see that every AGM agent is a doxastic agent: L ≤ S (~σ) is a proper filter whenever ⋂n i=0 σi 6= /0; hence, the beliefs of an AGM agent satisfy the usual KD45 axioms of doxastic logic (when learning any consistent data sequence). Moreover, it is well-known that in fact, the beliefs of AGM agents satisfy all the so-called AGM axioms from Belief Revision Theory [1]: if, for any data sequence ~σ = (σ0, . . . ,σn), we set T = L (σ0, . . . ,σn), and for any new observation φ ∈ O we set T ∗ φ = L (σ0, . . . ,σn,φ), then the resulting revision operator ∗ satisfies all the AGM postulates. In fact, for any AGM agent L , if we interpret the operator B~σ\nL (as defined above) as representing a conditional belief Bσ0∧...∧σn , then the sound and\ncomplete logic of these conditional belief operators is the so-called Conditional Doxastic Logic [8, 5] (which is itself just a repackaging of the AGM postulates in the language of conditional logic).\nObservation 1. Given a total preorder ≤ on S and a subset A ⊆ S, set\nMin≤(A) := {s ∈ A | s ≤ t for all t ∈ A}\nfor the set of ≤-minimal states in A. Let ~σ = (σ0, . . . ,σn) be any data sequence such that Min≤( ⋂n i=0 σi) 6= /0. Then L ≤ S (~σ) is the principal filter generated by Min≤( ⋂n i=0 σi), i.e., we have\nL ≤ S (σ0, . . . ,σn) := {P ⊆ S | Min≤(\nn ⋂\ni=0\nσi)⊆ P}.\nIn general though, the filter L ≤ S (~σ) is not principal. So AGM agents are not necessarily standard agents. But there is an important case when they are standard: whenever the preorder ≤S is well-founded in every space S (i.e., there are no infinite chains s0 > s1 > s2 . . . of more and more plausible states). It is easy to see that the map L associated to a standard AGM agent is given by the set of ≤-minimal states consistent with the data:\nL≤ S (σ0, . . . ,σn) := Min≤(\nn ⋂\ni=0\nσi).\nIntuitively, this means that a standard AGM agent believes a proposition P iff P is true in all the “most plausible” states consistent with the data.\nThe original semantics of AGM belief was given using only standard AGM agents. But this semantics was in fact borrowed by Grove [18] from Lewis’ semantics for conditionals [27], which did not assume well-foundedness.5\nDefinition 4. Let S be an epistemic space. An agent L verifies a proposition A ⊆ S in the limit if, for every state s ∈ S and every data stream ~O for s, we have s ∈ A iff there exists some k ∈ ω such that A ∈ LS(~O[n]) for all n ≥ k. For standard agents, this means that LS(~O[n])⊆ A for all n ≥ k. A set A ⊆ S is verifiable in the limit if there exists some agent that verifies A in the limit.6\nAn agent L falsifies a proposition A ⊆ S in the limit if, for every state s ∈ S and every data stream for ~O for s, we have s /∈ A iff there exists some k ∈ ω such that Ac ∈ L (S, ~O[n])⊆ Ac for all n ≥ k (here, as in the rest of this paper, X c := S\\X stands for the complement of X). For a standard agent, this means L(S, ~O[n])⊆ Ac for all n ≥ k,\nA proposition A ⊆ S is falsifiable in the limit if there exists some agent that falsifies A in the limit. A proposition A ⊆ S is decidable in the limit if it is both verifiable and falsifiable in the limit.\n5Indeed, Lewis’ definition of conditionals has a similar shape to our above definition of (conditional) beliefs for non-standard AGM agents.\n6For a discussion of the relationship between verifiability and learnability see, e.g., [20, 12].\nAn agent L solves a problem P= (S,Q) if, for every state s ∈ S and every data stream ~O for s, there exists some k ∈ ω such that As ∈ LS(~O[n]) for all n ≥ k (recall that As is true answer to Q at s). For a standard agent, this means that LS(~O[n]) ⊆ As for all n ≥ k. A problem is solvable (in the limit) if there exists some agent that solves it.\nAn epistemic space S = (S,O) is learnable (by an agent L ) if the (problem given by the) learning question QS = {{s} | s ∈ S} is solvable (by L ).\nAll the above notions have a standard counterpart, e.g., A is standardly verifiable if there exist some standard agent that verifies it; P is standardly solvable if it can be solved by some standard agent, etc.\nNote that standard learnability is essentially the same as Gold’s identifiability in the limit [29, 17]. Examples and Counterexamples: An example of non-learnable space S= (S,O) is obtained by taking four abstract states S = {s, t,u,w} and two observable properties O = {V,U}, with V = {s, t,u} and U = {t,u,w}, as depicted in Figure 2. Since states s and t satisfy the same observable properties, no learning method will ever distinguish them.\nBut even spaces in which no two states satisfy the same observations can still be non-learnable, e.g., all the n-dimensional Euclidean spaces from Example 1 are not learnable (though, as we will see, many questions are solvable and many subsets are decidable over these spaces). Another example of non-learnable space is given in Figure 3: formally, S = (S,O), where S := {sn | n ∈ ω}∪ {s∞}, and O = {Oi | i ∈ ω}, and for any i ∈ ω , Oi := {si,si+1, . . .}∪{s∞}.\nIn contrast, an example of learnable space is in Figure 4: formally, S = {sn | n ∈ ω} consists of countably many distinct states, with O = {On | n ∈ ω}, where On = {s0,s1,s2, . . . ,sn}. A standard agent that can learn this space in the limit is given by setting L(σ1, . . . ,σn) to be the maximum number (in the natural order) in\n⋂n i=0 σi, whenever there is such a maximum number, and setting L(σ1, . . . ,σn) :=\n⋂n i=0 σi otherwise.\nProposition 1. Let S be an epistemic space, A ⊆ S a proposition and P = (S,Q) an inductive problem. Then we have the following:\n• A is verifiable (falsifiable, decidable) in the limit iff it is standardly verifiable (falsifiable, decidable) in the limit.\n• P is solvable iff it is standardly solvable.\n• S is learnable iff it is standardly learnable.\nProof. Let A ⊆ S be a set that is verifiable (falsifiable, decidable) by an agent L on an epistemic space S. We construct a standard agent that does the same thing, by setting, for every data sequence ~σ ∈ O∗: LS(~σ) := A if A ∈ LS(~σ), LS(~σ) := Ac if A 6∈ LS(~σ) but Ac ∈ LS(~σ), and LS(~σ) := S otherwise. Also, on any other space S′ = (S′,O ′), we set by default LS′(~σ ′) := S′.\nSimilarly, let P = (S,Q) be a problem that is solvable by L . Let ≤ be some arbitrary well-order of the set Q. (Such a well-order exists, by the Well-Ordering Theorem.) We construct a standard agent who also solves P, by setting LS(~σ) := A if A is the first answer in Q (according to ≤) such that A ∈ LS(~σ) holds; and LS(~σ) := S if no such answer exists. (As before, we can extend our agent to any other space S′ = (S′,O ′), by setting LS′(~σ ′) := S′.)\nBy applying this to the learning problem Q = {{s} | s ∈ S}, we obtain the similar result for learnability.\nIn conclusion, everything that can be learned by any agent can also be learned by some standard agent. However, this is no longer true when we restrict to more canonical types of agents (such as AGM agents).\nProposition 2. There exist spaces that are learnable, but not learnable by standard AGM agents. Hence, there exist solvable problems that are not solvable by standard AGM agents.\nProof. Consider a counterexample from [13, 3, 4]. Take the epistemic model from Figure 4. This space is learnable, and thus learnable by AGM conditioning, but it is not learnable by standard conditioning. Indeed, this space is learnable by conditioning only with respect to the following non-wellfounded prior: s0 > s1 > .. . > sn > sn+1 > .. ."
    }, {
      "heading" : "4 The Observational Topology",
      "text" : "In this section, we assume familiarity with the following notions: topology τ (identified with its family of open subsets) over a set S of points, topological space (S,τ), open sets, closed sets, interior Int(X) and closure X of a set X , (open) neighborhood of a point s, base of a topology and local base (of neighborhoods) at a point. We use letters U , U ′, etc., for open sets in τ , and letters C, C′, etc., for closed sets.\nA space is said to be second-countable if its topology has a countable base. Given a topological space (S,τ), the specialization preorder ⊑⊆ S×S is defined in the following way: for any s, t ∈ S, we set\ns ⊑ t iff ∀U ∈ τ (s ∈U ⇒ t ∈U).\nSeparation Principles. In this paper we use four key topological separation notions. The first is the well-known separation axiom T 0, which will be satisfied by all the topologies that arise in our setting. The second is the separation axiom T D. This condition (together with countability) will be shown to characterize learnable spaces. The next two notions are analogues of T D separation for questions. Instead of asking for open sets that separate points (states), these conditions require the existence of open sets that separate answers (to the same question). The concept of locally closed questions is a first analogue of T D, and it will be shown to characterize in some sense solvable problems. Finally, the notion of linearly separated questions is a stronger analogue of T D for questions, which characterizes a stronger type of solvability, what we will call direct solvability by (AGM) conditioning.\nDefinition 5. A topological space (S,τ) satisfies the separation axiom T 0 if the specialization preorder is actually a partial order, i.e., it is antisymmetric: s ⊑ t ⊑ s implies s = t. Equivalently, if s 6= t, then there exists some “separating” open U, such that either s ∈U, t 6∈U, or s 6∈U, t ∈U.\nThe space (S,τ) satisfies the separation axiom T D iff for every point s ∈ S, there is an open Ux ∋ x such that y 6⊑ x for all y ∈ Ox \\ {x}. Equivalently: for every s ∈ S there is an open U ∈ τ such that {s} =U ∩{s}.\nEssentially, T 0 says that every two points s 6= t can be separated (by an open U ) one way or another (i.e., either s ∈U , t 6∈U , or s 6∈U , t ∈U ), while T D essentially says that every point s can be separated (by an open neighborhood) from all the points t 6= s that are inseparable from s.7\nDefinition 6. Given a topological space (S,τ), a set A ⊆ S is locally closed if it is the intersection A =U ∩C of an open set U with a closed set C. Equivalently, if it is of the form A =U ∩A for some open U.\nA set is ω-constructible if it is a countable union of locally closed sets. A question Q (partition of S) is locally closed if all its answers are locally closed. A problem P is\nlocally closed if its associated question is locally closed.\nEssentially, locally closed questions are partitions with the property that every “answer” (i.e., partition cell) A can be separated (by an open neighborhood) from all the non-A-states that are inseparable from A.8\nDefinition 7. A question Q is linearly separated if there exists some total order E on the answers in Q, such that A∩ ⋃\nB⊳A B = /0. In other words, every answer A can be separated (by some open UA ⊇ A) from the union of all the previous answers: UA ∩B = /0 for all B⊳A.\nEssentially, a linearly separated question is one whose answers can be totally ordered by a “plausibility” (or “simplicity”) order, in such a way that every answer A can be separated (by an open neighborhood UA ⊇ A) from all answers that are “more plausible” (or “simpler”) than A.\nDefinition 8. The observational topology τS associated with an epistemic space S= (S,O) is the topology generated by O (i.e., the smallest collection of subsets of S, that includes O ∪{ /0,S} and is closed under finite intersections and arbitrary unions).\nFrom now on, we will always implicitly consider our epistemic spaces S to also be topological spaces (S,τS), endowed with their observational topology τS. Every topological property possessed by the associated topological space will thus be also attributed to the epistemic space.\n7A point y is “inseparable” from x if every open neighborhood of y contains x, i.e., y and x are in the topological refinement order y ⊑ x.\n8Here, a state t is said to be “inseparable” from a set A if there is no open neighborhood U ∋ t that is disjoint from A.\nObservation 2. Every epistemic space is T 0 and second-countable. A (sound and complete) data stream for s is the same as a local neighborhood base at s.\nProposition 3. Every ω-constructible set can be written as a disjoint countable union of locally closed sets.\nProof. In order to prove this, we first recall some standard topological notions and results: A set is called constructible if it is a finite disjoint union of locally closed sets. Obviously, all locally closed sets are constructible. It is known that constructible sets form a Boolean algebra, i.e., the family of constructible sets is closed under complementation, finite unions, and finite intersections.\nSuppose A = ⋃\ni∈ω Ai, where all Ai are locally closed. Then we can rewrite A as a disjoint union A = ⋃\ni∈ω Bi, where we have set Bi = Ai \\ ( ⋃ k<i Ak) = Ai ∩ ⋂ k<i A c k, for every i. Since Bi’s are generated from locally closed sets using complementation and finite intersections, they must be constructible. Hence, each Bi can be written as disjoint finite unions of locally closed sets Bi = ⋃\n1≤ j≤i Bi j. Hence, we can write A = ⋃\ni∈ω ⋃ 1≤ j≤i Bi j as a disjoint countable union of locally closed sets.\nDefinition 9. A pseudo-stratification is a finite or ω-long sequence of locally closed sets 〈Ai | i < λ 〉 (where λ ∈ ω ∪{ω}), which form a partition of S satisfying the following condition:\nif j < i then either Ai ∩A j = /0 or Ai ⊆ A j.\nProposition 4. Every countable locally closed question can be refined to a pseudo-stratification.\nProof. Suppose Π = {Ai | i ∈ ω} is a countable locally closed question (partition of S). We first show the following:\nClaim. There exists a family {(Πi,<i) | i ∈ ω}, satisfying (1) each Πi is a finite partition of Ai into locally closed sets;\n(2) each <i is a total order on Πi; (3) if j < i, E ∈ Π j, B ∈ Πi, then either B ⊆ E or B ⊆ E c ; (4) if B,E ∈ Πi, E <i B, then B ⊆ E c .\nProof of Claim: We construct (Πn,<n) by recursion: for n = 0, set Π0 := {A0}, with <0 trivial. For the step n+1: assume given {(Πi,<i) | i ≤ n} satisfying the above four conditions (for i ≤ n). We set\nΠn+1 := {B f | f : n ⋃\ni=1\nΠi →{0,1}},\nwhere for each function f : ⋃n\ni=1 Πi →{0,1} we have set\nB f := An+1 ∩ ⋂ {E | E ∈ f−1(0)}∩ ⋂ {E c | E ∈ f−1(1)}.\nIt is obvious that the B f ’s are locally closed (given that An+1 is locally closed) and that they form a partition of An+1. So condition (1) is satisfied.\nIt is also easy to check condition (2) for i = n+ 1: let j < n+ 1, E ∈ Π j and B f ∈ Πn+1. Then we have either f (E) = 0, in which case B f ⊆ E (by construction of B f ), or else f (E) = 1, in which case B f ⊆ E c .\nTo construct the order <n+1, observe first that there is a natural total order <(n) on the disjoint union ⋃n\ni=1 Πi, namely the one obtained by concatenating the orders <0, <1, . . . , <n. More precisely, if, for\nevery B ∈ ⋃n i=1 Πi, we set i(B) to be the unique index i ≤ n such that B ∈ Πi, then the order <(n) is given by setting: B <(n) E iff either i(B)< i(E), or else i(B) = i(E) and B <i(B) E .\nNow, the order <n+1 on B f ’s is given by the lexicographic order induced by <(n) on the functions f (thought as “words” written with the letters 0 and 1). More precisely, we set:\nB f <n+1 Bg\niff there exists some set E ∈ ⋃n\ni=1 Πi such that (\n∀E ′ <(n) E f (E ′) = g(E ′), but f (E)< g(E) ) ,\nwhere < is the usual order 0 < 1 on {0,1}. Clearly, <n+1 is a total order on Πn+1, so condition (2) is satisfied.\nFinally, we check condition (4) for n+ 1, let B f ,Bg ∈ Πn+1 such that B f <n+1 Bg. By definition of the order <n+1, this means that there exists some E ∈ ⋃n i=1 Πi such that for all E ′ <(n) E we have f (E ′) = g(E ′) but f (E) < g(E), i.e., f (E) = 0 and g(E) = 1. By the construction of B f ’s, f (E) = 0 implies that B f ⊆ E, from which we get B f ⊆ E , and thus E c ⊆ B f c . Similarly, g(E) = 1 implies that Bg ⊆ E c . So we have Bg ⊆ E c ⊆ B f c , and thus by transitivity of inclusion we get Bg ⊆ B f c . This completes the proof of our Claim.\nGiven now the above Claim, we can prove our Lemma by taking as our refined partition\nΠ′ := ⋃\ni∈ω Πi.\nClearly, Π′ is a refinement of Π consisting of locally closed sets. We now define a well-order <′ on Π′ as the concatenation of all the ≤i’s.9 Obviously, <′ is a total order of type ≤ ω on Π′, so we get finite or ω-long sequence that enumerates Π′. The above properties (3) and (4) ensure that this is a pseudo-stratification.\nLemma 1. Given a pseudo-stratification 〈Ai | i < λ 〉 (of length λ ≤ ω), there exists a λ -long sequence of open sets 〈Ui | i < λ 〉, satisfying:\n(1) Ui ∩Ai = Ai;\n(2) if j < i and Ui ∩A j 6= /0, then Ai ⊆ A j.\nProof. We know that each Ai is locally closed, so there exists some open set UAi ∈ τ such that UAi ∩Ai = Ai. Now, for all i ∈ ω set\nUi :=U Ai ∩\n⋂ {A j c | j < i,Ai ⊆ A j c }.\nLet us first check that the sequence 〈Ui | i < λ 〉 satisfies condition (1):\nUi ∩Ai = (U Ai ∩\n⋂ {A j c | j < i,Ai ⊆ A j c })∩Ai\n= (Ui ∩Ai)∩ ⋂ {A j c | j < i,Ai ⊆ A j c }\n= Ai ∩ ⋂ {A j c | j < i,Ai ⊆ A j c }= Ai\n9Once again, one can specify this more precisely by first defining i : Π′ → ω by choosing i(B) to be the unique index i such that B ∈ Πi, and finally defining: B <′ E iff either i(B)< i(E), or else i(B) = i(E) and B <i(B) E.\nSecond, let us check condition (2): Suppose that we have j < i and Ui∩A j 6= /0, but Ai 6⊆A j. Since (Ai)i<λ is a pseudo-stratified sequence, from j < i and Ai 6⊆ A j we can derive Ai ⊆ A j c . By the construction of Ui, this implies that Ui ⊆ A j c , and hence that Ui ∩A j ⊆ A j c ∩A j ⊆ A j c ∩A j = /0, which contradicts the assumption that Ui ∩A j 6= /0.\nLemma 2. Every pseudo-stratification is linearly separated.\nProof. Let Π = {Ai | i < λ} be a pseudo-stratification (with λ ≤ ω), and let 〈Ui | i < λ 〉 be a sequence satisfying the conditions of Lemma 1. It is clear that, in order to prove our intended result, it is enough to construct a total order E on the set {i ∈ ω |i < λ}= λ ⊆ ω , such that\nUi ∩A j 6= /0 ⇒ iE j.\nFor this, we first define a reflexive relation R on λ , by setting\niR j ⇐⇒Ui ∩A j 6= /0.\nClaim: There are no non-trivial cycles\ni1R · · · inRi1 (with distinct ik’s).\nProof of Claim: Let i1R · · · inRi1 be a non-trivial cycle of minimal length n ≥ 2. There are two cases:\nCase 1: n = 2, i.e., i1Ri2Ri1 with i2 6= i1. We must have either i1 < i2 or i2 < i1. Without loss of generality, we can assume i1 < i2 (otherwise, just swap i1 and i2, and use the cycle i2Ri1Ri2). From i2Ri1, we get Ui2 ∩Ai1 6= /0. This together with i1 < i2, gives us Ai2 ⊆ Ai1 (by condition (2) from Lemma 2), and hence Ui1 ∩Ai2 ⊆Ui1 ∩Ai1 = Ai1 . From this, we get that Ui1 ∩Ai2 = (Ui1 ∩Ai2)∩Ai2 ⊆ Ai1 ∩Ai2 = /0 (since i1 6= i2, so Ai1 and Ai2 are different answers, hence disjoint), so we conclude that Ui1 ∩Ai2 = /0. But on the other hand, from i1Ri2 we get Ui1 ∩Ai2 6= /0. Contradiction.\nCase 2: n > 2. Since all the ik’s are distinct, there must exist a (unique) smallest index in the cycle. Without loss of generality (since otherwise we can rearrange the indices, permuting the cycle), we can assume that i3 is the smallest index. (Note that, since n > 2, there must be at least three distinct successive indices i1, i2, i3.) So i3 < i1 and i3 < i2. From i2Ri3 we get Ui2 ∩Ai2 6= /0. Since i3 < i2, it follows that Ai2 ⊆ Ai3 (by Lemma 2). But on the other hand, i1Ri2 gives us Ui1 ∩Ai2 6= /0. We hence obtain Ui1 ∩Ai3 6= /0. This, together with i3 < i1, gives us Ai1 ⊆ Ai3 (again by Lemma 2). From this, we derive Ai1 ⊆ Ui1 ∩Ai3 (since Ai ⊆ Ui for all i). Let now s ∈ Ai1 be any state satisfying the answer Ai1 ⊆ Ui1 ∩Ai3 . So we have s ∈ Ui1 and s ∈ Ai3 , which together imply that Ui1 ∩Ai3 6= /0 (since s ∈ Ai3 implies that every open neighborhood of s intersects Ai3 ). Hence, we have i1Ri3, which means we can shorten the cycle by eliminating i2, we obtain contradiction.\nGiven the above Claim, it follows that the transitive closure R∗ is a partial order on λ (which obviously includes R). By the Order Extension Principle, we can extend R∗ to a total order E on λ , which still includes R."
    }, {
      "heading" : "5 Topological Characterization of Solvability",
      "text" : "Definition 10. Let S = (S,O) be an epistemic space, L be a standard agent, A ⊆ S, and s ∈ A. An A-locking sequence for s (with respect to L) is a data sequence σ = (O1, . . . ,Ok), such that:\n(1) σ is sound for s, i.e., s ∈ ⋂\n1≤i≤k Oi;\n(2) if δ is any data sequence sound for s, then L(S,σ ∗δ )⊆ A. For a given data sequence σ , we denote by LσA the set of all states in A having σ as an A-locking\nsequence, i.e., LσA := {s ∈ A | σ is an A-locking sequence for s wrt L}.\nLemma 3. If A is verifiable in the limit by a standard agent L, then ⋃ σ∈O∗ L σ A = A.\nProof. Suppose not. Let A be verifiable in the limit, but such that A 6= ⋃ σ∈O∗ L σ A . Since all L σ A ⊆ A, his means that A 6⊆ ⋃\nσ∈O∗ L σ A , i.e., there exists some state s ∈ A for which there is no A-locking sequence.\nThis means that every data sequence σ that is sound for s can be extended to a sequence δ that is also sound for s and has L(δ ) 6⊆ A.\nLet now ~O be a (sound and complete) data stream for s. We construct a new infinite data stream ~V , by defining increasingly longer initial segments δk of ~O, in countably many stages: we first set V0 = O0, thus obtaining an initial segment δ0 = (O0) = (V0); at the k + 1-th stage, given some initial segment δk = (V0,V1, . . . ,Vnk) (of some length nk), we built our next initial segment by taking any extension δk+1 of the sequence σk = (V0, . . . ,Vnk ,On+1) that is sound for s and has L(σk) 6⊆ A. The resulting infinite stream ~V is a (sound and complete) stream for s (the completeness of ~V with respect to s follows the fact that this stream includes all the elements of ~U ), but which contains arbitrarily long initial segments σk with L(σk) 6⊆ A. Since s ∈ A, this contradicts the assumption that A is verifiable in the limit.\nLemma 4. If A ⊆ S is verifiable in the limit by a standard agent L, then for every data sequence σ = (O1, . . .Ok), the set LσA is locally closed.\nProof. Let O := ⋂k i=1 Oi be the intersection of all the observations in σ . We will show that\nO∩LσA = L σ A ,\nfrom which the desired conclusion follows. (⊇) If s∈ LσA , then σ is an A-locking sequence for s, hence σ is sound for s, and thus s∈ ⋂n i=1 Oi =O.\n(⊆) Suppose that s ∈ O∩LσA . We prove two claims:\nClaim 1: For every data sequence δ that is sound for s and extends σ , we have LS(δ )⊆ A. Proof of Claim 1: Let δ = (δ1, . . . ,δn) be a data sequence that is sound for s (i.e., s ∈ δi for all i = 1, . . . ,n) and extends σ , i.e., n ≥ k and Ui = Oi for all i ≤ k). Hence, ⋂n\ni=1 δi is an open neighborhood of s, and s ∈ LσA , so there must exist some t ∈ ⋂n i=1 δi such that t ∈ LσA . Hence, t ∈ A and σ is an A-locking sequence for t. But δ extends σ and is sound for t, so (by the definition of σ being an A-locking sequence for t), we have that L(δ )⊆ A, which concludes the proof of Claim 1. Claim 2: We have s ∈ A.\nProof of Claim 2: Let ~V be a stream for s that extends σ (such a stream must exist, since σ is sound for s: just take any stream for s and prefix it with σ ). Then, for every n≥ k, the sequence δn = (V1, . . . ,Vn) is sound for s and extends σ . Hence, by the above Claim, we must have that LS(V1, . . . ,Vn) ⊆ A for all n ≥ k. But we assumed that A is verifiable in the limit, so we must have s ∈ A, which concludes the proof of Claim 2.\nFrom Claims 1 and 2 together, we conclude that σ is an A-locking sequence for s ∈ A, hence s ∈ LσA .\nTheorem 1. Given an epistemic space (S,O), a set A ⊆ S is verifiable in the limit iff it is ω-constructible.\nProof. (⇐) Assume A = ⋃\nn(Un ∩Cn) is a countable disjoint union of (mutually disjoint) locally closed sets Un ∩Cn (with Un open and Cn closed). We define a standard agent L for A on finite data sequences δ = (O1, . . . ,Ok), by setting L(S,δ ) = Ac, if we have ⋂\nj O j 6⊆Un for all n ∈ ω ; L(S,δ ) = Ac (where Ac is the complement of A), if ⋂\nj O j ⊆C c n holds for the first index n∈ ω such that ⋂ j O j ⊆Un; and L(S,δ ) =A otherwise. Then it is easy to see that L verifies A in the limit.\n(⇒) Suppose that A is verifiable in the limit. By Proposition 1, it is then verifiable by a standard agent L. By Lemma 1, A is the union of all sets LσA for all finite data sequences σ . But there are only countably many such sequences, so this is a countable union. Moreover, by Lemma 2, each LσA is locally closed. Hence A is a countable union of locally closed sets, i.e., an ω-constructible set.\nCorollary 1. A is decidable in the limit iff both A and Ac are ω-constructible.\nProof. Follows trivially from the above results.\nTheorem 2. Let P= (S,Q) be an inductive problem on an epistemic space S. The following are equivalent:\n(1) P is solvable (in the limit);\n(2) the associated question Q is an (at most) countable family of ω-constructible answers; (3) Q has an (at most) countable locally closed refinement.\nProof. (1)⇒ (2) : Let P be a solvable problem. By Proposition 1, there exists some standard agent that solves it. Let L be such a standard agent that solves P. Claim: Every answer A ∈ Q is verifiable in the limit.\nProof of Claim: Let A ∈ Q be an answer. We construct a standard agent LA that verifies it, by setting LA S (σ) := A iff LS(σ)⊆ A, and LAS(σ) := Ac otherwise. It is easy to see that LA verifies A.\nUsing the Claim and Lemma 3, we obtain that, for each answer A ∈ Q, there exists some data sequence σ ∈ O∗ such that LS(σ) ⊆ A. But O∗ is countable, so there can be only countably many answers in Q.\nBy the claim above, Lemma 3 and Lemma 4, we obtain that every answer A ∈Q is a countable union of locally closed sets, hence it is ω-constructible. (2)⇒ (3) : By (2), Q is (at most) countable, say Q = {Ai | i ∈ ω}, and also each answer AI ∈ Q is ωconstructible, hence it can be written as a countable disjoint union of locally closets A = ⋃\nk∈ω A k i (where\nall Aki ’s locally closed and mutually disjoint). Then the question {A k i | i ∈ ω ,k ∈ ω} is a refinement of Q, which is countable and locally closed. (3)⇒ (1) : Let Q′ = {Bi | i ∈ ω} be a countable closed refinement of Q′. By Corollary 1, every answer B ∈Q′ is decidable, and so by Proposition 1, we can choose for each Bi ∈Q some standard agent Li that decides Bi. We define now a new standard agent L, by:\nLS(σ) := ⋃ {Bi | i ∈ ω such that Li(σ)⊆ Bi}.\nIt is easy to see that this agent L solves Q′, and since Q′ is a refinement of Q, L also solves Q.\nCorollary 2. An epistemic space S = (S,O) is learnable in the limit iff it is countable and satisfies the T D separation axiom.\nProof. Apply Theorem 2 to the learning question {{s} | s ∈ S}, noticing that the fact that all its answers are ω-constructible is equivalent to all singletons being locally closed, which is just another formulation of the T D axiom."
    }, {
      "heading" : "6 Universality of Conditioning",
      "text" : "Our aim in this section is to show that AGM conditioning is “universal”: every solvable problem can be solved by some AGM agent. First, we introduce an auxiliary notion, that of a problem being directly solvable by AGM conditioning.\nGiven a question Q on an epistemic space (S,O), any total order E ⊆ Q×Q on (the answers of) the question Q induces in a canonical way a total preorder ≤⊆ S×S, obtained by:\ns ≤ t iff As EAt\n(where As is the unique answer As ∈ Q such that s ∈ As).\nDefinition 11. A problem P = (S,Q) is directly solvable by conditioning if it is solvable by AGM conditioning with respect to (a prior ≤ that is canonically induced, as explained above, by) a total order E⊆ Q×Q on (the answers of) the question Q.\nDirect solvability by conditioning essentially means that the problem can be solved by a conditioning agent who does not attempt to refine the original question: she forms beliefs only about the answers to the given question, and is thus indifferent between states satisfying the same answer. Direct solvability by conditioning is thus a very stringent condition, and unsurprisingly this form of conditioning is not universal.\nProposition 5. (K. Genin, personal communication) Not every solvable problem is directly solvable by conditioning.\nProof. Let P be the problem in Example 3, depicted on the left-hand side of Figure 1. It is easy to see that this problem cannot be directly solvable by conditioning. Indeed, if {t,u}⊳{s,v} then v is not learnable by ⊳-conditioning; if {s,v} < {t,u} then t is not learnable by ⊳-conditioning; while if {t,u} and {s,v} are equally plausible, then neither t nor v are learnable.\nBut P can be refined to a directly solvable problem, namely the “learning question” P′ (depicted on the right-hand side of Figure 1), which can be directly solvable (e.g. if we set {t}⊳ {s}⊳ {v}⊳ {u}). As a consequence, P can itself be solved by (non-direct) conditioning (with respect to the order t < s < v < u).\nThis counterexample suggests a way to prove our intended universality result: it is enough to show that every solvable problem has a refinement that is directly solvable by conditioning. To do this, we first need a structural characterization of direct solvability.\nLemma 5. (Topological Characterization of Direct Solvability by Conditioning) A problem P= (S,Q) is directly solvable by conditioning iff Q is linearly separated.\nProof. Left-to-right implication: Suppose that P is directly solvable by conditioning with respect to (a prior ≤ that is canonically induced by) a total order E⊆Q×Q. Then, for every s∈ S choose some sound and complete data stream ~OS = (Osn)n∈ω for s (with O n s ∈ O ⊆ τS). Direct solvability by conditioning implies then that there exists some Ns such that Min≤(Os1, . . . ,O s Ns)⊆ As. Set Us := ⋂Ns i=1 O s i ∈ τS, so that we have s ∈Us and Min≤Us ⊆ As. Then set UA := ⋃\ns∈AUs ∈ τS for every answer A ∈ Q. We claim that UA “separates” A from the union of all the answers B⊳A (as linear separation demands): indeed, by the construction of UA, it is obvious that (1) A ⊆UA, and also that Min≤UA ⊆ A. By unfolding the last clause in terms of E, we obtain that: AEB holds for all B ∈ Q such that UA∩B 6= /0. Since E is a total order on\nQ, this is equivalent to: (2) UA∩B = /0 for all B⊳A. By (1) and (2) together, we obtain that Q is linearly separated.\nRight-to-left implication: Suppose Q is linearly separated. Let E be a total order on Q that linearly separates it. This means that, for every answer A ∈ Q, there exists some open set UA ∈ τS such that A ⊆ UA and UA ∩B = /0 for all B⊳A. For each s ∈ S, we set Us := UAs (where As is the unique answer As ∈ Q with s ∈ As).\nLet ≤ be the total preorder on S canonically induced by the order E⊆ Q×Q (by s ≤ t iff As EAt). We show now that P is directly solvable by conditioning with respect to ≤. For this, let s ∈ S be any state, and ~O = (On)n∈ω be a sound and complete stream for s. Completeness of the stream implies that there must exist some N ∈ ω such that\n⋂N i=1 Oi ⊆Us.\nTo conclude our proof, it is enough to show the following\nClaim: For every n ≥ N, we have\ns ∈ Min≤( n ⋂\ni=1\nOi)⊆ As.\nFirst, let us see why this Claim is enough to give us direct solvability by conditioning. The fact that s ∈ Min≤( ⋂n i=1 Oi) implies that Min≤( ⋂n i=1 Oi) 6= /0, for all n ≥ N. A previous observation tells us that, when applied to such data streams, the AGM agent L ≤ produces a “principal filter”, given by\nL ≤(O1, . . . ,On) = {P ⊆ S | Min≤(\nn ⋂\ni=1\nOi)⊆ P}.\nBy the Claim above we have Min≤( ⋂n i=1 Oi) ⊆ As, and hence we obtain As ∈ L ≤(O1, . . . ,On), for all n ≥ N.\nProof of Claim: Let n ≥ N. To prove the Claim, it is enough to show the following two implications (for all states t):\n(1) t ∈ ⋂n\ni=1 Oi ⇒ s ≤ t;\n(2) t ∈ Min≤( ⋂n i=1 Oi) ⇒ At = As.\nTo show (1), let t ∈ ⋂n i=1 Oi. Then t ∈Us (since ⋂n i=1 Oi ⊆ ⋂N\ni=1 Oi ⊆Us), so Us ∩At 6= /0. Hence (by linear separation) we must have As EAt , i.e., s ≤ t.\nTo show (2), let t ∈ Min≤( ⋂n i=1 Oi). This implies that t ≤ s (since s ∈ ⋂n\ni=1 Oi). But by (1), we also have s ≤ t, and hence s ≤ t ≤ s. This means that As EAt EAs. But E is a total order on Q, so it follows that At = As.\nTheorem 3. AGM conditioning is a universal problem-solving method, i.e., every solvable problem is solvable by some AGM agent.\nProof. Let P be a solvable problem. From Theorem 2, Proposition 3 and Lemma 2, it follows that P has a linearly separated refinement P′. By Lemma 5, that refinement is (directly) solvable by an AGM agent L≤. It is obvious (from the definition of solvability) that any doxastic agent which solves the more refined problem P′ solves also the original problem P.\nCorollary 3. AGM conditioning is a universal learning method, i.e., every learnable space is learnable by some AGM agent.\nProof. Apply the previous result to the finest question Q := {{s} | s ∈ S}.\nIn contrast, recall that the counterexample in Proposition 2 showed that standard AGM agents have a very limited problem-solving power. Standard conditioning is not a universal learning method (while general AGM conditioning is universal). This means that allowing prior plausibility orders that are nonwellfounded is essential for achieving universality of conditioning. Beliefs generated in this way may occasionally fail to be globally consistent. (Indeed, note that in the counterexample from Proposition 2, the beliefs of the non-standard AGM agent who learns the space are initially globally inconsistent. In conclusion, occasional global inconsistencies are the unavoidable price for the universality of AGM conditioning."
    }, {
      "heading" : "7 Conclusions and Connections to Other Work",
      "text" : "The general topological setting for problem-solving assumed here is a variation of the one championed by Kelly in various talks [23] and in unpublished work [24, 25], though until recently we did not realize this close similarity. Our topological characterizations of verifiable, falsifiable and decidable properties are generalizations of results by Kelly [20], who proved characterizations for the special case of Baire spaces.10 Our result on learning-universality (Corollary 3) is also a generalization of analogue results by Kelly [21, 26], and Kelly, Schulte and Hendricks [19]. But our generalization to arbitrary spaces is highly non-trivial, requiring the use of the T D characterization. In contrast, the Baire space satisfies the much stronger separation axiom T 1, which trivializes the specialization order, and so the proof of learning-universality is much easier in this special case: any total ω-like ordering of the space can be used for conditioning. Nevertheless, in a sense, this result is just a topological re-packaging of one of our own previous results [13, 3, 4].\nWhile writing this paper, we learned that our T D characterization of learnability (Corollary 2) was independently re-proven by Konstantin Genin ([11], unpublished manuscript), soon after we announced its proof. This characterization is actually a topological translation of a classical characterization of identifiability in the limit [2], and in fact it also follows from a result by de Brecht and Yamamoto [9], who prove it for so-called “concept spaces”.\nOur key new results are far-reaching and highly non-trivial: the topological characterization of solvability (Theorem 2), and the universality of AGM condition for problem-solving (Theorem 3). They required the introduction of new topological concepts (e.g., pseudo-stratifications and linearly separated partitions), and some non-trivial proofs of new topological results.\nPhilosophically, the importance of these results is that, on the one hand they fully vindicate the general topological program in Inductive Epistemology started by Kelly and others [20, 30], and on the other hand they reassert the power and applicability of the AGM Belief Revision Theory against its critics. To this conclusion, we need to add an important proviso: our results show that, in order to achieve problemsolving universality, AGM agents need to (a) be “creative”, by going beyond the original problem (i.e., finding a more refined problem that can be solved directly, and forming prior beliefs about the answer to this more refined question), and (b) admit non-standard priors, which occasionally will lead to beliefs that are globally inconsistent (although still locally consistent). Such occasional global inconsistencies can give rise to a type of “infinite Lottery Paradox”. But this is the price that AGM agents have to pay in\n10In unpublished work [25] the authors claim a characterization of solvability in a general setting. Their characterization is sightly “looser” than ours, and can be easily obtained from ours. Our tighter characterization is the one needed for proving universality.\norder to be able to solve every solvable question. Whether or not this is a price that is worth paying is a different, more vague and more “ideological” question, although a very interesting one. But this question lies beyond the scope of this paper."
    }, {
      "heading" : "8 Acknowledgments",
      "text" : "We thank Johan van Benthem, Nick Bezhanishvili, Konstantin Genin, Thomas Icard and Kevin Kelly for their useful feedback on issues related to this paper. Johan helped us place belief-based learning within the larger context of long-term doxastic protocols [7], and beyond this he gave us his continuous support and encouragement for our work on this line of inquiry. Nick pointed to us the connections between our work and the notions of TD-space and locally closed set. Konstantin pointed to us the connections to the notion of stratification and gave the counterexample proving Proposition 5. His critical feedback on our early drafts was really essential for clarifying our thoughts and cleaning up our proofs, and so it’s fair to say that this paper in its current form owes a lot to Konstantin Genin. Thomas Icard’s comments on a previous draft and our friendly interactions with him on related topics during our Stanford visits are very much appreciated. Finally, Kevin Kelly’s work forms of course the basis and the inspiration for ours. Our frequent discussions with him in recent years influenced the development of our own perspective on the topic. He also gave us excellent reference tips concerning the history of the connections between topology and formal epistemology, as well as concerning his more recent work on related issues.\nNina Gierasimczuk’s work on this paper was funded by an Innovational Research Incentives Scheme Veni grant 275-20-043, Netherlands Organisation for Scientific Research (NWO). Sonja Smets was funded in part by an Innovational Research Incentives Scheme Vidi grant from NWO, and by the European Research Council under the European Community’s Seventh Framework Programme (FP7/20072013)/ERC Grant agreement no. 283963."
    } ],
    "references" : [ {
      "title" : "On the Logic of Theory Change: Partial Meet Contraction and Revision Functions",
      "author" : [ "Carlos Alchourrón", "Peter Gärdenfors", "David Makinson" ],
      "venue" : "Journal of Symbolic Logic",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1985
    }, {
      "title" : "Inductive inference of formal languages from positive data",
      "author" : [ "Dana Angluin" ],
      "venue" : "Information and Control",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1980
    }, {
      "title" : "Belief revision as a truth-tracking process",
      "author" : [ "Alexandru Baltag", "Nina Gierasimczuk", "Sonja Smets" ],
      "venue" : "In K. Apt, editor: Proceedings of TARK’11,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "Truth Tracking by Belief Revision",
      "author" : [ "Alexandru Baltag", "Nina Gierasimczuk", "Sonja Smets" ],
      "venue" : "Technical Report, ILLC Report PP-2014-20",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2015
    }, {
      "title" : "A Qualitative Theory of Dynamic Interactive Belief Revision",
      "author" : [ "Alexandru Baltag", "Sonja Smets" ],
      "venue" : "editors: Proc. of LOFT’7, Texts in Logic and Games",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2008
    }, {
      "title" : "Logical Dynamics of Information and Interaction",
      "author" : [ "Johan van Benthem" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Merging Frameworks for Interaction",
      "author" : [ "Johan van Benthem", "Jelle Gerbrandy", "Tomohiro Hoshi", "Eric Pacuit" ],
      "venue" : "Journal of Philosophical Logic",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2009
    }, {
      "title" : "Dynamic interactive epistemology",
      "author" : [ "Oliver Board" ],
      "venue" : "Games and Economic Behavior",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2004
    }, {
      "title" : "Topological properties of concept spaces",
      "author" : [ "Matthew de Brecht", "Akihiro Yamamoto" ],
      "venue" : "Information and Computation",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2010
    }, {
      "title" : "Finite identification from the viewpoint of epistemic update",
      "author" : [ "Cédric Dégremont", "Nina Gierasimczuk" ],
      "venue" : "Information and Computation",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2011
    }, {
      "title" : "Linearizing a Countable TD Space",
      "author" : [ "Konstantin Genin" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2015
    }, {
      "title" : "Identification through Inductive Verification",
      "author" : [ "Nina Gierasimczuk" ],
      "venue" : "Proceedings of TBiLLC’07,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2009
    }, {
      "title" : "Knowing One’s Limits",
      "author" : [ "Nina Gierasimczuk" ],
      "venue" : "Logical Analysis of Inductive Inference. Ph.D. thesis, Universiteit van Amsterdam,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2010
    }, {
      "title" : "Logic and Learning",
      "author" : [ "Nina Gierasimczuk", "Vincent F. Hendricks", "Dick de Jongh" ],
      "venue" : "editors: Johan van Benthem on Logic and Information Dynamics, Outstanding Contributions to Logic",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2014
    }, {
      "title" : "On the Complexity of Conclusive Update",
      "author" : [ "Nina Gierasimczuk", "Dick de Jongh" ],
      "venue" : "The Computer Journal 56(3),",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2013
    }, {
      "title" : "Two modellings for theory change",
      "author" : [ "Adam Grove" ],
      "venue" : "Journal of Philosophical Logic",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1988
    }, {
      "title" : "Reliable Belief Revision",
      "author" : [ "Kevin T. Kelly", "Oliver Schulte", "Vincent Hendricks" ],
      "venue" : "editors:  Logic and Scientific Methods, Synthese Library",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1997
    }, {
      "title" : "The Logic of Reliable Inquiry",
      "author" : [ "Kevin T. Kelly" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1996
    }, {
      "title" : "The Learning Power of Belief Revision",
      "author" : [ "Kevin T. Kelly" ],
      "venue" : "Proceedings of the 7th Conference on Theoretical Aspects of Rationality and Knowledge,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1998
    }, {
      "title" : "Ockham’s Razor, Truth, and Information",
      "author" : [ "Kevin T. Kelly" ],
      "venue" : "editors: Handbook of the Philosophy of Information,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2008
    }, {
      "title" : "An erotetic theory of empirical simplicity and its connection with truth",
      "author" : [ "Kevin T. Kelly" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2011
    }, {
      "title" : "Notes on a General Topological Paradigm",
      "author" : [ "Kevin T. Kelly" ],
      "venue" : null,
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2015
    }, {
      "title" : "A simple theory of theoretical simplicity",
      "author" : [ "Kevin T. Kelly", "Hanti Lin" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2011
    }, {
      "title" : "Iterated Belief Revision, Reliability, and Inductive Amnesia",
      "author" : [ "Kevin T. Kelly" ],
      "venue" : "Erkenntnis 50(1),",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1999
    }, {
      "title" : "Scientific Discovery Based on Belief Revision",
      "author" : [ "Eric Martin", "Daniel Osherson" ],
      "venue" : "Journal of Symbolic Logic",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1997
    }, {
      "title" : "Trial and Error Predicates and the Solution to a Problem of Mostowski",
      "author" : [ "Hilary Putnam" ],
      "venue" : "Journal of Symbolic Logic 30(1),",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1965
    }, {
      "title" : "Topology as Epistemology",
      "author" : [ "Olivier Schulte", "Cory Juhl" ],
      "venue" : "Monist 79(1),",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 1996
    }, {
      "title" : "Topology Via Logic",
      "author" : [ "Steven Vickers" ],
      "venue" : null,
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 1996
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "[13, 10, 15]), learners can produce hypotheses based on beliefs.",
      "startOffset" : 0,
      "endOffset" : 12
    }, {
      "referenceID" : 9,
      "context" : "[13, 10, 15]), learners can produce hypotheses based on beliefs.",
      "startOffset" : 0,
      "endOffset" : 12
    }, {
      "referenceID" : 14,
      "context" : "[13, 10, 15]), learners can produce hypotheses based on beliefs.",
      "startOffset" : 0,
      "endOffset" : 12
    }, {
      "referenceID" : 18,
      "context" : "However, there does exist a line of research that combines belief revision with learning-theoretic notions, line pursued by Kelly [21, 26], Kelly, Schulte and Hendricks [19], Martin and Osherson [28] and ourselves [13, 3, 4, 14].",
      "startOffset" : 130,
      "endOffset" : 138
    }, {
      "referenceID" : 23,
      "context" : "However, there does exist a line of research that combines belief revision with learning-theoretic notions, line pursued by Kelly [21, 26], Kelly, Schulte and Hendricks [19], Martin and Osherson [28] and ourselves [13, 3, 4, 14].",
      "startOffset" : 130,
      "endOffset" : 138
    }, {
      "referenceID" : 16,
      "context" : "However, there does exist a line of research that combines belief revision with learning-theoretic notions, line pursued by Kelly [21, 26], Kelly, Schulte and Hendricks [19], Martin and Osherson [28] and ourselves [13, 3, 4, 14].",
      "startOffset" : 169,
      "endOffset" : 173
    }, {
      "referenceID" : 24,
      "context" : "However, there does exist a line of research that combines belief revision with learning-theoretic notions, line pursued by Kelly [21, 26], Kelly, Schulte and Hendricks [19], Martin and Osherson [28] and ourselves [13, 3, 4, 14].",
      "startOffset" : 195,
      "endOffset" : 199
    }, {
      "referenceID" : 12,
      "context" : "However, there does exist a line of research that combines belief revision with learning-theoretic notions, line pursued by Kelly [21, 26], Kelly, Schulte and Hendricks [19], Martin and Osherson [28] and ourselves [13, 3, 4, 14].",
      "startOffset" : 214,
      "endOffset" : 228
    }, {
      "referenceID" : 2,
      "context" : "However, there does exist a line of research that combines belief revision with learning-theoretic notions, line pursued by Kelly [21, 26], Kelly, Schulte and Hendricks [19], Martin and Osherson [28] and ourselves [13, 3, 4, 14].",
      "startOffset" : 214,
      "endOffset" : 228
    }, {
      "referenceID" : 3,
      "context" : "However, there does exist a line of research that combines belief revision with learning-theoretic notions, line pursued by Kelly [21, 26], Kelly, Schulte and Hendricks [19], Martin and Osherson [28] and ourselves [13, 3, 4, 14].",
      "startOffset" : 214,
      "endOffset" : 228
    }, {
      "referenceID" : 13,
      "context" : "However, there does exist a line of research that combines belief revision with learning-theoretic notions, line pursued by Kelly [21, 26], Kelly, Schulte and Hendricks [19], Martin and Osherson [28] and ourselves [13, 3, 4, 14].",
      "startOffset" : 214,
      "endOffset" : 228
    }, {
      "referenceID" : 25,
      "context" : "This notion matches the usual learningtheoretic concept of identifiability in the limit [31, 16, 29].",
      "startOffset" : 88,
      "endOffset" : 100
    }, {
      "referenceID" : 0,
      "context" : "The second goal is to use these topological results to look at the “solving power” of well-behaved doxastic agents, such as the ones whose beliefs satisfy the usual KD45 postulates of doxastic logic, as well as the standard AGM postulates of rational belief-revision [1].",
      "startOffset" : 267,
      "endOffset" : 270
    }, {
      "referenceID" : 27,
      "context" : "1 The close connections between Epistemology and General Topology have already been noticed long ago [32, 20].",
      "startOffset" : 101,
      "endOffset" : 109
    }, {
      "referenceID" : 17,
      "context" : "1 The close connections between Epistemology and General Topology have already been noticed long ago [32, 20].",
      "startOffset" : 101,
      "endOffset" : 109
    }, {
      "referenceID" : 17,
      "context" : "Based on these connections, Kevin Kelly started a far-reaching program [20, 22] meant to import ideas and techniques from both Formal Learning Theory and Topology into mainstream Epistemology, and show their relevance to the induction problem in Philosophy of Science.",
      "startOffset" : 71,
      "endOffset" : 79
    }, {
      "referenceID" : 19,
      "context" : "Based on these connections, Kevin Kelly started a far-reaching program [20, 22] meant to import ideas and techniques from both Formal Learning Theory and Topology into mainstream Epistemology, and show their relevance to the induction problem in Philosophy of Science.",
      "startOffset" : 71,
      "endOffset" : 79
    }, {
      "referenceID" : 19,
      "context" : "[22] Simplicity has been claimed to have topological characteristics—the simplicity order should in some way follow the structure imposed on the uncertainty range by possible tests and observations.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "It has also been linked with the notion of minimal mind change, where the learning agent keeps the conjecture changes to a minimum [20, 30].",
      "startOffset" : 131,
      "endOffset" : 139
    }, {
      "referenceID" : 26,
      "context" : "It has also been linked with the notion of minimal mind change, where the learning agent keeps the conjecture changes to a minimum [20, 30].",
      "startOffset" : 131,
      "endOffset" : 139
    }, {
      "referenceID" : 17,
      "context" : "Taken together, our results can be seen as a vindication both of the general topological program in Inductive Epistemology [20, 22] and of the AGM Belief Revision Theory [1].",
      "startOffset" : 123,
      "endOffset" : 131
    }, {
      "referenceID" : 19,
      "context" : "Taken together, our results can be seen as a vindication both of the general topological program in Inductive Epistemology [20, 22] and of the AGM Belief Revision Theory [1].",
      "startOffset" : 123,
      "endOffset" : 131
    }, {
      "referenceID" : 0,
      "context" : "Taken together, our results can be seen as a vindication both of the general topological program in Inductive Epistemology [20, 22] and of the AGM Belief Revision Theory [1].",
      "startOffset" : 170,
      "endOffset" : 173
    }, {
      "referenceID" : 2,
      "context" : "1This special case is a topological translation of one of our previous results [3, 4].",
      "startOffset" : 79,
      "endOffset" : 85
    }, {
      "referenceID" : 3,
      "context" : "1This special case is a topological translation of one of our previous results [3, 4].",
      "startOffset" : 79,
      "endOffset" : 85
    }, {
      "referenceID" : 5,
      "context" : "However, in the end we are of course interested in the actual revised beliefs after observing the data, so the assumption in this case is that conditional beliefs guide the agent’s revision strategy: they “pre-encode” future belief revisions, to use a term coined by Johan van Benthem [6].",
      "startOffset" : 285,
      "endOffset" : 288
    }, {
      "referenceID" : 0,
      "context" : "Moreover, it is well-known that in fact, the beliefs of AGM agents satisfy all the so-called AGM axioms from Belief Revision Theory [1]: if, for any data sequence ~σ = (σ0, .",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 7,
      "context" : "∧σn , then the sound and complete logic of these conditional belief operators is the so-called Conditional Doxastic Logic [8, 5] (which is itself just a repackaging of the AGM postulates in the language of conditional logic).",
      "startOffset" : 122,
      "endOffset" : 128
    }, {
      "referenceID" : 4,
      "context" : "∧σn , then the sound and complete logic of these conditional belief operators is the so-called Conditional Doxastic Logic [8, 5] (which is itself just a repackaging of the AGM postulates in the language of conditional logic).",
      "startOffset" : 122,
      "endOffset" : 128
    }, {
      "referenceID" : 15,
      "context" : "But this semantics was in fact borrowed by Grove [18] from Lewis’ semantics for conditionals [27], which did not assume well-foundedness.",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 17,
      "context" : ", [20, 12].",
      "startOffset" : 2,
      "endOffset" : 10
    }, {
      "referenceID" : 11,
      "context" : ", [20, 12].",
      "startOffset" : 2,
      "endOffset" : 10
    }, {
      "referenceID" : 25,
      "context" : "Note that standard learnability is essentially the same as Gold’s identifiability in the limit [29, 17].",
      "startOffset" : 95,
      "endOffset" : 103
    }, {
      "referenceID" : 12,
      "context" : "Consider a counterexample from [13, 3, 4].",
      "startOffset" : 31,
      "endOffset" : 41
    }, {
      "referenceID" : 2,
      "context" : "Consider a counterexample from [13, 3, 4].",
      "startOffset" : 31,
      "endOffset" : 41
    }, {
      "referenceID" : 3,
      "context" : "Consider a counterexample from [13, 3, 4].",
      "startOffset" : 31,
      "endOffset" : 41
    }, {
      "referenceID" : 20,
      "context" : "The general topological setting for problem-solving assumed here is a variation of the one championed by Kelly in various talks [23] and in unpublished work [24, 25], though until recently we did not realize this close similarity.",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 21,
      "context" : "The general topological setting for problem-solving assumed here is a variation of the one championed by Kelly in various talks [23] and in unpublished work [24, 25], though until recently we did not realize this close similarity.",
      "startOffset" : 157,
      "endOffset" : 165
    }, {
      "referenceID" : 22,
      "context" : "The general topological setting for problem-solving assumed here is a variation of the one championed by Kelly in various talks [23] and in unpublished work [24, 25], though until recently we did not realize this close similarity.",
      "startOffset" : 157,
      "endOffset" : 165
    }, {
      "referenceID" : 17,
      "context" : "Our topological characterizations of verifiable, falsifiable and decidable properties are generalizations of results by Kelly [20], who proved characterizations for the special case of Baire spaces.",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 18,
      "context" : "10 Our result on learning-universality (Corollary 3) is also a generalization of analogue results by Kelly [21, 26], and Kelly, Schulte and Hendricks [19].",
      "startOffset" : 107,
      "endOffset" : 115
    }, {
      "referenceID" : 23,
      "context" : "10 Our result on learning-universality (Corollary 3) is also a generalization of analogue results by Kelly [21, 26], and Kelly, Schulte and Hendricks [19].",
      "startOffset" : 107,
      "endOffset" : 115
    }, {
      "referenceID" : 16,
      "context" : "10 Our result on learning-universality (Corollary 3) is also a generalization of analogue results by Kelly [21, 26], and Kelly, Schulte and Hendricks [19].",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 12,
      "context" : "Nevertheless, in a sense, this result is just a topological re-packaging of one of our own previous results [13, 3, 4].",
      "startOffset" : 108,
      "endOffset" : 118
    }, {
      "referenceID" : 2,
      "context" : "Nevertheless, in a sense, this result is just a topological re-packaging of one of our own previous results [13, 3, 4].",
      "startOffset" : 108,
      "endOffset" : 118
    }, {
      "referenceID" : 3,
      "context" : "Nevertheless, in a sense, this result is just a topological re-packaging of one of our own previous results [13, 3, 4].",
      "startOffset" : 108,
      "endOffset" : 118
    }, {
      "referenceID" : 10,
      "context" : "While writing this paper, we learned that our T D characterization of learnability (Corollary 2) was independently re-proven by Konstantin Genin ([11], unpublished manuscript), soon after we announced its proof.",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 1,
      "context" : "This characterization is actually a topological translation of a classical characterization of identifiability in the limit [2], and in fact it also follows from a result by de Brecht and Yamamoto [9], who prove it for so-called “concept spaces”.",
      "startOffset" : 124,
      "endOffset" : 127
    }, {
      "referenceID" : 8,
      "context" : "This characterization is actually a topological translation of a classical characterization of identifiability in the limit [2], and in fact it also follows from a result by de Brecht and Yamamoto [9], who prove it for so-called “concept spaces”.",
      "startOffset" : 197,
      "endOffset" : 200
    }, {
      "referenceID" : 17,
      "context" : "Philosophically, the importance of these results is that, on the one hand they fully vindicate the general topological program in Inductive Epistemology started by Kelly and others [20, 30], and on the other hand they reassert the power and applicability of the AGM Belief Revision Theory against its critics.",
      "startOffset" : 181,
      "endOffset" : 189
    }, {
      "referenceID" : 26,
      "context" : "Philosophically, the importance of these results is that, on the one hand they fully vindicate the general topological program in Inductive Epistemology started by Kelly and others [20, 30], and on the other hand they reassert the power and applicability of the AGM Belief Revision Theory against its critics.",
      "startOffset" : 181,
      "endOffset" : 189
    }, {
      "referenceID" : 22,
      "context" : "10In unpublished work [25] the authors claim a characterization of solvability in a general setting.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 6,
      "context" : "Johan helped us place belief-based learning within the larger context of long-term doxastic protocols [7], and beyond this he gave us his continuous support and encouragement for our work on this line of inquiry.",
      "startOffset" : 102,
      "endOffset" : 105
    } ],
    "year" : 2016,
    "abstractText" : null,
    "creator" : "LaTeX with hyperref package"
  }
}