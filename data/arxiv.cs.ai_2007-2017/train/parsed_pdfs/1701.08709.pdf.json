{
  "name" : "1701.08709.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Diversification Methods for Zero-One Optimization",
    "authors" : [ "Fred Glover" ],
    "emails" : [ "glover@colorado.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We introduce new diversification methods for zero-one optimization that significantly extend strategies previously introduced in the setting of metaheuristic search. Our methods incorporate easily implemented strategies for partitioning assignments of values to variables, accompanied by processes called augmentation and shifting which create greater flexibility and generality. We then show how the resulting collection of diversified solutions can be further diversified by means of permutation mappings, which equally can be used to generate diversified collections of permutations for applications such as scheduling and routing. These methods can be applied to non-binary vectors by the use of binarization procedures and by Diversification-Based Learning (DBL) procedures which also provide connections to applications in clustering and machine learning. Detailed pseudocode and numerical illustrations are provided to show the operation of our methods and the collections of solutions they create.\nKeywords: mathematical optimization; binary programming; metaheuristics; adaptive memory; learning."
    }, {
      "heading" : "1. Introduction",
      "text" : "Diversification strategies are now widely recognized as a critical part of effective metaheuristics for complex optimization problems. The important class of zero-one optimization problems is especially relevant for designing diversification strategies, because of the wide range of applications in which they arise. In addition, many discrete optimization problems can be conveniently translated into zero-one problems or can be treated using neighborhood spaces equivalent to those of zero-one problems through the design of metaheuristic search methods.\nDiversification for zero-one optimization can also be applied to nonlinear continuous (global) optimization, taking advantage of the fact that binarization methods developed for converting discrete and continuous data into binary data (Mayoraz and Moreira, 1999) have proved to be quite effective for making certain types of global continuous problems susceptible to solution by zeroone optimization, notably in the realms of cluster analysis and machine learning.\nDiversification is treated here in the sense proposed in adaptive memory programming (tabu search), where the drive to obtain diverse new solutions goes hand-in-hand with intensification processes, which concentrate the search more strongly in regions anticipated to contain good solutions. Consequently, our prescriptions are assumed to operate within contexts where restrictions are imposed on the search space, as in assigning bounds or fixed values to particular variables (e.g., in exploiting strongly determined and consistent variables; as in Glover (1977, 2001) and Glover and Laguna (1997)).\nIn this paper we introduce new diversification strategies for zero-one optimization that extend a framework for generating diverse collections of zero-one vectors originally proposed in the context of the Scatter Search and Path Relinking evolutionary algorithms (Glover, 1997). The two principal diversification strategies from this source constitute a Progressive Gap method and a Max/Min method. The Progressive Gap method has been incorporated in several studies for applying evolutionary metaheuristics to zero-one optimization problems (see, e.g., Laguna an Marti, 2003), while the Max/Min method has advantages for achieving certain kinds of diversification, and is relevant to the topic of learning procedures for metaheuristic optimization, as embodied in the approach called Diversification-based Learning (DBL) (Glover and Hao, 2017). Further connections with learning strategies derive from the fact that DBL includes methods for basing the treatment of general vectors on the ability to handle zero-one vectors.\nWe begin by taking ideas underlying the Max/Min method as a starting point to provide new and more advanced methods for generating diversified collections of zero-one vectors, showing how to partition the space of solutions in more refined ways to create diverse collections. Building on this, we then give an Augmented-Max/Min generation method that provides greater flexibility for creating diversified collections, and identify an associated Shifting Procedure that extends the scope of these methods. Finally, we introduce permutation mappings that further enlarge the range of diversified solutions produced, yielding solutions with new structures through a recursive application of these mappings. Our methods are accompanied by numerical examples that illustrate their operation and the collections of solutions they create."
    }, {
      "heading" : "1.1 Basic Notation and Conventions",
      "text" : "In the following, the 0-1 vectors generated are denoted by x(r), for r = 0 to rLast, where x(0) denotes the seed vector x = (x1, x2, …, xn). The seed vector can be provided by the user, and in the case of binary optimization, can be selected to be a locally optimal 0-1 solution or derived from a linear combination of such local optima for the problem of interest.\nFor a given 0-1 vector x', Comp(x') denotes the complemented vector x\" given by xj\" = 1 – xj',\nj = 1, …, n.\nv denotes the integer floor function which identifies the largest integer ≤ v, for any real value v.\n(Consequently, v + .5 is the nearest integer neighbor of v.)\nrLim is a user-selected upper limit on rLast, the number of vectors in the collection x(r), for\nr = 0 to rLast.\nEach point x' or x\" generated is a shorthand for identifying a current point x(r). Hence, when an\nalgorithm assigns a particular value xj' or xj\", it is understood that xj(r)  xj' or xj(r)  xj\". In instances where xj' and xj\" are determined together, it is understood that xj' refers to x(r) and xj\" refers to x(r+1).\nSeveral parts of this paper deal with the challenge of increasing the number of vectors to be included in a diversified collection. It should be noted that increasing the number of vectors generated does not in itself increase the diversity of the collection, or more precisely, the Mean Diversity measured by the value Mean(|x – y|: for all pairs (x,y) in the collection). For example, the greatest Mean Diversity results for a collection of just two points, consisting of a complementary pair (x', x\"). Adding any additional point y compels the distance |x' – y| and |x\" – y| to be less than |x' – x\"|, and in general, if a set of points has been generated with a maximal Mean Diversity, adding more points will not increase the diversity by this measure.\nIn general, the smaller the number of points that are generated, the greater the (mean) diversity that can be achieved. However, a larger number of points can increase a different type of diversity, which involves the “coverage” provided by the points selected. (For example, one may define coverage = Mean Diversity/Mean Gap, where Gap(x, y) = |x – y| restricted to pairs (x, y) such that there is no point z closer to x than y or closer to y than x on the line segment joining x and y.) Although we do not attempt here to provide formal relationships joining these notions, it should be clear that adding more points can indeed improve the coverage. Hence, it is useful to select the limit rLim to be as large as reasonably possible, taking into account the computational tradeoffs of working with a larger number of points, as determined by the method that utilizes these points. An advantage of generating additional vectors is that it helps to combine intensification with diversification when selecting a best vector from the resulting set. The tradeoffs between relative diversity and the number of vectors produced is a recurring theme throughout the remainder of this paper.\n2. The Max/Min 0-1 Diversification Method\nThe strategy underlying the Max/Min algorithm, which we examine in several variations throughout subsequent sections, is to successively partition the indexes of x into equal sized subsets, so that each vector x' and its complement x\" in the resulting sequence is separated from previous vectors by maximizing the minimum Hamming distance to these vectors. (This property can be achieved strictly when n is a power of 2, and can be achieved approximately for other values of n.)\nThe criterion of maximizing the minimum distance between vectors in the collection generated rests on the following observation. If x' differs from x in half of its components, this implies that the complement x\" of x' will likewise differ from x in half of its components, and consequently the minimum distance of x' and x\" to x will be maximized. This same criterion also implies that x' and x\" will be (approximately) equidistant from the vector Comp(x), and hence the property of maximizing the minimum separating distance will hold in relation to Comp(x) as well."
    }, {
      "heading" : "2.1 Overview",
      "text" : "Let N(i), i = 1, …, iLast denote a partition of N = {1, …, n} . At each stage of the method, each set N(i) of the current partition is split into two equal parts (or as nearly as possible when N(i)\ncontains an odd number of elements), creating a total of iLast additional sets N(i). Let v denote\nthe integer ceiling of v, i.e., the least integer  v (hence v = v + 1 if v is fractional).\nTo begin, iLast = 1 and N(1) = N = {1, …, n}. N(1) is then split into left and right “halves” NL(1) and NR(1) so that the first n' = n/2 of N(1)’s elements go in NL(1) and the remaining n – n' elements go in NR(1), i.e., NL(1) = {1, …,n'} and NR(1) = {n'+1, …, n}. At the conclusion of this split we update the partition by setting N(1) = NL(1) and N(2) = NR(1), thus doubling the number iLast of current sets in the partition to become 2.\nOn the next iteration, each of N(1) and N(2) are similarly split, generating sets NL(1) and NR(1) from N(1) and NL(2) and NR(2) from N(2). Then the updated partition is created by redefining N(1) = NL(1), N(2) = NR(1), N(3) = NL(2) and N(4) = NR(2), and thus yielding iLast = 4. In general, each time the sets in the partition N(i), i = 1 to iLast are split, each set N(i) is subdivided\nby the following alternating assignment rule. If i is odd, the first |N(i)|/2 elements of N(i) go into\nNL(i), while if i is even, the first N(i)|/2 elements of N(i) go into NL(i). In each instance, remaining elements of N(i) go into NR(i).\nAs each set N(i) is split, before doubling iLast, we generate a new vector x' from x by setting\nxj' = 1 – xj for j  NL(i), i = 1, …, iLast, (2.1) xj' = xj for j  NR(i), i = 1, …, iLast. (2.2)\nWe also generate a second vector x\" = Comp(x'), or equivalently,\nxj\" = xj for j  NL(i), i = 1, …, iLast, (2.3)\nxj\" = 1 – xj for j  NR(i), i = 1, …, iLast. (2.4)\nFinally the partition is updated by defining N(2i – 1) = NL(i) and N(2i) = NR(i) for i = 1 to iLast, followed by doubling iLast.\nEach partition created by the “odd/even” rule for splitting the sets satisfies the property that |N(i)| = MaxNum or |N(i)| = MaxNum – 1, where MaxNum = Max(N(i), i = 1, …, iLast). Moreover, the organization of the method also assures MaxNum = |N(1)|. After some number of partitions have been generated, the value of MaxNum for the current partition will equal 2. (MaxNum may skip over some values as it successively decreases in the creation of new partitions, but will not skip over the value 2.) Once MaxNum = 2, the concluding step of the algorithm operates as follows. We identify the number Num2 of sets N(i) for i = 1 to iLast such that |N(i)| = 2. (Given MaxNum = 2, the condition |N(i)| = 2 is equivalent to Last(i) > First(i). All other sets, for which |N(i)| = 1, have Last(i) = First(i).) If Num2 is smaller than a chosen threshold value, such as Threshold = n/16, we may consider that it is not worthwhile to split the sets of the partition an additional time.\nOn the other hand, if Num2 > Threshold, then a final partition can be generated. It is relevant to observe how the algorithm handles the case where |N(i)| = 1. When the set N(i) contains a single element, e.g., N(i) = {j}, then the rule for dividing N(i) into NL(i) and NR(i) yields NL(i) = {j} and NR(i) =  if i is odd, and NL(i) =  and NR(i) = {j} if i is even. In the former case, only the assignments (2.1) and (2.3) are relevant, while in the latter case, only (2.2) and (2.4) are relevant.\nThe final operation of updating the partition can be skipped, since the only purpose of the partitions is to identify the assignments (2.1) to (2.4), and no additional assignments remain to be made."
    }, {
      "heading" : "2.2 Implementation",
      "text" : "The algorithm can be implemented conveniently by observing there is no need to store the sets N(i) at each step. Instead it suffices to record just two numbers, First(i) and Last(i), which identify N(i) as given by N(i) = {j: First(i) ≤ j ≤ Last(i)}. The precise number of elements in a set N(i) currently considered, which we call SetSize, is then given by SetSize = Last(i) + 1 – First(i).\nN(i) can thus be split by defining Split = SetSize/2 if i is odd and Split = SetSize/2 if i is even. This results in creating corresponding “First” and “Last” values for the sets NL(i) and NR(i) given as follows:\nSplitPoint = First(i) + Split – 1 FirstL(i) = First(i) LastL(i) = SplitPoint FirstR(i) = SplitPoint + 1 LastR(i) = Last(i)\nIn the special case where |N(i)| = 1, the condition NL(i) =  or NR(i) =  results in FirstL(i) = LastL(i) + 1 or FirstR(i) = LastR(i) + 1, respectively. If the computer environment for implementing\nthe method does not automatically bypass executing a loop of the form “For j = First to Last” under the condition First > Last, then this special situation needs to be handled separately.\nOne further type of streamlining is useful. The steps of the algorithm can be organized so that NL(i) and NR(i) need not be generated separately and then used to produce a new partition, but can instead be generated directly as new sets N(i) themselves. This requires the use of a vector Location(i) that identifies the location where the current “true” set N(i) is stored. More precisely, for i = 1 to iLast, the “First” and “Last” indexes that define N(i) are given by First(Loc) and Last(Loc) for Loc = Location(i).\nThe detailed form of the method is as follows, where we continue to make reference to vectors x(r) for r = 1 to rLast that may be used to store the successive vectors x' and x\" generated. The only input for the method is the value Threshold that determines whether a last assignment should be made when the number Num2 of sets with |N(i)| = 2 is small (i.e., when Num2 ≤ Threshold).\nMax/Min Generation Method iLast = 1 First(1) = 1 Last(1) = n % The next assignment remains invariant throughout the algorithm. Location(1) = 1 % Generate the first two vectors x' and x\" corresponding to x(0) and x(1). x' = x x\" = Comp(x') rLast = 1 % The iteration counter, Iter, is given a redundant bound of MaxIter = 100, noting that\nthe method will handle a problem as large as n = 2k for k = MaxIter – 1.\nMaxIter = 100 For Iter = 1 to MaxIter\n% Each iteration creates a new partition of N and associated vectors x' and x\". % Update the vector index rLast for recording x(rLast) = x' and x(rLast+1) = x\". rLast = rLast + 1 For i = 1 to iLast\n% Split each set N(i) of the current partition for i = 1 to iLast. Loc = Location(i) SetSize = Last(Loc) + 1 – First(Loc) If i is odd then\nSplit = SetSize/2\nElse\nSplit = SetSize/2\nEndif SplitPoint = First(Loc) + Split – 1 FirstL= First(Loc) LastL= SplitPoint FirstR = SplitPoint + 1 LastR = Last(Loc)\n% The next two loops carry out the assignments (1) – (4). % (If FirstL > LastL or FirstR > LastR, the corresponding\nloop should be skipped.)\nFor j = FirstL to LastL\nxj' = 1 – xj\nxj\" = xj Endfor (j) For j = FirstR to LastR xj' = xj xj\" = 1 - xj Endfor (j) % First(Loc) = FirstL already is true Last(Loc) = LastL First(Loc + iLast) = FirstR Last(Loc + iLast) = LastR\nEndfor (i) rLast = rLast + 1\nIf rLast  rLim then Stop. % Identify MaxNum = |N(1)| (Location(1) = 1 is invariant). MaxNum = Last(1) + 1 – First(1) If MaxNum = 1 then\n% All vectors x' and x\" have been generated. No need to update the final partition. Stop\nEndif % Update the partitions by updating the Location(i) array, to assure that\nLoc = Location(i) identifies where N(i) is stored for i = 1 to iLast.\nFor i = iLast to 1 (-1) % i = iLast, iLast – 1, …, 1\nLoc = Location(i) Location(2i – 1) = Loc Location(2i) = Loc + iLast\nEndfor (i) iLast = 2iLast If MaxNum = 2 then\n% Identify the number Num2 of sets having |N(i)| = 2. Don’t need to use\nLoc = Location(i) since the order of the sets doesn’t matter.\nNum2 = 0 For i = 1 to iLast\nIf Last(i) > First(i) then\nNum2 = Num2 + 1\nEndif\nEndfor (i) If Num2 ≤ Threshold then\n% Skip generating a final assignment. All relevant x' and x\"\nvectors have been generated.\nStop\nEndif\nEndif\nEndfor (Iter)\nThe number of iterations of the method within the “For Iter = 1 to MaxIter” loop will equal log2n or 1 + log2n , depending on whether the method stops because Num2 ≤ Threshold. (Hence the algorithm produces either 2log2n or 2 + 2log2n vectors in total.)"
    }, {
      "heading" : "2.3 Illustration",
      "text" : "We illustrate the method applied to the case for N = {1, 2, …, 11}. The outcomes for each iteration are shown in a block headed by “Iter = 1,” “Iter = 2,” and so forth. Each set N(i) for the current Iter is identified within “{ }” brackets, immediately below the value shown for the associated index i. Following this are the symbols “L” and “R” identifying the sets NL(i) and NR(i), which are depicted in the form {(NL(i)) (NR(i))}. Thus, for example, in the block for Iter = 3, the grouping {(7 8) (9 10 11)} beneath i = 2 discloses that NL(2) = {7, 8} and NR(2) = {9, 10, 11}.\nFollowing the rules of the algorithm, when a set N(i) cannot be divided into two equal left and right halves, NL(i) is the “larger half” or “smaller half” according to whether i is odd or even. Consequently, for Iter = 3 and i = 2, where i is even, the set NL(2) is the smaller half of N(2) (containing 2 elements compared to the 3 elements of NR(2)).\nThe vectors x' and x\" illustrated are based on assuming the seed vector x is the 0 vector. Hence the first two vectors generated (not shown) are x' = (0, 0, …, 0) and x\" = (1, 1, …, 1).\nIt should be pointed out that the partition shown at the beginning of each iteration is actually the one that is created by the updating operation at the conclusion of the preceding iteration. (The partition for Iter = 1 is the full set N, which is created as the initial N(1) outside the main loop, before Iter is assigned a value.) Listing the partitions in this way gives a better picture of the way the method operates, but provides a slight distortion concerning the termination condition. In particular, the value of MaxNum = |N(1)| shown at the beginning of each iteration is the MaxNum value identified by the algorithm at the conclusion of the preceding iteration. Consequently, as indicated below, the method terminates for this example at the end of Iter = 4, since the value MaxNum = 1 that triggers this termination is identified at the conclusion of this iteration.\nIter = 1 MaxNum = |N(1)| = 11 i = 1\n{1 2 3 4 5 6 7 8 9 10 11}\nL R\n{(1 2 3 4 5 6) (7 8 9 10 11)}\nx' = 1 1 1 1 1 1 0 0 0 0 0 x\" = 0 0 0 0 0 0 1 1 1 1 1\nIter = 2 MaxNum = |N(1)| = 6 i = 1 2\n{1 2 3 4 5 6} {7 8 9 10 11}\nL R L R\n{(1 2 3) (4 5 6)} {(7 8) (9 10 11)}\nx' = 1 1 1 0 0 0 1 1 0 0 0 x\" = 0 0 0 1 1 1 0 0 1 1 1\nIter = 3 MaxNum = |N(1)| = 3 i = 1 2 3 4\n{1 2 3} {4 5 6} {7 8} {9 10 11}\nL R L R L R L R\n{(1 2) (3)} {(4) (5 6)} {(7) (8)} {(9) (10 11)}\nx' = 1 1 0 1 0 0 1 0 1 0 0 x\" = 0 0 1 0 1 1 0 1 0 1 1\nIter = 4 MaxNum = |N(1)| = 2 i = 1 2 3 4 5 6 7 8\n{1 2} {3} {4} {5 6} {7} {8} {9} {10 11}\nL R R L L R L R L L R\n{(1) (2)} {(3)} {(4)} {(5) (6)} {(7)} {(8)} {(9)} {(10) (11)}\nx' = 1 0 0 1 1 0 1 0 1 1 0 x\" = 0 1 1 0 0 1 0 1 0 0 1\nThe method Stops at this point (by identifying MaxNum = |N(1)| = 1).\nAppendix 2 gives a “balanced” variant of the Max/Min approach that more nearly assures the number of complemented and un-complemented elements are equal."
    }, {
      "heading" : "2.4 Modifying x' to Produce Different Numbers of Complemented Variables",
      "text" : "We may modify the vector x' produced at each stage of the method by changing the treatment of every second or every third element such that xj' = 1 – xj by instead setting xj' = xj (e.g., setting x4', x7' and x10' equal to 0 in the last iteration of the illustration above if every second complemented element is changed, and setting x5' and x10' equal to 0 if every third complemented element is changed.). Similarly, we may replace every second or third element such that xj' = xj by instead setting xj' = 1 – xj (which sets x3' and x8' equal to 1 in the last iteration of the preceding illustration if every second such element is changed, and sets just x6' equal to 1 if every third such element is changed).\nThis departs from the Max/Min approach, which generates vectors consisting of approximately equal numbers of complemented and un-complemented elements, to produce vectors containing approximately 1/4 complemented and 3/4 un-complemented elements (or vice versa) if every second element designated element is changed, and approximately 1/3 complemented and 2/3 uncomplemented elements (or vice versa) if every third designated element is changed. This additional collection of vectors, when added to the collection generated directly by the Max/Min\napproach, produces greater variety in the types of vectors produced, though with the outcome that the members of this larger collection are less diverse relative to each other.\nThe next section provides a “Augmented-Max/Min” approach that generates additional vectors by an easily implemented alternative rule."
    }, {
      "heading" : "3. Augmented-Max/Min Diversification Generator",
      "text" : "The Augmented-Max/Min generation method, as in the case of the Max/Min generation approach, undertakes to subdivide N successively into k different approximately equal sized subsets, as k ranges over the k = 2, 4, 8, 16, …, where each subset is constructed to differ “as much as possible”\nfrom all others. Also, as in the Max/Min method, each subset contains approximately (n/k) + .5 elements. Beyond this, however, the Augmented-Max/Min approach includes numbers of subsets halfway between these values, adding the values of k given by k = 3, 6, 12, … (hence k = 2p, 2p-1 + 2p, for p = 1, 2, 3, …). Each vector generated is accompanied by generating its complement, likewise as in the case of the Max/Min method.\nFor simplicity, as we have done in the illustration for the Max/Min method, our rules to describe the Augmented-Max/Min method will be framed as generating binary vectors from the seed vector x(0) = (0, 0, …, 0). Each vector xo' thus generated can be used to create a corresponding vector x' “derived from” an arbitrary seed vector x by setting xj' = xj if xoj' = 0, and xj' = 1 – xj if xoj' = 1. (In other words, x' results by complementing those components of x for which xoj' = 1, and leaving all remaining components of x unchanged.)\nWe denote the vectors generated by x((s)), for values of s = (n/k) + .5 as k ranges over the values k = 2, 3, 4, 6, 8, 12, 16, …. The vector x((s)) consists of alternating strings 1’s and 0’s, each of size s – i.e., starting with s 1’s, followed by s 0’s, then s 1’s, and so on. The final string within x((s)) contains s' ≤ s components where s' is the number remaining to give the vector x((s)) a total\nof n components. (Hence, s' = n – n/s∙s, if n/s is not an integer.) If n is a power of 2, and if we used only the values k = 2, 4, 8, … (that are likewise powers of 2), then the Augmented-Max/Min method would generate exactly the same collection of vectors as the Max/Min method.\nTo complete the description of the Augmented-Max/Min method, we impose a lower limit sLim = n.5 + .5 on the size of the string s, noting that the value s = (n/k) + .5 diminishes in size as k grows. In particular, we interrupt the process of generating the vectors x((s)) upon reaching the smallest value of s such that s > sLim. At this point, we complete the process by generating the final vectors x((s)) for the values of s given by s = sLim – 1, sLim – 2, …, 1."
    }, {
      "heading" : "3.1 Illustration",
      "text" : "For n = 51, we begin with the values s given by s = (n/k) + .5 for k = 2, 3, 4, 6 (since sLim = (51.5 + .5 = 7). This yields\nx((25)) consisting of 26 1’s followed by 25 0’s. x((16)) consisting of 16 1’s, then 16 0’s, then 16 1’s, then 16 0’s, then 3 1’s.\nx((12)) consisting of 12 1’s, then 12 0’s, …, then 3 1’s. x((8)) consisting of 8 1’s then 8 0’s, …, then 3 1’s\nThe sequence is then completed by\nx((6)) consisting of 6 1’s, then 6 0’s, …, then 3 1’s x((5)) consisting of 5 1’s, then 5 0’s, …, then one 1. … x((1)) consisting of alternating 1’s and 0’s."
    }, {
      "heading" : "3.2 Extension by a Shifting Procedure",
      "text" : "We enlarge the set x((s)) by creating an additional vector xo((s)) for each value of s > 1 by inserting s/2 0’s at the start of x((s)), and drop the last s/2 components of x((s)). (Hence xo((s)) “shifts” x((s)) to the right by s/2 components.) We do not bother to consider xo((1)) since by definition this vector would shift x((1)) by 0 components. (The alternative of shifting x((1)) by 1 component is of no interest, since it just produces the complement of x((1)).)\nAs in the case of the x((s)) vectors, we also generate the complement of each xo((s)) vector. The collection produced by the Augmented-Max/Min method contains somewhat more than twice the number of vectors produced by the Max/Min method, and the simplicity of its rules commends it for use as an alternative approach. As in the case of the Max/Min method, alternating 1’s in the x((s)) vectors may be replaced by 0’s, or alternating 0’s may be replaced by 1’s, to produce different balances in the numbers of components of these vectors that are complemented and uncomplemented.\nThe next section gives the algorithm that can be used in accompaniment with the foregoing algorithms to generate additional diversified vectors."
    }, {
      "heading" : "4. Expanded Diversification by Permutation Mappings",
      "text" : "We now introduce a procedure that operates by mapping a given collection of vectors into one or more new collections that differ from the original collection in a manner consistent with the concept of diversity previously employed. This procedure incorporates a method proposed in Glover (1997) and applied by Campos, Laguna and Marti (2005) for generating diverse permutations, which we modify and then extend to provide a set of additional mappings. Adapted to the present context, the method expands the collection of vectors x(r), r = 0 to rAdd by adding vectors x(r) for r ranging from r = rAdd + 1 to rLim (the chosen limit on the total number of such vectors produced).\nWe make reference to a gap value g and a starting value s which s ranges from 1 to g. We also\nrefer to an iteration index k that runs from 0 to a maximum value kMax = (n – s)/g (hence identifying kMax to be the largest k such that the index j = s + kg satisfies j ≤ n). (The gap g and the indexes s and k are also used in the Progressive Gap method of Appendix 1.)\nIn the present setting we recommend setting g = n/2 – 1, which is particularly compatible with applying a recursive version of the current Permutation Mapping Algorithm in conjunction with the Max/Min Algorithm."
    }, {
      "heading" : "4.1 Structure of the Diverse Permutations.",
      "text" : "The permutations generated derive from operating on a given vector of numbers (1, …, n), which we take to be the indexes of the variables xj for j = 1 to n. Within this context, we construct a permutation Pn(g) of (1, …, n) by reference to a series of “sub-permutations” Pn(g: s), for s = 1 to g, whose components are given by\nPn(g: s) = (s + kg: k = 0 to kMax)\nor equivalently\nPn(g: s) = (s, s + g, s + 2g, …, s + kMaxg).\nThe sub-permutations Pn(g: s) can be placed end to end in any order to create Pn(g). However, we favor using the reverse order, hence creating\nPn(g) = (Pn(g: s): for s = g, g – 1, …, 1)."
    }, {
      "heading" : "4.1.1 Illustration",
      "text" : "Consider the permutation Pn(g) for the case n = 14 and g = 6 (= n/2 – 1). The sub-permutations of Pn(g) are then\nPn(g: 1) = (1 7 13) Pn(g: 2) = (2 8 14) Pn(g: 3) = (3 9) Pn(g: 4) = (4 10) Pn(g: 5) = (5 11) Pn(g: 6) = (6 12)\nAssembling these sub-permutations in reverse order yields\nPn(g) = (6 12 5 11 4 10 3 9 2 8 14 1 7 13)"
    }, {
      "heading" : "4.2 Employing Pn(g) as a Permutation Mapping",
      "text" : "We treat Pn(g) as a mapping M = (m(1), m(2), …, m(n)) that generates a vector y(r) from a given vector x(r) by defining yj(r) = xm(j)(r). This gives rise to a new collection of diverse vectors y(r), r = 1 to rLast from the original collection x(r), r = 1, …, rLast in the following manner.\nPermutation Mapping Algorithm\nFor r = 1 to rLast\nFor j = 1 to n\ni = m(j) yj(r) = xi(r)\nEndfor (j)\nEndfor (r)\nWhen the Permutation MappingAlgorithm is applied to enlarge a current collection of vectors x(r). r = 1 to rAdd, the vector yj(r) above is replaced by xj(r + rAdd) (hence xj(r + rAdd) = xi(r)) as r ranges from 1 to rLast, followed by re-setting rAdd = rAdd + rLast. The process can be stopped at point when the value r + rAdd reaches the desired limit rLim on the total number of diverse vectors accumulated.\nWe now identify a way to go farther than a single application of the preceding algorithm."
    }, {
      "heading" : "4.3 Recursive Permutation Mapping",
      "text" : "The mapping M = (m(1), m(2)…, m(n)) can be applied to any permutation P = (p(1), …, p(n)) of the indexes j = 1 to n, and not only to the initial permutation Po = (1, 2, …, n). We specifically define the mapping M(P) = P' = (p'(1), …, p'(n)) by\np'(j) = p(m(j)) for j = 1, ..., m. (4.1)\nThe foregoing mapping therefore replaces the jth element of P' by the m(j)th element of P. Note that if P = Po = (1, 2, …, n) then P' = M(P) = M.\nSince M itself can be any permutation, it follows that Po is the identity element with respect to all such mappings; i.e., Po(M) = M(Po) = M, taking M to be an arbitrary permutation. The inverse M -1 of M, which yields M-1(M) = M(M-1) = Po, and whose components are denoted by by writing M -1 = (m-1(1), …, m-1(n)), can be identified from the following relationship:\nm-1(i) = j for i = m(j), j = 1, …, n (4.2)\n(hence m-1(m(j)) = j for all j, and noting that (4.2) also holds for i = 1, …,n, we also have m(m-1(i)) = i for all i).\nIn the present setting, we are only interested in permutations M of the form given by M = Pn(g), for Pn(g) as previously identified. We may illustrate the inverse mapping by reference to the illustration of section 4.1.1, where\nj = 1 2 3 4 5 6 7 8 9 10 11 12 13 14\nPn(g) = (6 12 5 11 4 10 3 9 2 8 14 1 7 13)\nThen applying (4.2) for M = Pn(g) to obtain the inverse, we have\nj = 1 2 3 4 5 6 7 8 9 10 11 12 13 14\nM-1 = (12 9 7 5 3 1 13 10 8 6 4 2 14 11)\n(M-1 may be constructed conveniently using visual cues by looking for the successive indexes i = 1, …, n such that m(j) = i.)"
    }, {
      "heading" : "4.3.1 Recursive Use of M",
      "text" : "To use M recursively, we start by applying M to Po obtain M(Po) = M as the first permutation of a series. This first M, which we denote by M1, is the one used to generate yj(r) = xi(r), for i = m(j), j = 1 to n, by the Permutation Mapping Algorithm. Then we apply the mapping M again to obtain the mapping M(M(Po)), or M 2(Po) = M 2, where we define M2 = M(M). Now apply the Permutation Mapping Algorithm with M replaced by M2 in its description. (I.e., we replace m(j) in this algorithm by m2(j), where M2 = (m2(1), …, m2(n)).) This is equivalent to redefining x(r) to be the vector y(r) produced by the first application of the Permutation Mapping Algorithm, followed by applying the algorithm in its original form (without replacing M by M2) to the resulting new x(r) vector.\nIn a similar manner, we may generate the mapping M3 = M(M(M)) = M(M2) and apply the Permutation Mapping Algorithm with M replaced by M3 = (m3(1), …, m3(n)). Again, equivalently, this corresponds to applying the Permutation Mapping Algorithm unchanged to the “updated” vector x(r) (which is the new vector y(r) obtained from the preceding pass). The recursive use of M in this fashion is motivated by the expectation that each step should create a useful diversification relative to the vector last produced, given that M is designed to create such diversification relative to the permutation Po which is an arbitrary initial indexing for the variables.\nEventually, for some value h  1 we obtain a “next” mapping Mh+1 = M(Mh) that yields the initial vector Po = (1, …, n) as its outcome, and the process cycles. The relationship M(M h) = Po discloses that Mh is in fact the inverse mapping M-1. This further implies that we can obtain the same collection of y(r) vectors by starting with M-1 (= Mh), then continuing with M-2 = M-1(M-1) (= Mh-1), until finally reaching M-h (= M1 = M). In other words, starting with M-1 generates the same collection of y(r) vectors as starting with M, but in reverse order. Consequently, M-1 is on an equal footing with M as a diversifying permutation mapping. (The vector produced by reversing the order of the components of M does not have this same footing.)\nWhen applying the mapping M recursively as indicated, the number of different y(r) vectors that can be produced before reaching the “last” mapping Mh grows rapidly with the value of n (using the definition of M = Pn(g)). Consequently, the limit rLim on the total number of vectors generated may be reached long before cycling occurs. (Other definitions of M can potentially produce larger numbers of vectors before cycling, but our primary goal remains that of producing a diverse collection rather than a collection containing numerous elements.)"
    }, {
      "heading" : "4.4 Illustrated Use of Recursion",
      "text" : "We illustrate this recursive process for n = 9, where only a relatively small number of mappings are generated before cycling. For greater scope, we apply the mapping M = Pn(g) simultaneously to all of the vectors produced by the Max/Min Algorithm of Section 2. For n = 9 we have g = n/2 – 1 = 3, and hence\nP9(1: 3) = (1 4 7) P9(2: 3) = (2 5 8) P9(3: 3) = (3 6 9)\nto yield\nM = Pn(g) = (3 6 9 2 5 8 1 4 7)\nThe first (upper left) section of Table 1 below shows the 8 vectors produced by the Max/Min Algorithm, and lists the indexes j = 1 to n, the mapping M and the initial vector Po (shown as P0) above them. The next section, immediately below the first, shows the corresponding vectors upon applying M to the first section. Thus Po is replaced by M 1 (shown as M1), and the vectors listed as 9 through 16 are the result of applying M to the vectors listed as 1 through 8.\nThe third section likewise results by applying M to the second section, replacing M1 by M2 (shown as M2) and producing the vectors 17 through 24 from the corresponding vectors 9 through 16. The next section, which applies M once more to yield M3 (shown as M3), is the final pass of the recursive process, as may be verified by noting that M3 is in fact the inverse M-1 of M. The table shows the additional step that produces the vector M4 = Po, and causes all of the resulting vectors to be the same as in the first section of the table, though of course this step is not necessary.\nThe next section examines additional ways to generate diverse vectors, which can also be processed by the recursive mapping process to produce larger numbers of vectors."
    }, {
      "heading" : "5. Diversified Vectors from Balanced Sub-Vectors",
      "text" : "An auxiliary type of diversification approach results from a construction that is approximately the inverse of the one underlying the Max/Min Generation method. Instead of doing a “successive binary partitioning” of the index set for a seed vector, as a basis for identifying variables to\ncomplement, we start from the other end and employ a constructive process to achieve an objective similar to that pursued by the Max/Min Generation method."
    }, {
      "heading" : "5.1 Sub-Vector Coverage",
      "text" : "Let y = (y1, …, yp) denote a p-dimensional sub-vector that we seek to incorporate within a vector x' by repeating y multiple times within x'. We will produce a collection Y of these p-dimensional\nsub-vectors, and use each y  Y to build a different vector x'. Evidently we want the vectors y in Y to differ from each other, since this will assure the resulting vectors x' will likewise differ, and if p is not large, then the differences between the vectors y in Y will be magnified in the vectors x' since the latter will differ over a larger number (and proportion) of their components. To facilitate the analysis, we again suppose the seed vector x is the 0 vector and understand that the assignment xj' = 0 corresponds to setting xj' = xj and the assignment xj' = 1 corresponds to setting xj' = 1 – xj.\nFor the purpose of keeping p relatively small, we start by considering values of p in the range from 3 to 7. For a given value of p, we obtain a “maximum coverage” of the sub-space associated with the vectors y = (y1, …, yp) in Y if these vectors constitute all 2 p binary sub-vectors of dimension p (hence yielding |Y| = 2p with a cardinality ranging from 8 to 128 for the indicated small p values). This maximum sub-space coverage derives from the obvious fact that no other collection of pdimensional sub-vectors succeeds to matching every 0-1 vector possibility in the sub-space. However, the vectors y in Y by themselves are not particularly attractive as components to be incorporated in the vectors x', because Y does not come close to satisfying the balanced diversity\ncriterion which would require each of its members y  Y to have approximately half of its entries 1 and half 0. In fact, by satisfying the maximum sub-vector coverage property, Y conflicts with the balanced diversity criterion to the greatest extent possible.\nTo remedy this shortcoming, we treat each vector y in Y as the first half of a larger vector\ncontaining 2p components. Denoting a specific vector y  Y by y', we choose the second half of the 2p component vector to consist of the complement y\" of y' (which is also in Y). Then the “double length” vector y2 = (y', y\") possesses the desired property of containing half 0’s and half 1’s and yet the collection of such y2 vectors satisfies a relaxed form of the maximum sub-vector coverage property in that both of the halves y' and y\" of y2 satisfy this property in relation to pdimensional vectors as y' (and hence y\") ranges over the 2p vectors in Y to produce y2.\nWe replicate this new y2 vector as many times as possible to generate a n-vector x' = (y2, y2, y2, …, y2), understanding that the final y2 is truncated as necessary to permit x' to have n components. Then x' will also meet the balanced diversity criterion of containing roughly half 0’s and half 1’s (as will its complement x\").\nPerforming this same doubling operation with each of the 2p vectors y' in Y, we create 2p corresponding vectors y2 = (y', y\"), and thus produce in turn 2p vectors of the form x' = (y2, y2, y2, …, y2).\nThe ability to choose p relatively small results from the fact that the 2p vectors x' (and the associated 2p vectors x\") will constitute a sufficiently large number to provide as many of these\nvectors as desired while p retains a modest value. We can also choose different values of p, and generate different composite vectors y2 = (y', y\") to build up different x' vectors.\nIllustration\nThis construction is illustrated for p = 3 by listing the 2p = 8 vectors y'  Y on the left below, and matching each with its complement y\" on the right.\nh y' y\"\n---- ------- --------\n1 1 1 1 0 0 0 2 1 1 0 0 0 1 3 1 0 1 0 1 0 4 1 0 0 0 1 1 5 0 1 1 1 0 0 6 0 1 0 1 0 1 7 0 0 1 1 1 0 8 0 0 0 1 1 1\nFor purposes of generating these y' and y\" vectors, note that the vectors y' in the left column above correspond to listing the binary numbers from 0 to 7 in a bottom-to-top sequence and the vectors y\" in the right column correspond to listing these same numbers in a top-to-bottom sequence. Accordingly, a convenient way to generate such vectors is to refer to the binary numbers that correspond to the vectors y' and then, upon listing them in reverse order, to create the vectors y\" that correspond to the binary numbers in this reverse ordering.\nFinally, upon coupling these y' and y\" vectors to yield the 8 vectors of the form y2 = (y', y\"), we obtain the following 8 vectors x' = (y2, y2, …, y2), where we insert the symbol “|” to depict the separation between successive y2 vectors.\n(1, 1, 1, 0, 0, 0, | 1, 1, 1, 0, 0, 0, | 1, 1, 1, 0, 0, 0, | …) (1, 1, 0, 0, 0, 1, | 1, 1, 0, 0, 0, 1, | 1, 1, 0, 0, 0, 1, |…) (1, 0, 1, 0, 1, 0, | 1, 0, 1, 0, 1, 0, | 1, 0, 1, 0, 1, 0, |…)\n. . . . . .\n(0, 0, 0, 1, 1, 1, | 0, 0, 0, 1, 1, 1, | 0, 0, 0, 1, 1, 1, |…)\nSuch a collection may either be used by itself or added to those generated by the other algorithms of this paper to provide additional vectors (noting that some of the vectors of the current collection can also duplicate some of those generated by the other algorithms).\nGenerating Vectors with Different Balances Between 1’s and 0’s\nAs in the case of the Max/Min collection, we can generate vectors consisting of a different ratio of 1’s and 0’s. In addition to modifying vectors already generated by assigning some of their\ncomponents the opposite of the value previously assigned, we can also produce a different form of variation in the numbers of 1’s and 0’s in the following manner.\nEach vector pair y', y\" is extended to become a triple y', y\", yo, where yo is defined by setting yj o = yj' for j ≤ p/2 and yj o = yj\" for j > p/2. (Equivalently, y o complements the “second half” of the y' vector, leaving the first half unchanged.) Hence yo results by complementing roughly half the components of each of y' and y\", and thus is “maximally different” from these two vectors. (This effect is best achieved when p is chosen to be an even number.) We make use of this string of 3p elements by assembling each of its 2p instances end to end to produce 2p different x' vectors.\nThe number of 1’s and 0’s will vary by adding from 0 to p additional 1’s to each vector. (Most vectors will add p/2 new 1’s, then the next largest number of vectors will add p/2 +1 or p/2 – 1 new 1’s, etc.. For example, when p = 4, producing 2p = 16 different vectors, the number of vectors that add k 1’s will be 1 for k = 0, 4 for k = 1, 6 for k = 2, 4 for k = 3 and 1 for k = 4.)"
    }, {
      "heading" : "6. Conclusions",
      "text" : "Strategies that generate meaningful collections of diverse vectors are highly desirable in metaheuristic optimization. As a foundation for creating such collections, we have shown how various forms of a Max/Min principle lead to diversification methods that can be usefully refined and generalized by augmentation and shifting procedures, and by special types of permutation mappings. Working backward, we also show how to achieve useful forms of diversification by a simple constructive approach to generate balanced sub-vectors.\nOur methods motivate future research to apply them in the presence of constraints that are imposed to achieve intensification as well as diversification goals, as by bounding admissible objective function values or by setting limits on admissible distances from previous high quality solutions, and using supporting methods such as strategic oscillation that alternately drive the search to violate such limits and then to enforce them again by manipulating neighborhoods and search directions.\nAn instance of this type of extension consists of methods for generating diverse vectors that yield a selected number of elements in particular subsets equal to 1, using the Max/Min approach as an internal routine. Such methods can be useful in metaheuristic intensification strategies where it can be valuable to look for new solutions in which specified subsets of variables have approximately the same number of elements equal to 1 as in the best solutions. Joining such an approach with clustering strategies, and identifying different subsets of variables that may be relevant in different clusters, provides an area for further refinement."
    }, {
      "heading" : "F; Glover (2005) \"Adaptive Memory Projection Methods for Integer Programming,” in",
      "text" : "Metaheuristic Optimization Via Memory and Evolution, eds. C. Rego and B. Alidaee, Kluwer Academic Publishers, pp. 425-440.\nF. Glover and J.-K. Hao (2017) “Diversification-Based Learning in Computing and Optimization,”\nResearch Report, College of Engineering and Applied Science, University of Colorado, Boulder.\nF. Gortazar, A. Duarte, M. Laguna and R. Martí (2010) “Black Box Scatter Search for General\nClasses of Binary Optimization Problems,” Computers and OR, In Press.\nM. Laguna and R. Martí (2003) Scatter Search: Methodology and Implementations in C\nKluwer Academic Publishers: Boston, ISBN: 1-4020-7376-3.\nE. Mayoraz and M. Moreira (1999) “Combinatorial Approach for Data Binarization,” chapter in\nPrinciples of Data Mining and Knowledge Discovery, Volume 1704 of the series Lecture Notes in Computer Science, pp 442-447.\nAppendix 1: The Progressive Gap (PG) Method\nWe slightly modify the original description of the Progressive Gap method to clarify its main components and to give a foundation for the Extended PG method described below.\nNotation for the PG Method\ng = a gap value s = a starting index k = an increment index\nMethod Overview\nStarting with the seed vector x, successive vectors x' are generated by complementing specific components xj of x. A gap value g is used that iteratively varies over the range g = 1 to gMax, where gMax = n.5 + .5.1 Then, for each gap g, a starting index s iterates from s = 1 to sLim, where sLim = g except in the special case where g = 2 where sLim is restricted to 1 (to avoid a duplication among the vectors x' generated).\nFrom the initial assignment x' = x, the method sets xj' = 1 – xj for the index j = s + kg, as the increment index k ranges from 0 to kMax = (n – s)/g. Thus, xj' receives this complemented value of xj for j = s, s + g, s + 3g, …, thereby causes each j to be separated from the previous j by the gap of g. (The actual gap between two successive values of j is thus g – 1. For example, when g = 1, the values j and j + g = j + 1 are adjacent, and in this sense have a “0 gap” between them.) The indicated formula for the maximum value of k sets kMax as large as possible, subject to assuring j does not exceed n (when j attains its largest value j = s + kMax∙g). Each time a vector x' is generated, the corresponding vector x\" = Comp(x') is also generated. This simple pattern is repeated until no more gaps g or starting values s remaining to be considered.\nPG Algorithm\nrLast = 0 gMax = n.5 + .5 % Iterate over gap values g. For g = 1 to gMax\n% Choose the max starting index sLim to be the same as the gap g unless g = 2.\n1 A different limiting value for g is proposed in Glover (1997), consisting of gMax = n/5. The rationale for this upper limit in both cases is based on the fact that as g grows, the difference between x and x' becomes smaller, and hence a bound is sought that will prevent x' from becoming too similar to x.\nIf g = 2 then\nsLim = 1\nelse\nsLim = g\nEndif % Iterate over starting values s For s = 1 to sLim\n% Identify the largest value kMax for the increment index k so that the index j of xj\ngiven by j = s + kg will not exceed n.\nkMax = (n – s)/g % Increment the index rLast for identifying the vectors currently generated\nas x(r) for r = 0 to rLast.\nrLast = rLast + 1 % Begin generating the new vector x(rLast) = x'. x' = x % Start j at the starting index s. j = s For k = 0 to kMax\n% For each value k, implicitly j = s + kg xj' = 1 – xj % Insert a gap of g between the current j and the next j j = j + g\nEndfor (k) % the new vector x(rLast) = x' is now completed. Increment rLast and generate\nthe complement x\" of x' to implicitly identify x(rLast) = x\" for the next value of rLast.\nrLast = rLast + 1 x\" = Comp(x')\nIf rLast  rLim then Stop\nEndfor (s)\nEndfor (g)\nRemark: The method can avoid generating x\" = Comp(x') when x' is the first vector generated (i.e., x' = x(1)), since in this case Comp(x') = x, thus yielding the seed vector (x(0))."
    }, {
      "heading" : "To illustrate for the case where the seed vector is x = (0, 0, …, 0), the procedure generates the",
      "text" : "following vectors x' for the sampling of values shown for the starting index s and the gap g. Note that the vector x' for s = 2, g = 2 (marked with a “*” below) duplicates the complement of the x' vector for s = 1, g = 2. This is the reason the algorithm restricts the value sLim to 1 when g = 2, thus causing the vector for s = 2, g = 2 to be skipped.\ns = 1, g = 2: (1 0 1 0 1 0 1 0 1 0 …) s = 1, g = 3: (1 0 0 1 0 0 1 0 0 1 …) s = 2, g = 2: (0 1 0 1 0 1 0 1 0 0 …) * s = 2, g = 3: (0 1 0 0 1 0 0 1 0 0 …) s = 3, g = 2: (0 0 1 0 1 0 1 0 1 0 …)\ns = 3, g = 3: (0 0 1 0 0 1 0 0 1 0 …)\nExtended Version\nThe Extended PG Method can be used to generate a larger number of points, and also provides an additional form of variation in the vectors generated.\nThe extended version of the Progressive Gap Method is for situations where the basic version of the method provides fewer points than desired.\nBrief Overview.\nThe extended method “fills in spaces” between successive j values that determine the assignment xj' = 1 – xj. The method makes this assignment for a string of j values from j = j1 to j2, where j2 is chosen to leave an unassigned position between j2 and the next value of j1 given by j1 = jj + g. Consequently, j2 = j1 + g – 2 (and the method chooses j2 = j1 until g > 2.)\nThe resulting algorithm avoids referring to a starting index s to identify the location of the “first j value” at which xj' = 1 – xj. Instead, the starting value is always j = 1. This results from the fact that the complements x\" produced for the x' vectors automatically include all of the vectors x' that would be derived by using different starting indexes s.\nThe extended algorithm is stated as follows.\nExtended PGAlgorithm\nrLast = 0 gMax = n.5 + .5 % Iterate over gap values g. For g = 1 to gMax\nkMax = (n – 1)/g rLast = rLast + 1 % Begin generating the new vector x(rLast) = x'. x' = x % Start j1 at the value 1. j1 = 1 % identify the max value Δgmax that is added to j1 to produce j2 If g = 1 then\nΔgmax = 0\nElse\nΔgmax = g – 2\nEndif For Δg = 0 to Δgmax For k = 0 to kMax\n% For each value k, implicitly jj = 1 + kg j2 = j1 + Δg\nFor j = j1 to j2\nxj' = 1 – xj\nEndfor (j) % Insert a gap of g between the current j1 and the next j1 j1 = j1 + g\nEndfor (k) % the new vector x(rLast) = x' is now completed. Increment rLast and generate\nthe complement x\" of x' (implicitly identifying x(rLast) = x\" for the next value of rLast.\nrLast = rLast + 1 x\" = Comp(x')\nIf rLast  rLim then Stop\nEndfor (Δg)\nEndfor (g)\nThe PG Algorithm can be extended in additional ways, but we restrict attention to the preceding approach as the primary variation. Combining either the PG Algorithm its extension with Algorithm 3 will succeed in producing an additional collection of diversified vectors if still more such vectors are sought.\nAppendix 2: A “Balanced” Variant of the Max/Min Algorithm\nThe idea underlying the Balanced Variant of Algorithm 2 is to assure that sets N(i) with an odd\nnumber of elements SetSize are split so that SetSize/2 of their elements go into NL(i) when an odd number of such sets have been encountered and SetSize/2 of their elements go into NL(i) when an even number of such sets have been encountered. The rule is applied anew at each iteration (each successive value of Iter), when creating a new partition from the current sets N(i) for i = 1 to iLast.\nThe “balanced” terminology comes from the fact that this approach will tend to balance the number of variables xj that are complemented and not complemented to produce the vector x' generated on the current iteration. When this approach is not used, the order in which the current\nN(i) sets occur could cause each set with |N(i)| odd to be split in the same way, putting SetSize/2\n(or SetSize/2) elements in NL(i), thus causing the number of complemented xj to exceed the number of xj not complemented (or vice versa).\nWhen the Balanced Variant is used, the final assignment to be made (following the determination that MaxNum = 2) has a simple form that allows x' and x\" to be created by the following shortcut step.\nxj' = 1 – xj if j is odd (1') xj' = xj if j is even (2')\nand\nxj\" = xj if j is odd (3') xj\" = 1 – xj if j is even (4')\nConsequently, when MaxNum = 2, the method immediately makes this simplified final assignment and then stops.\nThe detailed form of this approach is as follows. A logical variable named OddSet keeps track of whether an even odd number of sets with |N(i)| odd have been encountered.\nBalanced Variant of the Max/Min Generation Method iLast = 1 First(1) = 1 Last(1) = n Location(1) = 1 % Generate the first two vectors x' and x\" corresponding to x(0) and x(1). x' = x x\" = Comp(x') rLast = 1 MaxIter = 100 For Iter = 1 to MaxIter\n% Each iteration creates a new partition of N and associated vectors x' and x\". % Update the vector index rLast for recording x(rLast) = x' and x(rLast+1) = x\". rLast = rLast + 1 % Initialize the logical variable OddSet to keep track of whether an even or odd number of\nsets N(i) have been encountered with SetSize = |N(i)| odd.\nOddSet = True For i = 1 to iLast\n% Split each set N(i) of the current partition for i = 1 to iLast. Loc = Location(i) SetSize = Last(Loc) + 1 – First(Loc) If SetSize is odd then\nIf OddSet = True then\nSplit = SetSize/2 OddSet = False\nElse\nSplit = SetSize/2 OddSet = True\nEndif\nElse\nSplit = SetSize/2\nEndif SplitPoint = First(Loc) + Split – 1 FirstL= First(Loc) LastL= SplitPoint FirstR = SplitPoint + 1 LastR = Last(Loc) % The next two loops carry out the assignments (1) – (4). % (If FirstL > LastL or FirstR > LastR, the corresponding\nloop should be skipped.)\nFor j = FirstL to LastL\nxj' = 1 – xj\nxj\" = xj Endfor (j) For j = FirstR to LastR xj' = xj xj\" = 1 - xj Endfor (j) % First(Loc) = FirstL already is true Last(Loc) = LastL First(Loc + iLast) = FirstR Last(Loc + iLast) = LastR\nEndfor (i) rLast = rLast + 1\nIf rLast  rLim then Stop. % Identify MaxNum = |N(1)| (Location(1) = 1 is invariant). MaxNum = Last(1) + 1 – First(1) If MaxNum = 1 then\n% All vectors x' and x\" have been generated. No need to update the final partition. Stop\nEndif % Update the partitions by updating the Location(i) array, to assure that % Loc = Location(i) identifies where N(i) is stored for i = 1 to iLast. For i = iLast to 1 (-1) % i = iLast, iLast – 1, …, 1\nLoc = Location(i) Location(2i – 1) = Loc Location(2i) = Loc + iLast\nEndfor (i) iLast = 2iLast If MaxNum = 2 then\n% Identify the number Num2 of sets having |N(i)| = 2. Don’t need to use\nLoc = Location(i) since the order of the sets doesn’t matter.\nNum2 = 0 For i = 1 to iLast\nIf Last(i) > First(i) then\nNum2 = Num2 + 1\nEndif\nEndfor (i) If Num2 ≤ Threshold then\n% Skip generating a final assignment. All relevant x' and x\"\nvectors have been generated.\nStop\nElse\n% Generate the shortcut assignment (1') to (4'). For j = 1 to n\nIf j is odd then\nxj' = 1 – xj xj\" = xj\nElse\nxj' = xj\nxj\" = 1 – xj Endif\nEndfor Stop\nEndif\nEndif\nEndfor (Iter)\nAppendix 3: Strongly Balanced Vector Generation\nWe consider a recursive process to generate diverse vectors that are not only composed of approximately half 0’s and half 1’s, but that additionally are strongly balanced in the sense that every successive pair of elements consists of a single 0 and a single 1. We start with the case for p = 2 and consider just the 2 vectors that contain exactly one 0 and one 1, which are complements of each other:\ny(1) = (1,0) and y(2) = (0,1).\nWe could use these vectors by themselves to generate the two x vectors given by x(1) = (y(1), y(1), …) and x(2) = (y(2), y(2), …), which also are complements of each other.\nNow we consider all ways of pairing these two vectors, thus obtaining all vectors of the form (y(p), y(q)) for p, q = 1, 2 (i.e., (y(1), y(1)), (y(1), y(2)), …, etc.) From this we obtain the 4 new vectors\ny(1) = (1, 0, 1, 0), y(2) = (1, 0, 0, 1), y(3) = (0, 1, 1, 0), y(4) = (0, 1, 0, 1)\nThe complement of each of these vectors is also contained in the collection generated. (For example, y(1) and y(4) are complements, and y(2) and y(3) are complements.) Moreover, these y vectors satisfy the strongly balanced property where every successive two components of these vectors consists of one 0 and one 1.\nAgain, we can form the vectors x(h) = (y(h), y(h), ….) for h = 1 to 4 and the complement of each vector is likewise in the collection. (This holds even if the last y(h) vector in each x(h) must be truncated so that x(h) has dimension n.) Similarly, every two successive components of each vector consists of one 0 and one 1, although if n is odd there will not be a final “second component” to pair with xn(h).\nTo take this process one step farther, we combine the vectors y(1) through y(4) to produce all possible pairs (y(p), y(q)) for p, q = 1, 2, 3, 4. The 4 x 4 = 16 resulting combinations are shown below.\nh y(p) y(q)\n---- ---------- ----------\n1 1 0 1 0 1 0 1 0 2 1 0 1 0 0 1 0 1 3 1 0 1 0 0 1 1 0 4 1 0 1 0 1 0 0 1 5 0 1 0 1 1 0 1 0 6 0 1 0 1 0 1 0 1 7 0 1 0 1 0 1 1 0 8 0 1 0 1 1 0 0 1 9 0 1 1 0 1 0 1 0\n10 0 1 1 0 0 1 0 1 11 0 1 1 0 0 1 1 0 12 0 1 1 0 1 0 0 1 13 1 0 0 1 1 0 1 0 14 1 0 0 1 0 1 0 1 15 1 0 0 1 0 1 1 0 16 1 0 0 1 1 0 0 1\nAs before, the complement of every vector is also contained in the collection, and every two successive elements consists of one 0 and one 1. By stringing these vectors together to produce vectors x(h) = (y(h), y(h), …), the resulting x(h) vectors will include vectors produced for the previous level when h ranged from 1 to 4.\nIf it is desired to go farther, we may produce the pairs (y(p), y(q)) from this collection to produce 16 x 16 = 256 new y(h) vectors, each containing 8 + 8 = 16 components. These strongly balanced vectors do not possess some of the key features of vectors generated by the other methods described in this paper, and hence produce collections that are less diversified. Nevertheless, we anticipate that their novel structure may prove useful in certain types of applications."
    } ],
    "references" : [ {
      "title" : "An Experimental Evaluation of a Scatter Search for the Linear Ordering Problem,",
      "author" : [ "V. Campos", "F. Glover", "M. Laguna", "R. Martí" ],
      "venue" : "Journal of Global Optimization,",
      "citeRegEx" : "Campos et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Campos et al\\.",
      "year" : 2001
    }, {
      "title" : "Context-Independent Scatter and Tabu Search for Permutation Problems,",
      "author" : [ "V. Campos", "M. Laguna", "R. Martí" ],
      "venue" : "INFORMS Journal on Computing,",
      "citeRegEx" : "Campos et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Campos et al\\.",
      "year" : 2005
    }, {
      "title" : "Tabu Search for the Maximum Diversity Problem,",
      "author" : [ "A. Duarte", "R. Martí" ],
      "venue" : "European Journal of Operational Research,",
      "citeRegEx" : "Duarte and Martí,? \\Q2007\\E",
      "shortCiteRegEx" : "Duarte and Martí",
      "year" : 2007
    }, {
      "title" : "Heuristics Algorithm for the Maximum Diverstity Problem,",
      "author" : [ "M. Gallego", "A. Duarte", "M. Laguna", "R. Martí" ],
      "venue" : "Computational Optimization and Application,",
      "citeRegEx" : "Gallego et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Gallego et al\\.",
      "year" : 2008
    }, {
      "title" : "Heuristics for Integer Programming Using Surrogate Constraints,",
      "author" : [ "F. Glover" ],
      "venue" : "Decision Sciences",
      "citeRegEx" : "Glover,? \\Q1977\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 1977
    }, {
      "title" : "Tabu Search for Nonlinear and Parametric Optimization (with Links to Genetic Algorithms),",
      "author" : [ "F. Glover" ],
      "venue" : "Discrete Applied Mathematics",
      "citeRegEx" : "Glover,? \\Q1994\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 1994
    }, {
      "title" : "A Template for Scatter Search and Path Relinking,",
      "author" : [ "F. Glover" ],
      "venue" : "Artificial Evolution, Lecture Notes in Computer Science",
      "citeRegEx" : "Glover,? \\Q1997\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 1997
    }, {
      "title" : "Scatter Search and Path Relinking,",
      "author" : [ "F. Glover" ],
      "venue" : "New Ideas in Optimization,",
      "citeRegEx" : "Glover,? \\Q1999\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 1999
    }, {
      "title" : "Multi-Start and Strategic Oscillation Methods – Principles to Exploit Adaptive Memory,” Computing Tools for Modeling, Optimization and Simulation: Interfaces in Computer",
      "author" : [ "F. Glover" ],
      "venue" : "Science and Operations Research,",
      "citeRegEx" : "Glover,? \\Q2000\\E",
      "shortCiteRegEx" : "Glover",
      "year" : 2000
    }, {
      "title" : "Adaptive Memory Projection Methods for Integer Programming,",
      "author" : [ "Glover" ],
      "venue" : "Metaheuristic Optimization Via Memory and Evolution,",
      "citeRegEx" : "F and Glover,? \\Q2005\\E",
      "shortCiteRegEx" : "F and Glover",
      "year" : 2005
    }, {
      "title" : "Diversification-Based Learning in Computing and Optimization,",
      "author" : [ "F. Glover", "J.-K. Hao" ],
      "venue" : "Research Report, College of Engineering and Applied Science,",
      "citeRegEx" : "Glover and Hao,? \\Q2017\\E",
      "shortCiteRegEx" : "Glover and Hao",
      "year" : 2017
    }, {
      "title" : "Black Box Scatter Search for General Classes of Binary Optimization Problems,",
      "author" : [ "F. Gortazar", "A. Duarte", "M. Laguna", "R. Martí" ],
      "venue" : "Computers and OR,",
      "citeRegEx" : "Gortazar et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Gortazar et al\\.",
      "year" : 2010
    }, {
      "title" : "Scatter Search: Methodology and Implementations in C Kluwer Academic Publishers: Boston, ISBN: 1-4020-7376-3",
      "author" : [ "M. Laguna", "R. Martí" ],
      "venue" : null,
      "citeRegEx" : "Laguna and Martí,? \\Q2003\\E",
      "shortCiteRegEx" : "Laguna and Martí",
      "year" : 2003
    }, {
      "title" : "Combinatorial Approach for Data Binarization,",
      "author" : [ "E. Mayoraz", "M. Moreira" ],
      "venue" : null,
      "citeRegEx" : "Mayoraz and Moreira,? \\Q1999\\E",
      "shortCiteRegEx" : "Mayoraz and Moreira",
      "year" : 1999
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "Diversification for zero-one optimization can also be applied to nonlinear continuous (global) optimization, taking advantage of the fact that binarization methods developed for converting discrete and continuous data into binary data (Mayoraz and Moreira, 1999) have proved to be quite effective for making certain types of global continuous problems susceptible to solution by zeroone optimization, notably in the realms of cluster analysis and machine learning.",
      "startOffset" : 235,
      "endOffset" : 262
    }, {
      "referenceID" : 4,
      "context" : ", in exploiting strongly determined and consistent variables; as in Glover (1977, 2001) and Glover and Laguna (1997)).",
      "startOffset" : 68,
      "endOffset" : 117
    }, {
      "referenceID" : 6,
      "context" : "In this paper we introduce new diversification strategies for zero-one optimization that extend a framework for generating diverse collections of zero-one vectors originally proposed in the context of the Scatter Search and Path Relinking evolutionary algorithms (Glover, 1997).",
      "startOffset" : 263,
      "endOffset" : 277
    }, {
      "referenceID" : 10,
      "context" : ", Laguna an Marti, 2003), while the Max/Min method has advantages for achieving certain kinds of diversification, and is relevant to the topic of learning procedures for metaheuristic optimization, as embodied in the approach called Diversification-based Learning (DBL) (Glover and Hao, 2017).",
      "startOffset" : 270,
      "endOffset" : 292
    }, {
      "referenceID" : 4,
      "context" : "This procedure incorporates a method proposed in Glover (1997) and applied by Campos, Laguna and Marti (2005) for generating diverse permutations, which we modify and then extend to provide a set of additional mappings.",
      "startOffset" : 49,
      "endOffset" : 63
    }, {
      "referenceID" : 4,
      "context" : "This procedure incorporates a method proposed in Glover (1997) and applied by Campos, Laguna and Marti (2005) for generating diverse permutations, which we modify and then extend to provide a set of additional mappings.",
      "startOffset" : 49,
      "endOffset" : 110
    } ],
    "year" : 2017,
    "abstractText" : "We introduce new diversification methods for zero-one optimization that significantly extend strategies previously introduced in the setting of metaheuristic search. Our methods incorporate easily implemented strategies for partitioning assignments of values to variables, accompanied by processes called augmentation and shifting which create greater flexibility and generality. We then show how the resulting collection of diversified solutions can be further diversified by means of permutation mappings, which equally can be used to generate diversified collections of permutations for applications such as scheduling and routing. These methods can be applied to non-binary vectors by the use of binarization procedures and by Diversification-Based Learning (DBL) procedures which also provide connections to applications in clustering and machine learning. Detailed pseudocode and numerical illustrations are provided to show the operation of our methods and the collections of solutions they create.",
    "creator" : "Microsoft® Word 2016"
  }
}