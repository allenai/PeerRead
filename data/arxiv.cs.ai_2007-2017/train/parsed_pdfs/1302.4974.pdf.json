{
  "name" : "1302.4974.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Theoretical Framework for Context-Sensitive Temporal Probability Model Construction with Application to Plan Projection",
    "authors" : [ "Liem Ngo", "Peter Haddawy", "James Helwig" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 Introduction\nMost of our knowledge about the world is highly con textual. The use of context facilitates reasoning by allowing an agent to focus its attention on that por tion of its knowledge relevant to a given problem. In automated reasoning the need to use context be comes particularly acute when dealing with probabilis tic knowledge. While Bayesian networks provide a rel atively efficient method for representing and reasoning with probabilistic information, inference in Bayesian networks remains NP-hard [4]. This complexity be comes particularly problematic as researchers seek to build large models such as those that arise in model ing temporal processes. The most common way to use Bayesian networks for temporal reasoning is to repre sent time discretely and to create an instance of each time-varying random variable for each point in time.\nWe can greatly reduce the size of the network mod els if we can identify some deterministic information and use it as a context to index the probabilistic in formation. For example, in using Bayesian networks for plan projection, actions are typically represented\nas nodes in the network [6, ch7], [2, 5]. This often results in networks with large numbers of nodes and large link matrices. The reason is that we need two types of knowledge for each domain variable: a speci fication of how it is influenced by each action (causal rules), and a specification of how it behaves over time in the absence of actions that influence it (persistence rules). But since when evaluating a plan, the perfor mance of one's own actions is deterministic knowledge\n- we know whether or not we plan to attempt an action-, actions can be used as context information.\nWe propose representing a class of Bayesian networks with a knowledge base of probabilistic rules augmented with context constraints. A context constraint is a logical expression that determines the applicability of a probabilistic relation based on some deterministic knowledge. A context-constrained rule has the general form (P( consequent/ antecedents) = prob) <--- context.\nFor example, we could represent the effect of a paint action with a set of context-constrained rules, one of which might be (P(painted(x, t)) = .99) <--- paint(x, t1) and the persistence of painted with as set of rules, one of which might be (P(painted(x,t) /painted(x,t1)) = .95) Each of these rules has a link matrix half the size of that for a rule representing both the action effect and persistence, and only one of these rules is applicable at any time point.\nAlthough Breese [3) developed a system for reasoning with such context constrained rules, he did not pro vide a formal semantics for the rules. In previous work [9] we began to address this problem by presenting a formal framework for constructing Bayesian networks from knowledge bases of first-order probability logic sentences. But that work did not allow contextual indexing of probability models and imposed several constraints on the language that limited its expres sive power. The objective of this paper is to provide a formal theory for representing context-sensitive tem poral probabilistic knowledge and to show how such a representation can be used for efficient probabilistic temporal reasoning.\nThe rest of this paper is organized as follows. First we provide an overview of the medical problem of evaluat-\n420 Ngo, Haddawy, and Helwig\ning interventions to cardiac arrest, which will be used as a running example throughout the paper. Then we present the representation language and associated se mantics for our context-sensitive probabilistic knowl edge bases. For a given probabilistic knowledge base, its declarative semantics is defined without reference to any particular reasoning procedure. We provide a pro cedure that answers probabilistic queries by construct ing Bayesian networks from such knowledge bases and we use the formal semantics to prove the procedure both sound and complete. We demonstrate the appli cation of the implemented procedure to our example. Finally we discuss related work.\n2 The Cardiac Arrest Domain\nWe illustrate the capabilities of context-sensitive tem poral probability model construction by modeling the effects of medications and other interventions on the condition of a patient in cardiac arrest. The goal of treatment is to maintain life and prevent anoxic in jury to the brain. Studies show that fewer than 10% of cardiopulmonary resuscitation attempts resulting in survival without brain damage.\nThe observable variable is the electrocardiogram (EKG) or rhythm strip. During the cardiac arrest, the patient may present with many different cardiac rhythms. While not including all possible rhythms, we consider the range of rhythms most commonly presented: Normal Sinus Rhythm (NSR), Ventricu lar Fibrillation (VF), Ventricular Tachycardia (VT), Atrial Fibrillation (AF), Super-Ventricular Tachycar dia (SVT), Bradycardia (B), Asystole (A).\nWhile patient survival is of primary importance, cere bral damage (CD) must be taken into account. The goal must be to maximize the chance of survival while minimizing the extent of brain damage. The length of time a patient has been without cerebral blood flow (CBF) determines the period of anoxia (POA). If the patient has ineffective circulation for over five minutes, there is a likelihood of sustaining cerebral damage. This damage is persistent and its severity increases as the POA increases.\nWe consider the two most common medical interven tions: cardiopulmonary resuscitation (CPR) and de fibrillation (DFIB), the passing of an electric current through the heart, which is used primarily to coordi nate contractions in a heart experiencing a dysrhyth mia.\nDrugs are often used as an initial treatment. They help control the heart rhythm and rate, improve car diac output and increase blood pressure. Many effec tive drugs are currently available, of which we choose to model the three most commonly used. Lidocaine (LIDO) is an anti-arrhythmic drug that helps restore a regular rhythm. It is usually used for VT, VF, or to prevent VF. Atropine (ATRO) increases the heart rate during B or A. Epinephrine (EPI) overcomes heart\nblock and helps restore cardiac function.\n3 The Representation Language\nThere are two disjoint types of predicates: context and probabilistic predicates. Some predicates are timed predicates. A timed predicate always has one attribute indicating the time the associated event or relation ship denoted by the predicate occurs. We model only discrete time points and throughout the paper we rep resent the set of time points by the set of integers. If t is a time point, t+5 denotes the fifth time point after t. If A is a ground timed atom and the time attribute is t, we say A (happens) at timet.\nContext predicates ( c-predicates) have value true or false and are deterministic. They are used to describe the context the agent is in and to eliminate unneces sary probabilistic information from consideration by the agent. An atom formed from a context predicate is called a context atom (c-atom). A context literal is either a c-atom or the negation of a c-atom. A context base (CB) is an acyclic normal logic program, which is a set of universally quantified sentences of the form Co +--- Lt, L2, ... , Ln, n � 0, where +---stands for impli cation, comma for logical conjunction, Co is a c-atom, and the Li are context literals. We use completion se mantics proposed by Clark [11] for the semantics of context bases.\nEach probabilistic predicate (p-predicate) represents a class of similar random variables. P-predicates appear in probabilistic sentences and are the focus of prob abilistic inference processes. An atom formed from a probabilistic predicate is called a probabilistic atom (p-atom). Queries and evidence are expressed as p atoms. In the probability models we consider, each random variable can assume a value from a finite set and in each possible realization of the world, that variable can have one and only one value. We cap ture this property by requiring that each p-predicate has at least one attribute. The last attribute of a p-predicate represents the value of the corresponding variable. For example, the variable rhythm of a per son can have value nsr, vf, vt, af, svt, b, or a and can be represented by a two-position predicate, the first position indicating which person and the second indicating that person's type of cardiac rhythm. Asso ciated with each p-predicate p must be a statement of the form V AL(p) = { v1, . . . , vn}, where Vt, . .. , Vn are constants. Let A = p( t 1, . . . , tm-1, tm) be a p-atom, we use obj(A) to designate the tuple (p, t1, . . . , tm- 1 ) and val(A) to designate tm. So if A is a ground p atom then obj(A) represents a concrete random vari able or object in the model and val(A) is its value. We also define Ext(A), the extension of A, to be the set { p( t 1, . . . , tm -1 , vi) II :S i :S n}. If A is an atom of predicate p, then V AL(A) means V AL(p). We assume that p-predicates are typed, so that each attribute of a p-predicate is assigned values in some well-defined domain. We denote the set of all such predicate dec-\nContext-Sensitive Temporal Probability Model Construction 421\nlarations in a knowledge base by PD.\nLet A be a (probabilistic or context) atom. We de fine ground( A) to be the set of all ground instances of A. We assume mutual exclusivity and exhaustivity: for each ground p-atom A and in each \"possible world\", one and only one element in Ext(A) is true. A set of ground p-atoms {A; II ::=; i ::=; n} is called coherent if there does not exist any Aj and Aj' such that j ::j:. j' and obj(Aj) = obj(Ai') ( and val(Aj) ::j:. val(Ai ' ) ). A probabilistic sentence has the form (P(AoiAJ, .. . ,An) = a) +- LJ, ... ,Lm where n � 0, m � 0, 0 ::; a ::=; 1, A are p-atoms, and Lj are context literals. The sentence can have free vari ables and each free variable is universally quantified over the entire scope of the sentence. The above sen tence is called context-free if m = 0. If 8 is the above probabilistic sentence, we define context(S) to be the conjunction L1, . . . , Lm, prob(S') to be the probabilis tic statement P(AoiAl, . . . . An) = a, ante(S) to be the conjunction A1 1\\ . . . I\\ An, and cons(S) to be Ao. Sometimes, we use ante(S) as the set of conjuncts and call cons(S) the consequent of S. A probabilistic base ( P B) of a knowledge base is a finite set of probabilistic sentences.\nA PB will typically not be a complete specification of a probabiltiy distribution over the random variables represented by the p-atoms. One type of information which may be lacking is the specification of the proba bility of a variable given combinations of values of two or more variables which influence it. For real-world ap plications, this type of information can be difficult to obtain. For example, for two diseases D1 and D2 and a symptom 8 we may know P(SID1) and P(SjD2) but not P(SID1, D2). Combining rules such as noisy-OR and noisy-AND [14] are commonly used to construct such combined influences.\nWe define a combining rule as any algorithm that takes as input a set of ground context-free probabilistic sentences with the same consequent {P(Ao I A;1, . . . , A;n;) = a; J l S i ::=; m} such that Uf,;1{A;1, . . . ,A;nJ is coherent and produces as output P(AoiA1, . . . ,An) = a, where A1, . . . , and An are all different and { A1, . . . , An} is a subset of Uf,;1 {A;1, . .. , A;nJ- We assume that for each p predicate p, there exists a corresponding combining rule in CR, the combining rules component of a KB.\nA knowledge base (KB) consists of predicate descrip tions, a probabilistic base, a context base, and a set of combining rules. We write]{ B = {P D, PB, CB, CR). Figure 1 shows a possible knowledge base for repre senting the cardiac arrest example introduced in the previous section.\nWe have the following p-predicates: rhythm, cbf, poa, and cd. The statement rhythm(X : Person, V) says that the first argument is a value in the do main Person, which is the set of all persons and V can take one value in the set { nsr, v f, vt, af, svt, b, a}.\nSo rhythm(john, t, nsr) means the random variable cardiac rhythm of John at time t, indicated in the language by obj(rhythm(john, t, nsr)), is nor mal sinus rhythm, indicated in the language by val(rhythm(john, t, nsr)) = nsr. Similar interpreta tions apply to other statements in PD.\nP B contains the probabilistic sentences. Due to space limitations, we cannot show all the sentences. We have a sentence for each possible combination of previ ous rhythm value and resulting rhythm value in each possible context. We also need sentences that com pletely describe the relationship between rhythm and cbf, cerebral blood flow, cbf and poa, period of anoxia, and poa and cd, cerebral damage. CB defines the relationships among context information. The clause NO_INTER(X,t) +- ...,DFIB(X,t),...,CPR(X,t) al lows us to imply that no intervention is being employed at a particular time if no intervention is specified. The negation in the antecedent encodes a non-monotonic deduction by negation as failure. Finally, genealized Noisy-OR is used as the combining rule.\n4 Declarative Semantics\nIt can be difficult for a user to guarantee global con sistency of a large probabilisitic knowledge base, espe cially when we allow context-dependent specifications. We define our semantics so that we need consider only that portion of a knowledge base relevant to a given problem. Thus if part of the knowledge base is incon sistent, this will not affect reasoning in all contexts. We define the semantics relative to an inference ses sion, characterized by a set of evidence and a set of context information.\nDefinition 1 A set of context information C is any set of c-atoms. A set of evidence E is simply a set of p atoms. We always assume that ground( E) is coherent.\nAn inference session will be concerned with determin ing the posterior probabiltiy of some p-atoms Q given E, within context C.\n4.1 Context\nWe interpret a probabilistic sentence of the form (P(AoiAl,···,An) a) +- L1, . .. ,Lm as representing the conditional probability sentence (P(AoiAl,···,An,Ll, . . . ,Lm) = o:) , where free vari ables are universally quantified outside the scope of the probability operator. The reason for distinugish ing syntactically between probabilistic conditioning atoms and context conditioning atoms is that they are treated differently. Conceptually the context informa tion C is a set of evidence or observations which we elaborate with the context base C B. We do this by ap plying completion semantics to C U C B and restricting the logical consequences to the Herbrand base on the c-predicates. When CB is acyclic, completed(CUCB)\nentails the truth or falsity of each c-atom in the Her brand base. We take completed(C' U CB) to hold with probability one, so that for every ground c-atom C'; either P(C;) = 0 or P(C;) = 1. Now comput ing the posterior probability of p-atoms Q given ev idence E, within context C amounts to computing P( Q IE, completed( C U C B)). Since the probability of each Ci is zero or one, we can condition the sentences in P B on completed( C U C B) by simply eliminating those for which the probability of the context is zero and eliminating the context from those for which the probability of the context is one. Consider the follow ing two sentences from our example KB:\nP(rhythm(X, t, nsr)lrhythm(X, t- 1, nsr)) = .05 <\nNO_INTER(X, t-1), EPI(X,t-1) P(rhythm(X, t, vf)lrhythm(X, t- 1, af)) = .20 <- NO_INTER(X, t- 1), ATRO(X, t- 1)\nIfC = {NO_INTER(john,1), EPI(john,1)} then condi tioning the sentences on completed( C U C B) produces P(rhythm(john, 2, nsr)lrhythm(john, 1, nsr)) = .05 The ability to condition the P B in this way will be used in defining the relevant portion of the P B.\n4.2 The Relevant Knowledge Base\nIn a particular inference session, only a portion of the KB is relevant. The relevant part of KB is determined\nby the given context information and the set of evi dence. The set of relevant atoms is the set of evidence, the set of atoms whose marginal probability is directly stated, and the set of atoms influenced by these two sets, as indexed by the context information. In con structing the set of relevant p-atoms, we consider only the qualitative dependencies described by probabilistic sentences. If (P(Ao IA1, . . . , An) = a) <--- L1, ... , Lm is a ground instance of a sentence in PB and L1, ... , Lm can be deduced from completed(C U CB), then that sentence confirms the fact that A0 is directly influ enced by A1 , . . . , An. If, in addition, A1, . . . , An are relevant atoms then it is natural to consider A0 as relevant. Let completed(C U CB) be the completed logic program with the associated equality theory [11] constructed from C U C B, then we have the following definition of the set of relevant p-atoms.\nDefinition 2 Given a set of evidence E, a set of context information C and a KB, the set of rele vant p-atoms (RAS) is defined recursively by: (1) ground(E) � RAS'; (2) if 8 is a ground instance of a probability sentence conforming to type con straints such that context(S) is a logical consequence of completed( C U C B) and ante(S) � RAS' then cons(S) E RAS; (3) if a p-atom A is in RAS then Ext(A) � RAS; (4) RAS is the smallest set statisfy ing the above conditions.\nContext-Sensitive Temporal Probability Model Construction 423\nThe RAS is constructed in a way similar to Herbrand least models for Horn programs. Context information is used to eliminate the portion of PB which is not related to the current problem.\nProposition 1 Given a set of evidence E, a set of context information C and a KB, RAS always exists.\nDefinition 3 Given a set of evidence E, a set of context information C and a KB, the set of rele vant probabilistic sentences (RP B) is defined as the set of all prob(S), where S is a ground probabilis tic sentence such that context(S) is a logical conse quence of completed(C U CB), cons(S) E RAS and ante(S) � RAS.\nThe RPB contains the basic relationships between p atoms in RAS. In the case of multiple influences repre sented by multiple sentences, we need combining rules to construct the combined probabilistic influenc.e.\nDefinition 4 Given a set of evidence E, a set of con text information C and a KB, the combined relevant PB (CRPB) is constructed by applying the correspond ing combining rules to each maximally coherent set of sentences in RP B which have the same atom in the consequent.\nCombined RPB's play a similar role to completed logic programs. We assume that each sentence in CRPB describes all random variables which directly influence the random variable in the consequent. Given a set of evidence E, a set of context information C and a KB, we can construct CRPB.\nWe define a syntactic property of CRPB which is nec essary in constructing Bayesian networks from the KB.\nDefinition 5 A CRPB is completely quantified if (1} for all ground atoms Ao in RAS, there exists at least one sentence in CRPB with A0 in the consequent; (2} and, for all ground sentence S: P(AolAt, ... , An) = a in CRPB, for all i = 0, .. , n, if val(Ai) = v and v' E V AL(Ai ), v :/= v', there exists another ground sentence S' in CRP B such that S' can be constructed from S by replacing val(A;) by v' and a by some a'.\nIf we think of each ground obj(A), where A is some p atom, as representing a random variable in a Bayesian network model then the above condition implies that we can construct a link matrix for each random vari able in the model. This is a generalization of con straint (C1) in [9]. We do not require the existence of link matrix for every random variable, but only for the random variables that are relevant to an inference problem.\n4.3 Probabilistic Independence Assumption\nBeside the probabilitistic quantities given in a PB, we assume some probabilistic independence relationships\nspecified by the structure of probabilistic sentences. Probabilistic independence assumptions are used in all related work [3, 13, 9] as the main device to construct a probability distribution from local conditional proba bilities. Unlike Poole [13], who assumes independence on the set of consistent \"assumable\" atoms, we formu late the independence assumption in our framework by using the structure of the sentences in CRPB. We find this approach more natural since the structure of the CRPB tends to reflect the causal structure of the domain and independencies are naturally thought of causally.\nDefinition 6 Given a set of ground context-free prob abilistic sentences, let A and B be two p-atoms. We say A is influenced by B if (1) there exists a sentence S, an atom A' in Ext(A) and an atom B' in Ext(B) such that A' = cons(S) and B' E ante(S') or (2) there exists another p-atom C such that A is influenced by C and C is influenced by B.\nAssumption 1 Given a set of evidence E, a set of context information C and a KB, we can construct CRPB. We assume that ifP(AolAt, .. . , An) = (t z.� in CRPB then for all ground p-atoms B which are not in Ext(Ao) and not influenced by A0, A0 and B arF probabilistically independent given A 1, ... , An .\nThis assumption is more intuitive and probably eas ier to check (for knowledge base builders) than the d-separation assumption in [9]. It is well known that these two ways of stating probabilistic independence assumptions are equivalent for finite Bayesian net works [12].\nExample 1 Continuing the cardiac arrest example, rhythm(john, 1, vf) is probabilistically independent of rhythm(john, 3, v f) given rhythm(john, 2, nsr).\n4.4 Model Theory\nWe define the semantics by using possible worlds on the Herbrand base. This approach of charac terizing the semantics by canonical Herbrand mod els is widely used in work on logic programming [7, 8]. In our semantics, the context constraints in the context base CB and the set of context information C: act to select the appropriate set of the possible worlds over which to evaluate the probabilistic part of the sentences. In this way they index probability distribu tions.\nThe RAS contains all relevant atoms for an inference session. We assume that in such a concrete situation, the belief of an agent can be formulated in terms of possible models on RA8.\nDefinition 7 Given a set of evidence E, a set of con text information C and a KB, a possible model M of the corresponding CRPB is a set of atoms in RA8 such that for all A in RA8, Ext(A) n M has one and only one element.\n424 Ngo, Haddawy, and Helwig\nA probability distribution on the possible mod els is realized by a probability density assign ment to each model. Let P be a probabil ity distribution on the possible models, we define P(At, . . . , An), where At, ... , An are atoms in RAS, as L {P(w) jw is a possible model containing A1, ... , An}  We take a sentence of the form P(Ao\\A1, . • • ,An) = a as shorthand for P(Ao, At, . .. , An) a X P(A1, ... , An), so that probabilities conditioned on zero are not problematic. We say P satisfies a sen tence P(AoiAt, ... , An) = a if P(Ao, A1, ... , An) a x P(At, ... , An) and P satisfies CRPB if it satisfies every sentence in CRPB.\nDefinitiou 8 A probability distribution induced by the set of evidence E, the set of context information C, and K B is a probability distribution on possible mod els of CRPB satisfying CRPB and the independence assumption implied by CRPB.\nWe define the consistency property only on the rele vant part of a KB. Since the entire KB contains infor mation about various contexts, testing for consistency of such a KB may be very difficult.\nDefinition 9 A completely quantified CRPB is con sistent if (1) there is no atom in RAS which is influ enced by itself and (2} for all P(Ao\\Al, ... ,An) = a in CRPB, l::{a;\\P(AbiAt, . .. , An)= a; E CRPB and obj(Ab) = obj(Ao)} 1.\nCondition ( 1) rules out cycles and condition (2) en forces the usual probability assignment constraint.\nA possible model in temporal frameworks corresponds to a world history [10]. The set of world histories is infinite. In practice, particularly for plan projection problems, we typically consider only events occurring over finite periods. We assume that for each temporal reasoning problem there exist two integers t, r, t :S: r such that things occurring outside [t, r] are not of our concern. So, any timed atom in E or Cis at a time in the interval [t, rJ.\nDefinition 10 Given two integers t, r(t r) , a set of evidence E, a set of context information and a KB, the (�, r)-bounded RAS, denoted by (t, r)-RAS is the set {AlAE RAS and if A is timed then it is timed at t and t :S: t :S: r}. The (t, r)-RPB and (t, r)-CRPB are confined versions of RP B and CRP B, correspondingly, on (t, r)-RAS.\nDefinition 11 Given two integers t, r(t :S: r), a set of evidence E, a set of context information C and a KB, a possible (t, r)-model M of the corresponding CRPB is a set of atoms in (t, r)-RAS such that for all A in (t, r)-RAS, Ext(A)nM has one and only one element.\nDefinition 12 Given two integers t, r(t :S: r). A probability distribution which is (t, r)-bound induced by the set of evidence E, the set of context informa tion C, and KB is a probability distribution on possible\n(t, r)-models of CRPB satisfying (t, r)-CRPB and the independence assumption implied by ( t, r)-CRPB.\nTheorem 1 Given two integers t, r( t :S: r), a set of evidence E, a set of context information C, and a KB, if the (t, r)-RAS is finite and the (t, r)-CRPB is com pletely quantified and consistent then there exi.sts one and only one (t, r)-bound induced probability distribu tion.\nIn one inference session, we can pose queries to ask for the posterior probabilities of some random variables.\nDefinitiou 13 A complete ground query wrt the set of evidence E and the set of context information C is a query of the form P(Q) where the last ar gument of Q is a variable and it is the only variable in Q. The meaning of such a query is: find the pote rior probability distribution of obj( Q). If VAL( Q) = { Vt, ... , Vn} then the answer to such a query is a vector ii = (a1, ... ,an), where 0 :S: ai :S: 1,2::::7::::1 ai I and ai is the posterior probability of obj( Q) receiving the value Vi.\nExample 2 We can pose the complete ground query P(rhythm(john, 3, V)) =? to the example KB to ask for the posterior probability of John's cardiac rhythm at time 3.\nAn inference problem in an inference session involving a KB, a set of evidence E, a set of context informa tion C is characterized by a query. We represent an inference problem by a tuple (P(Q) E, C, K B).\nDefinition 14 Assume that VAL(Q) = {v1, . .. ,v,..} and Q is at time t, t :S: t :S: r. We say P(Q) (a1, ... , Cl:'n) is a logical consequence of (P(Q) ?, E, C, K B) if for all probabiiity distributions P* which are (t, r)-bound induced by E, C, and KB and VO :S: i :S: n : P* ( {MIQi and E are true in M}) = ai x P*({M!E are true in M}), where Qi is Q after replacing val(Q) by V£.\nExample 3 Suppose we have the query Q = rhythm(john, 3, V). There are an infinite number of induced probability distributions but in all of them P(rhythm(john, 3, nsr)) 0.41, P(rhythm(john, 3, v f) = 0.09, and P(rhythm(john, 3, vt) = 0.04. {See the first exam ple in Section 6.) So they are logical consequences of CRPB.\nIn order to prove that the answers returned by our query answering procedure are correct, we need the following definition.\nDefinition 15 In the frame work {P(Q) =?,E,C,KB),P(Q) = (at, ... ,an) is a correct answer to the complete ground query P(Q) ='? if P(Q) = (at, ... , an) is a logical consequence of {E,C,KB}.\nContext-Sensitive Temporal Probability Model Construction 425\n5 Query Answering Procedure\nIn this section we present an algorithm for answer ing a complete query, which is a generalized form of complete ground queries with possible variables in any attribute of the atom. Assume that we are given (P( Q) =?, E, C, K B), where P( Q) =? is a complete query. We call the query answering procedure Q procedure. Q-procedure uses a form of SLD to rea son on PB and SLDNF to answer context queries on C U C B [11]. The SLD-like portion of Q-proeedure is more eomplex than SLD beeause it needs to eolleet all relevant sentenees before eombining rules ean be used. For that purpose, Q-proeedure needs to main tain a list of all ground probabilistic sentenees relevant to the current query atom. Q-procedure also ealls a Bayesian Net belief updating proeedure. There are several available proeedures for that purpose [12]. In cheeking for the validity of contexts, Q-procedure frequently calls the SLDNF proof procedure which works on CUC B and queries provided by Q-procedure. SLDNF is sound and, for some classes of normal logic. programs, eomplete under completed program seman ties. SLDNF is an effieient proof procedure for normal logic programs and is implemented as the inference engine for the Prolog language. The termination of Q-procedure depends on the termination of SLDNF.\nQ-procedure has the following steps: build the nec essary portion of the Bayesian network, each node of which corresponds to an obj(A), where A is a ground p-atom in RAS; update the network using the set of ev idence E; and output the updated belief of the query nodes. The main idea of the algorithm is to build a supporting network for each random variable corre sponding to a ground instance of an evidence atom or the query. Let A be a ground p-atom and consider the set of all ground p-atoms B such that A is influ enced by B in CRPB. The supporting network for obj(A) is a Bayesian network eonsisting of obj(A) and the set of all obj(B), with the relevant \"influenced by\" relationships represented as links or sequences of links.\nConstructing the network by building supporting net works is justified by the fact that atoms which do not influence either the evidence or the query are irrele vant. To build the supporting networks for the evi dence, we first generate the set of all ground instances of the evidence p-atoms. Then for each ground in stance, we build the supporting network using PB, the set of ground instances of the evidence which have not been explored, and the current net.\nThe supporting networks are constructed via calls BUILD-NET, which receives as input an atom whose supporting network needs to be explored. It updates the NET, which might have been partially built. The return value of the funetion is a set of substitutions such that for each substitution there exists a support ing network for the ground instance of the atom corre sponding to the substitution. BUILD-NET frequently\n· -- ------- � · ---- ----- · . ... ... ... ......... ... ... ... . I 1 I I I I 1 I 8 I I I I I 0 0\nNO_INTBR (O)j�-��T�: ;I; j- :� (�)--}) - - - - - - - ; BPI (0) NO_MBD (I) BPI (2)\nIn Q-procedure, we only construct the supporting net works, not the entire network for CRPB. We can show that this portion of the network is enough for evaluat ing the given query.\nTheorem 2 Given a complete query P(Q) =\"!, where Q is at time t, t :S t :S T, a set of evidence E, a set of context information C and a KB. If the COMBINE function always generates finite sets of sentences, CRPB is (t, r)-bound completely quantified and (t, r)-bound consistent and the proof procedure for C U C B is sound and complete wrt any query gener ated by Q-procedure then (1) Q-procedure is sound: the returned answers are correct; (2) Q-procedure is com plete: every ground instance of Q which has an answer is returned.\nThe Completeness of Q-procedure\nOur completeness result holds for acyclic rules. The expressiveness of acyclic normal programs is demon strated in [1]. We hope that acyclic PBs also have an equivalent importance. To the best of our knowl edge, PBs with loops are considered problematic and all PB's considered in the literature are acyclic. We need a syntactic criterion called allowedness [11] which enables us to prove the soundness and completeness for a large class of KBs.\nTheorem 3 In any framework (P(Q) =?,E,C,KB) where P( Q) =? is a complete query and Q is at a con stant time t, t :S t :S T, if K B is acyclic (both P B and CB are acyclic), (K B, E, C) is allowed, and CRPB is (t, r)-bound completely quantified and (t, r)-bound consistent then Q-procedure is sound and complete.\n6 Application\nWe have implemented a simplified version of Q procedure called BNG1. In this section we demonstrate how the system answers queries for our eardiac arrest domain. Our first example simulates a response to a heart attaek. Evidence is presented as the following\n1 The software is available via www at http:/ fwww.cs.uwm.edu/faculty /haddawy\n426 Ngo, Haddawy, and Helwig\nFigure 3: Network for querying cerebral damage.\ninitial state at time 0: rhythm is ventricular fibrilla tion, no period of anoxia, no cerebral damage, and cerebral blood flow is present. The actions, adminis tration of Epinephrine at times 0 and 2 and defibrilla tion at time 2, are represented as context information. Our query is the cardiac rhythm at time 3. Given this inference problem, BNG generates the network shown in Figure 2. The computed posterior probabilities are P(NSR) = 0.41, P(VF) = 0.09, P(VT) = 0.04, P(AF) = 0.00, P(SVT) = 0.01, P(B) = 0.00, P(A) = 0.44.\nThe next example models a cardiac arrest initiated through drowning. The initial rhythm is asystole, the period of anoxia is known to be 5 minutes, and there is no prior cerebral damage. Treatment consists of Epinephrine administered at time 2 and continued CPR from time 0 to 2. The network generated in re sponse to a query of cerebral damage at time 4 is shown in Figure 3. The computed posterior probabilities of cerebral damage are P(None) = 0.84, P(Mild) = 0.16.\n7 Related Work\nOur representation language has some similarities to Breese's Alterid [3). Breese mixes logic program clauses with probabilistic sentences. In contrast, we seperate logic program clauses from probabilistic sen tences and use context predicates to select the relevant probabilistic sentences. Breese does not provide a se mantics for the knowledge base. As a result, his pa per cannot prove the correctness of his query answer ing procedure. Breese's procedure does both backward and forward chaining. Q-procedure only chains back wards. In that way we can extend the procedure for some infinite domains.\nPoole [13] expresses an intention similar to ours: \"there has not been a mapping between logical speci fications of knowledge and Bayesian network represen tations .. \". He provides such a mapping using prob abilistic Horn abduction theory, in which knowledge is represented by Horn clauses and the independence assumption of Bayesian networks is explicitly stated. His work is developed along a different track than ours,\nhowever, by concentrating on using the theory for ab duction. His theory and ours come to some common points: the acyclicity of sentences, combining rules, completed logic program semantics, and the Bayesian network independence assumption. Our approach con centrates on knowledge base representation and the query answering procedure. We do not allow function symbols in our main results but we think the frame work can be extended to include functions.\nAcknowledgements\nThis work was partially supported by NSF grant IRI9207262.\nReferences\n[1] K. R. Apt and M. Bezem. Acyclic programs. New Generation Computing, pages 335-363, Sept 1991.\n[2] J .S. Blythe. Planning with external events. In Pro ceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, Seattle, July 1994.\n[3] J.S. Breese. Construction of belief and decision networks. Computational Intelligence, 8( 4):624-647, 1992.\n[4] G. F. Cooper. The computational complexity of prob abilistic inference using bayesian belief networks. Ar tificial Intelligence, 42(2-3):393-405, 1990.\n[5] A. Darwiche and M. Goldszmidt. Action networks: A framework for reasoning about actions and change under uncertainty. In Proceedings of the Tenth Con ference on Uncertainty in Artificial Intelligence, pages 136-144, Seattle, July 1994.\n[6] T.L. Dean and M.P. Wellman. Planning and Control. Morgan Kaufmann, San Mateo, CA, 1991.\n[7] A. V. Gelder, K. A. Ross, and J. S. Schlipf. The well founded semantics for general logic programs. JACM, pages 620-650, July 1991.\n[8] M. Gelfand and V . Liftschitz. The stable model se mantics for logic programming. In Proceedings of the Fifth International Conference and Symposium on Logic Programming, pages 1070-1080, 1988.\n(9] P. Haddawy. Generating Bayesian networks from probability logic knowledge bases. In Proceedings of the Tenth Conference on Uncertainty in Artificial In telligence, pages 262-269, Seattle, July 1994.\n[10] P. Haddawy. Representing Plans Under Uncertainty: A Logic of Time, Chance, and Action, volume 770 of Lecture Notes in Artificial Intelligence. Springer Verlag, Berlin, 1994.\n[11] J. W. Lloyd. Foundation of Logic Programming. Springer-Verlag, 1987. second edition.\n[12] J. Pearl. Probabilistic Reasoning in Intelligent Sys tems: Networks of Plausible Inference. Morgan Kauf mann, San Mateo, CA, 1988.\n[13] D. Poole. Probabilistic horn abduction and bayesian networks. Artificial Intelligence, 64(1 ):81-129, November 1993.\n(14] S. Srinivas. A generalization of the noisy-or model. In UAI-93, pages 208-217, July 1993."
    } ],
    "references" : [ {
      "title" : "Acyclic programs",
      "author" : [ "K.R. Apt", "M. Bezem" ],
      "venue" : "New Generation Computing,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1991
    }, {
      "title" : "Planning with external events",
      "author" : [ "J .S. Blythe" ],
      "venue" : "In Pro­ ceedings of the Tenth Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1994
    }, {
      "title" : "Construction of belief and decision networks",
      "author" : [ "J.S. Breese" ],
      "venue" : "Computational Intelligence,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1992
    }, {
      "title" : "The computational complexity of prob­ abilistic inference using bayesian belief networks",
      "author" : [ "G.F. Cooper" ],
      "venue" : "Ar­ tificial Intelligence,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1990
    }, {
      "title" : "Action networks: A framework for reasoning about actions and change under uncertainty",
      "author" : [ "A. Darwiche", "M. Goldszmidt" ],
      "venue" : "In Proceedings of the Tenth Con­ ference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1994
    }, {
      "title" : "Planning and Control",
      "author" : [ "T.L. Dean", "M.P. Wellman" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1991
    }, {
      "title" : "The well­ founded semantics for general logic programs",
      "author" : [ "A.V. Gelder", "K.A. Ross", "J.S. Schlipf" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1991
    }, {
      "title" : "The stable model se­ mantics for logic programming",
      "author" : [ "M. Gelfand", "V . Liftschitz" ],
      "venue" : "Proceedings of the Fifth International Conference and Symposium on Logic Programming,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1988
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "While Bayesian networks provide a rel­ atively efficient method for representing and reasoning with probabilistic information, inference in Bayesian networks remains NP-hard [4].",
      "startOffset" : 174,
      "endOffset" : 177
    }, {
      "referenceID" : 1,
      "context" : "For example, in using Bayesian networks for plan projection, actions are typically represented as nodes in the network [6, ch7], [2, 5].",
      "startOffset" : 129,
      "endOffset" : 135
    }, {
      "referenceID" : 4,
      "context" : "For example, in using Bayesian networks for plan projection, actions are typically represented as nodes in the network [6, ch7], [2, 5].",
      "startOffset" : 129,
      "endOffset" : 135
    }, {
      "referenceID" : 2,
      "context" : "Probabilistic independence assumptions are used in all related work [3, 13, 9] as the main device to construct a probability distribution from local conditional proba­ bilities.",
      "startOffset" : 68,
      "endOffset" : 78
    }, {
      "referenceID" : 6,
      "context" : "This approach of charac­ terizing the semantics by canonical Herbrand mod­ els is widely used in work on logic programming [7, 8].",
      "startOffset" : 123,
      "endOffset" : 129
    }, {
      "referenceID" : 7,
      "context" : "This approach of charac­ terizing the semantics by canonical Herbrand mod­ els is widely used in work on logic programming [7, 8].",
      "startOffset" : 123,
      "endOffset" : 129
    }, {
      "referenceID" : 0,
      "context" : "The expressiveness of acyclic normal programs is demon­ strated in [1].",
      "startOffset" : 67,
      "endOffset" : 70
    } ],
    "year" : 2011,
    "abstractText" : "We define a context-sensitive temporal prob­ ability logic for representing classes of discrete-time temporal Bayesian networks. Context constraints allow inference to be focused on only the relevant portions of the probabilistic knowledge. We provide a declarative semantics for our language. We present a Bayesian network construction algorithm whose generated networks give sound and complete answers to queries. We use related concepts in logic programming to justify our approach. We have implemented a Bayesian network construction algorithm for a subset of the theory and demonstrate it's application to the problem of evaluating the effectiveness of treatments for acute cardiac conditions.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}