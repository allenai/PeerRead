{
  "name" : "1411.5410.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Stable Model Counting and Its Application in Probabilistic Logic Programming",
    "authors" : [ "Rehan Abdul Aziz", "Geoffrey Chu", "Christian Muise", "Peter Stuckey" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Consider the counting version of graph reachability problem: given a directed graph, count the number of subgraphs in which node t is reachable from node s (Valiant 1979). This problem can be naturally modeled as a logic program under stable model semantics (Gelfond and Lifschitz 1988). Let us say that the input is given by two predicates: node(X) and edge(X,Y ). For each node, we can introduce a decision variable in that models whether the node is in the subgraph. Furthermore, we can model reachability (reach) from s as an inductive definition using the following two rules: reach(s) ← in(s) and reach(Y ) ←\n∗NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program. Copyright c© 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nin(Y ), reach(X), edge(X,Y ). The first rule says that s itself is reachable if it is in the subgraph. The second rule is the inductive case, specifying that a node Y is reachable if it is in the subgraph and there is a reachable node X that has an edge to it. Additionally, say there are arbitrary constraints in our problem, e.g., only consider subgraphs where a certain y is also reachable from s etc. This can be done using the integrity constraint: ← ¬reach(y). The number of stable models of this program is equal to the number of solutions of the problem.\nThere are at least two approaches to counting the stable models of a logic program. The first is to translate a given logic program to a propositional theory such that there is a one-to-one correspondence between the propositional models of the translated program and the stable models of the original program, and use SAT model counting (Gomes, Sabharwal, and Selman 2008). We show that this approach does not scale well in practice since such translations, if done a priori, can grow exponentially with the input size. The second approach is to use an answer set programming (ASP) solver like CLASP (Gebser et al. 2007) or DLV (Leone et al. 2006) and enumerate all models. This approach is extremely inefficient since model counting algorithms have several optimizations like caching and dynamic decomposition that are not present in ASP solvers. This motivates us to build a stable model counter that can take advantage of state-of-the-art ASP technology which combines partial translation and lazy unfounded set (Van Gelder, Ross, and Schlipf 1988) detection. However, we first show that it is not correct to naively combine partial translation and lazy unfounded set detection with SAT model counters due to the aforementioned optimizations in model counters. We then suggest two approaches to properly integrate unfounded set propagation in a model counter.\nWe show that we can apply our algorithms to solve probabilistic logic programs (Raedt and Kimmig 2013). Consider the probabilistic version of the above problem, also called the graph reliability problem (Arora and Barak 2009). In this version, each node can be in the subgraph with a certain probability 1 − p, or equivalently, fail with the probability p. We can model this by simply attaching probabilities to the in variables. We can model observed evidence as constraints. E.g., if we have evidence that a certain node y is reachable from s, then we can model this as the unary\nar X\niv :1\n41 1.\n54 10\nv1 [\ncs .A\nI] 2\n0 N\nov 2\n01 4\nconstraint (not rule): reach(y). The goal of the problem is to calculate the probability of node t being reachable from node s given the evidence. The probabilistic logic programming solver PROBLOG2 (Fierens et al. 2011) approaches this inference task by reducing it to weighted model counting of the translated propositional theory of the original logic program. We extend PROBLOG2 to use our implementation of stable model counting on the original logic program and show that our approach is more scalable."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "We consider propositional variables V . Each v ∈ V is (also) a positive literal, and ¬v, v ∈ V is a negative literal. Negation of a literal, ¬l is ¬v if l = v, and v if l = ¬v. An assignment θ is a set of literals which represents the literals which are true in the assignment, where ∀v ∈ V.{v,¬v} 6⊆ θ. If o is a formula or assignment, let vars(o) be the subset of V appearing in o. Given an assignment θ, let θ+ = {v ∈ θ | v ∈ V} and θ− = {¬v ∈ θ | v ∈ V}. Two assignments θ1 and θ2 agree on variables V ⊆ V , written θ1 =V θ2, if vars(θ+1 ) ∩ V = vars(θ + 2 ) ∩ V and vars(θ−1 ) ∩ V = vars(θ − 2 ) ∩ V . Given a partial assignment θ and a Boolean formula F , let F |θ be the residual of F w.r.t. θ. F |θ is constructed from F by substituting each literal l ∈ θ with true and each literal ¬l ∈ θ with false and simplifying the resulting formula. For a formula F , count(F ) is the number of assignments to vars(F ) that satisfy F ."
    }, {
      "heading" : "2.1 DPLL-Based Model Counting",
      "text" : "State of the art SAT model counters are very similar to SAT solvers, but have three important optimisations. The first optimisation is to count solution cubes (i.e., partial assignments θ, vars(θ) ⊆ V whose every extension is a solution) instead of individual solutions. Consider the Boolean formula: F1 = {¬b∨a,¬c∨¬a∨b,¬d∨c,¬e∨c}. Suppose the current partial assignment is {a, b, c}. The formula is already satisfied irrespective of values of d and e. Instead of searching further and finding all 4 solutions, we can stop and record that we have found a solution cube containing 2k solutions, where k is the number of unfixed variables.\nThe second important optimisation is caching. Different partial assignments can lead to identical subproblems which contain the same number of solutions. By caching such counts, we can potentially save significant repeated work. For a formula F and an assignment θ, the number of solutions of F under the subtree with θ is given by 2|vars(F )|−|vars(θ)|−|vars(F |θ)| × count(F |θ). We can use the residual as the key and cache the number of solutions the subproblem has. For example, consider F1 again. Suppose we first encountered the partial assignment θ1 = {d, c}. Then F1|θ1 = {¬b ∨ a,¬a ∨ b}. After searching this subtree, we find that this subproblem has 2 solutions and cache this result. The subtree under θ1 thus has 25−2−2 × 2 = 4 solutions. Suppose we later encounter θ2 = {¬d, e, c}. We find that F1|θ2 is the same as F1|θ1 . By looking it up in the cache, we can see that this subproblem has 2 solutions. Thus the subtree under θ2 has 25−3−2 × 2 = 2 solutions.\nThe last optimisation is dynamic decomposition. Suppose after fixing some variables, the residual decomposes into two or more formulas involving disjoint sets of variables. We can count the number of solutions for each of them individually and multiply them together to get the right result. Consider F2 = {a ∨ ¬b ∨ c, c ∨ ¬d ∨ e, e ∨ f} and a partial assignment {¬c}. The residual program can be decomposed into two components {a∨¬b} and {¬d∨e, e∨f} with variables {a, b} and {¬d ∨ e, e ∨ f} respectively. Their counts are 3 and 5 respectively, therefore, the number of solutions for F2 that extend the assignment {¬c} is 3 × 5 = 15. The combination of the three optimisations described above into a DPLL style backtracking algorithm has been shown to be very efficient for model counting. See (Bacchus, Dalmao, and Pitassi 2003; Gomes, Sabharwal, and Selman 2008; Sang et al. 2004) for more details."
    }, {
      "heading" : "2.2 Answer Set Programming",
      "text" : "We consider V split into two disjoint sets of variables founded variables (VF ) and standard variables (VS ). An ASP-SAT program P is a tuple (V, R, C) whereR is a set of rules of form: a← b1∧ . . .∧ bn∧¬c1∧ . . .∧¬cm such that a ∈ VF and {b1, . . . , cm} ⊆ V and C is a set of constraints over the variables represented as disjunctive clauses. A rule is positive if its body only contains positive founded literals. The least assignment of a set of positive rulesR, written Least(R) is one that that satisfies all the rules and contains the least number of positive literals. Given an assignment θ and a program P , the reduct of θ w.r.t. P , written, P θ is a set of positive rules that is obtained as follows: for every rule r, if any ci ∈ θ, or ¬bj ∈ θ for any standard positive literal, then r is discarded, otherwise, all negative literals and standard variables are removed from r and it is included in the reduct. An assignment θ is a stable model of a program P iff it satisfies all its constraints and θ =VF Least(P\nθ). Given an assignment θ and a set of rules R, the residual rules R|θ are defined similarly to residual clauses by treating every rule as its logically equivalent clause. A program is stratified iff it admits a mapping level from VF to non-negative integers where for each rule in the program s.t., referring to the above rule form, level(a) > level(ci) whenever ci ∈ VF for 1 ≤ i ≤ m and level(a) ≥ level(bi) whenever bi ∈ VF for 1 ≤ i ≤ n. In ASP terms, standard variables, founded variables and constraints are equivalent to choice variables, regular ASP variables, and integrity constraints resp. We opt for the above representation because it is closer to SAT-based implementation of modern ASP solvers."
    }, {
      "heading" : "3 SAT-Based Stable Model Counting",
      "text" : "The most straight forward approach to counting the stable models of a logic program is to translate the program into propositional theory and use a propositional model counter. As long as the translation produces a one-to-one correspondence between the stable models of the program and the solutions of the translated program, we get the right stable model count. Unfortunately, this is not a very scalable approach. Translations based on adding loop formulas (Lin and Zhao 2004) or the proof-based translation used\nin PROBLOG2 (Fierens et al. 2011) require the addition of an exponential number of clauses in general (see (Lifschitz and Razborov 2006) and (Vlasselaer et al. 2014) respectively). Polynomial sized translations based on level rankings (Janhunen 2004) do exist, but do not produce a one to one correspondence between the stable models and the solutions and thus are inappropriate for stable model counting.\nCurrent state of the art SAT-based ASP solvers do not rely on a full translation to SAT. Instead, they rely on lazy unfounded set detection. In such solvers, only the rules are translated to SAT. There is an extra component in the solver which detects unfounded sets and lazily adds the corresponding loop formulas to the program as required (Gebser, Kaufmann, and Schaub 2012). Such an approach is much more scalable for solving ASP problems. However, it cannot be naively combined with a standard SAT model counter algorithm. This is because the SAT model counter requires the entire Boolean formula to be available so that it can check if all clauses are satisfied to calculate the residual program. However, in this case, the loop formulas are being lazily generated and many of them are not yet available to the model counter. Naively combining the two can give the wrong results, as illustrated in the next example.\nExample 1. Consider a program P1 with founded variables {a, b}, standard variables {s} and rules: {a ← b, b ← a, a ← s}. There are only two stable models of the program {a, b, s} and {¬a,¬b,¬s}. If our partial assignment is {a, b}, then the residual program contains an empty theory which means that the number of solutions extending this assignment is 2 (or 2|{s}|). This is clearly wrong, since {a, b,¬s} is not a stable model of the program.\nNow consider P2 which is equal to P1 with these additions: founded variable c, standard variables {t, u} and two rules: c ← a ∧ t and b ← u. Consider the partial assignment {u, a, b, s}, the residual program has only one rule: c ← t. It has two stable models, {c, t} and {¬c,¬t}. Now, with the partial assignment {¬u, a, b}, we get the same residual program and the number of solutions should be: 2× 2|{s}| = 4 which is wrong since s cannot be false in order for a, b to be true when u is false, i.e., {¬u, c, t, a, b,¬s} and {¬u,¬c,¬t, a, b,¬s} are not stable models of P2.\nIn order to create a stable model counter which can take advantage of the scalability of lazy unfounded set detection, we need to do two things: 1) identify the conditions for which the ASP program is fully satisfied and thus we have found a cube of stable models, 2) identify what the residual of an ASP program is so that we can take advantage of caching and dynamic decomposition."
    }, {
      "heading" : "3.1 Searching on Standard Variables for Stratified Programs",
      "text" : "The first strategy is simply to restrict the search to standard variables. If the program is stratified, then the founded variables of the program are functionally defined by the standard variables of the program. Once the standard variables are fixed, all the founded variables are fixed through propagation (unit propagation on rules and the unfounded set propagation). It is important in this approach that the propa-\ngation on the founded variables is only carried out on the rules of the program, and not the constraints. Constraints involving founded variables should only be checked once the founded variables are fixed. The reader can verify that in Example 1, if we decide on standard variables first, then none of the problems occur. E.g., in P1, if s is fixed to either true or false, then we do not get any wrong stable model cubes. Similarly, in P2, if we replace the second assignment with {¬u, s} which propagates {a, b}, we still get the same residual program, but in this case, it is correct to use the cached value. Note that stratification is a requirement for all probabilistic logic programs under the distribution semantics (Sato 1995). For such programs given an assignment to standard variables, the well-founded model of the resulting program is the unique stable model."
    }, {
      "heading" : "3.2 Modifying the Residual Program",
      "text" : "In ASP solving, it is often very useful to make decisions on founded variables as it can significantly prune the search space. For this reason, we present a more novel approach to overcome the problem demonstrated in Example 1.\nThe root problem in Example 1 in both cases is the failure to distinguish between a founded variable being true and being justified, i.e., can be inferred to be true from the rules and current standard and negative literals. In the example, in P1, a and b are made true by search (and possibly propagation) but they are not justified as they do not necessarily have externally supporting rules (they are not true under stable model semantics if we set ¬s). In ASP solvers, this is not a problem since the existing unfounded set detection algorithms guarantee that in complete assignments, a variable being true implies that it is justified. This is not valid for partial assignments, which we need for counting stable model cubes. Next, we show that if we define the residual rules (not constraints) of a program in terms of justified subset of an assignment, then we can leverage a propositional model counter augmented with unfounded set detection to correctly compute stable model cubes of a program. In order to formalize and prove this, we need further definitions.\nGiven a program P = (V, R, C) and a partial assignment θ, the justified assignment JA(P, θ) is the subset of θ that includes all standard and founded negative literals plus all the positive founded literals implied by them using the rules of the program. More formally, let J0(θ) = θ− ∪ {v ∈ θ|v ∈ VS}. Then, JA(P, θ) = J0(θ) ∪ {v ∈ VF |v ∈ θ, v ∈ Least(R|J0(θ))}. Definition 1. Given a program P = (V, R, C) and a partial assignment θ, let J = JA(P, θ) and U = vars(θ)\\vars(J). The justified residual program of P , w.r.t. θ is written P |jθ and is equal to (W,S,D) where S = R|J , D = C|θ ∪ {u|u ∈ U} and W = vars(S) ∪ vars(D). Example 2. Consider a program P with founded variables {a, b, c, d, e, f}, standard variables {s, t, u, x, y, z} and the following rules and constraints:\na← b. c← d. e← ¬f. ¬s ∨ ¬t b← a. d← u. f ← ¬e. a ∨ b a← s. f ∨ x b← t.\nLet θ = {a, b, d, u,¬e, c, f}. Then, J0(θ) = {u,¬e} and JA(P, θ) = J0(θ) ∪ {d, f, c}. The justified residual program w.r.t. θ has all the rules in the first column and has the constraints: {¬s ∨ ¬t, a, b}. Theorem 1. Given an ASP-SAT program P = (V, R, C) and a partial assignment θ, let P |jθ = (W,S,D) be denoted byQ. Let the remaining variables be Vr = V\\(W∪vars(θ)) and π be a complete assignment over W . Assume any founded variable for which there is no rule in S is false in θ.\n1. If π is a stable model of Q, then for any assignment θr over the remaining variables, θ∪π ∪ θr is a stable model of P .\n2. For a given assignment θr over remaining variables, if θ∪π∪ θr is a stable model of P , then π is a stable model of Q.\nCorollary 2. Let the set of rules and constraints of Q decompose into k ASP-SAT programs Q1 = (W1, S1, D1), . . . , Qk = (Wk, Sk, Dk) where Wi = vars(Si) ∪ vars(Di) s.t. for any distinct i, j in 1 . . . k, Wi ∩ Wj = ∅. Let the remaining variables be: Vr = V\\(W1∪. . .∪Wk∪vars(θ)) and let π1, . . . , πk be complete assignments over W1, . . . ,Wk respectively.\n1. If π1, . . . , πk are stable models of Q1, . . . , Qk resp., then for any assignment θr over the remaining variables, θ ∪ π1 ∪ . . . ∪ πk ∪ θr is a stable model of P .\n2. For a given assignment θr over remaining variables, if θ ∪ π1 ∪ . . .∪ πk ∪ θr is a stable model of P , then πi is a stable model of Qi for each i ∈ 1 . . . k. The first part of Theorem 1 shows that we can solve the\njustified residual program independently (as well as cache the result) and extend any of its stable model to a full stable model by assigning any value to the remaining variables of the original program. The second part of the theorem establishes that any full stable model of the original program is counted since it is an extension of the stable model of the residual program. The corollary tells us that if the justified residual program decomposes into disjoint programs, then we can solve each one of them independently, and multiply their counts to get the count for justified residual program. Example 3. In Example 2, the justified residual program has only two stable models: π1 = {s, a, b,¬t} and π2 = {t, a, b,¬s}. It can be verified that the only stable assignments extending θ of P are θ ∪ π1 ∪ θxyz and θ ∪ π2 ∪ θxyz where θxyz is any assignment on the standard variables x, y, z. Therefore, the total number of stable models below θ is 2× 2|{x,y,z}| = 16.\nNow say we have another assignment θ′ = {a, b, c, d, u, e,¬f, x}. It can be seen that it produces the same justified residual program as that produced by θ for which we know the stable model count is 2. Furthermore, the set of remaining variables is {y, z}. Therefore, the number of stable assignments below θ′ is 2× 2|{y,z}| = 8.\nIn order to convert a model counter to a stable model counter, we can either modify its calculation of the residual program as suggested by Theorem 1, or, we can modify the actual program and use its existing calculation in a way that\nresidual of the modified program correctly models the justified residual program. Let us describe one such approach and prove that it is correct. We post a copy of each founded variable and each rule such that the copy variable only becomes true when the corresponding founded variable is justified. More formally, for each founded variable v, we create a standard variable v′, add the constraint ¬v′∨v, and for each rule a← f1∧ . . . fn∧sn1∧ . . .∧snm where each fi is a positive founded literal and each sni is a standard or negative literal, we add the clause a′ ∨¬f ′1 ∨ . . .¬f ′n ∨¬sn1 ∨ . . .∨¬snm. Most importantly, we do not allow search to take decisions on any of these introduced copy variables. Let this transformation of a program P be denoted by copy(P ).\nWe now show that it is correct to use the above approach for stable model counting. For the following discussion and results, let P = (V, R, C) be an ASP-SAT program, copy(P ) = (W,R,D) be denoted by Q. Let π, π1, π2 be assignments over W and θ, θ1, θ2 be their projections over non-copy variables (V). Let Q|π (similarly for π1, π2) be a shorthand for (vars(R|θ) ∪ vars(D|θ), R|θ, D|θ). The results assume that assignments π, π1, π2 are closed under unit propagation and unfounded set propagation, i.e., both propagators have been run until fixpoint in the solver.\nTo prove the results, we define a function prj that takes the copy program Q and π and maps it to the justified residual program w.r.t. to the projection of that π on noncopy variables and then argue that Q|π correctly models the justified residual program. Formally, prj (Q, π) is an ASPSAT program P ′ = (V ′, R′, C ′) constructed as follows. Add every constraint in D|π that does not have a copy variable in C ′. For every constraint v′ ∨ ¬f ′1 ∨ . . .¬f ′n ∨ ¬sn1 ∨ . . . ∨ ¬snm inD|π , add the rule v ← f1∧. . .∧fn∧sn1∧. . .∧snm in R′. Let U be the set of founded variables v such that v is true but v′ is unfixed in π. For every v in U , add the constraint v in C ′. Define V ′ as variables of R′ and C ′. Proposition 3 proves that we cannot miss any stable model of the original program if we use the copy approach. Proposition 3. If π cannot be extended to any stable model of Q, then θ cannot be extended to any stable model of P .\nTheorem 4 establishes that we can safely use Q|π to emulate the justified residual program P |jθ. Corollary 5 says that if we detect a stable model cube of Q|π , then we also detect a stable model cube of the same size for the justified residual program. This corollary and Proposition 3 prove that the stable model count of the actual program is preserved.\nTheorem 4. P |jθ = prj (Q, π). Corollary 5. If Q|π has no rules or constraints and there are k unfixed variables, then θ is a stable model cube of P |jθ of size 2k.\nThe next two corollaries prove that the copy approach can be used for caching dynamic decomposition respectively.\nCorollary 6. If Q|π1 = Q|π2 , then P | j θ1 = P |jθ2 . Corollary 7. If Q|π decomposes into k disjoint components Q1, . . . , Qk, then P |jθ decomposes into k disjoint components P1, . . . , Pk such that Pi = prj (Qi, πi) where πi is projection of π on vars(Qi)."
    }, {
      "heading" : "4 PROBLOG2 via Stable Model Counting",
      "text" : "In this section, we describe how we apply stable model counting in the probabilistic logic programming solver PROBLOG2 (Fierens et al. 2013). A probabilistic logic program is a collection of mutually independent random variables each of which is annotated with a probability, derived variables, evidence constraints and rules for the derived variables. The distribution semantics (Sato 1995) says that for a given assignment over the random variables, the values of the derived variables is given by the well-founded model. Furthermore, the weight of that world is equal to the product of probabilities of values of the random variables. In our setting, it is useful to think of random variables, derived variables, evidence constraints, and rules as standard variables, founded variables, constraints and rules respectively. PROBLOG2 handles various inference tasks, but the focus of this paper is computing the marginal probability of query atoms given evidence constraints. The probability of a query atom is equal to the sum of weights of worlds where a query atom and evidence are satisfied divided by the sum of weights of worlds where the evidence is satisfied.\nFigure 1 shows the execution of a PROBLOG2 program. The input is a non-ground probabilistic logic program which is given to the grounder that cleverly instantiates only parts of the program that are relevant to the query atoms, similar to how magic set transformation (Bancilhon et al. 1985) achieves the same goal in logic programming. The ground program and the evidence is then converted to CNF using the proof based encoding that we discussed earlier. This CNF is passed on to a knowledge compiler like DSHARP (Muise et al. 2012). DSHARP is an extension of SHARPSAT (Thurley 2006) where the DPLL-style search is recorded as d-DNNF. The d-DNNF produced by the knowledge compiler is given to the parser of PROBLOG2 along with the ground queries and probabilities of the random variables. The parser evaluates the probability of each query by crawling the d-DNNF as described in (Fierens et al. 2013).\nOur contribution is in the components in the dotted box in Figure 1. We have implemented stable model counting by extending the propositional model counter SHARPSAT as described in the previous section. Since SHARPSAT is part of the knowledge compiler DSHARP, our extension of SHARPSAT automatically extends DSHARP to a stable model knowledge compiler. The CNF conversion component in PROBLOG2 chain is replaced by a simple processing of the ground program and evidence to our desired input format. In the first approach where the search is restricted to standard variables, the evidence needs to be passed on to our\nstable model counter which posts a nogood (the current assignment of standard variables) each time an evidence atom is violated. In approach given in Section 3.2, however, we post each evidence as a unit clause, much like PROBLOG2 does in its CNF conversion step. Including evidence in constraints in the second approach is safe since our residual program relies on the justified assignment only, and propagation on founded literals that makes them true due to constraints does not change that. Outside the dotted box in the figure, the rest of the PROBLOG2 logic remains the same."
    }, {
      "heading" : "5 Experiments",
      "text" : "We compare the two approaches based on implementation of unfounded set detection as explained in Section 3 against the proof based encoding of PROBLOG2. We use two well-studied benchmarks: SmokersFriends (Fierens et al. 2011) problem and the graph reliability problem (GraphRel ) (Arora and Barak 2009) with evidence constraints.\nIn both problems, the graph is probabilistic. In GraphRel , the nodes are associated with probabilities while in SmokersFriends , the edges have probabilities. Naturally, for n nodes, the number of random variables is in O(n) and O(n2) for GraphRel and SmokersFriends respectively. Due to this, GraphRel has significantly more loops per random variables in the dependency graph which makes it more susceptible to the size problems of eager encoding. We refer to the fixed search approach of Section 3.1 as ASPROBLOGS and the proper integration of unfounded set detection through the use of copy variables of Section 3.2 as ASPROBLOG. All experiments were run on a machine running Ubuntu 12.04.1 LTS with 8 GB of physical memory and Intel(R) Core(TM) i7-2600 3.4 GHz processor.\nTable 1 shows the comparison between PROBLOG2, ASPROBLOG and ASPROBLOGS on GraphRel on random directed graphs. The instance is specified by N , the number of nodes, and P , the probability of an edge between any two nodes. The solvers are compared on the following parameters: time in seconds (Time), number of variables and clauses in the input program of DSHARP (V and C resp.), number of decisions (D), average decision level of backtrack due to conflict or satisfaction (A), the size in megabytes of the d-DNNF produced by DSHARP (S), and for ASPROBLOG and ASPROBLOGS, the number of loops produced during the search (L). Each number in the table represents the median value of that parameter from 10 random instances of the size in the row. The median is only defined if there are at least (6) output values. A ‘—’ represents memory exhaustion or a timeout of 5 minutes, whichever occurs first. A ‘—’ in columns Time, D, A, L, S means that the solver ran out of memory but the grounding and encoding was done successfully, while a ‘—’ in all columns of a solver means that it never finished encoding the problem. We show the comparison on three types of instances: small graphs with high density, medium graphs with high to medium density, and large graphs with low density.\nClearly ASPROBLOG and ASPROBLOGS are far more scalable than PROBLOG2. While PROBLOG2 requires less search (since it starts with all loop formulae encoded) the overhead of the eager encoding is prohibitive. For all solved\ninstances, ASPROBLOG has the best running time and dDNNF size, illustrating that the search restriction of ASPROBLOGS degrades performance significantly. While the encoding for ASPROBLOGS is always smallest, the encoding with copy variables and rules of ASPROBLOG is not significantly greater, and yields smaller search trees and fewer loop formulae. It is clearly the superior approach.\nFigure 2 compares the performance of PROBLOG2 and ASPROBLOG on SmokersFriends when the number of random variables is fixed to 31 and the problem size is increased. In the problem description, there are two sets of random variables, the stress and the influences variables. The first one exists for each person in the graph, while the latter exists for every edge in the graph. In our setting, for an instance with n persons, the number of influences ran-\ndom variables is equal to 31− n. The rest of the influences variables are fixed to true or false at run time. For the smallest instances of sizes 7 and 8, PROBLOG2 and ASPROBLOG have similar performance. For instances 9 to 12, PROBLOG2 does better than ASPROBLOG where the latter cannot solve instances 11 and 12 due to memory exhaustion. The reason is that the complete encoding in PROBLOG2 propagates better and the extra unfounded set check at each node in the search tree in ASPROBLOG does not pay off. But as the number of people increases and the number of probabilistic edges becomes less, the problem becomes easier for ASPROBLOG but not for PROBLOG2. The reason is that by fixing the probabilistic edges, we are just left with n external rules, and many internal rules, making many founded variables logically equivalent to each other. In the last instance, the number of loop formulas required for the problem is only one! Our lazy approach benefits from this structure in the problem, while PROBLOG2 does not. Our experiments with the same range of instances but with number of random variables fixed to 33 and 35 show similar behaviour of PROBLOG2 and ASPROBLOG where initially, PROBLOG2 does better, followed by hard instances for both, and finally, ASPROBLOG detecting the structure and solving the last few instances in less than 2 seconds."
    }, {
      "heading" : "6 Conclusion",
      "text" : "Stable model counting is required for reasoning about probabilistic logic programs with positive recursion in their rules. We demonstrate that the current approach of translating logic programs eagerly to propositional theories is not scalable because the translation explodes when there is a large number of recursive rules in the ground program. We give two methods to avoid this problem which enables reasoning about significantly bigger probabilistic logic programs."
    }, {
      "heading" : "A Proofs of theorems and their corollaries",
      "text" : "Theorem 1. Given an ASP-SAT program P = (V, R, C) and a partial assignment θ, let P |jθ = (W,S,D) be denoted byQ. Let the remaining variables be Vr = V\\(W∪vars(θ)) and π be a complete assignment over W . Assume any founded variable for which there is no rule in S is false in θ.\n1. If π is a stable model of Q, then for any assignment θr over the remaining variables, θ∪π ∪ θr is a stable model of P .\n2. For a given assignment θr over remaining variables, if θ∪π∪ θr is a stable model of P , then π is a stable model of Q.\nProof. Let J = JA(P, θ). Note that there cannot be a founded variable in the remaining variables Vr since if a founded variable is not true in θ and does not have a rule in S, then it must be false in θ due to the given assumption.\nThe key point is to view R as two separate sets of rules, S and R \\ S and argue that we can treat them separately for the purpose of least models. If there is any assignment that extends θ, then from R \\ S, we can safely delete the rules whose bodies intersect withW or θr as these rules are redundant since all assignments in J0(θ) are sufficient to imply the founded literals in J . Furthermore, the least assignment of reduct of R \\ S w.r.t. any assignment that extends θ will be exactly equal to the founded literals in J . Therefore:\nLeast(Rθ∪π∪θR) =VF J ∪ Least(Sπ∪θR) Since θR does not have any founded variables and we just argued that we can delete the rules in R \\ S that have any variable from θR and θR is completely disjoint from S by definition, we can simplify the above equality to: Least(Rθ∪π) =VF J ∪ Least(Sπ).\n1. We are given that π is a stable model of Q, i.e., π |= S, π |= D and Least(Sπ) =VF π. It is easy to show that this implies that θ ∪ π |= R ∪ C. Moreover, from the above equality, we get Least(Rθ∪π) =VF J ∪ π. Since, due to constraints added in D, θ and π are consistent on founded variables in V \\vars(J), we get Least(Rθ∪π) =VF θ∪π. It is easy to see that any assignment θR can be used to extend θ ∪ π without affecting satisfiability or the least model, which means that θ ∪ π ∪ θR is a stable model of P .\n2. We are given that θ∪π∪θR is a stable model ofP . By definition of residual programs, we know that θ |= C \\D and the intersection of variables in D and θ is empty, which means that if D is non-empty, then θ is not sufficient to satisfy D which implies that π |= D (if D is empty, then trivially π |= D). A similar argument for the case π |= R|θ can be made. Given that θ and π are consistent, we can also see that π |= S\\R|θ which means that π |= S. For least model, from the equality that we discussed previously, we are given that θ ∪ π =VF J ∪ Least(Sπ). Again, since θ ∪ π =VF J ∪ π, we can derive that π =VF Least(S\nπ) which means that π is a stable model of Q.\nCorollary 2. Let the set of rules and constraints of Q decompose into k ASP-SAT programs Q1 = (W1, S1, D1), . . . , Qk = (Wk, Sk, Dk) where Wi = vars(Si) ∪ vars(Di) s.t. for any distinct i, j in 1 . . . k, Wi ∩ Wj = ∅. Let the remaining variables be: Vr = V\\(W1∪. . .∪Wk∪vars(θ)) and let π1, . . . , πk be complete assignments over W1, . . . ,Wk respectively.\n1. If π1, . . . , πk are stable models of Q1, . . . , Qk resp., then for any assignment θr over the remaining variables, θ ∪ π1 ∪ . . . ∪ πk ∪ θr is a stable model of P .\n2. For a given assignment θr over remaining variables, if θ ∪ π1 ∪ . . .∪ πk ∪ θr is a stable model of P , then πi is a stable model of Qi for each i ∈ 1 . . . k.\nProof. Theorem 1 says that the justified residual program can be solved in isolation and its results can be combined with the parent program. Furthermore, since all ASP programs Q1, . . . , Qk are completely disjoint, both 1 and 2 follow from the Module Theorem (Theorem 1) as given in (Janhunen et al. 2007) which says that two mutually compatible assignments that are stable models of two respective programs can be joined to form a stable model of their union program and conversely, a stable model of the combined program can be split into stable models of individual programs, as long as there are no positive interdependencies between the two programs. Ours is a simple special case of Corollary 1 in (Janhunen et al. 2007) where all programs and their sets of variables are completely disjoint.\nFor the following discussion and results, let P = (V, R, C) be an ASP-SAT program, copy(P ) = (W,R,D) be denoted by Q. Let π, π1, π2 be assignments over W and θ, θ1, θ2 be their projections over non-copy variables (V). Let Q|π (similarly for π1, π2) be a shorthand for (vars(R|θ)∪ vars(D|θ), R|θ, D|θ). The results assume that assignments π, π1, π2 are closed under unit propagation and unfounded set propagation, i.e., both propagators have been run until fixpoint in the solver.\nTo prove the results, we define a function prj that takes the copy program Q and π and maps it to the justified residual program w.r.t. to the projection of that π on noncopy variables and then argue that Q|π correctly models the justified residual program. Formally, prj (Q, π) is an ASPSAT program P ′ = (V ′, R′, C ′) constructed as follows. Add every constraint in D|π that does not have a copy variable in C ′. For every constraint v′ ∨ ¬f ′1 ∨ . . .¬f ′n ∨ ¬sn1 ∨ . . . ∨ ¬snm inD|π , add the rule v ← f1∧. . .∧fn∧sn1∧. . .∧snm in R′. Let U be the set of founded variables v such that v is true but v′ is unfixed in π. For every v in U , add the constraint v in C ′. Define V ′ as variables of R′ and C ′. Proposition 3. If π cannot be extended to any stable model of Q, then θ cannot be extended to any stable model of P .\nProof sketch. Say θ has an extensionE that is a stable model of P . We can show that running unit propagation on Q and E yields a solution of Q that is an extension of π, which contradicts what is given.\nTheorem 4. P |jθ = prj (Q, π).\nProof. Recall the definition of justified assignment: JA(P, θ) = J0(θ) ∪ {v ∈ VF |v ∈ θ, v ∈ Least(R|J0(θ))}. Also recall that any copy constraint r′ in Q has the form: v′ ∨ ¬f ′1 ∨ . . .¬f ′n ∨ ¬sn1 ∨ . . .¬snm and by definition, each r′ is the copy of a rule r in P , which is v ← f1∧ . . . fn∧sn1∧ . . .∧snm. Recall that v′, f ′1, . . . , f ′n are copy variables of v, f1, . . . , fn respectively, f1, . . . , fn are positive literals in r and sn1, . . . , snm are either standard or negative literals in r. We show that the sets of rules, constraints, and variables of prj (Q, π) and P |jθ are equal, therefore, they are equal. We begin by reasoning about the sets of rules.\nLet us focus on the seed of the justified assignment J0(θ). It is easy to see that J0(π) ∩ V = J0(θ). Since r′ and r share all standard and negative literals, their residuals w.r.t. these literals will be simplified in exactly the same way, i.e., if r′|J0(π) = v′ ∨ ¬f ′1 ∨ . . .¬f ′n ∨ ¬sn1 ∨ . . .¬snk, then r|J0(θ) = v ← f1∧. . . fn∧sn1∧. . .∧snk. The core point of the proof is that running unit propagation on the set of copy rules r′|J0(π) is analogous to computing Least(R|J0(θ)). Each application of unit propagation on r′ that derives v′ must also derive v in r|J0(θ). This means that if, due to this propagation, the set of copy variables J ′ = {v′1, . . . , v′j} is derived, then JA(P, θ)\\J0(θ) = {v1, . . . , vj}. Furthermore, since no decisions on copy variables are allowed, and there is no other constraint that can possibly derive a literal v′, unit propagation cannot derive any other positive copy literal. Now, let us view prj (Q, π) as individual applications of a function prjcopy on each copy rule r′ to produce r. We can see that prjcopy(r|J0(π)∪J′) = r|JA(P,θ). Therefore, the set of rules in prj (Q, π) and P |jθ is exactly the same.\nFrom above, it also follows that the set U in the construction of prj (Q, π) and the set U in Definition 1 are equal. Since θ is just the restriction of π on non-copy variables, the residual of any constraint that has non-copy variables only is the same and since the consistency constraints due to U are also the same, the set of constraints C ′ and C are equal. Since the rules and constraints are equal in prj (Q, π) and P |jθ, their variables are also equal.\nCorollary 5. If Q|π has no rules or constraints and there are k unfixed variables, then θ is a stable model cube of P |jθ of size 2k.\nProof. Since Q|π is empty, prj (Q, π) is also empty, and since P |jθ = prj (Q, π), this means that P | j θ is a stable model cube. Furthermore, we can show that all founded variables and their copies must be fixed in Q|π , which means all k variables must be standard variables, therefore, the size of stable model cube of P |jθ is 2k.\nCorollary 6. If Q|π1 = Q|π2 , then P | j θ1 = P |jθ2 .\nProof. Follows directly from Theorem 4 and definition of prj function.\nCorollary 7. If Q|π decomposes into k disjoint components Q1, . . . , Qk, then P |jθ decomposes into k disjoint compo-\nnents P1, . . . , Pk such that Pi = prj (Qi, πi) where πi is projection of π on vars(Qi).\nProof. Note that the disjointness of components of Q|π is really determined by its constraints, and not its rules. The residual rules are always stronger (have fewer variables) than their respective residual copy constraints, because it is possible that a founded variables v is true in π but its copy variable v′ is unfixed. The opposite is not possible and moreover, standard and negative literals are shared in a rule and its corresponding copy constraint. This property of residual rules is important since prj (Q, π) works by projecting each individual copy rule to its original form in P |jθ and completely ignores the residual set of rules in Q|π .\nIt is clear from definition of prj (Q, π) that the projection of each rule merely replaces the copy variables with their corresponding founded variables. This means that we can take each disjoint component of Q|π and map it to its counterpart in P |jθ using the projection function. Non-copy constraint translation in prj (Q, π) is also straight-forward and cannot combine multiple disjoint components in Q|π to one component in P |jθ or split one component in Q|π to multiple components in P |jθ. Finally, addition of the unary clauses for all variables in U (as used in the definition of prj (Q, π)) also does not affect the components; by definition, a variable v in U must have at least one copy constraint v′ ∨ ¬f ′1 ∨ . . .¬f ′n ∨ ¬sn1 ∨ . . .¬snm which will be projected to v ← f1 ∧ . . . fn ∧ sn1 ∧ . . . snm in P |jθ. Adding v as a constraint does not affect the component Pi in which this projected rule appears in P |jθ."
    } ],
    "references" : [ {
      "title" : "Computational complexity - a modern approach (Chapter: Complexity of Counting)",
      "author" : [ "Arora", "S. Barak 2009] Arora", "B. Barak" ],
      "venue" : null,
      "citeRegEx" : "Arora et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Arora et al\\.",
      "year" : 2009
    }, {
      "title" : "DPLL with Caching: A new algorithm for #SAT and Bayesian Inference",
      "author" : [ "Dalmao Bacchus", "F. Pitassi 2003] Bacchus", "S. Dalmao", "T. Pitassi" ],
      "venue" : "Electronic Colloquium on Computational Complexity",
      "citeRegEx" : "Bacchus et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Bacchus et al\\.",
      "year" : 2003
    }, {
      "title" : "Magic sets and other strange ways to implement logic programs",
      "author" : [ "Bancilhon" ],
      "venue" : "In Proceedings of the fifth ACM SIGACT-SIGMOD symposium on Principles of database systems,",
      "citeRegEx" : "Bancilhon,? \\Q1985\\E",
      "shortCiteRegEx" : "Bancilhon",
      "year" : 1985
    }, {
      "title" : "Inference in probabilistic logic programs using weighted CNF’s",
      "author" : [ "Fierens" ],
      "venue" : "Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence",
      "citeRegEx" : "Fierens,? \\Q2011\\E",
      "shortCiteRegEx" : "Fierens",
      "year" : 2011
    }, {
      "title" : "Inference and learning in probabilistic logic programs using weighted boolean formulas",
      "author" : [ "Fierens" ],
      "venue" : "CoRR abs/1304.6810",
      "citeRegEx" : "Fierens,? \\Q2013\\E",
      "shortCiteRegEx" : "Fierens",
      "year" : 2013
    }, {
      "title" : "Conflict-driven answer set solving",
      "author" : [ "Gebser" ],
      "venue" : "In Proceedings of the 20th International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Gebser,? \\Q2007\\E",
      "shortCiteRegEx" : "Gebser",
      "year" : 2007
    }, {
      "title" : "Conflict-driven answer set solving: From theory to practice",
      "author" : [ "Kaufmann Gebser", "M. Schaub 2012] Gebser", "B. Kaufmann", "T. Schaub" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "Gebser et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gebser et al\\.",
      "year" : 2012
    }, {
      "title" : "The stable model semantics for logic programming",
      "author" : [ "Gelfond", "M. Lifschitz 1988] Gelfond", "V. Lifschitz" ],
      "venue" : "ICLP/SLP,",
      "citeRegEx" : "Gelfond et al\\.,? \\Q1988\\E",
      "shortCiteRegEx" : "Gelfond et al\\.",
      "year" : 1988
    }, {
      "title" : "Modularity aspects of disjunctive stable models",
      "author" : [ "Janhunen" ],
      "venue" : "In Logic Programming and Nonmonotonic Reasoning, 9th International Conference,",
      "citeRegEx" : "Janhunen,? \\Q2007\\E",
      "shortCiteRegEx" : "Janhunen",
      "year" : 2007
    }, {
      "title" : "The DLV system for knowledge representation and reasoning",
      "author" : [ "Leone" ],
      "venue" : "ACM Trans. Comput",
      "citeRegEx" : "Leone,? \\Q2006\\E",
      "shortCiteRegEx" : "Leone",
      "year" : 2006
    }, {
      "title" : "Why are there so many loop formulas",
      "author" : [ "Lifschitz", "Razborov 2006] Lifschitz", "Razborov" ],
      "venue" : "ACM Transactions on Computational Logic 7(2):261–268",
      "citeRegEx" : "Lifschitz et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Lifschitz et al\\.",
      "year" : 2006
    }, {
      "title" : "ASSAT: computing answer sets of a logic program by SAT solvers",
      "author" : [ "Lin", "F. Zhao 2004] Lin", "Y. Zhao" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "Lin et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2004
    }, {
      "title" : "DSHARP: Fast d-DNNF Compilation with sharpSAT",
      "author" : [ "Muise" ],
      "venue" : "In Canadian Conference on AI,",
      "citeRegEx" : "Muise,? \\Q2012\\E",
      "shortCiteRegEx" : "Muise",
      "year" : 2012
    }, {
      "title" : "Probabilistic programming concepts",
      "author" : [ "Raedt", "L.D. Kimmig 2013] Raedt", "A. Kimmig" ],
      "venue" : "In Programming Languages,",
      "citeRegEx" : "Raedt et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Raedt et al\\.",
      "year" : 2013
    }, {
      "title" : "Combining component caching and clause learning for effective model counting",
      "author" : [ "Sang" ],
      "venue" : "In Proceedings of the 7th International Conference on Theory and Applications of Satisfiability Testing (SAT-2004)",
      "citeRegEx" : "Sang,? \\Q2004\\E",
      "shortCiteRegEx" : "Sang",
      "year" : 2004
    }, {
      "title" : "The complexity of enumeration and reliability problems",
      "author" : [ "L.G. Valiant 1979] Valiant" ],
      "venue" : null,
      "citeRegEx" : "Valiant,? \\Q1979\\E",
      "shortCiteRegEx" : "Valiant",
      "year" : 1979
    }, {
      "title" : "Unfounded sets and wellfounded semantics for general logic programs",
      "author" : [ "Ross Van Gelder", "A. Schlipf 1988] Van Gelder", "K.A. Ross", "J.S. Schlipf" ],
      "venue" : "In Proceedings of the ACM Symposium on Principles of Database Systems,",
      "citeRegEx" : "Gelder et al\\.,? \\Q1988\\E",
      "shortCiteRegEx" : "Gelder et al\\.",
      "year" : 1988
    }, {
      "title" : "Compiling probabilistic logic programs into sentential decision diagrams",
      "author" : [ "Vlasselaer" ],
      "venue" : "In Workshop on Probabilistic Logic Programming (PLP), Vienna",
      "citeRegEx" : "Vlasselaer,? \\Q2014\\E",
      "shortCiteRegEx" : "Vlasselaer",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "Consider the counting version of graph reachability problem: given a directed graph, count the number of subgraphs in which node t is reachable from node s (Valiant 1979).",
      "startOffset" : 156,
      "endOffset" : 170
    } ],
    "year" : 2017,
    "abstractText" : "Model counting is the problem of computing the number of models that satisfy a given propositional theory. It has recently been applied to solving inference tasks in probabilistic logic programming, where the goal is to compute the probability of given queries being true provided a set of mutually independent random variables, a model (a logic program) and some evidence. The core of solving this inference task involves translating the logic program to a propositional theory and using a model counter. In this paper, we show that for some problems that involve inductive definitions like reachability in a graph, the translation of logic programs to SAT can be expensive for the purpose of solving inference tasks. For such problems, direct implementation of stable model semantics allows for more efficient solving. We present two implementation techniques, based on unfounded set detection, that extend a propositional model counter to a stable model counter. Our experiments show that for particular problems, our approach can outperform a state-of-the-art probabilistic logic programming solver by several orders of magnitude in terms of running time and space requirements, and can solve instances of significantly larger sizes on which the current solver runs out of time or memory.",
    "creator" : "LaTeX with hyperref package"
  }
}