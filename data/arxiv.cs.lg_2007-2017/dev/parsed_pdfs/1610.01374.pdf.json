{
  "name" : "1610.01374.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Domain Adaptation with Soft-margin multiple feature-kernel learning beats Deep Learning for surveillance face recognition",
    "authors" : [ "Samik Banerjee", "Sukhendu Das" ],
    "emails" : [ "samik@cse.iitm.ac.in", "sdas@iitm.ac.in" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Face recognition (FR) has gained importance in security for surveillance, which has recently attracted the attention of vision researchers. In surveillance scenarios, the problem of face recognition is difficult as the image frames captured by CCTV cameras often suffer from low illumination and distance-based attenuation factors, thus capturing poor quality images. The low quality face images coupled with low resolution produce unsatisfactory performance (accuracy) of recognition. There has been several attempts of FR to solve this problem in the recent past. Traditional FR techniques fail to cater to the changes in the resolution, contrast and illumination between the gallery and the probe samples.\nThe proposed approach consists of three stages: (i) Preprocessing and feature-extraction, (ii) Soft-margin learning for multiple feature-kernel combinations (SML-MFKC), and (iii) Domain Adaptation (DA). In the rest of the paper, section 2 details the recent advances in the field of the face detection and recognition under surveillance scenario, multiple kernel learning based classification and domain adaptation. Section 3 briefly outlines the proposed\ntechniques, while the section 4 introduces the three real world surveillance datasets used for the evaluation of the proposed techniques. Finally, section 5 gives the quantitative results of performance analysis for the proposed technique, on the three datasets, using rank-1 recognition rate, CMC and ROC metrics, and section 6 concludes the paper."
    }, {
      "heading" : "2. Related Works",
      "text" : "The most widely used face detection algorithm proposed by Viola et al. [30], is based on an efficient classifier build using the ADABOOST learning algorithm, which selects a subset of critical visual features from a very large set of potential features. Our proposed technique includes the face detection technique based on the set of 49 fiducial landmark points detected by the Chehra [4] face detector.\nA large scale implementation of support vector machine (SVM) for large number of kernels, known as sequential minimal optimization (SMO), was proposed by Bach et al. [5]. A multiple kernel learning (MKL) algorithm based on sparse representation-based classification (SRC) proposed in [25], represents the non-linearities in the highdimensional feature space based on kernel alignment criteria. Conic combinations of kernel matrices for classification proposed in [16] leads to a convex quadratically constrained quadratic problem (QCQP). Sonnenburg et al. [26] generalized the formulation to a larger class of problem.\nThe work proposed in [27] performs domain adaptation based on the calculation of the weights of the instances in the source domain. Yang et al. [35] proposed a method to effectively retrain a pre-trained SVM for target domain data, based on the calculated weights of the instances in the source domain. Duan et al. [9] proposed a domain adaptive machine (DAM), which learns a robust decision function for labeling the instances in the target domain, by leveraging a set of base classifiers learned on multiple source domains. Tranfer component analysis (TCA), proposed in [18], minimizes the disparity of distribution by comparing the difference in the means between two domains and preserving\n1\nar X\niv :1\n61 0.\n01 37\n4v 2\n[ cs\n.C V\n] 2\n7 O\nct 2\nthe local geometry of the underlying manifold. Subspaces are calculated based on eigen-vectors [10] of two domains, such that the basis vectors of the of the transformed source and target domains are aligned. Wang et al. [32] considered the manifold of each domain and estimated a latent space, where the manifolds of both the domains are similar to each other. A new method of unsupervised DA was proposed by Samanta et al. [23] using the properties of the of the sub-spaces spanning the source and target domains, when projected along a path in the Grassmannian manifold.\nSurveillance cameras produce images at very low resolution to cope with the high transmission speed and optimality of the storage data. Besides the degradation incurred due to low resolution, the images captured by surveillance cameras also contain noise and distortions (defocus, blur, low contrast), due to their uncontrolled environment conditions during capture. A matching algorithm based on transformation learning through an iterative majorization algorithm, in the kernel space, was proposed by Biswas et al. [8], known as multi-dimensional scaling (MDS). Ren et al. [21] proposed the Coupled Kernel Embedding approach, where they map the low and high resolution face images onto different kernel spaces and then transform them to a subspace for recognition. Rudrani et al. in [22] proposed an approach with the combination of partial restoration (using super-resolution) of probe samples and degradation of gallery samples. An outdoor surveillance dataset, FR_SURV, was also proposed in [22], for evaluating their approach. A Dynamic Bayesian Network (DBN) based unconstrained face recognition under surveillance scenario has been proposed by An et al. [2] to integrate the information from all the three cameras in the ChokePoint [33] dataset. The work proposed in [6] aims to bridge the gap of resolution and contrast using superresolution and contrast stretching on the probe samples and degrading the gallery samples. A DA technique based on an eigen-domain transformation was proposed to make the distributions of gallery (as source) features identical to that of probe (as target) samples."
    }, {
      "heading" : "3. Proposed Method",
      "text" : "The stages of the overall proposed framework for FR, as shown in figure 1, is briefly discussed below:"
    }, {
      "heading" : "3.1. Face Detection",
      "text" : "The Face detection stage is based on the 49 fiducial points obtained from the Chehra [4] face detector, to obtain a tightly cropped facial region."
    }, {
      "heading" : "3.2. Pre-processing",
      "text" : "Pre-processing of both the gallery and probe samples are required to bridge the gap between the face images obtained from the gallery and probe samples. The stages of\npre-processing are the same as described in [6]. The empirical values of the parameters in the pre-processing algorithms (see [6] for details) are: the Gaussian blur kernel, σ, for degradation of the gallery; and γ used for contrast enhancement of the probes, are given in table 1, for the three datasets used for performance analysis. An example showing the degraded gallery and enhanced probe for each dataset is shown in figure 2."
    }, {
      "heading" : "3.3. Feature Extraction",
      "text" : "Holistic features are extracted from each of these gallery and probe face samples. Several recent state-of-the art as-well-as traditional features are taken into account viz., Eigenfaces [29], Fisherfaces [7], Weberfaces [31], Local binary pattern (LBP) [1], Gaborfaces [17], Bag-of-words (BOW) [11], Fisher vector encoding on dense-SIFT features (FV-SIFT) [20] and VLAD encoding on dense-SIFT features (VLAD-SIFT) [3]. These form a bank of 8 sets of feature descriptors."
    }, {
      "heading" : "3.4. Soft-margin learning for multiple featurekernel combinations (SML-MFKC)",
      "text" : "The process of selecting the the best performing kernel function and its parameters in a support vector machine (SVM) during training, generally consists of a crossvalidation procedure. MKL techniques have been used to\ncope with this, where instead of selecting a specific kernel function, multiple kernels are learned using a weighted combination along with its corresponding parameters. Our proposed technique takes into consideration both the kernel and feature to be selected from a single framework. Given a training set (xi, yi),∀i = 1, ..., N , of N instances, each consisting of an image xi ∈ X and a class label yi ∈ 1, ..., C, and given a set of F image features Vm : X → Rdm ,∀m = 1, ..., F , where dm denotes the dimensionality of them-th feature, the problem of learning a classification function y : X → 1, ..., C from the features and training set is called the feature combination problem [12].\nSince we associate image features with kernel functions (km), kernel selection translates naturally into a feature selection problem. The objective of SML-MFKC is to jointly optimize over a linear combination of kernels k∗(x, y) =∑F m=1 βmkm(x, y), βm ∈ R, ~β ∈ RF and the parameters ~α ∈ RN and b ∈ R of an SVM. The objective function which determines the optimal combination of the feature and the kernel for the method, is given by the following proposed (novel) soft-margin cost function:\nsup argmin ~βq∈RF\n1\n2 F∑ m=1 βqm~α TV qm~α\n+ C N∑ i=1 L(yi, b+ F∑ m=1 βqm~α TV qm~α)\ns.t F∑\nm=1\nβqm = 1, β q m ≥ 0,∀m, q = 1, ...P.\n(1)\nwhere, L(y, t) = max(0, 1−yt) denotes the Hinge Loss, P denotes the total number kernels used for learning (see table 2, for details of the six different kernels used), V qm denotes the m-th feature for the q-th kernel function, and βqm ∈ R denotes the weight coefficient for the m-th feature and the q-th kernel combination.\neach of the q-th kernel, among the P kernels, the best selected feature, Ṽq is based on the supremum over the set, ~βq . The optimal feature-kernel combinations < M i, Qi >, ∀i ∈ {1, ..., P} is thus obtained, where M i ∈ {Ṽ1, ..., ṼF } and Qi is an element (km) from the set of P kernels. Each of these features, M i, are projected in the RKHS using Qi to obtain a new feature representation to be used in the DA stage."
    }, {
      "heading" : "3.5. Domain Adaptation",
      "text" : "The proposed DA technique proposed is based on the method described by Hoffman et al. in [15]. The normal to the affine hyperplane associated with the k-th binary SVM is denoted as θk, k = 1, ...,K, and the offset of that hyperplane from the origin as bk. The authors propose to estimate a transformation W of the input features, or, equivalently, a transformation WT of the source hyperplane parameters θk. Let, xs1, ..., x s nS denote the training points in the source domain (DS), with labels ys1, ..., y s nS . Let x t 1, ..., x t nT denote the labeled points in the target domain (DT ), with labels yt1, ..., y t nT , with hinge loss in this case, denoted as: L(y, x, θ) = max{0, 1 − δ(y, k) · xT θ}. Thus the cost function defined below, can be solved using a coordinatedescent approach. J(W, θk, bk) = 1\n2 ‖W‖2F+\nK∑ k=1 [ 1 2 ‖θk‖22 + CS nS∑ i=1 L ( ysi ,W · [ xsi 1 ] , [ θk bk ]) +\nCT nT∑ i=1 L ( yti , [ xti 1 ] , [ θk bk ])] (2)\nwhere, the constant CS penalizes the source classification error and CT penalizes the target adaptation error. Minimization of J in equation 2, yields the transformation matrix WT . The source domain data (features from gallery) are then transformed using WT to obtain the transformed source domain data.\nThe overall training phase for classification is illustrated in figure 3, which shows that the features obtained from the degraded gallery samples are fed to the SML-MFKC stage to find the optimal feature-kernel combinations, which in turn is passed into the DA module to obtained transformed source features for classification in RKHS."
    }, {
      "heading" : "3.6. Classification",
      "text" : "We use the kNN classifier to classify the probe images, which is trained with transformed source domain data based on the transformation obtained from the DA stage. Features from probes samples extracted during the testing stage, are also projected using the respective kernel functions to RKHS, and the Euclidian distance to the nearest transformed source domain data yields the recognized subject ID."
    }, {
      "heading" : "4. Real world surveillance datasets",
      "text" : "For experimentation purpose, we have used three realworld surveillance face datasets, namely, FR_SURV [22], SCFace [14] and ChokePoint [33]. For two (SCFace and ChokePoint) out of the three datasets, the probe samples are captured indoor, while the other (FR_SURV) is shot outdoor. For FR_SURV dataset [22], the gallery and probe samples consists cropped face regions at an average of 150 × 150 pixels and 33 × 33 pixels respectively for 51 subjects with 20 samples per class. The SCFace dataset [14] has a huge collection of static images of 130 different subjects. The gallery cropped by Chehra has an average of 800×600 pixels resolution, while the cropped probe images at Distances 1, 2 and 3 has a resolution at an average of 40×40, 60×60 and 100×100 pixels respectively, for cams 1-5. Cams 6-8 are not used for evaluation as they are IR images. The ChokePoint dataset [33] consists of 25 subjects (19 males and 6 females) in portal 1 and 29 subjects (23 males and 6 females) in portal 2. In total, it consists of 48 video sequences and 64, 204 face images. For experimentation, we consider the images obtained from camera, C1 as the Gallery set, since it contains maximum frontal images with better lighting conditions than C2 and C3, which are considered as the probe set. The probe images are passed through all the pre-processing stages, except the face hallucination stage, as the resolution of the images obtained from all these cameras are similar."
    }, {
      "heading" : "5. Experimental results and discussion",
      "text" : "Rigorous experimentations have been carried on three real-world datasets; SCface [14], FR_SURV [22], and ChokePoint [33]. The performance of the proposed methods are compared with several other recent state-of-the-art methods, and the results are reported in table 3, using Rank1 Recognition Rate.\nPre-processing is applied uniformly on all face samples prior to application of the algorithms used for comparative study of performance, to obtain fair numbers. For all algorithms in table 3, code was partially or fully obtained from authors’ websites, unless mentioned otherwise. These\nmethods of FR (table 3), are tuned separately for each of these three datasets, based on our best understanding of the algorithms described in the papers, to make the platform for comparative study uniformly similar (if not identical) across all these methods. In EDA1 method, proposed by Banerjee et al. [6], DA processing was based on an eigenvector based transformation, whose extension to RKHS is termed as KDA1, in which case the performances on the SCFace [14] and FR_SURV [22] are comparable; since the non-linearity in the transformation provided by DA technique in RKHS helps to obtain a slightly better result for FR_SURV compared to that in SCFace. Rudrani et al. [22] (COMP_DEG) tries to bridge the gap between the gallery and the probe samples by projecting them both into a lower dimensional subspace determined by the principal components of the feature vectors obtained from the test set (probes). This paper also acts as the primary source for the dataset, FR_SURV [22], where an algorithm (overtuned for degradation in the dataset) is proposed to solve the problem of face recognition under surveillance in an outdoor scenario for specific source and target sensors. Multidimensional scaling (MDS) proposed by Biswas et al. in [8] (near implementation to the best of our knowledge) projects both the gallery and the probe samples into a common subspace for classification. The methods proposed by Gopalan et al. [13] and Kliep [27] are two DA based techniques used for object classification across domains (codes borrowed from authors). Our proposed method is also compared with the BaseMKL method used in our formulation, but considered here with a single feature representation. This particular (BaseMKL) method, uses VLAD-SIFT [3] exclusively as the feature extracted from the face images, and then the optimal kernel is obtained using MKL [5]. We have also experimented on the Deep learning technique proposed by Parkhi et al. [19], using the architecture of convolutional\nneural network (CNN) proposed by the authors. The inputs given to the CNN for training include downgraded gallery images and a few upsampled probes, which were selected as target samples for DA based algorithms. The few set of probes used for DA differ among datasets. Table 4 gives the details of the same, used for experimentation. The test (probe) samples includes the total test sets for all cases. We can observe that our proposed technique has outperformed (our results are given in bold, in Table 3) all the other competing methods by a considerable margin. The complexity of the datasets is also observed by this result of FR, which are all moderately low (table 3) in many cases. Minor inconsistencies in performance for competing methods (see rows 2 & 4, in table 3) reveal the fact that some algorithms capture the nature (class separability and distributions) of the source and target samples better (due to inherent assumptions) than others, depending on the same for the dataset.\nResults are also reported using ROC and CMC plots as shown in figures 4 and 5 respectively, for the three datasets\nused. The plots drawn in red show the performance of our proposed method, which outperform all other competing methods. On an average, the second best performance is given by the naive approach, since the SML-MFKC is also incorporated into it, while the method proposed by Gopalan et al. [13] performs generally the worst.\nA closer look in the table 3 row-wise, reveals that the performance for FR_SURV dataset produces the least accuracy. This is an indication that there is still further scope of improvement in this field. Also, it shows that this database is quite tough to handle. As we can see that the gallery samples in FR_SURV are all taken in indoor laboratory conditions, while the probe samples are taken in Outdoor conditions, which results in the large complexity of the database. Since FR_SURV is an outdoor dataset, we can see the accuracy of FR is less than that of the ChokePoint dataset, which is the easiest to handle among the three. The SCface and the ChokePoint datasets are two indoor (for both gallery and probes) surveillance datasets. Experiments are done in both identification and verification mode. There is still scope of improvement to find a more effective transformation (by DA), such that the distribution of the features of the gallery and the probe become similar. The Naive combination, which is is very competitive in all the three datasets, consists of only the proposed SML-MKFC process (DA module not used). When these two powerful tools are combined (see figures 1 & 3), our proposed method outperforms all other methods by an appreciable extent.\nWhen compared with the recent state-of-the-art techniques, our method outperforms each of them by a huge margin. The Convolutional Neural Network (CNN) models proposed in the recent past mainly focus on the classification, where the test set and the training set have similar environmental conditions, but are unable to capture the variations in illumination, contrast and scale. Hence, for the three real-world surveillance datasets under experimentation, we can infer that these recent Deep Learning techniques fail to achieve appreciable results as shown in table 5, compared to our proposed method."
    }, {
      "heading" : "6. Conclusion",
      "text" : "The FR under surveillance scenario still remains a open area of research due to its enormous difference in training and the testing conditions. The recent state-of-the-art technique of deep learning [19] also fails to perform well for FR under surveillance scenarios, which otherwise have boosted the accuracy of FR in the recent past. An efficient method to tackle the problem of low-contrast and low-resolution in face recognition under surveillance scenario is proposed in this paper, which works well for near-frontal face images only. This paper proposes a novel method using SMLMFKC to obtain an optimal pairing of feature and kernel, followed by DA. The three metrics used to compare the per-\nformance of our proposed method with the recent state-ofthe-art techniques, show a great deal of superiority of our method than the other techniques, using three real-world surveillance face datasets."
    } ],
    "references" : [ {
      "title" : "Face description with local binary patterns: Application to face recognition",
      "author" : [ "T. Ahonen", "A. Hadid", "M. Pietikainen" ],
      "venue" : "IEEE T-PAMI, 28(12):2037–2041,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Dynamic bayesian network for unconstrained face recognition in surveillance camera networks",
      "author" : [ "L. An", "M. Kafai", "B. Bhanu" ],
      "venue" : "IEEE JESCTS, 3(2):155–164,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "All about vlad",
      "author" : [ "R. Arandjelovic", "A. Zisserman" ],
      "venue" : "IEEE CVPR, pages 1578–1585,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Incremental face alignment in the wild",
      "author" : [ "A. Asthana", "S. Zafeiriou", "S. Cheng", "M. Pantic" ],
      "venue" : "CVPR,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Multiple kernel learning, conic duality, and the smo algorithm",
      "author" : [ "F.R. Bach", "G.R. Lanckriet", "M.I. Jordan" ],
      "venue" : "ICML, page 6. ACM,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Face recognition in surveillance conditions with bag-of-words, using unsupervised domain adaptation",
      "author" : [ "S. Banerjee", "S. Samanta", "S. Das" ],
      "venue" : "ICVGIP. ACM,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Eigenfaces vs",
      "author" : [ "P.N. Belhumeur", "J.P. Hespanha", "D.J. Kriegman" ],
      "venue" : "fisherfaces: Recognition using class specific linear projection. IEEE T-PAMI, 19(7):711–720,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Multidimensional scaling for matching low-resolution face images",
      "author" : [ "S. Biswas", "K.W. Bowyer", "P.J. Flynn" ],
      "venue" : "IEEE T- PAMI, 34(10):2019–2030,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Domain adaptation from multiple sources: A domain-dependent regularization approach",
      "author" : [ "L. Duan", "D. Xu", "I.W. Tsang" ],
      "venue" : "IEEE T-NNLS, 23(3):504–518,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Unsupervised visual domain adaptation using subspace alignment",
      "author" : [ "B. Fernando", "A. Habrard", "M. Sebban", "T. Tuytelaars" ],
      "venue" : "IEEE ICCV, pages 2960–2967,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A visual bag of words method for interactive qualitative localization and mapping",
      "author" : [ "D. Filliat" ],
      "venue" : "IEEE ICRA,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "On feature combination for multiclass object classification",
      "author" : [ "P. Gehler", "S. Nowozin" ],
      "venue" : "IEEE ICCV. IEEE,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Domain adaptation for object recognition: An unsupervised approach",
      "author" : [ "R. Gopalan", "R. Li", "R. Chellappa" ],
      "venue" : "IEEE ICCV, pages 999–1006,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Scface–surveillance cameras face database",
      "author" : [ "M. Grgic", "K. Delac", "S. Grgic" ],
      "venue" : "Multimedia tools and applications, 51(3):863–879,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Efficient learning of domain-invariant image representations",
      "author" : [ "J. Hoffman", "E. Rodner", "J. Donahue", "T. Darrell", "K. Saenko" ],
      "venue" : "ICLR,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A statistical framework for genomic data fusion",
      "author" : [ "G.R. Lanckriet", "T. De Bie", "N. Cristianini", "M.I. Jordan", "W.S. Noble" ],
      "venue" : "Bioinformatics, 20(16):2626–2635,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Gabor feature based classification using the enhanced fisher linear discriminant model for face recognition",
      "author" : [ "C. Liu", "H. Wechsler" ],
      "venue" : "IEEE TIP, 11(4):467–476,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Domain adaptation via transfer component analysis",
      "author" : [ "S.J. Pan", "I.W. Tsang", "J.T. Kwok", "Q. Yang" ],
      "venue" : "IEEE T-NN, 22(2):199–210,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Deep face recognition",
      "author" : [ "O.M. Parkhi", "A. Vedaldi", "A. Zisserman" ],
      "venue" : "BMVC, 1(3):6,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Improving the fisher kernel for large-scale image classification",
      "author" : [ "F. Perronnin", "J. Sánchez", "T. Mensink" ],
      "venue" : "ECCV, pages 143–156. Springer,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Coupled kernel embedding for low-resolution face image recognition",
      "author" : [ "C.-X. Ren", "D.-Q. Dai", "H. Yan" ],
      "venue" : "IEEE TIP, 21(8):3770–3783,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Face recognition on low quality surveillance images, by compensating degradation",
      "author" : [ "S. Rudrani", "S. Das" ],
      "venue" : "ICIAR, pages 212–221. LNCS, Springer,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Unsupervised domain adaptation using eigenanalysis in kernel space for categorisation tasks",
      "author" : [ "S. Samanta", "S. Das" ],
      "venue" : "Image Processing, IET, 9(11):925–930,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Facenet: A unified embedding for face recognition and clustering",
      "author" : [ "F. Schroff", "D. Kalenichenko", "J. Philbin" ],
      "venue" : "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 815–823,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Multiple kernel learning for sparse representation-based classification",
      "author" : [ "A. Shrivastava", "V.M. Patel", "R. Chellappa" ],
      "venue" : "IEEE TIP, 23(7):3013–3024,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Large scale multiple kernel learning",
      "author" : [ "S. Sonnenburg", "G. Rätsch", "C. Schäfer", "B. Schölkopf" ],
      "venue" : "JMLR, 7:1531,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Direct importance estimation with model selection and its application to covariate shift adaptation",
      "author" : [ "M. Sugiyama", "S. Nakajima", "H. Kashima", "P. von Bünau", "M. Kawanabe" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2007
    }, {
      "title" : "Deep learning face representation from predicting 10,000 classes",
      "author" : [ "Y. Sun", "X. Wang", "X. Tang" ],
      "venue" : "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1891–1898,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Eigenfaces for recognition",
      "author" : [ "M. Turk", "A. Pentland" ],
      "venue" : "Journal of cognitive neuroscience, 3(1):71–86,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "Robust real-time face detection",
      "author" : [ "P. Viola", "M.J. Jones" ],
      "venue" : "IJCV, 57(2):137–154,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Illumination normalization based on weber’s law with application to face recognition",
      "author" : [ "B. Wang", "W. Li", "W. Yang", "Q. Liao" ],
      "venue" : "IEEE SPL, 18(8):462–465,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Heterogeneous domain adaptation using manifold alignment",
      "author" : [ "C. Wang", "S. Mahadevan" ],
      "venue" : "IJCAI, volume 22, page 1541,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Patch-based probabilistic image quality assessment for face selection and improved video-based face recognition",
      "author" : [ "Y. Wong", "S. Chen", "S. Mau", "C. Sanderson", "B.C. Lovell" ],
      "venue" : "IEEE Biometrics Workshop, CVPRW, June",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Soft margin multiple kernel learning",
      "author" : [ "X. Xu", "I.W. Tsang", "D. Xu" ],
      "venue" : "IEEE T-NNLS, 24(5):749–761,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Cross-domain video detection using adaptive svms",
      "author" : [ "J. Yang", "R. Yan", "A. Hauptmann" ],
      "venue" : "ICM. ACM,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 29,
      "context" : "[30], is based on an efficient classifier build using the ADABOOST learning algorithm, which selects a subset of critical visual features from a very large set of potential features.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 3,
      "context" : "Our proposed technique includes the face detection technique based on the set of 49 fiducial landmark points detected by the Chehra [4] face detector.",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 4,
      "context" : "[5].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 24,
      "context" : "A multiple kernel learning (MKL) algorithm based on sparse representation-based classification (SRC) proposed in [25], represents the non-linearities in the highdimensional feature space based on kernel alignment criteria.",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 15,
      "context" : "Conic combinations of kernel matrices for classification proposed in [16] leads to a convex quadratically constrained quadratic problem (QCQP).",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 25,
      "context" : "[26] generalized the formulation to a larger class of problem.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 26,
      "context" : "The work proposed in [27] performs domain adaptation based on the calculation of the weights of the instances in the source domain.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 34,
      "context" : "[35] proposed a method to effectively retrain a pre-trained SVM for target domain data, based on the calculated weights of the instances in the source domain.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 8,
      "context" : "[9] proposed a domain adaptive machine (DAM), which learns a robust decision function for labeling the instances in the target domain, by leveraging a set of base classifiers learned on multiple source domains.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 17,
      "context" : "Tranfer component analysis (TCA), proposed in [18], minimizes the disparity of distribution by comparing the difference in the means between two domains and preserving",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 9,
      "context" : "Subspaces are calculated based on eigen-vectors [10] of two domains, such that the basis vectors of the of the transformed source and target domains are aligned.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 31,
      "context" : "[32] considered the manifold of each domain and estimated a latent space, where the manifolds of both the domains are similar to each other.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 22,
      "context" : "[23] using the properties of the of the sub-spaces spanning the source and target domains, when projected along a path in the Grassmannian manifold.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 7,
      "context" : "[8], known as multi-dimensional scaling (MDS).",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 20,
      "context" : "[21] proposed the Coupled Kernel Embedding approach, where they map the low and high resolution face images onto different kernel spaces and then transform them to a subspace for recognition.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "in [22] proposed an approach with the combination of partial restoration (using super-resolution) of probe samples and degradation of gallery samples.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 21,
      "context" : "An outdoor surveillance dataset, FR_SURV, was also proposed in [22], for evaluating their approach.",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 1,
      "context" : "[2] to integrate the information from all the three cameras in the ChokePoint [33] dataset.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 32,
      "context" : "[2] to integrate the information from all the three cameras in the ChokePoint [33] dataset.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 5,
      "context" : "The work proposed in [6] aims to bridge the gap of resolution and contrast using superresolution and contrast stretching on the probe samples and degrading the gallery samples.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 3,
      "context" : "The Face detection stage is based on the 49 fiducial points obtained from the Chehra [4] face detector, to obtain a tightly cropped facial region.",
      "startOffset" : 85,
      "endOffset" : 88
    }, {
      "referenceID" : 5,
      "context" : "pre-processing are the same as described in [6].",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 5,
      "context" : "The empirical values of the parameters in the pre-processing algorithms (see [6] for details) are: the Gaussian blur kernel, σ, for degradation of the gallery; and γ used for contrast enhancement of the probes, are given in table 1, for the three datasets used for performance analysis.",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 5,
      "context" : "For details see [6].",
      "startOffset" : 16,
      "endOffset" : 19
    }, {
      "referenceID" : 21,
      "context" : "FR_SURV [22] 1.",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 13,
      "context" : "SCFace [14] 1.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 32,
      "context" : "50 ChokePoint [33] 1.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 3,
      "context" : "Example shots from the three datasets (one sample each), showing the degraded gallery and the enhanced probe images on the cropped faces provided by Chehra [4].",
      "startOffset" : 156,
      "endOffset" : 159
    }, {
      "referenceID" : 28,
      "context" : ", Eigenfaces [29], Fisherfaces [7], Weberfaces [31], Local binary pattern (LBP) [1], Gaborfaces [17], Bag-of-words (BOW) [11], Fisher vector encoding on dense-SIFT features (FV-SIFT) [20] and VLAD encoding on dense-SIFT features (VLAD-SIFT) [3].",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 6,
      "context" : ", Eigenfaces [29], Fisherfaces [7], Weberfaces [31], Local binary pattern (LBP) [1], Gaborfaces [17], Bag-of-words (BOW) [11], Fisher vector encoding on dense-SIFT features (FV-SIFT) [20] and VLAD encoding on dense-SIFT features (VLAD-SIFT) [3].",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 30,
      "context" : ", Eigenfaces [29], Fisherfaces [7], Weberfaces [31], Local binary pattern (LBP) [1], Gaborfaces [17], Bag-of-words (BOW) [11], Fisher vector encoding on dense-SIFT features (FV-SIFT) [20] and VLAD encoding on dense-SIFT features (VLAD-SIFT) [3].",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 0,
      "context" : ", Eigenfaces [29], Fisherfaces [7], Weberfaces [31], Local binary pattern (LBP) [1], Gaborfaces [17], Bag-of-words (BOW) [11], Fisher vector encoding on dense-SIFT features (FV-SIFT) [20] and VLAD encoding on dense-SIFT features (VLAD-SIFT) [3].",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 16,
      "context" : ", Eigenfaces [29], Fisherfaces [7], Weberfaces [31], Local binary pattern (LBP) [1], Gaborfaces [17], Bag-of-words (BOW) [11], Fisher vector encoding on dense-SIFT features (FV-SIFT) [20] and VLAD encoding on dense-SIFT features (VLAD-SIFT) [3].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 10,
      "context" : ", Eigenfaces [29], Fisherfaces [7], Weberfaces [31], Local binary pattern (LBP) [1], Gaborfaces [17], Bag-of-words (BOW) [11], Fisher vector encoding on dense-SIFT features (FV-SIFT) [20] and VLAD encoding on dense-SIFT features (VLAD-SIFT) [3].",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 19,
      "context" : ", Eigenfaces [29], Fisherfaces [7], Weberfaces [31], Local binary pattern (LBP) [1], Gaborfaces [17], Bag-of-words (BOW) [11], Fisher vector encoding on dense-SIFT features (FV-SIFT) [20] and VLAD encoding on dense-SIFT features (VLAD-SIFT) [3].",
      "startOffset" : 183,
      "endOffset" : 187
    }, {
      "referenceID" : 2,
      "context" : ", Eigenfaces [29], Fisherfaces [7], Weberfaces [31], Local binary pattern (LBP) [1], Gaborfaces [17], Bag-of-words (BOW) [11], Fisher vector encoding on dense-SIFT features (FV-SIFT) [20] and VLAD encoding on dense-SIFT features (VLAD-SIFT) [3].",
      "startOffset" : 241,
      "endOffset" : 244
    }, {
      "referenceID" : 11,
      "context" : ", C from the features and training set is called the feature combination problem [12].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 11,
      "context" : "We have used the block-wise coordinate-descent based approach to solve the problem of minimisation given in equation 1 (see [12], for proof of convexity), as proposed by Xu et al.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 33,
      "context" : "[34], to obtain the local mimimas, ~ β .",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "in [15].",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 21,
      "context" : "For experimentation purpose, we have used three realworld surveillance face datasets, namely, FR_SURV [22], SCFace [14] and ChokePoint [33].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 13,
      "context" : "For experimentation purpose, we have used three realworld surveillance face datasets, namely, FR_SURV [22], SCFace [14] and ChokePoint [33].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 32,
      "context" : "For experimentation purpose, we have used three realworld surveillance face datasets, namely, FR_SURV [22], SCFace [14] and ChokePoint [33].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 21,
      "context" : "For FR_SURV dataset [22], the gallery and probe samples consists cropped face regions at an average of 150 × 150 pixels and 33 × 33 pixels respectively for 51 subjects with 20 samples per class.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 13,
      "context" : "The SCFace dataset [14] has a huge collection of static images of 130 different subjects.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 32,
      "context" : "The ChokePoint dataset [33] consists of 25 subjects (19 males and 6 females) in portal 1 and 29 subjects (23 males and 6 females) in portal 2.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 13,
      "context" : "Rigorous experimentations have been carried on three real-world datasets; SCface [14], FR_SURV [22], and ChokePoint [33].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 21,
      "context" : "Rigorous experimentations have been carried on three real-world datasets; SCface [14], FR_SURV [22], and ChokePoint [33].",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 32,
      "context" : "Rigorous experimentations have been carried on three real-world datasets; SCface [14], FR_SURV [22], and ChokePoint [33].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 13,
      "context" : "Algorithm SCface [14] FR_SURV [22] ChokePoint [33] 1 EDA1 [6] 47.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 21,
      "context" : "Algorithm SCface [14] FR_SURV [22] ChokePoint [33] 1 EDA1 [6] 47.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 32,
      "context" : "Algorithm SCface [14] FR_SURV [22] ChokePoint [33] 1 EDA1 [6] 47.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 5,
      "context" : "Algorithm SCface [14] FR_SURV [22] ChokePoint [33] 1 EDA1 [6] 47.",
      "startOffset" : 58,
      "endOffset" : 61
    }, {
      "referenceID" : 21,
      "context" : "2 COMP_DEG [22] 4.",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 7,
      "context" : "3 MDS [8] 42.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 5,
      "context" : "4 KDA1 [6] 35.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 12,
      "context" : "5 Gopalan [13] 2.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 26,
      "context" : "6 Kliep [27] 37.",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 18,
      "context" : "7 Deep Face [19] 41.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 5,
      "context" : "[6], DA processing was based on an eigenvector based transformation, whose extension to RKHS is termed as KDA1, in which case the performances on the SCFace [14] and FR_SURV [22] are comparable; since the non-linearity in the transformation provided by DA technique in RKHS helps to obtain a slightly better result for FR_SURV compared to that in SCFace.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 13,
      "context" : "[6], DA processing was based on an eigenvector based transformation, whose extension to RKHS is termed as KDA1, in which case the performances on the SCFace [14] and FR_SURV [22] are comparable; since the non-linearity in the transformation provided by DA technique in RKHS helps to obtain a slightly better result for FR_SURV compared to that in SCFace.",
      "startOffset" : 157,
      "endOffset" : 161
    }, {
      "referenceID" : 21,
      "context" : "[6], DA processing was based on an eigenvector based transformation, whose extension to RKHS is termed as KDA1, in which case the performances on the SCFace [14] and FR_SURV [22] are comparable; since the non-linearity in the transformation provided by DA technique in RKHS helps to obtain a slightly better result for FR_SURV compared to that in SCFace.",
      "startOffset" : 174,
      "endOffset" : 178
    }, {
      "referenceID" : 21,
      "context" : "[22] (COMP_DEG) tries to bridge the gap between the gallery and the probe samples by projecting them both into a lower dimensional subspace determined by the principal components of the feature vectors obtained from the test set (probes).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "This paper also acts as the primary source for the dataset, FR_SURV [22], where an algorithm (overtuned for degradation in the dataset) is proposed to solve the problem of face recognition under surveillance in an outdoor scenario for specific source and target sensors.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 7,
      "context" : "in [8] (near implementation to the best of our knowledge) projects both the gallery and the probe samples into a common subspace for classification.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 12,
      "context" : "[13] and Kliep [27] are two DA based techniques used for object classification across domains (codes borrowed from authors).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 26,
      "context" : "[13] and Kliep [27] are two DA based techniques used for object classification across domains (codes borrowed from authors).",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 2,
      "context" : "This particular (BaseMKL) method, uses VLAD-SIFT [3] exclusively as the feature extracted from the face images, and then the optimal kernel is obtained using MKL [5].",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 4,
      "context" : "This particular (BaseMKL) method, uses VLAD-SIFT [3] exclusively as the feature extracted from the face images, and then the optimal kernel is obtained using MKL [5].",
      "startOffset" : 162,
      "endOffset" : 165
    }, {
      "referenceID" : 18,
      "context" : "[19], using the architecture of convolutional",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "ROC plots for performance analysis on: (a) FR_SURV [22], (b) SCFace [14] and (c) ChokePoint [33] datasets.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 13,
      "context" : "ROC plots for performance analysis on: (a) FR_SURV [22], (b) SCFace [14] and (c) ChokePoint [33] datasets.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 32,
      "context" : "ROC plots for performance analysis on: (a) FR_SURV [22], (b) SCFace [14] and (c) ChokePoint [33] datasets.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 21,
      "context" : "CMC plots for performance analysis on: (a) FR_SURV [22], (b) SCFace [14] and (c) ChokePoint [33] datasets.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 13,
      "context" : "CMC plots for performance analysis on: (a) FR_SURV [22], (b) SCFace [14] and (c) ChokePoint [33] datasets.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 32,
      "context" : "CMC plots for performance analysis on: (a) FR_SURV [22], (b) SCFace [14] and (c) ChokePoint [33] datasets.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 21,
      "context" : "FR_SURV [22] 5 per subject, from 20 random subjects SCFace [14] 3 per subject, from 30 random subjects",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 13,
      "context" : "FR_SURV [22] 5 per subject, from 20 random subjects SCFace [14] 3 per subject, from 30 random subjects",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 32,
      "context" : "ChokePoint [33] 6 per subject, from 5 males and 2 females per profile",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 12,
      "context" : "[13] performs generally the worst.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "Algorithm # CNN Layers FR _SURV [22] SCface [14] Choke Point [33]",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 13,
      "context" : "Algorithm # CNN Layers FR _SURV [22] SCface [14] Choke Point [33]",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 32,
      "context" : "Algorithm # CNN Layers FR _SURV [22] SCface [14] Choke Point [33]",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 5,
      "context" : "1 FV Faces + AlexNet [6] 8 12.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 18,
      "context" : "2 DeepFace [19] 19 29.",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 27,
      "context" : "3 DeepID2,2+,3 [28] 60 34.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 23,
      "context" : "4 FaceNet + Alignment [24] 22 36.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 18,
      "context" : "5 VGG Face Descriptor + DeepFace [19] 19 32.",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 18,
      "context" : "The recent state-of-the-art technique of deep learning [19] also fails to perform well for FR under surveillance scenarios, which otherwise have boosted the accuracy of FR in the recent past.",
      "startOffset" : 55,
      "endOffset" : 59
    } ],
    "year" : 2016,
    "abstractText" : "Face recognition (FR) is the most preferred mode for biometric-based surveillance, due to its passive nature of detecting subjects, amongst all different types of biometric traits. FR under surveillance scenario does not give satisfactory performance due to low contrast, noise and poor illumination conditions on probes, as compared to the training samples. A state-of-the-art technology, Deep Learning, even fails to perform well in these scenarios. We propose a novel soft-margin based learning method for multiple feature-kernel combinations, followed by feature transformed using Domain Adaptation, which outperforms many recent state-of-the-art techniques, when tested using three real-world surveillance face datasets.",
    "creator" : "LaTeX with hyperref package"
  }
}