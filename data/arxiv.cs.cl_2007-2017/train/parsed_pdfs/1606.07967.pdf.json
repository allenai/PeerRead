{
  "name" : "1606.07967.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "LEVERAGING SEMANTIC WEB SEARCH AND BROWSE SESSIONS FOR MULTI-TURN SPOKEN DIALOG SYSTEMS",
    "authors" : [ "Lu Wang", "Larry Heck", "Dilek Hakkani-Tür" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Index Terms— spoken dialog systems, statistical dialog management, multi-turn contextual model, dialog session, web search session, web browsing, entity extraction, relation extraction\n1. INTRODUCTION\nStatistical machine learning approaches for spoken dialog systems (SDS) have become popular in the last decade. However, an important problem that limits their practical application is the significant amount of annotated data that is required for training models in SDS [1]. This is particularly true for the dialog manager (DM) component, where the number of possible dialog state sequences is extremely high and difficult to enumerate. Hence scaling SDS approaches to handle even moderately complex dialog models is a key research problem.\nA simple approach to solve this problem relies on a flat initialization; as the system is used, training data is obtained from real users and annotated to train better dialog models. However, such a bootstrapped statistical model is not desirable for real-world SDS as the initial user experience is poor and limited. In addition, the subsequent learning is biased towards simplified interactions, since these are the only dialogs that yield success for the user.\nA more common solution is to exploit a small set of real user interactions to perform dialog simulations. With this approach, one can obtain a large set of artificial dialogs [2, 3, 4, 5]. Though simple to implement, the generated dialogs are typically not natural, and do not provide the opportunity for the system to learn the best ways to complete tasks from users. It may result in an SDS that leads a user through inefficient and occasionally non-sensical paths, causing user frustration and ultimately poor adoption rates [6]. Leveraging web search log to SDS. Nonetheless, large volumes of task-oriented and potentially relevant training data exist in web\nsearch engines. Users complete tasks everyday on the web, using a combination of search and browsing. The volume of the search data easily exceeds 100M queries per day over hundreds of millions of users. The breadth of tasks is also immense, ranging from simple (weather, finding directions, local events) to more complex (shopping, planning a trip, planning a night out).\nIn many ways, search and browsing have elements of automated conversational interactions. Figure 1 displays one fragment of web search session, and one fragment of an spoken dialog (conversational) session. We can see that the two sessions share similar browsing patterns (in blue) in terms of the entity types visited. Web search conversations are also interactive because the system responds to what has previously been communicated. The conversations are spontaneous as the user is not constrained by domain.\nThe advantage of using web data is the massive volume of interactions, with both depth in the number and complexity of user interactions and breadth in the variety of user goals. Some of the user’s actions (e.g., clicks) further provide enough constraints so that the labels (domains, intents, slots) can be inferred, enabling weakly supervised training. The observation thus inspires us to leverage the large volumes of logged user interactions that exist in centrally hosted web search engines and browsers to the SDS systems.\nIn this work, we take a first step to effectively exploit this source of training data for an SDS problem – entity extraction from the spoken dialogs. Session-based model for semantic parsing in SDS. Existing work\nar X\niv :1\n60 6.\n07 96\n7v 1\n[ cs\n.C L\n] 2\n5 Ju\nn 20\n16\nfor leveraging web search behavior to SDS mainly exploits offline information in the query-click logs. For instance, the web query-click graph has been employed for domain detection [7], slot filling [8], and intent detection [9]. Recently, the idea of combining the power of internet browser and multi-modal input (e.g. speech, gesture, etc) is discussed in [10] and implemented by [11]. Different from all of the work above, our session models are directly trained on the web search sessions with contextual information from the search logs. We then test the models on entity extraction problem for SDS with the acquired behaviorial patterns from web and multi-turn conversational context. Authors in [12] also try to leverage contextual information for the same task, however, they do not exploit web data. Distant supervision for query interpretation. In addition, we investigate a domain-independent framework that utilizes a structured semantic knowledge base of large scale to provide distant supervision. Modern systems of entity and relation extraction from web search queries are mostly based on supervised learning with small hand-labeled corpora, and are thus limited by the availability of training data [13]. Weakly-supervised approaches are also studied [14, 15], where seed instances are utilized for boostrap learning. Noisy extractions, with semantic shift, are hard to avoid.\nWith the emergence of large scale knowledge resources (e.g. Freebase, DBPedia), distant supervision has been proposed for relation extraction on formal text, such as Wikipedia articles [16], and news articles [17]. It is also investigated in [18, 19] for utilizing web search results to improve the relation extraction performance in SDS. In this work, we employ distant supervision to generate training samples based on web search queries instead of web pages returned by search engine. We also test entity extraction and relation extraction tasks on both spoken utterances and web search queries. Contributions. To the best of our knowledge, we are the first to exploit web search sessions and their contextual information and adapt it to train statistical dialog managers. Our experiments conducted in the film domain show that our session-based models trained on web search log are capable to leverage multi-turn context to produce significantly better entity extraction performance than the state-ofthe-art approach [20] in SDS.\nFurthermore, to address the issue of lack of training data, we propose a distantly supervised approach to semantic parsing, by employing massive unlabeled web search logs combined with large dictionaries of entities and relations gathered from knowledge bases. We train linear-chain Conditional Random Fields [21] and its variant learned on data with missing labels [22] to model web browsing behavior on session level. Our models achieve better results than nontrivial baselines on entity extraction and relation extraction for both spoken dialogs and web search query. Notice that with knowledge base as supervision, entities extracted by our models are beyond named entity slots used in conventional SDS. We are also able to find unnamed categories, such as film subject and descriptions.\n2. THE QUERY INTERPRETATION MODEL\nInvestigations from [13] discover that three templates (or types) of queries dominate entity-based web search (i.e. more than 65% of the sampled queries fall in these three types). The three templates can be formalized as: Entity (E), which contains one entity; Type u Relation(Entity) (T-R-E), which describes one entity and another entity type with a certain relation; Entity0 u Relation(Entity1) (E-R-E), which consists of a pair of related entities. In spoken dialog corpora studied in this work, we also observe more than 50% of utterances can be matched to those templates, where 54% of them belong to template E. For instance, in\nFigure 1, query “search for the great gatsby” (U2) falls into template E as it has a single film entity. Query “show me movies by leonardo dicaprio” (U4) matches template T-R-E where “movies” indicates the film type and “leonardo dicaprio” is an actor entity. A sample query for E-R-E could be “Titanic by James Cameron”.\nFor the remaining part of the section, we describe our full query interpretation pipeline, consisting of Entity Mention Identification, Entity Type Determination, and Relation Extraction."
    }, {
      "heading" : "2.1. Entity Mention Identification",
      "text" : "We first employ a linear-chain Conditional Random Fields (CRF) [21] to identify all the entity mentions in each query. We represent each query as a sequence of tokens, x = x0x1 . . . xn, and generate a sequence of labels, y = y0y1 . . . yn, that encode which tokens are part of entity mentions by using a BIO label format: {B-ENT (beginning of an entity), I-ENT (inside of an entity), O (outside of any entity)}. As defined in [21], the conditional probability is given by:\nP (y|x) = 1 Z(x) exp( ∑T t=1 ∑K k=1 λkfk(yt−1, yt, x, t))\nwhere T is the length of the sequence, K is the number of feature functions fk, and λk are the corresponding weights. Feature Design. We utilize lexical features such as word in lowercase, is capitalized, has any number, and has any non-alphabetic character. For syntactic features, POS tag, NER tag, and dependency relation output by Stanford parser [23] are used. We also consider context features within the session. Figure 1 shows that “leonardo dicaprio” is mentioned twice in T3 and T8. Intuitively, if an ngram appears repeatedly in the queries, it is likely to be an entity mention. Thus, we use repeat time to indicate if an ngram is repeated more than twice in recent 5 issued queries within the session.\nIn addition, we collect gazetteers from Freebase (http: //www.freebase.com/), and use a feature to indicate if the token is part of a term in the gazetteer. Gazetteers, which are lists of entity names or relation instances, are important features for SDS to understand users’ intent or represent dialog states. We then match each entity name in the gazetteer to the query. If there is any overlapping between two mapped names, e.g. “leonardo dicaprio” v.s. “dicaprio”, the longer one is retained.\nSuppose t represents the current token position and featurek[t] is the value of featurek, we extract unigram, bigram and trigram features over local context, e.g. featurek[t− 2], featurek[t− 2] : featurek[t−1], featurek[t−2] : featurek[t−1] : featurek[t].\n2.2. Entity Type Determination\nEntity type is determined after identifying entity mentions, e.g. whether the entity mention is an “actor” or a “film”. Instead of making prediction on each entity independent of the browsing history, we propose to use sequential labeling technique to predict entity types within a session simultaneously.\nSuppose session S consists of turns {s0, s1, · · · , sm}, where each turn si can be either a query or a web page click. Each entity mentioned in S represents a single state in our session-based entity type determination model. A click is mapped to an entity, if this\nURL is a source URL for that entity in Freebase. Figure 2 depicts a mapping from the web session in Figure 1 to our sequential model. CRF Training with Missing Labels. Linear-chain CRF as defined in Section 2.1 is utilized as the building block to predict entity types. Multiple entities in one query are considered as separate states. During training, it is possible that some turns do not contain any entity, which makes the labels partially observed for the session. We propose two ways to address this problem: 1) simply removing those turns in training; 2) training a CRF with missing labels.\nGiven a session with partial labels y =< yt0 , yt1 , · · · , ytm >, where ti is the index of an entity with observed label, and a hidden label sequence h =< hl0 , hl1 , · · · , hlm′ >, where lj is the index of an entity with latent (or unobserved) label, the conditional probability is,\nP (y|x) = ∑\nh p(y, h | x) = 1 Z(x) ∑ h exp( ∑T t=1 ∑K k=1 λkfk(yt−1, yt, x, t))\nWe adopt the direct gradient ascent procedure methods from [22] to maximize P (y|x). We omit details about parameter learning due to length limit, and refer the readers to [22] for further information. Feature Design. We use basic features such as NER tag, is capitalized, number of tokens, URL domain, and is in gazetteer. We also encode the context (i.e. ngrams and their POS tag sequence, n ≤ 3) of the entity mention as features. Likewise, unigram, bigram, trigram features are used as Section 2.1."
    }, {
      "heading" : "2.3. Relation Extraction",
      "text" : "After extracting entities from previous steps, we aim to identify queries satisfying templates T-R-E and E-R-E by using relation extraction techniques. For query with more than one entity, we predict if there exists a relation between pairwise entities (E-R-E). For entities not classified as E-R-E, we then predict if the query fits T-R-E. Specifically, for both templates, we train two multiclass logistic regression classifiers for relations based on one v.s. all strategy. Feature Design. Our features are based on standard lexical and shallow syntactic features (i.e. POS tags, dependency relations) from the literature [16]. We also consider the words and their POS tags between the entity pairs or entity-type pairs. A gazetteer feature is constructed to indicate if the sample is in Freebase. We also take the predicted entity types from previous module as features.\n3. WEB SEARCH QUERY INTERPRETATION\nWeb Search Session Log (Search Log). We collected 12 weeks of web search sessions from March 18 to June 9, 2013. The sessions consisting of query-click logs based on IE browsing history. This dataset will be called “Search log” henchforth. We choose a representative domain – film, to test our semantic parsing models. We further extract sessions that users express interests in film, i.e. sessions with page views in the domain of “www.imdb.com”, “www. fandango.com”, or “www.rottentomatoes.com”. This results in 297,352 sessions in total, from which 80% are randomly selected for training, with the remaining as the test set. The same tasks for other domains will be studied in the future work. Training via Distant Supervision. To construct training samples for entity extraction, we first collect a gazetteer consisting of entities in the form of names from Freebase along with their entity types. In the case that one entity has multiple types, the type having most instances in Freebase is chosen. To maintain high precision for the training set, we match entities with names longer than two words in the gazetteer to each query. Table 1 shows nearly half of the queries and URLs get matched with at least one entity.\nA gazetteer is also constructed for relation extraction. If a query contains two entities that compose a relation instance in Freebase, we assume this query expresses that relation. Those queries make up the training set for template E-R-E. For template T-R-E, a query is a positive sample when it contains entity e (e.g. “leonardo dicaprio”) and description for entity type t (e.g. “movies”), and there exists entity e′ (e.g. “Titanic”) of type t where e and e′ carry a relation.\nTable 2 lists the number of entity and relation instances matched in our training and test sets."
    }, {
      "heading" : "3.1. Pilot Study: Entity-based Search Session Modeling",
      "text" : "We first carry out experiments to validate our session assumption, i.e. current search behavior depends on the searching history. Formally, in our entity-based session modeling, a search session S is represented by a sequence of entities e0, e1, · · · , el, as described in Section 2.2. We compute the likelihood of the sessions based on Markov models with different history, where higher order model considers longer history. The likelihood of session S is expressed as the product of the entities that compose S, with each entity probability conditional on the previous n− 1 entities (i.e. order-n): P (S) =∏l\ni=1 P (ei|e i−1 i−n+1), where e j i denotes the sequence ei, ..., ej .\nMaximum likelihood estimation can be used to get PML(ei|ei−1i−n+1)\nas c(e i i−n+1)\nc(ei−1i−n+1) , where c(α) indicates the frequency of entity sequence α occurs. We also experiment with two smoothing techniques: additive smoothing and linear interpolation [24]. Due to space limit, we refer the readers to [24] for details. To handle unknown entities in test set, we replace the first appearance of each entity with label “<Unk>” during training. Unknown entities are also substituted with “<Unk>” during test.\nGiven test set T = {Si}, where Si represents a session, we take the performance of each model as its cross-entropy [24] on T , i.e. 1 N ∑|T | i=1−logP (Si), with N as the total number of entities.\nWe train each model on sessions collected from May 13, 2013 to May 19, 2013, and test on sessions of June 17, 2013 to June 23, 2013. We reserve 10% of the training data as development set to tune the parameters. Results in Figure 3 show that Markov models considering longer search history produce better performance (i.e. with lower cross-entropy), which confirms our session assumption."
    }, {
      "heading" : "3.2. Results: Entity and Relation Extraction",
      "text" : "Due to the large size of the test data, we automatically acquire labels by matching queries and entities with names longer than two words in gazetteer. The resulting labels are taken as the gold standard for evaluation. Because some predictions from our classifier are outside\nthe gazetteer, which makes the precision underestimated, we only report recalls for measuring how many entities or relations are retrieved by the models. In the test phase, we assume our models only have access to the part of the gazetteer observed in training. Comparisons. We compare with 1) two baselines, and 2) a linear-CRF that predicts the entity spans and their types simultaneously [13]. Baseline 1 (Gazetteer Only) is constructed by matching the entities in gazetteer to the queries, where longest matching is selected if one token is mapped to multiple entities. For Baseline 2 (No Session), we follow [25] to construct a multiclass Maximum Entropy classifier with one v.s. all strategy. Discussion. Table 5 shows that our two session-based models both significantly (p < 0.01) outperform the two strong baselines under a paired-t test. Our model based on CRF trained with missing labels also produces better performance than all the compared methods1.\n1We do not correct the spelling errors in the queries.\nFor relation extraction, we also compare with the baseline formulated by matching query to relation instances in the gazetteer. Table 3 presents the results for discovering relation instances for templates E-R-E and T-R-E, where our model outperforms the baseline."
    }, {
      "heading" : "4. ENTITY EXTRACTION IN SPOKEN DIALOG SYSTEMS",
      "text" : "SDS Corpora. To show how our models effectively leverage web search logs for entity extraction in SDS, two corpora are collected internally from real-use scenarios of two SDS, where the users interact with a system by voice and gesture to perform tasks like browsing the internet, searching, querying, and playing. The first conversational browsing dataset is constructed for various domains, and is called CB Data henceforth. The other dataset is designed for a natural language film search application based on Netflix (Netflix Data). As our models are trained on web search log in the film domain, we test them on the sessions of film-related tasks with manual transcripts. Specifically, we retain sessions annotated with entities in the film domain. In total, we have 6691 utterances from 136 sessions from CB; 13851 utterances from 1895 sessions from Netflix. We thus identify the entities and their types on utterance level. Comparisons. We use the gazetteer collected from Section 3 to construct the same baselines (i.e. Baseline 1 (Gazetteer Only), and Baseline 2 (No Session)). In addition, we compare with the state-ofthe-art approach designed for the same task in dialog management from [20], where they elicit training data from Wikipedia articles instead of web queries. They employ a linear-chain CRF to predict entities spans and their types simultaneously. Discussion. Table 4 demonstrates that our session-based models trained on web search logs outperform two nontrivial baselines and the state-of-the-art method in most entity types on spoken dialogs. This shows that our session-based models is able to effectively leverage the behavioral patterns mined from web search log and multiturn context to improve the entity extraction performance in spoken dialog systems. The performance on genre detection is relatively low. This may due to the different context people use for genres. For example, “Disney” is a genre in “Disney movie”, but is a place name in “Disney world”. Coreference resolution is not addressed in this work, but we believe it could further improve the performance.\n5. CONCLUSION\nIn conclusion, we present a full pipeline to leverage semantic web search and browse sessions for a semantic parsing problem in multiturn spoken dialog systems. Our models are able to apply the learned behaviorial browsing patterns from web seach logs to develop spoken dialog systems. With distant supervision technique, our models achieves better performance than nontrivial baselines and the stateof-the-art methods on both web search queries and spoken dialogs on tasks of entity and relation extraction."
    } ],
    "references" : [ {
      "title" : "Spoken Language Understanding - Systems for Extracting Semantic Information from Speech, chapter SLU in Commercial and Research Spoken Dialog",
      "author" : [ "David Suendermann", "Roberto Pieraccini" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2011
    }, {
      "title" : "Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning",
      "author" : [ "Konrad Scheffler", "Steve Young" ],
      "venue" : "Proceedings of the second international conference on Human Language Technology Research, San Francisco, CA, USA, 2002, HLT ’02, pp. 12–19, Morgan Kaufmann Publishers Inc.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Partially observable markov decision processes for spoken dialog systems",
      "author" : [ "Jason D. Williams", "Steve Young" ],
      "venue" : "Comput. Speech Lang., vol. 21, no. 2, pp. 393–422, Apr. 2007.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Machine learning for spoken dialogue systems",
      "author" : [ "Oliver Lemon", "Olivier Pietquin" ],
      "venue" : "In Proceedings of the European Conference on Speech Communication and Technologies (Interspeech07), Anvers, 2007.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "A statistical dialog manager for the luna project",
      "author" : [ "David Griol", "Giuseppe Riccardi", "Emilio Sanchis" ],
      "venue" : "INTERSPEECH. 2009, pp. 272–275, ISCA.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Recent research advances in reinforcement learning in spoken dialogue systems",
      "author" : [ "Matthew Frampton", "Oliver Lemon" ],
      "venue" : "Knowledge Eng. Review, vol. 24, no. 4, pp. 375–408, 2009.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Employing web search query click logs for multidomain spoken language understanding",
      "author" : [ "Dilek Hakkani-Tur", "Gokhan Tur", "Larry Heck", "Asli Celikyilmaz", "Ashley Fidler", "Dustin Hillard", "Rukmini Iyer", "Sarangarajan Parthasarathy" ],
      "venue" : "IEEE Automatic Speech Recognition and Understanding Workshop, 2011.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Towards unsupervised spoken language understanding: Exploiting query click logs for slot filling",
      "author" : [ "Gukhan Tur", "Dilek Z. Hakkani-Tur", "Dustin Hillard", "Asli elikyilmaz" ],
      "venue" : "INTER- SPEECH. 2011, pp. 1293–1296, ISCA.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Exploiting the semantic web for unsupervised spoken language understanding",
      "author" : [ "Larry Heck", "Dilek Hakkani-Tur" ],
      "venue" : "IEEE Workshop on Spoken Language Technology, 2012.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "The conversational web",
      "author" : [ "Larry Heck" ],
      "venue" : "IEEE Workshop on Spoken Language Technology, 2012.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Multimodal conversational search and browse",
      "author" : [ "Larry Heck", "Dilek Hakkani-Tur", "Madhu Chinthakunta", "Gokhan Tur", "Rukmini Iyer", "Partha Parthasarathy", "Lisa Stifelman", "Elizabeth Shriberg", "Ashley Fidler" ],
      "venue" : "IEEE Workshop on Speech, Language and Audio in Multimedia, 2013.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Easy contextual intent prediction and slot detection",
      "author" : [ "Aditya Bhargava", "Asli Celikyilmaz", "Dilek Hakkani-Tur", "Ruhi Sarikaya" ],
      "venue" : "ICASSP. 2013, IEEE.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Interpreting keyword queries over web knowledge bases",
      "author" : [ "Jeffrey Pound", "Alexander K. Hudek", "Ihab F. Ilyas", "Grant Weddell" ],
      "venue" : "Proceedings of the 21st ACM international conference on Information and knowledge management, New York, NY, USA, 2012, CIKM ’12, pp. 305–314, ACM.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Learning dictionaries for information extraction by multi-level bootstrapping",
      "author" : [ "Ellen Riloff", "Rosie Jones" ],
      "venue" : "Menlo Park, CA, USA, 1999, AAAI ’99/IAAI ’99, pp. 474–479, American Association for Artificial Intelligence.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Weakly-supervised discovery of named entities using web search queries",
      "author" : [ "Marius Paşca" ],
      "venue" : "Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, New York, NY, USA, 2007, CIKM ’07, pp. 683–690, ACM.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Dis-  tant supervision for relation extraction without labeled data",
      "author" : [ "Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky" ],
      "venue" : "Stroudsburg, PA, USA, 2009, ACL ’09, pp. 1003–1011, Association for Computational Linguistics.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Collective cross-document relation extraction without labelled data",
      "author" : [ "Limin Yao", "Sebastian Riedel", "Andrew McCallum" ],
      "venue" : "Stroudsburg, PA, USA, 2010, EMNLP ’10, pp. 1013–1023, Association for Computational Linguistics.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Exploiting the semantic web for unsupervised natural language semantic parsing",
      "author" : [ "Gokhan Tur", "Minwoo Jeong", "Ye-Yi Wang", "Dilek Hakkani-Tur", "Larry Heck" ],
      "venue" : "Proceedings of Interspeech, 2012.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Using a knowledge graph and query click logs for unsupervised learning of relation detection",
      "author" : [ "Dilek Hakkani-Tur", "Larry P. Heck", "Gokhan Tur" ],
      "venue" : "ICASSP. 2013, IEEE.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Leveraging knowledge graphs for web-scale unsupervised semantic parsing",
      "author" : [ "Larry Heck", "Dilek Hakkani-Tur", "Gokhan Tur" ],
      "venue" : "Proceedings of Interspeech, 2013.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira" ],
      "venue" : "Proceedings of the Eighteenth International Conference on Machine Learning, San Francisco, CA, USA, 2001, ICML ’01, pp. 282–289, Morgan Kaufmann Publishers Inc.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Learning Extractors from Unlabeled Text using Relevant Databases",
      "author" : [ "Kedar Bellare", "Andrew Mccallum" ],
      "venue" : "Sixth International Workshop on Information Integration on the Web (IIWeb), 2007.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Accurate unlexicalized parsing",
      "author" : [ "Dan Klein", "Christopher D. Manning" ],
      "venue" : "Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, Stroudsburg, PA, USA, 2003, ACL ’03, pp. 423–430, Association for Computational Linguistics.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "An empirical study of smoothing techniques for language modeling",
      "author" : [ "Stanley F. Chen", "Joshua Goodman" ],
      "venue" : "Stroudsburg, PA, USA, 1996, ACL ’96, pp. 310–318, Association for Computational Linguistics.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Language independent ner using a maximum entropy tagger",
      "author" : [ "James R. Curran", "Stephen Clark" ],
      "venue" : "Stroudsburg, PA, USA, 2003, CONLL ’03, pp. 164–167, Association for Computational Linguistics.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "However, an important problem that limits their practical application is the significant amount of annotated data that is required for training models in SDS [1].",
      "startOffset" : 158,
      "endOffset" : 161
    }, {
      "referenceID" : 1,
      "context" : "With this approach, one can obtain a large set of artificial dialogs [2, 3, 4, 5].",
      "startOffset" : 69,
      "endOffset" : 81
    }, {
      "referenceID" : 2,
      "context" : "With this approach, one can obtain a large set of artificial dialogs [2, 3, 4, 5].",
      "startOffset" : 69,
      "endOffset" : 81
    }, {
      "referenceID" : 3,
      "context" : "With this approach, one can obtain a large set of artificial dialogs [2, 3, 4, 5].",
      "startOffset" : 69,
      "endOffset" : 81
    }, {
      "referenceID" : 4,
      "context" : "With this approach, one can obtain a large set of artificial dialogs [2, 3, 4, 5].",
      "startOffset" : 69,
      "endOffset" : 81
    }, {
      "referenceID" : 5,
      "context" : "It may result in an SDS that leads a user through inefficient and occasionally non-sensical paths, causing user frustration and ultimately poor adoption rates [6].",
      "startOffset" : 159,
      "endOffset" : 162
    }, {
      "referenceID" : 6,
      "context" : "For instance, the web query-click graph has been employed for domain detection [7], slot filling [8], and intent detection [9].",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 7,
      "context" : "For instance, the web query-click graph has been employed for domain detection [7], slot filling [8], and intent detection [9].",
      "startOffset" : 97,
      "endOffset" : 100
    }, {
      "referenceID" : 8,
      "context" : "For instance, the web query-click graph has been employed for domain detection [7], slot filling [8], and intent detection [9].",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 9,
      "context" : "speech, gesture, etc) is discussed in [10] and implemented by [11].",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 10,
      "context" : "speech, gesture, etc) is discussed in [10] and implemented by [11].",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 11,
      "context" : "Authors in [12] also try to leverage contextual information for the same task, however, they do not exploit web data.",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 12,
      "context" : "Modern systems of entity and relation extraction from web search queries are mostly based on supervised learning with small hand-labeled corpora, and are thus limited by the availability of training data [13].",
      "startOffset" : 204,
      "endOffset" : 208
    }, {
      "referenceID" : 13,
      "context" : "Weakly-supervised approaches are also studied [14, 15], where seed instances are utilized for boostrap learning.",
      "startOffset" : 46,
      "endOffset" : 54
    }, {
      "referenceID" : 14,
      "context" : "Weakly-supervised approaches are also studied [14, 15], where seed instances are utilized for boostrap learning.",
      "startOffset" : 46,
      "endOffset" : 54
    }, {
      "referenceID" : 15,
      "context" : "Freebase, DBPedia), distant supervision has been proposed for relation extraction on formal text, such as Wikipedia articles [16], and news articles [17].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 16,
      "context" : "Freebase, DBPedia), distant supervision has been proposed for relation extraction on formal text, such as Wikipedia articles [16], and news articles [17].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 17,
      "context" : "It is also investigated in [18, 19] for utilizing web search results to improve the relation extraction performance in SDS.",
      "startOffset" : 27,
      "endOffset" : 35
    }, {
      "referenceID" : 18,
      "context" : "It is also investigated in [18, 19] for utilizing web search results to improve the relation extraction performance in SDS.",
      "startOffset" : 27,
      "endOffset" : 35
    }, {
      "referenceID" : 19,
      "context" : "Our experiments conducted in the film domain show that our session-based models trained on web search log are capable to leverage multi-turn context to produce significantly better entity extraction performance than the state-ofthe-art approach [20] in SDS.",
      "startOffset" : 245,
      "endOffset" : 249
    }, {
      "referenceID" : 20,
      "context" : "We train linear-chain Conditional Random Fields [21] and its variant learned on data with missing labels [22] to model web browsing behavior on session level.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 21,
      "context" : "We train linear-chain Conditional Random Fields [21] and its variant learned on data with missing labels [22] to model web browsing behavior on session level.",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 12,
      "context" : "Investigations from [13] discover that three templates (or types) of queries dominate entity-based web search (i.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 20,
      "context" : "We first employ a linear-chain Conditional Random Fields (CRF) [21] to identify all the entity mentions in each query.",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 20,
      "context" : "As defined in [21], the conditional probability is given by:",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 22,
      "context" : "For syntactic features, POS tag, NER tag, and dependency relation output by Stanford parser [23] are used.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 21,
      "context" : "We adopt the direct gradient ascent procedure methods from [22] to maximize P (y|x).",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 21,
      "context" : "We omit details about parameter learning due to length limit, and refer the readers to [22] for further information.",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 15,
      "context" : "POS tags, dependency relations) from the literature [16].",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 23,
      "context" : "We also experiment with two smoothing techniques: additive smoothing and linear interpolation [24].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 23,
      "context" : "Due to space limit, we refer the readers to [24] for details.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 23,
      "context" : "Given test set T = {Si}, where Si represents a session, we take the performance of each model as its cross-entropy [24] on T , i.",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 19,
      "context" : "[20] - 71.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[20] are in bold.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "We compare with 1) two baselines, and 2) a linear-CRF that predicts the entity spans and their types simultaneously [13].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 24,
      "context" : "For Baseline 2 (No Session), we follow [25] to construct a multiclass Maximum Entropy classifier with one v.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 19,
      "context" : "In addition, we compare with the state-ofthe-art approach designed for the same task in dialog management from [20], where they elicit training data from Wikipedia articles instead of web queries.",
      "startOffset" : 111,
      "endOffset" : 115
    } ],
    "year" : 2016,
    "abstractText" : "Training statistical dialog models in spoken dialog systems (SDS) requires large amounts of annotated data. The lack of scalable methods for data mining and annotation poses a significant hurdle for state-ofthe-art statistical dialog managers. This paper presents an approach that directly leverage billions of web search and browse sessions to overcome this hurdle. The key insight is that task completion through web search and browse sessions is (a) predictable and (b) generalizes to spoken dialog task completion. The new method automatically mines behavioral search and browse patterns from web logs and translates them into spoken dialog models. We experiment with naturally occurring spoken dialogs and large scale web logs. Our session-based models outperform the state-of-the-art method for entity extraction task in SDS. We also achieve better performance for both entity and relation extraction on web search queries when compared with nontrivial baselines.",
    "creator" : "LaTeX with hyperref package"
  }
}