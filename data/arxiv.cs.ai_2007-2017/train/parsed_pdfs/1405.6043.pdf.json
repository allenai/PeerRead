{
  "name" : "1405.6043.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Understanding model counting for β-acyclic CNF-formulas",
    "authors" : [ "Johann Brault-Baron", "Florent Capelli", "Stefan Mengel" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n40 5.\n60 43\nv1 [\ncs .C\nC ]\n2 3\nM ay\n2 01\n4\nUnderstanding model counting for β-acyclic\nCNF-formulas\nJohann Brault-Baron∗ Florent Capelli† Stefan Mengel‡\nMay 26, 2014\nWe extend the knowledge about so-called structural restrictions of #SAT by giving a polynomial time algorithm for β-acyclic #SAT. In contrast to previous algorithms in the area, our algorithm does not proceed by dynamic programming but works along an elimination order, solving a weighted version of constraint satisfaction. Moreover, we give evidence that this deviation from more standard algorithm is not a coincidence, but that there is likely no dynamic programming algorithm of the usual style for β-acyclic #SAT."
    }, {
      "heading" : "1. Introduction",
      "text" : "The propositional model counting problem #SAT is, given a CNF-formula F , to count the satisfying assignments of F . #SAT is the canonical #P-complete problem and is thus central to the area of counting complexity. Moreover, many important problems in artificial intelligence research reduce to #SAT (see e.g. [Rot96]), so there is also great interest in the problem from a practical point of view.\nUnfortunately, #SAT is computationally very hard: even for very restricted CNF-formulas, e.g. monotone 2-CNF-formulas, the problem is #P-hard and in fact even #P-hard to approximate [Rot96]. Thus the focus of research in finding tractable classes of #SAT-instances has turned to so-called structural classes, which one gets by assigning a graph or hypergraph to a CNF-formula and then restricting the class of (hyper)graphs considered. The general idea is that if the (hyper)graph associated to an instance has a treelike decomposition that is “nice” enough, e.g. a tree decomposition of small width, then there is a dynamic programming algorithm that solves #SAT for the instance. In the recent years, there has been a push for constructing such dynamic programming algorithms for ever more general classes of graphs and hypergraphs, see e.g. [FMR08, SS10, PSS13, SS13, CDM14].\nVery recently, Sæther, Telle and Vatshelle, in a striking contribution [STV14], have introduced a new width measure for CNF-formulas, that they call PS-width. Essentially, it is a measure for how much information has to be propagated from one step to the next in a natural formalization of the known dynamic programming algorithms. In our opinion, PS-width thus gives an upper bound on how far the dynamic programming techniques from the literature can\n∗LSV UMR 8643, ENS Cachan and Inria, France †IMJ UMR 7586 - Logique, Université Paris Diderot, France ‡LIX UMR 7161, Ecole Polytechnique, France\nbe extended. Moreover, Sæther, Telle and Vatshelle have shown that if one is given a formula F and a decomposition of small PS-width, one can efficiently count the number of satisfying assignments of F . Thus they have essentially turned the construction of dynamic programming algorithms into a question of graph theory: If, for a class of formulas, one can efficiently compute decompositions that have small PS-width for all formulas having these graphs, the dynamic programming of [STV14] solves these instances. In fact, PS-width gives a uniform explanation for all structural tractability results for #SAT from the literature that we are aware of. On the other hand, since, in our opinion, the framework of [STV14] is a very good formalization of dynamic programming, there is likely no efficient dynamic programming algorithm for a class of CNF-formulas, if it does not have decompositions of small PS-width, or if these decompositions cannot be constructed efficiently.\nIn this article, we focus on β-acyclic CNF-formulas, i.e., formulas whose associated hypergraph is β-acyclic. There are several different reasonable ways of defining acyclicity of hypergraphs that have been proposed [Fag83, Dur12], and β-acyclicity is the most general acyclicity notion discussed in the literature for which #SAT could be tractable (see the discussions in [OPS13, CDM14]). The complexity of #SAT for β-acyclic formulas is interesting for several reasons: First, up to this paper, it was the only structural class of formulas for which we know that SAT is tractable [OPS13] without this directly generalizing to a tractability result for #SAT. This is because the algorithm of [OPS13] does not proceed by dynamic programming but uses resolution, a technique that is known to generally not generalize to counting. Moreover, β-acyclicity can be generalized to a width-measure [GP04], so there is hope that a good algorithm for β-acyclic formulas might generalize to wider classes for which even the status for SAT is left as an open problem in [OPS13]. Since decomposition techniques based on hypergraph acyclicity tend to be more general than graph-based techniques [GLS00], this might lead to large, new classes of tractable #SAT-instances.\nThe contribution of this paper is twofold: First, we show that #SAT on β-acyclic hypergraphs is tractable. In fact, we show that a more general counting problem which we call weighted counting for constraint satisfaction with default values, short #CSPd, is tractable on β-acyclic hypergraphs. We remark that there is another line of research on #CSP, the counting problem related to constraint satisfaction, where dichotomy theorems for weighted #CSP depending on fixed constraint languages are proven, see e.g. [BDG+12, CC12]. We do not assume that the relations of our instances are fixed but we consider them as part of the input. Thus our results and those on fixed constraint languages are completely unrelated. Instead, the structural restrictions we consider are similar to those considered e.g. in [DJ04], but since we allow clauses, resp. relations, of unbounded arity, our results and those of [DJ04] are incomparable.\nWe note that our algorithm is in style very different from the algorithms for structural #SAT in the literature. Instead of doing dynamic programming along a decomposition, we proceed along a vertex elimination order which is more similar to the approach to SAT in [OPS13]. But in contrast to using well-understood resolution techniques, we develop from scratch a procedure to update the weights of our #CSPd instance along the elimination order. Our algorithm is non-obvious and novel, but it is relatively easy to write down and its correctness is easy to prove. Indeed most of the work in this paper is spent on showing the polynomial runtime bound which requires a thorough understanding of how the weights of instances evolve during the algorithm.\nOur second contribution is that we show that our tractability result is not covered by the framework of Sæther, Telle and Vatshelle [STV14], short STV-framework, which—as we show— covers all other known structural tractability results for #SAT. We do this by showing that β-acyclic #SAT-instances may have a PS-width so high that from [STV14] we cannot even get subexponential runtime bounds. This can be seen as an explanation for why the algorithm for\nβ-acyclic #SAT is so substantially different from the algorithms from the literature. If one accepts the framework of [STV14] as a good formalization of dynamic programming—which we do—then the deviation from the usual dynamic programming paradigm is not a coincidence but instead due to the fact that there is no efficient dynamic programming algorithm in the usual style. Thus, our algorithm indeed introduces a new algorithmic technique for #SAT that allows the solution of instances that could not be solved with techniques known before."
    }, {
      "heading" : "2. Preliminaries and notation",
      "text" : ""
    }, {
      "heading" : "2.1. Weighted counting for constraint satisfaction with default values",
      "text" : "Let D and X be two sets. DX denotes the set of functions from X to D. We think of X as a set of variables and of D as a domain, and thus we call a ∈ DX an assignment to the variables X. A partial assignment to the variables X is a mapping in DY where Y ⊆ X. If a ∈ DX and Y ⊆ X, we denote by a|Y the restriction of a onto Y . For a ∈ D\nX and b ∈ DY , we write a ∼ b if a|X∩Y = b|X∩Y and if a ∼ b, we denote by a ∪ b the mapping in D\nX∪Y with (a ∪ b)(x) = a(x) if x ∈ X and (a ∪ b)(x) = b(x) otherwise. Let a ∈ DX , y /∈ X and d ∈ D. We write a⊕y d := a ∪ {y 7→ d}.\nDefinition 1. A weighted constraint with default value c = (f, µ) on variables X and domain D is a function f : S → Q+ with S ⊆ D\nX and µ ∈ Q+. S = supp(c) is called the support of c, µ(c) = µ its default value and we denote by var(c) = X the variables of c. We define the size |c| of the constraint c to be |c| := |S| · |var(c)|. The constraint c naturally induces a total function on DX , also denoted by c, defined by c(a) = f(a) if a ∈ S and c(a) = µ otherwise.\nObserve that we do not assume var(c) to be non-empty. A constraint whose set of variables is empty has only one possible value in its support: the value associated to the empty assignment (the assignment that assigns no variable).\nSince we only consider weighted constraints with default value in this paper, we will only say weighted constraint where the default value is always implicitly understood. Note that we have to restrict ourselves to non-negative weights, because non-negativity will be crucial in the proofs. This is not a problem in our context, non-negative numbers are sufficient to encode #SAT as we will see in Section 2.3.\nDefinition 2. The problem #CSPd is the problem of computing, given a finite set I of weighted constraints on domain D, the partition function\nw(I) = ∑\na∈Dvar(I)\n∏\nc∈I\nc(a| var(c)),\nwhere var(I) := ⋃\nc∈I var(c). The size ‖I‖ of a #CSPd-instance I is defined to be ‖I‖ := ∑ c∈I |c|. Its structural size s(I)\nof I is defined to be s(I) := ∑\nc∈I |var(c)|.\nNote that the size of an instance as defined above roughly corresponds to that of an encoding in which the non-default values, i.e., the values on the support, are given by listing the support and the associated values in one table for each relation. We consider this convention as very natural and indeed it is near to the conventions in database theory and artificial intelligence.\nGiven an instance I, it will be useful to refer to subinstances of I, that is a set J ⊆ I. We will also refer to partition function of subinstances under some partial assignment, that is, the\npartition function of J where some of its variables are forced to a certain value. To this end, for a ∈ DW , with W ⊆ var(I), and J ⊆ I with V ′ = var(J) we define\nw(J, a) := ∑\nb∈DV ′\na∼b\n∏\nc∈J\nc(b| var(c)).\nWe use the following straightforward observation throughout this paper\nw(J, a) = ∑\nb∈DV ′\\W\n∏\nc∈J\nc((a ∪ b)| var(c))."
    }, {
      "heading" : "2.2. Graphs and hypergraphs associated to CNF-formulas",
      "text" : "We use standard notation for graphs which can e.g. be found in [Die05]. A hypergraph H = (V,E) consists of a finite set V and a set E of non-empty subsets of V . The elements of V are called vertices while the elements of E are called edges. As usual for graphs, we sometimes denote the vertex set of a hypergraph H by V (H) and the edge set of H by E(H). The size of a hypergraph is defined to be ‖H‖ = ∑ e∈E(H) |e|.\nA subhypergraph H′ of a hypergraphH is a hypergraph such that V (H′) ⊆ V (H) and E(H′) ⊆ {e ∩ V (H′) | e ∈ E(H), e ∩ V (H′) 6= ∅}. For S ⊆ V (H), the induced subhypergraph of H by S is the hypergraph H[S] = (S, {e ∩ S | e ∈ E(H)} \\ {∅}). We denote by H \\ S the hypergraph H[V (H) \\ S]. If S contains only one vertex v, we also write H \\ v for H \\ {v}.\nWe are interested in structural restrictions of the problem #CSPd. What we mean by structural restriction is that we restrict the way the variables interact in the different constraints. To formalize this notion, we introduce the hypergraph associated to an instance of #CSPd: The hypergraph H(I) associated to #CSPd-instance I is the hypergraph H(I) := (var(I), EI) where EI := {var(c) | c ∈ I}. The hypergraph of a CNF-formula is defined as H(F ) := (var(F ), EF ) where EF := {var(C) | C ∈ cla(F )} where var(F ) denotes the set of variables of F and cla(F ) denotes the set of clauses of F .\nThe incidence graph I(H) of a hypergraph H = (V,E) is the bipartite graph with the vertex set V ∪E and an edge between v ∈ V, e ∈ E if and only if v ∈ e. Similarly, the incidence graph I(F ) of a CNF-formula F has the vertex set var(F )∪ cla(F ) and x ∈ var(F ) and C ∈ cla(F ) are connected by an edge if and only if x appears in C.\n2.3. Relation to #SAT\nWe show in this section how we can encode #SAT into #CSPd-instances with the same hypergraphs.\nThe problem SAT differs from the classical CSP framework in the way the constraints are represented. Classically, in CSP, all the solutions to a constraint are explicitly listed. For a CNF-formula however, each clause with n variables has 2n − 1 solutions, which would lead to a CSP-representation exponentially bigger than the CNF-formula. One way of dealing with this is encoding CNF-formulas into CSP-instances by listing all assignments that are not solution of a constraint, see e.g. [CGH09]. In this encoding, each clause has only one counter-example and the corresponding CSP-instance is roughly of the same size as the CNF-formula.\nThe strength of the CSP with default values is that it can easily embed both representations. This leads to a polynomial reduction of #SAT to #CSPd.\nLemma 3. Given a CNF-formula F one can construct in polynomial time a #CSPd-instance I on variables var(F ) and domain {0, 1} such that\n• H(F ) = H(I),\n• for all a ∈ {0, 1}var(F ), a is a solution of F if and only if w(I, a) = 1, and otherwise w(I, a) = 0, and\n• s(I) = ‖I‖ = |F |.\nProof. For each clause C of F , we define a constraint c with default value 1 whose variables are the variables of C and such that supp(c) = {a} and c(a) = 0, where a is the only assignment of var(C) that is not a solution of C. It is easy to check that this construction has the above properties."
    }, {
      "heading" : "2.4. β-acyclicity of hypergraphs",
      "text" : "In this section we introduce the characterizations of β-acyclicity of hypergraphs we will use in this paper. We remark that there are many more characterizations, see e.g. [BLS99, Bra14].\nDefinition 4. Let H be a hypergraph. A vertex x ∈ V (H) is defined to be a nest point if {e ∈ E(H) | x ∈ e} forms a sequence of sets increasing for inclusion, that is {e ∈ E(H) | x ∈ e} = {e1, . . . , ek} with ei ⊆ ei+1 for i ∈ {1, . . . , k − 1}.\nA β-elimination order for H is defined inductively as follows:\n• If H = ∅, then only the empty tuple is a β-elimination order for H.\n• Otherwise, (x1, . . . , xn) is a β-elimination for H if x1 is a nest point of H and (x2, . . . , xn) is a β-elimination order for H \\ x1. A hypergraph H called β-acyclic if and only if there exists a β-elimination order for H.\nIt is easy to see that one can test β-acyclicity of a graph in polynomial time and that one can compute a β-elimination order efficiently if it exists.\nWe will also make use of another equivalent characterization of β-acyclic hypergraphs. A graph G is defined to be chordal bipartite if it is bipartite and every cycle of length at least 6 in G has a chord.\nTheorem 5 ([ADM86]). A hypergraph is β-acyclic if and only if its incidence graph is chordal bipartite.\nWe say that a #CSPd-instance I is β-acyclic if H(I) is β-acyclic and we use an analogous convention for #SAT. Note that the incidence graph of an instance I and that of its hypergraph in general do not coincide, because I might contain several constraints with the same sets of variables. But with Theorem 5, it is not hard to see that the incidence graph of an instance I is chordal bipartite if and only if the incidence graph of the hypergraph of I is chordal bipartite, so we can interchangeably use both notions of incidence graphs in this paper without changing the class of instances.\nCorollary 6. #SAT is polynomial time reducible to #CSPd. Moreover, #SAT restricted to β-acyclic formulas is polynomial time reducible to #CSPd restricted to β-acyclic instances.\nProof. Taking the construction of Lemma 3, it is clear that the number of solution of F is equal to w(I). The rest follows from the fact that the hypergraph remains unchanged during the reduction."
    }, {
      "heading" : "2.5. Width measures of graphs and CNF-Formulas",
      "text" : "In this section we introduce several width measures on graphs and CNF-formulas that are used when relating our algorithm for β-acyclic #CSPd to the framework of Sæther, Telle and Vatshelle [STV14]. Readers only interested in the algorithmic part of this paper may safely skip to Section 3.\nWe consider several width notions that are mainly defined by branch decompositions. For an introduction into this area and many more details see [Vat12]. For a tree T we denote by L(T ) the set of the leaves of T . A branch decomposition (T, δ) of a graph G = (V,E) consists of a subcubic tree T , i.e., a tree in which every vertex has at most degree 3, and a bijection δ between L(T ) and V . For convenience we often identify L(T ) and V . Moreover, it is often convenient to see a branch decomposition as rooted tree, and as this does not change any of the notions we define (see [Vat12]), we generally follow this convention. For every x ∈ V (T ) we define Tx be the subtree of T rooted in x. From x we get a partition or cut of V into two sets defined by (L(Tx), V \\ L(Tx)). For a set X ⊆ V we often write X̄ for V \\X.\nGiven a symmetric function f : 2V ×2V → R we define the f -width of a branch decomposition (T, δ) to be maxx∈V (T ) f(L(Tx), V \\L(Tx)), i.e., the f -width is the maximum value of f over all cuts of the vertices of T . The f -branch width of a graph G is defined as the minimum f -width of all branch decompositions of G.\nGiven a graph G = (V,E) and a cut (X, X̄) of V , we define G[X, X̄ ] to be the graph with vertex set V and edge set {uv | u ∈ X, v ∈ X̄, uv ∈ E}.\nWe will use at several places the well-known notion of treewidth of a graph G, denoted by tw(G). Instead of working with the usual definition of treewidth (see e.g. [Bod93]), it is more convenient for us to work with the strongly related notion of Maximum-Matching-width (short MM-width) introduced by Vatshelle [Vat12]. The MM-width of a graph G, denoted by mmw(G), is defined as the f -branch width of G for the function f that, given a cut (X, X̄) of G, computes the size of the maximum matching of G[X, X̄ ]. MM-width and treewidth are linearly related [Vat12, p. 28].\nLemma 7. Let G be a graph, then 13 (tw(G) + 1) ≤ mmw(G) ≤ tw(G) + 1.\nAnother width measure of graphs that we will use extensively is Maximum-Induced-Matchingwidth (short MIM-width): The MIM-width of a graph G, denoted by mimw(G), is defined as the f -branch width of G for the function f that, given a cut (X, X̄) of G, computes the size of the maximum induced matching of G[X, X̄ ].\nGiven a CNF-formula F , we say that a set of clauses C ⊆ cla(F ) is precisely satisfiable if there is an assignment to F that satisfies all clauses in C and no clause in cla(F ) \\ C. The PS-value of F is defined to be the number of precisely satisfiable subsets of cla(F ). Let F be a CNF-formula, X ⊆ var(F ) and C ⊆ cla(F ). Then we denote by FX,C the formula we get from F by deleting first every clause not in C and then every variable not in X.\nLet I(F ) be the incidence graph of F and let (A, Ā) be a cut of I(F ). Let X := var(F ) ∩ A, X̄ := var(F ) ∩ Ā, C := cla(F ) ∩ A and C̄ := cla(F ) ∩ Ā. Let ps(A, Ā) be the maximum of the PS-values of FX,C̄ and FX̄,C . Then the PS-width of a branch decomposition (T, δ) of G is defined as the ps-branch width of (T, δ). Moreover, the PS-width of F , denoted psw(F ), is defined to be the ps-branch width of I(F ).\nLet us try to give an intuition why we believe that PS-width is a good notion to model the limits of tractable dynamic programming for #SAT: The dynamic programming algorithms in the literature typically proceed by cutting instances into subinstances and then iteratively solving the instance along these cuts. During this process, some information has to be propagated\nbetween the subinstances. Intuitively, a minimum amount of such information is which sets of clauses are already satisfied by certain assignments and which clauses still have to be satisfied later in the process. In doing this, the individual clauses can be “bundled together” if they are satisfied by an assignment simultaneously. The number such bundles is exactly the PS-width of a cut, so we feel that PS-width is a good formalization of the minimum amount of information that has to be propagated during dynamic programming in the style of the algorithms from the literature.\nNot only is PS-width in our opinion a good measure for the limits of dynamic programming, but Sæther, Telle and Vatshelle also showed that it allows tractable solving of #SAT.\nTheorem 8 ([STV14]). Given a CNF-formula F of n variables and m clauses and of size s, and a branch decomposition (T, δ) of the incidence graph I(F ) of F with PS-width k, one can count the number of satisfying assignments of F in time O(k3s(m+ n)).\nWe admit that the intuition explained above is rather vague and informal, so the reader might or might not share it, but we stress that it is supported more rigorously by the fact that all known tractability results from the literature that were shown by dynamic programming can be explained by a combination of PS-width and Theorem 8.\nSæther, Telle and Vatshelle showed the following connection between the PS-width of a CNFformula F and the MIM-width of the incidence graph G of F .\nTheorem 9 ([STV14]). For any CNF-formula F over m clauses, any branch decomposition of the incidence graph I(F ) of F with MIM-width k has PS-width at most mk.\nTheorem 9 and Theorem 8 essentially turn finding structural classes of tractable #SATinstances into a problem of graph theory: it suffices to show that certain classes of formulas have sufficiently small MIM-width or PS-width to show that they are tractable. We will see that all tractability results from the literature can be explained this way. Unfortunately, deciding if a class of formulas has small MIM-width or PS-width seems to be tricky. In fact, even the complexity of deciding if a given graph has MIM-width 1 in polynomial time is left as an open problem in [Vat12]."
    }, {
      "heading" : "3. The algorithm and its correctness",
      "text" : "In this section we describe an algorithm that, given an instance I of #CSPd on domain D and a nest point x of H(I), constructs in a polynomial number of arithmetic operations an instance I ′ such that H(I ′) = H(I) \\ x, ‖I ′‖ ≤ ‖I‖ and w(I) = |D|w(I ′). We then explain that if I is β-acyclic, we can iterate the procedure to compute w(I) in a polynomial number of arithmetic operations.\nIn the following, for x ∈ var(I), we denote by I(x) = {c ∈ I | x ∈ var(c)}.\nTheorem 10. Let I be a set of weighted constraints on domain D and x a nest point of H(I). Let I(x) = {c1, . . . , cp} with var(c1) ⊆ . . . ⊆ var(cp). Let I ′ = {c′ | c ∈ I} where\n• if c /∈ I(x) then c′ := c\n• if c = ci, then c ′ i := (f ′ i , µ) is the weighted constraint on variables var(c ′ i) = var(c) \\ {x},\nwith default value µ(ci) and supp(c ′ i) := {a ∈ D var(c′i) | ∃d ∈ D, (a ⊕x d) ∈ supp(ci)}. Moreover, for all a ∈ supp(c′i), let Pi(a, d) := ∏i j=1 cj((a ⊕x d)|var(cj)) and P0(a, d) = 1. We define:\nf ′i(a) :=\n∑ d∈D Pi(a, d)∑\nd∈D Pi−1(a, d)\nif ∑\nd∈D Pi−1(a, d) 6= 0 and f ′ i(a) := 0 otherwise.\nThen H(I ′) = H(I) \\ x, ‖I ′‖ ≤ ‖I‖ and w(I) = |D|w(I ′). Moreover, one can compute I ′ with a O(p‖I(x)‖) arithmetic operations.\nProof. First, we explain why I ′ is well-defined. As x is a nest point, we can write I(x) = {c1, . . . , cm} with var(c1) ⊆ . . . ⊆ var(cm). If two constraints have the same variables, we choose an arbitrary order for them. Note that in Section 4 we will choose a specific order that ensures that the algorithm runs in polynomial time on a RAM, but in this proof any order will do. Finally, remark that Pi(a, d) is well defined since for a ∈ supp(c ′ i), d ∈ D and j ≤ i, (a ⊕x d) assigns all variables of cj since var(cj) ⊆ var(ci). Thus writing cj((a⊕x d)|var(cj)) is correct. We insist on the fact that it is only because x is a nest point that this definition works.\nH(I ′) = H(I) \\ x is obvious because for a constraint in I with variable set V , there exists a constraint in I ′ with variable set V \\ {x}.\n‖I ′‖ ≤ ‖I‖ because for all c ∈ I, |c′| ≤ |c| since |{a ∈ Dvar(c ′) | ∃d ∈ D, (a⊕x d) ∈ supp(c)}| ≤\n|supp(c)|. We now show by induction on i that for all a ∈ Dvar(c ′ i),\n|D| i∏\nj=1\nc′j(a) = ∑\nd∈D\nPi(a, d).\nFor i = 1, let a ∈ Dvar(c ′ 1). If a ∈ supp(c′1), then by definition:\nc′1(a) = ∑ d∈D P1(a, d)∑ d∈D P0(a, d) .\nSince P0(a, d) = 1 for all d, we have the expected result. If a /∈ supp(c′1), then for all d, a⊕x d /∈ supp(c1). Thus P1(a, d) = µ1 for all d and finally\n∑\nd∈D\nP1(a, d) = |D|µ1 = |D|c ′ 1(a).\nNow suppose that the result holds for i. Let a ∈ Dvar(c ′ i). Then we get by induction\n|D| i+1∏\nj=1\nc′j(a) = ( ∑\nd∈D\nPi(a, d))c ′ i+1(a).\nFirst, assume that ∑\nd∈D Pi(a, d) = 0. Since this sum is a sum of positive rationals, we have that for all d, Pi(a, d) = 0. Thus, Pi+1(a, d) = 0 for all d, that is ∑ d∈D Pi+1(a, d) = 0 which confirm the induction hypothesis. Now assume that ∑ d∈D Pi(a, d) 6= 0. If a ∈ supp(c ′ i+1), by definition of c ′ i+1, the induction hypothesis trivially holds. If a /∈ supp(ci+1), we have Pi+1(a, d) = µi+1Pi(a, d) for all d. Thus ∑ d∈D Pi+1(a, d) =\nµi ∑ d∈D Pi(a, d) = c ′ i+1(a) ∑ d∈D Pi(a, d) which establish the induction hypothesis for i+ 1.\nApplying the result for i = p, we find:\n|D| ∏\nc∈I(x)\nc′(a) = ∑\nd∈D\n∏\nc∈I(x)\nc((a ⊕x d)|var(c))\nNow, it is sufficient to remark that for c /∈ I(x), for all d ∈ D, c((a⊕x d)|var(c)) = c(a|var(c)) = c′(a|\nvar(c)) since x /∈ var(c) and c = c ′. Thus:\n|D|w(I ′) = ∑\na∈Dvar(I)\\{x}\n∑\nd∈D\n∏\nc∈I′\nc((a⊕x d)|var(c)) = w(I).\nWe now analyze the number of arithmetic operations we make in the construction of I ′. Clearly, if we have computed the ∑ d∈D Pi(a, d) for all i ≤ p and a ∈ supp(c ′ i) then we can compute c′i(a) with one division. Thus we need to do p divisions. Now remark that if we have computed Pi(a, d), then we only need one more multiplication to compute Pi+1(a, d).\nNow, we prove by induction on i that Pi(a, d) could take at least 1+ ∑i\nj=1 |cj | different values. It is trivial for i = 0. Now remark that if a ⊕x d /∈ supp(ci), then Pi(a, d) = µiPi−1(a, d), thus by induction, it gives 1+ ∑i−1 j=1 |cj | different values for Pi. And there is at most |supp(ci)| ≤ |ci| other values for a⊕x d ∈ supp(ci), which prove the induction. In the end, we have to compute at most O(p × ‖I(x)‖) different values for the Pi which can be done with a O(p × ‖I(x)‖) multiplications. Now if i is fixed, for all a, ∑\nd∈D Pi(a, d)\nhave at most 1 + ∑i\nj=1 |cj | different terms that are already computed. Thus we only need O(‖I(x)‖) operations to compute each of them. As there is p different sums to compute, we can do everything with a O(p‖I(x)‖) arithmetic operations.\nTheorem 11. If I is a β-acyclic instance of #CSPd, we can compute w(I) with a O(s(I) 2‖I‖) arithmetic operations.\nProof. We iterate the algorithm of Theorem 10 on a β-elimination order of the variables of I to transform it into an instance I∗. After all variables are eliminated, every constraint of I∗ has an empty set of variables, thus w(I∗) = ∏\nc∈I∗ c(ǫ), where ǫ denotes the empty assignment.\nMoreover, by Theorem 10, w(I) = |D||var(I)|w(I∗). Thus w(I) can be computed with O(s(I)) additionnal multiplications.\nIf we denote by px = |{c ∈ I | x ∈ var(c)}|, we have a total complexity of ∑\nx∈var(I)O(px‖I(x)‖), that is O(( ∑ x∈var(I) px)|var(I)|‖I‖). It is easy to see that ∑ x∈var(I) px = s(I) and since |var(I)| ≤ s(I), we have a total number of arithmetic operations that is a O(s(I)2‖I‖)."
    }, {
      "heading" : "4. Runtime analysis of the algorithm",
      "text" : "The analysis of Theorem 11 shows that our algorithm uses only a polynomial number of arithmetic operations. Unfortunately, this does not guarantee that the algorithm runs in polynomial time on a RAM. The problem is that, due to the many multiplications and divisions, the bitsize of the new (rational) weights computed by the algorithm at each step could grow exponentially, leading to an overall superpolynomial runtime. In this section we will prove that this is in fact not the case. We will show that at each step of the algorithm, numerous cancellations occur, leading to weights of polynomial bitsize. Combining this with Theorem 11, it will follow that the algorithm runs in polynomial time."
    }, {
      "heading" : "4.1. Some technical lemmas",
      "text" : "In this section, we will show some rather technical lemmas we will use later on. Throughout this paper, we follow the convention that for all assignment a, we have w(∅, a) = 1. This is motivated by the following lemma.\nLemma 12. Let I be a set of weighted constraints, J ⊆ I and a a partial assignment of var(I). If w(J, a) = 0 then w(I, a) = 0.\nProof. We have w(J, a) = 0 = ∑\nb≃a ∏ c∈J c(b|var(c)). Since every term of the sum is non-negative,\nwe have that for all b ≃ a it holds ∏\nc∈J c(b|var(c)) = 0. Thus,\nw(I, a) = ∑\nb≃a\n∏\nc∈J\nc(b| var(c))\n∏\nc∈I\\J\nc(b| var(c)) = 0.\nOne key ingredient in our analysis will be understanding how two subinstances interact under a partial assignment.\nLemma 13. Let I be a set of weighted constraints on domain D, J1 ⊆ I, J2 ⊆ I and a ∈ D W for W ⊆ var(I). Let V1 = var(J1), V2 = var(J2). If V1 ∩ V2 ⊆ W and J1 ∩ J2 = ∅, then\nw(J1 ∪ J2, a) = w(J1, a)w(J2, a)\nProof. Let V = V1 ∪ V2. Since V \\ W = (V1 \\ W ) ∪ (V2 \\ W ) and this union is disjoint by definition, there is a natural bijection between DV1\\W ×DV2\\W and DV \\W that associates to (b1, b2) the assignment b1∪b2. Moreover, if c ∈ J1, then (b1∪b2)|var(c) = b1|var(c) since var(c) ⊆ V1. Similarly, for c ∈ J2, (b1 ∪ b2)|var(c) = b2|var(c). Consequently,\nw(J1 ∪ J2, a) = ∑\nb1∈DV1\\W\n∑\nb2∈DV2\\W\n∏\nc∈J1\nc((a ∪ b1)|var(c)) ∏\nc∈J2\nc((a ∪ b2)|var(c))\n= w(J1, a)w(J2, a)\nCorollary 14. Let I be a set of weighted constraints on domain D, J1 ⊆ I, J2 ⊆ I and a ∈ D W for W ⊆ var(I). Let V1 = var(J1 \\ J2), V2 = var(J2 \\ J1) and V0 = var(J1 ∩ J2). If V0 ∩ V1 ⊆ W and V0 ∩ V2 ⊆ W . If w(J2, a) 6= 0, we have:\nw(J1, a) w(J2, a) = w(J1 \\ J2, a) w(J2 \\ J1, a)\nProof. First, remark that w(J2 \\ J1, a) 6= 0 by Lemma 12 since J2 \\ J1 ⊆ J2 and w(J2, a) 6= 0. Apply Lemma 13 on J1 \\ J2 and J1 ∩ J2 for the numerator and on J2 \\ J1 and J2 ∩ J1 for the denominator and observe that w(J1 ∩ J2, a) cancels.\nWe will use the following corollary heavily in Section 4.\nCorollary 15. Let I be a set of weighted constraints on domain D, J1, J2, J3, J4 ⊆ I and a ∈ DW for W ⊆ var(I). Assume that w(J3, a) 6= 0 and w(J4, a) 6= 0 and\n(i) J1 ∩ J2 ⊆ J3 and J3 ∩ J4 ⊆ J1,\n(ii) var(J1 \\ J3) ∩ var(J1 ∩ J3) ⊆ W ,\n(iii) var(J3 \\ J1) ∩ var(J1 ∩ J3) ⊆ W ,\n(iv) var(J1 \\ J3) ∩ var(J2) ⊆ W , and\n(v) var(J3 \\ J1) ∩ var(J4) ⊆ W .\nThen w(J1, a)w(J2, a)\nw(J3, a)w(J4, a) =\nw((J1 \\ J3) ∪ J2, a) w((J3 \\ J1) ∪ J4, a) .\nProof. Apply Corollary 14 on J1 and J3 and Lemma 13 on J1 \\J3 and J2 for the numerator and on J3 \\J1 and J4 for the denominator. Remark that Condition (i) ensures that (J1 \\J3)∩J2 = ∅ and (J3 \\ J1) ∩ J4 = ∅ and that the denominator is not null because w((J3 \\ J1) ∪ J4, a) = w(J3 \\ J1, a)w(J4, a) and w(J4, a) 6= 0 by assumption and w(J3 \\ J1, a) 6= 0 by Lemma 12 and w(J3, a) 6= 0."
    }, {
      "heading" : "4.2. Defining partial orders",
      "text" : "The algorithm of Theorem 10 transforms an instance into a new one with the same number of constraints but with one variable less. In this section we will give an explicit description of the weight of a constraint c ∈ I after k such elimination steps. In the following, I is a β-acyclic CSP-instance and {x1, . . . , xn} = var(I) is a β-elimination order of H(I). We assume that we will perform the elimination along this order. Let Xk = {x1, . . . , xk} and for c ∈ I, we denote by c(k) the constraint c after the elimination of xk. By convention, c\n(0) = c. Remark that var(c(k)) = var(c) \\Xk.\nIn the following, we will introduce for each k, a partial order ≺k on I. The intuition for this partial order is that for c, d ∈ I, c ≺k d means that d\n(k) “depends on” c(0). For example, assume that x1 ∈ var(c) ⊆ var(d). When we eliminate x1, we see—in the formula of Theorem 10—that the weight of c appears in the definition of d(1). Hence, we would like to have c ≺1 d.\nTo simplify the proofs, we make one more assumption on I: If c, d ∈ I and c 6= d, then var(c) 6= var(d). We may assume this w.l.o.g. since it is easy to merge two constraints with the same variables without increasing ‖I‖. Observe that we make this assumption only on the initial instance I. During the elimination process, constraints with the same set of variables might appear, but we can easily handle them.\nDefinition 16. For two constraints c, d ∈ I, we write c ≺ d if there exists k such that var(c) \\ Xk ( var(d) \\Xk. We write c d if c ≺ d or c = d.\nLemma 17. is a total order on I.\nProof. We first show that is antisymmetric. So let c, d be constraints such that c d and d c. By way of contradiction, assume that c 6= d, so c ≺ d and d ≺ c. By definition there are k, k′ such that var(c) \\Xk ( var(d) \\Xk and var(d) \\Xk′ ( var(c) \\Xk′ . W.l.o.g. assume that k < k′. Then var(c) \\Xℓ ⊆ var(d) \\Xℓ for all ℓ ≥ k which is a contradiction to d ≺ c. It follows that is antisymmetric.\nWe now show transitivity of . So let c, d, e ∈ I with c d and d e. If we have c = d or d = e, then we get immediately c d. Thus we may assume that c ≺ d and d ≺ e. By definition, there exist k, ℓ such that var(c) \\Xk ( var(d) \\Xk and var(d) \\Xℓ ( var(e) \\Xℓ. For m := max(k, ℓ) we get var(c) \\Xm ⊆ var(d) \\Xm ⊆ var(e) \\Xm and one of these inclusions is strict. Thus var(c) \\Xm ( var(e) \\Xm, that is c ≺ e and it follows that is transitive.\nWe now show that is total. So let c, d ∈ I. If c = d, then by definition c d. So we assume that c 6= d. Let k = max{j | xj(∈ var(c) \\ var(d)) ∪ (var(d) \\ var(c))}. Observe that k is well-defined, since var(d) 6= var(c) by assumption on I. Assume first that xk ∈ var(d) \\ var(c). Then var(c) \\ var(d) ⊆ Xk−1 by maximality of k. It follows that var(c) \\Xk−1 ⊆ var(d) \\Xk−1 and since xk ∈ var(d) \\Xk−1, we have var(c) \\Xk−1 ( var(d) \\Xk−1. Thus c ≺ d. Analogously, we get for xk ∈ var(c) \\ var(d) that d ≺ c. Hence ≺ is total.\nDefinition 18. For k ∈ {0, . . . , n}, we define the relation ≺k⊆ I × I inductively on k as\n• ≺0= ∅\n• for all c, d ∈ I, c ≺k+1 d if and only if c ≺k d or there exists e ∈ I such that c k e ≺ d and xk+1 ∈ var(d) ∩ var(e),\nwhere we denote by c k d if c = d or c ≺k d.\nObserve that the definition of ≺k is compatible with the informal discussion of c ≺k d at the beginning of this section: If d(k) depends on c(k). For k = 0, no constraint depends on another, thus ≺0= ∅. Then, when eliminating xk+1, if xk+1 /∈ var(d), then the dependencies of d do not change since d remains the same. But if xk+1 ∈ var(d), then the weight of each constraint e whose variables are included in var(d) and xk+1 ∈ var(e) will appear in d\n(k+1). And if e depends on c at step k, that is c ≺k e, then d will also depend on c after the elimination of xk+1.\nWe now show some properties of ≺k that are crucial for the understanding of how the weights of constraints interact with each other.\nLemma 19. a) (≺k) ⊆ (≺k+1).\nb) For all c, d ∈ I, c ≺k+1 d implies c ≺ d and var(c) \\Xk ⊆ var(d) \\Xk.\nc) ( k) is a partial order.\nProof. a) follows directly from the definition of ≺k+1. We prove b) by induction on k. For k = 0, let c, d ∈ I such that c ≺1 d. Since ≺0= ∅, c 6≺0 d. Thus, by definition, there exists e such that: c 0 e ≺ d and x1 ∈ var(c) ∩ var(d). Again, since ≺0= ∅, we have c = e. Thus c ≺ d and since x1 is a nest point, var(c) ⊆ var(d), which is the induction hypothesis for k = 0 since X0 = ∅.\nNow assume that k ≥ 0 and that the statement is true for k. Let c, d ∈ I such that c ≺k+1 d. If c ≺k d, then we get from the induction hypothesis that c ≺ d and var(c)\\Xk−1 ⊆ var(d)\\Xk−1. This directly yields var(c) \\ Xk ⊆ var(d) \\ Xk. Now, if c 6≺k d, then there exists e such that c k e, e ≺ d and xk+1 ∈ var(e)∩var(d). By induction c e and thus c ≺ d since ≺ is transitive by Lemma 17. As xk+1 is a nest point after eliminating Xk, we have var(e) \\Xk ⊆ var(d) \\Xk. By induction we get var(c) \\Xk ⊆ var(e) \\Xk and thus var(c) \\Xk ⊆ var(d) \\Xk as desired.\nFor c), observe that k reflexive by definition. Furthermore, k is antisymmetric since it is a subrelation of the order ≺ by b). It remains to show that ≺k is transitive. We do this by induction on k. The case k = 0 is trivial since (≺0) = ∅. Now suppose that (≺k) is transitive for k ≥ 0. Let c, d, e ∈ I such that c ≺k+1 d and d ≺k+1 e. If c ≺k d ≺k e, then by induction c ≺k e and then c ≺k+1 e since (≺k) ⊆ (≺k+1).\nNow assume that c 6≺k d. Then by definition, there exists c ′ such that c k c ′ ≺ d and xk+1 ∈ var(c ′)∩ var(d). Since d ≺k+1 e, we also have c ′ ≺ e and xk+1 ∈ var(d)\\Xk ⊆ var(e)\\Xk. Thus xk+1 ∈ var(c ′) ∩ var(e) and c k c\n′ ≺ e, that is c ≺k+1 e. Finally assume that c ≺k d and d 6≺k e. Since d ≺k+1 e, there exists d ′ such that d k d ′ ≺ e\nand xk+1 ∈ var(d ′) ∩ var(e). By induction, (≺k) is transitive. Thus c ≺k d ′ ≺ e and xk+1 ∈ var(d′) ∩ var(e). That is c ≺k+1 e.\nAgain, from our intuitive understanding of ≺k, the transitivity is obvious: if d (k) depends on c(k) and e(k) depends on d(k), then e(k) should depend on c(k). An other informal observation is that if c and d have no common dependencies at step k, then they should not share a variable in Xk since sharing a nest point automatically induces a dependency:\nLemma 20. For all c, d ∈ I, if c ≺ d but c 6≺k d, then var(c) ∩ var(d) ∩Xk = ∅.\nProof. By way of contradiction. If for j ≤ k, xj ∈ var(c) ∩ var(d) ∩ Xk then c j c ≺ d and xj ∈ var(c) ∩ var(d). That is c ≺j d and by Lemma 19 we get c ≺k d.\nWe need one final property: if d ≺ e both depend on c at step k, then these dependencies were induced by the elimination of at most two nest points. During the elimination of the second nest point, e will get both the dependencies of c but also the dependencies of d. Thus e should depend on d. This is formalized by the following lemma:\nLemma 21. Let c, d, e ∈ I. If c ≺k d, c ≺k e and d ≺ e then d ≺k e.\nProof. The proof is by induction on k. The case k = 0 is trivial since the precondition cannot hold. Assume the result holds for k ≥ 0 and let c, d, e ∈ I be constraints such that c ≺k+1 d, c ≺k+1 e and d ≺ e. If both c ≺k d and c ≺k e, then the induction gives d ≺k e thus d ≺k+1 e.\nOtherwise, assume that c 6≺k d and c 6≺k e. Then by definition xk+1 ∈ var(d) ∩ var(e). Since d ≺ e, it gives d ≺k+1 e.\nNow assume c 6≺k d but c ≺k e. By definition, there exists c ′ such that c k c ′ ≺ d and xk+1 ∈ var(c ′) ∩ var(d). Since c′ ≺ d ≺ e, we have c′ ≺ e and by induction c ≺k c ′ and c ≺k e gives c′ ≺k e. Thus xk+1 ∈ var(e) and d ≺k+1 e. Finally assume that c ≺k d but c 6≺k e. By definition, there exists c ′ such that c k c ′ ≺ e and xk+1 ∈ var(c ′) ∩ var(e). As in the previous case, by induction, we can deduce that d k c ′ or c′ ≺k d. Both cases lead to d ≺k+1 e.\nWe now define for every k and every constraint c a subinstance Ik(c) of I that intuitively contains the relations of I that have an influence on the weights of c after the first k variables have been eliminated.\nDefinition 22. For every k ∈ {0, . . . , n} and c ∈ I we define Ik(c) := {d ∈ I | d k c}.\nWe will now prove a lemma that helps us understand how Ik(c) is evolving during the algorithm. Again, the behaviour is intuitively very natural: If xk+1 /∈ var(c), then c will have no new dependencies, thus Ik+1(c) = Ik(c). If xk+1 ∈ var(c) however, c will take all the dependencies of the constraints d such that xk+1 ∈ var(d) and d ≺ c.\nLemma 23. For k ≤ 0, if xk+1 /∈ var(c) then Ik+1(c) = Ik(c). Otherwise, let I(xk+1) := {c1, . . . , cm} with c1 ≺ . . . ≺ cm. Then we have\nIk+1(c1) = Ik(c1)\nand for i < m Ik+1(ci+1) = Ik(ci+1) ∪ Ik+1(ci).\nProof. First, assume that xk+1 /∈ var(c). Since (≺k) ⊆ (≺k+1) by Lemma 19, it follows that Ik(c) ⊆ Ik+1(c). Now, if d ∈ Ik+1(c) and d 6= c, then either d ≺k c or there exists e such that d k e ≺ c and xk+1 ∈ var(c) ∩ var(e). Since xk+1 /∈ var(c), we necessarily have d ≺k c, that is d ∈ Ik(c). This implies Ik(c) = Ik+1(c).\nFor the second equality, Ik(c1) ⊆ Ik+1(c1) still follows from Lemma 19. For the other direction, consider d ∈ Ik+1(c1), that is d k+1 c1. By way of contradiction, assume that d 6 k c. By definition of ≺k+1, there exists e ∈ I such that d k e ≺ c1 and xk+1 ∈ var(e). However, by definition, c1 is the minimal constraint with respect to whose variables contain xk+1. Thus such an e ∈ I cannot exist. Consequently, d ∈ Ik(c1) and it follows Ik+1(c1) = Ik(c1).\nNow fix i < m. By definition of ci+1, we have xk+1 ∈ var(ci+1). We first prove that Ik(ci+1)∪ Ik+1(ci) ⊆ Ik+1(ci+1). By Lemma 19 again, Ik(ci+1) ⊆ Ik+1(ci+1). Now let d ∈ Ik+1(ci). We have ci k ci ≺ ci+1 and xk+1 ∈ var(ci) ∩ var(ci+1) and thus, by definition of ≺k+1 this implies ci ≺k+1 ci+1. This yields d k+1 ci ≺k+1 ci+1 and thus d ∈ Ik+1(ci+1).\nFinally, we prove that Ik+1(ci+1) ⊆ Ik(ci+1) ∪ Ik+1(ci). So let d ∈ Ik+1(ci+1). If d k ci+1, then, by definition, we have d ∈ Ik(ci+1). So assume now that d 6 k ci+1. By definition of ≺k+1, there exists e such that d k e ≺ ci+1 and xk+1 ∈ var(e) ∩ var(ci+1). Since xk+1 ∈ var(e) and e ≺ ci+1, it follows that e = cj for a j < i+1. If j = i, then d k e = ci and thus d k+1 ci which implies d ∈ Ik+1(ci). Otherwise, j < i and we have d k cj ≺ ci and xk+1 ∈ var(cj) ∩ var(ci), which gives d ≺k+1 ci. Thus d ∈ Ik+1(ci) as well."
    }, {
      "heading" : "4.3. Proof of the runtime bound",
      "text" : "In this section, we will prove that for each c ∈ I and a an assignment of var(c(k)), c(k)(a) is proportional to\nw(Ik(c), a)\nw(Ik(c) \\ {c}, a) .\nSince Ik(c) is a subinstance of I, the bitsize of the computed rational number is polynomial in the size of the input. Thus, it will follow that the weight of c(k) is a rational number of polynomial bitsize and thus all arithmetic operations of the algorithm can be done in polynomial time.\nRemember that by convention w(∅, a) = 1 and that for x ∈ var(I), I(x) = {c ∈ I | x ∈ var(c)}.\nLemma 24. Let k ≥ 0 and I(xk+1) = {c1, . . . , cm} with c1 ≺ . . . ≺ cm. For all j ≤ m and a : var(cj) \\Xk → D we have\nj∏\ni=1\nw(Ik(ci), a)\nw(Ik(ci) \\ {ci}, a) =\nw(Ik+1(cj), a)\nw(Ik+1(cj) \\ {c1, . . . , cj}, a) .\nProof. The proof is by induction on j. For j = 1, it is a consequence of Lemma 23 since Ik+1(c1) = Ik(c1). Assume the result holds for j ≥ 1. Fix a : var(cj+1) \\ Xk → D. Observe first that by Lemma 19 we have var(ci) \\Xk ⊆ var(cj+1) \\Xk for i ≤ j (this could alternatively be seen from the fact that xk+1 is a nest point after removing x1, . . . , xk). Thus we can use induction for a and get\nj+1∏\ni=1\nw(Ik(ci), a)\nw(Ik(ci) \\ {ci}, a) =\nw(Ik+1(cj), a)\nw(Ik+1(cj) \\ {c1, . . . , cj}, a)\nw(Ik(cj+1), a)\nw(Ik(cj+1) \\ {cj+1}, a) .\nWe will apply Corollary 15 with J1 := Ik+1(cj), J2 := Ik(cj+1), J3 := Ik(cj+1) \\ {cj+1} and J4 := Ik+1(cj) \\ {c1, . . . , cj} and W := var(cj+1) \\Xk.\nObserve that by Lemma 23 and by the fact that J3 ⊆ J2, (J1 \\J3)∪J2 = J1∪J2 = Ik+1(cj+1). Moreover, (J3 \\ J1)∪ J4 = (J3 \\ J1)∪ (J1 \\ {c1, . . . , cj}) = (J1 ∪ J3) \\ {c1, . . . , cj} = Ik+1(cj+1) \\ {c1, . . . , cj+1} since cj+1 /∈ J1. Hence, if the conditions of Corollary 15 are met, the lemma will follow.\nWe now verify each conditions of Corollary 15:\n(i) if c ∈ J1 ∩ J2, then c k+1 cj+1 (it is in J2) and c 6= cj+1 since c cj ≺ cj+1. Thus c ∈ J3. Moreover J4 ⊆ J1, thus J3 ∩ J4 ⊆ J1.\n(ii) since J3 ⊆ J2, this condition is implied by condition (iv).\n(iii) Let c ∈ J3 \\ J1 and d ∈ J1. Since both c ∈ J3 and d ∈ J1, we have c ≺k cj+1 and d ≺k+1 cj ≺k+1 cj+1. By Lemma 19, var(c) \\Xk ⊆ W and var(d) \\Xk ⊆ W .\nWe claim that c and d are incomparable with respect to ≺k.\nFirst, if c ≺k d, then c ≺k+1 d ≺k+1 cj that is c ∈ J1 which is a contradiction. Consequently, c ⊀k d.\nNow, if d ≺k c, then d ≺k+1 c and d ≺k+1 cj. Thus, since c 6 k+1 cj , we have cj ≺k+1 c ≺k+1 cj+1 thus cj ≺ c ≺ cj+1. We have that xk+1 ∈ var(cj), and by Lemma 19 b) we get xk+1 ∈ var(c). But this contradicts the definition of cj as the maximal constraint with respect to that is less than cj+1 and holds xk+1. Hence this is a contradiction and we get d ⊀ c.\nThus, c and d are indeed incomparable with respect to ≺k. Since ≺ is a total order we have either d ≺ c or c ≺ d and thus by Lemma 20 we have var(c) ∩ var(d) ∩ Xk = ∅. Since by Lemma 19 b) we have that var(c) \\Xk ⊆ var(cj+1) and var(d) \\Xk ⊆ var(cj+1), it follows that var(c) ∩ var(d) ⊆ W . Since this is true for all combinations of c and d, it follows that var(J3 \\ J1) ∩ var(J1 ∩ J3) ⊆ W as desired.\n(iv) let c ∈ J1 \\J3 and d ∈ J2. We have c ≺k+1 cj and d k cj+1. By Lemma 19, var(c) \\Xk ⊆ var(cj) \\Xk ⊆ W and var(d) \\Xk ⊆ W .\nWe again show that c and d are incomparable with respect to ≺k.\nIf c ≺k d, we get with d k cj+1 and transitivity c ≺k cj+1. Thus c ∈ J3 which is a contradiction. Consequently, c ⊀k d.\nNow assume that d ≺k c. We have c ≺ cj ≺ cj+1 and d k cj+1 and thus with Lemma 21 we get c ≺k cj+1. But then c ∈ J3 which is a contradiction again.\nThus c and d are indeed incomparable with respect to ≺k. Now the claim follows as in (iii).\n(v) since J4 ⊆ J1, this is implied by our proof of condition (iii) (we have not assumed d ∈ J3 there).\nWe can now state the main theorem of this section. Remember that c(k) is the weighted constraint we get from c after k steps of our elimination procedure.\nTheorem 25. For all c ∈ I and k ≥ 0, there exists αk(c) ∈ N \\ {0} such that for all a : var(c) \\Xk → D, either\nc(k)(a) = 0\nor\nc(k)(a) = 1\nαk(c) ·\nw(Ik(c), a)\nw(Ik(c) \\ {c}, a)\nand αk(c) ≤ |D| k.\nProof. The proof is by induction on k. Note that ≺0= ∅ by definition and by convention w(∅, a) = 1. So taking α0(c) = 1, proves the result for k = 0.\nNow assume that the result holds for k ≥ 0. To lighten the notations, we will denote xk+1 by x.\nIf x /∈ var(c), then c(k) = c(k+1). By Lemma 23, we also know that Ik+1(c) = Ik(c). Thus, if by choosing αk+1(c) = αk(c), the result follows.\nSo consider now I(x), i.e. the constraints that contain x as a variable. Let I(x) = {c1, . . . , cm} with c1 ≺ . . . ≺ cm. We will prove the result for all of the ci by induction on i. For i = 1, we have by definition, for all a : var(c1) \\Xk+1 → D, either c (k+1) 1 (a) = 0 and there is nothing to prove, or\nc (k+1) 1 (a) =\n∑ d∈D c (k) 1 (a⊕x d)\n|D| .\nBy induction on k, we get\nc (k+1) 1 (a) =\n1\n|D|αk(c1)\n∑\nd∈D′\nw(Ik(c1), a⊕x d)\nw(Ik(c1) \\ {c1}, a⊕x d)\nwhere D′ = {d ∈ D | c1(a ⊕x d) 6= 0}. As there is no constraint in Ik(c1) \\ {c1} having the variable x, the denominator in the sum does not depends on d. Moreover, Ik+1(c1) = Ik(c1) by Lemma 23. If d /∈ D′ then c1(a ⊕x d) = 0 and hence w(Ik(c1), a ⊕x d) = 0. Thus, if we set αk+1(c1) = |D|αk(c1), we have\nc (k+1) 1 (a) =\nαk+1(c1) −1\nw(Ik+1(c1) \\ {c1}, a)\n∑\nd∈D\nw(Ik+1(c1), a⊕x d)\n= 1\nαk+1(c1) ·\nw(Ik+1(c1), a)\nw(Ik+1(c1) \\ {c1}, a) .\nFor i > 1, for all a : var(ci+1) \\Xk+1 → D, either c (k+1) i+1 (a) = 0 and there is nothing to prove,\nor by definition\nc (k+1) i+1 (a) =\n∑ d∈D ∏ j≤i+1 c\n(k) j ((a⊕x d)|var(c(k)j ) )\n∑ d∈D ∏ j≤i c\n(k) j ((a⊕x d)|var(c(k)j )\n) .\nApplying the induction hypothesis and Lemma 24 on both the numerator and the denominator, by also remarking that Ik(ci) \\ {c1, . . . , ci} does not contain any constraint with the variable x\nc (k+1) i+1 (a) =\n1 αk(ci+1) · w(Ik+1(ci+1), a) w(Ik+1(ci), a) w(Ik+1(ci) \\ {c1, . . . , ci}, a) w(Ik+1(ci+1) \\ {c1, . . . , ci+1}, a) .\nWe now apply Corollary 15 with W := var(ci+1) \\Xk+1, J1 := Ik+1(ci) \\ {c1, . . . , ci}, J2 := Ik+1(ci+1), J3 := Ik+1(ci+1) \\ {c1, . . . , ci+1} and J4 := Ik+1(ci). Note that this will yields the desired result: We have (J1 \\ J3) ∪ J2 = J2 = Ik+1(ci+1) since J1 ⊆ J3 and (J3 \\ J1) ∪ J4 = Ik+1(ci+1)\\{ci+1}, from combining Lemma 23 and the fact that {c1, . . . , ci} ⊆ J4 and ci+1 /∈ J4.\nWe now check the conditions of Corollary 15.\n(i) Since J1 ⊆ J3, we have J1 ∩ J2 ⊆ J3. Moreover, J3 ∩ J4 ⊆ J1 since J1 = J4 \\ {c1, . . . , ci} and J3 does not contain any of the c1, . . . , ci.\n(ii) This condition holds since J1 \\ J3 = ∅.\n(iii) This condition is a consequence of condition (v) since J1 ∩ J3 ⊆ J4.\n(iv) This condition holds since J1 \\ J3 = ∅.\n(v) Let c ∈ J3 \\ J1 and d ∈ J4. We have that c ≺k+1 ci+1. Moreover, ci k ci ≺ ci+1 and x ∈ var(ci) ∩ var(ci+1) and consequently, by definition of ≺k+1, we have ci ≺k+1 ci+1. By definition of J4 we have d ≺k+1 ci thus by transitivity of ≺k+1 we get d ≺k+1 ci+1. Using Lemma 19 b), it follows that var(c) \\Xk+1 ⊆ W and var(d) \\Xk+1 ⊆ W .\nNote that c 6 k+1 ci, because c /∈ J1 and c /∈ {c1, . . . , ci+1}.\nWe now show that c and d are incomparable with respect to ≺k+1.\nBy way of contradiction, assume first that c ≺k+1 d. Then as d ≺k+1 ci, we get c ≺k+1 ci which is a contradiction.\nNow assume that d ≺k+1 c. With d ≺k+1 ci and the fact that ≺ is a total order we get from Lemma 21 that c ≺k+1 ci or ci ≺k+1 c. But we know that c 6≺k+1 ci, so it follows that ci ≺k+1 c ≺k+1 ci+1 and thus ci ≺ c ≺ ci+1. By definition of ci, we have x ∈ var(ci) and by Lemma 19 it follows that x ∈ var(c). But this contradicts the choice of ci as the maximal element in I(x) with respect to ≺ that is less than ci+1.\nConsequently, c and d are in fact incomparable with respect to ≺k+1. Now (v) follows as in as in (iii) in the proof of Lemma 24.\nHaving checked all conditions, we may apply Corollary 15 which concludes the proof.\nCombining the results of Section 3 and Section 4, we now state the main tractability result of this paper.\nTheorem 26. There exists an algorithm that, given a β-acyclic instance I of #CSPd on domain D, computes w(I) in polynomial time.\nProof. In a first step, one computes a β-elimination order for H(I), which can be done naively in polynomial time, iteratively searching by brute force for a nest point. When it is found, we remove the nest point and iterate.\nThen we can iterate the elimination procedure of Theorem 10, respecting the order ≺ of Section 4 induced by the elimination order. We make O(s(I)2‖I‖) arithmetic operations to perform all the elimination steps. The other operations needed are the computation of the new supports of the constraints at each step, which can be done in polynomial time.\nFinally, Section 4 provides a good upper bound on the size of the rationals on which we need to perform arithmetic operations. They are always of polynomial bitsize (of size O(|var(I)| log |D|)), thus each operation can be perform in polynomial time.\nCombining Theorem 26 and Corollary 6 we get the main tractability result for #SAT.\nCorollary 27. #SAT on β-acyclic CNF-formulas can be solved in polynomial time."
    }, {
      "heading" : "5. Relation to the STV-framework",
      "text" : "In this section we compare our algorithmic result for #SAT on β-acyclic hypergraphs to the framework proposed by Sæther, Telle and Vatshelle in [STV14] which we call short the STVframework. We first show that the STV-framework gives a uniform explanation of all tractability results for #SAT in the literature, extending the results of [STV14]. We see this as strong evidence that the STV-framework is indeed a good formalization of the intuitive notion of “dynamic programming for #SAT”.\nNext we show that the STV-framework cannot give any subexponential time algorithms for β-acyclic #SAT. To this end, we prove an exponential lower bound on the PS-width of β-acyclic CNF-formulas."
    }, {
      "heading" : "5.1. Explaining old results by PS-width",
      "text" : "In this section we show that the STV-framework is indeed strong enough to explain all known results on structural #SAT. Figure 1 shows the hierarchy for inclusion formed by the acyclicity notions and classes defined by bounding the width measures from the literature. Most proofs of inclusion can be found in [Fag83, Dur12, GP04, PSS13, CDM14] and the references therein. The relation between disjoint branches and MIM-width and that between β-acyclicity and MIMwidth are shown in this paper.\nKnown complexity results for the restrictions of #SAT can be found in Table 1; for definitions of the appearing complexity classes see e.g. [FG06].\nIn [Vat12] it is shown that MIM-width is bounded by cliquewidth, so nearly all tractability results of Table 1 follow from [STV14]. To show that the missing results can also be explained in the STV-framework, we only have to recover the tractability results for formulas with disjoint branches decompositions and the fixed-parameter result for formulas of bounded signed incidence cliquewidth. We reprove these results in the following sections by giving upper bounds on the MIM-width and the PS-width, respectively."
    }, {
      "heading" : "5.1.1. Hypergraphs with disjoint branches",
      "text" : "In this section we show how the tractability of #SAT on hypergraphs with a disjoint branches decomposition proved in [CDM14] can be explained by the STV-framework.\nA join tree (T, λ) of a hypergraph H = (V,E) consists of a rooted tree T and a mapping λ : V (T ) → E such that the following connectivity condition is satisfied: Let t1, t2 ∈ V (T ) and v ∈ λ(t1) ∩ λ(t2), then v ∈ λ(t) for every t ∈ V (T ) that lies on the path in T connecting t1 and t2. A join tree is a disjoint branches decomposition if whenever t1 and t2 lie on different branches of T , we have λ(t1) ∩ λ(t2) = ∅. Hypergraphs with disjoint branches decompositions are a strict subclass of β-acyclic hypergraphs [Dur12].\nTheorem 28. [CDM14] There is an algorithm that, given a hypergraph H, in time polynomial in ‖H‖ compute a disjoint branches decomposition of H if one exists and rejects otherwise.\nLemma 29. Given a hypergraph H and a disjoint branches decomposition of H, we can in polynomial time compute a branch decomposition of I(G) of MIM-width at most 2.\nProof. Let (T , λ) be a disjoint branches decomposition of H = (V,E). We construct a branch decomposition (T, δ) of H as follows: The vertices of T form the internal vertices of T . For every v ∈ V we introduce a new leaf u labeled by δ(u) = v connecting it to the vertex of T that corresponds to the edge containing v that is farthest from the root of T . Observe that this choice is unique because T has disjoint branches and thus vertices v ∈ V only appear along a path from the root to a leaf. Furthermore, we add a new leaf u for each e ∈ E labeled by δ(u) = e, connecting it to the vertex x of T with λ(x) = e.\nWe now make T subcubic: For any internal vertex x, we introduce a binary tree Tx having as leaves the leaf children of x and connect it to x. After that, for every vertex x having more than two children, we introduce again a binary tree T ′x having the children of x as its leaves and connect it to x. The result is a branch decomposition (T, δ) of the incidence graph of H.\nWe claim that (T, δ) has MIM-width at most 2. So let v be a cut vertex with cut (X, X̄). First assume that v lies in one of the Tx. Let e = λ(x) be the single e ∈ E that appears as label of a leaf of Tx. Observe that all u ∈ V ∩X lie in e. Also, all u ∈ V ∩X that lie in an edge different from e must lie in a common edge e′ ∈ E that corresponds to the parent of e in T . Since e′ /∈ X only one vertex in X ∩ V can contribute to an independent matching in I(H)[X, X̄ ]. Furthermore, e is the only edge in E ∩X, and it follows that the MIM-width of the cut (X, X̄) is at most 2.\nIf v does not lie in any Tx—that is v lies in a T ′ y or is a vertex y ∈ V (T )—then the cut (X, X̄) corresponds to cutting subtrees T1, . . . ,Ts from a vertex x in T . Every vertex u ∈ X ∩V lies in an edge e ∈ X ∩E which is the label λ(x′) for some vertex x′ in a Ti. Now if u is also in an edge e′ ∈ X̄ ∩ E, then u ∈ λ(x) ∈ X̄ ∩ E. Consequently, only one vertex u ∈ X ∩ V can be an end vertex of an induced matching in I(H)[X, X̄ ]. Furthermore, no vertex u in X̄ ∩ V is in an edge e ∈ X ∩ E, because we connected u to the vertex y farthest from the root in the construction of T and thus cutting outside Tx we cannot be in a situation where u /∈ X. Consequently, the MIM-width of the cut (X, X̄) is at most 1.\nCorollary 30 ([CDM14]). #SAT on hypergraphs with disjoint branches decompositions can be solved in polynomial time.\nProof. Given a CNF-Formula F , compute a disjoint branches decomposition with Theorem 28. Then apply the construction of Lemma 29 to get a branch decomposition of MIM-width at most 2. Now combining Theorem 9 and Theorem 8 yields the results."
    }, {
      "heading" : "5.1.2. Signed incidence cliquewidth",
      "text" : "In this section we use the STV-framework to reprove a result from [FMR08] stating that #SAT is fixed-parameter tractable parameterized by signed cliquewidth. We first state the relevant definitions from [FMR08].\nThe signed incidence graph SI(F ) of a CNF-formula is the incidence graph of F where each edge xC is signed positively or negatively depending on if the variable x appears positively or negatively in the clause C. The set of CNF-formulas of signed cliquewidth at most k is defined as the set of formulas whose signed incidence graph can be obtained by the following operations over graphs whose vertices are coloured by {1, . . . , k}, starting from singleton graphs.\n1. Disjoint union.\n2. Recolouring: For a vertex-coloured signed bipartite graph G, we defined ρi,j(G) to be the graph that results from recolouring with j all vertices that were previously coloured with i.\n3. Positive edge creation: For a vertex-coloured signed bipartite graph G, we define η+i,j(G) to be the graph that results from connecting all clause-vertices coloured i to all variablevertices coloured j, with edges signed positively. We do not add edges between variable vertices coloured i and clause-vertices coloured j, or any other vertices.\n4. Negative edge creation: Similarly to above, we define η−i,j(G) to be the graph resulting from connecting all clause-vertices coloured with i to all variable-vertices coloured with j, with edges signed negatively.\nThe signed cliquewidth of a CNF-formula is the minimum k such that it has signed cliquewidth at most k.\nA parse tree for the signed cliquewidth of a formula F is the rooted tree whose leaves hold singleton graphs, whose internal vertices are coloured with the operations of the definitions above (so a vertex corresponding to a disjoint union has two children, and vertices corresponding to other operations have one child), and whose root holds the graph SI(F ) (with any vertex colouring).\nGiven a signed parse tree of a formula F , we construct iteratively a branch decomposition. We assume w.l.o.g. that whenever we make a union, the graphs whose union we take have only disjoint colors in their vertex coloring. This can be easily achieved by at most doubling the number of colors used. Furthermore, we assume that in the end all vertices have the same color.\nWe construct the branch decomposition along the parse tree iteratively. To this end, we assign a tree Tτ to each sub-parse tree τ . To a singleton v representing a variable of F , we assign a singleton vertex labeled with v. For τ = η+i,j(τ ′) and τ = η−i,j(τ ′) we set Tτ := Tτ ′ . For τ = ρi,j(τ ′) we again let Tτ := Tτ ′ . Finally, for τ = τ1 ∪ τ2 we introduce a new root and connect it to Tτ1 and Tτ2 . Observe that Tτ is essentially the tree we get from τ by forgetting internal labels and contracting all paths to edges. Observe that the result (T, δ) is obviously a branch decomposition.\nLemma 31. (T, δ) has PS-width at most 22k.\nProof. Let v be a cut vertex with the cut (A, Ā). Let X := A ∩ var(F ), X̄ := Ā ∩ var(F ), C := A∩ cla(F ) and C̄ := Ā∩ cla(F ). Let τ be the sub-parse tree which is rooted by the union that led to the introduction of v.\nWe first show that |PS(FX,C̄)| ≤ 2 2k. Observe that when two variables x, x′ ∈ X have the\nsame color in τ , then they must always appear together in every clause in C̄ and their sign must be the same. Call Xi the set of variables in X that are colored by i. Then for every assignment of FX,C̄ the set of satisfied clauses depends only on if there is a variable in Xi that is set to true if Xi appears positively or if there is a variable in Xi set to false if Xi appears negatively. So to get the same precise satisfiability set, we can delete all but two variables from Xi from FX,C̄ . It follows that FX,C̄ has the same precise satisfiability set as a formula with 2k variables. But there are only 22k assignments to 2k variables, so it follows that |PS(FX,C̄)| ≤ 2 2k.\nWe now show that |PS(FX̄,C)| ≤ 2 2k. To this end observe that if two clauses C,C ′ in τ have\nthe same color i, then they will contain the same variables in X̄ and moreover C|X̄ = C ′|X̄ . Thus FX̄,C only has k different clauses, so trivially |PS(FX̄,C)| ≤ 2 2k.\nCorollary 32 ([FMR08]). #SAT on formulas of signed incidence cliquewidth k can be solved in time 2O(k)|F |2 assuming that we are provided a parse tree of width k.\nNote that the runtime bound in [FMR08] cannot be easily compared, because the runtime in [FMR08] depends on the size of the parse tree directly and not on the formula. But both results are fixed-parameter results that singly exponentially depend on k, so they are at least very close."
    }, {
      "heading" : "5.2. Lower bounds on MIM-width and PS-width",
      "text" : "In this section we will prove the promised lower bound on the PS-width of β-acyclic CNFformulas. We start off with a simple Lemma that can be seen as a partial reverse of Lemma 9. We remind the reader that a CNF-formula F is called monotone if all variables appear only positively in F .\nLemma 33. For every bipartite graph G there is a monotone CNF-formula F such that F has the incidence graph G and psw(F ) ≥ 2mimw(G)/2.\nProof. We construct F by choosing arbitrarily one color class of G to represent clauses and the other one to represent variables. This choice then uniquely yields a monotone formula where a clause C contains a variable x if and only if x is connected to C by an edge in G.\nLet (T, δ) be a branch decomposition of G and F . Let t be a vertex of T with cut (A, Ā). Set X := var(F ) ∩A, X̄ := var(F ) ∩ Ā, C := cla(F ) ∩A and C̄ := cla(F ) ∩ Ā. Moreover, let M be a maximum independent matching of G[A, Ā] and let VM be the end vertices of M .\nFirst assume that |C ∩ VM | ≥ |C̄ ∩ VM |. Let C1, . . . , Ck be the clauses in C ∩ VM and let x1, . . . , xk be variables in X̄ ∩ VM . Note that k ≥ |M |/2. Since M is an independent matching, every clause Ci contains exactly one of the variables xj, and we assume w.l.o.g. that Ci contains xi. Let a be an assignment to the xi and let a\n′ be the extended assignment of X̄ that we get by assigning 0 to all other variables. Then a′ satisfies in FX̄,C exactly the clauses Ci for which a(xi) = 1 since the formula is monotone. Since there are 2 k assignments to the xi, we have |PS(FX̄,C)| ≥ 2 k ≥ 2|M |/2.\nFor |C ∩ VM | ≤ |C̄ ∩ VM | it follow symmetrically that |PS(FX,C̄)| ≥ 2 |M |/2.\nConsequently, we have in either case that the PS-width of F is at least 2|M |/2 and the claim follows.\nTo a graph G = (V,E) we define a graph G′ = (V ′, E′) as follows:\n• for every v ∈ V there are two vertices xv, yv ∈ V ′,\n• for every edge e = uv ∈ E there are four vertices pe,u, qe,u, pe,v, qe,v ∈ V ′,\n• every u, v ∈ V we add the edge xvyu to E ′, and\n• for every edge e = uv ∈ E we add the edges pe,uqe,u, pe,vqe,v, xupe,u, yvqe,u, xvpe,v, yuqe,v.\nThese are all vertices and edges of G′.\nLemma 34. G′ is chordal bipartite.\nProof. We have to show that every cycle C in G′ of length at least 6 has a chord. We consider two cases: Assume first that C contains no vertex pe,v and consequently no qe,v either. Then all vertices of C are xv or yv and so C is a cycle in the complete bipartite graph induced by the xv and yv. Clearly, C has a chord then.\nNow assume that C contains a vertex pe,v and consequently also qe,v. Let e = uv. Then C must also contain xv and yu, so xvyu ∈ E ′ is a chord.\nLemma 35. Let G be bipartite. Then tw(G) ≤ 6mimw(G′).\nProof. Let (T ′, δ′) be a branch decomposition of G′. Let A,B ⊆ V (G) be the two colour classes of G. We construct a branch decomposition (T, δ) of G by deleting the leaves labeled with pe,u, qe,u, pe,v, qe,v, and those labeled xv for v ∈ A or with yv for v ∈ B. Then we delete all internal vertices of of T ′ that have become leaves by these deletions until we get a branch decomposition T with the leaves xv for v ∈ B and yv for v ∈ A. For the leaves of T we define δ(t) := v where v ∈ V is such that δ′(t) = xv or δ\n′(t) = yv. The result (T, δ) is a branch decomposition of G.\nLet t be a vertex of T with the corresponding cut (X, X̄). Let M ⊆ E be a matching in G[X, X̄ ]. Let (X ′, X̄ ′) be the cut of t in (T ′, δ′). Let e = uv ∈ M , then xu and yv are on different sides of the cut X ′ and they are connected by the path xupe,uqe,uyv. Consequently, there is at least one edge along this path in G′[X ′, X̄ ′]. Choose one such edge arbitrarily.\nLet M ′ be the set of edges we have chosen for the different edges in M . Let M ′x be the set of edges in M ′ that do not have an end vertex yv and let M ′ y be the set of edges in M\n′ that do not have an end vertex xv. Let M\n′′ be the bigger of these two sets. Since e′ ∈ M ′ can only have an end vertex xv or yu but not both, we have |M ′ x|+ |M ′ y| ≥ |M\n′| and thus |M ′′| ≥ |M ′|/2. We claim that M ′′ is an independent matching in G′. Clearly, M ′ is a matching because M\nis one. Consequently, M ′′ ⊆ M ′ is also a matching. We now show that M ′′ is also independent. By way of contradiction, assume this were not true. Then there must be two adjacent vertices u, v ∈ V ′ that are end vertices of edges in M ′′ but not in the same edge in M ′′. If u = pe′,w for some e′ ∈ E and w ∈ V , then v must be xw. But then by construction of M\n′, the vertex w must be incident to two edges in M which contradicts M being a matching. Similarly, we can rule out that v is qe,w. Thus, u must be xw or yw and v must be xw′ or yw′. Since xw and xw′ are in the same colour class of G′, they are not adjacent. Similarly yw and yw′ are not adjacent. Consequently, we may assume that u = xw and v = yw′. But then they cannot both be an endpoint of an edge in M ′′ by construction of M ′′. Thus M ′′ is independent.\nBy Lemma 7 we know that there is a t ∈ T with cut (X, X̄) such that we can find a matching M of size at least tw(G)3 in G[X, X̄ ]. By the construction above the corresponding cut (X ′, X̄ ′) yields an independent matching of size tw(G)6 in G ′[X ′, X̄ ′]. This completes the proof.\nUsing the connection between vertex expansion and treewidth (see [GM09]) the following lemma is easy to show.\nLemma 36. There is a family G of graphs and constants c > 0 and d ∈ N such that for every G ∈ G the graph G has maximum degree d and we have tw(G) ≥ c|E(G)|.\nCorollary 37. There is a family G′ of chordal bipartite graphs and a constant c such that for every graph G ∈ G we have mimw(G) ≥ c|V (G)|.\nProof. Let G be the class of Lemma 36. We first transform every graph G ∈ G into a bipartite one G1 by subdividing every edge, i.e. by introducing for each edge e = uv a new vertex we and by replacing e by uwe and wev. It is well-known that subdividing edges does not decrease the treewidth of a graph (see e.g. [Die05]), and thus tw(G) ≤ tw(G1). Moreover, |E(G1)| = 2|E(G)|, and thus tw(G1) ≥ 1 2c|E(G1)|. Now let G ′ = {G′1 | G ∈ G}. Then the graphs in G ′ are chordal bipartite by Lemma 34 and the bound on the MIM-width follows by combining Lemma 36 and Lemma 35.\nWe can now easily prove the main result of this section.\nCorollary 38. There is a family of monotone β-acyclic CNF-formulas of PS-width 2Ω(n) where n is the number of variables in the formulas.\nProof. Let F be the class of monotone CNF-formulas having the class G′ of Corollary 37 as its incidence graphs. By Theorem 5 the formulas in F are β-acyclic. Combining the bound on the MIM-width of G′ with Lemma 33 then directly yields the result.\nIt follows that the STV-framework cannot prove subexponential runtime bounds for #SAT on β-acyclic formulas."
    }, {
      "heading" : "6. Conclusion",
      "text" : "We have shown that β-acyclic #SAT can be solved in polynomial time, a question left open in [CDM14]. Our algorithm does not follow the dynamic programming approach that was used in all other structural tractability results that were known before, and as we have seen this is no coincidence. Instead, β-acyclic #SAT lies outside the STV-framework of [STV14] that explains all old results in a uniform way.\nWe close this paper with several open problems that we feel should be explored in the future. First, our algorithm for #SAT is specifically designed for the case of β-acyclic formulas, but we feel that the techniques developed, in particular those of Section 4, might possibly be extended to other classes of hypergraphs that one can characterize by elimination orders. In this direction, it would be interesting to see if hypergraphs of bounded β-hypertree width, a width measure generalizing β-acyclicity proposed in [GP04], can be characterized by elimination orders and if such a characterization can be used to solve #SAT on the respective instances. Note that this case lies outside of the STV-framework, therefore dynamic programming without new ingredients is unlikely to work. Also, even the complexity of deciding SAT on instances of bounded β-hypertree width is an open problem [OPS13].\nIt might also be interesting to generalize our algorithm to solve cases for which we already have polynomial time algorithms. For example, is there any uniform explanation for tractability of bounded cliquewidth #SAT and β-acyclic #SAT, similarly to the way in which the framework of [STV14] explains tractability for all previously known results?\nFinally, we feel that, although we have shown that the STV-framework does not explain all tractability results for #SAT, it is still a framework that should be studied in the future. We believe that there are still many classes to be captured by it in the future and thus we see a\nbetter understanding of the framework as an important goal for future research. One question is the complexity of computing branch decompositions of (approximately) minimal MIM-width or PS-width. Alternatively, one could try to find more classes of bipartite graphs for which one can efficiently compute branch decompositions of small MIM-width. This would then directly extend the knowledge on structural classes of CNF-formulas for which dynamic programming can efficiently solve #SAT."
    } ],
    "references" : [ {
      "title" : "A",
      "author" : [ "G. Ausiello" ],
      "venue" : "D’Atri, and M. Moscarini. Chordality properties on graphs and minimal conceptual connections in semantic data models. J. Comput. Syst. Sci., 33(2):179–202",
      "citeRegEx" : "ADM86",
      "shortCiteRegEx" : null,
      "year" : 1986
    }, {
      "title" : "The complexity of weighted and unweighted #csp",
      "author" : [ "A. Bulatov", "M. Dyer", "L.A. Goldberg", "M. Jalsenius", "M. Jerrum", "D. Richerby" ],
      "venue" : "Journal of Computer and System Sciences, 78(2):681–688, March",
      "citeRegEx" : "BDG+12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Graph Classes: A Survey",
      "author" : [ "A. Brandstädt", "V.B. Le", "J.P. Spinrad" ],
      "venue" : "Society for Industrial and Applied Mathematics, Philadelphia, PA, USA",
      "citeRegEx" : "BLS99",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "A tourist guide through treewidth",
      "author" : [ "H.L. Bodlaender" ],
      "venue" : "Acta Cybern., 11(1-2):1–21",
      "citeRegEx" : "Bod93",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "ArXiv e-prints",
      "author" : [ "J. Brault-Baron. Hypergraph Acyclicity Revisited" ],
      "venue" : "March",
      "citeRegEx" : "Bra14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "STOC ’12",
      "author" : [ "J.-Y. Cai", "X. Chen. Complexity of counting CSP with complex weights. In Proceedings of the Forty-fourth Annual ACM Symposium on Theory of Computing" ],
      "venue" : "page 909–920, New York, NY, USA,",
      "citeRegEx" : "CC12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Hypergraph acyclicity and propositional model counting",
      "author" : [ "F. Capelli", "A. Durand", "S. Mengel" ],
      "venue" : "CoRR, abs/1401.6307",
      "citeRegEx" : "CDM14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Constraint representations and structural tractability",
      "author" : [ "D.A. Cohen", "M.J. Green", "C. Houghton" ],
      "venue" : "Principles and Practice of Constraint Programming - CP 2009, pages 289–303",
      "citeRegEx" : "CGH09",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Graph Theory (Graduate Texts in Mathematics)",
      "author" : [ "R. Diestel" ],
      "venue" : "Springer, August",
      "citeRegEx" : "Die05",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "The complexity of counting homomorphisms seen from the other side",
      "author" : [ "V. Dalmau", "P. Jonsson" ],
      "venue" : "Theor. Comput. Sci., 329(1-3):315–323",
      "citeRegEx" : "DJ04",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Some characterizations of γ and β-acyclicity of hypergraphs",
      "author" : [ "D. Duris" ],
      "venue" : "Inf. Process. Lett., 112(16):617–620",
      "citeRegEx" : "Dur12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Degrees of acyclicity for hypergraphs and relational database schemes",
      "author" : [ "R. Fagin" ],
      "venue" : "Journal of the ACM, 30(3):514–550",
      "citeRegEx" : "Fag83",
      "shortCiteRegEx" : null,
      "year" : 1983
    }, {
      "title" : "Parameterized Complexity Theory",
      "author" : [ "J. Flum", "M. Grohe" ],
      "venue" : "Springer-Verlag New York Inc",
      "citeRegEx" : "FG06",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Counting truth assignments of formulas of bounded tree-width or clique-width",
      "author" : [ "E. Fischer", "J.A. Makowsky", "E.V. Ravve" ],
      "venue" : "Discrete Applied Mathematics, 156(4):511– 529",
      "citeRegEx" : "FMR08",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "A comparison of structural csp decomposition methods",
      "author" : [ "G. Gottlob", "N. Leone", "F. Scarcello" ],
      "venue" : "Artif. Intell., 124(2):243–282",
      "citeRegEx" : "GLS00",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "On tree width",
      "author" : [ "M. Grohe", "D. Marx" ],
      "venue" : "bramble size, and expansion. J. Comb. Theory, Ser. B, 99(1):218–228",
      "citeRegEx" : "GM09",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Hypergraphs in Model Checking: Acyclicity and Hypertree-Width versus Clique-Width",
      "author" : [ "G. Gottlob", "R. Pichler" ],
      "venue" : "SIAM Journal on Computing, 33(2)",
      "citeRegEx" : "GP04",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Satisfiability of acyclic and almost acyclic CNF formulas",
      "author" : [ "S. Ordyniak", "D. Paulusma", "S. Szeider" ],
      "venue" : "Theoretical Computer Science, 481:85–99",
      "citeRegEx" : "OPS13",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Model Counting for CNF Formulas of Bounded Modular Treewidth",
      "author" : [ "D. Paulusma", "F. Slivovsky", "S. Szeider" ],
      "venue" : "30th International Symposium on Theoretical Aspects of Computer Science, STACS 2013, pages 55–66",
      "citeRegEx" : "PSS13",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "On the hardness of approximate reasoning",
      "author" : [ "D. Roth" ],
      "venue" : "Artificial Intelligence, 82(1–2):273 – 302",
      "citeRegEx" : "Rot96",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Algorithms for propositional model counting",
      "author" : [ "M. Samer", "S. Szeider" ],
      "venue" : "Journal of Discrete Algorithms, 8(1):50–64",
      "citeRegEx" : "SS10",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Model Counting for Formulas of Bounded CliqueWidth",
      "author" : [ "F. Slivovsky", "S. Szeider" ],
      "venue" : "Algorithms and Computation - 24th International Symposium, ISAAC 2013, pages 677–687",
      "citeRegEx" : "SS13",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Solving MaxSAT and #SAT on structured CNF formulas",
      "author" : [ "S. Hortemo Sæther", "J.A. Telle", "M. Vatshelle" ],
      "venue" : "CoRR, abs/1402.6485",
      "citeRegEx" : "STV14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "New Width Parameters of Graphs",
      "author" : [ "M. Vatshelle" ],
      "venue" : "PhD thesis, University of Bergen",
      "citeRegEx" : "Vat12",
      "shortCiteRegEx" : null,
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 19,
      "context" : "[Rot96]), so there is also great interest in the problem from a practical point of view.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 19,
      "context" : "monotone 2-CNF-formulas, the problem is #P-hard and in fact even #P-hard to approximate [Rot96].",
      "startOffset" : 88,
      "endOffset" : 95
    }, {
      "referenceID" : 22,
      "context" : "Very recently, Sæther, Telle and Vatshelle, in a striking contribution [STV14], have introduced a new width measure for CNF-formulas, that they call PS-width.",
      "startOffset" : 71,
      "endOffset" : 78
    }, {
      "referenceID" : 22,
      "context" : "Thus they have essentially turned the construction of dynamic programming algorithms into a question of graph theory: If, for a class of formulas, one can efficiently compute decompositions that have small PS-width for all formulas having these graphs, the dynamic programming of [STV14] solves these instances.",
      "startOffset" : 280,
      "endOffset" : 287
    }, {
      "referenceID" : 22,
      "context" : "On the other hand, since, in our opinion, the framework of [STV14] is a very good formalization of dynamic programming, there is likely no efficient dynamic programming algorithm for a class of CNF-formulas, if it does not have decompositions of small PS-width, or if these decompositions cannot be constructed efficiently.",
      "startOffset" : 59,
      "endOffset" : 66
    }, {
      "referenceID" : 17,
      "context" : "The complexity of #SAT for β-acyclic formulas is interesting for several reasons: First, up to this paper, it was the only structural class of formulas for which we know that SAT is tractable [OPS13] without this directly generalizing to a tractability result for #SAT.",
      "startOffset" : 192,
      "endOffset" : 199
    }, {
      "referenceID" : 17,
      "context" : "This is because the algorithm of [OPS13] does not proceed by dynamic programming but uses resolution, a technique that is known to generally not generalize to counting.",
      "startOffset" : 33,
      "endOffset" : 40
    }, {
      "referenceID" : 16,
      "context" : "Moreover, β-acyclicity can be generalized to a width-measure [GP04], so there is hope that a good algorithm for β-acyclic formulas might generalize to wider classes for which even the status for SAT is left as an open problem in [OPS13].",
      "startOffset" : 61,
      "endOffset" : 67
    }, {
      "referenceID" : 17,
      "context" : "Moreover, β-acyclicity can be generalized to a width-measure [GP04], so there is hope that a good algorithm for β-acyclic formulas might generalize to wider classes for which even the status for SAT is left as an open problem in [OPS13].",
      "startOffset" : 229,
      "endOffset" : 236
    }, {
      "referenceID" : 14,
      "context" : "Since decomposition techniques based on hypergraph acyclicity tend to be more general than graph-based techniques [GLS00], this might lead to large, new classes of tractable #SAT-instances.",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 9,
      "context" : "in [DJ04], but since we allow clauses, resp.",
      "startOffset" : 3,
      "endOffset" : 9
    }, {
      "referenceID" : 9,
      "context" : "relations, of unbounded arity, our results and those of [DJ04] are incomparable.",
      "startOffset" : 56,
      "endOffset" : 62
    }, {
      "referenceID" : 17,
      "context" : "Instead of doing dynamic programming along a decomposition, we proceed along a vertex elimination order which is more similar to the approach to SAT in [OPS13].",
      "startOffset" : 152,
      "endOffset" : 159
    }, {
      "referenceID" : 22,
      "context" : "Our second contribution is that we show that our tractability result is not covered by the framework of Sæther, Telle and Vatshelle [STV14], short STV-framework, which—as we show— covers all other known structural tractability results for #SAT.",
      "startOffset" : 132,
      "endOffset" : 139
    }, {
      "referenceID" : 22,
      "context" : "We do this by showing that β-acyclic #SAT-instances may have a PS-width so high that from [STV14] we cannot even get subexponential runtime bounds.",
      "startOffset" : 90,
      "endOffset" : 97
    }, {
      "referenceID" : 22,
      "context" : "If one accepts the framework of [STV14] as a good formalization of dynamic programming—which we do—then the deviation from the usual dynamic programming paradigm is not a coincidence but instead due to the fact that there is no efficient dynamic programming algorithm in the usual style.",
      "startOffset" : 32,
      "endOffset" : 39
    }, {
      "referenceID" : 8,
      "context" : "be found in [Die05].",
      "startOffset" : 12,
      "endOffset" : 19
    }, {
      "referenceID" : 7,
      "context" : "[CGH09].",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "Theorem 5 ([ADM86]).",
      "startOffset" : 11,
      "endOffset" : 18
    }, {
      "referenceID" : 22,
      "context" : "In this section we introduce several width measures on graphs and CNF-formulas that are used when relating our algorithm for β-acyclic #CSPd to the framework of Sæther, Telle and Vatshelle [STV14].",
      "startOffset" : 189,
      "endOffset" : 196
    }, {
      "referenceID" : 23,
      "context" : "For an introduction into this area and many more details see [Vat12].",
      "startOffset" : 61,
      "endOffset" : 68
    }, {
      "referenceID" : 23,
      "context" : "Moreover, it is often convenient to see a branch decomposition as rooted tree, and as this does not change any of the notions we define (see [Vat12]), we generally follow this convention.",
      "startOffset" : 141,
      "endOffset" : 148
    }, {
      "referenceID" : 3,
      "context" : "[Bod93]), it is more convenient for us to work with the strongly related notion of Maximum-Matching-width (short MM-width) introduced by Vatshelle [Vat12].",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 23,
      "context" : "[Bod93]), it is more convenient for us to work with the strongly related notion of Maximum-Matching-width (short MM-width) introduced by Vatshelle [Vat12].",
      "startOffset" : 147,
      "endOffset" : 154
    }, {
      "referenceID" : 22,
      "context" : "Theorem 8 ([STV14]).",
      "startOffset" : 11,
      "endOffset" : 18
    }, {
      "referenceID" : 22,
      "context" : "Theorem 9 ([STV14]).",
      "startOffset" : 11,
      "endOffset" : 18
    }, {
      "referenceID" : 23,
      "context" : "In fact, even the complexity of deciding if a given graph has MIM-width 1 in polynomial time is left as an open problem in [Vat12].",
      "startOffset" : 123,
      "endOffset" : 130
    }, {
      "referenceID" : 22,
      "context" : "In this section we compare our algorithmic result for #SAT on β-acyclic hypergraphs to the framework proposed by Sæther, Telle and Vatshelle in [STV14] which we call short the STVframework.",
      "startOffset" : 144,
      "endOffset" : 151
    }, {
      "referenceID" : 22,
      "context" : "We first show that the STV-framework gives a uniform explanation of all tractability results for #SAT in the literature, extending the results of [STV14].",
      "startOffset" : 146,
      "endOffset" : 153
    }, {
      "referenceID" : 20,
      "context" : "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] γ-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] β-acyclic FP (this paper)",
      "startOffset" : 51,
      "endOffset" : 57
    }, {
      "referenceID" : 20,
      "context" : "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] γ-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] β-acyclic FP (this paper)",
      "startOffset" : 82,
      "endOffset" : 88
    }, {
      "referenceID" : 18,
      "context" : "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] γ-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] β-acyclic FP (this paper)",
      "startOffset" : 125,
      "endOffset" : 132
    }, {
      "referenceID" : 18,
      "context" : "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] γ-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] β-acyclic FP (this paper)",
      "startOffset" : 136,
      "endOffset" : 143
    }, {
      "referenceID" : 13,
      "context" : "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] γ-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] β-acyclic FP (this paper)",
      "startOffset" : 177,
      "endOffset" : 184
    }, {
      "referenceID" : 17,
      "context" : "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] γ-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] β-acyclic FP (this paper)",
      "startOffset" : 215,
      "endOffset" : 222
    }, {
      "referenceID" : 21,
      "context" : "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] γ-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] β-acyclic FP (this paper)",
      "startOffset" : 226,
      "endOffset" : 232
    }, {
      "referenceID" : 22,
      "context" : "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] γ-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] β-acyclic FP (this paper)",
      "startOffset" : 246,
      "endOffset" : 253
    }, {
      "referenceID" : 6,
      "context" : "class lower bound upper bound primal treewidth FPT [SS10] incidence treewidth FPT [SS10] modular incidence treewidth W1-hard [PSS13] XP [PSS13] signed incidence cliquewidth FPT [FMR08] incidence cliquewidth W1-hard [OPS13] XP [SS13] MIM-width XP [STV14] γ-acyclic FP [GP04, SS13] disjoint branches FP [CDM14] β-acyclic FP (this paper)",
      "startOffset" : 301,
      "endOffset" : 308
    }, {
      "referenceID" : 12,
      "context" : "[FG06].",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 23,
      "context" : "In [Vat12] it is shown that MIM-width is bounded by cliquewidth, so nearly all tractability results of Table 1 follow from [STV14].",
      "startOffset" : 3,
      "endOffset" : 10
    }, {
      "referenceID" : 22,
      "context" : "In [Vat12] it is shown that MIM-width is bounded by cliquewidth, so nearly all tractability results of Table 1 follow from [STV14].",
      "startOffset" : 123,
      "endOffset" : 130
    }, {
      "referenceID" : 6,
      "context" : "In this section we show how the tractability of #SAT on hypergraphs with a disjoint branches decomposition proved in [CDM14] can be explained by the STV-framework.",
      "startOffset" : 117,
      "endOffset" : 124
    }, {
      "referenceID" : 10,
      "context" : "Hypergraphs with disjoint branches decompositions are a strict subclass of β-acyclic hypergraphs [Dur12].",
      "startOffset" : 97,
      "endOffset" : 104
    }, {
      "referenceID" : 6,
      "context" : "[CDM14] There is an algorithm that, given a hypergraph H, in time polynomial in ‖H‖ compute a disjoint branches decomposition of H if one exists and rejects otherwise.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 6,
      "context" : "Corollary 30 ([CDM14]).",
      "startOffset" : 14,
      "endOffset" : 21
    }, {
      "referenceID" : 13,
      "context" : "In this section we use the STV-framework to reprove a result from [FMR08] stating that #SAT is fixed-parameter tractable parameterized by signed cliquewidth.",
      "startOffset" : 66,
      "endOffset" : 73
    }, {
      "referenceID" : 13,
      "context" : "We first state the relevant definitions from [FMR08].",
      "startOffset" : 45,
      "endOffset" : 52
    }, {
      "referenceID" : 13,
      "context" : "Corollary 32 ([FMR08]).",
      "startOffset" : 14,
      "endOffset" : 21
    }, {
      "referenceID" : 13,
      "context" : "Note that the runtime bound in [FMR08] cannot be easily compared, because the runtime in [FMR08] depends on the size of the parse tree directly and not on the formula.",
      "startOffset" : 31,
      "endOffset" : 38
    }, {
      "referenceID" : 13,
      "context" : "Note that the runtime bound in [FMR08] cannot be easily compared, because the runtime in [FMR08] depends on the size of the parse tree directly and not on the formula.",
      "startOffset" : 89,
      "endOffset" : 96
    }, {
      "referenceID" : 15,
      "context" : "Using the connection between vertex expansion and treewidth (see [GM09]) the following lemma is easy to show.",
      "startOffset" : 65,
      "endOffset" : 71
    }, {
      "referenceID" : 8,
      "context" : "[Die05]), and thus tw(G) ≤ tw(G1).",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 6,
      "context" : "We have shown that β-acyclic #SAT can be solved in polynomial time, a question left open in [CDM14].",
      "startOffset" : 92,
      "endOffset" : 99
    }, {
      "referenceID" : 22,
      "context" : "Instead, β-acyclic #SAT lies outside the STV-framework of [STV14] that explains all old results in a uniform way.",
      "startOffset" : 58,
      "endOffset" : 65
    }, {
      "referenceID" : 16,
      "context" : "In this direction, it would be interesting to see if hypergraphs of bounded β-hypertree width, a width measure generalizing β-acyclicity proposed in [GP04], can be characterized by elimination orders and if such a characterization can be used to solve #SAT on the respective instances.",
      "startOffset" : 149,
      "endOffset" : 155
    }, {
      "referenceID" : 17,
      "context" : "Also, even the complexity of deciding SAT on instances of bounded β-hypertree width is an open problem [OPS13].",
      "startOffset" : 103,
      "endOffset" : 110
    }, {
      "referenceID" : 22,
      "context" : "For example, is there any uniform explanation for tractability of bounded cliquewidth #SAT and β-acyclic #SAT, similarly to the way in which the framework of [STV14] explains tractability for all previously known results? Finally, we feel that, although we have shown that the STV-framework does not explain all tractability results for #SAT, it is still a framework that should be studied in the future.",
      "startOffset" : 158,
      "endOffset" : 165
    } ],
    "year" : 2014,
    "abstractText" : "We extend the knowledge about so-called structural restrictions of #SAT by giving a polynomial time algorithm for β-acyclic #SAT. In contrast to previous algorithms in the area, our algorithm does not proceed by dynamic programming but works along an elimination order, solving a weighted version of constraint satisfaction. Moreover, we give evidence that this deviation from more standard algorithm is not a coincidence, but that there is likely no dynamic programming algorithm of the usual style for β-acyclic #SAT.",
    "creator" : "LaTeX with hyperref package"
  }
}