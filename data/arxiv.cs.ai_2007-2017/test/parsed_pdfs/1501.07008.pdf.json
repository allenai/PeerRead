{
  "name" : "1501.07008.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A distance-based decision in the credal level",
    "authors" : [ "Amira Essaid", "Arnaud Martin", "Grégory Smits", "Boutheina Ben Yaghlane" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 1.\n07 00\n8v 1\n[ cs\n.A I]\n2 8\nJa n\n20 15\nKeywords: belief function theory, imprecise decision, distance"
    }, {
      "heading" : "1 Introduction",
      "text" : "Belief function theory [2,9] allows us to represent all kinds of ignorance and offers rules for combining several imperfect information provided by different sources in order to get a more coherent one. The combination process helps to make decisions later. Decision making consists in selecting, for a given problem, the most suitable actions to take. Today, we are often confronted with the challenge of making decisions in cases where information is imprecise or even not available. In [12], Smets proposed the transferable belief model (TBM) as an interpretation of the theory of belief functions. The TBM emphasizes a distinction between knowledge modeling and decision making. Accordingly, we distinguish the credal level and the pignistic level. In the credal level, knowledge is represented as belief functions and then combined. The pignistic level corresponds to decision making, a stage in which belief functions are transformed into probability functions.\nThe pignistic probability, the maximum of credibility and the maximum of plausibility are rules that allow a decision on a singleton of the frame of discernment. Sometimes and depending on application domains, it seems to be more convenient to decide on composite hypotheses rather than a simple one. In the literature, there are few works that propose a rule or an approach for making decision on a union of hypotheses [4,1,8]. Recently, we proposed a decision rule based on a distance measure [6]. This rule calculates the distance between a combined mass function and a categorical one. The most likely hypothesis to\nchoose is the hypothesis whose categorical mass function is the nearest to the combined one.\nThe main topic of this paper is to demonstrate that our proposed decision rule is a particular case of that detailed in [4] and to extend our rule so that it becomes able to give decisions even with no categorical mass functions. We present also our experiments on mass functions generated randomly as well as on real databases.\nThe remainder of this paper is organized as follows: in section 2 we recall the basic concepts of belief function theory. Section 3 presents our decision rule based on a distance measure proposed in [6]. In section 4, we demonstrate that our proposed rule is a particular case of that proposed in [4]. Section 5 presents experiments and the main results. Section 6 concludes the paper."
    }, {
      "heading" : "2 The theory of belief functions",
      "text" : "The theory of belief functions [2,9] is a general mathematical framework for representing beliefs and reasoning under uncertainty. In this section, we recall some concepts of this theory.\nThe frame of discernment Θ = {θ1, θ2, . . . , θn} is a set of n elementary hypotheses related to a given problem. These hypotheses are exhaustive and mutually exclusive. The power set of Θ, denoted by 2Θ is the set containing singleton hypotheses of Θ, all the disjunctions of these hypotheses as well as the empty set.\nThe Basic belief assignment (bba), denoted by m is a mass function defined on 2Θ. It affects a value from [0, 1] to each subset. It is defined as:\n∑\nA⊆2Θ\nm(A) = 1. (1)\nA focal element A is an element of 2Θ such that m(A) > 0. A categorical bba is a bba with a unique focal element such that m(A) = 1. When this focal element is a disjunction of hypotheses then the bba models imprecision.\nBased on the basic belief assignment, other belief functions (credibility function ad plausibility function) can be deduced.\n– Credibility function bel(A) expresses the total belief that one allocates to A. It is a mapping from elements of 2Θ to [0, 1] such that:\nbel(A) = ∑\nB⊆A,B 6=∅\nm(B). (2)\n– Plausibility function pl(A) is defined as:\npl(A) = ∑\nA∩B 6=∅\nm(B). (3)\nThe plausibility function measures the maximum amount of belief that supports the proposition A by taking into account all the elements that do not contradict. The value pl(A) quantifies the maximum amount of belief that might support a subset A of Θ.\nThe theory of belief function is a useful tool for data fusion. In fact, for a given problem and for the same frame of discernment, it is possible to get a mass function synthesizing knowledge from separate and independent sources of information through applying a combination rule. Mainly, there exists three modes of combination:\n– Conjunctive combination is used when two sources are distinct and fully reliable. In [10], the author proposed the conjunctive combination rule which is defined as:\nm1 ∩©2(A) = ∑\nB∩C=A\nm1(B) ×m2(C). (4)\nThe Dempster’s rule of combination [2] is a normalized form of the rule described previously and is defined as:\nm1⊕2(A) =\n\n   \n   \n∑\nB∩C=A\nm1(B)×m2(C)\n1−\n∑\nB∩C=∅\nm1(B)×m2(C) ∀A ⊆ Θ, A 6= ∅\n0 if A = ∅\n(5)\nThis rule is normalized through 1− ∑\nB∩C=∅\nm1(B)×m2(C) and it works under\nthe closed world assumption where all the possible hypotheses of the studied problem are supposed to be enumerated on Θ.\n– Disjunctive combination: In [11], Smets introduced the disjunctive combination rule which combines mass functions when an unknown source is unreliable. This rule is defined as:\nm1 ∪©2(A) = ∑\nB∪C=A\nm1(B)×m2(C) (6)\n– Mixed combination: In [5], the authors proposed a compromise in order to consider the benefits of the two combination modes previously described. This combination is given for every A ∈ 2Θ by the following formula:\n\n\n\nmDP (A) = m1 ∩©(A) + ∑\nB∩C=∅,B∪C=A\nm1(B)m2(C) ∀A ∈ 2Θ, A 6= ∅\nmDP (∅) = 0 (7)"
    }, {
      "heading" : "3 Decision Making in the theory of belief functions",
      "text" : "In the transferable belief model, decision is made on the pignistic level where the belief functions are transformed into a probability function, named pignistic probability. This latter, noted as BetP is defined for each X ∈ 2Θ, X 6= 0 as:\nbetP (X) = ∑\nY ∈2Θ,Y 6=∅\n|X ∩ Y |\n|Y |\nm(Y )\n1−m(∅) (8)\nwhere |Y | represents the cardinality of Y .\nBased on the obtained pignistic probability, we select the most suitable hypothesis with the maximum BetP. This decision results from applying tools of decision theory [4]. In fact, if we consider an entity represented by a feature vector x. A is a finite set of possible actions A = {a1, . . . , aN} and Θ a finite set of hypotheses, Θ = {θ1, . . . , θM}. An action aj corresponds to the action of choosing the hypothesis θj . But, if we select ai as an action whereas the hypothesis to be considered is rather θj then the loss occurred is λ(ai|θj). The expected loss associated with the choice of the action ai is defined as:\nRbetP (ai|x) = ∑\nθj∈Θ\nλ(ai|θj)BetP (θj). (9)\nThen, the decision consists in selecting the action which minimizes the expected loss. In addition to minimizing pignistic expected loss, other risks are presented in [4].\nDecision can be made on composite hypotheses [1,8]. We present in this paper the Appriou’s rule [1] which helps to choose a solution of a given problem by considering all the elements contained in 2Θ. This approach weights the decision functions (maximum of credibility, maximum of plausibility and maximum of pignistic probability) by an utility function depending on the cardinality of the elements. A ∈ 2Θ is chosen if:\nA = argmax X∈2Θ (md(X)pl(X)) (10)\nwhere md is a mass defined by:\nmd(X) = KdλX\n(\n1\n|X |r\n)\n(11)\nThe value r is a parameter in [0, 1] helping to choose a decision which varies from a total indecision when r is equal to 0 and a decision based on a singleton when r is equal 1. λX helps to integrate the lack of knowledge about one of the elements of 2Θ. Kd is a normalization factor and pl(X) is a plausibility function.\nIn the following, we present our decision rule based on a distance measure."
    }, {
      "heading" : "4 Decision rule based on a distance measure",
      "text" : "In [6], we proposed a decision rule based on a distance measure. It is defined as:\nA = argmin(d(mcomb,mA)) (12)\nThis rule aims at deciding on a union of singletons. It is based on the use of categorical bba which helps to adjust the degree of imprecision that has to be kept when deciding. Depending on cases, we can decide on unions of two elements or three elements, etc. The rule calculates the distance between a combined bba mcomb and a categorical onemA . The minimum distance is kept and the decision corresponds to the categorical bba’s element having the lowest distance with the combined bba. The rule is applied as follows:\n– We consider the elements of 2Θ. In some applications, 2Θ can be of a large cardinality. For this reason, we may choose some elements to work on. For example, we can keep the elements of 2Θ whose cardinality is less or equal to 2. – For each selected element, we construct its corresponding categorical bba. – Finally, we apply Jousselme distance [7] to calculate the distance between\nthe combined bba and a categorical bba. The distance with the minimum value is kept. The most likely hypothesis to select is the hypothesis whose categorical bba is the nearest to the combined bba.\nJousselme distance is defined for two bbas m1 and m2 as follows:\nd(m1,m2) =\n√\n1 2 (m1 −m2)tD(m1 −m2) (13)\nwhere D is a matrix based on Jaccard distance as a similarity measure between focal elements. This matrix is defined as:\nD(A,B) =\n{\n1 if A=B=∅ |A∩B| |A∪B| ∀A,B ∈ 2 Θ (14)\nIn this paper, we propose to apply the rule through two different manners:\n– Distance type 1 is calculated with categorical bbas (m(A) = 1) for all elements of 2Θ except Θ to have an imprecise result rather than a total ignorance. – Distance type 2 is calculated with simple bbas such as m(A) = α, m(Θ) = 1− α.\nIn the following, we show that our proposed rule can be seen as a particular case of that proposed in section 3.\nJousselme distance can be written as:\nd(m1,m2) = 1\n2\n∑\nY⊆Θ\n∑\nX⊆Θ\n|X ∩ Y | |X ∪ Y | m(X)m(Y ) (15)\nIf we consider the expected loss of choosing ai, then it can be written as:\nRbetP (ai|x) = ∑\nY ∈Θ\nλ(ai|Y )BetP (Y ).\nRbetP (ai|x) = ∑\nY ∈Θ\nλ(ai|Y ) ∑\nX∈Θ\n|X ∩ Y |\n|X |\nm(X)\n1−m(∅) .\nRbetP (ai|x) = ∑\nY ∈Θ\n∑\nX∈Θ\nλ(ai|Y ) |X ∩ Y |\n|X |\nm(X)\n1−m(∅) .\n(16)\nThe equation relative to decision is equal to that for the risk for a value of λ that has to be equal to:\nλ(ai|Y ) = |X |(1−m(∅))\n|X ∪ Y | m(X) (17)\nIn this section, we showed that for a particular value of λ, our proposed decision rule can be considered as a particular case of that proposed in [4]. In the following section, we give experiments and present comparisons between our decision rule based on a distance measure and that presented in [1]."
    }, {
      "heading" : "5 Experiments",
      "text" : ""
    }, {
      "heading" : "5.1 Experiments on generated mass functions",
      "text" : "We tested the proposed rule [6] on a set of mass functions generated randomly. To generate the bbas, one needs to specify the cardinality of the frame of discernment, the number of mass functions to be generated as well as the number of focal elements. The generated bbas are then combined. We use the Dempster’s rule of combination, the disjunctive rule and the mixed rule. Suppose we have a frame of discernment represented as Θ = {θ1, θ2, θ3} and three different sources for which we generate their corresponding bbas as given in Table 1.\nOnce the combination is performed, we can make decision. In Table 3, we compare between the results of three decision rules, namely the pignistic probability, the Appriou’s rule with r equal to 0.5 as well as our proposed decision rule based on distance measure.\nTable 3 shows the decision results obtained after applying some combination rules. We depict from this table that not all the time the rule proposed by Appriou gives a decision on a composite hypotheses. In fact, as shown in Table 3, the application of disjunctive rule as well as the mixed rule lead to a decision on a singleton which is θ1. This is completely different from what we obtain when we apply our proposed rule which promotes a decision on union of singletons when combining bbas. The obtained results seems to be convenient especially that the disjunctive and the mixed rules help to get results on unions of singletons."
    }, {
      "heading" : "5.2 Experiments on real databases",
      "text" : "To test our proposed decision rule, we do some experiments on real databases (IRIS1 and HaberMan’s survival2). Iris is a dataset contaning 150 instances, 4 attributes and 3 classes where each class refers to a type of iris plant. HaberMan is a dataset containing results study conducted at the University of Chicago’s Billings Hospital on the survival of patients who had undergone surgery for breast cancer. This dataset contains 306 instances, 3 attributes and 2 classes\n1 http://archive.ics.uci.edu/ml/datasets/Iris 2 http://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival\n(1: patient survived 5 years or longer, 2: patient died within 5 years). For the classification, our experiments are handled in two different manners.\n– First, we apply the k-NN classifier [3]. The results are illustrated in a confusion matrix as shown in Table 4 (left side). – Second, we modify the k-NN classifier’s algorithm based on the use of Dempster rule of combination, to make it able to combine belief functions through the mixed rule. Then, Appriou’s rule and our proposed decision rule are applied to make decision. Results are illustrated in Table 4.\nThe same tests are done for HaberMan’s survival dataset. The results of applying k-NN classifier, Appriou’s rule and our decision rule are given respectively in Table 5. For the classification of 40 sets chosen randomly from Iris, we remark that with the k-NN classifier, all the sets having θ1 and θ3 as corresponding classes are well classified and only two originally belonging to class θ2 were classified as θ3. Appriou’s rule gives a good classification for sets originally belonging to classes θ1 and θ2 and thus promoting a result on singletons rather than on a union of singletons.\nConsidering the results obtained when applying our decision rule based on a distance type 1, we note that only 2 sets are not well classified and that 3 have θ2 ∪ θ3 as a class. The obtained results are good because our method is based on an imprecise decision which is underlined by the fact of obtaining θ2 ∪ θ3 as a class.\nConsidering HaberMan’s survival dataset, we note that the k-NN classifier, Appriou’s rule as well as our decision rule give the same results where among the sets originally belonging to θ1, 34 are well classified and among the 18 belonging to θ2, only 6 are well classified. We obtain the same results as the other rules\nbecause the HaberMan’s survival dataset has only two classes and our method is based on getting imprecise decisions and excluding the ignorance.\nAll the experiments given previously are based on the use of distance type 1. The results shown below are based on distance type 2. In fact, we consider a simple bba and each time, we assign a value α to an element of 2Θ. The tested rule on Iris as illustrated in Table 6 (left side) gives better results with an α < 0.8. In addition to that, we obtained decisions on a union of singletons. The tests done on HaberMan’s survival as given in Table 6 (right side) shows that with α > 0.5, we obtain a better rate of good classification although we did not obtain a good classification for the class θ2 and no set belongs to Θ. We aim in the future to make experiments on other datasets because HaberMan’s survival, for example, does only have 2 classes, so we do not have enough imprecise elements."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we presented a rule based on a distance measure. This decision rule helps to choose the most likely hypothesis based on the calculation of the distance between a combined bba and a categorical bba. The aim of the proposed decision rule is to give results on composite hypotheses. In this paper, we demonstrated that our proposed rule can be seen as a particular case of that proposed in [4]. We presented also the different experiments handled on generated mass functions as well as on real databases."
    } ],
    "references" : [ {
      "title" : "Approche générique de la gestion de l’incertain dans les processus de fusion multisenseur",
      "author" : [ "A. Appriou" ],
      "venue" : "Traitement du Signal",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2005
    }, {
      "title" : "Upper and Lower probabilities induced by a multivalued mapping",
      "author" : [ "A.P. Dempster" ],
      "venue" : "Annals of Mathematical Statistics,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1967
    }, {
      "title" : "Representation and combination of uncertainty with belief functions and possibility measures",
      "author" : [ "D. Dubois", "H. Prade" ],
      "venue" : "Computational Intelligence,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1988
    }, {
      "title" : "Uncertainty in ontology matching: a decision rule based approach",
      "author" : [ "A. Essaid", "A. Martin", "G. Smits", "B. Ben Yaghlane" ],
      "venue" : "In proceeding of the International Conference on Information Processing and Mangement Uncertainty,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2014
    }, {
      "title" : "A New Distance Between Two Bodies of Evidence",
      "author" : [ "A.L. Jousselme", "D. Grenier", "E. Bossé" ],
      "venue" : "Information Fusion,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2001
    }, {
      "title" : "Decision support with belief functions theory for seabed characterization",
      "author" : [ "A. Martin", "I. Quidu" ],
      "venue" : "In proceeding of the International Conference on Information Fusion,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "A mathematical theory of evidence",
      "author" : [ "G. Shafer" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1976
    }, {
      "title" : "The Combination of Evidence in the Transferable Belief Model",
      "author" : [ "P. Smets" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1990
    }, {
      "title" : "Belief functions: The disjunctive rule of combination and the generalized Bayesian theorem",
      "author" : [ "P. Smets" ],
      "venue" : "International Journal of Approximate Reasoning,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1993
    }, {
      "title" : "The Transferable Belief Model",
      "author" : [ "P. Smets", "R. Kennes" ],
      "venue" : "Artificial Intelligent",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1994
    }, {
      "title" : "On the Dempster-Shafer framework and new combination rules",
      "author" : [ "R.R. Yager" ],
      "venue" : "Information Sciences,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1987
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "In [6], we proposed a decision rule based on a distance measure.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 1,
      "context" : "1 Introduction Belief function theory [2,9] allows us to represent all kinds of ignorance and offers rules for combining several imperfect information provided by different sources in order to get a more coherent one.",
      "startOffset" : 38,
      "endOffset" : 43
    }, {
      "referenceID" : 6,
      "context" : "1 Introduction Belief function theory [2,9] allows us to represent all kinds of ignorance and offers rules for combining several imperfect information provided by different sources in order to get a more coherent one.",
      "startOffset" : 38,
      "endOffset" : 43
    }, {
      "referenceID" : 9,
      "context" : "In [12], Smets proposed the transferable belief model (TBM) as an interpretation of the theory of belief functions.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "In the literature, there are few works that propose a rule or an approach for making decision on a union of hypotheses [4,1,8].",
      "startOffset" : 119,
      "endOffset" : 126
    }, {
      "referenceID" : 5,
      "context" : "In the literature, there are few works that propose a rule or an approach for making decision on a union of hypotheses [4,1,8].",
      "startOffset" : 119,
      "endOffset" : 126
    }, {
      "referenceID" : 3,
      "context" : "Recently, we proposed a decision rule based on a distance measure [6].",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 3,
      "context" : "Section 3 presents our decision rule based on a distance measure proposed in [6].",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 1,
      "context" : "2 The theory of belief functions The theory of belief functions [2,9] is a general mathematical framework for representing beliefs and reasoning under uncertainty.",
      "startOffset" : 64,
      "endOffset" : 69
    }, {
      "referenceID" : 6,
      "context" : "2 The theory of belief functions The theory of belief functions [2,9] is a general mathematical framework for representing beliefs and reasoning under uncertainty.",
      "startOffset" : 64,
      "endOffset" : 69
    }, {
      "referenceID" : 0,
      "context" : "It affects a value from [0, 1] to each subset.",
      "startOffset" : 24,
      "endOffset" : 30
    }, {
      "referenceID" : 0,
      "context" : "It is a mapping from elements of 2 to [0, 1] such that: bel(A) = ∑",
      "startOffset" : 38,
      "endOffset" : 44
    }, {
      "referenceID" : 7,
      "context" : "In [10], the author proposed the conjunctive combination rule which is defined as: m1 ∩ ©2(A) = ∑",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 1,
      "context" : "The Dempster’s rule of combination [2] is a normalized form of the rule described previously and is defined as:",
      "startOffset" : 35,
      "endOffset" : 38
    }, {
      "referenceID" : 8,
      "context" : "– Disjunctive combination: In [11], Smets introduced the disjunctive combination rule which combines mass functions when an unknown source is unreliable.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 2,
      "context" : "– Mixed combination: In [5], the authors proposed a compromise in order to consider the benefits of the two combination modes previously described.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 0,
      "context" : "Decision can be made on composite hypotheses [1,8].",
      "startOffset" : 45,
      "endOffset" : 50
    }, {
      "referenceID" : 5,
      "context" : "Decision can be made on composite hypotheses [1,8].",
      "startOffset" : 45,
      "endOffset" : 50
    }, {
      "referenceID" : 0,
      "context" : "We present in this paper the Appriou’s rule [1] which helps to choose a solution of a given problem by considering all the elements contained in 2.",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 0,
      "context" : "The value r is a parameter in [0, 1] helping to choose a decision which varies from a total indecision when r is equal to 0 and a decision based on a singleton when r is equal 1.",
      "startOffset" : 30,
      "endOffset" : 36
    }, {
      "referenceID" : 3,
      "context" : "4 Decision rule based on a distance measure In [6], we proposed a decision rule based on a distance measure.",
      "startOffset" : 47,
      "endOffset" : 50
    }, {
      "referenceID" : 4,
      "context" : "– Finally, we apply Jousselme distance [7] to calculate the distance between the combined bba and a categorical bba.",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 0,
      "context" : "In the following section, we give experiments and present comparisons between our decision rule based on a distance measure and that presented in [1].",
      "startOffset" : 146,
      "endOffset" : 149
    }, {
      "referenceID" : 3,
      "context" : "1 Experiments on generated mass functions We tested the proposed rule [6] on a set of mass functions generated randomly.",
      "startOffset" : 70,
      "endOffset" : 73
    } ],
    "year" : 2015,
    "abstractText" : "Belief function theory provides a flexible way to combine information provided by different sources. This combination is usually followed by a decision making which can be handled by a range of decision rules. Some rules help to choose the most likely hypothesis. Others allow that a decision is made on a set of hypotheses. In [6], we proposed a decision rule based on a distance measure. First, in this paper, we aim to demonstrate that our proposed decision rule is a particular case of the rule proposed in [4]. Second, we give experiments showing that our rule is able to decide on a set of hypotheses. Some experiments are handled on a set of mass functions generated randomly, others on real databases.",
    "creator" : "LaTeX with hyperref package"
  }
}