{
  "name" : "1610.06009.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Constrained Cohort Intelligence using Static and Dynamic Penalty Function Approach for Mechanical Components Design",
    "authors" : [ "Omkar Kulkarni", "Ninad Kulkarni", "Anand J Kulkarni", "Ganesh Kakandikar" ],
    "emails" : [ "kulk0003@uwindsor.ca;", "anand.kulkarni@sitpune.edu.in;", "kulk0003@ntu.edu.sg," ],
    "sections" : [ {
      "heading" : null,
      "text" : "Most of the metaheuristics can efficiently solve unconstrained problems; however, their performance may degenerate if the constraints are involved. This paper proposes two constraint handling approaches for an emerging metaheuristic of Cohort Intelligence (CI). More specifically CI with static penalty function approach (SCI) and CI with dynamic penalty function approach (DCI) are proposed. The approaches have been tested by solving several constrained test problems. The performance of the SCI and DCI have been compared with algorithms like GA, PSO, ABC, d-Ds. In addition, as well as three real world problems from mechanical engineering domain with improved solutions. The results were satisfactory and validated the applicability of CI methodology for solving real world problems.\nKeywords: Cohort Intelligence, Static Penalty Function Approach, Dynamic Penalty Function Approach, Constrained Optimization\n1. Introduction\nIn past few years, several metaheuristics have been proposed in the field of optimization. They include number of nature/bio-inspired optimization techniques such as Evolutionary Algorithms (EAs), Swarm Intelligence (SI), etc. Some of the SI techniques include Particle swarm optimization (PSO), Cuckoo Search Algorithm (CS) (Yang et al. 2009), Grey Wolf Optimizer (GWO) (Mirjalili et al. 2014), Artificial Bee Colony Algorithm (ABC) (Karaboga et al. 2011), Firefly Algorithm (FA) (Fister et.al. 2013), Ant Colony optimization (ACO) (Dorigo et al. 1997), etc. The evolutionary algorithms include Genetic Algorithm (GA) (Mitchell 1996), Differential Evolution (DE) (Storn et al. 2013; Qin et al. 2009), etc.\nCohort intelligence (CI) algorithm is a socio-inspired optimization algorithm proposed by Kulkarni, Durugkar and Kumar in 2013. The algorithm mimics the self-supervised learning behavior of cohort candidates. The cohort here refers to a group of candidates interacting and competing with one another to achieve some individual goal, which is inherently common to all. So far, CI has been applied for solving several unconstrained test problems (Kulkarni et al. 2013). In addition, it was modified using a mutation approach, which expanded the search space and helped CI algorithm jump out of local minima. Also, CI and modified CI (MCI) were hybridized with K-means (Krishnasamy et al. 2014) and applied for solving several data clustering problems. The hybridized approaches exhibited exceedingly improved performance over the other contemporary algorithms such as K-means, Kmeans++, GA, Simulated Annealing (SA), Tabu Search (TS), ACO, Honey-bee mating optimization (HBMO) algorithm, PSO, CI and MCI. The approach of CI was also applied for solving several cases of combinatorial problems such as 0-1 Knapsack problems (Kulkarni et al. 2016). The performance was comparable to other contemporary algorithm such as HS, IHS, NGHS, QICSA and QIHSA (Kulkarni et al. 2016). The approach was also applied for solving traveling salesman problem (Kulkarni et al. 2017). In\naddition, CI was successfully applied for solving large sized combinatorial problems with applications to healthcare, sea-cargo mix problem associated with logistics as well as cross-border supply chain problems (Kulkarni et al. 2016). It is important to mention that CI could handle the constraints using a specially developed probability based approach.\nIt is important to mention that the real world problems are constrained in nature. In order to make CI more generalized and powerful, constraint handling techniques need to be developed and incorporated into it. The most common approach to solve constrained optimization problems is by using a penalty functions methods. The penalty techniques transform a constrained problem into an unconstrained problem by penalizing the objective function when constraints are violated, and then minimize this penalized objective function using unconstrained optimization methods (Arora 2004). There are various penalty based constraint handling approaches developed such as static penalty approach (Homaifar et al. 1994), dynamic penalty approach (Joines & Houck 1994), annealing penalty approach (Michalewicz et al. 1994), superiority of feasible points (Powell et al. 1993), exact penalty function method (Huyer et al. 2003), barrier function methods (Arora 2004) etc. The barrier function methods are the simplest and popular method and are applicable only to the inequality constrained problems. Equality constraints may not be solvable using barrier function methods. Annealing penalty are based on the ideology of simulated annealing algorithm. This penalty approach starts with the separation of all constraints in their sub groups as linear equations, linear inequalities, nonlinear equations and nonlinear inequalities then initiating the starting point that satisfies linear constraints and then the penalty is induced (Michalewicz et al. 1994). Static penalty approach implies penalty at a constant rate whenever the constraint is violated. Dynamic penalty approach implies penalty at a dynamic or increasing rate whenever the constraint is violated. Exact penalty function method is quite promising and effective method (Ma & Zhang 2015). To avoid the difficulty of adding a large value of penalty parameter in the function the exact penalty function is used (Lucidi & Rinaldi 2010). Exact penalty can be known as function having property of recovering an exact solution of the original problem for reasonable finite values of the penalty parameter (Ma & Li 2012).\nThis paper investigates the constraint handling ability of CI with static penalty approach (SCI) and dynamic penalty approach (DCI). In this study, these two methods are preferred due to their advantages over other methods. The static penalty approach is characterized by its simplicity of formulation. Also, the convergence of the solutions is obtained at a faster rate as compared to other penalty function approaches. The dynamic penalty approach required small value of the penalty to be applied at the initial stages; however, as the iterations increase, the penalty also gradually increases (Mezura-Montes et al. 2011). The performance of the SCI and DCI approaches is tested by solving 20 well-known test problems from continuous domain including Pressure Vessel Design problem, Tension-Compression Spring Design problem and Welded Beam Design Problem (Liang et al. 2006; Mezura-Montes et al. 2007). The solutions are compared with several existing techniques. In addition, the Springback effect problem occurring in the automotive punch plate, thinning in connector and thickening in tail cap during the process of deep drawing are successfully solved. This validated the applicability of the proposed SCI and DCI.\nThe remainder of this paper is organized as follows: In Section 2, the framework of CI algorithm\nalong with the SCI and DCI approaches are discussed. In section 3, SCI and DCI experimental evaluations and comparisons are provided. Then in section 4, application of these approaches in mechanical engineering is discussed. Finally, in section 5, conclusions and future work are provided.\n2. Framework of Cohort Intelligence (CI) Algorithm\nCohort Intelligence (CI) algorithm models the ability of candidates in a cohort to self-supervise\nand improve their independent behavior. Every candidate has its own qualities which defines its behavior. In every learning attempt, each candidate tries to improve its own behavior through learning which is possible through interaction and competition with other candidates. In other words, the qualities learned eventually make every candidate improve its behavior. After certain learning attempts, the behavior of every candidate saturates and makes entire cohort converge to a unique behavior.\nThe Framework of the CI algorithm can be explained as follows: Step 1: The qualities of the candidates are referred to as the decision variables in the problem. These\nqualities are randomly generated from within the associated sampling intervals.\nStep 2: The qualities of each candidate define the behavior of the candidate. The behavior of the\ncandidate refers to the objective function is evaluated.\nStep 3: The probability of every candidate of being followed by other candidates is calculated on the\nbasis of its behavior. The candidate with the best behavior has a maximum probability of being followed by other candidates and vice versa.\nStep 4: Each candidate employs roulette wheel approach to follow a behavior in the cohort and further\nimproves its behavior by shrinking/expanding the sampling interval of every quality of the candidate being followed. This constitutes a single learning attempt.\nStep 5: The Algorithm is assumed to have converged on completion of the maximum number of\nlearning attempts or the difference between the behavior of every cohort candidate is not very significant for successive considerable number of learning attempts.\nGeneral Constrained optimization problem: Consider a general constrained problem (in the minimization sense) as follows: Minimize \uD835\uDC53(\uD835\uDC99) = \uD835\uDC53(\uD835\uDC651, … , \uD835\uDC65\uD835\uDC56 , … , \uD835\uDC65\uD835\uDC41) (1) Subject to \uD835\uDC54\uD835\uDC56(\uD835\uDC99) ≤ 0, \uD835\uDC56 = 1 … . \uD835\uDC5B ℎ\uD835\uDC57(\uD835\uDC99) = 0, \uD835\uDC57 = 1 … . \uD835\uDC5A \uD835\uDEF9\uD835\uDC56 \uD835\uDC59\uD835\uDC5C\uD835\uDC64\uD835\uDC52\uD835\uDC5F ≤ \uD835\uDC65\uD835\uDC56 ≤ \uD835\uDEF9\uD835\uDC56 \uD835\uDC62\uD835\uDC5D\uD835\uDC5D\uD835\uDC52\uD835\uDC5F , \uD835\uDC56 = 1, … , \uD835\uDC41.\nIn the context of CI, the variables \uD835\uDC99 = (\uD835\uDC651, … , \uD835\uDC65\uD835\uDC56 , … , \uD835\uDC65\uD835\uDC41) are considered as qualities. The CI optimization procedure begins with the initialization of number of candidates \uD835\uDC36, Sampling interval \uD835\uDEF9\uD835\uDC56 for each quality \uD835\uDC65\uD835\uDC56 , \uD835\uDC56 = 1,2, … , \uD835\uDC41, learning attempt counter \uD835\uDC59 = 1, and setting up of static sampling interval reduction factor \uD835\uDC5F ∈ [0,1], convergence parameter ԑ.\nThe penalty function approach is used to convert a constrained optimization problem into unconstrained optimization problem. Here we use two types of penalty function approaches. They are discussed below.\na. Static Penalty Function Method (Homaifar et al. 1994)\nA simple method to penalize infeasible solutions is to apply a constant penalty to those solutions that violate feasibility in any way. The penalty function for a problem with equality and inequality constraints can be added to form the pseudo-objective function \uD835\uDC53\uD835\uDC5E (\uD835\uDC99) as follows\n\uD835\uDC53\uD835\uDC5E(\uD835\uDC99) = \uD835\uDC53(\uD835\uDC99) + ∑ \uD835\uDC5E\uD835\uDC56 × \uD835\uDC46 × (\uD835\uDC54\uD835\uDC56(\uD835\uDC99)) 2\uD835\uDC5B \uD835\uDC56=1 + ∑ \uD835\uDC35\uD835\uDC57 × \uD835\uDC46 × ℎ\uD835\uDC57(\uD835\uDC99) \uD835\uDC5A \uD835\uDC57=1 (2)\nwhere \uD835\uDC53\uD835\uDC5E(\uD835\uDC99) is the expanded penalized objective function\n\uD835\uDC46 is a penalty imposed for violation of a constraint\n\uD835\uDC5E\uD835\uDC56 = 1, if constraint \uD835\uDC56 is violated.\n\uD835\uDC5E\uD835\uDC56 = 0, if constraint \uD835\uDC56 is satisfied. \uD835\uDC35\uD835\uDC57 = 1, if constraint \uD835\uDC56 is violated. \uD835\uDC35\uD835\uDC57 = 0, if constraint \uD835\uDC56 is satisfied.\n\uD835\uDC5B and \uD835\uDC5A are the number of inequality and equality constraints, respectively. It is illustrated below with one inequality constraint.\n\uD835\uDC40\uD835\uDC56\uD835\uDC5B\uD835\uDC56\uD835\uDC5A\uD835\uDC56\uD835\uDC67\uD835\uDC52 \uD835\uDC53(\uD835\uDC65) = −\uD835\uDC651\uD835\uDC652 (3)\n\uD835\uDC46\uD835\uDC62\uD835\uDC4F\uD835\uDC57\uD835\uDC52\uD835\uDC50\uD835\uDC61 \uD835\uDC61\uD835\uDC5C \uD835\uDC54(\uD835\uDC65) = \uD835\uDC651 + \uD835\uDC652 − 4 ≤ 0\nThe associated pseudo-objective function \uD835\uDC53\uD835\uDC5E(\uD835\uDC99) is as follows:\n\uD835\uDC53\uD835\uDC5E(\uD835\uDC99) = −\uD835\uDC651 ∗ \uD835\uDC652 + ∑ \uD835\uDC5E\uD835\uDC56 × \uD835\uDC46 × (\uD835\uDC651 + \uD835\uDC652 − 4 ) 2\uD835\uDC5B \uD835\uDC56=1 (4)\nIf the constraint is violated the value of the \uD835\uDC5E\uD835\uDC56 will be \uD835\uDC5C\uD835\uDC5B\uD835\uDC52 else, it will be \uD835\uDC67\uD835\uDC52\uD835\uDC5F\uD835\uDC5C. The value of penalty \uD835\uDC46 is chosen based on preliminary trials of the algorithm. As the learning attempts increase the violation of the constraint may decrease and eventually optimum value for the problem is achieved.\nb. Dynamic Penalty Function (Joines & Houck 1994) In this constraint handling technique, the individuals are evaluated based on following formula:\n\uD835\uDC53\uD835\uDC5E(\uD835\uDC99) = \uD835\uDC53(\uD835\uDC99) + ∑ ((\uD835\uDC5E\uD835\uDC58) \uD835\uDEFC × \uD835\uDC46) × (\uD835\uDC54\uD835\uDC56(\uD835\uDC99)) \uD835\uDEFD\uD835\uDC5B \uD835\uDC56=1 (5)\nwhere \uD835\uDEFC \uD835\uDC4E\uD835\uDC5B\uD835\uDC51 \uD835\uDEFD are integer constants.\nIn this approach, initially a very less penalty is applied for infeasible solutions and as the algorithm progresses, penalty is increased in every learning attempt. Here \uD835\uDC5E\uD835\uDC58 is the iteration number which is multiplied by penalty constant \uD835\uDC46; however, it is very sensitive to the parameters \uD835\uDEFC \uD835\uDC4E\uD835\uDC5B\uD835\uDC51 \uD835\uDEFD and the parameters need to be properly tuned based on the preliminary trials of the algorithm. In this technique, the penalty components have a significant effect on the objective function as they increase with every learning attempt. This approach is illustrated below with one inequality constraint.\n\uD835\uDC40\uD835\uDC56\uD835\uDC5B\uD835\uDC56\uD835\uDC5A\uD835\uDC56\uD835\uDC67\uD835\uDC52 \uD835\uDC53(\uD835\uDC65) = −\uD835\uDC651\uD835\uDC652 (7)\n\uD835\uDC46\uD835\uDC62\uD835\uDC4F\uD835\uDC57\uD835\uDC52\uD835\uDC50\uD835\uDC61 \uD835\uDC61\uD835\uDC5C \uD835\uDC54(\uD835\uDC65) = \uD835\uDC651 + \uD835\uDC652 − 4 ≤ 0\nThe associated pseudo-objective function \uD835\uDC53\uD835\uDC5E(\uD835\uDC99) is as follows:\n\uD835\uDC53\uD835\uDC5E(\uD835\uDC99) = −\uD835\uDC651 ∗ \uD835\uDC652 + ∑ (\uD835\uDC5E\uD835\uDC58 \uD835\uDEFC × \uD835\uDC46) × (\uD835\uDC651 + \uD835\uDC652 − 4 ) \uD835\uDEFD\uD835\uDC5B \uD835\uDC56=1 (8)\nThe value of penalty \uD835\uDC46 is set to be a constant; however, it is multiplied by the iteration number \uD835\uDC5E\uD835\uDC58 \uD835\uDEFC so as the iteration increases the value of the penalty also increases. Refer to Figure 1 for CI pseudo code for both the penalty function approaches. The iterative CI procedure solving penalized function \uD835\uDC53\uD835\uDC5E(\uD835\uDC99) is discussed below.\nStep 1: The probability of selecting the behavior \uD835\uDC53\uD835\uDC5E(\uD835\uDC99 \uD835\uDC50) of every associated candidate \uD835\uDC50 (\uD835\uDC50 = 1, . . . , \uD835\uDC36) is calculated as follows:\n\uD835\uDC5D\uD835\uDC50 = 1/\uD835\uDC53\uD835\uDC5E(\uD835\uDC99\n\uD835\uDC50)\n∑ 1/\uD835\uDC53\uD835\uDC5E(\uD835\uDC99 \uD835\uDC50)\uD835\uDC36\uD835\uDC50=1\n\uD835\uDC50 (\uD835\uDC50 = 1, . . . , \uD835\uDC36) (9)\nStep 2: Every candidate \uD835\uDC50 generates a random number \uD835\uDC5F\uD835\uDC4E\uD835\uDC5B\uD835\uDC51 ∈ [0,1] and using a roulette wheel approach decides to follow corresponding behavior \uD835\uDC53\uD835\uDC5E(\uD835\uDC99 \uD835\uDC50~) and associated qualities \uD835\uDC99\uD835\uDC50~ = \uD835\uDC651 \uD835\uDC50~, . . \uD835\uDC65\uD835\uDC56 \uD835\uDC50~, … \uD835\uDC65\uD835\uDC41 \uD835\uDC50~. The superscript ~ indicates that the behavior is selected by candidate c and not\nknown in advance. The roulette wheel approach could be most appropriate as it provides chance to every behavior in the cohort to get selected based on its quality as well as helps to incorporate uncertainty. In addition, it may increase the chances of any candidate to select the better behaviour as the associated probability stake \uD835\uDC5D\uD835\uDC36(\uD835\uDC50 = 1, … , \uD835\uDC36) presented in Eq. (9) in the interval [0, 1] is directly proportional to the quality of the behaviour \uD835\uDC53\uD835\uDC5E(\uD835\uDC99 \uD835\uDC50). In other words, better the solution, higher is the probability of being followed by the candidates in the cohort. Step 3: Every candidate \uD835\uDC50 (\uD835\uDC50 = 1, . . . , \uD835\uDC36) shrinks the sampling interval \uD835\uDF33\uD835\uDC56 \uD835\uDC50~, \uD835\uDC56 = 1,2, . . \uD835\uDC41 associated with every variable \uD835\uDC65\uD835\uDC56 \uD835\uDC50~, \uD835\uDC56 = 1,2, . . \uD835\uDC41 to its local neighborhood. This is done as follows:\n\uD835\uDF33\uD835\uDC56 \uD835\uDC50~ = [\uD835\uDC65\uD835\uDC56 \uD835\uDC50~ −\n‖\uD835\uDEF9\uD835\uDC56 \uD835\uDC62\uD835\uDC5D\uD835\uDC5D\uD835\uDC52\uD835\uDC5F −\uD835\uDEF9\uD835\uDC56 \uD835\uDC59\uD835\uDC5C\uD835\uDC64\uD835\uDC52\uD835\uDC5F‖\n2 × \uD835\uDC5F , \uD835\uDC65\uD835\uDC56\n\uD835\uDC50~ + ‖\uD835\uDEF9\uD835\uDC56\n\uD835\uDC62\uD835\uDC5D\uD835\uDC5D\uD835\uDC52\uD835\uDC5F −\uD835\uDEF9\uD835\uDC56 \uD835\uDC59\uD835\uDC5C\uD835\uDC64\uD835\uDC52\uD835\uDC5F‖\n2 × \uD835\uDC5F ] (10)\nStep 4: Every candidate \uD835\uDC50 (\uD835\uDC50 = 1, . . . , \uD835\uDC36) samples \uD835\uDC61 qualities from within the updated sampling interval \uD835\uDF33\uD835\uDC56 \uD835\uDC50~, \uD835\uDC56 = 1,2, . . \uD835\uDC41 associated with every quality \uD835\uDC65\uD835\uDC56 \uD835\uDC50~, \uD835\uDC56 = 1,2, . . \uD835\uDC41 and computes a set of associated \uD835\uDC61 behaviors, i.e. \uD835\uDC39\uD835\uDC5E \uD835\uDC50,\uD835\uDC61 = {\uD835\uDC53\uD835\uDC5E(\uD835\uDC65 \uD835\uDC50)1, … , \uD835\uDC53\uD835\uDC5E(\uD835\uDC65 \uD835\uDC50 )\uD835\uDC57 , … , \uD835\uDC53\uD835\uDC5E(\uD835\uDC65 \uD835\uDC50 )\uD835\uDC61 } and selects the best behavior \uD835\uDC53\uD835\uDC5E ∗(\uD835\uDC65\uD835\uDC50) from within. This makes the cohort available with \uD835\uDC36 updated behaviors represented as \uD835\uDC39\uD835\uDC5E ∗\uD835\uDC36 = {\uD835\uDC53∗(\uD835\uDC651), … \uD835\uDC53∗(\uD835\uDC65\uD835\uDC50), … \uD835\uDC53∗(\uD835\uDC65\uD835\uDC36 ). Step 5: The cohort behavior could be considered saturated, if there is no significant improvement in the behavior \uD835\uDC53∗(\uD835\uDC99\uD835\uDC50) of every candidate \uD835\uDC50 (\uD835\uDC50 = 1, . . . , \uD835\uDC36) in the cohort, and the difference between the individual behaviors is not very significant for successive considerable number of learning attempts, i.e. if\n1. ‖max(\uD835\uDC39\uD835\uDC5E ∗\uD835\uDC36) \uD835\uDC5B − max(\uD835\uDC39\uD835\uDC5E ∗\uD835\uDC36) \uD835\uDC5B−1 ‖ ≤ \uD835\uDF16, and\n2. ‖min(\uD835\uDC39\uD835\uDC5E ∗\uD835\uDC36) \uD835\uDC5B − min(\uD835\uDC39\uD835\uDC5E ∗\uD835\uDC36) \uD835\uDC5B−1 ‖ ≤ \uD835\uDF16, and\n3. ‖max(\uD835\uDC39\uD835\uDC5E ∗\uD835\uDC36) \uD835\uDC5B − min(\uD835\uDC39\uD835\uDC5E ∗\uD835\uDC36) \uD835\uDC5B ‖ ≤ \uD835\uDF16, every candidate \uD835\uDC50 (\uD835\uDC50 = 1, . . . , \uD835\uDC36) expands the sampling\ninterval \uD835\uDEF9\uD835\uDC56 \uD835\uDC50~, \uD835\uDC56 = 1, … , \uD835\uDC41 associated with every quality \uD835\uDC65\uD835\uDC56 \uD835\uDC50~ , \uD835\uDC56 = 1, . . , \uD835\uDC41 to its original one \uD835\uDEF9\uD835\uDC56 \uD835\uDC59\uD835\uDC5C\uD835\uDC64\uD835\uDC52\uD835\uDC5F ≤ \uD835\uDC65\uD835\uDC56 ≤ \uD835\uDEF9\uD835\uDC56 \uD835\uDC62\uD835\uDC5D\uD835\uDC5D\uD835\uDC52\uD835\uDC5F , \uD835\uDC56 = 1 … , \uD835\uDC41.\nStep 6: If either of the two criteria listed below is valid, accept any of the \uD835\uDC36 behaviors from current set of behaviors in the cohort as the final objective function value \uD835\uDC53∗(\uD835\uDC99) as the final solution and stop, else continue to Step 1.\na) If maximum number of learning attempts exceeded. b) If cohort saturates to the same behavior (satisfying the conditions in Step 5) for significant\nnumber of times.\n3. Experimental Evaluations\nPerformance of SCI and DCI was tested by evaluation of 20 well known test problems (Liang J. J.\net al. 2006, Mezura-Montes et al. 1994). The characteristics of these problems are listed in Table 1. In addition to these test functions, mechanical engineering problems such as like tension compression string, welded beam design and Pressure vessel design were also solved. The SCI and DCI were coded in Matlab (R2014a) on windows 7 platform with I5-3470 Processor 3.2GHZ processor speed and 4GB RAM. Every problem was solved 20 times with the CI parameters chosen as follows: number of candidates \uD835\uDC36 = 5, reduction factor \uD835\uDC5F = 0.9 and convergence factor \uD835\uDF00 = 1\uD835\uDC38 − 11. These parameters were chosen based on the preliminary trials of the algorithm.\nG05 4 Cubic 2 0 0 3\nG06 2 Cubic 0 2 0 0\nG07 10 Quadratic 3 5 0 0\nG08 2 Non-linear 0 2 0 0\nG09 7 Polynomial 0 4 0 0\nG10 8 Linear 3 3 0 0\nG11 2 Quadratic 0 0 0 1\nG12 3 Quadratic 0 1 0 0\nG14 10 Non-linear 0 0 3 0\nG15 3 Quadratic 0 0 1 1\nG17 6 Non-linear 0 0 0 4\nG18 9 Quadratic 0 13 0 0\nG24 2 Linear 0 2 0 0 *LI: linear inequality; NI: nonlinear inequality; LE: linear equality; NE: nonlinear equality\nThe performance of SCI & DCI is compared with the other methods in relevant literature including GA (Mezura-Montes and Coello 2005), PSO (Zavala et al. 2005), ABC (Karaboga et al. 2011) & DynamicDifferential Search algorithm (D-DS) (Jianjun et al. 2015, Mezura-Montes et al. 2007). These selected algorithms have their special qualities which led them in reaching the optimized solutions of the constrained test problems. GA is an optimization algorithm which is based on the Darwin’s theory of evolution. While solving constrained test problems using GA, Deb’s feasibility rules were used as a constraint handling technique which led them overcome infeasible solutions. Similarly, PSO is inspired by social behavior of bird flocking or fish schooling. PSO also used Deb’s feasibility rules for handing constraints. ABC also solved the constrained optimization problems by using static penalty method as a constraint handling technique and this technique was found to be more compatible with the algorithm as it converged quicker and gave optimized solutions. Similarly, D-DS algorithm used dynamic penalty method as a constraint handling technique and the technique was found to be quite effective as the penalty was steadily increasing with increasing number of iterations. Experimental results of CI algorithm over 20 runs are provided in Table 2.\nG07 24.306 24.30437 0.221551 24.3506 0.2135\nG08 0.095825 −0.09583 1.06\uD835\uDC38 − 12 −0.0958 6.23\uD835\uDC38 − 08 G09 680.63 680.6726 0.259831 680.6738 0.2882 G10 7049.25 7051.823 11.55862 7051.9256 15.3881 G11 0.75 0.74965 0.001311 0.7489 0.0011 G12 1.000 −1 1.63\uD835\uDC38 − 12 −1.0000 0.0025\nG14 −47.7649 −47.735 0.20067 −47.7385 0.1630 G15 961.7150 961.7152 0.009111 961.6403 0.2286 G18 −0.8660 −0.86603 0.001221 −0.8660 0.0005 G24 −5.5080 −5.50801 2.3\uD835\uDC38 − 07 −5.5080 2.94\uD835\uDC38 − 07 PV* 6059.86326 5891.588 37.96514 5890.5657 40.4247 TC* 0.0127048 0.012666 0.000453 0.0127 0.0001 WBD* 1.748 2.221102 0.166765 2.2556 0.1044\n*PV = Pressure Vessel Design, TC = Tension Compression Spring Design, WBD = Welded Beam Design.\nAs exhibited in Table 2, SCI and DCI have found solutions in the close neighborhood of the reported optimum solution for most of the problems. The standard deviation (SD) for SCI and DCI was observed to be varying with the variation in the type of problem. It shows that the constraint handling techniques used to solve the problems with equality constraints is not so compatible with CI. Table 3 shows the best solutions by SCI and DCI as well as some other methods. The results show that for problems which have comparatively larger feasible space (refer to Table 1) both SCI and DCI yielded comparative/superior results as compared to other algorithms.\nG14 47.765 \uD835\uDC41\uD835\uDC34 \uD835\uDC41\uD835\uDC34 \uD835\uDC41\uD835\uDC34 47.458 \uD835\uDFD2\uD835\uDFD5. \uD835\uDFD5\uD835\uDFD1\uD835\uDFD3 \uD835\uDFD2\uD835\uDFD5. \uD835\uDFD5\uD835\uDFD1\uD835\uDFD7\nG15 961.715 \uD835\uDC41\uD835\uDC34 \uD835\uDC41\uD835\uDC34 \uD835\uDC41\uD835\uDC34 961.715 \uD835\uDFD7\uD835\uDFD4\uD835\uDFCF. \uD835\uDFD5\uD835\uDFCF\uD835\uDFD3 \uD835\uDFD7\uD835\uDFD4\uD835\uDFCF. \uD835\uDFD4\uD835\uDFD2\uD835\uDFCE\nG17 8853.54 \uD835\uDC41\uD835\uDC34 \uD835\uDC41\uD835\uDC34 \uD835\uDC41\uD835\uDC34 8853.830 \uD835\uDC03\uD835\uDC0D\uD835\uDC02 \uD835\uDFD6\uD835\uDFD7\uD835\uDFCF\uD835\uDFD1. \uD835\uDFD5\uD835\uDFD6\uD835\uDFD4\nG18 −0.866 −0.852 \uD835\uDC41\uD835\uDC34 \uD835\uDC41\uD835\uDC34 −0.866 −\uD835\uDFCE. \uD835\uDFD6\uD835\uDFD4\uD835\uDFD4 −\uD835\uDFCE. \uD835\uDFD6\uD835\uDFD4\uD835\uDFD4\nG24 −5.508 −5.508 \uD835\uDC41\uD835\uDC34 −5.507 −5.508 −\uD835\uDFD3. \uD835\uDFD3\uD835\uDFCE\uD835\uDFD6 −\uD835\uDFD3. \uD835\uDFD3\uD835\uDFCE\uD835\uDFD6\nPV 6059.863 \uD835\uDC41\uD835\uDC34 6059.714 6059.714 \uD835\uDC41\uD835\uDC34 \uD835\uDFD3\uD835\uDFD6\uD835\uDFD7\uD835\uDFCF. \uD835\uDFD3\uD835\uDFD6\uD835\uDFD6 \uD835\uDFD3\uD835\uDFD6\uD835\uDFD7\uD835\uDFCE. \uD835\uDFD3\uD835\uDFD4\uD835\uDFD4\nTC 0.013 \uD835\uDC41\uD835\uDC34 0.013 0.013 \uD835\uDC41\uD835\uDC34 \uD835\uDFCE. \uD835\uDFCE\uD835\uDFCF\uD835\uDFD1 \uD835\uDFCE. \uD835\uDFCE\uD835\uDFCF\uD835\uDFD1\nWBD 1.748 \uD835\uDC41\uD835\uDC34 1.725 1.725 \uD835\uDC41\uD835\uDC34 \uD835\uDFD0. \uD835\uDFD0\uD835\uDFD0\uD835\uDFCF \uD835\uDFD0. \uD835\uDFD0\uD835\uDFD3\uD835\uDFD4\n*NA = Not Available, DNC = Did Not Converge\nIt could be observed that SCI and DCI perform better than GA, PSO, D-DS and ABC algorithms. It is important to mention here that all these problems have inequality type of constraints. Table 4 shows the number of average Function Evaluations (FE) and average time required by SCI and DCI. The table exhibited that with problems with fewer constraints (G08 and G12) and fewer dimensions (G11) fewer average FE and time was required; however, with increasing number of constraints and the dimensions average FE and the computational time increased.\nG14 4920 25.55 12375 98.52\nG15 2550 5.07 12195 37.83\nG17 DNC* DNC* 6475 23.87\nG18 1620 6.59 3210 18.38\nG24 1275 2.6 4345 13.65\nPV 7670 29.377 7455 27.4\nTC 3590 12.18 5235 18.85\nWBD 4865 13.41 4945 17.72\nDNC -Did Not Converge.\nAs an illustration of working mechanism of CI, the convergence plots for SCI and DCI for solving problem G24 is shown in Figure 2(a) and 2(b). These plots indicate that initially, the behavior of the candidates in a cohort is different from one another; however, with increasing learning attempts, the candidates learn by following the behavior of one another, which further led to saturation of the solutions. After the first saturation, the sampling interval associated with every quality/variable is expanded in order to avoid premature convergence and hence find the global optimum. In most of the test problems, the solution obtained on every saturation were quite closer except G04 and G07.\n1. G24 Problem\n4. Application of Cohort Intelligence\nNomenclature\n\uD835\uDC35\uD835\uDC3B\uD835\uDC39 Blank Holder Force (\uD835\uDC41)\n\uD835\uDC45\uD835\uDC37 Radius on Die (\uD835\uDC5A\uD835\uDC5A)\n\uD835\uDC45\uD835\uDC43 Radius on Punch (\uD835\uDC5A\uD835\uDC5A)\nµ Coefficient of Friction\n\uD835\uDC510 Blank Diameter (\uD835\uDC5A\uD835\uDC5A)\n\uD835\uDC511 Finished Component Diameter (\uD835\uDC5A\uD835\uDC5A)\n\uD835\uDC43 Pressure Applied (\uD835\uDC41/\uD835\uDC5A\uD835\uDC5A2)\n\uD835\uDC460 Thickness of the Sheet (\uD835\uDC5A\uD835\uDC5A)\n\uD835\uDC46\uD835\uDC37\uD835\uDC40 Springback Displacement Magnitude\n\uD835\uDC67 Corner Radius (\uD835\uDC5A\uD835\uDC5A)\nIn addition to the mechanical engineering design problems such as Pressure Vessel Design problem, Tension-Compression Spring Design problem and Welded Beam Design Problem, SCI and DCI were successfully applied to solve the Springback effect problem occurring in the automotive punch plate, thinning in connector and thickening in tail cap during the process of deep drawing (Kakandikar 2014). Similar to the above test problems the SCI and DCI were coded in MATLAB (R2014a) on windows 7 platform with intel I5-3470 Processor 3.2GHZ processor speed and 4GB RAM. Similar to the previous\nproblems, every problem was solved 20 times with the CI parameters chosen as follows: number of candidates \uD835\uDC36 = 5, reduction factor \uD835\uDC5F = 0.9 and convergence factor \uD835\uDF00 = 1\uD835\uDC38 − 11. These parameters were chosen based on the preliminary trials of the algorithm.\n4.1. Springback Problem in Punch Plate:\nSpringback is the elastic recovery of the component after the mechanical drawing process is completed. This occurs in all components where the elastic property of the material is present. Springback in any component is a defect which may vary the components dimensions from the desired one. So in any component it should be minimized. The Springback optimization problem of an automotive punch plate in the process of deep drawing is solved by SCI and DCI. The problem is linear with four variables and two inequality constraints."
    }, {
      "heading" : "4.1.1. Component Description",
      "text" : "The component used is Punch Plate for the optimization process. The weight of the component is 90 \uD835\uDC54\uD835\uDC5A\uD835\uDC60. The material used for the component is SPCC steel which is a commercial quality cold rolled steel. Thickness of the material used for the process is 0.8 \uD835\uDC5A\uD835\uDC5A. Yield strength of the material used is 280 \uD835\uDC40\uD835\uDC43\uD835\uDC4E. The ultimate tensile strength of the material is 340 \uD835\uDC40\uD835\uDC43\uD835\uDC4E.\n\uD835\uDC40\uD835\uDC56\uD835\uDC5B\uD835\uDC56\uD835\uDC5A\uD835\uDC56\uD835\uDC67\uD835\uDC52\n\uD835\uDC46\uD835\uDC37\uD835\uDC40 = 0.0488 − 0.000133 × \uD835\uDC35\uD835\uDC3B\uD835\uDC39 − 0.0167 × \uD835\uDF07 + 0.00150 × \uD835\uDC45\uD835\uDC37 + 0.00217 × \uD835\uDC45\uD835\uDC43 (11)\nSubject to 2.5 < \uD835\uDC45\uD835\uDC37 < 8\n3 × \uD835\uDC45\uD835\uDC37 > \uD835\uDC45\uD835\uDC5D > 6 × \uD835\uDC45\uD835\uDC37\nwhere\n\uD835\uDC35\uD835\uDC3B\uD835\uDC39 = \uD835\uDF0B\n4 (\uD835\uDC51\uD835\uDC5C\n2 + 2\uD835\uDC67)2 × \uD835\uDC43 (12)\nwhere \uD835\uDC43 = 2.5 \uD835\uDC41/\uD835\uDC5A\uD835\uDC5A2.\nand \uD835\uDC45\uD835\uDC37 = 0.035 [50 + (\uD835\uDC510 − \uD835\uDC511)√\uD835\uDC460 (13)\n\uD835\uDC45\uD835\uDC43 = (3 \uD835\uDC61\uD835\uDC5C 6) × \uD835\uDC45\uD835\uDC37"
    }, {
      "heading" : "4.1.2. Results obtained",
      "text" : "Table 5 (a) Results Obtained for Original Component (Kakandikar 2014)\nOriginal Component\nSDM 0.07420 \uD835\uDC5A\uD835\uDC5A\nRadius on Die\n(\uD835\uDC45\uD835\uDC37) 2.886 \uD835\uDC5A\uD835\uDC5A\nBlank Holder Force\n(\uD835\uDC35\uD835\uDC3B\uD835\uDC39) 16.931 \uD835\uDC3E\uD835\uDC41\nRadius on Punch\n(\uD835\uDC45\uD835\uDC43) 14.38111 \uD835\uDC5A\uD835\uDC5A\nCoefficient of\nFriction (µ) 0.15\nTable 5 (b) Results by SCI\nFigure 3 (a). Springback displacement magnitude of the original component.\nTable 5 (c) Results by DCI\nModified Component By DCI\nSDM 0.06466 \uD835\uDC5A\uD835\uDC5A\nRadius on Die\n(\uD835\uDC45\uD835\uDC37) 2.858 \uD835\uDC5A\uD835\uDC5A\nBlank Holder Force\n(\uD835\uDC35\uD835\uDC3B\uD835\uDC39) 17.42 \uD835\uDC3E\uD835\uDC41\nRadius on Punch\n(\uD835\uDC45\uD835\uDC43) 8.6049 \uD835\uDC5A\uD835\uDC5A\nCoefficient of\nFriction (µ) 0.14\nThe original component design and associated formulation for the Springback displacement magnitude (SDM) is taken from (Kakandikar 2014). The problem (Eq 11 to 13) is solved using SCI and DCI. The SDM depends on blank holder force, coefficient of friction, radius on die and radius on punch. All these parameters finally depend on variables blank diameter \uD835\uDC51\uD835\uDC5C, finished component diameter \uD835\uDC511 and corner radius \uD835\uDC67. These parameters define the design of the component. The solutions using the SCI and DCI were then used to modify the original component design.\nIt can be observed from the Table 5(a) that the SDM obtained in the original component is 0.07420 \uD835\uDC5A\uD835\uDC5A. The corresponding formability analysis solution performed in FromingSuite version 2015.1.0 software in Figure 3(a). It is observed that the range of the SDM for the component varied from 0.002 \uD835\uDC61\uD835\uDC5C 0.254 \uD835\uDC5A\uD835\uDC5A. The SDM obtained by SCI is 0.06698 \uD835\uDC5A\uD835\uDC5A (refer to Table 5(b)) which indicates that the springback is reduced by 9.73%. Also it can be observed from Figure 3(b) that the reduced component SDM ranges from 0.039 \uD835\uDC61\uD835\uDC5C 0.179 \uD835\uDC5A\uD835\uDC5A which indicates that the average springback through overall component is reduced. Similarly the SDM obtained by DCI is 0.06466 \uD835\uDC5A\uD835\uDC5A (refer to Table 5(c)) indicates that the springback is reduced by 12.85%. Also it can be observed from Figure 3(c) that the SDM for the entire component ranges from 0.034 \uD835\uDC61\uD835\uDC5C 0.164 \uD835\uDC5A\uD835\uDC5A this indicates that the average springback of overall component is reduced.\n4.2. Problem of Thinning in Connector\nThinning is the most common defect occurring in the components manufactured by deep drawing process. It is necessary to minimize thinning in order to maintain the quality of the product and further may reduce the production cost of the material and time. The final objective of deep drawing process in particular or of any sheet metal forming process in general is to produce good quality product, hence uniform thickness should be obtained throughout. The thinning minimization of connector in the process of deep drawing is solved by SCI and DCI.\nFigure 3 (c). Springback displacement magnitude of modified component by DCI"
    }, {
      "heading" : "4.2.1. Component Description",
      "text" : "The weight of the original component was 20 \uD835\uDC54\uD835\uDC5A\uD835\uDC60. The thickness of the sheet was selected as 1 \uD835\uDC5A\uD835\uDC5A. The material used was D 513, SS 4010. The Yield strength of the material was 280 \uD835\uDC40\uD835\uDC43\uD835\uDC4E while the ultimate tensile strength was 360 \uD835\uDC40\uD835\uDC5D\uD835\uDC4E.\n\uD835\uDC40\uD835\uDC56\uD835\uDC5B\uD835\uDC56\uD835\uDC5A\uD835\uDC56\uD835\uDC67\uD835\uDC52\n\uD835\uDC47ℎ\uD835\uDC56\uD835\uDC5B\uD835\uDC5B\uD835\uDC56\uD835\uDC5B\uD835\uDC54 = 1.35 − 0.0400 × \uD835\uDC35\uD835\uDC3B\uD835\uDC39 − 0.733 × \uD835\uDF07 − 0.0300 × \uD835\uDC45\uD835\uDC37 − 0.0183 × \uD835\uDC45\uD835\uDC43 (14)\nSubject to\n2 < \uD835\uDC45\uD835\uDC37 < 4\n3 × \uD835\uDC45\uD835\uDC37 > \uD835\uDC45\uD835\uDC5D > 6 × \uD835\uDC45\uD835\uDC37\nwhere\n\uD835\uDC35\uD835\uDC3B\uD835\uDC39 = \uD835\uDF0B\n4 (\uD835\uDC51\uD835\uDC5C\n2 + 2\uD835\uDC67)2 × \uD835\uDC43 (15)\nwhere \uD835\uDC43 = 2.5 \uD835\uDC41/\uD835\uDC5A\uD835\uDC5A2\nand\n\uD835\uDC45\uD835\uDC37 = 0.035 [50 + (\uD835\uDC510 − \uD835\uDC511)√\uD835\uDC460 (16)\n\uD835\uDC45\uD835\uDC43 = (3 \uD835\uDC61\uD835\uDC5C 6) × \uD835\uDC45\uD835\uDC37"
    }, {
      "heading" : "4.2.2. Results Obtained",
      "text" : "Table 6 (a) Results Obtained for Original Component (Kakandikar 2014)\nOriginal Component\nThinning 0.896 \uD835\uDC5A\uD835\uDC5A\nRadius on Die\n(\uD835\uDC45\uD835\uDC37) 2.52 \uD835\uDC5A\uD835\uDC5A\nBlank Holder Force\n(\uD835\uDC35\uD835\uDC3B\uD835\uDC39)\n3.89 \uD835\uDC3E\uD835\uDC41\nRadius on Punch\n(\uD835\uDC45\uD835\uDC43) 6.16 \uD835\uDC5A\uD835\uDC5A\nCoefficient of\nFriction (µ) 0.15\nFigure 4 (a) Thickness distribution of the original component.\nTable 6 (b) Results by SCI\nModified Component by SCI\nThinning 0.943 \uD835\uDC5A\uD835\uDC5A\nRadius on Die\n(\uD835\uDC45\uD835\uDC37) 2.50 \uD835\uDC5A\uD835\uDC5A\nBlank Holder Force\n(\uD835\uDC35\uD835\uDC3B\uD835\uDC39) 4.01 \uD835\uDC3E\uD835\uDC41\nRadius on Punch\n(\uD835\uDC45\uD835\uDC43) 9.17 \uD835\uDC5A\uD835\uDC5A\nCoefficient of Friction\n(µ)\n0.005\nTable 6 (c) Results by DCI\nThe original component design and mathematical formulation (Eq 14 to 16) for Thinning is taken from Kakandikar 2014. The \uD835\uDC47ℎ\uD835\uDC56\uD835\uDC5B\uD835\uDC5B\uD835\uDC56\uD835\uDC5B\uD835\uDC54 is solved using SCI and DCI. The \uD835\uDC47ℎ\uD835\uDC56\uD835\uDC5B\uD835\uDC5B\uD835\uDC56\uD835\uDC5B\uD835\uDC54 (refer to Eq 14) depends on blank holder force, coefficient of friction, radius on die and radius on punch. All these parameters finally depend on variables blank diameter \uD835\uDC51\uD835\uDC5C, finished component diameter \uD835\uDC511 and corner radius \uD835\uDC67. These parameters define the design of the component. The solutions using the SCI and DCI are then used to modify the original component design.\nIt can be observed from Table 6(a) that the \uD835\uDC47ℎ\uD835\uDC56\uD835\uDC5B\uD835\uDC5B\uD835\uDC56\uD835\uDC5B\uD835\uDC54 value obtained in the original component is 0.896 \uD835\uDC5A\uD835\uDC5A. The corresponding formability analysis solution performed in FromingSuite version 2015.1.0 software is shown in Figure 4(a). It is observed that the range of the thickness distribution in the overall component varies from 0.747 \uD835\uDC61\uD835\uDC5C 1.110 \uD835\uDC5A\uD835\uDC5A. The thickness obtained from solving by SCI is 0.943 \uD835\uDC5A\uD835\uDC5A (refer to Table 6(b)) indicates that the thickness is increased by 5.24%. also it can be\nFigure 4 (b) Thickness distribution of the modified component by SCI.\nobserved from Figure 4(b) that the overall component thickness distribution range is reduced from 0.745 \uD835\uDC61\uD835\uDC5C 1.109 \uD835\uDC5A\uD835\uDC5A which indicates that the overall thickness is increased. Similarly, the thickness obtained by DCI is 0.969 \uD835\uDC5A\uD835\uDC5A as shown in Table 6(c) this indicates that the thickness is increased by 8.45%. Also it can be observed from Figure 4(c) that the whole component thickness distribution ranges from 0.745 \uD835\uDC61\uD835\uDC5C 1.109 \uD835\uDC5A\uD835\uDC5A. It indicates that the average thickness in overall component is increased."
    }, {
      "heading" : "4.3. Thickening Problem in Tail Cap",
      "text" : "Thickening is one of the major defect occurring in the components manufactured by deep drawing process. It is necessary to minimize thickening in order to maintain the quality of the product. Determination of the thickness distribution and of the thinning of the sheet metal blank reduces the production cost of the material and time. The final objective of deep drawing process in particular or of any sheet metal forming process in general is to produce good quality product, hence uniform thickness should be obtained throughout. The thickening minimization of tail cap in the process of deep drawing was solved by SCI and DCI."
    }, {
      "heading" : "4.3.1. Component Description",
      "text" : "The weight of the original component was found to be 20 grams. The thickness of the sheet selected is 1.2 \uD835\uDC5A\uD835\uDC5A. The material used is D 513, SS 4010. The Yield strength of the material is 250 \uD835\uDC40\uD835\uDC43\uD835\uDC4E while the ultimate tensile strength was 350 \uD835\uDC40\uD835\uDC5D\uD835\uDC4E. \uD835\uDC47ℎ\uD835\uDC56\uD835\uDC50\uD835\uDC58\uD835\uDC52\uD835\uDC5B\uD835\uDC56\uD835\uDC5B\uD835\uDC54 = 1.278 + 0.00180 × \uD835\uDC35\uD835\uDC3B\uD835\uDC39 + 0.043 × \uD835\uDF07 − 0.0167 × \uD835\uDC45\uD835\uDC37 − 0.0000 × \uD835\uDC45\uD835\uDC43 (17)\nSubject to\n2 < \uD835\uDC45\uD835\uDC37 < 4\n3 × \uD835\uDC45\uD835\uDC37 > \uD835\uDC45\uD835\uDC5D > 6 × \uD835\uDC45\uD835\uDC37\nwhere\n\uD835\uDC35\uD835\uDC3B\uD835\uDC39 = \uD835\uDF0B\n4 (\uD835\uDC51\uD835\uDC5C\n2 + 2\uD835\uDC67)2 × \uD835\uDC43 (18)\nwhere \uD835\uDC43 = 2.5 \uD835\uDC41/\uD835\uDC5A\uD835\uDC5A2\nand\n\uD835\uDC45\uD835\uDC37 = 0.035 [50 + (\uD835\uDC510 − \uD835\uDC511)√\uD835\uDC460 (19)\n\uD835\uDC45\uD835\uDC43 = (3 \uD835\uDC61\uD835\uDC5C 6) × \uD835\uDC45\uD835\uDC37"
    }, {
      "heading" : "4.3.2. Results Obtained",
      "text" : "Table 7 (c) Results by DCI\nModified Component\nThickness 1.268 \uD835\uDC5A\uD835\uDC5A\nRadius on Die\n(\uD835\uDC45\uD835\uDC37) 3.85 \uD835\uDC5A\uD835\uDC5A\nBlank Holder Force\n(\uD835\uDC35\uD835\uDC3B\uD835\uDC39) 23.23 \uD835\uDC3E\uD835\uDC41\nRadius on Punch\n(\uD835\uDC45\uD835\uDC43) 17.3 \uD835\uDC5A\uD835\uDC5A\nCoefficient of Friction\n(µ) 0.005\nThe original component design and associated formulation for \uD835\uDC47ℎ\uD835\uDC56\uD835\uDC50\uD835\uDC58\uD835\uDC52\uD835\uDC5B\uD835\uDC56\uD835\uDC5B\uD835\uDC54 is taken from Kakandikar 2014. The problem (Eq 17 to 19) was solved using SCI and DCI. The \uD835\uDC47ℎ\uD835\uDC56\uD835\uDC50\uD835\uDC58\uD835\uDC52\uD835\uDC5B\uD835\uDC56\uD835\uDC5B\uD835\uDC54 (refer to Eq 17) depends on blank holder force, coefficient of friction, radius on die and radius on punch. All these parameters finally depend on variables blank diameter \uD835\uDC51\uD835\uDC5C, finished component diameter \uD835\uDC511 and corner radius \uD835\uDC67. These parameters define the design of the component. The solutions using the SCI and DCI are then used to modify the original component design.\nIt can be observed from the Table 7(a) that the thickness value obtained in the original component was 1.309 \uD835\uDC5A\uD835\uDC5A. The associated formability analysis performed in FromingSuite version 2015.1.0 software in (refer to Figure 5(a)) indicates that the range of the thickness distribution in the overall component varies from 0.356 \uD835\uDC61\uD835\uDC5C 1.378 \uD835\uDC5A\uD835\uDC5A. The thickness obtained by SCI is 1.276 \uD835\uDC5A\uD835\uDC5A (refer to Table 7(b)). It indicates that the thickness is reduced by 2.52%. Also it can be observed from Figure 5(b) that the whole component thickness distribution ranges from 0.357 \uD835\uDC61\uD835\uDC5C 1.378 \uD835\uDC5A\uD835\uDC5A. It indicates that the average thickness through overall component is reduced. Similarly the thickness obtained by DCI is 1.268 \uD835\uDC5A\uD835\uDC5A (refer to Table 7(c)). It indicates that the thickness is reduced by 3.13%. It can be observed from Figure 5(c) that the whole component thickness distribution ranges from 0.551 \uD835\uDC61\uD835\uDC5C 1.378 \uD835\uDC5A\uD835\uDC5A, which indicates that the average thickness of the overall component is reduced."
    }, {
      "heading" : "5. Conclusion and Future Works",
      "text" : "Two constraint handling approaches CI with static penalty approach (SCI) and CI with dynamic penalty approach (DCI) are successfully proposed and tested by solving 20 constrained test problems including pressure vessel design problem, tension-compression spring design and welded beam design problem. The results highlighted that the approach is significantly effective as compared to other algorithms solving these problems. The performance of the algorithm was satisfactory and competent in terms of the robustness, objective function value, and constraint satisfaction. The computational\nFigure 5 (c) Thickness distribution of the modified component by DCI.\ncost, i.e. computational time and function evaluations were also reasonable. In addition, the Springback effect problem occurring in the automotive punch plate, thinning in connector and thickening in tail cap during the process of deep drawing are successfully solved. This validated the applicability of the proposed constrained CI versions, SCI and DCI.\nThe computational time of CI can be further reduced by tuning the parameters such as size of cohort and sampling interval reduction factor. Also, the current version of SCI and DCI could solve problems with inequality constraints. An improvement in the existing approach is required to solve problems with equality constraints (Deshpande et al. 2013, Kulkarni & Tai 2011)."
    }, {
      "heading" : "Acknowledgements",
      "text" : "Authors would like to thank the anonymous reviewers. Their comments helped in much improvement in the quality of the manuscript."
    } ],
    "references" : [ {
      "title" : "Pressure Vessel Design Using the Dynamic Self-Adaptive Harmony Search Algorithm",
      "author" : [ "Ali Kattan", "Reem A. Alrawi" ],
      "venue" : "SDIWC, ISBN: 978-0-9891305-4-7,",
      "citeRegEx" : "Kattan and Alrawi,? \\Q2014\\E",
      "shortCiteRegEx" : "Kattan and Alrawi",
      "year" : 2014
    }, {
      "title" : "Ant Colony System: A Cooperative Learning Approach to the Travelling Salesman Problem",
      "author" : [ "M Dorigo" ],
      "venue" : "IEEE Transactions on Evolutionary Computation,",
      "citeRegEx" : "Dorigo.,? \\Q1997\\E",
      "shortCiteRegEx" : "Dorigo.",
      "year" : 1997
    }, {
      "title" : "Constraint-handling in nature-inspired numerical optimization: Past, present and future",
      "author" : [ "Efren Mezura-Montesa", "Carlos A. Coello Coello" ],
      "venue" : "Swarm and Evolutionary Computation,",
      "citeRegEx" : "Mezura.Montesa et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Mezura.Montesa et al\\.",
      "year" : 2011
    }, {
      "title" : "CAC, “A simple multimembered evolution strategy to solve constrained optimization problems",
      "author" : [ "Efren Mezura-Montes", "Coello" ],
      "venue" : "IEEE Trans Evol Computer",
      "citeRegEx" : "Mezura.Montes and Coello,? \\Q2005\\E",
      "shortCiteRegEx" : "Mezura.Montes and Coello",
      "year" : 2005
    }, {
      "title" : "A comprehensive review of firefly algorithms",
      "author" : [ "Fister. I", "Fister.I. Jr.", "Yang X.S", "Brest J" ],
      "venue" : "Journal of Swarm and Evolutionary Computation,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2013
    }, {
      "title" : "Constrained optimization via genetic algorithms",
      "author" : [ "Homaifar A", "S.H.Y. Lai", "X. Qi" ],
      "venue" : "4th International Workshop on Reliable Engineering Computing, National University of Singapore,",
      "citeRegEx" : "A et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "A et al\\.",
      "year" : 1994
    }, {
      "title" : "On the use of non-stationary penalty functions to solve nonlinear constrained optimization problems with Gas",
      "author" : [ "J Joines", "C Houck" ],
      "venue" : "Proceedings of the First IEEE Conference on Evolutionary Computation,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1994
    }, {
      "title" : "process for automotive cup using Genetic Algorithm",
      "author" : [ "Karaboga Dervis", "Bahriye Akay" ],
      "venue" : "IISc Centenary-International Conference on Advances in Mechanical Engineering ICICAME, Bangalore,",
      "citeRegEx" : "Dervis and Akay,? \\Q2008\\E",
      "shortCiteRegEx" : "Dervis and Akay",
      "year" : 2008
    }, {
      "title" : "A Hybrid Approach for Data Clustering Based on Modified Cohort Intelligence and K-means",
      "author" : [ "G Krishnasamy", "J. Kulkarni A", "R Paramesran" ],
      "venue" : "Applied Soft Computing,",
      "citeRegEx" : "Krishnasamy et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Krishnasamy et al\\.",
      "year" : 2014
    }, {
      "title" : "Three Selected Combinatorial Optimization Problems",
      "author" : [ "A.J. Kulkarni", "I.P. Durugkar", "M. Kumar" ],
      "venue" : "European Journal of Operational Research,",
      "citeRegEx" : "Kulkarni et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Kulkarni et al\\.",
      "year" : 2013
    }, {
      "title" : "Cohort Intelligence: A Socio-inspired Optimization Method",
      "author" : [ "A.J. Kulkarni", "G. Krishnasamy", "A. Abraham" ],
      "venue" : "Intelligent Systems Reference Library,",
      "citeRegEx" : "Kulkarni et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Kulkarni et al\\.",
      "year" : 2017
    }, {
      "title" : "Solving Constrained Optimization Problems Using Probability Collectives and a Penalty Function Approach",
      "author" : [ "A.J. Kulkarni", "K. Tai" ],
      "venue" : "International Journal of Computational Intelligence and Applications,",
      "citeRegEx" : "Kulkarni and Tai,? \\Q2011\\E",
      "shortCiteRegEx" : "Kulkarni and Tai",
      "year" : 2011
    }, {
      "title" : "Problem Defnitions and Evaluation Criteria",
      "author" : [ "Liang J. J", "Runarsson T. P", "Efren Mezura-Montes", "Clerc Maurice", "Suganthan P. N", "Carlos A. Coello Coello", "K. Deb" ],
      "venue" : "Special Session on Constrained RealParameter Optimization,",
      "citeRegEx" : "J. et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "J. et al\\.",
      "year" : 2006
    }, {
      "title" : "On an exact penalty function method for semi-infinite programming problems",
      "author" : [ "C Ma", "X. Li" ],
      "venue" : "Journal of Industrial and Management Optimization,",
      "citeRegEx" : "Ma and Li,? \\Q2012\\E",
      "shortCiteRegEx" : "Ma and Li",
      "year" : 2012
    }, {
      "title" : "Evolutionary optimization of constrained problems",
      "author" : [ "Michalewicz Z", "Attia N.F" ],
      "venue" : "in: Proceedings of the 3rd Annual Conference on Evolutionary Programming, World Scientific, Singapore,",
      "citeRegEx" : "Z and N.F,? \\Q1994\\E",
      "shortCiteRegEx" : "Z and N.F",
      "year" : 1994
    }, {
      "title" : "Using genetic algorithms in engineering design optimization with non-linear constraints",
      "author" : [ "Powell D", "Skolnick M.M" ],
      "venue" : "MIT press,",
      "citeRegEx" : "D and M.M,? \\Q1996\\E",
      "shortCiteRegEx" : "D and M.M",
      "year" : 1996
    }, {
      "title" : "Differential evolution algorithm with strategy adaptation for global numerical optimization",
      "author" : [ "A.K. Qin", "V.L. Huang", "P.N. Suganthan" ],
      "venue" : "IEEE Transactions on Evolutionary Computations,",
      "citeRegEx" : "Qin et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Qin et al\\.",
      "year" : 2009
    }, {
      "title" : "Problem Solving from Nature",
      "author" : [ "R. Storn", "K Price" ],
      "venue" : "Journal of Global Optimization,",
      "citeRegEx" : "Storn and Price,? \\Q1996\\E",
      "shortCiteRegEx" : "Storn and Price",
      "year" : 1996
    }, {
      "title" : "True Global Optimality of the Pressure Vessel Design Problem: A Benchmark for Bio-Inspired Optimization Algorithms",
      "author" : [ "Yang X. S", "Christian Huyck", "Mehmet Karamanoglu", "Nawaz Khan" ],
      "venue" : "International Journal of Bio-Inspired Computation,",
      "citeRegEx" : "S. et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "S. et al\\.",
      "year" : 2013
    }, {
      "title" : "ERV, “Constrained optimization via particle evolutionary swarm optimization algorithm (PESO)",
      "author" : [ "AEM Zavala", "AH Aguirre", "Diharce" ],
      "venue" : "Proceedings of the 2005 conference on genetic and evolutionary computation",
      "citeRegEx" : "Zavala et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Zavala et al\\.",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 16,
      "context" : "The evolutionary algorithms include Genetic Algorithm (GA) (Mitchell 1996), Differential Evolution (DE) (Storn et al. 2013; Qin et al. 2009), etc.",
      "startOffset" : 104,
      "endOffset" : 140
    }, {
      "referenceID" : 9,
      "context" : "So far, CI has been applied for solving several unconstrained test problems (Kulkarni et al. 2013).",
      "startOffset" : 76,
      "endOffset" : 98
    }, {
      "referenceID" : 8,
      "context" : "Also, CI and modified CI (MCI) were hybridized with K-means (Krishnasamy et al. 2014) and applied for solving several data clustering problems.",
      "startOffset" : 60,
      "endOffset" : 85
    }, {
      "referenceID" : 10,
      "context" : "The approach was also applied for solving traveling salesman problem (Kulkarni et al. 2017).",
      "startOffset" : 69,
      "endOffset" : 91
    }, {
      "referenceID" : 3,
      "context" : "The performance of SCI & DCI is compared with the other methods in relevant literature including GA (Mezura-Montes and Coello 2005), PSO (Zavala et al.",
      "startOffset" : 100,
      "endOffset" : 131
    }, {
      "referenceID" : 19,
      "context" : "The performance of SCI & DCI is compared with the other methods in relevant literature including GA (Mezura-Montes and Coello 2005), PSO (Zavala et al. 2005), ABC (Karaboga et al.",
      "startOffset" : 137,
      "endOffset" : 157
    } ],
    "year" : 2016,
    "abstractText" : "Most of the metaheuristics can efficiently solve unconstrained problems; however, their performance may degenerate if the constraints are involved. This paper proposes two constraint handling approaches for an emerging metaheuristic of Cohort Intelligence (CI). More specifically CI with static penalty function approach (SCI) and CI with dynamic penalty function approach (DCI) are proposed. The approaches have been tested by solving several constrained test problems. The performance of the SCI and DCI have been compared with algorithms like GA, PSO, ABC, d-Ds. In addition, as well as three real world problems from mechanical engineering domain with improved solutions. The results were satisfactory and validated the applicability of CI methodology for solving real world problems.",
    "creator" : "Microsoft® Word 2016"
  }
}