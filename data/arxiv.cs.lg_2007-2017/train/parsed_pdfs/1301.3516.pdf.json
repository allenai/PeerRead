{
  "name" : "1301.3516.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learnable Pooling Regions for Image Classification",
    "authors" : [ "Mateusz Malinowski" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Spatial pooling plays a crucial role in modern object recognition and detection systems. Motivated from biology [Riesenhuber and Poggio, 2009] and statistics of locally orderless images [Koenderink and Van Doorn, 1999], the spatial pooling approach has been found useful as an intermediate step of many today’s computer vision methods. For instance, the most popular visual descriptors such as SIFT [Lowe, 2004] and HOG [Dalal and Triggs, 2005], which compute local histograms of gradients, can be in fact seen as a special version of the spatial pooling strategy. In order to form more robust features under translation or small object deformations, activations of the codes are pooled over larger areas in a spatial pyramid scheme [Lazebnik et al., 2006, Yang et al., 2009]. Unfortunately, this critical decision, namely the spatial division, is most prominently based on hand-crafted algorithms and therefore data independent.\nRelated Work As large amounts of training data is available to us today,, there is an increasing interest to push the boundary of learning based approaches towards fully optimized and adaptive architectures where design choices, that would potentially constrain or bias a model, are kept to a minimum. Neural networks have a great tradition of approaching hierarchical learning problems and training intermediate representations [Ranzato et al., 2007, Le et al., 2012a]. Along this line, we propose a learnable spatial pooling strategy that can shape the pooling regions in a discriminative manner. Our architecture has a direct interpretation as a pooling strategy and therefore subsumes popular spatial pyramids as a special case. Yet we have the freedom to investigate different regularization terms that lead to new pooling strategies when optimized jointly with the classifier.\nRecent progress has been made in learning pooling regions in the context of image classification using the Spatial Pyramid Matching (SPM) pipeline [Lazebnik et al., 2006, Yang et al., 2009]. Jia and Huang [2011], Jia et al. [2012] and Feng et al. [2011] have investigated how to further liberate the recognition from preconceptions of the hand crafted recognition pipelines, and include the\nar X\niv :1\n30 1.\n35 16\nv1 [\ncs .C\nV ]\n1 5\nJa n\n20 13\npooling strategy into the optimization framework jointly with the classifier. However, these methods still make strong assumptions on the solutions that can be achieved. For instance Jia and Huang [2011] optimizes binary pooling strategies that are given by the superposition of rectangular basis functions, and Feng et al. [2011] finds pooling regions by applying a linear discriminant analysis for individual pooling strategies and training a classifier afterwards. Also as opposed to Ranzato and Hinton [2010], we aim for discriminative pooling over large neighborhoods in the SPM fashion where the information about the image class membership is available during training.\nOutline We question restrictions imposed by the above methods and suggest to learn pooling strategies under weaker assumptions. Indeed, our method discovers new pooling shapes that were not found previously as they were suppressed by the more restrictive settings.\nThe generality that we are aiming for comes at the price of a high dimensional parameters space. This manifests in a complex optimization problem that is more demanding on memory requirements as well as computations needs, not to mention a possibility of over-fitting. Therefore, we also discuss two approximations to our method. First approximation introduces a pre-pooling step and therefore reduces the spatial dimension of the codes. The second approximation divides the codes into a set of smaller batches (subset of codes) that can be optimized independently and therefore in parallel.\nFinally, we evaluate our method on the CIFAR-10 and show strong improvements over hand-crafted pooling schemes in the regime of small dictionaries where our more flexible model shows its capability to make best use of the representation by exploring spatial pooling strategies specific to each coordinate of the code. Despite the diminishing return, the performance improvements persist up to largest codes we have investigated. We also show strong classification performance on the CIFAR100 dataset where our method outperforms, to the best of our knowledge, the state-of-the-art."
    }, {
      "heading" : "2 Method",
      "text" : "As opposed to the methods that use fixed spatial pooling regions in the object classification task [Lazebnik et al., 2006, Yang et al., 2009] our method jointly optimizes both the classifier and the pooling regions. In this way, the learning signal available in the classifier can help shaping the pooling regions in order to arrive at better pooled features."
    }, {
      "heading" : "2.1 Parameterized pooling operator",
      "text" : "The simplest form of the spatial pooling is computing histogram over the whole image. This can be expressed as Σ(U) := ∑M j=1 uj , where uj ∈ RK is a code (out of M such codes) and an index j refers to the spatial location that the code originates from1. A code is an encoded patch extracted from the image. The proposed method is agnostic to the patch extraction method and encoding scheme. Since the pooling approach looses spatial information of the codes, Lazebnik et al. [2006] proposed to first divide the image into subregions, and afterwards to create pooled features by concatenating histograms computed over each subregion. There are two problems with such an approach: first, the division is largely arbitrary and in particular independent of the data; second, discretization artifacts occur as spatially nearby codes can belong to two different regions as the ’hard’ division is made.\nIn this paper we address both problems by using a parameterized version of the pooling operator\nΘw(U) := M∑ j=1 wj ◦ uj (1)\nwhere a ◦ b is the element-wise multiplication. Standard spatial division of the image can be recovered from Formula 1 by setting the vectors wj either to a vector of zeros 0, or ones 1. For instance, features obtained from dividing the image into 2 subregions can be recovered from Θ by\nconcatenating two vectors: ∑M\n2 j=1 1 ◦uj + ∑M j=M2 +1 0 ◦uj , and ∑M 2 j=1 0 ◦uj + ∑M j=M2 +1\n1 ◦uj , where { 1, ..., M2 } and { M 2 + 1, ...,M } refer to the first and second half of the image respectively.\n1That is j = (x, y) where x and y refer to the spatial location of the center of the extracted patch.\nIn general, let F := {Θw}w be a family of the pooling functions given by Eq. 1, parameterized by the vector w, and let w∗,l be the ’best’ parameter chosen from the family F based on the initial configuration l and a given set of images.2 First row of Figure 2 shows four initial configurations that mimic the standard 2-by-2 spatial image division. Every initial configuration can lead to different w∗,l as it is shown in Figure 2. Clearly, the family F contains all possible ’soft’ and ’hard’ spatial divisions of the image, and therefore can be considered as their generalization."
    }, {
      "heading" : "2.2 Learnable pooling regions",
      "text" : "In SPM architectures the pooling weights w are designed by hand, here we aim for joint learning w together with the parameters of the classifier. Intuitively, the classifier during training has access to the classes that the images belong to, and therefore can shape the pooling regions. On the other hand, the method aggregates statistics of the codes over such learnt regions and pass them to the classifier allowing to achieve higher accuracy. Such joint training of the classifier and the pooling regions can be done by adapting the backpropagation algorithm [Bishop, 1999, LeCun et al., 1998], and so can be interpreted as a densely connected multilayer perceptron [Collobert and Bengio, 2004, Bishop, 1999].\nConsider a sampling scheme and an encoding method producing M codes each K dimensional. Every coordinate of the code is an input layer for the multilayer perceptron. Then we connect every j-th input unit at the layer k to the l-th pooling unit akl via the relation w k lju k j . Since the receptive field of the pooling unit akl consists of all codes at the layer k, we have a k l := ∑M j=1 w k lju k j , and so in the vector notation\nal := M∑ j=1 wlj ◦ uj = Θwl(U) (2)\nNext, we connect all pooling units with the classifier allowing the information to circulate between the pooling layers and the classifier.\nAlthough our method is independent of the choice of a dictionary and an encoding scheme, in this work we use K-means with triangle coding fk(x) := max {0, µ(z)− zk} [Coates et al., 2011]. Similarly, every multi-class classifier that can be interpreted in terms of an artificial neural network can be used. In our work we employ logistic regression. This classifier is connected to the pooling units via the formula\nJ(Θ) := − 1 D D∑ i=1 C∑ j=1 1{y(i) = j} log p(y(i) = j|a(i); Θ) (3)\nwhere D denotes the number of all images, C is the number of all classes, y(i) is a label assigned to the i-th input image, and a(i) are responses from the ’stacked’ pooling units [al]l for the i-th image3. We use the logistic function to represent the probabilities: p(y = j|x; Θ) := exp(θ T j x)∑C\nl=1 exp(θ T l x) . Since the classifier is connected to the pooling units, our task is to learn jointly the pooling parameters W together with the classifier parameters Θ, where W is the matrix containing all pooling weights.\nFinally, we use standard gradient descent algorithm that updates the parameters using the following fixed point iteration Xt+1 := Xt − γ∇J(Xt) (4) where in our case X is a vector consisting of the pooling parameters W and the classifier parameters Θ. In practice, however, we employ a quasi-Newton algorithm LBFGS4."
    }, {
      "heading" : "2.3 Regularization terms",
      "text" : "In order to improve the generalization, we introduce regularization of our network as we deal with a large number of the parameters. For the classification Θ and pooling parameters W , we employ\n2 We will show the learning procedure that can select such parameter vectors in the following subsection. 3Providing the codes U (i) are collected from the i-th image and a(i)l := Θwl(U\n(i)) then a(i) := [a(i)l ]l. 4The algorithm, developed by Mark Schmidt, can be downloaded from the following webpage:\nhttp://www.di.ens.fr/ mschmidt/Software/minFunc.html\na simple L2 regularization terms: ||Θ||2l2 and ∑ k ||W k||2l2 . We improve the interpretability of the pooling weights as well as to facilitate a transfer among models by adding a projection onto a unit cube. To reduce quantization artifacts of the pooling strategy as well as to ensure smoothness of the output w.r.t. small translations of the image, the model penalizes weights whenever the pooling surface is non-smooth. This can be done by measuring the spatial variation, that is ||∇xW k||2l2 + ||∇yW k||2l2 for every layer k. This regularization enforces soft transition between the pooling subregions.\nEvery regularization term comes with its own hyper-parameter set by cross-validation. The overall objective that we want to optimize is\nminimize W ,Θ JR(Θ,W ) := (5)\n− 1 D D∑ i=1 C∑ j=1 1{y(i) = j} log p(y(i) = j|a(i); Θ)\n+ α1 2 ||Θ||2l2 + α2 2 ||W ||2l2 + α3 2 ( ||∇xW ||2l2 + ||∇yW || 2 l2 ) subject to W ∈ [0, 1]K×M×L\nwhere al is the l-th pooling unit described by Formula 2, and ||W ||l2 is the Frobenius norm."
    }, {
      "heading" : "2.4 Approximation of the model",
      "text" : "The presented approach is demanding to train in the means of the CPU time and memory storage when using high dimensional representations. That is, the number of the pooling parameters to learn grows as K ×M ×L, where K is dimensionality of codes, M is the number of patches taken from the image and L is the number of pooling units. Therefore, we propose two approximations to our method making the whole approach more scalable towards bigger dictionaries. However, we emphasize that learnt pooling regions have very little if any overhead compared to standard spatial division approaches at test time.\nFirst approximation does a fine-grained spatial partition of the image, and then pools the codes over such subregions. This operation, we call it a pre-pooling step, reduces the number of considered spatial locations by the factor of the pre-pooling size. For instance, if we collect M codes and the pre-pooling size is S per dimension, then we reduce the number of codes to a number MS2 . The prepooling operation fits well into our generalization of the SPM architectures as by choosing S := M2 we obtain a weighted quadrants scheme. Moreover, the modeler has the option to start with the larger S when little data is available and gradually decreases S as more parameters can be learnt using more data.\nThe second approximation divides a K dimensional code into KD batches, each D dimensional (where D ≤ K and K is divisible by D). Then we train our model on all such batches in parallel to obtain the pooling weights. Later, we train the classifier on top of the concatenation of the trained, partial models. As opposed to Le et al. [2012b] our training is fully independent and doesn’t need communication between different machines.\nSince the ordering of the codes is arbitrary, we also considerD dimensional batches formed from the permuted version of the original codes, and combine them together with the concatenated batches to boost the classification accuracy (we call this approximation redundant batches). Given a fixed sized dictionary, this approximation performs slightly better, although it comes at the cost of increased number of features due to the redundant batches.\nFinally, our approximations not only lead to a highly parallel training procedure with reduced memory requirements and computational demands, but also have shown to greatly reduce the number of required iterations as they tend to converge roughly 5 times faster than the full model on large dictionaries."
    }, {
      "heading" : "3 Experimental Results",
      "text" : "We evaluate our method on the CIFAR-10 and CIFAR-100 datasets [Krizhevsky and Hinton, 2010]. Furthermore, we provide insights into the learnt pooling strategies as well as investigate transfer between datasets. In this section we describe our experimental setup, and present our results on both datasets."
    }, {
      "heading" : "3.1 CIFAR-10 and CIFAR-100 datasets",
      "text" : "The CIFAR-10 and CIFAR-100 datasets contain 50000 training color images and 10000 test color images from respectively 10 and 100 categories, with 6000 and 600 images per class respectively. All images have the same size: 32 × 32 pixels, and were sampled from the 80 million tiny images dataset [Torralba et al., 2008]."
    }, {
      "heading" : "3.2 Evaluation pipeline",
      "text" : "In this work, we follow the Coates and Ng [2011] pipeline. We extract normalized and whitened 6 × 6 patches from images using a dense, equispaced grid with a unit sample spacing. As the next step, we employ the K-means assignment and triangle encoding [Coates and Ng, 2011, Coates et al., 2011] to compute codes – a K-dimensional representation of the patch. We classify images using either a logistic regression, or a linear SVM in the case of transferred pooling regions. Optionally we use two approximations described in subsection 2.4. As we want to be comparable to Coates et al. [2011], who use a spatial division into 2-by-2 subregions which results in 4 ·K pooled features, we use 4 pooling units. Furthermore, we use standard division (first row of Figure 2) as an initialization of our model.\nTo learn parameters of the model we use the limited-memory BFGS algorithm (details are described in subsection 2.2), and limit the number iterations to 3000. After the training, we can also concatenate the results of the parameterized pooling operator [Θwl(U)] 4 l=1. This yields a 4 ·K dimensional feature vector that can be again fed into the classifier, and trained independently with the already trained pooling regions. We call this procedure transfer of pooling regions.\nThe reason behind the transfer is threefold. Firstly, we can combine partial models trained with our approximation in batches to a full, originally intractable, model5. Secondly, the transfer process allows to combine both the codes and the learnt model from the dictionaries of different sizes. Lastly, it enables training of the pooling regions together with the classifier on one dataset, and then re-train the classifier alone on a target dataset. To transfer the pooling regions, we tried logistic regression classifier and linear SVM showing that both classifying procedures can benefit from the learnt pooling regions. However, since we achieve slightly better results for the linear SVM (about 0.5% for bigger dictionaries), only those results are reported. Similarly, we don’t notice significant difference in the classification accuracy for smaller dictionaries when the pre-pooling is used (with the pre-pooling size S := 3), and therefore all experiments refer only to this case. Finally, we select hyper-parameters of our model based on the 5-fold cross-validation."
    }, {
      "heading" : "3.3 Evaluation of our method on small dictionaries",
      "text" : "Figure 1(a) shows the classification accuracy of our full method against the baseline [Coates and Ng, 2011]. Since we train the pooling regions without any approximations in this set of experiments the results are limited to dictionary sizes up to 800. Our method outperforms the approach of Coates by 10% for dictionary size 16 (our method achieves the accuracy 57.07%, whereas the baseline only 46.93%). This improvement is consistent up to the bigger dictionaries although the margin is getting smaller. Our method is about 2.5% and 1.88% better than the baseline for 400 and 800 dictionary elements respectively."
    }, {
      "heading" : "3.4 Scaling up to sizable dictionaries",
      "text" : "In subsection 2.4 we have discussed the possibility of dividing the codes into low dimensional batches and learning the pooling regions on those. In the following experiments we use batches\n5The reader can find details of such approximation in subsection 2.4.\nwith 40 coordinates extracted from the original code, as those fit conveniently into the memory of a single, standard machine (about 5 Gbytes for the main data) and can all be trained in parallel.\nBesides a reduction in the memory requirements, the batches have shown multiple benefits in practice due to smaller number of parameters. We need less computations per iterations as well as observe faster convergence. Figure 1(b) shows the classification performance for larger dictionaries where we examined the full model [Our], the baseline [Coates], random pooling regions (described in subsection 3.5), bag of features, and two possible approximation - the batched model [Our (batches)], and the redundantly batched model [Our (redundant batches)].\nOur test results are presented in Table 1. When comparing our full model to the approximated versions with batches for dictionaries of size 200, 400 and 800, we observe that there is almost no drop in performance and we even slightly improve for the bigger dictionaries. We attribute this to the better conditioned learning problem of the smaller codes within one batch. With an accuracy for the batched model of 79.6% we outperform the Coates baseline by 1.7%. Interestingly, we gain another small improvement to 80.02% by adding redundant batches which amounts to a total improvement of 2.12% compared to the baseline. Our method performs comparable to the pooling strategy of Jia and Huang [2011] which uses more restrictive assumptions on the pooling regions and employs feature selection algorithm.\nTo the best of our knowledge Ciresan et al. [2012] achieves the best results on the CIFAR-10 dataset with an accuracy 88.79% with a method based on a deep architecture – different type of architecture to the one that we investigate in our study."
    }, {
      "heading" : "3.5 Random pooling regions",
      "text" : "Our investigation also includes results using random pooling regions where the weights for the parameterized operator (Eq. 2) were sampled from normal distribution with mean 0.5 and standard deviation 0.1, that is wlj ∼ N (0.5, 0.1) for all l. This notion of the random pooling differs from the Jia et al. [2012] where random selection of rectangles is used. The experiments show that the random pooling regions can compete with the standard spatial pooling (Figure 1(a) and 1(b)) on the CIFAR-10 dataset, and suggest that random projection can still preserve some spatial information.\nThis is especially visible in the regime of bigger dictionaries where the difference is only 1.09%. The obtained results indicate that hand-crafted division of the image into subregions is questionable, and call for a learning-based approach."
    }, {
      "heading" : "3.6 Investigation of the regularization terms",
      "text" : "Our model (Eq. 5) comes with two regularization terms associated with the pooling weights, each imposing different assumptions on the pooling regions. Hence, it is interesting to investigate their role in the classification task by considering all possible subsets of {l2, smooth}, where “l2” and “smooth” refer to ||W ||2l2 and ( ||∇xW ||2l2 + ||∇yW || 2 l2 ) respectively.\nTable 3 shows our results on CIFAR-10. We choose a dictionary size of 200 for these experiments, so that we can evaluate different regularization terms without any approximations. We conclude that the spatial smoothness regularization term is crucial to achieve a good predictive performance of our method whereas the l2-norm term can be left out, and thus also reducing the number of hyperparameters. Based on the cross-validation results (second column of Table 3), we select this setting for further experiments."
    }, {
      "heading" : "3.7 Experiments on the CIFAR-100 dataset",
      "text" : "Although the main body of work is conducted on the CIFAR-10 dataset, we also investigate how the model performs on and generalizes to the much more demanding CIFAR-100 dataset with 100 classes. Our model with the spatial smoothness regularization term on the 40 dimensional batches\nachieves 56.29% accuracy. To our best knowledge, this result consitutes the state-of-the-art performance on this dataset, outperforming Jia and Huang [2011] by 1.41%, and the baseline by 4.63%."
    }, {
      "heading" : "3.8 Transfer of the pooling regions between datasets",
      "text" : "Beyond the standard classification task, we also examine whether the learnt pooling regions are transferrable between datasets. In this scenario the pooling regions are first trained on the source dataset and then used on the target dataset to train a new classifier. We use dictionary of 1600 with 40-dimensional batches. Our results in Table 5 suggest that the learnt pooling regions are indeed transferable between both datasets. While we observe a decrease in performance when learning the pooling strategy on the less diverse CIFAR-10 dataset, we do see improvements for learning on the richer CIFAR-100 dataset. We arrive at a test accuracy of 80.35% which is an additional improvement of 0.75% and 0.18% over our best result (batch-based approximation) and Jia and Huang [2011] respectively."
    }, {
      "heading" : "3.9 Visualization and analysis of pooling strategies",
      "text" : "Table 2 visualizes different pooling strategies investigated in this paper. The first row shows the widely used rectangular spatial division of the image. The other visualizations correspond to pooling weights discovered by our model using different regularization terms, datasets and dictionary size.\nThe second row shows the results on CIFAR-10 with the “l2” regularization term. The pooling is most distinct from the other results, as it learns highly localized weights. This pooling strategy has also performed the worst in our investigation (Table 3).\nThe ”smooth” pooling performs the best. Visualization shows that weights are localized but vary smoothly over the image. The weights expose a bias towards initialization shown in the first row. All methods with the spatial smoothness regularization tend to focus on similar parts of the image, however “l2 & smooth” is more conservative in spreading out the weights.\nThe last two rows show weights trained using our approximation by batches. From visual inspection, they show a similar level of localization and smoothness to the regions obtained without approximation. This further supports the use of our approximation into independent batches."
    }, {
      "heading" : "4 Conclusion",
      "text" : "In this paper we propose a flexible parameterization of the pooling operator which can be trained jointly with the classifier. In this manner, we study the effect of different regularizers on the pooling regions as well as the overall system. To be able to train the large set of parameters we propose approximations to our model allowing efficient and parallel training without loss of accuracy.\nOur experiments show there is a room to improve the classification accuracy by advancing the spatial pooling stage. The presented method outperforms a popular hand-crafted pooling based method and previous approaches to learn pooling strategies. While our improvements are consistent over the whole range of dictionary sizes that we have investigated, the margin is most impressive for small codes where we observe improvements up to 10% compared to the baseline of Coates. Finally, our method achieves an accuracy of 56.29% on CIFAR-100, which is to the best of our knowledge the new state-of-the-art on this dataset.\nAs we believe that our method is a good framework for further investigations of different pooling strategies and in order to speed-up progress on the pooling stage we will make our code publicly available at time of publication."
    } ],
    "references" : [ {
      "title" : "Hierarchical models of object recognition in cortex",
      "author" : [ "M. Riesenhuber", "T. Poggio" ],
      "venue" : "Nature Neuroscience,",
      "citeRegEx" : "Riesenhuber and Poggio.,? \\Q2009\\E",
      "shortCiteRegEx" : "Riesenhuber and Poggio.",
      "year" : 2009
    }, {
      "title" : "The structure of locally orderless images",
      "author" : [ "J.J. Koenderink", "A.J. Van Doorn" ],
      "venue" : "International Journal of Computer Vision,",
      "citeRegEx" : "Koenderink and Doorn.,? \\Q1999\\E",
      "shortCiteRegEx" : "Koenderink and Doorn.",
      "year" : 1999
    }, {
      "title" : "Distinctive image features from scale-invariant keypoints",
      "author" : [ "D.G. Lowe" ],
      "venue" : null,
      "citeRegEx" : "Lowe.,? \\Q2004\\E",
      "shortCiteRegEx" : "Lowe.",
      "year" : 2004
    }, {
      "title" : "Histograms of oriented gradients for human detection",
      "author" : [ "N. Dalal", "B. Triggs" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Dalal and Triggs.,? \\Q2005\\E",
      "shortCiteRegEx" : "Dalal and Triggs.",
      "year" : 2005
    }, {
      "title" : "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories",
      "author" : [ "S. Lazebnik", "C. Schmid", "J. Ponce" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Lazebnik et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Lazebnik et al\\.",
      "year" : 2006
    }, {
      "title" : "Linear spatial pyramid matching using sparse coding for image classification",
      "author" : [ "J. Yang", "K. Yu", "Y. Gong", "T. Huang" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Yang et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2009
    }, {
      "title" : "Unsupervised learning of invariant feature hierarchies with applications to object recognition",
      "author" : [ "M.A. Ranzato", "F.J. Huang", "Y. Boureau", "Y. LeCun" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Ranzato et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Ranzato et al\\.",
      "year" : 2007
    }, {
      "title" : "Building high-level features using large scale unsupervised learning",
      "author" : [ "Q.V. Le", "M.A. Ranzato", "R. Monga", "M. Devin", "K. Chen", "G.S. Corrado", "J. Dean", "A.Y. Ng" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Le et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Le et al\\.",
      "year" : 2012
    }, {
      "title" : "Beyond spatial pyramids: Receptive field learning for pooled image features",
      "author" : [ "Y. Jia", "C. Huang" ],
      "venue" : "In NIPS Workshop on Deep Learning,",
      "citeRegEx" : "Jia and Huang.,? \\Q2011\\E",
      "shortCiteRegEx" : "Jia and Huang.",
      "year" : 2011
    }, {
      "title" : "Beyond spatial pyramids: Receptive field learning for pooled image features",
      "author" : [ "Y. Jia", "C. Huang", "T. Darrell" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Jia et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Jia et al\\.",
      "year" : 2012
    }, {
      "title" : "Geometric lp-norm feature pooling for image classification",
      "author" : [ "J. Feng", "B. Ni", "Q. Tian", "S. Yan" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Feng et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2011
    }, {
      "title" : "Modeling pixel means and covariances using factorized third-order boltzmann machines",
      "author" : [ "M.A. Ranzato", "G.E. Hinton" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Ranzato and Hinton.,? \\Q2010\\E",
      "shortCiteRegEx" : "Ranzato and Hinton.",
      "year" : 2010
    }, {
      "title" : "Neural Network for Pattern Recognition",
      "author" : [ "C.M. Bishop" ],
      "venue" : null,
      "citeRegEx" : "Bishop.,? \\Q1999\\E",
      "shortCiteRegEx" : "Bishop.",
      "year" : 1999
    }, {
      "title" : "Efficient backprop",
      "author" : [ "Y. LeCun", "L. Bottou", "G. Orr", "K. Müller" ],
      "venue" : "Neural networks: Tricks of the trade,",
      "citeRegEx" : "LeCun et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "LeCun et al\\.",
      "year" : 1998
    }, {
      "title" : "Links between perceptrons, mlps and svms",
      "author" : [ "R. Collobert", "S. Bengio" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Collobert and Bengio.,? \\Q2004\\E",
      "shortCiteRegEx" : "Collobert and Bengio.",
      "year" : 2004
    }, {
      "title" : "An analysis of single-layer networks in unsupervised feature learning",
      "author" : [ "A. Coates", "H. Lee", "A.Y. Ng" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "Coates et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Coates et al\\.",
      "year" : 2011
    }, {
      "title" : "Building high-level features using large scale unsupervised learning",
      "author" : [ "Q.V. Le", "R. Monga", "M. Devin", "G. Corrado", "K. Chen", "M.A. Ranzato", "J. Dean", "A.Y. Ng" ],
      "venue" : null,
      "citeRegEx" : "Le et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Le et al\\.",
      "year" : 2012
    }, {
      "title" : "Convolutional deep belief networks on cifar-10",
      "author" : [ "A. Krizhevsky", "G. Hinton" ],
      "venue" : "Technical report,",
      "citeRegEx" : "Krizhevsky and Hinton.,? \\Q2010\\E",
      "shortCiteRegEx" : "Krizhevsky and Hinton.",
      "year" : 2010
    }, {
      "title" : "Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition",
      "author" : [ "A. Torralba", "R. Fergus", "W.T" ],
      "venue" : null,
      "citeRegEx" : "Torralba et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Torralba et al\\.",
      "year" : 2008
    }, {
      "title" : "The importance of encoding versus training with sparse coding and vector quantization",
      "author" : [ "A. Coates", "A.Y. Ng" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Coates and Ng.,? \\Q2011\\E",
      "shortCiteRegEx" : "Coates and Ng.",
      "year" : 2011
    }, {
      "title" : "Multi-column deep neural networks for image classification",
      "author" : [ "D. Ciresan", "U. Meier", "J. Schmidhuber" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Ciresan et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Ciresan et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Motivated from biology [Riesenhuber and Poggio, 2009] and statistics of locally orderless images [Koenderink and Van Doorn, 1999], the spatial pooling approach has been found useful as an intermediate step of many today’s computer vision methods.",
      "startOffset" : 23,
      "endOffset" : 53
    }, {
      "referenceID" : 2,
      "context" : "For instance, the most popular visual descriptors such as SIFT [Lowe, 2004] and HOG [Dalal and Triggs, 2005], which compute local histograms of gradients, can be in fact seen as a special version of the spatial pooling strategy.",
      "startOffset" : 63,
      "endOffset" : 75
    }, {
      "referenceID" : 3,
      "context" : "For instance, the most popular visual descriptors such as SIFT [Lowe, 2004] and HOG [Dalal and Triggs, 2005], which compute local histograms of gradients, can be in fact seen as a special version of the spatial pooling strategy.",
      "startOffset" : 84,
      "endOffset" : 108
    }, {
      "referenceID" : 4,
      "context" : "Recent progress has been made in learning pooling regions in the context of image classification using the Spatial Pyramid Matching (SPM) pipeline [Lazebnik et al., 2006, Yang et al., 2009]. Jia and Huang [2011], Jia et al.",
      "startOffset" : 148,
      "endOffset" : 212
    }, {
      "referenceID" : 4,
      "context" : "Recent progress has been made in learning pooling regions in the context of image classification using the Spatial Pyramid Matching (SPM) pipeline [Lazebnik et al., 2006, Yang et al., 2009]. Jia and Huang [2011], Jia et al. [2012] and Feng et al.",
      "startOffset" : 148,
      "endOffset" : 231
    }, {
      "referenceID" : 4,
      "context" : "Recent progress has been made in learning pooling regions in the context of image classification using the Spatial Pyramid Matching (SPM) pipeline [Lazebnik et al., 2006, Yang et al., 2009]. Jia and Huang [2011], Jia et al. [2012] and Feng et al. [2011] have investigated how to further liberate the recognition from preconceptions of the hand crafted recognition pipelines, and include the",
      "startOffset" : 148,
      "endOffset" : 254
    }, {
      "referenceID" : 8,
      "context" : "For instance Jia and Huang [2011] optimizes binary pooling strategies that are given by the superposition of rectangular basis functions, and Feng et al.",
      "startOffset" : 13,
      "endOffset" : 34
    }, {
      "referenceID" : 8,
      "context" : "For instance Jia and Huang [2011] optimizes binary pooling strategies that are given by the superposition of rectangular basis functions, and Feng et al. [2011] finds pooling regions by applying a linear discriminant analysis for individual pooling strategies and training a classifier afterwards.",
      "startOffset" : 13,
      "endOffset" : 161
    }, {
      "referenceID" : 8,
      "context" : "For instance Jia and Huang [2011] optimizes binary pooling strategies that are given by the superposition of rectangular basis functions, and Feng et al. [2011] finds pooling regions by applying a linear discriminant analysis for individual pooling strategies and training a classifier afterwards. Also as opposed to Ranzato and Hinton [2010], we aim for discriminative pooling over large neighborhoods in the SPM fashion where the information about the image class membership is available during training.",
      "startOffset" : 13,
      "endOffset" : 343
    }, {
      "referenceID" : 4,
      "context" : "Since the pooling approach looses spatial information of the codes, Lazebnik et al. [2006] proposed to first divide the image into subregions, and afterwards to create pooled features by concatenating histograms computed over each subregion.",
      "startOffset" : 68,
      "endOffset" : 91
    }, {
      "referenceID" : 15,
      "context" : "Although our method is independent of the choice of a dictionary and an encoding scheme, in this work we use K-means with triangle coding fk(x) := max {0, μ(z)− zk} [Coates et al., 2011].",
      "startOffset" : 165,
      "endOffset" : 186
    }, {
      "referenceID" : 7,
      "context" : "As opposed to Le et al. [2012b] our training is fully independent and doesn’t need communication between different machines.",
      "startOffset" : 14,
      "endOffset" : 32
    }, {
      "referenceID" : 17,
      "context" : "We evaluate our method on the CIFAR-10 and CIFAR-100 datasets [Krizhevsky and Hinton, 2010].",
      "startOffset" : 62,
      "endOffset" : 91
    }, {
      "referenceID" : 18,
      "context" : "All images have the same size: 32 × 32 pixels, and were sampled from the 80 million tiny images dataset [Torralba et al., 2008].",
      "startOffset" : 104,
      "endOffset" : 127
    }, {
      "referenceID" : 18,
      "context" : "In this work, we follow the Coates and Ng [2011] pipeline.",
      "startOffset" : 28,
      "endOffset" : 49
    }, {
      "referenceID" : 15,
      "context" : "As the next step, we employ the K-means assignment and triangle encoding [Coates and Ng, 2011, Coates et al., 2011] to compute codes – a K-dimensional representation of the patch. We classify images using either a logistic regression, or a linear SVM in the case of transferred pooling regions. Optionally we use two approximations described in subsection 2.4. As we want to be comparable to Coates et al. [2011], who use a spatial division into 2-by-2 subregions which results in 4 ·K pooled features, we use 4 pooling units.",
      "startOffset" : 95,
      "endOffset" : 413
    }, {
      "referenceID" : 19,
      "context" : "Figure 1(a) shows the classification accuracy of our full method against the baseline [Coates and Ng, 2011].",
      "startOffset" : 86,
      "endOffset" : 107
    }, {
      "referenceID" : 8,
      "context" : "Our method performs comparable to the pooling strategy of Jia and Huang [2011] which uses more restrictive assumptions on the pooling regions and employs feature selection algorithm.",
      "startOffset" : 58,
      "endOffset" : 79
    }, {
      "referenceID" : 19,
      "context" : "Table 1: Comparison of our methods against the baseline [Coates and Ng, 2011] and Jia and Huang [2011] with respect to the dictionary size, number of features and the test accuracy on CIFAR-10.",
      "startOffset" : 56,
      "endOffset" : 77
    }, {
      "referenceID" : 8,
      "context" : "Table 1: Comparison of our methods against the baseline [Coates and Ng, 2011] and Jia and Huang [2011] with respect to the dictionary size, number of features and the test accuracy on CIFAR-10.",
      "startOffset" : 82,
      "endOffset" : 103
    }, {
      "referenceID" : 20,
      "context" : "To the best of our knowledge Ciresan et al. [2012] achieves the best results on the CIFAR-10 dataset with an accuracy 88.",
      "startOffset" : 29,
      "endOffset" : 51
    }, {
      "referenceID" : 9,
      "context" : "This notion of the random pooling differs from the Jia et al. [2012] where random selection of rectangles is used.",
      "startOffset" : 51,
      "endOffset" : 69
    }, {
      "referenceID" : 8,
      "context" : "To our best knowledge, this result consitutes the state-of-the-art performance on this dataset, outperforming Jia and Huang [2011] by 1.",
      "startOffset" : 110,
      "endOffset" : 131
    }, {
      "referenceID" : 18,
      "context" : "Table 4: The classification accuracy on CIFAR-100, where our method is compared against the Coates and Ng [2011] (we downloaded the framework from https://sites.",
      "startOffset" : 92,
      "endOffset" : 113
    }, {
      "referenceID" : 8,
      "context" : "com/site/kmeanslearning, we also use 5fold cross-validation to choose hyper-parameter C) and Jia and Huang [2011] (here we refer to the NIPS 2011 workshop paper).",
      "startOffset" : 93,
      "endOffset" : 114
    }, {
      "referenceID" : 8,
      "context" : "18% over our best result (batch-based approximation) and Jia and Huang [2011] respectively.",
      "startOffset" : 57,
      "endOffset" : 78
    } ],
    "year" : 2017,
    "abstractText" : "From the early HMAX model to Spatial Pyramid Matching, pooling has played an important role in visual recognition pipelines. Spatial pooling, by grouping of local codes, equips these methods with a certain degree of robustness to translation and deformation yet preserving important spatial information. Despite the predominance of this approach in current recognition systems, we have seen little progress to fully adapt the pooling strategy to the task at hand. This paper proposes a model for learning task dependent pooling scheme – including previously proposed hand-crafted pooling schemes as a particular instantiation. In our work, we investigate the role of different regularization terms used in the proposed model together with an efficient method to train them. Our experiments show improved performance over hand-crafted pooling schemes on the CIFAR-10 and CIFAR100 datasets – in particular improving the state-of-the-art to 56.29% on the latter.",
    "creator" : "LaTeX with hyperref package"
  }
}