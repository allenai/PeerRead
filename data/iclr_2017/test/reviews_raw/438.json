{"conference": "ICLR 2017 conference submission", "title": "Learning to Navigate in Complex Environments", "abstract": "Learning to navigate in complex environments with dynamic elements is an important milestone in developing AI agents. In this work we formulate the navigation question as a reinforcement learning problem and show that data efficiency and task performance can be dramatically improved by relying on additional auxiliary tasks to bootstrap learning. In particular we consider jointly learning the goal-driven reinforcement learning problem with an unsupervised depth prediction task and a self-supervised loop closure classification task. Using this approach we can learn to navigate from raw sensory input in complicated 3D mazes, approaching human-level performance even under conditions where the goal location changes frequently. We provide detailed analysis of the agent behaviour, its ability to localise, and its network activity dynamics, that show that the agent implicitly learns key navigation abilities, with only sparse rewards and without direct supervision.", "reviews": [{"is_meta_review": true, "comments": "This paper shows that a deep RL approach augmented with auxiliary tasks improves performance on navigation in complex environments. Specifically, A3C is used for the RL problem, and the agent is simultaneously trained on an unsupervised depth prediction task and a self-supervised loop closure classification task. While the use of auxiliary tasks to improve training of models including RL agents is not new, the main contribution here is the use of tasks that encourage learning an intrinsic representation of space and movement that enables significant improvements on maze navigation tasks.\n\nThe paper is well written, experiments are convincing, and the value of the auxiliary tasks for the problem are clear. However, the contribution is relatively incremental given previous work on RL for navigation and on auxiliary tasks. The work could become of greater interest provided broader analysis and insights on either optimal combinations of tasks for visual navigation (e.g. the value of other visual / geometry-based tasks), or on auxiliary tasks with RL in general.  As it is, it is a useful demonstration of the benefit of geometry-based auxiliary tasks for navigation, but of relatively narrow interest.", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "The paper proposes an approach to navigating in complex environments using RL agents that have auxiliary tasks besides just the successful navigation itself (for instance, the task of predicting depth from images). The idea is a nice one, and the demonstration is fairly compelling. The one aspect that seems a bit unsatisfying is that the the approach does seem a bit ad-hoc, and could be made more formal, but presenting these results on a challenging task like this navigation problem is certainly sufficient for the paper to be worth accepting. The pros and cons are as follows:\n \n \n Pros:\n + Idea of formulating auxiliary tasks is a nice one and the precise form in which it is done here appears novel\n + Good results on a challenge task of maze navigation from visual data\n \n Cons:\n - Methodology does seem a bit ad-hoc, it would be nice to see if some of the auxiliary task mechanisms could be formalized beyond simple \"this is what worked for this domain\"", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"TITLE": "Response to reviewers and revision summary", "OTHER_KEYS": "Piotr W Mirowski", "comments": "We have addressed the points/suggestions raised through several additional experiments which have been added to the paper in the latest revision.\n\n1) Exploring the optimal combinations of auxiliary tasks: we now include an additional auxiliary task, reward prediction (shown to be effective across a range of tasks in Jaderberg et al. 2016, ICLR submission). Results show that depth prediction is superior to reward prediction in the navigational settings examined, with the combination of the two being no more effective (section 5.3, table 2).\n\n2) The focus of our paper on navigation and the depth prediction auxiliary task: we now present results showing that auxiliary depth prediction is beneficial in scenarios that have minimal navigational demands, suggesting its general effectiveness (appendix C.3; figure 10).\n\n3) Whether auxiliary tasks increase robustness to hyperparameters: we provide a more systematic analysis to show that this does seem to be the case (appendix C.4; figure 11).\n\n4) Whether auxiliary tasks simply accelerate training: we provide evidence that they do more that this through analyses of asymptotic performance (appendix C.5; table 3), effects on the representations learnt (i.e. indexed by position decoding), demonstration that depth prediction shows benefits compared to the reward prediction auxiliary task in the navigation domain. ", "IS_META_REVIEW": false, "DATE": "13 Jan 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "well presented, convincing, but of limited novelty", "is_meta_review": false, "comments": "This paper shows that a deep RL approach augmented with auxiliary tasks improves performance on navigation in complex environments. Specifically, A3C is used for the RL problem, and the agent is simultaneously trained on an unsupervised depth prediction task and a self-supervised loop closure classification task. While the use of auxiliary tasks to improve training of models including RL agents is not new, the main contribution here is the use of tasks that encourage learning an intrinsic representation of space and movement that enables significant improvements on maze navigation tasks.\n\nThe paper is well written, experiments are convincing, and the value of the auxiliary tasks for the problem are clear. However, the contribution is relatively incremental given previous work on RL for navigation and on auxiliary tasks. The work could become of greater interest provided broader analysis and insights on either optimal combinations of tasks for visual navigation (e.g. the value of other visual / geometry-based tasks), or on auxiliary tasks with RL in general.  As it is, it is a useful demonstration of the benefit of geometry-based auxiliary tasks for navigation, but of relatively narrow interest.", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Depth is supervise learning", "is_meta_review": false, "comments": "I do like the demonstration that including learning of auxiliary tasks does not interfere with the RL tasks but even helps. This is also not so surprising with deep networks. The deep structure of the model allows the model to learn first a good representation of the world on which it can base its solutions for specific goals. While even early representations do of course depend on the task performance itself, it is clear that there are common first stages in sensory representations like the need for edge detection etc. Thus, training by additional tasks will at least increase the effective training size. It is of course unclear how to adjust for this to make a fair comparison, but the paper could have included some more insights such as the change in representation with and without auxiliary training. \n\nI still strongly disagree with the implied definition of supervised or even self-supervised learning. The definition of unsupervised is learning without external labels. It does not matter if this comes from a human or for example from an expensive machine that is used to train a network so that a task can be solved later without this expensive machine. I would call EM a self-supervised method where labels are predicted from the model itself and used to bootstrap parameter learning. In this case you are using externally supplied labels, which is clearly a supervised learning task!\n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "TITLE": "Review", "is_meta_review": false, "comments": "This relatively novel work proposes to augment current RL models by adding self-supervised tasks encouraging better internal representations. \nThe proposed tasks are depth prediction and loop closure detection. While these tasks assume a 3D environment as well some position information, such priors are well suited to a large variety of tasks pertaining to navigation and robotics.\n\nExtensive experiments suggest to incorporating such auxiliary tasks increase performance and to a large extent learning speed.\nAdditional analysis of value functions and internal representations suggest that some structure is being discovered by the model, which would not be without the auxiliary tasks.\n\n\nWhile specific to 3D-environment tasks, this work provides additional proof that using input data in addition to sparse external reward signals helps to boost learning speed as well as learning better internal representation. It is original, clearly presented, and strongly supported by empirical evidence.\n\nOne small downside of the experimental method (or maybe just the results shown) is that by picking top-5 runs, it is hard to judge whether such a model is better suited to the particular hyperparameter range that was chosen, or is simply more robust to these hyperparameter settings. Maybe an analysis of performance as a function of hyperparameters would help confirm the superiority of the approach to the baselines. My own suspicion is that adding auxiliary tasks would make the model robust to bad hyperparameters.\n\nAnother downside is that the authors dismiss navigation literature as \"not RL\". I sympathize with the limit on the number of things that can fit in a paper, but some experimental comparison with such literature may have proven insightful, if just in measuring the quality of the learned representations.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "other auxiliary tasks and gradient contribution", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_META_REVIEW": false, "DATE": "04 Dec 2016", "is_meta_review": false}, {"TITLE": "A few questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "", "IS_META_REVIEW": false, "DATE": "01 Dec 2016", "is_meta_review": false}, {"TITLE": "Unsupervised depth perception", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "", "IS_META_REVIEW": false, "DATE": "28 Nov 2016", "is_meta_review": false}, {"TITLE": "Paper update", "OTHER_KEYS": "Piotr W Mirowski", "comments": "We have just submitted an updated version of the paper, including additional references as well as new results on those agents that are enhanced with auxiliary tasks.\nSpecifically, we investigated:\n1) a new way of performing depth prediction, by formulating it as a classification task (over the quantized depth image) and compared it to depth regression.\n2) the use of depth prediction as an auxiliary task for the policy LSTM, instead of the convnet.\n3) the effect, during actor critic training, of reward clipping on the performance of the agent as well as on the stability of RL learning.", "IS_META_REVIEW": false, "DATE": "26 Nov 2016", "is_meta_review": false}, {"TITLE": "Prior Work", "OTHER_KEYS": "Kai Arulkumaran", "comments": "I like the approach (and more thorough insights) into making the RL problem easier by providing additional, related SL tasks to learn; however I think that \"Recurrent Reinforcement Learning: A Hybrid Approach\" should be cited as previous work in this regard (on top of Lample & Chaplot).", "IS_META_REVIEW": false, "DATE": "15 Nov 2016", "is_meta_review": false}], "SCORE": 7, "authors": "Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andy Ballard, Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu, Dharshan Kumaran, Raia Hadsell", "KEYWORDS": "We proposed a deep RL method, augmented with memory and auxiliary learning targets, for training agents to navigate within large and visually rich environments that include frequently changing start and goal locations", "accepted": true, "id": ""}
