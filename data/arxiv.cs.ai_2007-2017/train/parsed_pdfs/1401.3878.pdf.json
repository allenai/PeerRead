{
  "name" : "1401.3878.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Computing Small Unsatisfiable Cores in Satisfiability Modulo Theories",
    "authors" : [ "Alessandro Cimatti", "Alberto Griggio", "Roberto Sebastiani" ],
    "emails" : [ "cimatti@fbk.eu", "griggio@fbk.eu", "rseba@disi.unitn.it" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this paper we present a novel approach to this problem, called the Lemma-Lifting approach. The main idea is to combine an SMT solver with an external propositional core extractor. The SMT solver produces the theory lemmas found during the search, dynamically lifting the suitable amount of theory information to the Boolean level. The core extractor is then called on the Boolean abstraction of the original SMT problem and of the theory lemmas. This results in an unsatisfiable core for the original SMT problem, once the remaining theory lemmas are removed.\nThe approach is conceptually interesting, and has several advantages in practice. In fact, it is extremely simple to implement and to update, and it can be interfaced with every propositional core extractor in a plug-and-play manner, so as to benefit for free of all unsat-core reduction techniques which have been or will be made available.\nWe have evaluated our algorithm with a very extensive empirical test on SMT-LIB benchmarks, which confirms the validity and potential of this approach."
    }, {
      "heading" : "1. Motivations and Goals",
      "text" : "In the last decade we have witnessed an impressive advance in the efficiency of SAT techniques, which has brought large and previously-intractable problems at the reach of stateof-the-art SAT solvers. As a consequence, SAT solvers are now a fundamental tool in many industrial-strength applications, including most formal verification design flows for hardware systems, for equivalence, property checking, and ATPG. In particular, one of the most relevant problems in this context, thanks to its many important applications, is that of finding small unsatisfiable cores, that is, small unsatisfiable subsets of unsatisfiable sets of clauses.\nc©2011 AI Access Foundation. All rights reserved.\nExamples of such applications include use of SAT instead of BDDs for unbounded symbolic model checking (McMillan, 2002), automatic predicate discovery in abstraction refinement frameworks (McMillan & Amla, 2003; Wang, Kim, & Gupta, 2007), decision procedures (Bryant, Kroening, Ouaknine, Seshia, Strichman, & Brady, 2009), under-approximation and refinement in the context of bounded model checking of multi-threaded systems (Grumberg, Lerda, Strichman, & Theobald, 2005), debugging of design errors in circuits (Suelflow, Fey, Bloem, & Drechsler, 2008). For this reason, the problem of finding small unsat cores in SAT has been addressed by many authors in the recent years (Zhang & Malik, 2003; Goldberg & Novikov, 2003; Lynce & Marques-Silva, 2004; Oh, Mneimneh, Andraus, Sakallah, & Markov, 2004; Mneimneh, Lynce, Andraus, Marques-Silva, & Sakallah, 2005; Huang, 2005; Dershowitz, Hanna, & Nadel, 2006; Zhang, Li, & Shen, 2006; Biere, 2008; Gershman, Koifman, & Strichman, 2008; van Maaren & Wieringa, 2008; Aśın, Nieuwenhuis, Oliveras, & Rodŕıguez Carbonell, 2008; Nadel, 2010).\nThe formalism of plain propositional logic, however, is often not suitable or expressive enough for representing many other real-world problems, including the verification of RTL designs, of real-time and hybrid control systems, and the analysis of proof obligations in software verification. Such problems are more naturally expressible as satisfiability problems in decidable first-order theories —Satisfiability Modulo Theories, SMT. Efficient SMT solvers have been developed in the last five years, called lazy SMT solvers, which combine a Conflict-Driven Clause Learning (CDCL) SAT solver based on the DPLL algorithm (Davis & Putnam, 1960; Davis, Logemann, & Loveland, 1962; Marques-Silva & Sakallah, 1996; Zhang & Malik, 2002) — hereafter simply “DPLL” — with ad-hoc decision procedures for many theories of interest (see, e.g., Nieuwenhuis, Oliveras, & Tinelli, 2006; Barrett & Tinelli, 2007; Bruttomesso, Cimatti, Franzén, Griggio, & Sebastiani, 2008; Dutertre & de Moura, 2006; de Moura & Bjørner, 2008).\nSurprisingly, the problem of finding unsatisfiable cores in SMT has received virtually no attention in the literature. Although some SMT tools do compute unsat cores, this is done either as a byproduct of the more general task of producing proofs, or by modifying the embedded DPLL solver so that to apply basic propositional techniques to produce an unsat core. In particular, we are not aware of any work aiming at producing small unsatisfiable cores in SMT.\nIn this paper we present a novel approach addressing this problem, which we call the Lemma-Lifting approach. The main idea is to combine an SMT solver with an external propositional core extractor. The SMT solver stores and returns the theory lemmas it had to prove in order to refute the input formula; the external core extractor is then called on the Boolean abstraction of the original SMT problem and of the theory lemmas. Our algorithm is based on the following two key observations: i) the theory lemmas discovered by the SMT solver during search are valid clauses in the theory T under consideration, and therefore they do not affect the satisfiability of a formula in T ; and ii) the conjunction of the original SMT formula with all the theory lemmas is propositionally unsatisfiable. Therefore, the external (Boolean) core extractor finds an unsatisfiable core for (the Boolean abstraction of) the conjunction of the original formula and the theory lemmas, which can then be refined back into a subset of the original clauses by simply removing from it (the Boolean abstractions of) all theory lemmas. The result is an unsatisfiable core of the original SMT problem.\nAlthough simple in principle, the approach is conceptually interesting: basically, the SMT solver is used to dynamically lift the suitable amount of theory information to the Boolean level. Furthermore, the approach has several advantages in practice: first, it is extremely simple to implement and to update; second, it is effective in finding small cores; third, the core extraction is not prone to complex SMT reasoning; finally, it can be interfaced with every propositional core extractor in a plug-and-play manner, so as to benefit for free of all unsat-core reduction techniques which have been or will be made available.\nWe have evaluated our approach by a very extensive empirical test on SMT-LIB benchmarks, in terms of both effectiveness (reduction in size of the cores) and efficiency (execution time). The results confirm the validity and versatility of this approach.\nAs a byproduct, we have also produced an extensive and insightful evaluation of the main Boolean unsat-core-generation tools currently available.\nContent. The paper is organized as follows. In §2 and §3 we provide some background knowledge on techniques for SAT and SMT (§2), and for the extraction of unsatisfiable cores in SAT and in SMT (§3). In §4 we present and discuss our new approach and algorithm. In §5 we present and comment on the empirical tests. In §6 we conclude, suggesting some future developments."
    }, {
      "heading" : "2. SAT and SMT",
      "text" : "Our setting is standard first order logic. A 0-ary function symbol is called a constant. A term is a first-order term built out of function symbols and variables. If t1, . . . , tn are terms and p is a predicate symbol, then p(t1, . . . , tn) is an atom. A formula φ is built in the usual way out of the universal and existential quantifiers, Boolean connectives, and atoms. A literal is either an atom or its negation. We call a formula quantifier-free if it does not contain quantifiers, and ground if it does not contain free variables. A clause is a disjunction of literals. A formula is said to be in conjunctive normal form (CNF) if it is a conjunction of clauses. For every non-CNF formula ϕ, an equisatisfiable CNF formula ψ can be generated in polynomial time (Tseitin, 1983).\nWe also assume the usual first-order notions of interpretation, satisfiability, validity, logical consequence, and theory, as given, e.g., by Enderton (1972). We write Γ |= φ to denote that the formula φ is a logical consequence of the (possibly infinite) set Γ of formulas. A first-order theory, T , is a set of first-order sentences. A structure A is a model of a theory T if A satisfies every sentence in T . A formula is satisfiable in T (or T -satisfiable) if it is satisfiable in a model of T . (We sometimes use the word “T -formula” for a ground formula when we are interested in determining its T -satisfiability.)\nIn what follows, with a little abuse of notation, we might sometimes denote conjunctions of literals l1 ∧ . . . ∧ ln as sets {l1, . . . , ln} and vice versa. If η ≡ {l1, . . . , ln}, we might write ¬η to mean ¬l1 ∨ . . . ∨ ¬ln. Moreover, following the terminology of the SAT and SMT communities, we shall refer to predicates of arity zero as propositional variables, and to uninterpreted constants as theory variables.\nGiven a first-order theory T for which the (ground) satisfiability problem is decidable, we call a theory solver for T , T -solver, any tool able to decide the satisfiability in T of sets/conjunctions of ground atomic formulas and their negations — theory literals or T - literals — in the language of T . If the input set of T -literals µ is T -unsatisfiable, then a\ntypical T -solver not only returns unsat, but it also returns the subset η of T -literals in µ which was found T -unsatisfiable. (η is hereafter called a theory conflict set, and ¬η a theory conflict clause.) If µ is T -satisfiable, then T -solver not only returns sat, but it may also be able to discover one (or more) deductions in the form {l1, . . . , ln} |=T l, s.t. {l1, . . . , ln} ⊆ µ and l is an unassigned T -literal. If so, we call ( ∨n i=1 ¬li ∨ l) a theory-deduction clause. Importantly, notice that both theory-conflict clauses and theory-deduction clauses are valid in T . We call them theory lemmas or T -lemmas.\nSatisfiability Modulo (the) Theory T — SMT (T ) — is the problem of deciding the satisfiability of Boolean combinations of propositional atoms and theory atoms. Examples of useful theories are equality and uninterpreted functions (EUF), difference logic (DL) and linear arithmetic (LA), either over the reals (LA(Q)) or the integers (LA(Z)), the theory of arrays (AR), that of bit vectors (BV), and their combinations. We call an SMT (T ) tool any tool able to decide SMT (T ). Notice that, unlike a T -solver, an SMT (T ) tool must handle also Boolean connectives.\nHereafter we adopt the following terminology and notation. The symbols ϕ, ψ denote T -formulas, and µ, η denote sets of T -literals; ϕp, ψp denote propositional formulas, µp, ηp denote sets of propositional literals, which can be interpreted as truth assignments to variables."
    }, {
      "heading" : "2.1 Propositional Satisfiability with the DPLL Algorithm",
      "text" : "Most state-of-the-art SAT procedures are evolutions of the Davis-Putnam-Longeman-Loveland (DPLL) procedure (Davis & Putnam, 1960; Davis et al., 1962). A high-level schema of a modern DPLL engine, adapted from the description given by Zhang and Malik (2002),"
    }, {
      "heading" : "1. SatValue Lazy SMT Solver (T -formula ϕ) {",
      "text" : "is reported in Figure 1.1 The Boolean formula ϕ is in CNF; the assignment µ is initially empty, and it is updated in a stack-based manner.\nIn the main loop, decide next branch(ϕ, µ) chooses an unassigned literal l from ϕ according to some heuristic criterion, and adds it to µ. (This operation is called decision, l is called decision literal end the number of decision literals in µ after this operation is called the decision level of l.) In the inner loop, deduce(ϕ, µ) iteratively deduces literals l deriving from the current assignment and updates µ accordingly; this step is repeated until either µ satisfies ϕ, or µ falsifies ϕ, or no more literals can be deduced, returning sat, conflict and unknown respectively. (The iterative application of Boolean deduction steps in deduce is also called Boolean Constraint Propagation, BCP.) In the first case, DPLL returns sat. In the second case, analyze conflict(ϕ, µ) detects the subset η of µ which caused the conflict (conflict set) and the decision level blevel to backtrack. If blevel < 0, then a conflict exists even without branching, and DPLL returns unsat. Otherwise, backtrack(blevel, ϕ, µ) adds the clause ¬η to ϕ (learning) and backtracks up to blevel (backjumping), updating µ accordingly. (E.g., with the popular 1st-UIP schema, it backtracks to the smallest blevel where all but one literal in η are assigned, and hence it deduces the negation of the remaining literal applying BCP on the learned clause ¬η; see Zhang, Madigan, Moskewicz, & Malik, 2001.) In the third case, DPLL exits the inner loop, looking for the next decision.\nFor a much deeper description of modern DPLL-based SAT solvers, we refer the reader, e.g., to the work of Zhang and Malik (2002)."
    }, {
      "heading" : "2.2 Lazy Techniques for SMT",
      "text" : "The idea underlying every lazy SMT (T ) procedure is that (a complete set of) the truth assignments for the propositional abstraction of ϕ are enumerated and checked for satisfiability in T ; the procedure either returns sat if one T -satisfiable truth assignment is found, or returns unsat otherwise.\nWe introduce the following notation. T 2P is a bijective function (“theory to propositional”), called Boolean (or propositional) abstraction, which maps propositional variables into themselves, ground T -atoms into fresh propositional variables, and is homomorphic\n1. We remark that many of the details provided here are not critical for understanding the rest of the paper, but are mentioned only for the sake of completeness.\nw.r.t. Boolean operators and set inclusion. The function P2T (“propositional to theory”), called refinement, is the inverse of T 2P. (E.g., T 2P({((x − y ≤ 3) ∨ A3), (A2 → (x = z))}) = {(B1 ∨ A3), (A2 → B2)}, B1 and B2 being fresh propositional variables, and P2T ({A1,¬A2,¬B1, B2}) = {A1,¬A2,¬(x − y ≤ 3), (x = z)}.) In what follows, we shall use the “p” superscript for denoting the Boolean abstraction of a formula/truth assignment (e.g., ϕp denotes T 2P(ϕ), µ denotes P2T (µp)). Given a T -formula ϕ, we say that ϕ is propositionally unsatisfiable when T 2P(ϕ) |= ⊥. .\nFigure 2 presents a simplified schema of a lazy SMT (T ) procedure, called the off-line schema. The propositional abstraction ϕp of the input formula ϕ is given as input to a SAT solver based on the DPLL algorithm (Davis et al., 1962; Zhang & Malik, 2002), which either decides that ϕp is unsatisfiable, and hence ϕ is T -unsatisfiable, or returns a satisfying assignment µp; in the latter case, P2T (µp) is given as input to T -solver. If P2T (µp) is found T -consistent, then ϕ is T -consistent. If not, T -solver returns the conflict set η which caused the T -inconsistency of P2T (µp); the abstraction of the T -lemma ¬η, T 2P(¬η), is then added as a clause to ϕp. Then the DPLL solver is restarted from scratch on the resulting formula.\nPractical implementations follow a more elaborated schema, called the on-line schema (see Barrett, Dill, & Stump, 2002; Audemard, Bertoli, Cimatti, Korni lowicz, & Sebastiani, 2002; Flanagan, Joshi, Ou, & Saxe, 2003). As before, ϕp is given as input to a modified version of DPLL, and when a satisfying assignment µp is found, the refinement µ of µp is fed to the T -solver; if µ is found T -consistent, then ϕ is T -consistent; otherwise, T -solver returns the conflict set η which caused the T -inconsistency of P2T (µp). Then the clause ¬ηp is added in conjunction to ϕp, either temporarily or permanently (T -learning), and, rather than starting DPLL from scratch, the algorithm backtracks up to the highest point in the search where one of the literals in ¬ηp is unassigned (T -backjumping), and therefore its value is (propositionally) implied by the others in ¬ηp.\nAn important variant of this schema (Nieuwenhuis et al., 2006) is that of building a “mixed Boolean+theory conflict clause”, starting from ¬ηp and applying the backwardtraversal of the implication graph built by DPLL (Zhang et al., 2001), until one of the standard conditions (e.g., 1st UIP – Zhang et al., 2001) is achieved.\nOther important optimizations are early pruning and theory propagation: the T -solver is invoked also on (the refinement of) an intermediate assignment µ: if it is found T - unsatisfiable, then the procedure can backtrack, since no extension of µ can be T -satisfiable; if not, and if the T -solver performs a deduction {l1, . . . , ln} |=T l s.t. {l1, . . . , ln} ⊆ µ, then T 2P(l) can be unit-propagated, and the Boolean abstraction of the T -lemma ( ∨n i=1 ¬li ∨ l) can be learned.\nThe on-line lazy SMT (T ) schema is a coarse description of the procedures underlying all the state-of-the-art lazy SMT (T ) tools like, e.g., BarceLogic, CVC3, MathSAT, Yices, Z3. The interested reader is pointed to, e.g., the work of Nieuwenhuis et al. (2006), Barrett and Tinelli (2007), Bruttomesso et al. (2008), Dutertre and de Moura (2006), and de Moura and Bjørner (2008), for details and further references, or to the work of Sebastiani (2007) and Barrett, Sebastiani, Seshia, and Tinelli (2009) for a survey."
    }, {
      "heading" : "3. Extracting Unsatisfiable Cores",
      "text" : "Without loss of generality, in the following we consider only formulas in CNF. Given an unsatisfiable CNF formula ϕ, we say that an unsatisfiable CNF formula ψ is an unsatisfiable core of ϕ iff ϕ = ψ∧ψ′ for some (possibly empty) CNF formula ψ′. Intuitively, ψ is a subset of the clauses in ϕ causing the unsatisfiability of ϕ. An unsatisfiable core ψ is minimal iff the formula obtained by removing any of the clauses of ψ is satisfiable. A minimum unsat core is a minimal unsat core with the smallest possible cardinality."
    }, {
      "heading" : "3.1 Techniques for Unsatisfiable-Core Extraction in SAT",
      "text" : "In the last few years, several algorithms for computing small, minimal or minimum unsatisfiable cores of propositional formulas have been proposed. In the approach of Zhang and Malik (2003) and Goldberg and Novikov (2003), they are computed as a byproduct of a DPLL-based proof-generation procedure. The computed unsat core is simply the collection of all the original clauses that the DPLL solver used to derive the empty clause by resolution. The returned core is not minimal in general, but it can be reduced by iterating the algorithm until a fixpoint, using as input of each iteration the core computed at the previous one. The algorithm of Gershman et al. (2008), instead, manipulates the resolution proof so as to shrink the size of the core, using also a fixpoint iteration as Zhang and Malik (2003) to further enhance the quality of the results. Oh et al. (2004) present an algorithm to compute minimal unsat cores. The technique is based on modifications of a standard DPLL engine, and works by adding some extra variables (selectors) to the original clauses, and then performing a branch-and-bound algorithm on the modified formula. The procedure presented by Huang (2005) extracts minimal cores using BDD manipulation techniques, removing one clause at a time until the remaining core is minimal. The construction of a minimal core by Dershowitz et al. (2006) also uses resolution proofs, and it works by iteratively removing from the proof one input clause at a time, until it is no longer possible to prove inconsistency. When a clause is removed, the resolution proof is modified to prevent future use of that clause.\nAs far as the the computation of minimum unsatisfiable cores is concerned, the algorithm of Lynce and Marques-Silva (2004) searches all the unsat cores of the input problem; this is done by introducing selector variables for the original clauses, and by increasing the search space of the DPLL solver to include also such variables; then, (one of) the unsatisfiable subformulas with the smallest number of selectors assigned to true is returned. The approach described by Mneimneh et al. (2005) instead is based on a branch-and-bound algorithm that exploits the relation between maximal satisfiability and minimum unsatisfiability. The same relation is used also by the procedure of Zhang et al. (2006), which is instead based on a genetic algorithm."
    }, {
      "heading" : "3.2 Techniques for Unsatisfiable-Core Extraction in SMT",
      "text" : "To the best of our knowledge, there is no literature explicitly addressing the problem of computing unsatisfiable cores in SMT 2. However, four SMT solvers (i.e. CVC3, Barrett & Tinelli, 2007, MathSAT, Bruttomesso et al., 2008, Yices, Dutertre & de Moura, 2006 and\n2. Except for a previous short version of the present paper (Cimatti, Griggio, & Sebastiani, 2007).\nZ3, de Moura & Bjørner, 2008) support unsat core generation3. In the following, we describe the underlying approaches, that generalize techniques for propositional UC extraction. We preliminarily remark that none of these solvers aims at producing minimal or minimum unsat cores, nor does anything to reduce their size.\nStrictly related with this work, Liffiton and Sakallah (2008) presented a general technique for enumerating all minimal unsatisfiable subsets of a given inconsistent set of constraints, which they implemented in the tool CAMUS. Although the description of the properties and algorithms focuses on pure SAT, the authors remark that the approach extends easily to SMT, and that they have implemented inside CAMUS a SMT version of the procedure. Therefore in the following we briefly describe also their approach."
    }, {
      "heading" : "3.2.1 Proof-Based UC Extraction.",
      "text" : "CVC3 and MathSAT can run in proof-producing mode, and compute unsatisfiable cores as a byproduct of the generation of proofs. Similarly to the approach of Zhang and Malik (2003), the idea is to analyze the proof of unsatisfiability backwards, and to return an unsatisfiable core that is a collection of the assumptions (i.e. the clauses of the original problem) that are used in the proof to derive contradiction.\n3. The information reported here on the computation of unsat cores in CVC3, Yices and Z3 comes from private communications from the authors and from the user manual of CVC3.\nExample 1 In order to show how the described approaches work, consider this small unsatisfiable SMT (T ) formula, where T is LA(Z):\n((x = 0) ∨ ¬(x = 1) ∨A1) ∧ ((x = 0) ∨ (x = 1) ∨A2) ∧ (¬(x = 0) ∨ (x = 1) ∨A2)∧ (¬A2 ∨ (y = 1)) ∧ (¬A1 ∨ (x+ y > 3)) ∧ (y < 0) ∧ (A2 ∨ (x− y = 4))∧\n((y = 2) ∨ ¬A1) ∧ (x ≥ 0), (1)\nwhere x and y are real variables and A1 and A2 are Booleans.\nIn the proof-based approach, a resolution proof of unsatisfiability is built during the search. E.g., Figure 3 shows the proof tree found by MathSAT. The leaves of the tree are either original clauses (boxed in the Figure) or LA(Z)-lemmas (denoted with the LA(Z) suffix). The unsatisfiable core is built by collecting all the original clauses appearing as leaves in the proof. In this case, this is:\n{((x = 0) ∨ ¬(x = 1) ∨A1), ((x = 0) ∨ (x = 1) ∨A2), (¬(x = 0) ∨ (x = 1) ∨A2), (¬A2 ∨ (y = 1)), (y < 0), ((y = 2) ∨ ¬A1)}. (2)"
    }, {
      "heading" : "In this case, the unsat core is minimal.",
      "text" : ""
    }, {
      "heading" : "3.2.2 Assumption-Based UC Extraction",
      "text" : "The approach used by Yices (Dutertre & de Moura, 2006) and Z3 (de Moura & Bjørner, 2008) is an adaptation of the method by Lynce and Marques-Silva (2004): for each clause Ci in the problem, a new Boolean “selector” variable Si is created; then, each Ci is replaced by (Si → Ci); finally, before starting the search each Si is forced to true. In this way, when a conflict at decision level zero is found by the DPLL solver the conflict clause contains only selector variables, and the unsat core returned is the union of the clauses whose selectors appear in such conflict clause.\nExample 2 Consider again the formula (1) of Example 1. In the assumption-based approach, each of the 9 input clauses is augmented with an extra variable Si, which is asserted to true at the beginning of the search. The formula therefore becomes:∧\ni\nSi ∧\n(S1 → ((x = 0) ∨ ¬(x = 1) ∨A1)) ∧ (S2 → ((x = 0) ∨ (x = 1) ∨A2)) ∧ (S3 → (¬(x = 0) ∨ (x = 1) ∨A2)) ∧ (S4 → (¬A2 ∨ (y = 1))) ∧ (S5 → (¬A1 ∨ (x+ y > 3))) ∧ (S6 → (y < 0)) ∧ (S7 → (A2 ∨ (x− y = 4))) ∧ (S8 → ((y = 2) ∨ ¬A1)) ∧ (S9 → (x ≥ 0))\n(3)\nThe final conflict clause generated by conflict analysis (Zhang et al., 2001) is: 4\n¬S1 ∨ ¬S2 ∨ ¬S3 ∨ ¬S4 ∨ ¬S6 ∨ ¬S7 ∨ ¬S8, (4)\n4. using Yices.\ncorresponding to the following unsat core:\n{((x = 0) ∨ ¬(x = 1) ∨A1), ((x = 0) ∨ (x = 1) ∨A2), (¬(x = 0) ∨ (x = 1) ∨A2), (¬A2 ∨ (y = 1)), (y < 0), (A2 ∨ (x− y = 4)), ((y = 2) ∨ ¬A1)}. (5)\nNotice that this is not minimal, because of the presence of the redundant clause (A2∨(x−y = 4)), corresponding to ¬S7 in the final conflict clause (4).\nRemark 1 The idea behind the two techniques just illustrated is essentially the same. Both exploit the implication graph built by DPLL during conflict analysis to detect the subset of the input clauses that were used to decide unsatisfiability. The main difference is that in the proof-based approach this is done by explicitly constructing the proof tree, while in the activation-based one this can be done “implicitly” by “labeling” each of the original clauses. For a deeper comparison between these two approaches (and some variants of them), we refer the reader to the work of Aśın et al. (2008) and Nadel (2010)."
    }, {
      "heading" : "3.2.3 The CAMUS Approach for Extracting All Minimal UC’s.",
      "text" : "A completely different approach, aiming at generating all minimal UC’s of some given inconsistent set of propositional clauses Φ, is presented by Liffiton and Sakallah (2008) and implemented in the tool CAMUS. In a nutshell, the approach works in two distinct phases:\n(a) enumerate the set M of all Minimal Correction Subsets (MCS’s) of Φ. 5 This is performed by a specialized algorithm, using as backend engine an incremental SAT solver able to handle also AtMost constraints;\n(b) enumerate the set U of all the minimal UC’s of Φ as minimal hitting sets of the set M . This is also performed by a specialized algorithm. Alternatively, another algorithm can produce from M only one minimal UC with much less effort.\nIt is important to notice that both sets M and U returned can be exponentially big wrt. the size of Φ. Thus, the procedure may produce an exponential amount of MCS’s during phase (a) before producing one UC. To this extent, the authors provide also some modified and more efficient version of the technique, which sacrifice the completeness of the approach. We refer the reader to the work of Liffiton and Sakallah (2008) for a more detailed explanation of this technique and of its features.\nAs mentioned above, although the description of the algorithms focuses on pure SAT, the authors remark that the approach extends easily to SMT, and that they have implemented inside CAMUS a version of the algorithm working also for SMT, using Yices as backend SMT solver. Unfortunately, they provide no details of such an extension. 6\n5. A MCS Ψ of an unsatisfiable set of constraint Φ is the complement set of a maximal consistent subset of Φ: Φ \\ Ψ is consistent and, for every Ci ∈ Ψ, Φ \\ (Ψ \\ Ci) is inconsistent (Liffiton & Sakallah, 2008). 6. See §10 “Conclusions and Future Work.” of the article by Liffiton and Sakallah (2008).\nExample 3 Consider again the LA(Z)-formula (1) of Example 1 in form of clause set\nΦ def =  c1 : (x = 0) ∨ ¬(x = 1) ∨A1, c2 : (x = 0) ∨ (x = 1) ∨A2, c3 : ¬(x = 0) ∨ (x = 1) ∨A2, c4 : ¬A2 ∨ (y = 1), c5 : ¬A1 ∨ (x+ y > 3), c6 : (y < 0), c7 : A2 ∨ (x− y = 4), c8 : (y = 2) ∨ ¬A1, c9 : (x ≥ 0)  . (6)\nWhen run on (6), CAMUS returns the following two minimal UC’s:\nuc1 def = uc2 def = c1 : (x = 0) ∨ ¬(x = 1) ∨A1, c2 : (x = 0) ∨ (x = 1) ∨A2, c3 : ¬(x = 0) ∨ (x = 1) ∨A2, c4 : ¬A2 ∨ (y = 1), c5 : ¬A1 ∨ (x+ y > 3), c6 : (y < 0)  ,  c1 : (x = 0) ∨ ¬(x = 1) ∨A1, c2 : (x = 0) ∨ (x = 1) ∨A2, c3 : ¬(x = 0) ∨ (x = 1) ∨A2, c4 : ¬A2 ∨ (y = 1), c6 : (y < 0), c8 : (y = 2) ∨ ¬A1  . (7)\n(Notice that uc2 is identical to the UC found in Example 1.) We understand from Liffiton and Sakallah (2008) that, in order to produce uc1 and uc2, CAMUS enumerates first (not necessarily in this order) the following set of MCS’s:\n{{c1}, {c2}, {c3}, {c4}, {c6}, {c5, c8}} (8)\nand then computes uc1 and uc2 as minimal hitting sets of (8). Notice that (8) is a set of MCS’s because Φ, Φ \\ {c5} and Φ \\ {c8} are LA(Z)-inconsistent, and\n{A1 = ⊥, A2 = ⊥, x = 1, y = −3} |=LA(Z) Φ \\ {c1}, {A1 = ⊥, A2 = ⊥, x = 2, y = −6} |=LA(Z) Φ \\ {c2}, {A1 = ⊥, A2 = ⊥, x = 0, y = −4} |=LA(Z) Φ \\ {c3}, {A1 = ⊥, A2 = >, x = 0, y = −1} |=LA(Z) Φ \\ {c4}, {A1 = ⊥, A2 = >, x = 3, y = 1} |=LA(Z) Φ \\ {c6}, {A1 = >, A2 = ⊥, x = 1, y = −1} |=LA(Z) Φ \\ {c5, c8}.\nMoreover, it contains all MCS’s of Φ because also Φ \\ {c9}, Φ \\ {c5, c9} and Φ \\ {c8, c9} are LA(Z)-inconsistent."
    }, {
      "heading" : "4. A Novel Approach to Building Unsatisfiable Cores in SMT",
      "text" : "We present a novel approach, called the Lemma-Lifting approach, in which the unsatisfiable core is computed a posteriori w.r.t. the execution of the SMT solver, and only if the formula has been found T -unsatisfiable. This is done by means of an external (and possibly optimized) propositional unsat core extractor."
    }, {
      "heading" : "4.1 The Main Ideas",
      "text" : "In the following, we assume that a lazy SMT (T ) procedure has been run over a T - unsatisfiable set of SMT (T ) clauses ϕ =def {C1, . . . , Cn}, and that D1, . . . , Dk denote all the T -lemmas, both theory-conflict and theory-deduction clauses, which have been returned by the T -solver during the run. (Notice that, by definition, T -lemmas are T -valid clauses.) In case of mixed Boolean+theory-conflict clauses (Nieuwenhuis et al., 2006) (see § 2.2), the T -lemmas are those returned by the T -solver that have been used to compute the mixed Boolean+theory-conflict clause, including the initial theory-conflict clause and the theory-deduction clauses corresponding to the theory-propagation steps performed. 7 Under the above assumptions, two simple facts hold.\n(i) Since the T -lemmas Di are valid in T , they do not affect the T -satisfiability of a formula: (ψ ∧Di) |=T ⊥ ⇐⇒ ψ |=T ⊥. (ii) The conjunction of ϕ with all the T -lemmas D1, . . . , Dk is propositionally unsatisfiable: T 2P(ϕ ∧ ∧n i=1Di) |= ⊥.\nFact (i) is self-evident. Fact (ii) is the termination condition of all lazy SMT tools when the input formula is T -unsatisfiable. In the off-line schema of Figure 2, the procedure ends when DPLL establishes that T 2P(ϕ∧ ∧n i=1Di) is unsatisfiable, each Di being the negation of the theory-conflict set ηi returned by the i-th call to the T -solver. Fact (ii) generalizes to the on-line schema, noticing that T -backjumping on a theory-conflict clause Di produces an analogous effect as re-invoking DPLL on ϕp ∧ T 2P(Di), whilst theory propagation on a deduction {l1, . . . , lk} |=T l can be seen as a form on unit propagation on the theorydeduction clause T 2P ( ∨ i ¬li ∨ l).\nExample 4 Consider again formula (1) of Example 1. In order to decide its unsatisfiability, MathSAT generates the following set of LA(Z)-lemmas:\n{(¬(x = 1) ∨ ¬(x = 0)), (¬(y = 2) ∨ ¬(y < 0)), (¬(y = 1) ∨ ¬(y < 0))}. (9)\nNotice that they are all LA(Z)-valid (fact (i)). Then, the Boolean abstraction of (1) is conjoined with the Boolean abstraction of these LA(Z)-lemmas, resulting in the following propositional formula:\n(B1 ∨ ¬B2 ∨A1) ∧ (B1 ∨B2 ∨A2) ∧ (¬B1 ∨B2 ∨A2) ∧ (¬A2 ∨B3)∧ (¬A1 ∨B4) ∧B5 ∧ (A2 ∨B6) ∧ (B7 ∨ ¬A1) ∧B8∧\n(¬B2 ∨ ¬B1) ∧ (¬B7 ∨ ¬B5) ∧ (¬B3 ∨ ¬B5), (10)\nwhere: B1 def = T 2P(x = 0) B5 def = T 2P(y < 0)\nB2 def = T 2P(x = 1) B6 def = T 2P(x− y = 4) B3 def = T 2P(y = 1) B7 def = T 2P(y = 2) B4 def = T 2P(x+ y > 3) B8 def = T 2P(x ≥ 0).\n7. In this case, if the SMT solver did not provide the original T -lemmas when the feature of using mixed Boolean+theory-conflict clauses is active, then the latter feature should be disabled.\nThe propositional formula (10) is unsatisfiable (fact (ii)), as demonstrated by the following resolution proof.\n(B1 ∨B2 ∨ A2)\n(B1 ∨ A1 ∨ A2)\n(B1 ∨ ¬B2 ∨ A1)\n(B7 ∨ A2) (¬B7 ∨ ¬B5)\n(A2 ∨ ¬B5) (¬A2 ∨B3)\n(¬B5 ∨B3)\n(A1 ∨ A2)(B7 ∨ ¬A1)\n(¬B3 ∨ ¬B5)\n¬B5B5\n⊥\n(¬B2 ∨ ¬B1)\n(¬B1 ∨ A2)\n(¬B1 ∨B2 ∨ A2)\nFact (ii) holds also for those SMT tools which learn mixed Boolean+theory-clauses F1, . . . , Fn (instead of T -lemmas), obtained from the T -lemmas D1, . . . , Dn by backward traversal of the implication graph. In fact, in this case, T 2P(ϕ∧ ∧n i=1 Fi) |= ⊥ holds. Since\nϕ ∧ ∧n i=1Di |= ∧n i=1 Fi, because of the way the Fi’s are built, 8 (ii) holds.\nSome SMT tools implement theory-propagation in a slightly different way (e.g. BarceLogic, Nieuwenhuis et al., 2006). If l1, . . . , ln |=T l, instead of learning the T -lemma ¬l1∨ . . .∨¬ln∨ l and unit-propagating l on it, they simply propagate the value of l, without learning any clause. Only if such propagation leads to a conflict later in the search, the theory-deduction clause is learned and used for conflict-analysis. The validity of fact (ii) is not affected by this optimization, because only the T -lemmas used during conflict analysis are needed for it to hold (Nieuwenhuis et al., 2006).\nOverall, in all variants of the on-line schema, the embedded DPLL engine builds –either explicitly or implicitly– a resolution refutation of the Boolean abstraction of the conjunction of the original clauses and the T -lemmas returned by the T -solver. Thus fact (ii) holds."
    }, {
      "heading" : "4.2 Extracting SMT Cores by Lifting Theory Lemmas",
      "text" : "Facts (i) and (ii) discussed in §4.1 suggest a new approach to the generation of unsatisfiable cores for SMT. The main idea is that if the theory lemmas used during the SMT search are lifted into Boolean clauses, then the unsat core can be extracted by a purely propositional core extractor. Therefore, we call this technique the Lemma-Lifting approach.\nThe algorithm is presented in Figure 4. The procedure T -Unsat Core receives as input a set of clauses ϕ =def {C1, . . . , Cn} and it invokes on it a lazy SMT (T ) tool Lazy SMT Solver, which is instructed to store somewhere the T -lemmas returned by the\n8. Each clause T 2P(Fi) is obtained by resolving the clause T 2P(Di) with clauses in T 2P(ϕ∧ ∧i−1\nj=1 Fj), so that T 2P(ϕ ∧ ∧i−1 j=1 Fj ∧Di) |= T 2P(Fi). Thus, by induction, T 2P(ϕ ∧ ∧n i=1 Di) |= T 2P( ∧n\ni=1 Fi), so that ϕ ∧ ∧n i=1 Di |= ∧n i=1 Fi.\nT -solver, namely D1, . . . , Dk. If Lazy SMT Solver returns sat, then the whole procedure returns sat. Otherwise, the Boolean abstraction of {C1, . . . , Cn, D1, . . . , Dk}, which is inconsistent because of (ii), is fed to an external tool Boolean Unsat Core, which is able to return the Boolean unsat core ψp of the input. By construction, ψp is the Boolean abstraction of a clause set {C ′1, . . . , C ′m, D′1, . . . , D′j} s.t. {C ′1, . . . , C ′m} ⊆ {C1, . . . , Cn} and {D′1, . . . , D′j} ⊆ {D1, . . . , Dk}. As ψp is unsatisfiable, then {C ′1, . . . , C ′m, D′1, . . . , D′j} is T - unsatisfiable. By (i), the T -valid clauses D′1, . . . , D′j have no role in the T -unsatisfiability of {C ′1, . . . , C ′m, D′1, . . . , D′j}, so that they can be thrown away, and the procedure returns unsat and the T -unsatisfiable core {C ′1, . . . , C ′m}.\nNotice that the resulting T -unsatisfiable core is not guaranteed to be minimal, even if Boolean Unsat Core returns minimal Boolean unsatisfiable cores. In fact, it might be the case that {C ′1, . . . , C ′m}\\{C ′i} is T -unsatisfiable for some C ′i even though T 2P({C ′1, . . . , C ′m}\\ {C ′i}) is satisfiable, because all truth assignments µp satisfying the latter are such that P2T (µp) is T -unsatisfiable.\nExample 5 Consider the unsatisfiable SMT formula ϕ on LA(Z):\nϕ ≡ ((x = 0) ∨ (x = 1)) ∧ (¬(x = 0) ∨ (x = 1)) ∧ ((x = 0) ∨ ¬(x = 1))∧ (¬(x = 0) ∨ ¬(x = 1))\nand its propositional abstraction T 2P(ϕ):\nT 2P(ϕ) ≡ (B1 ∨B2) ∧ (¬B1 ∨B2) ∧ (B1 ∨ ¬B2) ∧ (¬B1 ∨ ¬B2).\nThen, T 2P(ϕ) is a minimal Boolean unsatisfiable core of itself, but ϕ is not a minimal core in LA(Z), since the last clause is valid in this theory, and hence it can be safely dropped.\nThe procedure can be implemented very simply by modifying the SMT solver so that to store the T -lemmas and by interfacing it with some state-of-the-art Boolean unsat core extractor used as an external black-box device. Moreover, if the SMT solver can provide the set of all T -lemmas as output, then the whole procedure may reduce to a control device interfacing with both the SMT solver and the Boolean core extractor as black-box external devices.\nRemark 2 Notice that here storing the T -lemmas does not mean learning them, that is, the SMT solver is not required to add the T -lemmas to the formula during the search. Instead, it is for instance sufficient to store them in some ad-hoc data structure, or even to dump them to a file. This causes no overhead to the Boolean search in the SMT solver, and imposes no constraint on the lazy strategy adopted (e.g., offline/online, permanent/temporary learning, usage of mixed Boolean+theory conflict clauses, etc.).\nExample 6 Once again, consider formula (1) of Example 1, and the corresponding formula (10) of Example 4, which is the Boolean abstraction of (1) and the LA(Z)-lemmas (9) found by MathSAT during search. In the Lemma-Lifting approach, (10) is given as input to an external Boolean unsat core device. The resulting propositional unsatisfiable core is:\n{(B1 ∨ ¬B2 ∨A1), (B1 ∨B2 ∨A2), (¬B1 ∨B2 ∨A2), (¬A2 ∨B3), B5, (B7 ∨ ¬A1), (¬B2 ∨ ¬B1), (¬B7 ∨ ¬B5), (¬B3 ∨ ¬B5)},\nwhich corresponds (via P2T ) to:\n{((x = 0) ∨ ¬(x = 1) ∨A1), ((x = 0) ∨ (x = 1) ∨A2), (¬(x = 0) ∨ (x = 1) ∨A2), (¬A2 ∨ (y = 1)), B5, ((y = 2) ∨ ¬A1), (¬(x = 1) ∨ ¬(x = 0)), (¬(y = 2) ∨ ¬(y < 0)), (¬(y = 1) ∨ ¬(y < 0))}.\nSince the last three clauses are included in the LA(Z)-lemmas, and thus are LA(Z)-valid, they are eliminated. The resulting core consists of only the first 6 clauses. In this case, the core turns out to be minimal, and is identical modulo reordering to that computed by MathSAT with proof-tracing (see Example 1).\nAs observed at the end of the previous section, our technique works also if the SMT tool learns mixed Boolean+theory clauses (provided that the original T -lemmas are stored), or\nuses the lazy theory deduction of Nieuwenhuis et al. (2006). Moreover, it works also if T -lemmas contain new atoms (i.e. atoms that do not appear in ϕ), as in the approaches of Flanagan et al. (2003), and Barrett, Nieuwenhuis, Oliveras, and Tinelli (2006), since both Facts (ii) and (i) hold also in that case.\nAs a side observation, we remark that the technique works also for the per-constraintencoding eager SMT approach of Goel, Sajid, Zhou, Aziz, and Singhal (1998), and Strichman, Seshia, and Bryant (2002). In the eager SMT approach, the input T -formula ϕ is translated into an equi-satisfiable Boolean formula, and a SAT solver is used to check its satisfiability. With per-constraint-encoding of Goel et al. (1998) and Strichman et al. (2002), the resulting Boolean formula is the conjunction of the propositional abstraction ϕp of ϕ and a formula ϕT which is the propositional abstraction of the conjunction of some T -valid clauses. Therefore, ϕT plays the role of the T -lemmas of the lazy approach, and our approach still works. This idea falls out of the scope of this work, and is not expanded further."
    }, {
      "heading" : "4.3 Discussion",
      "text" : "Despite its simplicity, the proposed approach is appealing for several reasons.\nFirst, it is extremely simple to implement. The building of unsat cores is delegated to an external device, which is fully decoupled from the internal DPLL-based enumerator. Therefore, there is no need of implementing any internal unsat core constructor nor to modify the embedded Boolean device. Every possible external device can be interfaced in a plug-and-play manner by simply exchanging a couple of DIMACS files9.\nSecond, the approach is fully compatible with optimizations carried out by the core extractor at the Boolean level: every original clause which the Boolean unsat core device is able to drop, is also dropped in the final formula. Notably, this involves also Boolean unsat-core techniques which could be very difficult to adapt to the SMT setting (and to implement within an SMT solver), such as the ones based on genetic algorithms (Zhang et al., 2006).\nThird, it benefits for free from the research on propositional unsat-core extraction, since it is trivial to update: once some novel, more efficient or more effective Boolean unsat core device is available, it can be used in a plug-and-play way. This does not require modifying the DPLL engine embedded in the SMT solver.\nOne may remark that, in principle, if the number of T -lemmas generated by the T - solver were huge, the storing of all T -lemmas might cause memory-exhaustion problems or the generation of Boolean formulas which are too big to be handled by the Boolean unsatcore extractor. In practice, however, this is not a real problem. In fact, even the hardest SMT formulas at the reach of current lazy SMT solvers rarely need generating more than 105 T -lemmas, whereas current Boolean unsat core extractors can handle formulas in the order of 106 − 107 clauses. In fact, notice that the default choice in MathSAT is to learn all T -lemmas permanently anyway, and we have never encountered problems due to this fact. Intuitively, unlike with plain SAT, in lazy SMT the computational effort is typically dominated by the search in the theory T , so that the number of clauses that can be stored with a reasonable amount of memory, or which can be fed to a SAT solver, is typically much\n9. DIMACS is a standard format for representing Boolean CNF formulas.\nbigger than the number of calls to the T -solver which can overall be accomplished within a reasonable amount of time.\nLike with the other SMT unsat-core techniques adopted by current SMT solvers, also with our novel approach the resulting T -unsatisfiable core is not guaranteed to be minimal, even if Boolean Unsat Core returns minimal Boolean unsatisfiable cores. However, with the Lemma-Lifting technique it is possible to perform all the reductions that can be done by considering only the Boolean skeleton of the formula. Although this is in general not enough to guarantee minimality, it is still a very significant gain, as we shall show in the next section. Moreover, notice that it is also possible to obtain minimal UC’s by iteratively calling one SMT core extractor, each time dropping one (or more) clause(s) from the current UC and checking for the T -inconsistency. This minimization technique is orthogonal wrt. the SMT core-extractor adopted, and as such it is not investigated here."
    }, {
      "heading" : "5. Empirical Evaluation",
      "text" : "We carried out an extensive experimental evaluation of the the Lemma-Lifting approach. We implemented the approach within the MathSAT (Bruttomesso et al., 2008) system. MathSAT has been extended with an interface for external Boolean unsatisfiable core extractors (UCE) to exchange Boolean formulas and relative cores in form of files in DIMACS format. (No modification was needed for the storage of T -lemmas, because MathSAT already can learn permanently all of them.)\nWe have tried eight different external UCEs, namely Amuse (Oh et al., 2004), PicoSAT (Biere, 2008), Eureka (Dershowitz et al., 2006), MiniUnsat (van Maaren & Wieringa, 2008), MUP (Huang, 2005), Trimmer (Gershman et al., 2008), ZChaff (Zhang & Malik, 2003), and the tool proposed by Zhang et al. (2006) (called Genetic here). All these tools explicitly target core size reduction (or minimality), with the exception of PicoSAT, which was conceived for speeding up core generation, with no claims of minimality. In fact, PicoSAT turned out to be both the fastest and the least effective in reducing the size of the cores. For these reasons, we adopted it as our baseline choice, as it is the ideal starting point for evaluating the trade-off between efficiency (in execution time) and effectiveness (in core size reduction). Thus, we start evaluating our approach by using PicoSAT as external UCE (§5.1) and then we investigate the usage of more effective though more expensive UCE’s (§ 5.2).\nAll the experiments have been performed on a subset of the SMT-LIB (Ranise & Tinelli, 2006) benchmarks. We used a total of 561 T -unsatisfiable problems, taken from the QF UF (126), QF IDL (89), QF RDL (91), QF LIA (135) and QF LRA (120) divisions, selected using the same criteria used in the annual SMT competition. In particular, the benchmarks are selected randomly from the available instances in the SMT-LIB, but giving a higher probability to real-world instances, as opposed to randomly generated or handcrafted ones. (See http://www.smtcomp.org/ for additional details.)\nWe used a preprocessor to convert the instances into CNF (when required), and in some cases we had to translate them from the SMT language to the native language of a particular SMT solver. 10\n10. In particular, CVC3 and Yices can compute unsatisfiable cores only if the problems are given in their own native format.\nAll the tests were performed on 2.66 GHz Intel Xeon machines with 16 GB of RAM running Linux. For each tested instance (unless explicitly stated otherwise) the timeout was set to 600 seconds, and the memory limit to 2 GB. For all the Boolean UCEs, we have used the default configurations."
    }, {
      "heading" : "5.1 Costs and Effectiveness of Unsat-Core Extraction Using PicoSAT",
      "text" : "The two scatter plots in Figure 5 give a first insight on the price that the Lemma-Lifting approach has to pay for running the external UCE. The plot on the left compares the execution time of PicoSAT with the total time of MathSAT+PicoSAT, whilst the plot on the right shows the comparison of the time of PicoSAT against that of MathSAT solving time only. From the two figures, it can be clearly seen that, except for few cases, the time required by PicoSAT is much lower or even negligible wrt. MathSAT solving time. Notice also that this price is payed only in the case of unsatisfiable benchmarks.\nWe now analyze our LL approach with respect to the size of the unsat cores returned. We compare the baseline implementation of our LL approach, MathSAT+PicoSAT, against MathSAT+ProofBasedUC (i.e. MathSAT with proof tracing), CVCLite (Barrett & Tinelli, 2007), 11 and Yices. 12 We have also performed a comparison with (the SMT version of) CAMUS (Liffiton & Sakallah, 2008), running it in “SingleMUS” mode (generate only one minimal UC, “CAMUS-one” hereafter). We also tried to run CAMUS in “AllMUS” mode (generate all minimal UC’s), but we encountered some unexpected results (in some\n11. We tried to use the newer CVC3, but we had some difficulties in the extraction of unsatisfiable cores with it. Therefore, we reverted to the older CVCLite for the experiments. 12. CVCLite version 20061231 and Yices version 1.0.19.\nPoints above the middle line and values greater than 1.00 mean better core quality for MathSAT+PicoSAT, and vice versa.\nexecutions all the generated MUSes were larger than the unsat cores found by the other tools13), and so we had to exclude it from the experiments.\n13. This is very surprising because, by definition, the output produced by CAMUS in “AllMUS” mode should should always contain UC’s of minimum size, and thus smaller than those found by the other tools. Therefore, we have no explanation for such results, apart from conjecturing the presence of some bug in CAMUS, or some incorrect use from our side (although we followed the indications of the authors),\nIn order to allow CAMUS-one terminate for a significant amount of samples, we have run it with an increased timeout of 1800 seconds. Even so, CAMUS-one was able to produce one UC within the timeout only for 144 formulas out of 561. For the record, MathSAT+PicoSAT, MathSAT+ProofBasedUC, CVCLite, and Yices solved within the timeout 474, 503, 253 and 494 problems out of 561 respectively.\nNotice that we do not present any comparison in time between the different tools because it is not significant for determining the relative cost of unsat-core computation, since (i) for all the former four tools the time is completely dominated by the solving time, which varies a lot from solver to solver (even within MathSAT, proof production requires setting ad-hoc options, which may result into significantly-different solving times since a different search space is explored); (ii) a comparison with CAMUS in terms of speed would not be fair, since the ultimate goal of CAMUS is to enumerate all mimimal UC’s, and as such it first runs the very-expensive step of enumerating all MCS’s (see §3.2).\nFigure 6 shows the absolute reduction in size performed by the different solvers: the x-axis displays the size (number of clauses) of the problem, whilst the y-axis displays the ratio between the size of the unsat core and the size of the problem. For instance, a point with y value of 1/10 means that the unsatisfiability is due to only 10% of the problem clauses.\nFigure 7(top) shows relative comparisons of the data of Figure 6. Each plot compares MathSAT+PicoSAT with each of the other solvers. Such plots, which we shall call “core-ratio” plots, have the following meaning: the x-axis displays the size (number of clauses) of the problem, whilst the y-axis displays the ratio between the size of the unsat core computed by CVCLite, MathSAT+ProofBasedUC, Yices or CAMUS-one and that computed by MathSAT+PicoSAT. For instance, a point with y value of 1/2 means that the unsat core computed by the current solver is half the size of that computed by MathSAT+PicoSAT; values above 1 mean a smaller core for MathSAT+PicoSAT. In core-ratio plots, we only consider the instances for which both solvers terminated successfully, since here we are only interested in the size of the cores computed, and not in the execution times. Figure 7(bottom) reports statistics about the ratios of the unsat core sizes computed by two different solvers.\nA comment is in order. The results reported for CAMUS-one are quite surprising wrt. our expectations, since CAMUS-one is supposed to return a minimal UC, so that we would expect greater reductions in core sizes. This can be explained by the fact that the minimal UC produced by CAMUS-one is not necessarily minimum. In fact, we have manually verified for the samples with the biggest core-size ratio that the UC’s returned by CAMUS-one are actually minimal, although significantly bigger than those returned by MathSAT+PicoSAT.\nOverall, the results presented show that, even when using as Boolean UCE PicoSAT, which is the least effective in reducing the size of the cores, the effectiveness of the baseline version of our LL approach is slightly better than those of the other tools.\nor the activation by default of some of the incomplete heuristics CAMUS can use in order to cope with the combinatorial explosion in the number of MCS’s UC’s generated (see §3.2.)\ncolumn), the X-axis represents the size of the problem, and the Y-axis represents the ratio between the size of the cores computed by the two systems: a point above the middle line means better quality for the baseline system. In the scatter plots (3rd column), the baseline system (MathSAT+PicoSAT) is always on the X-axis."
    }, {
      "heading" : "5.2 Impact on Costs and Effectiveness Using Different Boolean Unsat Core Extractors",
      "text" : "In this second part of our experimental evaluation we compare the results obtained using different UCE’s in terms of costs and effectiveness in reducing the size of the core. We show that, depending on the UCE used, it is possible to reduce significantly the size of cores, and to trade core quality for speed of execution (and vice versa), with no implementation\neffort. We compare our baseline configuration MathSAT+PicoSAT, against six other configurations, each calling a different propositional UCE.\nThe results are collected in Figures 8-9. The first column shows the absolute reduction in size performed by each tool (as in Figure 6). The second column shows core-ratio plots comparing each configuration against the baseline one using PicoSAT (as in Figure 7, with points below 1.00 meaning a better performance of the current configuration). Finally, the scatter plots in the third column compare the execution times (with PicoSAT always on the X-axis). We evaluated the six configurations which use, respectively, Amuse (Oh et al., 2004), Genetic (Zhang et al., 2006), Eureka (Dershowitz et al., 2006), MiniUnsat (van Maaren & Wieringa, 2008), Trimmer (Gershman et al., 2008), and ZChaff (Zhang & Malik, 2003), against the baseline configuration, using PicoSAT. We also compared with MUP (Huang, 2005), but we had to stop the experiments because of memory exhaustion\nPoints above the middle line and values greater than 1.00 mean better core quality for MathSAT+Eureka, and vice versa.\nproblems. Looking at the second column, we notice that Eureka, followed by MiniUnsat and ZChaff, seems to be the most effective in reducing the size of the final unsat cores, up to 1/3 the size of those obtained with plain PicoSAT. Looking at the third column, we notice that with Genetic, Amuse, MiniUnsat and ZChaff, and in part with Eureka, efficiency degrades drastically, and many problems cannot be solved within the timeout. With Trimmer the performance gap is not that dramatic, but still up to an order magnitude slower than the baseline version.\nFinally, in Figure 10 we compare the effectiveness of MathSAT+Eureka, the most effective extractor in Figures 8-9, directly with that of the other three solvers, CVCLite, MathSAT+ProofBasedUC and Yices, and with that of CAMUS. (Also compare the results with those in Figure 7.) The gain in core reduction wrt. previous state-of-the-art SMT core-reduction techniques is evident.\nIt is important to notice that, due to our limited know-how, we used the Boolean UCE’s in their default configurations. Therefore, we believe that even better results, in terms of both effectiveness and efficiency, could be obtained by means of a more accurate tuning of the parameters of the core extractors.\nAs a side remark, we notice that the results in Figures 8-9 have produced as a byproduct an insightful evaluation of the main Boolean unsat-core-generation tools currently available. To this extent, we notice that the performances of MUP (Huang, 2005) and Genetic (Zhang et al., 2006) seem rather poor; PicoSAT (Biere, 2008) is definitely the fastest tool, though the least effective in reducing the size of the final core; on the opposite side, Eureka (Dershowitz et al., 2006) is the most effective in this task, but pays a fee in terms of CPU time; Trimmer (Gershman et al., 2008) represents a good compromise between effectiveness and efficiency."
    }, {
      "heading" : "6. Conclusions",
      "text" : "We have presented a novel approach to generating small unsatisfiable cores in SMT, that computes them a posteriori, relying on an external propositional unsat core extractor. The technique is very simple in concept, and straightforward to implement and update. Moreover, it benefits for free of all the advancements in propositional unsat core computation. Our experimental results have shown that, by using different core extractors, it is possible to reduce significantly the size of cores and to trade core quality for speed of execution (and vice versa), with no implementation effort.\nAs a byproduct, we have also produced an insightful evaluation of the main Boolean unsat-core-generation tools currently available."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We wish to thank Mark Liffiton for his help with the CAMUS tool. We also thank the anonymous referees for their helpful suggestions.\nA. Griggio is supported in part by the European Community’s FP7/2007-2013 under grant agreement Marie Curie FP7 - PCOFUND-GA-2008-226070 “progetto Trentino”, project Adaptation.\nR. Sebastiani is supported in part by SRC under GRC Custom Research Project 2009-TJ1880 WOLFLING."
    } ],
    "references" : [ {
      "title" : "Efficient Generation of Unsatisfiability Proofs and Cores in SAT",
      "author" : [ "R. Aśın", "R. Nieuwenhuis", "A. Oliveras", "E. Rodŕıguez Carbonell" ],
      "venue" : "Proceedings of LPAR’08,",
      "citeRegEx" : "Aśın et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Aśın et al\\.",
      "year" : 2008
    }, {
      "title" : "A SAT Based Approach for Solving Formulas over Boolean and Linear Mathematical Propositions",
      "author" : [ "A. lowicz", "R. Sebastiani" ],
      "venue" : "In Proc. CADE’2002.,",
      "citeRegEx" : "lowicz and Sebastiani,? \\Q2002\\E",
      "shortCiteRegEx" : "lowicz and Sebastiani",
      "year" : 2002
    }, {
      "title" : "Splitting on Demand in SAT Modulo Theories",
      "author" : [ "C. Barrett", "R. Nieuwenhuis", "A. Oliveras", "C. Tinelli" ],
      "venue" : "LPAR, Vol. 4246 of LNCS,",
      "citeRegEx" : "Barrett et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Barrett et al\\.",
      "year" : 2006
    }, {
      "title" : "Checking Satisfiability of First-Order Formulas by Incremental Translation to SAT",
      "author" : [ "C.W. Barrett", "D.L. Dill", "A. Stump" ],
      "venue" : "Computer Aided Verification, 14th International Conference,",
      "citeRegEx" : "Barrett et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Barrett et al\\.",
      "year" : 2002
    }, {
      "title" : "Satisfiability modulo theories",
      "author" : [ "C.W. Barrett", "R. Sebastiani", "S.A. Seshia", "C. Tinelli" ],
      "venue" : null,
      "citeRegEx" : "Barrett et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Barrett et al\\.",
      "year" : 2009
    }, {
      "title" : "Picosat essentials",
      "author" : [ "A. Biere" ],
      "venue" : "Journal on Satisfiability, Boolean Modeling and Computation (JSAT),",
      "citeRegEx" : "Biere,? \\Q2008\\E",
      "shortCiteRegEx" : "Biere",
      "year" : 2008
    }, {
      "title" : "The MathSAT 4 SMT Solver",
      "author" : [ "R. Bruttomesso", "A. Cimatti", "A. Franzén", "A. Griggio", "R. Sebastiani" ],
      "venue" : "CAV, Vol. 5123 of LNCS,",
      "citeRegEx" : "Bruttomesso et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Bruttomesso et al\\.",
      "year" : 2008
    }, {
      "title" : "An abstraction-based decision procedure for bit-vector arithmetic",
      "author" : [ "R.E. Bryant", "D. Kroening", "J. Ouaknine", "S.A. Seshia", "O. Strichman", "B. Brady" ],
      "venue" : "Int. J. Softw. Tools Technol. Transf.,",
      "citeRegEx" : "Bryant et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Bryant et al\\.",
      "year" : 2009
    }, {
      "title" : "A Simple and Flexible Way of Computing Small Unsatisfiable Cores in SAT Modulo Theories",
      "author" : [ "A. Cimatti", "A. Griggio", "R. Sebastiani" ],
      "venue" : "SAT, Vol. 4501 of LNCS,",
      "citeRegEx" : "Cimatti et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Cimatti et al\\.",
      "year" : 2007
    }, {
      "title" : "A computing procedure for quantification theory",
      "author" : [ "M. Davis", "H. Putnam" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Davis and Putnam,? \\Q1960\\E",
      "shortCiteRegEx" : "Davis and Putnam",
      "year" : 1960
    }, {
      "title" : "A machine program for theoremproving",
      "author" : [ "M. Davis", "G. Logemann", "D.W. Loveland" ],
      "venue" : "Commun. ACM,",
      "citeRegEx" : "Davis et al\\.,? \\Q1962\\E",
      "shortCiteRegEx" : "Davis et al\\.",
      "year" : 1962
    }, {
      "title" : "A Scalable Algorithm for Minimal Unsatisfiable Core Extraction",
      "author" : [ "N. Dershowitz", "Z. Hanna", "A. Nadel" ],
      "venue" : "In Proceedings of SAT’06,",
      "citeRegEx" : "Dershowitz et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dershowitz et al\\.",
      "year" : 2006
    }, {
      "title" : "A Fast Linear-Arithmetic Solver for DPLL(T)",
      "author" : [ "B. Dutertre", "L. de Moura" ],
      "venue" : "In Proc. CAV’06,",
      "citeRegEx" : "Dutertre and Moura,? \\Q2006\\E",
      "shortCiteRegEx" : "Dutertre and Moura",
      "year" : 2006
    }, {
      "title" : "A Mathematical Introduction to Logic. Academic Pr",
      "author" : [ "H. Enderton" ],
      "venue" : null,
      "citeRegEx" : "Enderton,? \\Q1972\\E",
      "shortCiteRegEx" : "Enderton",
      "year" : 1972
    }, {
      "title" : "Theorem Proving Using Lazy Proof Explication",
      "author" : [ "C. Flanagan", "R. Joshi", "X. Ou", "J.B. Saxe" ],
      "venue" : "CAV, Vol. 2725 of LNCS,",
      "citeRegEx" : "Flanagan et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Flanagan et al\\.",
      "year" : 2003
    }, {
      "title" : "An approach for extracting a small unsatisfiable core",
      "author" : [ "R. Gershman", "M. Koifman", "O. Strichman" ],
      "venue" : "Formal Methods in System Design,",
      "citeRegEx" : "Gershman et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Gershman et al\\.",
      "year" : 2008
    }, {
      "title" : "BDD Based Procedures for a Theory of Equality with Uninterpreted Functions",
      "author" : [ "A. Goel", "K. Sajid", "H. Zhou", "A. Aziz", "V. Singhal" ],
      "venue" : "CAV, Vol. 1427 of LNCS,",
      "citeRegEx" : "Goel et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Goel et al\\.",
      "year" : 1998
    }, {
      "title" : "Verification of Proofs of Unsatisfiability for CNF Formulas",
      "author" : [ "E.I. Goldberg", "Y. Novikov" ],
      "venue" : "In Proceedings of 2003 Design, Automation and Test in Europe Conference and Exposition (DATE",
      "citeRegEx" : "Goldberg and Novikov,? \\Q2003\\E",
      "shortCiteRegEx" : "Goldberg and Novikov",
      "year" : 2003
    }, {
      "title" : "Proof-guided underapproximation-widening for multi-process systems",
      "author" : [ "O. Grumberg", "F. Lerda", "O. Strichman", "M. Theobald" ],
      "venue" : "SIGPLAN Not.,",
      "citeRegEx" : "Grumberg et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Grumberg et al\\.",
      "year" : 2005
    }, {
      "title" : "MUP: a minimal unsatisfiability prover",
      "author" : [ "J. Huang" ],
      "venue" : "In Proceedings of ASP-DAC",
      "citeRegEx" : "Huang,? \\Q2005\\E",
      "shortCiteRegEx" : "Huang",
      "year" : 2005
    }, {
      "title" : "Algortithms for Computing Minimal Unsatisfiable Subsets of Constraints",
      "author" : [ "M. Liffiton", "K. Sakallah" ],
      "venue" : "Journal of Automated Reasoning,",
      "citeRegEx" : "Liffiton and Sakallah,? \\Q2008\\E",
      "shortCiteRegEx" : "Liffiton and Sakallah",
      "year" : 2008
    }, {
      "title" : "On Computing Minimum Unsatisfiable Cores",
      "author" : [ "I. Lynce", "J.P. Marques-Silva" ],
      "venue" : "In SAT 2004 - The Seventh International Conference on Theory and Applications of Satisfiability Testing,",
      "citeRegEx" : "Lynce and Marques.Silva,? \\Q2004\\E",
      "shortCiteRegEx" : "Lynce and Marques.Silva",
      "year" : 2004
    }, {
      "title" : "GRASP - A new Search Algorithm for Satisfiability",
      "author" : [ "J.P. Marques-Silva", "K.A. Sakallah" ],
      "venue" : "In Proc. ICCAD’96",
      "citeRegEx" : "Marques.Silva and Sakallah,? \\Q1996\\E",
      "shortCiteRegEx" : "Marques.Silva and Sakallah",
      "year" : 1996
    }, {
      "title" : "Applying SAT Methods in Unbounded Symbolic Model Checking",
      "author" : [ "K.L. McMillan" ],
      "venue" : "Proceedings of CAV’02,",
      "citeRegEx" : "McMillan,? \\Q2002\\E",
      "shortCiteRegEx" : "McMillan",
      "year" : 2002
    }, {
      "title" : "Automatic abstraction without counterexamples",
      "author" : [ "K.L. McMillan", "N. Amla" ],
      "venue" : "Proceedings of TACAS’03,",
      "citeRegEx" : "McMillan and Amla,? \\Q2003\\E",
      "shortCiteRegEx" : "McMillan and Amla",
      "year" : 2003
    }, {
      "title" : "A Branch-and-Bound Algorithm for Extracting Smallest Minimal Unsatisfiable Formulas",
      "author" : [ "M.N. Mneimneh", "I. Lynce", "Z.S. Andraus", "J.P. Marques-Silva", "K.A. Sakallah" ],
      "venue" : "In Proc. SAT’05,",
      "citeRegEx" : "Mneimneh et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Mneimneh et al\\.",
      "year" : 2005
    }, {
      "title" : "Boosting Minimal Unsatisfiable Core Extraction",
      "author" : [ "A. Nadel" ],
      "venue" : "Proceedings of the 10th International Conference on Formal Methods in Computer-Aided Design",
      "citeRegEx" : "Nadel,? \\Q2010\\E",
      "shortCiteRegEx" : "Nadel",
      "year" : 2010
    }, {
      "title" : "Solving SAT and SAT Modulo Theories: From an abstract Davis–Putnam–Logemann–Loveland procedure to DPLL(T)",
      "author" : [ "R. Nieuwenhuis", "A. Oliveras", "C. Tinelli" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Nieuwenhuis et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Nieuwenhuis et al\\.",
      "year" : 2006
    }, {
      "title" : "Amuse: A Minimally-Unsatisfiable Subformula Extractor",
      "author" : [ "Y. Oh", "M.N. Mneimneh", "Z.S. Andraus", "K.A. Sakallah", "I.L. Markov" ],
      "venue" : "In Proceedings of DAC’04. ACM/IEEE",
      "citeRegEx" : "Oh et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Oh et al\\.",
      "year" : 2004
    }, {
      "title" : "The Satisfiability Modulo Theories Library (SMT-LIB). www.SMT-LIB.org",
      "author" : [ "S. Ranise", "C. Tinelli" ],
      "venue" : null,
      "citeRegEx" : "Ranise and Tinelli,? \\Q2006\\E",
      "shortCiteRegEx" : "Ranise and Tinelli",
      "year" : 2006
    }, {
      "title" : "Lazy Satisfiability Modulo Theories",
      "author" : [ "R. Sebastiani" ],
      "venue" : "Journal on Satisfiability, Boolean Modeling and Computation, JSAT,",
      "citeRegEx" : "Sebastiani,? \\Q2007\\E",
      "shortCiteRegEx" : "Sebastiani",
      "year" : 2007
    }, {
      "title" : "Deciding Separation Formulas with SAT",
      "author" : [ "O. Strichman", "S.A. Seshia", "R.E. Bryant" ],
      "venue" : "CAV, Vol. 2404 of LNCS,",
      "citeRegEx" : "Strichman et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Strichman et al\\.",
      "year" : 2002
    }, {
      "title" : "Using unsatisfiable cores to debug multiple design errors",
      "author" : [ "A. Suelflow", "G. Fey", "R. Bloem", "R. Drechsler" ],
      "venue" : "In Proceedings of GLSVLSI’08,",
      "citeRegEx" : "Suelflow et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Suelflow et al\\.",
      "year" : 2008
    }, {
      "title" : "On the complexity of derivation in propositional calculus. Automation of Reasoning: Classical Papers in Computational Logic 1967-1970Studies in Constructive Mathematics and Mathematical Logic, Part",
      "author" : [ "G.S. Tseitin" ],
      "venue" : null,
      "citeRegEx" : "Tseitin,? \\Q1983\\E",
      "shortCiteRegEx" : "Tseitin",
      "year" : 1983
    }, {
      "title" : "Finding Guaranteed MUSes Fast",
      "author" : [ "H. van Maaren", "S. Wieringa" ],
      "venue" : "In SAT,",
      "citeRegEx" : "Maaren and Wieringa,? \\Q2008\\E",
      "shortCiteRegEx" : "Maaren and Wieringa",
      "year" : 2008
    }, {
      "title" : "Hybrid CEGAR: combining variable hiding and predicate abstraction",
      "author" : [ "C. Wang", "H. Kim", "A. Gupta" ],
      "venue" : "In Proceedings of ICCAD’07,",
      "citeRegEx" : "Wang et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2007
    }, {
      "title" : "Extracting Minimum Unsatisfiable Cores with a Greedy Genetic Algorithm",
      "author" : [ "J. Zhang", "S. Li", "S. Shen" ],
      "venue" : "In Proceedings of ACAI,",
      "citeRegEx" : "Zhang et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2006
    }, {
      "title" : "Efficient conflict driven learning in a boolean satisfiability solver",
      "author" : [ "L. Zhang", "C.F. Madigan", "M.H. Moskewicz", "S. Malik" ],
      "venue" : "In Proceedings of ICCAD",
      "citeRegEx" : "Zhang et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2001
    }, {
      "title" : "The quest for efficient boolean satisfiability solvers",
      "author" : [ "L. Zhang", "S. Malik" ],
      "venue" : "CADE, Vol. 2392 of LNCS,",
      "citeRegEx" : "Zhang and Malik,? \\Q2002\\E",
      "shortCiteRegEx" : "Zhang and Malik",
      "year" : 2002
    }, {
      "title" : "Extracting Small Unsatisfiable Cores from Unsatisfiable Boolean Formulas",
      "author" : [ "L. Zhang", "S. Malik" ],
      "venue" : "In Proceedings of 6th International Conference on Theory and Applications of Satisfiability Testing (SAT2003)",
      "citeRegEx" : "Zhang and Malik,? \\Q2003\\E",
      "shortCiteRegEx" : "Zhang and Malik",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 23,
      "context" : "Examples of such applications include use of SAT instead of BDDs for unbounded symbolic model checking (McMillan, 2002), automatic predicate discovery in abstraction refinement frameworks (McMillan & Amla, 2003; Wang, Kim, & Gupta, 2007), decision procedures (Bryant, Kroening, Ouaknine, Seshia, Strichman, & Brady, 2009), under-approximation and refinement in the context of bounded model checking of multi-threaded systems (Grumberg, Lerda, Strichman, & Theobald, 2005), debugging of design errors in circuits (Suelflow, Fey, Bloem, & Drechsler, 2008).",
      "startOffset" : 103,
      "endOffset" : 119
    }, {
      "referenceID" : 19,
      "context" : "For this reason, the problem of finding small unsat cores in SAT has been addressed by many authors in the recent years (Zhang & Malik, 2003; Goldberg & Novikov, 2003; Lynce & Marques-Silva, 2004; Oh, Mneimneh, Andraus, Sakallah, & Markov, 2004; Mneimneh, Lynce, Andraus, Marques-Silva, & Sakallah, 2005; Huang, 2005; Dershowitz, Hanna, & Nadel, 2006; Zhang, Li, & Shen, 2006; Biere, 2008; Gershman, Koifman, & Strichman, 2008; van Maaren & Wieringa, 2008; Aśın, Nieuwenhuis, Oliveras, & Rodŕıguez Carbonell, 2008; Nadel, 2010).",
      "startOffset" : 120,
      "endOffset" : 527
    }, {
      "referenceID" : 5,
      "context" : "For this reason, the problem of finding small unsat cores in SAT has been addressed by many authors in the recent years (Zhang & Malik, 2003; Goldberg & Novikov, 2003; Lynce & Marques-Silva, 2004; Oh, Mneimneh, Andraus, Sakallah, & Markov, 2004; Mneimneh, Lynce, Andraus, Marques-Silva, & Sakallah, 2005; Huang, 2005; Dershowitz, Hanna, & Nadel, 2006; Zhang, Li, & Shen, 2006; Biere, 2008; Gershman, Koifman, & Strichman, 2008; van Maaren & Wieringa, 2008; Aśın, Nieuwenhuis, Oliveras, & Rodŕıguez Carbonell, 2008; Nadel, 2010).",
      "startOffset" : 120,
      "endOffset" : 527
    }, {
      "referenceID" : 26,
      "context" : "For this reason, the problem of finding small unsat cores in SAT has been addressed by many authors in the recent years (Zhang & Malik, 2003; Goldberg & Novikov, 2003; Lynce & Marques-Silva, 2004; Oh, Mneimneh, Andraus, Sakallah, & Markov, 2004; Mneimneh, Lynce, Andraus, Marques-Silva, & Sakallah, 2005; Huang, 2005; Dershowitz, Hanna, & Nadel, 2006; Zhang, Li, & Shen, 2006; Biere, 2008; Gershman, Koifman, & Strichman, 2008; van Maaren & Wieringa, 2008; Aśın, Nieuwenhuis, Oliveras, & Rodŕıguez Carbonell, 2008; Nadel, 2010).",
      "startOffset" : 120,
      "endOffset" : 527
    }, {
      "referenceID" : 33,
      "context" : "For every non-CNF formula φ, an equisatisfiable CNF formula ψ can be generated in polynomial time (Tseitin, 1983).",
      "startOffset" : 98,
      "endOffset" : 113
    }, {
      "referenceID" : 13,
      "context" : ", by Enderton (1972). We write Γ |= φ to denote that the formula φ is a logical consequence of the (possibly infinite) set Γ of formulas.",
      "startOffset" : 5,
      "endOffset" : 21
    }, {
      "referenceID" : 10,
      "context" : "Most state-of-the-art SAT procedures are evolutions of the Davis-Putnam-Longeman-Loveland (DPLL) procedure (Davis & Putnam, 1960; Davis et al., 1962).",
      "startOffset" : 107,
      "endOffset" : 149
    }, {
      "referenceID" : 10,
      "context" : "Most state-of-the-art SAT procedures are evolutions of the Davis-Putnam-Longeman-Loveland (DPLL) procedure (Davis & Putnam, 1960; Davis et al., 1962). A high-level schema of a modern DPLL engine, adapted from the description given by Zhang and Malik (2002),",
      "startOffset" : 130,
      "endOffset" : 257
    }, {
      "referenceID" : 38,
      "context" : ", to the work of Zhang and Malik (2002).",
      "startOffset" : 17,
      "endOffset" : 40
    }, {
      "referenceID" : 10,
      "context" : "The propositional abstraction φp of the input formula φ is given as input to a SAT solver based on the DPLL algorithm (Davis et al., 1962; Zhang & Malik, 2002), which either decides that φp is unsatisfiable, and hence φ is T -unsatisfiable, or returns a satisfying assignment μp; in the latter case, P2T (μp) is given as input to T -solver.",
      "startOffset" : 118,
      "endOffset" : 159
    }, {
      "referenceID" : 27,
      "context" : "An important variant of this schema (Nieuwenhuis et al., 2006) is that of building a “mixed Boolean+theory conflict clause”, starting from ¬ηp and applying the backwardtraversal of the implication graph built by DPLL (Zhang et al.",
      "startOffset" : 36,
      "endOffset" : 62
    }, {
      "referenceID" : 37,
      "context" : ", 2006) is that of building a “mixed Boolean+theory conflict clause”, starting from ¬ηp and applying the backwardtraversal of the implication graph built by DPLL (Zhang et al., 2001), until one of the standard conditions (e.",
      "startOffset" : 162,
      "endOffset" : 182
    }, {
      "referenceID" : 26,
      "context" : "An important variant of this schema (Nieuwenhuis et al., 2006) is that of building a “mixed Boolean+theory conflict clause”, starting from ¬ηp and applying the backwardtraversal of the implication graph built by DPLL (Zhang et al., 2001), until one of the standard conditions (e.g., 1st UIP – Zhang et al., 2001) is achieved. Other important optimizations are early pruning and theory propagation: the T -solver is invoked also on (the refinement of) an intermediate assignment μ: if it is found T unsatisfiable, then the procedure can backtrack, since no extension of μ can be T -satisfiable; if not, and if the T -solver performs a deduction {l1, . . . , ln} |=T l s.t. {l1, . . . , ln} ⊆ μ, then T 2P(l) can be unit-propagated, and the Boolean abstraction of the T -lemma ( ∨n i=1 ¬li ∨ l) can be learned. The on-line lazy SMT (T ) schema is a coarse description of the procedures underlying all the state-of-the-art lazy SMT (T ) tools like, e.g., BarceLogic, CVC3, MathSAT, Yices, Z3. The interested reader is pointed to, e.g., the work of Nieuwenhuis et al. (2006), Barrett and Tinelli (2007), Bruttomesso et al.",
      "startOffset" : 37,
      "endOffset" : 1071
    }, {
      "referenceID" : 26,
      "context" : "An important variant of this schema (Nieuwenhuis et al., 2006) is that of building a “mixed Boolean+theory conflict clause”, starting from ¬ηp and applying the backwardtraversal of the implication graph built by DPLL (Zhang et al., 2001), until one of the standard conditions (e.g., 1st UIP – Zhang et al., 2001) is achieved. Other important optimizations are early pruning and theory propagation: the T -solver is invoked also on (the refinement of) an intermediate assignment μ: if it is found T unsatisfiable, then the procedure can backtrack, since no extension of μ can be T -satisfiable; if not, and if the T -solver performs a deduction {l1, . . . , ln} |=T l s.t. {l1, . . . , ln} ⊆ μ, then T 2P(l) can be unit-propagated, and the Boolean abstraction of the T -lemma ( ∨n i=1 ¬li ∨ l) can be learned. The on-line lazy SMT (T ) schema is a coarse description of the procedures underlying all the state-of-the-art lazy SMT (T ) tools like, e.g., BarceLogic, CVC3, MathSAT, Yices, Z3. The interested reader is pointed to, e.g., the work of Nieuwenhuis et al. (2006), Barrett and Tinelli (2007), Bruttomesso et al.",
      "startOffset" : 37,
      "endOffset" : 1099
    }, {
      "referenceID" : 6,
      "context" : "(2006), Barrett and Tinelli (2007), Bruttomesso et al. (2008), Dutertre and de Moura (2006), and de Moura and Bjørner (2008), for details and further references, or to the work of Sebastiani (2007) and Barrett, Sebastiani, Seshia, and Tinelli (2009) for a survey.",
      "startOffset" : 36,
      "endOffset" : 62
    }, {
      "referenceID" : 6,
      "context" : "(2006), Barrett and Tinelli (2007), Bruttomesso et al. (2008), Dutertre and de Moura (2006), and de Moura and Bjørner (2008), for details and further references, or to the work of Sebastiani (2007) and Barrett, Sebastiani, Seshia, and Tinelli (2009) for a survey.",
      "startOffset" : 36,
      "endOffset" : 92
    }, {
      "referenceID" : 6,
      "context" : "(2006), Barrett and Tinelli (2007), Bruttomesso et al. (2008), Dutertre and de Moura (2006), and de Moura and Bjørner (2008), for details and further references, or to the work of Sebastiani (2007) and Barrett, Sebastiani, Seshia, and Tinelli (2009) for a survey.",
      "startOffset" : 36,
      "endOffset" : 125
    }, {
      "referenceID" : 6,
      "context" : "(2006), Barrett and Tinelli (2007), Bruttomesso et al. (2008), Dutertre and de Moura (2006), and de Moura and Bjørner (2008), for details and further references, or to the work of Sebastiani (2007) and Barrett, Sebastiani, Seshia, and Tinelli (2009) for a survey.",
      "startOffset" : 36,
      "endOffset" : 198
    }, {
      "referenceID" : 6,
      "context" : "(2006), Barrett and Tinelli (2007), Bruttomesso et al. (2008), Dutertre and de Moura (2006), and de Moura and Bjørner (2008), for details and further references, or to the work of Sebastiani (2007) and Barrett, Sebastiani, Seshia, and Tinelli (2009) for a survey.",
      "startOffset" : 36,
      "endOffset" : 250
    }, {
      "referenceID" : 29,
      "context" : "In the approach of Zhang and Malik (2003) and Goldberg and Novikov (2003), they are computed as a byproduct of a DPLL-based proof-generation procedure.",
      "startOffset" : 19,
      "endOffset" : 42
    }, {
      "referenceID" : 15,
      "context" : "In the approach of Zhang and Malik (2003) and Goldberg and Novikov (2003), they are computed as a byproduct of a DPLL-based proof-generation procedure.",
      "startOffset" : 46,
      "endOffset" : 74
    }, {
      "referenceID" : 14,
      "context" : "The algorithm of Gershman et al. (2008), instead, manipulates the resolution proof so as to shrink the size of the core, using also a fixpoint iteration as Zhang and Malik (2003) to further enhance the quality of the results.",
      "startOffset" : 17,
      "endOffset" : 40
    }, {
      "referenceID" : 14,
      "context" : "The algorithm of Gershman et al. (2008), instead, manipulates the resolution proof so as to shrink the size of the core, using also a fixpoint iteration as Zhang and Malik (2003) to further enhance the quality of the results.",
      "startOffset" : 17,
      "endOffset" : 179
    }, {
      "referenceID" : 14,
      "context" : "The algorithm of Gershman et al. (2008), instead, manipulates the resolution proof so as to shrink the size of the core, using also a fixpoint iteration as Zhang and Malik (2003) to further enhance the quality of the results. Oh et al. (2004) present an algorithm to compute minimal unsat cores.",
      "startOffset" : 17,
      "endOffset" : 243
    }, {
      "referenceID" : 14,
      "context" : "The algorithm of Gershman et al. (2008), instead, manipulates the resolution proof so as to shrink the size of the core, using also a fixpoint iteration as Zhang and Malik (2003) to further enhance the quality of the results. Oh et al. (2004) present an algorithm to compute minimal unsat cores. The technique is based on modifications of a standard DPLL engine, and works by adding some extra variables (selectors) to the original clauses, and then performing a branch-and-bound algorithm on the modified formula. The procedure presented by Huang (2005) extracts minimal cores using BDD manipulation techniques, removing one clause at a time until the remaining core is minimal.",
      "startOffset" : 17,
      "endOffset" : 555
    }, {
      "referenceID" : 11,
      "context" : "The construction of a minimal core by Dershowitz et al. (2006) also uses resolution proofs, and it works by iteratively removing from the proof one input clause at a time, until it is no longer possible to prove inconsistency.",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 11,
      "context" : "The construction of a minimal core by Dershowitz et al. (2006) also uses resolution proofs, and it works by iteratively removing from the proof one input clause at a time, until it is no longer possible to prove inconsistency. When a clause is removed, the resolution proof is modified to prevent future use of that clause. As far as the the computation of minimum unsatisfiable cores is concerned, the algorithm of Lynce and Marques-Silva (2004) searches all the unsat cores of the input problem; this is done by introducing selector variables for the original clauses, and by increasing the search space of the DPLL solver to include also such variables; then, (one of) the unsatisfiable subformulas with the smallest number of selectors assigned to true is returned.",
      "startOffset" : 38,
      "endOffset" : 447
    }, {
      "referenceID" : 11,
      "context" : "The construction of a minimal core by Dershowitz et al. (2006) also uses resolution proofs, and it works by iteratively removing from the proof one input clause at a time, until it is no longer possible to prove inconsistency. When a clause is removed, the resolution proof is modified to prevent future use of that clause. As far as the the computation of minimum unsatisfiable cores is concerned, the algorithm of Lynce and Marques-Silva (2004) searches all the unsat cores of the input problem; this is done by introducing selector variables for the original clauses, and by increasing the search space of the DPLL solver to include also such variables; then, (one of) the unsatisfiable subformulas with the smallest number of selectors assigned to true is returned. The approach described by Mneimneh et al. (2005) instead is based on a branch-and-bound algorithm that exploits the relation between maximal satisfiability and minimum unsatisfiability.",
      "startOffset" : 38,
      "endOffset" : 819
    }, {
      "referenceID" : 11,
      "context" : "The construction of a minimal core by Dershowitz et al. (2006) also uses resolution proofs, and it works by iteratively removing from the proof one input clause at a time, until it is no longer possible to prove inconsistency. When a clause is removed, the resolution proof is modified to prevent future use of that clause. As far as the the computation of minimum unsatisfiable cores is concerned, the algorithm of Lynce and Marques-Silva (2004) searches all the unsat cores of the input problem; this is done by introducing selector variables for the original clauses, and by increasing the search space of the DPLL solver to include also such variables; then, (one of) the unsatisfiable subformulas with the smallest number of selectors assigned to true is returned. The approach described by Mneimneh et al. (2005) instead is based on a branch-and-bound algorithm that exploits the relation between maximal satisfiability and minimum unsatisfiability. The same relation is used also by the procedure of Zhang et al. (2006), which is instead based on a genetic algorithm.",
      "startOffset" : 38,
      "endOffset" : 1027
    }, {
      "referenceID" : 20,
      "context" : "Strictly related with this work, Liffiton and Sakallah (2008) presented a general technique for enumerating all minimal unsatisfiable subsets of a given inconsistent set of constraints, which they implemented in the tool CAMUS.",
      "startOffset" : 33,
      "endOffset" : 62
    }, {
      "referenceID" : 38,
      "context" : "Similarly to the approach of Zhang and Malik (2003), the idea is to analyze the proof of unsatisfiability backwards, and to return an unsatisfiable core that is a collection of the assumptions (i.",
      "startOffset" : 29,
      "endOffset" : 52
    }, {
      "referenceID" : 21,
      "context" : "2 Assumption-Based UC Extraction The approach used by Yices (Dutertre & de Moura, 2006) and Z3 (de Moura & Bjørner, 2008) is an adaptation of the method by Lynce and Marques-Silva (2004): for each clause Ci in the problem, a new Boolean “selector” variable Si is created; then, each Ci is replaced by (Si → Ci); finally, before starting the search each Si is forced to true.",
      "startOffset" : 156,
      "endOffset" : 187
    }, {
      "referenceID" : 37,
      "context" : "The final conflict clause generated by conflict analysis (Zhang et al., 2001) is: 4 ¬S1 ∨ ¬S2 ∨ ¬S3 ∨ ¬S4 ∨ ¬S6 ∨ ¬S7 ∨ ¬S8, (4)",
      "startOffset" : 57,
      "endOffset" : 77
    }, {
      "referenceID" : 0,
      "context" : "For a deeper comparison between these two approaches (and some variants of them), we refer the reader to the work of Aśın et al. (2008) and Nadel (2010).",
      "startOffset" : 117,
      "endOffset" : 136
    }, {
      "referenceID" : 0,
      "context" : "For a deeper comparison between these two approaches (and some variants of them), we refer the reader to the work of Aśın et al. (2008) and Nadel (2010).",
      "startOffset" : 117,
      "endOffset" : 153
    }, {
      "referenceID" : 20,
      "context" : "A completely different approach, aiming at generating all minimal UC’s of some given inconsistent set of propositional clauses Φ, is presented by Liffiton and Sakallah (2008) and implemented in the tool CAMUS.",
      "startOffset" : 146,
      "endOffset" : 175
    }, {
      "referenceID" : 20,
      "context" : "We refer the reader to the work of Liffiton and Sakallah (2008) for a more detailed explanation of this technique and of its features.",
      "startOffset" : 35,
      "endOffset" : 64
    }, {
      "referenceID" : 20,
      "context" : "” of the article by Liffiton and Sakallah (2008).",
      "startOffset" : 20,
      "endOffset" : 49
    }, {
      "referenceID" : 20,
      "context" : ") We understand from Liffiton and Sakallah (2008) that, in order to produce uc1 and uc2, CAMUS enumerates first (not necessarily in this order) the following set of MCS’s:",
      "startOffset" : 21,
      "endOffset" : 50
    }, {
      "referenceID" : 27,
      "context" : ") In case of mixed Boolean+theory-conflict clauses (Nieuwenhuis et al., 2006) (see § 2.",
      "startOffset" : 51,
      "endOffset" : 77
    }, {
      "referenceID" : 27,
      "context" : "The validity of fact (ii) is not affected by this optimization, because only the T -lemmas used during conflict analysis are needed for it to hold (Nieuwenhuis et al., 2006).",
      "startOffset" : 147,
      "endOffset" : 173
    }, {
      "referenceID" : 25,
      "context" : "uses the lazy theory deduction of Nieuwenhuis et al. (2006). Moreover, it works also if T -lemmas contain new atoms (i.",
      "startOffset" : 34,
      "endOffset" : 60
    }, {
      "referenceID" : 14,
      "context" : "atoms that do not appear in φ), as in the approaches of Flanagan et al. (2003), and Barrett, Nieuwenhuis, Oliveras, and Tinelli (2006), since both Facts (ii) and (i) hold also in that case.",
      "startOffset" : 56,
      "endOffset" : 79
    }, {
      "referenceID" : 14,
      "context" : "atoms that do not appear in φ), as in the approaches of Flanagan et al. (2003), and Barrett, Nieuwenhuis, Oliveras, and Tinelli (2006), since both Facts (ii) and (i) hold also in that case.",
      "startOffset" : 56,
      "endOffset" : 135
    }, {
      "referenceID" : 14,
      "context" : "atoms that do not appear in φ), as in the approaches of Flanagan et al. (2003), and Barrett, Nieuwenhuis, Oliveras, and Tinelli (2006), since both Facts (ii) and (i) hold also in that case. As a side observation, we remark that the technique works also for the per-constraintencoding eager SMT approach of Goel, Sajid, Zhou, Aziz, and Singhal (1998), and Strichman, Seshia, and Bryant (2002).",
      "startOffset" : 56,
      "endOffset" : 350
    }, {
      "referenceID" : 14,
      "context" : "atoms that do not appear in φ), as in the approaches of Flanagan et al. (2003), and Barrett, Nieuwenhuis, Oliveras, and Tinelli (2006), since both Facts (ii) and (i) hold also in that case. As a side observation, we remark that the technique works also for the per-constraintencoding eager SMT approach of Goel, Sajid, Zhou, Aziz, and Singhal (1998), and Strichman, Seshia, and Bryant (2002). In the eager SMT approach, the input T -formula φ is translated into an equi-satisfiable Boolean formula, and a SAT solver is used to check its satisfiability.",
      "startOffset" : 56,
      "endOffset" : 392
    }, {
      "referenceID" : 14,
      "context" : "atoms that do not appear in φ), as in the approaches of Flanagan et al. (2003), and Barrett, Nieuwenhuis, Oliveras, and Tinelli (2006), since both Facts (ii) and (i) hold also in that case. As a side observation, we remark that the technique works also for the per-constraintencoding eager SMT approach of Goel, Sajid, Zhou, Aziz, and Singhal (1998), and Strichman, Seshia, and Bryant (2002). In the eager SMT approach, the input T -formula φ is translated into an equi-satisfiable Boolean formula, and a SAT solver is used to check its satisfiability. With per-constraint-encoding of Goel et al. (1998) and Strichman et al.",
      "startOffset" : 56,
      "endOffset" : 604
    }, {
      "referenceID" : 14,
      "context" : "atoms that do not appear in φ), as in the approaches of Flanagan et al. (2003), and Barrett, Nieuwenhuis, Oliveras, and Tinelli (2006), since both Facts (ii) and (i) hold also in that case. As a side observation, we remark that the technique works also for the per-constraintencoding eager SMT approach of Goel, Sajid, Zhou, Aziz, and Singhal (1998), and Strichman, Seshia, and Bryant (2002). In the eager SMT approach, the input T -formula φ is translated into an equi-satisfiable Boolean formula, and a SAT solver is used to check its satisfiability. With per-constraint-encoding of Goel et al. (1998) and Strichman et al. (2002), the resulting Boolean formula is the conjunction of the propositional abstraction φp of φ and a formula φT which is the propositional abstraction of the conjunction of some T -valid clauses.",
      "startOffset" : 56,
      "endOffset" : 632
    }, {
      "referenceID" : 36,
      "context" : "Notably, this involves also Boolean unsat-core techniques which could be very difficult to adapt to the SMT setting (and to implement within an SMT solver), such as the ones based on genetic algorithms (Zhang et al., 2006).",
      "startOffset" : 202,
      "endOffset" : 222
    }, {
      "referenceID" : 6,
      "context" : "We implemented the approach within the MathSAT (Bruttomesso et al., 2008) system.",
      "startOffset" : 47,
      "endOffset" : 73
    }, {
      "referenceID" : 28,
      "context" : ") We have tried eight different external UCEs, namely Amuse (Oh et al., 2004), PicoSAT (Biere, 2008), Eureka (Dershowitz et al.",
      "startOffset" : 60,
      "endOffset" : 77
    }, {
      "referenceID" : 5,
      "context" : ", 2004), PicoSAT (Biere, 2008), Eureka (Dershowitz et al.",
      "startOffset" : 17,
      "endOffset" : 30
    }, {
      "referenceID" : 11,
      "context" : ", 2004), PicoSAT (Biere, 2008), Eureka (Dershowitz et al., 2006), MiniUnsat (van Maaren & Wieringa, 2008), MUP (Huang, 2005), Trimmer (Gershman et al.",
      "startOffset" : 39,
      "endOffset" : 64
    }, {
      "referenceID" : 19,
      "context" : ", 2006), MiniUnsat (van Maaren & Wieringa, 2008), MUP (Huang, 2005), Trimmer (Gershman et al.",
      "startOffset" : 54,
      "endOffset" : 67
    }, {
      "referenceID" : 15,
      "context" : ", 2006), MiniUnsat (van Maaren & Wieringa, 2008), MUP (Huang, 2005), Trimmer (Gershman et al., 2008), ZChaff (Zhang & Malik, 2003), and the tool proposed by Zhang et al.",
      "startOffset" : 77,
      "endOffset" : 100
    }, {
      "referenceID" : 5,
      "context" : ", 2004), PicoSAT (Biere, 2008), Eureka (Dershowitz et al., 2006), MiniUnsat (van Maaren & Wieringa, 2008), MUP (Huang, 2005), Trimmer (Gershman et al., 2008), ZChaff (Zhang & Malik, 2003), and the tool proposed by Zhang et al. (2006) (called Genetic here).",
      "startOffset" : 18,
      "endOffset" : 234
    }, {
      "referenceID" : 28,
      "context" : "We evaluated the six configurations which use, respectively, Amuse (Oh et al., 2004), Genetic (Zhang et al.",
      "startOffset" : 67,
      "endOffset" : 84
    }, {
      "referenceID" : 36,
      "context" : ", 2004), Genetic (Zhang et al., 2006), Eureka (Dershowitz et al.",
      "startOffset" : 17,
      "endOffset" : 37
    }, {
      "referenceID" : 11,
      "context" : ", 2006), Eureka (Dershowitz et al., 2006), MiniUnsat (van Maaren & Wieringa, 2008), Trimmer (Gershman et al.",
      "startOffset" : 16,
      "endOffset" : 41
    }, {
      "referenceID" : 15,
      "context" : ", 2006), MiniUnsat (van Maaren & Wieringa, 2008), Trimmer (Gershman et al., 2008), and ZChaff (Zhang & Malik, 2003), against the baseline configuration, using PicoSAT.",
      "startOffset" : 58,
      "endOffset" : 81
    }, {
      "referenceID" : 19,
      "context" : "We also compared with MUP (Huang, 2005), but we had to stop the experiments because of memory exhaustion",
      "startOffset" : 26,
      "endOffset" : 39
    }, {
      "referenceID" : 19,
      "context" : "To this extent, we notice that the performances of MUP (Huang, 2005) and Genetic (Zhang et al.",
      "startOffset" : 55,
      "endOffset" : 68
    }, {
      "referenceID" : 36,
      "context" : "To this extent, we notice that the performances of MUP (Huang, 2005) and Genetic (Zhang et al., 2006) seem rather poor; PicoSAT (Biere, 2008) is definitely the fastest tool, though the least effective in reducing the size of the final core; on the opposite side, Eureka (Dershowitz et al.",
      "startOffset" : 81,
      "endOffset" : 101
    }, {
      "referenceID" : 5,
      "context" : ", 2006) seem rather poor; PicoSAT (Biere, 2008) is definitely the fastest tool, though the least effective in reducing the size of the final core; on the opposite side, Eureka (Dershowitz et al.",
      "startOffset" : 34,
      "endOffset" : 47
    }, {
      "referenceID" : 11,
      "context" : ", 2006) seem rather poor; PicoSAT (Biere, 2008) is definitely the fastest tool, though the least effective in reducing the size of the final core; on the opposite side, Eureka (Dershowitz et al., 2006) is the most effective in this task, but pays a fee in terms of CPU time; Trimmer (Gershman et al.",
      "startOffset" : 176,
      "endOffset" : 201
    }, {
      "referenceID" : 15,
      "context" : ", 2006) is the most effective in this task, but pays a fee in terms of CPU time; Trimmer (Gershman et al., 2008) represents a good compromise between effectiveness and efficiency.",
      "startOffset" : 89,
      "endOffset" : 112
    } ],
    "year" : 2011,
    "abstractText" : "The problem of finding small unsatisfiable cores for SAT formulas has recently received a lot of interest, mostly for its applications in formal verification. However, propositional logic is often not expressive enough for representing many interesting verification problems, which can be more naturally addressed in the framework of Satisfiability Modulo Theories, SMT. Surprisingly, the problem of finding unsatisfiable cores in SMT has received very little attention in the literature. In this paper we present a novel approach to this problem, called the Lemma-Lifting approach. The main idea is to combine an SMT solver with an external propositional core extractor. The SMT solver produces the theory lemmas found during the search, dynamically lifting the suitable amount of theory information to the Boolean level. The core extractor is then called on the Boolean abstraction of the original SMT problem and of the theory lemmas. This results in an unsatisfiable core for the original SMT problem, once the remaining theory lemmas are removed. The approach is conceptually interesting, and has several advantages in practice. In fact, it is extremely simple to implement and to update, and it can be interfaced with every propositional core extractor in a plug-and-play manner, so as to benefit for free of all unsat-core reduction techniques which have been or will be made available. We have evaluated our algorithm with a very extensive empirical test on SMT-LIB benchmarks, which confirms the validity and potential of this approach. 1. Motivations and Goals In the last decade we have witnessed an impressive advance in the efficiency of SAT techniques, which has brought large and previously-intractable problems at the reach of stateof-the-art SAT solvers. As a consequence, SAT solvers are now a fundamental tool in many industrial-strength applications, including most formal verification design flows for hardware systems, for equivalence, property checking, and ATPG. In particular, one of the most relevant problems in this context, thanks to its many important applications, is that of finding small unsatisfiable cores, that is, small unsatisfiable subsets of unsatisfiable sets of clauses. c ©2011 AI Access Foundation. All rights reserved. Cimatti, Griggio, & Sebastiani Examples of such applications include use of SAT instead of BDDs for unbounded symbolic model checking (McMillan, 2002), automatic predicate discovery in abstraction refinement frameworks (McMillan & Amla, 2003; Wang, Kim, & Gupta, 2007), decision procedures (Bryant, Kroening, Ouaknine, Seshia, Strichman, & Brady, 2009), under-approximation and refinement in the context of bounded model checking of multi-threaded systems (Grumberg, Lerda, Strichman, & Theobald, 2005), debugging of design errors in circuits (Suelflow, Fey, Bloem, & Drechsler, 2008). For this reason, the problem of finding small unsat cores in SAT has been addressed by many authors in the recent years (Zhang & Malik, 2003; Goldberg & Novikov, 2003; Lynce & Marques-Silva, 2004; Oh, Mneimneh, Andraus, Sakallah, & Markov, 2004; Mneimneh, Lynce, Andraus, Marques-Silva, & Sakallah, 2005; Huang, 2005; Dershowitz, Hanna, & Nadel, 2006; Zhang, Li, & Shen, 2006; Biere, 2008; Gershman, Koifman, & Strichman, 2008; van Maaren & Wieringa, 2008; Aśın, Nieuwenhuis, Oliveras, & Rodŕıguez Carbonell, 2008; Nadel, 2010). The formalism of plain propositional logic, however, is often not suitable or expressive enough for representing many other real-world problems, including the verification of RTL designs, of real-time and hybrid control systems, and the analysis of proof obligations in software verification. Such problems are more naturally expressible as satisfiability problems in decidable first-order theories —Satisfiability Modulo Theories, SMT. Efficient SMT solvers have been developed in the last five years, called lazy SMT solvers, which combine a Conflict-Driven Clause Learning (CDCL) SAT solver based on the DPLL algorithm (Davis & Putnam, 1960; Davis, Logemann, & Loveland, 1962; Marques-Silva & Sakallah, 1996; Zhang & Malik, 2002) — hereafter simply “DPLL” — with ad-hoc decision procedures for many theories of interest (see, e.g., Nieuwenhuis, Oliveras, & Tinelli, 2006; Barrett & Tinelli, 2007; Bruttomesso, Cimatti, Franzén, Griggio, & Sebastiani, 2008; Dutertre & de Moura, 2006; de Moura & Bjørner, 2008). Surprisingly, the problem of finding unsatisfiable cores in SMT has received virtually no attention in the literature. Although some SMT tools do compute unsat cores, this is done either as a byproduct of the more general task of producing proofs, or by modifying the embedded DPLL solver so that to apply basic propositional techniques to produce an unsat core. In particular, we are not aware of any work aiming at producing small unsatisfiable cores in SMT. In this paper we present a novel approach addressing this problem, which we call the Lemma-Lifting approach. The main idea is to combine an SMT solver with an external propositional core extractor. The SMT solver stores and returns the theory lemmas it had to prove in order to refute the input formula; the external core extractor is then called on the Boolean abstraction of the original SMT problem and of the theory lemmas. Our algorithm is based on the following two key observations: i) the theory lemmas discovered by the SMT solver during search are valid clauses in the theory T under consideration, and therefore they do not affect the satisfiability of a formula in T ; and ii) the conjunction of the original SMT formula with all the theory lemmas is propositionally unsatisfiable. Therefore, the external (Boolean) core extractor finds an unsatisfiable core for (the Boolean abstraction of) the conjunction of the original formula and the theory lemmas, which can then be refined back into a subset of the original clauses by simply removing from it (the Boolean abstractions of) all theory lemmas. The result is an unsatisfiable core of the original SMT problem.",
    "creator" : "TeX"
  }
}