{
  "name" : "1708.08575.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Identifying Subjective and Figurative Language in Online Dialogue",
    "authors" : [ "Stephanie M. Lukin", "Luke Eisenberg", "Thomas Corcoran", "Marilyn A. Walker" ],
    "emails" : [ "slukin@ucsc.edu", "leisenbe@ucsc.edu", "tcorcora@ucsc.edu", "mawalker@ucsc.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Identifying Subjective and Figurative Language in Online Dialogue\nStephanie M. Lukin, Luke Eisenberg, Thomas Corcoran, & Marilyn A. Walker Natural Language and Dialogue Systems Computer Science Department, SOE-3\nUniversity of California, Santa Cruz slukin,leisenbe,tcorcora,mawalker@ucsc.edu\nMore and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles. In contrast to traditional, monologic resources such as news, highly social dialogue is very frequent in social media, as illustrated in the snippets in Fig. 1 from the publicly available Internet Argument Corpus (IAC) (Walker et al., 2012). Utterances are frequently sarcastic, e.g., Really? Well, when I have a kid, I’ll be sure to just leave it in the woods, since it can apparently care for itself (R2 in Fig. 1 as well as Q1 and R1), and are often nasty, (R2 in Fig. 1). Note also the frequent use of dialogue specific discourse cues, e.g. the use of No in R1, Really? Well in R2, and okay, well in Q3 in Fig. 1 (Fox Tree and Schrock, 1999; Bryant and Fox Tree, 2002; Fox Tree, 2010).\nQuote Q, Response R Sarc Nasty Q1: I jsut voted. sorry if some people actually have, you know, LIVES and don’t sit around all day on debate forums to cater to some atheists posts that he thiks they should drop everything for. emoticon-rolleyes emoticonrolleyes emoticon-rolleyes As to the rest of your post, well, from your attitude I can tell you are not Christian in the least. Therefore I am content in knowing where people that spew garbage like this will end up in the End. R1: No, let me guess . . . er . . . McDonalds. No, Disneyland. Am I getting closer? 1 -3.6 Q2: The key issue is that once children are born they are not physically dependent on a particular individual. R2 Really? Well, when I have a kid, I’ll be sure to just leave it in the woods, since it can apparently care for itself. 1 -1\nFigure 1: Sample Quote/Response Pairs from 4forums.com with Mechanical Turk annotations for Sarcasm and Nasty/Nice. Highly negative values of Nasty/Nice indicate strong nastiness and sarcasm is indicated by values near 1.\nWe aim to automatically identify sarcastic and nasty utterances in unannotated online dialogue, extending a bootstrapping method previously applied to the classification of monologic subjective sentences by Riloff & Wiebe, henceforth R&W (Riloff and Wiebe, 2003; Thelen and Riloff, 2002). We look at both sarcastic and nasty dialogic turns as a way to explore generalization of the method. R&W’s method creates a High-Precision, CueBased Classifier to be a first approximation on unannotated text. They improve their classifier by learning and bootstrapping patterns (Fig. 2).\nWe found that this bootstrapping method ‘as is’ is not\nappropriate for our data because our Cue-Based Classifier yields a much lower precision than the bootstrapping requires. We have adapted the method to fit the sarcastic and nasty dialogic domain. Our method is as follows:\n1. Explore methods for identifying sarcastic and nasty cue words and phrases in dialogues;\n2. Use the learned cues to train a sarcastic (nasty) CueBased Classifier\n3. Learn general syntactic extraction patterns from the sarcastic (nasty) utterances and define fine-tuned sarcastic patterns to create a Pattern-Based Classifier;\n4. Combine both Cue-Based and fine-tuned PatternBased Classifiers to maximize precision at the expense of recall and test on unannotated utterances.\nCue Words. Sarcasm is known to be highly variable in form, and to depend, in some cases, on context for its interpretation (Sperber and Wilson, 1981; Gibbs, 2000; Bryant and Fox Tree, 2002). We elicit annotations from Mechanical Turk to identify sarcastic (nasty) cues in utterances from a development set. Turkers were presented with dialogic turns (a quote and its response) previously labeled sarcastic or nasty in the IAC by 7 different annotators, and were asked to identify sarcastic (nasty) or potentially sarcastic (nasty) phrases in the turn response. The Turkers then selected words or phrases from the response they believed could lead someone to believing the utterance was sarcastic or nasty. (Snow et al., 2008) measure the quality of Mechanical Turk annotations on common NLP tasks by comparing them to a gold standard. Pearson’s correlation coefficient shows that very few Mechanical Turk annotators were required to beat the gold standard data, often less than 5. Because our sarcasm (nasty) task does not have gold standard data, we asked 100 annotators to participate in the pilot. For all unigrams, bigrams, and trigrams, interannotator agreement\nar X iv :1\n70 8.\n08 57\n5v 1\n[ cs\n.C L\n] 2\n9 A\nug 2\n01 7\nplateaued around 20 annotators and is about 90%agreement with 10 annotators, showing that the Mechanical Turk task is well formed and there is high agreement. We begin to form a sarcastic and nasty vocabulary from these cues.\nCue based classifier. We use a development set to measure “goodness” of a cue that could serve as a high precision cue by using the percent sarcastic (nasty) and frequency statistics in the development set. These features rely on how frequent (FREQ) (subject to a θ1), and how reliable (%SARC and %NASTY) (subject to a θ2) a cue has to be to be useful. We select candidate cues by exhausting θ1 = [2, 4, 6, 8, 10] and θ2 = [.55, .60, .65, .70, .75, .80, .85, .90, .95, 1.00] for θ1 ≤ FREQ and θ2 ≤ SARC. At least two cues must be present and above the thresholds in an utterance to be classified by the Cue-Based Classifier. Less than two cues are needed to be classified as the counter-class. We select the best combination of parameters from our training set by selecting the parameters yielding the highest weighted f-measure that favors precision over recall. We then ran the Cue-Based Classifier with the best parameters on a test set. However as previously mentioned, R&W’s method expects the CueBased Classifier to yield high precision, whereas our results (CUE rows in Table 1) are just barely above baseline.\nPattern Based Classifier. The next step in R&W’s method is to create a Pattern-Based Classifier that takes as input the predicted labels from the Cue-Based Classifier. R&W’s Pattern-Based Classifier is trained on general, syntactic templates known to exist for subjectivity. These patterns are not limited to exact surface matches as the Cue-Based Classifiers require. We reimplement these patterns, and further developed new patterns specifically fine-tuned towards sarcasm in dialogue. For example, our new pattern OH RB (oh adverb) matches utterances like “oh right” and “oh sorry” and the pattern NP WHphrase matches “someone who” and “someone what”. Patterns are extracted from another development set and we again compute FREQ and %SARC and %NASTY for each pattern subject to θ1 ≤ FREQ and θ2 ≤ %SARC or % NASTY. Classifications are made if at least two patterns are present and both are above the specified θ1 and θ2, again exhausting all combinations of θ1 and θ2. Also following R&W, we do not learn “not sarcastic” or “nice” patterns. The counter-classes are predicted when the utterance contains less than two patterns. We test two Pattern-Based Classifiers: one with the original patterns proposed in R&W (BASELINE PATS) and one with the original patterns in addition to our new, fine-tuned patterns (NEW PATS). Table 1 shows the results of the pa-\nrameters with the highest weighted f-measure. The Pattern-Based Classifier performs better on Nasty than Sarcasm. We conclude that R&W’s patterns alone generalize well on our Sarcasm and Nasty datasets. By adding the fine-tuned patterns in the NEW PATS Classifier, we see a drastic increase in Sarcasm precision. There seems to be little change in recall for Sarcasm. Furthermore, we see a huge increase in precision for Nasty, but a steep decline in recall with the new patterns. We believe this is because these new patterns are tailored towards sarcastic utterances, not nasty. We did not create our own fine-tuned nasty patterns because we do well with R&W’s general patterns.\nCombined Classifier. To attempt to create a HighPrecision Classifier, we combine the Cue-Based Classifier and the Pattern-Based Classifier. We classify a post as sarcastic if it meets either the criteria of the Cue-Based Classifier (e.g. with θ1 = 2, θ2 = .55 for Sarcasm) or the Pattern-Based Classifier (e.g. with θ1 = 2, θ2 = .65 for Sarcasm). We use the same test set with which we test the Cue-Based Classifier and compare the results (Table 2). We furthermore distinguish between a Combined Classifier that makes a classification if both schemata are true (AND), or if only one is true (OR).\nOR does better than only the Cue-Based Classifier for all precision, recall, and f-measure. AND does better for precision by far than the Cue-Based Classifier, but with a lower recall. Despite the very low recall for AND, the f-measure of AND and OR is identical. AND is a more selective classifier, only saying “yes” if both schemata are true. This will naturally yield lower recall, but grant higher confidence in those classified.\nWe believe our Combined AND Classifier now has a high enough precision to be compared with R&W’s first approximation High-Precision, Cue-Based Classifier. After running the Combined Classifier on unannotated data, we select 100 predicted sarcastic and 100 predicted not sarcastic utterances and ask human annotators to label them. We expect a high overlap between annotators and the Combined Classifier, which would indicate that human annotators agree with the labels we are automatically predicting. These results are currently in progress.\nDespite the fact that we could not create a first approximation High-Precision, Cue-Based classifier like R&W, we have succeeded in creating a High-Precision Combined Classifier using both cues and fine-tuned patterns (71% precision for sarcasm and 88% precision for nastiness). Future work will involve developing fine-tuned patterns for nastiness and exploring different patterns for sarcasm."
    } ],
    "references" : [ {
      "title" : "Irony in talk among friends",
      "author" : [ "R.W. Gibbs" ],
      "venue" : "Metaphor and Symbol,",
      "citeRegEx" : "Gibbs.,? \\Q2000\\E",
      "shortCiteRegEx" : "Gibbs.",
      "year" : 2000
    }, {
      "title" : "Learning extraction patterns for subjective expressions",
      "author" : [ "Riloff", "Wiebe2003] E. Riloff", "J. Wiebe" ],
      "venue" : "In Proceedings of the 2003 conference on Empirical methods in natural language processing-Volume",
      "citeRegEx" : "Riloff et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Riloff et al\\.",
      "year" : 2003
    }, {
      "title" : "Cheap and fast—but is it good?: evaluating non-expert annotations for natural language tasks",
      "author" : [ "Snow et al.2008] R. Snow", "B. O’Connor", "D. Jurafsky", "A.Y. Ng" ],
      "venue" : "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Snow et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Snow et al\\.",
      "year" : 2008
    }, {
      "title" : "Irony and the use-mention distinction",
      "author" : [ "Sperber", "Wilson1981] Dan Sperber", "Deidre Wilson" ],
      "venue" : "Radical Pragmatics,",
      "citeRegEx" : "Sperber et al\\.,? \\Q1981\\E",
      "shortCiteRegEx" : "Sperber et al\\.",
      "year" : 1981
    }, {
      "title" : "A bootstrapping method for learning semantic lexicons using extraction pattern contexts",
      "author" : [ "Thelen", "Riloff2002] M. Thelen", "E. Riloff" ],
      "venue" : "In Proceedings of the ACL02 conference on Empirical methods in natural language processing-Volume",
      "citeRegEx" : "Thelen et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Thelen et al\\.",
      "year" : 2002
    }, {
      "title" : "A corpus for research on deliberation and debate",
      "author" : [ "Pranav Anand", "Robert Abbott", "Jean E. Fox Tree" ],
      "venue" : "In Language Resources and Evaluation Conference,",
      "citeRegEx" : "Walker et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Walker et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "1 from the publicly available Internet Argument Corpus (IAC) (Walker et al., 2012).",
      "startOffset" : 61,
      "endOffset" : 82
    }, {
      "referenceID" : 0,
      "context" : "Sarcasm is known to be highly variable in form, and to depend, in some cases, on context for its interpretation (Sperber and Wilson, 1981; Gibbs, 2000; Bryant and Fox Tree, 2002).",
      "startOffset" : 112,
      "endOffset" : 178
    }, {
      "referenceID" : 2,
      "context" : "(Snow et al., 2008) measure the quality of Mechanical Turk annotations on common NLP tasks by comparing them to a gold standard.",
      "startOffset" : 0,
      "endOffset" : 19
    } ],
    "year" : 2017,
    "abstractText" : "More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles. In contrast to traditional, monologic resources such as news, highly social dialogue is very frequent in social media, as illustrated in the snippets in Fig. 1 from the publicly available Internet Argument Corpus (IAC) (Walker et al., 2012). Utterances are frequently sarcastic, e.g., Really? Well, when I have a kid, I’ll be sure to just leave it in the woods, since it can apparently care for itself (R2 in Fig. 1 as well as Q1 and R1), and are often nasty, (R2 in Fig. 1). Note also the frequent use of dialogue specific discourse cues, e.g. the use of No in R1, Really? Well in R2, and okay, well in Q3 in Fig. 1 (Fox Tree and Schrock, 1999; Bryant and Fox Tree, 2002; Fox Tree, 2010).",
    "creator" : "LaTeX with hyperref package"
  }
}