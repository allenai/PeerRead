{"conference": "ICLR 2017 conference submission", "title": "A Differentiable Physics Engine for Deep Learning in Robotics", "abstract": "One of the most important fields in robotics is the optimization of controllers. Currently, robots are often treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent. When gradient-based methods are used, models are kept small or rely on finite difference approximations for the Jacobian. This method quickly grows expensive with increasing numbers of parameters, such as found in deep learning. We propose an implementation of a modern physics engine, which can differentiate control parameters. This engine is implemented for both CPU and GPU. Firstly, this paper shows how such an engine speeds up the optimization process, even for small problems. Furthermore, it explains why this is an alternative approach to deep Q-learning, for using deep learning in robotics. Finally, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software.", "reviews": [{"is_meta_review": true, "comments": "This paper creates a physics simulator using theano, and uses it to learn a neural network policy by back propagating gradients through the simulation. The approach is novel, and is motivated by being able to learn policies for robotics.\n\nMy two key reservations with the paper are as follows:\n1. The method is motivated by learning policies for robotics. However, the proposed method is *only* useful for robotics if the learned policy can transfer the real world. Transferring policies from simulation to real-world is an open research problem, and is particularly challenging with less realistic simulators.\n2. They key novelty/benefit of this approach over other model-based approaches is that the simulator is differentiable. However, the only empirical comparison in the paper is to a model-free approach (CMA-ES). To appropriately demonstrate the approach, it should be compared to other model-based approaches, which do not require analytic derivatives of the model.\n\nFor the reader to fully understand the pros and cons of the approach, the paper should also include quantitative comparison between the speed of the proposed simulator, and that of standard simulation platforms.\n\nBecause the idea is interesting and novel, I think it lies above the acceptance threshold. However, it would be significantly improved with the aforementioned comparisons.\n\nLastly, the writing of the paper could be improved, as it is rather informal and/or imprecise in a number of places. Here are some examples:\n-- \u201cwe model the use of a neural network as a general controller for a robot\u201d - can be more concisely phrased as something like \u201cwe model the robot controller using a neural network\u201d or \u201cthe robot controller is modeled using a neural network\"\n-- \u201cIn previous research, finding a gradient\u2026\u201d - This is a run-on sentence.\n-- \u201cWe basically jam this entire equation into\u201d - This sentence is informal and imprecise.\n-- \u201cdeep learning neural network\u201d - the word \u201clearning\u201d should be omitted\n-- \u201cone big RNN, where we unfold over time\u201d - should be \u201c\u2026RNN, which we unfold over time\u201d or \u201c\u2026RNN, unfolded over time\u201d\n\nThe writing would also be improved by making it more concise and fitting the paper into 8 pages.", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "Originality, significance:\n  The paper implements a physics-based simulator directly using Theano. This avoids the type of finite differentiation that physics engines such as MuJoCo use to compute derivatives. It is quite an interesting idea, and is demonstrated using learned control for several models. \n \n Quality, clarity:\n  The original version was somewhat loosely written; the current version is improved.\n \n Pros:\n - The nice idea of implementing a physics engine in a language such as Theano, and showing that this is quite feasible.\n - May inspire further work in this direction.\n \n Cons:\n - The speed is not systematically evaluated, as compared to finite-difference-based engines. It is thought to be \"in the same ballpark\" as other more full-featured engines. It is not clear that those using simulators will care whether it uses the true derivatives or finite differences.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Great and refreshing idea, but some lack of detail", "is_meta_review": false, "comments": "I would definitely love to have this and use it for my research. A great tool.\n\nHowever, the paper lacks detail. In particular, I feel that it is impossible for someone to reimplement the research-mostly because of the lack of detail. However, replicability is a crucial part of science. Other publications proposing software (e.g. the tensorflow, theano and edward papers) come along with open source code. This is not the case here and therefore the picture is quite incomplete.\n\nI am not convinced that ICLR is the right venue: robotics conferences such as IROS and ICRA might appreciate it much more. Nevertheless, this is just an encouragement to the authors to interact with those communities.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 2}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "nice idea, missing information", "is_meta_review": false, "comments": "A differentiable physics engine is indeed a wonderful thing to have. \n\nThe key selling point of the proposed software is its speed, however there is no comparison to other physics engines. Besides describing the engine's speed in rather creative units (e.g. \"model seconds per day\"), the reader has no idea if this is fast or slow. Todorov's engine (my simulator of choice) computes a dynamics step and its derivatives wrt both states and controls (using finite-differences) in less than 1ms for a *full humanoid* model (his code is available here mujoco.org/book/programming.html#saDerivative). I think this actually faster than the engine described in this paper, but I can't be sure.\n\nBecause this engine is so limited in what it can collide (sphere/sphere and sphere/plane), it would be trivial to build the example models in several other popular engines (e.g. ODE, Bullet and MuJoCo) and simply compare the performance. Until this comparison is done I consider the paper to be incomplete.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "Review", "is_meta_review": false, "comments": "This paper creates a physics simulator using theano, and uses it to learn a neural network policy by back propagating gradients through the simulation. The approach is novel, and is motivated by being able to learn policies for robotics.\n\nMy two key reservations with the paper are as follows:\n1. The method is motivated by learning policies for robotics. However, the proposed method is *only* useful for robotics if the learned policy can transfer the real world. Transferring policies from simulation to real-world is an open research problem, and is particularly challenging with less realistic simulators.\n2. They key novelty/benefit of this approach over other model-based approaches is that the simulator is differentiable. However, the only empirical comparison in the paper is to a model-free approach (CMA-ES). To appropriately demonstrate the approach, it should be compared to other model-based approaches, which do not require analytic derivatives of the model.\n\nFor the reader to fully understand the pros and cons of the approach, the paper should also include quantitative comparison between the speed of the proposed simulator, and that of standard simulation platforms.\n\nBecause the idea is interesting and novel, I think it lies above the acceptance threshold. However, it would be significantly improved with the aforementioned comparisons.\n\nLastly, the writing of the paper could be improved, as it is rather informal and/or imprecise in a number of places. Here are some examples:\n-- \u201cwe model the use of a neural network as a general controller for a robot\u201d - can be more concisely phrased as something like \u201cwe model the robot controller using a neural network\u201d or \u201cthe robot controller is modeled using a neural network\"\n-- \u201cIn previous research, finding a gradient\u2026\u201d - This is a run-on sentence.\n-- \u201cWe basically jam this entire equation into\u201d - This sentence is informal and imprecise.\n-- \u201cdeep learning neural network\u201d - the word \u201clearning\u201d should be omitted\n-- \u201cone big RNN, where we unfold over time\u201d - should be \u201c\u2026RNN, which we unfold over time\u201d or \u201c\u2026RNN, unfolded over time\u201d\n\nThe writing would also be improved by making it more concise and fitting the paper into 8 pages.", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "some questions and comments", "OTHER_KEYS": "(anonymous)", "comments": "Hi, it would be great if you can clarify the following.\n\n1. Section I: \"Evaluating finite difference approximations, however, requires the same number of model evaluations as the number of parameters with respect to which is differentiated.\" -- this is incorrect. If you have a differentiable policy, you only require model evaluations of the order of number of states (which are typically in 100s) and not number of parameters.\n\n2. Have you tried comparing against numerical derivatives of the Jacobian and propagating these to find derivatives with respect to policy parameters (as opposed to jamming everything into the RNN as noted in the paper)? To me, the entire pitch of the paper lies on the former being difficult. However, the robotics literature is full of success stories where essentially one plans through a model by computing gradients using finite differences (e.g. iLQG, CIO, GPS etc).\n\n3. How to handle cases when the dynamics is stochastic?\n\n4. How does this compare to other gradient based methods, but estimated differently. For example, policy gradient methods like REINFORCE, Natural Policy Gradient, or TRPO?", "IS_META_REVIEW": false, "DATE": "16 Dec 2016", "is_meta_review": false}, {"TITLE": "identify unknowns in the model?", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_META_REVIEW": false, "DATE": "11 Dec 2016", "is_meta_review": false}, {"TITLE": "pre-review questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "IS_META_REVIEW": false, "DATE": "01 Dec 2016", "is_meta_review": false}], "SCORE": 6, "authors": "Jonas Degrave, Michiel Hermans, Joni Dambre, Francis wyffels", "KEYWORDS": "We wrote a framework to differentiate through physics and show that this makes training deep learned controllers for robotics remarkably fast and straightforward", "accepted": false, "id": ""}
