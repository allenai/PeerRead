{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Sep-2015", "title": "Deep Temporal Sigmoid Belief Networks for Sequence Modeling", "abstract": "Deep dynamic generative models are developed to learn sequential dependencies in time-series data. The multi-layered model is designed by constructing a hierarchy of temporal sigmoid belief networks (TSBNs), defined as a sequential stack of sigmoid belief networks (SBNs). Each SBN has a contextual hidden state, inherited from the previous SBNs in the sequence, and is used to regulate its hidden bias. Scalable learning and inference algorithms are derived by introducing a recognition model that yields fast sampling from the variational posterior. This recognition model is trained jointly with the generative model, by maximizing its variational lower bound on the log-likelihood. Experimental results on bouncing balls, polyphonic music, motion capture, and text streams show that the proposed approach achieves state-of-the-art predictive performance, and has the capacity to synthesize various sequences.", "histories": [["v1", "Wed, 23 Sep 2015 18:36:42 GMT  (438kb,D)", "http://arxiv.org/abs/1509.07087v1", "to appear in NIPS 2015"]], "COMMENTS": "to appear in NIPS 2015", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["zhe gan", "chunyuan li", "ricardo henao", "david e carlson", "lawrence carin"], "accepted": true, "id": "1509.07087"}
