{
  "name" : "1611.02512.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Cognitive Discriminative Mappings for Rapid Learning",
    "authors" : [ "Wen-Chieh Fang", "Yi-ting Chiang" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Humans can learn concepts or recognize items from just a handful of examples, while machines require many more samples to perform the same task. In this paper, we build a computational model to investigate the possibility of this kind of rapid learning. The proposed method aims to improve the learning task of input from sensory memory by leveraging the information retrieved from long-term memory. We present a simple and intuitive technique called cognitive discriminative mappings (CDM) to explore the cognitive problem. First, CDM separates and clusters the data instances retrieved from long-term memory into distinct classes with a discrimination method in working memory when a sensory input triggers the algorithm. CDM then maps each sensory data instance to be as close as possible to the median point of the data group with the same class. The experimental results demonstrate that the CDM approach is effective for learning the discriminative features of supervised classifications with few training sensory input instances."
    }, {
      "heading" : "1 Introduction",
      "text" : "Scientists have interest in understanding the relations between all the levels that describe what a brain does. Adolphs listed the top 23 unsolved problems in neuroscience (including three \"meta\" issues) [1]. Two important questions, \"How does sensory transduction work?\" and \"How does learning and memory work?\", are closely connected [1]. Without sensory transduction that converts a sensory stimulus from one form to another, the brain cannot integrate and process the sensory input information with information stored in the memory.\nPeople can learn a new concept or recognize an item from just a handful of examples, while stateof-the-art machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy [6]. Scientists have long suspected that this type of \"one-shot learning,\" or rapid learning, involves a different mechanism in the brain than gradual learning [12]. We believe the underlying mechanism contains a complex information processing procedure.\nHumans have five main senses: sight, hearing, taste, smell, and touch [9]. The human brain can combine data from sensory memory (SM) and prior experiences retrieved from long-term memory (LTM) into a single phenomenal experience. Feature integration theory tackles the question of how humans perceive individual features as part of the same object by proposing a two-stage process: preattentive processing and focused attention processing [10] [11]. The basic idea is that objects are analyzed into features and that attention is necessary to combine these features to create perceptions of an object. We apply this theory to our model to describe how sensory input data are processed in SM. In addition, people can retrieve prior experiences encoded in LTM. We believe that this procedure is one of the reasons why humans learn new concepts quickly. Therefore, we simulate this procedure in our model.\nIn this paper, we model rapid learning as a prediction task with feature transformation and augmentation procedures in the working memory. The rapid learning problem aims at achieving high prediction\n29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n61 1.\n02 51\n2v 1\n[ cs\n.A I]\n8 N\nov 2\n01 6\nperformance when training a learning system with limited data drawn from SM by leveraging a relatively large amount of data retrieved from LTM.\nIn Section 2, we formally define the problem and introduce the framework of our approach. Then we present our approach, including the learning of discriminative features and the augmentation techniques in Section 3. We proceed by evaluating our approach on benchmark data sets and discuss the results in Section 4. Finally in Section 5, we conclude the paper and offer suggestions for future work."
    }, {
      "heading" : "2 Problem Definition",
      "text" : "Assuming that we have a labeled data set of NL points: {(xi, li)}NLi=1. The class li of each data instance xi ∈ Rm is in class set CL. We denote this data set as LTM data set DL. Let there be another data set of interest. We denote it as SM data set DS , which has few labeled data instances {(yi, li)}NSi=1. Each instance yi ∈ Rn. The class li is in class set CS . The class set CS is assumed to be equal to CL. The LTM and SM data sets are in different feature spaces. In most cases, the number of dimensions of the two input data sets are also different.\nOur goal is to build a classifier by making use of the small data {(yi, li)}NSi=1 from SM and the relatively large data {(xi, li)}NLi=1 from LTM. The classifier can be applied to new incoming data in SM and performs equally or even better than the classifier trained on data from SM. Note that there is no data instance without knowing its class from SM during the training phase.\nAccording to the definition in [7], given two domains, LTM domain DL = {X , P (X)} and SM domain DS = {Y, P (Y )}, where X , Y are feature spaces and P (X), P (Y ) are marginal probability distributions, X = {xi}NLi=1 ∈ X and Y = {yi} NS i=1 ∈ Y . If DL 6= DS , this implies that either X 6= Y or P (X) 6= P (Y ). In this paper, we focus on the situation of X 6= Y and CL = CS . We give two definitions in our problem:\n1. A discriminative cluster is a group of objects that share the same class label in a metric space.\n2. The radius of a cluster is the maximum distance between all the points and the median point.\nWe also give some assumptions:\n1. Data from SM and LTM exist for each class. Therefore our approach is a kind of supervised method.\n2. The data from SM and LTM may share no co-occurrence features. We do not rely on co-occurrence features to train the model; therefore, our approach can extend well to heterogeneous domains.\n3. No instance is shared across domains. 4. The relationship between the LTM domain and the SM domain is not given. We only know\nthat the two domains have the same classes in common. 5. The new incoming data from SM for evaluation are unseen during the training phase."
    }, {
      "heading" : "2.1 Lemma",
      "text" : "Lemma 1. A set of clusters C is said to be pairwise disjoint if and only if for every CL,CS ∈ C, let rCL and rCS be the radii of CL and CS respectively; then\nd(CL,CS) > rCL + rCS , (1)\nwhere d(CL,CS) is the distance between the median points of the two clusters CL and CS ."
    }, {
      "heading" : "2.2 Hypothesis",
      "text" : "We present the following main theoretical hypothesis. We believe the proposed hypothesis provides a promising theoretical base for us to develop the algorithm.\nHypothesis 1. Given that there exists an SM domain DS , a sample DS is from DS . If we can find a sample set DL in the LTM domain DL, and two mapping functions f and g are such that the following conditions are satisfied:\n1. Each data instance xi ∈ DL with class l and each data instance yj ∈ DS with same class l are mapped into a common discriminative cluster corresponding to the same class l in a new space.\n2. These discriminative clusters are pairwise disjoint.\nThen, there exists at least a hypothesis h ∈ H (H is a family of hypotheses in DS ) that the empirical error rate\n̂U∪V(h) ≤ ̂V(h) (2)\nwhere U is the projected LTM sample set in the new space, and V is the projected SM sample set in the new space. In other words, the samples in U help to reduce the empirical error rate."
    }, {
      "heading" : "3 Proposed Solution",
      "text" : ""
    }, {
      "heading" : "3.1 Main Idea",
      "text" : "Because the data from LTM and SM are in different feature spaces, it is desirable to find a common invariant feature space in which all data can be directly compared. Inspired by the min-max principle [5] and class-based constraints [8], we apply two transformations to map the LTM and SM data in order, to satisfy class constraints between the transformed points.\nIn order to learn two transformation functions f and g for the SM data classification, we first define two variables ψS and ψD as follows:\nψS(f, g) = ∑\ni∈LTM,j∈SM,li=lj\ndΩ(f(xi), g(yj)) + ∑\ni,j∈LTM,li=lj\ndΩ(f(xi), f(xj)) + ∑\ni,j∈SM,li=lj\ndΩ(g(yi), g(yj))\nψD(f, g) = ∑\ni∈LTM,j∈SM,li 6=lj\ndΩ(f(xi), g(yj)) + ∑\ni,j∈LTM,li 6=lj\ndΩ(f(xi), f(xj)) + ∑\ni,j∈SM,li 6=lj\ndΩ(g(yi), g(yj)) (3)\nHere, dΩ(·, ·) is the distance function defined in the common space Ω. ψS sums the distance between the transformed points from LTM and SM with the same class, while ψD indicates the sum of the distance between the projected instances from LTM and SM with different classes.\nThen, we posit that there exist two bounds u and l such that two inequations are necessary for the generation of pairwise disjoint discriminative clusters:\nψS(f, g) ≤ u ψD(f, g) ≥ l\n(4)\nwhere u and l are the upper and lower bounds chosen so that ψS should be small, and ψD should be large. Given the LTM data, SM data, and the class constraints in advance, if we can learn two transformation functions f and g from the data to satisfy inequations 4, we are able to use LTM data to help improve prediction performance."
    }, {
      "heading" : "3.2 Our Solution",
      "text" : "In this paper, we present a linear version. We represent f and g as two linear transformation functions, namely P and Q. That is, f(xi) = Pxi and g(yj) = Qyj .\nWe present a computational mappings model to make use of both data from LTM and SM. At first, sensory data instances are being taken in by sensory receptors and kept in SM. When the sensory data instances are stored in SM long enough, they are transferred to working memory. In the new working memory space, these transformed data are populated into clusters according to their classes. Fig. 1 illustrates the main idea of the proposed model.\nWe can estimate the two linear transformations P and Q by first deciding one transformation. Most of the time, there are many more related samples from LTM than there are sensory cases in SM. Consequently, we use mapping function P : X → U to project the LTM data X ∈ RNL×m into U ∈ RNL×d in a latent space Ω in working memory. Therefore P ∈ Rd×m. The latent space Ω is assumed to be a d-dimensional Riemannian manifold.\nWe present three different approaches in the retrieval phase. The first approach is where the c geometric medians of clusters corresponding to the classes are fixed and predefined in the latent space. The data in LTM are mapped into these locations by a transformation matrix P and form discriminative clusters simultaneously.\nIn the second approach, we apply Linear discriminant analysis (LDA) [4] to characterize or separate the classes of instances. We use the transformation matrix P provided by LDA to project original instances onto a latent space, and a new feature set is generated.\nIn the third approach, a linear transformation P is derived by minimizing a cost function similar to Graph embedding method (GE) [13] as follows:\nP = min P\n1\n2 ∑ i,j ||Pxi −Pxj ||2Wij , (5)\nwhere W is a sparse symmetric NL ×NL matrix that represents class similarity relationship and where Wij = 1 if li = lj and Wij = −1 if li 6= lj . Given the transformation P of the data from LTM, we can find a mapping Q : Y → V such that each data instance yi ∈ Rn with class li ∈ C is mapped to a point vi ∈ Rd in the neighborhood of the cluster corresponding to the class li. In this paper, we provide an approximation solution to find such a mapping. The idea is that each data instance yi with class label l ∈ C is mapped to a point vi such that vi is as close as possible to the median point γl. We can find such a linear mapping matrix Q ∈ Rd×n by setting:\nQ = arg min Q ∑ l ∑ i:li=l ||Qyi − γl||2, (6)\nwhere ∑ i:li=l denotes the summation over i such that label li = l.\nTo avoid overfitting, we add a regularization term ζ(Q). For example, we can set ζ(Q) = η||Q||2F , in which η is the weight and ||·||F is the Frobenius norm. The P and Q mapping functions are derived for the purpose of obtaining a low-dimensional representation of the data that separates the populations as much as possible. However, the classes may not be sufficiently separated. Consequently, we apply a discrimination method again to determine a mapping function H to render the classes as separated as possible."
    }, {
      "heading" : "3.3 Feature Augmentation",
      "text" : "After applying the final discrimination method to transfer the data, we derive new features. Daumé III provides a feature augmentation method to integrate more information [3]. For each instance, we utilize the feature augmentation method to augment the new features with the original features to represent the instance [3].\nWe define two feature mapping functions φL(x) = [(HPx)>, 0>n ] > and φS(y) = [(HQy)>,y>]> for the data from LTM and SM, respectively. Here 0n denotes zero column vectors of dimensions n. Including zeros in the feature representations ensures that the dimensions of the instances from LTM and SM become the same. Moreover, the entire data set from LTM has no information on the features from SM. Therefore, it is reasonable to set zero values (0>n ) in the later n feature dimensions."
    }, {
      "heading" : "3.4 Proposed Algorithmic Procedure",
      "text" : "As a summary, we give the algorithm of the proposed method:\n1. Use a projection approach to learn a mapping P to project data retrieved from LTM to a new d dimensional space in the working memory. All the projected data in the new space are grouped into several clusters corresponding to the classes.\n2. Compute the generalized geometric median of all clusters.\n3. Compute the mapping function Q for data in the SM via these generalized geometric medians.\n4. Apply Q to map the SM data for training and new incoming SM data to the new d dimensional space.\n5. Apply a discrimination method again to construct a transformation matrix H to separate all the instances into distinct classes.\n6. Augment the learned features with the original SM features to represent the instance.\n7. With the projected data with known classes from LTM and SM as training data, conventional supervised machine learning methods can be used to learn the model and predict the projected new incoming data from SM."
    }, {
      "heading" : "4 Experimental Results",
      "text" : "In this section, we conduct several experiments on two benchmark data sets. We assume that there is only one data set from LTM and one data set from SM. Because the upper bound of the number of retained dimensions in LDA is c− 1 (c is the number of classes), we set the dimension of the new space in the first projection for learning P and final projection to c− 1. For selection of the weight of the regularization term η, cross-validation is not applicable due to the small number of training instances from the SM domain.Therefore, we tune the parameters on a predefined range and report the optimal parameter value. In this paper, we report the results when η = 1.\nWe apply a k nearest neighbor classifier (kNN, k = 5) and a Support Vector Machine with a Radial Basis Function kernel (RBF SVM) to train the final classifiers on the data sets. The training instances are derived from both LTM and SM. For the baseline approach, we train the classifier on the original labelled instances from SM and use it to predict the test instances. We randomly sample the training instances ten times and report the average accuracy over the ten rounds of experiments. In this paper, we conduct experiments in different settings in the two data sets and report the results."
    }, {
      "heading" : "4.1 Data Sets",
      "text" : ""
    }, {
      "heading" : "4.1.1 Object Recognition Data Set",
      "text" : "The first data set1 contains 4, 652 images from 31 categories2 originating from the following three domains: Amazon (images downloaded from an online retail website), dslr (high-resolution images taken from a digital DLR camera) and webcam (low-resolution images taken from a web camera) [8]. SURF features are extracted for all the images.\nThe Amazon and webcam images are used as data retrieved from LTM. We randomly select twenty and eight training images per category for the Amazon and webcam data sets, respectively. We then randomly select k training images per category for the dslr data set as SM data, where k = 3, 4, 5, and 6. The remaining images are used for testing. Table 1 shows a summary of the data set."
    }, {
      "heading" : "4.1.2 Text Categorization Data Set",
      "text" : "The second data set is a subset of the Reuters RCV1/RCV2 collections [2]. It contains newswire articles written in English, French, German, Italian, and Spanish. There are six classes for these articles: C15, CCAT, E21, ECAT, GCAT, and M11.\nWe take Spanish articles as SM data and articles written in the other four languages as individual data sets retrieved from LTM. For each class, we randomly sample one hundred training instances from the data sets in LTM and k training instances from SM data, where k = 5, 7, 10, 15, and 20. We also perform a Principal Components Analysis (PCA) with 60% energy preserved on the TF-IDF features. The remaining instances from SM data are used as the test instances. Table 2 shows a summary of the data set, and Table 3 shows the distribution of classes in the data set."
    }, {
      "heading" : "4.2 Comparative Studies",
      "text" : ""
    }, {
      "heading" : "4.2.1 Object Recognition Data Set",
      "text" : "Table 4 shows the performance of the baseline approach and the CDM approach in different settings on the object recognition dataset. The results show that the CDM approach using a kNN classifier both with and without augmentation have outstanding performance in the object recognition dataset. In the case of the RBF SVM classifier, although the learned features are not good enough for training a prediction model, augmenting the learned features with the original features from SM improves the performance.\n1Visit http://vision.cs.uml.edu/adaptation.html for more details. 2These 31 categories are: backpack, bike, bike helmet, bookcase, bottle, calculator, computer, desk chair, desk lamp, file cabinet, headphones, keyboard, laptop, letter tray, mobile phone, monitor, mouse, mug, notebook, pen, phone, printer, projector, puncher, ring binder, ruler, scissors, speaker, stapler, tape, and trash can"
    }, {
      "heading" : "4.2.2 Text Categorization Data Set",
      "text" : "Table 5 shows the performance of both the baseline approach and the CDM approach in different settings on the text categorization dataset. Both the kNN and RBF SVM classifiers with and without augmentation outperform the baseline approach."
    }, {
      "heading" : "4.3 Influence of the Number of Training Samples per Class from SM domain",
      "text" : "Figure 2 shows the accuracy of baseline and the proposed CDM approach with respect to the number of training samples per class for each data set from SM. For both the CDM and baseline approaches, we use the RBF SVM as the classifier. As shown in Fig. 2a and Fig. 2b, the accuracies of the baseline approach and CDM increase when we use a larger k."
    }, {
      "heading" : "5 Conclusions",
      "text" : "We proposed a computational model called CDM for the cognitive rapid learning problem. CDM has the following excellent properties: a) CDM is elegant, intuitive, and efficient; and, b) CDM has a complete theoretical architecture. The experimental results show that we can find at least one hypothesis or classifier that satisfies our hypothesis for rapid learning. One-shot learning or rapid learning is still a work in progress. From the CDM experience, we think that cognitive scientists should be required to pay attention to the role of information retrieved from LTM in rapid learning.\nFrom the experimental results, we found that the feature augmentation did not always guarantee performance improvement. It is worth investigating this issue in the future.\nIn CDM, because we want to create a common metric space for LTM and SM, we proposed global metric learning in the working memory; unfortunately, this results in a CDM limitation. CDM attempts to find mapping matrices that minimize the sum of all pairwise distances between data points in the same class and maximize the sum of all pairwise distances between data points in different classes. As such, this implicitly assumes that classes form a single compact connected set. If the data instances are in highly multi-modal class distributions, the cost function will be penalized. Therefore, developing a discrimination approach that focuses on local neighborhoods for the problem is worth studying in future research."
    } ],
    "references" : [ {
      "title" : "The unsolved problems of neuroscience",
      "author" : [ "Ralph Adolphs" ],
      "venue" : "Trends in Cognitive Sciences,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2015
    }, {
      "title" : "Learning from multiple partially observed views - an application to multilingual text categorization",
      "author" : [ "Massih-Reza Amini", "Nicolas Usunier", "Cyril Goutte" ],
      "venue" : "In Proceedings of the 23rd Annual Conference on Advances in Neural Information Processing Systems",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "Frustratingly easy domain adaptation",
      "author" : [ "Halneigh Daumé III" ],
      "venue" : "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2007
    }, {
      "title" : "Introduction to statistical pattern recognition",
      "author" : [ "Keinosuke Fukunaga" ],
      "venue" : "Academic Press Professional,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1990
    }, {
      "title" : "Semi-supervised distance metric learning for collaborative image retrieval",
      "author" : [ "Steven C.H. Hoi", "Wei Liu", "Shih-Fu Chang" ],
      "venue" : "In Proceedings of the 21st IEEE Conference on Computer Vision and Pattern Recognition",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2008
    }, {
      "title" : "Human-level concept learning through probabilistic program induction",
      "author" : [ "Brenden Lake", "Ruslan Salakhutdinov", "Joshua Tenenbaum" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2015
    }, {
      "title" : "A survey on transfer learning",
      "author" : [ "Sinno Jialin Pan", "Qiang Yang" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "Adapting visual category models to new domains",
      "author" : [ "Kate Saenko", "Brian Kulis", "Mario Fritz", "Trevor Darrell" ],
      "venue" : "In Proceedings of the 11th European Conference on Computer Vision (ECCV’10),",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Cognitive Psychology",
      "author" : [ "Robert J. Sternberg", "Karin Sternberg" ],
      "venue" : "Wadsworth Publishing, sixth edition,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "Features and objects in visual processing",
      "author" : [ "Anne Treisman" ],
      "venue" : "Scientific American,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1986
    }, {
      "title" : "Solutions to the binding problem: progress through controversy",
      "author" : [ "Anne Treisman" ],
      "venue" : "and convergence. Neuron,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1999
    }, {
      "title" : "How one-shot learning unfolds in the brain",
      "author" : [ "Janelle Weaver" ],
      "venue" : "PLOS Biology,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Graph embedding and extensions: A general framework for dimensionality reduction",
      "author" : [ "Shuicheng Yan", "Dong Xu", "Benyu Zhang", "Hong-Jiang Zhang", "Qiang Yang", "Stephen Lin" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Adolphs listed the top 23 unsolved problems in neuroscience (including three \"meta\" issues) [1].",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 0,
      "context" : "Two important questions, \"How does sensory transduction work?\" and \"How does learning and memory work?\", are closely connected [1].",
      "startOffset" : 127,
      "endOffset" : 130
    }, {
      "referenceID" : 5,
      "context" : "People can learn a new concept or recognize an item from just a handful of examples, while stateof-the-art machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy [6].",
      "startOffset" : 215,
      "endOffset" : 218
    }, {
      "referenceID" : 11,
      "context" : "Scientists have long suspected that this type of \"one-shot learning,\" or rapid learning, involves a different mechanism in the brain than gradual learning [12].",
      "startOffset" : 155,
      "endOffset" : 159
    }, {
      "referenceID" : 8,
      "context" : "Humans have five main senses: sight, hearing, taste, smell, and touch [9].",
      "startOffset" : 70,
      "endOffset" : 73
    }, {
      "referenceID" : 9,
      "context" : "Feature integration theory tackles the question of how humans perceive individual features as part of the same object by proposing a two-stage process: preattentive processing and focused attention processing [10] [11].",
      "startOffset" : 209,
      "endOffset" : 213
    }, {
      "referenceID" : 10,
      "context" : "Feature integration theory tackles the question of how humans perceive individual features as part of the same object by proposing a two-stage process: preattentive processing and focused attention processing [10] [11].",
      "startOffset" : 214,
      "endOffset" : 218
    }, {
      "referenceID" : 6,
      "context" : "According to the definition in [7], given two domains, LTM domain DL = {X , P (X)} and SM domain DS = {Y, P (Y )}, where X , Y are feature spaces and P (X), P (Y ) are marginal probability distributions, X = {xi} i=1 ∈ X and Y = {yi} NS i=1 ∈ Y .",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 4,
      "context" : "Inspired by the min-max principle [5] and class-based constraints [8], we apply two transformations to map the LTM and SM data in order, to satisfy class constraints between the transformed points.",
      "startOffset" : 34,
      "endOffset" : 37
    }, {
      "referenceID" : 7,
      "context" : "Inspired by the min-max principle [5] and class-based constraints [8], we apply two transformations to map the LTM and SM data in order, to satisfy class constraints between the transformed points.",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 3,
      "context" : "In the second approach, we apply Linear discriminant analysis (LDA) [4] to characterize or separate the classes of instances.",
      "startOffset" : 68,
      "endOffset" : 71
    }, {
      "referenceID" : 12,
      "context" : "In the third approach, a linear transformation P is derived by minimizing a cost function similar to Graph embedding method (GE) [13] as follows:",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 2,
      "context" : "Daumé III provides a feature augmentation method to integrate more information [3].",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 2,
      "context" : "For each instance, we utilize the feature augmentation method to augment the new features with the original features to represent the instance [3].",
      "startOffset" : 143,
      "endOffset" : 146
    }, {
      "referenceID" : 7,
      "context" : "1 Object Recognition Data Set The first data set1 contains 4, 652 images from 31 categories2 originating from the following three domains: Amazon (images downloaded from an online retail website), dslr (high-resolution images taken from a digital DLR camera) and webcam (low-resolution images taken from a web camera) [8].",
      "startOffset" : 318,
      "endOffset" : 321
    }, {
      "referenceID" : 1,
      "context" : "2 Text Categorization Data Set The second data set is a subset of the Reuters RCV1/RCV2 collections [2].",
      "startOffset" : 100,
      "endOffset" : 103
    } ],
    "year" : 2016,
    "abstractText" : "Humans can learn concepts or recognize items from just a handful of examples, while machines require many more samples to perform the same task. In this paper, we build a computational model to investigate the possibility of this kind of rapid learning. The proposed method aims to improve the learning task of input from sensory memory by leveraging the information retrieved from long-term memory. We present a simple and intuitive technique called cognitive discriminative mappings (CDM) to explore the cognitive problem. First, CDM separates and clusters the data instances retrieved from long-term memory into distinct classes with a discrimination method in working memory when a sensory input triggers the algorithm. CDM then maps each sensory data instance to be as close as possible to the median point of the data group with the same class. The experimental results demonstrate that the CDM approach is effective for learning the discriminative features of supervised classifications with few training sensory input instances.",
    "creator" : "LaTeX with hyperref package"
  }
}