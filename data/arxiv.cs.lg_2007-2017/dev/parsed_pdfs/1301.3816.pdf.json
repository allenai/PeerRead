{
  "name" : "1301.3816.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning Output Kernels for Multi-Task Problems",
    "authors" : [ "Francesco Dinuzzo" ],
    "emails" : [ "fdinuzzo@tuebingen.mpg.de" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Combining multiple datasets for solving related inference problems is a common and successful practice in several domains such as econometrics and marketing analysis, recommender systems on the web, bioinformatics, pharmacology, and many others. Indeed, simultaneously solving multiple inference problems can improve performances, provided that the relationships between them are correctly modeled. The themes of transfer learning, multi-task learning or “learning to learn” [9, 19, 44] have attracted considerable attention in the literature, see [30] for a recent survey. A possible way to enforce relationships between the tasks is to extract a set of shared features. This can be done by employing multi-layer neural networks where the hidden layer is shared among the tasks [9], or also within a convex regularization framework [4]. Task relationships can be also modeled within the framework of Gaussian Processes estimation [7, 8, 31, 40, 46, 49] by designing a joint covariance function. A variety of other models have been proposed to represent and exploit inter-task relationships [3, 23,32,48,50,51].\n∗Max Planck Institute for Intelligent Systems, Spemannstrasse 38,72076 Tübingen, Germany. E-mail: fdinuzzo@tuebingen.mpg.de\nar X\niv :1\n30 1.\n38 16\nv1 [\ncs .L\nG ]\n1 6\nJa n\nCorrectly modeling the inter-task relationships for a given application is critical but not always easy. In fact, in many inference problems, the tasks are known to be related with each other, but the available prior knowledge is not sufficient to model the relationships in advance. For this reason, some recent works have been focusing on inferring inter-task relationships automatically from the data, while solving the multi-task learning problem. One possibility is to assume that the tasks can be clustered into homogeneous groups and try to learn such clustering from the data [6]. Optimization-based approaches that jointly infer the task parameters and the inter-task relationships in the form of a similarity matrix include the spectral regularization approach of [5] and the method of [52] based on convex optimization. An online method has been also proposed recently to learn multiple linear classifiers as well as a task relationship matrix [38].\nRegularized kernel methods [39] have been employed successfully in a variety of single-task learning problems. Their extension to the multi-task setting [15] calls for the design of suitable operator-valued kernels that model similarities of both inputs and tasks. Some classes of operator-valued kernels have been recently reviewed in [2]. Within the framework of regularization in RKHS of vectorvalued functions, the problem of inferring task relationships boils down to the problem of learning a multi-task kernel. A possible way to address this problem consists in learning a linear combination of task-specific kernels [47], within the framework of multiple kernel learning (MKL). Recently, a class of output kernel learning (OKL) methods [12, 13] has been introduced in the context of multi-output learning problems (such as vectorial regression, multi-class and multi-label classification) to automatically synthesize a decomposable matrixvalued kernel that encodes the relationships between the output components. Differently from MKL, OKL methods don’t require the specification of a set of basis kernels to be combined, as the output kernel is searched into the whole cone of positive semidefinite kernels.\nThis paper explores the possibility of automatically learning the relationships between multiple tasks via output kernel learning. To this end, we extend a technique for learning low-rank output kernels proposed in [11] to the multi-task setting. The low-rank encouraging regularization can be shown to be useful both for computational reasons and learning performances. The extension developed in this paper is based on the use of a suitable weighted loss that allows for multiple datasets with different input sampling patterns. The resulting method can be also interpreted as a non-linear kernel based generalization of low-rank matrix completion techniques. Even in the simpler setup of linear low-rank matrix factorization, the case of incomplete observations has been recognized to be computationally challenging, see e.g. [42], since existing optimization techniques based on eigendecompositions do not carry over to the weighted case. For this reason, we have developed a new strategy to solve the optimization problem. Similarly to [52], we learn multiple tasks as well as their relationships by solving a joint optimization problem. However, differently from [52] and [38], that learn multiple linear functions by convex optimization, we learn multiple non-linear functions by solving a non-convex optimization problem. Albeit non-convex, the\nproblem exhibits a special structure that allows for effective optimization via a block-coordinate descent procedure based on the iterative application of the conjugate gradient (CG) algorithm for linear operator equations. Our method is also related to the technique derived in [8] in the context of Bayesian estimation of Gaussian Processes, that allows to learn a similarity (covariance) matrix between the tasks. While [8] aims at optimizing a marginal likelihood type functional, our method is based on the minimization of a functional with trace norm regularization plus rank constraint. In [8], the authors adopt a general purpose gradient-descent solver to optimize their objective functional, whereas in this paper we develop a novel optimization strategy that is specifically designed to solve the proposed OKL optimization problem. Differently from [8], our method is able to deal with the case of incomplete sampling, and automatically encourages low-rank solutions without introducing relaxations of the original problem."
    }, {
      "heading" : "2 Weighted output kernel learning",
      "text" : "Let I denote the identity matrix and e the vector of all ones (of suitable dimensions). For any matrix A, let AT denote the transpose, tr(A) the trace, rank(A) the rank, vec(A) the vectorization operator, A† the pseudo-inverse,\n‖A‖F = ( tr ( ATA ))1/2 the Frobenius norm, and ‖A‖∗ := tr (( ATA )1/2) the nuclear norm. For any pair of matrices of the same size A,B, let 〈A,B〉F := tr(ATB) denote the Frobenius inner product. The symbols ⊗ and denote the Kronecker product and the Hadamard (element-wise) product, respectively. Finally, let Sm+ denote the closed cone of positive semidefinite matrices of order m, and\nSm,p+ = { A ∈ Sm+ : rank(A) ≤ p } ⊆ Sm+\nthe cone of positive semidefinite matrices with rank less than or equal to p."
    }, {
      "heading" : "2.1 Output kernel learning for multi-task problems",
      "text" : "Consider the problem of learning several functions (tasks) gj : X → R (j = 1, . . . ,m) from multiple datasets of input-output pairs (xij , yij). Since the input set X is common to all the tasks, the functions gj can be combined into a single vector-valued function g : X → Rm, to be learned from a single dataset of ` pairs (xi, yi), where the output data yi are now vectors that may contain missing components. Let W ∈ {0, 1}`×m denote a binary weight matrix specifying which output components are missing for each example. More precisely, the i-th row of the weight matrix is a binary vector wi with zeros in correspondence with the missing components of yi. Since the weight matrix is always available, we can assume without loss of generality that all the missing output components have been imputed with zeros.\nIn the following, we describe a regularization approach where the function g is searched into a reproducing kernel Hilbert space (RKHS) H of vector-valued functions g : X → Rm associated with a decomposable reproducing kernel H of the form\nH(x1, x2) = KX(x1, x2) · L,\nwhere KX is positive semidefinite scalar kernel (called input kernel) and L ∈ Sm+ is a symmetric positive semidefinite matrix (called output kernel). For more details about RKHS of vector-valued functions, see [27].\nThe function g ∈ H and the output kernel L are simultaneously learned by solving a joint regularization problem of the form\nmin L∈Sm,p+ g∈H\n(∑̀ i=1 ‖wi (g(xi)− yi)‖22 2λ + ‖g‖2H 2 + tr(L) 2 ) . (1)\nThe objective functional contains a data-fitting term, taking into account the prediction error in correspondence with the observed output components, a regularization term on the unknown function g, and a trace regularization on the output kernel. Optimization of the output kernel is carried over the low-rank cone Sm,p+ , thus also imposing a hard rank constraint.\nIn view of the representer theorem [14, 24], the minimization problem with respect to g admits a solution of the form\ng∗(x) = L ∑̀ i=1 ciKX(x, xi),\nwith suitable coefficient vectors ci ∈ Rm. Letting K ∈ S`+ be such that Kij = K(xi, xj), the following finite-dimensional optimization problem is obtained\nmin L∈Sm,p+ C∈R`×m\n( ‖Y −KCL‖2W\n2λ + 〈CTKC,L〉F 2 + tr(L) 2\n) , (2)\nwhere the matrices Y,C ∈ R`×m are defined as\nY = (y1, . . . , y`) T , C = (c1, . . . , c`) T ,\nand the (semi)-norm ‖ · ‖W is given by\n‖A‖W = ‖W A‖F .\nObserve that Y is a sparse matrix (missing values have been imputed with zeros). Moreover, since W is a binary matrix with the same sparsity pattern of Y, we also have\nY = W Y. (3)\nWithin the formulation of problems (1) and (2), a first possibility is to simply set p = m. With such a choice, the hard constraint on the rank is not present, but the trace regularization will still encourage low-rank solutions, see e.g. [16]. It is nevertheless convenient to allow for the more general choice p ≤ m. A first reason is that, by providing an explicit bound p < m on the rank, it is possible to control the computational and memory requirements of the method before running the optimization. This holds since, within the optimization framework developed in the next section, only matrices of rank p are stored and manipulated, whereas the full matrix L is never formed explicitly. A second reason is that, when the regularization parameter λ is small enough, the hard rank constraint becomes active, and may yield interesting solutions that are not obtainable by using only the trace regularization (see, for example, the experiment in subsection 4.1).\nThe objective functional of (2) is not jointly (quasi)-convex. However, it is convex separately with respect to both L and C. In addition, for p = m it is an invex function [28] in the interior of the feasible set, meaning that every stationary point is a global minimizer. When all the output components are observed, i.e. W = eeT , problem (2) can be attacked using techniques based on eigendecompositions. Since these techniques do not apply anymore for general weight matrices, in the following we develop a new strategy to obtain a minimizer of (2)."
    }, {
      "heading" : "2.2 Equivalent formulations",
      "text" : "Before going into the details of the optimization procedure proposed to solve (2), is it useful to introduce some equivalent reformulations of the optimization problem. The proofs of the two following Lemmas are reported in the appendix.\nLemma 2.1 If (A,B) is an optimal solution of the following problem:\nmin A∈R`×p B∈Rm×p\n( ‖Y −KABT ‖2W\n2λ + 〈A,KA〉F 2 + ‖B‖2F 2\n) , (4)\nthen any pair (C,L) such that\nL = BBT , A = CB,\nis an optimal solution of problem (2).\nLemma 2.1 provides a new formulation of the low-rank output kernel learning problem (2) that involves only “thin” matrices A and B, whose size can be controlled by selecting the parameter p. Such formulation turns out to be particularly convenient for optimization purposes. It is also insightful to observe that problem (2) can be reformulated as a reduced rank least square problem with a “kernelized” nuclear norm regularization.\nLemma 2.2 If Θ is an optimal solution of the following problem:\nmin Θ∈R`×m\n[ ‖Y −KΘ‖2W\n2λ + tr\n(( ΘTKΘ )1/2)] ,\nsubject to rank(Θ) ≤ p,\nthen the pair\nL = ( ΘTKΘ )1/2 , C = L†Θ,\nis an optimal solution of problem (2).\nLemma 2.2 shows that the low-rank output kernel learning problem (2) is a nonlinear kernelized generalization of least squares low-rank matrix approximation (RMF) with nuclear norm regularization. Indeed, RMF can be obtained as a particular case by choosing the input kernel as a Kronecker delta kernel\nK(x1, x2) = δK(x1, x2) = { 1, x1 = x2 0, else\nso that K = I, tr (( ΘTKΘ )1/2) = ‖Θ‖∗.\nThe related MMMF (maximum-margin matrix factorization) technique [33,43] would also correspond to the case K = I, but with hinge-type (SVM) losses instead of the square loss."
    }, {
      "heading" : "3 A block coordinate descent strategy",
      "text" : "In the following, we focus on the solution of (4). If p is much smaller than m, handling the low-dimensional factor B is much more convenient than directly handling the full output kernel matrix. Let J(A,B) denote the objective functional of (4). Observe that, although J is non-convex, it is unconstrained and separately convex with respect to both factors. Therefore, it is natural to adopt a block coordinate descent technique that iteratively alternates between optimization with respect to the two blocks. Clearly, other optimization strategies are also possible, but the block coordinate descent approach is memory efficient, robust, and simple to implement. In addition, it turns out to behave well in practice, since very few iterations are typically sufficient to obtain a good solution, especially when combined with a warm-start regularization path procedure (see subsection 3.3). As shown in the following, the two subproblems boil down to the solution of linear equations of the form\nLAA = yA, (5) LBB = yB (6)\nwhere LA and LB are linear operators mapping matrices into vectors. In the following subsections, we derive equations (5)-(6), and discuss the application of suitable iterative methods for solving them."
    }, {
      "heading" : "3.1 Sub-problem w.r.t. A",
      "text" : "The sub-problem w.r.t. A is the most numerically challenging of the two since, in general, the linear operator LA is not symmetric. For any fixed B, a necessary and sufficient condition for A to be optimal is obtained by setting to zero the partial derivative of the objective functional:\n∂J ∂A (A,B) = K\n[ W ( KABT −Y ) B\nλ + A\n] = 0.\nA sufficient condition is given by W ( KABT ) B + λA = YB,\nwhere we have used (3) in order to simplify the right hand side. If the weight matrix is full, this last equation reduces to a discrete-time Sylvester equation, a well studied class of linear matrix equations, see e.g. [41]. However, for general W, the optimality condition is not a Sylvester equation anymore, due to presence of the Hadamard product. Now, letting\nWD = diag(vec(W)), LAA = [( BT ⊗ I ) WD (B⊗K) + λI ] vec(A),\nyB = vec(YB),\nand using the matrix identities (8) and (10), the sufficient optimality condition can be rewritten in the form (5).\nIf W is full, it is easy to verify, using the mixed-product identity (9) for the Hadamard product, that the operator LA reduces to\nLAA = [( BTB ) ⊗K + λI ] vec(A),\nand is therefore symmetric and positive definite. In such a case, one can either apply the conjugate gradient algorithm, or also use a procedure based on eigendecompositions in order to solve (5). Unfortunately, these methods cannot be applied for general weight matrices, since the operator LA is not guaranteed to be symmetric.\nA first possible way to attack the problem is trying to directly obtain a solution of the non-symmetric operator equation (5) by means of iterative methods that can handle non-symmetric equations, such as the generalized minimal residual method (GMRES) [37]. However, the computational requirements of GMRES grow with the number of iterations and, for large scale problems, a restart strategy is needed to limit the memory requirements at the expense of convergence speed. The alternative is to introduce a change of variable to make the problem symmetric, and then apply a preconditioned conjugate gradient (CG) algorithm [20] on the new linear equation. Generally, CG requires less computational resources than GMRES, since the search directions are obtained via\nsimple recursive updates and a restart strategy is not required. For additional details about these and others iterative method for solving linear equations, see e.g. [36].\nAnother way to address non-symmetry is to look for a change of variable that makes the problem symmetric. A first possible change of variable derives from the observation that the optimal solution must be in the form A = CB. By using this representation, one can equivalently solve a new linear equation with respect to C:\nW [ K (W C) BBT ] + λC = Y.\nOnce again, the equation can be rewritten in the form\nLCC = vec(Y),\nwhere LCC = [ WD ( (BBT )⊗K ) WD + λI ] vec(C).\nThis time, the operator LC is symmetric and positive definite, so that CG applies. A disadvantage of this approach is that, for p m, C is much higherdimensional than A. Nevertheless, when the weight matrix W is sparse, C is also a sparse matrix with the same sparsity pattern, and one can take advantage of this property.\nAnother approach is based on a factorization of the input kernel matrix of the form\nK = FFT .\nThe factor F can be a Cholesky factor, a matrix square root, or also a low-rank factor. We can use the factorization to introduce a new change of variable\nAF = F TA, (7)\nso that the matrix AF solves the equation FTW ( FAFB T ) B + λAF = F TYB.\nThis last equation can be rewritten in vectorized form\nLFAF = vec(FTYB),\nwhere LFAF = [( BT ⊗ FT ) WD (B⊗ F) + λI ] vec(AF ).\nIndependently of which factorization of K has been adopted, the linear operator LF is symmetric and positive definite, so that CG can be applied. Once a solution AF has been obtained, the matrix A can be recovered as a solution of the linear system (7).\nIn our experiments, all of the aforementioned approaches have been tested. The last approach based on the Cholesky factorization of the input kernel matrix turned out to be generally faster than the others, therefore we selected it for our current implementation."
    }, {
      "heading" : "3.2 Sub-problem w.r.t. B",
      "text" : "The sub-problem w.r.t B is essentially a multiple ridge regression problem. First of all, observe that the objective functional depends on A only through the product E = KA. Therefore, when A is fixed, a necessary and sufficient condition for B to be optimal is\n∂J ∂B (A,B) = ET\nW ( EBT −Y ) λ + BT = 0.\nIn this case, it turns out that an expression for the rows of B can be even written in closed form. Indeed, let bj (j = 1, . . . ,m) denote the rows of B, y j and wj denote the columns of Y and W, respectively. Then, we have\nbj = ( ET diag(wj)E + λI )−1 Ediag(wj)yj .\nObserve that the updates for the different rows can be computed in parallel. Finally, by letting\nLBB = [ (ET ⊗ I)diag(vec(WT ))(E⊗ I) + λI ] vec(B),\nand yB = vec(Y TE),\nthe optimality condition can be also rewritten in the form (6). Here, the operator LB can be seen to be symmetric and positive definite, therefore it is possible to use a conjugate gradient method to obtain a solution."
    }, {
      "heading" : "3.3 Implementation details",
      "text" : "Several important details must be taken into account in order to guarantee a correct and efficient convergence behavior."
    }, {
      "heading" : "3.3.1 Warm-start path procedure",
      "text" : "It is typically necessary to train the kernel machine for several different values of the regularization parameter λ. Generally, the regularization problem is better conditioned for large values of λ. On the same time, the solution is expected to depend continuously on the regularization parameter. For these reasons, it is convenient to initialize the optimization of each problem with the solution obtained with the previous value of λ, after sorting the different values of the regularization parameter in decreasing order. Such warm-start regularization path strategy is very effective in practice: if the grid of values of λ is sufficiently fine, one or two iterations of block coordinate descent for each value of λ are often sufficient to converge with a good accuracy."
    }, {
      "heading" : "3.3.2 Initialization",
      "text" : "It is possible to show that the rank of B cannot increase between an iteration of block-coordinate descent and the next. For this reason, at the very beginning of the warm-start procedure, B is initialized to a full-rank matrix. Otherwise, an optimal solution of high rank may be missed by the algorithm. Another issue comes from the fact that the origin is a stationary point of the objective functional for any value of λ. Although, for very large values of the regularization parameter, the origin is actually a global minimizer, this is not the case anymore for small values. Now, in view of the warm-start procedure, the algorithm may never move away from the origin if the initial λ is very large. To safeguard against this behavior, B is re-initialized to a full-rank matrix every time it becomes too small (for example, w.r.t. the Frobenius norm)."
    }, {
      "heading" : "4 Experiments",
      "text" : "In this section, we analyze the performance of weighted OKL on a variety of multi-task problems, including pharmacokinetic-pharmacodynamics (PK-PD) problems, and popular collaborative filtering benchmarks (MovieLens datasets). In all the experiments on real data, the performance of weighted OKL is compared with the following methods:\n• Independent single-task learning: corresponds to fixing the output kernel as L = I instead of optimizing it, thus learning each task independently of the others.\n• Pooled single-task learning: corresponds to fixing the output kernel as L = eeT , thus assuming that all the tasks are the same.\n• Regularized Matrix Factorization (RMF): corresponds to fixing the input kernel as the Kronecker delta kernel, so that K = I.\nAll the experiments have been run in a MATLAB environment with an Intel i5 CPU 2.4 GHz, 4 GB RAM."
    }, {
      "heading" : "4.1 Reconstruction and denoising of multiple signals",
      "text" : "In order to analyze the dependence of the computation time on the rank bound parameter p of the proposed OKL method, we conducted some controlled experiments on synthetic data. The experiments show both the computational and the potential predictive advantage induced by the hard rank constraint. First of all, we generated 50 independent realizations Zk, (k = 1, . . . , 50) of a Gaussian Process on the interval [−1, 1] of the real line with zero-mean and covariance function\ncov [(Zk)x1 , (Zk)x2 ] = exp(−10|x1 − x2|).\nThen, we generated m = 200 new processes Uj as\nUj = 50∑ k=1 BjkZk,\nwhere the mixing coefficients Bjk are independently drawn from a uniform distribution on the interval [0, 1]. Output data yij have been generated by sampling the processes Uj in correspondence with 100 points in the interval [−1, 1] randomly drawn from a uniform grid of 200 points, and corrupting them by adding a zero-mean Gaussian noise with a signal to noise ratio of 1:1. For each process Uj , only 70 out of the 100 inputs have been used for training, while the remaining 30 are used for tuning the regularization parameter λ.\nThe input kernel for OKL is the same as the covariance function of the processes Zk. Performances are measured by the reconstruction MSE (mean squared error), which is computable since we have also access to the generated noncorrupted signals. Figure 1 reports the MSE (left panel) and the computation time needed to train OKL over a whole range of values of the regularization parameter λ (right panel), both as a function of the parameter p. Observe that the training time is roughly increasing with p since matrices of higher dimension are involved in the computation.\nThe best performance (in terms of MSE) is observed in correspondence with an intermediate value of the rank bound parameter (the vertical line corresponds to p = 32). Hence, the best rank is considerably lower than the “true rank” of the model used to generate the non-corrupted data (namely 50). A mismatch between the two is to be expected for finite and noisy samples. Conditions under which the rank of the original model can be recovered will depend on the\nsample size, the noise level, and the criteria used to choose the regularization parameter. It would be interesting to determine such conditions, a problem that we leave to future investigations."
    }, {
      "heading" : "4.2 Pharmacological data",
      "text" : "Reconstructing response curves in multiple subjects from sparse sets of individual measurements is a typical problem in pharmacology. The curves are generally expected to exhibit similar shapes but, on the same time, considerable inter-subject variability.\nThe Study 810 dataset [18, 26] has been obtained from a multicentric clinical trial (Study 810) for testing the efficacy of paroxetine (an antidepressant drug). The dataset contains time profiles of the so-called Hamilton Depression Rating Scale (HAMD) score for several patients suffering from major depressive disorders. The HAMD is an index obtained by processing a multiple choice questionnaire, that is used to measure the severity of a patient’s major depression. The patients under study were either treated with placebo or administered paroxetine at two different doses. The HAMD score was evaluated at several visits, planned for each patient at weeks 0,1,2,3,4,6,and 8. The drug is considered effective if a significant decreasing in the HAMD over the weeks is observed in the patients under treatment. Due to frequent dropouts (patients abandoning the study before its completion), several of the scores are missing, especially in the last weeks. Patients with missing scores cannot be simply removed from the dataset, since dropouts are highly correlated with non-decreasing of the HAMD score, and their removal would bias the efficacy assessment. Reconstructing the missing scores is a multi-task learning problem where each patient corresponds to a task, inputs are the time instants, and outputs are the scores. A full-rank (p = m) weighted OKL method has been applied, by modeling the HAMD score time profiles as piece-wise linear functions. This can be done by simply using a linear spline input kernel:\nK(t1, t2) = 1 + min{t1, t2}.\nThe overall dataset contains 2855 scores for 494 patients. Following the setup of [13], we extracted a test set containing 1012 scores, including all the scores taken after the third week for a subset of 450 randomly chosen patients. The remaining 1843 examples are further divided into a validation set containing 553 (about 30%) examples, and a training set containing the remaining 1290 examples (about 70%). The random training/validation selection is repeated 50 times, and each time the RMSE on both the validation and the test set is computed. The regularization parameter is chosen so as to minimize the average validation error. Table 1 reports the average and standard deviation of the test RMSE obtained by using OKL, a nuclear norm regularized lowrank matrix approximation method (RMF), the pooled, and the independent baselines, showing a clear advantage of the OKL multi-task approach. The\nnumerical rank of the best found output kernel is 7. Training over a whole regularization path took about 36 seconds in the average.\nThe PK-PD 27 dataset [29, 34] contains xenobiotics concentration time profiles for 27 human subjects, with samples taken at {0.5, 1, 1.5, 2, 4, 7, 12, 24} hours after a drug administration. The goal is to reconstruct the continuous-time response curves over the non-negative real time semiline, a multi-task learning problem where the tasks are the concentration time profiles for each subject, and the inputs are the time instants. We apply the weighted OKL method described in this paper with full rank (p = m), as well as RMF, the independent, and the pooled baselines. The input kernel is chosen as\nK(t1, t2) = t1t2W (h(t1), h(t2)),\nwhere W is the cubic spline kernel\nW (x1, x2) = x1x2 min{x1, x2} 2 − (min{x1, x2}) 3 3 ,\nand h is a simple transformation designed to obtain an asymptotic decay to zero of the response curve:\nh(t) = (1 + t)−1.\nThe kernel is designed so as to incorporate the available prior knowledge about the typical shape of a concentration response curve, which has to be smooth, with zero initial condition, and asymptotically decaying to zero. In order to simulate a realistic sparse sampling scenario, we follow the approach of [31], where only 3 measurements per subject (out of the 8 available) are randomly selected for training. The remaining samples are used for test. The selection is repeated 100 times, and the results are averaged. Table 2 reports the values of average RMSE in correspondence with the best value of λ, again showing an advantage of OKL over the other methods. Figure 2 reports the average RMSE as a function of the regularization parameter for the different method. Figure 3 reports the average training time of OKL as a function of the regularization parameter. The numerical rank of the best found output kernel is 27 (therefore, in this case we get a full rank solution). Training OKL over a whole regularization path took about 1.5 seconds in the average."
    }, {
      "heading" : "4.3 Collaborative filtering (MovieLens) data",
      "text" : "The MovieLens datasets 1 are popular collaborative filtering benchmarks, containing collections of ratings in the range {1, . . . , 5} assigned by several users to a set of movies. The goal is to learn the preferences of each user for all the movies. This can be interpreted as a multi-task learning problem, where each task is the preference function of one of the users. Currently, three datasets of different sizes are available, see Table 3. In addition to the ratings, the datasets contain additional metadata associated with the movies (e.g. genre and title), the users (e.g. gender, age, occupation) or the ratings themselves (timestamp, tags).\nThe weighted OKL method described in this paper has been applied to the three MovieLens datasets. The input kernel uses the movie’s metadata, while the similarity between the users is learned automatically from the data. Although the framework allows to incorporate any type of movie metadata, only the Id and the genre (present in all three datasets) have been used for simplicity. The input kernel has been designed as\nK(x1, x2) = δK(x id 1 , x id 2 ) + exp (−dH(x g 1, x g 2)) ,\nwhere δK is the Kronecker delta kernel (non-zero only when the movie Ids are equal), xg1, x g 2 are binary vectors encoding the genre metadata, and dH is the normalized Hamming distance. It can be easily shown that K is a valid positive semidefinite kernel. In these problems, keeping the δK kernel part is important, since it allows to treat two distinct movies with identical metadata as different.\nLearning performance are evaluated using both the root mean squared error (RMSE), and the normalized mean absolute error (NMAE). The latter is obtained by normalizing the mean absolute error (MAE) by a factor that depends on the range of the ratings, that is NMAE = MAE/(rmax − rmin), see\n1http://www.grouplens.org/\ne.g. [17]. For the MovieLens datasets, we have rmin = 1 and rmax = 5, so that NMAE = 0.25 ·MAE. For MovieLens100K and MovieLens10M, performance are evaluated on the test sets ra and rb provided with the datasets. The dataset MovieLens1M does not come with predefined test sets, therefore we also extracted a random test set containing about the 50% of the ratings for each user, a setup adopted in [22,45]. The regularization parameter is tuned automatically by minimizing over a broad range the performance measure (RMSE or NMAE) on a validation set containing 25% of the non-test examples for each user. Only the remaining 75% are used for training. The results are summarized in Table 4. In all the experiments, we use raw data without any normalization, and the rank of the output kernel has been limited to p = 5. The rank constraint turned out to be active for all the optimal kernels. The multi-task OKL method systematically outperforms RMF, as well as the two single-task baselines. Other recent results on these datasets under various experimental settings can be found, for example, in [1, 10,22,25,33,45].\nTable 4: MovieLens datasets: test RMSE (above) and NMAE (below) for different dataset splittings for weighted OKL, RMF, the pooled and the independent baselines.\nTest Pooled Independent RMF OKL\nMovieLens100K\nra 1.0371 1.0605 1.0007 0.9751 0.2087 0.2147 0.1949 0.1906 rb 1.0423 1.0809 1.0296 0.9958 0.2099 0.2181 0.2019 0.1942 50% 1.0209 1.0445 1.0300 0.9557 0.2043 0.2109 0.1993 0.1893\nMovieLens1M\n50% 0.9811 1.0297 0.9023 0.8945 0.1961 0.2070 0.1761 0.1752\nMovieLens10M\nra 0.9989 1.0344 1.6501 0.9427 0.1970 0.2063 0.2892 0.1806 rb 0.9810 1.0211 0.9296 0.9141 0.1926 0.2034 0.1806 0.1756 50% 0.9441 0.9721 0.8627 0.8501 0.1846 0.1915 0.1642 0.1624"
    }, {
      "heading" : "5 Conclusions and future developments",
      "text" : "Learning multiple tasks and simultaneously inferring the relationships between them is possible by using a kernel-based method that learns a decomposable multi-task kernel from multiple datasets. By employing a block coordinate descent strategy and iterative solvers for linear operator equations, it is possible to efficiently obtain a minimizer that yields good predictive performances. The method obviates the issue of manually specifying the similarities between the tasks. In addition, a systematic learning performance improvement with respect to single-task baselines and standard regularized low-rank matrix approximation can be observed on several datasets.\nIn the future, it would be worthwhile to extend the proposed method by using loss functions different from the the least square loss. Also, it would be interesting to extend the framework so as to exploit other types of structural knowledge about the task relationships, for instance along the lines of [4, 35]."
    }, {
      "heading" : "A Proofs",
      "text" : "Proof of Lemma 2.1\nAny optimal A ∈ R`×p for problem (4) admits a unique decomposition of the form\nA = CB + U, UBT = 0.\nBy letting L = BBT , it follows that L ∈ Sm,p+ , and we have\nKABT = KCBBT = KCL.\nIn addition, we have\n〈A,KA〉F 2 = 〈U,KU〉F 2 + 〈CTKC,L〉F 2\n≥ 〈C TKC,L〉F\n2 .\nIt follows that we can set U = 0 and A = CB, without any loss of generality.\nProof of Lemma 2.2\nLetting Θ = CL, problem (2) can be rewritten as\nmin Θ∈R`×m\n( ‖Y −KΘ‖2W\n2λ + min L∈Sm,p+ NΘ(L)\n) ,\nsubject to rg(Θ) ⊆ rg(L),\nwhere\nNΘ(L) = 〈ΘTKΘ,L†〉F\n2 +\ntr(L)\n2\nA minimizer of NΘ(L) can be expressed in closed-form:\nL = ( ΘTKΘ )1/2 ,\nso that min\nL∈Sm,p+ NΘ(L) = tr\n(( ΘTKΘ )1/2) .\nAll the constraints are satisfied provided that\nrank(Θ) = rank(L) ≤ p."
    }, {
      "heading" : "B Matrix identities",
      "text" : "We recall some identities involving the vectorization operator, the Kronecker and the Hadamard products, see e.g. [21]:\nvec (AXB) = ( BT ⊗A ) vec(X), (8)\n(A⊗B) (C⊗D) = (AC)⊗ (BD) , (9)\nvec (A B) = diag(vec (A))vec (B) . (10)\nThese identities hold whenever the sizes of the involved matrices are compatible."
    } ],
    "references" : [ {
      "title" : "A new approach to collaborative filtering: Operator estimation with spectral regularization",
      "author" : [ "J. Abernethy", "F. Bach", "T. Evgeniou", "J.-P. Vert" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2009
    }, {
      "title" : "Kernels for vector-valued functions: a review",
      "author" : [ "M.A. Alvarez", "L. Rosasco", "N.D. Lawrence" ],
      "venue" : "Foundations and Trends in Machine Learning, (3):195– 266",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A framework for learning predictive structures from multiple tasks and unlabeled data",
      "author" : [ "R.K. Ando", "T. Zhang" ],
      "venue" : "Journal of Machine Learning Research, 6:1817–1853",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Convex multi-task feature learning",
      "author" : [ "A. Argyriou", "T. Evgeniou", "M. Pontil" ],
      "venue" : "Machine Learning, 73(3):243–272",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "A spectral regularization framework for multi-task structure learning",
      "author" : [ "A. Argyriou", "C.A. Micchelli", "M. Pontil", "Y. Ying" ],
      "venue" : "J. C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 25–32. MIT Press, Cambridge, MA, USA",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Task clustering and gating for Bayesian multitask learning",
      "author" : [ "B. Bakker", "T. Heskes" ],
      "venue" : "Journal of Machine Learning Research, 4:83–99",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Multi-task preference learning with an application to hearing aid personalization",
      "author" : [ "A. Birlutiu", "P. Groot", "T. Heskes" ],
      "venue" : "Neurocomputing, 73:1177–1185",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Multi-task Gaussian process prediction",
      "author" : [ "E. Bonilla", "K.M. Chai", "C. Williams" ],
      "venue" : "J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems, pages 153–160. MIT Press, Cambridge, MA",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Multitask learning",
      "author" : [ "R. Caruana" ],
      "venue" : "Machine Learning, 28:41–75",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Collaborative prediction using ensembles of maximum margin matrix factorizations",
      "author" : [ "D. DeCoste" ],
      "venue" : "Proceedings of the 23rd international conference on Machine learning, ICML ’06, pages 249–256, New York, NY, USA",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Learning low-rank output kernels",
      "author" : [ "F. Dinuzzo", "K. Fukumizu" ],
      "venue" : "Journal of Machine Learning Research - Proceedings Track, 20:181–196",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Learning output kernels with block coordinate descent",
      "author" : [ "F. Dinuzzo", "C.S. Ong", "P. Gehler", "G. Pillonetto" ],
      "venue" : "Proceedings of the 28th Annual International Conference on Machine Learning, Bellevue, WA, USA",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Client-server multi-task learning from distributed datasets",
      "author" : [ "F. Dinuzzo", "G. Pillonetto", "G. De Nicolao" ],
      "venue" : "IEEE Transactions on Neural Networks, 22(2):290–303",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "The representer theorem for Hilbert spaces: a necessary and sufficient condition",
      "author" : [ "F. Dinuzzo", "B. Schölkopf" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2012
    }, {
      "title" : "Learning multiple tasks with kernel methods",
      "author" : [ "T. Evgeniou", "C.A. Micchelli", "M. Pontil" ],
      "venue" : "Journal of Machine Learning Research, 6:615–637",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "A rank minimization heuristic with application to minimum order system approximation",
      "author" : [ "M. Fazel", "H. Hindi", "S. Boyd" ],
      "venue" : "In Proceedings of the American Control Conference,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2001
    }, {
      "title" : "Eigentaste: A constant time collaborative filtering algorithm",
      "author" : [ "K.Y. Goldberg", "T. Roeder", "D. Gupta", "C. Perkins" ],
      "venue" : "Information Retrieval, 4(2):133–151",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Modelling placebo response in depression trials using a longitudinal model with informative dropout",
      "author" : [ "R. Gomeni", "A. Lavergne", "E. Merlo-Pich" ],
      "venue" : "European Journal of Pharmaceutical Sciences, 36(1):4–10",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Empirical Bayes for learning to learn",
      "author" : [ "T. Heskes" ],
      "venue" : "Proceedings of ICML, pages 367–374. Morgan Kaufmann",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Methods of conjugate gradients for solving linear systems",
      "author" : [ "M.R. Hestenes", "E. Stiefel" ],
      "venue" : "Journal Of Research Of The National Bureau Of Standards, 49(6):409–436",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1952
    }, {
      "title" : "Topics in Matrix Analysis",
      "author" : [ "R.A. Horn", "C.R. Johnson" ],
      "venue" : "Cambridge University Press",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "Sulovský. A simple algorithm for nuclear norm regularized problems",
      "author" : [ "M.M. Jaggi" ],
      "venue" : "Proceedings of the 27th International Conference on Machine Learning",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2010
    }, {
      "title" : "Conic programming for multitask learning",
      "author" : [ "T. Kato", "H. Kashima", "M. Sugiyama", "K. Asai" ],
      "venue" : "Knowledge and Data Engineering, IEEE Transactions on, 22(7):957 –968",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Some results on Tchebycheffian spline functions",
      "author" : [ "G. Kimeldorf", "G. Wahba" ],
      "venue" : "Journal of Mathematical Analysis and Applications, 33(1):82–95",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1971
    }, {
      "title" : "Non-linear matrix factorization with Gaussian processes",
      "author" : [ "N.D. Lawrence", "R. Urtasun" ],
      "venue" : "Proceedings of the 26th International Conference on Machine Learning,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2009
    }, {
      "title" : "Model-based approach and signal detection theory to evaluate the performance of recruitment centers in clinical trials with antidepressant drugs",
      "author" : [ "E. Merlo-Pich", "R. Gomeni" ],
      "venue" : "Clinical Pharmacology and Therapeutics,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2008
    }, {
      "title" : "On learning vector-valued functions",
      "author" : [ "C.A. Micchelli", "M. Pontil" ],
      "venue" : "Neural Computation, 17:177–204",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Invexity and optimization",
      "author" : [ "S.K. Mishra", "G. Giorgi" ],
      "venue" : "Nonconvex Optimization and Its Applications. Springer, Dordrecht",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Nonparametric identification of population models via Gaussian processes",
      "author" : [ "M. Neve", "G. De Nicolao", "L. Marchesi" ],
      "venue" : "Automatica, 43(7):1134–1144",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "A survey on transfer learning",
      "author" : [ "S.J. Pan", "Q. Yang" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering, 22(10):1345 –1359",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Bayesian online multitask learning of Gaussian processes",
      "author" : [ "G. Pillonetto", "F. Dinuzzo", "G. De Nicolao" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(2):193–205",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Multi-task compressive sensing with Dirichlet process priors",
      "author" : [ "Y. Qi", "D. Liu", "D. Dunson", "L. Carin" ],
      "venue" : "Andrew McCallum and Sam Roweis, editors, Proceedings of the 25th Annual International Conference on Machine Learning ",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Fast maximum margin matrix factorization for collaborative prediction",
      "author" : [ "J.D.M. Rennie", "N. Srebro" ],
      "venue" : "In Proceedings of the 22nd International Conference on Machine Learning, pages 713–719. ACM",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Comparison of the Bailer and Yeh methods using real data",
      "author" : [ "M. Rocchetti", "I. Poggesi" ],
      "venue" : "L. Aarons et al., editor, The population approach: Measuring and managing variability in response, concentration and dose, pages 385–390, Brussels, Belgium",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Exploiting unrelated tasks in multi-task learning",
      "author" : [ "B. Romera-Paredes", "A. Argyriou", "N. Berthouze", "M. Pontil" ],
      "venue" : "Journal of Machine Learning Research - Proceedings Track, 22:951–959",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Iterative Methods for Sparse Linear Systems",
      "author" : [ "Y. Saad" ],
      "venue" : "Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 2nd edition",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems",
      "author" : [ "Y. Saad", "M.H. Schultz" ],
      "venue" : "SIAM Journal on Scientific and Statistical Computing,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 1986
    }, {
      "title" : "Online learning of multiple tasks and their relationships",
      "author" : [ "A. Saha", "P. Rai", "H. Daumé III", "S. Venkatasubramanian" ],
      "venue" : "AISTATS, Ft. Lauderdale, Florida",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Learning with Kernels: Support Vector Machines",
      "author" : [ "B. Schölkopf", "A.J. Smola" ],
      "venue" : "Regularization, Optimization, and Beyond. (Adaptive Computation and Machine Learning). MIT Press",
      "citeRegEx" : "39",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Learning Gaussian process kernels via hierarchical Bayes",
      "author" : [ "A. Schwaighofer", "V. Tresp", "K. Yu" ],
      "venue" : "Advances in Neural Information Processing Systems, volume 17, pages 1209–1216",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Algorithms for Linear-quadratic Optimization",
      "author" : [ "V. Sima" ],
      "venue" : "Marcel Dekker, New York",
      "citeRegEx" : "41",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Weighted low-rank approximations",
      "author" : [ "N. Srebro", "T. Jaakkola" ],
      "venue" : "In 20th International Conference on Machine Learning, pages 720–727. AAAI Press",
      "citeRegEx" : "42",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Maximum-margin matrix factorization",
      "author" : [ "N. Srebro", "J.D.M. Rennie", "T.S. Jaakkola" ],
      "venue" : "L. K. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems 17, pages 1329–1336. MIT Press, Cambridge, MA",
      "citeRegEx" : "43",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "editors",
      "author" : [ "S. Thrun", "L.Y. Pratt" ],
      "venue" : "Learning To Learn. Kluwer Academic Publishers, Boston, MA",
      "citeRegEx" : "44",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "An accelerated proximal gradient algorithm for nuclear norm regularized least squares problems",
      "author" : [ "K Toh", "S. Yun" ],
      "venue" : "Optimization Online",
      "citeRegEx" : "45",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Shift-invariant grouped multitask learning for gaussian processes",
      "author" : [ "Y. Wang", "R. Khardon", "P. Protopapas" ],
      "venue" : "ECML/PKDD (3), pages 418–434",
      "citeRegEx" : "46",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Inferring latent task structure for multitask learning by multiple kernel learning",
      "author" : [ "C. Widmer", "N. Toussaint", "Y. Altun", "G. Rätsch" ],
      "venue" : "BMC bioinformatics, 11(Suppl 8):S5",
      "citeRegEx" : "47",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Multi-task learning for classification with Dirichlet process priors",
      "author" : [ "Y. Xue", "X. Liao", "L. Carin", "B. Krishnapuram" ],
      "venue" : "Journal of Machine Learning Research, 8:35–63",
      "citeRegEx" : "48",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Learning Gaussian processes from multiple tasks",
      "author" : [ "K. Yu", "V. Tresp", "A. Schwaighofer" ],
      "venue" : "Proceedings of the 22th Annual international conference on Machine learning ",
      "citeRegEx" : "49",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Robust multi-task learning with t-processes",
      "author" : [ "S. Yu", "V. Tresp", "K. Yu" ],
      "venue" : "Proceedings of the 24th Annual international conference on Machine learning ",
      "citeRegEx" : "50",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Flexible latent variable models for multi-task learning",
      "author" : [ "J. Zhang", "Z. Ghahramani", "Y. Yang" ],
      "venue" : "Machine Learning, 73(3):221–242",
      "citeRegEx" : "51",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "A convex formulation for learning task relationships in multi-task learning",
      "author" : [ "Y. Zhang", "D.-Y. Yeung" ],
      "venue" : "Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence (UAI), pages 733–442, Catalina Island, CA, USA",
      "citeRegEx" : "52",
      "shortCiteRegEx" : null,
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "The themes of transfer learning, multi-task learning or “learning to learn” [9, 19, 44] have attracted considerable attention in the literature, see [30] for a recent survey.",
      "startOffset" : 76,
      "endOffset" : 87
    }, {
      "referenceID" : 18,
      "context" : "The themes of transfer learning, multi-task learning or “learning to learn” [9, 19, 44] have attracted considerable attention in the literature, see [30] for a recent survey.",
      "startOffset" : 76,
      "endOffset" : 87
    }, {
      "referenceID" : 43,
      "context" : "The themes of transfer learning, multi-task learning or “learning to learn” [9, 19, 44] have attracted considerable attention in the literature, see [30] for a recent survey.",
      "startOffset" : 76,
      "endOffset" : 87
    }, {
      "referenceID" : 29,
      "context" : "The themes of transfer learning, multi-task learning or “learning to learn” [9, 19, 44] have attracted considerable attention in the literature, see [30] for a recent survey.",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 8,
      "context" : "This can be done by employing multi-layer neural networks where the hidden layer is shared among the tasks [9], or also within a convex regularization framework [4].",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 3,
      "context" : "This can be done by employing multi-layer neural networks where the hidden layer is shared among the tasks [9], or also within a convex regularization framework [4].",
      "startOffset" : 161,
      "endOffset" : 164
    }, {
      "referenceID" : 6,
      "context" : "Task relationships can be also modeled within the framework of Gaussian Processes estimation [7, 8, 31, 40, 46, 49] by designing a joint covariance function.",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 7,
      "context" : "Task relationships can be also modeled within the framework of Gaussian Processes estimation [7, 8, 31, 40, 46, 49] by designing a joint covariance function.",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 30,
      "context" : "Task relationships can be also modeled within the framework of Gaussian Processes estimation [7, 8, 31, 40, 46, 49] by designing a joint covariance function.",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 39,
      "context" : "Task relationships can be also modeled within the framework of Gaussian Processes estimation [7, 8, 31, 40, 46, 49] by designing a joint covariance function.",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 45,
      "context" : "Task relationships can be also modeled within the framework of Gaussian Processes estimation [7, 8, 31, 40, 46, 49] by designing a joint covariance function.",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 48,
      "context" : "Task relationships can be also modeled within the framework of Gaussian Processes estimation [7, 8, 31, 40, 46, 49] by designing a joint covariance function.",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 2,
      "context" : "A variety of other models have been proposed to represent and exploit inter-task relationships [3, 23,32,48,50,51].",
      "startOffset" : 95,
      "endOffset" : 114
    }, {
      "referenceID" : 22,
      "context" : "A variety of other models have been proposed to represent and exploit inter-task relationships [3, 23,32,48,50,51].",
      "startOffset" : 95,
      "endOffset" : 114
    }, {
      "referenceID" : 31,
      "context" : "A variety of other models have been proposed to represent and exploit inter-task relationships [3, 23,32,48,50,51].",
      "startOffset" : 95,
      "endOffset" : 114
    }, {
      "referenceID" : 47,
      "context" : "A variety of other models have been proposed to represent and exploit inter-task relationships [3, 23,32,48,50,51].",
      "startOffset" : 95,
      "endOffset" : 114
    }, {
      "referenceID" : 49,
      "context" : "A variety of other models have been proposed to represent and exploit inter-task relationships [3, 23,32,48,50,51].",
      "startOffset" : 95,
      "endOffset" : 114
    }, {
      "referenceID" : 50,
      "context" : "A variety of other models have been proposed to represent and exploit inter-task relationships [3, 23,32,48,50,51].",
      "startOffset" : 95,
      "endOffset" : 114
    }, {
      "referenceID" : 5,
      "context" : "One possibility is to assume that the tasks can be clustered into homogeneous groups and try to learn such clustering from the data [6].",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 4,
      "context" : "Optimization-based approaches that jointly infer the task parameters and the inter-task relationships in the form of a similarity matrix include the spectral regularization approach of [5] and the method of [52] based on convex optimization.",
      "startOffset" : 185,
      "endOffset" : 188
    }, {
      "referenceID" : 51,
      "context" : "Optimization-based approaches that jointly infer the task parameters and the inter-task relationships in the form of a similarity matrix include the spectral regularization approach of [5] and the method of [52] based on convex optimization.",
      "startOffset" : 207,
      "endOffset" : 211
    }, {
      "referenceID" : 37,
      "context" : "An online method has been also proposed recently to learn multiple linear classifiers as well as a task relationship matrix [38].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 38,
      "context" : "Regularized kernel methods [39] have been employed successfully in a variety of single-task learning problems.",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 14,
      "context" : "Their extension to the multi-task setting [15] calls for the design of suitable operator-valued kernels that model similarities of both inputs and tasks.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 1,
      "context" : "Some classes of operator-valued kernels have been recently reviewed in [2].",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 46,
      "context" : "A possible way to address this problem consists in learning a linear combination of task-specific kernels [47], within the framework of multiple kernel learning (MKL).",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 11,
      "context" : "Recently, a class of output kernel learning (OKL) methods [12, 13] has been introduced in the context of multi-output learning problems (such as vectorial regression, multi-class and multi-label classification) to automatically synthesize a decomposable matrixvalued kernel that encodes the relationships between the output components.",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 12,
      "context" : "Recently, a class of output kernel learning (OKL) methods [12, 13] has been introduced in the context of multi-output learning problems (such as vectorial regression, multi-class and multi-label classification) to automatically synthesize a decomposable matrixvalued kernel that encodes the relationships between the output components.",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 10,
      "context" : "To this end, we extend a technique for learning low-rank output kernels proposed in [11] to the multi-task setting.",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 41,
      "context" : "[42], since existing optimization techniques based on eigendecompositions do not carry over to the weighted case.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 51,
      "context" : "Similarly to [52], we learn multiple tasks as well as their relationships by solving a joint optimization problem.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 51,
      "context" : "However, differently from [52] and [38], that learn multiple linear functions by convex optimization, we learn multiple non-linear functions by solving a non-convex optimization problem.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 37,
      "context" : "However, differently from [52] and [38], that learn multiple linear functions by convex optimization, we learn multiple non-linear functions by solving a non-convex optimization problem.",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 7,
      "context" : "Our method is also related to the technique derived in [8] in the context of Bayesian estimation of Gaussian Processes, that allows to learn a similarity (covariance) matrix between the tasks.",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 7,
      "context" : "While [8] aims at optimizing a marginal likelihood type functional, our method is based on the minimization of a functional with trace norm regularization plus rank constraint.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 7,
      "context" : "In [8], the authors adopt a general purpose gradient-descent solver to optimize their objective functional, whereas in this paper we develop a novel optimization strategy that is specifically designed to solve the proposed OKL optimization problem.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 7,
      "context" : "Differently from [8], our method is able to deal with the case of incomplete sampling, and automatically encourages low-rank solutions without introducing relaxations of the original problem.",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 26,
      "context" : "For more details about RKHS of vector-valued functions, see [27].",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 13,
      "context" : "In view of the representer theorem [14, 24], the minimization problem with respect to g admits a solution of the form",
      "startOffset" : 35,
      "endOffset" : 43
    }, {
      "referenceID" : 23,
      "context" : "In view of the representer theorem [14, 24], the minimization problem with respect to g admits a solution of the form",
      "startOffset" : 35,
      "endOffset" : 43
    }, {
      "referenceID" : 15,
      "context" : "[16].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "In addition, for p = m it is an invex function [28] in the interior of the feasible set, meaning that every stationary point is a global minimizer.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 32,
      "context" : "The related MMMF (maximum-margin matrix factorization) technique [33,43] would also correspond to the case K = I, but with hinge-type (SVM) losses instead of the square loss.",
      "startOffset" : 65,
      "endOffset" : 72
    }, {
      "referenceID" : 42,
      "context" : "The related MMMF (maximum-margin matrix factorization) technique [33,43] would also correspond to the case K = I, but with hinge-type (SVM) losses instead of the square loss.",
      "startOffset" : 65,
      "endOffset" : 72
    }, {
      "referenceID" : 40,
      "context" : "[41].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 36,
      "context" : "A first possible way to attack the problem is trying to directly obtain a solution of the non-symmetric operator equation (5) by means of iterative methods that can handle non-symmetric equations, such as the generalized minimal residual method (GMRES) [37].",
      "startOffset" : 253,
      "endOffset" : 257
    }, {
      "referenceID" : 19,
      "context" : "The alternative is to introduce a change of variable to make the problem symmetric, and then apply a preconditioned conjugate gradient (CG) algorithm [20] on the new linear equation.",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 35,
      "context" : "[36].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 0,
      "context" : "where the mixing coefficients Bjk are independently drawn from a uniform distribution on the interval [0, 1].",
      "startOffset" : 102,
      "endOffset" : 108
    }, {
      "referenceID" : 17,
      "context" : "The Study 810 dataset [18, 26] has been obtained from a multicentric clinical trial (Study 810) for testing the efficacy of paroxetine (an antidepressant drug).",
      "startOffset" : 22,
      "endOffset" : 30
    }, {
      "referenceID" : 25,
      "context" : "The Study 810 dataset [18, 26] has been obtained from a multicentric clinical trial (Study 810) for testing the efficacy of paroxetine (an antidepressant drug).",
      "startOffset" : 22,
      "endOffset" : 30
    }, {
      "referenceID" : 12,
      "context" : "Following the setup of [13], we extracted a test set containing 1012 scores, including all the scores taken after the third week for a subset of 450 randomly chosen patients.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 28,
      "context" : "The PK-PD 27 dataset [29, 34] contains xenobiotics concentration time profiles for 27 human subjects, with samples taken at {0.",
      "startOffset" : 21,
      "endOffset" : 29
    }, {
      "referenceID" : 33,
      "context" : "The PK-PD 27 dataset [29, 34] contains xenobiotics concentration time profiles for 27 human subjects, with samples taken at {0.",
      "startOffset" : 21,
      "endOffset" : 29
    }, {
      "referenceID" : 30,
      "context" : "In order to simulate a realistic sparse sampling scenario, we follow the approach of [31], where only 3 measurements per subject (out of the 8 available) are randomly selected for training.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 16,
      "context" : "[17].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "The dataset MovieLens1M does not come with predefined test sets, therefore we also extracted a random test set containing about the 50% of the ratings for each user, a setup adopted in [22,45].",
      "startOffset" : 185,
      "endOffset" : 192
    }, {
      "referenceID" : 44,
      "context" : "The dataset MovieLens1M does not come with predefined test sets, therefore we also extracted a random test set containing about the 50% of the ratings for each user, a setup adopted in [22,45].",
      "startOffset" : 185,
      "endOffset" : 192
    }, {
      "referenceID" : 0,
      "context" : "Other recent results on these datasets under various experimental settings can be found, for example, in [1, 10,22,25,33,45].",
      "startOffset" : 105,
      "endOffset" : 124
    }, {
      "referenceID" : 9,
      "context" : "Other recent results on these datasets under various experimental settings can be found, for example, in [1, 10,22,25,33,45].",
      "startOffset" : 105,
      "endOffset" : 124
    }, {
      "referenceID" : 21,
      "context" : "Other recent results on these datasets under various experimental settings can be found, for example, in [1, 10,22,25,33,45].",
      "startOffset" : 105,
      "endOffset" : 124
    }, {
      "referenceID" : 24,
      "context" : "Other recent results on these datasets under various experimental settings can be found, for example, in [1, 10,22,25,33,45].",
      "startOffset" : 105,
      "endOffset" : 124
    }, {
      "referenceID" : 32,
      "context" : "Other recent results on these datasets under various experimental settings can be found, for example, in [1, 10,22,25,33,45].",
      "startOffset" : 105,
      "endOffset" : 124
    }, {
      "referenceID" : 44,
      "context" : "Other recent results on these datasets under various experimental settings can be found, for example, in [1, 10,22,25,33,45].",
      "startOffset" : 105,
      "endOffset" : 124
    }, {
      "referenceID" : 3,
      "context" : "Also, it would be interesting to extend the framework so as to exploit other types of structural knowledge about the task relationships, for instance along the lines of [4, 35].",
      "startOffset" : 169,
      "endOffset" : 176
    }, {
      "referenceID" : 34,
      "context" : "Also, it would be interesting to extend the framework so as to exploit other types of structural knowledge about the task relationships, for instance along the lines of [4, 35].",
      "startOffset" : 169,
      "endOffset" : 176
    }, {
      "referenceID" : 20,
      "context" : "[21]:",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2013,
    "abstractText" : "Simultaneously solving multiple related learning tasks is beneficial under a variety of circumstances, but the prior knowledge necessary to correctly model task relationships is rarely available in practice. In this paper, we develop a novel kernel-based multi-task learning technique that automatically reveals structural inter-task relationships. Building over the framework of output kernel learning (OKL), we introduce a method that jointly learns multiple functions and a low-rank multi-task kernel by solving a non-convex regularization problem. Optimization is carried out via a block coordinate descent strategy, where each subproblem is solved using suitable conjugate gradient (CG) type iterative methods for linear operator equations. The effectiveness of the proposed approach is demonstrated on pharmacological and collaborative filtering data.",
    "creator" : "LaTeX with hyperref package"
  }
}