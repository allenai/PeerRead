{
  "name" : "1505.08153.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "mohsen.fayyaz89@gmail.com,", "hajizadeh.m@gmail.com).", "sabokro@gmail.com).", "mahfathy@iust.ac.ir)." ],
    "sections" : [ {
      "heading" : null,
      "text" : "of applications and have improved people authentication. Signature verification is one of the most common biometric methods with techniques that employ various specifications of a signature. Recently, deep learning has achieved great success in many fields, such as image, sounds and text processing. In this paper, deep learning method has been used for feature extraction and feature selection, which has enormous impact on the accuracy of signature verification. This paper presents a method based on self-taught learning, in which a sparse autoencoder attempts to learn discriminative features of signatures from a large unlabeled signature dataset. Then, the features learned are employed to present users’ signatures by creating a model for each user based on user genuine signatures. Finally, users’ signatures are classified using a one-class classifier. The proposed method is independent on signature datasets thanks to self-taught learning. The features have been learned from 17,500 signatures (ATVS dataset) and verification process of the proposed system is evaluated on SVC2004 and SUSIG signature datasets, which contain genuine and skilled forgery signatures. The experimental results indicate significant error reduction and accuracy enhancement in comparison with state of the art counterparts.\nIndex Terms—Feature Representation, Self-Taught Learning, Sparse Linear Autoencoder, Online Signature Verification, OneClass Classifier, Biometric Verification.\nI. INTRODUCTION\nEOPLE Authentication, has been known as an intrinsic\npart of social life. Recent years have seen a growing interest toward personal identity authentication. Increasing\nsecurity requirements have placed biometrics at the center of a much attention. Biometric technology has become an\nimportant field in verifying people and has been used in\npeople identification and authentication. The term biometrics\nrefers to individual recognition based on a person’s\ndistinguishing characteristics [1]. In biometric systems,\nattributes do not have the disadvantages of token-based approaches that can be lost or stolen or knowledge-based\napproaches that can be forgotten. Therefore, biometric authentication systems have been used in a wide range of\nM. Fayyaz and M. Hajizadeh are M.S. students at Malek-Ashtar University of Technology, Tehran, Iran (email: mohsen.fayyaz89@gmail.com, hajizadeh.m@gmail.com). M. Sabokrou is Ph.D. student at Malek-Ashtar University of Technology, Tehran, Iran (email: sabokro@gmail.com).\nM. Fathy is with School of Computer Engineering, Iran University of Science and Technology, Tehran, Iran (email: mahfathy@iust.ac.ir).\ncontrol systems, etc.\nPeople recognition systems based on biometrics have two\nmain categories [2]:\n Physiological biometrics are based on recognizing\nsome physical part of the human body, such as\nfingerprint, retina, hand scan, etc.\n Behavioral biometrics are based on measuring some\ncharacteristics and behaviors of the human, such as\nhandwritten signature, voice, etc.\nRecognition refers to two different tasks: identification and\nverification. Identification specifies which user provides a\ngiven biometric parameter among a set of known users. Therefore, the input used for identification only contains\ngenuine data. However, verification determines if the given\nbiometric parameter is provided by a specific known user or is a forgery. Forgery consist of three types:\n Random forgery: Produced with no knowledge about\nthe signature shape or signer’s name\n Simple forgery: Produced by knowing only the name\nof the signer\n Skilled forgery: Produced by looking at the original\nsignature sample\nPerson recognition has been applied by several biometric modalities, such as; fingerprint, iris, face, vein and signature\n[3]. Handwritten signature recognition is one of the most common techniques to recognize the identity of a person.\nHowever, when dealing with signatures, most of the proposed\nsystems focus on verification rather than identification because of daily usage of signature verification systems [4].\nThere are two types of signature verification: Offline (static) verification and Online (dynamic) verification. In the\noffline setting, we have the shape of the signature by capturing\nor scanning them from papers and the system must extract\nfeatures from the picture of the signature. Therefore, in offline\nverification system, input data contains x-y coordinates of\nsignatures. However, in the online setting, the system uses devices for capturing additional information while the user is\nsigning [5]. Online signatures have extra information for extraction such as time, pressure, pen up and down, azimuth,\netc.\nTwo types of features can be extracted from a signature [1]\n(Figure 1):\n Function-Features: The signature is characterized in\nterms of a time function whose values constitute the\nfeature set, such as position, velocity, pressure, etc.\nP\n Parameter-Features: The signature is characterized as\na vector of elements each representing a value of a feature. Parameters are generally classified into two\nmain categories: local and global. Local features are so-called because of their relation to each point of the\nsignature, such as height or width ratio of the stroke,\nstroke orientation, pixel density, etc. Global features are so-called because of their relation to the whole of\nthe signature and signing process, such as total time,\naverage pressure, average speed, etc.\nThe Verification approaches can be described in three\ncategories [1]:\n Template Matching: A questioned sample is matched\nagainst templates of signatures, such as Dynamic\nTime Wrapping (DTW) [4-6], Euclidian distance.\n Statistical: In this approach, distance-based classifiers\ncan be considered, such as Neural Networks [7], Hidden Markov Models (HMM) [4, 8]..\n Structural: This approach is related to structural\nrepresentations of signatures and compared through graph or tree matching techniques [9].\nIn this paper, a signature verification system has been proposed based on deep learning. The sparse linear\nautoencoder has been implemented to learn the signature\nmodel of each user by learning features based on an unsupervised self-taught method. Furthermore, one-class\nclassifier has been used for classifying test signatures.\nThis paper is organized as follows: Section II presents a brief description of related work in the field of online\nsignature verification. Section III introduces the adopted\nmethodology while section IV presents the proposed system.\nExperimental results and their comparisons have been\ndescribed in section V. Finally, section VI presents the conclusion for this paper and suggestions for future work."
    }, {
      "heading" : "II. RELATED WORK",
      "text" : "There is an extensive literature in the field of online\nsignature verification. Most recent approaches have been described in [1, 2, 10]. The process of signature verification is\nusually divided into three phases:"
    }, {
      "heading" : "A. Preprocessing",
      "text" : "The signature dataset must take some preprocesses since there is no guarantee that different signatures of one user will always be the same. Several processes have been proposed for this phase, which generally consist of smoothing, rotation and normalization.\nCubic splines can be employed for smoothing purposes to solve the jaggedness in the signatures. Signatures can become rotation-invariant by rotating each signature based on orthogonal regression (Eq.1) [5].\n\uD835̅\uDF03 = \uD835\uDC61\uD835\uDC54−1( \uD835\uDC60\uD835\uDC66\n2−\uD835\uDC60\uD835\uDC65 2+√(\uD835\uDC60\uD835\uDC66 2−\uD835\uDC60\uD835\uDC65 2)2+4∗(\uD835\uDC50\uD835\uDC5C\uD835\uDC63(\uD835\uDC65,\uD835\uDC66) 2)\n2∗\uD835\uDC50\uD835\uDC5C\uD835\uDC63(\uD835\uDC65,\uD835\uDC66) ) (1)\nWhere \uD835\uDC60\uD835\uDC65 and \uD835\uDC60\uD835\uDC66 are variance and \uD835\uDC50\uD835\uDC5C\uD835\uDC63(\uD835\uDC65, \uD835\uDC66) is covariance\nof the horizontal and vertical components.\nThe signatures of one person must have the same size for better performance. The horizontal and vertical components of the signatures can be normalized to make a standard size of signature (Eq. 2, 3) [6].\n\uD835\uDC65\uD835\uDC5B = \uD835\uDC65−min(\uD835\uDC65)\nmax(\uD835\uDC65)−min(\uD835\uDC65) ∗ 100 (2)\n\uD835\uDC66\uD835\uDC5B = \uD835\uDC66−min(\uD835\uDC66)\nmax(\uD835\uDC66)−min(\uD835\uDC66) ∗ 100 (3)\nWhere \uD835\uDC65 and \uD835\uDC66 are original and \uD835\uDC65\uD835\uDC5B and \uD835\uDC66\uD835\uDC5B denote the normalized coordinates."
    }, {
      "heading" : "B. Feature Extraction",
      "text" : "Feature selection and feature extraction play an important role in verification systems. Many studies have done in the field of feature selection to choose the best set of features for extraction. List of common features have been described in Table 1 [5].\nFurthermore, some non-common features have been described in other papers [6, 9, 11-15]. Recently, some biometric authentication systems for face, iris and fingerprint have been proposed based on deep neural networks which used autoencoders for feature extraction phase [3, 16]."
    }, {
      "heading" : "C. Classification",
      "text" : "After the feature extraction phase, the system must learn the features extracted from reference signature. For classification phase, each signature must be compared against reference signatures and the difference between features of test signature and reference signatures would be calculated. By having the distances between test and reference signatures, the system can decide to accept or reject the test signature.\nThere are different options for distance calculation such as dmin/max which is minimum/maximum distance between a signature and the patterns of the reference set, and dcentral which is the distance between a signature and the center of mass of the reference set [17]. One of the important parameter in verification system is the threshold value for accepting or rejecting a signature. Consequently, choosing the best threshold is a crucial step. There are two types of thresholds: global and local. In global threshold, the system will choose one threshold value for all users. On the other hand, for local threshold, the system must choose one threshold per user so that, this approach could lead to a better result [17].\nAs mentioned, the signature recognition problem is an abstract concept, which comprises signature identification and signature verification. In daily usage of authenticating systems such as banking systems, handwritten signature of users have been used to verify the identity of official documents. In these sorts of problems, the main goal is verifying whether a signature belongs to one identified person or not. In contrast with multi-class classifiers, the aim for one-class classifiers is distinguishing one type of class (target) from other classes (outlier). Thus, For classifying a signature as genuine or forgery, one-class classifiers have been commonly used [17] to divide the set into two categories: target and outlier (Figure 2).\nJain and Gangrade [7] proposed a system by using angle, energy and chain code features to diffrentiate the signatures.\nIn this approach, a Neural Network has been applied for classification.\nFaundez-Zanuy [4] studied four pattern recognition algorithms for online signature recognition: Vector Quantization (VQ), Nearest Neighbor, DTW and HMM. The author proposed two methods based on VQ and Nearest Neighbor.\nRashidi, et al. [5] evaluated 19 dynamic features viewpoint classification error and discrimination capability between genuine and forgery signatures. They used a modified distance of DTW for improving performance of verification phase.\nAnsari, et al. [6] presented an online signature verification system based on fuzzy modelling. The point of geometric extrema has been chossen for signature segmentation and a minimum distance alignment between samples has been made by DTW techniques. Dynamic features have been converted to a fuzzy model and a user-dependent threshold used for classification.\nBarkoula, et al. [9] studied the signatures Turning Angle Sequence (TAS), the Turning Angle Scale Space (TASS) representations, and their application to online signature verification. In the matching stage, the authors have employed a variation of the longest common sub-sequence matching technique.\nYahyatabar, et al. [11] proposed a method based on efficient features defined in persian signatures. A combination of shape based and dynamic extracted features has been applied and a SVM has been used for classification phase.\nAlhaddad, et al. [12] explored a new technique by combining back-propagation Neural Network (BPNN) and the probabilistic model. BPNN has been used for local features classification, while probabilistic model has been used to classify global features.\nMohammadi and Faez [13] proposed a method based on the correspondence between important points in the direction of wrap for the time signal provided to maximize the distinction between the genuine and forged signatures.\nNapa and Memon [14] Presented a simple and effective method for signature verification in which an online signature is represented with a discriminative feature vector derived from attributes of several histograms that can be computed in linear time. For testing phase, the authors proposed a method on finger drawn signatures on touch devices by collecting a dataset from an uncontrolled environment and over multiple sessions.\nSouza, et al. [17] proposed an off-line signature verification system, which uses a combination of five distance measurements, such as, furthest, nearest, template and central using four operations: product, mean, maximum, and minimum as a feature vector.\nFallah, et al. [18] presented a new signature verification system based on Mellin transform. The features have been extracted by Mel Frequency Cepstral Coefficient (MFCC). Neural Network with multi-layer perception architecture and linear classifier in conjuction with Principal Component Analysis (PCA) have used for classification.\nIranmanesh, et al. [19] proposed a verification system by using multi-layer perceptron (MLP) on a subset of PCA features. This approach used a feature selection method on the\ninformation that has been discarded by PCA, which significantly reduced the error rate.\nCpałka, et al. [20] explored a new method by using area partitioning of high and low speed of the signature and high and low pen’s pressure. The template for each partition has been generated and by calculating the distance between signatures and template in each partition, a fuzzy classification has been implemented to classify the signatures.\nLopez-Garcia, et al. [21] presented a signature verification system implemented on an embedded system. In this approach, a template for each user has been generated and a DTW algorithm has been used for distance calculation. Finally, the features extracted and passed through a Gaussian Mixure Model (GMM) to calculate the similarity between the test signature and the generated template.\nGruber, et al. [22] proposed a technique based on Longest Common Subsequences (LCSS) detection. Authors have used a LCSS kernel of SVM for classifying the similarity of signature time series."
    }, {
      "heading" : "III. METHODOLOGY",
      "text" : "Deep learning (Feature Learning or Representation Learning) is a new era of machine learning which aims to\nlearn the high-level features from raw data to achieve a better\nperformance in classification tasks. Deep learning is part of a field of machine learning methods based on learning\nrepresentation of data [23].\nRaw data (e.g. an image) can be represented in many ways by using diverse handcrafted features. Feature learning tries to\nlearn discriminative features autonomously which is one of its advantages. The other advantage of feature learning is that the\nfeature learning process can be completely unsupervised. One\nof the goals of deep learning is hierarchical feature extraction. For achieving that goal, feature learning tries to learn a new\nrepresentation of the input data which is the observed data and continue learning new representations of previously learned\nfeatures at each level, which are able to reconstruct the\noriginal data.\nOne of the scopes of machine learning, which plays a key\nrole in deep learning, is self-taught learning. The main\npromise of self-taught learning is using unlabeled data in supervised classification tasks [24]. The key point of such\nalgorithms is that unlabeled data are not supposed to follow the same class labels. Indeed, unlabeled data are exploited to\nteach the system recognizing patterns or relations for the\nsupervised learning task. In summary, self-taught learning learns a concise, higher-level feature representation of the raw\ndata using unlabeled data. Having a concise high level feature representation brings us an easier classification task by having\nfeatures that are more significant [24]."
    }, {
      "heading" : "A. Autoencoder",
      "text" : "One of the unsupervised learning methods is the autoencoder algorithm. Autoencoder is an unsupervised learning architecture used to pre-train deep networks. There is one kind of autoencoder algorithm, which is based on multilayer perceptron neural networks. In contrary to traditional neural networks, MLP based autoencoders are unsupervised\nlearning algorithms which try learning weights of each layer to set the output values to be equal to the inputs for the neural network (Figure 3).\nSuppose \uD835\uDC65 ∈ ℝ is the set of input features. To learn features from input features, the basic autoencoder with regularization term to prevent over-fitting, attempts reconstructing input features by minimizing following cost function (Eq. 4):\n\uD835\uDC3D(\uD835\uDC4A, \uD835\uDC4F) = argmin \uD835\uDC4A,\uD835\uDC4F\n1 \uD835\uDC5A ∑‖ℎ\uD835\uDC64,\uD835\uDC4F(\uD835\uDC65 (\uD835\uDC56)) − \uD835\uDC65(\uD835\uDC56)‖ 2\n\uD835\uDC56\n+\n\uD835\uDF06∑ ∑ (\uD835\uDC4A\uD835\uDC56,\uD835\uDC57 \uD835\uDC59 )2\uD835\uDC56,\uD835\uDC57\uD835\uDC59 (4)\nWhere \uD835\uDC4A ∈ ℝ is weight matrix mapping nodes of each layer to next layer nodes, and \uD835\uDC4F ∈ ℝ is a bias vector.\nThe cost function of autoencoder mentioned in (Eq. 4) only focuses on the differences between input and output data of autoencoder. This brings us a network with the ability of representing raw data with learned feature without any guarantee of having sparse represented features, which plays a key role in classification task. In order to learn features that are more effective and having a sparser dataset of represented features, the sparsity constraint can impose on the autoencoder network. The objective function is as follows (Eq. 5-7):\n\uD835\uDC3D\uD835\uDC46\uD835\uDC5D\uD835\uDC4E\uD835\uDC5F\uD835\uDC60\uD835\uDC52(\uD835\uDC4A, \uD835\uDC4F) = \uD835\uDC3D(\uD835\uDC4A, \uD835\uDC4F) + \uD835\uDEFD ∑ \uD835\uDC3E\uD835\uDC3F(\uD835\uDF0C||\uD835̂\uDF0C\uD835\uDC57)\uD835\uDC56 (5)\n\uD835\uDC3E\uD835\uDC3F(\uD835\uDF0C||\uD835̂\uDF0C\uD835\uDC57) = \uD835\uDF0C\uD835\uDC59\uD835\uDC5C\uD835\uDC54 \uD835\uDF0C\n\uD835̂\uDF0C\uD835\uDC57 + (1 − \uD835\uDF0C)\uD835\uDC59\uD835\uDC5C\uD835\uDC54\n1−\uD835\uDF0C 1−\uD835̂\uDF0C\uD835\uDC57 (6)\n\uD835̂\uDF0C\uD835\uDC57 = 1\n\uD835\uDC5A ∑ [\uD835\uDC4E\uD835\uDC57\n2(\uD835\uDC65(\uD835\uDC56))]\uD835\uDC56 (7)\nWhere \uD835\uDC3E\uD835\uDC3F(\uD835\uDF0C||\uD835̂\uDF0C\uD835\uDC57) is the Kullback-Leibler (KL) divergence between a Bernoulli random variable with mean \uD835\uDF0C and a Bernoulli random variable with mean \uD835̂\uDF0C\uD835\uDC57, which is the average activation of hidden unit\uD835\uDC57. The notation summary of equation 4-7 is described in Table 2.\nA sparse autoencoder model can effectively realize feature extraction and dimension reduction of the input data, which play a vital role in classification tasks [16]."
    }, {
      "heading" : "B. Convolution and Pooling",
      "text" : "Raw input data are usually stationary. It means that the statistics of randomly selected parts of the data are the same. This characteristic shows that not all the features are useful. It is obvious that having more features results in increasing the computational complexity especially in a classification task. In order to avoid high computational complexity, redundant data have been neglected by picking up random patches of raw data and convolving them. After obtaining convolved features, pooling method can be exploited in order to obtain pooled convolved features. These pooled features can be used for classification task (Figure 4)."
    }, {
      "heading" : "IV. PROPOSED SYSTEM",
      "text" : "One of the important problems in signature verification is\nchoosing features due to diverse difficulties in signature verification, such as differences between same user signatures,\ndifferent circumstances of signing, various shapes of signatures, etc. Among these, exploiting an unsupervised\nfeature learning method results in system compatibility\nimprovement with various types of signatures and automatic\nfeature selecting from signatures. The proposed signature verification system comprises three steps: Feature learning,\nOne-class classification and Verification (Figure 5).\nIn the first step, named feature learning, features are learned by the autoencoder. In this step, an unlabeled dataset, which is discretized from train and test datasets, is used based on selftaught method. In classification step, a reference model of the system is built using classified represented data from users’ reference signatures. These two steps are parts of the system training section [14]. Finally, in verification step, which is system-working section, new unknown signatures are compared against the system reference model (classified data) to be verified. There are three principal phases among described steps, which are preprocessing, feature learning using autoencoder, and classification. These phases are explained as follows:"
    }, {
      "heading" : "A. Preprocessing",
      "text" : "As mentioned, in the preprocessing phase, the first step is normalizing size of the signature. This aim can be achieved by scaling the signature size. At the next step, the mean of the data must become equal to zero for data normalization.\nSignatures data in databases are based on time, pressure, pen up/down, etc. in x/y positions. To make representation become similar to reality, points of signatures have been continued. This object achieved by using time of the points to observe the sequence of data and pen up /down to check if the pen has gone up, the point must be separated from the next one. Finally, signatures have been represented base on two layer: pressure and time (Figure 6).\nPrincipal Component Analysis (PCA) is an algorithm that reduces dimensions of signature data and can be used to significantly speed up unsupervised feature learning algorithm. Since the system is trained based on signature images, adjacent pixel values are highly correlated. Whitening can make the input less redundant, the features become less correlated with each other and the features all become the same variance. Therefore, these two algorithms have used to reduce the dimension."
    }, {
      "heading" : "B. Feature Learning using Autoencoder",
      "text" : "For learning features from signatures, a linear autoencoder with sparsity have been used. The signature has been set for input and output and autoencoder has been checked to maps input to output. This autoencoder has been designed based on gradient descent.\nUnsupervised learning algorithms have high computational cost. In order to increase performance of learning phase, raw data (large patch of a signature) has been divided into small patches and have been used in feature learning phase as input. Then learned features have been convolved with large patch. After obtaining features using convolution, mean pooling method has been exploited in order to obtain pooled convolved features. These pooled features have been used for classification."
    }, {
      "heading" : "C. Classification",
      "text" : "The significant issues of classification in this type of problems are differences between same user’s signatures,\ndiverse circumstances of signing, low amount of signature samples, and forgery signatures. For resolving such issues,\nselecting an appropriate classifier is very important.\nThe one-class classifier in the proposed system has a target class, which is class of the user whose signature is being\ncompared with input signature, and the outlier class is other\nusers’ sample signatures. As a result, the classifier must create a model of target class for each user."
    }, {
      "heading" : "V. EXPERIMENTAL RESULTS",
      "text" : "In the evaluation process of proposed approach, test signatures have been comprised by comparing their features against reference signatures. In this section, short description of benchmarks and evaluation parameters have been described. In addition, three steps of the proposed system are explained."
    }, {
      "heading" : "A. Benchmarks",
      "text" : "For evaluation of the proposed approach, three public datasets have been used which are SVC2004 [25], SUSIG [26]\nand ATVS [27, 28]. The structure of the mentioned datasets\nhave been explained as follows:\n1) SVC20041 SVC2004 is the first international signature verification competition. The aim of holding SVC2004 competition was allowing researchers to evaluate the performance of their signature verification methods based on benchmark datasets and benchmarking rules that resulted in creating a benchmark dataset named SVC2004.\nSVC2004 main database has 100 sets of signature data. SVC2004 public database, which has been released before the\ncompetition, consists of 40 signature sets. Each set includes 20\ngenuine signatures of one signature contributor and 20 skilled forgeries of at least four other contributors (Figure 7).\nIn data collection process of the signature sets, contributors\nwere asked not to use their real signatures for privacy reasons. On the other hand, made-up signatures are shortcoming of this\ndatabase, which will result in having higher variance and higher error rates. For decreasing effect of the mentioned\nproblem, contributors were reminded that, not only should\ntheir signatures have spatial consistency in signature shape but should have temporal consistency of dynamic features as well.\nContributors were asked to contribute 20 genuine signatures in two sessions in two weeks. At least four other contributors\nforged the skilled forgeries for each contributor’s signature.\nIn SVS2004 database, each signature includes a sequence of points, which contains X, Y coordinates, time and pen\nup/down, azimuth, altitude and pressure. 2) SUSIG2 Sabanci University Signature database (SUSIG) is a database of online signatures, which aim is overcoming some of the shortcomings of its contemporary databases.\nThe SUSIG database consist of two subcorpora, which are visual and blind. In both subcorpora, contributors used their real signatures for creating genuine signatures sets, which is one of this database advantages in contrary to SVC2004 database (Figure 8).\n1 Available at http://www.cse.ust.hk/svc2004/download.html 2 Available at http://biometrics.sabanciuniv.edu/susig.html\nIn blind subcorpus data collection process, collection has been done on a tablet without visual feedback. It consists of signatures of 100 contributors. First group of 30 contributors provided eight genuine signatures, while the other 70 contributors provided 10 genuine signatures each. For providing forgery signatures, forgers were shown the genuine signatures’ drawing replay several times. After training well, forgers supplied ten forgeries for each set of contributors’ genuine signatures. Additionally, there is a separate ten-person validation set with ten genuine and ten forged signatures per person.\nIn visual subcorpus data collection process, collection has been done on a tablet with a LCD, which provided visual feedback to the contributors while they were signing signatures. Visual subcorpus data were collected in two separate sessions. Each contributor has provided 20 samples of his/her signature. In this database, in the visual subcorpus, there are two types of forgery signatures: skilled forgeries and highly skilled forgeries. For providing skilled forgeries, contributors were shown the genuine signatures’ drawing like the blind subcorpus. Each forger was asked to provide five forgeries of the signature. For providing highly skilled forgeries, the replay of the reference signature shown on both a monitor in front of forgers and the LCD screen of the tablet which provided forgers the ability of tracing the reference signature signing process. Like the normal skilled forgeries, forgers have forged five highly skilled forgeries for each set of genuine signatures. In summary, 20 genuine signatures and five skilled and five highly skilled forgeries were collected for each person in the subcorpus. Additionally, there is a separate 10 person-validation set with 10 genuine and 10 forged signatures per person acquired in a single session for tuning system parameters. 3) ATVS3 All two mentioned databases (SVC2004 and SUSIG) are human made database. Although they have advantages, such as, having real signature of a human, and having real world situations for sampling, they have restrictions, which are limited amount of data, privacy issues, subdued to legal aspects. Synthetic signature databases are solution of this\n3 Available at http://atvs.ii.uam.es/databases.jsp\nproblem. They are not restricted to limitations mentioned above. However, they miss the advantage of having real world situations, and real human signature. In spite of suffering from such problems, synthetic databases have had good approaches to simulation of real signatures, which involves the effect of real situation of sampling. ATVS database is one of the synthetic databases (Figure 9).\nThe artificial samples produced by ATVS follow the pattern of the western signatures, which are left-to-right concatenated handwritten signature [27]. ATVS signature generation contains two steps: First, a master signature corresponding to a synthetic individual is produced using a generative model based on information obtained. This information has been acquired by analyzing real signatures using a spectral analysis approach and the kinematic theory of rapid human movements. Second, various samples of the same synthetic subject are created using the master signature.\nATVS has two parts, named “direct modification of the time functions” and “modification of the sigma-lognormal parameters (LN-Parameters)”.\nIn direct modification of the time functions, time sequence of the reference signature have been modified according to a model simulating the distortions introduced by a given channel.\nIn Modification of the Sigma-Lognormal Parameters, authors have decomposed the velocity function v, derived from the coordinate functions x and y, into simple strokes. Each stroke is used with different velocity functions to set the Sigma-Lognormal parameters.\nIn summary, ATVS especially the ATVS-SSig have two types of data. In Modification time functions, as described, the time functions of the master signature is changed to generate the duplicated samples [27]. In modification LN-Parameters, duplicated samples are generated modifying the lognormal parameters of the master. Both methods use 25 signatures from 350 users. Of the 25 signatures, the first five follow an intra-session variability and the next 20 follow an inter-session variability."
    }, {
      "heading" : "B. Evaluation Parameters",
      "text" : "Different parameters have been used in verification systems. In the following, a short description of most commonly used parameters have been summarized. 1) Receiver Operating Characteristic (ROC) Curve A one-class classifier can be evaluated based on small fraction false negative (false reject rate) and false positive (false accept rate). ROC curve shows how the fraction false positive varies for varying fraction false negative. Traditionally the fraction true positive is plotted versus the fraction false positive. The smaller these fractions are, the more this one-class classifier is to be preferred. 2) Equal Error rate (EER) If a line connects the points (1, 0) and (0, 1) in the ROC curve of a classifier, EER can be defined such that false positive and false negative fractions are equal. This parameter is a simple way to compare system accuracies. The smaller the EER rate is, the more accurate the system is. 3) Area Under the ROC Curve (AUC) AUC is one way to summarize an ROC curve in a single number. This integrates the fraction true positive over varying thresholds (or equivalently, varying fraction false positive). Higher values indicate a better separation between target and outlier objects."
    }, {
      "heading" : "C. Feature Learning",
      "text" : "In feature learning phase, a methodology has been set to learn features based on a signatures set except of test and train sets. Therefore, all of the signatures in ATVS database have been used for feature extraction using autoencoder (Figure 10). The autoencoder comprises one hidden layer with 2000 nodes and the limited Broyden–Fletcher–Goldfarb–Shanno algorithm (L-BFGS) method with 700 iteration for minimization function."
    }, {
      "heading" : "D. Classification and Verification",
      "text" : "In this phase, SVC2004 and SUSIG databases have been used for a K-Fold Cross-Validation process that has been implemented to categorize train and test signature groups. Several experiments have been done to achieve the best values for system parameters.\nThe size of hidden layer and iteration value have been selected based on an experiment on auto-encoder with hidden size of 500, 1000, 1500, 2000, 2500 and 3000 nodes in which the iteration value was set from 100 to 700. EER and AUC results for SVC and SUSIG databases have been shown in Table 3 and Table 4, respectively.\nThe results shown a decrement in EER and an increment in AUC rate while facing iteration value increment. Due to change mitigation in more than 700 iterations, the iteration value has been set to 700. Although for hidden size parameter, the rate of enhancement of EER and AUC rates decreased for hidden sizes larger than 2000 while computational costs increased and had been prone to over fitting and curse of dimensionality. Finally, the size 2000 has been selected because of its computational efficiency and appropriate accuracy.\nAs a comparison between the proposed system and other approaches, verification protocols must be similar. Based on random and skilled forgery verification protocol [25, 26], 25 percent of each users’ genuine signatures have been used for training to create the user model. The remaining 75 percent of users’ genuine signatures, all of the skilled forgery signatures of his/her and all of the genuine signatures of other users have been used for testing based on a local threshold for each user. For evaluating the proposed method, multiple classifiers have been tested based on authors’ previous work [29]. These classifiers are available in Matlab open source Data Description toolbox4 (dd_tools). This toolbox has the ability of obtaining optimal coefficients for classifiers. Finally, based on experimental results achieved, Gaussian classifier has been used.\nThe results of proposed method in comparison with stateof-the-art methods for two standard benchmarks (SVC2004 and SUSIG) are shown in Table 5 and Table 6.\nThese tables indicate that proposed method have the best performance in comparison with competing algorithms. This method's EER on SVC dataset is 0.83 percent, where the next best method is 1.65 percent reported for the method Ansari, et al. [6]. This verification system is 0.82 percent better than the otherwise best result. On SUSIG benchmark, implemented method's EER is equal to 0.77 percent as it is 0.46 percent better than the next best method.\nTable 5 and 6 illustrate that in contrast to all reported methods, the results on two datasets are very close (0.06 percent difference in EER). This similarly is related that proposed method is dataset invariant.\n4 Available at http://www.prtools.org"
    }, {
      "heading" : "VI. CONCLUSIONS AND FUTURE WORK",
      "text" : "In this paper, a new approach has been introduced based on Self-thought learning to verify the signatures. As it can be inferred from experimental results and inherited properties of Self-thought learning, the proposed system is independent from specific benchmarks, which means that it is signature shape invariant.\nThe features, which are used to verify the signatures, have been extracted from ATVS dataset by using a sparse autoencoder with one hidden layer. By applying convolution and pooling methods, system has achieved pooled convolved features to verify the signatures. In addition, one-class classifier has been applied as it models the signatures of each user.\nTo compare with similar works, two standard benchmarks have used which are named as SVC and SUSIG datasets. Our results have shown superiority on both datasets. The features have been used in this paper can be used in other benchmarks, as this is the main component of the method proposed in this paper.\nThis method has proved its ability to extract the best set of features in problems that need to define hand-crafted features. Therefore, it can be used in a wide range of machine learning problems. As a future work, this method can be tested on offline signatures. In addition, the impact of deep convolutional networks can be tested on both online and offline signature datasets."
    } ],
    "references" : [ {
      "title" : "Automatic Signature Verification: The State of the Art",
      "author" : [ "D. Impedovo", "G. Pirlo" ],
      "venue" : "Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on, vol. 38, pp. 609- 635, 2008.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Handwritten Signature Verification: New Advancements and Open Issues",
      "author" : [ "D. Impedovo", "G. Pirlo", "R. Plamondon" ],
      "venue" : "Frontiers in Handwriting Recognition (ICFHR), 2012 International Conference on, 2012, pp. 367-372.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Deep Representations for Iris, Face, and Fingerprint Spoofing Detection",
      "author" : [ "D. Menotti", "G. Chiachia", "A. Pinto", "W. Schwartz", "H. Pedrini", "A. Falcao" ],
      "venue" : "Information Forensics and Security, IEEE Transactions on, vol. 10, 2015.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "On-line signature recognition based on VQ- DTW",
      "author" : [ "M. Faundez-Zanuy" ],
      "venue" : "Pattern Recognition, vol. 40, pp. 981-992, 3// 2007.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Authentication based on signature verification using position, velocity, acceleration and Jerk signals",
      "author" : [ "S. Rashidi", "A. Fallah", "F. Towhidkhah" ],
      "venue" : "Information Security and Cryptology (ISCISC), 2012 9th International ISC Conference on, 2012, pp. 26-31.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Online signature verification using segment-level fuzzy modelling",
      "author" : [ "A.Q. Ansari", "M. Hanmandlu", "J. Kour", "A.K. Singh" ],
      "venue" : "Biometrics, IET, vol. 3, pp. 113-127, 2014.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Online Signature Verification Using Energy, Angle and Directional Gradient Feature with Neural Network",
      "author" : [ "P. Jain", "J. Gangrade" ],
      "venue" : "International Journal of Computer Science and Information Technologies (IJCSIT), vol. 5, pp. 211-216, 2014.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "HMM-based on-line signature verification: Feature extraction and signature modeling",
      "author" : [ "J. Fierrez", "J. Ortega-Garcia", "D. Ramos", "J. Gonzalez-Rodriguez" ],
      "venue" : "Pattern Recognition Letters, vol. 28, pp. 2325-2334, 12/1/ 2007.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Online signature verification based on signatures turning angle representation using longest common subsequence matching",
      "author" : [ "K. Barkoula", "G. Economou", "S. Fotopoulos" ],
      "venue" : "International Journal on Document Analysis and Recognition (IJDAR), vol. 16, pp. 261- 272, 2013/09/01 2013.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A Survey of On-line Signature Verification",
      "author" : [ "Z. Zhang", "K. Wang", "Y. Wang" ],
      "venue" : "Biometric Recognition. vol. 7098, Z. Sun, J. Lai,  X. Chen, and T. Tan, Eds., ed: Springer Berlin Heidelberg, 2011, pp. 141-149.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Online signature verification: A Persian-language specific approach",
      "author" : [ "M.E. Yahyatabar", "Y. Baleghi", "M.R. Karami" ],
      "venue" : "Electrical Engineering (ICEE), 2013 21st Iranian Conference on, 2013, pp. 1-6.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Online Signature Verification Using Probablistic Modeling and Neural Network",
      "author" : [ "M.J. Alhaddad", "D. Mohamad", "A.M. Ahsan" ],
      "venue" : "Engineering and Technology (S-CET), 2012 Spring Congress on, 2012, pp. 1-5.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Matching between Important Points using Dynamic Time Warping for Online Signature Verification",
      "author" : [ "M.H. Mohammadi", "K. Faez" ],
      "venue" : "Cyber Journals: Multidisciplinary Journals in Science and Technology, Journal of Selected Areas in Bioinformatics (JBIO), 2012.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Online Signature Verification on Mobile Devices",
      "author" : [ "S.-B. Napa", "N. Memon" ],
      "venue" : "Information Forensics and Security, IEEE Transactions on, vol. 9, pp. 933-947, 2014.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "An Efficient Online Signature Verification Scheme Using Dynamic Programming of String Matching",
      "author" : [ "A. Reza", "H. Lim", "M. Alam" ],
      "venue" : "Convergence and Hybrid Information Technology. vol. 6935, G. Lee, D. Howard, and D. Ślęzak, Eds., ed: Springer Berlin Heidelberg, 2011, pp. 590-597.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Fingerprint Classification Based on Depth Neural Network",
      "author" : [ "R. Wang", "C. Han", "Y. Wu", "T. Guo" ],
      "venue" : "The Computing Research Repository (CoRR), vol. September 2014, 2014.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Off-line Signature Verification: An Approach Based on Combining Distances and One-class Classifiers",
      "author" : [ "M.R.P. Souza", "G.D.C. Cavalcanti", "R. Tsang Ing" ],
      "venue" : "Tools with Artificial Intelligence (ICTAI), 2010 22nd IEEE International Conference on, 2010, pp. 7-11.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A new online signature verification system based on combining Mellin transform, MFCC and neural network",
      "author" : [ "A. Fallah", "M. Jamaati", "A. Soleamani" ],
      "venue" : "Digital Signal Processing, vol. 21, pp. 404- 416, 3// 2011.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Online Handwritten Signature Verification Using Neural Network Classifier Based on Principal Component Analysis",
      "author" : [ "V. Iranmanesh", "S.M.S. Ahmad", "W.A.W. Adnan", "S. Yussof", "O.A. Arigbabu", "F.L. Malallah" ],
      "venue" : "The Scientific World Journal, vol. 2014, 2014.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "New method for the on-line signature verification based on horizontal partitioning",
      "author" : [ "K. Cpałka", "M. Zalasiński", "L. Rutkowski" ],
      "venue" : "Pattern Recognition, vol. 47, pp. 2652–2661, 2014.  10",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Embedded System for Biometric Online Signature Verification",
      "author" : [ "M. Lopez-Garcia", "R. Ramos-Lara", "O. Miguel-Hurtado", "E. Canto-Navarro" ],
      "venue" : "Industrial Informatics, IEEE Transactions on, vol. 10, pp. 491-501, 2014.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Online Signature Verification With Support Vector Machines Based on LCSS Kernel Functions",
      "author" : [ "C. Gruber", "T. Gruber", "S. Krinninger", "B. Sick" ],
      "venue" : "Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on, vol. 40, pp. 1088-1100, 2010.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Hierarchical Representation Using NMF",
      "author" : [ "H. Song", "S.-Y. Lee" ],
      "venue" : "Neural Information Processing. vol. 8226, M. Lee, A. Hirose, Z.-G. Hou, and R. Kil, Eds., ed: Springer Berlin Heidelberg, 2013, pp. 466-473.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Self-taught learning: transfer learning from unlabeled data",
      "author" : [ "R. Raina", "A. Battle", "H. Lee", "B. Packer", "A.Y. Ng" ],
      "venue" : "presented at the Proceedings of the 24th international conference on Machine learning, Corvalis, Oregon, USA, 2007.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "SVC2004: First International Signature Verification Competition",
      "author" : [ "D.-Y. Yeung", "H. Chang", "Y. Xiong", "S. George", "R. Kashi", "T. Matsumoto" ],
      "venue" : "Biometric Authentication. vol. 3072, D. Zhang and A. Jain, Eds., ed: Springer Berlin Heidelberg, 2004, pp. 16-22.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "SUSIG: an on-line signature database, associated protocols and benchmark results",
      "author" : [ "A. Kholmatov", "B. Yanikoglu" ],
      "venue" : "Pattern Analysis and Applications, vol. 12, pp. 227-236, 2009/09/01 2009.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Synthetic on-line signature generation. Part I: Methodology and algorithms",
      "author" : [ "J. Galbally", "j. Plamondon", "J. Fierrez", "J. Ortega-Garcia" ],
      "venue" : "Pattern Recognition, vol. 45, pp. 2610-2621, 2012.",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Synthetic on-line signature generation. Part II: Experimental validation",
      "author" : [ "J. Galbally", "J. Fierrez", "J. Ortega-Garcia", "j. Plamondon" ],
      "venue" : "Pattern Recognition, vol. 45, pp. 2622-2632, 2012.",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Online Signature Verification Based on Feature Representation",
      "author" : [ "M. Fayyaz", "M.H. Saffar", "M. Sabokrou", "M. Hoseini", "M. Fathy" ],
      "venue" : "International Symposium on Artificial Intelligence and Signal Processing, Iran, Mashhad, 2015.",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Enhanced DTW based on-line signature verification",
      "author" : [ "M.I. Khalil", "M. Moustafa", "H.M. Abbas" ],
      "venue" : "Image Processing (ICIP), 2009 16th IEEE International Conference on, 2009, pp. 2713- 2716.",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "On-line signature verification using global features",
      "author" : [ "M.T. Ibrahim", "M. Kyan", "G. Ling" ],
      "venue" : "Electrical and Computer Engineering, 2009. CCECE '09. Canadian Conference on, 2009, pp. 682-685.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "The term biometrics refers to individual recognition based on a person’s distinguishing characteristics [1].",
      "startOffset" : 104,
      "endOffset" : 107
    }, {
      "referenceID" : 1,
      "context" : "People recognition systems based on biometrics have two main categories [2]:  Physiological biometrics are based on recognizing some physical part of the human body, such as",
      "startOffset" : 72,
      "endOffset" : 75
    }, {
      "referenceID" : 2,
      "context" : "of the signer  Skilled forgery: Produced by looking at the original signature sample Person recognition has been applied by several biometric modalities, such as; fingerprint, iris, face, vein and signature [3].",
      "startOffset" : 208,
      "endOffset" : 211
    }, {
      "referenceID" : 3,
      "context" : "systems focus on verification rather than identification because of daily usage of signature verification systems [4].",
      "startOffset" : 114,
      "endOffset" : 117
    }, {
      "referenceID" : 4,
      "context" : "However, in the online setting, the system uses devices for capturing additional information while the user is signing [5].",
      "startOffset" : 119,
      "endOffset" : 122
    }, {
      "referenceID" : 0,
      "context" : "Two types of features can be extracted from a signature [1] (Figure 1):  Function-Features: The signature is characterized in terms of a time function whose values constitute the",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 0,
      "context" : "The Verification approaches can be described in three categories [1]:  Template Matching: A questioned sample is matched against templates of signatures, such as Dynamic Time Wrapping (DTW) [4-6], Euclidian distance.",
      "startOffset" : 65,
      "endOffset" : 68
    }, {
      "referenceID" : 3,
      "context" : "The Verification approaches can be described in three categories [1]:  Template Matching: A questioned sample is matched against templates of signatures, such as Dynamic Time Wrapping (DTW) [4-6], Euclidian distance.",
      "startOffset" : 191,
      "endOffset" : 196
    }, {
      "referenceID" : 4,
      "context" : "The Verification approaches can be described in three categories [1]:  Template Matching: A questioned sample is matched against templates of signatures, such as Dynamic Time Wrapping (DTW) [4-6], Euclidian distance.",
      "startOffset" : 191,
      "endOffset" : 196
    }, {
      "referenceID" : 5,
      "context" : "The Verification approaches can be described in three categories [1]:  Template Matching: A questioned sample is matched against templates of signatures, such as Dynamic Time Wrapping (DTW) [4-6], Euclidian distance.",
      "startOffset" : 191,
      "endOffset" : 196
    }, {
      "referenceID" : 6,
      "context" : "can be considered, such as Neural Networks [7], Hidden Markov Models (HMM) [4, 8].",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 3,
      "context" : "can be considered, such as Neural Networks [7], Hidden Markov Models (HMM) [4, 8].",
      "startOffset" : 75,
      "endOffset" : 81
    }, {
      "referenceID" : 7,
      "context" : "can be considered, such as Neural Networks [7], Hidden Markov Models (HMM) [4, 8].",
      "startOffset" : 75,
      "endOffset" : 81
    }, {
      "referenceID" : 8,
      "context" : " Structural: This approach is related to structural representations of signatures and compared through graph or tree matching techniques [9].",
      "startOffset" : 138,
      "endOffset" : 141
    }, {
      "referenceID" : 0,
      "context" : "Most recent approaches have been described in [1, 2, 10].",
      "startOffset" : 46,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "Most recent approaches have been described in [1, 2, 10].",
      "startOffset" : 46,
      "endOffset" : 56
    }, {
      "referenceID" : 9,
      "context" : "Most recent approaches have been described in [1, 2, 10].",
      "startOffset" : 46,
      "endOffset" : 56
    }, {
      "referenceID" : 4,
      "context" : "1) [5].",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 5,
      "context" : "2, 3) [6].",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 4,
      "context" : "List of common features have been described in Table 1 [5].",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 5,
      "context" : "Furthermore, some non-common features have been described in other papers [6, 9, 11-15].",
      "startOffset" : 74,
      "endOffset" : 87
    }, {
      "referenceID" : 8,
      "context" : "Furthermore, some non-common features have been described in other papers [6, 9, 11-15].",
      "startOffset" : 74,
      "endOffset" : 87
    }, {
      "referenceID" : 10,
      "context" : "Furthermore, some non-common features have been described in other papers [6, 9, 11-15].",
      "startOffset" : 74,
      "endOffset" : 87
    }, {
      "referenceID" : 11,
      "context" : "Furthermore, some non-common features have been described in other papers [6, 9, 11-15].",
      "startOffset" : 74,
      "endOffset" : 87
    }, {
      "referenceID" : 12,
      "context" : "Furthermore, some non-common features have been described in other papers [6, 9, 11-15].",
      "startOffset" : 74,
      "endOffset" : 87
    }, {
      "referenceID" : 13,
      "context" : "Furthermore, some non-common features have been described in other papers [6, 9, 11-15].",
      "startOffset" : 74,
      "endOffset" : 87
    }, {
      "referenceID" : 14,
      "context" : "Furthermore, some non-common features have been described in other papers [6, 9, 11-15].",
      "startOffset" : 74,
      "endOffset" : 87
    }, {
      "referenceID" : 2,
      "context" : "Recently, some biometric authentication systems for face, iris and fingerprint have been proposed based on deep neural networks which used autoencoders for feature extraction phase [3, 16].",
      "startOffset" : 181,
      "endOffset" : 188
    }, {
      "referenceID" : 15,
      "context" : "Recently, some biometric authentication systems for face, iris and fingerprint have been proposed based on deep neural networks which used autoencoders for feature extraction phase [3, 16].",
      "startOffset" : 181,
      "endOffset" : 188
    }, {
      "referenceID" : 16,
      "context" : "There are different options for distance calculation such as dmin/max which is minimum/maximum distance between a signature and the patterns of the reference set, and dcentral which is the distance between a signature and the center of mass of the reference set [17].",
      "startOffset" : 262,
      "endOffset" : 266
    }, {
      "referenceID" : 16,
      "context" : "On the other hand, for local threshold, the system must choose one threshold per user so that, this approach could lead to a better result [17].",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 16,
      "context" : "Thus, For classifying a signature as genuine or forgery, one-class classifiers have been commonly used [17] to divide the set into two categories: target and outlier (Figure 2).",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 6,
      "context" : "Jain and Gangrade [7] proposed a system by using angle, energy and chain code features to diffrentiate the signatures.",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 3,
      "context" : "Faundez-Zanuy [4] studied four pattern recognition algorithms for online signature recognition: Vector Quantization (VQ), Nearest Neighbor, DTW and HMM.",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 4,
      "context" : "[5] evaluated 19 dynamic features viewpoint classification error and discrimination capability between genuine and forgery signatures.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[6] presented an online signature verification system based on fuzzy modelling.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "[9] studied the signatures Turning Angle Sequence (TAS), the Turning Angle Scale Space (TASS) representations, and their application to online signature verification.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 10,
      "context" : "[11] proposed a method based on efficient features defined in persian signatures.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12] explored a new technique by combining back-propagation Neural Network (BPNN) and the probabilistic model.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "Mohammadi and Faez [13] proposed a method based on the correspondence between important points in the direction of wrap for the time signal provided to maximize the distinction between the genuine and forged signatures.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 13,
      "context" : "Napa and Memon [14] Presented a simple and effective method for signature verification in which an online signature is represented with a discriminative feature vector derived from attributes of several histograms that can be computed in linear time.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 16,
      "context" : "[17] proposed an off-line signature verification system, which uses a combination of five distance measurements, such as, furthest, nearest, template and central using four operations: product, mean, maximum, and minimum as a feature vector.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "[18] presented a new signature verification system based on Mellin transform.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "[19] proposed a verification system by using multi-layer perceptron (MLP) on a subset of PCA features.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[20] explored a new method by using area partitioning of high and low speed of the signature and high and low pen’s pressure.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "[21] presented a signature verification system implemented on an embedded system.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "[22] proposed a technique based on Longest Common Subsequences (LCSS) detection.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 22,
      "context" : "Deep learning is part of a field of machine learning methods based on learning representation of data [23].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 23,
      "context" : "The main promise of self-taught learning is using unlabeled data in supervised classification tasks [24].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 23,
      "context" : "Having a concise high level feature representation brings us an easier classification task by having features that are more significant [24].",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 15,
      "context" : "A sparse autoencoder model can effectively realize feature extraction and dimension reduction of the input data, which play a vital role in classification tasks [16].",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 13,
      "context" : "These two steps are parts of the system training section [14].",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 24,
      "context" : "For evaluation of the proposed approach, three public datasets have been used which are SVC2004 [25], SUSIG [26]",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 25,
      "context" : "For evaluation of the proposed approach, three public datasets have been used which are SVC2004 [25], SUSIG [26]",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 26,
      "context" : "and ATVS [27, 28].",
      "startOffset" : 9,
      "endOffset" : 17
    }, {
      "referenceID" : 27,
      "context" : "and ATVS [27, 28].",
      "startOffset" : 9,
      "endOffset" : 17
    }, {
      "referenceID" : 26,
      "context" : "The artificial samples produced by ATVS follow the pattern of the western signatures, which are left-to-right concatenated handwritten signature [27].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 26,
      "context" : "In Modification time functions, as described, the time functions of the master signature is changed to generate the duplicated samples [27].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 24,
      "context" : "Based on random and skilled forgery verification protocol [25, 26], 25 percent of each users’ genuine signatures have been used for training to create the user model.",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 25,
      "context" : "Based on random and skilled forgery verification protocol [25, 26], 25 percent of each users’ genuine signatures have been used for training to create the user model.",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 28,
      "context" : "For evaluating the proposed method, multiple classifiers have been tested based on authors’ previous work [29].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 21,
      "context" : "[22] 6.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "Mohammadi and Faez [13] 6.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 8,
      "context" : "[9] 5.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 10,
      "context" : "[11] 4.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 24,
      "context" : "[25] 2.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 5,
      "context" : "[6] 1.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 28,
      "context" : "[29] 2.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 29,
      "context" : "[30] 3.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "Napa and Memon [14] 2.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 25,
      "context" : "Kholmatov and Yanikoglu [26] 2.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 30,
      "context" : "[31] 1.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 5,
      "context" : "[6] 1.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[6].",
      "startOffset" : 0,
      "endOffset" : 3
    } ],
    "year" : 2015,
    "abstractText" : "Biometrics systems have been used in a wide range of applications and have improved people authentication. Signature verification is one of the most common biometric methods with techniques that employ various specifications of a signature. Recently, deep learning has achieved great success in many fields, such as image, sounds and text processing. In this paper, deep learning method has been used for feature extraction and feature selection, which has enormous impact on the accuracy of signature verification. This paper presents a method based on self-taught learning, in which a sparse autoencoder attempts to learn discriminative features of signatures from a large unlabeled signature dataset. Then, the features learned are employed to present users’ signatures by creating a model for each user based on user genuine signatures. Finally, users’ signatures are classified using a one-class classifier. The proposed method is independent on signature datasets thanks to self-taught learning. The features have been learned from 17,500 signatures (ATVS dataset) and verification process of the proposed system is evaluated on SVC2004 and SUSIG signature datasets, which contain genuine and skilled forgery signatures. The experimental results indicate significant error reduction and accuracy enhancement in comparison with state of the art counterparts.",
    "creator" : "Microsoft® Word 2013"
  }
}