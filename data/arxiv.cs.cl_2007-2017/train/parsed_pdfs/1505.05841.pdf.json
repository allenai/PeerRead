{
  "name" : "1505.05841.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Translation Memory Retrieval Methods",
    "authors" : [ "Michael Bloodgood", "Benjamin Strauss" ],
    "emails" : [ "meb@umd.edu", "bstrauss@umd.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The most widely used computer-assisted translation (CAT) tool for professional translation of specialized text is translation memory (TM) technology (Christensen and Schjoldager, 2010). TM consists of a database of previously translated material, referred to as the TM vault or the TM bank (TMB in the rest of this paper). When a translator is translating a new sentence, the TMB is consulted to see if a similar sentence has already been translated and if so, the most similar previous translation is retrieved from the bank to\nhelp the translator. The main conceptions of TM technology occurred in the late 1970s and early 1980s (Arthern, 1978; Kay, 1980; Melby and others, 1981). TM has been widely used since the late 1990s and continues to be widely used today (Bowker and Barlow, 2008; Christensen and Schjoldager, 2010; Garcia, 2007; Somers, 2003).\nThere are a lot of factors that determine how helpful TM technology will be in practice. Some of these include: quality of the interface, speed of the back-end database lookups, speed of network connectivity for distributed setups, and the comfort of the translator with using the technology. A fundamentally important factor that determines how helpful TM technology will be in practice is how well the TM bank of previously translated materials matches up with the workload materials to be translated. It is necessary that there be a high level of match for the TM technology to be most helpful. However, having a high level of match is not sufficient. One also needs a successful method for retrieving the useful translations from the (potentially large) TM bank.\nTM similarity metrics are used for both evaluating the expected helpfulness of previous translations for new workload translations and the metrics also directly determine what translations get provided to the translator during translation of new materials. Thus, the algorithms that compute the TM similarity metrics are not only important, but they are doubly important.\nThe retrieval algorithm used by commercial TM systems is typically not disclosed (Koehn and Senellart, 2010; Simard and Fujita, 2012; Whyman and Somers, 1999). However, the bestperforming method used in current systems is widely believed to be based on edit distance (Baldwin and Tanaka, 2000; Simard and Fujita, 2012; Whyman and Somers, 1999; Koehn and Senellart, 2010; Christensen and Schjoldager, 2010; Mandreoli et al., 2006; He et al., 2010). Recently\nThis paper was published within the Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 202-210, Gothenburg, Sweden, April 26-30 2014. c©2014 Association for Computational Linguistics\nar X\niv :1\n50 5.\n05 84\n1v 1\n[ cs\n.C L\n] 2\n1 M\nay 2\n01 5\nSimard and Fujita (2012) have experimented with using MT (machine translation) evaluation metrics as TM fuzzy match, or similarity, algorithms. A limitation of the work of (Simard and Fujita, 2012) was that the evaluation of the performance of the TM similarity algorithms was also conducted using the same MT evaluation metrics. Simard and Fujita (2012) concluded that their evaluation of TM similarity functions was biased since whichever MT evaluation metric was used as the TM similarity function was also likely to obtain the best score under that evaluation metric.\nThe current paper explores various TM fuzzy match algorithms ranging from simple baselines to the widely used edit distance to new methods. The evaluations of the TM fuzzy match algorithms use human judgments of helpfulness. An algorithm based on weighted n-gram precision consistently returns translations judged to be most helpful by translators for multiple domains and language pairs. In addition to being able to retrieve useful translations from the TM bank, the fuzzy match scores ought to be indicative of how helpful a translation can be expected to be. Many translators find it counter-productive to use TM when the best-matching translation from the TM is not similar to the workload material to be translated. Thus, many commercial TM products offer translators the opportunity to set a fuzzy match score threshold so that only translations with scores above the threshold will ever be returned. It seems to be a widely used practice to set the threshold at 70% but again it remains something of a black-box as to why 70% ought to be the setting. The current paper uncovers what expectations of helpfulness can be given for different threshold settings for various fuzzy match algorithms.\nThe rest of this paper is organized as follows. Section 2 presents the TM similarity metrics that will be explored; section 3 presents our experimental setup; section 4 presents and analyzes results; and section 5 concludes."
    }, {
      "heading" : "2 Translation Memory Similarity Metrics",
      "text" : "In this section we define the methods for measuring TM similarity for which experimental results are reported in section 4. All of the metrics compute scores between 0 and 1, with higher scores indicating better matches. All of the metrics take two inputs: M and C, where M is a workload sen-\ntence from the MTBT (Material To Be Translated) and C is the source language side of a candidate pre-existing translation from the TM bank. The metrics range from simple baselines to the surmised current industrial standard to new methods."
    }, {
      "heading" : "2.1 Percent Match",
      "text" : "Perhaps the simplest metric one could conceive of being useful for TM similarity matching is percent match (PM), the percent of tokens in the MTBT segment found in the source language side of the candidate translation pair from the TM bank.\nFormally,\nPM(M,C) = |Munigrams\n⋂ Cunigrams|\n|Munigrams| , (1)\nwhere M is the sentence from the MTBT that is to be translated, C is the source language side of the candidate translation from the TM bank, Munigrams is the set of unigrams in M , and Cunigrams is the set of unigrams in C."
    }, {
      "heading" : "2.2 Weighted Percent Match",
      "text" : "A drawback of PM is that it weights the matching of each unigram in an MTBT segment equally, however, it is not the case that the value of assistance to the translator is equal for each unigram of the MTBT segment. The parts that are most valuable to the translator are the parts that he/she does not already know how to translate. Weighted percent match (WPM) uses inverse document frequency (IDF) as a proxy for trying to weight words based on how much value their translations are expected to provide to translators. The use of IDFbased weighting is motivated by the assumption that common words that permeate throughout the language will be easy for translators to translate but words that occur in relatively rare situations will be harder to translate and thus more valuable to match in the TM bank. For our implementation of WPM, each source language sentence in the parallel corpus we are experimenting with is treated as a “document” when computing IDF.\nFormally,\nWPM(M,C) =∑ u∈{Munigrams ⋂ Cunigrams}\nidf(u,D)∑ u∈Munigrams idf(u,D) , (2)\nwhere M , C, Munigrams, and Cunigrams are as defined in Eq. 1, D is the set of all source language\nsentences in the parallel corpus, and idf(x,D) = log( |D||{d∈D:x∈d}|)."
    }, {
      "heading" : "2.3 Edit Distance",
      "text" : "A drawback of both the PM and WPM metrics are that they are only considering coverage of the words from the workload sentence in the candidate sentence from the TM bank and not taking into account the context of the words. However, words can be translated very differently depending on their context. Thus, a TM metric that matches sentences on more than just (weighted) percentage coverage of lexical items can be expected to perform better for TM bank evaluation and retrieval. Indeed, as was discussed in section 1, it is widely believed that most TM similarity metrics used in existing systems are based on string edit distance.\nOur implementation of edit distance (Levenshtein, 1966), computed on a word level, is similar to the version defined in (Koehn and Senellart, 2010).\nFormally, our TM metric based on Edit Distance (ED) is defined as\nED = max ( 1− edit-dist(M,C)\n|Munigrams| , 0\n) , (3)\nwhere M , C, and Munigrams are as defined in Eq. 1, and edit-dist(M,C) is the number of word deletions, insertions, and substitutions required to transform M into C."
    }, {
      "heading" : "2.4 N-Gram Precision",
      "text" : "Although ED takes context into account, it does not emphasize local context in matching certain high-value words and phrases as much as metrics that capture n-gram precision between the MTBT workload sentence and candidate source-side sentences from the TMB. We note that n-gram precision forms a fundamental subcomputation in the computation of the corpus-level MT evaluation metric BLEU score (Papineni et al., 2002). However, although TM fuzzy matching metrics are related to automated MT evaluation metrics, there are some important differences. Perhaps the most important is that TM fuzzy matching has to be able to operate at a sentence-to-sentence level whereas automated MT evaluation metrics such as BLEU score are intended to operate over a whole corpus. Accordingly, we make modifications to how we use n-gram precision for the purpose of TM matching than how we use it when we compute\nBLEU scores. The rest of this subsection and the next two subsections describe the innovations we make in adapting the notion of n-gram precision to the TM matching task.\nOur first metric along these lines, N-Gram Precision (NGP), is defined formally as follows:\nNGP = N∑\nn=1\n1\nN pn, (4)\nwhere the value of N sets the upper bound on the length of n-grams considered1, and\npn = |Mn-grams ∩ Cn-grams| Z ∗ |Mn-grams|+ (1− Z) ∗ |Cn-grams| , (5)\nwhere M and C are as defined in Eq. 1, Mn-grams is the set of n-grams in M , Cn-grams is the set of n-grams in C, and Z is a user-set parameter that controls how the metric is normalized.2\nAs seen by equation 4, we use an arithmetic mean of precisions instead of the geometric mean that BLEU score uses. An arithmetic mean is better than a geometric mean for use in translation memory metrics since translation memory metrics are operating at a segment level and not at the aggregate level of an entire test set. At the extreme, the geometric mean will be zero if any of the n-gram precisions pn are zero. Since large ngram matches are unlikely on a segment level, using a geometric mean can be a poor method to use for matching on a segment level, as has been described for the related task of MT evaluation (Doddington, 2002; Lavie et al., 2004). Additionally, for the related task of MT evaluation at a segment level, Lavie et al. (2004) have found that using an arithmetic mean correlates better with human judgments than using a geometric mean.\nNow we turn to discussing the parameter Z for controlling how the metric is normalized. At one extreme, setting Z=1 will correspond to having no penalty on the length of the candidate retrieved from the TMB and leads to getting longer translation matches retrieved. At the other extreme,\n1We used N = 4 in our experiments. 2Note that the n in n-grams is intended to be substituted with the corresponding integer. Accordingly, for p1, n = 1 and therefore Mn-grams = M1-grams is the set of unigrams in M and Cn-grams = C1-grams is the set of unigrams in C; for p2, n = 2 and therefore Mn-grams = M2-grams is the set of bigrams in M and Cn-grams = C2-grams is the set of bigrams in C; and so on.\nsetting Z=0 will correspond to a normalization that penalizes relatively more for length of the retrieved candidate and leads to shorter translation matches being retrieved. There is a precision/recall tradeoff in that one wants to retrieve candidates from the TMB that have high recall in the sense of matching what is in the MTBT sentence yet one also wants the retrieved candidates from the TMB to have high precision in the sense of not having extraneous material not relevant to helping with the translation of the MTBT sentence. The optimal setting of Z may differ for different scenarios based on factors like the languages, the corpora, and translator preference. We believe that for most TM applications there will usually be an asymmetric valuation of precision/recall in that recall will be more important since the value of getting a match will be more than the cost of extra material up to a point. Therefore, we believe a Z setting in between 0.5 and 1.0 will be an optimal default. We use Z=0.75 in all of our experiments described in section 3 and reported on in section 4 except for the experiments explicitly showing the impact of changing the Z parameter."
    }, {
      "heading" : "2.5 Weighted N-Gram Precision",
      "text" : "Analogous to how we improved PM with WPM, we seek to improve NGP in a similar fashion. As can be seen from the numerator of Equation 5, NGP is weighting the match of all n-grams as uniformly important. However, it is not the case that each n-gram is of equal value to the translator. Similar to WPM, we use IDF as the basis of our proxy for weighting n-grams according to the value their translations are expected to provide to translators. Specifically, we define the weight of an n-gram to be the sum of the IDF values for each constituent unigram that comprises the n-gram.\nAccordingly, we formally define method Weighted N-Gram Precision (WNGP) as follows:\nWNGP = N∑ n=1 1 N wpn, (6)\nwhere N is as defined in Equation 4, and\nwpn = ∑ i∈{Mn-grams ∩ Cn-grams} w(i)\nZ [ ∑ i∈Mn-grams w(i) ] + (1− Z) [ ∑ i∈Cn-grams w(i) ] , (7)\nwhere Z, Mn-grams, and Cn-grams are as defined in Equation 5, and\nw(i) = ∑\n1-gram∈i idf(1-gram,D), (8)\nwhere i is an n-gram and idf(x,D) is as defined above for Equation 2."
    }, {
      "heading" : "2.6 Modified Weighted N-gram Precision",
      "text" : "Note that in Equation 6 each wpn contributes equally to the average. Modified Weighted NGram Precision (MWNGP) improves on WNGP by weighting the contribution of each wpn so that shorter n-grams contribute more than longer ngrams. The intuition is that for TM settings, getting more high-value shorter n-gram matches at the expense of fewer longer n-gram matches will be more helpful since translators will get relatively more assistance from seeing new high-value vocabulary. Since the translators already presumably know the rules of the language in terms of how to order words correctly, the loss of the longer ngram matches will be mitigated.\nFormally we define MWNGP as follows:\nMWNGP = 2N\n2N − 1 N∑ n=1 1 2n wpn, (9)\nwhere N and wpn are as they were defined for Equation 6."
    }, {
      "heading" : "3 Experimental Setup",
      "text" : "We performed experiments on two corpora from two different technical domains with two language pairs, French-English and Chinese-English. Subsection 3.1 discusses the specifics of the corpora and the processing we performed. Subsection 3.2 discusses the specifics of our human evaluations of how helpful retrieved segments are for translation."
    }, {
      "heading" : "3.1 Corpora",
      "text" : "For Chinese-English experiments, we used the OpenOffice3 (OO3) parallel corpus (Tiedemann, 2009), which is OO3 computer office productivity software documentation. For French-English experiments, we used the EMEA parallel corpus (Tiedemann, 2009), which are medical documents from the European Medecines Agency. The corpora were produced by a suite of automated tools as described in (Tiedemann, 2009) and come sentence-aligned.\nThe first step in our experiments was to preprocess the corpora. For Chinese corpora we tokenize each sentence using the Stanford Chinese Word Segmenter (Tseng et al., 2005) with the Chinese Penn Treebank standard (Xia, 2000). For all corpora we remove all segments that have fewer than 5 tokens or more than 100 tokens. We call the resulting set the valid segments. For the purpose of computing match statistics, for French corpora we remove all punctuation, numbers, and scientific symbols; we case-normalize the text and stem the corpus using the NLTK French snowball stemmer. For the purpose of computing match statistics, for Chinese corpora we remove all but valid tokens. Valid tokens must include at least one Chinese character. A Chinese character is defined as a character in the Unicode range 0x4E000x9FFF or 0x4000-0x4DFF or 0xF900-0xFAFF. The rationale for removing these various tokens from consideration for the purpose of computing match statistics is that translation of numbers (when they’re written as Arabic numerals), punctuation, etc. is the same across these languages and therefore we don’t want them influencing the match computations. But once a translation is selected as being most helpful for translation, the original version (that still contains all the numbers, punctuation, case markings, etc.) is the version that is brought back and displayed to the translator.\nFor the TM simulation experiments, we randomly sampled 400 translations from the OO3 corpus and pretended that the Chinese sides of those 400 translations constitute the workload Chinese MTBT. From the rest of the corpus we randomly sampled 10,000 translations and pretended that that set of 10,000 translations constitutes the Chinese-English TMB. We also did similar sampling from the EMEA corpus of a workload French MTBT of size 300 and a French-English\nTMB of size 10,000. After the preprocessing and selection of the TMB and MTBT, we found the best-matching segment from the TMB for each MTBT segment according to each TM retrieval metric defined in section 2.3 The resulting sets of (MTBT segment,best-matching TMB segment) pairs formed the inputs on which we conducted our evaluations of the performance of the various TM retrieval metrics."
    }, {
      "heading" : "3.2 Human Evaluations",
      "text" : "To conduct evaluations of how helpful the translations retrieved by the various TM retrieval metrics would be for translating the MTBT segments, we used Amazon Mechanical Turk, which has been used productively in the past for related work in the context of machine translation (Bloodgood and Callison-Burch, 2010b; Bloodgood and CallisonBurch, 2010a; Callison-Burch, 2009).\nFor each (MTBT segment,best-matching TMB segment) pair generated as discussed in subsection 3.1, we collected judgments from Turkers (i.e., the workers on MTurk) on how helpful the TMB translation would be for translating the MTBT segment on a 5-point scale. The 5-point scale was as follows:\n• 5 = Extremely helpful. The sample is so similar that with trivial modifications I can do the translation.\n• 4 = Very helpful. The sample included a large amount of useful words or phrases and/or some extremely useful words or phrases that overlapped with the MTBT.\n• 3 = Helpful. The sample included some useful words or phrases that made translating the MTBT easier.\n• 2 = Slightly helpful. The sample contained only a small number of useful words or phrases to help with translating the MTBT.\n• 1 = Not helpful or detrimental. The sample would not be helpful at all or it might even be harmful for translating the MTBT.\nAfter a worker rated a (MTBT segment,TMB segment) pair the worker was then required to give\n3If more than one segment from the TMB was tied for being the highest-scoring segment, the segment located first in the TMB was considered to be the best-matching segment.\nan explanation for their rating. These explanations proved quite helpful as discussed in section 4. For each (MTBT segment,TMB segment) pair, we collected judgments from five different Turkers. For each (MTBT segment,TMB segment) pair these five judgments were then averaged to form a mean opinion score (MOS) on the helpfulness of the retrieved TMB translation for translating the MTBT segment. These MOS scores form the basis of our evaluation of the performance of the different TM retrieval metrics."
    }, {
      "heading" : "4 Results and Analysis",
      "text" : ""
    }, {
      "heading" : "4.1 Main Results",
      "text" : "Tables 1 and 2 show the percent of the time that each pair of metrics agree on the choice of the most helpful TM segment for the Chinese-English OO3 data and the French-English EMEA data, respectively. A main observation to be made is that the choice of metric makes a big difference in the choice of the most helpful TM segment. For example, we can see that the surmised industrial standard ED metric agrees with the new MWNGP metric less than 40% of the time on both sets of data (35.0% on Chinese-English OO3 and 39.3% on French-English EMEA data).\nTables 3 and 4 show the number of times each metric found the TM segment that the Turkers judged to be the most helpful out of all the TM segments retrieved by all of the different metrics. From these tables one can see that the MWNGP\nmethod consistently retrieves the best TM segment more often than each of the other metrics. Scatterplots showing the exact performance on every MTBT segment of the OO3 dataset for various metrics are shown in Figures 1, 2, and 3. To conserve space, scatterplots are only shown for metrics PM (baseline metric), ED (strong surmised industrial standard metric), and MWNGP (new highest-performing metric). For each MTBT segment, there is a point in the scatterplot. The ycoordinate is the value assigned by the TM metric to the segment retrieved from the TM bank and the x-coordinate is the MOS of the five Turkers on how helpful the retrieved TM segment would be for translating the MTBT segment. A point is depicted as a dark blue diamond if none of the other metrics retrieved a segment with higher MOS judgment for that MTBT segment. A point is depicted as a yellow circle if another metric retrieved a different segment from the TM bank for that MTBT segment that had a higher MOS.\nA main observation from Figure 1 is that PM is failing as evidenced by the large number of points in the upper left quadrant. For those points, the metric value is high, indicating that the retrieved segment ought to be helpful. However, the MOS is low, indicating that the humans are judging it to not be helpful. Figure 2 shows that the ED\nmetric does not suffer from this problem. However, Figure 2 shows that ED has another problem, which is a lot of yellow circles in the lower left quadrant. Points in the lower left quadrant are not necessarily indicative of a poorly performing metric, depending on the degree of match of the TMB with the MTBT workload. If there is nothing available in the TMB that would help with the MTBT, it is appropriate for the metric to assign a low value and the humans to correspondingly agree that the retrieved sentence is not helpful. However, the fact that so many of ED’s points are yellow circles indicates that there were better segments available in the TMB that ED was not able to retrieve yet another metric was able to retrieve them. Observing the scatterplots for ED and those for MWNGP one can see that both methods have the vast majority of points concentrated in the lower left and upper right quadrants, solving the upper left quadrant problem of PM. However, MWNGP has a relatively more densely populated upper right quadrant populated with dark blue diamonds than ED does whereas ED has a more densely populated lower left quadrant with yellow circles than MWNGP does. These results and trends are consistent across the EMEA FrenchEnglish dataset so those scatterplots are omitted to conserve space.\nExamining outliers where MWNGP assigns a high metric value yet the Turkers indicated that the translation has low helpfulness such as the point in Figure 3 at (1.6,0.70) is informative. Looking only at the source side, it looks like the translation retrieved from the TMB ought to be very helpful. The Turkers put in their explanation of their scores that the reason they gave low helpfulness is because the English translation was incorrect. This highlights that a limitation of MWNGP, and all other TM metrics we’re aware of, is that they only consider the source side."
    }, {
      "heading" : "4.2 Adjusting for length preferences",
      "text" : "As discussed in section 2, the Z parameter can be used to control for length preferences. Table 5 shows how the average length, measured by number of tokens of the source side of the translation pairs returned by MWNGP, changes as the Z parameter is changed.\nTable 6 shows an example of how the optimal translation pair returned by MWNGP changes from Z=0.00 to Z=1.00. The example illustrates\nthe impact of changing the Z value on the nature of the translation matches that get returned by MWNGP. As discussed in section 2, smaller settings of Z are appropriate for preferences for shorter matches that are more precise in the sense that a larger percentage of their content will be relevant. Larger settings of Z are appropriate for preferences for longer matches that have higher recall in the sense that they will have more matches with the content in the MTBT segment overall, although at the possible expense of having more irrelevant content as well."
    }, {
      "heading" : "5 Conclusions",
      "text" : "Translation memory is one of the most widely used translation technologies. One of the most important aspects of the technology is the system\nfor assessing candidate translations from the TM bank for retrieval. Although detailed descriptions of the apparatus used in commercial systems are lacking, it is widely believed that they are based on an edit distance approach. We have defined and examined several TM retrieval approaches, including a new method using modified weighted ngram precision that performs better than edit distance according to human translator judgments of helpfulness. The MWNGP method is based on the following premises: local context matching is desired; weighting words and phrases by expected helpfulness to translators is desired; and allowing shorter n-gram precisions to contribute more to the final score than longer n-gram precisions is desired. An advantage of the method is that it can be adjusted to suit translator length preferences of returned matches. A limitation of MWNGP, and all other TM metrics we are aware of, is that they only consider the source language side. Examples from our experiments reveal that this can lead to poor retrievals. Therefore, future work is called for to examine the extent to which the target language sides of the translations in the TM bank influence TM system performance and to investigate ways to incorporate target language side information to improve TM system performance."
    } ],
    "references" : [ {
      "title" : "Machine translation and computerized terminology systems: a translator’s viewpoint",
      "author" : [ "Peter J Arthern." ],
      "venue" : "Translating and the Computer: Proceedings of a Seminar, pages 77–108.",
      "citeRegEx" : "Arthern.,? 1978",
      "shortCiteRegEx" : "Arthern.",
      "year" : 1978
    }, {
      "title" : "The effects of word order and segmentation on translation retrieval performance",
      "author" : [ "Timothy Baldwin", "Hozumi Tanaka." ],
      "venue" : "Proceedings of the 18th conference on Computational linguistics-Volume 1, pages 35–41. Association for Computational Lin-",
      "citeRegEx" : "Baldwin and Tanaka.,? 2000",
      "shortCiteRegEx" : "Baldwin and Tanaka.",
      "year" : 2000
    }, {
      "title" : "Bucking the trend: Large-scale cost-focused active learning for statistical machine translation",
      "author" : [ "Michael Bloodgood", "Chris Callison-Burch." ],
      "venue" : "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 854–864.",
      "citeRegEx" : "Bloodgood and Callison.Burch.,? 2010a",
      "shortCiteRegEx" : "Bloodgood and Callison.Burch.",
      "year" : 2010
    }, {
      "title" : "Using mechanical turk to build machine translation evaluation sets",
      "author" : [ "Michael Bloodgood", "Chris Callison-Burch." ],
      "venue" : "Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 208–",
      "citeRegEx" : "Bloodgood and Callison.Burch.,? 2010b",
      "shortCiteRegEx" : "Bloodgood and Callison.Burch.",
      "year" : 2010
    }, {
      "title" : "A comparative evaluation of bilingual concordancers and translation memory systems",
      "author" : [ "Lynne Bowker", "Michael Barlow." ],
      "venue" : "Topics in Language Resources for Translation and Localization, Ámsterdam-Filadelfia: John Benjamins, pages 1–22.",
      "citeRegEx" : "Bowker and Barlow.,? 2008",
      "shortCiteRegEx" : "Bowker and Barlow.",
      "year" : 2008
    }, {
      "title" : "Fast, cheap, and creative: Evaluating translation quality using Amazon’s Mechanical Turk",
      "author" : [ "Chris Callison-Burch." ],
      "venue" : "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 286–295, Singapore, August. As-",
      "citeRegEx" : "Callison.Burch.,? 2009",
      "shortCiteRegEx" : "Callison.Burch.",
      "year" : 2009
    }, {
      "title" : "Translation-memory (tm) research: what do we know and how do we know",
      "author" : [ "Tina Paulsen Christensen", "Anne Gram Schjoldager" ],
      "venue" : null,
      "citeRegEx" : "Christensen and Schjoldager.,? \\Q2010\\E",
      "shortCiteRegEx" : "Christensen and Schjoldager.",
      "year" : 2010
    }, {
      "title" : "Automatic evaluation of machine translation quality using n-gram cooccurrence statistics",
      "author" : [ "George Doddington." ],
      "venue" : "Proceedings of the second international conference on Human Language Technology Research, HLT ’02, pages 138–145, San",
      "citeRegEx" : "Doddington.,? 2002",
      "shortCiteRegEx" : "Doddington.",
      "year" : 2002
    }, {
      "title" : "Power shifts in web-based translation memory",
      "author" : [ "Ignacio Garcia." ],
      "venue" : "Machine Translation, 21(1):55–68.",
      "citeRegEx" : "Garcia.,? 2007",
      "shortCiteRegEx" : "Garcia.",
      "year" : 2007
    }, {
      "title" : "Integrating n-best smt outputs into a tm system",
      "author" : [ "Yifan He", "Yanjun Ma", "Andy Way", "Josef Van Genabith." ],
      "venue" : "Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 374–382. Association for Computational Lin-",
      "citeRegEx" : "He et al\\.,? 2010",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2010
    }, {
      "title" : "The proper place of men and machines in language translation",
      "author" : [ "Martin Kay." ],
      "venue" : "Research Report",
      "citeRegEx" : "Kay.,? 1980",
      "shortCiteRegEx" : "Kay.",
      "year" : 1980
    }, {
      "title" : "Convergence of translation memory and statistical machine translation",
      "author" : [ "Philipp Koehn", "Jean Senellart." ],
      "venue" : "Proceedings of AMTA Workshop on MT Research and the Translation Industry, pages 21–31.",
      "citeRegEx" : "Koehn and Senellart.,? 2010",
      "shortCiteRegEx" : "Koehn and Senellart.",
      "year" : 2010
    }, {
      "title" : "The significance of recall in automatic metrics for mt evaluation",
      "author" : [ "Alon Lavie", "Kenji Sagae", "Shyamsundar Jayaraman." ],
      "venue" : "In Proceedings of the 6th Conference of the Association for Machine Translation in the Americas (AMTA-2004.",
      "citeRegEx" : "Lavie et al\\.,? 2004",
      "shortCiteRegEx" : "Lavie et al\\.",
      "year" : 2004
    }, {
      "title" : "Binary codes capable of correcting deletions, insertions and reversals",
      "author" : [ "Vladimir I Levenshtein." ],
      "venue" : "Soviet physics doklady, volume 10, page 707.",
      "citeRegEx" : "Levenshtein.,? 1966",
      "shortCiteRegEx" : "Levenshtein.",
      "year" : 1966
    }, {
      "title" : "Extra: a system for examplebased translation assistance",
      "author" : [ "Federica Mandreoli", "Riccardo Martoglia", "Paolo Tiberio." ],
      "venue" : "Machine Translation, 20(3):167–197.",
      "citeRegEx" : "Mandreoli et al\\.,? 2006",
      "shortCiteRegEx" : "Mandreoli et al\\.",
      "year" : 2006
    }, {
      "title" : "A bilingual concordance system and its use in linguistic studies",
      "author" : [ "Alan K Melby" ],
      "venue" : "The Eighth Lacus Forum, pages 541–549, Columbia, SC.",
      "citeRegEx" : "Melby,? 1981",
      "shortCiteRegEx" : "Melby",
      "year" : 1981
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th annual meeting on association for computational linguistics, pages 311–318. Association for",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "A poor man’s translation memory using machine translation evaluation metrics",
      "author" : [ "Michel Simard", "Atsushi Fujita." ],
      "venue" : "Conference of the Association for Machine Translation in the Americas 2012, San Diego, California, USA, October.",
      "citeRegEx" : "Simard and Fujita.,? 2012",
      "shortCiteRegEx" : "Simard and Fujita.",
      "year" : 2012
    }, {
      "title" : "Computers and translation: a translator’s guide, volume 35",
      "author" : [ "Harold L Somers." ],
      "venue" : "John Benjamins Publishing Company.",
      "citeRegEx" : "Somers.,? 2003",
      "shortCiteRegEx" : "Somers.",
      "year" : 2003
    }, {
      "title" : "News from OPUS - A collection of multilingual parallel corpora with tools and interfaces",
      "author" : [ "Jörg Tiedemann." ],
      "venue" : "N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors, Recent Advances in Natural Language Processing, vol-",
      "citeRegEx" : "Tiedemann.,? 2009",
      "shortCiteRegEx" : "Tiedemann.",
      "year" : 2009
    }, {
      "title" : "A conditional random field word segmenter for sighan bakeoff 2005",
      "author" : [ "Huihsin Tseng", "Pichuan Chang", "Galen Andrew", "Daniel Jurafsky", "Christopher Manning." ],
      "venue" : "Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing, volume",
      "citeRegEx" : "Tseng et al\\.,? 2005",
      "shortCiteRegEx" : "Tseng et al\\.",
      "year" : 2005
    }, {
      "title" : "Evaluation metrics for a translation memory system",
      "author" : [ "Edward K. Whyman", "Harold L. Somers." ],
      "venue" : "Software-Practice and Experience, 29:1265–1284.",
      "citeRegEx" : "Whyman and Somers.,? 1999",
      "shortCiteRegEx" : "Whyman and Somers.",
      "year" : 1999
    }, {
      "title" : "The segmentation guidelines for the penn chinese treebank (3.0)",
      "author" : [ "Fei Xia" ],
      "venue" : "Technical Report IRCS-00-06,",
      "citeRegEx" : "Xia.,? \\Q2000\\E",
      "shortCiteRegEx" : "Xia.",
      "year" : 2000
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "The most widely used computer-assisted translation (CAT) tool for professional translation of specialized text is translation memory (TM) technology (Christensen and Schjoldager, 2010).",
      "startOffset" : 149,
      "endOffset" : 184
    }, {
      "referenceID" : 0,
      "context" : "The main conceptions of TM technology occurred in the late 1970s and early 1980s (Arthern, 1978; Kay, 1980; Melby and others, 1981).",
      "startOffset" : 81,
      "endOffset" : 131
    }, {
      "referenceID" : 10,
      "context" : "The main conceptions of TM technology occurred in the late 1970s and early 1980s (Arthern, 1978; Kay, 1980; Melby and others, 1981).",
      "startOffset" : 81,
      "endOffset" : 131
    }, {
      "referenceID" : 4,
      "context" : "TM has been widely used since the late 1990s and continues to be widely used today (Bowker and Barlow, 2008; Christensen and Schjoldager, 2010; Garcia, 2007; Somers, 2003).",
      "startOffset" : 83,
      "endOffset" : 171
    }, {
      "referenceID" : 6,
      "context" : "TM has been widely used since the late 1990s and continues to be widely used today (Bowker and Barlow, 2008; Christensen and Schjoldager, 2010; Garcia, 2007; Somers, 2003).",
      "startOffset" : 83,
      "endOffset" : 171
    }, {
      "referenceID" : 8,
      "context" : "TM has been widely used since the late 1990s and continues to be widely used today (Bowker and Barlow, 2008; Christensen and Schjoldager, 2010; Garcia, 2007; Somers, 2003).",
      "startOffset" : 83,
      "endOffset" : 171
    }, {
      "referenceID" : 18,
      "context" : "TM has been widely used since the late 1990s and continues to be widely used today (Bowker and Barlow, 2008; Christensen and Schjoldager, 2010; Garcia, 2007; Somers, 2003).",
      "startOffset" : 83,
      "endOffset" : 171
    }, {
      "referenceID" : 11,
      "context" : "The retrieval algorithm used by commercial TM systems is typically not disclosed (Koehn and Senellart, 2010; Simard and Fujita, 2012; Whyman and Somers, 1999).",
      "startOffset" : 81,
      "endOffset" : 158
    }, {
      "referenceID" : 17,
      "context" : "The retrieval algorithm used by commercial TM systems is typically not disclosed (Koehn and Senellart, 2010; Simard and Fujita, 2012; Whyman and Somers, 1999).",
      "startOffset" : 81,
      "endOffset" : 158
    }, {
      "referenceID" : 21,
      "context" : "The retrieval algorithm used by commercial TM systems is typically not disclosed (Koehn and Senellart, 2010; Simard and Fujita, 2012; Whyman and Somers, 1999).",
      "startOffset" : 81,
      "endOffset" : 158
    }, {
      "referenceID" : 1,
      "context" : "However, the bestperforming method used in current systems is widely believed to be based on edit distance (Baldwin and Tanaka, 2000; Simard and Fujita, 2012; Whyman and Somers, 1999; Koehn and Senellart, 2010; Christensen and Schjoldager, 2010; Mandreoli et al., 2006; He et al., 2010).",
      "startOffset" : 107,
      "endOffset" : 286
    }, {
      "referenceID" : 17,
      "context" : "However, the bestperforming method used in current systems is widely believed to be based on edit distance (Baldwin and Tanaka, 2000; Simard and Fujita, 2012; Whyman and Somers, 1999; Koehn and Senellart, 2010; Christensen and Schjoldager, 2010; Mandreoli et al., 2006; He et al., 2010).",
      "startOffset" : 107,
      "endOffset" : 286
    }, {
      "referenceID" : 21,
      "context" : "However, the bestperforming method used in current systems is widely believed to be based on edit distance (Baldwin and Tanaka, 2000; Simard and Fujita, 2012; Whyman and Somers, 1999; Koehn and Senellart, 2010; Christensen and Schjoldager, 2010; Mandreoli et al., 2006; He et al., 2010).",
      "startOffset" : 107,
      "endOffset" : 286
    }, {
      "referenceID" : 11,
      "context" : "However, the bestperforming method used in current systems is widely believed to be based on edit distance (Baldwin and Tanaka, 2000; Simard and Fujita, 2012; Whyman and Somers, 1999; Koehn and Senellart, 2010; Christensen and Schjoldager, 2010; Mandreoli et al., 2006; He et al., 2010).",
      "startOffset" : 107,
      "endOffset" : 286
    }, {
      "referenceID" : 6,
      "context" : "However, the bestperforming method used in current systems is widely believed to be based on edit distance (Baldwin and Tanaka, 2000; Simard and Fujita, 2012; Whyman and Somers, 1999; Koehn and Senellart, 2010; Christensen and Schjoldager, 2010; Mandreoli et al., 2006; He et al., 2010).",
      "startOffset" : 107,
      "endOffset" : 286
    }, {
      "referenceID" : 14,
      "context" : "However, the bestperforming method used in current systems is widely believed to be based on edit distance (Baldwin and Tanaka, 2000; Simard and Fujita, 2012; Whyman and Somers, 1999; Koehn and Senellart, 2010; Christensen and Schjoldager, 2010; Mandreoli et al., 2006; He et al., 2010).",
      "startOffset" : 107,
      "endOffset" : 286
    }, {
      "referenceID" : 9,
      "context" : "However, the bestperforming method used in current systems is widely believed to be based on edit distance (Baldwin and Tanaka, 2000; Simard and Fujita, 2012; Whyman and Somers, 1999; Koehn and Senellart, 2010; Christensen and Schjoldager, 2010; Mandreoli et al., 2006; He et al., 2010).",
      "startOffset" : 107,
      "endOffset" : 286
    }, {
      "referenceID" : 17,
      "context" : "A limitation of the work of (Simard and Fujita, 2012) was that the evaluation of the performance of the TM similarity algorithms was also conducted using the same MT evaluation metrics.",
      "startOffset" : 28,
      "endOffset" : 53
    }, {
      "referenceID" : 13,
      "context" : "Our implementation of edit distance (Levenshtein, 1966), computed on a word level, is sim-",
      "startOffset" : 36,
      "endOffset" : 55
    }, {
      "referenceID" : 11,
      "context" : "ilar to the version defined in (Koehn and Senellart, 2010).",
      "startOffset" : 31,
      "endOffset" : 58
    }, {
      "referenceID" : 16,
      "context" : "We note that n-gram precision forms a fundamental subcomputation in the computation of the corpus-level MT evaluation metric BLEU score (Papineni et al., 2002).",
      "startOffset" : 136,
      "endOffset" : 159
    }, {
      "referenceID" : 7,
      "context" : "Since large ngram matches are unlikely on a segment level, using a geometric mean can be a poor method to use for matching on a segment level, as has been described for the related task of MT evaluation (Doddington, 2002; Lavie et al., 2004).",
      "startOffset" : 203,
      "endOffset" : 241
    }, {
      "referenceID" : 12,
      "context" : "Since large ngram matches are unlikely on a segment level, using a geometric mean can be a poor method to use for matching on a segment level, as has been described for the related task of MT evaluation (Doddington, 2002; Lavie et al., 2004).",
      "startOffset" : 203,
      "endOffset" : 241
    }, {
      "referenceID" : 7,
      "context" : "Since large ngram matches are unlikely on a segment level, using a geometric mean can be a poor method to use for matching on a segment level, as has been described for the related task of MT evaluation (Doddington, 2002; Lavie et al., 2004). Additionally, for the related task of MT evaluation at a segment level, Lavie et al. (2004) have found that using an arithmetic mean correlates better with human judgments than using a geometric mean.",
      "startOffset" : 204,
      "endOffset" : 335
    }, {
      "referenceID" : 19,
      "context" : "For Chinese-English experiments, we used the OpenOffice3 (OO3) parallel corpus (Tiedemann, 2009), which is OO3 computer office productivity software documentation.",
      "startOffset" : 79,
      "endOffset" : 96
    }, {
      "referenceID" : 19,
      "context" : "For French-English experiments, we used the EMEA parallel corpus (Tiedemann, 2009), which are medical documents from the European Medecines Agency.",
      "startOffset" : 65,
      "endOffset" : 82
    }, {
      "referenceID" : 19,
      "context" : "The corpora were produced by a suite of automated tools as described in (Tiedemann, 2009) and come sentence-aligned.",
      "startOffset" : 72,
      "endOffset" : 89
    }, {
      "referenceID" : 20,
      "context" : "For Chinese corpora we tokenize each sentence using the Stanford Chinese Word Segmenter (Tseng et al., 2005) with the Chinese Penn Treebank standard (Xia, 2000).",
      "startOffset" : 88,
      "endOffset" : 108
    }, {
      "referenceID" : 22,
      "context" : ", 2005) with the Chinese Penn Treebank standard (Xia, 2000).",
      "startOffset" : 48,
      "endOffset" : 59
    }, {
      "referenceID" : 3,
      "context" : "used Amazon Mechanical Turk, which has been used productively in the past for related work in the context of machine translation (Bloodgood and Callison-Burch, 2010b; Bloodgood and CallisonBurch, 2010a; Callison-Burch, 2009).",
      "startOffset" : 129,
      "endOffset" : 224
    }, {
      "referenceID" : 5,
      "context" : "used Amazon Mechanical Turk, which has been used productively in the past for related work in the context of machine translation (Bloodgood and Callison-Burch, 2010b; Bloodgood and CallisonBurch, 2010a; Callison-Burch, 2009).",
      "startOffset" : 129,
      "endOffset" : 224
    } ],
    "year" : 2015,
    "abstractText" : "Translation Memory (TM) systems are one of the most widely used translation technologies. An important part of TM systems is the matching algorithm that determines what translations get retrieved from the bank of available translations to assist the human translator. Although detailed accounts of the matching algorithms used in commercial systems can’t be found in the literature, it is widely believed that edit distance algorithms are used. This paper investigates and evaluates the use of several matching algorithms, including the edit distance algorithm that is believed to be at the heart of most modern commercial TM systems. This paper presents results showing how well various matching algorithms correlate with human judgments of helpfulness (collected via crowdsourcing with Amazon’s Mechanical Turk). A new algorithm based on weighted n-gram precision that can be adjusted for translator length preferences consistently returns translations judged to be most helpful by translators for multiple domains and language pairs.",
    "creator" : "LaTeX with hyperref package"
  }
}