{
  "name" : "1605.06770.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Automatic Construction of Discourse Corpora for Dialogue Translation",
    "authors" : [ "Longyue Wang", "Xiaojun Zhang", "Zhaopeng Tu", "Andy Way", "Qun Liu" ],
    "emails" : [ "qliu}@computing.dcu.ie,", "tu.zhaopeng@huawei.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Discourse Corpus, Dialogue, Machine Translation, Information Retrieval, Movie Script, Movie Subtitle"
    }, {
      "heading" : "1. Introduction",
      "text" : "Dialogue is an essential component of social behaviour to express human emotions, moods, attitudes and personality. To date, few researchers have investigated how to improve the machine translation (MT) of conversational material by exploiting their internal structure. This lack of research on the dialogue MT is a surprising fact, since dialogue exhibits more cohesiveness than single sentence and at least as much than textual discourse. Although there are a number of papers on corpus construction for various natural language processing (NLP) tasks, dialogue corpora are still scarce for MT. Some work regarding bilingual subtitles as parallel corpora exists, but it lacks rich information between utterances (sentence-level corpus) (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Itamar and Itai, 2008; Tiedemann, 2008; Xiao and Wang, 2009; Tiedemann, 2012; Zhang et al., 2014). Other work focuses on mining the internal structure in dialogue data from movie scripts. However, these are monolingual data which cannot used for MT (DanescuNiculescu-Mizil and Lee, 2011; Banchs, 2012; Walker et al., 2012; Schmitt et al., 2012). In general, the fact is that bilingual subtitles are ideal resources to extract parallel sentence-level utterances, and movie scripts contain rich information such as dialogue boundaries and speaker tags. Inspired by these facts, our initial idea was to build dialogue discourse corpus by bridging the information in these two kinds of resources (i.e., scripts and subtitles). The corpus should be parallel, align at the segment-level as well as contain rich dialogue information. We propose a simple but effective approach to build our dialogue corpus. Firstly, we extract parallel sentences from bilingual subtitles, and mine dialogue information from monolingual movie scripts. Secondly, we project dialogue information from script utterances to its corresponding parallel subtitle sentences using an information retrieval (IR) approach. Finally, we apply this approach to build a Chinese–English dialogue corpus, and also manually annotate dialogue boundaries and speaker tags based on automatic results. To validate the effect of the proposed approach, we car-\nried out experiments on the generated corpus. Experimental results show that the automatic annotation approach can achieve around 82% and 98% on speaker and dialogue boundaries annotation, respectively. Furthermore, we explore the integration of speaker information into MT via domain-adaptation techniques. Results show that we can improve translation performance by around 0.5 BLEU points compared to baseline system. Generally, the contributions of this paper include the following:\n• We propose an automatic method to build a segmentlevel dialogue parallel corpus with useful information, for building large-scale dialogue MT systems;\n• Through exploring dialogue information with MT, we show that speaker information is really helpful to dialogue MT systems;\n• We also manually annotate about 100K sentences from our dialogue corpus. The gold standard dataset1\ncan be further used to search for the coherence and consistency clues in discourse structure to implement a dialogue MT system.\nThe rest of the paper is organized as follows. In Section 2, we describe related work. Section 3 describes in detail our approaches to build a dialogue corpus as well as the structure of the generated database. The experimental results for both corpus annotation and translation are reported in Section 4. Finally, Section 5 presents our conclusions and future work plans."
    }, {
      "heading" : "2. Related Work",
      "text" : "In the specific case of dialogue MT system, data acquisition can impose challenges including data scarcity, translation quality and scalability. The release of the Penn Discourse Treebank (PDTB)2 (Prasad et al., 2008) helped bring about\n1We release our DCU English-Chinese Dialogue Corpus in http://computing.dcu.ie/˜lwang/resource. html.\n2Available at https://www.seas.upenn.edu/˜pdtb.\nar X\niv :1\n60 5.\n06 77\n0v 1\n[ cs\n.C L\n] 2\n2 M\nay 2\n01 6\na new sense of maturity in discourse analysis, finally providing a high-quality large-scale resource for training discourse parsers for English. Based on PDTB, some have applied the insights to MT (Meyer and Popescu-Belis, 2012). A resource like the PDTB is extremely valuable, and it would be desirable to have a similar resource in dialogue or conversation as well. There are two directions of work related to dialogue corpus construction. One is parallel corpora construction for dialogue or conversation MT (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Tiedemann, 2008; Itamar and Itai, 2008; Xiao and Wang, 2009; Tiedemann, 2012). Thanks to the effects of crowdsourcing and fan translation in audiovisual translation (O’Hagan, 2012), we can regard subtitles as parallel corpora. Zhang et al. (2014) leveraged the existence of bilingual subtitles as a source of parallel data for the Chinese-English language pair to improve the MT systems in the movie domain. However, their work only considers sentence-level data instead of extracting more useful information for dialogues. Besides, Japanese researchers constructed a speech dialogue corpus for a machine interpretation system (Aizawa et al., 2000; Matsubara et al., 2002; Ryu et al., 2003; Takezawa, 2003). They collected speech dialogue corpora for machine interpretation research via recording and transcribing Japanese/English interpreters’ consecutive/simultaneous interpreting in the booth. The German VERBMOBIL speech-to-speech translation programme (Wahlster, 2013) also collected and transcribed task-oriented dialogue data. This related work focused on speech-to-speech translation including three modules of automatic speech recognition (ASR), MT and textto-speech(TTS). The other one is mining rich information from other resources such as movie scripts. Danescu-Niculescu-Mizil and Lee (2011) created a conversation corpus containing large metadata-rich collections of fictional conversations extracted from raw movie scripts. Both Banchs (2012) and CMU released dialogue corpora extracted from the Internet Movie Script Database (IMSDb).3 Based on IMSDb, Walker et al. (2012) annotated 862 film scripts to learn and characterize the character style for an interactive story system, and Schmitt et al. (2012) annotated 347 dialogues to explore a spoken dialogue system. The resource of movie scripts, such as IMSDb, is good enough to generate conversational discourse for dialogue processing. However, monolingual movie scripts are not enough for MT which needs a large-scale bilingual dialogue corpus to train and tune translation models."
    }, {
      "heading" : "3. Building A Parallel Dialogue Corpus",
      "text" : "As already stated, our presented parallel dialogue corpus is extracted from bilingual movie/episode subtitles and monolingual scripts. We extend previous work on movie scripts to scripts of TV series such as Friends. From IMSDb and SimplyScripts4 and the like, we crawled movie/episode scripts data. In addition, we collected the English-Chinese bilingual subtitles from multiple audiovisual translation\n3Available at http://www.imsdb.com. 4Available at http://www.simplyscripts.com.\nweb resources such as Shooter5 and Opensubtitles. 6 Based on the hypothesis that both a script and a subtitle exist for the same movie or episode, the method can be described in a pipeline as follows:\n(1) given a monolingual movie/episode script, we identify dialogue boundaries and speaker tags using clues such as format and story structure tags in the script;\n(2) for a bilingual subtitle, we align each sentence with its translation using clues such as format and time information;\n(3) for each utterance in a processed script, we apply IR techniques to match it with the line(s) in its corresponding processed subtitle according to the shared language;\n(4) for each matched term, we map the useful annotations such as speaker and dialogue boundaries from the script side to the matched line(s) in its subtitle side."
    }, {
      "heading" : "3.1. Script and Subtitle",
      "text" : "Figure 1 depicts a browser snapshot illustrating an episode script layout of Friends. There are three kinds of information: speaker, shot/scene and action information in the script. The speaker element (red ellipses) contains the corresponding character who says the utterance(s). The shot/scene tags (e.g., “SCENE”, “SHOT”, “CUT INTO:” and “CUT TO:” etc.) can be regarded as the boundaries of dialogues. For instance, the tags “SCENE J” and “CUT TO:” refer to the beginning and end of a dialogue, respectively. The action (green frames) contains all additional information of a narrative nature and explains what is happening in the scene. In this work, we focus on the first two information type while ignoring final one. Figure 2 is the corresponding bilingual subtitle of the script in Figure 1. Subtitles are often organized in two formats: Advanced SubStation Alpha (ASS) and SubRip Text (SRT). As most lines are one-to-one aligned on two language sides, it easy to process them into a parallel corpus. We also use line id and time line information to deal with one-to-many or mismatching cases. Based on the above rules, we extract useful information from both scripts and subtitles. In order to obtain highquality data, we also apply a series of techniques including language detection, simplified-traditional Chinese conversation, coding conversation and punctuation normalization. After processing scripts and subtitles, the next step is to match and project terms from script side to subtitle side."
    }, {
      "heading" : "3.2. Matching and Projection",
      "text" : "Comparing examples in Figures 1 and 2, we found that the script and the subtitle share the same language (i.e., English). However, subtitle lines are not always the same as the utterances in a script for the actors may change their lines on site, either slightly or to a greater extent. For example, the first utterance in the script is Later, when Monica’s around, I want you to ask me about fire trunks while the\n5Available at http://sub.makedie.me. 6Available at http://www.opensubtitles.org.\ncorresponding line in the subtitle is When Monica’s around, ask me about fire trunks.. Another phenomenon is that one utterance on script side may be split into several lines on subtitle side. This change is made to accommodate the size of the TV screen. It is a big challenge to deal with these changed, missing or duplicated terms during matching. All the above problems make the task a complex N - to-N matching where N ≥ 0.\nTherefore, we regard the matching and projection as an IR task (Wang et al., 2012a). The Vector Space Model (VSM) (Salton et al., 1975) is a state-of-the-art IR model in which each document is represented as a vector of identifiers (here we describe each identifier as a term). The\nith utterance Di in the script is represented as a vector Di = [w1,i, w2,i, ...wk,i], in which k is the size of the term vocabulary. Many similarity functions can be employed to calculate the similarity between two utterance vectors (Cha, 2007). Here we apply the cosine distance:\nsim(di, dj) = N∑\nk=1\nwi,k · wj,k √√√√ N∑ k=1 wi,k · √√√√ N∑ k=1 wj,k (1)\nwhere N is the number of terms in an utterance vector, and wi,k and wj,k represent the weight of the ith/jth term in the utterance Di/Dj respectively. Technically, the distance between documents in VSM is calculated by comparing the\ndeviation of angles between vectors. A Boolean Retrieval Model sets a term weight to be either 0 or 1, while an alternative solution is calculating the term weights according to the appearance of a term within the document collection. To calculate the term weights according to the appearance of a term within the document collection, we apply term frequency-inverse document frequency (TF-IDF) (Ramos, 2003) as one term-weighting model. The weight w of each term t is determined by its own term frequency tf(t, d) in a document d and its inverse document frequency idf(t, d,D) within the search collection. The definition of term weight wt,d is shown as in Eq. (2) and (3):\nwt,d = tf(t, d) · idf(t, d,D) (2) idf(t, d,D) = log ( |D| |{d ∈ D|t ∈ d}| ) (3)\nwhere D is the total number of documents in the document collection. In practice, we regard each utterance as a document and build the index for each movie script. Then we use each subtitle sentence as a query to search for target related utterances. In order to deal with inconsistency problems, we employ several strategies:\n• For better indexing and searching, we split the sentences/utterances into the smallest units using a sentence splitter;\n• Except for punctuation mark, we do not remove any stop words. Furthermore we low-case each word;\n• For each original query, it can be split into n subqueries. For each sub-query, we apply 1-best search. Then search results of the sub-queries are combined to vote for the best candidate for the original query.\n• One query may be similar to several utterances in different lines of a script. The candidate closest to the last matched term is more likely to be the right answer. Thus we impose a dynamic window for subspace searching.\nAfter the script and subtitle are bridged, we project speaker tags and dialogue boundaries in scripts to their corresponding lines in subtitles. Finally, we preserve the results in XML format, which is illustrated in Figure 3."
    }, {
      "heading" : "4. Experiments and Results",
      "text" : "For dialogue corpus construction, we apply our methods to a ten-season sitcom Friends. We extract and process both scripts and subtitles of Friends (described in Section 3.1) and then bridge them (described in Section 3.2) to build a dialogue corpus in the format of Figure 3. For data processing, we employ the sentence splitter and English tokenizer in the Moses toolkit and our in-house Chinese segmentor (Wang et al., 2012b). Furthermore, we employ Apache Lucene7 for indexing and search tasks. Table 1 presents the main statistics of the resulting bilingual dialogue corpus. We obtained 5,428 bilingual dialogues with annotated speaker and dialogue boundary information.\n7Available at https://lucene.apache.org.\nTo verify the validity of our methods (described in Section 3), we conduct an evaluation on the matching accuracy of speaker tags and dialogue boundaries in the generated corpus. To generate gold standard reference, we also manually annotate the dialogue information based on the generated parallel dialogue corpus. The agreements between automatic labels and manual labels is 81.79% on speaker and 98.64% on dialogue boundary, respectively. This indicates that the proposed automatic annotation strategy through mapping is reasonably trustworthy. Furthermore, we conduct a simple experiment to explore the effects of speaker tags on dialogue MT. We first build a baseline MT engine using Moses (Koehn et al., 2007) on our generated parallel corpus (described in Table 1). We train a 5-gram language model (LM) using the SRI Language Toolkit (Stolcke, 2002) on the target side of parallel corpus. Besides, we use GIZA++ (Och and Ney, 2003) for word alignment and minimum error rate training (Och, 2003) to optimize feature weights. Based on the hypothesis that different types of speakers may have specific speaking styles, we employ a language model adaptation method to boost the MT system (Wang et al., 2014). Instead of building a LM on the whole data, we split the data into two separate parts according the speakers’ sex and then build two separate LMs. As Moses supports multiple LM integration, we directly feed Moses two LMs. The translation results are listed in Table 2. For Chinese-to-English (i.e.\n“ZH-EN”), the baseline system achieves 20.32 and 16.33 in BLEU score on development and test data, respectively, while for English-to-Chinese (i.e. “EN-ZH”), the scores are 16.78 and 14.11 in BLEU score. The BLEU scores are relatively low because 1) we have only one reference, 2) the training corpus is small, and 3) dialogue MT is a challenging task. By using LM adaptation, we improve the performance on test data by +0.50 and +0.43 BLEU points on Chinese-to-English and English-to-Chinese tasks respectively."
    }, {
      "heading" : "5. Conclusions and Future Work",
      "text" : "We propose a novel approach to build a parallel dialogue discourse corpus from monolingual scripts and their corresponding bilingual subtitles. We identify the dialogue boundaries according to the scene or shot tags in the script to segment the monolingual dialogue, and then map the matched monolingual dialogues to the source part of the bilingual subtitles with the speaker and utterance elements in order to obtain the bilingual discourse dialogues. Finally we align the bilingual dialogue subtitle lines to produce suitable MT training material. We expand the current dialogue generation resources from movie scripts to movie/episode scripts, and specify the current parallel corpus construction to bilingual dialogue corpus building based on bilingual subtitles. We pilot this approach on a 10-season sitcom Friends and automatically generated 5,428 bilingual parallel dialogue discourses. This is a quick way to generate a bilingual dialogue corpus. To validate the effect of the proposed approach, we annotated the speaker and dialogue boundary elements manually in 4-season Friends data and compared the manual results with our automatic findings. Experimental results show that the automatic annotation approach can achieve around 81.79% and 98.64% on dialogue boundaries and speaker tags, respectively. Furthermore, we explore the integration of speaker tags into MT using domain-adaptation techniques. The experiments show that we can improve translation performance compared to a baseline system. As far as future work is considered, we intend to explore automatic dialogue detection from bilingual subtitles. A reachable goal is to utilize the resulting bilingual dialogue corpus based on our approach to also summarize\nthe discourse elements such as coherence and co-reference, speaker relationship and time information of the subtitle lines. Some supervised and semi-supervised methods and machine learning approaches can be used on these tasks."
    }, {
      "heading" : "6. Acknowledgements",
      "text" : "This work is supported by the Science Foundation of Ireland (SFI) ADAPT project (Grant No.:13/RC/2106), and partly supported by the DCU-Huawei Joint Project (Grant No.:201504032-A (DCU), YB2015090061 (Huawei)). It is partly supported by the Open Projects Program of National Laboratory of Pattern Recognition (Grant 201407353) and the Open Projects Program of Centre of Translation of GDUFS (Grant CTS201501)."
    }, {
      "heading" : "7. Bibliographical References",
      "text" : "Aizawa, Y., Matsubara, S., Kawaguchi, N., Toyama, K.,\nand Inagaki, Y. (2000). Spoken language corpus for machine interpretation research. In Proceedings of the 6th International Conference on Spoken Language Processing, volume 3, pages 398–401, Beijing, China. Banchs, R. E. (2012). Movie-dic: A movie dialogue corpus for research and development. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers, volume 2, pages 203– 207, Jeju Island, Korea. Cha, S.-H. (2007). Comprehensive survey on distance/similarity measures between probability density functions. International Journal of Mathematical Models and Methods in Applied Sciences, 1:300–307. Danescu-Niculescu-Mizil, C. and Lee, L. (2011). Chameleons in imagined conversations: A new approach\nto understanding coordination of linguistic style in dialogs. In Proceedings of the 2nd Workshop on Cognitive Modeling and Computational Linguistics, pages 76–87, Portland, Oregon.\nItamar, E. and Itai, A. (2008). Using movie subtitles for creating a large-scale bilingual corpora. In Proceedings of the 6th International Conference on Language Resources and Evaluation, pages 269–272, Marrakech, Morocco.\nKoehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., and Herbst, E. (2007). Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177–180, Prague, Czech Republic.\nLavecchia, C., Smaili, K., and Langlois, D. (2007). Building parallel corpora from movies. In Proceedings of the 4th International Workshop on Natural Language Processing and Cognitive Science, pages 201–210, Funchal, Madeira, Portugal.\nMatsubara, S., Takagi, A., Kawaguchi, N., and Inagaki, Y. (2002). Bilingual spoken monologue corpus for simultaneous machine interpretation research. In Proceedings of the 3rd International Conference on Language Resources and Evaluation, pages 153–159, Las Palmas, Canary Islands - Spain.\nMeyer, T. and Popescu-Belis, A. (2012). Using senselabeled discourse connectives for statistical machine translation. In Proceedings of the Joint Workshop on Exploiting Synergies Between Information Retrieval and Machine Translation and Hybrid Approaches to Machine Translation, pages 129–138, Avignon, France.\nOch, F. J. and Ney, H. (2003). A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.\nOch, F. J. (2003). Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, pages 160–167, Sapporo, Japan.\nO’Hagan, M. (2012). From fan translation to crowdsourcing: Consequences of web 2.0 user empowerment in audiovisual translation. Approaches to Translation Studies, 36:25–41.\nPrasad, R., Dinesh, N., Lee, A., Miltsakaki, E., Robaldo, L., Joshi, A. K., and Webber, B. L. (2008). The penn discourse treebank 2.0. In Proceedings of the 6th International Conference on Language Resources and Evaluation, Marrakech, Morocco.\nRamos, J. (2003). Using tf-idf to determine word relevance in document queries. In Proceedings of the 1st instructional conference on machine learning, Piscataway, NJ USA.\nRyu, K., Matsubara, S., Kawaguchi, N., and Inagaki, Y. (2003). Bilingual speech dialogue corpus for simultaneous machine interpretation research.\nSalton, G., Wong, A., and Yang, C.-S. (1975). A vector\nspace model for automatic indexing. Communications of the ACM, 18:613–620.\nSchmitt, A., Ultes, S., and Minker, W. (2012). A parameterized and annotated spoken dialog corpus of the cmu let’s go bus information system. In Proceedings of the 8th International Conference on Language Resources and Evaluation, pages 3369–3373, Istanbul, Turkey.\nStolcke, A. (2002). Srilm - an extensible language modeling toolkit. In Proceedings of the 7th International Conference on Spoken Language Processing, pages 901– 904, Colorado, USA.\nTakezawa, T. (2003). Collecting machine-translationaided bilingual dialogues for corpus-based speech translation. In Proceedings of the 8th European Conference on Speech Communication and Technology, pages 2757– 2760, Geneva, Switzerland.\nTiedemann, J. (2007a). Building a multilingual parallel subtitle corpus. In Proceedings of the 17th Conference on Computational Linguistics in the Netherlands, pages 1–14, Leuven, Belgium.\nTiedemann, J. (2007b). Improved sentence alignment for movie subtitles. In Proceedings of the 3rd Conference on Recent Advances in Natural Language Processing, volume 7, pages 582–588, Borovets, Bulgaria.\nTiedemann, J. (2008). Synchronizing translated movie subtitles. In Proceedings of the 6th International Conference on Language Resources and Evaluation, pages 1902–1906, Marrakech, Morocco.\nTiedemann, J. (2012). Parallel data, tools and interfaces in opus. In Proceedings of the 8th International Conference on Language Resources and Evaluation, pages 2214–2218, Istanbul, Turkey.\nWahlster, W. (2013). Verbmobil: foundations of speech-tospeech translation. Springer Science & Business Media, Berlin.\nWalker, M. A., Lin, G. I., and Sawyer, J. (2012). An annotated corpus of film dialogue for learning and characterizing character style. In Proceedings of the 8th International Conference on Language Resources and Evaluation, pages 1373–1378, Istanbul, Turkey.\nWang, L., Wong, D. F., and Chao, L. S. (2012a). An improvement in cross-language document retrieval based on statistical models. In Proceedings of the 24th Conference on Computational Linguistics and Speech Processing, pages 144–155, Chung-Li, Taiwan.\nWang, L., Wong, D. F., Chao, L. S., and Xing, J. (2012b). Crfs-based chinese word segmentation for micro-blog with small-scale data. In Proceedings of the 2nd conference jointly organized by the Chinese Language Processing Society of China and the Association for Computational Linguistics Special Interest Group on Chinese Language Processing, pages 51–57, Tianjin, China.\nWang, L., Lu, Y., Wong, D. F., Chao, L. S., Wang, Y., and Oliveira, F. (2014). Combining domain adaptation approaches for medical text translation. In Proceedings of the 9th Workshop on Statistical Machine Translation, pages 254–259, Baltimore, USA.\nXiao, H. and Wang, X. (2009). Constructing parallel corpus from movie subtitles. In Proceedings of the\n22nd International Conference on Computer Processing of Oriental Languages. Language Technology for the Knowledge-based Economy, pages 329–336, Hong Kong, China. Zhang, S., Ling, W., and Dyer, C. (2014). Dual subtitles as parallel corpora. In Proceedings of the 10th International Conference on Language Resources and Evaluation, pages 1869–1874, Reykjavik, Iceland."
    } ],
    "references" : [ {
      "title" : "Spoken language corpus for machine interpretation research",
      "author" : [ "Y. Aizawa", "S. Matsubara", "N. Kawaguchi", "K. Toyama", "Y. Inagaki" ],
      "venue" : "Proceedings of the 6th International Conference on Spoken Language Processing, volume 3, pages 398–401, Beijing, China.",
      "citeRegEx" : "Aizawa et al\\.,? 2000",
      "shortCiteRegEx" : "Aizawa et al\\.",
      "year" : 2000
    }, {
      "title" : "Movie-dic: A movie dialogue corpus for research and development",
      "author" : [ "R.E. Banchs" ],
      "venue" : "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers, volume 2, pages 203– 207, Jeju Island, Korea.",
      "citeRegEx" : "Banchs,? 2012",
      "shortCiteRegEx" : "Banchs",
      "year" : 2012
    }, {
      "title" : "Comprehensive survey on distance/similarity measures between probability density functions",
      "author" : [ "Cha", "S.-H." ],
      "venue" : "International Journal of Mathematical Models and Methods in Applied Sciences, 1:300–307.",
      "citeRegEx" : "Cha and S..H.,? 2007",
      "shortCiteRegEx" : "Cha and S..H.",
      "year" : 2007
    }, {
      "title" : "Chameleons in imagined conversations: A new approach",
      "author" : [ "C. Danescu-Niculescu-Mizil", "L. Lee" ],
      "venue" : null,
      "citeRegEx" : "Danescu.Niculescu.Mizil and Lee,? \\Q2011\\E",
      "shortCiteRegEx" : "Danescu.Niculescu.Mizil and Lee",
      "year" : 2011
    }, {
      "title" : "Using movie subtitles for creating a large-scale bilingual corpora",
      "author" : [ "E. Itamar", "A. Itai" ],
      "venue" : "Proceedings of the 6th International Conference on Language Resources and Evaluation, pages 269–272, Marrakech, Morocco.",
      "citeRegEx" : "Itamar and Itai,? 2008",
      "shortCiteRegEx" : "Itamar and Itai",
      "year" : 2008
    }, {
      "title" : "Moses: Open source toolkit for statistical machine translation",
      "author" : [ "P. Koehn", "H. Hoang", "A. Birch", "C. Callison-Burch", "M. Federico", "N. Bertoldi", "B. Cowan", "W. Shen", "C. Moran", "R. Zens", "C. Dyer", "O. Bojar", "A. Constantin", "E. Herbst" ],
      "venue" : "Proceedings of the 45th Annual",
      "citeRegEx" : "Koehn et al\\.,? 2007",
      "shortCiteRegEx" : "Koehn et al\\.",
      "year" : 2007
    }, {
      "title" : "Building parallel corpora from movies",
      "author" : [ "C. Lavecchia", "K. Smaili", "D. Langlois" ],
      "venue" : "Proceedings of the 4th International Workshop on Natural Language Processing and Cognitive Science, pages 201–210, Funchal, Madeira, Portugal.",
      "citeRegEx" : "Lavecchia et al\\.,? 2007",
      "shortCiteRegEx" : "Lavecchia et al\\.",
      "year" : 2007
    }, {
      "title" : "Bilingual spoken monologue corpus for simultaneous machine interpretation research",
      "author" : [ "S. Matsubara", "A. Takagi", "N. Kawaguchi", "Y. Inagaki" ],
      "venue" : "Proceedings of the 3rd International Conference on Language Resources and Evaluation, pages 153–159, Las Palmas, Ca-",
      "citeRegEx" : "Matsubara et al\\.,? 2002",
      "shortCiteRegEx" : "Matsubara et al\\.",
      "year" : 2002
    }, {
      "title" : "Using senselabeled discourse connectives for statistical machine translation",
      "author" : [ "T. Meyer", "A. Popescu-Belis" ],
      "venue" : "Proceedings of the Joint Workshop on Exploiting Synergies Between Information Retrieval and Machine Translation and Hybrid Approaches to Machine",
      "citeRegEx" : "Meyer and Popescu.Belis,? 2012",
      "shortCiteRegEx" : "Meyer and Popescu.Belis",
      "year" : 2012
    }, {
      "title" : "A systematic comparison of various statistical alignment models",
      "author" : [ "F.J. Och", "H. Ney" ],
      "venue" : "Computational Linguistics, 29(1):19–51.",
      "citeRegEx" : "Och and Ney,? 2003",
      "shortCiteRegEx" : "Och and Ney",
      "year" : 2003
    }, {
      "title" : "Minimum error rate training in statistical machine translation",
      "author" : [ "F.J. Och" ],
      "venue" : "Proceedings of the 41st Annual Meeting on Association for Computational Linguistics Volume 1, pages 160–167, Sapporo, Japan.",
      "citeRegEx" : "Och,? 2003",
      "shortCiteRegEx" : "Och",
      "year" : 2003
    }, {
      "title" : "From fan translation to crowdsourcing: Consequences of web 2.0 user empowerment in audiovisual translation. Approaches to Translation Studies, 36:25–41",
      "author" : [ "M. O’Hagan" ],
      "venue" : null,
      "citeRegEx" : "O.Hagan,? \\Q2012\\E",
      "shortCiteRegEx" : "O.Hagan",
      "year" : 2012
    }, {
      "title" : "The penn discourse treebank 2.0",
      "author" : [ "R. Prasad", "N. Dinesh", "A. Lee", "E. Miltsakaki", "L. Robaldo", "A.K. Joshi", "B.L. Webber" ],
      "venue" : "In Proceedings of the 6th International Conference on Language Resources and Evaluation,",
      "citeRegEx" : "Prasad et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Prasad et al\\.",
      "year" : 2008
    }, {
      "title" : "Using tf-idf to determine word relevance in document queries",
      "author" : [ "J. Ramos" ],
      "venue" : "Proceedings of the 1st instructional conference on machine learning, Piscataway, NJ USA.",
      "citeRegEx" : "Ramos,? 2003",
      "shortCiteRegEx" : "Ramos",
      "year" : 2003
    }, {
      "title" : "Bilingual speech dialogue corpus for simultaneous machine interpretation research",
      "author" : [ "K. Ryu", "S. Matsubara", "N. Kawaguchi", "Y. Inagaki" ],
      "venue" : null,
      "citeRegEx" : "Ryu et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Ryu et al\\.",
      "year" : 2003
    }, {
      "title" : "A parameterized and annotated spoken dialog corpus of the cmu let’s go bus information system",
      "author" : [ "A. Schmitt", "S. Ultes", "W. Minker" ],
      "venue" : "Proceedings of the 8th International Conference on Language Resources and Evaluation, pages 3369–3373, Istanbul, Turkey.",
      "citeRegEx" : "Schmitt et al\\.,? 2012",
      "shortCiteRegEx" : "Schmitt et al\\.",
      "year" : 2012
    }, {
      "title" : "Srilm - an extensible language modeling toolkit",
      "author" : [ "A. Stolcke" ],
      "venue" : "Proceedings of the 7th International Conference on Spoken Language Processing, pages 901– 904, Colorado, USA.",
      "citeRegEx" : "Stolcke,? 2002",
      "shortCiteRegEx" : "Stolcke",
      "year" : 2002
    }, {
      "title" : "Collecting machine-translationaided bilingual dialogues for corpus-based speech translation",
      "author" : [ "T. Takezawa" ],
      "venue" : "Proceedings of the 8th European Conference on Speech Communication and Technology, pages 2757– 2760, Geneva, Switzerland.",
      "citeRegEx" : "Takezawa,? 2003",
      "shortCiteRegEx" : "Takezawa",
      "year" : 2003
    }, {
      "title" : "Building a multilingual parallel subtitle corpus",
      "author" : [ "J. Tiedemann" ],
      "venue" : "Proceedings of the 17th Conference on Computational Linguistics in the Netherlands, pages 1–14, Leuven, Belgium.",
      "citeRegEx" : "Tiedemann,? 2007a",
      "shortCiteRegEx" : "Tiedemann",
      "year" : 2007
    }, {
      "title" : "Improved sentence alignment for movie subtitles",
      "author" : [ "J. Tiedemann" ],
      "venue" : "Proceedings of the 3rd Conference on Recent Advances in Natural Language Processing, volume 7, pages 582–588, Borovets, Bulgaria.",
      "citeRegEx" : "Tiedemann,? 2007b",
      "shortCiteRegEx" : "Tiedemann",
      "year" : 2007
    }, {
      "title" : "Synchronizing translated movie subtitles",
      "author" : [ "J. Tiedemann" ],
      "venue" : "Proceedings of the 6th International Conference on Language Resources and Evaluation, pages 1902–1906, Marrakech, Morocco.",
      "citeRegEx" : "Tiedemann,? 2008",
      "shortCiteRegEx" : "Tiedemann",
      "year" : 2008
    }, {
      "title" : "Parallel data, tools and interfaces in opus",
      "author" : [ "J. Tiedemann" ],
      "venue" : "Proceedings of the 8th International Conference on Language Resources and Evaluation, pages 2214–2218, Istanbul, Turkey.",
      "citeRegEx" : "Tiedemann,? 2012",
      "shortCiteRegEx" : "Tiedemann",
      "year" : 2012
    }, {
      "title" : "Verbmobil: foundations of speech-tospeech translation",
      "author" : [ "W. Wahlster" ],
      "venue" : "Springer Science & Business Media, Berlin.",
      "citeRegEx" : "Wahlster,? 2013",
      "shortCiteRegEx" : "Wahlster",
      "year" : 2013
    }, {
      "title" : "An annotated corpus of film dialogue for learning and characterizing character style",
      "author" : [ "M.A. Walker", "G.I. Lin", "J. Sawyer" ],
      "venue" : "Proceedings of the 8th International Conference on Language Resources and Evaluation, pages 1373–1378, Istanbul, Turkey.",
      "citeRegEx" : "Walker et al\\.,? 2012",
      "shortCiteRegEx" : "Walker et al\\.",
      "year" : 2012
    }, {
      "title" : "An improvement in cross-language document retrieval based on statistical models",
      "author" : [ "L. Wang", "D.F. Wong", "L.S. Chao" ],
      "venue" : "Proceedings of the 24th Conference on Computational Linguistics and Speech Processing, pages 144–155, Chung-Li, Taiwan.",
      "citeRegEx" : "Wang et al\\.,? 2012a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2012
    }, {
      "title" : "Crfs-based chinese word segmentation for micro-blog with small-scale data",
      "author" : [ "L. Wang", "D.F. Wong", "L.S. Chao", "J. Xing" ],
      "venue" : "Proceedings of the 2nd conference jointly organized by the Chinese Language Processing Society of China and the Association for Com-",
      "citeRegEx" : "Wang et al\\.,? 2012b",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2012
    }, {
      "title" : "Combining domain adaptation approaches for medical text translation",
      "author" : [ "L. Wang", "Y. Lu", "D.F. Wong", "L.S. Chao", "Y. Wang", "F. Oliveira" ],
      "venue" : "Proceedings of the 9th Workshop on Statistical Machine Translation, pages 254–259, Baltimore, USA.",
      "citeRegEx" : "Wang et al\\.,? 2014",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2014
    }, {
      "title" : "Constructing parallel corpus from movie subtitles",
      "author" : [ "H. Xiao", "X. Wang" ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Xiao and Wang,? 2009",
      "shortCiteRegEx" : "Xiao and Wang",
      "year" : 2009
    }, {
      "title" : "Dual subtitles as parallel corpora",
      "author" : [ "S. Zhang", "W. Ling", "C. Dyer" ],
      "venue" : "Proceedings of the 10th International Conference on Language Resources and Evaluation, pages 1869–1874, Reykjavik, Iceland.",
      "citeRegEx" : "Zhang et al\\.,? 2014",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Some work regarding bilingual subtitles as parallel corpora exists, but it lacks rich information between utterances (sentence-level corpus) (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Itamar and Itai, 2008; Tiedemann, 2008; Xiao and Wang, 2009; Tiedemann, 2012; Zhang et al., 2014).",
      "startOffset" : 141,
      "endOffset" : 299
    }, {
      "referenceID" : 18,
      "context" : "Some work regarding bilingual subtitles as parallel corpora exists, but it lacks rich information between utterances (sentence-level corpus) (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Itamar and Itai, 2008; Tiedemann, 2008; Xiao and Wang, 2009; Tiedemann, 2012; Zhang et al., 2014).",
      "startOffset" : 141,
      "endOffset" : 299
    }, {
      "referenceID" : 19,
      "context" : "Some work regarding bilingual subtitles as parallel corpora exists, but it lacks rich information between utterances (sentence-level corpus) (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Itamar and Itai, 2008; Tiedemann, 2008; Xiao and Wang, 2009; Tiedemann, 2012; Zhang et al., 2014).",
      "startOffset" : 141,
      "endOffset" : 299
    }, {
      "referenceID" : 4,
      "context" : "Some work regarding bilingual subtitles as parallel corpora exists, but it lacks rich information between utterances (sentence-level corpus) (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Itamar and Itai, 2008; Tiedemann, 2008; Xiao and Wang, 2009; Tiedemann, 2012; Zhang et al., 2014).",
      "startOffset" : 141,
      "endOffset" : 299
    }, {
      "referenceID" : 20,
      "context" : "Some work regarding bilingual subtitles as parallel corpora exists, but it lacks rich information between utterances (sentence-level corpus) (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Itamar and Itai, 2008; Tiedemann, 2008; Xiao and Wang, 2009; Tiedemann, 2012; Zhang et al., 2014).",
      "startOffset" : 141,
      "endOffset" : 299
    }, {
      "referenceID" : 27,
      "context" : "Some work regarding bilingual subtitles as parallel corpora exists, but it lacks rich information between utterances (sentence-level corpus) (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Itamar and Itai, 2008; Tiedemann, 2008; Xiao and Wang, 2009; Tiedemann, 2012; Zhang et al., 2014).",
      "startOffset" : 141,
      "endOffset" : 299
    }, {
      "referenceID" : 21,
      "context" : "Some work regarding bilingual subtitles as parallel corpora exists, but it lacks rich information between utterances (sentence-level corpus) (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Itamar and Itai, 2008; Tiedemann, 2008; Xiao and Wang, 2009; Tiedemann, 2012; Zhang et al., 2014).",
      "startOffset" : 141,
      "endOffset" : 299
    }, {
      "referenceID" : 28,
      "context" : "Some work regarding bilingual subtitles as parallel corpora exists, but it lacks rich information between utterances (sentence-level corpus) (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Itamar and Itai, 2008; Tiedemann, 2008; Xiao and Wang, 2009; Tiedemann, 2012; Zhang et al., 2014).",
      "startOffset" : 141,
      "endOffset" : 299
    }, {
      "referenceID" : 1,
      "context" : "However, these are monolingual data which cannot used for MT (DanescuNiculescu-Mizil and Lee, 2011; Banchs, 2012; Walker et al., 2012; Schmitt et al., 2012).",
      "startOffset" : 61,
      "endOffset" : 156
    }, {
      "referenceID" : 23,
      "context" : "However, these are monolingual data which cannot used for MT (DanescuNiculescu-Mizil and Lee, 2011; Banchs, 2012; Walker et al., 2012; Schmitt et al., 2012).",
      "startOffset" : 61,
      "endOffset" : 156
    }, {
      "referenceID" : 15,
      "context" : "However, these are monolingual data which cannot used for MT (DanescuNiculescu-Mizil and Lee, 2011; Banchs, 2012; Walker et al., 2012; Schmitt et al., 2012).",
      "startOffset" : 61,
      "endOffset" : 156
    }, {
      "referenceID" : 12,
      "context" : "The release of the Penn Discourse Treebank (PDTB)2 (Prasad et al., 2008) helped bring about",
      "startOffset" : 51,
      "endOffset" : 72
    }, {
      "referenceID" : 8,
      "context" : "Based on PDTB, some have applied the insights to MT (Meyer and Popescu-Belis, 2012).",
      "startOffset" : 52,
      "endOffset" : 83
    }, {
      "referenceID" : 6,
      "context" : "One is parallel corpora construction for dialogue or conversation MT (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Tiedemann, 2008; Itamar and Itai, 2008; Xiao and Wang, 2009; Tiedemann, 2012).",
      "startOffset" : 69,
      "endOffset" : 207
    }, {
      "referenceID" : 18,
      "context" : "One is parallel corpora construction for dialogue or conversation MT (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Tiedemann, 2008; Itamar and Itai, 2008; Xiao and Wang, 2009; Tiedemann, 2012).",
      "startOffset" : 69,
      "endOffset" : 207
    }, {
      "referenceID" : 19,
      "context" : "One is parallel corpora construction for dialogue or conversation MT (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Tiedemann, 2008; Itamar and Itai, 2008; Xiao and Wang, 2009; Tiedemann, 2012).",
      "startOffset" : 69,
      "endOffset" : 207
    }, {
      "referenceID" : 20,
      "context" : "One is parallel corpora construction for dialogue or conversation MT (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Tiedemann, 2008; Itamar and Itai, 2008; Xiao and Wang, 2009; Tiedemann, 2012).",
      "startOffset" : 69,
      "endOffset" : 207
    }, {
      "referenceID" : 4,
      "context" : "One is parallel corpora construction for dialogue or conversation MT (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Tiedemann, 2008; Itamar and Itai, 2008; Xiao and Wang, 2009; Tiedemann, 2012).",
      "startOffset" : 69,
      "endOffset" : 207
    }, {
      "referenceID" : 27,
      "context" : "One is parallel corpora construction for dialogue or conversation MT (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Tiedemann, 2008; Itamar and Itai, 2008; Xiao and Wang, 2009; Tiedemann, 2012).",
      "startOffset" : 69,
      "endOffset" : 207
    }, {
      "referenceID" : 21,
      "context" : "One is parallel corpora construction for dialogue or conversation MT (Lavecchia et al., 2007; Tiedemann, 2007a; Tiedemann, 2007b; Tiedemann, 2008; Itamar and Itai, 2008; Xiao and Wang, 2009; Tiedemann, 2012).",
      "startOffset" : 69,
      "endOffset" : 207
    }, {
      "referenceID" : 11,
      "context" : "Thanks to the effects of crowdsourcing and fan translation in audiovisual translation (O’Hagan, 2012), we can regard subtitles as parallel corpora.",
      "startOffset" : 86,
      "endOffset" : 101
    }, {
      "referenceID" : 0,
      "context" : "Besides, Japanese researchers constructed a speech dialogue corpus for a machine interpretation system (Aizawa et al., 2000; Matsubara et al., 2002; Ryu et al., 2003; Takezawa, 2003).",
      "startOffset" : 103,
      "endOffset" : 182
    }, {
      "referenceID" : 7,
      "context" : "Besides, Japanese researchers constructed a speech dialogue corpus for a machine interpretation system (Aizawa et al., 2000; Matsubara et al., 2002; Ryu et al., 2003; Takezawa, 2003).",
      "startOffset" : 103,
      "endOffset" : 182
    }, {
      "referenceID" : 14,
      "context" : "Besides, Japanese researchers constructed a speech dialogue corpus for a machine interpretation system (Aizawa et al., 2000; Matsubara et al., 2002; Ryu et al., 2003; Takezawa, 2003).",
      "startOffset" : 103,
      "endOffset" : 182
    }, {
      "referenceID" : 17,
      "context" : "Besides, Japanese researchers constructed a speech dialogue corpus for a machine interpretation system (Aizawa et al., 2000; Matsubara et al., 2002; Ryu et al., 2003; Takezawa, 2003).",
      "startOffset" : 103,
      "endOffset" : 182
    }, {
      "referenceID" : 22,
      "context" : "The German VERBMOBIL speech-to-speech translation programme (Wahlster, 2013) also collected and transcribed task-oriented dialogue data.",
      "startOffset" : 60,
      "endOffset" : 76
    }, {
      "referenceID" : 1,
      "context" : ", 2007; Tiedemann, 2007a; Tiedemann, 2007b; Tiedemann, 2008; Itamar and Itai, 2008; Xiao and Wang, 2009; Tiedemann, 2012). Thanks to the effects of crowdsourcing and fan translation in audiovisual translation (O’Hagan, 2012), we can regard subtitles as parallel corpora. Zhang et al. (2014) leveraged the existence of bilingual subtitles as a source of parallel data for the Chinese-English language pair to improve the MT systems in the movie domain.",
      "startOffset" : 61,
      "endOffset" : 291
    }, {
      "referenceID" : 0,
      "context" : "Besides, Japanese researchers constructed a speech dialogue corpus for a machine interpretation system (Aizawa et al., 2000; Matsubara et al., 2002; Ryu et al., 2003; Takezawa, 2003). They collected speech dialogue corpora for machine interpretation research via recording and transcribing Japanese/English interpreters’ consecutive/simultaneous interpreting in the booth. The German VERBMOBIL speech-to-speech translation programme (Wahlster, 2013) also collected and transcribed task-oriented dialogue data. This related work focused on speech-to-speech translation including three modules of automatic speech recognition (ASR), MT and textto-speech(TTS). The other one is mining rich information from other resources such as movie scripts. Danescu-Niculescu-Mizil and Lee (2011) created a conversation corpus containing large metadata-rich collections of fictional conversations extracted from raw movie scripts.",
      "startOffset" : 104,
      "endOffset" : 782
    }, {
      "referenceID" : 0,
      "context" : "Besides, Japanese researchers constructed a speech dialogue corpus for a machine interpretation system (Aizawa et al., 2000; Matsubara et al., 2002; Ryu et al., 2003; Takezawa, 2003). They collected speech dialogue corpora for machine interpretation research via recording and transcribing Japanese/English interpreters’ consecutive/simultaneous interpreting in the booth. The German VERBMOBIL speech-to-speech translation programme (Wahlster, 2013) also collected and transcribed task-oriented dialogue data. This related work focused on speech-to-speech translation including three modules of automatic speech recognition (ASR), MT and textto-speech(TTS). The other one is mining rich information from other resources such as movie scripts. Danescu-Niculescu-Mizil and Lee (2011) created a conversation corpus containing large metadata-rich collections of fictional conversations extracted from raw movie scripts. Both Banchs (2012) and CMU released dialogue corpora extracted from the Internet Movie Script Database (IMSDb).",
      "startOffset" : 104,
      "endOffset" : 935
    }, {
      "referenceID" : 0,
      "context" : "Besides, Japanese researchers constructed a speech dialogue corpus for a machine interpretation system (Aizawa et al., 2000; Matsubara et al., 2002; Ryu et al., 2003; Takezawa, 2003). They collected speech dialogue corpora for machine interpretation research via recording and transcribing Japanese/English interpreters’ consecutive/simultaneous interpreting in the booth. The German VERBMOBIL speech-to-speech translation programme (Wahlster, 2013) also collected and transcribed task-oriented dialogue data. This related work focused on speech-to-speech translation including three modules of automatic speech recognition (ASR), MT and textto-speech(TTS). The other one is mining rich information from other resources such as movie scripts. Danescu-Niculescu-Mizil and Lee (2011) created a conversation corpus containing large metadata-rich collections of fictional conversations extracted from raw movie scripts. Both Banchs (2012) and CMU released dialogue corpora extracted from the Internet Movie Script Database (IMSDb).3 Based on IMSDb, Walker et al. (2012) annotated 862 film scripts to learn and characterize the character style for an interactive story system, and Schmitt et al.",
      "startOffset" : 104,
      "endOffset" : 1066
    }, {
      "referenceID" : 0,
      "context" : "Besides, Japanese researchers constructed a speech dialogue corpus for a machine interpretation system (Aizawa et al., 2000; Matsubara et al., 2002; Ryu et al., 2003; Takezawa, 2003). They collected speech dialogue corpora for machine interpretation research via recording and transcribing Japanese/English interpreters’ consecutive/simultaneous interpreting in the booth. The German VERBMOBIL speech-to-speech translation programme (Wahlster, 2013) also collected and transcribed task-oriented dialogue data. This related work focused on speech-to-speech translation including three modules of automatic speech recognition (ASR), MT and textto-speech(TTS). The other one is mining rich information from other resources such as movie scripts. Danescu-Niculescu-Mizil and Lee (2011) created a conversation corpus containing large metadata-rich collections of fictional conversations extracted from raw movie scripts. Both Banchs (2012) and CMU released dialogue corpora extracted from the Internet Movie Script Database (IMSDb).3 Based on IMSDb, Walker et al. (2012) annotated 862 film scripts to learn and characterize the character style for an interactive story system, and Schmitt et al. (2012) annotated 347 dialogues to explore a spoken dialogue system.",
      "startOffset" : 104,
      "endOffset" : 1198
    }, {
      "referenceID" : 24,
      "context" : "Therefore, we regard the matching and projection as an IR task (Wang et al., 2012a).",
      "startOffset" : 63,
      "endOffset" : 83
    }, {
      "referenceID" : 13,
      "context" : "To calculate the term weights according to the appearance of a term within the document collection, we apply term frequency-inverse document frequency (TF-IDF) (Ramos, 2003) as one term-weighting model.",
      "startOffset" : 160,
      "endOffset" : 173
    }, {
      "referenceID" : 25,
      "context" : "For data processing, we employ the sentence splitter and English tokenizer in the Moses toolkit and our in-house Chinese segmentor (Wang et al., 2012b).",
      "startOffset" : 131,
      "endOffset" : 151
    }, {
      "referenceID" : 5,
      "context" : "We first build a baseline MT engine using Moses (Koehn et al., 2007) on our generated parallel corpus (described in Table 1).",
      "startOffset" : 48,
      "endOffset" : 68
    }, {
      "referenceID" : 16,
      "context" : "We train a 5-gram language model (LM) using the SRI Language Toolkit (Stolcke, 2002) on the target side of parallel corpus.",
      "startOffset" : 69,
      "endOffset" : 84
    }, {
      "referenceID" : 9,
      "context" : "Besides, we use GIZA++ (Och and Ney, 2003) for word alignment and minimum error rate training (Och, 2003) to optimize feature weights.",
      "startOffset" : 23,
      "endOffset" : 42
    }, {
      "referenceID" : 10,
      "context" : "Besides, we use GIZA++ (Och and Ney, 2003) for word alignment and minimum error rate training (Och, 2003) to optimize feature weights.",
      "startOffset" : 94,
      "endOffset" : 105
    }, {
      "referenceID" : 26,
      "context" : "Based on the hypothesis that different types of speakers may have specific speaking styles, we employ a language model adaptation method to boost the MT system (Wang et al., 2014).",
      "startOffset" : 160,
      "endOffset" : 179
    } ],
    "year" : 2016,
    "abstractText" : "In this paper, a novel approach is proposed to automatically construct parallel discourse corpus for dialogue machine translation. Firstly, the parallel subtitle data and its corresponding monolingual movie script data are crawled and collected from Internet. Then tags such as speaker and discourse boundary from the script data are projected to its subtitle data via an information retrieval approach in order to map monolingual discourse to bilingual texts. We not only evaluate the mapping results, but also integrate speaker information into the translation. Experiments show our proposed method can achieve 81.79% and 98.64% accuracy on speaker and dialogue boundary annotation, and speaker-based language model adaptation can obtain around 0.5 BLEU points improvement in translation qualities. Finally, we publicly release around 100K parallel discourse data with manual speaker and dialogue boundary annotation.",
    "creator" : "LaTeX with hyperref package"
  }
}