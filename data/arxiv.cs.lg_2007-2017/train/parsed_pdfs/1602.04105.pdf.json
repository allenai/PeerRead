{
  "name" : "1602.04105.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Convolutional Radio Modulation Recognition Networks",
    "authors" : [ "Timothy J. O’Shea", "Johnathan Corgan" ],
    "emails" : [ "OSHEA@VT.EDU", "JOHNATHAN@CORGANLABS.COM" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Radio communications is a unique signal processing domain which presents a number of interesting challenges and opportunities to the machine learning community. It is a field in which expert features and decision criterion have been extensively developed, analyzed, and debated for optimality under certain criteria for many years in specific areas. In the past few years the trend in machine learning, primarily in image processing (Krizhevsky et al., 2012) and voice recognition (Sainath et al., 2015), is overwhelmingly that of feature learning from data.\nConcurrently, the demands on radio technologies, operators, and regulators is to increase the efficiency, adaptability, and flexibility with which devices may access, understand, and inter-operate within the same spectrum.\nIdeas such as dynamic spectrum access (DSA) (Kolodzy, 2004), the opportunistic access and sharing of spectrum, and ”Cognitive Radio” (CR) (Mitola III & Maguire Jr, 1999), a more broad class of radio optimization with learning algorithms, are widely discussed at the conceptual level in the field. Efforts in these fields are largely constrained\nPending Publication\nto application or task specific narrow solutions which lack the generality needed to deal with complex and growing emitter, interference and propagation environments. (Kim et al., 2007) (Clancy et al., 2007) (Rondeau, 2007)\nThis is a significant challenge in the community as expert systems designed to perform well on narrow tasks lack flexibility and can still be very expensive and tedious to develop.\nBy building upon successful strategies from image and voice recognition domains in machine learning, we demonstrate an approach in the radio domain which offers flexibility to learn features across a wide range of tasks and demonstrates comparable or better signal processing performance accuracy on tasks as current day systems."
    }, {
      "heading" : "2. Modulation Recognition",
      "text" : "In Dynamic Spectrum Access (DSA) one of the key tasks performed by spectrum users is that of providing sufficient awareness of their surroundings to avoid creating or being harmed by radio interference with other users. This involves being able to identify broadcast radio, local and wide area data and voice radios, radar users, and other sources or protected classes of potential radio interference in the vicinity. Modulation Recognition is generally this task of identifying based on a noisy received radio signal at some point, what kind of communications scheme is presently being used and thus what type of spectrum users are present that may cause interference or may need to be protected from interference.\nThe problem then is one of estimating a class of communications signals from a received radio signal time series which is typically represented as a complex base-band time series signal in a digitally sampled receiver. Classically, this is written as in 1 where s(t) is a time series signal of either a continuous signal or a series of discrete bits modulated onto a sinusoid with either varying frequency, phase, amplitude, trajectory, or some permutation of multiple thereof. c is some path loss or constant gain term on the\nar X\niv :1\n60 2.\n04 10\n5v 1\n[ cs\n.L G\n] 1\n2 Fe\nb 20\n16\nsignal, and n(t) is an additive Gaussian white noise process reflecting thermal noise.\nr(t) = s(t) ∗ c+ n(t) (1)\nAnalytically, this simplified expression is used widely in the development of features, but the real world relationship looks much more like this in many systems.\nr(t) = ej∗nLo(t) ∫ τ0 τ=0 s(nClk(t− τ))h(τ) + nAdd(t) (2)\nHere we introduce a number of real world effects which are non-trivial to model: complex modulation by a residual carrier random walk process, nLo(t), re-sampling by a residual clock oscillator random walk, nClk(t), convolution with a time varying rotating non-constant amplitude channel impulse response h(t − τ), and the addition of noise which may not be white, nAdd(t). Each of these presents an unknown time varying source of error.\nModeling expert feature and decision metric optimality analytically under each of these harsh realistic assumptions on propagation effects is non-trivial and often makes simplifying assumptions. For the purposes of this paper we focus on empirical measurement of performance results and harsh simulated propagation environments which include all of the above mentioned effects, but which do not attempt to analytically trace their performance in closed form."
    }, {
      "heading" : "2.1. Expert Cyclic-Moment Features",
      "text" : "Integrated cyclic-moment based features (Gardner & Spooner, 1992) are currently widely popular in performing modulation recognition and for forming analytically derived decision trees to sort modulations into different classes. In general, they take the form given in equation 3.\nsnm = fm(x n(t)...xn(t+ T )) (3)\nBy computing the m’th order statistic on the n’th power of the instantaneous or time delayed received signal r(t), we may obtain a set of statistics which uniquely separate it from other modulations given a decision process on the features. In our comparison, we compute the first 2 moments of the first 4 powers of the complex received signal, the received signal envelope, the complex signal phase, and the envelope of the received signal phase."
    }, {
      "heading" : "2.2. Convolutional Feature Learning",
      "text" : "Our method under evaluation in this case is a convolutional neural network provided with a windowed input of the raw\nradio time series r(t). Since automatic differentiation, and complex valued neural networks as a whole are still a developing field, we choose to treat samples from r(t) as t 2xN vectors for input into a narrow 2D Convolutional Network where the orthogonal and synchronously sampled InPhase and Quadrature (I & Q) samples make up the 2-wide dimension."
    }, {
      "heading" : "3. Evaluation Dataset",
      "text" : "While simulation and the use of synthetic data sets for learning is generally frowned upon in machine learning, radio communications presents a bit of a special case. Certainly training with real data is important and valuable - and we will address it more in the future - but there are certain properties which allow us to say this approximation of real data is reasonable.\nRadio communications signals are generated synthetically, and we can do so deterministically in a way identical to a real system, introducing modulation, pulse shaping, carried data, and other well characterized transmit parameters identical to a real world signal. We modulate real voice and text data sets onto the signal. In the case of digital modulation we whiten the data using a block randomizer to induce an independent random distribution among bits.\nChannel effects are relatively well characterized. This is where we must make simplifying assumptions, but we employ robust and reasonably approximate models for time varying multi-path fading of the channel impulse response, random walk drifting of carrier frequency oscillator and sample time clocks, and additive Gaussian white noise. Here we pass our synthetic signal sets through harsh channels perturbed by harsh offset effects which introduce unknown scale, translation, dilation, impulsive noise, and unknown modulated data bits onto our signal.\nWe model the generation of the dataset in GNU Radio (Blossom, 2004) using the GNU Radio channel model (O’Shea, 2013) blocks and then slice each time series signal up into a test set using a rectangular windowing process of 128 samples. The total dataset is roughly 500 MBytes stored as a python pickle file with complex 32 bit floating point samples."
    }, {
      "heading" : "3.1. Dataset Availability",
      "text" : "This data set will be of great use to others in the field and will begin to serve as a benchmark for this important application domain among machine learning researchers. We plan to make this dataset available both through the generative simulation model and parameters required to reproduce the data set, and as a python pickle file storing a fixed training and test set consisting of time-windowed examples and corresponding modulation classes. We hope to grow both\nthe scope of modulations addressed, the realism of channel models applied, and the relevance of signals considered in coming years as interest in this area as a pure machine learning problem grows."
    }, {
      "heading" : "3.2. Dataset Parameters",
      "text" : "We focus on a dataset consisting of 11 modulations: 8 digital and 3 analog modulation, all of which are widely used in every day wireless communications systems all around us. These consist of BPSK, QPSK, 8PSK, 16QAM, 64QAM, BFSK, CPFSK, and PAM4 for digital modulations, and WB-FM, AM-SSB, and AM-DSB for analog modulations. Data is modulated at a rate of approximately 8 samples per symbol with a normalized average transmit power of 0dB."
    }, {
      "heading" : "3.3. Dataset Plots",
      "text" : "Looking at a single example of each class of signal in the time domain, we see a number of similarities and differences between the types of modulations visually, but due to the use of a pulse shaping signal they are not all immediately discernible by an expert human viewer.\nViewing signal power of each of these signals in the frequency domain, we see that many of the signals follow a similar envelope by design and are not easily discernible to a human expert."
    }, {
      "heading" : "3.4. Modulated Information",
      "text" : "In radio communications, signals are typically comprised of a number of modulated data nits on well defined and understood basis functions into discrete modes formed by these bases. Complex baseband representation of a signal decomposes a radio voltage level time-series into its projections onto the sine and cosine functions at some carrier frequency. By manipulating the frequency, amplitude,\nphase, or sum thereof data bits are then modulated into this space through discrete and separable modes for each distinct symbol period in time in the case of digital, or continuous location in the case of analog modulation. For the case of QPSK this phase-mapping is shown in 4.\ns(ti) = e j2πfct+π\n2ci+1\n4 , ci ∈ 0, 1, 2, 3 (4)\nPulse shaping filters such as root-raised cosine are then typically applied to band-limit the signal in frequency and remove sharp wide-band transients between these distinct modes, resulting in mixing of adjacent symbols’ bases at the transmitter in a deterministic and invertible. In our simulated data set we use a root-raised cosine pulse shaping filter with an excess bandwidth of 0.35 for each digital signal."
    }, {
      "heading" : "3.5. Effects on the Modulated Signal",
      "text" : "Channel effects in contrast are not deterministic and not completely invertible in a communications system. Real systems experience a number of effects on the transmitted signal, which make recovery and representation thereof challenging. Thermal noise results in relatively flat white Gaussian noise at the receiver which forms a noise floor or sensitivity level and signal to noise ratio. Oscillator drift due to temperature and other semiconductor physics differing at the transmitter and receiver result in symbol timing offset, sample rate offset, carrier frequency offset and phase difference. These effects result in a temporal shifting, scaling, linear mixing/rotating between channels, and spinning of the received signal based on unknown time varying processes. Last, real channels undergo random filtering based on the arriving modes of the transmitted signal at the receiver with varying amplitude, phase, Doppler, and delay. This is a phenomenon commonly known as multi-path fad-\ning or frequency selective fading, which occurs in any environment where signals may reflect off buildings, vehicles, or any form of reflector in the environment. This is typically removed at the receiver by the estimation of the instantaneous value of the time varying channel response and deconvolution of it from the received signal."
    }, {
      "heading" : "3.6. Generating a dataset",
      "text" : "To generate a well characterized dataset, we select a collection of modulations which are used widely in practice and operate on both discrete binary alphabets (digital modulations), and continuous alphabets (analog modulations). We modulate known data over each modem and expose them each to the channel effects described above using GNU Radio. We segment the millions of samples into a dataset consisting of numerous short-time windows in a fashion similar to how a continuous acoustic voice signal is typically windowed for voice recognition tasks. We extract steps of 128 samples with a shift of 64 samples to form our extracted dataset.\nAfter segmentation, examples are roughly 128 µ sec each assuming a sample rate of roughly 1 MSamp/sec. Each contains between 8 and 16 symbols with random time offset, scaling, rotation, phase, channel response, and noise. These examples represent information about the modulated data bits, information about how they were modulated, information about the channel effects the signal passed through during propagation, and information about the state of the transmitted and receiver device states and contained random processes. We focus specifically on recovering the information about how the signal was modulated and thus label the dataset according to a discrete set of 11 class labels corresponding to the modulation scheme."
    }, {
      "heading" : "4. Technical Approach",
      "text" : "In a radio communication system, one class of receiver which is commonly considered is a ”matched-filter” receiver. That is on the receive side of a communications link, expert designed filters matched with each transmitted symbol representation are convolved with the incoming time signal, and form peaks as the correct symbol slides over the correct symbol time in the received signal. By convolving, we average out the impulsive noise in the receiver in an attempt to optimize signal to noise. Typically, before this convolutional stage, symbol timing and carrier frequency is recovered using an expert envelope or moment based estimators derived analytically for a specific modulation and channel model. The intuition behind the use of a convolutional neural network in this application then is that they will learn to form matched filters for numerous temporal features, each of which will have some filter gain to operate at lower SNR, and which when taken together can\nform a robust basis for classification."
    }, {
      "heading" : "4.1. Learning Invariance",
      "text" : "Many of these recovery processes in radio communications systems can be thought of in terms of invariance to linear mixing, rotation, time shifting, scaling, and convolution through random filters (with well characterized probabilistic envelopes and coherence times). These are analogous to similar learning invariance which is heavily addressed in vision domain learning where matched filters for specific items or features in the image may undergo scaling, shifting, rotation, occlusion, lighting variation, and other forms of noise. We seek to leverage the shift-invariant properties of the convolutional neural network to be able to learn matched filters which may delineate symbol encoding features naively, without expert understanding or estimation of the underlying waveform."
    }, {
      "heading" : "4.2. Evaluation Network",
      "text" : "We train against a 4-layer neural network, utilizing two convolutional layers and two dense fully connected layers. We use a rectified linear activation function for the first three and a Softmax activation on the last to choose the output class. Regularization is used to prevent overfitting by adding a ‖W‖2 norm penalty on the convolutional layer weights, encouraging minimum energy bases, and a ‖h‖1 norm penalty on the first dense layer activation, to encourage sparsity of solutions (Lee et al., 2006) (Zeiler et al., 2010). Dropout (Srivastava et al., 2014) is used to prevent over specialization of network units and training is conducted using a categorical cross entropy loss function. We use the Adam (Kingma & Ba, 2014) solver for optimization, an efficient momentum based form of stochastic gradient descent, and implement our network learning and inference using Keras (Chollet, 2015) running on top of TensorFlow (Abadi et al., 2015) on an NVIDIA Cuda (Nvidia, 2007) enabled Titan X GPU in a DIGITS Devbox.\nAn illustration of our Convolutional deep neural network architecture is shown in figure 3."
    }, {
      "heading" : "4.3. Training Complexity",
      "text" : "We train our model for approximately 9 minutes, performing 24 epochs for Adam-SGD over the ∼ 900, 000 sample training set in batch sizes of 1024 for 24 epochs, each taking approximately 22 seconds to complete. We observe some over-fitting on the training set beyond 13 epochs, but validation loss does not suffer significantly and performance at higher SNR seems to improve when we look at loss vs SNR separately. Our training loss curves are shown in figure 4."
    }, {
      "heading" : "4.4. Learned Features",
      "text" : "Plotting the learned features can sometimes give us an intuition as to what the network is learning about the underlying signal. In this case, we plot the convolutional layer 1 and convolutional layer 2 filter weights below. In figure 5, the first layer, we have 64 filters of 1x3. In this case we simply get a set of 1D edge and gradient detectors which operate across the I and the Q channel.\nIn convolutional layer 2, weights shown in figure 6 we compose this first layer feature map into 64*16x2x3 slightly larger feature maps, which comprise what is occurring on each adjacent I and Q channel, and what is occurring directly before and after each sample in time. These feature maps do not look hugely different than those seen at the lower levels of an image conv-net comprising of 2D learned edge detectors and Gabor-like filters."
    }, {
      "heading" : "5. Results",
      "text" : "To evaluate the performance of our classifier, we look at classification performance on a test data set. We train on a corpus of approximately 12 million complex samples divided across the 11 modulations. These are divided into training examples of 128 samples in length. We use approximately 96,000 example for training, and 64,000 examples for testing and validation. These samples are uniformly distributed in SNR from -20dB to +20dB and tagged so that we can evaluate on specific subsets of each set.\nAfter training, we achieve roughly a 64.4% classification accuracy across all signal to noise ratios on the test dataset, but to understand the meaning of this we must inspect how this classification accuracy breaks down across the SNR values of the different training examples, and how it compares to existing style expert feature based classifiers.\nIn the most rapidly digestible form, we compute the overall test accuracy at each discrete signal to noise ratio and plot accuracy as a function of SNR for each classifier type. In this case, classifiers all use expert cumulant features with the exception of the ConvNet using learned features directly on the sampled radio time series. This plot of the accuracy as a function of the SNR is perhaps the most interesting way to compare their performance in varying environments and one of the most important metrics used in wireless communications when selecting a best performing\nmethod for a given operating environment. In figure 7, we can see the ConvNet generally outperforms the classification accuracy on the cumulant features by 5 to 10 dB of SNR throughout the data set, a significant margin.\nFor our highest SNR case ConvNet classification we show a confusion matrix in figure 8. It shows that at +18dB SNR, we have a very clean diagonal in the confusion matrix and we can see our primary remaining discrepancies are that of 8PSK misclassified as QPSK, and WBFM misclassified as AM-DSB. Both of these are reasonably explainable in the underlying dataset. For instance, an 8PSK symbol containing the correct bits/symbols for a certain number of subsequent symbols is indiscernible from QPSK since the QPSK constellation points are spanned by that subset of 8PSK. In the case of the analog modulations, there are periods of\ntime when the underlying analog voice signal is actually idle or empty and the empty carrier tone is identical between the two for the time span of one test case. Therefore, we cannot expect to obtain 100% accuracy at high SNR on this data set and can expect that no unexplainable confusions seem to remain in the classifier.\nTo better understand how the performance differs for these approaches at varying SNR levels, we show confusion matrices of classifier performance at several interesting SNR levels to compare performance at very low (-10dB), low (0dB), and moderate (10dB) SNR levels.\nInspecting the very low SNR confusion matrices in figure 9, 10, 11, and 12 we can see that classification at -10dB is challenging and we have very little diagonal grouping of correct classes in any classifier at this point. In the case of the ConvNet, we begin to distinguish effectively between a few classes, but still have relatively abysmal performance.\nMoving up to a more moderate low SNR, we inspect the performance of each classifier again at 0dB signal to noise ratio.\nAt low SNR in figures 13, 14, 15, and 16, we see some of the most differentiated performance. At this point the\nConvNet has a very accurate and well defined diagonal for almost all classes, while the others still have largely underdefined but recognizable diagonals.\nAt moderate SNR (+10dB), we can now see in figures 17, 18, 19, and 20, strong well-defined diagonals for all except the SVM based classifier."
    }, {
      "heading" : "6. Conclusions",
      "text" : "While these results should not form a comprehensive comparison of existing best case expert feature based modulation classifiers, they demonstrate that compared to a rel-\natively well regarded approach, blind Convolutional Networks on time series radio signal data is a viable and attractive alternative method. In figure 7, we demonstrate a significant accuracy to SNR classification advantage of this classifier and believe that for such short data examples (128 complex samples), this represents a powerful and state of the art accuracy modulation classification capability which holds the potential to continue to adapt and learn numerous additional modulation types beyond the 11 tested here. This method should be considered a strong candidate for DSA and CR systems which rely on robust low SNR classification of radio emitters."
    }, {
      "heading" : "7. Future Work",
      "text" : "Our results compare to a reasonable approximation of the current best expert system approach, but because no robust competition data sets exist in the emerging field of machine learning in the radio domain, it is difficult to directly compare performance to current state of the art approaches. In later work, we hope to more robustly compare state of the art expert feature based systems with non-zero-delay cyclic cumulants in addition to the zero-delay cumulants evaluated in this work. Additional refinements are possible [inevitable] on the ConvNet network architecture, as we expended some effort on attempting to optimize the network structure, regularization and other learning parameters, but did not do so exhaustively. Larger filters or differently arranged filters along with varying pooling layer strategies may affect performance significantly, but were not fully investigated for their suitability. Numerous additional techniques could be applied to the problem including the introduction of invariance to additional channel induced effects such as dilation, I/Q imbalance, phase offset and others. Spatial Transformer Networks (Jaderberg et al., 2015) have demonstrated a powerful ability to learn this type of invariance on image data and may serve as an interesting candidate for enabling improved invariance learning to these effects. Sequence models and recurrent layers (Graves et al., 2013) which may represent the progression of a signal in some embedding will almost certainly prove to be a valuable tool in representing these forms of signals as well, but we have yet to investigate this area fully.\nThis application domain is ripe for a wide array of further investigation which will define and drive the future state of the art in wireless signal processing and cognitive radio capabilities."
    } ],
    "references" : [ {
      "title" : "TensorFlow: Large-scale machine learning",
      "author" : [ "Fernanda", "Vinyals", "Oriol", "Warden", "Pete", "Wattenberg", "Martin", "Wicke", "Yu", "Yuan", "Zheng", "Xiaoqiang" ],
      "venue" : "on heterogeneous systems,",
      "citeRegEx" : "Fernanda et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Fernanda et al\\.",
      "year" : 2015
    }, {
      "title" : "Applications of machine learning to cognitive radio networks",
      "author" : [ "Clancy", "Charles", "Hecker", "Joe", "Stuntebeck", "Erich", "O’Shea", "Tim" ],
      "venue" : "Wireless Communications,",
      "citeRegEx" : "Clancy et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Clancy et al\\.",
      "year" : 2007
    }, {
      "title" : "Signal interception: performance advantages of cyclic-feature detectors",
      "author" : [ "Gardner", "William A", "Spooner", "Chad M" ],
      "venue" : "Communications, IEEE Transactions on,",
      "citeRegEx" : "Gardner et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Gardner et al\\.",
      "year" : 1992
    }, {
      "title" : "Speech recognition with deep recurrent neural networks",
      "author" : [ "Graves", "Alex", "Mohamed", "Abdel-rahman", "Hinton", "Geoffrey E" ],
      "venue" : "CoRR, abs/1303.5778,",
      "citeRegEx" : "Graves et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Graves et al\\.",
      "year" : 2013
    }, {
      "title" : "Spatial transformer networks",
      "author" : [ "Jaderberg", "Max", "Simonyan", "Karen", "Zisserman", "Andrew", "Kavukcuoglu", "Koray" ],
      "venue" : "CoRR, abs/1506.02025,",
      "citeRegEx" : "Jaderberg et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Jaderberg et al\\.",
      "year" : 2015
    }, {
      "title" : "Cyclostationary approaches to signal detection and classification in cognitive radio. In New frontiers in dynamic spectrum access",
      "author" : [ "Kim", "Kyouwoong", "Akbar", "Ihsan A", "Bae", "Kyung K", "Um", "Jung-Sun", "Spooner", "Chad M", "Reed", "Jeffrey H" ],
      "venue" : null,
      "citeRegEx" : "Kim et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2007
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Kingma", "Diederik P", "Ba", "Jimmy" ],
      "venue" : "CoRR, abs/1412.6980,",
      "citeRegEx" : "Kingma et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma et al\\.",
      "year" : 2014
    }, {
      "title" : "Dynamic spectrum policies: promises and challenges",
      "author" : [ "Kolodzy", "Paul J" ],
      "venue" : "CommLaw Conspectus,",
      "citeRegEx" : "Kolodzy and J.,? \\Q2004\\E",
      "shortCiteRegEx" : "Kolodzy and J.",
      "year" : 2004
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing",
      "author" : [ "Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E" ],
      "venue" : null,
      "citeRegEx" : "Krizhevsky et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Efficient sparse coding algorithms",
      "author" : [ "Lee", "Honglak", "Battle", "Alexis", "Raina", "Rajat", "Ng", "Andrew Y" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "Lee et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2006
    }, {
      "title" : "Cognitive radio: making software radios more personal",
      "author" : [ "Mitola III", "Joseph", "Maguire Jr.", "Gerald Q" ],
      "venue" : "Personal Communications, IEEE,",
      "citeRegEx" : "III et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "III et al\\.",
      "year" : 1999
    }, {
      "title" : "Gnu radio channel simulation",
      "author" : [ "O’Shea", "Tim" ],
      "venue" : "In GNU Radio Conference",
      "citeRegEx" : "O.Shea and Tim.,? \\Q2013\\E",
      "shortCiteRegEx" : "O.Shea and Tim.",
      "year" : 2013
    }, {
      "title" : "Application of artificial intelligence to wireless communications",
      "author" : [ "Rondeau", "Thomas W" ],
      "venue" : "PhD thesis, Virginia Polytechnic Institute and State University,",
      "citeRegEx" : "Rondeau and W.,? \\Q2007\\E",
      "shortCiteRegEx" : "Rondeau and W.",
      "year" : 2007
    }, {
      "title" : "Learning the speech frontend with raw waveform cldnns",
      "author" : [ "Sainath", "Tara N", "Weiss", "Ron J", "Senior", "Andrew", "Wilson", "Kevin W", "Vinyals", "Oriol" ],
      "venue" : "In Proc. Interspeech,",
      "citeRegEx" : "Sainath et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sainath et al\\.",
      "year" : 2015
    }, {
      "title" : "Dropout: A simple way to prevent neural networks from overfitting",
      "author" : [ "Srivastava", "Nitish", "Hinton", "Geoffrey", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Srivastava et al\\.,? \\Q1929\\E",
      "shortCiteRegEx" : "Srivastava et al\\.",
      "year" : 1929
    }, {
      "title" : "Deconvolutional networks",
      "author" : [ "Zeiler", "Matthew D", "Krishnan", "Dilip", "Taylor", "Graham W", "Fergus", "Rob" ],
      "venue" : "In Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "Zeiler et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Zeiler et al\\.",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "In the past few years the trend in machine learning, primarily in image processing (Krizhevsky et al., 2012) and voice recognition (Sainath et al.",
      "startOffset" : 83,
      "endOffset" : 108
    }, {
      "referenceID" : 13,
      "context" : ", 2012) and voice recognition (Sainath et al., 2015), is overwhelmingly that of feature learning from data.",
      "startOffset" : 30,
      "endOffset" : 52
    }, {
      "referenceID" : 5,
      "context" : "(Kim et al., 2007) (Clancy et al.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 1,
      "context" : ", 2007) (Clancy et al., 2007) (Rondeau, 2007)",
      "startOffset" : 8,
      "endOffset" : 29
    }, {
      "referenceID" : 9,
      "context" : "Regularization is used to prevent overfitting by adding a ‖W‖2 norm penalty on the convolutional layer weights, encouraging minimum energy bases, and a ‖h‖1 norm penalty on the first dense layer activation, to encourage sparsity of solutions (Lee et al., 2006) (Zeiler et al.",
      "startOffset" : 242,
      "endOffset" : 260
    }, {
      "referenceID" : 15,
      "context" : ", 2006) (Zeiler et al., 2010).",
      "startOffset" : 8,
      "endOffset" : 29
    }, {
      "referenceID" : 4,
      "context" : "Spatial Transformer Networks (Jaderberg et al., 2015) have demonstrated a powerful ability to learn this type of invariance on image data and may serve as an interesting candidate for enabling improved invariance learning to these effects.",
      "startOffset" : 29,
      "endOffset" : 53
    }, {
      "referenceID" : 3,
      "context" : "Sequence models and recurrent layers (Graves et al., 2013) which may represent the progression of a signal in some embedding will almost certainly prove to be a valuable tool in representing these forms of signals as well, but we have yet to investigate this area fully.",
      "startOffset" : 37,
      "endOffset" : 58
    } ],
    "year" : 2016,
    "abstractText" : "We study the adaptation of convolutional neural networks to the complex temporal radio signal domain. We compare the efficacy of radio modulation classification using naively learned features against using expert features, which are currently used widely and well regarded in the field and we show significant performance improvements. We show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task.",
    "creator" : "LaTeX with hyperref package"
  }
}