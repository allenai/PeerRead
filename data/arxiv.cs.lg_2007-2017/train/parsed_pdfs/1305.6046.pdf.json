{
  "name" : "1305.6046.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Sidahmed Mokeddem", "Baghdad Atmani", "Mostéfa Mokaddem" ],
    "emails" : [ "sid_wise@hotmail.com", "atmani.baghdad@gmail.com", "mmemus@gmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Sundarapandian et al. (Eds) : CSE, CICS, DBDM, AIFL, SCOM - 2013 pp. 41–51, 2013. © CS & IT-CSCP 2013 DOI : 10.5121/csit.2013.3305\nFeature Selection (FS) has become the focus of much research on decision support systems\nareas for which datasets with tremendous number of variables are analyzed. In this paper we present a new method for the diagnosis of Coronary Artery Diseases (CAD) founded on Genetic Algorithm (GA) wrapped Bayes Naïve (BN) based FS.\nBasically, CAD dataset contains two classes defined with 13 features. In GA–BN algorithm, GA\ngenerates in each iteration a subset of attributes that will be evaluated using the BN in the second step of the selection procedure. The final set of attribute contains the most relevant feature model that increases the accuracy. The algorithm in this case produces 85.50% classification accuracy in the diagnosis of CAD. Thus, the asset of the Algorithm is then\ncompared with the use of Support Vector Machine (SVM), Multi-Layer Perceptron (MLP) and C4.5 decision tree Algorithm. The result of classification accuracy for those algorithms are respectively 83.5%, 83.16% and 80.85%. Consequently, the GA wrapped BN Algorithm is correspondingly compared with other FS algorithms. The Obtained results have shown very\npromising outcomes for the diagnosis of CAD.\nKEYWORDS\nBayes Naïve, Best First Search, C4.5, Coronary Artery Disease, Feature Selection, Genetic\nAlgorithm, Machine Learning, Multi-Layer Perceptron, Sequential Floating Forward Search, Support Vector machine."
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Some studies have proven that CAD is the leading cause of death in countries under development such as Algeria. It is estimated that 45% of deaths in Algeria are due to cardiovascular disease [7]. The risk of cardiovascular disease is linked by various factors such as environmental, psychological, genetic, demographic variables and health services. Many of these diseases require surgical treatment, most of these surgical interventions are expensive, and normal population cannot have such interventions. Moreover, the diagnosis of CAD is challenging, particularly when there is no symptom. Much information from patients is needed. Hence, the necessity of prevention systems and to predict risk factors for these diseases in order to take preventive measures is primordial.\nWith the increasing complexity in recent years, a large amount of information in the medical field is stored in electronic form such as the electronic patient record. These data are stored and used primarily for the management and analysis of the patient population. They are frequently used for research, evaluation, planning and other purposes by various users in terms of analysis and forecasting of the health status of individuals.\nAutomated medical diagnostic approaches are mainly based on a Machine Learning (ML) algorithm. Subsequently, they are trained to learn decision characteristics of a physician for an explicit disease and then they can be used to support physician decision making to diagnose future patients of the same disease [1, 2].Inappropriately, there is no common model that can be adjusted for the diagnosis of all kinds of diseases [3].\nA large number of features that can surpass the number of data themselves often characterizes the data used in ML. This problem known as \"the curse of dimensionality\" creates a challenge for various ML applications for decision support. This can increase the risk of taking into account correlated or redundant attributes which can lead to lower classification accuracy [4, 5, 6].\nTherefore, the process of eliminating irrelevant features is a vital phase for designing decision support systems with high accuracy. Therefore, the key objective of this paper is to design a FS approach to reduce dimension of CAD dataset and to obtain higher accuracy classification rates. The GA wrapped BN consists of a two-step process: In the first step, we generate a subset of features, the dimension of data is reduced using the GA algorithm running in parallel with BN. Accordingly, after the new subset feature model is obtained, a BN classifier is used to measure feature model accuracy. A10-fold cross-validation strategy has been used for validating the obtained model. Then, the proposed approach is also compared with four additional ML algorithms: SVM, MLP and C4.5. Additionally, the proposed algorithm is compared with other FS Algorithms.\nThe rest of the paper is planned as follows. The next section introduces a literature survey for CAD problem. Section 3 describes CAD and it is followed by a global introduction to FS strategies. In Section 4, The ML methods are introduced used to evaluate the accuracy of the feature model obtained by GA wrapped BN algorithm and the proposed approach is then explained and presented. In Section 5, experimental results are discussed and the conclusion is presented in Sections 6."
    }, {
      "heading" : "2. RELATED WORKS",
      "text" : "A Multiple studies have been proposed in the context of Fuzzy Logic Rule based for diagnosis of CAD. In [8] proposed a system for detecting the risk level for heart disease. This system consists of two phases, the first is the generation of fuzzy rules, and the second is the construction of a rule inference engine based on rules generated. Tsipouras et al. [9] have proposed a four stage system for decision support based on fuzzy rules: 1) construction of a decision tree from the data, 2) the extraction of rules from the tree, 3) the transformation rules from the rough form to fuzzy one and 4 ) and the model optimization. They obtained a classification accuracy of 65%. Another work in this context [10] have developed a fuzzy system. They extracted the rules using an extraction method based on Rough Set Theory [11]. The rules then are selected and fuzzified, after that, they weighted the rules using the information of support. The results showed that the system is able to have a better prediction percentage of CAD than cardiologists and angiography. Three expert cardiologists validate the system. Patil et al. [12] have proposed an intelligent system for predicting heart attacks; in order to make the data ready to be analyzed they integrate them into a data warehouse. Once the data is in the data warehouse, they built clusters using the K-means method to build groups of similar individuals. Therefore, with the help of the algorithm MAFIA, the frequent sequences appropriate for the preaching of heart attacks were extracted. With the use of frequent sequences as training set and the back propagation algorithm, the neural network was used. The results were satisfied in terms of prediction. In this study [13], the authors have used\ntechniques of data mining to study the risk factors that contribute significantly to the prediction of coronary artery syndromes. They assumed that the class is the diagnosis - with dichotomous values indicating the presence or absence of disease. They applied the binary regression. The data were taken from two hospitals of Karachi, Pakistan. For better performance of the model, a data reduction technique such as principal component analysis ACP was applied. Fidele et al [14] used techniques of artificial intelligence as the basis for evaluating risk factors for CAD. A two-layer perceptron that uses the Levenberg-Marquardt algorithm and back propagation. They have shown the efficiency of their system by applying it to the Long Beach data set."
    }, {
      "heading" : "3. CORONARY ARTERY DISEASE",
      "text" : "CAD includes a multitude of diseases related to the heart and circulatory system. Cardiovascular disorders are the most common coronary artery disease, which relate to the arteries of the heart, and include, among others, angina, heart failure, myocardial infarction (heart attack) and stroke brain (stroke) that occur when the brain receives inadequate blood supply.\nLike all medical fields and to prevent cardiovascular disease, one of the possible solutions is to make people aware of their CAD risks in advance and take preventive measures accordingly. According to experts, early detection of CAD at the stage of angina can prevent the death if the proper medication is given by the following. This is where the importance of developing a system for the diagnosis of CAD to assist the physicians to prevent from such Pathology. Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].\nPatients were evaluated using 14 features. The data set is taken from the Data Mining Repository of the University of California, Irvine (UCI) [19]. To end with the system is tested using Cleveland data sets. Features such as Age, sex, chest pain type, resting blood pressure, serum cholesterol in mg/dl, fasting blood sugar, resting electrocardiographic results, maximum heart rate achieved, exercise induced angina, ST depression, slope of the peak exercise ST segment, number of major vessels, thal and the diagnosis of heart disease are presented."
    }, {
      "heading" : "4. FEATURE SELECTION APPROACH",
      "text" : "FS is an active area of research and in development in various applications (indexing and retrieval of images, genomic analysis, document analysis...). A large number of algorithms have been proposed in the literature for unsupervised, supervised and semi-supervised FS. According to Dash et al., [20] a selection process of attributes is usually composed of four steps illustrated in Figure 1.\nThe generation procedure allows, in each iteration, to generate a subset of attributes that will be evaluated in the second step of the selection procedure. This procedure of generation either can start with an empty set of attributes or with the set of all attributes or with a subset of attributes selected randomly. In the first two cases, attributes are added iteratively (forward selection) or removed (Backward selection) [21]. Some other algorithms hybrid both concepts as Sequential Forward Floating Selection technique that apply, after each step Forward, Backward steps while the selected subset improves the evaluation function [22]. In the third case, a new subset of\nattributes is created randomly at each iteration (random generation).Genetic algorithms, introduced by Holland in 1975 [23] are the most common methods used for random generation [24].\nAccording to the evaluation criteria used in the selection process of attributes, we can distinguish between Wrapper approaches and Filter approaches. Wrapper Approaches use the classification accuracy rate as evaluation criteria [25]. Filter Approaches use an evaluation function based on the characteristics of the dataset, regardless of any classification algorithm, to select certain attributes or a subset of attributes (information measures, consistency measures, dependence measures and distance measures) [26][27]."
    }, {
      "heading" : "4.1. The proposed Methodology",
      "text" : "The random generation procedures explore randomly all 2n subset candidates, which n is the number of features in the database. A subset is therefore not the result of an increase or decrease of features from the previous subset. This cannot stop the search when the evaluation function of a subset reached a local optimum. However, the 2n subsets candidates are not all evaluated. Thus, a maximum number of iterations are imposed to ensure that computation time remains reasonable.\nIn our proposed Methodology, we make use of GA for the generation process Figure 2. GA is an adaptive heuristic search algorithm premised on the evolutionary ideas of natural selection and genetic. In our use of genetic algorithms, a subset of features is encoded as a chromosome. This group of chromosomes, i.e. population, is the search space of the algorithm. The fitness function used to evaluate performance of each chromosome (subset of features) to measure its nearness to solution. Accordingly, our study makes use of the BN Algorithm as a fitness function. The initial subsets of features (chromosomes) as parents are used to produce new subsets of features using genetic operators explicitly selection, mutation and crossover. At each iteration, the number of chromosomes in the population is always constant with removing features having lowest fitness value. This process is reiterated until a best subset of features is found or the maximum number of iterations is attained [28].We propose a new GA Wrapped BN methodology for identifying relevant features of CAD diagnosis Figure 2."
    }, {
      "heading" : "17 end for",
      "text" : ""
    }, {
      "heading" : "16 Calculate accuracy for k",
      "text" : ""
    }, {
      "heading" : "14 Train BN",
      "text" : ""
    }, {
      "heading" : "13 End for",
      "text" : ""
    }, {
      "heading" : "12 Replace chromosomes with lowest fitness of 7 by best chromosomes with highest fitness of 11",
      "text" : ""
    }, {
      "heading" : "10 Apply Binary Mutation with probability of 0.09",
      "text" : ""
    }, {
      "heading" : "9 Apply Binary Crossover with probability of 0.2",
      "text" : ""
    }, {
      "heading" : "7 Generate randomly a population of 20 chromosomes",
      "text" : ""
    }, {
      "heading" : "6 Encode features as binary chromosomes",
      "text" : ""
    }, {
      "heading" : "5 for number_generation=1 to 40",
      "text" : ""
    }, {
      "heading" : "3 Test_DATA_all =(1 fold for BN",
      "text" : ""
    }, {
      "heading" : "2 For k=1 to 10",
      "text" : ""
    }, {
      "heading" : "1 Split Dataset into 10 folds",
      "text" : "In our model, we encoded features as binary strings of 1 and 0. In this pattern, 1 signifies selection of a feature and 0 means a non-selection. The number of genetic factor in the chromosome is equivalent to 14, which is the size of the features of CAD dataset. The population consist of the number of chromosomes in the search space and we have chosen 20 as the population size. Therefore, the first population (parent) is generated randomly. We make use of BNevaluator as a fitness function, generally a fitness function evaluate the relevance of chromosome. Accordingly, in our case the relevance of chromosomes is represented by classification accuracy of the BNevaluator, so the aptness of a chromosome to be gathered depends on his accuracy rank obtained from the fitness function (BNevaluator) at each iteration. For generation process of chromosomes, we make use of three genetic operators. The selection operator depends of the fitness function, so most relevant chromosomes are retained for each turn. Crossover operator make a two-point substring exchange between two chromosomes to generate two new chromosomes with probability of 0.2. In mutation Operator, the selected genetic factors are inverted to avoid the search process not to get fixed in local maxima. With a mutation probability of 0.09.\nThe proposed Algorithm make use of the three Operators, termination criteria for the selection process is the number of generations. It stopped when the number of generation is equal to 40 Figure 2. Line 5. The proposed algorithm have two loops imbricate in each other, the first loop Figure 2. Line 5 contains the generation process. First, the features are encoded as binary chromosomes Figure 2. Line6 then a new population is generated randomly Figure 2. Line 7. The generated population is evaluated using the fitness function (BNevaluator). Formerly, we apply the Genetic Operators respectively Crossover Figure 2. Line 9 and mutation Figure 2. Line 10. The new generated population is evaluated with BNevaluator and then compared with that generated in Figure 2. Line 7. In the second, loop Figure 2. Line 2, the 9 folds set Figure 2. Line 4 with optimized new features of loop Figure 2. Line 5 is used as the train set for BNevaluator. Having trained BNwrapper algorithm with this train set, the algorithm is used to classify instances of reserved test set Figure 2. Line 3. This process is reiterated 10 times with shifting folds recursively to achieve an average classification accuracy."
    }, {
      "heading" : "4.2. Feature Selection Techniques used in this study",
      "text" : "In order to evaluate the efficacy of our proposed GN wrapped BN technique, we compare our methodology with another two FS wrapped methodologies. The two methodologies are based on BN algorithm. The first one uses the Best First Search (BFS) as a generation technique. BFS is a search algorithm that explores a graph by expanding the most promising node with the best score which will be evaluated using the wrapped BN [29].In the second methodology we generate the subset of features using the Sequential Floating Forward Search (SFFS). This technique is derived from the sequential forward generation techniques. The principle of such techniques is to add one or more attributes progressively. However, as they do not explore all possible subsets of attributes and cannot backtrack during the search, so they are suboptimal. SFFS after each step Forward, it applies Backward steps while the subset corresponding improves the efficacy of wrapped BN [30]."
    }, {
      "heading" : "4.3. Machine Learning techniques used in our study",
      "text" : "Our proposed methodology selects the most pertinent features from CAD dataset and it produces promising diagnosis accuracy. Nevertheless, to study the effectiveness of the selected features with other ML algorithms. In this section, we introduce generally those algorithms."
    }, {
      "heading" : "4.3.1. Naïve Bayes",
      "text" : "One of the Bayesian approaches is NB. All of Bayesian approaches use Bayes formula (1). The main hypothesis of this kind of methods is independency of features. Thus, when features are dependent on each other, this algorithm produce a low classification accuracy [31].\n(1)"
    }, {
      "heading" : "4.3.2. C4.5 Tree Algorithm",
      "text" : "One of the important decision tree algorithms is C4.5 [32]. This algorithm can deal with all kinds of data. It uses pruning techniques to increase accuracy and Gain Ratio for selecting features. For instance, C4.5 can use a pruning algorithm such as reduce error pruning and it increases accuracy of the algorithm. One of its parameters is M, which the minimum number of instances that a leaf should have. The second one is C, it is threshold for confidence, and it is used for pruning process."
    }, {
      "heading" : "4.3.3. Support Vector Machine",
      "text" : "SVM method is a supervised ML method, used for classification. It is widely used to produce a predicting model. For each given test input, SVM predicts which of two possible classes forms the input, making it a non-probabilistic binary linear classifier [33]. Given a training se of instance label pairs , i=1,……,r, where and . SVM involves the resolution of the problem given by (2)\nWith (2)\nIn (2), are training vectors and they are mapped into a higher dimensional space by the function . The C is the decision parameter for the error term. SVM finds a linear separating hyper plane with the highest margin in the dimensional space. Accordingly, the solution of (2) permit only a linear separation solution. Conversely, the use of a kernel allows nonlinear separation using a kernel function (linear, polynomial, radial basis and sigmoid kernel). In our study, we use the polynomial kernel."
    }, {
      "heading" : "4.3.4. Multi-Layer Perceptron",
      "text" : "MLP is feed-forward neural networks trained with the standard back-propagation algorithm [34]. It is supervised networks, so it learns based on an input data to conclude a desired response, so they are widely used for pattern classification. MLP contain one or two hidden layers. Obviously, the structure of MLP consists of an input and an output layer with one or more hidden layers. And\nfor each node in one layer is linked to every node in the following layer with a weight of .In MLP, the learning task occurs while the weights of nodes are updated with the use of back propagation method and the amount of error in the output compared to the desired result. More explicitly, error in output node j in the nth data point is represented by (3).\n(3)\nIn the equation, d is the desired value and y is the value produced by the MLP. Then, updating the weights (5) of the nodes based on those corrections, which minimize the entire output error, must be assessed and this is given by (4).\n(4)\n(5)\nWhere the output of the previous neuron and is the learning rate. In our experiments, we uses a learning rate of 0.3 and training time as 500 iterations."
    }, {
      "heading" : "5. EXPERIMENTS AND RESULTS",
      "text" : "For experimentation, we have chosen UCI CAD dataset, which is broadly accepted databases acquired from the UCI machine learning repository. In the testing phase, the testing dataset is given to the system to find the risk forecast of heart patients and achieved results are evaluated with the evaluation metric accuracy [35].\nAccuracy is the typically used measure to evaluate the efficacy ML method; it is used to reckon how the test was worthy and consistent. In order to calculate these metric, we first compute some of the terms like, True positive, True negative, False negative and False positive based on Table 1., where TP is the True positive, TN is the True negative, FN is the False negative and FP is the False positive.\nThe experiments are approved and for each of the proposed wrappers. We first calculated average accuracies of the wrapper algorithms coupled with BN classifier. In addition, each wrapper strategy produces feature subsets and we made experiments to measure effectiveness of these features with the use of the described ML methods (Section 4.3) used for CAD diagnosis. The results of the experiments are evaluated with average Accuracy. In order to show the relevance of FS strategies, we involved the performance of ML classifiers without FS in Table 3. Moreover, Table 2 delivers the list of features for CAD dataset and the selected subset of features generated by the wrapper algorithms."
    }, {
      "heading" : "BN SVM MLP C4.5",
      "text" : ""
    }, {
      "heading" : "5.1. Discussion",
      "text" : "Generally, results of our experiments and that from literature are presented in Figure 3. It is perceived that the proposed algorithm has the highest classification accuracy in the literature.\nThis study presents a GA wrapped BN classification model for diagnosis of CAD. The experimental results clearly show the efficiency of feature model selected by GA wrapper. In order to prove that, the proposed GA wrapper BN was compared with some other clinical systems from the literature. The algorithm was compared also with two wrapper FS methods (BFS and SFFS). The classification accuracies demonstrate the effectiveness of the features subset selected by GA."
    }, {
      "heading" : "6. CONCLUSIONS",
      "text" : "We have presented a new GA wrapped BN FS algorithm for the diagnosis of the heart disease. The automatic process to generate the subset of features is an advantage of the proposed algorithm. The proposed algorithm for CAD patients contains two steps such as: (1) generation of a subset of features and (2) and the evaluation of the system using BN ML technique. The experimental results demonstrate the strength of the proposed GA wrapped BN algorithm for selecting the most relevant features for efficient diagnosis of CAD diseases. Generally automated disease diagnosis problems need a reduction of Features space step to achieve high accuracy performance. Consequently, the proposed algorithm is applied to CAD disease."
    } ],
    "references" : [ {
      "title" : "Clinical decision support systems: a discussion on different methodologies used in health care",
      "author" : [ "M.M. Abbasi", "S. Kashiyarndi" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2006
    }, {
      "title" : "Total endoscopic coronary artery bypass grafting",
      "author" : [ "F. Volkmar", "T.A. Diegeler", "Walther" ],
      "venue" : "Eur J CardiothoracSurg,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2000
    }, {
      "title" : "Medical diagnostic decision support systems—past, present, and future: a threaded bibliography and brief commentary",
      "author" : [ "Miller RA" ],
      "venue" : "J Am Med Inform Assoc 1(1):8-27",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1994
    }, {
      "title" : "on the relationship between feature selection and classification accuracy",
      "author" : [ "W.N. Gansterer", "G.F. Ecker" ],
      "venue" : "Work",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2008
    }, {
      "title" : "The effect to diagnostic accuracy of decision tree classifier of fuzzy and k-NN based weighted pre-processing methods to diagnosis of erythemato-squamous diseases",
      "author" : [ "K. Polat", "S. Günes" ],
      "venue" : "Digital Signal Process",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2006
    }, {
      "title" : "Using support vector machines with a novel hybrid feature selection method for diagnosis of erythemato-squamous diseases",
      "author" : [ "J. Xie", "C. Wang" ],
      "venue" : "Expert Syst. Appl",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Automated diagnosis of coronary artery disease based on data mining and fuzzy modeling",
      "author" : [ "M.G. Tsipouras", "T.P. Exarchos", "D.I. Fotiadis", "A.P. Kotsia", "K.V. Vakalis", "K.K. Naka", "L.K. Michalis" ],
      "venue" : "IEEE Transactions on Information Technology in Biomedicine",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2008
    }, {
      "title" : "Diagnosis of coronary artery disease using artificial intelligence based decision support system",
      "author" : [ "N.A. Setiawan", "P.A. Venkatachalam", "A.F.M. Hani" ],
      "venue" : "Proceedings of the International Conference on Man-Machine Systems,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2009
    }, {
      "title" : "Intelligent and effective heart attack predic-tion system using data mining and artificial neural network",
      "author" : [ "S.B. Patil", "Y.S. Kumaraswamy" ],
      "venue" : "European Journal of Scientific Research",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2009
    }, {
      "title" : "Acute Coronary Syndrome prediction Using Data Mining Techniques- an Application",
      "author" : [ "Tahseen A. Jilani", "Huda Yasin", "MadihaYasin", "Cemal Ardil" ],
      "venue" : "World Academy of Science, Engineering and Technology,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2009
    }, {
      "title" : "Comparison of 18-lead ECG and selected body surface potential mapping leads in determining maximally deviated ST lead and efficacy in detecting acute myocardial ischemia during coronary occlusion",
      "author" : [ "S.F. Wung", "B. Drew" ],
      "venue" : "Journal of Electro-cardiology",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1999
    }, {
      "title" : "The angiotensin converting en-zyme D allele is an independent risk factor for early onset coronary artery disease",
      "author" : [ "A.V. Raygani", "H. Ghaneialvar", "Z. Rahimi", "H. Nomani", "M. Saidi", "F. Bahrehmand", "A. Vaisi-Raygani", "T.H. Tavilani" ],
      "venue" : "Pourmotabbed,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "Multifractal analysis of human synchronous 12-lead ECG signals using multiple scale factors",
      "author" : [ "X. Yang", "X. Ning", "J. Wang" ],
      "venue" : "Physica A: Statistical Mechanics and its Applications",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2007
    }, {
      "title" : "Designing prehospital ECG systems for acute coronary syndromes. Lessons learned from clinical trials involving 12-lead ST-segment monitoring",
      "author" : [ "B.J. Drew", "M.M. Pelter", "E. Lee", "J. Zegre", "D. Schindler", "K.E. Fleischmann" ],
      "venue" : "Journal of Electro-cardiology",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2005
    }, {
      "title" : "UCI repository of machine learning databases",
      "author" : [ "D.J. Newman", "S. Hettich", "C.L. Blake", "C.J. Merz" ],
      "venue" : "Department of Information and Computer Science,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1998
    }, {
      "title" : "Consistency based feature selection",
      "author" : [ "M. Dash", "H. Liu", "H. Motoda" ],
      "venue" : "In Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining ’ICKDDM00’,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2000
    }, {
      "title" : "An introduction to variable and feature selection",
      "author" : [ "GUYON", "Isabelle et ELISSEEFF", "André" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2003
    }, {
      "title" : "Floating search methods in feature selection",
      "author" : [ "PUDIL", "Pavel", "NOVOVIČOVÁ", "Jana", "et KITTLER", "Josef" ],
      "venue" : "Pattern recognition letters,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1994
    }, {
      "title" : "Adaptation in natural and artificial systems",
      "author" : [ "J.H. Holland" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1975
    }, {
      "title" : "Genetic algorithms in search, optimization, and machine learning",
      "author" : [ "D. Goldberg" ],
      "venue" : "Addison- Wisley Editions",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1989
    }, {
      "title" : "Wrappers for feature subset selection",
      "author" : [ "R.Kohavi", "G. John" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1997
    }, {
      "title" : "Laplacian score for feature selection",
      "author" : [ "X. He", "D. Cai", "P. Niyogi" ],
      "venue" : "In Proceedings of the Advances in Neural Information Processing Systems ’NIPS",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2005
    }, {
      "title" : "Feature selection as a preprocessing step for hierarchical clustering",
      "author" : [ "L. Talavera" ],
      "venue" : "In Proceedings of the 16th International Conference on Machine Learning ’ICML",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1999
    }, {
      "title" : "Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm",
      "author" : [ "H. Yan", "J. Zheng", "Y. Jiang", "C. Peng", "S. Xiao" ],
      "venue" : "Appl. Soft Comput",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2008
    }, {
      "title" : "Generalized best-first search strategies and the optimality of A*",
      "author" : [ "DECHTER", "Rinaet PEARL", "Judea" ],
      "venue" : "Journal of the ACM (JACM), vol. 32,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1985
    }, {
      "title" : "Floating search methods in feature selection",
      "author" : [ "PUDIL", "Pavel", "NOVOVIČOVÁ", "Jana", "et KITTLER", "Josef" ],
      "venue" : "Pattern recognition letters,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 1994
    }, {
      "title" : "Naive (Bayes) at forty: The independence assumption in information retrieval",
      "author" : [ "LEWIS", "David D" ],
      "venue" : "Machine learning:",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 1998
    }, {
      "title" : "Neural network: A comprehensive foundation",
      "author" : [ "S. Haykin" ],
      "venue" : "Upper Saddle River,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 1999
    }, {
      "title" : "Sensitivity, specificity, accuracy, associated confidence interval and roc analysis with practical SAS implementations",
      "author" : [ "W. Zhu", "N. Zeng", "N. Wang" ],
      "venue" : "NESUG Proceedings: Health Care and Life Sciences,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2010
    }, {
      "title" : "Use of fuzzy neural network to predict coronary heart disease in a Malaysian sample",
      "author" : [ "ABIDIN", "DOM Basir", "Rosma Mohd", "RAHMAN", "A. Rashid A" ],
      "venue" : "WSEAS International Conference. Proceedings. Mathematics and Computers in Science and Engineering. World Scientific and Engineering Academy and Society",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2009
    }, {
      "title" : "Fuzzy expert system approach for coronary artery disease screening using clinical parameters",
      "author" : [ "PAL", "Debabrata", "K.M. MANDANA", "Sarbajit" ],
      "venue" : null,
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2012
    }, {
      "title" : "Genetic algorithm wrapped Bayesian network feature selection applied to differential diagnosis of erythemato-squamous diseases",
      "author" : [ "ÖZÇIFT", "Akın et GÜLTEN", "Arif" ],
      "venue" : "Digital Signal Processing. Authors Sidahmed MOKEDDEM was born in Mostaganem, Algeria,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Subsequently, they are trained to learn decision characteristics of a physician for an explicit disease and then they can be used to support physician decision making to diagnose future patients of the same disease [1, 2].",
      "startOffset" : 215,
      "endOffset" : 221
    }, {
      "referenceID" : 1,
      "context" : "Subsequently, they are trained to learn decision characteristics of a physician for an explicit disease and then they can be used to support physician decision making to diagnose future patients of the same disease [1, 2].",
      "startOffset" : 215,
      "endOffset" : 221
    }, {
      "referenceID" : 2,
      "context" : "Inappropriately, there is no common model that can be adjusted for the diagnosis of all kinds of diseases [3].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 3,
      "context" : "This can increase the risk of taking into account correlated or redundant attributes which can lead to lower classification accuracy [4, 5, 6].",
      "startOffset" : 133,
      "endOffset" : 142
    }, {
      "referenceID" : 4,
      "context" : "This can increase the risk of taking into account correlated or redundant attributes which can lead to lower classification accuracy [4, 5, 6].",
      "startOffset" : 133,
      "endOffset" : 142
    }, {
      "referenceID" : 5,
      "context" : "This can increase the risk of taking into account correlated or redundant attributes which can lead to lower classification accuracy [4, 5, 6].",
      "startOffset" : 133,
      "endOffset" : 142
    }, {
      "referenceID" : 6,
      "context" : "[9] have proposed a four stage system for decision support based on fuzzy rules: 1) construction of a decision tree from the data, 2) the extraction of rules from the tree, 3) the transformation rules from the rough form to fuzzy one and 4 ) and the model optimization.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "Another work in this context [10] have developed a fuzzy system.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 8,
      "context" : "[12] have proposed an intelligent system for predicting heart attacks; in order to make the data ready to be analyzed they integrate them into a data warehouse.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 9,
      "context" : "In this study [13], the authors have used",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 10,
      "context" : "Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].",
      "startOffset" : 62,
      "endOffset" : 70
    }, {
      "referenceID" : 11,
      "context" : "Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].",
      "startOffset" : 62,
      "endOffset" : 70
    }, {
      "referenceID" : 12,
      "context" : "Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].",
      "startOffset" : 122,
      "endOffset" : 130
    }, {
      "referenceID" : 13,
      "context" : "Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].",
      "startOffset" : 122,
      "endOffset" : 130
    }, {
      "referenceID" : 10,
      "context" : "Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 14,
      "context" : "The data set is taken from the Data Mining Repository of the University of California, Irvine (UCI) [19].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 15,
      "context" : ", [20] a selection process of attributes is usually composed of four steps illustrated in Figure 1.",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 16,
      "context" : "In the first two cases, attributes are added iteratively (forward selection) or removed (Backward selection) [21].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 17,
      "context" : "Some other algorithms hybrid both concepts as Sequential Forward Floating Selection technique that apply, after each step Forward, Backward steps while the selected subset improves the evaluation function [22].",
      "startOffset" : 205,
      "endOffset" : 209
    }, {
      "referenceID" : 18,
      "context" : "Genetic algorithms, introduced by Holland in 1975 [23] are the most common methods used for random generation [24].",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 19,
      "context" : "Genetic algorithms, introduced by Holland in 1975 [23] are the most common methods used for random generation [24].",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 20,
      "context" : "Wrapper Approaches use the classification accuracy rate as evaluation criteria [25].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 21,
      "context" : "Filter Approaches use an evaluation function based on the characteristics of the dataset, regardless of any classification algorithm, to select certain attributes or a subset of attributes (information measures, consistency measures, dependence measures and distance measures) [26][27].",
      "startOffset" : 277,
      "endOffset" : 281
    }, {
      "referenceID" : 22,
      "context" : "Filter Approaches use an evaluation function based on the characteristics of the dataset, regardless of any classification algorithm, to select certain attributes or a subset of attributes (information measures, consistency measures, dependence measures and distance measures) [26][27].",
      "startOffset" : 281,
      "endOffset" : 285
    }, {
      "referenceID" : 23,
      "context" : "This process is reiterated until a best subset of features is found or the maximum number of iterations is attained [28].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 24,
      "context" : "BFS is a search algorithm that explores a graph by expanding the most promising node with the best score which will be evaluated using the wrapped BN [29].",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 25,
      "context" : "SFFS after each step Forward, it applies Backward steps while the subset corresponding improves the efficacy of wrapped BN [30].",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 26,
      "context" : "Thus, when features are dependent on each other, this algorithm produce a low classification accuracy [31].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 27,
      "context" : "MLP is feed-forward neural networks trained with the standard back-propagation algorithm [34].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 28,
      "context" : "In the testing phase, the testing dataset is given to the system to find the risk forecast of heart patients and achieved results are evaluated with the evaluation metric accuracy [35].",
      "startOffset" : 180,
      "endOffset" : 184
    }, {
      "referenceID" : 6,
      "context" : "A C C U R A CY S E N S I T I VI TY S P E C I FI T Y Anooj [8] Tsipouras [9] Abidin et al.",
      "startOffset" : 72,
      "endOffset" : 75
    }, {
      "referenceID" : 29,
      "context" : "[36]",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 7,
      "context" : "[10] Debabrata et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 30,
      "context" : "[37] Özçift et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 31,
      "context" : "[38]",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2013,
    "abstractText" : "Feature Selection (FS) has become the focus of much research on decision support systems areas for which datasets with tremendous number of variables are analyzed. In this paper we present a new method for the diagnosis of Coronary Artery Diseases (CAD) founded on Genetic Algorithm (GA) wrapped Bayes Naïve (BN) based FS. Basically, CAD dataset contains two classes defined with 13 features. In GA–BN algorithm, GA generates in each iteration a subset of attributes that will be evaluated using the BN in the second step of the selection procedure. The final set of attribute contains the most relevant feature model that increases the accuracy. The algorithm in this case produces 85.50% classification accuracy in the diagnosis of CAD. Thus, the asset of the Algorithm is then compared with the use of Support Vector Machine (SVM), Multi-Layer Perceptron (MLP) and C4.5 decision tree Algorithm. The result of classification accuracy for those algorithms are respectively 83.5%, 83.16% and 80.85%. Consequently, the GA wrapped BN Algorithm is correspondingly compared with other FS algorithms. The Obtained results have shown very promising outcomes for the diagnosis of CAD.",
    "creator" : "PScript5.dll Version 5.2.2"
  }
}