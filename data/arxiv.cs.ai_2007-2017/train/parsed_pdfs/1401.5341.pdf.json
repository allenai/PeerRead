{
  "name" : "1401.5341.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n40 1.\n53 41\nv1 [\ncs .A\nI] 2\n1 Ja\nn 20"
    }, {
      "heading" : "1 Introduction",
      "text" : "Constraint programming systems provide rich libraries of constraints, each of which models some specific structure useful across a wide range of applications. These constraints are important both from a modeling standpoint, as they make it possible to state problems at a high level of abstraction, and from an efficiency standpoint, as they allow dedicated algorithms to exploit the specific structure. The global constraint catalog [2] in fact lists about 354 global constraints at the time of writing. In addition, each of these constraints potentially come in many different forms as they can be applied, not only on variables, but also on expressions involving variables.\nThis large number of variants presents a challenge for system developers who must produce, validate, optimize, and maintain each version of each constraint. To avoid the proliferation of such variants, system developers often prefer to design a unique variant over variables and introduce new variables and constraints to model the more complex cases. For instance, a constraint\nalldifferent(x1 + 1, . . . , xn + n)\ncan be modeled by a system of constraints\n{alldifferent(y1, . . . , yn), y1 = x1 + 1, . . . , yn = xn + n}\nwhere the yi’s are new variables. This approach keeps the system core small but introduces an overhead in time and space. Indeed, the new constraints must\nbe propagated through the constraint engine and the system must maintain additional domains and constraints, increasing the cost of propagation and the space requirements.\nOver the years, system designers have sought ways to mitigate this difficulty and proposed several solutions of varying complexity. Prolog-style languages offered indexicals [5,3] while C++ libraries like Ilog Solver [6] introduces the concept of variable views. For an injective function f and a variable (or a view) x, a variable view y enforces the equivalent of the constraint y = f(x) but it does not introduce a new variable and a new constraint: Instead, it delegates all domain and constraint operations (the ability to wake constraints) on y to x, sometimes after applying f−1. These variable views remove the time and space overhead mentioned above and keep the solver kernel small, thus giving us a valuable abstraction for constraint programming. Recently, [8,9] demonstrated how variable views can be implemented in terms of C++ templates, providing further improvement in speed and memory usage. The idea is to use parametric polymorphism to allow for code reuse and compile-time optimizations based on code expansion and inlining. [9] demonstrates that variable views provide significant software engineering benefits as well as great computational improvements over the basic approach using new variables and constraints.\nThis paper aims at expanding the scope of constraint-programming views with an extremely simple abstraction: The concept of domain views which only delegate domain operations. Domain views preserve the benefits of variable views but simplify the implementation of value-based propagation, i.e., the propagation of events of the form 〈c, x, v〉, meaning that constraint c must be propagated because variable x has lost value v (e.g., [10,4]). The key benefit of domain views is to support non-injective views elegantly and compositionalls. Domain views can also be implemented using parametric polymorphism and hence are fully compatible with the compilation techniques in [9].\nThe rest of the paper is organized as follows. Sections 2, 3, and 4 present the preliminaries on constraint programming and on views. Section presents the implementation of variable views. Section 5 introduces the concept of domain views. Section 6 demonstrates how to generalize domain views to the case where the function f is not injective. Section 7 briefly discusses how to exploit monotonicity and anti-monotonicity. Section 8 presents experimental results. Section 9 discusses related work on advisors [7] and Section 10 concludes the paper."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "A constraint-programming system is organized around a queue of events Q and its main component is an engine propagating constraints in the queue, i.e.,\n1 while ¬ empty (Q) do 2 propagate ( pop(Q ) ) ;\nFor simplicity, we only consider two types of events: 〈c, x〉 and 〈c, x, v〉. An event 〈c, x〉 means that constraint cmust be propagated because the domain of variable\nx has been shrunk. An event 〈c, x, v〉 means that constraint cmust be propagated because the value v has been removed from the domain of variable x. Events of the form 〈c, x〉 are sometimes called variable-based propagation, while those of the form 〈c, x, v〉 are sometimes called value-based propagation. Note that some systems also implement what is called constraint-based propagation, where the event simply consists of constraint to propagate without additional information. We do not discuss constraint-based propagation here since it is easier to handle.\nThe propagation of a constraint may change the domains of some variables and thus introduce new events in the queue. As a result, a variable x not only maintains its domain D(x) but also keeps track of the constraints it appears in so that the proper events can be inserted in the queue. As a result, a variable x is best viewed as a triple 〈D,SC, SCv〉, where D is the domain of the variable, SC is the set of constraints involving x that use variable-based propagation, and SCv is the set of constraints involving x that use value-based propagation. If x is a variable, we use D(x), SC(x) and SCv(x) to denote these three components.\nFor simplicity, a variable in this paper implements the interface depicted in Figure 1, where V denotes the set of values considered (e.g., integers or reals) and C the set of constraints. For a variable x, method member(v) tests v ∈ D(x), method remove(v) implements D(x) := D(x) \\ {v} and returns true if the resulting domain is not empty, method watch(c) registers constraint c for variable-propagation, and method watchValue(c) registers constraint c for value-propagation. The wake methods are used for creating new events in the queue. Method wake must implement Q := Q ∪ {〈c, x〉 | c ∈ SC(x)} while method wakeValue(v) must implement Q := Q ∪ {〈c, x, v〉 | c ∈ SCv(x)}. With our conventions, a variable can be implemented as depicted in Figure 2."
    }, {
      "heading" : "3 Views",
      "text" : "The purpose of this paper is to define and implement abstractions for constraints of the form y = ψ(x). In a first step, the paper focuses on injective views, i.e., views in which function ψ is injective, which is the functionality provided by many constraint-programming solvers.\nDefinition 1 (Injective Function) A function ψ : D → V is injective if\n∀v, v′ ∈ D : ψ(v) = ψ(v′) ⇒ v = v′.\nThe inverse ψ−1 : V → D⊥ of injective function ψ is defined as\nψ−1(w) =\n{\nv if v ∈ D ∧ ψ(v) = w ⊥ otherwise\nwhere D⊥ = D ∪ {⊥}.\nNote that the definition of ψ−1 is a specification: An actual implementation uses a dedicated implementation of ψ−1 as the following two examples illustrate.\nExample 1 (Shift View) Consider the view y = x + c where c is an integer and x and y are integer variables. Function ψ : Z → Z can be specified (using lambda calculus notation [1]) as λk.k + c. Its inverse ψ−1 : Z → Z is defined as λk.k − c.\nExample 2 (Affine View) Consider the view y = ax + b where a, b ∈ Z and x, y are integer variables. ψ : Z → Z is λk.ak + b. Its inverse ψ−1 : Z → Z is\nψ−1 =\n{\nλk.(k − b)/a if (k − b) mod a = 0 λk.⊥ otherwise.\nViews must be compositional and make it possible to state a view over a view."
    }, {
      "heading" : "4 Variable Views",
      "text" : "The fundamental idea of variable views, implemented in many systems, is to delegate all domain and constraint operations of variable y to variable x. A variable view thus implements an adapter pattern that stores neither domain\nnor sets of constraints. The variable view simply stores a reference to variable x and delegates all domain and constraint operations to x, possibly after applying function ψ or ψ−1 on the arguments. Informally speaking, the membership test w ∈ D(y) becomes ψ−1(w) ∈ D(x), the removal operation proceeds similarly and variable x also watches all the constraints of y.\nThe only difficulty in variable views comes from the fact that variable x now needs to watch constraints on both x and y. For variable-based propagation, it is necessary to remember which variable is being watched for each constraint and the set SC now consists of pairs 〈c, z〉 where c is a constraint and z is a variable. For value-based propagation, it is necessary to store the function ψ since it must be applied when method wakeValue is applied. Hence the set SCv now contains triples of the form 〈c, z, ψ〉. These generalizations are necessary, since when a value v is removed from the domain of x, the value-based events for variable y must be of the form 〈c, y, ψ(v)〉.\nThe implementation of variables to support variable views is shown in Figure 3 where X denotes the set of variables/views and F the set of first-order functions. Observe the types of SC and SCv in lines 3–4, the new methods in lines 14–15 allow to watch a constraint c for a view y, the matching redefinition of the watch methods, and the wake methods that store additional information in the queue by applying the stored function ψ on value v (line 20).\nFigure 4 depicts a template for variable views in terms of an injective function ψ. A shift view specialization is shown in Figure 5. Observe that variable views do not store a domain nor constraint sets. Methods member and remove apply ψ−1 as mentioned earlier with only the addition of a test for the ⊥ case. Methods watch\nand watchValue (lines 10–11) state a view on the view itself. In particular, line 11 illustrates the need for function composition in the case of value propagation.\nThe instantiation for shift views in Figure 5 highlights some interesting points. First, there is no need for a ⊥ test, since the inverse of ψ is always in the domain of ψ. Second, value-based propagation requires the use of first-order functions (see lines 9 and 12) or objects implementing the same functionalities. In contrast, methods member and remove “inline” function φ−1 in the code, which is never stored or passed as a parameter.\nOptimization Variable views now stores tuples 〈c, z, ψ〉 for value-based propagation. Observe however that z is an object so that it is possible to use it to compute function ψ. This only requires the view to provide a method map that maps the value v through ψ. Lines 15 and 20 in Figure 3 become\n1 void watchValue (C c,X y ) { SCv := SCv ∪ {〈c, y〉} ;} 2 void wakeValue (V v ) { Q := Q ∪ {〈c, x, x.map(v)〉 | 〈c, x〉 ∈ SCv} ;}\nThe map method on standard variables is defined as\n1 V map(V v ) { return v ;}\nand its definition on views (defined over variable x with injective function ψ) is\n1 V map(V v ) { return ψ(x.map(v)) ;}\nObserve the recursive call, since views can be posted on views. This optimization clutters a bit the API of variables and views but only minimally.\nVariable views are an important concept in constraint programming for injective functions. For constraint-based and variable-based propagation, the implementation is simple and efficient, although it requires to upgrade slightly the data structure to watch constraints. For value-based propagation, the implementation is a bit more cumbersome. It requires a generalization of the constraint queue and the addition of a map method on variables and views to avoid manipulating first-order functions. Domain views provide an extremely simple alternative, which also has the benefits of supporting non-injective functions elegantly."
    }, {
      "heading" : "5 Domain Views",
      "text" : "The key idea behind domain views is to delegate only domain operations from variable y to variable x: The view for y maintains its own constraints to watch. This removes the need to manipulate first-order functions. To implement domain views, traditional variables (and views) must store which variables are viewing them. When their domains change, they must notify their views.\nFigure 6 depicts the revised implementation of domain variables to support domain views. The variable now keeps its views (line 5) and provides a method\nfor adding a view (line 8). The only other change is in method remove in lines 16–18: The domain variable calls method wake and wakeValue on its views to inform them of the loss of value v to let them schedule their own constraints.\nFigure 7 shows a template for domain views in terms of an injective function ψ. A specialization for shift views is shown in Figure 8. Observe first how the domain view maintains its own set of constraints. It delegates its domain operations in methods member and remove in the same way as variable views, but it does not delegate its watch methods, which are similar to those of a traditional domain variable. To implement views on views, the wake methods also wake the views (lines 16–20 and 21–25), using the function ψ to send the appropriate value since v is the value removed from D(x). D(x) may be explicit (traditional variable) or implicit (views). The shift view in Figure 8 does not manipulate first-order functions and inlines ψ−1 in lines 9 and 12 and ψ in line 24.\nDomain views provide an elegant alternative to variable views. They remove the need to modify the data structure for watching constraint and alleviate the need for the map function, while preserving the benefits of variable views and enabling more inlining for value-based propagation. They are based on a simple idea: Only delegating the domain operations. Instead of delegating constraint watching, constraints are watched locally. It is interesting to analyze the memory requirements of both approaches. Variable views need to store variables in their constraint lists, which require space proportional to the length of these lists. In contrast, domain views only require a few pointers for their own lists,\nthe constraints themselves being present in both approaches albeit in different lists. The viewed variables must also maintain the list of its views, which is proportional to the number of views."
    }, {
      "heading" : "6 Non-injective Views",
      "text" : "We now generalize domain views to non-injective functions.\nDefinition 2 (Inverse of a Non-Injective Function) The inverse ψ−1 : V → 2D ⊥ of non-injective function ψ : D → V is defined as\nψ−1(w) =\n{\n⊥ if 6 ∃ v ∈ D : ψ(v) = w {v ∈ D | ψ(v) = w} otherwise.\nFigure 9 gives the template for non-injective views. There are only a few modifications compared to the template for injective views. The member function must now test membership for a set of values (line 12) and the remove function must remove a set of values (line 18). Finally, method wakeValue(w) must test membership of v = ψ(w), since there may be multiple supports for v in D(x).\nThe key advantage of domain views is that they own their constraints. In the context of non-injective functions, this is critical since only the view “knows” whether its constraints must be scheduled for propagation.\nIt is more difficult and less elegant, but not impossible, to generalize variable views to support non-injective functions. Consider what should happen for\nvariable views. For a view y = f(x), when a value v is removed from the domain of x, it is no longer sufficient to just use the map function. The view must now decide whether the value f(v) is still supported for y. Moreover, if we have a view z = g(y) and variable x is trying to decide whether to schedule a constraint involving z, it must query z to find out whether the value g(f(v)) is still supported, which depends on whether value f(v) is still supported in variable y. Hence, to implement non-injective functions in variable views, waking constraints up must be conditional. It is necessary to implement a method needToSchedule on views to determine if the original removal will actually remove a value on the views. Method wakeValue now becomes\n1 void wakeValue (V v ) { 2 Q := Q∪ {〈c, x, x.map(v)〉 | 〈c, x〉 ∈ SCv & x . needToSchedule (v )} ;}\nThe implementation of needToSchedule must also be recursive (like the map function) to handle the case of views on views. For space reasons, we let readers figure out the details on how to do so correctly and only note the conceptual simplicity of domain views.3\nLiteral Views Reified constraints are a fundamental abstraction in constraint programming. For instance, In a magic series s of length n, every si must satisfy si = ∑n−1 j=0 (sj = i), i.e., it states that si should be the number of occurrences of value i in s itself. To implement this behavior, one could rely on auxiliary boolean variables bij ⇔ sj = i. for every i and j in 0..n−1 leading to a quadratic number of boolean variables and reified equality constraints. The reification b ⇔ x = i can be seen as a non-injective view and Figure 10 describes its implementation. The view uses two methods not described before: Method isBoundTo(i) on variable x holds if D(x) = {i}, while method bind(i) succeeds if i ∈ D(x) and reduces the domain D(x) to {i}. With these two functions, the implementation is direct with the methods member, remove, and wakeValue carried out by case analysis on the value of the “reified variable”.\nModulo Views We now show a view for a constraint y = x mod k with k ∈ Z. The view implementation maintains the supports for each value v ∈ D(y), i.e.,\n∀v ∈ D(y) sv = {w | w ∈ D(x) ∧ w mod k = v}\nFigure 11 depicts a sketch of a simple implementation."
    }, {
      "heading" : "7 Monotone and Anti-Monotone Views",
      "text" : "We briefly mention how to exploit monotone and anti-monotone properties to perform additional operations such as updateMin and updateMax. These techniques are well-known and are only reviewed here for completeness.\nDefinition 3 (Monotone/AntiMonotone Function) An injective function ψ is monotone if ∀v, w : v ≤ w → ψ(v) ≤ ψ(w). It is anti-monotone if ∀v, w : v ≤ w → ψ(v) ≥ ψ(w).\nIf ψ : Z → Z is a monotone function and y is a view on x, then the update operations on bounds becomes\n1 bool updateMin (Z v ) { return x . updateMin (ψ−1(v) ) ; } 2 bool updateMax (Z v ) { return x . updateMax (ψ−1(v) ) ; }\nignoring the case where ψ−1(v) is not well-defined. When ψ is anti-monotone, they become\n1 bool updateMin (Z v ) { return x . updateMax (ψ−1(v) ) ; } 2 bool updateMax (Z v ) { return x . updateMin (ψ−1(v) ) ; }\n3 Method needToSchedule must also update any internal state of the views. From a semantic standpoint, it would desirable to have another recursive method to notify the view that value v has been removed and to update the state."
    }, {
      "heading" : "8 Empirical Evaluation",
      "text" : "We now describe experimental results to demonstrate the efficiency of domain views. The experiments were run on MacOS X 10.8.3 running on a Core i7 at 2.6Ghz, using the Objective-CP optimization system [11]. The complete implementation of the integer and boolean variables, along with their domain and their views (including literal views) is around 3,200 lines of code, which is similar to the type of code reuse advertised for Gecode [9]. Objective-CP pushes the methodology advocated in [9] to the limit, only supporting core constraints and using views to obtain more complex versions. For instance, the CP solver in Objective-CP provides ∑n\ni=0 xi ≤ b but not ∑n\ni=0 ai · xi ≤ b. Note that cost-based propagation for COP would, of course, mandate global constraints retaining the ai. Objective-CP supports value-based propagation and noninjective views, which demonstrates the additional functionalities provided by domain views. Note that the experiments only aim at demonstrating the practicability of domain views: See [9] for the benefits of views.\nBenchmarks The implementation was validated with on a variety of benchmarks relying on views. The experiments compare implementations with no views, with the optimized variable views (with subtype polymorphism), and domain views. When no-views are used, the implementation uses the constraints and auxiliary variables introduced during the flattening of the model. The implementation uses the same models throughout and the search space and pruning are always identical. For bibd, we follow [9] and rewrite the boolean relations a ∧ b as ¬ (¬a ∨ ¬b) to ensure that the system uses negation views. Specifically, knapsack use linear equations ∑\ni∈S xi = b and introduce views for the coefficients. The Steel Mill Slab problem relies on literal views for the color constraint on slab s : ∑\nc∈Colors ∨o∈Orders[c](xo = s) ≤ 2. Debruijn uses both linear equations as well as reifications. Langford uses affine views to “shift” indices within element constraints. Magicseries clearly relies on reifications. Sport is the classic sport scheduling benchmark and uses global constraints.\nMeasurements The benchmarks use a simple first-fail heuristic as decomposition may change the behavior of more advanced heuristics (e.g., WDEG) and these experiments are only interested in assessing view implementations, not inherent speed. Table 1 offers a comparative view of the results. It is based on 50 execution of each benchmark to account for the inherent variability related to modern processor technology. Columns µ(Tcpu) and µ(Twc) give the average user-time or wall-clock times in milliseconds. Columns σ(Tcpu) and σ(Twc) report the standard deviations for those run times. Column |M | reports the peak memory consumption in kilobytes for the entire process. The measurement was taken at the level of the malloc C-runtime function and includes all memory\nallocations done by the executable. Finally, column P. reports the number of propagation events recorded by the engine (in thousands).\nWithout surprise, the results indicate that a minimalist kernelmust use views to be competitive. The differences in memory consumptions and running times are often quite significant when contrasted with view-based implementations. For all benchmarks involving only injective views, variable and domain views are essentially similar in time and space efficiency. Given the standard deviations, the differences in efficiency are not statistically significant, although variable views are often slightly more efficient. This is not always the case, as the sport-scheduling problem indicates. The main benefit of domain views is to support non-injective views simply and efficiently. This is particularly clear on the benchmarks relying on reifications, i.e, slab and magicserie. The benefits are in terms of runtime and memory consumption. The runtime benefits are quite substantial, as the running time is halved on the Steel Mill Slab problem. The dramatic drop in the number of propagations is easily explained by the absence of constraints of the form b⇔ (x = v), yet, the same work is still carried out by the view, albeit at a much lower overhead.\nIn summary, the experimental results show that domain views do not add any measurable overhead on injective views and bring significant benefits on non-injective views, which they support elegantly."
    }, {
      "heading" : "9 Related Work",
      "text" : "It is important to contrast the variable and domain view implementations proposed here with another approach using delta-sets and advisors [7,9]. Advisors are another way of “simulate” value-based propagation.4 An advisor is associated with a variable and a constraint and it modifies the state of the constraint directly upon a domain modification for its variables. Advisors do not go through the propagation queue but modify the state of their constraint directly. This has both an advantage (speed) and an inconvenience, since an advisor may be called while its constraint is propagating; Hence some care must be exercised to maintain a consistent state. Advisors also receive the domain change (called a delta set) which they may query.\nAdvisors can be associated with variable views. The view must now be upgraded to query, not only the domain, but also the delta sets. In other words, the queries on the delta must transform the domain delta, say {v1, . . . , vn}, through the view to obtain {φ(v1), . . . , φ(vn)}. Gecode [9] does not compute delta sets exactly but approximates them by intervals instead. A complete implementation of value-based propagation would require the creation of these delta sets. Advisors and delta sets can be used in the case of non-injective functions but that solution would still go through the propagation queue and use a constraint. Indeed, by design, advisors do not propagate constraints.\nThe key advantage of domain views in this context is their ability to implement non-injective views without going through the propogation queue."
    }, {
      "heading" : "10 Conclusion",
      "text" : "This paper reconsidered the concept of views, an important abstraction provided by constraint-programming systems to avoid the proliferation of constraints, while preserving the efficiency of dedicated implementation. It proposed an alternative to the concept of variable views, typically featured in constraintprogramming systems. Contrary to variable views, domain views only delegate domain operations and maintains their own set of constraints to watch. Domain views simplify the implementation of constraint-programming systems featuring value-based propagation as they avoid manipulating first-order functions (or objects implementing a similar functionality). They also make it possible to implement, in simple ways, views featuring non-injective functions. These are particularly useful for reified constraints, which are also an important features of constraint-programming systems. Experimental results demonstrate that domain views introduce a negligible overhead (if any) over variable views and that views over non-injective functions, which are elegantly supported by domain views, provide significant benefits.\n4 It is only a simulation since an advisor updates the constraint state but does not propagate a constraint itself. They are second-class citizens by choice in Gecode [7]."
    } ],
    "references" : [ {
      "title" : "The Lambda Calculus – Its Syntax and Semantics, volume 103 of Studies in Logic and the Foundations of Mathematics",
      "author" : [ "H.P. Barendregt" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1984
    }, {
      "title" : "Global constraint catalogue",
      "author" : [ "N. Beldiceanu", "M. Carlsson", "S. Demassey", "T. Petit" ],
      "venue" : "Past, present and future. Constraints,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2007
    }, {
      "title" : "An open-ended finite domain constraint solver",
      "author" : [ "M. Carlsson", "G. Ottosson", "B. Carlson" ],
      "venue" : "editors, PLILP,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1997
    }, {
      "title" : "Comet v2.1 user manual",
      "author" : [ "I. Dynadec" ],
      "venue" : "Technical report, Providence,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2009
    }, {
      "title" : "Constraint processing in cc(fd)",
      "author" : [ "P.V. Hentenryck", "V. Saraswat", "Y. Deville" ],
      "venue" : "Technical report,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1992
    }, {
      "title" : "Advisors for incremental propagation",
      "author" : [ "M. Lagerkvist", "C. Schulte" ],
      "venue" : "In Proceedings of the 13th International Conference on Principles and Practice of Constraint Programming,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2007
    }, {
      "title" : "Perfect derived propagators",
      "author" : [ "C. Schulte", "G. Tack" ],
      "venue" : "CP, volume 5202 of Lecture Notes in Computer Science,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "View-based propagator derivation",
      "author" : [ "C. Schulte", "G. Tack" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2013
    }, {
      "title" : "A Generic Arc Consistency Algorithm and Its Specializations",
      "author" : [ "P. Van Hentenryck", "Y. Deville", "C. Teng" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1992
    }, {
      "title" : "The Objective-CP Optimization System",
      "author" : [ "P. Van Hentenryck", "L. Michel" ],
      "venue" : "In Proceedings of the 19 International Conference on Principles and Practice of Constraint Programming,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "The global constraint catalog [2] in fact lists about 354 global constraints at the time of writing.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 4,
      "context" : "Prolog-style languages offered indexicals [5,3] while C++ libraries like Ilog Solver [6] introduces the concept of variable views.",
      "startOffset" : 42,
      "endOffset" : 47
    }, {
      "referenceID" : 2,
      "context" : "Prolog-style languages offered indexicals [5,3] while C++ libraries like Ilog Solver [6] introduces the concept of variable views.",
      "startOffset" : 42,
      "endOffset" : 47
    }, {
      "referenceID" : 6,
      "context" : "Recently, [8,9] demonstrated how variable views can be implemented in terms of C++ templates, providing further improvement in speed and memory usage.",
      "startOffset" : 10,
      "endOffset" : 15
    }, {
      "referenceID" : 7,
      "context" : "Recently, [8,9] demonstrated how variable views can be implemented in terms of C++ templates, providing further improvement in speed and memory usage.",
      "startOffset" : 10,
      "endOffset" : 15
    }, {
      "referenceID" : 7,
      "context" : "[9] demonstrates that variable views provide significant software engineering benefits as well as great computational improvements over the basic approach using new variables and constraints.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : ", [10,4]).",
      "startOffset" : 2,
      "endOffset" : 8
    }, {
      "referenceID" : 3,
      "context" : ", [10,4]).",
      "startOffset" : 2,
      "endOffset" : 8
    }, {
      "referenceID" : 7,
      "context" : "Domain views can also be implemented using parametric polymorphism and hence are fully compatible with the compilation techniques in [9].",
      "startOffset" : 133,
      "endOffset" : 136
    }, {
      "referenceID" : 5,
      "context" : "Section 9 discusses related work on advisors [7] and Section 10 concludes the paper.",
      "startOffset" : 45,
      "endOffset" : 48
    }, {
      "referenceID" : 0,
      "context" : "Function ψ : Z → Z can be specified (using lambda calculus notation [1]) as λk.",
      "startOffset" : 68,
      "endOffset" : 71
    }, {
      "referenceID" : 9,
      "context" : "6Ghz, using the Objective-CP optimization system [11].",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 7,
      "context" : "The complete implementation of the integer and boolean variables, along with their domain and their views (including literal views) is around 3,200 lines of code, which is similar to the type of code reuse advertised for Gecode [9].",
      "startOffset" : 228,
      "endOffset" : 231
    }, {
      "referenceID" : 7,
      "context" : "Objective-CP pushes the methodology advocated in [9] to the limit, only supporting core constraints and using views to obtain more complex versions.",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 7,
      "context" : "Note that the experiments only aim at demonstrating the practicability of domain views: See [9] for the benefits of views.",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 7,
      "context" : "For bibd, we follow [9] and rewrite the boolean relations a ∧ b as ¬ (¬a ∨ ¬b) to ensure that the system uses negation views.",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 5,
      "context" : "It is important to contrast the variable and domain view implementations proposed here with another approach using delta-sets and advisors [7,9].",
      "startOffset" : 139,
      "endOffset" : 144
    }, {
      "referenceID" : 7,
      "context" : "It is important to contrast the variable and domain view implementations proposed here with another approach using delta-sets and advisors [7,9].",
      "startOffset" : 139,
      "endOffset" : 144
    }, {
      "referenceID" : 7,
      "context" : "Gecode [9] does not compute delta sets exactly but approximates them by intervals instead.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 5,
      "context" : "They are second-class citizens by choice in Gecode [7].",
      "startOffset" : 51,
      "endOffset" : 54
    } ],
    "year" : 2014,
    "abstractText" : "Views are a standard abstraction in constraint programming: They make it possible to implement a single version of each constraint, while avoiding to create new variables and constraints that would slow down propagation. Traditional constraint-programming systems provide the concept of variable views which implement a view of the type y = f(x) by delegating all (domain and constraint) operations on variable y to variable x. This paper proposes the alternative concept of domain views which only delegate domain operations. Domain views preserve the benefits of variable views but simplify the implementation of value-based propagation. Domain views also support non-injective views compositionally, expanding the scope of views significantly. Experimental results demonstrate the practical benefits of domain views.",
    "creator" : "LaTeX with hyperref package"
  }
}