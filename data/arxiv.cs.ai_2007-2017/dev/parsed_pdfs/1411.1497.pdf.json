{
  "name" : "1411.1497.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Xiaoyu Chen", "Dongming Wang" ],
    "emails" : [ "franknewchen@gmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n41 1.\n14 97\nv1 [\ncs .A\nI] 6\nN ov\n2 01\n4\nWe study the data space D of any given data set X and explain how functions and relations are defined over D. From D and for a specific domain ∆ we construct the information space I of X by interpreting variables, functions, and explicit relations over D in ∆ and by including other relations that D implies under the interpretation in ∆. Then from I we build up the knowledge space K of X as the product of two spaces KT and KP , where KT is obtained from I by using the induction principle to generalize propositional relations to quantified relations, the deduction principle to generate new relations, and standard mechanisms to validate relations and KP is the space of specifications of methods with operational instructions which are valid in KT . Through our construction of the three topological spaces the following key observation is made clear: the retrieval of information from the given data set for ∆ consists essentially in mining domain objects and relations, and the discovery of knowledge from the retrieved information consists essentially in applying the induction and deduction principles to generate propositions, synthesizing and modeling the information to generate specifications of methods with operational instructions, and validating the propositions and specifications. Based on this observation, efficient approaches may be designed to discover profound knowledge automatically from simple data, as demonstrated by the result of our study in the case of geometry.\nKeywords data space, declarative knowledge, deduction principle, implied knowledge, induction principle, information retrieval, knowledge discovery, procedural knowledge, quantified relation"
    }, {
      "heading" : "1 Introduction",
      "text" : "With increasingly wide use of digital devices and networks, more and more scientific explorations and social activities are carried out electronically, where the involved objects, phenomena, and behaviors of interest are measured and presented in the form of data. Thus analyzing and modeling data, retrieving information from data, and discovering knowledge that data imply become essential tasks. In fact, data\naSKLSDE - School of Computer Science and Engineering, Beihang University, Beijing 100191, China. E-mail: franknewchen@gmail.com bLMIB - School of Mathematics and Systems Science, Beihang University, Beijing 100191, China cCentre National de la Recherche Scientifique, 3 rue Michel-Ange, 75794 Paris cedex 16, France\nmining, machine learning, information retrieval, and knowledge discovery are some of the directions of research and development which have been given high priority in various national programs [1]. Let us address three issues in more detail.\n(1) Data Management. Data are acquired, collected, and recorded in digital databases with respect to different aspects of concern, such as time, location, state, and relation, of observed objects. Data models and schemas need be well designed in order to provide manipulable structures for efficiently storing, retrieving, exchanging, and acting on data. Visualization techniques should be capable of representing the underling features and properties of data in the form of intuitive diagrams with dynamic animation. Data management techniques should be available as fundamental utilities in dealing with the activities of observation, measurement, and experiment. It becomes more and more difficult to process collections of complex data with large volume, high velocity of change, uncertain veracity, and variety of types, called big data [2], using traditional methodologies and existing database management tools. There is a need of substantially new ideas, techniques, approaches, and systems for the management of big data.\n(2) Information Retrieval. Information is implied in data and may be retrieved manually or mechanically through analyzing, modeling, computing, and learning. Valuable information depicts the essence of observed phenomena and can thus be used to predict the changing of the phenomena and to study the properties of the objects under observation. A large variety of methods, techniques, and tools have been developed in the fields of data mining, knowledge discovery, pattern recognition, and machine learning for retrieving information from data (see, e.g., the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7]. Current investigations tend to be more expertiseoriented and more problem-centered, as witnessed by the publications of a series of conference proceedings and journals. An integrated study of qualitative and quantitative methods from natural sciences with cognitive science, psychology, and human behaviors is likely to help enhance our understanding of information retrieval [8], hopefully resulting in revolutionary approaches for intelligent retrieval of information from big data.\n(3) Logical Reasoning. The discovery of scientific knowledge is inseparable from logical reasoning. The principle of induction points out how to formulate conjectures as to acquire knowledge based on experience of a few existing cases [9]. On the other hand, the inductive logic provides a less-than-certain inference mechanism of evidential support by using probability [10]. Holding a controversial view on the function of induction, Popper [11] argued that scientific theories are not inductively inferred from experience, nor is scientific experimentation carried out with a view to verifying or finally establishing the truth of theories; rather, all knowledge is\nprovisional, conjectural, hypothetical, disprovable rather than provable. In his view, scientific discovery is a deductive process in which scientists formulate hypotheses and theories that they test by deriving particular observable consequences, modify falsified theories based on empirical facts, and create new theories that corroborate the necessary predictions. Along this line of thought, Li [12] developed an operable revision calculus to deal with refutations and a logical framework for formalizing the process of scientific discovery.\nKnowledge may be discovered from data via information retrieval. To understand the process of knowledge discovery, one needs to study the properties of data, information, and knowledge and to clarify their relationship. Such studies are also necessary for the establishment of theoretical foundations for the sciences of data and knowledge. This paper presents the result of our initial study on what we call implied knowledge discovery by constructing three topological spaces for data, information, and knowledge. A key idea that is responsible for the richness of the constructed space of knowledge is to generate data-implied knowledge by applying meta-knowledge (notably the induction and deduction principles) and domain knowledge. We provide formal definitions for various concepts and theorems to describe features and relations of the three spaces and objects therein. According to the process of construction of the three spaces, efficient approaches may be designed to discover profound knowledge automatically from simple data. The interested reader is encouraged to consult [13] for one such approach, which is capable of generating nontrivial geometric theorems from images of diagrams."
    }, {
      "heading" : "2 The Space of Data",
      "text" : "We start by recalling a few standard concepts from the area of data analysis.\nDefinition 2.1 (Data point). A data point is a set of one or more measurements on a single member of a set of observed objects.\nDefinition 2.2 (Data set). A data set is a collection of data points.\nLet X be any given finite nonempty data set.\nDefinition 2.3 (Data space). The data space D of X is the set X of points endowed with a family τ of subsets of X such that (1) both ∅ and X are elements of τ , (2) any union of elements of τ is an element of τ , and (3) any intersection of finitely many elements of τ is an element of τ . Each element in τ is called an open set and τ is called the data structure of D.\nTheorem 2.1. The space D defined above is a finite topological space.\nProof. By definition of topology [14], it can be easily proved that τ is a topology on X . Thus, D is a topological space for which there are only finitely many data points.\nLet n be a positive integer and T ⊂ τn.\nDefinition 2.4 (Data Function). A data function is a map\nf : T 7→ τ (t1, . . . , tn) → f(t1, . . . , tn).\nDefinition 2.5 (Data Relation). A data relation is a map\nR : T 7→ {true, false} (t1, . . . , tn) → R[t1, . . . , tn].\nFor n = 2, the relation R[t1, t2] is sometimes written as t1R t2.\nExample 2.1. Given t, s ∈ τ , the data function intersection maps (t, s) to intersection(t, s), which is written usually as t ∩ s. There are two kinds of data relations: propositional (without using variables, e.g., {3} ⊂ {3, 7}) and quantified (to represent a set of propositional relations, e.g., ∀t ∈ τ ∃s ∈ τ (t ∪ s = X)).\nFor any fixed data set X , one can define different data spaces with different topologies. One can also define different binary relations (called preorders) on X that are reflexive and transitive. For any preorder on X , there is a data space with topology τ such that every upper set U of X with respect to (i.e., if x ∈ U and x y then y ∈ U) is an open set of τ . Conversely, for any data space with topology τ , there is a preorder on X such that x y if x is in the closure of {y} in τ . Therefore, the binary relations are in one-to-one correspondence with the data spaces.\nIn what follows, we list some properties of data spaces which are useful for data analysis.\n(1) Compactness. Every data space is compact (because each open cover of it has a finite subcover).\n(2) Separability. For any data space D of X , if D is T1 (i.e., for every pair of distinct data points in D, each point has an open neighborhood not containing the other), then D must be discrete (i.e., the data structure of D is the power set of X).\n(3) Connectivity. A data space is connected if and only if the associated graph with respect to its corresponding preorder is path-connected.\n(4) Metrizablity. A data space is metrizable if and only if it is discrete.\nIf a data space ofX is metrizable, then one can introduce a metric on X as follows.\nDefinition 2.6 (Metric). A metric on X is a map d : X2 7→ R (where R denotes the field of real numbers) which satisfies the following conditions: for all x, y, z ∈ X , (1) d(x, y) > 0; (2) d(x, y) = 0 if and only if x = y; (3) d(x, y) = d(y, x); (4) d(x, z) 6 d(x, y) + d(y, z).\nDefinition 2.7 (Similarity). Two data points x and y in X are said to be ǫ-similar, denoted as x ∼ǫ y, if d(x, y) 6 ǫ, where d is a metric\n1 on X and ǫ is a given threshold. If x and y are not ǫ-similar, then we write x 6∼ǫ y.\nDefinition 2.8 (Cluster). A subset C of X is called a cluster of X if\n(a) for any two data points x0, x ∈ C, there exist x1, . . . , xn ∈ C such that xi ∼ǫ xi−1 for i = 1, . . . , n and x ∼ǫ xn;\n(b) for any x ∈ C and y ∈ X \\ C, x 6∼ǫ y,\nwhere ǫ is a given threshold.\nObviously, any two clusters of X are disjoint. It is also easy to prove the following.\nTheorem 2.2. For any given finite data set X and threshold ǫ, there are finitely many clusters C1, . . . , Cm such that X = C1 ∪ · · · ∪ Cm.\nWhen X is a subset of the Euclidean space and d is the Euclidean distance, X can be converted into a graph by taking the points in X as its vertices and connections of proximate vertices as its edges. The obtained graph can be turned into a simplicial complex of X by gluing together simplices. The constructed simplicial complex is a topological space. Therefore, methods from algebraic topology can be used to study the simplicial complex of X (see [15] for more details).\nThe data structure of a data space, in which useful domain information is implied, plays an important role in depicting the features of the space."
    }, {
      "heading" : "3 Domain and Interpretation",
      "text" : "Let ∆ be an arbitrary but fixed domain.\nExample 3.1. The data set X = {3, 7, 11, 23} has no meaning. It may be interpreted as a set of strings of characters, or a set of mathematical numbers, or a set of identifiers for different athletes.\n1When the metric is Euclidean distance, ǫ-similarity measures the closeness of data points in X .\nDefinition 3.1 (Domain object). A domain object is an object of study that has clear meaning in ∆.\nDefinition 3.2 (Domain function). A domain function is a function that is defined over a subdomain of ∆ and has clear meaning in ∆.\nDefinition 3.3 (Domain relation). A domain relation is a relation among domain objects that has clear meaning in ∆.\nDefinition 3.4 (Propositional and quantified relation). A domain relation which does not involve any quantifier is called a propositional relation. A quantified relation is a relation which involves at least one of the quantifiers ∀ and ∃ to represent a set of propositional relations.2\nDomain functions and relations are introduced usually by definitions in the domain. There are two types of domain objects: primitive objects and derived objects. Primitive objects may be defined informally, while derived objects are defined through domain functions on primitive objects and already defined derived objects. Similarly, there are two types of domain relations: primitive relations and derived relations. The former may be defined informally, while the latter are defined through domain functions on primitive relations and already defined derived relations. To facilitate the study of the domain, let the set of primitive objects and relations be well chosen and then fixed.\nDefinition 3.5 (Operation). Let y = f(x1, . . . , xn) be a function defined over a subdomain δ of ∆. For any given values x̄1, . . . , x̄n ∈ δ, the evaluation f(x̄1, . . . , x̄n) is called an operation in ∆.\nDefinition 3.6 (Instruction). An instruction is a specification about where, when, and how to perform a sequence of operations in ∆.\nDefinition 3.7 (Method). A method consists of a specification about what is given and what is the goal to be achieved and a sequence of instructions on how to achieve the goal step-by-step using what is given.\nLet D∗ be a set consisting of open sets of data space D as well as data functions and relations on the open sets.\nDefinition 3.8 (Interpretation). An interpretation in ∆ is a map from D∗ to ∆ that maps each open set of D to a domain object (or a set of domain objects) in ∆, each data function in D∗ to a domain function in ∆, and each data relation in D∗ to a domain relation in ∆.\n2For the sake of convenience, we call any first-order logical formula over ∆ a domain relation; so\na proposition is also a domain relation.\nDefinition 3.9 (Implied relation). Any set of domain relations in ∆ which can be obtained from D∗ by means of interpretation in ∆ is a set of D-implied relations. Furthermore, any set of domain relations in ∆ which can be deduced from sets of D-implied relations is also a set of D-implied relations.\nTo retrieve information from X , one needs to mine domain objects and D-implied relations."
    }, {
      "heading" : "4 The Space of Information",
      "text" : "Definition 4.1 (Piece of information). A piece of information in ∆ is a pair 〈O,R〉, where O is a set of domain objects in ∆ and R is a set of domain relations in ∆ which involves the objects in O.\nExample 4.1. Let X in Example 3.1 be interpreted as a set X ′ = {3, 7, 11, 23} of mathematical numbers (i.e., ∆ is mathematics). Then X ′ with the relations that (1) the average (which is a derived object in ∆) of the numbers in X ′ is equal to 11 and (2) every number in X ′ is prime is a piece of information.\nEach piece of information can be presented in a standard mathematical structure (such as an ordered set, a table, a tree, or a graph).\nDefinition 4.2 (Implied information). Any piece of information in ∆ which can be obtained from D by means of interpretation in ∆ is a piece of D-implied information. Any piece of information in ∆ which can be deduced from pieces of D-implied information is also a piece of D-implied information.\nPieces of D-implied information may be retrieved from D and thus from the given data set X interpreted in ∆. To retrieve information from X , the domain ∆ must be specified or detected.\nExample 4.2. Assume that in the domain of administration, two open sets of a data space are interpreted into Cd and Bd. Cd, together with relations involving elements of Cd, is interpreted as a piece of information Ci for China and Bd, together with relations involving elements of Bd, is interpreted as a piece of information Bi for Beijing. Then Ci and Bi, together with D-implied information involving elements of Cd and/or Bd, form a piece of information Ai for China and Beijing.\nAi may contain such relations as “China is a country,” “Beijing is a city of China,” and “Beijing is the capital of China.” These relations are propositional and involve only the constants “China” and “Beijing” (without variables).\nDefinition 4.3 (Information space). The information space I of X for ∆ is the set S of pieces of D-implied information in ∆ endowed with a topology τI on S. Here τI is called the information structure of I.\nThere are different topologies, such as cofinite topology and discrete topology, which can be defined on S. In particular, as deductive relation → on S (a → b means that b can be deduced from a where a, b ∈ S) forms a preorder, a topology τ→ can thus be defined on S with respect to →.\nAn information space I of X for ∆ is said to be induced from a data space D of X if the information structure τI for I is constructed as follows:\n(a) if u ∈ τI , then u is a piece of D-implied information;\n(b) if u, v ∈ τI , then u ∩ v ∈ τI ;\n(c) if u, v ∈ τI , then u ∪ v ∈ τI .\nEach open set of an information space induced from a data space is a finite family of pieces of D-implied information with respect to the same set of objects in ∆.\nInformation is not necessarily true. It becomes knowledge when validated. For example, when “Beijing is the capital of China” is validated, it becomes part of a knowledge object."
    }, {
      "heading" : "5 The Space of Knowledge",
      "text" : "Knowledge is formulated from information spaces by means of induction, deduction, synthesis, modeling, and validation.\nDefinition 5.1 (Induction principle [9]). The principle of induction is a law to extrapolate from given information (called premises) and predict things containing more information than the premises make available. Let each domain object in ∆ be an instance of a concept or a class. Then the principle of induction may be stated as follows.\n(a) The greater the number of pieces of information in the form of 〈{o1, o2, . . . , on}, R〉 is, where each oi is an instance of a class Ci, the more probable it is (if no piece of information of failure of the relation R is known) that the relation R holds among all the instances of Ci for 1 6 i 6 n.\n(b) Under the same circumstances, a sufficient number of pieces of information on the relation R among some instances of C1, . . . , Cn will make it nearly certain that the relation R among other instances of C1, . . . , Cn is always satisfied, and will make this general law approach certainty without limit.\nThe induction principle may be used as a method to generalize propositional relations to quantified relations and as a scheme for the generation of induction proofs. Induction in a narrow sense refers to inferences with less than 100% probability\nbecause the conclusion is tentatively valid, provided that and so long as no cases are found that belie it; whereas deduction refers specifically to inferences with 100% probability [16].\nDefinition 5.2 (Deduction principle [16]). The principle of deduction is a law asserting that new relations or conclusions can be logically deduced from already established premises.\n(a) The conclusion must be fully justified by the premises.\n(b) The conclusion is sure and immutable, so long as no new information contradicts the premises.\nThe deduction principle may be used as a method to derive new information from known pieces of information and as a scheme for the generation of new relations (propositions in ∆).\nDefinition 5.3 (Modeling principle). The principle of modeling is a law pointing out that models for phenomena and their behaviors can be established from the information on instances of the phenomena and their behaviors.\n(a) Initial models are formulated with embedded parameters according to the information on the instances in analog to known models for similar phenomena.\n(b) The formulated models may be verified, modified, or improved iteratively through optimization of the parameter values by using additional information on the phenomena and their behaviors.\nThe modeling principle may be used to design schemes for the generation of algorithmic methods.\nDefinition 5.4 (Validation). A piece of information, a proposition, or a method may be validated by belief, by assumption, by proof, or by verification.\nProof may be deterministic or probabilistic and verification may be exhaustive or for samples in the domain. Statistical verification may be used for statements involving vague words such as “most,” “almost,” and “very.” Methods are validated usually by proofs or verifications for correctness.\nDefinition 5.5 (Knowledge object). A knowledge object is a description of a piece of information (representing a segment of a fact or a phenomenon), or a definition (of a function or a relation), or a proposition (representing a general law), or a method in the given domain, . . . , which has been validated.\nThere are mainly two types of knowledge objects, declarative and procedural.\nDefinition 5.6 (Declarative knowledge object). A knowledge object is said to be declarative if it declares a propositional or quantified relation.\nDefinition 5.7 (Procedural knowledge object). A knowledge object is said to be procedural if it specifies the functionality of a segment of a method in terms of input and output and provides the sequence of instructions on how to produce the output from the input.\nThe record of a sequence of operations performed according to the instructions provided in a procedural knowledge object for a particular input may also be considered as a knowledge object. Such knowledge objects include sequences of computations and proofs of theorems produced by general or particular methods and are secondary. They are also called procedural knowledge objects.\nBy synthesis we mean the generation of procedural knowledge objects from declarative ones. Validated pieces of information together with their extensions made by using induction, deduction, modeling, synthesis, and validation form the space of knowledge.\nExample 5.1. Refer to the previous example and let HasCapital(x) denote “x has a capital.” From the relations contained in Ai, one can conclude that HasCapital(China) by deduction and conjecture that “every country has a capital” by induction. The conjecture can be formulated as ∀x ∈ G (HasCapital(x)), where G denotes the set of all countries. When the conjecture is validated, it becomes part of a knowledge object in the domain of administration.\nDefinition 5.8 (Declarative knowledge space). The declarative knowledge space KT of X for ∆ is the set of declarative knowledge objects, which can be obtained from I for ∆ by applying the induction principle, the deduction principle, and validation mechanisms, endowed with a topology. The topology is called the knowledge structure of KT .\nDefinition 5.9 (Procedural knowledge space). The procedural knowledge space KP of X for ∆ is the set of procedural knowledge objects, which are valid in KT , endowed with a topology. The topology is called the knowledge structure of KP .\nDefinition 5.10 (Derivation relation). A derivation relation ։ is a binary relation on KT and KP . For any two knowledge objects o1 and o2, if o2 is obtained on the basis of o1, then we say that o2 is derived from o1, denoted as o1 ։ o2.\nThe derivation relation induces a partial order because it satisfies the following conditions for all o1, o2, and o3 inKT andKP : (1) o1 ։ o1; (2) if o1 ։ o2 and o2 ։ o1, then o1 = o2; (3) if o1 ։ o2 and o2 ։ o3, then o1 ։ o3. Therefore, the derivation relation also induces a preorder. Hence we can introduce knowledge structures τT։ and τP։ to define the declarative knowledge space KT։ and the procedural knowledge space KP։, respectively, because every open set of KT։ and KP։ is an upper set with respect to ։.\nDefinition 5.11 (Knowledge space). The knowledge space K of X for ∆ is the product of the declarative knowledge space KT and the procedural knowledge space KP , denoted as KT ×KP .\nDefinition 5.12 (Section of knowledge). A subset k of KT։ or KP։ is called a section of knowledge if\n(a) k is a singleton set containing only one element o from which no other element is derived and there is also no other element from which o is derived; or\n(b) for any two knowledge objects o0, om ∈ k, there exist o1, . . . , om−1 ∈ k such that oj is derived from oj−1 for j = 1, . . . , m; or\n(c) for any two knowledge objects o, o0 ∈ k, there exist om, . . . , o1 ∈ k such that o is derived from om and oj is derived from oj−1 for j = m, . . . , 1.\nA section k of knowledge is said to be complete if k cannot be enlarged. Each section of knowledge is an open set of KT։ or KP։.\nTheorem 5.1. If the knowledge space KT։ or KP։ is finite, then any set of the space may be uniquely decomposed into finitely many complete sections of knowledge.\nProof. Let k be a set of KT։ or KP։. If there exists an element o ∈ k such that no other element is derived from o and there is no other element from which o is derived, then k can be decomposed into a section of knowledge {o} and the set k \\ {o}. Otherwise, as the derivation relation ։ is a partial order, k with ։ can be represented as finitely many disjoint directed acyclic graphs. Each directed acyclic graph can be uniquely decomposed into finitely many longest chains of which each corresponds to a complete section of knowledge.\nConsider the set\nSK =\n{\nkT ⊗ kP\n∣ ∣ ∣ ∣ kT ⊂ KT , kP ⊂ KP , ∀a ∈ kT∃b ∈ kP (a ։ b), ∀b ∈ kP∃a ∈ kT (b ։ a) }\nof subspaces of K. An element kT ⊗ kP of SK is called a dual section of knowledge if both kT and kP are sections of knowledge. A dual section kT ⊗ kP ∈ Sk of knowledge is said to be complete if neither kT nor kP can be enlarged. A complete dual section of knowledge is also called a chapter of knowledge. A chapter of knowledge may be decomposed into dual sections of knowledge.\nAssumption. For each knowledge object oT in KT։, there exists at least one knowledge object oP in KP։ such that oT ։ oP or oP ։ oT ; for each knowledge object oP in KP։, there exists at least one knowledge object oT in KT։ such that oP ։ oT or oT ։ oP .\nUnder the above assumption, we can prove the following theorem.\nTheorem 5.2. If the knowledge space K։ = KT։ ×KP։ is finite, then K։ may be decomposed into finitely many chapters of knowledge. The decomposition is unique.\nProof. As the knowledge space K։ is finite, KT։ and KP։ must be finite. Then by Theorem 3, KT։ and KP։ can be uniquely decomposed into finitely many complete sections of knowledge, say ST1, ST2, . . . , STn and SP1, SP2, . . . , SPm, respectively. For each ST i and each SPj, there exists only one chapter kT ⊗ kP such that kT ⊂ ST i and kP ⊂ SPj for 1 6 i 6 n and 1 6 j 6 m. Under the assumption above, it is certain that the knowledge space K։ can be decomposed into such chapters. For each chapter kT ⊗ kP of knowledge, there must exist two and only two complete sections ST i and SPj of knowledge such that kT ⊂ ST i and kP ⊂ SPj where 1 6 i 6 n and 1 6 j 6 m. Therefore, the decomposition is unique.\nRemark. One can also define another binary relation on KT and KP . For any two knowledge objects o1 and o2, if o2 is related to o1, then o2 is said to be connected to o1. In this case, the relation has no “direction” and one can establish similar results for the relation.\nOne of the biggest challenges for implied knowledge discovery is how to effectively synthesize procedural knowledge objects from declarative ones. There are a few studies focused on specific issues, such as derivation of simple programs or algorithms from given specifications in particular declarative forms [17, 18], yet developing a general method or framework to mechanize and automate the process of synthesis is certainly hard."
    }, {
      "heading" : "6 Concluding Remarks",
      "text" : "We have introduced the three spaces of data, information, and knowledge with structures, from which one may observe how domain information and knowledge can be acquired from data. Some properties and characteristics of the three spaces are presented and their interrelations are clarified. More properties about the spaces of knowledge and their subspaces will be investigated further. Our study results in a general approach for the discovery of knowledge implied in data.\nThe data space D may be simple and small, while the knowledge space K built up from D for the given domain ∆ can become very rich because application of metaknowledge (mainly the induction and deduction principles) and domain knowledge to the information space I may yield many new and valuable knowledge objects which are related to or may be induced or deduced from D under the interpretation in ∆. Therefore, profound knowledge can be discovered from D by constructing knowledge objects of K according to specially designed domain-dependent procedures. The feasibility and effectiveness of our general approach has been demonstrated by our\nimplementation in the case of geometry [13], where nontrivial geometric theorems can be discovered automatically and efficiently from images of diagrams.\nTo apply our approach to discover knowledge of a concrete domain, one has to work on several issues, including formalization and representation of domain knowledge (see, e.g., [19]), design and implementation of induction and deduction schemes, and interpretation of data and retrieval of information from data in the domain. We shall report on the results of our studies in selected domains."
    } ],
    "references" : [ {
      "title" : "An introduction to scientific research",
      "author" : [ "B. Wilson E" ],
      "venue" : "New York: McGraw-Hill,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1952
    }, {
      "title" : "Big data: The next frontier for innovation, competition, and productivity",
      "author" : [ "J Manyika", "M Chui", "B Brown", "J Bughin", "R Dobbs", "C Roxburgh", "A. Byers" ],
      "venue" : "McKinsey Global Institute,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2011
    }, {
      "title" : "Top 10 algorithms in data mining",
      "author" : [ "D Wu X", "V Kumar", "R Quinlan J", "J Ghosh", "Q Yang", "H Motoda", "J McLachlan G", "A Ng", "B Liu", "S Yu P", "H Zhou Z", "M Steinbach", "J Hand D", "D. Steinberg" ],
      "venue" : "Knowledge and Information Systems,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2008
    }, {
      "title" : "Ensemble methods: Foundations and algorithms",
      "author" : [ "H. Zhou Z" ],
      "venue" : "Chapman and Hall/CRC,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "Navigation in a small world",
      "author" : [ "J. Kleinberg" ],
      "venue" : "Nature,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2000
    }, {
      "title" : "Graphs over time: densification laws, shrinking diameters and possible explanations",
      "author" : [ "J Leskovec", "J Kleinberg", "C. Faloutsos" ],
      "venue" : "Proceedings of the 11th ACM SIGKDD international conference on Knowledge discovery in data mining, Chicago,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2005
    }, {
      "title" : "Mining frequent patterns without candidate generation",
      "author" : [ "W Han J", "J Pei", "W. Yin Y" ],
      "venue" : "Newsletter ACM SIGMOD Record,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2000
    }, {
      "title" : "Data mining techniques and applications – A decade review",
      "author" : [ "H Liao S", "H Chu P", "Y. Hsiao P" ],
      "venue" : "Expert Systems with Applications,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2000
    }, {
      "title" : "The problems of philosophy",
      "author" : [ "B. Russell" ],
      "venue" : "Wilder Publications,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2009
    }, {
      "title" : "The logic of scientific discovery (Routledge Classics)",
      "author" : [ "K. Popper" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2002
    }, {
      "title" : "Mathematical logic: Foundations for information science",
      "author" : [ "W. Li" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2010
    }, {
      "title" : "Automated generation of geometric theorems from images of diagrams",
      "author" : [ "Y Chen X", "D Song", "M. Wang D" ],
      "venue" : "Geometric Reasoning — Special issue of the Annals of Mathematics and Artificial Intelligence. Springer,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Introduction to topology: third edition",
      "author" : [ "B. Mendelson" ],
      "venue" : "Dover Publications,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1990
    }, {
      "title" : "Topology and data",
      "author" : [ "G. Carlsson" ],
      "venue" : "Bulletin of the American Mathematical Society,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2009
    }, {
      "title" : "The principle of deduction",
      "author" : [ "A. Sion" ],
      "venue" : "TheLogician.net,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2012
    }, {
      "title" : "A Deductive Approach to Program Synthesis",
      "author" : [ "Z Manna", "R. Waldinger" ],
      "venue" : "ACM Transactions on Programming Languages and Systems,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1980
    }, {
      "title" : "Automated synthesis of some algorithms on finite sets",
      "author" : [ "I Dramnesc", "T. Jebelean" ],
      "venue" : "Proceedings of the 14th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2012
    }, {
      "title" : "Management of geometric knowledge in textbooks",
      "author" : [ "Y Chen X", "M. Wang D" ],
      "venue" : "Data & Knowledge Engineering,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "mining, machine learning, information retrieval, and knowledge discovery are some of the directions of research and development which have been given high priority in various national programs [1].",
      "startOffset" : 193,
      "endOffset" : 196
    }, {
      "referenceID" : 1,
      "context" : "It becomes more and more difficult to process collections of complex data with large volume, high velocity of change, uncertain veracity, and variety of types, called big data [2], using traditional methodologies and existing database management tools.",
      "startOffset" : 176,
      "endOffset" : 179
    }, {
      "referenceID" : 2,
      "context" : ", the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7].",
      "startOffset" : 85,
      "endOffset" : 88
    }, {
      "referenceID" : 3,
      "context" : ", the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7].",
      "startOffset" : 170,
      "endOffset" : 173
    }, {
      "referenceID" : 4,
      "context" : ", the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7].",
      "startOffset" : 279,
      "endOffset" : 288
    }, {
      "referenceID" : 5,
      "context" : ", the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7].",
      "startOffset" : 279,
      "endOffset" : 288
    }, {
      "referenceID" : 6,
      "context" : ", the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7].",
      "startOffset" : 279,
      "endOffset" : 288
    }, {
      "referenceID" : 7,
      "context" : "An integrated study of qualitative and quantitative methods from natural sciences with cognitive science, psychology, and human behaviors is likely to help enhance our understanding of information retrieval [8], hopefully resulting in revolutionary approaches for intelligent retrieval of information from big data.",
      "startOffset" : 207,
      "endOffset" : 210
    }, {
      "referenceID" : 8,
      "context" : "The principle of induction points out how to formulate conjectures as to acquire knowledge based on experience of a few existing cases [9].",
      "startOffset" : 135,
      "endOffset" : 138
    }, {
      "referenceID" : 9,
      "context" : "Holding a controversial view on the function of induction, Popper [11] argued that scientific theories are not inductively inferred from experience, nor is scientific experimentation carried out with a view to verifying or finally establishing the truth of theories; rather, all knowledge is",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 10,
      "context" : "Along this line of thought, Li [12] developed an operable revision calculus to deal with refutations and a logical framework for formalizing the process of scientific discovery.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 11,
      "context" : "The interested reader is encouraged to consult [13] for one such approach, which is capable of generating nontrivial geometric theorems from images of diagrams.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 12,
      "context" : "By definition of topology [14], it can be easily proved that τ is a topology on X .",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 13,
      "context" : "Therefore, methods from algebraic topology can be used to study the simplicial complex of X (see [15] for more details).",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 8,
      "context" : "1 (Induction principle [9]).",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 14,
      "context" : "because the conclusion is tentatively valid, provided that and so long as no cases are found that belie it; whereas deduction refers specifically to inferences with 100% probability [16].",
      "startOffset" : 182,
      "endOffset" : 186
    }, {
      "referenceID" : 14,
      "context" : "2 (Deduction principle [16]).",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 15,
      "context" : "There are a few studies focused on specific issues, such as derivation of simple programs or algorithms from given specifications in particular declarative forms [17, 18], yet developing a general method or framework to mechanize and automate the process of synthesis is certainly hard.",
      "startOffset" : 162,
      "endOffset" : 170
    }, {
      "referenceID" : 16,
      "context" : "There are a few studies focused on specific issues, such as derivation of simple programs or algorithms from given specifications in particular declarative forms [17, 18], yet developing a general method or framework to mechanize and automate the process of synthesis is certainly hard.",
      "startOffset" : 162,
      "endOffset" : 170
    }, {
      "referenceID" : 11,
      "context" : "implementation in the case of geometry [13], where nontrivial geometric theorems can be discovered automatically and efficiently from images of diagrams.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 17,
      "context" : ", [19]), design and implementation of induction and deduction schemes, and interpretation of data and retrieval of information from data in the domain.",
      "startOffset" : 2,
      "endOffset" : 6
    } ],
    "year" : 2014,
    "abstractText" : "We study the data space D of any given data set X and explain how functions and relations are defined over D. From D and for a specific domain ∆ we construct the information space I of X by interpreting variables, functions, and explicit relations over D in ∆ and by including other relations that D implies under the interpretation in ∆. Then from I we build up the knowledge space K of X as the product of two spaces KT and KP , where KT is obtained from I by using the induction principle to generalize propositional relations to quantified relations, the deduction principle to generate new relations, and standard mechanisms to validate relations and KP is the space of specifications of methods with operational instructions which are valid in KT . Through our construction of the three topological spaces the following key observation is made clear: the retrieval of information from the given data set for ∆ consists essentially in mining domain objects and relations, and the discovery of knowledge from the retrieved information consists essentially in applying the induction and deduction principles to generate propositions, synthesizing and modeling the information to generate specifications of methods with operational instructions, and validating the propositions and specifications. Based on this observation, efficient approaches may be designed to discover profound knowledge automatically from simple data, as demonstrated by the result of our study in the case of geometry.",
    "creator" : "LaTeX with hyperref package"
  }
}