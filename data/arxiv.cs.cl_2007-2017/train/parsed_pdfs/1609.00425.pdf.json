{
  "name" : "1609.00425.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Identifying Dogmatism in Social Media: Signals and Models",
    "authors" : [ "Ethan Fast", "Eric Horvitz" ],
    "emails" : [ "ethaen@stanford.edu,", "horvitz@microsoft.com" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "“I’m supposed to trust the opinion of a MS minion? The people that produced Windows ME, Vista and 8? They don’t even understand people, yet they think they can predict the behavior of new, selfguiding AI?” –anonymous\n“I think an AI would make it easier for Patients to confide their information because by nature, a robot cannot judge them. Win-win? :D”’ –anonymous\nDogmatism describes the tendency to lay down opinions as incontrovertibly true, without respect for conflicting evidence or the opinions of others (Oxford Dictionary, 2016). Which user is more dogmatic in the examples above? This question is simple for humans. Phrases like “they think” and “they\ndon’t even understand,” suggest an intractability of opinion, while “I think” and “win-win?” suggest the opposite. Can we train computers to draw similar distinctions? Work in psychology has called out many aspects of dogmatism that can be modeled computationally via natural language, such as overconfidence and strong emotions (Rokeach, 1954).\nWe present a statistical model of dogmatism that addresses two complementary goals. First, we validate psychological theories by examining the predictive power of feature sets that guide the model’s predictions. For example, do linguistic signals of certainty help to predict a post is dogmatic, as theory would suggest? Second, we apply our model to answer four questions:\nR1: What kinds of topics (e.g., guns, LGBT) attract the highest levels of dogmatism?\nR2: How do dogmatic beliefs cluster? R3: How does dogmatism influence a conversation on social media? R4: How do other user behaviors (e.g., frequency and breadth of posts) relate to dogmatism? We train a predictive model to classify dogmatic posts from Reddit, one of the most popular discussion communities on the web.1 Posts on Reddit capture discussion and debate across a diverse set of domains and topics – users talk about everything from climate change and abortion, to world news and relationship advice, to the future of artificial intelligence. As a prerequisite to training our model, we have created a corpus of 5,000 Reddit posts annotated with levels of dogmatism, which we are releasing to share with other researchers.\n1http://www.reddit.com\nar X\niv :1\n60 9.\n00 42\n5v 1\n[ cs\n.C L\n] 1\nS ep\n2 01\nUsing the model, we operationalize key domainindependent aspects of psychological theories of dogmatism drawn from the literature. We find these features have predictive power that largely supports the underlying theory. For example, posts that use less confident language tend to be less dogmatic. We also discover evidence for new attributes of dogmatism. For example, dogmatic posts tend not to verbalize cognition, through terms such as “I think,” “possibly,” or “might be.”\nOur model is trained on only 5,000 annotated posts, but once trained, we use it to analyze millions of other Reddit posts to answer our research questions. We find a diverse set of topics are colored by dogmatic language (e.g., people are dogmatic about religion, but also about LGBT issues). Further, we find some evidence for dogmatism as a deeper personality trait – people who are strongly dogmatic about one topic are more likely to express dogmatic views about others as well. Finally, in conversation, we discover that one user’s dogmatism tends to bring out dogmatism in their conversational partner, forming a vicious cycle."
    }, {
      "heading" : "2 Dogmatism data",
      "text" : "Posts on Reddit capture debate and discussion across a diverse set of topics, making them a natural starting point for untangling domain-independent linguistic features of dogmatism.\nData collection. Subreddits are sub-communities on Reddit oriented around specific interests or topics, such as technology or politics. Sampling from Reddit as a whole would bias the model towards the\nmost commonly discussed content. But by sampling posts from individual subreddits, we can control the kinds of posts we use to train our model. To collect a diverse training dataset, we have randomly sampled 1000 posts each from the subreddits politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. All posts in our sample appeared between January 2007 and March 2015, and to control for length effects, contain between 300 and 400 characters. This results in a total training dataset of 5000 posts.\nDogmatism annotations. Building a useful computational model requires labeled training data. We labeled the Reddit dataset using crowdworkers on Amazon Mechanical Turk (AMT), creating the first public corpus annotated with levels of dogmatism. We asked crowdworkers to rate levels of dogmatism on a 5-point Likert scale, as supported by similar annotation tasks in prior work (Danescu-NiculescuMizil et al., 2013). Concretely, we gave crowdworkers the following task:\nGiven a comment, imagine you hold a wellinformed, different opinion from the commenter in question. We’d like you to tell us how likely that commenter would be to engage you in a constructive conversation about your disagreement, where you each are able to explore the other’s beliefs. The options are: (5): It’s unlikely you’ll be able to engage in any substantive conversation. When you respectfully express your disagreement, they are likely to ignore you or insult you or otherwise lower the level of discourse. (4): They are deeply rooted in their opinion, but you are able to exchange your views without the conversation degenerating too much. (3): It’s not likely you’ll be able to change their mind, but you’re easily able to talk and understand each other’s point of view. (2): They may have a clear opinion about the subject, but would likely be open to discussing alternative viewpoints. (1): They are not set in their opinion, and it’s possible you might change their mind. If the comment does not convey an opinion of any kind, you may also select this option.\nTo ensure quality work, we restricted the task to Masters workers and provided examples corresponding to each point on the scale. Including examples in a task has been shown to significantly increase the agreement and quality of crowdwork\n(Doroudi et al., 2016). For instance, here is an example of a highly dogmatic (5) comment:\nI won’t be happy until I see the executive suite of BofA, Wells, and all the others, frogmarched into waiting squad cars. It’s ALREADY BEEN ESTABLISHED that...\nAnd a minimally dogmatic (1) comment:\nI agree. I would like to compile a playlist for us trance yogi’s, even if you just would like to experiment with it. Is there any preference on which platform to use?\nEach comment has been annotated by three independent workers on AMT, which is enough to produce reliable results in most labeling tasks (Sheng et al., 2008). To compute an aggregate measure of dogmatism for each comment, we summed the scores of all three workers. We show the resulting distribution of annotations in Figure 1.\nInter-annotator agreement. To evaluate the reliability of annotations we compute Krippendorff’s α, a measure of agreement designed for variable levels of measurement such as a Likert scale (Hayes and Krippendorff, 2007). An α of 0 indicates agreement indistinguishable from chance, while an α of 1 indicates perfect agreement. Across all annotations we find α = 0.44. While workers agree much more than chance, clearly dogmatism is also subjective. In fact, when we examine only the middle two quartiles of the dogmatism annotations, we find agreement is no better than chance. Alternatively, when we measure agreement only among the top and bottom quartiles of annotations, we find agreement of α = 0.69. This suggests comments with scores that are only slightly dogmatic are unreliable and often subject to human disagreement. For this reason, we use only the top and bottom quartiles of comments when training our model."
    }, {
      "heading" : "3 Approaches to Identifying Dogmatism",
      "text" : "We now consider strategies for identifying dogmatism based on prior work in psychology. We start with the Linguistic Inquiry and Word Count (LIWC), a lexicon popular in the social sciences (Pennebaker et al., 2001). LIWC provides human validated lists of words that correspond to highlevel psychological categories such as certainty or perception. In other studies, LIWC has uncovered\nlinguistic signals relating to politeness (DanescuNiculescu-Mizil et al., 2013), deception (Yoo and Gretzel, 2009), or authority in texts (Gilbert, 2012). Here, we examine how dogmatism relates to 17 of LIWC’s categories (Table 1).\nTo compute the relationships between LIWC categories and dogmatism, we first count the relevant category terms that appear in each annotated Reddit comment, normalized by its word count. We then calculate odds ratios on the aggregate counts of each LIWC category over the top and bottom quartiles of dogmatic comments. As we have discussed, using the top and bottom quartiles of comments provides a more reliable signal of dogmatism. We check for significant differences in categories between dogmatic and non-dogmatic comments using the MannWhitney U test and apply Holmes method for correction. All odds we report in this section are significant after correction.\nDogmatic statements tend to express a high degree of certainty (Rokeach, 1954). Here we consider LIWC categories that express certainty both positively (certainty) and negatively (tentativeness). For example, the word “always” is certain, while “possibly” is tentative. Conforming to existing theory, certainty is more associated with dogmatic comments (1.52 odds), while tentativeness is more associated with the absence of dogmatism (0.88 odds).\nTerms used to verbalize cognition can act as a hedge that often characterizes non-dogmatic language. LIWC’s insight category captures this effect through words such as “think,” “know,” or “believe.” These words add nuance to a statement (Pennebaker and Francis, 1996), signaling it is the product of someone’s mind (“I think you should give this paper a good review”) and not meant to be interpreted as an objective truth. Along these lines, we find the use of terms in the insight category is associated with non-dogmatic comments (0.83 odds).\nSensory language, with its focus on description and detail, often signals a lack of any kind of opinion, dogmatic or otherwise. LIWC’s perception category captures this idea through words associated with hearing, feeling, or seeing. For example, these words might occur when recounting a personal experience (“I saw his incoming fist”), which even if emotionally charged or negative, is less likely to be dogmatic. We find perception is associated with\nnon-dogmatic comments at 0.77 odds. Drawing comparisons or qualifying something as relative to something else conveys a nuance that is absent from traditionally dogmatic language. The LIWC categories comparison and relativity capture these effects through comparison words such as “than” or “as” and qualifying words such as “during” or “when.” For example, the statement “I hate politicians” is more dogmatic than “I hate politicians when they can’t get anything done.’ Relativity is associated with non-dogmatic comments at 0.80 odds, but comparison does not reach significance. Pronouns can be surprisingly revealing indicators of language: for example, signaling one’s gender or hierarchical status in a conversation (Pennebaker, 2011). We find first person singular pronouns are a useful negative signal for dogmatism (0.46 odds), while second person singular pronouns (2.18 odds) and third person plural (1.63 odds) are a useful positive signal. Looking across the corpus, we see I often used with a hedge (“I think” or “I know”), while you and they tend to characterize the beliefs of oth-\ners, often in a strongly opinionated way (“you are a moron” or “they are keeping us down”). Other pronoun types do not show significant relationships.\nLike pronouns, verb tense can reveal subtle signals in language use, such as the tendency of medical inpatients to focus on the past (Wolf et al., 2007). On social media, comments written in the present tense are more likely to be oriented towards a user’s current interaction (“this is all so stupid”), creating opportunities to signal dogmatism. Alternatively, comments in the past tense are more likely to refer to outside experiences (“it was an awful party”), speaking less to a user’s stance towards an ongoing discussion. We find present tense is a positive signal for dogmatism (1.11 odds) and past tense is a negative signal (0.69 odds).\nDogmatic language can be either positively or negatively charged in sentiment: for example, consider the positive statement “Trump is the SAVIOR of this country!!!” or the negative statement “Are you REALLY that stupid?? Education is the only way out of this horrible mess. It’s hard to imagine how anyone could be so deluded.” In diverse communities, where people hold many different kinds of opinions, dogmatic opinions will often tend to come into conflict with one another (McCluskey and Hmielowski, 2012), producing a greater likelihood of negative sentiment. Perhaps for this reason, negative emotion (2.09 odds) and swearing (3.80 odds) are useful positive signals of dogmatism, while positive emotion shows no significant relationship.\nFinally, we find that interrogative language (1.12 odds) and negation (1.35 odds) are two additional positive signals of dogmatism. While interrogative words like “how” or “what” have many benign uses, they disproportionately appear in our data in the form of rhetorical or emotionally charged questions, such as “how can anyone be that dumb?”\nMany of these linguistic signals are correlated with each other, suggesting that dogmatism is the cumulative effect of many component relationships. For example, consider the relatively non-dogmatic statement: “I think the reviewers are wrong in this instance.” Removing signals of insight, we have: “the reviewers are wrong in this instance,” which is slightly more dogmatic. Then removing relativity, we have: “the reviewers are wrong.” And finally, adding certainty, we have a dogmatic state-\nment: “the reviewers are always wrong.”"
    }, {
      "heading" : "4 Predicting dogmatism",
      "text" : "We now show how we can use the linguistic feature sets we have described to build a classifier that predicts dogmatism in comments. A predictive model further validates our feature sets, and also allows us to analyze dogmatism in millions of other Reddit comments in a scalable way, with multiple uses in ongoing, downstream analyses.\nPrediction task. Our goal is (1) to understand how well we can use the strategies in Section 3 to predict dogmatism, and (2) to test the domainindependence of these strategies. First, we test the performance of our model under cross-validation within the Reddit comment dataset. We then evaluate the Reddit-based model on a held out corpus of New York Times comments annotated using the technique in Section 2. We did not refer to this second dataset during feature construction.\nFor classification, we consider two classes of comments: dogmatic and non-dogmatic. As in the prior analysis, we draw these comments from the top and bottom quartiles of the dogmatism distribution. This means the classes are balanced, with 2,500 total comments in the Reddit training data and 500 total comments in the New York Times testing data.\nWe compare the predictions of logistic regression models based on unigram bag-of-words features (BOW), sentiment signals2 (SENT), the linguistic\n2For SENT, we use normalized word counts from LIWC’s positive and negative emotional categories.\nfeatures from our earlier analyses (LING), and combinations of these features. BOW and SENT provide baselines for the task. We compute BOW features using term frequency-inverse document frequency (TF-IDF) and category-based features by normalizing counts for each category by the number of words in each document. The BOW classifiers are trained with regularization (L2 penalties of 1.5).\nClassification results. We present classification accuracy in Table 2. BOW shows an AUC of 0.853 within Reddit and 0.776 on the held out New York Times comments. The linguistic features boost classification results within Reddit (0.881) and on the held out New York Times comments (0.791). While linguistic signals by themselves provide strong predictive power (0.801 AUC within domain), sentiment signals are much less predictive.\nThese results suggest that linguistic features inspired by prior efforts in psychology are useful for predicting dogmatism in practice and generalize across new domains."
    }, {
      "heading" : "5 Dogmatism in the Reddit Community",
      "text" : "We now apply our dogmatism classifier to a larger dataset of posts, examining how dogmatic language shapes the Reddit community. Concretely, we apply the BOW+LING model trained on the full Reddit dataset to millions of new unannotated posts, labeling these posts with a probability of dogmatism according to the classifier (0=non-dogmatic, 1=dogmatic). We then use these dogmatism annotations to address four research questions."
    }, {
      "heading" : "5.1 What subreddits have the highest and lowest levels of dogmatism? (R1)",
      "text" : "A natural starting point for analyzing dogmatism on Reddit is to examine how it characterizes the site’s sub-communities. For example, we might expect to see that subreddits oriented around topics such as abortion or climate change are more dogmatic, and subreddits about cooking are less so.\nTo answer this question, we randomly sample 1.6 million posts from the entire Reddit community between 2007 and 2015. We then annotate each of these posts with dogmatism using our classifier, and compute the average dogmatism level for each subreddit in the sample with at least 100 posts.\nWe present the results of this analysis in Table 3. The subreddits with the highest levels of dogmatism tend to be oriented around politics and religion (DebateAChristian or ukpolitics), while those with the lowest levels tend to focus on hobbies (photography or homebrewing). The subreddit with the highest average dogmatism level, cringepics, is a place to make fun of socially awkward messages, often from would-be romantic partners. Dogmatism here tends to take the form of “how could someone be that stupid” and is directed at the subject of the post, as opposed to other members of the community.\nSimilarly, SubredditDrama is a community where people come to talk about fights on the internet or social media. These fights are often then extended in discussion, for example: “If the best you can come up with is that something you did was legal, it’s probably time to own up to being an ass.” The presence of this subreddit in our analysis provides a further sanity check that our model is capturing a robust signal of dogmatism."
    }, {
      "heading" : "5.2 How do dogmatic beliefs cluster? (R2)",
      "text" : "Dogmatism is widely considered to be a domainspecific attitude (for example, oriented towards religion or politics) as opposed to a deeper personality trait (Rokeach, 1954). Here we use Reddit as a lens to examine this idea more closely. Are users who are dogmatic about one topic likely to be dogmatic about others? Do clusters of dogmatism exist around particular topics? To find out, we examine the re-\nlationships between subreddits over which individual users are dogmatic. For example, if many users often post dogmatic comments on both the politics and Christianity subreddits, but less often on worldnews, that would suggest politics and Christianity are linked per a boost in likelihood of individuals being dogmatic in both.\nWe sample 1000 Reddit users who posted at least once a year between 2007 and 2015 to construct a corpus of 10 million posts that constitute their entire post history. We then annotate these posts using the classifier and compute the average dogmatism score per subreddit per user. For example, one user might have an average dogmatism level of 0.55 for the politics subreddit and 0.45 for the economics subreddit. Most users do not post in all subreddits, so we track only subreddits for which a user had posted at least 10 times. Any subreddits with an average dogmatism score higher than 0.50 we consider to be a user’s dogmatic subreddits. We then count all pairs of these dogmatic subreddits. For example, 45 users have politics and technology among their dogmatic subreddits, so we consider politics and technology as linked 45 times. We compute the mutual information (Church and Hanks, 1990) between these links, which gives us a measure of the subreddits that are most related through dogmatism.\nWe present the results of this analysis in Table 4, choosing clusters that represent a diverse set of topics. For example, Libertarianism is linked through dogmatism to other political communities like Anarcho Capitalism, ronpaul, or ukpolitics, as well as other topical subreddits like guns or economy. Similarly, people who are dogmatic in the business subreddit also tend to be dogmatic in subreddits for Bitcoin, socialism, and technology. Notably, when we apply the same mutual information analysis to links defined by subreddits posted in by the same user, we\nsee dramatically different results. For example, the subreddits most linked to science through user posts are UpliftingNews, photoshopbattles, and firstworldanarchist, and millionairemakers.\nFinally, we see less obvious connections between subreddits that suggest some people may be dogmatic by nature. For example, among the users who are dogmatic on politics, they are also disproportionately dogmatic on unrelated subreddits such as science (p < 0.001), technology (p < 0.001), IAmA (p < 0.001), and AskReddit (p < 0.05), with pvalues computed under a binomial test."
    }, {
      "heading" : "5.3 What user behaviors are predictive of dogmatism? (R3)",
      "text" : "We have shown dogmatism is captured by many linguistic features, but can we discover other high-level user behaviors that are similarly predictive?\nTo find out, we compute metrics of user behavior using the data sample of 1000 users and 10 million posts described in Section 5.2. Specifically, we calculate (1) activity: a user’s total number of posts, (2) breadth: the number of subreddits a user has posted in, (3) focus: the proportion of a user’s posts that appear in the subreddit where they are most active, and (4) engagement: the average number of posts a user contributes to each discussion they engage in.\nWe then fit these behavioral features to a linear regression model where we predict each user’s average dogmatism level. Positive coefficients in this model are positively predictive of dogmatism, while negative coefficients are negatively predictive.\nWe find this model is significantly predicitive of dogmatism (R2 = 0.1, p < 0.001), with all features reaching statistical significance (p < 0.001). Activity and focus are positively associated with dogmatism, while breadth and engagement are negatively associated (Table 5). Together, these results suggest dogmatic users tend to post frequently and in specific communities, but are not as inclined to continue to engage with a discussion, once it has begun."
    }, {
      "heading" : "5.4 How does dogmatism impact a conversation? (R4)",
      "text" : "How does interacting with a dogmatic comment impact a conversation? Are users able to shrug it off? Or do otherwise non-dogmatic users become more dogmatic themselves?\nTo answer this question, we sample 600,000 conversations triples from Reddit. These conversations consist of two people (A and B) talking, with the structure: A1 → B → A2. This allows us to measure the impact of B’s dogmatism on A’s response, while also controlling for the dogmatism level initially set by A. Concretely, we model the impact of dogmatism on these conversations through a linear regression. This model takes two features, the dogmatism levels of A1 and B, and predicts the dogmatism response of A2. If B’s dogmatism has no effect on A’s response, the coefficient that corresponds to B will not be significant in the model. Alternatively, if B’s dogmatism does have some effect, it will be captured by the model’s coefficient.\nWe find the coefficient of the B feature in the model is positively associated with dogmatism (p < 0.001). In other words, engagement with a dogmatic comment tends to make a user more dogmatic themselves. This effect holds when we run the same model on data subsets consisting only of dogmatic or non-dogmatic users, and also when we conservatively remove all words used by B from A’s response (i.e., controlling for quoting effects)."
    }, {
      "heading" : "6 Related Work",
      "text" : "In contrast to the computational models we have presented, dogmatism is usually measured in psychology through survey scales, in which study participants answer questions designed to reveal underlying personality attributes (Rokeach, 1954). Over time, these surveys have been updated (Shearman and Levine, 2006) and improved to meet standards of psychometric validity (Crowson, 2009).\nThese surveys are often used to study the relationship between dogmatism and other psychological phenomena. For example, dogmatic people tend to show an increased tendency for confrontation (ElNawawy and Powers, 2010) or moral conviction and religiosity (Swink, 2011), and less likelihood of cognitive flexibility (Martin et al., 2011), even among stereotypically non-dogmatic groups like atheists (Gurney et al., 2013). From a behavioral standpoint, dogmatic people solve problems differently, spending less time framing a problem and expressing more certainty in their solution (Lohman, 2010). Here we similarly examine how user behaviors on Reddit relate to a language model of dogmatism.\nErtel sought to capture dogmatism linguistically, though a small lexicon of words that correspond with high-level concepts like certainty and compromise (1985). McKenny then used this dictionary to relate dogmatism to argument quality in student essays (2005). Our work expands on this approach, applying supervised models based on a broader set of linguistic categories to identify dogmatism in text.\nOther researchers have studied topics similar to dogmatism, such as signals of cognitive style in right-wing political thought (Van Hiel et al., 2010), the language used by trolls on social media (Cheng et al., 2015), or what makes for impartial language on twitter (Zafar et al., 2016). A similar flavor of work has examined linguistic models that capture politeness (Danescu-Niculescu-Mizil et al., 2013), deception (Ott et al., 2011), and authority (Gilbert, 2012). We took inspiration from these models when constructing the feature sets in our work.\nFinally, while we examine what makes an opinion dogmatic, other work has pushed further into the structure of arguments, for example classifying their justifications (Hasan and Ng, 2014), or what makes an argument likely to win (Tan et al., 2016). Our\nmodel may allow future researchers to probe these questions more deeply."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We have constructed the first corpus of social media posts annotated with dogmatism scores, allowing us to explore linguistic features of dogmatism and build a predictive model that analyzes new content. We apply this model to Reddit, where we discover behavioral predictors of dogmatism and topical patterns in the comments of dogmatic users.\nCould we use this computational model to help users shed their dogmatic beliefs? Looking forward, our work makes possible new avenues for encouraging pro-social behavior in online communities."
    } ],
    "references" : [ {
      "title" : "Antisocial behavior in online discussion communities",
      "author" : [ "Cheng et al.2015] Justin Cheng", "Cristian DanescuNiculescu-Mizil", "Jure Leskovec" ],
      "venue" : "arXiv preprint arXiv:1504.00680",
      "citeRegEx" : "Cheng et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Cheng et al\\.",
      "year" : 2015
    }, {
      "title" : "Word association norms, mutual information, and lexicography",
      "author" : [ "Church", "Hanks1990] Kenneth Ward Church", "Patrick Hanks" ],
      "venue" : "Computational linguistics,",
      "citeRegEx" : "Church et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Church et al\\.",
      "year" : 1990
    }, {
      "title" : "Does the dog scale measure dogmatism? another look at construct validity",
      "author" : [ "H Michael Crowson" ],
      "venue" : "The Journal of social psychology,",
      "citeRegEx" : "Crowson.,? \\Q2009\\E",
      "shortCiteRegEx" : "Crowson.",
      "year" : 2009
    }, {
      "title" : "A computational approach to politeness with application to social factors",
      "author" : [ "Moritz Sudhof", "Dan Jurafsky", "Jure Leskovec", "Christopher Potts" ],
      "venue" : "arXiv preprint arXiv:1306.6078",
      "citeRegEx" : "DanescuNiculescu.Mizil et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "DanescuNiculescu.Mizil et al\\.",
      "year" : 2013
    }, {
      "title" : "Toward a learning science for complex crowdsourcing tasks",
      "author" : [ "Ece Kamar", "Emma Brunskill", "Eric Horvitz" ],
      "venue" : "In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems,",
      "citeRegEx" : "Doroudi et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Doroudi et al\\.",
      "year" : 2016
    }, {
      "title" : "Al-jazeera english a conciliatory medium in a conflict-driven environment",
      "author" : [ "El-Nawawy", "Powers2010] Mohammed El-Nawawy", "Shawn Powers" ],
      "venue" : "Global Media and Communication,",
      "citeRegEx" : "El.Nawawy et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "El.Nawawy et al\\.",
      "year" : 2010
    }, {
      "title" : "Content analysis: An alternative approach to open and closed minds",
      "author" : [ "S Ertel" ],
      "venue" : "The High School Journal,",
      "citeRegEx" : "Ertel.,? \\Q1985\\E",
      "shortCiteRegEx" : "Ertel.",
      "year" : 1985
    }, {
      "title" : "Phrases that signal workplace hierarchy",
      "author" : [ "Eric Gilbert" ],
      "venue" : "In Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work,",
      "citeRegEx" : "Gilbert.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gilbert.",
      "year" : 2012
    }, {
      "title" : "Believe it or not: Exploring the relationship between dogmatism and openness within non-religious samples",
      "author" : [ "Shelley McKeown", "Jamie Churchyard", "Neil Howlett" ],
      "venue" : "Personality and Individual Differences,",
      "citeRegEx" : "Gurney et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Gurney et al\\.",
      "year" : 2013
    }, {
      "title" : "Why are you taking this stance? identifying and classifying reasons in ideological debates",
      "author" : [ "Hasan", "Ng2014] Kazi Saidul Hasan", "Vincent Ng" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Hasan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hasan et al\\.",
      "year" : 2014
    }, {
      "title" : "Answering the call for a standard reliability measure for coding data",
      "author" : [ "Hayes", "Krippendorff2007] Andrew F Hayes", "Klaus Krippendorff" ],
      "venue" : "Communication methods and measures,",
      "citeRegEx" : "Hayes et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Hayes et al\\.",
      "year" : 2007
    }, {
      "title" : "An unexamined triumvirate: dogmatism, problem solving, and hrd. Human Resource Development Review",
      "author" : [ "Margaret C Lohman" ],
      "venue" : null,
      "citeRegEx" : "Lohman.,? \\Q2010\\E",
      "shortCiteRegEx" : "Lohman.",
      "year" : 2010
    }, {
      "title" : "The relationships between cognitive flexibility with dogmatism, intellectual flexibility, preference for consistency, and self-compassion",
      "author" : [ "Sydney M Staggers", "Carolyn M Anderson" ],
      "venue" : "Communication Research Reports,",
      "citeRegEx" : "Martin et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Martin et al\\.",
      "year" : 2011
    }, {
      "title" : "Finding deceptive opinion spam by any stretch of the imagination",
      "author" : [ "Ott et al.2011] Myle Ott", "Yejin Choi", "Claire Cardie", "Jeffrey T Hancock" ],
      "venue" : "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language",
      "citeRegEx" : "Ott et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Ott et al\\.",
      "year" : 2011
    }, {
      "title" : "Cognitive, emotional, and language processes in disclosure",
      "author" : [ "Pennebaker", "Francis1996] James W Pennebaker", "Martha E Francis" ],
      "venue" : "Cognition & Emotion,",
      "citeRegEx" : "Pennebaker et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Pennebaker et al\\.",
      "year" : 1996
    }, {
      "title" : "Linguistic inquiry and word count",
      "author" : [ "Martha E Francis", "Roger J Booth" ],
      "venue" : "Liwc",
      "citeRegEx" : "Pennebaker et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Pennebaker et al\\.",
      "year" : 2001
    }, {
      "title" : "Dogmatism updated: A scale revision and validation",
      "author" : [ "Shearman", "Levine2006] Sachiyo M Shearman", "Timothy R Levine" ],
      "venue" : "Communication Quarterly,",
      "citeRegEx" : "Shearman et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Shearman et al\\.",
      "year" : 2006
    }, {
      "title" : "Get another label? improving data quality and data mining using multiple, noisy labelers",
      "author" : [ "Sheng et al.2008] Victor S Sheng", "Foster Provost", "Panagiotis G Ipeirotis" ],
      "venue" : "Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and",
      "citeRegEx" : "Sheng et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Sheng et al\\.",
      "year" : 2008
    }, {
      "title" : "Dogmatism and moral conviction in individuals: Injustice for all",
      "author" : [ "Nathan Swink" ],
      "venue" : null,
      "citeRegEx" : "Swink.,? \\Q2011\\E",
      "shortCiteRegEx" : "Swink.",
      "year" : 2011
    }, {
      "title" : "Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions",
      "author" : [ "Tan et al.2016] Chenhao Tan", "Vlad Niculae", "Cristian Danescu-Niculescu-Mizil", "Lillian Lee" ],
      "venue" : "Proceedings of WWW",
      "citeRegEx" : "Tan et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2016
    }, {
      "title" : "The relationship between social-cultural attitudes and behavioral measures of cognitive style: A meta-analytic integration of studies",
      "author" : [ "Emma Onraet", "Sarah De Pauw" ],
      "venue" : "Journal of personality,",
      "citeRegEx" : "Hiel et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Hiel et al\\.",
      "year" : 2010
    }, {
      "title" : "Linguistic analyses of natural written language: Unobtrusive assessment of cognitive style in eating disorders",
      "author" : [ "Wolf et al.2007] Markus Wolf", "Jan Sedway", "Cynthia M Bulik", "Hans Kordy" ],
      "venue" : "International Journal of Eating Disorders,",
      "citeRegEx" : "Wolf et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Wolf et al\\.",
      "year" : 2007
    }, {
      "title" : "Comparison of deceptive and truthful travel reviews. Information and communication technologies in tourism",
      "author" : [ "Yoo", "Gretzel2009] Kyung-Hyan Yoo", "Ulrike Gretzel" ],
      "venue" : null,
      "citeRegEx" : "Yoo et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Yoo et al\\.",
      "year" : 2009
    }, {
      "title" : "Message impartiality in social media discussions",
      "author" : [ "Krishna P Gummadi", "Cristian Danescu-Niculescu-Mizil" ],
      "venue" : "In Tenth International AAAI Conference on Web and Social Media",
      "citeRegEx" : "Zafar et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Zafar et al\\.",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "(Doroudi et al., 2016).",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 17,
      "context" : "Each comment has been annotated by three independent workers on AMT, which is enough to produce reliable results in most labeling tasks (Sheng et al., 2008).",
      "startOffset" : 136,
      "endOffset" : 156
    }, {
      "referenceID" : 15,
      "context" : "We start with the Linguistic Inquiry and Word Count (LIWC), a lexicon popular in the social sciences (Pennebaker et al., 2001).",
      "startOffset" : 101,
      "endOffset" : 126
    }, {
      "referenceID" : 3,
      "context" : "In other studies, LIWC has uncovered linguistic signals relating to politeness (DanescuNiculescu-Mizil et al., 2013), deception (Yoo and Gretzel, 2009), or authority in texts (Gilbert, 2012).",
      "startOffset" : 79,
      "endOffset" : 116
    }, {
      "referenceID" : 7,
      "context" : ", 2013), deception (Yoo and Gretzel, 2009), or authority in texts (Gilbert, 2012).",
      "startOffset" : 66,
      "endOffset" : 81
    }, {
      "referenceID" : 21,
      "context" : "Like pronouns, verb tense can reveal subtle signals in language use, such as the tendency of medical inpatients to focus on the past (Wolf et al., 2007).",
      "startOffset" : 133,
      "endOffset" : 152
    }, {
      "referenceID" : 2,
      "context" : "Over time, these surveys have been updated (Shearman and Levine, 2006) and improved to meet standards of psychometric validity (Crowson, 2009).",
      "startOffset" : 127,
      "endOffset" : 142
    }, {
      "referenceID" : 18,
      "context" : "For example, dogmatic people tend to show an increased tendency for confrontation (ElNawawy and Powers, 2010) or moral conviction and religiosity (Swink, 2011), and less likelihood of cognitive flexibility (Martin et al.",
      "startOffset" : 146,
      "endOffset" : 159
    }, {
      "referenceID" : 12,
      "context" : "For example, dogmatic people tend to show an increased tendency for confrontation (ElNawawy and Powers, 2010) or moral conviction and religiosity (Swink, 2011), and less likelihood of cognitive flexibility (Martin et al., 2011), even among stereotypically non-dogmatic groups like atheists (Gurney et al.",
      "startOffset" : 206,
      "endOffset" : 227
    }, {
      "referenceID" : 8,
      "context" : ", 2011), even among stereotypically non-dogmatic groups like atheists (Gurney et al., 2013).",
      "startOffset" : 70,
      "endOffset" : 91
    }, {
      "referenceID" : 11,
      "context" : "From a behavioral standpoint, dogmatic people solve problems differently, spending less time framing a problem and expressing more certainty in their solution (Lohman, 2010).",
      "startOffset" : 159,
      "endOffset" : 173
    }, {
      "referenceID" : 0,
      "context" : ", 2010), the language used by trolls on social media (Cheng et al., 2015), or what makes for impartial language on twitter (Zafar et al.",
      "startOffset" : 53,
      "endOffset" : 73
    }, {
      "referenceID" : 23,
      "context" : ", 2015), or what makes for impartial language on twitter (Zafar et al., 2016).",
      "startOffset" : 57,
      "endOffset" : 77
    }, {
      "referenceID" : 13,
      "context" : ", 2013), deception (Ott et al., 2011), and authority (Gilbert, 2012).",
      "startOffset" : 19,
      "endOffset" : 37
    }, {
      "referenceID" : 7,
      "context" : ", 2011), and authority (Gilbert, 2012).",
      "startOffset" : 23,
      "endOffset" : 38
    }, {
      "referenceID" : 19,
      "context" : "Finally, while we examine what makes an opinion dogmatic, other work has pushed further into the structure of arguments, for example classifying their justifications (Hasan and Ng, 2014), or what makes an argument likely to win (Tan et al., 2016).",
      "startOffset" : 228,
      "endOffset" : 246
    } ],
    "year" : 2016,
    "abstractText" : "We explore linguistic and behavioral features of dogmatism in social media and construct statistical models that can identify dogmatic comments. Our model is based on a corpus of Reddit posts, collected across a diverse set of conversational topics and annotated via paid crowdsourcing. We operationalize key aspects of dogmatism described by existing psychology theories (such as over-confidence), finding they have predictive power. We also find evidence for new signals of dogmatism, such as the tendency of dogmatic posts to refrain from signaling cognitive processes. When we use our predictive model to analyze millions of other Reddit posts, we find evidence that suggests dogmatism is a deeper personality trait, present for dogmatic users across many different domains, and that users who engage on dogmatic comments tend to show increases in dogmatic posts themselves.",
    "creator" : "LaTeX with hyperref package"
  }
}