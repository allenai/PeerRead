{
  "name" : "1510.00523.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Propositional satisfiability (SAT for short) is to decide if a Boolean formula is satisfiable. SAT is ubiquitous in computer science. Because of its significance, it has attracted the attention of many researchers from theory to practice. Many applications have motivated empirical studies, in particular the development of SAT solvers, softwares to solve satisfiability. A fundamental task of SAT solvers is to solve as many instances as possible in a realistic amount of time. To this end, various practical algorithms and elegant implementation techniques have been developed [56] [9] [40].\nThere are many variants of SAT. All solutions SAT (AllSAT for short) or model enumeration is studied in the paper. It is, given a CNF formula, to generate partial satisfying assignments such that they form a logically equivalent DNF formula. Compared to neighboring areas, AllSAT has been relatively unexplored. This is mentioned in the literature [29] and also supported by the fact that there are only a few recent papers, almost no software1 is publicly available, and it has not even been taken up in major handbooks related to satisfiability.\nA recent application of AllSAT is data mining. A fundamental task in data mining is to generate all interesting patterns from a given database [26]. Examples include frequent itemsets, maximal frequent itemsets, or closed itemsets in transaction databases. Although algorithms\n1A few exceptions are clasp [21], picosat [10], and relsat [6]. Although they support solution generation, they are positioned as an answer set solver, a single solution SAT solver, and a #SAT solver rather than AllSAT solvers, respectively.\n1\nar X\niv :1\n51 0.\n00 52\n3v 1\n[ cs\n.D S]\n2 O\nct 2\n01 5\nfor generating various patterns have been proposed, they are basically specialized for their target patterns. This means that different patterns require new algorithms. For this reason, a framework based on declarative paradigm has recently been proposed [24]. A basic flow is that constrains of patterns to be generated are formulated as logical formulae and solved with a generic solver. Hence, all that users do is simply to model their problems, not to design algorithms. Among much related work, an approach on which problems are encoded into CNF formulae and solved with AllSAT solvers has been studied [31]. An advantage of declarative paradigm is its ability to handle new patterns in a flexible manner. There is no need to see details of algorithms on which solvers are based, thereby it is opened to wider users. It is instead inferior in efficiency to problem-specific approaches. In practice it is necessary to balance between efficiency and flexibility. Therefore, improving solver’s performance is essential in the declarative framework.\nBesides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].\nConsidering the above, we find it important to clarify state-of-theart techniques of AllSAT solvers and to improve them on a firm basis. However, there are the following issues in the existing researches of ALLSAT.\n• Several methods are proposed but they are not globally compared. It is thus difficult to decide which method is effective for which kinds of ALLSAT instances. • Experiments are not carried out on comprehensive benchmarks. • There is few public ALLSAT solver, which makes it difficult to\ncompare existing techniques.\nWe thus would like to survey major techniques of AllSAT solvers and try to complement past references by gathering and organizing existing techniques. We further add some novel techniques. To evaluate solvers, we conduct experimental comparisons, including clasp, one of the few off-the-shelf softwares with solution generation support. Our implemented solvers are made publicly available with expectation that further improvement on solvers and their evaluation are easily done and the AllSAT research is stimulated.\nThe paper is organized as follows. Section 2 provides related work of AllSAT. Section 3 provides necessary notions, terminology, and results. Section 4 surveys major techniques of AllSAT solvers, where those including our original ideas are indicated by adding asterisks to their titles. Section 5 provides experimental results. Section 6 concludes the paper."
    }, {
      "heading" : "2. Related Work",
      "text" : "Another variant of SAT is the dualization of Boolean functions: given a DNF formula of a Boolean function f , it is to compute the complete DNF formula of the dual function fd. Since a CNF formula of fd can be easily obtained by interchanging logical disjunction with logical conjunction as well as the constants 0 with 1, a main part is to convert CNF to the complete DNF. Hence, an essential difference from AllSAT is that the resulting DNF formula must be complete. Dualization has been well-studied in terms of complexity [18] [15], while there seems no recent empirical study with a few exceptions [33] [11] [30] [54]. Practical algorithms for a restricted form of dualization have been presented [53] [46] and some implementations are available2, though they are not for arbitrary Boolean functions.\nAnother variant is the problem of counting the number of total satisfying assignments, called propositional model counting or #SAT. It has been well-studied because of good applications such as probabilistic inference problems and hard combinatorial problems, and some solvers are available [9]. Although #SAT is apparently similar to AllSAT, techniques such as connected components and component caching are inherent in counting, and they are not applicable to AllSAT as is [44]."
    }, {
      "heading" : "3. Preliminaries",
      "text" : "Necessary notions, terminology, and results concerning Boolean functions, satisfiability solvers, and binary decision diagrams are presented in this section.\n3.1. Boolean Basics. A literal is a Boolean variable or its negation. A clause is a finite disjunction of literals, and a term is a finite conjunction of literals. A propositional formula is in conjunctive normal form (CNF for short) if it is a finite conjunction of clauses and in a disjunction normal form (DNF for short) if it is a finite disjunction of terms. We identify clauses with sets of literals and CNF formulae with sets of clauses. The same applies to terms and DNFs. The dual of a Boolean function f is the function fd defined by fd(x1, . . . , xn) = ¬f(¬x1, . . . ,¬xn). An implicant of a Boolean function f is a term t with t ≤ f , where t is considered as a Boolean function and the order of Boolean functions is introduced as t ≤ f if t(v) ≤ f(v) for all v ∈ {0, 1}n. An implicant is prime if the removal of any literal results in a non-implicant. A DNF formula is complete if it consists of all prime implicants.\n2Hypergraph Dualization Repository, by Keisuke Murakami and Takeaki Uno, http://research.nii.ac.jp/~uno/dualization.html, accessed on 19th Jan., 2013. HTC-DD: Hypergraph Transversal Computation with Binary Decision Diagrams, by Takahisa Toda at ERATO MINATO Discrete Structure Manipulation System Project, Japan Science and Technology Agency, at Hokkaido University, http://www.sd.is.uec.ac.jp/toda/htcbdd.html, accessed on 10th Sept., 2015.\nAn assignment to a set V of Boolean variables is a partial function from V to {0, 1}. A satisfying assignment for a CNF formula is an assignment ν such that the CNF formula evaluates to 1. An assignment to V is total (or complete) if it is a total function, that is, all variables in V are assigned values. A Boolean formula is satisfiable if it has a satisfying assignment. For simplicity, we say that a literal is assigned a value v if the assignment to the underlying variable makes the literal evaluate to v. If there is no fear of confusion, we identify an assignment function ν over V with the set of the form {(x, v) ∈ V × {0, 1} | ν(x) = v}. We further identify the assignment x 7→ v with x if v = 1 and with ¬x if v = 0. In this way, assignments and literals are used interchangeably throughout the paper.\nExample 1. Consider the sequence of literals x1,¬x5, x3. This means that x1, x5, x3 are selected in this order and the values 1, 0, 1 are assigned to them, respectively.\n3.2. Satisfiability Solvers. Propositional satisfiability problem (SAT for short) is the problem of deciding if there exists a satisfying assignment for a CNF formula. Algorithm 1 shows a basic framework on which modern SAT solvers are based. For simplicity, other techniques such as lazy data structures, variable selection heuristics, restarting, deletion policy of learnt clauses are omitted. See for details [56] and [9].\nA basic behavior of Algorithm 1 is to search a satisfying assignment in such a way that a solver finds a candidate assignment by assigning values to variables and if the assignment turns out to be unsatisfying, the solver proceeds to the next candidate by backtracking. The extension of an assignment is triggered at the decide stage, where an unassigned variable x is selected and a value v ∈ {0, 1} is assigned to x, and it is then spread at the deduce stage, where assignments to other variables are deduced from the most recent decision (x, v).\nDecision assignments are those given at the decide stage and decision variables are those assigned values there. Consider a decision tree that branches at each decision assignment. A decision level is the depth of that decision tree, which is maintained by the variable dl in Algorithm 1. The decision level of a variable x, denoted by δ(x), is one at which x was assigned a value. For a literal l, the notation δ(l) is defined as that of the underlying variable, and l@d denotes that l, seen as an assignment, was given at level d, i.e. δ(l) = d.\nThe deduce stage is described below. A clause is unit if all but one of literals are assigned the value 0 and the remaining one is unassigned. The remaining literal is called a unit literal. Unit clauses are important in the deduce stage because assignments to the underlying variables of unit literals are necessarily determined so that unit literals evaluate to 1. After some assignments are determined by unit clauses, non-unit clauses may become unit. Hence, all implications are deduced until an\nALGORITHM 1: DPLL procedure with conflict driven clause learning,\nwhere δ(x) denotes the decision level of a variable x.\nInput: a CNF formula ψ, an empty assignment ν. Output: SAT if ψ is satisfied; UNSAT, otherwise.\n1 dl← 0; /* Decision level */ 2 while true do 3 ν ← propagate (ψ, ν); /* Deduce stage */ 4 if conflict happens then 5 if dl ≤ 0 then return UNSAT; 6 bl← analyze (ψ, ν); /* Diagnose stage */ 7 ν ← {(x, v) ∈ ν | δ(x) ≤ bl}; 8 dl← bl; 9 else\n10 if all variables are assigned values then 11 report ν;\n12 return SAT;\n13 else 14 dl← dl + 1; /* Decide stage */ 15 select an unassigned variable x and a value v; 16 ν ← ν ∪ {(x, v)}; 17 end\n18 end\n19 end\nunsatisfied clause exists or no unit clause exists. This process is called unit propagation. The function propagate performs unit propagation. Implied assignments are those given at this stage and implied variables are those assigned values there. The decision level of an implied variable x, the notations δ(x) and l@d, where l is a literal representing an implied assignment, are defined in the same way.\nExample 2. Consider the CNF formula ψ that consists of the following clauses.\nC1 = x1 ∨ ¬x3 C2 = x2 ∨ x3 ∨ x5 C3 = ¬x1 ∨ ¬x3 ∨ x4 C4 = x4 ∨ ¬x5 ∨ x6 C5 = x5 ∨ ¬x6\nAssume the decision assignment ¬x5@1. The implied assignment ¬x6@1 is obtained from C5. Assume the decision assignment x3@2. The implied assignments x1@2 and x4@2 are obtained from C1 and C3 in this\norder. Assume the decision assignment x2@3, and the CNF formula is satisfied.\nIt should be noted that in the middle of unit propagation, we may encounter with an unsatisfied clause. This case is called conflict. As soon as conflict happens, unit propagation halts, even though unit clauses still remain. In conflict case, if all assigned variables are those assigned prior to any decision (i.e. dl = 0), it means that there are no other assignments to be examined, thereby a CNF formula must be unsatisfiable. In that case, a solver halts, reporting UNSAT. If decision has been made at least once, we enter into the diagnose stage to resolve conflict.\nAt the diagnose stage, a ”cause” of the conflict we have just met is analyzed, a new clause is learnt as a result, and it is added to a CNF formula, by which a solver is guided not to fall into the conflict again (and other conflicts related to it). To do this efficiently, modern solvers maintain an implication graph during search, which represents an implication relation between assignments over unit propagation. Specifically, an implication graph is a directed acyclic graph G = (V,A) such that\n• vertices in V correspond to literals l representing assignments to their variables; • arcs in A correspond to implications so that if a unit clause C\nwith unit literal l yields in unit propagation, then arcs from all assignments to underlying variables in C \\ {l} to the implied assignment l are added; • if an unsatisfied clause exists, then arcs from all assignments to\nunderlying variables in that clause to the special vertex κ are added.\nAn implication graph might be implemented so that whenever a variable x is implied, it is associated with the clause that determined the assignment to x as a unit clause. This clause is called the antecedent of x.\nExample 3. Consider the CNF formula ψ given in Example 2. Assume in turn the decision assignments ¬x4@1, ¬x6@2, and ¬x2@3 in this order. The resulting implication graph is shown in Fig. 1. This case results in conflict because C1 becomes unsatisfied.\nA conflict graph is a subgraph H of an implication graph G obtained by restricting G so that all vertices have paths to κ. For a subset U of vertices in a conflict graph H = (V,A), the arc-cut (hereafter cut) corresponding to U is the set of arcs that connect vertices in U with those in V \\ U . Examples are illustrated by dotted curves in Fig. 1.\nWe are now ready to describe a clause learning scheme, which is performed by the function analyze. Consider cuts such that all decision assignments are on one side, called the reason side, and the special vertex κ is on the other side, called the conflict side. Take negation of literals on reason side that are incident to arcs in a cut, which form a conflict-driven clause (or conflict clause). This clause is considered as a ”cause” of conflict. Indeed,if variables are assigned values following literals on reason side that are incident to arcs in a cut, then the same implications on conflict side are derived and the same conflict must take place. Therefore, to avoid the conflict, it is necessary for variables to be assigned values so that at least one of those literals is negated. This condition is formulated as the conflict clause obtained above.\nAs illustrated in Fig. 1, there are many choices for cuts that induce conflict clauses. Among them, conflict clauses that contain exactly one literal from the current decision level are known to be effective. A unique implication point (UIP for short) is a vertex in a conflict graph such that every path from the decision at the current decision level to κ passes through it. Note that at least one UIP exists, because the decision at the current decision level is a UIP. The first UIP scheme is to find the UIP that is the closest to κ.\nExample 4. Consider the conflict graph given in Fig. 1. The middle curve gives the first UIP x3. Hence, a conflict clause is x4 ∨ ¬x3.\nThe first UIP scheme can be efficiently performed by traversing a conflict graph from κ in the reverse order of implications, based on the implementation of an implication graph stated above. During the traversal, it is easy to decide if the current literal is a UIP. Consider the cut that induces a UIP. For all literals on the reason side, their assignments are determined prior to those on the conflict side. Since the traversal is in the reverse order of implications, the UIP can then be located by keeping track of the number of unvisited vertices that are immediate neighbors of visited vertices.\nAll that remains is to decide a backtrack level bl, cancel all assignments above bl, and set bl to the current decision level. To decide a backtracking level, there are two choices. Suppose that the decision p at level i resulted in conflict and there is no solution that extends the\ncurrent assignment. Chronological backtracking cancels all assignments of level i including the decision p and attempts to find a solution by extending the assignment from level i − 1 with a conflict clause. In this way, chronological backtracking undoes assignments from a higher to a lower level. A drawback is that if there is no solution in higher levels, it is hard to get out of those levels. On the other hand, nonchronological backtracking jumps at once to a lower level j by canceling all assignments above j and attempts to find a solution upward by extending assignment from level j. The backtracking level j is commonly determined as the largest level of a variable in a conflict clause below the current level i. For each canceled assignment between the levels j and i, the possibility for becoming a solution is left in general, though this does not mean that a solver loses an opportunity to find solutions.\nExample 5. Consider the conflict graph given in Fig. 1. Since a conflict clause is x4∨¬x3, the non-chronological backtrack level is 1. Hence, the assignments ¬x6@2,¬x5@2 are canceled and search restarts from ¬x4@1, however a solution could be obtained by backtracking to the level 2.\nRemark 1. When a conflict clause is learnt, an assignment to its unit literal is implied. Hence, the function analyze adds the implied assignment to the current assignment function ν, by which its effect to other assignments is taken at a subsequent propagation.\n3.3. Binary Decision Diagrams. A binary decision diagram (BDD for short) is a graphical representation of Boolean functions in a compressed form [36] [1] [12]. We follow the notation and terminology in Knuth’s book [35].\nFigure 2 shows an example of a BDD. Exactly one node has indegree 0, which is called the root. Each branch node f has a label and two children. Node labels are taken from variable indices, and the children consists of the LO child and the HI child. The arc to a LO child is called LO arc, illustrated by a dotted arrow, and the LO arc of f means assigning the value 0 to the variable of f . Similarly, the arc to a HI child is called HI arc, illustrated by a solid arrow, and the HI arc of f in turn means assigning the value 1 to its variable. There are two sink nodes, denoted by > and ⊥. Paths from the root to > and ⊥ mean satisfying and unsatisfying assignments, respectively.\nBDDs are called ordered if for any node u with a branch node v as its child, the index of u is less than that of v. BDDs are called reduced if the following reduction operations can not be applied further.\n(1) If there is a branch node u whose arcs both point to v, then redirect all the incoming arcs of u to v, and then eliminate u (Fig. 3(a)). (2) If there are two branch nodes u and v such that the subgraphs rooted by them are equivalent, then merge them (Fig. 3(b)).\nIn this paper, ordered reduced BDDs are simply called BDDs. Ordered BDDs that need not be fully reduced are distinguished from ordinary BDDs by calling OBDDs. Note that each node in a BDD (or an OBDD) is conventionally identified with the subgraph rooted by it, which also forms BDD (or OBDD)."
    }, {
      "heading" : "4. Techniques of All Solutions SAT Solvers",
      "text" : "In order to implement an efficient AllSAT solver, we have to carefully determine an appropriate suite of techniques by considering various factors and their characteristics. Some details have been mentioned only partly and scattered in past references. We survey major existing techniques of AllSAT solvers and try to complement past references by gathering and organizing existing techniques. We further add some novel techniques.\nThis section is organized as follows. Three major types of solvers are presented in their own subsections. Each subsection starts with an overview, then provides specific techniques, and ends with the configuration of our implemented solvers. We added an asterisk to the title of each specific technique that contains our original ideas.\n4.1. Blocking Solvers.\n4.1.1. Overview. One of the easiest ways of implementing an AllSAT solver is to repeatedly run an ordinary SAT solver as a black box and find satisfying assignments one by one. A specific procedure is as follows.\n(1) Run a SAT solver with a CNF formula ψ. (2) If ψ is unsatisfiable, halt. (3) Report a found total satisfying assignment ν. (4) Compute the clause C of the form {x | ν(x) = 0}∪{¬x | ν(x) = 1}\nin a set notation. (5) Add C to ψ and go to Step 1.\nThe clause obtained at Step 4 is called a blocking clause [43]. Since the blocking clause C is the complement of the term corresponding to ν, the extended CNF formula ψ ∪ {C} is not satisfied by ν in a later search, thereby a new solution will be found in each repetition. Furthermore, since ν is total, no assignment other than ν is blocked.\nExample 6. Execute the procedure with the CNF formula:\nψ = (x1 ∨ ¬x2) ∧ (x2 ∨ ¬x3) ∧ (x3 ∨ ¬x1).\nSuppose a solver returns the satisfying assignment ¬x1,¬x2,¬x3. The blocking clause x1 ∨ x2 ∨ x3 is added to ψ:\nψ = (x1 ∨ ¬x2) ∧ (x2 ∨ ¬x3) ∧ (x3 ∨ ¬x1) ∧ (x1 ∨ x2 ∨ x3).\nThe solver then returns the satisfying assignment x1, x2, x3. The blocking clause ¬x1 ∨ ¬x2 ∨ ¬x3 is added to ψ:\nψ = (x1∨¬x2)∧(x2∨¬x3)∧(x3∨¬x1)∧(x1∨x2∨x3)∧(¬x1∨¬x2∨¬x3).\nThis time a solver returns UNSAT, which means all satisfying assignments are found.\nSince a blocking clause has size equal to the number of variables, unit propagation is likely to slow down. Hence, it is arguably better to consider blocking clauses that consist only of decisions, which we call a decision-based blocking clause for convenience. Since decisions determine the other assignments, decision-based blocking clauses have the same effect as those of all literals. However, to know which literals are decisions, we need to modify a solver code. Algorithm 2 is a pseudo code obtained by modifying Algorithm 1. For convenience, we simply call this blocking procedure to distinguish it from the other procedures presented later. Only lines 5,12-16 are changed. At line 5 and 12, a solver halts because dl ≤ 0 means that all variables are implied without any decision and all solutions are found. At line 15, all assignments except for those determined without any decision are canceled, and at line 16 a solver backtracks to the root level.\nA decision-based blocking clause only blocks a single assignment and there are as many number of blocking clauses as total satisfying assignments. Since they are stored, it is likely to result in space explosion and slow down of unit propagation. This is considered as a serious issue since unit propagation in modern SAT solvers occupies the majority of a whole processing time. Another disadvantage is that whenever a\nALGORITHM 2: Blocking procedure, where δ(x) denotes the decision\nlevel of x. Input: a CNF formula ψ, an empty assignment ν. Output: all satisfying assignments.\n1 dl← 0; /* Decision level */ 2 while true do 3 ν ← propagate (ψ, ν); /* Deduce stage */ 4 if conflict happens then 5 if dl ≤ 0 then halt; 6 bl← analyze (ψ, ν); /* Diagnose stage */ 7 ν ← {(x, v) ∈ ν | δ(x) ≤ bl}; 8 dl← bl; 9 else\n10 if all variables are assigned values then 11 report ν; 12 if dl ≤ 0 then halt; 13 compute a blocking clause C from ν; 14 ψ ← ψ ∪ {C}; 15 ν ← {(x, v) ∈ ν | δ(x) = 0}; 16 dl← 0; 17 else 18 dl← dl + 1; /* Decide stage */ 19 select an unassigned variable x and a value v; 20 ν ← ν ∪ {(x, v)}; 21 end\n22 end\n23 end\nsolution is found, a solver is enforced to restart from scrach with an extended CNF formula, not resuming search.\nOn the other hand, the blocking clause-based implementation might be considered as a good choice for such instances as even one solution is hard to find or for instances with a small number of solutions. It is easily implementable, because the blocking clause mechanism can be realized outside a solver or with a small modification on a solver code as demonstrated in Algorithm 2. We can benefit from powerful techniques of modern SAT solvers such as conflict-driven clause learning, nonchronological backtracking, and so on.\nRemark 2. Once blocking clauses are added to a CNF formula, they are not deleted afterward and must not be treated in the same way as conflict clauses. Otherwise, solutions would be rediscovered many times, which is not allowed in the paper.\n4.1.2. Simplifying Satisfying Assignments. Simplification of satisfying assignments is to obtain from a satisfying assignment ν to a CNF formula ψ a smaller assignment3 ν ′ that still makes ψ evaluate to 1. This is done by canceling assignments to redundant variables in ν, where redundant means either value is assigned without effect on the value of ψ. A simplified assignment is partial in general and it represents a set of total assignments, including the original assignment and possibly other satisfying assignments. Variable lifting refers to a number of such simplification techniques [50]. Since this topic is well-summarized in the literature [44], we do not go into details. The interested readers are referred to it, as well as the references therein. For recent results, see also the literature [57].\nSimplification allows us to obtain from a single solution possibly exponentially many solutions in a compact form, i.e., as a partial assignment. It is desirable if we can obtain a partial assignment of minimum size, however minimization is known to be computationally hard, and in practice we have to compromise with near-minimum assignment by means of approximation4. To combine simplification with the blocking mechanism of Algorithm 2, it suffices to perform simplification just before line 13 and then to take complement of decisions in a simplified assignment. It should be noted that if a simplified blocking clause is empty, that is, all variables except for implied ones turn out to be redundant, then it means that all remaining solutions are covered. Thus, in that case, a solver must be halted. Thanks to simplification, the number of blocking clauses may be largely reduced, which leads to a good effect on unit propagation at the cost of performing simplification.\nExample 7. Consider the CNF formula ψ given in Example 2. The assignments ¬x5@1,¬x6@1, x3@2, x1@2, x4@2, x2@3 were given in this order. The last decision is redundant. By removing it, we obtain the partial assignment ¬x5@1,¬x6@1, x3@2, x1@2, x4@2. Consider the decision assignments ¬x5@1 and x3@2, by which the other variables are implied or can be assigned either value. By flipping those assignments, we obtain the simplified blocking clause C6 = x5 ∨ ¬x3. 4.1.3. Continuing Search. In Algorithm 2, whenever a solution is found, a solver is enforced to backtrack to the root level. After that, due to a variable selection heuristic, a different assignment will be examined and a region of the search space in which a solution was just found remains incomplete, which may give rise to unnecessary propagations and conflicts in a later search for that region. Restart is, however, essential in AllSAT solving in particular when simplification is used. Indeed after simplification is performed and a new clause is added, the\n3We say that an assignment ν′ is smaller than ν if all variables x assigned values in ν′ are also assigned values in ν and their values coincide, i.e., ν(x) = ν′(x).\n4Even computing a minimal satisfying assignment requires quadratic time, which is still expensive.\nstate of implications such as which literals are decisions becomes inconsistent, and it is necessary to deduce implications again. It is not straightforward to answer how to continue search [32].\nThe problem of over-canceling due to backtracking was addressed [47], and a simple technique, called progress saving, that stores recent canceled decisions in an array and simulates them after backtracking was proposed. Specifically, any time a solver enters into the decide stage, it checks if an assignment to a selected variable is stored, and it simulates the previous decision if exists; otherwise, it follows a default heuristic. Although this technique was proposed in the context of SAT, it is also applicable to AllSAT.\nExample 8. Continuing Example 7, suppose that we added the blocking clause C6 to ψ and backtracked to the root level with progress saving enabled. At this point, all assignments above the root level are canceled, yet the previous decisions (x5, 0), (x3, 1) are stored in an array. If x5 or x3 is selected, the previous decision is made again. 4.1.4. Implementation. We implemented 4 programs based on blocking procedure according to whether simplification and continuation techniques are selected or not.\nFor a simplification technique, we used a method related to set covering model [44] and decision-based minimal satisfying cube [57]. For the sake of efficiency, near-minimal satisfying assignments are computed. A basic idea is that given a total assignment, we select as a small number of decision variables as make a CNF formula evaluate to 1. This is done in the following way:\n(1) select all decision variables that related to implications of at least one variable; (2) for each clause that is not satisfied by selected variables, select arbitrary decision variable that makes the current clause satisfied.\nA simplified satisfying assignment then consists of assignments to the selected decision variables and all implied variables. By flipping the assignments to the selected decisions, we obtain a blocking clause, which blocks all total assignments represented by the simplified assignment.\nWe implemented a continuation technique so that before backtracking at line 15, all decisions are stored in an array and after backtracking, we simulate these decisions whenever possible in the order of their decision levels. Clearly, not all decisions are assumed due to blocking clause, and conflict or contradiction to the previous decision will happen. It is this point where a solver continues search, and we will then enter into the conflict resolution or the decide stage. 4.2. Non-blocking Solvers. 4.2.1. Overview. We give a basic idea for an AllSAT procedure without the aid of blocking clauses. Like blocking procedure, we modify\nAlgorithm 1. A main feature is to employ chronological backtracking instead of non-chronological backtracking. The chronological backtracking used here is a bit different from the ordinary one described in Section 3.2. As shown in Fig. 3, only differences are to insert the flipped decision (x, v̄) in ν and register it to an implication graph so that it has no incomming arc. This is because there is no reason that implied flipped decisions because of the absence of blocking clauses.\nWe say that a literal, seen as an assignment, has NULL antecedent if it has no reason that implied it and there is no incomming arc in an implication graph. The chronological backtracking given above is hereafter abbreviated as BT for convenience, and it is performed by the function backtrack. We collectively call a number of procedures for AllSAT solving based on BT non-blocking procedure in contrast to blocking procedure presented in Section 4.1. If there is no fear of confusion, chronological backtracking always means BT.\nAn important point in this approach is how we make BT compatible with conflict-driven clause learning. Consider a conflict graph in clause\nlearning phase. Due to BT, a conflict graph may contain several roots, i.e. assignments with NULL antecedent, in the same decision level. See for example the literals ¬x20 and x18 in Fig. 5. Since an ordinary first UIP scheme commonly assumes a unique root in the same decision level, implementations based on that assumption get stuck in non-decision literals with NULL antecedent. To resolve this problem, two techniques are presented later.\nExample 9. Look at Fig. 4. (a) All variables are assigned values without conflict, which means a solution is found. (b) Following BT, all assignments of level 3 are canceled and the flipped decision x18 is inserted as a non-decision assignment at level 2. Since no propagation takes place, a new decision ¬x16 is made and a subsequent propagation results in conflict. The decision is the only one that has NULL antecedent in the current decision level, and ordinary first UIP scheme suffices in this case. (c) From the conflict we have just met, the conflict clause x6 ∨ x1 ∨ ¬x18 ∨ ¬x12 is learnt, and a solver backtracks to level 2. 5 The assignment x6 is implied by the conflict clause. A subsequent propagation results in conflict again. This time, there is a non-decision assignment with NULL antecedent in the same decision level.\nA major advantage of non-blocking approach is that no matter how many solutions exist, a performance of unit propagation does not deteriorate thanks to the absence of blocking clauses. Instead, it has to find total satisfying assignments one by one. Hence, there is a limit in the number of solutions to be generated in a realistic mount of time. 4.2.2. Sublevel-based First UIP Scheme. Grumberg et al. introduced the notion of sublevels and presented a sublevel-based first UIP scheme that is compatible with non-blocking approach [23]. A basic idea is to divide a single decision level into sublevels. Specifically, a new sublevel is defined whenever BT is performed, and sublevels are undefined as their decision levels are undefined. An ordinary first UIP scheme can then be applied in the current sublevel.\nA conflict clause obtained by this approach may contain many literals that are below the current sublevel yet in the same decision level. Among literals in that conflict clause, those with NULL antecedent are necessary for avoiding rediscovery of solutions and can not be removed if exist, however it is expected that other literals are reduced further. 4.2.3. Decision Level-based First UIP Scheme*. We present an alternative first UIP scheme that need not require sublevels. Our scheme can be realized with a small modification: it is simply not to stop at literals with NULL antecedent and attempt to find the first UIP in\n5In this case, there is no oppotunity to rediscover solutions by ordinary chronological backtracking, and hence the flipped decision x16 is not inserted. This technique is explained in more detail when non-chronological backtracking with level limit is introduced.\nALGORITHM 4: Non-blocking procedure with decision level-based first\nUIP scheme. Input: a CNF formula ψ, an empty variable assignment ν. Output: all satisfying assignments.\n1 dl← 0; /* Decision level */ 2 lim← 0; /* Limit level */ 3 while true do 4 ν ← propagate (ψ, ν); /* Deduce stage */ 5 if conflict happens then 6 if dl ≤ 0 then halt; 7 (ν, dl, lim)← resolve (ψ, ν, dl, lim); /* Resolve stage */ 8 else 9 if all variables are assigned values then\n10 report ν; 11 if dl ≤ 0 then halt; 12 (ν, dl)← backtrack (ν, dl); 13 lim← dl; 14 else 15 dl← dl + 1; /* Decide stage */ 16 select an unassigned variable x and a value v; 17 ν ← ν ∪ {(x, v)}; 18 end\n19 end\n20 end\nthe current decision level. A specific procedure is to traverse a conflict graph from κ in the reverse order of implications and construct a conflict clause C, repeating the following procedure until the first UIP appears:\n(1) if the current literal is below the current decision level, add the negated literal to C and do not go up through the incomming arcs of the current literal; (2) if the current literal has NULL antecedent, add the negated literal to C; (3) for the other case, go up through the incoming arcs of the current literal if their source vertices have not yet been visited.\nAfter the first UIP is found, add the negated literal to C. Compared to the sublevel-based first UIP scheme, the decision levelbased scheme might be considered better. First of all, it is simple. Secondly, a conflict clause contains unique literal from the current decision level except for those with NULL antecedent. However, it should be noted that conflict clauses obtained by the decision level-based scheme are not necessarily smaller, because the unique implication point is further from κ and thus a conflict clause may contain more literals below\nthe current decision level. A pseudo code for the modified scheme is omitted, because modification would be straightforward.\nExample 10. Continuing Example 9, consider the conflict case (c) in Fig. 4. Figure 5 illustrates the difference of the two schemes: the sublevel-based scheme finds x6 as a first UIP and learns ¬x6 ∨ ¬x9 as a conflict clause, while the decision level-based scheme finds ¬x20 as a first UIP and learns x20 ∨ x1 ∨¬x18 as a conflict clause. Note that the conflict clause in either case does not become unit after backtracking, though it does not menace algorithmic correctness because of the flipped decision x20.\nRemark 3. Recall that when the function analyze is performed, an assignment to its unit literal is set to the current assignment function ν. In non-blocking procedure, a conflict clause is not necessarily unit as seen in Example 10. Hence, the function analyze in non-blocking procedure only adds a conflict clause, and it does not consider an induced assignment.\nAlgorithm 4 is a pseudo code for the non-blocking approach using clause learning with the decision level-based first UIP scheme. Recall that the function backtrack is to backtrack chronologically, following Algorithm 3. There are some choices for it, where a generic function, named resolve, is called. A simple way of realizing the resolve stage is to perform clause learning, based on either first UIP scheme and then perform BT. More elaborate methods are introduced later, with which resolve can also be replaced. Since the variable lim is used in one of those methods, it is introduced when needed. 4.2.4. Conflict Directed Backjumping. Grumberg et al. augmented non-blocking approach with conflict resolution by means of a restricted non-chronological backtracking [23]. Their backtracking method can be considered as a form of conflict directed backjumping (CBJ for short).\nCBJ has been studied as one of tree search algorithms for constraint satisfaction problem [48] [13] [17].\nA basic idea is described below. Consider the scenario where conflict happens at decision level i+1, and after backtracking to level i, conflict happens again. In this case, obtain a conflict clause cl1 from the former conflict, while from the latter conflict, obtain a conflict clause cl2 so that its UIP is ¬p, where p is the first UIP in the former analysis. Perform resolution of cl1 and cl2 and obtain a resulting clause cl3. After that, backtrack to the level preceding the highest level in cl3.\nA pseudo code is given in Algorithm 5, which is almost faithfully rephrased in our setting from the code given in the literature [23]. The call of propagate at the end of the while loop was not explicitly written in the original code, which we consider necessary. At this call, unit propagation considers the effect of the recent flipped decision inserted as a result of backtrack. Note that the effect of an assignment implied by the recent conflict clause is not considered here, because our nonblocking procedure assumes that the function analysis simply records a conflict clause and does not insert an implied assignment, which is separately inserted at line 12. The halt means that non-blocking procedure is halted too.\n4.2.5. Non-chronological backtracking with Level Limit And Its Combination with CBJ*. We present an alternative conflict resolution by means of non-chronological backtracking with backtrack level limit. To our knowledge, this method was first presented by [22], though it was in the context of answer set programming. We thus would like to import their idea to our non-blocking procedure.\nSince non-blocking procedure does not record blocking clauses, it must not backtrack to arbitrary level, even though a backtracking level is one that is legitimately derived from a conflict clause. However, we can do this if there is no opportunity of rediscovering found solutions from the derived level. We use the variable lim that holds a ”safe” level to be backtracked, that is, the first level at which the current assignment and the previous satisfying assignment differ.\nA pseudo code is given in Algorithm 6. We call this approach nonchronological backtracking with level limit, denoted by BJ, where the underline means a backtrack level is limited. Since lim is always less than or equal to dl, BT is performed if and only if lim = dl. If lim < dl, backtracking does not entail inserting a flipped decision (see Example 9). This is because lim < dl implies no solution yet found, and hence no opportunity to rediscover solutions by backtracking.\nALGORITHM 5: Conflict resolution based on conflict-directed backjump-\ning\nInput: a CNF formula ψ, an assignment ν, the current decision level dl. Output: updated objects ν, dl.\n1 stack ← an empty stack; 2 while true do 3 if conflict happens then 4 if dl ≤ 0 then halt; 5 analyze (ψ, ν);\n6 push the learnt conflict clause into stack; 7 (ν, dl)← backtrack (ν, dl); 8 else if stack is not empty then 9 cl1 ← the clause popped from stack;\n10 if cl1 is a unit clause then 11 unit← the unit literal in cl1; 12 add unit, seen as an assignment, to ν so that it has antecedent\ncl1;\n13 ν ← propagate (ψ, ν); 14 if conflict happens then 15 if dl ≤ 0 then halt; 16 cl2 ← the conflict clause from the recent conflict with unit\nas UIP;\n17 cl3 ← the resolution of cl1 and cl2; 18 push cl3 into stack; 19 bl← the highest level in cl3; 20 (ν, dl)← backtrack (ν, bl); 21 end\n22 end\n23 else 24 break;\n25 end 26 ν ← propagate (ψ, ν); 27 end\n28 return ν, dl;\nWe furthermore present a combination6 of BJ and CBJ. This is obtained by replacing the else part in BJ, in which BT is performed, with CBJ: that is,\n(1) if lim is less than the current decision level, then perform BJ; (2) otherwise, perform CBJ.\n6It is mentioned [22] that a combination of conflict-directed backjumping and non-chronological backtracking is proposed. However, their pseudo code almost corresponds to Algorithm 6 and it is different from that stated in this paper.\nALGORITHM 6: Conflict resolution based on non-chronological back-\ntracking with level limit\nInput: a CNF formula ψ, an assignment ν, the current decision level dl, a level limit lim.\nOutput: updated objects ν, dl, lim. 1 bl← analyze (ψ, ν); /* Diagnose stage */ 2 if lim < dl then 3 if bl < lim then bl = lim; 4 ν ← {(x, v) ∈ ν | δ(x) ≤ bl}; 5 dl← bl; 6 else 7 (ν, dl)← backtrack (ν, dl); 8 lim← dl; 9 end\n10 return ν, dl, lim;\nStep 2 is selected only when lim equals the current decision level: in other words, when conflict happens just after the current assignment diverged from the previous satisfying assignment. Hence, BJ is preferentially applied when one or more decisions from the diverging point are made. This is designed with expectation that more decisions are made from the diverging point, more effectively BJ prunes search space. Since BJ is likely to be more frequently applied, this approach is denoted by BJ+CBJ. 4.2.6. Implementation. We implemented 8 programs based on nonblocking procedure according to which of the two first UIP schemes is selected and which of the conflict resolution methods, i.e. BT, BJ, CBJ, or BJ+CBJ, is selected, where BT means performing BT after clause learning. 4.3. Formula-BDD Caching Solvers. 4.3.1. Overview. Formula caching refers to a number of techniques to memorize formulae to avoid recomputation of subproblems [7]. Examples include a caching technique in probabilistic planning [39], conflict clauses in SAT [6] [42], component caching and other cachings in #SAT [5] [4], and blocking clauses in AllSAT [43].\nAnother type of formula caching in which formulae are associated with propositional languages such as FBDD, OBDD, and a subset of d-DNNF has been studied in the context of knowledge compilation [28]. Their work revealed a correspondence between exhaustive DPLL search and propositional languages. They also proposed speeding up compilation by exploiting techniques of modern SAT solvers through the correspondence. Although exhaustive DPLL search is simply used for efficiency in their compilation approach, compilation in turn can contribute to speeding up exhaustive DPLL search. Actually, if a CNF\nformula is compiled into a BDD, all satisfying assignments can be generated simply by traversing all possible paths from the root to the sink node >. This seems like taking a long way around to AllSAT solving, however thanks to the caching mechanism, recomputation of many subproblems can be saved. A connection to AllSAT was mentioned, however their primary concern is on the compilation to suitable languages for required queries, not restricted to AllSAT. To our knowledge, comparisons have been conducted only between various compilers. An application to an AllSAT solver itself was more explicitly mentioned in the literature [55] and a compiler-based AllSAT solver is released. However, comparisons with other AllSAT solvers have not been conducted yet and its power remains unknown. Similar caching techniques appear in other areas such as preimage computation in unbounded model checking [51] [37] [34], satisfiability [45], and discrete optimization [3] [8].\nThe paper only deals with the caching method that records pairs of formulae and OBDDs, which we call formula-BDD caching. A formulaBDD caching can be embedded in either blocking procedure or nonblocking procedure7. This is done without almost any loss of optimizations employed in an underlying procedure. An exception is that variables must be selected in a fixed order at the decide stage. This effect is far from negligible in terms of efficiency, as is well-recognized in a single solution SAT. It is, however, confirmed in experiments that formula-BDD caching solvers exhibit a quite good performance on the whole, and it provides an efficient solution method for instances that have a huge number of solutions and can not possibly be solved by other means.\n4.3.2. Caching Mechanism. We give a basic idea of formula-BDD caching, using a simple BDD construction method with formula-BDD caching. This method is elaborated later by implementing on top of a SAT solver. We first introduce terminology. A subinstance of ψ in an assignment ν is the CNF formula derived from ψ by applying all assignments defined in ν to ψ. The current subinstance refers to the subinstance induced by the current assignment.\nConsider the following procedure with a CNF formula ψ and an empty variable assignment ν as initial arguments:\n(1) if an unsatisfied clause exists in the current subinstance, then return ⊥; (2) if all variables are assigned values, then return >; (3) i← the smallest index of an unassigned variable; (4) f0 ← the result obtained by a recursive call with ψ and ν ∪ {(xi, 0)};\n7Only the combination with blocking procedure has been presented in the past work [27] [55].\n(5) f1 ← the result obtained by a recursive call with ψ and ν ∪ {(xi, 1)}; (6) return a node with the label i, the references to LO child f0 and to HI child f1;\nSince different assignments can yield subinstances that are logically equivalent, we want to speed up the procedure by applying dynamic programming. To do this, we need to quickly decide if the current subinstance is solved. If it is unsolved, we compute a BDD for all solutions of the instance and memorize it, associating with the instance. Otherwise, the result is obtained in a form of BDD and recomputation is avoided.\nHowever, this approach involves the equivalence test of CNF formulae, which is computationally intractable, as it includes satisfiability testing. Hence, we consider a weaker equivalence test. That is, we encode subinstances into formulae so that if two subinstances are not logically equivalent, then the encoded formulae are not identical. To decide if the current subinstance is solved, it suffices to search the encoded formula in the set of registered formula-BDD pairs. All requirements for formula-BDD caching to work is simply the sentence in italic above, and any encoding that meets it will do. It should be noted that our test is sound in that acceptance always is a correct decision, however if we prioritize efficiency of encoding excessively, logically equivalent subinstances are very likely to result in non-identical formulae, i.e., a wrong decision.\nExamples of formula-BDD cachings include those induced by cutsets and separators [27], defined below, and a variant of cutsets [55].\nDefinition 1. The i-th cutset of a CNF formula ψ is the set of clauses C in ψ such that C has literals with their underlying variables xj and xk satisfying j ≤ i < k. The cutwidth of ψ is the maximum size of a cutset of ψ.\nDefinition 2. The i-th separator of a CNF formula ψ is the set of variables xj such that some clause in the i-th cutset has a literal with its underlying variable xj satisfying j ≤ i. The pathwidth of ψ is the maximum size of a separtor of ψ.\nExample 11. Look at the CNF formula ψ illustrated in Fig. 6. The 3-rd cutset of ψ consists of C2 and C3, while the 3-rd separator of ψ consists of x1, x2, and x3. The cutwidth and the pathwidth of ψ are both 3.\nThe following proposition states that clauses (and variables) in cutsets (and separators) meet the requirement of formula-BDD caching, respectively. Proof is omitted. See [27].\nProposition 1. Let ψ be a CNF formula, where variables are ordered according to their indices. Let ν and µ be assignments with the i-th or less variables assigned values and other variables unassigned.\n(1) If satisfied clauses in the i-th cutset of ψ in ν coincide with those in µ, then the subinstance in ν is logically equivalent to that in µ. (2) If variables assigned the value 1 in the i-th separator of ψ in ν coincide with those in µ, then the subinstance in ν is logically equivalent to that in µ.\nExample 12. Figure 6 illustrates an OBDD constructed using cutsets as formula-BDD caching. Cutsets are associated with arcs, and satisfied clauses in them are underlined. If two arcs have the same set of satisfied clauses, Proposition 1 implies that their target vertices can be merged safely.\nIt should be noted that our weaker equivalence test may reject logically equivalent subintances; the subgraphs in a constructed BDD that correspond to those subinstances are not merged. This means that a constructed BDD is not fully reduced, i.e., an OBDD, though the OBDD give in Fig. 6 happens to be fully reduced.\nAn important point of the formula-BDD caching approach is how to balance quality with efficiency in our weaker equivalence test. The quality here refers to how many correct decisions are made. Theoretically, it holds that a correct decision of the separator approach always implies a correct decision of the cutset approach. On the other hand, the efficiency refers to how much time is taken to create formulae from\nsubinstances, which substantially amounts to evaluating clauses and variables in cutsets and separators, respectively. In terms of efficiency, evaluating clauses in a cutset would require time linear to the total size of clauses due to lazy evaluation mechanism if it is implemented on top of modern SAT solvers. On the other hand, evaluating variables in a separator requires time linear to the number of variables.\nFrom the argument above, we can say that for instances with small cutwidth, evaluation cost of cutset is negligible compared to separator and hence cutset is a better choice, and for instances with many clauses, separator should be used instead.\n4.3.3. Embedding Formula-BDD Caching in AllSAT Procedure*. We demonstrate how to embed formula-BDD caching in a concrete AllSAT procedure. We take non-blocking procedure as an example. To our knowledge, this is the first time that the combination is presented. The other combination, i.e. blocking procedure with formula-BDD caching, is omitted.\nWe have assumed so far that conflict clauses (and blocking clauses in blocking procedure) are added to a CNF ψ, but from now on we will assume that they are separately maintained from ψ. This makes ψ unchanged throughout the execution of our AllSAT procedure. Accordingly, the cutset and the separator in each level are unchanged too.\nAlgorithm 7 is a pseudo code of non-blocking procedure with formulaBDD caching embedded. Formula-BDD caching mechanism consists of the encode stage, the extend stage, and the enroll stage.\nAt the encode stage, the function makeformula receives a CNF ψ, the current assignment ν, and the index i − 1 of the largest assigned variable. It computes a formula for the current subinstance. No specific encoding is presented here. See Section 4.3.2 for examples of encoding. Note that if all variables are assigned values, then i must be ∞, and hence we have i− 1 =∞. In this case, let the function makeformula return 1, which is the special formula representing true.\nAt line 15, we search an entry with the key (i − 1, φ) in S, where S holds registered formula-BDD pairs. If it exists, the current subinstance is already solved, and the result is the OBDD g associated with the key, which appears as a subgraph of f . Hence, at the extend stage, the function extendobdd augments an OBDD f by adding a path from the root of f to the root of g, following the current assignment ν. It returns the pair of the extended OBDD and the added path. Since this stage is straightforward, we omit a pseudo code of it.\nAt the enroll stage, we associate formulae for solved subinstances with the corresponding OBDDs and insert these formula-BDD pairs to S. To do this, important points are how to identify when subinstances are solved and how to find their OBDDs. Let I be a subinstance\nwith the smallest unassigned variable xi. Since unit propagation is performed at the beginning of each repetition, without loss of generality we assume that xi is a decision variable. This means that a formula ζ has been made from I, thereby (i − 1, ζ) is in T . Let νI and dlI be the assignment and the decision level at this point. Without loss of generality we assume that there exist one or more solutions extending νI , because otherwise, the OBDD for I is not created. After adding at least one path to f , we have the node that corresponds to the decision at variable xi. Clearly, this node is reachable from the root of f through the path following νI , and it is the root of the OBDD for I. When all solutions for I are found, to go out of the exhausted search space, backtracking to a lower level than dlI is performed, which is directly triggered by an occurrence of conflict implying no solution left or by the discovery of the last solution. Backtracking to a lower level can also be performed without exhausting all solutions, however this case only happens when no solution of I is yet found. Hence, we can distinguish them. Summarizing the above, if a backtracking level is less than dlI and at least one solution for I is found, then I is solved, and the root of the OBDD for I is located at the end of the path following νI , which is a part of the assignment just before backtracking.\nThe function associate is in charge of the enroll stage. With the observation above, it is called whenever backtracking is performed. A procedure for it is given as follows. We scan all nodes h in the most recently added path π until the assignment at h taken in π contradicts to the current assignment. Note that scanned nodes h correspond to subinstances Ih such that Ih turns out to be satisfiable and the assignment that induced Ih is a part of the current assignment. For each scanned node h, we test if a backtracking level is less than the decision level of h and a formula ζ was made8 from Ih. If the test is passed, the pair of (j − 1, ζ) and h is inserted into S, where j is the label of h.\nThe function resolveplus behaves in the same way as reslove except that S and T are updated each time backtracking is performed, as in lines 19-20.\nExample 13. Figure 7 illustrates how Algorithm 7 constructs an OBDD for the CNF formula ψ given in Fig. 6.\n4.3.4. Refreshing OBDDs*. A constructed OBDD may become too large to be stored on memory, though it would be in practice much better in size than the list representation of all solutions and in the worst case equal to it except for constant factor. We present a simple technique to resolve this problem. Let n be the number of variables. We introduce a threshold θ of an OBDD size, where θ > n. Insert the following procedure after an BDD is extended and backtracking is\n8 This is equivalent to finding an entry (j − 1, ζ) in T , where j is the label of h.\nperformed. If the size of an OBDD is larger than or equal to θ − n, then the current OBDD f is dumped to a file in a secondary storage, and all objects f , S, T , and π of formula-BDD caching mechanism are refreshed with initial states. Since formula-BDD caching is almost independent of the underlying non-blocking procedure, after refreshing, the procedure simply attempts to examine unprocessed assignments with formula-BDD caching empty. 4.3.5. Implementation. We implemented 2 programs on each nonblocking procedure and 2 programs on each blocking procedure according to which formula-BDD caching is selected, cutset or separator."
    }, {
      "heading" : "5. Experiments",
      "text" : "5.1. Implementation And Environment. All solvers are implemented in C on top of MiniSat-C v1.14.1 [19]. Clasp 3.1.2 was taken from Potassco project9. As far as we are aware, clasp [21], picosat [10], and relsat [6] are only SAT solvers which support the enumeration of all solutions. Among them, we used clasp for the comparison, because it achieved better performance than picosat, and relsat does not support quiet mode in solution generation and generated solutions may be too large to be stored.\nAll experiments were performed on 2.13GHz Xeon R©E7- 2830 with 512GB RAM, running Red Hat Enterprise Linux 6.3 with gcc compiler version 4.4.7. In the execution of each AllSAT solver, time limit and memory limit were set to 600 seconds and 50GB, respectively. If either limit is exceeded, the solver is enforced to halt. All solvers simply touch found solutions and never output them.\n9Potassco, the Potsdam Answer Set Solving Collection, bundles tools for Answer Set Programming developed at the University of Potsdam,http://potassco. sourceforge.net/, accessed on 13rd Sept., 2015.\nALGORITHM 7: Non-blocking procedure with formula-BDD caching,\nwhere δ(x) denotes the decision level of a variable x.\nInput: a CNF formula ψ, an empty variable assignment ν. Output: an OBDD f for all satisfying assignments.\n1 dl← 0; /* Decision level */ 2 lim← 0; /* Limit level */ 3 f ← ⊥; /* OBDD */ 4 S ← {((∞, 1),>)}; /* Set of formula-BDD pairs */ 5 T ← ∅; /* Set of formulae with indices */ 6 π ← ; /* Sequence of BDD nodes */ 7 while true do 8 ν ← propagate (ψ, ν); /* Deduce stage */ 9 if conflict happens then 10 if dl ≤ 0 then return f ; 11 (ν, dl, lim, S, T )← resolveplus (ψ, ν, dl, lim, S, T ); /* Resolve and\nenroll stage */\n12 else 13 i← min {j | xj is not assigned value}; 14 φ← makeformula (ψ, ν, i− 1); /* Encode stage */ 15 if an entry with key (i− 1, φ) exists in S then 16 g ← the OBDD node associated with (i− 1, φ) in S; 17 (f, π)← extendobdd (f, g, ν); /* Extend stage */ 18 if dl ≤ 0 then return f ; 19 S ← associate (π, ν, S, T, dl − 1); /* Enroll stage */ 20 T ← {(j − 1, ζ) ∈ T | δ(xj) ≤ dl − 1}; 21 (ν, dl)← backtrack (ν, dl); 22 lim← dl; 23 else 24 T ← T ∪ {(i− 1, φ)}; 25 dl← dl + 1; /* Decide stage */ 26 select a value v; 27 ν ← ν ∪ {(xi, v)}; 28 end\n29 end\n30 end\nThe types of compared solvers are a blocking solver, a non-blocking solver, a formula-BDD caching solver, and clasp. The first three types have some variations according to which techniques are used (see the end of each subsection in Section 4). Among solvers of the same type, we selected a solver with the most solved instances. The selected solvers, called representative solvers, are as follows.\n• Blocking NoSimple Cont: the blocking solver with simplification unselected and continuation selected.\n• NonBlocking DLevel BJ: the non-blocking solver with decision level first UIP scheme and non-chronological backtracking with level limit both selected. • BDD Cut NonBlocking DLevel BJ: the formula-BDD caching\nsolver with cutset caching selected and it is implemented on top of NonBlocking DLevel BJ.\nThroughout the section, if there is no fear of confusion, they are abbreviated as Blocking, NonBLocking, and BDD. Notation for solvers with other configurations is introduced in the same way.\nIt is known that variable orderings significantly affect the performance of BDD compilation. Hence, we used the software MINCE version 1.0 [2] to decide a static variable order before the execution of formula-BDD caching solvers. The execution of MINCE failed for some instances, and for that case, we used the original order. The time required for deciding a variable order is included. Although for some instances time limit exceeded in preprocessing, it was negligible for many instances.\n5.2. Problem Instances. We used total 2867 CNF instances (all satisfiable), which are classified as follows.\n• satlib: SATLIB benchmark problems (2707 instances), taken from SATLIB website10. • sc14: SAT Competition 2014 benchmarks, application track\n(56 instances) and crafted track (65 instances), taken from SAT Competition 2014 website11. • iscas: ISCAS85 and 89 circuit benchmarks in DIMACS CNF\nformat (39 instances), taken from TG-Pro website12.\nAmong instances released in each repository, we selected all instances such that satisfiability could be decided in 600 seconds by either one of the SAT solvers clasp 3.1.2, glucose4, minisat 2.2, and minisat 1.3, and its result was satisfiable. For satlib and sc14, random instances are excluded.\n5.3. Comparison of Running Time. Figure 8 shows a cactus plot of representative solvers. Solved instances are ranked with respect to the times required to solve them. Each point represents a solved instance with its rank (the horizontal coordinate) and the required time (the vertical coordinate). Since one wants to solve as many instances as\n10SATLIB - The Satisfiability Library, by Holger H Hoos and Thomas Stützle at Darmstadt University of Technology, http://www.cs.ubc.ca/~hoos/SATLIB/ benchm.html, accessed on 16th May, 2014.\n11SAT Competition 2014, http://www.satcompetition.org/2014/ description.shtml, accessed on 8th Sept., 2015.\n12TG-Pro - A SAT-based ATPG System, by Huan Chen and Joao MarquesSilva, http://logos.ucd.ie/web/lib/exe/fetch.php?media=benchmarks: circuit-cnf-tgpro-20110317.tgz, accessed on 16th May, 2014\npossible in a given amount of time, it is thought that gentler the slope of plotted points is, more efficient a solver is. The formula-BDD caching solver clearly outperforms the other solvers. It is then followed by the non-blocking solver, clasp, and the blocking solver in this order.\nFigures 9, 10, and 11 depict differences between solvers of the same types. From Figure 9, we can observe that continuation of search is effective yet simplification degrades performance. For some instances, simplification enables a solver to find a large number of solutions, however such instances are limited and the current implementation is not powerful enough to make it possible to solve instances that can not be handled without simplification. Figure 10 has a narrower horizontal range than the other figures. This is because non-blocking solvers exhibit quite similar performance and they can not be distinguished otherwise. It is surprising that BT is almost as efficient as the other elaborated backtracking methods. Decision level-based scheme is equal to or more efficient than sublevel-based scheme. Figure 11 shows that nonblocking procedure is clearly better as an underlying solver in which caching mechanism is embedded, while there is almost no difference between caching methods.\n5.4. Comparison of Maximum Memory Usage. Figure 12 shows a cactus plot of the maximum memory usage. Solved instances are in turn ranked with respect to the maximum memory usage. Each point then represents a solved instance with its rank (the horizontal coordinate) and the required memory (the vertical coordinate). In terms of memory consumption, the formula-BDD caching solver is the worst, while the non-blocking solver and clasp exhibit a stable performance.\nThe rapid increase in the curves of the non-blocking solver and clasp is due to large CNF formulae. Although the formula-BDD caching solver consumes much memory, these days it is not unusual that even laptop computers have several giga bytes of RAM, and advantage of the formula-BDD caching solver is not impaired so much.\n5.5. Comparison of Scalability in The Number of Solutions. As shown in Table 1, each representative solver has the following limit in the number of solutions within 600 seconds time limit .\n• Blocking: one million solutions. • Clasp: one hundred million solutions. • Non-Blocking: ten billion solutions. • BDD: more than one quadrillion solutions.\n5.6. Distribution of Solved Instances over Instance Series. Table 2 shows the distribution of solved instances over all instance series.\nIn almost all series, differences in the number of solved instances between solvers can be explained by their scalability.\nExceptions are the sc14 instances. They are clearly harder instances. All solvers were unable to find even one solution in many instances. For sc14-crafted series, solved instances are those of less than 10 solutions with a few exceptions of BDD. Table 3 shows the distribution of all sc14 instances including unsolved instances. Although clasp could find relatively many solutions, the other solvers could only find less than 10 solutions for a majority of instances. In terms of the ability to find solutions for sc14 instances, we could say that the best solver is clasp; the blocking solvers and the non-blocking solvers are a tie, both ranked at the second; the formula-BDD caching solver is no match for those instances, which is due to fixed variable ordering.\nThe favorite ranges of instances for representative solvers are illustrated in Fig. 13 according to the two factors: hardness of instances and the numbers of solutions instances have. Each solver is placed in such a way that the vertical position corresponds to the ability to find solutions for sc14 instances, where the blocking solver is above the non-blocking solver because of more benefit from a SAT solver, and the horizontal position corresponds to the scalability in the number of solutions. Hence, each indicated range refers to instances leftward or downward from it as well as those within it. It should be noted that shrinking the vertical axis would be more suitable for real performance,\nbecause in reality all solvers, on the whole, exhibits a poor performance over hard instances.\n5.7. Comparisons to Publicly Available #SAT Solvers. We also have a comparison with publicly available #SAT solvers, sharpSAT version 1.1 [52], c2d version 2.20 [16] and relsat version 2.20 [6], to check the performance of our developed ALLSAT solvers for #SAT. In the result for the same 2867 instances, relsat, sharpSAT, c2d and BDD Cut NonBlocking DLevel BJ solved 2191, 2196, 2196 and 2223\nrespectively. Since relsat supports solution count, it was used as a solution counter in this comparison. So, even for #SAT, the formulaBDD caching solver shows better performance."
    }, {
      "heading" : "6. Conclusion",
      "text" : "We surveyed and discussed major techniques of existing AllSAT solvers. We classified the types of solvers into a blocking solver, a nonblocking solver, and a formula-BDD caching solver. We faithfully implemented and released these solvers publicly so that other researchers can easily develop their solver by modifying our codes and compare it with existing methods. We conducted comprehensive experiments with total 2867 instances taken from SATLIB, SAT competition 2014, and ISCAS benchmarks. Apart from our implemented solvers, we used clasp, one of the few off-the-shelf softwares with solution generation support. The experiments revealed the following solver’s characteristics (600 seconds time limit). See also Fig. 13.\n• The formula-BDD caching solver is the most powerful. It has the most solved instances, including instances with more than one quadrillion solutions. The maximum memory usage amounts to several tens giga bytes in the worst case, though it is controllable by refreshing caches at the cost of a low cache hit rate. They are bad at hard instances due to fixed variable ordering. • The non-blocking solver is ranked at the next best, followed by\nclasp. The non-blocking solver and clasp can handle instances with ten billion solutions and one hundred million solutions with a low maximum memory usage (a few mega bytes to several tens of mega bytes), respectively. Although both solvers exhibit relatively a similar performance, a difference is that clasp is able to find a moderately many number of solutions from even hard instances, though it is not powerful enough to make it possible to solve instances that can not be handled by other means. • The blocking solver is limited to instances with one million so-\nlutions as blocking clauses deteriorate the performance of unit propagation. However, it can benefit from state-of-the-art techniques of SAT solvers as they are, thereby it is suitable for finding a small number of solutions for hard instances.\nFrom the above, we conclude that the formula-BDD caching solver is the most superior in terms of exact AllSAT solving over various kinds of instances. However, since not all solutions are necessary in some practical applications and duplicated solutions may be allowed, it is recommended to select an appropriate solver in accordance with types of instances and applications."
    } ],
    "references" : [ {
      "title" : "Binary decision diagrams",
      "author" : [ "S.B. Akers" ],
      "venue" : "IEEE Trans. Comput.,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1978
    }, {
      "title" : "MINCE: A static global variable-ordering heuristic for SAT search and BDD manipulation",
      "author" : [ "Fadi A. Aloul", "Igor L. Markov", "Karem A. Sakallah" ],
      "venue" : "J. UCS,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2004
    }, {
      "title" : "A constraint store based on multivalued decision diagrams",
      "author" : [ "H.R. Andersen", "T. Hadzic", "J.N. Hooker", "P. Tiedemann" ],
      "venue" : "In Christian Bessiére, editor, Principles and Practice of Constraint Programming,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2007
    }, {
      "title" : "Algorithms and complexity results for #sat and bayesian inference",
      "author" : [ "F. Bacchus", "S. Dalmao", "T. Pitassi" ],
      "venue" : "In Foundations of Computer Science,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2003
    }, {
      "title" : "Counting models using connected components",
      "author" : [ "Roberto J. Bayardo", "J.D. Pehoushek" ],
      "venue" : "Proceedings of the AAAI National Conference,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2000
    }, {
      "title" : "Using csp lookback techniques to solve real-world sat instances",
      "author" : [ "Roberto J. Bayardo", "Jr.", "Robert C. Schrag" ],
      "venue" : "In Proceedings of the Fourteenth National Conference on Artificial Intelligence and Ninth Conference on Innovative Applications of Artificial Intelligence,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1997
    }, {
      "title" : "Formula caching in dpll",
      "author" : [ "Paul Beame", "Russell Impagliazzo", "Toniann Pitassi", "Nathan Segerlind" ],
      "venue" : "ACM Trans. Comput. Theory,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "Handbook of Satisfiability: Volume 185 Frontiers in Artificial Intelligence and Applications",
      "author" : [ "A. Biere", "M. Heule", "H. van Maaren", "T. Walsh" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2009
    }, {
      "title" : "Existential quantification as incremental sat",
      "author" : [ "Jrg Brauer", "Andy King", "Jael Kriener" ],
      "venue" : "Computer Aided Verification,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2011
    }, {
      "title" : "Graph-based algorithms for boolean function manipulation",
      "author" : [ "R.E. Bryant" ],
      "venue" : "Computers, IEEE Transactions on,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1986
    }, {
      "title" : "Conflict-directed backjumping revisited",
      "author" : [ "Xinguang Chen", "Peter van Beek" ],
      "venue" : "J. Artif. Int. Res.,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2001
    }, {
      "title" : "Predicate abstraction of ansi-c programs using sat",
      "author" : [ "Edmund Clarke", "Daniel Kroening", "Natasha Sharygina", "Karen Yorav" ],
      "venue" : "Formal Methods in System Design,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2004
    }, {
      "title" : "Boolean Functions: Theory, Algorithms, and Applications. Encyclopedia of Mathematics and its Applications",
      "author" : [ "Y. Crama", "P.L. Hammer" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2011
    }, {
      "title" : "New advances in compiling CNF into decomposable negation normal form",
      "author" : [ "Adnan Darwiche" ],
      "venue" : "In Proceedings of the 16th Eureopean Conference on Artificial Intelligence, ECAI’2004, including Prestigious Applicants of Intelligent Systems,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2004
    }, {
      "title" : "Backjump-based backtracking for constraint satisfaction problems",
      "author" : [ "Rina Dechter", "Daniel Frost" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2002
    }, {
      "title" : "Computational aspects of monotone dualization: A brief survey",
      "author" : [ "Thomas Eiter", "Kazuhisa Makino", "Georg Gottlob" ],
      "venue" : "Discrete Applied Mathematics,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2008
    }, {
      "title" : "An extensible sat-solver",
      "author" : [ "Niklas En", "Niklas Srensson" ],
      "venue" : "In Enrico Giunchiglia and Armando Tacchella, editors, Theory and Applications of Satisfiability Testing,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2004
    }, {
      "title" : "Efficient sat-based unbounded symbolic model checking using circuit cofactoring",
      "author" : [ "M.K. Ganai", "A. Gupta", "P. Ashar" ],
      "venue" : "In Computer Aided Design,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2004
    }, {
      "title" : "clasp: A conflict-driven answer set solver",
      "author" : [ "Martin Gebser", "Benjamin Kaufmann", "André Neumann", "Torsten Schaub" ],
      "venue" : "Logic Programming and Nonmonotonic Reasoning,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2007
    }, {
      "title" : "Conflict-driven answer set enumeration",
      "author" : [ "Martin Gebser", "Benjamin Kaufmann", "André Neumann", "Torsten Schaub" ],
      "venue" : "Logic Programming and Nonmonotonic Reasoning,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2007
    }, {
      "title" : "Memory efficient all-solutions sat solver and its application for reachability analysis",
      "author" : [ "Orna Grumberg", "Assaf Schuster", "Avi Yadgar" ],
      "venue" : "Formal Methods in Computer-Aided Design,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2004
    }, {
      "title" : "Itemset mining: A constraint programming perspective",
      "author" : [ "Tias Guns", "Siegfried Nijssen", "Luc De Raedt" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1983
    }, {
      "title" : "Sat-based image computation with application in reachability analysis",
      "author" : [ "Aarti Gupta", "Zijiang Yang", "Pranav Ashar", "Anubhav Gupta" ],
      "venue" : "Formal Methods in Computer-Aided Design, volume 1954 of Lecture Notes in Computer Science,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2000
    }, {
      "title" : "Frequent pattern mining: current status and future directions",
      "author" : [ "Jiawei Han", "Hong Cheng", "Dong Xin", "Xifeng Yan" ],
      "venue" : "Data Mining and Knowledge Discovery,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2007
    }, {
      "title" : "Using dpll for efficient obdd construction",
      "author" : [ "Jinbo Huang", "Adnan Darwiche" ],
      "venue" : "In HolgerH. Hoos and DavidG. Mitchell, editors, Theory and Applications of Satisfiability Testing,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2005
    }, {
      "title" : "The language of search",
      "author" : [ "Jinbo Huang", "Adnan Darwiche" ],
      "venue" : "J. Artif. Intell. Res. (JAIR),",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2007
    }, {
      "title" : "Extending modern SAT solvers for models enumeration",
      "author" : [ "Säıd Jabbour", "Jerry Lonlac", "Lakhdar Sais", "Yakoub Salhi" ],
      "venue" : "In Proceedings of the 15th IEEE International Conference on Information Reuse and Integration,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2014
    }, {
      "title" : "Enumerating prime implicants of propositional formulae in conjunctive normal form",
      "author" : [ "Said Jabbour", "Joao Marques-Silva", "Lakhdar Sais", "Yakoub Salhi" ],
      "venue" : "Logics in Artificial Intelligence,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2014
    }, {
      "title" : "Boolean satisfiability for sequence mining",
      "author" : [ "Said Jabbour", "Lakhdar Sais", "Yakoub Salhi" ],
      "venue" : "In Proceedings of the 22Nd ACM International Conference on Conference on Information; Knowledge Management,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2013
    }, {
      "title" : "Efficient conflict analysis for finding all satisfying assignments of a boolean circuit",
      "author" : [ "HoonSang Jin", "HyoJung Han", "Fabio Somenzi" ],
      "venue" : "Tools and Algorithms for the Construction and Analysis of Systems,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2005
    }, {
      "title" : "Prime clauses for fast enumeration of satisfying assignments to boolean circuits",
      "author" : [ "HoonSang Jin", "Fabio Somenzi" ],
      "venue" : "In Proceedings of the 42Nd Annual Design Automation Conference,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2005
    }, {
      "title" : "Sat-based unbounded symbolic model checking. Computer-Aided Design of Integrated Circuits and Systems",
      "author" : [ "Hyeong-Ju Kang", "In-Cheol Park" ],
      "venue" : "IEEE Transactions on,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2005
    }, {
      "title" : "The Art of Computer Programming, Volume 4, Fascicle 1: Bitwise Tricks & Techniques",
      "author" : [ "Donald E. Knuth" ],
      "venue" : "Binary Decision Diagrams. Addison-Wesley Professional,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2009
    }, {
      "title" : "Representation of switching circuits by binary-decision programs",
      "author" : [ "C.Y. Lee" ],
      "venue" : "Bell System Technical Journal,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 1959
    }, {
      "title" : "A novel SAT allsolutions solver for efficient preimage computation",
      "author" : [ "Bin Li", "Michael S. Hsiao", "Shuo Sheng" ],
      "venue" : null,
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2004
    }, {
      "title" : "Network verification in the light of program verification",
      "author" : [ "Nuno Lopes", "Nikolaj Bjorner", "Patrice Godefroid", "George Varghese" ],
      "venue" : "Technical report,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2013
    }, {
      "title" : "Using caching to solve larger probabilistic planning problems",
      "author" : [ "Stephen M. Majercik", "Michael L. Littman" ],
      "venue" : "In Proceedings of the Fifteenth National Conference on Artificial Intelligence and Tenth Innovative Applications of Artificial Intelligence Conference,",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 1998
    }, {
      "title" : "Boolean satisfiability from theoretical hardness to practical success",
      "author" : [ "Sharad Malik", "Lintao Zhang" ],
      "venue" : "Commun. ACM,",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2009
    }, {
      "title" : "On computing backbones of propositional theories",
      "author" : [ "Joao Marques-Silva", "Mikoláš Janota", "Inês Lynce" ],
      "venue" : "In Proceedings of the 2010 Conference on ECAI 2010: 19th European Conference on Artificial Intelligence,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2010
    }, {
      "title" : "Grasp: a search algorithm for propositional satisfiability",
      "author" : [ "J.P. Marques-Silva", "K.A. Sakallah" ],
      "venue" : "Computers, IEEE Transactions on,",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 1999
    }, {
      "title" : "Applying sat methods in unbounded symbolic model checking",
      "author" : [ "KenL. McMillan" ],
      "venue" : "In Ed Brinksma and KimGuldstrand Larsen, editors, Computer Aided Verification,",
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 2002
    }, {
      "title" : "Good learning and implicit model enumeration",
      "author" : [ "A. Morgado", "J. Marques-Silva" ],
      "venue" : "In Tools with Artificial Intelligence,",
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 2005
    }, {
      "title" : "A compressed breadth-first search for satisfiability",
      "author" : [ "DoRonB. Motter", "IgorL. Markov" ],
      "venue" : "In DavidM. Mount and Clifford Stein, editors, Algorithm Engineering and Experiments,",
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 2002
    }, {
      "title" : "Efficient algorithms for dualizing large-scale hypergraphs",
      "author" : [ "Keisuke Murakami", "Takeaki Uno" ],
      "venue" : "Discrete Applied Mathematics,",
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 2014
    }, {
      "title" : "A lightweight component caching scheme for satisfiability solvers",
      "author" : [ "Knot Pipatsrisawat", "Adnan Darwiche" ],
      "venue" : "In Theory and Applications of Satisfiability Testing - SAT 2007,",
      "citeRegEx" : "47",
      "shortCiteRegEx" : "47",
      "year" : 2007
    }, {
      "title" : "Hybrid algorithms for the constraint satisfaction problem",
      "author" : [ "Patrick Prosser" ],
      "venue" : "Computational Intelligence,",
      "citeRegEx" : "48",
      "shortCiteRegEx" : "48",
      "year" : 1993
    }, {
      "title" : "Applying formal methods to networking: Theory, techniques, and applications",
      "author" : [ "J. Qadir", "O. Hasan" ],
      "venue" : "Communications Surveys Tutorials,",
      "citeRegEx" : "49",
      "shortCiteRegEx" : "49",
      "year" : 2015
    }, {
      "title" : "Minimal assignments for bounded model checking",
      "author" : [ "Kavita Ravi", "Fabio Somenzi" ],
      "venue" : "Tools and Algorithms for the Construction and Analysis of Systems,",
      "citeRegEx" : "50",
      "shortCiteRegEx" : "50",
      "year" : 2004
    }, {
      "title" : "Efficient preimage computation using a novel success-driven atpg",
      "author" : [ "Shuo Sheng", "Michael Hsiao" ],
      "venue" : "In Proceedings of the Conference on Design, Automation and Test in Europe - Volume 1,",
      "citeRegEx" : "51",
      "shortCiteRegEx" : "51",
      "year" : 2003
    }, {
      "title" : "sharpsat counting models with advanced component caching and implicit bcp",
      "author" : [ "Marc Thurley" ],
      "venue" : "In Armin Biere and CarlaP. Gomes, editors, Theory and Applications of Satisfiability Testing - SAT 2006,",
      "citeRegEx" : "52",
      "shortCiteRegEx" : "52",
      "year" : 2006
    }, {
      "title" : "Hypergraph transversal computation with binary decision diagrams",
      "author" : [ "Takahisa Toda" ],
      "venue" : "Experimental Algorithms,",
      "citeRegEx" : "53",
      "shortCiteRegEx" : "53",
      "year" : 2013
    }, {
      "title" : "Dualization of boolean functions using ternary decision diagrams",
      "author" : [ "Takahisa Toda" ],
      "venue" : "In International Symposium on Artificial Intelligence and Mathematics, ISAIM",
      "citeRegEx" : "54",
      "shortCiteRegEx" : "54",
      "year" : 2014
    }, {
      "title" : "Bdd construction for all solutions sat and efficient caching mechanism",
      "author" : [ "Takahisa Toda", "Koji Tsuda" ],
      "venue" : "In Proceedings of the 30th Annual ACM Symposium on Applied Computing,",
      "citeRegEx" : "55",
      "shortCiteRegEx" : "55",
      "year" : 2015
    }, {
      "title" : "Handbook of Knowledge Representation",
      "author" : [ "Frank van Harmelen", "Vladimir Lifschitz", "Bruce Porter" ],
      "venue" : "Elsevier Science, San Diego, USA,",
      "citeRegEx" : "56",
      "shortCiteRegEx" : "56",
      "year" : 2007
    }, {
      "title" : "Allsat using minimal blocking clauses",
      "author" : [ "Yinlei Yu", "P. Subramanyan", "N. Tsiskaridze", "S. Malik" ],
      "venue" : "In VLSI Design and 2014 13th International Conference on Embedded Systems,",
      "citeRegEx" : "57",
      "shortCiteRegEx" : "57",
      "year" : 2014
    }, {
      "title" : "Verification of computer switching networks: An overview",
      "author" : [ "Shuyuan Zhang", "Sharad Malik", "Rick McGeer" ],
      "venue" : "(T. Toda) Graduate School of Information Systems, University of Electro-Communications,",
      "citeRegEx" : "58",
      "shortCiteRegEx" : "58",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 53,
      "context" : "practical algorithms and elegant implementation techniques have been developed [56] [9] [40].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 7,
      "context" : "practical algorithms and elegant implementation techniques have been developed [56] [9] [40].",
      "startOffset" : 84,
      "endOffset" : 87
    }, {
      "referenceID" : 37,
      "context" : "practical algorithms and elegant implementation techniques have been developed [56] [9] [40].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 26,
      "context" : "This is mentioned in the literature [29] and also supported by the fact that there are only a few recent papers, almost no software is publicly available, and it has not even been taken up in major handbooks related to satisfiability.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 23,
      "context" : "A fundamental task in data mining is to generate all interesting patterns from a given database [26].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 18,
      "context" : "1A few exceptions are clasp [21], picosat [10], and relsat [6].",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 5,
      "context" : "1A few exceptions are clasp [21], picosat [10], and relsat [6].",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 21,
      "context" : "For this reason, a framework based on declarative paradigm has recently been proposed [24].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 28,
      "context" : "Among much related work, an approach on which problems are encoded into CNF formulae and solved with AllSAT solvers has been studied [31].",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 55,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 35,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 46,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 11,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 189,
      "endOffset" : 193
    }, {
      "referenceID" : 38,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 216,
      "endOffset" : 220
    }, {
      "referenceID" : 22,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 281,
      "endOffset" : 285
    }, {
      "referenceID" : 40,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 286,
      "endOffset" : 290
    }, {
      "referenceID" : 48,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 291,
      "endOffset" : 295
    }, {
      "referenceID" : 34,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 296,
      "endOffset" : 300
    }, {
      "referenceID" : 17,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 301,
      "endOffset" : 305
    }, {
      "referenceID" : 20,
      "context" : "Besides the data mining, there have been many studies on the application of ALLSAT, in particular to formal verification, such as network verification [58] [38] [49], predicate abstraction [14], backbone computation [41], image and preimage computation in unbounded model checking [25] [43] [51] [37] [20] [23].",
      "startOffset" : 306,
      "endOffset" : 310
    }, {
      "referenceID" : 15,
      "context" : "Dualization has been well-studied in terms of complexity [18] [15], while there seems no recent empirical study with a few exceptions [33] [11] [30] [54].",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 12,
      "context" : "Dualization has been well-studied in terms of complexity [18] [15], while there seems no recent empirical study with a few exceptions [33] [11] [30] [54].",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 30,
      "context" : "Dualization has been well-studied in terms of complexity [18] [15], while there seems no recent empirical study with a few exceptions [33] [11] [30] [54].",
      "startOffset" : 134,
      "endOffset" : 138
    }, {
      "referenceID" : 8,
      "context" : "Dualization has been well-studied in terms of complexity [18] [15], while there seems no recent empirical study with a few exceptions [33] [11] [30] [54].",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 27,
      "context" : "Dualization has been well-studied in terms of complexity [18] [15], while there seems no recent empirical study with a few exceptions [33] [11] [30] [54].",
      "startOffset" : 144,
      "endOffset" : 148
    }, {
      "referenceID" : 51,
      "context" : "Dualization has been well-studied in terms of complexity [18] [15], while there seems no recent empirical study with a few exceptions [33] [11] [30] [54].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 50,
      "context" : "Practical algorithms for a restricted form of dualization have been presented [53] [46] and some implementations are available, though they are not for arbitrary Boolean functions.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 43,
      "context" : "Practical algorithms for a restricted form of dualization have been presented [53] [46] and some implementations are available, though they are not for arbitrary Boolean functions.",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 7,
      "context" : "It has been well-studied because of good applications such as probabilistic inference problems and hard combinatorial problems, and some solvers are available [9].",
      "startOffset" : 159,
      "endOffset" : 162
    }, {
      "referenceID" : 41,
      "context" : "Although #SAT is apparently similar to AllSAT, techniques such as connected components and component caching are inherent in counting, and they are not applicable to AllSAT as is [44].",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 53,
      "context" : "See for details [56] and [9].",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 7,
      "context" : "See for details [56] and [9].",
      "startOffset" : 25,
      "endOffset" : 28
    }, {
      "referenceID" : 33,
      "context" : "A binary decision diagram (BDD for short) is a graphical representation of Boolean functions in a compressed form [36] [1] [12].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 0,
      "context" : "A binary decision diagram (BDD for short) is a graphical representation of Boolean functions in a compressed form [36] [1] [12].",
      "startOffset" : 119,
      "endOffset" : 122
    }, {
      "referenceID" : 9,
      "context" : "A binary decision diagram (BDD for short) is a graphical representation of Boolean functions in a compressed form [36] [1] [12].",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 32,
      "context" : "We follow the notation and terminology in Knuth’s book [35].",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 40,
      "context" : "The clause obtained at Step 4 is called a blocking clause [43].",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 47,
      "context" : "Variable lifting refers to a number of such simplification techniques [50].",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 41,
      "context" : "Since this topic is well-summarized in the literature [44], we do not go into details.",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 54,
      "context" : "For recent results, see also the literature [57].",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 29,
      "context" : "It is not straightforward to answer how to continue search [32].",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 44,
      "context" : "The problem of over-canceling due to backtracking was addressed [47], and a simple technique, called progress saving, that stores recent canceled decisions in an array and simulates them after backtracking was proposed.",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 41,
      "context" : "For a simplification technique, we used a method related to set covering model [44] and decision-based minimal satisfying cube [57].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 54,
      "context" : "For a simplification technique, we used a method related to set covering model [44] and decision-based minimal satisfying cube [57].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 20,
      "context" : "introduced the notion of sublevels and presented a sublevel-based first UIP scheme that is compatible with non-blocking approach [23].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 20,
      "context" : "augmented non-blocking approach with conflict resolution by means of a restricted non-chronological backtracking [23].",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 45,
      "context" : "CBJ has been studied as one of tree search algorithms for constraint satisfaction problem [48] [13] [17].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 10,
      "context" : "CBJ has been studied as one of tree search algorithms for constraint satisfaction problem [48] [13] [17].",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 14,
      "context" : "CBJ has been studied as one of tree search algorithms for constraint satisfaction problem [48] [13] [17].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 20,
      "context" : "A pseudo code is given in Algorithm 5, which is almost faithfully rephrased in our setting from the code given in the literature [23].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 19,
      "context" : "To our knowledge, this method was first presented by [22], though it was in the context of answer set programming.",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 19,
      "context" : "6It is mentioned [22] that a combination of conflict-directed backjumping and",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 6,
      "context" : "Formula caching refers to a number of techniques to memorize formulae to avoid recomputation of subproblems [7].",
      "startOffset" : 108,
      "endOffset" : 111
    }, {
      "referenceID" : 36,
      "context" : "Examples include a caching technique in probabilistic planning [39], conflict clauses in SAT [6] [42], component caching and other cachings in #SAT [5] [4], and blocking clauses in AllSAT [43].",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 5,
      "context" : "Examples include a caching technique in probabilistic planning [39], conflict clauses in SAT [6] [42], component caching and other cachings in #SAT [5] [4], and blocking clauses in AllSAT [43].",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 39,
      "context" : "Examples include a caching technique in probabilistic planning [39], conflict clauses in SAT [6] [42], component caching and other cachings in #SAT [5] [4], and blocking clauses in AllSAT [43].",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 4,
      "context" : "Examples include a caching technique in probabilistic planning [39], conflict clauses in SAT [6] [42], component caching and other cachings in #SAT [5] [4], and blocking clauses in AllSAT [43].",
      "startOffset" : 148,
      "endOffset" : 151
    }, {
      "referenceID" : 3,
      "context" : "Examples include a caching technique in probabilistic planning [39], conflict clauses in SAT [6] [42], component caching and other cachings in #SAT [5] [4], and blocking clauses in AllSAT [43].",
      "startOffset" : 152,
      "endOffset" : 155
    }, {
      "referenceID" : 40,
      "context" : "Examples include a caching technique in probabilistic planning [39], conflict clauses in SAT [6] [42], component caching and other cachings in #SAT [5] [4], and blocking clauses in AllSAT [43].",
      "startOffset" : 188,
      "endOffset" : 192
    }, {
      "referenceID" : 25,
      "context" : "Another type of formula caching in which formulae are associated with propositional languages such as FBDD, OBDD, and a subset of d-DNNF has been studied in the context of knowledge compilation [28].",
      "startOffset" : 194,
      "endOffset" : 198
    }, {
      "referenceID" : 52,
      "context" : "An application to an AllSAT solver itself was more explicitly mentioned in the literature [55] and a compiler-based AllSAT solver is released.",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 48,
      "context" : "Similar caching techniques appear in other areas such as preimage computation in unbounded model checking [51] [37] [34], satisfiability [45], and discrete optimization [3] [8].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 34,
      "context" : "Similar caching techniques appear in other areas such as preimage computation in unbounded model checking [51] [37] [34], satisfiability [45], and discrete optimization [3] [8].",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 31,
      "context" : "Similar caching techniques appear in other areas such as preimage computation in unbounded model checking [51] [37] [34], satisfiability [45], and discrete optimization [3] [8].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 42,
      "context" : "Similar caching techniques appear in other areas such as preimage computation in unbounded model checking [51] [37] [34], satisfiability [45], and discrete optimization [3] [8].",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 2,
      "context" : "Similar caching techniques appear in other areas such as preimage computation in unbounded model checking [51] [37] [34], satisfiability [45], and discrete optimization [3] [8].",
      "startOffset" : 169,
      "endOffset" : 172
    }, {
      "referenceID" : 24,
      "context" : "work [27] [55].",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 52,
      "context" : "work [27] [55].",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 24,
      "context" : "Examples of formula-BDD cachings include those induced by cutsets and separators [27], defined below, and a variant of cutsets [55].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 52,
      "context" : "Examples of formula-BDD cachings include those induced by cutsets and separators [27], defined below, and a variant of cutsets [55].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 24,
      "context" : "See [27].",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 16,
      "context" : "1 [19].",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 18,
      "context" : "As far as we are aware, clasp [21], picosat [10], and relsat [6] are only SAT solvers which support the enumeration of all solutions.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 5,
      "context" : "As far as we are aware, clasp [21], picosat [10], and relsat [6] are only SAT solvers which support the enumeration of all solutions.",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 1,
      "context" : "0 [2] to decide a static variable order before the execution of formula-BDD caching solvers.",
      "startOffset" : 2,
      "endOffset" : 5
    }, {
      "referenceID" : 49,
      "context" : "1 [52], c2d version 2.",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 13,
      "context" : "20 [16] and relsat version 2.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 5,
      "context" : "20 [6], to check the performance of our developed ALLSAT solvers for #SAT.",
      "startOffset" : 3,
      "endOffset" : 6
    } ],
    "year" : 2015,
    "abstractText" : "All solutions SAT (AllSAT for short) is a variant of propositional satisfiability problem. Despite its significance, AllSAT has been relatively unexplored compared to other variants. We thus survey and discuss major techniques of AllSAT solvers. We faithfully implement them and conduct comprehensive experiments using a large number of instances and various types of solvers including one of the few public softwares. The experiments reveal solver’s characteristics. Our implemented solvers are made publicly available so that other researchers can easily develop their solver by modifying our codes and compare it with existing methods.",
    "creator" : "LaTeX with hyperref package"
  }
}