{
  "name" : "1206.6822.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Cutset Sampling with Likelihood Weighting",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "The paper extends the principle of cutset sampling over Bayesian networks, presented previously for Gibbs sampling, to likelihood weighting (LW). Cutset sampling is motivated by the Rao-Blackwell theorem which implies that sampling over a subset of variables requires fewer samples for convergence due to the reduction in sampling variance. The scheme exploits the network structure in selecting cutsets that allow efficient computation of the sampling distributions. In particular, as we show empirically, likelihood weighting over a loop-cutset (abbreviated LWLC), is time-wise cost-effective. We also provide an effective way for caching the probabilities of the generated samples which improves the performance of the overall scheme. We compare LWLC against regular liklihood-weighting and against Gibbsbased cutset sampling."
    }, {
      "heading" : "1 Introduction",
      "text" : "Stochastic sampling is a popular approach for estimating answers to Bayesian queries when exact inference is intractable. Based on the generated samples, we can obtain estimates that converge to the exact values as the number of samples increases. However, convergence may be slow in large networks due to increase in sampling variance. This is the problem we address in this paper.\nBased on Rao-Blackwell theorem, we can reduce sampling variance and speed up convergence by sampling only a subset of the variables (a cutset). However, the efficiency of sampling from lower-dimensional spaces is hindered by the overhead of computing the sampling distributions. The latter is equivalent to performing exact inference which is exponential in the induced\nwidth of the network whose instantiated variables (evidence and sampled) are removed.\nWe defined previously an efficient parametrized Gibbs cutset sampling scheme, called w-cutset sampling [2, 3], where the complexity of generating a single sample is bounded exponentially by w. In this paper, we extend the cutset sampling principle to likelihood weighting (LW) [11, 21], which is a form of importance sampling [21], focusing on sampling from a loop-cutset. The resulting scheme, which we call LWLC, computes a sample over a loop-cutset C in O((|C| + |E|) · N), where E is evidence and N is the size of the input network. While we present our scheme for LW, it is applicable to other importance sampling schemes.\nWhile both cutset schemes, one based on Gibbs sampling and one based on likelihood weighting, exploit the network structure to manage the complexity of exact inference, they compute different sampling distributions. Gibbs sampler draws a new value of variable Xi from distribution P (Xi|x\\xi). Likelihood weighting samples a new value from P (Xi|x1, ..., xi−1). Furthermore, while both schemes benefit from reducing the size of the sampling space, it is hard to predict which of the two schemes is superior. The convergence speed of Gibbs sampling depends on the maximum correlation between the sampled variables. The convergence of likelihood weighting is affected by the distance between the sampling and the target distributions and, thus, depends also on the nature of evidence. Finally, Gibbs estimates converge only when all Markov Chain transition probabilities are positive.\nThe advantages of cutset-based importance sampling, also known as Rao-Blackwellised importance sampling, were demonstrated previously in a few special cases [9, 8, 1]. Our scheme automates the cutset selection process based on the Bayesian network structure. We demonstrate empirically that LWLC is efficient timewise and has a lower rejection rate in networks with determinism. We achieve additional improvements by caching the probabilities of the generated samples.\nOur scheme can be generalized to other importance sampling schemes."
    }, {
      "heading" : "2 Background",
      "text" : "Definition 2.1 (belief networks) Let X={X1, ...,Xn} be a set of random variables over multi-valued domains D(X1), ...,D(Xn). A belief network is a pair <G,P> where G is a directed acyclic graph on X and P={P (Xi|pai)|Xi ∈ X} is the set of conditional probability tables (CPTs), conditioned on parents pai of Xi. An evidence e is an instantiated subset of variables E. A network is singlyconnected (also called a poly-tree), if its underlying undirected graph has no cycles. Otherwise, it is multiply-connected.\nDefinition 2.2 (loop-cutset) A loop in G is a subgraph of G whose underlying graph is a cycle. A vertex v is a sink with respect to a loop L if the two edges adjacent to v in L are directed into v. Every loop contains at least one vertex that is not a sink with respect to that loop. Each vertex that is not a sink with respect to a loop L is called an allowed vertex with respect to L. A loop-cutset of a directed graph G is a set of vertices that contains at least one allowed vertex with respect to each loop in G.\nThe queries over a singly-connected network can be processed in time linear in the size of the network [18]. In general, the complexity of queries can be reduced by restricting G to a relevant subnetwork.\nDefinition 2.3 (Relevant Subnetwork) A variable Xi in DAG G over X is irrelevant (barren) w.r.t. a subset Z⊂X if Xi /∈Z and Xi only has irrelevant descendants (if any). The relevant subnetwork of G w.r.t. a subset Z is the subgraph of G obtained by removing all variables that are irrelevant w.r.t Z."
    }, {
      "heading" : "2.1 Likelihood Weighting",
      "text" : "Likelihood weighting [11, 21] belongs to a family of importance sampling schemes that draw independent samples from a trial distribution Q(X). The trial distribution is different from the target distribution P (X). Generally, Q(X) is selected so that it is easy to compute. A typical query in Bayesian networks is to estimate the posterior marginals P (xi|e) which can be obtained from the sampling estimates of P (e) and P (xi, e). Let Y = X\\E. Then:\nEP [P (e)] = ∑\ny\nP (y, e) = ∑\ny\nP (y, e)\nQ(y) Q(y) = EQ[\nP (y, e)\nQ(y) ]\nConsequently, the sampling estimate P̂ (e) of P (e), based on T samples from Q(X), is obtained by:\nP̂ (e) = 1\nT\nT∑\nt=1\nP (y(t), e)\nQ(y(t)) =\n1\nT\nT∑\nt=1\nw(t) (1)\nwhere w(t) = P (y (t),e)\nQ(y(t)) is the weight of sample y(t). In a\nsimilar manner, but counting only those samples where Xi = xi, we can obtain an expression for the sampling estimate P̂ (xi, e) of P (xi, e) for Xi ∈ X\\E by:\nP̂ (xi, e) = 1 T ∑T t=1 w (t)δ(xi, x (t)) (2)\nwhere δ(xi, x (t))=1 iff x (t) i =xi and δ(xi, x (t))=0 otherwise. Since P (xi|e) = P (xi,e)\nP (e) , we get:\nP̂ (xi|e) =\n∑T t=1 w (t)δ(xi, x (t))\n∑T t=1 w (t) = α\nT∑\nt=1\nw(t)δ(xi, x (t))\n(3) where α is a normalization constant. These sampling estimates are guaranteed to converge to their target values as T increases as long as the support for Q(X) includes all support for P (X). Namely, the condition ∀x ∈ X, P (x) 6= 0 ⇒ Q(x) 6= 0 must hold. Eq. (3) yields a biased estimate of P̂ (xi|e). However, when the sample size is large enough, bias can be ignored [10].\nLikelihood weighting draws samples from a distribution Q(X) that is close to the prior distribution. It begins with a network without evidence and assigns values to nodes in topological order. First, root nodes are sampled from their prior distributions. Then, the values of all other nodes Xi∈X\\E are sampled from the distribution P (Xi|pai). Evidence variables Ei∈E are assigned their observed value. Thus, the sampling distribution of likelihood weighting can be described as follows:\nQ(X) = ∏\nXi∈X\\E P (Xi|pai) |E=e (4)\nWe therefore compute the weight w(t) of sample t by:\nw(t) = P (x(t))\nQ(x(t)) =\n∏ Xi∈X P (x (t) i |pa\n(t) i )∏\nXi∈X\\E P (x (t) i |pa (t) i )\n(5)\nAll factors in the numerator and denominator of the fraction cancel out except for P (ei|pai), leaving:\nw(t) = ∏\nEi∈E P (ei|pa (t) i ) (6)\nThus, during sampling, we compute the weight w(t) of sample t by initializing w(t)←1 and updating w(t)←w(t) · P (ei|pa (t) i ) whenever we encounter an evidence Ei = ei. The posterior marginals estimates are obtained by plugging the sample weights in Eq.(3).\nThe convergence of importance sampling schemes can be slow when Q(X) is very different from P (X). Consequently, many importance sampling schemes focus on finding an improved sampling distribution by either changing the variable sampling order [12] or updating the sampling distribution based on previously generated samples [21, 5, 22]. We can also improve convergence by reducing the dimensionality of the sampling space as implied by Rao-Blackwell theorem."
    }, {
      "heading" : "3 Rao-Blackwellised Likelihood Weighting",
      "text" : "Give a Bayesian network over a set of variables X with evidence E⊂X, E=e, let C⊂X\\E be a subset of variables in X, Z=C ⋃ E, and m=|Z|. Let o={Z1, ..., Zm} be a topological ordering of the variables. We can define likelihood weighting over Z as follows. Processing variables in order o, we sample value z1 from distribution P (Z1), z2 from P (Z2|z1), and so on. For each Zi∈C, we sample a value zi from the distribution P (Zi|z1, ..., zi−1). If Zi∈E, we assign Zi its observed value. The sampling distribution Q(C) is:\nQ(C) = ∏\nZi∈C\nP (Zi|z1, ..., zi−1) |E=e (7)\nThe weight w(t) of sample t is given by:\nw(t) = P (z(t))\nQ(z(t)) =\n∏ Zi∈Z P (z (t) i |z (t) 1 , ..., z\n(t) i−1)∏\nZi∈Z\\E P (z (t) i |z (t) 1 , ..., z (t) i−1)\n(8)\nAfter cancelling out the common factors in denominator and numerator, we get:\nw(t) = ∏\nZi∈E P (ei|z (t) 1 , ..., z (t) i−1) (9)\nDuring sampling, the weight (initialized to 1) is updated every time we encounter an evidence variable Zi ∈ E with observed value ei using:\nw(t) ← w(t) · P (ei|z1, ..., zi−1) (10)\nThe main difference between likelihood weighting over cutset C and sampling over all variables X is in computing the sampling distributions. In the latter case, the distribution P (Xi|x1, ..., xi−1) = P (Xi|pai) is readily available in the conditional probability table of Xi. However, the sampling distribution P (Zi|z1, ..., zi−1) for LWLC needs to be computed.\nConsider the special case when C ∪ E is a loopcutset. In this case, we can compute the probability P (z)=P (c, e) in linear time and space using Pearl’s belief propagation algorithm. We can show that we can also compute P (Zi|z1, ..., zi−1) efficiently if we order the variables in Z topologically and restrict our attention to the relevant subnetwork of Z1, ..., Zi.\nTheorem 3.1 Given Bayesian network over X, evidence E ⊂ X, and cutset C ⊂ X\\E, let Z = C ∪ E be a loop-cutset. If Z is topologically ordered, then ∀Zj ∈ Z the relevant subnetwork of Z1, ..., Zj is singlyconnected when Z1, ..., Zj are observed.\nProof. Proof by contradiction. Assume that the relevant subnetwork of Z1, ..., Zj contains a loop L with sink S. Then, either S = Zq or S has a descendant Zq, 1≤q≤j, (otherwise S is irrelevant). By definition of loop-cutset, ∃Cm∈L s.t. Cm 6=S and Cm ∈ C ⊂ Z. Threfore, Cm is an ancestor of Zq. Since variables are topologically ordered and all loop-cutset nodes preceding Zq are observed, Cm must be observed, thus, breaking the loop, yielding a contradiction. 2\nConclusion: if C is a loop-cutset, we can compute the distributions P (Zi|z1, ..., zi−1) for every Zi∈Z over the relevant subnetwork of Zi in linear time and space.\nTherefore, the complexity of computing a new sample is proportional to the number of variables in Z and the size of the input N . In summary:\nTheorem 3.2 (Complexity) Given a Bayesian network over X, evidence E, and a loop-cutset C⊂X\\E, the complexity of generating one sample using likelihood weighting over a cutset C is O(|Z| · N) where Z = C ∪ E and N is the size of the input network.\nOnce a sample c(t) is generated, we apply belief propagation algorithm one more time to obtain the posterior marginals, P (Xi|c\n(t), e), for each remaining variable. Once T samples are generated, we obtain the posterior marginals estimates, similar to Eq. (3), by:\nP̂ (ci|e) = α\nT∑\nt=1\nw(t)δ(ci, c (t)), ∀Ci ∈ C\nP̂ (xi|e) = α\nT∑\nt=1\nw(t)P (xi|c (t), e), ∀Xi ∈ X\\C,E"
    }, {
      "heading" : "3.1 Convergence",
      "text" : "Likelihood weighting on a loop-cutset (LWLC) has a higher overhead in computing the distributions P (Zi|z1, ..., zi−1) for ∀Zi ∈ Z, compared with sampling on a full variable set. However, as mentioned earlier, it converges faster. In general, importance sampling convergence rate is affected by the sampling variance and the distance between the sampling and the target distributions. The estimates obtained by sampling from a lower-dimensional space have lower variance due to Rao-Blackwell theorem. That is:\nV ar{ P (Y,C)\nQ(Y,C) } ≥ V ar{\nP (C) Q(C) }\nwhere P (C) = ∑ y P (Y,C) and Q(C) = ∑\ny Q(Y,C) [9, 16] A proof can be found in [9] and [16]. Consequently, fewer LWLC samples are needed to achieve the same accuracy as LW.\nThe information distance between target distribution P (C|e) and sampling distribution Q(C) in LWLC is smaller than the distance between P (X|e) and sampling distribution Q(X). We can show this for the KL-distance [15]:\nKL(P (X), Q(X)) = ∑\nx\nP (x) log P (x)\nQ(x) (11)\nTheorem 3.3 (Reduced Information Distance) Given a Bayesian network expressing probability distribution P (X), evidence E=e, and a cutset C ⊂ X\\E, let Q(X) and Q(C,E) denote the likelihood weighting sampling distribution over X and over C,E respectively. Then:\nKL(P (C|e), Q(C,E)) ≤ KL(P (X|e), Q(X))\nWe outline the proof in the Appendix. The details are available in [4]."
    }, {
      "heading" : "3.2 Caching Sampling on a Cutset",
      "text" : "Often, we can reduce the computation time of a sampling scheme by caching the generated samples and their probabilities. Caching LW values is of limited benefit since it uses probabilities stored in CPTs. However, in the case of LWLC, caching may compensate in part for the computation overhead. A suitable data structure for caching is a search-tree over the cutset C with a root node C1. As new variable values are sampled and a partial assignment to the variables C1, ..., Ci is generated, LWLC traverses the search tree along the path c1, ..., ci. Whenever a new value of Ci is sampled, the corresponding tree branch is expanded and the current sample weight and the sampling distribution P (Ci|z1, ..., zi−1) are saved in the node Ci. In the future, when generating the same partial assignment c1, ..., ci, LWLC saves on computation by reading saved distributions from the tree. We will use LWLC-BUF to denote LWLC sampling scheme that uses a memory buffer to cache previously computed probabilities. LWLC-BUF can also update the sampling distributions P (Ci|z1, ..., zi−1) when dead-ends are discovered. Namely, if the algorithm finds that a partial instantiation z1, ..., zi, cannot be extended to a full tuple with non-zero probability, then we set P (Ci|z1, ..., zi−1) = 0 and normalize the updated distribution."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Methodology",
      "text" : "In this section, we compare empirically the performance of full likelihood weighting (LW), sampling over all the variables, against likelihood weighting on a loop-cutset (LWLC) and buffered likelihood weighting on a loop-cutset (LWLC-BUF). In networks with positive distributions, we compare likelihood weighting side by side with Gibbs sampling (Gibbs) and Gibbsbased loop-cutset sampling (LCS) [2]. For reference, we also compare with the estimates obtained by Iterative Belief Propagation (IBP). Belief propagation computes the exact posterior marginals in poly-trees [18]. When applied to networks with loops, it computes approximate marginals when it converges. IBP is fast and often produces good estimates [17, 20].\nThe quality of the approximate posterior marginals is measured by the Mean Square Error (MSE):\nMSE =\n∑ Xi∈X\\E ∑ D(Xi) [P (xi|e)− P̂ (xi|e)] 2\n∑ Xi∈X\\E |D(Xi)|\nThe exact posterior marginals P (Xi|e) are obtained by bucket-tree elimination [7, 6]. We also measure the rejection rate R of each sampling scheme.\nOur benchmarks are taken from Bayesian network repository. They include two subsets of Pathfinder network, Pathfinder1 and Pathfinder2, Link, and two CPCS networks, cpcs360b and cpcs422b. The benchmarks’ properties are summarized in Table 1. Pathfinder is an expert system for identifying disorders from lymph node tissue sections [13]. Link is a model for the linkage between two genes [14]. The exact posterior marginals for those networks were easy to compute by bucket elimination. However, they are hard for sampling because of the large number of deterministic relationships. cpcs360b and cpcs422b are derived from the Computer-Based Patient Care Simulation system [19]. They are more challenging for exact inference because of their large induced widths. All experiments were performed on a 1.8 GHz CPU."
    }, {
      "heading" : "4.2 Results",
      "text" : ""
    }, {
      "heading" : "4.2.1 Sampling Speed",
      "text" : "We generated 30 instances of each network with different random observations among the leaf nodes. In Table 2, we report the speed of generating samples using LW, LWLC, and LWLC-BUF sampling schemes. As expected, LWLC generates far fewer samples than LW. Notably, the relative speed of LW and LWLC remains the same in the two Pathfinder networks and in Link network. By the time LW generates 100, 000 samples, LWLC generates 1200 samples. Table 2 also shows an order of magnitude improvement in the speed of generating samples by LWLC-BUF in cpcs360b, Pathfinder1, and Pathfinder2, a factor of 2 improvement in cpcs422b, and no change in the Link network. The improvement depends on the ratio of unique samples. The number of unique tuples in Pathfinder networks is only ≈1% of the total number of samples and, thus, 99% of the computation is redundant. However, in Link network, nearly all samples are unique. Hence, buffering was not beneficial."
    }, {
      "heading" : "4.2.2 Rejection Rates",
      "text" : "When target distribution P (X) has many zeros where sampling distribution Q(X) remains positive, many samples with weight 0 may be generated which do not contribute to the sampling estimates. Hence, we call them “rejected.” This is not an issue in cpcs360b and cpcs422b where all probabilities are positive. However, in deterministic networks, many samples may be rejected, contributing to slow convergence. We will use\nthe rejection rate R to denote the percentage of samples of weight 0. When the evidence is rare, we may need to generate a very large number of samples before we find a single sample of non-zero weight. When all samples are rejected, we will say that the rejection rate is 100% and call the network instance unresolved.\nThe rejection rates of the three likelihood weighting schemes over Pathfinder1, Pathfinder2, and Link are summarized in Table 3. For each benchmark, we report the number of instances k (out of 30), where the rejection rate <100%. As we can see, LW resolved all 30 instances of Pathfinder1 but only 28 instances of Pathfinder2 and only 17 instances of Link. LWLC and LWLC-BUF resolved all network instances.\nTable 3 also reports the rejection rate R averaged over those instances where all three algorithms generated some samples with non-zero probabilities. As we can see, LW has high rejection rates in all benchmarks. The corresponding LWLC rejection rates are a factor of 3 or more smaller. Although lower rejection rate alone does not guarantee faster convergence, it helps compensate for generating fewer samples. The rejection rate of LWLC-BUF is two orders of magnitude lower than LWLC in Pathfinder networks but it is the same as LWLC in Link network (also because most of the samples are unique).\nThe rejection rate of LW and LWLC does not change with time. However, as LWLC-BUF learns zeros of the target distribution, its rejection rate may decrease as the number of samples increases. Figure 1 demonstrates this on the example of Pathfinder networks."
    }, {
      "heading" : "4.2.3 Accuracy of the Estimates",
      "text" : "The MSE results for PathFinder1, Pathfinder2, and Link are shown in Figure 2 as a function of time. The comparative behavior of LW, LWLC, and LWLCBUF sampling schemes is similar in all three networks. LWLC consistenly converges faster than LW and out-\nperforms IBP within 2 seconds. LW outperforms IBP within 2 seconds in Pathfinder1 and within 8 seconds in Pathfinder2. However, LW is considerably worse than IBP in Link network. LWLC-BUF converges faster than LWLC in Pathfinder1 and Pathfinder2 because it generates more samples and has a lower rejection rate. In Link network, their performance is the same and, thus, we only show the LWLC curve.\nThe PathFinder2 network was also used as a benchmark in the evaluation of AIS-BN algorithm [5], an adaptive importance sampling scheme. Although we experimented with different network instances, we can make a rough comparison. Within 60 seconds, AIS-BN computes MSE ≈ 0.0005. Adjusting for the difference in processor speed, the corresponding MSEs of LWLC and LWLC-BUF are ≈0.004 and ≈0.00008, obtained in 6 seconds. Hence, AIS-BN and LWLC-BUF produce comparable results.\nThe accuracy of LW and LWLC for cpcs360b and cpcs422b networks is shown in Figure 3. Overall, results are similar. The LWLC outperforms LW by a wide margin in both benchmarks. Since all probabilities are positive, we also show the results for two Gibbs sampling schemes. Gibbs outperforms full likelihood weighting. Gibbs-based loop-cutset sampling (LCS) outperforms LWLC. Figure 4 focuses on the buffered cutset sampling schemes. Both LWLC-BUF and LCSBUF improve substantially over the plain LWLC and LCS. And again, the Gibbs-based LCS-BUF is better than LWLC-BUF.\nAlthough Gibbs sampling schemes outperformed likelihood weighting methods in cpcs360b and cpsc422b, where evidence was selected among leaf nodes, the two methods are likely to switch places when fewer leaf nodes are observed. In particular, likelihood weighting outperforms Gibbs sampling in cpcs360b and cpcs422b without evidence [4]."
    }, {
      "heading" : "5 Related Work and Conclusions",
      "text" : "In this paper we presented a cutset-based likelihood weighting. By reducing the dimensionality of the sampling space, we achieve reduction in th esampling variance and also reduce the information distance (KLdistance) between the sampling and the target distributions. Therefore, the cutset sampling scheme requires fewer samples to converge.\nIn the past, Rao-Blackwellised importance sampling was made efficient by exploiting the properties of the conditional probability distributions, e.g., when the distributions for the marginalised variables could be computed analytically using a Kalman filter [9, 8, 1] or when the marginalised variables in a factored HMM became conditionally independent (when sampled variables are observed) due to the numerical structure of the CPTs [8]. In contrast, our method bounds the complexity of computing the sampling distributions by exploiting the structure of the network.\nWe demonstrated empirically that cutset-based likelihood weighting is time-wise effective. Namely, it computes more accurate estimates than likelihood weighting as a function of time. We improve the convergence of cutset-based likelihood weighting by caching previously computed samples. The buffered scheme reduces the average sample computation time since it does not re-compute the probabilities of previously generated tuples and since it allows modifying the cached distributions dynamically.\nIn this paper, we only updated the saved distributions when a partially-instantiated cutset tuple could not be extended to a full cutset tuple with non-zero probability. However, we can additionally update cached distributions based on the weight of previously generated samples as adaptive importance sampling techniques do. The proposed cutset-based likelihood weighting can be generalized to other importance sampling schemes."
    } ],
    "references" : [ {
      "title" : "Blackwellised particle filtering via data augmentation",
      "author" : [ "C. Andrieu", "N. de Freitas", "A. Doucet. Rao" ],
      "venue" : "In Advances in Neural Information Processing Systems. MIT Press,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2002
    }, {
      "title" : "Cycle-cutset sampling for Bayesian networks",
      "author" : [ "B. Bidyuk", "R. Dechter" ],
      "venue" : "In 16th Canadian Conference on AI,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2003
    }, {
      "title" : "Empirical study of wcutset sampling for Bayesian networks",
      "author" : [ "B. Bidyuk", "R. Dechter" ],
      "venue" : "In UAI,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2003
    }, {
      "title" : "Rao-Blackwellised likelihood weighting",
      "author" : [ "B. Bidyuk", "R. Dechter" ],
      "venue" : "Technical report, UCI, www.ics.uci.edu/ ̃bbidyuk/lwlc.html,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2005
    }, {
      "title" : "AIS-BN: An adaptive importance sampling algorithm for evidenctial reasoning in large baysian networks",
      "author" : [ "J. Cheng", "M. Druzdzel" ],
      "venue" : "J. of AI Research,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2000
    }, {
      "title" : "Bucket elimination: A unifying framework for reasoning",
      "author" : [ "R. Dechter" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1999
    }, {
      "title" : "Constraint Processing",
      "author" : [ "R. Dechter" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2003
    }, {
      "title" : "Rao-Blackwellised particle filtering for dynamic Bayesian networks",
      "author" : [ "A. Doucet", "N. de Freitas", "K. Murphy", "S. Russell" ],
      "venue" : "In Uncertainty in AI,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2000
    }, {
      "title" : "Particle filters for state estimation of jump markov linear systems",
      "author" : [ "A. Doucet", "N. Gordon", "V. Krishnamurthy" ],
      "venue" : "Technical report,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1999
    }, {
      "title" : "Monte Carlo: concepts, algorithms, and applications",
      "author" : [ "G.S. Fishman" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1995
    }, {
      "title" : "Weighing and integrating evidence for stochastic simulation in Bayesian networks",
      "author" : [ "R. Fung", "K.-C. Chang" ],
      "venue" : "In Uncertainty in AI,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1989
    }, {
      "title" : "Backward simulation in Bayesian networks. In Uncertainty in AI, pages 227–234",
      "author" : [ "R. Fung", "B. del Favero" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1994
    }, {
      "title" : "Towards normative expert systems: Part i. the pathfinder project",
      "author" : [ "D. Heckerman", "E. Horvitz", "B. Nathawani" ],
      "venue" : "Methods of Information in Medicine,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1992
    }, {
      "title" : "Blocking Gibbs sampling for linkage analysis in large pedigrees with many loops. Research Report R-96-2048",
      "author" : [ "C.S. Jensen", "A. Kong" ],
      "venue" : "Aalborg University,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1996
    }, {
      "title" : "Information Theory and Statistics",
      "author" : [ "S. Kullback" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1959
    }, {
      "title" : "Sequential importance sampling for nonparametric bayes models: The next generation",
      "author" : [ "S. MacEachern", "M. Clyde", "J. Liu" ],
      "venue" : "The Canadian Journal of Statistics,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1998
    }, {
      "title" : "Loopy belief propagation for approximate inference: An empirical study",
      "author" : [ "K.P. Murphy", "Y. Weiss", "M.I. Jordan" ],
      "venue" : "In Uncertainty in AI,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1999
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems",
      "author" : [ "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1988
    }, {
      "title" : "Knowledge engineering for large belief networks",
      "author" : [ "M. Pradhan", "G. Provan", "B. Middleton", "M. Henrion" ],
      "venue" : "In Uncertainty in AI,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1994
    }, {
      "title" : "Empirical evaluation of approximation algorithms for probabilistic decoding",
      "author" : [ "I. Rish", "K. Kask", "R. Dechter" ],
      "venue" : "In Uncertainty in AI,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1998
    }, {
      "title" : "Simulation approaches to general probabilistic inference on belief networks",
      "author" : [ "R.D. Shachter", "M.A. Peot" ],
      "venue" : "In Uncertainty in AI,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1989
    }, {
      "title" : "An importance sampling algorithm based on evidence prepropagation",
      "author" : [ "C. Yuan", "M. Druzdzel" ],
      "venue" : "In Uncertainty in AI,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "We defined previously an efficient parametrized Gibbs cutset sampling scheme, called w-cutset sampling [2, 3], where the complexity of generating a single sample is bounded exponentially by w.",
      "startOffset" : 103,
      "endOffset" : 109
    }, {
      "referenceID" : 2,
      "context" : "We defined previously an efficient parametrized Gibbs cutset sampling scheme, called w-cutset sampling [2, 3], where the complexity of generating a single sample is bounded exponentially by w.",
      "startOffset" : 103,
      "endOffset" : 109
    }, {
      "referenceID" : 10,
      "context" : "In this paper, we extend the cutset sampling principle to likelihood weighting (LW) [11, 21], which is a form of importance sampling [21], focusing on sampling from a loop-cutset.",
      "startOffset" : 84,
      "endOffset" : 92
    }, {
      "referenceID" : 20,
      "context" : "In this paper, we extend the cutset sampling principle to likelihood weighting (LW) [11, 21], which is a form of importance sampling [21], focusing on sampling from a loop-cutset.",
      "startOffset" : 84,
      "endOffset" : 92
    }, {
      "referenceID" : 20,
      "context" : "In this paper, we extend the cutset sampling principle to likelihood weighting (LW) [11, 21], which is a form of importance sampling [21], focusing on sampling from a loop-cutset.",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 8,
      "context" : "The advantages of cutset-based importance sampling, also known as Rao-Blackwellised importance sampling, were demonstrated previously in a few special cases [9, 8, 1].",
      "startOffset" : 157,
      "endOffset" : 166
    }, {
      "referenceID" : 7,
      "context" : "The advantages of cutset-based importance sampling, also known as Rao-Blackwellised importance sampling, were demonstrated previously in a few special cases [9, 8, 1].",
      "startOffset" : 157,
      "endOffset" : 166
    }, {
      "referenceID" : 0,
      "context" : "The advantages of cutset-based importance sampling, also known as Rao-Blackwellised importance sampling, were demonstrated previously in a few special cases [9, 8, 1].",
      "startOffset" : 157,
      "endOffset" : 166
    }, {
      "referenceID" : 17,
      "context" : "The queries over a singly-connected network can be processed in time linear in the size of the network [18].",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 10,
      "context" : "Likelihood weighting [11, 21] belongs to a family of importance sampling schemes that draw independent samples from a trial distribution Q(X).",
      "startOffset" : 21,
      "endOffset" : 29
    }, {
      "referenceID" : 20,
      "context" : "Likelihood weighting [11, 21] belongs to a family of importance sampling schemes that draw independent samples from a trial distribution Q(X).",
      "startOffset" : 21,
      "endOffset" : 29
    }, {
      "referenceID" : 9,
      "context" : "However, when the sample size is large enough, bias can be ignored [10].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 11,
      "context" : "Consequently, many importance sampling schemes focus on finding an improved sampling distribution by either changing the variable sampling order [12] or updating the sampling distribution based on previously generated samples [21, 5, 22].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 20,
      "context" : "Consequently, many importance sampling schemes focus on finding an improved sampling distribution by either changing the variable sampling order [12] or updating the sampling distribution based on previously generated samples [21, 5, 22].",
      "startOffset" : 226,
      "endOffset" : 237
    }, {
      "referenceID" : 4,
      "context" : "Consequently, many importance sampling schemes focus on finding an improved sampling distribution by either changing the variable sampling order [12] or updating the sampling distribution based on previously generated samples [21, 5, 22].",
      "startOffset" : 226,
      "endOffset" : 237
    }, {
      "referenceID" : 21,
      "context" : "Consequently, many importance sampling schemes focus on finding an improved sampling distribution by either changing the variable sampling order [12] or updating the sampling distribution based on previously generated samples [21, 5, 22].",
      "startOffset" : 226,
      "endOffset" : 237
    }, {
      "referenceID" : 8,
      "context" : "where P (C) = ∑ y P (Y,C) and Q(C) = ∑ y Q(Y,C) [9, 16] A proof can be found in [9] and [16].",
      "startOffset" : 48,
      "endOffset" : 55
    }, {
      "referenceID" : 15,
      "context" : "where P (C) = ∑ y P (Y,C) and Q(C) = ∑ y Q(Y,C) [9, 16] A proof can be found in [9] and [16].",
      "startOffset" : 48,
      "endOffset" : 55
    }, {
      "referenceID" : 8,
      "context" : "where P (C) = ∑ y P (Y,C) and Q(C) = ∑ y Q(Y,C) [9, 16] A proof can be found in [9] and [16].",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 15,
      "context" : "where P (C) = ∑ y P (Y,C) and Q(C) = ∑ y Q(Y,C) [9, 16] A proof can be found in [9] and [16].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 14,
      "context" : "We can show this for the KL-distance [15]:",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 3,
      "context" : "The details are available in [4].",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 1,
      "context" : "In networks with positive distributions, we compare likelihood weighting side by side with Gibbs sampling (Gibbs) and Gibbsbased loop-cutset sampling (LCS) [2].",
      "startOffset" : 156,
      "endOffset" : 159
    }, {
      "referenceID" : 17,
      "context" : "Belief propagation computes the exact posterior marginals in poly-trees [18].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 16,
      "context" : "IBP is fast and often produces good estimates [17, 20].",
      "startOffset" : 46,
      "endOffset" : 54
    }, {
      "referenceID" : 19,
      "context" : "IBP is fast and often produces good estimates [17, 20].",
      "startOffset" : 46,
      "endOffset" : 54
    }, {
      "referenceID" : 6,
      "context" : "MSE = ∑ Xi∈X\\E ∑ D(Xi) [P (xi|e)− P̂ (xi|e)] 2 ∑ Xi∈X\\E |D(Xi)| The exact posterior marginals P (Xi|e) are obtained by bucket-tree elimination [7, 6].",
      "startOffset" : 143,
      "endOffset" : 149
    }, {
      "referenceID" : 5,
      "context" : "MSE = ∑ Xi∈X\\E ∑ D(Xi) [P (xi|e)− P̂ (xi|e)] 2 ∑ Xi∈X\\E |D(Xi)| The exact posterior marginals P (Xi|e) are obtained by bucket-tree elimination [7, 6].",
      "startOffset" : 143,
      "endOffset" : 149
    }, {
      "referenceID" : 12,
      "context" : "Pathfinder is an expert system for identifying disorders from lymph node tissue sections [13].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 13,
      "context" : "Link is a model for the linkage between two genes [14].",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 18,
      "context" : "cpcs360b and cpcs422b are derived from the Computer-Based Patient Care Simulation system [19].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 4,
      "context" : "The PathFinder2 network was also used as a benchmark in the evaluation of AIS-BN algorithm [5], an adaptive importance sampling scheme.",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 3,
      "context" : "In particular, likelihood weighting outperforms Gibbs sampling in cpcs360b and cpcs422b without evidence [4].",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 8,
      "context" : ", when the distributions for the marginalised variables could be computed analytically using a Kalman filter [9, 8, 1] or when the marginalised variables in a factored HMM became conditionally independent (when sampled variables are observed) due to the numerical structure of the CPTs [8].",
      "startOffset" : 109,
      "endOffset" : 118
    }, {
      "referenceID" : 7,
      "context" : ", when the distributions for the marginalised variables could be computed analytically using a Kalman filter [9, 8, 1] or when the marginalised variables in a factored HMM became conditionally independent (when sampled variables are observed) due to the numerical structure of the CPTs [8].",
      "startOffset" : 109,
      "endOffset" : 118
    }, {
      "referenceID" : 0,
      "context" : ", when the distributions for the marginalised variables could be computed analytically using a Kalman filter [9, 8, 1] or when the marginalised variables in a factored HMM became conditionally independent (when sampled variables are observed) due to the numerical structure of the CPTs [8].",
      "startOffset" : 109,
      "endOffset" : 118
    }, {
      "referenceID" : 7,
      "context" : ", when the distributions for the marginalised variables could be computed analytically using a Kalman filter [9, 8, 1] or when the marginalised variables in a factored HMM became conditionally independent (when sampled variables are observed) due to the numerical structure of the CPTs [8].",
      "startOffset" : 286,
      "endOffset" : 289
    } ],
    "year" : 2006,
    "abstractText" : "The paper extends the principle of cutset sampling over Bayesian networks, presented previously for Gibbs sampling, to likelihood weighting (LW). Cutset sampling is motivated by the Rao-Blackwell theorem which implies that sampling over a subset of variables requires fewer samples for convergence due to the reduction in sampling variance. The scheme exploits the network structure in selecting cutsets that allow efficient computation of the sampling distributions. In particular, as we show empirically, likelihood weighting over a loop-cutset (abbreviated LWLC), is time-wise cost-effective. We also provide an effective way for caching the probabilities of the generated samples which improves the performance of the overall scheme. We compare LWLC against regular liklihood-weighting and against Gibbsbased cutset sampling.",
    "creator" : "dvips(k) 5.94b Copyright 2004 Radical Eye Software"
  }
}