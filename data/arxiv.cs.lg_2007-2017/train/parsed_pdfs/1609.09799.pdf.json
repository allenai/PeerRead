{
  "name" : "1609.09799.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Optimal spectral transportation with application to music transcription",
    "authors" : [ "Rémi Flamary" ],
    "emails" : [ "remi.flamary@unice.fr", "cedric.fevotte@irit.fr", "courty@univ-ubs.fr", "valentin.emiya@lif.univ-mrs.fr" ],
    "sections" : [ {
      "heading" : "1 Context",
      "text" : "Many of nowadays spectral unmixing techniques rely on non-negative matrix decompositions. This concerns for example hyperspectral remote sensing (with applications in Earth observation, astronomy, chemistry, etc.) or audio signal processing. The spectral sample vn (the spectrum of light observed at a given pixel n, or the audio spectrum in a given time frame n) is decomposed onto a dictionary W of elementary spectral templates, characteristic of pure materials or sound objects, such that vn ≈Whn. The composition of sample n can be inferred from the non-negative expansion coefficients hn. This paradigm has led to state-of-the-art results for various tasks (recognition, classification, denoising, separation) in the aforementioned areas, and in particular in music transcription, the central application of this paper.\nIn state-of-the-art music transcription systems, the spectrogram V (with columns vn) of a musical signal is decomposed onto a dictionary of pure notes (in so-called multi-pitch estimation) or chords. V typically consists of (power-)magnitude values of a regular short-time Fourier transform (Smaragdis and Brown, 2003). It may also consists of an audio-specific spectral transform such as the Melfrequency transform, like in (Vincent et al., 2010), or the Q-constant based transform, like in (Oudre et al., 2011). The success of the transcription system depends of course on the adequacy of the time-frequency transform & the dictionary to represent the data V. In particular, the matrix W must\n29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n60 9.\n09 79\n9v 2\n[ st\nat .M\nL ]\n1 0\nbe able to accurately represent a diversity of real notes. It may be trained with individual notes using annotated data (Boulanger-Lewandowski et al., 2012), have a parametric form (Rigaud et al., 2013) or be learnt from the data itself using a harmonic subspace constraint (Vincent et al., 2010).\nOne important challenge of such methods lies in their ability to cope with the variability of real notes. A simplistic dictionary model will assume that one note characterised by fundamental frequency ν0 (e.g., ν0 = 440 Hz for note A4) will be represented by a spectral template with non-zero coefficients placed at ν0 and at its multiples (the harmonic frequencies). In reality, many instruments, such as the piano, produce musical notes with either slight frequency misalignments (so-called inharmonicities) with respect to the theoretical values of the fundamental and harmonic frequencies, or amplitude variations at the harmonic frequencies with respect to recording conditions or played instrument (variations of timbre). Handling these variabilities by increasing the dictionary with more templates is typically unrealistic and adaptive dictionaries have been considered in (Vincent et al., 2010; Rigaud et al., 2013). In these papers, the spectral shape of the columns of W is adjusted to the data at hand, using specific time-invariant semi-parametric models. However, the note realisations may vary in time, something which is not handled by these approaches. This work presents a new spectral unmixing method based on optimal transportation (OT) that is fully flexible and remedies the latter difficulties. Note that Typke et al. (2004) have previously applied OT to notated music (e.g., score sheets) for search-by-query in databases while we address here music transcription from audio spectral data."
    }, {
      "heading" : "2 A relevant baseline: PLCA",
      "text" : "Before presenting our contributions, we start by introducing the PLCA method of Smaragdis et al. (2006) which is heavily used in audio signal processing. It is based on the Probabilistic Latent Semantic Analysis (PLSA) of Hofmann (2001) (used in text retrieval) and is a particular form of nonnegative matrix factorisation (NMF). Simplifying a bit, in PLCA the columns of V are normalised to sum to one. Each vector vn is then treated as a discrete probability distribution of “frequency quanta” and is approximated as V ≈WH. The matrices W and H are of size M ×K and K ×N , respectively, and their columns are constrained to sum to one. As a result, the columns of the approximate V̂ = WH sum to one as well and each distribution vector vn is as such approximated by the counterpart distribution v̂n in V̂. Under the assumption that W is known, the approximation is found by solving the optimisation problem defined by\nmin H≥0\nDKL(V|WH) s.t ∀n, ‖hn‖1 = 1, (1)\nwhere DKL(v|v̂) = ∑\ni vi log(vi/v̂i) is the KL divergence between discrete distributions, and by extension DKL(V|V̂) = ∑ nDKL(vn|v̂n).\nAn important characteristic of the KL divergence is its separability with respect to the entries of its arguments. It operates a frequency-wise comparison in the sense that, at every frame n, the spectral coefficient vin at frequency i is compared to its counterpart v̂in, and the results of the comparisons are summed over i. In particular, a small displacement in the frequency support of one observation may disproportionally harm the divergence value. For example, if vn is a pure note with fundamental frequency ν0, a small inharmonicity that shifts energy from ν0 to an adjacent frequency bin will unreasonably increase the divergence value, when vn is compared with a purely harmonic spectral template with fundamental frequency ν0. As explained in Section 1 such local displacements of frequency energy are very common when dealing with real data. A measure of fit invariant to small perturbations of the frequency support would be desirable in such a setting, and this is precisely what OT can bring."
    }, {
      "heading" : "3 Elements of optimal transportation",
      "text" : "Given a discrete probability distribution v (a non-negative real-valued column vector of dimension M and summing to one) and a target distribution v̂ (with same properties), OT computes a transportation\nmatrix T belonging to the set Θ def= {T ∈ RM×M+ |∀i, j = 1, . . . , N, ∑M j=1 tij = vi, ∑M i=1 tij = v̂j}. T establishes a bi-partite graph connecting the two distributions. In simple words, an amount (or, in typical OT parlance, a “mass”) of every coefficient of vector v is transported to an entry of v̂. The sum of transported amounts to the jth entry of v̂ must equal v̂j . The value of tij is the amount\ntransported from the ith entry of v to the jth entry of v̂. In our particular setting, the vector v is a distribution of spectral energies v1, . . . , vM at sampling frequencies f1, . . . , fM .\nWithout additional constraints, the problem of finding a non-negative matrix T ∈ Θ has an infinite number of solutions. As such, OT takes into account the cost of transporting an amount from the ith entry of v to the jth entry of v̂, denoted cij (a non-negative real-valued number). Endorsed with this cost function, OT involves solving the optimisation problem defined by\nmin T\nJ(T|v, v̂,C) = ∑\nij cijtij s.t T ∈ Θ, (2)\nwhere C is the non-negative square matrix of size M with elements cij . Eq. (2) defines a convex linear program. The value of the function J(T|v, v̂,C) at its minimum is denoted DC(v|v̂). When C is a symmetric matrix such that cij = ‖fi−fj‖pp, where we recall that fi and fj are the frequencies in Hertz indexed by i and j, DC(v|v̂) defines a metric (i.e., a symmetric divergence that satisfies the triangle inequality) coined Wasserstein distance or earth mover’s distance (Rubner et al., 1998; Villani, 2009). In other cases, in particular when the matrix C is not even symmetric like in the next section, DC(v|v̂) is not a metric in general, but is still a valid measure of fit. For generality, we will refer to it as the “OT divergence”.\nBy construction, the OT divergence can explicitly embed a form of invariance to displacements of support, as defined by the transportation cost matrix C. For example, in the spectral decomposition setting, the matrix with entries of the form cij = (fi − fj)2 will increasingly penalise frequency displacements as the distance between frequency bins increases. This precisely remedies the limitation of the separable KL divergence presented in Section 2. As such, the next section addresses variants of spectral unmixing based on the Wasserstein distance."
    }, {
      "heading" : "4 Optimal spectral transportation (OST)",
      "text" : "Unmixing with OT. In light of the above discussion, a direct solution to the sensibility of PLCA to small frequency displacements consists in replacing the KL divergence with the OT divergence. This amounts to solving the optimisation problem given by\nmin H≥0\nDC(V|WH) s.t ∀n, ‖hn‖1 = 1, (3)\nwhere DC(V|V̂) = ∑\nnDC(vn|v̂n), W is fixed and populated with pure note spectra and C penalises large displacements of frequency support. This approach is a particular case of NMF with the Wasserstein distance, which has been considered in a face recognition setting by Sandler and Lindenbaum (2011), with subsequent developments by Zen et al. (2014) and Rolet et al. (2016). This approach is relevant to our spectral unmixing scenario but as will be discussed in Section 5 is on the downside computationally intensive. It also requires the columns of W to be set to realistic note templates, which is still constraining. The next two sections describes a computationally more friendly approach which additionally removes the difficulty of choosing W appropriately.\nHarmonic-invariant transportation cost. In the approach above, the harmonic modelling is conveyed by the dictionary W (consisting of comb-like pure note spectra) and the invariance to small frequency displacements is introduced via the matrix C. In this section we propose to model both harmonicity and local invariance through the transportation cost matrix C. Loosely speaking, we want to define a class of equivalence between musical spectra, that takes into account their inherent harmonic nature. As such, we essentially impose that a harmonic frequency (i.e., a close multiple of its fundamental) can be considered equivalent to its fundamental, the only target of multi-pitch estimation. As such, we assume that a mass at one frequency can be transported to a divisor frequency with no cost. In other words, a mass at frequency fi can be transported with no cost to fi/2, fi/3, fi/4, and so on until sampling resolution. One possible cost matrix that embeds this property is\ncij = min q=1,...,qmax\n(fi − qfj)2 + δq 6=1, (4)\nwhere qmax is the ceiling of fi/fj and is a small value. The term δq 6=1 favours the discrimination of octaves. Indeed, it penalises the transportation of a note of fundamental frequency 2ν0 or ν0/2 to the spectral template with fundamental frequency ν0, which would be costless without this additive term. Let us denote by Ch the transportation cost matrix defined by Eq. (4). Fig. 1 compares Ch\nto the more standard quadratic cost C2 defined by cij = (fi − fj)2. With the quadratic cost, only local displacements are permissible. In contrast, the harmonic-invariant cost additionally permits larger displacements to divisor frequencies, improving robustness to variations of timbre besides to inharmonicities.\nDictionary of Dirac vectors. Having designed an OT divergence that encodes inherent properties of musical signals, we still need to choose a dictionary W that will encode the fundamental frequencies of the notes to identify. Typically, these will consist of the physical frequencies of the 12 notes of the chromatic scale (from note A to note G, including half-tones), over several octaves. As mentioned in Section 1, one possible strategy is to populate W with spectral note templates. However, as also discussed, the performance of the resulting unmixing method will be capped by the representativeness of the chosen set of templates.\nA most welcome consequence of using the OT divergence built on the harmonic-insensitive cost matrix Ch is that we may use for W a mere set of Dirac vectors placed at the fundamental frequencies ν1, . . . , νK of the notes to identify and separate. Indeed, under the proposed setting, a real note spectra (composed of one fundamental and multiple harmonic frequencies) can be transported with no cost to its fundamental. Similarly, a spectral sample composed of several notes can be transported to mixture of Dirac vectors placed at their fundamental frequencies. This simply eliminates the problem of choosing a representative dictionary! This very appealing property is illustrated in Fig. 2. Furthermore, the particularly simple structure of the dictionary leads to a very efficient unmixing algorithm, as explained in the next section. In the following, the unmixing method consisting of the combined use of the harmonic-invariant cost matrix Ch and of the dictionary of Dirac vectors will be coined “optimal spectral transportation” (OST).\nAt this level, we assume for simplicity that the set of K fundamental frequencies {ν1, . . . , νK} is contained in the set of sampled frequencies {f1, . . . , fM}. This means that wk (the kth column of W) is zero everywhere except at some entry i such that fi = νk where wik = 1. This is typically not the case in practice, where the sampled frequencies are fixed by the sampling rate, of the form fi = 0.5(i/T )fs, and where the fundamental frequencies νk are fixed by music theory. Our approach can actually deal with such a discrepancy and this will be explained later in Section 5."
    }, {
      "heading" : "5 Optimisation",
      "text" : "OT unmixing with linear programming. We start by describing optimisation for the state-of-theart OT unmixing problem described by Eq. (3) and proposed by Sandler and Lindenbaum (2011). First, since the objective function is separable with respect to samples, the optimisation problem decouples with respect to the activation columns hn. Dropping the sample index n and combining Eqs. (2) and (3), optimisation thus reduces to solving for every sample a problem of the form\nmin h≥0,T≥0\n〈T,C〉 = ∑\nij tijcij s.t. T1M = v, T>1M = Wh, (5)\nwhere 1M is a vector of dimension M containing only ones and 〈·, ·〉 is the Frobenius inner product. Vectorising the variables T and h into a single vector of dimension M2 + K, problem (5) can be turned into a canonical linear program. Because of the large dimension of the variable (typically in the order of 105), resolution can however be very demanding, as will be shown in experiments.\nOptimisation for OST. We now assume that W is a set of Dirac vectors as explained at the end of Section 4. We also assume that K < M , which is the usual scenario. Indeed, K is typically in the order of a few tens, while M is in the order of a few hundreds. In such a setting v̂ = Wh contains by design at most K non-zero coefficients, located at the entries such that fi = νk. We denote this set of frequency indices by S . Hence, for j /∈ S , we have v̂j = 0 and thus ∑ i tij = 0, by the second constraint of Eq. (5). Additionally, by the non-negativity of T this also implies that T has only K non-zero columns, indexed by j ∈ S. Denoting by T̃ this subset of columns, and by C̃ the corresponding subset of columns of C, problem (5) reduces to\nmin h≥0,T̃≥0\n〈T̃, C̃〉 s.t. T̃1K = v, T̃>1M = h. (6)\nThis is an optimisation problem of significantly reduced dimension (M + 1)K. Even more appealing, the problem has a simple closed-form solution. Indeed, the variable h has a virtual role in problem (6). It only appears in the second constraint, which de facto becomes a free constraint. Thus problem (6) can be solved with respect to T̃ regardless of h, and h is then simply obtained by summing the columns of T̃> at the solution. Now, the problem\nmin T̃≥0 〈T̃, C̃〉 s.t. T̃1K = v (7)\ndecouples with respect to the rows t̃i of T̃, and becomes, ∀i = 1, . . . ,M ,\nmin t̃i≥0\n∑ k t̃ik c̃ik s.t. ∑ k t̃ik = vi. (8)\nThe solution is simply given by t̃ik?i = vi for k ? i = arg mink{c̃ik}, and t̃ik = 0 for k 6= k?i . Introducing the labelling matrix L which is everywhere zero except for indices (i, k?i ) where it is equal to 1, the solution to OST is trivially given by ĥ = L>v. Thus, under the specific assumption that W is a set of Dirac vectors, the challenging problem (5) has been reduced to an effortless assignment problem to solve for T and a simple sum to solve for h. Note that the algorithm is independent of the particular structure of C. In the end, the complexity per frame of OST reduces to O(M), which starkly contrasts with the complexity of PLCA, in the order O(KM) per iteration. In Section 4, we assumed for simplicity that the set of fundamental frequencies {νk}k was contained in the set of sampled frequencies {fi}i. As a matter of fact, this assumption can be trivially lifted in the proposed setting of OST. Indeed, we may construct the cost matrix C̃ (of dimensions M ×K) by replacing the target frequencies fj in Eq. (4) by the theoretical fundamental frequencies νk. Namely, we may simply set the coefficients of C̃ to be c̃ik = minq(fi − qνk)2 + δq 6=1, in the implementation. Then, the matrix T̃ indicates how each sample v is transported to the Dirac vectors placed at fundamental frequencies {νk}k, without the need for the actual Dirac vectors themselves, which elegantly solves the frequency sampling problem.\nOST with entropic regularisation (OSTe). The procedure described above leads to a winnertakes-all transportation of all of vi to its cost-minimum target entry k?i . We found it useful in\npractice to relax this hard assignment and distribute energies more evenly by using the entropic regularisation of Cuturi (2013). It consists of penalising the fit 〈T̃, C̃〉 in Eq. (6) with an additional term Ωe(T̃) = ∑ ik t̃ik log(t̃ik), weighted by the hyper-parameter λe. The negentropic term Ωe(T̃) promotes the transportation of vi to several entries, leading to a smoother estimate of T̃. As explained in the supplementary material, one can show that the negentropy-regularised problem is a Bregman projection (Benamou et al., 2015) and has again a closed-form solution ĥ = L>e v where Le is the M ×K matrix with coefficients lik = exp(−c̃ik/λe)/ ∑ p exp(−c̃ip/λe). Limiting cases λe = 0 and λe =∞ return the unregularised OST estimate and the maximum-entropy estimate hk = 1/K, respectively. Because Le becomes a full matrix, the complexity per frame of OSTe becomesO(KM).\nOST with group regularisation (OSTg). We have explained above that the transportation matrix T has a strong group structure in the sense that it contains by construction M −K null columns, and that only the subset T̃ needs to be considered. Because a small number of the K possible notes will be played at every time frame, the matrix T̃ will additionally have a significant number of null columns. This heavily suggests using group-sparse regularisation in the estimation of T̃.\nAs such, we also consider problem (6) penalised by the additional term Ωg(T̃) = ∑\nk\n√ ‖t̃k‖1\nwhich promotes group-sparsity at column level (Huang et al., 2009). Unlike OST or OSTe, OSTg does not offer a closed-form solution. Following Courty et al. (2014), a majorisation-minimisation procedure based on the local linearisation of Ωg(T̃) can be employed and the details are given in the supplementary material. The resulting algorithm consists in iteratively applying unregularised OST, as of Eq. (6), with the iteration-dependent transportation cost matrix C̃(iter) = C̃ + R̃(iter), where R̃(iter) is the M ×K matrix with coefficients r̃(iter)ik = 1 2‖t̃ (iter) k ‖ − 12 1 . Note that the proposed group-regularisation of T̃ corresponds to a sparse regularisation of h. This is because hk = ‖t̃k‖1 and thus, Ωg(T̃) = ∑ k √ hk. Finally, note that OSTe and OSTg can be implemented simultaneously, leading to OSTe+g, by considering the optimisation of the doubly-penalised objective function 〈T̃, C̃〉+ λe Ωe(T̃) + λg Ωg(T̃), addressed in the supplementary material."
    }, {
      "heading" : "6 Experiments",
      "text" : "Toy experiments with simulated data. In this section we illustrate the robustness, the flexibility and the efficiency of OST on two simulated examples. The top plots of Fig. 3 display a synthetic dictionary of 8 harmonic spectral templates, referred to as the “harmonic dictionary”. They have been generated as Gaussian kernels placed at a fundamental frequency and its multiples, and using exponential dampening of the amplitudes. As everywhere in the paper, the spectral templates are normalised to sum to one. Note that the 8th template is the upper octave of the first one. We compare the unmixing performance of five methods in two different scenarios. The five methods are as follows. PLCA is the method described in Section 2, where the dictionary W is the harmonic dictionary. Convergence is stopped when the relative difference of the objective function between two iterations falls below 10−5 or the number of iterations (per frame) exceeds 1000. OTh is the unmixing method with the OT divergence, as in the first paragraph of Section 4, using the harmonic transportation cost matrix Ch and the harmonic dictionary. OST is like OTh, but using a dictionary of Dirac vectors (placed at the 8 fundamental frequencies characterising the harmonic dictionary). OSTe, OSTg and OSTe+g are the regularised variants of OST, described at the end of Section 4. The iterative procedure in the group-regularised variants is run for 10 iterations (per frame).\nIn the first experimental scenario, reported in Fig. 3 (a), the data sample is generated by mixing the 1st and 4th elements of the harmonic dictionary, but introducing a small shift of the true fundamental frequencies (with the shift being propagated to the harmonic frequencies). This mimics the effect of possible inharmonicities or of an ill-tuned instrument. The middle plot of Fig. 3 (a), displays the generated sample, together with the “theoretical sample”, i.e., without the frequencies shift. This shows how a slight shift of the fundamental frequencies can greatly impact the overall spectral distribution. The bottom plot displays the true activation vector and the estimates returned by the five methods. The table reports the value of the (arbitrary) error measure ‖ĥ− htrue‖1 together with the run time (on an average desktop PC using a MATLAB implementation) for every method. The results show that group-regularised variants of OST lead to best performance with very light computational\nburden, and without using the true harmonic dictionary. In the second experimental scenario, reported in Fig. 3 (b), the data sample is generated by mixing the 1st and 6th elements of the harmonic dictionary, with the right fundamental and harmonic frequencies, but where the spectral amplitudes at the latters do not follow the exponential dampening of the template dictionary (variation of timbre). Here again the group-regularised variants of OST outperforms the state-of-the-art approaches, both in accuracy and run time.\nTranscription of real musical data. We consider in this section the transcription of a selection of real piano recordings, obtained from the MAPS dataset (Emiya et al., 2010). The data comes with a ground-truth binary “piano-roll” which indicates the active notes at every time. The note fundamental frequencies are given in MIDI, a standard musical integer-valued frequency scale that matches the keys of a piano, with 12 half-tones (i.e., piano keys) per octave. The spectrogram of each recording is computed with a Hann window of size 93-ms and 50% overlap (fs = 44.1Hz). The columns (time frames) are then normalised to produce V. Each recording is decomposed with PLCA, OST and OSTe, with K = 60 notes (5 octaves). Half of the recording is used for validation of the hyper-parameters and the other half is used as test data. For PLCA, we validated 4 and 3 values of the width and amplitude dampening of the Gaussian kernels used to synthesise the dictionary. For OST, we set = q 0 in Eq. (4), which was found to satisfactorily improve the discrimination of octaves increasingly with frequency, and validated 5 orders of magnitude of 0. For OSTe, we additionally validated 4 orders of magnitude of λe. Each of the three methods returns an estimate of H. The estimate is turned into a 0/1 piano-roll by only retaining the support of its Pn maximum entries at every frame n, where Pn is the ground-truth number of notes played in frame n. The estimated piano-roll is then numerically compared to its ground truth using the F-measure, a global recognition measure which accounts both for precision and recall and which is bounded between 0 (critically wrong) and 1 (perfect recognition). Our evaluation framework follows standard practice in music transcription evaluation, see for example (Daniel et al., 2008). As detailed in the supplementary material, it can be shown that OSTg and OSTe+g do not change the location of the maximum entries in the estimates of H returned by OST and OSTe, respectively, but only their amplitude. As such, they lead to the same F-measures than OST and OSTe, and we did not include them in the experiments of this section.\nWe first illustrate the complexity of real-data spectra in Fig. 4, where the amplitudes of the first six partials (the components corresponding to the harmonic frequencies) of a single piano note are represented along time. Depending on the partial order q, the amplitude evolves with asynchronous beats and with various slopes. This behaviour is characteristic of piano sounds in which each note comes from the vibration of up to three coupled strings. As a consequence, the spectral envelope of such notes cannot be well modelled by a fixed amplitude pattern. Fig. 4 shows that, thanks to its flexibility, OSTe can perfectly recover the true fundamental frequency (MIDI 50) while PLCA\nis prone to octave errors (confusions between MIDI 50 and MIDI 62). Then, Table 1 reports the F-measures returned by the three competing approaches on seven 15-s extracts of pieces from Chopin, Beethoven, Mussorgski and Mozart. For each of the three methods, we have also included a variant that incorporates a flat component in the dictionary that can account for noise or non-harmonic components. In PLCA, this merely consists in adding a constant vector wf(K+1) = 1/M to W. In OST or OSTe this consists in adding a constant column to C̃, whose amplitude has also been validated over 3 orders of magnitude. OST performs comparably or slightly inferiorly to PLCA but with an impressive gain in computational time (∼3000× speedup). Best overall performance is obtained with OSTe+noise with an average ∼10% performance gain over PLCA and ∼750× speedup. A Python implementation of OST and real-time demonstrator are available at https://github. com/rflamary/OST"
    }, {
      "heading" : "7 Conclusions",
      "text" : "In this paper we have introduced a new paradigm for spectral dictionary-based music transcription. As compared to state-of-the-art approaches, we have proposed a holistic measure of fit which is robust to local and harmonically-related displacements of frequency energies. It is based on a new form of transportation cost matrix that takes into account the inherent harmonic structure of musical signals. The proposed transportation cost matrix allows in turn to use a simplistic dictionary composed of Dirac vectors placed at the target fundamental frequencies, eliminating the problem of choosing a meaningful dictionary. Experimental results have shown the robustness and accuracy of the proposed approach, which strikingly does not come at the price of computational efficiency. Instead, the particular structure of the dictionary allows for a simple algorithm that is way faster than state-of-the-art NMF-like approaches. The proposed approach offers new foundations, with promising results and room for improvement. In particular, we believe exciting avenues of research concern the learning of Ch from examples and extensions to other areas such as in remote sensing, using application-specific forms of C.\nAcknowledgments. This work is supported in part by the European Research Council (ERC) under the European Union’s Horizon 2020 research & innovation programme (project FACTORY) and by the French ANR under the JCJC programme (project MAD). Many thanks to Antony Schutz for generating & providing some of the musical data."
    } ],
    "references" : [ {
      "title" : "Iterative Bregman projections for regularized transportation problems",
      "author" : [ "J.-D. Benamou", "G. Carlier", "M. Cuturi", "L. Nenna", "G. Peyré" ],
      "venue" : "SIAM Journal on Scientific Computing,",
      "citeRegEx" : "Benamou et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Benamou et al\\.",
      "year" : 2015
    }, {
      "title" : "Discriminative non-negative matrix factorization for multiple pitch estimation",
      "author" : [ "N. Boulanger-Lewandowski", "Y. Bengio", "P. Vincent" ],
      "venue" : "In Proc. International Society for Music Information Retrieval Conference (ISMIR),",
      "citeRegEx" : "Boulanger.Lewandowski et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Boulanger.Lewandowski et al\\.",
      "year" : 2012
    }, {
      "title" : "Domain adaptation with regularized optimal transport",
      "author" : [ "N. Courty", "R. Flamary", "D. Tuia" ],
      "venue" : "In Proc. European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD),",
      "citeRegEx" : "Courty et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Courty et al\\.",
      "year" : 2014
    }, {
      "title" : "Sinkhorn distances: Lightspeed computation of optimal transportation",
      "author" : [ "M. Cuturi" ],
      "venue" : "In Advances on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Cuturi.,? \\Q2013\\E",
      "shortCiteRegEx" : "Cuturi.",
      "year" : 2013
    }, {
      "title" : "Perceptually-based evaluation of the errors usually made when automatically transcribing music",
      "author" : [ "A. Daniel", "V. Emiya", "B. David" ],
      "venue" : "In Proc. International Society for Music Information Retrieval Conference (ISMIR),",
      "citeRegEx" : "Daniel et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Daniel et al\\.",
      "year" : 2008
    }, {
      "title" : "Multipitch estimation of piano sounds using a new probabilistic spectral smoothness principle",
      "author" : [ "V. Emiya", "R. Badeau", "B. David" ],
      "venue" : "IEEE Trans. Audio, Speech, and Language Processing,",
      "citeRegEx" : "Emiya et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Emiya et al\\.",
      "year" : 2010
    }, {
      "title" : "Unsupervised learning by probabilistic latent semantic analysis",
      "author" : [ "T. Hofmann" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Hofmann.,? \\Q2001\\E",
      "shortCiteRegEx" : "Hofmann.",
      "year" : 2001
    }, {
      "title" : "A group bridge approach for variable selection",
      "author" : [ "J. Huang", "S. Ma", "H. Xie", "C.-H. Zhang" ],
      "venue" : null,
      "citeRegEx" : "Huang et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2009
    }, {
      "title" : "Chord recognition by fitting rescaled chroma vectors to chord templates",
      "author" : [ "L. Oudre", "Y. Grenier", "C. Févotte" ],
      "venue" : "IEEE Trans. Audio, Speech and Language Processing,",
      "citeRegEx" : "Oudre et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Oudre et al\\.",
      "year" : 2011
    }, {
      "title" : "A parametric model and estimation techniques for the inharmonicity and tuning of the piano",
      "author" : [ "F. Rigaud", "B. David", "L. Daudet" ],
      "venue" : "The Journal of the Acoustical Society of America,",
      "citeRegEx" : "Rigaud et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Rigaud et al\\.",
      "year" : 2013
    }, {
      "title" : "Fast Dictionary Learning with a Smoothed Wasserstein Loss",
      "author" : [ "A. Rolet", "M. Cuturi", "G. Peyré" ],
      "venue" : "Proceedings of the 19th International Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "Rolet et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Rolet et al\\.",
      "year" : 2016
    }, {
      "title" : "A metric for distributions with applications to image databases",
      "author" : [ "Y. Rubner", "C. Tomasi", "L. Guibas" ],
      "venue" : "In Proc. International Conference in Computer Vision (ICCV),",
      "citeRegEx" : "Rubner et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Rubner et al\\.",
      "year" : 1998
    }, {
      "title" : "Nonnegative matrix factorization with earth mover’s distance metric for image analysis",
      "author" : [ "R. Sandler", "M. Lindenbaum" ],
      "venue" : "IEEE Trans. Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "Sandler and Lindenbaum.,? \\Q2011\\E",
      "shortCiteRegEx" : "Sandler and Lindenbaum.",
      "year" : 2011
    }, {
      "title" : "Non-negative matrix factorization for polyphonic music transcription",
      "author" : [ "P. Smaragdis", "J.C. Brown" ],
      "venue" : "In Proc. IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA),",
      "citeRegEx" : "Smaragdis and Brown.,? \\Q2003\\E",
      "shortCiteRegEx" : "Smaragdis and Brown.",
      "year" : 2003
    }, {
      "title" : "A probabilistic latent variable model for acoustic modeling",
      "author" : [ "P. Smaragdis", "B. Raj", "M.V. Shashanka" ],
      "venue" : "In Proc. NIPS workshop on Advances in models for acoustic processing,",
      "citeRegEx" : "Smaragdis et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Smaragdis et al\\.",
      "year" : 2006
    }, {
      "title" : "Searching notated polyphonic music using transportation distances",
      "author" : [ "R. Typke", "R.C. Veltkamp", "F. Wiering" ],
      "venue" : "In Proc. ACM International Conference on Multimedia,",
      "citeRegEx" : "Typke et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Typke et al\\.",
      "year" : 2004
    }, {
      "title" : "Optimal transport: old and new",
      "author" : [ "C. Villani" ],
      "venue" : null,
      "citeRegEx" : "Villani.,? \\Q2009\\E",
      "shortCiteRegEx" : "Villani.",
      "year" : 2009
    }, {
      "title" : "Adaptive harmonic spectral decomposition for multiple pitch estimation",
      "author" : [ "E. Vincent", "N. Bertin", "R. Badeau" ],
      "venue" : "IEEE Trans. Audio, Speech and Language Processing,",
      "citeRegEx" : "Vincent et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Vincent et al\\.",
      "year" : 2010
    }, {
      "title" : "Simultaneous ground metric learning and matrix factorization with earth mover’s distance",
      "author" : [ "G. Zen", "E. Ricci", "N. Sebe" ],
      "venue" : "In Proc. International Conference on Pattern Recognition (ICPR),",
      "citeRegEx" : "Zen et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zen et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "V typically consists of (power-)magnitude values of a regular short-time Fourier transform (Smaragdis and Brown, 2003).",
      "startOffset" : 91,
      "endOffset" : 118
    }, {
      "referenceID" : 17,
      "context" : "It may also consists of an audio-specific spectral transform such as the Melfrequency transform, like in (Vincent et al., 2010), or the Q-constant based transform, like in (Oudre et al.",
      "startOffset" : 105,
      "endOffset" : 127
    }, {
      "referenceID" : 8,
      "context" : ", 2010), or the Q-constant based transform, like in (Oudre et al., 2011).",
      "startOffset" : 52,
      "endOffset" : 72
    }, {
      "referenceID" : 1,
      "context" : "It may be trained with individual notes using annotated data (Boulanger-Lewandowski et al., 2012), have a parametric form (Rigaud et al.",
      "startOffset" : 61,
      "endOffset" : 97
    }, {
      "referenceID" : 9,
      "context" : ", 2012), have a parametric form (Rigaud et al., 2013) or be learnt from the data itself using a harmonic subspace constraint (Vincent et al.",
      "startOffset" : 32,
      "endOffset" : 53
    }, {
      "referenceID" : 17,
      "context" : ", 2013) or be learnt from the data itself using a harmonic subspace constraint (Vincent et al., 2010).",
      "startOffset" : 79,
      "endOffset" : 101
    }, {
      "referenceID" : 17,
      "context" : "Handling these variabilities by increasing the dictionary with more templates is typically unrealistic and adaptive dictionaries have been considered in (Vincent et al., 2010; Rigaud et al., 2013).",
      "startOffset" : 153,
      "endOffset" : 196
    }, {
      "referenceID" : 9,
      "context" : "Handling these variabilities by increasing the dictionary with more templates is typically unrealistic and adaptive dictionaries have been considered in (Vincent et al., 2010; Rigaud et al., 2013).",
      "startOffset" : 153,
      "endOffset" : 196
    }, {
      "referenceID" : 1,
      "context" : "It may be trained with individual notes using annotated data (Boulanger-Lewandowski et al., 2012), have a parametric form (Rigaud et al., 2013) or be learnt from the data itself using a harmonic subspace constraint (Vincent et al., 2010). One important challenge of such methods lies in their ability to cope with the variability of real notes. A simplistic dictionary model will assume that one note characterised by fundamental frequency ν0 (e.g., ν0 = 440 Hz for note A4) will be represented by a spectral template with non-zero coefficients placed at ν0 and at its multiples (the harmonic frequencies). In reality, many instruments, such as the piano, produce musical notes with either slight frequency misalignments (so-called inharmonicities) with respect to the theoretical values of the fundamental and harmonic frequencies, or amplitude variations at the harmonic frequencies with respect to recording conditions or played instrument (variations of timbre). Handling these variabilities by increasing the dictionary with more templates is typically unrealistic and adaptive dictionaries have been considered in (Vincent et al., 2010; Rigaud et al., 2013). In these papers, the spectral shape of the columns of W is adjusted to the data at hand, using specific time-invariant semi-parametric models. However, the note realisations may vary in time, something which is not handled by these approaches. This work presents a new spectral unmixing method based on optimal transportation (OT) that is fully flexible and remedies the latter difficulties. Note that Typke et al. (2004) have previously applied OT to notated music (e.",
      "startOffset" : 62,
      "endOffset" : 1587
    }, {
      "referenceID" : 13,
      "context" : "Before presenting our contributions, we start by introducing the PLCA method of Smaragdis et al. (2006) which is heavily used in audio signal processing.",
      "startOffset" : 80,
      "endOffset" : 104
    }, {
      "referenceID" : 6,
      "context" : "It is based on the Probabilistic Latent Semantic Analysis (PLSA) of Hofmann (2001) (used in text retrieval) and is a particular form of nonnegative matrix factorisation (NMF).",
      "startOffset" : 68,
      "endOffset" : 83
    }, {
      "referenceID" : 11,
      "context" : ", a symmetric divergence that satisfies the triangle inequality) coined Wasserstein distance or earth mover’s distance (Rubner et al., 1998; Villani, 2009).",
      "startOffset" : 119,
      "endOffset" : 155
    }, {
      "referenceID" : 16,
      "context" : ", a symmetric divergence that satisfies the triangle inequality) coined Wasserstein distance or earth mover’s distance (Rubner et al., 1998; Villani, 2009).",
      "startOffset" : 119,
      "endOffset" : 155
    }, {
      "referenceID" : 11,
      "context" : "This approach is a particular case of NMF with the Wasserstein distance, which has been considered in a face recognition setting by Sandler and Lindenbaum (2011), with subsequent developments by Zen et al.",
      "startOffset" : 132,
      "endOffset" : 162
    }, {
      "referenceID" : 11,
      "context" : "This approach is a particular case of NMF with the Wasserstein distance, which has been considered in a face recognition setting by Sandler and Lindenbaum (2011), with subsequent developments by Zen et al. (2014) and Rolet et al.",
      "startOffset" : 132,
      "endOffset" : 213
    }, {
      "referenceID" : 10,
      "context" : "(2014) and Rolet et al. (2016). This approach is relevant to our spectral unmixing scenario but as will be discussed in Section 5 is on the downside computationally intensive.",
      "startOffset" : 11,
      "endOffset" : 31
    }, {
      "referenceID" : 12,
      "context" : "(3) and proposed by Sandler and Lindenbaum (2011). First, since the objective function is separable with respect to samples, the optimisation problem decouples with respect to the activation columns hn.",
      "startOffset" : 20,
      "endOffset" : 50
    }, {
      "referenceID" : 0,
      "context" : "As explained in the supplementary material, one can show that the negentropy-regularised problem is a Bregman projection (Benamou et al., 2015) and has again a closed-form solution ĥ = Le v where Le is the M ×K matrix with coefficients lik = exp(−c̃ik/λe)/ ∑ p exp(−c̃ip/λe).",
      "startOffset" : 121,
      "endOffset" : 143
    }, {
      "referenceID" : 2,
      "context" : "practice to relax this hard assignment and distribute energies more evenly by using the entropic regularisation of Cuturi (2013). It consists of penalising the fit 〈T̃, C̃〉 in Eq.",
      "startOffset" : 115,
      "endOffset" : 129
    }, {
      "referenceID" : 7,
      "context" : "k √ ‖t̃k‖1 which promotes group-sparsity at column level (Huang et al., 2009).",
      "startOffset" : 57,
      "endOffset" : 77
    }, {
      "referenceID" : 2,
      "context" : "Following Courty et al. (2014), a majorisation-minimisation procedure based on the local linearisation of Ωg(T̃) can be employed and the details are given in the supplementary material.",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 5,
      "context" : "We consider in this section the transcription of a selection of real piano recordings, obtained from the MAPS dataset (Emiya et al., 2010).",
      "startOffset" : 118,
      "endOffset" : 138
    }, {
      "referenceID" : 4,
      "context" : "Our evaluation framework follows standard practice in music transcription evaluation, see for example (Daniel et al., 2008).",
      "startOffset" : 102,
      "endOffset" : 123
    } ],
    "year" : 2016,
    "abstractText" : "Many spectral unmixing methods rely on the non-negative decomposition of spectral data onto a dictionary of spectral templates. In particular, state-of-the-art music transcription systems decompose the spectrogram of the input signal onto a dictionary of representative note spectra. The typical measures of fit used to quantify the adequacy of the decomposition compare the data and template entries frequency-wise. As such, small displacements of energy from a frequency bin to another as well as variations of timbre can disproportionally harm the fit. We address these issues by means of optimal transportation and propose a new measure of fit that treats the frequency distributions of energy holistically as opposed to frequency-wise. Building on the harmonic nature of sound, the new measure is invariant to shifts of energy to harmonically-related frequencies, as well as to small and local displacements of energy. Equipped with this new measure of fit, the dictionary of note templates can be considerably simplified to a set of Dirac vectors located at the target fundamental frequencies (musical pitch values). This in turns gives ground to a very fast and simple decomposition algorithm that achieves state-of-the-art performance on real musical data.",
    "creator" : "LaTeX with hyperref package"
  }
}