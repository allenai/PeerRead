{
  "name" : "1305.1169.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Multi-Objective AI Planning: Comparing Aggregation and Pareto Approaches",
    "authors" : [ "M. R. Khouadjia", "M. Schoenauer", "V. Vidal", "J. Dréo" ],
    "emails" : [ "marc.schoenauer}@inria.fr,", "Vincent.Vidal@onera.fr", "pierre.saveant}@thalesgroup.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 5.\n11 69\nv1 [\ncs .A\nI] 6"
    }, {
      "heading" : "1 Introduction",
      "text" : "Most, if not all, classical AI planning solvers are single-objective. Given a planning domain (a set of predicates that describe the state of the system, and a set of actions with their pre-requisites and effects), and an instance of this domain (a set of objects on which the predicates are instantiated into boolean atoms, an initial state and a goal state), classical planners try to find, among the set of all feasible plans (sequences of actions such that, when applied to the initial state, the goal state becomes true), the one with the minimal number of actions (STRIP planning), or with the smallest cost (actions with costs) or with the smallest makespan (temporal planning, where actions have durations and can be applied in parallel). A detailed introduction to (single-objective) AI planning can be found in [1]. It is clear, however, that most planning problems are in fact multi-objective, as the optimal solution in real-world problems often involve some trade-off between makespan and cost [2]. A few trials have been made to\n⋆⋆ This work is being partially funded by the French National Research Agency under the research contract DESCARWIN (ANR-09-COSI-002)\nturn some classical planners into multi-objective optimizers, either using some twist in PDDL 2.04 to account for both makespan and cost [3,4,5], or using the new hooks for several objectives offered by PDDL 3.0 [6]. However, all these approaches are based on a linear aggregation of the different objectives, and were not pursued, as witnessed by the new “net-benefit” IPC track, dedicated to aggregated multiple objectives, that took place in 2006 [7] and 2008 [8], . . . but was canceled in 2011 due to a lack of entries.\nIn the framework of Evolutionary Algorithms (EAs), Pareto multi-objective optimization has received a lot of attention [9], and any single-objective EA can “easily” be turned into a multi-objective EA, by modifying the selection step (and possible adding some archiving mechanism). Unfortunately, there exist very few evolutionary AI planners. Directly evolving plans, as in [10], obviously does not scale up, and was never extended to multi-objective setting. Hence, as far as we are aware of, the state-of-the-art in evolutionary AI planning is the previous work of some of the authors, Divide-and-Evolve (DaE). DaE evolves variables length sequences of states, that start with the problem initial state and end at the problem goal state. DaE relies on a classical embedded planner to sequentially reach each state of the sequence from the previous one. The concatenation of all plans given by the embedded planner is a solution plan of the original problem. DaE can thus solve all types of planning problems that the embedded planner can solve. Proof-of-concept for DaE was obtained with DaECPT [11], where the embedded planner was CPT, an exact planner [12] – and already included some small multi-objective experiments. Since then, the DaE paradigm has evolved, and YAHSP a sub-optimal lookahead strategy planning system [13] is now used as the embedded planner [14], andDaEYAHSP has reached state-of-the-art results in all planning domains [15], winning the temporal deterministic satisficing track at the last IPC in 20115.\nThe very preliminary work in [11] regarding multi-objective optimization has also been recently revisited with DaEYAHSP. The lack of existing benchmark suite for multi-objective planning led us to extend the small toy problem from [11] into a tunable benchmark domain, on which different multi-objectivization of DaEYAHSP (MO-DaEYAHSP) were compared [16]. But because the only other approach in AI Planning is the aggregation of the objectives, there is a need to compare the multi-objective approach for DaEYAHSP with the single-objective approach based on the linear aggregation of the objectives: this is the purpose of the present work. Section 2 will briefly present planning problems andDaEYAHSP in the single-objective setting. In Section 3, the multi-objective context will be introduced. The multi-objective benchmark suite will be presented, and the multi-objectivization of DaEYAHSP will be detailed: because YAHSP is a singleobjective planner6, but can be asked to optimize either the makespan or the\n4 Planning Domain Definition Language, a dedicated language for the description of planning problems, set up for the International Planning Competitions (IPC). 5 See http://www.plg.inf.uc3m.es/ipc2011-deterministic 6 Note that it seems difficult, if at all opssible, to adapt it directly to multi-objective optimization, as it uses very different strategies for the makespan and the cost.\ncost, specific strategies had to be designed regarding how it is called within MODaEYAHSP. Section 4 describes the experimental settings, detailing in particular the implementation of the aggregation approach forDaEYAHSP and the intensive parameter tuning that was performed for all competing algorithms using the offline problem-independent tuner ParamILS [17]. The results will be presented and discussed in Section 5, and as usual, conclusion and hints about on-going and further work will be given in Section 6."
    }, {
      "heading" : "2 Single-Objective Background",
      "text" : "AI Planning Problems: A planning domain D is defined by a set of object types, a set of predicates, and a set of possible actions. An instance is defined by a set of objects of the domain types, an initial state, and a goal state. A predicate that is instantiated with objects is called an atom, and takes a boolean value. For a given instance, a state is defined by assigning values to all possible atoms. An action is defined by a set of pre-conditions (atoms) and a set of effects (changing some atom values): the action can be executed only if all pre-conditions are true in the current state, and after an action has been executed, the state is modified: the system enters a new state. The goal is to find a plan (sequence of actions) such that it leads from the initial state to the goal state, and minimizes either the number or costs of actions, or the makespan in the case of temporal planning where actions have durations and can be run in parallel.\nA simple temporal planning problem in the domain of logistics (inspired by the well-known Zeno problem of IPC series) is given in Figure 1, and will be the basis of the benchmark used in this work: the problem involves cities, passengers, and planes (object types). Passengers can be transported from one city to another (action fly), following the links on the figure. One plane can only carry one passenger at a time from one city to another, and the flight duration\n(number on the link) is the same whether or not the plane carries a passenger (this defines the domain of the problem). In the simplest non-trivial instance of such domain, there are 3 passengers and 2 planes. In the initial state, all passengers and planes are in city 0, and in the goal state, all passengers must be in city 4. In the default case labeled “Lin.” in the table right (forget about the costs for now), the not-so-obvious makespan-optimal solution has a total makespan of 8 and is left as a teaser for the reader.\nDivide-and-Evolve: Let PD(I,G) denote the planning problem defined on domain D with initial state I and goal state G. In order to solve PD(I,G), the basic idea of DaEX is to find a sequence of states S1, . . . , Sn, and to use some embedded planner X to solve the series of planning problems PD(Sk, Sk+1), for k ∈ [0, n] (with the convention that S0 = I and Sn+1 = G). The generation and optimization of the sequence of states (Si)i∈[1,n] is driven by an evolutionary algorithm. The fitness of a sequence is computed using the embedded planner X , that is called in turn on each of the sub-problems PD(Sk, Sk+1). The concatenation of the corresponding plans (possibly compressed to take into account possible parallelism in the case of temporal planning) is a solution of the initial problem. In case one sub-problem cannot be solved by the embedded solver, the individual is said unfeasible and its fitness is highly penalized in order to ensure that unfeasible individuals are always selected after feasible ones. A thorough description of DaEX can be found in [15]. The rest of this section will briefly recall the evolutionary parts of DaEX.\nAn individual in DaEX is a variable-length list of partial states of the given domain (similar to the goal state), and a partial state is a variable-length list of atoms (instantiated predicates). The initialization procedure is based on a heuristic estimation, for each atom, of the earliest time from which it can become true [18]. Furthermore, most existing planners (and this is true for CPT and YAHSP, that have been used within DaE) start by computing some partial mutual exclusion between possible atoms: this information is also used to reduce the search space in DaEX, whenever possible. An individual in DaEX is hence a variable-length time-consistent sequence of partial states, and each partial state is a variable-length list of atoms that are not pairwise mutually exclusive.\nCrossover and mutation operators are applied with respective user-defined probabilities pCross and pMut. They are defined on the DaEX representation in a straightforward manner - though constrained by the heuristic chronology and the partial mutex relation between atoms. One-point crossover is adapted to variable-length representation: both crossover points are independently chosen, uniformly in both parents. Only one offspring is kept, the one that respects the approximate chronological constraint on the successive states. Four different mutation operators are included, and operate either at the individual level, by adding (addState) or removing (delState) a state, or at the state level by adding or modifying (addChangeAtom) or removing (delAtom) some atoms in a uniformly chose state. The choice among these operators is made according to user-defined relative weights (named w-mutationname - see Table 1)."
    }, {
      "heading" : "3 Multi-Objective Background",
      "text" : ""
    }, {
      "heading" : "3.1 Pareto-based Multi-Objective Divide-and-Evolve",
      "text" : "Two modifications of DaEYAHSP are needed to turn it into an EMOA: use some multi-objective selection engine in lieu of the single-objective tournament selection that is used in the single-objective context; and compute the value of both objectives (makespan and cost) for both individuals. The former modification is straightforward, and several alternatives have been experimented within [16]. The conclusion is that the indicator-based selection using the hypervolume difference indicator [19] performs best – and only this one will be used in the following, denoted here MO-DaEYAHSP. As explained above, the computation of the fitness is done by YAHSP– and YAHSP, like all known planners to-date, is a single-objective planner. It is nevertheless possible, since PDDL 3.0 [6], to specify other quantities of interest that are to be computed throughout the execution of the final plan, without interfering with the search. Within MO-DaEYAHSP, two strategies are then possible for YAHSP: it can be asked to optimize either the makespan or the cost, and to simply compute the cost or the makespan when executing the solution plan (for feasible individuals).\nThe choice between both strategies is governed by user-defined weights, named respectively W-makespan and W-cost (see table 1). For each individual, the actual strategy is randomly chosen according to those weights, and applied to all subproblems of the individual. Note that those weights are tuned using ParamILS (see Section 4), and it turned out that the optimal values for MODaEYAHSP have always been equal weights: something that was to be expected, as no objective should be preferred to the other."
    }, {
      "heading" : "3.2 Aggregation-based Multi-Objective Divide-and-Evolve",
      "text" : "Aggregation is certainly the easiest and most common way to handle multiobjective problems with a single-objective optimization algorithm: a series of single-objective optimization problems are tackled in turn, the fitness of each of these problems is defined by a linear combination of the objectives. In the case of makespan and cost, both to be minimized, each linear combination can be defined by a single parameter α in [0, 1]. In the following, Fα will denote α ∗makespan + (1− α) ∗ cost, and DaEYAHSP run optimizing Fα will be called the α-run. One “run” of the aggregation method thus amounts to running several α-runs, and returns the set of non-dominated individuals among the union of all final populations7. Note that different alpha-runs might have different optimal values for their parameters: a complete parameter tuning run of ParamILSmust be performed for each α-run to ensure a fair comparison with other well-tuned approaches.\nThe choice of the number of values to choose for the different α depends on the available resources. But the choice of the actual values aims at exploring\n7 Some adaptive method has been proposed [20], where parameter α is adapted on-line, spanning all values within a single run: this is left for further work.\nthe objective space as uniformly as possible, and some issues might arise if both objectives are not scaled similarly. We hence propose here to use some evenly spaced values for α (see Section 4), but only after both objectives have been scaled into [0,1]. However, for such scaling to be possible, some bounds must be known for each objective. When they are not known, these bounds can be approximated from single-objective runs on each of the objectives in turn."
    }, {
      "heading" : "3.3 Multi-Objective Benchmarks:",
      "text" : "The reader will have by now solved the little puzzle set in Section 2, and found the solution with makespan 8, that manages to leave no plane idle (detailed solution in [16]). In order to turn this problem into a multi-objective one, costs (or risks) are added to the fly actions that land in one of the central cities, leading to two types of problem: InMultiZenoCost, the second objective is the total costs, that is accumulated every time a plane lands in a central city; In MultiZenoRisk, the second objective is the maximal risk encountered during the complete execution of a plan; both are to be minimized. The complexity of the instances can be increased by adding more passengers: instances with 3, 6 and 9 passengers will be used here. Finally, by tuning the values of the flight durations and the costs/risks, different shapes of the Pareto front can be obtained: Figure 1 summarizes three possible instances for the MultiZeno domain, and the corresponding Pareto fronts for the 6-passengers case are displayed in Figure 2."
    }, {
      "heading" : "4 Experimental Settings",
      "text" : "Parameter Tuning: It is now widely acknowledged that the large number of parameters of most EAs, even though it is a source of flexibility, is also a weakness, in that a poor parameter setting can ruin the performances of the most promising algorithm. Whereas no generic approach exists for on-line control, there are today many available methods for off-line parameter tuning that should be used within any evolutionary experiment, in spite of their huge computational cost.\nIn this work, unless otherwise stated, the user-defined parameters of both MO-DaEYAHSP andDaEYAHSP shown in Table 1 have been tuned anew for each instance, using the ParamILS framework [17]. ParamILS performs an Iterated\nLocal Search in the space of possible parameter configurations, evaluating each configuration by running the algorithm to be optimized with this configuration on the given instance.\nStopping Criteria: Due to the variable number of calls to YAHSP the number of function evaluation is not representative of the CPU effort of runs of DaEYAHSP. Hence the stopping criterion of all DaEYAHSP run was set to a given wall-clock time (300, 600 and 1800 seconds for MultiZeno3, 6 and 9 respectively (on an Intel(R) Xeon(R) @ 2.67GHz or equivalent). That of MO-DaEYAHSPwas set accordingly: for the sake of a fair comparison, because one run of the aggregated approach requires n runs of the single-objective version of DaEYAHSP, MO-DaEYAHSPwas run for n times the time of each of the DaEYAHSP runs. In the following, n will vary from 3 to 8 (see Section 5). The stopping criterion for ParamILS was likewise set to a fixed wall-clock time: 48h (resp. 72h) for MultiZeno3 and 6 (resp. MultiZeno9), corresponding to 576, 288, and 144 parameter configuration evaluations for MultiZeno3, 6 and 9 respectively.\nPerformance Metrics and Results Visualization: The quality measure used by ParamILS to optimize the parameters of both MO-DaEYAHSP and each of the α-runs of DaEYAHSP is the unary hypervolume IH− [19] of the set of nondominated points output by the algorithm with respect to the complete true Pareto front (only instances where the true Pareto front is fully known have been experimented with). The lower the better (a value of 0 indicates that the exact Pareto front has been reached). All reported differences in hypervolume have been tested using Wilcoxon signed rank test at 95% confidence level, unless otherwise stated.\nHowever, and because the true front is made of a few scattered points (at most 17 forMultiZeno9 in this paper), it is also possible to visually monitor the empirical Cumulative Distribution Function of the probability to discover each point, as well as the whole front. This allows some deeper comparison between algorithms even when none has found the whole front. Such hitting plots will be used in the following, together with more classical plots of hypervolume vs time. Finally, because hitting plots only tell if a given point was reached and do not\nprovide any information regarding how far from the other points the different runs ended, more details on the approximated Pareto fronts will be given by visualizing the merged final populations of all runs of given settings.\nImplementation: For all experiments, 11 independent runs have been performed, implemented within the ParadisEO-MOEO framework8. All performance assessment procedures (hypervolume calculations, statistical tests), have been achieved using the PISA performance assessment tool9."
    }, {
      "heading" : "5 Experimental Results",
      "text" : "This section will compare the Pareto-basedMO-DaEYAHSP and the aggregation approach Agg-DaEYAHSP on MultiZeno3, 6 and 9. Unless otherwise stated, the default domain definition leading to a linear Pareto front (see Figure 1 and 2-left) will be used, and one Agg-DaEYAHSP run will be made of 7 different α-runs, with α taking the values 0, 0.1, 0.3, 0.5, 0.7, 0.9, and 1.\nThe MultiZeno3 Problem proved to be too easy: both MO-DaEYAHSP and AggDaEYAHSP find the complete Pareto fronts, and the hitting plots reach 100% in less than 80s (resp. 90s) for the Cost (resp. Risk) version of the instance (not shown here). MO-DaEYAHSP is slightly slower (resp. faster) than AggDaEYAHSP in the Cost (resp. Risk) instance, but no significant difference is to be reported. Only instances -6 and -9 will be looked at in the following.\nThe Risk Objective: On these instances, however, the Risk objective proved to be almost too difficult to be of interest here, even though there are only 3 points on the Pareto Front, whatever the number of passengers: as can be seen on Figure 6, no algorithm could identify the complete Pareto front for the MultiZeno9 instance (line 4); for MultiZeno6 (line 2), MO-DaEYAHSP could reliably identify the whole front (in 9 runs out of 11), while only a single run of Agg-DaEYAHSP could identify the middle point (40,20). MO-DaEYAHSP is hence a clear winner here - however, too little information is brought by the risk value, as one single stop in a risky station will completely hide the possibly low-risk remaining of the plan. Further work will aim at designing a smoother fitness for such situations.\nThe rest of the paper will hence concentrate on the Cost versions of MultiZeno6 and 9 (simply denoted MultiZeno{6,9}), where significant differences between both approaches can be highlighted.\nResults on the Default Instance: From the plots of the evolution of the average hypervolumes (Figure 3), MO-DaEYAHSP is the winner for MultiZeno6, and Agg-DaEYAHSP is the winner for MultiZeno9. Taking a closer look at the hitting plots (Figure 6), we can see for MultiZeno6 (line 1) that all runs of\n8 http://paradiseo.gforge.inria.fr/ 9 http://www.tik.ee.ethz.ch/pisa/\nFig. 3: Evolution of hypervolume for DaEYAHSP (green squares) and AggDaEYAHSP (blue triangles) for MultiZeno6 (left) and MultiZeno9 (right).\n10\n15\n20\n25\n30\n35\n40\n20 30 40 50 60 70 80 90\nC os\nt\nMakespan\nAggregation Exact Pareto front\n15\n20\n25\n30\n35\n40\n45\n50\n55\n60\n30 40 50 60 70 80 90 100 110 120\nC os\nt\nMakespan\nibeahyper Exact Pareto front\n15\n20\n25\n30\n35\n40\n45\n50\n55\n60\n20 40 60 80 100 120 140 160\nC os\nt\nMakespan\nAggregation Exact Pareto front\nAgg-DaEYAHSP on MultiZeno6\nMO-DaEYAHSP on MultiZeno9\nAgg-DaEYAHSP on MultiZeno9\nFig. 4: Pareto fronts approximations (union of all final populations).\nMO-DaEYAHSP reach the complete Pareto front in around 2500s, while only 9 runs out of 11 do reach it. On the other hand, for MultiZeno9, and though the figures of line 3 are more difficult to read because they contain the CDF for 17 points, slightly more points seem to be reached by Agg-DaEYAHSP than by MO-DaEYAHSP. Looking now at the approximations of the Pareto fronts (Figure 4), the fronts returned byAgg-DaEYAHSP forMultiZeno6 show a large dispersion away from the true front, whereas the same figure for MO-DaEYAHSP (not shown) only contains the true front. Regarding MultiZeno9, even though it reaches less points from the true front, MO-DaEYAHSP demonstrates a much more robust behavior than Agg-DaEYAHSP, for which the approximate fronts are, again, quite dispersed, sometimes far from the true front.\nResults on other MultiZeno6 instances: Further experiments have been conducted on different variants of MultiZeno6 instance, described in Figure 1. The corresponding hitting plots can be seen on Figure 5. As in the Linear default case, MO-DaEYAHSP is a clear winner – and this is confirmed by the plots of the approximate Pareto fronts (not shown), for which Agg-DaEYAHSP again shows a much larger dispersion away from the true front than MO-DaEYAHSP.\nAll results presented until now have been obtained by first optimizing the parameters of all algorithms with ParamILS. Interestingly, when using the parameters optimized by ParamILS for the Linear instance on these other instances, the results are only slightly worse: this observation will motivate further work dedicated to the generalization of the parameter tuning across instances.\nFig. 5: Hitting plots for MO-DaEYAHSP (left) and Agg-DaEYAHSP (right), for instances 2, 3, and 4 of MultiZeno6 from Figure 1 (from top to bottom)."
    }, {
      "heading" : "6 Discussion and Conclusion",
      "text" : "The experiments presented in this paper have somehow demonstrated the greater efficiency of the Pareto-based approach to multi-objective AI Planning MODaEYAHSP compared to the more traditional approach by aggregation of the objectives Agg-DaEYAHSP. The case is clear on MultiZeno6, and on the different instances that have been experimented with, where MO-DaEYAHSP robustly finds the whole Pareto front (except for the Convex instance), whereas Agg-DaEYAHSP performs much worse in all aspects. This is also true on the MultiZeno9 instance, in spite of the better hypervolume indicator: indeed, a few more points on the Pareto front are found a little more often, but the global picture remains a poor approximation of the Pareto front. Other experiments on more instances are needed to confirm these first results, and on-going work is concerned with solving instances generated from IPC benchmarks by merging the cost and the temporal domains when the same instances exist in both.\nRegarding the computational cost, one Agg-DaEYAHSP run requires several single-objective runs – and as many parameter tuning procedures. We have chosen here to use 7 different values for α, and it was clear from results not shown here that taking away a few of these resulted in a decrease of quality of the results. The computational cost of the parameter tuning could be reduced, too: first, a complete tuning anew for each instance is unrealistic, and was only done here for the sake of a fair comparison between both approaches; second, even on a single instance, it should be possible to tune all parameters (except those of YAHSP strategy) for all α-runs together. Finally, one of the most promising directions for future research is the on-line tuning of YAHSP strategy, e.g., using a self-adaptive approach, where the strategies are attached to the individual.\nFig. 6: Hitting plots for MO-DaEYAHSP (left) and Agg-DaEYAHSP (right), for instances (from top to bottom) MultiZeno6Cost, MultiZeno6Risk, MultiZeno9Cost, and MultiZeno9Risk. The lower line on each plots is the experimental CDF for the probability to reach the whole Pareto front."
    }, {
      "heading" : "Preface",
      "text" : "This textbook is intended for use by students of physics, physical chemistry, and theoretical chemistry. The reader is presumed to have a basic knowledge of atomic and quantum physics at the level provided, for example, by the first few chapters in our book The Physics of Atoms and Quanta. The student of physics will find here material which should be included in the basic education of every physicist. This book should furthermore allow students to acquire an appreciation of the breadth and variety within the field of molecular physics and its future as a fascinating area of research.\nFor the student of chemistry, the concepts introduced in this book will provide a theoretical framework for that entire field of study. With the help of these concepts, it is at least in principle possible to reduce the enormous body of empirical chemical knowledge to a few basic principles: those of quantum mechanics. In addition, modern physical methods whose fundamentals are introduced here are becoming increasingly important in chemistry and now represent indispensable tools for the chemist. As examples, we might mention the structural analysis of complex organic compounds, spectroscopic investigation of very rapid reaction processes or, as a practical application, the remote detection of pollutants in the air.\nApril 1995 Walter Olthoff Program Chair\nECOOP’95"
    }, {
      "heading" : "Organization",
      "text" : "ECOOP’95 is organized by the department of Computer Science, Univeristy of Århus and AITO (association Internationa pour les Technologie Object) in cooperation with ACM/SIGPLAN."
    }, {
      "heading" : "Executive Commitee",
      "text" : "Conference Chair: Ole Lehrmann Madsen (Århus University, DK) Program Chair: Walter Olthoff (DFKI GmbH, Germany) Organizing Chair: Jørgen Lindskov Knudsen (Århus University, DK) Tutorials: Birger Møller-Pedersen (Norwegian Computing Center, Norway) Workshops: Eric Jul (University of Kopenhagen, Denmark) Panels: Boris Magnusson (Lund University, Sweden) Exhibition: Elmer Sandvad (Århus University, DK) Demonstrations: Kurt Nørdmark (Århus University, DK)"
    }, {
      "heading" : "Program Commitee",
      "text" : "Conference Chair: Ole Lehrmann Madsen (Århus University, DK) Program Chair: Walter Olthoff (DFKI GmbH, Germany) Organizing Chair: Jørgen Lindskov Knudsen (Århus University, DK) Tutorials: Birger Møller-Pedersen (Norwegian Computing Center, Norway) Workshops: Eric Jul (University of Kopenhagen, Denmark) Panels: Boris Magnusson (Lund University, Sweden) Exhibition: Elmer Sandvad (Århus University, DK) Demonstrations: Kurt Nørdmark (Århus University, DK)"
    }, {
      "heading" : "Referees",
      "text" : "V. Andreev Bärwolff E. Barrelet H.P. Beck G. Bernardi E. Binder P.C. Bosetti\nBraunschweig F.W. Büsser T. Carli A.B. Clegg G. Cozzika S. Dagoret Del Buono\nP. Dingus H. Duhm J. Ebert S. Eichenberger R.J. Ellison Feltesse W. Flauger\nIII\nA. Fomenko G. Franke J. Garvey M. Gennis L. Goerlich P. Goritchev H. Greif E.M. Hanlon R. Haydar R.C.W. Henderso P. Hill H. Hufnagel A. Jacholkowska Johannsen S. Kasarian I.R. Kenyon C. Kleinwort T. Köhler S.D. Kolya P. Kostka\nU. Krüger J. Kurzhöfer M.P.J. Landon A. Lebedev Ch. Ley F. Linsel H. Lohmand Martin S. Masson K. Meier C.A. Meyer S. Mikocki J.V. Morris B. Naroska Nguyen U. Obrock G.D. Patel Ch. Pichler S. Prell F. Raupach\nV. Riech P. Robmann N. Sahlmann P. Schleper Schöning B. Schwab A. Semenov G. Siegmon J.R. Smith M. Steenbock U. Straumann C. Thiebaux P. Van Esch from Yerevan Ph L.R. West G.-G. Winter T.P. Yiou M. Zimmer\nSponsoring Institutions\nBernauer-Budiman Inc., Reading, Mass. The Hofmann-International Company, San Louis Obispo, Cal. Kramer Industries, Heidelberg, Germany"
    }, {
      "heading" : "Table of Contents",
      "text" : ""
    }, {
      "heading" : "Hamiltonian Mechanics",
      "text" : "Hamiltonian Mechanics unter besonderer Berücksichtigung der höhreren Lehranstalten . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\nIvar Ekeland, Roger Temam, Jeffrey Dean, David Grove, Craig Chambers, Kim B. Bruce, and Elisa Bertino\nHamiltonian Mechanics2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Ivar Ekeland and Roger Temam\nAuthor Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\nSubject Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\nHamiltonian Mechanics unter besonderer"
    }, {
      "heading" : "Berücksichtigung der höhreren Lehranstalten",
      "text" : "Ivar Ekeland1, Roger Temam2 Jeffrey Dean, David Grove, Craig Chambers, Kim B. Bruce, and Elsa Bertino\n1 Princeton University, Princeton NJ 08544, USA, I.Ekeland@princeton.edu,\nWWW home page: http://users/~iekeland/web/welcome.html 2 Université de Paris-Sud, Laboratoire d’Analyse Numérique, Bâtiment 425,\nF-91405 Orsay Cedex, France\nAbstract. The abstract should summarize the contents of the paper using at least 70 and at most 150 words. It will be set in 9-point font size and be inset 1.0 cm from the right and left margins. There will be two blank lines before and after the Abstract. . . .\nKeywords: computational geometry, graph theory, Hamilton cycles"
    }, {
      "heading" : "1 Fixed-Period Problems: The Sublinear Case",
      "text" : "With this chapter, the preliminaries are over, and we begin the search for periodic solutions to Hamiltonian systems. All this will be done in the convex case; that is, we shall study the boundary-value problem\nẋ = JH ′(t, x)\nx(0) = x(T )\nwith H(t, ·) a convex function of x, going to +∞ when ‖x‖ → ∞."
    }, {
      "heading" : "1.1 Autonomous Systems",
      "text" : "In this section, we will consider the case when the Hamiltonian H(x) is autonomous. For the sake of simplicity, we shall also assume that it is C1.\nWe shall first consider the question of nontriviality, within the general framework of (A∞, B∞)-subquadratic Hamiltonians. In the second subsection, we shall look into the special case when H is (0, b∞)-subquadratic, and we shall try to derive additional information.\nThe General Case: Nontriviality. We assume that H is (A∞, B∞)-subquadratic at infinity, for some constant symmetric matrices A∞ and B∞, with B∞ −A∞ positive definite. Set:\nγ : = smallest eigenvalue of B∞ −A∞ (1) λ : = largest negative eigenvalue of J d\ndt +A∞ . (2)\n2 Theorem 1 tells us that if λ+ γ < 0, the boundary-value problem:\nẋ = JH ′(x) x(0) = x(T )\n(3)\nhas at least one solution x, which is found by minimizing the dual action functional:\nψ(u) =\n∫ T\no\n[ 1\n2\n( Λ−1o u, u ) +N∗(−u) ] dt (4)\non the range of Λ, which is a subspace R(Λ)2L with finite codimension. Here\nN(x) := H(x)− 1\n2 (A∞x, x) (5)\nis a convex function, and\nN(x) ≤ 1\n2 ((B∞ −A∞)x, x) + c ∀x . (6)\nProposition 1. Assume H ′(0) = 0 and H(0) = 0. Set:\nδ := lim inf x→0\n2N(x) ‖x‖ −2 . (7)\nIf γ < −λ < δ, the solution u is non-zero:\nx(t) 6= 0 ∀t . (8)\nProof. Condition (7) means that, for every δ′ > δ, there is some ε > 0 such that\n‖x‖ ≤ ε⇒ N(x) ≤ δ′\n2 ‖x‖\n2 . (9)\nIt is an exercise in convex analysis, into which we shall not go, to show that this implies that there is an η > 0 such that\nf ‖x‖ ≤ η ⇒ N∗(y) ≤ 1\n2δ′ ‖y‖\n2 . (10)\nFig. 1. This is the caption of the figure displaying a white eagle and a white horse on a snow field\n3 Since u1 is a smooth function, we will have ‖hu1‖∞ ≤ η for h small enough, and inequality (10) will hold, yielding thereby:\nψ(hu1) ≤ h2\n2\n1 λ ‖u1‖ 2 2 + h2 2 1 δ′ ‖u1‖ 2 . (11)\nIf we choose δ′ close enough to δ, the quantity ( 1\nλ + 1 δ′\n) will be negative, and\nwe end up with ψ(hu1) < 0 for h 6= 0 small . (12)\nOn the other hand, we check directly that ψ(0) = 0. This shows that 0 cannot be a minimizer of ψ, not even a local one. So u 6= 0 and u 6= Λ−1o (0) = 0. ⊓⊔\nCorollary 1. Assume H is C2 and (a∞, b∞)-subquadratic at infinity. Let ξ1, . . . , ξN be the equilibria, that is, the solutions of H\n′(ξ) = 0. Denote by ωk the smallest eigenvalue of H ′′ (ξk), and set:\nω := Min {ω1, . . . , ωk} . (13)\nIf: T\n2π b∞ < −E\n[ − T\n2π a∞\n] < T\n2π ω (14)\nthen minimization of ψ yields a non-constant T -periodic solution x.\nWe recall once more that by the integer part E[α] of α ∈ IR, we mean the a ∈ ZZ such that a < α ≤ a + 1. For instance, if we take a∞ = 0, Corollary 2 tells us that x exists and is non-constant provided that:\nT 2π b∞ < 1 < T 2π (15)\nor\nT ∈\n( 2π\nω , 2π\nb∞\n) . (16)\nProof. The spectrum of Λ is 2πT ZZ + a∞. The largest negative eigenvalue λ is given by 2πT ko + a∞, where\n2π T ko + a∞ < 0 ≤ 2π T (ko + 1) + a∞ . (17)\nHence:\nko = E\n[ − T\n2π a∞\n] . (18)\nThe condition γ < −λ < δ now becomes:\nb∞ − a∞ < − 2π\nT ko − a∞ < ω − a∞ (19)\nwhich is precisely condition (14). ⊓⊔\n4 Lemma 1. Assume that H is C2 on IR2n\\{0} and that H ′′(x) is non-degenerate for any x 6= 0. Then any local minimizer x̃ of ψ has minimal period T .\nProof. We know that x̃, or x̃ + ξ for some constant ξ ∈ IR2n, is a T -periodic solution of the Hamiltonian system:\nẋ = JH ′(x) . (20)\nThere is no loss of generality in taking ξ = 0. So ψ(x) ≥ ψ(x̃) for all x̃ in some neighbourhood of x in W 1,2 ( IR/TZZ; IR2n ) .\nBut this index is precisely the index iT (x̃) of the T -periodic solution x̃ over the interval (0, T ), as defined in Sect. 2.6. So\niT (x̃) = 0 . (21)\nNow if x̃ has a lower period, T/k say, we would have, by Corollary 31:\niT (x̃) = ikT/k(x̃) ≥ kiT/k(x̃) + k − 1 ≥ k − 1 ≥ 1 . (22)\nThis would contradict (21), and thus cannot happen. ⊓⊔\nNotes and Comments. The results in this section are a refined version of [1]; the minimality result of Proposition 14 was the first of its kind.\nTo understand the nontriviality conditions, such as the one in formula (16), one may think of a one-parameter family xT , T ∈ ( 2πω−1, 2πb−1\n∞\n) of periodic\nsolutions, xT (0) = xT (T ), with xT going away to infinity when T → 2πω −1, which is the period of the linearized system at 0.\nTable 1. This is the example table taken out of The TEXbook, p. 246\nYear World population\n8000 B.C. 5,000,000 50 A.D. 200,000,000 1650 A.D. 500,000,000 1945 A.D. 2,300,000,000 1980 A.D. 4,400,000,000\nTheorem 1 (Ghoussoub-Preiss). Assume H(t, x) is (0, ε)-subquadratic at infinity for all ε > 0, and T -periodic in t\nH(t, ·) is convex ∀t (23)\nH(·, x) is T−periodic ∀x (24)\nH(t, x) ≥ n (‖x‖) with n(s)s−1 → ∞ as s→ ∞ (25)\n5 ∀ε > 0 , ∃c : H(t, x) ≤ ε\n2 ‖x‖\n2 + c . (26)\nAssume also that H is C2, and H ′′(t, x) is positive definite everywhere. Then there is a sequence xk, k ∈ IN, of kT -periodic solutions of the system\nẋ = JH ′(t, x) (27)\nsuch that, for every k ∈ IN, there is some po ∈ IN with:\np ≥ po ⇒ xpk 6= xk . (28)\n⊓⊔\nExample 1 (External forcing). Consider the system:\nẋ = JH ′(x) + f(t) (29)\nwhere the Hamiltonian H is (0, b∞)-subquadratic, and the forcing term is a distribution on the circle:\nf = d\ndt F + fo with F ∈ L\n2 ( IR/TZZ; IR2n ) , (30)\nwhere fo := T −1 ∫ T o f(t)dt. For instance,\nf(t) = ∑\nk∈IN\nδkξ , (31)\nwhere δk is the Dirac mass at t = k and ξ ∈ IR 2n is a constant, fits the prescription. This means that the system ẋ = JH ′(x) is being excited by a series of identical shocks at interval T .\nDefinition 1. Let A∞(t) and B∞(t) be symmetric operators in IR 2n, depending continuously on t ∈ [0, T ], such that A∞(t) ≤ B∞(t) for all t. A Borelian function H : [0, T ]× IR2n → IR is called (A∞, B∞)-subquadratic at infinity if there exists a function N(t, x) such that:\nH(t, x) = 1\n2 (A∞(t)x, x) +N(t, x) (32)\n∀t , N(t, x) is convex with respect to x (33)\nN(t, x) ≥ n (‖x‖) with n(s)s−1 → +∞ as s→ +∞ (34)\n∃c ∈ IR : H(t, x) ≤ 1\n2 (B∞(t)x, x) + c ∀x . (35)\nIf A∞(t) = a∞I and B∞(t) = b∞I, with a∞ ≤ b∞ ∈ IR, we shall say that H is (a∞, b∞)-subquadratic at infinity. As an example, the function ‖x‖ α , with 1 ≤ α < 2, is (0, ε)-subquadratic at infinity for every ε > 0. Similarly, the Hamiltonian\nH(t, x) = 1\n2 k ‖k‖2 + ‖x‖α (36)\nis (k, k + ε)-subquadratic for every ε > 0. Note that, if k < 0, it is not convex.\n6 Notes and Comments. The first results on subharmonics were obtained by Rabinowitz in [5], who showed the existence of infinitely many subharmonics both in the subquadratic and superquadratic case, with suitable growth conditions on H ′. Again the duality approach enabled Clarke and Ekeland in [2] to treat the same problem in the convex-subquadratic case, with growth conditions on H only.\nRecently, Michalek and Tarantello (see [3] and [4]) have obtained lower bound on the number of subharmonics of period kT , based on symmetry considerations and on pinching estimates, as in Sect. 5.2 of this article."
    }, {
      "heading" : "Hamiltonian Mechanics2",
      "text" : "Ivar Ekeland1 and Roger Temam2\n1 Princeton University, Princeton NJ 08544, USA 2 Université de Paris-Sud, Laboratoire d’Analyse Numérique, Bâtiment 425,\nF-91405 Orsay Cedex, France\nAbstract. The abstract should summarize the contents of the paper using at least 70 and at most 150 words. It will be set in 9-point font size and be inset 1.0 cm from the right and left margins. There will be two blank lines before and after the Abstract. . . .\nKeywords: graph transformations, convex geometry, lattice computations, convex polygons, triangulations, discrete geometry"
    }, {
      "heading" : "1 Fixed-Period Problems: The Sublinear Case",
      "text" : "With this chapter, the preliminaries are over, and we begin the search for periodic solutions to Hamiltonian systems. All this will be done in the convex case; that is, we shall study the boundary-value problem\nẋ = JH ′(t, x)\nx(0) = x(T )\nwith H(t, ·) a convex function of x, going to +∞ when ‖x‖ → ∞."
    }, {
      "heading" : "1.1 Autonomous Systems",
      "text" : "In this section, we will consider the case when the Hamiltonian H(x) is autonomous. For the sake of simplicity, we shall also assume that it is C1.\nWe shall first consider the question of nontriviality, within the general framework of (A∞, B∞)-subquadratic Hamiltonians. In the second subsection, we shall look into the special case when H is (0, b∞)-subquadratic, and we shall try to derive additional information.\nThe General Case: Nontriviality. We assume that H is (A∞, B∞)-subquadratic at infinity, for some constant symmetric matrices A∞ and B∞, with B∞ −A∞ positive definite. Set:\nγ : = smallest eigenvalue of B∞ −A∞ (1) λ : = largest negative eigenvalue of J d\ndt +A∞ . (2)\n8 Theorem 21 tells us that if λ+ γ < 0, the boundary-value problem:\nẋ = JH ′(x) x(0) = x(T )\n(3)\nhas at least one solution x, which is found by minimizing the dual action functional:\nψ(u) =\n∫ T\no\n[ 1\n2\n( Λ−1o u, u ) +N∗(−u) ] dt (4)\non the range of Λ, which is a subspace R(Λ)2L with finite codimension. Here\nN(x) := H(x)− 1\n2 (A∞x, x) (5)\nis a convex function, and\nN(x) ≤ 1\n2 ((B∞ −A∞)x, x) + c ∀x . (6)\nProposition 1. Assume H ′(0) = 0 and H(0) = 0. Set:\nδ := lim inf x→0\n2N(x) ‖x‖ −2 . (7)\nIf γ < −λ < δ, the solution u is non-zero:\nx(t) 6= 0 ∀t . (8)\nProof. Condition (7) means that, for every δ′ > δ, there is some ε > 0 such that\n‖x‖ ≤ ε⇒ N(x) ≤ δ′\n2 ‖x‖\n2 . (9)\nIt is an exercise in convex analysis, into which we shall not go, to show that this implies that there is an η > 0 such that\nf ‖x‖ ≤ η ⇒ N∗(y) ≤ 1\n2δ′ ‖y‖\n2 . (10)\nFig. 1. This is the caption of the figure displaying a white eagle and a white horse on a snow field\n9 Since u1 is a smooth function, we will have ‖hu1‖∞ ≤ η for h small enough, and inequality (10) will hold, yielding thereby:\nψ(hu1) ≤ h2\n2\n1 λ ‖u1‖ 2 2 + h2 2 1 δ′ ‖u1‖ 2 . (11)\nIf we choose δ′ close enough to δ, the quantity ( 1\nλ + 1 δ′\n) will be negative, and\nwe end up with ψ(hu1) < 0 for h 6= 0 small . (12)\nOn the other hand, we check directly that ψ(0) = 0. This shows that 0 cannot be a minimizer of ψ, not even a local one. So u 6= 0 and u 6= Λ−1o (0) = 0. ⊓⊔\nCorollary 1. Assume H is C2 and (a∞, b∞)-subquadratic at infinity. Let ξ1, . . . , ξN be the equilibria, that is, the solutions of H\n′(ξ) = 0. Denote by ωk the smallest eigenvalue of H ′′ (ξk), and set:\nω := Min {ω1, . . . , ωk} . (13)\nIf: T\n2π b∞ < −E\n[ − T\n2π a∞\n] < T\n2π ω (14)\nthen minimization of ψ yields a non-constant T -periodic solution x.\nWe recall once more that by the integer part E[α] of α ∈ IR, we mean the a ∈ ZZ such that a < α ≤ a + 1. For instance, if we take a∞ = 0, Corollary 2 tells us that x exists and is non-constant provided that:\nT 2π b∞ < 1 < T 2π (15)\nor\nT ∈\n( 2π\nω , 2π\nb∞\n) . (16)\nProof. The spectrum of Λ is 2πT ZZ + a∞. The largest negative eigenvalue λ is given by 2πT ko + a∞, where\n2π T ko + a∞ < 0 ≤ 2π T (ko + 1) + a∞ . (17)\nHence:\nko = E\n[ − T\n2π a∞\n] . (18)\nThe condition γ < −λ < δ now becomes:\nb∞ − a∞ < − 2π\nT ko − a∞ < ω − a∞ (19)\nwhich is precisely condition (14). ⊓⊔\n10\nLemma 1. Assume that H is C2 on IR2n\\{0} and that H ′′(x) is non-degenerate for any x 6= 0. Then any local minimizer x̃ of ψ has minimal period T .\nProof. We know that x̃, or x̃ + ξ for some constant ξ ∈ IR2n, is a T -periodic solution of the Hamiltonian system:\nẋ = JH ′(x) . (20)\nThere is no loss of generality in taking ξ = 0. So ψ(x) ≥ ψ(x̃) for all x̃ in some neighbourhood of x in W 1,2 ( IR/TZZ; IR2n ) .\nBut this index is precisely the index iT (x̃) of the T -periodic solution x̃ over the interval (0, T ), as defined in Sect. 2.6. So\niT (x̃) = 0 . (21)\nNow if x̃ has a lower period, T/k say, we would have, by Corollary 31:\niT (x̃) = ikT/k(x̃) ≥ kiT/k(x̃) + k − 1 ≥ k − 1 ≥ 1 . (22)\nThis would contradict (21), and thus cannot happen. ⊓⊔\nNotes and Comments. The results in this section are a refined version of 1980; the minimality result of Proposition 14 was the first of its kind.\nTo understand the nontriviality conditions, such as the one in formula (16), one may think of a one-parameter family xT , T ∈ ( 2πω−1, 2πb−1\n∞\n) of periodic\nsolutions, xT (0) = xT (T ), with xT going away to infinity when T → 2πω −1, which is the period of the linearized system at 0.\nTable 1. This is the example table taken out of The TEXbook, p. 246\nYear World population\n8000 B.C. 5,000,000 50 A.D. 200,000,000 1650 A.D. 500,000,000 1945 A.D. 2,300,000,000 1980 A.D. 4,400,000,000\nTheorem 1 (Ghoussoub-Preiss). Assume H(t, x) is (0, ε)-subquadratic at infinity for all ε > 0, and T -periodic in t\nH(t, ·) is convex ∀t (23)\nH(·, x) is T−periodic ∀x (24)\nH(t, x) ≥ n (‖x‖) with n(s)s−1 → ∞ as s→ ∞ (25)\n11\n∀ε > 0 , ∃c : H(t, x) ≤ ε\n2 ‖x‖\n2 + c . (26)\nAssume also that H is C2, and H ′′(t, x) is positive definite everywhere. Then there is a sequence xk, k ∈ IN, of kT -periodic solutions of the system\nẋ = JH ′(t, x) (27)\nsuch that, for every k ∈ IN, there is some po ∈ IN with:\np ≥ po ⇒ xpk 6= xk . (28)\n⊓⊔\nExample 1 (External forcing). Consider the system:\nẋ = JH ′(x) + f(t) (29)\nwhere the Hamiltonian H is (0, b∞)-subquadratic, and the forcing term is a distribution on the circle:\nf = d\ndt F + fo with F ∈ L\n2 ( IR/TZZ; IR2n ) , (30)\nwhere fo := T −1 ∫ T o f(t)dt. For instance,\nf(t) = ∑\nk∈IN\nδkξ , (31)\nwhere δk is the Dirac mass at t = k and ξ ∈ IR 2n is a constant, fits the prescription. This means that the system ẋ = JH ′(x) is being excited by a series of identical shocks at interval T .\nDefinition 1. Let A∞(t) and B∞(t) be symmetric operators in IR 2n, depending continuously on t ∈ [0, T ], such that A∞(t) ≤ B∞(t) for all t. A Borelian function H : [0, T ]× IR2n → IR is called (A∞, B∞)-subquadratic at infinity if there exists a function N(t, x) such that:\nH(t, x) = 1\n2 (A∞(t)x, x) +N(t, x) (32)\n∀t , N(t, x) is convex with respect to x (33)\nN(t, x) ≥ n (‖x‖) with n(s)s−1 → +∞ as s→ +∞ (34)\n∃c ∈ IR : H(t, x) ≤ 1\n2 (B∞(t)x, x) + c ∀x . (35)\nIf A∞(t) = a∞I and B∞(t) = b∞I, with a∞ ≤ b∞ ∈ IR, we shall say that H is (a∞, b∞)-subquadratic at infinity. As an example, the function ‖x‖ α , with 1 ≤ α < 2, is (0, ε)-subquadratic at infinity for every ε > 0. Similarly, the Hamiltonian\nH(t, x) = 1\n2 k ‖k‖2 + ‖x‖α (36)\nis (k, k + ε)-subquadratic for every ε > 0. Note that, if k < 0, it is not convex.\n12\nNotes and Comments. The first results on subharmonics were obtained by Rabinowitz in 1985, who showed the existence of infinitely many subharmonics both in the subquadratic and superquadratic case, with suitable growth conditions on H ′. Again the duality approach enabled Clarke and Ekeland in 1981 to treat the same problem in the convex-subquadratic case, with growth conditions on H only.\nRecently, Michalek and Tarantello (see Michalek, R., Tarantello, G. 1982 and Tarantello, G. 1983) have obtained lower bound on the number of subharmonics of period kT , based on symmetry considerations and on pinching estimates, as in Sect. 5.2 of this article."
    } ],
    "references" : [ {
      "title" : "Nonlinear oscillations and boundary-value problems for Hamiltonian systems",
      "author" : [ "F. Clarke", "I. Ekeland" ],
      "venue" : "Arch. Rat. Mech. Anal. 78, 315–333",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1982
    }, {
      "title" : "Solutions périodiques, du période donnée, des équations hamiltoniennes",
      "author" : [ "F. Clarke", "I. Ekeland" ],
      "venue" : "Note CRAS Paris 287, 1013–1015",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1978
    }, {
      "title" : "Subharmonic solutions with prescribed minimal period for nonautonomous Hamiltonian systems",
      "author" : [ "R. Michalek", "G. Tarantello" ],
      "venue" : "J. Diff. Eq. 72, 28–55",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1988
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "A detailed introduction to (single-objective) AI planning can be found in [1].",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 1,
      "context" : "It is clear, however, that most planning problems are in fact multi-objective, as the optimal solution in real-world problems often involve some trade-off between makespan and cost [2].",
      "startOffset" : 181,
      "endOffset" : 184
    }, {
      "referenceID" : 2,
      "context" : "0 to account for both makespan and cost [3,4,5], or using the new hooks for several objectives offered by PDDL 3.",
      "startOffset" : 40,
      "endOffset" : 47
    }, {
      "referenceID" : 0,
      "context" : "In the case of makespan and cost, both to be minimized, each linear combination can be defined by a single parameter α in [0, 1].",
      "startOffset" : 122,
      "endOffset" : 128
    }, {
      "referenceID" : 0,
      "context" : "We hence propose here to use some evenly spaced values for α (see Section 4), but only after both objectives have been scaled into [0,1].",
      "startOffset" : 131,
      "endOffset" : 136
    }, {
      "referenceID" : 0,
      "context" : "Parameters Range Description W-makespan [0,5] Weight for makespan strategy for YAHSP W-cost [0,5] Weight for cost/risk strategy for YAHSP Pop-size [10,300] Population size Proba-cross [0,1] Probability to apply cross-over Proba-mut [0,1] Probability to apply one of the mutation w-addatom [1,10] Weight for addChangeAtom mutation w-addgoal [1,10] Weight for addGoal mutation w-delatom [1,10] Weight for delAtom mutation w-delgoal [1,10] Weight for delGoal mutation Proba-change [0,1] Probability to change each atom in the addChangeAtom mutation Proba-delatom [0,1] Probability to delete each atom in the delAtom mutation Radius [1,10] Number of neighbour goals to consider for the addGoal mutation",
      "startOffset" : 184,
      "endOffset" : 189
    }, {
      "referenceID" : 0,
      "context" : "Parameters Range Description W-makespan [0,5] Weight for makespan strategy for YAHSP W-cost [0,5] Weight for cost/risk strategy for YAHSP Pop-size [10,300] Population size Proba-cross [0,1] Probability to apply cross-over Proba-mut [0,1] Probability to apply one of the mutation w-addatom [1,10] Weight for addChangeAtom mutation w-addgoal [1,10] Weight for addGoal mutation w-delatom [1,10] Weight for delAtom mutation w-delgoal [1,10] Weight for delGoal mutation Proba-change [0,1] Probability to change each atom in the addChangeAtom mutation Proba-delatom [0,1] Probability to delete each atom in the delAtom mutation Radius [1,10] Number of neighbour goals to consider for the addGoal mutation",
      "startOffset" : 232,
      "endOffset" : 237
    }, {
      "referenceID" : 0,
      "context" : "Parameters Range Description W-makespan [0,5] Weight for makespan strategy for YAHSP W-cost [0,5] Weight for cost/risk strategy for YAHSP Pop-size [10,300] Population size Proba-cross [0,1] Probability to apply cross-over Proba-mut [0,1] Probability to apply one of the mutation w-addatom [1,10] Weight for addChangeAtom mutation w-addgoal [1,10] Weight for addGoal mutation w-delatom [1,10] Weight for delAtom mutation w-delgoal [1,10] Weight for delGoal mutation Proba-change [0,1] Probability to change each atom in the addChangeAtom mutation Proba-delatom [0,1] Probability to delete each atom in the delAtom mutation Radius [1,10] Number of neighbour goals to consider for the addGoal mutation",
      "startOffset" : 289,
      "endOffset" : 295
    }, {
      "referenceID" : 0,
      "context" : "Parameters Range Description W-makespan [0,5] Weight for makespan strategy for YAHSP W-cost [0,5] Weight for cost/risk strategy for YAHSP Pop-size [10,300] Population size Proba-cross [0,1] Probability to apply cross-over Proba-mut [0,1] Probability to apply one of the mutation w-addatom [1,10] Weight for addChangeAtom mutation w-addgoal [1,10] Weight for addGoal mutation w-delatom [1,10] Weight for delAtom mutation w-delgoal [1,10] Weight for delGoal mutation Proba-change [0,1] Probability to change each atom in the addChangeAtom mutation Proba-delatom [0,1] Probability to delete each atom in the delAtom mutation Radius [1,10] Number of neighbour goals to consider for the addGoal mutation",
      "startOffset" : 340,
      "endOffset" : 346
    }, {
      "referenceID" : 0,
      "context" : "Parameters Range Description W-makespan [0,5] Weight for makespan strategy for YAHSP W-cost [0,5] Weight for cost/risk strategy for YAHSP Pop-size [10,300] Population size Proba-cross [0,1] Probability to apply cross-over Proba-mut [0,1] Probability to apply one of the mutation w-addatom [1,10] Weight for addChangeAtom mutation w-addgoal [1,10] Weight for addGoal mutation w-delatom [1,10] Weight for delAtom mutation w-delgoal [1,10] Weight for delGoal mutation Proba-change [0,1] Probability to change each atom in the addChangeAtom mutation Proba-delatom [0,1] Probability to delete each atom in the delAtom mutation Radius [1,10] Number of neighbour goals to consider for the addGoal mutation",
      "startOffset" : 385,
      "endOffset" : 391
    }, {
      "referenceID" : 0,
      "context" : "Parameters Range Description W-makespan [0,5] Weight for makespan strategy for YAHSP W-cost [0,5] Weight for cost/risk strategy for YAHSP Pop-size [10,300] Population size Proba-cross [0,1] Probability to apply cross-over Proba-mut [0,1] Probability to apply one of the mutation w-addatom [1,10] Weight for addChangeAtom mutation w-addgoal [1,10] Weight for addGoal mutation w-delatom [1,10] Weight for delAtom mutation w-delgoal [1,10] Weight for delGoal mutation Proba-change [0,1] Probability to change each atom in the addChangeAtom mutation Proba-delatom [0,1] Probability to delete each atom in the delAtom mutation Radius [1,10] Number of neighbour goals to consider for the addGoal mutation",
      "startOffset" : 430,
      "endOffset" : 436
    }, {
      "referenceID" : 0,
      "context" : "Parameters Range Description W-makespan [0,5] Weight for makespan strategy for YAHSP W-cost [0,5] Weight for cost/risk strategy for YAHSP Pop-size [10,300] Population size Proba-cross [0,1] Probability to apply cross-over Proba-mut [0,1] Probability to apply one of the mutation w-addatom [1,10] Weight for addChangeAtom mutation w-addgoal [1,10] Weight for addGoal mutation w-delatom [1,10] Weight for delAtom mutation w-delgoal [1,10] Weight for delGoal mutation Proba-change [0,1] Probability to change each atom in the addChangeAtom mutation Proba-delatom [0,1] Probability to delete each atom in the delAtom mutation Radius [1,10] Number of neighbour goals to consider for the addGoal mutation",
      "startOffset" : 478,
      "endOffset" : 483
    }, {
      "referenceID" : 0,
      "context" : "Parameters Range Description W-makespan [0,5] Weight for makespan strategy for YAHSP W-cost [0,5] Weight for cost/risk strategy for YAHSP Pop-size [10,300] Population size Proba-cross [0,1] Probability to apply cross-over Proba-mut [0,1] Probability to apply one of the mutation w-addatom [1,10] Weight for addChangeAtom mutation w-addgoal [1,10] Weight for addGoal mutation w-delatom [1,10] Weight for delAtom mutation w-delgoal [1,10] Weight for delGoal mutation Proba-change [0,1] Probability to change each atom in the addChangeAtom mutation Proba-delatom [0,1] Probability to delete each atom in the delAtom mutation Radius [1,10] Number of neighbour goals to consider for the addGoal mutation",
      "startOffset" : 560,
      "endOffset" : 565
    }, {
      "referenceID" : 0,
      "context" : "Parameters Range Description W-makespan [0,5] Weight for makespan strategy for YAHSP W-cost [0,5] Weight for cost/risk strategy for YAHSP Pop-size [10,300] Population size Proba-cross [0,1] Probability to apply cross-over Proba-mut [0,1] Probability to apply one of the mutation w-addatom [1,10] Weight for addChangeAtom mutation w-addgoal [1,10] Weight for addGoal mutation w-delatom [1,10] Weight for delAtom mutation w-delgoal [1,10] Weight for delGoal mutation Proba-change [0,1] Probability to change each atom in the addChangeAtom mutation Proba-delatom [0,1] Probability to delete each atom in the delAtom mutation Radius [1,10] Number of neighbour goals to consider for the addGoal mutation",
      "startOffset" : 629,
      "endOffset" : 635
    }, {
      "referenceID" : 0,
      "context" : "The results in this section are a refined version of [1]; the minimality result of Proposition 14 was the first of its kind.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "Again the duality approach enabled Clarke and Ekeland in [2] to treat the same problem in the convex-subquadratic case, with growth conditions on H only.",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 2,
      "context" : "Recently, Michalek and Tarantello (see [3] and [4]) have obtained lower bound on the number of subharmonics of period kT , based on symmetry considerations and on pinching estimates, as in Sect.",
      "startOffset" : 39,
      "endOffset" : 42
    } ],
    "year" : 2012,
    "abstractText" : "Most real-world Planning problems are multi-objective, trying to minimize both the makespan of the solution plan, and some cost of the actions involved in the plan. But most, if not all existing approaches are based on single-objective planners, and use an aggregation of the objectives to remain in the single-objective context. Divide-andEvolve is an evolutionary planner that won the temporal deterministic satisficing track at the last International Planning Competitions (IPC). Like all Evolutionary Algorithms (EA), it can easily be turned into a Pareto-based Multi-Objective EA. It is however important to validate the resulting algorithm by comparing it with the aggregation approach: this is the goal of this paper. The comparative experiments on a recently proposed benchmark set that are reported here demonstrate the usefulness of going Pareto-based in AI Planning.",
    "creator" : "gnuplot 4.2 patchlevel 6 "
  }
}