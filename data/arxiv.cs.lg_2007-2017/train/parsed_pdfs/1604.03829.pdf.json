{
  "name" : "1604.03829.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Animation and Chirplet-Based Development of a PIR Sensor Array for Intruder Classification in an Outdoor Environment",
    "authors" : [ "Raviteja Upadrashta", "Tarun Choubisa", "A. Praneeth", "Tony G", "V. S. Aswath", "P. Vijay Kumar" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Index Terms—Wireless sensor network, passive infra-red sensor, intrusion detection, chirplets, animation, wildlife protection.\nI. INTRODUCTION\nAs described above, this project1 concerns the development of a Passive Infra-Red (PIR) based Sensor Tower Platform\n1The work presented here was supported in part by an Indo-US project jointly funded by the US National Science Foundation and the Indian Department of Electronics and Information Technology.\n(STP) that can distinguish between humans, animals and wind-blown vegetative clutter in an outdoor setting. We limit our attention to a small subclass of animals that are comparable in size and shape to a tiger or a dog. In the sequel2, we will refer to this sub-class of animals simply as animals. Also, when we speak of an intruder, the intruder could be either human or animal. We will refer to clutter generated by wind-blown vegetation as simply clutter. Power is not commonly available in settings of the type considered here and this motivates the use of low-power sensor networks."
    }, {
      "heading" : "A. Prior Work",
      "text" : "PIR sensors for detecting human motion in outdoor environments has only recently been investigated [1]–[5]. Hong et. al. in [4] use digital PIR sensors and energy thresholding for detecting human motion. The amount of signal processing that can be done using digital PIR sensors is limited in comparison to analog sensors that allow more sophisticated signal-processing algorithms to be employed for rejecting clutter. In [2], the PIR signal is first high-pass filtered to remove low frequency components resulting from slow environment changes and the signal energy is then compared against an adaptive threshold. In [3], clutter signals arising from environmental changes and wind-blown vegetation are rejected by a Support Vector Machine (SVM) based classifier that uses a Haar transform-based feature vector. However, the articles [1]–[4] described above, do not consider the problem of distinguishing between human and animal intrusions.\n2An earlier version of this paper was presented at the ISSNIP-2015 Conference. DOI:10.1109/ISSNIP.2015.7106914\nar X\niv :1\n60 4.\n03 82\n9v 1\n[ cs\n.L G\n] 1\n3 A\npr 2\nThe authors of [5] develop a Sensor Platform (SP) that is capable of classifying between human and animal that makes use of relatively expensive germanium lenses along with high resolution PIR sensors. The focus of the work presented here is on the development of a STP that makes use of offthe-shelf, relatively inexpensive PIR sensors and lenses. In a publication that appeared after the appearance of our 2015 conference publication [6], Zhao et. al. in [7] investigated the problem of discriminating between humans and false alarms generated by motion of animals of shape similar to dogs and geese using a single PIR sensor in conjunction with a multilens. However, false alarms potentially arising from moving vegetative clutter are not treated in this paper.\nSection II provides background on the PIR sensor. Section III gives a detailed description of our approach to PIR STP design. Section IV describes our data collection efforts. Section V, provides a description of ASPIRE, an animationbased simulation tool that was used to simulate PIR signals generated by human and animal intrusions. Chirp-based modeling of the intruder signal and its use in classification is covered in Section VI. Other features employed for detection and classification are described in Section VII. Our classification algorithm and experimental results are presented in Section VIII. The final section draw conclusions and presents thoughts on future extensions of this work.\nII. PIR SENSOR BACKGROUND\nPIR sensors work on the principle of pyroelectricity which causes them to respond to changes in incident radiation [8]. This ability has been used in a wide range of applications such as temperature sensing, traffic control, fire alarms, thermal imaging, and radiometers [9]. A further application involves the detection of humans as there are estimates that place the heat radiated by a human up to as much as 100 W. The use of PIR sensors in detecting human motion has been restricted mainly to indoor applications ranging from home security, smart homes, health care, hallway monitoring, gesture recognition, walker recognition, etc. As noted below in Section II-C, there are challenges to be overcome when attempting to employ a PIR in an outdoor environment."
    }, {
      "heading" : "A. Block Diagram of a PIR Sensor",
      "text" : "The block diagram of a typical, commercially-available PIR sensor is shown in Fig. 1. The PIR sensor typically consists\nof several radiation-sensing elements, called pixels, arranged in the form of an array, a common form being a (1 × 2) arrangement as shown in Fig. 2(a). We will refer to this (1×2) PIR sensor, simply as a PIR sensor. The pair of pixels in the (1×2) arrangement are wired together in a differential manner to overcome false alarms triggered by changes in the ambient temperature. A lens system is typically used to expand the Field of View (FoV) of the sensor and plays a key role in defining the sensor output signal. The lens system serves to focus radiation from different directions onto the pixels and consists of either a single lens or a multi-lens. A multi-lens is a set of contiguous lenses sharing a common focal point. The multi-lens shown in Fig. 1 corresponds to a set of contiguous plano-convex lenses 3. The FoV of the sensor can be viewed as a set of virtual beams cast out into space along which radiation is received. Fig. 2(a) illustrates the virtual beams cast out by a single spot lens, when placed in front of a (1×2) sensor. Given any plane in 3-dimensional space, the intersection of the FoV of the sensor with the plane is called the Virtual Pixel Array (VPA) associated with the particular plane. Fig. 2(a) shows the VPA associated to the (1 × 2) sensor used in conjunction with a spot lens. A typical signal generated as a result of a human intruder moving across the FoV of (1× 2) PIR pixel array is shown in Fig. 2(b). When the spot lens is replaced by a multilens, the resulting virtual beams are shown in Fig. 2(c). The output of the sensor in this case is the superposition of the signals generated by each pair of virtual pixels. A typical signal output for such an arrangement is shown in Fig. 2(d).\nThe human being radiates the peak emission at a wavelength of roughly 10 µm. An optical filter is used to reduce the influence of moving objects radiating at wavelengths significantly different from those of a human being.\n3In practice, each plano-convex lens is replaced by a Fresnel lens to reduce attenuation of the incident radiation."
    }, {
      "heading" : "B. PIR Signal Generation",
      "text" : "1) Radiation Model: The first step in determining the signal generated by a PIR sensor is to estimate the net radiation received from the source. Assuming the source can be modelled as a Lambertian source, i.e., a source that radiates equal energy in all directions, the net power transfer is [10]\nw(t) = τηFAeAproj(t)σ(T\n4 obj − T 4b )\nπR2 , (1)\nwhere, τ captures attenuation due to the atmosphere, η is the transmission coefficient of the lens, F is the fraction of the total radiation within the bandwidth of the optical filter, Ae is the area of the lens aperture, Aproj(t) is the area of the source when projected on to the VPA, σ is the Stefan-Boltzmann’s constant, Tobj is the object temperature in Kelvin, Tb is the background temperature in Kelvin and R is the distance of the radiating source from the detector.\n2) Impulse Response: One can model a PIR sensor as a bandpass filter with an impulse response given by [11], [12]\nh(t) = k1e −k2t − k3e−k4t, (2)\nwhere, the constants k1 through k4 depend on the physical properties of the PIR crystal and the amplifier electronics. The output voltage v(t) of the PIR sensor in response to a time-varying incident input radiation w(t) can be computed by simply convolving w(t) with h(t) i.e., v(t) = w(t)∗h(t).\nEquation (1) and the above model of a PIR sensor are employed by ASPIRE to simulate the output signal of a PIR sensor as will be seen in Section V. Simulation of the signal is useful when we wish to quickly understand the efficacy of a particular lens design without expending the time and effort needed for real-world data collection."
    }, {
      "heading" : "C. Challenges Faced in an Outdoor Deployment of a PIR Sensor",
      "text" : "One of the challenges to be overcome in an outdoor setting is the need to detect and classify in the presence of clutter. In such a setting, the radiation incident on a PIR could be altered due to changes in the environment, for example, when leaves blow in the wind or the sun comes out from behind a cloud."
    }, {
      "heading" : "III. APPROACH TO PIR SENSOR PLATFORM DESIGN",
      "text" : "Our two principal objectives are rejecting false alarms arising from moving vegetation and distinguishing between human and animal intruder motion. Two simple observations were key to the development of the STP. Firstly, that it is possible to distinguish between human and animal based on their height. Secondly, intruder motion is translational in nature, while vegetative motion tends to be oscillatory.\nThe following assumptions were made:\n1) At any given time, only a single intruder will be present within the FoV of the sensor; 2) Intruders move in a straight line at a uniform speed that is in a specified range: 1 to 3 m/sec; 3) Only animals having the same physical features as either a dog, wolf, leopard or tiger are considered here.\nA. VPA Design\nThe sensor platform consists of an array of 8 sensors arranged in the form of a tower (and hence referred to as sensor tower platform), which are labelled as A,B,C,D,L1, L2, R1, R2 (see Fig. 3(a)). Sensors A,B,C and D are arranged as a vertical array (see Fig. 3(a)) to provide the spatial resolution needed to distinguish between human and animal based on their height. Sensors A,B share a common multi-lens (called multi-lens AB) as do sensors C,D (multi-lens CD). The VPA associated with sensors A,B,C,D is shown in Fig. 3(b).\nSensors L1, L2, R1, R2 are placed so as to form two vertical arrays (see Fig. 3(a)) to distinguish between translational and oscillatory motion. Sensors L1, L2 share a single spot lens L as do sensors R1, R2 (spot lens R). The VPA associated with sensors Li, Ri, i = 1, 2, is shown in Fig. 3(b). If the intruder motion is translatory in nature with motion taking place from left to right of the STP, then the signal seen by sensor Ri will in general be a delayed version of the signal seen by Li. This will not be the case with oscillatory motion in general and it is this feature that we exploit in distinguishing between intruder and clutter.\nThe sensors and amplifier electronics are housed inside an IP65 box. The lens mounts for the multi-lenses AB and CD were made using a 3D printer. A snapshot of the developed STP appears in Fig. 4. For additional detail relating to components used4, please see Table I."
    }, {
      "heading" : "B. Use of Vertical Offset to Avoid Overlap Between Rows of the VPA",
      "text" : "The need for making the STP as compact as possible, forces the close placement of the multi-lenses AB and CD. However, close placement of the two multi-lenses will cause rows B and C of the VPA to overlap at larger distances from the STP, leading to a loss in spatial resolution. To overcome this, we resorted to the simple but effective trick of vertically offsetting sensors A,B and C,D, i.e., placing sensors A,B slightly below the optical axis of multi-lens AB and sensors C,D slightly above the optical axis of multi-lens CD. This is illustrated in Fig. 5."
    }, {
      "heading" : "C. Electronics for Sensor Platform",
      "text" : "The output of the PIR sensor is weak (typically on the order of µV) and needs amplification. A two-stage amplifier circuit is used to boost the signal amplitude (shown in Fig. 6). Potentiometers are used as feedback resistors at\n4The REP05B PIR sensor package has its pixels arranged in a 2 × 2 fashion. The sensor provides two outputs, one for each row of differentially wired pixels.\neach amplifier stage to provide a variable gain. The gain is adjusted in order to maintain a signal with large amplitude but free from saturation. The reason for this is that the signal processing techniques we employ for discriminating between various classes, is dependent on variations in signal amplitude. In order to improve the dynamic range of the amplifier, we provide a dual supply to the amplifier. This necessitates the inclusion of a rail-splitter. The rail-splitter takes the conventional single rail from a 9 V DC supply and splits it to provide a ± 4.5 V supply to the amplifiers. The output of the final amplification stage is DC level shifted by using a pull-up resistor in order to make the polarity of the signal positive (as the analog to digital converter on the mote requires signal inputs with a positive polarity only).\nThe PIR sensor signal is a function of the relative temperature difference between the moving object and its background (see (1)). The larger the temperature difference the larger will be the amplitude of the PIR sensor output and vice versa. Thus, a fixed gain cannot be used in a practical setting where the background temperature varies\nthroughout the day. To address this limitation one could measure the ambient temperature and adjust the gain of the potentiometers appropriately.\nIn order to avoid the cumbersome and time-consuming task of manually adjusting the potentiometers, we replace them with digital potentiometers whose resistance can be adjusted using a micro-controller (Fig. 7). An inter-integrated circuit (I2C) driver is used in conjunction with an I2C multiplexer to program each amplifier stage. We plan to utilize this circuit in conjunction with an ambient temperature sensor for automatic gain adjustment in future experiments."
    }, {
      "heading" : "D. Operating Range of the STP",
      "text" : "The STP is required to have the ability to distinguish between human and animal over a range of distances. A side view of the FoV of the STP is shown in Fig. 8. The inherent sensitivity of the PIR sensors as well as the divergent nature of the beams, making up the FoV, limit the operating range of the STP. The operating range of the STP developed here is 5-10m. At distances smaller than 5m, a small animal such as a dog will pass below all 4 beams A,B,C,D and hence will travel undetected as can be seen from Fig. 8. At ranges beyond 10m, the sensitivity of the sensors employed is not sufficient to guarantee detection with the required accuracy.\nIV. DATA COLLECTION\nA key step in supervised machine learning is data collection. Supervised classification algorithms require labelled data from which the machine learns the classification model. The 3 classes of interest here are humans, animals and clutter. In general, data collection in the case of animals, particularly wild animals, is both challenging as well as time consuming. We collected dog-intrusion data at a dog-trainer facility in Bengaluru. Data corresponding to tiger, leopard and wolf intrusions were collected at the Bannerghatta Biological Park (BBP). Data corresponding to human intruder motion as well as clutter were gathered on the forested campus of the Indian Institute of Science. The collected data corresponded to straight-line motion at a variety of typically observed speeds and angles of inclination θ (see Fig. 9(a)) at various distances within the desired operating range of 5-10m."
    }, {
      "heading" : "V. ASPIRE: ANIMATION-BASED SIMULATION TOOL FOR",
      "text" : "PASSIVE INFRA-RED SENSOR\nGiven the difficulty noted in Section IV in gathering data associated to animal motion, an Animation-based Simulation tool for Passive Infra-Red sEnsor (ASPIRE) was developed to simulate data corresponding not only to animal motion, but also human motion and clutter as well. Animated 3D models of the intruder were developed using the popular animation software Blender. The 3D model consists of a collection of triangles that are arranged in the form of a mesh that approximates the outer surface of the intruder.\nThe key intermediate step in determining the signal resulting from motion of the 3D model across the FoV of the STP is to find the area of the 3D mesh when projected onto the VPA of\nthe STP. By VPA here, we mean the VPA that is associated with the vertical plane along which the intruder moves. The area of projection of the 3D mesh can in turn be determined by projecting all triangles in the mesh model onto the VPA and computing the area of the polygon obtained by taking the union of all these projected triangles.\nTo simplify computation, in place of actual area computation, what is done in practice is to divide the VPA into a very large number of tiny squares. The area is then to a good approximation equal to be the sum of the areas of all squares that have non-empty intersection with the projected 3D mesh. This is illustrated in Figs. 11(a) and 11(b). This approach is along the lines of the approach employed in computer graphics for rendering a scene [13].\nAnimation techniques have been used previously to simulate waveforms in conjunction with doppler sensing for the purposes of detection and classification of different types of human motion [14]. In that paper, the authors use BioVision Hierarchy (BVH) files to simulate the motion of a human being as opposed to the more sophisticated Collada file format that we developed using Blender software.\nVI. CHIRPLET-BASED MODEL FOR INTRUDER SIGNAL\nIn the classification algorithm that is discussed in Section VIII, we exploit the simple-but-useful observation, made to our knowledge for the first time here, that intruder signals are well modeled using a chirp. More specifically, the signals generated by the intruder moving across A,B,C,D arrays of the VPA exhibit chirp.\nThe chirp phenomenon is explained in Fig. 12. This figure presents a top view of the virtual beams generated by employing a multi-lens in conjunction with a PIR sensor. Consider an intruder moving along a circular path at uniform speed. In this case, the size of the virtual pixels encountered and the gaps between two consecutive pixels of the VPA will be equal throughout the duration of intruder motion. As a result, the response of the PIR sensor will resemble a periodic sinusoidal signal. In the case of intruder motion from left to right along the straight-line path shown in Fig. 12, the size of the virtual pixels and gaps between two successive pixels of the VPA initially decreases until the intruder reaches the point of closest approach and thereafter increases. Thus, an intruder moving at a uniform speed along such a straight-line path will generate a signal comprising of an up-chirp followed by a down-chirp as illustrated at the top of Fig. 12. The extent and nature of the chirp will depend upon the angle θ of inclination of the intruder path. Clearly, in the case of oscillatory motion corresponding to clutter, no such chirp will be present. Figs. 13(a) and 13(b) show signals of intruder and clutter events, respectively.\nA. Intruder Detection via Chirplet Decomposition\nOur decomposition of the signal waveform as a sum of chirplets makes use of complex-exponential representation of elemental chirped signals in the form:\nx(n;m,ω, c, d) = (2πd2)− 1 4 exp { − ( n−m 2d )2} × exp { jω(n−m) + j c\n2 (n−m)2\n} , (3)\nwhere, m, ω, c and d are the parameters of the chirp signal representing the location in time, location in frequency, chirp rate and duration, respectively.\nAs a first step, we pass on from the real intruder signal s(n) to its complex, analytic representation sa(n) = (s(n) + jŝ(n)), where ŝ(n) is the Hilbert transform of s(n). We next decompose sa(n) as the weighted sum of q chirplets\nsa(n) = q∑ i=1 aie jφixi(n;mi, ωi, ci, di), (4)\nwhere, each xi(n) is given by an expression as in (3).\nNext, maximum likelihood estimates of the parameters a, m, ω, c and d of each chirplet are found using the method in [15]. The intruder signals turn out to be well approximated by the sum of three chirplets. The chirplet decomposition and subsequent reconstruction of an intruder and clutter signal associated to sensors A and B are shown in Fig. 14.\nNote that the reconstructed signal is close to that of the\noriginal signal in the case of an intruder signal and this is not true in the case of signal arising from clutter. What is fed to the SVM, however, are the parameters corresponding to this 3-chirplet decomposition. As will be seen in Section VIII, this approach resulted in high classification accuracy for the data sets collected. Some justification for this approach can be seen from the fact that in the chirplet decomposition associated to clutter, the times of arrival mi, of the different chirplet components, are well separated in time unlike in the case of an intruder signal, where the signals arrive synchronously. Also in terms of chirplet signal duration di, the different chirplets can have time durations that are very different, again unlike in the case of an intruder signal, where the time durations of the different chirplet components are very close to one another.\nVII. OTHER FEATURES USED IN CLASSIFICATION\nKey components of the feature vector used for classification were the parameters obtained from chirplet decomposition. Other important features employed relate to cross-correlation between signals obtained from sensors L1, L2, R1, R2 and the energy of signals from all 8 sensors as explained below."
    }, {
      "heading" : "A. Features Related to Signal Cross-Correlation",
      "text" : "When an intruder moves say from left to right, the signals generated by sensors L1, R1 are slightly delayed and timescaled versions of each other. A similar statement is true in the case of signals generated by sensors L2, R2. As a result, these signals will be highly correlated. Clutter generated by vegetation whose motion is oscillatory as opposed to translational will be unlikely to exhibit high correlation.\nThe precise quantity relating to signal correlation employed as part of the feature vector is the maximum crosscorrelation parameter ρmax corresponding to signals sLi , sRi generated by sensors Li, Ri, i = 1, 2 and given by:\nρmax = max k ∑ n ∑ i sLi(n+ k)sRi(n)√ (EL1 + EL2)(ER1 + ER2) , (5)\nwhere, ELi = ∑ n s 2 Li (n) and ERi = ∑ n s 2 Ri (n) for i = 1, 2.\nHistogram plots of ρmax observed for a large collection of events obtained both through real-world data collection and\nsimulation by ASPIRE are shown in Figs. 15(a) and15(b), respectively. Note that in both data sets, ρmax tends to be high for intruder motion and small in the case of vegetative motion. The differences between the two plots can be attributed in part, to the fact that the simulation data were generated using a smaller number of shrubs (to keep the complexity of simulation manageable) than were encountered in the real world. In addition, animal motion in the real world tended to take place at a slower speed (at larger distances) than could be reliably measured by the STP."
    }, {
      "heading" : "B. Signal-Energy-Based Classification",
      "text" : "Much effort went into designing the STP to endow it with a good spatial resolution. As can be seen from the data in Table II, it is possible to obtain some indication of the nature of the intruder and the intruder’s relative distance simply by examining the energy of the signals generated in sensors A,B,C,D.\nIn the table, a 0 or 1 entry indicates that the energy received by the particular sensor lies below or above a certain preset threshold, respectively. For example, a human intruder will typically trigger signals in all four sensors A,B,C,D, whereas an animal intrusion will most often trigger signals in sensors C,D. If only sensors A,B register signals, this is very likely indicative of clutter motion. Other inferences that can be drawn, also appear in the table. In terms of implementation however, the energy from all 8 sensors are fed as a feature vector to an SVM. An important advantage is the relative ease of extracting energy levels and hence the use of such features in classification is attractive from the standpoint of implementation on a mote that has limited computational capability."
    }, {
      "heading" : "A. Database Description",
      "text" : "Real-world and simulated databases were prepared. Each database covered a large number of events corresponding to either human or animal intrusion or else, clutter. Each event corresponded to a collection of (8 × 1024) samples from the 8 sensors with samples spaced 50 msec apart and hence corresponding to a time duration of approximately 50 secs. The break-up of the databases corresponding to the different event classes is shown in Table III. For each database, we used k-fold cross validation with 5 folds. 5"
    }, {
      "heading" : "B. Classification Algorithms",
      "text" : "In the three-way classification considered here, there were three feature vectors employed which we will refer to as:\nE8 ⇔ the energy recorded by all 8 sensors , ρmax ⇔ the maximum correlation parameter,\nC60 ⇔ the collection of 60 chirplet parameters.\nThe dimension of the feature vector C60 is given by\n(5 parameters per chirplet)× (3 chirplets per sensor signal) × (4 sensor signals) = total of 60 parameters.\n5The results presented in our previous paper [6] used the holdout method for cross-validation and a smaller range for the parameter C compared to what is employed in this paper. The parameter C is used in the SVM to control the trade-off between margin and allowed training errors.\nIn terms of machine learning algorithm, we uniformly relied upon SVM. We will use SVM(E8) and SVM(E8 ∪ ρmax) to denote SVM-based classification algorithms that employed E8 and (E8 ∪ ρmax) as their respective feature vectors, etc. We employed a 2-step classification algorithm. In the first step, we distinguished between intruder and clutter and in the next step we distinguish between human and animal intruder.\n1) Distinguishing Between Intruder and Clutter: This turned out to be the more challenging aspect of classification. Here, we tried out several possible choices of features (see Fig. 16) and the corresponding classification results can be found tabulated in Tables IV and V. We present results that represent the minimum and average accuracies attained. Our findings can be summarized as follows: (a) Improvement due to correlation parameter ρmax:\nThe performance of SVM(E8 ∪ ρmax) was noticeably better than that of SVM(E8) showing the parameter ρmax to be relevant in this context. (b) Efficacy of Chirplet Parameter set C60: • Interestingly, SVM(C60) significantly outperformed\nSVM(E8∪ρmax) despite the fact that the former only makes use of data from sensors A,B,C,D. • In the context of C60 data, both ρmax and E8 turned out to improve performance only marginally. Based upon these results, the decision was made to select the classifier based only on C60 as the feature vector. (c) Animation as a useful tool for algorithm testing: The relative performance of the various algorithms on real-world and simulated data was very similar, that suggests animation is a very useful tool in this setting. The performance of SVM(E8) on simulated data was lower compared to the performance on real-world data as some of the clutter events generated by ASPIRE were similar to intruder events. Such events were not present in the real-world database.\nTABLE V INTRUDER VERSUS CLUTTER - ACCURACY WITH SIMULATED DATA\nFeatures Minimum Accuracy % Average Accuracy % E8 ρmax C60 Clutter Intruder Total Clutter Intruder Total X 87.0 88.6 88.0 92.6 92.9 92.8 X X 87.0 96.2 92.5 94.1 95.0 94.6\nX 98.2 97.5 97.8 99.3 99.2 99.3\nFig. 16. Intruder vs clutter classification using energy, correlation and chirplet based feature vector.\n2) Distinguishing Between Human and Animal: In the second and final classification step, in order to distinguish between a human and animal, we simply fed the output of E8 to an SVM that carried out the binary classification. The spatial-resolution of the STP served us in good stead here, resulting in high-accuracy decisions.\n3) Classification Algorithm Finally Selected: Our 2-step classifier utilized the C60 feature vector for intruder vs clutter classification. Upon detecting the presence of an intruder, E8 features were then used to classify between human and animal in the second step (see Fig. 17).\nThe minimum and average accuracies obtained on real-world and simulated data are shown in Table VI."
    }, {
      "heading" : "IX. CONCLUSIONS AND FUTURE WORK",
      "text" : "The paper presents the design of a PIR STP that featured the use of (a) an array of PIR-sensors and lens combinations to endow the platform with the spatial resolution needed to distinguish between human, animal and vegetative clutter, (b) ASPIRE, a simulation tool that we developed that allowed us to judge the efficacy of various approaches to classification without the need for time consuming and challenging animal-motion data collection and (c) the modeling of an intruder signal as a waveform exhibiting chirp that\nwas effective in discriminating between intruder motion and clutter. The overall average classification accuracy was found to be quite high, over 97%.\nThe classification algorithm was carried out offline on a laptop as the complexity of extracting the 60 chirplet parameters exceeds the computational capabilities of the processor on the mote. It is planned as future work, to identify the key parameters among the 60 chirplet parameters employed for classification here with the aim of significantly reducing the complexity of the classification algorithm to the point where it can be implemented on a mote.\nX. ACKNOWLEDGMENT\nWe would like to acknowledge the help extended to us by the Executive Director and Staff at Bannerghatta Biological Park and dog trainer at Dog Guru for animal data collection.\nREFERENCES\n[1] A. Arora et al., “Exscal: Elements of an extreme scale wireless sensor network,” in Proc. IEEE Int. Conf. Embedded and Real-Time Computing Syst. and Applicat., 2005, pp. 102–108. [2] L. Gu et al., “Lightweight detection and classification for wireless sensor networks in realistic environments,” in Proc. Int. Conf. on Embedded Networked Sensor Syst. ACM, 2005, pp. 205–217. [3] SmartDetectTeam, “Wireless sensor networks for human intruder detection,” Journal of the Indian Institute of Science, Special Issue on Advances in Elect. Sci., vol. 90, no. 3, pp. 347–380, 2010. [4] S. G. Hong, N. S. Kim, and W. W. Kim, “Reduction of false alarm signals for PIR sensor in realistic outdoor surveillance,” J. ETRI, vol. 35, no. 1, pp. 80–88, 2013. [5] E. L. Jacobs, S. Chari, C. Halford, and H. McClellan, “Pyroelectric sensors and classification algorithms for border/perimeter security,” in Proc. SPIE Europe Security+ Defence, 2009, pp. 74 810P–74 810P. [6] R. Upadrashta et al., “An animation-and-chirplet based approach to intruder classification using pir sensing,” in Proc. IEEE Int. Conf. Intell. Sensors, Sensor Networks and Inform. Process., 2015, pp. 1–6. [7] J. Zhao, W. Gong, Y. Tang, and W. Li, “Emd-based symbolic dynamic analysis for the recognition of human and nonhuman pyroelectric infrared signals,” J.Sensors, vol. 16, no. 1, p. 126, 2016. [8] S. B. Lang, “Pyroelectricity: from ancient curiosity to modern imaging tool,” J. Physics Today, vol. 58, no. 8, pp. 31–36, 2005. [9] R. Whatmore, “Pyroelectric devices and materials,” J. Rep. Prog. Phys., vol. 49, no. 12, p. 1335, 1986. [10] F. A. S. Military Analysis Network, “Infrared propagation and detection,” [accessed 9-June-2015]. [Online]. Available: http://fas. org/man/dod-101/navy/docs/es310/IR prop/IR prop.htm [11] A. Hossain and M. H. Rashid, “Pyroelectric detectors and their applications,” IEEE Trans. Ind. Appl., vol. 27, pp. 824–829, 1991. [12] A. Chattopadhyay et al., “PIR-based wsn for outdoor deployment,” in Proc. IEEE Int. Conf. on Wireless Commun. and Sensor Networks, 2012. [13] T. Theoharis, G. Papaioannou, and E.-A. Karabassi, “The magic of the z-buffer: A survey,” in Proc. Int. Conf. Comput. Graph., Visualization and Comput. Vision, 2001, pp. 379–386.\n[14] S. S. Ram and H. Ling, “Simulation of human microdopplers using computer animation data,” in Proc. IEEE Radar Conf., 2008, pp. 1–6. [15] J. C. O’neill, P. Flandrin, and W. C. Karl, “Sparse representations with chirplets via maximum likelihood estimation,” 2001.\nRaviteja Upadrashta received the M.S. in Electrical Engineering from IIT Madras, Chennai in 2008. He is currently pursuing his Ph. D. in Department of Electrical and Communication Engineering at IISc, Bengaluru.\nTarun Choubisa received the M.Tech. in Digital Signal Processing from IIT Guwahati in 2010. He is currently pursuing his Ph. D. in Department of Electrical and Communication Engineering at IISc, Bengaluru.\nA. Praneeth(M’09) received B.E. in Electronics and Communication from PES College of Engineering in 2003 and M. E. (Telecom) from IISc in 2015. He is currently working with DRDO.\nTony G. received B. Tech. in Electrical and Electronics from NIT Calicut in 2013 and M. E. (Signal Processing) from IISc Bangalore in 2015. He is currently working in Flytxt Trivandrum as R & D Lead Data Science.\nV. S. Aswath received B. Tech. from department of electrical engineering from NIT Calicut in 2011, and M. E. degree in Signal processing from IISc in 2013. Currently employed with Broadcom India Research.\nP. Vijay Kumar (S’80-M’82-SM’01-F’02) received his Ph.D. from USC in 1983 in Electrical Engg. From 1983 to 2003 he was on the faculty of the EE-Systems Department at USC. Since 2003, he has been on the faculty of IISc, Bengaluru. He also holds the position of Adjunct Research Professor at USC. His current research interests include codes for distributed storage and intrusion-detection algorithms for WSNs. He is an ISI highly cited author and a Fellow of the Indian National Academy of Engg. He is also corecipient of the 1995 IEEE Information Theory Society Prize-Paper award, a Best-Paper award at the DCOSS 2008 conference on sensor networks and the IEEE Data Storage Best-Paper Award of 2011/2012. A pseudorandom sequence family designed in a 1996 paper co-authored by him now forms the short scrambling code of the 3G WCDMA cellular standard. He received the USC School of Engineering Senior Research Award in 1994 and the Rustum Choksi Award for Excellence in Research in Engg. in 2013 at IISc. He has been on the Board of Governors of the IEEE Information Theory Society since 2013.\nSripad Kowshik received B.E. in Electronics and Communication from Sri Venkateshwara College of Engg. in 2012. He is currently pursuing M.S. in Electrical Engg. and Computer Science at University of California, Irvine.\nHari Prasad Gokul R received the B.E. degree in Electronics and Communications Engineering from PSG College of Technology (Anna University), Coimbatore, in 2013 and is currently a Project Assistant with the Department of Electronic Systems Engineering, IISc, Bangalore, India.\nPrabhakar Venkata received M.Sc. (Engg.) from IISc, Bengaluru and PhD from TUDelft, Netherlands. He works as Senior Scientific Officer in the Department of Electronic Systems Engg, IISc, Bengaluru. His area of work is in Networked Embedded Systems. His research interest is in Energy Harvesting systems, Power Management Algorithms, Tactile IoT. The broad spectrum comprises of Modelling, Virtual Prototyping, System Building and Performance evaluation. His work in LED based communication won the best demo award in COMSNETS 2014. He is currently working on RFID localization algorithms, RF energy harvesting technologies in chip design and Indoor localization applications in healthcare and safety. The Zero Energy Networks laboratory (ZENLab) at IISc specializes in building ultra low power embedded boards and software stacks. The application areas are related to Smart Grids, Healthcare, Human Security and Agriculture."
    } ],
    "references" : [ {
      "title" : "Exscal: Elements of an extreme scale wireless sensor network",
      "author" : [ "A. Arora" ],
      "venue" : "Proc. IEEE Int. Conf. Embedded and Real-Time Computing Syst. and Applicat., 2005, pp. 102–108.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Lightweight detection and classification for wireless sensor networks in realistic environments",
      "author" : [ "L. Gu" ],
      "venue" : "Proc. Int. Conf. on Embedded Networked Sensor Syst. ACM, 2005, pp. 205–217.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Wireless sensor networks for human intruder detection",
      "author" : [ "SmartDetectTeam" ],
      "venue" : "Journal of the Indian Institute of Science, Special Issue on Advances in Elect. Sci., vol. 90, no. 3, pp. 347–380, 2010.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Reduction of false alarm signals for PIR sensor in realistic outdoor surveillance",
      "author" : [ "S.G. Hong", "N.S. Kim", "W.W. Kim" ],
      "venue" : "J. ETRI, vol. 35, no. 1, pp. 80–88, 2013.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Pyroelectric sensors and classification algorithms for border/perimeter security",
      "author" : [ "E.L. Jacobs", "S. Chari", "C. Halford", "H. McClellan" ],
      "venue" : "Proc. SPIE Europe Security+ Defence, 2009, pp. 74 810P–74 810P.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "An animation-and-chirplet based approach to intruder classification using pir sensing",
      "author" : [ "R. Upadrashta" ],
      "venue" : "Proc. IEEE Int. Conf. Intell. Sensors, Sensor Networks and Inform. Process., 2015, pp. 1–6.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Emd-based symbolic dynamic analysis for the recognition of human and nonhuman pyroelectric infrared signals",
      "author" : [ "J. Zhao", "W. Gong", "Y. Tang", "W. Li" ],
      "venue" : "J.Sensors, vol. 16, no. 1, p. 126, 2016.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Pyroelectricity: from ancient curiosity to modern imaging tool",
      "author" : [ "S.B. Lang" ],
      "venue" : "J. Physics Today, vol. 58, no. 8, pp. 31–36, 2005.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Pyroelectric devices and materials",
      "author" : [ "R. Whatmore" ],
      "venue" : "J. Rep. Prog. Phys., vol. 49, no. 12, p. 1335, 1986.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1986
    }, {
      "title" : "Infrared propagation and detection",
      "author" : [ "F.A.S. Military Analysis Network" ],
      "venue" : "[accessed 9-June-2015]. [Online]. Available: http://fas. org/man/dod-101/navy/docs/es310/IR prop/IR prop.htm",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Pyroelectric detectors and their applications",
      "author" : [ "A. Hossain", "M.H. Rashid" ],
      "venue" : "IEEE Trans. Ind. Appl., vol. 27, pp. 824–829, 1991.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "PIR-based wsn for outdoor deployment",
      "author" : [ "A. Chattopadhyay" ],
      "venue" : "Proc. IEEE Int. Conf. on Wireless Commun. and Sensor Networks, 2012.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "The magic of the z-buffer: A survey",
      "author" : [ "T. Theoharis", "G. Papaioannou", "E.-A. Karabassi" ],
      "venue" : "Proc. Int. Conf. Comput. Graph., Visualization and Comput. Vision, 2001, pp. 379–386.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Simulation of human microdopplers using computer animation data",
      "author" : [ "S.S. Ram", "H. Ling" ],
      "venue" : "Proc. IEEE Radar Conf., 2008, pp. 1–6.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "PIR sensors for detecting human motion in outdoor environments has only recently been investigated [1]–[5].",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 4,
      "context" : "PIR sensors for detecting human motion in outdoor environments has only recently been investigated [1]–[5].",
      "startOffset" : 103,
      "endOffset" : 106
    }, {
      "referenceID" : 3,
      "context" : "in [4] use digital PIR sensors and energy thresholding for detecting human motion.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 1,
      "context" : "In [2], the PIR signal is first high-pass filtered to remove low frequency components resulting from slow environment changes and the signal energy is then compared against an adaptive threshold.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 2,
      "context" : "In [3], clutter signals arising from environmental changes and wind-blown vegetation are rejected by a Support Vector Machine (SVM) based classifier that uses a Haar transform-based feature vector.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 0,
      "context" : "However, the articles [1]–[4] described above, do not consider the problem of distinguishing between human and animal intrusions.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 3,
      "context" : "However, the articles [1]–[4] described above, do not consider the problem of distinguishing between human and animal intrusions.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 4,
      "context" : "The authors of [5] develop a Sensor Platform (SP) that is capable of classifying between human and animal that makes use of relatively expensive germanium lenses along with high resolution PIR sensors.",
      "startOffset" : 15,
      "endOffset" : 18
    }, {
      "referenceID" : 5,
      "context" : "In a publication that appeared after the appearance of our 2015 conference publication [6], Zhao et.",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 6,
      "context" : "in [7] investigated the problem of discriminating between humans and false alarms generated by motion of animals of shape similar to dogs and geese using a single PIR sensor in conjunction with a multilens.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 7,
      "context" : "PIR sensors work on the principle of pyroelectricity which causes them to respond to changes in incident radiation [8].",
      "startOffset" : 115,
      "endOffset" : 118
    }, {
      "referenceID" : 8,
      "context" : "This ability has been used in a wide range of applications such as temperature sensing, traffic control, fire alarms, thermal imaging, and radiometers [9].",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 9,
      "context" : ", a source that radiates equal energy in all directions, the net power transfer is [10]",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 10,
      "context" : "2) Impulse Response: One can model a PIR sensor as a bandpass filter with an impulse response given by [11], [12]",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 11,
      "context" : "2) Impulse Response: One can model a PIR sensor as a bandpass filter with an impulse response given by [11], [12]",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 12,
      "context" : "This approach is along the lines of the approach employed in computer graphics for rendering a scene [13].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 13,
      "context" : "Animation techniques have been used previously to simulate waveforms in conjunction with doppler sensing for the purposes of detection and classification of different types of human motion [14].",
      "startOffset" : 189,
      "endOffset" : 193
    }, {
      "referenceID" : 5,
      "context" : "5The results presented in our previous paper [6] used the holdout method for cross-validation and a smaller range for the parameter C compared to what is employed in this paper.",
      "startOffset" : 45,
      "endOffset" : 48
    } ],
    "year" : 2016,
    "abstractText" : null,
    "creator" : "LaTeX with hyperref package"
  }
}