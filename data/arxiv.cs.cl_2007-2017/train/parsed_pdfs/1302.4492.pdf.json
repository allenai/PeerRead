{
  "name" : "1302.4492.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Bilingual Terminology Extraction Using Multi-level Termhood",
    "authors" : [ "Chengzhi ZHANG", "Dan WU" ],
    "emails" : [ "zhangchz@istic.ac.cn,", "woodan@whu.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Purpose: Terminology is the set of technical words or expressions used in\nspecific contexts, which denotes the core concept in a formal discipline and is usually applied in the fields of machine translation, information retrieval, information extraction and text categorization, etc. Bilingual terminology extraction plays an important role in the application of bilingual dictionary compilation, bilingual Ontology construction, machine translation and cross-language information retrieval etc. This paper addresses the issues of monolingual terminology extraction and bilingual term alignment based on multi-level termhood.\nDesign/methodology/approach: A method based on multi-level termhood is\nproposed. The new method computes the termhood of the terminology candidate as well as the sentence that includes the terminology by the comparison of the corpus. Since terminologies and general words usually have differently distribution in the corpus, termhood can also be used to constrain and enhance the performance of term alignment when aligning bilingual terms on the parallel corpus. In this paper, bilingual term alignment based on termhood constraints is presented.\nFindings: Experiment results show multi-level termhood can get better\nperformance than existing method for terminology extraction. If termhood is used as constrain factor, the performance of bilingual term alignment can be improved.\nOriginality/value: The termhood of the candidate terminology and the sentence that includes the terminology is used to terminology extraction, which is called\nmulti-level termhood. Multi-level termhood is computed by the comparison of the corpus. The experiment results show that the multi-level termhood can get better performance than standard method. Bilingual term alignment method based on termhood constraint is put forward and termhood is used in the task of bilingual terminology extraction. Experiment results show that termhood constraints can improve the performance of terminology alignment to some extent.\nKEYWORDS: Bilingual Terminology Extraction, Multi-level Termhood, Corpus\nComparison, Bilingual Terminology Alignment"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Terminology is the product of scientific and technological development. It is the set of technical words or expressions used in specific contexts, which denotes the core concept in a formal discipline. It can be applied in the research area of natural language processing (NLP), information retrieval, machine translation and data mining. There are two characters of terminology. On the one hand, terminology denotes the core concept in a discipline so the usage and the users are limited. General words are more acceptable and recognizable in different areas than terminology. On the other hand, compared to general words, terminology always has a single meaning in specific domain. These two characters of terminology can be computed by termhood. The higher the termhood is, the higher capability of distinguishing different domains the terminology has.\nIn the previous works about terminology extraction, only the termhood of a terminology candidate is considered, but not other aspects. In this paper, the termhood of the candidate terminology and the sentence that includes the terminology is used to terminology extraction, which is called multi-level termhood. Multi-level termhood is computed by the comparison of the corpus. The experiment results show that the multi-level termhood can get better performance than standard method.\nBilingual terminology extraction is composed of two steps: 1. extracting monolingual terms from monolingual document or sentence; 2. aligning the bilingual terms. Different from traditional word alignment, extracting and aligning bilingual terms from parallel sentences aims at extracting and aligning not all words but candidate terms in sentences. Therefore traditional word alignment methods can not directly applied to bilingual term alignment task. For those differently distributed terms and general words on corpus, result of traditional word alignment methods can be optimized or constrained with termhood during the process of term alignment to enhance the performance of term alignment. Bilingual term alignment method based on termhood constraint is put forward and termhood is used in the task of bilingual terminology extraction. Experiment results show that termhood constraints can improve the performance of terminology alignment to some extent.\nThe rest of this paper is organized as follows. The next section reviews some related work on bilingual terminology extraction. In section 3, a detailed description of\nterminology extraction based on multi-level termhood is presented. In section 4, the method of bilingual terminology alignment based on termhood constraints is described. The paper is concluded with a summary and directions for future work."
    }, {
      "heading" : "2. RELATED WORK",
      "text" : ""
    }, {
      "heading" : "2.1. Terminology Extraction",
      "text" : "With the enrichment of language resources and the development of NLP, many terminology extraction systems have been developed (Kit & Liu, 2008). The most commonly used terminology extraction methods include linguistic, statistics and hybrid approach. (1) Linguistic Approach Linguistic features are used to restrain the candidate terminology, that is, terminology is filtered by linguistic features (Ido and Ward, 1994). Linguistic methods exploit part-of-speech Tagging and shallow parsing to filter the terminology. (Bourigault, 1992) used shallow parsing to extract noun phrase that is a terminology. (Ido and Ward, 1994) limited the candidate terminology to a string that represents the pattern of noun sequences. (Justeson and Katz, 1995) used the prefix of terminology and selected strings whose prefix is noun to be candidate terms. Good results can be achieved in small corpora using linguistic methods, yet the recall rate is low for the shortage of patterns and the adaptability of fields and languages. (2) Statistical Approach Statistical approaches are based on the statistical information, such as the frequency of terms appearing in the corpora, to extract terms, including TF*IDF (Maedche & Staab, 2000), KF*IDF (Xu et al, 2002), C-value/NC-value (Frantzi et al, 2000) and so on.\nTermhood extraction relates to two basic statistical variables, that is, Unithood and Termhood of terminology. Statistical method is usually used to compute these two variables. For unithood, the approaches includes MI (Church & Hanks, 1990), LogL (Dunning, 1993) and left/right entropy (Patry & Langlais, 2005). When computing\ntermhood, methods such as TF*IDF (Maedche & Staab, 2000), DR-D (Velardi, 2001)、\nC-value/NC value (Frantzi et al, 2000), inter-domain entropy (IDE) (Chang, 2005) and Domain Component Feature Set (DCFS) (Zhang et al, 2003) are employed. (3) Hybrid Approach Linguistics and statistics have their own advantages and disadvantages, and they are usually integrated to extract terminology. There are two ways to combine them. One way is to extract candidate terms with linguistics methods and then with the statistics methods. The other way is to obtain candidate terms using statistics methods first and then use linguistic methods to abandon those terms inconsistent with linguistic patterns.\n(Daille, 1996) used the linguistic methods to get candidate terms and set them as the input of statistical models. Then statistical methods such as MI and LogL are used to get final terms. (Maynard & Ananiadou, 2000) did some research about the extraction of\nmulti-word term using thesaurus and semantic Web to get the semantic and category information, and then integrated it with the statistical and syntactic information in the corpora.\nDifferent terminology extraction toolkits can also be integrated to extract terminology besides the integration of linguistics and statistics methods (Kit & Liu, 2008). (Vivaldi & Rodríguez, 2000) integrated different term extraction tools by simple voting and the result is better than single term extraction tools. (Vivaldi & Màrquez, 2001) improved the above voting approach, got the best integration strategy by Boosting algorithm and enhanced the performance of terminology extraction based on hybrid approach."
    }, {
      "heading" : "2.2. Optimization of Bilingual Terminology Extraction",
      "text" : "(Wu & Wang, 2004; Wu et al, 2005) did some research about optimization of domain terms alignment with large general parallel corpus. (Wu & Wang, 2004) trained models for word alignment using domain specific and general corpus separately and employed the two models to improve performance of word alignment. (Wu et al, 2005) further optimized their method further, changed self-adaptive methods into statistical models and improved the performance of word alignment.\nIt’s important to note that domain term alignment optimization methods adopted by (Wu & Wang, 2004; Wu et al, 2005) rely on the availability of large domain and general parallel corpus. Their method has limitation when a large parallel corpus is not available. In this paper, termhood of terms in parallel sentences will be used instead of large general parallel corpus. General corpus of different languages is employed to compute termhood and results of term alignment can be optimized with termhood. So methods presented in this paper are expansive. (Wu & Wang, 2005; Wu et al, 2006) used integrated learning methods (including Bagging, Boosting and semi-supervised Boosting) to improve the result of word alignment.\nRelevant research includes the study on confidence measurement of word alignment by (Huang, 2009). He introduced sentence alignment confidence measure and alignment links confidence measure to improve performance of word alignment by selecting aligned sentence and linked word with high confidence.\nSome illegal sentence pairs (including some incorrect alignment result or partial alignment result) can be found by measuring termhood of sentences and evaluating alignment quality of parallel sentences pairs. Constraining results of term extraction with termhood can improve the performance of term extraction and alignment.\nWhen studying evaluation method of word alignment, (Huang et al, 2009) pointed out that lack of links is less important than wrong links when aligning words. So it’s valuable to find wrong results among results of word alignment."
    }, {
      "heading" : "3. TERMINOLOGY EXTRACTION BASED ON MULTI-LEVEL",
      "text" : "TERMHOOD\n3.1. Features used in Terminology Extraction\nIn this section, CRF model is used to extract terminology from documents. CRF is a model of probability graph proposed by (Lafferty, 2001) which is widely used in word segmentation, part-of-speech tagging, chunking recognition, named entity recognition and so on. The features used in CRF model are shown in Table1.\nIn this paper, Segtag (a tool with function of Chinese segmentation and POS tagging, it downloaded from http://www.nlp.org.cn) will be used to segment Chinese documents and tag POS with a general word segmentation lexicon. Since the linguistics and statistics methods are integrated in the tool, words, POS and termhood will be used as features of CRF and models will be trained with training data.\nNote that the above-mentioned POS refers to results of POS tagging of each\nsegmented unit. These units may be part of a terminology or even not be a terminology.\nCRF++ (http://crfpp.sourceforge.net) will be used in this paper to train and test the terminology extraction models. Statistical feature employed in this model, that is termhood of terminology and the sentence including this term will be illustrated."
    }, {
      "heading" : "3.2. Multi-level Termhood for Terminology Extraction",
      "text" : "The linguistics and statistics features of candidate terminology will be integrated in this paper. Termhood of candidate terminology and sentences containing these terms will be considered synthetically. (1) Termhood of Candidate Terminology In this paper, CRF model will be used to extract terms on manual-tagged corpus with 10-fold cross-validation. Results show that methods based on frequency difference is better than those based on frequency rank difference. Both of them are dependent on the size of domain and general corpus. Therefore, next step is to find corpus comparison method based on frequency difference or rank difference.\nDifferent from (Kit & Liu 2008), terminology extraction here is not limited to mono-word term extraction in this paper. When using CRF to extract terms, after text segmentation, part-of-speech tagging and computation of termhood, all of these features will be as input of CRF, including extraction of mono-word and multi-word terms.\nIn this paper, termhood is used to extract terminology. According to the research result of (Liu & Kit, 2008) about termhood computing of mono-word term and our preliminary experiment result, we compute termhood based on the frequency difference and rank difference between domain and general corpus. The brief description of the method is as follows.\nAssumption: candidate term is w, corpus is x, total number of words in corpus x (size of\nlexicon generated by x) is x V , )(wxf is the relative frequency of candidate term w\noccurred in x, )(wxc is the absolute frequency of candidate term w occurred in x, and\n)(wxf can be calculated by formula (1) (Liu & Kit, 2009).\n∑ ∈ =\nxVw\nxx wcwcwxf '\n' )()()( (1)\nFrequency difference of candidate term w occurred in domain corpus d x and general\ncorpus b x is computed by formula (2) (Liu & Kit, 2009).\n)()()( wfwfwf bd −=∆ (2)\nRank difference of candidate term w occurred in domain corpus d x and general corpus\nb x\nis computed by formula (3) (Liu & Kit, 2009).\n)()()( wrwrwr bd −=∆ (3)\nAnd, )(wr d 、 )(wr b are the rankings of frequency of term w occurred in domain\ncorpus d x and general corpus b x (Liu & Kit, 2009) (ranking can be reversed, that is, the\nhigher the ranking is, the larger the number is (Kit & Liu, 2008)). In this paper, tagged data of People’s Daily (http://www.people.com.cn/) from January to June 1998 are used as general corpus to extract terms.\nOn the basis of rank difference, number-intensified is done by formula (4) (Liu & Kit,\n2009) to get new rank difference after the enhancement.\n))()(()()( wrwrwcwr bddc −⋅=∆ (4)\n(2) Termhood of Sentences Containing Candidate Terminology Termhood of sentences refers to mean value of termhood of all words which are in the same sentences as the candidate terms. In this paper, corpus such as journal article title, journal article abstract, patent title, patent abstract, news title, news article, MARC (Machine-Readable Catalogue) title and MARC summary is used as statistical sample to compute termhood and average sentence termhood of diverse corpus.\nAs shown in table2, from the perspective of title, ranking of termhood of different\ncorpus is: patent corpus> journal article corpus > MARC corpus > news corpus.\nFrom the perspective of full text or abstract, ranking of termhood of different corpus\nis: MARC corpus > journal article corpus > patent corpus > news corpus. Previous research results about automatic keyword extraction show that title contributes more than abstract and full texts for keyword extraction (Hou et al, 2005). But term extraction and keyword extraction are two different tasks. Keyword extraction aims at extracting 6 to ten words that mostly represent the content of the document. However, term extraction extracts terms in certain documents or collections and the number of extracted terms depends on the document itself without any restriction. Compared to abstract and full text, title is the summary of full text, and contains less terms in order to increase readability. Abstract is the summary of key points of the document, so abstracts and full texts contain more terms. Results of sampling statistics also demonstrate this point. What’s more, the difference between title and abstract is more significant in MRAC than in dissertation. In future, more data will be used as\nstatistical samples to analyze termhood differences of titles, abstracts and full texts.\nAs shown in the statistical result, the sentence termhood of title and full text in news is lower than that of specific domain. In real texts, professional literature usually contains more terms while news has more general words. So when extracting terms, termhood of sentence can be integrated into term extraction model as part information of candidate term.\nTermhood of term itself and that of sentences or articles containing this term can complete mutual learning, that is, the higher termhood of sentences or articles is, the more likely that they contain terms and the higher termhood of a term is, the higher termhood of sentences or article containing this term is. The two kinds of information can be mutually learned through interaction to enhance the quality of term extraction. What’s more, terms are more likely to appear in sentence whose termhood is high. Termhood of all sentences which contain this term in corpus can be used as a global feature to complete data training.\nIt’s important to note that recently mutually reinforcing relationship between domain sentences and domain terms are studied by (Yang et al, 2010) to extract terms. They implemented this mutual reinforcing relationship by Link Analysis. Different from their work, in this paper, multi-level termhood such as term termhood and sentence termhood is integrated in the term extraction model trained by CRF model."
    }, {
      "heading" : "3.3. Experiment and Result Analysis",
      "text" : "(1) Training Data and Evaluation Method For lack of tagged English corpus, we only did experiment on Chinese text corpus to extract term with CRF model and several factors that influence the performance of term extraction is tested and analyzed.\nTagged Chinese corpus used in this paper is mainly article about computer and it is manually tagged with BIO (Begin, In, Out) tag, containing 1334 sentences, 15172 words and punctuations. There are 1910 manual-tagged terms (including repeated terms).\nThe common used evaluation merit for term extraction is precision, recall and F1 value. Assuming that there are n words in test set, extraction result can be represent as shown in table 3. This experiment splits manually-tagged results into two groups, that is terms manually tagged (word or phrase responsive to tag sequence “B-I-…”) and non-terms tagged manually (word or phrase before label “O”).\nPrecision\nba\na P\n+ = (5)\nPrecision P is the precision ration of term extraction. Precision indicates the ability of term extraction to get correct terms. The higher precision is, the less likely a term is a non-term.\nRecall\nca\na R\n+ = (6)\nRecall R is the ratio of tagged term and it indicates the ability of the term extraction\nsystem to find terms. The higher recall is, the less terms are untagged.\nF1 value\nRP\nPR RPF\n+ =\n2 ),(1 (7)\nF1 measurement is presented by van Rijsbergen which is the harmonic-mean of precision\nand recall (van Rijsbergen, 1979).\n10-fold cross-validated method is used in the experiment and P, R and F1 are employed\nfor evaluation. (2) Experiment Results and Analysis\nResult and Analysis of Multi-level Termhood\nTable 4 is the result of term extraction experiment that integrates multi-level termhood features.\nTable 4 shows that precision is improved when termhood of words in term is\nconsidered.\nWhen the simplest corpus comparison method, which uses frequency to compare domain and general corpus, is used, precision is 4% higher, and recall is 1% higher. When ranking value based corpus comparison method is used, the precision is 3% higher while recall drops greatly. When the way of difference is considered, corpus comparison method based on frequency and ranking is improved.\nThe performance of term extraction can also be improved but not significantly when\nranking value is enhanced by number.\nTable 4 shows that on the basis of frequency difference or rank value difference, when termhood of sentence (∆Freq_Sen or ∆Rank_Sen) which contains current candidate term is employed, F1 has no obvious change, yet recall is 1% higher. This illustrates that more terms can be found when termhood of sentences are considered as well as termhood of terms. And, among all termhood methods, the one which employs frequency difference of candidate terms and cumulative frequency difference of sentences which contains candidate terms get the highest F1 value and best performance.\nPrecision of term extraction improves slightly when frequency or ranking value of the\ncandidate term on domain and general corpus was integrated with their difference.\nAmong all termhood methods, the one that integrates frequency difference, ranking difference of candidate term in domain and general corpus, and cumulative frequency difference and ranking difference of the sentences that contains the candidate terms get the highest recall.\nExperiment result shows that termhood can enhance the performance of term extraction. Multiple differences can improve the precision of term extraction. Recall can be improved when termhood of sentences is employed.\nResult and Analysis of Different Features and Combination of Features\nTable 5 shows the result getting from different feature combination. It illustrates that the method employing word as the only feature performed the worst considering precision and recall. When POS was integrated, the results were improved. The performance was enhanced significantly when the frequency of word appearing in the domain and general corpus was considered.\nAmong all feature combinations, the methods employed POS, frequency, frequency difference and ranking difference of candidate terms on domain corpus and general\ncorpus has the highest precision. The methods employed frequency difference and ranking difference of candidate terms on domain corpus and general corpus, and cumulative frequency difference and ranking frequency of sentences which contains candidate terms achieved the highest recall. When frequency difference of candidate terms and cumulative frequency difference of sentences which contains candidate terms was used in extraction model, the corresponding F1 value is the highest."
    }, {
      "heading" : "4. BILINGUAL TERMINOLOGY ALIGNMENT BASED ON TERMHOOD",
      "text" : "CONSTRAINTS"
    }, {
      "heading" : "4.1. Using Termhood to Optimize the Bilingual Terminology Alignment",
      "text" : "The key idea of extracting bilingual terms from bilingual sentences-aligned corpus is that relevance is computed on the basis of co-occurrence of bilingual terms in a bilingual sentence-aligned corpus. POS and word frequency are often used in the process of bilingual word alignment to filter bilingual candidate terms. If the term in one language has high termhood, the corresponding term in other languages should also have high termhood.\nAccording to this assumption, termhood of Chinese and English candidate terms are used as constraints to study the alignment of Chinese-English terms. When computing relevance of bilingual terms, termhood and termhood ratio of Chinese-English terms are added as weights to compute the results of relevance.\nAssume Chinese word c, English word e, and their termhood, i.e. Termhood(c) and Termhood(e), after termhood ratio is integrated, their relevance which denoted as Association(c, e), turns to:\n)(*)(*\n} )(\n)( ,\n)(\n)( {\n),( )',( eTermhoodcTermhood\neTermhood\ncTermhood\ncTermhood\neTermhood Max\necnAssociatio ecnAssociatio =\n(8)\nGiven threshold θ, word pairs which satisfy )',( ecnAssociatio ≥θ or )',( ecnAssociatio\nare among the first k one is set to be the candidate term pairs.\nThe procedure of bilingual term alignment based on termhood constraints is as follows: After extracting bilingual terms from a domain parallel corpus, termhood is computed with Chinese-English bilingual general corpus and the relevance of Chinese-English terms is computed using termhood and termhood ratio as weights, and the alignment results with the first N relevance are the candidate bilingual term pairs. Bilingual termhood ratio can be used to constrain further on the basis of bilingual term alignment to filter candidate term pairs with termhood difference.\n4.2. Result and analysis of term extraction\n(1) Test Corpus and Evaluation Method The general corpus used in this experiment was the same one used in the project that tagged data from People’s Daily between Jan 1998 and Jun 1998 and English news corpus of NTCIR (http://research.nii.ac.jp/ntcir/) in 1998-2001. Domain corpus contains disserations in the infomation technology domain. More detail about corpus is shown in table 6.\nThe evaluation measure used in this paper is precision at first N words, denoted as P@N.\nAs shown in formula (9), P@N examines the ratio of correct alignments in the first N word alignment results\nN\nresult alignment N first the of alignment correct of Number P@N = (9)\nTwo types of checks were manually performed on the first N alignment results. First, four groups of bilingual term extraction experiments were conducted using 1000, 2000, 5000, and 10000 sentence pairs separately extracting from IT parallel corpus. In each group, extraction models used included N-Gram and CRF model (both of them are employed in Chinese term extraction and only N-Gram is used in English term extraction). Statistical relevance of bilingual terms was computed using Log likehood ratio (Dunning, 1993) and term-weighted Log likehood ratio.\nRelevance of bilingual candidate terms was computed by LogL likehood ratio. Given\nChinese word c, English word e and relevance LogL(c, e), term-weighted LogL is\n)(*)(*\n} )(\n)( ,\n)(\n)( {\n),( )',( eTermhoodcTermhood\neTermhood\ncTermhood\ncTermhood\neTermhood Max\necLogL ecLogL = (10)\nSecond, the results of Chinese-English term alignment and Chinese term extraction of terms with the first 500 relevance were manually annotated by four volunteers. The annotation was performed on the results of bilingual term extraction in the four corpora with different sizes. Based on the manual annotation, if the Chinese word is a term, the alignment of Chinese-English words was added and normalized, and precision P@N of Chinese-English term extraction was computed. (2) Analysis of Experiment Result Experiments in this section were carried out according to each scheme to obtain bilingualterm extraction and alignment results. Results of differnet scheme were manually evaluated according to the above-mentioned methods, and were compared and analyzed from two sides.\nTable 7 shows the precision of word alignment on parallel corpus with different sizes. Without termhood constraints, precision of word alignment using N-Gram model is actually better. However, termhood constraints have opposite effect on CRF model. It shows that the precision of alignment can be enhance by weighted termhood. By analyzing extraction results, we found that N-Gram model extracted more non-term words.\n5. CONCLUSION AND FUTURE WORKS\nThis paper discusses an innovative method for extracting bilingual terminology based on multi-level termhood. The multi-level termhood includes termhood of the terminology candidates and the sentence, and it is computed by the comparison of the corpus. This paper also put forward bilingual word alignment based on termhood constraint, and the termhood is used in the task of bilingual term extraction and alignment. Experiment results show that termhood constraints can enhance performance of term alignment.\nThe future work include: finding a method to compare corpora that are not limited by domain and background in computing termhood of candidate terminology; adding more features such as mutual information among words, chunking and semantics information to improve the precision of terminology extraction; using the Web to obtain background corpora to compute termhood and improve the recall of certain domain; employing integrated learning methods in the process to enhance the performance of terminology extraction system.\nThe future work that will be done about bilingual terminology alignment based on termhood constraint includes: optimizing results of bilingual term alignment with multi-level termhood; using more statistical relevance methods in computing multiple relevance of bilingual terms to have an integrated method for improving the precision of bilingual term alignment."
    } ],
    "references" : [ {
      "title" : "Surface grammatical analysis for the extraction of terminological noun phrases",
      "author" : [ "D. Bourigault" ],
      "venue" : "Proceedings of the 5th International Conference on Computational Linguistics (pp. 977-981)",
      "citeRegEx" : "Bourigault,? \\Q1992\\E",
      "shortCiteRegEx" : "Bourigault",
      "year" : 1992
    }, {
      "title" : "Domain Specific Word Extraction from Hierarchical Web Documents: A First Step toward Building Lexicon Trees from Web Corpora",
      "author" : [ "J.S. Chang" ],
      "venue" : "Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing (pp. 64-71)",
      "citeRegEx" : "Chang,? \\Q2005\\E",
      "shortCiteRegEx" : "Chang",
      "year" : 2005
    }, {
      "title" : "Word association norms, mutual information, and lexicography",
      "author" : [ "K.W. Church", "P. Hanks" ],
      "venue" : "Computational Linguistics,",
      "citeRegEx" : "Church and Hanks,? \\Q1990\\E",
      "shortCiteRegEx" : "Church and Hanks",
      "year" : 1990
    }, {
      "title" : "Study and implementation of combined techniques for automatic extraction of terminology",
      "author" : [ "B. Daille" ],
      "venue" : null,
      "citeRegEx" : "Daille,? \\Q1996\\E",
      "shortCiteRegEx" : "Daille",
      "year" : 1996
    }, {
      "title" : "Accurate methods for the statistics of surprise and coincidence",
      "author" : [ "T. Dunning" ],
      "venue" : "Computational Linguistics,",
      "citeRegEx" : "Dunning,? \\Q1993\\E",
      "shortCiteRegEx" : "Dunning",
      "year" : 1993
    }, {
      "title" : "Automatic recognition of multi-word terms",
      "author" : [ "K.T. Frantzi", "S. Ananiadou", "Mima H" ],
      "venue" : "The C-value/NC -value method. International Journal on Digital Libraries,",
      "citeRegEx" : "Frantzi et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Frantzi et al\\.",
      "year" : 2000
    }, {
      "title" : "Research On the Weighting of Indexing Sources for Web Concept Mining",
      "author" : [ "H.Q. Hou", "C.Z. Zhang", "H. Zheng" ],
      "venue" : "Jouranl of the China Society for Scientific and Technical Information,",
      "citeRegEx" : "Hou et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Hou et al\\.",
      "year" : 2005
    }, {
      "title" : "Confidence Measure for Word Alignment",
      "author" : [ "F. Huang" ],
      "venue" : "Proceedings of the Joint",
      "citeRegEx" : "Huang,? \\Q2009\\E",
      "shortCiteRegEx" : "Huang",
      "year" : 2009
    }, {
      "title" : "An Error-Sensitive Metric for Word Alignment in Phrase-based SMT",
      "author" : [ "S.J. Huang", "N. Xi", "Y.G. Zhao", "X.Y. Dai", "J.J. Chen" ],
      "venue" : "Journal of Chinese Information Processing,",
      "citeRegEx" : "Huang et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2009
    }, {
      "title" : "Termight: Identifying And Translating Technical Terminology",
      "author" : [ "D. Ido", "C.K. Ward" ],
      "venue" : "Proceedings of the fourth conference on Applied natural language processing (pp. 34-40)",
      "citeRegEx" : "Ido and Ward,? \\Q1994\\E",
      "shortCiteRegEx" : "Ido and Ward",
      "year" : 1994
    }, {
      "title" : "Technical terminology: Some linguistic properties and an algorithm for identification in text",
      "author" : [ "J.S. Justeson", "S.M. Katz" ],
      "venue" : "Natural Language Engineering",
      "citeRegEx" : "Justeson and Katz,? \\Q1995\\E",
      "shortCiteRegEx" : "Justeson and Katz",
      "year" : 1995
    }, {
      "title" : "Measuring mono-word termhood by rank difference via corpus",
      "author" : [ "C.Y. Kit", "X.Y. Liu" ],
      "venue" : "comparison. Terminology,",
      "citeRegEx" : "Kit and Liu,? \\Q2008\\E",
      "shortCiteRegEx" : "Kit and Liu",
      "year" : 2008
    }, {
      "title" : "Conditional Random Fields: Probabilistic Models for Segementing and Labeling Sequence Data",
      "author" : [ "J. Lafferty", "A. McCallum", "F. Pereira" ],
      "venue" : "Proceedings of the 18th International Conference on Machine Learning",
      "citeRegEx" : "Lafferty et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Lafferty et al\\.",
      "year" : 2001
    }, {
      "title" : "Statistical term-hood measurement for mono-word terms via corpus comparison",
      "author" : [ "X.Y. Liu", "C.Y. Kit" ],
      "venue" : "Proceedings of the Eighth International Conference on Machine Learning and Cybernetics (pp. 3499-3504)",
      "citeRegEx" : "Liu and Kit,? \\Q2009\\E",
      "shortCiteRegEx" : "Liu and Kit",
      "year" : 2009
    }, {
      "title" : "Mining ontologies from text",
      "author" : [ "A. Maedche", "S. Staab" ],
      "venue" : "Proceedings of the 12th International Conference on Knowledge Engineering and Knowledge Management (pp",
      "citeRegEx" : "Maedche and Staab,? \\Q2000\\E",
      "shortCiteRegEx" : "Maedche and Staab",
      "year" : 2000
    }, {
      "title" : "TRUCKS: A model for automatic multi-word term recognition",
      "author" : [ "D. Maynard", "Ananiadou S" ],
      "venue" : "Journal of Natural Language Processing,",
      "citeRegEx" : "Maynard and S.,? \\Q2000\\E",
      "shortCiteRegEx" : "Maynard and S.",
      "year" : 2000
    }, {
      "title" : "Corpus-based terminology extraction",
      "author" : [ "A. Patry", "P. Langlais" ],
      "venue" : "(Ed.) Terminology and Content Develpment - Proceedings of 7th International Conference On Terminology and Knowledge Engineering (pp. 313-321),",
      "citeRegEx" : "Patry and Langlais,? \\Q2005\\E",
      "shortCiteRegEx" : "Patry and Langlais",
      "year" : 2005
    }, {
      "title" : "Identification of relevant terms to support the construction of domain ontologies",
      "author" : [ "P. Velardi", "M. Missikoff", "R. Basili" ],
      "venue" : "Proceedings of the Workshop on Human Language Technology and Knowledge Management (pp. 18-28),",
      "citeRegEx" : "Velardi et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Velardi et al\\.",
      "year" : 2001
    }, {
      "title" : "Improving term extraction by system combination using boosting",
      "author" : [ "J. Vivaldi", "L. Màrquez", "Rodríguez H" ],
      "venue" : "Proceedings of the 12th European Conference on Machine Learning (pp",
      "citeRegEx" : "Vivaldi et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Vivaldi et al\\.",
      "year" : 2001
    }, {
      "title" : "Improving Term Extraction by Combining Different Techniques",
      "author" : [ "J. Vivaldi", "H. Rodríguez" ],
      "venue" : "Proceedings of the Workshop on Computational Terminology for Medical and Biological Applications (pp. 61-68),",
      "citeRegEx" : "Vivaldi and Rodríguez,? \\Q2000\\E",
      "shortCiteRegEx" : "Vivaldi and Rodríguez",
      "year" : 2000
    }, {
      "title" : "Improving domain-specific word alignment with a General Bilingual Corpus",
      "author" : [ "H. Wu", "H.F. Wang" ],
      "venue" : "Proceedings of the 6th Conference of the Association for Machine Translation in the Americas (pp",
      "citeRegEx" : "Wu and Wang,? \\Q2004\\E",
      "shortCiteRegEx" : "Wu and Wang",
      "year" : 2004
    }, {
      "title" : "Improving Statistical Word Alignment with Ensemble Methods",
      "author" : [ "H. Wu", "H.F. Wang" ],
      "venue" : "Proceedings of IJCNLP-05 (pp. 462-473)",
      "citeRegEx" : "Wu and Wang,? \\Q2005\\E",
      "shortCiteRegEx" : "Wu and Wang",
      "year" : 2005
    }, {
      "title" : "Alignment Model Adaptation for Domain-Specific Word Alignment",
      "author" : [ "H. Wu", "H.F. Wang", "Liu Z. Y" ],
      "venue" : "Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (pp. 467-474),",
      "citeRegEx" : "Wu et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2005
    }, {
      "title" : "Boosting Statistical Word Alignment Using Labeled and Unlabeled Data",
      "author" : [ "H. Wu", "H.F. Wang", "Liu Z. Y" ],
      "venue" : "Proceedings of Coling/ACL2006 Main Conference Poster Sessions (pp. 913-920)",
      "citeRegEx" : "Wu et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2006
    }, {
      "title" : "A Domain Adaptive Approach Automatic Acquisition of Domain Relevant Terms and their Relations with Bootstrapping",
      "author" : [ "F.Y. Xu", "D. Kurz", "J. Piskorski", "S. Schmeier" ],
      "venue" : "Proceedings of the 3rd International Conference on Language Resources an Evaluation (pp",
      "citeRegEx" : "Xu et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2002
    }, {
      "title" : "A delimiter-based general approach for Chinese term extraction",
      "author" : [ "Y.H. Yang", "Q. Lu", "T.J. Zhao" ],
      "venue" : "Journal of the American Society for Information Science and Technology,",
      "citeRegEx" : "Yang et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2010
    }, {
      "title" : "Measuring Termhood in Automatic Terminology Extraction",
      "author" : [ "Q.L. Zhang", "Q. Lu", "Z.F. Sui" ],
      "venue" : "Proceedings of the International Conference on Natural Language Processing and Knowledge Engineering (pp",
      "citeRegEx" : "Zhang et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2003
    }, {
      "title" : "Information Retrieval. London: Butterworths. Table1. Features of candidate terminology N o",
      "author" : [ "C.J. van Rijsbergen" ],
      "venue" : null,
      "citeRegEx" : "Rijsbergen,? \\Q1979\\E",
      "shortCiteRegEx" : "Rijsbergen",
      "year" : 1979
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "Linguistic features are used to restrain the candidate terminology, that is, terminology is filtered by linguistic features (Ido and Ward, 1994).",
      "startOffset" : 124,
      "endOffset" : 144
    }, {
      "referenceID" : 0,
      "context" : "(Bourigault, 1992) used shallow parsing to extract noun phrase that is a terminology.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 9,
      "context" : "(Ido and Ward, 1994) limited the candidate terminology to a string that represents the pattern of noun sequences.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 10,
      "context" : "(Justeson and Katz, 1995) used the prefix of terminology and selected strings whose prefix is noun to be candidate terms.",
      "startOffset" : 0,
      "endOffset" : 25
    }, {
      "referenceID" : 4,
      "context" : "For unithood, the approaches includes MI (Church & Hanks, 1990), LogL (Dunning, 1993) and left/right entropy (Patry & Langlais, 2005).",
      "startOffset" : 70,
      "endOffset" : 85
    }, {
      "referenceID" : 1,
      "context" : "C-value/NC value (Frantzi et al, 2000), inter-domain entropy (IDE) (Chang, 2005) and Domain Component Feature Set (DCFS) (Zhang et al, 2003) are employed.",
      "startOffset" : 67,
      "endOffset" : 80
    }, {
      "referenceID" : 3,
      "context" : "(Daille, 1996) used the linguistic methods to get candidate terms and set them as the input of statistical models.",
      "startOffset" : 0,
      "endOffset" : 14
    }, {
      "referenceID" : 7,
      "context" : "Relevant research includes the study on confidence measurement of word alignment by (Huang, 2009).",
      "startOffset" : 84,
      "endOffset" : 97
    }, {
      "referenceID" : 4,
      "context" : "Statistical relevance of bilingual terms was computed using Log likehood ratio (Dunning, 1993) and term-weighted Log likehood ratio.",
      "startOffset" : 79,
      "endOffset" : 94
    } ],
    "year" : 2011,
    "abstractText" : "Purpose: Terminology is the set of technical words or expressions used in specific contexts, which denotes the core concept in a formal discipline and is usually applied in the fields of machine translation, information retrieval, information extraction and text categorization, etc. Bilingual terminology extraction plays an important role in the application of bilingual dictionary compilation, bilingual Ontology construction, machine translation and cross-language information retrieval etc. This paper addresses the issues of monolingual terminology extraction and bilingual term alignment based on multi-level termhood. Design/methodology/approach: A method based on multi-level termhood is proposed. The new method computes the termhood of the terminology candidate as well as the sentence that includes the terminology by the comparison of the corpus. Since terminologies and general words usually have differently distribution in the corpus, termhood can also be used to constrain and enhance the performance of term alignment when aligning bilingual terms on the parallel corpus. In this paper, bilingual term alignment based on termhood constraints is presented. Findings: Experiment results show multi-level termhood can get better performance than existing method for terminology extraction. If termhood is used as constrain factor, the performance of bilingual term alignment can be improved. Originality/value: The termhood of the candidate terminology and the sentence that includes the terminology is used to terminology extraction, which is called multi-level termhood. Multi-level termhood is computed by the comparison of the corpus. The experiment results show that the multi-level termhood can get better performance than standard method. Bilingual term alignment method based on termhood constraint is put forward and termhood is used in the task of bilingual terminology extraction. Experiment results show that termhood constraints can improve the performance of terminology alignment to some extent.",
    "creator" : "Server http://www.activepdf.com"
  }
}