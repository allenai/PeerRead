{"conference": "ICLR 2017 conference submission", "title": "Unsupervised Deep Learning of State Representation Using Robotic Priors ", "abstract": "Our understanding of the world depends highly on how we represent it.  Using background knowledge about its complex underlying physical rules, our brain can produce intuitive and simplified representations which it can easily use to solve problems. The approach of this paper aims to reproduce this simplification process using a neural network to produce a simple low dimensional state representation of the world from images acquired by a robot. As proposed in Jonschkowski & Brock (2015), we train the neural network in an unsupervised way, using the \"a priori\" knowledge we have about the world as loss functions called \"robotic priors\" that we implemented through a siamese network. This approach has been used to learn a one dimension representation of a Baxter head position from raw images. The experiment resulted in a 97,7% correlation between the learned representation and the ground truth, and show that relevant visual features form the environment are learned.", "reviews": [{"is_meta_review": true, "comments": "This paper proposed to use unsupervised learning to learn features in a reinforcement learning setting. It is unclear what \"unsupervised\" means here since the \"causality prior\" uses reward signals for training. This is reinforcement learning, not unsupervised learning.\n\nThe experiments are also very premature. The task is as simple as moving the head of the robot left or right. There is also no comparison to baselines.\n\nIn conclusions section, the authors claim the proposed method can be used for transfer learning without experiments to backup the claim.\n\nOverall this paper is confusing and premature.", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "The authors apply an already-published method for state representation learning in a very simple experimental scenario. They give no additional contribution or comparison, nor do they offer any empirical or analytical study.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"TITLE": "Answer to reviewers", "OTHER_KEYS": "Timothee LESORT", "comments": "Dear reviewers,\n\nwe agreed that comparisons with other works need to be done and that other tasks have to be tested to improve evaluation and validation.\nIt will be done in future experiments.", "IS_META_REVIEW": false, "DATE": "19 Jan 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "Review", "is_meta_review": false, "comments": "This paper implements the method of Jonschkowski & Brock to learn a low-dimensional state representation represented as the last layer of a neural network. The experiments apply the method for learning a one-dimensional state representation of a simulated robot\u2019s head position from synthetic images.\n\nLearning state representations is an active and useful area of research for learning representations in interactive domains such as robotics. However, there seems to be no novelty in the method, over Jonschkowki & Brock. The primary contribution is the experimental evaluation performed on one task, where the paper evaluates the correlation between the learned state representation and the ideal state representation for the task (which is the robot\u2019s head position).\n\nAs acknowledged by the authors, the experiments are very preliminary, only showing one simple task with a one-dimensional learned representation and a two-dimensional discrete action space. To make the experiments compelling, there need to be comparisons to prior methods such as Lange et al. \u201912, Watter et al. NIPS \u201915, and Finn et al. ICRA \u201916 which also learn state representations from raw images. PCA on the images would also be a useful comparison, especially for simple tasks. Without these comparisons, it is impossible to evaluate the effectiveness of the method.\n\nLastly, as mentioned in the pre-review questions, the related work should include a discussion of other state representation learning methods such as Watter et al. NIPS \u201915, Finn et al. ICRA \u201916, and van Hoof et al. IROS \u201916.\n\nIn summary, this paper lacks novelty and significance, as the paper implements an existing method and demonstrates results on only one simple task. Without comparisons, the results are impossible to interpret. More challenging tasks and experimental comparisons would significantly improve the paper. Additionally, this paper does not introduce any novel contributions to state representation learning for solving challenges in this domain. One pro is that the paper is generally written clearly.", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Review", "is_meta_review": false, "comments": "The paper proposes to use the representation learning approach of [Jonschkowski & Brock, 2015] with a deep network as function approximator. The general task and approach are interesting, but contribution of this work is limited, and experimental evaluation is absolutely unsatisfactory, so the paper cannot be accepted for publications. \n\nThe approach is tested on a simple synthetic task with very small training and test sets and very little variation in the data. The authors admitted themselves that the results are preliminary. The proposed method is not compared with existing approaches or simple hand-crafted baselines. It is impossible to judge if the proposed method is useful and/or performs well compared to existing approaches. This makes the paper unfit for publication. \n\nWith proper experiments, and if the method works in interesting realistic scenarios, this could become a good paper.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "No Title", "is_meta_review": false, "comments": "This paper proposed to use unsupervised learning to learn features in a reinforcement learning setting. It is unclear what \"unsupervised\" means here since the \"causality prior\" uses reward signals for training. This is reinforcement learning, not unsupervised learning.\n\nThe experiments are also very premature. The task is as simple as moving the head of the robot left or right. There is also no comparison to baselines.\n\nIn conclusions section, the authors claim the proposed method can be used for transfer learning without experiments to backup the claim.\n\nOverall this paper is confusing and premature.", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Pre-Review Questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "is_meta_review": false}, {"TITLE": "pre-review questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "is_meta_review": false}], "SCORE": 3, "authors": "Timothee LESORT, David FILLIAT", "KEYWORDS": "This paper introduces a method for training a deep neural network to learn a  representation of a robot's environment state using a priori knowledge.", "accepted": false, "id": ""}
