{
  "name" : "1506.00893.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "jcr@dcc.fc.up.pt", "theo.mantadelis@dcc.fc.up.pt", "ines@dcc.fc.up.pt", "ricroc@dcc.fc.up.pt" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 6.\n00 89\n3v 1\n[ cs\n.A I]\n2 J\nun 2"
    }, {
      "heading" : "1 Introduction",
      "text" : "Statistical Relational Learning (SRL) [20] is a well-known collection of techniques whose main objective is to produce interpretable probabilistic classifiers, often in the form of readable logical sentences. While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge. In this work, we introduce SkILL – a Stochastic Inductive Logic Learner – which can combine the rule learning capability of classic Inductive Logic Programming (ILP) [11,16] with uncertain knowledge as probabilistic annotated data to produce First Order Logic (FOL) theories.\nILP is a machine learning branch which stands out due to its suitability to handle relational data. ILP’s main goal is to construct a theory which explains a set of observations (called examples), given a set of facts and/or rules which are of a relational nature (called background knowledge). The induced theory can then be used for prediction (as it can output probability values for a given example) as well as classification (as it can also output the specific categorical label for an example). Probabilistic Inductive Logic Programming (PILP) [20]\nextends discrete ILP by considering background knowledge and/or examples that are annotated with probabilities. This is a natural extension of ILP and can in fact model different semantic scenarios, according to the meaning that is assigned to the probabilities.\nUsing probabilities to describe data has the potential advantage of greatly reducing the dataset size, since useful information can still be extracted from marginal distributions. Also, in cases where the full conditional probability table is not known, information can still be used efficiently in the computation of a rule, for instance, by adding values from the literature in this form to the background knowledge. Compressing data in such a way could also be used in order to protect private sensitive data. There are surely several other scenarios in which probabilities can be applied and taken advantage of. Throughout this work, probabilities will be used as marginal distributions (motivational example), as a transformation of a numeric attribute in discrete data (metabolism dataset), and as an empirical confidence (non-definitive biopsies dataset).\nSkILL can not only use all these types of probabilistic data but it also addresses efficiency issues by introducing a novel, efficient and effective search strategy to guide the search for FOL theories. SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language. Knowledge is thus annotated according to ProbLog syntax and the MetaProbLog engine is used to evaluate the probabilities of the generated theories.\nThe remainder of this paper is organized as follows. First, a toy example is introduced to motivate the transition between ILP and PILP, followed by a description of related work. Next, we present the SkILL system and focus on some efficiency issues. Then, two experiments are performed to assess SkILL’s performance, followed by a discussion of results and the conclusion."
    }, {
      "heading" : "2 Motivational Example",
      "text" : "Rock-paper-scissors is a game where two players each play one of the three objects - either rock, paper or scissors - simultaneously, through movements of their hands, and the winner is chosen based on the rules presented in Fig. 1 (which use the Prolog syntax).\nIf data of this game were recorded, it would contain players’ choices of objects for each round as well as the result of each game. This is illustrated in Fig. 2, where the first argument represents each round (consecutive integers), the second argument is the player (playerA, playerB and playerC), and the third argument corresponds to each player’s outcome (rock, paper or scissors ). Predicate beats/3 represents for each round (first argument) which player is the winner (second argument), and which one is the loser (third argument).\nTraditional ILP can be used in this problem as is to induce the rules of the game. This formulation of the problem is trivial for an ILP engine and it can take as few as three examples to learn the three rules of the game.\nSkILL allows for inducing the same set of rules from different background knowledge (BK) information. Suppose the information about each round was not available and that all available information was the profile/strategy of a given player (how often does he/she play each object) and how often did that player win against other players. This setting carries much less information because nothing is known about the sequence of games or against whom a player played; only the marginal distributions are known. Figure 3 presents an example of this new form of BK, where semi-colon has the meaning of an exclusive-or connective (different from the Prolog syntax).\nIn Fig. 3, rules are annotated according to Halpern’s type 1 probability structure [5], where numbers on the left correspond to values of the game domain, which can be interpreted as the frequency with which each event happens. Predicates plays and beats have now only 2 arguments because the frequencies of the rounds are no longer relevant to the problem.\nExperiments were made by annotating simulated games based on random player profiles and SkILL induced the rules presented in Fig. 1 from information about the profiles of players using as little as 10 observations and three players."
    }, {
      "heading" : "3 SkILL",
      "text" : "SkILL is a tool which can extract non-trivial knowledge (FOL theories) from probabilistic data. As is the case of ILP systems, SkILL’s setting includes three main components:\nProbabilistic Background Knowledge (PBK) represents the basic information known about the problem and can be composed of both rules and facts, either probabilistic or not. Probabilistic Examples (PE) represent the observations the system is attempting to explain. In the classical ILP setting there can be positive and negative examples, but in the probabilistic setting that information must be encoded as probabilities. These probabilities are the expected values of examples and can represent either statistical information or the degree of belief in an example (using type I or type II probability structures [5], respectively). Search Space Constraints mode declarations used to guide the search, whose aim is to minimize a loss function.\nSince search spaces are often too large, a common approach is to guide the search by using strategies that can lead to good hypotheses without exhaustively traversing all the search space. SkILL introduces a novel, efficient and effective search strategy to guide the search in PILP environments."
    }, {
      "heading" : "3.1 Traversing the Search Space",
      "text" : "Algorithm 1 presents SkILL’s main algorithm. The algorithm takes as input the probabilistic background knowledge (PBK) and a set of examples (PE) plus parameters corresponding to the maximum length of a theory (or set of hypotheses) to be generated (MaxTheoryLength), the number of hypotheses to be combined in order to limit the search space (Psize and Ssize), a metric to rank the selection of hypotheses to be combined (RankMetric), and a final metric that is used to decide what is the best theory found (EvalMetric).\nAlgorithm 1: SkILL Algorithm\n1 Input = PBK, PE, MaxTheoryLength, Psize, Ssize, RankMetric, EvalMetric 2 Output = Best theory according to EvalMetric 3 Hyps1 = HypsN = AllHyps = generate hypotheses length one(PBK, PE) 4 for Length = 2; Length ≤ MaxTheoryLength; Length++ do 5 Primary = select primary set(HypsN, Psize, RankMetric) 6 Secondary = select secondary set(Hyps1, Ssize, RankMetric) 7 HypsN = generate combinations(Primary, Secondary) 8 AllHyps = AllHyps ∪ HypsN\n9 end 10 return best theory(AllHyps, EvalMetric)\nInitially, the algorithm uses the TopLog engine from the GILPS [17] ILP system, to generate all possible hypotheses composed of only one clause (line 3 in Alg. 1). A top level generic hypothesis is constructed from the mode declarations in the PBK and possible hypotheses are generated independently from each example using SLD refutation. This approach ensures that each hypothesis generated must be entailed by at least one example, and so the hypotheses mirror patterns contained in the observations with respect to the PBK. SkILL improves on this approach by removing hypotheses which are permutations of each other (i.e., syntactically distinct but semantically equal), so that probabilistic inference is only performed over semantically unique hypotheses.\nOnce hypotheses with length one are generated, the algorithm proceeds by generating hypotheses with length greater than one (lines 4–9 in Alg. 1) until reaching a given maximum theory size (argument MaxTheoryLength). Combining hypotheses in order to generate new hypotheses with larger size is not a trivial task – possible combinations are ( N\nK\n)\nwith N being the total number of length one hypotheses and K the maximum theory size. Ideally, an exhaustive search of the hypotheses space would be performed, but this is computationally taxing, particularly as the theory size grows. Therefore, SkILL’s search strategy selects candidate hypotheses for two different sets, named Primary and Secondary, and new hypotheses are then generated by only combining members of these sets. To do so, for each theory length, the algorithm first selects the Primary and Secondary sets of hypotheses, with sizes equal to arguments Psize and Ssize, respectively (lines 5–6 in Alg. 1), and then it performs the combinations (line 7 in Alg. 1). This procedure repeats until generating hypotheses for all lengths.\nSkILL’s selection procedure has two main goals: (i) reduce the number of combinations to be generated without losing the good hypotheses in the process and (ii) introduce some stochastic behavior by giving identical opportunity to weaker rules whose combination can be of interest. The primary and secondary sets can be seen as a way to materialize these two goals, respectively.\nThe primary set of hypotheses is considered to be the most relevant, i.e., the one holding the best set of hypotheses according to a given ranking metric (argument RankMetric). In each iteration of the algorithm, the primary set is filled with the Psize best hypotheses from the set of hypotheses generated in the previous iteration (1 clause hypotheses when searching for 2 clauses hypotheses; 2 clauses hypotheses when searching for 3 clauses hypotheses; etc). To rank hypotheses, SkILL supports three metrics: RMSE (root mean square error), PAcc (probabilistic accuracy) and Random.\nThe secondary set is filled with Ssize hypotheses from the set of hypotheses with length one. The aim of the secondary set is to include very different candidate hypotheses whose combination with the hypotheses from the primary set can be of interest. Priority to full stochastic behaviour can be given by randomly selecting all the hypotheses for the secondary set, or a selection based on best set of hypotheses according to the given ranking metric can be made. Additionally, both approaches can be combined in order to obtain a more heterogeneous set.\nIn particular, the experimental results presented used a mixed scenario where the secondary set always includes the Psize best hypotheses with one clause (i.e., the hypotheses selected for the first primary set) plus (Ssize - Psize) randomly selected distinct candidates from the remaining hypotheses with one clause. This stochastic component of the selection is distinct for each iteration.\nFinally, according to a given evaluation metric (argument EvalMetric), the best generated hypothesis for all different lengths is returned (line 10 in Alg. 1)."
    }, {
      "heading" : "3.2 Evaluation Metrics",
      "text" : "Currently, SkILL implements the RMSE and PAcc metrics. These metrics can be used to rank and/or evaluate hypotheses, as mentioned earlier. Since, from the point of view of SkILL’s algorithm, the ranking and evaluation phases are independent, we have chosen to introduce two different metric arguments instead of only one. By doing this, we not only highlight that independence but also do not restrict possibly different metric combinations.\nThe RMSE metric penalizes predictions farther from the expected values, while PAcc is the generalization of the discrete accuracy to the probabilistic setting as introduced by De Raedt and Thon [21] and used by Muggleton [15].\nThe RMSE of a hypothesis H can be defined as:\nRMSEH = 1\n|PE|\n∑\nei∈PE\n(PH(ei)− P (ei)) 2\n(1)\nwhere, PH(ei) denotes the probability that H together with the PBK entails an example ei, and P (ei) denotes the given expected value of an example ei.\nThe PAcc of a hypothesis H is often represented in terms of true positive (TP ), true negative (TN), false positive (FP ) and false negative (FN) examples, as shown in Equation 2.\nPAccH = TP + TN\nTP + TN + FP + FN (2)\nFrom [21], TP +TN+FP +FN = |PE|, and TP and TN are equal to the sum over all examples of min(PH(ei), P (ei)) and min(1−PH(ei), 1−P (ei)), respectively. Substituting into Equation 2, this gives that PAcc can be also represented in terms of the absolute average error between predictions and expected values, as shown in Equation 3.\nPAccH = 1\n|PE|\n∑\nei∈PE\n(min(PH(ei), P (ei)) +min(1− PH(ei), 1− P (ei)))\n= 1\n|PE|\n∑\nei∈PE\n(min(PH(ei), P (ei)) + 1−max(PH(ei), P (ei))\n= 1\n|PE|\n∑\nei∈PE\n(1− |PH(ei)− P (ei)|)\n=1− 1\n|PE|\n∑\nei∈PE\n|PH(ei)− P (ei)|\n(3)\nAs presented in Equation 4, both metrics can also be defined based on a common loss function lossH(ei) = PH(ei) − P (ei), which calculates the difference between the probabilistic expected value of an example and the value that can be predicted w.r.t a given hypothesis and the PBK.\nRMSEH = 1\n|PE|\n∑\nei∈PE\nlossH(ei) 2\nPAccH = 1− 1\n|PE|\n∑\nei∈PE\n|lossH(ei)|\n(4)\nHence, the aim of SkILL’s search engine is to find the hypothesis with minimum RMSE or maximum PAcc in the search space."
    }, {
      "heading" : "3.3 Pruning Combinations",
      "text" : "PILP shares a similar hypothesis search space as an ILP problem where all examples are expected to be true. The difference between the approaches lies obviously in the evaluation of hypotheses; in the first case it is a number between 0.0 and 1.0 representing a probability, whilst in the latter it is either true or false.\nTheories in ILP are constructed by combining several hypotheses through logic conjunction (∧) and disjunction (∨). Let H1, H2 be hypotheses; the hypothesis resulting from conjuncting H1 with H2 is more specific than either H1 or H2, while the disjunction of H1 and H2 is more general than either H1 or H2. Equation 5 shows how an example ei could be entailed by a disjunction in terms of two hypotheses H1 and H2.\nH1 ∨H2 |= ei ⇒H1 ∧ H̄2 |= ei OR\nH̄1 ∧H2 |= ei OR\nH1 ∧H2 |= ei\n(5)\nEquation 5 can be extended to the probabilistic case using the principle of inclusion/exclusion as follows. In the probabilistic scenario, the probability of a hypothesis PH represents the probabilistic mass covered by PBK ∪H |= true, which can range between 0 and 1. As such, the probability of a disjunction of hypotheses can be calculated according to the expression shown in Equation 6.\nPH1∨H2(ei) = PH1(e1) + PH2(ei)− PH1∧H2(ei) (6)\nThe PH1∧H2(ei) term of Equation 6 is the probability of both hypotheses (conjunction) entail the example. From set theory, three particular cases are known, namely: completely overlapping, independent or disjoint masses, and these can be calculated according to the expressions in Table 1. By analysing Table 1, it\nbecomes evident that the probability of the disjunction of two hypotheses has\nclear minimum and maximum boundaries, derived from the cases of completely overlapping and disjoint masses, respectively.\nPH1∨H2(ei) ∈ [max(PH1(ei), PH2(ei)),min(PH1(ei) + PH2(ei), 1.0)] (7)\nThe boundaries stated in Equation 7 make it possible to prune combinations of hypotheses whose interval of results does not contain the expected value for that example. SkILL can use these boundaries to prune combinations in two different contexts: (a) before probabilistic inference, to avoid performing such computations on some combinations, and (b) after probabilistic inference, to remove combinations found to be bad after inference. This is part of the generate combinations() function as illustrated in Algorithm 2. Functions possibly good combination() and good combinations() at lines 8 and 15 in Alg. 2 implement each pruning strategy, respectively.\nAlgorithm 2: Function generate combinations()\n1 Input = Primary and Secondary sets 2 Output = Combination of (not pruned) hypotheses from both sets 3 begin 4 HypsN = {} 5 foreach Hp in Primary do 6 foreach Hs in Secondary do 7 Hnew = Hp ∨Hs 8 if possibly good combination(Hnew) then 9 H(new,prob) = do problog inference(Hnew)\n10 HypsN = HypsN ∪ H(new,prob) 11 end"
    }, {
      "heading" : "12 end",
      "text" : ""
    }, {
      "heading" : "13 end",
      "text" : ""
    }, {
      "heading" : "14 end",
      "text" : "15 return good combinations(HypsN)\nFinding the best pruning strategies to use these boundaries is not evident, since we must take into account the predictions of a hypothesis for all examples. Because data will most likely not be completely independent or completely mutually exclusive, the strategies must consider that the contribution of a hypothesis in a combination of two hypotheses varies greatly and so care must be taken not to prune away rules which might have been important. This concept is better illustrated in Fig. 4.\nFigure 4(a) shows the case of combination of hypotheses, where the shaded area represents the possible contribution of the disjunction of hypotheses and the blue points are the estimated values PH1∨H2(ei) for the disjunction, which in the case of our function possibly good combination() are the values in the center of that interval.\nSince hypotheses are being combined using disjunctions, the value of the combination for one particular example ei can only be greater or equal than the value of any of the hypotheses in the combination. As such, combinations of hypotheses whose result is lower than the expected values are in principle of greater interest for combination than others. Figure 4(b) shows the case of a good and a bad hypothesis according to this principle. SkILL’s pruning functions possibly good combination() and good combinations() reflect this by discarding the combinations Hnew whose estimated contribution is overall less than the expected values P (ei), as shown by Equation 8.\n∑\nei∈PE\nPHnew (ei)− P (ei) > 0 (8)"
    }, {
      "heading" : "4 Experimental Settings",
      "text" : "The foremost focus of SkILL is the discovery of non-trivial knowledge from a dataset in order to explain observations. The quality of the knowledge discovered is currently evaluated by two different metrics (probabilistic accuracy or RMSE).\nFurthermore, the FOL theories found by SkILL can also be used in classification by introducing a threshold. The threshold could be learned from the original observations or be arbitrary chosen. This approach has a benefit over classical ILP (such as Aleph) in its capability to cope with noise in the data.\nAs such, this work presents experiments of both types: the metabolism dataset is used to evaluate the classification accuracy of the system, and a medical dataset of non-definite biopsies is used as the basis for extraction of non-trivial knowledge in this domain.\nAccuracy is used to evaluate the classifiers, using the standard formula in the discrete case (Aleph) and its probabilistic extension as presented in Section 3 for the probabilistic case (SkILL)."
    }, {
      "heading" : "4.1 Classification",
      "text" : "The dataset used to assess SkILL’s classification accuracy is the metabolism dataset, and is taken from the 2001 KDD Cup Challenge1. Although the challenge involved learning 14 different protein functions, this experiment focuses on a subtask that is to predict which proteins are responsible for metabolism. For this purpose, we use a subset of the full dataset containing 230 examples split evenly between positives and negatives. Since the dataset is originally discrete, a normalization to the interaction (gene1, gene2, type, strength) fact in the BK was made: interaction ’s fourth argument is a numerical argument which represents the strength of the interaction between two genes. By transforming interaction ( gene1, gene2, type, strength) to strength norm:: interaction (gene1, gene2, type), not only the search space of hypotheses is reduced (because that feature is no longer directly considered in the hypotheses generation process), but also predicates used to typically compare numerical features in ILP are made redundant in this case, since SkILL implicitly attempts to find the hypotheses with the best fit to the examples, taking into account the probabilities of the facts in the PBK. Finally, we converted the examples from discrete true/false to probabilistic with 1.0/0.0 probabilities respectively.\nMetabolism is a fairly small dataset: it is composed of 230 examples (half positive and half negative) and approximately 7000 BK facts, of which 3̃200 are probabilistic. As such, 30 70-30 bootstraps were generated and the results presented for all experiments are the average and standard deviation over the 30 bootstraps test sets (70% of each booststrap cases were used for training and 30% for test). Since SkILL provides several configuration options, various scenarios were tested in order to compare the results among them. Results presented for the Aleph system [24], are collected with the default parameters (except noise, which is set to maximum). However, since the BK of metabolism has been altered, the systems are not working with comparable data, and so these values are meant to be merely informative.\nTable 2 presents a comparison between using a pruning strategy and exhaustively combining Primary (20 hypotheses) against Secondary (200 hypotheses), for hypotheses until size 3. The number of hypotheses of size 1 of the training sets ranges from 2000 to 3000, and so Secondary represents about 10% of hypotheses, while Primary represents 1%. This table also presents discrete ILP results using Aleph’s default configuration and allowing for maximum noise.\nThe results in Table 2 show that driving the search with PAcc metric (both for evaluation and ranking) produces better classification results (2-tailed t-test, p = 0.04) than both the discrete case and when using RMSE as a ranking metric. We believe that penalizing greater distances from the expected values (like when using RMSE) produces worse results accuracy-wise because of overfitting the training dataset.\nTable 3 studies the effect of varying the sizes of Primary and Secondary, and how their accuracy and RMSE relate to the sizes of these sets for different ranking metrics.\nFrom Table 3, it becomes evident that all PAcc measurements are the same - this is because the best classifier for this dataset is always a hypothesis of length one, and therefore is always considered independently of the population and the ranking metric. None of the candidate hypotheses of length greater than one results in a better accuracy for this evaluation metric. However, when using the RMSE evaluation metric, many different hypotheses are generated, for different training datasets. Again, this substantiates the notion that the RMSE evaluation metric may be causing overfitting. These results also indicate that the difference between using a random or RMSE ranking criterion is negligible for small populations sizes (2-tailed t-test with p=0.47 and p=0.89 for 10/100 and 20/200, respectively). This happens because the best hypotheses ranked by RMSE are not good candidates for combination in this case, so the random hypotheses are in fact being used in most cases. In the case of 30/300 population, the RMSE ranking shows an improvement in the results, but at the cost of longer runtime. A random ranking strategy does not require that the population be ordered, and when the size of generated hypotheses grows, so does the time spent in ordering them."
    }, {
      "heading" : "4.2 Knowledge extraction",
      "text" : "Breast cancer diagnosis guidelines suggest that patients presenting suspicious breast lesions should be sent to perform a diagnostic mammogram and possibly an ultrasound, and a core needle biopsy to further define this abnormality. The biopsy is very important in determining malignancy of a lesion and usually yields definitive results; however, in 5% to 15% of cases, the results are nondefinitive [19]. Routine practice usually sends all patients with non-definitive biopsies to excision, even though only a small fraction of them (10-20%) have in\nfact a malignant finding confirmed after the procedure - the remainder of them did not need to be subjected to surgery. In the US this represents approximately 35,000 to 105,000 women who likely underwent excision and a majority of them ultimately received a benign diagnosis.\nAlthough non-definitive biopsies are relatively rare, sending every woman that has a non-definitive biopsy to excision is not a good practice. Machine learning methods have been used to mitigate this and other problems by allowing to produce models of the data that can distinguish between benign and malignant cases [10,3]. However, in the medical domain it is crucial to represent data in a way that experts can understand and reason about, and as such ILP can successfully be used to produce such models. Furthermore, probabilistic ILP allows for incorporating in the PBK the confidence of physicians in observations and known values from the literature.\nIn this study, we use 130 biopsies dating from January 2006 to December 2011, which were prospectively given a non-definitive diagnosis at radiologichistologic correlation conferences. 21 cases were determined to be malignant after surgery, and the remaining 109 proved to be benign. For all of these cases, several sources of variables were systematically collected including variables related to demographic and historical patient information (age, personal history, family history etc), mammographic BI-RADS descriptors (mass shape, mass margins, calcifications etc), pathological information after biopsy (type of disease, if it is incidental or not, number of foci etc), biopsy procedure information (needle gauge, type of procedure etc), and other relevant facts about the patient. Probabilistic data was also gathered: namely the confidence in malignancy for each case (before excision), assigned by different physicians analysing that case. Furthermore, and since physicians base their conclusions in literature values from the universe of all biopsies, values were added in the PBK as the probability of malignancy given a feature value (is malignant features). For example, it is well known among radiologists expert in mammography that if a mass has a spiculated margin, the probability that the associated finding is malignant is around 90%.\nTwo kinds of experiments were performed on this dataset: (i) the malignancy experiment consisted of finding theories by using as examples a discrete class variable malignancy determined after excision (either malignant or not), and (ii) malignancyPH experiments using as examples the probabilities assigned by different physicians (PH1, PH2, PH3) to the malignancy of each case. The resulting theories are presented in Figure 5. These experiments were performed on the full training set, since they were intended to be exploratory. For each classifier, we report accuracy on the full training set only to illustrate differences between the different classifiers. Figure 5 shows the best hypotheses found using: PAcc metric both for ranking and evaluation; primary/secondary population of 20/200; and generating hypotheses until length 3. The malignancy predicate is the best classifier found for malignancy of a tumour (experiment (i), accuracy = 88%). Probabilistic BK did not play an important role in this task, since the class variable is deterministic. Nevertheless, SkILL managed to find a good rule\nthat combines a variable/value indicative of malignancy: the presence of atypical ductal hyperplasia (aDH), with neutral variables such as the presence of mass or calcification distribution grouped (distrib Grp).\nPredicates malignancyPH are the classifiers found for experiment (ii) (accuracies of 94%, 95% and 86%, respectively). In all malignancyPH rules, at least one of the probabilistic literals is present. For example, the probabilistic literal that corresponds to a tumour of oval shape, which is highly correlated with malignancy, appears in malignancyPH1 and malignancyPH2. The same happens to the literal that represents the probability of malignancy of a tumour having an irregular shape, which appears in malignancyPH3. These results express the different mental models associated with each physician. These rules seem to indicate that some physicians give more weight to shape irregular while others give more importance to shape oval, besides giving weight to the Fibroepithelial lesions fibro . One of the great outcomes of these rules is that they can be combined and perhaps produce an even better model for all physicians.\nWhile it was not evident, the system found that a length 1 theory was sufficient to describe best the datasets studied, which is very important, specially in the case of the medical dataset, since physicians need to spend less time sieving through smaller rules. However, it is obvious that there exist problems that would require classifiers with multiple rules such as the motivational example of Section 2. In this aspect, SkILL takes advantage of its clever search and pruning of hypotheses combinations, being able to explore a more qualitative portion of the full space, whilst being able to perform both classification and prediction, efficiently extending the classical ILP approach."
    }, {
      "heading" : "5 Related Work",
      "text" : "The PILP setting was first introduced in [20], where three distinct settings – extended from traditional ILP [11] – are put forward: probabilistic entailment,\nprobabilistic interpretations, and probabilistic proofs. Later, Raedt and Thon presented the system ProbFOIL [21], which is not only capable of performing induction over probabilistic examples, but also on background knowledge encoded as ProbLog probabilistic facts. A number of relevant metrics such as precision, accuracy and m-estimate are adapted from the discrete ILP domain for use in the new setting, and ProbFOIL’s search for a hypothesis is guided based on probabilistic accuracy of the theories. This system then presents a proof of concept by analyzing two toy examples and extracting First Order Logic (FOL) rules about them. However, this system does not take advantage of the probabilistic data in order to tune its search engine, using simply an extension of an ILP algorithm with a different loss function.\nProbabilistic Explanation Based Learning (PEBL) [7] can find the most likely FOL clause which explains a set of positive examples in terms of a database of probabilistic facts. The explanation clause is the combination of predicates which yields the highest probability based on the examples, and is found by constructing variabilized refutation proofs for the given examples using SLD resolution. However, since PEBL is a deductive system, information about the expected structure of the explanation should be provided as predicates (which are often recursive).\nOrthogonally, Markov Logic Networks (MLNs) [22] also combine structure learning using a FOL framework with a probabilistic Markov Random Fields approach [9]. An MLN is a set of pairs of logic formulae and weights, where the latter are calculated based on the number of true groundings of the respective formula. Pairs sharing at least one variable in the same grounding are connected by an edge, and in fact an MLN can be thought of as generating a grounded Markov Network for each possible set of facts. Structure learning of MLNs can be done by altering the logic search space by (i) adding or removing one or more literals from a logic formula in a pair and (ii) inverting predicate symbols of a formula; both techniques are similar to operations performed in traditional ILP structure learning. Structure learning for MLNs softens the hypotheses by using probabilities and as such produces better classifiers, as shown in [9]; however, MLNs still consider crisp background knowledge, not taking into account the possibility of probabilistic logic facts. Additionally, and whilst MLNs are capable of structure learning, the final classifier is an MLN itself, which does not have the advantage of readability, especially when problem sizes are larger.\nFinally, Meta-Interpretive Learning [15] – which is a technique aimed at performing predicate invention in ILP using abduction – can also be used to perform probabilistic structure learning by calculating prior and posterior distributions on the hypotheses space according to the examples explained by a given hypothesis [14]. Meta-Interpretive Learning makes it possible to use Bayesian theory to both sample the hypotheses space and evaluate hypotheses according to their coverage of examples. Hypotheses search space can then be summarized as a super-imposed logic program, where the arcs connecting atoms contain the sum of all arcs for each individual hypothesis. As such, this approach can learn simultaneously the structure of the arguments of the meta rules and the parameters of\nthe super-imposed logic program. This approach is similar to structure learning for MLNs in the sense that a relation exists between simultaneously grounded entities in the data and that hypotheses are ranked according to how many of these possible configurations they explain. However, probabilistic background knowledge is also not supported by meta-interpretive learning, since it does not support probabilistic facts."
    }, {
      "heading" : "6 Conclusions",
      "text" : "This work presented the PILP learner SkILL, which extends classic ILP learners by incorporating probabilistic facts and rules in its BK, as well as by using probabilistic examples. There are different semantics which can apply to probabilistic data, and a toy example of probabilities used as marginal distributions was presented to motivate the use of data annotated with probabilities. Then, some details on the setting SkILL uses were presented, namely focusing on the strategy to traverse the search space, the evaluation metrics applied to hypotheses and how to efficiently prune the search. SkILL generates theories by combining hypotheses using a ranking metric and always maintaining a number of random hypotheses so as to ensure that weaker candidates are still considered. The evaluation metrics used to select the best hypotheses and to guide the search are probabilistic accuracy (PAcc) and root mean square error (RMSE); they differ because RMSE penalizes more heavily greater errors. Since SkILL works on probabilistic data, a pruning strategy based on set theory and the principle of inclusion/exclusion was devised and implemented with the aim of increasing efficiency in the system. SkILL’s classification performance was assessed using a subset of the metabolism dataset after some data were adapted to probabilities. Experiments show that SkILL’s accuracy performance is better than that of the discrete ILP system Aleph, and that the pruning strategy does not significantly alter SkILL’s final results. Finally, SkILL was used to extract non-trivial knowledge from a dataset of non-definitive biopsies annotated with probabilistic literature values. Results show that rules generated from data annotated with physicians degrees of belief vary, but agree with medical literature values. We have been working on the validation of these rules on a new unseen biopsy dataset."
    } ],
    "references" : [ {
      "title" : "The YAP Prolog System",
      "author" : [ "V. Santos Costa", "R. Rocha", "L. Damas" ],
      "venue" : "Journal of Theory and Practice of Logic Programming, 12(1 & 2):5–34,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "ProbLog: A probabilistic prolog and its application in link discovery",
      "author" : [ "Luc De Raedt", "Angelika Kimmig", "Hannu Toivonen" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2007
    }, {
      "title" : "Predicting Malignancy from Mammography Findings and Image-Guided Core Biopsies",
      "author" : [ "P. Ferreira", "N. Fonseca", "I. Dutra", "R. Woods", "E. Burnside" ],
      "venue" : "International Journal of Data Mining and Biomedicine,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Evaluating inference algorithms for the prolog factor language",
      "author" : [ "T. Gomes", "V. Santos Costa" ],
      "venue" : "In Fabrizio Riguzzi and Filip Železný, editors, Inductive Logic Programming, volume 7842 of Lecture Notes in Computer Science, pages 74–85. Springer Berlin Heidelberg,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "An Analysis of First-Order Logics of Probability",
      "author" : [ "J. Halpern" ],
      "venue" : "Artificial intelligence, 46(3):311–350,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "Basic principles of learning bayesian logic programs",
      "author" : [ "K. Kersting", "L. De Raedt" ],
      "venue" : "In Probabilistic Inductive Logic Programming - Theory and Applications, pages 189–221,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Probabilistic Explanation Based Learning",
      "author" : [ "A. Kimmig", "L. De Raedt", "H. Toivonen" ],
      "venue" : "In European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, pages 176–187. Springer,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "On the Implementation of the Probabilistic Logic Programming Language ProbLog",
      "author" : [ "A. Kimmig", "B. Demoen", "L. De Raedt", "V. Santos Costa", "R. Rocha" ],
      "venue" : "Theory and Practice of Logic Programming, 11(2 & 3):235–262,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Learning the Structure of Markov Logic Networks",
      "author" : [ "S. Kok", "P. Domingos" ],
      "venue" : "In International Conference on Machine learning, pages 441–448. ACM,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Using Machine Learning to Identify Benign Cases with Non-Definitive Biopsy",
      "author" : [ "F. Kuusisto", "I. Dutra", "H. Nassif", "Y. Wu", "M. Klein", "H. Neuman", "J. Shavlik", "E. Burnside" ],
      "venue" : "In International Conference on e-Health Networking, Application & Services, page 283–285, Lisbon, Portugal, October",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Relational Data Mining",
      "author" : [ "N. Lavrac", "S. Dzeroski" ],
      "venue" : "Springer, September",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Efficient Algorithms for Prolog Based Probabilistic Logic Programming",
      "author" : [ "T. Mantadelis" ],
      "venue" : "PhD thesis, Katholieke Universiteit Leuven, November",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Nesting probabilistic inference",
      "author" : [ "T. Mantadelis", "G. Janssens" ],
      "venue" : "Computing Research Repository, abs/1112.3785,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "MetaBayes: Bayesian Meta-Interpretive Learning using Higher-Order Stochastic Refinement",
      "author" : [ "S. Muggleton", "D. Lin", "J. Chen", "A. Tamaddoni-Nezhad" ],
      "venue" : "In Inductive Logic Programming, pages 1–17. Springer,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Meta-interpretive learning: application to grammatical inference",
      "author" : [ "S. Muggleton", "D. Lin", "N. Pahlavi", "A. Tamaddoni-Nezhad" ],
      "venue" : "Machine learning,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Inductive Logic Programming: Theory and Methods",
      "author" : [ "S. Muggleton", "L. De Raedt" ],
      "venue" : "Journal of Logic Programming, 19/20:629–679,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "TopLog: ILP Using a Logic Program Declarative Bias",
      "author" : [ "S. Muggleton", "J. Santos", "C. Almeida", "A. Tamaddoni-Nezhad" ],
      "venue" : "In International Conference on Logic Programming, pages 687–692. Springer,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Stochastic logic programs. In New Generation Computing",
      "author" : [ "Stephen Muggleton" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1996
    }, {
      "title" : "Malignancy rates after surgical excision of discordant breast biopsies",
      "author" : [ "B. Poole", "J. Wecsler", "P. Sheth", "S. Sener", "L. Wang", "L. Larsen", "D. Tripathy", "J. Lang" ],
      "venue" : "Journal of Surgical Research,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Probabilistic inductive logic programming",
      "author" : [ "L. De Raedt", "K. Kersting" ],
      "venue" : "In International Conference on Algorithmic Learning Theory, pages 19–36. Springer,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Probabilistic Rule Learning",
      "author" : [ "L. De Raedt", "I. Thon" ],
      "venue" : "In Inductive Logic Programming, pages 47–58. Springer,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Markov Logic Networks",
      "author" : [ "M. Richardson", "P. Domingos" ],
      "venue" : "Machine learning,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "PRISM: A language for symbolic-statistical modeling",
      "author" : [ "Taisuke Sato", "Yoshitaka Kameya" ],
      "venue" : "In International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1997
    }, {
      "title" : "Available from http://web.comlab.ox.ac.uk/oucl/research/areas/ machlearn/Aleph",
      "author" : [ "A. Srinivasan" ],
      "venue" : "The Aleph Manual,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 19,
      "context" : "Statistical Relational Learning (SRL) [20] is a well-known collection of techniques whose main objective is to produce interpretable probabilistic classifiers, often in the form of readable logical sentences.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 22,
      "context" : "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.",
      "startOffset" : 147,
      "endOffset" : 163
    }, {
      "referenceID" : 21,
      "context" : "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.",
      "startOffset" : 147,
      "endOffset" : 163
    }, {
      "referenceID" : 1,
      "context" : "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.",
      "startOffset" : 147,
      "endOffset" : 163
    }, {
      "referenceID" : 5,
      "context" : "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.",
      "startOffset" : 147,
      "endOffset" : 163
    }, {
      "referenceID" : 3,
      "context" : "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.",
      "startOffset" : 147,
      "endOffset" : 163
    }, {
      "referenceID" : 17,
      "context" : "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.",
      "startOffset" : 147,
      "endOffset" : 163
    }, {
      "referenceID" : 10,
      "context" : "In this work, we introduce SkILL – a Stochastic Inductive Logic Learner – which can combine the rule learning capability of classic Inductive Logic Programming (ILP) [11,16] with uncertain knowledge as probabilistic annotated data to produce First Order Logic (FOL) theories.",
      "startOffset" : 166,
      "endOffset" : 173
    }, {
      "referenceID" : 15,
      "context" : "In this work, we introduce SkILL – a Stochastic Inductive Logic Learner – which can combine the rule learning capability of classic Inductive Logic Programming (ILP) [11,16] with uncertain knowledge as probabilistic annotated data to produce First Order Logic (FOL) theories.",
      "startOffset" : 166,
      "endOffset" : 173
    }, {
      "referenceID" : 19,
      "context" : "Probabilistic Inductive Logic Programming (PILP) [20]",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 0,
      "context" : "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 16,
      "context" : "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 12,
      "context" : "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.",
      "startOffset" : 108,
      "endOffset" : 115
    }, {
      "referenceID" : 11,
      "context" : "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.",
      "startOffset" : 108,
      "endOffset" : 115
    }, {
      "referenceID" : 1,
      "context" : "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.",
      "startOffset" : 141,
      "endOffset" : 146
    }, {
      "referenceID" : 7,
      "context" : "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.",
      "startOffset" : 141,
      "endOffset" : 146
    }, {
      "referenceID" : 4,
      "context" : "3, rules are annotated according to Halpern’s type 1 probability structure [5], where numbers on the left correspond to values of the game domain, which can be interpreted as the frequency with which each event happens.",
      "startOffset" : 75,
      "endOffset" : 78
    }, {
      "referenceID" : 4,
      "context" : "These probabilities are the expected values of examples and can represent either statistical information or the degree of belief in an example (using type I or type II probability structures [5], respectively).",
      "startOffset" : 191,
      "endOffset" : 194
    }, {
      "referenceID" : 16,
      "context" : "Initially, the algorithm uses the TopLog engine from the GILPS [17] ILP system, to generate all possible hypotheses composed of only one clause (line 3 in Alg.",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 20,
      "context" : "The RMSE metric penalizes predictions farther from the expected values, while PAcc is the generalization of the discrete accuracy to the probabilistic setting as introduced by De Raedt and Thon [21] and used by Muggleton [15].",
      "startOffset" : 194,
      "endOffset" : 198
    }, {
      "referenceID" : 14,
      "context" : "The RMSE metric penalizes predictions farther from the expected values, while PAcc is the generalization of the discrete accuracy to the probabilistic setting as introduced by De Raedt and Thon [21] and used by Muggleton [15].",
      "startOffset" : 221,
      "endOffset" : 225
    }, {
      "referenceID" : 20,
      "context" : "From [21], TP +TN+FP +FN = |PE|, and TP and TN are equal to the sum over all examples of min(PH(ei), P (ei)) and min(1−PH(ei), 1−P (ei)), respectively.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 23,
      "context" : "Results presented for the Aleph system [24], are collected with the default parameters (except noise, which is set to maximum).",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 18,
      "context" : "The biopsy is very important in determining malignancy of a lesion and usually yields definitive results; however, in 5% to 15% of cases, the results are nondefinitive [19].",
      "startOffset" : 168,
      "endOffset" : 172
    }, {
      "referenceID" : 9,
      "context" : "Machine learning methods have been used to mitigate this and other problems by allowing to produce models of the data that can distinguish between benign and malignant cases [10,3].",
      "startOffset" : 174,
      "endOffset" : 180
    }, {
      "referenceID" : 2,
      "context" : "Machine learning methods have been used to mitigate this and other problems by allowing to produce models of the data that can distinguish between benign and malignant cases [10,3].",
      "startOffset" : 174,
      "endOffset" : 180
    }, {
      "referenceID" : 19,
      "context" : "The PILP setting was first introduced in [20], where three distinct settings – extended from traditional ILP [11] – are put forward: probabilistic entailment,",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 10,
      "context" : "The PILP setting was first introduced in [20], where three distinct settings – extended from traditional ILP [11] – are put forward: probabilistic entailment,",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 20,
      "context" : "Later, Raedt and Thon presented the system ProbFOIL [21], which is not only capable of performing induction over probabilistic examples, but also on background knowledge encoded as ProbLog probabilistic facts.",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 6,
      "context" : "Probabilistic Explanation Based Learning (PEBL) [7] can find the most likely FOL clause which explains a set of positive examples in terms of a database of probabilistic facts.",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 21,
      "context" : "Orthogonally, Markov Logic Networks (MLNs) [22] also combine structure learning using a FOL framework with a probabilistic Markov Random Fields approach [9].",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 8,
      "context" : "Orthogonally, Markov Logic Networks (MLNs) [22] also combine structure learning using a FOL framework with a probabilistic Markov Random Fields approach [9].",
      "startOffset" : 153,
      "endOffset" : 156
    }, {
      "referenceID" : 8,
      "context" : "Structure learning for MLNs softens the hypotheses by using probabilities and as such produces better classifiers, as shown in [9]; however, MLNs still consider crisp background knowledge, not taking into account the possibility of probabilistic logic facts.",
      "startOffset" : 127,
      "endOffset" : 130
    }, {
      "referenceID" : 14,
      "context" : "Finally, Meta-Interpretive Learning [15] – which is a technique aimed at performing predicate invention in ILP using abduction – can also be used to perform probabilistic structure learning by calculating prior and posterior distributions on the hypotheses space according to the examples explained by a given hypothesis [14].",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 13,
      "context" : "Finally, Meta-Interpretive Learning [15] – which is a technique aimed at performing predicate invention in ILP using abduction – can also be used to perform probabilistic structure learning by calculating prior and posterior distributions on the hypotheses space according to the examples explained by a given hypothesis [14].",
      "startOffset" : 321,
      "endOffset" : 325
    } ],
    "year" : 2015,
    "abstractText" : "Probabilistic Inductive Logic Programming (PILP) is a relatively unexplored area of Statistical Relational Learning which extends classic Inductive Logic Programming (ILP). This work introduces SkILL, a Stochastic Inductive Logic Learner, which takes probabilistic annotated data and produces First Order Logic theories. Data in several domains such as medicine and bioinformatics have an inherent degree of uncertainty, that can be used to produce models closer to reality. SkILL can not only use this type of probabilistic data to extract non-trivial knowledge from databases, but it also addresses efficiency issues by introducing a novel, efficient and effective search strategy to guide the search in PILP environments. The capabilities of SkILL are demonstrated in three different datasets: (i) a synthetic toy example used to validate the system, (ii) a probabilistic adaptation of a well-known biological metabolism application, and (iii) a real world medical dataset in the breast cancer domain. Results show that SkILL can perform as well as a deterministic ILP learner, while also being able to incorporate probabilistic knowledge that would otherwise not be considered.",
    "creator" : "LaTeX with hyperref package"
  }
}