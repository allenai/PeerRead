{
  "name" : "1704.07498.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Leveraging Time Series Data in Similarity Based Healthcare Predictive Models",
    "authors" : [ "Mohammad Amin Morid", "David Eccles", "Olivia R. Liu Sheng", "Samir Abdelrahman" ],
    "emails" : [ "amin.morid@business.utah.edu", "olivia.sheng@business.utah.edu", "samir.abdelrahman@utah.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Twenty-third Americas Conference on Information Systems, Boston, 2017\nPatient time series classification faces challenges in high degrees of dimensionality and missingness. In light of patient similarity theory, this study explores effective temporal feature engineering and reduction, missing value imputation, and change point detection methods that can afford similarity-based classification models with desirable accuracy enhancement. We select a piecewise aggregation approximation method to extract fine-grain temporal features and propose a minimalist method to impute missing values in temporal features. For dimensionality reduction, we adopt a gradient descent search method for feature weight assignment. We propose new patient status and directional change definitions based on medical knowledge or clinical guidelines about the value ranges for different patient status levels, and develop a method to detect change points indicating positive or negative patient status changes. We evaluate the effectiveness of the proposed methods in the context of early Intensive Care Unit mortality prediction. The evaluation results show that the k-Nearest Neighbor algorithm that incorporates methods we select and propose significantly outperform the relevant benchmarks for early ICU mortality prediction. This study makes contributions to time series classification and early ICU mortality prediction via identifying and enhancing temporal feature engineering and reduction methods for similarity-based time series classification."
    }, {
      "heading" : "Keywords",
      "text" : "time-series classification, similarity-based classification, mortality prediction, directional change point."
    }, {
      "heading" : "Introduction",
      "text" : "Patient time series data are collected over time at varying time intervals to update patient status and to support medical decisions, leading to a wide variety of patient time series data – e.g., vital signs, lab results, diagnoses, prescriptions and billings in Electronic Health Records (EHRs) and other healthcare information systems. Past studies have extracted and leveraged temporal patterns (e.g., temporal statistics, trends, transitions and similarity) from time series data for patient event, (e.g., readmission or mortality), risk (Johnson et al. 2012), cost prediction (Bertsimas et al. 2008), or performance prediction (Cho et al. 2008). Some of the past studies have reduced such problems to one of classifying one or multiple time series of the same entity into different outcome/decision classes, which is termed the time series classification (TSC) problem (Lee et al. 2012). Time series classification can be tackled by\nTwenty-third Americas Conference on Information Systems, Boston, 2017\nengineering temporal features that provide meaningful representations of time series and predictive power at reduced dimensionality for use with general-purposed classification methods (Hippisley-Cox et al. 2009). The synergy between a certain temporal abstraction approach and classification algorithm varies amongst the vast choice space, and hence must be properly considered. To diagnose new patients, physicians are often influenced by previous similar cases with relevant clinical evidences, resulting in patient similarity theory in the clinical decision support literature (Rouzbahman and Chignell 2014). In light of this theory, this study focuses on enhancing similarity-based classification methods for patient time series classification.\nThe challenges of time series data include high dimensionality and high degree of missingness. Temporal abstraction of time series, missing value imputation and feature reduction approaches provide options to address these challenges. In addition, changes or transitions in various contexts including time series classification have provided essential predictive power (Lin et al. 2014). To explore effective temporal abstraction, missing value imputation, feature weight assignment and change point detection methods that can afford the k-Nearest-Neighbor (kNN) algorithm with desirable synergy, this study asks these research questions:\n“What are the effective temporal abstraction, missing value imputation and feature reduction methods for similarity-based time series classification?\"\n“What is an effective approach to define and detect patient status change points for similarity-based time series classification?”"
    }, {
      "heading" : "Proposed Framework for Similarity-based Patient Time Series Classification",
      "text" : "In this section, we introduce the methods this study has selected or proposed for patient time series classification and some background and justifications for these methods."
    }, {
      "heading" : "Similarity based classification",
      "text" : "Similarity-based classifiers estimate the class label of a test or new sample based on the similarities between the test sample and a set of labeled training samples, and the pairwise similarities between the training samples (Chen et al. 2009). The most popular family of algorithms has grown out the k-NearestNeighbor (k-NN) algorithm where k is the number of training samples with maximal similarities to a test sample. Many advancements of the original k-NN including ENN (two-way similarity) (Tang and He 2015), CNN (condensed nearest neighbors) (Hart 1968) and kernel-based approaches (e.g., SVM-KNN) have been proposed (Chen et al. 2009) for similarity-based classification as well. To examine the usefulness of temporal features and reduction, and their synergy with similarity-based classification approaches, we made a conscientious decision to use the original k-NN in this study. The potentials of advancing the methods for patient time-series classification based on other similarity-based classification remain as future research directions.\nPast research on similarity measure has led to a wide variety of time series distance functions such as Dynamic Time Wrapping (DTW) (Berndt and Clifford 1994), Edit Distance with Real Penalty (ERP) (Chen and Ng 2004) and Longest Common Subsequence (LCSS) (Vlachos et al. 2002) to measure dissimilarities based on different considerations. Our empirical exploration of different distance functions shows that the simplicity of the Manhattan distance function offers desirable flexibility to leverage the joint benefits of distance function, PAA grain size and missing value imputation methods. We hence select the Manhattan distance function in k-NN for patient time series classification."
    }, {
      "heading" : "Temporal abstraction",
      "text" : "Temporal abstraction decides on how to transform time series data into the input features of a classification model. The challenges of time series data include high dimensionality and high amount of missing data amongst others. Extant temporal abstraction methods vary in their considerations to address these challenges and the predictive power of the resulting temporal features (Fu 2011). One commonly used simple temporal abstraction approach, called piecewise aggregation approximation (PAA), segments a time series into a sequence of fixed-sized non-overlapping consecutive windows (or\nTwenty-third Americas Conference on Information Systems, Boston, 2017\nintervals) (Lin et al. 2003). Each window is represented by the average of all data values time-stamped within the window. We regard the size of a PAA window as the grain size and divide the temporal features produced by PAA into fine-grain features versus coarse grain features. Table 1 compares the dimensionality, degrees of missingness and information loss of fine-grain versus coarse-grain features.\nThe low information loss of fine-grain PAA could afford k-NN improved accuracy over coarse-grain PAA features. Exploring effective grain-size, dimensionality reduction and missing value imputation methods are necessary to realize additional predictive power of fine-grain PAA temporal features."
    }, {
      "heading" : "PAA grain decision",
      "text" : "The optimal PAA grain decision is analytically intractable due to the apparent complexity of considering the interrelated factors including missing value imputation, feature reduction and distance function. Empirical comparison should be employed to decide on the grain size. To reduce the number of empirical experiments, we only compare the classification accuracy resulting from different grain sizes while holding other methods fixed at the selected or proposed settings for time series classification."
    }, {
      "heading" : "Missing value imputation (MVI)",
      "text" : "Missing value handling methods such as propensity score imputation, predictive model–based imputation and hot-deck imputation can be found from past literature (Penny and Chesney 2006). Some of the time series distance functions such DTW also incorporates missing value imputation (Berndt and Clifford 1994). In particular, DTW considers prior and posterior values of a missing value at a time point when deciding on the similarity between two time series. Motivated by DTW, we propose an adjacency-based imputation method which replaces a missing value by its posterior value if its prior value is not available or by its prior value if its posterior value is not available. If both prior and posterior values are available, their average becomes the imputed value. The proposed imputation can be performed independent of the distance function of choice."
    }, {
      "heading" : "Feature weighting (FW)",
      "text" : "Feature reduction for classification can utilize a variety of approaches such as information gain, Gini index and Chi-square metrics to calculate feature rankings or weights for feature selection or reduction (Singh et al. 2010). Because of the well-tested ability to improve accuracy, we adopt the Gradient Descent (GS) method (Modha and Spangler 2003; Wettschereck and Aha 1995) to assign weights to time series features."
    }, {
      "heading" : "Change point detection (CPD)",
      "text" : "Many change point detection methods focus on detecting changes in the mean, variance or trend in a time series that follows a distribution – e.g., Gaussian, normal or regression (Hawkins and Zamba 2012). Such methods are not appropriate for detecting change points in patient time series due to the underlying data distribution assumptions. In addition, a change in the mean or variance of numeric patient time series, for example, of blood pressure may not be a change in patient status if both the values before and after a change point represent the same patient status – e.g. normal. Therefore, this paper uses a change point detection method based on clinical domain knowledge.\nTwenty-third Americas Conference on Information Systems, Boston, 2017\nDirectional change point detection method\nPast research has emphasized the importance of change point in clinical guidelines and decision supports (Assareh et al. 2011; La Rosa et al. 2008; Sawaya et al. 2011). Few or many change points of a patient’s time series can easily differentiate a patient’s condition and outcomes. In this paper we propose to define and detect change points based on changes in the health status according to categories of values in the time series rather than measures like mean or variance. For instance, systolic blood pressure less than 120 is considered normal, while between 120 and 139 is considered Prehypertension (Le et al. 2013). A directional change point is defined as a change in a patients’ status category.\nWe denote a directional change point of patient i for time series (TS) j as DCP(i, j). The input is the status(i, j, k) that indicates the health status level of patient i during time window k based on TS j. The status output is an integer, where the lowest value of status for a feature represents the worst category of health status, while the highest value of status for this feature represents the best category of health status. Status change of patient i at time window k in terms of TS j is computed as follow:\nStatusChange(i, j, k) = Positive, if status(i, j, k) > status (i, j, m), m<k = Negative, if status(i, j, k) < status (i, j, m), m<k = Stable, if status(i, j, k) = status (i, j, m), m<k where m is the time window of the most recent available status of the patient before window k. We propose three change point features for patient i based on TS j - the number of directional change points or \uD835\uDC41\uD835\uDC62\uD835\uDC5A_\uD835\uDC5C\uD835\uDC53_\uD835\uDC37\uD835\uDC36\uD835\uDC43(\uD835\uDC56, \uD835\uDC57), and the first and last status changes, or LastStatusChange(i,j), and FirstStatusChange(i,j). The following determines the value of directional change point of patient i status at time windows k in terms of TS j:\nDCP(i, j, k) = 1, If status(i, j, k) is opposite to status (i, j, r), r<k = 0, if status(i, j, k) = is not opposite to status (i, j, r), r<k where r is the most recent available status change of the patient before window k that is either positive or negative (i.e., Stable is not counted). DCP(i,j,1) for the first window is set to zero. Assume W is the number of time windows (e.g., 24), the number of directional change points is derived as:\n\uD835\uDC41\uD835\uDC62\uD835\uDC5A_\uD835\uDC5C\uD835\uDC53_\uD835\uDC37\uD835\uDC36\uD835\uDC43(\uD835\uDC56, \uD835\uDC57) = ∑ \uD835\uDC37\uD835\uDC36\uD835\uDC43(\uD835\uDC56, \uD835\uDC57, \uD835\uDC58)\n\uD835\uDC4A\n\uD835\uDC58=1\nThe most recent and most related study to this method is the change point detection method proposed by Lin et al. (2014)(Lin et al. 2014) for time-to-event prediction of chronic conditions using EHR data. To detect change in patients’ status, the numerical time series values are replaced by three nominal states (i.e., high, medium, low) based on numerical trend and two nominal trends (i.e., decrease, increase, stable) based on numerical value changes of each predictor. Their change point detection will be used as a benchmark for evaluating our proposed domain based directional change point detection method.\nkNN-TSC-FIWC\nWe refer to the proposed patient time series classification method that combines the kNN algorithm with fine-grain temporal features (F), missing-value imputation (I), feature weight assignment (W) and change point detection (C) methods we select or propose to enhance similarity-based time series classification as kNN-TSC-FIWC. Figure 1 summarizes the flow of the training and testing phases of kNN-TSC-FIWC.\nAnother benchmark of kNN-TSC-FIWC is Lee et al. (2012)(Lee et al. 2012) which proposes a similarity based time series classification algorithm - KNN-TSC to predict customer churn after 30 days. KNN-TSC divides each feature’s time series data into 15 equal size intervals and adopts the Discrete Fourier transform (DFT) technique for time series similarity calculation. It doesn’t assign feature weights. KNNTSC utilizes stratified average voting to estimate the churn decision of a test sample. In empirical evaluation, we will compare the accuracy of kNN-TSC-FIWC to that of KNN-TSC.\nTwenty-third Americas Conference on Information Systems, Boston, 2017"
    }, {
      "heading" : "Empirical Evaluation",
      "text" : "To evaluate the effectiveness of kNN-TSC-FIWC and its enabling methods, we compare them to benchmarks representing combinations of different temporal features, classification algorithms, similarity functions and dimension reduction methods in the context of early Intensive Care Unit (ICU) mortality prediction. Accurate ICU mortality prediction impacts medical therapy, triaging, end-of-life care, and many other aspects of ICU care (Gartman et al. 2009). To enhance the performance of ICU mortality prediction more sophisticated machine learning methods have been utilized recently. The PhysioNet/Computing in Cardiology 2012 Challenge aimed to provide a benchmark environment for early ICU mortality prediction (Silva et al. 2012). To the best of our knowledge, its winner (CCW hereafter) is the best early ICU mortality prediction benchmark using patients’ first 48 hours of ICU time series data. CCW utilizes a new Bayesian ensemble scheme comprising of 500 weak decision tree learners which randomly assigns an intercept and gradient to a randomly selected single feature (Johnson et al. 2012)."
    }, {
      "heading" : "Data and evaluation procedure",
      "text" : "To compare our results with CCW, we use the same experimental setup in the competition where patients were filtered to 22,561 patients who are younger than 16 years old and remained in the ICU for at least 48 hours. The data input consists of time series data of 36 variables (e.g., Glasgow Coma Score GCS) extracted from patients’ ICU stay, plus four static features (i.e., age, gender, height, and initial weight). The target variable is a binary feature showing whether or not the patient eventually dies in the hospital before discharge. While almost half of the ICU patients have died eventually, most of the deaths happened out of hospital. The problem we analyze in this study is the prediction of in hospital mortality, which has\nTwenty-third Americas Conference on Information Systems, Boston, 2017\nan imbalanced distribution of 18% positive against 82% negative as shown in Table 2. It is interesting to observe that the difference in average ICU stays is very minor while the difference in outcomes is life versus death. Early mortality prediction may be able to help decision makers find ways to improve an ICU patient’s survival rate. For finding and tuning the parameters including finding the best k, 50% of the data was used, while the rest remained unseen for validation. In all experiments, 20-fold cross validation was used to evaluate the performance of each method based on the validation dataset. Classification performance was measured according to the average precision, recall, and F-measure across 20 folds."
    }, {
      "heading" : "Results",
      "text" : "Table 3 shows that using two hours’ time windows for the proposed method outperforms the same method with one, four and eight hours’ time windows. The performance of the smallest grain size suffers from high missingness and the resulting noises in two patients’ common PAA temporal values, while high loss of information details hurts the performance of large grain sizes. The best prediction performance is reached when the effect of missing values and information loss is balanced at window size of 2. Hence, the grain size chosen for the rest of the evaluations is 2 hours.\nTable 4 compares the performance of kNN-TSC-FIW where a few benchmarking distance functions replace the Manhattan distance function. Although the performance results are close, they do validate the performance benefit the simple Manhattan distance function offers.\nTwenty-third Americas Conference on Information Systems, Boston, 2017\nTable 5 compares the performance of kNN-FIW against some of the well-established data mining methods, including support vector machine (SVM), the original kNN without feature weight assignment, neural network (NN) and logistic regression (LR). The input features for these algorithms are derived based on the fine-grain PAA of 2-hr window size. The comparison validates the performance advantage of similarity-based classification over its non-similarity counter-parts for early ICU mortality prediction.\nTable 6 compares the performance of kNN combined with the selected or proposed methods starting with fine-grain time series abstraction (kNN-TSC-F), missing value imputation (kNN-TSC-FI), feature weighting (kNN-TSC-FIW) and change point detection (kNN-TSC-FIWC). The features based on the proposed fine-grain temporal abstraction, missing value imputation and feature weighting help the kNNTSC-FIW model outperform the CCW benchmark by increasing the F-measure of the “yes” class by 11%. The proposed change point features also further double this performance improvement. The significance and benefits of these performance improvements in early ICU mortality by the proposed classification features cannot be underestimated.\nTable 7 shows the significant effect of the proposed feature weighting technique on the proposed method (without considering change point features) against well-established feature weighting techniques, including Gini index, Chi-square and information gain, as well as the method proposed by Lee et al. (Lee et al. 2012).\nTwenty-third Americas Conference on Information Systems, Boston, 2017\nThis table shows the advantage of the selected Gradient Descent FW over methods that assign weights based on pre-calculated values as well as domain knowledge based weight assignment (i.e. Manual weights). The performance of a model without the proposed adjacency-based imputation on the left-hand side of Table 7 is significantly lower than the same model with imputation on the right-hand side, providing evidences for the effectiveness of the proposed minimalist imputation method.\nTable 8 compares the performance of kNN-TSC-FIWC using different change point detection (CPD) methods including parametric (M-G and V-G) and non-parametric (L-NP, S-NP, and LS-NP) CPD methods as well as the change point detection method proposed by Lin et al. (2014). Although nonparametric CPD approaches perform better than parametric CPD approaches, none of them nor the CPD method proposed by Lin et al. [16] could outperform kNN-TSC-FIWC. The comparison provides evidences that changes in patient time series cannot be detected without considering domain-based patient status categories. In addition, our post process analysis shows that patients with higher number of DCHP are more likely to die due to their unstable situation. Patients with negative last change points which indicate declining health status dominate the early death class. These patterns show the importance of the proposed change point detection features.\nTwenty-third Americas Conference on Information Systems, Boston, 2017"
    }, {
      "heading" : "Window",
      "text" : ""
    }, {
      "heading" : "Contributions and Limitations",
      "text" : "This study makes several contributions to the patient time series classification and the early ICU mortality prediction research fields:\nBased on the patient similarity theory, the study evaluates the effectiveness of the similarity-based patient time series classification approach.\nThe study further evaluates and identifies effective fine-grain PAA temporal abstraction, similarity functions and proposes necessary enhancements via adjacency-based missing value imputation. The study also evaluates the effectiveness of the gradient decent feature weight assignment approach for reducing temporal dimensions and improving accuracy.\nTo the best of our knowledge, the study is the first to propose directional patient status change point detection to extract effective features for patient time series classification.\nThe study contributes to solutions to an important healthcare predictive problem – early ICU mortality prediction by significantly improving prediction accuracy with a new framework that embeds effective extant methods and new enhancements. Both intensive caregivers and patients’ families can benefit from this framework with the crucial decision on aggressive or supportive treatment. Also, unexpected deaths, which are still common despite evidence that patients often show signs of clinical deterioration hours in advance, can be detected.\nThe main limitations of this study include the use of a single data set for evaluation, the difficulty of explaining a kNN model, and the need to examine additional methods appropriate for time series classification. Future research should pursue along the directions that could address these limitations."
    } ],
    "references" : [ {
      "title" : "Bayesian Change Point Detection in Monitoring Cardiac Surgery Outcomes,",
      "author" : [ "H. Assareh", "I. Smith", "K. Mengersen" ],
      "venue" : "Quality Management in Healthcare",
      "citeRegEx" : "Assareh et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Assareh et al\\.",
      "year" : 2011
    }, {
      "title" : "Using Dynamic Time Warping to Find Patterns in Time Series,\" KDD workshop",
      "author" : [ "D.J. Berndt", "J. Clifford" ],
      "venue" : null,
      "citeRegEx" : "Berndt and Clifford,? \\Q1994\\E",
      "shortCiteRegEx" : "Berndt and Clifford",
      "year" : 1994
    }, {
      "title" : "Algorithmic Prediction of Health-Care Costs,",
      "author" : [ "D. Bertsimas", "M.V. Bjarnadóttir", "M.A. Kane", "J.C. Kryder", "R. Pandey", "S. Vempala", "G. Wang" ],
      "venue" : "Operations Research",
      "citeRegEx" : "Bertsimas et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Bertsimas et al\\.",
      "year" : 2008
    }, {
      "title" : "On the Marriage of Lp-Norms and Edit Distance,",
      "author" : [ "L. Chen", "R. Ng" ],
      "venue" : "Proceedings of the Thirtieth international conference on Very large data bases-Volume 30: VLDB Endowment,",
      "citeRegEx" : "Chen and Ng,? \\Q2004\\E",
      "shortCiteRegEx" : "Chen and Ng",
      "year" : 2004
    }, {
      "title" : "Similarity-Based Classification: Concepts and Algorithms,",
      "author" : [ "Y. Chen", "E.K. Garcia", "M.R. Gupta", "A. Rahimi", "L. Cazzanti" ],
      "venue" : "The Journal of Machine Learning Research",
      "citeRegEx" : "Chen et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2009
    }, {
      "title" : "Application of Irregular and Unbalanced Data to Predict Diabetic Nephropathy Using Visualization and Feature Selection Methods,\" Artificial intelligence in medicine",
      "author" : [ "B.H. Cho", "H. Yu", "Kim", "K.-W", "T.H. Kim", "I.Y. Kim", "S.I. Kim" ],
      "venue" : null,
      "citeRegEx" : "Cho et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Cho et al\\.",
      "year" : 2008
    }, {
      "title" : "A Review on Time Series Data Mining,",
      "author" : [ "Fu", "T.-c" ],
      "venue" : "Engineering Applications of Artificial Intelligence",
      "citeRegEx" : "Fu and T..c.,? \\Q2011\\E",
      "shortCiteRegEx" : "Fu and T..c.",
      "year" : 2011
    }, {
      "title" : "Using Serial Severity Scores to Predict Death in Icu Patients: A Validation Study and Review of the Literature,\" Current opinion in critical care",
      "author" : [ "E.J. Gartman", "B.P. Casserly", "D. Martin", "N.S. Ward" ],
      "venue" : null,
      "citeRegEx" : "Gartman et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Gartman et al\\.",
      "year" : 2009
    }, {
      "title" : "The Condensed Nearest Neighbor Rule (Corresp.),",
      "author" : [ "P. Hart" ],
      "venue" : "IEEE Transactions on Information Theory",
      "citeRegEx" : "Hart,? \\Q1968\\E",
      "shortCiteRegEx" : "Hart",
      "year" : 1968
    }, {
      "title" : "Statistical Process Control for Shifts in Mean or Variance Using a Changepoint Formulation,\" Technometrics)",
      "author" : [ "D.M. Hawkins", "K. Zamba" ],
      "venue" : null,
      "citeRegEx" : "Hawkins and Zamba,? \\Q2012\\E",
      "shortCiteRegEx" : "Hawkins and Zamba",
      "year" : 2012
    }, {
      "title" : "Predicting Risk of Type 2 Diabetes in England and Wales: Prospective Derivation and Validation of Qdscore,\" Bmj",
      "author" : [ "J. Hippisley-Cox", "C. Coupland", "J. Robson", "A. Sheikh", "P. Brindle" ],
      "venue" : null,
      "citeRegEx" : "Hippisley.Cox et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hippisley.Cox et al\\.",
      "year" : 2009
    }, {
      "title" : "Patient Specific Predictions in the Intensive Care Unit Using a Bayesian Ensemble,",
      "author" : [ "A.E. Johnson", "N. Dunkley", "L. Mayaud", "A. Tsanas", "A. Kramer", "G.D. Clifford" ],
      "venue" : "Computing in Cardiology (CinC),",
      "citeRegEx" : "Johnson et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2012
    }, {
      "title" : "Detection of Uterine Mmg Contractions Using a Multiple Change Point Estimator and the K-Means Cluster Algorithm,",
      "author" : [ "P.S. La Rosa", "A. Nehorai", "H. Eswaran", "C.L. Lowery", "H. Preissl" ],
      "venue" : "IEEE Transactions on Biomedical Engineering",
      "citeRegEx" : "Rosa et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Rosa et al\\.",
      "year" : 2008
    }, {
      "title" : "Blood Glucose Measurement in the Intensive Care Unit: What Is the Best Method?,",
      "author" : [ "H.T. Le", "N.S. Harris", "A.J. Estilong", "A. Olson", "M.J. Rice" ],
      "venue" : "Journal of diabetes science and technology",
      "citeRegEx" : "Le et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Le et al\\.",
      "year" : 2013
    }, {
      "title" : "Nearest-Neighbor-Based Approach to Time-Series Classification,",
      "author" : [ "Lee", "Y.-H", "Wei", "C.-P", "Cheng", "T.-H", "Yang", "C.-T" ],
      "venue" : "Decision Support Systems",
      "citeRegEx" : "Lee et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2012
    }, {
      "title" : "A Symbolic Representation of Time Series, with Implications for Streaming Algorithms,",
      "author" : [ "J. Lin", "E. Keogh", "S. Lonardi", "B. Chiu" ],
      "venue" : "Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery: ACM,",
      "citeRegEx" : "Lin et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2003
    }, {
      "title" : "Time-to-Event Predictive Modeling for Chronic Conditions Using Electronic Health Records,",
      "author" : [ "Lin", "Y.-K", "H. Chen", "R.A. Brown", "Li", "S.-H", "Yang", "H.-J" ],
      "venue" : "IEEE Intelligent Systems",
      "citeRegEx" : "Lin et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2014
    }, {
      "title" : "Feature Weighting in K-Means Clustering,\" Machine learning (52:3)",
      "author" : [ "D.S. Modha", "W.S. Spangler" ],
      "venue" : null,
      "citeRegEx" : "Modha and Spangler,? \\Q2003\\E",
      "shortCiteRegEx" : "Modha and Spangler",
      "year" : 2003
    }, {
      "title" : "Imputation Methods to Deal with Missing Values When Data Mining Trauma Injury",
      "author" : [ "K.I. Penny", "T. Chesney" ],
      "venue" : "Data,\" 28th International Conference on Information Technology Interfaces,",
      "citeRegEx" : "Penny and Chesney,? \\Q2006\\E",
      "shortCiteRegEx" : "Penny and Chesney",
      "year" : 2006
    }, {
      "title" : "Predicting Icu Death with Summarized Data: The Emerging Health Data Search Engine,\")",
      "author" : [ "M. Rouzbahman", "M. Chignell" ],
      "venue" : null,
      "citeRegEx" : "Rouzbahman and Chignell,? \\Q2014\\E",
      "shortCiteRegEx" : "Rouzbahman and Chignell",
      "year" : 2014
    }, {
      "title" : "Early Detection and Prediction of Cardiotoxicity in Chemotherapy-Treated Patients,\" The American journal of cardiology",
      "author" : [ "H. Sawaya", "I.A. Sebag", "J.C. Plana", "J.L. Januzzi", "B. Ky", "V. Cohen", "S. Gosavi", "J.R. Carver", "S.E. Wiegers", "R.P. Martin" ],
      "venue" : null,
      "citeRegEx" : "Sawaya et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Sawaya et al\\.",
      "year" : 2011
    }, {
      "title" : "Predicting in-Hospital Mortality of Icu Patients: The Physionet/Computing in Cardiology Challenge 2012,\" Computing in Cardiology (CinC), 2012",
      "author" : [ "I. Silva", "G. Moody", "D.J. Scott", "L.A. Celi", "R.G. Mark" ],
      "venue" : null,
      "citeRegEx" : "Silva et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Silva et al\\.",
      "year" : 2012
    }, {
      "title" : "Feature Selection for Text Classification Based on Gini Coefficient of Inequality,",
      "author" : [ "S.R. Singh", "H.A. Murthy", "T.A. Gonsalves" ],
      "venue" : "FSDM",
      "citeRegEx" : "Singh et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Singh et al\\.",
      "year" : 2010
    }, {
      "title" : "Enn: Extended Nearest Neighbor Method for Pattern Recognition [Research Frontier],",
      "author" : [ "B. Tang", "H. He" ],
      "venue" : "IEEE Computational Intelligence Magazine",
      "citeRegEx" : "Tang and He,? \\Q2015\\E",
      "shortCiteRegEx" : "Tang and He",
      "year" : 2015
    }, {
      "title" : "Discovering Similar Multidimensional Trajectories,",
      "author" : [ "M. Vlachos", "G. Kollios", "D. Gunopulos" ],
      "venue" : "Data Engineering,",
      "citeRegEx" : "Vlachos et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Vlachos et al\\.",
      "year" : 2002
    }, {
      "title" : "Weighting Features,\" in Case-Based Reasoning Research and Development",
      "author" : [ "D. Wettschereck", "D.W. Aha" ],
      "venue" : null,
      "citeRegEx" : "Wettschereck and Aha,? \\Q1995\\E",
      "shortCiteRegEx" : "Wettschereck and Aha",
      "year" : 1995
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : ", readmission or mortality), risk (Johnson et al. 2012), cost prediction (Bertsimas et al.",
      "startOffset" : 34,
      "endOffset" : 55
    }, {
      "referenceID" : 2,
      "context" : "2012), cost prediction (Bertsimas et al. 2008), or performance prediction (Cho et al.",
      "startOffset" : 23,
      "endOffset" : 46
    }, {
      "referenceID" : 5,
      "context" : "2008), or performance prediction (Cho et al. 2008).",
      "startOffset" : 33,
      "endOffset" : 50
    }, {
      "referenceID" : 14,
      "context" : "Some of the past studies have reduced such problems to one of classifying one or multiple time series of the same entity into different outcome/decision classes, which is termed the time series classification (TSC) problem (Lee et al. 2012).",
      "startOffset" : 223,
      "endOffset" : 240
    }, {
      "referenceID" : 10,
      "context" : "Twenty-third Americas Conference on Information Systems, Boston, 2017 engineering temporal features that provide meaningful representations of time series and predictive power at reduced dimensionality for use with general-purposed classification methods (Hippisley-Cox et al. 2009).",
      "startOffset" : 255,
      "endOffset" : 282
    }, {
      "referenceID" : 19,
      "context" : "To diagnose new patients, physicians are often influenced by previous similar cases with relevant clinical evidences, resulting in patient similarity theory in the clinical decision support literature (Rouzbahman and Chignell 2014).",
      "startOffset" : 201,
      "endOffset" : 231
    }, {
      "referenceID" : 16,
      "context" : "In addition, changes or transitions in various contexts including time series classification have provided essential predictive power (Lin et al. 2014).",
      "startOffset" : 134,
      "endOffset" : 151
    }, {
      "referenceID" : 4,
      "context" : "Similarity-based classifiers estimate the class label of a test or new sample based on the similarities between the test sample and a set of labeled training samples, and the pairwise similarities between the training samples (Chen et al. 2009).",
      "startOffset" : 226,
      "endOffset" : 244
    }, {
      "referenceID" : 23,
      "context" : "Many advancements of the original k-NN including ENN (two-way similarity) (Tang and He 2015), CNN (condensed nearest neighbors) (Hart 1968) and kernel-based approaches (e.",
      "startOffset" : 74,
      "endOffset" : 92
    }, {
      "referenceID" : 8,
      "context" : "Many advancements of the original k-NN including ENN (two-way similarity) (Tang and He 2015), CNN (condensed nearest neighbors) (Hart 1968) and kernel-based approaches (e.",
      "startOffset" : 128,
      "endOffset" : 139
    }, {
      "referenceID" : 4,
      "context" : ", SVM-KNN) have been proposed (Chen et al. 2009) for similarity-based classification as well.",
      "startOffset" : 30,
      "endOffset" : 48
    }, {
      "referenceID" : 1,
      "context" : "Past research on similarity measure has led to a wide variety of time series distance functions such as Dynamic Time Wrapping (DTW) (Berndt and Clifford 1994), Edit Distance with Real Penalty (ERP) (Chen and Ng 2004) and Longest Common Subsequence (LCSS) (Vlachos et al.",
      "startOffset" : 132,
      "endOffset" : 158
    }, {
      "referenceID" : 3,
      "context" : "Past research on similarity measure has led to a wide variety of time series distance functions such as Dynamic Time Wrapping (DTW) (Berndt and Clifford 1994), Edit Distance with Real Penalty (ERP) (Chen and Ng 2004) and Longest Common Subsequence (LCSS) (Vlachos et al.",
      "startOffset" : 198,
      "endOffset" : 216
    }, {
      "referenceID" : 24,
      "context" : "Past research on similarity measure has led to a wide variety of time series distance functions such as Dynamic Time Wrapping (DTW) (Berndt and Clifford 1994), Edit Distance with Real Penalty (ERP) (Chen and Ng 2004) and Longest Common Subsequence (LCSS) (Vlachos et al. 2002) to measure dissimilarities based on different considerations.",
      "startOffset" : 255,
      "endOffset" : 276
    }, {
      "referenceID" : 15,
      "context" : "Twenty-third Americas Conference on Information Systems, Boston, 2017 intervals) (Lin et al. 2003).",
      "startOffset" : 81,
      "endOffset" : 98
    }, {
      "referenceID" : 18,
      "context" : "Missing value handling methods such as propensity score imputation, predictive model–based imputation and hot-deck imputation can be found from past literature (Penny and Chesney 2006).",
      "startOffset" : 160,
      "endOffset" : 184
    }, {
      "referenceID" : 1,
      "context" : "Some of the time series distance functions such DTW also incorporates missing value imputation (Berndt and Clifford 1994).",
      "startOffset" : 95,
      "endOffset" : 121
    }, {
      "referenceID" : 22,
      "context" : "Feature reduction for classification can utilize a variety of approaches such as information gain, Gini index and Chi-square metrics to calculate feature rankings or weights for feature selection or reduction (Singh et al. 2010).",
      "startOffset" : 209,
      "endOffset" : 228
    }, {
      "referenceID" : 17,
      "context" : "Because of the well-tested ability to improve accuracy, we adopt the Gradient Descent (GS) method (Modha and Spangler 2003; Wettschereck and Aha 1995) to assign weights to time series features.",
      "startOffset" : 98,
      "endOffset" : 150
    }, {
      "referenceID" : 25,
      "context" : "Because of the well-tested ability to improve accuracy, we adopt the Gradient Descent (GS) method (Modha and Spangler 2003; Wettschereck and Aha 1995) to assign weights to time series features.",
      "startOffset" : 98,
      "endOffset" : 150
    }, {
      "referenceID" : 9,
      "context" : ", Gaussian, normal or regression (Hawkins and Zamba 2012).",
      "startOffset" : 33,
      "endOffset" : 57
    }, {
      "referenceID" : 0,
      "context" : "Past research has emphasized the importance of change point in clinical guidelines and decision supports (Assareh et al. 2011; La Rosa et al. 2008; Sawaya et al. 2011).",
      "startOffset" : 105,
      "endOffset" : 167
    }, {
      "referenceID" : 20,
      "context" : "Past research has emphasized the importance of change point in clinical guidelines and decision supports (Assareh et al. 2011; La Rosa et al. 2008; Sawaya et al. 2011).",
      "startOffset" : 105,
      "endOffset" : 167
    }, {
      "referenceID" : 13,
      "context" : "For instance, systolic blood pressure less than 120 is considered normal, while between 120 and 139 is considered Prehypertension (Le et al. 2013).",
      "startOffset" : 130,
      "endOffset" : 146
    }, {
      "referenceID" : 16,
      "context" : "(2014)(Lin et al. 2014) for time-to-event prediction of chronic conditions using EHR data.",
      "startOffset" : 6,
      "endOffset" : 23
    }, {
      "referenceID" : 15,
      "context" : "The most recent and most related study to this method is the change point detection method proposed by Lin et al. (2014)(Lin et al.",
      "startOffset" : 103,
      "endOffset" : 121
    }, {
      "referenceID" : 14,
      "context" : "(2012)(Lee et al. 2012) which proposes a similarity based time series classification algorithm - KNN-TSC to predict customer churn after 30 days.",
      "startOffset" : 6,
      "endOffset" : 23
    }, {
      "referenceID" : 14,
      "context" : "Another benchmark of kNN-TSC-FIWC is Lee et al. (2012)(Lee et al.",
      "startOffset" : 37,
      "endOffset" : 55
    }, {
      "referenceID" : 7,
      "context" : "Accurate ICU mortality prediction impacts medical therapy, triaging, end-of-life care, and many other aspects of ICU care (Gartman et al. 2009).",
      "startOffset" : 122,
      "endOffset" : 143
    }, {
      "referenceID" : 21,
      "context" : "The PhysioNet/Computing in Cardiology 2012 Challenge aimed to provide a benchmark environment for early ICU mortality prediction (Silva et al. 2012).",
      "startOffset" : 129,
      "endOffset" : 148
    }, {
      "referenceID" : 11,
      "context" : "CCW utilizes a new Bayesian ensemble scheme comprising of 500 weak decision tree learners which randomly assigns an intercept and gradient to a randomly selected single feature (Johnson et al. 2012).",
      "startOffset" : 177,
      "endOffset" : 198
    }, {
      "referenceID" : 14,
      "context" : "(Lee et al. 2012).",
      "startOffset" : 0,
      "endOffset" : 17
    }, {
      "referenceID" : 15,
      "context" : "Table 8 compares the performance of kNN-TSC-FIWC using different change point detection (CPD) methods including parametric (M-G and V-G) and non-parametric (L-NP, S-NP, and LS-NP) CPD methods as well as the change point detection method proposed by Lin et al. (2014). Although nonparametric CPD approaches perform better than parametric CPD approaches, none of them nor the CPD method proposed by Lin et al.",
      "startOffset" : 249,
      "endOffset" : 267
    } ],
    "year" : 2017,
    "abstractText" : "Patient time series classification faces challenges in high degrees of dimensionality and missingness. In light of patient similarity theory, this study explores effective temporal feature engineering and reduction, missing value imputation, and change point detection methods that can afford similarity-based classification models with desirable accuracy enhancement. We select a piecewise aggregation approximation method to extract fine-grain temporal features and propose a minimalist method to impute missing values in temporal features. For dimensionality reduction, we adopt a gradient descent search method for feature weight assignment. We propose new patient status and directional change definitions based on medical knowledge or clinical guidelines about the value ranges for different patient status levels, and develop a method to detect change points indicating positive or negative patient status changes. We evaluate the effectiveness of the proposed methods in the context of early Intensive Care Unit mortality prediction. The evaluation results show that the k-Nearest Neighbor algorithm that incorporates methods we select and propose significantly outperform the relevant benchmarks for early ICU mortality prediction. This study makes contributions to time series classification and early ICU mortality prediction via identifying and enhancing temporal feature engineering and reduction methods for similarity-based time series classification.",
    "creator" : "Microsoft® Word 2016"
  }
}