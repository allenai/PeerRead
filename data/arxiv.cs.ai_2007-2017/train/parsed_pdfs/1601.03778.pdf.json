{
  "name" : "1601.03778.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Trust from the past: Bayesian Personalized Ranking based Link Prediction in Knowledge Graphs",
    "authors" : [ "Baichuan Zhang", "Sutanay Choudhury", "Mohammad Al Hasan", "Xia Ning", "Khushbu Agarwal", "Sumit Purohit", "Paola Gabriela Pesntez Cabrera" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 1.\n03 77\n8v 1\n[ cs\n.L G\n] 1\n4 Ja\nn 20\nEstimating the confidence for a link is a critical task for Knowledge Graph construction. Link prediction, or predict-\ning the likelihood of a link in a knowledge graph based on prior state is a key research direction within this area. We\npropose a Latent Feature Embedding based link recommen-\ndation model for prediction task and utilize Bayesian Personalized Ranking based optimization technique for learning\nmodels for each predicate. Experimental results on large-\nscale knowledge bases such as YAGO2 show that our approach achieves substantially higher performance than sev-\neral state-of-art approaches. Furthermore, we also study the performance of the link prediction algorithm in terms of\ntopological properties of the Knowledge Graph and present\na linear regression model to reason about its expected level of accuracy."
    }, {
      "heading" : "1 Introduction",
      "text" : "The past few years have seen a surge in research on knowledge representations and algorithms for building knowledge graphs. A knowledge graph is a repository of information about entities, where entities can be any thing of interest such as people, location, organization or even scientific topics, concepts etc. An entity is frequently characterized by its association with other entities. As an example, capturing the knowledge about a company involves describing its products, listing key individuals, its locations etc. Similarly, knowledge about a person involves her name, date and place of birth, affiliation with organizations etc. Resource Description Framework (RDF) is a frequent choice for capturing the interactions between two entities. A RDF dataset is equivalent to a heterogeneous graph, where each vertex and edge can belong to different classes. The class information captures taxonomic hierarchies between the type of various entities and relations. As an\n∗Department of Computer and Information Science, Indiana University - Purdue University Indianapolis, USA\n†Pacific Northwest National Laboratory, Richland, WA, USA ‡Department of Computer Science, Washington State Univer-\nsity, Pullman, WA, USA\nexample, a knowledge graph may identify Kobe Bryant as a basketball player, while its ontology will indicate that a basketball player is a particular type of athlete. Thus, one will be able to query for most famous athletes in United States and find Kobe Bryant.\nWe are interested in streaming data sources in natural language text and continuous updating a knowledge graph based on newer facts that become available over time. Towards that, we extract triples from the text data sources using state of the art techniques such as OpenIE [9] and semantic role labeling [4]. After passing these triples through a filtering phase we need to decide if every triple should be added to the knowledge graph. We have a number of choices. A triple (or a fact) may be already present in the knowledge graph. Under such circumstances we may choose to update any related metadata. For other facts we need to decide if it should be added to the knowledge graph. This is an extremely challenging problem.\nConsider the following example. Given a social media post “I wish Tom Cruise was the president of United States”, a natural language processing engine will extract a triple (“Tom Cruise”, “president of”, “United States”). On the other hand, a web crawler may find the fact that “Tom Cruise is president of Downtown Medical”, resulting in the triple (“Tom Cruise”, “president of”, “Downtown Medical”). Assuming that we do not have any information about the trustworthiness of the sources, can our prior knowledge of the entities mentioned in this triples allow us to decide on whether to admit or reject a triple? Also, once we decide to add a triple to the knowledge graph, it is desirable to have a confidence value associated with it. There can be multiple sources of confidence such as 1) trustworthiness of the data sources, 2) prior knowledge of subjects and objects, 3) a belief value reported by a natural language processing engine expressing its confidence in the correctness of parsing. This particular work is motivated by the second factor.\nWe adopt a link prediction 1 approach towards computing the confidence in a triple using the prior knowledge about its subject and object. Link prediction is a well established field [11] in the context of social network analysis. Lately, link prediction for heterogenous networks has received significant attention in the data mining community [5, 7, 27]. Bayesian personalized ranking (BPR) [23] based embedding model has been a major influence in this area and is the primary driver behind our approach. We build on the research in collaborative filtering for recommender systems that accept a user-item matrix; given a user-item pair, it returns a score indicating the likelihood of the user purchasing the item. Likewise, under this context, we build a BPR-based embedding model for every relation by casting the set of corresponding subjects and objects as a user-item matrix. Then our proposed method produces a real-valued score to measure the confidence of the given triple.\nIt is important that we quantitatively understand the accuracy of our prediction [28]. Given the same knowledge graph the prediction accuracy levels will vary from predicate to predicate. As an example, predicting one’s school or workplace can be a much harder task than predicting one’s liking for a local restaurant. Therefore, given two predicates “worksAt” and “likes”, we expect to see widely varying accuracy levels. Also, the average accuracy levels vary widely from one knowledge graph to another. The desire to obtain a quantitative grasp on prediction accuracy is complicated by a number of reasons: 1) Knowledge graphs constructed from web text or using machine reading approaches can have a very large number of predicates [6] that make manual verification difficult. 2) Creation of predicates, or the resultant graph structure is strongly shaped by the ontology, and the reification process used to generate RDF statements from a logical record in the data. Therefore, same data source can be represented in very different models and leads to different accuracy levels for the same predicate. 3) The effectiveness of knowledge graphs have inspired their construction from every imaginable data source: product inventories (at retailers such as Walmart), online social networks (such as Facebook), and web pages (Google’s Knowledge Vault). As we move from one data source to another, it is very critical to understand what accuracy levels we can expect from a given predicate.\nOur contributions in this work are outlined below:\n1. We implement a Link Prediction approach for estimating confidence for triples in a Knowledge\n1We use link prediction and link recommendation interchangeably.\nGraph. Specifically, we borrow from successful approaches in the recommender systems domain, adopt the algorithms for knowledge graphs and perform a thorough evaluation on a prominent benchmark dataset.\n2. We propose a Latent Feature Embedding based link recommendation model for prediction task and utilize Bayesian Personalized Ranking based optimization technique for learning models for each predicate (section 4). Our experiments on the well known YAGO2 knowledge graph (in section 5) shows that the BPR approach outperforms other competing approaches for a significant set of predicates (Figure 1).\n3. We apply a linear regression model to quantitatively analyze the correlation between the prediction accuracy for each predicate and the topological structure of the induced subgraph of the original Knowledge Graph. Our studies show that metrics such as clustering coefficient or average degree can be used to reason about the expected level of prediction accuracy (Section 5.3, Figure 2)."
    }, {
      "heading" : "2 Related Work",
      "text" : "There is a large body of work on link prediction/relation extraction in knowledge graph. In terms of methodology, factorization based and related latent variable models [3, 8, 14, 22, 25], graphical model [15], and graph feature based method [18, 19] are considered.\nThere exists large number of works which focus on factorization based models. The common thread among the factorization methods is that they explain the triples via latent features of entities. [2] presents a tensor based model that decomposes each entity and predicate in knowledge graphs as a low dimensional vector. However, such a method fails to consider the symmetry property of the tensor. In order to solve this issue, [22] proposes a relational latent feature model, RESCAL, an efficient approach which uses a tensor factorization model that takes the inherent structure of relational data into account. By leveraging relational domain knowledge about entity type information, [3] proposes a tensor decomposition approach for relation extraction in knowledge base which is highly efficient in terms of time complexity. In addition, various other latent variable models, such as neural network based methods [6, 26], have been explored for link prediction task. However, the major drawback of neural network based models is their complexity and computational cost in model training and parameter tuning. Many of these models require tuning large number of parameters, thus finding the right combination of these parameters\nis often considered more of an art than science. Recently graphical models, such as Probabilistic Relational Models [10], Relational Markov Network [29], Markov Logic Network [15, 24] have also been used for link prediction in knowledge graph. For instance, [24] proposes a Markov Logic Network (MLN) based approach, which is a template language for defining potential functions on knowledge graph by logical formula. Despite its utility for modeling knowledge graph, issues such as rule learning difficulty, tractability problem, and parameter estimation poses implementation challenge for MLNs.\nGraph feature based approaches assume that the existence of an edge can be predicted by extracting features from the observed edges in the graph. Lao and Cohen [18,19] propose Path Ranking Algorithm (PRA) to perform random walk on the graph and compute the probability of each path. The main idea of PRA is to use these path probabilities as supervised features for each entity pair, and use any favorable classification model, such as logistic regression and SVM, to predict the probability of missing edge between entity pair in a knowledge graph.\nIt has been demonstrated [1] that no single based approach emerges as a clear winner. Instead, the merits of factorization models and graph feature models are often complementary with each other. Thus combining the advantages of different approaches for learning knowledge graph is a promising option. For instance, [21] proposed to use additive model, which is a linear combination between RESCAL and PRA. The combination results in not only speeding up the training time but increased accuracy. [16] combined a latent feature model with an additive term to learn from latent and neighborhood-based information on multirelational data. [6] fuses the output of PRA and neural network model as features for training a binary classifier. Our work strongly aligns with this combination approach. We begin with building on techniques that have proved successful for recommender systems and plan to incorporate graph based features in future work."
    }, {
      "heading" : "3 Background and Problem Statement",
      "text" : "Definition 1: We define the knowledge graph as a collection of triple facts G = (S, P,O), where s ∈ S and o ∈ O are the set of subject and object entities and p ∈ P is the set of predicates or relations between them. G(s, p, o) = 1 if there is a direct link of type p from s to o, and G(s, p, o) = 0 otherwise.\nEach triple fact in knowledge graph is a statement interpreted as “A relationship p holds between entities s and o”. For instance, the statement “Kobe Bryant is a player of LA Lakers” can be expressed by the following\ntriple fact (“Kobe Bryant”, “playsFor”, “LA Lakers”). Definition 2: For each relation p ∈ P , we define Gp(Sp, Op) as a bipartite subgraph of G, where the corresponding set of entities sp ∈ Sp, op ∈ Op are connected by relation p, namely Gp(sp, op) = 1.\nProblem Statement: For every predicate p ∈ P and given an entity pair (s, o) in Gp, our goal is to learn a link recommendation model Mp such that xs,o = Mp(s, o) is a real-valued score.\nDue to the fact that the produced real-valued score is not normalized, we compute the probability Pr(yps,o = 1), where yps,o is a binary random variable that is true iff Gp(s, o) = 1. We estimate this probability Pr using the logistic function as follows:\n(3.1) Pr(yps,o = 1) = 1\n1 + exp(−xs,o)\nThus we interpret Pr(yps,o = 1) as the probability that a vertex (or subject) s in the knowledge graph G is in a relationship of given type p with another vertex (or the object) o."
    }, {
      "heading" : "4 Methods",
      "text" : "In this section, we describe our model, namely Latent Feature Embedding Model with Bayesian Personalized Ranking (BPR) based optimization technique that we propose for the task of link prediction in knowledge graph. In our link prediction setting, given predicate p, we first construct its bipartite subgraph Gp(Sp, Op). Then the optimal low dimensional embeddings for its corresponding subject and object entities sp ∈ Sp, op ∈ Op are learned by maximizing a ranking based distance function. The learning process relies on Stochastic Gradient Descent (SGD). The SGD based optimization technique iteratively updates the low dimensional representation of sp and op until convergence. Then the learned model is used for ranking the unobserved triple facts in descending order: triple facts with higher score values have an higher probability of representing true statement that leads to higher confidence to select for admission into knowledge graph."
    }, {
      "heading" : "4.1 Latent Feature Based Embedding Model",
      "text" : "For each predicate p, the model maps both its corresponding subject and object entites sp and op into lowdimensional continuous vector spaces, say Ups ∈ IR 1×K and V po ∈ IR 1×K respectively. We measure the compatibility between subject sp and object op as dot product of its corresponding latent vectors which is given as below:\n(4.2) xsp,op = (U p s )(V p o ) T + bpo\nwhere Up ∈ IR|S|×K , V p ∈ IR|O|×K , and bp ∈\nIR|O|×1. |S| and |O| denote the size of subject and object associated with predicate p respectively. K is the number of latent dimensions and bpo ∈ IR is a bias term associated with object o. Given predicate p, the higher the score of xsp,op , the more similar the entities sp and op in the embedded low dimensional space, which provides higher confidence to include this triple fact into knowledge base."
    }, {
      "heading" : "4.2 Bayesian Personalized Ranking",
      "text" : "In collaborative filtering, positive-only data is known as implicit feedback/binary feedback. For example, in the eCommerce platform, some users only buy but does not rate items. Motivated by [23], we employ Bayesian Personalized Ranking (BPR) based approach for model learning. Specifically, in recommender system domain, given user-item matrix, BPR based approach assigns the preference of user for purchased item with higher score than un-purchased item. Likewise, under this context, we assign observed triple facts higher score than unobserved triple facts in knowledge base. We assume that unobserved facts are not necessarily negative, rather they are “less preferable” than the observed ones.\nFor our task, in each predicate p, we denote the observed subject/object entity pair as (sp, o + p ) and unobserved one as (sp, o − p ). The observed facts in our case are the existing link between sp and op given Gp and unobserved ones are the missing link between them. Given this fact, BPR maximizes the following ranking based distance function:\n(4.3) BPR = max\nΘp\n∑\n(sp,o + p ,o − p )∈Dp lnσ(xsp,o+p − xsp,o−p )− λΘp || Θp ||\n2\nwhere Dp is a set of samples generated from the training data for predicate p, Gp(sp, o + p ) = 1 and Gp(sp, o − p ) = 0. And xsp,o+p and xsp,o−p are the predicted scores of subject sp on objects o + p and o − p respectively. We use the proposed latent feature based embedding model shown in Equation 4.2 to compute xsp,o+p and xsp,o−p respectively. The last term in Equation 4.3 is a l2-norm regularization term used for model parameters Θp = {U\np, V p, bp} to avoid overfitting in the learning process. In addition, the logistic function σ(.) in Equation 4.3 is defined as σ(x) = 11+e−x .\nNotice that the Equation 4.3 is differentiable, thus we employ the widely used SGD to maximize the objective. In particular, at each iteration, for given predicate p, we sample one observed entity pair (sp, o + p ) and one unobserved one (sp, o − p ) using uniform sampling technique. Then we iteratively update the model parameters Θp based on the sampled pairs. Specifically, for\neach training instance, we compute the derivative and update the corresponding parameters Θp by walking along the ascending gradient direction.\nFor each predicate p, given a training triple (sp, o + p , o − p ), the gradient of BPR objective in Equation 4.3 with respect to Ups , V p o+ , V p o− , bp o+ , bp o− can be computed as follows:\n∂BPR\n∂U p s\n= ∂ lnσ(xsp,o+p − xsp,o−p )\n∂U p s\n− 2λpsU p s\n= ∂ lnσ(x sp,o + p −x sp,o − p )\n∂σ(x sp,o + p −x sp,o − p\n) × ∂σ(x sp,o + p −x sp,o − p )\n∂(x sp,o + p −x sp,o − p )\n× ∂(x sp,o + p −x sp,o − p )\n∂U p\ns\n− 2λpsU p s\n= 1\nσ(xsp,o+p − xsp,o−p ) × σ(xsp,o+p − xsp,o−p ) (\n1− σ(xsp,o+p − xsp,o−p ) ) × (V p o+ − V p o− )− 2λpsU p s\n= ( 1− σ(xsp,o+p − xsp,o−p ) ) (V p o+ − V p o− )− 2λpsU p s\n(4.4)\nWe obtain the following using similar chain rule derivation.\n(4.5) ∂BPR\n∂V p\no+\n= ( 1−σ(xsp,o+p −xsp,o−p ) ) ×Ups −2λ p o+ V p o+\n(4.6) ∂BPR\n∂V p\no−\n= ( 1− σ(xsp ,o+p − xsp,o−p ) ) × (−Ups )− 2λ p o− V p o−\n(4.7) ∂BPR\n∂b p\no+\n= ( 1− σ(xsp,o+p − xsp,o−p ) ) × 1− 2λp o+ b p o+\n(4.8) ∂BPR\n∂b p\no−\n= ( 1− σ(xsp,o+p − xsp,o−p ) ) × (−1)− 2λp o− b p o−\nNext, the parameters are updated as follows:\n(4.9) Ups = U p s + α×\n∂BPR\n∂U p s\n(4.10) V p o+ = V p o+\n+ α× ∂BPR\n∂V p\no+\n(4.11) V p o− = V p o−\n+ α× ∂BPR\n∂V p\no−\n(4.12) bp o+ = bp o+\n+ α× ∂BPR\n∂b p\no+\n(4.13) bp o− = bp o−\n+ α× ∂BPR\n∂b p\no−\nwhere α is the learning rate.\nAlgorithm 1 Bayesian Personalized Ranking Based Latent Feature Embedding Model\nInput: latent dimension K, G, target predicate p Output: Up, V p, bp\n1: Given target predicate p and entire knowledge graph G, construct its bipartite subgraph, Gp 2: m = number of subject entities in Gp 3: n = number of object entities in Gp 4: Generate a set of training samples Dp =\n{(sp, o + p , o − p )} using uniform sampling technique\n5: Initialize Up as size m×K matrix with 0 mean and standard deviation 0.1 6: Initialize V p as size n×K matrix with 0 mean and stardard deviation 0.1 7: Initialize bp as size n×1 column vector with 0 mean and stardard deviation 0.1 8: for all (sp, o + p , o − p ) ∈ Dp do\n9: Update Ups based on Equation 4.9 10: Update V p\no+ based on Equation 4.10\n11: Update V p o−\nbased on Equation 4.11 12: Update bp\no+ based on Equation 4.12\n13: Update bp o−\nbased on Equation 4.13 14: end for 15: return Up, V p, bp"
    }, {
      "heading" : "4.3 Pseudo-code",
      "text" : "The pseudo-code of our proposed link prediction model is described in Algorithm 1. It takes the knowledge graph G and a specific target predicate p as input and generates the low dimensional latent matrices Up, V p, bp as output. Line 1 constucts the bipartite subgraph of predicate p, Gp given entire knowledge graph G. Line 2- 3 compute the number of subject and object entities as m and n in resultant bipartite subgraph Gp respectively. Line 4 generates a collection of triple samples using uniform sampling technique. Line 5-7 initialize the matrices Up, V p, bp using Gaussian distribution with 0 mean and 0.1 standard deviation, assuming all the entries in Up, V p and bp are independent. Line 8-14 update corresponding rows of matrices Up, V p, bp based on the sampled instance (sp, o + p , o − p ) in each iteration. As the sample generation step in line 4 is prior to the\nmodel parameter learning, thus the convergence criteria of Algorithm 1 is to iterate over all the sampled triples in Dp."
    }, {
      "heading" : "5 Experiments and Results",
      "text" : "This section presents our experimental analysis of the above algorithms for thirteen unique predicates in the well known YAGO2 knowledge graph [12]. We construct a model for each predicate and describe our evaluation strategies, including performance metrics and selection of state-of-the-art methods for benchmarking in section 5.1. We aim to answer two questions through our experiments:\nTable 1 shows the statistic of various YAGO2 relations used in our experiments. # Subject and # Object represent the number of subject and object entities associated with its corresponding predicate. The last column shown in Table 1 shows the number of facts for each relation in YAGO2. We run all the experiments on a 2.1 GHz Machine with 4GB memory running Linux operating system. The algorithms are implemented in Python language and used NumPy and SciPy libraries for linear algebra operations."
    }, {
      "heading" : "5.1 Experimental Setting",
      "text" : "For our experiment, in order to demonstrate the performance of our proposed link prediction model, we use the YAGO2 dataset and several evaluation metrics for all compared algorithms. Particularly, for each relation, we split the data into a training part, used for model training, and a test part, used for model evaluation. We\napply 5-time leave one out evaluation strategy, where for each subject, we randomly remove one fact (one subjectobject pair) and place it into test set Stest and remaining in the training set Strain. For every subject, the training model will generate a size-N ranked list of recommended objects for recommendation task. The evaluation is conducted by comparing the recommendation list of each subject and the object entity of that subject in the test set. Grid search is applied to find regularization parameters, and we set the values of parameters used in section 4.2 as λs = λo+ = λo− = λb = 0.005. For other model parameters, we fix learning rate α = 0.2, number of latent factors K = 50, maximum number of iterations allowed maxIter = 50 respectively. For parameter in model evaluation, we set N = 10.\nIn order to illustrate the merit of our proposed approach, we compare our model with the following methods for link prediction in a knowledge graph. Since the problem we solve in this paper is similar to one-class item recommendation [23] in recommender systems, we consider the following state-of-the-art oneclass recommendation methods as baseline approaches for comparison.\n1. Random (Rand): For each relation, this method randomly selects subject-object entity pair for link recommendation task.\n2. Most Popular (MP): For each predicate in knowledge base, this method presents a nonpersonalized ranked object list based on how often object entities are connected among all subject entities.\n3. MF: The matrix factorization method is proposed by [17], which uses a point-wise strategy for solving one-class item recommendation problem.\nDuring the model evaluation stage, we use three popular metrics, namely Hit Rate (HR), Average Reciprocal Hit-Rank (ARHR), and Area Under Curve (AUC), to measure the link recommendation quality of our proposed approach in comparison to baseline methods. HR is defined as follows:\n(5.14) HR = #hits\n#subjects\nwhere #subjects is the total number of subject entities in test set, and #hits is the number of subjects whose object entity in the test set is recommended in the size-N recommendation list. The second evaluation metric, ARHR, considering the ranking of the recommended\nobject for each subject entity in knowledge graph, is defined below:\n(5.15) ARHR = 1\n#subjects\n#hits ∑\ni=1\n1\npi\nwhere if an object of a subject is recommended for connection in knowledge graph which we name it hit under this scenario, pi is the position of the object in the ranked recommendation list. As we can see, ARHR is a weighted version of HR and it captures the importance of recommended object in the recommendation list.\nThe last metric, AUC is defined as follows:\n(5.16) AUC = 1#subjects ∑ s∈subjects 1 |E(s)| ∑ (o+,o−)∈E(s) δ(xs,o+ > xs,o−)\nWhere E(s) = {(o+, o−)|(s, o+) ∈ Stest ∩ (s, o −) 6∈ (Stest ∪ Strain)}, and δ() is the indicator function. For all of three metrics, higher values indicate better model performance. Specifically, the trivial AUC of a random predictor is 0.5 and the best value of AUC is 1."
    }, {
      "heading" : "5.2 YAGO2 Relation Prediction Performance",
      "text" : "Figure 1 shows the average link prediction performance for YAGO2 relations using various methods. Our proposed latent feature embedding approach shows significant improvement compared with other algorithms on most of relations in YAGO2. For instance, for all the YAGO2 predicates used in the experiment, our proposed model consistently outperforms MF based method, which demonstrates the empirical experience that pairwise ranking based method achieves much better performance than pointwise regression based method given implicit feedback for link recommendation task. Compared with Popularity based recommendation method MP, our method obtains better performance for most predicates. For example, predicates such as “participate”,“connect”,“hasChild”, and “influence”, our proposed model achieves more than 10 times better performance in terms of both HR and ARHR. However, for several predicates such as “import”, “export”, and “language”, MP based method performs the best among all the competing methods. The good performance of MP is owing to the semantic meaning of specific predicate. For instance, “import” represents Country/Product relation in YAGO, which indicates the types of its subject and object entities are geographic region and commodity respectively. For such predicate, most popular object entities such as food, cloth, fuel are linked to most of countries, which helps\nMP based method maintain good link recommendation performance."
    }, {
      "heading" : "5.3 Analysis and Discussion",
      "text" : "Figure 1 shows that the link prediction model performance widely varies from predicate to predicate in the YAGO2 knowledge base. For example, the HR of predicate “dealsWith” is significantly better than “own”. Thus it is critical that we quantitatively understand the model performance across various relations in a knowledge graph. Recall from the problem statement that given a predicate p, our model Mp only accounts for the bipartite subgraph Gp. Motivated by [20], we study the impact of resultant graph structure of Gp on the performance of Mp.\nFor each predicate p, we compute several graph topology metrics on its bipartite subgraph Gp such as graph density, graph average degree, and clustering coefficient. Figure 2 shows the quantitative analysis between graph structure and link prediction model performance of each predicate. In each subfigure, x-axis represents the computed graph topology metric value of each predicate and y-axis denotes our proposed link prediction model performance in terms of HR, ARHR, and AUC. Each cross point shown in blue represents one specific YAGO2 predicate used in our experiments. Then we developed a linear regression model to understand the correlation between link prediction model performance and each graph metric. For each linear regression curve shown in red, we also report its slope, intercept, and correlation coefficient (rvalue) to capture the association trend.\nFrom Figure 2, both graph density and graph average degree show strong positive correlation signal with proposed link prediction model as demonstrated by rvalue. As our approach is inspired by collaborative filtering for recommender systems that accept a useritem matrix as input, for resultant graph of each predicate, higher graph density indicates higher matrix density in user-item matrix, which naturally leads to better recommendation performance in recommender system domain. Similar explanation can be adapted to graph average degree. For the clustering coefficient, it shows strong negative correlation signal with link prediction model performance. For instance, in terms of AUC, the rvalue is around −0.69. As clustering coefficient (cc) is the number of closed triples over the total number of triples in graph, smaller value of cc indicates lower fraction of closed triples in the graph. Based on the transitivity property of a social graph, which states the friends of your friend have high likelihood to be friends themselves [13], it is relatively easier for link predic-\ntion model to predict (i.e.,hit) such link with open triple property in the graph, which leads to better link prediction performance."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "Inspired by the success of collaborative filtering algorithms for recommender systems, we propose a latent feature based embedding model for the task of link prediction in a knowledge graph. Our proposed method provides a measure of “confidence” for adding a triple into the knowledge graph. We evaluate our implementation on the well known YAGO2 knowledge graph. The experiments show that our Bayesian Personalized Ranking based approach achieves better performance compared with two state-of-art recommender system models: Most Popular and Matrix Factorization. We also develop a linear regression model to quantitatively study the correlation between the performance of link prediction model itself and various topological metrics of the graph from which the models are constructed. The regression analysis shows strong correlation between the link prediction performance and graph topological features, such as graph density, average degree and clustering coefficient.\nFor a given predicate, we built link prediction models solely based on the bipartite subgraph of the original knowledge graph. However, as real-world experience suggests, the existence of a relation between two entities can also be predicted from the presence of other relations, either direct or through common neighbors. As an example, the knowledge of where someone studies and who they are friends with is useful to predict possible workplaces. Incorporating such intuition as “social signals” into our current model will be the prime candidate for future work."
    } ],
    "references" : [ {
      "title" : "Constructing and mining web-scale knowledge graphs: Kdd 2014 tutorial",
      "author" : [ "A. Bordes", "E. Gabrilovich" ],
      "venue" : "SIGKDD, pages 1967–1967,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Parafac",
      "author" : [ "R. Bro" ],
      "venue" : "tutorial and applications. Chemometrics and Intelligent Laboratory Systems, pages 149–171,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Typed tensor decomposition of knowledge bases for relation extraction",
      "author" : [ "K.-W. Chang", "W. tau Yih", "B. Yang", "C. Meek" ],
      "venue" : "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. ACL,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2014
    }, {
      "title" : "Natural language processing (almost) from scratch",
      "author" : [ "R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa" ],
      "venue" : "The Journal of Machine Learning Research, pages 2493–2537,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Multirelational link prediction in heterogeneous information networks",
      "author" : [ "D. Davis", "R. Lichtenwalter", "N.V. Chawla" ],
      "venue" : "ASONAM, pages 281–288. IEEE,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Knowledge vault: A web-scale approach to probabilistic knowledge fusion",
      "author" : [ "X. Dong", "E. Gabrilovich", "G. Heitz", "W. Horn", "N. Lao", "K. Murphy", "T. Strohmann", "S. Sun", "W. Zhang" ],
      "venue" : "SIGKDD, KDD, pages 601– 610,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Link prediction and recommendation across heterogeneous social networks",
      "author" : [ "Y. Dong", "J. Tang", "S. Wu", "J. Tian", "N.V. Chawla", "J. Rao", "H. Cao" ],
      "venue" : "ICDM, pages 181–190. IEEE,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Predicting rdf triples in incomplete knowledge bases with tensor factorization",
      "author" : [ "L. Drumond", "S. Rendle", "L. Schmidt-Thieme" ],
      "venue" : "Proceedings of the 27th Annual ACM Symposium on Applied Computing, pages 326– 331,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Open information extraction from the web",
      "author" : [ "O. Etzioni", "M. Banko", "S. Soderland", "D.S. Weld" ],
      "venue" : "Communications of the ACM, pages 68–74,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Learning probabilistic relational models",
      "author" : [ "N. Friedman", "L. Getoor", "D. Koller", "A. Pfeffer" ],
      "venue" : "IJCAI, pages 1300–1309,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Link prediction using supervised learning",
      "author" : [ "M.A. Hasan", "V. Chaoji", "S. Salem", "M. Zaki" ],
      "venue" : "In Proc. of SDM 06 workshop on Link Analysis, Counterterrorism and Security,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Yago2: Exploring and querying world knowledge in time, space, context, and many languages",
      "author" : [ "J. Hoffart", "F.M. Suchanek", "K. Berberich", "E. Lewis- Kelham", "G. de Melo", "G. Weikum" ],
      "venue" : "In Proceedings of the 20th International Conference Companion on World Wide Web,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2011
    }, {
      "title" : "A latent factor model for highly multirelational data",
      "author" : [ "R. Jenatton", "N.L. Roux", "A. Bordes", "G.R. Obozinski" ],
      "venue" : "Advances in Neural Information Processing Systems 25, pages 3167–3175.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Learning to refine an automatically extracted knowledge base using markov logic",
      "author" : [ "S. Jiang", "D. Lowd", "D. Dou" ],
      "venue" : "ICDM, pages 912–917,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Link prediction in multi-relational graphs using additive models",
      "author" : [ "X. Jiang", "V. Tresp", "Y. Huang", "M. Nickel" ],
      "venue" : "SeRSy, pages 1–12,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Matrix factorization techniques for recommender systems",
      "author" : [ "Y. Koren", "R. Bell", "C. Volinsky" ],
      "venue" : "Computer, pages 30–37,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Relational retrieval using a combination of path-constrained random walks",
      "author" : [ "N. Lao", "W.W. Cohen" ],
      "venue" : "Journal of Machine learning, pages 53–67,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Random walk inference and learning in a large scale knowledge base",
      "author" : [ "N. Lao", "T. Mitchell", "W.W. Cohen" ],
      "venue" : "EMNLP, pages 529–539,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "The link prediction problem for social networks",
      "author" : [ "D. Liben-Nowell", "J. Kleinberg" ],
      "venue" : "CIKM, pages 556–559,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Reducing the rank in relational factorization models by including  observable patterns",
      "author" : [ "M. Nickel", "X. Jiang", "V. Tresp" ],
      "venue" : "NIPS, pages 1179–1187,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "A three-way model for collective learning on multi-relational data",
      "author" : [ "M. Nickel", "V. Tresp", "H. peter Kriegel" ],
      "venue" : "In ICML,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2011
    }, {
      "title" : "Bpr: Bayesian personalized ranking from implicit feedback",
      "author" : [ "S. Rendle", "C. Freudenthaler", "Z. Gantner", "L. Schmidt-Thieme" ],
      "venue" : "UAI, pages 452–461,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Markov logic networks",
      "author" : [ "M. Richardson", "P. Domingos" ],
      "venue" : "Machine learning, pages 107–136,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Relation extraction with matrix factorization and universal schemas",
      "author" : [ "S. Riedel", "L. Yao", "A. McCallum", "B.M. Marlin" ],
      "venue" : "Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings, pages 74–84,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Reasoning with neural tensor networks for knowledge base completion",
      "author" : [ "R. Socher", "D. Chen", "C.D. Manning", "A. Ng" ],
      "venue" : "NIPS, pages 926–934,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "When will it happen?: relationship prediction in heterogeneous information networks",
      "author" : [ "Y. Sun", "J. Han", "C.C. Aggarwal", "N.V. Chawla" ],
      "venue" : "WSDM, pages 663–672. ACM,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Trust, but verify: Predicting contribution quality for knowledge base construction and curation",
      "author" : [ "C.H. Tan", "E. Agichtein", "P. Ipeirotis", "E. Gabrilovich" ],
      "venue" : "WSDM, pages 553–562. ACM,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Discriminative probabilistic models for relational data",
      "author" : [ "B. Taskar", "P. Abbeel", "D. Koller" ],
      "venue" : "UAI, pages 485–492,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "Towards that, we extract triples from the text data sources using state of the art techniques such as OpenIE [9] and semantic role labeling [4].",
      "startOffset" : 109,
      "endOffset" : 112
    }, {
      "referenceID" : 3,
      "context" : "Towards that, we extract triples from the text data sources using state of the art techniques such as OpenIE [9] and semantic role labeling [4].",
      "startOffset" : 140,
      "endOffset" : 143
    }, {
      "referenceID" : 10,
      "context" : "Link prediction is a well established field [11] in the context of social network analysis.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 4,
      "context" : "Lately, link prediction for heterogenous networks has received significant attention in the data mining community [5, 7, 27].",
      "startOffset" : 114,
      "endOffset" : 124
    }, {
      "referenceID" : 6,
      "context" : "Lately, link prediction for heterogenous networks has received significant attention in the data mining community [5, 7, 27].",
      "startOffset" : 114,
      "endOffset" : 124
    }, {
      "referenceID" : 25,
      "context" : "Lately, link prediction for heterogenous networks has received significant attention in the data mining community [5, 7, 27].",
      "startOffset" : 114,
      "endOffset" : 124
    }, {
      "referenceID" : 21,
      "context" : "Bayesian personalized ranking (BPR) [23] based embedding model has been a major influence in this area and is the primary driver behind our approach.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 26,
      "context" : "It is important that we quantitatively understand the accuracy of our prediction [28].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 5,
      "context" : "The desire to obtain a quantitative grasp on prediction accuracy is complicated by a number of reasons: 1) Knowledge graphs constructed from web text or using machine reading approaches can have a very large number of predicates [6] that make manual verification difficult.",
      "startOffset" : 229,
      "endOffset" : 232
    }, {
      "referenceID" : 2,
      "context" : "In terms of methodology, factorization based and related latent variable models [3, 8, 14, 22, 25], graphical model [15], and graph feature based method [18, 19] are considered.",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 7,
      "context" : "In terms of methodology, factorization based and related latent variable models [3, 8, 14, 22, 25], graphical model [15], and graph feature based method [18, 19] are considered.",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 12,
      "context" : "In terms of methodology, factorization based and related latent variable models [3, 8, 14, 22, 25], graphical model [15], and graph feature based method [18, 19] are considered.",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 20,
      "context" : "In terms of methodology, factorization based and related latent variable models [3, 8, 14, 22, 25], graphical model [15], and graph feature based method [18, 19] are considered.",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 23,
      "context" : "In terms of methodology, factorization based and related latent variable models [3, 8, 14, 22, 25], graphical model [15], and graph feature based method [18, 19] are considered.",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 13,
      "context" : "In terms of methodology, factorization based and related latent variable models [3, 8, 14, 22, 25], graphical model [15], and graph feature based method [18, 19] are considered.",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 16,
      "context" : "In terms of methodology, factorization based and related latent variable models [3, 8, 14, 22, 25], graphical model [15], and graph feature based method [18, 19] are considered.",
      "startOffset" : 153,
      "endOffset" : 161
    }, {
      "referenceID" : 17,
      "context" : "In terms of methodology, factorization based and related latent variable models [3, 8, 14, 22, 25], graphical model [15], and graph feature based method [18, 19] are considered.",
      "startOffset" : 153,
      "endOffset" : 161
    }, {
      "referenceID" : 1,
      "context" : "[2] presents a tensor based model that decomposes each entity and predicate in knowledge graphs as a low dimensional vector.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 20,
      "context" : "In order to solve this issue, [22] proposes a relational latent feature model, RESCAL, an efficient approach which uses a tensor factorization model that takes the inherent structure of relational data into account.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 2,
      "context" : "By leveraging relational domain knowledge about entity type information, [3] proposes a tensor decomposition approach for relation extraction in knowledge base which is highly efficient in terms of time complexity.",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 5,
      "context" : "In addition, various other latent variable models, such as neural network based methods [6, 26], have been explored for link prediction task.",
      "startOffset" : 88,
      "endOffset" : 95
    }, {
      "referenceID" : 24,
      "context" : "In addition, various other latent variable models, such as neural network based methods [6, 26], have been explored for link prediction task.",
      "startOffset" : 88,
      "endOffset" : 95
    }, {
      "referenceID" : 9,
      "context" : "Recently graphical models, such as Probabilistic Relational Models [10], Relational Markov Network [29], Markov Logic Network [15, 24] have also been used for link prediction in knowledge graph.",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 27,
      "context" : "Recently graphical models, such as Probabilistic Relational Models [10], Relational Markov Network [29], Markov Logic Network [15, 24] have also been used for link prediction in knowledge graph.",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 13,
      "context" : "Recently graphical models, such as Probabilistic Relational Models [10], Relational Markov Network [29], Markov Logic Network [15, 24] have also been used for link prediction in knowledge graph.",
      "startOffset" : 126,
      "endOffset" : 134
    }, {
      "referenceID" : 22,
      "context" : "Recently graphical models, such as Probabilistic Relational Models [10], Relational Markov Network [29], Markov Logic Network [15, 24] have also been used for link prediction in knowledge graph.",
      "startOffset" : 126,
      "endOffset" : 134
    }, {
      "referenceID" : 22,
      "context" : "For instance, [24] proposes a Markov Logic Network (MLN) based approach, which is a template language for defining potential functions on knowledge graph by logical formula.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 16,
      "context" : "Lao and Cohen [18,19] propose Path Ranking Algorithm (PRA) to perform random walk on the graph and compute the probability of each path.",
      "startOffset" : 14,
      "endOffset" : 21
    }, {
      "referenceID" : 17,
      "context" : "Lao and Cohen [18,19] propose Path Ranking Algorithm (PRA) to perform random walk on the graph and compute the probability of each path.",
      "startOffset" : 14,
      "endOffset" : 21
    }, {
      "referenceID" : 0,
      "context" : "It has been demonstrated [1] that no single based approach emerges as a clear winner.",
      "startOffset" : 25,
      "endOffset" : 28
    }, {
      "referenceID" : 19,
      "context" : "For instance, [21] proposed to use additive model, which is a linear combination between RESCAL and PRA.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 14,
      "context" : "[16] combined a latent feature model with an additive term to learn from latent and neighborhood-based information on multirelational data.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 5,
      "context" : "[6] fuses the output of PRA and neural network model as features for training a binary classifier.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 21,
      "context" : "Motivated by [23], we employ Bayesian Personalized Ranking (BPR) based approach for model learning.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 11,
      "context" : "This section presents our experimental analysis of the above algorithms for thirteen unique predicates in the well known YAGO2 knowledge graph [12].",
      "startOffset" : 143,
      "endOffset" : 147
    }, {
      "referenceID" : 21,
      "context" : "Since the problem we solve in this paper is similar to one-class item recommendation [23] in recommender systems, we consider the following state-of-the-art oneclass recommendation methods as baseline approaches for comparison.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 15,
      "context" : "MF: The matrix factorization method is proposed by [17], which uses a point-wise strategy for solving one-class item recommendation problem.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 18,
      "context" : "Motivated by [20], we study the impact of resultant graph structure of Gp on the performance of Mp.",
      "startOffset" : 13,
      "endOffset" : 17
    } ],
    "year" : 2017,
    "abstractText" : "Estimating the confidence for a link is a critical task for Knowledge Graph construction. Link prediction, or predicting the likelihood of a link in a knowledge graph based on prior state is a key research direction within this area. We propose a Latent Feature Embedding based link recommendation model for prediction task and utilize Bayesian Personalized Ranking based optimization technique for learning models for each predicate. Experimental results on largescale knowledge bases such as YAGO2 show that our approach achieves substantially higher performance than several state-of-art approaches. Furthermore, we also study the performance of the link prediction algorithm in terms of topological properties of the Knowledge Graph and present a linear regression model to reason about its expected level",
    "creator" : "LaTeX with hyperref package"
  }
}