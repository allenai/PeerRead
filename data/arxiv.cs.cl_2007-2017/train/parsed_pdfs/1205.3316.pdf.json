{
  "name" : "1205.3316.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Arabic Language Learning Assisted by Computer, based on Automatic Speech Recognition",
    "authors" : [ "Naim TERBEH", "Mounir ZRIGUI" ],
    "emails" : [ "terbehnaim1987@gmail.co", "mounir.zrigui@fsm.rnu.tn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Computer Assisted Language Learning (CALL), Arabic Language, Automatic Speech Recognition (ASR), Acoustic Model, Acoustic-Phonetic Decoding (APD), Forced Alignment."
    }, {
      "heading" : "1. Introduction",
      "text" : "The computer-assisted learning has benefited from the revolution of information technology caused by the emergence of multimedia computers. There are thousands of educational CD-ROM on market. The topics covered are vast: art, language learning, science, encyclopedias etc... Today, teaching by computer is on an extremely favorable terrain [24]. This article will attempt to show what is done and what can be done to integrate these tools of automatic speech processing in the software language learning by computer. We uses the technique of forced alignment to see the degree of correspondence between the model proposed by the teacher and the learner."
    }, {
      "heading" : "2. Work Context",
      "text" : "This work takes place within the Research Laboratory Information and Communication Technology and Electrical Engineering (LATICE, Monastir unit). This article is part General of CALL, it is among the work of the computerbased Arabic language learning using automatic Arabic speech processing. We present in this work, at first, building the foundations of our speech recognition system. Next, we present our system of CALL in these parts of design, testing and discuss the results."
    }, {
      "heading" : "3. Arabic Language",
      "text" : "Arabic is the language spoken originally by the Arabs. It is a Semitic language (as Akkadian and Hebrew). Within this set, it belongs to the Southern Semitic subgroup. Because of territorial expansion in the Middle Ages and the dissemination of the Koran, this language has spread throughout North Africa and Minor Asia. Arabic has 445 million speakers to be ranked fourth in the number of speakers, ranked eighth in number of pages that circulate on the Internet [4, 3]. By its morphological and syntactic proprieties, Arabic language is considered difficult to control in the field of automatic language processing [5,6]. this difficulty requires new methods that facilitate learning of Arabic, which is a CALL."
    }, {
      "heading" : "4. Existing Systems",
      "text" : "For the most spoken languages in the world, several works on Assisted Computer Language Learning exist, we can mention:\n− One of the first systems well documented is Plato (Programmed Logic for Automated Teaching Operations), developed at the University of Illinois and used for the teaching of Russian and other languages from 1970. As its name suggests, this authoring system is in the pedagogic movement of \"teaching machines\" of Skinner: is used to present information and generate structural exercises. In France, from 1969 and in the center \"Computers for Education\" of Paris VII, Francoise Demaizière develops software for English learning of English and devoted a thesis to this subject, including analyzing how enunciation of \"dialogue\" machinelearner. More recent work within the approach \"Computer tutor\" often stand in the behaviorist paradigm and hold a better hand account of developments in language teaching and have the other almost always an experimentation with learners, according to a paradigm psycholinguistics at most[7]. − An other is the system Kanda in Tokyo for English, German, French, Spanish and Chinese [8]. − Also note Mirto, LIDILEM developed in the laboratory of Grenoble. The project Mirto (MultiInteractive Learning through Research on Texts and\nOral) is conducting a platform of language-teaching materials that use of linguistic material (for example: linguistics). MIRTO aims to put at the service teachers, resources and tools of NLP to enable them to design lesson plans exploiting the diversity and richness of the textual corpus. The scenarios will be developed are be used by learners from distance or face. The system should provide the possibility to calculate the \"Profile\" of each learner (mainly by exploiting its replies and its route), to provide an explanation of his mistakes and adapt scenarios to knowledge/skills in the course material for each learner[9]. Mirto is intended as a tool and environment serving language teachers, can allow them to express and implement proposals and solutions to problems relating to language teaching. We assume that these proposals and solutions can be conceived only through domain concepts. In this sense, any tool used must not only not to impose specific constraints, but allow easy manipulation of these concepts and facilitate their implementation [9]. − The project of the OPE [10], at the University of Paris VII, for the English language learning has a work of the CALL.\nThese achievements have undoubtedly a significant educational value, but they are limited by that they are applied only to the written language. we see that it is interesting to focus on the computer-assisted learning with automatic speech recognition, giving the student the ability to control his speaking. To our knowledge, little research has been done in this direction, we note the work of B. Northmann [11] at the University of Illinois, who proposed a project limited to the simulation of differences in pronunciation between teacher and student, and try to bring that possible the pronunciation of the learner to model proposed by the teacher.\nAmong the studies that are interested in Arabic, we can cite the work below:\n− El-Kasasy [19] developed a system for learning the Koran holy. This system is based on segmentation of the signal in syllabic units. Each segment of the test is compared to the reference, then the system accepts or rejects the segment, it will not give detailed comments on the error.\n− Omar proposed in [20] a system for identifying learner's pronunciation based on hidden Markov model (HMM). He brought together, in this work, different types of acceptable pronunciations of Arabic phonemes and compares them with the pronunciation's speaker to decide whether they are acceptable or not. The system involves two steps: First, the input pronunciation is segmented into phonemes. However, at this stage, substitution\nerrors, insertion and deletion between phonemes of the search word is detected. Second, these units are processed by HMM.\nWe see that it is worth taking advantage of the automatic speech recognition for to the computer assisted foreign language learning."
    }, {
      "heading" : "5. Automatic Speech Recognition",
      "text" : "The Automatic Speech Recognition (ASR) is a computer technology that allows a machine to extract the message oral contained in a speech signal. This technology uses computational methods in areas of signal processing and artificial intelligence. The What applications can imagine are many: help people with disabilities, control vocally machines, book flights, learn other languages, data entry, etc... Most applications in RAP use technology based on Hidden Markov Models (HMM), which are capable of simultaneously modeling time and frequency characteristics of the voice signal. This technology offers high performance algorithms for learning and recognition, whereby HMM proved the best adapted to the problems of speech recognition. However they have limitations and difficulties, which lie mainly in the choice of a good initial model for learning and modeling of phoneme duration [12,13]."
    }, {
      "heading" : "5.1. State of the art",
      "text" : "The automatic speech processing opens up new perspectives in view of the considerable difference between the manual and classical command and voice. The use of the natural language in human-machine puts technology within reach of all and leads to its extension, reducing constraints on the use of keyboards, mice and command codes to master. By simplifying the protocol human-computer dialogue, the Automatic Speech Treatment is therefore also an increase in productivity since it is the machine that adapts to humans to communicate, and not vice versa. Moreover, it makes possible the use Simultaneous eyes or hands to another tasks. It allows to humanize computer systems of information management, focusing their design on users. Basically, the voice recognition software used primarily to enter text mass while spending keyboard (which offers a rate of 50 words per minute, against more than 150 per minute for speech) the keyboard remains still necessary corrections to text and use the computer."
    }, {
      "heading" : "5.2. Stages of recognition",
      "text" : "The following diagram (Fig.1), present the process chain of automatic speech recognition.\nFrom a speech signal, the first treatment is to extract the parameters characteristics after pretreatment is done on frames of short duration (5 to 30 ms) used to improve the input signal, to reduce noise and eliminate the signal \"not talk\" (silence, music, etc ...). Then, to extract a feature vector (acoustic vector) for classification. The characteristic parameters generated are set in input of a module acoustic or an acoustic-phonetic decoding. The latter in turn can produce one or more phonetic hypotheses generally associated with a probability for each segment of the speech signal. This hypothesis generator is often modeled by local statistical models of elementary units of speech, for example a phoneme. To train the acoustic models, we learn models of acoustic units of a tagged corpus. The hypothesis generator interacts with a lexical module to force the acoustic-Phonetic decoding to recognizing only words represented in the lexical module. phonetic Models are represented by a dictionary of pronunciations (phonetic dictionary) or by the possibility of being represented by probabilistic automaton which are able to associate a probability to each possibility of word's pronunciation. What sets the automatic recognition of continuous speech with large vocabulary compared to that of isolated words is that the hypothesis generator interacts with a module syntactic to force the recognition system to take into account the constraints syntactic or semantic. These constraints are formalized by language models. For recognize what is said, firstly, we look, using the models of acoustic units, unit which is supposed to have been produced, then build, from the succession of acoustic units and a statistical language model, the following words most probably. The Bayesian equation applied to the topic of automatic speech recognition is formally summarized as follows: Let x be a sequence of acoustic vectors and unknown wi (i = 1 .. K) a K possible classes for this observation (phonemes, words, ...). Class recognized is:\nThe recognized word w* will be the one that maximizes this quantity, among all candidate words wi. The probabilities P(x|wi) to observe the signal x given the sequence wi require a acoustic model to be estimated. The priori probability P(wi) of the sequence, regardless of signal, need a language model to be estimated. P(x) is the probability of the signal. It is the same for all possible sequences so its value is not taken into account."
    }, {
      "heading" : "5.3. Corpus",
      "text" : "To make our system of automatic Arabic speech recognition, a corpus of multi-dialects voice is realized. This vocal database is in mono speaker with a 16khz sampling as shown in the following table (Table 1).\nThe task of preparing corpus requires much attention to the selection of the words most representative from any domain and save them to the highest possible quality that allows a higher recognition rate. The most words used in the exchange of speeches are practically the same used for newspaper articles. Following this approach, we consulted the newspapers published in Arabic language to manually select the words more employees daily. We arrived to clear approximately 3500 words, most present in the Arabic spoken in various areas of daily life: politics, sports, economy, business, etc...\nThe recording of these words with three speakers, downloading the voice AASR corpus [14], and profit of the corpus realized by [15] allows us to reach almost 6 hours of recordings. The following table summarizes in detail the body's vocal resources of our work. in our work, we seek a little more robustness to the different Arabic dialects, which justifies the choice of AASR corpus with the dialect of golf country and Egypt.\nThe following table (Table 3) summarizes our corpus of work in statistical terms: learning and test."
    }, {
      "heading" : "5.4. List of Arabic Phonemes",
      "text" : "The phoneme is the unit that the decoder will recognize. We noted in Table 4 lists of the 44 phonemes used in our work. At the end of this list, we added the standard phoneme /SIL/ ([14], [21], [22]) which corresponds to periods of blank space between units of words.\n• Short vowels /AE/, /IH/ and /UH/ match diacritical marks in Arabic Fatha, Dhamma, Kasra. • Long vowels are /AE :/, /IY/ and /UW/. • The short vowel /AH/ is the diacritical mark of\nArabic Fatha happens after an emphatic, that is long /AH:/.\n• The short vowel / IX / corresponds to the diacritical mark of Arabic Kasra with Tafkhim, that is long /IX:/. • The short vowel /AA/ corresponds to the diacritical mark of Arabic Fatha happens after a 'Tafkhim' (/R/ or /Q/), is the long /AA :/. • The language vowel /UX/ corresponds to the Arabic diacritical mark of dhamma happens after a 'Tafkhim'. • The phonemes /b/ and /D/ are similar to their English counterparts. • The phonemes /M/ and /N/ are also similar to their English counterparts. • /DD/ and /DH2/ correspond to the sounds of Arabic letters Thad (That as in English) and Dhad. • /JH/ probe corresponds to the Arabic letter Jim. • The phonemes /T/ and /K/ are fundamentally similar\nto their English counterparts. • The sound of the letter occlusive Qaf is represented\nby the phoneme /Q/. • The Hamza is represented by the phoneme /E/. • Fricatives deaf Arab /F/, /S/, /TH/, /SH/ and /H/ are\nfundamentally similar to their English counterparts. • Furthermore, the Arabic phonemes /SS/, /HH/\nand /KH/ are the sounds: Sad, Hah, and Khah. • The phonemes /AI/, /GH/, /Z/, and /DH/ correspond\nto the sounds: Ain, Ghain, Zain and Thel. • The phonemes /Y/, /W/, /L/ and /R/ correspond to\nthe sounds Yeh, Waw, Lam, and Reh. • The phoneme /AY/ and /AW/ correspond to the\nsounds Y and W with a Sukun."
    }, {
      "heading" : "5.5. Pronunciation Dictionary",
      "text" : "The dictionary is one of the textual components which is required for learning and recognition. It associates with each word one or more sequences of phonemes. So, one or several variations of acoustic pronunciations refer to the same written word. The quality of a automatic speech recognition system is highly dependent to the accuracy of pronunciation dictionary. The pronunciation dictionary must contain all words in the corpus to provide a important recognition rate, for that, we spent a significant period of our work, for build the dictionary. We had led finally to 25,841 words which is dictionary size sufficient to contain all the words in the corpus and ensure a significant recognition rate. Creating a dictionary of pronunciations based necessarily on the list of Arabic phonemes noted in the previous session. The following figure (Fig. 2) shows an excerpt from the dictionary used in our work."
    }, {
      "heading" : "5.6. Acoustic-Phonetic Decoding",
      "text" : "This process is responsible for generating, from a speech signal, the sequence of the phonemes more probably. This sequence of phonemes is based on parameter vectors extracted from the speech signal and assumptions provided by the acoustic model and the language model.\nThe module consists of two sub models: the first is to generate the representative parameters of the signal (Fig. 3) because the decoder can't process signals in wav format so must first extract the MFCC parameters. The second, it's the decoding it self. So, the necessary elements for the acoustic-phonetic decoding are:\n− The MFCC parameters − The Acoustic Model − The language model\nThis is an illustration that best sums up the phenomenon of acoustic-phonetic decoding, in following figure (Fig. 4)."
    }, {
      "heading" : "5.7. Principle of Forced Alignment",
      "text" : "This treatment involves aligning speech signals with corresponding transcriptions, locate the phonetic description of the speech signal in the phonetic dictionary, identify the boundaries phonemic in the registration and assign a score to each phoneme depending on the distance separates from the norm which is the acoustic model. We performed alignment with the Sphinx-align tool (in the box Sphinx3) who has possible to align the speech signal with the transcription. To do this, simply, we give the paths to the data signals that are necessary on MFCC format, the transcriptions, the phonetic dictionary and the acoustic model.\nOnce completed the forced alignment we get a segmented corpus into phonemes with results files that contain the start time and end time for each number of frames and the score which was affected, we find at the end of the file the sum of all scores for each signal."
    }, {
      "heading" : "5.8. Tests and Results",
      "text" : "The purpose of evaluation of our recognition system we make the training and testing on speech corpus previously noted, the latter is characterized by multi-phrase: 5 male speakers and 4 female speakers. The results obtained are very satisfactory, indeed, we could achieve an important recognition rate. The results obtained are summarized as follows:\nCorrect= 88.3% WER= 11.7%\nWith: Correct is the recognition rate, WER is the error rate (Word Error Rate). Respecting the following formulas:\nPercent Correct = (N-D-S) / N (2) Percentage WER = 100-Percent Correct (3)\nWith: N the number of labels in the file transcription, D the number of deletions, S the number of substitutions.\nThe results obtained are very satisfactory given the size of our training corpus is relatively small with a reduced number of speakers. It is recommended that learning with nearly 500 different voices to reach a recognition rate of 100% [16]. we did not use a large corpus for learning, but our results are already encouraging."
    }, {
      "heading" : "5.9. Comparing and Discussing",
      "text" : "To testing the effectiveness of our ASR system, we chose two other speech recognition for isolated words [17,18] and we made comparisons as the following table (Table 4) presents.\nThe scene is full of much research work on the topic of speech recognition then our choice is justified by the type of recognition (recognition of isolated words for Arabic language). So, to ensure a logical of comparison, both systems are chosen for isolated words."
    }, {
      "heading" : "5.10. Conclusion",
      "text" : "Seeing the recognition rate corresponding to each size of the corpus, although we note that it is not the primary factor that affects the results of a speech recognition system. So we must ensure a certain harmony between several factors: size's corpus, size of the pronunciation dictionary, recording quality (the least possible noise), the accuracy of the transcripts, good and correct pronunciation, proper approach, etc..."
    }, {
      "heading" : "6. CALL Applications",
      "text" : "The computer-assisted learning has attracted considerable attention in recent years [23]. Much research has been done to improve these systems particularly in the field of foreign language teaching. Along this section, we describe our system and the learning results of the Arabic spoken language assisted by computer. This work was developed to teach people (French) speak Arabic as foreign language, the correct pronunciation of phonemes. This application uses our automatic speech recognition system to detect errors in the pronunciation of the learner."
    }, {
      "heading" : "6.1. Design of our System",
      "text" : "This system consists of a mosaic of sub-program managed by a main program that allows users to interact firstly with the teacher in the design phase of programmed instructions, and subsequently, with the student during the lesson itself. The operator-machine dialogue (teacher or student) is usually provided through a keyboard, screen and microphone."
    }, {
      "heading" : "6.1.1. The role of the teacher:",
      "text" : "the teacher should call the lesson and then:\n− Select the words according to study problems of pronunciation adapted to grade level: Level 1 (A1), Level 2 (A2) or level 3 (B1). − The teacher supervises the system and decide whether to grant the words that were chosen by him even for learners."
    }, {
      "heading" : "6.1.2. The role of the learner:",
      "text" : "learner \"works\" as follows:\n− The student pronounces the words chosen by the teacher."
    }, {
      "heading" : "6.1.3. The role of the system:",
      "text" : "the system can produce results according to the pronunciation of the learner: - If the pronunciation was incorrect, then the system returns the word after stressing the instead of faulty pronunciation. - If the floor is too far from the model proposed by the teacher, especially if it is not provided that the fault that there will be only the error message. - In the latter case one may ask:\n• To go directly to the hearing of the next word and continuing work. • Either repeat the word as many times if the teacher wants.\nAll these rules are designed to make our system a very simple application that provides a genuine dialogue with the student, even in the absence of the teacher."
    }, {
      "heading" : "6.2. Grouping of Phonemes",
      "text" : "Phonemes present different challenges for each class, for learners. So, we find best to group them into classes as shown in Table 5.\nWe explain here the abbreviation used in this table (Table 5)\nLSVG : Long or short vowel germination WUS: Words with unfamiliar sounds SEOL: Sounds that exist in other languages MFH : Middle and final “hamza” EL: Emphatic Letters US : Unproblematic Sounds"
    }, {
      "heading" : "6.2. The process of CALL: Tests and Results",
      "text" : "This paragraph addresses the test procedure of our system. This application was tested for sound information in its ability to provide statistics on a student and on a level. Systematic tests on a large Arabic corpus (from the order of 562 words) selected by a linguist and categorized according to the grouping in table 5. The words are probably frequently used in daily life. They left as follows:\n− Its not pose problems: 62 words. − Letters emphatic: 100 words. − Hamza in the middle and end: 100 words. − Sounds existing in other languages: 100mots. − Words with unfamiliar sounds: 100 words. − Long vowel or short vowel and gemination: 100\nwords. This system was tested by 13 French students from the Bourguiba Institute of Modern Languages, Tunisia, after learning of foreign languages, Arabic in our case. The following figures show the level statistics of each student for each class of Arabic phonemes."
    }, {
      "heading" : "6.3. Discuss",
      "text" : "Note that the phonemes that exist in other languages do not have problems for learners at different levels, against the unknown phonemes cause pronunciation problems for most of the learners. The results for the emphatic letters (Figure 8) do not exceed the rate of 50% for at least 80% of learners so the teacher must more working on this side. Another problem of pronunciation for language vowels and gemination is been remarked upon seeing the results in Figure 6. Generally, results and statistics of our system: spoken language learning: case of Arabic language, are very satisfactory. Previous statistics show levels of each student over his pronunciation difficulties of each class of phonemes. These statistics are very useful for the teacher to automatically detect errors in the pronunciation of each learner."
    }, {
      "heading" : "6.4. Conclusion",
      "text" : "Analysis of forced alignment scores has us to give an idea of phonemes that cause problems for learners and the phonemes that are easier to master. We noticed that the sounds with characteristics similar to those of the mother tongue of learners are more difficult to master, in our case (Mother language: French, Foreign language: Arabic). Emphatic phonemes are the hardest to master. One of the difficult characteristics to control for learners is the duration of phonemes. We noticed this problem in the analyzes made of the short vowels and long vowels of Arabic and to gemination."
    }, {
      "heading" : "7. Future Works",
      "text" : "During this work, we have not considered the level of each student which opens the focuses on a possible improvement based on the properties of each level (A1, A2, B1) and problems encountered by learners to another level. We find it interesting to make tests on all the phonemes of Arabic dialects [25], in more targeted at all levels even those that are considered advanced, and trying to incorporate more nationalities for learners. This is more than interesting as\npossible to improve the sound references and review corrective messages."
    }, {
      "heading" : "8. Conclusion",
      "text" : "During this work, we got to build a corpus of six hours of speech recordings, we consult the operating mode of the recognition engine of Sphinx3 and make tests on this corpus. The results are satisfactory. In the second part, we presented our system of Computer Assisted foreign language Spoken learning: case of Arabic, it is based on the formalism of the Automatic Arabic Speech recognition. Our system has advantages over other work existing: it uses as a acoustic model of the Arabic speech based on hidden Markov model which gives results in the form of phonetic structures against by other works assume that the input signal is already phonetically labeled (as the case of El-Kasasy [19]). The help and correction messages show also a great advantage for our system.\n9. References\n[1]. http://cmusphinx.sourceforge.net. [2]. J-P.HATON, C.Cerisara, D.Fohr, Y.Laprie, K.Smaiili, Reconnaissance Automatique de la Parole: du signal à son interprétation, Belgique, mai 2006. [3]. SIL International, Ethnologue: Languages of the World, 15th Edition, ISBN 1-55671-159-X, 1272 pages, SIL International, Dallas, 2005. [4].http://fr.wikipedia.org/wiki/Liste_des_langues_par_nombr e_total_de_locuteurs. [5]. O. A LJLAYL , M. AND F RIEDER. On arabic search: Improving the retrieval effectiveness via a light stemming approach. In 11 the International Conference on Information and Knowledge Management (CIKM), pages 340–347, Virginia, USA, 2002. [6]. L.S. L ARKEY, L. BALLESTEROS et M.E. CONNELL. Improving stemming for Arabic information retrieval: light stemming and co-occurrence analysis. In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval, pages 275 –282, Tampere, Finland, 2002. [7]. Paru comme: Mangenot, F. (2005) «Seize ans de recherches en apprentissage des langues assisté par ordinateur». In Plurilinguisme et apprentissages, Mélanges Daniel Coste, p. 313-322. Lyon, ENS Editions. [8]. Simon J. « L’éduction et l’informatisation de la société » Rapport au président de la république. 1981. [9]. Georges Antoniadis, Claude Ponton , MIRTO : un système au service de l'enseignement des langues , LIDILEM – Université Stendhal de Grenoble, France , UNTELE 2004 [10]. Bestougeff H. Thèse de l’état université de Paris VII, 1970. [11]. Nord-mann B. « A comparative study of some visual speech displays » Rapport de contract Université Illinois USA, 1981.\n[12]. Aymen Trigui, Mohsen Maraoui, Mounir Zrigui: Acoustic Study of the Gemination Effect in Standard Arabic Speech. IPCV 2010: 192-196. [13]. Aymen Trigui, Mohsen Maraoui, Mounir Zrigui: The Gemination Effect on Consonant and Vowel Duration in Standard Arabic Speech. SNPD 2010: 102-105. [14]. http://www.ccse.kfupm.edu.sa/~elshafei/AASR.htm. [15]. M-A.BenJannet, Construction d'un corpus vocal pour l'Arabe, PFE à l'unité de recherche LATICE, MonastirTunisie, juin 2010. [16]. X.Huang, A. Acero, H. Hon, \"Spoken language processing a guide to theory, algorithm and system design\",Prentice Hall, 2001. [17]. H.Satori, Système de Reconnaissance Automatique de l’arabe basé sur CMUSphinx. [18]. N.Bakir, Reconnaissance Automatique des chiffres arabes en milieu réel par fusion audiovisuelle. [19]. El-Kasasy M. « An Automatic Speech Verification System » Thèse, Cairo University, Faculty of Engineering Department of Electronics and Communications Egypt, 1992. [20] Mourad Mars, Georges Antoniadis, Mounir Zrigui: Statistical Part Of Speech Tagger for Arabic Language. IC-AI 2010: 894-899. [21]. M.Belgacem, Reconnaissance automatique de la parole et ALAO: Vers un système d'apprentissage de l'arabe oral, thèse de doctorat de l'université standhal-Grenoble3, décembre 2011. [22]. Anis Zouaghi, Mounir Zrigui, Georges Antoniadis: Automatic Understanding of Spontaneous Arabic Speech - A Numerical Model. TAL 49(1): 141-166 (2008). [23]. Mohsen Maraoui, Georges Antoniadis, Mounir Zrigui: CALL System for Arabic Based on Natural Language Processing Tools. IICAI 2009: 2249-2258. [24]. Mohsen Maraoui, Georges Antoniadis, Mounir Zrigui: SALA: Call System for Arabic Based on NLP Tools. IC-AI 2009: 168-172. [25]. Mohamed Belgacem, Mounir Zrigui: Automatic Identification System of Arabic Dialects. IPCV 2010: 740- 749."
    } ],
    "references" : [ {
      "title" : "On arabic search: Improving the retrieval effectiveness via a light stemming approach",
      "author" : [ "M.O. A LJLAYL", "F RIEDER" ],
      "venue" : "In 11 the International Conference on Information and Knowledge Management (CIKM),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2002
    }, {
      "title" : "CONNELL. Improving stemming for Arabic information retrieval: light stemming and co-occurrence analysis",
      "author" : [ "L.S. L ARKEY", "L. BALLESTEROS et M.E" ],
      "venue" : "In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2002
    }, {
      "title" : "Seize ans de recherches en apprentissage des langues assisté par ordinateur",
      "author" : [ "F. Paru comme: Mangenot" ],
      "venue" : "In Plurilinguisme et apprentissages,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2005
    }, {
      "title" : "Acoustic Study of the Gemination Effect in Standard Arabic Speech",
      "author" : [ "Aymen Trigui", "Mohsen Maraoui", "Mounir Zrigui" ],
      "venue" : "IPCV",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2010
    }, {
      "title" : "The Gemination Effect on Consonant and Vowel Duration in Standard Arabic Speech",
      "author" : [ "Aymen Trigui", "Mohsen Maraoui", "Mounir Zrigui" ],
      "venue" : "SNPD",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2010
    }, {
      "title" : "Spoken language processing a guide to theory, algorithm and system design\",Prentice",
      "author" : [ "X.Huang", "A. Acero", "H. Hon" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2001
    }, {
      "title" : "An Automatic Speech Verification System ",
      "author" : [ "M. El-Kasasy" ],
      "venue" : "Faculty of Engineering Department of Electronics and Communications Egypt,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1992
    }, {
      "title" : "Statistical Part Of Speech Tagger for Arabic Language",
      "author" : [ "Mourad Mars", "Georges Antoniadis", "Mounir Zrigui" ],
      "venue" : "IC-AI",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2010
    }, {
      "title" : "Automatic Understanding of Spontaneous Arabic Speech - A Numerical Model. TAL",
      "author" : [ "Anis Zouaghi", "Mounir Zrigui", "Georges Antoniadis" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2008
    }, {
      "title" : "Zrigui: CALL System for Arabic Based on Natural Language Processing Tools",
      "author" : [ "Mohsen Maraoui", "Georges Antoniadis", "Mounir" ],
      "venue" : "IICAI",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2009
    }, {
      "title" : "SALA: Call System for Arabic Based on NLP Tools",
      "author" : [ "Mohsen Maraoui", "Georges Antoniadis", "Mounir Zrigui" ],
      "venue" : "IC-AI",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2009
    }, {
      "title" : "Automatic Identification System of Arabic Dialects",
      "author" : [ "Mohamed Belgacem", "Mounir Zrigui" ],
      "venue" : "IPCV",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 10,
      "context" : "Today, teaching by computer is on an extremely favorable terrain [24].",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 0,
      "context" : "By its morphological and syntactic proprieties, Arabic language is considered difficult to control in the field of automatic language processing [5,6].",
      "startOffset" : 145,
      "endOffset" : 150
    }, {
      "referenceID" : 1,
      "context" : "By its morphological and syntactic proprieties, Arabic language is considered difficult to control in the field of automatic language processing [5,6].",
      "startOffset" : 145,
      "endOffset" : 150
    }, {
      "referenceID" : 2,
      "context" : "More recent work within the approach \"Computer tutor\" often stand in the behaviorist paradigm and hold a better hand account of developments in language teaching and have the other almost always an experimentation with learners, according to a paradigm psycholinguistics at most[7].",
      "startOffset" : 278,
      "endOffset" : 281
    }, {
      "referenceID" : 6,
      "context" : "− El-Kasasy [19] developed a system for learning the",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 7,
      "context" : "− Omar proposed in [20] a system for identifying",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 3,
      "context" : "However they have limitations and difficulties, which lie mainly in the choice of a good initial model for learning and modeling of phoneme duration [12,13].",
      "startOffset" : 149,
      "endOffset" : 156
    }, {
      "referenceID" : 4,
      "context" : "However they have limitations and difficulties, which lie mainly in the choice of a good initial model for learning and modeling of phoneme duration [12,13].",
      "startOffset" : 149,
      "endOffset" : 156
    }, {
      "referenceID" : 8,
      "context" : "At the end of this list, we added the standard phoneme /SIL/ ([14], [21], [22]) which corresponds to periods of blank space between units of words.",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 5,
      "context" : "It is recommended that learning with nearly 500 different voices to reach a recognition rate of 100% [16].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 9,
      "context" : "The computer-assisted learning has attracted considerable attention in recent years [23].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 11,
      "context" : "We find it interesting to make tests on all the phonemes of Arabic dialects [25], in more targeted at all levels even those that are considered advanced, and trying to incorporate more nationalities for learners.",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 6,
      "context" : "Our system has advantages over other work existing: it uses as a acoustic model of the Arabic speech based on hidden Markov model which gives results in the form of phonetic structures against by other works assume that the input signal is already phonetically labeled (as the case of El-Kasasy [19]).",
      "startOffset" : 295,
      "endOffset" : 299
    } ],
    "year" : 2012,
    "abstractText" : "This work consists of creating a system of the Computer Assisted Language Learning (CALL) based on a system of Automatic Speech Recognition (ASR) for the Arabic language using the tool CMU Sphinx3 [1], based on the approach of HMM. To this work, we have constructed a corpus of six hours of speech recordings with a number of nine speakers. we find in the robustness to noise a grounds for the choice of the HMM approach [2]. the results achieved are encouraging since our corpus is made by only nine speakers, but they are always reasons that open the door for other improvement works.",
    "creator" : "Writer"
  }
}