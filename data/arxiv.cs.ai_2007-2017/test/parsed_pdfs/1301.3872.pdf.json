{
  "name" : "1301.3872.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Causal Mechanism-based Model Constructions",
    "authors" : [ "Tsai-Ching Lu", "Tze Yun Leong" ],
    "emails" : [ "@sis.", "leongty@comp." ],
    "sections" : [ {
      "heading" : null,
      "text" : "We propose a framework for building graph ical causal model that is based on the con cept of causal mechanisms. Causal models are intuitive for human users and, more im portantly, support the prediction of the ef fect of manipulation. We describe an imple mentation of the proposed framework as an interactive model construction module, Ima GeNie, in SMILE (Structural Modeling, In ference, and Learning Engine) and in GeNie (SMILE's Windows user interface).\n1 INTRODUCTION\nGraphical probabilistic models, such as Bayesian net works and influence diagrams, have become popular modeling tools for supporting decision making under uncertainty. The normative character of the graphi cal decision models guarantees the correctness of the inference procedure. Consequently, the quality of the advice suggested by the models depends directly on the requisiteness of the models. A model is requisite if it contains everything that is essential for solving the problem and no new insights about the problem will emerge by elaborating on it (Philips 1982). To build a requisite model requires human intuition and cre ativity since the notion of requisiteness is subjective. Construction of graphical models, therefore, is labo rious and demanding in terms of domain expertise. While support for obtaining model parameters, such as prior and conditional probability distribution, has received much attention in behavioral decision theory literature (see von Winterfeldt and Edwards (1988) for a review) and in artificial intelligence (Druzdzel & van der Gaag 2000), relatively little work has been done on composing model structure. At the same time, there are strong indications that the quality of advice is more sensitive to the model structure than to the precision\nof its numerical parameters (Pradhan et al. 1996).\nThere are essentially four approaches to aid model building. The first approach focuses on providing more expressive building tools. The Noisy-OR model (Pearl 1988; Henrion 1989) and its generalizations (Dlez 1993; Srinivas 1993) simplify the representation and elici tation of independence interactions among multiple causes. Beckerman (1990) developed the similarity network and partition as tools for representing subset independence to facilitate the structure construction and probability elicitation. The second approach, usu ally referred to knowledge-based model construction (KBMC), emphasizes aiding model building by auto mated generation of decision models from a domain knowledge-base guided by the problem description and observed information (see a special issue at the journal IEEE Transactions on Systems, Man and Cybernetics on the topic of KBMC (Breese, Goldman, & Wellman 1994)). The third approach focuses on algorithms that can learn the model structure and parameters from a database of observations (Cooper & Herskovits 1991; Pearl & Verma 1991; Spirtes, Glymour, & Scheines 1993). Although model construction from data can reduce the knowledge engineering effort, the learning approach faces other problems such as small data sets, unmeasured variables, missing data, selection bias, and the flexibility of model granularity.\nWhile we acknowledge that in the future it may be possible to build powerful computer systems that will model human creativity, sense for relevance, and sim plicity, we believe that these tasks are and will long be performed better by humans. Our view is that model building, a task that relies on all these capacities, is best implemented as an interactive process. The fourth approach on aiding model construction that is most re lated to our work is to apply system engineering and knowledge engineering techniques for aiding the pro cess of building Bayesian networks. Laskey and Ma honey (1996; 1997) address the issues of modulariza tion, object-orientation, knowledge-base, and evalua-\n354 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\ntion in a spiral model of development cycle. Koller and Pfeffer (1997; 1999) developed Object-Oriented Bayesian Networks (OOBN) that use objects as orga nizational units to reduce the complexity of modeling and increase the speed of inference.\nOur approach on aiding model construction is based on the concept of causal mechanisms. Causal mecha nisms, which are local interactions among domain vari ables, are building blocks that determine the causal structure of a model. As they encode our understand ing of local interactions and are fairly model inde pendent, causal mechanisms can be easily reused in various models. When the algebraic form of the in teraction is known, causal mechanisms are captured by so called structural equations. When less informa tion is available about the interaction, it can be spec ified in a probabilistic format. As shown by Druzdzel and Simon (1993), conditional probability tables in Bayesian networks that model causal relations among their variables can be also viewed as descriptions of causal mechanisms. Similarly to object-hierarchy ab straction, causal mechanism can be organized hierar chically in nearly decomposable system (Iwasaki & Si mon 1994). At the same time they provide a valu able heuristic for acquiring and managing knowledge: causality.\nIn our framework, we encode causal mechanisms as functional relations among variables and, wherever causal mechanisms are asymmetric, the direction of causal influence among variables. We extend Simon's causal ordering algorithm (Simon 1953) to develop a modeling process that uses the output graph of this algorithm in the interaction with users. We assist the model building process by helping user (1) to identify a set of mechanisms related to the current model and to bring them into model workspace (2) to integrate the newly added mechanisms with the model under construction (3) to specify the variables that can be manipulated, and (4) to extract reusable causal mech anisms from existing models into the knowledge base. The final model structures generated by our modeling process are guaranteed to be causal if the underlying structural equations reflect causal mechanisms of the modeled problem.\nIn addition to being intuitive for human users and facil itating crucial user interface functions such as explana tion, causal models support prediction of the effect of manipulation, i.e., changes in structure (Simon 1953; Spirtes, Glymour, & Scheines 1993; Pearl 1995). The users of such models (and that includes autonomous robots) can ask questions like \"What will happen if I perform action A?\" Manipulation is especially im portant in strategic planning, where it is important to derive creative decision options and not only evaluate\nexisting decision options. In the process of creating a model, a user may want to explore the possibility of manipulating its different elements. Supporting this manipulation is not straightforward, as some mecha nisms may be reversible, i.e., acting in reverse direc tion. For example, when driving up the hill, car engine causes the wheels to turn; but when driving down the hill in a low gear, the model should be able to predict that the wheels will cause the engine to slow down. Our approach supports causal modeling that includes reversible causal mechanisms and offers an integrated framework for building and using causal models.\nThe remainder of this paper is structured as follows. Section 2 gives an overview of structural equation mod els, causal mechanisms, and how these support changes in structure. Section 3 discusses the process of inter active model construction, including issues related to the representation of causal mechanism, assistant in terface, and the extension of causal ordering algorithm. Section 4 presents an example of user interaction with our system, ImaGeN/e. Finally, we discuss the impli cations of our approach and outline the direction for our future work.\n2 STRUCTURAL EQUATION\nMODELS\nWhen scientists study phenomena or problems, they normally focus on systems, pieces of the real world that can reasonably be studied in isolation. Scien tists identify the relevant variables, the ranges of the variables' values, and the relations among variables to form abstractions of these systems, known as mod els. One way of representing models is by systems of structural equations where each structural equa tion describes a conceptually distinct causal mecha nism active in the system. Such systems are known as Structural Equation Models (SEMs) (Haavelmo 1943; Simon 1953). A structural equation describing a causal mechanism M is often encoded as an implicit function\nwhere f is some algebraic function and its arguments V; are variables that directly participate in the mech anism M.\nA variable in a SEM is exogenous if it summarizes an outside influence on the system, i.e., its value is determined outside of the model. An exogenous vari able is truly exogenous if it represents a variable in the real world system that we cannot manipulate without changing the boundaries of the system. An exogenous variable is a policy variable if it represents a variable that we can manipulate, i.e., set its value. For exam ple, we normally model outside temperature as a truly\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 355\nexogenous variable in an agricultural model, but we can model the temperature as a policy variable in a model of a greenhouse. For each exogenous variable, there is a value assignment structural equation to des ignate the observed value (or a probability distribution over observed values) for the truly exogenous variable or the chosen value for the policy variable. A variable in a SEM is endogenous if its value is derived by substi tuting the values of exogenous variables into the core structural equations that depict the relations among modeled variables in the system and by solving these equations in SEM .\nA SEM S with m causal mechanisms and n variables is represented as\nm S = U fM,(Vl, V2, V3, ... , Vn).\ni=l\nSince the knowledge of which variables participate in which mechanisms is sufficient to determine the di rection of causation, 1 in the remainder of this paper we will only use structure matrix (Druzdzel & Simon 1993), a qualitative representation of a SEM.\nDefinition 1 (structure matrix) A structure ma trix A of a SEM S = U:1 fM,(Vl, V2, V3, . .. , Vn) = 0 is a m x n matrix with element a;j = x if Vj participates in f M;, where x is a marker, and a;j = 0 otherwise.\nLet Amxn be the structure matrix of a SEM S with m equations and n variables. S is non-over-constrained if following property holds.\nDefinition 2 (non-over-constrained system) A system of m structural equations S is non-over constrained if in any subset of k ::; m equations of S at least k different variables appear with nonzero co efficients.\nA non-over-constrained Amxn is self-contained if m = n. A non-over-constrained Amxn is under-constrained if m < n. Amxn is over-constrained if it violates non over-constrained property.\nExample: The University Performance Budget Planning Model (UPBPM) (Simon, Kalagnanam, & Druzdzel 2000) is comprised of 38 core equations that describe interactions among 88 variables in the university strategic budget plan ning context. The model has been adopted by the Office for Planning and Budget at Carnegie Mellon University for the purpose of strategic planning of university operations.\nThe following simple model, StudentFacultyRatio model, extracted from UPBPM, consists of one core equations and two value assignment equations and describes the interac tion among three variables: StudentFacultyRatio (SF R), NumberOJStudents (NS), and NumberOfFaculty (NF).\n1 Only when calculating the strength of the influences, we need the exact form of equations.\nThe corresponding structure matrix for this self-contained model is shown at the right hand side.\n{ \" NS = 22102 NS NF SFR /2: NF = 3006 h X 0 0 h: SFR = NSjNF h 0 X 0\nh X X X\n0\n2.1 Causal Ordering\nAs shown by Simon (1953), a self-contained SEM ex hibits asymmetries that can be represented by a di rected acyclic graph and interpreted causally. Simon developed a causal ordering algorithm that takes a self contained structure matrix A as input and outputs a causal graph G = {N(G), A( G)}, where the nodes, N(G), are sets of variables and the arcs, A (G), describe causal relations among them.\nLet B be a subset of equations in a non-over constrained SEM and Cpxq be the structure matrix of B. We say that B is a self-contained subset if p = q; B is a under-constrained subset if p < q. A self-contained subset is minimal if it does not contain any self-contained (proper) subsets itself. A minimal self-contained subset is a strongly coupled component if it contains more than one equation, which usually represents a feedback system in the real world.\nThe causal ordering algorithm starts with identifying the minimal self-contained subsets in input A. These identified minimal self-contained subsets are called complete subsets of 0-th order and a node is created for each subset. Next, the algorithm removes the equa tions of the complete subsets of 0-th order from A as solving the values of variables. Then it removes all variables that occur in the complete subsets of 0-th or der from the remaining equations in A as substituting the values of solved variables into remaining equations. The remaining set of equations is called the derived system of first order, a self-contained structure. The algorithm repeats the process of identifying, solving, and substituting on the derived system of k-th order until it is empty. In addition, whenever a node m is created for a minimal self-contained subset M, the al gorithm refers the set of equations EM of M back to the original set of equations OEM in A and adds arcs from the nodes representing variables in OV M \\ V M to m, where V M is the set of variables participating in EM and OV M is the set of variables participating in OEM·\nExample: The UPBPM (Simon, Kalagnanam, & Druzdzel 2000) implements Simon (1953) causal ordering algorithm that given an assignment of values to 50 exoge nous variables, derives the structure of the model.\nWhen applying the causal ordering algorithm to the struc\nture matrix of StudentFacultyRatio model, we first identify\n356 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nh and h as the complete subset of 0-th order. After solving and substituting of NS and NF, we then identify\nf� as the complete subset of 1-st order. The structure ma trix and the corresponding causal graph are shown below.\nNS NF X 0 0 X\nX X\nSFR 0 0 X\nGiven the causal graph, we can read off the causal rela\ntions among the nodes by focusing on the node of interest\nand its parents. For example, SF R directly depends on NF and NS. D\nNotice that the causality that we read off causal graphs is defined within models and causal asymmetries arise when mechanisms are placed in context. If the context has changed, it may result in changes in structure.\n2.2 Changes in Structure\nThe main value of structural equation models is that they support prediction of the effects of changes in structure, i.e., external manipulations that intervene in the mechanisms captured by the original system of equations. Such changes are modeled by modifying the equations that describe the affected mechanisms and leaving those equations that correspond to unaf fected mechanisms unmodified. The causal ordering algorithm applied to the modified SEMs derives the new causal structure of the system.\nNormally, the effect of external manipulation is lo cal and, when related back to the graph, amounts to arc cutting (Pearl 1995; Spirtes, Glymour, & Scheines 1993). The assumption underlying the arc-cutting op eration is that imposing a value on a variable by an external intervention makes that variable independent of its direct causes. This assumption is valid for mech anisms with strong asymmetric relationship between a variable and its causes; for example, wearing sun glasses protects our eyes from the sun but it does not make the sun go away. However, when a model contains reversible causal mechanisms (Simon 1953; Druzdzel & van Leijen 2000), manipulation can have a drastic effect on the graph.\nExample: From the causal graph of StudentFacultyRa tio model in previous example, we k now that changing NS will affect SFR but not NF. Now, consider that the budget planning officer would lik e to set the StudentFacultyRa tio to advertise their faculty availability. If needed, she is willing to adjust the NumberOfFaculty (e. g. , hire more faculty) . According to the revised modeling context, she needs to designate the variable SF R as exogenous, e. g. , j4 : SF R = 10, and release h : N F = 3, 006. The result ing structure matrix and corresponding causal graph are:\nNS X X 0 NF 0 X 0 SFR 0 X X\n()liL-D NF\n~ In the revised system, the causal ordering shows that N F\nhas become an endogenous variable affected by N S and SFR. Now, changing the number of students will affect the number of faculty. Manipulation has lead to a change in structure. D\nWe have developed an interactive and iterative model construction environment, ImaGeNie, that assists users in building graphical decision model in causal form. We use the causal ordering algorithm to gen erate the causal model structures which can later be associated with different node types and parameters and transformed into Bayesian networks or influence diagrams. Figure 1 shows the architecture of ImaGe N/e. It includes three knowledge structures: mech anism knowledge bases, which hold domain knowl edge expressed as causal mechanisms, model build ing workspace, which serve as a blackboard for model composition, and models. The domain knowledge can be maintained either by the equation authoring interface, where model builders can compose struc tural equations directly, or by the mechanism ex traction operation that enables model builders to ex tract reusable causal mechanisms from existing mod els. Model builders can use hierarchy navigation in terface to locate the mechanisms of interest and select\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 357\nthem into the model building workspace with assis tance of the mechanism selection operation. In ad dition to mechanism selection and traditional model authoring operations, model builders can manipulate variables and merge mechanisms as model building process evolves. The underlying causal ordering mod ule will restructure the models according to the user actions.\n3.1 Knowledge Representation\nIn ImaGeNie, the fundamental knowledge representa tion units are causal mechanisms, which are encoded as structural equations. For example, we can specify the student faculty ratio as h (S F R, NS, N F). Users may optionally provide explicit functions for causal mech anisms such as algebraic functions, conditional prob ability tables, truth tables, value/utility tables, and choice tables.\nWhile most mechanisms will be described in one, per haps their only, mode of operation, some mechanisms are reversible in the sense of being flexible as to the direction of causality that they imply when they are embedded in different contexts. We define the manip ulativeness and observability for each variable in our domain knowledge base to express the characteristics of the variable that may aid in the process of model building. Along with the manipulativeness character istic, a variable can be truly exogenous, manipulatable, or truly endogenous. For the sun and sunglasses exam ple, we may use two structural equations !5(S, G) and f6(S) to describe causal relation between S and G and assign S as a truly exogenous variable to express the fact that it is impossible to manipulate the sun in the current modeling domain. We may assign G as manip ulatable to designate it as a potential policy variable. A variable is truly endogenous if its value has to be de rived from embedded mechanisms. The observability is important in deciding whether adding this variable (observable or unobservable) will be of benefit to the model. In the diagnostic domain, it may be desired to develop the cost model that can associate manipulation cost/ observation cost with manipulatable/ observable variables.\nOur domain knowledge base is organized as a hierar chical system that consists of subsystems and causal mechanisms as its fundamental building elements. The hierarchical approach not only helps domain experts to express their domain knowledge in cognitively mean ingful units but also helps knowledge engineers to access stored mechanisms easily. Our approach is similar to type-hierarchy in (Koller & Pfeffer 1997; Laskey & Mahoney 1997) but without imposing the inheritance constraint since knowledge can be pos sibly organized hierarchically from different perspec-\ntives. More details on the syntax of our knowledge representation language can be found in (Lu 1999).\n3.2 Extending Causal Ordering to Under-constrained Model\nIn ImaGeNie, the model construction process is a re flection of our problem solving. The under-constrained models evolved in such process reveal different problem recognition stages. In an under-constrained model, the mechanisms are our observations of how the problem should be described so far. Model building process is strongly related to causal manipulation. The exoge nous variables are those outside influences that have been committed. An under-constrained model can not be drawn as a directed acyclic graph, as the di rection of causal interactions is not completely deter mined until the model is self-contained. However, it is desired to have a graphical representation of under constrained models during the whole process of model construction, since the graphical representation may help model builder identify her focus and change her commitments of the outside influences. We extend Si mon's causal ordering algorithm to explicate the causal ordering that has been identified in under-constrained models. We also propose a graphical representation to depict the causal ordering results in an informative graphical form that aims to help user in model build ing.\nIn order to formalize our extensions, we need to re state the theorem that was originally proved by Simon (1953).\nTheorem 1 Let A and B be two minimal self contained subsets of equations of a non-over constrained SEM, S. Then the structural equations of A and B, and likewise the variables in A and B are disjunct.\nConsider any subset B of the equations of a non-over constrained SEM. We will denote the number of equa tions in Bas ne8, and the number of variables appear ing in B as nvB.\nTheorem 2 Let S be a non-over-constrained system and D be the derived system of structural equations from S by applying identification, solving, and sub stitution. If D is not empty, then D is non-over constrained.\nProof: In the process of identification, let M be the union of all the minimal self-contained subsets, M = M 1 U M2 U ... U Mk, and the remainder R. We k now R is not empty since V is not empty.\nSuppose that V violates the non-over-constrained property. Then there exists a subset £' of V such that net:' > nvt:'·\n358 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nLet & be the subset of R that &' derives from. We know that ne£ = ne£1· Now, consider the subset :F = M U &. The equations of M and & are disjunct because M and R are disjunct and & � R. Therefore, ne;: = neM + ne£ = neM + ne£1. Since &' derives from & by substitution, the variables appearing in & are either in M or in &'. Con sequently, the variables in :F are either in M or in &'. Moreover, the variables in M and &' are disjunct because &' derives from & by substituting out the variables in M. Therefore, nv;: = nvM + nV£1. Since the equations of Mi, and likewise the variables in Mi, are disjunct by Theo rem 1, we have nVM = L;nvM, and neM = L;neM;· Hence nVM = neM. Therefore, ne;: = neM + ne£ = neM + ne£1 > neM + nV£1 = nvM + nV£1 = nv;:, i.e., the number of equations of :F is greater than the number of variables of :F. In other words, the set :F violates Defini tion 2 contradicting the fact that S is non-over-constrained. We conclude that V must be non-over-constrained. D\nGiven Theorem 2, we can keep applying identifica tion, solving, and substitution operations on derived non-over-constrained system until either V is empty or there are no more minimal self-contained subsets that can be identified. If V is empty, we know that S is self-contained. If V is not empty and no more self contained subsets can be identified, we know that S is under-constrained and we call V the derived strictly under-constrained subsets.\nDefinition 3 (strictly under-constrained sub sets) The strictly under-constrained subsets of a non over-constrained SEM are those under-constrained subsets that do not contain any self-contained subsets.\nTheorem 3 A SEM, S, is under-constrained if and only if there exists a derived strictly under-constrained subset inS.\nProof (sketch): We can prove => by construction and ¢:: by contradiction given Theorem 2. See (Lu 1999) for the formal proof. D\nFigure 2 outlines our extended causal ordering algo rithm that is based on Theorem 3. The input of the algorithm is a non-over-constrained structure matrix A. The output is a graph G = {V, A( G)}, where the nodes V are variables and A(G) is a set of directed, hi-directed, or undirected arcs. The algorithm essen tially follows the steps of identification, solving, and substitution as Simon's causal ordering algorithm un til there are no more self-contained subsets that can be identified from the derived system. The algorithm will explicitly depict the causal relations and relevant rela tions encoded in the strictly under-constrained subset, if there remains one.\nThe graph generated by our extended causal ordering algorithm is specifically designed to aid the process of\nmodel construction. Unlike the original causal order ing algorithm, each variable in the system is repre sented as a separate node so that the model builder can access and manipulate it directly. Directed arcs depict the causal relations among variables. In addi tion to these, our algorithm explicates the causal re lations encoded in the under-constrained system. Bi directed arcs denote feedback mechanisms in strongly coupled subsets. User can visualize the effect of break ing the feedback system by manipulating one of vari ables connected by the hi-directed arc. Undirected arcs visually express relevant but undetermined causal rela tions among variables so that model builder can focus on clarifying the mechanisms governing these variables and complete the model.\nExample: Suppose the budget planning officer wants to\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 359\nextend the StudentFacultyRatio model to take the average class size into account. She adds the structural equations h : CS = (NS * CL)/(NF * TL) and Is : CL = 15 to describe the relations among ClassSize ( CS), ClassLoad ( CL), TeachingLoad ( TL), NS and NF. The structure ma trix of the extended model is as follows.\nNS NF SFR cs CL TL /1 X 0 0 0 0 0 h 0 X 0 0 0 0 h X X X 0 0 0 h X X 0 X X X Is 0 0 0 0 X 0\nAfter applying the extended causal ordering algorithm to the system, she obtains the following under-constrained causal graph.\nCL\nTL\nFrom the under-constrained causal graph, she can read off the current stage of problem formulation as follows: StudentFacultyRatio is determined by NumberOIStudents and NumberOfFaculty; currently both ClassSize and TeachingLoad depend on NumberOfStudents, Num berOfFaculty, and ClassLoad, but the relation between ClassSize and TeachingLoad is not yet determined, which is the consequence of the fact that the system is still under-constrained. D\n3.3 Modeling Process\nThe modeling process starts with an initial focus, which is normally, in the spirit of value-focused think ing (Keeney 1994), the value variable. Users can also start with other focus variables, for example decision, observation, and whatever else is relevant or impor tant a-priori. With the assistant interface, users can interactively browse the mechanisms related to their focus variables, select those that best depict the prob lem at hand, merge them, or specify exogenous vari ables to set the boundary of the system. However, we suggest the users to focus on one variable and add rel evant mechanisms one at a time as the model evolves, since it resembles the action of focusing on a variable of interest, explaining or observing it in terms of its underlying mechanism. The user repeats the process iteratively until the model is requisite. In other words, users make decisions on the level of granularity and when to stop with the model building process. The system only plays the passive role of an assistant: sug gesting mechanisms to choose from, indicating the pos sible mechanisms to merge, and denoting the manipu latable variables.\nNormally a model evolves from an under-constrained system to a self-contained system. Designating rna-\nnipulatable variables as exogenous helps in obtaining a self-contained system, i.e., orienting all arcs in the model graph. If the user assigns a potential policy variable, a manipulatable variable that is endogenous in a self-contained system, as exogenous, the whole model becomes over-constrained, because the num ber of equations is greater than the number of vari ables. We allow a model to be under-constrained or self-contained at any stage of the model development in ImaGeNie, but we disallow a model to be over constrained. When a model becomes over-constrained, the system pops up a list of mechanisms that are currently in the model and asks users to release one of them in order to change the system into a self contained or an under-constrained system.\n4 EXAMPLE MODEL BUILDING\nSESSION\nWe continue on extending our simple model to demon strate how to interact with ImaGeNie to build a sim plified university budget model from U P B PM knowl edge base encoded in ImaGeN/e. Suppose the officer has designated T L variable as exogenous with equa tion fg : T L = 6. Figure 3 shows ImaGeNie interface with the navigation tree of the knowledge base and the model we have built so far in the workspace.\nSuppose she would like to plan the expenses related to faculty salary. She may use the navigation tree to lo cate mechanisms for faculty salary. Suppose she identi fies the mechanism f10: FS =(OJ +TA*NS)j(NF* ( 1 + 0)) that describes the interactions among vari ables: FacultySalary (FS), Otherlncome (OJ), Tu itionAmount (TA), Overhead (0), NS and N F . She drags it into the workspace. In order to maintain the unique variable identifiers in the model, ImaGeNie au tomatically renames the N S and N F into N SO and\n360 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nN FO. The extended causal ordering algorithm gener ates the graph shown in Figure 4.\nIJGeNiel 1!!11!1£1\nFigure 4: Model builder selects and drags !Io into workspace; the extended causal ordering algorithm generates a corresponding graph.\nShe can then integrate the added mechanism with the model by merging N S to N SO and N F to N FO. ( See Figure 5).\niii! GeNiel IIIII!JE'l\nFigure 5: Model builder performs the merge opera tions for N S (top). The causal ordering generates the corresponding graph (bottom).\nShe then makes T A , 0, and OJ exogenous by assigning equations: fn : T A = 1, 200, !I2 : 0 = 0.48, and JI3 : OJ= 30,000,000 and obtains a complete model\nthat describes the dependence relations among those variables of interests ( See Figure 6 top). She can now read off the following dependency relations from the complete model:\nNow, she can read off the local effect of her change on the system from the causal graph: teaching load is\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 361\ndetermined by the number of students, the number of faculty, class load, and class size.\nImaGeNie also supports model builder in extract ing reusable mechanisms from the workspace into the knowledge base. Model builder simply selects the nodes of interest and drags them into the destination branch in the navigation tree. Due to space limita tions, we are omitting this example.\n5 DISCUSSION A N D FUTURE\nWORK\nSupport for building model structure is one of the best ways of improving the quality of advice based on decision-theoretic models. While existing approaches focus on automatic model construction either from knowledge base or directly from data, our approach favors a closely-coupled loop between the system and its user. This is based on our belief that human judge ment with respect to relevance, model size, complete ness, and granularity is more reliable. Built on the assumption that under-constrained models reflect our problem recognition stages, ImaGeNie assists users in encoding their conceptual problem framing in a causal graph generated by the extended causal ordering al gorithm. Furthermore, ImaGeNie provides users with the flexibility to choose building blocks from knowl edge base to extend the model, to manipulate the variables in order to observe the effect of intervention (structure changes), and to extract reusable mecha nisms from existing models to knowledge bases. The concept of causal mechanisms, on which ImaGeNie re lies, provides a general mean to accommodate different forms of knowledge description and makes knowledge acquisition task easier.\nRecent research in applying the object-oriented frame work to extend Bayesian networks for modeling com plex domains (Koller & Pfeffer 1997; Laskey & Ma honey 1997; Pfeffer et al. 1999) is closely related to our work. Each of these approaches organizes do main knowledge into a hierarchical system. In Object Oriented Bayesian Network ( O O B N), the domain knowledge is structured explicitly as class-hierarchy for the type system and as object-hierarchy for the real model. In our framework, we do not impose any constraint on how users should organize their domain knowledge in the knowledge base. In the future, we would like to explore the semantics for combining type system with causal mechanisms so that our knowledge base can efficiently store the domain knowledge and be effectively used by users. As for the constructed mod els, ImaGeNie provides submodels to group nodes into a graphical organization unit for the sake of succinct presentation, but there is no special semantic meaning\nattached to submodels in terms of inference. We plan to impose d-sepset (Xiang, Poole, & Beddoes 1993) constraint on submodels composition such that each submodel has well defined 1/0 sets to resemble object hierarchy in O OB N.\nOnce the model structures generated from our frame work are associated with variable ranges and their nu merical parameters such as explicit equations or con ditional probability tables ( CP Ts), manipulation on the model may invalidate these numerical parameters. Druzdzel and van Leijen (2000) have shown the special conditions under which the CP Ts in Bayesian networks can be reversed under manipulation. As for the ex plicit equations, ImaGeNie tries to solve the manipu lated system symbolically if there exists a solution. We would like to further explore conditions under which we can derive the numerical parameters from the mix ture models after manipulation.\nImaGeNie provides a flexible interactive model build ing environment for users to build models in causal form with as much system assistance as possible but without giving up their control over the model build ing process. We believe our efforts in incorporating causality as a heuristic in aiding model building and knowledge acquisition is an important extension to the existing approaches.\nAcknowledgments\nThis research was supported by the Air Force Office of Sci\nentific Research, grants F49620-97-1-0225 and F49620-\n00-1-0112, by the National Science Foundation under\nFaculty Early Career Development (CAREER) Program,\ngrant IRI-9624629 , and by a strategic research grant num\nber RP960351 from the National Science and Technology\nBoard and the Ministry of Education in Singapore. We\nthank anonymous reviewers for suggestions improving the\nclarity of the paper. SMILE and GeNie are available at http://www2.sis.pitt.edu/�genie.\nReferences\nBreese, J. S.; Goldman, R. P.; and Wellman, M. P. 1994. Introduction to the special section on knowledge-based construction of probabilistic and de cision models. IEEE Transactions on Systems, Man and Cybernetics 24(11):1577-1579.\nCooper, G. F., and Herskovits, E. 1991. A Bayesian method for constructing Bayesian belief networks from databases. In Proceedings of the Seventh Annual Conference on Uncertainty in Artificial Intelligence (UAI-91}, 86-94. San Mateo, California: Morgan Kaufmann Publishers.\nDfez, F. J. 1993. Parameter adjustment in Bayes net-\n362 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nworks. The generalized noisy OR-gate. In Proceedings of the Ninth Annual Conference on Uncertainty in Artificial Intelligence (UAI-93), 99-105. San Fran cisco, CA: Morgan Kaufmann Publishers.\nDruzdzel, M. J., and Simon, H. A. 1993. Causality in Bayesian belief networks. In Proceedings of the Ninth Annual Conference on Uncertainty in Artificial Intel ligence (UAI-93), 3-11. San Francisco, CA: Morgan Kaufmann Publishers.\nDruzdzel, M. J., and van der Gaag, L. C. 2000. Intro duction to the special issue on building probabilistic networks: Where do the numbers come from? Jour nal of IEEE Transactions on Know ledge and Data Engineering. To appear.\nDruzdzel, M. J., and van Leijen, H. 2000. Causal reversibility in Bayesian networks. Journal of Ex perimental and Theoretical Artificial Intelligence. To appear.\nHaavelmo, T. 1943. The statistical implications of a system of simultaneous equations. Econometrica 11(1): 1-12.\nHeckerman, D. 1990. Probabilistic similarity net works. Networks 20(5):607-636.\nHenrion, M. 1989. Some practical issues in construct ing belief networks. In Uncertainty in Artificial Intel ligence 3, 161-173. New York, N. Y.: Elsevier Science Publishing Company, Inc.\nIwasaki, Y., and Simon, H. A. 1994. Causality and model abstraction. Artificial Intelligence 67(1): 143- 194.\nKeeney, R. L. 1994. Value-focused Thinking: a Path to Creative Decision Making. Cambridge, MA: Har vard University Press.\nKoller, D., and Pfeffer, A. 1997. Object-oriented Bayesian networks. In Proceedings of the Thirteenth Annual Conference on Uncertainty in Artificial In telligence (UAI-97), 302-313. San Francisco, CA: Morgan Kaufmann Publishers.\nLaskey, K. B., and Mahoney, S. M. 1997. Network fragments: Representing knowledge for constructing probabilistic models. In Proceedings of the Thirteenth Annual Conference on Uncertainty in Artificial Intel ligence (UAI-97), 334-341. San Francisco, CA: Mor gan Kaufmann Publishers.\nLu, T. C. 1999. ImaGeNie - interactive model au thoring in GeNie. Master's thesis, University of Pitts burgh, Pittsburgh, PA 15260.\nMahoney, S.M., and Laskey, K. B. 1996. Network en gineering for complex belief networks. In Proceedings of the Twelfth Annual Conference on Uncertainty in Artificial Intelligence (UAI-96), 389-396. San Fran cisco, CA: Morgan Kaufmann Publishers.\nPearl, J., and Verma, T. S. 1991. A theory of in ferred causation. In Allen, J.; Fikes, R.; and Sande wall, E., eds., KR-91, Principles of Knowledge Rep resentation and Reasoning: Proceedings of the Second International Conference, 441-452. Cambridge, MA: Morgan Kaufmann Publishers, Inc., San Mateo, CA.\nPearl, J. 1988. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. San Ma teo, CA: Morgan Kaufmann Publishers, Inc.\nPearl, J. 1995. Causal diagrams for empirical re search. Biometrika 82(4):669-710.\nPfeffer, A.; Koller, D.; Milch, B.; and Takusagawa, K. T. 1999. SPOOK: A system for probabilistic object-oriented knowledge representation. In Proceed ings of the Fifteenth Annual Conference on Uncer tainty in Artificial Intelligence (UAI-99 ), 541-550. San Francisco, CA: Morgan Kaufmann Publishers.\nPhilips, L. D. 1982. Requisite decision modeling: A case study. Journal of Operational Research Society 3:303-311.\nPradhan, M.; Henrion, M.; Provan, G.; Del Favero, B.; and Huang, K. 1996. The sensitivity of belief networks to imprecise probabilities: An experimental investigation. Artificial Intelligence 85 ( 1-2) :363-397.\nSimon, H. A.; Kalagnanam, J. R.; and Druzdzel, M. J. 2000. Performance budget planning: The case of a research university. In preparation.\nSimon, H. A. 1953. Causal ordering and identifia bility. In Hood, W. C., and Koopmans, T. C., eds., Studies in Econometric Method. Cowles Commission for Research in Economics. Monograph No. 14. New York, NY: John Wiley & Sons, Inc. chapter III, 49- 74.\nSpirtes, P.; Glymour, C.; and Scheines, R. 1993. Cau sation, Prediction, and Search. New York: Springer Verlag.\nSrinivas, S. 1993. A generalization of the noisy-OR model. In Proceedings of the Ninth Annual Confer ence on Uncertainty in Artificial Intelligence (UAI93), 208-215. San Francisco, CA: Morgan Kaufmann Publishers.\nvon Winterfeldt, D., and Edwards, W. 1988. Deci sion Analysis and Behavioral Research. Cambridge: Cambridge University Press.\nXiang, Y.; Poole, D.; and Beddoes, M. P. 1993. Multi ply sectioned Bayesian networks and junction forests for large knowledge based systems. Computational Intelligence 9(2):171-220."
    } ],
    "references" : [ {
      "title" : "Introduction to the special section on knowledge-based construction of probabilistic and de­ cision models",
      "author" : [ "J.S. Breese", "R.P. Goldman", "M.P. Wellman" ],
      "venue" : "IEEE Transactions on Systems, Man",
      "citeRegEx" : "Breese et al\\.,? 1994",
      "shortCiteRegEx" : "Breese et al\\.",
      "year" : 1994
    }, {
      "title" : "A Bayesian method for constructing Bayesian belief networks from databases",
      "author" : [ "G.F. Cooper", "E. Herskovits" ],
      "venue" : "Proceedings of the Seventh Annual",
      "citeRegEx" : "Cooper and Herskovits,? 1991",
      "shortCiteRegEx" : "Cooper and Herskovits",
      "year" : 1991
    }, {
      "title" : "Parameter adjustment in Bayes",
      "author" : [ "F.J. Dfez" ],
      "venue" : null,
      "citeRegEx" : "Dfez,? \\Q1993\\E",
      "shortCiteRegEx" : "Dfez",
      "year" : 1993
    }, {
      "title" : "Causality in Bayesian belief networks",
      "author" : [ "M.J. Druzdzel", "H.A. Simon" ],
      "venue" : "Proceedings of the Ninth Annual Conference on Uncertainty in Artificial Intel­ ligence (UAI-93), 3-11. San Francisco, CA: Morgan Kaufmann Publishers.",
      "citeRegEx" : "Druzdzel and Simon,? 1993",
      "shortCiteRegEx" : "Druzdzel and Simon",
      "year" : 1993
    }, {
      "title" : "Intro­ duction to the special issue on building probabilistic networks: Where do the numbers come from",
      "author" : [ "M.J. Druzdzel", "L.C. van der Gaag" ],
      "venue" : "Jour­ nal of IEEE Transactions on Know",
      "citeRegEx" : "Druzdzel and Gaag,? \\Q2000\\E",
      "shortCiteRegEx" : "Druzdzel and Gaag",
      "year" : 2000
    }, {
      "title" : "Causal reversibility in Bayesian networks",
      "author" : [ "M.J. Druzdzel", "H. van Leijen" ],
      "venue" : "Journal of Ex­ perimental and Theoretical Artificial Intelligence. To appear",
      "citeRegEx" : "Druzdzel and Leijen,? \\Q2000\\E",
      "shortCiteRegEx" : "Druzdzel and Leijen",
      "year" : 2000
    }, {
      "title" : "The statistical implications of a system of simultaneous equations",
      "author" : [ "T. Haavelmo" ],
      "venue" : "Econometrica 11(1): 1-12.",
      "citeRegEx" : "Haavelmo,? 1943",
      "shortCiteRegEx" : "Haavelmo",
      "year" : 1943
    }, {
      "title" : "Probabilistic similarity net­ works",
      "author" : [ "D. Heckerman" ],
      "venue" : "Networks 20(5):607-636.",
      "citeRegEx" : "Heckerman,? 1990",
      "shortCiteRegEx" : "Heckerman",
      "year" : 1990
    }, {
      "title" : "Some practical issues in construct­ ing belief networks",
      "author" : [ "M. Henrion" ],
      "venue" : "Uncertainty in Artificial Intel­ ligence 3, 161-173. New York, N. Y.: Elsevier Science Publishing Company, Inc.",
      "citeRegEx" : "Henrion,? 1989",
      "shortCiteRegEx" : "Henrion",
      "year" : 1989
    }, {
      "title" : "Causality and model abstraction",
      "author" : [ "Y. Iwasaki", "H.A. Simon" ],
      "venue" : "Artificial Intelligence 67(1): 143194.",
      "citeRegEx" : "Iwasaki and Simon,? 1994",
      "shortCiteRegEx" : "Iwasaki and Simon",
      "year" : 1994
    }, {
      "title" : "Value-focused Thinking: a Path to Creative Decision Making",
      "author" : [ "R.L. Keeney" ],
      "venue" : "Cambridge, MA: Har­ vard University Press.",
      "citeRegEx" : "Keeney,? 1994",
      "shortCiteRegEx" : "Keeney",
      "year" : 1994
    }, {
      "title" : "Object-oriented Bayesian networks",
      "author" : [ "D. Koller", "A. Pfeffer" ],
      "venue" : "Proceedings of the Thirteenth Annual Conference on Uncertainty in Artificial In­ telligence (UAI-97), 302-313. San Francisco, CA: Morgan Kaufmann Publishers.",
      "citeRegEx" : "Koller and Pfeffer,? 1997",
      "shortCiteRegEx" : "Koller and Pfeffer",
      "year" : 1997
    }, {
      "title" : "Network fragments: Representing knowledge for constructing probabilistic models",
      "author" : [ "K.B. Laskey", "S.M. Mahoney" ],
      "venue" : "Proceedings of the Thirteenth Annual Conference on Uncertainty in Artificial Intel­ ligence (UAI-97), 334-341. San Francisco, CA: Mor­",
      "citeRegEx" : "Laskey and Mahoney,? 1997",
      "shortCiteRegEx" : "Laskey and Mahoney",
      "year" : 1997
    }, {
      "title" : "ImaGeNie - interactive model au­ thoring in GeNie",
      "author" : [ "T.C. Lu" ],
      "venue" : "Master's thesis, University of Pitts­ burgh, Pittsburgh, PA 15260.",
      "citeRegEx" : "Lu,? 1999",
      "shortCiteRegEx" : "Lu",
      "year" : 1999
    }, {
      "title" : "Network en­ gineering for complex belief networks",
      "author" : [ "S.M. Mahoney", "K.B. Laskey" ],
      "venue" : "Proceedings of the Twelfth Annual Conference on Uncertainty in Artificial Intelligence (UAI-96), 389-396. San Fran­ cisco, CA: Morgan Kaufmann Publishers.",
      "citeRegEx" : "Mahoney and Laskey,? 1996",
      "shortCiteRegEx" : "Mahoney and Laskey",
      "year" : 1996
    }, {
      "title" : "A theory of in­ ferred causation",
      "author" : [ "J. Pearl", "T.S. Verma" ],
      "venue" : "Allen, J.; Fikes, R.; and Sande­ wall, E., eds., KR-91, Principles of Knowledge Rep­ resentation and Reasoning: Proceedings of the Second International Conference, 441-452. Cambridge, MA:",
      "citeRegEx" : "Pearl and Verma,? 1991",
      "shortCiteRegEx" : "Pearl and Verma",
      "year" : 1991
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "author" : [ "J. Pearl" ],
      "venue" : "San Ma­ teo, CA: Morgan Kaufmann Publishers, Inc.",
      "citeRegEx" : "Pearl,? 1988",
      "shortCiteRegEx" : "Pearl",
      "year" : 1988
    }, {
      "title" : "Causal diagrams for empirical re­ search",
      "author" : [ "J. Pearl" ],
      "venue" : "Biometrika 82(4):669-710.",
      "citeRegEx" : "Pearl,? 1995",
      "shortCiteRegEx" : "Pearl",
      "year" : 1995
    }, {
      "title" : "SPOOK: A system for probabilistic object-oriented knowledge representation",
      "author" : [ "A. Pfeffer", "D. Koller", "B. Milch", "K.T. Takusagawa" ],
      "venue" : "Proceed­ ings of the Fifteenth Annual Conference on Uncer­ tainty in Artificial Intelligence (UAI-99",
      "citeRegEx" : "Pfeffer et al\\.,? 1999",
      "shortCiteRegEx" : "Pfeffer et al\\.",
      "year" : 1999
    }, {
      "title" : "Requisite decision modeling: A case study",
      "author" : [ "L.D. Philips" ],
      "venue" : "Journal of Operational Research Society 3:303-311.",
      "citeRegEx" : "Philips,? 1982",
      "shortCiteRegEx" : "Philips",
      "year" : 1982
    }, {
      "title" : "The sensitivity of belief networks to imprecise probabilities: An experimental investigation",
      "author" : [ "M. Pradhan", "M. Henrion", "G. Provan", "B. Del Favero", "K. Huang" ],
      "venue" : "Artificial Intelligence 85 ( 1-2)",
      "citeRegEx" : "Pradhan et al\\.,? 1996",
      "shortCiteRegEx" : "Pradhan et al\\.",
      "year" : 1996
    }, {
      "title" : "Performance budget planning: The case of a research university",
      "author" : [ "H.A. Simon", "J.R. Kalagnanam", "M.J. Druzdzel" ],
      "venue" : "preparation.",
      "citeRegEx" : "Simon et al\\.,? 2000",
      "shortCiteRegEx" : "Simon et al\\.",
      "year" : 2000
    }, {
      "title" : "Causal ordering and identifia­ bility",
      "author" : [ "H.A. Simon" ],
      "venue" : "Hood, W. C., and Koopmans, T. C., eds., Studies in Econometric Method. Cowles Commission for Research in Economics. Monograph No. 14. New York, NY: John Wiley & Sons, Inc. chapter III, 49-",
      "citeRegEx" : "Simon,? 1953",
      "shortCiteRegEx" : "Simon",
      "year" : 1953
    }, {
      "title" : "Cau­ sation, Prediction, and Search",
      "author" : [ "P. Spirtes", "C. Glymour", "R. Scheines" ],
      "venue" : "New York: Springer Verlag.",
      "citeRegEx" : "Spirtes et al\\.,? 1993",
      "shortCiteRegEx" : "Spirtes et al\\.",
      "year" : 1993
    }, {
      "title" : "A generalization of the noisy-OR model",
      "author" : [ "S. Srinivas" ],
      "venue" : "Proceedings of the Ninth Annual Confer­ ence on Uncertainty in Artificial Intelligence (UAI93), 208-215. San Francisco, CA: Morgan Kaufmann Publishers.",
      "citeRegEx" : "Srinivas,? 1993",
      "shortCiteRegEx" : "Srinivas",
      "year" : 1993
    }, {
      "title" : "Deci­ sion Analysis and Behavioral Research",
      "author" : [ "D. von Winterfeldt", "W. Edwards" ],
      "venue" : null,
      "citeRegEx" : "Winterfeldt and Edwards,? \\Q1988\\E",
      "shortCiteRegEx" : "Winterfeldt and Edwards",
      "year" : 1988
    }, {
      "title" : "Multi­ ply sectioned Bayesian networks and junction forests for large knowledge based systems",
      "author" : [ "Y. Xiang", "D. Poole", "M.P. Beddoes" ],
      "venue" : "Computational Intelligence 9(2):171-220.",
      "citeRegEx" : "Xiang et al\\.,? 1993",
      "shortCiteRegEx" : "Xiang et al\\.",
      "year" : 1993
    } ],
    "referenceMentions" : [ {
      "referenceID" : 19,
      "context" : "it contains everything that is essential for solving the problem and no new insights about the problem will emerge by elaborating on it (Philips 1982).",
      "startOffset" : 136,
      "endOffset" : 150
    }, {
      "referenceID" : 25,
      "context" : "as prior and conditional probability distribution, has received much attention in behavioral decision theory literature (see von Winterfeldt and Edwards (1988) for a review) and in artificial intelligence (Druzdzel & van der Gaag 2000), relatively little work has been done on composing model structure.",
      "startOffset" : 129,
      "endOffset" : 160
    }, {
      "referenceID" : 20,
      "context" : "of its numerical parameters (Pradhan et al. 1996).",
      "startOffset" : 28,
      "endOffset" : 49
    }, {
      "referenceID" : 16,
      "context" : "The Noisy-OR model (Pearl 1988; Henrion 1989) and its generalizations (Dlez 1993; Srinivas 1993) simplify the representation and elici­ tation of independence interactions among multiple causes.",
      "startOffset" : 19,
      "endOffset" : 45
    }, {
      "referenceID" : 8,
      "context" : "The Noisy-OR model (Pearl 1988; Henrion 1989) and its generalizations (Dlez 1993; Srinivas 1993) simplify the representation and elici­ tation of independence interactions among multiple causes.",
      "startOffset" : 19,
      "endOffset" : 45
    }, {
      "referenceID" : 24,
      "context" : "The Noisy-OR model (Pearl 1988; Henrion 1989) and its generalizations (Dlez 1993; Srinivas 1993) simplify the representation and elici­ tation of independence interactions among multiple causes.",
      "startOffset" : 70,
      "endOffset" : 96
    }, {
      "referenceID" : 8,
      "context" : "The Noisy-OR model (Pearl 1988; Henrion 1989) and its generalizations (Dlez 1993; Srinivas 1993) simplify the representation and elici­ tation of independence interactions among multiple causes. Beckerman (1990) developed the similarity network and partition as tools for representing subset independence to facilitate the structure construction and probability elicitation.",
      "startOffset" : 32,
      "endOffset" : 212
    }, {
      "referenceID" : 3,
      "context" : "As shown by Druzdzel and Simon (1993), conditional probability tables in Bayesian networks that model causal relations among their variables can be also viewed as descriptions of causal mechanisms.",
      "startOffset" : 12,
      "endOffset" : 38
    }, {
      "referenceID" : 22,
      "context" : "We extend Simon's causal ordering algorithm (Simon 1953) to develop a modeling process that uses the output graph of this algorithm in the interaction with users.",
      "startOffset" : 44,
      "endOffset" : 56
    }, {
      "referenceID" : 22,
      "context" : ", changes in structure (Simon 1953; Spirtes, Glymour, & Scheines 1993; Pearl 1995).",
      "startOffset" : 23,
      "endOffset" : 82
    }, {
      "referenceID" : 17,
      "context" : ", changes in structure (Simon 1953; Spirtes, Glymour, & Scheines 1993; Pearl 1995).",
      "startOffset" : 23,
      "endOffset" : 82
    }, {
      "referenceID" : 6,
      "context" : "Such systems are known as Structural Equation Models (SEMs) (Haavelmo 1943; Simon 1953).",
      "startOffset" : 60,
      "endOffset" : 87
    }, {
      "referenceID" : 22,
      "context" : "Such systems are known as Structural Equation Models (SEMs) (Haavelmo 1943; Simon 1953).",
      "startOffset" : 60,
      "endOffset" : 87
    }, {
      "referenceID" : 22,
      "context" : "As shown by Simon (1953), a self-contained SEM ex­ hibits asymmetries that can be represented by a di­ rected acyclic graph and interpreted causally.",
      "startOffset" : 12,
      "endOffset" : 25
    }, {
      "referenceID" : 21,
      "context" : "Example: The UPBPM (Simon, Kalagnanam, & Druzdzel 2000) implements Simon (1953) causal ordering algorithm that given an assignment of values to 50 exoge­ nous variables, derives the structure of the model.",
      "startOffset" : 20,
      "endOffset" : 80
    }, {
      "referenceID" : 22,
      "context" : "However, when a model contains reversible causal mechanisms (Simon 1953; Druzdzel & van Leijen 2000), manipulation can have a drastic effect on the graph.",
      "startOffset" : 60,
      "endOffset" : 100
    }, {
      "referenceID" : 13,
      "context" : "More details on the syntax of our knowledge representation language can be found in (Lu 1999).",
      "startOffset" : 84,
      "endOffset" : 93
    }, {
      "referenceID" : 22,
      "context" : "In order to formalize our extensions, we need to re­ state the theorem that was originally proved by Simon (1953).",
      "startOffset" : 101,
      "endOffset" : 114
    }, {
      "referenceID" : 13,
      "context" : "See (Lu 1999) for the formal proof.",
      "startOffset" : 4,
      "endOffset" : 13
    }, {
      "referenceID" : 10,
      "context" : "The modeling process starts with an initial focus, which is normally, in the spirit of value-focused think­ ing (Keeney 1994), the value variable.",
      "startOffset" : 112,
      "endOffset" : 125
    }, {
      "referenceID" : 18,
      "context" : "Recent research in applying the object-oriented frame­ work to extend Bayesian networks for modeling com­ plex domains (Koller & Pfeffer 1997; Laskey & Ma­ honey 1997; Pfeffer et al. 1999) is closely related to our work.",
      "startOffset" : 119,
      "endOffset" : 188
    } ],
    "year" : 2011,
    "abstractText" : "We propose a framework for building graph­ ical causal model that is based on the con­ cept of causal mechanisms. Causal models are intuitive for human users and, more im­ portantly, support the prediction of the ef­ fect of manipulation. We describe an imple­ mentation of the proposed framework as an interactive model construction module, Ima­ GeNie, in SMILE (Structural Modeling, In­ ference, and Learning Engine) and in GeNie (SMILE's Windows user interface).",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}