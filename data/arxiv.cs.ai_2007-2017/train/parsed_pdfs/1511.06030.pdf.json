{
  "name" : "1511.06030.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "BIRDNEST: Bayesian Inference for Ratings-Fraud Detection",
    "authors" : [ "Bryan Hooi", "Neil Shah", "Alex Beutel", "Stephan Günneman", "Leman Akoglu", "Mohit Kumar", "Disha Makhija", "Christos Faloutsos" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Online reviews play an important role in informing customers’ purchasing decisions. This has led to the problem of fake reviews, in which businesses write or purchase fake reviews in order to raise the popularity of their products or services. Hence, it is crucial for online commercial platforms to identify and remove these reviews, in order to maintain customers’ trust in the accuracy of their reviews.\nVarious inputs such as rating, review text, timestamp etc. may be available for detection systems; in this work we focus on ratings and timestamps as they are commonly available and informative features. Informally, our problem is:\nPROBLEM 1. (INFORMAL) Given a set of users and products, and timestamped ratings (e.g. 1 to 5 stars) by users for\n∗Carnegie Mellon University †Technische Universität München ‡Stony Brook University §Flipkart\nproducts, compute a suspiciousness score for each user.\nCurrently, a number of algorithms use a temporal approach to detect ratings fraud [6, 7, 28]. These focus on catching products that receive a large number of positive or negative reviews in a short time, motivated by the ‘bursty’ nature of fraudulent reviews when a store wishes to rapidly increase their popularity or defame their competitors. An alternative approach based on rating distributions is to focus on finding users who rate products very differently from other users [12, 17]. These focus on detection of suspicious behavior by users or products in terms of their deviation from normal practice.\nIn this paper, we aim to combine both approaches in a principled way by constructing a Bayesian model for rating behavior, then formulating a likelihood-based metric which measures how much a user deviates from the rest of the users.\nThe Bayesian approach also provides a principled solution to the conceptually difficult problem of finding a good tradeoff between users with extreme rating distributions vs. users with larger number of ratings. Is a user with 50 ratings (average rating 5.0) more suspicious than a user with 500 ratings (average rating 4.95)? Bayesian methods allow us to quantitatively answer this question. Namely, our Bayesian method combines the rating distribution and number of ratings to estimate our beliefs about the rating characteristics of a user in a way that captures our uncertainty, which then determines how suspicious the user is.\nOur contributions are: • Theoretically sound user behavior model: we define\na Bayesian model for the data based on a mixture model which captures different types of user behavior. This model then allows us to determine how much an anomalous user deviates from normal behavior. • Suspiciousness metric: we define a likelihood-based metric which measures how much a user deviates from normal behavior. • Algorithm: we propose a scalable and effective algorithm for learning the Bayesian model and evaluating suspiciousness. • Effectiveness: we show that our method successfully spots review fraud in large, real-world graphs, with\nar X\niv :1\n51 1.\n06 03\n0v 1\n[ cs\n.A I]\n1 9\nN ov\n2 01\n5\nprecision of over 84% on the top 250 Flipkart users flagged by our algorithm. Reproducibility: our code is open-sourced at www.\nandrew.cmu.edu/user/bhooi/ratings.tar."
    }, {
      "heading" : "2 Background and Related Work",
      "text" : "Content-based approaches A significant portion of opinion fraud comes from customer reviews online. Customer reviews have been long studied [8], and many methods for review fraud focus on review text, such as [5, 11, 19]. While these methods are illuminating, many sites only have ratings without text, or text is easily manipulated. Therefore, in our setting, we focus on ratings and their temporal characteristics, as review text is not always available.\nGraph-based approaches Much of the existing work in fraud or anomaly detection on graphs has focused on detecting fraud in pure graphs; that is, graphs with no node or edge labels. This includes spectral methods which use eigen-decomposition or singular value decomposition (SVD) to group similar nodes in the graph [10, 21, 24]. [27] uses an iterative approach to label as honest and dishonest. Approaches based on Markov Random Fields and belief propagation have also been used to identify dense or suspicious subgraphs [1, 20]. [29] detects spammers through graphbased measures measuring self-similarity and neighborhood diversity. However, these methods do not make use of key temporal and rating data.\nTemporal methods for fraud detection There are a number of works on anomaly detection in multivariate time series [4, 16, 22, 26]. [3] focuses on fraudulent temporal patterns in graphs, and [6] found suspicious inter-arrival times between events in social media. A couple of works address temporal patterns of reviews, e.g. [28] detects spam singleton reviews and [7] detects time periods of unusual activity. However, our goal is to compute a general, principled, likelihood-based measurement of how suspicious each user is. In this regard, [9] offers a general suspiciousness metric for count data but is not suitable for ratings data.\nBehavior modeling and fraud detection A wide body of research has focused on understanding user behavior and especially rating behavior. In particular ratings have been studied by the recommendation systems community, with both frequentist [13] and Bayesian models [23] demonstrat-\ning great success. Additionally some models have worked to take into account temporal features [14], and others have captured the bimodal patterns in ratings data [2].\nOther behavior models have been proposed to detect users who deviate from normal practice in a meaningful way [12, 17]. In [25] a similar problem of finding anomalies in temporal rating data was treated with information theoretic arguments. By taking a Bayesian approach, we develop a significantly different perspective on the problem and our resulting metric of suspiciousness is more flexible, allowing for explicit priors, unique posteriors for each user, and easy extensions to other distributions."
    }, {
      "heading" : "3 Bayesian Model",
      "text" : "3.1 Motivating Example We start by illustrating why a Bayesian approach is helpful. Consider users Alice, Bob and Carol whose rating distributions are as given in Figure 3. For example, Alice rated 4 products, all with 5 stars. Bob did the same, 50 times. Carol gave about 300 ratings, and exhibits a ‘hockey-stick’ distribution, which is close to the average over all users. Which user is the most suspicious (i.e. likely fraudulent)? Our goal is to come up with a principled and intuitive measure of how suspicious each user is.\nWhy does Alice’s low rating count makes her less suspicious than Bob? Our answer is: since we only have 4 products rated by Alice, we have little information about her true (i.e. long-term) rating behavior. She may simply be a normal user who appears unusual as her first few ratings were high, but given more ratings, she would converge to a more typical distribution. Bob, however, is much less likely to be a normal user: we can say with greater certainty that his true rating behavior is anomalous.\nIntuitively, deciding how suspicious each user is involves a two-step process: first, we estimate our beliefs for what that user’s true rating distribution is. Second, we estimate how suspicious we believe they are, given our beliefs. For Alice, our beliefs are highly uncertain: we cannot be confident that her rating distribution is unusual. For Bob, we are confident that his rating distribution is fairly skewed\ntoward 5s. For Carol, we know her rating distribution with high confidence, but it is not suspicious.\nThe Bayesian approach applies this intuition in a principled manner. It first sets a prior, estimated from data, representing our ‘default’ beliefs about users’s rating behavior. It then estimates our beliefs (in the form of a posterior distribution) about their rating distribution. Finally, we compute how suspicious we believe them to be, averaging over their posterior distribution. Figure 4 illustrates how posterior distributions capture the information we need to identify a user as suspicious. The posterior distributions in Figure 4 refer to our beliefs about each user’s true long-term average rating, expressed as a probability distribution. The point estimates refer to each user’s observed average rating, which do not capture how much more certain we are in Bob’s case than Alice, and hence how much more suspicious Bob is.\nAlternatives that don’t work (z or t tests) What about instead performing a standard hypothesis test (such as a z or t-test) for each user’s average rating (or any other quantity associated with their rating distribution), to see whether their average rating differs significantly from the population? The problem with this approach lies with users like Carol, who differ slightly from the population but have a large number of ratings. Even as normal (non-fraudulent) users, we expect their true average rating to differ slightly from that of the population (say, by 0.1) just due to inter-person variation.\nGiven enough ratings, however, even such a small difference could produce arbitrarily small p-values under such a hypothesis test, since the test correctly concludes that there is an extremely small probability of drawing Carol’s observed average rating if her true average rating were equal to that of the population. However, such small differences are not suspicious. The Bayesian approach would instead estimate Carol’s posterior distribution as in Figure 4 and conclude that it is both narrow and entirely non-suspicious, which is a more\nsensible result.\n3.2 Proposed Model Table 1 summarizes the notation used in this paper.\nIn our problem setting, users are indexed i = 1, . . . ,m. User i has ni ratings, indexed by j = 1, . . . , ni. The ratings in stars given by user i are denoted by the variables xij ∈ {1, 2, . . . , s} (e.g. for star ratings from 1 to 5 we have s = 5). Similarly to [6], we preprocess the rating timestamps by computing its time difference from the previous rating, i.e. the difference between its timestamp and the timestamp of the last rating given by the same user. We then bucket the time differences according to the integer part of the log base b, where b is chosen to result in close to 20 buckets. The temporal bucket of the jth rating of user i is denoted ∆ij ∈ {1, 2, . . . ,∆max} for j = 1, . . . , ni, analogous to xij .\nUsing time differences instead of raw timestamps makes it possible to detect either unusually rapid rating of products by a user (due to having a concentration of small time differences), or unusually regular patterns, such as rating products once every hour. Both of these patterns suggest bot-like or spammy behavior, which we would like to detect. Moreover, the discretized i.e. multinomial approach allows us to flexibly detect a wide range of possible deviations from normal behavior without assuming a more restrictive parametric form, such as a Gaussian distribution.\nWe will consider the ratings X and time differences ∆ to be generated based on a model. From a high level, our generative model for user behavior is a mixture model in\nwhich each user belongs to one of K clusters: in general, there is no single type of user behavior, so we use clusters to capture different types of user behavior. Each cluster represents a certain type of rating distribution and temporal distribution for the users in that cluster.\nLet k = 1, . . . ,K index into the K clusters. For each user i, we first generate which cluster they belong to, zi ∈ {1, 2, . . . ,K}, from a Multinomial(π) distribution, where πk, the kth entry of π, is the probability that a random user is generated in cluster k.\nEven within a single cluster, it would not be reasonable to expect all users to behave exactly the same way. Thus, instead of using a single rating/temporal distribution per cluster, we allow small deviations per user. We do this by associating a common Dirichlet prior with each cluster: each user has their individual rating distribution drawn from this prior. We denote user i’s rating distribution by pi, a vector of length s of nonnegative entries which sums to 1, where the jth entry of this vector gives their probability of giving the jth rating. Thus, we draw user i’s rating distribution pi from a Dirichlet(αzi ). Similarly, qi represents user i’s temporal distribution, and we draw qi ∼ Dirichlet(βzi).\nFinally, to generate user i’s ratings, we draw each rating xij based on user i’s rating distribution: xij ∼ Multinomial(pi). Similarly, for the temporal buckets, we draw each ∆ij from a Multinomial(qi) distribution.\nThe generative model we have described is summarized in (3.1).\nzi ∼ Discrete(π) pi|zi = k ∼ Dirichlet(αk)\nxij ∼ Multinomial(ni,pi) qi|zi = k ∼ Dirichlet(βk)\n∆ij ∼ Multinomial(ni,qi)(3.1)\nThe corresponding graphical model is given in Figure 5."
    }, {
      "heading" : "4 Proposed Algorithms",
      "text" : "4.1 Fitting our Bayesian Model (BIRD) Algorithm 1 fits data to the model of Fig.5, by using a greedy hill climbing approach to maximize the overall likelihood function. In this algorithm, we iteratively adjust each parameter and the cluster assignments z until convergence. Each of the arg max lines in the algorithm can be solved efficiently, which we next describe how to do.\nCluster parameters Here we fix z and compute arg maxαk P (X,∆|αk, z) in Line 10; adjusting with respect to β will be similar. Note that adjusting αk only affects the likelihood with respect to xi, for i in cluster k. Thus we are equivalently maximizing∏ i:zi=k P (xi|αk, z).\nTo be clear, here P (xi|αk, z) refers to the marginal likelihood, i.e. the probability of generating xi, after marginalizing out pi. Thus we need to find the maximum likelihood update for αk given the xi for i in cluster k, which were sampled from the two-step process of first generating pi ∼ Dirichlet(αk) and then generating xi ∼ Multinomial(pi). This two-step process is also known as the Dirichlet-multinomial distribution; [18] provide fixedpoint iteration methods for maximum likelihood estimation of αk in this setting. Specifically, we repeat until convergence, for each k = 1, . . . ,K and l = 1, . . . , s:\nαnewkl = αkl\n∑m i=1\nnxil nxil−1+αkl∑m\ni=1 nxi nxi −1+ ∑ l′ αkl′ (4.2)\nSimilarly, the update for β is:\nβnewkl = βkl\n∑m i=1\nn∆il n∆il−1+βkl∑m\ni=1 n∆i n∆i −1+ ∑ l′ βkl′\n(4.3)\nCluster assignments In Line 15, we fix the cluster parameters and fit the maximum likelihood cluster assignment zi. Note that changing zi only affects the likelihood with respect to user i. Referring to our graphical model in Figure 5, maximizing P (X,∆|zi = k) is equivalent to finding:\nzi = arg max k\nπkP (xi|zi = k)P (∆i|zi = k)(4.4)\nTo compute P (xi|zi = k), note that this is the probability of drawing xi from a Dirichlet-multinomial distribution with known parameter αk.\nLet nxil = ∑ni j=1 1{xij = l} be the number of user i’s\nratings that equal l, and similarly n∆il = ∑ni j=1 1{∆ij = l}. The marginal distribution of a Dirichlet-multinomial\ndistribution (after marginalizing out pi) is known to be\nP (xi|zi = k) = Γ(Ak)\nΓ(ni +Ak) s∏ l=1 Γ(nxil + αkl) Γ(αkl)\nwhere Γ is the gamma function, andAk = ∑ l αkl. The term P (∆i|zi = k) can be computed in the same manner. Since zi is discrete, we can thus maximize (4.4) by computing πkP (xi|zi = k)P (∆i|zi = k) for each value of k and choosing the maximizing value of k.\nPosterior distributions of p and q Here we explain how to compute the posterior distributions in Line 18 of Algorithm 1. Let nxi = ((n x i1), . . . , (n x is)) and n ∆ i = ((n∆i1), . . . , (n ∆ is)). At this point the entire iterative process of estimating the hyperparameters and cluster assignments is complete, and we have to compute the posterior distributions of pi and qi given the dataX and ∆. pi has a Dirichlet(αzi) prior, so by the conjugate prior property of Dirichlet distributions, its posterior distribution is Dirichlet(αzi + n x i ). Similarly, the posterior distribution of β is Dirichlet(βzi + n ∆ i ).\nNumber of clusters We select the number of clusters K using the Bayesian Information Criterion (BIC).\nConvergence As we can see from Algorithm 1, each adjustment to π, α, β or z is an arg max step and increases the overall likelihood P (X,∆|z;π, α, β). Because the overall likelihood is bounded, this must converge.\n4.2 NEST: Proposed Metric for Detecting Suspicious Users Algorithm 1 gives us the posterior distributions P (pi|xi,∆i) and P (qi|xi,∆i) for the user parameters. In this section, we propose a suspiciousness metric, NEST (Normalized Expected Surprise Total). Recalling Figure 4, the overall idea is to compute user i’s suspiciousness, averaged over their posterior distribution.\nWe will compute suspiciousness with respect to rating and temporally, then normalize and combine them to ensure that each has equal influence. This is a practically motivated decision that ensures that even in settings where one of the variables has a much finer resolution than the other (i.e. it is bucketized into more buckets), neither variable will dominate the other in determining suspiciousness.\nWe now explain how to compute user i’s suspiciousness is in terms of their ratings distribution; the same formulas directly apply to the temporal distribution, and we explain how to combine the scores in (4.7).\nGlobal Distribution Recall that our Bayesian model BIRD gives us an estimate for the distribution underlying the rating behavior of all users, in the form of a mixture of Dirichlet(αk) distributions with mixture coefficients πk (and similarly, mixture of Dirichlet(βk) distributions for temporal\nAlgorithm 1 Fitting parameters for the model in Figure 5. X is a matrix containing all the xij and ∆ is a matrix containing all the ∆ij .\n1: procedure BIRD (X,∆) 2: Output: 3: cluster hyperparameters π, (αk,βk) K k=1 4: posterior distributions for each user’s rating and temporal distribution P (pi), P (qi) 5: while not converged do 6: Adjust cluster proportions π 7: πk = ∑m i=1 1{zi = k}/m 8: for k = 1, . . . ,K do 9: Adjust cluster hyperparameters αk,βk\n10: αnewk = arg maxαk P (X,∆|αk, z) (4.2) 11: βnewk = arg maxβk P (X,∆|βk, z) (4.3) 12: end for 13: for i = 1, . . . ,m do 14: Adjust users’ assignments to clusters: 15: znewi = arg maxk P (X,∆|zi = k) (4.4) 16: end for 17: end while 18: Compute user posterior distributions: 19: P (pi|X,∆) = Dirichlet(αzi + nxi ) 20: P (qi|X,∆) = Dirichlet(βzi + n ∆ i ) 21: end procedure\ndistributions). Denote this global distribution by Fx (resp. F∆):\nFx can be thought of as our estimate for the distribution of pi in general over all users (pi is the true rating distribution of user i).\nFx(p) = K∑ k=1 πk Dirichlet(p;αk)(4.5)\nwhere Dirichlet(p;αk) refers to the probability of generating p under a Dirichlet(αk) distribution.\nSurprise Denote p̃i := P (pi|xi,∆i), the posterior distribution of pi given the data. To be clear, observe that p̃i is a distribution over multinomial vectors. Recall that we estimate p̃i as part of BIRD: p̃i is a Dirichlet(αzi + n x i ) distribution. p̃i represents our beliefs about user i’s rating distribution. For the sake of intuition, imagine p̃i was a point mass, i.e. we had perfect knowledge of user i’s rating distribution: assume that it consists of a point mass at p. Recall that the posterior distribution p̃i is a distribution over multinomial vectors, so p here is a multinomial vector. Then user i’s suspiciousness could be calculated as surprise or negative log likelihood under the global distribution Fx evaluated at the rating distribution p:\nsurprise(p) = − logFx(p)\nThe less likely p is, the more suspicious the user is. This makes sense because Fx is our estimate for the global distribution from which all the usersare drawn from; the lower the log-likelihood of p, the more anomalous user i is when compared to this distribution. Thus, we use surprise to estimate the suspiciousness of a rating distribution p.\nExpected Surprise Now returning to the general case, when p̃i is a posterior distribution. In this case, we compute the average over p̃i of the surprise − logFx(p): that is, now p is drawn at random from this posterior distribution p̃i. Averaging the surprise gives us the posterior mean (or ‘Bayes estimate’) of user i’s suspiciousness, which can be regarded as our ‘best estimate’ of user i’s suspiciousness given our knowledge of them.1 Thus, we use expected surprise to estimate the suspiciousness of a user based on their posterior distribution p̃i.\nDEFINITION 1. (EXPECTED SURPRISE) The expected surprise for user i measures how surprising user i rating distribution is averaged over its posterior distribution, and is given by:\nsx(i) = −Ep∼p̃i logFx(p)(4.6)\nThe expected surprise s∆(i) with respect to the temporal distribution is computed similarly.\nAs discussed,−Ep∼p̃i logFx(p) measures the expected suspiciousness of a sample rating distribution drawn at random from the posterior distribution p̃i, where suspiciousness of a single rating distribution is given by its surprise or negative log likelihood under Fx.\nNormalized Expected Surprise Total (NEST) In our dataset, we use both ratings and temporal data. Using ratings data, we compute posterior distribution p̃i and the resulting expected surprise sx(i); using temporal data similarly gives us posterior distribution q̃i and expected surprise s∆(i). To combine these, we could simply add them; however, if one had a larger range of possible values than the other, the one with the largest range could end up dominating the sum. To give both terms comparable influence, we normalize them by their respective standard deviations. Let σx = std.dev(sx(1), . . . , sx(m)) and σ∆ be defined analogously. Then NEST is defined as:\nDEFINITION 2. (NEST) NEST measures how jointly suspicious user i is based on\n1The posterior mean of a parameter is also known as the minimum mean square error estimator, as it minimizes expected least squares loss. It has desirable properties such as consistency under fairly general conditions, and is widely used in practice. [15]\nhis or her ratings and temporally, and is given by:\nNEST(i) = sx(i) σx + s∆(i) σ∆ (4.7)\nNote that there is no need to normalize sx and s∆ additively (e.g. by subtracting the mean scores) since that would simply shift all the scores by the same amount.\nComputing NEST Fitting BIRD gives us the posterior distribution for user i’s rating distribution p̃i = P (pi|X,∆) (Line 19 in Algorithm 1); we get q̃i = P (qi|X,∆) similarly. We also know the full global distribution Fx(p) =∑K k=1 πk Dirichlet(p;αk). Hence, we can compute the expected surprise sx(i) = −Ep∼p̃i logFx(p) by taking a fixed number of samples from p̃i and repeatedly evaluating their log-likelihood under Fx. We can then compute the expected surprise values s∆(·) and combining the two as shown in (4.7)."
    }, {
      "heading" : "5 Experiments",
      "text" : "We conducted experiments to answer the following questions: Q1. Effectiveness on real data: does BIRDNEST catch fraud on real data? Q2. Scalability: does it scale to large datasets? Q3: Interpretability: can the results of the Bayesian model BIRD and the scores given by NEST be interpreted in a real-life setting?\nWe implemented BIRDNEST in Python; all experiments were carried out on a 2.4 GHz Intel Core i5 Macbook Pro, 16 GB RAM, running OS X 10.9.5. The code is available for download at www.andrew.cmu.edu/ user/bhooi/ratings.tar. We test BIRDNEST on a variety of real world datasets: table 2 offers details on the datasets we used.\nTable 2: Datasets used.\nDataset # of users # of products # of ratings\nFlipkart 1.1M 550K 3.3M SWM [1] 0.97M 15K 1.1M"
    }, {
      "heading" : "5.1 Q1: Effectiveness",
      "text" : "Evaluation on Flipkart data Flipkart is an online e-commerce platform on which merchants sell products to customers, on which customers review products from 1 to 5 stars. We applied BIRDNEST to detect the 250 most suspicious users and provided them to Flipkart; these accounts were investigated and hand-labelled by Flipkart, finding that 211 users of the top 250 flagged by BIRDNEST were involved in fraud. Figure 1b shows the algorithm’s precision at k: for various values of k up to 250: note\nthat precision for the most suspicious users is very high: e.g. precision of 1.0 for the first 50 users. These are substantial findings for Flipkart. One common pattern that the domain-experts found was that most of the users labeled as fraudulent are either spamming 4/5 star ratings to multiple products from a single seller (boosting seller’s ratings), or spamming 1/2 star ratings to multiple products from another seller (defaming the competition).\nFigure 2 plots the averaged rating distributions of users within each group: that is, for each user we computed their frequency of giving each rating from 1 to 5; Figures 2 and 1a takes the average of the rating distributions for users in the corresponding group. Examining the detected users in Figure 2, a common pattern we find is that they consist of extreme polarized rating distributions as well as temporal distributions. The detected users consist of highly negative users (who give only 1 ratings) and highly positive users (who give mostly 5 ratings, with a relatively small fraction of 4s). Similarly, Figure 1a shows the common pattern that detected users contain much shorter temporal differences than normal users.\nEvaluation on SWM data The SWM datasets consists of software product (app) reviews. The dataset was collected by [1] by crawling all the app reviews in the entertainment category from an anonymous online app store. Each review consists of review text as well as a rating from 1 star to 5 stars.\nWe find clear evidence of fake reviews in the dataset: for example, the most suspicious user posted a block of 27 reviews for the same app all within the span of less than a week, all five-star ratings with near-identical review title and text, as shown in Table 3. Moreover, the review text shows clear signs of being a fake review: they advertise a code associated with an app: typically, users advertise such codes because they give some benefit to the owner when new users download the app via one of these codes.\nuser’s reviews also consist of similar blocks of repeated text advertising the code. In fact, all 10 of the top suspicious user accounts flagged by BIRDNEST contain advertisements for codes in similar contexts, often accompanied with promises of free cash, points and gift cards.\n5.2 Q2: Scalability Assume that we run (#it) iterations of the outer loop of Algorithm 1, let m be the number of users, and K the number of clusters. In each iteration, adjusting π takes O(m) time; adjusting each αi, βi and zi all take O(K) time. Hence, the algorithm takes O((#it)mK) time, which is linear. Figure 6 shows that the algorithm is fast and its computation time grows linearly in practice.\n5.3 Q3: Interpretability In Section 3.1, we motivated the Bayesian approach by giving three users, Alice, Bob and Carol. We explained how the Bayesian approach captures our intuitions about these users through posterior distributions. We now use real data from Flipkart to verify that BIRDNEST indeed conforms to the intuitions that motivated this approach, and that the posterior distributions from BIRDNEST are interpretable and useful in real-life settings.\nWe selected 3 real Flipkart users: alice, bob and carol (names changed to maintain anonymity). They were chosen to match the rating frequencies of Alice, Bob and Carol in 3.1. We computed each user’s posterior distribution of their true rating distribution using BIRDNEST. From this we computed the posterior distribution of their true, longterm average rating, by simulating 10, 000 draws of pi from their Dirichlet posterior distribution. We display these with their NEST values in Figure 7.\nAgreeing with intuition, both alice and carol are nonsuspicious, while bob is very suspicious, as indicated by the NEST scores: alice is ranked around 189, 000th most suspicious, bob is ranked around 800th, and carol is ranked around 10, 000th, out of the 1.1 million users. The NEST scores given by our algorithm are interpretable\nas expected surprise values, i.e. they are in units of loglikelihood, so a unit difference (after normalization) represents an exponential increase in likelihood. As such, we see from this example that BIRDNEST conforms to intuition in the way it uses posterior distributions to measure uncertainty. Moreover, the posterior distributions of average rating or other quantities can be plotted via simulation and used for further understanding and investigation."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we developed BIRD, a Bayesian inference approach for ratings data, and NEST, a principled likelihoodbased suspiciousness metric for fraud detection. Our method provides a principled way to combine rating and temporal information to detect rating fraud, and to find a tradeoff between users with extreme rating distributions vs. users with larger number of ratings. Our contributions are: • Theoretically sound user behavior model: we define\na Bayesian model for the data based on a mixture model which captures different types of user behavior. This model then allows us to determine how much an anomalous user deviates from normal behavior. • Suspiciousness metric: we define a likelihood-based metric which measures how much a user deviates from normal behavior. • Algorithm: we propose a scalable and effective algorithm for learning the Bayesian model and evaluating suspiciousness. • Effectiveness: we show that our method successfully spots review fraud in large, real-world graphs, with precision of over 84% for the top 250 Flipkart users\nflagged by our algorithm."
    } ],
    "references" : [ {
      "title" : "Opinion fraud detection in online reviews by network effects",
      "author" : [ "L. Akoglu", "R. Chandy", "C. Faloutsos" ],
      "venue" : "ICWSM, 13:2–11,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2013
    }, {
      "title" : "Cobafi: collaborative bayesian filtering",
      "author" : [ "A. Beutel", "K. Murray", "C. Faloutsos", "A.J. Smola" ],
      "venue" : "In Proceedings of the 23rd international conference on World wide web,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2014
    }, {
      "title" : "Copycatch: stopping group attacks by spotting lockstep behavior in social networks",
      "author" : [ "A. Beutel", "W. Xu", "V. Guruswami", "C. Palow", "C. Faloutsos" ],
      "venue" : "In Proceedings of the 22nd international conference on World Wide Web,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "Detection and characterization of anomalies in multivariate time series",
      "author" : [ "H. Cheng", "P.-N. Tan", "C. Potter", "S.A. Klooster" ],
      "venue" : "In SDM,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2009
    }, {
      "title" : "Syntactic stylometry for deception detection",
      "author" : [ "S. Feng", "R. Banerjee", "Y. Choi" ],
      "venue" : "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2012
    }, {
      "title" : "Rsc: Mining and modeling temporal activity in social media",
      "author" : [ "A. Ferraz Costa", "Y. Yamaguchi", "A. Juci Machado Traina", "C. Traina Jr.", "C. Faloutsos" ],
      "venue" : "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2015
    }, {
      "title" : "Detecting anomalies in dynamic rating data: A robust probabilistic model for rating evolution",
      "author" : [ "S. Günnemann", "N. Günnemann", "C. Faloutsos" ],
      "venue" : "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2014
    }, {
      "title" : "Mining and summarizing customer reviews",
      "author" : [ "M. Hu", "B. Liu" ],
      "venue" : "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2004
    }, {
      "title" : "A general suspiciousness metric for dense blocks in multimodal data",
      "author" : [ "M. Jiang", "A. Beutel", "P. Cui", "B. Hooi", "S. Yang", "C. Faloutsos" ],
      "venue" : "In Data Mining (ICDM),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2015
    }, {
      "title" : "Inferring strange behavior from connectivity pattern in social networks",
      "author" : [ "M. Jiang", "P. Cui", "A. Beutel", "C. Faloutsos", "S. Yang" ],
      "venue" : "In Advances in Knowledge Discovery and Data Mining,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2014
    }, {
      "title" : "Opinion spam and analysis",
      "author" : [ "N. Jindal", "B. Liu" ],
      "venue" : "In Proceedings of the 2008 International Conference on Web Search and Data Mining,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2008
    }, {
      "title" : "Finding unusual review patterns using unexpected rules",
      "author" : [ "N. Jindal", "B. Liu", "E.-P. Lim" ],
      "venue" : "In Proceedings of the 19th ACM international conference on Information and knowledge management,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2010
    }, {
      "title" : "Factorization meets the neighborhood: a multifaceted collaborative filtering model",
      "author" : [ "Y. Koren" ],
      "venue" : "In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2008
    }, {
      "title" : "Collaborative filtering with temporal dynamics",
      "author" : [ "Y. Koren" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2010
    }, {
      "title" : "Theory of point estimation, volume 31",
      "author" : [ "E.L. Lehmann", "G. Casella" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1998
    }, {
      "title" : "Mining approximate top-k subspace anomalies in multi-dimensional time-series data",
      "author" : [ "X. Li", "J. Han" ],
      "venue" : "In Proceedings of the 33rd international conference on Very large data bases,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2007
    }, {
      "title" : "Detecting product review spammers using rating behaviors",
      "author" : [ "E.-P. Lim", "V.-A. Nguyen", "N. Jindal", "B. Liu", "H.W. Lauw" ],
      "venue" : "In Proceedings of the 19th ACM international conference on Information and knowledge management,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2010
    }, {
      "title" : "Estimating a dirichlet distribution",
      "author" : [ "T. Minka" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2000
    }, {
      "title" : "Finding deceptive opinion spam by any stretch of the imagination",
      "author" : [ "M. Ott", "Y. Choi", "C. Cardie", "J.T. Hancock" ],
      "venue" : "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies- Volume",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2011
    }, {
      "title" : "Netprobe: a fast and scalable system for fraud detection in online auction networks",
      "author" : [ "S. Pandit", "D.H. Chau", "S. Wang", "C. Faloutsos" ],
      "venue" : "In Proceedings of the 16th international conference on World Wide Web,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2007
    }, {
      "title" : "Eigenspokes: Surprising patterns and community structure in large graphs",
      "author" : [ "B. Prakash", "M. Seshadri", "A. Sridharan", "S. Machiraju", "C. Faloutsos" ],
      "venue" : "PAKDD, 2010a,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2010
    }, {
      "title" : "Efficient algorithms for mining outliers from large data sets",
      "author" : [ "S. Ramaswamy", "R. Rastogi", "K. Shim" ],
      "venue" : "In ACM SIG- MOD Record,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2000
    }, {
      "title" : "Bayesian probabilistic matrix factorization using markov chain monte carlo",
      "author" : [ "R. Salakhutdinov", "A. Mnih" ],
      "venue" : "In Proceedings of the 25th international conference on Machine learning,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2008
    }, {
      "title" : "Spotting suspicious link behavior with fbox: an adversarial perspective",
      "author" : [ "N. Shah", "A. Beutel", "B. Gallagher", "C. Faloutsos" ],
      "venue" : "In Data Mining (ICDM),",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2014
    }, {
      "title" : "Edgecentric: Anomaly detection in edge-attributed networks",
      "author" : [ "N. Shah", "A. Beutel", "B. Hooi", "L. Akoglu", "S. Gunnemann", "Makhija", "M. Kumar", "C. Faloutsos" ],
      "venue" : "arXiv preprint,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2015
    }, {
      "title" : "Unsupervised discovery of abnormal activity occurrences in multi-dimensional time series, with applications in wearable systems",
      "author" : [ "A. Vahdatpour", "M. Sarrafzadeh" ],
      "venue" : "In SDM,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2010
    }, {
      "title" : "Review graph based online store review spammer detection",
      "author" : [ "G. Wang", "S. Xie", "B. Liu", "P.S. Yu" ],
      "venue" : "In Data mining (icdm), 2011 ieee 11th international conference on,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2011
    }, {
      "title" : "Review spam detection via temporal pattern discovery",
      "author" : [ "S. Xie", "G. Wang", "S. Lin", "P.S. Yu" ],
      "venue" : "In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2012
    }, {
      "title" : "Discovering opinion spammer groups by network footprints",
      "author" : [ "J. Ye", "L. Akoglu" ],
      "venue" : "In Machine Learning and Knowledge Discovery in Databases,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "Currently, a number of algorithms use a temporal approach to detect ratings fraud [6, 7, 28].",
      "startOffset" : 82,
      "endOffset" : 92
    }, {
      "referenceID" : 6,
      "context" : "Currently, a number of algorithms use a temporal approach to detect ratings fraud [6, 7, 28].",
      "startOffset" : 82,
      "endOffset" : 92
    }, {
      "referenceID" : 27,
      "context" : "Currently, a number of algorithms use a temporal approach to detect ratings fraud [6, 7, 28].",
      "startOffset" : 82,
      "endOffset" : 92
    }, {
      "referenceID" : 11,
      "context" : "An alternative approach based on rating distributions is to focus on finding users who rate products very differently from other users [12, 17].",
      "startOffset" : 135,
      "endOffset" : 143
    }, {
      "referenceID" : 16,
      "context" : "An alternative approach based on rating distributions is to focus on finding users who rate products very differently from other users [12, 17].",
      "startOffset" : 135,
      "endOffset" : 143
    }, {
      "referenceID" : 7,
      "context" : "Customer reviews have been long studied [8], and many methods for review fraud focus on review text, such as [5, 11, 19].",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 4,
      "context" : "Customer reviews have been long studied [8], and many methods for review fraud focus on review text, such as [5, 11, 19].",
      "startOffset" : 109,
      "endOffset" : 120
    }, {
      "referenceID" : 10,
      "context" : "Customer reviews have been long studied [8], and many methods for review fraud focus on review text, such as [5, 11, 19].",
      "startOffset" : 109,
      "endOffset" : 120
    }, {
      "referenceID" : 18,
      "context" : "Customer reviews have been long studied [8], and many methods for review fraud focus on review text, such as [5, 11, 19].",
      "startOffset" : 109,
      "endOffset" : 120
    }, {
      "referenceID" : 9,
      "context" : "This includes spectral methods which use eigen-decomposition or singular value decomposition (SVD) to group similar nodes in the graph [10, 21, 24].",
      "startOffset" : 135,
      "endOffset" : 147
    }, {
      "referenceID" : 20,
      "context" : "This includes spectral methods which use eigen-decomposition or singular value decomposition (SVD) to group similar nodes in the graph [10, 21, 24].",
      "startOffset" : 135,
      "endOffset" : 147
    }, {
      "referenceID" : 23,
      "context" : "This includes spectral methods which use eigen-decomposition or singular value decomposition (SVD) to group similar nodes in the graph [10, 21, 24].",
      "startOffset" : 135,
      "endOffset" : 147
    }, {
      "referenceID" : 26,
      "context" : "[27] uses an iterative approach to label as honest and dishonest.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 0,
      "context" : "Approaches based on Markov Random Fields and belief propagation have also been used to identify dense or suspicious subgraphs [1, 20].",
      "startOffset" : 126,
      "endOffset" : 133
    }, {
      "referenceID" : 19,
      "context" : "Approaches based on Markov Random Fields and belief propagation have also been used to identify dense or suspicious subgraphs [1, 20].",
      "startOffset" : 126,
      "endOffset" : 133
    }, {
      "referenceID" : 28,
      "context" : "[29] detects spammers through graphbased measures measuring self-similarity and neighborhood diversity.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 3,
      "context" : "Temporal methods for fraud detection There are a number of works on anomaly detection in multivariate time series [4, 16, 22, 26].",
      "startOffset" : 114,
      "endOffset" : 129
    }, {
      "referenceID" : 15,
      "context" : "Temporal methods for fraud detection There are a number of works on anomaly detection in multivariate time series [4, 16, 22, 26].",
      "startOffset" : 114,
      "endOffset" : 129
    }, {
      "referenceID" : 21,
      "context" : "Temporal methods for fraud detection There are a number of works on anomaly detection in multivariate time series [4, 16, 22, 26].",
      "startOffset" : 114,
      "endOffset" : 129
    }, {
      "referenceID" : 25,
      "context" : "Temporal methods for fraud detection There are a number of works on anomaly detection in multivariate time series [4, 16, 22, 26].",
      "startOffset" : 114,
      "endOffset" : 129
    }, {
      "referenceID" : 2,
      "context" : "[3] focuses on fraudulent temporal patterns in graphs, and [6] found suspicious inter-arrival times between events in social media.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[3] focuses on fraudulent temporal patterns in graphs, and [6] found suspicious inter-arrival times between events in social media.",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 27,
      "context" : "[28] detects spam singleton reviews and [7] detects time periods of unusual activity.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 6,
      "context" : "[28] detects spam singleton reviews and [7] detects time periods of unusual activity.",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 8,
      "context" : "In this regard, [9] offers a general suspiciousness metric for count data but is not suitable for ratings data.",
      "startOffset" : 16,
      "endOffset" : 19
    }, {
      "referenceID" : 12,
      "context" : "In particular ratings have been studied by the recommendation systems community, with both frequentist [13] and Bayesian models [23] demonstrat-",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 22,
      "context" : "In particular ratings have been studied by the recommendation systems community, with both frequentist [13] and Bayesian models [23] demonstrat-",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 13,
      "context" : "Additionally some models have worked to take into account temporal features [14], and others have captured the bimodal patterns in ratings data [2].",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 1,
      "context" : "Additionally some models have worked to take into account temporal features [14], and others have captured the bimodal patterns in ratings data [2].",
      "startOffset" : 144,
      "endOffset" : 147
    }, {
      "referenceID" : 11,
      "context" : "Other behavior models have been proposed to detect users who deviate from normal practice in a meaningful way [12, 17].",
      "startOffset" : 110,
      "endOffset" : 118
    }, {
      "referenceID" : 16,
      "context" : "Other behavior models have been proposed to detect users who deviate from normal practice in a meaningful way [12, 17].",
      "startOffset" : 110,
      "endOffset" : 118
    }, {
      "referenceID" : 24,
      "context" : "In [25] a similar problem of finding anomalies in temporal rating data was treated with information theoretic arguments.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 5,
      "context" : "Similarly to [6], we preprocess the rating timestamps by computing its time difference from the previous rating, i.",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 17,
      "context" : "This two-step process is also known as the Dirichlet-multinomial distribution; [18] provide fixedpoint iteration methods for maximum likelihood estimation of αk in this setting.",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 14,
      "context" : "[15]",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 0,
      "context" : "3M SWM [1] 0.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "The dataset was collected by [1] by crawling all the app reviews in the entertainment category from an anonymous online app store.",
      "startOffset" : 29,
      "endOffset" : 32
    } ],
    "year" : 2017,
    "abstractText" : "Review fraud is a pervasive problem in online commerce, in which fraudulent sellers write or purchase fake reviews to manipulate perception of their products and services. Fake reviews are often detected based on several signs, including 1) they occur in short bursts of time; 2) fraudulent user accounts have skewed rating distributions. However, these may both be true in any given dataset. Hence, in this paper, we propose an approach for detecting fraudulent reviews which combines these 2 approaches in a principled manner, allowing successful detection even when one of these signs is not present. To combine these 2 approaches, we formulate our Bayesian Inference for Rating Data (BIRD) model, a flexible Bayesian model of user rating behavior. Based on our model we formulate a likelihood-based suspiciousness metric, Normalized Expected Surprise Total (NEST). We propose a linear-time algorithm for performing Bayesian inference using our model and computing the metric. Experiments on real data show that BIRDNEST successfully spots review fraud in large, real-world graphs: the 50 most suspicious users of the Flipkart platform flagged by our algorithm were investigated and all identified as fraudulent by domain experts at Flipkart.",
    "creator" : "LaTeX with hyperref package"
  }
}