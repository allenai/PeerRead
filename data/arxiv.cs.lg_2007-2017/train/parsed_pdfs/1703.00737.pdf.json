{
  "name" : "1703.00737.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Wireless Interference Identification with Convolutional Neural Networks",
    "authors" : [ "Malte Schmidt", "Dimitri Block", "Uwe Meier" ],
    "emails" : [ "malte.schmidt@rwth-aachen.de,", "dimitri.block@hs-owl.de,", "uwe.meier@hs-owl.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this work we propose the first WII approach based upon deep convolutional neural networks (CNNs). The CNN naively learns its features through self-optimization during an extensive data-driven GPU-based training process. We propose a CNN example which is based upon sensing snapshots with a limited duration of 12.8 µs and an acquisition bandwidth of 10 MHz. The CNN differs between 15 classes. They represent packet transmissions of IEEE 802.11 b/g, IEEE 802.15.4 and IEEE 802.15.1 with overlapping frequency channels within the 2.4 GHz ISM band. We show that the CNN outperforms state-ofthe-art WII approaches and has a classification accuracy greater than 95 % for signal-to-noise ratio of at least -5 dB.\nI. INTRODUCTION\nArtificial neural networks and especially convolutional neural networks (CNNs) achieved excellent results for different benchmarks in recent years [1], [2], [3]. Neural networks achieve the best performance e.g. for character recognition of the Mixed National Institute of Standards and Technology (MNIST) database [4]. The results achieved by the CNNs from Cireşan et al. [1] are comparable to human performance. Inspired by these results and the progress in deep learning, CNNs are used as classifier in a growing number of research fields.\nOne of these research fields is wireless interference identification (WII) for coexistence management of license-free frequency bands such as the 2.4 GHz ISM band. Such bands are shared between incompatible heterogeneous wireless communication systems. In industrial environments, typically standardized wireless communication systems within the 2.4 GHz ISM band are wide-band high-rate IEEE 802.11 b/g/n, narrow-band low-rate IEEE 802.15.4-based WirelessHART and ISA 100.11a, and IEEE 802.15.1-related PNO WSANFA and Bluetooth. Additionally, the spectrum band is shared with many proprietary wireless technologies which target specific application requirements such as the IEEE 802.11-based industrial WLAN (iWLAN) from Siemens AG, FHSS-based Trusted Wireless from Phoenix Contact and IEEE 802.15.1- based WISA from ABB Group.\nAny radio interference can cause packet loss and transmission latency for industrial radio communication systems. Both\neffects have to be mitigated for real-time medium requirements. Therefore, the norm IEC 62657-2 [5] for industrial radio communication systems recommends an active coexistence management for reliable medium utilization. [5] recommends (i) manual, (ii) automatic non-cooperative or (iii) automatic cooperative coexistence management. The first approach is the most in-efficient one, due to time-consuming complex configuration effort. The automatic approaches (ii) and (iii) enable efficient self-reconfiguration without manual intervention and radio-specific expertise. An automatic cooperative coexistence management (iii) requires a control channel, i.e. a logical common communication connection between each coexisting wireless system to enable deterministic medium access. In case of a single legacy coexisting wireless system without such connection, the non-cooperative approach (ii) is recommended. Non-cooperative coexistence management approaches are aware of coexisting wireless systems based on independent WII and mitigation.\nIn this paper, we propose the first WII approach based upon deep CNNs. In order to face realistic wireless device capabilities the approach is limited to a sensing bandwidth of 10 MHz and a sensing snapshot is limited to 128 IQ Samples with the duration of 12.8 µs. The evaluation is performed with standardized wireless communication systems based upon IEEE 802.11 b/g, IEEE 802.15.4 and IEEE 802.15.1, which are sharing the 2.4 GHz ISM band. In total 19 different variants of modulation types and symbol rates are utilized. Thereby, the WII approach has to differ between 15 classes which represent the allocated frequency channel and the wireless technology.\nFirst of all in chapter II we will present and discuss three publications related to our work: Compressed Sensing, the neuro-fuzzy signal classifier and Convolutional Modulation Recognition. Then, in chapter III, we will explain how we generated our data set and discuss our CNN design in chapter IV. Thirdly in chapter V we will evaluate the performance of our CNNs and compare it to the performance of the neurofuzzy signal classifier (NFSC). Finally in chapter VI we will suggest future work."
    }, {
      "heading" : "II. RELATED WORK",
      "text" : ""
    }, {
      "heading" : "A. Compressed Sensing",
      "text" : "Compressed sensing is utilized for sub-sampled signal reconstruction. In [6], [7] it is also applied for classification\nar X\niv :1\n70 3.\n00 73\n7v 1\n[ cs\n.L G\n] 2\nM ar\n2 01\n7\nof frequency bands into white, gray and black sections. Such separation depends on the spectral power density and shows in which sections of the frequency band a transmission without interference is likely.\nThis method tries to reduce the run-time of the decision process as much as possible. Therefore, the computation of the power density spectrum (PSD) is done with a compressed vector of input samples for the trade-off of accuracy. The goal of this method is not to exactly classify which radio signals are present but to find spectral spaces which are sparely used. For this task a wavelet-based edge detector is used.\nIn contrast to our approach the compressed sensing promises faster run-times and can make use of samples recorded with a sample rate lower than the Nyquist rate. This means lower hardware requirements. On the other hand this leads to an information loss which might be helpful for decision making."
    }, {
      "heading" : "B. Neuro-Fuzzy Signal Classifier",
      "text" : "The NFSC [8] is an expert system which classifies frequency bands with respect to known wireless technologies. The purpose of the NFSC is similar to the proposed CNN. The performance of the two classifiers will be compared later on.\nThe NFSC is separated into six different layers. The input of the first layer, the input layer, are the IQ samples of the signal. This layer computes the PSD of the input.\nIn the second layer, the fuzzification layer, the PSD is normalized to\nµ[n] = ∣∣∣∣ min (P )− P [n]min (P )−max (P ) ∣∣∣∣ (1)\nwith the PSD P in dBm. In the third layer, the filtering layer, the signal is filtered with a predefined filter shape. In the simplest case the filter shape is a rectangle that is greater than the channel bandwidth of the radio signal that has to be classified.\nAfter the filtering layer the similarity layer computes the similarity of the filtered signal with a predefined reference shape. After comparing the similarity to a threshold the radio signal is classified. Given the reference shape R and the fuzzificated, filtered signal S the similarity SM is given by\nSM =\n∑ n min (R [n] , S [n])\nmax (∑ n R [n] , ∑ n S [n] ) . (2) Thus it is possible to define many different filter and reference shapes to classify different radio signals at the same time.\nThe fifth layer, the statistics layer aggregates consecutive results for temporal evaluation. This information is handed over to the sixth layer, the interference layer, which decides if the radio signal belongs to a frequency-hopping system.\nIn this paper the NFSC up to the fourth layer is compared to the CNN because the CNN has only a very short measurement period and temporal statistics must be collected by a following processing unit.\nThe purpose of the NFSC is exactly the same as the CNN presented in this paper: to classify radio signals with respect to known standards. The approach however is quite different. While the NFSC relies on pre-defined features and a fixed decision process the CNN trains its feature extraction and decision process during a learning process. On the one hand this leads to a more flexible decision making. On the other hand it becomes more difficult to analyze the decision making process."
    }, {
      "heading" : "C. Convolutional Modulation Recognition",
      "text" : "O’Shea et al. [9] compared the performance of different classifiers for classifying 11 modulations, 8 digital and 3 analog modulations. The classifiers used were CNNs with different parameters, deep neural networks with different parameters, a decision tree, a naive bayes classifier, a k-nearestneighbor classifier and a support vector machine. For this task a CNN achieved the best results for low signal-to-noise ratios (SNRs). For high SNRs the difference of all classifiers were comparable except the naive bayes and a deep neural network with high regularization.\nO’Shea et al. investigated the complex-valued temporal radio signal domain whereas in this paper the spectral radio signal domain is investigated. Nevertheless there are many parallels in these domains and we adapted the CNN from O’Shea et al. that achieved the best results as a starting point for our work. This also shows how flexible such self-learning classifiers can be used. The network structure of this CNN was inspired by networks for the visual domain like the MNIST data set.\nFor data set generation O’Shea et al. used GNU Radio [10] a toolkit for software defined radios. The CNN was trained on approximately 96,000 snapshots each consisting of 128 IQ samples. These IQ samples were given as a 128× 2 matrix as the input for the CNN. One column of the matrix consisted of the I-samples and the other column of the Q-samples. No information about the link between the I- and Q-samples were given to the network. The snapshots were snapshots of the time domain. The data set is available at [11]."
    }, {
      "heading" : "III. GENERATION OF DATA SET",
      "text" : "The training and validation data that was used was generated with the vector signal generator (VSG) SMBV100A from RHODE & SCHWARZ and was recorded with the real time spectrum analyzer (RSA) RSA6114A from TEKTRONIX.\nThe measurement was triggered. Only data was recorded in which a radio signal was transmitted. For example the interframe gaps of the signals were not recorded. Every package that was sent by the VSG had the maximum allowed number of bytes as payload. The payload was chosen at random.\nFor the IEEE 802.11 b/g frames the Physical Layer Mode was varied between CCK, PBCC and OFDM and every allowed bit rate for each mode was used. For the IEEE 802.15.1 frames the Transport Mode was varied between ACL, eSCO and SCO and different packet types were used. For the IEEE802.15.4 frames the ACK-frame was used.\nIn the presented work some restrictions concerning the training and validation data were made:\n• Single-label classification • Flat fading channel model • Thermal noise reception distortions A single-label problem is considered, so signals of exactly one class are present in each input sensing snapshot for the CNN. This means no concurrent signals were allowed. Moreover for the generating of the data only one emitter, the VSG, was used.\nFurther, a flat fading channel was utilized due to the connection of the VSG and RSA via a coaxial cable. These restrictions were made to keep the problem simple to get a first prototype running.\nThe third restriction is an assumption of thermal noise reception distortions with additive white Gaussian noise in the SNR range of -20 dB until 20 dB with the step size of 2 dB. It was added with a SIMULINK [12] model in post-processing.\nIn total 151,200 sensing snapshots were used for training and 74,025 for validation."
    }, {
      "heading" : "IV. CONVOLUTIONAL NEURAL NETWORK DESIGN",
      "text" : "The CNNs design targets radio signal classification. The radio signals are complaint to IEEE 802.11 b/g, IEEE 802.15.4 and IEEE 802.15.1 packet transmissions. Thereby, the CNN shall classify the allocated frequency channel and the corresponding wireless technology.\nIn order to face realistic wireless device capabilities the CNN is limited to a sensing bandwidth of 10 MHz. Hence, to observe the whole 2.4 GHz-ISM-Band eight parallel classifiers are required. Therefore, a technology-specific relative channel number ROWT can be mapped to its absolute channel number ACHWT with the index nCNN ∈ {1, 2, ..., 8} of the utilized CNN:\nACHWT = RCHWT +ROWT · (nCNN − 1) +AOWT (3)\nwith technology-specific absolute and relative channel offsets ROWT and AOWT, respectively. The offset values and the channel number sets are listed in Tab. I. The limited sensing bandwidth comprises ten, two, and three frequency channels of IEEE 802.15.1, IEEE 802.15.4, and IEEE 802.11 b/g complaint signals, respectively. In total, 15 different classes have to be distinguished.\nFig. 1 illustrates the classes which represent frequency channels of the corresponding wireless technologies in case the third CNN with the center frequency of 2426.5 MHz is utilized. It is important to mention, that the frequency channels of the selected IEEE 802.15.1 and IEEE 802.15.4 complaint signals are within sensing bandwidth while the signals complaint to IEEE 802.11 b/g are only partly within sensing bandwidth.\nThe sensing bandwidth is exemplary and other bandwidths are possible. A greater sensing bandwidth with a fixed sensing snapshot duration increase the input data size proportionally. Additionally, the number of observable frequency channels and therefore distinguishable classes increases. Therefore, the\nCNNs requires more neurons in at least the first and last layer, which increases the computation complexity and also the required number of IQ-samples for a sensing snapshot."
    }, {
      "heading" : "A. Frequency-Domain Sensing Snapshots",
      "text" : "The sensing snapshot is limited to a duration of 12.8 µs and therefore consists of 128 IQ-Samples. It has to be greater than the symbol durations of the utilized wireless technologies for sense-making classification. With the minimal applied symbol duration of 1 µs, a single sensing snapshot contains up to 12.8 symbols.\nDanev et al. [13] showed for emission-based wireless device identification that frequency-based features outperform their time-based equivalents. Therefore, the IQ-Samples are transfered into frequency-domain by fast fourier transform (FFT). The resulting snapshot contains 128 complex-valued frequency bins."
    }, {
      "heading" : "B. Network Structure",
      "text" : "The network structure of the CNN is derived from O’Shea et al. [9] as listed in Tab. II.\nTherefore, the input data is a sensing snapshot with complex-valued frequency bins, whereby the real and imaginary parts are considered as independent floating point values. So, the input data results as 128× 2 matrix.\nThe output data size is a vector of the length 15 as there are 15 classes to classify. Each entry of the vector has a value between 0 and 1 and describes how likely it is that the input data belongs to the class it stands for in relation to the other classes."
    }, {
      "heading" : "C. Network Training",
      "text" : "For the training process the Adam optimizer [14] was used and the input data was normalized. This optimizer showed best results in the work of O’Shea et al.. The default parameters for the Adam optimizer except the learning rate were used. The learning rate for the CNN was 0.0001. The CNN was trained for 50 epochs. This setup showed best results among small parameter variations. No hyperparameter optimization was performed but could be done in the future to optimize the results. A batch size of 1024 was used for training which was near the limit of the graphics card memory."
    }, {
      "heading" : "D. Network Size Reduction",
      "text" : "As a rule of thumb it is often assumed that the degrees of freedom of the CNN should be less than the number of sensing snapshots for training. In practice it is difficult to apply to this rule because it is e.g. not applicable if you also have to determine the number of sensing snapshots you will use for training.\nAs the size of the data set was determined by orientating to the work of O’Shea et al. [9] we then reduced the size of the CNN so that it had approximately the same degrees of freedom as sensing snapshots were used for training. The idea of this rule is that the CNN learns to extract and recognize more reliable features in the sensing snapshots and does not try to learn random processes like noise in the data. This shall lead to a better generalization of the CNN. The network structure of the reduced CNN is listed in Tab. III.\nThe learning rate of the reduced CNN was 0.001 and it was trained for 200 epochs. A batch size of 1024 was used.\nE. Implementation\nThe CNN was implemented, trained and validated on high end computation platform with the central processing unit (CPU) Intel XEON E5-1660 v3, 16 GBit RAM and the graphics processing unit (GPU) Nvidia GTX 960. The CNN implementation utilizes the abstract modular deep learning\nlibrary Keras [15] and the computation library Theano [16] as its backend.\nPerforming CNN’s training on the GPU results in a duration of approximately 74 s per epoch and therefore 501 ms per batch. For the reduced CNN the duration cuts down to approximately 3 s per epoch and therefore cuts down to 20 ms per batch."
    }, {
      "heading" : "V. RESULTS",
      "text" : "The accuracy of the CNN for the validation data is shown in Fig. 2. For the IEEE-802.11 b/g channels the accuracy is the worst. The IEEE-802.11 b/g signals have the biggest channel width and the most different modulations and bit rates. Therefore they are the most complex signals for the investigated classification problem.\nThe best accuracy is achieved for the different IEEE802.15.1 channels. The four classes RCHIEEE802.15.1 0, 3, 8 and 9 have a slightly worse accuracy then the other IEEE802.15.1 classes. The channels at the borders of the observed bandwidth, the classes RCHIEEE802.15.1 0 and 9, are deformed by the anti-aliasing filter and the channel bandwidth of the class RCHIEEE802.15.1 9 overlaps with the channel bandwidth of the class RCHIEEE802.15.4 1. The classes RCHIEEE802.15.1 3 and 8 have the same center frequency as the classes RCHIEEE802.15.4 0 and 1. This causes a slightly worse recognition rate by the CNN because there are less features to distinguish between these classes.\nThe accuracy for all SNRs is clearly better than the accuracy achieved by the CNN for modulation recognition used by O’Shea et al. [9]. There are two possible reasons for this result. The first possible reason is that the training and validation data was generated too synthetically and does not represent the real world effects well enough. The other possible reason which seems to be more likely is that a mainly frequency selective classification is much easier for a CNN to classify. Another hint which leads to this conclusion is that the CNN could be reduced significantly without a big loss of accuracy.\nThe significant reduction of the CNN points out that a frequency selective classification problem is less complex than a modulation selective classification which was investigated by O’Shea et al. [9]. Another proof for this assumption is the slightly worse recognition rate of the IEEE 802.15.1 signals which have the same center frequency as the IEEE 802.15.4 signals. If all signals that have to be classified use the same center frequency the accuracy will likely get worse as it is the case in the work of O’Shea et al.."
    }, {
      "heading" : "A. Comparison of CNN and NFSC",
      "text" : "The accuracy of the CNN was compared to the accuracy of the NFSC. Therefore, the filter and reference shape of the NFSC rectangles were used. The filter shape was twice as wide as the reference shape which had the channel bandwidth as width. Further, a threshold of 0.5 for the similarity was used. For fair comparison, the classification of IEEE-802.11 b/g complaint signals were ignored due to suboptimal performance for out-of-band signal identification.\nThe performance under such constraints of the NFSC in comparison with CNN is shown in Fig. 3. It is important to note, that the resulting classification accuracies are averaged for all utilized classes. For the applied validation data, the CNN outperforms the NFSC in terms of classification accuracy independent of SNRs. The CNN shows an average\nperformance gain and classification accuracy improvement of at least 5.32 dB and 8.19 %, respectively. Hence, the datadriven CNN approach is limited to sensing snapshots similar to the trained data, while the NFSC can be also utilized for real world scenarios. Nevertheless, CNN’s promising results should be investigated further."
    }, {
      "heading" : "B. Frequency- and Time-Domain Sensing Snapshots",
      "text" : "The CNN can either be trained with sensing snapshots in time- or in frequency domain. Hence, the training was also performed with same-sized time-equivalent with quadrature and imaginary components of the raw 128 IQ-Samples as 128× 2 input matrix.\nThe classification accuracy with both frequency- and timeDomain sensing snapshots as input are shown in Fig. 4 As expected the frequency-domain sensing snapshots outperform the time-equivalent because foremost the CNNs’s differentiation has to be frequency selective."
    }, {
      "heading" : "C. Reduced CNN",
      "text" : "The reduced CNN has over 99% reduced degrees of freedom compared to the big CNN and is therefore much faster. The accuracy of the training and validation data of both CNNs is shown in Fig. 5.\nAlthough the degrees of freedom for the small CNN were reduced significantly the accuracy of the validation data is similar. While for training the classification accuracy drops for the reduced CNN especially for low SNRs values, for validation the performance of both CNNs is comparable. The training performance difference shows that the original CNN memorizes the sensing snapshot pattern including noise while the reduced CNN generalizes much better."
    }, {
      "heading" : "VI. CONCLUSION",
      "text" : "The steadily growing use of license-free frequency bands requires reliable coexistence management and therefore proper wireless interference identification (WII).\nIn this work we propose the first WII approach based upon deep convolutional neural network (CNN). The CNN naively learns its features through self-optimization during an extensive data-driven training process. The design of the CNN was derived from the network of O’Shea et al. [9] for the related field of modulation recognition. Further, a network size reduction was performed by 99 % of the total degrees of freedom. During the training phase it showed better generalization.\nIn order to face realistic wireless device capabilities the CNN identifies time- and frequency-limited sensing snapshots with a duration of 12.8 µs and acquisition bandwidth of 10 MHz. Thereby, it differs between 15 classes, which represent allocated frequency channels of IEEE 802.15.4, IEEE 802.15.1, and partly in-band IEEE 802.11 b/g compliant packet transmissions. In total 151,200 sensing snapshots were used for training and 74,025 for validation containing 19 different variants of modulation types and symbol rates.\nFor implementation the Python library Keras in combination with Theano was utilized with a high level of abstraction. The GPU-based training speeds up the training duration to approximately 501 ms for the original and 20 ms for the reduced CNN per batch size of 1024.\nThe proposed CNN shows promising results with high classification accuracy for signals with low signal-to-noise ratio (SNR). In average, the accuracy exceeds 95 % for SNRs greater than -5 dB. The performance drops with wideband signals which are clipped by the limited acquisition bandwidth such as IEEE 802.11 b/g compliant packet transmissions. Secondly, it also shows minimal performance issues with transmission signals sharing the same center frequency such as the fourth IEEE 802.15.1 and first IEEE 802.15.4\nchannel. Nevertheless, the CNN outperforms state-of-the-art WII approaches such as neuro-fuzzy signal classifier (NFSC) [8] under similar constraints. Thereby, the CNN approach shows an average performance gain and classification accuracy improvement of at least 5.32 dB and 8.19 %, respectively.\nNevertheless, the prototype has to be enhanced and must be validated in the field to become a viable option as a classifier for coexistence management. Such an enhancement is a design of a CNN suitable for multi-label WII of concurrent transmissions in the same frequency range. Secondly, the training data has to be extended and diversified to get a better representation of channel and hardware impairments for the training data."
    } ],
    "references" : [ {
      "title" : "Multi-column deep neural networks for image classification",
      "author" : [ "D.C. Cireşan", "U. Meier", "J. Schmidhuber" ],
      "venue" : "CoRR, vol. abs/1202.2745, 2012.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "A. Krizhevsky", "I. Sutskever", "G. Hinton" ],
      "venue" : "Advances in Neural Information Processing Systems 25, F. Pereira, Burges, C. J. C., L. Bottou, and K. Q. Weinberger, Eds. Curran Associates, Inc, 2012, pp. 1097–1105. [Online]. Available: www.papers.nips.cc/paper/ 4824-imagenet-classification-with-deep-convolutional-neural-networks. pdf",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Network in network",
      "author" : [ "M. Lin", "Q. Chen", "S. Yan" ],
      "venue" : "CoRR, vol. abs/1312.4400, 2013.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Industrial communication networks – wireless communication networks – part 2: Coexistence management",
      "author" : [ "IEC" ],
      "venue" : "2013.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Compressed sensing for wideband cognitive radios",
      "author" : [ "Z. Tian", "G.B. Giannakis" ],
      "venue" : "2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP ’07, 2007, pp. 1357–1360.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Cognitive radios exploiting gray spaces via compressed sensing",
      "author" : [ "D. Wieruch", "P. Jung", "T. Wirth", "A. Dekorsy", "T. Haustein" ],
      "venue" : "Frequenz, vol. 70, no. 7-8, pp. 289–300, 2016.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Neuro-fuzzy signal classifier (NFSC) for standard wireless technologies",
      "author" : [ "K. Ahmad", "G. Shresta", "U. Meier", "H. Kwasnicka" ],
      "venue" : "2010 7th International Symposium on Wireless Communication Systems, Sept 2010, pp. 616–620.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Convolutional radio modulation recognition networks",
      "author" : [ "T.J. O’Shea", "J. Corgan", "T.C. Clancy" ],
      "venue" : "CoRR, vol. abs/1602.04105, 2016.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Gnuradio",
      "author" : [ "E. Blossom", "B. Hilburn", "J. Corgan", "GNU Project" ],
      "venue" : "2016. [Online]. Available: www.gnuradio.org/",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Transient-based identification of wireless sensor nodes",
      "author" : [ "B. Danev", "S. Capkun" ],
      "venue" : "IPSN, 2009.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "D.P. Kingma", "J. Ba" ],
      "venue" : "CoRR, vol. abs/1412.6980, 2014.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Keras: Deep learning library for theano and tensorflow",
      "author" : [ "F. Chollet" ],
      "venue" : "2015. [Online]. Available: www.github.com/fchollet/keras",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Theano: A Python framework for fast computation of mathematical expressions",
      "author" : [ "Theano Development Team" ],
      "venue" : "arXiv e-prints, vol. abs/1605.02688, May 2016. [Online]. Available: http://arxiv.org/abs/ 1605.02688",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Artificial neural networks and especially convolutional neural networks (CNNs) achieved excellent results for different benchmarks in recent years [1], [2], [3].",
      "startOffset" : 147,
      "endOffset" : 150
    }, {
      "referenceID" : 1,
      "context" : "Artificial neural networks and especially convolutional neural networks (CNNs) achieved excellent results for different benchmarks in recent years [1], [2], [3].",
      "startOffset" : 152,
      "endOffset" : 155
    }, {
      "referenceID" : 2,
      "context" : "Artificial neural networks and especially convolutional neural networks (CNNs) achieved excellent results for different benchmarks in recent years [1], [2], [3].",
      "startOffset" : 157,
      "endOffset" : 160
    }, {
      "referenceID" : 0,
      "context" : "[1] are comparable to human performance.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "Therefore, the norm IEC 62657-2 [5] for industrial radio communication systems recommends an active coexistence management for reliable medium utilization.",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 3,
      "context" : "[5] recommends (i) manual, (ii) automatic non-cooperative or (iii) automatic cooperative coexistence management.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "In [6], [7] it is also applied for classification ar X iv :1 70 3.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 5,
      "context" : "In [6], [7] it is also applied for classification ar X iv :1 70 3.",
      "startOffset" : 8,
      "endOffset" : 11
    }, {
      "referenceID" : 6,
      "context" : "The NFSC [8] is an expert system which classifies frequency bands with respect to known wireless technologies.",
      "startOffset" : 9,
      "endOffset" : 12
    }, {
      "referenceID" : 7,
      "context" : "[9] compared the performance of different classifiers for classifying 11 modulations, 8 digital and 3 analog modulations.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "used GNU Radio [10] a toolkit for software defined radios.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 9,
      "context" : "[13] showed for emission-based wireless device identification that frequency-based features outperform their time-based equivalents.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 7,
      "context" : "[9] as listed in Tab.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 10,
      "context" : "For the training process the Adam optimizer [14] was used and the input data was normalized.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 7,
      "context" : "[9] we then reduced the size of the CNN so that it had approximately the same degrees of freedom as sensing snapshots were used for training.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 11,
      "context" : "The CNN implementation utilizes the abstract modular deep learning library Keras [15] and the computation library Theano [16] as its backend.",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 12,
      "context" : "The CNN implementation utilizes the abstract modular deep learning library Keras [15] and the computation library Theano [16] as its backend.",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 7,
      "context" : "[9].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[9].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[9] for the related field of modulation recognition.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "Nevertheless, the CNN outperforms state-of-the-art WII approaches such as neuro-fuzzy signal classifier (NFSC) [8] under similar constraints.",
      "startOffset" : 111,
      "endOffset" : 114
    } ],
    "year" : 2017,
    "abstractText" : "The steadily growing use of license-free frequency bands requires reliable coexistence management for deterministic medium utilization. For interference mitigation, proper wireless interference identification (WII) is essential. In this work we propose the first WII approach based upon deep convolutional neural networks (CNNs). The CNN naively learns its features through self-optimization during an extensive data-driven GPU-based training process. We propose a CNN example which is based upon sensing snapshots with a limited duration of 12.8 μs and an acquisition bandwidth of 10 MHz. The CNN differs between 15 classes. They represent packet transmissions of IEEE 802.11 b/g, IEEE 802.15.4 and IEEE 802.15.1 with overlapping frequency channels within the 2.4 GHz ISM band. We show that the CNN outperforms state-ofthe-art WII approaches and has a classification accuracy greater than 95 % for signal-to-noise ratio of at least -5 dB.",
    "creator" : "LaTeX with hyperref package"
  }
}