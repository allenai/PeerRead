{
  "name" : "1511.06426.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "moontae@cs.cornell.edu", "xiaohe@microsoft.com", "scottyih@microsoft.com", "jfgao@microsoft.com", "deng@microsoft.com", "smolensky@jhu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n51 1.\n06 42\n6v 4\n[ cs"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "Ideal machine learning systems should be capable not only of learning rules automatically from training data, but also of transparently incorporating existing principles. While an end-to-end framework is suitable for learning without human intervention, existing human knowledge is often valuable in leveraging data toward better generalization to novel input. Question answering (QA) is one of the ultimate tasks in Natural Language Processing (NLP) on which synergy between the two capabilities could enable better understanding and reasoning.\nRecently the Facebook bAbI tasks were introduced to evaluate complex reading comprehension via QA (Weston et al. (2015)); these have received considerable attention. Understanding natural questions, for example in WebQuestions tasks (Berant et al. (2013)), requires significant comprehension of the semantics, yet reasoning out the answers is then relatively simple (e.g., Bordes et al. (2014);\n∗This research was conducted while the first author held a summer internship in Microsoft Research, Redmond, and the last author was a Visiting Researcher there.\nYih et al. (2015)). In contrast, the synthetic questions in bAbI require rather complex reasoning over multiple computational steps while demanding only minimal semantic understanding. As the previous work on bAbI consists only of end-to-end models (Weston et al. (2014); Kumar et al. (2015); Sukhbaatar et al. (2015); Peng et al. (2015)), it is unclear whether incorrect answers arise from an imperfect semantic understanding, inadequate knowledge encoding, or insufficient model capacity (Dupoux (2015)). This is partly because the current paradigms based on neural networks have no interpretable intermediate representations which modelers can use to assess the knowledge present in the vectorial encoding of the system’s understanding of the input sentences. Our approach, in contrast, can illuminate what knowledge is caputred in each representation via the formalism of TPR.\nTensor Product Representation (TPR), proposed by Smolensky (1990); Smolensky & Legendre (2006), is a mathematical method to represent complex structures from basic vectorial building blocks, so called fillers and roles. For example, one can encode a binary tree by binding filler vectors corresponding to the left- and right-child entities to role vectors corresponding to the ‘left child’ and ‘right child’ positions, respectively. Arbitrary trees can be represented by recursively applying the same method. As an outer product (i.e., tensor product) realizes the binding operation, both filler and role components are decodable from the resulting representation via the inner product; this is called unbinding. TPR is known to be capable of various applications such as tree operations, grammar processing and lambda-calculus evaluation (Smolensky (2012)).\nIn this paper, we endeavor to disentangle the problem cleanly into semantic parsing, knowledge encoding, and logical reasoning. Proposing two vector-space models inspired by TPR, we first provide an in-depth analysis of the bAbI dataset by clustering, based solely on their logical properties, the twenty question categories defined by bAbI. Such analysis enables us to conjecture why most existing models, in spite of their complexity, have failed to achieve good accuracy on positional reasoning and path finding tasks, whereas Peng et al. (2015) achieved successful results. If the bAbI tasks turn out to be considerably simpler than intended for its ultimate purpose of providing a major step towards “AI-complete question answering”, then more elaborated tasks will be required to test the power of proposed QA models such as memory networks.\nAs a further contribution, we also develop the foundation of a theory that maps inference for logical reasoning to computation over TPRs, generalizing our models under the rigorous TPR formalism. Due to the page limit, this theoretical foundation is relegated to the supplementary materials (Smolensky et al. (2016)). The experimental results show that accurate inference based on common-sense knowledge is transparently attainable in this formalism. We hope our exploration can contribute to the further improvement of end-to-end models toward the transparency and interpretability. To the best of our knowledge, our in-depth analysis of bAbI and of logical reasoning over distributed vectorial representations are each the first of their kind."
    }, {
      "heading" : "2 RELATED WORK",
      "text" : "Since the seminal work of Bengio et al. (2003), researchers have paid increasing attention to various distributed representations in continuous vector spaces. In the computer science literature, Skipgram/CBoW (Mikolov et al. (2013)) and GloVe (Pennington et al. (2014)) are popular models that are trained based on the distributional similarities in word co-occurrence patterns; they have been frequently utilized as initial embeddings for a variety of other NLP tasks. In the cognitive science literature, on the other hand, BEAGLE (Jones & Mewhort (2007)) and DVRS (Ustun et al. (2014)) are trained differently, with random initializations and circular convolution. They assign two vectors for each word: an environmental vector to describe physical properties and a lexical vector to indicate meaning.\nWhereas such representations are known to provide a useful way to incorporate prior linguistic knowledge, their usefulness is not clear for reasoning-oriented tasks. In other contexts, Grefenstette (2013) shows how to simulate predicate logic with matrices and tensors. Similarly, Rocktaschel et al. (2014) try to find low-dimensional embeddings which can model first-order logic in a vectorial manner. These models are only concentrated on general logic problems without considering NLP tasks. Note that vectorial encodings are necessary in many machine learning models such as neural networks. Reasoning based on linguistic cues in vector space uniquely characterizes our paper among these relevant work.\nThe tasks in bAbI have been studied mainly within the context of the Memory Network (MemNN) model, which consists of an array of representations called “memory” and four learnable modules: the I-module encodes the input into feature representation, the G-module updates relevant memory slots, the O-module performs inferences to compute output features given the input representation and the current memory, and finally the R-module decodes the output feature-based representation to the final response. Since the proposal of the basic MemNN (Weston et al. (2014)) model, the Adaptive/Nonlinear MemNN (Weston et al. (2015)), DMN (Kumar et al. (2015)), and MemN2N (Sukhbaatar et al. (2015)) models have been developed by varying certain parts of these modules. Nonetheless, none of these models except Peng et al. (2015) successfully accomplish either positional reasoning or path finding tasks. Our speculation about the performance by Peng et al. (2015) will be given in a later section based on our bAbI analysis."
    }, {
      "heading" : "3 MODELS AND ANALYSIS",
      "text" : "The bAbI dataset consists of twenty different types of questions where each question category is claimed to be atomic and independent from the others (Weston et al. (2015)). In this section, we investigate clusters of categories with sample QA problems, analyzing what kinds of logical properties are shared across various types. We also elucidate, based on our vector space models, why it is difficult to achieve good accuracy on certain categories: positional reasoning and path finding."
    }, {
      "heading" : "3.1 CONTAINEE-CONTAINER RELATIONSHIP",
      "text" : "Supporting Facts (1, 2, 3) The first three question categories of bAbI ask for the current or previous locations of actors and objects based on the statements given prior to the question. Category 1–3 questions respectively require precisely one, two, or three supporting facts to reason out the proper answers. Figure 1 illustrates sample statements and questions extracted from real examples in the training set. Reasoning in Category 1 implicitly requires a simple common-sense reasoning rule that “An actor cannot exist in two different locations at the same time.” In order to answer the questions in Category 2, we implicitly need another rule that “An object that belongs to an actor follows its owner’s location.” Further, if an item is dropped at one particular location, it will permanently stay in that location until someone grabs it and moves around with it later.\nWhile two independent relations, pick/drop and move, seem to be involved in parallel in the Category 2 tasks, these questions can be all uniformly answered under the transitivity of a containee belongs to a container. If an actor moves to a location, he/she (a containee) now belongs to that location\n(a container). Similarly, if an actor acquires an object, the item (a containee) newly belongs to that actor (a container). Transitivity then logically implies that the object belongs to the location occupied by the owner.\nKnowing that every actor and object is unique without any ambiguity, one can encode such containee-conatainer relationships by the following model using distributed representations. Assume all entities: actors, objects, and locations are represented by d-dimensional unit vectors in R\nd.1 Then each statement is encoded by a second-order tensor (or matrix) in which the containee vector is bound to the container vector via the fundamental binding operation of TPR, the tensor (or outer) product2 — in tensor notation, (containee) ⊗ (container), or in matrix notation, (containee)(container)T — and then stored in a slot in a memory. When an item is dropped, we perform an inference to store the appropriate knowledge in memory. For the example in Table 1, the container of the football at Statement 9 — the garden — is determined after figuring out the most recent owner of the football, Mary; transitivity is implemented through simple matrix multiplication of the encodings of Statement 3 (locating the football) and Statement 4 (locating the football’s current owner, Mary):\n(fmT ) · (mgT ) = f(mT ·m)gT = fgT (∵ mTm = ||m||2 2 = 1)\nFinally, Category 3 asks the trajectory of items considering the previous locations of actors. Thus the overall task is to understand the relocation sequence of each actor and from this to reconstruct the trajectory of item locations. Whereas MemNNs introduced an additional vector for each statement for encoding a time stamp, we define another binding operation ◦ : Rd × Rd −→ Rd. This binding operation maps a pair of (next, prev) location vectors into a d-dimensional vector via a d × 2d temporal encoding matrix U like the following:\nn ◦ p = U\n[\nn p\n]\n∈ Rd.\nIn Table 1, the second expression in the Encodings column specifies temporal encodings that identify location transitions: Statement 4, translated as Mary belongs to the garden (from the kitchen), is encoded as m(g ◦k)T . We can now reason to the proper answers for the questions in Figure 1 by the following inference steps, using basic encodings (for C1 & C2) and temporal encodings (for C3):\nC1. Where is Mary?\n(a) Left-multiply by mT all statements prior to time 3. (Yields m ·mT bT , mT · jhT .) (b) Pick the most recent container where 2-norms of the multiplications in (a) are approximately\n1.0. (Yields bT ; mT j is small.) (c) Answer by finding the location corresponding to the result representation. ⇒ bathroom\nC2. Where is the football?\n1Topologically speaking, the unit hypersphere can be constructed by adding one more point (“at infinity”) to Euclidean space. Thus sampling from the hypersphere does not limit the generality of representations.\n2In TPR terms, the containee corresponds to a filler, and the container corresponds to a role.\n(a) Left-multiply by fT all statements prior to the current time. (Yields fT · mkT , fT · soT , fT · fmT , fT ·mgT .)\n(b) Pick the most recent container where 2-norms of the multiplications in (a) are approximately 1.0. (Yields mT .)\n(c) If the container is an actor (e.g., Mary in statement 3), • Find the most recent container of the actor by left-multiplying by mT (Yields gT .) • Answer by the most recent container. ⇒ garden for the questions at time 5 and 8.\n(d) If the container is a location (e.g., garden in statement 9), simply answer by the container.\nC3. Where was the apple before the hallway?\n(a) Left-multiply by aT all existing temporal encodings prior to time 7. (Yields aT ·s(h ◦ n)T , aT · adT , ... .)\n(b) Pick the earliest container (the start of the trajectory). ⇒ Daniel in statement 2. (c) Find the containers of Daniel by left-multiplying by dT the temporal encodings between\ntime 2 and 7. (Yields dT · adT , dT · j(k ◦ n)T , dT · d(b ◦ n)T , dT · fdT , dT · d(h ◦ b), ... .) (d) By multiplying by the pseudo-inverse U †, unbind 2d-dimensional vectors between time 4\nand 7. (Yields U †(b ◦ n) ≈ [b;n], then [h; b].) (e) Reconstruct the item trajectory in sequence. ⇒ nowhere → bedroom → hallway (f) Answer with (the most recent) location which is prior to the hallway. ⇒ bedroom\nThree Argument Relations (5) In this category, there is a new type of statement which specifies ownership transfer: an actor gives an object to another actor. Since now some relations involve three arguments, (source-actor, object, target-actor), we need to encode an ownership trajectory instead of a location trajectory.\nAnalogously to the ◦ operation used for Category 3, we realize the ∗ operation by defining a map ∗ : Rd × Rd −→ Rd. This new binding operation maps a pair of (next, prev) owner vectors into a d-dimensional vector via a d× 2d matrix V in the exactly same fashion: n ∗ p = V [n; p] ∈ Rd. Due to the similarity in encoding, the inference is also analogous to the inference for Category 3.\nC5. Three questions of Table 2?\n(a) Find the owners of the milk by left-multiplying by mT the encodings prior to time 3. (b) Unbind the owner transitions by multiplying them by the pseudo-inverse V †. (c) Reconstruct the ownership trajectory for the milk. ⇒ Nobody → Jeff → Bill (d) Answer accordingly each question based on the trajectory.\nThough no more complex examples or distinct categories exist in the dataset, it is clear that our encoding scheme is capable of inferring the full trajectory of item location considering both relocation of actors and transfers of ownership. In such cases, both ◦ and ∗ will be used at the same time in\n3To avoid notational confusion, we modify the name of an actor (from Mary to Daniel) and a location (from the bathroom to the office) from the real example in Category 5.\nencoding. (e.g., encoding for time 5 will be then d(h ◦ o)T . Note also that there may be multiple transfers between the same pair of actors in a history prior to the given question. While any of them could be appropriate evidence to justify different answers, the ground-truth answers in the training set turned out to be all based on the most recent clues.\nAnswer Variations (6, 7, 8, 9) As shown in Figure 2, the responses to questions of Categories 6-9 require different measures of the inferred element. For example, the statements in Category 6 are structurally equivalent to the statements in Category 2, while the questions concern only a current location, similar to Category 1. However, each question is formulated in a binary yes/no format, confirming “Is Daniel in the hallway?” instead of asking “Where is Daniel?”. Category 7 is isomorphic to Category 5 in the sense that actors can pick up, drop, and pass objects to other actors. However, each question inquires the number of objects currently belonging to the given actor. On the other hand, a response in Category 8 must give the actual names of objects instead of counting their number. The statements in this category are based not on Category 5, but on Category 2 which is simpler due to the lack of ownership transfer. Lastly, statements in Category 9 can contain a negative quantifier such as ‘no’ or ‘no longer’. Responses confirm or not the location of actors via yes/no dichotomy as for Category 6. However, the overall story is based on the simplest Category 1.\nSince answer measures are the only differences of these categories from Category 1, 2, 3, and 5, no additional encodings or inferences are necessary. However, there are several caveats in formulating actual answers: 1) For yes/no questions, we should know the answers must be either yes or no in advance based on the training examples. 2) When counting the number of belongings, the answer must use English number words rather than Arabic numerals. 3) When enumerating the names of belongings, names must be sequenced by their order of acquisition. 4) A negative quantifier is realized by binding the initial default location nowhere back to the given actor. Note that there is no double negation.\nStatement Variations (10, 11, 12, 13) Statements in Categories 10-13 contain more challenging linguistic elements such as conjunctions (and/or) or pronouns (he/she/they). While statements in Category 10 is structurally similar to Category 1’s, an actor can be located in either one or another location. Due to such uncertainty, some questions must be answered indefinitely by ‘maybe’. On the other hand, each statement in Category 12 can contain multiple actors conjoined by ‘and’ to indicate that these actors all carry out the action. Aside from such conjunctions, statements and questions are isomorphic to Category 1’s. Statements in Categories 11/13 can consist of a singular/plural pronoun to indicate single/multiple actors mentioned earlier. Since coreference resolution is itself a\ndifficult problem, all pronouns are limited to refer only to actors mentioned in the immediately prior statement.\nTo encode conjunctions, we can still leverage the same method: conjoin two objects by another bilinear binding operation ⋆ : Rd × Rd −→ Rd, and unbind similarly via the pseudo-inverse of the corresponding matrix. In our implementation, every statement is encoded using such a binding operation. For instance, the first two statements of the given Category 10 example are encoded into j(k ⋆ k)T and b(s ⋆ o)T , with ⋆ encoding or. If two locations unbound from the target actor are identical, we output a yes/no definite answer, whereas two different locations imply the indefinite answer ‘maybe’ if one of the unbound locations matches the queried location. For the conjunction and in Category 12, exactly the same formalism is applicable for conjoining actors instead. Whereas a singular pronoun appearing at time t in Category 11 is simply replaced by the actor mentioned at time t − 1, we also use ⋆-binding to provide the multiple coreference needed for Category 13. For instance, the first statement in the given Category 13 example is encoded as (m⋆d)bT and the same encoding is substituted for ‘they’ to represent the actors in the following statement.\nDeduction/Induction (15, 16, 18, 20) While the statements and questions in these categories seem different at first glance, their goals are all to reason using a transitivity-like rule. Categories 15 creates a food chain among various animals, and Category 18 yields a partial/total order of sizes among various objects. Whereas inference in these two categories is deductive, Categories 16 and 20 require inductive inference. In all four categories, every statement is easily represented by a containee-container relation obeying transitivity. For instance, the Category 15 example of Figure 4 is encoded by {mcT , wmT , csT , swT }. Then the answer for the first question: “What is Jessica afraid of?” will be answered by left-multiplying these by the transpose of j = m and finding the one whose norm is approximately 1.0, which is mcT . Thus the result jT · (mcT ) = mT (mcT ) = (mTm)cT = cT produces the desired answer cat. Similarly, in Category 18, if question encoding (e.g., “Does the chocolate fit in the box?” = cbT ) is achievable by some inner products of statement encodings, the answer must be ‘yes’, otherwise, ‘no’.\nOn the other hand, in Category 16, transitivity is applied reversely as a container-containee fashion. For instance, “Lily is a ℓion” is encoded by ℓlT , whereas “Lily is green” is encoded by lgT . In encoding “x is-a Y”, we put the more general concept at the left side of the outer-product binding Y xT ; to encode “x has-property Z” we use xZT . This allows us to induce a property for the general category Y based on the single observation of one of its members, via simple matrix multiplication, just as transitive inference was implemented above: (ℓlT ) · (lgT ) = ℓgT , meaning “ℓion is green.” Similarly in Category 20, there exists precisely one statement which describes a property of an actor (e.g., “Sumit is bored.” = bsT ). Then a statement describes the actor’s relocation (e.g., “Sumit journeyed to the garden.” = sgT ), yielding an inductive conclusion by matrix multiplication: “Being boring makes people go to the garden.” = (bsT ) · (sgT ) = bgT . The inductive reasoning also generalizes to other actions (e.g., the reason for later activity, “Sumit grabbed the football.” = sfT , is also being bored, because (bsT ) · (sfT ) = bfT ).\nPrior Knowledge (4, 14) Though statements in Category 4 looks quite dissimilar from those in the other categories, they can be eventually modeled by a uni-relational reasoning chain based on the containee-container relation, provided we know that ‘north’ and ‘south’ are opposite to each other. Thus the first two statements in the first Category 4 example in Figure 6 yield {koT , gkT}, from which we infer (gkT ) · (koT ) = goT “The office is north of the garden.” While the questions are all simple knowledge confirmation, note that a relational word (e.g., ‘east’) might never appear in the prior statements, as illustrated in the second example of Category 4 in Figure 6. However the most important point is that two non-collinear relations (e.g., ‘north’, ‘east’) never appear together in the same example.\nOn the other hand, statements in Category 14 are no longer chronologically ordered. In order to infer a correct locational trajectory without repeating statements multiple times, we predefine four vectors for each time stamp: yesterday, this morning, this afternoon, and this evening, and bind location with the corresponding stamp instead of the previous location. For example, the encoding for the statement at time 2 now becomes j(b ◦m)T instead of j(b ◦ p)T . Knowing the correct order of these four time stamps, which could be learned from the training examples, we can easily reorder by unbinding time stamps."
    }, {
      "heading" : "3.2 MULTIPLE RELATIONSHIPS",
      "text" : "Path Finding (19) Our goal in this category is to find the path from one location to another location in a Manhattan-grid-like sense. Note that if A is north of B, and B is north of C, then the right path from A to C in grid must be ‘north, north’ rather than simply ’north’. We assume given four d× d non-singular matrices N,E,W, S encoding four different directions satisfying N = S−1 and E = W−1. Then\nAfter initializing the first object in the right-hand side (e.g., ‘hallway’) by a random vector, we decide the rest of the object vectors in sequence by multiplying the directional matrix (or its inverse in case that the right-hand side is unknown and the left-hand side is known). In case that both sides are unknown, we defer such a statement by putting it into a queue. In fact, the solution path X can be determined either by selecting, of all combinations of two directions {NN, NE, NW, NS, ... SN, SE, SW, SS}, the one which best satisfies b = Xg (in the example of Table 3) or by solving this equation based on iterative substitutions. Note also that we need to know that (n, e, w, s) in the answers correspond to (north, east, west, south), respectively, which could be learned from training data.\nPositional Reasoning (17) While this category could be seen similar to Path Finding, each question only asks a relative position between two objects. For instance, if “r is below s”, and “b is below r”, then the position of b with respect to s must be simply ‘below’ rather than ‘below, below’. Even if an object is mentioned to be left of another object, it could be also located in left-above or leftbelow of another object. Due to these subtleties, we here adopt redundant representations with four d × d singular matrices (A,B,L,R) corresponding to four directions: (above, below, left, right).\nFor this directional subsumption, in contrast to the non-singularity of the directional matrices for Category 19, we now strictly enforce idempotency to these matrices (i.e., An = ... = A2 = A 6= I). Then we define the following four 4d × 4d block matrices and encode each statement with these matrices in the same manner as for Category 19.\nA =\n\n\n A 0 0 0 0 I 0 0 0 0 I 0 0 0 0 I\n\n  B =\n\n\n I 0 0 0 0 B 0 0 0 0 I 0 0 0 0 I\n\n  L =\n\n\n I 0 0 0 0 I 0 0 0 0 L 0 0 0 0 I\n\n  R =\n\n\n I 0 0 0 0 I 0 0 0 0 I 0 0 0 0 R\n\n\n\nIn this encoding, each of the four d-dimensional subspaces of R4d plays a role of indicating relative positions with respect to (above, below, left, right), independently. Carrying out the encoding of “r is below s”, r = Bs, ensures that the components of r and s differ only in the dimensions from (d + 1) to 2d (from the B block of B); that is, rk = sk for k = 1, 3, 4 (where si indicates the i-th d-dimensional sub-block of s). This is actually inconsistent with the encoding of “s is above r”, which demands that s and r differ only in their first sub-block. Thus in order to determine whether or not s is indeed above r, it is necessary to check whether r2 = Bs2 as well as whether s1 = Ar1. If either condition is satisfied, we can confirm ‘s is above to r’ . Similarly, horizontal relations must be checked on both the third and fourth d-dimensional sub-blocks."
    }, {
      "heading" : "4 EXPERIMENTAL RESULTS",
      "text" : "We implement our models and algorithms under the analysis given in the previous section. Due to the small vocabulary (mostly less than or equal to four elements among actors, objects, locations, and actions) and non-ambiguous grammars, a simple dependency parser4 and basic named entity recognition enable us to achieve 100% accurate semantic parsing. Then we translate every statement into a representation based on the appropriate containee-container or multiway relation, and then store it in an array of memory slots. The logical reasoning after semantic parsing and knowledge representation no longer refers to the original text symbols.\nIn contrast to all previous models reported in Table 4, in Table 5 we also report test accuracy on the training data to measure how well our models incorporate common sense. Note that testing on the training data is available because our training procedure only parses the appropriate semantic components such as actors, objects, locations, actions, and the forms of answers without using given answers and clues for tuning the model parameters.\nNote that the imperfect accuracy in Category 16 is due to the ambiguity of evidence. As given in Figure 4, one can answer the color of Brian as ‘yellow’ because the latest evidence tells Julius who is a lion is yellow. Similarly, in Category 5, the 8th story consists of incorrect/inconsistent answers at time 14 and 17 (for training), as they ignore the most recent ownership transfers and choose some old history as ground-truth answers. (The 63rd and 186th stories in the test data also consist of incorrect answers, at time 27 and 22, respectively) Other than these two categories, we achieve perfect accuracies performing common-sense operations only on representations in memory.\n4We use Stanford Dependency Parser. http://nlp.stanford.edu/software/stanford-dependencies.shtml\nAs the experimental results show, there is a clear distinction between two sets of tasks. Tasks in most categories can be modeled by a containee-container-like relationship respecting a transitivitylike inference rule, whose goals are to create a linear/circular chain. On the other hand, positional reasoning and path finding require multiple relationships where each corresponding pair (e.g., north vs. south) has its own transitivity structure, operating independently of other pairs (e.g. east vs. west). We hypothesize that this difference poses a major difficulty for most of Memory Network models to perform an accurate inference for positional reasoning and path finding.\nRecently, Neural Reasoner (NR) by Peng et al. (2015) improves the accuracy for these two difficult categories by a large margin, achieving 97.9% and 87.0% when using 10k training set. 5 Different from other memory network models, NR has multiple reasoning layers. Starting from the initial statements and questions, NR constructs new statements and questions at the next layer, and repeats this process recursively over multiple layers. As both positional reasoning and path finding require generating inferences from, and new versions of, relevant statements for each relationship (e.g., “x is north of ” can become “y is south of x”), the abilities to generate new facts and to derive final answers by integrating them from multiple relationships could be a key reason why NR is successful, like our TPR-based reasoner. While NR in experiment is simplified so that all new facts maintain the same initial representations, the question representation changes for each layer considering all existing facts and the previously evolved question. Due to the simplicity of the task, we conjecture that evolving representations of the question could be sufficient to comprise the key ingredient for each multi-relationship. However, it seems that training such multiple layers requires a large amount of training data, yielding drastically different performance of NR on two different dataset sizes."
    }, {
      "heading" : "5 CONCLUSION",
      "text" : "The major contributions of this paper are two-fold. First, we throughly analyze the recently acclaimed bAbI question-answering tasks by grouping the twenty categories based on their relational properties. Our analysis reveals that most categories except positional reasoning and path finding are governed by uni-relational characteristics. As these turn out to support inference in a similar manner under transitivity, it could be dangerous to evaluate the capacity of network models based only on their performance on bAbI. In contrast, two more difficult categories require the capability of performing multi-relational reasoning, a capability which is apparently missing in most previous models. One could later develop a more sophisticated dataset that needs substantially harder reasoning by introducing multiple relationships. Second, we propose two vector space models which can perform logistic reasoning for QA with distributed representations. While TPR has been used for various problems such as tree/grammar encoding and lambda-calculus evaluation, logical reasoning is a new area of application that requires iterative processing of TPRs. In subsequent work, we will generalize the vector-space approach for multi-relational problems. We hope these studies shed light on the viability of developing further reasoning models which can perform inference with existing knowledge in an interpretable and transparent manner.\n55 All accuracy values of various models reported in the experimental section of the present paper are based on a 1k training set. Neural Reasoner achieves 66.4% and 17.3% when using the 1k dataset."
    } ],
    "references" : [ {
      "title" : "A neural probabilistic language model",
      "author" : [ "Bengio", "Yoshua", "Ducharme", "Rejean", "Vincent", "Pascal", "Janvin", "Christian" ],
      "venue" : "JMLR, 3:1137–1155,",
      "citeRegEx" : "Bengio et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2003
    }, {
      "title" : "Semantic parsing on Freebase from questionanswer pairs",
      "author" : [ "Berant", "Jonathan", "Chou", "Andrew", "Frostig", "Roy", "Liang", "Percy" ],
      "venue" : "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Berant et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Berant et al\\.",
      "year" : 2013
    }, {
      "title" : "Question answering with subgraph embeddings",
      "author" : [ "Bordes", "Antoine", "Chopra", "Sumit", "Weston", "Jason" ],
      "venue" : "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Bordes et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bordes et al\\.",
      "year" : 2014
    }, {
      "title" : "Deconstructing ai-complete question-answering: going beyond toy tasks",
      "author" : [ "Dupoux", "Emmanuel" ],
      "venue" : null,
      "citeRegEx" : "Dupoux and Emmanuel.,? \\Q2015\\E",
      "shortCiteRegEx" : "Dupoux and Emmanuel.",
      "year" : 2015
    }, {
      "title" : "Towards a formal distributional semantics: Simulating logical calculi with tensors",
      "author" : [ "Grefenstette", "Edward" ],
      "venue" : "Association for Computational Linguistics,",
      "citeRegEx" : "Grefenstette and Edward.,? \\Q2013\\E",
      "shortCiteRegEx" : "Grefenstette and Edward.",
      "year" : 2013
    }, {
      "title" : "Representing word meaning and order information in a composite holographic lexicon",
      "author" : [ "Jones", "Michael N", "Mewhort", "Douglas J. K" ],
      "venue" : "Psychological Review,",
      "citeRegEx" : "Jones et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Jones et al\\.",
      "year" : 2007
    }, {
      "title" : "Ask me anything: Dynamic memory networks for natural language processing",
      "author" : [ "Kumar", "Ankit", "Irsoy", "Ozan", "Su", "Jonathan", "Bradbury", "James", "English", "Robert", "Pierce", "Brian", "Ondruska", "Peter", "Gulrajani", "Ishaan", "Socher", "Richard" ],
      "venue" : "CoRR, abs/1506.07285,",
      "citeRegEx" : "Kumar et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kumar et al\\.",
      "year" : 2015
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Mikolov", "Tomas", "Sutskever", "Ilya", "Chen", "Kai", "Corrado", "Greg S", "Dean", "Jeff" ],
      "venue" : null,
      "citeRegEx" : "Mikolov et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Towards neural network-based reasoning",
      "author" : [ "Peng", "Baolin", "Lu", "Zhengdong", "Li", "Hang", "Wong", "Kam-Fai" ],
      "venue" : "CoRR, abs/1508.05508,",
      "citeRegEx" : "Peng et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2015
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Pennington", "Jeffrey", "Socher", "Richard", "Manning", "Christopher D" ],
      "venue" : "pp. 1532–1543,",
      "citeRegEx" : "Pennington et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Low-dimensional embeddings of logic",
      "author" : [ "Rocktaschel", "Tim", "Singh", "Sameer", "Bosnjak", "Matko", "Riedel", "Sebastian" ],
      "venue" : null,
      "citeRegEx" : "Rocktaschel et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Rocktaschel et al\\.",
      "year" : 2014
    }, {
      "title" : "Tensor product variable binding and the representation of symbolic structures in connectionist systems",
      "author" : [ "Smolensky", "Paul" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Smolensky and Paul.,? \\Q1990\\E",
      "shortCiteRegEx" : "Smolensky and Paul.",
      "year" : 1990
    }, {
      "title" : "Symbolic functions from neural computation",
      "author" : [ "Smolensky", "Paul" ],
      "venue" : "Philosophical Transactions of the Royal Society,",
      "citeRegEx" : "Smolensky and Paul.,? \\Q2012\\E",
      "shortCiteRegEx" : "Smolensky and Paul.",
      "year" : 2012
    }, {
      "title" : "The Harmonic Mind: From Neural Computation to OptimalityTheoretic GrammarVolume I: Cognitive Architecture",
      "author" : [ "Smolensky", "Paul", "Legendre", "Geraldine" ],
      "venue" : null,
      "citeRegEx" : "Smolensky et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Smolensky et al\\.",
      "year" : 2006
    }, {
      "title" : "Basic reasoning with tensor product representations",
      "author" : [ "Smolensky", "Paul", "Lee", "Moontae", "He", "Xiaodong", "Yih", "Wen-tau", "Gao", "Jianfeng", "Deng", "Li" ],
      "venue" : "Technical Report, Microsoft Research,",
      "citeRegEx" : "Smolensky et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Smolensky et al\\.",
      "year" : 2016
    }, {
      "title" : "End-to-end memory networks",
      "author" : [ "Sukhbaatar", "Sainbayar", "Szlam", "Arthur", "Weston", "Jason", "Fergus", "Rob" ],
      "venue" : "CoRR, abs/1503.08895,",
      "citeRegEx" : "Sukhbaatar et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sukhbaatar et al\\.",
      "year" : 2015
    }, {
      "title" : "Distributed vector representations of words in the sigma cognitive architecture",
      "author" : [ "Ustun", "Volkan", "Rosenbloom", "Paul S", "Sagae", "Kenji", "Demski", "Abram" ],
      "venue" : null,
      "citeRegEx" : "Ustun et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Ustun et al\\.",
      "year" : 2014
    }, {
      "title" : "Towards ai-complete question answering: A set of prerequisite toy tasks. volume abs/1502.05698",
      "author" : [ "Weston", "Jason", "Bordes", "Antoine", "Chopra", "Sumit", "Mikolov", "Tomas", "Rush", "Alexander M", "van Merrienboer", "Bart" ],
      "venue" : null,
      "citeRegEx" : "Weston et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Weston et al\\.",
      "year" : 2015
    }, {
      "title" : "Semantic parsing via staged query graph generation: Question answering with knowledge",
      "author" : [ "Yih", "Wen-Tau", "Chang", "MingWei", "He", "Xiaodong", "Gao", "Jianfeng" ],
      "venue" : null,
      "citeRegEx" : "Yih et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Yih et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "Recently the Facebook bAbI tasks were introduced to evaluate complex reading comprehension via QA (Weston et al. (2015)); these have received considerable attention.",
      "startOffset" : 99,
      "endOffset" : 120
    }, {
      "referenceID" : 1,
      "context" : "Understanding natural questions, for example in WebQuestions tasks (Berant et al. (2013)), requires significant comprehension of the semantics, yet reasoning out the answers is then relatively simple (e.",
      "startOffset" : 68,
      "endOffset" : 89
    }, {
      "referenceID" : 1,
      "context" : "Understanding natural questions, for example in WebQuestions tasks (Berant et al. (2013)), requires significant comprehension of the semantics, yet reasoning out the answers is then relatively simple (e.g., Bordes et al. (2014);",
      "startOffset" : 68,
      "endOffset" : 228
    }, {
      "referenceID" : 14,
      "context" : "As the previous work on bAbI consists only of end-to-end models (Weston et al. (2014); Kumar et al.",
      "startOffset" : 65,
      "endOffset" : 86
    }, {
      "referenceID" : 6,
      "context" : "(2014); Kumar et al. (2015); Sukhbaatar et al.",
      "startOffset" : 8,
      "endOffset" : 28
    }, {
      "referenceID" : 6,
      "context" : "(2014); Kumar et al. (2015); Sukhbaatar et al. (2015); Peng et al.",
      "startOffset" : 8,
      "endOffset" : 54
    }, {
      "referenceID" : 6,
      "context" : "(2014); Kumar et al. (2015); Sukhbaatar et al. (2015); Peng et al. (2015)), it is unclear whether incorrect answers arise from an imperfect semantic understanding, inadequate knowledge encoding, or insufficient model capacity (Dupoux (2015)).",
      "startOffset" : 8,
      "endOffset" : 74
    }, {
      "referenceID" : 6,
      "context" : "(2014); Kumar et al. (2015); Sukhbaatar et al. (2015); Peng et al. (2015)), it is unclear whether incorrect answers arise from an imperfect semantic understanding, inadequate knowledge encoding, or insufficient model capacity (Dupoux (2015)).",
      "startOffset" : 8,
      "endOffset" : 241
    }, {
      "referenceID" : 8,
      "context" : "Such analysis enables us to conjecture why most existing models, in spite of their complexity, have failed to achieve good accuracy on positional reasoning and path finding tasks, whereas Peng et al. (2015) achieved successful results.",
      "startOffset" : 188,
      "endOffset" : 207
    }, {
      "referenceID" : 13,
      "context" : "Due to the page limit, this theoretical foundation is relegated to the supplementary materials (Smolensky et al. (2016)).",
      "startOffset" : 96,
      "endOffset" : 120
    }, {
      "referenceID" : 0,
      "context" : "Since the seminal work of Bengio et al. (2003), researchers have paid increasing attention to various distributed representations in continuous vector spaces.",
      "startOffset" : 26,
      "endOffset" : 47
    }, {
      "referenceID" : 0,
      "context" : "Since the seminal work of Bengio et al. (2003), researchers have paid increasing attention to various distributed representations in continuous vector spaces. In the computer science literature, Skipgram/CBoW (Mikolov et al. (2013)) and GloVe (Pennington et al.",
      "startOffset" : 26,
      "endOffset" : 232
    }, {
      "referenceID" : 0,
      "context" : "Since the seminal work of Bengio et al. (2003), researchers have paid increasing attention to various distributed representations in continuous vector spaces. In the computer science literature, Skipgram/CBoW (Mikolov et al. (2013)) and GloVe (Pennington et al. (2014)) are popular models that are trained based on the distributional similarities in word co-occurrence patterns; they have been frequently utilized as initial embeddings for a variety of other NLP tasks.",
      "startOffset" : 26,
      "endOffset" : 269
    }, {
      "referenceID" : 0,
      "context" : "Since the seminal work of Bengio et al. (2003), researchers have paid increasing attention to various distributed representations in continuous vector spaces. In the computer science literature, Skipgram/CBoW (Mikolov et al. (2013)) and GloVe (Pennington et al. (2014)) are popular models that are trained based on the distributional similarities in word co-occurrence patterns; they have been frequently utilized as initial embeddings for a variety of other NLP tasks. In the cognitive science literature, on the other hand, BEAGLE (Jones & Mewhort (2007)) and DVRS (Ustun et al.",
      "startOffset" : 26,
      "endOffset" : 557
    }, {
      "referenceID" : 0,
      "context" : "Since the seminal work of Bengio et al. (2003), researchers have paid increasing attention to various distributed representations in continuous vector spaces. In the computer science literature, Skipgram/CBoW (Mikolov et al. (2013)) and GloVe (Pennington et al. (2014)) are popular models that are trained based on the distributional similarities in word co-occurrence patterns; they have been frequently utilized as initial embeddings for a variety of other NLP tasks. In the cognitive science literature, on the other hand, BEAGLE (Jones & Mewhort (2007)) and DVRS (Ustun et al. (2014)) are trained differently, with random initializations and circular convolution.",
      "startOffset" : 26,
      "endOffset" : 588
    }, {
      "referenceID" : 10,
      "context" : "Similarly, Rocktaschel et al. (2014) try to find low-dimensional embeddings which can model first-order logic in a vectorial manner.",
      "startOffset" : 11,
      "endOffset" : 37
    }, {
      "referenceID" : 14,
      "context" : "Since the proposal of the basic MemNN (Weston et al. (2014)) model, the Adaptive/Nonlinear MemNN (Weston et al.",
      "startOffset" : 39,
      "endOffset" : 60
    }, {
      "referenceID" : 14,
      "context" : "Since the proposal of the basic MemNN (Weston et al. (2014)) model, the Adaptive/Nonlinear MemNN (Weston et al. (2015)), DMN (Kumar et al.",
      "startOffset" : 39,
      "endOffset" : 119
    }, {
      "referenceID" : 6,
      "context" : "(2015)), DMN (Kumar et al. (2015)), and MemN2N (Sukhbaatar et al.",
      "startOffset" : 14,
      "endOffset" : 34
    }, {
      "referenceID" : 6,
      "context" : "(2015)), DMN (Kumar et al. (2015)), and MemN2N (Sukhbaatar et al. (2015)) models have been developed by varying certain parts of these modules.",
      "startOffset" : 14,
      "endOffset" : 73
    }, {
      "referenceID" : 6,
      "context" : "(2015)), DMN (Kumar et al. (2015)), and MemN2N (Sukhbaatar et al. (2015)) models have been developed by varying certain parts of these modules. Nonetheless, none of these models except Peng et al. (2015) successfully accomplish either positional reasoning or path finding tasks.",
      "startOffset" : 14,
      "endOffset" : 204
    }, {
      "referenceID" : 6,
      "context" : "(2015)), DMN (Kumar et al. (2015)), and MemN2N (Sukhbaatar et al. (2015)) models have been developed by varying certain parts of these modules. Nonetheless, none of these models except Peng et al. (2015) successfully accomplish either positional reasoning or path finding tasks. Our speculation about the performance by Peng et al. (2015) will be given in a later section based on our bAbI analysis.",
      "startOffset" : 14,
      "endOffset" : 339
    }, {
      "referenceID" : 17,
      "context" : "The bAbI dataset consists of twenty different types of questions where each question category is claimed to be atomic and independent from the others (Weston et al. (2015)).",
      "startOffset" : 151,
      "endOffset" : 172
    }, {
      "referenceID" : 8,
      "context" : "Recently, Neural Reasoner (NR) by Peng et al. (2015) improves the accuracy for these two difficult categories by a large margin, achieving 97.",
      "startOffset" : 34,
      "endOffset" : 53
    } ],
    "year" : 2016,
    "abstractText" : "Question answering tasks have shown remarkable progress with distributed vector representation. In this paper, we investigate the recently proposed Facebook bAbI tasks which consist of twenty different categories of questions that require complex reasoning. Because the previous work on bAbI are all end-to-end models, errors could come from either an imperfect understanding of semantics or in certain steps of the reasoning. For clearer analysis, we propose two vector space models inspired by Tensor Product Representation (TPR) to perform knowledge encoding and logical reasoning based on common-sense inference. They together achieve near-perfect accuracy on all categories including positional reasoning and path finding that have proved difficult for most of the previous approaches. We hypothesize that the difficulties in these categories are due to the multi-relations in contrast to uni-relational characteristic of other categories. Our exploration sheds light on designing more sophisticated dataset and moving one step toward integrating transparent and interpretable formalism of TPR into existing learning paradigms.",
    "creator" : "LaTeX with hyperref package"
  }
}