{
  "name" : "1106.4090.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Maria Teresa Llano", "Andrew Ireland", "Alison Pease" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "J. Derrick , E.A. Boiten, S. Reeves (Eds.): Refinement Workshop 2011. EPTCS 55, 2011, pp. 1–19, doi:10.4204/EPTCS.55.1\nc© M.T. Llano, A. Ireland & A. Pease This work is licensed under the Creative Commons Attribution License.\nDiscovery of Invariants through Automated Theory Formation ∗\nMaria Teresa Llano† Andrew Ireland Heriot-Watt University\nSchool of Mathematical and Computer Sciences\nAlison Pease University of Edinburgh\nSchool of Informatics\nRefinement is a powerful mechanism for mastering the complexities that arise when formally modelling systems. Refinement also brings with it additional proof obligations – requiring a developer to discover properties relating to their design decisions. With the goal of reducing this burden, we have investigated how a general purpose theory formation tool, HR, can be used to automate the discovery of such properties within the context of Event-B. Here we develop a heuristic approach to the automatic discovery of invariants and report upon a series of experiments that we undertook in order to evaluate our approach. The set of heuristics developed provides systematic guidance in tailoring HR for a given Event-B development. These heuristics are based upon proof-failure analysis, and have given rise to some promising results."
    }, {
      "heading" : "1 Introduction",
      "text" : "By allowing a developer to incrementally introduce design details, refinement provides a powerful mechanism for mastering the complexities that arise when formally modelling systems. This benefit comes with proof obligations (POs) – the task of proving the correctness of each refinement step. Discharging such proof obligations typically requires a developer to supply properties – properties that relate to their design decisions. Ideally automation should be provided to support the discovery of such properties, allowing the developer to focus on design decisions rather than analysing failed proof obligations.\nWith this goal in mind, we have developed a heuristic approach for the automatic discovery of invariants in order to support the formal modelling of systems. Our approach, shown in Figure 1, involves three components:\n• a simulation component that generates system traces,\n• an Automatic Theory Formation (ATF) component that generates conjectures from the analysis of the traces and,\n• a formal modelling component that supports proof and proof failure analysis.\nCrucially, proof and proof failure analysis is used to tailor the theory formation component. From a modelling perspective we have focused on Event-B [1] and the Rodin tool-set [2], in particular we have used the ProB animator plug-in [14] for the simulation component. In terms of ATF, we have used a general-purpose system called HR [4]. Generating invariants from the analysis of ProB animation traces is an approach analogous to that of the Daikon system [9]; however, while Daikon is tailored for programming languages here we focus on formal models. We come back to this in §6. ∗The research reported in this paper is supported by EPSRC grants EP/F037058 and EP/F035594. †Maria Teresa Llano is partially funded by a BAE Systems studentship.\nOur investigation involved a series of experiments, drawing upon examples which include Abrial’s “Cars on a Bridge” [1] and the Mondex case study by Butler et al. [3] . Our initial experiments highlighted the power of HR as a tool for automating the discovery of both system and gluing invariants – system invariants introduce requirements of the system while gluing invariants relate the state of the refined model with the state of the abstract model. However, our experiments also showed significant limitations: i) selecting the right configuration for HR according to the domain at hand, i.e. selection of production rules and the number of theory formation steps needed to generate the missing invariants, and ii) the overwhelming number of conjectures that are generated. This led us to consider how HR could be systematically tailored to provide practical support during an Event-B development. As a result we developed a set of heuristics which are based upon proof-failure analysis. These heuristics have given rise to some promising results and are the main focus of this paper. Although we show here the application of our technique in the context of Event-B, we believe our approach can be applied to any refinement style formal modelling framework that supports simulation and that uses proof in order to verify refinement steps.\nThe remainder of this paper is organised as follows. In §2 we provide background on both Event-B and HR. The application of HR within the context of Event-B is described in §3, along with the limitations highlighted above. In §4 we present our heuristics, and describe their rationale. Our experimental results are given in §5, while related and future work are discussed in §6."
    }, {
      "heading" : "2 Background",
      "text" : ""
    }, {
      "heading" : "2.1 Event-B",
      "text" : "Event-B promotes an incremental style of formal modelling, where each step of a development is underpinned by formal reasoning. An Event-B development is structured around models and contexts. A context represents the static parts of a system, i.e. constants and axioms, while the dynamic parts are represented by models. Models have a state, i.e. variables, which are updated via guarded actions, known as events, and are constrained by invariants.\nTo illustrate the basic features of a refinement consider the two events shown in Figure 2, which are part of the Mondex development [3]. The Mondex system models the transfer of money between electronic purses. The event StartFrom handles the initiation of a transaction on the side of the source purse. In order to initiate a transaction, the source purse must be in the idle state (waiting state) and after the transaction has been initiated the state of the purse must be changed to epr (expecting request).\nAs shown in Figure 2, in this step of the refinement the abstract model represents the state of purses by disjoint sets, i.e. the variables eprP and idleFP, while the concrete model handles these states through a function, i.e. the variable statusF, which maps a purse to an enumerated set that represents the current state, i.e. the constants IDLEF and EPR.\nNote that the keyword refines specifies the event being refined, while the keywords any, where and then delimit event parameters, guards and actions respectively. Note also that the concrete event on the right represents a refinement of the abstract event on the left.\nIn order to verify this refinement an invariant is required that relates the concrete and abstract states – these are known as gluing invariants. In the case of the events given above, the required gluing invariant takes the form:\nidleFP = statusF−1[{IDLEF}] (1)\nThis invariant states that the abstract set idleFP can be obtained from the inverse of the function statusF evaluated over the enumerated set IDLEF. A similar gluing invariant would be required for the abstract set eprP and the function statusF. Within the Rodin toolset1, the user is required to supply such gluing invariants. Likewise, invariants relating to state variables within a single model must also be supplied by the user – what we refer to here as system invariants. To illustrate, the following disjointness property represents an invariant of the abstract event above:\neprP ∩ idleFP = ø\nFrom a theoretical perspective such invariants are typically not very challenging. They are however numerous and represent a significant obstacle to increasing the accessibility of formal refinement approaches such as Event-B."
    }, {
      "heading" : "2.2 Automated theory formation and HR",
      "text" : "Lenat developed one of the earliest examples of a discovery system in mathematics; Automated Mathematician (AM) [12] and its successor Eurisko [13]. Despite subsequent methodological criticism of\n1Rodin provides an Eclipse based platform for Event-B, with a range of modelling and reasoning plug-ins, e.g. UML-B [23], ProB model checker and animator [14], B4free theorem prover (http://www.b4free.com).\nLenat’s work [22], he did show us that it is possible to formalise heuristics for discovery in mathematics. Colton has developed this intuition in his HR machine learning system2 [4]. HR performs descriptive induction to form a theory about a set of objects of interest which are described by a set of core concepts (this is in contrast to predictive learning systems which are used to solve the particular problem of finding a definition for a target concept). Based on Colton’s observation that it is possible to gain an understanding of a complex concept by decomposing it via small steps into simpler concepts, Colton defined production rules which take in concepts and make small changes to produce further concepts.\nHR constructs a theory by finding examples of objects of interest, inventing new concepts, making plausible statements relating those concepts, evaluating both concepts and statements and, if working in a mathematical domain, proving or disproving the statements. Objects of interest are the entities which a theory discusses. For instance, in number theory the objects of interest are integers, in group theory they are groups, etc. Concepts are either provided by the user (core concepts) or developed by HR (non-core concepts) and have an associated data table (or table of examples). The data table is a function from an object of interest, such as the number 1, or the prime 3, to a truth value or a set of objects.\nEach production rule is generic and works by performing operations on the content of one or two input data tables and a set of parameterisations in order to produce a new output data table, thus forming a new concept. The production rules and parameterisations are usually applied automatically according to a search strategy which has been entered by the user, and are applied repeatedly until HR has either exhausted the search space or has reached a user-defined number of theory formation steps to perform. Production rules include:\n• The split rule: this extracts the list of examples of a concept for which some given parameters hold. • The negate rule: this negates predicates in the new definition. • The compose rule: combines predicates from two old concepts in the new concept. • The arithmetic rule: performs arithmetic operations (+, -, ∗, ÷) on specified entries of two con-\ncepts.\n• The numrelation rule: performs arithmetic comparisons (<, >, ≤, ≥) on specified entries of two concepts.\nEach time a new concept is generated, HR checks to see whether it can make conjectures with it. This could be equivalence conjectures, if the new concept has the same data table as a previous concept; implication conjectures, if the data table of the new concept either subsumes or is subsumed by that of another concept, or non-existence conjectures, if the data table for the new concept is empty.\nThus, the theories HR produces contain concepts which relate the objects of interest; conjectures which relate the concepts; and proofs which explain the conjectures. Theories are constructed via theory formation steps which attempt to construct a new concept and, if successful, formulate conjectures and evaluate the results. HR has been used for a variety of discovery projects, including mathematics and scientific domains (it has been particularly successful in number theory [6] and algebraic domains [19]) and constraint solvers [8, 21].\nAs an example, we show how HR produces the concept of prime numbers and the conjecture that all prime numbers are non-squares. Figure 3 shows the data tables used by HR for the formation of the concept of prime numbers.\nIn order to generate this concept, HR would take in the concept of divisors (b|a where b is a divisor of a), represented by a data table for a subset of integers (partially shown in Figure 3 for integers from\n2HR is named after mathematicians Godfrey Harold Hardy (1877 - 1947) and Srinivasa Aiyangar Ramanujan (1887 - 1920).\n1 to 10). Then, HR would apply the size production rule with the parameterisation < 1 >. This means that the number of tuples for each entry in column 1 are counted, and this number is then recorded for each entry. For instance, in the data table representing the concept of divisors, 1 appears only once in the first column, 2 and 3 appear twice each, and 10 appears four times. This number is recorded next to the entries in a new data table (the table for the concept Tau function). HR then takes in this new concept and applies the split production rule with the parameterisation < 2 = 2 >, which means that it produces a new data table consisting of those entries in the previous data table whose value in the second column is 2. This is the concept of a prime number.\nAfter this concept has been formed HR checks to see whether the data table is equivalent to, subsumed by, or subsumes another data table, or whether it is empty. Assuming the concept of non-square numbers has been formed previously by HR, the data tables of both the concept of prime numbers and the concept of non-square numbers, shown in Figure 4, are compared.\nHR would immediately see that all of its prime numbers are also non-squares, and so conjectures that this is true for all prime numbers. That is, it will make the following implication conjecture:\n2 = |{b : b|a}|︸ ︷︷ ︸ ⇒ ¬(exists b.(b|a & b∗b = a))︸ ︷︷ ︸ prime number non-square number"
    }, {
      "heading" : "3 Automated theory formation for Event-B models with HR",
      "text" : "In this section we show how gluing invariant (1) introduced in the example of §2.1 can be generated through the use of theory formation and, in particular, with the HR system."
    }, {
      "heading" : "3.1 Construction of conjectures in the domain of the Mondex system",
      "text" : "HR’s input consists of a set of core concepts that describe the domain. With respect to Event-B models, these core concepts are represented by the state of the system, i.e. variables, and by the static information given in the context of the model, i.e. constants and sets. Furthermore, a concept is composed of a series of examples. Here, animation traces are used to provide HR with a list of examples for each of the concepts of an Event-B model. As mentioned before, we use ProB [14] to animate the models. For the purpose of the example, in Figure 5 we introduce some of the core concepts with their respective data tables – which were generated through the animation of the model with the ProB system.\nThen, HR applied all possible combinations of concepts and production rules in order to generate new concepts and form conjectures. After the 433 step, HR formed the concept of the set of purses whose status in function statusF maps to IDLEF by applying the split production rule. The application of this step is illustrated in Figure 6. An intermediate output is generated with all tuples of concept statusF whose third column matches the parameter IDLEF. Since the third column is the same for all tuples of the intermediate concept, this column is removed from the final output concept.\nImmediately after the generation of new concepts, HR looks for relationships with other existing concepts. As shown in Figure 7, HR found that the new concept has the same list of examples as concept idleFP, which gives rise to the following equivalence conjecture:\n∀A,B.(state(A) ∧ purseSet(B) ∧ idleFP(A,B) ⇔ status(IDLEF) ∧ statusF(A,B, IDLEF))\nwhich can be represented in Event-B as (1)."
    }, {
      "heading" : "3.2 Challenges in applying HR",
      "text" : "For the domain of the Mondex system a total of 4545 conjectures were generated after 1000 formation steps. As can be observed, this is a considerable set of conjectures to analyse. In general, using HR for the discovery of invariants presented us with three main challenges:\n1. The HR theory formation mechanism consists of an iterative application of production rules over\nexisting and new concepts. In order for HR to perform an exhaustive search, all possible combinations of production rules and concepts must be carried out. However, there is not a fixed number of theory formation steps set up for this process, since this varies depending on the domain, i.e. some domains need more theory formation steps than others. This represented a challenge for the use of HR in the discovery of invariants since it was possible that an invariant had not been formed only because not enough formation steps were run.\n2. Some production rules are more effective in certain domains than others. Selecting the appropriate production rules results in the construction of a more interesting theory. For instance, if we are looking at a refinement step in an Event-B model that introduces a partition of sets we expect the new invariants to define properties over the new sets; therefore, production rules like the arithmetic production rule will not be of much interest in the development of the theory associated to the refinement step. Automatically selecting appropriate production rules requires knowledge about the domain; therefore, a technique was needed in order to perform this selection.\n3. Finally, as highlighted in our example, HR produces a large number of conjectures – in our experiments some where in the range of 3000 to 12000 conjectures per run – from which only a very small set represented interesting invariants of the system. Thus, our main challenge was to find a way of automatically selecting the conjectures that are interesting for the domain among the conjectures obtained from HR.\nIn order to overcome these challenges, we have developed an approach that uses proof failure analysis to guide the search in HR. In the next section, we introduce this approach and illustrate its application, based on our running example from the Mondex case study."
    }, {
      "heading" : "4 Proof failure analysis and HR",
      "text" : "In order to use HR, a user must first configure the system for their application domain. This involves the user in selecting production rules and conjecture making techniques, as well as deciding how many steps HR should be run. In the example introduced in §3.1, the application of the split production rule with respect to the concept statusF, for the value IDLEF, is an informed decision, based upon the user’s knowledge of the model. On its own, HR does not have the capability of applying this type of reasoning. Often particular combinations of these parameters turn out to be useful for different domains. Finding the right combination is largely a process of trial and error.\nHere we have developed a heuristic approach with the aim of automating this trial and error process. Our heuristics exploit the strong interplay between modelling and reasoning in Event-B. In the context of the discovery of invariants through theory formation, we use the feedback provided by failed POs to make decisions about how to configure HR in order to guide the search for invariants. Specifically, our approach consists of analysing the structure of failed POs so that we can automate:\n1. the prioritisation in the development of conjectures about specific concepts, 2. the selection of appropriate production rules that increase the possibilities of producing the missing\ninvariants and, 3. the filtering of the final set of conjectures to be analysed as possible candidate invariants."
    }, {
      "heading" : "4.1 Heuristics",
      "text" : "Our heuristics constrain the search for invariants by focusing HR on concepts that occur within failed POs. We use two classes of heuristics – those used in configuring HR, i.e. Pre-Heuristics (PH), and\nthose used in selecting conjectures from HR’s output, i.e. Selection Heuristics (SH). Below we explain each class of heuristics in turn:"
    }, {
      "heading" : "4.1.1 HR configuration heuristics",
      "text" : "We use two overall heuristics when configuring HR for a given Event-B refinement:\nPH1. Prioritise core and non-core concepts that occur within the failed POs as follows:. Goal concepts: concepts that appear within the goals of the failed POs. Hypotheses concepts: concepts that appear within the hypotheses of the failed POs. Other concepts: concepts that do not appear within the failed POs.\nPH2. Select production rules which will give rise to conjectures relating to the concepts occurring within the failed POs, i.e.\nSplit rule: is selected if members of finite sets occur. Arithmetic rule: is selected if there are occurrences of arithmetic operators, e.g. +,-,*,/. Numrelation rule: is selected if there are occurrences of relational operators, e.g. >,<,≤,≥. In addition, because of the set theoretic nature of Event-B, the compose, disjunct and negate production rules are always used in the search for invariants – where compose relates to conjunction and intersection, disjunct relates to disjunction and union and negate relates to negation and set complement.\nBelow we provide the rationale for these heuristics:\n• As explained in §2.2, HR uses the agenda mechanism to organise the theory formation steps. The purpose of PH1 is to give higher priority to core and non-core concepts that occur within the failed POs, which means HR will generate related conjectures earlier within the theory formation process by having the prioritised concepts in the top of the agenda. Furthermore, we have observed that in most cases, we are able to identify the missing invariants by focusing in the first instance on the concepts that arise within the goals of the failed POs. As a result, such concepts are assigned the highest priority in the application of heuristic PH1. The concepts associated to the hypotheses follow in order of interest, while the remaining concepts are given the lesser priority.\n• The missing invariants that are required in order to overcome proof failures will typically have strong syntactic similarities with the failed POs. This is the intuition behind PH2, which selects production rules that focus HR’s theory formation process on such syntactic similarities.\nAs will be shown in §5, the empirical evidence we have gathered so far supports our rationale."
    }, {
      "heading" : "4.1.2 Conjecture selection heuristics",
      "text" : "In order to prune the set of conjectures generated by HR, we use the following five selection heuristics:\nSH1. Select conjectures that focus purely on prioritised core and non-core concepts.\nSH2. Select conjectures where the sets of variables occurring on the left- and right-hand sides are disjoint.\nSH3. Select only the most general conjectures.\nSH4. Select conjectures that discharge the failed POs.\nSH5. Select conjectures that minimise the number of additional proof failures that are introduced.\nThe rationale for these heuristics is as follows:\n• SH1 initiates the pruning of uninteresting conjectures by selecting those that describe properties about the prioritised core and non-core concepts (as identified by PH1). Furthermore, the selected conjectures should focus purely on the prioritised concepts; this means that we are interested only in equivalence and implication conjectures of the forms:\nα ⇔ β α ⇒ β β ⇒ α\nwhere α relates to a prioritised core or non-core concept and β to any other concept. All nonexistence conjectures associated with the prioritised concepts are selected. Note that this selection criteria still gives rise to a large set of conjectures. However, as explained in the rationale of PH1 in §4.1.1, in most cases we have identified the missing invariants by focusing first on the concepts associated to the goals of the failed POs. For the selection process the same reasoning is followed and, therefore, heuristics SH1 to SH5 are focused first on conjectures associated to the concepts of the goals identified by the application of PH1. If no candidate invariants are found, or if old failures are still not addressed by the identified invariants, then the selection process starts again from SH1 to SH5 but focused on the conjectures associated with the concepts of the hypotheses.\n• SH2 further prunes the set of conjectures by selecting only those that do not use the same variable(s) in both sides of the conjecture. The reason for this is that invariants in Event-B typically express relationships between different variables of the model.\n• SH3 is used to eliminate redundancies amongst the set of selected conjectures by removing those that are logically implied by more general conjectures.\n• SH4 is used to select candidate invariants which discharge the given failed POs. • Potentially, overcoming one proof failure via the introduction of missing invariants may give rise\nto new proof fails. SH5 selects conjectures that discharge the failed POs, whilst minimising the number of new failed POs that are introduced. This iterative approach to discovering all the missing invariants is typical of Event-B developments, as described in Section 5 of [3], where invariant discovery is manual. Of course, if a development is incorrect, then this process will not terminate. We return to the issue of working with incorrect developments in §6.\nNote that the selection conjectures must be applied in order from SH1 to SH5 so as to optimise the selection procedure."
    }, {
      "heading" : "4.2 Worked example",
      "text" : "We now illustrate the application of our heuristics by returning to the refinement step described in §3.1. Recall that the gluing invariant (1) was required in order for the correctness of the refinement to be proved. When this invariant is missing from the model, an unprovable guard strengthening (GRD) PO3, as shown in Figure 8, is generated. The failed PO shows that the guard p1 ∈ idleFP of the abstract event is not implied by the guards of the concrete event.\n3 A GRD PO verifies that the guards of a refined event imply the guards of the abstract event.\nWe start the process of invariant discovery with the application of heuristic PH1. We extract the list of core concepts that occur in the failed PO, giving them higher priority within the theory formation process. The extracted concepts are:\nidleFP, statusF, status, startFromM, from, FSeqno and currentSeqNo\nExcept for status, all these concepts explicitly occur within the PO. Note that status is added because the constant IDLEF is a representative of the set status.\nRegarding non-core concepts, the hypothesis p1 7→ IDLEF ∈ statusF in the failed PO suggests that function statusF maps an arbitrary purse to the status IDLEF. This is an example of a non-core concept. This concept is obtained through the application of the split production rule over the concept statusF on the value IDLEF. No other non-core concepts are identified in the PO.\nThe next step is the selection of the production rules. The following production rules are used in the invariant discovery process:\ncompose, disjunct, negate and split\nThe compose, disjunct and negate production rules are always used in the search, as defined by heuristic PH2. The split production rule is selected because hypothesis p1 7→ IDLEF ∈ statusF makes reference to a member of the finite set status: namely, the constant IDLEF. Thus, the split production rule is applied over the finite set status and the values to split are all the members of the set, i.e.: IDLEF, EPR, EPA, ABORTEPR, ABORTEPA, ENDF, IDLET, EPV, ABORTEPV and ENDT.\nAfter the application of the PH heuristics, the initial configuration of HR is complete. By running HR for 1000 steps, 2134 conjectures were formed. This should be compared with the 4545 conjectures that are generated if our PH heuristics are not used to configure HR.\nNow turning to the SH heuristics, SH1 selects conjectures that relate to the prioritised concepts that appear within the goal of the failed PO. In our example, this focuses on conjectures that involve the concept idleFP. After applying SH1 we obtained:"
    }, {
      "heading" : "4 equivalences, 2 implications and 79 non-exists conjectures",
      "text" : "The application of SH2 removes conjectures whose left- and right-hand sides are not disjoint with respect to the variable occurrences. The application of SH2 yields the following results:"
    }, {
      "heading" : "1 equivalence, 2 implications and 79 non-exists conjectures",
      "text" : "Through the application of SH3, less general conjectures are removed. Applying this heuristic produces:\n1 equivalence, 2 implications and 46 non-exists conjectures\nSH4 selects only conjectures that discharge the failed PO, the results of this step are:"
    }, {
      "heading" : "1 equivalence, 0 implications and 0 non-exists conjectures",
      "text" : "Only one conjecture discharges the failed PO. Furthermore, this conjecture does not introduce any additional failures; therefore, it represents an invariant. Within HR the invariant takes the form:\n∀A,B.(state(A) ∧ purseSet(B) ∧ idleFP(A,B) ⇔ status(IDLEF) ∧ statusF(A,B, IDLEF))\nwhich translates into the missing gluing invariant (1). It should be noted that this conjecture was formed by HR after one theory formation step. This shows that, in this example, our heuristics guided HR to discover interesting conjectures early within the theory formation process."
    }, {
      "heading" : "5 Experimental results",
      "text" : "The experiments we carried out were divided into two stages. The first stage involved the development of our heuristics, and was based upon four relatively simple Event-B models, as described below:\n1. Traffic light system: This model represents a traffic light circuit that controls the sequencing of lights. It is composed of an abstract model and involves a single refinement. The abstract model controls the red and green lights, while the refinement introduces a third light to the sequence, i.e. an amber light.\n2. Two representations of a vending machine:\n• Set-like representation: This model of a vending machine controls the stock of products through the use of states. It is composed of an abstract and a concrete model. The abstract model represents the states of products using state sets, while the refinement introduces a status function that maps products to their states.\n• Arithmetic-like representation: This model of the vending machine uses natural numbers to represent the stock and money held within the machine. While the abstract model deals with a single product, the refinement introduces a second product to the vending machine.\n3. Refinements 1 and 2 of Abrial’s cars on a bridge system [1]: Models a system that controls the flow of cars on a bridge that connects a mainland to an island. At the abstract level, cars are modelled leaving and entering the island, the first refinement introduces the requirement that the bridge only supports one way traffic, while the second refinement introduces traffic lights.\nWe used the second stage of our experiments to evaluate the heuristics developed during stage one. Here the experiments were performed on more complex Event-B models:\n1. Refinement 3 of Abrial’s cars on a bridge system [1]: The third refinement of this system models the introduction of sensors that detect the physical presence of cars.\n2. The Mondex system [3]: Models an electronic purse that allows the transfer of money between purses. This development is composed of one abstract model and nine refinement steps. We targeted the third, fourth and eighth refinement steps. The third refinement handles dual state sets in both sides of a transaction in order to handle information locally. The fourth refinement introduces the use of messaging channels between purses and the eighth refinement introduces a status function that maps purses to their states instead of using state sets.\nIn the work reported in [3], it was highlighted that the manual analysis of failed POs was used to guide the construction of gluing invariants. In particular, this was illustrated in the third step of the refinement in which, through the analysis of failed POs, and after three iterations of invariant strengthening, the set of invariants needed to prove the refinement between levels three and four were added to the model. As part of our experiments we attempted the re-construction of the Mondex system in Event-B based on the development presented in [3]. In the following section we present the results obtained by the application of our approach to the refinement between levels three and four of the Mondex system, and we show that these results are similar to the ones obtained through the interactive development [3]."
    }, {
      "heading" : "5.1 The Mondex system",
      "text" : "In level three of the Mondex system a transaction is permitted to be in one of four states: idle, pending, recover or ended, while the refinement in level four introduces dual states to a transaction so that each side has their own local protocol state. In order to evaluate our approach, we introduced the model in level 4 with only basic typing invariants. The absence of the invariants produces the failed POs shown in Figure 9.\nWe start the invariant discovery process with the application of heuristic PH1. The set of core concepts selected from the failed POs are:\nidle, pending, recover, purse, epr, epv, abortepv, from, am, bal, epa, abortepa and to\nMoreover, from the analysis of the predicates in the failed POs, we identify the following non-core concepts:\nepv ∪ abortepv and epa ∪ abortepa\nThese concepts are identified from hypotheses t ∈ epv ∪ abortepv and t ∈ epa ∪ abortepa within PO1 and PO2, respectively. Note that t does not represent a concept in the domain, it represents an arbitrary transaction passed as a parameter to the event associated with the failed POs. For this reason, only the right hand sides of the membership relations are selected as interesting non-core concepts.\nThe process continues with the selection of the productions rules. Based on the failed POs shown in Figure 9, the following production rules are selected for the search:\ncompose, disjunct, negate and numrelation\nThe compose, disjunct and negate production rules are always used in the search as stated in heuristic PH2. The numrelation production rule is selected because hypothesis a≤ bal(p1) within PO1 expresses a property based on the relational operator ≤. After the pre-heuristics have been applied HR is run for 1000 steps, resulting in 7296 conjectures.\nThe selection heuristics are now applied over this set of conjectures. Heuristic SH1 suggests looking at the prioritised concepts associated to the goals of the failed POs. From the goals of the POs shown in Figure 9, we identified the concepts idle, pending and recover. Thus, we look for the conjectures associated to each of these concepts. The results from the application of this heuristic are shown in Table 1. This table also shows the results of applying heuristics SH2, SH3 and SH4 over each of the selected concepts.\nAs can be observed, after applying the four initial selection heuristics we have narrowed the set of selected conjectures to a total of five conjectures: two implications involving the concept idle, two implications for concept pending and one equivalence about the concept recover.\nThe final step in the discovery process is the selection of the conjectures that produce the smaller number of new failed POs. The two implications associated with concept idle discharge PO1 and produce one extra failed PO. We believe that in this kind of situation it is the user who has to decide which one is the most appropriate conjecture according to his/her knowledge about the model. Thus, we present both conjectures as candidate invariants and leave the decision of which one to select to the user. Regarding the two implications associated with concept pending, one of them discharges PO2 and PO3 and produces two new failed POs, while the other one discharges PO4 but produces three new failed POs. As there are no other conjectures that help to overcome the failures produced by PO2, PO3 and PO4, both conjectures are suggested as candidate invariants. Finally, the equivalence conjecture associated with concept recover discharges PO5 and it does not produce any extra failures, so this conjecture is also suggested as a candidate invariant. The set of invariants represented by the conjectures obtained from HR in this first iteration of our approach is shown in Figure 10(a) 4.\nAfter the new set of invariants is introduced to the model, six new failed POs are generated. We then start the analysis again by applying our approach based on the new set of failed POs. This new iteration results in the discovery of five new invariants. Again, when these invariants are added to the model, one\n4Note that we have given the equivalent set theoretic representation of these conjectures instead of using the universally quantified format provided by HR. This is because some experiments, for instance the development of the Mondex system carried out in [3], have shown that the automatic provers do better with quantifier-free predicates.\nnew failed PO is generated. We discovered one new invariant after a third iteration of our approach. No further failed POs are generated when this invariant is added to the model. Figures 10(b) and Figure 10(c) shows the invariants obtained after the second and the third iteration, respectively.\nThe invariants shown in Figure 10 are a subset of the invariants suggested in [3] for this step of the refinement. In total we obtained 11 invariants from the 17 used in [3]. However, it is important to note that we have addressed all the failures produced when proving consistency between the refinement levels. Our hypothesis, is that the extra invariants used in [3] represent new requirements of the system, which are out of the scope of our technique since we only target invariants needed to prove the refinement steps."
    }, {
      "heading" : "5.2 Summary of results",
      "text" : "Table 2 summarises the results of the application of our approach in each of the Event-B models used during the development and the evaluation stages. Notice that all the experiments were performed over models with only basic typing invariants. This means that neither gluing nor system invariants were present in the models when using our technique. The table shows for each refinement step, the number of failed POs that arose, as well as the number of gluing and system invariants discovered through our approach. We also record the number of iterations involved in the invariant discovery process.\nIn Table 3 we compare our results with the actual invariants given in the literature for the models of the cars on a bridge [1] and the Mondex system [3]; the other developments are not compared because they are of our own authorship (note that the invariants of the refinement from levels four to five of the Mondex system are not given in the literature). All automatically discovered invariants are subsets of the\ninvariants given in the literature; however, it is important to highlight that the automatically discovered invariants were sufficient to prove all the refinement steps in our experimental models.\nAs it can be observed from Table 3, the automatic discovery of gluing invariants through the use of theory formation and the HR system has provided promising results. In most cases, the set of gluing invariants discovered through our technique was almost identical to the set of gluing invariants provided in the literature. Regarding system invariants, it can be observed that the last refinement of the cars on a bridge system shows a big gap between the invariants given in the literature and those found automatically with our approach. As mentioned previously, we believe that this difference can be explained by the introduction of new requirements, resulting in the need for extra properties in the model.\nFigure 11, shows all the invariants that were discovered through the application of our approach. The invariants for refinement three of the Mondex system are omitted since they are shown in §5.1."
    }, {
      "heading" : "6 Related and future work",
      "text" : "As far as we are aware, automated theory formation techniques have not been investigated within the context of refinement style formal modelling. The closest work we know of is Daikon [9], a system which uses templates to detect likely program invariants by analysing program execution traces. The quality of the invariants generated by both approaches depends in part upon the quality of the input data – ProB animation traces in our work and program test suites for Daikon. Like HR, Daikon is configurable. However, while HR is a general purpose theory formation tool, Daikon has been designed with program analysis in mind. It should also be stressed that Daikon is a system, whereas the work presented here is an initial investigation into developing an invariant generation tool for refinement based formal methods.\nWithin automated theory formation there are a number of alternative tools to HR that could be explored. For instance, IsaCoSy [11], IsaScheme [20], the CORE system [16] and MathsAid [17]. Underlying the first three of these systems is a notion of term synthesis, i.e. the automatic generation of candidate conjectures based upon application of domain knowledge. IsaCoSy and IsaScheme support the discovery of theorems within the context of mathematical induction, while MathsAid provides broader support for the development of mathematical theories. The CORE system has a strong software verification focus, supporting the automatic generation of frame and loop invariants for use in reasoning about pointer programs. What distinguishes these approaches from HR is that they do not rely upon animation/execution traces, instead they follow a generate-and-test approach, where the “test” component involves theorem proving. Coupled with its configurability, the trace analysis capability led us to use HR for our investigations.\nAs noted above, animation is key to our approach, where the quality of the invariants produced by HR strongly depends on the quality of the animation traces. The ProB animator provided good animation traces for most of our experiments; however, we found two areas where further improvements are required:\n1. We believe that increasing the randomness in the production of the traces would improve our results.\n2. ProB preferences only allows for the creation of sets with a few elements, as well as very limited integer ranges. This restricted some of the traces we were able to generate, and thus impacted negatively on the invariants that could be discovered. Specifically, this limitation arose during our analysis of the Mondex case study.\nThe process of finding a “correct” refinement will typically involve exploring many “incorrect” refinements. While the work reported here focuses on supporting the verification of correct refinements, we are currently investigating how counter-examples generated by ProB could be combined with HR in order to provide useful feedback to a developer when faced with an incorrect refinement.\nLonger-term, we are looking to use theory formation within our REMO [10] formal modelling planning system. That is, when faced with a refinement failure, we aim to use theory formation, automatically tailored by refinement plans [15], to suggest modelling alternatives. Of course, such “modelling alternatives” are only suggestions, ultimately users must select which is most appropriate to their needs.\nCurrently, the animation traces obtained from the ProB animator are automatically converted into HR’s input, i.e. a domain file with the list of examples for each of the concepts (variables, constants and sets) is created. However, the automation of the heuristics is still under development. Automating the configuration heuristics involves the prioritisation of concepts in the domain file and the creation of a macro file. The macro file records the search strategy that will be applied by HR (usually supplied by the user). Here is where the production rules selected by our proof failure analysis are specified. The\nautomation of the selection heuristics requires integration with a theorem prover and the Rodin toolset. HR uses the Otter theorem prover [18] to prove the conjectures. We will exploit the use of the Otter theorem prover in HR for the selection of the most general conjectures (heuristic SH3), while the Rodin toolset will be used to obtain the status of the POs after the candidate invariants have been introduced into the model (heuristics SH4 and SH5). As future work, we aim to automate this process and, as mentioned before, integrate it with our REMO tool."
    }, {
      "heading" : "7 Conclusions",
      "text" : "We have described an investigation into how the HR theory formation tool can be used to automatically discover the kinds of invariants that developers typically have to supply in order to verify Event-B refinements. The key contribution of our work is the development of a set of heuristics. Using proof-failure analysis to prune the wealth of conjectures HR discovers, these heuristics have proven highly effective at identifying missing invariants. While more experimentation is required, we believe that our heuristics provide a firm foundation upon which to further explore techniques that support formal refinement – techniques that suggest design alternatives, whilst removing the burden of proof failure analysis from developers.\nAcknowledgements: Our thanks go to Alan Bundy, Gudmund Grov and Julian Gutierrez for their feedback and encouragement with this work. Also, we want to thank Jens Bendisposto and the ProB development team for their assistance, and Simon Colton and John Charnley for their help in using the HR system."
    } ],
    "references" : [ {
      "title" : "Modeling in Event-B - System and Software Engineering",
      "author" : [ "J-R. Abrial" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2010
    }, {
      "title" : "Rodin: an open toolset for modelling and reasoning in Event-B",
      "author" : [ "J-R. Abrial", "M. Butler", "S. Hallerstede", "T. Hoang", "F. Mehta", "L. Voisin" ],
      "venue" : "STTT 12(6),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2010
    }, {
      "title" : "An incremental development of the Mondex system in Event-B",
      "author" : [ "M. Butler", "D. Yadav" ],
      "venue" : "Formal Aspects of Computing",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2008
    }, {
      "title" : "Automated Theory Formation in Pure Mathematics",
      "author" : [ "S. Colton" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2002
    }, {
      "title" : "Constraint Generation via Automated Theory Formation",
      "author" : [ "S. Colton", "I. Miguel" ],
      "venue" : "International Conference on the Principles and Practice of Constraint Programming,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2001
    }, {
      "title" : "The Daikon system for dynamic detection of likely invariants",
      "author" : [ "M. Ernst", "J. Perkins", "P. Guo", "S. McCamant", "C. Pacheco", "M. Tschantz", "C. Xiao" ],
      "venue" : "Science of Computer Programming",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2007
    }, {
      "title" : "Reasoned Modelling Critics: Turning Failed Proofs into Modelling Guidance",
      "author" : [ "A. Ireland", "G. Grov", "M. Llano", "M. Butler" ],
      "venue" : "Science of Computer Programming",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2011
    }, {
      "title" : "Case-Analysis for Rippling and Inductive Proof",
      "author" : [ "M. Johansson", "L. Dixon", "A. Bundy" ],
      "venue" : "1st International Conference on Interactive Theorem Proving,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2010
    }, {
      "title" : "AM: An Artificial Intelligence approach to discovery in mathematics",
      "author" : [ "D. Lenat" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1976
    }, {
      "title" : "Eurisko: A program which learns new heuristics and domain concepts",
      "author" : [ "D. Lenat" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1983
    }, {
      "title" : "ProB: A Model Checker for B",
      "author" : [ "M. Leuschel", "M. Butler" ],
      "venue" : "In: International Symposium of Formal Methods Europe, LNCS 2805,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2003
    }, {
      "title" : "Automatic Guidance for Refinement Based Formal Methods. 5th workshop on Automated Formal Methods (AFM‘10), a satellite workshop of the 22nd International Conference on Computer Aided Verification (CAV‘10)",
      "author" : [ "M. Llano", "G. Grov", "A. Ireland" ],
      "venue" : "Also available via: School of Mathematical and Computer Sciences,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2010
    }, {
      "title" : "Refinement and Term Synthesis in Loop Invariant Generation. In: 2nd International Workshop on Invariant Generation (WING’09), a satellite workshop of ETAPS’09",
      "author" : [ "E. Maclean", "A. Ireland", "L. Dixon", "R. Atkey" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2009
    }, {
      "title" : "Automated Discovery of Inductive Theorems. In: From Insight to Proof: Festschrift in Honour of Andrzej Trybulec, Studies in Logic, Grammar and Rhetoric",
      "author" : [ "R. McCasland", "A. Bundy", "S. Autexier" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2007
    }, {
      "title" : "Employing Theory Formation to Guide Proof Planning. In: AISC/Calculemus’02",
      "author" : [ "A. Meier", "V. Sorge", "S. Colton" ],
      "venue" : "LNAI 2385, Springer,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2002
    }, {
      "title" : "Scheme-Based Synthesis of Inductive Theories",
      "author" : [ "O. Montano-Rivas", "R. McCasland", "L. Dixon", "A. Bundy" ],
      "venue" : "In: MICAI,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2010
    }, {
      "title" : "Applying Lakatos-style reasoning to AI problems. In: Thinking Machines and the philosophy of computer science: Concepts and principles",
      "author" : [ "A. Pease", "A. Smaill", "S. Colton", "A. Ireland", "M. Llano", "R. Ramezani", "G. Grov", "M. Guhe" ],
      "venue" : "IGI Global, PA,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2010
    }, {
      "title" : "AM: a case study in methodology",
      "author" : [ "G. Ritchie", "F. Hanna" ],
      "venue" : "editors: The foundations of AI: a sourcebook, CUP, Cambridge,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1990
    }, {
      "title" : "UML-B: Formal modeling and design aided by UML",
      "author" : [ "C. Snook", "M. Butler" ],
      "venue" : "ACM Transactions on Software Engineering and Methodology",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "From a modelling perspective we have focused on Event-B [1] and the Rodin tool-set [2], in particular we have used the ProB animator plug-in [14] for the simulation component.",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 1,
      "context" : "From a modelling perspective we have focused on Event-B [1] and the Rodin tool-set [2], in particular we have used the ProB animator plug-in [14] for the simulation component.",
      "startOffset" : 83,
      "endOffset" : 86
    }, {
      "referenceID" : 10,
      "context" : "From a modelling perspective we have focused on Event-B [1] and the Rodin tool-set [2], in particular we have used the ProB animator plug-in [14] for the simulation component.",
      "startOffset" : 141,
      "endOffset" : 145
    }, {
      "referenceID" : 3,
      "context" : "In terms of ATF, we have used a general-purpose system called HR [4].",
      "startOffset" : 65,
      "endOffset" : 68
    }, {
      "referenceID" : 5,
      "context" : "Generating invariants from the analysis of ProB animation traces is an approach analogous to that of the Daikon system [9]; however, while Daikon is tailored for programming languages here we focus on formal models.",
      "startOffset" : 119,
      "endOffset" : 122
    }, {
      "referenceID" : 0,
      "context" : "Our investigation involved a series of experiments, drawing upon examples which include Abrial’s “Cars on a Bridge” [1] and the Mondex case study by Butler et al.",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 2,
      "context" : "[3] .",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "To illustrate the basic features of a refinement consider the two events shown in Figure 2, which are part of the Mondex development [3].",
      "startOffset" : 133,
      "endOffset" : 136
    }, {
      "referenceID" : 8,
      "context" : "Lenat developed one of the earliest examples of a discovery system in mathematics; Automated Mathematician (AM) [12] and its successor Eurisko [13].",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 9,
      "context" : "Lenat developed one of the earliest examples of a discovery system in mathematics; Automated Mathematician (AM) [12] and its successor Eurisko [13].",
      "startOffset" : 143,
      "endOffset" : 147
    }, {
      "referenceID" : 18,
      "context" : "UML-B [23], ProB model checker and animator [14], B4free theorem prover (http://www.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 10,
      "context" : "UML-B [23], ProB model checker and animator [14], B4free theorem prover (http://www.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 17,
      "context" : "Lenat’s work [22], he did show us that it is possible to formalise heuristics for discovery in mathematics.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 3,
      "context" : "Colton has developed this intuition in his HR machine learning system2 [4].",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 14,
      "context" : "HR has been used for a variety of discovery projects, including mathematics and scientific domains (it has been particularly successful in number theory [6] and algebraic domains [19]) and constraint solvers [8, 21].",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 4,
      "context" : "HR has been used for a variety of discovery projects, including mathematics and scientific domains (it has been particularly successful in number theory [6] and algebraic domains [19]) and constraint solvers [8, 21].",
      "startOffset" : 208,
      "endOffset" : 215
    }, {
      "referenceID" : 16,
      "context" : "HR has been used for a variety of discovery projects, including mathematics and scientific domains (it has been particularly successful in number theory [6] and algebraic domains [19]) and constraint solvers [8, 21].",
      "startOffset" : 208,
      "endOffset" : 215
    }, {
      "referenceID" : 10,
      "context" : "As mentioned before, we use ProB [14] to animate the models.",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 2,
      "context" : "This iterative approach to discovering all the missing invariants is typical of Event-B developments, as described in Section 5 of [3], where invariant discovery is manual.",
      "startOffset" : 131,
      "endOffset" : 134
    }, {
      "referenceID" : 0,
      "context" : "Refinements 1 and 2 of Abrial’s cars on a bridge system [1]: Models a system that controls the flow of cars on a bridge that connects a mainland to an island.",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 0,
      "context" : "Refinement 3 of Abrial’s cars on a bridge system [1]: The third refinement of this system models the introduction of sensors that detect the physical presence of cars.",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 2,
      "context" : "The Mondex system [3]: Models an electronic purse that allows the transfer of money between purses.",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 2,
      "context" : "In the work reported in [3], it was highlighted that the manual analysis of failed POs was used to guide the construction of gluing invariants.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 2,
      "context" : "As part of our experiments we attempted the re-construction of the Mondex system in Event-B based on the development presented in [3].",
      "startOffset" : 130,
      "endOffset" : 133
    }, {
      "referenceID" : 2,
      "context" : "In the following section we present the results obtained by the application of our approach to the refinement between levels three and four of the Mondex system, and we show that these results are similar to the ones obtained through the interactive development [3].",
      "startOffset" : 262,
      "endOffset" : 265
    }, {
      "referenceID" : 2,
      "context" : "This is because some experiments, for instance the development of the Mondex system carried out in [3], have shown that the automatic provers do better with quantifier-free predicates.",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 2,
      "context" : "The invariants shown in Figure 10 are a subset of the invariants suggested in [3] for this step of the refinement.",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 2,
      "context" : "In total we obtained 11 invariants from the 17 used in [3].",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 2,
      "context" : "Our hypothesis, is that the extra invariants used in [3] represent new requirements of the system, which are out of the scope of our technique since we only target invariants needed to prove the refinement steps.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "In Table 3 we compare our results with the actual invariants given in the literature for the models of the cars on a bridge [1] and the Mondex system [3]; the other developments are not compared because they are of our own authorship (note that the invariants of the refinement from levels four to five of the Mondex system are not given in the literature).",
      "startOffset" : 124,
      "endOffset" : 127
    }, {
      "referenceID" : 2,
      "context" : "In Table 3 we compare our results with the actual invariants given in the literature for the models of the cars on a bridge [1] and the Mondex system [3]; the other developments are not compared because they are of our own authorship (note that the invariants of the refinement from levels four to five of the Mondex system are not given in the literature).",
      "startOffset" : 150,
      "endOffset" : 153
    }, {
      "referenceID" : 5,
      "context" : "The closest work we know of is Daikon [9], a system which uses templates to detect likely program invariants by analysing program execution traces.",
      "startOffset" : 38,
      "endOffset" : 41
    }, {
      "referenceID" : 7,
      "context" : "For instance, IsaCoSy [11], IsaScheme [20], the CORE system [16] and MathsAid [17].",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 15,
      "context" : "For instance, IsaCoSy [11], IsaScheme [20], the CORE system [16] and MathsAid [17].",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 12,
      "context" : "For instance, IsaCoSy [11], IsaScheme [20], the CORE system [16] and MathsAid [17].",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 13,
      "context" : "For instance, IsaCoSy [11], IsaScheme [20], the CORE system [16] and MathsAid [17].",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 6,
      "context" : "Longer-term, we are looking to use theory formation within our REMO [10] formal modelling planning system.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 11,
      "context" : "That is, when faced with a refinement failure, we aim to use theory formation, automatically tailored by refinement plans [15], to suggest modelling alternatives.",
      "startOffset" : 122,
      "endOffset" : 126
    } ],
    "year" : 2013,
    "abstractText" : "event StartFrom =̂ any t, p1 where p1 ∈ idleFP ... then eprP := eprP ∪ {p1} idleFP := idleFP \\ {p1} ... end Concrete event StartFrom =̂ refines StartFrom any t, p1 where p1 7→ IDLEF ∈ statusF ... then statusF(p1) := EPR ... end Figure 2: Abstract and concrete views of event StartFrom. Note that the keyword refines specifies the event being refined, while the keywords any, where and then delimit event parameters, guards and actions respectively. Note also that the concrete event on the right represents a refinement of the abstract event on the left. In order to verify this refinement an invariant is required that relates the concrete and abstract states – these are known as gluing invariants. In the case of the events given above, the required gluing invariant takes the form: idleFP = statusF−1[{IDLEF}] (1) This invariant states that the abstract set idleFP can be obtained from the inverse of the function statusF evaluated over the enumerated set IDLEF. A similar gluing invariant would be required for the abstract set eprP and the function statusF. Within the Rodin toolset1, the user is required to supply such gluing invariants. Likewise, invariants relating to state variables within a single model must also be supplied by the user – what we refer to here as system invariants. To illustrate, the following disjointness property represents an invariant of the abstract event above:",
    "creator" : "LaTeX with hyperref package"
  }
}