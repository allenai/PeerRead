{
  "name" : "1702.01200.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Fuzzy Clustering Data Given on the Ordinal Scale Based on Membership and Likelihood Functions Sharing",
    "authors" : [ "Zhengbing Hu", "Yevgeniy V. Bodyanskiy" ],
    "emails" : [ "hzb@mail.ccnu.edu.cn", "yevgeniy.bodyanskiy@nure.ua", "lehatish@gmail.com," ],
    "sections" : [ {
      "heading" : null,
      "text" : "I. INTRODUCTION\nData processing tasks that deal with data given not in a numerical form have become really popular nowadays [1, 2]. One can see frequently this sort of tasks in economics, sociology, education and medicine [3-12]. Well-known clustering methods (such as k-means [13, 14], FCM [15, 16], EM-algorithm [17, 18]) usually use an approach based on replacement of linguistic variables by their ranks. But this approach turns out to be incorrect in most cases because it assumes equality of distances between neighboring numerical ranks (which is not always true).\nAn approach that seems more natural is developed by R.K. Brouwer [19, 20] and based on maximization of a likelihood function. A constraint of this method is an assumption about the Gaussian distribution of initial data which is not fulfilled in many real-world applications as well as a way of likelihood calculation for ordinal variables.\nAn algorithm of fuzzy clustering data given on the ordinal scale based on membership and likelihood functions sharing is proposed in this article. Initial information for solving this task is an ordered sequence of linguistic variables\n1 2, ,..., ,mx x x 1 ... 1 1 ...l l l m       where lx is a linguistic variable and l is a corresponding rank.\nIt was introduced in [21-23] to carry out fuzzification procedures for input data based on the occurrence frequency distribution analysis of specific linguistic variables for ordinal data processing. It was also supposed that these distributions were subject to the Gaussian law. An approach was proposed in [24] that was not associated with the hypothesis of normal distribution which will be used in the future work. Thus, initial data for solving the fuzzy clustering task is a sample of images formed by N n  dimensional feature vectors  (1), (2),..., ( ),..., ( )X x x x k x N where 1 2{ , ,..., ,..., }j NX x x x x , 1,...,j N , { }, 1,..., ; 1,..., l j jkx x k n l m   is a rank of a specific value of a\nlinguistic variable in the k  th coordinate of the n  dimensional space for the j  th observation.\nA result of this clustering algorithm is partition of an initial data array X into c clusters with membership levels ijw of the j  th feature vector to the i  th cluster.\nThe remainder of this paper is organized as follows: Section 2 describes some basic concepts of likelihood and probability. Section 3 describes a fuzzy clustering algorithm based on membership and likelihood functions. Section 4\ndescribes calculation of the conditional probability and the initial data fuzzification. Section 5 presents several synthetic and real-world applications to be solved with the help of the proposed method. Conclusions and future work are given in the final section.\nII. LIKELIHOOD AND PROBABILITY\nThere are several basic approaches to data clustering such as hierarchical clustering, metric clustering, iterative clustering etc. [25]. Iterative clustering is used in many domains wherein an algorithm detects the best clusters objects may belong to.\nLet’s consider a rather simple example where each observation has four attributes 1 2 3 4, , ,x x x x . Let’s suppose that they are mutually independent. Then a task of the iteration clustering may be reduced to a task of finding a cluster y via maximization of likelihood 1 2 3 4( | )P y x x x x for each observation with features 1 2 3 4, , ,x x x x . According to the Bayesian formula, this likelihood can be calculated like\n1 2 3 4 1 2 3 4\n1 2 3 4\n( | ) ( )( | ) ( ) P x x x x y P y P y x x x x P x x x x  (1)\nwhich means that finding a cluster y via maximization of likelihood 1 2 3 4( | )P y x x x x is equivalent to solving this task via maximization of conditional probability 1 2 3 4( | )P x x x x y . Moreover, an assumption about the fact that features are mutually independent allows writing down an obvious relation:\n1 2 3 4 1 2 3 4( | ) ( | ) ( | ) ( | ) ( | )P x x x x y P x y P x y P x y P x y . (2)\nTherefore a problem of finding the cluster y is a problem of maximizing the right side of the equation (2).\nThus, a problem of clusters’ finding is solved via maximization of a product of individual conditional probabilities for observation’s features. It should be noted that the probability ( | )jP x y defines the fact how often an observation\njx appears in a sample with all equal feature values in the cluster y . In other words, ( | )jP x y is a certain kind of occurrence frequency for jx with equal parameters’ values in the cluster y ."
    }, {
      "heading" : "III. A FUZZY CLUSTERING ALGORITHM OF ORDINAL DATA BASED ON MEMBERSHIP AND LIKELIHOOD FUNCTIONS",
      "text" : "The proposed algorithm has a rather similar algorithmic structure to FCM.\nThe clustering task can be solved with the help of FCM for quantitative characteristics by minimization of an objective function\n2\n1 1\nc N\nij j i i j Q w x v     (3)\nunder constraints\n1\n1\n0, 1,..., ; 1,..., ;\n1, 1,..., ;\n0, 1,...,\nij\nc\nij i N\nij j\nw i c j N\nw j N\nw i c\n\n\n    \n  \n  \n\n\n(4)\nwhere ijw is a membership level of the j  th observation to the i  th cluster,  is a non-negative fuzzifier (a fuzzification parameter). A membership level and clusters’ prototypes are calculated according to\n2 1\n1\n1 , 1,..., ; 1,...,tj c\nj t\ni j i\nw t c j N x v\nx v\n \n             \n,(5)\n1\n1\n, 1,...,\nN\ntj j j\nt N\ntj j\nw x v t c\nw\n\n\n\n\n   \n . (6)\nOne can see from the expressions (5) and (6) that a distance between an observation and a corresponding cluster centroid iv is used while calculating a membership level ijw of a specific observation to a cluster. Then iv should be recalculated based on membership levels ijw to clusters. The calculations are carried out iteratively until a stopping condition for the algorithm is met.\nAn idea of the proposed algorithm consists in the fact that observations’ likelihoods are used for defining clusters instead of using distances (like that happens in FCM). Thus, the task is solved via maximization of an objective function\n1 1\nc N\nij ij i j Q w L     (7)\nor minimization\n1 1\nc N\nij ij i j Q w U     (8)\nunder constraints\n1\n1\n0, 1,..., ; 1,..., ;\n1, 1,..., ;\n0, 1,...,\nij\nc\nij i N\nij j\nw i c j N\nw j N\nw i c\n\n\n    \n  \n  \n\n\n(9)\nwhere ijL stands for a membership likelihood of the j  th observation to the i  th cluster; ijU stands for a logarithm of dissimilarity for the j  th observation with the i  th cluster.\nThe likelihood ijL in (7) is calculated according to\n1\nn\nij ijk k L p   (10)\nwhere ijkp is a conditional probability for occurrence of a certain value of the k  th feature for the j  th observation in the i  th cluster. It’s calculated in the form of\n( | )ijk jk ip P x y . (11)\nThe logarithm of dissimilarity in (8) is defined as\nlnij ijU L  (12)\nwherein the objective function (8) can be written down in the form\n1 1 1 1 1 1 11 ( ln ) ln .\nnc N c N c N n\nij ij ij ijk ij ijk i j i j i j kk Q w U w p w p                  (13)\nTo compute ijw , one should use an expression [19]\n1 1\n1\n1 , 1,..., ; 1,...,tj mc\ntj\ni ij\nw t c j N U U \n             \n. (14)\nAnd membership functions (which are described below in Section 4) should be used for computing conditional probabilities ijkp .\nA basic drawback of this approach is the fact that an object under consideration is smeared into all existing clusters that leads to a loss of a physical sense in the ordinal scale. In this regard, it seems appropriate to recalculate all distances ( , )j id x v after calculating centroids, to put them in an ascending order and to choose the minimal value min min ( , )j id x v and the next value min ( , )j ld x v that follows the minimal one. Considering two minimal distances, we may use these formulas [24]\n2 min min\n2 2 min min min\n( , ) ,\n( , ) ( , ) j i\nji j i j l\nd x v w\nd x v d x v\n\n   (15)\n2 min\n2 2 min min min\n( , ) ( , ) ( , ) j l jl\nj i j l\nd x v w\nd x v d x v\n\n   . (16)\nSo, the algorithm may be performed as a sequence of steps:\n1. Initializing , 1,..., ; 1,..., ;ijkp i c j N    1,...,k n  with random values. 2. Calculating , 1,..., ; 1,...,ijw i c j N    according to the expression (14). 3. Calculating , 1,..., ; 1,..., ; 1,...,ijkp i c j N k n      with the help of the expression (23). 4. Steps 2 and 3 should be repeated iteratively until a condition is met  max _ _ij ij ijold new    . 5. Calculating all the distances ( , ) || ||j i j id x v x v  and choosing two minimal distances min min ( , )j id x v and\nmin ( , )j ld x v where l may take on values either 1i  or 1i  ;\n6. Calculating membership levels for jx to two neighboring clusters according to the formulas (15) and (16).\nIV. CALCULATION OF THE CONDITIONAL PROBABILITY AND THE INITIAL DATA FUZZIFICATION\nThe fuzzification process for a sequence of rank linguistic variables should be considered on an example of a onedimensional sample 1,...., Nx x where each observation jx may be assigned to one of the ranks l , 1,...,l m .\nLet a value jx that corresponds to the l  th rank occur in the sample lN times. Then relative occurrence frequencies of the l  th rank are taken into consideration\nl l\nN f\nN  (17)\nwherein the condition\n1 1\nm\ni i f   (18)\nis naturally met.\nAveraged occurrence frequencies of observations are formed based on relative frequencies. It’s really handy to use a recurrent ratio\n1 1\n1 1 0.5 , 0.5( ), 2,...,l l l l c f c c f f l m        (19)\nfor their calculation.\nThen all ordinal data is replaced by the corresponding averaged occurrence frequencies for observations. A fuzzification stage can be presented in the form of a histogram in Fig.1.\nFig.1. A distribution histogram of ordinal values by occurrence frequency in the sample.\nAssuming that a membership level  1,..., ; 1,...,ij i c j N     of observations to clusters is known, a mode value is calculated for each feature in each cluster * , 1,..., ; 1,...,ikx i c k n    .\nConsidering the obtained modes, an asymmetric membership function is built.\n1) If * 0.5ikx  , the membership function looks similar to Fig.2 and can be described by a formula\n* *\n* *\n*\n, [0, ],\n2 , [0, ].\nj ik\nik ijk\nik j ik\nik\nx x x x x x\nx x x\n\n \n   \n\n(20)\nFig.2. The membership function for a sample of rank values in case of * 0.5ikx  .\n2) If * 0.5ikx  , the membership function looks similar to Fig.3 and can be described by a formula\n* *\n* * *\n1 , [ ,1], 1 2 1\n, [ ,1]. 1\nj ik\nik ijk\nj ik ik\nik\nx x x\nx x x\nx x x\n    \n   \n(21)\nFig.3. The membership function for a sample of rank values in case of * 0.5ikx  .\n3) If * 0.5ikx  , the membership function looks similar to Fig.4 and can be described by a formula\n* *\n* *\n, [0, ],\n1 , [ ,1]. 1\nj ik\nik ijk\nj ik ik\nx x x x x\nx x x\n\n \n    \n(22)\nFig.4. The membership function for a sample of rank values in case of * 0.5ikx  .\nSince the conditional probability ijkp directly depends on the occurrence frequency of a specific feature value in the sample and ordinal data is clearly given in a specific order (from the smallest value to the largest one), it may be said that\nijk ijkp  . (23)\nV. EXPERIMENTS\nA. Students’ performance To prove the efficiency of the introduced algorithm, we used data describing students’ performance. The data contains grades in three courses for 1108 freshmen students in one of Ukrainian universities.\nCentroids were determined for each rank (grade) for each value. Results can be found in Table 1.\nThen the data was divided into four clusters: ”Excellent”, “Good”, “Fair” and “Poor”. Clusters’ centroids were later obtained as the results of the proposed method (Table 2).\n15% of students were assigned to the “Excellent” cluster; 26% of students were assigned to the “Good” cluster; 30% of students were assigned to the “Fair” cluster; and 29% of students were assigned to the “Poor” cluster. It would be also interesting to mention that the experiment’s results have a 98% match with classification previously performed by the dean’s office.\nB. Fuzzy clustering ordinal data based on membership and likelihood functions sharing We chose 3 labeled data samples from the UCI repository for our experiment. A dataset Iris contains 150 observations divided into 3 classes where each observation contains 4 features. A dataset Wine contains 178 observations’ vectors divided into 3 clusters where each observation contains 13 features. A dataset Nursery consists of 12958 observations divided into 4 classes where each observation contains 8 features given in the ordinal scale. The datasets Iris and Wine were transformed into the ordinal scale to check the proposed approach. Since every data sample has correct classification labels, clustering efficiency was measured as % of accuracy with respect to benchmark partition after the defuzzification procedure.\nFor our tests, we selected the FCM algorithm with a parameter 2  , a modification of FCM for ordinal data (FCMO) [19] and the proposed fuzzy clustering method (LMFCM). Every cell in Table 3 describes the final result in the form of an average value, a minimum value and a maximum value for a sequence of 50 tests.\nThe obtained results demonstrate that LMFCM is more stable and its efficiency is higher when compared to FCM and FCMO. Although it should be noted that the results might also depend greatly on a size of a training set.\nTable 3. Comparison of clustering accuracy for different data samples\nMethods Iris Wine Nursary\navg max min avg max min avg max min\nFCM\n(β =2)\n70 75 35 69 74 33 62 67 36\nFCMO 83 93 58 70 73 45 71 79 43\nLMFCM 85 95 55 71 75 41 74 77 45\nC. Automated processing of thermal images for electrical equipment diagnosing\nWe used the fuzzy clustering method for ordinal data based on membership and likelihood functions sharing to solve a task of automated processing of thermal images for electrical equipment diagnosing. The data was segmented at the first stage and then clustered.\nDiagnosis and identification of electrical equipment defects is a topical issue nowadays. Any electrical equipment contains a large number of different elements, contacts and connections. Their weakening, oxidation, load imbalance and overload, burnout wiring insulation, etc. may lead not only to equipment malfunction, but it can also cause an accident.\nTimely removal of electrical defects can increase its lifetime and avoid costs for eliminating consequences of an accident.\nThermal imaging diagnostics (a method of non-destructive heat testing) makes it possible to determine the electrical malfunction at early stages of their development. It is based on the analysis of temperature fields which are obtained with the help of portable infrared cameras (thermal imagers). This technique allows carrying out diagnostics while your equipment is on that makes it possible to obtain a more complete picture of existing and emerging defects that are difficult to observe with a naked eye (Fig.5).\nSuch types of defects can be defined as a violation of electrical elements’ encapsulation, overheating of contact connections, deterioration of an internal insulation of windings, a breakdown of elements’ sections, inputs’ defects, etc. with the help of the thermal imaging diagnosis. Examples of possible defects detected by the thermal imaging diagnostics are shown in Fig.7-10.\nFig.5. An example of thermal imaging for phase diagnostics in an apparatus of protection and control movement for a mine elevator installation (a photo).\nFig.6. An example of thermal imaging for phase diagnostics in an apparatus of protection and control movement for a mine elevator installation (a thermogram).\nFig.7. Examples of defects which can be determined during the thermal imaging diagnostics. Exceeding a permissible temperature of a conductor for one phase (a photo).\nFig.8. Examples of defects which can be determined during the thermal imaging diagnostics. Exceeding a permissible temperature of a conductor for one phase (a thermogram).\nFig.9. Examples of defects which can be determined during the thermal imaging diagnostics.Overheating of a terminal box (a photo).\nFig.10. Examples of defects which can be determined during the thermal imaging diagnostics..Overheating of a terminal box (a thermogram).\nSome privileges of this approach could be enumerated:\n- carrying out diagnostics of electrical equipment in an operating mode (without voltage shutdown);\n- detection of defects at early stages of their appearance and development;\n- forecasting occurrence of defects;\n- low effort required for the diagnostics’ production;\n- safety of workers during the diagnostics;\n- there is no need to arrange a separate workplace;\n- an ability to execute a large amount of work in a relatively short period of time;\n- high performance and diagnostics’ descriptiveness.\nAnalysis data is a collection of about 5000 thermal images. Some of these thermal images can be seen in Fig.11.\nFig.11. Examples of thermograms.\nThis problem implies the initial data partition into clusters to determine defects of electrical equipment and to and to develop a sequence of measures for their removal.\nThe task is solved with the help of two-stage clustering of every image. Images’ segmentation is performed at the first stage. An image is represented in a color space ' ' 'L a b for this purpose. Here 'L stands for color intensity, 'a displays a color of a pixel in the red-and-green axis, and 'b displays a pixel’s color in the blue-and-yellow axis. After pixelization, an image is a two-dimensional sample which is then divided into clusters using FCM. An example of a thermogram after segmentation is shown in Fig.13.\nRanking is later performed for every pixel of the segmented image according to a thermal image palette of colors that improves accuracy and descriptiveness for further clustering. Moreover, this approach solves a task of a choice of many different palettes during a thermal imaging shooting.\nAfter the ranking procedure for the detected segments is over, the data becomes ordinal. Then the adaptive fuzzy clustering method for ordinal data based on membership and likelihood functions sharing is used.\nImplementation of the system made it possible to detect defects of electrical equipment at early stages, increased a speed and efficiency of its diagnostics, and reduced equipment downtime.\nFig.12. Segmenting a thermogram. An initial view of a thermogram.\nFig.13. Segmenting a thermogram. A thermogram after segmentation.\nVI. CONCLUSION\nThe fuzzy clustering algorithm for data given in the ordinal scale based on membership and likelihood functions sharing is proposed. This approach allows effective information processing due to consideration of the nature of the processed data distribution. The fuzzification method and a way of defining a conditional probability ijkp of specific observations’ occurrence in every cluster allow quickly and accurately classifying a sample. The main advantage of this method is the fact that it’s robust to outliers because of usage of ordered values while constructing membership functions.\nREFERENCES [1] R. Xu and D.C. Wunsch, Clustering. Hoboken, NJ: John Wiley & Sons, Inc. 2009. [2] C.C. Aggarwal and C.K. Reddy, Data Clustering. Algorithms and Application. Boca Raton: CRC Press, 2014. [3] Zh. Hu, Ye.V. Bodyanskiy, and O.K. Tyshchenko, “A Cascade Deep Neuro-Fuzzy System for High-Dimensional Online\nPossibilistic Fuzzy Clustering”, Proc. of the XI-th International Scientific and Technical Conference “Computer Science and Information Technologies” (CSIT 2016), 2016, Lviv, Ukraine, pp.119-122. [4] Zh. Hu, Ye.V. Bodyanskiy, and O.K. Tyshchenko, “A Deep Cascade Neuro-Fuzzy System for High-Dimensional Online Fuzzy Clustering”, Proc. of the 2016 IEEE First Int. Conf. on Data Stream Mining & Processing (DSMP), 2016, Lviv, Ukraine, pp.318-322. [5] Ye. Bodyanskiy, O. Tyshchenko, and D. Kopaliani, “An evolving neuro-fuzzy system for online fuzzy clustering”, Proc. Xth Int. Scientific and Technical Conf. “Computer Sciences and Information Technologies (CSIT’2015)”, 2015, pp.158-161. [6] Ye. Bodyanskiy, O. Tyshchenko, and D. Kopaliani, “Adaptive learning of an evolving cascade neo-fuzzy system in data stream mining tasks”, in Evolving Systems, 2016, vol. 7(2), pp.107-116. [7] Ye. Bodyanskiy, O. Tyshchenko, and D. Kopaliani, “An Extended Neo-Fuzzy Neuron and its Adaptive Learning Algorithm”, in I.J. Intelligent Systems and Applications (IJISA), 2015, vol.7(2), pp.21-26. [8] Ye. Bodyanskiy, O. Tyshchenko, and D. Kopaliani, “A hybrid cascade neural network with an optimized pool in each cascade”, in Soft Computing. A Fusion of Foundations, Methodologies and Applications (Soft Comput), 2015, vol. 19(12), pp.3445-3454. [9] Zh. Hu, Ye.V. Bodyanskiy, O.K. Tyshchenko, and O.O. Boiko, “An Evolving Cascade System Based on a Set of Neo-Fuzzy Nodes”, in International Journal of Intelligent Systems and Applications (IJISA), vol. 8(9), 2016, pp.1-7. [10] Zhengbing Hu, Yevgeniy V. Bodyanskiy, O.K. Tyshchenko, Viktoriia O. Samitova,\"Fuzzy Clustering Data Given in the Ordinal Scale\", International Journal of Intelligent Systems and Applications(IJISA), Vol.9, No.1, pp.67-74, 2017. DOI: 10.5815/ijisa.2017.01.07. [11] O. Tyshchenko, “A Reservoir Radial-Basis Function Neural Network in Prediction Tasks”, Automatic Control and Computer Sciences, Vol. 50, No. 2, pp. 65-71, 2016. [12] Ye. Bodyanskiy, O. Tyshchenko, A. Deineko, “An Evolving Radial Basis Neural Network with Adaptive Learning of Its Parameters and Architecture”, Automatic Control and Computer Sciences, Vol. 49, No. 5, pp. 255-260, 2015. [13] Z.B. MacQueen, “Some Methods of Classification and Analysis of Multivariate Observations”, Proc. of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, 1967, pp.281-297. [14] Lloyd S. P., Least Squares Quantization in PCM // IEEE Transactions on Information Theory. – 1982. – vol. IT-28. – P. 129- 137. [15] Bezdek J.C., Pattern Recognition with Fuzzy Objective Function Algorithms. – N.Y.:Plenum Press, 1981. – 272p. [16] Jang J.-Sh. R., Sun Ch.-T., Mizutani E., Neuro-Fuzzy and Soft Computing. – Upper Saddle River, NJ: Prentice Hall, 1997. -\n614 p.\n[17] Dempster A. P., Laird N. M., and R. D. B., Maximum-Likelihood from Incomplete Data via the EM Algorithm // Journal of the Royal Statistical Society. – 1977. – vol.B. – P. 1-38 [18] Zhong S. and Ghosh J., A Unified Framework for Model-based Clustering // Journal of Machine Learning Research. – 2003. – vol. 4. – P. 1001-1037. [19] M. Lee and R. K. Brouwer, “Likelihood Based Fuzzy Clustering for Data Sets of Mixed Features”, IEEE Symposium on Foundations of Computational Intelligence (FOCI 2007), 2007, pp.544-549. [20] L. Mahnhoon, “Mapping of Ordinal Feature Values to Numerical Values through Fuzzy Clustering”, in IEEE Trans. on Fuzzy Systems, 2008, pp.732-737. [21] Brouwer R.K., Pedrycz W. A feedforward neural network for mapping vectors to fuzzy sets of vectors // Proc.Int.Conf. on Artificial Neural Networks and Neural Information Processing ICANN/ICOMIP 2003. – Istanbul, Turkey, 2003. – P.45-48. [22] B.S. Butkiewicz, “Robust fuzzy clustering with fuzzy data”, in Lecture Notes in Computer Science, Vol. 3528, 2005, pp.7682. [23] R.K. Brouwer, “Fuzzy set covering of a set of ordinal attributes without parameter sharing”, in Fuzzy Sets and Systems, 2006, vol. 157(13), pp.1775-1786. [24] Ye.V. Bodyanskiy, V.A. Opanasenko, and А.N. Slipchenko, “Fuzzy clustering for ordinal data”, in Systemy Obrobky Informacii, 2007, Iss. 4(62), pp.5-9. (in Russian) [25] F. Hoeppner, F. Klawonn, R. Kruse, and T. Runkler, Fuzzy Clustering Analysis: Methods for Classification, Data Analysis and Image Recognition. Chichester: John Wiley & Sons, 1999."
    } ],
    "references" : [ {
      "title" : "Data Clustering. Algorithms and Application",
      "author" : [ "C.C. Aggarwal", "C.K. Reddy" ],
      "venue" : "Boca Raton: CRC Press,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2014
    }, {
      "title" : "Tyshchenko, “A Cascade Deep Neuro-Fuzzy System for High-Dimensional Online Possibilistic Fuzzy Clustering",
      "author" : [ "Zh. Hu", "Ye.V. Bodyanskiy", "O.K" ],
      "venue" : "Proc. of the XI-th International Scientific and Technical Conference “Computer Science and Information Technologies”",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2016
    }, {
      "title" : "Tyshchenko, “A Deep Cascade Neuro-Fuzzy System for High-Dimensional Online Fuzzy Clustering",
      "author" : [ "Zh. Hu", "Ye.V. Bodyanskiy", "O.K" ],
      "venue" : "Proc. of the 2016 IEEE First Int. Conf. on Data Stream Mining & Processing (DSMP),",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2016
    }, {
      "title" : "Kopaliani, “An evolving neuro-fuzzy system for online fuzzy clustering",
      "author" : [ "Ye. Bodyanskiy", "O. Tyshchenko" ],
      "venue" : "Proc. Xth Int. Scientific and Technical Conf. “Computer Sciences and Information Technologies (CSIT’2015)”,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2015
    }, {
      "title" : "Kopaliani, “Adaptive learning of an evolving cascade neo-fuzzy system in data stream mining tasks",
      "author" : [ "Ye. Bodyanskiy", "O. Tyshchenko" ],
      "venue" : "Evolving Systems, 2016,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2016
    }, {
      "title" : "Kopaliani, “An Extended Neo-Fuzzy Neuron and its Adaptive Learning Algorithm",
      "author" : [ "Ye. Bodyanskiy", "O. Tyshchenko" ],
      "venue" : "in I.J. Intelligent Systems and Applications (IJISA),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2015
    }, {
      "title" : "Kopaliani, “A hybrid cascade neural network with an optimized pool in each cascade",
      "author" : [ "Ye. Bodyanskiy", "O. Tyshchenko" ],
      "venue" : "Soft Computing. A Fusion of Foundations, Methodologies and Applications (Soft Comput),",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2015
    }, {
      "title" : "Boiko, “An Evolving Cascade System Based on a Set of Neo-Fuzzy Nodes",
      "author" : [ "Zh. Hu", "Ye.V. Bodyanskiy", "O.K. Tyshchenko", "O.O" ],
      "venue" : "in International Journal of Intelligent Systems and Applications (IJISA),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2016
    }, {
      "title" : "A Reservoir Radial-Basis Function Neural Network in Prediction Tasks",
      "author" : [ "O. Tyshchenko" ],
      "venue" : "Automatic Control and Computer Sciences,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2016
    }, {
      "title" : "An Evolving Radial Basis Neural Network with Adaptive Learning of Its Parameters and Architecture",
      "author" : [ "Ye. Bodyanskiy", "O. Tyshchenko", "A. Deineko" ],
      "venue" : "Automatic Control and Computer Sciences,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Some Methods of Classification and Analysis of Multivariate Observations",
      "author" : [ "Z.B. MacQueen" ],
      "venue" : "Proc. of the Fifth Berkeley Symposium on Mathematical Statistics and Probability,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1967
    }, {
      "title" : "Least Squares Quantization in PCM",
      "author" : [ "P. Lloyd S" ],
      "venue" : "IEEE Transactions on Information Theory. – 1982. – vol",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1982
    }, {
      "title" : "Pattern Recognition with Fuzzy Objective Function",
      "author" : [ "J.C. Bezdek" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1981
    }, {
      "title" : "Neuro-Fuzzy and Soft Computing",
      "author" : [ "R. Jang J.-Sh", "Ch.-T. Sun", "E. Mizutani" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1997
    }, {
      "title" : "Maximum-Likelihood from Incomplete Data via the EM Algorithm",
      "author" : [ "P. Dempster A", "M. Laird N", "B.R. D" ],
      "venue" : "Journal of the Royal Statistical Society",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1977
    }, {
      "title" : "A Unified Framework for Model-based Clustering",
      "author" : [ "S. Zhong", "J. Ghosh" ],
      "venue" : "Journal of Machine Learning Research",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2003
    }, {
      "title" : "Likelihood Based Fuzzy Clustering for Data Sets of Mixed Features",
      "author" : [ "M. Lee", "R.K. Brouwer" ],
      "venue" : "IEEE Symposium on Foundations of Computational Intelligence (FOCI",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2007
    }, {
      "title" : "Mapping of Ordinal Feature Values to Numerical Values through Fuzzy Clustering",
      "author" : [ "L. Mahnhoon" ],
      "venue" : "IEEE Trans. on Fuzzy Systems,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2008
    }, {
      "title" : "A feedforward neural network for mapping vectors to fuzzy sets of vectors",
      "author" : [ "R.K. Brouwer", "W. Pedrycz" ],
      "venue" : "Proc.Int.Conf. on Artificial Neural Networks and Neural Information Processing ICANN/ICOMIP",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2003
    }, {
      "title" : "Robust fuzzy clustering with fuzzy data",
      "author" : [ "B.S. Butkiewicz" ],
      "venue" : "Notes in Computer Science,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2005
    }, {
      "title" : "Fuzzy set covering of a set of ordinal attributes without parameter sharing",
      "author" : [ "R.K. Brouwer" ],
      "venue" : "Fuzzy Sets and Systems,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2006
    }, {
      "title" : "Opanasenko, and А.N. Slipchenko, “Fuzzy clustering for ordinal data",
      "author" : [ "V.A. Ye.V. Bodyanskiy" ],
      "venue" : "Systemy Obrobky Informacii,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2007
    }, {
      "title" : "Fuzzy Clustering Analysis: Methods for Classification, Data Analysis and Image Recognition",
      "author" : [ "F. Hoeppner", "F. Klawonn", "R. Kruse", "T. Runkler" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1999
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "INTRODUCTION Data processing tasks that deal with data given not in a numerical form have become really popular nowadays [1, 2].",
      "startOffset" : 121,
      "endOffset" : 127
    }, {
      "referenceID" : 1,
      "context" : "One can see frequently this sort of tasks in economics, sociology, education and medicine [3-12].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 2,
      "context" : "One can see frequently this sort of tasks in economics, sociology, education and medicine [3-12].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 3,
      "context" : "One can see frequently this sort of tasks in economics, sociology, education and medicine [3-12].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 4,
      "context" : "One can see frequently this sort of tasks in economics, sociology, education and medicine [3-12].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 5,
      "context" : "One can see frequently this sort of tasks in economics, sociology, education and medicine [3-12].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 6,
      "context" : "One can see frequently this sort of tasks in economics, sociology, education and medicine [3-12].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 7,
      "context" : "One can see frequently this sort of tasks in economics, sociology, education and medicine [3-12].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 8,
      "context" : "One can see frequently this sort of tasks in economics, sociology, education and medicine [3-12].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 9,
      "context" : "One can see frequently this sort of tasks in economics, sociology, education and medicine [3-12].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 10,
      "context" : "Well-known clustering methods (such as k-means [13, 14], FCM [15, 16], EM-algorithm [17, 18]) usually use an approach based on replacement of linguistic variables by their ranks.",
      "startOffset" : 47,
      "endOffset" : 55
    }, {
      "referenceID" : 11,
      "context" : "Well-known clustering methods (such as k-means [13, 14], FCM [15, 16], EM-algorithm [17, 18]) usually use an approach based on replacement of linguistic variables by their ranks.",
      "startOffset" : 47,
      "endOffset" : 55
    }, {
      "referenceID" : 12,
      "context" : "Well-known clustering methods (such as k-means [13, 14], FCM [15, 16], EM-algorithm [17, 18]) usually use an approach based on replacement of linguistic variables by their ranks.",
      "startOffset" : 61,
      "endOffset" : 69
    }, {
      "referenceID" : 13,
      "context" : "Well-known clustering methods (such as k-means [13, 14], FCM [15, 16], EM-algorithm [17, 18]) usually use an approach based on replacement of linguistic variables by their ranks.",
      "startOffset" : 61,
      "endOffset" : 69
    }, {
      "referenceID" : 14,
      "context" : "Well-known clustering methods (such as k-means [13, 14], FCM [15, 16], EM-algorithm [17, 18]) usually use an approach based on replacement of linguistic variables by their ranks.",
      "startOffset" : 84,
      "endOffset" : 92
    }, {
      "referenceID" : 15,
      "context" : "Well-known clustering methods (such as k-means [13, 14], FCM [15, 16], EM-algorithm [17, 18]) usually use an approach based on replacement of linguistic variables by their ranks.",
      "startOffset" : 84,
      "endOffset" : 92
    }, {
      "referenceID" : 16,
      "context" : "Brouwer [19, 20] and based on maximization of a likelihood function.",
      "startOffset" : 8,
      "endOffset" : 16
    }, {
      "referenceID" : 17,
      "context" : "Brouwer [19, 20] and based on maximization of a likelihood function.",
      "startOffset" : 8,
      "endOffset" : 16
    }, {
      "referenceID" : 18,
      "context" : "It was introduced in [21-23] to carry out fuzzification procedures for input data based on the occurrence frequency distribution analysis of specific linguistic variables for ordinal data processing.",
      "startOffset" : 21,
      "endOffset" : 28
    }, {
      "referenceID" : 19,
      "context" : "It was introduced in [21-23] to carry out fuzzification procedures for input data based on the occurrence frequency distribution analysis of specific linguistic variables for ordinal data processing.",
      "startOffset" : 21,
      "endOffset" : 28
    }, {
      "referenceID" : 20,
      "context" : "It was introduced in [21-23] to carry out fuzzification procedures for input data based on the occurrence frequency distribution analysis of specific linguistic variables for ordinal data processing.",
      "startOffset" : 21,
      "endOffset" : 28
    }, {
      "referenceID" : 21,
      "context" : "An approach was proposed in [24] that was not associated with the hypothesis of normal distribution which will be used in the future work.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 22,
      "context" : "[25].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "To compute ij w , one should use an expression [19]",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 21,
      "context" : "Considering two minimal distances, we may use these formulas [24]",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 16,
      "context" : "For our tests, we selected the FCM algorithm with a parameter 2   , a modification of FCM for ordinal data (FCMO) [19] and the proposed fuzzy clustering method (LMFCM).",
      "startOffset" : 116,
      "endOffset" : 120
    } ],
    "year" : 2017,
    "abstractText" : "A task of clustering data given on the ordinal scale under conditions of overlapping clusters has been considered. It’s proposed to use an approach based on membership and likelihood functions sharing. A number of performed experiments proved effectiveness of the proposed method. The proposed method is characterized by robustness to outliers due to a way of ordering values while constructing membership functions.",
    "creator" : "PScript5.dll Version 5.2.2"
  }
}