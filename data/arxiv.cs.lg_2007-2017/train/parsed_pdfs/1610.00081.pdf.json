{
  "name" : "1610.00081.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction",
    "authors" : [ "Junbo Zhang", "Yu Zheng", "Dekang Qi" ],
    "emails" : [ "v-deq}@microsoft.com" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Predicting the flow of crowds in a city is of great importance to traffic management and public safety. For instance, massive people streamed into a strip region at the New Year’s Eve celebrations in Shanghai in 2015, resulting in a catastrophic stampede killing 36 people. In mid-July of 2016, hundreds of “Pokemon Go” players ran through the Central Park of NYC in hopes of catching a particularly rare digital monster, leading to a dangerous stampede there. If being able to predict the crowd flow in a region, we can avoid such tragedies by launching some emergency mechanisms, such as conducting traffic control, sending warnings to people, or evacuating people, in advance.\nIn this paper, we predict two types of crowd flows (Zhang et al. 2016): in-flow and out-flow, as shown in Figure 1. Inflow means the total traffic of crowds entering a region from other place during a given time interval. On the contrary, outflow denotes the total traffic of crowds leaving a region for ∗Yu Zheng is the correspondence author of this paper. †The research was done when the third author was an intern in Microsoft Research.\nother places during a given time interval. Both flows track the transition of crowds among regions. Knowing them is very beneficial for risk assessment and traffic management. Both flows can be measured by the number of pedestrians, or the number of cars driven on roads, or the number of people traveling in public transportation systems (e.g., metro, bus), or all of them together if data is available. Figure 1(b) presents an example. We can use mobile phone signals to measure the number of walkers, showing that the in-flow and out-flow of r2 are (3, 1) respectively. Similarly, using GPS trajectories of the vehicles, the two types flows are (0, 3) respectively.\nSimultaneously forecasting the in-flow and out-flow of crowds in each and every region throughout a city, however, is very challenging, affected by the following three complex factors:\n1. Spatial dependencies. The in-flow of Region r2 (shown in Figure 1) is affected by out-flows of its nearby regions (like r1) as well as distant regions. Likewise, the out-flow of r2 would affect the in-flows of other regions (e.g., r3). The in-flow of region r2 would affect its own out-flow as well. 2. Temporal dependencies. The flow of crowds in a region is affected by that of both recent, near and even distant time intervals. For instance, a traffic congestion occurred at 8am will affect that of 9am. In addition, traffic conditions in morning rush hours may be simi-lar in consecutive workdays, repeating every 24 hours. Furthermore, the morning rush hours may gradually arrive later as winter comes. When temperature grad-ually drops and the time of sun rise postpones, people get up later and later. 3. External influence. Some external factors, such as weather conditions and events may change the flow of crowds tremendously in different regions of a city. ar X\niv :1\n61 0.\n00 08\n1v 1\n[ cs\n.A I]\n1 O\nct 2\n01 6\nTo tackle these challenges, we propose a deep spatiotemporal residual network (ST-ResNet) model to collectively predict in-flow and out-flow of the crowds in each and every region. Our contributions are four-fold:\n• ST-ResNet employs convolution-based residual networks to model the nearby and distant spatial dependencies between any two regions in a city, while ensuring the models prediction accuracy not comprised by the deep structure of the neural network.\n• We summarize the temporal properties of crowd flows into three categories, consisting of temporal closeness, period, and trend. ST-ResNet uses three residual networks to model these properties, respectively.\n• ST-ResNet dynamically aggregates the output of the three aforementioned networks, assigning different weights to different branches and regions. The aggregation is further combined with external factors (e.g., weather).\n• We evaluate our approach using Beijing taxicabs trajectories and meteorological data, and NYC bike trajectory data. The results demonstrate the advantages of our approach compared with 6 baselines."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "In this section, we briefly revisit the crowd flows prediction problem (Zhang et al. 2016; Hoang, Zheng, and Singh 2016) and formally introduce the deep residual learning (He et al. 2016)."
    }, {
      "heading" : "2.1 Formulation of Crowd Flows Problem",
      "text" : "Definition 1 (Region (Pang et al. 2011)) There are many definitions of a location in terms of different granularities and semantic meanings. In this study, we partition a city into an I×J grid map based on the longitude and latitude where a grid denotes a region, as shown in Figure 2(a).\nDefinition 2 (In- & Out-flows (Zhang et al. 2016)) Let P be a collection of trajectories at the tth time interval. For a grid (i, j) that lies at the ith row and the jth column, the in-flow and out-flow of the crowds at the time interval t are defined respectively as\nxin,i,jt = ∑ Tr∈P |{k > 1|gk−1 6∈ (i, j) ∧ gk ∈ (i, j)}|\nxout,i,jt = ∑ Tr∈P |{k ≥ 1|gk ∈ (i, j) ∧ gk+1 6∈ (i, j)}|\nwhere Tr : g1 → g2 → · · · → g|Tr| is a trajectory in P, and gk is the geospatial coordinate; gk ∈ (i, j) means the point gi lies within grid (i, j), and vice versa; | · | denotes the cardinality of a set.\nAt the tth time interval, in-flow and out-flow in all I × J regions can be denoted as a tensor Xt ∈ R2×I×J where (Xt)0,i,j = x in,i,j t , (Xt)1,i,j = x out,i,j t . The in-flow matrix is shown in Figure 2(b). Formally, for a dynamical system over a spatial region represented by a I × J grid map, there are 2 types of flows in each grid over time. Thus, the observation at any time can be represented by a tensor X ∈ R2×I×J . Problem 1 Given the historical observations {Xt|t = 0, · · · , n− 1}, predict Xn."
    }, {
      "heading" : "2.2 Deep Residual Learning",
      "text" : "Deep residual learning (He et al. 2015) allows convolution neural networks to have a super deep structure of over-100 layers, even over-1000 layers. And this method has shown state-of-the-art results on multiple challenging recognition tasks, including image classification, object detection, segmentation and localization (He et al. 2015).\nFormally, a residual unit with an identity mapping (He et al. 2016) is defined as:\nX(l+1) = X(l) + F(X(l)) (1)\nwhere X(l) and X(l+1) are the input and output of the lth residual unit, respectively; F is a residual function, e.g., a stack of two 3×3 convolution layers in (He et al. 2015). The central idea of the residual learning is to learn the additive residual function F with respect to X(l) (He et al. 2016)."
    }, {
      "heading" : "3 Deep Spatio-Temporal Residual Networks",
      "text" : "Figure 3 presents the architecture of ST-ResNet, which is comprised of four major components modeling the temporal closeness, period, trend, and external influence, respectively. As illustrated in the top-right part of Figure 3, we first\nturn in-flow and out-flow throughout a city at each time interval into a 2-channel image-like matrix respectively, using the approach introduced in Definitions 1 and 2. We then divide the time axis into three fragments, denoting recent time, near history and distant history. The 2-channel flow matrices of intervals in each time fragment are then fed into the first three components separately to model the aforementioned three temporal properties: closeness, period and trend, respectively. The first three components share the same network structure with a convolutional neural network followed by a sequence of Residual Unit. Such structure captures the spatial dependency between nearby and distant regions. In the external component, we manually extract some features from external datasets, such as weather conditions and events, feeding them into a two-layer fully-connected neural network. The outputs of the first three components are fused (XRes) based on a parameter matrix, which assigns dif-ferent weights to the results of different components in different regions. XRes is further integrated with the output of the external component XExt. Finally, the aggregation is mapped into [−1, 1] by a Tanh function."
    }, {
      "heading" : "3.1 Structures of the First Three Components",
      "text" : "The first three components (i.e. closeness, period, trend) share the same network structure, which is composed of two sub-components: convolution and residual unit, as shown in Figure 4.\nConvolution. A city usually has a very large size, containing many regions with different distances. Intuitively, the flow of crowds in nearby regions may affect each other, which can be effectively handled the convolutional neural network (CNN) that have shown its powerful ability to hierarchically capture spatial structural information (LeCun et al. 1998). In addition, subway systems and highways connect two locations with a far distance, leading to the dependency between distant regions. In order to capture the spatial dependency of any regions, we need to design a CNN with many layers because one convolution only accounts for spatial near dependencies, limited by the size of their kernels. The same problem also has been found in the video sequence generating task where the input and output have the same resolution (Mathieu, Couprie, and LeCun 2015). Several methods have been introduced to avoid the loss of resolution brought about by subsampling while preserving\ndistant dependencies (Long, Shelhamer, and Darrell 2015). Being different from the classical CNN, we do not use subsampling, but only convolutions (Jain et al. 2007). As shown in Figure 4(a), there are three multiple levels of feature maps which are connected with a few convolutions. We find that a node in the high-level feature map depends on nine nodes of the middle-level feature map, those of which depend on all nodes in the lower-level feature map (i.e. input). It means one convolution naturally captures spatial near dependencies, and a stack of convolutions can further captures distant dependencies, even citywide dependencies.\nThe closeness component in Figure 3 adopts a few 2- channel flows matrices of intervals in the recent time to model the temporal closeness dependence. Let the recent fragment be [Xt−lc ,Xt−(lc−1), · · · ,Xt−1], which is also known as the closeness dependent sequence. Formally, we first use a particular convolution (i.e. the Conv module shown in Figure 3) to merge them as follows,\nX(1)c = f  lc∑ j=1 W (1) cj ∗Xt−j + b (1) c  (2) where ∗ denotes the convolution operator; f is an activation function, e.g. the rectifier f(z) := max(0, z) (Krizhevsky, Sutskever, and Hinton 2012); W (1)c· , b (1) c are the parameters in the first layer. Residual Unit. As we known, very deep convolutional networks compromise the training effectiveness though the well-known activation function (e.g. ReLU) and regularization techniques are applied (Ioffe and Szegedy 2015; Krizhevsky, Sutskever, and Hinton 2012; Nair and Hinton 2010). On the other hand, we still need a very deep network to capture a very large citywide dependencies. For a typical crowd flows data, assume that the input size is 32× 32, and the kernel size of convolution is fixed to 3× 3, if we want to model citywide dependencies (i.e., each node in high-level layer depends on all nodes of the input), it needs more than 15 consecutive convolutional layers. To address this issue, we employ residual learning (He et al. 2015) in our model, which have been demonstrated to be very effective for training a super deep neural networks of over-1000 layers.\nIn our implementation, we mainly employ a residual unit that contains two combinations of “ReLU + Convolution (3 × 3 kernel)”, as shown in Figure 4(b). We also attempt Batch Normalization (BN) (Ioffe and Szegedy 2015) which are added before ReLU. Formally, we stack L residual units upon the convolution of Eq. 2 as follows,\nX(l+1)c = X (l) c + F(X(l)c ; θ(l)c ), l = 1, · · · , L (3)\nwhere F is the residual function, shown in Figure 4(b), and θ(l) is parameters of the lth residual unit. The output of the closeness component of Figure 3 is X(L+1)c .\nLikewise, using the above operations, we can construct the period and trend components of Figure 3. Assume that there are lp time intervals from the period fragment and the period is p. Therefore, the period dependent sequence is [Xt−lp·p,Xt−(lp−1)·p, · · · ,Xt−p]. With the convolutional\noperation and L residual units like in Eqs. 2 and 3, the output of the period component is X(L+1)p . Meanwhile, the output of the trend component is X(L+1)q with the input [Xt−lq·q,Xt−(lq−1)·q, · · · ,Xt−q] where lq is the length of the trend dependent sequence and q is the trend span. Note that p and q are actually two different types of periods. In the detailed implementation, p is equal to one-day that describes daily periodicity, and q is equal to one-week that reveals the weekly trend."
    }, {
      "heading" : "3.2 The Structure of the External Component",
      "text" : "Traffic flows could be affected by many complex external factors, such as weather and event. Figure 5(a) shows that crowd flows during holidays (Chinese Spring Festival) can be significantly different from the flows during normal days. Figure 5(b) shows that heavy rain sharply reduces the crowd flows at Office Area compared the same day of the latter week. Let Et be the feature vector that represents these external factors at predicted time interval t. In our implementation, we mainly consider weather, holiday event and meta data (i.e. DayOfWeek, Weekday/Weekend). The details are introduced in Table 1. To predict flows at time interval t, the holiday event and meta data can be directly obtained. However, the weather at the future time interval t is unknown. Instead, one can use the forecasting weather at time interval t or the approximate weather at time interval t−1. Formally, we stack two fully-connected layers upon Et, the first layer can be viewed as a embedding layer for each sub-factor followed by an activation. The second layer is used to map lowdimension to the high dimension that has the same shape with Xt. The output of the external component of Figure 3 is denoted as XExt with the parameters θExt."
    }, {
      "heading" : "3.3 Fusion",
      "text" : "In this section, we discuss about how to fuse four components in Figure 3. We first fuse the first three components with a parametric-matrix-based fusion method, which is then further combined with the external component.\nFigure 6(a) and (d) presents the ratio between arbitrary two in-flows at two different time intervals using Beijing trajectory data presented in Table 1. The curves from two different regions all show an empirical temporal correlation in time series, namely, in-flows of recent time intervals are more relevant than ones of distant time intervals, which implies temporal closeness. Two curves has different\nshape which demonstrates different regions may have different characteristics of closeness. Figures 6(b) and (e) depict in-flows at all time intervals of 7 days. We can see the obvious daily periodicity in all these three regions. In Office Area, the peak values in the weekdays are much higher than ones in weekend. Living Quarter has similar peak values in both weekdays and weekend. Figures 6(c) and (f) describes in-flows at a certain time interval (9:00pm-9:30pm) of Tuesday from March 2015 and Jun 2015. As time goes by, the in-flow progressively decreases in Office Area, and increase in Living Quarter. It shows the different trend in different regions. In summary, in-flows of three regions are all affected closeness, period and trend, but the degrees of influence may be very different. We also find the same properties in other regions as well as their out-flows.\nIn summary, two different regions are all affected by closeness, period and trend, but the degrees of influence may be different. Inspired by these observations, we propose a parametric-matrix-based fusion method. Parametric-matrix-based fusion. Formally, we fuse the first three components of Figure 3 as follows\nXRes = Wc◦X(L+1)c +Wp◦X(L+1)p +Wq ◦X(L+1)q (4)\nwhere ◦ is Hadamard product (i.e., element-wise multiplication), Wc, Wp and Wq are the parameters that adjust the degrees affected by closeness, period and trend, respectively. Fusing the external component. We here directly merge the output of the first three components with that of the external component, as shown in Figure 3. Finally, the predicted value at tth time interval, denoted as X̂t, defined as\nX̂t = tanh(XRes +XExt) (5)\nwhere tanh is a hyperbolic tangent that ensures the output values are between -1 and 1.\nOur ST-ResNet can be trained to predict Xt from three sequences of flow matrices and external factor features by minimizing mean squared error between the predicted flow matrix and the true flow matrix:\nL(θ) = ‖Xt − X̂t‖22 (6) where θ are all learnable parameters in the ST-ResNet."
    }, {
      "heading" : "3.4 Algorithms and Optimization",
      "text" : "Algorithm 1 outlines the ST-ResNet training process. We first construct the training instances from the original sequence data (lines 1-6). Then, ST-ResNet is trained via backpropagation and Adam (Kingma and Ba 2014) (lines 7-11).\nAlgorithm 1: Training of ST-ResNet Input: Historical observations: {X0, · · · ,Xn−1};\nexternal features: {E0, · · · , En−1}; lengths of closeness, period, trend sequences: lc, lp, lq; peroid: p; trend span: q.\nOutput: ST-ResNet modelM // construct training instances\n1 D ←− ∅ 2 for all available time interval t(1 ≤ t ≤ n− 1) do 3 Sc = [Xt−lc ,Xt−(lc−1), · · · ,Xt−1] 4 Sp = [Xt−lp·p,Xt−(lp−1)·p, · · · ,Xt−p] 5 Sq = [Xt−lq·q,Xt−(lq−1)·q, · · · ,Xt−q] // Xt is the target at time t 6 put an training instance ({Sc,Sp,Sq, Et},Xt) into D\n// train the model 7 initialize the parameters θ 8 repeat 9 randomly select a batch of instances Db from D\n10 find θ by minimizing the objective (6) with Db 11 until stopping criteria is met 12 output the learned ST-ResNet modelM\nAfter training, the learned ST-ResNet model M is obtained for the single- or multi-step look-ahead prediction. the process of which is summarized in Algorithm 2. Some types of external features (i.e., weather) used here are different from that in Algorithm 1. In the training process, we use the true weather data, which is replaced by the forecasted weather data in Algorithm 2.\nAlgorithm 2: Multi-step ahead prediction using STResNet\nInput: Learned ST-ResNet model:M; number of look-ahead steps: k; historical observations: {X0, · · · ,Xn−1}; external features: {En, · · · , En+k−1}; lengths of closeness, period, trend sequences: lc, lp, lq; peroid: p; trend span: q.\n1 X ←− {X0, · · · ,Xn−1} // (i.e., Xt = Xt,∀t); 2 for t = n to n+ k − 1 do 3 Sc = [Xt−lc ,Xt−(lc−1), · · · ,Xt−1]; 4 Sp = [Xt−lp·p,Xt−(lp−1)·p, · · · ,Xt−p] ; 5 Sq = [Xt−lq·q,Xt−(lq−1)·q, · · · ,Xt−q] ; 6 X̂t ←−M(Sc,Sp,Sq, Et); 7 put X̂t into X , i.e., Xt = X̂t; 8 output {X̂n, · · · , X̂n+k−1}"
    }, {
      "heading" : "4 Experiments",
      "text" : "In this section, we evaluate our ST-ResNet on two types of crowd flows in Beijing and NYC against 6 baselines."
    }, {
      "heading" : "4.1 Settings",
      "text" : "Datasets. We use two different sets of data as shown in Table 1. Each datasets contains two sub-datasets: trajectories\nand weather, as detailed as follows. • TaxiBJ: Trajectoriy data is the taxicab GPS data and me-\nteorology data in Beijing from four time intervals: 1st Jul 2013 - 30th Otc 2013, 1st Mar 2014 - 30th Jun 2014, 1st Mar 2015 - 30th Jun 2015, 1st Nov 2015 - 10th Apr 2016. Using Definition 2, we obtain two types of crowd flows. We choose data from the last four weeks as the testing data, and all data before that as training data.\n• BikeNYC: Trajectory data is taken from NYC Bike system in 2014, from 1st Apr to 30th Sep. Trip data includes: trip duration, start and end station IDs, start and end times. Among data, last 10 days are chosen as testing data, and other as training data.\nBaselines. In order to confirm the effectiveness of our models, we conduct experiments to compare our methods with 6 baselines as follows. • HA: We predict in-flow and out-flow of crowds by the\naverage value of historical in-flow and out-flow in the corresponding periods, e.g., 9:00am-9:30am on Tuesday, its corresponding periods are all historical time intervals from 9:00am to 9:30am on all historical Tuesday.\n• ARIMA: The in-flow/out-flow is a time series. Thus it can be predicted by ARIMA (autoregressive integrated moving average), which is a common tool for understanding and predicting future values in a time series.\n• SARIMA: Seasonal ARIMA. • VAR: Vector Auto-Regressive model is an more advanced\nspatio-temporal model, which can capture the pairwise relationships among all flows, and has heavy computational costs due to the large number of parameters.\n• ST-ANN: It first extracts spatial (nearby 8 regions’ value) and temporal (8 previous time intervals) features, then fed into an artificial neural network (Zheng et al. 2015).\n• DeepST (Zhang et al. 2016): a DNN-based prediction model for spatio-temporal data, which shows state-of-theart results on crowd flows prediction. DeepST has 4 variants, namely DeepST-C, DeepST-CP, DeepST-CPT, and DeepST-CPTM, which focus on different temporal dependencies and external factors.\nPreprocessing. In the output of the ST-ResNet, we use tanh as our final activation (see Eq. 5), whose range is between - 1 and 1. Here, we use Min-Max normalization method to scale the data into the range [−1, 1]. In the evaluation, we re-scale the predicted value back to the normal values, compared with the groundtruth. For external factors, we use onehot coding to transform meta data (i.e., DayOfWeek, Weekend/Weekday), holidays and weather conditions into binary vectors, and use Min-Max normalization method to scale the Temperature and Wind speed into the range [0, 1]. Hyperparameters. The python libraries, including Theano (Theano Development Team 2016) and Keras (Chollet 2015), are used to build our models. The learnable parameters are initialized using a uniform distribution with the default parameter in Keras (Chollet 2015). We set 64 feature maps in the convolutions (3 × 3 kernel) of all residual units. The Adam (Kingma and Ba 2014) is used for optimization. The batch size is 32. We select the 90% of training data for training each model, and the remaining 10% is chosen as the validation set, which is used to early-stop our training algorithm for each model based on the best validation score. Afterwards, we continue to train the model on the full training data 100 epochs. There are 5 extra hyperparamers in our ST-ResNet, of which p and q are empirically fixed to one-day and one-week, respectively. For the lengths of three dependent sequences, we set them as: lc ∈ {3, 4, 5}, lp ∈ {1, 2, 3, 4}, lq ∈ {1, 2, 3, 4}. Evaluation Metric: We measure our method by Root Mean Square Error (RMSE) as\nRMSE =\n√ 1\nz ∑ i (xi − x̂i)2 (7)\nwhere v̂ and v are the predicted value and ground thuth, respectively; z is the number of all predicted values. 4.2 Results on TaxiBJ We first give the comparison with 6 other models on TaxiBJ, as shown in Table 2. We here give 7 variants of ST-ResNet with different layers and different factors. Taking L12-E for example, it considers all available external factors and has 12 residual units, each of which is comprised of two convolutional layers. We observe that all of these 7 models are better than 6 baselines. Comparing with the previous stateof-the-art models, L12-E-BN reduces error to 16.69, which significantly improves the accuracy. Effects of Different Components. Let L12-E be the compared model.\n• Number of Residual Units: The results of L2-E, L4-E and L12-E show RMSE decreases as the number of residual units increases, which means that using residual learning, the deeper of the network leads to the better accuracy. • Internal Structure of Residual Unit: We attempt three different types of residual units. L12-E adopts the standard Residual Unit (seeing Figure 4(b)). Comparing with L12E, Residual Unit of L12-single-E only contains 1 ReLU followed by 1 convolution, and Residual Unit of L12-EBN added two batch normalization layers, each of which is inserted before ReLU. We observe that L12-single-E is\nworse than L12-E, and L12-E-BN is the best, demonstrating the effectiveness of the batch normalization. • External Factors: L12-E considers the external factors, including meteorology data, holiday events and meta data. If not, the model is degraded as L12. The results indicate that L12-E is better than L12, pointing out that external factors are always beneficial. • Parametric-Matrix-Based Fusion: Being different with L12-E, L12-E-noFusion donot use parametric-matrixbased fusion (seeing Eq. 4). Instead, L12-E-noFusion use a straightforward method for fusing, i.e., X(L+1)c + X (L+1) p + X (L+1) q . It shows the error greatly increases,\nwhich demonstrates the effectiveness of our proposed parametric-matrix-based fusion.\nMulti-step Ahead Prediciton. According to Algorithm 2, we can use historical observations and the recent predicted ones to forecast the crowd flows in subsequent time intervals which is referreed to multi-step ahead prediction. Figure 7 shows multi-step prediction results of 10 different models on TaxiBJ. We find that L12-E performs best though L12-E-BN is the best in the single-step prediction showing in Table 2. To verify the advantages of the temporal closeness, period and trend in the proposed ST-ResNet, here, we evaluate two degraded models of L12-E, including the models CP and C. Comparing with the architecture of ST-ResNet (showing in Figure 3), CP does not employ the trend component, and C only uses the closeness and external components. From the curves of C, CP and L12-E, we observe that L12-E is significantly better, demonstrating the period and trend are much more important for the multi-step ahead prediction."
    }, {
      "heading" : "4.3 Results on BikeNYC14",
      "text" : "Table 3 shows the results of our model and other baselines on BikeNYC14. Being different from TaxiBJ, BikeNYC14 is consisted of two different types of crowd flows, including new-flow and end-flow (Hoang, Zheng, and Singh 2016). Here, we adopt a total of 4-residual-unit ST-ResNet, and consider the meta data as external features like DeepST (Zhang et al. 2016). ST-ResNet has relatively from 14.8% up to 37.1% lower RMSE than these baselines, demonstrating that our proposed model has good generalization performance on other flow prediction tasks."
    }, {
      "heading" : "5 Related Work",
      "text" : "There are some work to predict an individual’s movement based on their location history (Fan et al. 2015; Song et al. 2014). They mainly forecast millions of, even billions of individuals’ mobility traces rather than the aggregated crowd flows in a region. Such a task may need huge computational resources, and it is always not necessary for the application scenario of public safety. Another branch of research focus on predicting travel speed and traffic volume on the road (Abadi, Rajabioun, and Ioannou 2015; Silva, Kang, and Airoldi 2015). Most of them are predicting a single or some road segments (Chen, Chen, and Qian 2014; Xu et al. 2014), rather than citywide speed and volume. Recently, the researchers start to focus on the city-scale traffic flows prediction (Hoang, Zheng, and Singh 2016; Zhang et al. 2016; Li et al. 2015). (Hoang, Zheng, and Singh 2016) introduced an approach to predict crowd flows in echo region of a city. This work is still different from ours where the model naturally focuses on the individual region not the city, and they do not partition the city using a grid-based method which needs a more complex method to find irregular regions first. In the previous work (Zhang et al. 2016), we proposed employing a deep neural network based prediction model for spatio-temporal data. The main improvements include two aspects: 1) the method proposed in this paper employs residual learning to construct a much deeper networks; 2) a parametric-matrix-based fusion mechanism is proposed to model both spatial and temporal dependencies."
    }, {
      "heading" : "6 Conclusions and Future Work",
      "text" : "In this paper, we proposed a novel deep-learning-based model for a spatio-temporal prediction problem, namely, forecasting the flow of crowds in each and every region throughout a city, based on historical trajectory data, weather and events. We evaluate our model on two types of crowd flows in Beijing and NYC, achieving performances which are significantly beyond 6 baseline methods, confirming that our model is better and applicable to crowd flows prediction. In the future, we will consider more different types of flows (e.g., taxi/truck/bus trajectory data, phone signals data, metro card swiping data), and use all of them to generate much more types of flows, and collectively predict all of these flows by appropriate fusion mechanism."
    } ],
    "references" : [ {
      "title" : "Traffic flow prediction for road transportation networks with limited traffic data",
      "author" : [ "A. Abadi", "T. Rajabioun", "P.A. Ioannou" ],
      "venue" : "IEEE Transactions on Intelligent Transportation Systems 16(2):653–662.",
      "citeRegEx" : "Abadi et al\\.,? 2015",
      "shortCiteRegEx" : "Abadi et al\\.",
      "year" : 2015
    }, {
      "title" : "Road traffic congestion monitoring in social media with hinge-loss markov random fields",
      "author" : [ "P.-T. Chen", "F. Chen", "Z. Qian" ],
      "venue" : "2014 IEEE International Conference on Data Mining, 80–89. IEEE.",
      "citeRegEx" : "Chen et al\\.,? 2014",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2014
    }, {
      "title" : "Keras",
      "author" : [ "F. Chollet" ],
      "venue" : "https://github.com/ fchollet/keras.",
      "citeRegEx" : "Chollet,? 2015",
      "shortCiteRegEx" : "Chollet",
      "year" : 2015
    }, {
      "title" : "Citymomentum: an online approach for crowd behavior prediction at a citywide level",
      "author" : [ "Z. Fan", "X. Song", "R. Shibasaki", "R. Adachi" ],
      "venue" : "Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing, 559–569. ACM.",
      "citeRegEx" : "Fan et al\\.,? 2015",
      "shortCiteRegEx" : "Fan et al\\.",
      "year" : 2015
    }, {
      "title" : "Deep residual learning for image recognition",
      "author" : [ "K. He", "X. Zhang", "S. Ren", "J. Sun" ],
      "venue" : "arXiv preprint arXiv:1512.03385.",
      "citeRegEx" : "He et al\\.,? 2015",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2015
    }, {
      "title" : "Identity mappings in deep residual networks",
      "author" : [ "K. He", "X. Zhang", "S. Ren", "J. Sun" ],
      "venue" : "arXiv preprint arXiv:1603.05027.",
      "citeRegEx" : "He et al\\.,? 2016",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2016
    }, {
      "title" : "Forecasting citywide crowd flows based on big data",
      "author" : [ "M.X. Hoang", "Y. Zheng", "A.K. Singh" ],
      "venue" : "ACM SIGSPATIAL 2016.",
      "citeRegEx" : "Hoang et al\\.,? 2016",
      "shortCiteRegEx" : "Hoang et al\\.",
      "year" : 2016
    }, {
      "title" : "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "author" : [ "S. Ioffe", "C. Szegedy" ],
      "venue" : "Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, 448–456.",
      "citeRegEx" : "Ioffe and Szegedy,? 2015",
      "shortCiteRegEx" : "Ioffe and Szegedy",
      "year" : 2015
    }, {
      "title" : "Supervised learning of image restoration with convolutional networks",
      "author" : [ "V. Jain", "J.F. Murray", "F. Roth", "S. Turaga", "V. Zhigulin", "K.L. Briggman", "M.N. Helmstaedter", "W. Denk", "H.S. Seung" ],
      "venue" : "2007 IEEE 11th International Conference on Computer Vision, 1–8. IEEE.",
      "citeRegEx" : "Jain et al\\.,? 2007",
      "shortCiteRegEx" : "Jain et al\\.",
      "year" : 2007
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "D. Kingma", "J. Ba" ],
      "venue" : "arXiv preprint arXiv:1412.6980.",
      "citeRegEx" : "Kingma and Ba,? 2014",
      "shortCiteRegEx" : "Kingma and Ba",
      "year" : 2014
    }, {
      "title" : "ImageNet classification with deep convolutional neural networks",
      "author" : [ "A. Krizhevsky", "I. Sutskever", "G.E. Hinton" ],
      "venue" : "Advances in neural information processing systems, 1097–1105.",
      "citeRegEx" : "Krizhevsky et al\\.,? 2012",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Gradient-based learning applied to document recognition",
      "author" : [ "Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner" ],
      "venue" : "Proceedings of the IEEE 86(11):2278–2324.",
      "citeRegEx" : "LeCun et al\\.,? 1998",
      "shortCiteRegEx" : "LeCun et al\\.",
      "year" : 1998
    }, {
      "title" : "Traffic prediction in a bike-sharing system",
      "author" : [ "Y. Li", "Y. Zheng", "H. Zhang", "L. Chen" ],
      "venue" : "Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems, 33. ACM.",
      "citeRegEx" : "Li et al\\.,? 2015",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2015
    }, {
      "title" : "Fully convolutional networks for semantic segmentation",
      "author" : [ "J. Long", "E. Shelhamer", "T. Darrell" ],
      "venue" : "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 3431–3440.",
      "citeRegEx" : "Long et al\\.,? 2015",
      "shortCiteRegEx" : "Long et al\\.",
      "year" : 2015
    }, {
      "title" : "Deep multiscale video prediction beyond mean square error",
      "author" : [ "M. Mathieu", "C. Couprie", "Y. LeCun" ],
      "venue" : "arXiv preprint arXiv:1511.05440.",
      "citeRegEx" : "Mathieu et al\\.,? 2015",
      "shortCiteRegEx" : "Mathieu et al\\.",
      "year" : 2015
    }, {
      "title" : "Rectified linear units improve restricted boltzmann machines",
      "author" : [ "V. Nair", "G.E. Hinton" ],
      "venue" : "Proceedings of the 27th International Conference on Machine Learning (ICML-10), 807–814.",
      "citeRegEx" : "Nair and Hinton,? 2010",
      "shortCiteRegEx" : "Nair and Hinton",
      "year" : 2010
    }, {
      "title" : "On mining anomalous patterns in road traffic streams",
      "author" : [ "L.X. Pang", "S. Chawla", "W. Liu", "Y. Zheng" ],
      "venue" : "International Conference on Advanced Data Mining and Applications, 237–251. Springer.",
      "citeRegEx" : "Pang et al\\.,? 2011",
      "shortCiteRegEx" : "Pang et al\\.",
      "year" : 2011
    }, {
      "title" : "Predicting traffic volumes and estimating the effects of shocks in massive transportation systems",
      "author" : [ "R. Silva", "S.M. Kang", "E.M. Airoldi" ],
      "venue" : "Proceedings of the National Academy of Sciences 112(18):5643–5648.",
      "citeRegEx" : "Silva et al\\.,? 2015",
      "shortCiteRegEx" : "Silva et al\\.",
      "year" : 2015
    }, {
      "title" : "Prediction of human emergency behavior and their mobility following large-scale disaster",
      "author" : [ "X. Song", "Q. Zhang", "Y. Sekimoto", "R. Shibasaki" ],
      "venue" : "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, 5–14. ACM.",
      "citeRegEx" : "Song et al\\.,? 2014",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2014
    }, {
      "title" : "Theano: A Python framework for fast computation of mathematical expressions",
      "author" : [ "Theano Development Team." ],
      "venue" : "arXiv e-prints abs/1605.02688.",
      "citeRegEx" : "Team.,? 2016",
      "shortCiteRegEx" : "Team.",
      "year" : 2016
    }, {
      "title" : "Accurate and interpretable bayesian mars for traffic flow prediction",
      "author" : [ "Y. Xu", "Q.-J. Kong", "R. Klette", "Y. Liu" ],
      "venue" : "IEEE Transactions on Intelligent Transportation Systems 15(6):2457–2469.",
      "citeRegEx" : "Xu et al\\.,? 2014",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2014
    }, {
      "title" : "DNN-based prediction model for spatial-temporal data",
      "author" : [ "J. Zhang", "Y. Zheng", "D. Qi", "R. Li", "X. Yi" ],
      "venue" : "ACM SIGSPATIAL 2016, https://www.microsoft.com/enus/research/publication/dnn-based-prediction-modelspatial-temporal-data.",
      "citeRegEx" : "Zhang et al\\.,? 2016",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2016
    }, {
      "title" : "Forecasting fine-grained air quality based on big data",
      "author" : [ "Y. Zheng", "X. Yi", "M. Li", "R. Li", "Z. Shan", "E. Chang", "T. Li" ],
      "venue" : "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2267–2276. ACM.",
      "citeRegEx" : "Zheng et al\\.,? 2015",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "In this paper, we predict two types of crowd flows (Zhang et al. 2016): in-flow and out-flow, as shown in Figure 1.",
      "startOffset" : 51,
      "endOffset" : 70
    }, {
      "referenceID" : 21,
      "context" : "In this section, we briefly revisit the crowd flows prediction problem (Zhang et al. 2016; Hoang, Zheng, and Singh 2016) and formally introduce the deep residual learning (He et al.",
      "startOffset" : 71,
      "endOffset" : 120
    }, {
      "referenceID" : 5,
      "context" : "2016; Hoang, Zheng, and Singh 2016) and formally introduce the deep residual learning (He et al. 2016).",
      "startOffset" : 86,
      "endOffset" : 102
    }, {
      "referenceID" : 16,
      "context" : "Definition 1 (Region (Pang et al. 2011)) There are many definitions of a location in terms of different granularities and semantic meanings.",
      "startOffset" : 21,
      "endOffset" : 39
    }, {
      "referenceID" : 21,
      "context" : "Definition 2 (In- & Out-flows (Zhang et al. 2016)) Let P be a collection of trajectories at the t time interval.",
      "startOffset" : 30,
      "endOffset" : 49
    }, {
      "referenceID" : 4,
      "context" : "Deep residual learning (He et al. 2015) allows convolution neural networks to have a super deep structure of over-100 layers, even over-1000 layers.",
      "startOffset" : 23,
      "endOffset" : 39
    }, {
      "referenceID" : 4,
      "context" : "And this method has shown state-of-the-art results on multiple challenging recognition tasks, including image classification, object detection, segmentation and localization (He et al. 2015).",
      "startOffset" : 174,
      "endOffset" : 190
    }, {
      "referenceID" : 5,
      "context" : "Formally, a residual unit with an identity mapping (He et al. 2016) is defined as:",
      "startOffset" : 51,
      "endOffset" : 67
    }, {
      "referenceID" : 4,
      "context" : ", a stack of two 3×3 convolution layers in (He et al. 2015).",
      "startOffset" : 43,
      "endOffset" : 59
    }, {
      "referenceID" : 5,
      "context" : "The central idea of the residual learning is to learn the additive residual function F with respect to X (He et al. 2016).",
      "startOffset" : 105,
      "endOffset" : 121
    }, {
      "referenceID" : 11,
      "context" : "Intuitively, the flow of crowds in nearby regions may affect each other, which can be effectively handled the convolutional neural network (CNN) that have shown its powerful ability to hierarchically capture spatial structural information (LeCun et al. 1998).",
      "startOffset" : 239,
      "endOffset" : 258
    }, {
      "referenceID" : 8,
      "context" : "Being different from the classical CNN, we do not use subsampling, but only convolutions (Jain et al. 2007).",
      "startOffset" : 89,
      "endOffset" : 107
    }, {
      "referenceID" : 7,
      "context" : "ReLU) and regularization techniques are applied (Ioffe and Szegedy 2015; Krizhevsky, Sutskever, and Hinton 2012; Nair and Hinton 2010).",
      "startOffset" : 48,
      "endOffset" : 134
    }, {
      "referenceID" : 15,
      "context" : "ReLU) and regularization techniques are applied (Ioffe and Szegedy 2015; Krizhevsky, Sutskever, and Hinton 2012; Nair and Hinton 2010).",
      "startOffset" : 48,
      "endOffset" : 134
    }, {
      "referenceID" : 4,
      "context" : "To address this issue, we employ residual learning (He et al. 2015) in our model, which have been demonstrated to be very effective for training a super deep neural networks of over-1000 layers.",
      "startOffset" : 51,
      "endOffset" : 67
    }, {
      "referenceID" : 7,
      "context" : "We also attempt Batch Normalization (BN) (Ioffe and Szegedy 2015) which are added before ReLU.",
      "startOffset" : 41,
      "endOffset" : 65
    }, {
      "referenceID" : 9,
      "context" : "Then, ST-ResNet is trained via backpropagation and Adam (Kingma and Ba 2014) (lines 7-11).",
      "startOffset" : 56,
      "endOffset" : 76
    }, {
      "referenceID" : 22,
      "context" : "• ST-ANN: It first extracts spatial (nearby 8 regions’ value) and temporal (8 previous time intervals) features, then fed into an artificial neural network (Zheng et al. 2015).",
      "startOffset" : 156,
      "endOffset" : 175
    }, {
      "referenceID" : 21,
      "context" : "• DeepST (Zhang et al. 2016): a DNN-based prediction model for spatio-temporal data, which shows state-of-theart results on crowd flows prediction.",
      "startOffset" : 9,
      "endOffset" : 28
    }, {
      "referenceID" : 2,
      "context" : "The python libraries, including Theano (Theano Development Team 2016) and Keras (Chollet 2015), are used to build our models.",
      "startOffset" : 80,
      "endOffset" : 94
    }, {
      "referenceID" : 2,
      "context" : "The learnable parameters are initialized using a uniform distribution with the default parameter in Keras (Chollet 2015).",
      "startOffset" : 106,
      "endOffset" : 120
    }, {
      "referenceID" : 9,
      "context" : "The Adam (Kingma and Ba 2014) is used for optimization.",
      "startOffset" : 9,
      "endOffset" : 29
    }, {
      "referenceID" : 21,
      "context" : "Here, we adopt a total of 4-residual-unit ST-ResNet, and consider the meta data as external features like DeepST (Zhang et al. 2016).",
      "startOffset" : 113,
      "endOffset" : 132
    }, {
      "referenceID" : 21,
      "context" : "The results of ARIMA, SARIMA, VAR and 4 DeepST variants are taken from (Zhang et al. 2016).",
      "startOffset" : 71,
      "endOffset" : 90
    }, {
      "referenceID" : 3,
      "context" : "There are some work to predict an individual’s movement based on their location history (Fan et al. 2015; Song et al. 2014).",
      "startOffset" : 88,
      "endOffset" : 123
    }, {
      "referenceID" : 18,
      "context" : "There are some work to predict an individual’s movement based on their location history (Fan et al. 2015; Song et al. 2014).",
      "startOffset" : 88,
      "endOffset" : 123
    }, {
      "referenceID" : 20,
      "context" : "Most of them are predicting a single or some road segments (Chen, Chen, and Qian 2014; Xu et al. 2014), rather than citywide speed and volume.",
      "startOffset" : 59,
      "endOffset" : 102
    }, {
      "referenceID" : 21,
      "context" : "Recently, the researchers start to focus on the city-scale traffic flows prediction (Hoang, Zheng, and Singh 2016; Zhang et al. 2016; Li et al. 2015).",
      "startOffset" : 84,
      "endOffset" : 149
    }, {
      "referenceID" : 12,
      "context" : "Recently, the researchers start to focus on the city-scale traffic flows prediction (Hoang, Zheng, and Singh 2016; Zhang et al. 2016; Li et al. 2015).",
      "startOffset" : 84,
      "endOffset" : 149
    }, {
      "referenceID" : 21,
      "context" : "In the previous work (Zhang et al. 2016), we proposed employing a deep neural network based prediction model for spatio-temporal data.",
      "startOffset" : 21,
      "endOffset" : 40
    } ],
    "year" : 2016,
    "abstractText" : "Forecasting the flow of crowds is of great importance to traffic management and public safety, yet a very challenging task affected by many complex factors, such as inter-region traffic, events and weather. In this paper, we propose a deep-learningbased approach, called ST-ResNet, to collectively forecast the in-flow and out-flow of crowds in each and every region through a city. We design an end-to-end structure of STResNet based on unique properties of spatio-temporal data. More specifically, we employ the framework of the residual neural networks to model the temporal closeness, period, and trend properties of the crowd traffic, respectively. For each property, we design a branch of residual convolutional units, each of which models the spatial properties of the crowd traffic. ST-ResNet learns to dynamically aggregate the output of the three residual neural networks based on data, assigning different weights to different branches and regions. The aggregation is further combined with external factors, such as weather and day of the week, to predict the final traffic of crowds in each and every region. We evaluate ST-ResNet based on two types of crowd flows in Beijing and NYC, finding that its performance exceeds six well-know methods.",
    "creator" : "TeX"
  }
}