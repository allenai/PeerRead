{
  "name" : "1401.7941.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Exploiting Causality for Selective Belief Filtering in Dynamic Bayesian Networks",
    "authors" : [ "Stefano V. Albrecht", "Subramanian Ramamoorthy" ],
    "emails" : [ "svalb@cs.utexas.edu", "s.ramamoorthy@ed.ac.uk" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Dynamic Bayesian networks (DBNs) (Dean & Kanazawa, 1989) are a general model for stochastic processes with partially observed states. The topology of a DBN is a compact specification of how variables in the process interact during transitions (cf. Figure 1). Given the possible incompleteness and noise in observations, it may not generally be possible to infer the state of the process with absolute certainty. Instead, we may infer beliefs about the process state based on the history of observations, in the form of a probability distribution over the state space of the process. This is often called a belief state and the task of calculating belief states is commonly referred to as belief filtering.\nA number of exact and approximate inference methods exist for Bayesian networks (see, e.g., Koller & Friedman, 2009; Pearl, 1988) which can be used for filtering in DBNs, by applying them to the “unrolled” DBN in which the t+ 1 slice is repeated for each observed time step, or via a successive update in which the current posterior (belief state) is used\nc©2016 AI Access Foundation. All rights reserved.\nar X\niv :1\n40 1.\n79 41\nv3 [\ncs .A\nI] 2\n5 A\ni variables represent the process states at time t and\nt+ 1, respectively, while the yt+1i variables (shaded) represent the observation at time t+ 1. The arrows describe how the variables interact.\nas the prior in the next time step (see also Murphy, 2002). However, it is clear that the unrolled variant becomes intractable as the network grows unboundedly with time. Even in the successive update, exact methods become intractable in high-dimensional process states and approximate methods may propagate growing errors over time. Therefore, filtering methods were developed which utilise the special structure of DBNs and maintain the errors propagated over time. (We defer a detailed discussion of such methods to Section 2.)\nOften, the key to developing efficient filtering methods is to identify structure in the process which can be leveraged for inference. In this article, we are interested in the application of DBNs as representations of actions in partially observed decision processes, such as POMDPs (Kaelbling, Littman, & Cassandra, 1998; Sondik, 1971) and their many variants. DBNs can be used to represent the effects of actions on the decision process, by specifying how variables interact and what information the decision maker observes. In many cases, decision processes exhibit high degrees of causal structure (Pearl, 2000), by which we mean that a change in one part of the process may cause a change in another part. Our experience with such processes is that this causal structure may be used to make the filtering task more tractable, because it can tell us that beliefs need only be revised for certain aspects of the process state. For example, if the variable x2 in Figure 1 changes its value only if variable x1 changed its value (i.e. a change in x1 causes a change in x2), then it seems intuitive to use this causal relation when deciding whether to revise one’s belief about x2. Unfortunately, current filtering methods do not take such causal structure into account.\nWe refer to the above type of causal relation (between x1 and x2) as passivity. Intuitively, we say that a state variable xi is passive in a given action if, when executing that action, there is a subset of the state variables that directly affect xi (i.e. xi’s parents in the DBN) such that xi may change its value only if at least one of the variables in this subset changed its value. It is worth pointing out that passivity occurs naturally and frequently in many planning domains, especially in robotic and other physical systems (Mainzer, 2010). The following example1 illustrates this in a simple robot arm:\n1. We mark the end of an example with a solid black square.\nExample 1 (Robot arm). Consider a robot arm with three rotational joints and a gripper, as shown in Figure 2a. The joints are denoted by θ1, θ2, θ3 and may take any values from the discrete set {0◦, 1◦, ..., 359◦} which indicate their absolute orientations (e.g. θi = 0◦ means that joint i points exactly to the right, θi = 180\n◦ means that it points to the left). For each joint i, let there be two actions CWi and CCWi which rotate the joint by 1\n◦ clockwise and counter-clockwise, respectively. The uncertainty in this system could be due to stochastic joint movements or unreliable sensor readings for the joint orientations.\nFor any action CWi or CCWi, the variable θi is not passive because its value is directly modified by the action. However, the variables θj 6=i are passive because they change their values only if the corresponding preceding variable θj−1 changed its value, since a changed orientation of joint j − 1 causes a changed orientation of joint j (recall that the orientations are absolute). Note that this also accounts for chains of such causal effects, as indicated by the arrows: the orientation of joint 3 changes if the orientation of joint 1 changes, since joint 1 causes joint 2 to change, which in turn causes joint 3 to change.\nFurther examples of passivity can be seen in the context of object manipulation, such as in the “blocks” planning domain (e.g. Pasula, Zettlemoyer, & Kaelbling, 2007). Figure 2b shows the arm holding blocks B and A, with A on top of B. Here, the position of B (XB) is passive with respect to the joint orientations since it will only change if any of the orientations changed. Furthermore, there is a causal chain from the joint orientations to the position of block A (XA), since A’s position will change if B’s position changes.\nHow can passivity be exploited to accelerate the filtering task in the above example? The fact that the state variables are passive means that some aspects of the state may remain unchanged, depending on which action we choose. For example, if we choose to rotate joint 3, then the fact that joints 1 and 2 are passive means that they are unaffected by this action. Thus, it seems redundant to revise beliefs for the orientations of joints 1 and 2. However, this is precisely what current filtering methods do (cf. Section 2).\nMore concretely, assume we use a factored belief representation P (θ1, θ2, θ3) = P (θ1, θ2)∗ P (θ2, θ3) and choose to rotate θ3 in any direction. Then, it is easy to see that we will need to update the factor P (θ2, θ3), since θ3 changes its value, but not the factor P (θ1, θ2), since the variables θ1, θ2 are both passive. Since the parents of θ1, θ2 (if any) do not change their values, we know that θ1, θ2 will not change their values either. As we will show later, skipping\nover P (θ1, θ2) does not result in a loss of information in such cases, and similarly for chains of such causal connections (cf. Example 1). A more complex example of a planning domain involving passivity, and how it can be exploited, is discussed in Section 6.2.\nIn addition to guiding belief revision, there are several features which make passivity an interesting example of a causal relation: First of all, passivity is a latent causal relation, meaning that it can be readily extracted from the process dynamics without additional annotation by an expert. (In Section 4, we give a procedure which identifies passive variables based on their conditional probability tables.) Furthermore, passivity is not a deterministic relation since passive variables may have any stochastic behaviour when changing their values. Finally, passivity is a relatively simple example of a causal relation, and the idea of exploiting passivity in order to accelerate the filtering task is intuitive. Yet, to the best of our knowledge, this has not been formalised and explored rigorously before.\nThe purpose of the present article is to formalise and evaluate the idea of automatically exploiting causal structure for efficient belief filtering in DBNs, using passivity as a concrete example of a causal relation. Specifically, our hypothesis is that in large processes with high degrees of passivity, this structure can be exploited to accelerate the filtering task. After discussing related work in Section 2 and technical preliminaries in Section 3, our contributions can be grouped into the following parts:\n• In Section 4, we give a formally concise definition of passivity and discuss various aspects of this definition. Our definition assumes a decision process which is specified as a set of dynamic Bayesian networks (one for each action). We also discuss a nonexample of passivity, by which we mean variables which appear to be passive but really are not passive. Finally, we give a simple procedure which can detect passive variables based on their conditional probability tables.\n• In Section 5, we present the Passivity-based Selective Belief Filtering (PSBF) method. Following the idea outlined above, PSBF uses a factored belief representation in which the belief factors are defined over clusters of correlated state variables. PSBF follows a 2-step update procedure wherein the belief state is first propagated through the process dynamics (the transition step) and then conditioned on the observation (the observation step). The interesting novelty of PSBF is the way in which it performs the transition step: rather than updating all belief factors, PSBF updates only those factors whose variables it suspects to have changed, which is possible by exploiting passivity (to be made precise shortly). Similarly, in the observation step, PSBF updates only those belief factors which it determines to be structurally connected with the observation, and it uses only those parts of the observation which are relevant to the belief factor, thus allowing for a more efficient incorporation of observations. PSBF produces exact belief states under certain assumptions and approximate belief states otherwise. We also discuss the computational complexity and error bounds of PSBF.\n• In Section 6, we evaluate PSBF in two experimental domains: We first evaluate PSBF in synthetic (i.e. randomly generated) processes of varying sizes and degrees of passivity. The process sizes vary from one thousand to one trillion states, and the passivity degrees vary from 25% to 100% passivity. Our results show that PSBF is faster than several alternative methods while maintaining competitive accuracy. In particular, our\nresults indicate that the computational gains grow significantly with both the degree of passivity and the size of the process. We then evaluate PSBF in a complex simulation of a multi-robot warehouse system in the style of Kiva (Wurman, D’Andrea, & Mountz, 2008). We show how passivity occurs in this system and how PSBF can exploit this to accelerate the filtering task, again outperforming alternative methods.\nFinally, we discuss the strengths and weaknesses of PSBF in Section 7, and we conclude our work in Section 8. All proofs can be found in the appendix."
    }, {
      "heading" : "2. Related Work",
      "text" : "There exists a substantial body of work on belief filtering in partially observed stochastic processes. In this section, we review filtering methods that utilise the special structure of DBNs and situate our work within this and other related literature."
    }, {
      "heading" : "2.1 Approximate Belief Filtering in DBNs",
      "text" : "Several authors proposed filtering methods wherein the belief state is represented as a set of state samples. Specifically, the probability that the process is in state s is the normalised frequency with which the state samples correspond to s. These methods are now commonly referred to as particle filters (PF); see the work of Doucet, de Freitas, and Gordon (2001) for a survey. In a common variant of PF (Gordon, Salmond, & Smith, 1993), the filtering task consists of propagating the current state samples through the process dynamics and a subsequent resampling step based on the probabilities with which the new state samples would have produced the observation. Two interesting features of PF are that it can be applied to processes with discrete and continuous variables, and that the approximation error converges to zero as we increase the number of state samples.\nA known problem of PF is the fact that the number of samples needed for acceptable approximations can grow drastically with the variance in the process dynamics (as shown in our experiments; cf. Section 6). Rao-Blackwellised PF (RBPF) (Doucet, De Freitas, Murphy, & Russell, 2000) was developed to address this problem. RBPF assumes that the state variables can be grouped into sets R and X such that the distribution over X can be efficiently calculated from R during the filtering. Hence, a sample in RBPF consists of a sample of R and a corresponding marginal distribution over X. RBPF is useful when the variance in R is relatively low and the variance in X is high, since this reduces the number of samples needed for acceptable approximations.\nBoyen and Koller (1999, 1998) recognised that if a process consists of several independent or weakly interacting subcomponents, then the belief state can be represented more efficiently as a product of smaller beliefs about these individual subcomponents. Their seminal contribution is to show that the approximation error due to this factored representation is essentially bounded by the degree of uncertainty (or “mixing rates”) in the process. More precisely, they prove that the relative entropy (or KL divergence; Kullback & Leibler, 1951) between two belief states contracts at an exponential rate when propagated through a stochastic transition process. Based on this observation, they propose a filtering method (BK) wherein the belief state is represented in factored form and the belief factors are updated using an exact inference method, such as the junction tree algorithm (Lauritzen & Spiegelhalter, 1988). Since\nthe internal “cliques” used in the junction tree algorithm may not correspond to the belief state representation of BK, a final “projection step” will typically have to be performed in which the original factorisation is restored. The performance of this method depends crucially on whether the relevant correlations between state variables can be captured in small clusters, and whether the projection step can be performed efficiently.\nFactored particle filtering (FP) (Ng, Peshkin, & Pfeffer, 2002) addresses the main drawbacks of PF (many samples needed) and BK (small clusters required) by approximating the belief factors using a set of factored state samples. The samples are factored in the sense that they only assign values to the variables in the corresponding factor. This allows FP to represent belief factors which are too large for BK, and it reduces the number of samples needed due to the smaller number of variables in each factor. The authors provide different methods of updating the factored state samples, but the generic idea is to first perform a “join” operation in which full state samples are reconstructed from the factored samples, which are then updated as in standard PF. The updated samples are then projected down into factored form using a “project” operation. The main drawback of FP is that these join and project operations essentially correspond to standard relational database operations, which can be very expensive.\nMurphy and Weiss (2001) propose a filtering method called factored frontier (FF). FF uses a fully factored representation of belief states; that is, the belief state is a product of marginals for each individual state variable. This allows for a very compact representation of beliefs. The algorithm works by “moving” a set of state variables (the frontier) forward and backward in the DBN topology. This requires a certain variable ordering, which can be difficult to attain if intra-correlations between state variables (i.e. edges within the t+ 1 slice of the DBN) are allowed. The authors show that their method is equivalent to a single iteration of loopy belief propagation (LBP) (Pearl, 1988). Thus, similar to LBP, FF can be applied in successive iterations to improve the approximation accuracy.\nNone of the works discussed above explicitly address the question of how causal relations between state variables can be exploited to accelerate the filtering task, or, alternatively, how the filtering methods proposed therein implicitly benefit from causal structure. Our method, PSBF, is related to BK and FP in that PSBF, too, uses a factored belief representation, where the belief factors are defined over clusters of correlated state variables. Therefore, the analysis of approximation errors by Boyen and Koller (1998) also applies to PSBF, as we show in Section 5 as well as in our experiments. However, in contrast to BK and FP, PSBF does not perform inference over the complete factorisation, but rather over the individual factors. As a consequence, PSBF does not require a join or project operation, which is one of the main disadvantages of BK and FP."
    }, {
      "heading" : "2.2 Belief Filtering in Decision Processes",
      "text" : "The methods discussed in the preceding subsection can be used for belief filtering in decision processes, including POMDPs (Kaelbling et al., 1998; Sondik, 1971). In this regard, these methods can be viewed as “pure” filters in that they are only concerned with belief filtering and not with the control of the decision process. This is in contrast to combined filtering methods, which interleave the filtering and control tasks in decision processes and make specific assumptions regarding solutions thereof. There exists a large body of literature on such\ncombined methods, including reachability-based methods (Hauskrecht, 2000; Washington, 1997), grid-based methods (Zhou & Hansen, 2001; Brafman, 1997; Lovejoy, 1991), pointbased methods (Smith & Simmons, 2005; Pineau, Gordon, & Thrun, 2003), and compression methods (Roy, Gordon, & Thrun, 2005; Poupart & Boutilier, 2002).\nA potential advantage of such combined methods is that they have access to additional structure and may, therefore, utilise synergies between the filtering and control tasks. One such synergy is the use of decision quality to guide belief filtering, rather than metrics such as relative entropy. Poupart and Boutilier (2001, 2000) propose a filtering method, called value-directed approximation, which chooses different approximation schemes for different decisions so as to minimise the expected loss in decision quality (i.e. accumulated rewards). The method assumes that the POMDP has been solved exactly and that the value function is provided in the form of α-vectors which represent the available actions in the POMDP. Based on the value function, their algorithm computes a “switching set” and “alternative plans” to determine the error bounds of approximation schemes. This is used to search for an optimal approximation scheme in a tree-based manner, where the search traverses from approximate to exact schemes.\nWhile the idea of using decision quality to guide belief filtering is appealing, their method involves a series of optimisation problems and an exhaustive tree search, which can be very costly in complex systems. The advantage of pure filtering methods, including our proposed method PSBF, is that they can filter processes which are too complex for combined methods, such as the multi-robot warehouse system studied in Section 6. The actual control task can then be done via domain-specific solutions (cf. Section 6.2.1)."
    }, {
      "heading" : "2.3 Substructure in Parameterisation",
      "text" : "Bayesian networks, and hence DBNs, allow for a compact parameterisation (i.e. specification of probabilities) and efficient inference via conditional independence relations. In addition, there has been considerable work in identifying substructure in the parameterisation to further simplify knowledge acquisition and enhance inference (Koller & Friedman, 2009; Boutilier, Dean, & Hanks, 1999). The property studied in this work, passivity, is one example of substructure in the parameterisation. Other notable examples include causal independence (e.g. Heckerman & Breese, 1994; Heckerman, 1993) and context-specific independence (Boutilier, Friedman, Goldszmidt, & Koller, 1996).\nCausal independence is the assumption that the effects of individual causes on a common variable (i.e. the parents of that variable) are independent of one another. This allows for a compact parameterisation via operators such as “noisy-or” (Srinivas, 1993; Pearl, 1988), and it can be used to enhance inference (Zhang & Poole, 1996). Note that passivity is a conceptually much simpler property than causal independence, because passivity is neither concerned with the strength of individual causes nor the extent to which they depend on each other. Moreover, passivity can be read directly from the parameterisation (cf. Section 4.3) whereas causal independence is usually imposed by the designer.\nContext-specific independence (CSI) is a property which states that a variable is independent of some of its parents given a certain assignment of values (i.e. “context”) to some of its other parents. Non-local CSI statements follow similarly to d-separation (Geiger, Verma, & Pearl, 1989). This can allow for a further reduction of parameters (Boutilier et al., 1996)\nand enhancement of inference (Poole & Zhang, 2003). As we will discuss in Section 4, passivity can be viewed as a special kind of CSI applied to DBNs, in that the parents with respect to which the variable is passive provide the context for CSI. However, in contrast to CSI, passivity does not assume that the context is actually observed."
    }, {
      "heading" : "3. Technical Preliminaries",
      "text" : "This section introduces the basic concepts and notation used in our work. We begin with a brief discussion of decision processes to provide the context for our work, followed by a discussion of dynamic Bayesian networks as the model over which we perform inference."
    }, {
      "heading" : "3.1 Decision Processes, Belief States, Exact Updates",
      "text" : "We consider a stochastic decision process wherein, at each time t, the process is in state st ∈ S and a decision maker, or “agent”, is choosing an action at. After executing at in st, the process transitions into state st+1 ∈ S with probability T at(st, st+1) and the agent receives an observation ot+1 ∈ O with probability Ωat(st+1, ot+1). We assume factored representations of the state space S and observation space O, such that S = X1× ...×Xn and O = Y1× ...×Ym, where the domains Xi, Yj are finite. The notation si is used to denote the value of Xi in state s ∈ S, and analogously for oj with o ∈ O. Moreover, we assume that the process is time-invariant, meaning that T a and Ωa are independent of t. This framework is compatible with many decision models used in the artificial intelligence literature, including POMDPs (Kaelbling et al., 1998; Sondik, 1971) and its many variants.\nThe agent chooses action at based on its belief state bt (also known as information state), which represents the agent’s beliefs about the likelihood of states at time t. Formally, a belief state is a probability distribution over the state space S of the process. Belief filtering is the task of calculating a belief state based on the history of observations. Ideally, the resulting belief state should be exact in that it retains all relevant information from the past observations (this is sometimes referred to as sufficient statistic; cf. Astrom, 1965). The exact update rule is a simple procedure that produces exact belief states:\nDefinition 1 (Exact update rule). The exact update rule is defined as follows: After taking action at and observing ot+1, the belief state bt is updated to bt+1 via\nb̂t+1(s′) = ∑\ns∈S bt(s)T a\nt (s, s′) (1)\nbt+1(s′) = η b̂t+1(s′) Ωa t (s′, ot+1) (2)\nwhere η is a normalisation constant.\nWe sometimes refer to the step bt → b̂t+1 as the transition step and to the step b̂t+1 → bt+1 as the observation step. Unfortunately, the space complexity of storing exact belief states and the time complexity of updating them using the exact update rule are both exponential in the number of state variables, making it infeasible for complex systems with large state spaces. Hence, more efficient approximate methods are required."
    }, {
      "heading" : "3.2 Dynamic Bayesian Networks",
      "text" : "A dynamic Bayesian network (DBN) (Dean & Kanazawa, 1989) is a Bayesian network with a special temporal semantics that specifies how a stochastic process transitions from one state into another. DBNs can be used to model the effects of actions in a stochastic decision process. Specifically, they are a compact representation of the transition function T a and observation function Oa of action a:\nDefinition 2 (DBN). A dynamic Bayesian network for action a, denoted ∆a, is an acyclic directed graph consisting of:\n• State variables Xt = { xt1, ..., x t n } and Xt+1 = { xt+11 , ..., x t+1 n } with xti, x t+1 i ∈ Xi,\nrepresenting the states of the process at time t and t+ 1, respectively.\n• Observation variables Y t+1 = { yt+11 , ..., y t+1 m } with yt+1j ∈ Yj , representing the obser-\nvation received at time t+ 1.\n• Directed edges Ea ⊆ ( Xt ×Xt+1 ) ∪ ( Xt+1 ×Xt+1 ) ∪ ( Xt+1 × Y t+1 ) ∪ ( Y t+1 × Y t+1 ) ,\nspecifying the network topology and dependencies between variables.\n• Conditional probability distributions Pa(z | paa(z)) for each variable z ∈ Xt+1 ∪ Y t+1, specifying the probability that z assumes a certain value given a specific assignment to its parents paa(z) = {z′ | (z′, z) ∈ Ea}. For convenience, we also define pata(Z) = Xt ∩ paa(Z) and pat+1a (Z) = Xt+1 ∩ paa(Z), where paa(Z) = ∪z∈Z paa(z).\nThe edges Ea and distributions Pa define the functions T a and Ωa as\nT a(s, s′) = n∏\ni=1\nPa ( xt+1i = s ′ i | paa(xt+1i )←↩ (s, s′) ) (3)\nΩa(s′, o) = m∏\nj=1\nPa ( yt+1j = oj | paa(yt+1j )←↩ (s′, o) ) (4)\nwhere we use the notation paa(x t+1 i ) ←↩ (s, s′) to specify that the parents of xt+1i in Xt and Xt+1, respectively, assume their corresponding values from s and s′. Formally, if xtl ∈ pata(xt+1i ) and xt+1l′ ∈ pat+1a (xt+1i ), then xtl = sl and xt+1l′ = s′l′ . Similarly, we use the notation paa(y t+1 j ) ←↩ (s′, o) to specify that the parents of yt+1j in Xt+1 and Y t+1, respectively, assume corresponding values from s′ and o.\nExample 2 (DBN representation of robot arm). We can represent the robot arm from Example 1 as a set of DBNs, where we have one DBN ∆a for each action a ∈ {CWi,CCWi}. The state and observation variables in the DBNs are Xt = { θt1, θ t 2, θ t 3 } , Xt+1 = { θt+11 , θ t+1 2 , θ t+1 3 } ,\nand Y t+1 = { θ̂t+11 , θ̂ t+1 2 , θ̂ t+1 3 } . To make our example more realistic, let us assume that the joint orientations are bounded relative to the orientation of the immediately preceding joint (e.g. in the form of a cone), where the first joint is bounded relative to the ground. This means that the joint movement depends on its own as well as the preceding joint orientation, as shown in Figure 3. Moreover, the joint orientations are correlated (i.e. edges within\nXt+1) such that no joint can exceed the bound given by the preceding joint. Finally, the observation variables depend solely on the corresponding joint variable. The actions in this example would differ in their variable distributions Pa."
    }, {
      "heading" : "3.3 Additional Definitions",
      "text" : "It will be useful to define the following:\n• The binary order ≺ is defined over Xt ∪Xt+1 such that xti ≺ xtj and xt+1i ≺ xt+1j for all 1 ≤ i < j ≤ n, and xti ≺ xt+1j for all 1 ≤ i, j ≤ n.\n• Given a set Z ⊆ Xt∪Xt+1, we write Z≺ to denote the tuple that contains all variables of Z, ordered by ≺.\n• Given the ordered tuple Z≺ = (zi1 , ..., zi|Z|), we define the set S(Z) = Xi1 × ....×Xi|Z| to contain all value tuples for the variables in Z.\n• Given a value tuple sZ = (si1 , ..., si|Z|) ∈ S(Z), we use the notation Z ←↩ sZ as an abbreviation for zil = sil for each zil ∈ Z≺ (i.e. the variables in Z assume their corresponding values from sZ)."
    }, {
      "heading" : "4. Passivity",
      "text" : "This section introduces a formal definition of passivity, which will then be used as the basis for the remainder of this article. We also provide a simple procedure to detect passive variables from the process dynamics."
    }, {
      "heading" : "4.1 Formal Definition",
      "text" : "As outlined in Section 1, a state variable xt+1i is called passive in action a if there exists a subset of xt+1i ’s parents in X t (in the DBN ∆a) such that xt+1i may change its value only\nif at least one of the variables in this subset changed its value. Conversely, xt+1i does not change if the variables in the subset did not change. Formally, we define passivity as follows:\nDefinition 3 (Passivity). Let action a be given by a DBN ∆a. A state variable xt+1i is called passive in ∆a if there exists a set Φa,i ⊆ pata(xt+1i ) \\ { xti } such that:\n(i) ∀xtj ∈ Φa,i : ( xt+1j , x t+1 i ) ∈ Ea and (ii) for any two states st and st+1 with T a(st, st+1) > 0 :\n( ∀xtj ∈ Φa,i : stj = st+1j ) ⇒ sti = st+1i (5)\nA state variable which is not passive is called active.\nThe set Φa,i corresponds to the subset of variables described above: it contains all those variables which directly affect xt+1i (i.e. they are parents of x t+1 i in X\nt) such that xt+1i may change its value only if any of the variables in Φa,i changed its value. We will sometimes say that a variable xt+1i is passive in ∆\na with respect to another variable xtj if it is the case that xtj ∈ Φa,i. Furthermore, we will omit “in ∆a” if it is obvious from context.\nClause (i) in Definition 3 requires that xt+1i is intra-correlated with the variables in Φa,i; specifically, that there is an edge from xt+1j to x t+1 i for all x t j ∈ Φa,i. As an example, see Figure 1 in which we assumed that the variable xt+12 was passive with respect to the variable xt1. (We will discuss the purpose of this clause in the next subsection.) Clause (ii) defines the core semantics of passivity by requiring that xt+1i remains unchanged if all variables in Φa,i remain unchanged. Note that this means that the distribution Pa for x t+1 i may specify any deterministic or stochastic behaviour if the variables in Φa,i change their values. This includes that xt+1i may not change its value at all.\nA state variable xt+1i can be passive even if it has no parents in X t, or none other than xti. In this case, the set Φa,i would be empty and clause (i) as well as the premise in (5) would trivially hold true. However, such a variable can only be passive if it does not change its value under any circumstances. In other words, it would have to be a constant. In that case, one should consider removing the variable from the state description in order to reduce computational costs.\nAs noted in Section 2.3, passivity can be shown to be a special kind of context-specific independence (CSI) (Boutilier et al., 1996) applied to DBNs. Here, the associated set Φa,i of a passive variable xt+1i provides the context: given any assignment of values to x t j ∈ Φa,i (i.e. context) such that xtj = x t+1 j , x t+1 i is independent of all x t k, x t+1 k with x t k ∈ pata(xt+1i ) \\ Φa,i and k 6= i. However, besides this similarity, there is an important difference between passivity and CSI, which is that passivity does not actually assume that the context is observed. Thus, passivity can be viewed as a kind of CSI for unobserved contexts. This will become clear in Section 5, when we describe a filtering method that exploits passivity."
    }, {
      "heading" : "4.2 Non-Example of Passivity",
      "text" : "What is the purpose of clause (i) in the definition of passivity? After all, and as discussed previously, clause (ii) captures the core idea of passivity, which is that a variable may only change its value if any of the variables with respect to which it is passive changed its value.\nHowever, while it may seem intuitive that clause (ii) be sufficient for passivity, there are in fact processes in which clause (ii) alone does not suffice. In other words, clause (ii) is necessary but not sufficient for passivity. We illustrate this in the following example:\nExample 3 (Non-example of passivity). Consider a process with two binary state variables, x1, x2, and a single action, a, shown in Figure 4. (We omit the observation variables for clarity.) The dynamics of the process are such that xt+11 takes the value of x t 2 and x t+1 2 takes the value of xt1 (i.e. x1 and x2 swap their values at each time step). In this process, both state variables satisfy clause (ii) of Definition 3: If we set x01 = x 0 2 (i.e. same initial values), then T a(st, st+1) is positive only for states st = st+1, and hence (5) is true. If we set x01 6= x02, then T a(st, st+1) is positive only for states st, st+1 with sti 6= st+1i , i ∈ {1, 2}, and hence (5) is trivially true since its premise is false.\nDespite satisfying clause (ii), the state variables xt+11 and x t+1 2 from Example 3 are in fact not passive, for the following two reasons: Firstly, passivity is a causal relation and as such it must imply a causal order (Pearl, 2000). However, there is no causal order between x1 and x2, because there is no edge between x t+1 1 and x t+1 2 . Secondly, passivity means that a variable may change its value only if another variable with respect to which it is passive (a variable in Φa,i) changed its value. In other words, whether or not a passive variable x t+1 i may change its value depends on both the past values of Φa,i (at time t) and the new values of Φa,i (at time t+ 1). However, the variables in Example 3 only depend on the values at time t, hence their own values at time t+ 1 are predetermined and do not depend on whether the variables in Φa,i change values.\nThe first issue, namely that of the causal order, can be addressed by adding the corresponding edges in Xt+1. For instance, in Example 3 we could add an edge from xt+11 to x t+1 2 to establish a causal order. However, this does not generally solve the second issue, which is that every passive variable xt+1i must depend on both past and new values of the variables in Φa,i. In other words, x t+1 i must be both inter-correlated as well as intra-correlated with the variables in Φa,i. The former is given by definition (since every variable in Φa,i is a parent of xt+1i ) and the latter is precisely what is required by clause (i) in Definition 3. Therefore, clauses (i) and (ii) together define the formal meaning of passivity."
    }, {
      "heading" : "4.3 Detecting Passive Variables",
      "text" : "As mentioned in Section 1, passivity is a latent causal property in the sense that it can be extracted from the process dynamics without additional information, and with no additional assumptions regarding the representation of variable distributions. In order to determine if a\nAlgorithm 1 Passive(xt+1i ,∆ a)\n1: Input: state variable xt+1i , DBN ∆ a 2: Output: Φa,i if x t+1 i is passive in ∆ a, else false 3: Q← OrderedQueue ( P ( pata(x t+1 i ) \\ { xti }))\n// in ascending order of |Φa,i| 4: while Q 6= ∅ do 5: Φa,i ← NextElement(Q) 6: Q← Q \\ {Φa,i} 7: for all xtj ∈ Φa,i do 8: if ( xt+1j , x t+1 i ) 6∈ Ea then\n9: Go to line 4 // clause (i) violated\n10: Ψa,i ← paa(xt+1i ) \\ ( Φa,i ∪ { xti })\n11: Φt+1a,i ← { xt+1j |xtj ∈ Φa,i } 12: for all sΨ ∈ S(Ψa,i), sΦ ∈ S(Φa,i), si ∈ Xi do 13: if Pa ( xt+1i = si | xti = si, Φa,i ←↩ sΦ, Φt+1a,i ←↩ sΦ, Ψa,i ←↩ sΨ ) < 1 then\n14: Go to line 4 // clause (ii) violated\n15: return Φa,i\n16: return false\nvariable xt+1i is passive in ∆ a, one has to find a set Φa,i such that both clauses of Definition 3 are satisfied. A simple procedure which does this for any representation of the variable distributions is given in Algorithm 1. The algorithm takes as inputs a variable xt+1i and a DBN ∆a, and checks whether xt+1i is passive in ∆\na by searching for a set Φa,i which satisfies both clauses of Definition 3. Note that the power set P in line 3 includes the empty set ∅, hence it also accounts for Φa,i = ∅. Lines 7 to 9 check if clause (i) is satisfied while lines 10 to 14 check if clause (ii) is satisfied. Line 13 essentially checks if (5) holds true. If both clauses are satisfied, then xt+1i is passive in ∆\na with respect to the variables in Φa,i, and the algorithm returns the set Φa,i. Otherwise, the algorithm returns a logical false. 2\nThe time complexity of Algorithm 1 is exponential in the worst case, in which xt+1i is not passive. Specifically, the time requirements of line 4 grow exponentially with the number of parents of xt+1i in X\nt, and the time requirements of line 12 grow exponentially with the cardinality of Φa,i and Ψa,i. However, these time requirements can be reduced significantly when committing to specific representations for the variable distributions Pa. For example, if the distributions are represented in tabular form, then one can utilise arrays of indices to perform sweeping tests of (5), i.e. line 13. Moreover, it is important to realise that the algorithm needs to be performed only once for each state variable, prior to the start of the\n2. Strictly speaking, Algorithm 1 checks for a property which is stronger than passivity because it does not check for T a(st, st+1) > 0 (cf. clause (ii)) in line 12. However, the algorithm can be modified to include such a check. We omit this in our exposition in order to highlight the core ideas behind the algorithm.\nprocess or on demand. This is since passivity is invariant of the process states. In other words, if a variable is passive in ∆a, then it will always be passive in ∆a. Therefore, it suffices to check once in advance for passivity.\nNote that the set Φa,i is not necessarily unique. For example, consider a variable x t+1 1\nwhich is passive in ∆a with respect to variables xt2 and x t 3, i.e. Φa,1 = { xt2, x t 3 } , and assume that xt+12 changes if and only if x t+1 3 changes (i.e. they change at the same time). Then, it is\neasy to verify that Φ′a,1 = { xt2 } and Φ′′a,1 = { xt3 }\nalso satisfy clauses (i) and (ii), and hence Φa,1,Φ ′ a,1,Φ ′′ a,1 are all valid sets under our definition of passivity. The guiding principle in such cases is Occam’s razor, which, intuitively speaking, states that the simplest explanation suffices. In our case, this means that it suffices to use the smallest set Φa,i in terms of the cardinality |Φa,i|. (Hence, line 3 in Algorithm 1 sorts the queue Q in ascending order of |Φa,i|.) The rationale is that if there exist multiple causal explanations for a passive variable xt+1i , then the one involving the fewest key variables is to be favoured since it reduces (compared to the alternative explanations) the number of cases in which we would have to revise our beliefs about xt+1i . In our earlier example, if we accept Φa,1 as a causal explanation for xt+11 , then we would have to revise our beliefs for x t+1 1 every time x t+1 2 or x t+1 3 may have changed their values. However, if we accept Φ′a,1 as a causal explanation, then we would have to revise our belief for xt+11 only if x t+1 2 may have changed its value. This difference will become more obvious in Section 5.2, which explains how passivity can be exploited to reduce computational costs."
    }, {
      "heading" : "5. Passivity-based Selective Belief Filtering",
      "text" : "This section presents the Passivity-based Selective Belief Filtering (PSBF) method, which exploits passivity for efficient filtering. As discussed in Section 3, we assume that the process is specified as a set of dynamic Bayesian networks which contains one DBN ∆a for each action a ∈ A. Therefore, whenever we refer to an action a (e.g. T a, Ωa, Pa, paa), this is assumed to be in the context of ∆a.\nPSBF follows the general two-step update procedure in which the belief state is first propagated through the process dynamics (transition step) and then conditioned on the observation (observation step). Thus, it is natural to divide the exposition of PSBF into three parts: (1) the belief state representation, (2) the transition step, and (3) the observation step. These are discussed in Sections 5.1, 5.2, and 5.3, respectively. A summary of PSBF is given in Section 5.4. We also discuss the computational complexity and error bounds of PSBF in Sections 5.5 and 5.6, respectively."
    }, {
      "heading" : "5.1 Belief State Representation",
      "text" : "Recall from Section 1 that the principal idea behind PSBF is to maintain separate beliefs about individual aspects of the process, and to exploit passivity in order to perform selective updates over these separate beliefs. The union of all individual aspects constitutes a complete state description of the process. Therefore, the belief state can be represented as the product of all separate beliefs about the individual aspects.\nWe capture the informal notion of “individual aspects” formally in the form of clusters, which are defined as follows:\nDefinition 4 (Cluster). A clustering of Xt+1 is a set C = {C1, ..., CK} which satisfies ∀k : Ck ⊆ Xt+1 and C1 ∪ ... ∪ CK = Xt+1. We refer to the elements Ck ∈ C as clusters.\nThe underlying idea behind the concept of clusters is that the variables in a cluster Ck are connected in some important sense. Specifically, if two or more variables are in a common cluster, then there exists some relation between these variables regarding the likelihood of values which they may assume. In other words, the variables are correlated in Xt+1.\nThe number K and the concrete choice of clusters Ck can be specified by the user or generated automatically. For example, they may be specified manually by a domain expert who is familiar with the structure of the modelled system, or generated automatically using methods such as the ones described in Section 6.1. It should be stressed, however, that in order to reduce computational costs, it is advisable to follow the general rule “as small as possible, as large as necessary” when choosing clusters (see Section 5.5 for a discussion about computational complexity). Therefore, if two variables are strongly correlated, then they should presumably be in a common cluster, whereas if they are not or only weakly correlated (“weakly” meaning that the correlation can be ignored safely), then they should be in separate clusters in order to reduce computational costs. This is illustrated in the following example:\nExample 4 (Clusters in robot DBN). Recall the robot arm DBN from Example 2, specifically Figure 3. One way to cluster the state variables in Xt+1 is given by the three clusters C1 = { θt+11 } , C2 = { θt+12 } , C3 = { θt+13 } , as shown in Figure 5a. This clustering is most efficient since it minimises the size of each cluster. However, the clusters fail to capture the important correlation that the joint orientation θi is restricted by the preceding joint orientation θi−1. Another way to cluster the state variables is given by the single cluster C1 = { θt+11 , θ t+1 2 , θ t+1 3 } , as shown in Figure 5b. This clustering captures all correlations between variables. However, this is the largest possible cluster and, therefore, the least efficient one. A compromise is given by the two clusters C1 = { θt+11 , θ t+1 2 } , C2 = { θt+12 , θ t+1 3 } , which are shown in Figure 5c. This clustering captures the correlation of the joint orientations with the immediately preceding joint orientations, and it is more efficient than the previous clustering since it has smaller clusters.\nGiven the definition of clusters, we capture the informal notion of “separate beliefs” in the form of belief factors:\nDefinition 5 (Belief factor). Given a cluster Ck, the corresponding belief factor bk is a probability distribution over the set S(Ck).\nIntuitively, a belief factor bk represents the agent’s beliefs as to the likelihood of values for the variables in the corresponding cluster Ck. An analogy to this is to view a belief factor as a “smaller” belief state, and to view b as the “full” belief state which is a combination of the smaller belief states. However, to distinguish the two, we refer to b simply as the belief state and to bk as a belief factor.\nFinally, given the clusters Ck and their corresponding belief factors bk, the belief state b is represented in factored form as\nb(s) = K∏\nk=1\nbk(sk)\nwhere we use the notation sk to refer to the tuple (si)xt+1i ∈Ck . (E.g., if Ck =\n{ xt+12 , x t+1 3 }\nand s = (s1, s2, s3, s4), then sk = (s2, s3).)"
    }, {
      "heading" : "5.2 Exploiting Passivity in the Transition Step",
      "text" : "In order to perform selective updates over the belief factors bk, we require a procedure which performs the transition step independently for each factor.3 We obtain such a procedure by introducing two assumptions which allow us to modify the transition step (1) of the exact update rule. The assumptions guarantee that the transition step is performed exactly, in the sense of (1). However, as we will discuss shortly, the assumptions can be violated to obtain approximate belief states.\nThe first assumption, (A1), states that the clusters must be uncorrelated (i.e. there are no edges in Xt+1 between clusters), and the second assumption, (A2), states that the clusters must be disjoint. Formally, these are defined as follows:\n(A1) ∀a : xt+1i ∈ Ck → pat+1a (xt+1i ) ⊆ Ck\n(A2) ∀k 6= k′ : Ck ∩ Ck′ = ∅\nNote that neither assumption implies the other. That is, it may be the case that (A1) is satisfied while (A2) is violated, and vice versa. Assuming both (A1) and (A2), we can reformulate (1) to\nb̂t+1k (s ′ k) = η1\n∑\ns̄∈S(pat at (Ck))\nT a t k (s̄, s ′ k)\n∏\nk′:[∃xt+1i ∈Ck′ :xti∈ patat (Ck)] btk′(s̄k′) (6)\nwhere η1 is a normalisation constant and\nT ak (s̄, s ′ k) =\n∏\nxt+1i ∈Ck\nPa ( xt+1i = (s ′ k)i | paa(xt+1i )←↩ (s̄, s′k) ) .\n3. This also has the advantage that the belief factors can be updated in parallel, which is a useful feature considering that many platforms use parallel processing techniques.\nThis procedure performs the transition step independently for each belief factor bk, hence they can be updated in any order and in parallel.\nAssumption (A1) is what allows us to bring (1) into a form which updates the belief factors bk independently of each other. Specifically, (A1) allows us to define the cluster-based transition function T ak , which in turn enables the summation in (6). Assumption (A2), on the other hand, guarantees that the product in (6) is correct. In particular, it may be the case that |s̄k′ | < |Ck′ | (i.e. there are fewer elements in s̄k′ than in Ck′) if there are variables in Ck′ which are not in pa t at(Ck) (i.e. x t+1 i ∈ Ck′ but xti /∈ patat(Ck)). In such cases, btk′ is taken to be the marginal distribution over variables xt+1i ∈ Ck′ with xti ∈ patat(Ck), where (A2) guarantees that the marginalisation introduces no errors.\nAs mentioned previously, each assumption may be violated to obtain approximate belief states. However, there is an important distinction between (A1) and (A2) in this regard: If (A2) is violated, then (6) is still well-defined in the sense that it can still be executed, except that the product in (6) may degrade the accuracy of the results. This is in contrast to (A1), which is a structural requirement of T ak in the sense that T a k is ill-defined without (A1). This is since, if (A1) is violated, the variables in Ck may have parents in X t+1 which are not in Ck, in which case paa(x t+1 i )←↩ (s̄, s′k) would be ill-defined. Thus, if (A1) is violated, we have to enforce it by modifying the distributions Pa of all x t+1 i ∈ Ck to marginalise out all variables in pat+1at (x t+1 i ) which are not in Ck, for all clusters Ck. This means that each variable has a separate distribution for every cluster which contains the variable, thereby possibly introducing an approximation error.\nGiven the modified transition step (6), we can exploit passivity to perform selective updates over the belief factors bk. Recall from Section 4.1 that a variable x t+1 i is passive in ∆a if there exists a set Φa,i of variables such that x t+1 i may change its value only if any of the variables in Φa,i changed its value. This causal connection can be used to decide whether or not the values of the variables in a cluster Ck may have changed, in which case the corresponding belief factor bk should be updated. Theorem 1 provides the formal foundation: Theorem 1. If (A1) and (A2) hold, and if all xt+1i ∈ Ck are passive in ∆a t , then\n∀s ∈ S : b̂t+1k (sk) = btk(sk). Proof. Proof in Appendix A.\nTheorem 1 states that if the clusters C1, ..., CK are disjoint and uncorrelated, and if all variables in cluster Ck are passive in ∆\nat , then the transition step for the corresponding belief factor btk → b̂t+1k can be omitted without loss of information.\nHow does Theorem 1 translate into situations in which (A1) or (A2), or both, are violated? The key assumption is again (A1), which states that the clusters must be uncorrelated. As discussed earlier, we can enforce this by modifying the variable distributions Pa in each cluster. However, if a passive variable xt+1i ∈ Ck is correlated with a (passive or active) variable xt+1j ∈ Ck′ , where xt+1j ∈ pat+1a (xt+1i ), then marginalising out xt+1j in the distribution Pa of xt+1i will typically cause x t+1 i to lose its passivity, in the sense that it would no longer satisfy the clauses in Definition 3. Consequently, we would always have to perform the transition step for Ck, even if the unmodified variables in Ck are all passive. This is problematic not only because of the unnecessary computations, but also because the modified distributions will introduce an error every time the transition step is performed.\nTo alleviate this effect, one can check if there is a chance that the unmodified variables in the cluster would change their values. It can be shown that this is the case whenever there is a causal path from any active variable to a variable in the cluster:\nDefinition 6 (Causal path). A causal path in ∆a, from an active variable xt+1i to another variable xt+1j , is a sequence 〈x(1), x(2), ..., x(Q)〉 such that x(1) = xt+1i , x(Q) = xt+1j , and for all for all 1 ≤ q < Q :\n(i) x(q) ∈ Xt+1 (ii) ( x(q), x(q+1) ) ∈ Ea (iii) x(q+1) is passive in ∆a with respect to x(q)\nIntuitively, a causal path defines a chain of causal effects (such as between joints 1 and 3 in Example 1): since the active variable x(1) may have changed its value and x(2) is passive with respect to x(1), x(2) may also have changed its value; since x(2) may have changed its value and x(3) is passive with respect to x(2), x(3) may also have changed its value, etc. Hence, in the absence of observing these changes, the mere existence of a causal path from x(1) to x(Q) is reason to revise our beliefs about x(Q). Therefore, as a general update rule, we can omit the transition step btk → b̂t+1k if all unmodified variables in cluster Ck are passive in ∆a t , and if there is no causal path from any active variable in ∆a t to any variable in Ck. This is demonstrated in the following example:\nExample 5 (PSBF update rule in robot arm DBN). Let us again consider the robot arm from the previous examples. Figure 6 shows a DBN which implements the action CW3. This action rotates joint 3 of the robot arm by 1◦ clock-wise (i.e. the joint orientation θt+13 is a direct target of the action). Therefore, the variable θt+13 is active while the variables θt+11 and θ t+1 2 are passive (shown as dashed circles).\nWe use the clustering C1 = { θt+11 , θ t+1 2 } , C2 = { θt+12 , θ t+1 3 } for reasons given in Example 4. Since θt+11 is a parent of θ t+1 2 , PSBF will have to enforce assumption (A1) by\nAlgorithm 2 SkippableClusters(C,∆a)\n1: Input: clustering C = {C1, ..., CK}, DBN ∆a 2: Output: set of clusters C∗ ⊂ C which can be skipped in transition step 3: C∗ ← C 4: Q← OrderedQueue(Xt+1) 5: while C∗ 6= ∅ ∧Q 6= ∅ do 6: xt+1i ← NextElement(Q) 7: Q← Q \\ { xt+1i } 8: if ¬Passive(xt+1i ,∆a) then 9: C∗ ← C∗ \\ { Ck ∈ C∗ | xt+1i ∈ Ck }\n10: for all xt+1j ∈ Q do 11: if CausalPath(xt+1i , x t+1 j ,∆ a) then\n12: C∗ ← C∗ \\ { Ck ∈ C∗ | xt+1j ∈ Ck } 13: Q← Q \\ { xt+1j } 14: return C∗\nmarginalising θt+11 out of the variable distribution Pa of θ t+1 2 in cluster C2. While the modified variable distribution loses the passivity property (both clauses of Definition 3 are violated), the unmodified distribution of θt+11 is still passive.\nWhen performing the transition step, PSBF has to update the belief factor b2 because the corresponding cluster C2 contains the active variable θ t+1 3 . However, since all variables in cluster C1 are passive (there are no modified variables in C1), and since there is no causal path from θt+13 to any variable in C1, PSBF can omit the update for the belief factor b1. Intuitively, this makes sense since a change in the orientation of joint 3 cannot cause a change in the orientations of the preceding joints. Note that this corresponds to a saving of 50% in the transition step.\nAlgorithm 2 defines a procedure which utilises this rule to find clusters for which the transition step can be skipped. The algorithm takes as inputs a clustering C and a DBN ∆a, and returns a set C∗ of skippable clusters. It essentially searches through all active variables xt+1i in ∆\na and removes all clusters Ck from C which contain variables to which there is a causal path from xt+1i . The function OrderedQueue(X\nt+1) returns an ordered queue Q with all variables in Xt+1. The performance of Algorithm 2 depends on the order of the queue. In our experiments, we obtained good performance by ordering the variables in descending order of their number of outgoing edges. The function NextElement(Q) returns the next element in the queue; the function Passive(xt+1i ,∆\na) is defined in Algorithm 1; and the function CausalPath(xt+1i , x t+1 j ,∆ a) returns a logical true if and only if there is a\ncausal path from xt+1i to x t+1 j in ∆ a.4 Note that, given the invariance of passivity to process states (cf. Section 4.1), it suffices to call Algorithm 2 only once (in advance or as needed) to determine which of the clusters to omit in the transition step."
    }, {
      "heading" : "5.3 Efficient Incorporation of Observations",
      "text" : "PSBF can perform the observation step similarly to the exact update rule (2), which conditions the propagated belief state b̂t+1 on the observation ot+1 to obtain a fully updated belief state bt+1. However, given the factored belief state representation used by PSBF, we require a procedure which respects this factorisation in the observation step. Assuming that (A1) and (A2) both hold, we can bring (2) into a form which updates the belief factors bk independently of each other\nbt+1k (s ′ k) = η2 b̂ t+1 k (s ′ k)\n∑\ns̄∈S(pat+1 at (Y t+1)) : s̄k = s ′ k\nΩa t (s̄, ot+1)\n∏\nk′ 6= k :Ck′∩ pat+1at (Y t+1) 6= ∅\nb̂t+1k′ (s̄k′) (7)\nwhere η2 is a normalisation constant. Note that, analogously to (6), if there are variables in Ck′ which are not in pa t+1 at (Y t+1), then b̂t+1k′ is taken to be the marginal distribution over Ck′ ∩ pat+1at (Y t+1). Assumption (A2) guarantees that the marginalisation introduces no errors. If (A1) and (A2) both hold, then the transition step (6) and observation step (7) produce exact belief states in the sense of (1) and (2), regardless of how many clusters were skipped in the transition step (cf. Theorem 1).\nThe observation step (7) updates all belief states and uses all observation variables in the process. In other words, it ignores the internal structure of the observation variables. However, it is clear that if the variables in a cluster Ck are marginally independent of the observation variables Y t+1 (this can be determined using d-separation (Geiger et al., 1989), or simply by checking if there is a directed path from Ck to Y\nt+1), then there is no need to perform the observation step for the corresponding belief factor bk. This is expressed formally in Theorem 2: Theorem 2. If all xt+1i ∈ Ck are marginally independent of all yt+1j ∈ Y t+1 in ∆a t , then\n∀s ∈ S : bt+1k (sk) = b̂t+1k (sk). Proof. Proof in Appendix B.\nTheorem 2 states that if the variables in Ck are independent of those in Y t+1, then the observation step for bk can be skipped. However, even if Ck is not independent of Y t+1, it may be the case that the variables in Ck depend only on a subset Yk ⊂ Y t+1 of the observation variables. Clearly, in such cases, it suffices to use Yk rather than Y\nt+1 in the observation step. To account for this, we first note that the variables in Y t+1 may be correlated with each other. To preserve the correlations, we subdivide Y t+1 into clusters Ĉl ⊆ Y t+1 and introduce the following assumptions:\n(A3) ∀a : yt+1j ∈ Ĉl → ( paa(y t+1 j ) ∩ Y t+1 ) ⊆ Ĉl\n(A4) ∀l 6= l′ : Ĉl ∩ Ĉl′ = ∅ 4. A simple way to implement this function is to modify a standard graph search method (such as breath-first\nsearch) to check for (iii) in Definition 6, and to apply it to the variables in Xt+1 with edges Ea from ∆ a.\nAssumptions (A3) and (A4) are analogous to (A1) and (A2), respectively, and essentially serve the same purposes for the observation step. To distinguish the clusters Ck and Ĉl, we sometimes refer to the former as state cluster and to the latter as observation cluster. Assuming that (A3) and (A4) both hold, we can redefine the observation step to\nbt+1k (s ′ k) = η2 b̂ t+1 k (s ′ k)\n∏\nl: Ĉl∩Yk 6=∅\n∑\ns̄∈S(pat+1 at (Ĉl)) : s̄k = s ′ k\nΩa t l (s̄, o t+1)\n∏\nk′ 6= k :Ck′∩ pat+1at (Ĉl) 6= ∅ b̂t+1k′ (s̄k′) (8)\nwhere Ωal (s̄, o t+1 l ) = ∏\nyt+1j ∈ Ĉl\nPa ( yt+1j =(o t+1 l )j | paa(yt+1j )←↩ (s̄, ot+1l ) )\nand Yk ⊂ Y t+1 is the set of observation variables which are not marginally independent of the variables in Ck.\nGiven Theorem 2, one can see that (8) is equivalent to (7) if the observation variables are not clustered (or, equivalently, there is a single observation cluster Ĉl = Y\nt+1). However, it is important to note that if the observation variables are clustered (i.e. there are multiple observation clusters Ĉl), then (8) is not necessarily equivalent to (7). To see this, it is helpful to compare the abstract formulations ∏m j=1 ∑ s Ωs(oj) bs and ∑ s ∏m j=1 Ωs(oj) bs, where the former corresponds to (8) and the latter to (7). Therein, (o1, ..., om) ∈ O is an observation, bs is the probability of being in state s ∈ S, and Ωs(oj) is the probability of observing yj = oj in s. These abstract formulations are equivalent for m = 1 or if bs = 1 for some s, but in all other cases they may not be equivalent. Nonetheless, if we fix the number of observation variables m, then (8) approximates (7) closely as we increase the number of state variables n. Our experiments indicate that it often suffices to use just a few more state variables than observation variables in order to obtain good approximations.\nFinally, to show that it suffices to perform the observation step for bk using only those clusters Ĉl whose variables are not independent of the variables in Ck, we observe that (8) is in fact a repeated application of (7) for every Ĉl, where the updated belief factor b t+1 k is used in place of b̂t+1k in the subsequent application. Since every application has the same form as (7) (with Y t+1 = Ĉl), we conclude that Theorem 2 holds, and hence the observation step can be skipped for clusters Ĉl which are independent of Ck."
    }, {
      "heading" : "5.4 Summary of PSBF",
      "text" : "The preceding sections can be summarised as follows:\n• Representation: The belief state bt is represented as a product of K belief factors btk, such that bt(s) = ∏K k=1 b t k(s). Each belief factor b t k is a probability distribution over\nthe set S(Ck), where Ck ⊆ Xt+1 is a cluster of correlated state variables.\n• Transition step: The transition step btk → b̂t+1k is performed using (6), for all clusters Ck which include active variables in ∆\nat , or to which there is a causal path from an active variable in ∆a t . All other clusters are skipped.\n• Observation step: The observation step b̂t+1k → bt+1k is performed using (8), for all clusters Ck which are dependent on the observation variables Y\nt+1, using only those observation clusters Ĉl which are relevant for Ck. All other clusters are skipped.\nAlgorithm 3 PSBF(at, ot+1, (btk)Ck∈C | C, Ĉ, (∆a)a∈A) 1: Input: action at, observation ot+1, belief factors (btk)Ck∈C\n2: Parameters: state clustering C, observation clustering Ĉ, DBNs (∆a)a∈A 3: Output: updated belief factors (bt+1k )Ck∈C\n4: // Transition step\n5: C∗ ← SkippableClusters(C,∆at) 6: for all Ck ∈ C do 7: if Ck ∈ C∗ then 8: b̂t+1k ← btk 9: else\n10: for all s′k ∈ S(Ck) do\n11: b̂t+1k (s ′ k)← η1\n∑\ns̄∈S(pat at (Ck))\nT a t k (s̄, s ′ k)\n∏\nk′:[∃xt+1i ∈Ck′ :xti∈ patat (Ck)] btk′(s̄k′)\n12: // Observation step\n13: for all Ck ∈ C do 14: Yk ← { yt+1j ∈ Y t+1 | there is a directed path from Ck to yt+1j in ∆a t } 15: if Yk = ∅ then 16: bt+1k ← b̂t+1k 17: else\n18: for all s′k ∈ S(Ck) do\n19: bt+1k (s ′ k)← η2 b̂t+1k (s′k)\n∏\nĈl∈ Ĉ : Ĉl∩Yk 6=∅\n∑\ns̄∈S(pat+1 at (Ĉl)) : s̄k = s′k\nΩa t l (s̄, o t+1)\n∏\nk′ 6= k :Ck′∩ pat+1at (Ĉl) 6= ∅ b̂t+1k′ (s̄k′)\n20: return (bt+1k )Ck∈C\nAlgorithm 3 provides a procedural specification of PSBF. The algorithm takes as inputs the action at time t, at, the subsequent observation at time t+ 1, ot+1, and the belief factors at time t, btk. The internal parameters are the state clustering C, the observation clustering Ĉ, and the set of DBNs (∆a)a∈A which define the process. Lines 4 to 11 implement the transition step while lines 12 to 19 implement the observation step. Note that it suffices to execute lines 5 and 14 once in advance (or on demand) and to remember the results for future reference. The algorithm returns the updated belief factors bt+1k ."
    }, {
      "heading" : "5.5 Space and Time Complexity",
      "text" : "A belief factor bk has one element bk(sk) for each sk ∈ S(Ck).5 Thus, the total space required to maintain K belief factors bk is ∑K k=1 |S(Ck)|. Furthermore, the size of the set S(Ck) grows exponentially with the number of variables in Ck, hence the dominant growth factor in the space requirement is given by the largest cluster Ck such that |Ck| = maxk′ |Ck′ |. Therefore, the space complexity of PSBF is in O(exp maxk |Ck|), hence the representation is feasible for reasonably small clusters Ck.\nSimilarly, the number of operations required to perform the transition and observation steps is in the order of 2 ∑K k=1 |S(Ck)| in the worst case (i.e. all clusters need to be updated in both steps). Specifically, line 11 and line 19 in Algorithm 3 are each executed once for every sk ∈ Ck. The dominant growth factor is again given by the largest cluster Ck, hence the time complexity of PSBF is in O(2 exp maxk |Ck|) = O(exp maxk |Ck|). Note that this assumes that the analysis performed by lines 5 and 14 in Algorithm 3 is done in advance.\nThe above time complexity is for the worst case, in which all clusters need to be updated in the transition and observation steps. It is difficult to derive the time complexity for the average case because it is unclear what the average case is in terms of passivity. Even if we stipulate a certain average degree of passivity (e.g. 50% of all variables are passive), it would still be difficult to make a general statement about time requirements since this depends crucially on how the passive variables are distributed across the clusters. For example, even if a process has on average 90% passivity, if there is one active variable in each cluster then every cluster would need to be updated in the transition step. Thus, the only general statement we can make with regards to passivity is that the time complexity of PSBF can be refined to O(exp maxCk∈CT∪CO |Ck|), where CT and CO include only those clusters that need to be updated in the transition and observation step, respectively."
    }, {
      "heading" : "5.6 Error Bounds",
      "text" : "There are five possible sources of approximation errors in PSBF:\n• If the clusters are correlated (i.e. (A1) or (A3) are violated)\n• If the clusters are overlapping (i.e. (A2) or (A4) are violated)\n• Generally in (8) if multiple observation clusters Ĉl are used\nIn the first two cases, the approximation error depends on the amount of correlation and overlap. If there is only little correlation and overlap between the clusters, then the approximation error can be expected to be small. Conversely, if the clusters are strongly correlated and overlapping, then the approximation error can be expected to be large.\nBoyen and Koller (1998) provide a useful analysis of the error bound of any filtering method which uses a factored belief state representation. Since PSBF uses a factored representation, their analysis applies directly to PSBF. The purpose of this section is to restate the main result of their analysis in the context of our work.\nTheir analysis uses the concept of relative entropy (Kullback & Leibler, 1951) as a measure of similarity for belief states:\n5. In practice, it suffices to store only |S(Ck)| − 1 elements, but this is irrelevant in our analysis.\nDefinition 7 (Relative entropy). Let φ and ψ be two probability distributions defined over a set X. The relative entropy from φ to ψ is defined as\nKL(φ||ψ) = ∑\nx∈X φ(x) ln\nφ(x)\nψ(x)\nwhere φ(x) > 0⇒ ψ(x) > 0.\nSimilar to Boyen and Koller (1998), we define the approximation error incurred by PSBF relative to the exact belief state. However, since we consider a decision process with multiple actions a ∈ A (represented by the DBNs ∆a), we define the error for each action respectively:\nDefinition 8 (Approximation error). Let b be an exact belief state and b̃ be the approximation by PSBF. After taking action a, let b′ be the exact update of b (using (1) and (2)) and b̃′ be the PSBF-update of b̃ (using (6) and (8)). Furthermore, let b̌′ be the exact update of b̃ (using (1) and (2)). We say that PSBF incurs error a in ∆a relative to b′ if\nKL(b′||b̃′)−KL(b′||b̌′) ≤ a.\nThe analysis also relies on the concept of mixing rates. Intuitively, the mixing rate γa of a DBN ∆a quantifies the degree of stochasticity in ∆a. It depends on the mixing rates γak of the individual clusters Ck:\nDefinition 9 (Mixing rate). The mixing rate of a cluster Ck ⊂ Xt+1 in ∆a is defined as\nγak = min s′,s′′∈S\n∑\ns∈S(Ck) min\n[ T ak (s ′, s), T ak (s ′′, s) ] .\nIf all Ck satisfy (A1) and (A2), and if all observation variables Y t+1 are in one observation\ncluster, then the mixing rate of ∆a is given by γa = (mink γ a k/r) q where each cluster Ck depends on at most r and influences at most q other clusters Ck′ 6=k (Boyen & Koller, 1998). In the worst case (that is, all (A1–A4) are violated), the minimal mixing rate is given by γak for the single cluster Ck = X t+1.\nFinally, the main result in the work of Boyen and Koller (1998), here restated in the context of our work in Theorem 3, essentially states that the approximation error of PSBF (measured in terms of relative entropy) is bounded by the mixing rates of the process:\nTheorem 3 (Boyen & Koller, 1998). Let bt be an exact belief state and b̃t be the approximation by PSBF using clusters Ck. Then, for any t with states ~s = (s\n0, ..., st) and actions ~a = (a0, ..., at−1), we have\nEo1,...,ot [ KL(bt||b̃t) ] ≤ maxa∈~a a\nmina∈~a γa\nwhere the expectation E is taken over all possible sequences of observations o1, ..., ot with probabilities P (o1, ..., ot) = ∏t−1 τ=0 Ω aτ(sτ+1, oτ+1), and where a and γa are defined as above."
    }, {
      "heading" : "6. Experimental Evaluation",
      "text" : "We evaluated PSBF in two experimental domains: In Section 6.1, we evaluated PSBF in synthetic (i.e. randomly generated) processes with varying sizes and degrees of passivity. In Section 6.2, we evaluated PSBF in a simulation of a multi-robot warehouse system. A brief summary of the experimental results is given in Section 6.3."
    }, {
      "heading" : "6.1 Synthetic Processes",
      "text" : "We first evaluated PSBF in a series of synthetic processes. PSBF is compared with a selection of alternative methods, including PF (Gordon et al., 1993), RBPF (Doucet et al., 2000), BK (Boyen & Koller, 1998), and FF (Murphy & Weiss, 2001); see Section 2 for a discussion of these methods. The algorithms were implemented in Matlab 7.13, where we used the Matlab toolbox BNT (Murphy, 2001) to implement BK and FF."
    }, {
      "heading" : "6.1.1 Specification of Synthetic Processes",
      "text" : "We generated synthetic processes of four different sizes which are specified in Table 1. Each process was generated as follows:\nFirst, each variable xt+1i is chosen to be passive with probability p, in which case we also add the edge (xti, x t+1 i ). We refer to p as the degree of passivity. To sample further edges from Xt/Xt+1 to Xt+1, we generate a mixture of Gaussians G using Algorithm 4 (see Appendix C). Figure 7 shows an example of G generated for a process of size M. The set G is used to produce “areas” of correlated variables (i.e. the Gaussians), which will then constitute natural candidates for state clusters.\nLet ω be the vector of maximum densities for each Gaussian in G, and let δi be the vector of densities at value i ∈ N. Then, for every combination of i and j, the edge (xti, xt+1j ) is added with probability equal to the maximum element in δiδj/ω\n2, in which all operators are point-wise. If xt+1i was chosen to be passive, then the edge (x t i, x t+1 j ) is only added if i < j. In that case, we also add the edge (xt+1i , x t+1 j ). Edges (x t+1 i , x t+1 j ) are added similarly for each i < j,6 where we also add the edge (xti, x t+1 j ) for passive x t+1 j . To ensure that every variable has an effect in the generated process, each xti is connected to at least one x t+1 j (adding (xti, x t+1 i ) if necessary) and each x t+1 j has at least one parent in X t or Xt+1 (adding\n6. The condition i < j in both cases is to ensure that the resulting DBN is acyclic.\ni and x\nt+1\nj are under the peak of a common\nGaussian, the higher the probability that an edge will be added between them.\n(xtj , x t+1 j ) if necessary). Finally, edges (x t+1 i , y t+1 j ) are added with probability 0.1, for each i, j, while ensuring that each yt+1j has at least one parent in X t+1.\nAll variables in the process are binary. Passive variables are assumed to be passive with respect to all of their parents in Xt. The distributions Pa of x t+1 i ∈ Xt+1 are generated uniformly randomly without bias. For passive variables xt+1i , we modify Pa to satisfy clause (ii) in Definition 3. The distributions Pa of y t+1 j ∈ Y t+1 are generated with each probability sampled uniformly from either [0.0, 0.2] or [0.8, 1.0], to obtain meaningful observations. Finally, every process consists of two actions. These are obtained by randomly choosing between one and three variables xt+1i whose distributions Pa are resampled as above and edges from Xt added with probability 0.1 (passive variables chosen in this way are no longer passive). During simulations, these actions are chosen uniformly randomly.\nEach process starts in a random initial state, and all algorithms are tested on the same sequence of processes, initial states, chosen actions, and random numbers."
    }, {
      "heading" : "6.1.2 Clustering Methods",
      "text" : "We used three different clustering methods, denoted 〈pc〉, 〈moral〉, and 〈modis〉. The methods were applied to the variables in Xt+1 without edges involving Xt or Y t+1:\n• 〈pc〉 drops the directions of the edges (i.e. for any edge xt+1i → xt+1j it ads the reverse edge xt+1j → xt+1i ) and puts all variables between which there is a (undirected) path into one cluster. By definition, the resulting clusters satisfy all assumptions (A1–A4).\n• 〈moral〉 connects all parents of a variable and drops the directions (it “moralises” the variables) and then extracts clusters of fully connected variables (“maximum cliques”). The resulting clusters may not satisfy any of the assumptions (A1–A4).\n• 〈modis〉 is similar to 〈moral〉 but truncates the resulting clusters to make them disjoint (clusters are removed if they become a subset of another cluster). By definition, the resulting clusters satisfy (A2/A4), but not necessarily (A1/A3).\nAs an example, consider Figure 5 from Section 5.1. Here, 〈pc〉 would produce the cluster C1 from Figure 5b, since all variables are connected by an undirected path. Furthermore,\n〈moral〉 would produce the two clusters C1 and C2 from Figure 5c, which correspond to the two maximum cliques after moralising the variables in Xt+1. Finally, 〈modis〉 would produce the cluster C1 from Figure 5c and the cluster C3 from Figure 5a.\nPSBF used the same clustering method to generate clusters of state variables (Ck) and observation variables (Ĉl). Moreover, PSBF enforced (A1/A3) whenever necessary by modifying the variable distributions as described in Section 5.1."
    }, {
      "heading" : "6.1.3 Accuracy",
      "text" : "In order to compare the accuracy of the tested algorithms, we computed the relative entropy (cf. Definition 7) from exact belief states obtained using the exact update rule (cf. Definition 1) to the approximate belief states produced by the tested algorithms. However, since exact belief states and relative entropy are hard to compute for large processes, we were able to compare the accuracy of algorithms in processes of size S only. All algorithms were initialised with uniform belief states, or uniformly sampled particles.\nWe first compared the accuracy of PSBF and BK, since they use the same factorisation in their belief state representations. Figure 8 shows the relative entropy of PSBF and BK averaged over 1000 processes with 0%, 20%, 40%, 60%, 80%, and 100% passivity, respectively. The results show that PSBF 〈pc/modis〉 produced a lower relative entropy (i.e. higher accuracy) than BK 〈pc/modis〉, and that PSBF 〈moral〉 produced a relative entropy comparable to that of BK 〈moral〉. This indicates that violations of (A2/A4) introduce smaller errors than violations of (A1/A3). Note that PSBF and BK had the same convergent behaviour in their relative entropy, which shows that the approximation error due to the factorisation was bounded, as discussed in Section 5.6. This is interesting since PSBF and BK obtain approximation errors from the factorisation in different ways: PSBF loses accuracy by modifying the variable distributions to ensure that the state clusters are independent (cf. Section 5.2), while BK loses accuracy by marginalising out the original factorisation after the inference (i.e. the “projection step”; cf. Section 2.1). Nevertheless, as shown in our results, the resulting approximation errors were bounded in both cases, with similar convergence.\nNote that the relative entropy of both methods increased with the degree of passivity in the process. This is explained by the fact that higher passivity implies higher determinacy and, therefore, lower mixing rates (cf. Definition 9), which are a crucial factor in the error bounds of PSBF and BK (cf. Theorem 3). Finally, note that PSBF did not produce exact belief states (i.e. zero relative entropy) when using 〈pc〉 clustering, despite the fact that the clusters generated by 〈pc〉 satisfy all assumptions (A1–A4). However, as discussed in detail in Sections 5.3 and 5.6, another possible source of approximation errors is if multiple observation clusters are used, which was often the case when using 〈pc〉 to produce observation clusters.\nTo compare the accuracy of PF/RBPF with PSBF/BK, the number of samples used in PF/RBPF was chosen automatically in each process such that they required approximately as much time per belief update as PSBF 〈moral〉 and BK 〈moral〉, respectively. In our experiments, this meant that PF (RBPF) was only able to process between 100 and 300 (20 and 50) samples. However, since each process has over 1000 states, this was not nearly enough to represent a uniform belief state. Hence, PF/RBPF produced much higher relative entropy than PSBF/BK. Moreover, the fact that the processes have very high variance means that PF/RBPF would require many more samples to achieve the same accuracy as PSBF/BK (as\nshown in the next section). One would expect that this latter issue was alleviated by the use of exact inference in RBPF (cf. Section 2.1). However, this is only the case if much of the variance in the process can be captured in the marginal distributions used in the particles in RBPF. In contrast, our synthetic processes exhibit high variance across all variables, and our\nautomatic grouping7 of state variables into “sampled” and “exact” variables still contained much variance in the sampled variables. Hence, RBPF required significantly more samples than the number it could process in the time provided.\nFinally, in order to compare the accuracy of FF with PSBF/BK, the number of iterations used in FF (more precisely, the number of iterations in loopy belief propagation; cf. Murphy & Weiss, 2001) was chosen automatically in each process such that FF required approximately as much time per belief update as PSBF 〈moral〉 and BK 〈moral〉, respectively. However, while FF was often able to perform several iterations in the provided time, the resulting relative entropy was again substantially higher than that of PSBF/BK. The problem is that FF was designed for a specific class of DBN topologies, namely those containing no edges within Xt+1 (called “regular” DBNs by Murphy & Weiss, 2001). This is what allows FF to use a fully factored representation of belief states, in which each variable is its own belief factor. However, the processes used in our experiments have high intra-correlation between state variables (i.e. many edges in Xt+1), especially with increasing passivity. These correlations cannot be captured in the belief state representation of FF, resulting in a significantly higher relative entropy than PSBF/BK."
    }, {
      "heading" : "6.1.4 Timing",
      "text" : "We measured computation times in processes of sizes S, M, L, XL with passivities of 25%, 50%, 75%, 100%, respectively. PSBF and BK used 〈moral〉 clustering, which seemed most appropriate for a fair comparison since it produced consistently similar accuracy for both algorithms. The number of samples used in PF was chosen automatically in each process such that PF achieved an average accuracy approximately as good as that of PSBF and BK, respectively, in the final 20% of the process. As this involved computing exact belief states and relative entropies, we were able to use PF in processes of size S only. We omit RBPF and FF in this section as they were shown in the previous section to be unsuitable for the processes we consider. PSBF was tested with 1, 2, and 4 parallel processes, which were allocated approximately the same number of belief factors.\nFigures 9a – 9d show the times for 1000 transitions averaged over 1000 processes, and Figure 9e shows the average percentage of belief factors that were updated in the transition and observation steps of PSBF. The timing reported for PSBF includes the time taken to modify variable distributions (in case of overlapping clusters) and to detect skippable clusters in the transition and observation steps, both of which were done once in advance for each action. The results show that PSBF was able to minimise the time requirements significantly by exploiting passivity. First, we note that there were only marginal gains from 25% to 50% passivity, despite the fact that PSBF updated 14% fewer clusters in the transition step. This is because these clusters were mostly very small. However, there were significant gains from 50% to 75% passivity with average speed-ups of 11% (S), 14% (M), 15% (L), 18% (XL), and\n7. It is an open question how to group state variables into “sampled” and “exact” variables (Doucet et al., 2000). We used a simple heuristic whereby the set of sampled variables contained all variables xt+1i that had no parents in Xt/t+1 or none other than xti. The remaining variables in X\nt+1 constituted the set of exact variables. To ensure that the resulting grouping was valid for all actions (i.e. DBNs) in a process, we considered edges in all involved DBNs; that is, we performed the grouping over the union of Ea for all a. Moreover, to improve efficiency, we further subdivided the set of exact variables into clusters of variables that were connected by undirected edges in Xt+1 without edges involving the sampled variables."
    }, {
      "heading" : "L (trans)",
      "text" : "from 75% to 100% passivity with further average speed-ups of 11% (S), 33% (M), 46% (L), 49% (XL). This shows that the computational gains can grow significantly with both the degree of passivity and the size of the process.\nOur results show that PSBF consistently outperformed BK in all process sizes. There are two main computational savings in PSBF relative to BK: firstly, by skipping over belief factors in the transition and observation steps, and secondly, by not having to perform a potentially expensive projection step to restore the original factorisation after the inference. However, while the times of both algorithms grew exponentially in the size of the process, we note that the relative difference between PSBF and BK decreased significantly for lower degrees of passivity. This is an instance of “No Free Lunch” (see Section 7 for a discussion), which means that PSBF performs best in processes with high passivity but can suffer in performance in processes that lack passivity. Specifically, the computational overhead of modifying variable distributions and detecting skippable belief factors does not amortise\nas effectively in large processes with low passivity. Furthermore, with low passivity, PSBF often has to perform full transition and observation steps (i.e. update all belief factors in each step), which can be costly in large processes.\nHow were BK and PF affected by passivity? Not surprisingly, the performance of BK was nearly unaffected by the increasing degrees of passivity. The junction tree algorithm used in BK benefited marginally from an increased sparsity in the process, but the computational gains were minimal. We were at first unable to use PF as it required too many samples (between 10k and 200k) to achieve comparable accuracy to PSBF/BK, due to the very high variance in the processes. In order to investigate the effect of passivity on PF, we implemented a version of PF which was strictly optimised for binary variables. Interestingly, we found that passivity had an adverse effect on the performance of PF, requiring it to use exponentially more samples with increased passivity (see Figure 9a). This makes sense if we view PF as a factored approximation method (such as PSBF and BK) which means that the analysis in Section 5.6 applies. However, because PF puts all variables into a single cluster (since it is not actually a factored method), the mixing rate of the process will be much lower than for PSBF and BK (as discussed in Section 5.6) and, thus, the error bounds are less tight. To compensate for this, PF requires significantly more samples for increased passivity."
    }, {
      "heading" : "6.2 Multi-robot Warehouse System",
      "text" : "In this section, we demonstrate how passivity can occur naturally in a more complex system and how PSBF can exploit this to accelerate the filtering task. To this end, we consider a multi-robot warehouse system in the style of Kiva (Wurman et al., 2008), in which the robots’ task is to transport goods within the warehouse (cf. Figure 10a)."
    }, {
      "heading" : "6.2.1 Specification of Warehouse System",
      "text" : "Figure 10b shows the initial state of the warehouse simulation. The warehouse consists of 2 workstations (W1, W2), 4 robots (R1–R4), and 16 inventory pods (I1–I16). Each robot can move forward and backward, turn left and right, load and unload an inventory pod (if positioned under the pod), or do nothing. As in Kiva, robots can move under inventory pods unless they are carrying a pod, in which case the other pods become obstacles. The move and turn operations are stochastic in that the robot may move/turn too far (3% chance) or do nothing (2% chance). Each robot possesses two sensors, one telling it which inventory pod it has loaded (if any) and one for the direction it is facing. The direction sensor is noisy in that a random direction may be reported (3% chance).\nEach robot maintains a list of tasks in the form of “Bring inventory pod I to workstation W” (yellow area around W) and “Bring inventory pod I to position (x,y)”. How these tasks are executed depends on the control mode, of which we use two in our simulations:8\n8. Our control modes are ad hoc and often make suboptimal decisions. However, we found that current solution techniques for (DEC-)POMDPs, including approximate methods, were infeasible in this setting. Nonetheless, the quality of the decisions made by our control modes largely depends on the accuracy of the belief states, hence it is important that the belief states are updated accurately. Therefore, the control modes were sufficient for our purposes.\nCentralised mode: A central controller maintains a belief state bt about the state of the warehouse system. At each time t, it samples 100 states from bt and removes all duplicate states, resulting in the set Ŝ = {ŝ1, ŝ2, ...}. It then resamples a state ŝ∗ ∈ Ŝ with probabilities w(ŝ∗) = bt(ŝ∗)/ ∑ q b t(ŝq). Based on ŝ\n∗ and the current task of each robot, it performs an A∗ search (Hart, Nilsson, & Raphael, 1968) (with Manhattan distance) in the space of joint actions to find the optimal action for each robot. After executing their actions, the robots send their sensor readings to the controller, and the controller updates its belief state using the sensor readings.\nDecentralised mode: Each robot maintains its own belief state and there is no communication between the robots. The only knowledge the robots have about each other are their current tasks, communicated by the task allocation module. At each time t, each robot samples the set Ŝ and state ŝ∗ as is done in the centralised mode. Treating the other robots as static obstacles, it performs an A∗ search based on ŝ∗ and its current task to find an action at. This is repeated for each other robot r in all states ŝq ∈ Ŝ, resulting in actions ar,q which are used to obtain distributions πr : A → [0, 1] (A is the set of all actions) with πr(a) = ∑ q : ar,q=a w(ŝq). The robot then executes its ac-\ntion at and updates its belief state using its sensor readings and the distributions πr to average over the other robots’ actions.\nThe tasks are generated by an external scheduler in time intervals sampled from U [1, 10]. Each generated task is assigned to one of the robots through a sequential auction (Dias, Zlot, Kalra, & Stentz, 2006). The robots’ bids are calculated as their total number of steps needed to solve all of their current tasks and the auctioned task (in a simplified model in which the other robots are removed), averaged over all states in Ŝ. The robot with the lowest bid is assigned the task."
    }, {
      "heading" : "6.2.2 DBN Topology and Clustering",
      "text" : "Figure 11 shows an example DBN for a smaller warehouse with one inventory pod and two robots. Each inventory pod I is represented by two variables, I.x and I.y, which correspond to the x and y position of the inventory pod. Each robot R is represented by four variables: R.x/R.y for its x/y position, R.d for its direction, and R.s for its status. The status of a robot R is either R.s=0 (unloaded) or R.s=I (loaded with inventory pod I). Constants such as the size of the warehouse and the positions of the workstations are omitted in the DBN.\nThere are four types of clusters: The I-clusters (C1–C4) preserve the correlation that if R is loaded with I, then I must always have the same position as R (there are two I-clusters for each (I,R) pair); The R-clusters (C5) and S-clusters (C6), respectively, preserve the correlation that no two robots can have the same position or carry the same inventory pod (there is one R/S-cluster for each (Ra,Rb) pair with a > b); And, finally, the D-clusters (C7, C8). PSBF uses singleton observation clusters (i.e. one cluster for each observation variable).\nThere are some differences between the DBNs for the centralised and decentralised modes (Figure 11 uses the centralised mode). In the centralised mode, there is one DBN for each action combination of the robots. Since the controller observes all R.s noise-free, it can add edges from R.x/R.y to I.x/I.y if R.s=I or remove them otherwise to simplify the inference (thus, in Figure 11, R1 is loaded with I1 and R2 is unloaded). In the decentralised mode, each robot only observes its own sensor readings, hence it can add or remove edges only for itself, while edges for all other robots must be permanently added. This also means that the other robots’ status variables (R.s) must be linked to all I.x/I.y and, therefore, included in the I-clusters (to preserve the correlation that I must have the same position as R if R is loaded with I). Moreover, since each robot only knows its own action, there is one DBN for\neach of its own actions, and all variables associated with the other robots are active (the distributions πr defined in the previous section are used to average over their actions)."
    }, {
      "heading" : "6.2.3 Results",
      "text" : "We implemented PSBF, BK, and PF in C#, using the framework Infer.NET (Minka, Winn, Guiver, & Knowles, 2012) to implement BK. This allowed BK to exploit sparsity in the process and offered improved memory handling. PSBF was optimised for sparsity in (6) and (8), respectively, by summing over states s̄ for which all btk′ / b̂ t+1 k′ are positive. PF naturally benefits from sparsity as it allows it to concentrate the samples on fewer states. The number of samples used in PF was set in such a way that the controller decisions were invariant of the random numbers used in the sampling process of PF. This was done to ensure that the results were repeatable. Finally, to maintain sparsity in the process, each probability in the belief states lower than 0.01 was set to 0. All tested algorithms were initialised with an exact belief state, shown in Figure 10b.\nFigure 12 shows the time per transition averaged over 20 different simulations with 100 transitions each. The timing reported for PSBF includes the time needed to modify variable distributions (for overlapping clusters) and to detect skippable belief factors for the transition and observation steps, both of which were done once on demand for every previously unseen DBN. In the centralised mode, PSBF was able to outperform BK on average by 49% and PF by 36%. PF needed 20,000 samples to produce consistent (i.e. repeatable) results. In the decentralised mode, PSBF outperformed BK on average by 17% and PF by 32%. PF now needed 45,000 samples to produce consistent results, due to the increased variance in the process. All differences were statistically significant, based on paired t-tests with a 5% significance level. Note that PSBF and BK were slower in the decentralised mode since the corresponding DBNs had much higher inter-connectivity. In addition, PSBF updated more belief factors since there were more active variables.\nAs expected, PSBF was able to exploit the high degree of passivity in the process to accelerate the filtering task. In many cases, this meant that PSBF needed to update less than half of the belief factors. Precisely how many belief factors had to be updated depends on the\nperformed action. To illustrate this, consider the smaller warehouse DBN shown in Figure 11 (for the centralised mode), in which R1 is moving and R2 is turning. Here, R1.x, R1.y, and R2.d are active variables while all other variables are passive (dashed circles), corresponding to a passivity of 70%. In this DBN, PSBF updates the belief factors corresponding to clusters C1, C2, C5, and C8, since they each contain active variables, and it also updates the belief factors for C3 and C4, since there are directed paths from active variables (R1.x and R1.y) to each of them. Therefore, the only factors which are not updated are for C6 and C7. Now consider the full warehouse in our experiment, which contains 16 inventory pods and 4 robots, resulting in 48 variables with 128 I-clusters, 6 R-clusters, 6 S-clusters, and 4 D-clusters. Assume a similar situation in which one robot moves with an inventory pod, say R4 with I1, while the R1–3 turn. In this case, PSBF updates only 3 of 6 R-clusters (those containing R4), 0 of 6 S-clusters (since no status change), 3 of 4 D-clusters (for R1–3), and 38 of 128 I-clusters (32 I-clusters containing R4 plus 6 I-clusters from R1–3 for I1), amounting to a total saving of 69.44% of belief factors which do not need to be updated.\nThe number of states in the warehouse system (including invalid states) exceeded 1045 states. Therefore, we were unable to compare the accuracy of the tested algorithms in terms of relative entropy. Instead, we compared their accuracy based on the results of the task auctions and the number of completed tasks by the end of each simulation. This gives a good indication of the algorithms’ accuracy, since both the outcome of the auction and the number of completed tasks depend on the accuracy of the belief states. In the centralised mode, the algorithms generated over 95% identical task auctions and completed 15.7 (BK), 15.5 (PSBF), and 15.2 (PF) tasks on average. In the decentralised mode, they generated over 93% identical auctions and completed 12.1 (BK), 12.2 (PSBF), and 11.7 (PF) tasks on average. In both modes, none of these differences were statistically significant. Therefore, this indicates that PSBF achieved an accuracy similar to that of BK and PF."
    }, {
      "heading" : "6.3 Summary of Experimental Evaluation",
      "text" : "The experimental results show that PSBF produces belief states with competitive accuracy: In the synthetic processes, PSBF achieved an accuracy which on average was better or comparable to the accuracy of the alternative methods. In the warehouse system, PSBF was able to complete a statistically equivalent number of tasks as compared to the other methods, which indicates that its accuracy was equivalent or comparable.\nFurthermore, the experimental results show that PSBF performed the belief updates significantly faster than the alternative methods: In the synthetic processes, PSBF using no parallel processes outperformed BK by up to 64% in the largest process (XL), while PF took too much time to achieve an accuracy comparable to PSBF. In particular, the results show that the computational gains can grow significantly with both the degree of passivity and the size of the process. In the warehouse system, PSBF outperformed the alternative methods by up to 49%, which is a substantial saving considering the size of the state space (more than 1045 states). Furthermore, the computational gains where much higher in the centralised control mode than in the decentralised control mode, since the latter had a significantly lower degree of passivity. Therefore, this again shows that high degrees of passivity can bear great potential for the filtering task."
    }, {
      "heading" : "7. No Free Lunch for PSBF",
      "text" : "Our view is that no belief filtering method is generally suited for all types of processes. Instead, each method assumes a certain structure in the process (explicitly or implicitly) which it attempts to exploit in order to render the filtering task more tractable. Typically, the methods are tailored in such a way with respect to this structure that they perform well if the structure is present in the process, but suffer a significant loss in performance if the structure is absent. For instance, PF works best in processes with low degrees of uncertainty, since this means that fewer state samples are needed for acceptable approximations. On the other hand, the number of samples needed for acceptable approximations can grow substantially with the degree of uncertainty in the process (as shown in our experiments). As another example, BK works best in processes with little correlation between state variables, since this means that the belief factors will be small and can be processed efficiently. However, if there are many variables which are strongly correlated, then BK typically becomes infeasible. Therefore, these structural assumptions have to be taken into account when choosing a filtering method for a specific process.\nA formal account of this view is given by the “No Free Lunch” theorems (Wolpert & Macready, 1997, 1995) which state that, intuitively speaking, any two algorithms have equivalent performance when averaged over all possible instances of the problem. In other words, if there are classes of problem instances for which algorithm A has better performance than algorithm B, then there must be other classes of problem instances for which A has worse performance than B. Then, the question is: for what class of problem instances (that is, processes) can PSBF be expected to achieve good performance? This class is essentially described by the following three criteria:\nDegree of passivity — PSBF attempts to accelerate the filtering task by omitting the transition step for as many belief factors as possible. This depends on the passivity of the variables in the state clusters. In the ideal case, the process exhibits a high degree of passivity such that PSBF can omit the transition step for many belief factors. In the worst case, the process has no passive variables at all, and PSBF has to update all belief factors in the transition step. However, as discussed in Section 5.5, a high degree of passivity is not necessarily sufficient to infer that many clusters can be skipped in the transition step, since the passive variables could be distributed in such a way that no cluster can be skipped (e.g. if the passive variables are distributed uniformly amongst the state clusters). Therefore, in an optimal case, the passivity is concentrated on correlated state variables such that passive variables end up in the same clusters.\nSize of state clusters — The space and time complexity of the belief state representation in PSBF is exponential in the size of the largest state cluster (cf. Section 5.5). Therefore, in the ideal case, the relevant variable correlations can be captured in small state clusters and the cost of storing the belief factors and performing the update procedures is small. In the worst case, large state clusters are required to retain the variable correlations and the cost of storing and updating belief factors is large. Another reason why the state clusters should be small is because of the way in which PSBF performs the transition step. One pre-requisite for omitting the transition step for a belief factor is that all variables in the corresponding cluster are passive. If there are many variables\nin one cluster, then it is less likely that all variables in the cluster are passive, and, therefore, it is less likely that the cluster can be skipped.\nStructure of observations — A third criterion, though arguably less important than the other criteria, is the structure of the observations (i.e. the way in which the observation variables depend on the state variables) and the size of the observation clusters (Ĉl). PSBF attempts to accelerate the observation step by skipping over all those state clusters whose variables are structurally independent of the observation, and, if a cluster cannot be skipped, by incorporating only those observation clusters which are relevant to the update. Therefore, in the ideal case, only a fraction of the state clusters depend on the observation, and the relevant correlations between observation variables can be captured in small observation clusters. In the worst case, all state clusters depend on the observation in some sense, and the structure of the observation does not allow for an efficient clustering.\nThus, in summary, PSBF is most suitable for processes with high degrees of passivity and in which the relevant variable correlations can be captured in small state and observation clusters. On the other hand, PSBF may not be suitable if there is no or only low degrees of passivity, and if large state and observation clusters are necessary to retain the relevant variable correlations in the process.\nIn addition to identifying the class of processes for which a filtering method is suitable, it is also important to justify the practical relevance of this class. In this work, we are interested in robotic and other physical decision processes (as shown by our examples and experiments). Such systems typically exhibit a number of features: First of all, robotic systems usually have some causal structure (e.g. Mainzer, 2010; Pearl, 2000). Passivity, as a specific type of causality, can be observed in many robotic systems, including the robot arm used in our examples and the multi-robot warehouse system in Section 6.2. Furthermore, robotic systems most typically have a modular structure, in which each module is responsible for a specific subtask and may interact with other modules. This modular structure often allows for an efficient clustering, in the sense that each module corresponds to a cluster of correlated state variables. Finally, the sensors used in robotic systems typically only provide information about certain aspects of the system, and some components of the system may not benefit from some of the sensor information. In other words, there are independencies between state and observation variables. These features correspond to the criteria (above) which specify the class of processes for which PSBF is a suitable filtering method. Therefore, we believe that this class is practically justified."
    }, {
      "heading" : "8. Conclusion",
      "text" : "Inferring the state of a stochastic process can be a difficult technical challenge in complex systems with large state spaces. The key to developing efficient solutions is to identify special structure in the process, e.g. in the topology and parameterisation of dynamic Bayesian networks, which can be leveraged to render the filtering task more tractable.\nTo this end, the present article explored the idea of automatically detecting and exploiting causal structure in order to accelerate the belief filtering task. We considered a specific type of causal relation, termed passivity, which pertains to how state variables cause changes in other\nstate variables. To demonstrate the potential of exploiting passivity, we developed a novel filtering method, PSBF, which uses a factored belief state representation and exploits passivity to perform selective updates over the belief factors. PSBF produces exact belief states under certain assumptions and approximate belief states otherwise. We showed empirically, in synthetic processes with varying sizes and degrees of passivity as well as in an example of a complex multi-robot system, that PSBF can be faster than several alternative methods while achieving competitive accuracy. In particular, our results showed that the computational gains can grow significantly with the size of the process and the degree of passivity.\nOur work demonstrates that if a system exhibits much causal structure, then there can be great potential in exploiting this structure to render the filtering task more tractable. In particular, our experiments support our initial hypothesis that factored beliefs and passivity can be a useful combination in large processes. This insight is relevant for complex processes with high degrees of causality, such as robots used in homes, offices, and industrial factories, where the filtering task may constitute a major impediment due to the often very large state space of the system.\nThere are several potential directions for future work. For example, it would be useful to know if the definition of passivity could be relaxed such that more variables fall under this definition, and such that the principal idea behind PSBF is still applicable. One such relaxation could be in the form of approximate passivity, which allows for small probabilities that passive variables change values even if the relevant parents remain unchanged. In addition, it would be interesting to know if the idea of performing selective updates over belief factors (via passivity) could also be applied to other existing methods that use a factored belief state representation (cf. Section 2.1). Finally, another useful avenue for future work would be to formulate additional types of causal relations which can be exploited in ways similar to how PSBF exploits passivity, or perhaps in ways other than that."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This article is the result of a long debate on the presented topic, and in the process benefited from a number of discussions and suggestions. In particular, the authors wish to thank anonymous reviewers from the NIPS’12 and UAI’13 conferences as well as the Journal of AI Research; attendees of the workshop on “Advances in Causal Inference” held at UAI’15; and our colleagues in the School of Informatics at The University of Edinburgh. Furthermore, the authors acknowledge the financial support of the German National Academic Foundation, the UK Engineering and Physical Sciences Research Council (grant number EP/H012338/1), and the European Commission (TOMSY Grant Agreement 270436)."
    }, {
      "heading" : "Appendix A. Proof of Theorem 1",
      "text" : "To prove Theorem 1, it will be useful to first establish the following lemma:\nLemma 1. If (A1) holds and all xt+1i ∈ Ck are passive in ∆a, then\n∀s, s′ : T ak (s, s′k) = 1⇔ sk = s′k.\nProof.\n⇒: The fact of (A1) means that Φa,i ⊆ Ck for all xt+1i ∈ Ck. Since all xt+1i ∈ Ck are passive in ∆a, it follows that all xtj ∈ Φa,i are passive in ∆a, for all Φa,i. Therefore, given T ak (s, s ′ k) = 1 and clause (ii) in Definition 3, it follows that sk = s ′ k.\n⇐: Follows directly by (A1) and the fact that all xt+1i ∈ Ck are passive in ∆a.\nUsing Lemma 1, we can give a compact proof of Theorem 1:\nTheorem 2. If (A1) and (A2) hold, and if all xt+1i ∈ Ck are passive in ∆a t , then\n∀s : b̂t+1k (sk) = btk(sk).\nProof.\nb̂t+1k (s ′ k) = η1\n∑\ns̄∈S(pat at (Ck))\nT a t k (s̄, s ′ k)\n∏\nk′:[∃xt+1i ∈Ck′ :xti∈ patat (Ck)] btk′(s̄k′)\nLem1 = η1\n∑\ns̄∈S(pat at (Ck)):s̄k=s ′ k\nT a t k (s̄, s ′ k)\n∏\nk′:[∃xt+1i ∈Ck′ :xti∈ patat (Ck)] btk′(s̄k′)\n= η1 b t k(sk)\n∑\ns̄∈S(pat at (Ck)):s̄k=s ′ k\nT a t k (s̄, s ′ k)\n∏\nk′ 6= k:[∃xt+1i ∈Ck′ :xti∈ patat (Ck)] btk′(s̄k′)\n︸ ︷︷ ︸ (A1) = 1\n= η1 b t k(sk)\n= btk(sk). (η1 = 1 since b t k normalised)"
    }, {
      "heading" : "Appendix B. Proof of Theorem 2",
      "text" : "To prove Theorem 2, we first note the following proposition:\nProposition 1. If all xt+1i ∈ Ck are marginally independent of all yt+1j ∈ Y t+1 in ∆a t , then\n∀s, s′ : ( ∧k′ 6=k sk′ = s′k′ ) → Ωa(s, ot) = Ωa(s′, ot).\nThis proposition follows directly by definition.\nUsing Proposition 1, we can give a compact proof of Theorem 2:\nTheorem 2. If all xt+1i ∈ Ck are marginally independent of all yt+1j ∈ Y t+1 in ∆a t , then\n∀s : bt+1k (sk) = b̂t+1k (sk).\nProof.\nbt+1k (s ′ k) = η2 b̂ t+1 k (s ′ k)\n∑\ns̄∈S(pat+1 at (Y t+1)) : s̄k = s ′ k\nΩa t (s̄, ot+1)\n∏\nk′ 6= k :Ck′∩ pat+1at (Y t+1) 6= ∅\nb̂t+1k′ (s̄k′)\n︸ ︷︷ ︸ Prop1\n= constant α, independent of s′k\n= b̂t+1k (s ′ k)α∑\ns′′k b̂t+1k (s ′′ k)α\n= b̂t+1k (s ′ k)∑\ns′′k b̂t+1k (s ′′ k)\n= b̂t+1k (s ′ k)."
    }, {
      "heading" : "Appendix C. Mixture of Gaussians",
      "text" : "Algorithm 4 provides a simple procedure that randomly generates a mixture of Gaussians (i.e. a set of normal distributions) for the synthetic processes in Section 6.1. The algorithm takes as input the number n of state variables and returns a set G of Gaussians whose means are in the set {1, ..., n}. The number of Gaussians, their means, and their variances are chosen automatically so as to achieve good “coverage” of state variables while minimising the (visual) overlap of Gaussians. See Figure 7 for an example.\nAlgorithm 4 MixtureOfGaussians(n)\n1: Input: number of state variables n\n2: Parameters: λ← 4, σmin ← 5λ , σmax ← n10 3: Output: mixture of Gaussians G\n4: G← ∅ 5: R← {(1, ..., n)} 6: while R 6= ∅ do 7: R← next element of R 8: R← R \\ {R} 9: µ← R(drand ∗ |R|e) // rand returns random number from (0, 1)\n10: β ← λ−1 min[µ−R(1), R(|R|)− µ] 11: σ ← min[σmax, max[σmin, rand ∗ β]] 12: G← G ∪ { (µ, σ2) } // mean and variance of Gaussian\n13: R− ← (R(1), R(2), ..., R(p)) such that R(p) < µ− σλ 14: R+ ← (R(q), R(q + 1), ..., R(|R|)) such that R(q) > µ+ σλ 15: if R− 6= ∅ then 16: R← R ∪ {R−} 17: if R+ 6= ∅ then 18: R← R ∪ {R+} 19: return G"
    } ],
    "references" : [ {
      "title" : "Optimal control of Markov processes with incomplete state information",
      "author" : [ "K. Astrom" ],
      "venue" : "Journal of Mathematical Analysis and Applications,",
      "citeRegEx" : "Astrom,? \\Q1965\\E",
      "shortCiteRegEx" : "Astrom",
      "year" : 1965
    }, {
      "title" : "Decision-theoretic planning: structural assumptions and computational leverage",
      "author" : [ "C. Boutilier", "T. Dean", "S. Hanks" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Boutilier et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Boutilier et al\\.",
      "year" : 1999
    }, {
      "title" : "Context-specific independence in Bayesian networks",
      "author" : [ "C. Boutilier", "N. Friedman", "M. Goldszmidt", "D. Koller" ],
      "venue" : "In Proceedings of the 12th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Boutilier et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Boutilier et al\\.",
      "year" : 1996
    }, {
      "title" : "Tractable inference for complex stochastic processes",
      "author" : [ "X. Boyen", "D. Koller" ],
      "venue" : "In Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Boyen and Koller,? \\Q1998\\E",
      "shortCiteRegEx" : "Boyen and Koller",
      "year" : 1998
    }, {
      "title" : "Exploiting the architecture of dynamic systems",
      "author" : [ "X. Boyen", "D. Koller" ],
      "venue" : "In Proceedings of the 16th National Conference on Artificial Intelligence,",
      "citeRegEx" : "Boyen and Koller,? \\Q1999\\E",
      "shortCiteRegEx" : "Boyen and Koller",
      "year" : 1999
    }, {
      "title" : "A heuristic variable grid solution method for POMDPs",
      "author" : [ "R. Brafman" ],
      "venue" : "In Proceedings of the 14th National Conference on Artificial Intelligence,",
      "citeRegEx" : "Brafman,? \\Q1997\\E",
      "shortCiteRegEx" : "Brafman",
      "year" : 1997
    }, {
      "title" : "Future challenges of coordinating hundreds of autonomous vehicles in distribution facilities",
      "author" : [ "R. D’Andrea", "P. Wurman" ],
      "venue" : "In Proceedings of the IEEE International Conference on Technologies for Practical Robot Applications,",
      "citeRegEx" : "D.Andrea and Wurman,? \\Q2008\\E",
      "shortCiteRegEx" : "D.Andrea and Wurman",
      "year" : 2008
    }, {
      "title" : "A model for reasoning about persistence and causation",
      "author" : [ "T. Dean", "K. Kanazawa" ],
      "venue" : "Computational Intelligence,",
      "citeRegEx" : "Dean and Kanazawa,? \\Q1989\\E",
      "shortCiteRegEx" : "Dean and Kanazawa",
      "year" : 1989
    }, {
      "title" : "Market-based multirobot coordination: a survey and analysis",
      "author" : [ "M. Dias", "R. Zlot", "N. Kalra", "A. Stentz" ],
      "venue" : "Proceedings of the IEEE,",
      "citeRegEx" : "Dias et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dias et al\\.",
      "year" : 2006
    }, {
      "title" : "Sequential Monte Carlo Methods in Practice",
      "author" : [ "A. Doucet", "N. de Freitas", "N. Gordon" ],
      "venue" : null,
      "citeRegEx" : "Doucet et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Doucet et al\\.",
      "year" : 2001
    }, {
      "title" : "Rao-Blackwellised particle filtering for dynamic Bayesian networks",
      "author" : [ "A. Doucet", "N. De Freitas", "K. Murphy", "S. Russell" ],
      "venue" : "In Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Doucet et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Doucet et al\\.",
      "year" : 2000
    }, {
      "title" : "d-separation: from theorems to algorithms",
      "author" : [ "D. Geiger", "T. Verma", "J. Pearl" ],
      "venue" : "In Proceedings of the 5th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Geiger et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Geiger et al\\.",
      "year" : 1989
    }, {
      "title" : "Novel approach to nonlinear/non-Gaussian Bayesian state estimation",
      "author" : [ "N. Gordon", "D. Salmond", "A. Smith" ],
      "venue" : "In IEE Proceedings F (Radar and Signal Processing),",
      "citeRegEx" : "Gordon et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Gordon et al\\.",
      "year" : 1993
    }, {
      "title" : "A formal basis for the heuristic determination of minimum cost paths",
      "author" : [ "P. Hart", "N. Nilsson", "B. Raphael" ],
      "venue" : "In IEEE Transactions on Systems Science and Cybernetics,",
      "citeRegEx" : "Hart et al\\.,? \\Q1968\\E",
      "shortCiteRegEx" : "Hart et al\\.",
      "year" : 1968
    }, {
      "title" : "Value-function approximations for partially observable Markov decision processes",
      "author" : [ "M. Hauskrecht" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Hauskrecht,? \\Q2000\\E",
      "shortCiteRegEx" : "Hauskrecht",
      "year" : 2000
    }, {
      "title" : "Causal independence for knowledge acquisition and inference",
      "author" : [ "D. Heckerman" ],
      "venue" : "In Proceedings of the 9th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Heckerman,? \\Q1993\\E",
      "shortCiteRegEx" : "Heckerman",
      "year" : 1993
    }, {
      "title" : "A new look at causal independence",
      "author" : [ "D. Heckerman", "J. Breese" ],
      "venue" : "In Proceedings of the 10th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Heckerman and Breese,? \\Q1994\\E",
      "shortCiteRegEx" : "Heckerman and Breese",
      "year" : 1994
    }, {
      "title" : "Planning and acting in partially observable stochastic domains",
      "author" : [ "L. Kaelbling", "M. Littman", "A. Cassandra" ],
      "venue" : "Artificial intelligence,",
      "citeRegEx" : "Kaelbling et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Kaelbling et al\\.",
      "year" : 1998
    }, {
      "title" : "Probabilistic Graphical Models: Principles and Techniques",
      "author" : [ "D. Koller", "N. Friedman" ],
      "venue" : null,
      "citeRegEx" : "Koller and Friedman,? \\Q2009\\E",
      "shortCiteRegEx" : "Koller and Friedman",
      "year" : 2009
    }, {
      "title" : "On information and sufficiency",
      "author" : [ "S. Kullback", "R. Leibler" ],
      "venue" : "The Annals of Mathematical Statistics,",
      "citeRegEx" : "Kullback and Leibler,? \\Q1951\\E",
      "shortCiteRegEx" : "Kullback and Leibler",
      "year" : 1951
    }, {
      "title" : "Local computations with probabilities on graphical structures and their application to expert systems",
      "author" : [ "S. Lauritzen", "D. Spiegelhalter" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "Lauritzen and Spiegelhalter,? \\Q1988\\E",
      "shortCiteRegEx" : "Lauritzen and Spiegelhalter",
      "year" : 1988
    }, {
      "title" : "Computationally feasible bounds for partially observed Markov decision processes",
      "author" : [ "W. Lovejoy" ],
      "venue" : "Operations Research,",
      "citeRegEx" : "Lovejoy,? \\Q1991\\E",
      "shortCiteRegEx" : "Lovejoy",
      "year" : 1991
    }, {
      "title" : "Causality in natural, technical, and social systems",
      "author" : [ "K. Mainzer" ],
      "venue" : "European Review,",
      "citeRegEx" : "Mainzer,? \\Q2010\\E",
      "shortCiteRegEx" : "Mainzer",
      "year" : 2010
    }, {
      "title" : "The Bayes net toolbox for Matlab",
      "author" : [ "K. Murphy" ],
      "venue" : "Computing Science and Statistics,",
      "citeRegEx" : "Murphy,? \\Q2001\\E",
      "shortCiteRegEx" : "Murphy",
      "year" : 2001
    }, {
      "title" : "The factored frontier algorithm for approximate inference in DBNs",
      "author" : [ "K. Murphy", "Y. Weiss" ],
      "venue" : "In Proceedings of the 17th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Murphy and Weiss,? \\Q2001\\E",
      "shortCiteRegEx" : "Murphy and Weiss",
      "year" : 2001
    }, {
      "title" : "Dynamic Bayesian Networks: Representation, Inference and Learning",
      "author" : [ "K. Murphy" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "Murphy,? \\Q2002\\E",
      "shortCiteRegEx" : "Murphy",
      "year" : 2002
    }, {
      "title" : "Factored particles for scalable monitoring",
      "author" : [ "B. Ng", "L. Peshkin", "A. Pfeffer" ],
      "venue" : "In Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Ng et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Ng et al\\.",
      "year" : 2002
    }, {
      "title" : "Learning symbolic models of stochastic domains",
      "author" : [ "H. Pasula", "L. Zettlemoyer", "L. Kaelbling" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Pasula et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Pasula et al\\.",
      "year" : 2007
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "author" : [ "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "Pearl,? \\Q1988\\E",
      "shortCiteRegEx" : "Pearl",
      "year" : 1988
    }, {
      "title" : "Causality: Models, Reasoning, and Inference",
      "author" : [ "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "Pearl,? \\Q2000\\E",
      "shortCiteRegEx" : "Pearl",
      "year" : 2000
    }, {
      "title" : "Point-based value iteration: an anytime algorithm for POMDPs",
      "author" : [ "J. Pineau", "G. Gordon", "S. Thrun" ],
      "venue" : "In Proceedings of the 18th International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Pineau et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Pineau et al\\.",
      "year" : 2003
    }, {
      "title" : "Exploiting contextual independence in probabilistic inference",
      "author" : [ "D. Poole", "N. Zhang" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Poole and Zhang,? \\Q2003\\E",
      "shortCiteRegEx" : "Poole and Zhang",
      "year" : 2003
    }, {
      "title" : "Value-directed belief state approximation for POMDPs",
      "author" : [ "P. Poupart", "C. Boutilier" ],
      "venue" : "In Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Poupart and Boutilier,? \\Q2000\\E",
      "shortCiteRegEx" : "Poupart and Boutilier",
      "year" : 2000
    }, {
      "title" : "Vector-space analysis of belief-state approximation for POMDPs",
      "author" : [ "P. Poupart", "C. Boutilier" ],
      "venue" : "In Proceedings of the 17th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Poupart and Boutilier,? \\Q2001\\E",
      "shortCiteRegEx" : "Poupart and Boutilier",
      "year" : 2001
    }, {
      "title" : "Value-directed compression of POMDPs",
      "author" : [ "P. Poupart", "C. Boutilier" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Poupart and Boutilier,? \\Q2002\\E",
      "shortCiteRegEx" : "Poupart and Boutilier",
      "year" : 2002
    }, {
      "title" : "Finding approximate POMDP solutions through belief compression",
      "author" : [ "N. Roy", "G. Gordon", "S. Thrun" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Roy et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Roy et al\\.",
      "year" : 2005
    }, {
      "title" : "Point-based POMDP algorithms: improved analysis and implementation",
      "author" : [ "T. Smith", "R. Simmons" ],
      "venue" : "In Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Smith and Simmons,? \\Q2005\\E",
      "shortCiteRegEx" : "Smith and Simmons",
      "year" : 2005
    }, {
      "title" : "The Optimal Control of Partially Observable Markov Processes",
      "author" : [ "E. Sondik" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "Sondik,? \\Q1971\\E",
      "shortCiteRegEx" : "Sondik",
      "year" : 1971
    }, {
      "title" : "A generalization of noisy-or model",
      "author" : [ "S. Srinivas" ],
      "venue" : "In Proceedings of the 9th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Srinivas,? \\Q1993\\E",
      "shortCiteRegEx" : "Srinivas",
      "year" : 1993
    }, {
      "title" : "BI-POMDP: bounded, incremental partially-observable Markovmodel planning",
      "author" : [ "R. Washington" ],
      "venue" : "In Recent Advances in AI Planning,",
      "citeRegEx" : "Washington,? \\Q1997\\E",
      "shortCiteRegEx" : "Washington",
      "year" : 1997
    }, {
      "title" : "No free lunch theorems for search",
      "author" : [ "D. Wolpert", "W. Macready" ],
      "venue" : "Tech. rep. SFI-TR95-02-010, Santa Fe Institute",
      "citeRegEx" : "Wolpert and Macready,? \\Q1995\\E",
      "shortCiteRegEx" : "Wolpert and Macready",
      "year" : 1995
    }, {
      "title" : "No free lunch theorems for optimization",
      "author" : [ "D. Wolpert", "W. Macready" ],
      "venue" : "IEEE Transactions on Evolutionary Computation,",
      "citeRegEx" : "Wolpert and Macready,? \\Q1997\\E",
      "shortCiteRegEx" : "Wolpert and Macready",
      "year" : 1997
    }, {
      "title" : "Coordinating hundreds of cooperative, autonomous vehicles in warehouses",
      "author" : [ "P. Wurman", "R. D’Andrea", "M. Mountz" ],
      "venue" : "AI Magazine,",
      "citeRegEx" : "Wurman et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Wurman et al\\.",
      "year" : 2008
    }, {
      "title" : "Exploiting causal independence in Bayesian network inference",
      "author" : [ "N. Zhang", "D. Poole" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Zhang and Poole,? \\Q1996\\E",
      "shortCiteRegEx" : "Zhang and Poole",
      "year" : 1996
    }, {
      "title" : "An improved grid-based approximation algorithm for POMDPs",
      "author" : [ "R. Zhou", "E. Hansen" ],
      "venue" : "In Proceedings of the 17th International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Zhou and Hansen,? \\Q2001\\E",
      "shortCiteRegEx" : "Zhou and Hansen",
      "year" : 2001
    } ],
    "referenceMentions" : [ {
      "referenceID" : 28,
      "context" : "A number of exact and approximate inference methods exist for Bayesian networks (see, e.g., Koller & Friedman, 2009; Pearl, 1988) which can be used for filtering in DBNs, by applying them to the “unrolled” DBN in which the t+ 1 slice is repeated for each observed time step, or via a successive update in which the current posterior (belief state) is used",
      "startOffset" : 80,
      "endOffset" : 129
    }, {
      "referenceID" : 37,
      "context" : "In this article, we are interested in the application of DBNs as representations of actions in partially observed decision processes, such as POMDPs (Kaelbling, Littman, & Cassandra, 1998; Sondik, 1971) and their many variants.",
      "startOffset" : 149,
      "endOffset" : 202
    }, {
      "referenceID" : 29,
      "context" : "In many cases, decision processes exhibit high degrees of causal structure (Pearl, 2000), by which we mean that a change in one part of the process may cause a change in another part.",
      "startOffset" : 75,
      "endOffset" : 88
    }, {
      "referenceID" : 22,
      "context" : "It is worth pointing out that passivity occurs naturally and frequently in many planning domains, especially in robotic and other physical systems (Mainzer, 2010).",
      "startOffset" : 147,
      "endOffset" : 162
    }, {
      "referenceID" : 28,
      "context" : "The authors show that their method is equivalent to a single iteration of loopy belief propagation (LBP) (Pearl, 1988).",
      "startOffset" : 105,
      "endOffset" : 118
    }, {
      "referenceID" : 21,
      "context" : "Murphy and Weiss (2001) propose a filtering method called factored frontier (FF).",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 3,
      "context" : "Therefore, the analysis of approximation errors by Boyen and Koller (1998) also applies to PSBF, as we show in Section 5 as well as in our experiments.",
      "startOffset" : 51,
      "endOffset" : 75
    }, {
      "referenceID" : 17,
      "context" : "The methods discussed in the preceding subsection can be used for belief filtering in decision processes, including POMDPs (Kaelbling et al., 1998; Sondik, 1971).",
      "startOffset" : 123,
      "endOffset" : 161
    }, {
      "referenceID" : 37,
      "context" : "The methods discussed in the preceding subsection can be used for belief filtering in decision processes, including POMDPs (Kaelbling et al., 1998; Sondik, 1971).",
      "startOffset" : 123,
      "endOffset" : 161
    }, {
      "referenceID" : 14,
      "context" : "combined methods, including reachability-based methods (Hauskrecht, 2000; Washington, 1997), grid-based methods (Zhou & Hansen, 2001; Brafman, 1997; Lovejoy, 1991), pointbased methods (Smith & Simmons, 2005; Pineau, Gordon, & Thrun, 2003), and compression methods (Roy, Gordon, & Thrun, 2005; Poupart & Boutilier, 2002).",
      "startOffset" : 55,
      "endOffset" : 91
    }, {
      "referenceID" : 39,
      "context" : "combined methods, including reachability-based methods (Hauskrecht, 2000; Washington, 1997), grid-based methods (Zhou & Hansen, 2001; Brafman, 1997; Lovejoy, 1991), pointbased methods (Smith & Simmons, 2005; Pineau, Gordon, & Thrun, 2003), and compression methods (Roy, Gordon, & Thrun, 2005; Poupart & Boutilier, 2002).",
      "startOffset" : 55,
      "endOffset" : 91
    }, {
      "referenceID" : 5,
      "context" : "combined methods, including reachability-based methods (Hauskrecht, 2000; Washington, 1997), grid-based methods (Zhou & Hansen, 2001; Brafman, 1997; Lovejoy, 1991), pointbased methods (Smith & Simmons, 2005; Pineau, Gordon, & Thrun, 2003), and compression methods (Roy, Gordon, & Thrun, 2005; Poupart & Boutilier, 2002).",
      "startOffset" : 112,
      "endOffset" : 163
    }, {
      "referenceID" : 21,
      "context" : "combined methods, including reachability-based methods (Hauskrecht, 2000; Washington, 1997), grid-based methods (Zhou & Hansen, 2001; Brafman, 1997; Lovejoy, 1991), pointbased methods (Smith & Simmons, 2005; Pineau, Gordon, & Thrun, 2003), and compression methods (Roy, Gordon, & Thrun, 2005; Poupart & Boutilier, 2002).",
      "startOffset" : 112,
      "endOffset" : 163
    }, {
      "referenceID" : 15,
      "context" : "Other notable examples include causal independence (e.g. Heckerman & Breese, 1994; Heckerman, 1993) and context-specific independence (Boutilier, Friedman, Goldszmidt, & Koller, 1996).",
      "startOffset" : 51,
      "endOffset" : 99
    }, {
      "referenceID" : 38,
      "context" : "This allows for a compact parameterisation via operators such as “noisy-or” (Srinivas, 1993; Pearl, 1988), and it can be used to enhance inference (Zhang & Poole, 1996).",
      "startOffset" : 76,
      "endOffset" : 105
    }, {
      "referenceID" : 28,
      "context" : "This allows for a compact parameterisation via operators such as “noisy-or” (Srinivas, 1993; Pearl, 1988), and it can be used to enhance inference (Zhang & Poole, 1996).",
      "startOffset" : 76,
      "endOffset" : 105
    }, {
      "referenceID" : 2,
      "context" : "This can allow for a further reduction of parameters (Boutilier et al., 1996)",
      "startOffset" : 53,
      "endOffset" : 77
    }, {
      "referenceID" : 17,
      "context" : "This framework is compatible with many decision models used in the artificial intelligence literature, including POMDPs (Kaelbling et al., 1998; Sondik, 1971) and its many variants.",
      "startOffset" : 120,
      "endOffset" : 158
    }, {
      "referenceID" : 37,
      "context" : "This framework is compatible with many decision models used in the artificial intelligence literature, including POMDPs (Kaelbling et al., 1998; Sondik, 1971) and its many variants.",
      "startOffset" : 120,
      "endOffset" : 158
    }, {
      "referenceID" : 2,
      "context" : "3, passivity can be shown to be a special kind of context-specific independence (CSI) (Boutilier et al., 1996) applied to DBNs.",
      "startOffset" : 86,
      "endOffset" : 110
    }, {
      "referenceID" : 29,
      "context" : "Despite satisfying clause (ii), the state variables x 1 and x t+1 2 from Example 3 are in fact not passive, for the following two reasons: Firstly, passivity is a causal relation and as such it must imply a causal order (Pearl, 2000).",
      "startOffset" : 220,
      "endOffset" : 233
    }, {
      "referenceID" : 11,
      "context" : "However, it is clear that if the variables in a cluster Ck are marginally independent of the observation variables Y t+1 (this can be determined using d-separation (Geiger et al., 1989), or simply by checking if there is a directed path from Ck to Y t+1), then there is no need to perform the observation step for the corresponding belief factor bk.",
      "startOffset" : 164,
      "endOffset" : 185
    }, {
      "referenceID" : 3,
      "context" : "Boyen and Koller (1998) provide a useful analysis of the error bound of any filtering method which uses a factored belief state representation.",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 3,
      "context" : "Similar to Boyen and Koller (1998), we define the approximation error incurred by PSBF relative to the exact belief state.",
      "startOffset" : 11,
      "endOffset" : 35
    }, {
      "referenceID" : 3,
      "context" : "Finally, the main result in the work of Boyen and Koller (1998), here restated in the context of our work in Theorem 3, essentially states that the approximation error of PSBF (measured in terms of relative entropy) is bounded by the mixing rates of the process:",
      "startOffset" : 40,
      "endOffset" : 64
    }, {
      "referenceID" : 12,
      "context" : "PSBF is compared with a selection of alternative methods, including PF (Gordon et al., 1993), RBPF (Doucet et al.",
      "startOffset" : 71,
      "endOffset" : 92
    }, {
      "referenceID" : 10,
      "context" : ", 1993), RBPF (Doucet et al., 2000), BK (Boyen & Koller, 1998), and FF (Murphy & Weiss, 2001); see Section 2 for a discussion of these methods.",
      "startOffset" : 14,
      "endOffset" : 35
    }, {
      "referenceID" : 23,
      "context" : "13, where we used the Matlab toolbox BNT (Murphy, 2001) to implement BK and FF.",
      "startOffset" : 41,
      "endOffset" : 55
    }, {
      "referenceID" : 10,
      "context" : "It is an open question how to group state variables into “sampled” and “exact” variables (Doucet et al., 2000).",
      "startOffset" : 89,
      "endOffset" : 110
    }, {
      "referenceID" : 42,
      "context" : "To this end, we consider a multi-robot warehouse system in the style of Kiva (Wurman et al., 2008), in which the robots’ task is to transport goods within the warehouse (cf.",
      "startOffset" : 77,
      "endOffset" : 98
    }, {
      "referenceID" : 29,
      "context" : "Such systems typically exhibit a number of features: First of all, robotic systems usually have some causal structure (e.g. Mainzer, 2010; Pearl, 2000).",
      "startOffset" : 118,
      "endOffset" : 151
    } ],
    "year" : 2016,
    "abstractText" : "Dynamic Bayesian networks (DBNs) are a general model for stochastic processes with partially observed states. Belief filtering in DBNs is the task of inferring the belief state (i.e. the probability distribution over process states) based on incomplete and noisy observations. This can be a hard problem in complex processes with large state spaces. In this article, we explore the idea of accelerating the filtering task by automatically exploiting causality in the process. We consider a specific type of causal relation, called passivity, which pertains to how state variables cause changes in other variables. We present the Passivity-based Selective Belief Filtering (PSBF) method, which maintains a factored belief representation and exploits passivity to perform selective updates over the belief factors. PSBF produces exact belief states under certain assumptions and approximate belief states otherwise, where the approximation error is bounded by the degree of uncertainty in the process. We show empirically, in synthetic processes with varying sizes and degrees of passivity, that PSBF is faster than several alternative methods while achieving competitive accuracy. Furthermore, we demonstrate how passivity occurs naturally in a complex system such as a multi-robot warehouse, and how PSBF can exploit this to accelerate the filtering task.",
    "creator" : "LaTeX with hyperref package"
  }
}