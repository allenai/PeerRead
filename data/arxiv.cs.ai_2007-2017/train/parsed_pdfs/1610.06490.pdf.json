{
  "name" : "1610.06490.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "An Ensemble of Adaptive Neuro-Fuzzy Kohonen Networks for Online Data Stream Fuzzy Clustering",
    "authors" : [ "Zhengbing Hu", "Yevgeniy V. Bodyanskiy", "Olena O. Boiko" ],
    "emails" : [ "hzb@mail.ccnu.edu.cn", "yevgeniy.bodyanskiy@nure.ua", "lehatish@gmail.com,", "olena.boiko@ukr.net" ],
    "sections" : [ {
      "heading" : null,
      "text" : "I. INTRODUCTION\nMultidimensional data clustering is common in Data Mining tasks. Such application areas as Text Mining and Web Mining have become really widespread lately. A traditional approach to solving this sort of tasks assumes that each vector of a processed sequence may only belong to a single class. Although it’s a more natural case when each specific observation may be attributed to several classes at the same time with different membership levels.\nThis situation is a subject under study for fuzzy cluster analysis [1, 2]. In this approach, the most effective and simplest methods are probabilistic fuzzy clustering procedures based on optimization of some objective functions. Initial data for a fuzzy clustering problem is a sample of observations which consists of N  1m  dimensional feature vectors         1 , 2 , , , nX x x x k x N R   , and a result of this clustering procedure is a partition of the initial data set into m overlapping classes with some membership levels  0 1ju k  of the k  th feature vector to the j  th cluster, 1, 2, ,j m  . Thus, the overwhelming majority of the well-known fuzzy clustering algorithms is designated for a batch mode processing which means that a sample volume N can’t be changed while the data are processed.\nThere’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode. This task is rather typical for Web Mining when information is fed in a real time mode directly from the Internet.\nSelf-organizing maps (SOMs) by Kohonen proved its efficiency in clustering tasks. Their efficiency is defined by their computational simplicity and their ability to work in a real time mode for sequential data processing. These neural networks are learnt with the help of self-learning procedures based on the principles “Winner takes all” (WTA) and “Winner takes more” (WTM). It’s previously assumed that a structure of processed data implies that formed clusters don’t mutually intersect which means that it’s possible to build a separating hyper-surface which clearly distinguish different classes during a learning procedure of a neural network.\nRecurrent modifications of the fuzzy clustering algorithms (which make it possible to solve a task in an online mode) were introduced for sequential data processing in [17, 18]. It should be noted that the introduced procedures are structurally close to the Kohonen self-learning rule according to the principle «Winner Takes More». It allows\nintroducing a so-called «fuzzy clustering Kohonen network» [19] which possesses a number of advantages comparing to a conventional self-organizing map.\nThe well-known and most commonly used fuzzy clustering algorithms can’t be called fuzzy in the full sense, because their results are significantly defined by a value of a special parameter (also known as a fuzzifier  which is chosen empirically). A case when  belongs to an interval from 1 to  corresponds to a transition from crisp borders  1  , which are obtained with the help of the K-means procedure, to their complete blurriness     , when all observations belong to all clusters with the same membership level. We should note that 2  in most cases that corresponds to the fuzzy C-means procedure (FCM) by Bezdek [20].\nThere may be a situation while processing real-world data when one object belongs to different classes at the same time and these classes mutually intersect (overlap). Conventional SOMs don’t take into consideration this occasion, but this problem can be considered with the help of fuzzy clustering techniques.\nThe remainder of this paper is organized as follows: Section 2 describes fuzzy clustering techniques with a variable fuzzifier. Section 3 describes an ensemble’s architecture of adaptive neuro-fuzzy Kohonen networks. Section 4 gives some details on possibilistic fuzzy clustering with a variable fuzzifier. Section 5 presents a realworld application to be solved with the help of the proposed fuzzy clustering approach. Conclusions and future work are given in the final section.\nII. FUZZY CLUSTERING WITH A VARIABLE FUZZIFIER Algorithms based on goal functions are considered to be strict from a mathematical point of view among all clustering procedures. They solve a task of their optimization under different a priori assumptions. The most commonly used procedure in this situation is the probabilistic approach which is based on a goal function’s minimization\n    2 1 1\n, ( ) N m\nj j j j k j E u c u k x k c     (1)\nunder constraints\n1\n( ) 1, m\nj j u k   (2)\n  1\n0 N\nj k u k N    (3)\nwhere   [0,1 ]ju k  is a membership level of a vector ( )x k to the j -th class, jc is a prototype of the j -th cluster,  is a non-negative fuzzification parameter (a fuzzifier) which actually determines a level of borders’ blurriness\nbetween clusters, 1, 2, , k N  . A result of this clustering procedure is a  N m -matrix  ( )jU u k which is also called a fuzzy partition matrix.\nWe should notice that elements of the matrix U due to the constraint (2) may be considered as probabilities that data vectors belong to some definite clusters. Because of this fact, procedures based on the minimization (1) are called probabilistic fuzzy clustering algorithms. A number of clusters m is set beforehand and can’t be changed during computation procedures.\nIntroducing the Lagrange function\n      \n   \n2\n1 1\n1 1\n, , ( )\n1\nN m\nj j j j k j\nN m\nj k j\nL u k c k u k x k c\nk u k\n\n\n \n \n  \n     \n \n\n  (4)\n(here ( )k is an undetermined Lagrange multiplier) and solving the Karush-Kuhn-Tucker system of equations, we can get a solution in the form\n    \n      \n   \n1 2 1\n1 2 1\n1\n1\n1 11\n12\n1\n,\n( )\n,\n,\nj\nj m\nll\nN jk\nj N jk\nm\nl l\nx k c u k\nx k c\nu k x k c\nu k\nk x k c\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n \n\n\n                                \n(5)\nwhich coincides with the Fuzzy C-Means algorithm (FCM) by J.Bezdek (when 2  ). And when 1  its results are close to results of the well-known conventional crisp clustering algorithm (Hard K-Means, HKM).\nAs an alternative to procedures that use a fuzzifier 1    , Klawonn and Hoeppner [21] offered an objective function for fuzzy probabilistic clustering\n      22 1 1\n, ( ) (1 ) ( ) N m\nj j j j j k j E u c u k u k x k c        (6) with the constraints (2) and (3), where 0 1  is an adjustable parameter which defines a nature of the obtained solution.\nIntroducing the Lagrange function\n            2 1 1 1 2 1 ( ) (1 ) ( ), , 1\nN m N m\nj j j j k l j k j jL u k c k x k c k uu k u k k      \n   \n         \nand solving the Karush-Kuhn-Tucker system of equations\n    \n        \n                   \n   \n2\n2\n1\n1\n, , 2 1 0,\n, , 2 1 0,\n, , 1 0,\nj\nj j j j\nj\nN\nc j j j j j k\nm j j\nj j\nL u k c k u k x k c k\nu k\nL u k c k u k u k x k c\nL u k c k u k\nk\n   \n  \n\n\n\n\n                          \nwe come to a solution\n     \n     \n2\n21\n2 1\n2 1\n111 2 , 2\n(1 ) ( ) ( ) .\n(1 ) ( )\nj\nm j\nl l\nN j jk\nj N j jk\nm u k\nx k c\nx k c\nu k u k x k c\nu k u k\n   \n \n \n\n\n\n \n   \n\n  \n               \n(7)\nIt’s easy to notice that when 1  this procedure coincides with FCM. Thus, the procedure (7) can’t be used for\nsolving Data Stream Mining tasks, because it can’t process information in an online mode. Therefore, an adaptive modification of the expression (7) was introduced in [22]\n     \n             \n2\n21\n2\n111 21 , 2 1 ( )\n1 ( )\n1 ( ) 1 1 1 1 ( )\nj\nm j\nl l\nj j j j j\nm u k\nx k c k\nx k c k\nc k c k k u k u k x k c k\n   \n  \n\n \n     \n \n     \n    \n   \n \n\n (8)\nwhere ( )k is a learning rate parameter. It’s easy to notice that the second recurrent expression (8) is the Kohonen self-learning rule according to the principle «Winner Takes More» with a neighborhood function      2 1 1 1j ju k u k     .\nIII. AN ENSEMBLE OF ADAPTIVE NEURO-FUZZY KOHONEN NETWORKS Although a value of the parameter  in the formulas (7) and (8) lies in a much narrower range than a fuzzifier\n , but there are currently no formal rules how to choose it and to tune it. Therefore, while solving a concrete task in a batch mode, this task is usually repeatedly solved with the help of the expression (7) with different  values (from a very small quantity to 1). It’s clear that such an approach can’t solve tasks effectively in an online mode. It might be expedient to use an idea of an ensemble of parallel working clustering procedures [23, 24] in this situation, where each clustering procedure works with a different from others  value. This ensemble can be easily implemented with the help of adaptive neuro-fuzzy Kohonen networks [25]. They are two-layer architectures where prototypes are clarified in the Kohonen competitive layer (which contains m neurons KjN ) and membership levels\nare calculated in the output layer (which contains m neurons MjN ). There is an architecture of the two-layer adaptive neuro-fuzzy Kohonen network in Fig.1. There is also an ensemble formed by such networks in Fig.2. A self-learning algorithm for the p  th ensemble’s member  1,2, ,p q  in an ensemble that contains q\nneuro-fuzzy networks can be written down in the form\nFig.1. An adaptive neuro-fuzzy Kohonen network (FSOM)\nFig.2. An architecture of an ensemble of adaptive neuro-fuzzy Kohonen networks\n             \n     \n2\n2\n21\n1 ( ) 1 1 ( ) ,\n1 1\n1 2 1\n2 1 ( )\n1 ( )\njp jp p jp p jp jp\np\np p jp\np m jp\nl lp\nc k c k k u k u k x k c k\nm u k\nx k c k\nx k c k\n  \n   \n\n      \n \n    \n \n\n    \n \n\n   \n\n(9)\nwherein the Kohonen layer is tuned with the help of the first ratio (9), and the output layer calculates membership levels  1jpu k  for each incoming observation  1x k  .\nClassification quality provided by each ensemble member may be estimated with the help of any fuzzy clustering index [2]. Wherein one of the simplest and most effective indexes is the so-called “partition coefficient” (PC) which is a mean value of squared membership levels of all observations to each cluster:\n    1 2\n1 1\n11 . 1\nk m\np jp j PC k u k \n \n \n    (10)\nThis coefficient has a clear physical sense: the better clusters are expressed, the higher the value pPC is (a limit\nis 1pPC  ), its minimum ( 1 pPC m  ) is reached if data belong to all clusters evenly. But this phenomenon is\nobviously a worthless solution. This coefficient is convenient in the framework of the proposed system, because it allows online calculation.\nIt should be noticed that the expression (10) is closely related to the traditional FCM. This coefficient must be modified for a considered case in the form\n         1 2\n1 1\n11 1 1\nk m\np p jp p jp j PC k u u k \n    \n \n     \nwhich coincides with the expression (10) when 1p  .\nSo, clustering a data stream that is fed in an online mode is solved with the help of parallel working adaptive neuro-fuzzy Kohonen networks which differ from each other only by a value of the parameter p . Thus, the\nnetwork’s results are applied to a maximum value  1pPC k  as a final result at any particular time point.\nIV. POSSIBILISTIC FUZZY CLUSTERING WITH A VARIABLE FUZZIFIER Basic problems that arise in fuzzy clustering have to do with constraints on a sum of membership values (they must be equal to 1). That’s why algorithms that use the constraint (2) are called probabilistic fuzzy clustering algorithms. An existence of this constraint leads to the fact that an observation which doesn’t belong to any class gets the same membership levels for all classes. One can avoid this drawback if the ideas of possibilistic fuzzy clustering are used [26]. These ideas are based on minimization of an objective function\n      2 1 1 1 1\n( ), 1 N m m N\nj j j j j k l k j j\nE u c x ku c u kk \n           where a scalar parameter 0j  defines a distance where a membership level takes on a value of 0.5 which means that if\n  2j jx k c   then\n  0.5.ju k  Introducing an objective function [22, 25] similarly to (6)\n         1\n2 2\n1 1\n2\n1 1, ( ) (1 ) ( ) ( )\nN m\nj j j j\nm N\njj j k j j k E u c u k u k x k c u k          \nand minimizing it by , ,j j ju c  , we come to a modified possibilistic procedure in the form\n      \n  \n               \n               \n1\n1\n2\n2\n2\n2\n22 1\n2 1\n1 ,\n2\n1\n1 ,\n1 .\n1\nN\nk j N\nk\nj j j\nj\nj j\nj j\nj j\nN j j jk\nj N j jk\nx k c u k\nx k c\nu k u k\nu k u k\nu k u k x k c\nu k u\nx k c\nk\n\n\n\n\n  \n \n\n\n \n \n\n\n\n    \n \n \n \n\n     \n \n \n         \n   \n \n(11)\nIt’s interesting to note that this ratio for a prototype calculation in the formulas (7) and (11) completely\ncoincides. The expressions (11) can be written down for an adaptive case in the form\n            \n      \n                 \n                     \n2\n2\n2\n121 12 2 1 1\n1 1 1 ,\n2 1\n1 1 1 1 1\n1 1 1 1\n,\n.\nj j j\nj\nj j\nj j jj j\nk k j j j j j jp p\nk x k c k k u k\nx k c k k\nk k k u k u k x k c k\nk u p u p x p c k u p u p\nc c\n  \n \n \n  \n\n     \n      \n  \n       \n                           \n(12)\nAs one can see, the second recurrent ratio (12) is the WTM self-learning rule by Kohonen with the neighborhood function      2 1 1 1j ju k u k     . Although the possibilistic algorithm (12) is a little more complicated from a computational point of view than the probabilistic procedure (8), its advantage is the fact that new clusters may be detected with the help of the possibilistic approach during online data processing. If a membership level of a new incoming observation  1x k  to all classes turns out to be lower than some predefined threshold then we can assume that there’s a new  1m   th cluster and its initial prototype coordinates are\n   1 0 1 .mc x k  \nThe algorithm (12) can be used as a learning procedure for the two-layer FSOM (Fig.1). Let’s notice that an ensemble of clustering neural networks with the help of the possibilistic approach was introduced in [27, 28], but its unwieldiness impedes its usage while processing data streams. Simplicity of the ensemble’s (Fig.2) numerical implementation makes it possible to process data in a real time mode.\nV. EXPERIMENTS We have taken real-world data for our experiment. A data set describes students’ knowledge status about the subject of Computer Science. The data set contains multivariate characteristics. It contains 302 instances with 5 attributes for each observation. Speaking of attribute information, the data set contains these attributes: - STG (a degree of study time for goal object materials); - SCG (a degree of a user’s repetition number for goal object materials); - STR (a degree of user’s study time for related objects with a goal object); - LPR (a user’s exam performance for related objects with a goal object); - PEG (a user’s exam performance for goal objects).\nWe chose 3 attributes (STR, LPR, PEG) for the sake of visualization.\nFig.3. The Result of Fuzzy Clustering (STR/PEG)\nFig.4. The Result of Fuzzy Clustering (PEG/ STR/LPR)\nAs it can be seen, the proposed method makes it possible to represent clusters in a rather compact form. A level of cluster overlapping is rather high (and it will keep on growing when a feature vector’s dimensionality increases). An a parameter for the considered case belonged to an interval [0.3; 0.4].\nFig.5. The Result of Fuzzy Clustering (SCG/PEG)\nAs it can be seen from Fig.3, there are 3 fuzzy clusters. Generally speaking, students’ current knowledge level should be determined with the help of real values (STG, SCG, PEG, STR, LPR).\nIt should be noted that there are some points in Fig.3 which are not likely to be in those regions. For example, a point belongs to a “green” class although all neighbor points in that region belong to some other (“pink” or “yellow”) class. Probably, this fact means that a student didn’t actually spend much time on his exam preparation although he demonstrated a high level of performance (his PEG index is high). There may be another situation when a student spent much time on his preparation but his results aren’t very good.\nSo, the clustering accuracy increases for fuzzy algorithms and worsens for crisp ones with the growth of a sample size; the clustering accuracy lessens with the growth of dimensionality of a feature space. Fuzzy procedures are preferable for those clustering tasks when every object belongs to several categories at the same time.\nVI. CONCLUSION The method for online fuzzy clustering multidimensional data sequences to be processed in a real time mode is proposed. The task is solved with the help of an ensemble of adaptive neuro-fuzzy Kohonen networks which differ from each other by a parameter’s value that accounts for fuzziness of the received results. The proposed procedure has rather simple computational implementation and makes it possible to organize parallel computing to accelerate the system’s processing speed (because it can process data in an online mode and this fact is really important for Web Mining and Data Stream Mining). The results may be successfully used in a wide class of Data Stream Mining, Dynamic Data Mining, Temporal Data Mining tasks and especially in such applied areas as Web Mining, Text Mining, Medical Data Mining etc.\nSo, the proposed ensemble of adaptive neuro-fuzzy self-organizing Kohonen maps has proved its efficiency for online Data Stream fuzzy clustering. A number of experiments demonstrated a high effectiveness of the proposed neuro-fuzzy system especially under conditions of clusters’ overlapping.\nACKNOWLEDGMENT\nThe authors would like to thank anonymous reviewers for their careful reading of this paper and for their helpful comments.\nThis scientific work was supported by RAMECS and CCNU16A02015.\nREFERENCES [1] F. Hoeppner, F. Klawonn, R. Kruse, and T. Runkler, Fuzzy Clustering Analysis: Methods for Classification, Data Analysis\nand Image Recognition, Chichester: John Wiley & Sons, 1999. [2] R. Xu and D.C. Wunsch, Clustering (IEEE Press Series on Computational Intelligence), Hoboken: John Wiley & Sons,\n2009. [3] H. Bouchachia and E. Balaguer-Ballester, “DELA: A Dynamic Online Ensemble Learning Algorithm”, in Proc. 22nd\nEuropean Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2014), Apr. 2014, pp. 491-496. [4] D. Leite, P. Costa Jr., and F. Gomide, “Evolving granular neural networks from fuzzy data streams”, Neural Networks, vol. 38, 2013, pp. 1-16. [5] D. Leite, R. Ballini, Pyramo Costa Jr., and F. Gomide, “Evolving fuzzy granular modeling from nonstationary fuzzy data streams”, Evolving Systems, vol.3(2), 2012, pp. 65-79. [6] D. Leite, R. Ballini, Pyramo Costa Jr., and F. Gomide, “Evolving fuzzy granular modeling from nonstationary fuzzy data streams”, Evolving Systems, vol.3(2), 2012, pp. 65-79. [7] D. Kangin and P. Angelov, “Evolving clustering, classification and regression with TEDA”, in Proc. International Joint Conference on Neural Networks (IJCNN 2015), July 2015, pp. 1-8. [8] R. Hyde and P. Angelov, “A new online clustering approach for data in arbitrary shaped clusters”, in Proc. International Conference on Cybernetics (CYBCONF 2015), June 2015, pp. 228-233. [9] R.D. Baruah, P.P. Angelov, and D. Baruah, “Dynamically evolving clustering for data streams”, in Proc. Evolving and Adaptive Intelligent Systems (EAIS 2014), June 2014, pp. 1-6. [10] R. Rosa, F.A.C. Gomide, D. Dovzan, I. Skrjanc, “Evolving neural network with extreme learning for system modeling”, in Proc. Evolving and Adaptive Intelligent Systems (EAIS 2014), June 2014, pp. 1-7. [11] D. Dovzan and I. Skrjanc, “Recursive clustering based on a Gustafson-Kessel algorithm”, Evolving Systems, vol. 2(1), 2011, pp. 15-24. [12] R.D. Baruah, P.P. Angelov, and D. Baruah, “Dynamically evolving fuzzy classifier for real-time classification of data streams”, in Proc. IEEE Int. Conf. on Fuzzy Systems (FUZZ-IEEE 2014), July 2014, pp. 383-389. [13] R.D. Baruah and P.P. Angelov, “Online learning and prediction of data streams using dynamically evolving fuzzy approach”, in Proc. IEEE Int. Conf. on Fuzzy Systems (FUZZ-IEEE 2013), July 2013, pp. 1-8. [14] A.P. Lemos, W.M. Caminhas, and F.A.C. Gomide, “Multivariable Gaussian Evolving Fuzzy Modeling System”, IEEE Trans. Fuzzy Systems, vol.19(1), 2011, pp. 91-104. [15] R.D. Baruah and P.P. Angelov, “Evolving fuzzy systems for data streams: a survey”, Data Mining and Knowledge Discovery, vol.1(6), 2011, pp. 461-476. [16] M. Pratama, S.G. Anavatti, M.J. Er, and E. Lughofer, “pClass: An Effective Classifier for Streaming Examples”, IEEE Trans. Fuzzy Systems, vol.23(2), 2015, pp. 369-386. [17] Ye. Bodyanskiy, V. Kolodyaznhiy, and A. Stephan, “Recursive fuzzy clustering algorithms”, in Proc. 10th East West Fuzzy Colloqium, Sept. 2002, pp. 276-283.\n[18] Ye. Bodyanskiy, “Computational intelligence techniques for data analysis”, Lecture Notes in Informatics, vol. P-72, 2005, pp. 15-36. [19] Ye. Gorshkov, V. Kolodyazhniy, and Ye. Bodyanskiy, “New recursive learning algorithms for fuzzy Kohonen clustering network”, in Proc. 17th Int. Workshop on Nonlinear Dynamics of Electronic Systems, June 2009, pp. 58-61. [20] J.C. Bezdek, Pattern Recognition with Fuzzy Objective Function Algorithms, N.Y.: Plenum Press, 1981. [21] F. Klawonn and F. Hoeppner, “What is fuzzy about fuzzy clustering? Understanding and improving the concept of the\nfuzzifier”, Lecture Notes in Computer Science, vol. 2811, 2003, pp. 254-264. [22] B. Kolchygin and Ye. Bodyanskiy, “Adaptive fuzzy clustering with a variable fuzzifier”, Cybernetics and System Analysis,\nvol. 49, no. 3, 2013, pp.176-181. [23] A. Topchy, B. Minaei-Bidgali, A.K. Jain, and W.F. Punch, “Adaptive clustering ensembles”, in Proc.17th Int. Conf. on\nPattern Recognition “ICPR 2004”, Aug. 2004, pp. 272 – 275. [24] S. Vega-Pons and J. Ruiz-Shulcloper, “A survey of clustering ensemble algorithms”, Int. J. Pattern Recognition and\nArtificial Intelligence, vol. 25, no. 337, 2011, pp. 337-372. [25] Ye. Bodyanskiy, B. Kolchygin, and I. Pliss, “Adaptive neuro-fuzzy Kohonen network with variable fuzzifier”, Int. J.\nInformation Theories and Applications, vol. 18, no. 3, 2011, pp. 215-223. [26] R. Krishnapuram and J.M. Keller, “A possibilistic approach to clustering”, Fuzzy Systems, vol. 1, no. 2, pp. 98-110. [27] B.V. Kolchygin, “Ensemble of neuro-fuzzy Kohonen networks for adaptive clustering”, in Proc. 2nd Int. Sci. Conf. of\nStudents and Young Scientists “Theoretical and Applied Aspects of Cybernetics”, Nov. 2012, pp. 176-181. [28] Ye.V. Bodyanskiy, V.V. Volkova, and A.S. Yegorov, “Clustering of document collections based on the adaptive self-\norganizing neural network”, Radio Electronics, Informatics, Control, vol.1(20), 2009, pp. 113-117."
    } ],
    "references" : [ {
      "title" : "Fuzzy Clustering Analysis: Methods for Classification, Data Analysis and Image Recognition",
      "author" : [ "F. Hoeppner", "F. Klawonn", "R. Kruse", "T. Runkler" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1999
    }, {
      "title" : "Clustering (IEEE Press Series on Computational Intelligence), Hoboken",
      "author" : [ "R. Xu", "D.C. Wunsch" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "DELA: A Dynamic Online Ensemble Learning Algorithm",
      "author" : [ "H. Bouchachia", "E. Balaguer-Ballester" ],
      "venue" : "Proc. 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2014
    }, {
      "title" : "Evolving granular neural networks from fuzzy data streams",
      "author" : [ "D. Leite", "P. Costa Jr.", "F. Gomide" ],
      "venue" : "Neural Networks,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "Evolving fuzzy granular modeling from nonstationary fuzzy data streams",
      "author" : [ "D. Leite", "R. Ballini", "Pyramo Costa Jr.", "F. Gomide" ],
      "venue" : "Evolving Systems,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2012
    }, {
      "title" : "Evolving fuzzy granular modeling from nonstationary fuzzy data streams",
      "author" : [ "D. Leite", "R. Ballini", "Pyramo Costa Jr.", "F. Gomide" ],
      "venue" : "Evolving Systems,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2012
    }, {
      "title" : "Evolving clustering, classification and regression with TEDA",
      "author" : [ "D. Kangin", "P. Angelov" ],
      "venue" : "Proc. International Joint Conference on Neural Networks (IJCNN",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2015
    }, {
      "title" : "A new online clustering approach for data in arbitrary shaped clusters",
      "author" : [ "R. Hyde", "P. Angelov" ],
      "venue" : "in Proc. International Conference on Cybernetics (CYBCONF",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2015
    }, {
      "title" : "Dynamically evolving clustering for data streams",
      "author" : [ "R.D. Baruah", "P.P. Angelov", "D. Baruah" ],
      "venue" : "in Proc. Evolving and Adaptive Intelligent Systems (EAIS",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2014
    }, {
      "title" : "Evolving neural network with extreme learning for system modeling",
      "author" : [ "R. Rosa", "F.A.C. Gomide", "D. Dovzan", "I. Skrjanc" ],
      "venue" : "in Proc. Evolving and Adaptive Intelligent Systems (EAIS",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2014
    }, {
      "title" : "Recursive clustering based on a Gustafson-Kessel algorithm",
      "author" : [ "D. Dovzan", "I. Skrjanc" ],
      "venue" : "Evolving Systems,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2011
    }, {
      "title" : "Dynamically evolving fuzzy classifier for real-time classification of data streams",
      "author" : [ "R.D. Baruah", "P.P. Angelov", "D. Baruah" ],
      "venue" : "in Proc. IEEE Int. Conf. on Fuzzy Systems (FUZZ-IEEE",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2014
    }, {
      "title" : "Angelov, “Online learning and prediction of data streams using dynamically evolving fuzzy approach",
      "author" : [ "P.P.R.D. Baruah" ],
      "venue" : "in Proc. IEEE Int. Conf. on Fuzzy Systems (FUZZ-IEEE",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2013
    }, {
      "title" : "Multivariable Gaussian Evolving Fuzzy Modeling System",
      "author" : [ "A.P. Lemos", "W.M. Caminhas", "F.A.C. Gomide" ],
      "venue" : "IEEE Trans. Fuzzy Systems,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2011
    }, {
      "title" : "Angelov, “Evolving fuzzy systems for data streams: a survey",
      "author" : [ "P.P.R.D. Baruah" ],
      "venue" : "Data Mining and Knowledge Discovery,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2011
    }, {
      "title" : "pClass: An Effective Classifier for Streaming Examples",
      "author" : [ "M. Pratama", "S.G. Anavatti", "M.J. Er", "E. Lughofer" ],
      "venue" : "IEEE Trans. Fuzzy Systems,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2015
    }, {
      "title" : "Recursive fuzzy clustering algorithms",
      "author" : [ "Ye. Bodyanskiy", "V. Kolodyaznhiy", "A. Stephan" ],
      "venue" : "in Proc. 10 East West Fuzzy Colloqium,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2002
    }, {
      "title" : "Computational intelligence techniques for data analysis",
      "author" : [ "Ye. Bodyanskiy" ],
      "venue" : "Lecture Notes in Informatics,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2005
    }, {
      "title" : "Bodyanskiy, “New recursive learning algorithms for fuzzy Kohonen clustering network",
      "author" : [ "Ye. Gorshkov", "V. Kolodyazhniy", "Ye" ],
      "venue" : "in Proc. 17 Int. Workshop on Nonlinear Dynamics of Electronic Systems,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2009
    }, {
      "title" : "Pattern Recognition with Fuzzy Objective Function Algorithms, N.Y.",
      "author" : [ "J.C. Bezdek" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1981
    }, {
      "title" : "What is fuzzy about fuzzy clustering? Understanding and improving the concept of the fuzzifier",
      "author" : [ "F. Klawonn", "F. Hoeppner" ],
      "venue" : "Lecture Notes in Computer Science,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2003
    }, {
      "title" : "Bodyanskiy, “Adaptive fuzzy clustering with a variable fuzzifier",
      "author" : [ "B. Kolchygin", "Ye" ],
      "venue" : "Cybernetics and System Analysis,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2013
    }, {
      "title" : "Adaptive clustering ensembles",
      "author" : [ "A. Topchy", "B. Minaei-Bidgali", "A.K. Jain", "W.F. Punch" ],
      "venue" : "Proc.17th Int. Conf. on Pattern Recognition “ICPR 2004”,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2004
    }, {
      "title" : "A survey of clustering ensemble algorithms",
      "author" : [ "S. Vega-Pons", "J. Ruiz-Shulcloper" ],
      "venue" : "Int. J. Pattern Recognition and Artificial Intelligence,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2011
    }, {
      "title" : "Adaptive neuro-fuzzy Kohonen network with variable fuzzifier",
      "author" : [ "Ye. Bodyanskiy", "B. Kolchygin", "I. Pliss" ],
      "venue" : "Int. J. Information Theories and Applications,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2011
    }, {
      "title" : "Ensemble of neuro-fuzzy Kohonen networks for adaptive clustering",
      "author" : [ "B.V. Kolchygin" ],
      "venue" : "Proc. 2 Int. Sci. Conf. of Students and Young Scientists “Theoretical and Applied Aspects of Cybernetics”,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2012
    }, {
      "title" : "Yegorov, “Clustering of document collections based on the adaptive selforganizing neural network",
      "author" : [ "Ye.V. Bodyanskiy", "V.V. Volkova", "A.S" ],
      "venue" : "Radio Electronics, Informatics, Control,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "This situation is a subject under study for fuzzy cluster analysis [1, 2].",
      "startOffset" : 67,
      "endOffset" : 73
    }, {
      "referenceID" : 1,
      "context" : "This situation is a subject under study for fuzzy cluster analysis [1, 2].",
      "startOffset" : 67,
      "endOffset" : 73
    }, {
      "referenceID" : 2,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 3,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 4,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 5,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 6,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 7,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 8,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 9,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 10,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 11,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 12,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 13,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 14,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 15,
      "context" : "There’s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 16,
      "context" : "Recurrent modifications of the fuzzy clustering algorithms (which make it possible to solve a task in an online mode) were introduced for sequential data processing in [17, 18].",
      "startOffset" : 168,
      "endOffset" : 176
    }, {
      "referenceID" : 17,
      "context" : "Recurrent modifications of the fuzzy clustering algorithms (which make it possible to solve a task in an online mode) were introduced for sequential data processing in [17, 18].",
      "startOffset" : 168,
      "endOffset" : 176
    }, {
      "referenceID" : 18,
      "context" : "introducing a so-called «fuzzy clustering Kohonen network» [19] which possesses a number of advantages comparing to a conventional self-organizing map.",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 19,
      "context" : "We should note that 2   in most cases that corresponds to the fuzzy C-means procedure (FCM) by Bezdek [20].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 0,
      "context" : "  1 0 N j k u k N     (3) where   [0,1 ] j u k  is a membership level of a vector ( ) x k to the j -th class, j c is a prototype of the j -th cluster,  is a non-negative fuzzification parameter (a fuzzifier) which actually determines a level of borders’ blurriness between clusters, 1, 2, , k N   .",
      "startOffset" : 42,
      "endOffset" : 48
    }, {
      "referenceID" : 20,
      "context" : "As an alternative to procedures that use a fuzzifier 1     , Klawonn and Hoeppner [21] offered an objective function for fuzzy probabilistic clustering",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 21,
      "context" : "Therefore, an adaptive modification of the expression (7) was introduced in [22]",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 22,
      "context" : "It might be expedient to use an idea of an ensemble of parallel working clustering procedures [23, 24] in this situation, where each clustering procedure works with a different from others  value.",
      "startOffset" : 94,
      "endOffset" : 102
    }, {
      "referenceID" : 23,
      "context" : "It might be expedient to use an idea of an ensemble of parallel working clustering procedures [23, 24] in this situation, where each clustering procedure works with a different from others  value.",
      "startOffset" : 94,
      "endOffset" : 102
    }, {
      "referenceID" : 24,
      "context" : "This ensemble can be easily implemented with the help of adaptive neuro-fuzzy Kohonen networks [25].",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 1,
      "context" : "Classification quality provided by each ensemble member may be estimated with the help of any fuzzy clustering index [2].",
      "startOffset" : 117,
      "endOffset" : 120
    }, {
      "referenceID" : 21,
      "context" : "Introducing an objective function [22, 25] similarly to (6)",
      "startOffset" : 34,
      "endOffset" : 42
    }, {
      "referenceID" : 24,
      "context" : "Introducing an objective function [22, 25] similarly to (6)",
      "startOffset" : 34,
      "endOffset" : 42
    }, {
      "referenceID" : 25,
      "context" : "Let’s notice that an ensemble of clustering neural networks with the help of the possibilistic approach was introduced in [27, 28], but its unwieldiness impedes its usage while processing data streams.",
      "startOffset" : 122,
      "endOffset" : 130
    }, {
      "referenceID" : 26,
      "context" : "Let’s notice that an ensemble of clustering neural networks with the help of the possibilistic approach was introduced in [27, 28], but its unwieldiness impedes its usage while processing data streams.",
      "startOffset" : 122,
      "endOffset" : 130
    } ],
    "year" : 2016,
    "abstractText" : "A new approach to data stream clustering with the help of an ensemble of adaptive neuro-fuzzy systems is proposed. The proposed ensemble is formed with adaptive neuro-fuzzy self-organizing Kohonen maps in a parallel processing mode. Their learning procedure is carried out with different parameters that define a nature of cluster borders’ blurriness. Clusters’ quality is estimated in an online mode with the help of a modified partition coefficient which is calculated in a recurrent form. A final result is chosen by the best neuro-fuzzy self-organizing Kohonen map.",
    "creator" : "PScript5.dll Version 5.2.2"
  }
}