{
  "name" : "1705.08550.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Deep Multi-instance Networks with Sparse Label Assignment for Whole Mammogram Classification",
    "authors" : [ "Wentao Zhu", "Qi Lou", "Yeeleng Scott Vang", "Xiaohui Xie" ],
    "emails" : [ "xhx}@ics.uci.edu,", "ysvang}@uci.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Deep multi-instance learning, whole mammogram classification, max pooling-based MIL, label assignment-based MIL, sparse MIL"
    }, {
      "heading" : "1 Introduction",
      "text" : "According to the American Cancer Society, breast cancer is the most frequently diagnosed solid cancer and the second leading cause of cancer death among U.S. women [1]. Mammogram screening has been demonstrated to be an effective way for early detection and diagnosis, which can significantly decrease breast cancer mortality [15]. Traditional mammogram classification requires extra annotations such as bounding box for detection or mask ground truth for segmentation [17,5,11]. Other work have employed different deep networks to detect ROIs and obtain mass boundaries in different stages [6]. However, these methods require hand-crafted features to complement the system [12], and training data to be annotated with bounding boxes and segmentation ground truths which require expert domain knowledge and costly effort to obtain. In addition, multi-stage training cannot fully explore the power of deep networks.\nDue to the high cost of annotation, we intend to perform classification based on a raw whole mammogram. Each patch of a mammogram can be treated as an instance and a whole mammogram is treated as a bag of instances. The whole mammogram classification problem can then be thought of as a standard MIL problem. Due to the great representation power of deep features [9,21,19,20], combining MIL with deep neural networks is an emerging topic. Yan et al. used a deep MIL to find discriminative\n1 The code can be downloaded from https://github.com/wentaozhu/deep-mil-for-wholemammogram-classification.git.\nar X\niv :1\n70 5.\n08 55\n0v 1\n[ cs\n.C V\n] 2\n3 M\nay 2\n01 7\npatches for body part recognition [18]. Patch based CNN added a new layer after the last layer of deep MIL to learn the fusion model for multi-instance predictions [10]. Shen et al. employed two stage training to learn the deep multi-instance networks for pre-detected lung nodule classification [16]. The above approaches used max pooling to model the general multi-instance assumption which only considers the patch of max probability. In this paper, more effective task-related deep multi-instance models with end-to-end training are explored for whole mammogram classification. We investigate three different schemes, i.e., max pooling, label assignment, and sparsity, to perform deep MIL for the whole mammogram classification task.\nThe framework for our proposed end-to-end trained deep MIL for mammogram classification is shown in Fig. 1. To fully explore the power of deep MIL, we convert the traditional MIL assumption into a label assignment problem. As a mass typically composes only 2% of a whole mammogram (see Fig. 2), we further propose sparse deep MIL. The proposed deep multi-instance networks are shown to provide robust performance for whole mammogram classification on the INbreast dataset [14]."
    }, {
      "heading" : "2 Deep MIL for Whole Mammogram Mass Classification",
      "text" : "Unlike other deep multi-instance networks [18,10], we use a CNN to efficiently obtain features of all patches (instances) at the same time. Given an image I , we obtain a much smaller feature map F of multi-channels Nc after multiple convolutional layers and max pooling layers. The (F )i,j,: represents deep CNN features for a patch Qi,j in I , where i, j represents the pixel row and column index respectively.\nThe goal of our work is to predict whether a whole mammogram contains a malignant mass (BI-RADS ∈ {4, 5, 6} as positive) or not, which is a standard binary classification problem. We add a logistic regression with weights shared across all the pixel positions following F , and an element-wise sigmoid activation function is applied to the output. To clarify it, the malignant probability of feature space’s pixel (i, j) is\nri,j = sigmoid(a · Fi,j,: + b), (1)\nwhere a is the weights in logistic regression, b is the bias, and · is the inner product of the two vectors a and Fi,j,:. The a and b are shared for different pixel positions i, j. We can combine ri,j into a matrix r = (ri,j) of range [0, 1] denoting the probabilities of patches being malignant masses. The r can be flattened into a one-dimensional vector as r = (r1, r2, ..., rm) corresponding to flattened patches (Q1,Q2, ...,Qm), where m is the number of patches."
    }, {
      "heading" : "2.1 Max Pooling-based Multi-instance Learning",
      "text" : "The general multi-instance assumption is that if there exists an instance that is positive, the bag is positive [7]. The bag is negative if and only if all instances are negative. For whole mammogram classification, the equivalent scenario is that if there exists a malignant mass, the mammogram I should be classified as positive. Likewise, negative mammogram I should not have any malignant masses. If we treat each patch Qi of I as an instance, the whole mammogram classification is a standard multi-instance task.\nFor negative mammograms, we expect all the ri to be close to 0. For positive mammograms, at least one ri should be close to 1. Thus, it is natural to use the maximum component of r as the malignant probability of the mammogram I\np(y = 1|I,θ) = max{r1, r2, ..., rm}, (2)\nwhere θ is the weights in deep networks. If we sort r first in descending order as illustrated in Fig. 1, the malignant probability of the whole mammogram I is the first element of ranked r as\n{r′1, r′2, ..., r′m} = sort({r1, r2, ..., rm}), p(y = 1|I,θ) = r′1, and p(y = 0|I,θ) = 1− r′1,\n(3)\nwhere r′ = (r′1, r′2, ..., r′m) is descending ranked r. The cross entropy-based cost function can be defined as\nLmaxpooling = − 1\nN N∑ n=1 log(p(yn|In,θ)) + λ 2 ‖θ‖2 (4)\nwhere N is the total number of mammograms, yn ∈ {0, 1} is the true label of malignancy for mammogram In, and λ is the regularizer that controls model complexity.\nOne disadvantage of max pooling-based MIL is that it only considers the patch Q′1, and does not exploit information from other patches. A more powerful framework should add task-related priori, such as sparsity of mass in whole mammogram, into the general multi-instance assumption and explore more patches for training."
    }, {
      "heading" : "2.2 Label Assignment-based Multi-instance Learning",
      "text" : "For the conventional classification tasks, we assign a label to each data point. In the MIL scheme, if we consider each instance (patch) Qi as a data point for classification, we can convert the multi-instance learning problem into a label assignment problem.\nAfter we rank the malignant probabilities r = (r1, r2, ..., rm) for all the instances (patches) in a whole mammogram I using the first equation in Eq. 3, the first few r′i should be consistent with the label of whole mammogram as previously mentioned, while the remaining patches (instances) should be negative. Instead of adopting the general MIL assumption that only considers the Q′1 (patch of malignant probability r ′ 1), we assume that 1) patches of the first k largest malignant probabilities {r′1, r′2, ..., r′k} should be assigned with the same class label as that of whole mammogram, and 2) the rest patches should be labeled as negative in the label assignment-based MIL.\nAfter the ranking/sorting layer using the first equation in Eq. 3, we can obtain the malignant probability for each patch\np(y = 1|Q′i,θ) = r′i, and p(y = 0|Q′i,θ) = 1− r′i. (5)\nThe cross entropy loss function of the label assignment-based MIL can be defined\nLlabelassign. =− 1\nmN N∑ n=1 ( k∑ j=1 log(p(yn|Q′j ,θ))+\nm∑ j=k+1 log(p(y = 0|Q′j ,θ)) ) + λ 2 ‖θ‖2.\n(6)\nOne advantage of the label assignment-based MIL is that it explores all the patches to train the model. Essentially it acts a kind of data augmentation which is an effective technique to train deep networks when the training data is scarce. From the sparsity perspective, the optimization problem of label assignment-based MIL is exactly a ksparse problem for the positive data points, where we expect {r′1, r′2, ..., r′k} being 1 and {r′k+1, r′k+2, ..., r′m} being 0. The disadvantage of label assignment-based MIL is that it is hard to estimate the hyper-parameter k. Thus, a relaxed assumption for the MIL or an adaptive way to estimate the hyper-parameter k is preferred."
    }, {
      "heading" : "2.3 Sparse Multi-instance Learning",
      "text" : "From the mass distribution, the mass typically comprises about 2% of the whole mammogram on average (Fig. 2), which means the mass region is quite sparse in the whole\nmammogram. It is straightforward to convert the mass sparsity to the malignant mass sparsity, which implies that {r′1, r′2, ..., r′m} is sparse in the whole mammogram classification problem. The sparsity constraint means we expect the malignant probability of part patches r′i being 0 or close to 0, which is equivalent to the second assumption in the label assignment-based MIL. Analogously, we expect r′1 to be indicative of the true label of mammogram I .\nAfter the above discussion, the loss function of sparse MIL problem can be defined\nLsparse = 1\nN N∑ n=1 ( − log(p(yn|In,θ)) + µ‖r′n‖1 ) + λ 2 ‖θ‖2, (7)\nwhere p(yn|In,θ) can be calculated in Eq. 3, rn = (r′1, r′2, ..., r′m) for mammogram In, ‖ · ‖1 denotes the L1 norm, µ is the sparsity factor, which is a trade-off between the sparsity assumption and the importance of patchQ′1.\nFrom the discussion of label assignment-based MIL, this learning is a kind of exact k-sparse problem which can be converted to L1 constrain. One advantage of sparse MIL over label assignment-based MIL is that it does not require assign label for each patch which is hard to do for patches where probabilities are not too large or small. The sparse MIL considers the overall statistical property of r\nAnother advantage of sparse MIL is that, it has different weights for general MIL assumption (the first part loss) and label distribution within mammogram (the second part loss), which can be considered as a trade-off between max pooling-based MIL (slack assumption) and label assignment-based MIL (hard assumption)."
    }, {
      "heading" : "3 Experiments",
      "text" : "We validate the proposed models on the most frequently used mammographic mass classification dataset, INbreast dataset [14], as the mammograms in other datasets, such as DDSM dataset [4], are of low quality. The INbreast dataset contains 410 mammograms of which 100 containing malignant masses. These 100 mammograms with malignant masses are defined as positive. For fair comparison, we also use 5-fold cross validation to evaluate model performance as [6]. For each testing fold, we use three folds for training, and one fold for validation to tune hyper-parameters. The performance is reported as the average of five testing results obtained from cross-validation.\nWe employ techniques to augment our data. For each training epoch, we randomly flip the mammograms horizontally, shift within 0.1 proportion of mammograms horizontally and vertically, rotate within 45 degree, and set 50 × 50 square box as 0. In experiments, the data augmentation is essential for us to train the deep networks.\nFor the CNN network structure, we use AlexNet and remove the fully connected layers [13]. Through CNN, the mammogram of size 227×227 becomes 256 6×6 feature maps. Then we use steps in Sec. 2 to do MIL. Here we employ weights pretrained on the ImageNet due to the scarce of data. We use Adam optimization with learning rate 5 × 10−5 for training models [2]. The λ for max pooling-based and label assignmentbased MIL are 1 × 10−5. The λ and µ for sparse MIL are 5 × 10−6 and 1 × 10−5 respectively. For the label assignment-based MIL.\nWe firstly compare our methods to previous models validated on DDSM dataset and INbreast dataset in Table 1. Previous hand-crafted feature-based methods require manually annotated detection bounding box or segmentation ground truth even in test denoting as manual [3,17,8]. The feat. denotes requiring hand-crafted features. Pretrained CNN uses two CNNs to detect the mass region and segment the mass, followed by a third CNN to do mass classification on the detected ROI region, which requires handcrafted features to pretrain the network and needs multi-stages training[6]. Pretrained CNN+Random Forest further employs random forest and obtained 7% improvement. These methods are either manually or need hand-crafted features or multi-stages training, while our methods are totally automated, do not require hand-crafted features or extra annotations even on training set, and can be trained in an end-to-end manner.\nThe max pooling-based deep MIL obtains better performance than the pretrained CNN using 3 different CNNs and detection/segmentation annotation in the training set. This shows the superiority of our end-to-end trained deep MIL for whole mammogram classification. According to the accuracy metric, the sparse deep MIL is better than the label assignment-based MIL, which is better than the max pooling-based MIL. This result is consistent with previous discussion that the sparsity assumption benefited from not having hard constraints of the label assignment assumption, which employs all the patches and is more efficient than max pooling assumption. Our sparse deep MIL achieves competitive accuracy to random forest-based pretrained CNN, while much higher AUC than previous work, which shows our method is more robust. The main reasons for the robust results using our models are as follows. Firstly, data augmentation is an important technique to increase scarce training datasets and proves useful here. Secondly, the transfer learning that employs the pretrained weights from ImageNet is effective for the INBreast dataset. Thirdly, our models fully explore all the patches to train our deep networks thereby eliminating any possibility of overlooking malignant patches by only considering a subset of patches. This is a distinct advantage over previous networks employing several stages.\nTo further understand our deep MIL, we visualize the responses of logistic regression layer for four mammograms on test set, which represents the malignant probability of each patch, in Fig. 3. We can see the deep MIL learns not only the prediction of whole mammogram, but also the prediction of malignant patches within the whole mammogram. Our models are able to learn the mass region of the whole mammogram\nwithout any explicit bounding box or segmentation ground truth annotation of training data. The max pooling-based deep multi-instance network misses some malignant patches in (a), (c) and (d). The possible reason is that it only considers the patch of max malignant probability in training and the model is not well learned for all patches. The label assignment-based deep MIL mis-classifies some patches in (d). The possible reason is that the model sets a constant k for all the mammograms, which causes some mis-classifications for small masses. One of the potential applications of our work is that these deep MIL networks could be used to do weak mass annotation automatically, which provides evidence for the diagnosis."
    }, {
      "heading" : "4 Conclusion",
      "text" : "In this paper, we propose end-to-end trained deep MIL for whole mammogram classification. Different from previous work using segmentation or detection annotations, we conduct mass classification based on whole mammogram directly. We convert the general MIL assumption to label assignment problem after ranking. Due to the sparsity of masses, sparse MIL is used for whole mammogram classification. Experimental\nresults demonstrate more robust performance even without detection or segmentation annotation in the training.\nIn future work, we plan to extend the current work by: 1) incorporating multi-scale modeling such as spatial pyramid to further improve whole mammogram classification, 2) employing the deep MIL to do annotation or provide potential malignant patches to assist diagnoses, and 3) applying to large datasets if the big dataset is available."
    } ],
    "references" : [ {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "J. Ba", "D. Kingma" ],
      "venue" : "ICLR",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Digital mammographic computer aided diagnosis (cad) using adaptive level set segmentation",
      "author" : [ "J.E. Ball", "L.M. Bruce" ],
      "venue" : "EMBS",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "The digital database for screening mammography",
      "author" : [ "K. Bowyer", "D. Kopans", "W Kegelmeyer" ],
      "venue" : "IWDM",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Unregistered multiview mammogram analysis with pre-trained deep learning models",
      "author" : [ "G. Carneiro", "J. Nascimento", "A.P. Bradley" ],
      "venue" : "MICCAI. pp. 652–660. Springer",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "The automated learning of deep features for breast mass classification from mammograms",
      "author" : [ "N. Dhungel", "G. Carneiro", "A.P. Bradley" ],
      "venue" : "MICCAI. pp. 106–114. Springer",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Solving the multiple instance problem with axis-parallel rectangles",
      "author" : [ "T.G. Dietterich", "R.H. Lathrop", "T. Lozano-Pérez" ],
      "venue" : "Artificial intelligence 89(1), 31–71",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Inbreast-database masses characterization",
      "author" : [ "I. Domingues", "E. Sales", "J. Cardoso", "W. Pereira" ],
      "venue" : "XXIII CBEB",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique",
      "author" : [ "H. Greenspan", "B. van Ginneken", "R.M. Summers" ],
      "venue" : "IEEE Transactions on Medical Imaging 35(5), 1153–1159",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Patch-based convolutional neural network for whole slide tissue image classification",
      "author" : [ "L. Hou", "D. Samaras", "Kurc", "T.M" ],
      "venue" : "arXiv:1504.07947",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "A deep feature based framework for breast masses classification",
      "author" : [ "Z. Jiao", "X. Gao", "Y. Wang", "J. Li" ],
      "venue" : "Neurocomputing",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Large scale deep learning for computer aided detection of mammographic lesions",
      "author" : [ "T. Kooi", "G. Litjens", "B van Ginneken" ],
      "venue" : "Medical image analysis 35, 303–312",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "A. Krizhevsky", "I. Sutskever", "G.E. Hinton" ],
      "venue" : "NIPS. pp. 1097–1105",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Inbreast: toward a full-field digital mammographic database",
      "author" : [ "I.C. Moreira", "I. Amaral", "I Domingues" ],
      "venue" : "Academic radiology",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Breast cancer screening for women at average risk: 2015 guideline update from the american cancer society",
      "author" : [ "K.C. Oeffinger", "E.T. Fontham", "R Etzioni" ],
      "venue" : "Jama",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Learning from experts: Developing transferable deep features for patient-level lung cancer prediction",
      "author" : [ "W. Shen", "M. Zhou", "F Yang" ],
      "venue" : "MICCAI",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Use of border information in the classification of mammographic masses",
      "author" : [ "C. Varela", "S. Timp", "N. Karssemeijer" ],
      "venue" : "Physics in Medicine and Biology 51(2), 425",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Co-occurrence feature learning for skeleton based action recognition using regularized deep lstm networks",
      "author" : [ "W. Zhu", "C. Lan", "J Xing" ],
      "venue" : "AAAI",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Hierarchical extreme learning machine for unsupervised representation learning",
      "author" : [ "W. Zhu", "J. Miao", "L. Qing", "G.B. Huang" ],
      "venue" : "IJCNN. pp. 1–8. IEEE",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Adversarial deep structural networks for mammographic mass segmentation",
      "author" : [ "W. Zhu", "X. Xie" ],
      "venue" : "arXiv:1612.05970",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "Mammogram screening has been demonstrated to be an effective way for early detection and diagnosis, which can significantly decrease breast cancer mortality [15].",
      "startOffset" : 157,
      "endOffset" : 161
    }, {
      "referenceID" : 15,
      "context" : "Traditional mammogram classification requires extra annotations such as bounding box for detection or mask ground truth for segmentation [17,5,11].",
      "startOffset" : 137,
      "endOffset" : 146
    }, {
      "referenceID" : 3,
      "context" : "Traditional mammogram classification requires extra annotations such as bounding box for detection or mask ground truth for segmentation [17,5,11].",
      "startOffset" : 137,
      "endOffset" : 146
    }, {
      "referenceID" : 9,
      "context" : "Traditional mammogram classification requires extra annotations such as bounding box for detection or mask ground truth for segmentation [17,5,11].",
      "startOffset" : 137,
      "endOffset" : 146
    }, {
      "referenceID" : 4,
      "context" : "Other work have employed different deep networks to detect ROIs and obtain mass boundaries in different stages [6].",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 10,
      "context" : "However, these methods require hand-crafted features to complement the system [12], and training data to be annotated with bounding boxes and segmentation ground truths which require expert domain knowledge and costly effort to obtain.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 7,
      "context" : "Due to the great representation power of deep features [9,21,19,20], combining MIL with deep neural networks is an emerging topic.",
      "startOffset" : 55,
      "endOffset" : 67
    }, {
      "referenceID" : 18,
      "context" : "Due to the great representation power of deep features [9,21,19,20], combining MIL with deep neural networks is an emerging topic.",
      "startOffset" : 55,
      "endOffset" : 67
    }, {
      "referenceID" : 16,
      "context" : "Due to the great representation power of deep features [9,21,19,20], combining MIL with deep neural networks is an emerging topic.",
      "startOffset" : 55,
      "endOffset" : 67
    }, {
      "referenceID" : 17,
      "context" : "Due to the great representation power of deep features [9,21,19,20], combining MIL with deep neural networks is an emerging topic.",
      "startOffset" : 55,
      "endOffset" : 67
    }, {
      "referenceID" : 11,
      "context" : "Here we use the convolutional layers in AlexNet [13].",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 8,
      "context" : "Patch based CNN added a new layer after the last layer of deep MIL to learn the fusion model for multi-instance predictions [10].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 14,
      "context" : "employed two stage training to learn the deep multi-instance networks for pre-detected lung nodule classification [16].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 12,
      "context" : "The proposed deep multi-instance networks are shown to provide robust performance for whole mammogram classification on the INbreast dataset [14].",
      "startOffset" : 141,
      "endOffset" : 145
    }, {
      "referenceID" : 8,
      "context" : "Unlike other deep multi-instance networks [18,10], we use a CNN to efficiently obtain features of all patches (instances) at the same time.",
      "startOffset" : 42,
      "endOffset" : 49
    }, {
      "referenceID" : 5,
      "context" : "The general multi-instance assumption is that if there exists an instance that is positive, the bag is positive [7].",
      "startOffset" : 112,
      "endOffset" : 115
    }, {
      "referenceID" : 12,
      "context" : "We validate the proposed models on the most frequently used mammographic mass classification dataset, INbreast dataset [14], as the mammograms in other datasets, such as DDSM dataset [4], are of low quality.",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 2,
      "context" : "We validate the proposed models on the most frequently used mammographic mass classification dataset, INbreast dataset [14], as the mammograms in other datasets, such as DDSM dataset [4], are of low quality.",
      "startOffset" : 183,
      "endOffset" : 186
    }, {
      "referenceID" : 4,
      "context" : "For fair comparison, we also use 5-fold cross validation to evaluate model performance as [6].",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 11,
      "context" : "For the CNN network structure, we use AlexNet and remove the fully connected layers [13].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 0,
      "context" : "We use Adam optimization with learning rate 5 × 10−5 for training models [2].",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 1,
      "context" : "[3] DDSM Manual+feat.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 15,
      "context" : "[17] DDSM Manual+feat.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 6,
      "context" : "[8] INbr.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "89 N/A Pretrained CNN [6] INbr.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 4,
      "context" : "10 Pretrained CNN+Random Forest [6] INbr.",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 1,
      "context" : "Previous hand-crafted feature-based methods require manually annotated detection bounding box or segmentation ground truth even in test denoting as manual [3,17,8].",
      "startOffset" : 155,
      "endOffset" : 163
    }, {
      "referenceID" : 15,
      "context" : "Previous hand-crafted feature-based methods require manually annotated detection bounding box or segmentation ground truth even in test denoting as manual [3,17,8].",
      "startOffset" : 155,
      "endOffset" : 163
    }, {
      "referenceID" : 6,
      "context" : "Previous hand-crafted feature-based methods require manually annotated detection bounding box or segmentation ground truth even in test denoting as manual [3,17,8].",
      "startOffset" : 155,
      "endOffset" : 163
    }, {
      "referenceID" : 4,
      "context" : "Pretrained CNN uses two CNNs to detect the mass region and segment the mass, followed by a third CNN to do mass classification on the detected ROI region, which requires handcrafted features to pretrain the network and needs multi-stages training[6].",
      "startOffset" : 246,
      "endOffset" : 249
    } ],
    "year" : 2017,
    "abstractText" : "Mammogram classification is directly related to computer-aided diagnosis of breast cancer. Traditional methods rely on regions of interest (ROIs) which require great efforts to annotate. Inspired by the success of using deep convolutional features for natural image analysis and multi-instance learning (MIL) for labeling a set of instances/patches, we propose end-to-end trained deep multiinstance networks for mass classification based on whole mammogram without the aforementioned ROIs. We explore three different schemes to construct deep multi-instance networks for whole mammogram classification. Experimental results on the INbreast dataset demonstrate the robustness of proposed networks compared to previous work using segmentation and detection annotations. 1",
    "creator" : "LaTeX with hyperref package"
  }
}