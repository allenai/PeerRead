{
  "name" : "1301.3870.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Game Networks",
    "authors" : [ "Pierfrancesco La Mura" ],
    "emails" : [ "plamura@stanford.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We introduce Game networks ( G nets), a novel representation for multi-agent decision problems. Compared to other game-theoretic representations, such as strategic or extensive forms, G nets are more structured and more compact; more fundamentally, G nets consti tute a computationally advantageous frame work for strategic inference, as both prob ability and utility independencies are cap tured in the structure of the network and can be exploited in order to simplify the infer ence process. An important aspect of multi agent reasoning is the identification of some or all of the strategic equilibria in a game; we present original convergence methods for strategic equilibrium which can take advan tage of strategic separabilities in the G net structure in order to simplify the computa tions. Specifically, we describe a method which identifies a unique equilibrium as a function of the game payoffs, and one which identifies all equilibria.\n1 Introduction\nThe formal analysis of multi-agent systems is a topic of interest to both economic theory and artificial intel ligence. While game-theoretic notions and method ologies have already populated the economic main stream, only recently they started to attract interest in the context of artificial intelligence, where their inte gration with existing methods constitutes a promising area of new research.\nIn this paper we introduce a new class of graphical rep resentations for multi-agent decision problems, Game networks ( G nets). Compared to standard game theoretic representations, such as strategic and exten sive forms, G nets are more structured and more com-\npact, as both probabilities and utilities enjoy a mod ular representation. More fundamentally, G nets pro vide a computationally advantageous framework for strategic inference, as one can exploit conditional prob ability and utility independencies to reduce the com plexity of the inference process.\nAn important aspect of multi-agent reasoning is the identification of some or all of the strategic equilibria in a game. For all but the simplest classes of games this a computationally demanding task, which can in principle be alleviated by making more efficient use of the information contained in the game structure (see [ M M96] for a survey on the recent state of the art on the computation of strategic equilibria). We de rive original convergence methods for strategic equi librium which can exploit strategic separabilities in the G net representation in order to simplify computa tions. Specifically, we describe a path-tracking method which identifies a unique equilibrium as a function of the game payoffs, and one which identifies all equilib ria.\nG nets are closely related to a novel representation for single-agent decision problems, Expected Utility networks ( E U nets), introduced in [ L M S99]. E U nets generalize Markovian networks from the AI literature [ Pea88], and provide a modular and compact frame work for strategic inference.\nE U nets exploit a novel notion of utility independence, closely related to its probabilistic counterpart. To gether, conditional probability and utility indepen dence imply conditional expected utility (or strate gic) independence. What is important about strate gically independent decisions is that they can be effec tively decentralized: a single, complicated agent can be replaced by simpler, conditionally independent sub agents, who can do just as well. This property is of interest not only to artificial intelligence, since it can be exploited to reduce the complexity of planning, but also to economic theory, as it suggests a principled way for the identification of optimal task allocations within\n336 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\neconomic organizations.\nYet, E U nets are somewhat limited for the purpose of modeling, as they do not capture causal relation ships among events. Obviating to such limitation is a primary motivation for the introduction of G nets.\nGame networks stand in roughly the same relationship to Bayesian networks as Expected Utility networks to Markovian networks. Bayesian networks encompass a probabilistic notion of causality, whereas the causal \"parents\" of each variable in the network are assumed to determine its conditional probability, but not its truth value. While the resulting implicit represen tation of the state space affords significant computa tional advantages, it still captures all the relevant in formation for the purpose of Bayesian inference, and provides an intuitive and compact modeling frame work. Moreover , the probabilistic independencies cap tured by the network structure can be exploited to simplify the inference process, either directly or by first passing to a Markovian representation.\nG nets encompass a decision-theoretic notion of causal ity, Bayesian rationality, whereas the agents' prefer ences constrain the conditional probabilities of the pos sible actions, but not their truth values. We argue that Bayesian rationality captures all the relevant informa tion for the purpose of strategic inference, while at the same time avoiding some difficulties faced by other no tions of causality. As in the case of Bayesian networks, one can either perform strategic inference directly on a G net, or switch to a (multi-agent) E U net represen tation first.\nThe rest of the paper is organized as follows. In section 2 we briefly present the decision-theoretic background of G nets. In section 3 we give a formal definition of G nets, and discuss how they can be used to model multi-agent decision problems in the context of a sim ple example. F inally, in section 4 we give existence and convergence results for strategic equilibrium in G nets.\n2 Decision-theoretic preliminaries\nIn this section we present the decision-theoretic back ground of G nets; we first give a brief summary of the framework developed in [ L M S98], and then discuss how to incorporate an appropriate notion of causality within the framework.\nLet A be a Boolean algebra of events (or propositions), and !:::; a preference ordering on the nonempty events A-{0}. Without loss of generality, we extend!:::; to the entire algebra A by assuming E >- 0 for all nonempty EEA.\nWe now define what it means for a preference ordering !:::; to admit an expected utility representation.\nDefinition 1 An expected utility representation of!:::; on A is a pair (P, U), where P : A---+ [0, 1] is a prob ability function and U : A ---+ JR+ is a non-negative utility function such that:\n1. U(E) � U(F) if and only if E!:::; F\n2. U(E)P(E) = Lk U(Ek)P(Ek) for any finite, measurable partition { Ek} of E.\nWithout loss of generality, we assume that the utility of the empty set is zero.\nExample 1 Let b. be the set of all probability mea sures defined on a finite algebra A, and let !:::; be a pref erence ordering on b. which admits a von Neumann Morgenstern expected utility representation. Let P E b. be a given, strictly positive probability measure representing the agent's prior beliefs, and for all nonempty E E A let PE be the conditional measure defined by PE(F) = P(E n F)/ F(E), F E A. Pref erences over posterior probabilities { PE } can be iden tified with preferences over nonempty events in A by imposing E !:::; F if and only if PE !:::; PF. Then the resulting preference ordering on A admits an expected utility representation in our sense.\nWe say that a family {PEhEA-{0} is a conditional probability system if it assigns to every non-empty con\nditioning event E E A a conditional probability mea sure over AnE, such that the PE agree with Bayesian conditioning whenever possible; specifically, for any nonempty E, F, G E A such that G C F C E, one has that PE(G) = PE(F)pF(G).\nDefinition 2 A conditional expected utility repre sentation of !:::; on A is a pair (p, u) , where p := {PEhEA-{0} is a conditional probability system and u : A ---+ JR+ is a non-negative utility junction such that:\n• u(E) � u(F) if and only if E !:::; F\n• u(E) = Z:::: u(Ek) PE(Ek) for any finite, measur able partition {Ek} of E.\nLet I be a finite set of agents. Agent i E I is assumed to have preferences not only about the basic events in a finite algebra Ao and its own preferences, but on other agents' preferences as well.\nLet W be a set of possible worlds, and !:::;� a function which associates to each pair (i, w) a preference order ing on zw. For any E, F E A0, let [E >-iF] denote the\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 337\nproposition {wE W I E >-� F} (\"i (strictly ) prefers E to F\"), and by [E ,..,_,i F] the set {wE W I E rv� F} (\" i is indifferent between E and F\"). Furthermore, let Bb denote the set of all finite intersections of proposi tions [E >-iF] and [E ,..,_,iF].\nWe recursively define n-th order (n > 0) algebras and preferences:\n• An= An-1 U (UiEIB�_1) is the algebra generated by events in An-1 and 8�_1, i E I\n• B� ( i E I) is the set of all finite intersections of propositions [E >-i F], [E ,..,_,i F], where E, F E An\n• A = UnAn is the algebra generated by events E E An (n � 0), and Bi is the set of all finite intersections of propositions [E >-i F], [E ,..,_,i F], where E, FE A.\nNotice that Bi C A, and hence A = AU (UiEIBi). Therefore, further iteration is superfluous: all the pref\nerences on events in A are already included in A.\nUnder regularity conditions described in [LMS98] there exists an expected utility representation of agent i's preferences on events in An, for all finite n and for all i E I, which satisfies\nfor any finite, An-measurable partition {Ek} of E. Ob serve that, since here probabilities and utilities emerge purely as expressions of preferences, statements about (unobservable, but strategically relevant ) probabilities and utilities can be made sense of as statements about preferences (observable, at least in principle ). Also, statements about higher-order probabilities and utili ties (such as \"I believe that you consider E more likely than F\", or \"I would like you to believe F\" , etc., also useful when carrying out explicit strategic reason ing ) can be similarly interpreted as statements about higher-order preferences.\nFurthermore, under additional regularity conditions, for all i E I there exists a conditional expected utility representation of t on A which satisfies\nfor all (E, F) E Ax Bi, and for any finite, measurable partition { Ek} of E. 1\n1 For a precise statement of the result and for proofs see (LM99].\nSo far the representation does not involve any notion of causality: in other words, nothing links the agents' preferences on events with the actual occurrence of those events. To bring causality into the picture we first assume that the set of basic events Ao is the Boolean algebra generated by the available moves in an extensive form game. For each information set H in the extensive form, let { E H} be the partition gen erated by the available moves at H. We shall refer to the EH as optional events, or actions.\nWe could now assume that, for any information set H associated to agent i, and for any EH and FH which are available actions at H, EH >-i FH implies FH = 0; in other words, we could regard any action which is not the most preferred by the agent at the corresponding information set as impossible. One problem with this approach is that all dominated actions, being impossi ble, must be indifferent to each other. In other words, for no three actions EH, FH, G H can it be the case that EH >-i FH >-i GH. This naive treatment of causality leads to significant difficulties when reasoning about weakly dominated strategies, as the latter cannot be regarded as disbelieved yet possible events.\nWe avoid this problem by adopting a probabilistic no tion of causality. In this view, all optional events are possible; the notion of possibility logically precedes the agents' decisions, and is part of the description of the game. In particular, this will allow us to regard a prisoner's dilemma, where cooperation is indeed an available action, as logically distinct from a degenerate game in which the two players have no choice at all.\nThe following property links preferences to actions; for any two actions EH, FH available to agent i at H, EH >-i FH implies PH(FH) = 0. The interpre tation of this assumption, which we shall refer to as Bayesian rationality, is that agents do not directly as sign the truth values of optional events; rather, their preferences constrain the conditional probabilities of the possible actions in such a way that the probabil ity of any dominated action is equal to zero. Intu itively, we are assuming that the agents' decisions may be prone to occasional mistakes, but the likelihood of any such mistake is infinitesimal.\n3 Game Networks\nThere are two standard representations for mathemat ical games: the normal (or strategic ) form, and the extensive form. The extensive form is more structured than the normal form: not only it describes the iden tities of the players, the strategies available to each player, and the payoff functions, as the normal form does; but also the information held by the agents at any possible state of the system, and the causal struc-\n338 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nture of events in the game. The extensive form is at least as general as the normal form: any game in nor mal form can be interpreted as a game with simulta neous moves, and represented in the extensive form. The reverse operation (from the extensive to the nor mal form) is also possible, but some of the structural information is lost in the process, and hence the result ing normal-form representation is often impractically large.\nEven though extensive-form representations are more compact than normal-form ones, they may still be quite redundant: often, in concrete examples, differ ent end nodes may have identical payoffs, and the same actions may be available at different informa tion sets, but the recognition of those symmetries does not lead to a more parsimonious representation. Fur thermore, changing a few details in the setup usually entails rewriting the whole game; in other words, the extensive-form representation is not particularly mod ular. As we shall see, compared to extensive forms G nets are at least as general, but more structured and more compact.\nIn order to formally define G nets we need some more notation, which we borrow from [ L M S99]. Let {Xk}kEN be a set of variables, and for any M C N let XM := XkEMXk. Let u: XN---+ IR+ be a strictly posi tive utility function, and let {A, B, C} be a partition of N; also, define -A:= BUC. F inally, let w(xAIX-A) = u(xA, X-A)/u(x�, X-A), where x0 E XN is an arbi trary reference point; w(xAIX-A) is called the utility potential at XA, and captures how the utility changes when the variables in A shift away from the reference point, while the values of the remaning variables are held fixed at X-A· If, for all (xA, X-A) , the value of w(xAIX-A) only depends on xc, and not on XB, we say that XA is u-independent of XB given Xc, and define new quantities w(xAJxc) := w(xAJx�,xc). If XA and XB are both probabilistically and u-independent given Xc then we say that they are strategically independent given Xc.\n3.1 A formal definition\nG nets are comprised of a finite, ordered set of nodes XN (where N = {1, . . ,n}), corresponding to a set of\nstrategically relevant variables which we also assume to be finitely-valued, a partition I of N which determines the identity of the agent responsible for the decision at each node2 (including Nature), and two types of arc, representing causal and preferential (teleological) de-\n2For simplicity, we assume that all the actions available at node k pertain to the same player i(k), although this assumption can be relaxed. In fact, our treatment carries over without changes if we assume that different agents are active at different information sets of the same node.\npendencies. Causal dependencies are represented by directed (probability) arcs, with no cycles, and prefer ential dependencies by undirected (utility) arcs.\nA node Xk (k E N) is associated with two quantities, w ( xk iXuN(k) and p(xklxPF(k)), where UN(k) are the\nnodes directly connected to Xk via utility arcs (the utility neighbors of X k), and P F ( k) is the set of prob ability parents 3 of xk. While the p(xkiXPF(k)) iden tify a conditional probability system, the same for all players, w is a vector of functions ( wi). 1, one for each zE player. In turn, the wi ( xk lxuN(k ) are interpreted as the utility potentials coming from some strictly posi tive utility finction ui.\nThe incoming probability arcs represent those events which the agent who controls Xk can observe at the moment of decision. A decision-maker (including Na ture) may choose any random rule, as long as it de pends on the truth values of the XPF(k) only. An element of the partition generated by the XPF(k) is called an information set at k, and represents all the information available to the agent at the moment of decision.\nWe say that payoffs are normal if the utilities of all states are positive, and are expressed as multiples of u i(x0) (where x0 is the arbitrary reference point). Clearly, any game can be transformed in one with nor mal payoffs via a suitable positive affine rescaling of the original payoffs. Hence, without loss of generality, we shall concentrate on games with normal payoffs.\nA G net in which only the probabilities of Nature 's ac tions (and not those of the other agents') are specified is a G frame. A G frame can be regarded as the set of all G nets which respect the implied independence structure, and agree in the utility assignments and in the probabilities of Nature 's actions.\nTheorem 1 Any finite game in extensive form has a G frame representation.\nLet Ai(H) be the set of actions available to player i at an information set H. Ai(H) can be regarded as a partition of H into possible actions EH.\nDefinition 3 A Game network is said to satisfy Bayesian rationality if, for all k E N, for all informa tion sets H = XPF(k), and for any EH, FH E Ai(k) ( H) , it is the case that ui (k) ( EH JH) > ui(k)(FHJH) implies PH(FH) = 0.\nAnticipating our discussion on the existence of strate gic equilibrium in game networks, we state the follow-\n3The probability parents of a node Xk are those nodes which are immediate predecessors of Xk in the partial or dering induced by the (directed) probability arcs.\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 339\ning important corollary.\nCorollary 2 For any finite G frame there exists a corresponding G net which satisfies Bayesian rational ity .\n3.2 An example: the beer/quiche game\nAs an example of G net we present the beer /quiche game. In this game, Nature selects the type of player 1, who may be either strong ( S ) or weak (- S ). Player 1 (who knows his type ) goes to a pub, and has to decide whether to get beer (B ) or quiche (- B ). His decisions are observed by player 2, who is a bully and, as such, enjoys fighting against weak types. After observing what player 1 orders, player 2 decides whether to start a fight with player 1 ( F ) or not (- F ). If player 1 is strong he will fight back, and hence player 2 in that case prefers not to fight. Player 1 always prefers not to get into a fight, but more strongly so if he is a weak type and hence knows that he would be beaten up. Finally, strong types of player 1 prefer beer to quiche, while weak types have the opposite preference.\nA G net (or, more precisely, a G frame ) representation of this game is depicted in figure 1, along with the cor responding extensive-form representation. The prob ability dependencies are represented by solid arrows, while the dashed and dotted lines represent utility de pendencies for players 1 and 2 respectively.\np(S)-0.9 w(S.BI·F)-1 w,(SI-F)-1\nw1(BIS)=3/2 w,(BI-5)\"2/3\n(3, 4)\n(12, 2)\n(4. I)\n(8, 2)\nF\n-F\n···-:::, ··· ....\n-B\n-S\ns\n-B\nw1(FIS)=112 w,(FI-5)=1/4 F w,(FIS)=112 w2(F�S)=2\nB\n0.1\n0.9\nB\nreference point: -S,-B,-F payoffs - utility relative to referenoe point, times 12.\nF (2, 4)\n-F (8, 2)\n(6, 1)\n(12, 2)\nF igure 1: The beer / quiche game.\nIn the informal description above are buried several in dependence assumptions. For instance, it is implicitly assumed that Nature's choice cannot depend on what the two players will do later, or that player 2's decision\ncontingent on the observation of player 1 's behavior is independent of Nature's choice. Moreover, it is im plicitly assumed that player 1 prefers beer or quiche regardless of whether he will have to fight or not, or that player 2 only cares about 1 's type if he chooses to fight, but not otherwise.\nIn the G net representation, both probability and util ity independencies are captured in the structure of the network. By contrast, the extensive form only cap tures probability independencies, while the recognition of utility independencies (which induce symmetries in the payoff structure ) does not lead to a more compact representation. In our example, compactness is also reflected in the number of parameters needed to spec ify the game payoffs: in the extensive form one needs 16 parameters to identify the payoffs, while in the G net representation one only needs 8.\nCompactness is only one of several advantages of G nets over extensive forms; another one is modularity. For instance, in a G net one can easily introduce new moves (e.g., the reaction of a third player to player 2's decision to fight or not ), or change the informational assumptions while at the same time retaining most of the existing structure (in particular, payoffs do not need to be completely reassessed if the state space is refined ).\nA third advantageous feature of G nets is that the rele vant information about utilities can generally be intro duced more naturally than in extensive forms. In the context of our example, for instance, going from the in formal description to a numeric assessment of the pay offs is relatively cumbersome; the decision maker needs to report absolute utility values for all possible out comes, while the informal description only compares a few different scenarios. By contrast, to construct a G net one only needs information about payoff depen dencies and order-of-magnitude comparisons between the relative utilities of alternative scenarios, which is closely related to the type of information contained in the informal description.\n4 Strategic equilibrium in game networks\nAn important aspect of multi-agent reasoning is the identification of some or all of the strategic equilibria in a game. In this section we establish convergence re sults for strategic equilibrium which can exploit strate gic separabilities in the G net representation in order to simplify the computation of equilibria. Specifically, we describe a path-tracking method which identifies a unique equilibrium as a function of the game payoffs, and one which identifies all equilibria.\n340 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nLet X be a finite set of states, and let A be a Boolean algebra of subsets of X.\nWe assume that the agent's preferences on A admit a conditional expected utility representation (p, u), where p is a conditional probability system defined on A, and u is a function associating to each state x a positive real number u(x).\nThe expected utility and conditional expected utility for general events are defined by\nu(p)(E) := L u(x)p(xiE), and X\nu(En F) u(p)(FIE) :=\nu(E) .\nLet v(FIE) := p(FIE)u(FIE); we say that VE(F) := v(FIE) is the conditional value of F given E. Notice\nthat { VE }eEA-{0} is a conditional probability system. Moreover, for any nonempty conditioning event E and for any F whose conditional probability is nonzero,\nv(FIE) u(FIE) =\np(FIE) .\nHence, in such cases we can regard the conditional expected utility as the ratio of two conditional prob abilities, one representing value and the other be lief. Note that, even when the probability of F given E is equal to zero, the conditional expected utility u(p)(E n F)/u(p)(E) is well defined and strictly posi tive.\n4.1 Existence of equilibrium in game\nnetworks\nLet G be a game network characterized by a finite set X = {Xk}kEN of decision nodes and their asso ciated probability (directed ) and utility (undirected ) arcs, and let ui : X ---+ IR+ be the utility function for player i (i E I) . For each k E N, let i(k) denote the player responsible for the choice of Xk. Let � be the set of all conditional probability systems {PH} on X where His an information set XPP(k) for some kEN, and PP(k) are the probability parents of k. Then the probability of any state x can be obtained by means of the simple product rule p(x) = xkENP(Xk lxPP(k) ). No tice that � is a compact subset of !Rn (where n is the number of parameters p(xkiXPP(k)) which character ize p), and is also convex with respect to combinations p>..p' defined by\np)..p'(xkiXPP(k)) = Ap(xk lxPP(k))+(1-A.)p'(xk lxPP(k)),\nfork EN, ).. E [0, 1].\nNext, let v : � ---+ � be a function which associates to each p E � a conditional probability system { v H} , where H = XPP(k) are the information sets, and\nThen v is a continuous self-function on a convex and compact subset of !Rn, and hence it has a fixed point by Brouwer's theorem. A fixed point is characterized by the set of equalities p(xklxPP(k)) = v(p)(xklxPP(k)), for all k, x k and x p P( k). Let F be the set of such fixed points.\nA Nash equilibrium is defined as a conditional proba bility system p E � such that\nfor all k E N, xPP(k) and q E �- The set of Nash equilibria E is contained in F, as equilibrium probabil ities satisfy the fixed point conditions p(xkixPP(k)) = v(p)(xkiXPP(k))· This is an immediate consequence of the following result.\nProposition 3 p is a Nash equilibrium if and only if\n1. ui(k)(p)(xkixPP(k)):::; 1, and\n2. Ui(k)(p)(xkiXPP(k)) = 1 ifp(xkiXPP(k)) > 0.\nHow do we know that the set of Nash equilibria is nonempty? It is easy to check that Nash equilibria in G nets correspond to Nash equilibria in the agent strategic form [FT91, p.354], and hence an equilibrium exists by Nash's theorem. Yet, we present a simple direct proof, which motivates the convergence method we define later on.\nLet fe : � ---+ � be the function defined by f := uv = cz + (1 - c)v, where z is the conditional probability\nsystem which assigns equal probability to all the avail able actions at each information set. Brouwer's theo rem guarantees that the set of fixed points of fe is not empty. F ixed points of fe have an important property:\nProposition 4 If p is a fixed point of fe, then ui(k)(p)(xklxPP(k)) > ui(k)(p)(x�lxPP(k)) implies p(xkiXPP(k)) > p(xkiXPP(k)).\nWe define a robust equilibrium as a limit point of a sequence of fixed points of fe, as c goes to zero. By\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 341\ncompactness of D. any such sequence has a limit point, and hence the set of robust equilibria is nonempty. Since a robust equilibrium always exists, the following result ensures that the set of Nash equilibria is not empty.\nProposition 5 Any robust equilibrium zs a Nash equilibrium.\nIn fact, a stronger result holds: robust equilibria are also perfect, as they are easily shown to satisfy Defi nition 8.5C in [F T91, p.352 ].\nRobust equilibria are similar to proper equilibria [Mye78 ], in that they are limits of sequences of strictly\npositive measures such that strategies with higher util ities always have higher probabilities.\n4.2 Global convergence to equilibrium in\ngame networks\nLet { ui} iEI be the utility functions in a G net. We saw that an equilibrium is a conditional probability system p which satisfies F(p) = 0, where F(p) is the vector of functions defined by\nF(p)(xkiXPP(k)) = p(xkiXPP(k))- v(p)(xkiXPP(k)), and Ui(k) (p)(xk, XPP(k))\nv(p)(xkiXPP(k)) = p(xkiXPP(k)) i(k)( )( ) · U P XPP(k)\nWe study convergence to a zero of the vector F under the assumption that the probability of an action in creases or decreases in proportion to its relative utility with respect to the other available actions. For now we shall ignore the fact that some fixed points may fail to be equilibria; in fact, we show below that the method we are presenting will converge to a Nash equilibrium in games with generic payoffs.\nConsider the perturbed problem\nF.,(p)(xkiXPP(k)) = p(xkiXPP(k))- f .,(p)(xkixPP(k)) · Observe that F., can be rewritten as cF0(p) + (1 - c)F(p), where F(p) is the target system whose ze\nros we want to find and F0(p) is the trivial system ( p(xkixPP(k))- z(xkixPP(k) )xk>xPP(kJ, whose unique solution is p = z. Then F., defines a convex-linear ho motopy h(p, t) = F1_t [Mor87, p.135 ] with parameter t E [0, 1 ]. Note that h coincides with the trivial system for t = 0, and with the target system for t = 1.\nIn our setting h is extremely well behaved: for generic payoffs it satisfies conditions 1,2,3 and 4b in [Mor87, p.122 ] by construction, and moreover it satisfies condi-\ntion 5 (in !Rn) because F is bounded. Therefore, stan dard path-tracking methods are guaranteed to work for generic games. The end point of the homotopy path is a robust equilibrium, as it is the limit, as c goes to zero, of a sequence of solutions for the perturbed prob lem. To handle degenerate cases, in which the uniform distribution is a bad choice of initial condition, it suf fices to introduce a slight random perturbation to the game payoffs to guarantee convergence.\nNow we can define a new solution concept (the end point of the homotopy path ), which we name first equi librium, and claim that:\n• a generic G net has a unique first equilibrium\n• the first equilibrium is uniquely determined by the payoff structure of the game\n• the first equilibrium of a generic G net can be ap proximated using standard path-tracking meth ods\n• the first equilibrium is a robust equilibrium of the game.\nHow does the above procedure compare with the ex isting game-theoretic methods for computing a sample equilibrium? The literature on computational meth ods in game theory is quite technical, and we shall not attempt an explicit comparison here; for a sur vey on the recent state of the art we refer to [M M96]. The main advantage of our approach with respect to other methods is that, for given (xk, XpP(k)), strate gically independent variables do not affect the values of F(p)(xkixPP(k)) ; it follows that, in the presence of strategic independencies, convergence to the zeros of a large system can be reduced to convergence to the zeros of smaller, strategically independent subsystems. The following example illustrates the point for a simple case.\nExample 2 Suppose that there is only one agent, and let A and B be two strategically independent subsets of variables with marginal probability functions Pa and Pb respectively. Then p = Pa x Pb, and F(p) (a) and can be written as Pa (1 - w a l,��) ) , while a sim-a' W a 0 Pa' ilar expression holds for F(p)(b) . Note that F(p)(a) (resp., F(p)(b)) is a function of Pa (resp., Pb) only, and hence the zeros of F(p) correspond to the zeros of the two independent subsystems FA(Pa) := F(p)(a) and FB(Pb) := F(p)(b).\n4.3 Computing all the equilibria\nThe convergence method we presented above only tracks a single robust equilibrium. Yet, in many cases\n342 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\none wants a complete list of all the Nash equilibria. For instance, we may want to design agents who always coordinate on a Pareto efficient equilibrium, whenever such efficient equilibrium is unique. How would our agents know if that condition is met? In principle, they will need to identify all the equilibria in order to infer their optimal strategies.\nFinding all equilibria is computationally very demand ing. As in the single-equilibrium case, we seek a method which can take advantage of strategic inde pendencies in order to simplify computations. It turns out that an adaptation of the procedure defined in sec tion 4.2 can be put to such use.\nLet G(p) be the vector of functions (gJ)jEJ (where j = (xk, XPF(k))) defined by G(p)(xkixPF(k)) = ui(k) (p)(xPF(k))F(p)(xk lxPF(k))· Since u is strictly\npositive and bounded, the zeros of G coincide with the zeros of F.\nNotice that both the numerator and the denomina tor of v(p)(xkiXPF(k)) are polynomial functions of the p(xkiXPF(k) ), and hence G(p) is a vector of polynomial functions, whose zeros include all the Nash equilibria. Also, observe that strategically independent variables do not affect the zeros of G(p)(xklxPF(k)); they only play the role of multiplicative scaling factors. As in the single-equilibrium case, in the presence of strate gic independencies we can replace a large system of polynomial equations with smaller, strategically inde pendent subsystems, as the following example shows for a simple case.\nExample 3 As in example 2 assume that there is a single agent, and two strategically independent subsets of variables A and B. Then G(p)(a) can be writ ten as Pa [La' w(a'lbo)Pa' - w(albo)] (Lb w(blao)Pb) , while a similar expression holds for G(p)(b). Observe that the last term in the product is strictly positive, and hence the zeros of G(pa, Pb) correspond to the zeros of the two independent subsystems G A (Pa) and G B (Pb), where GA(Pa)(a) := Pa [La' w(a'lbo)Pa'- w(albo)], and GB(Pb)(b) := Pb [Lb' w(b'lao)Pb'- w(blao)].\nA Nash equilibrium may not have any homotopy path converging to it in !Rn. Yet, the following result ensures that we can get at them in the complex space en. Let G0 be the initial system defined by\n0( d· d· d· Gj p) = D/P/ - !3/'\nwhere j (xk, XPF(k)), dj is the degree of G(p)(xkiXPF(k)), and aj and f3J are generic complex constants. Then G0(p) = 0 has d = XjEJdj solutions. Let h(x, t) be the homotopy defined by\nThen the following result in [Mor87, p. 60 ] applies.\nTheorem 6 Given G, there are sets of measure zero, Aa and As in en such that, if a � Aa and {3 � At3, then:\n1. the solution set {(p, t) E en X [0, 1 ) : h(p, t) = 0 } is a collection of d non-overlapping (smooth} paths\n2. the paths move from t = 0 to t = 1 without back tracking in t\n3. each geometrically isolated solution of G = 0 of multiplicity m has exactly m continuation paths converging to it.\nTheorem 6 guarantees that the homotopy paths gen erated by h are well-behaved, and can be tracked with standard computational techniques. Observe that this method will identify all the zeros of G, in cluding those which are not Nash equilibria; yet, the latter are easily singled out, as they correspond to the real solutions which lie in the region delimited by ui(k)(p)(xkiXPF(k)) � 1.\nReferences\n[FT91 ] Fudenberg, D. and Tirole, J., 1991, Game Theory, M IT Press, Cambridge.\n[L M S98 ] La Mura, P. and Shoham, Y., 1998, Condi tional, hierarchical, multi-agent preferences. In Proc. of Theoretical Aspects of Rationality and Knowledge - VII, 215-224.\n[L M S99 ] La Mura, P. and Shoham, Y., 1999, Expected Utility Networks. In Proc. of the 15th con ference on Uncertainty in Artificial Intelli gence, 366-373.\n[L M99 ] La Mura, P., 1999, Foundations of Multi Agent Systems, Ph.D. dissertation. Graduate School of Business, Stanford University.\n[M M96] McKelvey, R. and Mc Lennan, A., 1996, Computation of Equilibria in F inite Games. In Handbook of Computational Economics,\nVol. 1., Elsevier Science B.V.\n[Mor87 ] Morgan, A., 1987. Solving polynomial sys tems using continuation for engineering and scientific problems. Prentice- Hall.\n[Mye78 ] Myerson, R., 1978, \"Refinements of the Nash Equilibrium Concept\", International Jour nal of Game Theory 7, 73-80.\n[Pea88 ] Pearl, J., 1988, Probabilistic reasoning in in telligent systems. Morgan Kaufmann."
    } ],
    "references" : [ {
      "title" : "Condi­ tional, hierarchical, multi-agent preferences",
      "author" : [ "M L" ],
      "venue" : "In Proc. of Theoretical Aspects of Rationality and Knowledge - VII,",
      "citeRegEx" : "L,? \\Q1998\\E",
      "shortCiteRegEx" : "L",
      "year" : 1998
    }, {
      "title" : "Expected Utility Networks",
      "author" : [ "Y. Shoham" ],
      "venue" : "In Proc. of the 15th con­ ference on Uncertainty in Artificial Intelli­ gence,",
      "citeRegEx" : "Shoham,? \\Q1999\\E",
      "shortCiteRegEx" : "Shoham",
      "year" : 1999
    }, {
      "title" : "Foundations of Multi­ Agent Systems, Ph.D",
      "author" : [ "P. La Mura" ],
      "venue" : null,
      "citeRegEx" : "Mura,? \\Q1999\\E",
      "shortCiteRegEx" : "Mura",
      "year" : 1999
    }, {
      "title" : "Solving polynomial sys­ tems using continuation for engineering and scientific problems",
      "author" : [ "A. Morgan" ],
      "venue" : null,
      "citeRegEx" : "Morgan,? \\Q1987\\E",
      "shortCiteRegEx" : "Morgan",
      "year" : 1987
    } ],
    "referenceMentions" : [ ],
    "year" : 2011,
    "abstractText" : "We introduce Game networks ( G nets), a novel representation for multi-agent decision problems. Compared to other game-theoretic representations, such as strategic or extensive forms, G nets are more structured and more compact; more fundamentally, G nets consti­ tute a computationally advantageous frame­ work for strategic inference, as both prob­ ability and utility independencies are cap­ tured in the structure of the network and can be exploited in order to simplify the infer­ ence process. An important aspect of multi­ agent reasoning is the identification of some or all of the strategic equilibria in a game; we present original convergence methods for strategic equilibrium which can take advan­ tage of strategic separabilities in the G net structure in order to simplify the computa­ tions. Specifically, we describe a method which identifies a unique equilibrium as a function of the game payoffs, and one which identifies all equilibria.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}