{
  "name" : "1606.05124.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Robust Active Perception via Data-association aware Belief Space Planning",
    "authors" : [ "Shashank Pathak", "Vadim Indelman" ],
    "emails" : [ "shashank@technion.ac.il", "antony.thomas@technion.ac.il", "asaff@technion.ac.il", "vadim.indelman@technion.ac.il" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In the context of partially observable Markovian systems, planning over belief space (BSP) under some simplifying assumptions, provides scalable applications including autonomous navigation, object grasping and manipulation, active SLAM, and robotic surgery. In presence of uncertainty, such as in robot motion and sensing, the true state of variables of interest (e.g. robot poses), is unknown and can only be represented by a probability distribution over possible states, given available data. This distribution, the belief space, is inferred using probabilistic approaches based on incoming sensor observations and prior knowledge. The corresponding problem is an instantiation of a partially observable Markov decision problem (POMDP) [16]. Apart from simplifying structural assumptions – such as Gaussian noise around a given observation and motion model – state-of-the-art BSP approaches typically assume data association to be ar X\niv :1\n60 6.\n05 12\n4v 1\n[ cs\n.R O\n] 1\n6 Ju\ngiven and perfect (see Figure 1b), i.e. the robot is assumed to correctly perceive the environment to be observed by its sensors, given a candidate action. For brevity, we shall call it DAS. In reality, the world is often full of ambiguity, that together with other sources of uncertainty, make perception a challenging task. As an example, matching images from two different but similar in appearance places, or attempting to recognise an object that is similar in appearance, from the current viewpoint, to another object. Both cases are examples of ambiguous situations, where näıve and straightforward approaches using DAS are likely to yield incorrect results, i.e. mistakenly considering the two places as same, and incorrectly associating the observed object.\nThus, in presence of ambiguity, DAS may lead to incorrect posterior beliefs and as a result, to sub-optimal actions. More advanced approaches are therefore required to enable reliable operation in ambiguous conditions, approaches often referred to as (active) robust perception. These approaches typically involve probabilistic data association and hypothesis tracking given available data. Thus, for the object detection example, each hypothesis may represent a candidate object from a given database that the current observation (e.g. image or point-cloud) is successfully registered to. Similarly, one might reason probabilistically regarding perceptual aliasing, as in the first example above, which would also involve probabilistic data association. Yet, existing robust perception approaches focus on the passive case, where robot actions are externally determined and given, while the closely related approaches for active object detection and classification consider the robot to be perfectly localised.\nIn this work we develop a general data association aware belief space planning (DA-BSP) framework capable of better handling complexities arising in real world, possibly perceptually aliased, scenarios. We rigorously incorporate reasoning about data association within belief space planning, while also considering\nother sources of uncertainty (motion, sensing and environment). In particular, we show our framework can be used for active disambiguation by determining appropriate actions, e.g. future viewpoints, for increasing confidence in a certain data association hypothesis.\nOrganization of the paper : After discussing related work and stating our contributions, we formulate the considered problem in Section 2. In Section 3 we provide concept overview and then discuss in detail the proposed approach, while demonstrating key aspects in simulated basic and realistic scenarios in Section 4. Finally, in Section 5 we conclude the discussion and suggest potential directions for future research."
    }, {
      "heading" : "1.1 Related Work",
      "text" : "Calculating optimal solutions to POMDP is computationally intractable (PSPACEcomplete) [22] for all but the smallest problems. The vast research area of approximate approaches (with reduced computational complexity) can be roughly segmented into point-based value iteration methods [19, 26], simulation based [30] and sampling based approaches [2, 6, 27], and direct trajectory optimization [11, 25, 33] methods. In all cases, finding the (locally) optimal actions involves evaluating a given objective function while considering future observations to be acquired as a result of each candidate action. They all assume DAS. For example, it is typically assumed that the robot can be localised by making observations of known landmarks or beacons (see, e.g. [2, 27]), while assuming to correctly associate each future measurement with an appropriate landmark. Though reasonable in certain scenarios, DAS becomes unrealistic in the presence of perceptually aliased environments (two scenes that look alike) and localisation uncertainty, as in this work.\nThe issue of perceptual aliasing has been considered in the earlier works on POMDP planning, though again with highly simplified scenarios, since the data-association further complicates the problem. In a slightly separate line of research, the approaches that study the issue were in the context of multiple hypothesis tracking(see [28] for earliest work on MHT) or more recently, of active robust perception. Both these approaches rely on passive and often nonparametric approaches, through various filtering techniques; we refer an interested reader to the book [15] and tutorial [3] for further details. For example, [34] proposed using Gaussian mixture probability hypothesis density (PHD) filter. To the best of our knowledge, such approaches are not considered in the context of active planning.\nComing back to scalable planning methods such as BSP, we note that while the traditional BSP approaches had typically assumed the environment to be accurately known (e.g. a given map), recent works, including [8,9,11,18,35], relax this assumption and model the uncertainty of the environment mapped thus far within the belief. The corresponding framework is thus tightly related to active SLAM, with the well known trade-off between exploration and exploitation. Recent work [9,11,18,35] in this branch focused in particular on probabilistically\nmodelling what future observations will be obtained given a candidate action. Though none of them relax DAS assumption.\nIn the last few years, the SLAM research community has investigated approaches to be resilient to false data association (outliers) overlooked by frontend algorithms (e.g. image matching), see e.g. [7, 13, 14, 21, 31]. However these approaches, also known as robust graph optimization approaches, are developed only for the passive problem setting, i.e. robot actions are given and externally determined. In contrast, we consider a complimentary active framework that incorporates data association aspects within BSP.\nOur approach is also tightly related with recent work on active hypothesis disambiguation in the context object detection and classification [4,20,29,32,36]. Given hypotheses regarding object class and pose, these approaches aim to find a sequence future viewpoints that will lead to disambiguation, i.e. identifying the correct hypothesis. However, these approaches assume the sensor is perfectly localized and can be shown to be a specific case of DA-BSP.\nProbably the closest work to our approach is by Agarwal et al. [1], where the authors also consider hypotheses due to ambiguous data association and develop a BSP approach for active disambiguation. However, unlike them, DABSP considers ambiguous data association also in posterior and thus does not require a guarantee of fully disambiguating action in the future."
    }, {
      "heading" : "1.2 Contributions",
      "text" : "To summarize, our main contributions in this paper1 are as follows: (a) relaxing the data-association-is-solved assumption for a general data-association aware BSP framework (DA-BSP) with GMM priors (b) considering active dataassociation aspect for both planning and inference, hence providing a closed-loop framework (c) reducing some of the known recent BSP approaches to a degenerate cases of DA-BSP (d) demonstrating empirical results in support of two claims: data-association is crucial for a robust BSP and the principled approach of DA-BSP can be scalable enough to be applied on practical problems."
    }, {
      "heading" : "2 Notations and Problem Formulation",
      "text" : "Consider a robot operating in a partially known or pre-mapped environment which can be ambiguous and perceptually aliased. The robot takes observations of different scenes and objects in the environment, and uses these observations to infer application-dependent random variables of interest (e.g. past and current robot poses). The following three spaces are involved in the considered problem, as shown in Figure 1: pose-space, scene-space and observation-space.\nPose-space involves all possible perspectives a robot can take with respect to a given environment model and in the context of task at hand. We denote the robot pose at time step k by xk and a sequence of poses from 0 up to k by\n1Earlier versions of this paper appeared in [24] and [23].\nXk . = {x0, . . . , xk}. Given all controls u0:k−1 . = {u0, . . . , uk−1} and observations Z0:k . = {Z0, . . . , Zk} up to time step k, the posterior probability distribution function2 is defined as P(Xk|u0:k−1, Z0:k). For notational convenience, we define below histories Hk and H−k+1 and rewrite the posterior pdf (belief ), at time k as b[Xk] . = P(Xk|Hk).\nHk . = {u0:k−1, Z0:k} , H−k+1 . = Hk ∪ {uk}. (1)\nThe scene-space involves a discrete set of objects or scenes, denoted by the set {AN}, in the given world model, and which can be detected through the sensors of the robot. We will use symbols Ai and Aj to denote such typical scenes. Note that even if the objects are identical, they are distinct in scene space. This will be important when we shall consider the cases where the objects look similar from some perspectives. Finally, observation-space is the set of all possible observations that the robot is capable of obtaining when considering its mission and sensory capabilities.\nWe consider probabilistic motion and observation models\nxk+1 = f(xk, uk) + wk , zk = h(xk, Ai) + vk, (2)\nand denote them by P(xk+1|xk, uk) and P(zk|xk, Ai), respectively. As common in literature, we consider Gaussian zero-mean process and measurement noise wi ∼ N (0, Σw) and vk ∼ N (0, Σv), with known noise covariance matrices Σw and Σv. Here, h(xk, Ai) is a noise-free observation which we would refer as nominal or predicted observation ẑ, that corresponds to observing scene Ai from pose xk.\nGiven a prior P(x0) and motion and observation models (2), the joint posterior pdf at the current time k can be written as\nP(Xk|Hk) = P(x0) k∏ i=1 P(xi|xi−1, ui−1)P(Zi|xi, Ai). (3)\nNote that DAS is the underlying assumption in the above equation. If the prior P(x0) is Gaussian, it is not difficult to show that b[Xk] is also a Gaussian with some mean X̂k and covarianceΣk that can be efficiently calculated via maximum a posteriori (MAP) inference, see e.g. [17]. It is also valid in case where the environment model is given but uncertain, and when this model is unknown a priori and instead is constructed on-line within SLAM framework. However, in this paper we consider a more general case where the prior belief is modeled by a Gaussian mixture model (GMM). Such a situation can arise, for example, in the kidnapped robot problem in a perceptually aliased environment (e.g. different similar in appearance rooms), where matching sensor observations against a given map would indicate several most probable robot locations. In\n2Strictly speaking, this is either the probability mass function or the probability density function for a discrete or a continuous random variable, respectively.\nsuch a case the belief at time k can be represented by a GMM,\nb[Xk] = Mk∑ j=1 ξjkP(Xk|Hk, γ = j), (4)\nwhere Mk is the number of components (or modes), the jth component is represented by the weight ξjk . = P(γ = j|Hk), modeling the probability of the robot being in that component, and by the conditional Gaussian\nb[Xjk] . = P(Xk|Hk, γ = j) = N (X̂jk, Σ j k), (5)\nwith appropriate mean X̂jk and covariance Σ j k. Here, γ is an indicator variable denoting the component number. Given the belief at time k, one can reason about the robot’s best future actions that would minimize (or maximize) an objective function J .\nJ(uk) = E {c (b[Xk+1], uk)} , (6)\nwhere the expectation is over the (unknown) future observation zk+1, and c(.) is the immediate cost.\nThe posterior belief at time tk+1 is a function of control uk and observation zk+1, i.e.\nb[Xk+1] . = P(Xk+1|Hk+1) ≡ P(Xk+1|Hk, zk+1, uk). (7)\nNote that, according to Eq. (6), we need to calculate the posterior belief (7) for each possible value of zk+1.\nSimilarly, we define the propagated joint belief as\nb[X−k+1] . = P(Xk|Hk)P(xk+1|xk, uk), (8)\nfrom which the marginal belief over the future pose xk+1 can be calculated as b[x−k+1] . = ∫ ¬xk+1 b[X − k+1].\nIn particular, the propagated belief at the first look ahead step, given the GMM belief (4) at time k is\nb[X−k+1] = Mk∑ j=1 ξj−k+1b[X j− k+1], (9)\nwith ξj−k+1 . = P(γk+1 = j|H−k+1) ≡ ξ j k, and b[X j− k+1] . = P(Xk+1|H−k+1, γk = j) = b[Xjk]P(xk+1|xk, uk). As earlier, with DAS assumption, one can consider for each specific value of zk+l the corresponding observed scene Ai, and express the posterior (7) recursively as\nb[Xk+1]=ηb[X − k+1]P(zk+1|xk+1, Ai), (10)\nwhich can be represented as b[Xk+1] = N (X̂k+1, Σk+1) with appropriate mean X̂k+1 and covariance Σk+1. The optimal control is then defined as: u?k . = arg minuk J(uk).\nDAS assumption simplifies greatly the above formulation. Yet, in practice, determining data association reliably is often a non trivial task by itself, especially when operating in perceptually aliased environments. An incorrect data association (wrong scene Ai in Eq. (10)) can lead to catastrophic results, see, e.g. [12–14]. In this work we relax this restricting assumption and rigorously incorporate data association aspects within belief space planning and inference considering the underlying distributions are GMMs."
    }, {
      "heading" : "3 Approach",
      "text" : "Given some candidate action (or sequence of actions) and the belief at planning time k, we can reason about a future observation zk+1 (e.g. an image) to be obtained once this action is executed; its actual value is unknown. All the possible values such an observation can assume should be taken into account while evaluating the objective function; hence, the expectation operator in Eq. (6). When written explicitly it transforms to\nJ(uk) . = ∫ zk+1 (a)︷ ︸︸ ︷ P(zk+1 | H−k+1) c\n (b)︷ ︸︸ ︷ P(Xk+1|H−k+1, zk+1)  (11) The two terms (a) and (b) in the above equation have intuitive meaning: for each considered value of zk+1, (a) represents how likely is it to get such an observation when both the history H and control uk are known, while (b) corresponds to the posterior belief given this specific zk+1.\nConsidering DAS means we can correctly associate each possible measurement zk+1 with the corresponding scene Ai it captures, as in Eq. (10). Yet, it is unknown from what future robot pose xk+1 the actual observation zk+1 will be acquired, since the actual robot pose xk at time k is unknown and the control is stochastic. Indeed, as a result of action uk, the robot actual (true) pose xk+1 can be anywhere within the propagated belief b[x−k+1]. In inference, we have a similar situation with the key difference that the observation z has been acquired. We must first associate the captured measurement z with the scene or object Ai it describes, i.e. write the appropriate measurement likelihood term in the posterior (3).\nIn BSP framework, solved data association means that for each such observation z ∈ {z} the corresponding observed scene Ai ∈ A is known. In contrast, we do not assume this, and instead reason about possible scenes or objects that the future observation zk+1 could be generated from, see Figures 1b and 1.\nParsimonious data association: Incorporating data-association is expensive. However, if the environment has only distinct scenes or objects, then for each specific value of zk+1, there will be only one scene Ai that can generate such an observation according to the model (2). In case of perceptually aliased environments, there could be also several scenes (or objects) that are either completely identical,\nor have a similar visual appearance when observed from appropriate viewpoints. They could equally well explain the considered observation zk+1. Thus, there are several possible associations {Ai} and due to localisation uncertainty determining which association is the correct one is not trivial. As we show in the sequel, in these cases the posterior b[Xk+1] (term (b) in Eq. (11)) becomes a Gaussian mixture with appropriate weights that we rigorously compute. Additionally, the weight updates are capable of discriminating against unlikely data-associations, during the planning steps.\nPerceptual aliasing: Intuitively speaking, perceptual aliasing occurs when an object different from the actual one, produces the same observation and thereby is an alias, in the sense of perception, to the true object. Consider two notions of perceptual aliasing: exact and probabilistic. Exact perceptual aliasing of scenes Ai and Aj is defined as ∃x, x′, h(x,Ai) = h(x′, Aj), and will be denoted in this paper by {Ai, Aj}aliased. In other words, the same nominal (noisefree) observation ẑ can be generated by observing different scenes, possibly from different viewpoints. Such a situation is depicted in Figure 1. A probabilistic perceptual aliasing is a more general form of aliasing, which can be defined as ∃x, x′, |P(z|Ai, x)− P(z|Aj , x′)| < for some small threshold ."
    }, {
      "heading" : "3.1 Computing the term (a) : P(zk+1|H−k+1)",
      "text" : "Applying total probability over non-overlapping scene space {AN} and marginalizing over all possible robot poses, yields\nP(zk+1|H−k+1)≡ |AN|∑ i ∫ x P(zk+1, x, Ai |H−k+1) . = |AN|∑ i wik+1. (12)\nAs seen from the above equation, to calculate the likelihood of obtaining some observation zk+1, we consider separately, for each scene Ai ∈ {AN}, the likelihood that this observation was generated by scene Ai. This probability is captured for each scene Ai by a corresponding weight w i k+1; these weights are then summed to get the actual likelihood of observation zk+1. As will be seen below, these weights naturally account for perceptual aliasing aspects for each considered zk+1.\nIn practice, instead of considering the entire scene space {AN} that could be huge, the availability of the belief b[X−k+1] makes it possible to consider only those scenes that could be actually observed from viewpoints with non-negligible probability according b[X−k+1], e.g. within 3 standard deviations of uncertainty for each GMM component. In the following, however, we proceed while reasoning about the entire scene space {AN}.\nProceeding with the derivation further, using the chain rule we compute∑ i ∫ x P(zk+1 | x,Ai,H−k+1)P(Ai, x | H − k+1) (13)\nHowever, since P(Ai, x | H−k+1) = P(Ai|x | H − k+1)b[x − k+1 = x], we get\n|AN|∑ i ∫ x P(zk+1|x,Ai,H−k+1)P(Ai|H − k+1, x)b[x − k+1 = x]. (14)\nThus,\nwik+1 . = ∫ x P(zk+1|x,Ai,H−k+1)P(Ai|H − k+1, x)b[x − k+1=x]. (15)\nSince the propagated belief (9), from which b[x−k+1] is calculated, is a GMM, we can replace b[x−k+1 = x] with ∑Mk j=1 ξ − k+1,jb[x − k+1,j = x].\nHere, P(zk+1 | Ai, x,H−k+1) ≡ P(zk+1 | Ai, x) is the standard measurement likelihood term, while P(Ai | H−k+1, x) represents the event likelihood, which denotes the probability of scene Ai to be observed from viewpoint x. In other words, this scenario-dependent term encodes from what viewpoints each scene Ai is observable and could also model occlusion and additional aspects. As such, this term can be determined given a model of the environment and thus, in this work, we consider this term to be given.\nThe weights wik+1 (15) naturally capture perceptual aliasing aspects: consider some observation zk+1 and the corresponding generative model zk+1 = h(xtr, Atr) + v with appropriate unknown true robot pose xtr and scene Atr ∈ {AN}. Clearly, the measurement likelihood P(zk+1 | x,Ai,H−k+1) will be high when evaluated for Ai = A\ntr and in vicinity of xtr. Note that we will necessarily consider such a case, since according to Eq. (12) we separately consider each scene Ai in {AN}, and, given Ai, we reason about all poses x in Eq. (15). In case of perceptual aliasing, however, there will be also another scene(s) Aj which could generate the same observation zk+1 from appropriate robot pose x\n′. Thus, the corresponding measurement likelihood term to Aj will also be high for x\n′. However, the actual value of wi (for each Ai ∈ {AN}) depends, in addition to the measurement likelihood, also on the mentioned-above event likelihood and on the GMM belief b[x−k+1], with the latter weighting the probability of each considered robot pose x. This correctly captures the intuition that those observations z with low-probability poses b[x−k+1 = x tr] will be unlikely to be actually acquired, leading to low value of wi with Ai = A tr. Since b[x−k+1] is a GMM with Mk components, low-probability pose x tr corresponds to low probabilities b[xj−k+1 = x tr] for each component j ∈ {1, . . . ,Mk}. However, the likelihood term (12) could still go up in case of perceptual aliasing, where the aliased scene Aj generates a similar observation to zk+1 from viewpoint x\n′ with latter being more probable, i.e. high probability b[x−k+1 = x\n′]. In practice, calculating the integral in Eq. (15) can be done efficiently considering separately each component of the GMM b[x−k+1]. Each such component is a Gaussian that is multiplied by the measurement likelihood P(zk+1 | Ai, x,H) which is also a Gaussian and it is known that a product of Gaussians remains a Gaussian. The integral can then be only calculated for the window where event\nlikelihood is non-zero i.e P(Ai | x,H) > 0. For general probability distributions, the integral in Eq. (15) should be computed numerically. Since in practical applications P(Ai | x,H) is sparse w.r.t. x, this computational cost is not severe.\n3.2 Computing the term (b) : P(Xk+1|H−k+1, zk+1)\nThe term (b), P(Xk+1|H−k+1, zk+1), represents the posterior probability conditioned on observation zk+1. This term can be similarly calculated, with a key difference: since the observation zk+1 is given, it must have been generated by one specific (but unknown) scene Ai according to measurement model (2). Hence, also here, we consider all possible such scenes and weight them accordingly, with weights w̃ik+1 representing the probability of each scene Ai to have generated the observation zk+1. As will be seen next, the posterior P(Xk+1|H−k+1, zk+1) is a GMM with Mk+1 components.\nApplying total probability over non-overlapping {AN} and chain-rule, we get:\nP(Xk+1|H−k+1, zk+1) = |AN|∑ i=1 P(Xk+1 | H−k+1, zk+1, Ai) · P(Ai | H − k+1, zk+1). (16)\nThe first term, P(Xk+1 | H−k+1, zk+1, Ai), is the posterior belief conditioned on observation zk+1, history H−k+1, as well as a candidate scene Ai that supposedly generated the observation zk+1. It is not difficult to show that this posterior is actually the GMM\nP(Xk+1 | H−k+1, zk+1, Ai) = Mk∑ j=1 ξjkb[X j+ k+1|Ai], (17)\nwhere b[Xj+k+1|Ai] . = P(Xk+1|H−k+1, γ = j, Ai, zk+1) is the posterior of the jth GMM component of the propagated belief b[X−k+1], see Eq. (9).\nPlugging in Eq. (17) back into P(Xk+1|H−k+1, zk+1) yields from Eq. (10):\nb[Xk+1] ≡ P(Xk+1|H−k+1, zk+1) = |AN|∑ i=1 Mk∑ j=1 ξjkP(Ai | H − k+1, zk+1)b[X j+ k+1|Ai]. (18) The term, P(Ai | Hk, uk, zk+1), is merely the likelihood of Ai being actually the one which generated the observation zk+1. This term can be evaluated, in a similar fashion to Section 3.1, accounting for b[xj−k+1] for each considered\njth component as P(Ai | H−k+1, zk+1) = ∫ x P(Ai, x | H−k+1, zk+1), and applying Bayes’ rule yields\nw̃ijk+1 . =η′ ∫ x P(zk+1|Ai, x,H−k+1)P(Ai|H − k+1, x)b[x j− k+1=x], (19)\nwith η′ = 1/P(zk+1 | H−k+1). Note that for each component j, ∑ i w̃ ij k+1 = 1. Finally, we can re-write Eq. (18) as\nP(Xk+1|H−k+1, zk+1)= Mk+1∑ r=1 ξrk+1P(Xk+1|Hk+1, γ = r), (20)\nor in short, b[Xk+1] = ∑Mk+1 r=1 ξ r k+1b[X r+ k+1], where\nξrk+1 . = ξijk+1 ≡ ξ j kw̃ ij k+1 , b[X r+ k+1] . = b[Xj+k+1|Ai]. (21)\nAs seen, we got a new GMM with Mk+1 components, where each component r ∈ [1,Mk+1], with appropriate mapping to indices (i, j) from Eq. (18), is represented by weight ξrk+1 and posterior conditional belief b[X r+ k+1]. The latter can be evaluated as the Gaussian b[Xr+k+1] ∝ b[X j− k+1]P(zk+1 | xk+1, Ai) = N (X̂rk+1, Σrk+1), where the mean X̂rk+1 and covariance Σ r k+1 can be efficiently recovered via MAP inference."
    }, {
      "heading" : "3.3 Summary thus Far",
      "text" : "To summarize the discussion thus far, we have shown that for the myopic case, the objective function (11) can be re-written as\nJ(uk) = ∫ zk+1 ( |AN|∑ i wik+1) · c Mk+1∑ r ξrk+1b[X r+ k+1]  . (22) One can observe that according to Eq. (18), each of the Mk components from the belief at a previous time, is split into |AN| new components with appropriate weights. This would imply an explosion in the number of components, making the proposed framework hardly applicable. However, in practice, the majority of the weights will be negligible, and therefore can be pruned, while the remaining number of components is denoted by Mk+1 in Eq. (20). Depending on the scenario and the degree of perceptual aliasing, this can correspond to full or partial disambiguation.\nHaving shown incorporating data association within belief space planning leads to Eq. (22), we now proceed with the exposition of our approach.\n3.4 Simulating Future Observations {zk+1} given b[X−k+1]\nCalculating the objective function (22) for each candidate action uk involves considering all possible realizations of zk+1. One approach to perform this in practice, is to simulate future observations {zk+1} given propagated GMM belief b[X−k+1], scenes {AN} and observation model (2). One can then evaluate Eq. (22) considering all observations in {zk+1}.\nWe now briefly describe how this concept can be realised. First, viewpoints {x} are sampled from b[X−k+1]. For each viewpoint x ∈ {x}, an observed scene\nAi is determined according to event likelihood P(Ai | Hk, x). Together, x and Ai are then used to generate nominal ẑ = h(x,Ai) and noise-corrupted observations {z} according to observation model (2): z = h(x,Ai) + v. The set {zk+1} is then the union of all such generated observations {z}. Note that while generating {zk+1}, the true association is known (scene Ai), it is unknown to our algorithm, i.e. while evaluating Eq. (22). 3.5 Computing Mixture of Posterior Beliefs ∑\ni w̃ib[X i+ k+1]\nAs seen from Eq. (22), reasoning about data association aspects resulted in a mixture of posteriors within the cost c(.), i.e. ∑ i w̃ib[X i+ k+1], for each possible observation zk+1 ∈ {zk+1}. In this section we briefly describe how one can actually calculate the corresponding posterior distributions, given some specific observation zk+1 ∈ {zk+1}. For simplicity, we consider the belief at planning time k is a Gaussian b[Xk] = N (X̂k, Σk). However, our approach could be applied also to more general cases (e.g. mixture of Gaussians) with a certain price in terms of computational complexity. Further investigation of these aspects is left to future research.\nUnder this setting, each of the components b[Xi+k+1] in the mixture pdf can be written as b[Xi+k+1] ∝ b[Xk]P(xk+1 | xk, uk)P(zk+1 | xk+1, Ai). It is then not difficult to show that the above belief is a Gaussian b[Xi+k+1] = N (X̂ik+1, Σik+1) and to find its first two moments via MAP inference. Obviously, the mixture of posterior beliefs in the cost c(.) from Eq. (22) is now a mixture of Gaussians:\n∑ i w̃ib[X i+ k+1] = ∑ i w̃iN (X̂ik+1, Σik+1). (23)"
    }, {
      "heading" : "3.6 Designing a Specific Cost Function",
      "text" : "The treatment so far has been agnostic to the structure of the cost function c(.). Recalling Eq. (22) we see that the belief over which the cost function is defined, is multimodal in general. Standard cost functions in literature, typically include terms such as control usage cu, distance to goal cG and uncertainty cΣ , see e.g. [11,33]. In our case, however, the specific form of the latter should be reexamined and an additional term quantifying ambiguity level can be introduced. In this section we thus briefly discuss these two terms, starting with the cost over posterior uncertainty.\nSince, unlike in usual BSP, the posterior belief in our case is multimodal and represented as mixture of Gaussians ∑ i w̃iN (X̂ik+1, Σik+1), see Eq. (23), we could define several different cost structures depending on how we treat the different modes. Two particular such costs are taking the worst-case covariance among all covariances Σik+1 in the mixture, e.g. Σ = maxi{tr(Σi)}, or to collapse the mixture into a single Gaussian N (., Σ), see e.g. [5]. In both cases, we can define the cost due to uncertainty as cΣ = trace(Σ̂).\nThe cost due to ambiguity, cw, should penalise ambiguities such as those arising out of perceptual aliasing. Here, we note that non-negligible weights wi in Eq. (22) arise due to perceptual aliasing, whereas in case of no aliasing, all but one of these weights are zero. In most severe case of aliasing (all scenes or objects Ai are identical), all of these weights are comparable among each other. Thus we take Kullback-Leibler divergence KLu({w̃i}) of these weights {w̃i} from a uniform distribution to penalise higher aliasing, and define cw({w̃i}) . = 1 KLu({w̃i})+ , where is a small number to avoid division-by-zero in case of extreme perceptual aliasing. With user-defined weights Mu,MG,MΣ and Mw, the overall cost then can be defined as a combination\nc . = Mucu +MGcG +MΣcΣ +Mwcw, (24)"
    }, {
      "heading" : "3.7 Formal Algorithm for DA-BSP",
      "text" : "We now have all the ingredients to present the overall framework of dataassociation aware belief space planning, calling it DA-BSP for brevity. It is summarised in Algorithm 1 and briefly described below.\nGiven a GMM belief b[Xk] and candidate action uk, we first propagate the belief to get b[X−k+1] and then simulate future observations {zk+1} (line 2). The algorithm then calculates the contribution of each observation zk+1 ∈ {zk+1} to the objective function (22). In particular, on lines 8 and 9 we calculate the weights wik+1 that are used in evaluating the likelihood ws of obtaining observation zk+1. On lines 10-16 we compute the posterior belief: this involves updating each jth component from the propagated belief b[Xj−k+1] with observation zk+1, considering each of the possible scenes Ai. After pruning (line 18), this yields a posterior GMM with Mk+1 components. We then evaluate the cost c(.) (line 20) and use ws to update the value of the objective function J with the weighted cost for measurement zk+1 (line 21)."
    }, {
      "heading" : "4 Experimental results",
      "text" : ""
    }, {
      "heading" : "4.1 An Abstract Example for DA-BSP",
      "text" : "Consider the problem of robotic manipulation of objects in the kitchen. For simplicity, let us abstract it to a simpler domain of three objects, |{AN}| = 3. We consider a single step control at time step k, from a given belief b[Xk], as well as that of one step ahead b[X−k+1], and assume the following motion and observation models f and h\nf(x, u) = ( 1 0 0 1 ) · x+ d { [0, 1]T if u = up [1, 0]T if u = right ,\nh(x,Ai) = hi(x) = ( 1 0 0 1 ) · (x− xi) + si.\n(25)\nAlgorithm 1 Data association aware belief-space planning Input: Current GMM belief b[Xk] at step-k, history Hk, action uk, scenes {AN}, event likelihood\nP(Ai | Hk, x) for each Ai ∈ {AN}\n1: b[X−k+1] ← b[Xk]P(xk+1 | xk, uk) . Eq. (9) 2: {zk+1} ← SimulateObservations(b[X−k+1], {AN}) 3: J ← 0 4: for ∀zk+1 ∈ {zk+1} do 5: ws ← 0 6: for i ∈ [1 . . . |A|] do 7: . compute weight, Eq. (15) 8: wik+1 ← CalcWeights(zk+1, P(Ai | H − k+1, x), b[X − k+1])\n9: ws ← ws + wi 10: for ∀j ∈ [1, . . . ,Mk] do 11: . compute weight w̃ijk+1 for each GMM component, Eq. (19) 12: w̃ijk+1 ← CalcWeights(zk+1, P(Ai | H − k+1, x), b[X j− k+1]) 13: ξijk+1 ← ξ j kw̃ ij k+1 . Eq. (21) 14: . Calculate posterior of b[Xj−k+1], given Ai 15: b[Xij+k+1] ← UpdateBelief(b[X j− k+1], zk+1, Ai) 16: end for 17: end for 18: Prune components with weights ξijk+1 below a threshold 19: Construct b[X+k+1] from the remaining Mk+1 components via Eq. (20) 20: c ← CalcCost(b[X+k+1]) . Eq. 24 21: J ← J + ws · c 22: end for 23: return J\nwhere observations as well as the shift si is in an object-centric frame, with xi representing location of Ai. Intuitively, si is a simple mechanism to model perceptual aliasing between objects; e.g., identical objects Ai would have the same si. Figure 2 illustrates the process of simulating future observations {zk+1} for uk = up, considering unique and perceptually aliased scenes (Figures 2c-2d). In particular, a sampled pose xtr used to generate an observation zk+1 ∈ {zk+1} is shown in Figure 2b.\nFigure 3 demonstrates key aspects in our approach, considering each time a single observation zk+1. Our approach reasons about data association and hence we consider each zk+1 could have been generated by one of the 3 objects; each such association would fetch us a conditional posterior belief b[Xi+k+1] as denoted by small ellipses. Finally, we compute the total cost according to Algorithm 1.\nFigures 3a-3d denote the situation when the true pose xtr is close to center and observe A2, while in Figures 3e-3h it is at the left side and observe A1. Different degrees of aliasing are considered. Both weights wi and w̃i are shown in the inset histograms. Note that the unnormalised weight wi is higher when the object is at the centre, because the overall likelihood of the observation is higher. Also, with no aliasing, for any other scene Aj than the true one, the normalised weight wj is small irrespective of where x\ntr is. In other words, weights are also related to how likely the objects are to be the causes behind an observation; in case of no aliasing, this can be negligibly small. This is crucial since it implies\nthat DA-BSP in practical applications with infrequent aliasing, would not require any significant additional computational effort w.r.t. usual BSP.\nFigures 3b-3d depict {A1, A2}aliased, {A1, A3}aliased and {A1, A2, A3}aliased. When {A1, A3}aliased, the weights wi are similar, and indeed our cost cw of weights (in Eq. (24)) is high. For similar uncertainty in pose, this cost would remain constant. Hence, in the presence of identical objects placed similarly within the current belief, optimization of general cost function would be guided towards active localization. On the other hand, if one object j lies closer to the\ncurrent nominal pose, it will have slightly higher wj . In case {A1, A2, A3}aliased, i.e. all objects are identical, the weights wi are simply an indication of the prior. This is reasonable since in such a case, considering different data association does not yield any new information.\nFinally, in Table 1, we present the numerical analysis of cost computation (see Eq. (24)) of these configurations, as well as a metric { BSP , DA} quantifying estimation error, defined over incorrect (w.r.t ground-truth) associations through random sampling of various modes. Intuitively BSP and DA evaluate how good the posterior mean is w.r.t. ground-truth xtr for usual BSP and DABSP respectively (lower is better). Recall that unlike action u1, action u2 leads to fully unambiguous observations, around most-likely value (see Fig. 3) and consequently, BSP ' DA."
    }, {
      "heading" : "4.2 Gazebo World",
      "text" : "To demonstrate generality of DA-BSP, we compared (in simulation) it with current state of the art (denoted as BSP) and the approach proposed in [1]. For the latter case (see Fig. 4b), we have a simulated environment of rectangular corridors with shelfs(si) and elevator(e), where a pioneer robot has a non-Gaussian belief prior (shown with p1, p2); as it can be in either of the two corridors, with localization as its objective. We evaluate our algorithm for inference (infer) as well as active planning (plan) (see Table 2). The absence of pose uncertainty, which is the case in [1], would lead us to a wrong inference and estimate the robot to be at pose p1 (corridor 1) initially, whereas our approach which considers pose uncertainty will lead to correct inference with high weight for being in corridor 2 (Fig. 4b).\nTo compare with the current state of the art, we consider another scenario with 4 floors. Floor 1 has the same configuration as in Fig. 4b, floor 2 and floor 3 have the left and the right shelves (w.r.t floor 1) removed respectively and floor 4 has no shelves at all. We use the metric ηda as one of the possible\nways to quantify data association performance by computing the probability of picking the right mode in the posterior GMM (which corresponds to groundtruth position of robot). Thus, for two equally weighted GMM components, ηda = 0.5 or 0 if the correct component is one of them or if it has been pruned. The number of modes in the posterior is also indicated (for planning, the total number of modes for all the considered future observations is shown). As seen, many of the data associations considered within BSP are wrong (ηda = 0.29), while also in inference an incorrect association is made (ηda = 0). This can lead to (possibly catastrophic) mission failure; in this case, failure to associate to the correct corridor. We also show a counter-example (Fig. 4b)) for [1] (ηda = 0) since that approach does not model uncertainty within each of the GMM components. In contrast, DA-BSP outperforms both approaches within planning and inference.\nIn order to evaluate DA-BSP, we consider a simplistic set of actions, namely {fwd1, fwd2, bwd1} for a one-step forward, two-step forward and one-step backward movements, respectively (see Table 3). These actions highlight the challenges of data-association aware planning, even in the context of a simplistic scenario. Note that number of modes (which signifies different associations planner is considering at that step) is significantly higher in the planning, than in the inference. However, when there exists a disambiguating action, such as fwd2 is,\nthe planner is able to associate to the correct association all the time (demonstrated by ηda = 1)."
    }, {
      "heading" : "4.3 Aliased Multi-Floor Environment",
      "text" : "Since, incorporating data-association implies that (at least theoretically) an exponential blow-up of number of unimodal beliefs maintained in the posterior, we therefore evaluated DA-BSP in simple but real-world scene by deploying a real Pioneer robot in a 3-floor aliased environment (see Fig. 5a), with similar objective of floor and position disambiguation. When not reasoning about perceptual aliasing, the robot takes greedy (w.r.t. control cost and position uncertainty) action and fails to disambiguate, whereas DA-BSP successfully tackles planning with data-association, as shown in Figure 5b. Although not witnessed here, BSP can not guarantee global optimum solution (w.r.t. control and uncertainty cost) and DA-BSP similarly can not provide a global least cost path for full disambiguation - a problem known to be NP-hard [10]."
    }, {
      "heading" : "5 Conclusions",
      "text" : "State-of-the-art belief space planning (BSP) approaches typically consider data association to be given and perfect. However, such an assumption is less appropriate in presence of localisation uncertainty while operating in ambiguous environments, where two scenes could be similar in appearance when observed from appropriate viewpoints. In this work, we developed a data association aware belief space planning (DA-BSP) approach that relaxes the aforementioned assumption. Our framework rigorously incorporates data association aspects within BSP, while considering different sources of uncertainty (uncertainty in robot motion, sensing and possibly in the observed environment). As such, it is capable of better coping with ambiguous, perceptually aliased, situations by appropriately calculating belief evolution and expected cost due to candidate actions, and in particular, could be used for active disambiguation. Thanks to this association being inherent in planning, DA-BSP considers data-association parsimoniously and a simple thresholding is enough for a scalable application of data-association aware belief space planning. We demonstrated key aspects of\nDA-BSP in abstract example as well as Gazebo simulations. We also applied it on a real-world problem with Pioneer robot lost in a multi-storied building.\nOne of the major contributions of this work is in proposing a data-associationaware robust perception in a unified framework of plan-infer-execute. This is in contrast with passive approaches known in robust perception literature as well as that of multi-hypothesis tracking. Consequently, we are currently looking into extending the approach to non-myopic setting such that the generality of the framework becomes further explicit. Additionally, proving the general theoretical properties of DA-BSP, such as probabilistic completeness under uncertainty along the lines proposed by [2], is another interesting direction of research. Apart from this, evaluating the approach in a more complex real-world scenarios is also an avenue for future research."
    } ],
    "references" : [ {
      "title" : "Motion planning in non-gaussian belief spaces for mobile robots",
      "author" : [ "S. Agarwal", "A. Tamjidi", "S. Chakravorty" ],
      "venue" : "arXiv preprint arXiv:1511.04634,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2015
    }, {
      "title" : "Firm: Sampling-based feedback motion planning under motion uncertainty and imperfect measurements",
      "author" : [ "A.-A. Agha-Mohammadi", "S. Chakravorty", "N.M. Amato" ],
      "venue" : "Intl. J. of Robotics Research,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2014
    }, {
      "title" : "A tutorial on particle filters for on-line non-linear/non-Gaussian Bayesian tracking",
      "author" : [ "S. Arulampalam", "S. Maskell", "N. Gordon", "T. Clapp" ],
      "venue" : "IEEE Trans. Signal Processing,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2002
    }, {
      "title" : "Nonmyopic view planning for active object classification and pose estimation",
      "author" : [ "N. Atanasov", "B. Sankaran", "J.L. Ny", "G.J. Pappas", "K. Daniilidis" ],
      "venue" : "IEEE Trans. Robotics,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2014
    }, {
      "title" : "Estimation with applications to tracking and navigation: theory algorithms and software",
      "author" : [ "Yaakov Bar-Shalom", "X Rong Li", "Thiagalingam Kirubarajan" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2004
    }, {
      "title" : "Rapidly-exploring random belief trees for motion planning under uncertainty",
      "author" : [ "A. Bry", "N. Roy" ],
      "venue" : "In IEEE Intl. Conf. on Robotics and Automation (ICRA),",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Selecting good measurements via l1 relaxation: A convex approach for robust estimation over graphs",
      "author" : [ "L. Carlone", "A. Censi", "F. Dellaert" ],
      "venue" : "In IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2014
    }, {
      "title" : "Opportunistic sampling-based planning for active visual slam",
      "author" : [ "S.M. Chaves", "A. Kim", "R.M. Eustice" ],
      "venue" : "In IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS),",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2014
    }, {
      "title" : "Risk aversion in belief-space planning under measurement acquisition uncertainty",
      "author" : [ "Stephen M Chaves", "Jeffrey M Walls", "Enric Galceran", "Ryan M Eustice" ],
      "venue" : "In IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2015
    }, {
      "title" : "Localizing a robot with minimum travel",
      "author" : [ "Gregory Dudek", "Kathleen Romanik", "Sue Whitesides" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1998
    }, {
      "title" : "Planning in the continuous domain: a generalized belief space approach for autonomous navigation in unknown environments",
      "author" : [ "V. Indelman", "L. Carlone", "F. Dellaert" ],
      "venue" : "Intl. J. of Robotics Research,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2015
    }, {
      "title" : "Incremental distributed robust inference from arbitrary robot poses via em and model selection",
      "author" : [ "V. Indelman", "N. Michael", "F. Dellaert" ],
      "venue" : "In RSS Workshop on Distributed Control and Estimation for Robotic Vehicle Networks,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2014
    }, {
      "title" : "Incremental distributed inference from arbitrary poses and unknown data association: Using collaborating robots to establish a common reference",
      "author" : [ "V. Indelman", "E. Nelson", "J. Dong", "N. Michael", "F. Dellaert" ],
      "venue" : "IEEE Control Systems Magazine (CSM), Special Issue on Distributed Control and Estimation for Robotic Vehicle Networks,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2016
    }, {
      "title" : "Multi-robot pose graph localization and data association from unknown initial relative poses via expectation maximization",
      "author" : [ "V. Indelman", "E. Nelson", "N. Michael", "F. Dellaert" ],
      "venue" : "In IEEE Intl. Conf. on Robotics and Automation (ICRA),",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2014
    }, {
      "title" : "Stochastic Processes and Filtering Theory",
      "author" : [ "A. Jazwinsky" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1970
    }, {
      "title" : "Planning and acting in partially observable stochastic domains",
      "author" : [ "L.P. Kaelbling", "M.L. Littman", "A.R. Cassandra" ],
      "venue" : "Artificial intelligence,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1998
    }, {
      "title" : "iSAM2: Incremental smoothing and mapping using the Bayes tree",
      "author" : [ "M. Kaess", "H. Johannsson", "R. Roberts", "V. Ila", "J. Leonard", "F. Dellaert" ],
      "venue" : "Intl. J. of Robotics Research,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2012
    }, {
      "title" : "Active visual slam for robotic area coverage: Theory and experiment",
      "author" : [ "A. Kim", "R.M. Eustice" ],
      "venue" : "Intl. J. of Robotics Research,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2014
    }, {
      "title" : "Sarsop: Efficient point-based pomdp planning by approximating optimally reachable belief spaces",
      "author" : [ "H. Kurniawati", "D. Hsu", "W.S. Lee" ],
      "venue" : "In Robotics: Science and Systems (RSS),",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2008
    }, {
      "title" : "Active object recognition via monte carlo tree search",
      "author" : [ "M. Lauri", "N.A. Atanasov", "G. Pappas", "R. Ritala" ],
      "venue" : "In Workshop on Beyond Geometric Constraints at the International Conference on Robotics and Automation (ICRA),",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2015
    }, {
      "title" : "Inference on networks of mixtures for robust robot mapping",
      "author" : [ "Edwin Olson", "Pratik Agarwal" ],
      "venue" : "Intl. J. of Robotics Research,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2013
    }, {
      "title" : "The complexity of markov decision processes",
      "author" : [ "C. Papadimitriou", "J. Tsitsiklis" ],
      "venue" : "Mathematics of operations research,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1987
    }, {
      "title" : "Da-bsp: Towards data association aware belief space planning for robust active perception",
      "author" : [ "S. Pathak", "A. Thomas", "A. Feniger", "V. Indelman" ],
      "venue" : "In European Conference on Artificial Intelligence (ECAI),",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2016
    }, {
      "title" : "Towards data association aware belief space planning for robust active perception. In AI for Long-term Autonomy, workshop in conjunction with",
      "author" : [ "S. Pathak", "A. Thomas", "A. Feniger", "V. Indelman" ],
      "venue" : "IEEE International Conference on Robotics and Automation",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2016
    }, {
      "title" : "Scaling up gaussian belief space planning through covariance-free trajectory optimization and automatic differentiation",
      "author" : [ "S. Patil", "G. Kahn", "M. Laskey", "J. Schulman", "K. Goldberg", "P. Abbeel" ],
      "venue" : "In Intl. Workshop on the Algorithmic Foundations of Robotics,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2014
    }, {
      "title" : "Anytime point-based approximations for large pomdps",
      "author" : [ "J. Pineau", "G.J. Gordon", "S. Thrun" ],
      "venue" : "J. of Artificial Intelligence Research,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2006
    }, {
      "title" : "The belief roadmap: Efficient planning in belief space by factoring the covariance",
      "author" : [ "S. Prentice", "N. Roy" ],
      "venue" : "Intl. J. of Robotics Research,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2009
    }, {
      "title" : "An algorithm for tracking multiple targets",
      "author" : [ "D.B. Reid" ],
      "venue" : "IEEE Trans. Automat. Contr.,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1979
    }, {
      "title" : "Policy learning with hypothesis based local action selection",
      "author" : [ "Bharath Sankaran", "Jeannette Bohg", "Nathan Ratliff", "Stefan Schaal" ],
      "venue" : "arXiv preprint arXiv:1503.06375,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2015
    }, {
      "title" : "Information gain-based exploration using rao-blackwellized particle filters",
      "author" : [ "C. Stachniss", "G. Grisetti", "W. Burgard" ],
      "venue" : "In Robotics: Science and Systems (RSS),",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2005
    }, {
      "title" : "Towards a robust back-end for pose graph slam",
      "author" : [ "N. Sunderhauf", "P. Protzel" ],
      "venue" : "In IEEE Intl. Conf. on Robotics and Automation (ICRA),",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2012
    }, {
      "title" : "Motion planning under uncertainty using iterative local optimization in belief space",
      "author" : [ "J. Van Den Berg", "S. Patil", "R. Alterovitz" ],
      "venue" : "Intl. J. of Robotics Research,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2012
    }, {
      "title" : "The gaussian mixture probability hypothesis density filter",
      "author" : [ "Ba-Ngu Vo", "Wing-Kin Ma" ],
      "venue" : "Signal Processing, IEEE Transactions on,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2006
    }, {
      "title" : "Belief space planning for underwater cooperative localization",
      "author" : [ "Jeffrey M Walls", "Stephen M Chaves", "Enric Galceran", "Ryan M Eustice" ],
      "venue" : "In IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS),",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2015
    }, {
      "title" : "Data association for semantic world modeling from partial views",
      "author" : [ "L. Wong", "L. Kaelbling", "T. Lozano-Pérez" ],
      "venue" : "Intl. J. of Robotics Research,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "The corresponding problem is an instantiation of a partially observable Markov decision problem (POMDP) [16].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 21,
      "context" : "Calculating optimal solutions to POMDP is computationally intractable (PSPACEcomplete) [22] for all but the smallest problems.",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 18,
      "context" : "The vast research area of approximate approaches (with reduced computational complexity) can be roughly segmented into point-based value iteration methods [19, 26], simulation based [30] and sampling based approaches [2, 6, 27], and direct trajectory optimization [11, 25, 33] methods.",
      "startOffset" : 155,
      "endOffset" : 163
    }, {
      "referenceID" : 25,
      "context" : "The vast research area of approximate approaches (with reduced computational complexity) can be roughly segmented into point-based value iteration methods [19, 26], simulation based [30] and sampling based approaches [2, 6, 27], and direct trajectory optimization [11, 25, 33] methods.",
      "startOffset" : 155,
      "endOffset" : 163
    }, {
      "referenceID" : 29,
      "context" : "The vast research area of approximate approaches (with reduced computational complexity) can be roughly segmented into point-based value iteration methods [19, 26], simulation based [30] and sampling based approaches [2, 6, 27], and direct trajectory optimization [11, 25, 33] methods.",
      "startOffset" : 182,
      "endOffset" : 186
    }, {
      "referenceID" : 1,
      "context" : "The vast research area of approximate approaches (with reduced computational complexity) can be roughly segmented into point-based value iteration methods [19, 26], simulation based [30] and sampling based approaches [2, 6, 27], and direct trajectory optimization [11, 25, 33] methods.",
      "startOffset" : 217,
      "endOffset" : 227
    }, {
      "referenceID" : 5,
      "context" : "The vast research area of approximate approaches (with reduced computational complexity) can be roughly segmented into point-based value iteration methods [19, 26], simulation based [30] and sampling based approaches [2, 6, 27], and direct trajectory optimization [11, 25, 33] methods.",
      "startOffset" : 217,
      "endOffset" : 227
    }, {
      "referenceID" : 26,
      "context" : "The vast research area of approximate approaches (with reduced computational complexity) can be roughly segmented into point-based value iteration methods [19, 26], simulation based [30] and sampling based approaches [2, 6, 27], and direct trajectory optimization [11, 25, 33] methods.",
      "startOffset" : 217,
      "endOffset" : 227
    }, {
      "referenceID" : 10,
      "context" : "The vast research area of approximate approaches (with reduced computational complexity) can be roughly segmented into point-based value iteration methods [19, 26], simulation based [30] and sampling based approaches [2, 6, 27], and direct trajectory optimization [11, 25, 33] methods.",
      "startOffset" : 264,
      "endOffset" : 276
    }, {
      "referenceID" : 24,
      "context" : "The vast research area of approximate approaches (with reduced computational complexity) can be roughly segmented into point-based value iteration methods [19, 26], simulation based [30] and sampling based approaches [2, 6, 27], and direct trajectory optimization [11, 25, 33] methods.",
      "startOffset" : 264,
      "endOffset" : 276
    }, {
      "referenceID" : 31,
      "context" : "The vast research area of approximate approaches (with reduced computational complexity) can be roughly segmented into point-based value iteration methods [19, 26], simulation based [30] and sampling based approaches [2, 6, 27], and direct trajectory optimization [11, 25, 33] methods.",
      "startOffset" : 264,
      "endOffset" : 276
    }, {
      "referenceID" : 1,
      "context" : "[2, 27]), while assuming to correctly associate each future measurement with an appropriate landmark.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 26,
      "context" : "[2, 27]), while assuming to correctly associate each future measurement with an appropriate landmark.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 27,
      "context" : "In a slightly separate line of research, the approaches that study the issue were in the context of multiple hypothesis tracking(see [28] for earliest work on MHT) or more recently, of active robust perception.",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 14,
      "context" : "Both these approaches rely on passive and often nonparametric approaches, through various filtering techniques; we refer an interested reader to the book [15] and tutorial [3] for further details.",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 2,
      "context" : "Both these approaches rely on passive and often nonparametric approaches, through various filtering techniques; we refer an interested reader to the book [15] and tutorial [3] for further details.",
      "startOffset" : 172,
      "endOffset" : 175
    }, {
      "referenceID" : 32,
      "context" : "For example, [34] proposed using Gaussian mixture probability hypothesis density (PHD) filter.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 7,
      "context" : "a given map), recent works, including [8,9,11,18,35], relax this assumption and model the uncertainty of the environment mapped thus far within the belief.",
      "startOffset" : 38,
      "endOffset" : 52
    }, {
      "referenceID" : 8,
      "context" : "a given map), recent works, including [8,9,11,18,35], relax this assumption and model the uncertainty of the environment mapped thus far within the belief.",
      "startOffset" : 38,
      "endOffset" : 52
    }, {
      "referenceID" : 10,
      "context" : "a given map), recent works, including [8,9,11,18,35], relax this assumption and model the uncertainty of the environment mapped thus far within the belief.",
      "startOffset" : 38,
      "endOffset" : 52
    }, {
      "referenceID" : 17,
      "context" : "a given map), recent works, including [8,9,11,18,35], relax this assumption and model the uncertainty of the environment mapped thus far within the belief.",
      "startOffset" : 38,
      "endOffset" : 52
    }, {
      "referenceID" : 33,
      "context" : "a given map), recent works, including [8,9,11,18,35], relax this assumption and model the uncertainty of the environment mapped thus far within the belief.",
      "startOffset" : 38,
      "endOffset" : 52
    }, {
      "referenceID" : 8,
      "context" : "Recent work [9,11,18,35] in this branch focused in particular on probabilistically",
      "startOffset" : 12,
      "endOffset" : 24
    }, {
      "referenceID" : 10,
      "context" : "Recent work [9,11,18,35] in this branch focused in particular on probabilistically",
      "startOffset" : 12,
      "endOffset" : 24
    }, {
      "referenceID" : 17,
      "context" : "Recent work [9,11,18,35] in this branch focused in particular on probabilistically",
      "startOffset" : 12,
      "endOffset" : 24
    }, {
      "referenceID" : 33,
      "context" : "Recent work [9,11,18,35] in this branch focused in particular on probabilistically",
      "startOffset" : 12,
      "endOffset" : 24
    }, {
      "referenceID" : 6,
      "context" : "[7, 13, 14, 21, 31].",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 12,
      "context" : "[7, 13, 14, 21, 31].",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 13,
      "context" : "[7, 13, 14, 21, 31].",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 20,
      "context" : "[7, 13, 14, 21, 31].",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 30,
      "context" : "[7, 13, 14, 21, 31].",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 3,
      "context" : "Our approach is also tightly related with recent work on active hypothesis disambiguation in the context object detection and classification [4,20,29,32,36].",
      "startOffset" : 141,
      "endOffset" : 156
    }, {
      "referenceID" : 19,
      "context" : "Our approach is also tightly related with recent work on active hypothesis disambiguation in the context object detection and classification [4,20,29,32,36].",
      "startOffset" : 141,
      "endOffset" : 156
    }, {
      "referenceID" : 28,
      "context" : "Our approach is also tightly related with recent work on active hypothesis disambiguation in the context object detection and classification [4,20,29,32,36].",
      "startOffset" : 141,
      "endOffset" : 156
    }, {
      "referenceID" : 34,
      "context" : "Our approach is also tightly related with recent work on active hypothesis disambiguation in the context object detection and classification [4,20,29,32,36].",
      "startOffset" : 141,
      "endOffset" : 156
    }, {
      "referenceID" : 0,
      "context" : "[1], where the authors also consider hypotheses due to ambiguous data association and develop a BSP approach for active disambiguation.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 23,
      "context" : "Earlier versions of this paper appeared in [24] and [23].",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 22,
      "context" : "Earlier versions of this paper appeared in [24] and [23].",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 16,
      "context" : "[17].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12–14].",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 12,
      "context" : "[12–14].",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 13,
      "context" : "[12–14].",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 10,
      "context" : "[11,33].",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 31,
      "context" : "[11,33].",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 4,
      "context" : "[5].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 0,
      "context" : "f(x, u) = ( 1 0 0 1 ) · x+ d { [0, 1] if u = up [1, 0] if u = right ,",
      "startOffset" : 31,
      "endOffset" : 37
    }, {
      "referenceID" : 0,
      "context" : "f(x, u) = ( 1 0 0 1 ) · x+ d { [0, 1] if u = up [1, 0] if u = right ,",
      "startOffset" : 48,
      "endOffset" : 54
    }, {
      "referenceID" : 0,
      "context" : "To demonstrate generality of DA-BSP, we compared (in simulation) it with current state of the art (denoted as BSP) and the approach proposed in [1].",
      "startOffset" : 144,
      "endOffset" : 147
    }, {
      "referenceID" : 0,
      "context" : "The absence of pose uncertainty, which is the case in [1], would lead us to a wrong inference and estimate the robot to be at pose p1 (corridor 1) initially, whereas our approach which considers pose uncertainty will lead to correct inference with high weight for being in corridor 2 (Fig.",
      "startOffset" : 54,
      "endOffset" : 57
    }, {
      "referenceID" : 0,
      "context" : "4b)) for [1] (ηda = 0) since that approach does not model uncertainty within each of the GMM components.",
      "startOffset" : 9,
      "endOffset" : 12
    }, {
      "referenceID" : 0,
      "context" : "[1] plan -na- -na- -na- -nainfer -63.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "control and uncertainty cost) and DA-BSP similarly can not provide a global least cost path for full disambiguation - a problem known to be NP-hard [10].",
      "startOffset" : 148,
      "endOffset" : 152
    }, {
      "referenceID" : 1,
      "context" : "Additionally, proving the general theoretical properties of DA-BSP, such as probabilistic completeness under uncertainty along the lines proposed by [2], is another interesting direction of research.",
      "startOffset" : 149,
      "endOffset" : 152
    } ],
    "year" : 2016,
    "abstractText" : "We develop a belief space planning (BSP) approach that advances the state of the art by incorporating reasoning about data association (DA) within planning, while considering additional sources of uncertainty. Existing BSP approaches typically assume data association is given and perfect, an assumption that can be harder to justify while operating, in presence of localization uncertainty, in ambiguous and perceptually aliased environments. In contrast, our data association aware belief space planning (DA-BSP) approach explicitly reasons about DA within belief evolution, and as such can better accommodate these challenging real world scenarios. In particular, we show that due to perceptual aliasing, the posterior belief becomes a mixture of probability distribution functions, and design cost functions that measure the expected level of ambiguity and posterior uncertainty. Using these and standard costs (e.g. control penalty, distance to goal) within the objective function, yields a general framework that reliably represents action impact, and in particular, capable of active disambiguation. Our approach is thus applicable to robust active perception and autonomous navigation in perceptually aliased environments. We demonstrate key aspects in basic and realistic simulations.",
    "creator" : "LaTeX with hyperref package"
  }
}