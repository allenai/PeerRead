{
  "name" : "1701.08761.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "C3A: A Cognitive Collaborative Control Architecture For an Intelligent Wheelchair",
    "authors" : [ "Rupam Bhattacharyya", "Adity Saikia", "Shyamanta M Hazarika" ],
    "emails" : [ "rupam15@tezu.ernet.in", "rupam15@tezu.ernet.in" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Collaborative control, ROS, USARSim, 3D robotic simulator"
    }, {
      "heading" : "1. Introduction",
      "text" : "Recent progresses in the field of humanitarian robotics and automation technology has brought smiles to millions of people who suffer from cognitive and mobility impairment. In spite of tremendous progress in the area of intelligent assistive devices, intelligent wheelchairs are yet to be widely accepted. According to a survey consisting of 200 clinicians, greater than 50% of wheelchair users reported complaint with its control [23][5]. Further, persons who lose their cognitive/physical ability have to go through a rehearsal of their residual capability in a continuous manner. This prevents them from losing any further skill set and may rejuvenate them to acquire the lost abilities. For this reason, the assistance to human patient must be offered on need basis [15]. We aspire to offer a wheelchair which can be used by people having different levels of cognitive and/or physical impairment.\nA novel cognitive collaborative control architecture is presented in this paper. Collaboration is best explained by the following examples. Let us consider that a human patient is currently sitting on an intelligent wheelchair with robotic arms. Their shared goal is to lift the pen placed on the table. Suppose the human patient is active and moves near to the table; suddenly the human is no longer able to proceed further towards the goal. This situation is immediately traced by the robotic wheelchair and lifts\n*Corresponding author. E-mail: rupam15@tezu.ernet.in Tel.: +91-3712-275136 Fax: +91-3712-267005\n0000-0000/16/$00.00 c© 2016\nar X\niv :1\n70 1.\n08 76\n1v 1\n[ cs\n.R O\n] 3\n0 Ja\nthe pen from the table. For other type of collaboration, consider two persons are riding a tandem bicycle. If one person slows down, then other person has to put some extra effort to maintain the balance and to move on to the common destination. In both the examples, the adaptation is automatic because of which collaboration is so delightful and effective. The conceptual understanding of the two terms; namely “shared control\" and “collaborative control\" is essential for the readers to understand our architecture in a better way. Following conceptual definitions of the two terms provided by Urdiales [8] are considered as the standard one and the remaining section of this paper will follow these only. Shared control:\n“Situations where machines and persons cooperate to achieve a common goal fall within the field of shared control.”[8] Collaborative control:\n“Collaborative control is a specific type of shared control where there are no sharp control switches between person and machine. Furthermore, humans always retain some control and are rewarded with more when they perform better, yet receive more assistance when needed.”[8]\nThe remainder of the paper is organized as follows. In section 2, we discuss the human-robot co-operative approaches present in the literature and the requirements needed to design a cognitive agent. Section 3 describes C3A: a three layered cognitive collaborative control architecture. Section 4 is divided into three subsections; namely Evaluation Metrics, Experimental Set Up, and Experimentation. In simulation of our proposed architecture, we have used USARSim [35] and ROS [28]. P3AT robot is treated as our wheelchair which imbibes our architecture. This research work envisages the integration of USARSim/ROS to build a cognitive agent on top of C3A. Section 3 and Section 4 collectively gives an insight to the systematic approach of designing and implementing the whole system. Section 5 deals with performance of the whole system. Concluding remarks and future trend will be discussed in section 6."
    }, {
      "heading" : "2. Background",
      "text" : ""
    }, {
      "heading" : "2.1. Approaches related to human-robot co-operation",
      "text" : "Co-operation between human and robot addresses several relationships between them. As there is a considerable difference in users’ ability to control a wheelchair, the system’s contribution to control plays a significant role. According to [9], control approaches in which human and robots (or machine) jointly operate with each other to achieve a common destination can be classified into:\n• safeguarded operation and • shared control. In safeguarded operation, robots will be completely controlled by the user and robot occasionally takes over to avoid possible danger [9]. Table 1 will help the readers to understand the basic principle of a few well known shared control approaches for human-robot co-operation. It is difficult to discuss all these approaches and their differences with collaborative control. Two survey papers namely [24] and [1]; are good starting point to start research in human-robot co-operation/collaboration. From the discussion till now; collaborative control seems to be the best for rehabilitation of patients.\nUrdiales et. al. [9] can be considered as pioneer in collaborative control strategy for wheelchair. A number of smart wheelchairs - MAID, NavChair, TinMan and SmartChair use shared control [34]; differing\nonly in how behaviors are implemented. There are two intelligent wheelchair technologies namely Smile Rehab1 and TAO-7 Intelligent Wheelchair Base from AAI Canada2 which made the transition from the lab environment to the public and commercial sectors [40]. A common problem in most of these systems is that the man and the machine do not contribute to control simultaneously. Though see [9]; wherein this is overcome using a purely reactive navigation system [32]. Urdiales et. al. [9] report detailed clinical trails of their collaborative system based on reactive navigation. In [39], the collaborative controller uses a multiple-hypotheses method to continuously predicts the short-term goals of the user and calculates an associated confidence of the prediction.\nIt is observed that literature related to the stability analysis of wheelchair controllers based on shared control approaches is scarce. Novel techniques such as [41] and [42] can be a good starting point to undergo such an analysis. With the availability of brain computer interfaces (BCI), a wheelchair can be controlled through EEG signals [43]. Similar problem in a distributed environment has been studied in [44]."
    }, {
      "heading" : "2.2. Cognitive agent: requirement and design principle",
      "text" : "Embodiment of cognition within an intelligent agent will bolster human robot interaction [2]. To generate rational behaviour in any external environment, agent should be embedded with well established cognitive architecture like ACT-R [19] or SOAR [20]. The conceptual understanding behind a rational agent and its behaviour in our context is provided below: Rational agent: “A system that makes decisions by considering all possible actions and choosing the one that leads to the best expected outcome can be treated as rational agent.”[37] Rational behavior: Rational behavior in human-robot collaboration will be to assist the user whenever required and our cognitive agent help us to attain this behavior. However the selection of a particular cognitive architecture to tackle a distinct HCI problem is hugely difficult [30]. Our aim is to use a popular cognitive architecture and introduce within it certain novel features to effect collaboration as these architectures don’t have any module for collaboration per se. This certainly opens up the path of research in building a cognitive model incorporating collaboration into it. ACT-R has been utilized successfully to model higher-level cognition phenomena, such as memory, reasoning and skill acquisition [21]. This is the main reason that encourage us to incorporate the flavor of ACT-R into the C3A.\nTo imitate human cognition, cognitive agents can be constructed to act properly in changing environment. Throughout this paper, we have used cognitive agent, wheelchair and P3AT robot interchangeably. The cognitive agent can be defined as below [6]:\n• Functions incessantly and autonomously in an environment. • Able to accomplish activities in an adaptable and intelligent manner. • Responsive to modifications in the environment. • Proactive; exhibit goal-oriented and opportunistic behaviour. • Take the initiative when required. • Learn from experience.\n1http://www.smilesmart-tech.com/assistive-technology-products/smile-smart-wheelchair/ 2http://www.aai.ca/robots/tao_7.html\nThere must be some combination of the agent’s data structures and algorithms must reflect the knowledge it has about its surrounding environment [26]. Agent architectures can be divided into three broad categories based on [29]; we are interested in the reactive architecture which is defined to be the one that does not include any kind of central symbolic world model, and does not use complex symbolic reasoning [29]. A subsumption architecture [32] is a hierarchy of task-accomplishing behaviours which followed this alternative approach. Thus a compact collaborative control architecture with the flavor of ACT-R may be helpful in fulfilling a decent acceptance rate among users along with simultaneous control and need-based assistance."
    }, {
      "heading" : "3. C3A : Cognitive Collaborative Control Architecture",
      "text" : "The proposed cognitive collaborative control architecture is shown in Figure 1. It is inspired from the work [11] and adaptation of well established cognitive architecture, ACT-R [19]. C3A is a layered architecture with the following layers:\n• User Interface Layer, • Superior Control Layer and • Local Control Layer. The functionality of each layer and the inter dependence among them are described below."
    }, {
      "heading" : "3.1. User Interface Layer",
      "text" : "User has to interact with this layer for setting the shared goal in the environment. We have assumed that the user of our system is visually active. User Interface Layer helps the users to navigate the P3AT through the maze environment with the help of keyboard. This layer is utilized by the users for interacting with rest of the layers of C3A. The wheelchair will be used by people who have either physical disability or cognitive disability or both. So, it is essential for us to determine how much help the patient should be provided so that their residual skill remains intact. There are various effective tests to measure the current health status of the patient. In [9], they have conducted five tests to calculate the cognitive/physical disability score. The procedure followed by us to calculate the score can be found in the subsection 4.3. This score is stored in procedural memory of the memory module for future usage. Later on, the score is fed to the heuristic engine of the reactive module for further processing."
    }, {
      "heading" : "3.2. Superior Control Layer",
      "text" : "This layer is composed of two sub-modules;\n• Reactive Module and • Reactive Navigator."
    }, {
      "heading" : "3.2.1. Reactive Module",
      "text" : "This module is one of the important modules for proper functioning of the wheelchair. The reactive module comprises of the following:\n• Heuristic Engine, • Memory Module and\n• Interaction Layer. 1. Heuristic Engine The control architecture given in the Figure 1 is followed by both the machine and human. These type of architectures designed for rehabilitation of patients should consist of modules which corresponds to constant monitoring of local efficiencies of human/robot command or prediction of intention of human as a driver or measuring the physiological state of the human. A method has been proposed in [9] to calculate local efficiencies of human as well as robot. Similarly in [39], an approach for intention prediction is given. Heuristic engine utilize the score from procedural memory to produce\na priority configuration file. This file contains the priority of two modes of operation (human user and machine) of the P3AT robot. The users with low cognitive score should be allowed to drive the P3AT carefully. The intervention level of the system will be more and machine should take back the control from the user as and when required. On the other hand the system’s intervention is less while the P3AT is driven by users with high cognitive score.\nHeuristic engine uses shared goal location(i,j) and agent position(i,j) with respect to maze environment to produce a performance related metric called distance. This metric along with the priority configuration file will identify the quality of driving of the cognitive agent. The heuristic engine can guide us to model an effective collaborator.\n2. Memory Module\n• Procedural memory, • Episodic memory and • Semantic memory. One important design issue related to memory module is to identify which of the outputs of different modules will go into which memory structure. Clear distinction among different memory structures is given in [13].\na. Procedural memory It is concerned with how things are done [13]. In achieving a particular shared goal, it is indeed an inevitable memory structure which utilizes perception, cognitive and motor skills of the agent. State and action of agents in mobile robotics plays a vital role. Planning language help us to formalize the structure of states and actions. The states and actions of the cognitive agent will be included in procedural memory. The cognitive and physical ability score is another entry into this memory structure from the user interface layer.\nb. Episodic Memory It is concerned with the remembrance of personally experience event [13]. The human Wayfinding behaviour as explained in [4] follows different strategies to traverse the maze successfully. If we consider Central Point Strategy of [4], then there must be specific states and their corresponding sequence of actions that the agent tries to remember. Agent may also be interested in states and actions of two modes of operation; because in the middle of the simulation human users’ incapability allows the shifting of control to automated navigator of ROS.\nc. Semantic memory This memory structure will provide context i.e. from procedural memory it can collect certain states and actions and based on which semantic memory try to assign meaning to the current situation.\nOur future aim is to formalize the states and action of the cognitive agent. For the time being, the states are internal to ROS environment and actions of all the modules are the result of different packages concurrently executing. For successful functioning of the whole system, all packages are dependent on each other through the publisher-subscriber mechanism of ROS."
    }, {
      "heading" : "3. Interaction Layer",
      "text" : "This sub-module act like a communication backbone for entire architecture. It simultaneously interacts with the heuristic engine, memory module and reactive navigator. Thus we have two communication paths.\n• Heuristic Engine-Interaction Layer-Reactive Navigator • Memory Module-Interaction Layer-Reactive Navigator a. Heuristic Engine-Interaction Layer-Reactive Navigator: Heuristic Engine provides us the smart driver at any instant of time with the help of procedural memory. From the User Interface Layer(see Figure 1), procedural memory receives cognitive score (no label), goal location (label 3 of Figure 1) and agent position(label 6 of Figure 1). These three information is utilized by heuristic engine to constitute two metrics (explained in subsection 4.1) for choosing the smart driver. When the wheelchair is run for the first time, then interaction layer access these metrics from heuristic engine to invoke anyone of the two sub-modules of the reactive navigator. The communication path is described in table 2. With the help of heuristic engine, interaction layer have to dynamically track\nwhich component of the reactive navigator has to be invoked. So, interaction layer also communicates with the memory module for states and action sequences (label 1 from Figure 1) along with the agent position(label 6 of Figure 1).\nb. Memory Module-Interaction Layer-Reactive Navigator This communication path is described through table 3 and table 4. Table 3 focuses on the communication happening between interaction layer and automated navigator(mostly reactive navigator). On the other hand, table 4 focuses on the communication happening between memory module and interaction layer. Most of the labels (label 6, 4, 3, 2, 1) on the C3A (Figure 1) have already been explained in the previous communication path.\nThe physical interaction through the User Interface Layer(see Figure 1) leads to change in various parameters shown through different labels in the C3A. Thus, it is the responsibility of the interaction layer to be aware of such kind changes in the simulation environment. Labels 7 and 5 (of Figure 1) represents the storage and retrieval of the specific states and action sequences of the agent which corresponds to\nspecific event in episodic memory of the memory module respectively. This happens through the interaction layer and implementation related to episodic memory is kept as future work."
    }, {
      "heading" : "3.2.2. Reactive Navigator",
      "text" : "Before building a reactive navigator, system designer needs to be very focused in the speed sensitive parts of the cognitive architecture. In, improving the speed sensitive information, ROS introduces a new\nconcept called “nodelets\" which helps us to build reactive controller. These are almost similar to conventional nodes but lots of important features are embedded into it. Reactive navigator is composed of two sub-modules which is part of ROS control framework:\n• Automated Navigator of ROS and • Patient as Driver. a. Automated Navigator of ROS: ROS is composed of number of complex tools and libraries. Incorporation of details about automated\nnavigator will make the architecture shown in figure 1 clumsy. Our motivation is that the complexity of ROS should not dominate the understanding of our control architecture.The automated navigator of ROS is the machine in our approach.\nPlanning is essential for guiding the agent autonomously without causing any harm. Global planner is related to creating long term plans over the entire environment [31] and it takes input from global costmap as shown in figure 3. Local planner is mainly used for obstacle avoidance which uses Local costmap. The costmap_2d package of ROS provides a structure which is configurable. This package maintains information about where should the robot navigate in the form of an occupancy grid [12]. Thus global planner and local planner with the information of pose estimate from AMCL (Adaptive Monte Carlo Localization) and obstacle information from costmap can plan effectively to reach the shared goal. The sensor data (in our case SICK LMS200) may be utilized in building both the costmaps.\nThe text that is written in communication lines (shown in figure 3) will reflect the key functionality of individual sub modules. Figure 2 describes the communication between Reactive Navigator and Local Control Layer. It depicts the communication involved in implementing our architecture integrating\nUSARSim and ROS control framework. It will help the reader to understand the C3A in a better way. Figure 3 describes the internal message passing between sub- modules of Automated Navigator of ROS. This figure gives detailed understanding of the how the agent can move autonomously.\nThe functionality of Automated navigator of ROS is achieved through a ROS node called move_base. This node is customized to modify the reactive behaviour (figure 3) ; so that collaboration can be achieved. b. Patient as Driver:\nThis sub module uses ROS tele-operation to move around the maze environment through the keyboard. The ROS node is teleop_twist_keyboard [36] and corresponds to the package brown_remotelab [7]."
    }, {
      "heading" : "3.3. Local Control Layer",
      "text" : "This layer corresponds to the 3D USARSim simulator where both the P3AT robot and maze environment co-exist simultaneously. P3AT robot uses SICK LMS200 laser range finder. It can be augmented with many other sensors. This sensor is an integral part of local control layer. All the actuators are also part of this layer. Whenever the agent is tested in real time environment, then we need a real time wheelchair. All the sensors, actuators and other hardware related aspects present in P3AT must be embedded inside the real time wheelchair."
    }, {
      "heading" : "4. Simulation",
      "text" : ""
    }, {
      "heading" : "4.1. Evaluation Metrics",
      "text" : "There are lots of metrics [3] are suggested to test the performance of human-robot application. For experimental evaluation of the collaborative control of the P3AT robot, two types of metrics are considered.\n• Condition related metric and • Performance related metric. Condition related metric It determines the cognitive status of the user of the wheelchair. This score leads to a priority configuration file. The ROS node, Cognitive_Score [see Table5] designed by us deals with the computation of this metric. Performance related metric This metric is related to effective collaboration and finding out the efficiency of the agent while driving the P3AT. Agent drives the P3AT under two explicit modes of operation namely,\n• teleoperation (human is controlling the P3AT through keyboard) and • Machine (Automated Navigator of ROS drives the P3AT). Implicitly collaborative mode is enforced as discussed below.\nDistance between the current position of the P3AT and shared goal location with respect to the maze environment is selected as the performance metric. This distance is dynamically calculated. The Velocity_multiplexer node and move_base node [see Table5] are customized in such a way that the condition related metric along with performance related metric gives an effective way for the human to collaborate smoothly with its machine counterpart.\nThe system behaviour can be understood by considering two scenarios. Scenario: 1 Suppose, human is controlling the P3AT and the metric indicates that P3AT is moving away from the goal. In this situation, as soon as human pauses (releases the keyboard) for a moment, then MACHINE instantly takes over the Control of P3AT. We are considering implicit communication without prior coordination. There is no explicit consensus between the two parties, but system treats this whole scenario as a situation where assistance is required. Users can always take back the control from machine whenever it is desired to do so. Thus, human is not kept away from the control loop of the system. Our aim is to allow user to utilize their own motor and cognitive skills. Scenario: 2 Let us say, currently wheelchair is driven by human. Suppose the metric indicates that distance is reducing towards goal which indirectly tells about the good driving skills of the driver. So, right now even if human pauses for a moment, then MACHINE won’t be able to take over the Control.\nThe behaviour of above two scenarios will be same when machine is considered to drive the robot. A Finite State Machine (FSM) is shown in figure 4 which will help the readers to understand the flow of the entire architecture. Figure 5 can be used to describe the two scenarios involving collaboration. Circles marked in figure 5 are the important zones. Pink cursor in Circle A shows the shared goal, the P3AT robot can be seen as the box outlined with light green boundary. Circle A is the area where human is driving the robot well; this represent the Scenario 2 described above.\nCircle B and Circle C represent area where human is moving away from the shared goal. In such a situation, MACHINE takes over the control of the P3AT robot. MACHINE corrects the erratic driving behaviour of the human by taking over the control of the robot. Scenario 1 is visualized through these circles."
    }, {
      "heading" : "4.2. Experimental Set Up",
      "text" : "The experimental simulation set up is shown in figure 6. To start the services of different ROS nodes, a universal launch file is created. Simulation starts from a “form fill-up\" process by the user. It is followed by launching the testing arena which is the maze environment. This maze is designed using “Unreal Development Kit\" which is embedded inside USARSim simulator. The same maze is utilized for testing all the participants. Except for the testing arena, every other utility is provided through ROS nodes. Table 5 gives a detailed specification of the functionality of different ROS nodes and their correspondence with\nC3A. Experimentation can start only after all nodes mentioned in table 5 functions properly3.\n3Interested readers can access https://drive.google.com/file/d/0BwgHQRnAyRbgWXhhdWxlN0ctU0k/view?usp=sharing to preview the snapshot of our whole system (the graph of the whole simulation when all ROS nodes are correctly running) in a successful scenario.\nThe initial launching location of P3AT robot is same for all the participants. The term “shared goal\" is vital for any collaborative system. We have assumed that the user can clearly locate the shared goal through the User Interface Layer. In this simulation, users can set a goal via ‘rviz’ window through mouse-click/touch-pad over 2D map generated through SLAM module. The “shared goal\" is fixed in a corner of the maze for all participants. The ‘rviz’ package acts as visualisation tool for the ROS. So, in case of our C3A, the goal is universal; both machine and human can rely on it."
    }, {
      "heading" : "4.3. Experimentation",
      "text" : "The cognitive collaborative control architecture is evaluated for its effectiveness by comparing the manoeuvring time (total time required from start to goal) under the following modes. 1. human(standalone mode), 2. machine (standalone mode) and 3. collaborative control mode. The cognitive score of the subjects is based on the questionnaire from the table 6. Questions are adapted from standard papers Instrumental activities of daily living (IADL)[27] and Folstein test or mini-mental state examination (MMSE)[33]. The questionnaire can be used as an instrument for analyzing the participants in a short period of time. Six subjects are taken in random. Each of them is made to go through the questionnaire; cognitive score is evaluated. There are two groups of people; group A having high cognitive score (HCS) and group B with low cognitive score (LCS). Four subjects belong to group A, as their cognitive score is more than five. Two persons belong to group B; as they score less than five. Table 7 shows the profile of six sub-\njects that test our simulation. All the subjects are given three minutes to memorize/learn the navigation\ncommands and setting of global shared goal. Subjects are told about their task to be completed in the\nsimulated environment."
    }, {
      "heading" : "5. Results",
      "text" : "Figure 7 reports the manoeuvring time (in seconds) required by all the six subjects to reach the prespecified goal. All the three modes described in subsection 4.3 are shown in the figure 7. Machine time for different runs is different. This is because of the way the machine navigates and users has nothing to do with this. The machine in our case is the automated navigator of ROS. This navigator generates different recovery behavior based on dynamic construction of Costmap. Costmap is built using the laser scans obtained from SICK LMS200 laser range finder. A single laser scan might not arrive in the same time window between two sets of experiment leading to a different Costmap and thus behavior. The performance of the collaborative mode versus the human user (standalone mode) is compared to evaluate the system. The autonomous navigation of ROS is highly configurable, making possible to use a large number of algorithms. The driving behavior of different users will be different if there are no traffic rules. In our maze, there is no driving rule to go to the shared goal. Thus, in two different trials, the user commands will leave the whole system in two different situations. Thus, the planners inside the move_base node acts differently which gives rise to different completion time in collaborative control mode.\nAs expected the time taken by the human to reach a particular goal is more as compared to driving the P3AT in collaborative mode. All the LCS group i.e. group B participants’ benefits from the C3A. Similar trend can be observed in most of the participants of the HCS group i.e. group A participants’. Note that an exception occurred in case of subject_4. Users were observed during simulation and subjective estimation done. As seen from Table 7, subject_4 is less attentive and fails to memorize the navigation commands properly; can not relate them to arrow keys. Even though, this subject is from HCS group; its driving is erratic and frequently moves the robot away from the shared goal. Machine requires more time to make corrections to bring the robot on-course, leading to increase in manoeuvring time under collaboration.\nOur architecture is not yet implemented in a real wheelchair. A differential model of the wheelchair has to be created inside USARSim to replace the P3AT robot. Several real robots works successfully by\nusing ROS which encourage us to believe that this initial simulation result is a good starting point to build a real one. The generalizable nature of our findings is an important issue to discuss here. Our claim is not to prove the generalized nature of our simulation result on different types of wheelchair users. This initial research should be viewed as a new way to achieve the collaborative control by exploiting the open Source research platform, ROS."
    }, {
      "heading" : "6. Final Comments",
      "text" : "Robust real-world behavior can not be pre-programmed. ROS overcomes this limitation because of its sound message passing and shared memory concept. The wheelchair control imbibing C3A is aware of its location, driver quality along with other environmental facts such as proximity towards the shared goal through the memory module. The navigation commands from user and the wheelchair are simultaneously active through ROS topic. Assistive wheelchair with collaborative control is achieved by C3A through ROS is an approach of embodiment of cognition. ROS contains all the required features to build an effective collaborative device.\nThe limitation of our approach are mentioned below:\n– Our initial result with six participants is used to show that our approach has some positive directions. Rigorous testing with more users are possible; once we implement the whole memory module. In our future work, we try to incorporate more evaluation metric and rigorous statistical analysis to improve our approach towards collaborative control. – For simulation reported in this paper, the user has to be visually active to set the shared goal and have motor control to operate the keys.\nThe novelty of the paper is the development of C3A and the functionality of ROS is effectively utilised to analyze the utility of collaborative control. This approach for designing cognitively enabled wheelchair introduces several new research avenues within the ROS environment. Instead of using autonomous navigator of ROS, agent can be programmed to use a planner designed using formal methods. Several researchers are working on EEG (electroencephalogram) based brain-actuated wheelchair system using motor imagery. Overcoming the above mentioned limitations by extending ROS is part of our ongoing research. Controlling the wheelchair through EEG is our future goal."
    } ],
    "references" : [ {
      "title" : "Human-robot collaboration: a survey",
      "author" : [ "A. Bauer", "D. Wollherr", "M. Buss" ],
      "venue" : "in: International Journal of Humanoid Robotics, 5(01)",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Using computational cognitive models to build better human-robot interaction, in: NAE US",
      "author" : [ "A. C . Schultz" ],
      "venue" : "FOE Symposium,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2006
    }, {
      "title" : "Common metrics for human-robot interaction",
      "author" : [ "A. Steinfeld", "T. Fong", "D. Kaber", "M. Lewis", "J. Scholtz", "A. Schultz", "M. Goodrich" ],
      "venue" : "in: Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-robot Interaction (HRI ’06), New York, USA",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Solving a Maze: Experimental Exploration on Wayfinding Behaviour for Cognitively Enhanced Collaborative Control",
      "author" : [ "A. Saikia", "S.M. Hazarika" ],
      "venue" : "in: Intelligent Interactive Technologies and Multimedia, Springer Berlin Heidelberg",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Machine Learning for Shared Control with Assistive Machines, in: Proceedings of ICRA Workshop on Autonomous Learning: From Machine Learning to Learning in Real world",
      "author" : [ "B.D. Argall" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2013
    }, {
      "title" : "T",
      "author" : [ "C. Crick" ],
      "venue" : "Jay and S. Osentoski",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "From shared control to collaborative navigation",
      "author" : [ "C. Urdiales" ],
      "venue" : "in: Collaborative Assistive Robot for Mobility Enhancement (CARMEN), volume 27 of Intelligent Systems Reference Library, Springer Berlin Heidelberg",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Wheelchair collaborative control for disabled users navigating indoors",
      "author" : [ "C. Urdiales" ],
      "venue" : "in: Artif. Intell. Med,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "Designing an architecture for adjustably autonomous robot teams",
      "author" : [ "D. Kortenkamp" ],
      "venue" : "in: R. Kowalczyk, S. Loke, N. Reed, and G. Williams, editors, Advances in Artificial Intelligence, PRICAI 2000 Workshop Reader, volume 2112 of Lecture Notes in Computer Science, Springer Berlin Heidelberg",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "move_base - ROS Wiki. [online] Wiki.ros.org. Retrieved from: http://wiki.ros.org/move_base",
      "author" : [ "E. Marder-Eppstein" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2012
    }, {
      "title" : "costmap_2d - ROS Wiki. [online] Wiki.ros.org. Retrieved from: http://wiki.ros.org/costmap_2d",
      "author" : [ "E. Marder Eppstein" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2010
    }, {
      "title" : "Memory and consciousness, in: Canadian Psychology/Psychologie canadienne",
      "author" : [ "E. Tulving" ],
      "venue" : "Jan 1985,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1985
    }, {
      "title" : "Results in sliding autonomy for multi-robot spatial assembly",
      "author" : [ "F. Heger", "L. Hiatt", "B. Sellner", "R. Simmons", "S. Singh" ],
      "venue" : "in: 8th International Symposium on Artificial Intelligence, Robotics and Automation in Space (iSAIRAS)",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Prevention and rehabilitation of stroke",
      "author" : [ "G.E. Gresham" ],
      "venue" : "in: Stroke,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1997
    }, {
      "title" : "and N",
      "author" : [ "J.A. Adams", "P. Rani" ],
      "venue" : "Sarkar ",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Preliminary results in sliding autonomy for coordinated teams",
      "author" : [ "J. Brookshire", "S. Singh", "R. Simmons" ],
      "venue" : "in: Proceedings of The 2004 Spring Symposium Series",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Mixed-initiative interaction",
      "author" : [ "J.E. Allen", "C. Guinn" ],
      "venue" : "in: Intelligent Systems and their Applications, IEEE, 14(5)",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "The Newell test for a theory of cognition.",
      "author" : [ "J.R. Anderson", "C. Lebiere" ],
      "venue" : "in: Behavioral and brain Sciences,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2003
    }, {
      "title" : "Soar: An architecture for general intelligence",
      "author" : [ "J. Laird", "A. Newell", "P. Rosenbloom" ],
      "venue" : "in: Artificial Intelligence, 33 ",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1987
    }, {
      "title" : "ACT-R Frequently Asked Questions List. [online] Acs.ist.psu.edu",
      "author" : [ "J.W. Kim", "F. .E. Ritter" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    }, {
      "title" : "An agent-based architecture for an adaptive human-robot interface",
      "author" : [ "K. Kawamura", "P. Nilas", "K. Muguruma", "J. Adams", "C. Zhou" ],
      "venue" : "in: Proceedings of the 36th Annual Hawaii International Conference on System Sciences",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Adequacy of power wheelchair control interfaces for persons with severe disabilities : A clinical survey",
      "author" : [ "L. Fehr", "W.E. Langbein", "S.B. Skaar" ],
      "venue" : "in: Journal of Rehabilitation Research and Development, 37(3)",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Human-robot interaction: a survey",
      "author" : [ "M.A. Goodrich", "A.C. Schultz" ],
      "venue" : "in: Foundations and trends in human-computer interaction, 1(3)",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "B",
      "author" : [ "M. Johnson", "J.M. Bradshaw", "P.J. Feltovich", "C.M. Jonker" ],
      "venue" : "van Riemsdijk, and M. Sierhuis, The fundamental principle of coactive design: interdependence must shape autonomy, in: Coordination, Organizations, Institutions, and Norms in Agent Systems VI, Springer Berlin Heidelberg",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Cognitive agents",
      "author" : [ "M.N. Huhns", "M.P. Singh" ],
      "venue" : "IEEE, in: Internet Comput., November/December ",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Assessment of older people: self-maintaining and instrumental activities of daily living",
      "author" : [ "M. Lawton", "E. Brody" ],
      "venue" : "in: Gerontologist, 9",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 1969
    }, {
      "title" : "ROS: an open-source Robot Operating System",
      "author" : [ "M. Quigley" ],
      "venue" : "in: ICRA workshop on open source software,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2009
    }, {
      "title" : "Agent Theories",
      "author" : [ "M. Wooldridge", "N.R. Jennings" ],
      "venue" : "Architectures, and Languages: a Survey, in Wooldridge and Jennings eds., Intelligent Agents, Springer-Verlag",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "An adaptive architecture for physical agents",
      "author" : [ "P. Langley" ],
      "venue" : "in: Proc. IEEE/WIC/ACM Int. Conf. Intell. Agent Technol., Compiegne, France",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Navigation/Tutorials/Robotsetup-ROS Wiki, [online] Wiki.ros.org. Retrieved from: http://wiki.ros.org/navigation/Tutorials/RobotSetup",
      "author" : [ "P. Yoonseok" ],
      "venue" : null,
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2014
    }, {
      "title" : "A robust layered control system for a mobile robot",
      "author" : [ "R.A. Brooks" ],
      "venue" : "in: IEEE Journal of Robotics and Automation,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 1986
    }, {
      "title" : "Smart wheelchairs: A literature review",
      "author" : [ "R. Simpson" ],
      "venue" : "in: J. Rehabil. Res. Dev.,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2005
    }, {
      "title" : "USARSim. [online] SourceForge. Retrieved from: http://sourceforge.net/projects/usarsim",
      "author" : [ "S. Balakirsky" ],
      "venue" : null,
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2013
    }, {
      "title" : "USARSim/ROS: A Combined Framework for Robotic Control and Simulation",
      "author" : [ "S.B. Balakirsky", "Z. Kootbally" ],
      "venue" : "in: Proceedings of the ASME 2012 International Symposium on Flexible Automation ",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Artificial Intelligence",
      "author" : [ "S.J. Russell", "P. Norvig" ],
      "venue" : "Englewood Cliffs, N.J.: Prentice Hall",
      "citeRegEx" : "37",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Using symbiotic relationships with humans to help robots overcome limitations",
      "author" : [ "S. Rosenthal", "M. Veloso" ],
      "venue" : "in: Workshop for Collaborative Human/AI Control for Interactive Experiences",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Collaborative control mechanisms for an intelligent robotic wheelchair",
      "author" : [ "T.E. Carlson" ],
      "venue" : "Ph.D. Dissertation, Imperial College London (University of London)",
      "citeRegEx" : "39",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Modular and adaptive wheelchair automation",
      "author" : [ "B.D. Argall" ],
      "venue" : "in: Experimental Robotics, Springer International Publishing",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Stability analysis of a class of hybrid stochastic retarded systems under asynchronous switching",
      "author" : [ "Y. Kang" ],
      "venue" : "in: IEEE Transactions on Automatic Control,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2014
    }, {
      "title" : "On Input-to-State Stability of Switched Stochastic Nonlinear Systems Under Extended Asynchronous Switching",
      "author" : [ "Y. Kang" ],
      "venue" : "in: IEEE transactions on cybernetics,",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2016
    }, {
      "title" : "Control of a Wheelchair in an Indoor Environment Based on a BrainâĂŞComputer Interface and Automated Navigation",
      "author" : [ "R. Zhang" ],
      "venue" : "in: IEEE transactions on neural systems and rehabilitation engineering,",
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 2016
    }, {
      "title" : "Analyzing electroencephalograms using cloud computing techniques",
      "author" : [ "K. Ericson", "S. Pallickara", "C.W. Anderson" ],
      "venue" : "in: Proceedings of the Second (IEEE) International Conference on Cloud Computing Technology and Science (CloudCom), USA",
      "citeRegEx" : "44",
      "shortCiteRegEx" : null,
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "According to a survey consisting of 200 clinicians, greater than 50% of wheelchair users reported complaint with its control [23][5].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 4,
      "context" : "According to a survey consisting of 200 clinicians, greater than 50% of wheelchair users reported complaint with its control [23][5].",
      "startOffset" : 129,
      "endOffset" : 132
    }, {
      "referenceID" : 13,
      "context" : "For this reason, the assistance to human patient must be offered on need basis [15].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 6,
      "context" : "Following conceptual definitions of the two terms provided by Urdiales [8] are considered as the standard one and the remaining section of this paper will follow these only.",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 6,
      "context" : "”[8] Collaborative control: “Collaborative control is a specific type of shared control where there are no sharp control switches between person and machine.",
      "startOffset" : 1,
      "endOffset" : 4
    }, {
      "referenceID" : 6,
      "context" : "”[8]",
      "startOffset" : 1,
      "endOffset" : 4
    }, {
      "referenceID" : 32,
      "context" : "In simulation of our proposed architecture, we have used USARSim [35] and ROS [28].",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 26,
      "context" : "In simulation of our proposed architecture, we have used USARSim [35] and ROS [28].",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 7,
      "context" : "According to [9], control approaches in which human and robots (or machine) jointly operate with each other to achieve a common destination can be classified into:",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 7,
      "context" : "In safeguarded operation, robots will be completely controlled by the user and robot occasionally takes over to avoid possible danger [9].",
      "startOffset" : 134,
      "endOffset" : 137
    }, {
      "referenceID" : 22,
      "context" : "Two survey papers namely [24] and [1]; are good starting point to start research in human-robot co-operation/collaboration.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 0,
      "context" : "Two survey papers namely [24] and [1]; are good starting point to start research in human-robot co-operation/collaboration.",
      "startOffset" : 34,
      "endOffset" : 37
    }, {
      "referenceID" : 7,
      "context" : "[9] can be considered as pioneer in collaborative control strategy for wheelchair.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 31,
      "context" : "A number of smart wheelchairs - MAID, NavChair, TinMan and SmartChair use shared control [34]; differing",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 20,
      "context" : "Supervisory control It is described as the concept in which control is performed by an intelligent controller under the supervision of a human instead of the human performing direct manual control [22].",
      "startOffset" : 197,
      "endOffset" : 201
    }, {
      "referenceID" : 8,
      "context" : "Adjustable autonomy Enable the individual robots to act fairly independently of one another, while still allowing for tight, precise coordination when necessary [10].",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 15,
      "context" : "The autonomous system is given the ability to ask for human assistance[17] [14].",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 12,
      "context" : "The autonomous system is given the ability to ask for human assistance[17] [14].",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 35,
      "context" : "Symbiotic relationship The robot accomplishes tasks for humans and ask for help only to finish the task perfectly [38].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 16,
      "context" : "Mixedinitiative interaction(MII) Mixed-initiative interaction lets agents work most effectively as a team and agents dynamically adapt their interaction style to best address the problem at hand [18].",
      "startOffset" : 195,
      "endOffset" : 199
    }, {
      "referenceID" : 14,
      "context" : "In [16], a humanrobot collaborative architecture is built using the MII approach.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 23,
      "context" : "The fundamental principle of Coactive Design recognizes that the underlying interdependence of participants in joint activity is a critical factor in the design of human -agent systems[25].",
      "startOffset" : 184,
      "endOffset" : 188
    }, {
      "referenceID" : 37,
      "context" : "There are two intelligent wheelchair technologies namely Smile Rehab1 and TAO-7 Intelligent Wheelchair Base from AAI Canada2 which made the transition from the lab environment to the public and commercial sectors [40].",
      "startOffset" : 213,
      "endOffset" : 217
    }, {
      "referenceID" : 7,
      "context" : "Though see [9]; wherein this is overcome using a purely reactive navigation system [32].",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 30,
      "context" : "Though see [9]; wherein this is overcome using a purely reactive navigation system [32].",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 7,
      "context" : "[9] report detailed clinical trails of their collaborative system based on reactive navigation.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 36,
      "context" : "In [39], the collaborative controller uses a multiple-hypotheses method to continuously predicts the short-term goals of the user and calculates an associated confidence of the prediction.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 38,
      "context" : "Novel techniques such as [41] and [42] can be a good starting point to undergo such an analysis.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 39,
      "context" : "Novel techniques such as [41] and [42] can be a good starting point to undergo such an analysis.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 40,
      "context" : "With the availability of brain computer interfaces (BCI), a wheelchair can be controlled through EEG signals [43].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 41,
      "context" : "Similar problem in a distributed environment has been studied in [44].",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 1,
      "context" : "Embodiment of cognition within an intelligent agent will bolster human robot interaction [2].",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 17,
      "context" : "To generate rational behaviour in any external environment, agent should be embedded with well established cognitive architecture like ACT-R [19] or SOAR [20].",
      "startOffset" : 141,
      "endOffset" : 145
    }, {
      "referenceID" : 18,
      "context" : "To generate rational behaviour in any external environment, agent should be embedded with well established cognitive architecture like ACT-R [19] or SOAR [20].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 34,
      "context" : "”[37] Rational behavior: Rational behavior in human-robot collaboration will be to assist the user whenever required and our cognitive agent help us to attain this behavior.",
      "startOffset" : 1,
      "endOffset" : 5
    }, {
      "referenceID" : 28,
      "context" : "However the selection of a particular cognitive architecture to tackle a distinct HCI problem is hugely difficult [30].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 19,
      "context" : "ACT-R has been utilized successfully to model higher-level cognition phenomena, such as memory, reasoning and skill acquisition [21].",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 24,
      "context" : "There must be some combination of the agent’s data structures and algorithms must reflect the knowledge it has about its surrounding environment [26].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 27,
      "context" : "Agent architectures can be divided into three broad categories based on [29]; we are interested in the reactive architecture which is defined to be the one that does not include any kind of central symbolic world model, and does not use complex symbolic reasoning [29].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 27,
      "context" : "Agent architectures can be divided into three broad categories based on [29]; we are interested in the reactive architecture which is defined to be the one that does not include any kind of central symbolic world model, and does not use complex symbolic reasoning [29].",
      "startOffset" : 264,
      "endOffset" : 268
    }, {
      "referenceID" : 30,
      "context" : "A subsumption architecture [32] is a hierarchy of task-accomplishing behaviours which followed this alternative approach.",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 9,
      "context" : "It is inspired from the work [11] and adaptation of well established cognitive architecture, ACT-R [19].",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 17,
      "context" : "It is inspired from the work [11] and adaptation of well established cognitive architecture, ACT-R [19].",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 7,
      "context" : "In [9], they have conducted five tests to calculate the cognitive/physical disability score.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 7,
      "context" : "A method has been proposed in [9] to calculate local efficiencies of human as well as robot.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 36,
      "context" : "Similarly in [39], an approach for intention prediction is given.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 11,
      "context" : "Clear distinction among different memory structures is given in [13].",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 11,
      "context" : "Procedural memory It is concerned with how things are done [13].",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 11,
      "context" : "Episodic Memory It is concerned with the remembrance of personally experience event [13].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 3,
      "context" : "The human Wayfinding behaviour as explained in [4] follows different strategies to traverse the maze successfully.",
      "startOffset" : 47,
      "endOffset" : 50
    }, {
      "referenceID" : 3,
      "context" : "If we consider Central Point Strategy of [4], then there must be specific states and their corresponding sequence of actions that the agent tries to remember.",
      "startOffset" : 41,
      "endOffset" : 44
    }, {
      "referenceID" : 29,
      "context" : "Global planner is related to creating long term plans over the entire environment [31] and it takes input from global costmap as shown in figure 3.",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 10,
      "context" : "This package maintains information about where should the robot navigate in the form of an occupancy grid [12].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 33,
      "context" : "The ROS node is teleop_twist_keyboard [36] and corresponds to the package brown_remotelab [7].",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 5,
      "context" : "The ROS node is teleop_twist_keyboard [36] and corresponds to the package brown_remotelab [7].",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 2,
      "context" : "There are lots of metrics [3] are suggested to test the performance of human-robot application.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 25,
      "context" : "Questions are adapted from standard papers Instrumental activities of daily living (IADL)[27] and Folstein test or mini-mental state examination (MMSE)[33].",
      "startOffset" : 89,
      "endOffset" : 93
    } ],
    "year" : 2017,
    "abstractText" : "Retention of residual skills for persons who partially lose their cognitive or physical ability is of utmost importance. Research is focused on developing systems that provide need-based assistance for retention of such residual skills. This paper describes a novel cognitive collaborative control architecture CA, designed to address the challenges of developing needbased assistance for wheelchair navigation. Organization of CA is detailed and results from simulation of the proposed architecture is presented. For simulation of our proposed architecture, we have used ROS (Robot Operating System) as a control framework and a 3D robotic simulator called USARSim (Unified System for Automation and Robot Simulation).",
    "creator" : "LaTeX with hyperref package"
  }
}