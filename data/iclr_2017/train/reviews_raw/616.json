{"conference": "ICLR 2017 conference submission", "title": "Inverse Problems in Computer Vision using  Adversarial  Imagination Priors", "abstract": "Given an image,  humans  effortlessly run the image formation process backwards in their minds: they can tell albedo from shading,  foreground from background, and imagine the occluded parts of the scene behind foreground objects. In this work, we propose a weakly supervised inversion machine trained to generate similar imaginations that when rendered using differentiable, graphics-like decoders, produce the original visual input. We constrain the imagination spaces by providing exemplar memory repositories in the form of foreground segmented objects, albedo, shading, background scenes and imposing adversarial losses on the imagination spaces. Our model learns to perform such inversion with weak supervision, without ever having seen paired annotated data, that is, without having seen the image paired with the corresponding ground-truth imaginations. We demonstrate our method by applying it to three  Computer Vision tasks: image in-painting, intrinsic decomposition and object segmentation, each task having its own differentiable renderer.  Data driven adversarial imagination priors  effectively guide inversion,  minimize the need for hand designed priors of smoothness or good continuation, or the need for paired annotated data.", "reviews": [{"is_meta_review": true, "comments": "The paper describes a network architecture for inverse problems in computer vision. Example inverse problems considered are image inpainting, computing intrinsic image decomposition and foreground/background separation.\nThe architecture is composed of (i) a generator that produces target (latent) output (such as foreground / background regions), \n(ii) renderer that composes that latent output back to the image that can be compared with the input to measure reconstruction error, \nand (iii) adversarial prior that ensures the target output (latent) image respects a certain image statistics.\n\nStrong  points.\n- The proposed architecture with memory database is interesting and appears to be novel. \n\nWeak points:\n- Experimental results are only proof-of-concept in toy set-ups and do not clearly demonstrate benefits of the proposed architecture.\n- It is unclear whether the memory retrieval engine that retrieves images based on L2 distance on pixel values is going generalize to other more realistic scenarios. \n- Clarity. The clarity of explanation can be also improved (see below).\n\n\nDetailed evaluation.\n\nOriginality:\n- The novelty of this work lies in the (iii) adversarial prior that places an adversarial loss between the generated latent output and a single image retrieved from a large unlabelled database of target output examples (called memory). The adversarial prior has a convolutional form matching local image statistics, rather than the entire image.  The particular form of network architecture with the memory-based fully convolutional adversarial loss appears to be novel and potentially interesting.\n\n- Motivation for the Architecture. The weakest point of the proposed architecture is the \"Memory retrieval engine\" R (section 2.4),\nwhere images are retrieved from the memory by measuring L2 distance on pixel intensities. While this maybe ok for simple problems considered in this work, it is unclear how this can generalize to other more complicated datasets and problems.  \nThis should be better discussed, better justified and ideally results in some more realistic set-up shown (see below).\n\n\nQuality:\n- Experiments. Results are shown for inpainting of MNIST digits, intrinsic image decomposition on the MIT intrinsic image database, and figure/ground layer extraction on the synthesized dataset of 3D chairs rendered onto background from real photographs.  \n The experimental validation of the model is not very strong and proof-of-concept only. All the experiments are performed in simplified toy set-ups. The MNIST digit inpainting is far from current state-of-the-art on image inpainting in real photographs (see e.g. Pathak et al., 2016). The foreground background separation is done on  only synthetically generated test data. Even for intrinsic image demposition problem there is now relatively large-scale dataset of (Bell et al., 2014), see the citation below.  \n\nWhile this is probably ok for the ICLR paper, it diminishes the significance of the work. Is this model going to be useful in a real settings? One possibility to address this would be to focus on one of the problems and show results on a challenging state-of-the-art data. It would be great to see the benefits of the memory database. \n\nS. Bell, K. Bala, and N. Snavely. Intrinsic images in the wild.\nACM Transactions on Graphics, 33(4):159, 2014.\n\nClarity:\n- The clarity of the writing can be improved. I found some of the terminology of the paper, specially the \u201cimagination\u201d and \u201cmemory\u201d confusing. From figure 2, it is not clear how the \u201cmemories\u201d for the given input image are obtained, which also took me some time to understand.\n\n- To help understand the proposed architecture, it would be useful to draw an illustration of what is happening in the \"feature space\u201d, similar in spirit e.g. to figure 2 in", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "All three reviewers point to significant deficiencies (particularly the lack of quantitative evaluation and clarity problems). No response or engagement from the authors. I see no basis for supporting this paper.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "No Title", "is_meta_review": false, "comments": "In this work, the authors propose to use a (perhaps deterministic) retrieval function to replace uniform sampling over the train data in training the discriminator of a GAN.\nAlthough I like the basic idea, the experiments are very weak.  There are essentially no quantitative results, no real baselines, and only a small amount of not especially convincing qualititative results.   It is honestly hard to review the paper- there isn't any semblance of normal experimental validation.\n\nNote:  what is happening with the curves in fig. 6?", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "The proposed model has potential merits, but lack of quantitative evaluation and paper clarity issues put the paper below the bar.", "is_meta_review": false, "comments": "This paper proposes a model that generates a latent representation of input image(s) and optimizes a reconstruction loss with an adversarial loss (Eq (1)) over nearest neighbors from a bank of images (\u201cmemory\u201d).   The framework is adapted to three tasks: (i) image in-painting, (ii) intrinsic image decomposition, (iii) figure-ground layer extraction.  Qualitative results are shown for all three tasks.\n\nI think the proposed model has potential merits.  I particularly like the fact that it seems to be reasoning over image composites via matching against a bank of images (somewhat similar to \u201cSegmenting Scenes by Matching Image Composites\u201d work in NIPS 2009).  However, I won\u2019t champion the paper as the overall clarity and evaluation could be improved.\n\nMore detailed comments:\n\nI believe the fatal flaw of the paper is there is no quantitative evaluation of the approach.  At the very least, there should be a comparison against prior work on intrinsic image decomposition (e.g., SIRFS, maybe benchmark on \"intrinsic images in the wild\u201d dataset).\n\nI found the writing vague and confusing throughout.  For instance, \u201cmemory database\u201d could mean a number of things, and in the end it seems that it\u2019s simply a set of images.  \u201cImagination\u201d is also vague.  On page 4, R(M,x) has the database and input image as arguments, but Fig 2 doesn\u2019t show the input image as an input to R.  The contributions listed on page 3 should be tightened (e.g., it\u2019s not clear what \u201cRelevant memory retrieval for informative adversarial priors\u201d means).  Fig 3 seems inconsistent with Fig 2 as the module for \u201cmemory database\u201d is not present.  The fully-convolutional discriminator could use more details; one possibility is to provide a cost function.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "The proposed architecture seems novel and potentially interesting, but experiments are only proof-of-concept and clarity can be improved", "is_meta_review": false, "comments": "The paper describes a network architecture for inverse problems in computer vision. Example inverse problems considered are image inpainting, computing intrinsic image decomposition and foreground/background separation.\nThe architecture is composed of (i) a generator that produces target (latent) output (such as foreground / background regions), \n(ii) renderer that composes that latent output back to the image that can be compared with the input to measure reconstruction error, \nand (iii) adversarial prior that ensures the target output (latent) image respects a certain image statistics.\n\nStrong  points.\n- The proposed architecture with memory database is interesting and appears to be novel. \n\nWeak points:\n- Experimental results are only proof-of-concept in toy set-ups and do not clearly demonstrate benefits of the proposed architecture.\n- It is unclear whether the memory retrieval engine that retrieves images based on L2 distance on pixel values is going generalize to other more realistic scenarios. \n- Clarity. The clarity of explanation can be also improved (see below).\n\n\nDetailed evaluation.\n\nOriginality:\n- The novelty of this work lies in the (iii) adversarial prior that places an adversarial loss between the generated latent output and a single image retrieved from a large unlabelled database of target output examples (called memory). The adversarial prior has a convolutional form matching local image statistics, rather than the entire image.  The particular form of network architecture with the memory-based fully convolutional adversarial loss appears to be novel and potentially interesting.\n\n- Motivation for the Architecture. The weakest point of the proposed architecture is the \"Memory retrieval engine\" R (section 2.4),\nwhere images are retrieved from the memory by measuring L2 distance on pixel intensities. While this maybe ok for simple problems considered in this work, it is unclear how this can generalize to other more complicated datasets and problems.  \nThis should be better discussed, better justified and ideally results in some more realistic set-up shown (see below).\n\n\nQuality:\n- Experiments. Results are shown for inpainting of MNIST digits, intrinsic image decomposition on the MIT intrinsic image database, and figure/ground layer extraction on the synthesized dataset of 3D chairs rendered onto background from real photographs.  \n The experimental validation of the model is not very strong and proof-of-concept only. All the experiments are performed in simplified toy set-ups. The MNIST digit inpainting is far from current state-of-the-art on image inpainting in real photographs (see e.g. Pathak et al., 2016). The foreground background separation is done on  only synthetically generated test data. Even for intrinsic image demposition problem there is now relatively large-scale dataset of (Bell et al., 2014), see the citation below.  \n\nWhile this is probably ok for the ICLR paper, it diminishes the significance of the work. Is this model going to be useful in a real settings? One possibility to address this would be to focus on one of the problems and show results on a challenging state-of-the-art data. It would be great to see the benefits of the memory database. \n\nS. Bell, K. Bala, and N. Snavely. Intrinsic images in the wild.\nACM Transactions on Graphics, 33(4):159, 2014.\n\nClarity:\n- The clarity of the writing can be improved. I found some of the terminology of the paper, specially the \u201cimagination\u201d and \u201cmemory\u201d confusing. From figure 2, it is not clear how the \u201cmemories\u201d for the given input image are obtained, which also took me some time to understand.\n\n- To help understand the proposed architecture, it would be useful to draw an illustration of what is happening in the \"feature space\u201d, similar in spirit e.g. to figure 2 in ", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}], "SCORE": 6, "authors": "Hsiao-Yu Fish Tung, Katerina Fragkiadaki", "KEYWORDS": "We present a model that given a visual image learns to generate imaginations of  complete scenes, albedo, shading etc, by using adversarial data driven priors on the imaginations spaces.", "accepted": false, "id": ""}
