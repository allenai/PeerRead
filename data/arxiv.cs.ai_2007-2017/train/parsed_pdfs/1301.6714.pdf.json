{
  "name" : "1301.6714.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Expected Utility Networks",
    "authors" : [ "Piero La Mura", "Yoav Shoham" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "We introduce a new class of graphical representations, expected utility networks (EUNs), and discuss some of its properties and potential applications to artificial intelli gence and economic theory.\nIn EUNs not only probabilities, but also util ities enjoy a modular representation. EUNs are undirected graphs with two types of arc, representing probability and utility depen dencies respectively. The representation of utilities is based on a novel notion of con ditional utility independence, which we in troduce and discuss in the context of other existing proposals.\nJust as probabilistic inference involves the computation of conditional probabilities, strategic inference involves the computation of conditional expected utilities for alterna tive plans of action. We define a new notion of conditional expected utility (EU) indepen dence, and show that in EUNs node separa tion with respect to the probability and util ity subgraphs implies conditional EU inde pendence.\n1 Introduction\nModularity is the cornerstone of knowledge represen tation in AI; it allows concise representations of other wise quite complex concepts. Logic offers modularity via the compositional nature of the logical connectives, and the property is exploited by theorem provers. Probability allows this via the notion of probabilis tic independence, a notion fully exploited by Bayesian networks. In recent years there have been several at tempts to provide modular utility representations of preferences (Bacchus and Grove 1995, Doyle and Well man 1995, Shoham 1997).\nIt has proven difficult to devise a useful representation of utilities; this difficulty can certainly be ascribed to the different properties of utility and probability func tions, but also, more fundamentally, to the fact that reasoning about probabilities and utilities together re quires more than simply gluing together a representa tion of utility and one of probability.\nIn fact, just as probabilistic inference involves the com putation of conditional probabilities, strategic infer ence - the reasoning process which underlies rational decision-making1 - involves the computation of condi tional expected utilities for alternative plans of action, which may not have a modular representation even if probabilities and utilities, taken separately, do.\nThe purpose of this paper is to introduce a new class of graphical representations, expected utility networks (EUNs). EUNs are undirected graphs with two types of arc, representing probability and utility dependen cies respectively. In EUNs not only probabilities, but also utilities enjoy a modular representation. The rep resentation of utilities is based on a novel notion of conditional utility independence, which departs signif icantly from other existing proposals, and is defined in close analogy with its probabilistic counterpart.\nWe also define a novel notion of conditional expected utility (EU) independence, and show that in EUNs node separation with respect to the probability and utility subgraphs implies conditional EU indepen dence. In this respect, choosing the \"right\" notion of conditional utility independence turns out to be cru cial.\nWhat's important about conditionally independent de cisions is that they can be effectively decentralized: a single, complicated agent can be replaced by simpler, conditionally independent sub-agents, who can do just as well. This property is of interest not only to artifi-\n1 Here, and elsewhere, the term \"strategic\" is used in the context of individual decision-making, and does not necessarily refer to a multi-agent scenario.\ncia! intelligence, since it can be exploited to reduce the complexity of planning, but also to economic theory, as it suggests a principled way for the identification of optimal task allocations within economic organiza tions.\nThe rest of the paper is organized as follows. In section 2 we introduce our notion of conditional utility inde pendence, and discuss it in the context of other recent proposals in the literature. In section 3 we formally introduce EUNs, and discuss some of their structural properties. Next, we extend the utility function from elementary \"states\" or outcomes to general events, with the interpretation that the utility of an event is the expected utility of that event, conditional on it be ing true. We explain this, and other characteristics of the underlying decision theoretic framework, in section 4. In section 5 we show that conditional probability and utility independence jointly imply conditional ex pected utility independence, and argue that condition ally independent decisions can be effectively decentral ized. In section 6 we address the issue of probabilistic and strategic inference in EUNs, and show how con ditional probabilities and conditional expected utili ties can be recovered from the structural elements of EUNs. In the last section, we discuss a concrete appli cation of the EUN methodology in the context of an economic example: a second-price auction.\n2 Conditional independence of probabilities and utilities\nConditional probability independence is a powerful no tion: it incorporates a natural, intuitive notion of rel evance, and may dramatically reduce the complexity of probabilistic inference by allowing a convenient de composition of the probability function.\nIn strategic inference, reducing the complexity of the decision problem calls for a decomposition of utilities along with probabilities. Yet, this is generally not enough: even if probabilities and utilities are sepa rately decomposable, strategic inference typically in volves computation of the expected utilities for alter native plans of action, and hence what is really impor tant is the ability to decompose the expected utility function.\nSeveral proposals which recently appeared in the lit erature (Bacchus and Grove 1995, Shoham 1997) rely on additive notions of utility independence, while the familiar notion of probabilistic independence is mul tiplicative. This difference may account for the diffi culty encountered by these proposals to achieve a con venient decomposition of the expected utility function, and hence an effective reduction in the complexity of\nExpected Utility Networks 367\nstrategic inference.\nIn this section, we propose a multiplicative notion of conditional utility independence, which is a close ana logue of its probabilistic counterpart. In the following sections, we argue that these two notions turn out to play well together, by inducing a modular decomposi tion of the expected utility function, and a consequent simplification of the decision process.\nLet {X;};EN (N == {1, ... ,n}) be a finite, ordered set of random variables2, and let x0 == (xY, .. . , x�) be some arbitrary given realization which will act as the refer ence point (we use uppercase letters to denote random variables, and lowercase to denote their realizations). A joint realization X== (x1, ... , xn) represents a (global) state, or outcome. For any M C N, we denote by XM the set {X;};EM. Let p be a strictly positive proba bility measure defined on the Boolean algebra A gen erated by XN, and let u be a (utility) function which assigns to each state x a positive real number. We as sume that the decision maker's beliefs and preferences are completely characterized by (p, u) . Specifically, we assume that p represents the decision maker's prior beliefs, and that for any two probability measures p' and p\", p' >- p\" (p' is preferred to p\") if and only if Ep•(u) > Ep\"(u), where Ep(u) == L:x u(x)p(x). Fi nally, let\nThe interpretation of q is in terms of ceteris paribus comparisons: it tells us how the probability changes when the values of XM are shifted away from the ref erence point, while the values of XN-M are held fixed at XN-M·\nWe also define a corresponding ceteris paribus compar ison operator for utilities:\nOne way to interpret w is as a measure of the inten sity of preference for x M (with respect to the reference point) conditional on XN-M·\nSuppose that q(xM !xN-M) only depends on XK, where K C N- M, but not on XN-M-K· It is easily veri fied that this condition holds for all x N if and only if XM is probabilistically independent of XN-M-K given XK· We express (and record) this by defining new quantities q(xM!xK) == q(xM!XN-M), where the\n2To keep the notation simple, we assume that they may take only finitely many values. Yet, the construction is easily extended to more general classes of random variables.\n368 La Mura and Shoham\nconditions XN-M-K are dropped. We call this notion p-independence: note that it is only defined in terms of states (as opposed to general events), and corresponds to conditional probability independence whenever it is defined. Specifically, if A, B and C are three subsets of the set X N of all random variables, the statement \"A is p-independent of B given C\" only makes sense if A, B and C constitute a partition of X N, and in that case it is equivalent to the statement that A and B are probabilistically independent given C.\nA corresponding notion of conditional utility indepen dence (u-independence) is defined accordingly. Sup pose that w(xMIXN-M) depends on XK, but not on XN -M-K· Hence, the intensity of preference for the variables in XM (relative to their reference values) depends on the values of XK, but not on those of XN-M-K· In that case, we again define new quan tities w(xM lxK) = w(xMixN-M ), and say that XM is u-independent of XN-M-K given XK.\nIt is instructive to compare our notion of condi tional utility independence with several other propos als which have appeared in the literature, in the con text of an example adapted from Bacchus and Grove (1995). Suppose that there are two basic events, H and W (\"health and wealth\"), and that the following payoff tables, where payoffs are expressed as multiples of u(�H n �w) (an arbitrary reference point), repre sent the decision maker's preferences over H and W in two different scenarios:\n�w w �w w �H 1 2 �H 1 2 H 3 6 H 3 4\nBacchus and Grove's utility independence is, funda mentally, a qualitative notion, which in the example reduces to payoff dominance. Since H dominates �H and W dominates � W, utility independence holds in both cases.\nAdditive utility independence specializes utility inde pendence by requiring that probability measures with the same marginals be indifferent. In our 2 x 2 exam ple, this amounts to the restriction that u(H n W) + u(�Hn�W) = u(Hn�W)+u(�HnW). Hence, addi tive utility independence holds in the second case but not in the first.\nShoham further specializes the notion of additive inde pendence, with the following intended interpretation: the two Boolean variables in the example are indepen dent if it is possible to associate to each of them a linear \"contribution\" , such that the utility of a joint realization is given by the sum of the contributions. In our 2 x 2 example, this criterion coincides with ad-\nditive independence; however, in the general case it is more stringent.\nWe too introduce quantitative information, but in a different way: the two variables in the example are independent in our sense (conditional on the empty set) if the increment in utility relative to the refer ence point is the product of the increments along each component. The intended interpretation of utility in dependence in our case is that the \"intensity of pref erence\" for one variable with respect to its reference value, represented by the ceteris paribus utility ratio, does not depend on the particular value taken by the other variable. Hence, in our sense, H and W are in dependent in the first scenario but not in the second.\nWe claim that u-independence is a particularly attrac tive notion for two reasons:\n• it is information that is natural to elicit from people, as it purely involves relevance consider ations and order-of-magnitude comparisons be tween utilities\n• it gives rise to a graphical representation and asso ciated inference mechanism, expected utility net works (defined in the next section), which is simul taneously modular in probabilities, utilities and expected utilities.\n3 Expected utility networks: a formal definition and some structural properties\nWe define an expected utility network as an undirected graph G with two types of arc, representing probabil ity and utility dependencies respectively. Each node represents a random variable (say, X;), and is as sociated with two positive functions, q(x;IXP(i)) and w(x;lxu(;)), where P(i) denotes the set of nodes di rectly connected to X; via probability arcs3, and U(i) the corresponding set of nodes directly connected to X; via utility arcs.\nThese quantities are interpreted as the probability and utility ratios (defined in the previous section) pro duced by some expected utility representation (p, u), and may be assessed by the decision maker through ceteris paribus comparisons. Alternatively, the prob ability layer of a EUN may be initially specified as a Bayes network, and the probability ratios q derived from conditional probability tables.\nFigure 1 depicts a simple EUN. Although it is possible to present much richer examples, we select this one\n3 P(i) corresponds to the Markov mantle of X;, i.e., the minimal set of variables such that, conditional on those, X; is (probability) independent of everything else.\nIf the q and w functions are specified directly, then any arbitrary assignment of positive functions q(x; lx BP(i), x�P(i)) for all i (where AP( i) denotes the set of all variables in P( i) whose index is greater than i, and BP(i) = P(i) -AP(i)) uniquely iden tifies a corresponding probability function. Sim ilarly, any arbitrary assignment of positive func tions w(x; lxsP(i), x�P(i)) identifies a utility function, unique up to normalization. 4\nWe remark that, if q(x;lx-;) only depends on XP(i)• then fixing XP(i) completely specifies the behavior of the probability function along the i -th coordinate (up to the probability of the reference point), and that such behavior does not depend on the particular values taken by the other variables. The same is true about the utility of x; with respect to its reference value, given Xu(i). It turns out that node separation with respect to the probability and utility subgraphs characterizes all the implied p- and u- independencies. More precisely, for any probability - utility pair (p, u) there exists an undirected graph G such that, if A, B and C are three subsets of variables (each variable being asso ciated with a node in the graph), A is p- (resp., u-) independent of B given C if and only if C separates A from B with respect to the probability (resp., utility) subgraph (in the sense that every path from A to B in the subgraph must pass through C). In the language of Pearl (1988), G is a perfect map of the independence structure.\n4The particular normalization we adopt is discussed in section 4.\nExpected Utility Networks 369\nTheorem 1 The set of p- and u- independencies gen erated by any pair (p, u) has a perfect map.\nProof. We follow the methodology of Bacchus and Grove (1995), that is, we appeal to a necessary and sufficient condition in Pearl and Paz ( 1989) and check that suitable generalizations of p-independence and u independence both possess the following five proper ties: symmetry, decomposition, intersection, strong union and transitivity.\nWe prove it in the case of utility; the proof for prob ability is analogous. Let A, B, C, D, R, R', R\" be sub sets of random variables, where R, R' and R\" always denote the subset of remaining variables in the appro priate context (so, for instance, in the context of some A, B and C, R = XN -A -B -C). As elsewhere in this paper, we use uppercase/lowercase to denote (subsets of) random variables and their realizations respectively.\nFor the purpose of this proof, let's say that A is inde pendent of B given C, and write J(A, BIC) if and only ifw(alb,c,r) = w(albo,c,r) for all (a,b,c,r). Then the following properties hold.\nSymmetry: J(A, BIC) =? J(B, AI C).\nThis follows because w(bla, c, r) u(a,b,c,r) u(a,b,c,r) u(a0 ,b,c,r) u(a,b0 ,c,r) u(ab ,b,c,r) u(a,bb ,c,r) u(a,b0,c,r) u(a0,b,c,r) _ (bl 0 ) u(a0,b0,c,r)u(a,bO,c,r)- w a ,c,r .\nDecomposition: J(A, B U DIC) =? I(A, BIG) II I(A,DIC).\nThis is equivalent to saying that w(alb, c, d, r) = w(albo, c, do, r) implies w(alb, c, r') = w(albo, c, r') and w(alc, d, r\") = w(alc, do, r\"). This follows trivially, be causer' = (d, r) and r\" = (b, r). Intersection: J(A, BIG U D) II l(A, DIB U C) =? I(A, B u DIC).\nEquivalently, w(alb, c, d, r) w(albo, c, d, r) and w(alb,c,d,r) = w(alb,c,do,r) imply w(alb,c,d,r) = w(albo,c, do, r). This also follows quite easily by alge braic manipulation.\nStrong union: J(A, BIG) =? I(B, AIC U D).\nEquivalently, w(alc, b, r) w(a\\bo, c, r) implies w(bla, c, d, r') = w(blao, c, d, r'). This follows by sym metry, and the fact that r = (d, r'). Transitivity: J(A, BIC) =? I(A, VIC) V J(B, VIC),where V is any single variable. This is equivalent to saying that w(alb, c, r) = w(albo, c, r) implies w(a\\v, c, r') = w(a\\vo, c, r') or w(b\\v, c, r\") = w(b\\vo, c, r\"), which follows by observing that either v is in b or else is in r. •\n370 La Mura and Shoham\n4 Conditional expected utility\nWhile probability is a set function, defined for gen eral events, utility is so far only defined for elementary events (states). The notion of p-independence intro duced in section 2 precisely corresponds to conditional probability independence whenever it is defined, and it is only defined in terms of states- in turn, this enabled us to define a corresponding notion of conditional util ity independence, also defined in terms of states, which we named u-independence.\nAs we have seen, all p- and u- independencies can be immediately recovered from the graphical structure of EUNs, because they are fully characterized by node separation with respect to the probability and utility subgraphs. For instance, in the simple EUN repre sented in figure 1, V and C are conditionally p- and u- independent of each other, given A, B and S.\nSuppose now that A and B are controllable variables, in the sense that their values can be freely set by the decision maker. A rational decision maker will want to choose values of A and B which maximize expected utility; hence, for each assignment (a, b), the decision maker should compute the correspond ing expected utility, and identify an optimal decision. Clearly, the decision process becomes quite cumber some when there are many decision variables; to re duce its complexity, we seek conditions under which the expected utility calculations can be conveniently decomposed.\nThe first step will be to extend utility to a be a set function as well, with the following interpretation: the utility of an event is the expected utility of the event, conditional on the event being true. Formally,\nu(E) = L u(x)p(xiE). xEE\nThe following important property is an immediate con sequence of the definition: for any nonempty E E A and for any non-empty, finite partition {Ek} of E, where the Ek may or may not be elementary \"states\",\nu(E) = L u(Ek)p(EkiE). k\nThe (von Neumann - Morgenstern) utilities we start from5 are only defined up to positive affine transfor mations. It is natural then to normalize the utility\n5We start with von Neumann - Morgenstern utilities and a given prior probability, as it is customary in eco nomics. It is beyond the scope of this paper to discuss the decision-theoretic foundations of EUNs; we refer to La Mura and Shoham ( 1998) for a formal exposition of the\nmeasure around certain values, just as probabilities are normalized to lie between zero and one. Hence, we require that u(True) = 1, where True denotes the tautological event, or the entire universe. 6\nAlthough it won't play a direct role in EUNs, in order to facilitate the exposition we also define the value (or impact) of event E:\nv(E) = u(E)p(E)\nUnder the above normalization v is a (strictly posi tive) probability measure, since it is an additive set function, and\nv(True) = 1 2: v(E) > 0\nfor all nonempty E. Moreover, since p is also strictly positive, we have that\nv(E) u(E) =\np(E) .\nNote the remarkable structure of conditional expected utility: the utility \"measure\" is simply the ratio of two probability measures, one representing value, and the other belief.\nBeside being important for the practical construction of EUNs, this normalization of u allows us to speak about \"good\" and \"bad\" events. True - the status quo - is neutral, neither good or bad. An event E is said to be good (i.e., better than True) if u(E) > 1, and bad if u(E) < 1.\nThe conditional versions of the three set functions - probability, utility, and value - are defined in the natural way: p(E)F) = p(E n F)/p(F), and simi larly u(EIF) = u(E n F)fu(F), and v(E)F) = v(E n F)fv(F).\nThe three notions of conditioning are related by\nv(EIF) = u(E)F)p(E)F).\nBeing a probability measure, p obeys Bayes' rule (and, clearly, so does v):\np(EIF)p(F) p(FIE) = p(E)F)p(F) + p(EI-F)p(-F)\nunderlying decision-theoretic framework, and a represen tation result for conditional (and counterfactual), hierar chical, multi-agent preferences.\n6This normalization uniquely identifies the expected utility function if the utility of a second event Eo is also fixed, or, equivalently, if utilities are expressed as multiples of u(x0), the utility of an arbitrary reference point, as we do in EUNs.\nBayes' rule does not hold for utilities, but a modified version of it does:\nu(EIF)u(F) u(FIE)\n= u(EJF)u(F)p(F\\E) + u(E\\-F)u(-F)p(-FjE)\nNote that this is a \"hybrid\" relationship: conditional utility depends, among· other things, on conditional probabilities. This is another fact which is important to keep in mind in connection with EUNs.\n5 Conditional expected utility independence\nWe have now extended the utility function from com plete states to arbitrary events, but this new concept will be useful only insofar as it can be associated with a corresponding independence notion, and this extended notion is also captured in the structure of the graph. In this section we show that both these conditions hold. First we shall define a notion of conditional expected utility independence, and then show that this notion is indeed captured in the graphical structure of EUNs.\nWe define conditional expected utility independence (or, more concisely, conditional EU independence) for general events in analogy with the familiar notion of conditional probability independence. Two events, E and F, are said to be conditionally EU independent given a third event G if\nu(E n FIG) = u(E\\G)u(F\\G).\nConditional expected utility independence generalizes u-independence from states to general events, much as conditional probability independence generalizes p independence. Yet, since expected utilities involve probabilities as well, the relationship between condi tional EU independence and u-independence is medi ated by probabilities.\nLet's look at the general case first. Consider a parti tion of the set of all random variables into three sub sets A, B and C. The conditional expected utility of b given a is\nu(b!a) = u(a, b) = L u(a, b, c)p(cja, b) . u(a) I:b,c u(a, b, c)p(b, cJa)\nSuppose now that a separates b from c with respect to both the probability and utility subgraphs. Then the following simplification obtains:\nExpected Utility Networks 371\nw(bJa) u(bja) = I:b w(bia)p(bja)\nq(bia) p(bja) = I:b q(bia) .\nHence, the formula for u(bia) does not involve terms in C, and similarly u( cl a) does not involve terms in B.\nThis is not true if B and C are not p-independent, as the following example shows.\nExample 1 Consider the special case in which A is empty, and w(b) = 1 (in which case, we say that B is payoff-irrelevant). Then B and C are u-independent, although they may not be p-independent.\n� _ I;, w(c)q(clb) . . . Hence, U(b'} - l:c w(c)q(clb'), a quantzty whzch zs generally different from one. Intuitively, in this case B is purely instrumental to C: it is irrelevant in itself, but its expected utility reflects the influence that a partic ular choice of B has on the probability of C. If B and C are also p-independent, then the above expression reduces to :g)) = 1 (in which case, we say that B is strategically irrelevant).\nThese observations are central to the following result.\nTheorem 2 p- and u- independence jointly imply conditional expected utility independence.\nHence, the graphical structure of EUNs can be ex ploited to identify conditional EU independencies: node separation with respect to both the utility and probability subgraph implies conditional EU indepen dence. The upshot is that, conditional on A, decisions regarding B and C can be effectively decomposed: if both B and C contain variables which are under the control of the decision maker, it is not necessary nor useful to possess information about C in order to de cide on B, and vice versa. One way to think about such decomposability is in terms of strategic decen tralization: a single, centralized decision maker can be replaced by two conditionally independent, simpler agents, who only need to worry about their own re spective domains in order to make jointly optimal de cisions.\n6 Inference in expected utility networks\nIn EUNs, probabilities and utilities are implicitly de scribed by the q and w functions, together with the topological structure of the network. Probabilistic in ference involves the computation of conditional prob abilities, and strategic inference the computation of\n372 La Mura and Shoham\nconditional expected utilities; in this section, we show how these quantities can be readily recovered from the structural elements of EUNs.\nThe probability layer of a EUN is essentially a Markov network, even though probabilities are subject to a somewhat unusual normalization, and hence proba bilistic inference can be performed with standard tech niques whenever the potentials q are known. In turn, potentials can either be assigned directly by the deci sion maker in the form of ceteris paribus comparisons, or derived from conditional probabilities if one starts with a Bayes network.\nThe advantage of using utility \"potentials\" in EUNs is that they are based purely on utility comparisons between states, which do not involve probabilities: this enables one to elicit all the relevant preferences from the decision maker without assuming that he or she already knows the probabilities.\nAlthough we don't tackle here the issue of computa tional efficiency for probabilistic and strategic infer ence in EUNs (a topic which is next on our research agenda), we'll show how the two fundamental oper ations of marginalization and conditionalization for probabilities and expected utilities can be easily re duced to operations on the probability and utility po tentials.\nOnce the potentials are known, the computation of p(x)/p(x0) is straightforward:\np(x) p(xO)\np(x1, x�1) p(x) p(x0) p(x1, x�1)\n( I 0 ) p(x2,x1,xC:.p,2}) p(x)\n= q X! XP(l) ( 0 0 ) ( 0 ) p x2,X!, X_{l,2} p X2, X!,X_{l,2}\n= q(xllx�(l))q(x2lx1,X�p(2)) ( p(x)\no ) p X2,X!,X_{l,2} = . . . = X;q(xdxBP(i)•X�P(i)).\nOne can obtain p(xM )/p(x0) (where p(xM) is now the marginal probability function for a subset of random variables XM) by summing over the XN-M:\nOne can then use p(xM )/p(x0) to compute ra tios of marginal probabilities p(xA)/p(xB), and in particular conditional probabilities p(xAixB) = p(XA,XB)/p(XB). To compute u(x)/u(x0), we use the same decomposi tion:\nThe marginal (expected) utility of XM, relative to the reference point, can hence be computed as\nOne can then use ratios u(xM )/u(x0) to compute ra tios of expected utilities u(xA)/u(xB), and in par ticular conditional expected utilities u(xAixB) u(xA,XB)/u(xB). Notice that marginal utilities generally depend on probabilities. For instance, the utility of catching a particular cab rather than not is measured by the ra tio u(Cab)fu(-,Cab), and will generally depend on how likely it is that another cab will show up, on the prob ability of rain, and so on.\nAgain, we remark that using utility \"potentials\" as the initial data in EUNs (rather than conditional expected utilities) enables the decision maker to specify all the relevant preferences without any prior knowledge of the probabilities.\n7 Example: second-price auction\nTo conclude our presentation of EUNs, we propose a concrete application of the EUN machinery in the con text of an economic example: a second-price (\"Vick rey\") auction.\nIn a second-price auction the highest bidder gets the auctioned good, but only pays the second-highest bid. We assume that there are two bidders, and that the values of the good to each bidder correspond to the realizations of independent random variables.\nAgent 1 privately observes her own value for the good (denoted by V), and then decides how much to bid (B). Independently, the value of the good for agent 2 ( S) is realized, and contingent on that he decides how much to bid (C). The two bids jointly determine the final allocation (A), which is a pair a = (g, m) denoting who gets the good (g = 1, 2) and how much must be paid for it ( m) . To remove potential confusion (as our presentation of EUNs was centered on a single-agent perspective), we emphasize that we only model the game from the point of view of a single agent, and solve it as an individual decision problem. Yet, in a second price auction, as well as in other dominance-solvable games, this also suffices to identify the unique equilibrium.\nFigure 2 represents the auction from the point of view of agent 1. The probability layer is represented as a Bayes network, to emphasize the causal structure of the events in the game. Once again, we remark that the probability potentials q (and the corresponding Markov representation) can be readily derived from the conditional probability tables, in which case the resulting EUN looks like the one depicted in Figure 1. Here we omit this extra step, as we won't need it in the context of the example (since we shall simplify the ex pected utility function directly, rather than appealing to Theorem 2). Also, we omit all the utility potentials w which are identically equal to 1 (corresponding to payoff-irrelevant variables).\nThe probability of ending up with a particular alloca tion (g, m) depends on b and c, and is given by 7\n{ 1 if b :;:: c, c = m, g = 1 p(alb, c) = 1 if b < c, b = m, g = 2\n0 otherwise\nFor the purpose of exposition, we also postulate a par ticular functional form for agent 1 's preferences. We assume that the following condition holds:\nw a v = l+m { l+v if g = 1\n( I ) 1 otherwise\nNote that agent 1 's preferences on different allocations depend on her realized value for the good. We also assume that the distribution of agent 2's bids, from the point of view of agent 1, has full support.\n7For definiteness, we assume that in the case of identical bids agent 1 gets the good.\nExpected Utility Networks 373\nAgent 1 chooses her bid in order to maximize utility, given her private value for the good. The expected utility of b conditional on v is given by:\nu(biv) = j u(a,b,c,siv)p(da,dc,dsib,v) u(x0) j\n= --) w(a,b,c,s,v)p(da\\b,c)p(dc,ds) u(v\n= u(x0)w(vla0) (;\" 1 + v p(dc) + ;oo p(dc)) . u(v) 1 + c\n00 b\nThe first-order condition for optimality is given by\n1 + v I I -p(c) = p(c) 1 + C c=b\" c=b• and returns b* = v.\nHence, regardless of what her opponent is going to bid (as long as the distribution has full support), the opti mal strategy for agent 1 is to bid her true evaluation: i.e., to bid exactly the amount of money which keeps her indifferent between getting the good (and paying for it) or not.\nReferences\nF. Bacchus and A. Grove (1995), Graphical models for preference and utility. In Proc. 11th Conference on Uncertainty in Artificial Intelligence, pp. 3-10.\nJ. Doyle and M. P. Wellman (1995), Defining pref erences as Ceteris Paribus Comparatives. In Proc. AAAI Spring Symp. on Qualitative Decision Making, pp. 69-75.\nP. La Mura and Y. Shoham (1998), Conditional, hier archical, multi-agent preferences. In Proc. of Theoret ical Aspects of Rationality and Knowledge - VII, pp. 215-224.\nJ. Pearl (1988), Probabilistic reasoning in intelligent systems. Morgan Kaufmann.\nJ. Pearl and A. Paz (1989), Graphoids: A Graph Based Logic for Reasoning About Relevance Relations. In B. Du Boulay (Ed.) , Advances in Artificial Intelli gence - II, North-Holland.\nY. Shoham (1997), A Symmetric View of Probabilities and Utilities. In Proc. 13th Conference on Uncertainty in Artificial Intelligence, pp. 429-436."
    } ],
    "references" : [ {
      "title" : "Graphical models for preference and utility",
      "author" : [ "F. Bacchus", "A. Grove" ],
      "venue" : "In Proc. 11th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Bacchus and Grove,? \\Q1995\\E",
      "shortCiteRegEx" : "Bacchus and Grove",
      "year" : 1995
    }, {
      "title" : "Defining pref­ erences as Ceteris Paribus Comparatives",
      "author" : [ "J. Doyle", "M.P. Wellman" ],
      "venue" : "In Proc. AAAI Spring Symp. on Qualitative Decision Making,",
      "citeRegEx" : "Doyle and Wellman,? \\Q1995\\E",
      "shortCiteRegEx" : "Doyle and Wellman",
      "year" : 1995
    }, {
      "title" : "Conditional, hier­ archical, multi-agent preferences",
      "author" : [ "P. La Mura", "Y. Shoham" ],
      "venue" : "In Proc. of Theoret­ ical Aspects of Rationality and Knowledge - VII,",
      "citeRegEx" : "Mura and Shoham,? \\Q1998\\E",
      "shortCiteRegEx" : "Mura and Shoham",
      "year" : 1998
    }, {
      "title" : "Probabilistic reasoning in intelligent systems",
      "author" : [ "J. Pearl" ],
      "venue" : "Advances in Artificial Intelli­",
      "citeRegEx" : "Pearl,? \\Q1988\\E",
      "shortCiteRegEx" : "Pearl",
      "year" : 1988
    }, {
      "title" : "A Symmetric View of Probabilities and Utilities",
      "author" : [ "Y. Shoham" ],
      "venue" : "In Proc. 13th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Shoham,? \\Q1997\\E",
      "shortCiteRegEx" : "Shoham",
      "year" : 1997
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "It is instructive to compare our notion of condi­ tional utility independence with several other propos­ als which have appeared in the literature, in the con­ text of an example adapted from Bacchus and Grove (1995). Suppose that there are two basic events, H and W (\"health and wealth\"), and that the following payoff tables, where payoffs are expressed as multiples of u(�H n �w) (an arbitrary reference point), repre­ sent the decision maker's preferences over H and W in two different scenarios:",
      "startOffset" : 192,
      "endOffset" : 217
    }, {
      "referenceID" : 3,
      "context" : "In the language of Pearl (1988), G is a perfect map of the independence structure.",
      "startOffset" : 19,
      "endOffset" : 32
    }, {
      "referenceID" : 0,
      "context" : "We follow the methodology of Bacchus and Grove (1995), that is, we appeal to a necessary and sufficient condition in Pearl and Paz ( 1989) and check that suitable generalizations of p-independence and u­ independence both possess the following five proper­ ties: symmetry, decomposition, intersection, strong union and transitivity.",
      "startOffset" : 29,
      "endOffset" : 54
    } ],
    "year" : 2011,
    "abstractText" : "We introduce a new class of graphical representations, expected utility networks (EUNs), and discuss some of its properties and potential applications to artificial intelli­ gence and economic theory. In EUNs not only probabilities, but also util­ ities enjoy a modular representation. EUNs are undirected graphs with two types of arc, representing probability and utility depen­ dencies respectively. The representation of utilities is based on a novel notion of con­ ditional utility independence, which we in­ troduce and discuss in the context of other existing proposals. Just as probabilistic inference involves the computation of conditional probabilities, strategic inference involves the computation of conditional expected utilities for alterna­ tive plans of action. We define a new notion of conditional expected utility (EU) indepen­ dence, and show that in EUNs node separa­ tion with respect to the probability and util­ ity subgraphs implies conditional EU inde­ pendence.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}