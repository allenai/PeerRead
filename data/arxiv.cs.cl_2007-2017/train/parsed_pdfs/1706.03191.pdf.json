{
  "name" : "1706.03191.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "CLASSIFICATION OF QUESTIONS AND LEARNING OUTCOME STATEMENTS (LOS) INTO BLOOM’S TAXONOMY (BT) BY SIMILARITY MEASUREMENTS TOWARDS EXTRACTING OF LEARNING OUTCOME FROM LEARNING MATERIAL",
    "authors" : [ "Shadi Diab", "Badie Sartawi" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "DOI : 10.5121/ijmit.2017.9201 1\nBloom’s Taxonomy (BT) have been used to classify the objectives of learning outcome by dividing the learning into three different domains; the cognitive domain, the effective domain and the psychomotor domain. In this paper, we are introducing a new approach to classify the questions and learning outcome statements (LOS) into Blooms taxonomy (BT) and to verify BT verb lists, which are being cited and used by academicians to write questions and (LOS). An experiment was designed to investigate the semantic relationship between the action verbs used in both questions and LOS to obtain more accurate classification of the levels of BT. A sample of 775 different action verbs collected from different universities allows us to measure an accurate and clear-cut cognitive level for the action verb. It is worth mentioning that natural language processing techniques were used to develop our rules as to induce the questions into chunks in order to extract the action verbs. Our proposed solution was able to classify the action verb into a precise level of the cognitive domain. We, on our side, have tested and evaluated our proposed solution using confusion matrix. The results of evaluation tests yielded 97% for the macro average of precision and"
    }, {
      "heading" : "90% for F1. Thus, the outcome of the research suggests that it is crucial to analyse and verify the action verbs cited and used by academicians to write LOS and classify their questions based on blooms taxonomy in order to obtain a definite and more accurate classification.",
      "text" : "KEYWORDS\nLearning outcome; Natural Language Processing, Similarity Measurement; Questions Classification"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "The new international trends in education show a shift from traditional teacher-centred approach to a “student-centred” approach, which focuses, in turn, on what the students are expected to do at the end of the learning process! Therefore, this approach is commonly referred to as an outcomebased approach. Statements called intended learning outcomes, commonly shortened to learning outcomes, are being used to express what the students are expected to be able to do at the end of the learning period [1]. Learning is defined, in term of its outcome, in different contexts and for difference purposes or settings e.g. in terms of education, work, guidance and personnel context [2]. As for our research, it focuses on the education context presented in the form of textbooks deployed by the teaching staff. Learning outcomes can be defined for a single course taught by several teachers, or be standardized across universities or whole domains. Instructional designers (represented by the author of the textbook itself) should be provided a list of relevant learning\noutcome definitions they can link to their courses [3]. There are many useful guides for developing a comprehensive list of student outcomes. For example, Bloom's taxonomy is used to define the objective of learning and teaching as well as to divide learning into three types of domains: cognitive, affective and psychomotor. Then, it defines the level of performance for each domain [4]. Former students of blooms and a group of cognitive psychologists, curriculum theorists and instructional researchers have released a new version of bloom’s taxonomy in 2001 [5]. Our research will focus on the cognitive domain of bloom’s taxonomy 1.\nIt is a truism for educators that questions play an important role in teaching [6]. Our research focuses on questions classification into a cognitive level of bloom’s taxonomy, which is a framework for classifying educational goals and objectives into a hierarchical structure representing levels of learning. BT is of three different domains: the cognitive domain, the affective domain and the psychomotor domain. Each of these has a multi-tiered hierarchical structure for classifying learning [5]. The Cognitive Domain (Bloom et al., 1956) has become widely used throughout the world to assist in the preparation of evaluation materials [1]. There are six major categories (levels). The levels are Knowledge; Comprehension; Application; Analysis; Synthesis and Evaluation [7]. In our proposed approach, we will use the action verb of the question or (LOS) which represents the cognitive skill to classify the question into one or more levels."
    }, {
      "heading" : "2. LITERATURE AND RELATED WORK",
      "text" : "Many researchers attempted to classify questions into different classes and for different purposes. In [8] they classified learning questions through a machine learning approach, and learned a hierarchical classifier guided by a layered semantic hierarchy of answer types. They eventually classified questions into fine-grained classes. Their hierarchal classifier achieved 98.80% precision for coarse classes with all the features, and 95% for the fine classes.\nKeywords database matching with the verb of the question method has been developed, piloted and tested for automatic Bloom's taxonomy analysis, that matches all levels of cognitive domain of bloom [9], the results have shown that the knowledge level achieved 75% correct match in comparison with the expert’s results. The researchers system allows both teachers and students work together in the same platform to insert questions and review learning-outcome matches with the cognitive domain of BT.\n[10] They proposed natural language processing-based automatic concept extraction and outlines rule-based approach for separation of prerequisite concepts and learning outcomes covered in learning document, by their manual creation of domain ontology. Their system achieved Precision: 0.67 Recall: 0.83 F-score: 0.75.\n[11] They also proposed rule-based approach to analyse and classify written examination questions through natural language processing for computer programming subjects, the rules were developed using the syntactic structure of each question to apply the pattern of each question to the cognitive level of bloom. Their evaluation achieved macro F1 of 0.77. The researchers, in their other research, [12] proposed Bloom's Taxonomy Question Categorization Using Rules and N-Gram Approaches. In their experiment; 100 questions were selected for training and 35 were used for testing and both were based on programming domain. The categorization uses rule-based approach, N-gram and a combination of both. Their result demonstrated that combination rulebased and n-gram approaches obtained the highest and the best score of precision of average of 88%.\n[13] researchers have taken data of Li and Roth in [8] to classify the questions into three broad categoris instead of 6 course grain and and 50 fine grained categories. They analyzed the questions\nsyntacically to expect the answer type for every particuler category of the questions. [14] They also classified questions with different five machine learning algorithms: Nearest Neighbours (NN); Naïve Bayes (NB); Decision Tree (DT); Sparse Network of Winnows (SNoW); and Support Vector Machines (SVM). They did the classification using two features: bag-of-words and bag-of n-grams. They proposed a special kernel function to enable (SVM) take advantages of the syntactic structure of the questions. In their experiment, the questions classification accuracy reached 90%.\n[15] They proposed two Level Question Classification based on SVM and Question Semantic\nSimilarity in computer service & support domain, their results showed that question classification dramatically improves when complementing the domain ontology knowledge with questionspecific domain concepts. They also presented a two level classification approach based on SVM and question semantic similarity. [16] They also explored the effectiveness of support vector machines (SVMs) to classify questions, their evaluation showed the micro was 87.4 accuracy, 83.33 precision and 44.64 F1.\nMost of the researchers in our literature review had focused on classifying questions into different classes, including the classes of cognitive levels of BT... Purely machine learning and rules based approaches has been applied. Most of these researchers used huge amount of data and domain ontology to run their experiments, including the need to domain-experts to evaluate the performance, we consider [17] is the most related research to our approach. They used WordNet with cosine algorithm to classify exams question into bloom taxonomy. Questions pattern identification was required as a step to measure the cosine similarity by finding the total number of WordNet values for questions and run cosine similarity twice; first for pattern detection and second after calculating the WordNet value. Their evaluation achieved 32 questions out of 45 correctly classified. However, in our research, we proposed one similarity algorithm to measure the semantic similarity between the action verb of the question and the action verb list categorized by domain experts to find out the most accurate level for the question. Moreover, our algorithm was evaluated using confusion matrix. It was applied to both the cognitive domain of BT and the remaining two domains"
    }, {
      "heading" : "3. SEMANTIC SIMILARITY MEASUREMENT",
      "text" : ""
    }, {
      "heading" : "3.1 Semantic Similarity",
      "text" : "Semantic similarity has attracted great concern for a long time in artificial intelligence, psychology and cognitive science. In recent years, the measures based on WordNet have shown its capabilities and attracted great concern [18]. Researchers used measure of semantic relatedness to perform the task of word sense disambiguation [19]. Semantic similarity measures can be generally partitioned based on four grounds: based on the distance similarity between two concepts; based on information the two concepts share; based on the properties of the concepts; and based on a combination of the previous options [20]."
    }, {
      "heading" : "3.2 Wordnet",
      "text" : "WordNet is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of synonyms (Synsets). Synsets are interlinked by means of conceptual-semantic and lexical relations. It includes 82115 nouns, 13767 verbs, 18156 adjectives, 3621 adverbs [21]. The Wu and Palmer (Wu and Palmer, 1994) similarity metric measures semantic similarity through the depth of the two concepts in the WordNet taxonomy [22]. However, there are some important distinctions: First, WordNet interlinks not just word forms strings of letters but also specific senses of words. As a result, words found in close proximity to one another in the network are semantically disambiguated. Second, WordNet labels the semantic relations among words,\nwhereas the groupings of words in a thesaurus does not follow any explicit pattern other than meaning similarity [22]. Wu-Palmer representation scheme does not only take care of the semantic-syntactic correspondence, but it also provides similarity measures for the system for the performance of inexact matches based on verb meanings [23]. Wu-Palmer algorithm uses the following equation to measure the similarity:"
    }, {
      "heading" : "4. RESEARCH’S METHODOLOGY",
      "text" : "Analysing questions and LOS to determine the most accurate level in BT domains is a challenge. This will lead us to discover the intended learning outcome that will be achieved by the students. In our research, we concentrated on the action verbs that should be used to write questions and LOS based on cognitive domain through analysing the questions and LOS.\nWe have observed that categorization of the actions verbs may occur in different levels of the cognitive domain, thus, you may find the verb write in knowledge, application, comprehension or analysis levels, such this classification depends on the understanding of the action verb classified by domain experts. Academicians would manually classify the question into taxonomy level based on their styles [11]. Through our research, we will answer the following questions:\nHow can we classify the question and LOS into one or more of level of the cognitive domain using semantic similarity measurements? Does our proposed approach apply to the two remaining domains of BT? Will semantic similarity between action verbs of the question and the action verb lists assist in the enhancement of classifying questions and the writing of more accurate LOS?"
    }, {
      "heading" : "5. COLLECTING DATA FROM DOMAIN EXPERTS",
      "text" : "We have observed that many universities, worldwide, prepared guides papers and publications to be used for their teachers, in order to support them to write questions and LOS based on BT. The guides that classify the action verb is used as reference to classify the action verbs into BT. By assuming that the teachers use guides and supportive publications of their schools and universities in order to write questions and LOS, We collected 605 different action verbs that describe the cognitive skills in each level from websites of different universities [24] [25] [26] [27]. To gain more accurate and precise data, we filtered and modified the data lists by collecting the verbs intersecting with three or four lists (threshold 75-100%). We also added verbs intersecting with two resources if and only if having no conflict with other lists (threshold 50%). The result was a new dataset that contains 77 different action verbs distributed on the six levels of cognitive domain of BT. Moreover, questions starters from [28], which organize the starters of questions that cover each level of the cognitive domain of BT, has been collected."
    }, {
      "heading" : "6. STRUCTURAL INDUCTION OF THE QUESTION",
      "text" : "Structural induction may be defined as the process of extracting structural information using machine learning techniques and the patterns found may use to classify the questions [29]. This allows us to take some parts of question and leave the others for further processing. Our experiment aims to extract the action verb of the question by using the structural induction. Using the questions starters collected from [28], we were able to extract the action verb of the questions throughout implementing the following steps:\nsplitting the questions into separate lines, tokenization, lemmatization, POS tagging, partial parser over grammar which detect main action verb of the question , we were able to convert such question in form of POS tags patters contain the action verb of the question.\nFor example, running partial parsing over manually built in grammar to detect the knowledge level of the cognitive domain based on starters of [28]: Q: How would you explain computer science to a five-year-old? Steps will return the chunked tree labelled with \"KNOW\" as in Figure 1, while the main action verb explain refers to the knowledge level of BT\nWe have observed, after the implementation of our experiment, that adapting partial parser over built in grammars is applicable and effective to extract the action verb in order to move forward in our next experiments and analysis."
    }, {
      "heading" : "7. THE PROPOSED ACTION VERBS CLASSIFICATION ALGORITHM",
      "text" : "Different verbs can be used to demonstrate different levels of learning, for example: the basic level the learning outcomes may require learners to be able to define, recall, list, describe, explain or discuss [2]. In addition to that, the verb is considered the center, the fulcrum and the engine of a learning outcome statement. We should note that verbs refer to events, not to states; events are specific actions [30]. Thus, our proposed solution is based on the classification of action verb of the questions or LOS, in order to classify the whole question or LOS into more accurate level. The following definitions and steps describe our algorithm:\nBTD (Bloom’s Taxonomy Dimensions) = [C, A, P] where denotes for cognitive, affective and the psychomotor domains respectively.\nBased on BT classification each dimension of BT contains different levels (L), where the cognitive domain (C) contains six levels, and each affective (A) and psychomotor (P) domain contains 5 levels, thus C= [L1...L6], A= [L1… L5], and P= [L1… L5], for each level (L) in any dimension there are some groups of action verbs represent the particular level, these verbs assist and support the academicians to write LOS and questions based on BT.\nClassification of the action verb of the question or LOS (VQ) into one or more of dimension of BTD by similarity measurement between the action verb in VQ and each verbs of L in C, A or P by calculating similarity (sim) measurements, maximum similarity (Maxsim) and the total of similarities in each level, our algorithm will find three main measurements as follow:\n• Similarity measurement between the obtained action verb of the question or LOS and each of verbs represent the level of BT, Sim = Similarity_algorithm (VQ, N), where N is number\nof verbs represent the particular level.\n• Maximum similarity value between the action verb of the question or LOS and the verbs represent each level of BT, Maxsim = Maximum of semantic similarities between (VQ, N)\nfor each L.\n• Maximum area represent the total amount of similarity values for the action verb of the question or LOS in each level, Maxarea of L in C, A or P = MAX ( = sim (0) +\nsim (1) +… + sim (n), where i >=0 and n is the list of action verbs."
    }, {
      "heading" : "8. ACTION VERBS CLASSIFICATION ALGORITHM (AVCA)",
      "text" : "For the sake of simplicity, our algorithm and implementation applied on the cognitive domain, while the data (verbs) represent the cognitive domain are same type of data represent the other domains but with different verbs, furthermore our algorithm may accept any input data in form of verbs regardless if its related to cognitive, affective or psychomotor verbs, the proposed algorithm Pseudo code and step as follow:\n(Pseudo code):\nAlgorithm AVCA (VQ [0...M], CL [1...N], Maxsim [1…6], Maxarea):\n// the algorithm measure the similarity between groups of verbs //by calculating the high similarity and total amount of similarity values // Input: List of action verbs obtained from questions or LOS, VQ [1...M], and list of verbs //represent the cognitive domain CL, where CL= [L1...L6] and each contains group of verbs L= //[1...N] //Output: The maximum similarity between each verb of VQ list and L in CL, and maximum similarity area for each verb of VQ in each L in CL\nFor each L in CL:\nCompute Sim = [Similarity_algorithm (M, N)] Compute Maxsim = [Max (sim)] Classification result = L with greatest (Max (sim)) IF Len (Maxsim) >1 //have more than one max similarity appears in more than one level L\nFor each L in CL:\nMaxarea = Sum (sim1, sim2….Sim...n) Classification result = L with greatest (Maxarea)\nSTOP\nWhile there are a few similarity algorithms adapted in WORDNET, we implemented our algorithm on Wu-Palmer similarity algorithm to measure the similarity values, maximum similarities and similarity area, in additional, our algorithm will remain correct and applicable on the other similarity algorithms, and while the input data types are all in form of action verbs regardless if belong to cognitive, affective or psychomotor, our algorithm also will generate correct results and remain applicable for any dimension of BT."
    }, {
      "heading" : "9. EXPERIMENT AND ANALYSIS",
      "text" : "Our classification algorithm applied the constructed verb lists from questions and LOS to compute the maximum similarity for each level of the cognitive domain. Then it compares the maximum similarities to nominate (the greater) one and only one level as accurate level for the classified verb. Our experiment was built based on the collected data from [24] [25] [26] [27]. Such data has\nbeen built to support the academicians to write questions and LOS, we observed the following behaviours and cases:\nIdentical similarity will appear when the Synsets of the action verb has 1 similarity value with one or more verbs in the lists of cognitive domain. For example, figure 2 shows that the verb compile has 1 similarity value with the verb roll up in the synthesis level. We may conclude that the verb compile is way closer to the synthesis level than the other levels.\nHigher similarity value will appear when the action verb has less than 1 maximum similarity value. It also appears in one and only one level of cognitive domain. For example, figure 3 shows that the verb write has higher similarity value (0.857) with the verb dramatize in the application level. Thus, we may conclude that the verb dramatize belongs to application level more than the others do.\nObtaining same maximum similarity for some action verbs in more than one cognitive level may mean that the verb of the question could be applied to more than one level, see figure 4, Such case, in the point of view of some academicians may make sense. Moreover, we could prove that the action verb of the question may belong to one and only one level of the cognitive domain and have greater similarity semantically than the others. Figure 4 shows that the verb manipulate have maximum similarity (0.28) in all levels."
    }, {
      "heading" : "10. ENHANCEMENT OF THE ACTION VERBS LIST",
      "text" : "We validate our proposed algorithm on new data sets of action verbs collected from different resources from [31] [32]. All verbs were tested against each verb in our collected data [24] [25] [26] [27]. We found that our proposed algorithm can improve the correctness of the categorization based on cognitive blooms taxonomy from average of 71% to 97%.\nHowever, our algorithm was able to find that (34%) were incorrectly manually classified, on its part, has reduced the incorrectly classified verbs percentage from 34% to 8%. The improvement\naverage detected was 97% for both data sets as a result of applying a threshold ≥ 50% as an evidence from our source data."
    }, {
      "heading" : "11. EVALUATION AND RESULTS",
      "text" : "We evaluated our algorithm to measure the performance and our obtained results. We used confusion matrix, which is often used to describe the performance of classification model [33] in order to measure the following values:\n• True Positives (TP) is the count of correctly predicted positive values. We count the number of TP for each verb in our implementation as if the actual verb is classified in\nthe same class or level (both of the two verbs belong to the same cognitive level)\n• True Negatives (TN) is the count of correctly predicted negative values; the total amount of cases when the result of classification is false and the actual verb is also in\ndifferent class. (Both of our predicted result and the actual classified verb are not in the correct level.)\n• False Positives (FP): when the prediction result is yes and the actual verb is in different class.\n• False Negatives (FN): when the prediction return negative result but the actual is true.\nEvaluation of our algorithm was based on unseen data collected from [31] [32]. Moreover, a threshold of ≥ 50% used to measure the actual level of each verb in [24] [25] [26] [27]. By comparing the result and the actual level for each verb, we were able to create the confusion matrix in order to measure the most common measures used to evaluate the performance:\n• Accuracy: The simplest metric that can be used for evaluation; it measures the percentage of inputs in the test set that the classifier correctly labeled [33]. it also can be measured by\ncalculating TP+TN/TP+FP+FN+TN [34]\n• Precision: Indicates how many of our items that we identified were relevant and can be measured by calculating TP/ (TP+FP) [33].\n• Recall: Indicates how many of the relevant items that we identified, and measured by TP/ (TP+FN) [33].\n• F1 (or F-Score): combines the precision and recall to give a single score. F1 is defined to be the harmonic mean of the precision and recall and measured as follow:\n(2 × Precision × Recall)/ (Precision Recall) [33].\n• Error-Rate (ERR): the calculated number of all incorrect prediction divided by the total number of the dataset = FP + FN / N [35]\n• Macro-Average: To calculate the harmonic mean of precision, recall for all classes (levels).\nThe obtained results after processing the test sets in [31] and [32] are summarized in table 1 and table 2.\nIt can be concluded that the accuracy, precision and recall in each level in our two evaluation tests are very satisfactory. Moreover, our algorithms’ evaluation overall is very satisfactory as well. In both our validation and evaluation, we were able to prove that the classification of the action verb into one or more level of cognitive domain of BT will increase the efficiency of such classification. This can be used to enhance not only writing learning outcome statements but also classifying the question into more accurate level semantically."
    }, {
      "heading" : "12. CONCLUSION",
      "text" : "We introduced in this work, the classification problem of the questions and LOS into bloom taxonomy. Our research explored the rules-based approach to induct the most important part of the question. Such parts, which include the action verb of the question, will lead us to measure the accurate level of the action verb in the cognitive domain. We also conducted an analysis of currently used action-verb lists as guides for academicians and proposed a new method to measure the relation between these verbs, the verb of the question and the learning outcome statements (LOS). We, as well, adapted similarity measures to provide accurate classification for such verbs by two methods; using the maximum similarity and calculating the whole similarity area for each one six of the cognitive domain hierarchy. We have validated and proved that our proposed solution will improve the classified action verbs into more accurate levels. Later, we evaluated our proposed method by using the confusion matrix and measured a very high Macro-average of precisions for all one six of the cognitive domain of BT. In conclusion, this will enhance the cognitive action verb lists. These lists, however, are being used and cited by academicians to write LOS and classify their questions based on blooms taxonomy as this work helps provide more\naccurate verbs, this will, in turn, provide more accurate intended mental skills. This will also, in addition to the previously mentioned, clear the ambiguity that lies behind classification of questions into bloom taxonomy as well as the action verbs when used in writing LOS."
    }, {
      "heading" : "13. FUTURE WORK",
      "text" : "Deeply Syntax analysis is required to convert the whole question into LOS automatically. Moreover, analysing the figures such as images, graphs and tables in order to construct LOS, which represents the objectives behind by such figures, is very important toward constructing LOS from learning material."
    } ],
    "references" : [ {
      "title" : "Writing and using learning outcomes: a practical guide, Page 18, Cork: University",
      "author" : [ "Declan Kennedy" ],
      "venue" : "College Cork,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2006
    }, {
      "title" : "Repository services for outcome-based learning",
      "author" : [ "Totschnig", "Michael" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2010
    }, {
      "title" : "The Use of Questions in Teaching",
      "author" : [ "M.D. Gall" ],
      "venue" : "American Educational Research Association, vol. 40, no. 5, pp. 707-721, 1970.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1970
    }, {
      "title" : "Learning Question Classifiers",
      "author" : [ "Li", "Roth" ],
      "venue" : "Illinois USA: 19th International Conference on Compuatational Linguistics (COLING)",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2002
    }, {
      "title" : "Automatic Applying Bloom's Taxonomy to Classify and Analysis the cognition level of english questions items, Taiwan",
      "author" : [ "Wen-Chih Chang", "Ming-Shun Chung" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2009
    }, {
      "title" : "Automatic extraction of prerequisites and learning outcome from learning material, India",
      "author" : [ "Sonal Jain", "Jyoti Pareek" ],
      "venue" : "Inderscience Enterprises Ltd.,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2013
    }, {
      "title" : "A Rule-based Approach in Bloom’s Taxonomy Question Classification through Natural Language, Malaysia",
      "author" : [ "Syahidah Haris", "Nazila Omar" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2013
    }, {
      "title" : "Question Classification Using Syntactic And Rule Based Approach",
      "author" : [ "Payal Biswas" ],
      "venue" : "New Delhi: International Conference on Advances in Computing,Communications and Informatics (ICACCI),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Question Classification using Support Vector Machines, Singapore",
      "author" : [ "Dell Zhang" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2003
    }, {
      "title" : "Two Level Question Classification Based on SVM and Question Semantic Similarity, Beijing",
      "author" : [ "Jibin Fu" ],
      "venue" : "China: International Conference on Electronic Computer Technology,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2009
    }, {
      "title" : "Automatic Classification Of Questions Into Bloom's Cognitive Levels Using Support Vector Machines, Najran: Researchgate",
      "author" : [ "Anwar Ali Yahya", "Addin Osman" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2011
    }, {
      "title" : "An automatic classifer for exam questions with wordnet and cosine, International Journal of Emerging Technologies in Learning (iJET",
      "author" : [ "J K" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2016
    }, {
      "title" : "A Review of Semantic Similarity Measures in WordNet",
      "author" : [ "Lingling Meng" ],
      "venue" : "International Journal of Hybrid Information Technology, vol. 6, no. 1, p. 1, 2013.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Using Measures of Semantic Relatedness for Word Sense Disambiguation",
      "author" : [ "Siddharth Patwardhan" ],
      "venue" : "Springer, p. 241–257, 2003.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Semantic Similarity Methods in WordNet and Their Application to Information Retrieval on the Web",
      "author" : [ "G.V. e. al" ],
      "venue" : "ACM New York, NY, USA ©2005, pp. 10-16, 2005.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "WordNet - A Lexical Database for English",
      "author" : [ "G.A. Miller" ],
      "venue" : "Communications of the ACM, vol. 38, no. 11, pp. 39-41, 2005. International Journal of Managing Information Technology (IJMIT) Vol.9, No.2, May 2017 12",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Measuring the Semantic Similarity of Texts",
      "author" : [ "C.C. a. R. Mihalcea" ],
      "venue" : "University of North Texas: University of North Texas,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2005
    }, {
      "title" : "VERB SEMANTICS AND LEXICAL SELECTION",
      "author" : [ "Z.W. a. M. Palmer" ],
      "venue" : "In Proceedings of the 32nd Annual Meeting of the Associations for Computational Linguistics, Las Cruces, New Mexico,, 1994.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Bloom's Taxonomy of Cognitive Skills with Action Verb List Source",
      "author" : [ "Virginia.ED" ],
      "venue" : "University of Verginia, 20 2 2017. [Online]. Available: http://avillage.web.virginia.edu/iaas/assess/resources/verblist.pdf. [Accessed 20 2 2017].",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Bloom's Taxonomy",
      "author" : [ "U.O.C. Florida" ],
      "venue" : "University of Central Florida, 20 2 2017. [Online]. Available: http://www.fctl.ucf.edu/teachingandlearningresources/coursedesign/bloomstaxonomy/. [Accessed 20 2 2017].",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Bloom’s Taxonomy Action Verbs",
      "author" : [ "M.S. University" ],
      "venue" : "Missouri State University, 20 2 2017. [Online]. Available: https://www.missouristate.edu/assets/fctl/Blooms_Taxonomy_Action_Verbs.pdf. [Accessed 20 2 2017].",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Bloom's Taxonomy Verbs",
      "author" : [ "C.A. College" ],
      "venue" : "Central Arizona College, 20 2 2017. [Online]. Available: http://www.centralaz.edu/Documents/class/Bloom's%20Taxonomy%20Verbs%20Web.pdf. [Accessed 20 2 2017].",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "http://www.bloomstaxonomy.org",
      "author" : [ "F. Kugelman" ],
      "venue" : "6 2 2017. [Online]. Available: http://www.bloomstaxonomy.org/BloomsTaxonomyquestions.pdf. [Accessed 06 02 2017].",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Question classification by structure induction",
      "author" : [ "Zaanen" ],
      "venue" : "IJCAI'05 Proceedings of the 19th international joint conference on Artificial intelligence, Edinburgh, Scotland , 2005.",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "The Language and Syntax of Learning Outcomes Statements",
      "author" : [ "C. Adelman" ],
      "venue" : "National Institute for Learning Outcomes Assessment,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2015
    }, {
      "title" : "Bloom’s Taxonomy Action Verbs",
      "author" : [ "Fresnostate university" ],
      "venue" : "[Online]. Available: http://www.fresnostate.edu/academics/oie/documents/assesments/Blooms%20Level.pdf. [Accessed 4 3 2017].",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Simple guide to confusion matrix terminology",
      "author" : [ "K. Markham" ],
      "venue" : "dataschool, [Online]. Available: http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/. [Accessed 07 03 2017].",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Statements called intended learning outcomes, commonly shortened to learning outcomes, are being used to express what the students are expected to be able to do at the end of the learning period [1].",
      "startOffset" : 195,
      "endOffset" : 198
    }, {
      "referenceID" : 1,
      "context" : "2 outcome definitions they can link to their courses [3].",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 2,
      "context" : "It is a truism for educators that questions play an important role in teaching [6].",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 0,
      "context" : ", 1956) has become widely used throughout the world to assist in the preparation of evaluation materials [1].",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 3,
      "context" : "In [8] they classified learning questions through a machine learning approach, and learned a hierarchical classifier guided by a layered semantic hierarchy of answer types.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 4,
      "context" : "Keywords database matching with the verb of the question method has been developed, piloted and tested for automatic Bloom's taxonomy analysis, that matches all levels of cognitive domain of bloom [9], the results have shown that the knowledge level achieved 75% correct match in comparison with the expert’s results.",
      "startOffset" : 197,
      "endOffset" : 200
    }, {
      "referenceID" : 5,
      "context" : "[10] They proposed natural language processing-based automatic concept extraction and outlines rule-based approach for separation of prerequisite concepts and learning outcomes covered in learning document, by their manual creation of domain ontology.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 6,
      "context" : "[11] They also proposed rule-based approach to analyse and classify written examination questions through natural language processing for computer programming subjects, the rules were developed using the syntactic structure of each question to apply the pattern of each question to the cognitive level of bloom.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 7,
      "context" : "[13] researchers have taken data of Li and Roth in [8] to classify the questions into three broad categoris instead of 6 course grain and and 50 fine grained categories.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 3,
      "context" : "[13] researchers have taken data of Li and Roth in [8] to classify the questions into three broad categoris instead of 6 course grain and and 50 fine grained categories.",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 8,
      "context" : "[14] They also classified questions with different five machine learning algorithms: Nearest Neighbours (NN); Naïve Bayes (NB); Decision Tree (DT); Sparse Network of Winnows (SNoW); and Support Vector Machines (SVM).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 9,
      "context" : "[15] They proposed two Level Question Classification based on SVM and Question Semantic Similarity in computer service & support domain, their results showed that question classification dramatically improves when complementing the domain ontology knowledge with questionspecific domain concepts.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[16] They also explored the effectiveness of support vector machines (SVMs) to classify questions, their evaluation showed the micro was 87.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "Most of these researchers used huge amount of data and domain ontology to run their experiments, including the need to domain-experts to evaluate the performance, we consider [17] is the most related research to our approach.",
      "startOffset" : 175,
      "endOffset" : 179
    }, {
      "referenceID" : 12,
      "context" : "In recent years, the measures based on WordNet have shown its capabilities and attracted great concern [18].",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 13,
      "context" : "Researchers used measure of semantic relatedness to perform the task of word sense disambiguation [19].",
      "startOffset" : 98,
      "endOffset" : 102
    }, {
      "referenceID" : 14,
      "context" : "Semantic similarity measures can be generally partitioned based on four grounds: based on the distance similarity between two concepts; based on information the two concepts share; based on the properties of the concepts; and based on a combination of the previous options [20].",
      "startOffset" : 273,
      "endOffset" : 277
    }, {
      "referenceID" : 15,
      "context" : "It includes 82115 nouns, 13767 verbs, 18156 adjectives, 3621 adverbs [21].",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 16,
      "context" : "The Wu and Palmer (Wu and Palmer, 1994) similarity metric measures semantic similarity through the depth of the two concepts in the WordNet taxonomy [22].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 16,
      "context" : "4 whereas the groupings of words in a thesaurus does not follow any explicit pattern other than meaning similarity [22].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 17,
      "context" : "Wu-Palmer representation scheme does not only take care of the semantic-syntactic correspondence, but it also provides similarity measures for the system for the performance of inexact matches based on verb meanings [23].",
      "startOffset" : 216,
      "endOffset" : 220
    }, {
      "referenceID" : 6,
      "context" : "Academicians would manually classify the question into taxonomy level based on their styles [11].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 18,
      "context" : "By assuming that the teachers use guides and supportive publications of their schools and universities in order to write questions and LOS, We collected 605 different action verbs that describe the cognitive skills in each level from websites of different universities [24] [25] [26] [27].",
      "startOffset" : 269,
      "endOffset" : 273
    }, {
      "referenceID" : 19,
      "context" : "By assuming that the teachers use guides and supportive publications of their schools and universities in order to write questions and LOS, We collected 605 different action verbs that describe the cognitive skills in each level from websites of different universities [24] [25] [26] [27].",
      "startOffset" : 274,
      "endOffset" : 278
    }, {
      "referenceID" : 20,
      "context" : "By assuming that the teachers use guides and supportive publications of their schools and universities in order to write questions and LOS, We collected 605 different action verbs that describe the cognitive skills in each level from websites of different universities [24] [25] [26] [27].",
      "startOffset" : 279,
      "endOffset" : 283
    }, {
      "referenceID" : 21,
      "context" : "By assuming that the teachers use guides and supportive publications of their schools and universities in order to write questions and LOS, We collected 605 different action verbs that describe the cognitive skills in each level from websites of different universities [24] [25] [26] [27].",
      "startOffset" : 284,
      "endOffset" : 288
    }, {
      "referenceID" : 22,
      "context" : "Moreover, questions starters from [28], which organize the starters of questions that cover each level of the cognitive domain of BT, has been collected.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 23,
      "context" : "Structural induction may be defined as the process of extracting structural information using machine learning techniques and the patterns found may use to classify the questions [29].",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 22,
      "context" : "Using the questions starters collected from [28], we were able to extract the action verb of the questions throughout implementing the following steps:",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 22,
      "context" : "For example, running partial parsing over manually built in grammar to detect the knowledge level of the cognitive domain based on starters of [28]: Q: How would you explain computer science to a five-year-old? Steps will return the chunked tree labelled with \"KNOW\" as in Figure 1, while the main action verb explain refers to the knowledge level of BT",
      "startOffset" : 143,
      "endOffset" : 147
    }, {
      "referenceID" : 24,
      "context" : "We should note that verbs refer to events, not to states; events are specific actions [30].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 18,
      "context" : "Our experiment was built based on the collected data from [24] [25] [26] [27].",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 19,
      "context" : "Our experiment was built based on the collected data from [24] [25] [26] [27].",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 20,
      "context" : "Our experiment was built based on the collected data from [24] [25] [26] [27].",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 21,
      "context" : "Our experiment was built based on the collected data from [24] [25] [26] [27].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 25,
      "context" : "We validate our proposed algorithm on new data sets of action verbs collected from different resources from [31] [32].",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 18,
      "context" : "All verbs were tested against each verb in our collected data [24] [25] [26] [27].",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 19,
      "context" : "All verbs were tested against each verb in our collected data [24] [25] [26] [27].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 20,
      "context" : "All verbs were tested against each verb in our collected data [24] [25] [26] [27].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 21,
      "context" : "All verbs were tested against each verb in our collected data [24] [25] [26] [27].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 26,
      "context" : "We used confusion matrix, which is often used to describe the performance of classification model [33] in order to measure the following values:",
      "startOffset" : 98,
      "endOffset" : 102
    }, {
      "referenceID" : 25,
      "context" : "Evaluation of our algorithm was based on unseen data collected from [31] [32].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 18,
      "context" : "Moreover, a threshold of ≥ 50% used to measure the actual level of each verb in [24] [25] [26] [27].",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 19,
      "context" : "Moreover, a threshold of ≥ 50% used to measure the actual level of each verb in [24] [25] [26] [27].",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 20,
      "context" : "Moreover, a threshold of ≥ 50% used to measure the actual level of each verb in [24] [25] [26] [27].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 21,
      "context" : "Moreover, a threshold of ≥ 50% used to measure the actual level of each verb in [24] [25] [26] [27].",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 26,
      "context" : "• Accuracy: The simplest metric that can be used for evaluation; it measures the percentage of inputs in the test set that the classifier correctly labeled [33].",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 26,
      "context" : "it also can be measured by calculating TP+TN/TP+FP+FN+TN [34] • Precision: Indicates how many of our items that we identified were relevant and can be measured by calculating TP/ (TP+FP) [33].",
      "startOffset" : 187,
      "endOffset" : 191
    }, {
      "referenceID" : 26,
      "context" : "• Recall: Indicates how many of the relevant items that we identified, and measured by TP/ (TP+FN) [33].",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 26,
      "context" : "F1 is defined to be the harmonic mean of the precision and recall and measured as follow: (2 × Precision × Recall)/ (Precision Recall) [33].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 25,
      "context" : "The obtained results after processing the test sets in [31] and [32] are summarized in table 1 and table 2.",
      "startOffset" : 64,
      "endOffset" : 68
    } ],
    "year" : 2017,
    "abstractText" : "Bloom’s Taxonomy (BT) have been used to classify the objectives of learning outcome by dividing the learning into three different domains; the cognitive domain, the effective domain and the psychomotor domain. In this paper, we are introducing a new approach to classify the questions and learning outcome statements (LOS) into Blooms taxonomy (BT) and to verify BT verb lists, which are being cited and used by academicians to write questions and (LOS). An experiment was designed to investigate the semantic relationship between the action verbs used in both questions and LOS to obtain more accurate classification of the levels of BT. A sample of 775 different action verbs collected from different universities allows us to measure an accurate and clear-cut cognitive level for the action verb. It is worth mentioning that natural language processing techniques were used to develop our rules as to induce the questions into chunks in order to extract the action verbs. Our proposed solution was able to classify the action verb into a precise level of the cognitive domain. We, on our side, have tested and evaluated our proposed solution using confusion matrix. The results of evaluation tests yielded 97% for the macro average of precision and 90% for F1. Thus, the outcome of the research suggests that it is crucial to analyse and verify the action verbs cited and used by academicians to write LOS and classify their questions based on blooms taxonomy in order to obtain a definite and more accurate classification.",
    "creator" : "PScript5.dll Version 5.2.2"
  }
}