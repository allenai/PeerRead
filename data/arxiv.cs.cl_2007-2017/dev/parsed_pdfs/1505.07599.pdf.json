{
  "name" : "1505.07599.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Overview of the NLPCC 2015 Shared Task: Chinese Word Segmentation and POS Tagging for Micro-blog Texts",
    "authors" : [ "Xipeng Qiu", "Peng Qian", "Liusong Yin", "Shiyu Wu", "Xuanjing Huang" ],
    "emails" : [ "xpqiu@fudan.edu.cn", "pqian11@fudan.edu.cn", "lsyin14@fudan.edu.cn", "sywu13@fudan.edu.cn", "xjhuang@fudan.edu.cn" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Word segmentation and Part-of-Speech (POS) tagging are two fundamental tasks for Chinese language processing. In recent years, word segmentation and POS tagging have undergone great development. The popular method is to regard these two tasks as sequence labeling problem [7, 5], which can be handled with supervised learning algorithms such as Maximum Entropy (ME) [1], averaged perceptron [2], Conditional Random Fields (CRF)[3]. After years of intensive researches, Chinese word segmentation and POS tagging achieve a quite high precision. However, their performance is not so satisfying for the practical demands to analyze Chinese texts, especially for informal texts. The key reason is that most of annotated corpora are\nar X\niv :1\n50 5.\n07 59\n9v 3\n[ cs\n.C L\ndrawn from news texts. Therefore, the system trained on these corpora cannot work well with the out-of-domain texts.\nIn this shared task, we focus to evaluate the performances of word segmentation and POS tagging on relatively informal micro-texts."
    }, {
      "heading" : "2 Data",
      "text" : "Different with the popular used newswire dataset, we use relatively informal texts from Sina Weibo1. The training and test data consist of micro-blogs from various topics, such as finance, sports, entertainment, and so on. Both the training and test files are UTF-8 encoded.\nThe information of dataset is shown in Table 1. The out-of-vocabulary (OOV) rate is slight higher than the other benchmark datasets. For example, the OOV rate is 5.58% in the popular division [9] of the Chinese Treebank (CTB 6.0) dataset [8], while the OOV rate of our dataset is 7.25%.\nThere are total 35 POS tags in this dataset. A detailed list of POS tags is shown in Table 2.\n1http://weibo.com/"
    }, {
      "heading" : "2.1 Background Data",
      "text" : "Besides the training data, we also provide the background data, from which the training and test data are drawn. The purpose is to find the more sophisticated features by the unsupervised way."
    }, {
      "heading" : "3 Description of the Task",
      "text" : "In this shared task, we wish to investigate the performances of Chinese word segmentation and POS tagging for the micro-blog texts."
    }, {
      "heading" : "3.1 Subtasks",
      "text" : "This task focus the two fundamental problems of Chinese language processing: word segmentation and POS tagging, which can be divided into two subtasks:\n1. SEG Chinese word segmentation\n2. S&T Joint Chinese word segmentation and POS Tagging"
    }, {
      "heading" : "3.2 Tracks",
      "text" : "Each participant will be allowed to submit the three runs for each subtask: closed track run, semi-open track run and open track run.\n1. In the closed track, participants could only use information found in the provided training data. Information such as externally obtained word counts, part of speech information, or name lists was excluded.\n2. In the semi-open track, participants could use the information extracted from the provided background data in addition to the provided training data. Information such as externally obtained word counts, part of speech information, or name lists was excluded.\n3. In the open track, participants could use the information which should be public and be easily obtained. But it is not allowed to obtain the result by the manual labeling or crowdsourcing way."
    }, {
      "heading" : "4 Participants",
      "text" : "Sixteen teams have registered for this task. Finally, there are 27 qualified submitted results from 10 teams. A summary of qualified participating teams are shown in Table 3."
    }, {
      "heading" : "5 Results",
      "text" : ""
    }, {
      "heading" : "5.1 Evaluation Metrics",
      "text" : "The evaluation measure are reported are precision, recall, and an evenly-weighted F1."
    }, {
      "heading" : "5.2 Baseline Systems",
      "text" : "Currently, the mainstream method of word segmentation is discriminative characterbased sequence labeling. Each character is labeled as one of {B, M, E, S} to indicate the segmentation. {B, M, E} represent Begin, Middle, End of a multi-character segmentation respectively, and S represents a Single character segmentation.\nFor the joint word segmentation and POS tagging, the state-of-the-art method is also based on sequence learning with cross-labels, which can avoid the problem of error propagation and achieve higher performance on both subtasks[4]. Each label is the cross-product of a segmentation label and a tagging label, e.g. {B-NN, I-NN, E-NN, S-NN, ...}. The features are generated by position-based templates on character-level.\nSequence labeling is the task of assigning labels y = y1, . . . , yn to an input sequence x = x1, . . . , xn. Given a sample x, we define the feature Φ(x,y). Thus, we can label x with a score function,\nŷ = arg max y F (w,Φ(x,y)), (1)\nwhere w is the parameter of function F (·). For sequence labeling, the feature can be denoted as φk(yi, yi−1,x, i), where i stands for the position in the sequence and k stands for the number of feature templates.\nHere, we use two popular open source toolkits for sequence labeling task as the baseline systems: FNLP2 [6] and CRF++3. Here, we use the default setting of CRF++ toolkit with the feature templates as shown in Table 4. The same feature templates are also used for FNLP."
    }, {
      "heading" : "5.3 Chinese word segmentation",
      "text" : "In word segmentation task, the best F1 performances are 95.12, 95.52 and 96.65 for closed, semi-open and open tracks respectively. The best system outperforms the baseline systems on closed track. The best system on semi-open track is better\n2https://github.com/xpqiu/fnlp/ 3http://taku910.github.io/crfpp/\nthan that on closed track. Unsurprisingly, the performances boost greatly on open track."
    }, {
      "heading" : "5.4 Joint Chinese word segmentation and POS Tagging",
      "text" : "In the joint word segmentation and POS tagging, the best performances are 88.93, 88.69 and 91.55 for closed, semi-open and open tracks respectively."
    }, {
      "heading" : "6 Analysis",
      "text" : ""
    }, {
      "heading" : "7 Conclusion",
      "text" : "After years of intensive researches, Chinese word segmentation and POS tagging have achieved a quite high precision. However, the performances of the stateof-the-art systems are still relatively low for the informal texts, such as microblogs, forums. The NLPCC 2015 Shared Task on Chinese Word Segmentation and POS Tagging for Micro-blog Texts focuses on the fundamental research in Chinese language processing.\nIt is the first time to use the micro-texts to evaluate the performance of the state-of-the-art methods\nIn future work, we hope to run an online evaluation system to accept open registration and submission. Currently, a simple system is available at http: //nlp.fudan.edu.cn/nlpcc2015. The system also gives the leaderboards for the up-to-date results under the different tasks and tracks. Besides, we also wish to extend the scale of corpus and add more informal texts."
    }, {
      "heading" : "Acknowledgement",
      "text" : "We are very grateful to the students from our lab for their efforts to annotate and check the data. We would also like to thank the participants for their valuable feedbacks and comments."
    } ],
    "references" : [ {
      "title" : "A maximum entropy approach to natural language processing",
      "author" : [ "A.L. Berger", "V.J. Della Pietra", "S.A. Della Pietra" ],
      "venue" : "Computational Linguistics,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1996
    }, {
      "title" : "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms",
      "author" : [ "Michael Collins" ],
      "venue" : "In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2002
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira" ],
      "venue" : "In Proceedings of the Eighteenth International Conference on Machine Learning,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2001
    }, {
      "title" : "Chinese part-of-speech tagging: one-at-a-time or all-atonce? word-based or character-based",
      "author" : [ "H.T. Ng", "J.K. Low" ],
      "venue" : "In Proceedings of EMNLP,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2004
    }, {
      "title" : "Chinese segmentation and new word detection using conditional random fields",
      "author" : [ "F. Peng", "F. Feng", "A. McCallum" ],
      "venue" : "Proceedings of the 20th international conference on Computational Linguistics,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2004
    }, {
      "title" : "FudanNLP: A toolkit for Chinese natural language processing",
      "author" : [ "Xipeng Qiu", "Qi Zhang", "Xuanjing Huang" ],
      "venue" : "In Proceedings of Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2013
    }, {
      "title" : "Chinese word segmentation as character tagging",
      "author" : [ "N. Xue" ],
      "venue" : "Computational Linguistics and Chinese Language Processing,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2003
    }, {
      "title" : "The Penn Chinese TreeBank: Phrase structure annotation of a large corpus",
      "author" : [ "Naiwen Xue", "Fei Xia", "Fu-Dong Chiou", "Martha Palmer" ],
      "venue" : "Natural language engineering,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2005
    }, {
      "title" : "Chinese comma disambiguation for discourse analysis. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 786–794",
      "author" : [ "Yaqin Yang", "Nianwen Xue" ],
      "venue" : "Association for Computational Linguistics,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "The popular method is to regard these two tasks as sequence labeling problem [7, 5], which can be handled with supervised learning algorithms such as Maximum Entropy (ME) [1], averaged perceptron [2], Conditional Random Fields (CRF)[3].",
      "startOffset" : 77,
      "endOffset" : 83
    }, {
      "referenceID" : 4,
      "context" : "The popular method is to regard these two tasks as sequence labeling problem [7, 5], which can be handled with supervised learning algorithms such as Maximum Entropy (ME) [1], averaged perceptron [2], Conditional Random Fields (CRF)[3].",
      "startOffset" : 77,
      "endOffset" : 83
    }, {
      "referenceID" : 0,
      "context" : "The popular method is to regard these two tasks as sequence labeling problem [7, 5], which can be handled with supervised learning algorithms such as Maximum Entropy (ME) [1], averaged perceptron [2], Conditional Random Fields (CRF)[3].",
      "startOffset" : 171,
      "endOffset" : 174
    }, {
      "referenceID" : 1,
      "context" : "The popular method is to regard these two tasks as sequence labeling problem [7, 5], which can be handled with supervised learning algorithms such as Maximum Entropy (ME) [1], averaged perceptron [2], Conditional Random Fields (CRF)[3].",
      "startOffset" : 196,
      "endOffset" : 199
    }, {
      "referenceID" : 2,
      "context" : "The popular method is to regard these two tasks as sequence labeling problem [7, 5], which can be handled with supervised learning algorithms such as Maximum Entropy (ME) [1], averaged perceptron [2], Conditional Random Fields (CRF)[3].",
      "startOffset" : 232,
      "endOffset" : 235
    }, {
      "referenceID" : 8,
      "context" : "58% in the popular division [9] of the Chinese Treebank (CTB 6.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 7,
      "context" : "0) dataset [8], while the OOV rate of our dataset is 7.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 3,
      "context" : "For the joint word segmentation and POS tagging, the state-of-the-art method is also based on sequence learning with cross-labels, which can avoid the problem of error propagation and achieve higher performance on both subtasks[4].",
      "startOffset" : 227,
      "endOffset" : 230
    }, {
      "referenceID" : 5,
      "context" : "Here, we use two popular open source toolkits for sequence labeling task as the baseline systems: FNLP2 [6] and CRF++3.",
      "startOffset" : 104,
      "endOffset" : 107
    } ],
    "year" : 2015,
    "abstractText" : "In this paper, we give an overview for the shared task at the 4th CCF Conference on Natural Language Processing & Chinese Computing (NLPCC 2015): Chinese word segmentation and part-of-speech (POS) tagging for micro-blog texts. Different with the popular used newswire datasets, the dataset of this shared task consists of the relatively informal micro-texts. The shared task has two sub-tasks: (1) individual Chinese word segmentation and (2) joint Chinese word segmentation and POS Tagging. Each subtask has three tracks to distinguish the systems with different resources. We first introduce the dataset and task, then we characterize the different approaches of the participating systems, report the test results, and provide a overview analysis of these results. An online system is available for open registration and evaluation at http://nlp.fudan.edu.cn/nlpcc2015.",
    "creator" : "LaTeX with hyperref package"
  }
}