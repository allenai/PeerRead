{
  "name" : "1306.4040.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "An Algorithm to Find Optimal Attack Paths in Nondeterministic Scenarios",
    "authors" : [ "Carlos Sarraute", "Gerardo Richarte", "Jorge Lucángeli Obes" ],
    "emails" : [ "carlos@corest.com", "gera@corest.com", "jlucangeli@dc.uba.ar" ],
    "sections" : [ {
      "heading" : "Categories and Subject Descriptors",
      "text" : "C.2.0 [Computer-Communication Networks]: General— Security and protection; I.2.8 [Artificial Intelligence]: Problem Solving, Control Methods, and Search—Plan execution, formation, and generation; K.6.5 [Management of Computing and Information Systems]: Security and Protection—Unauthorized access; K.6.m [Management of Computing and Information Systems]: Miscellaneous—Security\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. AISec’11, October 21, 2011, Chicago, Illinois, USA. Copyright 2011 ACM 978-1-4503-1003-1/11/10 ...$10.00."
    }, {
      "heading" : "General Terms",
      "text" : "Security"
    }, {
      "heading" : "Keywords",
      "text" : "Network security, exploit, automated pentesting, attack planning"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Penetration testing has become one of the most trusted ways of assessing the security of networks large and small. The result of a penetration test is a repeatable set of steps that result in the compromise of particular assets in the network. Penetration testing frameworks have been developed to facilitate the work of penetration testers and make the assessment of network security more accessible to nonexpert users [6]. The main tools available are the commercial products Core Impact (since 2001), Immunity Canvas (since 2002), and the open source project Metasploit (launched in 2003, owned by Rapid7 since 2009). These tools have the ability to launch actual exploits for vulnerabilities, contributing to expose risk by conducting an attack in the same way an external attacker would [3].\nAs pentesting tools have evolved and have become more complex – covering new attack vectors, and shipping increasing numbers of exploits and information gathering techniques – the problem of controlling the pentest framework successfully has become an important question. A computergenerated plan for an attack would isolate the user from the complexity of selecting suitable exploits for the hosts in the target network. In addition, a suitable model to represent these attacks would help to systematize the knowledge gained during manual penetration tests performed by expert users, making pentesting frameworks more accessible to non-experts.\nA natural way to address this issue is as an attack planning problem. This problem was introduced to the AI planning community by Boddy et al. as the “Cyber Security” domain [5]. In the pentesting industry, Lucangeli et al. proposed a solution based on modeling the actions and assets in the PDDL language,1 and using off-the-shelf planners to generate attack plans [16]. Herein we are concerned with the specific context of regular automated pentesting, as in “Core Insight Enterprise” tool. We will use the term “attack planning” in that sense.\n1PDDL stands for Planning Domain Definition Language. Refer to [10] for a specification of PDDL 2.1.\nar X\niv :1\n30 6.\n40 40\nv1 [\ncs .C\nR ]\n1 7\nJu n\n20 13\nRecently, a model based on partially observable Markov decision processes (POMDP) was proposed, in part by one of the authors [25]. This grounded the attack planning problem in a well-researched formalism, and provided a precise representation of the attacker’s uncertainty with respect to the target network. In particular, the information gathering phase was modeled as an integral part of the planning problem. However, as the authors show, this solution does not scale to medium or large real-life networks.\nIn this paper, we take a different direction: the uncertainty about the results of the actions is modeled as a probability of success of each action, whereas in [25] the uncertainty is modeled as a distribution of probabilities over the states. This allows us to produce an efficient planning algorithm, specifically designed for this problem, that achieves industrial-scale runtime performance.\nOf course planning in the probabilistic setting is far more difficult than in the deterministic one. We do not propose a general algorithm, but a solution suited for the scenarios that need to be solved in a real world penetration test. The computational complexity of our planning solution is O(n logn), where n is the total number of actions in the case of an attack tree (with fixed source and target hosts), and O(M2 · n logn) where M is the number of machines in the case of a network scenario. With our implementation, we were able to solve planning in scenarios with up to 1000 hosts distributed in different networks.\nWe start with a brief review of the attack model in Section 2, then continue with a presentation of two “primitives” in Sections 3 and 4. These primitives are applied in more general settings in Sections 5 and 6. Section 7 shows experimental results from the implementation of these algorithms. We conclude with some ideas for future work."
    }, {
      "heading" : "2. THE ATTACK MODEL",
      "text" : "We provide below some background on the conceptual model of computer attacks that we use, for more details refer to [4, 11, 22, 24]. This model is based on the concepts of assets, goals, agents and actions. In this description, an attack involves a set of agents, executing sequences of actions, obtaining assets (which can be information or actual modifications of the real network and systems) in order to reach a set of goals.\nAn asset can represent anything that an attacker may need to obtain during the course of an attack, including the actual goal. Examples of assets: information about the Operating System (OS) of a host H; TCP connectivity with host H on port P ; an Agent installed on a given host H. To install an agent means to break into a host, take control of its resources, and eventually use it as pivoting stone to continue the attack by launching new actions based from that host.\nThe actions are the basic steps which form an attack. Actions have requirements (also called preconditions) and a result: the asset that will be obtained if the action is successful. For example, consider the exploit IBM Tivoli Storage Manager Client Remote Buffer Overflow2 for the vulnerabilities in dsmagent described by CVE-2008-4828. The result\n2The particular implementations that we have studied are the exploit modules for Core Impact and Core Insight Enterprise, although the same model can be applied to other implementations, such as Metasploit.\nof this action is to install an agent, and it requires that the OS of the target host is Windows 2000, Windows XP, Solaris 10, Windows 2003, or AIX 5.3. In this model, all the exploits (local, remote, client-side, webapps) are represented as actions. Other examples of actions are: TCP Network Discovery, UDP Port Scan, DCERPC OS Detection, TCP Connectivity Probe.\nThe major differences between the attack model used in this work and the attack graphs used in [2, 14, 15, 20, 23, 27] are twofold: to improve the realism of the model, we consider that the actions can produce numerical effects (for example, the expected running time of each action); and that the actions have a probability of success (which models the uncertainty about the results of the action)."
    }, {
      "heading" : "Deterministic Actions with Numerical Effects",
      "text" : "In the deterministic case, the actions and assets that compose a specific planning problem can be successfully represented in the PDDL language. This idea was proposed in [26] and further analyzed in [16]. The assets are represented as PDDL predicates, and the actions are translated as PDDL operators. The authors show how this PDDL representation allowed them to integrate a penetration testing tool with an external planner, and to generate attack plans in realistic scenarios. The planners used – Metric-FF [13] and SGPlan [7] – are state-of-the-art planners able to handle numerical effects.\nFig. 1 shows an example of a PDDL action: an exploit for the IBM Tivoli vulnerability, that will attempt to install an agent on target host t from an agent previously installed on the source host s. To be successful, this exploit requires that the target runs a specific OS, has the service mil-204547001 running and listening on port 1581.\n(:action IBM_Tivoli_Storage_Manager_Client_Exploit :parameters (?s - host ?t - host) :precondition (and (compromised ?s) (and (has_OS ?t Windows) (has_OS_edition ?t Professional) (has_OS_servicepack ?t Sp2) (has_OS_version ?t WinXp) (has_architecture ?t I386))\n(has_service ?t mil-2045-47001) (TCP_connectivity ?s ?t port1581)\n) :effect(and (installed_agent ?t high_privileges) (increase (time) 4) ))\nFigure 1: Exploit represented as PDDL action.\nThe average running times of the exploits are measured by executing all the exploits of the penetration testing tool in a testing lab. More specifically, in Core’s testing lab there are more than 748 virtual machines with different OS and installed applications, where all the exploits of Core Impact are executed every night [21]."
    }, {
      "heading" : "Actions’ Costs",
      "text" : "The execution of an action has a multi-dimensional cost. We detail below some values that can be measured (and optimized in an attack):\nExecution time: Average running time of the action.\nNetwork traffic: The amount of traffic sent over the network increases the level of noise produced.\nIDS detection: Logs lines generated and alerts triggered by the execution of the action increase the noise produced.\nHost resources: The execution of actions will consume resources of both the local and remote host, in terms of CPU, RAM, hard disc usage, etc.\nTraceability of the attack: Depends on the number of intermediate hops and topological factors.\nZero-day exploits: Exploits for vulnerabilities that are not publicly known are a valuable resource, that should be used only when other exploits have failed (the attacker usually wants to minimize the use of “0-days”).\nIn our experiments, we have chosen to optimize the expected execution time. In the context of regular penetration tests, minimizing the expectation of total execution time is a way of maximizing the amount of exploits successfully launched in a fixed time frame (pentests are normally executed in a bounded time period).\nHowever, the same techniques can be applied to any other scalar cost, for example to minimize the noise produced by the actions (and the probability of being detected)."
    }, {
      "heading" : "Probabilistic Actions",
      "text" : "Another way to add realism to the attack model is to consider that the actions are nondeterministic. This can be modeled by associating probabilities to the outcomes of the actions. In the case of an exploit, the execution of the exploit can be successful (in that case the attacker takes control of the target machine) or a failure. This is represented by associating a probability of success to each exploit.\nThe probability of success is conditional: it depends on the environment conditions. For example, the IBM Tivoli exploit for CVE-2008-4828 is more reliable (has a higher probability of success) if the OS is Solaris since it has no heap protection, the stack is not randomized and is executable by default. Alternatively, the exploit is less reliable (has a lower probability of success) if the OS is Windows XP SP2 or Windows 2003 SP1, with Data Execution Prevention (DEP) enabled. On Windows Vista, the addition of Address Space Layout Randomization (ASLR) makes the development of an exploit even more difficult, and diminishes its probability of success. In practice, the probability of success of each exploit is measured by exhaustively executing the exploit against a series of targets, covering a wide range of OS and application versions.\nAlthough it improves the realism of the model, considering probabilistic actions also makes the planning problem more difficult. Using general purpose probabilistic planners did not work as in the deterministic case; for instance, we experimented with Probabilistic-FF [8] with poor results, since it was able to find plans in only very small cases.\nIn the rest of this paper, we will study algorithms to find optimal attack paths in scenarios of increasing difficulty. We first describe two primitives, and then apply them in the context of regular automated pentesting. In these scenarios we make an additional hypothesis: the independence of the actions. Relaxing this hypothesis is a subject for future work.\n3. THE CHOOSE PRIMITIVE We begin with the following basic problem. Suppose that the attacker (i.e. pentester) wants to gain access to the credit cards stored in a database server H by installing a system agent. The attacker has a set of n remote exploits that he can launch against that server. These exploits result in the installation of a system agent when successful (see Fig. 2).\nIn this scenario, the attacker has already performed information gathering about the server H, collecting a list of open/closed ports, and running an OS detection action such as Nmap. The pentesting tool used provides statistics on the probability of success and expected running time for each exploit in the given conditions.3 The attacker wants to minimize the expected execution time of the whole attack. A more general formulation follows:\nProblem 1. Let g be a fixed goal, and let {A1, . . . , An} be a set of n independent actions whose result is g. Each action Ak has a probability of success pk and expected cost tk. Actions are executed until an action is successful and provides the goal g (or all the actions fail). Task: Find the order in which the actions must be executed in order to minimize the expected total cost.\nWe make the simplifying assumption that the probability of success of each action is independent from the others. If the actions are executed in the order A1, . . . , An, using the notation pi = 1− pi, the expected cost can be written as\nT{1...n} = t1 + p1 t2 + . . . + p1 p2 . . . pn−1 tn. (1)\nThe probability of success is given by\nP{1...n} = p1 + p1 p2 + p1 p2 p3 + . . . + p1 . . . pn−1 pn,\nand the complement P{1...n} = p1 p2 . . . pn. In particular this shows that the total probability of success does not depend on the order of execution.\nEven though this problem is very basic, we didn’t find references to its solution. This is why we give below some details on the solution that we found.\nLemma 1. Let A1, . . . , An be actions such that t1/p1 6 t2/p2 6 . . . 6 tn/pn. Then\nT{1...n−1} P{1...n−1} 6 tn pn .\nProof. We prove it by induction. The case with two actions is trivial, since we know by hypothesis that t1/p1 6 t2/p2. For the inductive step, suppose that the proposition\n3In our experiments we used the database of tests of Core Impact and Core Insight Enterprise.\nholds for n − 1 actions. Consider the first three actions A1, A2, A3. The inequality\nT{12} P{12} 6 t3 p3\nholds if and only if t2/p2 6 t3/p3. So the first two actions can be considered as a single action A12 with expected cost (e.g. running time) T{12} and probability of success P{12}. We have reduced to the case of n − 1 actions, and we can use the induction hypothesis to conclude the proof.\nProposition 1. A solution to Problem 1 is to sort the actions according to the coefficient tk/pk (in increasing order), and to execute them in that order. The complexity of finding an optimal plan is thus O(n logn).\nProof. We prove it by induction. We begin with the case of two actions Ai and Aj such that ti/pi 6 tj/pj . It follows easily that −pitj 6 −pjti and that\nti + (1− pi) tj 6 tj + (1− pj) ti.\nFor the inductive step, suppose for the moment that the actions are numbered so that t1/p1 6 . . . 6 tn/pn, and that the proposition holds for all sets of n − 1 actions. We have to prove that executing A1 first is better that executing any other action Ak for all k 6= 1. We want to show that\nt1 + ∑\n26i6n\nti · ∏\n16j6i−1\npj\n6 tk + ∑\n16i6n, i 6=k\nti · pk · ∏\n16j6i−1, j 6=k\npj .\nNotice that in the two previous sums, the coefficients of tk+1, . . . , tn are equal in both expressions. They can be simplified, and using notations previously introduced, the inequality can be rewritten\nT{1...k−1} + P{1...k−1} tk 6 tk + pk T{1...k−1}\nwhich holds if and only if\nT{1...k−1} P{1...k−1} 6 tk pk\nwhich is true by Lemma 1. We have reduced the problem to sorting the coefficients tk/pk. The complexity is that of making the n divisions tk/pk and sorting the coefficients. Thus it is O(n + n logn) = O(n logn).\nWe call this the choose primitive because it tells you, given a set of actions, which action to choose first: the one that has the smallest t/p value. In particular, it says that you should execute first the actions with smaller cost (e.g. runtime) or higher probability of success, and precisely which is the trade-off between these two dimensions.\nThe problem of choosing the order of execution within a set of exploits is very common in practice. In spite of that, the automation methods currently implemented in penetration testing frameworks offer an incomplete solution,4 over which the one proposed here constitutes an improvement. 4As of July 2011, Immunity Canvas [1] doesn’t provide automated execution of exploits; Metasploit [17] has a feature called “autopwn” that launches all the exploits available for the target ports in arbitrary order; Core Impact Pro launches first a set of “fast” exploits and then “brute-force” exploits [26], but arbitrary order is used within each set; Core Insight Enterprise uses planning techniques based on a PDDL description [16] that takes into account the execution time but not the probability of success of the exploits.\n4. THE COMBINE PRIMITIVE"
    }, {
      "heading" : "Predefined Strategies",
      "text" : "We now consider the slightly more general problem where the goal g can be obtained by predefined strategies. We call strategy a group of actions that must be executed in a specific order. The strategies are a way to incorporate the expert knowledge of the attacker in the planning system (cf. the opening moves in chess). This idea has been used in the automation of pentesting tools, see [26].\nFor example consider an attacker who has installed an agent with low privileges on a host H running Windows XP, and whose goal is to obtain system privileges on that host. The attacker has a set of n predefined strategies to perform this privilege escalation (see Fig. 3). An example of a strategy is: refine knowledge of the OS version; verify that the edition is Home or Professional, with SP2 installed; get users and groups; then launch the local exploit Microsoft NtUserMessageCall Kernel Privilege Escalation that (ab)uses the vulnerability CVE-2008-1084. More generally:\nProblem 2. Let g be a fixed goal, and {G1, . . . , Gn} a set of n strategies, where each strategy Gk is a group of ordered actions. For a strategy to be successful, all its actions must be successful. As in Problem 1, the task is to minimize the expected total cost.\nIn this problem, actions are executed sequentially, choosing at each step one action from one group, until the goal g is obtained. Considering only one strategy G, we can calculate its expected cost and probability of success. Suppose the actions of G are {A1, . . . , An} and are executed in that order. Then the expected cost (e.g. expected runtime) of the group G is\nTG = t1 + p1 t2 + p1 p2 t3 + . . . + p1 p2 . . . pn−1 tn\nand, since all the actions must be successful, the probability of success of the group is simply PG = p1 p2 . . . pn.\nProposition 2. A solution to this problem is to sort the strategies according to the coefficient TG/PG (smallest value first), and execute them in that order. For each strategy group, execute the actions until an action fails or all the actions are successful.\nProof. In this problem, an attack plan could involve choosing actions from different groups without completing\nall the actions of each group. But it is clear that this cannot happen in an optimal plan.5\nSo an optimal attack plan consists in choosing a group and executing all the actions of that group. Since the actions of each group G are executed one after the other, they can be considered as a single action with probability PG and expected time TG. Using the choose primitive, it follows that groups should be ordered according to the coefficients TG/PG."
    }, {
      "heading" : "Multiple Groups of Actions",
      "text" : "We extend the previous problem to consider groups of actions bounded by an AND relation (all the actions of the group must be successful in order to obtain the result g), but where the order of the actions is not specified. The difference with Problem 2 is that now we must determine the order of execution within each group.\nFig. 4 shows an example of this situation. A System Agent can be installed by using a Remote exploit, a Client-side exploit or a SQL injection in a web application. Each of these actions has requirements represented as assets, which can be fulfilled by the actions represented on the second layer. For example, before executing the Remote exploit, the attacker must run a Host probe (to verify connectivity with the target host), Port probe (to verify that the target port of the exploit is open), and an OS Detection module (to verify the OS of the target host).\nProblem 3. Same as Problem 2, except that we have n groups {G1, . . . , Gn} of unordered actions. If all the actions in a group are successful, the group provides the result g.\nProposition 3. Let G = {A1, . . . , An} be a group of actions bounded by an AND relation. To minimize the expected total cost, the actions must be ordered according to the coefficient tk/(1− pk).\n5Suppose that there are only two groups GA and GB , whose actions are {A1, . . . , As} and {B1, . . . , Bt} respectively. Suppose that in the optimal plan As precedes Bt. Suppose also that the execution of an action Bj 6= Bt precedes the execution of As. Executing Bj will not result in success (that requires executing Bt as well), and it will delay the execution of As by the expected running time of Bj . Thus to minimize the expected total running time, a better solution can be obtained by executing Bj after the execution of As. This contradiction shows that all the actions of GB must be executed after As in an optimal solution. This argument can be easily extended to any number of groups.\nProof. If the actions are executed in the order A1, . . . , An, then the expected cost is\nTG = t1 + p1 t2 + . . . + p1 p2 . . . pn−1 tn (2)\nThis expression is very similar to equation (1). The only difference is that costs are multiplied by pk instead of pk. So in this case, the optimal solution is to order the actions according to the coefficient tk/pk = tk/(1− pk).\nIntuitively the actions that have higher probability of failure have higher priority, since a failure ends the execution of the group. The coefficient tk/(1− pk) represents a trade-off between cost (time) and probability of failure.\nWrapping up the previous results, to solve Problem 3, first order the actions in each group according to the coefficient t/(1− p) in increasing order. Then calculate for each group G the values TG and PG. Order the groups according to the coefficient TG/PG, and select them in that order. For each group, execute the actions until an action fails or all the actions are successful.\nWe call it the combine primitive, because it tells you how to combine a group of actions and consider them (for planning purposes) as a single action with probability of success PG and expected running time TG."
    }, {
      "heading" : "5. USING THE PRIMITIVES IN AN ATTACK TREE",
      "text" : "We apply below the choose and the combine primitives to a probabilistic attack tree, where the nodes are bounded by AND relations and OR relations. The tree is composed of two types of nodes, distributed in alternating layers of asset nodes and action nodes (see Fig. 5)."
    }, {
      "heading" : "Asset",
      "text" : "An asset node is connected by an OR relation to all the actions that provide this asset: for example, an Agent asset is connected to the Exploit actions that may install an agent on the target host.\nAn action node is connected by an AND relation to its requirements: for example, the local exploit Microsoft NtUserMessageCall Kernel Privilege Escalation requires an agent asset (with low level privileges) on the target host H, and a Windows XP OS asset for H.\nThe proposed solution is obtained by composing the primitives from previous sections. In the AND-OR tree, the leaves that are bounded by an AND relation can be considered as a single node. In effect, using the combine primitive, that group G can be considered as a single action with compound probability of success PG and execution time TG.\nThe leaves that are bounded by an OR relation can also be (temporarily) considered as a single node. In effect, in an optimal solution, the node that minimizes the t/p coefficient will be executed first (using the choose primitive), and be considered as the cost of the group in a single step plan.\nBy iteratively reducing groups of nodes, we build a single path of execution that minimizes the expected cost. After executing a step of the plan, the costs may be modified and the shape of the graph may vary. Since the planning algorithm is very efficient, we can replan after each execution and build a new path of execution. We are assured that before each execution, the proposed attack plan is optimal given the current environment knowledge."
    }, {
      "heading" : "Constructing the Tree",
      "text" : "We briefly describe how to construct a tree beginning with an agent asset (e.g. the objective is to install an agent on a fixed machine). Taking this goal as root of the tree, we recursively add the actions that can complete the assets that appear in the tree, and we add the assets required by each action.\nTo ensure that the result is a tree and not a DAG, we make an additional independence assumption: the assets required by each action are considered as independent (i.e. if an asset is required by two different actions, it will appear twice in the tree).\nThat way we obtain an AND-OR tree with alternating layers of asset nodes and action nodes (as the one in Fig. 5). The only actions added are Exploits, TCP/UDP Connectivity checks, and OS Detection modules. These actions don’t have as requirements assets that have already appeared in the tree, in particular the tree only has one agent asset (the root node of the tree). So, by construction, we are assured that no loops will appear, and that the depth of the tree is very limited.\nWe construct the tree in this top-down fashion, and as we previously saw, we can solve it bottom-up to obtain as output the compound probability of success and the expected running time of obtaining the goal agent."
    }, {
      "heading" : "6. THE GRAPH OF DISTINGUISHED ASSETS",
      "text" : "In this section we use the previous primitives to build an algorithm for attack planning in arbitrary networks, by making an additional assumption of independence between machines. First we distinguish a class of assets, namely the assets related with agents. We refer to them as distinguished assets. At the PDDL level, the predicates associated with the agents are considered as a separate class.\nPlanning is done in two different abstraction levels: in the first level, we evaluate the cost of compromising one target distinguished asset from one fixed source distinguished asset. More concretely, we compute the cost and probability of obtaining a target agent given a source agent. At this level, the attack plan must not involve a third agent. The algorithm at the first level is thus to construct the attack tree and compute an attack plan as described in Section 5.\nAt the second level, we build a directed graph G = (V, E) where the nodes are distinguished assets (in our scenario, the hosts in the target network where we may install agents), and the edges are labeled with the compound probability and expected time obtained at the first level. Given this\ngraph, an initial asset s ∈ V (the local agent of the attacker) and a final asset g ∈ V (the goal of the attack), we now describe two algorithms to find a path that approximates the minimal expected time of obtaining the goal g.\nThe first algorithm is a modification of Floyd-Warshall’s algorithm to find shortest paths in a weighted graph. Let M = |V| be the number of machines in the target network. By executing M2 times the first level procedure, we obtain two functions: the first is Prob(i, j) which returns the compound probability of obtaining node j from node i (without intermediary hops), or 0 if that is not possible in the target network; the second is T ime(i, j) which returns the expected time of obtaining node j directly from node i, or +∞ if that is not possible. The procedure is described in Algorithm 1.\nAlgorithm 1 Modified Floyd-Warshall\nP [i, j]← Prob(i, j) ∀ 1 ≤ i, j ≤M T [i, j]← T ime(i, j) ∀ 1 ≤ i, j ≤M for k = 1 to M do\nfor i = 1 to M do\nfor j = 1 to M do\nT ′ ← T [i, k] + P [i, k]× T [k, j] P ′ ← P [i, k]× P [k, j] if T ′/P ′ < T [i, j]/P [i, j] then\nT [i, j]← T ′ P [i, j]← P ′\nreturn 〈T, P 〉\nWhen the execution of this algorithm finishes, for each i, j the matrices contain the compound probability P [i, j] and the expected time T [i, j] of obtaining the node j starting from the node i. This holds in particular when i = s (the source of the attack) and j = g (the goal of the attack). The attack path is reconstructed just as in the classical FloydWarshall algorithm.\nIn a similar fashion, Dijkstra’s shortest path algorithm can be modified to use the choose and combine primitives. See the description of Algorithm 2.\nAlgorithm 2 Modified Dijkstra’s algorithm\nT [s] = 0, P [s] = 1 T [v] = +∞, P [v] = 0 ∀v ∈ V, v 6= s S ← ∅ Q← V (where Q is a priority queue) while Q 6= ∅ do\nu← arg minx∈Q T [x]/P [x] Q← Q\\{u}, S ← S ∪ {u} for all v ∈ V\\S adjacent to u do\nT ′ = T [u] + P [u]× T ime(u, v) P ′ = P [u]× Prob(u, v) if T ′/P ′ < T [v]/P [v] then\nT [v]← T ′ P [v]← P ′\nreturn 〈T, P 〉\nWhen execution finishes, the matrices contain the compound probability P [v] and the expected time T [v] of obtaining the node v starting from the node s. Using the modified Dijkstra’s algorithm has the advantage that its complexity is\nO(M2) instead of O(M3) for Floyd-Warshall. Let n be the number of actions that appear in the attach trees, this gives us that the complexity of the complete planning solution is O(M2 · n logn + M2) = O(M2 · n logn)."
    }, {
      "heading" : "7. OUR IMPLEMENTATION",
      "text" : "We have developed a proof-of-concept implementation of these ideas in the Python language. This planner takes as input a description of the scenario in the PPDDL language, an extension of PDDL for expressing probabilistic effects [28].\nOur main objective was to build a probabilistic planner able to solve scenarios with 500 machines, which was the limit reached with classical (deterministic) planning solutions in [16]. Additionally we wanted to tame memory complexity, which was the limiting factor. The planner was integrated with the pentesting framework Core Impact, using the procedures previously developed for the work [16]. The architecture of this solution is described in Fig. 6.\nThis planner solves the planning problem by breaking it into two levels as described in Section 6. On the higher level, a graph representation of goal objects is built. More concretely, there is a distinguished node for each host. The directed edges in this graph are obtained by carrying out the tree procedure described in Section 5, obtaining a value for the probability and the cost of obtaining the predicate represented by the target node, when the predicate represented by the source node is true.\nThe final plan can then be determined by using the modified versions of Dijkstra and Floyd-Warshall algorithms. The figures that follow show the planner running time using the modified Dijkstra’s algorithm."
    }, {
      "heading" : "Testing and Performance",
      "text" : "The experiments were run on a machine with an Intel Core2 Duo CPU at 2.4 GHz and 8 GB of RAM. We focused our performance evaluation on the number of machines M in the attacked network. We generated a network consisting of five subnets with varying number of machines, all joined to one main network to which the attacker initially has access.\nFig. 7 shows the memory consumption of this planning solution, which clearly grows linearly with M . Our current implementation manages to push the network size limit up to 1000 machines, and brings memory consumption under control.6 For M = 1000, we are using less than 1 GB of\n6By contrast, in [16] the hard limit was memory: in scenarios with 500 machines we ran out of memory in a computer with 8 GB of RAM. The memory consumption growth was clearly\nRAM, with a planner completely written in Python (not optimized in terms of memory consumption).\nFig. 8 shows the growth of solver running time, which seems clearly quadratic, whereas in [16] the growth was exponential. It should be noted however that, comparing only up to 500 machines, running times are slightly worse than those of the solution based on deterministic planners. This can be improved: since our planner is written in Python, a reasonable implementation in C of the more CPU intensive loops should allow us to lower significantly the running time.\nAnd of course we added a notion of probability of success that wasn’t present before. As a comparison, in another approach that accounts for the uncertainty about the attacker’s actions [25], the authors use off-the-shelf solvers, managing to solve scenarios with up to 7 machines – and are thus still far from the network sizes reached here.\nBoth curves are compared in Fig. 9 showing the quadratic growth of solver runtime. In the testing scenarios, the nodes are fully connected, so we have to solve a quadratic number of attack trees. This figure also confirms in practice the computed complexity.\nAn interesting characteristic of the solution proposed is that it is inherently parallelizable. The main workload are the M2 executions of the first level procedure of Section 6. This could be easily distributed between CPUs or GPUs to obtain a faster planner. Another possible improvement is to\nexponential, for instance 400 machines used 4 GB of RAM. This was difficult to scale up.\nrun the planner “in the cloud” with the possibility of adding processors on demand."
    }, {
      "heading" : "8. RELATED WORK",
      "text" : "Early work on attack graph solving relied on model checking techniques [15, 27], with their inherent scalability restrictions; or on monotonicity assumptions [2, 18, 19] that are not able to express situations in which compromised resources are lost due to crashes, detection or other unforeseen circumstances.\nThe first application of planning techniques and PDDL solving for the security realm was [5], however this application was not focused on finding actual attack paths or driving penetration testing tools. In [12] attack paths are generated from PDDL description of networks, hosts and exploits, although the scenarios studied do not cover realistic scales. Previous work by the authors [16] addresses this limitation by solving scenarios with up 500 machines, and feeding the generated attack plans to guide a penetration testing tool. However, this work does not include probabilistic considerations. Recent work [9] also manages to provide attack paths to a penetration testing tool, in this case the Metasploit Framework, but again does not include probabilistic considerations.\nPrevious work by one of the authors [25] takes into account the uncertainty about the result of the attacker’s actions. This POMDP-based model also accounts for the uncertainty about the target network, addressing information gathering as an integral part of the attack, and providing a comprehensive notion of attack planning under uncertainty. However, as previously stated, this solution does not scale to medium or large real-life networks."
    }, {
      "heading" : "9. SUMMARY AND FUTURE WORK",
      "text" : "We have shown in this paper an extension of established attack graphs models, that incorporates probabilistic effects, and numerical effects (e.g. the expected running time of the actions). This model is more realistic than the deterministic setting, but introduces additional difficulties to the planning problem. We have demonstrated that under certain assumptions, an efficient algorithm exists that provides optimal attack plans with computational complexity O(n logn), where n is the number of actions and assets in the case of an attack\ntree (between two fixed hosts), and O(M2 ·n logn) where M is the number of machines in the case of a network scenario.\nOver the last years, the difficulties that arose in our research in attack planning were related to the exponential nature of planning algorithms (especially in the probabilistic setting), and our efforts were directed toward the aggregation of nodes and simplification of the graphs, in order to tame the size and complexity of the problem. Having a very efficient algorithm in our toolbox gives us a new direction of research: to refine the model, and break down the actions in smaller parts, without fear of producing an unsolvable problem.\nA future step in this research is thus to analyze and divide the exploits into basic components. This separation gives a better probability distribution of the exploit execution. For example, the Debian OpenSSL Predictable Random Number Generation Exploit – which exploits the vulnerability CVE-2008-0166 reported by Luciano Bello – brute forces the 32,767 possible keys. Each brute forcing iteration can be considered as a basic action, and be inserted independently in the attack plan. Since the keys depend on the Process ID (PID), some keys are more probable than others.7 So the planner can launch the Debian OpenSSL PRNG exploit, execute brute forcing iterations for the more probable keys, switch to others exploits and come to back to the Debian PRNG exploit if the others failed. This finer level of control over the exploit execution should produce significant gains in the total execution time of the attack.\nOther research directions in which we are currently working are to consider actions with multidimensional numeric effects (e.g. to minimize the expected running time and generated network traffic simultaneously); and to extend the algorithm to solve probabilistic attack planning in Directed Acyclic Graphs (DAG) instead of trees. In this setting, an asset may influence the execution of several actions. This relaxes the independence assumption of Sections 4 and 5. Although finding a general algorithm that scales to the network sizes that we consider here seems a difficult task, we believe that efficient algorithms specifically designed for network attacks scenarios can be found."
    }, {
      "heading" : "Acknowledgments",
      "text" : "Thanks to Ariel Futoransky and Ariel Waissbein for their contributions and insightful discussions."
    }, {
      "heading" : "10. REFERENCES",
      "text" : "[1] D. Aitel. An introduction to MOSDEF. In Black Hat\nBriefings, USA, 2004.\n[2] P. Ammann, D. Wijesekera, and S. Kaushik. Scalable, graph-based network vulnerability analysis. In Proceedings of the 9th ACM Conference on Computer and Communications Security, pages 217–224. ACM New York, NY, USA, 2002.\n[3] I. Arce and G. McGraw. Why attacking systems is a good idea. IEEE Computer Society - Security & Privacy Magazine, 2(4), 2004.\n[4] I. Arce and G. Richarte. State of the art security from an attacker’s viewpoint. In PacSec Conference, Tokyo, Japan, 2003.\n7The OpenSSL keys generated in vulnerable Debians only depend on the PID. Since Secure Shell usually generates the key in a new installation, PIDs between 2,000 and 5,000 are more probable than the others.\n[5] M. S. Boddy, J. Gohde, T. Haigh, and S. A. Harp. Course of action generation for cyber security using classical planning. In Proc. of ICAPS’05, 2005.\n[6] B. Burns, D. Killion, N. Beauchesne, E. Moret, J. Sobrier, M. Lynn, E. Markham, C. Iezzoni, P. Biondi, J. S. Granick, S. Manzuik, and P. Guersch. Security Power Tools. O’Reilly Media, 2007.\n[7] Y. Chen, B. W. Wah, and C. Hsu. Temporal planning using subgoal partitioning and resolution in SGPlan. J. of Artificial Intelligence Research, 26:369, 2006.\n[8] C. Domshlak and J. Hoffmann. Probabilistic planning via heuristic forward search and weighted model counting. Journal of Artificial Intelligence Research, 30(1):565–620, 2007.\n[9] D. Elsbroek, D. Kohlsdorf, D. Menke, and L. Meyer. Fidius: Intelligent support for vulnerability testing. In Working Notes for the 2011 IJCAI Workshop on Intelligent Security (SecArt), page 58, 2011.\n[10] M. Fox and D. Long. PDDL2. 1: An extension to PDDL for expressing temporal planning domains. Journal of Artificial Intelligence Research, 20(2003):61–124, 2003.\n[11] A. Futoransky, L. Notarfrancesco, G. Richarte, and C. Sarraute. Building computer network attacks. Technical report, CoreLabs, 2003.\n[12] N. Ghosh and S. K. Ghosh. An intelligent technique for generating minimal attack graph. In First Workshop on Intelligent Security (Security and Artificial Intelligence) (SecArt ’09), 2009.\n[13] J. Hoffmann. Extending FF to numerical state variables. In Proceedings of the 15th European Conference on Artificial Intelligence (ECAI-02), pages 571–575, 2002.\n[14] S. Jajodia, S. Noel, and B. O’Berry. Topological analysis of network attack vulnerability. Managing Cyber Threats: Issues, Approaches and Challenges, pages 248–266, 2005.\n[15] S. Jha, O. Sheyner, and J. Wing. Two formal analyses of attack graphs. In 15th IEEE Computer Security Foundations Workshop, 2002. Proceedings, pages 49–63, 2002.\n[16] J. Lucangeli, C. Sarraute, and G. Richarte. Attack Planning in the Real World. In Workshop on Intelligent Security (SecArt 2010), 2010.\n[17] H. D. Moore. Penetration testing automation. In SANS Penetration Testing Summit, 2010.\n[18] S. Noel, M. Elder, S. Jajodia, P. Kalapa, S. OŠHare, and K. Prole. Advances in Topological Vulnerability Analysis. In Proceedings of the 2009 Cybersecurity Applications & Technology Conference for Homeland Security, pages 124–129. IEEE Computer Society, 2009.\n[19] S. Noel and S. Jajodia. Understanding complex network attack graphs through clustered adjacency matrices. In Proceedings of the 21st Annual Computer Security Applications Conference, pages 160–169, 2005.\n[20] C. A. Phillips and L. P. Swiler. A graph-based system for network-vulnerability analysis. In Workshop on New Security Paradigms, pages 71–79, 1998.\n[21] M. Picorelli. Virtualization in software development and QA, 2006. WMWorld 2006.\n[22] G. Richarte. Modern intrusion practices. In Black Hat Briefings, 2003.\n[23] R. Ritchey and P. Ammann. Using model checking to analyze network vulnerabilities. In IEEE Symposium on Security and Privacy, pages 156–165. IEEE Computer Society, 2000.\n[24] F. Russ and D. Tiscornia. Zombie 2.0. In Hack.lu Conference, Luxembourg, 2007.\n[25] C. Sarraute, O. Buffet, and J. Hoffmann. Penetration testing == POMDP planning? In SecArt’11, 2011.\n[26] C. Sarraute and A. Weil. Advances in automated attack planning. In PacSec Conference, Tokyo, Japan, 2008.\n[27] O. Sheyner, J. Haines, S. Jha, R. Lippmann, and J. Wing. Automated generation and analysis of attack graphs. In IEEE Symposium on Security and Privacy, pages 273–284. IEEE Computer Society, 2002.\n[28] H. Younes and M. Littman. PPDDL 1.0: The language for the probabilistic part of IPC-4. In Proc. International Planning Competition, 2004."
    } ],
    "references" : [ {
      "title" : "An introduction to MOSDEF",
      "author" : [ "D. Aitel" ],
      "venue" : "Black Hat Briefings, USA",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Scalable",
      "author" : [ "P. Ammann", "D. Wijesekera", "S. Kaushik" ],
      "venue" : "graph-based network vulnerability analysis. In Proceedings of the 9th ACM Conference on Computer and Communications Security, pages 217–224. ACM New York, NY, USA",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Why attacking systems is a good idea",
      "author" : [ "I. Arce", "G. McGraw" ],
      "venue" : "IEEE Computer Society - Security & Privacy Magazine, 2(4)",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "State of the art security from an attacker’s viewpoint",
      "author" : [ "I. Arce", "G. Richarte" ],
      "venue" : "PacSec Conference, Tokyo, Japan",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Course of action generation for cyber security using classical planning",
      "author" : [ "M.S. Boddy", "J. Gohde", "T. Haigh", "S.A. Harp" ],
      "venue" : "Proc. of ICAPS’05",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Security Power Tools",
      "author" : [ "B. Burns", "D. Killion", "N. Beauchesne", "E. Moret", "J. Sobrier", "M. Lynn", "E. Markham", "C. Iezzoni", "P. Biondi", "J.S. Granick", "S. Manzuik", "P. Guersch" ],
      "venue" : "O’Reilly Media",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Temporal planning using subgoal partitioning and resolution in SGPlan",
      "author" : [ "Y. Chen", "B.W. Wah", "C. Hsu" ],
      "venue" : "J. of Artificial Intelligence Research, 26:369",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Probabilistic planning via heuristic forward search and weighted model counting",
      "author" : [ "C. Domshlak", "J. Hoffmann" ],
      "venue" : "Journal of Artificial Intelligence Research, 30(1):565–620",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Fidius: Intelligent support for vulnerability testing",
      "author" : [ "D. Elsbroek", "D. Kohlsdorf", "D. Menke", "L. Meyer" ],
      "venue" : "Working Notes for the 2011 IJCAI Workshop on Intelligent Security (SecArt), page 58",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "PDDL2",
      "author" : [ "M. Fox", "D. Long" ],
      "venue" : "1: An extension to PDDL for expressing temporal planning domains. Journal of Artificial Intelligence Research, 20",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Building computer network attacks",
      "author" : [ "A. Futoransky", "L. Notarfrancesco", "G. Richarte", "C. Sarraute" ],
      "venue" : "Technical report, CoreLabs",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "An intelligent technique for generating minimal attack graph",
      "author" : [ "N. Ghosh", "S.K. Ghosh" ],
      "venue" : "First Workshop on Intelligent Security (Security and Artificial Intelligence) (SecArt ’09)",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Extending FF to numerical state variables",
      "author" : [ "J. Hoffmann" ],
      "venue" : "Proceedings of the 15th European Conference on Artificial Intelligence (ECAI-02), pages 571–575",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "and B",
      "author" : [ "S. Jajodia", "S. Noel" ],
      "venue" : "O’Berry. Topological analysis of network attack vulnerability. Managing Cyber Threats: Issues, Approaches and Challenges, pages 248–266",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Two formal analyses of attack graphs",
      "author" : [ "S. Jha", "O. Sheyner", "J. Wing" ],
      "venue" : "15th IEEE Computer Security Foundations Workshop, 2002. Proceedings, pages 49–63",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Attack Planning in the Real World",
      "author" : [ "J. Lucangeli", "C. Sarraute", "G. Richarte" ],
      "venue" : "Workshop on Intelligent Security ",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Penetration testing automation",
      "author" : [ "H.D. Moore" ],
      "venue" : "SANS Penetration Testing Summit",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Advances in Topological Vulnerability Analysis",
      "author" : [ "S. Noel", "M. Elder", "S. Jajodia", "P. Kalapa", "S. OŠHare", "K. Prole" ],
      "venue" : "Proceedings of the 2009 Cybersecurity Applications & Technology Conference for Homeland Security, pages 124–129. IEEE Computer Society",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Understanding complex network attack graphs through clustered adjacency matrices",
      "author" : [ "S. Noel", "S. Jajodia" ],
      "venue" : "Proceedings of the 21st Annual Computer Security Applications Conference, pages 160–169",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "A graph-based system for network-vulnerability analysis",
      "author" : [ "C.A. Phillips", "L.P. Swiler" ],
      "venue" : "Workshop on New Security Paradigms, pages 71–79",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Virtualization in software development and QA",
      "author" : [ "M. Picorelli" ],
      "venue" : "WMWorld",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2006
    }, {
      "title" : "Modern intrusion practices",
      "author" : [ "G. Richarte" ],
      "venue" : "Black Hat Briefings",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Using model checking to analyze network vulnerabilities",
      "author" : [ "R. Ritchey", "P. Ammann" ],
      "venue" : "IEEE Symposium on Security and Privacy, pages 156–165. IEEE Computer Society",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Zombie 2.0",
      "author" : [ "F. Russ", "D. Tiscornia" ],
      "venue" : "In Hack.lu Conference,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2007
    }, {
      "title" : "and J",
      "author" : [ "C. Sarraute", "O. Buffet" ],
      "venue" : "Hoffmann. Penetration testing == POMDP planning? In SecArt’11",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Advances in automated attack planning",
      "author" : [ "C. Sarraute", "A. Weil" ],
      "venue" : "PacSec Conference, Tokyo, Japan",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Automated generation and analysis of attack graphs",
      "author" : [ "O. Sheyner", "J. Haines", "S. Jha", "R. Lippmann", "J. Wing" ],
      "venue" : "IEEE Symposium on Security and Privacy, pages 273–284. IEEE Computer Society",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "PPDDL 1.0: The language for the probabilistic part of IPC-4",
      "author" : [ "H. Younes", "M. Littman" ],
      "venue" : "In Proc. International Planning Competition,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "Penetration testing frameworks have been developed to facilitate the work of penetration testers and make the assessment of network security more accessible to nonexpert users [6].",
      "startOffset" : 176,
      "endOffset" : 179
    }, {
      "referenceID" : 2,
      "context" : "These tools have the ability to launch actual exploits for vulnerabilities, contributing to expose risk by conducting an attack in the same way an external attacker would [3].",
      "startOffset" : 171,
      "endOffset" : 174
    }, {
      "referenceID" : 4,
      "context" : "as the “Cyber Security” domain [5].",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 15,
      "context" : "proposed a solution based on modeling the actions and assets in the PDDL language, and using off-the-shelf planners to generate attack plans [16].",
      "startOffset" : 141,
      "endOffset" : 145
    }, {
      "referenceID" : 9,
      "context" : "Refer to [10] for a specification of PDDL 2.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 24,
      "context" : "Recently, a model based on partially observable Markov decision processes (POMDP) was proposed, in part by one of the authors [25].",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 24,
      "context" : "In this paper, we take a different direction: the uncertainty about the results of the actions is modeled as a probability of success of each action, whereas in [25] the uncertainty is modeled as a distribution of probabilities over the states.",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 3,
      "context" : "We provide below some background on the conceptual model of computer attacks that we use, for more details refer to [4, 11, 22, 24].",
      "startOffset" : 116,
      "endOffset" : 131
    }, {
      "referenceID" : 10,
      "context" : "We provide below some background on the conceptual model of computer attacks that we use, for more details refer to [4, 11, 22, 24].",
      "startOffset" : 116,
      "endOffset" : 131
    }, {
      "referenceID" : 21,
      "context" : "We provide below some background on the conceptual model of computer attacks that we use, for more details refer to [4, 11, 22, 24].",
      "startOffset" : 116,
      "endOffset" : 131
    }, {
      "referenceID" : 23,
      "context" : "We provide below some background on the conceptual model of computer attacks that we use, for more details refer to [4, 11, 22, 24].",
      "startOffset" : 116,
      "endOffset" : 131
    }, {
      "referenceID" : 1,
      "context" : "The major differences between the attack model used in this work and the attack graphs used in [2, 14, 15, 20, 23, 27] are twofold: to improve the realism of the model, we consider that the actions can produce numerical effects (for example, the expected running time of each action); and that the actions have a probability of success (which models the uncertainty about the results of the action).",
      "startOffset" : 95,
      "endOffset" : 118
    }, {
      "referenceID" : 13,
      "context" : "The major differences between the attack model used in this work and the attack graphs used in [2, 14, 15, 20, 23, 27] are twofold: to improve the realism of the model, we consider that the actions can produce numerical effects (for example, the expected running time of each action); and that the actions have a probability of success (which models the uncertainty about the results of the action).",
      "startOffset" : 95,
      "endOffset" : 118
    }, {
      "referenceID" : 14,
      "context" : "The major differences between the attack model used in this work and the attack graphs used in [2, 14, 15, 20, 23, 27] are twofold: to improve the realism of the model, we consider that the actions can produce numerical effects (for example, the expected running time of each action); and that the actions have a probability of success (which models the uncertainty about the results of the action).",
      "startOffset" : 95,
      "endOffset" : 118
    }, {
      "referenceID" : 19,
      "context" : "The major differences between the attack model used in this work and the attack graphs used in [2, 14, 15, 20, 23, 27] are twofold: to improve the realism of the model, we consider that the actions can produce numerical effects (for example, the expected running time of each action); and that the actions have a probability of success (which models the uncertainty about the results of the action).",
      "startOffset" : 95,
      "endOffset" : 118
    }, {
      "referenceID" : 22,
      "context" : "The major differences between the attack model used in this work and the attack graphs used in [2, 14, 15, 20, 23, 27] are twofold: to improve the realism of the model, we consider that the actions can produce numerical effects (for example, the expected running time of each action); and that the actions have a probability of success (which models the uncertainty about the results of the action).",
      "startOffset" : 95,
      "endOffset" : 118
    }, {
      "referenceID" : 26,
      "context" : "The major differences between the attack model used in this work and the attack graphs used in [2, 14, 15, 20, 23, 27] are twofold: to improve the realism of the model, we consider that the actions can produce numerical effects (for example, the expected running time of each action); and that the actions have a probability of success (which models the uncertainty about the results of the action).",
      "startOffset" : 95,
      "endOffset" : 118
    }, {
      "referenceID" : 25,
      "context" : "This idea was proposed in [26] and further analyzed in [16].",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 15,
      "context" : "This idea was proposed in [26] and further analyzed in [16].",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 12,
      "context" : "The planners used – Metric-FF [13] and SGPlan [7] – are state-of-the-art planners able to handle numerical effects.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 6,
      "context" : "The planners used – Metric-FF [13] and SGPlan [7] – are state-of-the-art planners able to handle numerical effects.",
      "startOffset" : 46,
      "endOffset" : 49
    }, {
      "referenceID" : 20,
      "context" : "More specifically, in Core’s testing lab there are more than 748 virtual machines with different OS and installed applications, where all the exploits of Core Impact are executed every night [21].",
      "startOffset" : 191,
      "endOffset" : 195
    }, {
      "referenceID" : 7,
      "context" : "Using general purpose probabilistic planners did not work as in the deterministic case; for instance, we experimented with Probabilistic-FF [8] with poor results, since it was able to find plans in only very small cases.",
      "startOffset" : 140,
      "endOffset" : 143
    }, {
      "referenceID" : 0,
      "context" : "As of July 2011, Immunity Canvas [1] doesn’t provide automated execution of exploits; Metasploit [17] has a feature called “autopwn” that launches all the exploits available for the target ports in arbitrary order; Core Impact Pro launches first a set of “fast” exploits and then “brute-force” exploits [26], but arbitrary order is used within each set; Core Insight Enterprise uses planning techniques based on a PDDL description [16] that takes into account the execution time but not the probability of success of the exploits.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 16,
      "context" : "As of July 2011, Immunity Canvas [1] doesn’t provide automated execution of exploits; Metasploit [17] has a feature called “autopwn” that launches all the exploits available for the target ports in arbitrary order; Core Impact Pro launches first a set of “fast” exploits and then “brute-force” exploits [26], but arbitrary order is used within each set; Core Insight Enterprise uses planning techniques based on a PDDL description [16] that takes into account the execution time but not the probability of success of the exploits.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 25,
      "context" : "As of July 2011, Immunity Canvas [1] doesn’t provide automated execution of exploits; Metasploit [17] has a feature called “autopwn” that launches all the exploits available for the target ports in arbitrary order; Core Impact Pro launches first a set of “fast” exploits and then “brute-force” exploits [26], but arbitrary order is used within each set; Core Insight Enterprise uses planning techniques based on a PDDL description [16] that takes into account the execution time but not the probability of success of the exploits.",
      "startOffset" : 303,
      "endOffset" : 307
    }, {
      "referenceID" : 15,
      "context" : "As of July 2011, Immunity Canvas [1] doesn’t provide automated execution of exploits; Metasploit [17] has a feature called “autopwn” that launches all the exploits available for the target ports in arbitrary order; Core Impact Pro launches first a set of “fast” exploits and then “brute-force” exploits [26], but arbitrary order is used within each set; Core Insight Enterprise uses planning techniques based on a PDDL description [16] that takes into account the execution time but not the probability of success of the exploits.",
      "startOffset" : 431,
      "endOffset" : 435
    }, {
      "referenceID" : 25,
      "context" : "This idea has been used in the automation of pentesting tools, see [26].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 27,
      "context" : "This planner takes as input a description of the scenario in the PPDDL language, an extension of PDDL for expressing probabilistic effects [28].",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 15,
      "context" : "Our main objective was to build a probabilistic planner able to solve scenarios with 500 machines, which was the limit reached with classical (deterministic) planning solutions in [16].",
      "startOffset" : 180,
      "endOffset" : 184
    }, {
      "referenceID" : 15,
      "context" : "The planner was integrated with the pentesting framework Core Impact, using the procedures previously developed for the work [16].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 15,
      "context" : "By contrast, in [16] the hard limit was memory: in scenarios with 500 machines we ran out of memory in a computer with 8 GB of RAM.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 15,
      "context" : "8 shows the growth of solver running time, which seems clearly quadratic, whereas in [16] the growth was exponential.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 24,
      "context" : "As a comparison, in another approach that accounts for the uncertainty about the attacker’s actions [25], the authors use off-the-shelf solvers, managing to solve scenarios with up to 7 machines – and are thus still far from the network sizes reached here.",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 14,
      "context" : "Early work on attack graph solving relied on model checking techniques [15, 27], with their inherent scalability restrictions; or on monotonicity assumptions [2, 18, 19] that are not able to express situations in which compromised resources are lost due to crashes, detection or other unforeseen circumstances.",
      "startOffset" : 71,
      "endOffset" : 79
    }, {
      "referenceID" : 26,
      "context" : "Early work on attack graph solving relied on model checking techniques [15, 27], with their inherent scalability restrictions; or on monotonicity assumptions [2, 18, 19] that are not able to express situations in which compromised resources are lost due to crashes, detection or other unforeseen circumstances.",
      "startOffset" : 71,
      "endOffset" : 79
    }, {
      "referenceID" : 1,
      "context" : "Early work on attack graph solving relied on model checking techniques [15, 27], with their inherent scalability restrictions; or on monotonicity assumptions [2, 18, 19] that are not able to express situations in which compromised resources are lost due to crashes, detection or other unforeseen circumstances.",
      "startOffset" : 158,
      "endOffset" : 169
    }, {
      "referenceID" : 17,
      "context" : "Early work on attack graph solving relied on model checking techniques [15, 27], with their inherent scalability restrictions; or on monotonicity assumptions [2, 18, 19] that are not able to express situations in which compromised resources are lost due to crashes, detection or other unforeseen circumstances.",
      "startOffset" : 158,
      "endOffset" : 169
    }, {
      "referenceID" : 18,
      "context" : "Early work on attack graph solving relied on model checking techniques [15, 27], with their inherent scalability restrictions; or on monotonicity assumptions [2, 18, 19] that are not able to express situations in which compromised resources are lost due to crashes, detection or other unforeseen circumstances.",
      "startOffset" : 158,
      "endOffset" : 169
    }, {
      "referenceID" : 4,
      "context" : "The first application of planning techniques and PDDL solving for the security realm was [5], however this application was not focused on finding actual attack paths or driving penetration testing tools.",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 11,
      "context" : "In [12] attack paths are generated from PDDL description of networks, hosts and exploits, although the scenarios studied do not cover realistic scales.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 15,
      "context" : "Previous work by the authors [16] addresses this limitation by solving scenarios with up 500 machines, and feeding the generated attack plans to guide a penetration testing tool.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 8,
      "context" : "Recent work [9] also manages to provide attack paths to a penetration testing tool, in this case the Metasploit Framework, but again does not include probabilistic considerations.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 24,
      "context" : "Previous work by one of the authors [25] takes into account the uncertainty about the result of the attacker’s actions.",
      "startOffset" : 36,
      "endOffset" : 40
    } ],
    "year" : 2013,
    "abstractText" : "As penetration testing frameworks have evolved and have become more complex, the problem of controlling automatically the pentesting tool has become an important question. This can be naturally addressed as an attack planning problem. Previous approaches to this problem were based on modeling the actions and assets in the PDDL language, and using off-the-shelf AI tools to generate attack plans. These approaches however are limited. In particular, the planning is classical (the actions are deterministic) and thus not able to handle the uncertainty involved in this form of attack planning. We herein contribute a planning model that does capture the uncertainty about the results of the actions, which is modeled as a probability of success of each action. We present efficient planning algorithms, specifically designed for this problem, that achieve industrial-scale runtime performance (able to solve scenarios with several hundred hosts and exploits). These algorithms take into account the probability of success of the actions and their expected cost (for example in terms of execution time, or network traffic generated). We thus show that probabilistic attack planning can be solved efficiently for the scenarios that arise when assessing the security of large networks. Two “primitives” are presented, which are used as building blocks in a framework separating the overall problem into two levels of abstraction. We also present the experimental results obtained with our implementation, and conclude with some ideas for further work.",
    "creator" : "LaTeX with hyperref package"
  }
}