{
  "name" : "1605.05894.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Twitter as a Lifeline: Human-annotated Twitter Corpora for NLP of Crisis-related Messages",
    "authors" : [ "Muhammad Imran", "Prasenjit Mitra", "Carlos Castillo" ],
    "emails" : [ "mimran@qf.org.qa,", "pmitra@qf.org.qa,", "chato@acm.org" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Natural language processing, Twitter, Disaster response, Supervised classification"
    }, {
      "heading" : "1. Introduction",
      "text" : "Twitter has been extensively used as an active communication channel, especially during mass convergence events such as natural disasters like earthquakes, floods, typhoons (Imran et al., 2015; Hughes and Palen, 2009). During the onset of a crisis, a variety of information is posted in real-time by affected people; by people who are in need of help (e.g., food, shelter, medical assistance, etc.) or by people who are willing to donate or offer volunteering services. Moreover, humanitarian and formal crisis response organizations such as government agencies, public health care NGOs, and military are tasked with responsibilities to save lives, reach people who need help, etc. (Vieweg et al., 2014). Situation-sensitive requirements arise during such events and formal disaster response agencies look for actionable and tactical information in real-time to effectively estimate early damage assessment, and to launch relief efforts accordingly. Recent studies have shown the importance of social media messages to enhance situational awareness and also indicate that these messages contain significant actionable and tactical information (Cameron et al., 2012; Imran et al., 2013; Purohit et al., 2013). Many Natural-LanguageProcessing (NLP) techniques such as automatic summarization, information classification, named-entity recognition, information extraction can be used to process such social media messages (Bontcheva et al., 2013; Imran et al., 2015). However, many social media messages are very brief, informal, and often contain slangs, typograpical errors, abbreviations, and incorrect grammar (Han et al., 2013). These issues degrade the performance of many NLP techniques when used down the processing pipeline (Ritter et al., 2010; Foster et al., 2011). We present Twitter corpora consisting of more than 52 million crisis-related messages collected during 19 different crises. We provide human annotations (volunteers and\ncrowd-sourced workers) of two types. First, the tweets are annotated with a set of categories such as displaced people, financial needs, infrastructure, etc. These annotation schemes were built using input taken from formal crisis response agencies such as United Nations Office for the Coordination of Humanitarian Affairs (UN OCHA). Second, the tweets are annotated to identify out-of-vocabulary(OOV) terms, such as slangs, places names, abbreviations, misspellings, etc. and their corrections and normalized forms. This dataset can form the basis for research in text classification for short messages and for research on normalizing informal language.\nCreating large corpora for training supervised machinelearning models is hard because it requires time and money that may not be available. However, since our dataset was used for disaster relief efforts, volunteers were willing to annotate it; this work can now be leveraged to improve text classification and language processing tasks. Our work provides annotations for around 50,000 thousand messages, which is a significant corpus, that will enable research into applied machine learning and consequently benefit the disaster relief (and other) research communities. Our dataset has been collected from various countries and during various times of the year. This diversity would make it an interesting dataset that if used would be a foil to solutions that only work for specific language “dialects”, e.g., American English and would fail or suffer from degradation of quality if applied to variations, such as Indian English. Our work shows that when a dataset is used for a real application, we could obtain larger number of annotations than otherwise. These can then be used to improve text processing as a byproduct.\nThe annotated data is also used to train machine-learning classifiers. In this case, we use three well-known learning algorithms: Naive Bayes, Random Forest, and Support Vector Machines (SVM). We remark that these classifiers\nar X\niv :1\n60 5.\n05 89\n4v 2\n[ cs\n.C L\n] 3\n1 M\nay 2\n01 6\nare useful for formal crisis response organizations as well as for the research community to build more effective computational methods (Pak and Paroubek, 2010; Imran et al., 2015) on top. We also train word2vec word embeddings from all 52 million messages and make them available to research community."
    }, {
      "heading" : "1.1. Contributions",
      "text" : "The contributions of this paper are as follows:\n1. We present human-annotated crisis-related messages collected during 19 different crises\n2. We use human-annotations to built machine-learning classifiers in a multiclass classification setting to classify messages that are useful for humanitarian efforts\n3. We provide first largest word2vec word embeddings trained using 52 million crisis-related messages\n4. We use the collected data to identify OOV (out-ofvocabulary) words and provide human-annotated normalized lexical resources for different lexical variations"
    }, {
      "heading" : "1.2. Paper organization",
      "text" : "The rest of the paper is organized as follows. In the next section, we describe datasets details and annotation schemes. Section 3 describes supervised classification task and word2vec word embeddings. Section 4 provides details of text normalization and we present related work in section 5. We conclude the paper in section 6."
    }, {
      "heading" : "2. Crises Corpora Collection and Annotation",
      "text" : ""
    }, {
      "heading" : "2.1. Data collection",
      "text" : "We collected crisis-related messages from Twitter posted during 19 different crises that took place from 2013 to 2015. Table 1 shows the list of crisis events along with their names, crisis type (e.g. earthquake, flood), countries where they took place, and the number of tweets each crisis contains. We collected these messages using our AIDR (Artificial Intelligence for Disaster Response) platform (Imran et al., 2014). AIDR is an open source platform to collect and classify Twitter messages during the onset of a humanitarian crisis. AIDR has been used by UN OCHA during many major disasters such as Nepal Earthquake, Typhoon Hagupit. AIDR provides different convenient ways to collect messages from Twitter using the Twitter’s streaming API. One can use different data collection strategies. For example, collecting tweets that contain some keywords and are specifically from a particular geographical area/region/city (e.g. New York). The detailed data collection strategies used to collect the datasets shown in Table 1 are included in each dataset folder."
    }, {
      "heading" : "2.2. Data annotation",
      "text" : "Messages posted on social media vary greatly in terms of information they contain. For example, users post messages of personal nature, messages useful for situational\nawareness (e.g. infrastructure damage, causalities, individual needs), or not related to the crisis at all. Depending on their information needs, different humanitarian organizations use different annotation schemes to categories these messages. In this work, we use a subset of the annotations used by the United Nations Office for the Coordination of Humanitarian Affairs (UN OCHA). The 9 category types (including two catch-all classes: “Other Useful Information” and “Irrelevant”) used by the UN OCHA are shown in the below-presented annotation scheme. For most of the datasets we have performed annotations by employing volunteers and paid workers. To perform volunteered-based annotations, messages were collected from Twitter in real-time and passed through a deduplication process. Only unique messages were considered for human-annotation. We use Stand-By-Task-Force (SBTF)1 volunteers to annotate messages using our MicroMappers platform.2 The real-time annotation process helps train machine learning classifiers rapidly, which are then used to classify new incoming messages. This process helps address time-critical information needs requirement of many humanitarian organizations. After the first round of annotations, we found that some categories are small in terms of number of labels thus showing high class-imbalance. A dataset is said to be imbalanced if at least one of the classes has significantly fewer annotated instances than the others. The class imbalance problem has been known to hinder the learning performance of classification algorithms. In this case, we performed another round of annotations for datasets that have high class imbalance using the paid crowdsourcing platform CrowdFlower.3 In both annotation processes, an annotation task consists of a tweet and the list of categories listed below. A paid worker or volunteer reads the message and selects one of the categories most suitable for the message. Messages that do not belong to any category but contain some important information are categorized as “Other Useful Information”. A task is finalized (i.e. a category is assigned) when three different volunteers/paid workers agree on a category. According to the Twitter’s data distribution policy, we are not allowed to publish actual contents of more than 50k tweets. For this reason, we publish all annotated tweets, which are less than 50k, along with tweet-ids of all the unannotated messages at http://CrisisNLP.qcri. org/. We also provide a tweets retrieval tool implemented in Java, which can be used to get full tweets content from Twitter. In below we show the annotation scheme used for crisis events caused by natural disasters. For other events, details regarding their annotations are available with the published data. Annotation scheme: Categorizing messages by information types\n• Injured or dead people: Reports of casualties and/or injured people due to the crisis\n1http://blog.standbytaskforce.com/ 2http://micromappers.org/ 3http://crowdflower.com/\nTable 1: Crises datasets details including crisis type, name, year, language of messages, country, # of tweets.\nCrisis type Crisis name Country Language # of Tweets Start-date End-date Earthquake Nepal Earthquake Nepal English 4,223,937 2015-04-25 2015-05-19 Earthquake Terremoto Chile Chile Spanish 842,209 2014-04-02 2014-04-10 Earthquake Chile Earthquake Chile English 368,630 2014-04-02 2014-04-17 Earthquake California Earthquake USA English 254,525 2014-08-24 2014-08-30 Earthquake Pakistan Earthquake Pakistan English 156,905 2013-09-25 2013-10-10 Typhoon Cyclone PAM Vanuatu English 490,402 2015-03-11 2015-03-29 Typhoon Typhoon Hagupit Phillippines English 625,976 2014-12-03 2014-12-16 Typhoon Hurricane Odile Mexico English 62,058 2014-09-15 2014-09-28 Volcano Iceland Volcano Iceland English 83,470 2014-08-25 2014-09-01 Landslide Landslides worldwide Worldwide English 382,626 2014-03-12 2015-05-28 Landslide Landslides worldwide Worldwide French 17,329 2015-03-12 2015-06-23 Landslide Landslides worldwide Worldwide Spanish 75,244 2015-03-12 2015-06-23 Floods Pakistan Floods Pakistan English 1,236,610 2014-09-07 2014-09-22 Floods India Floods India English 5,259,681 2014-08-10 2014-09-03 War & conflict Palestine Conflict Palestine English 27,770,276 2014-07-12 2014-10-02 War & conflict Peshawar Attack Pakistan Pakistan English 1,135,655 2014-12-16 2014-12-28 Biological Middle East Respiratory Syndrome Worldwide English 215,370 2014-04-27 2014-07-14 Infectious disease Ebola virus outbreak Worldwide English 5,107,139 2014-08-02 2014-10-27 Airline accident Malaysia Airlines flight MH370 Malaysia English 4,507,157 2014-03-11 2014-07-12\n• Missing, trapped, or found people: Reports and/or questions about missing or found people\n• Displaced people and evacuations: People who have relocated due to the crisis, even for a short time (includes evacuations)\n• Infrastructure and utilities damage: Reports of damaged buildings, roads, bridges, or utilities/services interrupted or restored\n• Donation needs or offers or volunteering services: Reports of urgent needs or donations of shelter and/or supplies such as food, water, clothing, money, medical supplies or blood; and volunteering services\n• Caution and advice: Reports of warnings issued or lifted, guidance and tips\n• Sympathy and emotional support: Prayers, thoughts, and emotional support\n• Other useful information: Other useful information that helps understand the situation\n• Not related or irrelevant: Unrelated to the situation or irrelevant"
    }, {
      "heading" : "3. Classification of Messages",
      "text" : "To make sense of huge amounts of Twitter messages posted during crises, we consider a basic operation, that is, the automatic categorization of messages into the categories of interest. This is a multiclass categorization problem in which instances are categorized into one of several classes. Specifically, we aim at learning a predictor h : X → Y , where X is the set of messages and Y is a finite set of categories. For this purpose, we use three well-known learning algorithms i.e. Naive Bayes (NB), Support Vector Machines (SVM), and Random Forest (RF)."
    }, {
      "heading" : "3.1. Preprocessing and feature extraction",
      "text" : "Prior to learning a classifier, we perform the following preprocessing steps. First, stop-words, URLs, and usermentions are removed from the Twitter messages. We perform stemming using the Lovins stemmer. We use Unigrams and bi-grams as our features. Previous studies found these two features outperform when used for similar classification tasks (Imran et al., 2013). Finally, we used the information gain, a well-know feature selection method to select top 1k features. The labeled data we used in this task was annotated by the paid workers."
    }, {
      "heading" : "3.2. Evaluation and Results",
      "text" : "We trained all three different kinds of classifiers using the preprocessed data. For the evaluation of the trained models, we used 10-folds cross-validation technique. Table 2 shows the results of the classification task in terms of Area Under ROC curve4 for all classes of the 8 different disaster datasets. We also show the proportion of each class in each dataset. Given the complexity of the task i.e. multiclass classification of short messages, we can see that all three classifiers have pretty decedent results. In this case, a random classifier represents an AUC = 0.50 and higher values are preferable. Other than the “missing trapped or found people” class, which is the smallest class in term of proportion across all the datasets, results for most of the other classes are at the acceptable level (i.e. ≥ 0.80)."
    }, {
      "heading" : "3.3. Crisis word embeddings",
      "text" : "Many applications of machine learning and computational linguistics rely on semantic representations and relationships between words of a text document. Many different types of methods have been proposed that use continuous representations of words such as Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA). How-\n4https://en.wikipedia.org/wiki/Receiver_ operating_characteristic\never, recently models based on distributional representations of words become more famous. In this work, we train word embeddings (i.e. distributed word representations) using the 52 million Twitter messages in our datasets and make it available to research community. To the best of our knowledge this is the first largest word embeddings that are trained on crisis-related tweets. We use word2vec, a very popular software to train word embedding (Mikolov et al., 2013). As preprocessing, we replaced URLs, digits, and usernames with fixed constants and removed special characters. Finally, the word embeddings are generated using Continuous Bag Of Words (CBOW) architecture with negative sampling along with 300 word representation dimensionality."
    }, {
      "heading" : "4. Twitter Text Normalization",
      "text" : ""
    }, {
      "heading" : "4.1. Language issues in Twitter messages",
      "text" : "The quality—in terms of readability, grammar, sentence structure etc.—of Twitter messages vary significantly. Typically, Twitter messages are brief, informal, noisy, unstructured, and often contain misspellings and grammatical mistakes. Moreover, due to Twitter’s 140 character limit restriction, Twitter users intentionally shorten words by using abbreviations, acronyms, slangs, and sometimes words without spaces. The accuracy of natural language processing techniques would improve if we can identify the informal nature of the language in tweets and normalize OOV terms (Han et al., 2013). We divide these lexical variations into the following five categories:\n1. Typos/misspellings: e.g. earthquak (earthquake), missin (missing), ovrcme (overcome)\n2. Single-word abbreviation/slangs: e.g. pls (please), srsly (seriously), govt (government), msg (message)\n3. Multi-word abbreviation/slangs: e.g. imo (in my opinion), im (i am), brb (be right back)\n4. Phonetics substitutions: e.g. 2morrow (tomorrow), 4ever (forever), 4g8 (forget), w8 (wait)\n5. Words without spaces: e.g. prayfornepal (pray for nepal), wehelp (we help), weneedshelter (we need shelter)"
    }, {
      "heading" : "4.2. Identification of candidate OOV words",
      "text" : "To identify candidate OOV words that require normalization, we first build initial vocabularies consisting of lexical variations mentioned in the previous section. We use a dictionary available on the web to normalize abbreviations, chat shortcuts, and slang.5 We also use the SCOWL (Spell Checker Oriented Word Lists) aspell English dictionary 6 that consists of 349,554 English words. The SCOWL dictionary is suitable for English spell checkers for most of English dialects. Although, the SCOWL dictionary contains places names (e.g. names of countries and famous cities), after testing it on Nepal Earthquake data, we found that its coverage is not complete and a large number of cities/towns of Nepal are missing. To overcome this issue, we use the\n5http://www.innocentenglish.com/news/ texting-abbreviations-collection-textingslang.html\n6http://wordlist.aspell.net/\nMaxMind 7 world cities database that consists of 3,173,959 cities. Using the above resources, we try to find OOV words in the dataset. However, we observed that a large number of OOVs consist of misspelled words for which a correct form can be obtained using one edit-distance change (i.e. by performing one insertion, deletion, or substitution operation). For this purpose, we train a language model using lists of most frequent words from Wiktionary,8 the British National Corpus,9 and words in our SCOWL dictionary. For a given\n7https://www.maxmind.com/en/free-worldcities-database\n8http://en.wiktionary.org/wiki/Wiktionary 9http://www.kilgarriff.co.uk/bnc-readme.\nhtml\nmisspelled word w, we aim to find a correction c out of all possible corrections where the probability of c given w is maximum, i.e., argmaxcP (c|w) By Bayes Theorem this is equivalent to:\nargmaxcP (c|w) = argmaxcP (w|c)P (c)/P (w) or it can be written as:\nargmaxcP (c|w) = argmaxcP (w|c)P (c) where P (c) is the probability that c is the correct word and P (w|c) is the probability that the author typed w when c was intended. We then restrict the language model to predict corrections within one edit-distance range and from those choose the one with highest probability. Misspellings for which more than one change is required, we consider them as OOVs to be corrected by human workers."
    }, {
      "heading" : "4.3. Normalization of OOV words",
      "text" : "To normalize the identified OOV words, we used the CrowdFlower crowdsourcing platform. A crowdsourcing task in this case consists of a Twitter message that contains one or more OOV words and a set of instructions shown in Figure 1. The workers were asked to read the instructions and examples carefully before providing an answer. A worker reads the given message and provides a correct OOV tag (i.e. slang/abbreviation/acronym, a location name, an organization name, a misspelled word, or a person name). If an OOV is a misspelled word, the worker also provides its corrected form. We provide all the resources and the results of crowdsoucing to research community."
    }, {
      "heading" : "5. Related Work",
      "text" : "The use of microblogging platforms such as Twitter during the sudden onset of a crisis situation has been increased in the last few years. Thousands of crisis-related messages that are posted online contain important information that can also be useful to humanitarian organizations for disaster response efforts, if processed timely and effectively (Hughes and Palen, 2009; Imran et al., 2015). Many different types of processing techniques ranging from machine learning to natural language processing to computational linguistics have been developed (Corvey et al., 2010) for different purposes (Imran et al., 2016). Despite there exists some resources e.g. (Temnikova et al., 2015; Olteanu et al., 2015), however, due to the scarcity of relevant data, in particular human-annotated data, crisis informatics researchers still cannot fully utilize the capabilities of different computational methods. To overcome these issues, we present to research community a corpora consisting of labeled and unlabeled crisis-related Twitter messages. Moreover, we also provide normalized lexical resources useful for linguistic analysis of Twitter messages."
    }, {
      "heading" : "6. Conclusions",
      "text" : "We present Twitter corpora consisting of over 52 million crisis-related tweets collected during 19 crisis events. We provide two sets of annotations related to topiccategorization of the tweets and tagging out-of-vocabulary words and their normalizations. We build machine-learning classifiers to empirically validate the effectiveness of the annotated datasets. We also provide word2vec word embeddings trained on 52 million messages. We believe that these resources and the tools built using them will help improve automatic natural language processing of crisisrelated messages and eventually be useful for humanitarian organizations."
    }, {
      "heading" : "7. References",
      "text" : "Bontcheva, K., Derczynski, L., Funk, A., Greenwood,\nM. A., Maynard, D., and Aswani, N. (2013). Twitie: An open-source information extraction pipeline for microblog text. In RANLP, pages 83–90. Cameron, M. A., Power, R., Robinson, B., and Yin, J. (2012). Emergency situation awareness from twitter for crisis management. In Proc. of the 21st international conference companion on World Wide Web, pages 695– 698.\nCorvey, W. J., Vieweg, S., Rood, T., and Palmer, M. (2010). Twitter in mass emergency: what nlp techniques can contribute. In Proc. of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 23–24. Foster, J., Çetinoglu, Ö., Wagner, J., Le Roux, J., Hogan, S., Nivre, J., Hogan, D., and Van Genabith, J. (2011). # hardtoparse: Pos tagging and parsing the twitterverse. In AAAI 2011 Workshop on Analyzing Microtext, pages 20–25. Han, B., Cook, P., and Baldwin, T. (2013). Lexical normalization for social media text. ACM Transactions on Intelligent Systems and Technology (TIST), 4(1):5. Hughes, A. L. and Palen, L. (2009). Twitter adoption and use in mass convergence and emergency events. International Journal of Emergency Management, 6(3-4):248– 260. Imran, M., Elbassuoni, S. M., Castillo, C., Diaz, F., and Meier, P. (2013). Extracting information nuggets from disaster-related messages in social media. Proc. of ISCRAM, Baden-Baden, Germany. Imran, M., Castillo, C., Lucas, J., Meier, P., and Vieweg, S. (2014). AIDR: Artificial intelligence for disaster response. In Proc. the 23rd international conference on World wide web companion, pages 159–162. Imran, M., Castillo, C., Diaz, F., and Vieweg, S. (2015). Processing social media messages in mass emergency: A survey. ACM Computing Surveys (CSUR), 47(4):67. Imran, M., Meier, P., Castillo, C., Lesa, A., and Garcia Herranz, M. (2016). Enabling digital health by automatic classification of short messages. In Proceedings of the 6th International Conference on Digital Health Conference, pages 61–65. ACM. Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013). Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781. Olteanu, A., Vieweg, S., and Castillo, C. (2015). What to expect when the unexpected happens: Social media communications across crises. In Proc. of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing, pages 994–1009. ACM. Pak, A. and Paroubek, P. (2010). Twitter as a corpus for sentiment analysis and opinion mining. In LREC, volume 10, pages 1320–1326. Purohit, H., Castillo, C., Diaz, F., Sheth, A., and Meier, P. (2013). Emergency-relief coordination on social media: Automatically matching resource requests and offers. First Monday, 19(1). Ritter, A., Cherry, C., and Dolan, B. (2010). Unsupervised modeling of twitter conversations. In Proc of NAACL. Temnikova, I., Castillo, C., and Vieweg, S. (2015). Emterms 1.0. In Information Systems for Crisis Response and Management, ISCRAM. Vieweg, S., Castillo, C., and Imran, M. (2014). Integrating social media communications into the rapid assessment of sudden onset disasters. In Social Informatics, pages 444–461. Springer."
    } ],
    "references" : [ {
      "title" : "Twitie: An open-source information extraction pipeline for microblog text",
      "author" : [ "K. Bontcheva", "L. Derczynski", "A. Funk", "M.A. Greenwood", "D. Maynard", "N. Aswani" ],
      "venue" : "RANLP, pages 83–90.",
      "citeRegEx" : "Bontcheva et al\\.,? 2013",
      "shortCiteRegEx" : "Bontcheva et al\\.",
      "year" : 2013
    }, {
      "title" : "Emergency situation awareness from twitter for crisis management",
      "author" : [ "M.A. Cameron", "R. Power", "B. Robinson", "J. Yin" ],
      "venue" : "Proc. of the 21st international conference companion on World Wide Web, pages 695– 698.",
      "citeRegEx" : "Cameron et al\\.,? 2012",
      "shortCiteRegEx" : "Cameron et al\\.",
      "year" : 2012
    }, {
      "title" : "Twitter in mass emergency: what nlp techniques can contribute",
      "author" : [ "W.J. Corvey", "S. Vieweg", "T. Rood", "M. Palmer" ],
      "venue" : "Proc. of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 23–24.",
      "citeRegEx" : "Corvey et al\\.,? 2010",
      "shortCiteRegEx" : "Corvey et al\\.",
      "year" : 2010
    }, {
      "title" : " hardtoparse: Pos tagging and parsing the twitterverse",
      "author" : [ "J. Foster", "Ö. Çetinoglu", "J. Wagner", "J. Le Roux", "S. Hogan", "J. Nivre", "D. Hogan", "J. Van Genabith" ],
      "venue" : "AAAI 2011 Workshop on Analyzing Microtext, pages 20–25.",
      "citeRegEx" : "Foster et al\\.,? 2011",
      "shortCiteRegEx" : "Foster et al\\.",
      "year" : 2011
    }, {
      "title" : "Lexical normalization for social media text",
      "author" : [ "B. Han", "P. Cook", "T. Baldwin" ],
      "venue" : "ACM Transactions on Intelligent Systems and Technology (TIST), 4(1):5.",
      "citeRegEx" : "Han et al\\.,? 2013",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2013
    }, {
      "title" : "Twitter adoption and use in mass convergence and emergency events",
      "author" : [ "A.L. Hughes", "L. Palen" ],
      "venue" : "International Journal of Emergency Management, 6(3-4):248– 260.",
      "citeRegEx" : "Hughes and Palen,? 2009",
      "shortCiteRegEx" : "Hughes and Palen",
      "year" : 2009
    }, {
      "title" : "Extracting information nuggets from disaster-related messages in social media",
      "author" : [ "M. Imran", "S.M. Elbassuoni", "C. Castillo", "F. Diaz", "P. Meier" ],
      "venue" : "Proc. of ISCRAM, Baden-Baden, Germany.",
      "citeRegEx" : "Imran et al\\.,? 2013",
      "shortCiteRegEx" : "Imran et al\\.",
      "year" : 2013
    }, {
      "title" : "AIDR: Artificial intelligence for disaster response",
      "author" : [ "M. Imran", "C. Castillo", "J. Lucas", "P. Meier", "S. Vieweg" ],
      "venue" : "Proc. the 23rd international conference on World wide web companion, pages 159–162.",
      "citeRegEx" : "Imran et al\\.,? 2014",
      "shortCiteRegEx" : "Imran et al\\.",
      "year" : 2014
    }, {
      "title" : "Processing social media messages in mass emergency: A survey",
      "author" : [ "M. Imran", "C. Castillo", "F. Diaz", "S. Vieweg" ],
      "venue" : "ACM Computing Surveys (CSUR), 47(4):67.",
      "citeRegEx" : "Imran et al\\.,? 2015",
      "shortCiteRegEx" : "Imran et al\\.",
      "year" : 2015
    }, {
      "title" : "Enabling digital health by automatic classification of short messages",
      "author" : [ "M. Imran", "P. Meier", "C. Castillo", "A. Lesa", "M. Garcia Herranz" ],
      "venue" : "Proceedings of the 6th International Conference on Digital Health Conference, pages 61–65. ACM.",
      "citeRegEx" : "Imran et al\\.,? 2016",
      "shortCiteRegEx" : "Imran et al\\.",
      "year" : 2016
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "T. Mikolov", "K. Chen", "G. Corrado", "J. Dean" ],
      "venue" : "arXiv preprint arXiv:1301.3781.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "What to expect when the unexpected happens: Social media communications across crises",
      "author" : [ "A. Olteanu", "S. Vieweg", "C. Castillo" ],
      "venue" : "Proc. of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing, pages 994–1009. ACM.",
      "citeRegEx" : "Olteanu et al\\.,? 2015",
      "shortCiteRegEx" : "Olteanu et al\\.",
      "year" : 2015
    }, {
      "title" : "Twitter as a corpus for sentiment analysis and opinion mining",
      "author" : [ "A. Pak", "P. Paroubek" ],
      "venue" : "LREC, volume 10, pages 1320–1326.",
      "citeRegEx" : "Pak and Paroubek,? 2010",
      "shortCiteRegEx" : "Pak and Paroubek",
      "year" : 2010
    }, {
      "title" : "Emergency-relief coordination on social media: Automatically matching resource requests and offers",
      "author" : [ "H. Purohit", "C. Castillo", "F. Diaz", "A. Sheth", "P. Meier" ],
      "venue" : "First Monday, 19(1).",
      "citeRegEx" : "Purohit et al\\.,? 2013",
      "shortCiteRegEx" : "Purohit et al\\.",
      "year" : 2013
    }, {
      "title" : "Unsupervised modeling of twitter conversations",
      "author" : [ "A. Ritter", "C. Cherry", "B. Dolan" ],
      "venue" : "Proc of NAACL.",
      "citeRegEx" : "Ritter et al\\.,? 2010",
      "shortCiteRegEx" : "Ritter et al\\.",
      "year" : 2010
    }, {
      "title" : "Information Systems for Crisis Response and Management, ISCRAM",
      "author" : [ "I. Temnikova", "C. Castillo", "S. Vieweg" ],
      "venue" : "Emterms",
      "citeRegEx" : "Temnikova et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Temnikova et al\\.",
      "year" : 2015
    }, {
      "title" : "Integrating social media communications into the rapid assessment of sudden onset disasters",
      "author" : [ "S. Vieweg", "C. Castillo", "M. Imran" ],
      "venue" : "Social Informatics, pages 444–461. Springer.",
      "citeRegEx" : "Vieweg et al\\.,? 2014",
      "shortCiteRegEx" : "Vieweg et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "Twitter has been extensively used as an active communication channel, especially during mass convergence events such as natural disasters like earthquakes, floods, typhoons (Imran et al., 2015; Hughes and Palen, 2009).",
      "startOffset" : 173,
      "endOffset" : 217
    }, {
      "referenceID" : 5,
      "context" : "Twitter has been extensively used as an active communication channel, especially during mass convergence events such as natural disasters like earthquakes, floods, typhoons (Imran et al., 2015; Hughes and Palen, 2009).",
      "startOffset" : 173,
      "endOffset" : 217
    }, {
      "referenceID" : 16,
      "context" : "(Vieweg et al., 2014).",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 1,
      "context" : "Recent studies have shown the importance of social media messages to enhance situational awareness and also indicate that these messages contain significant actionable and tactical information (Cameron et al., 2012; Imran et al., 2013; Purohit et al., 2013).",
      "startOffset" : 193,
      "endOffset" : 257
    }, {
      "referenceID" : 6,
      "context" : "Recent studies have shown the importance of social media messages to enhance situational awareness and also indicate that these messages contain significant actionable and tactical information (Cameron et al., 2012; Imran et al., 2013; Purohit et al., 2013).",
      "startOffset" : 193,
      "endOffset" : 257
    }, {
      "referenceID" : 13,
      "context" : "Recent studies have shown the importance of social media messages to enhance situational awareness and also indicate that these messages contain significant actionable and tactical information (Cameron et al., 2012; Imran et al., 2013; Purohit et al., 2013).",
      "startOffset" : 193,
      "endOffset" : 257
    }, {
      "referenceID" : 0,
      "context" : "Many Natural-LanguageProcessing (NLP) techniques such as automatic summarization, information classification, named-entity recognition, information extraction can be used to process such social media messages (Bontcheva et al., 2013; Imran et al., 2015).",
      "startOffset" : 209,
      "endOffset" : 253
    }, {
      "referenceID" : 8,
      "context" : "Many Natural-LanguageProcessing (NLP) techniques such as automatic summarization, information classification, named-entity recognition, information extraction can be used to process such social media messages (Bontcheva et al., 2013; Imran et al., 2015).",
      "startOffset" : 209,
      "endOffset" : 253
    }, {
      "referenceID" : 4,
      "context" : "However, many social media messages are very brief, informal, and often contain slangs, typograpical errors, abbreviations, and incorrect grammar (Han et al., 2013).",
      "startOffset" : 146,
      "endOffset" : 164
    }, {
      "referenceID" : 14,
      "context" : "These issues degrade the performance of many NLP techniques when used down the processing pipeline (Ritter et al., 2010; Foster et al., 2011).",
      "startOffset" : 99,
      "endOffset" : 141
    }, {
      "referenceID" : 3,
      "context" : "These issues degrade the performance of many NLP techniques when used down the processing pipeline (Ritter et al., 2010; Foster et al., 2011).",
      "startOffset" : 99,
      "endOffset" : 141
    }, {
      "referenceID" : 12,
      "context" : "are useful for formal crisis response organizations as well as for the research community to build more effective computational methods (Pak and Paroubek, 2010; Imran et al., 2015) on top.",
      "startOffset" : 136,
      "endOffset" : 180
    }, {
      "referenceID" : 8,
      "context" : "are useful for formal crisis response organizations as well as for the research community to build more effective computational methods (Pak and Paroubek, 2010; Imran et al., 2015) on top.",
      "startOffset" : 136,
      "endOffset" : 180
    }, {
      "referenceID" : 7,
      "context" : "We collected these messages using our AIDR (Artificial Intelligence for Disaster Response) platform (Imran et al., 2014).",
      "startOffset" : 100,
      "endOffset" : 120
    }, {
      "referenceID" : 6,
      "context" : "Previous studies found these two features outperform when used for similar classification tasks (Imran et al., 2013).",
      "startOffset" : 96,
      "endOffset" : 116
    }, {
      "referenceID" : 10,
      "context" : "We use word2vec, a very popular software to train word embedding (Mikolov et al., 2013).",
      "startOffset" : 65,
      "endOffset" : 87
    }, {
      "referenceID" : 4,
      "context" : "The accuracy of natural language processing techniques would improve if we can identify the informal nature of the language in tweets and normalize OOV terms (Han et al., 2013).",
      "startOffset" : 158,
      "endOffset" : 176
    }, {
      "referenceID" : 5,
      "context" : "Thousands of crisis-related messages that are posted online contain important information that can also be useful to humanitarian organizations for disaster response efforts, if processed timely and effectively (Hughes and Palen, 2009; Imran et al., 2015).",
      "startOffset" : 211,
      "endOffset" : 255
    }, {
      "referenceID" : 8,
      "context" : "Thousands of crisis-related messages that are posted online contain important information that can also be useful to humanitarian organizations for disaster response efforts, if processed timely and effectively (Hughes and Palen, 2009; Imran et al., 2015).",
      "startOffset" : 211,
      "endOffset" : 255
    }, {
      "referenceID" : 2,
      "context" : "Many different types of processing techniques ranging from machine learning to natural language processing to computational linguistics have been developed (Corvey et al., 2010) for different purposes (Imran et al.",
      "startOffset" : 156,
      "endOffset" : 177
    }, {
      "referenceID" : 9,
      "context" : ", 2010) for different purposes (Imran et al., 2016).",
      "startOffset" : 31,
      "endOffset" : 51
    }, {
      "referenceID" : 15,
      "context" : "(Temnikova et al., 2015; Olteanu et al., 2015), however, due to the scarcity of relevant data, in particular human-annotated data, crisis informatics researchers still cannot fully utilize the capabilities of different computational methods.",
      "startOffset" : 0,
      "endOffset" : 46
    }, {
      "referenceID" : 11,
      "context" : "(Temnikova et al., 2015; Olteanu et al., 2015), however, due to the scarcity of relevant data, in particular human-annotated data, crisis informatics researchers still cannot fully utilize the capabilities of different computational methods.",
      "startOffset" : 0,
      "endOffset" : 46
    } ],
    "year" : 2016,
    "abstractText" : "Microblogging platforms such as Twitter provide active communication channels during mass convergence and emergency events such as earthquakes, typhoons. During the sudden onset of a crisis situation, affected people post useful information on Twitter that can be used for situational awareness and other humanitarian disaster response efforts, if processed timely and effectively. Processing social media information pose multiple challenges such as parsing noisy, brief and informal messages, learning information categories from the incoming stream of messages and classifying them into different classes among others. One of the basic necessities of many of these tasks is the availability of data, in particular human-annotated data. In this paper, we present human-annotated Twitter corpora collected during 19 different crises that took place between 2013 and 2015. To demonstrate the utility of the annotations, we train machine learning classifiers. Moreover, we publish first largest word2vec word embeddings trained on 52 million crisis-related tweets. To deal with tweets language issues, we present human-annotated normalized lexical resources for different lexical variations.",
    "creator" : "LaTeX with hyperref package"
  }
}