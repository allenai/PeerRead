{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2016", "title": "Learning recurrent representations for hierarchical behavior modeling", "abstract": "We propose a framework for detecting action patterns from motion sequences and modeling the sensory-motor relationship of animals, using a generative recurrent neural network. The network has a discriminative part (classifying actions) and a generative part (predicting motion), whose recurrent cells are laterally connected, allowing higher levels of the network to represent high level phenomena. We test our framework on two types of data, fruit fly behavior and online handwriting. Our results show that 1) taking advantage of unlabeled sequences, by predicting future motion, significantly improves action detection performance when training labels are scarce, 2) the network learns to represent high level phenomena such as writer identity and fly gender, without supervision, and 3) simulated motion trajectories, generated by treating motion prediction as input to the network, look realistic and may be used to qualitatively evaluate whether the model has learnt generative control rules.", "histories": [["v1", "Tue, 1 Nov 2016 01:03:53 GMT  (5366kb,D)", "http://arxiv.org/abs/1611.00094v1", null], ["v2", "Thu, 3 Nov 2016 23:39:43 GMT  (7526kb,D)", "http://arxiv.org/abs/1611.00094v2", null], ["v3", "Tue, 15 Nov 2016 18:06:10 GMT  (7527kb,D)", "http://arxiv.org/abs/1611.00094v3", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CV", "authors": ["eyrun eyjolfsdottir", "kristin branson", "yisong yue", "pietro perona"], "accepted": true, "id": "1611.00094"}
