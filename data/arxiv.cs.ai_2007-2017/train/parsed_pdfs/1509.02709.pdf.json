{
  "name" : "1509.02709.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Topological Approach to Meta-heuristics: Analytical Results on the BFS vs. DFS Algorithm Selection Problem",
    "authors" : [ "Tom Everitt", "Marcus Hutter" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords\nBFS, DFS, Analytical Algorithm Selection, Average runtime, Metaheuristics, Tree Search, Graph Search, Probabilistic Goal Distribution\nContents"
    }, {
      "heading" : "1 Introduction 2",
      "text" : ""
    }, {
      "heading" : "2 Graph search problems 3",
      "text" : "2.1 Algorithm performance . . . . . . . . . . . . . . . . . . . . . . . 5"
    }, {
      "heading" : "3 Basic Search Algorithms 6",
      "text" : "3.1 Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 3.2 Uninformed search methods . . . . . . . . . . . . . . . . . . . . . 6 3.3 Informed Constructive Methods . . . . . . . . . . . . . . . . . . . 7 3.4 Informed Local Search . . . . . . . . . . . . . . . . . . . . . . . . 8"
    }, {
      "heading" : "4 Literature review 8",
      "text" : "4.1 Feature-based Meta-heuristics . . . . . . . . . . . . . . . . . . . . 8 4.2 Learning the search policy . . . . . . . . . . . . . . . . . . . . . . 9\nar X\niv :1\n50 9.\n02 70\n9v 1\n[ cs\n.A I]\n9 S"
    }, {
      "heading" : "5 Complete Binary Tree 10",
      "text" : "5.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 5.2 Complete Binary Tree with a Single Goal Level . . . . . . . . . . 12 5.3 Complete Binary Tree with Multiple Goal Levels . . . . . . . . . 15\n5.3.1 DFS Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 15 5.3.2 BFS Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 16"
    }, {
      "heading" : "6 Colliding Branches 17",
      "text" : "6.1 DFS Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 6.2 BFS Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19"
    }, {
      "heading" : "7 Grammar Problems 20",
      "text" : "7.1 Binary Grammar . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 7.2 Random Grammar . . . . . . . . . . . . . . . . . . . . . . . . . . 22 7.3 Full Grammar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23"
    }, {
      "heading" : "8 Experimental verification 24",
      "text" : ""
    }, {
      "heading" : "9 Empirical Predictions 27",
      "text" : ""
    }, {
      "heading" : "10 Discussion 29",
      "text" : ""
    }, {
      "heading" : "A List of notation 33",
      "text" : ""
    }, {
      "heading" : "B List of search problems 34",
      "text" : ""
    }, {
      "heading" : "C List of Topological features 35",
      "text" : ""
    }, {
      "heading" : "1 Introduction",
      "text" : "A wide range of problems in artificial intelligence can be naturally formulated as search problems (Russell and Norvig, 2010; Edelkamp and Schrödl, 2012). Examples include planning, scheduling, and combinatorial optimisation (TSP, graph colouring, etc.), as well as various toy problems such as Sudoku and the Towers of Hanoi. Search problems can be solved by exploring the space of possible solutions in a more or less systematic or clever order. Meta-heuristics are general search methods not aimed at a specific type of problem. They interact with the problem through abstract properties such as a neighbourhood relation on the space of feasible solutions, and a heuristic or objective function. One possible way to create flexible meta-heuristics is to combine a portfolio of search algorithms, and use problem features to predict which search algorithms works the best. Predicting the best algorithm is sometimes known as the algorithm selection problem (Rice, 1975).\nA number of studies have approached the algorithm selection problem with machine learning techniques (Kotthoff, 2014; Hutter et al., 2014). While demonstrably a feasible path, machine learning tend to be used as a black box, offering little insight into why a certain method works better on a given problem. On the other hand, most existing analytical results focus on worst-case big-O analysis, which is often less useful than average-case analysis when selecting algorithm. An important worst-case result is Knuth’s (1975) simple but useful technique\nfor estimating the depth-first search tree size. Kilby et al. (2006) used it for algorithm selection in the SAT problem. See also the extensions by Purdom (1978), Chen (1992), and Lelis et al. (2013). Analytical IDA* runtime predictions based on problem features was obtained by Korf et al. (2001) and Zahavi et al. (2010). In this study we focus on theoretical analysis of average runtime of BFS and DFS. While the IDA* results can be interpreted to give rough estimates for average BFS search time, no similar results are available for DFS.\nTo facilitate the analysis, we use a probabilistic model of goal distribution and graph structure. Currently no method to automatically estimate the model parameters is available (this is an important line of future research). Regardless, the analysis still offers important theoretical insights into BFS and DFS search. The parameters of the model can also be interpreted as a Bayesian prior belief about goal distribution. A precise understanding of BFS and DFS performance is likely to have both practical and theoretical value: Practical, as BFS and DFS are both widely employed; theoretical, as BFS and DFS are two most fundamental ways to search, so their properties may be useful in analytical approaches to more advanced search algorithms as well. In particular, our results may be a first step to selecting search strategy based on the (local) topology of the problem graph, an aspect ignored by most meta-heuristics.\nOur main contribution is an analysis of expected BFS and DFS runtime as a function of tree depth, goal level, branching factor and path redundancy (Sections 5–7). We also verify the results experimentally (Section 8). Most of these results will be published as (Everitt and Hutter, 2015a,b). Definitions of different types of search problems and search algorithms are given in Section 2 and 3, and a review of related work can be found in Section 4. Conclusions and outlooks come in Section 9 and 10. Finally, Appendix A provides a list of notation, and Appendix B and C contain lists of search problems and potentially useful topological features."
    }, {
      "heading" : "2 Graph search problems",
      "text" : "A common feature of many search problems is that there are a set of operations for cheaply modifying a proposed solution into similar proposed solutions. This makes it natural to view the problem as a graph search problem, where proposed solutions are states or nodes, and the modification operations induce directed edges.\nWe define two kinds of graph search problems.\nDefinition 1 (Constructive graph search problem). A constructive graph search problem consists of a state space S, a starting state s0 ∈ S, and the following efficiently computable functions:\n1. Neighbourhood N : S → 2S\n2. Goal check C : S → {0, 1} 3. Edge cost: EC : (S × S)→ R+\n4. Heuristic h : S → R+\n5. Contract (tree/graph, solution depth, number of goals, admissible/consistent heuristic)\nItems 4 and 5 are optional. A constructive solution is a path s0, . . . , sn from the starting state s0 to a goal state sn with C(sn) = 1. The solution quality of the\npath s0, . . . , sn is ∑n−1 i=0 EC (si, si+1).\nFor instance, planning problems are formalised as constructive graph search problems. The neighbourhood function gives a list of states reachable by a single action from the given state. The goal check indicates whether a state is a goal, and the edge cost indicates how costly it is to use a certain action (how it affects the solution quality). A solution is a sequence of actions leading to a goal state.\nA heuristic may give an estimate of how close the given state is to a goal state (in terms of edge cost). An important class of heuristics are the admissible ones, that never overestimate the distance. Consistent heuristics additionally respect the triangle inequality. The properties of the heuristics may be given in the contract. The contract is not formalised here, but may be given as a dictionary of known problem properties.\nDefinition 2 (Local graph search problem). A local graph search problem consists of a state space S together with the following efficiently computable functions:\n1. Neighbourhood N : S → 2S\n2. Constraint C : S → {0, 1} 3. Objective function Q : S → R 4. Contract (continuity properties of the objective function)\nItem 4 is optional. A local solution is a state s ∈ S, C(s) = 1, and its solution quality is Q(s).\nIn local graph search problems, the goal is to find an s ∈ S that satisfies the constraints C and achieves as high objective value as possible. An objective function Q is (Lipschitz) continuous with respect to the neighbourhood topology with Lipschitz constant d if |Q(v1)−Q(v2)| < d whenever v1 and v2 are neighbours. Lipschitz continuity can make a problem easier, as it allows the objective values of surrounding nodes to be estimated from the current target value.\nThe search for an optimal circuit layout is one example of a problem that naturally formalises as a local graph search problems. Neighbours are reached by modifying the current layout (changing one connection), and the objective function incorporates the component cost and the energy efficiency of the layout. The constraint disqualifies circuits that fail the specifications. Also, any constructive search problem G1 = 〈S1, N1, C1,EC 〉 may be formulated as local search problem G2 = 〈S2, N2, C2, Q〉, by letting\n• S2 be the set of paths in G1, • the objective function Q be the negative sum of the path cost, • the constraint C2 check whether the last node of the path is a goal node,\nand\n• the neighbourhood function N2 extend or contract a path by adding or removing a final node according to N1 (better choices of N2 may be available).\nFor example, the travelling salesman problem can be viewed as a constructive problem where a path is built step-by-step, or as a local problem where a full path is modified by swapping edges, and the objective function equals the summed edge cost. Some potentially useful structure may be lost in the conversion from a constructive to a local problem.\nAlthough mixtures of local and constructive search problems are possible (e.g., combining an objective function with a constructive solution and edge cost), most practical graph search problems naturally formalises as either a constructive or a local graph search problem.\nConstraint Satisfaction Problems Search problem can also often be naturally cast as constraint satisfaction problems (CSPs). Blum and Roli (2003) suggest that this offers a unified view of many search problems. A CSP formulation also seems largely in line with what Pearl (1988) has in mind, although Pearl is less specific.\nConstructive graph problems may be formulated as a CSP by encoding the neighbourhood relation with constraints, without significant loss of structure. (If the state space is infinite, an infinite number of CSP variables may be necessary.) For other problems, like the Quadratic Assignment Problem or Eternity II1, the CSP formulation is more natural and retains more structure. More structure makes the space of policies richer, and permits more clever strategies. It can also make analytic results harder, however."
    }, {
      "heading" : "2.1 Algorithm performance",
      "text" : "A search algorithm is an algorithm that returns a solution (a state or a path) to a graph search problem, given oracle access to the functions N and C, and possibly either EC and h, or Q (depending on the type of the search problem).\nPerformance on a single problem may be defined in terms of:\n1. Solution quality.\n2. The number of explored states; a state s is considered explored if either N(s) or C(s) has been called.\n3. The running time of the algorithm.\n4. The memory consumption of the algorithm (typically measured by the maximum number of states kept in memory).\nTo measure performance on a finite class of graph problems, average or worstcase performance may be used. For infinite classes, items 1 and 2 are typically subject to worst-case analysis (is the procedure complete/optimal), and 3 and 4 to asymptotic worst-case or average-case analysis.\nWe will focus on constructive search, and measure performance by the average number of explored states until in a goal is found in. In many cases the number of explored states is proportional to the actual runtime of the algorithm (state expansion is often the dominant operation during search).\nSearch algorithms that always finds a goal (when there is one) are called complete, and algorithms that always finds an optimal solution (when there is one) are called optimal.\n1The Quadratic Assignment Problem is a classic combinatorial problem, and Eternity II is a famous puzzle competition by TOMY UK Ltd."
    }, {
      "heading" : "3 Basic Search Algorithms",
      "text" : "A plethora of search methods have been studied for both the constructive and the local search problems. We here review only a subset of the more important ones, and refer to the books (Russell and Norvig, 2010; Edelkamp and Schrödl, 2012) for more details. First some preliminaries on trees, a fundamental structure in search analysis."
    }, {
      "heading" : "3.1 Trees",
      "text" : "A rooted tree is a (directed) graph with a root s0 where every pair of nodes is connected by exactly one path. The level of a node v is the distance from the root s0 to v. The depth d is the length of a longest path starting from s0. If every node on level less than D ∈ N has exactly b children, and nodes on level D are leafs (have no children), then the tree is complete with branching factor b and depth D. Such a tree will have bD leaves and (bD+1 − 1)/(b− 1) nodes. In particular, complete binary trees (with branching factor 2) have 2D leaves and 2D+1 − 1 nodes.\nA node v is a descendant of a node u if there is a path from u to v (i.e., if v is a child of a child of . . . of u)."
    }, {
      "heading" : "3.2 Uninformed search methods",
      "text" : "Uninformed search refers to the case where neither a heuristic function nor an objective function is used for guidance of the search. The two standard methods for exploring a graph in this case are Breadth-first Search (BFS) and Depth-first Search (DFS). BFS searches a successively growing neighbourhood around the the start node, while DFS follows a single path as long as possible, and backtracks when stuck. Algorithm 1 and 2 give pseudo-code for BFS and DFS respectively, and Figure 1 shows the traversal order of BFS and DFS in a complete binary tree.\nAlgorithm 1 Pseudo-code for BFS\nQ ← emtpyQueue Discovered ← emptySet Q.add(start-node) Discovered.add(start-node) while Q not empty do\nu←Q.pop() if C(u) then return u\nfor v in N(u) do if not v ∈ Discovered then\nQ.add(v) Discovered.add(v)\nDFS is substantially more memory-efficient than BFS: O(d) compared to O(bd). However, BFS can be emulated by an iterative deepening DFS, with the same memory cost as DFS and only a small penalty in runtime in most graphs (in graphs with exponentially growing neighbourhoods, to be precise).\nAlgorithm 2 Pseudo-code for (Recursive) DFS\nfunction DFS-REC(N,C, u, Discovered) Discovered.add(u) if C(u) then return u\nBFS and DFS come in two flavors, depending on whether they keep track of visited nodes or not. The tree search variants do not keep track of visited nodes, while the graph search variants do. In trees (where each node can only be reached from one path), nothing is gained by keeping track of visited nodes. In contrast, keeping track of visited nodes can benefit search performance greatly in multiply connected graphs. Keeping track of visited nodes may also be expensive in terms of memory consumption, however.\nOne way to understand tree search behaviour in general graphs is to say that tree search algorithms effectively explore a tree; branches in this tree correspond to paths in the original graph, and copies of the same node v will appear in several places of the tree whenever v can be reached through several paths. DFS tree search may search forever if there are cycles in the graph. We always assume that path lengths are bounded by a constant D.\nDepending on the positions of the goals in the graph, DFS and BFS may have substantially different performance. In Sections 5–7 below, We investigate some simple models of how the goal position and the graph structure affect BFS and DFS performance."
    }, {
      "heading" : "3.3 Informed Constructive Methods",
      "text" : "Informed constructive search methods make use of a heuristic function. This often speeds up the search significantly. The most popular method for informed constructive search is A*. It may be seen as a generalisation of BFS. A* combines the heuristic information h(v) of a node v with the accumulated edge cost g(v) of the shortest found path from the start node to v. A* always expands the discovered node with the smallest g(v) +h(v). But when the heuristic function is\nsmaller for nodes closer to the goal, A* will prioritise more promising nodes and find the goal much faster than BFS. If in particular the heuristic is consistent (never overestimates distance and respects the triangle inequality), then A* is guaranteed to find an optimal solution. The tree search version of A* only requires the heuristic to be admissible (never overestimate search distance) for guaranteed optimality.\nOne of the main draw-backs of A* is its memory consumption. Iterative deepening A* (IDA*) uses a cutoff value c that is incremented between iterations. In each iteration, nodes v not satisfying g(v) + h(v) < c are ignored, while the rest are expanded in DFS manner. The memory consumption thus becomes on par with DFS. However, unlike iterative deepening BFS, the runtime slowdown of IDA* compared to A* may be exponentially worse, since it may only be possible to increase the cutoff c marginally between iterations if optimality of the solution must be guaranteed. A range of other memory-efficient versions of A* can be found in the literature.\nIf the edge cost is always 1 and the heuristic entirely uninformative h ≡ 0, then A* reduces to BFS and IDA* to iterative-deepening DFS.\nIn many cases the priority is to find a goal as fast as possible, and the goal does not need to be an optimal one. In these cases, a greedy best-first search strategy may be used, that expands nodes according to h(v) instead of g(v)+h(v). Greedy best-first may be seen as the most natural generalisation of DFS to the informed constructive scenario. Beam-search is a variant of greedy best-first that searches slightly more widely."
    }, {
      "heading" : "3.4 Informed Local Search",
      "text" : "Most informed local search algorithms strive to combine an exploiting, hillclimbing component with an exploration component. The simplest one is hillclimbing, which always goes to the neighbour with the highest objective value, and randomly restarts when stuck. More advanced methods include simulated annealing, which adds a random moves to hill-climbing. The randomness component decays over time. Genetic algorithms use a population of search nodes, and tries to find new search points by combining features of discovered ones."
    }, {
      "heading" : "4 Literature review",
      "text" : "We divide our review of related work into two subsections. The works in the first subsection assumes that a portfolio of predefined algorithms is given, and only tries to predict which algorithm in the portfolio is better for which problem. The second subsection reviews approaches that try to build new search policies, possibly using a set of basic algorithms as building blocks."
    }, {
      "heading" : "4.1 Feature-based Meta-heuristics",
      "text" : "The algorithm selection problem asks what algorithm best to use on a given problem (Rice, 1975; Kotthoff, 2014). Tightly related is the question of inferring the search time of different search algorithms on the problem, as this information can be used to select the fastest algorithm. Both analytical investigations and machine learning techniques applied to empirical data have been tried. The latter\nis sometimes known as empirical performance models. The most comprehensive surveys are given by Hutter et al. (2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011).\nFor DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth’s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy.\nIn the case of informed search, Korf et al. (2001) developed an interesting analytic technique for estimating the search time of IDA*. Assuming a consistent heuristic function, the estimate is based on the distribution of heuristic function values at different depths of the search tree, rather than heuristic accuracy. Intuitively, the scheme works because the number of nodes expanded in each iteration of IDA* depends on the number of nodes with heuristic value less than the threshold. The distribution of heuristic values is also easy to estimate in practice. Zahavi et al. (2010) generalise the work of Korf et al. to non-consistent heuristics.\nMany other approaches instead try to directly infer the best search policy, without the intermediate step of estimating runtime. Fink (1998) does this for STRIPS-like learning using only the problem size to infer which method is likely to be more efficient. Schemes using much wider ranges of problem properties are applied to CSPs in (Thompson, 2011; Arbelaez Rodriguez, 2011), and to the NP-complete problems SAT, TSP and Mixed integer programming in (Hutter et al., 2014). Smith-Miles and Lopes (2012) review and discuss commonly used features for the algorithm selection problem, mainly applied to the local search scenario. They divide features into two main categories: General and problem-specific. General features usually phrased in terms of the fitness landscape (i.e., the target function and the neighbourhood structure). A common fitness landscape feature is for example the variability (ruggedness) of the target function. Another general feature is the performance of a simple, fast algorithm such as gradient descent. Problem-specific features are discussed for a range of NP-complete problems such as TSP and Bin-packing."
    }, {
      "heading" : "4.2 Learning the search policy",
      "text" : "Explanation-based Learning (EBL) (Dejong and Mooney, 1986; Mitchell et al., 1986; Minton, 1988) is a general method for learning from examples and domain knowledge. In the context of search, the domain knowledge is the neighbourhood function (or the consequence of applying an ‘action’ to a state). An example to learn from can be the search trace of an optimiser. The EBL learner analyses the different decisions represented in the search trace, judges whether they were good or bad, and tries to find the reason they were good or bad. Once a reason has been found, the gained understanding can be used to pick similar good decisions at an earlier point during the next search, and to avoid similar bad\ndecisions (decisions leading to paths where no goal will be found). EBL systems have been applied to STRIPS-like planning scenarios (Minton, 1988, 1990).\nOne characteristic feature of EBL is that it requires only one or a few training examples (in addition to the domain knowledge). While attractive, it can also lead to overspecific learning (Minton, 1988). Partial Evaluation (PE) is an alternative learning method that is more robust in this respect, with less dependency on examples (Etzioni, 1993). Leckie and Zukerman (1998) develops a more inductive way to learn search control knowledge (in contrast to the deductive generalisations performed by EBL and PE), where plenty of training examples substitute for domain knowledge.\nA more modern approach is known as hyper heuristics (Burke et al., 2003, 2013). It views the problem of inferring good search policies more abstractly. Rather than interacting with the neighbourhood structure/graph problem directly, the hyper heuristic only has access to a set of search policies for the original graph problem. The search policies are known as low-level heuristics in this literature (not to be confused with heuristic functions). The goal of the hyper heuristic is to find a good policy for when to apply which low-level heuristic. For example, Ross et al. (2002) used Genetic Algorithms to learn which binpacking heuristic to apply in which type of state in a bin-packing problem. The learned hyper heuristic outperformed all the provided low-level heuristics used by themselves. In applications of hyper heuristics, the low-level heuristics are typically simple search policies provided by the human programmers, although nothing prevents them from being arbitrarily advanced meta-heuristics. Some research is also being done on automatic construction of low-level heuristics (see (Burke et al., 2013) for references). A related approach directed at programming in general is programming by optimisation (Hoos, 2012), where machine learning techniques are used to find the best algorithm in a space of programs delineated by the human programmer."
    }, {
      "heading" : "5 Complete Binary Tree",
      "text" : "In a search graph, the neighbourhood relation N induces a topology on the state space S. The following two sections analytically explore how the structure and depth of the graph and the distribution of the goals can be used to predict the search performance of BFS and DFS. Figure 1 gives the intuition for the different search strategies BFS and DFS, and how they initially focus the search on different areas of the tree.\nAs a concrete example, consider the search problem of solving a Rubik’s cube. There is an upper bound D = 20 to how many moves it can take to reach the goal (Rokicki and Kociemba, 2013). We may however suspect that most goals are located around level 17 (±2 levels). If we consider search algorithms that do not remember where they have been, the search space becomes a complete tree with fixed branching factor 9. What would be the expected BFS and DFS search time for this problem? Which one would be faster?\nAfter some initial background in the first subsection, this section first investigates a model where goals are located on a single goal level g in Section 5.2, and then generalises it to multiple goal levels in Section 5.3. Section 6 develops techniques for analyzing the performance of the graph search variants of BFS and DFS, which recognize the path redundancies often present in problems. All\nanalytical runtime estimates are verified experimentally in Section 8."
    }, {
      "heading" : "5.1 Preliminaries",
      "text" : "For simplicity, we say that the runtime or search time of a search method (BFS or DFS) is the number of nodes explored until a first goal is found (5 and 6 respectively in Figure 1). This simplifying assumption relies on node expansion being the dominant operation, consuming similar time throughout the tree. If no goal exists, the search method will explore all nodes before halting. In this case, we define the runtime as the number of nodes in the search problem plus 1 (i.e., 2D+1 in the case of a binary tree of depth D).2\nLet Γ be the event that a goal exists, Γk the event that a goal exists on level k, and Γ̄ and Γ̄k their complements. Let Fk = Γk ∩ ( ⋂k−1 i=0 Γ̄i) be the event that level k has the first goal. A random variable X is geometrically distributed Geo(p) if P (X = k) = (1− p)k−1p for k ∈ {1, 2, . . . }. The interpretation of X is the number of trials until the first success when each trial succeeds with probability p. Its cumulative distribution function (CDF) is P (X ≤ k) = 1 − (1 − p)k, and its average or expected value E[X] = 1/p. A random variable Y is truncated geometrically distributed X ∼ TruncGeo(p,m) if Y = (X | X ≤ m) for X ∼ Geo(p), which gives\nP (Y = k) =\n{ (1−p)kp\n1−(1−p)m for k ∈ {1, . . . ,m} 0 otherwise.\nE[Y ] = E[X | X ≤ m] = 1− (1− p) m(pm+ 1)\np(1− (1− p)m) .\nLet tc(p,m) denote the expected value of a truncated geometrically distributed variable with parameters p and m (i.e., tc(p,m) = E[Y ]). When p 1m , Y is approximately Geo(p), and tc(p,m) ≈ 1p . When p 1 m , Y becomes approximately uniform on {1, . . . ,m} and tc(p,m) ≈ m2 . A random variable Z is exponentially distributed Exp(λ) if P (Z ≤ z) = 1− e−λz for z ≥ 0. The expected value of Z is 1λ , and the probability density function of Z is λe−λz. An exponential distribution with parameter λ = − ln(1−p) might be viewed as the continuous counterpart of a Geo(p) distribution. We will use this approximation in Section 5.3.\nLemma 3 (Exponential approximation). Let Z ∼ Exp(− ln(1− p)) and X ∼ Geo(p). Then the CDFs for X and Z agree for integers k, P (Z ≤ k) = P (X ≤ k). The expectations of Z and X are also similar in the sense that 0 ≤ E[X]−E[Z] ≤ 1.\nProof. For z > 0, P (Z ≤ z) = 1 − exp(z ln(1 − p)) = 1 − (1 − p)z, and P (X ≤ z) = 1−(1−p)bzc. Thus, for integers k > 0, P (Z ≤ k) = P (X ≤ k) which proves the first statement. Further, 1−(1−p)bzc ≤ 1−(1−p)z < 1−(1−p)bz+1c, so P (X ≤ z) ≤ P (Z ≤ z) < P (X − 1 ≤ z). Hence E[X] ≥ E[Z] > E[X − 1] = E[X]− 1, which proves the second statement.\n2It may have seem more justified to set the non-goal case to the exact number of nodes instead of adding 1. However, adding 1 makes most expressions slightly more elegant, and does not affect the results in any substantial way.\nWe will occasionally make use of the convention 0 · undefined = 0, and often expand expectations by conditioning on disjoint events:\nLemma 4. Let X be a random variable and let the sample space Ω = ⋃̇ i∈ICi be\npartitioned by mutually disjoint events Ci. Then E[X] = ∑ i∈I P (Ci)E[X | Ci]."
    }, {
      "heading" : "5.2 Complete Binary Tree with a Single Goal Level",
      "text" : "Consider a binary tree of depth D, where solutions are distributed on a single goal level g ∈ {0, . . . , D}. At the goal level, any node is a goal with iid probability pg ∈ [0, 1]. We will refer to this kind of problems as (single goal level) complete binary trees with depth D, goal level g and goal probability pg (Section 5.3 generalises the setup to multiple goal levels).\nThe probability that a goal exists is P (Γ) = P (Γg) = 1 − (1 − pg)2 g\n. If a goal exists, let Y be the position of the first goal at level g. Conditioned on a goal existing, Y is a truncated geometric variable Y ∼ TruncGeo(pg, 2g). When pg 2−g the goal position Y is approximately Geo(pg), which makes most expressions slightly more elegant. This is often a realistic assumption, since if p 6 2−g, then often no goal would exist.\nProposition 5 (BFS runtime Single Goal Level). Let the problem be a complete binary tree with depth D, goal level g and goal probability pg. When a goal exists and has position Y on the goal level, the BFS search time is\ntBFSSGL(g, pg, Y ) = 2 g − 1 + Y , with expectation\ntBFSSGL(g, pg | Γg) = 2g − 1 + tc(pg, 2g) ≈ 2g − 1 + 1\npg .\nIn general, when a goal does not necessarily exist, the expected BFS search time is\ntBFSSGL(g, pg) = P (Γ) · (2g − 1 + tc(pg, 2g)) + P (Γ̄) · 2D+1 ≈ 2g − 1 + 1\npg .\nThe approximations are close when pg 2−g.\nProof. When a goal exists, BFS will explore all of the top of the tree until depth g − 1 (that is, 2(g−1)+1 = 2g nodes) and Y nodes on level g, before finding the first goal. That is, tBFSSGL(D, g, pg, Y ) = 2\ng − 1 + Y , with expected value 2g − 1 + tc(pg, 2g).\nIn the general case, the expected value of the search time X expands as\nE[X] = P (Γ) · E[X | Γ] + P (Γ̄) · E[X | Γ̄] = P (Γ) · tBFSSGL(D, p, pg | Γg) + P (Γ̄) · 2D+1\n= P (Γ) · (2g − 1 + tc(pg, 2g)) + P (Γ̄) · 2D+1.\nWhen pg 2−g, then Γ ≈ 1, Γ̄ ≈ 0 and Y ≈ Geo(p) which justifies the approximation.\nA memory-efficient tree-search variant of BFS can be implemented as iterative deepening DFS (ID-DFS). The runtime of ID-DFS is about twice the runtime of BFS; our results are only marginally affected by this. Korf et al. (2001) study\nIDA*, which may be seen as a generalised ID-DFS. Their Theorem 1 give a similar result to our Proposition 5 by setting: the heuristic h = 0, the number of i-level nodes Ni = 2\ni, the equilibrium distribution P (x) = 1, the edge cost = 1, and the cost bound c equal to our max depth D. Their bound then comes out as tBFSSGL(g) = 2\ng+1 − 1, and as tBFSSGL(g) ≈ 2g+2 after iteration over all levels ≤ g. This corresponds to the worst case in our scenario.\nProposition 6. Consider a complete binary tree with depth D, goal level g and goal probability pg. When a goal exists and has position Y on the goal level, the DFS search time is approximately\nt̃DFSSGL(D, g, pg, Y ) := (Y − 1)2D−g+1 + 2, with expectation t̃DFSSGL(D, g, pg | Γg) := ( 1 pg − 1 ) 2D−g+1 + 2.\nWhen pg 2−g, the expected DFS search time when a goal does not necessarily exist is approximately\nt̃DFSSGL(D, g, pg) := P (Γ)((tc(pg, 2 g)−1)2D−g+1+2)+P (Γ̄)2D+1≈\n( 1 pg −1 ) 2D−g+1.\nProof. One way to count the nodes explored by DFS when a goal exists is the following. To the left of the first goal on level g, DFS will explore 2(Y −1) subtrees rooted at level g + 1. These subtrees will have depth D − (g + 1), and contain 2D−g − 1 nodes each. DFS will also explore Y nodes on level g and their parents, which amounts to about 2Y nodes. Summing the contributions up gives the DFS search time approximation t̃DFSSGL(D, g, pg, Y ) = 2(Y −1) · (2D−g−1) + 2Y = (Y − 1)2D−g+1 + 2.\nBy Lemma 4, the expected value of the search time X expands as\nE[X] = P (Γ) · E[X | Γ] + P (Γ̄) · E[X | Γ̄] = P (Γ) · E[t̃DFSSGL(D, g, pg, Y ) | Γ] + P (Γ̄) · 2D+1\n= P (Γ) · ((tc(pg, 2g)− 1)2D−g+1 + 2) + P (Γ̄) · 2D+1\nwhere the last step uses that (Y | Γ) ∼ TruncGeo(pg, 2g). When pg 2−g, then Γ ≈ 1, Γ̄ ≈ 0 and Y ≈ Geo(pg) which justifies the approximation.\nFigure 2 shows the runtime estimates as a function of goal level.\nComparison BFS vs. DFS. Figure 6 on page 23 shows how the expected search time varies with goal depth (and also compares the results with the Binary Grammar Problem described in Section 7.1). The runtime estimates can be used to predict whether BFS or DFS will be faster, given the parameters D, g, and pg, as stated in the next Proposition.\nProposition 7. Let γpg = log2 (tc(pg, 2 g)− 1) /2 ≈ log2 ( 1−pg pg ) /2. Given the approximation of DFS runtime of Proposition 6, BFS wins in expectation in a complete binary tree with depth D, goal level g and goal probability pg when\ng < D\n2 + γpg\nand DFS wins in expectation when g > D2 + γpg + 1 2 .\nThe term γpg is in the range [−1, 1] when pg ∈ [0.2, 0.75], g ≥ 2, in which case Proposition 7 roughly says that BFS wins (in expectation) when the goal level g is located higher than the middle of the tree. For smaller pg, BFS benefits with the boundary level being shifted γpg ≈ k/2 levels from the middle when pg ≈ 2−k 2−g. Figure 2 illustrates the prediction as a function of goal depth and tree depth for a fixed probability pg = 0.07.\nProof of Proposition 7. When no goal exists, BFS and DFS will perform the same. When the tree contains at least one goal node, BFS will found the goal somewhere on its sweep across level g, so the BFS runtime is bounded between 2g ≤ tBFSSGL(g, pg) ≤ 2g+1.\nThe upper bound for tBFSSGL(g, pg) gives that t BFS SGL(g, pg) < tDFS(D, g, pg) when 2g+1 < (tc(pg, 2 g)− 1) 2D−g+1. Taking the binary logarithm of both sides yields\ng + 1 < log2 (tc(pg, 2 g)− 1) +D − g + 1.\nCollecting the g’s on one side and dividing by 2 gives the desired bound\ng < log2(tc(pg, 2 g)− 1) 2 + D 2 = D 2 + γpg .\nSimilar calculations with the lower bound for tBFSSGL(g, pg) gives the condition for t̃DFSSGL(D, g, pg) < t BFS SGL(g, pg) when g > D 2 + γpg + 1 2 .\nIt is straightforward to generalise the calculations to arbitrary branching factor b, by just substituting the 2 in the base of tBFSSGL and t̃ DFS SGL for b. In Proposition 7, the change only affects the base of the logarithm in γpg .\nCorollary 8. Given the above approximations to BFS and DFS runtime, BFS wins in expectation in a complete tree with integer branching factor b ≥ 2, depth D, goal level g, and goal probability pg when g < D 2 + γb,pg , and DFS wins in expectation when g > D2 + γb,pg + 1 2 , where γb,pg = logb (tc(pg, b\ng)− 1) /2 ≈ logb( 1−pg pg )/2."
    }, {
      "heading" : "5.3 Complete Binary Tree with Multiple Goal Levels",
      "text" : "We now generalise the model developed in the previous section to problems that can have goals on any number of levels. For each level k ∈ {0, . . . , D}, let pk be the associated goal probability. Not every pk should be equal to 0. Nodes on level k have iid probability pk of being a goal. We will refer to this kind of problems as (multi goal level) complete binary trees with depth D and goal probabilities p."
    }, {
      "heading" : "5.3.1 DFS Analysis",
      "text" : "Our approximation of DFS performance in the case of multiple goal levels approximates the geometric distribution used in Proposition 6 with an exponential distribution (its continuous approximation by Lemma 3).\nProposition 9 (Expected Multi Goal Level DFS Performance). Consider a complete binary tree of depth D with goal probabilities p = [p0, . . . , pD] ∈ [0, 1)D+1. If for at least one j, pj 2−j, and for all k, pk 1, then the expected number of nodes DFS will search is approximately\nt̃DFSMGL(D,p) := 1/ D∑ k=0 ln(1− pk)−12−(D−k+1).\nThe proof constructs for each level k an exponential random variable Xk that approximates the search time before a goal is found on level k (disregarding goals on other levels). The minimum of all Xk then becomes an approximation of the search time to find a goal on any level. The approximations use exponential variables for easy minimisation.\nProof. The proof uses two approximations. First approximate the position of the first goal on level k with Yk ∼ Exp(λk), where λk = − ln(1 − pk). This is reasonable for the following reason. For pk 2−k, Yk is approximately Geo(pk), so the approximation is justifiable by Lemma 3. For smaller pk, the probability that this level has a goal is small, so the imprecision of the approximation does not affect the result significantly (as long as not all pj are this small).\nSecond, disregarding goals on levels other than k, the total number of nodes that DFS needs to search before reaching a goal on level k is approximately Xk ∼ Exp(λk2−(D−k+1)). This follows from an approximation of Proposition 6: The number of nodes DFS needs to search to find a goal on level k is\nt̃DFSSGL(D, k, pk, Yk) = (Yk − 1)2D−k+1 + 2 ≈ Yk · 2D−k+1.\n(This is a reasonable estimate if Yk is large, which is likely given that pk 1 by assumption.) So Xk is approximately a multiple 2\nD−k+1 of Yk. For any exponential random variable Z with parameter λ, the scaled variable m · Z is Exp(λ/m). This completes the justification of the second approximation.\nThe result now follows by a standard minimisation of exponential variables. Since Xk approximates the number of nodes searched before finding a goal on level k, the number of nodes searched before finding a goal on any level is X = minkXk. The CDF for X is\nP (X ≤ y) = 1− D∏ k=0 P (Xk > y)\n= 1− D∏ k=0 exp(−λk2−(D−k+1)y)\n= 1− exp(−y D∑ k=0 λk2 −(D−k+1)).\n(The minimum of exponential variables Zk ∼ Exp(ξk) is again an exponential variable Exp( ∑ ξk).)\nSoX ∼ Exp( ∑D k=0 λk2 −(D−k+1))) with the claimed expected value 1/ ∑D k=0 λk2 −(D−k+1)).\nIn the special case of a single goal level, the approximation of Proposition 9 is similar to the one given by Proposition 6. When p only has a single element pj 6= 0, the expression t̃DFSMGL simplifies to\nt̃DFSMGL(D,p) = 1 λj 2D−j+1 = − 1 ln(1− pj) 2D−j+1.\nFor pj not close to 1, the factor −1/ ln(1 − pj) is approximately the same as the corresponding factor 1/pj − 1 in Proposition 6 (the Laurent expansion is −1/ ln(1− pj) = 1/pj − 1/2 +O(pj))."
    }, {
      "heading" : "5.3.2 BFS Analysis",
      "text" : "The corresponding expected search time tBFSMGL(D,p) for BFS requires less insight and can be calculated exactly by conditioning on which level the first goal is. The resulting formula is less elegant, however. The same technique cannot be used for DFS, since DFS does not exhaust levels one by one.\nThe probability that level k has the first goal is P (Fk) = P (Γk) ∏k−1 j=0 P (Γ̄j),\nwhere P (Γi) = (1 − (1 − pi)2 i\n). The expected BFS search time gets a more uniform expression by the introduction of an extra hypothetical level D+ 1 where all nodes are goals. That is, level D + 1 has goal probability pD+1 = 1 and\nP (FD+1) = P (Γ̄) = 1− ∑D k=0 P (Fk).\nProposition 10 (Expected Multi Goal Level BFS Performance). The expected number of nodes tBFSMGL(p) that BFS needs to search to find a goal in a complete binary tree of depth D with goal probabilities p = [p0, . . . , pD], p 6= 0, is\ntBFSMGL(p) = D+1∑ k=0 P (Fk)t BFS SGL(k, pk | Γk) ≈ D+1∑ k=0 P (Fk) ( 2k + 1 pk ) For pk = 0, the expression t BFS CB (k, pk) and 1/pk will be undefined, but this\nonly occurs when P (Fk) is also 0.\nProof. To BFS, the event Fk that level k has a goal is equivalent to the single goal level model of Section 5.2. Let X be BFS search time, and let (X | Fk) be the number of nodes that BFS needs to search when k is the first level with a goal. Then (X | Fk) = tBFSSGL(k, pk, X − (2k− 1) | Γk), and E[X | Fk] = tBFSSGL(k, pk | Γk). The result follows by expanding E[X] over F0, . . . , FD+1 as in Lemma 4.\nThe approximation tends to be within a factor 2 of the correct expression, even when pk < 2\n−k for some or all pk ∈ p. The reason is that the corresponding P (Fk)’s are small when the geometric approximation is inaccurate.\nBoth Proposition 9 and 10 naturally generalise to arbitrary branching factor b. Although their combination does not yield a similarly elegant expression as Proposition 7, they can still be naively combined to predict the BFS vs. DFS winner (Figure 8)."
    }, {
      "heading" : "6 Colliding Branches",
      "text" : "The last section predicted runtime of tree search algorithms that do not remember which nodes they visit, which means that the search graph always has shape of a tree (with the same node possibly occurring in several places). In this section, we explore the performance of graph search algorithms that avoid revisiting previously explored nodes by keeping track of which nodes have already been seen. Figure 3 gives an idea of the difference between BFS and DFS in multiply connected graphs (with bounded search depth).\nDefinition 11. For a given search problem: Let the level of a node v, level(v), be the length of a shortest path from the start node to v. Let D = maxv level(v) be the (generalised) depth of the search graph. Let δn be the first node on level n reached by DFS, 0 ≤ n ≤ D.\nThe descendant counter L plays a central role in the analysis. For a given search problem, let\nL(n, d) = |{v : level(v) = d, v ∈ descendants(δn)}|\ncount the number of nodes on level d that are reachable from δn.\nAs in the previous section, we assume that goals are distributed by level in an iid manner according to a goal probability vector p. We will also assume that the probability of DFS finding a goal before finding δD is negligible. We will refer to\nthis kind of problems as search problems with depth D, goal probabilities p and descendant counter L. The rest of this section justifies the following proposition.\nProposition 12. The DFS and BFS runtime of a search problem can be roughly estimated from the descendant counter L, the depth D and the goal probabilities p = [p0, . . . , pD] when the probability of finding a goal before δD is negligible.\nThe assumption of DFS not finding a goal before δD is not always realistic, but is for example satisfied in the grammar problems considered in Section 7 below."
    }, {
      "heading" : "6.1 DFS Analysis",
      "text" : "The nodes δ0, . . . , δD play a central role in the analysis of DFS runtime, since all the descendants of δn+1 will be explored before the descendants of δn (excluding the δn+1 descendants). We say that DFS explores from δn after DFS has explored all descendants of δn+1 and until all descendants of δn have been explored. The general idea of the DFS analysis will be to count the number of nodes under each δn, and to compute the probability that any of these nodes is a goal.\nSome notation for this:\n• Let the δn-subgraph Sn = {v : v ∈ descendants(δn)} be the set of nodes reachable from δn, with cardinality |Sn| = ∑D i=0 L(n, i), 0 ≤ n ≤ D.\nLet SD+1 = ∅ and let S−1 be a set of cardinality |S−1| = |S0| + 1 =∑D i=0 L(0, i) + 1.\n• Let the δn-explorables Tn = Sn \\ Sn+1 be the nodes explored from δn.\n• Let the number of level-d δn-explorables An,d = L(n, d)− L(n+ 1, d) be the number of level d descendants of δn that are not descendants of δn+1 for 0 ≤ n, d ≤ D. The relation between Tn and An,d is the following: |Tn| = ∑D i=nAn,i.\nLet qk = 1− pk for 0 ≤ k ≤ D.\nLemma 13. Consider a search problem with depth D, goal probabilities p, and descendant counter L. The probability that the δn-explorables Tn contains a goal\nis τn := 1 − ∏D k=0 q An,k k , and the probability that Tn contains the first goal is\nφn := τn ∏D i=n+1(1− τi).\nProof. τn is 1 minus the probability of not hitting a goal at any level d, n ≤ d ≤ D, since at each level d, An,d probes are made when exploring from δn.\nProposition 14 (Colliding branches expected DFS search time). The expected DFS search time tDFSCB (D,p, L) in a search problem with depth D, goal probabilities p, and descendant counter L is bounded by\ntDFSCBL(D,p, L) := D∑ n=−1 |Sn+1|φn ≤ tDFSCB (D,p, L) ≤ D∑ n=−1 |Sn|φn := tDFSCBU(D,p, l) where φ−1 = Γ̄ = 1− ∑D n=0 φn is the probability that no goal exists.\nThe arithmetic mean t̃DFSCB (D,p, L) := (t DFS CBL(D,p, L) + t DFS CBU(D,p, L))/2\nbetween the bounds can be used for a single runtime estimate.\nProof. Let X be the DFS search time in a search problem with the features described above. The expectation of X may be decomposed as\nE[X] = P (Γ̄)E[X | Γ̄] + D∑ n=0 P (first goal in Tn) · E[X | first goal in Tn]. (1)\nThe conditional search time (X | first goal in Tn) is bounded by |Sn+1| ≤ (X | first goal in Tn) ≤ |Sn| for 0 ≤ n ≤ D, since to find a goal DFS will search the entire δn+1-subgraph Sn+1 before finding it when searching the δn-explorables Tn, but will not need to search more than the δn-subgraph Sn = Sn+1 ∪ Tn (disregarding the few probes made ‘on the way down to’ δn (i.e. to Tn); these probes were assumed negligible). The same bounds also hold with S0 and S−1 when no goal exists (recall that |S−1| := |S0| + 1). Therefore the conditional expectation satisfies\n|Sn+1| ≤ E[X | first goal in Tn] ≤ |Sn| (2)\nfor −1 ≤ n ≤ D. By Lemma 13, the probability that the first goal is among the δn-explorables Tn is φn, and the probability P (Γ̄) that no goal exists is φ−1 by definition.\nSubstituting φn and (2) into (1) gives the desired bounds for expected DFS search time t̃DFSCB (D,p, L) = E[X].\nThe informativeness of the bounds of Proposition 14 depends on the dispersion of nodes between the different Tn’s. If most nodes belong to one or a few sets Tn, the bounds may be almost completely uninformative. This happens in the special case of complete trees with branching factor b, where a fraction (b− 1)/b of the nodes will be in T0. The previous section derives techniques for these cases. The grammar problems investigated in Section 7 below show that the bounds may be relevant in more connected graphs, however."
    }, {
      "heading" : "6.2 BFS Analysis",
      "text" : "The analysis of BFS only requires the descendant counter L(0, ·) with the first argument set to 0, and follows the same structure as Section 5.3.2. In contrast to the DFS bounds above, this analysis gives a precise expression for the expected runtime. The idea is to count the number of nodes in the upper k levels of the tree (derived from L(0, 0), . . . , L(0, k)), and to compute the probability that\nthey contain a goal. Let the upper subgraph Uk = ∑k−1 i=0 L(0, i) be the number of nodes above level k When there is only a single goal level, Proposition 5 naturally generalises to the more general setting of this section.\nLemma 15 (BFS runtime Single Goal Level). For a search problem with depth D and descendant counter L, assume that the problem has a single goal level g with goal probability pg, and that pj = 0 for j 6= g. When a goal exists and has position Y on the goal level, the BFS search time is:\ntBFSCB (g, pg, L, Y ) = Ug + Y , with expected value\ntBFSCB (g, pg, L | Γg) = Ug + tc(pg, L(0, g))\nProof. When a goal exists, BFS will explore all of the top of the tree until depth g − 1 (that is, Ug nodes) and Y nodes on level g before finding the first goal. The expected value of Y is tc(pg, L(0, g)).\nThe probability that level k has a goal is P (Γk) = 1 − qL(0,k)k , and the probability that level k has the first goal is P (Fk) = P (Γk) ∏k−1 i=0 P (Γ̄i). By the same argument as in Proposition 10, the following proposition holds.\nProposition 16 (Branch Colliding Expected BFS Performance). The expected number of nodes that BFS needs to search to find a goal in a search problem with depth D, goal probabilities p = [p0, . . . , pD], p 6= 0, and descendant counter L is\ntBFSCB (p, L) = D+1∑ k=0 P (Fk)t BFS CB (k, pk, L | Γk)\nwhere the goal probabilities have been extended with an extra element pD+1 = 1, and FD+1 = Γ̄ is the event that no goal exists.\nFor pk = 0, t BFS CB will be undefined, but this only occurs when P (Fk) is also 0. Proposition 14 and 16 give (rough) estimates of average BFS and DFS graph search time given the goal distribution p and the structure parameter L. The results can be combined to make a decision whether to use BFS or DFS (Figure 5)."
    }, {
      "heading" : "7 Grammar Problems",
      "text" : "We now show how to apply the general theory of Section 6 to two concrete grammar problems. A grammar problem is a constructive search problem where nodes are strings over some finite alphabet B, and the neighbourhood relation is given by a set of production rules. Production rules are mappings x → y, x, y ∈ B∗, defining how strings may be transformed. For example, the production rule S → Sa permits the string aSa to be transformed into aSaa. A grammar problem is defined by a set of production rules, together with a starting string and a set of goal strings. A solution is a sequence of production rule applications that transforms the starting string into a goal string. Many search problems can be formulated as grammar problems, with string representations of states modified by production rules. Their generality makes it computably undecidable whether a given grammar problem has a solution or not. We here consider a simplified version where the search depth is artificially limited, and goals are distributed according to a goal probability vector p.\nGrammar problems exhibit two features not present in the complete tree model. First, it is possible for branches of the grammar tree to ‘die’. This happens if no production rule is applicable to the string of the state. Second, often the same string can be produced by different sequences, which means that the grammar search graph in general is not a tree. The following subsections apply the theory of Section 6 of colliding branches to simple grammar problems."
    }, {
      "heading" : "7.1 Binary Grammar",
      "text" : "Let be the empty string. The binary grammar consists of two production rules, → a and → b over the alphabet B = {a, b}. The starting string is the empty\nstring . A maximum depth D of the search graph is imposed, and strings on level k are goals with iid probability pk, 0 ≤ k ≤ D. Since the left hand substring of both production rules is the empty string, both can always be applied at any place to a given string. The resulting graph is shown in Figure 4.\nConsider a node v at level d. Its children are reached by either adding an a or by adding a b. Let #a denote the number of a’s in v, and let #b denote the number of b’s in v. Then #a+ 1 distinct strings can be created by adding a b, and #b+ 1 distinct strings can be created by adding an a. In total then, v will have (#a+ 1) + (#b+ 1) = d+ 2 children. Nodes further to the right will have more of their children previously discovered. The number of parents of a node is the number of contiguous ai and bj segments. For example, bbaaab have three segments bb-aaa-b and three parents b aaa b, bb aa b and bb aaa. A parent always differs from a child by the removal of one letter from one segment, and within a segment it is irrelevant which letter is removed.\nThe first node on level n that DFS reaches in the binary grammar problem is δn = a\nn for 0 ≤ n ≤ D, assuming that the production rule → a is always used first by DFS. The following lemma derives an expression for the descendant counter LBG required by Proposition 14. Incidentally, the number of level-d δn explorables An,d (Section 6.1) gets an elegant form in the binary grammar problem.\nLemma 17. For n < d, let LBG(n, d) = |{v : level(v) = d, v ∈ descendants(an)}| be the number of nodes reachable from an, and let An,d = L\nBG(n, d)−LBG(n+1, d) be the number of descendants of an that are not descendants of an+1. Then LBG(n, d) = ∑d−n i=0 ( d i ) , and An,d = ( d d−n ) .\nProof. The reachable nodes on level d that we wish to count are d−n levels below an. To reach this level we must add i ≤ d−n number of b’s and d−n− i number of a’s to an. The number of length d strings containing exactly i number of b’s is ( d i ) (we are choosing positions for the b’s non-uniquely with repetition among\nd− i+ 1 possible positions). Summing over i, we obtain LBG(n, d) = ∑d−n i=0 ( d i ) , and An,d = L BG(n, d)− LBG(n+ 1, d) = ( d d−n ) .\nCorollary 18 (Expected Binary Grammar BFS Search Time). The expected BFS search time t̃DFSBG (p) in a Binary Grammar Problem of depth D with goal probabilities p = [p0, . . . , pD] is\ntBFSBG (p) = t BFS CB (p, L BG).\nCorollary 19 (Expected Binary Grammar DFS Search Time). The expected DFS search time t̃DFSBG (D,p) in a binary grammar problem of depth D with goal probabilities p = [p0, . . . , pD] is bounded between t DFS BGL(D,p) := t DFS CBL(D,p, L\nBG) and tDFSBGU(D,p) := t DFS CBU(D,p, L BG), and is approximately\nt̃DFSBG (D,p) := t̃ DFS CB (D,p, L BG).\nProof of Corollary 18 and 19. Direct application of Lemma 17, and Proposition 16 and 14 respectively.\nThe bounds are plotted for a single goal level in Figure 5 and 6."
    }, {
      "heading" : "7.2 Random Grammar",
      "text" : "The Random Grammar Problem has alphabet B = {S, a, b} and start string S, The production rules always include S → (with denoting the empty string) plus a random subset of the adding rules S → Sa, S → Sb, S → aS, S → bS, and a random subset of the moving rules Sa → aS, Sb → bS, aS → Sa, and bS → Sb. Only strings containing no S can be goal nodes. As usual, a maximum depth D and a goal probability vector p = [p0, . . . , pD] are given.\nFor simplified analysis, we will abuse notation the following way. We will consider S-less nodes to be one level higher than they actually are. For example, we will consider a to be on level 1, although it is technically on level 2 or lower (e.g. reached by the path S → Sa, S → ). A slight modification of BFS and DFS makes them always check the S-less child first (which is always child-less in turn), which means the change will only slightly affect search time. We will still consider δn = Sa n whenever S → Sa is among the production rules, however.\nComplete Binary Tree\nBinary Grammar\nThe general case of when a random set of production rules are used is explored experimentally in Section 9. The special case of a binary tree arises when none of the moving rules are used, and either only the first two or only the last two of the addition rules. The analysis of Section 5.2 applies to this case. The special case when all rules are present can be analysed analytically by the means of Section 6. We will call this case the full grammar problem."
    }, {
      "heading" : "7.3 Full Grammar",
      "text" : "The search graph of the full grammar problem is shown in Figure 7 (edges induced by moving rules are not shown). Since there are four adding rules that can be applied to each node, each node will have four children. Typically, when we move further to the right in the tree, more children will already have been discovered.\nThe full grammar problem can be analysed by a reduction to a binary grammar problem with the same parameters D and p. Assign to each string v of the binary grammar problem the set of strings that only differ from v by (at most) an extra S. We call such sets node clusters. For example, {a, Sa, aS} constitutes the node cluster corresponding to a. Due to the abusing of levels for the S-less strings, all members of a cluster appear on the same level in the full grammar problem (the level is equal to the number of a’s and b’s). The level is also the same as the corresponding string in the binary grammar problem.\nLemma 20 (Binary Grammar Reduction). For every n, d, n ≤ d, the descendant counter LFG of the full grammar problem is LFG(n, d) = (d+ 2)LBG(n, d).\nProof. LBG(n, d) counts the level d descendants of an in the binary grammar problem (BGP), and LFG(n, d) counts the level d descendants of San in the full grammar problem (FGP). The node u is a child of v in BGP iff the members of the u node cluster are descendants of Su. Therefore the node clusters on level d descending from San in FGP correspond to the BGP nodes descending from an. At level d, each node cluster contains d+ 2 nodes.\nCorollary 21 (Expected Full Grammar BFS Search Time). The expected BFS search time t̃DFSFG (p) in a full grammar problem of depth D with goal probabilities p = [p0, . . . , pD] is\ntBFSFG (p) := t BFS CB (p, L FG).\nCorollary 22 (Expected Full Grammar DFS Search Time). The expected DFS search time t̃DFSFG (D, p) in a full grammar problem of depth D with goal probabilities p = [p0, . . . , pD] is bounded between t DFS FGL(D,p) := t DFS CBL(D,p, L\nFG) and tDFSFGU(D,p) := t DFS CBU(D,p, L FG), and is approximately\nt̃DFSFG (D,p) := t̃ DFS CB (D,p, L FG).\nProof of Corollary 21 and 22. Direct application of Lemma 20, and Proposition 16 and 14 respectively."
    }, {
      "heading" : "8 Experimental verification",
      "text" : "To verify the analytical results, we have implemented the models Sections 5–7 in Python 3 using the graph-tool package (Peixoto, 2015). The data reported in Tables 1–3 is based on an average of 1000 independently generated search problems with depth D = 14.\n• The first number in each box is the empirical average,\n• the second number is the analytical estimate, and\n• the third number is the percentage error of the analytical estimate.\nFor certain parameter settings, there is only a small chance (< 10−3) that there are no goals. In such circumstances, all 1000 generated search graphs typically inhabit a goal, and so the empirical search times will be comparatively small. However, since a tree of depth 14 has about 215 ≈ 3 · 105 nodes (and\na search algorithm must search through all of them in case there is no goal), the rarely occurring event of no goal can still influence the expected search time substantially. To avoid this sampling problem, we have ubiquitously discarded all instances where no goal is present, and compared the resulting averages to the analytical expectations conditioned on at least one goal being present.\nTo develop a concrete instance of the multi goal level model we consider the special case of Gaussian goal probability vectors, with two parameters µ and σ2. For a given depth D, the goal probabilities are given by\npi = min\n{ 1\n20 √ σ2 e(i−µ) 2/σ2 , 1 2\n} .\nThe parameter µ ∈ [0, D] ∩N is the goal peak, and the parameter σ2 ∈ R+ is the goal spread. The factor 1/20 is arbitrary, and chosen to give an interesting dynamics between searching depth-first and breadth-first. No pi should be greater than 1/2, in order to (roughly) satisfy the assumption of Proposition 10. We call this model the Gaussian binary tree.\nComplete Tree The accuracy of the predictions of Proposition 5 and 6 are shown in Table 1, and the accuracy of Proposition 9 and 10 in Table 2. The relative error is always small for BFS (< 10%). For DFS the error is generally within 20%, except when the search time is small (< 35 probes), in which case the absolute error is always small. The decision boundary of Proposition 7 is\nshown in Figure 2, and the decision boundary of Proposition 9 vs. 10 is shown in Figure 8. These boundary plots show that the analysis generally predict the correct BFS vs. DFS winner.\nGrammar The binary grammar model of Section 7.1 serves to verify the general estimates of Proposition 14 and 16. The results are shown in Table 3. The estimates for BFS are accurate as usual (< 3% error). With few exceptions, the lower and the upper bounds tDFSBGL and t DFS BGU of Corollary 19 for DFS differ by at most 50% on the respective sides from the true (empirical) average.The arithmetic mean t̃DFSBG often give surprisingly accurate predictions (< 4%) except when tDFSBGL and t DFS BGU leave wide margins as to the expected search time (when g = 14, the margin is up to 84% downwards and 125% upwards). Even then, the t̃DFSBG error remains within 30%."
    }, {
      "heading" : "9 Empirical Predictions",
      "text" : "The Random Grammar model of Section 7.2 exhibits a rich variety of topological features such as properties of the branching factor distribution. It is an interesting\nBG are mostly\naccurate. Each box contains empirical average/analytical expectation/error percentage.\nquestion to what extent such features can be used to predict whether BFS or DFS is the better search method. However, it is harder to approach analytically, due to its many cases not the least. We therefore approached this problem empirically.\nWe generated a data set with 1827 randomly sampled random grammars. The sampling was done uniformly from the following sets: First sample a number of rules r ∈ [4, 8] ∩ N, then a random size r subset of the 8 possible production rules. Also sample maximum depth D ∈ [11, 15] ∩ N. Sample a number of goals n ∈ [3, 5D] ∩ N. Sample n times a level k ∈ [1, D] ∩ N and a node on level k; make the sampled node a goal.\nWe trained a Support Vector Machine from the scikit-learn package (Pedregosa et al., 2011) with a (Gaussian) Radial Basis Kernel to predict whether BFS or DFS would find a first goal faster. The features we predicted from were\n• Mean branching factor\n• Standard deviation of branching factor\n• Number of rules\n• Maximum depth\nThe best parameter settings for the support vector machine were C = 1000, degree = 3, γ = 0.1. Against a cross-validation data set, the trained support vector classifier got the BFS/DFS winner correct in 63% of the cases, in a dataset where DFS won 55% of the time. The results give an early indication that it may be possible to predict the best search method based solely on locally estimable features of the search graph."
    }, {
      "heading" : "10 Discussion",
      "text" : "Search and optimisation problems appears in different flavors throughout the field of artificial intelligence; in planning, problem solving, games, and learning. Therefore even minor improvements to search performance can potentially lead to gains in many aspects of intelligent systems. It is even possible to equate intelligence with (Bayesian expectimax) optimisation performance (Legg and Hutter, 2007).\nSummary. In this report we have derived analytical results for expected runtime performance. Section 5 focused on BFS and DFS tree search where explored nodes were not remembered. A vector p = (p1, . . . , pD) described a priori goal probabilities for the different levels of the tree. This concrete but general model of goal distribution allowed us to calculate approximate closedform expression of both BFS and DFS average runtime. Earlier studies have only addressed worst-case runtimes: Knuth (1975) and followers for DFS; Korf et al. (2001) and followers for IDA*, effectively a generalised version of BFS.\nSection 6 and 7 generalised the model of Section 5 to non-tree graphs. In addition to the goal probability vector p, the graph search analysis required additional structural information in the form of a descendant counter L. The graph search estimates also took the form of less precise bounds. The analysis of Section 6 does not supersede the analysis in Section 5, as the bounds of\nSection 6 become uninformative when the graph is a tree. The results are generally consistent with empirical reality.\nConclusions and Outlook. The value of the results are at least twofold. They offer a concrete means of deciding between BFS and DFS given some rough idea of the location of the goal (and the graph structure). To make the results more generally usable, automatic inference of model parameters would be necessary; primarily of goal distribution p and graph structure L. (The depth D will often be set by the searcher itself, and perhaps be iteratively increased.) There is good hope that the descendant counter L can be estimated online from the local sample obtained during search, similar to (Knuth, 1975). The goal distribution is likely to prove more challenging, but resembles the automatic creation of heuristic functions, so techniques such as relaxed problems could well prove useful (Pearl, 1984). Estimates of goal distribution could possible also be inferred from a heuristic function.\nThe results also offer theoretical insight into BFS and DFS performance. As BFS and DFS are in a sense the most fundamental search operations, we have high hopes that our results and techniques will prove useful as building blocks for analysis of more advanced search algorithms as well. For example, A* and IDA* may be viewed as a generalisations of BFS, and Beam Search and Greedy Best-First as generalisations of DFS."
    }, {
      "heading" : "A List of notation",
      "text" : "P Probability X, Y Random variables E[ · ] Expectation of a random variable O Big-O notation EC Edge cost h Heuristic function g Accumulated path cost from start node Q Objective function D Maximum depth of search space pg Goal probability at a single goal level g pk Goal probability for a level k p Vector of probabilities for multiple goal levels µ, σ2 Goal peak and goal spread in Gaussian binary tree Γ Probability that a goal exists Γk Probability that level k has a goal Fk Probability that level k has the first goal tBFSSGL, t̃ DFS SGL Expected BFS search time and approximate expected DFS search time in a complete tree with a single goal level tBFSMGL, t̃ DFS MGL Expected BFS search time and approximate expected DFS search time in a complete tree with multiple goal levels tBFSCB , t̃ DFS CB Expected BFS search time and approximate expected DFS search time in a graph with colliding branches tBFSBG , t̃ DFS BG Expected BFS search time and approximate expected DFS search time in the binary grammar problem tBFSFG , t̃ DFS FG Expected BFS search time and approximate expected DFS search time in the full grammar problem δn The first node on level n reached by DFS L(n, d) Descendant counter, counting the number of level d descendants reachable from δn LFG, LBG Descendant counters for the binary grammar problem and the full grammar problem An,d Number of nodes reachable from δn not reachable from δn+1 Sn Descendants of δn Tn Descendants of δn that are not descendants of δn+1 Un The number of nodes above level n. τn The probability that Tn contains a goal (Lemma 13) φn The probability that Tn inhabits the first goal b Branching factor Empty string"
    }, {
      "heading" : "B List of search problems",
      "text" : "The following is an incomplete list of problems naturally modelled as search problems, organised by type.\n• Puzzles\n– N-puzzle\n– Instant insanity (Knuth 1975)\n– Eternity II (Assembly puzzles)\n• Infinite\n– Grammar (aka Production system; simpler PSVN)\n– STRIPS planning (PDDL language)\n– Root-factorial (Knuth)\n• Real-world problems\n– MDP\n– SAT\n– VLSI chip design (cell layout, channel routing)\n– Robot navigation (continuous)\n– Route finding\n– Tour finding\n– Assembly sequencing\n– Protein design\n– Jobshop (who does what task when)\n• Other\n– Towers of Hanoi\n– Cannibal-missionary\n– Sokoban\n– Rubik’s cube\n– Sudoku\n– Knight jumping\n– N-queens\n– Belief state (in a deterministic, partially observable world)\n– Quasigroup completion problem (Gomes et al., 1997), naturally CSP\n– Counterfeit coin problem (Pearl, 1988)"
    }, {
      "heading" : "C List of Topological features",
      "text" : "The neighbourhood relation N induces a topology on the state space S. The goal of this study is to closer investigate how topological features of the search graph affects search performance. Following is a list of potentially useful features, where +, ?, - ranks the features by a priori likelihood of being useful. Please refer to (Diestel, 2006) for a standard reference on graph theory and for explanations and definitions of below terms.\n• Problem type + Directed/undirected graph\n• State space + number of nodes (finite or infinite)\n- number of edges\n• Graph structure - bipartite/k-partite\n+ clique size distribution\n+ clique covering number (how many cliques are required to cover the graph?)\n- chordal (every cycle of length ≥ 4 has a ”chord”) - stability number (greatest number of non-connected nodes)\n+ degree (max/min/average)\n- min cycle (girth)\n- max cycle (circumference)\n- diameter = maxx,y distance(x, y)\n- radius = minx maxy distance(x, y) (x is ‘the centre’ of the graph). The radius satisfies radius(G) ≤ diameter(G) ≤ 2 · radius(G).\n• Tree structure + height\n+ max width\n+ width as a function of depth\n• Branching factor + Distribution (possibly as a function of depth)\n+ Max\n+ Effective (when using heuristic)\n• Path length + Max/average path length from origin, repeating allowed/disallowed\n• Path redundancy + k-connectedness (every node pair have at least k independent paths)\n- l-edge-connectedness (no cutset of l edges)\n+ distribution of connectedness/revisiting frequency\n• Matrix properties + Spectrum (Spectral Graph Theory)\n• Edge space ? Cyclomatic number (defined in (Diestel, 2006, p. 24) as the dimension\nof the space formed by cycles – a subspace of the space of edges under ”symmetric difference”)\n- Cut space dimension\nMany properties of the search graph can be estimated from local samples. For example, Wu and Preciado (2013) show that the spectrum of the graph (i.e., the eigenvalues of the matrix representation of the graph) can be estimated this way."
    } ],
    "references" : [ {
      "title" : "Learning During Search",
      "author" : [ "A. Arbelaez Rodriguez" ],
      "venue" : "Phd thesis, University of Paris-Sud",
      "citeRegEx" : "Rodriguez,? \\Q2011\\E",
      "shortCiteRegEx" : "Rodriguez",
      "year" : 2011
    }, {
      "title" : "Metaheuristics in Combinatorial Optimization: Overview and Conceptual Comparison",
      "author" : [ "C. Blum", "A. Roli" ],
      "venue" : "ACM Computing Surveys,",
      "citeRegEx" : "Blum and Roli,? \\Q2003\\E",
      "shortCiteRegEx" : "Blum and Roli",
      "year" : 2003
    }, {
      "title" : "Hyper Heuristics: an emerging direction in modern search technology",
      "author" : [ "E. Burke", "E. Hart", "G. Kendall", "J. Newall", "P. Ross", "S. Schulenburg" ],
      "venue" : "Handbook of Metaheuristics,",
      "citeRegEx" : "Burke et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Burke et al\\.",
      "year" : 2003
    }, {
      "title" : "Hyper-heuristics: a survey of the state of the art",
      "author" : [ "E.K. Burke", "M. Gendreau", "M. Hyde", "G. Kendall", "G. Ochoa 1ã", "E. Zcan", "R. Qu" ],
      "venue" : "Journal of the Operational Research Society,",
      "citeRegEx" : "Burke et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Burke et al\\.",
      "year" : 2013
    }, {
      "title" : "Heuristic Sampling: A Method for Predicting the Performance of Tree Searching Programs",
      "author" : [ "P.C. Chen" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Chen,? \\Q1992\\E",
      "shortCiteRegEx" : "Chen",
      "year" : 1992
    }, {
      "title" : "Explanation-based Learning: An Alternative View",
      "author" : [ "G. Dejong", "R. Mooney" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Dejong and Mooney,? \\Q1986\\E",
      "shortCiteRegEx" : "Dejong and Mooney",
      "year" : 1986
    }, {
      "title" : "Graph Theory (Graduate Texts in Mathematics)",
      "author" : [ "R. Diestel" ],
      "venue" : null,
      "citeRegEx" : "Diestel,? \\Q2006\\E",
      "shortCiteRegEx" : "Diestel",
      "year" : 2006
    }, {
      "title" : "Acquiring search-control knowledge via static analysis",
      "author" : [ "O. Etzioni" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Etzioni,? \\Q1993\\E",
      "shortCiteRegEx" : "Etzioni",
      "year" : 1993
    }, {
      "title" : "Analytical Results on the BFS vs. DFS Algorithm Selection Problem",
      "author" : [ "T. Everitt", "M. Hutter" ],
      "venue" : "Part I: Tree Search. In 28th Australian Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Everitt and Hutter,? \\Q2015\\E",
      "shortCiteRegEx" : "Everitt and Hutter",
      "year" : 2015
    }, {
      "title" : "Analytical Results on the BFS vs. DFS Algorithm Selection Problem. Part II: Graph Search",
      "author" : [ "T. Everitt", "M. Hutter" ],
      "venue" : "In 28th Australian Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Everitt and Hutter,? \\Q2015\\E",
      "shortCiteRegEx" : "Everitt and Hutter",
      "year" : 2015
    }, {
      "title" : "How to Solve It Automatically: Selection Among ProblemSolving Methods",
      "author" : [ "E. Fink" ],
      "venue" : "In Proceedings of the Fourth International Conference on Artificial Intelligence Planning Systems,",
      "citeRegEx" : "Fink,? \\Q1998\\E",
      "shortCiteRegEx" : "Fink",
      "year" : 1998
    }, {
      "title" : "Heavy-tailed distributions in combinatorial search",
      "author" : [ "C.P. Gomes", "B. Selman", "N. Crato" ],
      "venue" : "Principles and Practice of Constraint",
      "citeRegEx" : "Gomes et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Gomes et al\\.",
      "year" : 1997
    }, {
      "title" : "Online estimation of SAT solving runtime",
      "author" : [ "S. Haim", "T. Walsh" ],
      "venue" : "In Theory and Applications of Satisfiability Testing,",
      "citeRegEx" : "Haim and Walsh,? \\Q2008\\E",
      "shortCiteRegEx" : "Haim and Walsh",
      "year" : 2008
    }, {
      "title" : "Programming by optimization",
      "author" : [ "H.H. Hoos" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "Hoos,? \\Q2012\\E",
      "shortCiteRegEx" : "Hoos",
      "year" : 2012
    }, {
      "title" : "Algorithm runtime prediction: Methods & evaluation",
      "author" : [ "F. Hutter", "L. Xu", "H.H. Hoos", "K. Leyton-Brown" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Hutter et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hutter et al\\.",
      "year" : 2014
    }, {
      "title" : "Estimating Search Tree Size",
      "author" : [ "P. Kilby", "J. Slaney", "S. Thiébaux", "T. Walsh" ],
      "venue" : "In Proc. of the 21st National Conf. of Artificial Intelligence,",
      "citeRegEx" : "Kilby et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Kilby et al\\.",
      "year" : 2006
    }, {
      "title" : "Estimating the efficiency of backtrack programs",
      "author" : [ "D.E. Knuth" ],
      "venue" : "Mathematics of Computation,",
      "citeRegEx" : "Knuth,? \\Q1975\\E",
      "shortCiteRegEx" : "Knuth",
      "year" : 1975
    }, {
      "title" : "Time complexity of iterativedeepening-A",
      "author" : [ "R.E. Korf", "M. Reid", "S. Edelkamp" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Korf et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Korf et al\\.",
      "year" : 2001
    }, {
      "title" : "Algorithm Selection for Combinatorial Search Problems: A Survey",
      "author" : [ "L. Kotthoff" ],
      "venue" : "AI Magazine,",
      "citeRegEx" : "Kotthoff,? \\Q2014\\E",
      "shortCiteRegEx" : "Kotthoff",
      "year" : 2014
    }, {
      "title" : "Fundaments of Branching Heuristics: Theory and Examples",
      "author" : [ "O. Kullmann" ],
      "venue" : "Technical report,",
      "citeRegEx" : "Kullmann,? \\Q2008\\E",
      "shortCiteRegEx" : "Kullmann",
      "year" : 2008
    }, {
      "title" : "Inductive learning of search control rules for planning",
      "author" : [ "C. Leckie", "I. Zukerman" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Leckie and Zukerman,? \\Q1998\\E",
      "shortCiteRegEx" : "Leckie and Zukerman",
      "year" : 1998
    }, {
      "title" : "Predicting the size of Depthfirst Branch and Bound search trees",
      "author" : [ "L.H.S. Lelis", "L. Otten", "R. Dechter" ],
      "venue" : "IJCAI International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Lelis et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lelis et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning Search Control Knowledge: An Explanation-Based Approach",
      "author" : [ "S. Minton" ],
      "venue" : null,
      "citeRegEx" : "Minton,? \\Q1988\\E",
      "shortCiteRegEx" : "Minton",
      "year" : 1988
    }, {
      "title" : "Quantitative results concerning the utility of explanationbased learning",
      "author" : [ "S. Minton" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Minton,? \\Q1990\\E",
      "shortCiteRegEx" : "Minton",
      "year" : 1990
    }, {
      "title" : "Explanation-based generalization: A unifying view",
      "author" : [ "T. Mitchell", "R. Keller", "S. Kedar-CabeUi" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Mitchell et al\\.,? \\Q1986\\E",
      "shortCiteRegEx" : "Mitchell et al\\.",
      "year" : 1986
    }, {
      "title" : "Heuristics: Intelligent Search Strategies for Computer Problem Solving",
      "author" : [ "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "Pearl,? \\Q1984\\E",
      "shortCiteRegEx" : "Pearl",
      "year" : 1984
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "author" : [ "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "Pearl,? \\Q1988\\E",
      "shortCiteRegEx" : "Pearl",
      "year" : 1988
    }, {
      "title" : "The graph-tool python library. figshare",
      "author" : [ "T.P. Peixoto" ],
      "venue" : null,
      "citeRegEx" : "Peixoto,? \\Q2015\\E",
      "shortCiteRegEx" : "Peixoto",
      "year" : 2015
    }, {
      "title" : "Tree Size by Partial Backtracking",
      "author" : [ "P.W. Purdom" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Purdom,? \\Q1978\\E",
      "shortCiteRegEx" : "Purdom",
      "year" : 1978
    }, {
      "title" : "The algorithm selection problem",
      "author" : [ "J.R. Rice" ],
      "venue" : "Advances in Computers,",
      "citeRegEx" : "Rice,? \\Q1975\\E",
      "shortCiteRegEx" : "Rice",
      "year" : 1975
    }, {
      "title" : "The diameter of the rubiks cube group is twenty",
      "author" : [ "T. Rokicki", "H. Kociemba" ],
      "venue" : "SIAM Journal on Discrete Mathematics,",
      "citeRegEx" : "Rokicki and Kociemba,? \\Q2013\\E",
      "shortCiteRegEx" : "Rokicki and Kociemba",
      "year" : 2013
    }, {
      "title" : "Hyperheuristics: learning to combine simple heuristics in bin-packing problems",
      "author" : [ "P. Ross", "S. Schulenburg", "J.G. Marin-Blazquez", "E. Hart" ],
      "venue" : null,
      "citeRegEx" : "Ross et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Ross et al\\.",
      "year" : 2002
    }, {
      "title" : "Artificial intelligence: a modern approach",
      "author" : [ "S.J. Russell", "P. Norvig" ],
      "venue" : null,
      "citeRegEx" : "Russell and Norvig,? \\Q2010\\E",
      "shortCiteRegEx" : "Russell and Norvig",
      "year" : 2010
    }, {
      "title" : "Measuring instance difficulty for combinatorial optimization problems",
      "author" : [ "K. Smith-Miles", "L. Lopes" ],
      "venue" : "Computers and Operations Research,",
      "citeRegEx" : "Smith.Miles and Lopes,? \\Q2012\\E",
      "shortCiteRegEx" : "Smith.Miles and Lopes",
      "year" : 2012
    }, {
      "title" : "Metareasoning about propagators for constraint satisfaction",
      "author" : [ "C. Thompson" ],
      "venue" : "Phd thesis, University of Saskatchewan",
      "citeRegEx" : "Thompson,? \\Q2011\\E",
      "shortCiteRegEx" : "Thompson",
      "year" : 2011
    }, {
      "title" : "Laplacian Spectral Properties of Graphs from Random Local Samples",
      "author" : [ "Z. Wu", "V.M. Preciado" ],
      "venue" : null,
      "citeRegEx" : "Wu and Preciado,? \\Q2013\\E",
      "shortCiteRegEx" : "Wu and Preciado",
      "year" : 2013
    }, {
      "title" : "Predicting the performance of IDA* using conditional distributions",
      "author" : [ "U. Zahavi", "A. Felner", "N. Burch", "R.C. Holte" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Zahavi et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Zahavi et al\\.",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 32,
      "context" : "A wide range of problems in artificial intelligence can be naturally formulated as search problems (Russell and Norvig, 2010; Edelkamp and Schrödl, 2012).",
      "startOffset" : 99,
      "endOffset" : 153
    }, {
      "referenceID" : 29,
      "context" : "Predicting the best algorithm is sometimes known as the algorithm selection problem (Rice, 1975).",
      "startOffset" : 84,
      "endOffset" : 96
    }, {
      "referenceID" : 18,
      "context" : "A number of studies have approached the algorithm selection problem with machine learning techniques (Kotthoff, 2014; Hutter et al., 2014).",
      "startOffset" : 101,
      "endOffset" : 138
    }, {
      "referenceID" : 14,
      "context" : "A number of studies have approached the algorithm selection problem with machine learning techniques (Kotthoff, 2014; Hutter et al., 2014).",
      "startOffset" : 101,
      "endOffset" : 138
    }, {
      "referenceID" : 14,
      "context" : "A number of studies have approached the algorithm selection problem with machine learning techniques (Kotthoff, 2014; Hutter et al., 2014). While demonstrably a feasible path, machine learning tend to be used as a black box, offering little insight into why a certain method works better on a given problem. On the other hand, most existing analytical results focus on worst-case big-O analysis, which is often less useful than average-case analysis when selecting algorithm. An important worst-case result is Knuth’s (1975) simple but useful technique",
      "startOffset" : 118,
      "endOffset" : 525
    }, {
      "referenceID" : 12,
      "context" : "Kilby et al. (2006) used it for algorithm selection in the SAT problem.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 12,
      "context" : "Kilby et al. (2006) used it for algorithm selection in the SAT problem. See also the extensions by Purdom (1978), Chen (1992), and Lelis et al.",
      "startOffset" : 0,
      "endOffset" : 113
    }, {
      "referenceID" : 4,
      "context" : "See also the extensions by Purdom (1978), Chen (1992), and Lelis et al.",
      "startOffset" : 42,
      "endOffset" : 54
    }, {
      "referenceID" : 4,
      "context" : "See also the extensions by Purdom (1978), Chen (1992), and Lelis et al. (2013). Analytical IDA* runtime predictions based on problem features was obtained by Korf et al.",
      "startOffset" : 42,
      "endOffset" : 79
    }, {
      "referenceID" : 4,
      "context" : "See also the extensions by Purdom (1978), Chen (1992), and Lelis et al. (2013). Analytical IDA* runtime predictions based on problem features was obtained by Korf et al. (2001) and Zahavi et al.",
      "startOffset" : 42,
      "endOffset" : 177
    }, {
      "referenceID" : 4,
      "context" : "See also the extensions by Purdom (1978), Chen (1992), and Lelis et al. (2013). Analytical IDA* runtime predictions based on problem features was obtained by Korf et al. (2001) and Zahavi et al. (2010). In this study we focus on theoretical analysis of average runtime of BFS and DFS.",
      "startOffset" : 42,
      "endOffset" : 202
    }, {
      "referenceID" : 1,
      "context" : "Blum and Roli (2003) suggest that this offers a unified view of many search problems.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 1,
      "context" : "Blum and Roli (2003) suggest that this offers a unified view of many search problems. A CSP formulation also seems largely in line with what Pearl (1988) has in mind, although Pearl is less specific.",
      "startOffset" : 0,
      "endOffset" : 154
    }, {
      "referenceID" : 32,
      "context" : "We here review only a subset of the more important ones, and refer to the books (Russell and Norvig, 2010; Edelkamp and Schrödl, 2012) for more details.",
      "startOffset" : 80,
      "endOffset" : 134
    }, {
      "referenceID" : 29,
      "context" : "The algorithm selection problem asks what algorithm best to use on a given problem (Rice, 1975; Kotthoff, 2014).",
      "startOffset" : 83,
      "endOffset" : 111
    }, {
      "referenceID" : 18,
      "context" : "The algorithm selection problem asks what algorithm best to use on a given problem (Rice, 1975; Kotthoff, 2014).",
      "startOffset" : 83,
      "endOffset" : 111
    }, {
      "referenceID" : 28,
      "context" : "Several generalisations have been developed (Purdom, 1978; Chen, 1992).",
      "startOffset" : 44,
      "endOffset" : 70
    }, {
      "referenceID" : 4,
      "context" : "Several generalisations have been developed (Purdom, 1978; Chen, 1992).",
      "startOffset" : 44,
      "endOffset" : 70
    }, {
      "referenceID" : 34,
      "context" : "Schemes using much wider ranges of problem properties are applied to CSPs in (Thompson, 2011; Arbelaez Rodriguez, 2011), and to the NP-complete problems SAT, TSP and Mixed integer programming in (Hutter et al.",
      "startOffset" : 77,
      "endOffset" : 119
    }, {
      "referenceID" : 14,
      "context" : "Schemes using much wider ranges of problem properties are applied to CSPs in (Thompson, 2011; Arbelaez Rodriguez, 2011), and to the NP-complete problems SAT, TSP and Mixed integer programming in (Hutter et al., 2014).",
      "startOffset" : 195,
      "endOffset" : 216
    }, {
      "referenceID" : 10,
      "context" : "The most comprehensive surveys are given by Hutter et al. (2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011).",
      "startOffset" : 44,
      "endOffset" : 65
    }, {
      "referenceID" : 10,
      "context" : "The most comprehensive surveys are given by Hutter et al. (2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011).",
      "startOffset" : 44,
      "endOffset" : 85
    }, {
      "referenceID" : 10,
      "context" : "The most comprehensive surveys are given by Hutter et al. (2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011).",
      "startOffset" : 44,
      "endOffset" : 121
    }, {
      "referenceID" : 0,
      "context" : "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime.",
      "startOffset" : 76,
      "endOffset" : 93
    }, {
      "referenceID" : 0,
      "context" : "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime.",
      "startOffset" : 76,
      "endOffset" : 116
    }, {
      "referenceID" : 0,
      "context" : "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth’s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime.",
      "startOffset" : 76,
      "endOffset" : 449
    }, {
      "referenceID" : 0,
      "context" : "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth’s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al.",
      "startOffset" : 76,
      "endOffset" : 615
    }, {
      "referenceID" : 0,
      "context" : "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth’s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms.",
      "startOffset" : 76,
      "endOffset" : 639
    }, {
      "referenceID" : 0,
      "context" : "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth’s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy.",
      "startOffset" : 76,
      "endOffset" : 726
    }, {
      "referenceID" : 0,
      "context" : "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth’s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy. In the case of informed search, Korf et al. (2001) developed an interesting analytic technique for estimating the search time of IDA*.",
      "startOffset" : 76,
      "endOffset" : 966
    }, {
      "referenceID" : 0,
      "context" : "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth’s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy. In the case of informed search, Korf et al. (2001) developed an interesting analytic technique for estimating the search time of IDA*. Assuming a consistent heuristic function, the estimate is based on the distribution of heuristic function values at different depths of the search tree, rather than heuristic accuracy. Intuitively, the scheme works because the number of nodes expanded in each iteration of IDA* depends on the number of nodes with heuristic value less than the threshold. The distribution of heuristic values is also easy to estimate in practice. Zahavi et al. (2010) generalise the work of Korf et al.",
      "startOffset" : 76,
      "endOffset" : 1501
    }, {
      "referenceID" : 0,
      "context" : "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth’s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy. In the case of informed search, Korf et al. (2001) developed an interesting analytic technique for estimating the search time of IDA*. Assuming a consistent heuristic function, the estimate is based on the distribution of heuristic function values at different depths of the search tree, rather than heuristic accuracy. Intuitively, the scheme works because the number of nodes expanded in each iteration of IDA* depends on the number of nodes with heuristic value less than the threshold. The distribution of heuristic values is also easy to estimate in practice. Zahavi et al. (2010) generalise the work of Korf et al. to non-consistent heuristics. Many other approaches instead try to directly infer the best search policy, without the intermediate step of estimating runtime. Fink (1998) does this for STRIPS-like learning using only the problem size to infer which method is likely to be more efficient.",
      "startOffset" : 76,
      "endOffset" : 1707
    }, {
      "referenceID" : 0,
      "context" : "(2014) and Kotthoff (2014), and the PhD theses Thompson (2011) and Arbelaez Rodriguez (2011). For DFS, Knuth (1975) made a simple but important observation how the branching factor seen during search can be used to estimate the size of the search tree and the runtime. Despite the simplicity of the scheme, the estimates work surprisingly well in practice. Several generalisations have been developed (Purdom, 1978; Chen, 1992). Kilby et al. (2006) generalise Knuth’s method, and also use it to select search policy for the SAT problem based on which search policy has the lowest estimated runtime. Kullmann (2008) and Lelis et al. (2013) both develop estimation schemes for branch-and-bound algorithms. Haim and Walsh (2008) approach the SAT problem, and instead of branching factor use properties of the given formula (such as the number and the size of clauses) to be predict search time and best search policy. In the case of informed search, Korf et al. (2001) developed an interesting analytic technique for estimating the search time of IDA*. Assuming a consistent heuristic function, the estimate is based on the distribution of heuristic function values at different depths of the search tree, rather than heuristic accuracy. Intuitively, the scheme works because the number of nodes expanded in each iteration of IDA* depends on the number of nodes with heuristic value less than the threshold. The distribution of heuristic values is also easy to estimate in practice. Zahavi et al. (2010) generalise the work of Korf et al. to non-consistent heuristics. Many other approaches instead try to directly infer the best search policy, without the intermediate step of estimating runtime. Fink (1998) does this for STRIPS-like learning using only the problem size to infer which method is likely to be more efficient. Schemes using much wider ranges of problem properties are applied to CSPs in (Thompson, 2011; Arbelaez Rodriguez, 2011), and to the NP-complete problems SAT, TSP and Mixed integer programming in (Hutter et al., 2014). Smith-Miles and Lopes (2012) review and discuss commonly used features for the algorithm selection problem, mainly applied to the local search scenario.",
      "startOffset" : 76,
      "endOffset" : 2071
    }, {
      "referenceID" : 5,
      "context" : "Explanation-based Learning (EBL) (Dejong and Mooney, 1986; Mitchell et al., 1986; Minton, 1988) is a general method for learning from examples and domain knowledge.",
      "startOffset" : 33,
      "endOffset" : 95
    }, {
      "referenceID" : 24,
      "context" : "Explanation-based Learning (EBL) (Dejong and Mooney, 1986; Mitchell et al., 1986; Minton, 1988) is a general method for learning from examples and domain knowledge.",
      "startOffset" : 33,
      "endOffset" : 95
    }, {
      "referenceID" : 22,
      "context" : "Explanation-based Learning (EBL) (Dejong and Mooney, 1986; Mitchell et al., 1986; Minton, 1988) is a general method for learning from examples and domain knowledge.",
      "startOffset" : 33,
      "endOffset" : 95
    }, {
      "referenceID" : 22,
      "context" : "While attractive, it can also lead to overspecific learning (Minton, 1988).",
      "startOffset" : 60,
      "endOffset" : 74
    }, {
      "referenceID" : 7,
      "context" : "Partial Evaluation (PE) is an alternative learning method that is more robust in this respect, with less dependency on examples (Etzioni, 1993).",
      "startOffset" : 128,
      "endOffset" : 143
    }, {
      "referenceID" : 3,
      "context" : "Some research is also being done on automatic construction of low-level heuristics (see (Burke et al., 2013) for references).",
      "startOffset" : 88,
      "endOffset" : 108
    }, {
      "referenceID" : 13,
      "context" : "A related approach directed at programming in general is programming by optimisation (Hoos, 2012), where machine learning techniques are used to find the best algorithm in a space of programs delineated by the human programmer.",
      "startOffset" : 85,
      "endOffset" : 97
    }, {
      "referenceID" : 5,
      "context" : "Partial Evaluation (PE) is an alternative learning method that is more robust in this respect, with less dependency on examples (Etzioni, 1993). Leckie and Zukerman (1998) develops a more inductive way to learn search control knowledge (in contrast to the deductive generalisations performed by EBL and PE), where plenty of training examples substitute for domain knowledge.",
      "startOffset" : 129,
      "endOffset" : 172
    }, {
      "referenceID" : 2,
      "context" : "A more modern approach is known as hyper heuristics (Burke et al., 2003, 2013). It views the problem of inferring good search policies more abstractly. Rather than interacting with the neighbourhood structure/graph problem directly, the hyper heuristic only has access to a set of search policies for the original graph problem. The search policies are known as low-level heuristics in this literature (not to be confused with heuristic functions). The goal of the hyper heuristic is to find a good policy for when to apply which low-level heuristic. For example, Ross et al. (2002) used Genetic Algorithms to learn which binpacking heuristic to apply in which type of state in a bin-packing problem.",
      "startOffset" : 53,
      "endOffset" : 583
    }, {
      "referenceID" : 30,
      "context" : "There is an upper bound D = 20 to how many moves it can take to reach the goal (Rokicki and Kociemba, 2013).",
      "startOffset" : 79,
      "endOffset" : 107
    }, {
      "referenceID" : 17,
      "context" : "Korf et al. (2001) study",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 27,
      "context" : "To verify the analytical results, we have implemented the models Sections 5–7 in Python 3 using the graph-tool package (Peixoto, 2015).",
      "startOffset" : 119,
      "endOffset" : 134
    }, {
      "referenceID" : 16,
      "context" : "Earlier studies have only addressed worst-case runtimes: Knuth (1975) and followers for DFS; Korf et al.",
      "startOffset" : 57,
      "endOffset" : 70
    }, {
      "referenceID" : 16,
      "context" : "Earlier studies have only addressed worst-case runtimes: Knuth (1975) and followers for DFS; Korf et al. (2001) and followers for IDA*, effectively a generalised version of BFS.",
      "startOffset" : 57,
      "endOffset" : 112
    }, {
      "referenceID" : 16,
      "context" : ") There is good hope that the descendant counter L can be estimated online from the local sample obtained during search, similar to (Knuth, 1975).",
      "startOffset" : 132,
      "endOffset" : 145
    }, {
      "referenceID" : 25,
      "context" : "The goal distribution is likely to prove more challenging, but resembles the automatic creation of heuristic functions, so techniques such as relaxed problems could well prove useful (Pearl, 1984).",
      "startOffset" : 183,
      "endOffset" : 196
    } ],
    "year" : 2015,
    "abstractText" : "Search is a central problem in artificial intelligence, and BFS and DFS the two most fundamental ways to search. In this report we derive results for average BFS and DFS runtime: For tree search, we employ a probabilistic model of goal distribution; for graph search, the analysis depends on an additional statistic of path redundancy and average branching factor. As an application, we use the results on two concrete grammar problems. The runtime estimates can be used to select the faster out of BFS and DFS for a given problem, and may form the basis for further analysis of more advanced search methods. Finally, we verify our results experimentally; the analytical approximations come surprisingly close to empirical reality.",
    "creator" : "LaTeX with hyperref package"
  }
}