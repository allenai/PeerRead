{
  "name" : "1511.06653.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "SEMI-SUPERVISED LEARNING WITH ENCODER- DECODER RECURRENT NEURAL NETWORKS: EX-",
    "authors" : [ "PERIMENTS WITH", "MOTION CAPTURE SEQUENCES", "Félix G. Harvey" ],
    "emails" : [ "felix.gingras-harvey@polymtl.ca", "christopher.pal@polymtl.ca" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : "It is often the case that for a given task a small amount of labeled data is available compared to a much larger amount of unlabeled data. In these cases, semi-supervised learning may be preferred to supervised learning as it uses all the available data for training, and has good regularization properties (Erhan et al., 2010). A common technique for semi-supervised learning is to perform training in two phases: unsupervised pre-training, followed by supervised fine tuning (Bengio et al., 2007; Erhan et al., 2010; Yu et al., 2010).\nRecent advances in Recurrent Encoder-Decoder networks have afforded models the ability to perform both supervised learning (Sutskever et al., 2014; Cho et al., 2014) and unsupervised learning (Srivastava et al., 2015). These architectures are often based on the idea that recurrent neural networks (RNNs) can model temporal dependencies and that when handling a sequence, the last hidden state of an RNN can be made to contain information about the whole sequence. Therefore, this representation has a fixed length, even if sequences do not. The encoder networks in the prior work above all have similar architectures, while the decoders differ more significantly and use different sorts of target sequences. The separation between the encoder and the decoder networks allows one to easily add, modify or re-purpose decoders for desired tasks. Using multiple decoders forces the encoder to learn rich, multipurpose representations. This can also allow one to perform semi-supervised training in a single phase. In our case, we combine the unsupervised pre-training phase with the supervised fine-tuning phase to jointly train a classifier decoder and a reconstruction decoder, which both use the representation provided by the encoder. As we used a particular type of RNN known as a Long-Short-Term-Memory model we call these types of networks RNN Auto-Encoder Classifiers\nar X\niv :1\n51 1.\n06 65\n3v 1\n[ cs\n.C V\n] 2\n0 N\nov 2\n(RNN-AECs) or LSTM-AECs. We test our approach on publicly available Motion Capture (MOCAP) datasets, combining labeled and unlabeled data. We show that the use of both reconstruction and classification decoders allows us to use unlabelled data in a way that enables the use of higher capacity models while reducing the effect of overfitting. Our main contributions are:\n• The introduction of a novel architecture of the Recurrent Encoder-Decoder type that allows for supervised and unsupervised learning in a common model.\n• An empirical study of variants of such an architecture. • The definition and execution of experiments using a more realistic test set partitioning of\na widely used public MOCAP dataset, thereby facilitating more informative future evaluations.\n• The provision of further evidence of the benefits of semi-supervised learning.\nThe rest of the paper is divided as follow: in section 2, we talk about MOCAP data, current results on MOCAP movement classification, how the definition of a more realistic test set is needed and how it impacts current results. In section 3 we review the underlying theory and recent work on RNNs, Bi-directional RNNs (BRNNs), Long Short Term Memory (LSTM) RNNs, and Recurrent EncoderDecoders. We present our model in section 4, with an empirical study of architecture variants and hyper-parameters. Finally, in sections 5 and 6, we present our results, and talk about future work."
    }, {
      "heading" : "2 MOCAP",
      "text" : "Motion capture (MOCAP) technologies allow one to track and save movements of an actor wearing a special suit with multiple markers on it. The recorded positions of these markers at each time step make it possible to apply these movements to virtual characters in order to simulate realistic motions. These technologies find use in multiple areas, like video games, movies and health. As MOCAP is used more extensively in these applications, searches through databases of sequences becomes desirable. While sequences could be labeled or annotated to facilitate search, in practice sequences are often not labeled, or labeled at a coarse semantic level. A key element for labeling MOCAP sequences is human action recognition. This challenge can be seen as sequence classification, when only one action is performed in the sequence, or as sequence to sequence translation, when we want a fuller description of what is happening or when multiple actions are performed."
    }, {
      "heading" : "2.1 DATASETS",
      "text" : "One of the main challenges with the application of deep learning on MOCAP data is the lack of strongly labeled data. For this work, we used the two biggest publicly available MOCAP datasets that we are aware of. The first is the HDM05 public dataset (Müller et al., 2007). It contains over 270 weakly labeled takes, or sequences of multiple actions for which the frames-to-action alignment is not specified. This dataset also contains 2329 strongly labeled cuts, e.g. sequences of single actions, so the alignment is known since all frames represent this single action. These cuts are taken from full takes. There are about 100 classes of movements, which can be reduced to 65 when the number of repetitions or the side of the limb starting the action (left, right) are ignored. From this dataset, we use only these strongly labeled cuts.\nThe second dataset we use is the CMU Graphics Lab Motion Capture Database1. This is to our knowledge the biggest public MOCAP dataset in terms of number of frames. It contains 2148 weakly labeled or unlabeled sequences. This dataset can hardly be used for supervised learning as the labeling of sequences, if any, was only made to give high level indications, and does not seem to have followed any stable conventions throughout the dataset. In the present work, we use this dataset for unsupervised learning only."
    }, {
      "heading" : "2.2 PREVIOUS WORK ON ACTION RECOGNITION",
      "text" : "Some interesting work has been made on action recognition in MOCAP sequences in recent years. Cho & Chen (2013) have obtained good movement classification rates on simple sequences (cuts) on\n1http://mocap.cs.cmu.edu/\nthe publicly available HDM05 dataset using a simple Multi-Layer Perceptron (MLP)+Auto-encoder hybrid. Chen & Koskela (2013) tested multiple types of features, using a fast technique they call Extreme Machine Learning to classify, again, HDM05 cuts. Results were really good in both cases, with accuracies of over 95% and 92% with 65 and 40 action classes respectively. Their models were trained at the frame level, and sequence classification was done by majority voting. Other work by Du et al. (2015) treated the simple sequences’ classification problem with the same action classes as Cho & Chen (2013) with a hierarchical network handling in its first layer parts of the body (e.g. torso, arms and legs), and concatenating some of these parts in each layer until the whole body is treated in the last hidden layer. They used recurrent neural networks to use context information, instead of concatenating features of some previous frames at each timestep like Cho & Chen (2013) and Chen & Koskela (2013). This led to better results, and their classification accuracy on simple sequences reached 96.92%. Chaudhry et al. (2013) created bio-inspired features based on the neural encoding of shapes and, using neural nets with support vector machines, have obtained good results on simple sequences classification on 11 actions from the public HDM05 dataset. In our case, we are interested on the classification task for all of the 65 movement classes in HDM05."
    }, {
      "heading" : "2.3 DEFINING A GOOD TEST SET",
      "text" : "These techniques, based on their results all seem to almost solve the problem of action recognition in the HDM05 dataset. Nevertheless, it seems that there is an underlying problem for these results (except for (Chaudhry et al., 2013)), which relies in the definition of the test sets. All those experiments perform 10-fold cross validation with 10 balanced partitions of shuffled sequences. This means that takes or frames recorded with a particular actor can be found in the training set as well as in the test set. This might not be representative of reality, when new takes are recorded with new actors. If an actor is asked to repeat five times the same movement in five different takes, then these will probably be very similar, and shuffling the frames or sequences will insert an undesired bias in the test set. Chaudhry et al. (2013), on the other hand, isolate their test set based on actors performing the actions. This should give a test set more representative of reality. To show the difference it can make on the full dataset (65 classes), Table 1 presents our attempt at obtaining the results of Cho & Chen (2013) using their MLP+Auto-encoder hybrid with a random, balanced, 10% test set, as well as with a test set of sequences recorded with actors identified with dg and tr only. Note that using two of the five actors of HDM05 to produce the test set leaves only roughly 60% of the data as training data, as opposed to 90% when using the 10% random test set. This is why, using the same technique, we show that even with 40% of the data in the test set, if partitions are random and balanced, results are considerably higher than when using a more realistic test set. Also, when using our preprocessing technique (PP) on the data, we get higher results on the newly defined test set. We explain this preprocessing method in section 5.1. The main difference with the one used by Cho & Chen (2013) is that we allow hips to rotate over an axis so that the actor may have a horizontal position (when lying down for example), while their method fixes the hips in a constant position and orientation."
    }, {
      "heading" : "3 RECURRENT NEURAL NETWORKS",
      "text" : "We will summarize here some key elements that form the basis of our approach."
    }, {
      "heading" : "3.1 RECURRENT NEURAL NETWORKS",
      "text" : "At their core, RNNs are artificial neural networks in which hidden layer units have connections towards themselves through time. This means that at each time step, hidden layers receive lower layers’ current outputs as well as their own output from the previous timestep. This allows the network to use past context information to provide better outputs, making it very efficient when it comes to temporal sequences. This is why RNNs have often proven over the years to be very powerful on multiple sequential problems, such as speech recognition (Graves et al., 2013b; Sak et al., 2014; Graves et al., 2013a), handwriting recognition (Graves et al., 2008), text generation (Sutskever et al., 2011; Graves, 2012), or in our case MOCAP action recognition (Du et al., 2015). The forward pass of an RNN is very similar to the one of an ordinary feed-forward neural net, except for the fact that hidden layers use their own previous outputs as well as current lower outputs as their inputs. For example, for a single hidden layer recurrent network, given an input sequence x = [x1, ...xT ], its hidden state can be calculated with:\nht = σ(Wxhxt +Whhht−1 + bh) (1)\nwhere, t is the current time step, Wxh, Whh are the weight matrices of the input to the hidden layer and of the hidden layer to itself respectively. bh is the bias vector for the hidden layer and σ() is a differentiable activation function such as a sigmoid or a tanh function."
    }, {
      "heading" : "3.2 BI-DIRECTIONAL RECURRENT NETWORKS",
      "text" : "RNNs make use of past context in order to model a sequence up to a certain point. In many problems however, future context may be available and useful. In those cases, using bi-directional RNNs (BRNNs) can make the network more powerful. BRRNs contain layers that have two sets of units. One set handles the sequence in chronological order, while the other handles it in reverse order. The output of such a layer is the concatenation of the hidden activations of both sets. Using such networks doubles the number of hidden units, as well as the number of input dimensions for the output layer and all hidden layers, except for the first one. Outputs of bi-directional recurrent layers contain information about all the sequence at each timestep. Figure 1 shows an unfolded bi-directional layer."
    }, {
      "heading" : "3.3 LONG-SHORT-TERM MEMORY",
      "text" : "One known problem with RNNs is that they can be very hard to train to model long-term dependencies because of the vanishing gradient problem (Bengio et al., 1994; Hochreiter, 1998). One of the most popular and effective methods to counter this problem is the use of Long-Short-Term Memory networks (LSTMs), as presented by Hochreiter & Schmidhuber (1997). These recurrent networks\nhave, instead of simple hidden units, memory cells having input, output, and forget gates that determine whether information is added to, released from, and kept in the cell at each timestep. This enables the recurrent network to keep past context information for a long time internally, therefore allowing it to model long time dependencies. One memory cell is shown in Figure 2. In our context, we do not use in-cell connections (also called peepholes) as they have not been found to be useful in recent experiments (Breuel, 2015). Therefore, gates, cell values, and hidden outputs are calculated as follow:\ni = sigmoid(Wxixt +Whiht−1 + bi) (2)\no = sigmoid(Wxoxt +Whoht−1 + bo) (3)\nf = sigmoid(Wxfxt +Whfht−1 + bf ) (4)\nct = f ∗ ct−1 + i ∗ tanh(Wxcxt +Whcht−1 + bc) (5)\nht = o ∗ tanh(ct) (6)\nWhere W represents a weight matrix, and b a bias vector."
    }, {
      "heading" : "3.4 RECURRENT ENCODER-DECODERS",
      "text" : "A major advantage and key attribute of Recurrent Encoder-Decoders is their ability to transform variable-length sequences into a fixed-size vector in the encoder, then use one or more decoders to decode this vector for different purposes. Using an RNN as an encoder allows one to obtain this representation of the whole input sequence. Cho et al. (2014) as well as Sutskever et al. (2014) have used this approach for sequence-to-sequence translation, with some differences in the choice of hidden units and in the use of an additional summary vector (and set of weights) in the case of Cho et al. (2014). Both these approaches need a symbol of end-of-sequence to allow input and target sequences to have different lengths. They are trained to maximize the conditional probability of the target sequence given the input sequence. Our approach is more closely related to the one used by Srivastava et al. (2015) in which they perform unsupervised learning, by either reconstructing the sequence, predicting the next frames, or both."
    }, {
      "heading" : "4 OUR MODEL",
      "text" : ""
    }, {
      "heading" : "4.1 THE ARCHITECTURE",
      "text" : "Figure 3 shows an overview of the proposed LSTM-AEC architecture. The model is made of three main components: one encoder, and two decoders. One of the decoders is a generative or, more\nprecisely, reconstructive, while the other is discriminative, performing classifications. The encoder, as well as the reconstruction decoder are two separate LSTM networks with the same number of hidden units. This is necessary since the LSTM decoder’s initial hidden state is initialized with the last hidden state of the encoder. The classifier is a 1-hidden-layer perceptron, with a softmax output layer. It uses the representation provided by the encoder at time T as its input. Some aspects of the architecture can be easily modified, depending on the needs. For example, as explained by Srivastava et al. (2015), a recurrent decoder may use at each timestep, in addition to its last hidden state, its previous output as an additional input. Such a decoder is called conditional, while a nonconditional decoder won’t use its previous output. Such changes in the architecture are analysed in section 4.3."
    }, {
      "heading" : "4.2 LOSS FUNCTION",
      "text" : "The multipurpose encoder-decoder architecture that we have described above naturally leads to well defined reconstructive and discriminitive loss functions for the associated decoders. For the classifier loss, we want to minimize the negative log-likelihood (NNL) in order to maximize the conditional probability of a label y given a sequence X = x1, ..., xT in the set of N sequences, and given the set of all the network’s parameters θ:\nNNL = − N∑ i=1 log(P (Y = y(i)|x(i)1 , ..., x (i) T , θ)) (7)\nFor the LSTM decoder, we use the reconstruction error. It is calculated using the mean across frames of the sum of the squared distances between every marker’s position and its reconstructed position:\nRE = 1/T T∑\nt=1 M∑ m=1 (xm,t − x̂m,t)2 (8)\nwhere x̂ represents the reconstructed sequence, and m and t are marker and frame indices respectively. Using a classification weight α, we can calculate our total loss:\nloss = α ∗NNL+ (1− α) ∗RE (9)\nSetting α to 1 will result in a sequence classifier network only, while setting it to 0 will result in a reconstructive auto-encoder only. Note that when the network handles unlabeled data, α is always set to 0. Since these loss functions as well as all activations functions of the network are differentiable with respect to each of its parameters, we can employ stochastic gradient descent (SGD) and backpropagation through time (BPTT) to train the network."
    }, {
      "heading" : "4.3 EMPIRICAL STUDY OF ARCHITECTURAL VARIANTS",
      "text" : "Before performing our main experiments, we investigated the impact of some hyper parameters and variants of the architecture with a small network, on HDM05 data only, in order to test the best possible configurations on a larger scale. Figure 2 summarizes these tests. Those were all performed once, with the same weight initializations. Our baseline (BL) for these tests consists of two 2-hidden-layers LSTM networks for the encoder and reconstructive decoder components, with each layer having 64 units. It uses cell values (c) and hidden outputs (h) at time T as an initial representation for the decoder. The baseline network doesn’t have a hidden layer in its classifier decoder (just a softmax layer), and the reconstruction decoder is not conditional (as explained in section 4.1). It also uses a classification loss ratio of 0.75 when handling labeled sequences. Reducing the number of sequences in a minibatch (MB) had higher impact on results. This is probably due to the fact that we use variable-length sequences inside each minibatch. To do so, we use zero-padding, and masked hidden state updates as well as a masked reconstruction loss calculation. Therefore, to limit zero-padded regions, we sort sequences in increasing lengths before creating minibatches. This inserts an unwanted bias in learning since sequences in a same action class tend to have approximately the same length. This implies that some minibatches contain many or only examples of a single action, therefore boosting the weight update in a certain direction. We found that minibatches of size 4 offered a good balance between training times and results. Using Bidirectional LSTM units (BDLSTM) also helped significantly. Adding a hidden layer to the classifier decoder (HidClassif), using a conditional decoder (ConDecoder) and using only hidden activations (h) as representations (OnlyH) all helped on the classification task, but to a lesser extent. Finally, we also tried a classifier-only network, by setting the classifying loss ratio to 1.0, therefore discarding the reconstruction error. This is equivalent to performing supervised learning only. In this case, the results were significantly lower. This indicates that features learned from reconstruction are useful for classification. All changes having a positive effect on the final classification rates were applied in the larger networks for the main experiments."
    }, {
      "heading" : "5 EXPERIMENTS",
      "text" : ""
    }, {
      "heading" : "5.1 DATA",
      "text" : "The data in these experiments come from the HDM05 and the CMU MOCAP datasets. They both are recorded at 120 frames per second (fps) and contain more than 30 markers’ positions. In our case, we use 23 common markers between the two datasets. We work with the C3D file format, which contains series of positions for each marker. Our preprocessing of the data consists mainly of orienting, centering and scaling the point cloud of every frame given by the files. The orientation process is a basis change of all 3D positions so that the actor’s hips are always facing the same direction. This way, we ease the learning of movements, since the network won’t have to learn to ignore orientations for classifying an action. This is especially useful given the small size of the\ndatasets. We then center the hips of the actor at position (0,0,0) and scale so every marker is always in the interval [−1, 1]. This can help handling different actors with different sizes. To speed up training, we use only 1 frame out of 4 to create shorter, but still fluid sequences, giving a 30 fps frame rate."
    }, {
      "heading" : "5.2 NETWORK",
      "text" : "As explained in section 4.3, we combined all elements that had a positive impact on the classification task with the small network for the main experiment. Our larger network has two BDLSTM layers of size 512 in both the encoder and the reconstructive decoder. The hidden layer for the classifier decoder has a size of 2048. The reconstructive decoder is conditional, the minibatch size is 4, and the input dimension is 69. For input weights’ initializations, we draw uniformly from [− √ 1/fanin, √ 1/fanin], while we use orthonormal initialization for recurrent weight matrices. All biases are initialized at 0, except for LSTM forget gates which are initialized to 1, as proposed by Gers et al. (2000) and Jozefowicz et al. (2015). The learning rate is initialized to 0.1, and is halved when the validation cost is not reduced in three consecutive epochs, until it reaches 0.002 or below. We use early stopping with a tolerance of 10 epochs. We use a 0.9 momentum value, and we clip gradients in the interval [−0.05, 0.05] in order to prevent exploding gradients with long sequences."
    }, {
      "heading" : "5.3 RESULTS",
      "text" : "Table 3 shows our results on the movement classification task on our test set within HDM05, containing all sequences performed by actors identified by dg and tr in the files. We compare our results with our implementation of the technique from Cho & Chen (2013) on the same test set. Here again, we tested different classification cost ratios, and confirmed that learning features for reconstruction is useful for classification. We then used the best classification cost ratio from networks trained on HDM05 only and applied it to train a network using both HDM05 and CMU datasets."
    }, {
      "heading" : "5.3.1 ADDING UNLABELED DATA",
      "text" : "Figure 4 shows the effect of adding CMU unlabeled data to the training set of a network pre-trained on HDM05 only during 48 epochs. As we can see, the more obvious change after epoch 48 (when CMU data is added) is the considerable reduction of the gap between training and testing costs, thus showing once again that a bigger dataset helps regularization. Also, the accuracy of the classification is improved, indicating the added benefit of using unsupervised learning for a supervised task."
    }, {
      "heading" : "6 CONCLUSION AND FUTURE WORK",
      "text" : "We showed that using the Recurrent Encoder-Decoder architecture with multiple decoders makes it possible to combine supervised and unsupervised tasks such as classification and reconstruction, and to train a recurrent network for both in a single phase. We showed that using two decoders, one generative, and one discriminative leads to better results on a movement classification task. Adding unlabeled data to the training set also helps on the supervised task. We also defined a realistic test set on HDM05 that we hope can serve as a benchmarking set in future works on MOCAP classification.\nFurther tests shall be done using more decoders (e.g. a future predictor decoder) to learn richer representations, and with different classification cost ratios in order to find the best one. Other tests could be conducted using a summary vector as Cho et al. (2014) have done. Using only this vector would allow independent number of hidden units in the reconstruction decoder and in the encoder,\nas the initial state of the decoder would not have to be initialized with the last hidden state of the encoder."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "We acknowledge the support of Ubisoft for this research. We would also like to thank the authors of Theano (Bergstra et al., 2011)."
    } ],
    "references" : [ {
      "title" : "Learning long-term dependencies with gradient descent is difficult",
      "author" : [ "Bengio", "Yoshua", "Simard", "Patrice", "Frasconi", "Paolo" ],
      "venue" : "Neural Networks, IEEE Transactions on,",
      "citeRegEx" : "Bengio et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 1994
    }, {
      "title" : "Greedy layer-wise training of deep networks",
      "author" : [ "Bengio", "Yoshua", "Lamblin", "Pascal", "Popovici", "Dan", "Larochelle", "Hugo" ],
      "venue" : "Advances in neural information processing systems,",
      "citeRegEx" : "Bengio et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2007
    }, {
      "title" : "Theano: Deep learning on gpus with python",
      "author" : [ "Bergstra", "James", "Bastien", "Frédéric", "Breuleux", "Olivier", "Lamblin", "Pascal", "Pascanu", "Razvan", "Delalleau", "Desjardins", "Guillaume", "Warde-Farley", "David", "Goodfellow", "Ian", "Bergeron", "Arnaud" ],
      "venue" : "In NIPS 2011,",
      "citeRegEx" : "Bergstra et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bergstra et al\\.",
      "year" : 2011
    }, {
      "title" : "Benchmarking of lstm networks",
      "author" : [ "Breuel", "Thomas M" ],
      "venue" : "arXiv preprint arXiv:1508.02774,",
      "citeRegEx" : "Breuel and M.,? \\Q2015\\E",
      "shortCiteRegEx" : "Breuel and M.",
      "year" : 2015
    }, {
      "title" : "Bio-inspired dynamic 3d discriminative skeletal features for human action recognition",
      "author" : [ "Chaudhry", "Rizwan", "Ofli", "Ferda", "Kurillo", "Gregorij", "Bajcsy", "Ruzena", "Vidal", "René" ],
      "venue" : "In Computer Vision and Pattern Recognition Workshops (CVPRW),",
      "citeRegEx" : "Chaudhry et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Chaudhry et al\\.",
      "year" : 2013
    }, {
      "title" : "Classification of rgb-d and motion capture sequences using extreme learning machine",
      "author" : [ "Chen", "Xi", "Koskela", "Markus" ],
      "venue" : "In Image Analysis,",
      "citeRegEx" : "Chen et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2013
    }, {
      "title" : "Classifying and visualizing motion capture sequences using deep neural networks",
      "author" : [ "Cho", "Kyunghyun", "Chen", "Xi" ],
      "venue" : "arXiv preprint arXiv:1306.3874,",
      "citeRegEx" : "Cho et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Cho et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning phrase representations using rnn encoderdecoder for statistical machine translation",
      "author" : [ "Cho", "Kyunghyun", "Van Merriënboer", "Bart", "Gulcehre", "Caglar", "Bahdanau", "Dzmitry", "Bougares", "Fethi", "Schwenk", "Holger", "Bengio", "Yoshua" ],
      "venue" : "arXiv preprint arXiv:1406.1078,",
      "citeRegEx" : "Cho et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Cho et al\\.",
      "year" : 2014
    }, {
      "title" : "Hierarchical recurrent neural network for skeleton based action recognition",
      "author" : [ "Du", "Yong", "Wang", "Wei", "Liang" ],
      "venue" : "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Du et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Du et al\\.",
      "year" : 2015
    }, {
      "title" : "Why does unsupervised pre-training help deep learning",
      "author" : [ "Erhan", "Dumitru", "Bengio", "Yoshua", "Courville", "Aaron", "Manzagol", "Pierre-Antoine", "Vincent", "Pascal", "Samy" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Erhan et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Erhan et al\\.",
      "year" : 2010
    }, {
      "title" : "Learning to forget: Continual prediction with lstm",
      "author" : [ "Gers", "Felix A", "Schmidhuber", "Jürgen", "Cummins", "Fred" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Gers et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Gers et al\\.",
      "year" : 2000
    }, {
      "title" : "Hybrid speech recognition with deep bidirectional lstm",
      "author" : [ "Graves", "Alan", "Jaitly", "Navdeep", "Mohamed", "Abdel-rahman" ],
      "venue" : "In Automatic Speech Recognition and Understanding (ASRU),",
      "citeRegEx" : "Graves et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Graves et al\\.",
      "year" : 2013
    }, {
      "title" : "Speech recognition with deep recurrent neural networks",
      "author" : [ "Graves", "Alan", "Mohamed", "Abdel-rahman", "Hinton", "Geoffrey" ],
      "venue" : "In Acoustics, Speech and Signal Processing (ICASSP),",
      "citeRegEx" : "Graves et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Graves et al\\.",
      "year" : 2013
    }, {
      "title" : "Supervised sequence labelling with recurrent neural networks, volume 385",
      "author" : [ "Graves", "Alex" ],
      "venue" : null,
      "citeRegEx" : "Graves and Alex.,? \\Q2012\\E",
      "shortCiteRegEx" : "Graves and Alex.",
      "year" : 2012
    }, {
      "title" : "Unconstrained on-line handwriting recognition with recurrent neural networks",
      "author" : [ "Graves", "Alex", "Liwicki", "Marcus", "Bunke", "Horst", "Schmidhuber", "Jürgen", "Fernández", "Santiago" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Graves et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Graves et al\\.",
      "year" : 2008
    }, {
      "title" : "The vanishing gradient problem during learning recurrent neural nets and problem solutions",
      "author" : [ "Hochreiter", "Sepp" ],
      "venue" : "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems,",
      "citeRegEx" : "Hochreiter and Sepp.,? \\Q1998\\E",
      "shortCiteRegEx" : "Hochreiter and Sepp.",
      "year" : 1998
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Hochreiter", "Sepp", "Schmidhuber", "Jürgen" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Hochreiter et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Hochreiter et al\\.",
      "year" : 1997
    }, {
      "title" : "An empirical exploration of recurrent network architectures",
      "author" : [ "Jozefowicz", "Rafal", "Zaremba", "Wojciech", "Sutskever", "Ilya" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning",
      "citeRegEx" : "Jozefowicz et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Jozefowicz et al\\.",
      "year" : 2015
    }, {
      "title" : "Documentation mocap database hdm05",
      "author" : [ "Müller", "Meinard", "Röder", "Tido", "Clausen", "Michael", "Eberhardt", "Bernhard", "Krüger", "Björn", "Weber", "Andreas" ],
      "venue" : null,
      "citeRegEx" : "Müller et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Müller et al\\.",
      "year" : 2007
    }, {
      "title" : "Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition",
      "author" : [ "Sak", "Haşim", "Senior", "Andrew", "Beaufays", "Françoise" ],
      "venue" : "arXiv preprint arXiv:1402.1128,",
      "citeRegEx" : "Sak et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Sak et al\\.",
      "year" : 2014
    }, {
      "title" : "Unsupervised learning of video representations using lstms",
      "author" : [ "Srivastava", "Nitish", "Mansimov", "Elman", "Salakhutdinov", "Ruslan" ],
      "venue" : "arXiv preprint arXiv:1502.04681,",
      "citeRegEx" : "Srivastava et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Srivastava et al\\.",
      "year" : 2015
    }, {
      "title" : "Generating text with recurrent neural networks",
      "author" : [ "Sutskever", "Ilya", "Martens", "James", "Hinton", "Geoffrey E" ],
      "venue" : "In Proceedings of the 28th International Conference on Machine Learning",
      "citeRegEx" : "Sutskever et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2011
    }, {
      "title" : "Sequence to sequence learning with neural networks. In Advances in neural information processing",
      "author" : [ "Sutskever", "Ilya", "Vinyals", "Oriol", "Le", "Quoc VV" ],
      "venue" : null,
      "citeRegEx" : "Sutskever et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2014
    }, {
      "title" : "Roles of pre-training and fine-tuning in context-dependent dbnhmms for real-world speech recognition",
      "author" : [ "Yu", "Dong", "Deng", "Li", "G. Dahl" ],
      "venue" : "In Proc. NIPS Workshop on Deep Learning and Unsupervised Feature Learning,",
      "citeRegEx" : "Yu et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "In these cases, semi-supervised learning may be preferred to supervised learning as it uses all the available data for training, and has good regularization properties (Erhan et al., 2010).",
      "startOffset" : 168,
      "endOffset" : 188
    }, {
      "referenceID" : 1,
      "context" : "A common technique for semi-supervised learning is to perform training in two phases: unsupervised pre-training, followed by supervised fine tuning (Bengio et al., 2007; Erhan et al., 2010; Yu et al., 2010).",
      "startOffset" : 148,
      "endOffset" : 206
    }, {
      "referenceID" : 9,
      "context" : "A common technique for semi-supervised learning is to perform training in two phases: unsupervised pre-training, followed by supervised fine tuning (Bengio et al., 2007; Erhan et al., 2010; Yu et al., 2010).",
      "startOffset" : 148,
      "endOffset" : 206
    }, {
      "referenceID" : 23,
      "context" : "A common technique for semi-supervised learning is to perform training in two phases: unsupervised pre-training, followed by supervised fine tuning (Bengio et al., 2007; Erhan et al., 2010; Yu et al., 2010).",
      "startOffset" : 148,
      "endOffset" : 206
    }, {
      "referenceID" : 22,
      "context" : "Recent advances in Recurrent Encoder-Decoder networks have afforded models the ability to perform both supervised learning (Sutskever et al., 2014; Cho et al., 2014) and unsupervised learning (Srivastava et al.",
      "startOffset" : 123,
      "endOffset" : 165
    }, {
      "referenceID" : 7,
      "context" : "Recent advances in Recurrent Encoder-Decoder networks have afforded models the ability to perform both supervised learning (Sutskever et al., 2014; Cho et al., 2014) and unsupervised learning (Srivastava et al.",
      "startOffset" : 123,
      "endOffset" : 165
    }, {
      "referenceID" : 20,
      "context" : ", 2014) and unsupervised learning (Srivastava et al., 2015).",
      "startOffset" : 34,
      "endOffset" : 59
    }, {
      "referenceID" : 18,
      "context" : "The first is the HDM05 public dataset (Müller et al., 2007).",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 7,
      "context" : "Other work by Du et al. (2015) treated the simple sequences’ classification problem with the same action classes as Cho & Chen (2013) with a hierarchical network handling in its first layer parts of the body (e.",
      "startOffset" : 14,
      "endOffset" : 31
    }, {
      "referenceID" : 7,
      "context" : "Other work by Du et al. (2015) treated the simple sequences’ classification problem with the same action classes as Cho & Chen (2013) with a hierarchical network handling in its first layer parts of the body (e.",
      "startOffset" : 14,
      "endOffset" : 134
    }, {
      "referenceID" : 7,
      "context" : "Other work by Du et al. (2015) treated the simple sequences’ classification problem with the same action classes as Cho & Chen (2013) with a hierarchical network handling in its first layer parts of the body (e.g. torso, arms and legs), and concatenating some of these parts in each layer until the whole body is treated in the last hidden layer. They used recurrent neural networks to use context information, instead of concatenating features of some previous frames at each timestep like Cho & Chen (2013) and Chen & Koskela (2013).",
      "startOffset" : 14,
      "endOffset" : 509
    }, {
      "referenceID" : 7,
      "context" : "Other work by Du et al. (2015) treated the simple sequences’ classification problem with the same action classes as Cho & Chen (2013) with a hierarchical network handling in its first layer parts of the body (e.g. torso, arms and legs), and concatenating some of these parts in each layer until the whole body is treated in the last hidden layer. They used recurrent neural networks to use context information, instead of concatenating features of some previous frames at each timestep like Cho & Chen (2013) and Chen & Koskela (2013). This led to better results, and their classification accuracy on simple sequences reached 96.",
      "startOffset" : 14,
      "endOffset" : 535
    }, {
      "referenceID" : 4,
      "context" : "Chaudhry et al. (2013) created bio-inspired features based on the neural encoding of shapes and, using neural nets with support vector machines, have obtained good results on simple sequences classification on 11 actions from the public HDM05 dataset.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 4,
      "context" : "Nevertheless, it seems that there is an underlying problem for these results (except for (Chaudhry et al., 2013)), which relies in the definition of the test sets.",
      "startOffset" : 89,
      "endOffset" : 112
    }, {
      "referenceID" : 4,
      "context" : "Nevertheless, it seems that there is an underlying problem for these results (except for (Chaudhry et al., 2013)), which relies in the definition of the test sets. All those experiments perform 10-fold cross validation with 10 balanced partitions of shuffled sequences. This means that takes or frames recorded with a particular actor can be found in the training set as well as in the test set. This might not be representative of reality, when new takes are recorded with new actors. If an actor is asked to repeat five times the same movement in five different takes, then these will probably be very similar, and shuffling the frames or sequences will insert an undesired bias in the test set. Chaudhry et al. (2013), on the other hand, isolate their test set based on actors performing the actions.",
      "startOffset" : 90,
      "endOffset" : 721
    }, {
      "referenceID" : 4,
      "context" : "Nevertheless, it seems that there is an underlying problem for these results (except for (Chaudhry et al., 2013)), which relies in the definition of the test sets. All those experiments perform 10-fold cross validation with 10 balanced partitions of shuffled sequences. This means that takes or frames recorded with a particular actor can be found in the training set as well as in the test set. This might not be representative of reality, when new takes are recorded with new actors. If an actor is asked to repeat five times the same movement in five different takes, then these will probably be very similar, and shuffling the frames or sequences will insert an undesired bias in the test set. Chaudhry et al. (2013), on the other hand, isolate their test set based on actors performing the actions. This should give a test set more representative of reality. To show the difference it can make on the full dataset (65 classes), Table 1 presents our attempt at obtaining the results of Cho & Chen (2013) using their MLP+Auto-encoder hybrid with a random, balanced, 10% test set, as well as with a test set of sequences recorded with actors identified with dg and tr only.",
      "startOffset" : 90,
      "endOffset" : 1008
    }, {
      "referenceID" : 4,
      "context" : "Nevertheless, it seems that there is an underlying problem for these results (except for (Chaudhry et al., 2013)), which relies in the definition of the test sets. All those experiments perform 10-fold cross validation with 10 balanced partitions of shuffled sequences. This means that takes or frames recorded with a particular actor can be found in the training set as well as in the test set. This might not be representative of reality, when new takes are recorded with new actors. If an actor is asked to repeat five times the same movement in five different takes, then these will probably be very similar, and shuffling the frames or sequences will insert an undesired bias in the test set. Chaudhry et al. (2013), on the other hand, isolate their test set based on actors performing the actions. This should give a test set more representative of reality. To show the difference it can make on the full dataset (65 classes), Table 1 presents our attempt at obtaining the results of Cho & Chen (2013) using their MLP+Auto-encoder hybrid with a random, balanced, 10% test set, as well as with a test set of sequences recorded with actors identified with dg and tr only. Note that using two of the five actors of HDM05 to produce the test set leaves only roughly 60% of the data as training data, as opposed to 90% when using the 10% random test set. This is why, using the same technique, we show that even with 40% of the data in the test set, if partitions are random and balanced, results are considerably higher than when using a more realistic test set. Also, when using our preprocessing technique (PP) on the data, we get higher results on the newly defined test set. We explain this preprocessing method in section 5.1. The main difference with the one used by Cho & Chen (2013) is that we allow hips to rotate over an axis so that the actor may have a horizontal position (when lying down for example), while their method fixes the hips in a constant position and orientation.",
      "startOffset" : 90,
      "endOffset" : 1793
    }, {
      "referenceID" : 19,
      "context" : "This is why RNNs have often proven over the years to be very powerful on multiple sequential problems, such as speech recognition (Graves et al., 2013b; Sak et al., 2014; Graves et al., 2013a), handwriting recognition (Graves et al.",
      "startOffset" : 130,
      "endOffset" : 192
    }, {
      "referenceID" : 14,
      "context" : ", 2013a), handwriting recognition (Graves et al., 2008), text generation (Sutskever et al.",
      "startOffset" : 34,
      "endOffset" : 55
    }, {
      "referenceID" : 21,
      "context" : ", 2008), text generation (Sutskever et al., 2011; Graves, 2012), or in our case MOCAP action recognition (Du et al.",
      "startOffset" : 25,
      "endOffset" : 63
    }, {
      "referenceID" : 8,
      "context" : ", 2011; Graves, 2012), or in our case MOCAP action recognition (Du et al., 2015).",
      "startOffset" : 63,
      "endOffset" : 80
    }, {
      "referenceID" : 0,
      "context" : "One known problem with RNNs is that they can be very hard to train to model long-term dependencies because of the vanishing gradient problem (Bengio et al., 1994; Hochreiter, 1998).",
      "startOffset" : 141,
      "endOffset" : 180
    }, {
      "referenceID" : 0,
      "context" : "One known problem with RNNs is that they can be very hard to train to model long-term dependencies because of the vanishing gradient problem (Bengio et al., 1994; Hochreiter, 1998). One of the most popular and effective methods to counter this problem is the use of Long-Short-Term Memory networks (LSTMs), as presented by Hochreiter & Schmidhuber (1997). These recurrent networks",
      "startOffset" : 142,
      "endOffset" : 355
    }, {
      "referenceID" : 11,
      "context" : "Based on Figure 1 in Graves et al. (2013b).",
      "startOffset" : 21,
      "endOffset" : 43
    }, {
      "referenceID" : 6,
      "context" : "Cho et al. (2014) as well as Sutskever et al.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 6,
      "context" : "Cho et al. (2014) as well as Sutskever et al. (2014) have used this approach for sequence-to-sequence translation, with some differences in the choice of hidden units and in the use of an additional summary vector (and set of weights) in the case of Cho et al.",
      "startOffset" : 0,
      "endOffset" : 53
    }, {
      "referenceID" : 6,
      "context" : "Cho et al. (2014) as well as Sutskever et al. (2014) have used this approach for sequence-to-sequence translation, with some differences in the choice of hidden units and in the use of an additional summary vector (and set of weights) in the case of Cho et al. (2014). Both these approaches need a symbol of end-of-sequence to allow input and target sequences to have different lengths.",
      "startOffset" : 0,
      "endOffset" : 268
    }, {
      "referenceID" : 6,
      "context" : "Cho et al. (2014) as well as Sutskever et al. (2014) have used this approach for sequence-to-sequence translation, with some differences in the choice of hidden units and in the use of an additional summary vector (and set of weights) in the case of Cho et al. (2014). Both these approaches need a symbol of end-of-sequence to allow input and target sequences to have different lengths. They are trained to maximize the conditional probability of the target sequence given the input sequence. Our approach is more closely related to the one used by Srivastava et al. (2015) in which they perform unsupervised learning, by either reconstructing the sequence, predicting the next frames, or both.",
      "startOffset" : 0,
      "endOffset" : 574
    }, {
      "referenceID" : 20,
      "context" : "For example, as explained by Srivastava et al. (2015), a recurrent decoder may use at each timestep, in addition to its last hidden state, its previous output as an additional input.",
      "startOffset" : 29,
      "endOffset" : 54
    }, {
      "referenceID" : 10,
      "context" : "All biases are initialized at 0, except for LSTM forget gates which are initialized to 1, as proposed by Gers et al. (2000) and Jozefowicz et al.",
      "startOffset" : 105,
      "endOffset" : 124
    }, {
      "referenceID" : 10,
      "context" : "All biases are initialized at 0, except for LSTM forget gates which are initialized to 1, as proposed by Gers et al. (2000) and Jozefowicz et al. (2015). The learning rate is initialized to 0.",
      "startOffset" : 105,
      "endOffset" : 153
    }, {
      "referenceID" : 6,
      "context" : "Other tests could be conducted using a summary vector as Cho et al. (2014) have done.",
      "startOffset" : 57,
      "endOffset" : 75
    } ],
    "year" : 2017,
    "abstractText" : "Recent work on sequence to sequence translation using Recurrent Neural Networks (RNNs) based on Long Short Term Memory (LSTM) architectures has shown great potential for learning useful representations of sequential data. These architectures, using one recurrent neural network to encode sequences into fixedlength representations, and one or more network(s) to decode representations into new sequences have the advantages of being modular, while also allowing modules to be jointly trained. A one-to-many encoder-decoder(s) scheme allows for a single encoder to provide representations serving multiple purposes. In our case, we present an LSTM encoder network able to produce representations used by two decoders: one that reconstructs, and one that classifies if the training sequence has a labelling. This allows the network to learn representations that are useful for both discriminative and generative tasks at the same time. We show how this paradigm is very well suited for semi-supervised learning with sequences. We test our proposed approach on an action recognition task using motion capture (MOCAP) sequences and show that semi-supervised feature learning can improve movement classification.",
    "creator" : "LaTeX with hyperref package"
  }
}