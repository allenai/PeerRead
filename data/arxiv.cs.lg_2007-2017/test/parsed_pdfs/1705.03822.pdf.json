{
  "name" : "1705.03822.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Context-Aware Hierarchical Online Learning for Performance Maximization in Mobile Crowdsourcing",
    "authors" : [ "Sabrina Müller", "Cem Tekin", "Mihaela van der Schaar", "Anja Klein" ],
    "emails" : [ "a.klein}@nt.tu-darmstadt.de", "cemtekin@ee.bilkent.edu.tr", "mihaela@ee.ucla.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Index Terms—Crowdsourcing, task assignment, online learning, contextual multi-armed bandits\nI. INTRODUCTION\nConventional web-based crowdsourcing is a popular way to outsource human intelligence tasks, prominent examples being Amazon Mechanical Turk1 and Crowdflower2. More recently, mobile crowdsourcing has evolved as a powerful tool to leverage the workforce and skills of a plethora of mobile users to accomplish tasks in a distributed manner [1]. This may be due to the fact that the number of mobile devices is growing rapidly and at the same time, people spend a considerable amount of their daily time using these devices. For example,\nThis work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.\n1https://www.mturk.com 2https://www.crowdflower.com/\naccording to the Cisco Visual Networking Index, between 2015 and 2016, the global number of mobile devices grew from 7.6 to 8 billion [2]. Moreover, according to an estimate of eMarketer [3], the daily time US adults spend using mobile devices will be more than 3 hours in 2017, which is an increase by more than 50% compared to 2013.\nIn mobile crowdsourcing, task owners outsource their tasks via an intermediary mobile crowdsourcing platform (MCSP) to a set of workers, i.e., mobile users, who may be willing to complete these tasks. A mobile crowdsourcing task may require the worker to interact with his mobile device in the physical world (e.g., photography tasks) or to complete some virtual task via his mobile device (e.g., image annotation, sentiment analysis). Some mobile crowdsourcing tasks, subsumed under the term spatial crowdsourcing [4], are spatially constrained (e.g., photography task at point of interest), or require high spatial resolution (e.g., air pollution map of a city). In spatial crowdsourcing, tasks typically require workers to travel to certain locations. However, recently emerging mobile crowdsourcing applications are also concerned with locationindependent tasks. For example, MapSwipe3 lets mobile users annotate satellite imagery to find inhabitated regions around the world. The GalaxyZoo app4 lets mobile users classify galaxies. The latter project is an example of the more general trend of citizen science [5]. On the commercial side, Spare55 or Crowdee6 outsource micro-tasks (e.g., image annotation, sentiment analysis, and opinion polls) to mobile users in return for small payments. While location-independent tasks could as well be completed by users of static devices as in web-based crowdsourcing, emerging mobile crowdsourcing applications for location-independent tasks exploit the increasing amount of online mobile users that complete tasks on the go.\nMobile crowdsourcing – be it spatial or locationindependent – requires an appropriate task assignment strategy, since not all online workers may be equally suitable for a given task. First, different workers may have different task preferences and hence different acceptance rates. Secondly, different workers may have different skills, and hence provide\n3https://mapswipe.org/ 4https://www.galaxyzoo.org/ 5https://app.spare5.com/fives 6https://www.crowdee.de/\nar X\niv :1\n70 5.\n03 82\n2v 1\n[ cs\n.L G\n] 1\n0 M\nay 2\n2 different quality when completing a task. Two assignment modes considered in the crowdsourcing literature are the server-assigned task (SAT) mode and the worker-selected task (WST) mode (see [6] for a taxonomy). In SAT mode, the MCSP tries to match workers and tasks in an optimal way, e.g., to maximize the number of task assignments, possibly under a given task budget. For this purpose, the MCSP typically gathers task and worker information to decide on task assignment. While this represents a sophisticated strategy, it may require a large communication overhead and a privacy concern for workers since the MCSP has to be regularly informed about the current worker contexts (e.g., their current positions). Moreover, previous work on the SAT mode often either assumed that workers always accept a task once assigned to it or that workers’ acceptance rates and quality are known in advance. However, this is not necessarily true in reality, since acceptance rates and quality are usually not known beforehand and therefore have to be learned by the MCSP over time. In addition, a worker’s acceptance rate and the quality of completed tasks might depend not only on the specific task, but also on the worker’s context, e.g., the worker’s location or the time of day [7]. This context may change quickly, especially in mobile crowdsourcing with location-independent tasks, since workers can complete such tasks anytime and anywhere.\nIn contrast, in WST mode, workers autonomously select tasks from a list. This rather simple mode is often used in practice (e.g., on Amazon Mechanical Turk) since it has the advantage that workers automatically select tasks they are interested in. However, the WST mode can lead to suboptimal task assignments since first, finding suitable tasks is not as easy as it seems (e.g., time-consuming searches within a long list of tasks are needed and workers might simply select from the first displayed tasks [8]) and secondly, workers might leave unpopular tasks unassigned. Therefore, in WST mode, the MCSP might additionally provide personalized task recommendation (TR) to workers such that workers find appropriate tasks [7]. However, personalized TR typically requires the workers to share their current context with the MCSP, which again means a communication overhead and a privacy concern for workers.\nWe argue that a task assignment strategy is needed which combines the advantages of the above modes: The MCSP should centrally coordinate task assignment to ensure that appropriate workers are selected for each task, as in SAT mode. At the same time, the communication overhead due to task assignment should be small and workers’ personal data should be protected. Hence, no worker context should be shared with the MCSP, as in basic WST mode. Moreover, task assignment should take into account that workers may decline a task they are assigned to, and hence, the assignment should fit to the workers’ preferences, as in WST mode with personalized TR. In addition, task assignment should be based both on acceptance rates and on the quality with which a task is completed. Since observing the quality of completed tasks may require costly quality assessments (e.g., a manual quality rating from a task owner, or an automatic quality assessment using local software in a mobile device), the required number of quality assessments should be kept low. Finally, workers’ acceptance rates and quality have to be learned over time.\nOur contribution therefore is as follows: We propose a context-aware hierarchical online learning algorithm for performance maximization in mobile crowdsourcing for locationindependent tasks. Our algorithm is split into two parts, one part executed by the MCSP, the other part by local controllers (LCs) located in each of the workers’ mobile devices. An LC learns its worker’s performance in terms of acceptance rate and quality online over time, by observing the worker’s personal contexts and his decisions to accept or decline tasks and the quality in completing these tasks. The LC learns from its worker’s context only locally, and personal context is not shared with the MCSP. Each LC regularly sends performance estimates to the MCSP. Based on these estimates, the MCSP takes care of the worker selection. This hierarchical (in the sense of the coordination between the MCSP and the LCs) approach enables the MCSP to select suitable workers for each task under its budget without having access to the workers’ personal contexts. Moreover, workers receive personalized task requests based on their interests and skills, while keeping the number of (possibly costly) quality assessments low. Since our algorithm learns in an online fashion, it adapts and improves the worker selection over time and can hence achieve good results already during run time. We prove that our algorithm converges to the optimal task assignment strategy, which for each task selects the subset of workers which maximizes the expected performance under the task budget.\nThe remainder of this paper is organized as follows. Section II gives an overview on related work. Section III describes the system model. In Section IV, we propose a context-aware hierarchical online algorithm for performance maximization in mobile crowdsourcing. In Section V, we theoretically analyze our proposed algorithm in terms of its regret, as well as its requirements with respect to local storage, communication and worker quality assessment. Section VI contains a numerical evaluation of our algorithm based on synthetic and real data. Section VII concludes the paper."
    }, {
      "heading" : "II. RELATED WORK",
      "text" : "Research has put some effort in theoretically defining and classifying crowdsourcing systems, such as web-based crowdsourcing [9], mobile [1] and spatial [4] crowdsourcing. Below, we give an overview on related work on task assignment in general, mobile and spatial crowdsourcing systems, as relevant for our scenario. Note that strategic behavior of workers and task owners in crowdsourcing systems, e.g., concerning pricing and effort spent in task completion [10], represents an active research area itself, which is out of the scope of this paper. Also note that we assume that the quality of a completed task can be observed. A different line of work on crowdsourcing deals with quality estimation in case of missing ground truth, recently also using online learning [11].\nDue to the inherent dynamic nature of crowdsourcing, with tasks and/or workers typically arriving dynamically over time, task assignment is often modeled as an online decision making problem [12]. For general crowdsourcing systems, [13] proposed a competitive online task assignment algorithm for maximizing the utility of a task owner on a given set of task\n3\ntypes, with finite number of tasks per task type, by learning the skills of sequentially appearing workers. While [13] considers sequentially arriving workers and their algorithm decides which task to assign to a worker, we consider sequentially arriving tasks and our algorithm decides which workers should be assigned to a task. Therefore, our algorithm can be applied to an infinite number of task types by describing a task using its context. Moreover, our algorithm additionally takes worker context into account, which may affect worker performance in mobile crowdsourcing. In [14], a bounded multi-armed bandit model for expert crowdsourcing is presented and a task assignment algorithm with sublinear regret is derived which maximizes the utility of a budget-constrained task owner under uncertainty about the skills of a finite set of workers with (known) different prices and limited working time. While in [14], the average skill of a worker is learned, our algorithm additionally takes worker and task contexts into account, and thereby learns context-specific performance. In [15], a realtime algorithm for finding the top-k workers for sequentially arriving tasks is presented. First, tasks are categorized offline into different types and the similarity between a worker’s profile and each task type is computed. Then, in real time, the topk workers are selected for a task based on a matching score, which takes into account the similarity and historic worker performance. The authors propose to periodically update the performance estimates offline in batches, but no guarantees on the learning process are given. Compared to [15], we additionally take into account worker context, learn contextspecific performance and derive guarantees on the learning speed. In [16], methods for learning a worker preference model are proposed for personalized TR in WST mode. These methods use the history of worker preferences for different tasks, but in contrast to our algorithm, they do not take into account the worker context for context-aware TR.\nIn mobile crowdsourcing, [17] proposes algorithms for optimal TR in WST mode that take into account the trade-off between the privacy of worker context, the utility to recommend the best tasks and the efficiency in terms of communication and computation overhead. The TR is performed by a server based on a generalized context shared by the worker. The statistics used for TR are gathered offline via a proxy that ensures differential privacy guarantees. While [17] allows to flexibly adjust the shared generalized context and makes TRs based on offline statistics and generalized worker context, our approach keeps the worker context locally and learns each worker’s individual statistics online. In [18], which is\nfocused on mobile crowdsensing, an online learning algorithm is presented to maximize the sensing revenue of a budgetconstrained task owner by learning the sensing value of workers with known prices. While [18] considers a total budget and each crowdsensing task requires a minimum number of workers, we consider a separate budget per task, which translates to a maximum number of required workers. Moreover, we additionally take task and worker context into account.\nA taxonomy for spatial crowdsourcing was first introduced in [6]. The authors present a location-entropy based algorithm for SAT mode to maximize the number of task assignments under uncertainty about task and worker arrival processes. The server decides on task assignment based on centrally gathered knowledge about the workers’ current locations. In [19], the authors extend this framework to maximize the quality of assignments under varying worker skills for different task types. However, in contrast to our work, [6] and [19] assume that worker context is centrally gathered, that workers always accept assigned tasks within certain known bounds and that worker skills are known a priori. In [20], an online task assignment algorithm is proposed for spatial crowdsourcing with SAT mode for maximizing the expected number of accepted tasks. The problem is modeled as a contextual multi-armed bandit problem, and workers are selected for sequentially arriving tasks. The authors adapt the LinUCB algorithm by assuming that the acceptance rate is a linear function of the worker’s distance to the task and the task type. However, such a linearity assumption is restrictive and it especially may not hold in mobile crowdsourcing with location-independent tasks. In contrast, our algorithm works for more general relationships between context and performance. In [21], an algorithm for privacy-preserving spatial crowdsourcing in SAT mode is proposed. Using differential privacy and geocasting, the algorithm preserves worker locations (i.e., their context) while optimizing the expected number of accepted tasks. However, the authors assume that the workers’ acceptance rates are identical and known, whereas our algorithm learns context-specific acceptance rates. In [22], exact and approximation algorithms for acceptance maximization in spatial crowdsourcing with SAT mode are proposed. The algorithms are performed offline for given sets of available workers and tasks based on a probability of interest for each pair of worker and task. The probabilities of interest are computed beforehand using maximum likelihood estimation. On the contrary, our algorithm learns acceptance rates online and we provide an upper bound on the regret of this learning.\n4 Our proposed algorithm is based on the contextual multiarmed bandit problem [23]–[28]. The closest related work is [28], in which a learner observes multiple context arrivals in each round and selects a subset of actions which maximize the expected rewards given the set of context arrivals. We extended the algorithm in [28] as follows: While in [28], a central learner observes all contexts and selects actions based on these contexts, our algorithm is decoupled to several learning entities, each observing the context of one particular action and learning the rewards of this action, and a coordinating entity, which selects actions based on the learning entities’ estimates.\nIn the crowdsourcing scenario, an action corresponds to a worker, the learning entities correspond to the LCs which learn the performance of their workers, and the coordinating entity corresponds to the MCSP, which selects workers based on the performance estimates from the LCs. Moreover, while in [28], the same number of actions is selected per round and all actions are available in any round, we allow different numbers of actions to be selected per round and we allow actions to be unavailable. In the crowdsourcing scenario, this corresponds to allowing different number of required workers for different tasks and allowing that workers may be unavailable."
    }, {
      "heading" : "III. SYSTEM MODEL",
      "text" : ""
    }, {
      "heading" : "A. Mobile Crowdsourcing Platform",
      "text" : "We consider an MCSP, to which a fixed setW = {1, ...,W} of W = |W| workers belongs. A worker is a user equipped with a mobile device, in which the mobile crowdsourcing application is installed. Workers can be in two modes: A worker is called available, if the mobile crowdsourcing application on his device is running. In this case, the MCSP might request the worker to complete a task, which the worker may then accept or decline. A worker is called unavailable, if the mobile crowdsourcing application on his device is turned off.\nTask owners can place location-independent tasks of different types into the MCSP and select their task budget. In detail, a task t is defined by a tuple (bt, ct), where bt > 0 denotes the budget that the task owner is willing to pay the MCSP for this task and ct ∈ C denotes the task context. The task context is taken from a bounded C-dimensional task context space C := [0, 1]C and captures information about the task type.7 The task owner has to pay the MCSP for taking care of selecting appropriate workers for his task and for requesting these workers to complete the task. We assume here that the MCSP sets a fixed price e > 0 per requested worker to be paid by the task owner. Moreover, we assume that for each task t, the budget bt satisfies bt ∈ [e,We], so that the MCSP should request at least one worker and at most W workers. Based on the budget bt, the MCSP computes the number mt := b bte c ∈ {1, ...,W} of workers it should request.\nWe assume that tasks arrive at the MCSP sequentially and we denote the sequentially arriving tasks by t = 1, ..., T . For each arriving task t, the MCSP should select a subset of mt\n7In order to represent different task types, we assume that tasks are described by C context dimensions. In each of the C context dimensions, a task is classified via a value between [0, 1]. Then, ct ∈ [0, 1]C is a vector describing task t’s overall context.\nFig. 1. System model. A task arrives at the MCSP. The MCSP has to select an appropriate subset of available workers for the task.\nworkers which maximizes the worker performance for that task. Due to the dynamics in worker availability over time, the MCSP can only select workers from the set Wt ⊆ W of currently available workers for task t, as defined byWt := {i : worker i is available at arrival time of t}, where the number of available workers8 is denoted by Wt = |Wt| ∈ {1, ...,W}. Since the MCSP can select at most all available workers, it aims at selecting min{mt, |Wt|} workers for task t, see Fig. 1 for an illustration.9"
    }, {
      "heading" : "B. Context-Specific Worker Performance",
      "text" : "The performance of an (available) worker depends on (i) the worker’s willingness to accept the task and (ii) the worker’s quality in completing the task, where we assume that the quality can take values in a range [qmin, qmax] ⊆ R0,+. Both the willingness of a worker to accept the task as well as the quality may depend on the worker’s current context and the task context. Let xt,i denote the personal context of worker i ∈ Wt at the arrival time of task t, coming from a bounded Xi-dimensional personal context space Xi := [0, 1]Xi . Here, we allow each worker i to have an individual personal context space Xi, since each worker may allow access to an individual set of context dimensions due to his personal settings (e.g., the worker allows access to a certain set of sensors of his mobile device that are used to derive his context). Possible personal context dimensions could be the worker’s current location (in terms of geographic coordinates), the type of location (e.g., at home, in a coffee shop), the worker’s current activity (e.g., commuting, working) or his current device status (e.g., battery state, type of wireless connection). We further call the concatenation (xt,i, ct) ∈ Xi × C the joint context of worker i and task t. For worker i, this joint context is hence a vector of dimension Di := Xi + C. We call Xi × C = [0, 1]Xi × [0, 1]C ≡ [0, 1]Di the joint (personal and task) context space of worker i. The reason for considering the joint context is that the performance of worker i may depend on both the his current context xt,i and the task context ct – in other words, the performance depends jointly on (xt,i, ct).\n8We assume that for each arriving task, at least one worker is available. 9Note that each task will only be processed once by the MCSP, even if there are too few workers available. If less workers are available than required for a task, the MCSP will request all available workers to complete the task and the task owner will only be charged for the actual number of requested workers.\n5 Let pi(xt,i, ct) denote the performance of worker i with current personal context xt,i for task context ct. The performance can be decomposed into (i) worker i’s decision di(xt,i, ct) to accept (di(xt,i, ct) = 1) or reject (di(xt,i, ct) = 0) the task and, in case the worker accepts the task, also on (ii) worker i’s quality qi(xt,i, ct) when completing the task. Hence, we can write\npi(xt,i, ct) := { qi(xt,i, ct), if di(xt,i, ct) = 1, 0, if di(xt,i, ct) = 0.\nThe performance is a random variable whose distribution depends on the distributions of the random variables di(xt,i, ct) and qi(xt,i, ct). Here, since the decision di(xt,i, ct) is binary, it is drawn from the Bernoulli distribution with unknown parameter ri(xt,i, ct) ∈ [0, 1]. Hence, ri(xt,i, ct) represents the acceptance rate of worker i when the joint context of worker i and task t is (xt,i, ct). The quality qi(xt,i, ct) is a random variable conditioned on di(xt,i, ct) = 1 (i.e., conditioned on task acceptance) with unknown distribution and we denote its expected value by µi(xt,i, ct) := E[qi(xt,i, ct)]. Hence, µi(xt,i, ct) represents the average quality of worker i with personal context xt,i when completing a task of context ct. Therefore, the performance pi(xt,i, ct) of worker i with personal context xt,i for a task of context ct has unknown distribution, takes values in [0, qmax] and its expected value satisfies\nE[pi(xt,i, ct)] = θi(xt,i, ct),\nwhere θi(xt,i, ct) := ri(xt,i, ct)µi(xt,i, ct)."
    }, {
      "heading" : "C. Formal Problem Formulation",
      "text" : "Consider an arbitrary sequence of task budgets {bt}t=1,...,T (which translates to a sequence {mt}t=1,...,T ) and an arbitrary sequence of worker availability {Wt}t=1,...,T . Let yt,i denote a binary variable which is 1 if worker i is requested to complete task t and 0 otherwise. Then, the problem of selecting, for each task, a subset of workers which maximizes the sum of expected performances given the task budget is given by\nmax {yt,i}i∈Wt\nT∑ t=1 ∑ i∈Wt θi(xt,i, ct)yt,i (1)\ns.t. ∑ i∈Wt yt,i ≤ mt ∀t = 1, ..., T\nyt,i ∈ {0, 1} ∀i ∈ Wt, ∀t = 1, ..., T.\nFirst, we analyze problem (1) assuming full knowledge about worker performance. Therefore, assume that there was an entity that (i) was an omniscient oracle, which knows the expected performance of each worker in each context for each task context a priori and (ii) for each arriving task, this entity is centrally informed about the current contexts of all available worker. For such an entity, problem (1) is an integer linear programming problem, which can be decoupled to an independent sub-problem per arriving task. For a task t, if less workers are available than required, i.e., Wt ≤ mt, the optimal solution is to request all available workers to complete the task. However, if Wt > mt, the corresponding\nsub-problem is a special case of a knapsack problem with a knapsack of size mt and with items of identical size and non-negative profit. Therefore, the optimal solution can be easily computed in at most O(W log(W )) by ranking the available workers according to their context-specific expected performance and selecting the mt highest ranked workers. By S∗t = {s∗t,1, ..., s∗t,min{mt,Wt}}, we denote the optimal subset of workers to select for task t. Formally, these workers satisfy\ns∗t,j ∈ argmax i∈Wt\\ ⋃j−1 k=1 s ∗ t,k θi(xt,i, ct) for j = 1, ...,min{mt,Wt}.\nNote that S∗t depends on the task budget bt and context ct, the set Wt of available workers and their personal contexts {xt,i}i∈Wt , but we write S∗t instead of S∗t (bt, ct,Wt, {xt,i}i∈Wt) for brevity. Let S∗ = {S∗t }t=1,...,T be the collection of optimal subsets of workers for the collection {1, ..., T} of tasks. We call this collection the solution achieved by a centralized oracle, since it requires an entity which has a priori knowledge about expected performances and central knowledge about all current worker contexts to make optimal decisions.\nHowever, we assume that the MCSP does not have a priori knowledge about expected performances, but it still has to select workers for arriving tasks. Let St := {st,1, ..., st,min{mt,Wt}} denote the set of workers that the MCSP selects and requests to complete task t. If for an arriving task, less workers are available than required, i.e., Wt ≤ mt, by simply requesting all available workers (i.e., St = Wt) to complete the task, the MCSP still automatically selects the optimal subset of workers. Otherwise, for Wt > mt, the MCSP cannot simply solve problem (1) like an omniscient oracle, since it does not know the expected performances θi(xt,i, ct). Moreover, we assume that a worker’s current personal context is only locally available in his mobile device. We call the software of the mobile crowdsourcing application, which is installed in a worker’s mobile device, a local controller (LC) and we denote by LC i the LC of worker i. Each LC has access to its corresponding worker’s personal context information, but it does not share this information with the MCSP. Hence, only the set of LCs, but not the MCSP does have knowledge about the workers’ current personal contexts (such as, their current locations, their activities). However, the expected performance of a worker might depend on his personal context.\nHence, the MCSP and the LCs should cooperate in order to learn expected performances over time and in order to select an appropriate subset of workers for each task. For this purpose, over time, the system of MCSP and LCs has to find a trade-off between exploration and exploitation, by, on the one hand, selecting workers about whose performance only little information is available and, on the other hand, selecting workers which are likely to have high expected performance. For each arriving task, the selection of workers depends on the history of previously selected workers and their observed performances. However, observing worker performance might be costly, since it might require a manual quality rating from a task owner, or an automatic quality assessment using local software in a battery-constrained mobile device. Hence, the number of performance observations should be limited in order\n6 to keep the cost for such quality assessment feasible (e.g., a task owner should not have to rate the quality of dozens of workers for a single task; quality assessment in mobile devices should be limited to save battery).\nNext, we will present a context-aware hierarchical online learning algorithm, which maps the history of previously selected workers and observed performances to the next selection of workers. The performance of this algorithm can be evaluated by comparing its loss with respect to the centralized oracle. This loss is called the regret of learning. For an arbitrary sequence of task budgets {bt}t=1,...,T (translating to a sequence {mt}t=1,...,T ) and an arbitrary sequence of worker availability {Wt}t=1,...,T , the regret is formally defined as\nR(T ) = E  T∑ t=1 min{mt,Wt}∑ j=1 ( ps∗t,j (xt,s∗t,j , ct)− pst,j (xt,st,j , ct) ), (2)\nwhich is equivalent to\nR(T ) = T∑ t=1 min{mt,Wt}∑ j=1 ( θs∗t,j (xt,s∗t,j , ct)− E[θst,j (xt,st,j , ct)] ) .\n(3)"
    }, {
      "heading" : "IV. A CONTEXT-AWARE HIERARCHICAL ONLINE LEARNING ALGORITHM FOR PERFORMANCE",
      "text" : "MAXIMIZATION IN MOBILE CROWDSOURCING\nThe goal of the MCSP is to select, for each arriving task, a set of workers that maximizes the sum of expected performances for that task given the task budget. Since the expected performances are not known a priori by neither MCSP nor the LCs, they have to be learned over time. Moreover, since only the LCs have access to the personal context of their respective worker, a coordination is needed between the MCSP and the LCs. Below, we propose a hierarchical contextual online learning algorithm, which is based on algorithms for the contextual multi-armed bandit problem [23]–[28]. Our algorithm is based on the assumption that a worker’s expected performance is similar in similar personal and task contexts. Therefore, by observing the task context, a worker’s personal context and his performance when requested to complete a task, the worker’s context-specific expected performances can be learned and exploited for future worker selection.\nWe call the proposed algorithm Hierarchical Context-aware Learning (HCL). Fig. 2 shows an overview of HCL’s operation. In HCL, the MCSP broadcasts the context of each arriving task to the LCs. Upon receiving information about a task, an LC first observes its worker’s personal context. If the worker’s performance has been observed sufficiently often before given the current joint personal and task context, the LC relies on previous observations to estimate its worker’s performance and sends the estimated performance to the MCSP. If its worker’s performance has not been observed sufficiently often before, the LC informs the MCSP that its worker has to be explored. Based on the messages received from the LCs, the MCSP selects a subset of workers and requests them to complete the task. The number of selected workers depends\nFig. 2. Overview of operation of HCL algorithm for task t.\non the task budget, the price per worker and the number of available workers. The LC of each selected worker observes its worker’s decision to accept/decline the task. If a worker was selected for exploration purposes and he accepted the task, the LC additionally observes the quality of the completed task. The reason for only making a quality assessment when a worker was selected for exploration purposes is that this may either require a manual quality rating from the task owner, or, an automatic quality assessment at the mobile device using local software, which both may be costly.10 Hence, by observing the quality of a completed task only if the worker was selected for exploration purposes, HCL keeps the number of costly quality assessments low.\nIn HCL, a worker’s personal contexts, decisions and qualities are only locally stored at the LC, but not shared with the MCSP. Thereby, i) personal context is locally protected, ii) the required storage space for worker information at the MCSP is kept low, iii) task completion and result transmission can be directly handled between the LC and the task owner, without the need for the MCSP to interfere, iv) workers receive requests for tasks that are interesting for them and which they are good at, but without the need to share their context information, v) even though an LC has to keep track of its worker’s personal context, decision and quality, the computation and storage overhead for each LC is small.\nIn more detail, LC i operates as follows, as given in the pseudocode in Alg. 1. First, for synchronization purposes, LC i receives the finite number T of tasks to be considered, the task context space C and its dimension C from the MCSP. Moreover, LC i checks to which of worker i’s context dimensions it has access. This defines the personal context space Xi and its dimension Xi. Then, LC i sets the joint context space to Xi ×C with size Di := Xi +C. In addition, LC i has to set a parameter hT,i ∈ N and a control function Ki : {1, ..., T} → R+, which are both described below. Next, LC i initializes a uniform partition QT,i of worker i’s joint context space [0, 1]Di , which consists of (hT,i)Di Di-dimensional hypercubes of equal size 1hT,i × . . . × 1 hT,i .\n10If quality assessment is cheap, HCL can be adapted to always observe worker quality. This may increase the learning speed.\n7 Algorithm 1 HCL@LC: Local Controller i of Worker i. 1: Receive input from MCSP: T , C, C 2: Receive input from worker i: Xi, Xi 3: Set joint context space Xi × C, set Di := Xi + C 4: Set parameter hT,i ∈ N and control function Ki : {1, ..., T} → R+\n5: Initialize context partition: Create partition QT,i of [0, 1]Di into (hT,i)Di hypercubes of identical size 6: Initialize counters: For all q ∈ QT,i, set Ni,q = 0 7: Initialize estimated performance: For all q ∈ QT,i, set θ̂i,q = 0 8: for each t = 1, ..., T do 9: if i ∈ Wt then 10: Receive task context ct 11: Observe worker i’s personal context xt,i 12: Find the set qt,i ∈ QT,i such that (xt,i, ct) ∈ qt,i 13: if Ni,qt,i > Ki(t) then 14: Send messagei := θ̂i,qt,i to MCSP 15: else 16: Send messagei := ”explore” to MCSP 17: end if 18: Wait for MCSP’s worker selection 19: if MCSP requests worker i to perform task t then 20: Observe worker i’s decision d 21: if messagei == ”explore” then 22: if d = 1 then 23: Observe worker i’s quality q, set p := q 24: else 25: Set p := 0 26: end if 27: θ̂i,qt,i = θ̂i,qt,iNi,qt,i+p\nNi,qt,i+1\n28: Ni,qt,i = Ni,qt,i + 1 29: end if 30: end if 31: end if 32: end for\nHence, the parameter hT,i ∈ N determines the granularity of the partition of the context space. Moreover, LC i initializes a counter Ni,q(t) for its worker i for each hypercube q ∈ QT,i. The counter Ni,q(t) represents the number of times before (i.e., up to, but not including) task t, in which worker i was selected to complete a task when worker i’s joint personal and task context belonged to hypercube q. Additionally, for each hypercube q ∈ QT,i, LC i initializes the counter θ̂i,q(t), which represents the estimated performance of its worker i for contexts in hypercube q before task t.\nThen, LC i performs the following steps for each of the sequentially arriving tasks t = 1, ..., T . For an arriving task t, LC i only takes actions if its worker i is currently available (i.e., i ∈ Wt). If this is the case, LC i first receives the task context ct sent by the MCSP.11 Moreover, it observes worker i’s current personal context xt,i and determines the\n11A worker being not available may mean that he is offline so that the LC cannot even receive information about the arriving task. Therefore, we here consider the LC to only take actions if its worker is in the “available” mode.\nhypercube from QT,i to which the joint context (xt,i, ct) belongs to. We denote this hypercube by qt,i ∈ QT,i. It satisfies (xt,i, ct) ∈ qt,i. Then, LC i checks if worker i has not been selected sufficiently often before when worker i’s joint personal and task context belonged to hypercube qt,i. For this purpose, LC i compares the counter Ni,qt,i(t) with Ki(t), where Ki : {1, ..., T} → R+ is a deterministic, monotonically increasing control function, set in the beginning of the algorithm. On the one hand, if worker i has been selected sufficiently often before (Ni,qt,i(t) > Ki(t)), LC i can rely on the estimated performance θ̂i,qt,i(t), which it sends to the MCSP in this case. On the other hand, if worker i has not been selected sufficiently often before (Ni,qt,i(t) ≤ Ki(t)), LC i sends an “explore” message to the MCSP. The control function Ki(t) is hence needed to distinguish when a worker should be selected for exploration (to achieve reliable estimates) or when its estimates are already reliable and can be exploited. Therefore, the choice of control function is essential to ensure a good result of the learning algorithm, since it determines the trade-off between exploration and exploitation. Then, LC i waits for the MCSP to take care of the worker selection. If worker i is not selected, LC i does not take further actions. However, if the MCSP requests worker i, LC i observes whether worker i declines or accepts the task. If worker i was selected for exploration purposes, LC i performs an additional counter update. For this, if worker i accepted the task, LC i first additionally observes worker i’s quality in completing the task (e.g., by requesting a quality rating from the task owner or by using local software for automatic quality assessment) and sets the observed performance to the observed quality. If worker i declined the task, LC i sets the observed performance to 0. Then, based on the observed performance, LC i computes the estimated performance θ̂i,qt,i(t+1) for hypercube qt,i and the counter Ni,qt,i(t+1). Note that in Alg. 1, the argument t is omitted from counters Ni,q(t) and θ̂i,q(t) since it is not necessary to store previous values of these counters.\nBy definition of HCL, the estimated performance θ̂i,q(t) corresponds to the product of (i) the relative frequency with which worker i accepted tasks when the joint context belonged to hypercube q and (ii) the average quality in completing these tasks. Formally, θ̂i,q(t) is computed as follows. Let Ei,q(t) be the set of observed performances of worker i before task t when worker i was selected for a task and the joint context was in hypercube q. If before task t, worker i’s performance has never been observed before for a joint context in hypercube q, we have Ei,q(t) = ∅ and θ̂i,q(t) := 0. Otherwise, the estimated performance is given by θ̂i,q(t) := 1|Ei,q(t)| ∑ p∈Ei,q(t) p. However, in HCL, the set Ei,q(t) does not appear, since the estimated performance θ̂i,q(t) can be computed based on θ̂i,q(t− 1), Ni,q(t− 1) and on the performance for task t− 1.\nIn HCL, the MCSP is responsible for the worker selection, which it performs according to the pseudocode given in Alg. 2. First, for synchronization purposes, the MCSP sends the finite number T of tasks to be considered, the task context space C and its dimension C to the LCs. Then, for each arriving task t = (bt, ct), the MCSP computes the required number of workers mt, based on the budget bt and the price e per\n8 Algorithm 2 HCL@MCSP: Worker Selection at MCSP. 1: Send input to LCs: T , C, C 2: for each t = 1, ..., T do 3: Receive task t = (bt, ct) 4: Compute mt = b bte c 5: Set Wt = ∅ 6: Set Wuet = ∅ 7: Broadcast task context ct 8: for each i = 1, ...,W do 9: if Receive messagei from LC i then 10: Wt =Wt ∪ {i} 11: if messagei == ”explore” then 12: Wuet =Wuet ∪ {i} 13: end if 14: end if 15: end for 16: Compute Wt = |Wt| 17: if Wt ≤ mt then . SELECT ALL 18: Select all Wt workers from Wt 19: else 20: Compute nue,t = |Wuet | 21: if nue,t == 0 then . EXPLOITATION 22: Rank workers in Wt according to estimates from (messagei)i∈Wt 23: Select the mt highest ranked workers 24: else . EXPLORATION 25: if nue,t ≥ mt then 26: Select mt workers randomly from Wuet 27: else 28: Select the nue,t workers from Wuet 29: Rank workers in Wt \\ Wuet according to estimates from (messagei)i∈Wt\\Wuet 30: Select the (mt − nue,t) highest ranked workers 31: end if 32: end if 33: end if 34: Request selected workers to perform task t 35: end for\nworker. In addition, the MCSP initializes two sets. The set Wt represents the set of available workers when task t arrives, while Wuet is the so-called set of under-explored workers, which contains all available workers which have not been selected sufficiently often before. After broadcasting the task context ct, the MCSP waits for messages from the LCs. If the MCSP receives a message from an LC, it adds the corresponding worker to the set Wt of available workers. Moreover, in this case the MCSP additionally checks if the received message is an “explore” request. If this is the case, the MCSP adds the corresponding worker to the set Wuet of under-explored workers. Note that according to Alg. 1 and Alg. 2, the set of under-explored workers is hence given by\nWuet = {i ∈ Wt : Ni,qt,i(t) ≤ Ki(t)}. (4)\nNext, the MCSP calculates the number Wt of available workers. If Wt ≤ mt, i.e., exactly the required number or less\nworkers are available, the MCSP enters a select-all-workers phase and selects all available workers to complete the task. Otherwise, the MCSP continues by calculating the number nue,t := |Wuet | of under-explored workers. If there is no underexplored worker, the MCSP enters an exploitation phase. It ranks the available workers in Wt according to the estimated performances, which it received from their respective LCs. Then, the MCSP selects the mt highest ranked workers from this ranking. By this procedure, the MCSP is able to use context-specific estimated performances without actually observing the workers’ current personal context. If there are under-explored workers, the MCSP enters an exploration phase. These phases are needed, such that the LCs of all workers are able to update their estimated performances sufficiently often. Here, two different cases can occur, depending on the number nue,t of under-explored workers. Either the number nue,t of under-explored workers is at least mt, in which case the MCSP selects mt under-explored workers at random. Or the number nue,t of under-explored workers is smaller than mt, in which case the MCSP selects all nue,t underexplored workers. Since it should select mt−nue,t additional workers, it ranks the available sufficiently-explored workers according to the estimated performances, which it received from their respective LCs. Then, the MCSP additionally selects the (mt−nue,t) highest ranked workers from this ranking. In this way, additional exploitation is carried out in exploration phases, when the number of under-explored workers is small. After worker selection, the MCSP requests selected workers to perform the task by alerting them via the application’s user interface. Via their interface, these workers are also informed about task context ct. Note that since the MCSP does not have to keep track of the workers’ decisions, the LCs can handle the contact to the task owner directly (e.g., the task owner may send more detailed task instructions directly to the LC; after task completion, the LC sends the result of the completed task to the task owner)."
    }, {
      "heading" : "V. THEORETICAL ANALYSIS",
      "text" : ""
    }, {
      "heading" : "A. Upper Regret Bound",
      "text" : "The performance of HCL is evaluated by analyzing its regret, see Eq. (2), with respect to the centralized oracle. In this section, we derive a sublinear bound on the regret, i.e., we show that R(T ) = O(T γ) with some γ < 1 holds. Hence, our algorithm does not have a loss compared to the centralized oracle, since for T → ∞, it follows that limT→∞ R(T ) T = 0. The regret bound is derived based on the assumption that under a similar personal context and a similar task context, a worker’s expected performance is also similar. This assumption can be formalized as follows.12\nAssumption 1 (Hölder continuity assumption): There exists L > 0, α > 0 such that for all workers i ∈ W and for all joint contexts (x, c), (x̃, c̃) ∈ Xi × C ≡ [0, 1]Di , it holds that\n|θi(x, c)− θi(x̃, c̃)| ≤ L||(x, c)− (x̃, c̃)||αi ,\nwhere || · ||i denotes the Euclidean norm in RDi .\n12Note that our algorithm can also be applied to data, which does not satisfy this assumption. In this case, the regret bound may, however, not hold.\n9 The theorem given below shows that the regret of HCL is sublinear in the time horizon T .\nTheorem 1 (Bound for R(T )): Given that Assumption 1 holds, when LC i, i ∈ W , runs Alg. 1 with parameters Ki(t) = t 2α 3α+Di log(t), t = 1, ..., T , and hT,i = dT 1 3α+Di e, and the MCSP runs Alg. 2, the regret R(T ) is bounded by\nR(T ) ≤ qmaxW W∑ i=1 2Di ( log(T )T 2α+Di 3α+Di + T Di 3α+Di ) +\nW∑ i=1 2qmax (2α+Di)/(3α+Di) T 2α+Di 3α+Di\n+ 2 W∑ i=1 LD α 2 i T 2α+Di 3α+Di + qmaxW π2 3 .\nHence, the leading order of the regret is O ( qmaxW 2T 2α+Dmax 3α+Dmax log(T ) ) , where Dmax := maxi=1,...,W Di. The proof of Theorem 1 is given in Appendix A. Theorem 1 shows that HCL converges to the centralized oracle in the sense that when the number T of tasks goes to infinity, the averaged regret R(T )T diminishes. Moreover, since Theorem 1 is applicable for any finite number T of tasks, it can be used to characterize the algorithm’s speed of learning.\nWhile the regret bound given in Theorem 1 holds for an arbitrary sequence of task budgets and worker availability, more specific regret bounds can be derived for specific stochastic task budgets and worker availability. For example, consider the case when both the task budgets {bt}t=1,...,T and the worker availability {Wt}t=1,...,T are i.i.d. random variables. Furthermore, assume that the distributions of {bt}t=1,...,T and {Wt}t=1,...,T are such that Pr(mt < Wt) = Pr(b bte c < Wt) = β for some β ∈ [0, 1] for t = 1, ..., T . This means, that with probability β, the number of available workers exceeds the required number of workers for any task. For this scenario, the following regret bound holds.\nCorollary 1 (Bound for R(T ) under Pr(mt < Wt) = β): Given that Assumption 1 holds and Pr(mt < Wt) = β, ∀ t = 1, . . . , T , when LC i, i ∈ W , runs Alg. 1 with the parameters given in Theorem 1, and the MCSP runs Alg. 2, the regret R(T ) is bounded by\nR(T ) ≤ β ( qmaxW\nW∑ i=1 2Di ( log(T )T 2α+Di 3α+Di + T Di 3α+Di ) +\nW∑ i=1 2qmax (2α+Di)/(3α+Di) T 2α+Di 3α+Di\n+ 2 W∑ i=1 LD α 2 i T 2α+Di 3α+Di + qmaxW π2 3\n) .\nThe proof of Corollary 1 is given in Appendix B. Compared to Theorem 1, in this special case, the regret is scaled by the factor β, since with probability (1 − β), the tasks need more workers than available workers, and hence, the algorithm selects the optimal set of workers, which is the set of all available workers."
    }, {
      "heading" : "B. Local Storage Requirements",
      "text" : "The required local storage size in the mobile device of a worker is determined by the storage size needed when the LC executes Alg. 1. In Alg. 1, the LC of worker i stores the counters Ni,q and θ̂i,q for each q ∈ QT,i. Using the parameters from Theorem 1, the number of hypercubes in the partition QT,i is (hT,i)Di = dT 1 3α+Di eDi ≤ 2DiT Di 3α+Di . Hence, the number of counters to store in the mobile device of worker i is upper bounded by 2DiT Di 3α+Di . Hence, the required storage depends on the number Di = Xi + C of context dimensions. If the worker allows access to a high number Xi of personal context dimensions and/or the number C of task context dimensions is large, the algorithm learns the worker’s context-specific performance with finer granularity and therefore the assigned tasks are more personalized, but also the required storage size will increase."
    }, {
      "heading" : "C. Communication Requirements",
      "text" : "The communication requirements of HCL can be deduced from its main operation steps: For each task t, first, the MCSP broadcasts the task context to the LCs, which is a vector of dimension C (or, in other words, C scalars). Then, the LCs of available workers estimate their worker’s performance and send it to the MCSP. This corresponds to Wt scalars to be transmitted (one scalar sent by each LC of an available worker). Finally, the MCSP informs the selected workers about its decision, which corresponds to mt scalars sent by the MCSP. Hence, for task t, in sum, Wt · (C + 1) +mt scalars have to be transmitted. Among these, Wt ·C +mt scalars are transmitted by the MCSP and one scalar is transmitted by each mobile device of an available worker.\nWe now compare the communication requirements of HCL and of the centralized version of HCL, in which for each task, first, the personal contexts of available workers are gathered in the MCSP, which then makes the worker selection based on the task and personal contexts and informs selected workers about its decision. The communication requirements of the centralized version are as follows: For each task t, the LC of each available worker i sends the current worker context to the MCSP, which is a vector of dimension Di (i.e., Di scalars). Hence, in sum, ∑ i∈Wt Di scalars are transmitted. After worker selection, the MCSP requests selected workers to perform the task, which corresponds to mt scalars sent by the MCSP. Moreover, the MCSP has to inform the mt selected workers about the task context, which is a vector of dimension C (i.e., C scalars). Hence, in total, ∑ i∈Wt Di+mt · (C +1) scalars are transmitted for task t. Among these, mt · (C + 1) scalars are transmitted by the MCSP and Di scalars are transmitted by each mobile device of an available worker.\nFrom this analysis, we can deduce the following: Since the number Di of personal context dimensions will typically be larger than 1, HCL reduces the size of transmission of each mobile device, compared to the centralized approach, while still taking advantage of personal context information. In a special case, even the sum communication requirements (for all mobile devices and the MCSP in sum) of HCL are smaller than that of the centralized approach: If C < Dmin, where\n10\nDmin = mini=1,...,W Di, and additionally 1C ≤ mt Wt for all t = 1, ..., T , then in the centralized approach, in sum, at least∑ i∈Wt Di + mt · (C + 1) ≥ WtDmin + mt · (C + 1) > Wt · (C + 1) +mt scalars are transmitted."
    }, {
      "heading" : "D. Worker Quality Assessment Requirements",
      "text" : "As mentioned above, observing a worker’s quality might be costly since it might require either a quality rating by the task owner or an automatic quality assessment using local software in the battery-constrained mobile device. HCL explicitly takes this into account by only requesting a quality assessment if a worker is selected for exploration purposes. Here, we give an upper bound on the number Ai(T ) of quality assessments per worker up to task T .\nCorollary 2 (Bound for Number of Quality Assessments up to task T ): Given that Assumption 1 holds, when LC i, i ∈ W , runs Alg. 1 with parameters Ki(t) = t 2α 3α+Di log(t), t = 1, ..., T , and hT,i = dT 1\n3α+Di e, and the MCSP runs Alg. 2, the number Ai(T ) of quality assessments of each worker i up to task T is upper bounded by\nAi(T ) ≤ 2Di ( log(T )T 2α+Di 3α+Di + T Di 3α+Di ) .\nThe proof of Corollary 2 is given in Appendix C. From Corollary 2, we see that the number of quality assessments per worker is sublinear in T . Hence, it holds limT→∞ Ai(T ) T = 0, so that the for T →∞, the average rate of quality assessments approaches zero."
    }, {
      "heading" : "VI. NUMERICAL RESULTS",
      "text" : "We evaluate HCL by comparing its performance with various algorithms based on synthetic and real data."
    }, {
      "heading" : "A. Reference Algorithms",
      "text" : "The following algorithms are used for comparison. • (Centralized) Oracle: The Oracle has perfect a priori\nknowledge about context-specific expected performances. Moreover, it is centrally informed about the current contexts of available workers. • LinUCB: This algorithm assumes that the expected performance of a worker is linear in its context [29], [30]. Based on a linear reward function over contexts and the history of previous observations of contextspecific worker performances, for each task, the algorithm chooses the mt available workers with highest estimated upper confidence bounds on their expected performance. The algorithm has an input parameter λLinUCB, controlling the influence of the confidence bound. LinUCB is used in [20] for task assignment in spatial crowdsourcing. • AUER: This algorithm [31] is an extension of the wellknown UCB algorithm [32] to the sleeping arm case. It learns from previous observations of worker performances, but without taking into account context information. Based on the history of previous observations of worker performances, this algorithm selects the mt available workers with highest estimated upper confidence bounds on their expected performance. The algorithm has\nan input parameter λAUER, which controls the influence of the confidence bound. • -Greedy: With a probability of ∈ (0, 1), this algorithm selects a random subset of available workers. With a probability of (1 − ), the algorithm selects the mt available workers with highest estimated performance. The estimated performance of a worker is computed based on the history of previous performances [32], but without taking into account context. • Myopic: This algorithm only learns from the last interaction with each worker. For task 1, it selects a random subset of m1 workers. For each of the following tasks, it checks which of the available workers have previously accepted a task. If more than mt of the available workers have accepted a task when requested the last time, the algorithm selects out of these workers the mt workers with the highest performance in their last completed task. Otherwise, the algorithm selects all of these workers and an additional subset of random workers so that in total mt workers are selected. • Random: For each task t, a random subset of mt available workers is selected.\nNote that, if an algorithm originally would have selected only one worker per task, we adapted it to select mt workers per task. Also, above, we described the behavior of the algorithms for the case mt < Wt. In the case of mt ≥ Wt, we adapted each algorithm such that it selects all available workers. Moreover, most of the reference algorithms are usually used in a centralized fashion, but they can be decoupled to use them in the same hierarchical setting as HCL."
    }, {
      "heading" : "B. Evaluation Metrics",
      "text" : "Each algorithm is run over a sequence of tasks t = 1, ..., T and its result is evaluated using the following metrics. As a function of the arriving tasks, we compute the cumulative performance up to t achieved by an algorithm, which is the cumulative sum of performances by all selected workers up to (and including) task t. Formally, if the set of selected workers of an algorithm A for task t is {sAt,j}j=1,...,min{mt,Wt} and psAt,j (t) is the observed performance of worker s A t,j , the cumulative performance up to t achieved by algorithm A is\nt∑ t̃=1 min{mt̃,Wt̃}∑ j=1 psA t̃,j (t̃).\nMoreover, we compute the average worker performance up to t achieved by an algorithm, which is the average performance of all selected workers up to task t. Formally, the average worker performance up to t is defined by\n1∑t t̃=1 min{mt̃,Wt̃} t∑ t̃=1 min{mt̃,Wt̃}∑ j=1 psA t̃,j (t̃)."
    }, {
      "heading" : "C. Simulation Setup",
      "text" : "We evaluate the different algorithms using synthetic as well as real data. The difference between the two approaches lies in the arrival process of workers and their contexts. To produce\n11\nsynthetic data, we generate workers and their contexts based on some predefined distributions as described below. In case of real data, similar to, e.g., [6], [20], [22], we use a data set from Gowalla [33]. Gowalla is a location-based social network where users share their location by checking in at ’spots’, i.e., certain places in their vicinity. We use the check-ins to simulate the arrival process of workers and their contexts. The Gowalla data set consists of 6,442,892 check-ins of 107,092 distinct users over the period of February 2009 to October 2010. Each entry of the data set consists of the form (User ID, Check-in Time, Latitude, Longitude, Location ID). Similar to the approach in [22], we first extract the check-ins in New York City, which leaves a subset of 138,954 checkins of 7,115 distinct users at 21,509 distinct locations. This resulting Gowalla-NY data set is used below. Fig. 3(a) shows the distribution of the number of check-ins in the GowallaNY data set. The number of check-ins is distributed between 1 check-in (1414 users) up to 1794 check-ins (1 user). As an example, 2532 users checked in more than 10 times. Fig. 3(b) shows the distribution of the number of distinct locations visited by the users in the Gowalla-NY data set. The number of visited locations is distributed between 1 location (1524 users) up to 1633 locations (1 user). For example, 3661 users checked in at more than 5 locations.\nFor both synthetic and real data, the basic simulation setup is as follows: We simulate an MCSP, to which a set of W = 100 workers belongs. For synthetic data, 100 workers are created in the beginning. For real data, we randomly select 100 users from the Gowalla-NY data set, which represent the 100 workers of the MCSP. Then we use this reduced Gowalla-NY data set containing the check-ins of 100 users. Task owners have to pay a fixed price of e = 1 per worker requested by the MCSP to perform the task. The quality of a completed task lies in the range qmin = 0 and qmax = 5. The task properties are modeled as follows. The task budget is sampled from a normal distribution with expected value 20 and standard deviation of 5, truncated between 1 and 500, i.e., given the price e = 1, the required number mt of workers is on average 20. The task context is assumed to be uniformly distributed in C = [0, 1] (i.e., C = 1).\nThe worker arrival process and the worker context are sampled differently in case of synthetic and real data. For synthetic data, we let each worker be available with a probability of ρ = 0.7 (default value) for each arriving task. The personal context space of an available worker i is set to Xi = [0, 1]2 (i.e., Xi = 2). The first personal context\ndimension refers to the worker’s location, which is sampled from 5 different (personal) locations, using a weighted discrete distribution with probabilities { 12 , 1 3 , 1 12 , 1 24 , 1 24} to represent the fact that workers may use the crowdsourcing application different amounts of time in different places (e.g., at home more often than at work). The second personal context dimension refers to the worker’s battery state, which is sampled from a uniform distribution in [0, 1]. The worker performance is modeled as follows. The joint personal and task context space C × Xi (of dimension Di = 3) is uniformly split into a uniform grid of 125 subsets (i.e., in each of the 3 dimension, the space is split into 5 identical parts). In each of the subsets, the expected performance of a worker is a priori sampled uniformly at random from [0, 5]. Later, for each sampled joint worker and task context, first it is checked to which subset of the grid the sampled context belongs. Then, the instantaneous performance is sampled by adding noise uniformly sampled from [−1, 1] to the expected performance in the given subset of the grid (the noise interval is truncated to a smaller interval if the expected performance lies close to either 0 or qmax).\nUsing real data, the arrival processes of workers and their contexts are sampled as follows. For the worker availability, we use a Binomial distribution with parameters W = 100 and ρ = 0.7 (default value) to sample the number of available workers Wt for an arriving task.13 Having sampled Wt, we randomly draw samples from the reduced Gowalla-NY data set (consisting of the check-ins of 100 users) until these samples contain Wt distinct users. These Wt sampled users correspond to the available workers (i.e., users with higher number of check-ins in the reduced Gowalla-NY data set translate to workers that are more often available for the MCSP). The personal context space of an available worker is again set to Xi = [0, 1]2 (i.e., Xi = 2). We set the first personal context of the available workers to the check-in location of the respective user from the sample.14 The second personal context dimension refers again to the battery state, uniformly sampled from [0, 1]. The worker performance is modeled as follows. The joint personal and task context space C × Xi (Di = 3) is split into a grid. Along the dimensions of task context and battery state, the context space is split into 5 uniform parts each. Along the dimension of location context, the context space is split into li uniform parts, where li corresponds to the number of distinct locations visited by the corresponding user from the reduced Gowalla-NY data set (i.e., for each visited location, the expected performance will be different). In each of the 5 ·5 · li subsets, the expected performance of a worker is a priori sampled uniformly at random from [0, 5]. In this way, workers with higher number of visited locations have a higher number of different context-specific performances. Later, for each sampled joint worker and task context, the instantaneous performance is sampled by adding noise uniformly sampled from [−1, 1] to the expected performance in the given subset of the grid (the noise interval is truncated to a smaller interval if the expected performance lies close to either 0 or qmax).\n13In this way, the number of available workers in our experiments using the real and the synthetic data are distributed in the same way.\n14If a user was sampled several times until we sampled Wt distinct users, we choose his first sampled check-in location.\n12"
    }, {
      "heading" : "D. Parameter Selection",
      "text" : "HCL, LinUCB, AUER and -Greedy require a parameter as input, which affects their performance. In order to find appropriate parameters, we generate 20 synthetic instances, each instance consisting of a sequence of T = 10, 000 tasks and worker arrivals sampled according to the procedure explained above. Then, we run HCL, LinUCB, AUER and -Greedy with different parameters. Note that for HCL, we set α = 1, choose hT,i = dT 1 3+Di e, i = 1, ...,W , as in Theorem 1, and set the control function to Ki(t) = ft 2α\n3α+Di log(t), t = 1, ..., T , where the factor f ∈ (0, 1] is included to reduce the number of exploration phases. Then we search for an appropriate f . Table II shows the parameters at which each of the algorithms performed best, respectively."
    }, {
      "heading" : "E. Results",
      "text" : "Next, in order to evaluate the different algorithms, we generate another 100 synthetic instances and 100 instances based on real data. Each instance consists again of a sequence of T = 10, 000 tasks and worker arrivals sampled according to the descriptions given above. Then, we run the algorithms with the parameters from Table II, on the 100 synthetic instances and on the 100 instances based on real data, respectively. The results shown below are averaged over these 100 instances.\nFig. 4(a) and Fig. 4(b) show the cumulative worker performance up to task t as a function of the sequentially arriving tasks t = 1, ..., T , for synthetic and real data, respectively. The cumulative performance achieved by each algorithm is linearly increasing for increasing number of processed tasks for both synthetic and real data. As expected, while Oracle outperforms all other algorithms due to its a priori knowledge about the workers’ expected performances, Random gives a lower bound on the achievable cumulative performance. The proposed algorithm HCL clearly outperforms the algorithms LinUCB, AUER, -Greedy and Myopic, even though HCL observes worker performance only when requesting a worker for exploration purposes, while the other algorithms have access to worker performance whenever a worker is requested. This is due to the fact that HCL smartly exploits worker and task context information. In detail, the cumulative worker performance up to T achieved by HCL corresponds to between 1.47 (1.30) and 1.62 (1.39) times the results achieved by the other non-oracle algorithms for the synthetic (real) data. Moreover, HCL reaches a result close to the optimal. In detail, the cumulative worker performance up to T achieved by HCL corresponds to 0.96 (0.82) times the one achieved by Oracle for the synthetic (real) data. In contrast, the algorithms LinUCB, AUER, -Greedy and Myopic perform by far worse\nand interestingly, lie in a very similar region close to the result of Random. This shows that the learning approaches which either do not take context into account (i.e., AUER, -Greedy and Myopic) or which assume a linear dependency between context and performance (i.e., LinUCB), cannot cope with the non-linear context dependency of expected worker performance. Comparing synthetic and real data, HCL has a better performance on the synthetic data, but it still reaches a good result on the real data, even though each worker has his own diversity in context arrival and hence in expected performance in the real data (since users in the Gowalla-NY data set have different numbers of visited check-in locations).\nFig. 5(a) and Fig. 5(b) show the average worker performance up to task t as a function of the sequentially arriving tasks t = 1, ..., T . We see that over the sequence of tasks, the average worker performance achieved by Oracle and Random stay nearly constant at around 4.2 and 2.5 for both synthetic and real data. The algorithms LinUCB, AUER, -Greedy and Myopic increase the average worker performance slightly, starting between 2.4 and 2.5 at t = 1 and ending with average performance of between 2.5 and 2.7 at t = T . On the contrary, HCL is able to increase the average worker performance from\n13\n2.5 at t = 1 up to 4.0 (3.5) at t = T for the synthetic (real) data. Hence, HCL learns context-specific worker performances over time and after sufficiently many processed tasks selects workers almost as well as Oracle does.\nFinally, we evaluate the impact of worker availability by varying the probability ρ.15 For each value of ρ, we run all algorithms on 100 synthetic instances and 100 instances based on real data for T = 10, 000, respectively. Then, we average the results. Fig. 6(a) and 6(b) show the cumulative performance at T achieved by the algorithms for different ρ. For small ρ = 0.1, all algorithms yield approximately the same performance. This is as expected since given our modelling of task budget, for small ρ, the number of available workers is often smaller than the required number of workers. Since each of the algorithm enters a select-all-workers phase in this case, each algorithm performs optimally. For increasing worker availability ρ, the cumulative performance at T achieved by each of the algorithm increases. However, the gap in\n15Note that this is equivalent to varying the expected task budget. We therefore do not separately evaluate the impact of the task budget. In particular, the results presented below for different worker availability of course scale with the task budget and cannot be used to draw absolute conclusions.\nachieved performance between Oracle and HCL algorithm on the one hand, and the remaining algorithms LinUCB, AUER, -Greedy, Myopic and Random on the other hand, is increasing for increasing ρ. For example, at ρ ∈ {0.3, 0.7, 1}, the cumulative performance achieved by HCL corresponds to {1.23, 1.47, 1.49} ({1.10, 1.30, 1.35}) times the one achieved by the respective next best algorithm {AUER, LinUCB, LinUCB} ({ -Greedy, LinUCB, LinUCB}) for the synthetic (real) data. Hence, the more workers are available, the more severe is the effect of not selecting the most appropriate workers and only HCL is able to cope with the more difficult worker selection."
    }, {
      "heading" : "VII. CONCLUSION",
      "text" : "In this paper, we presented a context-aware hierarchical online learning algorithm, which learns the workers’ acceptance rates and their quality online over time in order to maximize the performance in a mobile crowdsourcing system for location-independent tasks. Our algorithm is split into two parts, one executed by local controllers in the mobile devices of the workers, the other executed by the mobile crowdsourcing platform. While the local controllers learn their\n14\nworkers’ acceptance rates and quality, the mobile crowdsourcing platform assigns workers to tasks based on regular information exchange with the local controllers. Our hierarchical approach ensures that the most suitable workers are requested by the mobile crowdsourcing platform. The learning in local controllers ensures that personal worker context can be kept locally, but still workers are offered those tasks they may be interested in. We showed that the requirements of our algorithm in terms of storage, communication and the number of quality assessments are small and that the algorithm converges to the optimal task assignment strategy."
    }, {
      "heading" : "ACKNOWLEDGEMENT",
      "text" : "The work by Sabrina Müller and Anja Klein has been funded by the German Research Foundation (DFG) as part of project B3 within the Collaborative Research Center 1053 – MAKI. The work by Mihaela van der Schaar was supported by an ONR Mathematical Data Sciences grant."
    }, {
      "heading" : "APPENDIX A PROOF OF THEOREM 1",
      "text" : "Given any length T sequence of task budgets and worker availability, let τT be the set of tasks in {1, ..., T} for which Wt > mt, and τ cT = {1, ..., T} \\ τT . τ cT is also called the set of select-all-workers phases. Also let τ̃T ⊆ τT be the set of tasks in τT for which the MCSP is in exploitation phase, and τ̃ cT = τT \\ τ̃T be the set of tasks in τT for which the MCSP is in exploration phase. τ̃T and τ̃ cT are random sets that depend on the selections of the MCSP and the randomness of the observed performances. Using the expressions above, the regret can be decomposed as follows:\nR(T ) = E [Rall(T ) +Ror(T ) +Roi(T )] ,\nwhere\nRall(T ) := ∑ t∈τcT min{mt,Wt}∑ j=1 ( θs∗t,j (xt,s∗t,j , ct)− θst,j (xt,st,j , ct) ) Ror(T ) :=\n∑ t∈τ̃cT min{mt,Wt}∑ j=1 ( θs∗t,j (xt,s∗t,j , ct)− θst,j (xt,st,j , ct) ) Roi(T ) :=\n∑ t∈τ̃T min{mt,Wt}∑ j=1 ( θs∗t,j (xt,s∗t,j , ct)− θst,j (xt,st,j , ct) ) .\nHere, Rall(T ), Ror(T ) and Roi(T ) represent the regret due to select-all-workers phases, due to exploration phases and due to exploitation phases, respectively. The regret is computed by considering for each task the loss due to selecting workers {st,j}j=1,...,min{mt,Wt} instead of the optimal workers {s∗t,j}j=1,...,min{mt,Wt}. This loss is computed by subtracting the sum of expected performances of the optimal workers from the sum of expected performances of the selected workers.\nNext, we will bound the expected values of each of the three summands above separately.\nFirst, we show that the regret due to select-all-workers phases is 0.\nLemma 1 (Value of E[Rall(T )]): When LC i ∈ W , runs Alg. 1 with an arbitrary deterministic function Ki : {1, ..., T} → R+ and an arbitrary hT,i ∈ N, and the MCSP runs Alg. 2, the regret E [Rall(T )] satisfies\nE[Rall(T )] = 0. (5)\nProof of Lemma 1: For t ∈ τ cT , i.e., Wt ≤ mt, the MCSP enters a select-all-workers phase. Moreover, for Wt ≤ mt, the trivial optimal solution is to request all available workers to complete task t. Hence, the MCSP’s selection of workers is optimal and therefore, select-all-workers phases do not contribute to the regret, i.e., E[Rall(T )] = 0.\nNext, a bound for E [Ror(T )] is given. It depends on the choice of some parameters zi and γi, i = 1, ...,W , which are only used in the regret analysis.\nLemma 2 (Bound for E[Ror(T )]): When LC i, i ∈ W , runs Alg. 1 with parameters Ki(t) = tzi log(t), t = 1, ..., T , and hT,i = dT γie, where 0 < zi < 1 and 0 < γi < 1Di , and the MCSP runs Alg. 2, the regret E [Ror(T )] is bounded by\nE[Ror(T )] ≤Wqmax W∑ i=1 2Di(log(T )T zi+γiDi + T γiDi).\n(6)\nProof of Lemma 2: Let t ∈ τ̃ cT be a task for which the MCSP enters an exploration phase. By design of HCL, in this case, it holds that Wt > mt, i.e., mt = min{mt,Wt}. Since the expected performance of a worker is bounded in [0, qmax], it follows that\nRor(T ) = ∑ t∈τ̃cT mt∑ j=1 ( θs∗t,j (xt,s∗t,j , ct)− θst,j (xt,st,j , ct) ) ≤ ∑ t∈τ̃cT mtqmax.\nHence, the regret can be bounded by\nE[Ror(T )] ≤ E ∑ t∈τ̃cT mtqmax  ≤Wqmax E\n∑ t∈τ̃cT 1  , since mt ≤W holds for all t = 1, ..., T .\nSince t ∈ τ̃ cT , the set of under-explored workers Wuet is non-empty. Hence, there exists an available worker i ∈ Wt with Ni,qt,i(t) ≤ Ki(t) = tzi log(t). By definition of Wuet , up to task T , worker i can induce at most dT zi log(T )e exploration phases for each of the (hT,i)Di hypercubes of the partition QT,i. Hence, the number of exploration phases is upper bounded as follows:\nE ∑ t∈τ̃cT 1  ≤ W∑ i=1 (hT,i) DidT zi log(T )e.\n15\n(This upper bound is rather loose, since several workers might be explored simultaneously, in which case they do not induce separate exploration phases.) Hence, we conclude\nE[Ror(T )] ≤Wqmax W∑ i=1 (hT,i) DidT zi log(T )e.\nUsing (hT,i)Di = dT γieDi ≤ (2T γi)Di = 2DiT γiDi , it holds\nE[Ror(T )] ≤Wqmax W∑ i=1 2Di(log(T )T zi+γiDi + T γiDi).\nNext, we give a bound for E [Roi(T )]. Again, this bound depends on the choice of some parameters zi and γi, i = 1, ...,W .\nLemma 3 (Bound for E [Roi(T )]): Given that Assumption 1 holds, when LC i, i ∈ W , runs Alg. 1 with parameters Ki(t) = tzi log(t), t = 1, ..., T , and hT,i = dT γie, where 0 < zi < 1 and 0 < γi < 1Di , and the MCSP runs Alg. 2, the regret E [Roi(T )] is bounded by\nE[Roi(T )] ≤ 2 W∑ i=1 qmax T 1− zi 2 1− zi2 + 2 W∑ i=1 LDi α 2 T 1−αγi\n+ qmaxW π2\n3 . (7)\nProof of Lemma 3: Let t ∈ τ̃T , i.e., the MCSP enters an exploitation phase. By design of HCL, in this case, it holds Wt > mt, i.e., mt = min{mt,Wt}. Additionally, since in exploitation phases, the set of under-explored workers is empty, i.e., Wuet = ∅, it holds that Ni,qt,i(t) > Ki(t) = tzi log(t) for all available workers i ∈ Wt.\nNow, let V (t) be the event that at the arrival of task t, each available worker i’s estimated performance θ̂i,qt,i(t) in the current hypercube qt,i is ”close” to its true expected value E[θ̂i,qt,i(t)], i.e.,\nV (t) = {|θ̂i,qt,i(t)− E[θ̂i,qt,i(t)]| < Hi(t) for all i ∈ Wt},\nfor some arbitrary Hi(t) > 0, i ∈ Wt. Next, we distinguish between exploitation phases in which V (t) or its complementary event, denoted by V c(t), hold. Let I{·} denote the indicator function. Then, we can write\nRoi(T ) = ∑ t∈τ̃T ( I{V (t)} (mt∑ j=1 (θs∗t,j (xt,s∗t,j , ct)− θst,j (xt,st,j , ct)) ))\n+ ∑ t∈τ̃T\n( I{V c(t)} (mt∑ j=1 (θs∗t,j (xt,s∗t,j , ct)− θst,j (xt,st,j , ct)) )) .\nUsing that the expected performance of a worker is bounded in [0, qmax], this term can further be bounded as\nRoi(T ) ≤ ∑ t∈τ̃T ( I{V (t)} · (mt∑ j=1 (θs∗t,j (xt,s∗t,j , ct)− θst,j (xt,st,j , ct)) )) (8)\n+ ∑ t∈τ̃T mtqmaxI{V c(t)}. (9)\nFirst, we bound (8). We start by noting that in an exploitation phase t ∈ τ̃T , since the MCSP selected workers {st,j}j=1,...,mt instead of {s∗t,j}j=1,...,mt , it holds that\nmt∑ j=1 θ̂s∗t,j ,qs∗t,j (t) ≤ mt∑ j=1 θ̂st,j ,qst,j (t). (10)\nWe also know that when V (t) holds, we have\n{|θ̂i,qt,i(t)− E[θ̂i,qt,i(t)]| < Hi(t) for all i ∈ Wt} (11)\nalmost surely. Finally, note that by Hölder continuity from Assumption 1, since (xt,i, ct) ∈ qt,i and for calculating θ̂i,qt,i(t), only contexts from hypercube qt,i are used, for each i ∈ Wt, it follows that\n|θi(xt,i, ct)− E[θ̂i,qt,i(t)]|\n= ∣∣∣∣∣θi(xt,i, ct)− E[ 1|Ei,qt,i(t)| ∑\np∈Ei,qt,i (t)\np ]∣∣∣∣∣\n= ∣∣∣∣∣ 1|Ei,qt,i(t)| ∑\np∈Ei,qt,i (t)\n(θi(xt,i, ct)− E[p]) ∣∣∣∣∣ ≤ 1 |Ei,qt,i(t)| ∑ p∈Ei,qt,i (t)\n∣∣∣θi(xt,i, ct)− E[p]∣∣∣ ≤ 1 |Ei,qt,i(t)| ∑ p∈Ei,qt,i (t) L ∣∣∣∣∣∣( 1 hT,i , . . . , 1 hT,i )∣∣∣∣∣∣α i ≤ LDi α 2 h−αT,i , (12)\nwhere we used the definition of θ̂i,qt,i(t) in the first line, linearity of expectation in the second line, triangle inequality in the third line. In the fourth line, since the corresponding context of each of the observed performances p ∈ Ei,qt,i(t) came from hypercube qt,i, we can use Assumption 1 and exploit the size 1hT,i × . . . × 1 hT,i\nof the hypercubes. Hence, by first using (12), then (11) and then (10), we have for (8)\n16\nI{V (t)} · ( mt∑ j=1 ( θs∗t,j (xt,s∗t,j , ct)− θst,j (xt,st,j , ct) ))\n≤ I{V (t)} · ( mt∑ j=1 ( E[θ̂s∗t,j ,qs∗t,j (t)]− E[θ̂st,j ,qst,j (t)]\n+ LDs∗t,j α 2 h−αT,s∗t,j + LDst,j α 2 h−αT,st,j\n))\n≤ I{V (t)} · ( mt∑ j=1 θ̂s∗t,j ,qs∗t,j (t)− mt∑ j=1 θ̂st,j ,qst,j (t)\n+ mt∑ j=1 ( Hs∗t,j (t) +Hst,j (t)\n+ LDs∗t,j α 2 h−αT,s∗t,j + LDst,j α 2 h−αT,st,j\n))\n≤ mt∑ j=1 ( Hs∗t,j (t) +Hst,j (t)\n+ LDs∗t,j α 2 h−αT,s∗t,j + LDst,j α 2 h−αT,st,j\n) almost surely.\n(13)\nTaking the expectation of (8) and exploiting that (13) holds almost surely for any t ∈ τ̃T yields\nE[Roi(T )]\n≤ T∑ t=1 ( mt∑ j=1 (Hs∗t,j (t) +Hst,j (t)\n+ LDs∗t,j α 2 h−αT,s∗t,j + LDst,j α 2 h−αT,st,j )\n)\n+ E [∑ t∈τ̃T mtqmaxI{V c(t)} ] .\nFinally, adding non-negative summands and using h−αT,i = dT γie−α ≤ T−αγi , we further have\nE[Roi(T )]\n≤ T∑ t=1\n( 2\nW∑ i=1 Hi(t) + 2 W∑ i=1 LDi α 2 T−αγi\n)\n+ T∑ t=1 mtqmax Pr(V c(t)|t ∈ τ̃T ).\nNext, we bound Pr(V c(t)|t ∈ τ̃T ). The event V c(t) can be written as\nV c(t) = {∃i ∈ Wt s.t. |θ̂i,qt,i(t)− E[θ̂i,qt,i(t)]| ≥ Hi(t)}.\nHence,\nPr(V c(t)|t ∈ τ̃T ) ≤ Pr(∃i ∈ Wt s.t. |θ̂i,qt,i(t)− E[θ̂i,qt,i(t)]| ≥ Hi(t)|t ∈ τ̃T )\n≤ ∑ i∈Wt Pr(|θ̂i,qt,i(t)− E[θ̂i,qt,i(t)]| ≥ Hi(t)|t ∈ τ̃T ).\nFor t ∈ τ̃T , we get by the definition of Wuet , for each i ∈ Wt it holds that Ni,qt,i(t) > Ki(t) = tzi log(t), and hence, |Ei,qt,i(t)| > tzi log(t). For i ∈ Wt, applying ChernoffHoeffding bound [34] and using |Ei,qt,i(t)| > tzi log(t), we get\nPr ( |θ̂i,qt,i(t)− E[θ̂i,qt,i(t)]| ≥ Hi(t)|t ∈ τ̃T ) = Pr ( θ̂i,qt,i(t)− E[θ̂i,qt,i(t)] ≥ Hi(t)|t ∈ τ̃T\n) + Pr ( −θ̂i,qt,i(t)− (−E[θ̂i,qt,i(t)]) ≥ Hi(t)|t ∈ τ̃T\n) ≤ 2 exp ( −2|Ei,qt,i(t)|Hi(t)2 1\nq2max ) ≤ 2 exp ( −2Hi(t)2tzi log(t) 1\nq2max\n) .\nHence, the regret due to exploitation phases is bounded by\nE[Roi(T )] ≤ T∑ t=1 ( 2 W∑ i=1 Hi(t) + 2 W∑ i=1 LDi α 2 T−αγi ) +\nT∑ t=1 mtqmax2 exp ( −2Hi(t)2tzi log(t) 1 q2max ) .\nSo far, the analysis was performed with respect to some arbitrary Hi(t) > 0, i = 1, ...,W . Setting Hi(t) := qmaxt− zi 2 for i = 1, ...,W , we get E[Roi(T )] ≤ T∑ t=1 ( 2 W∑ i=1 qmaxt − zi2 + 2 W∑ i=1 LDi α 2 T−αγi\n) +\nT∑ t=1 mtqmax2 exp\n( −2q2max(t− zi 2 )2tzi log(t)\nq2max\n)\n= 2 W∑ i=1 qmax T∑ t=1 t− zi 2 + 2 W∑ i=1 LDi α 2 T 1−αγi\n+ qmax T∑ t=1 mt2t −2\n≤ 2 W∑ i=1 qmax T 1− zi 2 1− zi2 + 2 W∑ i=1 LDi α 2 T 1−αγi\n+ qmaxW π2\n3 ,\nwhere, in the last step, we used the result from Appendix D, the fact that mt ≤ W holds and the value of the Dirichlet series.\nThe overall regret is now bounded by applying the above lemmas.\nProof of Theorem 1: First, for i = 1, ...,W , let Ki(t) = tzi log(t) and hT,i = dT γie, where 0 < zi < 1 and 0 < γi < 1 Di\n. Then, under Assumption 1, by combining the results of Lemmas 1-3, the regret R(T ) is bounded by\nR(T ) ≤ qmaxW W∑ i=1 2Di(log(T )T zi+γiDi + T γiDi)\n+ 2 W∑ i=1 qmax T 1− zi 2 1− zi2 + 2 W∑ i=1 LDi α 2 T 1−αγi + qmaxW π2\n3 .\n17\nThe summands contribute to the regret with leading orders O( ∑W i=1 T zi+γiDi log(T )), O( ∑W i=1 T\n1−αγi) and O( ∑W i=1 T\n1− zi2 ). In order to balance the leading orders, we select the parameters zi, γi as the following values zi :=\n2α 3α+Di ∈ (0, 1), γi := zi2α ∈ (0, 1 Di ). Then, the regret R(T ) is bounded by\nR(T ) ≤ qmaxW W∑ i=1 2Di(log(T )T 2α+Di 3α+Di + T Di 3α+Di )\n+ W∑ i=1 2qmax (2α+Di)/(3α+Di) T 2α+Di 3α+Di\n+ 2 W∑ i=1 LD α 2 i T 2α+Di 3α+Di + qmaxW π2 3 .\nSetting Dmax := maxi=1,...,W Di, the leading order of the regret is hence O ( qmaxW 2T 2α+Dmax 3α+Dmax log(T ) ) ."
    }, {
      "heading" : "APPENDIX B PROOF OF COROLLARY 1",
      "text" : "Proof of Corollary 1: This follows directly from the proofs of Lemmas 1-3 and Theorem 1. With probability (1− β), a task t has mt ≥ Wt, in which case the MCSP enters a select-all-workers phase, which does not contribute to the regret by Lemma 1. With probability β, a task t has mt < Wt, in which the MCSP either enters an exploration or exploitation phase. Hence, the regret for exploration or exploitation phases is scaled by β. This concludes the proof."
    }, {
      "heading" : "APPENDIX C PROOF OF COROLLARY 2",
      "text" : "Proof of Corollary 2: This follows directly from the proof of Lemma 2 and the proof of Theorem 1. A quality assessment is only requested if a worker is selected for exploration purposes. From the proof of Lemma 2, the number of times, a worker can at most be selected for exploration purposes is upper bounded by 2Di(log(T )T zi+γiDi + T γiDi). Setting the parameters zi, γi as in the proof of Theorem 1 concludes the proof."
    }, {
      "heading" : "APPENDIX D",
      "text" : ""
    }, {
      "heading" : "A BOUND ON DIVERGENT SERIES",
      "text" : "For p > 0, p 6= 1, the following formula holds: T∑ t=1 1 tp ≤ 1 + T 1−p − 1 1− p\nProof: See [35]."
    } ],
    "references" : [ {
      "title" : "Exploiting mobile crowdsourcing for pervasive cloud services: challenges and solutions",
      "author" : [ "J. Ren", "Y. Zhang", "K. Zhang", "X. Shen" ],
      "venue" : "IEEE Communications Magazine, vol. 53, no. 3, pp. 98–105, Mar. 2015.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Spatial crowdsourcing: current state and future directions",
      "author" : [ "Y. Zhao", "Q. Han" ],
      "venue" : "IEEE Communications Magazine, vol. 54, no. 7, pp. 102– 107, Jul. 2016.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Next steps for citizen science",
      "author" : [ "R. Bonney", "J.L. Shirk", "T.B. Phillips", "A. Wiggins", "H.L. Ballard", "A.J. Miller-Rushing", "J.K. Parrish" ],
      "venue" : "Science, vol. 343, no. 6178, pp. 1436–1437, Mar. 2014.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Geocrowd: Enabling query answering with spatial crowdsourcing",
      "author" : [ "L. Kazemi", "C. Shahabi" ],
      "venue" : "Proc. 20th ACM International Conference on Advances in Geographic Information Systems (SIGSPATIAL), 2012, pp. 189–198.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Personalized task recommendation in crowdsourcing information systems current state of the art",
      "author" : [ "D. Geiger", "M. Schader" ],
      "venue" : "Decision Support Systems, vol. 65, pp. 3 – 16, Sep. 2014.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Task search in a human computation market",
      "author" : [ "L.B. Chilton", "J.J. Horton", "R.C. Miller", "S. Azenkot" ],
      "venue" : "Proc. ACM SIGKDD Workshop on Human Computation (HCOMP), 2010, pp. 1–9.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Crowdsourcing systems on the world-wide web",
      "author" : [ "A. Doan", "R. Ramakrishnan", "A.Y. Halevy" ],
      "venue" : "Commun. ACM, vol. 54, no. 4, pp. 86–96, Apr. 2011.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Dynamic assessments, matching and allocation of tasks",
      "author" : [ "K. Ahuja", "M. van der Schaar" ],
      "venue" : "arXiv preprint, arXiv: 1602.02439, 2016.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "An online learning approach to improving the quality of crowd-sourcing",
      "author" : [ "Y. Liu", "M. Liu" ],
      "venue" : "IEEE/ACM Transactions on Networking, vol. PP, no. 99, pp. 1–14, 2017.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Online decision making in crowdsourcing markets: Theoretical challenges",
      "author" : [ "A. Slivkins", "J.W. Vaughan" ],
      "venue" : "SIGecom Exch., vol. 12, no. 2, pp. 4–23, Dec. 2013.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Online task assignment in crowdsourcing markets",
      "author" : [ "C.-J. Ho", "J.W. Vaughan" ],
      "venue" : "Proc. 26th AAAI Conference on Artificial Intelligence, 2012, pp. 45–51.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Efficient crowdsourcing of unknown experts using bounded multi-armed bandits",
      "author" : [ "L. Tran-Thanh", "S. Stein", "A. Rogers", "N.R. Jennings" ],
      "venue" : "Artificial Intelligence, vol. 214, pp. 89 – 111, Sep. 2014.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Real-time recommendation algorithms for crowdsourcing systems",
      "author" : [ "M. Safran", "D. Che" ],
      "venue" : "Applied Computing and Informatics, vol. 13, no. 1, pp. 47 – 56, Jan. 2017.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Towards task recommendation in micro-task markets",
      "author" : [ "V. Ambati", "S. Vogel", "J. Carbonell" ],
      "venue" : "Proc. 11th AAAI Conference on Human Computation, 2011, pp. 80–83.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Optimal task recommendation for mobile crowdsourcing with privacy control",
      "author" : [ "Y. Gong", "L. Wei", "Y. Guo", "C. Zhang", "Y. Fang" ],
      "venue" : "IEEE Internet of Things Journal, vol. 3, no. 5, pp. 745–756, Oct. 2016.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Taming the uncertainty: Budget limited robust crowdsensing through online learning",
      "author" : [ "K. Han", "C. Zhang", "J. Luo" ],
      "venue" : "IEEE/ACM Transactions on Networking, vol. 24, no. 3, pp. 1462–1475, Jun. 2016.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "A server-assigned spatial crowdsourcing framework",
      "author" : [ "H. To", "C. Shahabi", "L. Kazemi" ],
      "venue" : "ACM Trans. Spatial Algorithms Syst., vol. 1, no. 1, pp. 2:1–2:28, Jul. 2015.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "A multi-armed bandit approach to online spatial task assignment",
      "author" : [ "U. ul Hassan", "E. Curry" ],
      "venue" : "IEEE 11th International Conference on Ubiquitous Intelligence and Computing (UTC), 2014, pp. 212–219.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Differentially private location protection for worker datasets in spatial crowdsourcing",
      "author" : [ "H. To", "G. Ghinita", "L. Fan", "C. Shahabi" ],
      "venue" : "IEEE Transactions on Mobile Computing, vol. 16, no. 4, pp. 934–949, Apr. 2017.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Maximizing acceptance in rejection-aware spatial crowdsourcing",
      "author" : [ "L. Zheng", "L. Chen" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering, vol. PP, no. 99, pp. 1–1, 2017.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Contextual multi-armed bandits",
      "author" : [ "T. Lu", "D. Pal", "M. Pal" ],
      "venue" : "Proc. International Conference on Artificial Intelligence and Statistics (AIS- TATS), 2010, pp. 485–492.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Contextual bandits with similarity information",
      "author" : [ "A. Slivkins" ],
      "venue" : "Journal of Machine Learning Research, vol. 15, no. 1, pp. 2533–2568, Jan. 2014.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Distributed online learning via cooperative contextual bandits",
      "author" : [ "C. Tekin", "M. van der Schaar" ],
      "venue" : "IEEE Transactions on Signal Processing, vol. 63, no. 14, pp. 3700–3714, Mar. 2015.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Distributed online learning in social recommender systems",
      "author" : [ "C. Tekin", "S. Zhang", "M. van der Schaar" ],
      "venue" : "IEEE Journal of Selected Topics in Signal Processing, vol. 8, no. 4, pp. 638–652, Aug 2014.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Contextaware proactive content caching with service differentiation in wireless networks",
      "author" : [ "S. Müller", "O. Atan", "M. van der Schaar", "A. Klein" ],
      "venue" : "IEEE Transactions on Wireless Communications, vol. 16, no. 2, pp. 1024–1036, Feb. 2017.  18",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Smart caching in wireless small cell networks via contextual multi-armed bandits",
      "author" : [ "——" ],
      "venue" : "IEEE International Conference on Communications (ICC), 2016, pp. 1–7.",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "A contextual-bandit approach to personalized news article recommendation",
      "author" : [ "L. Li", "W. Chu", "J. Langford", "R.E. Schapire" ],
      "venue" : "Proc. 19th ACM International Conference on World Wide Web (WWW), 2010, pp. 661–670.",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Contextual bandits with linear payoff functions",
      "author" : [ "W. Chu", "L. Li", "L. Reyzin", "R. Schapire" ],
      "venue" : "Proc. 14th International Conference on Artificial Intelligence and Statistics (AISTATS), 2011, pp. 208 – 214.",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Regret bounds for sleeping experts and bandits",
      "author" : [ "R. Kleinberg", "A. Niculescu-Mizil", "Y. Sharma" ],
      "venue" : "Mach. Learn., vol. 80, no. 2-3, pp. 245– 272, Sep. 2010.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Finite-time analysis of the multiarmed bandit problem",
      "author" : [ "P. Auer", "N. Cesa-Bianchi", "P. Fischer" ],
      "venue" : "Mach. Learn., vol. 47, no. 2-3, pp. 235– 256, May 2002.",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Friendship and mobility: User movement in location-based social networks",
      "author" : [ "E. Cho", "S.A. Myers", "J. Leskovec" ],
      "venue" : "Proc. 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2011, pp. 1082–1090.",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Probability inequalities for sums of bounded random variables",
      "author" : [ "W. Hoeffding" ],
      "venue" : "Journal of the American Statistical Association, vol. 58, no. 301, pp. 13–30, Mar. 1963.",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 1963
    }, {
      "title" : "An approximate formula for a partial sum of the divergent p-series",
      "author" : [ "E. Chlebus" ],
      "venue" : "Applied Mathematics Letters, vol. 22, no. 5, pp. 732 – 737, May 2009.",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "More recently, mobile crowdsourcing has evolved as a powerful tool to leverage the workforce and skills of a plethora of mobile users to accomplish tasks in a distributed manner [1].",
      "startOffset" : 178,
      "endOffset" : 181
    }, {
      "referenceID" : 1,
      "context" : "Some mobile crowdsourcing tasks, subsumed under the term spatial crowdsourcing [4], are spatially constrained (e.",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 2,
      "context" : "The latter project is an example of the more general trend of citizen science [5].",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 3,
      "context" : "Two assignment modes considered in the crowdsourcing literature are the server-assigned task (SAT) mode and the worker-selected task (WST) mode (see [6] for a taxonomy).",
      "startOffset" : 149,
      "endOffset" : 152
    }, {
      "referenceID" : 4,
      "context" : ", the worker’s location or the time of day [7].",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 5,
      "context" : ", time-consuming searches within a long list of tasks are needed and workers might simply select from the first displayed tasks [8]) and secondly, workers might leave unpopular tasks unassigned.",
      "startOffset" : 128,
      "endOffset" : 131
    }, {
      "referenceID" : 4,
      "context" : "Therefore, in WST mode, the MCSP might additionally provide personalized task recommendation (TR) to workers such that workers find appropriate tasks [7].",
      "startOffset" : 150,
      "endOffset" : 153
    }, {
      "referenceID" : 6,
      "context" : "Research has put some effort in theoretically defining and classifying crowdsourcing systems, such as web-based crowdsourcing [9], mobile [1] and spatial [4] crowdsourcing.",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 0,
      "context" : "Research has put some effort in theoretically defining and classifying crowdsourcing systems, such as web-based crowdsourcing [9], mobile [1] and spatial [4] crowdsourcing.",
      "startOffset" : 138,
      "endOffset" : 141
    }, {
      "referenceID" : 1,
      "context" : "Research has put some effort in theoretically defining and classifying crowdsourcing systems, such as web-based crowdsourcing [9], mobile [1] and spatial [4] crowdsourcing.",
      "startOffset" : 154,
      "endOffset" : 157
    }, {
      "referenceID" : 7,
      "context" : ", concerning pricing and effort spent in task completion [10], represents an active research area itself, which is out of the scope of this paper.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 8,
      "context" : "A different line of work on crowdsourcing deals with quality estimation in case of missing ground truth, recently also using online learning [11].",
      "startOffset" : 141,
      "endOffset" : 145
    }, {
      "referenceID" : 9,
      "context" : "Due to the inherent dynamic nature of crowdsourcing, with tasks and/or workers typically arriving dynamically over time, task assignment is often modeled as an online decision making problem [12].",
      "startOffset" : 191,
      "endOffset" : 195
    }, {
      "referenceID" : 10,
      "context" : "For general crowdsourcing systems, [13] proposed a competitive online task assignment algorithm for maximizing the utility of a task owner on a given set of task",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 10,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 12,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 13,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 14,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 15,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 3,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 16,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 17,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 18,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 19,
      "context" : "[13] [14] [15] [16] [17] [18] [6], [19] [20] [21] [22] This work Crowdsourcing Type General General General General Mobile Mobile Spatial Spatial Spatial Spatial Loc.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 10,
      "context" : "While [13] considers sequentially arriving workers and their algorithm decides which task to assign to a worker, we consider sequentially arriving tasks and our algorithm decides which workers should be assigned to a task.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 11,
      "context" : "In [14], a bounded multi-armed bandit model for expert crowdsourcing is presented and a task assignment algorithm with sublinear regret is derived which maximizes the utility of a budget-constrained task owner under uncertainty about the skills of a finite set of workers with (known) different prices and limited working time.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 11,
      "context" : "While in [14], the average skill of a worker is learned, our algorithm additionally takes worker and task contexts into account, and thereby learns context-specific performance.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 12,
      "context" : "In [15], a realtime algorithm for finding the top-k workers for sequentially arriving tasks is presented.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 12,
      "context" : "Compared to [15], we additionally take into account worker context, learn contextspecific performance and derive guarantees on the learning speed.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 13,
      "context" : "In [16], methods for learning a worker preference model are proposed for personalized TR in WST mode.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 14,
      "context" : "In mobile crowdsourcing, [17] proposes algorithms for optimal TR in WST mode that take into account the trade-off between the privacy of worker context, the utility to recommend the best tasks and the efficiency in terms of communication and computation overhead.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 14,
      "context" : "While [17] allows to flexibly adjust the shared generalized context and makes TRs based on offline statistics and generalized worker context, our approach keeps the worker context locally and learns each worker’s individual statistics online.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 15,
      "context" : "In [18], which is focused on mobile crowdsensing, an online learning algorithm is presented to maximize the sensing revenue of a budgetconstrained task owner by learning the sensing value of workers with known prices.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 15,
      "context" : "While [18] considers a total budget and each crowdsensing task requires a minimum number of workers, we consider a separate budget per task, which translates to a maximum number of required workers.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 3,
      "context" : "A taxonomy for spatial crowdsourcing was first introduced in [6].",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 16,
      "context" : "In [19], the authors extend this framework to maximize the quality of assignments under varying worker skills for different task types.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 3,
      "context" : "However, in contrast to our work, [6] and [19] assume that worker context is centrally gathered, that workers always accept assigned tasks within certain known bounds and that worker skills are known a priori.",
      "startOffset" : 34,
      "endOffset" : 37
    }, {
      "referenceID" : 16,
      "context" : "However, in contrast to our work, [6] and [19] assume that worker context is centrally gathered, that workers always accept assigned tasks within certain known bounds and that worker skills are known a priori.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 17,
      "context" : "In [20], an online task assignment algorithm is proposed for spatial crowdsourcing with SAT mode for maximizing the expected number of accepted tasks.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 18,
      "context" : "In [21], an algorithm for privacy-preserving spatial crowdsourcing in SAT mode is proposed.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 19,
      "context" : "In [22], exact and approximation algorithms for acceptance maximization in spatial crowdsourcing with SAT mode are proposed.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 20,
      "context" : "Our proposed algorithm is based on the contextual multiarmed bandit problem [23]–[28].",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 25,
      "context" : "Our proposed algorithm is based on the contextual multiarmed bandit problem [23]–[28].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 25,
      "context" : "The closest related work is [28], in which a learner observes multiple context arrivals in each round and selects a subset of actions which maximize the expected rewards given the set of context arrivals.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 25,
      "context" : "We extended the algorithm in [28] as follows: While in [28], a central learner observes all contexts and selects actions based on these contexts, our algorithm is decoupled to several learning entities, each observing the context of one particular action and learning the rewards of this action, and a coordinating entity, which selects actions based on the learning entities’ estimates.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 25,
      "context" : "We extended the algorithm in [28] as follows: While in [28], a central learner observes all contexts and selects actions based on these contexts, our algorithm is decoupled to several learning entities, each observing the context of one particular action and learning the rewards of this action, and a coordinating entity, which selects actions based on the learning entities’ estimates.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 25,
      "context" : "Moreover, while in [28], the same number of actions is selected per round and all actions are available in any round, we allow different numbers of actions to be selected per round and we allow actions to be unavailable.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 0,
      "context" : "The task context is taken from a bounded C-dimensional task context space C := [0, 1] and captures information about the task type.",
      "startOffset" : 79,
      "endOffset" : 85
    }, {
      "referenceID" : 0,
      "context" : "In each of the C context dimensions, a task is classified via a value between [0, 1].",
      "startOffset" : 78,
      "endOffset" : 84
    }, {
      "referenceID" : 0,
      "context" : "Then, ct ∈ [0, 1]C is a vector describing task t’s overall context.",
      "startOffset" : 11,
      "endOffset" : 17
    }, {
      "referenceID" : 0,
      "context" : "Let xt,i denote the personal context of worker i ∈ Wt at the arrival time of task t, coming from a bounded Xi-dimensional personal context space Xi := [0, 1]i .",
      "startOffset" : 151,
      "endOffset" : 157
    }, {
      "referenceID" : 0,
      "context" : "We call Xi × C = [0, 1]i × [0, 1] ≡ [0, 1]i the joint (personal and task) context space of worker i.",
      "startOffset" : 17,
      "endOffset" : 23
    }, {
      "referenceID" : 0,
      "context" : "We call Xi × C = [0, 1]i × [0, 1] ≡ [0, 1]i the joint (personal and task) context space of worker i.",
      "startOffset" : 27,
      "endOffset" : 33
    }, {
      "referenceID" : 0,
      "context" : "We call Xi × C = [0, 1]i × [0, 1] ≡ [0, 1]i the joint (personal and task) context space of worker i.",
      "startOffset" : 36,
      "endOffset" : 42
    }, {
      "referenceID" : 0,
      "context" : "Here, since the decision di(xt,i, ct) is binary, it is drawn from the Bernoulli distribution with unknown parameter ri(xt,i, ct) ∈ [0, 1].",
      "startOffset" : 131,
      "endOffset" : 137
    }, {
      "referenceID" : 20,
      "context" : "Below, we propose a hierarchical contextual online learning algorithm, which is based on algorithms for the contextual multi-armed bandit problem [23]–[28].",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 25,
      "context" : "Below, we propose a hierarchical contextual online learning algorithm, which is based on algorithms for the contextual multi-armed bandit problem [23]–[28].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 0,
      "context" : "Next, LC i initializes a uniform partition QT,i of worker i’s joint context space [0, 1]i , which consists of (hT,i)i Di-dimensional hypercubes of equal size 1 hT,i × .",
      "startOffset" : 82,
      "endOffset" : 88
    }, {
      "referenceID" : 0,
      "context" : ", T} → R+ 5: Initialize context partition: Create partition QT,i of [0, 1]i into (hT,i)i hypercubes of identical size 6: Initialize counters: For all q ∈ QT,i, set Ni,q = 0 7: Initialize estimated performance: For all q ∈ QT,i, set θ̂i,q = 0 8: for each t = 1, .",
      "startOffset" : 68,
      "endOffset" : 74
    }, {
      "referenceID" : 0,
      "context" : "12 Assumption 1 (Hölder continuity assumption): There exists L > 0, α > 0 such that for all workers i ∈ W and for all joint contexts (x, c), (x̃, c̃) ∈ Xi × C ≡ [0, 1]i , it holds that",
      "startOffset" : 161,
      "endOffset" : 167
    }, {
      "referenceID" : 0,
      "context" : ",T are such that Pr(mt < Wt) = Pr(b bt e c < Wt) = β for some β ∈ [0, 1] for t = 1, .",
      "startOffset" : 66,
      "endOffset" : 72
    }, {
      "referenceID" : 26,
      "context" : "• LinUCB: This algorithm assumes that the expected performance of a worker is linear in its context [29], [30].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 27,
      "context" : "• LinUCB: This algorithm assumes that the expected performance of a worker is linear in its context [29], [30].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 17,
      "context" : "LinUCB is used in [20] for task assignment in spatial crowdsourcing.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 28,
      "context" : "• AUER: This algorithm [31] is an extension of the wellknown UCB algorithm [32] to the sleeping arm case.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 29,
      "context" : "• AUER: This algorithm [31] is an extension of the wellknown UCB algorithm [32] to the sleeping arm case.",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 29,
      "context" : "The estimated performance of a worker is computed based on the history of previous performances [32], but without taking into account context.",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 3,
      "context" : ", [6], [20], [22], we use a data set from Gowalla [33].",
      "startOffset" : 2,
      "endOffset" : 5
    }, {
      "referenceID" : 17,
      "context" : ", [6], [20], [22], we use a data set from Gowalla [33].",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 19,
      "context" : ", [6], [20], [22], we use a data set from Gowalla [33].",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 30,
      "context" : ", [6], [20], [22], we use a data set from Gowalla [33].",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 19,
      "context" : "Similar to the approach in [22], we first extract the check-ins in New York City, which leaves a subset of 138,954 checkins of 7,115 distinct users at 21,509 distinct locations.",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 0,
      "context" : "The task context is assumed to be uniformly distributed in C = [0, 1] (i.",
      "startOffset" : 63,
      "endOffset" : 69
    }, {
      "referenceID" : 0,
      "context" : "The personal context space of an available worker i is set to Xi = [0, 1] (i.",
      "startOffset" : 67,
      "endOffset" : 73
    }, {
      "referenceID" : 0,
      "context" : "The second personal context dimension refers to the worker’s battery state, which is sampled from a uniform distribution in [0, 1].",
      "startOffset" : 124,
      "endOffset" : 130
    }, {
      "referenceID" : 2,
      "context" : "In each of the subsets, the expected performance of a worker is a priori sampled uniformly at random from [0, 5].",
      "startOffset" : 106,
      "endOffset" : 112
    }, {
      "referenceID" : 0,
      "context" : "The personal context space of an available worker is again set to Xi = [0, 1] (i.",
      "startOffset" : 71,
      "endOffset" : 77
    }, {
      "referenceID" : 0,
      "context" : "14 The second personal context dimension refers again to the battery state, uniformly sampled from [0, 1].",
      "startOffset" : 99,
      "endOffset" : 105
    }, {
      "referenceID" : 2,
      "context" : "In each of the 5 ·5 · li subsets, the expected performance of a worker is a priori sampled uniformly at random from [0, 5].",
      "startOffset" : 116,
      "endOffset" : 122
    }, {
      "referenceID" : 31,
      "context" : "For i ∈ Wt, applying ChernoffHoeffding bound [34] and using |Ei,qt,i(t)| > ti log(t), we get",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 32,
      "context" : "Proof: See [35].",
      "startOffset" : 11,
      "endOffset" : 15
    } ],
    "year" : 2017,
    "abstractText" : "In mobile crowdsourcing, mobile users accomplish outsourced human intelligence tasks. Mobile crowdsourcing requires an appropriate task assignment strategy, since different workers may have different performance in terms of acceptance rate and quality. Task assignment is challenging, since a worker’s performance (i) may fluctuate, depending on both the worker’s current context and the task context, (ii) is not known a priori, but has to be learned over time. However, learning context-specific worker performance requires access to context information, which workers may not grant to a central entity. Moreover, evaluating worker performance might require costly quality assessments. In this paper, we propose a context-aware hierarchical online learning algorithm addressing the problem of performance maximization in mobile crowdsourcing. In our algorithm, a local controller (LC) in the mobile device of a worker regularly observes its worker’s context, his decisions to accept or decline tasks and the quality in completing tasks. Based on these observations, the LC regularly estimates its worker’s context-specific performance. The mobile crowdsourcing platform (MCSP) then selects workers based on performance estimates received from the LCs. This hierarchical approach enables the LCs to learn context-specific worker performance and it enables the MCSP to select suitable workers. In addition, our algorithm preserves worker context locally, and it keeps the number of required quality assessments low. We prove that our algorithm converges to the optimal task assignment strategy. Moreover, the algorithm outperforms simpler task assignment strategies in experiments based on synthetic and real data.",
    "creator" : "LaTeX with hyperref package"
  }
}