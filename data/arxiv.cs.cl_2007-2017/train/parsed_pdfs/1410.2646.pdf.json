{
  "name" : "1410.2646.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "ARABIC TEXTS", "Mohamed Bebah", "Chennoufi Amine", "Mazroui Azzeddine" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "DOI : 10.5121/ijnlc.2014.3404 53\nHybrid approaches for automatic vowelization of Arabic texts are presented in this article. The process is made up of two modules. In the first one, a morphological analysis of the text words is performed using the open source morphological Analyzer AlKhalil Morpho Sys. Outputs for each word analyzed out of context, are its different possible vowelizations. The integration of this Analyzer in our vowelization system required the addition of a lexical database containing the most frequent words in Arabic language. Using a statistical approach based on two hidden Markov models (HMM), the second module aims to eliminate the ambiguities. Indeed, for the first HMM, the unvowelized Arabic words are the observed states and the vowelized words are the hidden states. The observed states of the second HMM are identical to those of the first, but the hidden states are the lists of possible diacritics of the word without its Arabic letters. Our system uses Viterbi algorithm to select the optimal path among the solutions proposed by Al Khalil Morpho Sys. Our approach opens an important way to improve the performance of automatic vowelization of Arabic texts for other uses in automatic natural language processing.\nKEYWORDS\nArabic language, Automatic vowelization, morphological analysis, hidden Markov model, corpus"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "The Arabic writing system is characterized in most texts by the lack of diacritics: i.e., short vowels /a/ \"\"َ (fatha), /u/ \"\"ُ (damma) and /i/ \"\"ِ (kasra), in addition to signs /an/\"\"ً(tanween alfatha), /un/ \"\"ٌ (tanween al-damma ), /un/ \"\"ٍ(tanween al-kasra), consonant doubling \"\"ّ (shadda) and vowel absence \"\"ْ (sukuun). The absence of these signs generates a significant increase of the ambiguity in the Arabic text, which can cause confusion in more than 90% of the text words [1]. Despite the fact that the reader with a certain level of knowledge of Arabic language can easily recover the missing diacritics by using the context of words and its knowledge of the morphology and the syntax of the Arabic language, texts without diacritics present an obstacle for non-native learners of the Arabic language and those with learning difficulties. Similarly, the limits of performance of several applications of natural language processing for Arabic (NLPA) such as parsers and Treebank are in part a result of the absence of diacritics in Arabic texts [2,3]. Indeed, unlike European languages where it is easy to identify oral phonemes corresponding to texts (Text to Speech), it is imperative for Arabic texts to retrieve the diacritics before researching the correspondent oral phonemes [4]. On the other hand, some research has underlined the importance of using texts with diacritics to increase the efficiency of speech recognition [5].\nGiven the importance of the recovery of diacritics, several attempts have been made by research teams over the past two decades. They developed automatic vowelization algorithms for Arabic texts with an acceptable efficiency. These attempts can be divided, as most applications of NLP, in two categories: the first one concerns commercial companies that have developed automatic vowelization algorithms as an independent program or as a part of another application, such as the text to speech or spell checker. Among the most interesting projects, there is the vowelization program called ArabDiac developed by Egyptian factory RDI (Research & Development International) and those developed by SAKHR Software (Egyptian company)) and CIMOS company. The company Google has also launched three years ago Tashkeel program. It was a free automatic vowelization program for Arabic texts, but this service was discontinued for unknown reasons. Despite the importance of these attempts, their commercial and monopolistic nature, which prevents access to the source code and linguistic resources used in the development of these programs, does not allow to improve or to integrate them into other applications. The second category of these attempts is due to the efforts of researchers in projects within academic research centers. These efforts have resulted in the past two decades the emergence of many attempts in this field. The used approaches are often the statistical type based on the Markov models or the n-gram models [6,7,8,9]. However, some hybrid approaches using linguistic analysis followed by a statistical treatment are also used to develop an automatic vowelization system [4,10,11,12].\nAn automatic vowelization systems based on a hybrid approaches which combine a morphological analysis and hidden Markov models is presented in this article. These approaches differ from other hybrid approaches to linguistic and statistical levels. Indeed, at the linguistic level, the open source morphological Analyzer Alkhalil Morpho Sys is used (www.sourceforge.net/projects/alkhalil) [13]. The integration of this Analyzer in our vowelization system required the addition of a lexical database containing the most frequent words in order to adjust their diacritics and circumvent the problems of slow due to the high number of solutions proposed by the morphological Analyzer. This database has been generated from the corpora of more than 250 million words of eight Arabic corpuses available on the Internet. Our system uses the results of the morphological Analyzer and extracts possible vowelizations out of context proposed for words. Statistically, two Markov models are used. The first model uses the unvowelized Arabic words as observed states and vowelized words as hidden states, while the second model keeps the same observed states of the first Markov model, but the hidden states are the lists of possible diacritics of word without their Arabic letters. Finally, a representative corpus is used in the training phase.\nThe article is organized as follows. In Section 2, the state of art in the field of Arabic vowelization is recalled. After, the morphological Analyzer Alkhalil Morpho Sys used in the first part of our system is presented in Section 3, and the statistical approach adopted in the second part is explained. The fourth and fifth sections are devoted respectively to training and testing phases. Finally, conclusion and future prospects are given in the last section."
    }, {
      "heading" : "2. STATE OF THE ART",
      "text" : "Referring to the previous works, the approaches related to the automatic vowelization of Arabic texts can be divided into three sections: rule-based approaches, statistical approaches and hybrid approaches."
    }, {
      "heading" : "2.1. Rule-based Approaches",
      "text" : "There have been some researches aimed at programming audio, morphological, grammatical and spelling grammar rules in order to vowelize the Arabic words. Among the first studies on the subject, there is the approach mentioned in [14] that uses syntactic rules for semi-automatic vowelization of Arabic verbs. In [1], Debili, Fathi and Hadhemi Achour present a study of the automatic vowelization Arabic texts in relation to the ambiguity of written words and the impact of lexical and morphological analysis and POS tagging in detecting ambiguities and hence the vowelization of words of Arabic texts.\nBut given the high level of ambiguity, the large number of morphological and syntactic rules, the unavailability of an efficient parser and the need of a semantic analysis in some cases, it is difficult to develop an automatic vowelization system based solely on grammar rules and this explains the absence of such an efficient system."
    }, {
      "heading" : "2.2. Statistical Approaches",
      "text" : "Given the great feat achieved by the statistical approaches in various fields of natural language processing such as automatic speech recognition, machine translation and information retrieval [15], the majority of works in the field of automatic vowelization of Arabic texts have adopted these approaches. The used methods are quite varied. Indeed, some researchers have developed statistical methods based on research of diacritic marks on the character level. Others have exploited these methods to identify the diacritic marks on the word level. Finally, a third group of researchers have developed hybrid methods coupling the two approaches.\nIndeed, Emam and Fischer [7] had filed a patent for an automatic vowelization system for Arabic texts based on the example-based machine translation. In order to select the most probable sentence vowelization, the approach consists first of searching in a database some examples of the sentence, then the parts of the sentence and finally the isolated words of the sentence. In addition, they apply statistical methods (n-gram model) at characters level for words that do not appear in the database. Not far from this idea, there is in [8] an approach based on the statistical machine translation technology based on parallel corpus composed of vowelized texts and their unvowelized counterparts. Also, Gal [9] has presented a Markovian approach to vowelize the Arabic and Hebrew texts. The author has used in this work the Holy Quran texts in the Arabic language and the Bible texts in the Hebrew language. In this work, the unvowelized words and the vowelized words represent, respectively the observation and the hidden states of the model. However, the Arabic vowelization in this work is limited to short vowels.\nFor automatic vowelization by the Markovian approaches, there are works of Deltour [16] and Elshafei, Al-Muhtaseb, and Alghamdi [6]. In [16], the researcher reviewed some statistical methods of automatic vowelization on the level of characters and words, and concluded that the best results are obtained when she has used the hidden Markov models. Similarly, the researchers have presented in [6] a Markovian approach distinct from those of work of Gal [9] since it concerns all diacritical marks, and the training and evaluation processes were realized by using a variety of texts and not only the Quranic texts.\nIn [17], the authors have presented an Arabic diacritizer developed at King Abdel Aziz City for Science and Technology (KACST). This system is based on a quad-grams applied at the character level."
    }, {
      "heading" : "2.3. Hybrid Approaches",
      "text" : "Hybrid methods are algorithms that combine linguistic rules and statistical processes to exploit the strengths of both approaches. From important work in this field, there is the diacritizer ArabDiac developed by RDI [18]. This system uses the morphological Analyzer ArabMorpho and the POS tagger ArabTagger in a probabilistic framework where the choice of the best vowelization is performed using the A* search algorithm.\nThe authors Nelken and Shieber [10] have proposed a method for automatic vowelization based on finite state automata. This method combines statistical tri-gram models at the word level, quad-gram models at the character level and a slight morphological Analyzer that recognizes the prefixes and suffixes of words.\nZitouni, Sorensen, and Sarikaya [3] presented a vowelizer system using statistical classifier based on maximum entropy. Morpho-syntactic information is used to select the best classification.\nIn [4], diacritics of Arabic words are restored by combining a morphological analysis and contextual information with an acoustic model. Automatic vowelization in this work is seen as an unsupervised tagging problem where each word is tagged as one of the possible solutions provided by the Buckwalter Analyzer [19]. The maximum expectation algorithm was used in this work to perform the learning section.\nIn [11], there is a similar approach to that presented by Vergyri and Kirchhoff [4] in the sense that the vowelization problem was seen as a problem of choosing the best solution among those proposed by the Buckwalter Analyzer.\nWe have already presented in [12] a vowelization system for Arabic sentences based on a morpho-statistical approach. The Analyzer Alkhalil Morho Sys was used to identify the various possible vowelized patterns of words analyzed out of context. Then, the statistical treatment removes ambiguity by considering these patterns as hidden states of a hidden Markov model. It remains to note that this approach shares with the approach presented in this research the utilization of the Analyzer Alkhalil Morpho Sys in the first step. However, the Alkhalil version used in this research was modified by adding a lexicon of the most frequent Arabic words. In addition, the hidden states for each approach and the used corpus in the learning and testing phases are different."
    }, {
      "heading" : "3. PRESENTATION OF THE SYSTEM",
      "text" : "This section give a detailed presentation of the developed system. The process of automatic vowelization of Arabic texts will be done in two main phases, as shown in Figure 1."
    }, {
      "heading" : "3.1. First Phase: Morphological Analysis",
      "text" : "Morphological analysis is performed using the open source Analyzer Alkhalil Morpho Sys. It provides all possible vowelizations for each word of the text taken out of context. To further clarify this point, a brief overview of the Analyzer and its mode of operation are given at the beginning, and then the detail of the lexical database that is integrated in the Analyzer databases is presented. To evaluate the contribution of the added lexical database, the performances of the system with and without the lexicon are tested and the results will be presented in the section related to tests bellow."
    }, {
      "heading" : "3.1.1. Overview of Alkhalil Morhp Sys",
      "text" : "The morphological Analyzer Alkhalil Morpho Sys is considered one of the most important open source Analyzers [13]. It was conducted as part of a partnership project between the Mohammed First University Oujda Morocco (UMP), the Arab League Educational, Cultural and Scientific Organization (ALECSO) and the King Abdulaziz City for Science and Technology (KACST). For a given word, Alkhalil Morpho Sys identifies all possible solutions associated with their morpho-syntactic features as defined below:\n• Possible vowelizations of the word. • Possible proclitics and enclitics. • Nature of the word (noun or verb or tool word). • Vowelized patterns (for derivable words). • Stems. • Roots (for derivable words). • Part of speech (for nouns and verbs).\nThe main steps of the morphological analysis for each word with Alkhalil Morpho Sys can be summarized as follows:\n1. First step: it aims to identify potential prefixes and suffixes of the word by making all possible\nsegmentations and checking if the first and the last segments of the segmentation belong respectively to databases of prefixes and suffixes. Due to the inflectional nature of the Arabic, this process often leads to more than one segmentation. 2. Second step: after removing the prefix and suffix associated with each valid segmentation of\nthe first step, the remaining segment (stem) will be analyzed as a proper noun. To do this, the program uses a list of 6,000 proper nouns.\n3. Third step: the program checks after if the stem belongs to the tool word list. 4. Fourth step: the program checks if the stem is a derived noun. This check will be done\naccording to the following steps:\n• Identify possible patterns of the stem and compare them with those of the nominal patterns database. • Extract the possible roots of the stem and ascertain their presence in the roots database of the Arabic language. • Check the compatibility of each root with the pattern by referring to the database of roots accompanied by patterns of names derived from this root.\n5. Step Five: The program checks if the stem is a verb. This check will be using the same steps as\nfor the names.\nThese are briefly the most important steps of morphological analysis in the official version of Alkhalil Morpho Sys available on the website sourceforge. However, the integration of the Analyzer Alkhalil Morpho Sys in the automatic vowelization system obliged us to make adjustments that consist primarily of adding a database in the form of a dictionary of the Arabic words most commonly in the available Arab corpuses. Similarly, the mechanism of the morphological analysis outputs are modified, keeping only the possible vowelizations of words and ignoring the other information such as pattern, root, etc... In what follows, the detail of this dictionary is presented."
    }, {
      "heading" : "3.1.2. Dictionary of the Most Frequent Words",
      "text" : "This dictionary has been built on the one hand to accelerate the process of morphological analysis and on the other hand to adjust the quality of vowelization of the most frequent words belonging to the various texts. To do this, the steps bellows are followed:\n• Gather a large Arabic corpus of more than 250 million words drawn from eight Arab corpuses available on the Internet. The corpuses are as follows:\n- The corpus of the researcher Ahmed Abdelali (http://aracorpus.e3rab.com/ argistestsrv.nmsu.edu/AraCorpus/Data/) which contains over 147 million unvowelized\nwords. This corpus was constituted from a variety of media texts collected from 28 journalistic websites covering most Arab countries. - The corpus (Tashkeela) (http://sourceforge.net/projects/tashkeela/) which contains over 60 million of vowelized words and is composed of classical Arabic texts collected by the\nresearcher T. Zerouki from library books (Achamila).\n- The open source Arabic corpora (OSAC) (https://sites.google.com/site/motazsite/Home/ osac) collected by researchers W. Moataz K. Saad and Ouissam Ashour in order to use it\nin applications of text mining. This corpus contains about 20 million unvowelized words gathered from local and international Arabic news websites.\n- The corpus of L. Sulaiti (http://www.comp.leeds.ac.uk/eric/latifa/research.htm) composed of unvowelized contemporary texts covering several areas (political, economic,\nreligious, sports, etc.). This corpus contains over half a million words.\n- The corpus (Khaleej-2004) (http://sourceforge.net/projects/arabiccorpus/files/) collected by researchers M. Abbas and K. Smaili from newspaper (Akhbar Al Khaleej), Bahrain.\nThis corpus, which contains about 2.8 million words, has been used in applications of automatic classification of documents [20]. - The UN Parallel Corpora (http://www.uncorpora.org/) which consists of 2,100 resolutions adopted by the General Assembly of the United Nations and written in the\nsix official languages of the United Nations. Only the Arabic content of this resolutions containing about 2.5 million words has been processed. This corpus was originally collected for use in applications such as machine translation [21]. - The corpus of the RDI (http://www.rdi-eg.com/RDI/TrainingData/) society is composed of vowelized texts gathered mainly from classical Arabic books and a small percentage\nof contemporary writing. This corpus was collected in order to use in the field of automatic vowelization. It contains 20 million words. - The ArabicWritten Corpus NEMLAR (Network for Euro-Mediterranean LAnguage Resources) (http://catalog.elra.info/product_info.php?products_id=873) was carried out\nby several researchers in the NEMLAR project [22]. It is a vowelized corpus, with morpho-syntactically tagging and marketed by European Language Resources Association (ELRA). It contains texts from various fields and consists of approximately half a million words.\n• After the collection phase, the encoding and storing methods of different files are standardized using CP1256 code and \".txt\" extension for backup files. These files are cleaned\nby removing the symbols and words written in non Arabic letters.\n• For each corpus, the occurrence frequencies of all words are calculated and ordered in decreasing order. In this step, each corpus is analyzed separately because of size differences\nbetween the corpuses, and the fact that frequent words vary according to the nature of the corpus. Indeed, words such as (told us) \" / HdvnA\", (he said) \"ل /qAl \" and (he prayed) \" / SlY \", which are very common in classical Arabic texts, are almost non-existent in the resolutions of the General Assembly of the United Nations. • The next step consists to develop the first list of dictionary entries of the most frequent words. We have integrated the list of words related to each corpus and we have eliminated the\ndiacritics that appear in some of them. Finally, a single word is stored in the case of words belonging to more than one list. The size of this dictionary has reached 16,200 words. • Then, diacritics corresponding to dictionary entries are identified. For this, the entries are divided into two groups:\n- The first group consists of the words from the vowelized corpus (Tashkeela, NEMLAR and RDI). Every word of this group is accompanied by different lists of possible\ndiacritics.\n- The second group consists of the remaining 1,200 words. Because this group contains many foreign words in Arabic language commonly used in contemporary texts and\nforeign proper names, these words are analyzed using the Aramorph Analyzer [19].This step is completed by performing a manual correction of the outputs of this analysis.\nAfter making these steps, a dictionary of 16,200 most frequent words is obtained in the available corpuses. Each word of this dictionary is accompanied by a list of its different possible vowelizations. This lexicon is integrated in the process of morphological analysis program Alkhalil Morpho Sys. This has allowed immediately recognize possible vowelizations of the words belonging to this dictionary and this has led to faster processing.\n3.1.3. Unanalyzed Words\nDuring the morphological analysis step, some Arabic words are not analyzed due to incomplete coverage of the Alkhalil Analyzer databases. Indeed, for the authentic version of Alkhalil (version without the lexical basis of the most frequent words), the percentage of unanalyzed words is equal to 5.92%, while for the version including the dictionary of the most common words this percentage decreases to 2.74%."
    }, {
      "heading" : "3.2. Statistical Analysis",
      "text" : "After the program has conducted a morphological analysis of text words, allowing to have the potential vowelizations for each word, the second step of the vowelization process is initiated. It consists of a statistical treatment based on the hidden Markov model and the Viterbi algorithm, and allows obtaining the most likely vowelization of words in the sentence. In what follows, the mechanisms of this model are recalled in detail. Let O={o1,...,oM} be a finite set of observations and let S = {s1, ..., sN} be a finite set of hidden states.\nDefinition 1\nA first-order HMM is a double process (Xt,Yt)t≥1 where:\n• (Xt)t≥1 is a homogeneous Markov chain with values in the hidden states set S where:\nijitjthitjt asXsXsXsXsX ======= ++ )Pr(), . . . ,Pr( 111 (1)\naij is the transition probability from state si to state sj and the matrix A = (aij) is called transition matrix.\n• (Yt)t≥1 is an observable process taking values in the observation set O where:\n)()Pr(),, . . . ,,,Pr( 1111 1111 kbsXoYsXoYsXoYsXoY iitktikitktitkt tt ========== −− −−\n(2)\nbi(k) is the probability of observing ok given the state si and the matrix B = (bi(t)) is called transmission matrix."
    }, {
      "heading" : "3.2.1. First Model",
      "text" : "In this model, the observations are unvowelized words of the sentence, and the hidden states are the vowelized words as in previous studies [1,10]. For example, the unvowelized word \" د/dxl\" is the observed state and the hidden state is one of the possible vowelized words such as (he came) \" ََدَ / daxala \" or (income) \"ٌْدَ/daxolN\" given in the morphological analysis step (see Figure 3 below)."
    }, {
      "heading" : "3.2.2. Second Model",
      "text" : "The observations of this model are identical to those of the first model (unvowelized words), but the hidden states are the lists of possible diacritics in Arabic. So, they are vectors which have the same sizes as the observations (see Figure 4 below). To illustrate this definition, some examples of hidden states are given :\nExample 1:\n\",ُ ,ِ ,ْ \"َ: is the succession of short vowels (fatha), (Sukuun), (kasra) and (damma). It represents a potential hidden state of several observations related to words of four characters such as \"ف / tErf\", \" / nSbr\" and \" ض / yErD\". After applying these signs to these words, we get (she\nknows) \"فَُِْ / taEorifu\", (we are patient) \"َُِْ/ naSobiru\" and (he displays) \"ضَُِْ / yaEoriDu\" .\nExample 2: \",ٌ ,َ , ,َ \"ُ : is the succession of five short vowels (damma), (fatha), (shadda) with (kasra), (fatha) and (tanween al-damma). To this list correspond several observations such as \"!\" # / mElmp\" and \" !# $# / mqdmp\" and it allows us to have the following vowelized words (teacher) \"!ٌ\"َ َ#ُ / muEal~imapN\" and (introduction) \"!ٌ#َ $َ#ُ / muqad~imapN\".\nExample 3:\n\",َ #, \"َ: is the succession of short vowel (fatha), the sign \"#\" and (fatha). The sign \"#\" represents the lack of diacritic sign on the corresponding character. This list allows to vowelize words such as \"ع & / bAE\", \"ء ( / jA' \" and \"ز * / fAz\" and so the following vowelized words are obtained : (he sold) \"عَ &َ / baAEa\", (he came) \"ءَ (َ /jaA'a\" and (he won) \"زَ *َ / faAza\". It is obvious that the abstract nature of the hidden states of this model requires fewer parameters compared to first model which use the vowelized words as hidden states."
    }, {
      "heading" : "3.2.3. Viterbi Algorithm",
      "text" : "In what follows, there is an explanation of the use of these models to vowelize Arabic texts. Suppose, for example, that there is an Arabic sentence W=(w1, w2, ..., wn) consisting of n words wi. The series of observation is a set of unvowelized words w1, w2, ..., wn. Let C = {c1, c2, ..., cN} be the set of the hidden states (vowelized words for the first model and possible lists of Arabic diacritic signs for the second model). Based on these assumptions, determining the correct vowelization at this level of analysis is to find a sequence of hidden states (c1 * , c2 * , …, cn * ) in C which satisfies:\n).. . . . . . Pr(maxarg) ., . . ,( 11\n. . .\n** 1\n1\nnn Ccc\nn wwcccc\nn∈\n=\n(3)\nSince\n) . . . Pr(\n) . . . Pr() . . . . . . Pr( ). . . . . . Pr(\n1\n111 11\nn\nnnn nn\nww\nccccww wwcc =\n(4)\nThe sequence (c1 * , c2 * , …, cn * ) verifies:\n) . . . Pr() . . . . . . Pr(maxarg) ., . . ,( 111 ** 1 nnnn ccccwwcc = (5)\nThe equation (5) can be written as follows:\n) . . . Pr() . . . . . . Pr(maxarg) ., . . ,( 11 111\n1\n** 1 nn\ni ij i\nj n jj n j n\nni Cc\nn ccccwwcc\n≤≤ ∈\n=\n(6)\nWhere { }iniii ccC ,...,1= is for a first model (respectively second model) a set of the possible vowelized words (respectively the lists of diacritic signs of the possible vowelized words) obtained by morphological analysis of the words wi. The equation (6) will be solved by seeking the most likely path in the network solutions obtained by morphological analysis of words out of context:\nW=(w1, w2, …, wn)\nThe Viterbi algorithm [23] identifies the optimal path in the network. It is based on the values of\nthe functionφ defined by:\n[\n]),, . . . ,Pr(\n),, . . . ,,, . . . ,Pr(max),(\n11\n11\n11\n11\n1111\nk t k t k\nk t k t k\ntt r\nk t\nccc\ncccwwwct\nt\nt\nti i\nij i\n−\n−\n−≤≤\n−\n−− ℜ∈\n×\n=φ (7)\nWhere ),( k tctφ represents the probability of the partial path which passes through the list k tc\n( k\ntc belongs in the set of possible vowelizations of the word wk). The equation (7) can be written\nas follows:\n[ ]\n)Pr()Pr(),1(max\n)Pr()Pr(),1(max\n)Pr()Pr()Pr()Pr(max),(\n)(\n)(\n11\n11\n1\n1\n1\n1\n11\n11\n1 1 1\n11\n11\nk tt\nj\nt\nk t j\nt Cc\nk tt j t k t j\nt Cc\nj\nt\nk t k tt\nt\ni\nj\ni\nj\ni\nj\nii r\nk t\ncwccct\ncwccct\ncccwcccwct\nt j t\ntt\nt tj t\ntiii\nti i\nij i\n−− ∈\n−− ∈\n−\n−\n=\n− ℜ∈\n×−=\n×−=\n×××=\n−−\n−−\n− − −\n−−\n−≤≤\n∏\nφ\nφ\nφ\n(8)\nThe last formula (8) allows us to calculate the value of φ by induction. To identify the optimal\npath, the function ψ is defined. It allows at any time t to store the vowelization which generates the largest value for the equation (8) above.\nThe function ψ is defined by:\n)Pr(),1(maxarg),( 11 11\nj\nt\nk t j\nt Cc\nk\nt ccctct t j t −− ∈ −= −− φψ (9)\nWith the remark that ),( 1−∈ t k t Cctψ . The relations (8) and (9) allow us to find the optimal path using the following decreasing Viterbi algorithm:\nStep 1 (initialization):\nFor 1 ≤ k ≤ n1 , calculate ),( 1 kctψ the probability that the sentence begins with w1 accompanied by a hidden state 1 kc .\nStep 2 (recursive computation):\nFor 2 ≤ t ≤ n et 1 ≤ k ≤ nt, calculate ),( k\ntctφ and ),( k tctψ from the following formulas:\n)Pr()Pr(),1(max),( )( 11 11 k tt\nj\nt\nk t j\nt Cc\nk\nt cwccctct t j t −− ∈ ×−= −− φφ\n)Pr(),1(maxarg),( 11 11\nj\nt\nk t j\nt Cc\nk\nt ccctct t j t −− ∈ −= −− φψ\nStep 3 (final state):\n),(maxarg)1( jn Cc cnn n j n φψ ∈ =+\nStep 4 (deduction of the optimal path):\n)1(* += ncn ψ For t = n-1 :1"
    }, {
      "heading" : "4. TRAINING PHASE",
      "text" : "The parameters of the statistical model defined above A=(aij)ij and B=(bi(t))it will be estimated during the training phase from representative linguistic corpora. Thus, if C ={Ph1, …, Phk} is an Arabic corpus formed by M sentences Phk, then the training phase consists of estimating the parameters of the matrices A and B by the maximum likelihood method [15]. Indeed, if we put\n• kin = the number of occurrences of the hidden state ci in the sentence Phk, • kijn = the transition number from the state ci to the state cj in the sentence Phk,\n• kitm = the number of times that the unvowelized word wt correspond to the hidden state\nci in the sentence Phk,\nThe coefficients aij and bi(t) can be estimate by:\n1\n1\n∑\n∑\n=\n== M\nk\nk i\nM\nk\nk ij\nij\nn\nn a (10)\n)( 1\n∑\n∑\n=\n== M\nk\nk i\nM\nk\nk it\ni\nn\nm tb (11)\nDuring the statistical phase, the unanalyzed words by Alkhalil are labelled by the label \"unkown\". Before proceeding to the Viterbi algorithm, an initial probability is assigned equal to 10 -5 for all probabilities of the transition and transmission matrices relating to the state \"unknown\". This technical trick bypasses the problem of transition between unanalyzed words and the other words of the sentence. These unanalyzed words will not be vowelized by this statistical step of our system. So, for each unanalyzed word, another hidden Markov model is used which the observed states are the word letters and the hidden states are the diacritic signs. The training phase was carried out with 90% of a corpus consisting of 2,463,351 vowelized words divided between NEMLAR corpus (460,000 words), (Tashkeela) corpus (780,000 words) and\nRDI corpus (1,223,351 words). The remaining 10% will be used in the test phase. The reason for non-use of million vowelized words available in the literature of classical Arabic is the desire to use a balanced corpus between contemporary texts and texts of classical Arabic. Thus, in parallel with contemporary texts of NEMLAR corpus and 13 books of RDI corpus, we selected 30 books of classical Arabic of (Tashkeela) corpus and 4 classic books from the RDI corpus, and then a random 10% of each book is picked. Finally, operations are used which consist in segmenting texts into sentences, classifying the words of these sentences and deducing the corresponding vowelized words necessary to estimate model parameters.\nFor unanalyzed words in morphological step, a model based on the characters is used. Each word will be fragmented into characters and diacritics. Transitions are between the letters without diacritics and emissions are calculated from the observed states (characters) and the hidden states (diacritics). The hidden Markov model was generated by learning 90% on the same corpus of 2.46 million words.\n5.TEST PHASE\nThe characteristics of the used equipment are a PC with 2 CPU Intel (R) Pentium (R) 1.9 GHz and RAM with 3Gigats bytes. The used environment is the operating system Windows 7. The application has been extended to 1,024 Megabytes memory. To evaluate the performance of our system, the error rate at the word level WER (WER: Word Error Rate) and the error rate at the character level DER (DER: Diacritic Error Rate) are calculated. For each of these two types of errors, we compute both the error rate which takes into account the diacritic sign of the last character and the one that ignores this sign. Thus, the 4 following error rates are calculated:\n• WER1: calculates the rate of words which are vowelized wrongly by the program taking into account the diacritic sign of the last character. • WER2: calculates the rate of words which are vowelized wrongly by the program while ignoring the diacritic sign of the last character. • DER1: calculates the rate of characters which are vowelized wrongly by the program taking into account the diacritic sign of the last character. • DER2: calculates the rate of characters which are vowelized wrongly by the program while ignoring the diacritic sign of the last character.\nThe test was focused on the test corpus composed of 199,197 words and completely independent of the learning corpus.\nIt is recalled that the original version of the morphological Analyzer Alkhalil Morpho Sys is modified by including the dictionary of the most frequent words. To evaluate the contribution of this change, our vowelization system is tested at the first using the original version of Alkhalil Morpho Sys in the morphological analysis phase, and thereafter one that uses the modified version of Alkhalil Morpho Sys."
    }, {
      "heading" : "5.1. Evaluation without the Dictionary of the Most Frequent Words",
      "text" : "The Table 1 below shows the evaluation results of our vowelization system which use in the first phase (morphological analysis phase) the original version of the Analyzer Alkhalil Morpho Sys. The second line of Table 1 indicates the execution time and the four error rates of the first model in which the hidden states are vowelized words. The third line of Table 1 is devoted to the execution time and the four error rates of the second model in which the hidden states are the lists of possible diacritic signs of Arabic.\nThese results show that the system performance obtained with the second model are better than those relating to the first model. The first system is faster than the second (90.34 words are vowelized per second for the first model against 86.56 words per second for the second). This can be explained by the fact that the transmission matrix B is probabilistic (all values of B are equal to 1 or 0).\nHowever, the error rate at the word level (WER1) is around 30.88% for the first model and 28.31% for the second model. This error rate decreases by almost half if the diacritic of the last character is ignored (WER2). The error rate DER1 relating to all characters of the text is about 11% and decreases, as in the case of words, by almost half in the case where the diacritic sign of the last character is omitted."
    }, {
      "heading" : "5.2 Evaluation with the Dictionary of the Most Frequent Words",
      "text" : "Table 2 below shows the evaluation results of our vowelization system using in the first phase the modified version of Alkhalil Morpho Sys which include the dictionary of the most frequent words. As in Table 1, the second line of Table 2 shows the execution time and the four error rates of the first model in which the hidden states are vowelized words. The third line of Table 2 is devoted to the execution time and the four error rates of the second model in which the hidden states are the lists of possible diacritic signs of Arabic.\nUnlike the previous paragraph, the results obtained with the first model are better than those relating to the second model. The error rate at the word level (WER1) is around 21% (21.10% for the first model and 21.41% for the second model), and it decreases by more than half if the diacritic of the last character is ignored (WER2).\nThe error rate DER1 relating to all characters of the text is about 7% and decreases, as in the case of words, by almost half in the case where the diacritic sign of the last character is omitted. The use of the dictionary of the most frequent words makes on the one hand the system faster (the first model of this system vowelized 109.63 words per second against 90.34 words per second for\nthe system without the dictionary). On the other hand, it has allowed to significantly improving system performance. Indeed, the error rates WER1, WER2, DER1 and DER2 relating the use the original version of Alkhalil Morpho Sys in the system, and which are respectively equal to 30.88%, 16.91%, 11.38% and 6.01%, decreased to 21,11%, 9.93%, 7.37% and 3.75 respectively, after having inserted into Alkhalil Morpho Sys the dictionary of the most frequent words."
    }, {
      "heading" : "5.3. Comparison of results",
      "text" : "To compare our results with those of other systems in the literature, Table 3 shows the different error rates. However, as these systems have not been tested on the same corpus, it should take the conclusions with some caution."
    }, {
      "heading" : "5.4. Synthesis",
      "text" : "It emerges from these evaluations the following conclusions:\n• The integration of the dictionary of the most frequent words in Alkhalil Analyzer has allowed to make more efficient the vowelization systems. Indeed, the error rate WER1 decreased by\n31% for model 1 (it decreased from 30.88 to 21.11) and 25% for model 2 (it decreased from 28.31 to 21.41). Similarly, the error rate WER2 was decreased by 41% for model 1 (it decreased from 16.91 to 9.92) and 42% for model 2 (it decreased from 10.59 to 6.1). • It also makes the system faster. Indeed, the system using the original version of Alkhalil Morpho Sys vowelized 90.34 words per second for the first model and 86.65 words per second\nfor the second model, when that using the dictionary vowelized 109.63 words per second for the first model and 105.34 words per second for the second model. • When Alkhalil analyzer is used without the dictionary of the most frequent words, the error rates obtained with model 1 are slightly less good than those of model 2 (see Table 1). The\ntrend is reversed after integrating this dictionary in Alkhalil Analyzer (see Table 2).\n• The first vowelization model is faster than the second independently of integration or not of the dictionary of the most frequent words in the morphological step (without the dictionary,\nthe first model analysis 109 words per second against 90 for the second, and with the dictionary, the first model analysis 105 words per second against 86 for the second). This goes against our expectations. Indeed, the sizes of the transition and transmission matrices of the second model (size(A) = 21,267 x 21,267 and size(B) = 21,267 x 145,469) are much smaller than that of the first model (size(A) = 224,414 x 224,414 and size(B) = 224,414 x 145,469). So it was natural to expect that the second model will be the fastest. This unexpected finding may be explained by the probabilistic nature of the transmission matrix B of the first model (the coefficients of the matrix B are all equal to 1 or 0). • The error rate WER1decreases by almost half if the diacritic of the last character is ignored (error rate WER2). So, almost half of the errors are syntactic errors. • It is recalled that for computing the error rates WER1 and WER2, a word is considered correctly vowelized by our system if there is total agreement between the vowels given by the\nvowelization system and those in the corpus. As the corpus is marred by several errors\n(including spelling errors), a negative impact is generated both in the learning phase (to estimate the matrices A and B) and in the test phase. This partly explains the obtained values for WER1 and WER2. • To analyze the performance of each of the two steps of our system (the morphological analysis step and the statistical step), the error share for each of these two steps will be identified. It\nshould be noted that the vowelization error of a word is due to the one of the following three reasons: – Alkhalil Analyzer does not analyze the word. – Alkhalil Analyzer analyzes the word but the right solution (the solution in the context) is not included in the analysis outputs. – Viterbi algorithm does not identify the right solution even if it is one of the outputs provided by Alkhalil Analyzer.\nTable 4 shows the distribution of the error rate at the word level WER1 according to each of these reasons when the original version of Alkhalil Morpho Sys is used in the morphological step.\nIt is clear from these statistics that between 40% and 45% vowelization errors (depending on model) are due to the analysis morphological step and the rest is a consequence of the statistical step. Distributions for the other kinds of errors (WER2, DER1 and DER2) look like those shown in Table 4."
    }, {
      "heading" : "6. CONCLUSION AND OUTLOOK",
      "text" : "Automatic vowelization systems based on hybrid approaches that combine morphological analysis and hidden Markov models are presented in this article. These approaches differ from other hybrid approaches to linguistic and statistical levels. At the linguistic level, Alkhalil Morpho Sys which is an open source morphological Analyzer is used. Our system uses the outputs of this Analyzer and extracts possible vowelizations out of context for each word. The integration of this Analyzer in our vowelization system required the addition of a lexical database containing the most frequent words in Arabic language. This has allowed to adjust their diacritic signs and to circumvent problems of slow due to the high number of solutions proposed by Alkhalil Analyzer. This lexicon has been generated from a database of more than 250 million words from eight Arab corpuses available on the Internet.\nStatistically, two Markov models are used whose observations are unvowelized Arabic words and the hidden states are for the first model the vowelized words and for the second the lists of diacritic marks of the words. Similarly, in the training phase, a varied corpus was used containing classical and contemporary Arabic texts and whose size exceeds 2.46 million words. Finally, the evaluation results obtained are very encouraging, especially for the system incorporating the lexical database. Our system can be improved by acting on the following complementary levels:\n• Improve the performance of Alkhalil system so that these outputs will be more accurate and its coverage broader (reduce the error rate of the unanalyzed words by the system). • Enrich the corpus used in the learning and testing phases and correct any errors in the corpus. • Exploiting syntactic information provided by the Alkhalil Analyzer to reduce the error rate\nrelating to the vocalization of the last word character (it is recalled that almost half of the errors are at the last character of the word). • As the corpus used in the learning phase cannot cover all the Arabic language, some coefficients of the estimated transition and transmission matrices are equal to zero. In order to\nimprove the performance of our systems, some smoothing techniques studied in [24] will be used to estimate these coefficients."
    } ],
    "references" : [ {
      "title" : "Voyellation automatique de l’arabe",
      "author" : [ "Debili", "Fathi", "Hadhemi Achour" ],
      "venue" : "In Proceedings of the workshop on Computation approaches to Semitic languages,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1998
    }, {
      "title" : "Diacritization: a challenge to Arabic treebank annotation and parsing",
      "author" : [ "Maamouri", "Mohamed", "Ann Bies", "Seth Kulick" ],
      "venue" : "In Proceedings of the British Computer Society Arabic NLP/MT Conference",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2006
    }, {
      "title" : "Maximum entropy based restoration of arabic diacritics",
      "author" : [ "Zitouni", "Imed", "Jefrey S. Sorensen", "Ruhi Sarikaya" ],
      "venue" : "In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics. Workshop on Computational approaches to Semitic Languages,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2006
    }, {
      "title" : "Automatic diacritization of arabic for acoustic modeling in speech recognition",
      "author" : [ "Vergyri", "Dimitra", "Katrin Kirchhoff" ],
      "venue" : "In Proceedings of the Workshop on Computational Approaches to Arabic Script-based Languages. COLING, Geneva,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2004
    }, {
      "title" : "The limsi rt04 b arabic system",
      "author" : [ "Messaoudi", "Abdel", "Lori Lamel", "Jean-Luc Gauvain" ],
      "venue" : "In Proceedings DARPA RT04,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2004
    }, {
      "title" : "Machine generation of arabic diacritical marks",
      "author" : [ "Elshafei", "Moustafa", "Husni Al-Muhtaseb", "Mansour Alghamdi" ],
      "venue" : "In The 2006 World Congress in Computer Science Computer Engineering, and Applied Computing. Las Vegas,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2006
    }, {
      "title" : "Hierarchical approach for the statistical vowelization of arabic text. Technical report, IBM Corporation Intellectual Property",
      "author" : [ "Emam", "Ossama", "Volker Fischer" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2005
    }, {
      "title" : "Diacritization as a machinetranslation problem and as a sequence labeling problem",
      "author" : [ "Schlippe", "Tim", "ThuyLinh Guyen", "ThuyLinh Vogel" ],
      "venue" : "In 8th AMTA conference,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "An hmm approach to vowel restoration in arabic and hebrew",
      "author" : [ "Gal", "Yaakov" ],
      "venue" : "In Proceedings of the Workshop on Computational Approaches to Semitic Languages- Philadelphia- Association for Computational Linguistics,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2002
    }, {
      "title" : "Arabic diacritization using weighted finite-state transducers",
      "author" : [ "Nelken", "Rani", "Stuart M. Shieber" ],
      "venue" : "In Proceedings of the ACL 2005 Workshop On Computational Approaches To Semitic Languages, Ann Arbor, Michigan,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2005
    }, {
      "title" : "Arabic diacritization through full morphological tagging. In Proceeding NAACL-Short ’07 Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics - Companion Volume - Short Papers Rochester - New York- USA, pages 53–56",
      "author" : [ "Habash", "Nizar", "Owen Rambow" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2007
    }, {
      "title" : "Approche morpho-statistique pour la voyellation des texts arabes",
      "author" : [ "Bebah", "Mohamed Ould Abdallahi Ould", "Abdelouafi Meziane", "Azzeddine Mazroui", "Abdelhak Lakhouaja" ],
      "venue" : "Journal of Computer Science and Engineering,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2012
    }, {
      "title" : "Alkhalil morpho sys",
      "author" : [ "Bebah", "Mohamed Ould Abdallahi Ould", "Abdelouafi Meziane", "Azzeddine Mazroui", "Abdelhak Lakhouaja" ],
      "venue" : "In 7th International Computing Conference in Arabic, May 31- June",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2011
    }, {
      "title" : "Semi-automatic vowelization of arabic verbs",
      "author" : [ "T El-Sadany", "M Hashish" ],
      "venue" : "In 10th NC Conference,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1988
    }, {
      "title" : "Foundations of statistical natural language processing. Massachusetts Institute of Technology Press - Library of Congress Cataloging in publication Information",
      "author" : [ "Manning", "Chris", "Hinrich Schutze" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1999
    }, {
      "title" : "Methodes statistiques pour la voyellisation des texts arabes",
      "author" : [ "Deltour", "Amelie" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2003
    }, {
      "title" : "Automatic arabic text diacritizer-final report ci 25 02",
      "author" : [ "Mansour", "Alghamdi", "Muhammad Khursheed", "Mustafa Elshafei", "Fayz Alhargan", "Muhammed Alkanhal", "Abu Aus Alshamsan", "Saad Alqahtani", "Syed Zeeshan Muzaffar", "Yasser Altowim", "Adnan Yusuf", "Husni Almuhtasib" ],
      "venue" : "Technical report, KING ABDUL AZIZ CITY FOR SCIENCE AND TECHNOLOGY KACST",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2006
    }, {
      "title" : "A hybrid system for automatic arabic diacritization",
      "author" : [ "Rashwan", "Mohsen", "Mohammad Al-Badrashiny", "Mohamed Attia", "Sherif M. Abdou" ],
      "venue" : "In Natural Language Processing and Knowledge Engineering",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2009
    }, {
      "title" : "Arabic morphological analyzer version 2.0 - ldc2004l02",
      "author" : [ "Buckwalter", "Tim" ],
      "venue" : "In Linguistic Data Consortium, University of Pennsylvania,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2004
    }, {
      "title" : "Comparison of topic identification methods for Arabic language",
      "author" : [ "Abbas", "Mourad", "Kamel Smaili" ],
      "venue" : "In the International conference RANLP05 Recent Advances in Natural Language Processing, Borovets Bulgary,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2005
    }, {
      "title" : "United nations general assembly resolutions: a sixlanguage parallel corpus",
      "author" : [ "Rafalovitch", "Alexandre", "Robert Dale" ],
      "venue" : "In Proceedings of the MT Summit XII, Ottawa,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2009
    }, {
      "title" : "Specifications of the Arabic written corpus produced within the nemlar project. Technical report, NEMLAR, Center for Sprogteknologi",
      "author" : [ "Atiyya", "Muhammad", "Khalid Choukri", "Mustafa Yaseen" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2005
    }, {
      "title" : "The viterbi algorithm as an aid in text recognition",
      "author" : [ "D.L. Neuhoff" ],
      "venue" : "IEEE Transaction on Information Theory,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1975
    }, {
      "title" : "Smoothing techniques for arabic diacritics restoration",
      "author" : [ "Hifni", "Yasser" ],
      "venue" : "In Proceedings of the Twelfth Conference on Language Engineering (ESOLEC’12)",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "The absence of these signs generates a significant increase of the ambiguity in the Arabic text, which can cause confusion in more than 90% of the text words [1].",
      "startOffset" : 158,
      "endOffset" : 161
    }, {
      "referenceID" : 1,
      "context" : "Similarly, the limits of performance of several applications of natural language processing for Arabic (NLPA) such as parsers and Treebank are in part a result of the absence of diacritics in Arabic texts [2,3].",
      "startOffset" : 205,
      "endOffset" : 210
    }, {
      "referenceID" : 2,
      "context" : "Similarly, the limits of performance of several applications of natural language processing for Arabic (NLPA) such as parsers and Treebank are in part a result of the absence of diacritics in Arabic texts [2,3].",
      "startOffset" : 205,
      "endOffset" : 210
    }, {
      "referenceID" : 3,
      "context" : "Indeed, unlike European languages where it is easy to identify oral phonemes corresponding to texts (Text to Speech), it is imperative for Arabic texts to retrieve the diacritics before researching the correspondent oral phonemes [4].",
      "startOffset" : 230,
      "endOffset" : 233
    }, {
      "referenceID" : 4,
      "context" : "On the other hand, some research has underlined the importance of using texts with diacritics to increase the efficiency of speech recognition [5].",
      "startOffset" : 143,
      "endOffset" : 146
    }, {
      "referenceID" : 5,
      "context" : "The used approaches are often the statistical type based on the Markov models or the n-gram models [6,7,8,9].",
      "startOffset" : 99,
      "endOffset" : 108
    }, {
      "referenceID" : 6,
      "context" : "The used approaches are often the statistical type based on the Markov models or the n-gram models [6,7,8,9].",
      "startOffset" : 99,
      "endOffset" : 108
    }, {
      "referenceID" : 7,
      "context" : "The used approaches are often the statistical type based on the Markov models or the n-gram models [6,7,8,9].",
      "startOffset" : 99,
      "endOffset" : 108
    }, {
      "referenceID" : 8,
      "context" : "The used approaches are often the statistical type based on the Markov models or the n-gram models [6,7,8,9].",
      "startOffset" : 99,
      "endOffset" : 108
    }, {
      "referenceID" : 3,
      "context" : "However, some hybrid approaches using linguistic analysis followed by a statistical treatment are also used to develop an automatic vowelization system [4,10,11,12].",
      "startOffset" : 152,
      "endOffset" : 164
    }, {
      "referenceID" : 9,
      "context" : "However, some hybrid approaches using linguistic analysis followed by a statistical treatment are also used to develop an automatic vowelization system [4,10,11,12].",
      "startOffset" : 152,
      "endOffset" : 164
    }, {
      "referenceID" : 10,
      "context" : "However, some hybrid approaches using linguistic analysis followed by a statistical treatment are also used to develop an automatic vowelization system [4,10,11,12].",
      "startOffset" : 152,
      "endOffset" : 164
    }, {
      "referenceID" : 11,
      "context" : "However, some hybrid approaches using linguistic analysis followed by a statistical treatment are also used to develop an automatic vowelization system [4,10,11,12].",
      "startOffset" : 152,
      "endOffset" : 164
    }, {
      "referenceID" : 12,
      "context" : "net/projects/alkhalil) [13].",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 13,
      "context" : "Among the first studies on the subject, there is the approach mentioned in [14] that uses syntactic rules for semi-automatic vowelization of Arabic verbs.",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 0,
      "context" : "In [1], Debili, Fathi and Hadhemi Achour present a study of the automatic vowelization Arabic texts in relation to the ambiguity of written words and the impact of lexical and morphological analysis and POS tagging in detecting ambiguities and hence the vowelization of words of Arabic texts.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 14,
      "context" : "Given the great feat achieved by the statistical approaches in various fields of natural language processing such as automatic speech recognition, machine translation and information retrieval [15], the majority of works in the field of automatic vowelization of Arabic texts have adopted these approaches.",
      "startOffset" : 193,
      "endOffset" : 197
    }, {
      "referenceID" : 6,
      "context" : "Indeed, Emam and Fischer [7] had filed a patent for an automatic vowelization system for Arabic texts based on the example-based machine translation.",
      "startOffset" : 25,
      "endOffset" : 28
    }, {
      "referenceID" : 7,
      "context" : "Not far from this idea, there is in [8] an approach based on the statistical machine translation technology based on parallel corpus composed of vowelized texts and their unvowelized counterparts.",
      "startOffset" : 36,
      "endOffset" : 39
    }, {
      "referenceID" : 8,
      "context" : "Also, Gal [9] has presented a Markovian approach to vowelize the Arabic and Hebrew texts.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 15,
      "context" : "For automatic vowelization by the Markovian approaches, there are works of Deltour [16] and Elshafei, Al-Muhtaseb, and Alghamdi [6].",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 5,
      "context" : "For automatic vowelization by the Markovian approaches, there are works of Deltour [16] and Elshafei, Al-Muhtaseb, and Alghamdi [6].",
      "startOffset" : 128,
      "endOffset" : 131
    }, {
      "referenceID" : 15,
      "context" : "In [16], the researcher reviewed some statistical methods of automatic vowelization on the level of characters and words, and concluded that the best results are obtained when she has used the hidden Markov models.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 5,
      "context" : "Similarly, the researchers have presented in [6] a Markovian approach distinct from those of work of Gal [9] since it concerns all diacritical marks, and the training and evaluation processes were realized by using a variety of texts and not only the Quranic texts.",
      "startOffset" : 45,
      "endOffset" : 48
    }, {
      "referenceID" : 8,
      "context" : "Similarly, the researchers have presented in [6] a Markovian approach distinct from those of work of Gal [9] since it concerns all diacritical marks, and the training and evaluation processes were realized by using a variety of texts and not only the Quranic texts.",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 16,
      "context" : "In [17], the authors have presented an Arabic diacritizer developed at King Abdel Aziz City for Science and Technology (KACST).",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 17,
      "context" : "From important work in this field, there is the diacritizer ArabDiac developed by RDI [18].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 9,
      "context" : "The authors Nelken and Shieber [10] have proposed a method for automatic vowelization based on finite state automata.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 2,
      "context" : "Zitouni, Sorensen, and Sarikaya [3] presented a vowelizer system using statistical classifier based on maximum entropy.",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 3,
      "context" : "In [4], diacritics of Arabic words are restored by combining a morphological analysis and contextual information with an acoustic model.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 18,
      "context" : "Automatic vowelization in this work is seen as an unsupervised tagging problem where each word is tagged as one of the possible solutions provided by the Buckwalter Analyzer [19].",
      "startOffset" : 174,
      "endOffset" : 178
    }, {
      "referenceID" : 10,
      "context" : "In [11], there is a similar approach to that presented by Vergyri and Kirchhoff [4] in the sense that the vowelization problem was seen as a problem of choosing the best solution among those proposed by the Buckwalter Analyzer.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 3,
      "context" : "In [11], there is a similar approach to that presented by Vergyri and Kirchhoff [4] in the sense that the vowelization problem was seen as a problem of choosing the best solution among those proposed by the Buckwalter Analyzer.",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 11,
      "context" : "We have already presented in [12] a vowelization system for Arabic sentences based on a morpho-statistical approach.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 12,
      "context" : "The morphological Analyzer Alkhalil Morpho Sys is considered one of the most important open source Analyzers [13].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 19,
      "context" : "8 million words, has been used in applications of automatic classification of documents [20].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 20,
      "context" : "This corpus was originally collected for use in applications such as machine translation [21].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 21,
      "context" : "php?products_id=873) was carried out by several researchers in the NEMLAR project [22].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 18,
      "context" : "Because this group contains many foreign words in Arabic language commonly used in contemporary texts and foreign proper names, these words are analyzed using the Aramorph Analyzer [19].",
      "startOffset" : 181,
      "endOffset" : 185
    }, {
      "referenceID" : 0,
      "context" : "In this model, the observations are unvowelized words of the sentence, and the hidden states are the vowelized words as in previous studies [1,10].",
      "startOffset" : 140,
      "endOffset" : 146
    }, {
      "referenceID" : 9,
      "context" : "In this model, the observations are unvowelized words of the sentence, and the hidden states are the vowelized words as in previous studies [1,10].",
      "startOffset" : 140,
      "endOffset" : 146
    }, {
      "referenceID" : 22,
      "context" : "The Viterbi algorithm [23] identifies the optimal path in the network.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 14,
      "context" : ", Phk} is an Arabic corpus formed by M sentences Phk, then the training phase consists of estimating the parameters of the matrices A and B by the maximum likelihood method [15].",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 9,
      "context" : "(2005) [10] 23.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 5,
      "context" : "2010) [6] 46.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 11,
      "context" : "25 Bebah et al (2012) [12] / 20.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 23,
      "context" : "In order to improve the performance of our systems, some smoothing techniques studied in [24] will be used to estimate these coefficients.",
      "startOffset" : 89,
      "endOffset" : 93
    } ],
    "year" : 2014,
    "abstractText" : "Hybrid approaches for automatic vowelization of Arabic texts are presented in this article. The process is made up of two modules. In the first one, a morphological analysis of the text words is performed using the open source morphological Analyzer AlKhalil Morpho Sys. Outputs for each word analyzed out of context, are its different possible vowelizations. The integration of this Analyzer in our vowelization system required the addition of a lexical database containing the most frequent words in Arabic language. Using a statistical approach based on two hidden Markov models (HMM), the second module aims to eliminate the ambiguities. Indeed, for the first HMM, the unvowelized Arabic words are the observed states and the vowelized words are the hidden states. The observed states of the second HMM are identical to those of the first, but the hidden states are the lists of possible diacritics of the word without its Arabic letters. Our system uses Viterbi algorithm to select the optimal path among the solutions proposed by Al Khalil Morpho Sys. Our approach opens an important way to improve the performance of automatic vowelization of Arabic texts for other uses in automatic natural language processing.",
    "creator" : "PScript5.dll Version 5.2.2"
  }
}